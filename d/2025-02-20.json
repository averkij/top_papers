{
    "date": {
        "ru": "20 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 20",
        "zh": "2æœˆ20æ—¥"
    },
    "time_utc": "2025-02-20 04:12",
    "weekday": 3,
    "issue_id": 2310,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.13144",
            "title": "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
            "url": "https://huggingface.co/papers/2502.13144",
            "abstract": "Existing end-to-end autonomous driving (AD) algorithms typically follow the Imitation Learning (IL) paradigm, which faces challenges such as causal confusion and the open-loop gap. In this work, we establish a 3DGS-based closed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGS techniques, we construct a photorealistic digital replica of the real physical world, enabling the AD policy to extensively explore the state space and learn to handle out-of-distribution scenarios through large-scale trial and error. To enhance safety, we design specialized rewards that guide the policy to effectively respond to safety-critical events and understand real-world causal relationships. For better alignment with human driving behavior, IL is incorporated into RL training as a regularization term. We introduce a closed-loop evaluation benchmark consisting of diverse, previously unseen 3DGS environments. Compared to IL-based methods, RAD achieves stronger performance in most closed-loop metrics, especially 3x lower collision rate. Abundant closed-loop results are presented at https://hgao-cv.github.io/RAD.",
            "score": 13,
            "issue_id": 2309,
            "pub_date": "2025-02-18",
            "pub_date_card": {
                "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 18",
                "zh": "2æœˆ18æ—¥"
            },
            "hash": "0db330614af75888",
            "authors": [
                "Hao Gao",
                "Shaoyu Chen",
                "Bo Jiang",
                "Bencheng Liao",
                "Yiang Shi",
                "Xiaoyang Guo",
                "Yuechuan Pu",
                "Haoran Yin",
                "Xiangyu Li",
                "Xinbang Zhang",
                "Ying Zhang",
                "Wenyu Liu",
                "Qian Zhang",
                "Xinggang Wang"
            ],
            "affiliations": [
                "Horizon Robotics",
                "Huazhong University of Science & Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13144.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#benchmark",
                    "#alignment",
                    "#3d",
                    "#games",
                    "#reasoning",
                    "#agents"
                ],
                "emoji": "ğŸš—",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¸: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ñ„Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¸Ñ€Ğ°Ñ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼Ñƒ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ„Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ RAD, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸ Ğ¸ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒÑÑ Ñ Ğ½ĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸ÑĞ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹. Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ñ‹ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ° Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¸ Ğ±Ñ‹Ğ»Ğ¾ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ğ¸ (IL) Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ RAD Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° IL, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ² ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ ÑÑ‚Ğ¾Ğ»ĞºĞ½Ğ¾Ğ²ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Revolutionizing Autonomous Driving with Closed-Loop Reinforcement Learning",
                    "desc": "This paper presents a new approach to autonomous driving using a closed-loop Reinforcement Learning (RL) paradigm, addressing limitations of traditional Imitation Learning (IL). By creating a realistic 3D digital environment, the model can explore various driving scenarios and learn from trial and error, improving its ability to handle unexpected situations. The authors introduce specialized rewards to enhance safety by teaching the model to react appropriately to critical events and understand causal relationships in driving. Additionally, they incorporate IL as a regularization term to better align the model's behavior with human driving patterns, resulting in significantly improved performance metrics, including a lower collision rate."
                },
                "zh": {
                    "title": "é—­ç¯å¼ºåŒ–å­¦ä¹ æå‡è‡ªä¸»é©¾é©¶å®‰å…¨æ€§ä¸æ€§èƒ½",
                    "desc": "ç°æœ‰çš„ç«¯åˆ°ç«¯è‡ªä¸»é©¾é©¶ç®—æ³•é€šå¸¸é‡‡ç”¨æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰æ–¹æ³•ï¼Œä½†é¢ä¸´å› æœæ··æ·†å’Œå¼€æ”¾ç¯è·¯å·®è·ç­‰æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3DGSçš„é—­ç¯å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡æ„å»ºçœŸå®ç‰©ç†ä¸–ç•Œçš„é€¼çœŸæ•°å­—å¤åˆ¶å“ï¼Œä½¿è‡ªä¸»é©¾é©¶ç­–ç•¥èƒ½å¤Ÿå¹¿æ³›æ¢ç´¢çŠ¶æ€ç©ºé—´ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡è¯•é”™å­¦ä¹ å¤„ç†åˆ†å¸ƒå¤–åœºæ™¯ã€‚ä¸ºäº†æé«˜å®‰å…¨æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸“é—¨çš„å¥–åŠ±æœºåˆ¶ï¼Œå¼•å¯¼ç­–ç•¥æœ‰æ•ˆåº”å¯¹å®‰å…¨å…³é”®äº‹ä»¶ï¼Œå¹¶ç†è§£ç°å®ä¸–ç•Œçš„å› æœå…³ç³»ã€‚åŒæ—¶ï¼Œä¸ºäº†æ›´å¥½åœ°ä¸äººç±»é©¾é©¶è¡Œä¸ºå¯¹é½ï¼Œæˆ‘ä»¬å°†æ¨¡ä»¿å­¦ä¹ ä½œä¸ºæ­£åˆ™åŒ–é¡¹èå…¥åˆ°å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.13922",
            "title": "LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization",
            "url": "https://huggingface.co/papers/2502.13922",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities through pretraining and alignment. However, superior short-context LLMs may underperform in long-context scenarios due to insufficient long-context alignment. This alignment process remains challenging due to the impracticality of human annotation for extended contexts and the difficulty in balancing short- and long-context performance. To address these challenges, we introduce LongPO, that enables short-context LLMs to self-evolve to excel on long-context tasks by internally transferring short-context capabilities. LongPO harnesses LLMs to learn from self-generated short-to-long preference data, comprising paired responses generated for identical instructions with long-context inputs and their compressed short-context counterparts, respectively. This preference reveals capabilities and potentials of LLMs cultivated during short-context alignment that may be diminished in under-aligned long-context scenarios. Additionally, LongPO incorporates a short-to-long KL constraint to mitigate short-context performance decline during long-context alignment. When applied to Mistral-7B-Instruct-v0.2 from 128K to 512K context lengths, LongPO fully retains short-context performance and largely outperforms naive SFT and DPO in both long- and short-context tasks. Specifically, \\ourMethod-trained models can achieve results on long-context benchmarks comparable to, or even surpassing, those of superior LLMs (e.g., GPT-4-128K) that involve extensive long-context annotation and larger parameter scales.",
            "score": 11,
            "issue_id": 2309,
            "pub_date": "2025-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "93cf8365ba7edb80",
            "authors": [
                "Guanzheng Chen",
                "Xin Li",
                "Michael Qizhe Shieh",
                "Lidong Bing"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group",
                "Hupan Lab, 310023, Hangzhou, China",
                "National University of Singapore",
                "Shanda AI Research Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13922.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#transfer_learning",
                    "#benchmark",
                    "#long_context",
                    "#architecture",
                    "#rlhf"
                ],
                "emoji": "ğŸ“",
                "ru": {
                    "title": "LongPO: Ğ¡Ğ°Ğ¼Ğ¾ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ LongPO Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼. LongPO Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ½Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…, ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğº Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑĞ°Ğ¼Ğ¾Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑÑ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ KL Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ LongPO Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ°Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¸ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…."
                },
                "en": {
                    "title": "Empowering Short-Context LLMs for Long-Context Mastery",
                    "desc": "This paper presents LongPO, a method designed to enhance the performance of short-context Large Language Models (LLMs) on long-context tasks. The challenge arises from the difficulty of aligning LLMs for long contexts due to the lack of human-annotated data and the need to balance performance across different context lengths. LongPO allows LLMs to learn from their own generated data, creating a preference model that helps them adapt their short-context skills to long-context scenarios. The results show that models trained with LongPO maintain their short-context performance while significantly improving their long-context capabilities, even rivaling more advanced models like GPT-4."
                },
                "zh": {
                    "title": "LongPOï¼šçŸ­ä¸Šä¸‹æ–‡æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡è‡ªæˆ‘æ¼”åŒ–",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢„è®­ç»ƒå’Œå¯¹é½æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­å¯èƒ½è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†LongPOæ–¹æ³•ï¼Œä½¿çŸ­ä¸Šä¸‹æ–‡çš„LLMsèƒ½å¤Ÿè‡ªæˆ‘æ¼”åŒ–ï¼Œä»¥åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚LongPOé€šè¿‡ç”ŸæˆçŸ­åˆ°é•¿çš„åå¥½æ•°æ®ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¹ å¦‚ä½•åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­ä¿æŒçŸ­ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨LongPOçš„æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³å¯ä»¥ä¸æ›´å¼ºå¤§çš„LLMsç›¸åª²ç¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.13965",
            "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
            "url": "https://huggingface.co/papers/2502.13965",
            "abstract": "Large language model (LLM) applications are evolving beyond simple chatbots into dynamic, general-purpose agentic programs, which scale LLM calls and output tokens to help AI agents reason, explore, and solve complex tasks. However, existing LLM serving systems ignore dependencies between programs and calls, missing significant opportunities for optimization. Our analysis reveals that programs submitted to LLM serving engines experience long cumulative wait times, primarily due to head-of-line blocking at both the individual LLM request and the program. To address this, we introduce Autellix, an LLM serving system that treats programs as first-class citizens to minimize their end-to-end latencies. Autellix intercepts LLM calls submitted by programs, enriching schedulers with program-level context. We propose two scheduling algorithms-for single-threaded and distributed programs-that preempt and prioritize LLM calls based on their programs' previously completed calls. Our evaluation demonstrates that across diverse LLMs and agentic workloads, Autellix improves throughput of programs by 4-15x at the same latency compared to state-of-the-art systems, such as vLLM.",
            "score": 7,
            "issue_id": 2310,
            "pub_date": "2025-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "f64be1cc6aba8b4c",
            "authors": [
                "Michael Luo",
                "Xiaoxiang Shi",
                "Colin Cai",
                "Tianjun Zhang",
                "Justin Wong",
                "Yichuan Wang",
                "Chi Wang",
                "Yanping Huang",
                "Zhifeng Chen",
                "Joseph E. Gonzalez",
                "Ion Stoica"
            ],
            "affiliations": [
                "Google DeepMind",
                "Shanghai Jiao Tong University",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13965.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#agents",
                    "#architecture"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Autellix: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğ¸ LLM Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Autellix - ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰ÑƒÑ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼. Autellix Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ ĞºĞ°Ğº Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°, Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ LLM Ğ¸ Ğ¾Ğ±Ğ¾Ğ³Ğ°Ñ‰Ğ°Ñ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ñ‹ Ğ´Ğ²Ğ° Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¿Ğ¾Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ¸ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ LLM Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€Ğ°Ğ½ĞµĞµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ñ‹Ñ… Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Autellix ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ½ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼ Ğ² 4-15 Ñ€Ğ°Ğ· Ğ¿Ñ€Ğ¸ Ñ‚Ğ¾Ğ¹ Ğ¶Ğµ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞµ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Autellix: Optimizing LLM Serving for Enhanced Throughput",
                    "desc": "This paper discusses the evolution of large language models (LLMs) from simple chatbots to more complex, agentic programs that can perform a variety of tasks. It identifies a significant issue in current LLM serving systems, which overlook the dependencies between different programs and their calls, leading to inefficiencies and long wait times. The authors introduce Autellix, a new LLM serving system that optimizes these processes by treating programs as first-class entities and enhancing scheduling with program-level context. Their proposed scheduling algorithms significantly improve the throughput of LLM programs, achieving 4-15 times better performance compared to existing systems while maintaining similar latency."
                },
                "zh": {
                    "title": "ä¼˜åŒ–LLMè°ƒç”¨ï¼Œæå‡ç¨‹åºæ€§èƒ½çš„Autellix",
                    "desc": "è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡ç³»ç»Ÿï¼Œåä¸ºAutellixã€‚Autellixé€šè¿‡å°†ç¨‹åºè§†ä¸ºç¬¬ä¸€ç±»å…¬æ°‘ï¼Œä¼˜åŒ–äº†LLMè°ƒç”¨çš„è°ƒåº¦ï¼Œä»è€Œå‡å°‘äº†æ•´ä½“å»¶è¿Ÿã€‚ç ”ç©¶è¡¨æ˜ï¼Œç°æœ‰çš„LLMæœåŠ¡ç³»ç»Ÿå¿½è§†äº†ç¨‹åºä¸è°ƒç”¨ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´äº†é•¿æ—¶é—´çš„ç­‰å¾…ã€‚é€šè¿‡å¼•å…¥æ–°çš„è°ƒåº¦ç®—æ³•ï¼ŒAutellixåœ¨å¤šç§LLMå’Œä»»åŠ¡è´Ÿè½½ä¸‹ï¼Œæå‡äº†ç¨‹åºçš„ååé‡ï¼Œæ•ˆæœæ˜¾è‘—ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.13347",
            "title": "Craw4LLM: Efficient Web Crawling for LLM Pretraining",
            "url": "https://huggingface.co/papers/2502.13347",
            "abstract": "Web crawl is a main source of large language models' (LLMs) pretraining data, but the majority of crawled web pages are discarded in pretraining due to low data quality. This paper presents Crawl4LLM, an efficient web crawling method that explores the web graph based on the preference of LLM pretraining. Specifically, it leverages the influence of a webpage in LLM pretraining as the priority score of the web crawler's scheduler, replacing the standard graph connectivity based priority. Our experiments on a web graph containing 900 million webpages from a commercial search engine's index demonstrate the efficiency of Crawl4LLM in obtaining high-quality pretraining data. With just 21% URLs crawled, LLMs pretrained on Crawl4LLM data reach the same downstream performances of previous crawls, significantly reducing the crawling waste and alleviating the burdens on websites. Our code is publicly available at https://github.com/cxcscmu/Crawl4LLM.",
            "score": 6,
            "issue_id": 2310,
            "pub_date": "2025-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "dd055f606e1ddfe2",
            "authors": [
                "Shi Yu",
                "Zhiyuan Liu",
                "Chenyan Xiong"
            ],
            "affiliations": [
                "Department of Computer Science and Technology, Tsinghua University",
                "School of Computer Science, Carnegie Mellon University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13347.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#graphs",
                    "#open_source",
                    "#data"
                ],
                "emoji": "ğŸ•·ï¸",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ²ĞµĞ±-ĞºÑ€Ğ°ÑƒĞ»Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Crawl4LLM - ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ²ĞµĞ±-ĞºÑ€Ğ°ÑƒĞ»Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±-ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ LLM Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ° ĞºÑ€Ğ°ÑƒĞ»ĞµÑ€Ğ°, Ğ·Ğ°Ğ¼ĞµĞ½ÑÑ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ²ÑĞ·Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ³Ñ€Ğ°Ñ„Ğµ Ğ¸Ğ· 900 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Crawl4LLM Ğ² Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ²ÑĞµĞ³Ğ¾ 21% URL Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ Ñ‚ĞµÑ… Ğ¶Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ñ‡Ñ‚Ğ¾ Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°Ñ… Ğº ĞºÑ€Ğ°ÑƒĞ»Ğ¸Ğ½Ğ³Ñƒ."
                },
                "en": {
                    "title": "Crawl Smart: Boosting LLMs with Efficient Web Crawling",
                    "desc": "This paper introduces Crawl4LLM, a novel web crawling technique designed to enhance the quality of pretraining data for large language models (LLMs). Instead of relying on traditional methods that prioritize web page connectivity, Crawl4LLM uses a priority score based on the potential influence of a webpage on LLM performance. The method was tested on a vast web graph with 900 million pages, showing that it can achieve comparable downstream performance with only 21% of the URLs crawled. This approach not only improves data quality but also minimizes the environmental impact of web crawling by reducing unnecessary data collection."
                },
                "zh": {
                    "title": "é«˜æ•ˆçˆ¬è™«ï¼Œæå‡LLMé¢„è®­ç»ƒæ•°æ®è´¨é‡",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCrawl4LLMçš„é«˜æ•ˆç½‘ç»œçˆ¬è™«æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒæ•°æ®çš„è´¨é‡ã€‚è¯¥æ–¹æ³•é€šè¿‡ç½‘é¡µåœ¨LLMé¢„è®­ç»ƒä¸­çš„å½±å“åŠ›ä½œä¸ºä¼˜å…ˆçº§è¯„åˆ†ï¼Œä¼˜åŒ–äº†çˆ¬è™«è°ƒåº¦å™¨çš„å·¥ä½œï¼Œè€Œä¸æ˜¯ä¾èµ–äºä¼ ç»Ÿçš„å›¾è¿æ¥æ€§ä¼˜å…ˆçº§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCrawl4LLMåœ¨ä»…çˆ¬å–21%çš„ç½‘å€çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿè·å¾—ä¸ä¹‹å‰çˆ¬å–ç›¸åŒçš„ä¸‹æ¸¸æ€§èƒ½ï¼Œæ˜¾è‘—å‡å°‘äº†çˆ¬å–æµªè´¹ã€‚æ­¤æ–¹æ³•ä¸ä»…æé«˜äº†æ•°æ®è´¨é‡ï¼Œè¿˜å‡è½»äº†å¯¹ç½‘ç«™çš„è´Ÿæ‹…ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.12143",
            "title": "Small Models Struggle to Learn from Strong Reasoners",
            "url": "https://huggingface.co/papers/2502.12143",
            "abstract": "Large language models (LLMs) excel in complex reasoning tasks, and distilling their reasoning capabilities into smaller models has shown promise. However, we uncover an interesting phenomenon, which we term the Small Model Learnability Gap: small models (leq3B parameters) do not consistently benefit from long chain-of-thought (CoT) reasoning or distillation from larger models. Instead, they perform better when fine-tuned on shorter, simpler reasoning chains that better align with their intrinsic learning capacity. To address this, we propose Mix Distillation, a simple yet effective strategy that balances reasoning complexity by combining long and short CoT examples or reasoning from both larger and smaller models. Our experiments demonstrate that Mix Distillation significantly improves small model reasoning performance compared to training on either data alone. These findings highlight the limitations of direct strong model distillation and underscore the importance of adapting reasoning complexity for effective reasoning capability transfer.",
            "score": 6,
            "issue_id": 2309,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "5abea4fb025815c2",
            "authors": [
                "Yuetai Li",
                "Xiang Yue",
                "Zhangchen Xu",
                "Fengqing Jiang",
                "Luyao Niu",
                "Bill Yuchen Lin",
                "Bhaskar Ramasubramanian",
                "Radha Poovendran"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "University of Washington",
                "Western Washington University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12143.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#transfer_learning",
                    "#optimization",
                    "#reasoning",
                    "#small_models"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ğ»Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ´Ğ¾ 3 Ğ¼Ğ»Ñ€Ğ´ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²) Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¸ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¾Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ Mix Distillation, ÑĞ¾Ñ‡ĞµÑ‚Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¸ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼."
                },
                "en": {
                    "title": "Bridging the Learnability Gap for Small Models with Mix Distillation",
                    "desc": "This paper explores the challenges faced by small language models (with 3 billion parameters or fewer) in learning from complex reasoning tasks. It identifies a phenomenon called the Small Model Learnability Gap, where these smaller models do not gain advantages from long chain-of-thought (CoT) reasoning or direct distillation from larger models. Instead, they perform better when trained on shorter, simpler reasoning chains that match their learning abilities. To improve their performance, the authors propose a method called Mix Distillation, which combines both long and short reasoning examples, leading to better reasoning outcomes for small models."
                },
                "zh": {
                    "title": "æ··åˆè’¸é¦ï¼šæå‡å°æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆç­–ç•¥",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æˆ‘ä»¬å‘ç°å°æ¨¡å‹ï¼ˆå‚æ•°å°äºç­‰äº3äº¿ï¼‰åœ¨é•¿é“¾æ¨ç†æˆ–ä»å¤§æ¨¡å‹è’¸é¦ä¸­å¹¶ä¸æ€»æ˜¯å—ç›Šã€‚ç›¸åï¼Œå®ƒä»¬åœ¨çŸ­å°ç®€å•çš„æ¨ç†é“¾ä¸Šå¾®è°ƒæ—¶è¡¨ç°æ›´å¥½ï¼Œè¿™ä¸å®ƒä»¬çš„å­¦ä¹ èƒ½åŠ›æ›´ä¸ºå¥‘åˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆè’¸é¦ï¼ˆMix Distillationï¼‰ç­–ç•¥ï¼Œé€šè¿‡ç»“åˆé•¿çŸ­æ¨ç†ç¤ºä¾‹æˆ–æ¥è‡ªå¤§æ¨¡å‹å’Œå°æ¨¡å‹çš„æ¨ç†ï¼Œå¹³è¡¡æ¨ç†å¤æ‚æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæ··åˆè’¸é¦æ˜¾è‘—æé«˜äº†å°æ¨¡å‹çš„æ¨ç†æ€§èƒ½ï¼Œå¼ºè°ƒäº†ç›´æ¥å¼ºæ¨¡å‹è’¸é¦çš„å±€é™æ€§ï¼Œå¹¶çªå‡ºäº†é€‚åº”æ¨ç†å¤æ‚æ€§çš„é‡è¦æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.13233",
            "title": "SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?",
            "url": "https://huggingface.co/papers/2502.13233",
            "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in general domains but often struggle with tasks requiring specialized knowledge. Conventional Retrieval-Augmented Generation (RAG) techniques typically retrieve external information from static knowledge bases, which can be outdated or incomplete, missing fine-grained clinical details essential for accurate medical question answering. In this work, we propose SearchRAG, a novel framework that overcomes these limitations by leveraging real-time search engines. Our method employs synthetic query generation to convert complex medical questions into search-engine-friendly queries and utilizes uncertainty-based knowledge selection to filter and incorporate the most relevant and informative medical knowledge into the LLM's input. Experimental results demonstrate that our method significantly improves response accuracy in medical question answering tasks, particularly for complex questions requiring detailed and up-to-date knowledge.",
            "score": 5,
            "issue_id": 2310,
            "pub_date": "2025-02-18",
            "pub_date_card": {
                "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 18",
                "zh": "2æœˆ18æ—¥"
            },
            "hash": "58503159cb9ed740",
            "authors": [
                "Yucheng Shi",
                "Tianze Yang",
                "Canyu Chen",
                "Quanzheng Li",
                "Tianming Liu",
                "Xiang Li",
                "Ninghao Liu"
            ],
            "affiliations": [
                "Illinois Institute of Technology",
                "Massachusetts General Hospital and Harvard Medical School",
                "University of Georgia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13233.jpg",
            "data": {
                "categories": [
                    "#rag",
                    "#synthetic",
                    "#healthcare",
                    "#science"
                ],
                "emoji": "ğŸ©º",
                "ru": {
                    "title": "SearchRAG: Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ SearchRAG - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸, SearchRAG Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ Ğ¾Ñ‚Ğ±Ğ¾Ñ€ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ SearchRAG Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Enhancing Medical Q&A with Real-Time Search and Smart Querying",
                    "desc": "This paper introduces SearchRAG, a new framework designed to enhance the performance of Large Language Models (LLMs) in medical question answering. Unlike traditional Retrieval-Augmented Generation (RAG) methods that rely on static knowledge bases, SearchRAG utilizes real-time search engines to access current and detailed medical information. The framework employs synthetic query generation to transform complex medical inquiries into queries suitable for search engines, and it uses uncertainty-based knowledge selection to ensure that only the most relevant information is included. Experimental results indicate that SearchRAG significantly boosts the accuracy of LLM responses, especially for intricate medical questions that demand precise and updated knowledge."
                },
                "zh": {
                    "title": "å®æ—¶æœç´¢æå‡åŒ»ç–—é—®ç­”å‡†ç¡®æ€§",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸€èˆ¬é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„ä»»åŠ¡ä¸­å¸¸å¸¸é‡åˆ°å›°éš¾ã€‚ä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯é€šå¸¸ä»é™æ€çŸ¥è¯†åº“ä¸­æ£€ç´¢å¤–éƒ¨ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯èƒ½è¿‡æ—¶æˆ–ä¸å®Œæ•´ï¼Œç¼ºä¹å‡†ç¡®åŒ»ç–—é—®ç­”æ‰€éœ€çš„ç»†èŠ‚ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶SearchRAGï¼Œé€šè¿‡åˆ©ç”¨å®æ—¶æœç´¢å¼•æ“æ¥å…‹æœè¿™äº›é™åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒ»ç–—é—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†å“åº”å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯å¯¹äºéœ€è¦è¯¦ç»†å’Œæœ€æ–°çŸ¥è¯†çš„å¤æ‚é—®é¢˜ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.13943",
            "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
            "url": "https://huggingface.co/papers/2502.13943",
            "abstract": "Current approaches for training Process Reward Models (PRMs) often involve breaking down responses into multiple reasoning steps using rule-based techniques, such as using predefined placeholder tokens or setting the reasoning step's length into a fixed size. These approaches overlook the fact that specific words do not typically mark true decision points in a text. To address this, we propose AdaptiveStep, a method that divides reasoning steps based on the model's confidence in predicting the next word. This division method provides more decision-making information at each step, enhancing downstream tasks, such as reward model learning. Moreover, our method does not require manual annotation. We demonstrate its effectiveness through experiments with AdaptiveStep-trained PRMs in mathematical reasoning and code generation tasks. Experimental results indicate that the outcome PRM achieves state-of-the-art Best-of-N performance, surpassing greedy search strategy with token-level value-guided decoding, while also reducing construction costs by over 30% compared to existing open-source PRMs. In addition, we provide a thorough analysis and case study on the PRM's performance, transferability, and generalization capabilities.",
            "score": 2,
            "issue_id": 2310,
            "pub_date": "2025-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "41ab630e56147df2",
            "authors": [
                "Yuliang Liu",
                "Junjie Lu",
                "Zhaoling Chen",
                "Chaofeng Qu",
                "Jason Klein Liu",
                "Chonghan Liu",
                "Zefan Cai",
                "Yunhui Xia",
                "Li Zhao",
                "Jiang Bian",
                "Chuheng Zhang",
                "Wei Shen",
                "Zhouhan Lin"
            ],
            "affiliations": [
                "MSRA",
                "Nanjing University",
                "Shanghai Jiaotong University",
                "UW-Madison",
                "University of Technology Sydney"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.13943.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#plp",
                    "#training",
                    "#open_source",
                    "#math",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "AdaptiveStep: ÑƒĞ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑˆĞ°Ğ³Ğ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ PRM",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ AdaptiveStep Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² (PRM). Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° ÑˆĞ°Ğ³Ğ¸ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹, AdaptiveStep Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¸ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† ÑˆĞ°Ğ³Ğ¾Ğ² Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑˆĞ°Ğ³Ğµ Ğ¸ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ PRM, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AdaptiveStep, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ´Ğ°, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹."
                },
                "en": {
                    "title": "AdaptiveStep: Smarter Reasoning for Better Reward Models",
                    "desc": "This paper introduces AdaptiveStep, a novel method for training Process Reward Models (PRMs) that improves the way reasoning steps are defined. Instead of relying on fixed-length steps or predefined tokens, AdaptiveStep adjusts the reasoning process based on the model's confidence in predicting the next word. This approach enhances the decision-making information available at each step, leading to better performance in tasks like reward model learning. Experimental results show that PRMs trained with AdaptiveStep outperform traditional methods in mathematical reasoning and code generation, while also being more cost-effective."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”æ­¥éª¤ï¼šæå‡å¥–åŠ±æ¨¡å‹çš„å†³ç­–èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰çš„æ–¹æ³•ï¼Œç§°ä¸ºAdaptiveStepã€‚è¯¥æ–¹æ³•é€šè¿‡æ ¹æ®æ¨¡å‹å¯¹ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹çš„ä¿¡å¿ƒæ¥åˆ’åˆ†æ¨ç†æ­¥éª¤ï¼Œä»è€Œæä¾›æ›´ä¸°å¯Œçš„å†³ç­–ä¿¡æ¯ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•ä¸åŒï¼ŒAdaptiveStepä¸éœ€è¦æ‰‹åŠ¨æ ‡æ³¨ï¼Œä¸”åœ¨æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨AdaptiveStepè®­ç»ƒçš„PRMåœ¨æ€§èƒ½ä¸Šè¶…è¿‡äº†ç°æœ‰çš„å¼€æºPRMï¼Œå¹¶ä¸”æ„å»ºæˆæœ¬é™ä½äº†30%ä»¥ä¸Šã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-02-19.html",
    "link_next": "2025-02-21.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "19.02",
        "en": "02/19",
        "zh": "2æœˆ19æ—¥"
    },
    "short_date_next": {
        "ru": "21.02",
        "en": "02/21",
        "zh": "2æœˆ21æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 2,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 1,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 1,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 3,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç°æœ‰ç«¯åˆ°ç«¯è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œæ•°æ®é«˜æ•ˆè®­ç»ƒå°šæœªæ·±å…¥æ¢è®¨ã€‚æ–‡ç« èšç„¦äºè¯­éŸ³å’Œæ–‡æœ¬ä¹‹é—´çš„ä¸¤ä¸ªåŸºæœ¬é—®é¢˜ï¼šè¡¨ç¤ºç©ºé—´å·®è·å’Œåºåˆ—é•¿åº¦ä¸ä¸€è‡´ã€‚ä½œè€…æå‡ºäº†Soundwaveï¼Œå®ƒä½¿ç”¨é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥å’Œæ–°é¢–çš„æ¶æ„æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚ç»“æœæ˜¾ç¤ºï¼ŒSoundwaveåœ¨ä½¿ç”¨äº”ååˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®æ—¶ï¼Œåœ¨è¯­éŸ³ç¿»è¯‘å’ŒAIR-Benchè¯­éŸ³ä»»åŠ¡ä¸­ä¼˜äºå…ˆè¿›çš„Qwen2-Audioã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒSoundwaveåœ¨å¯¹è¯ä¸­ä»ä¿æŒå…¶æ™ºèƒ½ã€‚é¡¹ç›®çš„ä»£ç å¯åœ¨https://github.com/FreedomIntelligence/Soundwaveæ‰¾åˆ°ã€‚",
        "title": "Soundwave: Less is More for Speech-Text Alignment in LLMs",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç°æœ‰ç«¯åˆ°ç«¯è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œæ•°æ®é«˜æ•ˆè®­ç»ƒå°šæœªæ·±å…¥æ¢è®¨ã€‚\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le xiÃ nyÇ’u duÄnduÄn yÇ”yÄ«n dÃ  yÇ”yÃ¡n mÃ³xÃ­ng (LLMs) tÅngchÃ¡ng yÄ«lÃ i dÃ  guÄ«mÃ³ biÄozhÃ¹ shÃ¹jÃ¹ jÃ¬nxÃ­ng xÃ¹nliÃ n, Ã©r shÃ¹jÃ¹ gÄoxiÃ o xÃ¹nliÃ n shÃ ngwÃ¨i shÄ“nrÃ¹ tÃ ntÃ o.\n\næ–‡ç« èšç„¦äºè¯­éŸ³å’Œæ–‡æœ¬ä¹‹é—´çš„ä¸¤ä¸ªåŸºæœ¬é—®é¢˜ï¼šè¡¨ç¤ºç©ºé—´å·®è·å’Œåºåˆ—é•¿åº¦ä¸ä¸€è‡´ã€‚\nWÃ©nzhÄng jÃ¹jiÄo yÃº yÇ”yÄ«n hÃ© wÃ©nbÄ›n zhÄ«jiÄn de liÇng gÃ¨ jÄ«bÄ›n wÃ¨ntÃ­: biÇoshÃ¬ kÅngjiÄn chÄjÃ¹ hÃ© xÃ¹liÃ¨ chÃ¡ngdÃ¹ bÃ¹ yÄ«zhÃ¬.\n\nä½œè€…æå‡ºäº†Soundwaveï¼Œå®ƒä½¿ç”¨é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥å’Œæ–°é¢–çš„æ¶æ„æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚\nZuÃ²zhÄ› tÃ­chÅ« le Soundwave, tÄ shÇyÃ²ng gÄoxiÃ o de xÃ¹nliÃ n cÃ¨lÃ¼Ã¨ hÃ© xÄ«nyÇng de jiÃ gÃ²u lÃ¡i jiÄ›juÃ© zhÃ¨xiÄ“ wÃ¨ntÃ­.\n\nç»“æœæ˜¾ç¤ºï¼ŒSoundwaveåœ¨ä½¿ç”¨äº”ååˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®æ—¶ï¼Œåœ¨è¯­éŸ³ç¿»è¯‘å’ŒAIR-Benchè¯­éŸ³ä»»åŠ¡ä¸­ä¼˜äºå…ˆè¿›çš„Qwen2-Audioã€‚\nJiÃ©gÇ”o xiÇnshÃ¬, Soundwave zÃ i shÇyÃ²ng wÇ”shÃ­ fÄ“n zhÄ« yÄ« de xÃ¹nliÃ n shÃ¹jÃ¹ shÃ­, zÃ i yÇ”yÄ«n fÄnyÃ¬ hÃ© AIR-Bench yÇ”yÄ«n rÃ¨nwÃ¹ zhÅng yÅuyÃº xiÄnjÃ¬n de Qwen2-Audio.\n\nè¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒSoundwaveåœ¨å¯¹è¯ä¸­ä»ä¿æŒå…¶æ™ºèƒ½ã€‚\nJÃ¬n yÄ«bÃ¹ fÄ“nxiÇn biÇomÃ­ng, Soundwave zÃ i duÃ¬huÃ  zhÅng rÃ©ng bÇochÃ­ qÃ­ zhÃ¬nÃ©ng.\n\né¡¹ç›®çš„ä»£ç å¯åœ¨https://github.com/FreedomIntelligence/Soundwaveæ‰¾åˆ°ã€‚\nXiÃ ngmÃ¹ de dÃ imÇ kÄ› zÃ i https://github.com/FreedomIntelligence/Soundwave zhÇo dÃ o.",
        "vocab": "[\n    {\"word\": \"è®¨è®º\", \"pinyin\": \"tÇo lÃ¹n\", \"trans\": \"discuss\"},\n    {\"word\": \"ç«¯åˆ°ç«¯\", \"pinyin\": \"duÄn dÃ o duÄn\", \"trans\": \"end-to-end\"},\n    {\"word\": \"è¯­éŸ³\", \"pinyin\": \"yÇ” yÄ«n\", \"trans\": \"speech\"},\n    {\"word\": \"å¤§è¯­è¨€æ¨¡å‹\", \"pinyin\": \"dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng\", \"trans\": \"large language model\"},\n    {\"word\": \"ä¾èµ–\", \"pinyin\": \"yÄ« lÃ i\", \"trans\": \"rely on\"},\n    {\"word\": \"å¤§è§„æ¨¡\", \"pinyin\": \"dÃ  guÄ« mÃ³\", \"trans\": \"large-scale\"},\n    {\"word\": \"æ ‡æ³¨\", \"pinyin\": \"biÄo zhÃ¹\", \"trans\": \"annotate\"},\n    {\"word\": \"æ•°æ®\", \"pinyin\": \"shÃ¹ jÃ¹\", \"trans\": \"data\"},\n    {\"word\": \"è¿›è¡Œ\", \"pinyin\": \"jÃ¬n xÃ­ng\", \"trans\": \"carry out\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹n liÃ n\", \"trans\": \"train\"},\n    {\"word\": \"é«˜æ•ˆ\", \"pinyin\": \"gÄo xiÃ o\", \"trans\": \"efficient\"},\n    {\"word\": \"æ·±å…¥\", \"pinyin\": \"shÄ“n rÃ¹\", \"trans\": \"in-depth\"},\n    {\"word\": \"æ¢è®¨\", \"pinyin\": \"tÃ n tÇo\", \"trans\": \"explore\"},\n    {\"word\": \"èšç„¦\", \"pinyin\": \"jÃ¹ jiÄo\", \"trans\": \"focus on\"},\n    {\"word\": \"åŸºæœ¬\", \"pinyin\": \"jÄ« bÄ›n\", \"trans\": \"basic\"},\n    {\"word\": \"é—®é¢˜\", \"pinyin\": \"wÃ¨n tÃ­\", \"trans\": \"problem\"},\n    {\"word\": \"è¡¨ç¤º\", \"pinyin\": \"biÇo shÃ¬\", \"trans\": \"represent\"},\n    {\"word\": \"ç©ºé—´\", \"pinyin\": \"kÅng jiÄn\", \"trans\": \"space\"},\n    {\"word\": \"å·®è·\", \"pinyin\": \"chÄ jÃ¹\", \"trans\": \"gap\"},\n    {\"word\": \"åºåˆ—\", \"pinyin\": \"xÃ¹ liÃ¨\", \"trans\": \"sequence\"},\n    {\"word\": \"é•¿åº¦\", \"pinyin\": \"chÃ¡ng dÃ¹\", \"trans\": \"length\"},\n    {\"word\": \"ä¸ä¸€è‡´\", \"pinyin\": \"bÃ¹ yÄ« zhÃ¬\", \"trans\": \"inconsistent\"},\n    {\"word\": \"æå‡º\", \"pinyin\": \"tÃ­ chÅ«\", \"trans\": \"propose\"},\n    {\"word\": \"ç­–ç•¥\", \"pinyin\": \"cÃ¨ lÃ¼Ã¨\", \"trans\": \"strategy\"},\n    {\"word\": \"æ¶æ„\", \"pinyin\": \"jiÃ  gÃ²u\", \"trans\": \"architecture\"},\n    {\"word\": \"è§£å†³\", \"pinyin\": \"jiÄ› juÃ©\", \"trans\": \"solve\"},\n    {\"word\": \"ç»“æœ\", \"pinyin\": \"jiÃ© guÇ’\", \"trans\": \"result\"},\n    {\"word\": \"æ˜¾ç¤º\", \"pinyin\": \"xiÇn shÃ¬\", \"trans\": \"show\"},\n    {\"word\": \"ä¼˜äº\", \"pinyin\": \"yÅu yÃº\", \"trans\": \"superior to\"},\n    {\"word\": \"å…ˆè¿›\", \"pinyin\": \"xiÄn jÃ¬n\", \"trans\": \"advanced\"},\n    {\"word\": \"åˆ†æ\", \"pinyin\": \"fÄ“n xÄ«\", \"trans\": \"analyze\"},\n    {\"word\": \"è¡¨æ˜\", \"pinyin\": \"biÇo mÃ­ng\", \"trans\": \"indicate\"},\n    {\"word\": \"ä¿æŒ\", \"pinyin\": \"bÇo chÃ­\", \"trans\": \"maintain\"},\n    {\"word\": \"æ™ºèƒ½\", \"pinyin\": \"zhÃ¬ nÃ©ng\", \"trans\": \"intelligence\"},\n    {\"word\": \"é¡¹ç›®\", \"pinyin\": \"xiÃ ng mÃ¹\", \"trans\": \"project\"},\n    {\"word\": \"ä»£ç \", \"pinyin\": \"dÃ i mÇ\", \"trans\": \"code\"}\n]",
        "trans": "This article discusses how existing end-to-end speech large language models (LLMs) typically rely on large-scale annotated data for training, while data-efficient training has not been deeply explored. The article focuses on two fundamental issues between speech and text: the representation space gap and the inconsistency in sequence length. The authors propose Soundwave, which employs efficient training strategies and novel architecture to address these problems. The results show that Soundwave outperforms the advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks while using one-fiftieth of the training data. Further analysis indicates that Soundwave retains its intelligence in conversations. The project's code can be found at https://github.com/FreedomIntelligence/Soundwave.",
        "update_ts": "2025-02-19 09:11"
    }
}