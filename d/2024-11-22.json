{
    "date": {
        "ru": "22 ноября",
        "en": "November 22",
        "zh": "11月22日"
    },
    "time_utc": "2024-11-22 11:09",
    "weekday": 4,
    "issue_id": 728,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.10442",
            "title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization",
            "url": "https://huggingface.co/papers/2411.10442",
            "abstract": "Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning, particularly in the Chain-of-Thought (CoT) performance. To address this, we introduce a preference optimization (PO) process to enhance the multimodal reasoning capabilities of MLLMs. Specifically, (1) on the data side, we design an automated preference data construction pipeline to create MMPR, a high-quality, large-scale multimodal reasoning preference dataset. and (2) on the model side, we explore integrating PO with MLLMs, developing a simple yet effective method, termed Mixed Preference Optimization (MPO), which boosts multimodal CoT performance. Our approach demonstrates improved performance across multiple benchmarks, particularly in multimodal reasoning tasks. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 on MathVista, outperforming InternVL2-8B by 8.7 points and achieving performance comparable to the 10x larger InternVL2-76B. We hope this study could inspire further advancements in MLLMs. Code, data, and model shall be publicly released.",
            "score": 32,
            "issue_id": 722,
            "pub_date": "2024-11-15",
            "pub_date_card": {
                "ru": "15 ноября",
                "en": "November 15",
                "zh": "11月15日"
            },
            "hash": "3cc3675b352b1634",
            "authors": [
                "Weiyun Wang",
                "Zhe Chen",
                "Wenhai Wang",
                "Yue Cao",
                "Yangzhou Liu",
                "Zhangwei Gao",
                "Jinguo Zhu",
                "Xizhou Zhu",
                "Lewei Lu",
                "Yu Qiao",
                "Jifeng Dai"
            ],
            "affiliations": [
                "Fudan University",
                "Nanjing University",
                "OpenGVLab, Shanghai AI Laboratory",
                "SenseTime Research",
                "The Chinese University of Hong Kong",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.10442.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#benchmark",
                    "#reasoning",
                    "#open_source",
                    "#dataset",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Усиление мультимодальных рассуждений ИИ через оптимизацию предпочтений",
                    "desc": "Исследователи представили новый метод улучшения мультимодальных языковых моделей (MLLM) с помощью оптимизации предпочтений (PO). Они создали крупномасштабный набор данных MMPR для мультимодальных рассуждений и разработали метод смешанной оптимизации предпочтений (MPO). Их модель InternVL2-8B-MPO показала значительное улучшение производительности в задачах мультимодальных рассуждений, особенно в тестах типа Chain-of-Thought. Результаты демонстрируют потенциал этого подхода для повышения способностей MLLM к мультимодальным рассуждениям."
                },
                "en": {
                    "title": "Boosting Multimodal Reasoning with Preference Optimization",
                    "desc": "This paper addresses the limitations of existing multimodal large language models (MLLMs) in reasoning tasks due to distribution shifts. It introduces a preference optimization (PO) process to enhance the Chain-of-Thought (CoT) performance of these models. The authors create a high-quality dataset called MMPR through an automated preference data construction pipeline and develop a method called Mixed Preference Optimization (MPO) to integrate PO with MLLMs. Their model, InternVL2-8B-MPO, shows significant improvements in multimodal reasoning tasks, achieving higher accuracy than previous models and demonstrating the potential for further advancements in this field."
                },
                "zh": {
                    "title": "提升多模态推理能力的新方法",
                    "desc": "本文介绍了一种新的方法来提高多模态大语言模型（MLLMs）的推理能力。我们提出了一种偏好优化（PO）过程，旨在解决现有模型在多模态推理中的分布偏移问题。通过构建高质量的大规模多模态推理偏好数据集MMPR，并将PO与MLLMs结合，我们开发了混合偏好优化（MPO）方法，显著提升了模型在多模态链式思维（CoT）任务中的表现。实验结果表明，我们的模型在多个基准测试中表现优异，特别是在多模态推理任务上。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14405",
            "title": "Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions",
            "url": "https://huggingface.co/papers/2411.14405",
            "abstract": "Currently OpenAI o1 has sparked a surge of interest in the study of large reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also places greater emphasis on open-ended resolutions. We aim to address the question: \"Can the o1 model effectively generalize to broader domains where clear standards are absent and rewards are challenging to quantify?\" Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and innovative reasoning strategies -- optimized for complex real-world problem-solving tasks.",
            "score": 14,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "ef4a95abeea69237",
            "authors": [
                "Yu Zhao",
                "Huifeng Yin",
                "Bo Zeng",
                "Hao Wang",
                "Tianqi Shi",
                "Chenyang Lyu",
                "Longyue Wang",
                "Weihua Luo",
                "Kaifu Zhang"
            ],
            "affiliations": [
                "MarcoPolo Team, Alibaba International Digital Commerce"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14405.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#rl",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Расширение границ искусственного интеллекта: от стандартных задач к открытым проблемам",
                    "desc": "Статья описывает разработку модели Marco-o1, которая расширяет возможности OpenAI o1 в области рассуждений. Модель нацелена на решение задач с открытым концом, где отсутствуют четкие стандарты и сложно количественно оценить результаты. Marco-o1 использует усовершенствованные методы, такие как обучение с подкреплением, цепочки размышлений и метод Монте-Карло. Основная цель - создать модель, способную эффективно обобщать знания и решать сложные задачи реального мира."
                },
                "en": {
                    "title": "Unlocking Generalization in Large Reasoning Models",
                    "desc": "This paper explores the capabilities of the Marco-o1 model in handling large reasoning tasks across various domains. It emphasizes the model's ability to generalize beyond traditional areas like mathematics and coding, where answers are clear-cut. The research investigates how Marco-o1 can tackle open-ended problems where standard solutions and quantifiable rewards are not readily available. Key techniques employed include Chain-of-Thought fine-tuning and Monte Carlo Tree Search, which enhance the model's reasoning and problem-solving abilities in complex scenarios."
                },
                "zh": {
                    "title": "推动推理模型的广泛应用",
                    "desc": "这篇论文探讨了大型推理模型（LRM）的研究，特别是OpenAI的o1模型。Marco-o1不仅关注数学、物理和编程等有标准答案的学科，还强调开放式问题的解决能力。研究的核心问题是o1模型是否能够有效地推广到缺乏明确标准和难以量化奖励的更广泛领域。Marco-o1结合了链式思维（CoT）微调、蒙特卡洛树搜索（MCTS）、反思机制和创新推理策略，以优化复杂的现实问题解决任务。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.12364",
            "title": "Ultra-Sparse Memory Network",
            "url": "https://huggingface.co/papers/2411.12364",
            "abstract": "It is widely acknowledged that the performance of Transformer models is exponentially related to their number of parameters and computational complexity. While approaches like Mixture of Experts (MoE) decouple parameter count from computational complexity, they still face challenges in inference due to high memory access costs. This work introduces UltraMem, incorporating large-scale, ultra-sparse memory layer to address these limitations. Our approach significantly reduces inference latency while maintaining model performance. We also investigate the scaling laws of this new architecture, demonstrating that it not only exhibits favorable scaling properties but outperforms traditional models. In our experiments, we train networks with up to 20 million memory slots. The results show that our method achieves state-of-the-art inference speed and model performance within a given computational budget.",
            "score": 11,
            "issue_id": 721,
            "pub_date": "2024-11-19",
            "pub_date_card": {
                "ru": "19 ноября",
                "en": "November 19",
                "zh": "11月19日"
            },
            "hash": "090bf8a39ee13838",
            "authors": [
                "Zihao Huang",
                "Qiyang Min",
                "Hongzhi Huang",
                "Defa Zhu",
                "Yutao Zeng",
                "Ran Guo",
                "Xun Zhou"
            ],
            "affiliations": [
                "Seed-Foundation-Model Team, ByteDance"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.12364.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#inference",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "UltraMem: сверхбыстрые трансформеры с разреженной памятью",
                    "desc": "В этой статье представлен новый подход UltraMem, который использует сверхразреженные слои памяти для улучшения производительности трансформеров. Метод позволяет значительно снизить задержку при выводе, сохраняя качество модели. Исследованы законы масштабирования новой архитектуры, показывающие её преимущества перед традиционными моделями. Эксперименты с сетями, содержащими до 20 миллионов ячеек памяти, демонстрируют state-of-the-art скорость вывода и качество модели при заданном вычислительном бюджете."
                },
                "en": {
                    "title": "UltraMem: Speeding Up Transformers with Sparse Memory!",
                    "desc": "This paper presents UltraMem, a novel architecture designed to enhance the efficiency of Transformer models by integrating a large-scale, ultra-sparse memory layer. By decoupling the number of parameters from computational complexity, UltraMem addresses the high memory access costs that hinder inference speed in existing models. The authors demonstrate that their approach not only reduces inference latency but also maintains competitive model performance, even with networks containing up to 20 million memory slots. Additionally, the study explores the scaling laws of UltraMem, showing that it outperforms traditional models while adhering to computational constraints."
                },
                "zh": {
                    "title": "UltraMem：提升推理速度的新架构",
                    "desc": "本论文提出了一种名为UltraMem的新架构，旨在解决Transformer模型在推理时的高内存访问成本问题。通过引入大规模的超稀疏内存层，UltraMem能够在保持模型性能的同时显著降低推理延迟。我们还研究了这种新架构的扩展规律，结果表明其具有良好的扩展性，并且在性能上优于传统模型。实验表明，我们的方法在给定的计算预算内实现了最先进的推理速度和模型性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14199",
            "title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs",
            "url": "https://huggingface.co/papers/2411.14199",
            "abstract": "Scientific progress depends on researchers' ability to synthesize the growing body of literature. Can large language models (LMs) assist scientists in this task? We introduce OpenScholar, a specialized retrieval-augmented LM that answers scientific queries by identifying relevant passages from 45 million open-access papers and synthesizing citation-backed responses. To evaluate OpenScholar, we develop ScholarQABench, the first large-scale multi-domain benchmark for literature search, comprising 2,967 expert-written queries and 208 long-form answers across computer science, physics, neuroscience, and biomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o hallucinates citations 78 to 90% of the time, OpenScholar achieves citation accuracy on par with human experts. OpenScholar's datastore, retriever, and self-feedback inference loop also improves off-the-shelf LMs: for instance, OpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations, experts preferred OpenScholar-8B and OpenScholar-GPT4o responses over expert-written ones 51% and 70% of the time, respectively, compared to GPT4o's 32%. We open-source all of our code, models, datastore, data and a public demo.",
            "score": 11,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "f429efe07ec308f2",
            "authors": [
                "Akari Asai",
                "Jacqueline He",
                "Rulin Shao",
                "Weijia Shi",
                "Amanpreet Singh",
                "Joseph Chee Chang",
                "Kyle Lo",
                "Luca Soldaini",
                "Sergey Feldman",
                "Mike D'arcy",
                "David Wadden",
                "Matt Latzke",
                "Minyang Tian",
                "Pan Ji",
                "Shengyan Liu",
                "Hao Tong",
                "Bohao Wu",
                "Yanyu Xiong",
                "Luke Zettlemoyer",
                "Graham Neubig",
                "Dan Weld",
                "Doug Downey",
                "Wen-tau Yih",
                "Pang Wei Koh",
                "Hannaneh Hajishirzi"
            ],
            "affiliations": [
                "Allen Institute for AI",
                "Carnegie Mellon University",
                "Meta",
                "Stanford University",
                "University of Illinois, Urbana-Champaign",
                "University of North Carolina, Chapel Hill",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14199.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#rag",
                    "#open_source",
                    "#multimodal",
                    "#benchmark",
                    "#hallucinations"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "OpenScholar: ИИ-помощник для синтеза научной литературы",
                    "desc": "Статья представляет OpenScholar - специализированную языковую модель с расширенным поиском, которая отвечает на научные запросы, используя 45 миллионов научных статей. Для оценки модели авторы разработали ScholarQABench - первый масштабный мультидоменный бенчмарк для поиска литературы. OpenScholar-8B превосходит GPT-4 и PaperQA2 по точности ответов, несмотря на меньший размер модели. Эксперты предпочли ответы OpenScholar-8B и OpenScholar-GPT4o экспертным ответам в 51% и 70% случаев соответственно."
                },
                "en": {
                    "title": "Empowering Scientific Research with OpenScholar: Accurate, Citation-Backed Insights",
                    "desc": "This paper presents OpenScholar, a retrieval-augmented language model designed to assist researchers in synthesizing scientific literature. OpenScholar effectively identifies relevant passages from a vast collection of 45 million open-access papers and generates citation-backed responses to scientific queries. The model is evaluated using ScholarQABench, a benchmark that includes expert-written queries and answers across multiple domains, demonstrating superior performance in correctness compared to other models like GPT-4o. Additionally, OpenScholar shows a significant reduction in citation hallucination, achieving accuracy comparable to human experts, and enhances the performance of existing models through its innovative architecture."
                },
                "zh": {
                    "title": "OpenScholar：提升科学文献检索的智能助手",
                    "desc": "本论文介绍了一种名为OpenScholar的专用检索增强语言模型，旨在帮助科学家从4500万篇开放获取论文中提取相关信息并生成基于引用的回答。我们开发了ScholarQABench，这是第一个大规模的多领域文献搜索基准，包含2967个专家编写的查询和208个长答案，涵盖计算机科学、物理学、神经科学和生物医学等领域。OpenScholar在准确性上超越了GPT-4o和PaperQA2，尽管其模型规模较小，且在引用准确性方面与人类专家相当。我们还开源了所有代码、模型和数据，提供了公共演示，促进了科学文献的检索和理解。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14402",
            "title": "Multimodal Autoregressive Pre-training of Large Vision Encoders",
            "url": "https://huggingface.co/papers/2411.14402",
            "abstract": "We introduce a novel method for pre-training of large-scale vision encoders. Building on recent advancements in autoregressive pre-training of vision models, we extend this framework to a multimodal setting, i.e., images and text. In this paper, we present AIMV2, a family of generalist vision encoders characterized by a straightforward pre-training process, scalability, and remarkable performance across a range of downstream tasks. This is achieved by pairing the vision encoder with a multimodal decoder that autoregressively generates raw image patches and text tokens. Our encoders excel not only in multimodal evaluations but also in vision benchmarks such as localization, grounding, and classification. Notably, our AIMV2-3B encoder achieves 89.5% accuracy on ImageNet-1k with a frozen trunk. Furthermore, AIMV2 consistently outperforms state-of-the-art contrastive models (e.g., CLIP, SigLIP) in multimodal image understanding across diverse settings.",
            "score": 10,
            "issue_id": 723,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "95826a974f0f9bb2",
            "authors": [
                "Enrico Fini",
                "Mustafa Shukor",
                "Xiujun Li",
                "Philipp Dufter",
                "Michal Klein",
                "David Haldimann",
                "Sai Aitharaju",
                "Victor Guilherme Turrisi da Costa",
                "Louis Béthune",
                "Zhe Gan",
                "Alexander T Toshev",
                "Marcin Eichner",
                "Moin Nabi",
                "Yinfei Yang",
                "Joshua M. Susskind",
                "Alaaeldin El-Nouby"
            ],
            "affiliations": [
                "Apple"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14402.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#multimodal",
                    "#benchmark",
                    "#architecture"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "AIMV2: универсальный энкодер изображений с мультимодальным предобучением",
                    "desc": "Представлен новый метод предобучения крупномасштабных энкодеров изображений под названием AIMV2. Он расширяет авторегрессионное предобучение на мультимодальный контекст, включая изображения и текст. AIMV2 использует мультимодальный декодер для генерации фрагментов изображений и текстовых токенов. Модель демонстрирует высокую производительность в различных задачах компьютерного зрения и мультимодального понимания, превосходя современные контрастивные модели."
                },
                "en": {
                    "title": "AIMV2: Unifying Vision and Text for Superior Multimodal Understanding",
                    "desc": "This paper presents AIMV2, a new method for pre-training vision encoders that can handle both images and text. It builds on recent techniques in autoregressive pre-training, allowing the model to generate image patches and text tokens effectively. AIMV2 is designed to be scalable and performs exceptionally well on various tasks, including localization and classification. The results show that AIMV2 outperforms existing models like CLIP in multimodal image understanding, achieving high accuracy on benchmarks like ImageNet-1k."
                },
                "zh": {
                    "title": "AIMV2：多模态视觉编码的创新之路",
                    "desc": "我们提出了一种新颖的大规模视觉编码器预训练方法。该方法基于最近在自回归视觉模型预训练方面的进展，扩展到多模态设置，即图像和文本。我们介绍了AIMV2，这是一系列通用的视觉编码器，具有简单的预训练过程、可扩展性和在多种下游任务中的卓越表现。我们的编码器在多模态评估和视觉基准测试（如定位、基础和分类）中表现出色，AIMV2-3B编码器在ImageNet-1k上实现了89.5%的准确率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.13676",
            "title": "Hymba: A Hybrid-head Architecture for Small Language Models",
            "url": "https://huggingface.co/papers/2411.13676",
            "abstract": "We propose Hymba, a family of small language models featuring a hybrid-head parallel architecture that integrates transformer attention mechanisms with state space models (SSMs) for enhanced efficiency. Attention heads provide high-resolution recall, while SSM heads enable efficient context summarization. Additionally, we introduce learnable meta tokens that are prepended to prompts, storing critical information and alleviating the \"forced-to-attend\" burden associated with attention mechanisms. This model is further optimized by incorporating cross-layer key-value (KV) sharing and partial sliding window attention, resulting in a compact cache size. During development, we conducted a controlled study comparing various architectures under identical settings and observed significant advantages of our proposed architecture. Notably, Hymba achieves state-of-the-art results for small LMs: Our Hymba-1.5B-Base model surpasses all sub-2B public models in performance and even outperforms Llama-3.2-3B with 1.32% higher average accuracy, an 11.67x cache size reduction, and 3.49x throughput.",
            "score": 9,
            "issue_id": 721,
            "pub_date": "2024-11-20",
            "pub_date_card": {
                "ru": "20 ноября",
                "en": "November 20",
                "zh": "11月20日"
            },
            "hash": "24009a4acf67d4c7",
            "authors": [
                "Xin Dong",
                "Yonggan Fu",
                "Shizhe Diao",
                "Wonmin Byeon",
                "Zijia Chen",
                "Ameya Sunil Mahabaleshwarkar",
                "Shih-Yang Liu",
                "Matthijs Van Keirsbilck",
                "Min-Hung Chen",
                "Yoshi Suhara",
                "Yingyan Lin",
                "Jan Kautz",
                "Pavlo Molchanov"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2411.13676.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#training",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Гибридная архитектура Hymba: эффективность малых языковых моделей на новом уровне",
                    "desc": "Авторы представляют Hymba - семейство малых языковых моделей с гибридной параллельной архитектурой, сочетающей механизмы внимания трансформеров и модели пространства состояний (SSM) для повышения эффективности. В модель добавлены обучаемые мета-токены, хранящие важную информацию и снижающие нагрузку на механизмы внимания. Оптимизация включает межслойное разделение ключей и значений, а также частичное скользящее окно внимания. Модель Hymba-1.5B-Base превосходит все публичные модели до 2 млрд параметров и даже Llama-3.2-3B по точности, при значительном уменьшении размера кэша и увеличении пропускной способности."
                },
                "en": {
                    "title": "Hymba: Efficient Language Models with Hybrid Architecture",
                    "desc": "Hymba is a new family of small language models that combines transformer attention with state space models (SSMs) to improve efficiency. The model uses attention heads for detailed recall and SSM heads for summarizing context effectively. It also features learnable meta tokens that help retain important information without overloading the attention mechanism. Our experiments show that Hymba outperforms existing small language models, achieving better accuracy while using significantly less cache and providing faster processing speeds."
                },
                "zh": {
                    "title": "Hymba：高效的小型语言模型新选择",
                    "desc": "我们提出了Hymba，这是一种小型语言模型，采用混合头并行架构，将变换器注意机制与状态空间模型（SSMs）结合，以提高效率。注意头提供高分辨率的回忆，而SSM头则实现高效的上下文总结。此外，我们引入了可学习的元标记，这些标记被添加到提示前，存储关键信息，减轻了与注意机制相关的“强制关注”负担。我们的模型通过跨层键值（KV）共享和部分滑动窗口注意机制进一步优化，结果是缓存大小紧凑。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14432",
            "title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models",
            "url": "https://huggingface.co/papers/2411.14432",
            "abstract": "Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high-quality long-chain reasoning data and optimized training pipelines still remain inadequately explored in vision-language tasks. In this paper, we present Insight-V, an early effort to 1) scalably produce long and robust reasoning data for complex multi-modal tasks, and 2) an effective training pipeline to enhance the reasoning capabilities of multi-modal large language models (MLLMs). Specifically, to create long and structured reasoning data without human labor, we design a two-step pipeline with a progressive strategy to generate sufficiently long and diverse reasoning paths and a multi-granularity assessment method to ensure data quality. We observe that directly supervising MLLMs with such long and complex reasoning data will not yield ideal reasoning ability. To tackle this problem, we design a multi-agent system consisting of a reasoning agent dedicated to performing long-chain reasoning and a summary agent trained to judge and summarize reasoning results. We further incorporate an iterative DPO algorithm to enhance the reasoning agent's generation stability and quality. Based on the popular LLaVA-NeXT model and our stronger base MLLM, we demonstrate significant performance gains across challenging multi-modal benchmarks requiring visual reasoning. Benefiting from our multi-agent system, Insight-V can also easily maintain or improve performance on perception-focused multi-modal tasks.",
            "score": 7,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "0af1bb82d8021d3b",
            "authors": [
                "Yuhao Dong",
                "Zuyan Liu",
                "Hai-Long Sun",
                "Jingkang Yang",
                "Winston Hu",
                "Yongming Rao",
                "Ziwei Liu"
            ],
            "affiliations": [
                "Nanjing University",
                "S-Lab, NTU",
                "Tencent",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14432.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#long_context",
                    "#multimodal",
                    "#data",
                    "#dataset",
                    "#benchmark",
                    "#agents",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Улучшение визуальных рассуждений ИИ через длинные цепочки и мультиагентное обучение",
                    "desc": "Статья представляет Insight-V - подход к улучшению способностей мультимодальных больших языковых моделей (MLLM) к рассуждениям. Авторы предлагают двухэтапный конвейер для создания длинных и структурированных данных для обучения без участия человека. Они также разрабатывают мультиагентную систему, состоящую из агента рассуждений и агента-резюме, для эффективного обучения MLLM. Результаты показывают значительное улучшение производительности на сложных мультимодальных задачах, требующих визуального рассуждения."
                },
                "en": {
                    "title": "Empowering Multi-Modal Reasoning with Insight-V",
                    "desc": "This paper introduces Insight-V, a novel approach to enhance the reasoning capabilities of multi-modal large language models (MLLMs) by generating high-quality long-chain reasoning data. The authors propose a two-step pipeline that creates structured reasoning paths without human intervention and employs a multi-granularity assessment method to ensure the quality of the generated data. They also develop a multi-agent system that includes a reasoning agent for long-chain reasoning and a summary agent to evaluate and condense the reasoning outputs. The results show that Insight-V significantly improves performance on complex multi-modal tasks, particularly those requiring visual reasoning, while maintaining effectiveness on perception-focused tasks."
                },
                "zh": {
                    "title": "提升多模态推理能力的创新方法",
                    "desc": "本文介绍了一种名为Insight-V的系统，旨在提高多模态大语言模型（MLLMs）的推理能力。我们设计了一个两步生成管道，以无人工干预的方式创建长且结构化的推理数据，并采用多粒度评估方法确保数据质量。研究表明，直接用复杂推理数据监督MLLMs并不能达到理想效果，因此我们构建了一个多代理系统，包括专注于长链推理的推理代理和负责评估和总结推理结果的总结代理。通过这种方法，Insight-V在视觉推理等多模态基准测试中表现出显著的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14251",
            "title": "Natural Language Reinforcement Learning",
            "url": "https://huggingface.co/papers/2411.14251",
            "abstract": "Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models. This paper seeks a new possibility, Natural Language Reinforcement Learning (NLRL), by extending traditional MDP to natural language-based representation space. Specifically, NLRL innovatively redefines RL principles, including task objectives, policy, value function, Bellman equation, and policy iteration, into their language counterparts. With recent advancements in large language models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value improvement by either pure prompting or gradient-based training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games demonstrate the effectiveness, efficiency, and interpretability of the NLRL framework among diverse use cases. Our code will be released at https://github.com/waterhorse1/Natural-language-RL.",
            "score": 7,
            "issue_id": 719,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "351fc2a705b34aff",
            "authors": [
                "Xidong Feng",
                "Ziyu Wan",
                "Haotian Fu",
                "Bo Liu",
                "Mengyue Yang",
                "Girish A. Koushik",
                "Zhiyuan Hu",
                "Ying Wen",
                "Jun Wang"
            ],
            "affiliations": [
                "Brown University",
                "National University of Singapore",
                "Shanghai Jiao Tong University",
                "University College London",
                "University of Bristol",
                "University of Surrey"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14251.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#rl",
                    "#rlhf",
                    "#open_source",
                    "#games"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "Обучение с подкреплением заговорило на естественном языке",
                    "desc": "Эта статья представляет новую концепцию - обучение с подкреплением на естественном языке (NLRL). NLRL расширяет традиционные марковские процессы принятия решений, переопределяя основные принципы RL в языковом пространстве. Используя достижения в области больших языковых моделей, NLRL может быть реализовано с помощью промптов или градиентного обучения. Эксперименты на играх Maze, Breakthrough и крестики-нолики демонстрируют эффективность и интерпретируемость этого подхода."
                },
                "en": {
                    "title": "Revolutionizing Decision-Making with Language: Natural Language Reinforcement Learning",
                    "desc": "This paper introduces Natural Language Reinforcement Learning (NLRL), which adapts traditional Reinforcement Learning (RL) methods to work with natural language representations. By extending the Markov Decision Process (MDP) framework, NLRL redefines key RL concepts such as task objectives, policies, and value functions in the context of language. The approach leverages advancements in large language models (LLMs) to enhance policy and value updates through prompting or gradient-based training. Experimental results on games like Maze, Breakthrough, and Tic-Tac-Toe showcase NLRL's effectiveness and interpretability across various applications."
                },
                "zh": {
                    "title": "自然语言强化学习：决策的新视角",
                    "desc": "强化学习（RL）通过马尔可夫决策过程（MDP）来数学化决策制定。本文提出了一种新的可能性，即自然语言强化学习（NLRL），通过将传统的MDP扩展到基于自然语言的表示空间。NLRL创新性地重新定义了强化学习的原则，包括任务目标、策略、价值函数、贝尔曼方程和策略迭代，使其适应语言的对应关系。通过在迷宫、突破和井字棋等游戏中的实验，验证了NLRL框架在多种应用场景中的有效性、效率和可解释性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14430",
            "title": "Stable Flow: Vital Layers for Training-Free Image Editing",
            "url": "https://huggingface.co/papers/2411.14430",
            "abstract": "Diffusion models have revolutionized the field of content synthesis and editing. Recent models have replaced the traditional UNet architecture with the Diffusion Transformer (DiT), and employed flow-matching for improved training and sampling. However, they exhibit limited generation diversity. In this work, we leverage this limitation to perform consistent image edits via selective injection of attention features. The main challenge is that, unlike the UNet-based models, DiT lacks a coarse-to-fine synthesis structure, making it unclear in which layers to perform the injection. Therefore, we propose an automatic method to identify \"vital layers\" within DiT, crucial for image formation, and demonstrate how these layers facilitate a range of controlled stable edits, from non-rigid modifications to object addition, using the same mechanism. Next, to enable real-image editing, we introduce an improved image inversion method for flow models. Finally, we evaluate our approach through qualitative and quantitative comparisons, along with a user study, and demonstrate its effectiveness across multiple applications. The project page is available at https://omriavrahami.com/stable-flow",
            "score": 2,
            "issue_id": 723,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "4d5707c1fdd2e4f9",
            "authors": [
                "Omri Avrahami",
                "Or Patashnik",
                "Ohad Fried",
                "Egor Nemchinov",
                "Kfir Aberman",
                "Dani Lischinski",
                "Daniel Cohen-Or"
            ],
            "affiliations": [
                "Reichman University",
                "Snap Research",
                "Tel Aviv University",
                "The Hebrew University of Jerusalem"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14430.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#training",
                    "#diffusion",
                    "#optimization"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Стабильное редактирование изображений через выборочное внедрение признаков в DiT",
                    "desc": "Эта статья представляет новый подход к редактированию изображений с использованием диффузионных моделей. Авторы предлагают метод выборочного внедрения признаков внимания в ключевые слои Диффузионного Трансформера (DiT) для выполнения стабильных и контролируемых изменений изображений. Они также разрабатывают улучшенный метод инверсии изображений для потоковых моделей, что позволяет редактировать реальные изображения. Эффективность подхода демонстрируется через качественные и количественные сравнения, а также пользовательское исследование."
                },
                "en": {
                    "title": "Enhancing Image Editing with Vital Layer Injection in Diffusion Transformers",
                    "desc": "This paper discusses advancements in diffusion models for content synthesis and editing, specifically focusing on the Diffusion Transformer (DiT) architecture. The authors address the challenge of limited generation diversity in DiT by proposing a method to selectively inject attention features into vital layers of the model. This approach allows for consistent and controlled image edits, such as non-rigid modifications and object additions, despite DiT's lack of a traditional coarse-to-fine synthesis structure. Additionally, the paper introduces an improved image inversion method for flow models and validates the effectiveness of their technique through various evaluations and user studies."
                },
                "zh": {
                    "title": "利用扩散变换器实现稳定的图像编辑",
                    "desc": "扩散模型在内容合成和编辑领域取得了革命性进展。最近的模型用扩散变换器（DiT）替代了传统的UNet架构，并采用流匹配技术以改善训练和采样。然而，这些模型的生成多样性有限。我们利用这一限制，通过选择性注入注意力特征来实现一致的图像编辑，并提出了一种自动识别DiT中关键层的方法，以便进行稳定的图像修改。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14343",
            "title": "UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages",
            "url": "https://huggingface.co/papers/2411.14343",
            "abstract": "Large language models (LLMs) under-perform on low-resource languages due to limited training data. We present a method to efficiently collect text data for low-resource languages from the entire Common Crawl corpus. Our approach, UnifiedCrawl, filters and extracts common crawl using minimal compute resources, yielding mono-lingual datasets much larger than previously available sources. We demonstrate that leveraging this data to fine-tuning multilingual LLMs via efficient adapter methods (QLoRA) significantly boosts performance on the low-resource language, while minimizing VRAM usage. Our experiments show large improvements in language modeling perplexity and an increase in few-shot prompting scores. Our work and released source code provide an affordable approach to improve LLMs for low-resource languages using consumer hardware. Our source code is available here at https://github.com/bethelmelesse/unifiedcrawl.",
            "score": 1,
            "issue_id": 728,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "e3be7df0af13931a",
            "authors": [
                "Bethel Melesse Tessema",
                "Akhil Kedia",
                "Tae-Sun Chung"
            ],
            "affiliations": [
                "Ajou University Suwon, South Korea",
                "Independent Researcher Seoul, South Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14343.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#low_resource",
                    "#open_source",
                    "#training",
                    "#multilingual",
                    "#data"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "Улучшение языковых моделей для малоресурсных языков с помощью UnifiedCrawl",
                    "desc": "Статья представляет метод UnifiedCrawl для эффективного сбора текстовых данных для малоресурсных языков из корпуса Common Crawl. Авторы демонстрируют, что использование этих данных для дообучения многоязычных языковых моделей с помощью эффективных методов адаптации (QLoRA) значительно повышает производительность на малоресурсных языках. Эксперименты показывают улучшение перплексии языкового моделирования и повышение оценок при few-shot промптинге. Предложенный подход позволяет улучшать большие языковые модели для малоресурсных языков, используя доступное оборудование."
                },
                "en": {
                    "title": "Boosting Low-Resource Languages with UnifiedCrawl",
                    "desc": "This paper addresses the challenge of large language models (LLMs) performing poorly on low-resource languages due to a lack of training data. The authors introduce a method called UnifiedCrawl, which efficiently collects and filters text data from the Common Crawl corpus, creating larger mono-lingual datasets. They demonstrate that fine-tuning multilingual LLMs with this data using efficient adapter methods like QLoRA leads to significant improvements in language modeling and few-shot prompting scores. The approach is designed to be accessible, allowing enhancements to LLMs for low-resource languages using standard consumer hardware."
                },
                "zh": {
                    "title": "提升低资源语言模型性能的新方法",
                    "desc": "本论文提出了一种名为UnifiedCrawl的方法，用于从Common Crawl数据集中高效收集低资源语言的文本数据。该方法通过最小化计算资源的使用，过滤和提取数据，从而生成比以往更大的单语数据集。我们展示了利用这些数据通过高效的适配器方法（QLoRA）对多语言大语言模型进行微调，可以显著提高低资源语言的性能，同时减少显存使用。实验结果表明，语言建模的困惑度有了显著改善，少量示例提示的得分也有所提高。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.13807",
            "title": "MagicDriveDiT: High-Resolution Long Video Generation for Autonomous Driving with Adaptive Control",
            "url": "https://huggingface.co/papers/2411.13807",
            "abstract": "The rapid advancement of diffusion models has greatly improved video synthesis, especially in controllable video generation, which is essential for applications like autonomous driving. However, existing methods are limited by scalability and how control conditions are integrated, failing to meet the needs for high-resolution and long videos for autonomous driving applications. In this paper, we introduce MagicDriveDiT, a novel approach based on the DiT architecture, and tackle these challenges. Our method enhances scalability through flow matching and employs a progressive training strategy to manage complex scenarios. By incorporating spatial-temporal conditional encoding, MagicDriveDiT achieves precise control over spatial-temporal latents. Comprehensive experiments show its superior performance in generating realistic street scene videos with higher resolution and more frames. MagicDriveDiT significantly improves video generation quality and spatial-temporal controls, expanding its potential applications across various tasks in autonomous driving.",
            "score": 1,
            "issue_id": 728,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "95ef9fbe239921f8",
            "authors": [
                "Ruiyuan Gao",
                "Kai Chen",
                "Bo Xiao",
                "Lanqing Hong",
                "Zhenguo Li",
                "Qiang Xu"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "Huawei Cloud",
                "Huawei Noahs Ark Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.13807.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#diffusion",
                    "#training",
                    "#video"
                ],
                "emoji": "🚗",
                "ru": {
                    "title": "Революция в синтезе видео для беспилотных автомобилей",
                    "desc": "Статья представляет MagicDriveDiT - новый подход к генерации видео для автономного вождения, основанный на архитектуре DiT. Метод улучшает масштабируемость с помощью flow matching и прогрессивного обучения для сложных сценариев. MagicDriveDiT использует пространственно-временное кодирование условий для точного контроля над латентными переменными. Эксперименты показывают превосходную производительность в генерации реалистичных уличных сцен с более высоким разрешением и большим количеством кадров."
                },
                "en": {
                    "title": "MagicDriveDiT: Revolutionizing Video Generation for Autonomous Driving",
                    "desc": "This paper presents MagicDriveDiT, a new method for generating high-quality videos using diffusion models, specifically designed for applications in autonomous driving. It addresses the limitations of existing techniques by enhancing scalability and integrating control conditions more effectively. The approach utilizes flow matching and a progressive training strategy to handle complex video scenarios, ensuring better performance in generating long, high-resolution videos. By incorporating spatial-temporal conditional encoding, MagicDriveDiT allows for precise control over the generated video content, making it suitable for various autonomous driving tasks."
                },
                "zh": {
                    "title": "MagicDriveDiT：提升视频生成质量与控制能力的创新方法",
                    "desc": "本论文介绍了一种名为MagicDriveDiT的新方法，基于DiT架构，旨在解决视频合成中的可扩展性和控制条件集成问题。该方法通过流匹配技术增强了可扩展性，并采用渐进式训练策略来处理复杂场景。通过引入时空条件编码，MagicDriveDiT能够精确控制时空潜变量。实验结果表明，该方法在生成高分辨率和更多帧的真实街景视频方面表现优越，显著提升了视频生成质量和时空控制能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14257",
            "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
            "url": "https://huggingface.co/papers/2411.14257",
            "abstract": "Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about. Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie. This suggests that models can have self-knowledge: internal representations about their own capabilities. These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse. We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism. Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token.",
            "score": 1,
            "issue_id": 728,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "765c1d51aaa40d67",
            "authors": [
                "Javier Ferrando",
                "Oscar Obeso",
                "Senthooran Rajamanoharan",
                "Neel Nanda"
            ],
            "affiliations": [
                "ETH Zürich",
                "UPC"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14257.jpg",
            "data": {
                "error": "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}"
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.13082",
            "title": "Patience Is The Key to Large Language Model Reasoning",
            "url": "https://huggingface.co/papers/2411.13082",
            "abstract": "Recent advancements in the field of large language models, particularly through the Chain of Thought (CoT) approach, have demonstrated significant improvements in solving complex problems. However, existing models either tend to sacrifice detailed reasoning for brevity due to user preferences, or require extensive and expensive training data to learn complicated reasoning ability, limiting their potential in solving complex tasks. To bridge this gap, following the concept of scaling test-time, we propose a simple method by encouraging models to adopt a more patient reasoning style without the need of introducing new knowledge or skills. To employ a preference optimization approach, we generate detailed reasoning processes as positive examples and simple answers as negative examples, thereby training the model to favor thoroughness in its responses. Our results demonstrate a performance increase of up to 6.7% on GSM8k with training just on a lightweight dataset.",
            "score": 1,
            "issue_id": 726,
            "pub_date": "2024-11-20",
            "pub_date_card": {
                "ru": "20 ноября",
                "en": "November 20",
                "zh": "11月20日"
            },
            "hash": "b18aa77451c249b7",
            "authors": [
                "Yijiong Yu"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.13082.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Терпеливые рассуждения: новый путь к улучшению ИИ",
                    "desc": "Статья описывает новый метод улучшения рассуждений больших языковых моделей без необходимости обширного обучения. Авторы предлагают подход, основанный на оптимизации предпочтений, где модель учится выдавать более подробные рассуждения вместо кратких ответов. Метод использует детальные рассуждения как положительные примеры и простые ответы как отрицательные при обучении. Результаты показывают улучшение производительности до 6.7% на наборе данных GSM8k при обучении на небольшом датасете."
                },
                "en": {
                    "title": "Enhancing Reasoning in Language Models with Simple Training Techniques",
                    "desc": "This paper discusses improvements in large language models using the Chain of Thought (CoT) method, which enhances their ability to solve complex problems. It identifies a challenge where models often prioritize brevity over detailed reasoning, or require large amounts of training data to develop reasoning skills. The authors propose a new method that encourages models to adopt a more thorough reasoning style without needing additional knowledge. By using preference optimization, they train models with detailed reasoning as positive examples and simple answers as negative examples, achieving a notable performance increase on the GSM8k dataset with minimal training data."
                },
                "zh": {
                    "title": "提升推理能力，简化训练过程",
                    "desc": "本文探讨了大型语言模型在解决复杂问题时的进展，特别是通过思维链（CoT）方法的应用。现有模型往往为了简洁而牺牲详细推理，或者需要大量昂贵的训练数据来学习复杂的推理能力。为了解决这个问题，我们提出了一种简单的方法，鼓励模型采用更耐心的推理风格，而无需引入新知识或技能。通过生成详细的推理过程作为正例和简单答案作为负例，我们训练模型更倾向于全面的回答，结果显示在GSM8k上性能提高了6.7%。"
                }
            }
        }
    ],
    "link_prev": "2024-11-21.html",
    "link_next": "2024-11-25.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "21.11",
        "en": "11/21",
        "zh": "11月21日"
    },
    "short_date_next": {
        "ru": "25.11",
        "en": "11/25",
        "zh": "11月25日"
    },
    "categories": {
        "#dataset": 4,
        "#data": 2,
        "#benchmark": 4,
        "#agents": 1,
        "#cv": 2,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 4,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 4,
        "#healthcare": 0,
        "#training": 9,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 4,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 1
    },
    "zh": {
        "text": "这篇文章讨论了现有开源多模态大语言模型（MLLMs）的训练过程和存在的问题。这些模型通常经过预训练和监督微调，但在分布偏移方面表现不佳，影响其多模态推理能力，特别是在Chain-of-Thought（CoT）性能上。为了解决这个问题，作者提出了一种偏好优化（PO）过程，并创建了一个高质量的多模态推理偏好数据集MMPR。此外，他们还开发了一种混合偏好优化（MPO）方法，提升了多模态CoT性能。实验结果显示，他们的模型在多个基准测试中表现更好，特别是在多模态推理任务中。",
        "title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization",
        "pinyin": "这篇文章讨论了现有开源多模态大语言模型（MLLMs）的训练过程和存在的问题。\nZhè piān wénzhāng tǎolùn le xiànyǒu kāiyuán duō móshì dà yǔyán móxíng (MLLMs) de xùnliàn guòchéng hé cúnzài de wèntí.\n\n这些模型通常经过预训练和监督微调，但在分布偏移方面表现不佳，影响其多模态推理能力，特别是在Chain-of-Thought（CoT）性能上。\nZhèxiē móxíng tōngcháng jīngguò yùxùnliàn hé jiàndū wēitiáo, dàn zài fēnbù piānyí fāngmiàn biǎoxiàn bùjiā, yǐngxiǎng qí duō móshì tuīlǐ nénglì, tèbié shì zài Chain-of-Thought (CoT) xìngnéng shàng.\n\n为了解决这个问题，作者提出了一种偏好优化（PO）过程，并创建了一个高质量的多模态推理偏好数据集MMPR。\nWèile jiějué zhègè wèntí, zuòzhě tíchū le yīzhǒng piānhào yōuhuà (PO) guòchéng, bìng chuàngjiàn le yīgè gāo zhìliàng de duō móshì tuīlǐ piānhào shùjùjí MMPR.\n\n此外，他们还开发了一种混合偏好优化（MPO）方法，提升了多模态CoT性能。\nCǐwài, tāmen hái kāifā le yīzhǒng hùnhé piānhào yōuhuà (MPO) fāngfǎ, tíshēng le duō móshì CoT xìngnéng.\n\n实验结果显示，他们的模型在多个基准测试中表现更好，特别是在多模态推理任务中。\nShíyàn jiéguǒ xiǎnshì, tāmen de móxíng zài duō gè jīzhǔn cèshì zhōng biǎoxiàn gèng hǎo, tèbié shì zài duō móshì tuīlǐ rènwù zhōng.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'},\n{'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'},\n{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'},\n{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'},\n{'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'},\n{'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'train'},\n{'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'},\n{'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'},\n{'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'},\n{'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-train'},\n{'word': '监督', 'pinyin': 'jiàn dū', 'trans': 'supervise'},\n{'word': '微调', 'pinyin': 'wēi tiáo', 'trans': 'fine-tune'},\n{'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'},\n{'word': '偏移', 'pinyin': 'piān yí', 'trans': 'shift'},\n{'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'},\n{'word': '影响', 'pinyin': 'yǐng xiǎng', 'trans': 'affect'},\n{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'},\n{'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'},\n{'word': '特别', 'pinyin': 'tè bié', 'trans': 'especially'},\n{'word': 'Chain-of-Thought', 'pinyin': 'Chéng fǎn de Sī xiǎng', 'trans': 'Chain-of-Thought'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},\n{'word': '偏好', 'pinyin': 'piān hào', 'trans': 'preference'},\n{'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimize'},\n{'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'},\n{'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high-quality'},\n{'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'},\n{'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'},\n{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},\n{'word': '提升', 'pinyin': 'tí shēng', 'trans': 'improve'},\n{'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'},\n{'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'},\n{'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'show'},\n{'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'},\n{'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'},\n{'word': '任务', 'pinyin': 'rèn wù', 'trans': 'task'}]",
        "trans": "This article discusses the training process and issues of existing open-source multimodal large language models (MLLMs). These models typically undergo pre-training and supervised fine-tuning, but they perform poorly in distribution shifts, affecting their multimodal reasoning capabilities, particularly in Chain-of-Thought (CoT) performance. To address this issue, the authors propose a preference optimization (PO) process and create a high-quality multimodal reasoning preference dataset called MMPR. Additionally, they develop a hybrid preference optimization (MPO) method, which enhances multimodal CoT performance. Experimental results show that their model performs better on multiple benchmark tests, especially in multimodal reasoning tasks.",
        "update_ts": "2024-11-22 09:11"
    }
}