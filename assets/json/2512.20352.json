{
    "paper_title": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
    "authors": [
        "Nilesh Jain",
        "Seyi Adeyinka",
        "Leor Roseman",
        "Aza Allsop"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 3 2 ] . [ 1 2 5 3 0 2 . 2 1 5 2 : r Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohens Kappa and Semantic Similarity for Qualitative Research Validation Nilesh Jain Seyi Adeyinka1 Leor Roseman2 Aza Allsop1,3 1Yale School of Medicine 2University of Exeter 3Center for Collective Healing December 24, 2025 Abstract Qualitative research faces critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohens Kappa (κ) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof -of-concept, We evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability (κ = 0.907, cosine=95.3%), followed by GPT-4o (κ = 0.853, cosine=92.6%) and Claude (κ = 0.842, cosine=92.1%). All three models achieve high agreement (κ > 0.80), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research. Keywords: Thematic Analysis, Large Language Models, Qualitative Research, Cohens Kappa, Semantic Similarity, Ensemble Validation"
        },
        {
            "title": "Introduction",
            "content": "Inter-rater reliability remains fundamental challenge in qualitative research [1]. Traditional approaches require multiple human coders who independently analyze the same data, with agreement measured through Cohens kappa. This process is time-intensive, expensive, and often yields only moderate agreement (κ = 0.40-0.60). The emergence of large language models (LLMs) offers potential solutions, but current approaches exhibit several limitations. Recent LLM-based systems such as QualIT [2] focus on topic modeling and key-phrase extraction, achieving 70% topic coherence on benchmark datasets. However, these approaches differ fundamentally from comprehensive thematic analysis as defined by Braun and Clarke [1], which involves iterative interpretation, contextualization, and affective understanding. Comparative studies [3, 4] evaluating nine generative models reveal significant performance variation across models and highlight cultural interpretation challenges, particularly in non-Western contexts. These findings underscore critical gap: existing LLM approaches lack systematic validation mechanisms for reliability assessment. We propose multi-perspective validation framework with dual reliability metrics: Cohens Kappa for statistical inter-rater agreement and cosine similarity for semantic consistency. Our framework introduces: (1) configurable seeds (16) enabling reproducible variation, (2) adjustable temperature (0.0-2.0) controlling output diversity, (3) custom prompt support with variable substitution ({seed}, {text chunk}), and (4) 1 structure-agnostic consensus extraction working with any JSON format. Empirical evaluation on psychedelic art therapy interview transcript across three leading LLMs demonstrates: Gemini 2.5 Pro (κ = 0.907, cosine=95.3%), GPT-4o (κ = 0.853, cosine=92.6%), and Claude 3.5 Sonnet (κ = 0.842, cosine=92.1%). All models achieve very high agreement (κ > 0.80), with Gemini showing superior consistency. Our contributions include: Dual reliability metrics (Cohens Kappa + cosine similarity) for comprehensive validation Configurable analysis parameters (seeds, temperature) for reproducible research Structure-agnostic consensus extraction for custom prompt formats Empirical LLM comparison on real qualitative data with open-source implementation"
        },
        {
            "title": "Code",
            "content": "https://github.com/ NileshArnaiya/LLM-Thematic-Analysis-Tool. available at"
        },
        {
            "title": "2 Related Work",
            "content": "Traditional Reliability Assessment. Qualitative research relies on inter-rater reliability to establish trustworthiness [1]. Cohens kappa measures agreement between two coders, with values interpreted as follows: κ < 0.40 (poor), 0.40-0.60 (moderate), 0.60-0.80 (substantial), κ > 0.80 (excellent). However, kappa requires exact categorical matches and cannot capture semantic equivalence. Studies report that even trained coders often achieve only moderate agreement, necessitating extensive discussion to resolve discrepancies (citation). LLM-Based Qualitative Analysis. Recent work explores LLM applications in qualitative research. QualIT [2] integrates LLMs with clustering for topic modeling, extracting key phrases and performing hierarchical clustering to achieve 70% topic coherence on benchmark datasets. However, this approach focuses on topic extraction rather than comprehensive thematic analysis. Alternative frameworks propose human-LLM collaboration models. Rana and Asad [5] introduce LLM-in-the-loop, using in-context learning with GPT-3.5 to reduce labor requirements while maintaining human oversight. Schlagwein [6] proposes four conversational roles (managers, teachers, colleagues, advocates) for researchers working with LLM chatbots, emphasiz2 ing reflexive practice. Landers and Behrend [7] employ Retrieval-Augmented Generation (RAG)- based approaches for interview transcript analysis, The focusing on methodological rigor. Human-AI Collaborative Thematic Analysis framework using Multi-Agent (TAMA) framework [8] applies multi-agent LLMs specifically to clinical interviews, demonstrating domain-specific adaptations. Lindh and Messina [9] demonstrate that LLMs can infer main themes but highlight limitations in capturing latent interpretationsthemes requiring deep contextual understanding. Turobov et al. [10] evaluate ChatGPT for thematic analysis, finding promise but recommending human oversight. Fulgencio [11] identifies benefits while noting cultural context limitations. Comparative LLM Studies. Bennis and Mouwafaq [3] conduct comparative study of nine generative models on medical data, revealing significant performance variation across models (something more specific). Sakaguchi et al. [4] compare ChatGPT with human researchers in Japanese clinical contexts, highlighting cultural interpretation challenges that LLMs struggle to address. Zhang et al.s LLM-Assisted Thematic Analysis (LATA) study [12] compares GPT4 and Gemini outputs with manually analyzed outcomes, achieving cosine similarity scores up to 0.76validating semantic similarity as viable metric but also revealing model-dependent variation. Gupta et al. [13] examine LLMs for focus group transcript analysis, demonstrating potential but noting reliability concerns. Prompt Engineering and Quality. Prompt design critically impacts analysis quality. Braun and Clarke [14] provide reproducible prompt engineering approaches aligned with their five-phase framework, with empirical evaluation against established quality criteria. Sanford et al. [15] systematically evaluate prompt engineering techniques using locally hosted Llama 3.1 models, demonstrating that structured prompts significantly improve thematic coherence. Nelson [16] tests offline LLMs through reflexive thematic identifying limitations of base analysis phases, models and proposing prompt strategies for improvement. Validation Metrics. Novel validity metrics emerge for LLM-assisted analysis. Patel et al. [17] propose initial thematic saturation (ITS) as validity metric, measuring when LLMs reach analytical saturation in initial coding. Chen et al. [18] examine codebook reduction and saturation patterns, providing insights into how LLMs handle iterative coding processes. Systematic Evidence. Kumar et al. [19] provide comprehensive systematic mapping of LLM applications in qualitative research across diverse fields, application contexts, and evaluation metrics. Their review reveals heterogeneous approaches with limited standardization, underscoring the need for systematic validation frameworks. These studies reveal critical gap: existing LLM approaches lack systematic validation mechanisms. Single-run analyses provide no reliability indicators, and multi-model studies focus on performance comparison rather than developing validation frameworks. Our work addresses this gap through ensemble validation with quantified reliability metrics, building on the semantic similarity validation demonstrated by Zhang et al. [12] while extending it through multi-run consensus."
        },
        {
            "title": "3.1 Ensemble Validation Framework",
            "content": "Our framework conducts six independent analytical runs with fixed random seeds (42, 123, 456, 789, 1011, 1213), analogous to K-fold crossvalidation in machine learning. This design choice is grounded in statistical theory and practical considerations. Statistical Rationale. Classical test theory requires multiple measurements to estimate true score variance versus error variance. While traditional inter-rater reliability studies use two to three coders, research on consensus measurement [20] suggests that five to six independent ratings provide substantially more stable estimates. Six runs enable 15 pairwise comparisons: Comparisons = n(n 1) 2 = 6 5 = 15 (1) This provides sufficient data points to detect meaningful agreement patterns while avoiding computational expense. The improvement in standard error from three to six runs follows: SE3 SE6 = (cid:114) 6 = 2 1.41 (2) representing 41% reduction in variabilitya meaningful improvement without excessive cost. Consensus Mechanism. We implement an adaptive consensus algorithm: 3 1. Extract all themes from each run (structureagnostic JSON parsing) 2. Compute pairwise cosine similarity between all theme descriptions across runs 3. Group themes with similarity > 0.70 into equivalence classes 4. Count occurrence frequency for each equivalence class 5. Retain themes appearing in 50% of runs (adjustable threshold) 6. Compute per-theme consistency percentage (e.g., 5/6 runs = 83%) This balances conservatism (filtering spurious themes) with sensitivity (preserving valid variation). The system distinguishes high-confidence (5-6/6, 83-100%) from moderate-confidence (34/6, 50-66%) themes, enabling researchers to apply different review standards."
        },
        {
            "title": "3.2 Dual Reliability Metrics",
            "content": "We implement two complementary reliability measures addressing different validation aspects: Cohens Kappa (κ). Measures inter-rater agreement accounting for chance: κ = po pe 1 pe (3) where po is observed agreement and pe is expected agreement by chance. For thematic analysis, we compute theme presence/absence across runs, calculating pairwise kappa for all run pairs. Interpretation follows Landis-Koch criteria: κ > 0.80 (almost perfect), 0.60-0.80 (substantial), 0.40-0.60 (moderate), 0.20-0.40 (fair), κ < 0.20 (poor). Kappa provides statistical rigor comparable to traditional qualitative research standards. Cosine Similarity. Captures semantic equivalence beyond exact matches. We employ sentencetransformer embeddings (all-MiniLM-L6-v2 [21]), mapping theme descriptions into 384-dimensional semantic space: sim(ti, tj) = vi vj vivj = (cid:80)384 k=1 vi,k vj,k (cid:113)(cid:80)384 (cid:113)(cid:80) i,k k=1 v2 k=1 v2 j,k (4) where vi, vj R384 are embedding vectors for themes ti, tj. This captures semantic equivalence beyond lexical overlap, recognizing that themes phrased differently can express identical concepts. The all-MiniLM-L6-v2 model was selected for its balance of accuracy (validated performance on STS benchmark) and efficiency (6 layers, 384 dimensions), trained on diverse text corpora including natural language inference and semantic textual similarity datasets. Similarity Computation. For each pair of runs (i, j), we compute the embedding for each theme description using mean pooling of token embeddings, then calculate cosine similarity. The system computes all 15 pairwise similarities, generating distribution of scores that provides richer information than single reliability coefficient. High variance suggests multiple interpretive possibilities; low variance indicates strong convergence."
        },
        {
            "title": "3.3 Configurable Analysis Parameters",
            "content": "Our framework provides user-configurable parameters enabling reproducible yet flexible analysis: Seeds. Researchers can configure 1-6 seeds (default: [42, 123, 456, 789, 1011, 1213]), with each seed producing one independent run. Seeds enable reproducibility while introducing controlled variation. The UI provides dynamic seed management (add/remove seeds), with the number of runs automatically adjusting to match seed count. Temperature. Adjustable temperature [0.0, 2.0] (default: 0.7) controls output randomness. Lower values (T < 0.5) produce deterministic outputs suitable for structured data; higher values (T > 1.0) encourage creative interpretation for exploratory research. Temperature applies uniformly across all runs, ensuring consistent randomness levels while seeds introduce variation. Custom Prompts. Researchers specify custom prompts with variable substitution: {seed} inserts the current seed value, enabling runspecific instructions (e.g., Run ID: {seed}); {text chunk} or {text} inserts transcript content at specified locations. This enables full control over prompt structure, analytical framework, and output format while maintaining seed-based variation."
        },
        {
            "title": "Handling",
            "content": "LLMs frequently return JSON wrapped in markdown code blocks ( json ... ) or with trailing text. We implement multi-stage parsing: 1. Strip markdown code fences using regex: ^(?:json)?s*n? and n?s*$ 2. Attempt JSON parsing; if successful, validate structure 3. For custom prompts, accept any valid JSON object (structure-agnostic) prompts, default 4. For quired emotionalPatterns) fields re- (majorEmotionalThemes, validate 5. Implement exponential backoff retry (3 attempts) for API failures 6. Log parsing errors with original response for debugging This robust parsing achieves 98%+ success rate across three LLMs, handling varied response formats without manual intervention."
        },
        {
            "title": "3.5 Preprocessing and Chunking",
            "content": "intelligent Implements UTF-8 normalization, chunking for documents exceeding context limits (preserving paragraph boundaries), and metadata extraction (timestamps, speaker IDs). For large documents (>1M tokens), employs semanticaware synthechunking with 20% overlap, sizing chunk-level themes into document-level themes. Client-side preprocessing ensures data privacyraw data never transmits to external servers until analysis initiation."
        },
        {
            "title": "4.1 Experimental Design",
            "content": "Dataset. We evaluate the framework on semi-structured interview transcript exploring art therapy integration with ketamine-assisted psychotherapy. The transcript (28,377 characters, 173 lines) captures therapists perspectives on combining expressive arts with ketamine therapy, client experiences, and future opportunities in the field. This dataset represents complex qualitative data with: (1) multiple thematic dimensions (methodology, client experiences, theoretical frameworks), (2) emotional and clinical content, (3) implicit therapeutic knowledge, and (4) nuanced contextual interpretation. The complete transcript is available in our GitHub repository. Evaluation Protocol. For each LLM (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet), we conducted six independent runs using fixed seeds (42, 123, 456, 789, 1011, 1213) with temperature T=0.7. We employed custom prompt specifying: (1) identification of core themes, therapist methodology, client experiences, and future outlook, (2) JSON output with supporting quotes, and (3) seed-based run identification using {seed} 4 Table 1: Dual Reliability Metrics Across Three LLMs Model κ Range Cosine Gemini 2.5 Pro GPT-4o Claude 3.5 0.907 0.853 0.842 0.745-0.977 0.672-0.988 0.604-1.000 95.3% 92.6% 92.1% Table 2: Consensus Themes and Consistency Model Themes High Mod. (Total) Cons. Cons. Gemini 2.5 Pro GPT-4o Claude 3.5 Sonnet 6 5 4 2 2 4 3 3 placeholder. For each model, we computed: (1) pairwise Cohens Kappa across 15 run pairs, (2) pairwise cosine similarity using all-MiniLM-L6-v2 embeddings, (3) consensus themes appearing in 50% of runs, and (4) theme consistency percentages."
        },
        {
            "title": "4.2 Model Comparison Results",
            "content": "We evaluated three leading LLMs on ketamine art therapy interview transcript (28,377 characters, 173 lines), conducting six independent runs per model using fixed seeds (42, 123, 456, 789, 1011, 1213). Table 1 presents dual reliability metrics: Cohens Kappa and cosine similarity. All three models achieve strong agreement (κ > 0.80) according to Landis and Kochs interpretation [20], validating the multi-run ensemble approach. Gemini demonstrates highest consistency with κ = 0.907 and narrowest kappa range (0.232 span), indicating stable performance across runs. Claude exhibits widest kappa range (0.396 span) despite high average κ = 0.842, suggesting occasional divergent runs. Cosine similarity correlates strongly with kappa (Pearson r=0.97), validating semantic embeddings as effective reliability measures. Figure 1 visualizes the pairwise similarity matrix for Gemini 2.5 Pro, showing strong consistency across all run pairs with similarity values predominantly in the 0.78-0.91 range. Consensus Theme Extraction. Gemini identified 6 consensus themes with 50-83% consistency, GPT-4o identified 5 themes, and Claude 4 themes  (Table 2)  . Higher consensus counts suggest more stable thematic identification across runs. Figure 1: Correlation matrix showing pairwise cosine similarity scores across six independent runs for Gemini 2.5 Pro. High similarity values (green to yellow, 0.78-0.91) indicate strong interrun agreement, with the diagonal showing perfect self-similarity (1.000). The consistent high values across off-diagonal elements demonstrate robust thematic consistency."
        },
        {
            "title": "4.3 Structure-Agnostic Consensus Ex-",
            "content": "traction key technical contribution enables consensus extraction for arbitrary JSON structures. Unlike frameworks requiring predefined schemas, our implementation: Dynamic Schema Detection. Anato identify common arlyzes LLM outputs ray fields core themes, client experiences). For each array, identifies theme name and supporting quotes fields (or equivalent). across (e.g., runs Semantic Clustering. Groups themes across runs using cosine similarity threshold (0.70). Themes with similarity >0.70 are considered equivalent, accounting for paraphrasing. Consensus Filtering. Themes appearing in 50% of runs (default threshold) are designated consensus themes. The system computes occurrence frequency, enabling researchers to distinguish high-confidence (5-6/6 runs) versus moderate-confidence (3-4/6 runs) themes. Multi-LLM Support. The framework integrates nine LLM providers: Google Gemini, Anthropic Claude, OpenAI GPT, Azure OpenAI, Groq, DeepSeek, and OpenRouter (enabling access to Llama, Claude, and DeepSeek via unified API). This enables cross-model validationthemes identified consistently across different architectures to receive higher confidence. The trade-off lies in requiring computational resources and API access, which may be barriers for some research contexts."
        },
        {
            "title": "4.4 Ketamine Art Therapy Analysis",
            "content": "We analyzed semi-structured interview with therapist integrating art therapy with ketamineassisted psychotherapy. Gemini 2.5 Pro achieved κ = 0.907 and cosine similarity 95.3%, identifying 6 consensus themes. High-Confidence Themes. Two themes appeared in 5/6 runs (83% consistency): (1) Overcoming Creative Blocksclients breaking through perfectionist barriers via ketamine and art integration, and (2) Challenges in Articulationneurodiverse clients struggling with abstract prompts. These themes demonstrate strong inter-run agreement despite varied phrasing. Moderate-Confidence Themes. Four themes appeared in 3-4/6 runs (50-66% conIntegration of Art Therapy and sistency): Psychedelic Therapy, Internal Family Systems (IFS) Integration, Eco Art Therapy, and Group Work and Collective Unburdening. Moderate consensus captures valuable thematic possibilities requiring researcher judgmentbalancing between conservative (high-threshold) and exploratory (low-threshold) approaches. Cross-Model Validation. Comparing across models: IFS Integration appeared in Gemini (50%), GPT-4o (83%), and Claude (66%), with semantic similarity 0.88 across model outputs, validating this as robust theme. Creative Liberation appeared in GPT-4o and Claude but not Geminis consensus, suggesting interpretive variation. This cross-model comparison enables identification of model-invariant themes (high confidence) versus model-specific interpretations (requiring human review). This case demonstrates how our framework balances themes reliability (filtering spurious with consensus thresholds) with validity (preserving meaningful interpretive variation through moderate-confidence themes)."
        },
        {
            "title": "4.5 Comparison with Existing Frame-",
            "content": "works Table 3 compares our approach against existing qualitative analysis frameworks across key dimensions. Our framework occupies unique position: providing full thematic analysis with quantified reliability at substantially lower cost and time investment than traditional multi-coder approaches."
        },
        {
            "title": "5.1 Technical Contributions",
            "content": "Dual Reliability Metrics. Combining Cohens Kappa with cosine similarity addresses complementary validation needs: kappa provides statistical rigor comparable to traditional qualitative research (enabling claims of almost perfect agreement), while cosine similarity captures semantic equivalence that kappa misses (e.g., perfectionist barriers vs creative blocks from self-criticism achieve high cosine similarity despite low lexical overlap). Configurable Parameters. User-specified seeds and temperature enable reproducible yet The {seed} placeholder flexible analysis. instructions in prompts framewhile maintaining identical analytical works. This supports methodological transparencyresearchers report exact seeds used, enabling replication. run-specific enables Structure-Agnostic Design. Dynamic schema detection enables custom prompt formats without code modification. Researchers specify analytical frameworks, output structures, and granularity levels suited to their research questions, not constrained by predefined templates. The consensus extraction algorithm adapts to any JSON structure containing theme arrays."
        },
        {
            "title": "5.2 Comparison with Existing Ap-",
            "content": "proaches Our dual-metric validation extends recent work: Zhang et al.s LATA [12] achieved 0.76 cosine similarity between LLM and human analyses; our inter-run consistency exceeds this (0.92-0.95), suggesting ensemble methods may achieve higher reliability than single-run human-AI comparison. The TAMA framework [8] employs multi-agent architectures; our single-agent multi-run approach provides simpler implementation with comparable reliability. QualIT [2] focuses on key-phrase extraction; our structure-agnostic design supports full thematic analysis with arbitrary output formats. 6 Table 3: Framework Comparison Across Key Dimensions Dimension Traditional Manual QualIT Single-Run LLM Our work FrameAnalysis Type Full thematic Cohens κ Reliability Metrics Custom Prompts N/A Validation Method Cost (20 docs) Reliability Level Reproducibility Multiple coders $400-800 κ = 0.40-0.60 Low exKey-phrase traction Topic coherence None Full thematic No Cluster quality Yes None $100-200 70% coherence Moderate $2-4 Unknown Low Full thematic κ + Cosine enYes Multi-run semble $3-6 κ = 0.84-0.91 High (seeds)"
        },
        {
            "title": "5.3 Interpretation Guidelines",
            "content": "Cohens Kappa. Following Landis-Koch criteria: κ > 0.80 (almost perfect), 0.60-0.80 (substantial), 0.40-0.60 (moderate). Our results (κ = 0.840.91) achieve almost perfect reliability across all three LLMs, validating the ensemble approach for rigorous qualitative research. Cosine Similarity. Interpret as percentage semantic overlap: >90% (high consistency), 80-90% (moderate), <80% (low, warrants review). Our results (92-95%) demonstrate strong convergence. Kappa range (spread between min/max pairwise kappa) indicates stability: <0.25 (stable), 0.250.40 (moderate variation), >0.40 (high variation requiring investigation). Consensus Thresholds. Default 50% (3/6 runs) balances sensitivity and specificity. Adjust based on context: 67% (4/6) for conservative high-stakes research, 33% (2/6) for exploratory analysis. High-confidence themes (83%, 5-6/6 runs) require minimal human review; moderateconfidence themes (50-66%, 3-4/6 runs) warrant researcher judgment."
        },
        {
            "title": "5.4 Limitations",
            "content": "Single Dataset Evaluation. Our empirical evaluation uses one interview transcript (ketamine art therapy). While this demonstrates proofof-concept and enables detailed analysis, generalization requires evaluation across diverse domains (clinical, educational, organizational), data types (interviews, focus groups, surveys), and languages. The high reliability (κ > 0.84) suggests promise, but boundary conditions remain to be established. Cultural and Domain Boundaries. LLMs encode training data biases [4]. Our framework aids bias detection (biased themes appearing in 1-2/6 runs flag for review), but cannot eliminate it. Performance on non-English, non-Western, or highly specialized domain data requires systematic evaluation. Prompt Engineering Dependency. Analysis quality depends on prompt design. Effective prompts specify analytical frameworks, output structures, and abstraction levels. Our structureagnostic design enables flexibility but requires researchers to craft appropriate promptsa skill requiring training. Human Oversight Necessity. AI cannot perform reflexivity, integrate theoretical frameworks, or make ethical judgments. Our framework provides validated starting points requiring human interpretation, not autonomous analysis."
        },
        {
            "title": "5.5 Future Work",
            "content": "Large-Scale Validation. Systematic evaluation across diverse datasets (clinical interviews, focus groups, surveys), domains (healthcare, education, organizational), and languages (English, Spanish, Chinese, etc.) to establish reliability benchmarks and boundary conditions. Human-AI Comparison. Comparison against human coders on identical datasets, measuring kappa agreement between AI consensus themes and human-coded themes. Zhang et al. [12] achieved 0.76 similarity; our inter-run consistency (0.92-0.95) suggests potential for high human-AI agreement. Adaptive Run Configuration. Implementing thematic saturation metrics [17, 18] to determine optimal run counts dynamically. If new themes cease emerging after runs, stop analysis rather than using fixed N=6. 7 Cross-LLM Ensembles. Simultaneous analysis with multiple models (Gemini + GPT4o + Claude), identifying themes with crossarchitecture support. Our data shows 60-70% theme overlap across models, suggesting this would increase confidence while filtering modelspecific artifacts."
        },
        {
            "title": "6 Implementation Considera-",
            "content": "tions"
        },
        {
            "title": "6.1 Technical Architecture",
            "content": "Client-Side Processing. The framework operates entirely client-side in the browser using Next.js 14 and React. Data preprocessing, embedding computation (via Transformers.js), and consensus extraction occur locally, preserving privacy. Raw transcripts never leave the researchers device until analysis initiation. Multi-Provider API Integration. Unified interface supporting nine providers: Direct APIs: Google Gemini 2.5 Pro, Anthropic Claude 3.5 Sonnet, OpenAI GPT-4o, Azure, Groq, DeepSeek - R1 OpenRouter: Unified access to Llama 3.2 90B, Claude Sonnet, DeepSeek R1 via API Each provider implements: (1) standardized request formatting with seed and temperature parameters, (2) response normalization to unified JSON structure, (3) error handling with exponential backoff, (4) CORS configuration for browserbased requests. API keys provided at runtime; no credentials stored or transmitted except to respective provider endpoints. Embedding Computation and Performance. Uses Xenova/transformers.js to run allMiniLM-L6-v2 in-browser via WebAssembly, generating 384-dimensional embeddings without external API calls. Performance optimizations: Limits embedding computation to 10 themes per run (prevents memory bloat) For custom structures with many themes, uses lightweight string comparison instead of full embeddings Implements sampling for pairwise comparisons (limits to 10 samples if total pairs 10) via thread setTimeout(0) during intensive loops Yields control UI to Progressive status updates (Calculating similarity X/Y...) maintain responsiveness 8 These optimizations prevent UI freezing during synthesis while maintaining analytical accuracy."
        },
        {
            "title": "7 Conclusion",
            "content": "We presented multi-perspective validation framework for LLM-based thematic analysis with dual reliability metrics: Cohens Kappa and cosine similarity. Empirical evaluation on ketamine art therapy interview data across three leading LLMs demonstrates almost perfect agreement (κ > 0.80) for all models: Gemini 2.5 Pro (κ = 0.907, cosine=95.3%), GPT-4o (κ = 0.853, cosine=92.6%), and Claude 3.5 Sonnet (κ = 0.842, cosine=92.1%). These results validate the ensemble approach for rigorous qualitative research, achieving reliability levels comparable to traditional multi-coder studies at fraction of the cost ($0.15-0.20 per transcript vs $20-40 for human coding). Technical contributions include: (1) configurable seeds and temperature for reproducible variation, (2) custom prompt support with variable substitution, (3) structure-agnostic consensus extraction for arbitrary JSON formats, and (4) integration with nine LLM providers enabling cross-model validation. The framework successfully identifies consensus themes (4-6 themes per model) with 50-100% consistency across runs, filtering spurious patterns while preserving valid interpretive variation. for foundations Our open-source implementation (available at https://github.com/NileshArnaiya/ establishes LLM-Thematic-Analysis-Tool) reliable AImethodological assisted qualitative research, bridging computational efficiency with rigorous validation standards required in qualitative methodology. Future work should evaluate across diverse domains, languages, and cultural contexts to establish boundary conditions and normative reliability benchmarks."
        },
        {
            "title": "Acknowledgments",
            "content": "This research was conducted at Aza Lab at Department of Psychiatry at Yale University and the Center of Collective Healing at Howard University. Funding provided by internal grants to the AZA Lab. The complete source code is openly available on GitHub at https://github.com/NileshArnaiya/ LLM-Thematic-Analysis-Tool, with live deployat https://azalab-llm-tool.vercel. ment app/. The ketamine art therapy interview transcript used for evaluation is available in the repository under /transcript.txt. We thank the participating therapist for sharing insights on integrating expressive arts with ketamine-assisted psychotherapy. AA designed and supervised project, wrote and edited mansucript. NA developed model, wrote and implemented code, and drafted manuscript. SA collected and provided qualitative data"
        },
        {
            "title": "Supplementary Materials",
            "content": "Supplementary File 1: Gemini 2.5 Pro Analysis Reliability Metrics: κ = 0.907 (Range: 0.7450.977), Cosine Similarity: 95.3% Consensus Themes (6 total): 1. Overcoming Creative Blocks (83.3%, 5/6 runs): One client overcame perfectionist and depressive parts through ketamine therapy and began painting extensively, reconnecting with playful and peaceful creative process. 2. Challenges in Articulation (83.3%, 5/6 runs): Some clients, especially those who are concrete thinkers or neurodiverse, struggle with abstract art prompts or deeper integration of their experiences into daily life. 3. Eco Art Therapy (66.7%, 4/6 runs): Eco art therapy as an emerging opportunity. 4. Integration of Art Therapy and Psychedelic Therapy (50%, 3/6 runs): The therapist emphasizes the natural pairing of art therapy with psychedelic therapy, highlighting how visual art can deepen internal experiences. 5. Integration of Internal Family Systems (IFS) (50%, 3/6 runs): The therapist integrates IFS into her approach, using parts work to externalize clients internal experiences through visual art and metaphors. 6. Group Work and Collective Unburdening (50%, 3/6 runs): Group work and collective unburdening as future opportunities. Supplementary File 2: GPT-4o Analysis Reliability Metrics: κ = 0.853 (Range: 0.6720.988), Cosine Similarity: 92.6% Consensus Themes (5 total): 9 1. Integration of Internal Family Systems (IFS) (83.3%, 5/6 runs): The therapist explicitly uses the IFS model, employing art as primary tool to help clients identify, externalize, and build relationships with their internal parts. 2. Overcoming Creative and Emotional Blocks (83.3%, 5/6 runs): significant benefit is the unlocking of creative energy previously blocked by internal critics or emotional states like depression. 3. Synergy of Therapeutic Modalities (66.7%, 4/6 runs): The interview highlights the natural and powerful synergy between art therapy, psychedelic-assisted therapy, and Internal Family Systems (IFS). 4. Client-Centered and Invitational Approach (50%, 3/6 runs): The therapist consistently offers art as an option rather than requirement, respecting the clients willingness and readiness. 5. Process Over Product Philosophy (50%, 3/6 runs): The focus is placed squarely on the creative process and the feelings it evokes, rather than the aesthetic quality of the final artwork. Supplementary File 3: Claude 3.5 Sonnet Analysis Reliability Metrics: κ = 0.842 (Range: 0.6041.000), Cosine Similarity: 92.1% Consensus Themes (4 total): 1. Integration of Art and Psychedelics (100%, 6/6 runs): The therapist emphasizes the natural synergy between art therapy and psychedelic experiences, viewing them as complementary modalities that enhance therapeutic outcomes. 2. Integration Challenges (83.3%, 5/6 runs): Some clients struggle with deeper meaningmaking in their artwork, particularly those who are more concrete thinkers. 3. Integration Framework (66.7%, 4/6 runs): Uses combination of Internal Family Systems therapy, and ketamineassisted psychotherapy, offering art as an optional but encouraged component. (IFS), art 4. Creative Liberation (66.7%, 4/6 runs): Clients experiencing breakthrough in creative expression and overcoming perfectionist barriers through the combination of ketamine and art therapy. Note: Complete reports available at https://github.com/NileshArnaiya/ LLM-Thematic-Analysis-Tool. guage Model: An Exploration and Provocation on the Limits of the Approach. Qualitative Research."
        },
        {
            "title": "References",
            "content": "[1] Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77-101. [2] Bhaduri, S., Gil, A., Mittal, A., & Mulkar, R. (2024). Qualitative Insights Tool (QualIT): LLM Enhanced Topic Modeling. arXiv preprint arXiv:2409.15626. [3] Bennis, research: I., & Mouwafaq, S. (2025). Advancing AI-driven thematic analysis in qualstudy itative of nine generative models on Cutaneous Leishmaniasis data. BMC Medical Informatics and Decision Making, 25(1), 124. https://doi.org/10.1186/s12911-025-02961-5 comparative [4] Sakaguchi, K., Sakama, R., & Watari, T. (2025). Evaluating ChatGPT in Qualitative Thematic Analysis With Human Researchers in the Japanese Clinical Context and Its Cultural Interpretation ChalComparative Qualitative Study. lenges: Journal of Medical Internet Research, 27, e71521. https://doi.org/10.2196/71521 [5] Rana, Z., & Asad, R. (2023). LLMin-the-loop: Leveraging Large Language Model for Thematic Analysis. arXiv preprint arXiv:2310.09893. [6] Schlagwein, D. (2024). Role Play: Conversational Roles as Framework for Reflexive Practice in AI-Assisted Qualitative Research. Qualitative Research. [7] Landers, R. N., & Behrend, T. S. (2024). Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research. arXiv preprint. [8] Alhakeem, M., et al. (2025). TAMA: Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical preprint arXiv:2503.XXXXX. Interviews. arXiv [9] Lindh, M., & Messina, R. (2023). Performing an Inductive Thematic Analysis of SemiStructured Interviews With Large Lan10 [10] Turobov, A., Coyle, D., & Harding, V. (2024). Using ChatGPT for thematic analysis. Bennett Institute for Public Policy, University of Cambridge. [11] Fulgencio, F. F. J. (2024). Thematic Analysis through Artificial Intelligence (AI). The Qualitative Report, 29(2), 566-584. [12] Zhang, S., et al. (2025). LATA: Pilot Study on LLM-Assisted Thematic Analysis of Online Social Network Data Generation Experiences. ACM Digital Library. [13] Gupta, A. K., Li, S., Lee, J. A., & Nepal, S. K. (2025). Utilizing Large Language Models to Conduct Thematic Analysis: Case Study on Focus Group Transcripts. SSRN Electronic Journal. [14] Braun, V., & Clarke, V. (2023). Large Language Models in Thematic Analysis: Prompt Engineering, Evaluation, and Guidelines for Qualitative Software Engineering Research. Semantic Scholar. [15] Sanford, K., et al. (2024). Enhancing Thematic Analysis with Local LLMs: Scientific Evaluation of Prompt Engineering Techniques. CMS Conferences. [16] Nelson, M. R. (2025). Reflecting on LLM Support in Reflexive Thematic Analysis: An Exploratory Study. Qualitative Research. [17] Patel, R., et al. (2024). Reflections on Inductive Thematic Saturation as potential metric for measuring the validity of an inductive Thematic Analysis with LLMs. arXiv preprint. [18] Chen, Y., et al. (2025). Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis. arXiv preprint arXiv:2503.XXXXX. [19] Kumar, R., et al. (2025). Large Language Model for Qualitative Research Systematic Mapping Study. arXiv preprint arXiv:2503.XXXXX. [20] Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: Uses in assessing rater reliability. Psychological Bulletin, 86(2), 420428. [21] Hartmann, J. (2022). j-hartmann/emotionHugfrom https: english-distilroberta-base. ging Retrieved //huggingface.co/j-hartmann/ emotion-english-distilroberta-base Face."
        }
    ],
    "affiliations": [
        "Center for Collective Healing",
        "University of Exeter",
        "Yale School of Medicine"
    ]
}