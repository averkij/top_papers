{
    "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
    "authors": [
        "Silei Xu",
        "Wenhao Xie",
        "Lingxiao Zhao",
        "Pengcheng He"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ a more efficient strategy: drafting concise intermediate thoughts that capture only essential information. In this work, we propose Chain of Draft (CoD), a novel paradigm inspired by human cognitive processes, where LLMs generate minimalistic yet informative intermediate reasoning outputs while solving tasks. By reducing verbosity and focusing on critical insights, CoD matches or surpasses CoT in accuracy while using as little as only 7.6% of the tokens, significantly reducing cost and latency across various reasoning tasks."
        },
        {
            "title": "Start",
            "content": "Chain of Draft: Thinking Faster by Writing Less Silei Xu, Wenhao Xie, Lingxiao Zhao, Pengcheng He Zoom Communications 5 2 0 2 5 2 ] . [ 1 0 0 6 8 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ more efficient strategy: drafting concise intermediate thoughts that capture only essential information. In this work, we propose Chain of Draft (CoD), novel paradigm inspired by human cognitive processes, where LLMs generate minimalistic yet informative intermediate reasoning outputs while solving tasks. By reducing verbosity and focusing on critical insights, CoD matches or surpasses CoT in accuracy while using as little as only 7.6% of the tokens, significantly reducing cost and latency across various reasoning tasks."
        },
        {
            "title": "Introduction",
            "content": "Recent advances in reasoning models such as OpenAI o1 (OpenAI, 2024) and DeepSeek R1 (Guo et al., 2025) have propelled large language models (LLMs) to unprecedented performance on complex tasks using techniques like Chain of Thought (CoT) (Wei et al., 2022). This paradigm encourages models to break down problems into step-bystep explorations, mimicking the structured reasoning process of humans. While effective, this approach demands substantially more computational resources at inference time, leading to verbose outputs and higher latency. Such verbosity contrasts sharply with how humans typically approach problem-solving: we rely on concise drafts or shorthand notes to capture essential insights without unnecessary elaboration. Motivated by this difference, we propose Chain of Draft (CoD), novel prompting strategy that aligns more closely with human reasoning by prioritizing efficiency and minimalism. Instead of Correspondence to <silei.xu@zoom.us> Figure 1: Comparison of Claude 3.5 Sonnets accuracy and token usage across different tasks with three different prompt strategies: direct answer (Standard), Chain of Thought (CoT), and Chain of Draft (CoD). CoD achieves similar accuracy as CoT while using significant fewer tokens. verbose intermediate steps, Chain of Draft encourages LLMs to generate concise, dense-information outputs at each step. This approach reduces latency and computational costs without sacrifice of accuracy, making LLMs more practical for real-world applications where efficiency is paramount. The intuition behind Chain of Draft is rooted in how humans externalize thought. When solving complex tasks whether solving mathematical problems, drafting essays, or coding we often jot down only the critical pieces of information that help us progress. By emulating this behavior, LLMs can focus on advancing toward solutions without the overhead of verbose reasoning. To evaluate the effectiveness of Chain of Draft, we conducted experiments across variety of benchmarks requiring multi-step reasoning, including arithmetic reasoning, common sense reasoning, and symbolic reasoning. Our results demonstrate that this minimalist approach maintains or even improves accuracy compared with standard Chain of Thought, while significantly reducing token usage and latency. The contributions of this paper are threefold: We introduce Chain of Draft, concise reasoning prompting strategy inspired by human cognitive processes. We empirically validate that Chain of Draft can achieve significantly reduced latency and cost without sacrificing accuracy. We discuss the implications of Chain of Draft for LLM design, deployment, and real-world usability."
        },
        {
            "title": "2 Related Work",
            "content": "Structured Reasoning Frameworks for LLMs Recently, variety of reasoning language models have emerged, including o1 by OpenAI (OpenAI, 2024), QwQ by Alibaba (Team, 2024), and R1 by DeepSeek (Guo et al., 2025), demonstrating substantial improvements in tackling complex tasks. These models leverage structured reasoning methods to enhance robustness and problem-solving capabilities. The concept of Chain-of-Thought reasoning (CoT) (Wei et al., 2022; Kojima et al., 2022), established foundational approach to reasoning in LLMs. Building on this foundation, more sophisticated topologies have emerged, such as tree (Yao et al., 2024; Chen et al., 2024a; Yu et al., 2023) and graph (Besta et al., 2024; Lei et al., 2023; Jiang et al., 2023), enabling LLMs to address increasingly intricate problems. Other enhancements include self-consistency CoT (Wang et al., 2022), which incorporates verification and reflection mechanisms to bolster reasoning reliability, and ReAct (Yao et al., 2022), which integrates tool usage into the reasoning process, allowing LLMs to access external resources and knowledge. These innovations collectively expand the reasoning capabilities of LLMs across diverse range of applications. LLM Inference Latency Reduction Although structured reasoning greatly enhances LLMs ability to solve complex questions, it significantly increases the token usage before arriving at final answer. This makes it challenging to apply in costsensitive and latency-sensitive scenarios (Wang et al., 2024). Furthermore, the models lack of awareness regarding task complexity often leads to overthinking (Chen et al., 2024b; Chiang and Lee, 2024) even on simple tasks, resulting in unnecessary resource consumption. Techniques like streaming aim to reduce perceived latency by incrementally providing partial outputs as they are generated, rather than waiting for the entire output sequence. However, this approach cannot fully mitigate overall latency or computational cost, and it is often unsuitable for chain-of-thought reasoning, as intermediate steps are often not intended to be shown to end users. Ning et al. (2023) proposes Skeleton-of-Thought (SoT), method that first guides LLMs to generate skeleton outline of the answer, followed by parallel decoding to reduce latency. While SoT helps lower latency, it does not reduce computational cost and is limited to questions that can be parallelized effectively. Zhang et al. (2023) took different approach, it first generates draft tokens at lower quality but higher speed through selective skipping of intermediate layers, and then validates the draft in single forward pass. Our approach, CoD, can be combined with these approaches to further reduce the latency. Hao et al. (2024) proposes Coconut to train LLMs to perform reasoning in continuous latent space rather than in the traditional natural language space using the final hidden state of the LLM to represent the reasoning process. While Coconut reduces latency and computational cost, it suffers from reduced accuracy in complex tasks, such as GSM8k. Additionally, it loses the interpretability of natural language reasoning and cannot be applied to black-box models like GPT and Claude. The works closest to ours are Concise Thoughts (CCoT) (Nayab et al., 2024) and token-budgetaware LLM reasoning (TALE) (Han et al., 2024). CCoT proposes using fixed global token budget for reasoning steps. However, different tasks may require varying budgets to achieve the optimal balance between performance and cost. Moreover, LLMs may fail to adhere to an impractical budget, often generating far more tokens than intended (Han et al., 2024). Han et al. (2024) extends this idea by dynamically estimating global token budget for different problems based on reasoning complexity. However, this approach requires an additional LLM call to estimate the budget, which increases latency. Furthermore, it assumes that the model can accurately predict the complexity of requests, limiting its applicability to more complex tasks where reflection, self-correction, or external knowledge retrieval may be necessary during the reasoning process. In contrast, our approach employs per-step budget, allowing unlimited reasoning steps, which makes it more adaptable to various structured reasoning techniques."
        },
        {
            "title": "3 Chain-of-Draft Prompting",
            "content": "The Chain-of-Thought (CoT) prompting strategy has demonstrated significant effectiveness across wide range of tasks, particularly those requiring complex multi-step reasoning. However, LLMs often produce excessively verbose reasoning steps, consuming substantial number of tokens before arriving at final answer. In contrast, humans tend to adopt more concise approach when solving complex problems involving multi-step reasoning, such as mathematical or logical puzzles. Rather than elaborating on every detail, humans typically jot down only the essential intermediate results minimal drafts to facilitate their thought processes. Inspired by this natural tendency, we propose novel prompting strategy called Chain-ofDraft (CoD). This approach aims to reduce verbosity by limiting the number of words used in each reasoning step, focusing only on the essential calculations or transformations needed to progress. To illustrate the difference between standard prompting, Chain-of-Thought prompting, and our proposed Chain-of-Draft prompting, consider the following simple arithmetic problem: Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny? The response generated by standard prompting approach directly outputs the answer, often without any reasoning. While correct, this lacks transparency in how the answer was derived, and requires the language model to run multi-step reasoning without any help from intermediate result, which often leads to hallucination."
        },
        {
            "title": "Standard",
            "content": "Q: Jason had 20 lollipops. lollipops. lollipops did Jason give to Denny? A: 8 Now Jason has 12 lollipops. He gave Denny some How many Chain-of-Thought prompting, on the other hand, provides detailed reasoning process. While this response is accurate and interpretable, it includes unnecessary details about Jason, Denny, and the lollipops, which are irrelevant to solving the mathematical problem. This verbosity inflates the token count and increases the response latency. Chain-of-Thought Now Jason has 12 lollipops. He gave Denny some How many After giving some to Denny, Jason now has 12 Q: Jason had 20 lollipops. lollipops. lollipops did Jason give to Denny? A: Lets think through this step by step: 1. Initially, Jason had 20 lollipops. 2. lollipops. 3. To find out how many lollipops Jason gave to Denny, we need to calculate the difference between the initial number of lollipops and the remaining number. 4. We can set up simple subtraction problem: Initial number of lollipops - Remaining number of lollipops = Lollipops given to Denny 5. Putting in the numbers: 20 - 12 = Lollipops given to Denny 6. Solving the subtraction: 20 - 12 = 8 Therefore, Jason gave 8 lollipops to Denny. #### 8 lollipops By contrast, Chain-of-Draft prompting condenses the reasoning process into minimal, abstract representations. Here, the reasoning is distilled into concise equation, focusing solely on the essential mathematical operation required to arrive at the solution. By abstracting away irrelevant contextual details, CoD significantly reduces the token count while maintaining transparency and correctness. Chain-of-Draft Q: Jason had 20 lollipops. lollipops. lollipops did Jason give to Denny? A: 20 - = 12; = 20 - 12 = 8. #### 8 Now Jason has 12 lollipops. He gave Denny some How many"
        },
        {
            "title": "4 Experiments",
            "content": "In empirical experiments, we follow the original CoT paper (Wei et al., 2022) to evaluate on 3 categories of tasks: arithmetic reasoning, commonsense reasoning, and symbolic reasoning. We pick representative tasks where original CoT significantly improves the accuracy over the baseline without reasoning. In particular, we pick GSM8k (Cobbe et al., 2021) for arithmetic reasoning; date understanding and sports understanding from BIG-bench (bench authors, 2023) for commonsense reasoning; and coin flip tasks introduced in the CoT paper (Wei et al., 2022) for symbolic reasoning."
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "We compare three different prompt strategies: CoT, CoD, and Standard prompting as baseline. Standard prompting. we use standard few-shot prompting (Brown et al., 2020), where the model is given input-output pairs as in-context examples. LLMs are asked to directly return the final answer, without any reasoning or explanation. Chain-of-Thought. We follow the exact few-shot examples provided in the appendix of the CoT paper with the exception of having the final answer after four hashtags (####) for more stable answer extraction. Chain-of-Draft. In CoD, we also asked the model to think step by step. However, the model is asked to limit each reasoning step to five words at most. Note that we do not enforce such limitation in any way, it is just general guideline to promte short reasoning steps. For each few-shot example, we also include the Chain of Draft written manually by the authors."
        },
        {
            "title": "The complete system prompt for each prompting",
            "content": "strategy is shown below. Standard Answer the question directly. preamble, explanation, or reasoning. Do not return any Chain-of-Thought Think step by step to answer the following question. Return the answer at the end of the response after separator ####. Chain-of-Draft Think step by step, but only keep minimum draft for each thinking step, with 5 words at most. Return the answer at the end of the response after separator ####. We evaluated each task with two of the most popular flagship models: GPT-4o (gpt-4o-2024-0806) from OpenAI and Claude 3.5 Sonnet (claude3-5-sonnet-20240620) from Anthropic."
        },
        {
            "title": "4.2 Arithmetic Reasoning",
            "content": "We first consider math problems that measure the arithmetic reasoning capabilities of LLMs. GSM8k (Cobbe et al., 2021) has emerged as the benchmark of choice for evaluating arithmetic reasoning in language models, providing comprehensive dataset of 8,500 diverse grade-school-level mathematical problems. Each problem is paired with detailed step-by-step solution, emphasizing arithmetic, geometry, algebra, and logical reasoning skills. The evaluation results are presented in Table 1. The dataset poses significant challenges for both GPT-4o and Claude 3.5 Sonnet when using standard prompting, yielding accuracies of 53.3% and 64.6%, respectively. However, with the application of the CoT, both models surpass 95% accuracy, albeit at the expense of generating approximately 200 tokens per response. In contrast, the chain-ofdraft approach achieves an accuracy of 91% for both models while requiring only about 40 tokens per response, thereby reducing the average output token count by 80% and cutting the average latency by 76.2% and 48.4%, respectively."
        },
        {
            "title": "Accuracy",
            "content": "Token #"
        },
        {
            "title": "Latency",
            "content": "GPT-4o Claude 3.5 Sonnet"
        },
        {
            "title": "CoD",
            "content": "53.3% 95.4% 91.1% 64.6% 95.8% 91.4% 1.1 205.1 43.9 1.1 190.0 39. 0.6 4.2 1.0 0.9 3.1 1.6 Table 1: GSM8K evaluation results."
        },
        {
            "title": "4.3 Commonsense Reasoning",
            "content": "We evaluate the tasks of date understanding and sports understanding from BIG-bench to demonstrate the effectiveness of CoD in common sense reasoning. For consistency, we use the same system prompts as those employed in the arithmetic reasoning evaluation. The evaluation results, presented in Table 2, show that CoD significantly reduces both latency and cost by generating considerably fewer tokens in responses compared to CoT. Additionally, CoD outperforms CoT in accuracy in various cases. Notably, chain-of-thought prompting leads to excessively verbose responses for Claude 3.5 Sonnet, especially in the sports understanding task, where CoD reduces the average output tokens from 189.4 to 14.3 92.4% reduction. Model Prompt Accuracy Token # Latency GPT-4o Claude 3.5 Sonnet Standard CoT CoD Standard CoT CoD 72.6% 90.2% 88.1% 84.3% 87.0% 89.7% 5.2 75.7 30. 5.2 172.5 31.3 0.6 1.7 1.3 1.0 3.2 1.4 Table 2: Date understanding evaluation results."
        },
        {
            "title": "4.4 Symbolic Reasoning",
            "content": "The original CoT paper (Wei et al., 2022) introduces the task of coin flipping, where the LLMs are asked to predict which side is up after sequence of coin flip actions. Since the exact dataset Model Prompt Accuracy Token # Latency GPT-4o Claude 3.5 Sonnet Standard CoT CoD Standard CoT CoD 90.0% 95.9% 98.3% 90.6% 93.2% 97.3% 1.0 28.7 15.0 1. 189.4 14.3 0.4 0.9 0.7 0.9 3.6 1.0 Table 3: Sports understanding evaluation results. is not published, we synthesize test set of 250 examples following the same design. Specifically, we randomly chose 4 out of the top 1000 first names in the US region according to NameDataset (Remy, 2021) and randomly decided to flip the coin or not for each name. An example of the evaluation data is shown below. Q: coin is heads up. Robyn flips the coin. Peggy flips the coin. Grant flips the coin. Vanessa does not flip the coin. Is the coin still heads up? A: No. The evaluation results for GPT-4o and Claude 3.5 Sonnet are shown in Table 4. They achieve 73.2% and 85.2% with standard prompting, respectively. However, both models reach perfect 100% accuracy with CoT and CoD. Again, CoD demonstrates significant reduction of tokens compared to CoT, from 68% for GPT-4o to 86% for Claude 3.5 Sonnet. lengthy reasoning steps, CoD leverages concise reasoning drafts to speed up response generation without sacrificing correctness. Additionally, CoD offers significant cost advantages. By compacting the reasoning steps, it reduces the number of input tokens required for few-shot prompting and shortens the output token length, directly lowering computational cost. This token efficiency makes CoD especially appealing in cost-sensitive scenarios, such as large-scale deployments of LLMs or applications with strict budget constraints. CoD demonstrates that effective reasoning in LLMs does not necessarily require lengthy outputs, offering an alternative approach where reasoning depth is maintained with minimal verbosity. Future work could explore combining CoD with other latency-reducing methods, such as adaptive parallel reasoning or multi-pass validation, to further optimize performance across different application domains. In addition, the principles behind the compact reasoning of CoD could inspire new strategies to improve reasoning models by training with compact reasoning data, while maintaining interpretability and efficiency in LLMs, helping bridge the gap between research-driven improvements in reasoning and the practical demands of real world systems. Model Prompt Accuracy Token # Latency"
        },
        {
            "title": "References",
            "content": "GPT-4o Claude 3.5 Sonnet Standard CoT CoD Standard CoT CoD 73.2% 100.0% 100.0% 85.2% 100.0% 100.0% 1.0 52.4 16.8 1. 135.3 18.9 0.4 1.4 0.8 1.2 3.1 1.6 Table 4: Coin flip evaluation results."
        },
        {
            "title": "5 Discussion",
            "content": "BIG bench authors. 2023. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. 2024. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1768217690. The latency issue has often been overlooked in studies of the reasoning capabilities of LLMs. However, it is crucial for lots of real-time applications to have low latency while maintaining high-quality responses. In this work, we propose Chain of Draft (CoD), novel approach that substantially reduces the latency required for reasoning while achieving comparable or even superior accuracy compared to standard Chain-of-Thought prompting strategies. Unlike traditional methods that often involve Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. In AdLanguage models are few-shot learners. vances in Neural Information Processing Systems, volume 33, pages 18771901. Curran Associates, Inc. OpenAI. 2024. Openai o1 system card. Accessed: 2024-12-01. Philippe Remy. 2021. Name dataset. https://github. com/philipperemy/name-dataset. Qwen Team. 2024. Qwq: Reflect deeply on the boundaries of the unknown. Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, and Ben Athiwaratkun. 2024. Reasoning in token economies: Budget-aware evaluation of llm reasoning strategies. arXiv preprint arXiv:2406.06461. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, volume 35, pages 2482424837. Curran Associates, Inc. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2024. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems, 36. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629. Junchi Yu, Ran He, and Rex Ying. 2023. Thought propagation: An analogical approach to complex reasoning with large language models. arXiv preprint arXiv:2310.03965. Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, and Sharad Mehrotra. 2023. Draft & verify: Lossless large language model acceleration via self-speculative decoding. arXiv preprint arXiv:2309.08168. Sijia Chen, Baochun Li, and Di Niu. 2024a. Boosting of thoughts: Trial-and-error problem solving with large language models. arXiv preprint arXiv:2402.11140. Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, et al. 2024b. Do not think that much for 2+ 3=? on the overthinking of o1-like llms. arXiv preprint arXiv:2412.21187. Cheng-Han Chiang and Hung-yi Lee. 2024. Overreasoning and redundant calculation of large language models. arXiv preprint arXiv:2401.11467. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. Tingxu Han, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen, and Zhenting Wang. 2024. Token-budget-aware llm reasoning. arXiv preprint arXiv:2412.18547. Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian. 2024. Training large language models to reason in continuous latent space. arXiv preprint arXiv:2412.06769. Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, et al. 2023. Resprompt: Residual connection prompting advances multi-step reasoning in large language models. arXiv preprint arXiv:2310.04743. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:22199 22213. Bin Lei, Chunhua Liao, Caiwen Ding, et al. 2023. Boosting logical reasoning in large language models through new framework: The graph of thought. arXiv preprint arXiv:2308.08614. Sania Nayab, Giulio Rossolini, Giorgio Buttazzo, Nicolamaria Manes, and Fabrizio Giacomelli. 2024. Concise thoughts: Impact of output length on llm reasoning and cost. arXiv preprint arXiv:2407.19825. Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, and Yu Wang. 2023. Skeleton-ofthought: Large language models can do parallel decoding. Proceedings ENLSP-III."
        }
    ],
    "affiliations": [
        "Zoom Communications"
    ]
}