{
    "paper_title": "Machine Learning for Energy-Performance-aware Scheduling",
    "authors": [
        "Zheyuan Hu",
        "Yifei Shi"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose a Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multi-core architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis (fANOVA) and comparing different covariance kernels (e.g., Matérn vs. RBF), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 0 3 ] . [ 1 4 3 1 3 2 . 1 0 6 2 : r Machine Learning for Energy-Performance-aware Scheduling Zheyuan Hu, Yifei Shi Department of Computer Science and Technology, University of Cambridge, Cambridge, UK. {zh369, ys690}@cam.ac.uk"
        },
        {
            "title": "Abstract",
            "content": "In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multicore architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis (fANOVA) and comparing different covariance kernels (e.g., Matérn vs. RBF), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance."
        },
        {
            "title": "Introduction",
            "content": "The end of Dennard scaling [1] has ushered in an era of extreme architectural heterogeneity, where modern processors integrate diverse computational units within single silicon die. In this regime, the mapping between operating system scheduling decisions (e.g., task placement, time slice granularity, frequency scaling) and the resulting system metrics (e.g., energy consumption, instruction throughput) exhibits complex, non-linear sensitivities. Consequently, traditional heuristic schedulers often fail to navigate this landscape. While high-fidelity simulation offers detailed evaluation platform, relying on exhaustive search or random sampling within such environments is often computationally intractable due to the combinatorial explosion of the configuration space. Conversely, recent attempts to employ Deep Reinforcement Learning (DRL) [2] offer data-driven alternative but trade one opacity for another. Treating the scheduler as black-box neural network requires prohibitive training data and, crucially, offers minimal insight into why particular schedule is optimal. While powerful, DRL merely replaces one opacity with another, requiring prohibitive amounts of training data while offering minimal insight into why particular schedule is optimal. In contrast to data-hungry DRL, Bayesian Optimization (BO) has demonstrated superior sample efficiency in system tuning, exemplified by works like CherryPick [3] and OtterTune [4]. However, these approaches typically target the smooth, continuous landscapes of cloud computing, overlooking the discrete discontinuities inherent to embedded heterogeneous architectures. Bridging this gap, our work focuses on the offline configuration of post-Dennard multi-core systems. We move beyond simple parameter tuning to address fundamental scientific question: What is the latent topological structure of the optimization landscape in heterogeneous architectures, and can data-driven framework decipher this structure to reveal interpretable, physics-compliant scheduling principles? We answer this by rethinking scheduling through the lens of Bayesian Statistics. Rather than viewing the system merely as black box to be optimized, we employ the Gaussian Process (GP) [5] as denotes equal contribution. probabilistic probe to map the unknown performance function. This approach frames scheduling as sequential model-based exploration that rigorously balances the exploration of unsampled configurations with the exploitation of efficient states. In particular, we integrate Sensitivity Analysis [6] directly into the loop, allowing us to demystify the optimization process and extract physical interpretability from the learned model. The contributions of our work are summarized as follows: 1. Methodological Validation for Non-Smooth Landscapes: We demonstrate that the scheduling landscape is inherently non-smooth. Through rigorous kernel benchmarking, we establish that the Matérn 5/2 kernel outperforms the standard RBF kernel, as it correctly models the sharp performance cliffs associated with discrete core allocations. 2. Discovery of \"Race-to-Idle\" Physics: By analyzing the energy-latency trade-off, our model autonomously rediscovers the \"Race-to-Idle\" phenomenon. We provide empirical evidence that activating high-frequency big cores often yields superior energy efficiency compared to leakage-prone low-frequency execution. 3. Structural Decoupling of Heterogeneity: Our multi-objective analysis reveals functional decoupling in hardware resources. The optimizer learns to map latency-critical tasks to big cores while leveraging little cores for energy conservation, effectively disentangling the conflicting objectives of the heterogeneous system."
        },
        {
            "title": "2 Related works",
            "content": "Processor scheduling. Modern hardware and operating system designers deal with task assignment to achieve high degree of parallelism or low battery usage [7]. Classic algorithms, e.g., FCFS, Round Robin, and priority-based schedulers, provide decent practical usage with strong theoretical support. However, determining appropriate parameters (e.g., time quantum) remains challenging as they are heavily influenced by specific workload characteristics and system settings. Heterogeneous multi-core systems. Unlike homogeneous systems that deploy identical cores, heterogeneous systems are designed for multi-objective optimization. In practice, the Arm big.LITTLE architecture [8] integrates performance-oriented high-frequency cores with energy-efficient lowfrequency cores. This heterogeneity introduces complex, non-smooth parameter space that challenges traditional heuristic tuning methods. Machine learning for systems. Recently, machine learning has been increasingly adopted to solve combinatorial system optimization problems. Deep Reinforcement Learning (DRL) has demonstrated remarkable capability in mapping computational graphs to heterogeneous devices, as demonstrated by Mirhoseini et al. [9]. However, despite DRLs ability to handle high-dimensional problems, it often suffers from poor sample efficiency and lack of interpretability [2]. As more sampleefficient alternatives, BO and probabilistic programming have gained traction [10]. Dalibard et al. [11] incorporated structural priors into BO to accelerate convergence. Similarly, Shao et al. [12] demonstrated that leveraging probabilistic programs for tensor program optimization can significantly outperform traditional search strategies in compiler tuning. Our work aligns with this trend of sample-efficient optimization but specifically focuses on the kernel selection mechanism within BO."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we define how our simulator is designed, including tasks, processors and schedulers, followed by the turnaround time, priority-aware latency, energy metrics with respect to processor frequency. Motivated by real-world problems, we aim to grasp knowledge with the help from machine learning techniques. 3.1 Simulator design Task definition. The system consists of set of tasks = {τi}Ntask process, can be defined as five-element tuple: τ = (ta, tf , p, NIC, E), i=1 . Each task τ , e.g., thread or ta, tf , R, p, NIC Z, 2 where arrival time ta, preferred finish time tf , instruction count NIC, priority level p, and energy consumed are task attributes. These are summarised in Table 1. For each task in the given set, its attributes are randomly initialised over fixed region by data factory class (Figure 1a). The factory method pattern creates task objects following the Open-Closed Principle (OCP). As an example, the tasks follow the Poisson process and the waiting time modelled by exponential distribution. Regarding detailed performance analysis, please refer to 3.2. Table 1: Task attributes and their data type. task id int arrival time float instruction count float priority int energy float finish time Optional[float]"
        },
        {
            "title": "Type",
            "content": "Heterogeneous multi-core design. The system consists of set of processors = {Pi}Ncores i=1 . Each processor is set to fixed frequency during the whole execution time for simplicity, i.e. Dynamic Voltage and Frequency Scaling, or DVFS for short, is not considered. In this work, we aim to investigate how many types are needed for given workload and how frequencies should be set for each processor type. There is balance between high performance and low energy consumption. This is important for configuring per-core CPU frequency settings. Scheduler design. The core goal of schedulers is to dispatch tasks to appropriate processors. There are various task assignment algorithms in the literature, which differ by their simplicity, overhead, fairness, and whether they are preemptive. We implement the following scheduling methods (also shown in Table 2), First-Come, First-Served (FCFS), also known as First-In, First-Out (FIFO). Tasks are executed strictly according to the order of arrival time. The pros are its predictability, starvation-free. However, short tasks that arrive late will wait longer time, which is termed the Convoy effect. Round Robin (RR) is specific implementation of time-sliced or quantum based scheduling (Figure 1b), where tasks are preempted from the processors after the quantum used up. This saves computation time for short tasks, but keeps the average turnaround time larger. Priority-based scheduling. Tasks are dispatched based on the priority level. It can either be preemptive or non-preemptive. It favors high-priority tasks, but might starve those low-priority processes. Table 2: Comparison of FCFS, Round Robin, and priority-based scheduling algorithms. Features decision basis preemptive starvation context switchg use case FCFS arrival time batch processing Round Robin (RR) time quantum time-sharing Priority-based priority level real-time / critical In this project, we aim to learn which scheduler works best for given series of tasks, including their attributes, e.g., time quantum for Round Robin, in the context of energy-performance-aware scheduling. Simulation environment and logging. We adopt SimPy [13], process-based discrete-event framework, as our backend simulation environment. It supports waiting, interrupting process and shared resources. Our simulator is divided into Task, Processors, Schedulers, and Simulators packages, where details are described as above. For efficient verification and debugging, we deploy logging to track every event of the simulation. An example log output generated via logging. INFO:Task factory:Created <N> tasks. Processor <p_id>:Frequency = <f>. INFO:Round Robin scheduler:Initialized with quantum = <q>. INFO:Simulator:Task <t_id> arrived at time <t>, with instruction <count>. INFO:Round Robin scheduler:Task <t_id> quantum expired, enqueuing again. 3 (a) Tasks factory visualisation. (b) Round robin for six heterogeneous processors. Figure 1: Simulator visualisation and results. 3.2 Main objectives Latency and frequency modelling. Instructions per Cycle (IPC) is governed by architectural design, e.g., superscalar pipelines, out-of-order execution, speculation, and branch prediction. We assume that IPC is fixed parameter, not subject to change or variation in our analysis. For task with instruction count NIC, the number of cycles it takes Ncycle = NIC IPC and the total execution time, , where is the operating frequency in also known as turnaround time is cycles per second, or Hertz (Hz). = NIC IPCf 1 = Ncycle Priority-aware latency. Each task is categorized into levels of importance p, as in the standard Operating System. When aggregating the latency, those with higher priority are given larger weight: w(p) = 1 {0, 1, 2, . . . , K}, where lower stands for higher priority and is the least priority level. (p+1)2 , The priority-aware aggregated latency for dataset of tasks is the weighted average given by taggregated = (cid:80)Ntask i=1 wi(p) ti, where Ntask is the total number of tasks, ti is per-task latency, and wi(p) is the weight for each task. Figure 2a shows the weighted task latency as function of both processor frequency and task priority. Energy and frequency modelling. The total power of the computer systems consists of both the processor and the rest (e.g., display, memory subsystems, sensors). Here we focus on the power consumption PXPU of the processors XPU, encompassing CPU, GPU, NPU and other specialised ASIC. Here we focus on two parts [14], i.e. dynamic and leakage power: PXPU = Pdynamic + Pleakage. The dynamic power Pdynamic is that consumed when transistors switch states, i.e. from 0 to 1 or vice versa. This comprises the key and basic step of processors for nearly all computation. With α [0, 1] of the processors actively switching, the dynamic power is, Pdynamic = α 2 , where is the system capacitance as measured in the unit of Farad (F), is the applied voltage expressed in Volts (V), and is the operating frequency in cycles per second, or Hertz (Hz). When there is no computation taking place, which means the processor is idle, the dynamic power is zero, i.e. Pdynamic = 0. The leakage power Pleakage = Ileakage captures power from flowed current Ileakage when Metal Oxide Semiconductor Field Effect Transistor, or MOSFET for short, is in either ON or OFF state, which occurs when the gate-source voltage VGS is above or below the threshold voltage of the MOSFET VT , i.e. VGS VT or VGS < VT . Note that leakage power occurs even when the processor is not actively processing tasks and is not turned OFF, which prevents all transistors from turning ON at all times. This leads to phenomenon termed the power wall in the semiconductor world. The achievable frequency is constrained by gate delay. Here we assume that the operating voltage is far from the threshold VT and thus can be approximated by linear dependency with respect to the operating frequency, = 1 tdelay (V Vth)γ kV + bf , where γ [1, 2], kV , bf R. (1) The relationship between energy (Joules) and power (Joules per second or Watts) over the time period τ is E(τ ) = (cid:82) τ Thus, the total processor energy over fixed time period τ with respect to frequency is, when bf = 0, as shown in Figure 2b, including the active, idle and total energy as function of the processor frequency over fixed period of time, 0 (t) dt = τ , if the power is constant along execution time. E(f ) = τ = (αC 1 k2 3 + Ileakage 1 kV ) τ. Likewise, for tasks with fixed number of instructions NIC, the total processor energy is, 1 kV NIC IPC 3 + Ileakage 2 + Ileakage E(f ) = = (αC = αC 1 kV ) 1 . 1 k2 1 k2 (2) (3) (a) Weight latency vs. frequency and task priority. (b) Energy consumption vs. frequency. Figure 2: Processor energy consumption and task latency. 3.3 Emulator Design Gaussian Process Priors To model the complex, non-linear landscape of CPU scheduling performance, we employ Gaussian Process regression as probabilistic surrogate [5]. GP defines distribution over functions, specified by mean function m(x) (assumed zero after normalization) and covariance kernel k(x, x). The kernel encodes our prior assumptions about the systems smoothness. We explicitly compare the Radial Basis Function (RBF) kernel and the Matérn kernel. The RBF kernel assumes infinite differentiability, which implies highly smooth objective landscape [15]. However, CPU scheduling often involves discrete parameters (e.g., core counts) and performance cliffs (e.g., sudden latency spikes when buffers overflow). Therefore, we adopted the Matérn 5/2 kernel (ν = 2.5) as the optimal compromise. This kernel relaxes the infinite smoothness assumption of RBF to capture system non-linearities (e.g., performance cliffs) while retaining sufficient differentiability (twice differentiable) to ensure robust numerical stability and efficient gradient-based optimization of the acquisition function. Bayesian Optimization and Acquisition Strategy Based on the GP posterior, BO iteratively selects the next configuration xt+1 by maximizing an acquisition function a(x) that balances exploration (variance reduction) and exploitation (mean minimization) [10, 16]. Single-Objective (LogEI) [17]: For scalarized cost minimization, we employ Log Expected Improvement (LogEI). While conceptually equivalent to standard EI, LogEI performs computations in the logarithmic space to prevent numerical underflow in regions of high posterior probability. This ensures robust gradient estimation even when the expected improvement is asymptotically small near the global optimum [18]. Multi-Objective (Pareto Frontier) [19]: For the Pareto optimization phase, we utilize the Expected Hypervolume Improvement (EHVI) [20]. Unlike scalarization methods, EHVI explicitly targets 5 the increase in the hypervolume dominated by the current Pareto front . By integrating over the non-dominated region of the posterior distribution, this strategy effectively incentivizes the discovery of diverse trade-off solutions that extend the frontier towards lower energy and latency. Hyperparameter Sensitivity Analysis To interpret the black-box simulation model and identify the dominant factors driving system performance, we conduct post-hoc sensitivity analysis on the fitted surrogate models [6]. Since our surrogate model is anisotropic, the model learns distinct length-scale parameter ld for each input dimension d. There is an inverse relationship between length-scale and sensitivity: Importanced 1 ld small length-scale ld implies that the objective function changes rapidly along dimension d, indicating high sensitivity. Conversely, large length-scale suggests the dimension is irrelevant (the function is flat along that axis). . In the multi-objective context, we perform this analysis separately for the Energy and Time objectives. This allows us to decouple conflicting drivers, revealing, for example, which hardware resources constitute the bottleneck for latency versus which are the primary sources of power consumption. 3.4 Evaluation Metrics To comprehensively assess the performance of the proposed BO framework, we utilize combination of scalarized cost metrics, multi-objective indicators, and statistical distribution analysis. Weighted Log-Sum Cost For the single-objective phase, we employ scalarization technique to transform the vector-valued outputs into single minimization target. We apply logarithmic transformation to handle the disparate magnitudes of energy (E) and time (T ): L(x) = β ln(E(x)) + γ ln(T (x)) (4) where β and γ are user-defined preference weights. This metric evaluates the optimizers ability to find specific trade-off point on the Pareto frontier. Pareto Optimality and Hypervolume Indicator In the multi-objective phase, we aim to approximate the true Pareto Front . solution x1 dominates x2 (x1 x2) if it is strictly better in at least one objective and no worse in others. To quantitatively evaluate the quality of the obtained Pareto set, we use the Hypervolume (HV) Indicator [20]. HV measures the volume of the objective space dominated by the solution set relative to reference point r. larger Hypervolume indicates better approximation of the true Pareto front, reflecting both the convergence (closeness to the optimum) and diversity (spread) of the solutions. Baselines We compare the performance of our Gaussian Process-based BO against Random Search baseline. Random Search serves as fundamental benchmark to demonstrate the sample efficiency and convergence speed of the active learning strategy employed by our BO framework."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Experiment Setup The processor constants and the units of time and frequency are set according to Table 3, in accordance with the range specified in the standard processor design document. All experiments were conducted on workstation with 9 CPU Cores and 18 GiB RAM, using Optuna [21] and BoTorch [22] libraries. Table 3: Constants used in the processor power and frequency model. kV bf Ileakage unit of unit of 5 109 Hz/V 0 Hz 1 109 3 101 ns (109 s) GHz (109 Hz) Simulation Environment The workload is generated using Poisson process with an average arrival rate λ. Unless otherwise stated (e.g., in the robustness analysis), the default simulation parameters are fixed as follows: (1) Total Simulation Time: Tend = 1000 ms, (2) Total Tasks: Ntasks = 500, (3) Default Workload Pressure: λ = 1.0 (tasks/ms). 6 Design Space (Search Space) The optimization problem involves mixed-variable search space , consisting of continuous (frequency, time quantum), integer (core counts), and categorical (scheduling policy) parameters. The bounds for each decision variable are detailed in Table 4. The Time Quantum parameter is conditional and only active when the scheduling strategy is non-preemptive (i.e., Round Robin or Priority). Component"
        },
        {
            "title": "Scheduler",
            "content": "Table 4: Definition of the Search Space . Parameter Type Range / Options Frequency (GHz) Count Frequency (GHz) Count Frequency (GHz) Count"
        },
        {
            "title": "Continuous\nInteger",
            "content": "[0.5, 1.5] {0, 1, . . . , 4} [1.0, 2.5] {0, 1, . . . , 4} [1.5, 3.5] {0, 1, . . . , 4} Strategy Categorical Time Quantum (ms) Continuous {FCFS, RR, Priority} [0.5, 5.0] Optimization Configuration To ensure statistical robustness, each optimization experiment consists of total budget of = 100 trials. To initialize the Gaussian Process surrogate model, we employ warm-up phase of Ninit = 10 trials sampled using Sobol sequence, which provides better space-filling properties than uniform random sampling. 4.2 Experimental Design To comprehensively evaluate the proposed BO framework, we designed four distinct experimental scenarios. Each scenario targets specific aspect of the systems behaviour and the optimizers capability. Surrogate Model Calibration In this phase, we benchmark different kernels (RBF vs. Matérn) under standard workload (λ = 1.0). The objective is to determine which kernel best captures the discrete and non-smooth landscape of the CPU scheduling problem. The selected kernel is then used as the baseline for subsequent experiments. Preference Sensitivity Analysis Since the cost function is weighted sum of energy and time, system behaviour is highly sensitive to the weights β (energy) and γ (time). We vary these coefficients to simulate different user priorities: (1) Performance-First: High penalty on time (γ > β), (2) EnergyFirst: High penalty on energy (β > γ), (3) Equal weights (β = γ). The objective is to verify if the optimizer can correctly shift the hardware configuration (e.g., scaling frequencies or core counts) to align with the specified high-level preferences. Workload Robustness Testing We evaluate the optimizers robustness by varying the task arrival rate λ (from low load λ = 0.5 to high load λ = 5.0). The objective is to investigate how the optimal architectural configuration evolves under pressure. Specifically, we aim to observe if the system automatically scales up resources (e.g., activating big cores) to prevent latency cliffs during peak loads. Multi-Objective Pareto Exploration Finally, to overcome the limitations of fixed weights, we decouple the objectives and perform Multi-Objective Optimization (MOO). Instead of minimizing scalar loss, we aim to approximate the Pareto Frontier. The objective is to uncover the intrinsic trade-off curve between Energy and Time, providing set of non-dominated solutions that allow system administrators to make posteriori decisions without manually tuning weights."
        },
        {
            "title": "5 Results and Analysis",
            "content": "To comprehensively assess the performance of the proposed BO framework, we utilize combination of scalarized cost metrics, multi-objective indicators, and statistical distribution analysis. Table 5 presents summary of the optimal configurations found across all experimental scenarios. Table 5: Comprehensive Summary of Optimal Configurations found by Bayesian Optimization vs. Baseline. Panel compares different search strategies under the default balanced workload. Panel demonstrates adaptation to user preferences. Panel reveals the systems robustness strategy under varying workload intensities. Note: Objective values are only comparable within the same Panel. Experiment Group Scenario / Variant Core Config (Count Freq) Little Medium Big Scheduler Obj. Value Panel A: Search Strategy Comparison (Balanced, λ = 1.0) - BO (Matérn 5/2) 1 1.6 BO (Matérn 3/2) 4 1.3 BO (RBF) 2 1.8 Random Baseline 3 1.5 - 1 1.5 4 1.2 Algorithm 2 1.5 4 1.5 - - FCFS FCFS RR (4.1ms) RR (2.0ms) Panel B: Preference Adaptation (Metric Shifts) Metric Weights Balanced Energy-First Time-First 3 1.5 - 3 0. - 2 2.5 - 2 1.5 2 3.5 3 1.5 FCFS FCFS Priority (0.7ms) Panel C: Workload Robustness (λ Variation) Arrival Rate (λ) Low (λ = 0.5) High (λ = 2.5) Extreme (λ = 5.0) 3 1.4 4 1.5 1 0.5 - 4 1.5 - - 4 1.5 - Priority (3.8ms) FCFS RR (0.7ms) -19.65 -19.65 -19.63 -19.57 -19.65 -18.35 -61. -19.59 -19.74 -20.63 5.1 Kernel Selection In this section, we evaluate the impact of the Gaussian Process covariance kernel on the optimization performance. We compared the Matérn 5/2, Matérn 3/2, and RBF kernels under the standard balanced metric defined by Equation 4, with the hyperparameter of β = 1, γ = 1. Figure 3 illustrates the optimization history (objective value vs. trial number) for the three kernels. Convergence Speed: As observed in Figure 3a, the Matérn 5/2 kernel demonstrates the most stable convergence trajectory. It rapidly identifies the high-performance region within the first 20 trials and maintains low variance in subsequent iterations. Impact of Smoothness: The RBF kernel (Figure 3c) assumes infinite differentiability and performs slightly worse than the Matérn family. This result validates our hypothesis that the CPU scheduling landscape is non-smooth because it is characterized by discrete core counts and integer parameters. Consequently, the RBF kernel tends to over-smooth the objective function and potentially misses the sharp performance cliffs caused by discrete resource changes. Roughness Handling: The Matérn 3/2 kernel (Figure 3b) performs comparably to Matérn 5/2 but exhibits slightly higher exploration variance. Based on these results, we selected Matérn 5/2 as the baseline kernel for subsequent experiments, as it offers the optimal balance between modelling the rough landscape and maintaining numerical stability for the acquisition function. Specifically, the Sensitivity Analysis in Figure 4 exposes critical flaw in the RBF kernel. While the proposed Matérn 5/2 kernel (Figure 4a) correctly identifies freq_big_ghz and freq_medium_ghz as the dominant factors driving system performance, the RBF kernel (Figure 4c) yields contradicting feature importance ranking, misleadingly attributing the highest sensitivity to freq_little_ghz. This discrepancy suggests that the RBF kernels assumption of infinite smoothness causes it to misinterpret the causal relationship between hardware configurations and the objective function. The Matérn 5/2 kernels ability to prioritize high-performance core frequencies aligns with the physical reality that latency is most sensitive to the clock speed of the most powerful computational units. (a) Optimization History for Matern 2.5. (b) Optimization History for Matern 1.5. (c) Optimization History for RBF. Figure 3: Results of Bayesian Optimization history for different types of kernels. (a) Sensitivity Analysis for Matern 2.5. (b) Sensitivity Analysis for Matern 1.5. (c) Sensitivity Analysis for RBF. Figure 4: Results of Sensitivity Analysis for different types of kernels. 5.2 Metric Evaluation To assess the adaptability of the framework, we tested the optimizer under three distinct preference scenarios: Balance (β = γ = 1), Energy-First (β = 3, γ = 1), and Time-First (β = 1, γ = 3). Figure 6 reveals the shift in hyperparameter importance. Shift in Optimization Strategy The empirical results derived from the sensitivity analysis demonstrate that the optimizer effectively aligns the hardware configuration with high-level user preferences. By observing the variations in hyperparameter importance across different metrics (Figure 6), we identify distinct strategic adaptations: Time-Focused Scenario: In the scenario where latency minimization is prioritized (Figure 6c), the sensitivity analysis reveals that system performance is driven primarily by peak processing speed rather than parallel capacity. Consequently, freq_big_ghz exhibits the highest importance score. Interestingly, the model identifies quantum_ms (scheduling time slice) and count_little as critical factors, ranking them significantly higher than count_big. This indicates that the optimizer prioritizes maximizing the clock speed of the primary core while fine-tuning the schedulers granularity to minimize preemption overhead, rather than simply activating more big cores. Energy-Focused Scenario: Conversely, under the energy-priority setting (Figure 6b), the relative importance of the big core count decreases as the model seeks to minimize static and dynamic power consumption. Instead, the optimizer directs its search effort toward tuning the medium core frequency and the little core count. This shift implies that the algorithm converges toward an efficiency-oriented strategy, where it attempts to offload tasks to the most energy-efficient cores or employs \"Race-to-Idle\" strategy depending on the workload intensity. Physical Interpretation This dynamic shift in hyperparameter sensitivity confirms that the Bayesian Optimization framework captures the underlying physical trade-offs of the heterogeneous processor rather than simply memorizing data points. The algorithm automatically reallocates its exploration focus to different hardware resources in response to the specific definition of the loss function. This behaviour proves that the Gaussian Process surrogate model has successfully learned the distinct contribution of each core type toward energy efficiency and latency reduction, allowing it to navigate the design space intelligently without explicit human guidance. 9 (a) Contour Plot of the Objective Value surface (Energy-Focused Scenario) visualizing the interaction between Big Core Frequency (X-axis) and Little Core Frequency (Y-axis). Darker regions indicate better performance (lower loss). (b) Contour Plot for Time-Focused Scenario (Little vs. Medium Frequency). Note the significantly narrower scale of the objective value compared to the energy scenario, indicating low sensitivity. Figure 5: Contour Plot for different types of metrics. (a) Sensitivity Analysis for Balance Metric Evaluation. (b) Sensitivity Analysis for EnergyFocused Metric Evaluation. (c) Sensitivity Analysis for TimeFocused Metric Evaluation. Figure 6: Results of Sensitivity Analysis for different types of metrics. 5.3 Robustness Test We evaluated the method robustness by testing under different workload intensities (λ) as visualized in Figure 7. Dynamic Scaling under Load The results confirm that the optimizer performs autonomous scaling strategies aligned with the workload pressure: Idle State (λ = 0.5): Under light load conditions, the Sensitivity Analysis (Figure 7a) identifies count_big as the overwhelmingly dominant factor (Importance 0.5). This high sensitivity confirms that the optimizer correctly learns strict constraint: Big Cores must be deactivated to minimize static power. Consequently, the system converges to minimal configuration dependent on Little Cores, maximizing energy efficiency while maintaining acceptable latency. Full Scale-Out (λ = 2.5): This represents the systems optimal operating point. Facing high workload pressure, the Bayesian Optimizer fully activates the heterogeneous resources (4 Little, 4 Medium, 4 Big). As shown in Figure 7b, the focus shifts to freq_medium_ghz, indicating that once all cores are active, the optimizer fine-tunes the frequency of the most power-efficient clusters to balance the latency-energy trade-off. Throughput Saturation (λ = 5.0): Under extreme overload, the optimizer reverts to minimal configuration dominated by Little Cores (Figure 7c). While initially counter-intuitive, this behaviour is mathematically optimal response to the logarithmic loss function. As queuing ln delays grow exponentially, the gradient of the latency term vanishes (limT 0). Recognizing that performance targets are physically unattainable, the optimizer adopts \"damage control\" strategy: it minimizes the energy penalty (ln E) by throttling resources. 10 (a) Sensitivity Analysis for λ = 0.5. (b) Sensitivity Analysis for λ = 2.5. (c) Sensitivity Analysis for λ = 5.0. Figure 7: Results of Sensitivity Analysis for different lambda rates. 5.4 Multi-Objective Optimization In this final experiment, we treat Energy and Time as conflicting objectives to approximate the Pareto Frontier. To provide clear visualization of the trade-off surface, outliers with extreme penalties were filtered from the scatter plot. (a) Pareto Frontier Visualization. (b) Divergent Hyperparameter Importance. Figure 8: Multi-Objective Optimization Results. (a) The scatter plot reveals the convex trade-off curve, where the \"frontier\" of non-dominated solutions represents the optimal compromise. (b) The importance analysis confirms the structural conflict: Objective 0 (Energy, blue) relies on Medium frequency and Little core count, while Objective 1 (Time, orange) is dominated by Big Core resources. Pareto Analysis The Multi-Objective Optimization results are summarized in Figure 8. Trade-off Discovery (Figure 8a): The scatter plot clearly identifies the convex Pareto Frontier. We observe dense cluster of non-dominated solutions ranging from low-energy/high-latency to high-energy/low-latency regions. The distinct curvature suggests the existence of knee point, representing balanced configuration that avoids the performance extremes of both singleobjective optimizations. Structural Conflict (Figure 8b): The Hyperparameter Importance plot provides the physical explanation for this trade-off. We observe clear divergence in resource sensitivity: The Energy objective (Blue) is primarily driven by freq_medium_ghz and count_little, confirming that efficiency is maximized by tuning the mid-tier and low-power cores. In contrast, the Time objective (Orange) is overwhelmingly dominated by Big Core resources, specifically count_big (Importance 0.37) and freq_big_ghz. This stark separation proves that the MOO algorithm successfully decoupled the conflicting physical requirements of the heterogeneous system."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we reformulated the scheduling parameter tuning of heterogeneous multi-core systems as Bayesian Optimization problem. Beyond demonstrating the algorithmic efficiency of the framework, 11 our extensive sensitivity and multi-objective analyses revealed three critical insights into the physical behaviour of post-Dennard architectures: 1. Non-Smoothness of the Performance Landscape: The superior performance of the Matérn 5/2 kernel over the RBF kernel confirms that the optimization landscape is characterized by sharp performance cliffs rather than smooth gradients. This necessitates the use of roughness-aware surrogate models to handle discrete resource discontinuities. 2. Emergence of \"Race-to-Idle\" and Resource Decoupling: The optimizer autonomously discovered sophisticated control strategies without expert heuristics. Specifically, it validated the \"Race-to-Idle\" theory in energy-constrained scenarios (activating high-frequency big cores to minimize leakage) and demonstrated structural decoupling where latency optimization is governed by big cores while energy efficiency is managed by little cores. 3. Phase Transition under Saturation: Our robustness tests identified distinct phase transition in the optimal strategy. While resource scaling is effective in the linear workload region (λ 2.5), the system shifts to \"penalty mitigation\" mode under saturation (λ = 5.0), minimizing energy consumption when throughput limits render latency optimization impossible. Future Work Although this study successfully demonstrates the efficacy of Bayesian Optimization for offline parameter tuning, several avenues remain for extending the frameworks applicability to dynamic, real-world environments. First, future research will focus on transitioning from static offline configuration to online run-time adaptation. By integrating lightweight surrogate models, such as Contextual Bandits, the system could dynamically adjust voltage and frequency (DVFS) settings in response to real-time traffic bursts, rather than relying on fixed schedule. Additionally, we aim to relax the assumption of independent tasks by incorporating task dependency models, specifically Directed Acyclic Graphs (DAGs). Handling inter-task dependencies introduces additional challenges regarding communication overhead and pipeline stalling, which are critical for complex embedded applications like video processing."
        },
        {
            "title": "References",
            "content": "[1] Robert Dennard, Fritz Gaensslen, Hwa-Nien Yu, Leo Rideout, Ernest Bassous, and Andre LeBlanc. Design of ion-implanted mosfets with very small physical dimensions. IEEE Journal of solid-state circuits, 9(5):256268, 2003. [2] Maziyar Khadivi, Todd Charter, Marjan Yaghoubi, Masoud Jalayer, Maryam Ahang, Ardeshir Shojaeinasab, and Homayoun Najjaran. Deep reinforcement learning for machine scheduling: Methodology, the state-of-the-art, and future directions. Computers & Industrial Engineering, 200:110856, 2025. [3] Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang. CherryPick: Adaptively unearthing the best cloud configurations for big data analytics. In 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17), pages 469482, 2017. [4] Dana Van Aken, Andrew Pavlo, Geoffrey Gordon, and Bohan Zhang. Automatic database management system tuning through large-scale machine learning. In Proceedings of the 2017 ACM international conference on management of data, pages 10091024, 2017. [5] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2005. [6] Jeremy E. Oakley and Anthony OHagan. Probabilistic sensitivity analysis of complex models: bayesian approach. Journal of the Royal Statistical Society: Series (Statistical Methodology), 66(3):751769, 2004. [7] Miguel González-Rodríguez, Lorena Otero-Cerdeira, Encarnación González-Rufino, and Francisco Javier Rodríguez-Martínez. Study and evaluation of CPU scheduling algorithms. Heliyon, 10(9):e29959, 2024. [8] Arm Holdings. big.LITTLE: Balancing Power Efficiency and Performance. https://www. arm.com/technologies/big-little. [9] Azalia Mirhoseini, Hieu Pham, Quoc Le, Benoit Steiner, Rasmus Larsen, Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, and Jeff Dean. Device placement optimization with reinforcement learning. In International conference on machine learning, pages 24302439. PMLR, 2017. [10] Jasper Snoek, Hugo Larochelle, and Ryan Adams. Practical bayesian optimization of machine learning algorithms. Advances in neural information processing systems, 25, 2012. [11] Valentin Dalibard, Michael Schaarschmidt, and Eiko Yoneki. Boat: Building auto-tuners with structured bayesian optimization. In Proceedings of the 26th International Conference on World Wide Web, pages 479488, 2017. [12] Junru Shao, Xiyou Zhou, Siyuan Feng, Bohan Hou, Ruihang Lai, Hongyi Jin, Wuwei Lin, Masahiro Masuda, Cody Hao Yu, and Tianqi Chen. Tensor program optimization with probabilistic programs. Advances in Neural Information Processing Systems, 35:3578335796, 2022. [13] Ontje Lünsdorf and Stefan Scherfke. SimPy: Discrete-Event Simulation for Python, 20022024. https://simpy.readthedocs.io/. [14] Karel De Vogeleer, Gerard Memmi, Pierre Jouvelot, and Fabien Coelho. The energy/frequency convexity rule: Modeling and experimental validation on mobile devices. In International Conference on Parallel Processing and Applied Mathematics, pages 793803. Springer, 2013. https://minesparis-psl.hal.science/hal-00919414v1. [15] Marc G. Genton. Classes of kernels for machine learning: statistics perspective. J. Mach. Learn. Res., 2:299312, March 2002. [16] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. Taking the human out of the loop: review of bayesian optimization. Proceedings of the IEEE, 104(1):148175, 2016. 13 [17] Sebastian Ament, Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy. Unexpected improvements to expected improvement for bayesian optimization. Advances in Neural Information Processing Systems, 36:2057720612, 2023. [18] James Wilson, Frank Hutter, and Marc Deisenroth. Maximizing acquisition functions for bayesian optimization. Advances in neural information processing systems, 31, 2018. [19] Kalyanmoy Deb. Multi-objective optimisation using evolutionary algorithms: an introduction. In Multi-objective evolutionary optimisation for product design and manufacturing, pages 334. Springer, 2011. [20] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. Differentiable expected hypervolume improvement for parallel multi-objective bayesian optimization. Advances in neural information processing systems, 33:98519864, 2020. [21] Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pages 26232631, 2019. [22] Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew Wilson, and Eytan Bakshy. Botorch: framework for efficient monte-carlo bayesian optimization. Advances in neural information processing systems, 33:2152421538, 2020."
        },
        {
            "title": "A Details and additional results",
            "content": "(a) Optimization History for Balance Metric Evaluation. (b) Optimization History for EnergyFocused Metric Evaluation. (c) Optimization History for TimeFocused Metric Evaluation. Figure 9: Results of Bayesian Optimization history for different types of metrics. (a) Optimization History for λ = 0.5. (b) Optimization History for λ = 2.5. (c) Optimization History for λ = 5.0. Figure 10: Results of Bayesian Optimization history for different lambda rates."
        },
        {
            "title": "B Proposal",
            "content": "Main goals. We use ML to learn knowledge regarding how CPU scheduling affects the efficiencyenergy trade-off. Specifically, it covers the following aspects, - Which aspects of scheduling behaviour (e.g., pre-emption frequency, load balance, task affinity) most influence efficiency and energy use. - How tuneable conventional scheduling or hybrid algorithms (e.g., priority-based, load-balancing, or DVFS-aware) can optimise throughput, latency, and power consumption; - How ML can learn knowledge and thus provide insights into scheduling decisions, e.g. enhancing traditional heuristics by learning parameters, predicting workloads, or guiding real-time decisions."
        },
        {
            "title": "C Author contributions",
            "content": "Both authors jointly discussed and researched relevant prior work, assisted each other with debugging, and participated in reviewing and improving the overall codebase. Personal contribution. Zheyuan (zh369) Implemented SimPy simulation frameworks for scheduling algorithms, including, First-Come, First-Served (FCFS), Time-sliced / quantum based, Round Robin (RR), Priority-based scheduling. Designed and implemented the task models used in the project. Implemented detailed logging of scheduler behavior, tracking task attributes, task assignments, core energy consumption, latency, fairness and throughput. Researched the related metrics with underlying theory, e.g. active or idle power consumption w.r.t. frequency. Implemented per-run evaluation of energy consumption and performance metrics. 15 Contributed to overall system design discussions, including the optimization component among, Gaussian Processes (GP), different kernel choices, Bayesian Optimization (BO), Sensitivity Analysis. Authored the Abstract, Related work, Simulation sections of the paper, including the underlying motivations, theories and practical design choices. Refined the Introduction section for our experimental settings. Contributed to overall paper editing, including figures, tables, and result interpretation. Yifei (ys690) Implemented the optimization component from simulator outputs of latency, throughput, fairness, and energy. Researched, designed overall methodologies, including, Gaussian Processes (GP), different kernel choices, Bayesian Optimization (BO), Sensitivity Analysis. Contributed to the scheduling simulators, including, First-In, First-Out (FIFO), Time quantum (or slice) based, Round Robin (RR), Priority-based scheduling. Designed and contributed to the task models used in the project, e.g. modelling tasks as Poisson process. Design modular experiment codebase to support flexible settings for Bayesian Optimization controlled by .yaml files. Override native interface of optuna library to support the replacement of kernels. Authored the Introduction, Emulation, Discussion sections of the paper. Refined the other sections. Contributed to overall paper editing, including figures, tables, and result interpretation. Acknowledgement. We sincerely appreciate Professor Carl Henrik Ek for organizing the exciting module L48 Machine Learning and the Physical World at Department of Computer Science and Technology, University of Cambridge and providing consistent feedback regarding this project during the proposal and viva phase."
        }
    ],
    "affiliations": [
        "Department of Computer Science and Technology, University of Cambridge"
    ]
}