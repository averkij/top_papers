{
    "paper_title": "AITEE -- Agentic Tutor for Electrical Engineering",
    "authors": [
        "Christopher Knievel",
        "Alexander Bernhardt",
        "Christian Bernhardt"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Intelligent tutoring systems combined with large language models offer a promising approach to address students' diverse needs and promote self-efficacious learning. While large language models possess good foundational knowledge of electrical engineering basics, they remain insufficiently capable of addressing specific questions about electrical circuits. In this paper, we present AITEE, an agent-based tutoring system for electrical engineering designed to accompany students throughout their learning process, offer individualized support, and promote self-directed learning. AITEE supports both hand-drawn and digital circuits through an adapted circuit reconstruction process, enabling natural interaction with students. Our novel graph-based similarity measure identifies relevant context from lecture materials through a retrieval augmented generation approach, while parallel Spice simulation further enhances accuracy in applying solution methodologies. The system implements a Socratic dialogue to foster learner autonomy through guided questioning. Experimental evaluations demonstrate that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, with even medium-sized LLM models showing acceptable performance. Our results highlight the potential of agentic tutors to deliver scalable, personalized, and effective learning environments for electrical engineering education."
        },
        {
            "title": "Start",
            "content": "1 AITEE - Agentic Tutor for Electrical Engineering Christopher Knievel, Alexander Bernhardt, Christian Bernhardt Intelligent tutoring systems combined with large language models offer promising approach to address students diverse needs and promote self-efficacious learning. While large language models possess good foundational knowledge of electrical engineering basics, they remain insufficiently capable of addressing specific questions about electrical circuits. In this paper, we present AITEE, an agent-based tutoring system for electrical engineering designed to accompany students throughout their learning process, offer individualized support, and promote self-directed learning. AITEE supports both hand-drawn and digital circuits through an adapted circuit reconstruction process, enabling natural interaction with students. Our novel graph-based similarity measure identifies relevant context from lecture materials through retrieval augmented generation approach, while parallel Spice simulation further enhances accuracy in applying solution methodologies. The system implements Socratic dialogue to foster learner autonomy through guided questioning. Experimental evaluations demonstrate that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, with even medium-sized LLM models showing acceptable performance. Our results highlight the potential of agentic tutors to deliver scalable, personalized, and effective learning environments for electrical engineering education. Index TermsIntelligent tutoring systems, electrical engineering education, graph neural networks, large language models 5 2 0 M 7 2 ] . [ 1 2 8 5 1 2 . 5 0 5 2 : r I. INTRODUCTION HE field of educational technology has seen remarkable advancements, with the emergence of transformative tools such as Learning Management Systems, Massive Open Online Courses, and Intelligent Tutoring Systems. These technologies have enabled shift towards distance learning models, allowing students to learn at their own pace and providing teachers with the ability to scale up effective teaching practices [1]. However, despite these innovations, many educational technologies do not substantially change the traditional role of teachers. Typical teaching activities, such as providing feedback, motivation, and content adaptation, are still primarily entrusted to human instructors, leading to the teacherbandwidth problem where there is shortage of teaching staff to provide highly informative and competence-oriented feedback at large scale [2]. The advent of ChatGPT, an application based on state-of-the-art GPT language models for natural language processing (NLP) model, has further expanded the potential of Intelligent Tutoring Systems (ITS). Tracing its origins to the pioneering ELIZA chatbot developed in 1966, the capabilities of modern chatbots have become increasingly sophisticated, with the ability to engage in human-like conversations and provide personalized learning experiences [3]. Intelligent Tutoring Systems promise to address the limitations of traditional educational technologies by incorporating computational models to provide individualized learning, formative feedback, and personalized learning paths [4]. Chatbots, as subtype of dialog systems, have emerged as particularly promising approach, with the ability to simulate conversational partners and provide feedback through natural language [1, 5]. Despite their potential, deploying chatbots as Intelligent Tutoring Systems involves several complications. Due to their susceptibility to hallucinations and limited robustness, unsupervised chatbot usage may enable students to extract incorrect solutions from the system, which is particularly problem for weaker students [69]. Additionally, there is risk that C. Knievel, A. Bernhardt and C. Bernhardt are with the Department of Electrical Engineering and Information Technology, HTWG Hochschule Konstanz, University of Applied Sciences, Germany (email: {cknievel,abernhard,cbernhard}@htwg-konstanz.de). students lose their sense of self-efficacy when solving tasks independently due to excessive support and instead develop dependency on the tutor [10, 11]. The application of intelligent tutoring systems to electrical engineering is very limited [12] and is restricted to static knowledge representation, lacking dynamic inference and application of knowledge to solve questions related to electrical circuits. In this paper, we develop an agentic tutor for electrical engineering (AITEE), which provides students with an interactive platform for asking questions about electrical circuits while ensuring reliability and accuracy of information, leveraging domain-specific contextual knowledge, and preventing excessive trust in and dependence on technology. To support students self-efficacy, AITEE employs Socratic dialogue that fosters learner autonomy through systematic questioning, guiding students toward logical conclusions [13, 14]. Furthermore, AITEE has to address the typical challenges faced by first-semester electrical engineering students when analyzing DC circuits, who need to apply both mathematical foundations, such as linear algebra, as well as electrical engineering principles, such as Kirchhoffs laws, to given circuit. This involves identifying and applying the solution approaches discussed in the lecture. An exemplary circuit is shown in Fig. 1, with the task of calculating the current I3 through the ohmic resistance. The challenge for AITEE is to identify the relevant context within the knowledge base given only the image of the circuit and the fragmented question: How do calculate the current I3? as input. We develop deep learning-based approach to detect the Fig. 1: Exemplary electrical circuit with current and voltage source as well as an ohmic resistor. 2 Circuit Scripts Students Detection of components and connections Conversion into Graph/Netlist Simulation with Spice Relevant context in vector database Retriever (RAG) LLM-Instructions Prompt Large Language Model Prompt: Output Fig. 2: Overview of the required components of AITEE. electrical components and their connections. Different representations of the query and the circuits were examined for their suitability for retrieval augmented generation. Due to the poor performance of naive and advanced RAG methods, we adapted the so-called passage retrieval [15] to use representation of electrical circuits as indexes, termed indexcircuits, and thereby identify the relevant passages in the script. In order to find the relevant index-circuit for given querycircuit, similarity measure between the two circuits must be calculated. For this purpose, the circuit is transformed into latent vector representation using graph-neural network, which captures, among other things, the structure of the circuit. similarity measure is calculated based on the cosine distance between the vectors of different circuits. Given the relevant context, several language models, both open-source as well as closed-source were evaluated regarding their understanding of electrical circuits and their ability to correctly solve firstsemester electrical engineering problems. Additionally, the models robustness against erroneous information in multi-turn dialogues with students was investigated. The remainder of this paper is organized as follows: Chapter II introduces the architecture of the agentic system. In chapter. III the identification of the electrical circuit as well as the graph-representation and the subsequent similarity measure are discussed. Four different large language models (LLMs) are evaluated in Chapter IV concerning their capabilities of understanding electrical circuits. Furthermore, the performance of all four LLMs is evaluated with various prompting and retrieval strategies. Finally, chapter concludes the paper. II. SYSTEM ARCHITECTURE Chatbots in education have the potential to increase students motivation to learn and strengthen their self-perception and self-efficacy [5]. For an Intelligent Tutoring System (ITS) in electrical engineering to achieve these goals, it must be able to understand electrical circuits and solve tasks by applying the correct methods. However, AI hallucinations - convincingly formulated but factually incorrect responses - remain an unsolved problem [16]. This is particularly concerning when students receive these false answers, as they often lack the ability to verify their correctness. In order to enhance accessibility and provide seamless learning support, AITEE is designed to process both digitally created as well as hand-drawn circuit diagrams. This capability allows students to interact naturally with the system, whether they are working with computergenerated schematics or sketching circuits during problemsolving sessions. AITEE combines several key technologies: circuit image processing to create netlists (a textual representation of an electrical circuit), graph neural network-based similarity measure for context retrieval, and an LLM supported by Retrieval-Augmented Generation (RAG). Guided by its system prompt, the tutoring agent engages students in Socratic dialogue, promoting active learning and self-efficacy by leading them towards solutions rather than providing immediate answers. To ensure accuracy and prevent hallucinations, SPICE simulation of the circuit is used to provide precise voltage and current values in case specific values are given in the task description. These components work together to create reliable and effective tutoring system. The overall architecture of AITEE is shown in Fig. 2, visualizing the flow of information. III. REPRESENTATION & SIMILARITY OF ELECTRICAL CIRCUITS The transformation of hand-drawn circuit diagrams into machine-readable format begins with the detection of components and their interconnections. While research in electrical circuit recognition is extensive, studies specifically addressing hand-drawn circuits remain limited [1719]. Hand-drawn circuit recognition presents unique challenges, primarily requiring robust detection algorithms that can handle inherent imprecisions in sketches. Notable approaches using YOLO models for component detection have demonstrated promising results, achieving AP0.5 scores of 98.2% and 91.6% respectively [17, 18]. Uzair et al. further refined this approach by developing two-stage detector specifically optimized for smaller component detection [19]. The established method for connection detection in hand-drawn electrical circuits involves multi-step process: first removing identified components from the image, then applying Canny edge detection followed by Hough transformation. The resulting nodes are then grouped using k-means clustering, with cluster centers serving as connection endpoints. While this approach has proven effective for conventional circuits, it faces limitations when applied to educational contexts. In educational settings, circuit layouts often follow specific didactic principles. For instance, ) or delta () circuits may intentionally incorporate star ( diagonal connections or components to emphasize particular circuit characteristics. These pedagogically motivated layouts present unique challenges that existing connection recognition methods cannot easily address. Although the Connected Component Analysis [19, 20] could be potential solutions, it is not well-suited for processing hand-drawn circuits due to its susceptibility to the inherent inaccuracies of the given circuits. Therefore, we have developed novel approach that better serves these educational requirements. The following sections describe the technical components of the circuit analysis system. First, we introduce the netlist as generic circuit representation format and the graph neural network for determining circuit similarities. Next, we present the methods for object detection and node recognition. The final section details the calculation of graph embeddings and the similarity measure. A. Generic Representation In electrical engineering, the circuit provides the context for students question, with explicit references to specific circuit elements. To identify relevant solution methods from lecture materials, AITEE must search for approaches applied to circuits with similar characteristics, as it cannot be expected that all possible circuit variations are comprehensively documented. However, LLMs face challenges in interpreting graphical representations of electrical circuits [21]. Netlists, topology, which provide textual description of circuit offer machine-readable alternative. The netlist of the circuit shown in Fig. 3 is given as an example in Table I. The netlist of circuit contains list of all components and the corresponding nodes they are connected with, i.e. in the given example from N001 to N006. It is important to note that subtle changes in the circuit configuration can significantly alter the solution strategy. For instance, replacing resistor R6 with second voltage source U2 requires the use of, for example, the superposition principle, which is significant change for first-semester student. In the netlist, however, only two characters are changed. measure of similarity between two circuits on the basis of netlists is therefore challenging. Nevertheless, netlist is used as input for the supporting SPICE simulation. more promising solution compared to the netlist representation is given by graph neural networks [2224]. central idea in this paper, is to use the cosine distance between two feature vectors of GNN as measure of similarity between two electrical circuits. Initially, all components listed in the netlist were stored as graph nodes. Additionally, connection nodes appearing more than twice in the netlist were also created as graph nodes, thereby, enabling the representation of parallel structures within the graph. Subsequently, all graph nodes are connected by edges using the connection nodes from the netlist. The result is graph that captures the complete structure of an electrical circuit. Each graph node stores specific features: node type, 3 R1 N003 N006 R2 N002 N001 R3 N004 N002 R4 N006 N004 R5 N005 N002 R6 N005 N005 U1 N001 N003 Fig. 3: Image of circuit with netlist nodes. TABLE I: Netlist of the circuit shown to the left. number of neighbors, and centrality, which serve as node embeddings. The resulting graph of the circuit in Fig. 3 is shown in Fig. 4. For the calculation of graph similarity, the R2 N2 U1 R4 R5 R6 R1 N6 Fig. 4: Graph representation of the exemplary circuit. graph neural network Φ, parameterized by the weights θ, maps each circuit ci into an embedding space of dimensions [25]: fi = Φ (ci; θϕ) where fi Rd is referred to as the feature representation of the circuit ci. The similarity between two circuit representations can be calculated by the cosine similarity [25]: (1) S(fi, fj) = fj fi fj . (2) Cosine similarity provides measure of vector alignment in space. value of 1 means vectors point in identical directions (0 angle). value of 0 indicates perpendicular vectors (90 angle). value of 1 shows vectors pointing in opposite directions (180 angle) [26]. For circuit embeddings, this similarity metric captures structural relationships. Similar circuits have embeddings that point in nearly the same direction in latent space, with cosine similarity approaching 1. As circuits become more dissimilar, their embeddings become increasingly orthogonal, with cosine similarity nearing 0. B. Object Detection & Node Recognition Similarly to [22, 23], we use one-stage YOLO detector to detect all circuit components. Namely, the YOLO-v8 version from Ultralytics [27], which improves the detection of small objects [28]. Due to the lack of public dataset containing electrical circuits with european symbols, the first and second semester students studying electrical engineering at the HTWG Hochschule Konstanz drew 831 resistor circuits comprising linear and parallel circuits, voltage dividers, Wheatstone bridges, and deltaand star-circuits. The selection of circuits is based on the syllabus of electrical engineering 1. The labeled dataset can be accessed here: [29]. In addition to the passive and active two-pole circuits, the identifiers of the two-pole circuits as well as the corner and intersection points in the circuit have also been labeled. Four variants of the YOLOv8 model were trained (nano, small, medium, large) and their runtime and mean average precision were measured at an IoU of 0.5 on Intel i7-4790k CPU. The results are given in Table II. Based Model YOLOv8n YOLOv8s YOLOv8m YOLOv8l Runtime in ms mAP0.5 0.965 0.971 0.971 0.973 120 211 392 632 TABLE II: Precision and runtime results for the YOLOv8based detection. on these results, we chose the YOLOv8s model providing the best trade-off between precision and runtime. The output of the object detection is shown for the example circuit in Fig. 5. Given the detection results, we can subsequently proceed to reconstruct the connections between the detected components. In contrast to previous publications, we also detect the corner and intersection points in circuit. This facilitates simple approach to also detect diagonal connections. The process of the connection recognition is shown in Fig. 6. In first step, all detected components and their identifiers are removed from the image. Then, Nd contour points are created on the remaining connections (see c1 in Fig. 6). In parallel, all corner and intersection points are connected to each other building so-called inter-node connections (see c2 in Fig. 6). The validation of inter-node connections is performed using line-loss metric that quantifies the geometric proximity between candidate connections and actual circuit paths. The lineFig. 5: Output of the object detection for the example circuit with the YOLOv8s model. 4 loss computation consists of two steps: Initially, each internode connection is discretized with Nb,k equidistant interval the Euclidean distance is points (xk,i, yk,i). Subsequently, calculated from each interval point to its nearest circuit contour point. The set of contour points is defined as: Nd = {(xj, yj) R2 = 1, . . . , n}. (3) The line-loss metric for connection is computed as: dk = b,k (cid:88) i=1 (cid:113) min cj Nd (xk,i xj)2 + (yk,i yj) (4) where (xk,i, yk,i) denotes the coordinates of the i-th interval point of connection k, for 1, ..., Nb,k. The term b,k Nb,k accounts for the exclusion of interval points which are located within bounding box of detected component from the line-loss metric. The validation step establishes heuristically determined linear threshold value to differentiate valid from invalid inter-node connections. The result of the analysis is shown next to c3 in Fig. 6 where green lines represent the valid inter-node connections and red lines belong to invalid inter-node connections. The final integration step, indicated by c4 in Fig. 6, compares the bounding boxes of the detected components with the valid inter-node connections. The resulting intersections are used to incorporate the components into the electrical circuit structure. Additionally, each valid inter-node connection corresponds to netlist node. Together with the class of the detected component, this allows both the netlist to be generated and graph-based processing to be enabled. C. Graph Embedding & Similarity Measure After reconstructing an electrical circuit diagram, it becomes necessary to identify its corresponding context within the lecture materials. Electrical engineering fundamentals are typically taught using basic circuit configurations, including series circuits, parallel circuits, and combinations thereof. Students face primary challenge in applying learned principles across different circuit configurations. For AITEE, this presents specific challenge since the input circuit may not exactly match those presented in lecture materials. Therefore, the objective is to identify the most analogous circuit and derive the applicable methodologies. In this paper, we propose to model the electrical circuit as an undirected graph and to use the global graph embeddings to calculate circuit-similarity measure. Due to the application within an educational setting, the similarity between electrical circuits is primarily defined by their shared methodological approaches to problem-solving. Two key characteristics determine the calculation methodology: 1) Circuit Type: This describes the interconnection pattern of components within the electrical circuit. Each circuit type (series, parallel, mixed, and bridge circuits) typically requires specific formulas and procedures for problem-solving. 2) Special Cases: These arise when specific conditions, unusual components, or particular connection types are 5 types (parallel, series, mixed, and bridge circuits) with two source configurations (single and multiple sources). The circuit classifications are summarized in Table III. The computation Circuit Class Single source Multiple sources Parallel Circuit Series Circuit Mixed Circuit Bridge Circuit Class 1 Class 3 Class 5 Class 7 Class 2 Class 4 Class 6 Class 8 TABLE III: The different circuit classes in the GNN classification. of graph embeddings follows the process illustrated in Fig. 7 and is explained in detail in Sec. III-C1. In the evaluation of suitable architectures for the graph neural network (GNN) component, several established approaches were examined: Graph Convolutional Networks (GCNs) [30], Graph Attention Networks (GATs) [31], GraphSAGE [32], and Graph Isomorphism Network (GIN) [33]. The evaluation involved training the different GNNs with 150 netlists from various classes and validating them using 30 netlists. Based on this evaluation, GraphSAGE was chosen showing slightly better performance. 1) Graph Embedding The graph embedding generation integrates two primary inputs: the netlist graph and its associated metadata, processed through distinct pathways as depicted in Fig. 7. The netlist graph encodes component interconnections and their topological relationships, whereas the metadata comprises the amount and type of components. The structural information initializes the GraphSAGE network, generating node embeddings that incorporate both local and global structural characteristics. These node embeddings capture contextual information from their neighborhood, yet inherently provide comprehensive representation of the entire graph structure. To address this limitation, global pooling operation is implemented, aggregating the node embeddings into single they do not Fig. 6: Illustration of the process for recognizing the connection nodes in an electrical circuit. present. Even single connection or component can trigger special case, potentially requiring completely different calculation methodology. The superposition principle is one such special case, used to analyze circuits with multiple independent sources by evaluating each sources effect individually before combining the results. This definition of circuit similarity forms the foundation for developing feature representations that can effectively capture these characteristics for comparison purposes. In order to develop an effective feature representation, we formulate classification problem with eight distinct circuit classes. These classes are derived from combining four basic circuit Fig. 7: Process to calculate normalized graph embeddings using the netlist graph as well as netlist metadata. representative vector. subsequent fully-connected layer with softmax activation function outputs the normalized feature vector fg. The secondary path implements heuristic approach to process netlist metadata. This approach comprises three key components: sigmoid function fc for component quantification, linear combination fs for source type distribution and binary function fb that differentiates between single-source (fb = 0) and multi-source (fb = 1) configurations. The component quantification function fc uses sigmoid form defined as fc = 1 1 + exp (c1 (x c2)) . (5) The sigmoid parameters were calibrated with c1=1 and c2=7.5, establishing normalized range of [0, 1] for circuits containing 1 to 14 components. This range covers the typical complexity found in lecture materials. linear combination quantifies the number and type of sources: fs = 0.33 + 0.66 + 0.01 C, (6) where and are binary indicators (V, {0, 1}) for the presence of voltage and current sources, respectively. Finally, binary function fb indicates whether there is only one source (fb=0) or multiple sources (fb=1) in the three functions circuit. The feature representations of all are consolidated into unified vector fm = [ fc, fs, fb]. To ensure consistent scaling, the elements of fm are normalized, constraining their sum to unity, and stored in m. 2) Similarity Measure The effectiveness of graph embeddings for circuit representation is clearly demonstrated in our experimental results. As shown in Fig. 8, the similarity map based on cosine distances between embeddings across 8 distinct circuit classes (2 circuits per class) reveals strong intra-class relationships. Circuits belonging to the same class exhibit high similarity values, approaching 1, indicating their embeddings point in nearly identical directions within the latent space. Conversely, cross-class comparisons show minimal similarity, suggesting the embeddings become increasingly orthogonal as circuit differences grow. This clear separation validates that the graphbased representation successfully captures the fundamental characteristics that define circuit classes while distinguishing between different topological configurations. IV. LLM-BASED TUTOR IN ELECTRICAL ENGINEERING To ensure the technical accuracy of AITEE, it is essential that the employed LLM is able to correctly interpret given electrical circuit as well as to apply corresponding solution methods. The correct recognition and interpretation of the electrical circuit represented by netlist is therefore crucial. Misinterpretation at this stage can introduce significant errors, potentially compromising the effectiveness of domain-specific electrical engineering knowledge when applied to an inaccurately understood circuit. The following section analyzes the 6 Fig. 8: Cosine Similarity Map of Circuit Embeddings. Heat map showing similarities between circuit embeddings across 8 classes (2 circuits per class). High similarity values (yellow) appear between circuits of the same class, with minimal similarity (black) between different classes, demonstrating the effectiveness of graph embeddings in distinguishing circuit topologies. fundamental capabilities of three open-source and one closedsource LLM in interpreting netlist representations. Subsequent chapters will then evaluate the application of RetrievalAugmented Generation (RAG) approaches for solving electrical circuit tasks. Finally, the robustness of the agent and the effectiveness of Socratic dialogue strategies will be assessed. A. Understanding of Electrical Circuits For the evaluation of the LLMs capabilities to understand electrical circuits, we manually created dataset comprising 24 netlists, with three examples each for the circuit classes defined in Table III, along with their corresponding accurate descriptions. Each model received netlists from the dataset and was tasked with generating circuit descriptions. The initial assessment focused on the baseline performance of LLMs without optimization. To automate the evaluation process, GPT-4.0 was employed as the judge, utilizing the LLM-asa-Judge method described by Zheng et al [34]. For each generated description, the judge was instructed to provide rating from 0 to 4, based on the following scoring scheme: 0 points: The description is completely incorrect. 1 point: The description exhibits numerous errors or fails to capture many aspects of the reference description. 2 points: The description includes limited number of errors or differs from the reference in few aspects. 3 points: The description displays only minor errors or diverges in few aspects from the reference description. 4 points: The description is entirely error-free and logically describes the same circuit as the reference description. corresponding prompt example for the baseline approach is shown in Fig. 9 The baseline accuracy results are presented in the first column of Table IV. Accuracy is quantified as the ratio of the total points achieved to the maximum possible total points. The smallest model, Llama 3.1 8B, demonstrated significant deficit in netlist comprehension, which resulted in the misinterpretation of the majority of circuits within the dataset. The next larger open-source models, Llama 3.1 70B and Llama 3.1 405B, also showed fundamental shortcomings in this area. particular notable weakness was observed in [Human] ### Here is the netlist to be described. Netlist: R_D N004 N005 450Ω R_B N002 N003 270Ω R_C N003 N004 360Ω V7 N001 N005 18V R_A N001 N002 180Ω [System] Your task is to analyze netlist and briefly and concisely describe the circuit. Describe the circuit represented by the netlist, not the netlist itself. Fig. 9: Baseline prompt example for the generation of circuit descriptions for given netlist. the interpretation of electrical nodes. The closed-source model Claude 3.5 Sonnet accurately described simple circuits such as series and parallel configurations. However, it demonstrated limitations with more complex circuits, particularly in the recognition of nodes and parallel branches. Model Accuracy l B 0.25 0.37 0.55 0.74 C 0.28 0.69 0.73 0.8 - S - 2 0.31 0.83 0.82 0.95 - S - 0.5 0.87 0.89 0.95 Llama 3.1 8B Llama 3.1 70B Llama 3.1 405B Claude 3.5 Sonnet t l x o + - S - 0.57 0.89 0.90 0.97 TABLE IV: Accuracy for the correct interpretation and analysis of electrical circuits as function of prompt engineering method by LLM-as-a-Judge. Chain-of-Thought (CoT) prompting [35] was implemented to enhance reasoning capabilities of the models in the analysis, recognition, and interpretation of netlists, which is inherently complex reasoning task. The previously employed baseline prompt provided only brief task description, prompting the LLMs to attempt single-step solution. To address this, the prompt was modified to guide the LLMs to process the task through defined chain of thought. Specifically, the chain begins with identifying the component connections, followed by analyzing the current flow pattern through the circuit. The analysis then proceeds to identify circuit topologies and configurations, examining parts of the circuit which are in series or parallel arrangement, delta/wye connections, or bridge circuits. Only after completing this systematic examination does the process generate comprehensive circuit description. It can be seen from the results in the second column of Table IV that the Llama models 70B and 405B improve significantly while Claude Sonnet 3.5 and especially Llama 3.1 8B only slightly improve. 7 [Human] ### Here is the netlist to be described. Netlist: R_D N004 N005 450Ω R_B N002 N003 270Ω R_C N003 N004 360Ω V7 N001 N005 18V R_A N001 N002 180Ω [System] Your task is to analyze netlist and briefly and concisely describe the circuit it represents. Follow these steps in order: 1. Create description explaining how the components of the circuit are connected. 2. Create description of how the electric current flows through the circuit from the first pole of the source to the second. (This point can be ignored for circuits with multiple sources) 3. Create list of sub-circuits, such as series circuits, parallel circuits, or delta/star connections. 4. Create description of the overall circuit. (Describe the circuit represented by the netlist, not the netlist itself.) Fig. 10: Chain-of-thought prompt example for the generation of circuit descriptions for given netlist. In order to further enhance the performance, few-shot prompting, as described by Brown et al. [36], was evaluated. This technique was implemented with both two and four examples, in conjunction with Chain-of-Thought prompting. These configurations are denoted as 2-Shot-CoT and 4-ShotCoT, respectively, in Table IV. As can be seen from the results, further improvements were achieved for all models. Notable Claude Sonnet 3.5 reached near optimal results of 0.95. Building upon the initial analysis of netlist interpretations, which revealed frequent inaccuracies in the identification of electrical nodes, static contextualization strategy was introduced. This approach incorporates deterministically derived information about the electrical nodes directly into the prompt. Furthermore, guidance on interpreting the netlist structure was also provided within the prompt. The contextualization in combination with 4-Shot-CoT Prompting achieved the best results. It can be seen, that the mid-sized Llama model (70B) achieved almost the same results as the 405B model and performs only slightly worse than the Claude 3.5 Sonnet model. It is important to note that although perfect score was not achieved by any model, the scoring was influenced by GPT-4.0 as the judge, which lowered scores for minor deviations from the reference description. With the exception of Llama 3.1 8B, all models are able to provide sufficiently accurate descriptions of the netlist. 8 Model Llama 3.1 8B Llama 3.1 70B Llama 3.1 405B Claude 3.5 Sonnet + - S - 3 - a 0.15 0.38 0.5 0.73 C - S - 3 0.15 0.57 0.68 0.77 l B 0.15 0.50 0.47 0.69 Accuracy + C - S - 3 + P o F - + C - S - 3 + P D 0.27 0.65 0.65 0. 0.42 0.54 0.62 0.84 + - S - 1 0.39 0.77 0.85 0. + - S - 1 + M 0.42 0.85 0.92 0.96 TABLE V: Accuracy of the LLMs when applying domain-specific knowledge of electrical engineering to electrical circuits. Fig. 11: Accuracy by Circuit Class for the given LLM configurations. Stacked bar histogram detailing the accuracy (y-axis) of Llama 3.1 (8B, 70B, 405B) and Claude 3.5 Sonnet models under various problem-solving strategies. B. Application of Solution Methods to Electrical Circuits In the following, the correct application of solution methods to tasks for given electrical circuits is evaluated. The tasks are limited to the curriculum of the first semester of Fundamentals of Electrical Engineering, in which, among other topics, resistance networks with direct current are examined. One or two tasks for subset of circuit classes from Table III, with several subtasks, are evaluated. In order to make the capabilities of the models in precise statement about relation to the correct application of the methods, the reference description of the netlist is provided for each task. Since none of the models examined, including GPT-4.0, was able to solve the tasks without errors, the solutions of all models were checked manually. The achievable partial points were defined in advance for each subtask to ensure consistent evaluation. 1) Baseline Performance Evaluation The baseline results over all circuit classes are shown in the first column of Table V. Furthermore, the results per circuit class are depicted as stacked bar plot in Fig. 11. Due to their particular importance and widespread use in lecture materials, we have listed tasks on voltage and current dividers for mixed circuits separately, denoted by class 5+. As Fig. 11 illustrates for the Baseline configurations, correct solutions are predominantly concentrated in the simpler Class 1/3 circuits (single source source, series/parallel) and, to lesser extent, Class 5+ (voltage/current dividers). This latter observation supports the notion that tasks on this subclass could be solved significantly better due to their widespread use in training material. The Llama 3.1 70B and 405B models were able to solve many tasks for the simple series and parallel circuits (Class 1/3) and majority of tasks related to current and voltage dividers (Class 5+). However, more complex configurations such as Class 7 and especially Class 6/8 saw minimal to no success across all models at baseline. Furthermore, the baseline performance of the models could not be significantly improved by CoT prompt engineering either. Hereby, the number and order of the examples have been empirically evaluated and set to three examples. The results for the 3-Shot-CoT can be seen in the second column of Table IV and detailed in Fig. 11. Figure 11 confirms that 3-Shot-CoT offered only marginal gains over the baseline approach for most models, with performance still heavily reliant on solving Class 1/3 and Class 5+ circuits. While the Llama 3.1 405B model was able to achieve more noticeable improvement in performance, Fig. 11 reveals this was largely 9 due to an increased proficiency on these same less complex classes, rather than breakthrough in handling more difficult circuit types. By bridging this linguistic gap, HyDE enables more effective retrieval of relevant information despite differences in formulation and terminology. 2) Retrieval-Augmented Generation and its Limitations It is evident that neither the baseline performance nor the performance achieved with the 3-Shot-CoT approach for the language models is sufficient for tutor application, particularly given their challenges with circuits beyond moderate complexity. typical solution to provide the domain-specific knowledge to the LLM is given by Retrieval-Augmented Generation (RAG) [3739]. For AITEE, the lecture content was preprocessed as knowledge base where relevant formulas and calculations were reproduced with LATEX equations. Circuit illustrations were converted to netlists and placed at appropriate locations. The script was then divided into 400token chunks. OpenAIs text-embedding-ada-002-v2 model was used to create the embeddings. To identify semantically relevant content in the vector database, circuit description must be added to the prompt alongside the students question (e.g., How do calculate the current I3). The three most similar chunks are returned and used to contextualize the LLM. The results are denoted by 3-Shot-Cot + Naive RAG. Compared to isolated prompt engineering, the performance actually deteriorated for some models. detailed analysis of the responses revealed that the naive RAG approach introduced an additional source of error. Without RAG, the baseline models relied on their trained knowledge, whereas with RAG, they used the provided chunks for finding solutions. Unsuitable chunks led to poorer responses. However, identifying the relevant chunks is challenging. Simply combining the circuit description and the task formulation is not sufficient to find appropriate chunks. The query must be optimized for the retrieval process. Additionally, some queries relate to multiple sections of the script. For example, when question about mixed circuit is posed and this circuit is simplified during the response process, such as to series circuit, it would be optimal to have chunks with higher abstraction that contain information about both mixed circuits and series circuits. To address these limitations, we evaluated two advanced retrieval approaches. The first approach combines RAPTOR [40] with RAG-Fusion [41]. RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) constructs hierarchical tree of recursively embedded, clustered, and summarized text chunks, enabling retrieval at different levels of abstraction. RAG-Fusion complements this by generating multiple contextual queries and reranking them using reciprocal rank fusion, which helps capture various perspectives of the original query. The second approach pairs RAPTOR with HyDE (Hypothetical Document Embeddings) [42]. which specifically addresses the style mismatch between student queries and the knowledge base. HyDE first uses large language model to generate hypothetical text segment that mimics the style of the lecture script while answering the query. Although this generated text may contain errors, it is not used directly for answering but rather to identify semantically similar chunks in the vector database. This approach is particularly valuable in educational contexts where first-semester students questions often differ significantly from the formal language used in lecture scripts. Although advanced RAG methods improved the performance of the naive RAG approach, as illustrated in Fig. 11, they enabled models to solve greater proportion of Class 5, Class 5+, and begin addressing Class 7 circuits. However, for the Llama models, these methods did not achieve significantly better performance compared to isolated prompt engineering (cf. 3-Shot-CoT performance), especially for the most complex classes. primary limitation was the suboptimal suitability of queries - comprising circuit descriptions and questions - for similarity searches of matching chunks. Only the large closedsource Claude 3.5 Sonnet model achieved sufficient overall performance and, as seen in Fig. 11, broader capability across circuit complexities with advanced RAG methods to suggest tutor-level expertise. 3) Multi-Representation Indexing for Improved Retrieval key consideration for RAG is the chunking strategy. Instead of segmenting content based on fixed number of tokens, the teaching material is structured into clearly defined units. From didactic perspective, unit represents basic building blocks of knowledge in electrical engineering, encompassing declarative knowledge (definitions, facts), procedural knowledge (application methods, problem-solving strategies), and conceptual knowledge (understanding of interrelationships and principles). Thus, supplementing the prompt with the most relevant unit is anticipated to enhance the performance of the LLM. To address the query suitability issue, multi-representation indexing (MRI) was implemented. Chen et al. [15] introduced MRI, advocating for indexing corpus using propositions concise, self-contained factoids as retrieval units. In contrast to this proposition-based approach, our implementation of MRI utilizes representative netlists as indices for units. For each unit, typical electrical circuits are generated, and their corresponding netlists serve as indices for that unit. When prompt includes circuit, the GNN-based similarity measure, detailed in Section III-C, identifies the representative netlists most similar to the given circuit. The units associated with these similar netlists are then retrieved and provided to the LLM in combination with single CoT example. The performance results of this approach, termed 1-Shot-CoT+MRI, are presented in Table and Figure 11. The implemented system demonstrates significant performance improvement compared to previously evaluated approaches. As shown in Fig. 11, the 1-Shot-CoT+MRI approach led to substantial increase in accuracy, particularly enabling models to successfully address more complex circuit classes. With the exception of the Llama 3.1 8B model, all other models exhibit performance level that suggests the potential to ensure tutor-level expertise. Notably, Llama 3.1 70B and 405B, and especially the Claude 3.5 Sonnet model, showed significant capability in solving Class 7 and even the challenging Class6/8 problems, which were largely unsolvable with previous methods. The Claude 3.5 Sonnet model achieves near-flawless performance on the tasks within the dataset. Consistent with findings reported by Chen et al. [43], our analysis also reveals recurring challenge for all language models in performing basic arithmetic operations. 4) Simulation-Based Arithmetic Validation To address the identified limitations of LLMs in arithmetic operations, the system was augmented with simulation execution capability. This enhancement incorporates the tool is PySpice [44]. The netlist representation of the circuit provided as input to PySpice, and the simulation generates output parameters including partial voltages, currents, total current, total voltage, and total resistance. The results presented in Table and Figure 11 with 1Shot-CoT+MRI+Sim, indicate near-optimal performance for both the Llama 3.1 405B and Claude 3.5 Sonnet models across most circuit classes. However, for tasks within Classes 6 and 8, which necessitate the application of the superposition principle, some inaccuracies in current calculations were observed. These errors appear to originate from inconsistencies in current direction definitions between the provided netlist and the task query. Specifically, the system may have failed to detect or reconcile cases where the netlists current direction convention deviated from that implied or explicitly stated in the query, resulting in incorrect calculations using the superposition method. C. Evaluation of Didactic Competence main goal of AITEE is to generate didactically valuable the tutor guides students responses. This necessitates that towards solutions, rather than directly presenting them. While comprehensive analysis of the full spectrum of didactic capabilities in LLMs presents significant challenge, this section concentrates on evaluating key aspects of pedagogical effectiveness relevant to tutoring system. Specifically, we focus on two critical dimensions of didactic quality: fostering learner autonomy and dialogue robustness. These two metrics are prioritized as essential indicators of systems ability to provide effective and pedagogically sound guidance. To provide focused and evaluable assessment of didactic quality, we employ the following metrics: Fostering Learner Autonomy: This metric assesses the systems success in promoting independent learning. Recognizing that effective tutoring should guide rather than dictate, we evaluate whether the system avoids directly providing solutions or explicit intermediate steps. Instead, pedagogically sound dialogues are expected to employ counter-questions and guiding prompts to facilitate the learners autonomous progress towards both intermediate and final solutions. Dialogues are considered to fall short in fostering autonomy if the system preempts the learners problem-solving process by directly supplying final answers or critical intermediate results. Dialogue Robustness: This metric specifically measures the systems resilience to potentially inaccurate user input. key characteristic of robust tutoring agent is its ability to maintain consistent and correct understanding, even when confronted with erroneous user statements. For example, robust system should remain unaffected if user mistakenly classifies series circuit as parallel circuit. To specifically examine dialogue robustness, each evaluation dialogue includes simulated instance of such user-provided misinformation. Dialogues are classified as insufficiently robust if the system inappropriately accepts the inaccurate user statement and subsequently adapts its behavior based on this error. In order to ensure focused evaluation, dataset was constructed consisting of electrical circuit descriptions paired with corresponding tasks or questions. Each questioncircuit pair serves as the starting point for dialogue, which is then extended to include five user queries and five system responses. To assess dialog robustness, each conversation includes one intentional insertion of false information (for example, incorrectly labeling parallel circuit as series circuit). This methodology results in five dialogs, each containing five questionanswer exchanges per initial query. Finally, the resulting dialogs were evaluated using the predefined metrics for learner autonomy and dialogue robustness. The results are presented in Table VI. All evaluated models exhibit fundamental behavioral deficiencies in the context of this tutoring application. Specifically, the LLMs consistently generated complete solutions directly, practice that could negatively impact student learning outcomes. Regarding dialogue robustness, the smallest model, Llama 3.1 8B, adopted the users perspective in four out of five dialogues. This behavior was also observed in the other models, albeit less frequently, occurring twice out of five dialogues. In all cases, this level of robustness is deemed insufficient for effective pedagogical application. Model Learner Autonomy i r I l B . 4/5 5/5 5/5 5/5 Dialogue Robustness i r I . 4/5 5/5 5/5 5/5 l B 1/5 3/5 3/5 3/5 Llama 3.1 8B Llama 3.1 70B Llama 3.1 405B Claude 3.5 Sonnet 0/5 0/5 0/5 0/ TABLE VI: Evaluation of fostering the learner autonomy and dialogue robustness for baselines models vs models with instruction prompts. To address these limitations, the system prompt of the LLMs is designed to clearly define the tutors tasks and provide specific guidelines to follow: 1) Socratic Questioning: Ask specific question that stimulates the students critical thinking and lead them step by step to the solution. 2) No direct solutions: Never provide complete or partial solutions. Your role is to enable students to solve problems independently. 3) Promote self-efficacy: Encourage students to think for themselves and apply their knowledge. Dont show the students how to do it, but encourage them to find the solution themselves. 4) Error correction: If students give incorrect answers, gently guide them in the right direction without giving away the correct answer. 5) Technical terms: Use and explain relevant electrical engineering terms to deepen understanding. 6) Language: Answer in German only. 7) Adaptability: Adapt your explanations and questions to the students level of understanding. 8) Positive reinforcement: Reward correct answers and pedagogical soundness. Despite these promising results, certain limitations persist. Arithmetic inaccuracies, particularly in complex circuits requiring superposition, and the need for further enhancement of dialogue robustness are identified as key areas for future work. crucial next step involves conducting comprehensive test with students to evaluate AITEEs effectiveness in real-world educational settings and to gather feedback on its usability and impact on student learning outcomes. progress to increase motivation. 9) Short and specific answers: Always answer the students specific question to enable step-by-step problem solving. To further align the language model with the task, few-shot examples of desired dialogues are provided. As result, all examined language models engage in Socratic dialogue. Neither the closed-source model Claude 3.5 Sonnet nor the opensource models Llama 3.1 405B and 70B provide complete or partial results for the test dialogues. Only the smallest model, Llama 3.1 8B, provided partial results in one of five dialogues. the three largest models examined remain robust and do not adopt the students opinion. They guide the student through the task and provide only the necessary support. The models appropriately decline when students request complete solutions, explaining that providing answers directly is not possible. When faced with incorrect user input, V. CONCLUSIONS This paper introduces AITEE, an agentic tutor designed to address the limitations of traditional educational technologies in electrical engineering education, particularly the teacher bandwidth problem. AITEE integrates Large Language Models within an Intelligent Tutoring System to provide interactive and personalized learning experiences for students analyzing electrical circuits. key feature of AITEE is its ability to process both digital and hand-drawn circuit diagrams, enabling students to interact with the system using either digital tools or hand sketches. The core strength of AITEE lies in its agentic nature, leveraging tools such as circuit reconstruction and Spice simulation, while separately employing Socratic dialogue as its pedagogical approach to foster learner autonomy and self-efficacy by guiding students towards solutions through systematic questioning rather than providing direct answers. Our evaluation focused on netlist interpretation and the application of domain-specific knowledge to engineering tasks for students. Results demonstrate that the proposed graphbased similarity measure effectively retrieves relevant contextual information from lecture materials. Regarding didactic competence, initial evaluations revealed tendency for LLMs to provide direct solutions, which hindered learner autonomy. However, implementing instruction prompts that explicitly guide the LLMs to adopt Socratic questioning techniques significantly improved the systems ability to foster learner autonomy and enhance dialogue quality. While improving dialogue robustness remains an ongoing challenge, the instruction-prompted models demonstrated significant improvement in resisting inaccurate user input while maintaining REFERENCES [1] S. Wollny, J. Schneider, D. Di Mitri, J. Weidlich, M. Rittberger, and H. Drachsler, Are We There Yet? - Systematic Literature Review on Chatbots in Education, Frontiers in Artificial Intelligence, vol. 4, p. 654924, Jul. 2021. [2] D. A. Wiley and E. Edwards, Online self-organizing social systems: The decentralized future of online learning, The Quarterly Review of Distance Education, 2002. [3] L. Labadze, M. Grigolia, and L. Machaidze, Role of ai chatbots in education: systematic literature review, International Journal of Educational Technology in Higher Education, vol. 20, pp. 117, 12 2023. [4] A. C. Graesser, K. VanLehn, C. P. Rose, P. W. Jordan, and D. Harter, Intelligent Tutoring Systems with Conversational Dialogue, AI Magazine, vol. 22, no. 4, pp. 3939, Dec. 2001. [5] R. Winkler and M. Sollner, Unleashing the Potential of Chatbots in Education: State-Of-The-Art Analysis, Academy of Management Proceedings, vol. 2018, p. 15903, Apr. 2018. [6] T. Lehmann, I. Hahnlein, and D. Ifenthaler, Cognitive, metacognitive and motivational perspectives on preflection in self-regulated online learning, Computers in Human Behavior, vol. 32, pp. 313323, Mar. 2014. [7] J. Maynez, S. Narayan, B. Bohnet, and R. McDonald, On Faithfulness and Factuality in Abstractive Summarization, in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, Eds. Online: Association for Computational Linguistics, Jul. 2020, pp. 19061919. [8] J. Quiroga Perez, T. Daradoumis, and J. Puig, Rediscovering the use of chatbots in education: systematic literature review, Computer Applications in Engineering Education, vol. 28, Sep. 2020. [9] D. Marın, Review of the Practical Applications of Pedagogic Conversational Agents to Be Used in School and University Classrooms, Digital, vol. 1, pp. 1833, Jan. 2021. [10] J. B. Wiggins, J. F. Grafsgaard, K. E. Boyer, E. N. Wiebe, and J. C. Lester, Do You Think You Can? The Influence of Student Self-Efficacy on the Effectiveness of Tutorial Dialogue for Computer Science, International Journal of Artificial Intelligence in Education, vol. 27, no. 1, pp. 130153, Mar. 2017. [11] L. E. Margulieux, J. Prather, B. N. Reeves, B. A. Becker, G. Cetin Uzun, D. Loksa, J. Leinonen, and P. Denny, Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems, in Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1, ser. ITiCSE 2024. New York, NY, USA: Association for Computing Machinery, Jul. 2024, pp. 276282. [12] M. Negnevitsky, Application of an intelligent tutoring system in electrical engineering education, in 1996 IEEE International Conference on Multi Media Engineering Education. Conference Proceedings, Jul. 1996, pp. 491497. [13] L. Favero, J. A. Perez-Ortiz, T. Kaser, and N. Oliver, Enhancing Critical Thinking in Education by means of Socratic Chatbot, arXiv preprint arXiv:2409.05511, 2024. [14] L. Zhang, J. Lin, Z. Kuang, S. Xu, and X. Hu, SPL: Socratic Playground for Learning Powered by Large Language Model, arXiv preprint arXiv:2406.13919, Sep. 2024. [15] T. Chen, H. Wang, S. Chen, W. Yu, K. Ma, X. Zhao, H. Zhang, and D. Yu, Dense Retrieval: What Retrieval Granularity Should We Use? arXiv preprint arXiv:2312.06648, 2024. [16] V. Plevris, G. Papazafeiropoulos, and A. Jimenez Rios, Chatbots Put to the Test in Math and Logic Problems: Comparison and Assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard, AI, vol. 4, no. 4, pp. 949969, Dec. 2023. 12 [39] C. Dong, Y. Yuan, K. Chen, S. Cheng, and C. Wen, How to Build an Adaptive AI Tutor for Any Course Using Knowledge GraphEnhanced Retrieval-Augmented Generation (KG-RAG), arXiv preprint arXiv:2311.17696, Feb. 2025. [40] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D. Manning, RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval, in The Twelfth International Conference on Learning Representations, Oct. 2023. [41] Z. Rackauckas, Rag-Fusion: New Take on Retrieval Augmented Generation, International Journal on Natural Language Computing, vol. 13, no. 1, pp. 3747, Feb. 2024. [42] L. Gao, X. Ma, J. Lin, and J. Callan, Precise Zero-Shot Dense Retrieval without Relevance Labels, in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Toronto, Canada: A. Rogers, J. Boyd-Graber, and N. Okazaki, Eds. Association for Computational Linguistics, Jul. 2023, pp. 17621777. [43] C.-C. Chen, H. Takamura, I. Kobayashi, and Y. Miyao, The Impact of Language on Arithmetic Proficiency: Multilingual Investigation with Cross-Agent Checking Computation, in Proceedings of the 2024 the Association for Conference of Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), K. Duh, H. Gomez, and S. Bethard, Eds. Mexico City, Mexico: Association for Computational Linguistics, Jun. 2024, pp. 631 637. the North American Chapter of [44] F. Salvaire, Pyspice, https://pyspice.fabrice-salvaire.fr, 2021. [17] R. R. Reddy and M. R. Panicker, Hand-Drawn Electrical Circuit Recognition using Object Detection and Node Recognition, arXiv preprint arXiv:2106.11559, Nov. 2021. [18] B. Bohara and H. S. Krishnamoorthy, Computer Vision based Framework for Power Converter Identification and Analysis, in 2022 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES), Dec. 2022, pp. 16. [19] W. Uzair, D. Chai, and A. Rassau, ElectroNet: An Enhanced Model for Small-Scale Object Detection in Electrical Schematic Diagrams, preprint Research Square, Jul. 2023. [20] L. He, X. Ren, Q. Gao, X. Zhao, B. Yao, and Y. Chao, The connectedcomponent labeling problem: review of state-of-the-art algorithms, Pattern Recognition, vol. 70, pp. 2543, Oct. 2017. [21] P. S. Meshram, S. Karthikeyan, Bhavya, and S. Bhat, ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual Question Answering? arXiv preprint arXiv:2412.00102, 2024. [22] A. Mirhoseini, A. Goldie, M. Yazgan, J. W. Jiang, E. Songhori, S. Wang, Y.-J. Lee, E. Johnson, O. Pathak, A. Nova, J. Pak, A. Tong, K. Srinivasa, W. Hang, E. Tuncer, Q. V. Le, J. Laudon, R. Ho, R. Carpenter, and J. Dean, graph placement methodology for fast chip design, Nature, vol. 594, no. 7862, pp. 207212, Jun. 2021. [23] A. Said, M. Shabbir, B. Broll, W. Abbas, P. Volgyesi, and X. Koutsoukos, Circuit design completion using graph neural networks, Neural Computing and Applications, vol. 35, no. 16, pp. 12 14512 157, Jun. 2023. [24] Y. Yamakaji, H. Shouno, and K. Fukushima, Circuit2Graph: Circuits With Graph Neural Networks, IEEE Access, vol. 12, pp. 51 81851 827, 2024. [25] D. D. Mohan, B. Jawade, S. Setlur, and V. Govindaraj, Deep Metric Learning for Computer Vision: Brief Overview, arXiv preprint arXiv:2312.10046, Dec. 2023. [26] C. Allen and T. Hospedales, Analogies Explained: Towards Understanding Word Embeddings, arXiv preprint arXiv:1901.09813, May 2019. [27] G. Jocher, J. Qiu, and A. Chaurasia, Ultralytics YOLO, Jan. 2023. [Online]. Available: https://github.com/ultralytics/ultralytics [28] A. Vijayakumar and S. Vairavasundaram, YOLO-based Object Detection Models: Review and its Applications, Multimedia Tools and Applications, vol. 83, no. 35, pp. 83 53583 574, Oct. 2024. [29] C. Knievel, A. Bernhardt, and C. Bernhardt, Circuit-dataset for AITEE - agentic tutor for electrical engineering, 2025. [Online]. Available: https://github.com/CKnievel/aitee-dataset [30] T. N. Kipf and M. Welling, Semi-Supervised Classification with Graph Convolutional Networks, arXiv preprint arXiv:1609.02907, Feb. 2017. [31] P. Veliˇckovic, G. Cucurull, A. Casanova, A. Romero, P. Li`o, and Y. Bengio, Graph Attention Networks, arXiv preprint arXiv:1710.10903, Feb. 2018. [32] W. L. Hamilton, R. Ying, and J. Leskovec, Inductive Representation Learning on Large Graphs, arXiv preprint arXiv:1706.02216, Sep. 2018. [33] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, How Powerful are Graph Neural Networks? arXiv preprint arXiv:1810.00826, Feb. 2019. [34] L. Zheng, W.-L. Chiang, Y. Sheng, S. Zhuang, Z. Wu, Y. Zhuang, Z. Lin, Z. Li, D. Li, E. P. Xing, H. Zhang, J. E. Gonzalez, and I. Stoica, Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, arXiv preprint arXiv:2306.05685, Dec. 2023. [35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le, and D. Zhou, Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, arXiv preprint arXiv:2201.11903, Jan. 2023. [36] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. HerbertVoss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, Language Models are Few-Shot Learners, in Advances in Neural Information Processing Systems, vol. 33. Curran Associates, Inc., 2020, pp. 18771901. [37] J. J. Slade, A. Hyk, and R. A. R. Gurung, Transforming Learning: Assessing the Efficacy of Retrieval-Augmented Generation System as Tutor for Introductory Psychology, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 68, no. 1, pp. 18271830, Sep. 2024. [38] E. Mullins, A. Portillo, K. Ruiz Rohena, and A. Piplai, Enhancing classroom teaching with LLMs and RAG, in Proceedings of the 25th Annual Conference on Information Technology Education, ser. SIGITE 24. New York, NY, USA: Association for Computing Machinery, Dec. 2024, pp. 145146."
        }
    ],
    "affiliations": [
        "Department of Electrical Engineering and Information Technology, HTWG Hochschule Konstanz, University of Applied Sciences, Germany"
    ]
}