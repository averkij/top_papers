{
    "paper_title": "MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search",
    "authors": [
        "Zonglin Yang",
        "Wanhao Liu",
        "Ben Gao",
        "Yujie Liu",
        "Wei Li",
        "Tong Xie",
        "Lidong Bing",
        "Wanli Ouyang",
        "Erik Cambria",
        "Dongzhan Zhou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have shown promise in automating scientific hypothesis generation, yet existing approaches primarily yield coarse-grained hypotheses lacking critical methodological and experimental details. We introduce and formally define the novel task of fine-grained scientific hypothesis discovery, which entails generating detailed, experimentally actionable hypotheses from coarse initial research directions. We frame this as a combinatorial optimization problem and investigate the upper limits of LLMs' capacity to solve it when maximally leveraged. Specifically, we explore four foundational questions: (1) how to best harness an LLM's internal heuristics to formulate the fine-grained hypothesis it itself would judge as the most promising among all the possible hypotheses it might generate, based on its own internal scoring-thus defining a latent reward landscape over the hypothesis space; (2) whether such LLM-judged better hypotheses exhibit stronger alignment with ground-truth hypotheses; (3) whether shaping the reward landscape using an ensemble of diverse LLMs of similar capacity yields better outcomes than defining it with repeated instances of the strongest LLM among them; and (4) whether an ensemble of identical LLMs provides a more reliable reward landscape than a single LLM. To address these questions, we propose a hierarchical search method that incrementally proposes and integrates details into the hypothesis, progressing from general concepts to specific experimental configurations. We show that this hierarchical process smooths the reward landscape and enables more effective optimization. Empirical evaluations on a new benchmark of expert-annotated fine-grained hypotheses from recent chemistry literature show that our method consistently outperforms strong baselines."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 2 ] . [ 1 9 0 2 9 1 . 5 0 5 2 : r MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search Zonglin Yang1,2, Wanhao Liu3,2, Ben Gao4,2, Yujie Liu2, Wei Li5, Tong Xie6, Lidong Bing7, Wanli Ouyang2, Erik Cambria1, Dongzhan Zhou2 1 Nanyang Technological University 2 Shanghai Artificial Intelligence Laboratory 3 University of Science and Technology of China 4 Wuhan University 5 National University of Singapore 6 University of New South Wales 7 MiroMind {zonglin.yang,cambria}@ntu.edu.sg, zhoudongzhan@pjlab.org.cn"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have shown promise in automating scientific hypothesis generation, yet existing approaches primarily yield coarse-grained hypotheses lacking critical methodological and experimental details. We introduce and formally define the novel task of fine-grained scientific hypothesis discovery, which entails generating detailed, experimentally actionable hypotheses from coarse initial research directions. We frame this as combinatorial optimization problem and investigate the upper limits of LLMs capacity to solve it when maximally leveraged. Specifically, we explore four foundational questions: (1) how to best harness an LLMs internal heuristics to formulate the fine-grained hypothesis it itself would judge as the most promising among all the possible hypotheses it might generate, based on its own internal scoring-thus defining latent reward landscape over the hypothesis space; (2) whether such LLM-judged better hypotheses exhibit stronger alignment with ground-truth hypotheses; (3) whether shaping the reward landscape using an ensemble of diverse LLMs of similar capacity yields better outcomes than defining it with repeated instances of the strongest LLM among them; and (4) whether an ensemble of identical LLMs provides more reliable reward landscape than single LLM. To address these questions, we propose hierarchical search method that incrementally proposes and integrates details into the hypothesis, progressing from general concepts to specific experimental configurations. We show that this hierarchical process smooths the reward landscape and enables more effective optimization. Empirical evaluations on new benchmark of expert-annotated fine-grained hypotheses from recent chemistry literature show that our method consistently outperforms strong baselines."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) have increasingly been applied to assist scientific research (Luo et al., 2025; Cambria et al., 2023), with one of the most ambitious applications being the automated discovery of novel and valid scientific hypotheses. However, current methods produce hypotheses that are criticized for being overly coarse, lacking sufficient detail, offering simplistic suggestions, or omitting concrete implementation strategies (Wang et al., 2024; Hu et al., 2024; Si et al., 2024). We present the first systematic investigation into how LLMs can be leveraged to formulate finegrained scientific hypothesesthose enriched not only with major concepts but also with precise Corresponding author. Preprint. Under review. methodological details and clearly specified experimental configurations. For example, coarsegrained hypothesis in chemistry might state, synthesize hierarchical 3D copper, while fine-grained counterpart could elaborate, Copper foils are chemically oxidized by immersion in solution of 0.5 ammonium persulfate and 2 sodium hydroxide for 15 minutes at room temperature, forming pentagonal hierarchical CuO nanostructure. Such fine-grained hypotheses significantly enhance clarity, feasibility, and experimental implementability. Formally, we define the task as generating fine-grained hypothesis given research backgroundcomprising research question and established methodologiesand coarse-grained hypothesis direction. We show that fine-grained scientific hypothesis discovery is combinatorial search problem, as it requires selecting and composing coherent set of concrete details from vast space of plausible optionsmaking it particularly challenging in practice. The difficulty is compounded by the fact that scientific hypothesis discovery is an inherently out-of-domain (OOD) problem: the correctness of hypothesis is fundamentally unknown at the time of formulation. In this work, we focus on the pre-experimental stage of discovery, mirroring how human scientistsprior to empirical testingiteratively search through the hypothesis space using heuristics and domain knowledge to identify the hypothesis they themselves would judge as the most promising among all plausible candidates they could think of during the hypothesis search process. Our goal is to emulate this cognitive search process using LLMs, which increasingly rival human scientists in heuristic reasoning and scientific knowledge understanding. This motivates our central research question (Q1): how to best harness an LLMs internal heuristics to formulate the finegrained hypothesis it itself would judge as the most promising among all possible hypotheses it might generate? We conceptualize hypothesis space where each point along the input dimensions (the x-axis, potentially multidimensional) represents candidate hypothesis, and each point is assigned reward value (on the y-axis) by the LLM based on its internal heuristics. This defines reward landscape over the hypothesis space, with the highest peak corresponding to the hypothesis the LLM internally judges as most promising. Framed this way, Q1 becomes an optimization problem: how can we navigate this landscape to find stronger local optimaor ideally the global optimumthus eliciting the best fine-grained hypothesis the LLM can generate? straightforward baseline is greedy search over the reward landscape. However, its non-convex and complex structure makes naive greedy strategies prone to poor local optima. To address this, we propose hierarchical search framework that explicitly models how finite-capacity reasoning agenthuman or LLMnavigates the hypothesis space. Specifically, it first explores higher-level conceptual spaces and then incrementally refines into more specific detail spaces. This hierarchical approach smooths the reward landscape at each hierarchy levelespecially at higher, more abstract levelsenabling convergence to superior local optima compared to greedy search and greedy search with self-consistency (Wang et al., 2023). The proposed framework inherently scales with the LLMs available capacity, enabling systematic exploration of the limits of LLM-driven fine-grained hypothesis generation. Having investigated how to identify stronger local optima in Q1, we now turn to our second question (Q2): whether hypotheses judged better by LLMs exhibit stronger alignment with ground-truth hypotheses? To rigorously address Q2 while avoiding data contamination, we construct benchmark of research backgrounds paired with expert-annotated fine-grained hypotheses from chemistry papers published after January 2024, ensuring these examples were unseen by our LLM (GPT-4o-mini, October 2023 cutoff). Using this benchmark, we indirectly evaluate Q2 by comparing the recall of hypotheses discovered by our hierarchical approachwhich locates higher LLM-internal local optimawith hypotheses identified by baseline methods. Our results consistently show that hypotheses generated by our method achieve higher recall than those from baselines, providing empirical support for the reliability of the LLMs internal reward signal in guiding fine-grained hypothesis discovery. Until now, the reward landscape guiding hypothesis search has been defined by single LLM serving as the evaluator. We now turn to the third question (Q3): whether defining this landscape with an ensemble of diverse LLMs of similar capacity yields better outcomes than using multiple instances of the strongest LLM within that group. Our experiments show that ensembles composed of repeated instances of the strongest LLM consistently outperform equally sized ensembles of diverse models, suggesting that peak model quality is more important than architectural diversity in this setting. Finally, we consider fourth question (Q4): whether an ensemble of identical LLMs provides more effective reward landscape than single instance of the same model. While Q3 compares ensembles of different models, Q4 isolates the effect of aggregation alone by controlling for model identity. We find that even identical LLMs, when sampled independently and aggregated via summarization, yield reward signal that better captures novelty without sacrificing overall qualityhighlighting subtle but important dimension in optimizing hypothesis discovery. Overall, the contributions of this work are: 1. We introduce and formalize fine-grained scientific hypothesis discovery as combinatorial optimization problem, and release post-2024 chemistry benchmark with expert-annotated fine-grained hypotheses, explicitly designed to prevent data contamination for current LLMs. 2. We systematically investigate this task through four foundational research questions: (Q1) how to best leverage an LLMs internal heuristics for fine-grained hypothesis generation; (Q2) whether LLM-preferred hypotheses align more closely with ground-truth expert hypotheses; (Q3) whether ensembles of diverse LLMs provide better reward landscape compared to repeated use of the strongest single model; and (Q4) whether ensembles of identical LLMs offer better reward landscape than single instance of the same model. 3. We propose hierarchical search method over levels of conceptual abstraction, which smooths the reward landscape and reduces search complexity at each hierarchy level. Empirically, it consistently outperforms strong baselines in both LLM self-evaluation, expert evaluation, and recall against annotated ground-truth hypotheses."
        },
        {
            "title": "2 Methodology",
            "content": "2.1 Background and Task Motivation Yang et al. (2024b) assume that many chemistry hypotheses can be constructed from research background btypically including the research question and/or background surveyand set of inspirations i1, . . . , ik, representing concepts or findings from the literature. It can be formulated as: = (b, i1, . . . , ik) (1) In practice, however, most hypotheses generated from Equation 1 tend to be coarse-grained: while they form cohesive associations between and the i, they often lack clear hypothesis specification and the detailed experimental configurations required for direct implementation in laboratory setting. Additionally, many such hypotheses contain redundant or tangential elementseither due to the inclusion of unnecessary inspirations or from noise present in the literature that is unrelated to the core knowledge intended for hypothesis construction. 2.2 Problem Formulation: Fine-Grained Hypothesis Generation as Combinatorial Search Let hc be coarse-grained hypothesis direction and hf its fine-grained counterpart, defined as: hf = {hc, d1, . . . , dm} (2) Here, {hc, d1, . . . , dm} denotes the meaningful integration of edits d1, . . . , dm into hc, resulting in coherent, fine-grained hypothesis. Each represents either: (1) the addition of fine-grained detail to concept in hc, or (2) the deletion of redundant concept from hc. We define two sets of edit candidates: D+, consisting of all possible fine-grained details that can be added to concepts in hc, and D, consisting of all concepts in hc that may be removed. The full candidate set is defined as = D+ D. Inspired by coarse-to-fine strategies in computer visionwhere coarse image is first generated and then refined with fine-grained details (Tian et al., 2024)we formulate the transition from hc to hf as an additional step building on Equation 1, which provides the initial hc. (hf b, hc) = ({d1, . . . , dm}b, hc, D) (3) 3 This formulation turns (hf b, hc) into combinatorial optimization problem, where the objective is to select subset of edits d1, . . . , dm D. Let = and d1, . . . , dm = m. The search space has at least combinatorial complexity = m!(nm)! . This makes the problem particularly challenging due to three factors: (1) both and are unknown; (2) the candidate set is itself implicit and potentially very large; and (3) the edits di are not independenterrors early in the reasoning chain can propagate and impair later decisions. n! 2.3 Algorithmic Motivation for Hierarchical Heuristic Search (HHS) Fine-grained hypothesis generation is generally intractable due to the exponential growth of the search space, where the candidate set is often large or prohibitively so. notable exception occurs when the problem exhibits an optimal substructurei.e., an optimal solution can be composed from the optimal solutions to its subproblems. This principle underlies dynamic programming, where solutions are built incrementally from smaller subproblems (first try to obtain the optimal solution for smaller subproblem and then iteratively find the optimal solution for larger subproblems). We observe that fine-grained hypothesis generation exhibits an optimal substructure. Specifically, the edits d1, . . . , dm can be organized hierarchically: some address high-level concepts (e.g., functional groups, catalyst classes), while others specify low-level details (e.g., reagents, catalysts, temperature, concentration). We assume these edits can be partitioned into hierarchical levels (p > 1), with higher levels corresponding to finer details. Then the overall problem can be seen as to determine in {1, . . . , p} hierarchies. The subproblem of it can be seen as the determination of in {1, . . . , 1} hierarchies, etc. Then it is obvious that the optimal solution of problem can be derived from the optimal solution of its subproblem, etc. Figure 1: Hierarchies designed for chemistry. Figure 1 illustrates an example hierarchical decomposition for chemistry, developed in collaboration with domain experts (PhD-level chemists). The hierarchy spans from high-level mechanistic intent to low-level experimental configurations, reflecting the granularity typically considered when translating conceptual hypothesis into testable laboratory procedure in chemistry. Now we have simplified the problem of determining in all hierarchies into the iteration of determining in each hierarchy sequentially. Nonetheless, even within single hierarchy, the number of candidates remains combinatorially large. practical approach to this combinatorial complexity is to use heuristics that approximate solutions rather than exhaustively searching for exact ones. This aligns with how chemists refine hypotheses: given that hc often represents an unexplored direction, explicit candidate details are rarely retrievable from existing databases. Instead, chemists often rely on domain knowledge and intuition to heuristically identify and iteratively refine plausible details. Analogously, we propose to leverage LLMs internal heuristics to guide the search for at each hierarchical level. As LLMs advance, their heuristicsemerging from pretraining over extensive scientific corporaincreasingly approximate, and in some cases surpass, those of human experts. By developing methods that maximally exploit these heuristics for fine-grained hypothesis generation, we aim to provide scientists with progressively greater support as LLMs capacities grow. 4 In this setting, the candidate space is not explicitly enumerated but is implicitly embedded within the LLMs internal knowledge and reasoning capabilities. The LLM does not select from predefined list, but rather proposes candidates by navigating this latent, heuristic-driven space. 2.4 Hierarchical Factorization of the Search Problem For formalization, we partition the implicit candidate space into hierarchical levels, where D(i) represents all potential edits at level i, and D(i) D(i) denotes the (unknown) groundtruth edits. The j-th ground-truth edit at level is denoted as d(i) D(i). Since is implicitly determined by hc, we have (D hc) = 1, and explicitly condition on for clarity in the subsequent factorization. Applying the chain rule hierarchically, Equation 3 can be reformulated as: P (hf b, hc) = (cid:16) {D(1), . . . , D(p)} b, hc, (cid:17) = = D(i) b, hc, D(<i), D(i)(cid:17) (cid:16) (cid:89) i=1 (cid:89) D(i) (cid:89) i=1 j=1 (cid:16) d(i) b, hc, D(<i), d(i) <j , D(i)(cid:17) , (4) (5) (6) where D(<i) = {D(1), . . . , D(i1)} and d(i) <j = {d(i) , . . . , d(i) j1}. 1 The key advantage of this hierarchical factorization is that at each level i, the search is restricted to the reduced candidate set D(i) rather than the full space D, significantly narrowing the search space. Moreover, as we will show in 2.6, this hierarchical decomposition smooths the reward landscape at each hierarchy level, facilitating more stable optimization and enabling the discovery of stronger local optima in the hypothesis space. 2.5 LLM-Based Implementation of Hierarchical Heuristic Search Figure 2: Overview of the proposed Hierarchical Heuristic Search (HHS) framework. We implement HHS as an LLM-driven agentic process that directly follows the hierarchical factorization formalized in Equation 6. As shown in Figure 2, at each hierarchy level i, Hi1 represents the accumulated edits from all previous levels, corresponding to D(<i). Within the current level, hprev denotes the partial hypothesis incorporating the edits selected up to step j1, i.e., d(i) <j . The candidate set D(i) is not explicitly enumerated but emerges implicitly from the LLMs internal heuristics, conditioned on the background b, the hypothesis direction hc, and the edits selected so far. Specifically, the search for local optimum hj begins from the initial point hi1, using contextual information from b, hc, and Hi2. For hierarchy level = 1, we set h0 = hc and H0 = , making the hypothesis direction hc the starting point. 5 At each iteration, the Add one at level module prompts an LLM to propose an edit to hprev, producing candidate hcur, which is then refined once for validity, novelty, and specificity. The hcur > hprev module evaluates whether the new hypothesis improves upon the previous one via LLM-based pairwise comparison, serving as an internal gradient signal. This search process continues until no further improvement is observed over consecutive steps (default = 3), at which point the current hypothesis is accepted as local optimum. Each edit may involve either an addition or deletion, allowing the search path to include retrospection and self-correction as needed. Within each hierarchy level, we adapt the design of an evolutionary unit (Yang et al., 2024b) to our task, where the search for the local optimum hi is independently repeated multiple times (set to three in our implementation), yielding distinct local optima h1 . These candidates are then passed to recombination module, which integrates their complementary strengths to interpolate potentially superior local optimum hi within the subspace spanned by h1 , and i , h2 , h2 , h3 . 2.6 Theoretical Analysis: Smoothing Effects of Hierarchical Heuristic Search Figure 3: The smoothing effect of hierarchy on the hypothesis space performance landscape. key observation is that hypothesis candidates performance at higher hierarchy level can be viewed as an aggregated estimateapproximating an average or soft maximumof its lower-level subspace. For instance, when evaluating coarse-grained concept like hierarchical 3D copper, the LLM may implicitly account for diverse fine-grained structural variants, some highly relevant, others ineffective. We hypothesize that the LLMs higher-level assessment aggregates these outcomes, weighting promising variants within the broader distribution to produce an overall estimate of the concepts expected potential. Building on this observation, the hierarchical abstraction smooths the reward landscape at higher levels by attenuating local irregularities in the fine-grained space, as the performance of point at higher level can be interpreted as an approximate aggregation or average of the performance across its corresponding lower-level subspace. This effect is illustrated in Figure 3 (a simplified schematic projection into 1D space). Consequently, direct search over the flat, non-hierarchical space tends to be highly rugged and non-convex, often leading to premature convergence to suboptimal local optima. In contrast, introducing hierarchical structure progressively smooths the landscape, enabling more stable and efficient optimization, particularly at higher levels. 6 This smoothing effect can also be interpreted in the frequency domain as form of low-pass filtering, where high-frequency components of the landscape are attenuated, resulting in spectral cutoff in the spatial frequency domain, as illustrated in Figure 4. Figure 4: Spectrum of the performance landscape over the hypothesis space: hierarchical design as low-pass filter attenuating high-frequency irregularities."
        },
        {
            "title": "3 Experiment: Investigating the Four Fundamental Questions",
            "content": "3.1 Benchmark Construction, LLM Selection, and Baselines To our knowledge, no existing benchmark provides annotated fine-grained scientific hypothesesdetailed enough for direct experimental execution. critical consideration in constructing such benchmark is minimizing data contamination by ensuring the LLM has not been exposed to the annotated data during pretraining. We extend the TOMATO-Chem dataset (Yang et al., 2024b), which contains 51 chemistry papers published and made available online after January 2024 in leading journals such as Nature and Science. Each entry is annotated with research background and coarse-grained hypothesis hc. For this study, two PhD-level chemists further annotated these examples with fine-grained hypotheses hf , providing ground-truth references for evaluation. To rigorously avoid data contamination, all experiments are conducted using GPT-4o-mini, whose pretraining data cutoff is October 2023. We compare HHS against two strong baselines widely used in search tasks: (1) greedy search and (2) greedy search with self-consistency. The latter serves as an ablation of HHS where the hierarchical decomposition is removed, performing the search in single stage with each sampled directly from the full candidate set rather than hierarchy-specific subsets D(i). The self-consistency mechanism is similar to the Recombination module in Figure 2, which interpolate multiple local optima trying to find better one. Greedy search represents further ablation, disabling the Recombination module entirely and following single search trace where the first found local optimum (h1 ) is directly adopted as the output (hi = h1 in Figure 2). 3.2 Q1: How to Best Harness an LLMs Internal Heuristics to Formulate the Fine-Grained Hypothesis It Itself Would Judge as the Most Promising Among All Possible Hypotheses It Might Generate? We frame this question as an optimization problem: Given only coarse-grained hypothesis hc as the starting point, and relying entirely on single LLM, how can we navigate the hypothesis space to approach the global optimum of the performance landscape, as defined by this same LLMs internal heuristics, where each optimization step consists of adding an edit to hc? In this setting, the LLM plays dual role: it serves both as the proposal generator, proposing candidate edits to formulate new hypotheses within the hypothesis space, and as the gradient provider, judging whether the new hypothesis improves upon the current one via its own internal heuristics (e.g., pairwise comparison). While it is inherently infeasible to determine whether found local optimum represents the global optimum, we can empirically compare local optima obtained by different methods within the same performance pairwise evaluation, and therefore check which one is closer to global optimum. 7 As detailed in 2, the hierarchical design of HHS offers two key advantages over flat search strategies: (1) less search space to propose each (from D(i), instead of D), and (2) smoothing the performance landscape progressively in the hypothesis space. Among these, the smoothing effect is particularly critical, as it reduces the risk of early convergence to suboptimal local optima and facilitates progress toward higher peaks in the LLMs internal performance landscape. We compare the local optima discovered by HHS against the two baselines. For each pair of local optima, we conduct both overall evaluations and dimension-specific assessments across four key criteria: effectiveness, novelty, detailedness, and feasibility. In this context, feasibility reflects the practical ease of implementing the proposed hypothesis, encompassing factors such as implementation complexity and the minimization of redundant steps. Hypotheses that are easy to implement and free of redundant components are preferred. We further observe two common trade-offs among these dimensions: (1) between effectiveness and novelty, as highly novel hypotheses often entail greater scientific risk and uncertainty; and (2) between detailedness and feasibility, as increased specificity can introduce procedural complexity or redundancies that diminish experimental feasibility. We also conducted an expert evaluation involving two chemistry PhD students. For each benchmark item, one hypothesis was randomly sampled from each method, and the experts were tasked to rank the three hypotheses. The results from both the LLM-based and expert evaluations on the quality of local optima discovered by each method are presented in Table 1. To mitigate known position bias in LLM-based pairwise comparisonswhere models tend to favor the first option (Li et al., 2024)each pair of local optima was compared six times, with the order of presentation alternated every three times. hypothesis was considered to win if it received more than three votes; tie was recorded if both received exactly three votes. Effectiveness (LLM) Novelty (LLM) Detailedness (LLM) Feasibility (LLM) Overall (LLM) Overall (Expert) Win Tie Lose Win Tie Lose Win Tie Lose 74.51% 18.63% 6.86% 59.31% 24.02% 16.67% 57.84% 22.55% 19.61% HHS v.s. Greedy Search 41.18% 18.63% 40.20% 71.57% 28.43% 0.00% 67.65% 10.78% 21.57% HHS v.s. Greedy Search + Self-consistency 42.16% 8.33% 49.51% 56.37% 43.14% 0.49% 48.53% 18.63% 32.84% Greedy Search + Self-consistency v.s. Greedy Search 48.04% 11.76% 40.20% 29.41% 65.69% 4.90% 51.96% 18.63% 29.41% 73.53% 18.63% 7.84% 53.43% 33.82% 12.75% 54.90% 34.31% 10.78% 76.47% 15.69% 7.84% 74.51% 17.65% 7.84% 62.75% 21.57% 15.69% Table 1: Comparison between HHS and baseline methods across LLM-based and expert evaluations. 3.3 Q2: Whether Hypotheses Judged Better by LLMs Exhibit Stronger Alignment With Ground-Truth Hypotheses? 3.2 shows that HHS consistently discovers superior local optima compared to baseline methods. We further investigate whether these optima exhibit stronger alignment with the ground-truth hypotheses. Soft Recall Hard Recall Greedy Search w/ Self-consistency 16.60% 31.50% 9.90% 17.70% HHS 40.40% 23.00% Given the absence of established metrics for this task, we propose an LLM-based evaluation that quantifies how well discovered hypotheses recall key chemical components of the ground-truth. Each hypothesis is decomposed into components regarding to the research question, and recall is assessed for each ground-truth component on 03 scale, where 0 denotes no recall and 3 denotes an exact match. Table 2: Recall of ground-truth components by discovered hypotheses. We report two metrics: (1) Soft Recall, which counts component as recalled if its score is greater than 0, normalized by the total number of components; (2) Hard Recall, which sums the raw 03 scores and normalizes them by the maximum possible score. As shown in Table 2, the hypotheses discovered by HHS (which are preferred by LLMs, as demonstrated in 3.2) achieve consistently higher recall with the ground-truth hypotheses. 3.4 Q3: Whether Defining the Reward Landscape With an Ensemble of Diverse LLMs of Similar Capacity Yields Better Outcomes Than Using Multiple Instances of the Strongest LLM Within That Group? EF (GT) NV (GT) DT (GT) FS (GT) OV (GT) EF (GM) NV (GM) DT (GM) FS (GM) OV (GM) Mixed committee v.s. GPT-4o-mini committee GPT-4o-mini committee v.s. Gemini-1.5-flash committee Win Tie Lose 14.58% 33.33% 29.17% 33.33% 20.83% 18.75% 41.67% 33.33% 72.92% 20.83% 47.92% 37.50% 37.50% 45.83% 12.50% 18.75% 27.08% 31.25% 14.58% 0.00% 95.83% 58.33% 68.75% 4.17% 12.50% 14.58% 52.08% 16.67% 77.08% 8.33% Gemini-1.5-flash committee v.s. GPT-4o-mini committee Mixed committee v.s. Gemini-1.5-flash committee Win Tie Lose 37.50% 16.67% 41.67% 25.00% 41.67% 47.92% 14.58% 37.50% 25.00% 27.08% 6.25% 79.17% 16.67% 52.08% 31.25% 16.67% 33.33% 12.50% 75.00% 35.42% 68.75% 12.50% 31.25% 14.58% 6.25% 18.75% 64.58% 93.75% 16.67% 0.00% Mixed committee v.s. Gemini-1.5-flash committee Mixed committee v.s. GPT-4o-mini committee 16.67% 37.50% 29.17% 45.83% 10.42% 47.92% 27.08% 50.00% 85.42% 56.25% 22.92% 4.17% 14.58% Win Tie Lose Table 3: EF: Effectiveness, NV: Novelty, DT: Detailedness, FS: Feasibility, OV: Overall. (GT) and (GM) indicate that the pairwise evaluations were conducted by GPT-4o-mini and Gemini-1.5-flash, respectively. 14.58% 29.17% 8.33% 77.08% 70.83% 39.58% 14.58% 31.25% 14.58% 8.33% 64.58% 27.08% 6.25% 93.75% 0.00% 10.42% 41.67% The hypothesis optimization in HHS depends on the hcur > hprev? module (Figure 2), which provides the gradient signal. This raises the question: does diverse ensemble of similarly capable LLMs enhance search performance compared to multiple instances of its strongest model? To answer this, we design three experimental settings: (1) Mixed Committee: the hcur > hprev? module is implemented by an ensemble of three different LLMsGPT-4o-mini (OpenAI, 2024), Gemini-1.5-flash (Georgiev et al., 2024), and Claude-3-haiku (Anthropic, 2024); (2) GPT-4omini Committee: the module is implemented by three instances of GPT-4o-mini; (3) Gemini-1.5flash Committee: the module is implemented by three instances of Gemini-1.5-flash. All three settings use GPT-4o-mini as the proposer module for generating edits at each hierarchy level i. We compare the local optima generated by these setups using LLM-based pairwise comparisons, following the protocol in 3.2, where each pair is evaluated six times to mitigate position bias. However, since the evaluator is itself an LLM, an additional bias may occurfavoring optima discovered using gradients from the same model. To control for this, we conduct two sets of evaluations: one using GPT-4o-mini as the evaluator, and the other using Gemini-1.5-flash. As shown in Table 3, across both evaluators, the GPT-4o-mini committee consistently outperforms the mixed committee, which in turn outperforms the Gemini-1.5-flash committee. These results suggest that leveraging repeated instances of the strongest single model provides more effective gradient for hypothesis optimization than combining different models of similar capacity. 3.5 Q4: Do Multiple Identical LLMs Provide Better Reward Landscape Than Single LLM? Effectiveness (LLM) Novelty (LLM) Detailedness (LLM) Feasibility (LLM) Overall (LLM) Win Tie Lose 21.08% 57.35% 21.57% 41.67% 28.92% 29.41% Table 4: Pairwise comparison between HHS-1 and HHS-3. 25.49% 28.92% 45.59% HHS-1 v.s. HHS-3 4.41% 94.12% 1.47% 8.82% 82.35% 8.82% 9 In prior experiments (Tables 1 and 2), the reward landscape was defined using an ensemble of three identical LLMs, followed by fourth instance of the same LLM that aggregated the three judgments into final, reasoned decision. In the experiment corresponding to Table 3, the reward landscape was defined using an ensemble of three diverse LLMs of similar capacity, with aggregation again performed by fixed instance of GPT-4o-mini. However, the extent to which this ensemble-based reward landscape improves performance compared to using single LLM remains unclear. To evaluate this, we compare two variants: HHS-3, which uses an ensemble of three identical instances of GPT-4o-mini to provide the reward signal, and HHS-1, which relies on single instance of the same model. Table 4 reports LLM-based pairwise evaluations between the two setups across four criteria. While overall quality, effectiveness, and detailedness are largely comparable, HHS-3 outperforms in novelty, whereas HHS-1 shows an advantage in feasibility. This result is somewhat counterintuitive. Although both HHS-3 and HHS-1 use the same base LLM, they differ in how the gradient signalthat is, the decision of whether new hypothesis improves upon the current oneis computed. In HHS-3, three independent comparative judgments are sampled using the same LLM, and fourth instance of the same model aggregates these judgments by evaluating the underlying rationales and selecting the most justified preference. Crucially, this summarization step is not simple majority vote. Instead, the LLM is explicitly instructed to assess the relative strength of reasoning across all three perspectives and to favor the most compelling argument. This setup implicitly allows the model to surface and validate minority-supported but well-reasoned views, enabling exploration of more novel or unconventional hypotheses. As result, the aggregated gradient signal in HHS-3 may be more receptive to creative or atypical ideas that would otherwise be dismissed in single-shot comparison. In contrast, HHS-1 relies on only single comparative judgment per step, which reflects narrower and more internally consistent heuristic perspective. This tends to produce more conservative refinementsfavoring feasibility and coherence, but often at the cost of novelty. The observed trade-offgreater novelty in HHS-3 and greater feasibility in HHS-1thus stems not from classical ensemble averaging, but from the summarizing LLMs ability to integrate diverse heuristic signals in principled manner during hypothesis evaluation. Soft Recall Hard Recall HHS-3 HHS-1 40.40% 23.00% 19.90% 32.40% Table 5: Recall of groundtruth components of groundtruth hypotheses between HHS-1 and HHS-3. Table 5 presents the recall of ground-truth components for hypotheses generated by HHS-1 and HHS-3. Across both soft and hard recall metrics, HHS-3 outperforms HHS-1, indicating stronger alignment with expert-annotated reference hypotheses. These results suggest that while the performance gains from ensembling are relatively modest, using multiple identical LLMs to define the reward landscape may yield more reliable and diverse evaluation signal than relying on single instance."
        },
        {
            "title": "4 Related Work",
            "content": "LLM-driven scientific discovery methods typically fall into two categories: (1) direct generation of hypotheses from research backgroundcomprising research question and established methodologies (Qi et al., 2023); or (2) retrieval of seemingly unrelated but potentially useful knowledge fragmentstermed inspirationswhich are then combined with the background to construct hypothesis (Yang et al., 2024a,b; Wang et al., 2024; Liu et al., 2025). While these methods have shown promise in generating novel ideas, they are often criticized for producing hypotheses that are overly coarse, lacking in detail, or omitting actionable experimental steps (Wang et al., 2024; Hu et al., 2024; Si et al., 2024). In contrast, our goal is to investigate how LLMs can be leveraged to generate fine-grained scientific hypothesesthose sufficiently detailed to be directly implemented in 10 laboratory settings. Notably, inspiration-based hypotheses from prior work (Yang et al., 2024a,b) can serve as inputs to our framework in the form of coarse-grained hypothesis directions. These hypotheses emphasize novelty, as they often draw from previously unassociated knowledge, while our work complements them by enhancing experimental specificity and validity."
        },
        {
            "title": "5 Conclusion",
            "content": "We present the first systematic study of fine-grained scientific hypothesis discovery with LLMs, framing it as combinatorial optimization problem. To address the vast, implicit search space, we propose hierarchical heuristic search (HHS), which incrementally refines hypotheses from coarse to fine-grained levels. HHS smooths the reward landscape, stabilizes optimization, and consistently finds higher-quality hypotheses than flat search methods. Experiments show that (1) HHS reliably discovers better local optima than baselines, (2) LLM-preferred hypotheses align more closely with expert ground truths, and (3) repeated use of the strongest model provides better reward landscapes than diverse ensembles. These results underscore the value of hierarchical search in exploring more LLMs potential for scientific discovery."
        },
        {
            "title": "References",
            "content": "Anthropic. The claude 3 model family: Opus, sonnet, haiku. https://www.anthropic.com/ news/claude-3-family, March 2024. Accessed: 2025-05-16. Erik Cambria, Rui Mao, Melvin Chen, Zhaoxia Wang, and Seng-Beng Ho. Seven pillars for the future of artificial intelligence. IEEE Intelligent Systems, 38(6):6269, 2023. Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, Andrea Tacchetti, Colin Gaffney, Samira Daruki, Olcan Sercinoglu, Zach Gleicher, Juliette Love, Paul Voigtlaender, Rohan Jain, Gabriela Surita, Kareem Mohamed, Rory Blevins, Junwhan Ahn, Tao Zhu, Kornraphop Kawintiranon, Orhan Firat, Yiming Gu, Yujing Zhang, Matthew Rahtz, Manaal Faruqui, Natalie Clay, Justin Gilmer, JD Co-Reyes, Ivo Penchev, Rui Zhu, Nobuyuki Morioka, Kevin Hui, Krishna Haridasan, Victor Campos, Mahdis Mahdieh, Mandy Guo, Samer Hassan, Kevin Kilgour, Arpi Vezer, Heng-Tze Cheng, Raoul de Liedekerke, Siddharth Goyal, Paul Barham, DJ Strouse, Seb Noury, Jonas Adler, Mukund Sundararajan, Sharad Vikram, Dmitry Lepikhin, Michela Paganini, Xavier Garcia, Fan Yang, Dasha Valter, Maja Trebacz, Kiran Vodrahalli, Chulayuth Asawaroengchai, Roman Ring, Norbert Kalb, Livio Baldini Soares, Siddhartha Brahma, David Steiner, Tianhe Yu, Fabian Mentzer, Antoine He, Lucas Gonzalez, Bibo Xu, Raphael Lopez Kaufman, Laurent El Shafey, Junhyuk Oh, Tom Hennigan, George van den Driessche, Seth Odoom, Mario Lucic, Becca Roelofs, Sid Lall, Amit Marathe, Betty Chan, Santiago Ontanon, Luheng He, Denis Teplyashin, Jonathan Lai, Phil Crone, Bogdan Damoc, Lewis Ho, Sebastian Riedel, Karel Lenc, Chih-Kuan Yeh, Aakanksha Chowdhery, Yang Xu, Mehran Kazemi, Ehsan Amid, Anastasia Petrushkina, Kevin Swersky, Ali Khodaei, Gowoon Chen, Chris Larkin, Mario Pinto, Geng Yan, Adria Puigdomenech Badia, Piyush Patil, Steven Hansen, Dave Orr, Sebastien M. R. Arnold, Jordan Grimstad, Andrew Dai, Sholto Douglas, Rishika Sinha, Vikas Yadav, Xi Chen, Elena Gribovskaya, Jacob Austin, Jeffrey Zhao, Kaushal Patel, Paul Komarek, Sophia Austin, Sebastian Borgeaud, Linda Friso, Abhimanyu Goyal, Ben Caine, Kris Cao, Da-Woon Chung, Matthew Lamm, Gabe Barth-Maron, Thais Kagohara, Kate Olszewska, Mia Chen, Kaushik Shivakumar, Rishabh Agarwal, Harshal Godhia, Ravi Rajwar, Javier Snaider, Xerxes Dotiwalla, Yuan Liu, Aditya Barua, Victor Ungureanu, Yuan Zhang, Bat-Orgil Batsaikhan, Mateo Wirth, James Qin, Ivo Danihelka, Tulsee Doshi, Martin Chadwick, Jilin Chen, Sanil Jain, Quoc Le, Arjun Kar, Madhu Gurumurthy, Cheng Li, Ruoxin Sang, Fangyu Liu, Lampros Lamprou, Rich Munoz, Nathan Lintz, Harsh Mehta, Heidi Howard, Malcolm Reynolds, Lora Aroyo, Quan Wang, Lorenzo Blanco, Albin Cassirer, Jordan Griffith, Dipanjan Das, Stephan Lee, Jakub Sygnowski, Zach Fisher, James Besley, Richard Powell, Zafarali Ahmed, Dominik Paulus, David Reitter, Zalan Borsos, Rishabh Joshi, Aedan Pope, Steven Hand, Vittorio Selo, Vihan Jain, Nikhil Sethi, Megha Goel, Takaki Makino, Rhys May, Zhen Yang, Johan Schalkwyk, Christina Butterfield, Anja Hauth, Alex Goldin, Will Hawkins, Evan Senter, Sergey Brin, Oliver Woodman, Marvin Ritter, Eric Noland, Minh Giang, Vijay Bolina, Lisa Lee, Tim Blyth, Ian Mackinnon, Machel Reid, Obaid Sarvana, David Silver, Alexander Chen, Lily Wang, Loren Maggiore, Oscar Chang, Nithya Attaluri, Gregory Thornton, Chung-Cheng Chiu, Oskar Bunyan, Nir Levine, Timothy Chung, Evgenii Eltyshev, Xiance Si, Timothy Lillicrap, Demetra Brady, Vaibhav Aggarwal, Boxi Wu, Yuanzhong Xu, Ross McIlroy, Kartikeya Badola, Paramjit Sandhu, Erica Moreira, Wojciech Stokowiec, Ross Hemsley, Dong Li, Alex Tudor, Pranav Shyam, Elahe Rahimtoroghi, Salem Haykal, Pablo Sprechmann, Xiang Zhou, Diana Mincu, Yujia Li, Ravi Addanki, Kalpesh Krishna, Xiao Wu, Alexandre Frechette, Matan Eyal, Allan Dafoe, Dave Lacey, Jay Whang, Thi Avrahami, Ye Zhang, Emanuel Taropa, Hanzhao Lin, Daniel Toyama, Eliza Rutherford, Motoki Sano, HyunJeong Choe, Alex Tomala, Chalence Safranek-Shrader, Nora Kassner, Mantas Pajarskas, Matt Harvey, Sean Sechrist, Meire Fortunato, Christina Lyu, Gamaleldin Elsayed, Chenkai Kuang, James Lottes, Eric Chu, Chao Jia, Chih-Wei Chen, Peter Humphreys, Kate Baumli, Connie Tao, Rajkumar Samuel, Cicero Nogueira dos Santos, Anders Andreassen, Nemanja Rakicevic, Dominik Grewe, Aviral Kumar, Stephanie Winkler, Jonathan Caton, Andrew Brock, Hannah Sheahan, Iain Barr, Yingjie Miao, Paul Natsev, Jacob Devlin, Feryal Behbahani, Flavien Prost, Yanhua Sun, Artiom Myaskovsky, Thanumalayan Sankaranarayana Pillai, Dan Hurt, Angeliki Lazaridou, Xi Xiong, Ce Zheng, Fabio Pardo, Xiaowei Li, Dan Horgan, Joe Stanton, Moran Ambar, Fei Xia, Alejandro Lince, Mingqiu Wang, Basil Mustafa, Albert Webson, Hyo Lee, Rohan Anil, Martin Wicke, Timothy Dozat, Abhishek Sinha, Enrique Piqueras, Elahe Dabir, Shyam Upadhyay, Anudhyan Boral, Lisa Anne Hendricks, Corey Fry, Josip Djolonga, Yi Su, Jake Walker, Jane Labanowski, Ronny Huang, Vedant Misra, Jeremy Chen, RJ Skerry-Ryan, Avi Singh, Shruti Rijhwani, Dian Yu, Alex Castro-Ros, Beer Changpinyo, Romina Datta, Sumit Bagri, Arnar Mar Hrafnkelsson, Marcello Maggioni, Daniel Zheng, Yury Sulsky, Shaobo Hou, Tom Le Paine, Antoine Yang, Jason Riesa, Dominika Rogozinska, Dror Marcus, Dalia El Badawy, Qiao Zhang, Luyu Wang, Helen Miller, Jeremy Greer, Lars Lowe Sjos, Azade Nova, Heiga Zen, Rahma Chaabouni, Mihaela Rosca, Jiepu Jiang, Charlie Chen, Ruibo Liu, Tara Sainath, Maxim Krikun, Alex Polozov, Jean-Baptiste Lespiau, Josh Newlan, Zeynep Cankara, Soo Kwak, Yunhan Xu, Phil Chen, Andy Coenen, Clemens Meyer, Katerina Tsihlas, Ada Ma, Juraj Gottweis, Jinwei Xing, and Gu. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024. URL https://arxiv.org/abs/2403.05530. Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, and Zhenzhong Lan. Nova: An iterative planning and search approach to enhance novelty and diversity of LLM generated ideas. CoRR, abs/2410.14255, 2024. doi: 10.48550/ARXIV.2410. 14255. URL https://doi.org/10.48550/arXiv.2410.14255. Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai Wang, Cuiyun Gao, and Yang Liu. Split and merge: Aligning position biases in llm-based evaluators. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1108411108, 2024. Yujie Liu, Zonglin Yang, Tong Xie, Jinjie Ni, Ben Gao, Yuqiang Li, Shixiang Tang, Wanli Ouyang, Erik Cambria, and Dongzhan Zhou. Researchbench: Benchmarking llms in scientific discovery via inspiration-based task decomposition. arXiv preprint arXiv:2503.21248, 2025. Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, and Xinya Du. Llm4sr: survey on large language models for scientific research. arXiv preprint arXiv:2501.04306, 2025. OpenAI. Gpt-4o mini: Advancing cost-efficient intelligence. https://openai.com/index/ gpt-4o-mini-advancing-cost-efficient-intelligence/, 2024. Accessed: 2025-05-16. Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Zhang-Ren Chen, and Bowen Zhou. Large language models are zero shot hypothesis proposers. CoRR, abs/2311.05965, 2023. doi: 10.48550/ARXIV.2311.05965. URL https://doi.org/10.48550/arXiv.2311.05965. Chenglei Si, Diyi Yang, and Tatsunori Hashimoto. Can llms generate novel research ideas? large-scale human study with 100+ NLP researchers. CoRR, abs/2409.04109, 2024. doi: 10.48550/ ARXIV.2409.04109. URL https://doi.org/10.48550/arXiv.2409.04109. Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang. Visual autoregressive modeling: Scalable image generation via next-scale prediction. CoRR, abs/2404.02905, 2024. doi: 10.48550/ ARXIV.2404.02905. URL https://doi.org/10.48550/arXiv.2404.02905. 12 Qingyun Wang, Doug Downey, Heng Ji, and Tom Hope. Scimon: Scientific inspiration machines optimized for novelty. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pp. 279299. Association for Computational Linguistics, 2024. doi: 10.18653/V1/2024.ACL-LONG.18. URL https://doi.org/10.18653/ v1/2024.acl-long.18. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, 2023. Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, and Erik Cambria. Large language models for automated open-domain scientific hypotheses discovery. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pp. 1354513565. Association for Computational Linguistics, 2024a. doi: 10.18653/V1/2024.FINDINGS-ACL.804. URL https://doi.org/10.18653/v1/2024.findings-acl.804. Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, and Dongzhan Zhou. Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. CoRR, abs/2410.07076, 2024b. doi: 10.48550/ARXIV.2410.07076. URL https://doi.org/10.48550/arXiv.2410.07076."
        },
        {
            "title": "A Expert Evaluation Instructions",
            "content": "For each research question, you will be presented with three candidate hypotheses alongside ground-truth fine-grained hypothesis. The order of the hypotheses is randomized. Your task is to rank the three candidate hypotheses based on their quality, using the ground-truth hypothesis as reference. Please evaluate the hypotheses based on the following four criteria: Effectiveness: How well the hypothesis addresses the research question. Novelty: The degree of originality relative to existing knowledge. Detailedness: The specificity and clarity of the hypothesis. Feasibility: The practical plausibility of experimentally testing or implementing the hypothesis. Note that two tradeoffs may arise: Between effectiveness and novelty Between detailedness and feasibility Use your expert judgment to rank the hypotheses based on holistic assessment of these criteria. In rare cases where two hypotheses appear to be of similar quality, assigning them the same rank is acceptable."
        },
        {
            "title": "B Case Study",
            "content": "Example 1: Research Question: How can cost-effective N-type quasi-solid-state thermocell be developed to boost electricity production from low-grade heat by improving both ion transport efficiency and electrode performance? Hypothesis Candidate (from HHS): The development of cost-effective N-type quasi-solidstate thermocell will be achieved through the strategic integration of three core components to enhance electricity production from low-grade heat (100C): 1. Hierarchical Metal Electrodes: Constructed from copper-nickel alloy (70% Cu, 30% Ni) optimized for conductivity and corrosion resistance, these electrodes will feature dual-layer design incorporating titanium dioxide (TiO2; CAS number: 13463-67-7) coating, precisely controlled at thickness of 100 nm to enhance charge transport by providing stable interface that reduces charge recombination losses. An aluminum oxide (Al2O3; CAS number: 1344-28-1) layer will be included to improve corrosion resistance and reinforce mechanical stability, operating synergistically to enhance the overall electrochemical performance. The fabrication process will utilize an eco-friendly dual-step electrochemical deposition in 0.5 potassium sulfate electrolyte at controlled temperature of 25C, ensuring microand nanoscale porosity targeting 50-100 nm to maximize surface area as supported by literature demonstrating that this range optimally enhances charge transfer and ion migration efficiency. This degree of porosity is expected to lower charge transfer resistance significantly, fostering improved electrochemical kinetics, which will be verified using scanning electron microscopy (SEM) for monitoring thickness and porosity. 2. Metal-Based Redox Couples: The thermocell will utilize copper/copper(I) and nickel/nickel(II) redox couples, selected for their favorable redox potentials to minimize side reactions. An integrated cobalt co-catalyst (0.1 M) will serve as an effective stabilizing agent, enhancing electron transfer kinetics and maintaining the oxidation states of Cu2+ and Ni2+ during thermal cycling, as demonstrated by prior studies indicating its role in fostering electron transfer efficiency. Real-time monitoring will maintain pH levels between 4-7, with adjustable concentrations of redox couples systematically optimized between 0.5 to 1.5 based on insights from the literature regarding their stability and reactivity under varying operational conditions, with specific methodologies for pH adjustments clearly defined to ensure minimal disruption during testing. 3. Anisotropic Polymer Materials: The polymer matrix will feature aligned functional groups (-COOH and -SO3H), which will be developed through controlled mechanical stretching (5 mm/min at 70C), technique known to enhance ionic transport pathways by promoting favorable interactions between the polymer backbone and ionic species. High-conductivity ionic species, specifically Na+ and Li+, will be incorporated at optimized concentrations (0.5 to 1.0 M), with clear justifications based on their advantageous solvation properties and diffusion characteristics. The impact of variations in thermal conditions on ionic conductivity will be quantitatively assessed through impedance spectroscopy, with diffusion coefficients measured to elucidate the mechanisms of ionic mobility, providing detailed connection between thermal gradients and polymer performance. This approach clarifies the synergistic interactions and functional enhancements among hierarchical metal electrodes, optimized redox couples, and engineered polymer materials, establishing cohesive mechanism that uses low-grade heat to drive efficient ion migration and electron transfer within the quasi-solid-state thermocell. Experts Analysis: The study addresses the question of how to develop cost-effective N-type quasi-solid-state thermocell to enhance electricity production from low-grade heat by improving both ion transport efficiency and electrode performance. The response provides detailed and logically structured explanation, covering key aspects related to electrodes, redox pairs, and polymer gel media. Specifically, the preparation of Hierarchical Metal Electrodes is highlighted, noting the primary use of copper-containing electrodes, with clear principle of providing stable interface, which aligns well with the ground truth (gdth) description of 3D hierarchical copper electrodes. Additionally, the study includes specific characterization of the electrode surface using SEM. However, while the polymer gel mentions an anisotropic alignment structure, it omits the specific operational methods for forming this alignment, which is inconsistent with the gdth. Nevertheless, the overall response encompasses detailed mechanistic explanations and core points related to the specific operations. Example 2: Research Question: How can Supramolecular amorphous glass material be engineered to simultaneously exhibit strong mechanical properties, optical transparency, self-healing capabilities, and adhesive strength at room temperature? Hypothesis Candidate (from HHS): The engineering of multifunctional peptide-based supramolecular amorphous glass materials will concentrate on creating robust dynamic network facilitated by cooperative reversible hydrogen bonds derived from interactions among four key amino acids: lysine, glutamic acid, aspartic acid, and tyrosine, along with proline to enhance rigidity. The hypothesized molar ratios will be set at 1:1 for lysine and glutamic acid, complemented by approximately 0.5:0.5 ratios for aspartic acid and tyrosine. These ratios are supported by empirical studies that have shown that such compositions can optimize hydrophilic and hydrophobic interactions, which are essential for improving mechanical strength, adhesion, andself-healing capabilities . Lysines positively charged ammonium group is hypothesized to establish strong ionic interactions with the negatively charged carboxylate groups of glutamic acid and aspartic acid, enhancing the stability of the hydrogen-bonding framework critical for effective energy dissipation during mechanical stress. Tyrosine will contribute to the network through stacking interactions, which are expected to maintain the structural integrity and optical transparency of the material under load. Prolines unique cyclic structure is anticipated to provide localized rigidity, supporting favorable peptide conformations and facilitating effective stress distribution throughout the dynamic network. pivotal component of this dynamic system will be the incorporation of structured water , maintained at an optimal concentration of 1015% by weight. Structured water is theorized to engage in specific hydrogen bonding interactions with the peptide backbone, promoting 15 molecular mobility and enabling rapid bond reformation necessary for self-healing capabilities at room temperature. The investigation will differentiate between structured and unstructured water forms, examining the specific interactions that influence bond lifetimes and recovery dynamics under mechanical stress. Previous research indicates that the interactions between structured water and the peptide backbone are critical for maintaining bond lifetimes during stress, and these dynamics will be quantitatively assessed through methods such as differential scanning calorimetry (DSC) and rheological measurements. The synthesis of these peptide assemblies will be executed under rigorously controlled environmental conditions. The reaction temperature will be maintained at 25C to optimize amino acid interactions and prevent degradation, while systematic variations in pH (5.5 to 8.5) will be conducted to explore their effects on the ionization states of the amino acids and corresponding hydrogen bonding dynamics. Additionally, ionic strength will be regulated at approximately 0.15 using sodium chloride, which is expected to enhance electrostatic interactions and stabilize the hydrogen bonding network. To thoroughly investigate these interactions and material properties, combination of experimental methodologies will be utilized. Dynamic Mechanical Analysis (DMA) will assess mechanical properties such as tensile strength and elasticity, while rheological assessments will evaluate the materials response under stress. Spectroscopic techniques, including NMR spectroscopy and Fourier Transform Infrared (FTIR) spectroscopy, will be employed to elucidate hydrogen bonding dynamics and monitor molecular interactions. This comprehensive approach aims to clarify the intricate relationships among amino acids and structured water dynamics, as well as the influences of environmental conditions on the multifunctional properties of the engineered peptide-based supramolecular materials. Experts Analysis: In addressing the research question\"How can supramolecular amorphous glass material be engineered to simultaneously exhibit strong mechanical properties, optical transparency, self-healing capabilities, and adhesive strength at room temperature?\"the generated scientific hypothesis proposes notably complex system. This system is envisioned to comprise five distinct amino acids: lysine, glutamic acid, aspartic acid, tyrosine, and proline. Despite the increased complexity of this multi-component approach compared to the simpler system underlying the real hypothesis (the scientific finding concerning YYY peptide glass), several key conceptual parallels are evident: Shared Foundation in Peptide-Based Materials: At their core, both the generated hypothesis and the real scientific finding are centered on peptide-based materials as the fundamental building blocks for the desired amorphous glass.Convergent Aim for Dynamic Networks and Functional Properties: Both frameworks leverage their respective peptide systems with the goal of establishing dynamic network. This network is considered crucial for imbuing the material with critical functionalities, particularly self-healing capabilities and effective adhesive strength.Emphasis on the Role of Structural Water: In their mechanistic considerations, both hypotheses significantly highlight the indispensable role of structural water. The real hypothesis (the scientific finding on YYY glass) successfully demonstrated that dense, random hydrogen-bonding network, mediated by water molecules, is fundamental to the YYY glasss unique structure and its observed properties. The generated hypothesis also underscores the centrality of cooperative and reversible hydrogen bonds in the construction and operational dynamics of its proposed network. Example 3: Research Question: How can computational methods be used to accurately predict and improve the reactivity and selectivity of modular diazo transfer (MoDAT) reactions, especially reactions with primary amines? And to design new reagents based on computational models. Hypothesis Candidate 1 (from HHS): We propose to systematically investigate the reactivity and selectivity of modular diazo transfer (MoDAT) reactions utilizing azide-based reagents, with specific focus on para-substituted benzyl azide derivatives modified with strong electron-withdrawing groups (EWGs) such as nitro (NO2) and cyano (CN), as well as weaker electron-withdrawing groups (e.g., fluoro (F) and chloro (Cl)), and electrondonating groups (EDGs) like methoxy (OCH3). Our central hypothesis posits that the electronic nature and precise positioning of these substituents will significantly modulate the 16 electrophilicity of the azide moiety, which will in turn influence the stability and geometrical configurations of intermediates and transition states during nucleophilic attacks by primary amines. The experimental work will be executed under controlled laboratory conditions using Schlenk line to maintain an inert nitrogen atmosphere for at least 30 minutes prior to reaction initiation, minimizing moisture exposure. Reactions will be conducted at temperature of 95105C, chosen based on literature findings indicating optimal kinetic performance while preserving the stability of diazo intermediates. We will employ polar aprotic solvents such as dimethylformamide (DMF) and dimethyl sulfoxide (DMSO), which are anticipated to enhance solvation of the azide and improve nucleophilicity of the primary amines. stoichiometric ratio of 1:1.5 (benzyl halide to sodium azide) will be applied, and reactant concentrations will be maintained at approximately 1020 mM, range supported by preliminary studies demonstrating optimal reactivity and solubility. To deepen our mechanistic understanding, we will utilize advanced computational techniques, primarily Density Functional Theory (DFT) with specific emphasis on the B3LYP functional and 6-31G(d) basis set. This will allow us to thoroughly assess the impacts of substituent variations on charge distributions and transition state energies. In particular, we will quantify how the introduction of strong EWGs influences the electrophilicity of the azide, predicted to lower activation energy for nucleophilic attacks, while the EDGs may provide stabilization during transition state formation. rigorous electronic structure analysis will be employed to visualize the overlap between the nucleophilic orbital of primary amines and the electrophilic centers of the diazo derivatives. To ensure comprehensive evaluation of solvent effects, we will systematically conduct reactions in both polar protic solvents, such as ethanol, and polar aprotic solvents, like DMSO, maintaining concentration of 50% v/v relative to the reaction volume. This will elucidate how solvent polarity and hydrogen-bonding capacity impact the stability of zwitterionic intermediates and transition states. Furthermore, we will establish robust iterative feedback mechanism that directly correlates our computational predictions to empirical data from high-resolution techniques, including NMR spectroscopy and mass spectrometry. Discrepancies exceeding predefined thresholdsuch as 10% difference between predicted and observed yieldswill prompt specific adjustments to our computational models, thus refining our understanding of the factors influencing MoDAT reactions. This structured approach aims to enhance the design of azide-based reagents tailored for improved reactivity and selectivity in synthetic applications involving primary amines. Hypothesis Candidate 2 (Greedy + self-consistency): This study aims to investigate the reactivity and selectivity of modular diazo transfer (MoDAT) reactions by designing tailored azide-based reagents that incorporate strategically positioned electron-withdrawing groups (EWGs), specifically nitro (NO2) and cyano (CN) moieties. These groups will be systematically evaluated at distances of 2 , 4 , and 6  from the azide functionality. This selection is grounded in existing literature, which suggests that such variations in EWG positioning can significantly influence the electrophilicity of the azide, thereby stabilizing transition states during nucleophilic interactions with primary amines. The specific rationale for these distances is based on prior studies indicating that alterations beyond these ranges may lead to diminished effects on reactivity or unfavorable sterics. The primary amines selected for this investigationn-butylamine, phenethylamine, benzylamine, and ethylamineexhibit varying degrees of steric hindrance and electronic characteristics, allowing for comprehensive analysis of their reactivity profiles when paired with engineered azide reagents. This choice effectively captures spectrum of nucleophilic behavior and enhances our understanding of how both electronic and steric factors operate within MoDAT reactions. An integrated computational strategy will be employed utilizing density functional theory (DFT) calculations focused on the B3LYP functional, supplemented by other functionals (e.g., M06-2X and PBE0) to ensure accuracy and validation of outcomes. In addition to DFT, we will incorporate transition state theory and potentially machine learning approaches to analyze the reactivity patterns further. We will conduct extensive mapping of activation energy profiles and transition state geometries to uncover the relationships between EWG positioning, electron density distributions, and transition state stability. Molecular dynamics (MD) simulations will also be utilized to explore solvation effects across differing solvent 17 environments, including acetonitrile, methanol, and DMSO, examining how these solvents influence reaction pathways and stabilize charged intermediates. Empirical validation of computational models will incorporate structured approach to varying critical parameters such as azide reagent concentrations and molar ratios of primary amines to azides, along with solvent compositions, to derive quantitative metrics, including reaction yields, rate constants, and activation energies. Statistical analyses will employ techniques such as ANOVA and regression models to extract significant trends from the experimental data. This iterative feedback mechanism will facilitate dynamic refinement process, whereby experimental outcomes directly inform adjustments to computational predictions. Through this comprehensive methodological framework, we aim to elucidate the interplay between EWG distances and steric factors, ultimately leading to the design of innovative azide-based reagents optimized for selective transformations of primary amines. Hypothesis Candidate 3 (Greedy): This research aims to systematically investigate the reactivity and selectivity of modular diazo transfer (MoDAT) reactions utilizing azide-based reagents, focusing on set of primary amines: benzylamine, 2-aminopropane, and cyclohexylamine. This selection combines varying steric and electronic profiles, enabling comprehensive evaluation of how solvent and reaction conditions influence reactivity and selectivity across different nucleophilicity ranges. Initial studies will determine baseline reactivities through systematic kinetic measurements, assessing critical parameters such as rate constants and product ratios under controlled conditions. Reactant concentrations will be evaluated at specific increments of 0.1 (0.1 M, 0.5 M, and 1.0 M), and the temperature will be optimized through systematic approach involving stepwise assessments from 25C to 60C, analyzing how these variations affect reaction progress. comprehensive assessment of solvent effects will be performed, including the examination of solvent mixtures (e.g., varying concentrations of water, DMSO, and possible co-solvents) to quantify their influence on nucleophilicity and overall reactivity. Advanced computational methods, including density functional theory (DFT) calculations with the M06-2X functional and 6-31G basis set, will be employed to simulate the MoDAT reaction environment accurately. We will analyze key molecular descriptors such as nucleophilicity, electrophilicity, and steric hindrance to construct predictive models of reactivity. These analyses will guide experimental design, with feedback mechanism where discrepancies between computational predictions and experimental observations will result in specific adjustments to molecular descriptors or computational parameters, refining the predictive capabilities of the models. Following these investigations, the design of innovative azide-based reagents will be undertaken to optimize MoDAT reactions. This design process will emphasize the incorporation of electron-withdrawing groups like trifluoromethyl and cyano, aimed at enhancing both stability and selectivity by stabilizing the transition state. Rigorous standardized experimental protocols will ensure reproducibility, including specific techniques for measuring yields and selectivity ratios over controlled reaction durations. By integrating mechanistic insights from computational and empirical findings, this research will elucidate the key factors influencing reactivity and selectivity in diazo transfer reactions, enhancing our understanding of these critical processes. Experts Analysis: 1 conducted relatively comprehensive analysis, for instance, suggesting that modifying the azide reagent with functional groups could improve it, which aligns with the original text. However, 2 and 3 did not. This time, 1 has an obvious error: the speculated temperature is incorrect, and the proposed temperature is experimentally unfeasible, as azide reagents are prone to explosion at high temperatures. Of course, temperature is minor point, and overall, 1 is still acceptable. 2 deviates significantly from the original text in terms of the research design approach. Compared to 2, 3 lacks consideration of the group effect in the research design, making 3 the weakest. Finally, all three mentioned using DFT calculations, and although there are deviations in details from the original text, the approach is correct. Example 4: Research Question: How can photoredox catalysis be used to exploit the latent reactivity of phosphorus ylides, allowing them to participate in formal three-component cycloaddition 18 that converts inert CH and C=P bonds into CC and C=C bonds, creating versatile synthetic building blocks in an efficient, controlled manner? Hypothesis Candidate 1 (from HHS): The mechanism for activating phosphorus ylides in formal three-component cycloaddition via photoredox catalysis can be articulated in four key steps, each supported by optimized experimental conditions: 1. Initiation of Single-Electron Transfer (SET): Irradiation of phosphorus ylides with specific wavelengths of visible light (400450 nm) from high-intensity LED source (approximately 20 mW/cm2), validated by studies demonstrating effective radical generation at this intensity (Smith et al., 2020), promotes SET using suitable photoredox catalysts (e.g., [Ru(bpy)3]2+ or [Ir(dF(CF3)ppy)2(bpy)]). The resulting radical cation exhibits enhanced electrophilicity due to significant charge localization, which is further assisted by strong electron-withdrawing substituents such as carbonyl or nitro groups. Empirical evidence indicates an increase in reactivity by up to 2.5-fold as supported by Hammett parameters. 2. Stabilization via Zwitterionic Intermediate: The radical cation transitions to zwitterionic intermediate, characterized by resonance stabilization through delocalized -electrons and non-covalent interactions, such as hydrogen bonding in polar aprotic solvents like acetonitrile (dielectric constant 37) and DMSO (dielectric constant 47). To optimize stabilization, 1:1 (v/v) mixture of these solvents will be used, taking advantage of their combined dielectric properties ( 38) to enhance charge separation and stabilize reactive intermediates. Literature supports this approach, showing improved reaction kinetics (Miller et al., 2021). 3. Selective Nucleophilic Attack: The zwitterionic intermediate selectively engages in nucleophilic attacks on activated CH and C=P bonds, particularly those adjacent to strong electron-withdrawing groups. Maintaining phosphorus ylide concentrations at 0.1-0.5 and controlling reaction temperatures precisely within an optimized range of 10-25 C, as indicated by previous studies on radical stability, will minimize side reactions. An inert atmosphere (nitrogen or argon) will be established by purging the reaction vessel for 30 minutes before use, effectively mitigating oxidation. Real-time NMR (utilizing 1D and 2D techniques) and GC-MS metrics will be employed to monitor yield and product distribution effectively, specifying analytical conditions (e.g., temperature settings and flow rates) to ensure accurate assessment of outcomes. 4. Concerted Formation of Products: The reaction culminates in the concerted formation of new CC and C=C bonds, facilitating the synthesis of valuable carbocycles and synthetic building blocks. The influence of substituent identity and positioning (ortho, meta, para) on reactivity will be quantitatively analyzed using NMR and HPLC techniques. This systematic approach will provide insight into the efficiency and selectivity of the cycloaddition process, explaining how each factor contributes to overall reactivity. By integrating these components clearly and methodically, this hypothesis presents comprehensive exploration of how photoredox catalysis can unveil new reactivity pathways for phosphorus ylides, fully addressing the research question with explicitly defined roles of each mechanistic step and comprehensive definitions for specialized terms provided for clarity. Hypothesis Candidate 2 (Greedy + self-consistency): This study aims to investigate how photoredox catalysis can elucidate specific reactivity mechanisms in diphenylphosphinyl ylides, focusing on their participation as intermediates in formal three-component cycloaddition reactions that convert inert alkyl CH bonds and coordinated C=P bonds into CC and C=C bonds. We will concentrate on diphenylphosphinyl ylides due to their capacity to facilitate charge inversion processes, which are crucial for generating stabilized radical intermediates. Specifically, we will examine how the electronic structure of diphenylphosphinyl ylides transforms upon excitation under visible light (e.g., at wavelengths of 400-450 nm) into polar intermediates, leading to the generation of stable benzylic radicals from CH bond cleavage and allylic radicals from C=P bond activationboth essential for effective cycloaddition. 1. Charge Inversion Mechanisms: We will clarify the mechanisms of charge inversion by detailing the electronic transitions involved, emphasizing the role of excited state lifetimes and how solvent polarity affects the stabilization of generated radicals. Our discussion will include specific references to known photoredox systems and their operational parameters in literature, enhancing our findings with context. 19 2. Role of -Stacking Interactions: We will investigate the influence of -stacking interactions, specifying the optimal inter-ring distances and energy considerations between the stabilized radicals and electrophilic carbon centers from substrates like 2,6-dibromoaryl and 2,4-difluoroaryl. This section will include quantitative assessments of radical coupling reactivity, aiming to determine coupling efficiencies and product selectivity through methods such as 1H NMR and UV-Vis spectroscopy. 3. Solvent and Temperature Effects: We will analyze solvent effects by conducting reactions in range of solvents with varied dielectric constants, including thorough comparison of polar solvents like acetonitrile and non-polar solvents like dichloromethane. We will detail how these solvents are expected to influence radical stabilization and the kinetics of cycloaddition, providing theoretical framework based on established solvent interaction models. Additionally, we will justify the controlled temperature range of room temperature to 50C by linking it to the expected stability of radical intermediates and the kinetics of the reactions, ensuring optimal conditions for product yield and selectivity. 4. Experimental Conditions: Reactions will be conducted under carefully controlled conditions, with temperature justification focusing on maintaining the balance between radical stability and reaction kinetics. We will outline how these conditions directly relate to the completed cycloaddition mechanism and the anticipated outcomes of the study. By systematically elucidating these mechanismsspecifically charge inversion, -stacking interactions, and solvent effectswe aim to develop robust methodologies for the efficient generation of versatile synthetic building blocks from simple molecular precursors. Hypothesis Candidate 3 (Greedy): Investigate how photoredox catalysis enhances the reactivity of phosphorus ylides through selective nucleophilic attack on , -unsaturated carbonyl compounds, such as crotonaldehyde, which are activated to form stable radical cation intermediates via photoredox-driven single-electron transfer (SET) processes. These radical cations, characterized by their electrophilicity, promote effective nucleophilic attacks by phosphorus ylides, generating stabilized carbon radical intermediates that significantly enhance their reactivity in subsequent bond-forming transformations. Conduct formal three-component cycloaddition by introducing nucleophilic amine, such as ammonia or an aniline derivative, selected based on its electronic properties which influence the stabilization of the radical intermediates and affect product selectivity. Detail specific optimized reaction conditions, including the use of polar aprotic solvents like acetonitrile, which facilitate radical stability, and employ specific light wavelength of 400 nm to ensure efficient excitation of the photocatalyst. These conditions will be designed to minimize potential side reactions and maximize the conversion of inert CH and C=P bonds into desired CC and C=C bonds through well-defined mechanistic pathways, addressing the nuanced interplay between reaction parameters and final product outcomes. Experts Analysis: 1 accurately predicted the light source wavelength range, metal catalyst system, and solvent system, such as the use of Ir catalyst and acetonitrile as the solvent, all of which align with the original text. In contrast, 2 only correctly predicted the wavelength range and solvent system but failed to specify the metal catalyst system, which is crucial in organic chemical reactions. Therefore, 2 is inferior to 1. Finally, 3 did not predict the light source wavelength range or the metal catalyst system, missing several key pieces of information, making it the weakest."
        },
        {
            "title": "C Hypothesis Search Prompt",
            "content": "The black prompt are shared prompt between the baseline methods and HHS, and the orange prompt is HHS specific prompt describing hierarchy. Below is the prompt: You are assisting with scientists research. Given their research question, survey on the past methods for the research question, and preliminary coarse-grained research hypothesis for the research question, please help to make modifications into the coarse-grained hypothesis, to make it one step closer to more effective and more complete fine-grained hypothesis. The modification can be two-folds: (1): delete or change an existing improper detail or information in the existing hypothesis; (2) add and integrate one detail to the existing hypothesis. If you choose to add detail, do not simply append new information to the existing hypothesis. Instead, think 20 thoroughly how the new detail relates to the existing components and integrate it seamlessly into the hypothesis to create new coherent and unified hypothesis. In addition if you choose to add detail to general information, if the corresponding general information is correct, you should try to keep the corresponding general information in the updated hypothesis and also mention the details, instead of replacing the general information with the details. In this way, it would be much easier for scientists to understand both the general infomration/structure and the details from your generated hypothesis. It would be also easier for scientists to propose better details, inspired by your suggested details, following the general information. Please remind that this is about research: research is about discover new solution to the problem that ideally is more effective and can bring new insights. Usually we dont need the hypothesis to contain lots of known tricks to make it work better: we want to explore the unknown, which ideally is more effective than the known methods and can also bring in new insights. Therefore, research hypothesis is usually about small set (usually less than eight) of major components (and lots of details on how to implement these major components), which overall composes novel and complete solution to the research question, which potentially can bring in new insights. Hypotheses that include an excessive number of irrelevant or unnecessary major components, which do not contribute to addressing the research question, are less favorable, as we only want to know exactly what are the key components that fundamentally make the hypothesis work. If you think any ancillary components that can truly assist with the research question, you may mention what are the key components and what are the ancillary components to avoid the ambiguity of which components are the key component. The reaction mechanism, however, is not classified as major component or detail (and therefore not limited by the number of major components). Instead, novel and valid reaction mechanism can be good source of insights. If previous hypothesis already contains too many major components, you should consider to replace some of the major components with more effective ones (but not to add more major components), or to give more details to the existing major components for clarity and ease of implementation (instead of adding or replacing major components). Here we are searching for the fine-grained hypothesis in hierarchical way. The rationale is that, we can classify any complete set of modifications into several hierarchy, with different levels of details. If we do not search in hierarchical way, we need to consider all the available details in all hierarchy levels for each search step, which (1) has very high complexity, and (2) first search low-level detail might largely influence the following search of high-level detail: it might stuck in one high-level detail corresponding to the already searched low-level detail without considering the other low-level details corresponding to other high-level details, making the search process stuck in local minumum at the beginning. Here we roughly classify all possible modifications into five hierarchies: (1) Mechanism of the Reaction: Describes how the reaction proceeds at conceptual level, focusing on electron flow, bond formation and breaking, and any intermediates or transition states involved. This is the theoretical blueprint that explains why the reaction works; (2) General Concept or General Component Needed: Identifies the type of reagent or functional group required (e.g., strong acid, Lewis base, an activated aromatic ring) without committing to specific chemical. It outlines the broader roles that are necessary for the mechanism to proceed; (3) Specific Components for the General Concept: Narrows down from the general category to particular substance (e.g., concentrated HCl for strong acid, benzene for an aromatic ring). This makes the reaction hypothesis testable by specifying which chemicals fulfill the roles; (4) Full Details of the Specific Components: Provides exact structural or molecular informationsuch as SMILES strings, IUPAC names, purity, or CAS numbers. These details ensure clarity and reproducibility so researchers know precisely which substances to use; (5) Experimental Conditions: Specifies the practical setuptemperature, pressure, solvent system, reaction time, atmosphere, and any work-up procedures. This final layer describes how to carry out the reaction in laboratory setting. And we are searching for modifications hierarchy by hierarchy: hierarchy (1) first, and then hierarchy (2), and so on. Hypothesis from higher hierarchy is an expansion of the hypothesis from its previous hierarchy, with additional information described above. The research question is: The survey is: Now please help to make modifications into the coarse-grained hypothesis, to make it one step closer to more effective and more complete fine-grained hypothesis. Please do not include the expected performance or the significance of the hypothesis in your generation. Please answer the question in the following response format. (response format: Reasoning Process: Revised Hypothesis: )"
        },
        {
            "title": "D Experiment Compute Resources",
            "content": "We implement our proposed framework as an agentic LLM system using GPT-4o-mini using OpenAIs official API. Generating the final hypothesis via the HHS optimization processconverging to the final local optimum at hierarchy level 5typically involves several hundred or even to thousand iterative search steps."
        },
        {
            "title": "E Limitation",
            "content": "While HHS consistently discovers higher-quality local optima compared to baseline methods, it does not guarantee convergence to the global optimum. Addressing this limitation remains an open direction for future research."
        }
    ],
    "affiliations": [
        "MiroMind",
        "Nanyang Technological University",
        "National University of Singapore",
        "Shanghai Artificial Intelligence Laboratory",
        "University of New South Wales",
        "University of Science and Technology of China",
        "Wuhan University"
    ]
}