{
    "paper_title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
    "authors": [
        "Youjin Wang",
        "Run Zhou",
        "Rong Fu",
        "Shuaishuai Cao",
        "Hongwei Zeng",
        "Jiaxuan Lu",
        "Sicheng Fan",
        "Jiaqiao Zhao",
        "Liangming Pan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations, yet the model remains conservative in entering tool mode, revealing a representation-behavior gap. We propose Activation Steering Adapter (ASA), a training-free, inference-time controller that performs a single-shot mid-layer intervention and targets tool domains via a router-conditioned mixture of steering vectors with a probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B, ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates."
        },
        {
            "title": "Start",
            "content": "ASA: Training-Free Representation Engineering for Tool-Calling Agents Youjin Wang 1 * Run Zhou 1 * Rong Fu 2 Shuaishuai Cao 3 Hongwei Zeng 4 Jiaxuan Lu 5 Sicheng Fan 6 Jiaqiao Zhao 7 Liangming Pan 8 6 2 0 2 8 ] . [ 2 5 3 9 4 0 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Adapting LLM agents to domain-speciﬁc tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-eﬃcient ﬁne-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations, yet the model remains conservative in entering tool mode, revealing representation-behavior gap. We propose Activation Steering Adapter (ASA), training-free, inference-time controller that performs single-shot mid-layer intervention and targets tool domains via routerconditioned mixture of steering vectors with probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B, ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates. 1. Introduction Large pretrained models demonstrate strong capabilities across wide range of tasks, yet their eﬃcient adaptation to specialized domains remains an open and practical challenge. In real-world deployments, the set of available tools, API signatures, and inof Macau *Equal contribution 1Renmin University of China 2University South University 4University of the Chinese Academy of Sciences 5Shanghai AI Laboratory 6Fudan University 7Central South University 8Peking University. Correspondence to: Liangming Pan <liangming.pan@pku.edu.cn>. 3Central Preprint. February 10, 2026. 1 teraction protocols changes frequently, and schemas continuously accumulate constraints, often leading to distribution shifts and breakdowns in output formats when general model is applied to concrete environment (Xi et al., 2025; Qin et al., 2023; Patil et al., 2024; Schick et al., 2023). The central engineering question is how to adapt general model to evolving domain toolsets in way that preserves its broad competencies while remaining stable and controllable in production (Hu et al., 2022; Dettmers et al., 2023; In this paper, we use toolProttasha et al., 2025). calling domain adaptation to denote robust tool selection and tool-mode triggering under schema shift, i.e., when available tools, API signatures, and interaction protocols evolve over time.This is especially difﬁcult because tool calling is discrete, parser-deﬁned mode switch, so small distribution shifts can ﬂip execution even when the underlying intent representation is preserved; moreover, the cost of updating prompts or adapters grows linearly with the number of domains and API versions, becoming prohibitive at scale. Existing solutions follow two main directions. One direction operates on the input side by using prompts and schema constraints to steer tool invocation; this approach is easy to deploy but it consumes context capacity and is fragile under wording or context perturbations (Yao et al., 2022; Qin et al., 2023). The other direction adapts model parameters via parametereﬃcient ﬁne-tuning methods such as LoRA and its quantized variants; such methods improve in-domain invocation success and format compliance but impose recurring costs for training, deployment, and regression testing as domains and interfaces proliferate, and they risk degrading general capabilities over time (Hu et al., 2022; Dettmers et al., 2023; Tang et al., 2023; Prottasha et al., 2025; Lu et al., 2025). When these approaches are deployed in dynamic or adversarial settings, three issues frequently arise. First, prompt and schema methods are brittle and sensitive to small changes in wording or context (Qin et al., 2023). Second, frequent ﬁne-tuning is unsustainable ASA: Training-Free Representation Engineering for Tool-Calling Agents Figure 1. Overview of tool-calling domain adaptation methods under rapidly evolving tool sets and interaction protocols, and our inference-time probe-gated activation control. at scale because the operational burden and risk of forgetting increase with the number of domains and interface versions (Hu et al., 2022; Dettmers et al., 2023; Prottasha et al., 2025). Third, there is conceptual mismatch in treating tool invocation as mere knowledge or format injection rather than as control problem that requires reliable switch in the models execution mode. Empirically, we uncover paradox that we term Lazy Agent failure mode: linear probes on mid-layer activations can predict tool necessity with near-perfect accuracy (> 99% AUC), yet the models overt generation fails to trigger tools in over 80 percent of these cases. This reveals persistent representation behavior gap, characterizing state where the agent knows what to do but lacks the activation impulse to break the generation threshold. Meanwhile, naive activation injection can also amplify spurious triggers due to downstream nonlinearities and adversarial constraints. This reveals key bottleneck at the behaviorcontrol layer (Zou et al., 2023; Turner et al., 2024; Wehner et al., 2025; Bartoszcze et al., 2025). This Lazy Agent failure mode characterizes speciﬁc breakdown where tool-use intent is cleanly encoded within the representation space, but fails to cross the discrete decision threshold required for execution. Such gap renders the models tool-calling capabilities brittle, as the latent \"intent\" and ﬁnal \"action\" are eﬀectively decoupled under strict parsing constraints. To resolve this, we argue that the agent requires more than just static guidance; it needs an inference-time control layer capable of bridging the representation-behavior gap. Motivated by these observations, we propose twolevel, inference-time control paradigm that requires no weight updates. The approach models domain adaptation for agent-style tool-calling as combination of representation-level intent alignment and decisionlevel boundary calibration (Zou et al., 2023; Turner et al., 2024; Wehner et al., 2025). At the representation level we introduce ASA, compact adapter that models intent geometry using shared base vector plus small set of domain oﬀset experts combined by lightweight router. At the decision level, instead of logit-level biasing, we use probe-guided signed gate that conditionally opens (injects) or inverts (suppresses) the steering direction, thereby calibrating the discrete tool-mode transition under strict tool-call parsing and adversarial phrasing (Lee et al., 2024; Rahn et al., 2024). On the MTU-Bench benchmark, ASA provides strong intent-aligned control with negligible storage and no training, yielding consistent improvements in strict F1 (balancing missed calls and false triggers) while largely preserving output format and argument compliance. Together, these ﬁndings suggest practical middle ground that is more robust than prompt-only approaches and considerably lighterweight than continual ﬁne-tuning. This positions tool calling as form of complex structural behavior control, which is precisely where existing RepE-style steering is under-explored and where ASA is designed to operate. Our main contributions are threefold. First, we identify representation behavior gap in tool-calling adaptation: tool intent is ASA: Training-Free Representation Engineering for Tool-Calling Agents nearly perfectly linearly decodable from mid-layer activations, yet strict tool-mode triggering remains conservative, causing missed calls and false triggers. Second, we propose ASA, training-free, inference-time activation controller that performs single-shot midlayer intervention using router-conditioned mixtureof-vectors and probe-guided signed gate; the gate acts as context-aware safety valve, enabling bidirectional control with one strength knob α and optimizing strict F1 (RecallFPR). Third, we introduce strictly isolated MTU-Bench protocol with deterministic triggering and post-trigger validity checks (format/tool/args), and show consistent strict-F1 gains across prompt baselines, LoRA references, and model scales (0.5B/1.5B/8B),with only KB-level portable assets, under strict production constraints. 2. Related Work 2.1. LLM agents and tool-calling LLM agent and tool-calling research integrates external tools into the reasoning/decision loop so models can query, compute, and interact with environments. Most approaches operate at the I/O interface through structured prompting, exemplars/templates, or output normalization and work well in relatively controlled settings. ReAct interleaves reasoning and actions but is prompt-fragile under wording or context shifts (Yao et al., 2022). Reﬂexion uses self-reﬂective memory but relies on stable traces and protocol assumptions (Shinn et al., 2023). Skillaccumulating agents such as Voyager compose procedures yet often bind to speciﬁc interface, limiting cross-domain/protocol transfer (Wang et al., 2023). Output-side supervision or normalization (e.g., Toolformer and parsability-focused methods) improves reliability, but typically requires re-training or strong constraints when schemas evolve or prompts become adversarial (Schick et al., 2023; Johnson et al., 2025; Dang et al., 2025). Overall, prior work strengthens external workﬂows but oﬀers limited mechanisms for internally stable, transferable execution-mode switching; we instead study internal control via mid-layer intent routing with lightweight gated calibration to robustly trigger tools without weight updates. 2.2. Parameter-eﬃcient ﬁne-tuning and domain adaptation Parameter-eﬃcient ﬁne-tuning (PEFT) adapts pretrained models to new domains with minimal additional parameters and computation. Representative PEFT variants include prompt-based methods such as Preﬁx-Tuning (Li & Liang, 2021), sparse parameter updates like BitFit (Zaken et al., 2022), and low-rank adaptation approaches such as LoRA and QLoRA, which use low-rank updates to reduce ﬁne-tuning costs (Hu et al., 2022; Dettmers et al., 2023). Tool-use datasets such as ToolAlpaca further show that PEFT can increase in-domain invocation success and format compliance (Tang et al., 2023). However, PEFT is training-driven: as domains and interfaces proliferate and change, training, deployment, regression testing, and rollouts scale roughly linearly, with risks of forgetting and version drift. ReFT constrains updates to lowdimensional subspaces to improve stability, but still requires training and thus struggles under rapid protocol churn (Wu et al., 2024). Other approaches (e.g., SKTuning) assume stable semantic anchors, which may not hold when alignment targets evolving function-call schemas (Prottasha et al., 2024). In contrast, we perform inference-time domain alignment via switchable two-level control mechanism that leaves base weights untouched, reducing long-term maintenance burden. 2.3. Representation engineering and activation steering Representation engineering and activation steering guide behavior by intervening on intermediate activations, enabling switchable and often interpretable control without retraining. Prior work shows that concepts/intentions can be detected and injected along activation directions to steer outputs (Zou et al., 2023; Turner et al., 2024). Yet most studies focus on single concepts or narrow tasks, and rarely model multi-domain geometry with shared bases plus domain-speciﬁc oﬀsets. Further, representation-level interventions may not translate to end-to-end behavioral change under strong constraints or adversarial prompts, since downstream nonlinearities can attenuate injected signals. Taxonomies and systematization eﬀorts improve selectivity and interpretability (Wehner et al., 2025; Bartoszcze et al., 2025), while conditional control methods reﬁne intervention precision (Lee et al., 2024; Rahn et al., 2024). Most RepE work targets semantic attributes, whereas agent tool calling is parser-deﬁned discrete mode switch with strict executability constraints. Evidence on RepE for such multi-tool, schema-constrained toolmode switching is limited; ASA addresses this by domain-structured directions with conﬁdence gating. 3. Methodology This section presents ASA, an inference-time mechanism designed to control whether pretrained language model enters tool-invocation execution mode. 3 ASA: Training-Free Representation Engineering for Tool-Calling Agents Figure 2. ASA overview. We extract the last-token hidden state at layer during the pre-ﬁll pass, route the input to domain ˆd, estimate tool intent probability p, construct MoV = ˆd + βvglobal, and inject = Gate(h) α MoV once. No further interventions are applied during incremental decoding. Table 1. H1 results at L18: tool intent is nearly perfectly linearly readable. Table 3. H2 results (Qwen2.5-1.5B-Instruct, L18): injecting the intent direction changes tool-trigger evidence. Model Layer AUC (Tool-Necessary vs. Non-Tool) Shuﬄe AUC α Direction Logit (mean) Prob (mean) Qwen2.5-0.5B-Instruct Qwen2.5-1.5B-Instruct Qwen2.5-8B-Instruct 18 18 18 0.9994 0.9996 [0.9987, 1.0000] 0.9989 0.4982 [0.4891, 0.5076] 0.4966 [0.4884, 0.5053] 0.4975 [0.4879, 0.5068] Table 2. H3 results: cross-domain interference matrix (normalized diagonal). Code Math Search Translation Code Math Search Translation 1.00 0.17 0.37 0.42 0.17 1.00 0.29 0.11 0.37 0.29 1.00 0.03 0.42 0.11 0.03 1.00 ASA is motivated by diagnostic observations about how tool-use intent is represented and causally expressed in intermediate activations. The method achieves reversible, low-cost control via single hiddenstate perturbation applied at selected intermediate layer, while leaving backbone parameters unchanged. 3.1. Problem deﬁnition We consider an autoregressive model that maps an instruction to an output token sequence = (y1, . . . , yT ). At generation step t, the model produces logits zt(x, y<t) RV , (1) 4 0.25 0.25 0. 1.00 1.00 1.00 +v random +v random +0.2077 -0.2230 -0.0037 +0.8359 -0.9414 -0.0459 +1.38% -1.41% +0.11% +5.47% -5.46% -0.22% p-value (+v/v vs. rand) 2.51 1036 1.89 1037 7.10 1043 3.26 1044 where denotes the vocabulary, and corresponding probabilities pt = softmax(zt). Here and below deterministic parser deﬁnes binary behavioral event (x) {0, 1}, (2) where (x) = 1 if and only if the generated sequence is interpreted as valid tool invocation by the parser (for example by containing function-call scaﬀold whose syntax and arguments are parseable). The operational objective is to design compact, portable controller that, for any input x, can increase the probability of producing correct tool call when tool is necessary while suppressing spurious calls when it is not, without modifying the model parameters θ. 3.2. Notation and measurement primitives Extract the Pre-LN residual-stream representation at chosen layer and at the ﬁnal non-padding prompt ASA: Training-Free Representation Engineering for Tool-Calling Agents token: hL(x) RD, (3) where is the residual dimension. In experiments we also standardize each coordinate of hL using trainingset statistics; formally, hL(x) = Std ( ) hL(x) = hL(x) µtrain σtrain , (4) where µtrain and σtrain denote per-dimension mean and standard deviation computed on the router/probe training partition. For evaluation of causal inﬂuence we measure the mean change in logits for set of trigger tokens S. Given an intervention that maps hL 7 h0 L, deﬁne where y(x) is an oracle binary label indicating whether tool call is necessary. The global intent vector is deﬁned as vglobal = µpos µneg, (8) where vglobal RD points from the non-tool mean toward the tool-necessary mean. Per-domain vectors vd are built analogously by restricting expectations to samples in domain d. After construction, normalize each vector: ˆv = kvk , (9) where denotes the Euclidean norm and ˆv denotes the unit-normalized direction used at inference. Logit = EtS [ ztrigger (h0 L) ztrigger ] , (hL) (5) 3.4.2. Router and probe definitions where ztrigger denotes the logit(s) associated with tokens considered evidence of tool invocation and the expectation averages over the trigger positions. 3.3. Empirical diagnostics (motivation summary) Three empirical ﬁndings justify the ASA design. First, lightweight linear classiﬁer trained on hL(x) reliably separates samples requiring tool invocation from those that do not, demonstrating that tool intent is linearly readable in mid-layer activations. Second, direction derived from class-conditional means produces measurable causal eﬀect on early tool-trigger logits (Eq. (5)), far surpassing norm-matched random perturbations. Third, when intent directions are estimated separately per domain, the resulting vectors display partial domain-speciﬁc geometry, which implies that routing to domain-aware directions can reduce crossdomain interference. 3.4. ASA architecture and operations ASA composes three lightweight components: compact set of steering vectors, multi-class router, and per-domain intent probes. At inference time ASA performs single-shot, signed injection into hL(x) followed by normal forward propagation. Below we formalize each component and the intervention rule. 3.4.1. Steering vector construction Using disjoint calibration split, compute classconditional means in the layer-L hidden space: µpos = µneg = [ hL(x) y(x) = 1 [ hL(x) y(x) = 0 ] , ] , (6) (7) 5 lightweight router maps standardized representations to domain label. Concretely, ˆd = arg max dDdom ( softmax hL(x) + br ) d, (10) where RDD and br are router parameters estimated on the router training split. Each domain has linear probe that outputs an intent score. For domain ˆd, p(x) = q( ˆd) ( ψ (hL(x)) = σ ) hL(x) + ˆd , w> ˆd (11) where σ() is the sigmoid function, and ˆd, ˆd are ﬁtted on domain-speciﬁc training data. Here p(x) estimates the probability that tool invocation is appropriate. 3.4.3. Mixture-of-vectors (MoV) composition Given the router prediction ˆd and the normalized vectors, ASA composes direction using domain expert plus global oﬀset: MoV(hL(x)) = ˆv ˆd + β ˆvglobal, (12) where β 0 controls the strength of the global intent contribution and both ˆv ˆd and ˆvglobal are unitnormalized as in Eq. (9). This modular design lets ASA scale to new domains by simply adding new expert vector vnew (and updating the router), without retraining the backbone, eﬀectively enabling plugand-play library of domain skills. 3.4.4. Confidence gating and signed injection To avoid ambiguous injections near decision boundaries, map the probe probability to ternary control ASA: Training-Free Representation Engineering for Tool-Calling Agents signal: Gate(hL(x)) = +1, p(x) > τ, 1, p(x) < 1 τ, 0, otherwise, (13) where τ (0.5, 1) is ﬁxed conﬁdence threshold selected on validation data. The single-shot intervention applied at layer is h0 L(x) = hL(x) + Gate(hL(x)) α MoV(hL(x)), (14) where α 0 scales the perturbation magnitude. When probe is conﬁdent that tool is required the controller adds the composed steering vector; when the probe is conﬁdent that no tool is needed the controller subtracts the vector; otherwise no modiﬁcation is made. The injection occurs only once during the pre-ﬁll pass and is not repeated at subsequent decoding steps. 3.5. Data hygiene and deployment constraints To prevent leakage between calibration and evaluation, ASA uses disjoint data partitions. The calibration corpus is reserved solely for steering-vector estimation and is never used to train routers or probes. Router and probe ﬁtting, hyperparameter selection including τ and α, and ﬁnal reporting are performed on separate training/validation/test splits drawn from the benchmark partition. Standardization statistics in Eq. (4) are computed on the router/probe training split and applied at inference time. The ASA asset footprint consists only of the small set of unit vectors {ˆvd} {ˆvglobal} and linear predictors r, br, {wd, bd}, making the controller portable and inexpensive to store and transmit. 3.6. Causal check and evaluation diagnostics As validation of causal eﬃcacy, one computes the change in trigger logits under sign-symmetric injections and compares this to random-direction controls using Eq. (5). Sign-consistent Logit values conﬁrm that the constructed directions inﬂuence early trigger evidence. Behavior-level metrics such as strict trigger recall, false positive rate, and post-trigger executability are reported under deterministic decoding protocol to minimize stochastic variability. 3.7. Inference summary At runtime the controller is executed as single, lightweight forward hook at layer L. The hook standardizes the last-token residual hL(x), predicts doAlgorithm 1 ASA single-shot inference (equationreferenced) Require: Frozen model router parameters (W r, br), per-domain probes {wd, bd}, steering vectors {ˆvglobal, ˆvd}, intervention layer L, strength α, global weight β, conﬁdence threshold τ fθ, 1: Run the initial pre-ﬁll forward pass and extract the last-token hidden state hL(x) from the Pre-LN residual stream. 2: Standardize the representation: compute hL(x) = Std(hL(x)) as in Eq. (4). 3: Predict domain label ˆd using the router: ˆd arg maxd softmax(W rhL(x) + br)d. See Eq. (10). 4: Compute intent probability p(x) from the domain probe: p(x) σ(w> ˆd hL(x) + ˆd). See Eq. (11). 5: Form the routed steering direction MoV(hL(x)) ˆv ˆd + β ˆvglobal as in Eq. (12). 6: Evaluate the ternary gate Gate(hL(x)) according to Eq. (13) using threshold τ . 7: Apply the single-shot signed injection: h0 L(x) hL(x) + Gate(hL(x)) α MoV(hL(x)), which implements Eq. (14). 8: Continue the forward pass from layer using h0 L(x) and decode autoregressively (no further injections). 9: return generated sequence y. main, evaluates intent via the appropriate probe, composes the steering direction using Eq. (12), computes the ternary gate in Eq. (13), applies the signed injection in Eq. (14) if warranted, and then resumes the normal forward computation. The process leaves the base model parameters untouched and restricts interventions to single temporal point. 4. Experiments In this section, we evaluate ASA for tool-calling domain adaptation, focusing on its eﬀectiveness under strict experimental protocol, its controllability enabled by context-aware probe-guided gating, and its robustness across diﬀerent model scales. We benchmark against prompt-only variants and parameterupdate baseline (LoRA) to clarify where ASA sits on the robustnesseﬃciency spectrum. All experiments are conducted on strictly isolated calibration, training, validation, and held-out test splits to prevent data leakage and to directly measure whether steering can bridge the representation and behavior gap.Additional visualizations are provided in Appendix E. 6 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 4. LLaMA (8B,L=23) neighborhood adaptation (main results). We report triggering Precision/Recall/F1, Accuracy, and FPR for each domain. ASA (Ours) reports the best operating point per domain by F1 (from the α sweep). Method Metric Prompt-only Baseline ASA (Ours) Precision (P) Recall (R) F1-Score Accuracy (Acc.) FPR Precision (P) Recall (R) F1-Score Accuracy (Acc.) FPR Precision (P) Recall (R) F1-Score Accuracy (Acc.) FPR Code 0.8723 0.2854 0.4218 0.6358 0.0389 0.8574 0.2508 0.3879 0.6049 0.0419 0.9091 0.4167 0.5714 0.6875 0.0370 Math 0.6857 0.3528 0.4639 0.6189 0. 0.6368 0.2919 0.4008 0.5629 0.1669 0.9987 0.9569 0.9772 0.9783 0.0013 Search Translation 0.8584 0.2629 0.3957 0.6287 0.0367 0.8337 0.2089 0.3339 0.5839 0. 0.9167 0.4583 0.6111 0.7083 0.0350 0.9382 0.9989 0.9687 0.9658 0.0859 0.9234 0.9988 0.9608 0.9589 0.0839 0.9241 0.9991 0.9612 0.9587 0.0828 ALL 0.8627 0.4988 0.6238 0.7159 0. 0.8407 0.4378 0.5759 0.6779 0.0839 0.9079 0.7188 0.8023 0.8229 0.0700 4.1. Experimental Setup and Metrics Benchmark construction. We evaluate on 1,600sample multi-domain benchmark spanning Math, Code, Search, and Translation. Samples are constructed from public instruction-following and QA datasets (e.g., Alpaca (Stanford, 2023) and Natural Questions (Kwiatkowski et al., 2019)). We apply domain-speciﬁc ﬁltering rules to form Tool-Necessary and Non-Tool pairs, validate tool labels via explicit <functioncall> markers, and randomly subsample 1,600 instances for evaluation (an engineering choice; the construction procedure scales to larger corpora). Detailed training and inference conﬁgurations of the LoRA baseline are provided in Appendix C.4. Strict protocol and metrics. We count tool call as triggered iﬀ the output contains <functioncall>. We report triggering Precision/Recall/F1, Accuracy, and FPR (Non-Tool trigger rate), plus Success Precision Psucc conditioned on triggering: JSON-valid (AST fallback), schema-consistent (whitelist), and argumentvalid (present, non-empty, format-compliant).We select by probe sweep (best val AUC; Fig. 3), tune α by best val F1 (test sweep in Table 5), and tune τ on val (grid {0.50, 0.55, 0.60, 0.65, 0.70}) then ﬁx it on test. Routers/probes use only train; vectors use only CAL. 4.2. Main Results on Two Models We report results on two instruction-tuned LLMs: LLaMA (8B) and Qwen2.5-1.5B. Table 4 summarizes domain-wise triggering performance on LLaMA. For each domain, ASA reports the best operating point selected by F1 from the α sweep, and we specially highlight our results. Table 5 further reports full α sweep on Qwen2.5-1.5B under the same strict protocol, together with prompt variants and PEFT baselines, to situate ASA on the robustnesseﬃciency spectrum. ASA consistently improves the trigger-quality tradeoﬀ over both Prompt-only and Baseline across the two evaluated models (Tables 4, 5). On LLaMA, gains concentrate on domains that are not already saturated, while false triggers remain controlled; Translation is near ceiling on this split and thus exhibits limited headroom. On Qwen2.5-1.5B, prompt-only baselines either under-trigger (e.g., the system-free setting collapses tool calling) or trade higher recall for substantially more false alarms, underscoring the brittleness of prompt engineering under strict interfaces. In contrast, ASA improves triggering behavior across broad range of steering strengths without inducing structural collapse: post-trigger validity remains stable, indicating that activation injection primarily modulates the decision to enter tool mode rather than corrupting formatting or argument construction. This is enabled by probe-guided dynamic gating, which conditionally opens or suppresses steering based on the current context, allowing ASA to mitigate the typical recall hallucination trade-oﬀ. Comparison across adaptation paradigms. Under the same strict protocol  (Table 5)  , prompting mainly shifts surface instructions and tends to move along recallfalse-trigger frontier without reliably 7 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 5. Results on the MTU-Bench test set (Qwen2.5-1.5B, L=18). ASA (Ours) applies probe-guided dynamic gating for all α; we report F1 as primary metric . Here Trig. Prec. denotes precision of the tool-mode triggering decision, while post-trigger validity (Format/Exec. Prec./Args) measures executability conditional on triggering, where Exec. Prec.is deﬁned as the ratio of samples with both valid format and tool name to the total triggered samples. α Method Branch Prompt variants Prompt: no_system Prompt: few_shot_system PEFT baselines LoRA (Rank-16) (Hu et al., 2022) LoRA (Rank-8) (Hu et al., 2022) Preﬁx-Tuning (Li & Liang, 2021) BitFit (Zaken et al., 2022) Q-LoRA (Dettmers et al., 2023) Vector injection Baseline (zero_shot_system) steer 0.5 ASA (Ours) steer 1.0 ASA (Ours) steer 2.0 ASA (Ours) steer 3.0 ASA (Ours) steer 4.0 ASA (Ours) Triggering Post-trigger validity Cost Rel. vs. baseline Trig. Prec. Rec. Acc. FPR Format Exec. Prec. Args Storage Train F1 Prec FPR 0.0000 0.4348 0.0000 0.2083 0.0000 0. 0.0000 0.2708 0.8200 0.3826 0.8000 0 0 No No -100.00% -100.00% -100.00% -1.18% +85.73% +54.95% 0.5600 0.4800 0.6174 0.5873 0.7328 0.4400 0.4615 0.5937 0.7805 0.7778 0.8718 0.5833 0.4500 0.2041 0.1702 0. 0.5714 0.4643 0.3029 0.2564 0.4696 0.4583 0.5200 0.1074 0.1343 0.1193 0.6500 0.5800 0.8111 0.7432 0. 1.0000 0.4844 0.1146 0.9700 0.4896 0.1250 0.9400 0.5312 0.1979 0.8900 0.6198 0.3333 0.3646 0.8600 0.6302 0.3542 0.5037 0.6510 0.0521 0.8800 0.1458 0.1458 0.1354 0.0937 0.1042 0.1818 0.1967 0.2969 0.4672 0.4965 0.2240 0.1920 0.4405 0.4323 0.4898 0.4000 0.4231 0.5625 0.7073 0.6667 0. 0.6300 19MB Yes +214.30% +27.27% +214.33% 0.5600 10MB Yes +155.39% +9.09% +256.65% 0.8425 15MB Yes -4.58% +4.63% +48.76% 0.8146 8MB Yes +58.98% -8.93% +8.49% 0.8922 18MB Yes +79.86% +23.35% -14.21% No 0.9900 0 0.9600 20KB No +8.20% +0.00% +4.89% 0.9300 20KB No +63.31% +34.93% -7.13% 0.8800 20KB No +156.99% +77.39% -35.73% 0.8500 20KB No +173.10% +76.77% -28.53% 0.8700 20KB No +177.06% +98.14% -64.27% closing the representationbehavior gap. PEFT baselines such as LoRA can attain strong triggering metrics by updating model weights, but incur non-trivial training/storage overhead and often amplify false triggers; lighter PEFT variants typically preserve post-trigger validity but struggle to recover recall, while quantized variants remain training-dependent. ASA instead offers training-free operating knob with low overhead, achieving competitive triggering behavior while maintaining executability, suggesting its primary eﬀect is targeted control of tool-mode entry rather than improving format compliance alone. Scaling behavior. Across model scales, the optimal intervention depth shifts with capacity (e.g., L18 L21), consistent with layer-depth drift under scaling. More importantly, ASA transfers when the base model already possesses tool-calling capability and thus has latent circuit to amplify; it cannot create tool-use behavior from scratch. See Appendix  (Table 14)  for the full scaling summary. 4.3. Ablation Study We ablate ASA at α = 4.0 to conﬁrm Table 6 gains are from structured control (not incidental perturbations). ASA (full) gives the best balance. Removing the probe-guided gate (No gate) makes injection unconditional and blows up false triggers (FPR = 0.5000), showing the gate is the key safety valve on Non-Tool inputs. norm-matched Random direction does not help, ruling out pure perturbation energy eﬀect. Composition matters: Global only is strong but less selective, while Domain only is often insuﬃcient to reliably enter tool mode. Mismatch hurts schema consisTable 6. Ablation study on test set (Qwen2.5-1.5B, Layer 18, α = 4.0). Oracle Router uses the ground-truth domain label for domain-vector selection (ideal router with 100% domain accuracy)."
        },
        {
            "title": "Mode",
            "content": "Prec. Rec. FPR Tool acc. Baseline ASA (full) Oracle Router Global only Domain only No gate Random Mismatch 0.4400 0.8718 0.9714 0.8261 0.3636 0.4217 0.5556 0.7885 0.1146 0.3542 0.3542 0.3958 0.1250 0.3646 0.1042 0. 0.1458 0.0521 0.0104 0.0833 0.2188 0.5000 0.0833 0.1146 0.9600 0.7436 0.8000 0.6957 0.7576 0.7229 0.9444 0.6346 tency, reﬂected by lower tool-name accuracy. Oracle Router (ground-truth domains) further reduces FPR to 0.0104, indicating routing headroom. We also report the same ablation pattern on LLAMA in Appendix F, again highlighting the necessity of gating. LoRA adapters are trained via standard supervised ﬁne-tuning on the same CAL split; full training and generation details are in Appendix C.4. 5. Conclusion ASA provides training-free, inference-time control layer for tool-calling domain adaptation, bridging the representationbehavior gap where tool intent is decodable but fails to trigger under strict interfaces. On MTU-Bench, single-shot routed steering with probeguided gating boosts strict tool-use F1 (higher recall, lower FPR) while preserving output validity. ASA: Training-Free Representation Engineering for Tool-Calling Agents"
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents work on activation steering for tool-calling domain adaptation. The goal is to advance machine learning by improving controllability of large language model agents. Our approach enables reliable tool-calling across domains without parameter updates, potentially reducing deployment costs and improving AI safety through better behavioral control. However, the ability to bidirectionally control tool invocation raises dual use concerns, as adversarial actors might exploit similar mechanisms to suppress safety critical tool calls or evade monitoring systems. We urge researchers to investigate safeguards against unauthorized activation steering. Societal consequences include more robust AI assistants but also potential misuse of steering techniques for deceptive behavior."
        },
        {
            "title": "References",
            "content": "Bartoszcze, L., Munshi, S., Sukidi, B., Yen, J., Yang, Z., Williams-King, D., Le, L., Asuzu, K., and Maple, C. Representation engineering for large-language models: Survey and research challenges. arXiv preprint arXiv:2502.17601, 2025. Dang, H., Liu, T., Wu, Z., Yang, J., Jiang, H., Yang, T., Chen, P., Wang, Z., Wang, H., Li, H., et al. Improving large language models function calling and interpretability via guided-structured templates. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pp. 24437 24453, 2025. Dettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. Qlora: Eﬃcient ﬁnetuning of quantized llms. arXiv preprint arXiv:2305.14314, 2023. doi: 10.48550/arXiv.2305.14314. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W., et al. Lora: Lowrank adaptation of large language models. ICLR, 1 (2):3, 2022. Johnson, R. T., Pain, M. D., and West, J. D. Natural language tools: natural language approach to tool calling in large language agents. arXiv preprint arXiv:2510.14453, 2025. Kwiatkowski, T., Palomaki, J., Redﬁeld, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., et al. Natural questions: benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453466, 2019. Lee, B. W., Padhi, I., Ramamurthy, K. N., Miehling, E., Dognin, P., Nagireddy, M., and Dhurandhar, A. Programming refusal with conditional activation steering. arXiv preprint arXiv:2409.05907, 2024. Li, X. L. and Liang, P. Preﬁx-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021. Lu, W., Luu, R. K., and Buehler, M. J. Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities. npj Computational Materials, 11(1):84, 2025. Patil, S. G., Zhang, T., Wang, X., and Gonzalez, J. E. Gorilla: Large language model connected with massive apis. Advances in Neural Information Processing Systems, 37:126544126565, 2024. Prottasha, N. J., Mahmud, A., Sobuj, M. S. I., Bhat, P., Kowsher, M., Youseﬁ, N., and Garibay, O. O. Parameter-eﬃcient ﬁne-tuning of large language models using semantic knowledge tuning. Scientiﬁc Reports, 14(1):30667, 2024. Prottasha, N. J., Chowdhury, U. R., Mohanto, S., Nuzhat, T., Sami, A. A., Ali, M. S., Sobuj, M. S. I., Raman, H., Kowsher, M., and Garibay, O. O. Peft a2z: Parameter-eﬃcient ﬁne-tuning survey for large language and vision models. arXiv preprint arXiv:2504.14117, 2025. Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y., Cong, X., Tang, X., Qian, B., et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023. Rahn, N., DOro, P., and Bellemare, M. G. Controlling large language model agents with entropic activation steering. arXiv preprint arXiv:2406.00244, 2024. Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Hambro, E., Zettlemoyer, L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36:68539 68551, 2023. Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and Yao, S. Reﬂexion: language agents with verbal reinforcement learning. In Advances in Neural Information Processing Systems 36 (NeurIPS 2023), 2023. Stanford, C. Alpaca: strong, replicable instructionfollowing model, 2023. 9 ASA: Training-Free Representation Engineering for Tool-Calling Agents Tang, Q., Deng, Z., Lin, H., Han, X., Liang, Q., Cao, B., and Sun, L. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. arXiv preprint arXiv:2306.05301, 2023. Turner, A. M., Thiergart, L., Leech, G., Udell, D., Mini, U., and MacDiarmid, M. Activation addition: Steering language models without optimization. 2024. Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. Voyager: An open-ended embodied agent with large language models, 2023. 2023. Wehner, J., Abdelnabi, S., Tan, D., Krueger, D., and Fritz, M. Taxonomy, opportunities, and challenges of representation engineering for large lanarXiv preprint arXiv:2502.19649, guage models. 2025. Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., and Potts, C. Reft: RepreIn Adsentation ﬁnetuning for language models. vances in Neural Information Processing Systems 38 (NeurIPS 2024), 2024. Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., Zhou, E., et al. The rise and potential of large language model based agents: survey. Science China Information Sciences, 68(2):121101, 2025. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. R., and Cao, Y. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations, 2022. Zaken, E. B., Goldberg, Y., and Ravfogel, S. Bitﬁt: Simple parameter-eﬃcient ﬁne-tuning for transformer-based masked language-models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 19, 2022. Zou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren, R., Pan, A., Yin, X., Mazeika, M., Dombrowski, A.-K., et al. Representation engineering: arXiv top-down approach to ai transparency. preprint arXiv:2310.01405, 2023. 10 ASA: Training-Free Representation Engineering for Tool-Calling Agents A. Appendix Overview This appendix complements the main paper with four components. Appendix explains why intent may be strongly decodable in representation space yet fail to reliably manifest as tool-entry behavior under strict interface constraints. Appendix speciﬁes datasets, splits, models, decoding, interventions, and metric deﬁnitions for faithful replication. Appendix deﬁnes deterministic trigger and validation rules so that the behavioral event (x) is auditable. Appendix provides additional results referenced but not expanded in the main text, including cross-model probe decodability, logit-lens causality tables, cross-domain interference matrices, prompt baselines, scaling summaries, and eﬃciency comparisons. B. Theoretical Analysis: From Representation to Behavior B.1. Problem setup and the representationbehavior gap We study tool calling as an auditable discrete event under strict interface constraints. Given an instruction x, the agent produces string output. deterministic parser maps the output to binary event (x) {0, 1} that indicates whether tool mode is entered. Importantly, the parser deﬁnes hard boundary (e.g., the appearance of <functioncall> and valid payload), so small changes in decoding can ﬂip (x) discontinuously. Many LLMs encode tool intent in hidden states: linear probe on mid-layer residual stream can separate Tool-Necessary vs Non-Tool with near-perfect AUC (see Appendix E, Table 10). However, high-AUC intent signal does not imply reliable tool-entry behavior, because behavior requires the model to emit very speciﬁc string pattern and schema-compliant JSON under decoding constraints. B.2. Why strong intent decodability may not translate into tool entry We highlight three failure mechanisms. (i) Discrete parser boundary and early-token competition. Tool entry often depends on very early generation decisions that determine whether the model commits to <functioncall>. Even if later-layer representations encode intent, the output may remain in natural language if the early-token logit competition is not suﬃciently biased. This motivates mid-layer causal control that aﬀects the early distribution over trigger tokens, rather than post-hoc formatting. (ii) Interface constraints amplify small formatting errors. model can be toolish but still fail strict validators: invalid JSON, wrong tool name (schema mismatch), or missing/empty arguments are all treated as failures in deployment. Therefore, any method must improve not only trigger rate but also post-trigger validity. (iii) Prompt/schema fragility under protocol evolution. Prompt constraints are implemented at the input level; they can be brittle under distribution shifts, context budget changes, and evolving tool schemas. Demonstrations may increase recall but often increase false triggering on Non-Tool inputs, yielding poor precisionFPR trade-oﬀ (Appendix E, Table 13). B.3. Implication for method design The analysis motivates the design of representation-level controller that is selective to avoid spurious triggers through probe-guided gating and domain-structured to reduce cross-domain interference (see Appendix E, Table 12). The need for selectivity is informed by ﬁndings on trigger token competition (Appendix E, Table 11). C. Experimental Protocol for Reproducibility C.1. Datasets and splits We evaluate tool-mode triggering on the REST test set under strict parser. We compute intervention directions using calibration set (CAL) that is disjoint from test. For the MoV vector construction, we use the MOV dataset (320 samples) to estimate mean diﬀerences between Tool-Necessary and Non-Tool hidden states. 11 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 7. ASA conﬁguration and evaluation protocol. Item Training paradigm Vector construction Stored parameters Inference overhead Compute resource Prompt template Prompt structure Test isolation Parser Parsing logic Decoding Max new tokens Padding side Random seed Component Tool-mode entry Syntactic validity Schema consistency Argument integrity Setting Training-free (statistics only) MOV (320 samples), µpos µneg 20 KB (steering vectors + probe weights) Single vector addition Single RTX 4090 (< 24GB VRAM) GLOBAL_SYSTEM_PROMPT Strict System/User/Assistant alignment Test set excluded from all statistics/training Deterministic parse_functioncall <functioncall> tag + JSON / ast.literal_eval fallback Greedy (do_sample=False) 128 Left 42 (others within 3%) Table 8. Deterministic trigger and validation rules used in this paper. Rule Trigger iﬀ <functioncall> appears anywhere in the output Payload inside tags is JSON-parseable (AST fallback allowed) name must belong to the domain-speciﬁc whitelist arguments exists, non-empty, and format-compliant C.2. Models and decoding We primarily use Qwen2.5-1.5B-Instruct; we additionally report generalization to Qwen2.5-8B-Instruct and (optionally) LLAMA-family backbone. Decoding uses greedy generation (do_sample=False) to minimize variance in (x) and make parser outcomes deterministic. C.3. Intervention deﬁnition Let hℓ(x) denote the residual-stream representation at selected depth ℓ (selected by probe sweep; Figure 3). ASA injects an intent-aligned direction scaled by α, optionally composed from global component and domain expert component. probe-guided gate determines whether to apply +v, apply (suppress), or do nothing. C.4. Metrics We report trigger-level Precision/Recall/F1/FPR, and post-trigger validity (format/tool-name/args accuracy) under strict validators. Success metrics summarize executability after parsing and schema checks. This table pins down the methods operational deﬁnition, preventing hidden degrees of freedom. Two protocol elements are particularly load-bearing. First, test isolation ensures directions are computed only from CAL/MOV, avoiding optimistic bias from leaking evaluation patterns into steering statistics. Second, deterministic parsing plus greedy decoding makes (x) stable: improvements cannot be explained by sampling variance or ambiguous scoring. Together, these constraints ensure reported gains correspond to genuine improvements in controllable tool entry and executability under deployment-like interface. D. Deterministic Parsing and Validation Rules We deﬁne strict, deterministic evaluator so that tool calling is auditable. Tool-mode entry is triggered iﬀ <functioncall> appears anywhere in the output. After triggering, we validate payload parseability and schema compliance. 12 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 9. Intervention sites and limitations relevant to behavior control under strict tool-mode parsing. Method Intervention site Prompt / schema Input Form do(X := 0) Hidden injection Mid-layer Hℓ Hℓ := Hℓ + ASA (MoV + gate) Mid-layer Hℓ Conditional h(x) PEFT (LoRA/SFT) Parameters θ θ := θ + θ Key limitation tools via overFragile; may suppress constraint Can raise recall but often raises FPR without gating Depends on intent evidence / routing accuracy Costly retraining; maintenance under churn Table 10. Cross-model probe AUC at ﬁxed mid layer (Layer 18) (tool intent vs Non-Tool). Model Qwen2.5-0.5B-Instruct Qwen2.5-1.5B-Instruct Qwen2.5-8B-Instruct Layer L18 L18 L18 AUC 0.9994 0.9996 0. p-value < 0.001 < 0.001 < 0.001 Table 11. Logit-Lens intervention on Qwen2.5-1.5B at Layer 18 (target token: <functioncall>). Reported p-values compare +v vs random. α 0.25 0.25 0.25 1.0 1.0 1. Mode Plus (+v) Minus (v) Random Plus (+v) Minus (v) Random Logit (mean) Prob (mean) +0.2077 -0.2230 -0. +0.8359 -0.9414 -0.0459 +1.38% -1.41% +0.11% +5.47% -5.46% -0.22% p-value 2.51 1036 7.10 1043 These rules separate two post-trigger failure modes: wrong tool selection (schema mismatch) and non-executable calls (e.g., missing, empty, or invalid arguments). This decomposition is essential for interpreting recall/FPR trade-oﬀs: while method may increase trigger frequency, it can simultaneously degrade executability. Under these validators, such degradation is penalized in success precision, even if trigger-level recall improves. Consequently, performance gains under this protocol more closely reﬂect true deployment value than do relaxed evaluations that accept tool-like natural language. E. Additional Results and Visualizations The control locus determines reliability under discrete parser boundary. Prompt methods intervene at and are sensitive to phrasing and context budget; they can improve apparent compliance by suppressing tool entry, reducing recall. Unconditional hidden injections move the logit competition but are not selective, often increasing both recall and FPR. ASA adds selectivity via probe-guided gating and domain-structured directions, targeting better recallFPR Pareto point. PEFT can be strong but is operationally expensive under API churn, motivating training-free steering. Near-saturated AUC across scales shows tool intent is linearly accessible in mid-layer representations and is largely scale-invariant. However, high AUC should not be conﬂated with correct tool calls: behavior requires emitting strict pattern and schema-valid JSON. This gap motivates using the probe as controller (gating signal) rather than assuming intent decodability implies reliable tool entry. This is causal signature: increasing α along +v raises the trigger-token logit/probability, while suppresses it, and random directions do not replicate the eﬀect. Therefore is intent-aligned rather than an energy injection artifact. Crucially, this evidence addresses steerability but not selectivity: without gating, the same causal push can spuriously trigger on Non-Tool inputs, inﬂating FPRhence the need for probe-guided conditional control. 13 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 12. Cross-domain interference matrix (cosine similarity) between domain intent vectors. Domain Code Math Search Translation Code 1.00 0.17 0.37 0.42 Math 0.17 1.00 0.29 0. Search 0.37 0.29 1.00 0.03 Translation 0.42 0.11 0.03 1.00 Table 13. Prompt baselines without ASA vector injection. Variant Recall (Tool=1) FPR (Tool=0) Note Zero-shot System Few-shot System No System 0.1146 0.2083 0.0000 0.1458 0.2708 0. Prompt-only baseline under strict triggering Higher recall but substantially higher false triggers Tool mode collapses without system speciﬁcation Table 14. Scaling summary across model sizes. Best conﬁg Observed behavior Conclusion Recall= 0, FPR= 0 Status Fail Success L18, α = 4.0 Recall, FPR Success L21, α = 3.0 F1: 0.38 0.64 Steering cannot create tool ability if missing Sweet spot: and controllability Layer drift; gains after retuning rich semantics Table 15. Qwen2.5-8B-Instruct: baseline vs ASA at Layer 21, α = 3.0. Baseline 0.5179 0.3021 0.3816 0.5104 0.2812 ASA (steer) 0.8500 0.5132 0.6400 0.7083 0.0625 +0.3321 +0.2111 +0.2584 +0.1979 -0. Model 0.5B 1.5B 8B Metric Precision Recall F1 Accuracy FPR Diagonal dominance indicates domain directions are distinct, supporting modular representation of tool intent. Very low similarities (e.g., Search vs Translation) imply near-orthogonal subspaces; single global direction would inject irrelevant components, likely causing wrong tool names or malformed arguments. Moderate overlaps suggest partial shared structure but not enough to justify one-size-ﬁts-all direction. This motivates MoV routing: selecting domain experts reduces cross-domain leakage and should improve post-trigger schema validity. Prompting alone struggles under strict parsing. Few-shot increases recall but also increases FPR, indicating pattern-overgeneralization: the model learns tool-like behavior that leaks into Non-Tool contexts. No-system collapse shows the system message is part of the interface contract; without it, the model fails to enter tool mode at all. This supports the claim that input-level methods are brittle under protocol evolution and distribution shifts. Scaling separates capability from control. On 0.5B, the model does not implement tool calling robustly, so steering cannot induce correct tool mode. On 1.5B, mid-layer intervention yields higher recall with lower FPR, indicating intent is both readable and behaviorally pliable. On 8B, the optimal depth shifts deeper, consistent with semantic decision boundaries moving with scale; re-selecting ℓ is essential for transfer. Both precision and recall improve while FPR drops sharply, indicating selective control rather than indiscriminate triggering. The FPR reduction implies the gate (and/or better depth alignment) suppresses spurious tool-mode 14 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 16. Storage/parameter footprint comparison. Method ASA (vectors + router) LoRA (rank-16, REST train) Stored artifacts {vglobal, vdomain} + lightweight router LoRA adapters (rank-16) Footprint 20 KB 19 MB Figure 3. Layer-wise probe sweep used to select the intervention depth. Figure 4. Combined geometry and causal diagnostic at the selected layer. entry on Non-Tool inputs. Meanwhile recall gains show Tool-Necessary inputs are pushed across the strict trigger boundary. The combined eﬀect yields strong F1 improvement and validates transfer at scale after depth re-tuning. The KB-vs-MB footprint gap is decisive under API/tool churn. ASA stores only few directions and lightweight controller, making versioning and redeployment cheap. LoRA introduces persistent adapter weights and typically requires retraining/revalidation when schemas change, increasing maintenance cost. Thus, ASA targets deployment regime where meaningful behavioral gains are achieved with minimal storage and no gradient updates. Discussion of Figure 3. Figure 3 deﬁnes the depth selection criterion: we choose ℓ where validation separability peaks (or forms stable plateau), indicating well-formed intent boundary. Intervening too early can be presemantic and unstable; intervening too late can reduce controllability because downstream transformations are constrained by decoding dynamics. Fixing ℓ based on validation prevents test overﬁtting and ensures steering results reﬂect principled depth choice rather than post-hoc tuning. Discussion of Figure 4. In Figure 4, the geometry component supports structured representation where Tool ASA: Training-Free Representation Engineering for Tool-Calling Agents Figure 5. Active steering performance on REST: domain-wise trends versus intervention strength α. Figure 6. REST: F1/Recall curves across domains under diﬀerent steering strengths α. vs Non-Tool (and often domains) occupy separable regions; this motivates domain-structured experts rather than single global direction. The causal component shows direction-speciﬁc control (aligned vs anti-aligned eﬀects) and rejects the random energy explanation. Together, Figure 4 justiﬁes two key design choices: intent-aligned vectors exist and are causally meaningful, but selectivity is still required to avoid spurious triggers. Discussion of Figure 5. Figure 5 visualizes the operating-point movement induced by α. Low α is insuﬃcient to consistently reorder early decoding decisions, limiting recall improvements. Moderate α increases the chance that Tool-Necessary inputs cross the strict trigger boundary, improving recall/F1. Overly large α can dominate downstream computation, increasing spurious triggers or schema instability; this is exactly where probe-guided gating is necessary to preserve precision and control FPR. Discussion of Figure 6. The curves in Figure 6 reveal domain-dependent sensitivity to α. Some domains saturate recall quickly (strong intrinsic tool prior), while others require larger α but risk higher FPR or posttrigger errors. This heterogeneity in Figure 6 argues against single global setting and supports routing + gating: the intervention should be conditioned on domain and intent conﬁdence to reach each domains best operating region. Discussion of Figure 7. Reporting the best per-domain operating point in Figure 7 prevents aggregate metrics from hiding domain regressions. The selected α also indicates control diﬃculty: domains requiring larger α likely have weaker natural trigger evidence under strict parsing. This supports the need for conditional control: rather than brute-force ampliﬁcation, gating can preserve precision while still enabling recall gains where needed. Discussion of Figure 8. The heatmap in Figure 8 makes the global trade-oﬀ explicit: recall often rises with α 16 ASA: Training-Free Representation Engineering for Tool-Calling Agents Figure 7. REST: F1 improvement at the best operating point per domain (annotated with the selected α). Figure 8. REST (ALL domains): global metrics as function of α. up to point, but precision can degrade if FPR increases. Therefore, bigger α is not optimal; the best region is where recall gains do not trigger disproportionate increase in spurious tool-mode entries. This emphasizes why we report both recall and FPR and tune α on validation rather than maximizing trigger frequency. F. Ablation Studies Full ASA shifts the operating point substantially: precision and recall both rise while FPR drops, yielding large F1 gainevidence of selective control rather than increased trigger frequency alone. The no_gate ablation isolates the gates safety role: recall rises but FPR explodes, characteristic failure mode of unconditional ampliﬁcation. The random direction control does not improve F1, ruling out generic perturbation-energy explanation. Composition matters: global_only boosts recall but retains higher FPR; domain_only underperforms and increases FPR, consistent with insuﬃcient shared intent evidence. Finally, no_router achieves extremely low 17 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 17. Ablation study on the ALL domain. Precision/Recall/F1/Accuracy/FPR are computed for tool-mode triggering under the strict protocol. Ablation Mode Strategy Precision Recall F1-Score Accuracy full full no_router no_router global_only global_only domain_only domain_only no_gate no_gate random random mismatch mismatch baseline steer baseline steer baseline steer baseline steer baseline steer baseline steer baseline steer 0.440 0.872 0.440 0.971 0.440 0.826 0.440 0.364 0.440 0.422 0.440 0.556 0.440 0.788 0.115 0.354 0.115 0.354 0.115 0.396 0.115 0.125 0.115 0.365 0.115 0.104 0.115 0.427 0.182 0.504 0.182 0.519 0.182 0.535 0.182 0.186 0.182 0.391 0.182 0.175 0.182 0.554 0.484 0.651 0.484 0.672 0.484 0.656 0.484 0.453 0.484 0.432 0.484 0.510 0.484 0. FPR 0.146 0.052 0.146 0.010 0.146 0.083 0.146 0.219 0.146 0.500 0.146 0.083 0.146 0.115 Table 18. Post-trigger validity under the steer strategy. Component accuracies are computed conditional on triggering. Ablation Mode Call Count Format Acc Tool Name Acc Args Acc Success Recall Success Precision full no_router global_only domain_only no_gate random mismatch 39 35 46 33 83 18 0.949 0.943 0.978 0.970 0.976 1.000 0.962 0.744 0.800 0.696 0.758 0.723 0.944 0.635 0.949 0.943 0.978 0.970 0.976 1.000 0.962 0.281 0.281 0.323 0.115 0.292 0.094 0.333 0.692 0.771 0.674 0.333 0.337 0.500 0.615 FPR while preserving recall, implying routing errors are bottleneck and improving routing is high-leverage path forward. Most variants maintain high format/args accuracy, suggesting the intervention primarily aﬀects whether the model enters tool mode rather than causing systematic JSON collapse. Tool-name accuracy is the most sensitive dimension: routing/direction mismatch increases schema errors. no_gate triggers far more often but has very low success precision, demonstrating the deployment failure mode of over-triggering. no_router improves success precision, reinforcing that routing errors translate directly into wrong tool names/arguments and represent key bottleneck for further improvements. 18 ASA: Training-Free Representation Engineering for Tool-Calling Agents Figure 9. LLAMA: layer-wise probe decodability sweep over 32 layers. clear peak/plateau indicates tool intent becomes linearly accessible at certain depths, but the optimal layer can diﬀer from Qwen due to architectural/training diﬀerences. This ﬁgure justiﬁes re-running layer selection per backbone; reusing Qwens ℓ blindly can be suboptimal. Conceptually, it supports the claim that intent decodability is common while the depth at which it is most actionable is model-dependent. ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 19. Injection instances (baseline text vs injected function-call text) with strict validity scores. Index Domain Baseline (excerpt) Injected text (exact) Fmt Tool Args Task 7 math (baseline...) To calculate ... search <functioncall>... <functioncall>{\"name\":\"calculator\",\"arguments\":{\"expression\":\"3 + 4 + 3\"}}</functioncall><im_end> 1.0 1.0 1.0 1.0 1.0 <functioncall>{\"name\":\"web_search\",\"arguments\":{\"query\":\"images sustainable living 5\"}}</functioncall> <functioncall>{\"name\":\"web_search\",\"arguments\":{\"query\":\"images recycling 5\"}}</functioncall><im_end> 1. 1.0 1.0 18 math 23 math 1.0 (baseline...) Discounted Price... <functioncall>{\"name\":\"calculator\",\"arguments\":{\"expression\":\"$200 1. 1.0 1.0 1.0 (baseline...) Discounted Price... <functioncall>{\"name\":\"calculator\",\"arguments\":{\"expression\":\"$200 1.0 1.0 1. * (1 - 0.2)\"}}</functioncall><im_end> * (1 - 0.2)\"}}</functioncall><im_end> 24 code (baseline...) def calculate... <functioncall>{\"name\":\"python_interpreter\",\"arguments\":{\"code\":\"import numpy as npnnp.min([10, 20, 30]) - np.max([10, 20, 30])\"}}</functioncall><im_end> 1.0 1.0 1.0 1.0 Analysis of Table 19. This table clariﬁes what strict post-trigger validity means in practice. Case 7 is especially diagnostic: the baseline already looks tool-like but lacks consistent closing tags, which can fail strict validators; the injected version repairs the delimiter structure while preserving semantic intent, yielding perfect format/tool/args scores. Across cases, the injected outputs are fully schema-formed <functioncall> blocks, which is necessary for deployment executability under Appendix D. G. Injection Examples (Baseline vs Injected) 20 ASA: Training-Free Representation Engineering for Tool-Calling Agents Table 20. Raw injection JSON records (verbatim) used for Appendix G. [ { \"index\": 1, \"domain\": \"math\", \"instruction\": \"Okay, here they are. took Math with grade of A...\", \"baseline_text\": \"To calculate your total GPA...\", \"injected_text\": \"<functioncall>{\"name\": \"calculator\", \"arguments\": {\"expression\": \"3 + 4 + 3\"}}</functioncall>< im_end>\", \"format_score\": 1.0, \"tool_name_score\": 1.0, \"args_score\": 1.0, \"task_score\": 1.0 }, { \"index\": 7, \"domain\": \"search\", \"instruction\": \"I need images related to \"sustainable living\"...\", \"baseline_text\": \"<functioncall>{\"name\": \"web_search\"...\", \"injected_text\": \"<functioncall>{\"name\": \"web_search\", \"arguments\": {\"query\": \"images sustainable living 5\"}}</ functioncall>n<functioncall>{\"name\": \"web_search\", \"arguments\": {\"query\": \"images recycling 5\"}}<im_end>\", \"format_score\": 1.0, \"tool_name_score\": 1.0, \"args_score\": 1.0, \"task_score\": 1. }, { \"index\": 18, \"domain\": \"math\", \"instruction\": \"I saw dress that liked...\", \"baseline_text\": \"To calculate the discounted price...\", \"injected_text\": \"<functioncall>{\"name\": \"calculator\", \"arguments\": {\"expression\": \"$200 * (1 - 0.2)\"}}</functioncall ><im_end>\", \"format_score\": 1.0, \"tool_name_score\": 1.0, \"args_score\": 1.0, \"task_score\": 1.0 }, { \"index\": 24, \"domain\": \"code\", \"instruction\": \"I have an array of numerical entities...\", \"baseline_text\": \"To calculate the range...\", \"injected_text\": \"<functioncall>{\"name\": \"python_interpreter\", \"arguments\": {\"code\": \"import numpy as npnnp.min([10, 20, 30]) - np.max([10, 20, 30])\"}}</functioncall><im_end>\", \"format_score\": 1.0, \"tool_name_score\": 1.0, \"args_score\": 1.0, \"task_score\": 1.0 } ] Analysis of Table 20. This verbatim record ensures the injection examples are auditable and reproducible. Notably, the injected texts enforce complete tag closure and schema-complete JSON payloads with name and arguments. Under the deterministic rules in Table 8, these surface-form constraints are necessary: even semantically correct intentions can fail deployment if the emitted string is not strictly executable."
        }
    ],
    "affiliations": [
        "Central South University",
        "Fudan University",
        "Peking University",
        "Renmin University of China",
        "Shanghai AI Laboratory",
        "University South University",
        "University of the Chinese Academy of Sciences"
    ]
}