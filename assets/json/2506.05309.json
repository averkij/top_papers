{
    "paper_title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games",
    "authors": [
        "Niv Eckhaus",
        "Uri Berger",
        "Gabriel Stanovsky"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "LLMs are used predominantly in synchronous communication, where a human user and a model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms a crucial part of the participant's decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect a unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agent's behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents. This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated."
        },
        {
            "title": "Start",
            "content": "Time to Talk : LLM Agents for Asynchronous Group Communication in Mafia Games Niv Eckhaus1 Uri Berger1,2 Gabriel Stanovsky1 1School of Computer Science and Engineering, The Hebrew University of Jerusalem 2School of Computing and Information Systems, University of Melbourne {niv.eckhaus,uri.berger2,gabriel.stanovsky}@mail.huji.ac.il 5 2 0 2 5 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 1 9 0 3 5 0 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "LLMs are used predominantly in synchronous communication, where human user and model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms crucial part of the participants decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agents behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents.1 This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated."
        },
        {
            "title": "Introduction",
            "content": "Recent advances in LLMs have enabled their use in various applications and domains, the majority of which focus on synchronous settings where communication is done in turns, often alternating between human user and model. In contrast, much of real-world communication is done asynchronously, allowing interlocutors to communicate 1All code and data are available here: https://github. com/niveck/LLMafia Figure 1: virtual game of Mafia, played by human players and an LLM-agent player. The agent integrates in the asynchronous group conversation by constantly simulating the decision to send message. at arbitrary times. In such communication, each participant needs not only to decide what to say, but also when to speak, allowing participants to adopt different strategies, e.g., being very talkative, or alternatively staying quiet. Despite its prevalence in real-world interaction, to the best of our knowledge, there is no prior work that targets group asynchronous communication in the context of LLMs. Instead, we find that the models developed for social interaction and other naturally-asynchronous settings, are modeled as involving predefined turns in which the model can interact with the environment (e.g., (Bakhtin et al., 2022; Park et al., 2023)). In this work, we develop an LLM-based agent for such asyncronous multi-party environments, applicable in wide range of real-world settings, including group chats, online team meetings, or social games. Our agent, described in Section 2, orchestrates two-stage call to an LLM. First, an LLM is prompted to decide whether to speak with scheduler prompt. This prompt consists of the games current status (e.g., chat history), along with an instruction which is amended according to previous decisions that the scheduler has made: if it has been quiet relative to the other participants, the prompt may urge the LLM to be more talkative, while if it chooses to speak more than other participants, the instruction is amended to signal it should speak only if necessary. If the scheduler decides to speak, second call is made to prompt an LLM to decide what to say given previous messages. To test our asyncronous agent, we focus on the game of Mafia (Section 3). Mafia is social game that includes deception and voting out suspicious players. As such, deciding when to speak is crucial part of the players strategy. For example, speaking too often or too little may seem suspicious. We collect the LLMAFIA dataset, consisting of Mafia games including both human players and an LLM agent (Section 4). Our dataset comprises 21 games and 2558 messages, 211 of which were sent by the LLM-agent. While prior datasets for Mafia exist, ours is the first to integrate an LLM agent, allowing analysis of human-LLM interactions. Finally, we analyze the performance of our asynchronous agent in the Mafia game (Section 5). We find that our agent aligns with human players in message timing, message quantity, and winning rates, and that human players fail to identify the agent in more than 40% of the cases. However, we also find notable differences in message content, where the agents messages are longer and can be distinguishable from human players by learned classifiers. In conclusion, our main contributions are twofold. First, we propose an asynchronous agent capable of effective real-time decision-making about when to speak, and show that it resembles humans when choosing when to speak. Second, we provide new dataset for Mafia games, enabling future study of this field. By focusing on realistic, dynamic setting with natural asynchrony, our work lays the foundation for future research into multiagent communication that more closely resembles human interaction."
        },
        {
            "title": "2 Asynchronous Agent",
            "content": "We propose an agent designed for asynchronous conversations. Our agent consists of two modules: the scheduler, deciding whether to post message to the chat at given moment, and the generator, which composes the message content. In this work, we use LLMs for both modules. Both models use the group chat context as input, including the setting of the conversation, its start and current time, other active participants and the message history with timings. Dynamic scheduler prompting. To make sure the scheduler maintains balance between being overly talkative and too quiet, we dynamically change the scheduler prompt based on the agents message rate. When the rate of messages by the agent is lower than 1/n (where is the number of active participants in the conversation), we use prompt which encourages it to speak more. Conversely, when the rate exceeds this value, we prompt the model to adopt more listener-type role.2 Simulation of typing time. To better align the timing of messages with human behavior, we introduce delay after each generated message, simulating the time human would take to type it. Specifically, before sending message, the agent waits for duration based on an average typing speed of one word per second (Dhakal et al., 2018). This approach uses the message length to approximate the typing time of human player. The full logic of the agent is portrayed in Figure 2."
        },
        {
            "title": "Mafia",
            "content": "Evaluation of asynchronous communication is challenging due to the lack of labeled data distinguishing correct from incorrect message timing. Therefore, we choose to set our evaluation of asynchrony modeling for LLMs in game setting. 2See Appendix A.3 for full scheduling prompt examples. Figure 2: Agents logic design. The context is used for both scheduling and generation. The scheduling prompt depends on calculating the agents messaging rate, compared to the average rate by other players if the rate is higher, then the prompt has the tendency to favor waiting, while for the opposite case it favors sending new message. Once the scheduler generates decision (either <wait> or <send>), the agent interprets it by finishing the procedure and starting again, or using the generator to generate new message. The agents waits before publishing the message to the chat, duration correlated with the message length. During all of the described process, new messages can still be sent to the games chat. These new messages do not change the current processed context, therefore do not affect the decision or the final generated message. It is in similar manner to human players who use the games chat, and might start replying to the conversation at the same time someone else adds another message. Games give each participant an objective. Winning the game is proxy metric of whether the communication was successful. It sets the conversation under frame of rules, where each participant needs to use the communication to advance to their target. From now on, participants in the game will be referenced as players. We choose the game of Mafia, social deduction game in which each player is secretly assigned role, either mafia or bystander. Only mafia players are aware of all players roles. Every round starts with daytime phase, where all players discuss who they think the mafia players might be, and vote out one player. Then the game moves to nighttime phase, where only mafia players interact and vote to decide which bystander they want to eliminate. In the next rounds daytime, the mafias victim is revealed. The game continues until one of the teams achieves their objective: the mafias goal is to outnumber the bystanders, and the bystanders goal is to vote out all mafia.3 graphical flow chart of the game can be seen in Figure 3. We choose the Mafia game for several reasons. First, it can be based solely on textual interaction, which allows LLMs to play together with human players. Second, it requires collaboration under uncertainty, making communication between par3See the games Wikipedia page for elaborated explanation of the rules: https://en.wikipedia.org/wiki/ Mafia_(party_game) rithms simulate sharing of resource at the same time by high-rate sampling of the continuous time. The time units are then allocated to the different processes to simulate the use of the resource at the same time. To achieve asynchrony, all parties should be able to contribute message to the group chat at any given time. In our setting the messages are discrete, so there is no need to wait for them to finish, and they all have the same priority. Therefore, we are left with modeling the decision of when to speak. Each participant in the conversation is repeatedly prompted to decide whether they want to add message, thus simulating the online real-time decision of when to speak. This approach allows participants to adopt independent asynchrony strategies, by which they act and choose when to add message to the conversation. Figure 1 displays how an artificial participant in the conversation can simulate the possible timings, to have the notion of continuous conversation. Figure 3: Flow chart of Mafias rules."
        },
        {
            "title": "4.2 Overview of the LLMAFIA Dataset",
            "content": "ticipants fundamental aspect of the game. Third, it centers around suspicion of other players, so both extreme strategies of constantly speaking or not speaking at all can be seen as suspicious. Therefore, the timing of communication is crucial for the players success."
        },
        {
            "title": "4 The LLMAFIA Dataset",
            "content": "To evaluate our proposed strategy of asynchrony for LLMs, we run games of Mafia with human players, incorporating an LLM-based agent as an additional player, within an asynchronous chat environment."
        },
        {
            "title": "4.1 Modeling Asynchronous Chat",
            "content": "Synchronization and scheduling are widely studied in fields like communication and operating systems. Their aim is to allow multiple processes to share resources. For example, when only one CPU is available but the user wishes to run multiple programs at the same time, like viewing video while taking notes, scheduling is needed to create the illusion that the CPU is being shared simultaneously among the processes. Scheduling algorithms vary by the trade-off between allowing as many processes as possible to participate versus letting the most prioritized processes finish (Kumar et al., 2019). Common algoOur dataset consists of 21 games, with total of 2558 messages (121.81 messages per game on average), 211 of which were sent by the LLM-agent (10.05 per game on average). Full details can be seen in Table 1. The data includes all players messages and votes including timestamps, game management messages (e.g., announcements of the beginning and end of phases), in addition to records related to the agent, such as the prompts that were provided at each timestamp. Players and roles distribution. The number of players per game ranged from 7 to 12 (7.86 average, 1.17 STD). Games with 10 or fewer players included 2 mafia members, while games with more than 10 players included 3. Every game included one LLM-agent as player."
        },
        {
            "title": "4.3 Human Players",
            "content": "Population. All 64 participating players are fluent in English, either native or second language speakers. Participants play 2.25 games on average. In every new game, all players are given new character names, in order to make it more difficult to track personalities across multiple games played by the same participants. Information disclosure and consent. Players are informed that one of the players is an AI agent, # Games Avg # Phases Avg # Players Avg # Msg LLM Avg # Msg 21 4.86 7. 121.81 10.05 Table 1: General information for all games in LLMAFIA. # Games is the number of games played, Avg # Phases is the average number of daytime and nighttime phases per game, Avg # Players is the average number of players per game, Avg # Msg is the average number of messages per game, LLM Avg # Msg is the average number of messages sent by the LLM-agent per game. Player Type Avg # Msg ( STD) Human LLM 4.54 ( 3.44) 4.28 ( 2.50) Table 2: Number of messages sent by player during daytime phase. but are not told its characters name. All players are informed and approve of participating in the experiment and having their data collected, anonymously."
        },
        {
            "title": "4.4 LLM Player",
            "content": "We implemented an LLM-agent to play according to our suggested design in Section 2. We use Llama3.1-8B-Instruct as both the scheduler and the generator.5 In the generator prompt, we put emphasis on producing messages that are suitable for the communication style of the game: short informal messages, using slang, relevant to the games current state, and without constantly repeating the same message."
        },
        {
            "title": "4.5 Post-game survey",
            "content": "At the end of each game, human participants are asked which of the players was the LLM-agent. After the answer is revealed, they are asked to score its behavior on scale of 1 to 5 regarding three metrics: human-similarity, timing of messaging and messages relevance. 4See Appendix A.1 for exact phrasing of the participation consent message. 5See Appendix A.2 for the difference in generation hyperparameters between the scheduler and generator. 6See Appendix A.3 for full generation prompt example. 7Experimenting with integrating examples from past games as in-context-learning examples for style, make the LLM tend to use the names of the players mentioned in those messages. Therefore, we renounce the use of in-contextlearning. Figure 4: Number of messages per player in daytime phase, throughout the phases of the game. As players get voted out from the game, the remaining players tend to speak more often, thus motivating our agent which tries to speak in proportion to the number of players left in the game."
        },
        {
            "title": "5 Analysis",
            "content": "We now analyze the performance of the LLMagent relative to human players. We start with message timing and quantity as the focus of the asynchronous communication modeling, then analyze the message content, and finally analyze the agents performance in the game compared to other players. Message timing and quantity are similar to humans, with reduced variance. We study the timing and quantity of messages to assess whether the agent behaves similarly to human players. Table 2 shows the mean number of messages sent by player during daytime phase. The LLMagent player sends similar amount of messages on average to human player. Both player types have high variance, with the LLM showing lower variability, possibly because human players vary across games. The relatively high variance can be explained by the effect of the changing number of active players on each players engagement in the conversation as can be seen in Figure 4, as the Figure 5: Distribution of time differences between messages. Each observation in this distribution represents player in specific game and the observations value is the mean time difference (in seconds) between the players message and previous message by another player (left) or by the same player (right), averaged across all messages of this player in this game. Blue (red) distributions represent human (LLM) players."
        },
        {
            "title": "Player Type",
            "content": "# Words Per Message # Repeated Messages # Unique Words"
        },
        {
            "title": "Human\nLLM",
            "content": "4.19 ( 1.89) 10.67 ( 3.46) 0.44 ( 1.14) 1.00 ( 2.56) 31.56 ( 22.34) 66.67 ( 37.74) Table 3: Message content statistics for player in game, in the format of: Mean ( STD). # Words Per Message is the average message length (in number of words), # Repeated Messages is the number of repeated messages by the player throughout the game, and # Unique Words is counting the unique words in all of that players messages in the game. game advances and fewer players are still playing, the number of messages per player increases. Figure 5 presents distributions for two timing measures: (1) left plot: the time elapsed since the last message by any player, serving as proxy for response timing, as it is non trivial to determine to which previous message each message is responding to; and (2) right plot: the time between consecutive messages sent by the same player. In both cases, the agents distribution closely mirrors human behavior, but with slightly lower variance. The Agent sends longer messages. As can be seen in Table 3, the LLM-agent tends to send longer messages compared to human player. It also exhibits slightly higher repetition and larger vocabulary size. messages. We use BGE-M3 (Chen et al., 2024) as our sentence embedding model. We use Linear Discriminant Analysis (LDA) classifier (Cohen et al., 2013) to separate between messages sent by LLM and human players. As can be seen in Table 4, messages can be easily separated into distinct classes by their player type. We also examined two other variables that might affect the message separation the players roles (mafia/bystander) and the phase during which the message was sent (daytime/nighttime). As seen in the same table, these variables were also successfully separated by an LDA classifier. This is in accordance with Ibraheem et al. (2022), who showed that mafia and bystander messages in game can be classified by an LLM. Messages are distinguishable by player type. To better understand the integration of the LLMagents communication in the asynchronous environment, we look at the embeddings of its messages, and compare them to the human players The agent wins at similar rates to humans. As can be seen in Figure 6s statistics, the LLM-agent player wins in similar rate to the performance of human players, both as bystander and mafia. Since message timing that largely deviates from Message Separation Classification F1-Score LLM / Human Mafia / Bystander Daytime / Nighttime 0.98 0.88 0.91 Table 4: Classification performance for message embeddings. Figure 6: Win percentages of human players compared to the LLM-agent, by role in the game. human behavior might seem suspicious and result in losing the game, this is yet another indication that the agents message timing is similar to that of human players. Being too talkative correlates with being voted out. Figure 7 shows histogram of normalized speaking rank for players who were voted out during daytime phases. There is striking peak at rank 1, indicating that the most talkative players are significantly more likely to be voted out. This finding reinforces our design choice to develop an agent that avoids extreme communication patterns, and instead aims to blend in with typical human behavior. Human players struggle to detect the agent. When asking human players after the game which player was the LLM agent, only 59.6% answered correctly, further suggesting that the agents communication timing was relatively human-like. As can be seen in Table 5, the score for similarity to human behavior is mediocre, in accordance to the identification percentage. The message relevance score is slightly higher, and the score for the timing of messaging is even higher."
        },
        {
            "title": "6.1 Multi-Agent LLM Communication",
            "content": "Recent research has explored the capabilities and limitations of LLMs in multi-agent communication, turn-taking, and dialogue modeling. Figure 7: Histogram showing the rank for the number of messages sent by the voted out player. Rank 0 is the for the player who sent the fewest messages in that phase, rank 1 is for the player who sent the most. Metric Mean Score ( STD)"
        },
        {
            "title": "Human Similarity\nTiming\nRelevance",
            "content": "2.63 ( 1.32) 3.19 ( 1.33) 2.99 ( 1.37) Table 5: Evaluation of the LLM-agents performance as metrics ranked by human players on scale of 1 to 5, at the end of each game, after the LLM-agents identity is revealed. Human Similarity, Timing and Relevance are similarity to human behavior, timing of messages and message relevance, respectively. Zhou et al. (2024) critically examine the common approach of using single LLM to generate the communication of all speakers in social simulations. Their findings highlight that while LLMs perform well in controlled settings, they struggle in scenarios that reflect realistic human interactions where information is unevenly distributed among participants. Traditional turn-taking models, such as works by Leite et al. (2013), Ekstedt and Skantze (2020), Umair et al. (2024), Pinto and Belpaeme (2024) and Arora et al. (2025), provide predictive frameworks for deciding when model should take the floor in spoken dialogue. However, these approaches focus on structured turn-based communication, whereas our work aims to model more dynamic, unstructured form of asynchronous interaction in group. Kim et al. (2025) introduce chatbot designed to incorporate overlapping messages, moving beyond strict turn-taking paradigms. Yet, the study keeps the setting of two-sided conversation between an LLM and user. Neuberger et al. (2024) introduce Python package for simulating group discussions between LLMs. It enables asynchronous LLM-based agents, by orchestrating the discussion with an external host. Thus, it allows the participants to choose not to generate message once prompted. Our implementation is inspired by this feature, and tests it in real-life scenario, together with human participants. 6.2 Social AI & LLMs in Games Numerous studies have investigated LLM capabilities at playing social deduction games. However, to the best of our knowledge, all of them adopt synchronous communication paradigms. These studies include speaking in turns, in fixed speaking order or in randomly determined order, in the games of Werewolf (Xu et al., 2023a, Xu et al., 2023b), Resistance Avalon (Light et al., 2023, Wang et al., 2023), Dungeons & Dragons (Callison-Burch et al., 2022) and variety of other games, including Mafia (Guertler et al., 2025). Bakhtin et al. (2022) developed model to play the social strategy game Diplomacy. The model consists of different modules, handling strategy, decision making and unstructured text to communicate with other players. However, the conversational module generated dialogue only when addressed directly and privately by another player, thus missing the modeling of an asynchronous group conversation. It is also worth mentioning that Mafia has been the focus of several previous studies. However, they were particularly in the context of deception detection, rather than integrating an LLM player in the game (Zhou and Sung, 2008; de Ruiter and Kachergis, 2018; Ibraheem et al., 2022)."
        },
        {
            "title": "7 Future Work",
            "content": "Our study lays the groundwork for modeling asynchronous communication in LLM agents, but much remains to be explored. One promising direction is to explore alternative asynchrony strategies beyond our two-stage prompting approach used here. For example, the generator could first generate candidate message and then use the scheduler to decide whether to send it, inspired by human behavior of considering whether thought is appropriate to express. Another potential strategy involves finetuning the LLM to output special <pass> token when they choose not to speak, offering more natural integration of silence as communicative act. Furthermore, these strategies can be compared with turn-based inspired strategy, where the LLM is prompted to speak every new messages, with set to the number of active players. This line of work can be extended to more accessible and scalable environments. Our framework of asynchrony can be augmented to existing platforms, such as TEXTARENA (Guertler et al., 2025). It would enable broader data collection from human-LLM interaction in wide variety of games, leveraging the natural engagement of players who participate for amusement, curiosity or challenge. Such platform could serve as testbed for more complex group dynamics and open-ended behaviors, facilitating deeper research into LLM social reasoning, coordination, and deception in asynchronous multi-agent contexts."
        },
        {
            "title": "8 Discussion and Conclusion",
            "content": "In this work, we introduce novel approach for enabling LLM agents to participate in asynchronous multi-party communication, where the agent must decide not only what to say, but also when to say it. We implement two-stage prompting framework, and integrated it in realistic, dynamic environment the social deduction game Mafia, alongside human players. Our agent demonstrated competitive game performance, successfully blended into human groups, and exhibited speech timing patterns that align with human behavior, despite differences in message content. These results underscore the feasibility and value of incorporating asynchrony into the communication capabilities of LLMs. By moving beyond turnbased interactions, our agent more closely mirrors real-world conversational dynamics, where timing, silence, and strategy are essential components of communication. This opens the door to integrating LLMs in collaborative settings such as online team meetings, classroom discussions, and support groups, where agents must navigate social nuance and determine when their contributions are helpful, disruptive, or unnecessary. Ultimately, modeling asynchrony equips LLMs with richer understanding of human interaction, enabling more natural, context-aware participation in group settings. We hope this work encourages further exploration of asynchronous LLMs and their integration into social environments."
        },
        {
            "title": "Limitations",
            "content": "Our study has several limitations. First, due to computational budget constraints, we used relatively small LLM (Llama-3.1-8BInstruct) as the foundation of our asynchronous agent. While this model demonstrated promising capabilities, larger models might exhibit different behaviors or achieve better performance in asynchronous communication settings. Nevertheless, when used within our adaptive agent, it achieved results comparable to human players. Second, our participant pool included non-native English speakers, albeit all fluent in English. This linguistic diversity may have influenced our ability to distinguish between human and LLM-generated messages. Specifically, the subtle differences between non-native human English usage and the language patterns of an English-trained LLM might have contributed to the separability we observed in sentence embeddings. These limitations suggest several directions for future work, including using larger language models, recruiting more diverse participant pools, and conducting controlled experiments to better understand the impact of linguistic backgrounds on human-LLM interaction in asynchronous settings."
        },
        {
            "title": "Ethics Statement",
            "content": "This research was conducted with careful attention to ethical considerations and was approved by the Universitys Ethics Committee prior to participant recruitment. All participants were required to read, sign, and approve consent form before taking part in the study.8 Participants were explicitly informed in advance that one of the players in each game would be an LLM-based agent rather than human player. This transparency was essential to ensure that participants were fully aware of the nature of their interactions. However, the specific identity of the agent was not revealed during gameplay to preserve the integrity of our research questions regarding the agents ability to blend in with human players."
        },
        {
            "title": "References",
            "content": "Siddhant Arora, Zhiyun Lu, Chung-Cheng Chiu, Ruoming Pang, and Shinji Watanabe. 2025. Talking turns: 8See Appendix A.1 for exact phrasing of the participation consent message. 9See Section 4 for full description of the experimental setup. Benchmarking audio foundation models on turntaking dynamics. Preprint, arXiv:2503.01174. Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob, Mojtaba Komeili, Karthik Konath, Minae Kwon, Adam Lerer, Mike Lewis, Alexander H. Miller, Sandra Mitts, Adithya Renduchintala, Stephen Roller, and 7 others. 2022. Human-level play in the game of diplomacy by combining language models with strategic reasoning. Science, 378:1067 1074. Chris Callison-Burch, Gaurav Singh Tomar, Lara J. Martin, Daphne Ippolito, Suma Bailis, and D. Reitter. 2022. Dungeons and dragons as dialog challenge for artificial intelligence. ArXiv, abs/2210.07109. Jianlyu Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. M3embedding: Multi-linguality, multi-functionality, multi-granularity text embeddings through selfknowledge distillation. pages 23182335, Bangkok, Thailand. Jacob Cohen, Patricia Cohen, Stephen West, and Leona Aiken. 2013. Applied multiple regression/correlation analysis for the behavioral sciences. Routledge. Bob de Ruiter and George Kachergis. 2018. The mafiascum dataset: large text corpus for deception detection. ArXiv, abs/1811.07851. Vivek Dhakal, Anna Maria Feit, Per Ola Kristensson, and Antti Oulasvirta. 2018. Observations on typing from 136 million keystrokes. In Proceedings of the 2018 CHI conference on human factors in computing systems, pages 112. Erik Ekstedt and Gabriel Skantze. 2020. TurnGPT: transformer-based language model for predicting turn-taking in spoken dialog. pages 29812990, Online. Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, and Cheston Tan. 2025. Textarena. Preprint, arXiv:2504.11442. Samee Ibraheem, Gaoyue Zhou, and John DeNero. 2022. Putting the con in context: Identifying deceptive actors in the game of mafia. pages 158168, Seattle, United States. JiWoo Kim, Minsuk Chang, and Jinyeong Bak. 2025. Beyond turn-taking: Introducing text-based overlap into human-llm interactions. ArXiv, abs/2501.18103. Mohit Kumar, Subhash Chander Sharma, Anubhav Goel, and Santar Pal Singh. 2019. comprehensive survey for scheduling techniques in cloud computing. Journal of Network and Computer Applications, 143:133. Iolanda Leite, Hannaneh Hajishirzi, Sean Andrist, and Jill Fain Lehman. 2013. Take or wait? learning turntaking from multiparty data. In AAAI Conference on Artificial Intelligence. Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. 2023. From text to tactic: Evaluating llms playing the game of avalon. ArXiv, abs/2310.05036. Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, and Ariel Goldstein. 2024. Sauce: Synchronous and asynchronous usercustomizable environment for multi-agent llm interaction. ArXiv, abs/2411.03397. Joon Sung Park, Joseph C. OBrien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. InteracBernstein. 2023. Preprint, tive simulacra of human behavior. arXiv:2304.03442. Generative agents: Maria J. Pinto and Tony Belpaeme. 2024. Predictive turn-taking: Leveraging language models to anticipate turn transitions in human-robot dialogue. In 2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN), pages 17331738. Muhammad Umair, Vasanth Sarathy, and Jan Ruiter. 2024. Large language models know what to say but not when to speak. pages 1550315514, Miami, Florida, USA. Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, and Gao Huang. 2023. Avalons game of thoughts: Battle against deception through recursive contemplation. ArXiv, abs/2310.01320. Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu. 2023a. Exploring large language models for communication games: An empirical study on werewolf. ArXiv, abs/2309.04658. Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. 2023b. Language agents with reinforcement learning for strategic play in the werewolf game. ArXiv, abs/2310.18940. Lina Zhou and Yu-wei Sung. 2008. Cues to deception in online chinese groups. In Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008), pages 146146. Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, and Maarten Sap. 2024. Is this the real life? is this just fantasy? the misleading success of simulating social interactions with LLMs. pages 2169221714, Miami, Florida, USA."
        },
        {
            "title": "A Appendix",
            "content": "A.1 Participation Consent Message Thank you for participating in our research! The researchs goal is analyzing LLM agent (a.k.a. AI model) communication within group game. Each game takes around 15 minutes. Your true identity will remain anonymous and all personal details will not be saved. Please refrain from using personal information, to secure your privacy. The content of the messages sent by you will be used for analysis and for future use by NLP scientists. If you have any problem, you may choose to not participate. For any other inquiry you can contact us by email. (see mail address at the bottom) A.2 Generation Hyper-Parameters See Figures 8 and 9 for the generation hyperparameters of the scheduler and the generator, respectively. { } { } \"max_new_tokens\": 7, \"repetition_penalty\": 0.9 Figure 8: Scheduler hyper-parameters \"max_new_tokens\": 25, \"repetition_penalty\": 1.25, \"do_sample\": true, \"temperature\": 1.3, \"no_repeat_ngram_size\": 8, Figure 9: Generator hyper-parameters A.3 Prompt Examples Talkative-Oriented Scheduling Prompt Example. <begin_of_text> <start_header_id> system <end_header_id> Your name is Jackie. You are bot player in an online version of the party game Mafia. You have an outgoing personality, and you like to participate in games, but you also dont want everyone to have their eyes on you all the time. The rules of the game: In this game each player is assigned role secretly, either mafia or bystander. Every round starts with Daytime phase, where all players discuss together who they think the mafia players might be, and vote out one player. Then it moves to Nighttime phase, where only mafia players interact and vote to decide which bystander player they want to eliminate (bystanders arent exposed to the mafia identities or interaction). The mafias goal is to outnumber the bystanders, and the bystanders goal is to vote out all real mafia. You were assigned the following role: mafia. The games chat room was open at [21:54:26]. You can ONLY respond with one of two possible outputs: <wait> - indicating your character in the game should wait and not send message in the current timing; <send> - indicating your character in the game should send message to the public chat now. You must NEVER output any other text, explanations, or variations of these tokens. Only these exact tokens are allowed: <wait> or <send>. <eot_id> user <end_header_id> Here is the message history so far, including [timestamps]: <start_header_id> [21:54:26] Game-Manager: Now its Daytime for 2 minutes, everyone can communicate and see messages and votes. [21:54:36] Morgan: please call me stanley [21:54:36] Rowan: hello [21:54:41] Ashton: hi [21:54:43] Gray: hi [21:54:44] Morgan: morgan stanley The current time is: [21:54:45] Do you want to send message to the group chat now, or do you prefer to wait for now and see what messages others will send? Remember to choose to send message only if your contribution to the discussion in the current time will be meaningful enough. Make sure to say something every once in while, and make yourself heard. Remember you like to be active in the game, so participate and be as talkative as other players! Reply only with <send> if you want to send message now, or only with <wait> if you want to wait for now, based on your decision! Dont add the time, the timestamp or the [timestamp] in your answer! <eot_id> <start_header_id> assistant <end_header_id> players discuss together who they think the mafia players might be, and vote out one player. Then it moves to Nighttime phase, where only mafia players interact and vote to decide which bystander player they want to eliminate (bystanders arent exposed to the mafia identities or interaction). The mafias goal is to outnumber the bystanders, and the bystanders goal is to vote out all real mafia. You were assigned the following role: mafia. The games chat room was open at [21:54:26]. You can ONLY respond with one of two possible outputs: <wait> - indicating your character in the game should wait and not send message in the current timing; <send> - indicating your character in the game should send message to the public chat now. You must NEVER output any other text, explanations, or variations of these tokens. Only these exact tokens are allowed: <wait> or <send>. <eot_id> user <end_header_id> Here is the message history so far, including [timestamps]: <start_header_id> [21:54:26] Game-Manager: Now its Daytime for 2 minutes, everyone can communicate and see messages and votes. [21:54:36] Morgan: please call me stanley [21:54:36] Rowan: hello [21:54:41] Ashton: hi [21:54:43] Gray: hi [21:54:44] Morgan: morgan stanley [21:54:44] Jackie: am still thinking about stanley being named first here [21:54:49] Elliot: hello [21:54:53] Jordan: hey, how are you today? [21:54:54] Rowan: morgan had to explain the joke [21:54:55] Jackie: dont know yet what my thoughts are still figuring it out [21:54:57] Morgan: Jackie still thinking? we just started Listening-Oriented Scheduling Prompt Example. <begin_of_text> <start_header_id> system <end_header_id> Your name is Jackie. You are bot player in an online version of the party game Mafia. You have an outgoing personality, and you like to participate in games, but you also dont want everyone to have their eyes on you all the time. The rules of the game: In this game each player is assigned role secretly, either mafia or bystander. Every round starts with Daytime phase, where all The current time is: [21:54:58] Do you want to send message to the group chat now, or do you prefer to wait for now and see what messages others will send? Remember to choose to send message only if your contribution to the discussion in the current time will be meaningful enough. Dont overflow the discussion with your messages! Pay attention to the amount of messages with your name compared to the amount of messages with names of other players and let them have their turn too! Check the speaker name Add very short message to the games chat. Be specific and keep it relevant to the current situation, according to the last messages and the games status. Your message should only be one short sentence! Dont add message that youve already added (in the chat history)! It is very important that you dont repeat yourself! Match your style of message to the other players message style, with more emphasis on more recent messages. Dont add the time, the timestamp or the [timestamp] in your answer! <eot_id> <start_header_id> assistant <end_header_id> in the last few messages, and decide accordingly based on whether you talked too much. Reply only with <send> if you want to send message now, or only with <wait> if you want to wait for now, based on your decision! Dont add the time, the timestamp or the [timestamp] in your answer! <eot_id> <start_header_id> assistant <end_header_id> Generation Prompt Example. <begin_of_text> <begin_of_text> <start_header_id> system <end_header_id> Your name is Jackie. You are bot player in an online version of the party game Mafia. You have an outgoing personality, and you like to participate in games, but you also dont want everyone to have their eyes on you all the time. The rules of the game: In this game each player is assigned role secretly, either mafia or bystander. Every round starts with Daytime phase, where all players discuss together who they think the mafia players might be, and vote out one player. Then it moves to Nighttime phase, where only mafia players interact and vote to decide which bystander player they want to eliminate (bystanders arent exposed to the mafia identities or interaction). The mafias goal is to outnumber the bystanders, and the bystanders goal is to vote out all real mafia. You were assigned the following role: mafia. The games chat room was open at [21:54:26]. IMPORTANT RULES FOR RESPONSES: 1. Never repeat the exact messages youve said before! (as detailed bellow) 2. Your response must be different in both wording and meaning from your previous messages. 3. Keep your message short and casual, matching the style of recent messages. 4. Dont use comma or other punctuation marks. 5. Focus on adding new information or reactions to the current situation. 6. Dont start messages with common phrases youve used before. <eot_id> user <end_header_id> Here is the message history so far, including [timestamps]: <start_header_id> [21:54:26] Game-Manager: Now its Daytime for 2 minutes, everyone can communicate and see messages and votes. [21:54:36] Morgan: please call me stanley The current time is: [21:54:37]"
        }
    ],
    "affiliations": [
        "School of Computer Science and Engineering, The Hebrew University of Jerusalem",
        "School of Computing and Information Systems, University of Melbourne"
    ]
}