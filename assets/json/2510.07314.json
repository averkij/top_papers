{
    "paper_title": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations",
    "authors": [
        "Fabian Paischer",
        "Gianluca Galletti",
        "William Hornsby",
        "Paul Setinek",
        "Lorenzo Zanisi",
        "Naomi Carey",
        "Stanislas Pamela",
        "Johannes Brandstetter"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to viable fusion power is understanding plasma turbulence, which significantly impairs plasma confinement, and is vital for next-generation reactor design. Plasma turbulence is governed by the nonlinear gyrokinetic equation, which evolves a 5D distribution function over time. Due to its high computational cost, reduced-order models are often employed in practice to approximate turbulent transport of energy. However, they omit nonlinear effects unique to the full 5D dynamics. To tackle this, we introduce GyroSwin, the first scalable 5D neural surrogate that can model 5D nonlinear gyrokinetic simulations, thereby capturing the physical phenomena neglected by reduced models, while providing accurate estimates of turbulent heat transport.GyroSwin (i) extends hierarchical Vision Transformers to 5D, (ii) introduces cross-attention and integration modules for latent 3D$\\leftrightarrow$5D interactions between electrostatic potential fields and the distribution function, and (iii) performs channelwise mode separation inspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely used reduced numerics on heat flux prediction, captures the turbulent energy cascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three orders of magnitude while remaining physically verifiable. GyroSwin shows promising scaling laws, tested up to one billion parameters, paving the way for scalable neural surrogates for gyrokinetic simulations of plasma turbulence."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 ] - l . s [ 1 4 1 3 7 0 . 0 1 5 2 : r GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations Fabian Paischer1, Gianluca Galletti1 William Hornsby2 Paul Setinek1 Lorenzo Zanisi2 Naomi Carey2 Stanislas Pamela2 Johannes Brandstetter1, 1 ELLIS Unit, Institute for Machine Learning, JKU Linz 2 United Kingdom Atomic Energy Authority, Culham campus 3 EMMI AI, Linz {paischer,galletti,brandstetter}@ml.jku.at github.com/ml-jku/neural-gyrokinetics"
        },
        {
            "title": "Abstract",
            "content": "Nuclear fusion plays pivotal role in the quest for reliable and sustainable energy production. major roadblock to viable fusion power is understanding plasma turbulence, which significantly impairs plasma confinement, and is vital for nextgeneration reactor design. Plasma turbulence is governed by the nonlinear gyrokinetic equation, which evolves 5D distribution function over time. Due to its high computational cost, reduced-order models are often employed in practice to approximate turbulent transport of energy. However, they omit nonlinear effects unique to the full 5D dynamics. To tackle this, we introduce GyroSwin, the first scalable 5D neural surrogate that can model 5D nonlinear gyrokinetic simulations, thereby capturing the physical phenomena neglected by reduced models, while providing accurate estimates of turbulent heat transport. GyroSwin (i) extends hierarchical Vision Transformers to 5D, (ii) introduces cross-attention and integration modules for latent 3D5D interactions between electrostatic potential fields and the distribution function, and (iii) performs channelwise mode separation inspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely used reduced numerics on heat flux prediction, captures the turbulent energy cascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three orders of magnitude while remaining physically verifiable. GyroSwin shows promising scaling laws, tested up to one billion parameters, paving the way for scalable neural surrogates for gyrokinetic simulations of plasma turbulence."
        },
        {
            "title": "Introduction",
            "content": "Nuclear fusion promises sustainable energy by fusing hydrogen isotopes in an ionized plasma. The plasma must be confined in magnetic field as it reaches hundreds of millions of degrees. During this process, turbulence usually arises due to microinstabilities, resulting in energy and particle transport towards the reactor walls. The design and control of plasma scenarios strictly require knowledge of turbulent transport, which can be obtained via nonlinear gyrokinetic simulations that evolve 5D Partial Differential Equation (PDE) over time. The computational cost of nonlinear gyrokinetic simulations is prohibitive. Therefore, QuasiLinear approaches (QL), such as QuaLiKiz (Bourdelle et al., 2015; Citrin et al., 2017) and TGLF (Staebler et al., 2007; Staebler & Kinsey, 2010), are commonly used to approximate turbulent transport. They Equal contribution 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Figure 1: Left: GyroSwin models the 5D distribution function of nonlinear gyrokinetics and incorporates integration blocks to predict 3D electrostatic potential fields and scalar heat flux. Right: ROMs (quasilinear) solve cartesian product of 2D modes in spectral space and 3D fields. Furthermore. They rely on saturation rules to approximate the nonlinear flux spectrum. are based on Reduced-Order Model (ROM) that operates in 3D and adopt so-called saturation rule to estimate nonlinear fluxes. These saturation rules usually employ free parameters that are fitted to nonlinear flux data. However, QL models neglect essential parts of the nonlinear physics that contribute substantially to evolving turbulent transport, namely zonal flows. Therefore, reliable estimate of turbulent fluxes to date is only attainable via expensive nonlinear gyrokinetic simulations. To tackle the prohibitive cost of nonlinear gyrokinetic simualtions, we introduce GyroSwin, scalable neural surrogate model to efficiently approximate turbulent transport. GyroSwin is based on three essential ingredients: (i) extension of Swin transformer (Liu et al., 2021) to 5D data, (ii) ilatent cross-attention and integration modules for interaction between 5D and 3D fields, as well as 5D 3D integration, and (iii) channelwise mode separation informed by nonlinear physics. To ground GyroSwin on physically meaningful quantities, we train it in multitask manner on the 5D distribution function and derived quantities thereof, such as 3D potential fields, and scalar fluxes. GyroSwin accurately captures nonlinear physics of 5D gyrokinetics. To verify this, we infer physical downstream quantities of the predicted 5D PDE, such as heat flux, turbulence related spectra, and zonal flows. We find that the predicted quantities align well with the ground truth for unseen simulations and GyroSwin scales favorably compared to other neural surrogate approaches. Furthermore, GyroSwin is three orders of magnitude faster than the numerical code GKW for the adiabatic electron approximation. In summary, our contributions are as follows. We introduce GyroSwin, multitask hierarchical Vision Transformer that handles data of arbitrary It is trained on the adiabatic electron approximation using channelwise mode dimensionality. separation to predict the 5D PDE, 3D electrostatic potentials, and scalar fluxes simultaneously. We propose latent cross-attention between fields of varying dimensionality, as well as integration layers that enable integrating along various dimensions of the 5D field. We demonstrate that GyroSwin captures nonlinear dynamics in the 5D field, improves timeaveraged flux predictions over state-of-the-art ROMs, and significantly outperforms deep learning surrogates on plasma turbulence modelling. We demonstrate promising scaling laws of GyroSwin, tested up to 1B parameters."
        },
        {
            "title": "2 Background and Related Work",
            "content": "5D Gyrokinetics. To determine turbulent transport, one must simulate the evolution of electrons and ions in the plasma over time. In principle, this could be achieved by modelling each species as particle in the plasma (Birdsall & Langdon, 2005; Tskhakaya, 2008). However, because the number of particles in plasma can exceed 1020, this approach is computationally expensive. An alternative 2 approach is to statistically model ensembles of particles in the plasma using distribution function. This approach is termed plasma kinetics and is desirable to analyse stability in bulk of plasma. Plasma kinetics models the time evolution of electrons and ions via the distribution function based on 3D coordinates, their parallel and perpendicular velocities, and the angle around the field lines. Gyrokinetics (Krommes, 2012) is reduced form of plasma kinetics that is more efficient by averaging out the angle around the field lines and only considering the guiding center of particle. Local gyrokinetics focuses on perpendicular spatial scales comparable to the gyroradius and on frequencies much lower than the particle cyclotron frequency, the circular motion of charged particles around magnetic field lines due to the Lorentz force. Hence, the 5D gyrokinetic distribution function can be written as = (kx, ky, s, v, µ), where kx and ky are spectral coordinates (for the spatial and y), is the toroidal coordinate along field line, and and µ represent parallel and perpendicular velocity components, respectively. The perturbed time-evolution of , for each species (ions and electrons), is governed by t (cid:124) + (vb + vD) µB B B2 v + vχ = , (1) (cid:123)(cid:122) Linear (cid:125) (cid:124) (cid:123)(cid:122) Nonlinear (cid:125) where vb is the motion along magnetic field lines, = B/B is the unit vector along the magnetic field with magnitude B2, vD the magnetic drift due to gradients and curvature in B, and vχ describes drifts arising from the force, key driver of plasma turbulence. The nonlinear term models the interaction between the distribution function and the electrostatic potential, ϕ = E, which comes from the velocity space integral of itself, and describes turbulent advection. The resulting nonlinear coupling constitutes the computationally most expensive term. Finally, is the source term that represents collisions between particles. For more detailed derivation of the gyrokinetic equation, see Section A. Quantities of interest. In practice, the main quantity of interest is the radial transport of energy (heat) towards the reactor wall, which is crucial for reactor design. It can be obtained by integrals on the 5D distribution function as (cid:90) (cid:90) = v2ϕf dvdµ dxdyds, ϕ = (cid:90) J0f dvdµ, (2) where A, Rxsy comprise geometric and operating parameters, Rvµ denotes particle energy, and J0 denotes the zeroth-order Bessel function and ϕ Rxsy is the electrostatic potential. In tokamak, largely points in the toroidal direction, kx encodes the radial direction, and ky is perpendicular to kx (binormal poloidal) in Fourier space. Electrostatic fluctuations that drive turbulence occur mainly in the ky direction, while kx encodes the radial structural properties of turbulence, i.e. the size of emerging eddies. Radial turbulent transport occurs only if the amplitude of the ky modes is non-zero, as this results in drift, and consequently in fully developed nonlinear turbulence. turbulent simulation usually follows certain pattern. In the linear phase, different modes in ky start growing due to underlying micro-instability, resulting in an initial increase in heat flux. Afterwards, the simulations enter the nonlinear (saturated) regime where modes start interacting and the system converges into statistically steady state. This state is controlled by zonal flows that shear and break up arising eddies, effectively dampening turbulence (Itoh et al., 2006). To analyse turbulence, practitioners usually investigate various spectra along the ky direction, as those provide insights into turbulent transport. Most importantly, Q(ky) provides insight into which modes dominate the turbulence energy: Q(ky) = (cid:88) Q(v.µ, s, kx, ky) , v,µ,s,kx (3) where Rvµskxky is the flux field, which aggregates to the scalar flux in Equation (2). In addition (ky) Rky describes the intensity of turbulence along y, and zonal flows dampen 2We adopt uppercase notation for vector fields and to adhere with literature. 3 turbulence resulting in the statistically steady state which can be isolated as the first mode of ϕ in ky direction: (ky) = (cid:88) s,kx ϕ(kx, s, ky)2 , ϕZF(x, t) = (cid:88) kx ϕkx, ky=0(t) eikxx. (4) Since the system converges to statistically steady state, practitioners usually investigate timeaveraged quantities of Q(ky), (ky), ϕZF, and scalar heat flux trace Q. State-of-the-art numerical approximations. Solving Equation (1) numerically is computationally expensive, especially for high-fidelity simulations across ion and electron scales. Quasilinear (QL) models mitigate the main source of computational cost and are commonly adopted in integrated modelling pipelines (Mulders et al., 2021; Citrin et al., 2024). They are based on linear simulations that neglect the nonlinear term in Equation (1) and solve for multiple for each mode in kx ky independently. This results in speedup as the order of is reduced to ˆf = (v, µ, s). As result, linear simulations do not account for interaction between modes, but only compute linear growth rates and potential transport contributions for each of them. This mode-wise transport contribution is combined via so-called saturation rules by (cid:90) = QQL(ky) ˆW (ky)dky , (5) where QQL(ky) is the flux contribution per mode, and ˆW (ky) is modelled weighting function which approximates (ky) and whose free parameters are fit to nonlinear simulations. Since QL models are based on linear simulations, they neglect nonlinear physics that substantially impact turbulence. Another limitation of QL models are operating parameter regions leading to strong turbulence (Staebler et al., 2024; Kiefer et al., 2021; Dimits et al., 2000; Bourdelle et al., 2008). Machine learning for Gyrokinetics. Machine Learning offers fruitful alternative to ROMs. Most literature to date has focused on multilayer perceptrons (van de Plassche et al., 2020; Citrin et al., 2023; Zanisi et al., 2024, MLP) or gaussian processes (Hornsby et al., 2024). They usually map from operating parameters, such as temperature or density gradients to predicted via ROMs. Hence, they are inherently limited by the capabilities of ROMs used to produce the training data. Few works have attempted to train machine learning surrogates for nonlinear gyrokinetics. Narita et al. (2022) leverage convolutional neural networks on 2D wavenumber (kx ky) slices to predict time to saturation and heat flux. Building on this idea, Honda et al. (2023) include snapshots of electrostatic potentials as additional channels. More recently, Wan et al. (2025) investigate transfer from low-fidelity to higher-fidelity simulations in reduced 1D space. Our proposed GyroSwin is fundamentally different, as it is trained directly on the 5D distribution function of nonlinear gyrokinetics. Neural surrogates. Over recent years, deep neural network-based surrogates have emerged as computationally efficient alternative in science and engineering (Thuerey et al., 2021; Zhang et al., 2023; Brunton et al., 2020), impacting weather forecasting (Kurth et al., 2023; Bi et al., 2023; Lam et al., 2023; Nguyen et al., 2023; Bodnar et al., 2024), protein folding (Jumper et al., 2021; Abramson et al., 2024), material design (Merchant et al., 2023; Zeni et al., 2025; Yang et al., 2024), and multi-physics modelling Alkin et al. (2024b). These success stories share the common thread of deep learning surrogates overcoming seemingly insurmountable challenges (Brandstetter, 2024). Especially for weather modelling, Vision Transformer (Dosovitskiy et al., 2021, ViT) and especially Swin Transformer (Liu et al., 2021) have shown exceptional performance, which manifested in the first medium-range weather modelling surpassing numerical accuracy (Bi et al., 2023), and the current state-of-the-art foundation model of the atmosphere(Bodnar et al., 2024). In gyrokinetics we face similar challenges in terms of fidelity, complexity and local couplings. However, these challenges are even exacerbated for gyrokinetics due to its 5D nature."
        },
        {
            "title": "3 GyroSwin",
            "content": "State-of-the-art ROMs neglect 5D physical phenomena that are crucial for reliable turbulent transport estimates. To remedy this, we develop neural surrogate, GyroSwin, that directly learns to evolve the 5D distribution function of nonlinear gyrokinetics over time. The most important aspect 4 (a) High-level GyroSwin architecture. (b) 5D attention, latent mixing and integrator layers. Figure 2: Left: GyroSwin receives the 5D distribution function as input and predicts the evolved 5D distribution function, as well as the respective 3D potential and heat flux at the next timestep. Right: Essential building blocks and integrator layers that enable multitask training. The latent 5D space is integrated over velocity space to obtain latent 3D field for potential prediction via cross-attention. in designing such surrogate model is scalability as nonlinear gyrokinetic equations can span multiple turbulence modalities for different species at varying resolutions. Furthermore, downstream physical quantities, such as electrostatic potential fields and scalar fluxes should be consistent with the predicted 5D field. Finally, understanding the structure of the 5D field enables us to bake inductive biases into the model architecture that improve capturing nonlinear dynamics, i.e., zonal flows. Based on these observations we pose the following desiderata for designing GyroSwin. 1. Scalability. We identify two main candidates: (1) Convolution-based (Fukushima, 1980; LeCun et al., 1989, CNN) or FNOs (Li et al., 2021), and (2) Vision Transformers (Dosovitskiy et al., 2021, ViT). To preserve locality of the 5D field, CNNs or FNOs require factorized implementations (Wang et al., 2017; Tran et al., 2023) that do not scale well (see Table 3). ViTs are in principle applicable to 5D, however flattening 5D field results in extremely long patch sequences. Due to their quadratic complexity (Vaswani et al., 2017), ViTs do not scale well to high resolution input. Hierarchical processing with linear attention, as in Swin (Liu et al., 2021), provides an efficient way to preserve locality via local window attention and was successfully applied to 3D (Liu et al., 2022) or 4D (Kim et al., 2023) input. Finally, patch embeddings can be compressed to lower resolution to facilitate scalability. 2. Modelling latent integrals. Electrostatic potentials and heat fluxes are computed as integrals (Equation (2)). We replicate this operation in the latent space of GyroSwin. To obtain the 3D latent fields, we introduce latent integrator module that aggregates over the velocity space. Similarly, taking inspiration from Equation (2), the flux prediction is based on cross-attention pooling of 3D and 5D latents. 3. Inductive biases. The main benefit of GyroSwin over ROMs is that nonlinear dynamics can be captured that severely affect emerging turbulence. To bias GyroSwin towards nonlinear zonal flows, we perform channelwise mode separation. Specifically, we separate the zonal flow mode from Equation (4) from the other modes and transfer the spectral space to real space to retain the same dimensions. Then we add real and imaginary parts of the zonal flow as additional channel. Taking into account these requirements, we design GyroSwin as Swin-based UNet (Ronneberger et al., 2015) with multiple branches to accommodate multitask predictions, and physical priors. The following paragraphs explain the main architectural components of GyroSwin. We describe them in the domain-specific case of gyrokinetics with 5D shifted Window Attention (5DWA) and 5D up/downsampling layers. Regardless, all of them are generalized to n-dimensions through adaptive window partitioning and local convolution. 5D shifted window attention. The main characteristic of Swin Transformer (Liu et al., 2021) is local attention in fixed window sizes. This has significant advantage over ViTs, reducing the quadratic complexity in token count to near-linear. More information on complexity for Swin and ViT can be found in Section H.1. The core component of GyroSwin is 5DWA In 5DWA, attention is performed across tokens within 5D windows of size (see Figure 2b). (cid:16) Mv Mvµ MsMxMy := Mv Mvµ Ms Mx My. Let Rbvvµsxyd be 5D field of batch size and hidden dimension d. After partitioning into non-overlapping windows, we obtain d, with Nwin = v/Mv vµ/Mvµ . . . denoting the numXw R(b Nwin) ber of windows. Self-attention is performed within each window in parallel across all windows. To enable interaction across neighboring windows we stack Window Multi-Head Attention (W-MSA) and Shifted Window MSA (SW-MSA) blocks. This results in approximate global attention with increasing depth. We define W-MSA for any n-dimensional as (XwW (cid:33) (cid:32) (cid:34) (cid:35) (cid:17) W-MSA(X) = o"
        },
        {
            "title": "SoftMax",
            "content": "(XwW ) , (6) )(XwW ) hheads , , where are the head-wise query, key and value projection matrices for head h, and is the output matrix. The shifted version SW-MSA is defined as spatially shifting the window partition stencil prior to Equation (6), and reversing the shift after 2 SW-MSA(x) = roll W-MSA 2 X, (cid:19)(cid:19) roll , + (7) (cid:18) (cid:18) (cid:18) (cid:19) , where roll (cid:0)X, (cid:1) is matrix roll operation, which circularly shifts each dimension of by 2 in the respective dimension. For details on batched implementation of the cyclic shift we refer to Liu et al. (2021) and Kim et al. (2023). 2 Up/Downsampling. Following (Dosovitskiy et al., 2021), we employ patch embedding to split the input into non-overlapping patches via 5D local convolution and embed them into tokens. The inputs are then spatially downsampled by the patch size and channels are projected to dimension C. The downsampling path of the UNet interleaves 5DWA blocks with patch merging layers to compress the 5D field at each stage. We extend these patch merging layers from Liu et al. (2021) to 5D: they concatenate features of 22222 neighboring patches and apply an MLP, reducing resolution by 25 times. The output dimension is set to 2C, which doubles the channels after each merge. We store intermediate feature maps for skip connections to produce hierarchical representations at different resolutions, resulting in growing receptive field and lower computational cost at lower stages. For upsampling we employ patch expansion layers, reversing the patch embedding (and merging) via linear projection and rearrangement to the original field size. Figure 2a sketches the architecture of GyroSwin, incorporating patch embedding/merging/expansion blocks along with 5DWA. Multitask training. To ensure that GyroSwin adheres to downstream integrated quantities, such as electrostatic potential fields ϕ and scalar flux Q, we add prediction tasks for each of them in addition to predicting . The ϕ-head is constructed of blocks, each of which employs an integral layer to reduce the 5D latent to 3D latent followed by 3DWA layers and expansion layers until the original spatial resolution is recovered. For the Q-head, we perform max pooling over the integrated 3D space followed by an MLP head. Importantly, we also employ latent 5D 3D mixing layers at each block to facilitate latent communication among the different heads. For multitask training of GyroSwin, we introduce loss terms for each head with weighting factors: = wf Lf ( ˆf , ) + wϕLϕ( ˆϕ, ϕ) + wQLQ( ˆQ, Q). (8) 5D3D mixing and integrator modules. Multitask training on 3D potential fields requires reducing the 5D latent space to latent 3D space. To this end, we incorporate latent integrator modules (see Vspace block in Figure 2b). They perform cross-attention between learnable 1D query R1d, which is broadcasted over the velocity space of K, R(bsxy)vµd. This procedure is reminiscent of perceiver-style pooling (Jaegle et al., 2021) with single fixed query across velocity dimensions. Moreover, we allow interaction between 3D and 5D latents via cross-attention in each block L, where Rbsxyd and K, Rb(vvµ)sxyd. Figure 2b shows an example of latent 3D 5D interaction. by swapping with and , we also obtain 5D 3D cross-attention. We stack both cross-attention layers to obtain our 53DMix bloks."
        },
        {
            "title": "4 Experiments",
            "content": "In this section we elaborate on our experimental setup, ranging from data generation to baselines and our evaluation setup. For implementation details see Section D. 6 Data Generation. We run nonlinear simulations using the numerical code GKW (Peeters et al., 2009), varying noise amplitude of initial conditions and four operating parameters, namely the safety factor q, the magnetic shear ˆs, the ion temperature gradient R/Lt and the density gradient R/Ln. To reduce the computational burden of data generation, we consider the adiabatic electron approximation at resolution of (32 8 16 85 32), i.e. we only consider turbulence originating from ion temperature gradients. We use latin hypercube sampling to uniformly populate the parameter space (McKay et al., 1979) and chose parameter regions to ensure that the resulting simulations are highly turbulent. The distribution of operating parameters and corresponding heat flux can be observed in Figure 5. We run each simulation for total of 31,920 steps, which are averaged every 40 steps and subsampled every third step, resulting in total of 266 snapshots. Each snapshot comes with two channels, representing the real and imaginary parts of the ballooning transform, commonly used for plasma coordinates. We neglect the first 80 snapshots of each simulations as those correspond to the linear phase where turbulence is not fully established yet. The entire dataset comprises 255 simulations, based on which we assemble two training subsets, one comprising 48 simulations and another one comprising 241 simulations. We use the small subset for comparison to baselines and the latter for scaling experiments. In total, this results in 44,585 training samples, of which 8880 are used for the small subset. We provide visualizations of sample snapshots of the 5D fields in Section C. Baselines. We implement three types of baselines: (i) As state-of-the-art ROM, we implement the QuaLiKiz saturation rule (Bourdelle et al., 2015) and fit it to nonlinear fluxes of our training set, similarly to Kumar et al. (2021). For details, see Section B. (ii) Tabular regressors, such as Gaussian Process Regression (GPR) for nonlinear fluxes as proposed by (Hornsby et al., 2024), and MLP trained in the same manner, akin to van de Plassche et al. (2020). (iii) Neural surrogates, trained to predict the 5D density function: Fourier Neural Operator (Li et al., 2021, FNO), PointNet (Qi et al., 2016), Transolver (Wu et al., 2024), and vanilla ViT (Dosovitskiy et al., 2021). Additional information on baselines can be found in Section D.1. Evaluation. The promise of GyroSwin is that it can replace QL approaches as it is trained on the full 5D distribution function, but maintains efficiency and scalability. To properly evaluate whether our GyroSwin yields improvements over QL models, we compile set of nonlinear simulations in high ion temperature gradient regime, ensuring strong turbulence regime. We set aside 14 of the 255 simulations that we generate in total to evaluate for in-distribution (ID) and out-of-distribution (OOD) generalization. For the ID set, we identify region in the 4D parameter set that lives within the convex hull of the training set, but is unseen to the model. Conversely, we ensure that the OOD set is not governed by the convex hull of the training simulations. In total, we compile select six simulations for the ID set and five simulations for the OOD set. The remaining three simulations are used as validation set during training. All of them are excluded from the training set."
        },
        {
            "title": "5 Results",
            "content": "As shown in Table 1 different methods are restricted to certain evaluations, i.e. tabular regressors can only be evaluated on nonlinear flux prediction (scalars), while QL models can additionally be used to evaluate for diagnostics. Neural surrogates that predict the full 5D field, such as GyroSwin, are the only class that can also be evaluated for zonal flows. In line with this observation, we provide results for each of the three categories based on their capabilities. Table 1: Comparison of different surrogate approaches by capabilities. Average Flux Zonal Flows Diagnostics Turbulence Method Tabular Regressors, e.g., GPR, MLP SOTA Reduced Numerical modelling, e.g., QL Neural Surrogates, e.g. GyroSwin (Ours) 1D0D 3D0D 5D0D 3D1D 5D1D 5D1D 5D5D 5D5D Turbulence modelling. To evaluate for 5D turbulence modelling capabilities, we perform an autoregressive rollouts with the neural surrogates and measure correlation time. Following Alkin et al. (2024a), we define correlation time as the number of snapshots that can be predicted while maintaining certain pearson correlation τ . This metric, demonstrates what methods are capable of performing stable autoregressive rollouts without drifting too far from the ground truth. We report 7 Table 2: Evaluation for 5D turbulence modelling and nonlinear heat flux prediction. We evaluate all methods across six in-distribution (ID) and five out-of-distribution (OOD) simulations. For we report RMSE of time-averaged predictions after an autoregressive rollout. For we report correlation time for autoregressive rollouts with threshold τ = 0.1. Higher correlation time is better. Method Input ID () OOD () ID () OOD () QL (Bourdelle et al., 2007) GPR (Hornsby et al., 2024) MLP FNO (Li et al., 2021) PointNet (Qi et al., 2016) Transolver (Wu et al., 2024) ViT (Dosovitskiy et al., 2021) GyroSwin (Ours) GyroSwinSmall (Ours) GyroSwinMedium (Ours) GyroSwin (Ours) SOTA Reduced Numerical modelling n/a n/a 89.53 11.76 95.22 21.57 Classical Regression Techniques n/a n/a n/a n/a 43.82 10.84 50.50 10.79 59.28 17.55 61.98 18.41 Neural Surrogate Models (48 simulations) 9.33 0.56 7.33 0.21 9.83 1.40 16.83 1.49 26.50 3.55 9.20 0.58 7.40 0.24 10.80 1.46 19.20 1.36 28.60 8. 119.88 13.15 119.93 13.15 119.93 13.15 119.63 13.13 67.68 10.28 124.96 23.27 125.05 23.29 125.05 23.28 125.13 23.29 70.48 17.21 Scaling GyroSwin to 241 simulations 98.00 27.53 94.17 21.96 110.33 19.74 76.40 17.60 91.20 18.61 111.80 23.86 23.72 4.05 37.24 9.60 18.35 1. 53.54 18.10 44.17 17.68 26.43 9.49 3D 0D 0D 3D 5D 5D 5D 5D 5D 5D 5D correlation times for the neural surrogates in Table 2. We observe clear trend that GyroSwin is by far the most stable autoregressive method compared to other neural surrogates. Remarkably, when scaling GyroSwin in terms of data and model size, we attain stable rollouts for over 100 timesteps, even for OOD simulations. 5D0D average flux. The task for this evaluation is to predict the average heat flux over the last 80 timesteps of simulation from the full 5D field after an autoregressive rollout. We present results for both ID and OOD evaluation sets in Table 2. On the reduced training set GyroSwin yields the best performance compared to the QL model and alternative 5D neural surrogates. Interestingly, most neural surrogates converge to similar heat flux Q. The reason for this is error accumulation the more noisy the predictions, the higher Q. In the extreme case, for completely random 5D field, we obtain values of > 1000. This indicates that competitors accumulate similar amount of error, leading to higher predictions for Q. Furthermore, when scaling GyroSwin to more data and larger model sizes, we observe drastic improvement in nonlinear flux prediction, achieving significantly lower error than currently existing surrogates. In Section we also show that the composition of all components of GyroSwin results in the best performance. Scalability. In integrated plasma simulations, turbulent heat fluxes must be repeatedly computed across thousands of runs, radial locations, and time intervals, underscoring the need for scalable surrogate architectures. To assess scalability of neural surrogates, we report inference speed, memory consumption, and number of parameters on single NVIDIA H100 80GB HBM3 in Table 3. We exclude the 3D FNO as it is based on collapsing velocity dimensions into channels (see Section D) which is inherently unscalable to higher resolutions. Factorized variants of FNO and CNN are also slow and memory heavy. Field-based surrogates (PointNet, Transolver) require subsampling during training and chunked inference, limiting scalability. ViTs suffer from quadratic complexity and similar memory consumption despite using half of the parameters of GyroSwin. Scaling ViT to the same parameter count as GyroSwinSmall results in 18ms inference speed which is 52.5% slower than GyroSwinSmall. GyroSwin is roughly three orders of magnitude faster than the numerical code GKW (4200 vs. 756 GFLOPs). When scaled to 1B parameters (Figure 3), GyroSwin continues to improve training and validation loss for both and ϕ prediction, demonstrating superior scalability and strong potential for higher-fidelity simulations. 5D1D flux spectrum. major advantage of quasilinear approaches over tabular regressors is physical verifiability. As they are based on 3D linear simulations, flux contributions for each mode in ky (Q(ky)) from Equation (3) can be inspected. This provides insights as to whether modes are 8 Figure 3: Scaling GyroSwin to 1B parameters trained on 241 simulations amounting to approximately 6TB of data. We show train/validation error for predicting the 5D distribution function (left) and the 3D electrostatic potential field (right). Figure 4: Left: (ky) averaged over time and OOD simulations for different 5D neural surrogates. Competitors tend to underestimate while GyroSwin matches the spectrum well with slight discrepancy on higher frequencies. Right: Time-averaged zonal flow profile for slice along across radial coordinates for selected OOD simulation. GyroSwin captures the zonal flow profile. captured that contribute most to heat transport. Similarly, we assess whether the general structure of Q(ky) is captured in predicted 5D snapshots of neural surrogates. We report pearson correlation to the ground-truth Q(ky) for all 5D neural surrogates in Table 3. We observe that all neural surrogates exhibit higher correlation than the QL approach highlighting their potential. Furthermore, we demonstrate that GyroSwin exhibits the best correlation on the OOD test cases. However, it performs slightly worse on the ID cases than competitors. When scaling GyroSwin to the large training set, we find boost in performance, resulting in almost perfect reproduction of the shape of Q(ky). This means that GyroSwinLarge captures the energy transport per-mode almost perfectly. In Figure 10 we visualize Q(ky) for all ID as well as OOD cases. As mentioned in Section 2 another useful diagnostic is the turbulence intensity spectrum (ky) which is not necessarily aligned with Q(ky), i.e. the mode transporting the most energy might not be the same where turbulence is most intense. Therefore we visually showcase (ky) in Figure 4 (left) averaged across time and all OOD cases. In addition we provide visualizations for each test case of ID and OOD separately in Figure 9. We observe that while all neural surrogates decently reproduce the shape of the spectrum, they heavily underestimate the magnitude. Furthermore, GyroSwinLarge matches shape and magnitude almost perfectly, up until few higher frequency components. We attribute this finding to the spectral bias of neural networks towards lower frequency (higher energy) modes (Rahaman et al., 2019). 9 Table 3: Evaluation for scalability, diagnostics, and nonlinear physics. We evaluate all methods across six in-distribution (ID), and five out-of-distribution (OOD) simulations. For diagnostics and nonlinear physics we report time-averaged pearson correlation for autoregressive rollout. GyroSwin is the only method that can be scaled to 1B parameters while maintaining reasonable inference speed and improving correlation to diagnostics. Method Fwd[ms] Mem[GB] Params[M] Q(ky) ID () OOD () SOTA Reduced Numerical modelling QL (Bourdelle et al., 2007) N/A N/A N/A 0.51 0.4 0.58 0. Neural Surrogate Models (48 simulations) F-CNN F-FNO PointNet (Qi et al., 2016) Transolver (Wu et al., 2024) ViT (Dosovitskiy et al., 2021) GyroSwin (Ours) 569.6 963.3 27K 18K 6.3 11.8 11.1 36.9 5.8 2.85 2.4 2.8 2.0 1.3 60.6 27.3 46.1 90.2 N/A N/A 0.61 0.04 0.62 0.05 0.56 0.05 0.59 0. N/A N/A 0.66 0.09 0.65 0.08 0.68 0.10 0.69 0.06 Scaling GyroSwin to 241 simulations GyroSwinSmall (Ours) GyroSwinMedium (Ours) GyroSwinLarge (Ours) 11.8 12.1 15.4 2.8 5.3 9.6 90.2 250.9 998. 0.84 0.09 0.74 0.06 0.87 0.10 0.84 0.08 0.78 0.11 0.92 0.07 New capability: 5D zonal flow modelling. Zonal flows have significant impact on the turbulence dynamics. To evaluate whether GyroSwin is capable of capturing zonal flows, we visualize the zonal flow profile of test case of the OOD set. We again time-average the profiles and compare to the time-averaged predicted zonal flow profile of GyroSwinLarge. We find that GyroSwinLarge accurately captures the zonal flow profile. This capability has so far been unreachable by any other surrogate modelling technique. We provide additional visualizations for each test case of the ID and OOD sets in Figure 11."
        },
        {
            "title": "6 Conclusions and Limitations",
            "content": "We present GyroSwin, scalable neural surrogate model for nonlinear gyrokinetic equations modelling turbulent transport in Plasmas. Unlike existing surrogate models, GyroSwin operates directly in 5D space and evolves the 5D distribution function of gyrokinetics. It is based on latent crossattention and integration modules for 3D5D latent interaction and trained in multitask fashion to predict the distribution function, electrostatic potentials and heat fluxes. Furthermore, we perform channelwise mode separation to incorporate an inductive bias towards essential nonlinear phenomena (zonal flows) that are essential for modelling turbulence. We show that GyroSwin outperforms reduced numerical appraoches and scales favorably compared to other neural surrogates. Furthermore, GyroSwin accurately captures nonlinear phenomena self-consistently, capability not present in prior surrogate or reduced numerical models. As result, GyroSwin offers fruitful alternative to efficient approximation of turbulent transport. Currently, the main limitation of GyroSwin is that it does not take into account the chaotic and therefore distributional nature of turbulence. Although we find that GyroSwin produces stable autoregressive rollouts over 100 timesteps, it suffers from error accumulation. Generative modelling offers remedy to this problem by directly predicting snapshots in the saturated phase. We aim to incorporate such distributional approaches in future work. Furthermore, we neglect the linear phase of the simulation. The reason for this is that our focus primarily lies in modelling turbulence. In the future we aim to extend GyroSwin to the linear phase as well. Finally, we only consider the adiabatic electron approximation, as it allows generation of relatively large training set at rather low cost. Still, each simulation produces considerable data volumes, making full coverage of the 4D parameter space difficult. Beyond that, we envision high-fidelity surrogate model by transfer learning from low-fidelity approximate simulations."
        },
        {
            "title": "Acknowledgments and Disclosure of Funding",
            "content": "We extend special thanks to our colleagues Wei Lin for the discussion on computer vision and multitask learning, and Anna Zimmel and Gerald Gutenbrunner for conversations on the spectral behavior of neural networks. The ELLIS Unit Linz, the LIT AI Lab, the Institute for Machine Learning, are supported by the Federal State Upper Austria. We thank the projects FWF AIRI FG 9-N (10.55776/FG9), AI4GreenHeatingGrids (FFG899943), Stars4Waters (HORIZON-CL6-2021-CLIMATE-01-01), FWF Bilateral Artificial Intelligence (10.55776/COE12). We acknowledge EuroHPC Joint Undertaking for awarding us access to Leonardo at CINECA, Italy, and Deucalion at MACC, Portugal."
        },
        {
            "title": "References",
            "content": "Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew Ballard, Joshua Bambrick, et al. Accurate structure prediction of biomolecular interactions with alphafold 3. Nature, pp. 13, 2024. Benedikt Alkin, Andreas Fürst, Simon Schmid, Lukas Gruber, Markus Holzleitner, and Johannes Brandstetter. Universal physics transformers. CoRR, abs/2402.12365, 2024a. doi: 10.48550/ ARXIV.2402.12365. Benedikt Alkin, Tobias Kronlachner, Samuele Papa, Stefan Pirker, Thomas Lichtenegger, and Johannes Brandstetter. Neuraldem-real-time simulation of industrial particulate flows. arXiv preprint arXiv:2411.09678, 2024b. Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian. Accurate mediumrange global weather forecasting with 3d neural networks. Nat., 619(7970):533538, 2023. doi: 10.1038/S41586-023-06185-3. C. K. Birdsall and A. B. Langdon. Plasma physics via computer simulation. New York: Taylor and Francis, first edition, 2005. Cristian Bodnar, Wessel P. Bruinsma, Ana Lucic, Megan Stanley, Johannes Brandstetter, Patrick Garvan, Maik Riechert, Jonathan A. Weyn, Haiyu Dong, Anna Vaughan, Jayesh K. Gupta, Kit Thambiratnam, Alex Archibald, Elizabeth Heider, Max Welling, Richard E. Turner, and Paris Perdikaris. Aurora: foundation model of the atmosphere. CoRR, abs/2405.13063, 2024. doi: 10.48550/ARXIV.2405.13063. C. Bourdelle, X. Garbet, F. Imbeaux, A. Casati, N. Dubuit, R. Guirlet, and T. Parisot. new gyrokinetic quasilinear transport model applied to particle transport in tokamak plasmas. Physics of Plasmas, 14(11):112501, 11 2007. ISSN 1070-664X. doi: 10.1063/1.2800869. C. Bourdelle, A. Casati, X. Garbet, F. Imbeaux, J. Candy, F. Clairet, G. Dif-Pradalier, G. Falchetto, T. Gerbaud, V. Grandgirard, P. Hennequin, R. Sabot, Y. Sarazin, L. Vermare, and R. E. Waltz. Validity of quasi-linear transport model. In Proceedings of the 22nd IAEA Fusion Energy Conference, pp. 227, Vienna, Austria, 2008. International Atomic Energy Agency. Paper TH/P87. Bourdelle, Citrin, Baiocchi, Casati, Cottier, Garbet, and Imbeaux and. Core turbulent transport in tokamak plasmas: bridging theory and experiment with QuaLiKiz. Plasma Physics and Controlled Fusion, 58(1):014036, December 2015. doi: 10.1088/0741-3335/58/1/014036. Johannes Brandstetter. Envisioning better benchmarks for machine learning pde solvers. Nature Machine Intelligence, pp. 12, 2024. Steven L. Brunton, Bernd R. Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics. Annual Review of Fluid Mechanics, 52(Volume 52, 2020):477508, 2020. ISSN 1545-4479. doi: https://doi.org/10.1146/annurev-fluid-010719-060214. Citrin, Bourdelle, Casson, Angioni, Bonanomi, Camenen, Garbet, Garzotti, Görler, Gürcan, Koechl, Imbeaux, Linder, van de Plassche, Strand, and Szepesi 11 and. Tractable flux-driven temperature, density, and rotation profile evolution with the quasilinear gyrokinetic transport model QuaLiKiz. Plasma Physics and Controlled Fusion, 59(12):124005, November 2017. doi: 10.1088/1361-6587/aa8aeb. J. Citrin, P. Trochim, T. Goerler, D. Pfau, K. L. van de Plassche, and F. Jenko. Fast transport simulations with higher-fidelity surrogate models for ITER. Physics of Plasmas, 30(6), jun 2023. doi: 10.1063/5.0136752. Jonathan Citrin, Ian Goodfellow, Akhil Raju, Jeremy Chen, Jonas Degrave, Craig Donner, Federico Felici, Philippe Hamel, Andrea Huber, Dmitry Nikulin, David Pfau, Brendan Tracey, Martin Riedmiller, and Pushmeet Kohli. Torax: fast and differentiable tokamak transport simulator in jax, 2024. A. M. Dimits, G. Bateman, M. A. Beer, B. I. Cohen, W. Dorland, G. W. Hammett, C. Kim, J. E. Kinsey, M. Kotschenreuther, A. H. Kritz, L. L. Lao, J. Mandrekas, W. M. Nevins, S. E. Parker, A. J. Redd, D. E. Shumaker, R. Sydora, and J. Weiland. Comparisons and physics basis of tokamak transport models and turbulence simulations. Physics of Plasmas, 7(3):969983, 03 2000. ISSN 1070-664X. doi: 10.1063/1.873896. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. Kunihiko Fukushima. Neocognitron: self-organizing neural network model for mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4):193202, 1980. Mitsuru Honda, Emi Narita, Shinya Maeyama, and Tomo-Hiko Watanabe. Multimodal convolutional neural networks for predicting evolution of gyrokinetic simulations. Contributions to Plasma Physics, 63(5-6):e202200137, 2023. doi: https://doi.org/10.1002/ctpp.202200137. W. Hornsby, A. Gray, J. Buchanan, B. S. Patel, D. Kennedy, F. J. Casson, C. M. Roach, M. B. Lykkegaard, H. Nguyen, N. Papadimas, B. Fourcin, and J. Hart. Gaussian process regression models for the properties of micro-tearing modes in spherical tokamaks. Physics of Plasmas, 31 (1), jan 2024. ISSN 1089-7674. doi: 10.1063/5.0174478. K. Itoh, S.-I. Itoh, P. H. Diamond, T. S. Hahm, A. Fujisawa, G. R. Tynan, M. Yagi, and Y. Nagashima. Physics of zonal flowsa). Physics of Plasmas, 13(5):055502, 05 2006. ISSN 1070-664X. doi: 10.1063/1.2178779. Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and João Carreira. Perceiver: General perception with iterative attention. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pp. 46514664. PMLR, 2021. John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. nature, 596(7873):583589, 2021. C.K. Kiefer, C. Angioni, G. Tardini, N. Bonanomi, B. Geiger, P. Mantica, T. Pütterich, E. Fable, P.A. Schneider, ASDEX Upgrade Team , EUROfusion MST1 Team , and JET Contributors . Validation of quasi-linear turbulent transport models against plasmas with dominant electron heating for the prediction of iter pfpo-1 plasmas. Nuclear Fusion, 61(6):066035, may 2021. doi: 10.1088/1741-4326/abfc9c. Peter Kim, Junbeom Kwon, Sunghwan Joo, Sangyoon Bae, Donggyu Lee, Yoonho Jung, Shinjae Yoo, Jiook Cha, and Taesup Moon. Swift: Swin 4d fmri transformer. Advances in Neural Information Processing Systems, 36:4201542037, 2023. Diederik P. Kingma and Jimmy Ba. Adam: method for stochastic optimization. In Yoshua Bengio and Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. Nikola B. Kovachki, Zongyi Li, Burigede Liu, Kamyar Azizzadenesheli, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar. Neural operator: Learning maps between function spaces with applications to pdes. J. Mach. Learn. Res., 24:89:189:97, 2023. John A. Krommes. The gyrokinetic description of microturbulence in magnetized plasmas. Annual Review of Fluid Mechanics, 44(Volume 44, 2012):175201, 2012. ISSN 1545-4479. doi: https: //doi.org/10.1146/annurev-fluid-120710-101223. N. Kumar, Y. Camenen, S. Benkadda, C. Bourdelle, A. Loarte, A.R. Polevoi, F. Widmer, and JET contributors. Turbulent transport driven by kinetic ballooning modes in the inner core of jet hybrid h-modes. Nuclear Fusion, 61(3):036005, jan 2021. doi: 10.1088/1741-4326/abd09c. Thorsten Kurth, Shashank Subramanian, Peter Harrington, Jaideep Pathak, Morteza Mardani, David Hall, Andrea Miele, Karthik Kashinath, and Anima Anandkumar. Fourcastnet: Accelerating global high-resolution weather forecasting using adaptive fourier neural operators. In Proceedings of the Platform for Advanced Scientific Computing Conference, PASC 23, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701900. doi: 10.1145/3592979. 3593412. Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, Alexander Merose, Stephan Hoyer, George Holland, Oriol Vinyals, Jacklynn Stott, Alexander Pritzel, Shakir Mohamed, and Peter Battaglia. Learning skillful medium-range global weather forecasting. Science, 382(6677):14161421, 2023. doi: 10.1126/science.adi2336. Yann LeCun, Bernhard E. Boser, John S. Denker, Donnie Henderson, Richard E. Howard, Wayne E. Hubbard, and Lawrence D. Jackel. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput., 1(4):541551, 1989. doi: 10.1162/neco.1989.1.4.541. Zongyi Li, Nikola B. Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar. Neural operator: Graph kernel network for partial differential equations. CoRR, abs/2003.03485, 2020. Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations, 2021. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021, pp. 999210002. IEEE, 2021. doi: 10.1109/ICCV48922.2021.00986. Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, and Han Hu. Video swin transformer. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022, pp. 31923201. IEEE, 2022. doi: 10.1109/ CVPR52688.2022.00320. M. D. McKay, R. J. Beckman, and W. J. Conover. comparison of three methods for selecting values of input variables in the analysis of output from computer code. Technometrics, 21(2): 239245, May 1979. ISSN 0040-1706. doi: 10.2307/1268522. OSTI 5236110. Amil Merchant, Simon L. Batzner, Samuel S. Schoenholz, Muratahan Aykol, Gowoon Cheon, and Ekin Dogus Cubuk. Scaling deep learning for materials discovery. Nat., 624(7990):8085, 2023. doi: 10.1038/S41586-023-06735-9. S. Van Mulders, F. Felici, O. Sauter, J. Citrin, A. Ho, M. Marin, and K.L. van de Plassche. Rapid optimization of stationary tokamak plasmas in RAPTOR: demonstration for the ITER hybrid scenario with neural network surrogate transport model QLKNN. Nuclear Fusion, 61(8):086019, July 2021. doi: 10.1088/1741-4326/ac0d12. E. Narita, M. Honda, S. Maeyama, and T.-H. Watanabe. Toward efficient runs of nonlinear gyrokinetic simulations assisted by convolutional neural network model recognizing wavenumberspace images. Nuclear Fusion, 62(8):086037, jun 2022. doi: 10.1088/1741-4326/ac70e8. 13 Tung Nguyen, Johannes Brandstetter, Ashish Kapoor, Jayesh K. Gupta, and Aditya Grover. Climax: foundation model for weather and climate. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pp. 2590425938. PMLR, 2023. William Peebles and Saining Xie. Scalable diffusion models with transformers. In IEEE/CVF International Conference on Computer Vision, ICCV 2023, Paris, France, October 1-6, 2023, pp. 41724182. IEEE, 2023. doi: 10.1109/ICCV51070.2023.00387. A.G. Peeters, Y. Camenen, F.J. Casson, W.A. Hornsby, A.P. Snodin, D. Strintzi, and G. Szepesi. The nonlinear gyro-kinetic flux tube code gkw. Computer Physics Communications, 180(12): 26502672, 2009. ISSN 0010-4655. doi: https://doi.org/10.1016/j.cpc.2009.07.001. 40 YEARS OF CPC: celebratory issue focused on quality software for high performance, grid and novel computing architectures. Ethan Perez, Florian Strub, Harm de Vries, Vincent Dumoulin, and Aaron C. Courville. Film: Visual reasoning with general conditioning layer. In Sheila A. McIlraith and Kilian Q. Weinberger (eds.), Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pp. 39423951. AAAI Press, 2018. doi: 10.1609/AAAI. V32I1.11671. Charles Qi, Hao Su, Kaichun Mo, and Leonidas Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. arXiv preprint arXiv:1612.00593, 2016. Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred A. Hamprecht, Yoshua Bengio, and Aaron C. Courville. On the spectral bias of neural networks. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 53015310. PMLR, 2019. Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine learning. Adaptive computation and machine learning. MIT Press, 2006. ISBN 026218253X. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Nassir Navab, Joachim Hornegger, William M. Wells III, and Alejandro F. Frangi (eds.), Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015 - 18th International Conference Munich, Germany, October 5 - 9, 2015, Proceedings, Part III, volume 9351 of Lecture Notes in Computer Science, pp. 234241. Springer, 2015. doi: 10.1007/978-3-319-24574-4_28. Paul Setinek, Gianluca Galletti, Thomas Gross, Dominik Schnürer, Johannes Brandstetter, and Werner Zellinger. Simshift: benchmark for adapting neural surrogates to distribution shifts, 2025. G. Staebler, C. Bourdelle, J. Citrin, and R. Waltz. Quasilinear theory and modelling of gydoi: rokinetic turbulent transport in tokamaks. Nuclear Fusion, 64(10):103001, sep 2024. 10.1088/1741-4326/ad6ba5. G. M. Staebler and J. E. Kinsey. Electron collisions in the trapped gyro-landau fluid transport model. Physics of Plasmas, 17(12), dec 2010. ISSN 1089-7674. doi: 10.1063/1.3505308. G. M. Staebler, J. E. Kinsey, and R. E. Waltz. theory-based transport model with comprehensive physics. Physics of Plasmas, 14(5), may 2007. ISSN 1089-7674. doi: 10.1063/1.2436852. Nils Thuerey, Philipp Holl, Maximilian Müller, Patrick Schnell, Felix Trost, and Kiwon Um. Physics-based deep learning. CoRR, abs/2109.05237, 2021. Alasdair Tran, Alexander Mathews, Lexing Xie, and Cheng Soon Ong. Factorized fourier neural operators, 2023. 14 David Tskhakaya. The Particle-in-Cell Method, pp. 161189. Springer Berlin Heidelberg, Berlin, Heidelberg, 2008. ISBN 978-3-540-74686-7. doi: 10.1007/978-3-540-74686-7_6. K. L. van de Plassche, J. Citrin, C. Bourdelle, Y. Camenen, F. J. Casson, V. I. Dagnelie, F. Felici, A. Ho, S. Van Mulders, and JET Contributors. Fast modeling of turbulent transport in fusion plasmas using neural networks. Physics of Plasmas, 27(2):022310, 02 2020. ISSN 1070-664X. doi: 10.1063/1.5134126. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 59986008, 2017. Chenguang Wan, Youngwoo Cho, Zhisong Qu, Yann Camenen, Robin Varennes, Kyungtak Lim, Kunpeng Li, Jiangang Li, Yanlong Li, and Xavier Garbet. high-fidelity surrogate model for the ion temperature gradient (itg) instability using small expensive simulation dataset. Nuclear Fusion, 65(5):054001, apr 2025. doi: 10.1088/1741-4326/adc7c9. Min Wang, Baoyuan Liu, and Hassan Foroosh. Factorized convolutional neural networks. In 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), pp. 545553, 2017. doi: 10.1109/ICCVW.2017.71. Haixu Wu, Huakun Luo, Haowen Wang, Jianmin Wang, and Mingsheng Long. Transolver: fast transformer solver for pdes on general geometries. In International Conference on Machine Learning, 2024. Han Yang, Chenxi Hu, Yichi Zhou, Xixian Liu, Yu Shi, Jielan Li, Guanzhi Li, Zekun Chen, Shuizhou Chen, Claudio Zeni, Matthew Horton, Robert Pinsler, Andrew Fowler, Daniel Zügner, Tian Xie, Jake Smith, Lixin Sun, Qian Wang, Lingyu Kong, Chang Liu, Hongxia Hao, and Ziheng Lu. Mattersim: deep learning atomistic model across elements, temperatures and pressures. arXiv preprint arXiv:2405.04967, 2024. L. Zanisi, A. Ho, J. Barr, T. Madula, J. Citrin, S. Pamela, J. Buchanan, F.J. Casson, and V. Gopakumar. Efficient training sets for surrogate models of tokamak turbulence with active deep ensembles. Nuclear Fusion, 64(3):036022, February 2024. ISSN 1741-4326. doi: 10.1088/1741-4326/ad240d. Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton, Xiang Fu, Zilong Wang, Aliaksandra Shysheya, Jonathan Crabbé, Shoko Ueda, et al. generative model for inorganic materials design. Nature, pp. 13, 2025. Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen Xie, Meng Liu, Yuchao Lin, Zhao Xu, Keqiang Yan, Keir Adams, Maurice Weiler, Xiner Li, Tianfan Fu, Yucheng Wang, Haiyang Yu, Yuqing Xie, Xiang Fu, Alex Strasser, Shenglong Xu, Yi Liu, Yuanqi Du, Alexandra Saxton, Hongyi Ling, Hannah Lawrence, Hannes Stärk, Shurui Gui, Carl Edwards, Nicholas Gao, Adriana Ladera, Tailin Wu, Elyssa F. Hofgard, Aria Mansouri Tehrani, Rui Wang, Ameya Daigavane, Montgomery Bohde, Jerry Kurtin, Qian Huang, Tuong Phung, Minkai Xu, Chaitanya K. Joshi, Simon V. Mathis, Kamyar Azizzadenesheli, Ada Fang, Alán Aspuru-Guzik, Erik J. Bekkers, Michael M. Bronstein, Marinka Zitnik, Anima Anandkumar, Stefano Ermon, Pietro Liò, Rose Yu, Stephan Günnemann, Jure Leskovec, Heng Ji, Jimeng Sun, Regina Barzilay, Tommi S. Jaakkola, Connor W. Coley, Xiaoning Qian, Xiaofeng Qian, Tess E. Smidt, and Shuiwang Ji. Artificial intelligence for science in quantum, atomistic, and continuum systems. CoRR, abs/2307.08423, 2023. doi: 10.48550/ARXIV.2307.08423."
        },
        {
            "title": "A Derivation of the Gyrokinetic equation",
            "content": "We begin with the Vlasov equation for the distribution function (r, v, t): t + + (E + B) vf = 0 (9) 15 The Vlasov equation describes the conservation of particles in phase space in the absence of collisions. Here, = (x, y, s) and = (vx, vy, vs) correspond to coordinates in the spatial and the velocity domain, respectively. Hence the Vlasov equation is 7D (including time) PDE representing the density of particles in phase space at position r, velocity v, and time. The term vf describes the response of the distribution function to accelerations of particles and (E + B) denotes the Lorentz force, which depends on particle charge and mass m, as well as electric field and magnetic field B. Finally, the advection (or convection) term vf describes transport of the distribution functon through space due to velocities. To derive the gyrokinetic equation, we transform from particle coordinates to guiding center coordinates (R, v, µ, θ), where µ = mv2 2B is the magnetic moment, θ the gyrophase, which describes the position of particle around its guiding center as it gyrates along field line, and is the coordinate of the guiding center. Assuming the time scale at which the background field changes is much longer than the gyroperiod with small Larmor radius ρ L, we can gyroaverage to remove the dependency on the gyrophase θ, yielding: t + f + f = 0 Linear Terms The unperturbed (background) motion of the guiding center is governed by: = vb + vD µ v = (10) (11) (12) Here, = B/B is the unit vector along the magnetic field, and vD represents magnetic drifts. Substituting into the kinetic equation yields t + (vb + vD) µ B v = We can express the magnetic gradient term using: = µ B = µB B B2 so that: Nonlinear Term (13) (14) (15) Fluctuating electromagnetic potentials δϕ, δA induce EB and magnetic flutter drifts. We define the gyroaveraged generalized potential as χ = ϕ A, (16) where is the aprallel component of the vector potential, denotes the gyroaverage, and is the speed of light, which is added to ensure correct units. ϕ is the electrostatic potential, the computation of which involves an integral of over the velocity space (see eq. 1.41 in the GKW manual 3 for complete description). This gives rise to the drift and yields the nonlinear advection term vχ . vχ = χ, 3https://bitbucket.org/gkw/gkw/src/develop/doc/manual/ (17) Final Equation We arrive at the gyrokinetic equation in split form: t (cid:124) + (vb + vD) (cid:123)(cid:122) Linear µB B B2 v (cid:125) + vχ (cid:125) (cid:123)(cid:122) Nonlinear (cid:124) = (18) Here, represents external sources, collisions, or other drive terms. To enhance the tractability of Equation (1), the distribution function is usually split into equilibrium and perturbation terms = f0 + δf = f0 Zϕ (cid:123)(cid:122) Adiabatic f0 + (cid:125) , t (cid:124) (cid:123)(cid:122) (cid:125) Kinetic (19) (cid:124) where f0 is background or equilibrium distribution function, the particle temperature, the particle charge, ϕ the electrostatic potential, and δf the total perturbation to the distribution function, which comprises of adiabatic and kinetic response. The adiabatic term describes rapid and passive responses to the electrostatic potential that do not contribute to turbulent transport, while the kinetic term governs irreversible dynamics that facilitate turbulence. Numerical codes, such as GKW (Peeters et al., 2009), rely on solving for δf instead of . common simplification is to assume that electrons are adiabatic, which allows us to neglect the kinetic term in the respective δf . Hence, the respective for electrons (fe) does not need to be modelled, effectively halving the computational cost."
        },
        {
            "title": "B Quasilinear models",
            "content": "We used the QuaLiKiZ saturation rule (Bourdelle et al., 2007) applied to lienar GKW simulations, following Kumar et al. (2021). The QuaLiKiz saturation rule estimates turbulent transport based on linear gyrokinetic stability analysis, using quasilinear theory and empirical saturation rules. The quasilinear ion heat flux is modelled as: (cid:88) = AkWk (20) where Ak is the linear weight spectrum that quantifies the phase relationship between electrostatic potential fluctuations and that is retrieved by solving the linear gyrokinetic equation, and Wk is the turbulence intensity spectrum which in QuaLiKiz is parametrised by shape function Sk and normalisation factor calibrated on nonlinear gyrokinetic simulations. To fit the nomalisation factor C, we assume access to vector of nonlinear fluxes Rj and set the right-hand side of Equation (20) to Rj, then the optimal solution for can be obtained via least-squares fit = . (21) (cid:80) xjqj x2 (cid:80) In our setup, we used flux estimates from the small training set (48 simulations) to compute the fit that resulted in = 7.93. This value differs slightly from the one reported in Kumar et al. (2021). We attribute the difference to the different sampling strategy of simulations. The QuaLiKiz saturation rule retains key physics from gyrokinetics while allowing efficient prediction of turbulent transport in integrated modelling frameworks. Furthermore, we found it beneficial to center the nonlinear flux vector which alters the normalisation constant C, but leads to reduced error on flux predictions on separate validation set."
        },
        {
            "title": "C Data Generation and Visualisation",
            "content": "Data Generation. 17 Figure 5: Distribution of input parameters ˆs, q, R/Ln, and R/Lt along with average heat flux Q. The sampled parameter space is evenly distributed. In this work we mainly consider turbulence driven by ion temperature gradients. We leverage the numerical code GKW (Peeters et al., 2009) for generating nonlinear and linear Gyrokinetic simulations, by varying four parameters: R/Lt, R/Ln, ˆs, and q, which significantly affect emerging turbulence in the Plasma. R/Lt is the ion temperature gradient, which is the main driver of turbulence. Larger values of R/Lt always result in stronger turbulence (see Figure 5). R/Ln is the density gradient, whose effect is less pronounced. It can have stabilizing effect, but can sometimes also lead to enhanced turbulence. The parameter denotes the so-called safety factor, which is the inverse of the rotational transform and describes how often particle takes poloidal turn before taking toroidal turn. ˆs denotes magnetic shearing, hence it usually has stabilizing effect as more magnetic shearing results in improved isolation of the Plasma. We specify the ranges for sampling the four parameters as R/LT [1, 12], R/Ln [1, 7], [1, 9], and ˆs [0.5, 5]. Additionally, we also vary the noise amplitude of the initial condition within [1e 5, 1e 3] and the initial condition itself as one of [sin, cos, random]. We first generated the nonlinear simulations and then use the same parameter combination for each linear simulation. Thel linear simulations are required for implementing the quasilinear model. 5D Data Visualization. We show visual illustration of the 5D distribution function in Figure 6. For visualization purposes, we always show combinations of the different axes while averaging or Figure 6: Visualization of the 5D distribution function of nonlinear gyrokinetics (ground truth, Fourier space along kx and ky). We show different combinations of axes of the 5D field while averaging over the remaining ones for different timesteps. Colorbars are shared columnwise. slicing across the remaining ones. This way, we end up with 2D planes that are easy to visualize. The time evolution of the 5D field clearly shows that interaction between modes grows with time. The figure shows three different timesteps, where the first one is still in the linear phase, while the last one is well into the saturated phase. This illustrates the growth in magnitudes, as the simulation progresses in time. Furthermore, we also highlight the difference between nonlinear and linear simulations in Figure 7. We plot 2D planes of the 5D field of nonlinear and linear simulations side-by-side for three different timesteps. Since colorbars are shared across each pair of 2D planes, the difference between nonlinear and linear simulations can be clearly observed. Specifically, the structure in the linear simulation is symmetric, while the nonlinear simulation exhibits asymmetries. Furthermore, the difference is particularly obvious in wavenumber space, where (1) magnitudes of nonlinear simulations are much larger, and (2), there is lot more interaction between modes. Hence, there is structure in the nonlinear simulations that is not captured in linear ones, which is drawback of approximations based on linear simulations, i.e. for quasilinear models."
        },
        {
            "title": "D Implementation details",
            "content": "Data preprocessing. first measure we take is standardizing all fields and fluxes to zero mean and unit variance. We observed that this positively affects training. To enable autoregressive rollouts, we simply accumulate all statistics across all training simulations, and use them to normalize and denormalize during inference. Furthermore, another measure that had significant impact on training dynamics is transferring from spectral kx, ky coordinates to real x, y. This makes normalization easier within the 5D cubes. While electrostatic potential fields coming from GKW are already in real space, they are padded for the real FFT and result in different spatial dimensions to the 5D distribution function. This is inconvenient for up/downsampling, so we unpad the Fourier-space electrostatic potentials to match spatial dimensions of the 5D field, before transforming them back 19 Figure 7: Comparison of 5D distribution functions for linear and nonlinear simulations (ground truth, Fourier space along kx and ky). We show different combinations of axes of the 5D field while averaging over the remaining ones for different timesteps. Colorbars are shared across each 2D nonlinear and linear plane. to real space. After preprocessing, we could reduce the size of the training dataset from an overall 15TB to 2.2TB. GyroSwin. Vision Transformers usually employ convolutions for patch operations (Dosovitskiy et al., 2021; Liu et al., 2021, 2022), but they are not scalable to 5D. Whereas in convolutions the kernel is shared across every location, this is harder to parallelize in general nD setting. Therefore, we employ less parameter efficient local convolutions with kernels are independent at each location, implemented through fully connected layers. N-dimensional input grids are first tiled with adaptive reshapes, then the flattened patch dimension is embedded with shallow MLP. Patch embedding, merging, and expansions are implemented as linear layers or MLPs. Furthermore, we add relative positional biases and condition all Swin layers on the 4 parameters as well as the current timestep via FiLM (Perez et al., 2018). We experimented with DiT-style conditioning (Peebles & Xie, 2023), but found no improvements despite the additional parameter cost. We train GyroSwin for next-step prediction of the 5D distribution function of nonlinear gyrokinetic simulations. We use the Adam optimizer (Kingma & Ba, 2015) with weight decay of 1e-5 and cosine learning rate scheduler with linear warmup with peak at 3e-4, decayed to 0. During training we employ automatic mixed precision and gradient clipping to magnitude of 1. Due to the bulk of training data we perform lazy dataloading which results in substantial overhead, however it is not possible to fit all data in RAM. In our special case of adiabatic electrons, each direction in the magnetic moment µ is independent of each other. Therefore, this dimension can be decoupled from the remaining ones and viewed as additional channels. This is not an approximation, and results in substantial speedup without any loss of information. We train our model for 200 epochs and evaluate every 20 epochs on the three holdout trajectories based on which we perform model selection. During inference, we roll out the model autoregressively for the entire duration of each simulation (185 timesteps). GyroSwin is trained on four H100 GPUs with 80GB VRAM using PyTorchs Distributed Data Parallel (DDP) for approximately 120 hours. D.1 Baselines Gaussian Process Regression (GPR). We use four-parameter GPR trained on the physical parameters (R/LT , R/Ln, q, and ˆs). It uses Matern 3/2 kernel (Rasmussen & Williams, 2006) to predict the nonlinear flux. This is the model proposed by Hornsby et al. (2024). Multi-Layer Perceptron (MLP). We use 3 layer MLP with 128 hidden dimension and GELU activations. The inputs are the four physical parameters (R/LT , R/Ln, q, and ˆs), which are em20 Figure 8: Side-by-side comparison of autoregressive rollout predictions with GyroSwin compared to ground truth (x and in real space), in the saturated phase with shared colorbars. GyroSwin preserves the high-level structure within the first rollout steps. After larger amount of rollout steps error accumulates, but predictions remain stable and do not diverge. bedded in continuous sin-cos space, and the output is the time-averaged scalar heat flux. This is similar to QLKNN proposed by van de Plassche et al. (2020), but trained on nonlinear fluxes instead of quasiliner ones. FNO. The neuraloperator library4 (Kovachki et al., 2023) contains tensorized nD implementations of Fourier convolution layers. However, as shown in ?? these are too expensive to be reliably trained on our data. To enable training FNO (Li et al., 2020), we utilize much faster 3D FNO which operates only on the spatial dimensions, while flattening the velocity space in the channels. This baseline has 256 latent dimension, 4 layers and considers 1 2 of the total modes on each dimension (5,004 flat spatial modes). PointNet. We use PointNets (Qi et al., 2016) implementation from SIMSHIFT (Setinek et al., 2025), adapted to work on regular grid data. The total number of points on the grid is approximately 1.1M. Therefore, to train this coordinate-based baseline, we randomly subsample the grid to 65,536 points. The hidden dimension is 256, and GELU activations are used. Additionally to the original architecture, we embed positions in sincos space and condition it on the physical parameters. Finally, as the task is to predict the evolution of the distribution function, we provide its values at the corresponding coordinates at time to predict those for + 1. Transolver. We use Transovers (Wu et al., 2024) implementation from SIMSHIFT (Setinek et al., 2025), adapted to work on regular grid data. As for PointNet, the inputs are subsampled to 65,536 points. The Transolver base is set to 256 with 4 layers, and GELU activations. Again, we additionally provde the values for the distribution function at time as input to predict the values at + 1."
        },
        {
            "title": "E Additional Results",
            "content": "Finally, we include qualitative results for autoregressive rollouts of GyroSwin. Specifically, we visualize model predictions for for the test case ID1 and compare it to the ground truth in Figure 8 for timesteps {10, 100, 200}. We observe that the overall structure is more or less preserved within the first 10 rollout steps, however, afterwards the model suffers from error accumulation. This is especially pronounced for the velocity space, where the model seems to overpredict. Interestingly, though, the predictions in wavenumber space remain somewhat stable and do not diverge, evan after 100 autoregressive prediction steps. Generally we can say that GyroSwin yields stable predictions for long rollouts well beyond 100 timesteps. 4https://github.com/neuraloperator/neuraloperator 21 (a) ID (b) OOD Figure 9: Comparison of (ky) In-Distribution and Out-Of-Distribution. (a) ID (b) OOD Figure 10: Comparison of flux spectra In-Distribution and Out-Of-Distribution."
        },
        {
            "title": "F Diagnostics",
            "content": "We provide visualizations for the time-averaged turbulence-intensity spectrum (ky) for the six different ID test cases in Figure 9a and the five different OOD test cases in Figure 9b. Furthermore, we show flux spectra Q(ky) for the six different ID test cases in Figure 10a and the five different OOD test cases in Figure 10b. Generally, we observe that GyroSwin susbtantially improves over the state-of-the-art reduced-numerical quasilinear model on (ky), which is reflected in the pearson correlation coefficients shown in Table 3. Interestingly, the fit for Q(ky) at first glance appears to be improved as well, however the correlation is approximately the same as for the quasilinear model. The reason for this is that high-frequencies are not well captured by GyroSwin. We expect this to be result of the inherent spectral bias of neural network architectures (Rahaman et al., 2019). In addition to the time-averaged spectra, we provide visualizations for the time-averaged zonal flow profile for all ID simulations as well as OOD simulations for GyroSwinLarge. We observe that GyroSwinLargeusually tends to overestimate the amplitude therefore we normalize it for visualization purposes. The results for the ID and OOD test cases can be observed in Figure 11a, and Figure 11b, respectively. Generally, we observe that the predicted zonal flow profile of GyroSwinLargeappears as smoothed out version of the ground-truth. Again, our intuition is that this is due to the inherent lowfrequency bias. Interestingly, on some test cases the zonal flow profile is entirely off, which explains the rather high variance observed in the main table. Overall, we can conclude that GyroSwinLarge 22 (a) ID (b) OOD Figure 11: Comparison of zonal flow profiles In-Distribution and Out-Of-Distribution. can capture the zonal flow of unseen simulations in an autoregressive manner even though there is plenty of room for improvement."
        },
        {
            "title": "G Ablation Studies",
            "content": "To justify the design choices of GyroSwin, we conduct set of ablation studies as follows. We progressively add components of GyroSwin to 5D Swin transformer and evaluate based on correlation time to the 5D distribution function and RMSE for the time-averaged flux trace Q. We report our results in Section G. Interestingly, the 5D-Swin already appears to be capable of performing stable rollouts, however it completely fails in capturing the nonlinear flux trace. When moving to UNet like structure, we observe slight drop in correlation time, but improved flux predictions. Furthermore, adding channelwise mode separation gives boost in correlation time, particularly on OOD simulations. Moreover, there is slight improvement in correlation time when adding our latent cross-attention and integrator modules. Finally, the most significant boost is observed when adding the flux prediction head, which results in our final design of GyroSwin, which achieves the best combination of stable autoregressive rollouts and nonlinear flux prediction. Table 4: Ablation study on different components in GyroSwin, i.e. channel-wise mode separation of zonal flows and latent cross-attention/integrator modules. We report correlation time with τ = 0.1 for the 5D distribution function and RMSE for on ID and OOD test cases. All methods are trained on reduced dataset of 48 simulations. Method Params [M] ID () OOD () ID () OOD () 5D-Swin GyroSwinf GyroSwinf + ZF channel GyroSwinf +ϕ GyroSwinf +ϕ + LatentCA GyroSwinf +ϕ+ 46.2 36.3 44.2 77.8 87.3 91. 24.83 3.19 19.50 1.86 19.33 1.84 20.17 0.75 21.00 2.62 22.83 2.63 25.00 2.39 18.60 0.51 22.00 2.26 21.80 1.20 22.80 2.89 25.00 0.71 121.34 13.36 119.85 13.15 119.19 13.65 106.26 14.09 116.49 12.81 67.68 10.28 125.74 23.23 124.91 23.2 122.76 23.63 112.95 25.22 121.41 23.45 70.48 17."
        },
        {
            "title": "H Learning a saturation rule",
            "content": "We perform an additional ablation study where we discard the nonlinear term in Equation (1), e.g. train GyroSwin on linear simulations to predict nonlinear fluxes. This effectively mirrors saturation in the Quasilinear setting, except that it does not rely on growth rates and reconstruction of the ky spectrum. Since linear simulations essentially converge to fixed structure in the statistically steady state, we only use the last snapshot of simulation and provide it as input to the model to predict 23 the average nonlinear flux Q. We call this ablation variant GyroSwinLinearand compare it to the Quasilinear saturation rule. Since this baseline is relatively cheap to train, we train it for both training sets, containing 48 and 241 simulations and report our results in Equation (5). Remarkably, we observe that the learned saturation rule consistently outperforms the quasilinear saturation rule. This is surprising because the QL baseline uses linear growth rates of modes and flux contributions per mode to infer the nonlinear flux transport, while GyroSwinLinear is entirely deprived of this information. Furthermore, since there is nonlinear term in these equations we can conclude that the learned saturation rule is capable of generalizing over linear mode structures to infer nonlinear fluxes. Finally, we observe substantial improve in RMSE for both ID and OOD test cases when trained on the larger dataset comprising 241 simulations. Table 5: Learning saturation rule with GyroSwin. We report RMSE for the average flux on ID and OOD test cases. Method QL48 sims QL241 sims ID () OOD ()"
        },
        {
            "title": "Reduced numerical methods",
            "content": "89.53 11.76 40.74 7.47 95.22 21.57 53.30 14.77 Learned saturation rule GyroSwinLinear (48 sims) GyroSwinLinear (241 sims) 68.56 10.09 38.03 10.73 72.62 15.86 31.19 8. H.1 Vision Transformer Complexity Computational complexity of 5D swin layers, with an input of resolution k, channels and window size (assumed square for simplicity) is O(MSA) = 4 (xyzhw)2 d2 + 2 (xyzhw)2 O(W-MSA) = 4 xyzhw d2 + 2M 5 xyzhw removing the squared dependency on the sequence length xyzhw, and replacing it with much smaller window complexity of 5. This consideration is the motivation behind the original swin paper by (Liu et al., 2021), as it makes attention on images close to linear in resolution."
        }
    ],
    "affiliations": [
        "ELLIS Unit, Institute for Machine Learning, JKU Linz",
        "EMMI AI, Linz",
        "United Kingdom Atomic Energy Authority, Culham campus"
    ]
}