{
    "paper_title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework",
    "authors": [
        "Ziyuan Liu",
        "Ruifei Zhu",
        "Long Gao",
        "Yuanxiu Zhou",
        "Jingyu Ma",
        "Yuantao Gu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Deep learning has achieved significant success in the field of remote sensing image change detection (CD), yet two major challenges remain: the scarcity of sub-meter, all-inclusive open-source CD datasets, and the difficulty of achieving consistent and satisfactory detection results across images with varying change areas. To address these issues, we introduce the JL1-CD dataset, which contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5 to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation (MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD datasets demonstrate that the MTKD framework significantly improves the performance of CD models with various network architectures and parameter sizes, achieving new state-of-the-art results. The code is available at https://github.com/circleLZY/MTKD-CD."
        },
        {
            "title": "Start",
            "content": "IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 1 JL1-CD: New Benchmark for Remote Sensing Change Detection and Robust Multi-Teacher Knowledge Distillation Framework Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, and Yuantao Gu, Senior Member, IEEE 5 2 0 2 9 ] . [ 1 7 0 4 3 1 . 2 0 5 2 : r AbstractDeep learning has achieved significant success in the field of remote sensing image change detection (CD), yet two major challenges remain: the scarcity of sub-meter, all-inclusive open-source CD datasets, and the difficulty of achieving consistent and satisfactory detection results across images with varying change areas. To address these issues, we introduce the JL1-CD dataset, which contains 5,000 pairs of 512 512 pixel images with resolution of 0.5 to 0.75 meters. Additionally, we propose multi-teacher knowledge distillation (MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD datasets demonstrate that the MTKD framework significantly improves the performance of CD models with various network architectures and parameter sizes, achieving new state-of-the-art results. The code is available at https://github.com/circleLZY/MTKD-CD. Index TermsKnowledge distillation, change detection, remote sensing. I. INTRODUCTION Remote sensing image change detection (CD) is technique used to detect and analyze surface changes by leveraging multi-temporal data [1]. Over the past few decades, it has been extensively studied and has become crucial tool for Earth surface observation. CD plays significant role in various fields, including land-use change updates, natural disaster assessment, environmental monitoring, and urban planning. Early traditional CD methods primarily relied on image processing techniques, detecting changes by directly comparing pixel values or spectral features between multi-temporal images. Examples include Image Differencing [2], Change Vector Analysis (CVA) [3], Principal Component Analysis (PCA) [4], KauthThomas (KT) transforms [5], and Multivariate Alteration Detection (MAD) [6]. While these methods are simple and intuitive, they exhibit limited performance when handling complex change patterns, such as those affected by significant noise, lighting variations, or seasonal differences. With the rise of machine learning (ML), CD methods began to incorporate feature extraction and classifiers. Common techniques include Support Vector Machines (SVM) [7], Random Forest (RF) [8], K-means clustering [9] and so on. These machine learning approaches significantly improved detection Ziyuan Liu and Yuantao Gu are with the Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China (e-mail: liuziyua22@mails.tsinghua.edu.cn; gyt@tsinghua.edu.cn). Ruifei Zhu, Long Gao, Yuanxiu Zhou, and Jingyu Ma are with Chang Guang Satellite Technology Co., Ltd. (CGSTL) Changchun 130102, China (e-mail: zhuruifei@jl1.cn; gaolong1056@jl1.cn; zhouyuanxiu@jl1.cn; majingyu@jl1.cn). (Corresponding author: Yuantao Gu.) accuracy but heavily relied on high-quality labeled data and manually designed features. In recent years, the rapid advancement of deep learning (DL) has revolutionized remote sensing CD, delivering substantial performance breakthroughs. DL-based CD methods generally involve three steps: (1) extracting change features from image pairs, (2) generating change maps based on the extracted features, and (3) predicting labels based on the feature maps. Convolutional Neural Networks (CNNs), which achieved remarkable success in image processing, were the first neural network architecture applied to remote sensing CD and remain widely optimized and utilized today [10] [12]. With the introduction of Transformers, some studies have explored their application in CD tasks [13], [14]. More recently, Foundational Model (FM) has emerged as novel paradigm, aiming to achieve multi-task and multidomain generalization through large-scale pretraining [15]. There have been works utilizing remote sensing data to finetune pretrained models such as Vision Transformers (ViT) [16], Segment Anything Model (SAM) [17], and Contrastive Language-Image Pretraining (CLIP) [18], achieving higher performance in CD tasks [19][22]. Several semi-supervised methods have also been proposed, further improving CD performance under limited labeled data. Zhang et al. [23] propose novel multilevel consistency-regularization-based semi-supervised CD approach, incorporating Fourier-based frequency transformation and dynamic pseudolabel selection scheme to mitigate background noise and improve unlabeled data utilization. Xu et al. [24] introduce semi-supervised label and embedding consistency network (SS-LEC) for ORSI scene classification, which strategically enforces consistency across augmentations and stages of training. Li et al. [25] propose SemiCD-VL, VLM-guided semi-supervised change detection method that synthesizes pseudo labels via mixed change event generation strategy, achieving significant performance gains over FixMatch and SOTA unsupervised methods. However, DL-based CD methods generally face two major challenges: the scarcity of high-quality, high-resolution, all-inclusive CD datasets and limitations in handling highly dynamic change areas. Although numerous CD datasets have been constructed and proposed, they are often tailored to specific scenarios, which restricts the generalization capabilities of the algorithms. For instance, models trained on datasets focused on human-induced changes often fail to perform effectively when confronted with natural change scenarios. On the other hand, the learning capacity of these models IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 2 Fig. 1. Timeline of the development of mainstream DL-based CD methods. is inherently limited. Most existing algorithms rely on single-phase training approach, typically end-to-end training, supplemented by techniques such as learning rate decay. While such training strategies can achieve satisfactory results within the models performance constrained range of changes, significantly degrades when addressing scenarios with wide variations in change areas, ranging from no change to complete change. To address the aforementioned challenges, we construct new large-scale, high-resolution, all-inclusive open-source CD dataset, named JL1-CD (named after the Jilin-1 satellite). This dataset comprises 5,000 pairs of 512 512 images captured in China, with resolution of 0.50.75 meters, along with binary change labels at the pixel level. The JL1-CD dataset not only includes common human-induced changes such as buildings and roads but also encompasses various natural changes, such as forests, water bodies, and grasslands. Additionally, we propose multi-teacher knowledge distillation (MTKD) framework for change detection optimization. First, we introduce the O-P strategy. To address the difficulty of handling highly dynamic change areas in existing algorithms, we propose the concept of the Change Area Ratio (CAR) and partition the dataset based on different CAR levels. CD models are then trained on each partition, reducing the learning burden on individual models, thereby achieving better training outcomes and higher detection accuracy. Next, to lower the computational and time complexity during inference, we extend the O-P strategy by training student model under the MTKD framework. The student model learns the strengths of teacher models optimized for various CAR scenarios, achieving superior detection accuracy without increasing resource consumption during inference. Our main contributions are as follows: 1) We introduce JL1-CD, new sub-meter, all-inclusive opensource CD dataset comprising 5,000 pairs of remote sensing image patches with resolution of 0.50.75 meters. 2) We propose the O-P strategy, which partitions the training of CD models based on CAR levels, significantly improving performance across diverse CAR scenarios. 3) We further develop the MTKD framework, where models trained under the O-P strategy serve as teacher models. The student model trained under the supervision of multiple teachers achieves superior detection accuracy without additional computational or time costs during inference. 4) Extensive benchmarking experiments on existing algorithms demonstrate that O-P and MTKD significantly enhance performance across various architectures and parameter sizes, achieving new state-of-the-art (SOTA) results. II. RELATED WORKS A. Traditional and ML-Based CD Traditional CD methods have been extensively studied in remote sensing, with early approaches relying on simple algebraic operations such as image differencing [2] and image ratioing [26]. These techniques compute pixel-level differences or ratios between two images and apply threshold to identify change regions. Subsequent advancements introduced improved thresholding strategies, such as the Otsu method [27] and the normalized difference vegetation index (NDVI) IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 3 algorithm [28], to enhance detection accuracy. Transformbased methods, such as PCA [4] and MAD [6], were later adopted, leveraging statistical properties of images. However, these methods are heavily dependent on image statistics, which limits their scalability and precision in large-scale, highresolution CD applications. The advent of machine learning has significantly enhanced the ability to extract useful change features. For instance, Bovolo et al. [29] proposed an unsupervised change detection framework that leverages semisupervised SVM initialized with pseudo-training data, effectively addressing the complexity of multi-temporal spectral feature analysis. Wessels et al. [30] developed an automated system for land cover update mapping, integrating iteratively reweighted MAD (IRMAD) for change mask generation and RF classifiers for robust land cover classification, achieving notable accuracy in operational settings. Despite these advancements, traditional and early ML-based approaches often rely on manually designed features, which perform well in limited generalization straightforward scenarios but exhibit capability for complex and diverse change types. B. DL-Based CD In recent years, deep learning has experienced rapid advancements, achieving remarkable success in remote sensing image CD. As illustrated in Fig. 1, we present timeline of the development of mainstream DL-based CD algorithms. Based on the differences in neural network architectures and training paradigms, DL-based CD methods can be classified into three main categories a) CNN-Based CD: CNNs serve as the foundation of many early DL-based CD methods and remain widely utilized today. Daudt et al. [10] proposed three fully convolutional neural network architectures, including two Siamese network extensions, which achieved significant improvements in accuracy and efficiency for CD tasks on multiple datasets. Zhang et al. [31] introduced the Image Fusion Network (IFN), which employs deeply supervised two-stream architecture for highresolution remote sensing CD, achieving SOTA performance with superior boundary completeness and compactness in change maps. Chen et al. [32] proposed the Siamese-based Spatial-Temporal Attention Network (STANet), incorporating novel CD self-attention module to model spatial-temporal dependencies at various scales, significantly improving F1-scores on benchmark datasets. Fang et al. [33] designed SNUNetCD, densely connected Siamese network that preserves localization information and employs an Ensemble Channel Attention Module (ECAM) for deep supervision, achieving better trade-offs between accuracy and computational cost. Zheng et al. [34] proposed ChangeStar, model leveraging single-temporal supervised learning with ChangeMixin modules to train CD models using unpaired images. Han et al. [35] introduced HANet, hierarchical attention network with progressive foreground-balanced sampling and lightweight selfattention mechanism, effectively addressing class imbalance in CD tasks and achieving superior results on highly imbalanced datasets. The Change Guiding Network (CGNet) introduced by Han et al. [11] utilizes self-attention mechanism to improve edge detection and internal consistency in change maps, demonstrating robust performance across multiple CD datasets. Some studies have focused on designing lightweight and fast CD models. Codegoni et al. [36] presented TinyCD, lightweight and efficient CD model using Siamese U-Net architecture and the Mix and Attention Mask Block (MAMB), outperforming SOTA models while being significantly smaller and faster. Xing et al. [37] proposed LightCDNet, lightweight CD model with an early fusion backbone and pyramid decoder. b) Transformer-Based CD: Transformer-based methods have emerged as promising approach for CD. Chen et al. [38] introduced the bitemporal image transformer (BIT), combining transformer encoder with ResNet backbone to model spatial-temporal contexts efficiently. Bandara et al. [13] proposed ChangeFormer, fully transformer-based Siamese network for CD, which unifies hierarchical transformer encoder with multi-layer perceptron (MLP) decoder. Fang et al. [14] introduced the Changer series framework, novel architecture for CD that incorporates alternative interaction layers between bi-temporal features. This framework is applicable to both CNN-based and Transformer-based models, significantly enhancing the performance of the original models. c) FM-Based CD: Recently, foundation models have become new training paradigm, and some works have applied them to CD tasks. Li et al. [19] proposed the Bi-Temporal Adapter Network (BAN), universal FM-based framework for CD, which enhances existing models with minimal additional parameters and achieves significant performance improvements. Chen et al. [21] introduced Time Travelling Pixels (TTP), method that integrates latent knowledge from the SAM model into CD, overcoming domain shifts and spatiotemporal complexities, demonstrating SOTA results on the LEVIR-CD [32] dataset. Zheng et al. [22] developed AnyChange, zero-shot CD model built on the SAM that utilizes bitemporal latent matching for training-free adaptation, setting new SOTA on the SECOND [39] benchmark and achieving significant improvements in both unsupervised and supervised CD tasks. C. Knowledge Distillation in CD Knowledge distillation (KD), introduced by Hinton et al. [40], aims to transfer the representational knowledge of teacher network to smaller student network. In recent years, as the complexity of DL models in remote sensing tasks has increased, researchers have explored how to transfer knowledge from large, complex teacher models to smaller, more efficient student models through KD, thereby improving performance [41], [42]. Yan et al. [43] proposed novel self-supervised learning approach for unsupervised CD by fusing domain knowledge of remote sensing indices during both training and inferthey selected highence. By calculating cosine similarity, similarity feature vectors from both the teacher and student networks to implement hard negative sampling strategy, effectively improving CD performance. Wang et al. [44] addressed remote sensing semantic CD (SCD), which focuses on detecting changes in land cover and land use over time. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 4 Fig. 2. Sample images from the JL1-CD dataset. Each row, from top to bottom, represents: the image at time 1, the image at time 2, and the ground truth label. Each column corresponds to different change types: (a) Decrease in woodland; (b) Building changes; (c) Conversion of cropland to greenhouses; (d) Road changes; (e) Waterbody changes; and (f) Surface hardening (central region). The authors introduced dual-dimension feature interaction network (DFINet) that enhances intraclass and interclass feature differentiation by incorporating temporal difference feature enhancement (TDFE) module, which captures temporal features comprehensively. Wang et al. [45] proposed KDbased method for CD (CDKD), designed to overcome the challenges of deploying large deep learning models with high computational and storage requirements on resourceconstrained spaceborne edge devices. Although these methods have successfully utilized KD to enhance the performance of various student models, they are tailored to specific models and do not provide generalized distillation framework applicable to various CD models. Furthermore, there is lack of opensource KD-based code for remote sensing image CD tasks. In contrast, the proposed MTKD framework significantly improves the performance of CD models with various architectures and parameter sizes, and we commit to open-sourcing all the code and models. III. JL1-CD DATASET High-resolution, all-inclusive CD datasets are crucial for remote sensing applications. High-resolution images provide richer spatial information, which is more conducive to visual interpretation compared to mediumand low-resolution images. Datasets with comprehensive change features enable the development of algorithms with greater generalization and transferability. Despite the numerous open-source change detection datasets proposed over the past decades, many still lack sub-meter-level resolution, and the variety of change types remains limited. These limitations hinder progress in TABLE INFORMATION OF OPEN-SOURCE CD DATASETS AND THE PROPOSED JL1-CD DATASET Dataset Class Image Pairs SZTAKI [46] DSIFN [31] SECOND [39] WHU-CD [47] LEVIR-CD [32] S2Looking [48] CDD [49] SYSU-CD [50] JL1-CD 1 1 6 1 1 1 1 1 1 13 394 4,662 1 637 5,000 16,000 20,000 5,000 Image Size 952 640 1, 048 724 512 512 512 512 32,20 15,354 1,024 1,024 1,024 1,024 256 256 256 256 512 512 Resolution 1.5 2 0.5-3 0.2 0.3 0.5-0.8 0.03-1 0.5 0.5-0.75 CD research, particularly in the development of DL-based algorithms. We collect the number of types of changes, number of image pairs, image size, and resolution information of mainstream CD datasets in Table I. The SZTAKI AirChange Benchmark [46] contains 12 pairs of 952 640 and one pair of 1,048 724 optical aerial images. It is one of the earliest and most commonly used CD datasets in early research. The DSIFN dataset [31] consists of 6 large bi-temporal image pairs from 6 cities in China, which are cropped into 394 sub-image pairs, each sized 512 512. The SECOND dataset [39] includes 4,662 pairs of aerial images collected from multiple platforms and sensors, covering cities such as Hangzhou, Chengdu, and Shanghai. Unlike other datasets that classify changes into only two categories (change and no change), SECOND IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING Fig. 3. Overview of the training (green boxes) and testing (pink boxes) pipelines of the proposed Origin-Partition (O-P) strategy and Multi-Teacher Knowledge Distillation (MTKD) framework. trees, provides detailed annotations for change types, including nonvegetated surfaces, low vegetation, water, buildings, and playgrounds. However, the resolution of all or part of the images in these datasets does not reach the sub-meter level. WHU-CD [47], LEVIR-CD [32], and S2Looking [48] are very popular datasets that are specifically designed for monitoring building changes. These datasets predominantly include human-induced changes and lack natural change types. The CDD dataset is derived from 7 pairs of 4,725 2,700 realworld seasonal change remote sensing images. The SYSU-CD contains 20,000 pairs of 0.5-meter aerial images captured in Hong Kong between 2007 and 2014. These datasets feature high resolution and diverse change types. To provide better benchmark for evaluating CD algorithms, we propose the JL1-CD dataset, high-resolution, all-inclusive change detection dataset. JL1-CD includes 5,000 pairs of satellite images captured in China from early 2022 to the end of 2023, including Shandong, Ningxia, Anhui, Hebei, Hunan, and other regions. The images have sub-meter resolutions ranging from 0.5 to 0.75 meters and are sized 512 512 pixels. As shown in Fig. 2, the dataset covers various common human-induced and natural surface features, such as piled earth, buildings, roads, hardened surfaces, woodlands, grasslands, croplands, and water bodies. The original 5,000 image pairs are divided into 4,000 pairs for training and 1,000 pairs for testing, following an 80:20 split. The JL1-CD dataset will be made openly available for all research needs. IV. METHODOLOGY In this section, we provide comprehensive overview of the proposed methods. In Section IV-A, we first introduce the Origin-Partition (O-P) strategy designed for the challenging all-inclusive CD dataset. Building upon the O-P strategy, we further present our Multi-Teacher Knowledge Distillation (MTKD) framework in Section IV-B. Finally, in Section IV-C, we describe the overall loss function used for training the teacher and student models. A. O-P Strategy The traditional training and testing approach for CD models is illustrated in the upper-left corner of Fig. 3 (green box) and the upper-right corner (pink box). For given change detection model M, the input consists of pair of images (X1, X2), and the output is change map (CM). If the number of channels = 1, the predicted label ˆY can be directly obtained using thresholding method as follows: ˆY (i) = (cid:40) 1, 0, if CM (i) > th if CM (i) th (1) where (i) denotes the pixel location in the image, 1 represents change, and 0 represents no change (for visualization purpose, 1 will be mapped to grayscale value of 255). The threshold th is predefined value. If = 2, the predicted label ˆY is typically determined using an element-wise comparison of the two channels, such as: ˆY (i) = (cid:40) 1, 0, if CM0(i) CM1(i) if CM0(i) < CM1(i) (2) where CM0 and CM1 represent the first and second layers of the change map, respectively. If > 2, it indicates that the CD model not only predicts the locations of changes but also detects the types of changes, which is beyond the scope of this paper. However, as shown in Fig. 4, for dataset like JL1-CD, where the Change Area Ratio (CAR) can range from 0% to 100%, training single model using traditional methods may not be optimal. The model would struggle to learn the full IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING Fig. 4. Sample images with different change area ratios (CAR). Each column represents specific CAR: (a) 0.00%; (b) 19.98%; (c) 39.93%; (d) 59.96%; (e) 80.25%; and (f) 100.00%. range of change patterns in an all-inclusive manner. To address this issue, we propose the Origin-Partition (O-P) strategy to enhance the models detection performance. As illustrated in the green boxes of Fig. 3 (Step 1 and Step 2), for given CD algorithm, we train the corresponding models in the following sequence: 1) The original model MO is trained on the complete training set using the algorithms default configuration. 2) As shown in Fig. 5, the CAR range for the training, validation, and test sets is very large. However, the majority of images have CAR of less than 5%. Therefore, we set appropriate thresholds th1 and th2 and divide the original training set into three categories: small, medium, and large. 3) The models are then trained from scratch using the partitioned training sets, yielding models MTS , MTM , and MTL. The training process can be formalized as: ˆY = fMTS fMTM fMTL (X1, X2), (X1, X2), (X1, X2), if CARGT th1 if th1 < CARGT th2 if CARGT > th (3) where CARGT denotes the CAR calculated based on the ground truth label for the image pair (X1, X2). As shown in the middle pink box in Fig. 3, during testing, since we do not know the CAR of the test images, we first use MO to estimate the CAR roughly. Based on this estimated CAR, we then classify the image into one of the three categories: small, medium, or large, and send it to the corresponding model MTS , MTM , or MTL to obtain the final detection result: ˆY = fMTS fMTM fMTL (X1, X2), (X1, X2), (X1, X2), if CARMO th1 if th1 < CARMO th2 if CARMO > th2 (4) where CARMO denotes the CAR calculated based on the predicted label from the original model MO. B. MTKD Framework By partitioning the training set, we effectively reduce the learning burden for each model. As result, the OriginPartition (O-P) strategy significantly enhances the performance of the CD algorithm. However, clear issue arises: during inference, we are required to load 4 different models, and even disregarding data throughput, the time spent is at least twice that of the original algorithm (often much more). This substantially increases both memory and time complexity. We are thus prompted to consider: is there way to combine the capabilities of these four models into single model? To address this, we propose the Multi-Teacher Knowledge Distillation (MTKD) framework. In the O-P strategy, we have already trained the models MO, MTS , MTM , and MTL . Building on this, we further train student model MS. First, we initialize the student model MS using the parameters from MO, and then use MTS , MTM , and MTL as teacher models to perform KD. For each input image pair, we select the appropriate teacher model based on the images CAR to guide the student model. The process is shown in the green box at the bottom of Fig. 3. In this framework, when the student model MS is supervised by the ground truth labels, it also IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 7 Fig. 6. CAR distribution of the training and test sets in SYSU-CD. Thus, the complete loss function for training MS is given by: = LCE + λLKD (7) where the parameter λ is used to balance the contributions of the cross-entropy loss and the distillation loss. V. EXPERIMENT A. Dataset Description We first conduct experiments on our JL1-CD dataset. Additionally, to validate the robustness of the proposed O-P strategy and MTKD framework, we further perform experiments on the SYSU-CD dataset [50]. The detailed information for these two datasets is as follows: 1) JL1-CD Dataset: As described in Section III, the JL1CD dataset consists of 5,000 pairs of high-resolution images, with resolution of 0.5-0.75 meters and image size of 512 512. In the competition, the first 4,000 image pairs are used for training, and the remaining 1,000 image pairs are used for testing (with the ground truth labels being unavailable during the competition). To ensure sufficient data for training, we use the first 100 image pairs as the validation set, the next 3,900 image pairs as the training set, and the remaining 1,000 image pairs for testing. As shown in Fig. 5, our data split is reasonable, as the CAR distributions of the three sets are very similar. 2) SYSU-CD Dataset: As illustrated in Fig. 6, the SYSUCD dataset is also challenging dataset with very large CAR range, so we choose this dataset as the second benchmark to validate the robustness of our proposed methods. The SYSUCD dataset contains 12,000 pairs for training, 4,000 pairs for validation, and 4,000 pairs for testing, with each image having resolution of 0.5 meters and size of 256 256. Fig. 5. CAR distribution of the training, validation and test sets in JL1-CD. receives the CM information corresponding to different CAR ranges, provided by the teacher models. During the testing phase, only the student model MS is used for inference, thereby significantly improving the models CD performance across different CAR ranges without introducing any additional computational cost. C. Loss Function When training the original model MO and the teacher models MTS , MTM , and MTL, we employ the standard binary cross-entropy loss: LCE ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) (Y (i) log( ˆY (i)) (1 (i)) log(1 ˆY (i))) i=1 (5) where (i) denotes the ground truth label of pixel i. When training the student model MS, we select the appropriate teacher model based on the CAR range. Then the mean squared error (MSE) is computed at the CM layer as the distillation loss: LKD ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) i=1 (CM (i) CMT (i))2 , {TS, TM , TL}. (6) IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 8 TABLE II BENCHMARK METHODS AND THE CORRESPONDING IMPLEMENTATION DETAILS Method FC-EF [10] FC-Siam-Conc [10] FC-Siam-Diff [10] STANet-Base [32] IFN [31] SNUNet-c16 [33] BIT [38] ChangeStar [34] ChangeFormer [13] TinyCD [36] HANet [35] Changer [14] LightCDNet-s [37] CGNet [11] BAN [19] TTP [21] Backbone CNN CNN CNN ResNet-18 VGG-16 CNN ResNet-18 FarSeg (ResNet-18) [51] UPerNet (ResNet-18) [52] MiT-b0 MiT-b1 CNN CNN MiT-b0 MiT-b1 ResNet-18 ResNeSt-50 CNN VGG-16 ViT-B ViT-B (IN21K) ViT-L SAM [17] Param (M) 1.353 1.548 1.352 12.764 35.995 3.012 2.990 16.965 13.952 3.847 13.941 0.285 3.028 3.457 13.355 11.391 26.693 0.342 38.989 91.346 115.712 261.120 361. Flops (G) 12.976 19.956 17.540 70.311 323.584 46.921 34.996 76.845 55.634 11.380 26.422 5.791 97.548 8.523 23.306 23.820 67.241 6.995 425.984 74.409 83.142 346.112 929.792 Initial LR 1e-3 1e-3 1e-3 1e-3 1e-3 1e-3 1e-3 1e-3 1e-3 6e-5 6e-5 3.57e-3 1e-3 1e-4 1e-4 5e-3 5e-3 3e-3 5e-4 1e-4 1e-4 1e-4 4e-4 λ - - - 5e-3 1e-4 1e-4 1e-4 1e-3 1e-4 1e-3 5e-4 1e-5 1e-3 1e-4 1e-3 1e-3 1e-5 5e-3 1e-3 - - 1e-3 5e-3 Scheduler LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR LinearLR CosineAnnealingLR Batch Size 8 8 8 8 8 8 8 16 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 GPU 3090 3090 3090 3090 3090 3090 3090 3090 3090 3090 3090 3090 A800 3090 3090 3090 3090 3090 A800 3090 3090 A800 B. Benchmark Methods To comprehensively verify the validity of our JL1-CD dataset and the superiority of the proposed O-P strategy and MTKD framework, we conduct extensive experiments on existing benchmark algorithms. The selected models, along with their corresponding backbones, parameter sizes, and computational complexities, are summarized in Table II. Based on the backbone architecture, the models are categorized into three groups: Alice Blue for CNN-based models, Light Cyan for Transformer-based models, and Lavender Blue for FM-based models, encompassing almost all mainstream architectures. FLOPs is calculated with an input image of size 512 512. the selected models span wide As shown in the table, range of sizes, from lightweight models such as TinyCD and LightCDNet with less than 1MB to the latest SOTA model TTP, which exceeds 360MB. This wide range allows us to verify the universality of the O-P and MTKD methods across models with different backbones and scales. C. Evaluation Metrics The common evaluation metrics for CD models include Intersection over Union (IoU), accuracy, precision, recall, and F1-score. IoU measures the overlap between the detected change region and the ground truth. Accuracy reflects the overall correctness of the model. Precision indicates the false positive rate of the model, recall reflects the false negative rate, and F1-score balances both precision and recall. higher F1score indicates better detection performance. However, given the large CAR range in the JL1-CD dataset, both change and non-change regions are equally important. Therefore, we choose the averaged versions of the aforementioned metrics, which are calculated as follows: mIoU = = mPrecision = = mAcc = = mFscore = = 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 (IoU0 + IoU1) (cid:18) TN TN + FP + FN + TP TP + FP + FN (cid:19) (Precision0 + Precision1) (cid:19) (cid:18) TN + TP TP + FP TN + FN (Recall0 + Recall1) (cid:18) TN + TP TP + FN TN + FP (8) (cid:19) (Fscore0 + Fscore1) 1 (cid:88) i=0 2 Precisioni Recalli Precisioni + Recalli where TP, FP, TN, and FN represent true positives, false positives, true negatives, and false negatives, respectively. The averaged accuracy and recall are equivalent, so we only use mAcc for consistency in subsequent experiments. It is important to note that in the toolboxes like MMthese metrics are Segmentation [53] and MMRotate [54], computed based on the total number of pixels across all predicted label images. In this paper, however, to align with the competition requirements, we first calculate these metrics for each individual image and then compute the average of the results across all images to obtain the final outcome. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 9 Method Strategy mIoU mAcc mPrecision mFscore Method Strategy mIoU mAcc mPrecision mFscore TABLE III EXPERIMENTAL RESULTS ON JL1-CD TEST SET STANet (Base) SNUNet (c16) ChangeStar (FarSeg) ChangeFormer (MiT-b0) TinyCD Changer (MiT-b0) Changer (r18) LightCDNet (s) BAN (ViT-L) BAN (ViT-B) FC-EF FC-Siam-Diff - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P - O-P - O-P 66.76 64.56 67.92 68.97 71.39 71.12 69.47 68.87 69.14 73.51 72.58 73.25 71.04 72.22 72.55 74.85 75.29 75.35 68.37 70.76 69.45 66.70 70.19 65.99 73.54 73.61 73.95 73.30 72.47 57.08 49.59 61.30 56.49 81.71 78.47 82.07 74.87 78.60 78.27 75.58 74.74 76.49 80.46 79.16 79.20 78.77 79.93 80.98 81.84 81.40 81.76 75.15 77.42 77.26 73.21 77.43 72.44 79.54 79.17 80.26 80.36 78.78 61.90 53.30 66.03 60. 74.73 78.47 76.24 85.06 83.36 84.96 84.46 84.90 82.09 86.33 86.33 87.15 83.05 83.49 83.17 86.09 87.06 87.18 83.43 83.86 81.50 83.45 83.99 83.86 87.89 88.10 87.12 85.91 86.31 86.40 95.54 86.45 91.64 74.73 71.25 75.10 75.25 77.98 77.56 75.57 74.86 75.41 79.70 78.79 79.30 77.74 78.76 79.26 80.98 81.32 81.28 74.54 77.01 75.86 72.46 76.16 71.48 79.47 79.45 79.92 79.47 78.58 61.28 51.47 66.34 60.57 IFN BIT ChangeStar (UPerNet) ChangeFormer (MiT-b1) HANet Changer (MiT-b1) Changer (s50) CGNet TTP BAN (ViT-B-IN21K) FC-Siam-Conc - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P MTKD - O-P - O-P 71.25 71.06 72.72 67.22 69.41 68.86 64.85 64.68 65.10 73.05 73.45 73.92 63.64 69.05 67.67 75.94 75.42 76.15 62.31 71.80 62.96 73.37 72.95 73.82 75.05 76.69 76.85 74.69 73.50 63.79 60.25 78.91 78.37 80.28 74.47 76.29 75.49 69.18 69.05 70.26 79.70 79.19 80.43 69.77 76.53 74.39 81.99 81.67 82.85 69.23 79.76 69.65 80.31 79.71 80.32 80.24 83.48 82.99 81.09 79.98 69.54 63.84 84.53 84.28 84.66 83.71 84.02 84.71 88.26 87.23 87.69 86.95 87.45 86.89 83.43 83.05 84.38 87.74 87.13 86.98 80.91 83.15 81.76 85.33 85.50 86.33 89.82 87.27 88.05 87.14 86.25 84.77 91.19 77.33 77.21 78.80 73.37 75.77 74.88 70.19 70.08 70.58 79.22 79.41 80.18 69.39 75.66 73.92 81.93 81.43 82.13 67.83 78.23 68.52 79.65 79.12 79.91 80.76 82.52 82.56 80.75 79.50 69.19 64. D. Implementation Details All algorithms are trained and tested using the PyTorchbased OpenCD Toolbox [55]. To ensure fair comparison and clearly assess the contributions of the Origin-Partition (O-P) strategy and the Multi-Teacher Knowledge Distillation (MTKD) framework to the performance improvement of the CD models, we adopt consistent settings for all models (MO, MTL, MTM , MTS , and MS) across the various algorithms, as described below: 1) The patch size of the input images is 512 512, which matches the original image dimensions. 2) Data augmentation methods, including RandomRotate, RandomFlip, and PhotoMetricDistortion, are applied. 3) The AdamW optimizer is used with β1 = 0.9 and β2 = 0.99, and the default batch size is set to 8 image pairs (with batch size of 16 for ChangeStar-FarSeg). 4) Models MO, MTL, MTM , and MTS are trained for 200k iterations on the original and the corresponding partitioned datasets (300 epochs for TTP), while the student model MS is trained for an additional 100k iterations (100 epochs for TTP) on the original dataset. 5) Training begins with warm-up phase of 1k iterations (5 epochs for TTP), during which the learning rate (LR) is linearly increased from 1e-6 to the initial LR value, as specified in Table II. Afterward, the LR is linearly decayed to 0 as training progresses (TTP employs CosineAnnealing decay schedule). 6) The HANet, CGNet, BAN (ViT-L), and TTP models are trained on the NVIDIA A800 server, while other models are trained on the NVIDIA RTX 3090 server. All models are tested on the A800 server. When partitioning the dataset, we set the thresholds th1 = 0.05 and th2 = 0.2, which ensures balanced distribution of samples across the partitions. The model is saved every 1k iterations (5 epochs for TTP), and the checkpoint with the highest mIoU value on the validation set is selected for testing. For the training of MTS , due to the varying distributions of the change maps and the different magnitudes of LCE across modelss, grid search is performed over the set {1e 5, 5e 5, 1e4, 5e4, 1e3, 5e3, 1e2} to determine the optimal distillation loss weight λ for each model. More configuration details are summarized in Table II. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 10 Fig. 7. Visual comparison on the JL1-CD dataset. Each row, from top to bottom, represents the following: image at time 1, image at time 2, ground truth, output from the original model, output from the O-P strategy, and output from the MTKD framework. Red denotes missed detections (FN), while blue indicates false alarms (FP). The selected algorithms are: (a) BAN-ViT-L, (b) BIT, (c) TTP, (d) SNUNet, (e) IFN, (f) Changer-MiT-b1, (g) ChangeFormer-MiT-b1, (h) TinyCD, and (i) CGNet. Fig. 8. mIoU of HANet, ChangeFormer-MiT-b1, and TTP across different CAR ranges. The first and second rows show results on the validation and test sets, respectively. In each plot, the left y-axis represents CAR size, and the right y-axis represents mIoU. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 11 TABLE IV COMPARISON OF DETECTION RESULTS ON CHANGE AND NO-CHANGE CLASSES Method IFN SNUNet (c16) ChangeFormer (MiT-b0) ChangeFormer (MiT-b1) TinyCD Changer (MiT-b0) Changer (MiT-b1) CGNet BAN (ViT-L) TTP Class unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed unchanged changed IoU +0.24 +2.71 +0.10 +4.21 +0.21 -0.74 +0.07 +1.68 +0.30 +2.72 +0.21 +0.80 +0.02 +0.41 +0.02 +0.88 +0.12 +0.70 +0.23 +3.36 Acc +0.29 +2.44 -0.60 +7.38 -0.02 -2.51 +0.12 +1.35 +0.29 +4.13 +0.32 -0.48 +0.09 +1.63 -0.03 +0.03 +0.23 +1.21 -0.19 +5.69 Precision +0.04 +0.22 +0.65 -0.86 +0.24 +1.41 -0.01 -0.11 +0.08 +0.16 -0.14 +2.32 -0.04 -1.47 -0.04 +2.04 -0.09 -1.46 +0.45 -3. Fscore +0.12 +2.82 +0.06 +4.54 +0.18 -0.99 +0.05 +1.86 +0.20 +2.85 +0.19 +0.41 -0.01 +0.42 -0.06 +0.59 +0.07 +0.82 +0.20 +3.39 E. Experimental Results the O-P strategy does not a) Quantitative Comparison: Table III summarizes the numerical results of mIoU, mAcc, mPrecision, and mFscore for all methods on the JL1-CD test set, trained under the original, O-P, and MTKD strategies. As shown in the table, lead to perwe observe that formance improvements for BAN-ViT-B, BAN-ViT-B-IN21k, FC-EF, FC-Siam-Conc, and FC-Siam-Diff. This suggests that the partition-based training method is not suitable for these algorithms, and thus cannot obtain sufficiently strong teacher models. Therefore, we do not continue with MTKD experiments for these methods. However, the O-P strategy or MTKD framework can improve the performance of all other algorithms to certain extent. The following conclusions can be drawn from these results: 1) Surprisingly, unlike their performance on the validation set, many algorithms under O-P perform worse than under MTKD, and in some cases, even worse than the original models (e.g., STANet, IFN, Changer-MiT-b1, etc.). However, the student models obtained through MTKD training can achieve significantly better performance than models trained under the original and O-P methods. This is mainly due to the inability of the original models to achieve accurate CAR on the test set during the coarse detection stage. This finding also indicates that our MTKD method can endow student models with superior capabilities compared to the teacher models, without increasing computation and time cost during inference. 2) After MTKD optimization, the single Changer-MiT-b0 and Changer-MiT-b1 models can outperform the original TTP the TTP model, after in terms of mIoU. Additionally, MTKD optimization, shows improvements in mIoU and mFscore by 1.30% and 1.80%, respectively, setting new SOTA. 3) The O-P strategy shows the most significant improvement for Changer-MiT-s50 (with 9.49% increase in mIoU and 10.4% increase in mFscore), while the MTKD framework yields the most significant performance boost for HANet (with 4.03% increase in mIoU and 4.53% increase in mFscore). b) Visual Comparison: In remote sensing change detection, four main challenges are typically encountered: false internal density, and boundary alarms, missed detections, completeness. To visually assess the effectiveness of the OP and MTKD strategies in addressing these challenges, we present the visual results of several algorithms in Fig. 7, where red indicates missed detections and blue indicates false alarms. The first five columns show performance in terms of missed detection. As depicted, the original algorithms struggle to detect small changes accurately, particularly for objects with subtle variations. However, after optimization with O-P and MTKD, the missed detection rate for small-scale changes is significantly reduced. Of course, the improvement is limited; for example, in the first and fourth columns, although MTKD detects more road changes, it still cannot fully capture the narrow variations. The sixth column displays the performance in terms of false alarms, where it is evident that the false alarm rate decreases progressively across the original, O-P, and MTKD methods. The last three columns illustrate the improvements in internal density and boundary completeness. We effectively reduce the occurrence of internal holes within the change areas, and the boundaries become more complete. c) Results on Different CAR Partitions: We select one model from each of the CNN, Transformer, and FM architectures and evaluate their performance across different CAR ranges. Fig. 8 summarizes the mIoU results of HANet, ChangeFormer-MiT-b1, and TTP on both the validation set (first row) and the test set (second row). The images are sorted by CAR in ascending order and divided into five equal partitions. Each bar in the figure represents the lower and upper bounds of CAR for each partition, while the line graph indicates the mIoU across the different partitions. From the figure, it can be observed that the detection performance of O-P and MTKD may actually decrease for images with high CAR (e.g., ChangeFormer-MiT-b1 and TTP). However, OP and MTKD significantly enhance model performance on images with low CAR. In the first partition of the test set (CAR range 0.02% to 0.88%), O-P improves the mIoU for the three algorithms by 8.15%, 3.21%, and 6.55%, respectively, while MTKD improves it by 4.42%, 3.36%, and 2.85%. These results demonstrate significant improvement in the accuracy of detecting tiny changes, which is consistent with the findings in Fig. 7. d) Comparison of Results on Change and No-Change Classes: We further select all algorithms with an mIoU greater than 70% under the MTKD framework and compared their performance in detecting change and no-change regions. The experimental results are summarized in Table IV. Using the original models as baseline, we analyze the contribution of MTKD to different metrics. Except for the ChangeFormerIEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING Fig. 9. Visual comparison on the SYSU-CD dataset. Red denotes missed detections (FN). Blue indicates false alarms (FP). (a) Image at Time 1. (b) Image at Time 2. (c) Ground Truth. (d) Changer-MiT-b1 (Original). (e) Changer-MiT-b1 (MTKD). (f) CGNet (Original). (g) CGNet (MTKD). (h) TTP (Original). (i) TTP (MTKD). TABLE IMPACT OF DIFFERENT NUMBERS OF TEACHER MODELS ON O-P AND MTKD PERFORMANCE Method Strategy Changer (MiT-b0) Changer (MiT-b1) CGNet TTP O-P MTKD O-P MTKD O-P MTKD O-P MTKD No. of MT 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 mIOU 75.29 (+0.44) 75.44 (+0.59) 75.35 (+0.50) 75.72 (+0.87) 75.42 (-0.52) 75.91 (-0.03) 76.15 (+0.21) 76.77 (+0.83) 72.95 (-0.42) 73.56 (+0.19) 73.82 (+0.45) 73.78 (+0.41) 76.69 (+1.64) 76.65 (+1.60) 76.85 (+1.80) 76.31 (+1.26) mAcc 81.40 (-0.44) 81.96 (+0.12) 81.76 (-0.08) 82.30 (+0.46) 81.67 (-0.32) 82.11 (+0.12) 82.85 (+0.86) 83.38 (+1.39) 79.71 (-0.60) 80.76 (+0.45) 80.32 (+0.01) 80.61 (+0.29) 83.48 (+3.24) 82.98 (+2.74) 82.99 (+2.75) 83.24 (+3.00) mPrecision 87.06 (+0.97) 85.85 (-0.24) 87.18 (+1.09) 86.80 (+0.71) 87.13 (-0.61) 87.87 (+0.13) 86.98 (-0.76) 87.30 (-0.44) 85.50 (+0.17) 85.07 (-0.26) 86.33 (+1.00) 85.67 (+0.34) 87.27 (-2.55) 87.39 (-2.43) 88.05 (-1.77) 86.81 (-3.01) mFscore 81.32 (+0.34) 81.51 (+0.53) 81.28 (+0.30) 81.66 (+0.68) 81.43 (-0.50) 81.97 (+0.04) 82.13 (+0.20) 82.66 (+0.73) 79.12 (-0.53) 79.92 (+0.27) 79.91 (+0.26) 79.89 (+0.24) 82.52 (+1.76) 82.49 (+1.73) 82.56 (+1.80) 82.22 (+1.46) MiT-b0 model, all MTKD-optimized models demonstrated significant improvements in both IoU and Fscore for the change regions. This indicates that the MTKD framework is more sensitive to the detection of change areas. F. Robustness of MTKD To verify the robustness of the MTKD framework, we conduct the following two sets of experiments: a) Impact of Different Numbers of Teacher Models on MTKD Performance: In the previous subsection, we have demonstrated that the MTKD framework based on three teacher models can significantly improve the performance of various CD models. Therefore, we further explore the performance of MTKD with two teacher models. We set threshold of th = 0.10 to divide the dataset into small and large partitions and train the models MTS and MTL on these partitions, respectively. Subsequently, the student model MS is trained using the MTKD framework. Except for the reduced number of teacher models, all other experimental settings remain unchanged. Using the original models as baseline, Table compares the metrics of models trained with the O-P strategy and the MTKD framework under different numbers of teacher models. The results indicate that two teacher models can still achieve significant performance improvements over the baseline. Notably, for Changer-MiT-b0 and Changer-MiT-b1, the two-teacher model setup yields even IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 13 TABLE VI EXPERIMENTAL RESULTS ON SYSU-CD TEST SET Method Strategy mIoU mAcc mPrecision mFscore Changer (MiT-b1) CGNet TTP - O-P MTKD - O-P MTKD - O-P MTKD 75.49 75.32 75.56 71.41 69.85 71.87 76.09 75.97 76.11 84.25 83.88 83.97 80.32 80.05 81.74 84.59 84.54 83.93 86.38 85.86 87.33 84.72 82.39 84.05 87.08 86.20 87.77 82.38 82.19 82.40 78.82 77.40 79.42 82.72 82.66 82.77 greater improvements compared to the three-teacher setup. For CGNet, the O-P strategy with two teachers achieves higher mIoU and mFscore, although the MTKD performance is lower in this case. For TTP, the performance of O-P and MTKD under the three teacher model still remains the strongest. These experiments validate the robustness of our methods in terms of the number of teachers. They also suggest that for some models, reducing the number of teachers can lead to comparable or even superior results while consuming fewer training resources. b) Performance of MTKD on the SYSU-CD Dataset: We further validated the effectiveness of the MTKD framework on the SYSU-CD dataset. Transformer-based Changer-MiT-b1, CNN-based CGNet, and FM-based TTP models are selected. As shown in Table VI, after MTKD optimization, all the models achieve higher mIoU and mFscore values, with the most significant improvement on CGNet (mIoU increased by 0.46% and mFscore increased by 0.60%). However, the O-P strategy does not yield better results compared to the original models. The visual comparison is presented in Fig. 9, illustrating the detection results of these algorithms on four image pairs. Comparing the 4th and 5th columns, it is evident that MTKD significantly reduces the false alarm rate for Changer-MiT-b1. For example, in the 1st row, large areas of false detection are eliminated, and in the 3rd row, small falsepositive patch is removed. However, the 4th row exhibits an increase in false alarms. For CGNet, MTKDs most notable contribution is the enhancement of internal compactness in detected regions. The original TTP model already produces satisfactory detection results, but MTKD further reduces false alarms. For instance, large patch in the 1st row and small patch in the 3rd row are effectively eliminated. However, the 1st row also shows an increase in missed detections. Overall, MTKD demonstrated substantial effectiveness on the SYSUCD dataset, further validating its robustness. VI. CONCLUSION In this work, we introduce new benchmark dataset, JL1CD, which significantly complements existing CD datasets by offering sub-meter resolution, wide range of change types, and large dataset scale. We also propose the MTKD framework, which significantly enhances the performance of CD models on dual-temporal remote sensing images with different change areas, without increasing time and computational complexity during inference. Our approach effectively improves the generalization and robustness of the model across different cD scenarios. Future work will focus on developing more universal knowledge distillation framework that not only further enhances model performance in diverse scenarios but also reduces model size and increases inference speed."
        },
        {
            "title": "REFERENCES",
            "content": "[1] L. Wang, M. Zhang, X. Gao, and W. Shi, Advances and challenges in deep learning-based change detection for remote sensing images: review through various learning paradigms, Remote Sensing, vol. 16, no. 5, p. 804, 2024. [2] P. R. Coppin and M. E. Bauer, Digital change detection in forest ecosystems with remote sensing imagery, Remote sensing reviews, vol. 13, no. 3-4, pp. 207234, 1996. [3] R. D. Johnson and E. Kasischke, Change vector analysis: technique for the multispectral monitoring of land cover and condition, International journal of remote sensing, vol. 19, no. 3, pp. 411426, 1998. [4] G. Byrne, P. Crapper, and K. Mayo, Monitoring land-cover change by principal component analysis of multitemporal landsat data, Remote sensing of Environment, vol. 10, no. 3, pp. 175184, 1980. [5] J. B. Collins and C. E. Woodcock, An assessment of several linear change detection techniques for mapping forest mortality using multitemporal landsat tm data, Remote sensing of Environment, vol. 56, no. 1, pp. 6677, 1996. [6] A. A. Nielsen, K. Conradsen, and J. J. Simpson, Multivariate alteration detection (mad) and maf postprocessing in multispectral, bitemporal image data: New approaches to change detection studies, Remote Sensing of Environment, vol. 64, no. 1, pp. 119, 1998. [7] H. Nemmour and Y. Chibani, Multiple support vector machines for land cover change detection: An application for mapping urban extensions, ISPRS Journal of Photogrammetry and Remote Sensing, vol. 61, no. 2, pp. 125133, 2006. [8] K. J. Wessels, F. Van den Bergh, D. P. Roy, B. P. Salmon, K. C. Steenkamp, B. MacAlister, D. Swanepoel, and D. Jewitt, Rapid land cover map updates using change detection and robust random forest classifiers, Remote sensing, vol. 8, no. 11, p. 888, 2016. [9] T. Celik, Unsupervised change detection in satellite images using principal component analysis and k-means clustering, IEEE geoscience and remote sensing letters, vol. 6, no. 4, pp. 772776, 2009. [10] R. C. Daudt, B. Le Saux, and A. Boulch, Fully convolutional siamese networks for change detection, in 2018 25th IEEE international conference on image processing (ICIP). IEEE, 2018, pp. 40634067. [11] C. Han, C. Wu, H. Guo, M. Hu, J. Li, and H. Chen, Change guiding network: Incorporating change prior to guide change detection in remote sensing imagery, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2023. [12] Z. Liu, S. Wang, and Y. Gu, two-stage method for joint denoising and compression of sar images, in 2024 IEEE 4th International Conference on Power, Electronics and Computer Applications (ICPECA). IEEE, 2024, pp. 853859. [13] W. G. C. Bandara and V. M. Patel, transformer-based siamese network for change detection, in IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium. IEEE, 2022, pp. 207210. [14] S. Fang, K. Li, and Z. Li, Changer: Feature interaction is what you need for change detection, IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp. 111, 2023. [15] Z. Liu, S. Wang, and Y. Gu, Optimizing sar target detection through the multi-stage pre-training and fine-tuning strategy, in 2024 IEEE 12th International Conference on Computer Science and Network Technology (ICCSNT). IEEE, 2024, pp. 178181. [16] A. Dosovitskiy, An image is worth 16x16 words: Transformers for image recognition at scale, arXiv preprint arXiv:2010.11929, 2020. [17] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo et al., Segment anything, in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 40154026. [18] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark et al., Learning transferable language supervision, in International visual models from natural conference on machine learning. PMLR, 2021, pp. 87488763. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 14 [41] Z. Liu, S. Wang, Y. Li, Y. Gu, and Q. Yu, Dsrkd: Joint despecking and super-resolution of sar images via knowledge distillation, IEEE Transactions on Geoscience and Remote Sensing, 2024. [42] Z. Liu, S. Wang, and Y. Gu, Sar image compression with inherent denoising capability through knowledge distillation, IEEE Geoscience and Remote Sensing Letters, 2024. [43] L. Yan, J. Yang, and J. Wang, Domain knowledge-guided selfsupervised change detection for remote sensing images, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 16, pp. 41674179, 2023. [44] B. Wang, Z. Jiang, W. Ma, X. Xu, P. Zhang, Y. Wu, and H. Yang, Dual-dimension feature interaction for semantic change detection in remote sensing images, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024. [45] G. Wang, N. Zhang, J. Wang, W. Liu, Y. Xie, and H. Chen, Knowledge distillation-based lightweight change detection in high-resolution remote sensing imagery for on-board processing, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024. [46] C. Benedek and T. Sziranyi, Change detection in optical aerial images by multilayer conditional mixed markov model, IEEE Transactions on Geoscience and Remote Sensing, vol. 47, no. 10, pp. 34163430, 2009. [47] S. Ji, S. Wei, and M. Lu, Fully convolutional networks for multisource building extraction from an open aerial and satellite imagery data set, IEEE Transactions on geoscience and remote sensing, vol. 57, no. 1, pp. 574586, 2018. [48] L. Shen, Y. Lu, H. Chen, H. Wei, D. Xie, J. Yue, R. Chen, S. Lv, and B. Jiang, S2looking: satellite side-looking dataset for building change detection, Remote Sensing, vol. 13, no. 24, p. 5094, 2021. [49] N. Bourdis, D. Marraud, and H. Sahbi, Constrained optical flow for aerial image change detection, in 2011 IEEE international geoscience and remote sensing symposium. IEEE, 2011, pp. 41764179. [50] Q. Shi, M. Liu, S. Li, X. Liu, F. Wang, and L. Zhang, deeply supervised attention metric-based network and an open aerial image dataset for remote sensing change detection, IEEE transactions on geoscience and remote sensing, vol. 60, pp. 116, 2021. [51] Z. Zheng, Y. Zhong, J. Wang, and A. Ma, Foreground-aware relation network for geospatial object segmentation in high spatial resolution remote sensing imagery, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2020, pp. 40964105. [52] T. Xiao, Y. Liu, B. Zhou, Y. Jiang, and J. Sun, Unified perceptual the European parsing for scene understanding, in Proceedings of conference on computer vision (ECCV), 2018, pp. 418434. [53] M. Contributors, segmentation toolbox and benchmark, https://github.com/open-mmlab/ mmsegmentation, 2020. MMSegmentation: Openmmlab semantic [54] Y. Zhou, X. Yang, G. Zhang, J. Wang, Y. Liu, L. Hou, X. Jiang, X. Liu, J. Yan, C. Lyu et al., Mmrotate: rotated object detection benchmark using pytorch, in Proceedings of the 30th ACM International Conference on Multimedia, 2022, pp. 73317334. [55] K. Li, J. Jiang, A. Codegoni, C. Han, Y. Deng, K. Chen, Z. Zheng, H. Chen, Z. Zou, Z. Shi et al., Open-cd: comprehensive toolbox for change detection, arXiv preprint arXiv:2407.15317, 2024. [19] K. Li, X. Cao, and D. Meng, new learning paradigm for foundation model-based remote-sensing change detection, IEEE Transactions on Geoscience and Remote Sensing, vol. 62, pp. 112, 2024. [20] S. Dong, L. Wang, B. Du, and X. Meng, Changeclip: Remote sensing change detection with multimodal vision-language representation learning, ISPRS Journal of Photogrammetry and Remote Sensing, vol. 208, pp. 5369, 2024. [21] K. Chen, C. Liu, W. Li, Z. Liu, H. Chen, H. Zhang, Z. Zou, and Z. Shi, Time travelling pixels: Bitemporal features integration with foundation model for remote sensing image change detection, in IGARSS 20242024 IEEE International Geoscience and Remote Sensing Symposium. IEEE, 2024, pp. 85818584. [22] Z. Zheng, Y. Zhong, L. Zhang, and S. Ermon, Segment any change, arXiv preprint arXiv:2402.01188, 2024. [23] Z. Zhang, X. Jiang, Y. Zhou, and X. Liu, Semi-supervised change detection with fourier-based frequency transformation, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024. [24] G. Xu, Z. Zhang, X. Jiang, Y. Zhou, and X. Liu, Semi-supervised scene classification for optical remote sensing images via label and embedding consistency, IEEE Geoscience and Remote Sensing Letters, 2024. [25] K. Li, X. Cao, Y. Deng, J. Song, J. Liu, D. Meng, and Z. Wang, Semicdvl: Visual-language model guidance makes better semi-supervised change detector, IEEE Transactions on Geoscience and Remote Sensing, 2024. [26] M. Gong, Y. Cao, and Q. Wu, neighborhood-based ratio approach for change detection in sar images, IEEE Geoscience and Remote Sensing Letters, vol. 9, no. 2, pp. 307311, 2011. [27] N. Otsu et al., threshold selection method from gray-level histograms, Automatica, vol. 11, no. 285-296, pp. 2327, 1975. [28] G. M. Gandhi, S. Parthiban, N. Thummalu, and A. Christy, Ndvi: Vegetation change detection using remote sensing and gisa case study of vellore district, Procedia computer science, vol. 57, pp. 11991210, 2015. [29] F. Bovolo, L. Bruzzone, and M. Marconcini, novel approach to unsupervised change detection based on semisupervised svm and similarity measure, IEEE transactions on geoscience and remote sensing, vol. 46, no. 7, pp. 20702082, 2008. [30] K. J. Wessels, F. Van den Bergh, D. P. Roy, B. P. Salmon, K. C. Steenkamp, B. MacAlister, D. Swanepoel, and D. Jewitt, Rapid land cover map updates using change detection and robust random forest classifiers, Remote sensing, vol. 8, no. 11, p. 888, 2016. [31] C. Zhang, P. Yue, D. Tapete, L. Jiang, B. Shangguan, L. Huang, and G. Liu, deeply supervised image fusion network for change detection in high resolution bi-temporal remote sensing images, ISPRS Journal of Photogrammetry and Remote Sensing, vol. 166, pp. 183200, 2020. [32] H. Chen and Z. Shi, spatial-temporal attention-based method and new dataset for remote sensing image change detection, Remote Sensing, vol. 12, no. 10, p. 1662, 2020. [33] S. Fang, K. Li, J. Shao, and Z. Li, Snunet-cd: densely connected siamese network for change detection of vhr images, IEEE Geoscience and Remote Sensing Letters, vol. 19, pp. 15, 2021. [34] Z. Zheng, A. Ma, L. Zhang, and Y. Zhong, Change is everywhere: Single-temporal supervised object change detection in remote sensing imagery, in Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 15 19315 202. [35] C. Han, C. Wu, H. Guo, M. Hu, and H. Chen, Hanet: hierarchical attention network for change detection with bitemporal very-highresolution remote sensing images, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 16, pp. 3867 3878, 2023. [36] A. Codegoni, G. Lombardi, and A. Ferrari, Tinycd: (not so) deep learning model for change detection, Neural Computing and Applications, vol. 35, no. 11, pp. 84718486, 2023. [37] Y. Xing, J. Jiang, J. Xiang, E. Yan, Y. Song, and D. Mo, Lightcdnet: Lightweight change detection network based on vhr images, IEEE Geoscience and Remote Sensing Letters, 2023. [38] H. Chen, Z. Qi, and Z. Shi, Remote sensing image change detection with transformers, IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 114, 2021. [39] K. Yang, G.-S. Xia, Z. Liu, B. Du, W. Yang, M. Pelillo, and L. Zhang, Asymmetric siamese networks for semantic change detection in aerial images, IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 118, 2021. [40] G. Hinton, Distilling the knowledge in neural network, arXiv preprint arXiv:1503.02531, 2015."
        }
    ],
    "affiliations": [
        "Chang Guang Satellite Technology Co., Ltd. (CGSTL) Changchun 130102, China",
        "Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China"
    ]
}