{
    "paper_title": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback",
    "authors": [
        "Sein Kim",
        "Sangwu Park",
        "Hongseok Kang",
        "Wonjoong Kim",
        "Jimin Seo",
        "Yeonjun In",
        "Kanghoon Yoon",
        "Chanyoung Park"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec."
        },
        {
            "title": "Start",
            "content": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Sangwu Park sangwu.park@kaist.ac.kr KAIST Daejeon, Republic of Korea Sein Kim rlatpdlsgns@kaist.ac.kr KAIST Daejeon, Republic of Korea Hongseok Kang ghdtjr0311@kaist.ac.kr KAIST Daejeon, Republic of Korea 6 2 0 2 3 1 ] . [ 1 2 1 6 2 1 . 2 0 6 2 : r Wonjoong Kim wjkim@kaist.ac.kr KAIST Daejeon, Republic of Korea Jimin Seo jimin.seo@kaist.ac.kr KAIST Daejeon, Republic of Korea Yeonjun In yeonjun.in@kaist.ac.kr KAIST Daejeon, Republic of Korea Kanghoon Yoon ykhoon08@kaist.ac.kr KAIST Daejeon, Republic of Korea Chanyoung Park cy.park@kaist.ac.kr KAIST Daejeon, Republic of Korea Abstract Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, novel framework that establishes directional feedback loop by integrating User Simulator for qualitative critiques and Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce Diagnosis Tool - Model CoEvolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec. Keywords Recommender System, Agentic AI, Self-Evolving Agents"
        },
        {
            "title": "1 Introduction\nDriven by the growth of online data [5, 10], recommender sys-\ntems have evolved from Matrix Factorization [14, 18, 19, 40] to",
            "content": "Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference acronym XX, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX Graph Neural Networks [13, 47] and Transformers [17, 44]. However, optimal performance relies heavily on the entire recommendation pipeline (e.g., loss functions, negative sampling) rather than model architecture alone [35, 56], making manual refinement of this pipeline by human expertise inefficient and costly [53]. To mitigate manual design inefficiencies, Automated Machine Learning (AutoML) techniques, such as Neural Architecture Search (NAS) [6, 55] have emerged as prominent approach to automating the discovery of optimal recommendation architectures [25, 27, 28, 42, 51]. However, these methodologies are inherently constrained by fixed search space bounded by human priors [4, 37], limiting optimization to symbolic combinations within closed pool of pre-defined operators. Due to this lack of generative expressivity, existing NAS methods struggle to address non-architectural componentssuch as loss functions and data processingand fail to jointly optimize the entire recommendation pipeline. Consequently, achieving comprehensive system optimization requires shifting from closed operator pool to an open-ended program space [37]. To realize open-ended optimization, new paradigm known as LLM-driven code evolution has emerged. Pioneering frameworks such as FunSearch [39] and Eureka [32] validated LLM-driven code evolution approach by leveraging LLMs to optimize isolated functions or specific logic components. Substantially expanding this scope, AlphaEvolve [36] targets entire codebases rather than single functions. By orchestrating an autonomous evolutionary pipeline, AlphaEvolve iteratively optimizes complex algorithmic structures and computational stacks through direct code modifications. Complementing AlphaEvolve, DeepEvolve [30] extends the evolution loop by incorporating Retrieval-Augmented Generation (RAG) [8, 26]. By retrieving academic papers from arXiv, it leverages external scientific knowledge to facilitate systematic idea generation and codebase refinement. Unlike NAS confined to combining existing modules, these LLM-driven approaches enable open-ended optimization akin to human researchers, allowing the invention of novel components beyond pre-defined design space. Although existing LLM-driven methodologies have introduced novel open-ended paradigm for code-level evolution, they suffer Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. from critical limitation: the evolution process is guided primarily by scalar metrics (e.g., accuracy and MSE) that lack diagnostic insights. Consequently, without qualitative analysis of model behaviors or root causes of failures, these frameworks are restricted to an undirected trial-and-error search. This limitation is particularly critical in the recommendation domain. Unlike mathematical problems where correctness is defined by deterministic groundtruth [36], recommendation failure is multifaceted and stems from diverse root causes. For instance, drop in NDCG or Hit Ratio does not inherently reveal whether the system suffers from excessive popularity bias, lack of category diversity, or failure to capture short-term user interests [43, 54]. Because scalar metrics condense these complex failure modes into single numerical value, the LLMagent cannot discern whether to mitigate bias or enhance diversity to resolve the deficiency. Thus, we argue that effective code evolution in recommender systems requires directional feedback that analyzes the root causes of failure and encapsulates user experience to effectively guide the evolution process. To address this challenge, we propose Self-EvolveRec, novel LLM-driven code evolution framework that orchestrates directional feedback loop by integrating User Simulator and Model Diagnosis Tool to guide the evolution of recommendation systems. The User Simulator evaluates recommendation lists using diverse user personas, providing qualitative natural language feedback on potential improvements. For instance, the simulator critiques: \"I seek low-cost accessories, not expensive electronics.\" This provides diagnostic explanation for the failure, whereas scalar metrics only reflect performance drop without revealing the cause. While the simulator captures user experience without costly real-world testing, relying solely on simulated feedback risks subjective bias and fails to detect underlying structural or behavioral deficiencies of the model, such as embedding collapse. To mitigate this problem, our proposed Model Diagnosis Tool serves as deterministic verification mechanism. Unlike the simulator and standard scalar metrics (e.g., NDCG), the model diagnosis tool directly probes the models underlying mechanisms and structural properties to quantitatively substantiate issues. For instance, the model diagnosis tool detects structural failures such as embedding collapse by analyzing the geometric distribution of item representations, which simulator feedback alone cannot verify. By corroborating qualitative user critiques with quantitative diagnostic signals, the framework accurately pinpoints critical structural deficiencies within the current recommendation pipeline. Furthermore, as the recommendation pipeline undergoes structural evolution, static diagnostic criteria become obsolete due to the model structural mismatches, where the fixed diagnosis tool can no longer interpret the mechanisms of newly evolved components. This inadequacy arises not only from architectural incompatibility but also from the diagnosis tools inability to quantitatively instantiate new qualitative insights provided by the simulator. To address this, we design the \"Diagnosis Tool - Model Co-Evolution\", ensuring that verification logic dynamically aligns with both the shifting architecture and the emerging scope of qualitative feedback. For instance, if the simulator raises new complaint about short-term bias, the co-evolution mechanism dynamically generates corresponding probe, such as testing how recommendations shift when the most recent interaction is removed, to verify this specific claim. Our main contributions are summarized as follows: We propose Self-EvolveRec, LLM-driven code evolution framework for recommender systems, establishing directional feedback loop. By coupling User Simulator with Model Diagnosis Tool, our framework resolves structural and behavioral failures that are often undetectable to scalar metrics through cross-verified qualitative and quantitative insights. We introduce \"Diagnosis Tool - Model Co-Evolution strategy\" to ensure verification reliability. By dynamically synchronizing diagnostic logic with both architectural shifts and emerging user feedback, our framework prevents evaluation criteria from becoming obsolete as the recommendation pipeline evolves. Our extensive experiments demonstrate that Self-EvolveRec outperforms existing NAS and LLM-driven Code Evolution baselines. Furthermore, the results validate that directional feedback leads to deterministic improvements in recommendation performance, user satisfaction, and the technical quality of the evolved algorithmic logic."
        },
        {
            "title": "2 Related Work\nNeural Architecture Search for Recommender Systems. Neu-\nral Architecture Search (NAS) has been increasingly explored in\nrecommender systems to automate the design of feature interac-\ntions and model architectures. Early studies like AutoFIS [28] re-\nplace discrete interaction feature choices with learnable gating to\nfilter redundant interactions. Later methods extend NAS to back-\nbone design. AutoCTR [42] uses evolutionary search to assemble\noperator blocks into a DAG, whereas DNAS [25] and NASRec [51]\nleverage weight-sharing supernets for scalability. Automation has\nalso expanded to non-architectural components. AutoLossGen [27]\ncasts loss function design as an automated search problem, us-\ning reinforcement learning (RL) to explore loss formulations com-\nposed of basic mathematical operators (e.g., addition, log, mul-\ntiplication). Nevertheless, these approaches remain bounded by\npre-defined operator sets and wiring rules, restricting innovation\nto selection/parameterization within a fixed search space rather\nthan open-ended synthesis of new procedural algorithms.",
            "content": "LLM-driven Code Evolution. To overcome the limitations of fixed search spaces, recent work has explored LLM-driven code evolution, which shifts the optimization target from parameters to open-ended programs. FunSearch [39] utilizes an LLM-evaluator loop to discover interpretable algorithms for mathematical tasks, while Eureka [32] automates RL reward engineering by iteratively refining code based on execution feedback. Building on this line, AlphaEvolve [36] generalizes the evolutionary loop into an autonomous coding pipeline that iteratively edits and tests code using evaluator feedback, scaling to more complex algorithmic optimization tasks. More recently, DeepEvolve [30] integrates retrievalaugmented generation, leveraging external knowledge to systematically inform hypothesis generation and implementation for scientific discovery tasks. However, most existing approaches are guided primarily by single scalar metric (e.g., accuracy or success rate), which provides limited diagnostic insight into user-centric failure modes such as bias, off-topic, or lack of diversity, which are key considerations for holistic recommender-system optimization. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 1: Two core mechanism of Self-EvolveRec. (a) is the overview of the Directional Feedback Generation: (a.1) is the user simulator, (a.2) is the model diagnosis tool. (b) is the Diagnosis Tool - Model Co-evolution in Self-EvolveRec. LLM-based User Simulation. LLM-based user simulation has emerged as promising alternative to static recommendation metrics and costly online A/B testing. Initial approaches focused on realistic persona construction. Agent4Rec [50] models social traits like conformity from real-world data, while Profile-aware simulators [7] utilize natural language summaries of user history to align with human judgment. Enhancing psychological fidelity, PUB [31] further integrates Big Five personality traits [9, 38] to replicate diverse interaction patterns. Recent research shifts focus to utilizing user simulators for system optimization. RecoMind [1] employs the simulator as virtual training environment to refine RL policies for long-term engagement. Meanwhile, RecoWorld [29] establishes proactive feedback loop, where the simulator explicitly signals user states (e.g., boredom) to guide the recommenders adaptation."
        },
        {
            "title": "3 Problem Definition\nDataset. Let D = (U, V, E, X) denote the dataset with user set\nU and item set V. The interaction set (ùë¢, ùë£, ùë°ùë¢,ùë£, ùëüùë¢,ùë£, revùë¢,ùë£) ‚àà E\nindicates that user ùë¢ ‚àà U interacted with item ùë£ ‚àà V at timestamp\nùë°ùë¢,ùë£, providing a rating ùëüùë¢,ùë£ and a textual review revùë¢,ùë£. Based on E,\nwe define the interaction history for user ùë¢ as Hùë¢ = {ùë£ | (ùë¢, ùë£, ùë°ùë¢,ùë£) ‚àà\nE}, chronologically ordered by ùë°ùë¢,ùë£. Additionally, ùë•ùë£ ‚àà X denotes\nthe set of side information, where ùë•ùë£ represents the raw attribute\nset for item ùë£ (e.g., category, title, and price).",
            "content": "Optimization Goal. Let denote the entire codebase governing the recommendation pipeline within the open-ended program space S. The evolutionary process starts with seed codebase (0) and proceeds through ùëá iterations, where (ùë° ) represents the evolved codebase at iteration ùë°. Specifically, (0) constitutes fully functional seed recommendation pipeline, encapsulating seed recommender architecture ùëì (0) ) (e.g., NCF [14]), data processing logic (e.g., basic loaders for interactions and raw attributes X), and standard optimization loop (e.g., loss computation, and parameter updates). Our goal is to evolve this seed codebase (0) into an optimal codebase that maximizes standard recommendation metric (e.g., Hit Ratio, NDCG) within ùëá iterations. We formulate this code evolution task as bi-level optimization problem: (0) (; ùúÉ = argmax )(cid:1) (cid:0)ùëìB ( Eval, X; ùúÉ (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:125) (cid:124) score(B) s.t. ùúÉ = argmin ùúÉ LB (ùëìB ( Etrain, X; ùúÉ ) ) (1) where represents the loss function defined within B. Here, ùúÉ indicates the optimal model parameters for the architecture defined by B, learned on the training set Etrain by minimizing B. 4 Proposed Framework: Self-EvolveRec In this section, we propose Self-EvolveRec, novel framework designed to enable LLMs to perform directional feedback-based evolutionary code optimization for recommender systems. As illustrated in Figure 1, Self-EvolveRec operates through two core mechanisms to overcome the limitations of existing metric-based approaches [30, 36]. First, we establish Directional Feedback Generation (Sec. 4.1, Figure 1 (a)), which integrates User Simulator (Sec. 4.1.1) and Model Diagnosis Tool (Sec. 4.1.2) to provide qualitative and quantitative guidance. By integrating simulator critiques with diagnostic verifications, Self-EvolveRec enables the LLM agent to identify the root causes of failures in the recommendation pipeline beyond numerical performance alone. This feedback then guides the Evolution Pipeline (Sec. 4.2, Figure 2) to perform precise, deterministic code modifications. Second, we introduce Diagnosis Tool - Model Co-evolution (Sec. 4.3, Figure 1 (b)), strategy that ensures the diagnosis tool to dynamically adapt to the structural changes of the recommendation pipeline, maintaining the validity of the feedback loop throughout the evolution process. 4.1 Directional Feedback Generation While scalar metrics (e.g., NDCG) quantify how well recommendation pipeline performs, they lack the semantic depth to explain why it fails or how to resolve it. To address this, we introduce Directional Feedback, which integrates qualitative critiques from the User Simulator and quantitative verifications from the Model Diagnosis Tool. This mechanism translates non-interpretable numerical metrics into actionable insights, enabling the LLM to pinpoint and resolve structural deficiencies within the recommendation pipeline."
        },
        {
            "title": "4.1.1 User Simulator: Qualitative Critique. We employ a User\nSimulator (SIM) to complement standard metrics with qualitative\ndirectional feedback. While scalar metrics (e.g., NDCG) quantify",
            "content": "Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. how well model performs, they fail to reveal the root causes of failure [33] such as insufficient category diversity or an inability to capture short-term interests. By adopting the agentic paradigm [31, 50], as depicted in Figure 1 (a.1), our simulator acts as diverse set of virtual users, offering explicit natural language critiques that pinpoint specific deficiencies in the recommendation pipeline. To ensure behavioral realism and heterogeneity, we characterize each simulated user ùë¢ through structured persona Tùë¢ . This persona is constructed by combining the users interaction history Hùë¢ with sociopsychological traits [34, 50]. Following previous studies [50], we primarily utilize three key traits: (1) Activity represents the users engagement level, quantified by the length of their interaction history; (2) Conformity measures the adherence to mainstream tastes, calculated based on the deviation between the users specific ratings and the global average rating of items; and (3) Diversity reflects the breadth of interests, defined as the number of unique categories within the users interaction set. Based on these definitions, we compute numerical scores for each trait and categorize them into three levels (i.e., LOW, MID, HIGH) using quantile-based thresholds. These levels are then mapped to predefined natural language descriptions (e.g., \"Activity (HIGH): Frequently interacts with the recommender system ...). Further details on calculating these traits are described in App. B. These traits condition the LLM to exhibit distinct behavioral patterns, ranging from passive users to highly active users with diverse interests. Note that our framework is agnostic to specific persona definitions. Therefore, alternative traits like the Big Five [9, 31] can be integrated, as explored in App. F.2. The feedback generation process proceeds in two steps. First, SIM conducts an individual assessment for sampled user ùë¢ by evaluating the recommendation list Aùë¢ from trained recommender ùëìB (e.g., NCF) based on their persona Tùë¢ and interaction history Hùë¢ . This assessment identifies specific behavioral or semantic misalignment, which is formalized into an individual qualitative feedback report ùëÖùë¢ = LLM(ISIM, Tùë¢, Hùë¢, Aùë¢ ), where ISIM is instruction for user simulator1. Second, to mitigate individual user bias and capture common failure patterns, we summarize reports from set of sampled users Usample into comprehensive summary: RSIM = LLM( ISUMMARIZE, {ùëÖùë¢ ùë¢ Usample } ) (2) where ISUMMARIZE guides the LLM to abstract common failure patterns from individual critiques."
        },
        {
            "title": "4.1.2 Model Diagnosis Tool: Quantitative Verification. While\nthe SIM generates qualitative feedback from user experience, rely-\ning solely on this feedback fails to detect hidden structural issues\nsuch as embedding collapse. To address this, we introduce the Model\nDiagnosis Tool (DIAG; denoted as DIAG(ùë° ) at iteration ùë°), which is\na computational probing module designed to verify structural or\nbehavioral deficiencies of the recommender system. As depicted\nin Figure 1 (a.2), unlike the SIM, the DIAG(ùë° ) directly accesses the\nmodel parameters ùúÉ and data loaders within the codebase B (ùë° ) to\nconduct a systematic validity check.",
            "content": "As the seed diagnosis tool DIAG(0) (0) , we implement two foundational probes to detect common structural failures: 1Throughout the paper, we denote the task-specific instructions guiding the LLM-agent as Itask (e.g., ISIM, IPLAN, ICODE). While we describe the high-level objective of each instruction within the main text, the exact prompt templates are provided in App. G.1. Figure 2: Overall evolutionary pipeline of Self-EvolveRec. 1) Embedding Collapse: To detect state where representations degenerate into narrow subspace losing discriminative power, DIAG computes the mean pairwise cosine similarity across sampled item embeddings. high similarity score serves as proxy for representation degeneration. 2) Ranking Margin: DIAG evaluates decision boundaries by analyzing the ranking margin Œîùë¢,ùë£ = ùë† (ùë¢, ùë£) ùë† (ùë¢, ùë£ ) for all users ùë¢ and their observed interactions ùë£ Hùë¢ . Here, ùë† (ùë¢, ùë£) and ùë† (ùë¢, ùë£ ) denote the predicted logits for the ground-truth item ùë£ and randomly sampled negative item ùë£ Hùë¢ , respectively. To assess overall discriminative power, DIAG computes the global average margin Eùë¢ U,ùë£ Hùë¢ [Œîùë¢,ùë£]. Specifically, high margin indicates robust discrimination between ground-truth item and negative item, whereas low or negative margin indicates failure to distinguish ground-truth. To pinpoint the potential failure modes of such failures, DIAG aggregates cases with extremely low margins and counts their common attributes (e.g., specific categories like Computers in Figure 1 (a.2) - \"core_findings\"). These probes generate set of raw numerical diagnostics analysis ùê∑raw = DIAG(ùë° ) (B (ùë° ) ). Subsequently, to bridge the gap between numerical diagnostics and algorithmic solutions, an LLM acts as senior researcher to interpret these signals, converting them into structured diagnosis report: RDIAG = LLM( IDIAG, ùê∑raw ) (3) Furthermore, DIAG serves as verification mechanism to check whether the qualitative deficiencies pointed out by SIM have actually resolved (detailed in Sec. 4.3)."
        },
        {
            "title": "4.2 Evolution Pipeline\nIn this section, we detail the iterative execution workflow of Self-\nEvolveRec, designed to autonomously refine the codebase B through\ncycles of evaluation, reasoning, and evolution. To support these\ncycles, Self-EvolveRec adopts a population-based exploration strat-\negy [30, 36, 39, 45] by maintaining an Evolutionary Archive P (ùë° )",
            "content": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY that stores the comprehensive history of codebases and feedback. At each iteration, target codebase is selected from this archive to serve as the parent, denoted as Bparent Sample(P (ùë° ) ). Unlike existing studies [30, 36] that rely solely on scalar metrics, which often lead to aimless exploration, Self-EvolveRec actively integrates the Directional Feedback mechanisms (Sec. 4.1). By integrating qualitative insights from the user feedback report (RSIM) and quantitative findings from the diagnosis report (RDIAG), Self-EvolveRec shifts the focus from mere scalar metrics to pinpoint the root causes of failure. As illustrated in Figure 2, Self-EvolveRec follows fourphase workflow to address these failures and evolve the codebase. We first detail the three-phase workflow dedicated to refinement of the recommendation codebase, i.e., 1), 2), and 3) in Figure 2 (Bparent (ùë° +1) )2, followed by the Diagnosis Tool Co-Evolution stage, i.e., 4) in Figure 2 (Sec. 4.3). 1) Multi-faceted Evaluation. First, Self-EvolveRec evaluates the currently selected codebase Bparent to obtain the scalar score shown in Equation 1 (i.e., score(Bparent)), while simultaneously generating 3. These outputs the user feedback RSIM and diagnosis report RDIAG serve as the directional context for the subsequent planning. 2) Feedback-Aware Planning & Retrieval. Self-EvolveRec introduces feedback-aware planning & retrieval that shifts the RAG methods in previous work [30] from general-purpose knowledge gathering to targeted failure resolution. By conditioning on directional feedback from RSIM and RDIAG, the LLM agent acts as planner to formulate precise feedback targeted research queries = LLM(IPLAN, RSIM, RDIAG, (ùë° ) ). Conditioned on specific failure modes and the evolutionary archive (ùë° ) , the agent generates targeted queries (e.g., \"Retrieve methods to mitigate category mismatch identified in user reports\") to retrieve relevant academic literature from online sources, including arXiv. These targeted queries ensure retrieval focusing on resolving the identified structural deficiencies, rather than broad algorithmic exploration. These insights are then integrated into structured Development Report: RDev = LLM( IREPORT, RSIM, RDIAG, (ùë° ) , ) where RDev outlines the algorithmic modifications required to address the identified issues. 3) Code Evolution. Guided by RDev, the agent implements codelevel modifications to instantiate the updated codebase (ùë° +1) = LLM(ICODE, RDev, Bparent, (ùë° ) ). Upon successful execution, the new codebase (ùë° +1) is incorporated into the population history (ùë° +1) , following standard evolutionary protocols [30, 36]. This cycle recursively refines to optimize the objective defined in Equation 1. (4)"
        },
        {
            "title": "4.3 Diagnosis Tool - Model Co-Evolution\nThe evolution of the DIAG (i.e., 4) in Figure 2) is driven by two\nobjectives: First, as B undergoes structural transformations, such\nas the introduction of new loss functions or architectural layers, a\nstatic DIAG inevitably becomes obsolete. DIAG must continuously",
            "content": "2The Model Diagnosis Tool is also part of the codebase B. However, its evolution is conducted separately as described in Sec. 4.3. Thus, although Sec. 4.2 focuses on evolving excluding the diagnosis tool, we do not explicitly distinguish them for notational convenience. 3To maximize efficiency, if the selected codebase Bparent is already recorded in the archive (ùë° ) with complete evaluation logs, Self-EvolveRec retrieves the cached results instead of re-executing the evaluation process. adapt to analyze and evaluate these new components effectively. Second, DIAG serves to quantitatively verify the qualitative insights provided by the SIM. While the SIM offers rich, human-like critiques that traditional metrics fail to capture (e.g., perceiving recommendation list as \"conceptually repetitive\" despite high accuracy scores), these subjective critiques must be translated into measurable metrics to confirm their validity and assess their impact for precise code optimization. Therefore, DIAG evolves to stay compatible with the evolved codebase while formulating specific metrics that mathematically capture the essence of the SIMs feedback. As depicted in Figure 1 (b), if the SIM reports \"boredom due to lack of diversity\", DIAG autonomously implements tailored metric (e.g., measuring diversity among top-k items) to quantify this feedback precisely, ensuring that the subsequent evolution is guided by concrete objectives. To address this, we implement co-evolution mechanism that begins with understanding the structural shifts. Since the codebase is continuously updated (Bparent (ùë° +1) ), the agent first scans the new codebase (ùë° +1) and original DIAGparent 4 to generate structural analysis report: RAnalyze = LLM( IAnalyze, (ùë° +1) , DIAGparent ) (5) The RAnalyze summarizes key information such as the updated execution flow, newly added modules, and modified loss functions. This blueprint enables the agent to design diagnostic criteria that are structurally compatible with the new architecture. Subsequently, to synchronize the diagnosis tool with both the structural changes and the user feedback RSIM, the agent executes the evolution cycle. By integrating the qualitative RSIM with the structural blueprint RAnalyze, the agent identifies evaluation gaps (e.g., cannot verify new encoder, and embedding). Similar to the main pipeline (Sec. 4.2), it retrieves relevant methodologies KDIAG using research queries QDIAG = LLM and then updates the DIAG: IPLAN-DIAG, RSIM, RAnalyze, (ùë° ) (cid:17) (cid:16) RDev-DIAG = LLM (cid:0)IREPORT-DIAG, RSIM, RAnalyze, KDIAG DIAG(ùë° +1) = LLM (6) ICODE-DIAG, RDev-DIAG, (ùë° +1), DIAGparent, (ùë° ) (cid:17) (cid:1) , (cid:16) The new model diagnosis tool DIAG(ùë° +1) is incorporated into the population history (ùë° +1) . This adaptive process guarantees that DIAG(ùë° +1) is equipped with both the logic to inspect new architectures and the specific metrics required to transform the simulators qualitative feedback into actionable, quantitative signals. We further investigate the additional evolutionary pipeline of the User Simulator in experiments in Sec. 5.3.3."
        },
        {
            "title": "5 Experiments\nDatasets. For evaluations, we used three Amzaon datasets [15]\n(CDs, Electronics, and Office) and the MovieLens dataset [12]. Fol-\nlowing prior works [17, 20, 44], we use five-core datasets, ensuring\nthat each user and item has at least five interactions. Detailed sta-\ntistics for each dataset are provided in Table 7 in App. D.",
            "content": "4The agent retrieves the corresponding model diagnosis tool DIAGparent that was originally paired with Bparent from the (ùë° ) . Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Baselines. We evaluate Self-EvolveRec against representative NASbased recommender architecture search methods, including AutoFIS [28] and NASRec [51], as well as recent LLM-driven evolutionary frameworks such as AlphaEvolve [36] and DeepEvolve [30]. Details regarding the baseline methods are provided in App. E.1. Evaluation Protocol. We use the leave-last-out strategy [3, 17, 22, 44, 46] for evaluation or recommender models, where we use the most recent item and second most item for testing and validation, respectively, and the remaining history for training. Each test item is paired with 99 random sampled non-interacted items. We report performance using two standard metrics: Normalized Discounted Cumulative Gain (NDCG@5) and Hit Ratio (HR@5). Implementation Details. To ensure fair comparisons, all evolutionbased methods are initialized with four distinct seed recommenders: NCF [14] (MF-based), NGCF [47] (graph-based), SASRec [17] (sequential), and MoRec [49] (multi-modal). We employ GPT-5-mini for planning and retrieval, while utilizing GPT-5 as the coding agent for all frameworks. To account for the computational overhead associated with these LLMs, we provide comprehensive efficiency analysis, including time cost per iteration and user sampling impact, in App. F.1. Please refer to the App. and E.2 for more details regarding the seed recommender and hyper-parameters settings."
        },
        {
            "title": "5.1.2 User Satisfaction Analysis. To bridge the gap between\nstatic metrics and actual user satisfaction, we adopt the agentic",
            "content": "Figure 3: LLM-as-a-Judge evaluation of the evolved models. simulation environment from Agent4Rec [50] and PUB [31] as scalable proxy for A/B testing. In this dynamic environment, generative agents driven by distinct traits (e.g., Big Five) are presented with pages of four items and decide whether to continue or terminate the session based on relevance and diversity. Following Agent4Rec, we quantify this simulation using three key metrics: View (item view ratio), Satisfy (a comprehensive score about recommender from 1 to 10), and Depth (the number of pages explored before termination). Notably, in the Agent4Rec setup, agents terminate recommendation sessions upon encountering unsatisfactory items, indicating that higher Depth signifies successful user retention through consistently relevant recommendations. The results of the user satisfaction are summarized in Table 2. From the results, we have the following observations: 1) Self-EvolveRec consistently outperforms all baselines across all satisfaction-oriented metrics (i.e., View, Satisfy, and Depth) regardless of the seed model. These results demonstrate that the directional feedback from the user simulator (i.e., RSIM) enables the models to evolve beyond mere accuracy, substantially improving the perceived quality of recommendations from user-centric perspective, and sustaining user engagement for longer durations. 2) In contrast, AlphaEvolve and DeepEvolve show suboptimal generalization to user-centric metrics and, in some cases, even underperform the initial models. This suggests that scalar metric-only optimization is insufficient to capture the complex dynamics of the user experience. Without guidance, the evolved models tend to overfit to narrow numerical targets, which degrades overall user satisfaction."
        },
        {
            "title": "5.1.3 Codebase Quality Evaluation. To verify substantive al-\ngorithmic improvements beyond numerical gains, we employ an\nLLM-as-a-judge (GPT-5) to evaluate the code of the recommender\nmodel in all evolved codebases presented in Table 1 on a 1-10 scale\nagainst the recommender model in the seed codebase. The evalua-\ntion covers four dimensions: Creativity (novel mechanisms beyond\nsimple parameter tuning), Explicitness (interpretability of logic\nflows), Insight (logical intention to resolve specific failures, e.g.,\npopularity bias), and Personalization (user-context awareness).\nDetailed prompts for these criteria are provided in App. G.2. From\nthe results in Figure 3, we have the following observations: 1) Self-\nEvolveRec consistently achieves the highest scores across all criteria.\nSpecifically, the high scores in Creativity and Insight validate the ef-\nfectiveness of our directional feedback loop, which integrating SIM\nand DIAG, enables targeted logic refinement, whereas scalar-driven\nbaselines rely on inefficient trial-and-error without understanding\nthe underlying problems in codebase. 2) Self-EvolveRec shows a\nsubstantial gain in Personalization (+50% over baselines). This su-\nperiority is driven by the SIM, which forces the evolution to reflect\nspecific user needs directly into the algorithmic logic. Conversely,",
            "content": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Table 1: Overall model performance (S: Seed Recommender Model, A: AlphaEvolve, D: DeepEvolve). Dataset Metric NAS Seed Recommender: NCF Seed Recommender: NGCF Seed Recommender: SASRec Seed Recommender: MoRec AutoFIS NASRec A Ours D Ours Ours A Ours CDs Electronics Office MovieLens NDCG@5 HR@5 NDCG@5 HR@5 NDCG@5 HR@5 NDCG@5 HR@5 0.2077 0. 0.1753 0.2456 0.1714 0.2490 0.1369 0.2099 0.2026 0.2989 0.1706 0.2444 0.1377 0. 0.2916 0.4346 0.2312 0.2979 0.1078 0.1610 0.1620 0.2343 0.3413 0.4970 0.2556 0. 0.1183 0.1733 0.1751 0.2523 0.3465 0.5091 0.2421 0.3497 0.1817 0.2600 0.1705 0. 0.1908 0.2735 0.2723 0.3799 0.1907 0.2714 0.1759 0.2659 0.3764 0.5475 0.3446 0. 0.1531 0.2247 0.1711 0.2494 0.1824 0.2876 0.3449 0.4896 0.1808 0.2590 0.1799 0. 0.2355 0.3672 0.3280 0.4465 0.1726 0.2385 0.1805 0.2591 0.2010 0.3162 0.3721 0. 0.1925 0.2759 0.1930 0.2743 0.3588 0.5220 0.3559 0.4676 0.2325 0.3208 0.1799 0. 0.5667 0.7283 0.3528 0.4623 0.2063 0.2891 0.1939 0.2750 0.5583 0.7199 0.3610 0. 0.2508 0.3427 0.1816 0.2631 0.5722 0.7344 0.3865 0.5274 0.2600 0.3591 0.2329 0. 0.5765 0.7366 0.2558 0.3779 0.1883 0.2724 0.1851 0.2689 0.3796 0.5414 0.2414 0. 0.1912 0.2675 0.1848 0.2633 0.4993 0.6743 0.3701 0.4864 0.1938 0.2745 0.1697 0. 0.5281 0.6967 0.3977 0.5340 0.2056 0.2921 0.1884 0.2703 0.5460 0.7131 Table 2: Multi-facet satisfaction metrics on SASRec and NCF under two agentic evaluators (Agent4Rec and PUB). Table 3: Ablation studies on the components of SelfEvolveRec (Seed Recommender: SASRec). Seed Recommender Agentic Evaluator Metric CDs Electronics D Ours D Ours SASRec NCF Agent4Rec View 0.372 0.378 0.379 0.381 0.335 0.342 0.351 0.353 Satisfy 4.606 4.384 4.710 5.046 4.173 4.308 4.487 4.502 Depth 1.926 1.830 1.952 2.048 1.754 1.778 1.782 1. PUB View 0.128 0.122 0.130 0.136 0.133 0.134 0.141 0.144 Satisfy 4.630 4.506 4.810 4.906 3.928 3.972 4.082 4.134 Depth 1.912 1.910 1.922 2.018 1.856 1.888 1.904 1.928 Agent4Rec View 0.365 0.354 0.369 0.372 0.339 0.337 0.307 0.342 Satisfy 4.206 4.461 4.392 4.650 4.320 4.270 4.132 4.354 Depth 1.776 1.882 1.840 1.934 1.786 1.744 1.720 1.798 PUB View 0.125 0.127 0.119 0.134 0.135 0.125 0.124 0.139 Satisfy 4.488 4.650 4.422 4.770 3.842 3.826 3.564 3.952 Depth 1.914 1.918 1.940 1.952 1.874 1.768 1.754 1. baselines merely evolve the models based on numerical metrics, failing to address specific user needs. 3) AlphaEvolve exhibits inferior performance across all criteria due to the absence of external knowledge. Unlike RAG-based methods (DeepEvolve and Self-EvolveRec), its reliance on internal knowledge restricts the discovery of novel mechanisms, underscoring the necessity of retrieving external insights for open-ended development."
        },
        {
            "title": "Row",
            "content": "(1) (2) (3) (4) (5) (6)"
        },
        {
            "title": "Electronics",
            "content": "SIM DIAG Co-Evolve NDCG@5 HR@5 NDCG@5 HR@5 0.3610 0.3751 0.3676 0.3789 0.3727 0.3865 0.4870 0.5102 0.4791 0.5164 0.5014 0. 0.2508 0.2573 0.2515 0.2584 0.2532 0.2600 0.3427 0.3551 0.3449 0.3566 0.3520 0.3591 Table 4: Performance comparison under extreme initialization scenarios (Random and Ensemble). Peak indicates the iteration number of the best performance. Dataset Seed Recommender AlphaEvolve DeepEvolve Ours NDCG@5 HR@5 NDCG@5 HR@5 Peak NDCG@5 HR@5 Peak NDCG@5 HR@5 Peak Seed Recommender: Random CDs Electronics 0.0312 0.0310 0.0525 0.0531 0.3430 0.2037 0.4549 0. 15 19 0.3766 0.1972 0.4963 0.2761 13 18 0.3883 0.2109 0.5165 0. Seed Recommender: NCF+NGCF+SASRec 0.3864 0.2496 CDs Electronics 0.5179 0.3246 0.3946 0.2385 0.5075 0.3386 FAIL 0.3695 0.2353 0.5002 0.3240 17 FAIL 0.4105 0.2524 0.5409 0.3426 8"
        },
        {
            "title": "5.3 Model Analysis\n5.3.1 Adaptability to extreme initialization scenarios. To fur-\nther validate the adaptability of Self-EvolveRec, we evaluate its\nperformance under two extreme initialization settings: a Random\nrecommender representing a development starting from scratch,\nand a highly optimized Ensemble (NCF + NGCF + SASRec) reflect-\ning a sophisticated industrial deployment. We have the following\nobservations in Table 4: 1) Even starting from a random recom-\nmender, Self-EvolveRec successfully evolves a fully functional and\nhighly competitive recommender pipeline. Self-EvolveRec reaches\nthe peak performance at the 8th (CDs) and the 11th (Electronics)\niterations, significantly faster than baselines (13 to 19 iterations).\nThis confirms that directional feedback systematically constructs\nvalid pipelines by resolving structural deficiencies, avoiding the\naimless trial-and-error of scalar-driven methods. 2) In the ensemble\nsetting, achieving further gains is exceedingly challenging due to\nthe high initial performance and structural complexity. We observe\nthat scalar-only baselines, AlphaEvolve and DeepEvolve, struggle\nto navigate the structural complexity of the ensemble, even de-\ngrading the initial performance. In contrast, Self-EvolveRec consis-\ntently identifies and resolves latent bottlenecks within the ensemble,\ndemonstrating that directional feedback is effective even in high-\nperformance regimes, where numerical scores alone fail to provide\nguidance for optimizing such structurally complex systems.",
            "content": "These results demonstrate Self-EvolveRec as comprehensive solution for the industrial lifecycle, which frequently alternates between building new services for new domains and refining highperformance ensemble models for established services [2, 10, 23, 48]. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Table 5: Performance when Feedback-aware Planning & Retrieval is removed (Seed Recommender: SASRec). C: Creativity, E: Explicitness, I: Insight, P: Personalization."
        },
        {
            "title": "Codebase Quality",
            "content": "NDCG@5 HR@5 NDCG@5 HR@5 AlphaEvolve DeepEvolve Self-EvolveRec 0.3528 0.3610 0.3865 0.4623 0.4870 0.5274 0.2063 0.2508 0. 0.2891 0.3427 0.3591 w.o. Planning 0.3988 0.5134 0.2597 0. 4.5 7.5 8.0 6.5 5.0 6.0 7.5 6.0 6.5 7.5 8.0 8.0 3.0 4.0 6.5 4.5 Table 6: Evolving User Simulator. Accuracy denotes the accuracy of identifying the target item from 20 candidates. Recommendation Performance (Performance of Evolved NCF) Simulator Reliability (Performance of SIM) Dataset Evolution Strategy NDCG@5 CDs Electronics - Fixed Simulator Evolved Simulator - Fixed Simulator Evolved Simulator - 0.2723 0.2745 - 0.1907 0.1891 HR@5 - 0.3799 0. - 0.2714 0.2744 SIM Type Accuracy NCF (Baseline) Initial SIM Evolved SIM NCF (Baseline) Initial SIM Evolved SIM 0.2882 0.3473 0. 0.2191 0.2238 0."
        },
        {
            "title": "5.3.2 Removing Feedback-aware Planning & Retrieval. To\nevaluate the contribution of the feedback-aware planning & re-\ntrieval introduced in Sec. 4.2, we compare Self-EvolveRec against\na variant that excludes Planning & Retrieval shown in Equation 4,\ndenoted as w.o. Planning in Table 5. In this variant, the agent gen-\nerates code directly based on the directional feedback through the\ncode evolution step as B (ùë° +1) = LLM(ICODE, RSIM, RDIAG, Bparent,\nP (ùë° ) ) instead of B (ùë° +1) = LLM(ICODE, RDev, Bparent, P (ùë° ) ). From\nthe results in Table 5, we have the following observations: 1) w.o.\nPlanning achieves comparable recommendation performance to\nthe original Self-EvolveRec. This implies that the primary driver of\nperformance is the precise identification of failure modes via direc-\ntional feedback, rather than the incorporation of external research\nideas. 2) However, the absence of planning significantly degrades\ncodebase quality.5 While Insight remains high (effectively identify\nwhat is wrong), w.o. Planning exhibits substantial drops in Creativ-\nity and Explicitness, along with a notable decline in Personalization.\nThis suggests that without planning, the agent relies on local heuris-\ntic patches rather than systematic, modular designs grounded in\nexternal knowledge. 3) While DeepEvolve achieves high Creativity\nvia external knowledge (RAG), w.o. Planning achieves higher Per-\nsonalization. This confirms that the directional feedback from SIM,\nwhich captures specific user needs, is more crucial for personaliza-\ntion than generic knowledge retrievals.",
            "content": "Evolving User Simulator. Although our framework em5.3.3 ploys fixed user simulator for efficiency, we further investigate the impact of evolving the user simulator alongside the codebase. Analogous to Sec. 4.3, the co-evolution of the user simulator follows the same structured workflow of analysis, retrieval, and planning. Specifically, the LLM analyzes the current simulator and synthesizes development plan RDev-SIM using retrieved methodologies KSIM, yielding the evolved simulator: SIM(ùë° +1) = LLM(ICode-SIM, RDev-SIM, SIMparent, (ùë° ) ). In Table 6, we evaluate simulator reliability by measuring the accuracy of identifying the target item from 20 candidates, utilizing simple recommender model, NCF, as 5We use the evaluation criteria from Sec. 5.1.3 to evaluate the evolved models in Table 5. Figure 4: Case study on Diagnosis Tool - Model Co-Evolution on CDs dataset (Seed Recommender: SASRec). baseline. While the recommendation performance remains comparable, the SIMs accuracy reveals the following observation: 1) The comparable recommendation performance indicates that the initial SIM is already effective for modeling complex user preferences, achieving an accuracy superior to the NCF (see Simulator Reliability). This result indicates that the SIM provides reliable, high-quality directional feedback that captures complex user intent in decision making processes on given recommendation list. Consequently, even without evolving the simulator, the feedback signals from RSIM are already robust enough to guide the Self-EvolveRec toward an optimal codebase. 2) Nevertheless, evolution on SIM further elevates the simulators reliability. The evolved SIM achieves an even higher accuracy compared to its initial state. This confirms that while the resulting recommendation score are similar on evolved codebase, the evolutionary process constructs statistically more trustworthy feedback, ensuring that the directional feedback is grounded in realistic user behavior patterns."
        },
        {
            "title": "5.3.5 Case Study 2: Evolutionary Trajectory. To validate the\neffectiveness of the directional feedback loop, we conducted a case\nstudy comparing the evolutionary trajectories of Self-EvolveRec against",
            "content": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY"
        },
        {
            "title": "6 Conclusion\nIn this paper, we propose a novel LLM-driven code evolution frame-\nwork, named Self-EvolveRec. The main idea is to overcome the\nlimitations of existing scalar metric-based code optimization by\nestablishing a directional feedback loop that integrates qualitative\ncritiques from a User Simulator with quantitative verification from a\nModel Diagnosis Tool. By doing so, Self-EvolveRec significantly out-\nperforms state-of-the-art evolutionary baselines based on NAS and\nLLM in both standard recommendation accuracy and multi-faceted\nuser satisfaction. Moreover, we demonstrate the indispensability\nof our Diagnosis Tool - Model Co-Evolution strategy, which en-\nsures that diagnostic criteria dynamically adapt to structural shifts,\nmaintaining a grounded and reliable feedback loop throughout the\nprocess. Lastly, we show the potential of Self-EvolveRec in practi-\ncal industrial deployment, demonstrated by its robust adaptability\nacross diverse initialization settings (from scratch to complex en-\nsembles) and the functional reliability of the co-evolved Diagnosis\nTool in accurately pinpointing structural deficiencies. In future\nwork, we plan to address the computational overhead associated\nwith the iterative training and evaluation of evolved models. We\naim to explore more efficient evaluation protocols, such as pre-\ndicting model performance directly from architectural descriptions\nusing LLMs [16], to accelerate the evolutionary cycle.",
            "content": "Figure 5: Case study on evolutionary trajectory on CDs dataset (Seed Recommender: SASRec). (a) is comparison of evolutionary paths. Color-coded markers (e.g., Red) illustrate causal alignment between directional feedback and evolved codebase. (b) is performance comparison across iterations. baselines. Figure 5 (a) illustrates the step-by-step evolution of codebases, while Figure 5 (b) tracks the performance progress over all iterations. We have the following observations: 1) Self-EvolveRec shows structured evolutionary path, where algorithmic improvements are causally linked to identified failures. For instance, in Iteration (0 1), RSIM explicitly flagged \"Ignores Subgenre\", while RDIAG detected \"High Embedding Collapse.\" Guided by this directional feedback, the agent introduced \"Category-Aware Hard Negatives\" and \"Popularity-annealed Weighting,\" resulting in an immediate performance increment (HR: 0.4676 0.5138). 2) In contrast, baselines exhibit unstable or delayed progress due to their reliance on scalar metrics. AlphaEvolve attempts an erroneous combination of loss functions (BCE + BPR) at Iteration 3, causing significant performance drop, which is only rectified by removing the module at Iteration 7. Consequently, it does not exceed its initial performance state throughout the evolution. DeepEvolve suffers from prolonged stagnation in low-performance regions, as evident in Figure 5 (b), and only manages gain at Iteration 15 by retrieving the RefinedLogQ module. Due to such inefficient exploration, as observed in Figure 5 (b), both baselines remain trapped in low-performance regions (ùêªùëÖ@5 : 0.05 0.25), failing to escape suboptimal states throughout the evolution process. Conversely, Self-EvolveRec leverages directional feedback to maintain robust evolutionary trajectory. Additional case study is provided in App. F.3.2. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. References [1] Mehdi Ben Ayed, Fei Feng, Jay Adams, Vishwakarma Singh, Kritarth Anand, and Jiajing Xu. 2025. RecoMind: reinforcement learning framework for optimizing in-session user satisfaction in recommendation systems. arXiv preprint arXiv:2508.00201 (2025). [2] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 710. [3] Seungyoon Choi, Sein Kim, Hongseok Kang, Wonjoong Kim, and Chanyoung Park. 2025. Dynamic Time-aware Continual User Representation Learning. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (Padua, Italy) (SIGIR 25). Association for Computing Machinery, New York, NY, USA, 740749. doi:10.1145/3726302.3729959 [4] Yuanzheng Ci, Chen Lin, Ming Sun, Boyu Chen, Hongwen Zhang, and Wanli Ouyang. 2021. Evolving search space for neural architecture search. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 66596669. [5] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations (RecSys 16). Association for Computing Machinery, New York, NY, USA. doi:10.1145/2959100.2959190 [6] Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. 2019. Neural architecture search: survey. Journal of Machine Learning Research 20, 55 (2019), 121. [7] Francesco Fabbri, Gustavo Penha, Edoardo DAmico, Alice Wang, Marco De Nadai, Jackie Doremus, Paul Gigioli, Andreas Damianou, Oskar St√•l, and Mounia Lalmas. 2025. Evaluating podcast recommendations with profile-aware llm-as-a-judge. In Proceedings of the Nineteenth ACM Conference on Recommender Systems. 1181 1186. [8] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: survey. arXiv preprint arXiv:2312.10997 2, 1 (2023). [9] Lewis R. Goldberg. 1992. THE DEVELOPMENT OF MARKERS FOR THE BIGFIVE FACTOR STRUCTURE. Psychological Assessment 4 (1992), 2642. https: //api.semanticscholar.org/CorpusID:144709415 [10] Carlos A. Gomez-Uribe and Neil Hunt. 2016. The Netflix Recommender System: Algorithms, Business Value, and Innovation. 6, 4 (2016). doi:10.1145/2843948 [11] Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, et al. 2024. survey on llm-as-a-judge. The Innovation (2024). [12] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5, 4, Article 19 (Dec. 2015), 19 pages. doi:10.1145/2827872 [13] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. 639648. [14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173182. [15] Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian McAuley. 2024. Bridging Language and Items for Retrieval and Recommendation. arXiv preprint arXiv:2403.03952 (2024). [16] Ganesh Jawahar, Muhammad Abdul-Mageed, Laks Lakshmanan, and Dujian Ding. 2024. Llm performance predictors are good initializers for architecture search. In Findings of the Association for Computational Linguistics: ACL 2024. 1054010560. [17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 197206. [18] Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, and Hwanjo Yu. 2016. Convolutional Matrix Factorization for Document Context-Aware Recommendation (RecSys 16). Association for Computing Machinery, New York, NY, USA. doi:10.1145/2959100.2959165 [19] Jiwan Kim, Hongseok Kang, Sein Kim, Kibum Kim, and Chanyoung Park. 2025. Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (Padua, Italy) (SIGIR 25). Association for Computing Machinery, New York, NY, USA, 18201829. doi:10.1145/3726302.3729953 [20] Kibum Kim, Sein Kim, Hongseok Kang, Jiwan Kim, Heewoong Noh, Yeonjun In, Kanghoon Yoon, Jinoh Oh, and Chanyoung Park. 2025. Image is All You Need: Towards Efficient and Effective Large Language Model-Based Recommender Systems. arXiv preprint arXiv:2503.06238 (2025). [21] Sein Kim, Hongseok Kang, Seungyoon Choi, Donghyun Kim, Minchul Yang, and Chanyoung Park. 2024. Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Barcelona, Spain) (KDD 24). Association for Computing Machinery, New York, NY, USA, 13951406. doi:10.1145/3637528.3671931 [22] Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian McAuley, and Chanyoung Park. 2025. Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2 (Toronto ON, Canada) (KDD 25). Association for Computing Machinery, New York, NY, USA, 11601171. doi:10.1145/3711896.3737035 [23] Sein Kim, Namkyeong Lee, Donghyun Kim, Minchul Yang, and Chanyoung Park. 2023. Task Relation-aware Continual User Representation Learning. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD 23). Association for Computing Machinery, New York, NY, USA, 11071119. doi:10.1145/3580305.3599516 [24] Wonjoong Kim, Sangwu Park, Yeonjun In, Sein Kim, Dongha Lee, and Chanyoung Park. 2025. Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents. arXiv preprint arXiv:2510.02837 (2025). [25] Ravi Krishna, Aravind Kalaiah, Bichen Wu, Maxim Naumov, Dheevatsa Mudigere, Misha Smelyanskiy, and Kurt Keutzer. 2021. Differentiable nas framework and application to ads ctr prediction. arXiv preprint arXiv:2110.14812 (2021). [26] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems 33 (2020), 94599474. [27] Zelong Li, Jianchao Ji, Yingqiang Ge, and Yongfeng Zhang. 2022. Autolossgen: Automatic loss function generation for recommender systems. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. 13041315. [28] Bin Liu, Chenxu Zhu, Guilin Li, Weinan Zhang, Jincai Lai, Ruiming Tang, Xiuqiang He, Zhenguo Li, and Yong Yu. 2020. Autofis: Automatic feature interaction selection in factorization models for click-through rate prediction. In proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 26362645. [29] Fei Liu, Xinyu Lin, Hanchao Yu, Mingyuan Wu, Jianyu Wang, Qiang Zhang, Zhuokai Zhao, Yinglong Xia, Yao Zhang, Weiwei Li, et al. 2025. Recoworld: Building simulated environments for agentic recommender systems. arXiv preprint arXiv:2509.10397 (2025). [30] Gang Liu, Yihan Zhu, Jie Chen, and Meng Jiang. 2025. Scientific algorithm arXiv preprint discovery by augmenting alphaevolve with deep research. arXiv:2510.06056 (2025). [31] Chenglong Ma, Ziqi Xu, Yongli Ren, Danula Hettiachchi, and Jeffrey Chan. 2025. PUB: an LLM-enhanced personality-driven user behaviour simulator for recommender system evaluation. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval. 26902694. [32] Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023. Eureka: Human-level reward design via coding large language models. arXiv preprint arXiv:2310.12931 (2023). [33] Sean M. McNee, John Riedl, and Joseph A. Konstan. 2006. Being accurate is not enough: how accuracy metrics have hurt recommender systems. In CHI 06 Extended Abstracts on Human Factors in Computing Systems (Montr√©al, Qu√©bec, Canada) (CHI EA 06). Association for Computing Machinery, New York, NY, USA, 10971101. doi:10.1145/1125451.1125659 [34] Manel Mezghani, Corinne Amel Zayani, Ikram Amous, and Faiez Gargouri. 2012. user profile modelling using social annotations: survey (WWW 12 Companion). Association for Computing Machinery, New York, NY, USA. doi:10.1145/2187980.2188230 [35] Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, CaroleJean Wu, Alisson Azzolini, et al. 2019. Deep learning recommendation model for personalization and recommendation systems. arXiv preprint arXiv:1906.00091 (2019). [36] Alexander Novikov, Ng√¢n u, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehrabian, et al. 2025. AlphaEvolve: coding agent for scientific and algorithmic discovery. arXiv preprint arXiv:2506.13131 (2025). [37] Esteban Real, Chen Liang, David So, and Quoc Le. 2020. Automl-zero: Evolving machine learning algorithms from scratch. In International conference on machine learning. PMLR, 80078019. [38] Sonia Roccas, Lilach Sagiv, Shalom H. Schwartz, and Ariel Knafo. 2002. The Big Five Personality Factors and Personal Values. Personality and Social Psychology Bulletin 28 (2002), 789 801. https://api.semanticscholar.org/CorpusID:144611052 [39] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan Ellenberg, Pengming Wang, Omar Fawzi, et al. 2024. Mathematical discoveries from program search with large language models. Nature 625, 7995 (2024), 468475. [40] Ruslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic Matrix Factorization (NIPS07). Curran Associates Inc., Red Hook, NY, USA. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY [41] Asankhaya Sharma. 2025. OpenEvolve: an open-source evolutionary coding agent. https://github.com/algorithmicsuperintelligence/openevolve [42] Qingquan Song, Dehua Cheng, Hanning Zhou, Jiyan Yang, Yuandong Tian, and Xia Hu. 2020. Towards automated neural interaction discovery for click-through rate prediction. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 945955. [43] Harald Steck. 2018. Calibrated recommendations. In Proceedings of the 12th ACM Conference on Recommender Systems (Vancouver, British Columbia, Canada) (RecSys 18). Association for Computing Machinery, New York, NY, USA, 154162. doi:10.1145/3240323.3240372 [44] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 14411450. [45] Reiko Tanese, John H. Holland, and Quentin F. Stout. 1989. Distributed genetic algorithms for function optimization. Ph. D. Dissertation. USA. AAI9001722. [46] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the eleventh ACM international conference on web search and data mining. 565573. [47] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval. 165174. [48] Xuesi Wang, Guangda Huzhang, Qianying Lin, and Qing Da. 2022. Learning-toensemble by contextual rank aggregation in e-commerce. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining. 1036 1044. [49] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to Go Next for Recommender Systems? IDvs. Modality-based Recommender Models Revisited. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 26392649. [50] An Zhang, Yuxin Chen, Leheng Sheng, Xiang Wang, and Tat-Seng Chua. 2024. On generative agents in recommendation. In Proceedings of the 47th international ACM SIGIR conference on research and development in Information Retrieval. 1807 1817. [51] Tunhou Zhang, Dehua Cheng, Yuchen He, Zhengxing Chen, Xiaoliang Dai, Liang Xiong, Feng Yan, Hai Li, Yiran Chen, and Wei Wen. 2023. NASRec: weight sharing neural architecture search for recommender systems. In Proceedings of the ACM Web Conference 2023. 11991207. [52] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in neural information processing systems 36 (2023), 4659546623. [53] Ruiqi Zheng, Liang Qu, Bin Cui, Yuhui Shi, and Hongzhi Yin. 2023. Automl for deep recommender systems: survey. ACM Transactions on Information Systems 41, 4 (2023), 138. [54] Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. 2005. Improving recommendation lists through topic diversification. In Proceedings of the 14th International Conference on World Wide Web (Chiba, Japan) (WWW 05). Association for Computing Machinery, New York, NY, USA, 2232. doi:10.1145/ 1060745. [55] Barret Zoph and Quoc Le. 2017. Neural Architecture Search with Reinforcement Learning. In International Conference on Learning Representations. https: //openreview.net/forum?id=r1Ue8Hcxg [56] Kuan Zou and Aixin Sun. 2025. Survey of Real-World Recommender SysarXiv preprint tems: Challenges, Constraints, and Industrial Perspectives. arXiv:2509.06002 (2025). Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Ethics Statement To the best of our knowledge, this paper aligns with the KDD Code of Ethics without any ethical concerns. The datasets and codes employed in our research are publicly available. Traits Activity (Engagement Level). Activity quantifies the degree of users engagement with the recommender system. Since useritem interactions are typically sparse, we define activity as the cardinality of the users interaction history: ùëáact (ùë¢) = Hùë¢ . (7) Users with lower ùëáact (ùë¢) values correspond to passive users who interact infrequently with recommended items, whereas higher values indicate highly engaged users with rich interaction histories. Conformity (Mainstream Adherence). Conformity measures the extent to which users preferences align with global public consensus. This trait captures whether user follows mainstream tastes or exhibits individualized preferences. We define conformity as the mean squared deviation between the users rating ùëüùë¢,ùë£ and the global average rating ùëüùë£ of item ùë£: ùëáconf (ùë¢) = 1 Hùë¢ ùë£ Hùë¢ (ùëüùë¢,ùë£ ùëüùë£)2, (8) where ùëüùë£ denotes the average rating of item ùë£ across all users. lower conformity value implies that the users preferences closely align with popular sentiment, while higher value reflects more distinctive and personalized tastes. Diversity (Interest Breadth). Diversity characterizes the breadth of users interests across item categories. We define this trait as the number of unique categories associated with the items in the users interaction history: ùëádiv (ùë¢) = (cid:12) (cid:12){ùëêùë£ ùë£ Hùë¢ }(cid:12) (cid:12). (9) Users with lower ùëádiv (ùë¢) values tend to focus on narrow set of categories, whereas higher values indicate preference for exploring broader and more diverse range of categories. We categorized each user trait into three distinct levels, defined as follows: Activity: HIGH: Frequently interacts with the system and maintains high volume of engagement with recommendations. MID: Interacts moderately, primarily when items strictly align with personal preferences. LOW: Rarely interacts with the system and does not interact if recommendations are not relevant to their interests. Conformity: HIGH: Heavily influenced by popularity and public ratings; tends to follow mainstream trends. MID: Considers both popularity and personal taste, balancing trends with individual preferences. LOW: Ignores popularity and trends, evaluating items purely based on intrinsic personal preference. Diversity: HIGH: Seeks high variety and novelty, enjoying the exploration of diverse categories and new styles. Figure 6: Recommendation performance over number of sampled user Usample on CDs dataset (Seed Recommender: SASRec). Table 7: Statistics of datasets after preprocessing."
        },
        {
            "title": "Dataset",
            "content": "# Users # Items"
        },
        {
            "title": "Office MovieLens",
            "content": "14,335 11,436 32,232 17,695 20,147 10, 6,040 3,952 # Interactions 126,225 257,850 145, 1,000,209 MID: Mostly consumes preferred categories but occasionally explores similar alternatives. LOW: Sticks strictly to narrow set of familiar categories and avoids exploration. Implementation Details Regarding the baseline implementation of AlphaEvolve, due to the unavailability of the official code, we utilized OpenEvolve [41], an open-source implementation, following prior work [30]. In our evolutionary framework, we set the maximum evolution steps to 21 across all LLM-driven evolutionary frameworks. For all LLM-driven evolutionary frameworks, we set the maximum evolution iterations to 21. For NAS baselines, we configured the search epochs to 5 for AutoFIS and 1 for NASRec, following the hyper-parameter setting in NASRec [51]. We employ GPT-5-mini for the User Simulator (SIM) and set the number of sampled users to Usample = 20 (refer to App. F.1.1 for an analysis of the number of sampled users). To ensure fair comparison, we uniformly configured all recommender modelsincluding the retraining phase of NAS modelswith user/item embedding dimension of 50, batch size of 128, and learning rate of 0.001. The maximum number of epochs was set to 300 for both standard training and the NAS retraining stage. All experiments were conducted on single NVIDIA GeForce A6000 (48GB) GPU. Datasets Table 7 shows the statistics of the dataset after preprocessing. Baselines and Seed Recommender E.1 Baselines (1) Neural Architecture Search Baselines Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Table 8: Comparison of average execution time per iteration on CDs dataset (Seed Recommender: SASRec). Table 9: Big Five Personality"
        },
        {
            "title": "Method",
            "content": "RAG Coding Co-Evolve"
        },
        {
            "title": "DIAG Total Time",
            "content": "6m 23s 7m 43s 7m 15s - 6m 16s 6m 24s"
        },
        {
            "title": "AlphaEvolve\nDeepEvolve\nOurs",
            "content": "- - 7m 06s The User Simulation time is measured with 20 sampled users, processed in parallel batches of 4 (5 batches 54.24s 4m 31s). Diagnosis Co-Evolve includes both research (3m 54s) and coding (3m 12s). 6m 23s 13m 59s 25m 28s - - 4m 31s - - 12s AutoFIS [28] automatically identifies essential feature interactions by employing learnable gates to prune redundant feature combinations. NASRec [51] leverages weight-sharing supernet to efficiently search for optimal full architectures. (2) LLM-driven Code Evolution Baselines AlphaEvolve [36] orchestrates an autonomous LLM-driven evolutionary pipeline to iteratively evolve and optimize algorithmic codebases. DeepEvolve [30] integrates retrieval-augmented generation (RAG) into the evolutionary loop to guide code optimization with external scientific knowledge. E.2 Seed Recommender NCF [14] is pioneering neural collaborative filtering framework which combines multi-layer perceptron (MLP) to learn user-item interactions. NGCF [47] is graph-based model that explicitly encodes collaborative signals in the embedding space by propagating embeddings on the user-item bipartite graph SASRec [17] is sequential recommendation model leveraging self-attention mechanisms to dynamically capture user interests from interaction sequences. MoRec [49] is multi-modal framework that utilizes pre-trained encoders (e.g., SBERT) to initialize item embeddings with textual features. Following prior work [21], we employ SASRec as the backbone architecture for MoRec. Additional Experiments F.1 Efficiency Analysis Impact of user sampling size. To investigate the efficiency F.1.1 and robustness of Self-EvolveRec on Usample, we conducted experiments by varying the user sample size of the User Simulator. As shown in Figure 6, we observe that Self-EvolveRec achieves robust performance even with small number of sampled users. Notably, performance improves significantly as the sample size increases from 1 to 3, eventually stabilizing around sample size of 5. This robustness stems from the Diagnosis Tool - Model Co-Evolution mechanism (Sec. 4.3). Although the SIM operates on small subset of users to generate qualitative feedback (e.g., \"lack of diversity\"), the DIAG translates these critiques into deterministic numerical metrics (e.g., measuring category entropy). Consequently, even with limited user samples, the evolved DIAG effectively verifies"
        },
        {
            "title": "Electronics",
            "content": "NDCG@5 HR@5 NDCG@5 HR@5 Self-EvolveRec 0.3865 0.5274 0.2600 0. Big 5 Personality 0.3915 0.5244 0.2551 0.3561 and quantifies structural deficiencies across the global data distribution, ensuring reliable evolutionary guidance without the need for extensive user sampling. F.1.2 Time Efficiency Analysis. We compare the execution time per iteration of evolution in Table 8. The reported times are averaged over the evolution of SASRec on the CDs dataset. We have the following observations: 1) Although Self-EvolveRec requires approximately 25 minutes per iterationhigher than AlphaEvolve (6m) and DeepEvolve (14m)it significantly reduces the total number of iterations required to reach peak performance. As illustrated in Table 4, Self-EvolveRec reaches its peak in just around 8 to 11 iterations, whereas baselines relying on aimless trial-and-error require 13 to 19 iterations or fail to outperform the initial model. 2) While integrating RAG processes in DeepEvolve and Self-EvolveRec increases the runtime per iteration compared to AlphaEvolve, it is critical for ensuring the quality of the evolved logic. As discussed in Sec. 5.1.3, the absence of external knowledge limits AlphaEvolves ability to discover novel mechanisms, resulting in lower Creativity and Insight. Conversely, Self-EvolveRec leverages this RAG latency to incorporate external algorithmic knowledge and diagnostic signals, enabling the discovery of novel mechanisms that scalar-driven baselines fail to achieve. 3) The User Simulator introduces an additional time cost (4m 31s), yet it is crucial for sustaining high performance. Furthermore, as detailed in App. F.1.1, the simulator remains stable and effective even with small number of sampled users, ensuring efficiency without compromising robustness. F.2 Other User Simulator To demonstrate the simulator agnostic toward specific user traits, we replaced the traits with the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreebleness, and Neuroticism), following prior works [31]. As shown in Table 9, Self-EvolveRec achieves comparable recommendation performance regardless of the trait definition. This results aligns with our observations in Sec. 5.3.3, indicating that the SIM is already effective at modeling complex user preferences and generating informative feedback irrespective of the specific traits schema. Consequently, this results shows that the key factor in evolution is the precise and qualitative nature of RSIM itself, which effectively identifies recommendation failures and provides valid guidance for codebase improvements, proving that Self-EvolveRec is robust to variations in user characterization. F.3 Additional Case Studies F.3.1 Addtional Case Study: Reliability of Co-evolved Diagnostic Tool via Deficiencies Injection. In case Figure 7, we injected deficiencies into an evolved MoRec pipeline by: (i) inverting content signals, and (ii) inflating popularity scores. The co-evolved DIAG effectively Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. between these detected deficiencies and the performance drop confirms that the co-evolved metrics can effectively bridge the gap between internal behavioral shifts and external recommendation accuracy. F.3.2 Additional Case Study: Evolutionary Trajectory. In an additional case study analyzing evolutionary, to investigate the SelfEvolveRecs behavior on extreme initial recommender setting, we examined Self-EvolveRecs behavior starting from Random Recommender (Sec. 5.3.1). Figure 8(a) illustrates the step-by-step code evolution, while Figure 8(b) tracks the performance progress. We have the following observations: 1) Self-EvolveRec demonstrates structured evolutionary path where algorithmic improvements are causally linked to identified failures. For instance, in the transition from Iteration 0 1, RDIAG explicitly flagged the \"Random Ranking\" behavior, while RSIM highlighted the neglect of item categories (\"Ignores genre\"). Guided by this directional feedback, SelfEvolveRec introduced an \"LM-Augmented Bi-Encoder\" to embed \"Genre Tags\" and utilized the InfoNCE loss with an MF module. This effectively resolved the random recommendation issue, yielding significant performance leap (HR: 0.0525 0.3737). Similarly, at Iteration 5, Self-EvolveRec detected \"Recency Insensitivity\" and addressed it by integrating \"Time-RoPE Sequence Encoding,\" further boosting performance to HR: 0.5070. 2) Consistent with the findings in Sec. 5.3.5, baselines exhibit unstable or delayed progress due to their reliance on scalar metrics without diagnostic guidance. At Iteration 4, AlphaEvolve attempted to add \"Popularity Bias and Global Bias\" to the model, but this update degraded performance (HR:2405 0.1969), as depicted in Figure 8 (b). Consequently, AlphaEvolve removes these changes and add \"User Bias\" at iteration 8, illustraing the inefficient tiral-and-error process. DeepEvolve shows successful evolution with \"Two-Stage Pipeline\" at iteration 6, but failed to improve at iteration 9 due to an incompatible curriculum learning strategy for LM negatives. Also in Figure 8 (b) confirms that while baselines suffer from performance fluctuations, Self-EvolveRec maintains robust evolutionary trajectory enabled by directional feedback. Prompts G.1 Task-specific Instruction Prompts The instruction prompts for the code evolution process were formulated by drawing upon existing methodologies [30, 36], ensuring consistency with established benchmarks. G.2 LLM-as-a-Judge Figure 20 illustrates the LLM-as-a-Judge prompt utilized in Sec. 5.1.3 to evaluate the quality of the generated code. Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009 Figure 7: Case study on Diagnosis Tool - Model Co-Evolution on CDs dataset (Seed Recommender: MoRec). Figure 8: Case study on evolutionary trajectory on CDs dataset (Seed Recommender: Random). (a) is comparison of evolutionary paths. Color-coded markers (e.g., Red) illustrate causal alignment between directional feedback and evolved codebase. (b) is performance comparison across iterations. detects these deficiencies through newly formulated metrics such as the Off-Category Rate (Mismatch rate between the categories of the Top-K recommended items and the categories present in users recent interaction history) and Popularity correlation (Correlation between the models predicted recommendation logits and the item popularity distribution). The Rùê∑ùêºùê¥ùê∫ accurately reports that the system has begun to \"surface off-category or popular items rather than reliably relevant ones\" providing clear directional feedback for subsequent correction. Notably, the strong association Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 9: Example prompt of ISIM. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 10: Example prompt of ISUMMARIZE. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 11: Example prompt of IDIAG. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 12: Example prompt of IPLAN. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 13: Example prompt of IREPORT. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 14: Example prompt of ICODE. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 15: Example prompt of IAnalyze. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 16: Example prompt of IPLAN-DIAG. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 17: Example prompt of IREPORT-DIAG. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 18: Example prompt of ICODE-DIAG. Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 19: Example prompt of ICODE-SIM. Conference acronym XX, June 0305, 2018, Woodstock, NY Kim et al. Figure 20: Example prompt of LLM-as-a-Judge for evolved models evaluation."
        }
    ],
    "affiliations": [
        "KAIST"
    ]
}