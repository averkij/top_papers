{
    "paper_title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
    "authors": [
        "Zhongxiang Sun",
        "Qipeng Wang",
        "Weijie Yu",
        "Jingxuan Yang",
        "Haolang Lu",
        "Jun Xu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By embedding monitoring directly into the reasoning-retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness."
        },
        {
            "title": "Start",
            "content": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Weijie Yu School of Information Technology and Management University of International Business and Economics Beijing, China yu@uibe.edu.cn Zhongxiang Sun Qipeng Wang Gaoling School of Artificial Intelligence Renmin University of China Beijing, China {sunzhongxiang,wqp}@ruc.edu.cn Jingxuan Yang Search Applications Department, Tencent Beijing, China emmajxyang@tencent.com 6 2 0 2 0 ] . [ 1 8 8 1 3 2 . 1 0 6 2 : r Haolang Lu Beijing University of Posts and Telecommunications Beijing, China lhl_bupt@bupt.edu.cn Jun Xu Gaoling School of Artificial Intelligence Renmin University of China Beijing, China junxu@ruc.edu.cn Abstract Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By embedding monitoring directly into the reasoningretrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness. Keywords Deep Search Agent, Meta-cognition Monitor, Critical Model ACM Reference Format: Zhongxiang Sun, Qipeng Wang, Weijie Yu, Jingxuan Yang, Haolang Lu, and Jun Xu. 2026. Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience. In . ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn This work is licensed under Creative Commons Attribution 4.0 International License. Conference17, Washington, DC, USA 2026 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/10.1145/nnnnnnn.nnnnnnn Figure 1: Cognitive neuroscience-inspired hierarchical metacognitive monitoring for deep search agents. Top: Humans rely on fast, implicit monitor to detect anomalies during execution, which selectively triggers slow, experiencedriven monitor for reflective correction. Middle: Standard deep search agents lack such monitoring, allowing early cognitive errors to propagate across reasoning steps. Bottom: Our DS-MCM integrates the fast consistency monitor and slow experience-driven monitor into the deep search loop, enabling timely detection and correction of unreliable execution (Illustrative examples sampled from BrowseCompPlus [4])."
        },
        {
            "title": "1 Introduction\nHuman problem solving relies not only on strong reasoning ability,\nbut also on the capacity to monitor and regulate oneâ€™s own rea-\nsoning process [20]. Through evolution, humans have developed\ncognitive systems that can continuously detect when reasoning\nbecomes unreliable, adjust confidence in response to ambiguous\nevidence, and correct errors before they propagate [9, 17]. This",
            "content": "Conference17, July 2017, Washington, DC, USA Zhongxiang Sun et al. metacognitive capability enables robust decision making in complex and uncertain environments [11]. In contrast, modern deep search agents powered by large language models have achieved remarkable progress in retrieval, reasoning, and long-horizon planning [30, 36]. By iteratively interacting with external tools and synthesizing information across multiple steps, deep search agents can solve increasingly complex, open-ended tasks. However, despite their strong cognitive capacity, these agents still exhibit systematic failures in practice. These failures tend to arise not at the level of isolated reasoning steps, but as tasks evolve with intermediate feedback and partial or conflicting evidence [39]. In practice, agents are often seen to follow rigid reasoning trajectories with limited adjustment to newly acquired information, while retrieval behaviors may treat information acquisition, integration, and verification as loosely connected stages [26, 39]. Such patterns suggest broader phenomenon in which agents struggle to maintain and regulate their reasoning and retrieval states over time, especially under uncertainty, rather than simple lack of reasoning or retrieval capacity. Insights from cognitive neuroscience suggest that human metacognition is organized hierarchically [17]. As shown in the top of Figure 1, rather than relying on single reflective process, humans employ fast monitoring mechanism that rapidly detects anomalies such as conflict or prediction error [1, 11], and slow monitoring mechanism that performs deliberate reflection and corrective control when needed [24]. Crucially, the slow mechanism is not invoked continuously; it is selectively triggered by signals from the fast monitor and is shaped by accumulated experience, rather than operating as generic, context-free evaluator [8, 25]. Existing approaches to agent monitoring provide partial signals for detecting abnormal behavior, but remain insufficient for the demands of deep search agents, where reasoning and retrieval are tightly interleaved over multiple steps. Fast monitoring is commonly approximated using token-level uncertainty measures [16, 23], which can be unreliable in deep search settings where multiple reasoning paths from diverse retrieval results may be simultaneously plausible, such that high entropy does not necessarily correspond to erroneous behavior [5]. Conversely, low entropy may instead signal overconfident reasoning that fails to consider alternative retrieved evidence. Slow monitoring is typically implemented through standalone critical model that evaluates reasoning in isolation, without access to historical experience or accumulated knowledge about recurring failure and successful patterns [13, 15], in contrast to human reflective processes that are shaped by experience [17, 20]. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. As shown in Figure 1, our approach decomposes metacognitive monitoring into Fast Consistency Monitor and Slow ExperienceDriven Monitor, tightly integrated into the agents reasoning retrieval loop. (1) The fast monitor tracks the alignment between external Searching Entropy (SE) and internal Reasoning Entropy (RE), enabling the detection of abnormal execution states where confidence and evidence diverge. (2) The slow monitor draws on metacognitive patterns distilled from historical agent trajectories to supervise and regulate deepsearch execution at test time. Together, this design allows monitoring signals to go beyond raw uncertainty estimates and context-agnostic critique, providing principled guidance on when intervention is warranted and how corrective actions should be informed by past experience. Experiments across multiple deep-search benchmarks and agent architectures demonstrate consistent performance improvements. The contributions of this paper are summarized as follows: (1) We introduce neuroscience-inspired perspective on monitoring deep search agents, highlighting that existing systems lack explicit metacognitive mechanisms to maintain and regulate their reasoning and retrieval states. This perspective motivates the need for structured monitoring beyond task-level reasoning and retrieval. (2) We propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), hierarchical framework for deep-search agents that separates task-level reasoning from metacognitive control by combining fast, evidence-aware consistency monitoring with slow, experience-driven reflective regulation for deep-search agent. (3) We empirically demonstrate the effectiveness of metacognitive monitoring in deep search, showing consistent improvements in robustness and reasoning resilience across multiple benchmarks and backbone models, and enabling open-source systems to match or surpass strong proprietary deep-search systems."
        },
        {
            "title": "2.2 Critical Models\nRecent work has explored process-level supervision and critique\nmechanisms for large language models to detect and correct reason-\ning errors during execution. A representative direction is Process",
            "content": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Conference17, July 2017, Washington, DC, USA Reward Models (PRMs), which provide step-wise supervision signals for intermediate reasoning states, but suffer from limitations such as annotation noise, reward bias, and weak cross-task generalization [42]. Benchmarks such as ProcessBench further formalize step-level error localization [43], while PRM-style supervision has been extended to retrieval-augmented and multi-step reasoning settings [28]. In parallel, LLM-as-critic approaches generate structured critique via separate critic models or self-critique mechanisms, improving robustness without dense human supervision [34, 37]. Orthogonal to explicit critics, uncertaintyand entropy-based detection methods provide lightweight signals for identifying unreliable reasoning or hallucinations. These approaches leverage measures such as semantic entropy or representation-level uncertainty probes to flag potentially incorrect generations without requiring step-level supervision [7, 16]. Recent studies further extend critical and uncertainty-aware mechanisms to long-horizon and agentic reasoning, showing that such signals can be incorporated into extended reasoning trajectories, though they are often reactive and local in scope [27]. Despite their effectiveness at step-level oversight, these methods are largely designed for standalone reasoning traces or generic correction loops. They lack explicit metacognitive monitoring mechanisms for deep search agents operating under evolving, incomplete, and potentially inconsistent external evidence. In particular, prior work does not model the calibration between internal reasoning confidence and external evidence uncertainty, nor does it leverage historical execution experience to guide monitoring and regulation. This limitation prevents agents from dynamically identifying abnormal search states and adjusting their behavior in human-like manner during long-horizon execution. In contrast, our work introduces hierarchical metacognitive monitoring framework tailored to deep search agents, combining fast uncertainty-consistency checks with slow, experience-driven reflection. This design enables lightweight online detection of abnormal reasoning states and sustained, agent-level regulation over long-horizon deep search processes."
        },
        {
            "title": "3 Methods\n3.1 Overview\nWe consider a deep search agent ğœ‹ğœƒ following the ReAct para-\ndigm [36], where reasoning and information acquisition are inter-\nleaved through iterative interactions with external tools. Given a\nuser query ğ‘, the agent executes a sequence of steps",
            "content": "H ğ‘ ğ‘‡ = {ğ‘ 1, ğ‘ 2, . . . , ğ‘ ğ‘‡ }, (1) where each step ğ‘ ğ‘¡ consists of (i) internal reasoning generated by the base language model, and (ii) an action such as tool call or termination decision. Tool outputs are incorporated into the context and inform subsequent reasoning steps. Despite strong reasoning and retrieval capabilities, standard deep search agents lack an explicit mechanism to monitor and regulate their own execution state as the search process unfolds. To address this limitation, we propose Deep Search with Meta-Cognitive Monitoring (DSMCM), which augments the standard deep search loop with an explicit monitoring layer. As illustrated in Figure 2, the key design principle of DS-MCM is to separate task-level cognition (reasoning and retrieval) from metacognitive control, while tightly integrating the latter into the execution process. DS-MCM introduces two complementary monitoring components. Fast Consistency Monitor operates at every step with low overhead, providing rapid signals about potential inconsistencies between internal reasoning uncertainty and external evidence uncertainty. When such signals indicate abnormal execution states, Slow Experience-Driven Monitor is selectively triggered to perform reflective analysis and generate corrective guidance based on accumulated metacognitive experience. At each step, monitoring is applied after internal reasoning and before the next action decision, allowing the agent to either proceed normally or adjust its behavior when necessary. This hierarchical design enables continuous yet non-intrusive regulation of deep search execution, ensuring that reflective intervention is invoked only when warranted."
        },
        {
            "title": "3.2 Fast Consistency Monitor\nUnlike single-shot generation, deep search agents iteratively in-\nterleave reasoning with evidence acquisition, causing the agentâ€™s\ninternal reasoning state to be continuously shaped by retrieved\ninformation. As a result, uncertainty observed during reasoning\nis not inherently pathological. When external evidence is ambigu-\nous, incomplete, or mutually inconsistent, it is natural and often\ndesirable for the agent to maintain multiple competing hypotheses.\nIn such cases, elevated reasoning uncertainty reflects legitimate\nmulti-path exploration rather than failure [5].",
            "content": "This observation implies that reasoning uncertainty should not be evaluated in isolation. Instead, it must be interpreted relative to the uncertainty of the retrieved evidence. An agent may reasonably exhibit high uncertainty when the evidence itself is unclear, while persistent uncertainty under clear and consistent evidence often signals abnormal execution states, such as information misuse, tool misalignment, or unstable reasoning dynamics. Conversely, overly confident reasoning in the presence of ambiguous evidence may indicate premature commitment and ignored counter-evidence. These considerations motivate consistency-based monitoring principle: deep search agent operates normally when its internal reasoning uncertainty is calibrated to the uncertainty of external evidence, and becomes suspicious when the two diverge. This perspective departs from conventional fast monitoring approaches that treat token-level entropy as direct proxy for correctness. In deep search settings, high token entropy may simply reflect evidence-induced ambiguity, while low entropy may still correspond to confident but incorrect conclusions. The Fast Consistency Monitor is therefore explicitly designed for deep search execution, modeling the expected relationship between retrieval uncertainty and reasoning uncertainty rather than relying on raw token statistics alone. Searching Entropy (SE). Formally, let ğ‘ denote the user query 3.2.1 and let ğ‘¡ index ReAct step ğ‘ ğ‘¡ . After executing retrieval action at step ğ‘¡, the agent obtains set of retrieved documents Dğ‘¡ = {ğ‘‘1, . . . , ğ‘‘ğ¾ }. (2) Conference17, July 2017, Washington, DC, USA Zhongxiang Sun et al. Figure 2: Overview of Deep Search with Meta-Cognitive Monitoring (DS-MCM). DS-MCM augments standard ReAct-based deep search agent with an explicit metacognitive monitoring module. At each step, Fast Consistency Monitor (3.2) checks whether reasoning uncertainty is calibrated with the uncertainty of retrieved evidence. When abnormal mismatches are detected, Slow Experience-Driven Monitor (3.3) is triggered to perform reflective diagnosis using success and failure experiences stored in metacognitive memory, and to issue corrective guidance for subsequent steps. The memory is continuously updated and consolidated online, enabling efficient and experience-driven regulation of deep search execution. Rather than treating individual documents as independent evidence, we characterize the semantic diversity of the retrieved results by operating in an embedding space. Specifically, each document ğ‘‘ğ‘˜ is mapped to dense semantic representation eğ‘˜ using pretrained embedding model [41]. Documents that convey similar semantic content are expected to form coherent neighborhoods in this space. To approximate the distribution of semantic interpretations implied by the retrieved evidence, we induce embedding based clustering over the documents based on their embedding similarity [2]. This yields set of latent semantic clusters Cğ‘¡ = {ğ‘1, . . . , ğ‘ğ‘€ }, (3) where each cluster ğ‘ğ‘– represents distinct semantic theme or evidence pattern present in the retrieved results. We define probability distribution over these semantic clusters by aggregating the normalized contribution of documents assigned to each cluster, ğ‘ğ‘  (ğ‘ğ‘– ğ‘, Dğ‘¡ ), ğ‘€ ğ‘–=1 ğ‘ğ‘  (ğ‘ğ‘– ğ‘, Dğ‘¡ ) = 1, (4) where ğ‘ğ‘  (ğ‘ğ‘– ğ‘, Dğ‘¡ ) reflects the relative semantic mass of cluster ğ‘ğ‘– in the retrieved evidence. We then define the Searching Entropy (SE) at step ğ‘¡ as the Shannon entropy of this semantic distribution: SEğ‘¡ = ğ‘€ ğ‘–=1 ğ‘ğ‘  (ğ‘ğ‘– ğ‘, Dğ‘¡ ) log ğ‘ğ‘  (ğ‘ğ‘– ğ‘, Dğ‘¡ ). (5) Intuitively, low value of SEğ‘¡ indicates that the retrieved documents are semantically coherent and concentrate around small number of consistent evidence patterns, whereas high value reflects semantic fragmentation, where the retrieval results support multiple competing or incompatible interpretations. 3.2.2 Reasoning Entropy (RE). To capture the agents internal uncertainty during reasoning, we define Reasoning Entropy (RE) based on the base language models token prediction distributions within the reasoning segment. Let the reasoning trace at step ğ‘¡ consist of ğ‘‡ generation positions. At each position ğ‘—, we consider the normalized next-token distribution restricted to the top-ğ¾ tokens, denoted by ğ‘ğ‘Ÿ (). The Reasoning Entropy is computed as REğ‘¡ = 1 ğ‘‡ (cid:32) ğ‘‡ ğ‘—=1 ğ¾ ğ‘˜=1 ğ‘ğ‘Ÿ (cid:16) ğ‘¦ (ğ‘˜ ) ğ‘¡,ğ‘— ğ‘¦< ğ‘—, ğ‘, Dğ‘¡ (cid:17) log ğ‘ğ‘Ÿ (cid:16) ğ‘¦ (ğ‘˜ ) ğ‘¡,ğ‘— ğ‘¦< ğ‘—, ğ‘, Dğ‘¡ (cid:33) (cid:17) . Low values of REğ‘¡ indicate stable and confident reasoning trajectories, whereas high values suggest uncertainty among multiple plausible reasoning continuations. Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Conference17, July 2017, Washington, DC, USA Fast Consistency Monitor. The Fast Consistency Monitor de3.2.3 tects abnormal execution states by assessing whether the observed reasoning uncertainty REğ‘¡ is consistent with the uncertainty of the retrieved evidence SEğ‘¡ . Using set of historically successful steps from the same memory set of the Slow Experience-Driven Monitor (Section 3.3), we fit simple calibration function that captures the typical relationship between evidence uncertainty and reasoning uncertainty, (6) (cid:99)REğ‘¡ = ğ‘ SEğ‘¡ + ğ‘, where ğ‘ 0 and ğ‘ are learnable parameters. We then define the residual: (7) ğœ–ğ‘¡ = REğ‘¡ (cid:99)REğ‘¡ , where the residual ğœ–ğ‘¡ quantifies the degree of mismatch between internal and external uncertainty. Small residuals indicate wellcalibrated reasoning behavior, whereas large positive residuals correspond to unusually high reasoning uncertainty given clear evidence, and large negative residuals reflect unusually confident reasoning despite ambiguous evidence. In practice, we estimate the standard deviation ğœ of residuals from successful trajectories and define an anomaly threshold ğœ = ğ‘˜ğœ. step is flagged as anomalous when (8) ğœ–ğ‘¡ > ğœ . When such an anomaly is detected, the Fast Consistency Monitor triggers the Slow Experience-Driven Monitor, which performs reflective diagnosis and issues corrective control signals (Section 3.3). Overall, the Fast Consistency Monitor provides lightweight, step-level mechanism that grounds internal reasoning uncertainty in the uncertainty of retrieved evidence, making it particularly well suited to the iterative retrievalreasoning dynamics of deep search agents."
        },
        {
            "title": "3.3 Slow Experience-Driven Monitor\nThe Fast Consistency Monitor provides a lightweight mechanism\nfor detecting when a deep search step deviates from normal uncer-\ntainty calibration. However, identifying why such deviations arise\nand how the agent should adapt its behavior requires reflective\nreasoning grounded in prior experience. To address this need, we\nintroduce a Slow Experience-Driven Monitor, which supervises\ndeep search execution using a persistent metacognitive memory\ndistilled from historical agent trajectories.",
            "content": "Formally, the Slow Monitor operates over memory set constructed from past executions and interacts with the current trajectory Hğ‘¡ = {ğ‘ 1, . . . , ğ‘ ğ‘¡ } in selective, memory-conditioned manner. Unlike the Fast Monitor, which relies solely on local uncertainty signals, the Slow Monitor performs experience-informed diagnosis and generates corrective guidance by comparing the current execution state against previously observed cognitive patterns. 3.3.1 Metacognitive Experience Memory Construction. The Slow Experience-Driven Monitor is supported by compact metacognitive memory that encodes reusable cognitive experience extracted from historical deep search executions. Rather than storing raw trajectories or long-horizon interaction histories, we distill past executions into lightweight, session-level memory entries that emphasize how the agent reasoned and interacted with tools at each step. We construct this memory offline from historical trajectories. Given deep search execution ğœğ‘˜ = {ğ‘ 1, ğ‘ 2, . . . , ğ‘ ğ‘‡ }, (9) each step ğ‘ ğ‘¡ corresponds to one ReAct iteration and is treated as session-level cognitive unit. session preserves only local information relevant for metacognitive analysis, including the user query, the agents internal reasoning trace, executed action, and tool feedback. This representation deliberately abstracts away taskspecific surface details while retaining the agents cognitive behavior at that step. Supervision for historical executions is typically available only at the trajectory level. To enable scalable memory construction, we propagate trajectory-level outcomes to all constituent sessions: ğ‘¦(ğ‘ ğ‘¡ ) = (cid:40)1, 0, if the trajectory is successful, if the trajectory is unsuccessful. (10) This coarse-grained labeling reflects our focus on global cognitive behavior patterns. In successful trajectories, intermediate steps usually exhibit coherent reasoning and tool usage that collectively support task completion. In unsuccessful trajectories, cognitive deficiencies tend to recur across steps, even when isolated actions appear locally reasonable. Each session is then converted into metacognitive memory entry through label-conditioned abstraction process. For session ğ‘ ğ‘¡ , we generate ğ‘šğ‘¡ = (cid:0)ğ‘ ğ‘¡ , â„ğ‘¡, ğ‘§ğ‘¡, ğ‘¦ (ğ‘ ğ‘¡ )(cid:1), (11) where ğ‘ ğ‘¡ denotes the structured representation of the current session, â„ğ‘¡ is concise summary of historically relevant sessions leading up to ğ‘ ğ‘¡ , and ğ‘§ğ‘¡ is natural-language abstraction extracted by LLMs capturing the cognitive behavior expressed at step ğ‘¡. The abstraction of ğ‘§ğ‘¡ is explicitly label-dependent. For sessions labeled as successful (ğ‘¦(ğ‘ ğ‘¡ ) = 1), the abstraction prompt emphasizes the extraction of positive cognitive behaviors, guiding the model to identify effective reasoning strategies, appropriate tool usage, and sound evidence integration patterns. For sessions labeled as unsuccessful (ğ‘¦ (ğ‘ ğ‘¡ ) = 0), the abstraction focuses on failure diagnosis, encouraging the model to surface recurring cognitive deficiencies, such as insufficient external information acquisition, premature closure, or verification mechanism failure, and to articulate high-level improvement insights [39]. Although the two abstraction prompts share an identical output structure, their semantic emphasis induces systematically different representations. As result, all memory entries are organized into two complementary repositories: = M+ , where M+ stores success experiences that exemplify effective cognitive behaviors, and stores failure experiences that capture typical error patterns together with their corrective insights. These two memory spaces provide the experiential foundation upon which the Slow Experience-Driven Monitor performs memoryconditioned diagnosis and intervention. (12) 3.3.2 Memory-Conditioned Monitoring and Intervention. When the Fast Consistency Monitor flags session ğ‘ ğ‘¡ as potentially abnormal, the Slow Experience-Driven Monitor is selectively activated to Conference17, July 2017, Washington, DC, USA Zhongxiang Sun et al. interpret the anomaly through prior experience. At this stage, the current session is used as query to retrieve relevant experiences from both success and failure memory spaces. We encode the current session representation into dense semantic embedding (13) eğ‘¡ = ğ‘“enc (ğ‘ ğ‘¡ ), where ğ‘“enc () denotes fixed embedding model [41]. For each memory entry ğ‘šğ‘– M, we precompute an embedding eğ‘– (ğ‘šğ‘– ) = ğ‘“enc (ğ‘ ğ‘– ) + ğ‘“enc (â„ğ‘– ), where â„ğ‘– is the stored historical-session summary associated with that memory entry. (14) Retrieval is performed independently over the success and failure memory pools by computing cosine similarity: sim(ğ‘ ğ‘¡, ğ‘šğ‘– ) = cos(eğ‘¡, eğ‘– ) , ğ‘šğ‘– M+ or . (15) For each memory pool, we select the top-ğ¾ most similar entries: R+ ğ‘¡ = TopK ğ‘šğ‘– M+ sim(ğ‘ ğ‘¡, ğ‘šğ‘– ), ğ‘¡ = TopK ğ‘šğ‘– sim(ğ‘ ğ‘¡, ğ‘šğ‘– ). (16) Conditioned on the current session and the retrieved success and failure experiences, the Critical Model performs reflective evaluation. Formally, it defines mapping (errğ‘¡ , ğ›¿ğ‘¡ ) = (cid:0)ğ‘ ğ‘¡ , R+ ğ‘¡ , ğ‘¡ (cid:1) , (17) where errğ‘¡ {0, 1} indicates whether cognitive error is identified at step ğ‘¡, and ğ›¿ğ‘¡ denotes corresponding corrective suggestion. When errğ‘¡ = 0, we set ğ›¿ğ‘¡ = . The corrective suggestion ğ›¿ğ‘¡ modulates subsequent deep search execution by conditioning the base agents policy: ğ‘ ğ‘¡ +1 ğœ‹ğœƒ ( Hğ‘¡ , ğ›¿ğ‘¡ ) , where Hğ‘¡ = {ğ‘ 1, . . . , ğ‘ ğ‘¡ } denotes the updated execution context. When no cognitive error is detected, policy execution reduces to standard deep search behavior without intervention. (18) 3.3.3 Online Memory Update and Consolidation (optional). During online execution, ground-truth trajectory-level correctness labels are unavailable. Instead, metacognitive memory is updated incrementally based on signals provided by the Fast Consistency Monitor and the Slow Experience-Driven Monitor. After completing session ğ‘ ğ‘¡ , the resulting online supervision signal is denoted as ğ‘¦online ğ‘¡ {success, failure}. (19) For each online-labeled session, we construct metacognitive memory entry ğ‘šğ‘¡ = (cid:0)ğ‘ ğ‘¡ , â„ğ‘¡, ğ‘§ğ‘¡ (cid:1), (20) which is assigned to either the success memory M+ or the failure memory . To prevent uncontrolled memory growth, we perform online deduplication by computing embedding similarity: sim(ğ‘šğ‘¡, ğ‘šğ‘– ) = cos(cid:0)e(ğ‘šğ‘¡ ), e(ğ‘šğ‘– )(cid:1). If max ğ‘šğ‘– sim(ğ‘šğ‘¡, ğ‘šğ‘– ) ğœdup, (21) (22) the candidate is discarded; otherwise, it is inserted into the corresponding memory pool."
        },
        {
            "title": "4.1 Experimental Settings\n4.1.1 Datasets and Evaluation Metrics. We evaluate DS-MCM on\nfour deep-search benchmarks: BrowseComp-Plus [4], BrowseComp-\nZH [45], xbench-DeepSearch [3], and GAIA [18], covering con-\ntrolled English search, high-difficulty Chinese web search, tool-\ncentric deep search, and general-purpose assistant evaluation.",
            "content": "BrowseComp-Plus [4] replaces live web search with fixed curated corpus, enabling fair and reproducible assessment of retrieval reasoning behaviors, while BrowseComp-ZH [45] extends this setting to the Chinese web with high-difficulty multi-hop questions. xbench-DeepSearch [3] focuses on tool use and information seeking in complex retrieval-centric scenarios, and GAIA [18] evaluates general AI assistants on real-world tasks requiring web browsing, reasoning, and tool use. Since BrowseComp-Plus and BrowseCompZH contain thousands of questions, we follow prior work [38] and randomly sample 100 queries from each benchmark for evaluation, providing cost-efficient yet representative estimate of overall performance. For the slow monitor (Section 3.3), the metacognitive memory set is constructed by sampling 500 trajectories from the BrowseComp [31] training split, ensuring no overlap with any evaluation questions. We adopt Accuracy as the primary evaluation metric following the standard evaluation protocol of each benchmark [30]. 4.1.2 Backbone and Baseline Models. We evaluate DS-MCM on three representative open-source deep-search backbones: TongyiDeepResearch-A30B-A3B (Tongyi-DeepResearch) [30], MiroThinker-v1.0-8B (MiroThinker-DeepResearch) [29], and Qwen3A30B-A3B-Instruct-2507 (Qwen3-30B-MoE) [35]. These models cover both full-fledged deep-research agent systems and modern instruction-tuned MoE reasoning backbones, providing diverse and strong foundation for assessing the generality of our approach. On each backbone, we implement our proposed DS-MCM and compare it against strong LLM-as-Critic baseline, where critic model directly performs both fast monitoring and slow reflective analysis through prompted self-evaluation, without explicit uncertaintyevidence consistency modeling or experience-driven metacognitive memory. For additional comparison, we also report results from several proprietary deep-search systems and models, including GPT-5 and o3 [21] from OpenAI, Gemini2.5 Pro [12], Grok-3 DeeperSearch [33], and OpenAI Deep Research [22]. The reported results for these proprietary systems are obtained from existing benchmarks [3, 38]. Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Conference17, July 2017, Washington, DC, USA Table 1: Main results (%) on deep-search benchmarks. Average is computed across the four benchmarks, with its statistical significance assessed via paired t-tests; missing entries () are excluded from averaging. Colored cells highlight DS-MCM results, with light orange marking notable cases that surpass proprietary systems. Boldface denotes the best performance. indicates statistically significant improvements over the corresponding baselines (permutation test with 10,000 trials, ğ‘ < 0.05). Model BrowseComp-Plus BrowseComp-ZH X-Bench GAIA Average Proprietary Deep-Search Systems / Models OpenAI GPT-5 OpenAI o3 Gemini 2.5 Pro Grok-3 DeeperSearch OpenAI DeepSearch 70.0 63.5 59.4 51.5 34.3 29.1 27.3 12.2 42. Open-Source Deep-Search Systems / Models Tongyi-DeepResearch + LLM-Critic + DS-MCM MiroThinker-DeepResearch + LLM-Critic + DS-MCM Qwen3-30B-MoE + LLM-Critic + DS-MCM 51.0 55.0 62.0 21.0 24. 26.0 5.0 22.0 29.0 38.0 42.0 45.0 31.0 30.0 34.0 21.0 27.0 35.0 75.0 65.0 56.0 50.0 66.7 69.0 68.0 74.0 62.0 64.0 68.0 42.0 47.0 53.0 62. 70.9 60.6 47.1 70.5 70.1 69.3 71.7 63.8 63.0 69.3 40.9 43.3 47.2 60.5 57.1 50.8 36.4 57. 57.0 58.6 63.2 44.5 45.2 49.3 27.2 34.8 41.1 Implementation Details. DS-MCM is implemented on top of 4.1.3 standard ReAct-based deep search agent without modifying the underlying task-level policy. We use Qwen-Embedding-8B [41] as the unified embedding model for semantic clustering in the Fast Consistency Monitor and for encoding sessions and memory entries in the Slow Experience-Driven Monitor. At each retrieval step, the agent retrieves the top-5 documents, which are clustered in the embedding space to compute Searching Entropy. All session and memory embeddings are indexed using FAISS-based vector index to enable efficient similarity search [6]. The Fast Consistency Monitor is applied at every step, with the anomaly threshold set to ğœ = ğ‘˜ğœ and ğ‘˜ = 2. When an anomaly is detected, the Slow Experience-Driven Monitor is triggered, using Qwen3-A30B-A3B-Instruct-2507 as the Critical Model [35] and GPT 5.2 [21] to construct experience memory. For each flagged session, we retrieve two relevant entries from the success memory and two from the failure memory ğ‘¡ = 2) to perform memory-conditioned diagnosis and (R+ generate corrective suggestions. ğ‘¡ = All experiments are conducted using the SGLang inference engine [44] with the HuggingFace Transformers library [32], on machines equipped with NVIDIA A6000 GPUs and 52-core Intel(R) Xeon(R) Gold 6230R CPUs at 2.10GHz. In addition to the BrowseComp-Plus benchmark, external documents during deep search are obtained via the Google Search API 1 and processed using the Jina API 2. 1https://serper.dev/ 2https://jina.ai/"
        },
        {
            "title": "4.2 RQ1: Overall Performance\nTable 1 summarizes the performance of different deep-search sys-\ntems across four benchmarks. Overall, DS-MCM consistently\nand substantially improves performance across all evaluated\nbackbones, yielding significant gains over both vanilla deep-search\nsystems and strong LLM-as-Critic baselines. For open-source mod-\nels, DS-MCM achieves clear improvements on nearly all bench-\nmarks, with many gains being statistically significant (â€ ), demon-\nstrating that explicit meta-cognitive monitoring provides benefits\nbeyond generic LLM as critic alone.",
            "content": "Notably, DS-MCM elevates the open-source Tongyi DeepResearch to new performance regime. With DS-MCM, TongyiDeepResearch attains the highest overall average score among all evaluated systems, surpassing its own LLM-Critic variant by large margin and outperforming multiple proprietary deepsearch systems, including OpenAI o3, OpenAI DeepSearch, Gemini 2.5 Pro, and Grok-3 DeeperSearch on average. This result is particularly striking given that these proprietary systems rely on larger closed models and tightly integrated commercial pipelines. These results indicate that the performance gap between opensource and proprietary deep-search systems is not solely determined by model scale or closed infrastructures. Instead, principled, neuroscience-inspired meta-cognitive monitoring can substantially improve robustness and accuracy, enabling open-source deep-search agents to match or even exceed the performance of state-of-the-art commercial systems. Conference17, July 2017, Washington, DC, USA Zhongxiang Sun et al. Table 2: Ablation study of DS-MCM on different open-source deep-search backbones. Model w/o Experience Memory w/o Searching Entropy FULL DS-MCM Tongyi-DR MiroThinker-DR Qwen3-30B-MoE 53 57 62 23 24 26 23 25 29 Table 3: Evaluation on the Who&When benchmark for identifying faulty agents and erroneous steps. Method Who&When (Handcrafted) Who&When (Automated) Qwen3-8B + MCM Qwen3-30B + MCM GPT-4o + MCM GPT-4.1 + MCM GPT-5 + MCM Agent-level 46.55 55.17 31.03 39.66 51.72 51.72 36.21 55.17 36.21 51.72 Step-level 3.45 22.41 5.17 15.52 5.17 22.41 8.62 24.14 18.97 29.31 Agent-level 57.14 57. 57.94 64.29 41.27 54.76 60.32 60.32 58.73 60.76 Step-level 14.29 34.13 19.05 44.44 14.29 38.89 26.98 43.65 14.29 50."
        },
        {
            "title": "Monitoring for Agent Process Supervision",
            "content": "To evaluate the ability of the Slow Experience-Driven Monitor to identify errors during execution, we conduct experiments on the Who&When benchmark [40], which includes handcrafted subset derived from Magnetic-One [10] and an automated subset constructed from AG2 [19]. Following prior work [40], we report agent-level accuracy, measuring whether the faulty agent is correctly identified, and step-level accuracy, assessing whether the exact erroneous reasoning step is localized. To enforce strict generalization setting, we adopt cross-memory protocol: when evaluating on the handcrafted subset, the experience memory is constructed from the automated subset, and vice versa, preventing memory leakage and encouraging reusable error pattern learning. As shown in Table 3, incorporating MCM with experience memory consistently improves error localization performance across all LLM based critical models and both subsets. The most substantial gains occur at the step level, where MCM significantly increases the accuracy of identifying the precise erroneous step, indicating stronger process-level supervision. Agent-level accuracy also improves for most backbones, suggesting better attribution of failures within multi-step trajectories. Notably, these improvements persist under the cross-memory evaluation protocol, demonstrating that MCM captures generalizable execution-level error patterns rather than dataset-specific artifacts. Overall, these results validate the effectiveness of the slow experience-driven monitor in detecting and localizing errors during deep-search execution."
        },
        {
            "title": "4.6 RQ3: Time Efficiency Analysis\nTable 4 reports the runtime overhead of different monitoring strate-\ngies on BrowseComp-Plus and GAIA. Incorporating an LLM-Critic\nconsistently introduces substantial latency, increasing end-to-end\nexecution time by 12â€“22% across backbones and benchmarks. This\noverhead arises from invoking a full critic model at every step,\nregardless of whether reflective intervention is necessary. In con-\ntrast, DS-MCM incurs only modest additional cost. Across both\nTongyi-DeepResearch and MiroThinker-DeepResearch, DS-MCM\nincreases runtime by merely 3â€“7%, which is significantly lower",
            "content": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Conference17, July 2017, Washington, DC, USA Figure 3: Sensitivity analysis of DS-MCM with respect to key hyperparameters. Table 4: Time efficiency analysis (seconds per query) on deepsearch benchmarks. Numbers in parentheses indicate relative overhead compared to the corresponding backbone. Table 6: Human evaluation of corrective suggestions ğ›¿ğ‘¡ generated by different monitoring strategies. Method Tongyi-DeepResearch + LLM-Critic + DS-MCM BrowseComp-Plus 519.71 (1.00) 581.43 (1.12) 541.43 (1.04) MiroThinker-DeepResearch + LLM-Critic + DS-MCM 608.76 (1.00) 690.32 (1.13) 631.25 (1.03) GAIA 219.57 (1.00) 253.43 (1.15) 235.35 (1.07) 273.56 (1.00) 334.23 (1.22) 292.41 (1.07) Table 5: Effect of different knowledge bases for constructing the Slow Experience-Driven Monitor. All results are evaluated on BrowseComp-Plus. Î” denotes the absolute improvement over the corresponding base model. Method Knowledge Base Accuracy (%) Tongyi-DeepResearch Base + DS-MCM + DS-MCM BrowseComp GAIA MiroThinker-DeepResearch Base BrowseComp GAIA + DS-MCM + DS-MCM 51 62 60 21 26 25 ğš« 0.11 0.09 0.05 0.04 than that of LLM-Critic. This efficiency gain stems from the hierarchical design of DS-MCM: the Fast Consistency Monitor operates with lightweight detection at every step, while the computationally expensive Slow Experience-Driven Monitor is triggered only when abnormal execution states are detected. These results demonstrate that DS-MCM achieves favorable trade-off between effectiveness and efficiency. By avoiding unconditional critique and enabling selective reflective control, DS-MCM delivers strong performance improvements with minimal additional latency, making it more suitable for practical deployment of deep-search agents. Method BrowseComp-Plus GAIA Tongyi-DeepResearch + LLM-Critic + DS-MCM MiroThinker-DeepResearch + LLM-Critic + DS-MCM 69.0 80.0 64.0 75.0 65.0 73. 59.0 79."
        },
        {
            "title": "4.8 RQ4: Human Evaluation\nWe conduct a human evaluation to assess whether the corrective\nsuggestions ğ›¿ğ‘¡ generated by the Slow Experience-Driven Moni-\ntor are reasonable. We randomly sample 100 sessions where the\nslow monitor is triggered and provide annotators with the query,\nexecution history, and current session state. Each session is inde-\npendently evaluated by two human annotators, and a suggestion is\ncounted as correct only when both annotators agree. As shown in\nTable 6, DS-MCM consistently outperforms the LLM-Critic baseline\nacross both backbones and benchmarks. These results indicate that\nthe experience-driven slow monitor produces more reasonable and\nactionable corrective suggestions than generic LLM-based critique.",
            "content": "Conference17, July 2017, Washington, DC, USA Zhongxiang Sun et al."
        },
        {
            "title": "5 Conclusion\nDeep-search agents operate under long-horizon execution with con-\ntinuously evolving and often uncertain external evidence, making\neffective monitoring and regulation critical for reliable performance.\nHowever, existing systems largely focus on task-level reasoning\nwhile lacking explicit mechanisms for execution-level metacog-\nnitive control. We present DS-MCM, a metacognitive monitoring\nframework for deep-search agents that separates task-level rea-\nsoning from execution-level control. DS-MCM integrates a fast\nconsistency check between reasoning and evidence uncertainty\nwith a slow, experience-driven monitor to guide corrective behav-\nior. Experiments show that DS-MCM consistently improves perfor-\nmance across benchmarks and backbones, enabling open-source\nsystems to rival or surpass proprietary deep-search models. Further\nanalyses confirm the complementary roles of fast and slow mon-\nitoring with only modest computational overhead. These results\nhighlight metacognitive monitoring as a key ingredient for robust\nand practical deep-search agents.",
            "content": "References [1] Matthew Botvinick, Todd Braver, Deanna Barch, Cameron Carter, and Jonathan Cohen. 2001. Conflict monitoring and cognitive control. Psychological review 108, 3 (2001), 624. [2] Ricardo J.G.B. Campello, Davoud Moulavi, and JÃ¶rg Sander. 2013. Density-Based Clustering Based on Hierarchical Density Estimates. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. [3] Kaiyuan Chen, Yixin Ren, Yang Liu, Xiaobo Hu, Haotong Tian, Tianbao Xie, Fangfu Liu, Haoye Zhang, Hongzhang Liu, Yuan Gong, et al. 2025. xbench: Tracking Agents Productivity Scaling with Profession-Aligned Real-World Evaluations. arXiv preprint arXiv:2506.13651 (2025). [4] Zijian Chen, Xueguang Ma, Shengyao Zhuang, Ping Nie, Kai Zou, Sahel Sharifymoghaddam, Andrew Liu, Joshua Green, Kshama Patel, Ruoxi Meng, et al. [n. d.]. BrowseComp-Plus: More Fair and Transparent Evaluation Benchmark of Deep-Research Agent. In First Workshop on Multi-Turn Interactions in Large Language Models. [5] Guanting Dong, Licheng Bao, Zhongyuan Wang, Kangzhi Zhao, Xiaoxi Li, Jiajie Jin, Jinghan Yang, Hangyu Mao, Fuzheng Zhang, Kun Gai, et al. 2025. Agentic entropy-balanced policy optimization. arXiv preprint arXiv:2510.14545 (2025). [6] Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel MazarÃ©, Maria Lomeli, Lucas Hosseini, and HervÃ© JÃ©gou. 2025. The faiss library. IEEE Transactions on Big Data (2025). [7] Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal. 2024. Detecting hallucinations in large language models using semantic entropy. Nature 630, 8017 (2024), 625630. [8] John Flavell. 1979. Metacognition and cognitive monitoring: new area of cognitivedevelopmental inquiry. American psychologist 34, 10 (1979), 906. [9] Stephen Fleming and Hakwan Lau. 2014. How to measure metacognition. Frontiers in human neuroscience 8 (2014), 443. [10] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, et al. 2024. Magentic-one: generalist multi-agent system for solving complex tasks. arXiv preprint arXiv:2411.04468 (2024). [11] William Gehring, Brian Goss, Michael GH Coles, David Meyer, and Emanuel Donchin. 1993. neural system for error detection and compensation. Psychological science 4, 6 (1993), 385390. [12] Google. 2025. Gemini Deep Research (incl. Gemini 2.5 Pro capabilities). https: //gemini.google/overview/deep-research/ [13] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Nan Duan, Weizhu Chen, et al. [n. d.]. CRITIC: Large Language Models Can Self-Correct with ToolInteractive Critiquing. In The Twelfth International Conference on Learning Representations. [14] Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yongkang Wu, Ji-Rong Wen, Yutao Zhu, and Zhicheng Dou. 2025. Webthinker: Empowering large reasoning models with deep research capability. arXiv preprint arXiv:2504.21776 (2025). [15] Zijun Liu, Peiyi Wang, Runxin Xu, Shirong Ma, Chong Ruan, Peng Li, Yang Liu, and Yu Wu. 2025. Inference-time scaling for generalist reward modeling. arXiv preprint arXiv:2504.02495 (2025). [16] Andrey Malinin and Mark Gales. 2020. Uncertainty estimation in autoregressive structured prediction. arXiv preprint arXiv:2002.07650 (2020). [17] Janet Metcalfe. 2013. Evolution of metacognition. In Handbook of metamemory and memory. Psychology Press, 2946. [18] GrÃ©goire Mialon, ClÃ©mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023. Gaia: benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations. [19] Microsoft. 2024. AG2 (formerly AutoGen): The Open-Source AgentOS. https: //github.com/ag2ai/ag2. [20] Thomas Nelson. 1990. Metamemory: theoretical framework and new findings. In Psychology of learning and motivation. Vol. 26. Elsevier, 125173. [21] OpenAI. 2025. GPT-5 is here. https://openai.com/gpt-5/ [22] OpenAI. 2025. Introducing Deep Research (OpenAI). https://openai.com/index/ introducing-deep-research/ [23] Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, and Peter Liu. [n. d.]. Out-of-Distribution Detection and Selective Generation for Conditional Language Models. In The Eleventh International Conference on Learning Representations. [24] Nicholas Shea, Annika Boldt, Dan Bang, Nick Yeung, Cecilia Heyes, and Chris Frith. 2014. Supra-personal cognitive control and metacognition. Trends in cognitive sciences 18, 4 (2014), 186193. [25] Amitai Shenhav, Matthew Botvinick, and Jonathan Cohen. 2013. The expected value of control: an integrative theory of anterior cingulate cortex function. Neuron 79, 2 (2013), 217240. [26] Zhengliang Shi, Yiqun Chen, Haitao Li, Weiwei Sun, Shiyu Ni, Yougang Lyu, Run-Ze Fan, Bowen Jin, Yixuan Weng, Minjun Zhu, et al. 2025. Deep Research: Systematic Survey. arXiv preprint arXiv:2512.02038 (2025). [27] Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, and Jun Xu. 2025. Detection and Mitigation of Hallucination in Large Reasoning Models: Mechanistic Perspective. arXiv preprint arXiv:2505.12886 (2025). [28] Zhongxiang Sun, Qipeng Wang, Weijie Yu, Xiaoxue Zang, Kai Zheng, Jun Xu, Xiao Zhang, Yang Song, and Han Li. 2025. Rearter: Retrieval-augmented reasoning with trustworthy process rewarding. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval. 12511261. [29] MiroMind Team, Song Bai, Lidong Bing, Carson Chen, Guanzheng Chen, Yuntao Chen, Zhe Chen, Ziyi Chen, Jifeng Dai, Xuan Dong, et al. 2025. MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling. arXiv preprint arXiv:2511.11793 (2025). [30] Tongyi DeepResearch Team, Baixuan Li, Bo Zhang, Dingchu Zhang, Fei Huang, Guangyu Li, Guoxin Chen, Huifeng Yin, Jialong Wu, Jingren Zhou, et al. 2025. Tongyi deepresearch technical report. arXiv preprint arXiv:2510.24701 (2025). [31] Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. 2025. Browsecomp: simple yet challenging benchmark for browsing agents. arXiv preprint arXiv:2504.12516 (2025). [32] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz, et al. 2019. Huggingfaces transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771 (2019). [33] xAI. 2025. Grok AI Assistant and Search Enhanced Model. https://grok.com/ [34] Zhiheng Xi, Dingwen Yang, Jixuan Huang, Jiafu Tang, Guanyu Li, Yiwen Ding, Wei He, Boyang Hong, Shihan Do, Wenyu Zhan, et al. 2024. Enhancing llm reasoning via critique models with test-time and training-time supervision. arXiv preprint arXiv:2411.16579 (2024). [35] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. 2025. Qwen3 technical report. arXiv preprint arXiv:2505.09388 (2025). [36] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations. [37] Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, et al. 2025. Self-generated critiques boost reward modeling for language models. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 1149911514. [38] Weihao Zeng, Keqing He, Chuqiao Kuang, Xiaoguang Li, and Junxian He. 2025. Pushing test-time scaling limits of deep search with asymmetric verification. arXiv preprint arXiv:2510.06135 (2025). [39] Dingling Zhang, He Zhu, Jincheng Ren, Kangqi Song, Xinran Zhou, Boyu Feng, Shudong Liu, Jiabin Luo, Weihao Xie, Zhaohui Wang, et al. 2025. How Far Are We from Genuinely Useful Deep Research Agents? arXiv preprint arXiv:2512.01948 (2025). [40] Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, et al. 2025. Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems. In Forty-second International Conference on Machine Learning. Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience Conference17, July 2017, Washington, DC, USA [41] Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, and Jingren Zhou. 2025. Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models. arXiv preprint arXiv:2506.05176 (2025). [42] Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, and Junyang Lin. 2025. The lessons of developing process reward models in mathematical reasoning. arXiv preprint arXiv:2501.07301 (2025). [43] Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, and Junyang Lin. 2025. Processbench: Identifying process errors in mathematical reasoning. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 10091024. [44] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Livia Sun, Jeff Huang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph Gonzalez, et al. 2024. Sglang: Efficient execution of structured language model programs. Advances in neural information processing systems 37 (2024), 6255762583. [45] Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, et al. 2025. Browsecomp-zh: Benchmarking web browsing ability of large language models in chinese. arXiv preprint arXiv:2504.19314 (2025)."
        }
    ],
    "affiliations": [
        "Beijing University of Posts and Telecommunications",
        "Gaoling School of Artificial Intelligence Renmin University of China",
        "School of Information Technology and Management University of International Business and Economics",
        "Search Applications Department, Tencent"
    ]
}