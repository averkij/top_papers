{
    "paper_title": "DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior",
    "authors": [
        "Junzhe Lu",
        "Jing Lin",
        "Hongkun Dou",
        "Ailing Zeng",
        "Yue Deng",
        "Xian Liu",
        "Zhongang Cai",
        "Lei Yang",
        "Yulun Zhang",
        "Haoqian Wang",
        "Ziwei Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We present DPoser-X, a diffusion-based prior model for 3D whole-body human poses. Building a versatile and robust full-body human pose prior remains challenging due to the inherent complexity of articulated human poses and the scarcity of high-quality whole-body pose datasets. To address these limitations, we introduce a Diffusion model as body Pose prior (DPoser) and extend it to DPoser-X for expressive whole-body human pose modeling. Our approach unifies various pose-centric tasks as inverse problems, solving them through variational diffusion sampling. To enhance performance on downstream applications, we introduce a novel truncated timestep scheduling method specifically designed for pose data characteristics. We also propose a masked training mechanism that effectively combines whole-body and part-specific datasets, enabling our model to capture interdependencies between body parts while avoiding overfitting to specific actions. Extensive experiments demonstrate DPoser-X's robustness and versatility across multiple benchmarks for body, hand, face, and full-body pose modeling. Our model consistently outperforms state-of-the-art alternatives, establishing a new benchmark for whole-body human pose prior modeling."
        },
        {
            "title": "Start",
            "content": "DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior Junzhe Lu1,* Xian Liu5 Zhongang Cai6 Jing Lin2,* Hongkun Dou3 Ailing Zeng4 Yue Deng3 Lei Yang6 Yulun Zhang7 Haoqian Wang1, Ziwei Liu2, 1Tsinghua University 2Nanyang Technological University 4Independent Researcher 5NVIDIA Research 6SenseTime Research 7Shanghai Jiao Tong University https://dposer.github.io/ 3Beihang University 5 2 0 2 4 ] . [ 2 9 9 5 0 0 . 8 0 5 2 : r Figure 1. An overview of DPoser-Xs versatility and performance across multiple pose-related tasks. Built on diffusion models, DPoser-X serves as robust and adaptable prior for 3D whole-body human pose modeling. Shown are scenarios in (a) pose generation, (b) human mesh recovery, and (c) pose completion. With up to 61% improvement across 8 benchmarks, DPoser-X consistently outstrips existing priors like VPoser [51] and NRDF [24], proving its superiority in tasks involving the human body, hand, and face."
        },
        {
            "title": "Abstract",
            "content": "1. Introduction We present DPoser-X, diffusion-based prior model for 3D whole-body human poses. Building versatile and robust full-body human pose prior remains challenging due to the inherent complexity of articulated human poses and the scarcity of high-quality whole-body pose datasets. To address these limitations, we introduce Diffusion model as body Pose prior (DPoser) and extend it to DPoser-X for expressive whole-body human pose modeling. Our approach unifies various pose-centric tasks as inverse problems, solving them through variational diffusion sampling. To enhance performance on downstream applications, we introduce novel truncated timestep scheduling method specifically designed for pose data characteristics. We also propose masked training mechanism that effectively combines whole-body and part-specific datasets, enabling our model to capture interdependencies between body parts while avoiding overfitting to specific actions. Extensive experiments demonstrate DPoser-Xs robustness and versatility across multiple benchmarks for body, hand, face, and full-body pose modeling. Our model consistently outperforms state-of-the-art alternatives, establishing new benchmark for whole-body human pose prior modeling. * Equal contribution. Corresponding authors. Human pose modeling is fundamental research topic with broad applications, ranging from human-robot interaction to augmented and virtual reality experiences. Obtaining plausible and realistic human poses requires learning effective pose distribution from large-scale datasets, which can then serve as priors for downstream tasks like body model fitting, motion capture, and gesture recognition. Previous approaches to human pose prior modeling have primarily adopted techniques such as Gaussian Mixture Models (GMMs) [1], Variational Auto-encoders (VAEs) [51], and Neural Distance Fields (NDFs) [24, 65]. However, each of these approaches faces inherent limitations. GMMs can generate implausible poses due to their unbounded nature, and VAEs enforce Gaussian prior in the latent that undermines expressiveness. NDFs, while promising for 3D surface modeling, struggle to generalize across the complex, high-dimensional manifolds of human pose. Moreover, due to the scarcity of whole-body pose data, most existing prior models focus on body-only poses, neglecting the wholebody domain which is crucial for detailed human modeling. To overcome these limitations, recent advances in diffusion models [26, 62] offer compelling new paradigm. Unlike VAEs with their restrictive latent bottlenecks, diffusion models show greater expressiveness in learning com1 plex distributions. This has led to state-of-the-art results in domains from image synthesis [14, 32] to human motion generation [44, 58] and multi-hypothesis pose estimation [9, 27]. However, these pose-related applications are typically designed for specific generation tasks or tailored to work with conditional inputs. The potential of diffusion models to serve as universal human pose prior that benefits various pose-related tasks remains largely unexplored. In this work, we introduce DPoser, diffusion-based human pose prior that can be seamlessly integrated across diverse pose-related tasks via test-time optimization. Our approach begins with training an unconditional diffusion model. We then formulate various pose-centric tasks as inverse problems, solving them based on variational diffusion sampling [46], where DPoser serves as regularization component. Furthermore, our investigations reveal that key pose information during diffusion is concentrated in the later timesteps, leading us to develop novel truncated timestep scheduling strategy to enhance optimization performance. Finally, we extend DPoser to DPoser-X for whole-body pose modeling with mixed training strategy to address the data scarcity issue. Extensive experiments demonstrate that DPoser-X outshines state-of-the-art pose priors in range of downstream tasks involving the body, hand, and face. An overview of DPoser-Xs versatility and performance across pose-related tasks is shown in Fig. 1. In summary, our main contributions are as follows: We introduce DPoser, novel framework based on diffusion models that creates robust and flexible human pose prior applicable across diverse pose-related tasks. We analyze the impact of diffusion timesteps in the pose domain and propose truncated timestep scheduling for more efficient test-time optimization. We present DPoser-X, the first whole-body pose prior, which incorporates mixed training strategy that effectively leverages both whole-body and part-only datasets. Extensive experiments demonstrate that DPoser-X outstrips previous pose priors on multiple benchmarks for body, hand, face, and full-body modeling. 2. Methodology 2.1. Preliminary: Diffusion Models Diffusion models [26, 59, 61, 62] are class of generative models that operate by reversing predefined forward noising process. This forward process systematically corrupts data x0 pdata by adding Gaussian noise over continuous or discrete time variable [0, 1]. noisy sample xt at any given time is produced according to: xt = αtx0 + σtϵ, ϵ (0, I) (1) Here, αt and σt are predefined schedule functions such that as increases from 0 to 1, the data distribution is gradually transformed into tractable prior, typically an isotropic Gaussian distribution (0, I). The generative aspect lies in learning to reverse this process. This is achieved by training neural network, typically parameterized as noise predictor ϵϕ(xt; t), to estimate the noise component ϵ from given noisy sample xt. The network is optimized using the following L2-loss objective [26], where w(t) is positive weighting function: 2 (2) (cid:3) , (cid:2)w(t)ϵ ϵϕ(xt; t)2 Ex0pdata,ϵN (0,I),tU [0,1] Once trained, the model can generate novel data by simulating the reverse diffusion trajectory. This procedure starts with random sample from the prior, x1 (0, I), and iteratively applies the learned denoiser ϵϕ to produce clean sample x0. In practice, this reverse simulation is implemented by numerical solvers [62], such as the discrete samplers introduced in DDPM [26] and DDIM [60]. 2.2. Learning Pose Prior with Diffusion Models SMPL-based pose representation. To build flexible 3D human pose prior for the body, we propose to utilize the SMPL body model [43], which can be viewed as differentiable function [J, ] = (θ, β) that maps body joint angles θ R321 and shape parameters β R10 to mesh vertices R36890 and joint positions R322. Our target is to model the distribution of joint angles p(θ). Training of unconditional diffusion models. To this end, we adopt an unconditional diffusion model to learn the pose representation θ. This approach aligns with task-agnostic strategy, focusing solely on the distribution of 3D poses. For the diffusion process, we employ the sub-VP SDE parameterization proposed in [62]. Specifically, the coefficients in Eq. (1) can be obtained as: αt = exp and (cid:82) σt = 1 exp scheduled noise scales. , where ξ(t) denotes linear (cid:17) (cid:82) 0 ξ(s)ds (cid:17) 0 ξ(s)ds 1 2 (cid:16) (cid:16) During training, we sample clean pose θ (also x0) from datasets and introduce noise to generate noisy samples xt according to the forward process (Eq. (1)). Then we apply the objective in Eq. (2) to train the noise predictor ϵϕ(xt; t) with weights w(t) = σ2 as suggested in [62]. 2.3. Optimization Leveraging Diffusion Priors The acquired noise predictor, denoted as ϵϕ, permits the generation of novel poses through various samplers. Yet, integrating diffusion priors into general downstream tasks remains largely unexplored. We address this by reframing pose-related tasks as inverse problems and applying variational diffusion sampling [46] for efficient resolution. Inverse problem formulation. Given an original signal x0 and degraded measurement y, typical inverse problem can be formulated as: = A(x0) + n, y, Rd, x0 Rn, where symbolizes the degradation pattern and consti- (3) 2 intuitive regularization term defined as: LDPoser = wtx0 sg[ˆx0(t)] 2, where (5) . (6) ˆx0(t) = xt σtϵϕ(xt; t) αt Here, ˆx0(t) functions as one-step denoising estimation using the diffusion model ϵϕ(xt; t), which recovers clean pose from diffused sample xt at any timestep t. The straightforward L2-loss encourages the current pose x0 towards denoised, plausible pose distribution. Further, it is theoretically consistent with the gradient direction of the regularization loss during variational diffusion sampling in Eq. (4). Proof: Differentiating Eq. (5) with respect to x0 yields: x0LDPoser = 2wt(x0 ˆx0(t)) = 2wt( xt σtϵ αt xt σtϵϕ(xt; t) αt ) (ϵϕ(xt; t) ϵ) = 2wt σt αt (ϵϕ(xt; t) ϵ). (7) DPoser across pose-related tasks. As regularization term, DPoser can be combined with task-specific measurement losses in various pose-related tasks. We demonstrate the applications like human mesh recovery (illustrated in Fig. 2) and inverse kinematics. Section provides test-time details about more domains (e.g., hand and face) and tasks such as pose completion and motion denoising. Human mesh recovery (HMR) aims to deduce the human pose and shape from monocular images. In this context, we refine the optimization function in SMPLify [1], integrating DPoser as regularization term, LDPoser, and omitting the original intricate interpenetration error component. The modified objective, engaging both body pose θ and shape β parameters from the SMPL model [43], is defined as: L(θ, β) = LHMR + wβLβ + wθLDPoser. (8) The re-projection loss LHMR, acting as the measurement loss, is defined by: LHMR = (cid:88) iJoints λiρ (cid:0)ΠC (MJ (θ, β)i) est (cid:1) , (9) where MJ (θ, β) denotes SMPLs forward kinematics. The camera function ΠC maps 3D joint coordinates into 2D space. est refers to the 2D keypoints estimated using offthe-shelf 2D pose estimators, with λi reflecting the confidence score. The Geman-McClure error function (ρ) is employed to assess the discrepancy in 2D joint locations. To avoid unrealistic poses when minimizing re-projection loss, our DPoser regularization LDPoser is introduced on the body pose θ. Moreover, shape regularization term Lβ = β2 2 is utilized to constrain the body shapes. Their weights are expressed as wθ, and wβ respectively. Another application is inverse kinematics (IK), which estimates poses from noisy or incomplete 3D joint positions, 3 Figure 2. Overview of the DPoser-regularized optimization framework. Task inputs (e.g., 2D keypoints in human mesh recovery) and current poses are used to compute the measurement loss based on the degradation pattern A() (e.g., camera projection). Meanwhile, DPoser regularization introduces noise to the current pose and applies one-step denoiser to compute DPoser loss LDPoser. tutes noise, assumed to be white Gaussian. x0 refers to pose representations in human models like SMPL [43]. This formulation allows us to approach various pose-centric tasks by adapting and interpreting accordingly: Pose completion: Here, serves as mask matrix, with being the observed incomplete pose data. Inverse kinematics & Motion denoising: In this scenario, applies forward kinematics of human models, treating as the observed noisy 3D joints. Human mesh recovery: integrates forward kinematics and perspective camera projection to relate to 2D joint observations in images (i.e. 2D keypoints). The aim is to recover the original signal x0 based on the degraded measurement y. Specifically, our objective shifts to sampling from the posterior distribution (x0 y). Solving inverse problems with diffusion models. To simulate this posterior sampling process, we adopt the variational diffusion sampling technique [46]. It employs variational distribution (x0 y) := (µ, σ2I) and aims to minimize the KL divergence between this variational distribution and the true posterior (x0 y). Further, under the assumption of zero variance (σ 0), the optimization problem of seeking x0 (i.e., µ) is demonstrated to be equivalent to minimizing the following loss function [46, 63]: (4) = A(x0)2 + wt(sg[ϵϕ(xt; t) ϵ])x0, where the first term represents the task-specific measurement loss, and the second term corresponds to the regularization loss. Here, wt denotes the loss weights, ϵ is the standard Gaussian noise, and sg signifies stopped-gradient. The regularization procedure initiates by selecting timestep and perturbs the optimization variable x0 as per Eq. (1), resulting in xt. Then, the gradients [ϵϕ(xt; t) ϵ] are applied. Introducing DPoser regularization. To shed more light on the working mechanism, we propose an equivalent but more Algorithm 1 Test-time Optimization with DPoser Require: trained diffusion model ϵϕ(xt; t), task-specific loss Ltask, range of diffusion timesteps [tmax, tmin], number of optimization iterations . Ensure: Initialization of pose parameters x0 Timestep scheduling 1: for iter = 0, 1, . . . , 1 do tmax (tmaxtmin)iter 2: 1 Sample ϵ (0, I) 3: xt αtx0 + σtϵ 4: ˆx0(t) xtσtϵϕ(xt;t) 5: αt LDPoser wtx0 sg[ˆx0(t)]2 2 Ltotal Ltask + LDPoser Update x0 via backpropagation on Ltotal Forward diffusion One-step denoiser Regularization 6: 7: 8: 9: end for 10: return x0 Figure 3. Illustration of the rationale behind the proposed truncated timestep scheduling. We employ the DDIM sampler [60] with limited steps and visualize the generated poses. Our observations reveal that pose refinement occurs at later timesteps. obs, where the set of known joints is assumed to be provided. The task-specific measurement loss, LIK, is an L2loss between the models 3D joints and the observed ones: LIK = (cid:88) iKnown Joints MJ (θ, β)i obs 2 2. (10) As with HMR, the full objective combines LIK with our DPoser regularization LDPoser. The inclusion of LDPoser is crucial for ensuring plausible poses, especially when 3D joint observations are sparse or noisy. Given the structure of LDPoser, selecting the suitable diffusion timestep is essential in the iterative optimization process. In the subsequent section, we address this by introducing our novel truncated timestep scheduling. 2.4. Test-time Truncated Timestep Scheduling In the diffusion process, previous research [5] on images shows that initial timesteps (larger t) correspond to the perceptual content, while later timesteps refine details. Pose data, however, lacks the similar structured layering and spatial redundancy, implying need for tailored timestep scheduling approach. As depicted in Fig. 3, we find that pose generation does not benefit from the early timesteps as image generation does. The significant stages of pose refinement occur at smaller t, specifically when 0.3. With limited steps, the uniform scheduling, as tested in (b), proves less effective. In contrast, allocating these steps toward the latter end of the diffusion process, as in (c), yields better samples. This indicates that critical pose information is concentrated more heavily in the later timesteps. Based on the above insights, we propose shift from standard uniform timestep scheduling [6, 46] to truncated strategy for pose data. Specifically, the timestep for each optimization step can be expressed as: = tmax (tmax tmin) iter . (11) where denotes the number of optimization iterations, and iter signifies the current iteration. Note that when the interval [tmax, tmin] is set to ([1.0, 0.0]), this strategy degenerates to the uniform linear timestep schedule used in prior works [6, 46]. This formulation is integral to our optimization framework, which is summarized in Alg. 1. The timestep interval is chosen based on the tasks noise scale (typically [0.15, 0.05]). See Section for details. 2.5. Building Whole-body Pose Prior To model the whole-body pose, we separately train three part-specific DPoser models to capture the distribution of body pose, hand pose, and facial expressions, following the training mechanism described in Section 2.2. For DPoserhand, we adopt the MANO [56] model with the learned target being hand joint angles θhand R315. For DPoserface, we utilize the FLAME [38] model, where the modeling target θf ace R103 includes 100 facial expression coefficients and 3-dimensional jaw pose. As baseline, the three models are combined directly, referred to as DPoserX-base. Specifically, it splits the whole-body pose input into body, hand, and face parts, processing each through its respective part-specific model. DPoser-X-base, however, fails to capture the interactions between different parts, which is crucial for whole-body pose modeling. For instance, in relaxed standing poses, the left and right hand poses are usually mirrored. To address this issue, we introduce fused module after the DPoserX-base model and train it on whole-body datasets, resulting in DPoser-X-fused. While this model performs well in tasks like completion, it exhibits limited pose diversity, as demonstrated in Section 3.5. This limitation stems from the fact that existing whole-body pose datasets mainly capture spe4 Figure 4. Overview of the DPoser-X methodology. (a) The whole-body network consists of frozen part-only networks, and fused module trained on whole-body datasets. (b) The mixed training strategy utilizes part-only datasets by applying loss only to available parts. To prevent arbitrary predictions on unavailable parts, the whole-body data is sometimes randomly masked, and loss is applied to all parts. cific actions (e.g., speech gestures or object-grabbing scenarios), resulting in degraded generalization. To improve this, we propose mixed training strategy, which utilizes whole-body, body-only, hand-only, twohands, and face-only datasets, leading to the DPoser-Xmixed model. Specifically, we treat part-only data as incomplete whole-body data, applying loss only to the available parts. In addition, to reduce the data type gap, we randomly mask the whole-body data and apply loss across all parts, forcing the network to predict masked parts. In practice, we implement the unavailable and masked data parts as the mean poses and enable masking at probability of 20%. This mixed training strategy enables DPoser-X-mixed to maintain whole-body modeling ability while leveraging part-only datasets to enhance generalization. 3. Experiments In this section, we showcase the robustness and versatility of DPoser-X across wide range of pose-centric tasks involving the human body, hand, face, and whole-body. Section and provide evaluation metrics and complete assessments including but not limited to body pose completion, hand mesh recovery, and face generation. 3.1. Experimental Setup Implementation details. DPoser-body is trained on the AMASS dataset [45] with the same splits as prior works [51, 65]. The model employs axis-angle representation for joint rotations, which we normalize to have zero mean and unit variance. The architecture consists of fully connected neural network with about 8.28M parameters. It draws inspiration from GFPose [9] but omits conditional input pathways for our unconditional setting. We train this model for 800,000 iterations using the Adam optimizer with learning rate of 2 104 and batch size of 1280. DPoser-hand and DPoser-face networks use similar architecture. DPoser-hand uses the FreiHAND, DexYCB, HO3D, H2O, and ReInterHand datasets [3, 23, 35, 48, 76]. DPoser-face employs WCPA and MICA datasets [31, 75]. The DPoser-X network integrates last-layer features from pre-trained part models using fully connected neural net- (a) GAN-S [12] (b) Pose-NDF [65] (c) NRDF [24] (d) VPoser [51] (e) DPoser (ours) Figure 5. Qualitative comparison of generated human poses: (e) illustrates naturalistic poses aligned with real-world data, whereas (f) shows poses that, despite superior APD, lack natural appearance. *We use DDIM sampler [60] with only 10 steps. (f) DPoser (ours)* Sample source APD FID Prec. Rec. Real-world [45] 15.44 0.005 GMM [1] VPoser [51] GAN-S [12] Pose-NDF [65] NRDF [24] DPoser DPoser* 16.28 10.75 15.68 18.75 22.82 14.28 19. 1.02 0.66 0.18 5.92 0.64 0.07 0.58 0.86 0.13 0.29 0.61 0.02 0.03 0.72 0.10 0.90 0.34 0.42 0.41 0.00 0.99 0.80 0.95 dN 0.001 4.37 3.74 2.98 9.08 6.69 2.63 2.95 Table 1. Comparative analysis of pose generation metrics. *Indicates the use of 10-step DDIM sampler. work with identical residuals. Whole-body datasets include BEAT2, GRAB, ARCTIC, and EgoBody [16, 41, 64, 71]. After data source weight balancing, based on our mixed training strategy, DPoser-X-mixed is trained on around 65% whole-body, 14% body-only, 12% single-hand, 4% twohand, and 5% face-only data. Comparison settings. We compare against SOTA pose priors including GMM [1], VPoser [51], GAN-S [12], PoseNDF [65], and NRDF [24]. The above works focus on the body, so we have trained the hand versions of VPoser and NRDF. Since NRDF relies on quaternion representations, VPoser is trained for face and whole-body comparisons. We also include an L2-regularization baseline. See Section G.9 for details of comparative methods implementation. 3.2. Body-only Tasks Body pose generation. We conduct generation experiments to assess the learned data distribution of pose priors. Since 5 Figure 6. Visualization of human mesh recovery results (body only) on EHF [51] when fitting from scratch. Initialization w/o fitting GMM [1] VPoser [51] Pose-NDF [65] NRDF [24] GAN-S [12] DPoser from scratch CLIFF [39] 108.57 56.62 58.32 51.02 58.08 49. 57.87 49.50 57.38 49.27 57.26 49.58 56.05 49.05 Table 2. Performance comparison of human mesh recovery on the EHF dataset [51]. PA-MPJPE is reported as the metric. generation is not an inverse problem, we employ standard Euler-Maruyama discretization [62] with 1000 steps for DPosers pose generation. As shown in Fig. 5, DPoser generates visually diverse and realistic poses, indicating well-learned prior distribution. In contrast, VPoser [51] exhibits limited diversity due to its mean-centric nature, constrained by the explicit Gaussian latents. Additionally, both Pose-NDF [65] and NRDF [24] struggle to project pure noise to plausible poses, resulting in unnatural outputs due to their limited generalization capabilities. In terms of quantitative evaluation  (Table 1)  , Pose-NDF and NRDF show high Average Pairwise Distance (APD) but poor Precision and dN . The high APD is likely due to exaggerated poses, which should be avoided in pose priors. To verify this, we test 10-step DDIM sampler [60] named DPoser* that is suboptimal by design. Despite superior APD, DPoser* performs poorly in FID and Precision, indicating that too few steps lead to divergence from the expected distribution. Our findings highlight the need for balanced evaluation of quantitative and qualitative results. Human mesh recovery. We probe the efficacy of DPoser in HMR, focusing on estimating human body pose and shape from monocular images. Following Pose-NDF [65], we conduct experiments on the EHF dataset [51] and benchmark our method against existing SOTA priors. Our optimization-based framework incorporates two initialization paradigms: (1) baseline that utilizes mean poses, and (2) an advanced scheme that employs CLIFF [39], pre-trained regression-based model tailored for HMR. We further compare with recent generation-based methods GFPose [9] and HuProSO3 [15] in Section H.1. As presented in Table 2 and Fig. 6, when fitting from scratch, DPoser surpasses established SOTA priors like GAN-S [12] and NRDF [24]. Moreover, DPoser can refine initial pose estimations from SOTA regression-based models like CLIFF [39], aligning better with images. Motion denoising. Though not initially designed for temporal tasks, DPoser adapts well in motion denoising. The task aims to recover clean body poses from noisy 3D joint Methods AMASS [45] HPS [22] w/o prior VPoser [51] Pose-NDF [65] MVAE [40] HuMoR [55] DPoser 24.19 23.42 22.13 26.80 22.69 19.87 23.67 22.78 21.60 N/A N/A 20.54 Table 3. Performance metrics (MPJPE) for motion denoising. MPJPE MPVPE Methods Setting w/o prior L2 prior VPoser [51] NRDF [24] DPoser-hand w/o prior L2 prior VPoser [51] NRDF [24] DPoser-hand sparse sparse sparse sparse sparse fingertip fingertip fingertip fingertip fingertip Vis. 0.07 0.84 0.37 0.11 0.06 0.13 1.02 0.48 0.15 0.07 Occ. 14.46 13.84 13.10 13.92 5.15 4.00 3.58 4.35 3.95 2.40 All. 8.98 8.89 8.25 8.66 3.21 2.89 2.85 3.25 2.93 1.74 All. 10.07 8.94 8.84 9.53 3.43 4.59 3.15 3.93 3.95 1.99 Table 4. Quantitative evaluation of hand inverse kinematics on the ReInterhand dataset [48] under various masking settings. positions in motion sequences. Following Pose-NDF [65] and HuMoR [55], we apply Gaussian noise (standard deviation of 40 mm) to the 60-frame sequences from the AMASS dataset [45]. We also test on the HPS dataset [22] without additional training to validate generalization. As shown in Table 3, DPoser sets new standard in motion denoising, outperforming even specialized motion priors like HuMoR. 3.3. Hand-only and Face-only Tasks Hand inverse kinematics. We assess DPosers performance in hand inverse kinematics (IK) tasks using the ReInterhand dataset [48], considering various challenging conditions. Table 4 summarizes results across the two settings: sparse (60% keypoints masked) and fingertip (only 5 fingertip keypoints visible). DPoser consistently outperforms baselines, achieving the lowest error. Notably, in the sparse setting, DPoser reduces MPJPE by over 50% compared to other methods, showcasing its robustness in recovering ac6 Methods w/o prior L2 prior VPoser [51] DPoser-face MICA [75] + w/o prior + L2 prior + VPoser [51] + DPoser-face all side-view 12.97/16.07/13.15 12.21/15.15/12.74 12.23/15.13/12.71 11.68/14.58/12.17 9.03/11.12/9.24 9.01/11.09/9.15 9.96/12.37/10.44 9.93/12.34/10.43 8.76/10.78/9.00 13.15/16.22/13.26 12.29/15.22/12.62 12.20/15.35/12.98 11.77/14.67/12.34 9.29/11.71/10.04 9.47/11.80/9.84 10.01/12.49/10.62 10.00/12.50/10.65 9.18/11.47/9. Table 5. Face reconstruction performance on the NOW benchmark [57]. Results are reported as median/mean/std of MPVPE. Figure 7. Visualization of face reconstruction on the NOW bench- (b) Initialization using mark [57]. MICA [75]. *MICA predicts only face shape without expressions; translational and global orientation are fitted for visualization. (a) Fitting from scratch. Methods APDbody APDhands FID Prec. Rec. VPoser-X [51] DPoser-X-base DPoser-X-fused DPoser-X-mixed 7.79 14.45 11.78 14.08 1.16 2.34 1.93 2.04 14.52 90.78 3.71 13.97 0.64 0.00 0.32 0.02 0.07 0.00 0.77 0.81 Table 6. Quantitative evaluation of whole-body pose generation. curate hand poses from limited observations. Face reconstruction. We evaluate DPoser on face reconstruction tasks using the NOW [57] benchmark. The target is to estimate face shape accurately from single image. To assess model performance in more challenging scenarios, we collect and test on side-view subset of NOW. For initialization, in addition to fitting from scratch, we use the SOTA face reconstruction model MICA [75]. As shown in Table 5, when fitting from scratch, DPoser achieves the lowest reconstruction errors across both overall and side-view cases. With MICA initialization, DPoser achieves the best performance, reducing mean error to 8.76 mm. In contrast, due to their mean-centric characteristics, L2 prior and VPoser [51] do not improve on MICAs results, getting even worse results than the baseline without pose prior. Visualizations in Fig. 7 show DPosers ability to reconstruct realistic faces, handling occlusion effectively. 3.4. Whole-body Tasks Whole-body pose generation. We evaluate whole-body pose generation in Table 6 for VPoser-X and three DPoserX variants. See Fig. S-18 for visualization results. DPoser7 Methods ARCTIC [16] BEAT2 [41] MPVPE APD MPVPE APD VPoser-X [51] 37.34/43.24/4.60 21.81/30.99/6.10 DPoser-X 0.59 1.24 27.49/35.46/5.06 15.92/25.89/6.04 0.66 1.18 Table 7. Performance metrics (min/mean/std of MPVPE and APD) for whole-body pose completion on multiple datasets. PA-MPVPE PA-MPJPE"
        },
        {
            "title": "Face",
            "content": "w/o prior GMM [1] & L2 prior VPoser-X [51] DPoser-X SMPLer-X [2] + w/o prior + GMM [1] & L2 prior + VPoser-X [51] + DPoser-X 72.94 67.25 66.74 60.98 26.15 26.33 25.60 25.41 24.65 18.80 17.93 17.44 15.60 11.21 10.34 9.99 9.50 7. 11.60 10.92 10.99 9.75 2.95 2.86 2.78 2.83 2."
        },
        {
            "title": "Body",
            "content": "86.40 79.08 79.88 73.00 29.31 28.69 28.12 28.37 27.87 Table 8. Whole-body mesh recovery results on ARCTIC [16]. X-fused produces more diverse body and hand poses compared to VPoser-X, which prioritizes dataset-consistent realism but has limited diversity. The DPoser-X-base model exhibits the highest diversity but deviates from the wholebody data distribution, as indicated by the high FID. Benefiting our mixed training strategy, DPoser-X-mixed strike good balance between learning whole-body actions (e.g., expressive grabbing and talking) and preserving generalization on more diverse data sources. For conciseness, in subsequent experiments, we denote our DPoser-X-mixed model simply as DPoser-X when no confusion arises. Whole-body pose completion. We conduct challenging pose completion experiment where one hand is masked randomly. This task evaluates the ability to model interdependencies between whole-body parts, particularly between two hands. Given the inherent uncertainties, we obtain 10 hypotheses and evaluate them based on their min/mean/std of errors against the GT. APD across multiple solutions is computed to assess the solution diversity. The testing datasets include ARCTIC [16] and BEAT2 [41], focusing separately on cooperative manipulations and speech gestures involving two hands. As shown in Table 7, DPoserX achieves the lowest min-MPVPE and reflects task uncertainty well with high APD. This indicates that DPoser-X learns the correlation between whole-body parts effectively. Whole-body mesh recovery. We evaluate DPoser-X on the ARCTIC dataset [16] for whole-body mesh recovery. For fitting from scratch, 2D whole-body keypoints are detected by RTMPose [28], while for SMPLer-X [2] initialization, GT 2D keypoints are used. For comparison, we choose VPoser-X and pose prior baseline that employs GMM [1] for body poses and L2 prior for hands and face. Results in Table 8 show that DPoser-X outperforms VPoser-X [51] and GMM baselines across all metrics for Figure 8. Visualization of whole-body mesh recovery on the ARCTIC dataset [16]. DPoser-X can recover plausible whole-body poses from imperfect 2D keypoints detected by RTMPose [28], while other methods struggle to handle noisy inputs effectively. Scheduling Random [52] Fixed [4] Uniform [6, 46] Truncated (ours) Whole-body Mesh Recovery Motion Denoising PA-MPVPEall PA-MPVPEhands MPVPE MPJPE 62.28 61.69 62.13 60.98 16.63 15.71 17.32 15.60 43.33 45.69 39.72 38.21 23.87 22.54 20.80 19.87 Table 9. Ablation of timestep scheduling on key pose-related tasks"
        },
        {
            "title": "Methods",
            "content": "ARCTIC [16] BEAT2 [41] MPVPE APD MPVPE APD 25.49/36.94/8.13 DPoser-X-base DPoser-X-fused 21.51/30.37/5.96 DPoser-X-mixed 21.81/30.99/6.10 1.43 1.14 1.24 21.98/33.41/8.20 15.51/24.58/6.25 15.92/25.89/6.04 1.37 1.12 1.18 Table 10. Ablation of training strategies for whole-body pose completion. min/mean/std of MPVPE and APD are reported. PA-MPVPE PA-MPJPE Methods All Hands Face DPoser-X-base DPoser-X-fused DPoser-X-mixed 72.79 72.06 70.91 17.21 18.12 15.83 5.41 5.35 5.27 Body 74.68 75.27 74.33 Table 11. Ablation of training strategies for whole-body mesh recovery on the Fit3D dataset [19]. the entire body. When used alongside SMPLer-X, DPoserX further refines the initialization, especially on hands, an area often overlooked by the SOTA whole-body mesh recovery models. Qualitative results in Fig. 8 demonstrate that DPoser-X can recover plausible poses from noisy keypoints observations, unlike VPoser-X, which struggles with occlusion and produces unrealistic poses. 3.5. Ablation Study We conduct ablation studies to evaluate the effectiveness of the proposed truncated timestep scheduling and mixed training strategy. Experiments on data representations, network settings, and comparisons with other diffusion-based inverse problem solvers are available in Section and J. Effectiveness of truncated timestep scheduling. We contrast our proposed scheduling strategy against three established methodsrandom [52], fixed [4], and uniform [6, 46] scheduling. The results in Table 9 demonstrate that our scheduling outperforms existing strategies on all the evaluated tasks. As outlined in Section 2.4, the timestep range should be selected based on the noise characteristic of each task. This actually provides perspective to explain the performance. The uniform scheduling (i.e., range as [1.0, 0.0]) performs poorly on mesh recovery due to the low noise scale of this task. Meanwhile, the fixed scheduling (i.e., tmax = tmin) yields the worst results for motion denoising, since the poses are denoised gradually during optimization and the timestep should decrease to adapt it. Advantage of mixed training strategy. The mixed training strategy for DPoser-X combines part-only and wholebody datasets, allowing whole-body modeling and effectively preserving generalization. Beyond the generation experiments in Table 6, we evaluate DPoser-X variants on more downstream tasks. In whole-body pose completion  (Table 10)  , DPoser-X-mixed delivers comparable accuracy to DPoser-X-fused in MPVPE, showing the ability to learn correlations between whole-body parts. In contrast, DPoser-X-base struggles to model such interactions, evidenced by much higher MPVPE. Furthermore, we conduct whole-body mesh recovery experiments on Fit3D [19], which contains challenging sports poses, without additional training. As shown in Table 11, DPoser-X-mixed achieves the best overall PA-MPVPE and outperforms both DPoser-X-fused and DPoser-X-base, especially in handrelated metrics. These results highlight the strength of the mixed training strategy, enabling DPoser-X-mixed to generalize well while maintaining whole-body modeling ability. 4. Conclusion We present DPoser, an unconditional diffusion-based pose prior model designed to support wide range of poserelated tasks. DPoser is engineered for versatility, functioning as simple L2-loss regularizer, and is further enhanced by our novel truncated timestep scheduling for testtime optimization. Unlike prior methods focused solely on the human body, DPoser models are developed for body, hand, and face, demonstrating their efficiency and robustness across various downstream tasks. Additionally, we introduce mixed training strategy to construct the wholebody model, DPoser-X, which effectively integrates both whole-body and part-only datasets. This approach enables DPoser-X to capture correlations between whole-body parts while maintaining strong generalization. Comprehensive experiments substantiate DPoser-Xs superior performance over existing state-of-the-art pose priors, highlighting its potential for broad application. 8 5. Acknowledgments This research was supported by the National Key Research and Development Program of China (Project No. 2022YFB36066) and the Shenzhen Science and Technology Project (Grant Nos. KJZD20240903103210014, JCYJ20220818101004). This work was also supported by the Ministry of Education, Singapore, under its MOE AcRF Tier 2 (MOE-T2EP20221-0012, MOE-T2EP20223-0002), and under the RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s)."
        },
        {
            "title": "References",
            "content": "[1] Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero, and Michael Black. Keep it smpl: Automatic estimation of 3d human pose and shape from single image. In ECCV, 2016. 1, 3, 5, 6, 7, 12, 14, 17, 20, 22 [2] Zhongang Cai, Wanqi Yin, Ailing Zeng, Chen Wei, Qingping Sun, Wang Yanjun, Hui En Pang, Haiyi Mei, Mingyuan Zhang, Lei Zhang, et al. Smpler-x: Scaling up expressive human pose and shape estimation. Advances in Neural Information Processing Systems, 36, 2024. 7, 17 [3] Yu-Wei Chao, Wei Yang, Yu Xiang, Pavlo Molchanov, Ankur Handa, Jonathan Tremblay, Yashraj Narang, Karl Van Wyk, Umar Iqbal, Stan Birchfield, et al. Dexycb: benchmark for capturing hand grasping of objects. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 90449053, 2021. 5, 15 [4] Hanbyel Cho and Junmo Kim. Generative approach for probabilistic human mesh recovery using diffusion models. In ICCV, 2023. 8, 12 [5] Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, and Sungroh Yoon. Perception prioritized training of diffusion models. In CVPR, 2022. 4 [6] Hyungjin Chung, Jeongsol Kim, Michael Mccann, Marc Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. arXiv preprint arXiv:2209.14687, 2022. 4, 8, 23, 24 [7] Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. NeurIPS, 2022. 23, 24 [8] Hyungjin Chung, Jeongsol Kim, Sehui Kim, and Jong Chul Ye. Parallel diffusion models of operator and image for blind inverse problems. In CVPR, 2023. 23 [9] Hai Ci, Mingdong Wu, Wentao Zhu, Xiaoxuan Ma, Hao Dong, Fangwei Zhong, and Yizhou Wang. Gfpose: Learning 3d human pose prior with gradient fields. In CVPR, 2023. 2, 5, 6, 12, [10] Radek Danˇeˇcek, Michael Black, and Timo Bolkart. Emoca: Emotion driven monocular face capture and animation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2031120322, 2022. 20, 21, 33 [11] Giannis Daras, Hyungjin Chung, Chieh-Hsin Lai, Yuki Mitsufuji, Jong Chul Ye, Peyman Milanfar, Alexandros Dimakis, and Mauricio Delbracio. survey on diffusion models for inverse problems. arXiv preprint arXiv:2410.00083, 2024. 13, 24 [12] Andrey Davydov, Anastasia Remizova, Victor Constantin, Sina Honari, Mathieu Salzmann, and Pascal Fua. Adversarial parametric pose prior. In CVPR, 2022. 5, 6, 12, 13, 14, 17 [13] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248255. Ieee, 2009. 14 [14] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. NeurIPS, 2021. 2, [15] Olaf Dunkel, Tim Salzmann, and Florian Pfaff. Normalizing flows on the product space of so (3) manifolds for probabilistic human pose modeling. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22852294, 2024. 6, 18 [16] Zicong Fan, Omid Taheri, Dimitrios Tzionas, Muhammed Kocabas, Manuel Kaufmann, Michael Black, and Otmar Hilliges. Arctic: dataset for dexterous bimanual handobject manipulation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1294312954, 2023. 5, 7, 8, 16, 20 [17] Haven Feng. https : / / github . com / HavenFeng / photometric _ optimization, 2020. 17 Photometric optimization. [18] Yao Feng, Haiwen Feng, Michael Black, and Timo Bolkart. Learning an animatable detailed 3d face model from in-thewild images. ACM Transactions on Graphics (ToG), 40(4): 113, 2021. [19] Mihai Fieraru, Mihai Zanfir, Silviu Cristian Pirlea, Vlad Olaru, and Cristian Sminchisescu. Aifit: Automatic 3d human-interpretable feedback models for fitness training. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 99199928, 2021. 8, 16, 20, 22, 36 [20] Georgios Georgakis, Ren Li, Srikrishna Karanam, Terrence Chen, Jana Koˇsecka, and Ziyan Wu. Hierarchical kinematic human mesh recovery. In ECCV, 2020. 12 [21] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 2020. 12 [22] Vladimir Guzov, Aymen Mir, Torsten Sattler, and Gerard Pons-Moll. Human poseitioning system (hps): 3d human pose estimation and self-localization in large scenes from body-mounted sensors. In CVPR, 2021. 6, 14, 19 [23] Shreyas Hampali, Mahdi Rad, Markus Oberweger, and Vincent Lepetit. Honnotate: method for 3d annotation of hand In Proceedings of the IEEE/CVF conand object poses. ference on computer vision and pattern recognition, pages 31963206, 2020. 5, 15 [24] Yannan He, Garvita Tiwari, Tolga Birdal, Jan Eric Lenssen, and Gerard Pons-Moll. Nrdf: Neural riemannian distance 9 fields for learning articulated pose priors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16611671, 2024. 1, 5, 6, 12, 17, 19, 20, 21, 29 [25] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium. Advances in neural information processing systems, 30, 2017. 17 [26] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 2020. 1, 2, 12, 13 [27] Karl Holmquist and Bastian Wandt. Diffpose: Multihypothesis human pose estimation using diffusion models. In ICCV, 2023. 2, 12 [28] Tao Jiang, Peng Lu, Li Zhang, Ningsheng Ma, Rui Han, Chengqi Lyu, Yining Li, and Kai Chen. Rtmpose: Realtime multi-person pose estimation based on mmpose. arXiv preprint arXiv:2303.07399, 2023. 7, 8, 20, 21 [29] Zhongyu Jiang, Zhuoran Zhou, Lei Li, Wenhao Chai, ChengYen Yang, and Jenq-Neng Hwang. Back to optimization: Diffusion-based zero-shot 3d human pose estimation. arXiv preprint arXiv:2307.03833, 2023. 12, [30] Angjoo Kanazawa, Michael Black, David Jacobs, and Jitendra Malik. End-to-end recovery of human shape and pose. In CVPR, 2018. 12 [31] Yueying Kao, Bowen Pan, Miao Xu, Jiangjing Lyu, Xiangyu Zhu, Yuanzhang Chang, Xiaobo Li, Zhen Lei, and Zixiong Qin. Single-image 3d face reconstruction under perspective projection. arXiv preprint arXiv:2205.04126, 2022. 5, 15, 17, 20, 21, 22, 32, 33 [32] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. NeurIPS, 2022. 2 [33] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration models. NeurIPS, 2022. 23 [34] Diederik Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013. 12, 18 [35] Taein Kwon, Bugra Tekin, Jan Stuhmer, Federica Bogo, and Marc Pollefeys. H2o: Two hands manipulating objects for In Proceedings of the first person interaction recognition. IEEE/CVF International Conference on Computer Vision, pages 1013810148, 2021. 5, [36] Tuomas Kynkaanniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall metric for assessing generative models. Advances in neural information processing systems, 32, 2019. 17 [37] Lijun Li, Lian Zhuo, Bang Zhang, Liefeng Bo, and Chen Chen. Diffhand: End-to-end hand mesh reconstruction via diffusion models. arXiv preprint arXiv:2305.13705, 2023. 12 [38] Tianye Li, Timo Bolkart, Michael Black, Hao Li, and Javier Romero. Learning model of facial shape and expression from 4d scans. ACM Trans. Graph., 36(6):1941, 2017. 4, 15, 16, 17 [39] Zhihao Li, Jianzhuang Liu, Zhensong Zhang, Songcen Xu, and Youliang Yan. Cliff: Carrying location information in full frames into human pose and shape estimation. In ECCV, 2022. 6, 26 [40] Hung Yu Ling, Fabio Zinno, George Cheng, and Michiel Van De Panne. Character controllers using motion vaes. TOG, 2020. 6, 12 [41] Haiyang Liu, Zihao Zhu, Giorgio Becherini, Yichen Peng, Mingyang Su, You Zhou, Xuefei Zhe, Naoya Iwamoto, Bo Zheng, and Michael Black. Emage: Towards unified holistic co-speech gesture generation via expressive masked audio In Proceedings of the IEEE/CVF Congesture modeling. ference on Computer Vision and Pattern Recognition, pages 11441154, 2024. 5, 7, 8, [42] Qiang Liu and Dilin Wang. Stein variational gradient descent: general purpose bayesian inference algorithm. NeurIPS, 2016. 24 [43] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael Black. Smpl: skinned multiperson linear model. ACM Transactions on Graphics, 34(6), 2015. 2, 3, 12, 16, 21 [44] Shunlin Lu, Ling-Hao Chen, Ailing Zeng, Jing Lin, Ruimao Zhang, Lei Zhang, and Heung-Yeung Shum. Humantomato: Text-aligned whole-body motion generation. arXiv preprint arXiv:2310.12978, 2023. 2 [45] Naureen Mahmood, Nima Ghorbani, Nikolaus Troje, Gerard Pons-Moll, and Michael Black. Amass: Archive of motion capture as surface shapes. In ICCV, 2019. 5, 6, 14, 16, 18, 19, 21, 23, 24 [46] Morteza Mardani, Jiaming Song, Jan Kautz, and Arash Vahdat. variational perspective on solving inverse problems with diffusion models. arXiv preprint arXiv:2305.04391, 2023. 2, 3, 4, 8, 14, 23, 24 [47] Gyeongsik Moon, Hongsuk Choi, and Kyoung Mu Lee. Accurate 3d hand pose estimation for whole-body 3d human In Proceedings of the IEEE/CVF Conmesh estimation. ference on Computer Vision and Pattern Recognition, pages 23082317, 2022. 19, 20, [48] Gyeongsik Moon, Shunsuke Saito, Weipeng Xu, Rohan Joshi, Julia Buffalini, Harley Bellan, Nicholas Rosen, Jesse Richardson, Mallorie Mize, Philippe De Bree, et al. dataset of relighted 3d interacting hands. Advances in Neural Information Processing Systems, 36, 2024. 5, 6, 15, 20, 21 [49] Lea Muller, Vickie Ye, Georgios Pavlakos, Michael Black, and Angjoo Kanazawa. Generative proxemics: prior arXiv preprint for 3d social arXiv:2306.09337, 2023. 12 interaction from images. [50] Naoki Murata, Koichi Saito, Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Yuki Mitsufuji, and Stefano Ermon. Gibbsddrm: partially collapsed gibbs sampler for solving blind inverse problems with denoising diffusion restoration. arXiv preprint arXiv:2301.12686, 2023. 23 [51] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and Michael Black. Expressive body capture: 3d hands, face, and body from single image. In CVPR, 2019. 1, 5, 6, 7, 12, 14, 16, 17, 18, 19, 20, 21, 22, 29 [67] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond Yeh, and Greg Shakhnarovich. Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation. In CVPR, 2023. 12, 13 [68] Jian Wang, Zhe Cao, Diogo Luvizon, Lingjie Liu, Kripasindhu Sarkar, Danhang Tang, Thabo Beeler, and Christian Theobalt. Egocentric whole-body motion capture with In Profisheyevit and diffusion-based motion refinement. ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 777787, 2024. 12 [69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation. arXiv preprint arXiv:2305.16213, 2023. 24 [70] Yufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao. ViTPose: Simple vision transformer baselines for human In Advances in Neural Information Propose estimation. cessing Systems, 2022. 24 [71] Siwei Zhang, Qianli Ma, Yan Zhang, Zhiyin Qian, Taein Kwon, Marc Pollefeys, Federica Bogo, and Siyu Tang. Egobody: Human body shape and motion of interacting people from head-mounted devices. In European conference on computer vision, pages 180200. Springer, 2022. 5, 16 [72] Siwei Zhang, Bharat Lal Bhatnagar, Yuanlu Xu, Alexander Winkler, Petr Kadlecek, Siyu Tang, and Federica Bogo. Rohm: Robust human motion reconstruction via diffusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1460614617, 2024. 12 [73] Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao Li. On the continuity of rotation representations in neural networks. In CVPR, 2019. [74] Joseph Zhu and Peiye Zhuang. Hifa: High-fidelity textarXiv preprint to-3d with advanced diffusion guidance. arXiv:2305.18766, 2023. 13 [75] Wojciech Zielonka, Timo Bolkart, and Justus Thies. Towards metrical reconstruction of human faces. In European conference on computer vision, pages 250269. Springer, 2022. 5, 7, 15, 17 [76] Christian Zimmermann, Duygu Ceylan, Jimei Yang, Bryan Russell, Max Argus, and Thomas Brox. Freihand: dataset for markerless capture of hand pose and shape from single rgb images. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 813822, 2019. 5, 14, 19, 21 [52] Ben Poole, Ajay Jain, Jonathan Barron, and Ben Mildenhall. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988, 2022. 8, 12, 13 [53] Abhinanda Punnakkal, Arjun Chandrasekaran, Nikos Athanasiou, Alejandra Quiros-Ramirez, and Michael Black. Babel: Bodies, action and behavior with english labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 722731, 2021. [54] Zhongwei Qiu, Qiansheng Yang, Jian Wang, Xiyu Wang, Chang Xu, Dongmei Fu, Kun Yao, Junyu Han, Errui Ding, and Jingdong Wang. Learning structure-guided diffusion arXiv preprint model for 2d human pose estimation. arXiv:2306.17074, 2023. 12 [55] Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar, and Leonidas Guibas. Humor: 3d human motion model for robust pose estimation. In ICCV, 2021. 6, 12, 21 [56] Javier Romero, Dimitrios Tzionas, and Michael Black. Embodied hands: Modeling and capturing hands and bodies together. arXiv preprint arXiv:2201.02610, 2022. 4, 15, 17 [57] Soubhik Sanyal, Timo Bolkart, Haiwen Feng, and Michael Black. Learning to regress 3d face shape and expression In Proceedings of from an image without 3d supervision. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 77637772, 2019. 7, 15, 20 [58] Yonatan Shafir, Guy Tevet, Roy Kapon, and Amit Bermano. Human motion diffusion as generative prior. arXiv preprint arXiv:2303.01418, 2023. 2 [59] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In ICML, 2015. [60] Jiaming Song, Chenlin Meng, Denoising diffusion implicit models. arXiv:2010.02502, 2020. 2, 4, 5, 6, 12, 21 and Stefano Ermon. arXiv preprint [61] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. NeurIPS, 2019. 2, 12 [62] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020. 1, 2, 6, 12, 23, 24 [63] Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of score-based diffusion models. NeurIPS, 2021. [64] Omid Taheri, Nima Ghorbani, Michael Black, and Dimitrios Tzionas. Grab: dataset of whole-body human grasping of objects. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part IV 16, pages 581600. Springer, 2020. 5, 16 [65] Garvita Tiwari, Dimitrije Antic, Jan Eric Lenssen, Nikolaos Sarafianos, Tony Tung, and Gerard Pons-Moll. Pose-ndf: Modeling human pose manifolds with neural distance fields. In ECCV, 2022. 1, 5, 6, 12, 14, 16, 17, 18, 19 [66] Pascal Vincent. connection between score matching and denoising autoencoders. Neural computation, 2011. 13 11 Supplementary Material: DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior This appendix provides comprehensive details to supplement our main work. Section presents an in-depth discussion of related studies. The parameterization of diffusion models and their connection to score functions are recapped in Section B, followed by the perspective of Score Distillation Sampling (SDS) to understand our DPoser regularization in Section C. Section examines the runtime and computational overhead introduced by DPoser, while Section explores testtime timestep scheduling across both pose and image domains. The datasets used for training and evaluation are detailed in Section F. Section covers detailed experimental setup including task-specific loss, evaluation metrics used in each task and implementation of comparative methods. Further evaluations of DPoser-X on additional tasks and datasets are provided in Section H. Section outlines the training process for DPoser, whereas Section discusses extended optimization techniques. Section outlines the methods limitations, presents failure cases, and suggests avenues for future research. Lastly, Section showcases additional qualitative results. A. Related Work A.1. Human Pose Priors Human body models like SMPL [43] and SMPL-X [51] serve as powerful tools for parameterizing both pose and shape, thereby offering comprehensive framework for describing human gestures. Within the SMPL model, body poses are represented using rotation matrices or joint angles linked to kinematic skeleton. Adjusting these parameters enables the representation of diverse human actions. Nonetheless, feeding unrealistic poses into these models can result in non-viable human figures, primarily because plausible human poses are confined within complex, highdimensional manifold due to biomechanical constraints. Various strategies [1, 12, 24, 51, 65] have been put forward to build human pose priors. Generative frameworks like GMMs, VAEs [34], and Generative Adversarial Networks (GANs) [21] have shown promise in encapsulating the multifaceted pose distribution, facilitating advancements in tasks like human mesh recovery [20, 30]. Further, some studies have delved into conditional pose priors tailored to specific tasks, incorporating extra information such as image features [4, 54], 2D joint coordinates [9], or se- * Equal contribution. Corresponding authors. quences of preceding poses [40, 55]. Our initiative leans towards an unconditional pose prior without relying on additional inputs like images or text, aiming for versatile application across various pose-related scenarios. A.2. Diffusion Models for Pose-centric Tasks Diffusion models [26, 6062] have emerged as powerful tools for capturing intricate data distributions, aligning well with the demands of multi-hypothesis estimation in ambiguous human poses. Notable works include DiffPose [27], which employs Graph Convolutional Network (GCN) architecture conditioned on 2D pose sequences for 3D pose estimation by learned reverse process (i.e., generation). Similarly, DiffusionPose [54] and GFPose [9] employ the generation-based pipeline but take different approaches in conditioning. Further, ZeDO [29] concentrates on 2D-to3D pose lifting, while Diff-HMR [4] and DiffHand [37] explore estimating SMPL parameters and hand mesh vertices, respectively. EgoWholeBody [68] and RoHM [72] focus on refining noisy motion sequences via diffusion-based generation. BUDDI [49] stands out for using diffusion models to capture the joint distribution of interacting individuals and leveraging SDS loss [52, 67] for optimization during testing phases. While DPoser shares similar optimization implementation with BUDDI, it sets itself apart by introducing wider perspective of inverse problems and equipping an innovative timestep scheduling strategy tailored to human poses. Unlike other approaches [9, 27, 29, 54] that primarily focus on 3D location-based representation, DPoser takes on the more demanding task of modeling SMPL-based rotation pose representation. Furthermore, DPoser-X improves whole-body modeling with detailed hand and facial expressions, making it versatile choice for pose-centric tasks. B. Parameterization of Score-based Diffusion"
        },
        {
            "title": "Models",
            "content": "In the seminal work by Song et al. [62], it is demonstrated that both score-based generative models [61] and diffusion probabilistic models [26] can be interpreted as discretized versions of stochastic differential equations (SDEs) defined by score functions. This unification allows the training objective to be interpreted either as learning time-dependent denoiser or as learning sequence of score functions that describe increasingly noisy versions of the data. We begin by revisiting the training objective for scorebased models [61] to elucidate the link with diffusion mod12 els [26]. Consider the transition kernel of the forward diffusion process p0t(xtx0) = (xt; αtx0, σ2 I). Our goal is to learn score functions xt log pt(xt) through neural network sθ(xt; t), by minimizing the L2 loss as follows (we omit the expectation operator for conciseness) : (cid:2)w(t)sθ(xt; t) xt log pt (xt) 2 (12) (cid:3) . 2 Here, xt = αtx0 + σtϵ, where ϵ (0, I). Based on denoising score matching [66], we know the minimizing objective Eq. (12) is equivalent to the following tractable term: (cid:2)w(t)sθ(xt; t) xt log p0t(xtx0)2 2 (cid:3) . (13) To link this with the noise predictor ϵθ(xt; t) in diffusion models, we can employ the reparameterization sθ(xt; t) = ϵθ(xt;t) σt . Then, Eq. (13) can be simplified as follows: w(t) =w(t) =w(t) ϵθ(xt; t) σt ϵθ(xt; t) σt ϵθ(xt; t) σt xt log p0t(xt x0)2 2 + + (xt αtx0) σ2 2 σtϵ σ2 )2 2 = w(t) σ2 ϵθ(xt; t) ϵ)2 2 (14) The resulting form of Eq. (14) aligns precisely with the noise prediction form of diffusion models [26] (refer to Eq. (4) in the main text). This implies that by training ϵθ(xt; t) in diffusion model context, we simultaneously get handle on the score function, approximated as xt log pt(xt) ϵθ(xt;t) . σt C. View DPoser as Score Distillation Sampling Interestingly, the gradient of DPoser (Eq. (10) in the main text) coincides with Score Distillation Sampling (SDS) [52, 67], which can be interpreted as aiming to minimize the following KL divergence: (15) (xt; θ) (cid:1), KL(cid:0)p0t (xt x0) pSDE where pSDE (xt; θ) denote the marginal distribution whose score function is estimated by ϵθ(xt; t). For the specific case where 0, this term encourages the Dirac distribution δ(x0) (i.e., the optimized variable) to gravitate toward the learned data distribution pSDE (x0; θ), while the Gaussian perturbation like Eq. (15) softens the constraint. Building on this understanding, we can borrow advanced techniques from SDSa rapidly evolving area ripe for methodological innovations [11]. To extend this, we experiment with multi-step denoising strategy adapted from HiFA [74], substituting our original one-step denoising process. This alternative, however, yields suboptimal results across most evaluation metrics, as demonstrated in Table S0 Figure S-1. Visualization of the impact of different timestep values in DPoser regularization. larger effectively corrects undesirable poses but may excessively alter well-posed inputs, resulting in plausible yet unrelated poses. Conversely, smaller better preserves the original pose but struggles to correct implausible ones. 1. plausible explanation could be that our proposed truncated timestep scheduling effectively manages low noise levels (i.e., small t), thus negating the need for more denoising steps. In our main experiments, we keep the efficient one-step denoiser. D. Runtime Comparison Diffusion models generally require iterative steps for gradual denoising, making them less efficient than VAEs and GANs in generation tasks. However, when applied to downstream optimization processes, DPoser introduces minimal additional computational overhead. This is due to two key factors: (1) DPoser regularization involves only singlestep denoising at each optimization step, and (2) the stopgradient operator ensures that the regularization does not require backpropagation through the trained network. To assess DPosers efficiency, we benchmarked its runtime against various prior models (including baseline without pose prior) for human mesh recovery across 100 images in consistent execution environment. As shown in Table S-2, incorporating DPoser results in only modest (10%) increase in optimization runtime compared to the baseline. In contrast, GAN-S [12] incurs significant computational cost due to its required GAN-inversion phase, which converts initial poses into their latent representations. E. Analysis of Test-time Timestep Scheduling During optimization, the selection of timestep is crucial for downstream tasks. As discussed in Section 2.4, the key information of pose data emerges at small values (t 0.3), which serves as coarse range. Moreover, the L2 loss format of our DPoser regularization gives an intuitive view of the impact of timestep. As shown in Fig. S-1, while is small, since the adding noise and denoising path is short, the denoised pose is close to the origin and the DPoser guidance is weak. Specifically, considering the extreme case where 0, in ˆx0(t) = xtσtϵϕ(xt;t) , the coefficient σt 0 while αt 1, causing ˆx0(t) to approach x0, which leads αt"
        },
        {
            "title": "Strategy",
            "content": "1 step 5 step 10 step Whole-body Mesh Recovery"
        },
        {
            "title": "Motion Denoising",
            "content": "PA-MPVPE (all) PA-MPVPE (hands) MPVPE APD MPVPE MPJPE 60.98 61.39 61.52 15.60 15.70 15. 38.79/78.31/27.13 40.15/85.01/31.96 41.04/87.36/32.51 6.53 7.72 8.07 38.21 40.22 40.69 19.87 21.21 21.34 Table S-1. Ablation of different denoising steps in DPosers optimization. w/o prior GMM [1] VPoser [51] Pose-NDF [65] GAN-S [12] DPoser 15.64 16.14 16.83 21.88 74.60 17. Table S-2. Runtime comparison (in seconds) of different prior models for human mesh recovery on 100 images, evaluated using an RTX 3090Ti GPU."
        },
        {
            "title": "Noise std",
            "content": "[0.15, 0.05] [0.2, 0.05] [0.2, 0.1] [0.25, 0.1] 40 mm 100 mm 19.83 36. 19.87 34.15 21.68 33.18 22.14 33.83 Table S-3. Ablation of timestep range for motion denoising on the AMASS dataset [45]. MPJPE is reported as the metric. to near-zero DPoser loss. On the contrary, suitably large means strong DPoser guidance and can correct implausible poses better. Thus, we tailor [tmax, tmin] intervals to specific tasks based on their noise scales. To verify this, we conduct ablation of the timestep range on motion denoising. As evidenced in Table S-3, to achieve the best performance, larger values are required for noisier inputs. Based on the above analyses, we select task-specific timestep intervals [tmax, tmin] as follows: [0.2, 0.05] for motion denoising (40 mm noise), [0.15, 0.05] for pose completion and inverse kinematics, and [0.12, 0.08] for mesh recovery. All the experiments, including body-only, hand-only, face-only, and whole-body, share the same timestep hyperparameters without more tuning. It is also noteworthy that our truncated timestep scheduling is designed for human poses and does not work well on images. In image domains, the initial timesteps play crucial role in generating foundational perceptual content. In our study, we employed 256x256 unconditional diffusion model [14] trained on ImageNet [13] with variational diffusion sampling [46] for image inpainting. This model employs 1000 discrete timesteps during training. We compared standard scheduling (timesteps 990 to 0) with truncated scheduling (timesteps 495 to 0), both using 100 steps. The results, shown in Fig. S-2, indicate that truncation negatively affects image quality. While the standard approach preserved perceptual content, the truncated method produced disjointed patches that were misaligned with the original context. These results affirm that truncated timestep scheduling excels in pose data where key information emerges in later stages but falls short in image tasks where early timesteps are essential. This scheduling is thus bespoke to the characteristics of human poses and is unsuitable for image processes that rely on the full diffusion timeline for content fidelity. F. Dataset Description This section provides detailed overview of the datasets used in our experiments, categorized based on the body part they focus on. We describe each datasets specific use case along with the number of samples available for each dataset. F.1. Body-only Dataset AMASS The AMASS dataset [45] is large-scale collection of high-quality 3D human body meshes derived from multiple motion capture sources. It provides motion sequences and human poses in SMPL-based format, covering broad range of activities such as walking, sitting, dancing, and running. Following the same splits as VPoser [51], and after sampling to de-duplicate the data, we use approximately 55 million body poses in the SMPL-X [51] format to train our DPoser-body model. The test split consists of 54,000 body poses, which are used to evaluate model performance on tasks including body pose completion and motion denoising. HPS The HPS dataset [22] contains over 300K synchronized RGB images, paired with reference 3D poses and locations, captured from seven people interacting with largescale 3D scenes. The dataset includes motion sequences of various activities such as exercising, reading, eating, lecturing, using computer, making coffee, and dancing. Following Pose-NDF [65], we use the HPS dataset to evaluate the motion denoising task without training on it. After sampling, we got 350 sequences, each consisting of 60 frames for testing. F.2. Hand-only Dataset FreiHAND FreiHAND [76] is large-scale dataset for 3D hand pose estimation, focusing on single-hand poses. It includes 130,240 training samples (432560) and 3,960 evaluation samples. Each training hand pose is accompanied by 4 RGB images, providing diverse data for training ro14 Figure S-2. Image inpainting using standard and truncated timestep scheduling. The process evolution is shown over iterations with the middle row depicting the log-magnitude spectrum and the bottom row the phase spectrum. (a) The standard scheduling exhibits cohesive restoration with detail fidelity. (b) The truncated scheduling results in detail-rich patches that are perceptually incongruent with the original image context. bust models. We use 32,560 hand poses, represented in the MANO format [56], for training the DPoser-hand model. The remaining 3,960 evaluation samples are used to assess hand mesh recovery performance during testing. DexYCB DexYCB [3] is dataset for capturing 3D hand poses during hand-object interactions, focusing on singlehand poses. We use only the hand poses for training the DPoser-hand model. The training set includes 407,000 single hand poses. HO3D HO3D [23] is dataset that provides 3D annotations for both hand poses and object interactions. Similar to DexYCB, we utilize the hand poses for training the DPoserhand model. The training set contains 83,000 hand poses. H2O The H2O dataset [35] provides 3D pose annotations for two-hand and object interactions. For the purpose of training DPoser-hand, we use only the right-hand poses. The training set contains 58,000 hand poses. ReInterHand ReInterHand [48] is high-quality synthetic dataset designed for 3D hand pose estimation, specifically focusing on interacting hands. It includes annotations for both hands. For training DPoser-hand, we flip the left-hand pose as right-hand to unify the format. The dataset is split into training, validation, and test sets with an 8:1:1 ratio. We use approximately 186,000 hand poses for training, and 23,000 poses for testing. The test set is used to evaluate hand inverse kinematics tasks. F.3. Face-only Dataset MICA The MICA dataset [75] consists of eight smaller datasets that were unified to represent about 2315 subjects using the FLAME [38] model. It contains only shape geometry. We use the MICA dataset to train the shape component of DPoser-face, focusing on high-quality 3D face shapes. WCPA WCPA [31] is large-scale dataset focusing on 3D face reconstruction under perspective projection. It contains 200 subjects and 356,640 training instances, with detailed annotations for facial expressions. We use WCPA to train the expression component of DPoser-face, with 1/10 of the dataset reserved for testing. The test set is used to evaluate face reconstruction, considering both shape and expressions. NOW NOW [57] is widely-used benchmark for face reconstruction. It introduces standard evaluation metrics for assessing the accuracy and robustness of 3D face reconstruction methods, especially under variations in viewing angle, lighting, and occlusions. The validation set containing 352 images is employed for our face reconstruction task. We focus on the non-metrical evaluation of face shape, as 15 the ground truth (GT) only includes shape. As in previous works such as DECA [18], expressions are set to zero in the FLAME [38] model to obtain neutral face mesh for final evaluation. F.4. Whole-body Dataset BEAT2 BEAT2 [41] is holistic co-speech dataset that combines the MoShed SMPL-X [51] body with FLAME It refines the modeling of head, neck, head parameters. and finger movements, providing high-quality 3D motioncaptured data. After de-duplication, we have 1.48 million whole-body poses for training DPoser-X, and the test set contains 172,000 whole-body poses used for whole-body pose completion. GRAB GRAB [64] is dataset containing full 3D shape and pose sequences of 10 subjects interacting with 51 everyday objects of varying shapes and sizes. We use this dataset for training DPoser-X, with 391,000 whole-body poses. The data helps train the model for whole-body mesh recovery during grasping actions. ARCTIC ARCTIC [16] is dataset focused on two-hand object manipulation, with 2.1 million video frames paired with 3D hand and object meshes. After de-duplication, we have 77,000 whole-body poses for training DPoser-X. The validation set, which contains 10,000 whole-body poses, is used for testing whole-body mesh recovery and pose completion. Note that the face expressions are not annotated, so we set models output expressions as zeros for evaluation. Face-related metrics in whole-body mesh recovery are only influenced by the human shape. EgoBody EgoBody [71] is large-scale dataset that captures 3D human motions during social interactions in 3D scenes. It provides SMPL-X [51] annotations for 3D wholebody pose, shape, and motion for both the interactee and the camera wearer. The training set contains 38,896 instances of whole-body poses (x2 for each subject), and the test set contains 24,665 instances. The test set is used for the whole-body pose completion task. Fit3D Fit3D [19] is dataset with over 3 million images and corresponding 3D human shape and motion capture ground truth data, covering 37 exercises performed by instructors and trainees. We take the subject s04 which consists of 612 images after sampling, for whole-body mesh recovery tasks to test DPoser-Xs generalization, without training the model on this dataset. EHF EHF [51] is curated dataset comprising 100 images with pseudo whole-body poses. Following Pose-NDF [65], we use this dataset to evaluate body mesh recovery performance, specifically calculating PA-MPJPE for body joints. G. Experimental Details In this section, we provide detailed descriptions of the experimental setups and specific loss functions for various tasks. These tasks include pose completion, motion denoising, inverse kinematics, face reconstruction, hand mesh recovery, and whole-body mesh recovery. In addition, we explain the evaluation metrics used in each task and implementation details of comparative methods. G.1. Pose Completion For partial observations y, the measurement operator is modeled as known mask matrix Rdn. Based on our optimization framework denoted in Alg. 1, we define the task-specific loss, Lcomp, as follows: Lcomp = x0 y2 2. Here, x0 denotes the complete body pose θ we try to recover, where the unseen parts are initialized as random noise. In the following ablated studies, if not specified, the evaluation of the body pose completion is performed using 10 hypotheses on the AMASS dataset [45] with left leg occlusion. (16) G.2. Motion Denoising (Noisy Input) Adhering to Pose-NDF settings [65], we aim to refine noisy joint positions obs over frames to obtain clean poses θt, initialized from mean poses in SMPL with small noise. We formulate the task-specific loss combining an observation fidelity term Lobs and temporal consistency term Ltemp: Lobs = 1 (cid:88) t=0 MJ (θt, β0) obs2 2, (17) Ltemp = 1 (cid:88) t=1 MJ (θt1, β0) MJ (θt, β0)2 2, (18) where MJ denotes the 3D joint positions regressed from SMPL [43] and β0 is the constant mean shape parameters. G.3. Motion Denoising (Partial Input) This task focuses on reconstructing clean poses, θt, from partially observed joint positions, obs, across frames, employing known mask matrix to identify visible joints. The optimization objective mirrors that of motion denoising (Section G.2), but incorporates mask in Eq. (17) to specifically target visible parts, ensuring that only these segments guide the recovery process. G.4. Inverse Kinematics Inverse kinematics (IK) aims to estimate clean poses from noisy or partially observed 3D joint positions, similar to the motion denoising task. The key difference in the implementation is that the inputs are single-frame data, meaning the temporal consistency term Ltemp is not required. For inverse kinematics applied to hand poses, we optimize only the hand poses while keeping the hand shape parameters fixed. This simplifies the optimization, focusing solely on pose adjustments. For the face, we optimize both the face expression and shape parameters, as face-related tasks require accurate modeling of both shape and dynamic expressions. In all cases, we employ similar optimization framework as in the motion denoising task, using only the fidelity loss for observed 3D joints. G.5. Face Reconstruction Reconstructing human faces using only 2D keypoints is challenging and typically insufficient for high-quality reconstructions. To address this, we utilize the photometric optimization approach described in [17] to fit textured FLAME model [38]. The optimization aims to refine the face shape and expression parameters, as well as adjust the appearance and lighting parameters for the face rendering. We use combination of two key loss functions: the photometric loss (L1-loss between rendered and target images) and the reprojection loss (for 2D face keypoints). We observe that face shape plays crucial role in tasks like face reconstruction. To this end, DPoser-face is designed to separately model face shape and expression. Given that these two components (shape and expression) are largely independent, we train the face shape and expression models separately using the WCPA [31] and MICA [75] datasets, respectively. For face-only tasks such as face reconstruction, DPoser regularization is applied to both the face shape and expression models. It is important to note that only the expression component of DPoser-face contributes to the broader DPoser-X framework, with the shape component being reserved for face-specific tasks. For fair comparison, we implement the same strategy for training the VPoser-face model. G.6. Hand Mesh Recovery For hand mesh recovery, we optimize the hand poses using the MANO model [56] instead of the SMPL model. Similar to the body mesh recovery task, we employ reprojection loss based on 2D hand keypoints. In addition to using our DPoser loss for plausible hand poses, we also employ the L2 prior for hand shape, similar to Eq. (11) in the main text, to maintain natural hand geometry. G.7. Whole-body Mesh Recovery Whole-body mesh recovery shares similarities with body mesh recovery (as discussed in Section 2.5) but additionally incorporates the face and hands into the optimization. The goal is to recover the whole-body poses θ (including body, hands, and face) and shape parameters β by optimizing reprojection loss based on whole-body 2D keypoints. distinguishing feature is the inclusion of two root-relative reprojection losses, one for the hands and another for the face, to refine local poses. Specifically, the wrists for hands and the mouth for the face are chosen as the root, and the root coordinates are subtracted before calculating the reprojection losses. This ensures that the hand and face poses are localized relative to the body, improving the accuracy of hand and facial mesh recovery. G.8. Evaluation Metrics For comprehensive assessment across various tasks, following recent works like NRDF [24] and SMPLer-X [2], we adopt task-specific metrics: Pose Generation: Diversity and fidelity are evaluated using Average Pairwise Distance (APD) and dN [24], respectively. dN measures the distance between the generated pose and its nearest neighbor from the training data. We also report the common metrics for generative models, including FID [25] (distribution similarity), Precision [36] (fidelity), and Recall [36] (diversity). Human Mesh Recovery: Procrustes-aligned Mean Per- (PA-MPJPE) and ProcrustesVertex Position Error aligned Mean Per-Joint Position Error (PA-MPVPE) measures the accuracy of recovered human meshes. Multi-hypothesis Pose Completion: MPVPE and APD on masked parts across multiple hypotheses measure solution accuracy and diversity, respectively. Motion Denoising & Inverse Kinematics: Both MPJPE and MPVPE are calculated to assess the performance. All errors are reported in millimeter units. G.9. Implementation of Comparative Methods In pose generation experiments, we employ standard including sampling techniques for generative models, GMM [1], VPoser (VAE) [51], and GAN-S (GAN) [12]. For Pose-NDF [65] and NRDF [24], we reproduce their projection algorithms using their official repositories. For other tasks during testing, to ensure fair comparison, we implement all pose priors within the same optimization frameworkusing identical task-specific loss functions and optimization iterationswhile tuning hyperparameters such as loss weights for each method. VPoser and GAN-S function as pose priors due to their learned meaningful latent representations. We optimize the pose latents for both methods. Given VPosers Gaussian assumption, it naturally incorporates L2 regularization on the latent pose [51]. However, we observe that applying spherical loss to the latents of GAN-S [12] degrades human mesh recovery performance. Therefore, we use only GAN-Ss generator for decoding without imposing additional constraints on the pose latents. Both NDF [65] and NRDF [24] directly optimize pose rotation representations by minimizing the predicted distance between the current pose and their learned plausible pose fields. We implement these methods using their official code and model weights. Since GAN-S does not provide pre-trained models, we train it from scratch on the same datasets as our DPoser. Addi-"
        },
        {
            "title": "Methods",
            "content": "hypotheses num=1 hypotheses num=10 GFPose [9] HuProSO3 [15] DPoser (ours) 68.64/89.88 72.00/104.52 56.05/79.82 62.80/83.39 57.42/84.21 53.28/76.53 Table S-4. Comparison with generation-based methods on the HMR task using the EHF dataset [51]. We report the minimum PA-MPJPE/MPJPE across multiple hypotheses. tionally, for hand, face, and whole-body models, we train the comparative methods ourselves. H. Additional Experiments In this section, we present series of additional experiments that further demonstrate the efficacy of DPoser-X across various tasks. These experiments cover body mesh recovery, body pose completion, motion denoising, hand/face generation, hand/face inverse kinematics, face reconstruction, and whole-body mesh recovery, with focus on different input types and datasets. H.1. Body Mesh recovery In addition to the priors compared in the main text, we evaluate DPoser against two recent state-of-the-art, generationbased methods: GFPose [9] and HuProSO3 [15]. Unlike optimization-based priors, these methods are designed to produce multiple, diverse hypotheses for given input."
        },
        {
            "title": "We report",
            "content": "the results for the Human Mesh Recovery (HMR) task on the EHF dataset [51] in Table S4. The comparison is conducted with both single hypothesis (hypotheses num=1) and multiple hypotheses (hypotheses num=10), reporting the minimum PA-MPJPE and MPJPE. The results clearly show that while GFPose and HuProSO3 can generate diverse potential poses, our DPoser achieves significantly higher accuracy (i.e., lower error) in both evaluation settings. This suggests that DPoser provides more precise and reliable pose prior for this task. H.2. Body Pose Completion In practical scenarios, HMR algorithms often grapple with occlusions leading to incomplete 3D pose estimates. In this context, the task is to recover full 3D poses from partially observed data, initializing the occluded parts with noise. Our DPoser model is employed to refine these initially implausible poses into feasible ones, utilizing an L2 loss on the visible parts to ensure data consistency. In parallel, we employ comparable optimization strategy for both PoseNDF [65] and VPoser [51]. As task-specific baseline, we adapt the original VPoser model into CVPoser by incorporating conditional inputs within its VAE framework [34] for end-to-end training and conditional sampling. The completion experiment is conducted on the AMASS dataset [45] with occlusion of various body parts. Given the uncertainties in this task, we generate multiple hypotheses and evaluate them using minimum, mean, and standard deviation errors against the ground truth. We calculate APD across solutions to assess diversity. As illustrated in Table S-5, DPoser exhibits superior performance across different occlusion scenarios compared to existing pose priors and even the task-specific CVPoser, highlighting its effectiveness in pose completion. The qualitative evaluations are presented in Fig. S-3. Here, we observe that DPoser can generate multitude of plausible poses, capability lacking in VPoser [51]. Pose-NDF [65], meanwhile, struggles with generalizing to unseen noisy poses and making plausible adjustments from the mean pose initialization. H.3. Motion Denoising (Noisy Input) To further evaluate DPosers performance in motion denoising, we extend our analysis to scenarios with varying noise levels. In complement to the results presented in Table 3 of our main text, we conduct an in-depth examination that spans broader range of noise conditions. The extended results, detailed in Table S-6, showcase DPosers exceptional performance against state-of-the-art (SOTA) pose priors, especially under high noise conditions, manifesting DPosers resilience to noise. H.4. Motion Denoising (Partial Input) We next assess the performance of our model in scenarios involving partial input using the AMASS dataset [45]. Two types of occlusions were considered: legs and left arm. The quantitative results of these experiments are presented in Table S-7, while visual examples can be found in Section L. Errors (in cm) are evaluated in terms of MPJPE across visible (Vis.), occluded (Occ.), and all joints, along with MPVPE for all vertices. In the leg occlusion scenario, where the AMASS dataset primarily consists of straight poses, the lack of diversity allows for reasonable results even without incorporating pose prior. In this case, the optimization starts from an initial point that closely matches these common poses. However, while VPosers mean-centered approach struggles to faithfully replicate visible areas, DPoser accurately handles the visible portions and guides the reconstruction of ocIn contrast, cluded parts, yielding more realistic results. Pose-NDF does not effectively enhance the occluded regions. For left arm occlusions, which involve more varied movements, DPoser markedly surpasses other methods, underlining its adaptability and precision in handling diverse motion patterns. H.5. Hand Pose Generation We evaluate the generated hand poses based on their diversity and realism. As shown in Table S-8, DPoser produces strong combination of both, outperforming methMethods Occ. left leg Occ. legs Occ. arms Occ. torso MPVPE APD MPVPE APD MPVPE APD MPVPE APD Pose-NDF [65] (S = 1) Pose-NDF (S = 5) Pose-NDF (S = 10) VPoser [51] (S = 1) VPoser (S = 5) VPoser (S = 10) CVPoser (S = 10) DPoser (S = 1) DPoser (S = 5) DPoser (S = 10) 168.61 157.62/168.49/7.94 154.21/168.45/8.66 200.23 187.38/200.73/10.52 182.31/200.51/12.20 113.48/128.04/10.36 78.78 46.23/78.13/24.96 38.79/78.31/27.13 NAN 1.95 1.95 NAN 2.38 2.41 1. NAN 6.58 6.53 169.92 162.30/169.94/5.54 159.75/169.86/6.12 221.21 201.70/221.16/14.57 195.76/221.34/16.40 121.00/134.35/10.17 103.12 72.37/102.73/23.05 63.65/102.46/25.39 NAN 1.96 1.97 NAN 5.49 5.44 2.43 NAN 7.72 7.75 261.11 254.97/261.01/4.38 252.90/260.94/4.81 206.83 191.27/206.55/11.54 186.55/206.72/12.91 153.12/162.82/5. 104.59 74.32/105.70/24.15 64.72/104.94/26.44 NAN 1.22 1.20 NAN 4.06 4.08 1.08 NAN 5.67 5.69 115.03 108.07/114.98/4.98 105.87/114.97/5.43 58.66 49.88/58.67/6.71 47.31/58.71/7.38 45.16/51.23/4.32 44.60 27.47/44.63/13.26 22.63/44.60/14.65 NAN 0.93 0.93 NAN 1.59 1.56 0. NAN 2.19 2.21 Table S-5. Performance metrics (min/mean/std of MPVPE and APD) for body pose completion on the AMASS dataset [45] under varying occlusion scenarios. denotes the number of hypotheses. Task-specific baseline trained with partial poses as conditional input. Figure S-3. Visual comparisons of body pose completion. Three hypotheses are drawn for each method. DPoser uniquely offers multiple plausible solutions for partial poses, scenario where competitors often struggle due to limited generalization."
        },
        {
            "title": "Methods",
            "content": "AMASS [45] HPS [22] 20mm 100mm 20mm 100mm w/o prior VPoser [51] Pose-NDF [65] DPoser 15.33 15.20 13.84 13.64 51.48 49.10 46.10 33. 16.26 17.24 15.62 13.45 50.87 46.69 47.50 35.32 Table S-6. Performance comparison of motion denoising under varying noise scales. MPJPE is reported afters denoising."
        },
        {
            "title": "Occlusion",
            "content": "w/o prior VPoser [51] Pose-NDF [65] DPoser w/o prior VPoser [51] Pose-NDF [65] DPoser legs legs legs legs left arm left arm left arm left arm"
        },
        {
            "title": "MPVPE",
            "content": "Vis. 0.26 1.75 0.25 0.28 0.26 1.21 0.25 0.27 Occ."
        },
        {
            "title": "All",
            "content": "14.72 14.29 15.71 12.24 24.87 13.23 17.70 7.80 5.52 6.31 5.87 4.63 4.74 3.40 3.42 1."
        },
        {
            "title": "All",
            "content": "5.45 7.38 5.64 3.65 9.91 7.68 7.86 3.81 ods like VPoser [51] and NRDF [24]. Specifically, NRDF shows poor realism, reflected in high FID and dN scores. VPoser, while achieving moderate precision, suffers from limited diversity, as indicated by its low APD. See Fig. S12 visualization comparison. H.6. Hand Mesh Recovery To evaluate DPosers ability to recover hand meshes, we test its performance on the FreiHAND dataset [76] unTable S-7. Comparative analysis of methods for motion denoising with different occlusions (legs or left arm) on the AMASS dataset [45]. der two initialization strategies: mean poses and the Hand4Whole [47] prediction poses. The results, detailed in Table S-9 and visually represented in Section (Fig. S-15 and Fig. S-14), show DPosers superior performance across various metrics and initialization settings."
        },
        {
            "title": "Methods",
            "content": "APD FID Prec. Rec. dN H.9. Face Reconstruction VPoser [51] NRDF [24] DPoser-hand 1.99 1.76 2.36 0.21 5.20 0.01 0.68 0.17 0. 0.65 0.65 0.87 1.85 5.37 1.45 Table S-8. Quantitative evaluation of hand pose generation. DPoser consistently outperforms competing methods, such as VPoser [51] and NRDF [24], achieving the lowest PA-MPJPE and PA-MPVPE values. For example, when using keypoints detected by RTMPose [28], DPoser reduces PA-MPJPE by 20% compared to VPoser. Morethe performance is further enhanced when using over, Hand4Whole [47] initialization, highlighting DPosers ability to refine results from existing SOTA mesh recovery models. In contrast, methods like the L2 prior and VPoser, which rely on mean-centered priors, fail to match the quality of the initializations, producing poorer results. Additionally, DPoser demonstrates significant advantages over NRDF in modeling hand pose distributions, offering more reliable guidance in mesh recovery. By leveraging ground truth (GT) keypoints, DPoser consistently recovers natural hand meshes that align well with observed 2D keypoints. H.7. Hand Inverse Kinematics (Noisy Input) For hand inverse kinematics, we extend our experiments to noisy settings using the ReInterHand dataset [48]. Table S10 shows that DPoser consistently outperforms alternative methods across different noise levels (2mm, 5mm, 10mm), achieving the lowest MPVPE and MPJPE. While methods like the L2 prior and VPoser [51] perform competitively at lower noise levels, their accuracy deteriorates significantly as noise increases. In contrast, DPoser maintains both stability and precision, showcasing its superior ability to handle noisy input and recover plausible hand poses even under challenging conditions. H.8. Face Generation We conduct the face generation experiments for the shape and expression separately since they are uncorrelated attrbutes. As detailed in Table S-11, DPoser outperforms VPoser [51] in terms of FID, achieving values of 5.331 for shape and 0.156 for expression, which highlights DPosers superior ability to model the distribution of face shapes and expressions. While VPoser achieves higher precision scores, its recall values are considerably lower, indicating lack of variability in the generated samples. This observation is further corroborated by qualitative results shown in Fig. S-4, which demonstrate DPosers ability to generate wide variety of realistic face shapes and expressions. Compared to VPoser, DPoser captures broader range of subtle variations, especially in expressions, while maintaining fidelity. For face reconstruction, along with the NOW beachmark [57], we test on the WCPA [31] dataset, which evaluates both face shape and expression. As shown in Table S-12, DPoser consistently outperforms other methods. It achieves the lowest PA-MPVPE and PA-MPJPE errors across all configurations, with notable reduction in errors for both overall and side-view cases. When combined with EMOCA [10] initialization, DPoser further refines the reconstruction quality, reducing the mean PA-MPVPE error to 3.10 mmm compared to 3.58 mm for EMOCA alone. Qualitative visualizations in Fig. S-17 illustrate DPosers ability to reconstruct detailed and realistic face meshes, even in challenging scenarios involving variations in sideview poses and complex expressions. While other methods often struggle to generalize across such cases, DPoser remains robust and highly accurate, demonstrating its capability to handle the full diversity of facial shapes and expressions in real-world conditions. H.10. Face Inverse Kinematics To evaluate DPosers robustness in face inverse kinematics, we conduct experiments under various noise levels and occlusion scenarios using the WCPA dataset [31]. The results in Table S-13 demonstrate that DPoser consistently achieves the lowest MPVPE and MPJPE errors across all tested conditions. Notably, DPoser retains its strong performance even under extreme noise conditions, whereas VPoser [51] experiences significant degradation as noise levels increase. Qualitative results, visualized in Fig. S-16, further confirm DPosers ability to reconstruct realistic and aligned facial details under noisy and occluded conditions. H.11. Whole-body Mesh Recovery We extend our evaluation of whole-body mesh recovery to include the Fit3D dataset [19], in addition to the comparative results on ARCTIC [16]. For this evaluation, we compare DPoser-X with VPoser-X [51] and the GMM baseline, which utilizes Gaussian Mixture Model (GMM) [1] for body poses and an L2 prior for hands and face. As shown in Table S-14, DPoser-X outperforms both VPoser-X [51] and GMM [1] across most metrics, for both hands and the entire body. However, we observe that the L2-prior baseline performs better than DPoser-X in terms of PA-MPVPE on the face. We attribute this result to the low-resolution images in the Fit3D dataset, where the face is depicted with limited pixel density and the 2D keypoints are less expressive. In this case, the neutral face produced by the L2 prior is more likely to yield better results due to the lack of detailed facial features in the input. Nonetheless, DPoser-X still outperforms other methods in handling the full-body mesh recovery, showing its robustness in both body and hand mesh reconstruction."
        },
        {
            "title": "Methods",
            "content": "PA-MPJPE PA-MPVPE F@5 F@15 w/o prior L2 prior VPoser [51] NRDF [24] DPoser-hand hand4whole + w/o prior + L2 prior + VPoser [51] + NRDF [24] + DPoser-hand 17.71/16.12 12.87/11.49 12.31/10.62 13.19/11.04 10.71/8.68 8.50 9.13/6.04 9.91/7.16 9.13/6.42 9.00/6.15 7.96/5.36 18.40/17.04 12.71/11.59 12.23/10.91 13.39/11.59 10.48/8.70 7.81 8.97/6.06 9.69/7.11 9.04/6.55 8.99/6.29 7.69/5.20 0.396/0.446 0.512/0.533 0.524/0.609 0.469/0.554 0.574/0.679 0.651 0.609/0.749 0.568/0.686 0.605/0.717 0.595/0.726 0.663/0. 0.875/0.895 0.924/0.927 0.931/0.943 0.914/0.937 0.947/0.963 0.97 0.965/0.985 0.953/0.974 0.964/0.981 0.964/0.983 0.973/0.990 Table S-9. Performance evaluation of hand mesh recovery on the FreiHAND dataset [76]. Results are reported using 2D keypoints detected by RTMPose [28] / ground truth."
        },
        {
            "title": "Methods",
            "content": "No prior L2 prior VPoser [51] NRDF [24] DPoser-hand 2mm 5mm 10mm MPVPE MPJPE MPVPE MPJPE MPVPE MPJPE 3.95 2.10 2.47 2.67 1. 1.50 1.43 1.36 1.40 1.17 5.82 4.06 4.15 4.57 3.30 3.46 2.92 2.85 3.11 2.39 8.62 6.06 6.32 7.18 5.39 5.97 4.27 4.40 5.06 3.87 Table S-10. Performance of hand inverse kinematics on the ReInterHand dataset [48] under noisy settings."
        },
        {
            "title": "Methods",
            "content": "FID Prec. Rec. dN I. Ablated DPosers Training VPoser [51] (shape) DPoser-face (shape) VPoser [51] (expression) DPoser-face (expression) 31.91 5.331 0.888 0.156 0.984 0.689 0.993 0.818 0.105 0.396 0.019 0. 6.52 8.29 0.79 1.01 Table S-11. Quantitative evaluation for face generation."
        },
        {
            "title": "Methods",
            "content": "all side-view w/o prior L2 prior VPoser [51] DPoser-face EMOCA [10] + w/o prior + L2 prior + VPoser [51] + DPoser-face 3.67/4.19 3.56/3.90 3.59/4.01 3.34/3.65 3.58/4.07 3.49/3.88 3.49/3.82 3.39/3.65 3.10/3. 3.77/4.46 3.58/4.01 3.62/4.13 3.32/3.61 3.78/4.43 3.92/4.56 3.68/4.28 3.56/4.05 3.16/3.72 Table S-12. Face reconstruction performance (PA-MPVPE/PAMPJPE) on the WCPA dataset [31]. This section dissects the impact of different rotation representations and normalization techniques on DPosers performance. The ablation of training experiments is conducted for the DPoser-body model trained on AMASS [45]. Initially, we examine axis-angle representation, comparing various normalization strategies: min-max scaling, z-score normalization, and no normalization. Our findings, summarized in Table S-15, indicate that z-score normalization is generally the most effective. Subsequently, using this optimal normalization, we explore 6D rotations [73] as an alternative. As evidenced by Table S-16, axis-angle representation offers superior performance. This preference can be attributed to the effective modeling capabilities of diffusion models, which do not benefit much from more continuous data representation. Inspired by HuMoR [55], we experiment with integrating the SMPL body model [43] as regularization term during training. Alongside the prediction of additive noise, as outlined in Eq. (4) in the main text, we employ 10-step DDIM sampler [60] to recover clean version of the pose, denoted as x0, from the diffused xt. The regularization loss aims to minimize the discrepancy between the original and (a) VPoser (b) DPoser (ours) Figure S-4. Visualization of face generation results. Top row shows varying face shapes; bottom row shows varying expressions."
        },
        {
            "title": "Methods",
            "content": "1mm Noise 2mm Noise 5mm Noise Half Face Occ. MPVPE MPJPE MPVPE MPJPE MPVPE MPJPE MPVPE MPJPE w/o prior L2 prior VPoser [51] DPoser-face 1.460 1.121 1.153 0.784 0.878 0.865 0.803 0.584 2.230 1.626 1.688 1.098 1.702 1.288 1.480 0.963 4.701 2.570 2.716 1.902 4.028 2.344 2.688 1. 0.752 0.698 0.671 0.427 0.632 0.512 0.361 0.228 Table S-13. Performance of face inverse kinematics on the WCPA dataset [31] under noisy and occlusion settings. PA-MPVPE PA-MPJPE"
        },
        {
            "title": "Face",
            "content": "w/o prior GMM [1] & L2 prior VPoser-X [51] DPoser-X SMPLerX + w/o prior + GMM [1] & L2 prior + VPoser-X [51] + DPoser-X 89.72 86.95 81.96 70.91 25.49 24.72 24.28 24.41 23.20 23.51 18.22 17.59 15.83 18.89 11.92 11.09 10.21 8. 7.26 5.38 6.37 5.27 2.85 2.78 2.58 2.65 2."
        },
        {
            "title": "Body",
            "content": "91.18 83.58 86.50 74.33 28.30 22.98 22.95 23.03 21.22 Table S-14. Whole-body mesh recovery results on the Fit3d dataset [19]. recovered poses under the SMPL body model : Lreg = MJ (x0, β0) MJ (x0, β0)2 2 + MV (x0, β0) MV (x0, β0)2 2. (19) Here, β0 represents the mean shape parameters in SMPL. To account for denoising errors, we scale the regularization loss by log(1 + αt ), thereby increasing the weight for samσt ples with smaller values (less noise). Fig. S-5 visualizes the impact of this regularization on MPJPE during the training, specifically for pose completion tasks with occlusion of both legs. We observe that weighted regularization offers slight performance gains in the early training process, while the absence of weighting introduces instability and deterioration in results. Despite these insights, the computational cost of incorporating the SMPL modelespecially for our large batch size of 1280makes the training approximately 8 times slower. Therefore, we opted not to include this regularization in our main experiments. We ablate the architectural hyperparameters of DPoserbody and the number of optimization steps on the HMR task, with results shown in Table S-17. Our findings indicate that more complex architecture (i.e., 4 blocks or 2048 hidden dimension) does not improve accuracy. Regarding the optimization, increasing the steps to 1000 offers the best accuracy (55.74 PA-MPJPE) but at high compu-"
        },
        {
            "title": "Normalization",
            "content": "w/o norm min-max z-score"
        },
        {
            "title": "Motion Denoising",
            "content": "PA-MPJPE MPJPE (S = 10) MPVPE MPJPE 57.88 59.17 56.49 45.37/102.28/41.08 47.41/107.00/43.42 34.37/72.47/26.32 44.82 42.70 38. 24.04 21.29 20.24 Table S-15. Comparative performance of normalization methods using axis-angle rotation representation across multiple tasks."
        },
        {
            "title": "Representation",
            "content": "axis-angle 6D rotations"
        },
        {
            "title": "Motion Denoising",
            "content": "PA-MPJPE MPJPE (S = 10) MPVPE MPJPE 56.05 57.54 34.76/72.41/26.09 40.89/81.43/27.31 38.21 38. 19.87 20.12 Table S-16. Comparative performance of rotation representations using z-score normalization across multiple tasks. J. Extended DPosers Optimization In addressing pose-centric tasks as inverse problems, we propose versatile optimization framework, which employs variational diffusion sampling as its foundational approach [46]. Our exploration extends to an array of diffusion-based methodologies for solving these complex inverse problems. Among the techniques considered are ScoreSDE [62], MCG [7], and DPS [6]. These methods augment standard generative processes with observational data, either by employing gradient-based guidance or back-projection techniques. We compare these methods with our DPoser for body pose completion tasks. Our findings, captured in Table S-18, reveal that DPoser outperforms the competitors under most occlusion conditions. Consequently, DPoser emerges not merely as universally applicable solution to pose-related tasks, but also as an exceptionally efficient one. It is worth mentioning that methods rooted in generative frameworks [6, 7, 33, 62] can pose challenges for broader applicability in pose-centric tasks. For instance, in blind inverse problemscertain parameters in (e.g., camera models in HMR) are unknowngenerative methods are less straightforward to implement. ZeDO [29], recent study focusing on the 2D-3D lifting task, adopts the ScoreSDE [62] framework and refines camera translations by solving an optimization sub-problem after each generative step. However, directly porting this strategy to HMR is non-trivial, owing to the added complexity of body shape parameter optimizationa feature currently absent in our DPoser model. Although some state-of-the-art techniques [8, 50] offer solutions by jointly modeling operator and data distributions, full-fledged discussion on this subject is beyond this papers purview and remains an open question for future work. Figure S-5. MPJPE evolution in DPoser training with different regularization loss settings for body pose completion, assessed on AMASS [45] with 10 hypotheses under legs occlusion scenarios. Steps Blocks Hidden Dim HMR (PA-MPJPE) Runtime (s) 500 250 1000 500 500 2 2 2 4 2 1024 1024 1024 2048 56.05 56.53 55.74 56.47 56.67 17.34 8.44 34.11 18.72 19.12 Table S-17. Ablation of DPosers architecture and optimization steps for the HMR task. tational cost (34.11s), while 250 steps are fastest but less accurate. Based on this analysis, we adopt the configuration of 500 steps, 2 blocks, and 1024 hidden dimension for our experiments, as it provides solid trade-off between accuracy and runtime efficiency."
        },
        {
            "title": "Methods",
            "content": "Occ. left leg Occ. legs Occ. arms Occ. torso ScoreSDE [62] DPS [6] MCG [7] DPoser 48.73/106.32/41.30 40.51/104.32/54.57 49.04/106.37/41.07 35.37/74.01/26. 74.68/128.32/37.27 64.26/113.46/33.71 74.90/128.53/37.40 59.25/96.77/24.55 66.89/127.86/48.15 60.63/119.85/42.78 66.17/127.72/48.15 51.27/81.76/20.04 16.69/34.54/12.21 15.10/33.90/13.27 16.69/34.66/12.23 13.95/28.57/9.85 Table S-18. Comparative evaluation of diffusion-based solvers for body pose completion on the AMASS dataset [45]. The min/mean/std of MPJPE are reported (hypotheses number = 10). variational diffusion sampling [46] process it employs, most notably tendency towards mode-seeking. For example, minimizing the DPoser regularization loss alone for generation results in high Precision of 0.995 but low Recall of 0.163. The low recall, compared to standard generative diffusion samplers (see Table 1 in the main text), indicates that the optimization framework captures the primary modes of the data distribution accurately but lacks diversity. To address this, future research could explore techniques like particle-based variational inference [42, 69] to enhance solution diversity. Finally, within the broader context of inverse problems we have framed, plethora of existing methods [11] could be adapted to leverage our diffusion-based pose prior. Exploring these methods holds great potential for future progress. L. More Qualitative Results We show more qualitative results for body pose generation (Fig. S-7), body pose completion (Fig. S-8), body mesh recovery (Fig. S-9), motion denoising (Fig. S-10 and Fig. S11), hand generation (Fig S-12), hand inverse kinematics (Fig S-13), hand mesh recovery (Fig S-14 and Fig S15), face inverse kinematics (Fig S-16), face reconstruction (Fig S-17), whole-body pose generation (Fig S-18 and Fig. S-19), whole-body mesh recovery (Fig S-20), wholebody pose completion (Fig S-21 and Fig. S-22). Figure S-6. Failure cases of our method on challenging yoga Inaccuracies in the estimated 2D keypoints (middle colposes. umn), combined with our models limited exposure to such outof-distribution poses during training, lead to flawed 3D mesh reconstructions (right column). K. Limitation and future work primary limitation of our work is the dependency on the training datas distribution. Our body pose prior is trained on the AMASS dataset [45], which, while diverse in common daily actions, contains limited examples of challenging or extreme poses like those found in yoga. This data imbalance leads to two main issues. First, the learned prior is inherently biased towards common standing poses. Second, when confronted with out-of-distribution inputs, as illustrated in Fig. S-6, the prior may offer limited or even incorrect guidance. This problem is often exacerbated by the failure of off-the-shelf 2D keypoint detectors like ViTPose [70] to produce accurate keypoints for such complex images, which in turn misguides the optimization. Future work could address these data-driven limitations in several ways. To mitigate the action imbalance, techniques like clustering motions with action labels [53] and performing importance sampling during training could be effective. To improve robustness on challenging poses, incorporating more diverse training data and exploring more robust fitting strategies, such as using predicted dense depth maps for supervision, are promising directions."
        },
        {
            "title": "Our framework also inherits certain limitations from the",
            "content": "24 Figure S-7. Visualization of body pose generation. DPoser can generate diverse and realistic body poses. Figure S-8. Visualization of body pose completion. (a) Left leg under occlusion. (b) Torso under occlusion. 25 Figure S-9. Visualization of body mesh recovery. (a) Fitting from scratch. (b) Initialization using the CLIFF [39] prediction results. (c) More results of DPoser optimization with CLIFF initialization on in-the-wild images. (a) Gaussian noise with 40 mm standard deviation. Figure S-10. Visualization of motion denoising with noisy observations. We visualize every 20th of the sequence. (b) Gaussian noise with 100 mm standard deviation. 27 (a) Legs under occlusion. Figure S-11. Visualization of motion denoising with partial observations. We visualize every 20th of the sequence. (b) Left arm under occlusion. 28 (a) DPoser (ours) (b) VPoser (c) NRDF Figure S-12. Visualization of hand pose generation. DPoser produces more diverse and realistic hand poses compared to VPoser [51] and NRDF [24]. Figure S-13. Visualization of hand inverse kinematics under multiple challenging settings. Comparison across (a) noisy keypoints, (b) fingertip keypoints, (c) partial finger keypoints, and (d) sparse keypoints settings. 29 Figure S-14. Visualization of hand mesh recovery with mean pose initialization. 30 Figure S-15. Visualization of hand mesh recovery with Hand4Whole [47] initialization. Figure S-16. Qualitative results of face inverse kinematics on the WCPA dataset [31]. Comparison across (a) 1 mm noise, (b) 5 mm noise, and (c) half-face occlusion. Better zoom in and compare the human eyes and chin. 32 Figure S-17. Visualization of face reconstruction results on the WCPA dataset [31]. Comparisons include (a) fitting from scratch and (b) initialization using EMOCA [10] results. *Ground truth lacks global orientation and translational data; these are fitted for visualization. 33 (a) VPoser-X (b) DPoser-X-base (c) DPoser-X-fused (d) DPoser-X-mixed Figure S-18. Visualization of whole-body pose generation. (a) VPoser-X primarily generates standing poses with limited diversity. (b) DPoser-X-base generates diverse samples but lacks realism in hand interactions and facial expressions. (c) DPoser-X-fused produces less diverse samples while maintaining plausible whole-body poses. (d) DPoser-X-mixed achieves well-balanced trade-off between diversity and realism. 34 (a) DPoser-X-mixed Figure S-19. Extended visualization of whole-body pose generation. DPoser-X-mixed generates diverse range of whole-body poses while maintaining realistic hand interactions and facial expressions. In contrast, DPoser-X-fused retains high realism but produces less diverse results. (b) DPoser-X-fused 35 Figure S-20. Visualization of whole-body mesh recovery on the Fit3d dataset [19]. Figure S-21. Qualitative comparison of whole-body pose completion. One hand is masked randomly. 36 Figure S-22. Visualization of whole-body pose completion for three DPoser-X variants. One hand is masked randomly."
        }
    ],
    "affiliations": [
        "Beihang University",
        "Independent Researcher",
        "NVIDIA Research",
        "Nanyang Technological University",
        "SenseTime Research",
        "Shanghai Jiao Tong University",
        "Tsinghua University"
    ]
}