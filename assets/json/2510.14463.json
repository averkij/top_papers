{
    "paper_title": "Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration",
    "authors": [
        "Thomas Katraouras",
        "Dimitrios Rafailidis"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Image quality is a critical factor in delivering visually appealing content on web platforms. However, images often suffer from degradation due to lossy operations applied by online social networks (OSNs), negatively affecting user experience. Image restoration is the process of recovering a clean high-quality image from a given degraded input. Recently, multi-task (all-in-one) image restoration models have gained significant attention, due to their ability to simultaneously handle different types of image degradations. However, these models often come with an excessively high number of trainable parameters, making them computationally inefficient. In this paper, we propose a strategy for compressing multi-task image restoration models. We aim to discover highly sparse subnetworks within overparameterized deep models that can match or even surpass the performance of their dense counterparts. The proposed model, namely MIR-L, utilizes an iterative pruning strategy that removes low-magnitude weights across multiple rounds, while resetting the remaining weights to their original initialization. This iterative process is important for the multi-task image restoration model's optimization, effectively uncovering \"winning tickets\" that maintain or exceed state-of-the-art performance at high sparsity levels. Experimental evaluation on benchmark datasets for the deraining, dehazing, and denoising tasks shows that MIR-L retains only 10% of the trainable parameters while maintaining high image restoration performance. Our code, datasets and pre-trained models are made publicly available at https://github.com/Thomkat/MIR-L."
        },
        {
            "title": "Start",
            "content": "Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration Thomas Katraouras Dept. of Electrical and Computer Engineering University of Thessaly Volos, Greece tkatraouras@uth.gr Dimitrios Rafailidis Dept. of Electrical and Computer Engineering University of Thessaly Volos, Greece draf@uth.gr 5 2 0 2 6 1 ] . [ 1 3 6 4 4 1 . 0 1 5 2 : r AbstractImage quality is critical factor in delivering visually appealing content on web platforms. However, images often suffer from degradation due to lossy operations applied by online social networks (OSNs), negatively affecting user experience. Image restoration is the process of recovering clean high-quality image from given degraded input. Recently, multi-task (all-inone) image restoration models have gained significant attention, due to their ability to simultaneously handle different types of image degradations. However, these models often come with an excessively high number of trainable parameters, making them computationally inefficient. In this paper, we propose strategy for compressing multi-task image restoration models. We aim to discover highly sparse subnetworks within overparameterized deep models that can match or even surpass the performance of their dense counterparts. The proposed model, namely MIR-L, utilizes an iterative pruning strategy that removes low-magnitude weights across multiple rounds, while resetting the remaining weights to their original initialization. This iterative process is important for the multi-task image restoration models optimization, effectively uncovering winning tickets that maintain or exceed state-of-the-art performance at high sparsity levels. Experimental evaluation on benchmark datasets for the deraining, dehazing, and denoising tasks shows that MIR-L retains only 10% of the trainable parameters while maintaining high image restoration performance. Our code, datasets and pre-trained models are made publicly available at https://github.com/Thomkat/MIR-L. Index TermsMulti-task, Web Image Restoration, Pruning. I. INTRODUCTION Image quality is critical factor in delivering visually appealing content across web platforms, where images are essential to user engagement and experience. However, images on the web frequently undergo lossy operations applied by online social networks (OSNs), such as JPEG compression and format conversion [1][4]. These operations result in noticeable degradation, with higher compression ratios correlated with greater degradation [5]. Such reductions in image quality can negatively impact user experience, as lower visual quality reduces the perceived value of online content [6]. Overcoming the problem of degraded images is important for improving user experience on the web. Image restoration is fundamental task in computer vision that aims to recover high-quality images from degraded versions. This degradation can be caused by factors such as noise [7], rain [8], haze [9], motion blur [10], low resolution [11], or compression artifacts [12]. Image restoration seeks to enhance the visual quality and clarity of images, making them more suitable for various applications. Recent image restoration models utilize deep learning techniques [8][10], [13][21] to reconstruct clean images by learning complex mappings from degraded inputs to their high-quality equivalents. These models offer breakthrough performance compared to conventional restoration methods [22][25] and are widely used in fields such as medical imaging [26], astronomy [27] and aerial imaging [28], where accurate and visually enhanced images are essential for analysis and decision-making. In addition, image restoration not only improves visual fidelity, but it also promotes high performance in tasks such as object detection [29], [30]. Image restoration models have been designed to handle specific tasks, such as denoising [7], [17], [20], deraining [8], [18], [31], dehazing [9], [16], [32], deblurring [10], [13], [33] and super-resolution [11], [15], [21]. However, real-world images often suffer from multiple types of degradation. To address this, the focus has shifted towards multi-task (all-in-one) image restoration models [14], [34][36], handling various types of degradation within single framework, without requiring any prior knowledge of the degradation. Multi-task models provide an efficient and unified solution for real-world image restoration problems, as they reduce the overhead of deploying separate networks for individual degradations. However, despite their effectiveness, multi-task image restoration models often require significantly high number of trainable parameters, as demonstrated in our experiments in Section IV. This leads to substantial computational costs and memory demands, making running these models feasible only on high-end machines, rather than consumer-grade devices. Additionally, this limits their usability in real-time applications, such as client-side web image restoration. To address the complexity issue, researchers have explored several techniques to reduce the size and computational requirements of deep learning models, while maintaining their performances. Model compression methods such as one-shot pruning [37][39], knowledge distillation [40][42] and parameter sharing [43], [44] have been applied to deep neural networks. One-shot pruning removes redundant parameters in single step, knowledge distillation transfers knowledge from large teacher Accepted at WI-IAT 2025 model to smaller student model and parameter sharing reduces redundancy by reusing parameters across different tasks or layers, effectively lowering the model size. These techniques have shown promising results in reducing the size of complex deep learning models. However, achieving balance between preserving the models ability to handle diverse degradations in the image restoration problem and minimizing redundant parameters still remains challenge. One promising approach to model compression is the Lottery Ticket Hypothesis (LTH), which suggests that within large, overparameterized neural network, there are small subnetworksreferred to as winning ticketsthat can be trained in isolation to achieve comparable performance to the original model [45]. It has been studied in image classification [46], [47] and natural language processing [48], [49]. The effectiveness of lottery tickets in reducing the size of multitask image restoration models has not been thoroughly explored. Investigating LTH in this context could reveal whether certain subnetworks consistently perform well across multiple image restoration tasks, potentially enabling more efficient allin-one solutions for handling diverse image degradations. In this paper we propose the MIR-L model based on lottery tickets for compressing multi-task image restoration models while maintaining the performance high. Specifically, we make the following contributions: We propose LTH-based pruning algorithm designed for multi-task image restoration models, focusing on deraining, dehazing and denoising tasks. The algorithm iteratively removes the smallest-magnitude weights and resets the remaining weights to their original initialization, seamlessly integrating to the multi-task image restoration models optimization process. We explore both layer-wise and global pruning strategies to assess their effectiveness in discovering sparse networks. We show that global pruning is capable of finding very sparse winning tickets, while layer-wise pruning diminishes performance. We conduct experiments on benchmark datasets for the deraining, dehazing, and denoising tasks, comparing our proposed MIR-L with baseline pruning methods and state-of-theart multi-task image restoration models. Our results demonstrate that the sparse networks of MIR-L reduce the number of trainable parameters by up to 90% compared to the original dense models and outperform baseline pruning methods. In many cases, these sparse networks match or even exceed the performance of dense, state-of-the-art multi-task image restoration models, confirming that our approach effectively discovers efficient and highly sparse subnetworkswinning ticketsfor multi-task image restoration. The remainder of this paper is structured as follows: Section II provides an overview of pruning techniques. Section III presents our proposed method, the architecture of the multitask image restoration model, the pruning strategy and the MIR-L optimization algorithm. Section IV provides the experimental evaluation, showcasing results on various datasets. Finally, Section concludes the paper, summarizing key findings and discussing potential future directions. II. PRELIMINARIES Pruning is technique in deep learning used to reduce the number of parameters in neural network by removing certain connections. The goal is to create an efficient model with reduced memory and computational costs, while preserving the performance high. Formally, given dense network (x; θ), pruning identifies and removes subset of parameters θp θ, yielding sparse network (x; θ θp) [50]. Below, we outline preliminaries of existing pruning strategies. 1) Magnitude Pruning.: Magnitude-based pruning is widely used pruning strategy that removes parameters having the smallest absolute values, assuming they contribute less to the networks performance and can be removed with minimal impact. Formally, given trained dense network (x; θ) and threshold τ , parameter θi is pruned if θi < τ , setting θi = 0 for such parameters. The resulting pruned network is represented as (x; θ), where θ = θ {θi : θi < τ } [51], [52]. 2) One-shot Pruning.: One-shot pruning is pruning strategy where the network parameters are pruned once after the initial training phase. fixed percentage p% of the parameters are removed based on pruning criterion, e.g., magnitudebased, resulting in sparse network with pruned parameters set to zero [37], [38]. 3) Iterative Pruning: Iterative pruning is an approach to network sparsification, where pruning is performed in multiple rounds rather than in single step. This method iteratively prunes percentage p% of the parameters and optimizes the network after each pruning step [53], [54]. III. PROPOSED METHOD A. Multi-Task Image Restoration Model 1) Tasks: multi-task (all-in-one) blind image restoration model is designed to recover clean images from degraded inputs without prior knowledge of the degradation type. Specifically, it handles the following image restoration tasks: I. Deraining: removes rain streaks and artifacts; II. Dehazing: removes haze and fog; III. Denoising: reduces unwanted noise caused by low-light conditions, sensor imperfections, or compression artifacts. 2) Architecture: multi-task image restoration model takes degraded image RHW as input, where is the spatial resolution, and = 3 represents the RGB color channels [36]. This image has undergone an unknown degradation D. The model produces restored image RHW C. The model follows UNet-style network architecture [19] with transformer blocks [55] in both the encoding and decoding stages. Initially, low-level features F0 RHW are extracted from by applying 3 3 convolution: F0 = Conv33(I). These features go through four-level hierarchical encoder-decoder, where each level increases channel capacity while reducing spatial resolution, ultimately generating low-resolution latent features Fl 8 8C [36]. 8 The decoder gradually upsamples and refines Fl, leading to the final clean output image I. During decoding, the model incorporates sequential prompt blocks at multiple levels to inject degradation-aware information. Each prompt block consists of two components: Prompt Generation Module (PGM) and Prompt Interaction Module (PIM). Given learnable prompt components Pc RN ˆH ˆW ˆC and input features Fl ˆH ˆW ˆC, the prompt block produces refined features ˆFl = PIM(PGM(Pc, Fl), Fl). The PGM learns an adaptive prompt conditioned on both Fl and Pc. In particular, the PGM aggregates spatial information from Fl using global average pooling, followed by 1 1 convolution and softmax to produce prompt weights: = Softmax(Conv11(GAP(Fl))), where R11N . These weights determine the contribution of each prompt component {Pc1 , . . . , PcN } in weighted sum. The resulting combination is then refined by 3 3 convolution: = Conv33((cid:80)N i=1 wi Pci). The PIM fuses with Fl by concatenating along the channel dimension: Fconcat = Concat(Fl, P). transformer block processes Fconcat to incorporate degradation-specific information, followed by two consecutive 1 1 and 3 3 convolutions: (cid:0)Conv11(T(Fconcat))(cid:1). Finally, ˆFl propagate ˆFl = Conv33 through the decoder, leading to the reconstructed image I. The L1 loss function is used to minimize the absolute differences between the restored and ground truth images, defined as IGTi Ii, where IGT RHW is L1 = 1 the ground truth image [36]. The optimization is performed using the Adam optimizer. (cid:80)HW i=1 HW B. Lottery Ticket Hypothesis The LTH proposes that within dense, randomly-initialized neural network, there is sparse subnetworkreferred to as winning ticketthat can be trained in isolation to achieve performance comparable to the original network [45]. Definition 1 (Winning Ticket). winning ticket, denoted as fw(x; θw), is sparse subnetwork within dense, randomlyinitialized neural network (x; θ) with initial parameters θ0 Dθ, such that when trained in isolation from its original initialization θ0, it satisfies afw af , jfw jf , and θw θ; where afw and af denote the test accuracies achieved by fw and , respectively, jfw and jf denote the number of training iterations required to reach minimum validation loss, and θw and θ denote the number of parameters in the winning ticket and the original network, respectively. Proposition 1. Consider dense feed-forward neural network (x; θ) with initial parameters θ0 Dθ. Let {0, 1}θ be binary mask that identifies the active connections in the subnetwork. The Lottery Ticket Hypothesis predicts that mask does exist such that training (x; θ0), where denotes element-wise multiplication, results in winning ticket fw(x; θw); where θw θ0. 1) Layer-wise Pruning: Layer-wise pruning is strategy where pruning is applied independently to each layer of the network. fixed percentage p% of the smallest-magnitude Algorithm 1 MIR-L Optimization Algorithm Input: 1. Initial dense network (I; θ0), 2. Pruning rate p, 3. Number of training epochs j, 4. Number of warmup epochs jw, 5. Batch size B, 6. Training samples Xtrain, 7. Initial learning rate ηstart, 8. Base learning rate ηbase, 9. Minimum learning rate ηmin, 10. Target sparsity level Output: Trained sparse network (I; θ) Initialize binary mask Set initial parameters 1: 1θ0 2: θ θ0 3: while m0 4: 5: θ0 < do for epoch = 1 do Compute learning rate ηt using Linear Warmup Cosine Annealing: ηt = (cid:40)ηstart + ηmin + 1 jw 1 (ηbase ηstart), 2 (ηbase ηmin) (cid:16) 1 + cos (cid:16) (tjw )π jjw (cid:17)(cid:17) 0 < jw , jw 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: for step = 1 Xtrain IB = {f (Ii; θ)}B LL1 1 (cid:80)HW i=1 HW do i=1, Ii Xtrain Forward pass IGTi IBi Compute the reconstruction loss weights θLL1 LL1 Backward pass θ θLL1 θLL1 Mask gradients of pruned θ θ ηt θLL1 θ θ Parameter update via Adam Apply sparsity mask to updated weights end for end for Determine pruning threshold τ as the p-th percentile of (cid:0)m θ(cid:1) θ, i.e., τ = Quantilep (m θ τ ) θ θ0 16: 17: 18: 19: end while 20: return Final sparse model (I; θ) Calculate new mask Prune and reset to initial values Update mask weights within each layer are pruned, ensuring that sparsity is uniformly distributed across all layers. The output layer is pruned at half the rate, 2 %, since it typically contains far fewer parameters compared to other layers. Pruning it too aggressively can lead to diminishing returns much earlier. 2) Global Pruning: Global pruning is strategy where fixed percentage p% of the smallest-magnitude weights are pruned across the entire network, rather than on per-layer basis. This approach is particularly effective in deeper networks, where layers can have significantly different numbers of parameters. By pruning globally, bottlenecks caused by uniformly pruning smaller layers are avoided. As result, global pruning can identify smaller winning tickets compared to layer-wise pruning, especially in networks with imbalanced layer sizes. C. MIR-L Optimization Algorithm The proposed MIR-L model optimizes the multi-task image restoration model (Section III-A) and prunes it with the LTH to obtain sparse yet equally or more effective multitask image restoration model. MIR-L, optimized with an L1 reconstruction loss, is iteratively trained and pruned, until the target sparsity level is reached. Algorithm 1 provides formal outline of the model optimization and pruning process. Firstly, the dense network parameters and binary mask are initialized (lines 12). Next, the network is trained for epochs with learning rate schedule that includes linear warmup followed by cosine annealing (lines 414). After each training steps backward pass, to ensure they remain zeroed. After each training cycle, pruning threshold τ is determined based on pruning rate p, the mask is updated, the network is pruned and remaining weights are reset to their initial values (lines 1518). This procedure is repeated until the target sparsity is reached, resulting in final sparse model. the gradients and weights are masked, Note that for layer-wise pruning, the threshold τ is determined for each layer independently, whereas for global pruning τ is determined across all layers. IV. EXPERIMENTAL EVALUATION A. Datasets We evaluate our MIR-L model, as well as the baselines following the evaluation protocol of [34][36]. Specifcially, for image denoising, we use combination of the BSD400 [56] and WED [57] datasets for training. BSD400 consists of 400 training images and the WED dataset consists of 4,744 images. Due to training resourse constraints, we randomly selected 5% of the images of each dataset for training. From the clean images, we generate the noisy images by adding Gaussian noise with different noise levels σ {15, 25, 50}. Testing is performed on the Color BSD68 [58] and Urban100 [59] datasets consisting of 68 and 100 images, respectively. For image deraining, we use the Rain100L [60] dataset, which consists of 200 rainy-clean image pairs for training and 100 rainy-clean image pairs for testing. We randomly selected 10% of the original pairs for training. For image dehazing, we use the OTS [61] dataset for training, which consists of 72,135 images. We randomly selected 3% of the original pairs. Testing is performed on the SOTS [61] dataset, consisting of 500 hazy-clean image pairs. In the all-in-one setting (covering both training and testing), we combine the aforementioned datasets across denoising, deraining, and dehazing. This approach enables unified evaluation of our method under single model across multiple restoration tasks. All the datasets are publicly available for reproducibility purposes at https://github.com/Thomkat/MIR-L. B. Evaluation Protocol To evaluate the performance of our model, we need to specify appropriate metrics that objectively compare different models. In image restoration tasks, Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) are commonly used to assess the quality of restored images [8], [16], [19], [20], [35], [36], [62]. These metrics provide insight into the reconstruction fidelity and perceptual similarity of the restored images. 1) Peak Signal-to-Noise Ratio (PSNR): measures the ratio between the maximum possible power of signal and the power of the noise that affects its representation. higher PSNR value indicates better image quality, as it implies lower level of distortion in the restored image. The PSNR is calculated as follows: SN = 10 log (cid:19) (cid:18) AX 2 SE (1) where MAX is the maximum possible pixel value, i.e., 255 for an 8-bit image and MSE (Mean Squared Error) represents the average squared differences between corresponding pixels of the original and restored images. 2) Structural Similarity Index Measure (SSIM): quantifies the perceived visual quality of an image by considering luminance, and contrast. higher structural SSIM value indicates better perceptual quality and structural similarity to the reference image. The SSIM is calculated as follows: information, SSIM (x, y) = (2µxµy + C1)(2σxy + C2) + µ2 + C1)(σ + σ2 + C2) (µ2 (2) where µx and µy are the mean intensities of images and y, and σ2 σ2 are their variances, σxy is the covariance, and C1 and C2 are small constants to avoid instability. While PSNR is useful for measuring absolute reconstruction fidelity, SSIM aligns better with human visual perception. Therefore, both PSNR and SSIM provide complementary insights into the performance of our model. C. Experimental Setup 1) Implementation Details: All the experiments were performed on the NVIDIA A40 GPU, using PyTorch version 2.5.1. The model was trained for 120 epochs (15 warmup epochs) with batch size of 8. Optimization was performed using the Adam optimizer with an L1 loss function and learning rate of 2 104. The target sparsity level is 90%, which corresponds to 15 pruning steps, and pruning rate was set to 20%. During training, the input images were randomly cropped into patches of size 64 64. To improve generalization, random horizontal and vertical flips were applied to the training data. Smaller datasets were artificially expanded by duplicating their images, while random augmentations ensured variation, allowing the model to perceive them as distinct and maintain balanced training process. 2) Examined Models: MSPFN1 [8]: multi-scale progressive fusion network for image deraining, using cross-scale and intra-scale information with recurrent refinement. EPDN2 [16]: An enhanced Pix2pix Dehazing Network reframing dehazing as image-to-image translation, with GAN-based enhancer module. AirNet3 [35]: An all-in-one image restoration network 1https://github.com/kuijiang94/MSPFN 2https://github.com/ErinChen1/EPDN 3https://github.com/XLearning-SCU/2022-CVPR-AirNet TABLE EXAMINED IMAGE RESTORATION MODELS Model Single-Task Multi-Task Task Sparse Deraining Dehazing Denoising MSPFN [8] EPDN [16] FFDNet [20] AirNet [35] Restormer [19] MPRNet [62] AdaIR [34] PromptIR [36] PIR-OSM PIR-OSM II PIR-OSR PIR-OSR II MIR-L-LW MIR-L-G for unknown degradations via contrastive-based encoding and degradation-guided recovery. Restormer4 [19]: transformer-based restoration network for high-resolution images, utilizing attention for long-range dependencies. FFDNet5 [20]: convolutional neural network (CNN) for image denoising using downsampled sub-images and tunable noise-level map for spatially varying noise. MPRNet6 [62]: multi-stage all-in-one image restoration network that progressively refines spatial details. AdaIR7 [34]: An adaptive all-in-one image restoration network that mines lowand high-frequency features and modulates them bidirectionally for progressive correction. PromptIR8 [36]: An all-in-one blind image restoration model that generalizes to various unknown degradation types and levels by using prompt-based learning to encode degradation-specific information, dynamically guiding the restoration network. PIR-OSM I: pruned version of the model described in Section III-A (one-shot, magnitude-based), obtained by removing 30% of the smallest weights post-training and fine-tuning for an additional 5% of training epochs. PIR-OSM II: variant of PIR-OSM, removing 70% of the smallest weights. PIR-OSR I: pruned version of the model described in Section III-A (one-shot, random), obtained by randomly removing 30% of weights post-training and fine-tuning for an additional 5% of training epochs. PIR-OSR II: variant of PIR-OSR, randomly removing 70% of the weights. MIR-L-LW (Layer-wise Pruning): Our proposed model based on the LTH with layer-wise pruning. MIR-L-G (Global Pruning): Our proposed model based on the LTH with global pruning."
        },
        {
            "title": "In Table I we present an overview of the examined image",
            "content": "4https://github.com/swz30/Restormer 5https://github.com/cszn/FFDNet 6https://github.com/swz30/MPRNet 7https://github.com/c-yn/AdaIR 8https://github.com/va1shn9v/PromptIR restoration models. To ensure fair comparison, we retrain all the aforementioned models using their publicly available implementations and the datasets described in Section IV-A. All the models are trained with an input patch size of 64 64. D. Experimental Results Table II compares our MIR-L against conventional oneshot pruning baselines and model baselines on the following single-task settings: Table IIa reports deraining results on the Rain100L dataset, Table IIb reports dehazing results on the SOTS dataset and Table IIc reports denoising results on the BSD68 and Urban100 datasets. In the single task setting, separate models are trained for each individual degradation (Table I). Multi-task models have higher number of trainable parameters than single-task models but they achieve better restoration performance. Although one-shot magnitude (PIROSM I. & II.) and random pruning (PIR-OSR I. & II.) reduce the trainable parameters, they show steep drop in performance at high sparsity levels, expressed by fewer trainable parameters. The proposed MIR-L-LW and MIR-L-G drastically reduce the parameters, down to 4.7M, while preserving the performance high. Our strategy achieves superior performance by gradually pruning the model and resetting the remaining weights to their original values. This process allows the optimization to relearn the weights and recover any lost performance by modifying the relationships between the surviving weights. In subsequent rounds, less important weights are pruned again, ensuring that the most critical parts of the network are preserved. By contrast, conventional oneshot pruning methods remove large portion of weights all at once, leaving little opportunity for the model to adjust and fully recover the lost performance. MIR-L-G consistently outperforms MIR-L-LW in all settings, demonstrating that global pruning more effectively discovers winning tickets in large networks. Table III compares our MIR-L against conventional oneshot pruning baselines and model baselines on the multi-task setting: Table IIIa reports deraining results on the Rain100L dataset, Table IIIb reports dehazing results on the SOTS dataset and Table IIIc reports denoising results on the BSD68 and Urban100 datasets. In the multi-task (all-in-one) setting, model is trained to simultaneously handle multiple degradations. Similarly to the single-task settings, one-shot magnitude (PIROSM I. & II.) and random pruning (PIR-OSR I. & II.) reduce the parameters, while their performance degrades significantly as sparsity increases. The proposed MIR-L-LW and MIR-LG achieve greater performance than PIR-OSM and PIR-OSR, using only 4.7M parameters, an approximate 87% reduction compared to the dense models 35.6M parameters on average, corresponding to compression rate of x7.57. Similarly to the single-task setting, MIR-L-G outperforms MIR-L-LW, with the former achieving restoration performance that reaches or exceeds state-of-the-art both in terms of PSNR and SSIM. Figure 1 reports PSNR when varying the number of trainable parameters for layer-wise and global pruning. The xaxis indicates the number of trainable parameters, where TABLE II COMPARISON OF SINGLE-TASK RESULTS FOR (A) DERAINING, (B) DEHAZING, AND (C) DENOISING. THE BEST RESULTS ARE SHOWN IN BOLD, AND THE SECOND-BEST ARE UNDERLINED. OUR MIR-L-LW AND MIR-L-G MODELS DRASTICALLY REDUCE TRAINABLE PARAMETERS WHILE REACHING PERFORMANCE SIMILAR TO DENSE BASELINE MODELS. (a) Derain Model (Rain100L) (b) Dehaze Model (SOTS) Method PSNR/SSIM Trainable Parameters Method PSNR/SSIM Trainable Parameters MSPFN [8] AirNet [35] Restormer [19] PromptIR [36] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G 25.85/0.8118 28.77/0.8867 30.09/0.9114 35.13/0.9683 34.75/0.9640 25.52/0.8140 25.74/0.8158 25.69/0. 32.14/0.9395 34.72/0.9652 21M 7.6M 26.1M 35.6M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M EPDN [16] AirNet [35] Restormer [19] PromptIR [36] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G 24.57/0.9367 22.13/0.9228 25.32/0.9432 26.76/0.9556 26.55/0.9525 18.75/0.8612 20.70/0.8838 17.25/0. 26.53/0.9533 27.62/0.9609 22.9M 7.6M 26.1M 35.6M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M Dataset Method BSD Urban100 FFDNet [20] AirNet [35] Restormer [19] PromptIR [36] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G FFDNet [20] AirNet [35] Restormer [19] PromptIR [36] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G (c) Denoise Model (BSD68 & Urban100) σ = 15 PSNR/SSIM 33.42/0.9240 33.89/0.9324 33.64/0.9243 33.97/0.9330 33.72/0.9272 27.73/0.7058 29.14/0.839 25.44/0.6159 33.01/0.9208 33.85/0.9298 32.65/0.9316 34.30/0.9476 34.36/0.9449 33.90/0.9433 33.46/0.9363 27.61/0.7262 27.08/0.8389 25.52/0.6500 32.00/0.9250 33.71/0.9392 σ = 25 PSNR/SSIM 30.93/0.8768 31.28/0.8883 31.22/0.8796 31.32/0.8876 31.07/0.8777 23.54/0.5287 28.06/0.7848 21.15/0.4397 30.40/0.8688 31.30/0.8862 30.57/0.9017 31.99/0.9219 32.05/0.9183 31.51/0.9139 31.10/0.9049 23.54/0.5750 26.31/0.7858 21.28/0.4998 29.54/0.8846 31.50/0.9131 σ = 50 PSNR/SSIM 27.81/0.7838 28.09/0.7997 28.12/0.7896 28.08/0.7961 27.97/0.7873 17.88/0.2980 24.61/0.5993 15.59/0. 27.06/0.7554 28.07/0.7962 27.51/0.8367 28.72/0.8661 28.83/0.8608 28.23/0.8522 28.04/0.8442 17.95/0.3696 23.57/0.616 15.75/0.3080 26.04/0.7910 28.26/0.8529 Trainable Parameters 494K 7.6M 26.1M 35.6M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M 494K 7.6M 26.1M 35.6M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M larger pruning step corresponds to fewer trainable parameters. We observe that MIR-L-G consistently outperforms MIRL-LW as sparsity increases, primarily because global pruning selectively removes redundant weights across all layers, avoiding bottlenecks in thinner layers and thus preserving the subnetworks overall representational capacity. In the singletask settings, both pruning strategies initially maintain high PSNR values, but as pruning becomes more aggressive, layerwise pruning shows significant performance drop compared to global pruning. An exception is deraining, where global pruning shows large drop at higher sparsity levels compared to layer-wise pruning. This occurs because weights essential for deraining performance are pruned by the global magnitude pruning criterion during these steps. In the multi-task (allin-one) setting, we observe similar trend: global pruning tasks, but not only maintains higher PSNR across all performance improves in all tasks as parameters are reduced, whereas layer-wise pruning shows steep performance drop at higher sparsity levels. PSNR vs. Fig. 1. trainable parameter count across progressive pruning steps. The x-axis denotes the number of trainable parameters, where larger pruning step corresponds to fewer trainable parameters. MIR-L-G consistently maintains high performance as step (sparsity) increases, while MIR-L-LW experiences sharp drop at higher pruning levels. V. CONCLUSION This paper proposes pruning strategy for multi-task image restoration models based on lottery tickets (MIR-L), focusing TABLE III COMPARISON OF MULTI-TASK (ALL-IN-ONE) RESULTS FOR (A) DERAINING, (B) DEHAZING, AND (C) DENOISING. THE BEST RESULTS ARE SHOWN IN BOLD, AND THE SECOND-BEST ARE UNDERLINED. OUR MIR-LW AND MIR-L-G MODELS ACHIEVE PERFORMANCE SIMILAR TO OR HIGHER THAN STATE-OF-THE-ART, WITH SUBSTANTIALLY FEWER TRAINABLE PARAMETERS THAN DENSE MODELS. (a) Rain100L Dataset (b) SOTS Dataset Method MPRNet [62] AirNet [35] PromptIR [36] AdaIR [34] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G PSNR/SSIM 27.64/0.8477 27.83/0.8809 32.17/0.9372 25.90/0.8409 31.85/0.9272 26.59/0.8365 25.39/0.8101 26.02/0.8171 25.49/0.8125 32.43/0.9425 Method MPRNet [62] AirNet [35] PromptIR [36] AdaIR [34] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G Trainable Parameters 39.5M 7.6M 35.6M 28.8M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M σ = 15 PSNR/SSIM 32.15/0.8976 32.79/0.9167 33.50/0.9247 33.52/0.9250 32.97/0.9148 25.91/0.6374 25.38/0.6382 24.62/0. 31.22/0.8731 33.53/0.9269 Method MPRNet [62] AirNet [35] PromptIR [36] AdaIR [34] PIR-OSM I. PIR-OSM II. PIR-OSR I. PIR-OSR II. MIR-L-LW MIR-L-G PSNR/SSIM 24.34/0.9350 22.41/0.8738 26.49/0.9535 27.09/0.9575 26.43/0.9524 17.54/0.8399 18.02/0.8404 16.54/0. 25.63/0.9446 27.45/0.9591 Trainable Parameters 39.5M 7.6M 35.6M 28.8M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M (c) BSD68 Dataset σ = 25 PSNR/SSIM 30.10/0.8552 30.30/0.8602 30.79/0.8734 30.82/0.8747 30.29/0.8556 21.66/0.4605 21.47/0.4628 20.56/0.4218 28.55/0.7946 30.83/0.8772 σ = 50 PSNR/SSIM 27.36/0.7647 27.07/0.7437 27.41/0.7667 27.48/0.7695 26.76/0.7202 16.06/0.2475 16.00/0.2504 15.14/0.2220 24.80/0.6166 27.48/0.7736 Trainable Parameters 39.5M 7.6M 35.6M 28.8M 25.6M 12.4M 25.6M 12.4M 4.7M 4.7M on the deraining, dehazing, and denoising tasks. To deal with the overparameterization of multi-task image restoration models, we presented an iterative pruning strategy that removes low-magnitude weights in multiple rounds, while resetting the surviving weights to their initial values. The proposed MIRL optimization algorithm discovers sparse winning tickets capable of matching or surpassing the performance of their dense counterparts, at fraction of trainable parameters. Our experiments demonstrated that MIR-L effectively reduces the number of trainable parameters by up to 90% across both single-task and multi-task settings, while maintaining high performance on benchmark datasets. This model size reduction and low computational requirements are beneficial for web platforms, allowing faster delivery of high-quality images and improved user experience even on less powerful client devices. In future work, exploring more sophisticated pruning criteria, such as SynFlow [63], or expanding the implementation to image restoration tasks commonly used in real-time applications, such as super-resolution [15], [21], may offer further improvements in both efficiency and image restoration accuracy."
        },
        {
            "title": "REFERENCES",
            "content": "[1] M.-R. Ra, R. Govindan, and A. Ortega, P3: Toward {PrivacyPreserving} photo sharing, in 10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13), 2013, pp. 515528. [2] J. Ning, I. Singh, H. V. Madhyastha, S. V. Krishnamurthy, G. Cao, and P. Mohapatra, Secret message sharing using online social media, in 2014 IEEE Conference on Communications and Network Security. IEEE, 2014, pp. 319327. [3] W. Sun, J. Zhou, R. Lyu, and S. Zhu, Processing-aware privacypreserving photo sharing over online social networks, in Proceedings of the 24th ACM international conference on Multimedia, 2016, pp. 581585. [4] W. Sun, J. Zhou, S. Zhu, and Y. Y. Tang, Robust privacy-preserving image sharing over online social networks (osns), ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), vol. 14, no. 1, pp. 122, 2018. [5] J. Hu, S. Song, and Y. Gong, Comparative performance analysis of web image compression, in 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISPBMEI), 2017, pp. 15. [6] A. Asif, H. He, A. Khan, and M. Shafiq, Assessment of quality of experience (qoe) of image compression in social cloud computing, Multiagent and Grid Systems, vol. 14, no. 2, pp. 125143, 2018. [7] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, Beyond gaussian denoiser: Residual learning of deep cnn for image denoising, IEEE TIP, 2017. [8] K. Jiang, Z. Wang, P. Yi, C. Chen, B. Huang, Y. Luo, J. Ma, and J. Jiang, Multi-scale progressive fusion network for single image deraining, in CVPR, 2020. [9] B. Li, X. Peng, Z. Wang, J.-Z. Xu, and D. Feng, Aod-net: All-in-one dehazing network, in ICCV, 2017. [10] K. Kim, S. Lee, and S. Cho, Mssnet: Multi-scale-stage network for single image deblurring, in ECCV, 2022, pp. 524539. [11] H. Li, Y. Yang, M. Chang, S. Chen, H. Feng, Z. Xu, Q. Li, and Y. Chen, Srdiff: Single image super-resolution with diffusion probabilistic models, Neurocomputing, vol. 479, pp. 4759, 2022. [12] M. Ehrlich, L. Davis, S.-N. Lim, and A. Shrivastava, Quantization guided jpeg artifact correction, in Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part VIII 16. Springer, 2020, pp. 293309. [13] S.-J. Cho, S.-W. Ji, J.-P. Hong, S.-W. Jung, and S.-J. Ko, Rethinking coarse-to-fine approach in single image deblurring, in ICCV, 2021, pp. 46414650. [14] Q. Fan, D. Chen, L. Yuan, G. Hua, N. Yu, and B. Chen, general decoupled learning framework for parameterized image operators, IEEE TPAMI, 2021. [15] Z. Lu, J. Li, H. Liu, C. Huang, L. Zhang, and T. Zeng, Transformer for single image super-resolution, in CVPR, 2022, pp. 457466. [16] Y. Qu, Y. Chen, J. Huang, and Y. Xie, Enhanced pix2pix dehazing network, in CVPR, 2019. [17] C. Tian, Y. Xu, and W. Zuo, Image denoising using deep cnn with batch renormalization, Neural Networks, vol. 121, pp. 461473, 2020. [18] W. Wei, D. Meng, Q. Zhao, Z. Xu, and Y. Wu, Semi-supervised transfer learning for image rain removal, in CVPR, 2019. [19] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, and M.-H. Yang, Restormer: Efficient transformer for high-resolution image restoration, in CVPR, 2022. [20] K. Zhang, W. Zuo, and L. Zhang, Ffdnet: Toward fast and flexible solution for cnn based image denoising, IEEE TIP, 2018. [21] W. Zhang, W. Zhao, J. Li, P. Zhuang, H. Sun, Y. Xu, and C. Li, Cvanet: Cascaded visual attention network for single image super-resolution, Neural Networks, vol. 170, pp. 622634, 2024. [22] W. Dong, L. Zhang, G. Shi, and X. Wu, Image deblurring and superresolution by adaptive sparse domain selection and adaptive regularization, IEEE TIP, vol. 20, no. 7, pp. 18381857, 2011. [23] K. He, J. Sun, and X. Tang, Single image haze removal using dark channel prior, in CVPR, 2009. [24] C. Liu, R. Szeliski, S. B. Kang, C. L. Zitnick, and W. T. Freeman, Automatic estimation and removal of noise from single image, IEEE TPAMI, vol. 30, no. 2, pp. 299314, 2007. [25] R. Timofte, V. De, and L. Van Gool, Anchored neighborhood regression for fast example-based super-resolution, in ICCV, 2013. [26] Z. Yang, H. Chen, Z. Qian, Y. Yang, H. Zhang, D. Zhao, B. Wei, and Y. Xu, All-in-one medical image restoration via task-adaptive routing, in MICCAI, 2024. [27] P. Jia, R. Ning, R. Sun, X. Yang, and D. Cai, Data-driven image restoration with option-driven learning for big and small astronomical image data sets, MNRAS, vol. 501, no. 1, pp. 291301, 2021. [28] M. Y. Hossain, M. M. H. Rakib, S. Rajit, I. R. Nijhum, and R. M. Rahman, Adaptive and automatic aerial image restoration pipeline leveraging pre-trained image restorer with lightweight fully convolutional network, ESWA, vol. 259, p. 125210, 2025. [29] S. Sun, W. Ren, T. Wang, and X. Cao, Rethinking image restoration for object detection, Advances in Neural Information Processing Systems, vol. 35, pp. 44614474, 2022. [30] J. Wang, M. Xu, H. Xue, Z. Huo, and F. Luo, Joint image restoration for object detection in snowy weather, IET Computer Vision, 2024. [31] R. Yasarla and V. M. Patel, Uncertainty guided multi-scale residual learning-using cycle spinning cnn for single image de-raining, in CVPR, 2019. [32] Y. Dong, Y. Liu, H. Zhang, S. Chen, and Y. Qiao, Fd-gan: Generative adversarial networks with fusion-discriminator for single image dehazing, AAAI, vol. 34, pp. 10 72910 736, 2020. [33] X. Ji, Z. Wang, S. Satoh, and Y. Zheng, Single image deblurring with row-dependent blur magnitude, in ICCV, 2023, pp. 12 26912 280. [34] Y. Cui, S. W. Zamir, S. Khan, A. Knoll, M. Shah, and F. S. Khan, Adair: Adaptive all-in-one image restoration via frequency mining and modulation, in ICLR, 2025. [35] B. Li, X. Liu, P. Hu, Z. Wu, J. Lv, and X. Peng, All-in-one image restoration for unknown corruption, in CVPR, 2022. [36] V. Potlapalli, S. W. Zamir, S. H. Khan, and F. Shahbaz Khan, Promptir: Prompting for all-in-one image restoration, in NeurIPS, 2023. [37] T. Chen, B. Ji, T. Ding, B. Fang, G. Wang, Z. Zhu, L. Liang, Y. Shi, S. Yi, and X. Tu, Only train once: one-shot neural network training and pruning framework, Advances in Neural Information Processing Systems, vol. 34, pp. 19 63719 651, 2021. [38] P. Hu, X. Peng, H. Zhu, M. M. S. Aly, and J. Lin, Opq: Compressing deep neural networks with one-shot pruning-quantization, in Proceedings of the AAAI conference on artificial intelligence, vol. 35, no. 9, 2021, pp. 77807788. [39] S. Khaki and K. N. Plataniotis, The need for speed: Pruning transformers with one recipe, arXiv preprint arXiv:2403.17921, 2024. [40] Y. Jiang, J. Nawala, F. Zhang, and D. R. Bull, Compressing deep image super-resolution models, PCS, pp. 15, 2023. [41] B. Murugesan, S. Vijayarangan, K. Sarveswaran, K. Ram, and M. Sivaprakasam, Kd-mri: knowledge distillation framework for image reconstruction and image restoration in mri workflow, arXiv, vol. abs/2004.05319, 2020. [42] P. Wang, H. Huang, X. Luo, and Y. Qu, Data-free learning for lightweight multi-weather image restoration, in ISCAS, 2024. [43] A. Dudhane, O. Thawakar, S. W. Zamir, S. Khan, F. Khan, and M.-H. Yang, Dynamic pre-training: Towards efficient and scalable all-in-one image restoration, arXiv, vol. abs/2404.02154, 2024. [44] X. Zhou, H. Huang, Z. Wang, and R. He, Ristra: Recursive image super-resolution transformer with relativistic assessment, IEEE TMM, vol. 26, pp. 64756487, 2024. [45] J. Frankle and M. Carbin, The lottery ticket hypothesis: Finding sparse, trainable neural networks, in ICLR, 2019. [46] T. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, M. Carbin, and Z. Wang, The lottery tickets hypothesis for supervised and self-supervised pretraining in computer vision models, in CVPR, 2021, pp. 16 30616 316. [47] C. Ma, J. Jia, J. Huang, and X. Wang, Exploration and optimization of lottery ticket hypothesis for few-shot image classification task, in IPEC, 2024, pp. 221227. [48] T. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin, The lottery ticket hypothesis for pre-trained bert networks, NeurIPS, vol. 33, pp. 15 83415 846, 2020. [49] H. Yu, S. Edunov, Y. Tian, and A. S. Morcos, Playing the lottery with rewards and multiple languages: lottery tickets in rl and nlp, arXiv preprint arXiv:1906.02768, 2019. [50] Y. LeCun, J. Denker, and S. Solla, Optimal brain damage, in NeurIPS, 1989. [51] K. Belay, Gradient and mangitude based pruning for sparse deep neural networks, in Proceedings of the AAAI conference on artificial intelligence, vol. 36, no. 11, 2022, pp. 13 12613 127. [52] G. Li, C. Qian, C. Jiang, X. Lu, and K. Tang, Optimization based layerwise magnitude-based pruning for dnn compression. in IJCAI, vol. 330, 2018, pp. 23832389. [53] B. Geng, M. Yang, F. Yuan, S. Wang, X. Ao, and R. Xu, Iterative network pruning with uncertainty regularization for lifelong sentiment classification, in Proceedings of the 44th International ACM SIGIR conference on Research and Development in Information Retrieval, 2021, pp. 12291238. [54] L. Yu, X. Li, Y. Li, T. Jiang, Q. Wu, H. Fan, and S. Liu, Dipnet: Efficiency distillation and iterative pruning for image super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 16921701. [55] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, Attention is all you need, in NeurIPS, 2017. [56] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik, Contour detection and hierarchical image segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 5, pp. 898916, 2011. [57] K. Ma, Z. Duanmu, Q. Wu, Z. Wang, H. Yong, H. Li, and L. Zhang, Waterloo exploration database: New challenges for image quality assessment models, IEEE Transactions on Image Processing, vol. 26, no. 2, pp. 10041016, 2017. [58] D. Martin, C. Fowlkes, D. Tal, and J. Malik, database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics, in Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, vol. 2, 2001, pp. 416423 vol.2. [59] J.-B. Huang, A. Singh, and N. Ahuja, Single image super-resolution from transformed self-exemplars, in 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 51975206. [60] W. Yang, R. T. Tan, J. Feng, Z. Guo, S. Yan, and J. Liu, Joint rain detection and removal from single image with contextualized deep networks, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 6, pp. 13771393, 2020. [61] B. Li, W. Ren, D. Fu, D. Tao, D. Feng, W. Zeng, and Z. Wang, Benchmarking single-image dehazing and beyond, IEEE Transactions on Image Processing, vol. 28, no. 1, pp. 492505, 2019. [62] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M.-H. Yang, and L. Shao, Multi-stage progressive image restoration, in CVPR, 2021. [63] H. Tanaka, D. Kunin, D. L. Yamins, and S. Ganguli, Pruning neural networks without any data by iteratively conserving synaptic flow, Advances in neural information processing systems, vol. 33, pp. 6377 6389, 2020."
        }
    ],
    "affiliations": [
        "Dept. of Electrical and Computer Engineering University of Thessaly Volos, Greece"
    ]
}