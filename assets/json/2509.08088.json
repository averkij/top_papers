{
    "paper_title": "EnvX: Agentize Everything with Agentic AI",
    "authors": [
        "Linyao Chen",
        "Zimian Peng",
        "Yingxuan Yang",
        "Yikun Wang",
        "Wenzheng Tom Tang",
        "Hiroki H. Kobayashi",
        "Weinan Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The widespread availability of open-source repositories has led to a vast collection of reusable software components, yet their utilization remains manual, error-prone, and disconnected. Developers must navigate documentation, understand APIs, and write integration code, creating significant barriers to efficient software reuse. To address this, we present EnvX, a framework that leverages Agentic AI to agentize GitHub repositories, transforming them into intelligent, autonomous agents capable of natural language interaction and inter-agent collaboration. Unlike existing approaches that treat repositories as static code resources, EnvX reimagines them as active agents through a three-phase process: (1) TODO-guided environment initialization, which sets up the necessary dependencies, data, and validation datasets; (2) human-aligned agentic automation, allowing repository-specific agents to autonomously perform real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple agents to collaborate. By combining large language model capabilities with structured tool integration, EnvX automates not just code generation, but the entire process of understanding, initializing, and operationalizing repository functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18 repositories across domains such as image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX achieves a 74.07% execution completion rate and 51.85% task pass rate, outperforming existing frameworks. Case studies further demonstrate EnvX's ability to enable multi-repository collaboration via the A2A protocol. This work marks a shift from treating repositories as passive code resources to intelligent, interactive agents, fostering greater accessibility and collaboration within the open-source ecosystem."
        },
        {
            "title": "Start",
            "content": "EnvX: Agentize Everything with Agentic AI Linyao Chen1,4, Zimian Peng1,2,5, Yingxuan Yang3 Yikun Wang1,2,6 Wenzheng Tom Tang1 Hiroki H. Kobayashi4 Weinan Zhang2,3, 1EnvX Team 2Shanghai Innovation Institute 4The University of Tokyo 5Zhejiang University 3Shanghai Jiao Tong University 6Fudan University 5 2 0 2 9 ] . [ 1 8 8 0 8 0 . 9 0 5 2 : r Equal contribution Corresponding author."
        },
        {
            "title": "Abstract",
            "content": "The widespread availability of open-source repositories has led to vast collection of reusable software components, yet their utilization remains manual, error-prone, and disconnected. Developers must navigate documentation, understand APIs, and write integration code, creating significant barriers to efficient software reuse. To address this, we present EnvX, framework that leverages Agentic AI to agentize GitHub repositories, transforming them into intelligent, autonomous agents capable of natural language interaction and inter-agent collaboration. Unlike existing approaches that treat repositories as static code resources, EnvX reimagines them as active agents through three-phase process: (1) TODO-guided environment initialization, which sets up the necessary dependencies, data, and validation datasets; (2) human-aligned agentic automation, allowing repository-specific agents to autonomously perform realworld tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple agents to collaborate. By combining large language model capabilities with structured tool integration, EnvX automates not just code generation, but the entire process of understanding, initializing, and operationalizing repository functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18 repositories across domains such as image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX achieves 74.07% execution completion rate and 51.85% task pass rate, outperforming existing frameworks. Case studies further demonstrate EnvXs ability to enable multi-repository collaboration via the A2A protocol. This work marks shift from treating repositories as passive code resources to intelligent, interactive agents, fostering greater accessibility and collaboration within the opensource ecosystem. Keywords: Agentization, Agentic AI, Code Repository, Multi-Agent System"
        },
        {
            "title": "Introduction",
            "content": "In the field of artificial intelligence, an agent is an autonomous system capable of perceiving its environment, reasoning about goals, and taking actions to achieve them. Agentization (Acharya et al., 2025; Sapkota et al., 2025; Yang et al., 2025b) refers to the process of transforming various entities, such as environments, code, and services, into agents that not only retain their original functionalities but also gain the capacity for autonomous action and communication. This concept lays the foundation for EnvX, novel framework designed to \"agentize everything\" in the software ecosystem. Through the power of agentic AI, EnvX transforms open-source repositories into intelligent, interactive agents that not only retain their core functionalities but can also autonomously respond to natural language instructions, collaborate with other agents, and adapt to changing requirements. 1 The proliferation of open-source software repositories has fundamentally transformed modern software development, with platforms like GitHub hosting millions of projects that serve as building blocks for countless applications. However, the current paradigm of repository utilization (Asadi et al., 2019; Ma et al., 2025) remains fundamentally manual: developers must navigate documentation, understand APIs, examine code examples, and write integration code before they can leverage repositorys functionality. This process is not only time-consuming but also error-prone, creating significant barriers to efficient software reuse and collaboration. Recent advances in Large Language Models (LLMs) have sparked efforts to automate this process (Chen et al., 2025; Luo et al., 2024; Wang et al., 2025a), with systems demonstrating capabilities in repository understanding, code generation, and automated task execution. However, these approaches primarily treat repositories as sources for code generation or targets for modification, rather than transforming them into interactive agents that users can directly interact with through natural language. The challenge of enabling seamless natural language communication with repository functionalities remains largely unaddressed. This paper introduces EnvX, novel framework that automatically transforms arbitrary GitHub repositories into agents with agentic automation and agentic communication capacity. Unlike traditional NL2Code approaches (Zan et al., 2023) that focus on generating new code, EnvX enables users to directly invoke existing repository functionalities through natural language instructions. More importantly, EnvX extends beyond single-agent interactions by implementing the Agent-to-Agent (A2A) protocol, enabling multiple repository agents to collaborate and form an ecosystem of intelligent software components. The agentization of arbitrary repositories presents several fundamental challenges. Repositories exhibit extreme heterogeneity in structure, dependencies, and usage patterns. Understanding repository semantics transcends mere code parsing, which means the framework must comprehend intended functionality, identify entry points, and infer usage patterns from often incomplete documentation. Additionally, enabling meaningful inter-agent communication requires establishing common protocols while preserving repository-specific capabilities. Our key insight is that by combining LLM capabilities with structured tool integration, we can automate not just code generation but the entire process of understanding, initializing, and operationalizing repository functionality. This shift from treating repositories as passive code resources to reimagining them as active, intelligent agents represents fundamental paradigm change in how developers discover, understand, and utilize software components. We evaluate EnvX on GitTaskBench, demonstrating its effectiveness across diverse domains including image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX significantly outperforms existing code agent frameworks, validating our hypothesis that systematic agentization can make complex repositories accessible through natural language interaction. The remainder of this paper is organized as follows: Section 2 reviews related work. Section 3 presents the EnvX framework and our three-phase agentization process. Section 4 describes our experimental setup and results. Section 5 discusses implications and limitations. Section 6 concludes with future directions."
        },
        {
            "title": "2 Related Work",
            "content": "2.1 Language Models as Agents The integration of Large Language Models (LLMs) (DeepSeek-AI et al., 2025; OpenAI et al., 2024) as autonomous agents (Li et al., 2023; Huang et al., 2024) has emerged as transformative paradigm, enabling them to plan, reason, and execute complex tasks. ReAct (Yao et al., 2023) exemplifies this by combining reasoning and acting, allowing LLMs to generate both reasoning traces and taskspecific actions for autonomous problem solving. Parallel efforts have explored multi-agent systems (MAS) (Yang et al., 2024b; Zhang et al., 2025b), where multiple LLM agents collaborate on complex tasks. In software engineering, ChatDev (Qian et al., 2024) demonstrates this potential by simulating software company with role-based agents, while MetaGPT (Hong et al., 2024) extends the approach with standardized operating procedures inspired by human practices. These advances pave the way for structured, collaborative interactions in software development. What differentiates our work is the introduction of an Agent-to-Agent (A2A) protocol (Google, 2025; Yang et al., 2025a), which enables 2 multiple repository agents to communicate, collaborate, and coordinate on tasks, thereby forming cohesive ecosystem of intelligent components capable of addressing complex challenges."
        },
        {
            "title": "2.2 Software Engineering for Repository",
            "content": "Another important line of work focuses on software repositories themselves, moving beyond their role as static code collections toward active, intelligent entities. RepoAgent (Luo et al., 2024) leverages LLMs to automatically generate and maintain repository documentation, improving developer comprehension and usability of complex codebases. Building on this idea, RepoMaster (Wang et al., 2025a) autonomously explores and analyzes GitHub repositories, including structures and dependencies, to enable context-aware code execution and task solving, achieving strong performance on benchmarks such as GitTaskBench (Ni et al., 2025) and OpenAct (Lyu et al., 2025). From data and training perspective, RepoForge (Chen et al., 2025) complements these efforts by constructing large-scale executable environments and providing efficient labeling pipelines for agent training in software engineering. Despite these advances in repository intelligence, most existing systems still focus primarily on code modification and issue resolution rather than enabling natural language interaction. SWEAgent (Yang et al., 2024a) equips LLMs with specialized interface for navigating and editing codebases, OpenHands (Wang et al., 2025b) provides flexible platform for building agents that interact with software environments, and Aider (aid) delivers terminal-based assistant tightly integrated with repositories. While these approaches excel at automated code editing and bug fixing, they treat repositories as targets for modification rather than as interactive partners. They still demand significant manual effort to fully understand repository functionality and fall short of transforming repositories into agents capable of natural language interaction."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we present EnvX, novel LLM-based framework designed to transcend purely toolcalling workflow by incorporating carefully engineered tools that enable the systematic agentization of arbitrary repositories. Distinct from prior approaches, EnvX seamlessly integrates specialized tools into the agentization pipeline, thereby transforming the process into one that is both reliable and efficient. Specifically, Section 3.1 delineates the overall system workflow, while Section 3.2 elaborates on the design and integration of the key tools. 3.1 System Overview As illustrated in Fig. 1, the agentization of repository within EnvX proceeds through three progressive phases. In the first phase, the system establishes the computational environment necessary for interacting with the target repository. This requires the agent to acquire comprehensive understanding of the repositorys codebase and its accompanying documentation (e.g., README files). During this stage, the agent systematically explores the repository and generates structured representation of its context to support subsequent phases. In the second phase, EnvX instantiates repository-specific agent capable of addressing user queries and tasks in manner that emulates human reasoning and operations. The repository agent is derived by integrating the environment constructed in Phase 1 with the extracted repository context, thereby enabling task execution through agentic automation. In the third phase, EnvX augments the repository agent with communication capabilities based on the Agent-to-Agent (A2A) protocol. This protocol establishes standardized schema for inter-agent communication through the generation of agent cards and the extraction of agent skills. Consequently, the repository agent acquires the ability to interact, collaborate, and coordinate with other agents, thereby facilitating multi-agent cooperation and enhancing system-level scalability and robustness. 3.2 TODO-Guided Environment Initialization As depicted in Fig. 1, Phase 1 focuses on constructing comprehensive environment that empowers the agent to operationalize the functionalities of the original repository. Unlike traditional approaches that 3 (a) Phase 1: Agentic Environment Setting (b) Phase 2: Agentic Automation & Phase 3: Agentic Communication Figure 1: Overview of EnvX workflow. Three phases are defined for the operation, including the Agentic Environment Setting phase, Agentic Automation phase for solving real-world user queries, and Agentic Communication Phase to introduce generated repository agent to multi-agent communication and collaboration. narrowly define the environment as collection of packages and dependencies, EnvX conceptualizes the environment as comprising three critical components: (1) dependencies and packages, (2) data and model artifacts, and (3) validation datasets. This broader definition ensures that the environment can robustly support repository operations while providing verifiable reliability through validation data. central mechanism in this phase is the generation of structured TODO list. Based on an in-depth analysis of guidance documents (e.g., README files and technical manuals), EnvX automatically produces comprehensive set of initialization tasks. dedicated TODO management tool subsequently maintains and executes these tasks, orchestrating the entire environment initialization workflow. Moreover, the system iteratively revises the TODO list in response to execution errors, thereby improving adaptability. By embedding TODO-driven control into initialization, EnvX not only systematizes the workflow and enhances goal clarity and decomposition, but also strengthens monitoring and selfreflection within the agentic system. 3.3 Human-Aligned Agentic Automation During Phase 2, EnvX constructs repository agents that autonomously perform real-world tasks through tool-mediated automation. To ensure alignment with human usage scenarios, we design meta-agent framework equipped with widely adopted development and management tools. By leveraging the environment initialized in Phase 1 and the repository context extracted from the codebase, the meta-agent is agentized as repository-specific agent. Compared with meta-agent, the agentized repository agent understands and integrates the functionalities in the original repository, with the capacity to call the functionalities to solve real-world tasks. 4 These agents are capable of receiving diverse user queries and tasks and producing responses in manner that aligns with human expectations of utility, reliability, and interpretability. When the users interact with system via the input queries, the repository agent tries to reason over given queries, and invokes tools and repository functionalities to complete the requirements of the input queries."
        },
        {
            "title": "3.4 Agentization for Agentic Communication",
            "content": "Research on multi-agent communication (Sukhbaatar et al., 2016; Zhang et al., 2025a) has garnered substantial scholarly interest, as it enables distributed systems to achieve coordination, cooperation, and collective problem-solving beyond the capacity of individual agents. Moreover, effective communication mechanisms are essential for ensuring the scalability, robustness, and adaptability of multi-agent systems. In Phase 3, EnvX equips the repository agent with communication competencies through the A2A protocol. This protocol prescribes standardized communication interface, operationalized via the construction of agent cards and the formalization of agent skills using predefined A2A toolbox. By implementing an A2A communication port grounded in the repository context and initialized environment, EnvX facilitates seamless inter-agent collaboration and enables higher-order forms of agentic intelligence. 3.5 Agentic Tool Integration Section 3.1 outlined the overall agentization pipeline, which operates through pure tool-calling paradigm. Within this paradigm, tools assume pivotal role in enabling the diverse functionalities required by the agent. We categorize the tools into six principal classes: Basic Tools: Fundamental utilities that support core agent functions such as reasoning, file reading and writing, script execution, and task completion. These tools also serve as the foundation of the meta-agent, ensuring that the repository agent achieves baseline functionality. File Download Tool: utility that enables agents to acquire necessary files, particularly during the environment setup phase, thereby facilitating the preparation of datasets and model checkpoints required for downstream tasks. TODO Management Tool: Central to Phase 1, this tool provides three essential capabilities: (1) initialization of structured TODO lists, (2) automatic generation of validation data for new tasks, and (3) systematic verification of task completion. By integrating these capabilities, the tool ensures that initialization workflows are reliable, traceable, and aligned with the repositorys requirements. Dependency Management Tool: unified mechanism for handling repository-specific dependencies. Given that repositories may adopt heterogeneous initialization practices (e.g., requirements.txt, Conda environments), this tool abstracts and manages dependency installation to guarantee consistent execution environment. Code Knowledge Graph Tool: semantic analysis component that extracts the reposIt enables the construction of itorys primary functionalities and potential applications. Code Knowledge Graph (CKG), which agents can query during task automation to support reasoning and enhance interpretability. A2A Generation Tool: specialized module that endows repository agents with agentic communication abilities. Following human-like operational logic, the tool identifies agent skills, initializes services, generates corresponding implementation code, and produces agent cards, thereby enabling seamless integration with other agents through the A2A protocol."
        },
        {
            "title": "4 Empirical Study",
            "content": "In this section, we report the preliminary experimental results of EnvX on open benchmarks and provide case studies."
        },
        {
            "title": "4.1 Benchmarks and Metrics",
            "content": "To verify the effectiveness of our system, we adopt GitTaskBench (Ni et al., 2025) as our evaluation benchmark. GitTaskBench targets open-source repositories, thereby reflecting practical, real-world tasks. The benchmark comprises 18 repositories spanning multiple domains (image, speech, document, video, and others), enabling assessment of agent capabilities under complex, realistic scenarios. It further provides 54 human-validated tasks and rigorous evaluation pipeline to ensure trustworthy assessment. Following the design of GitTaskBench, we employ the following metrics: Execution Completion Rate (ECR): Measures whether the repository can be executed to produce evaluable outputs by inspecting the generated files. Specifically, it verifies that the expected output files exist, are non-empty, and can be processed by the official evaluation scripts. Task Pass Rate (TPR): Computed on top of ECR to quantify task-level performance quality. GitTaskBench provides domain-specific evaluation scripts that compare the generated outputs with ground truth using appropriate criteria for each domain. This metric reflects the overall task success rate of repository agent. Token Costs: Quantifies efficiency in terms of LLM usage. We report both input and output tokens. 4.2 Evaluation Setup We compare our system against three existing coding-agent frameworks designed for repository-level task execution, using three widely adopted LLM backbones. Details are as follows. 4.2.1 Baselines As described above, we implement the following baselines for comparison: OpenHands (Wang et al., 2025b): An LLM-driven coding-agent architecture that provides sandboxed environments for code execution and API interactions. We deploy the repositories in local sandboxes and evaluate each query in its corresponding environment. Aider (aid): terminal-based AI coding agent that operates on top of existing repositories/codebases. We execute each task within the corresponding repository following Aiders standard workflow. SWE-Agent (Yang et al., 2024a): An LLM-driven agent for software engineering, widely used for autonomous GitHub repository understanding and issue resolution. We evaluate it using its default workflow to assess its agentic capabilities. We use three widely adopted LLMs: GPT-4o (OpenAI et al., 2024), GPT-4.1 (OpenAI, 2024), and Claude 3.7 (Anthropic, 2024) Sonnet as the backbone models for both our system and the baselines, enabling comprehensive and fair comparison. 4.2.2 Implementation Details In our experiments, we implement the EnvX system with the tools described in Section 3.1, issuing one function call per round to complete environment setup, agentic automation, and agent communication. We cap the maximum number of steps at 200 and allow parallel tool calls within the workflow. To mitigate potential issues caused by network or system instability, we set the maximum number of retries to 10. Because the original benchmark evaluation scripts were not directly compatible with our system, we configured EnvX to write outputs to the designated directories; we then determine execution success and task success by verifying the outputs and comparing them against the ground truth. Framework LLM ECR (%) TPR (%) Input Tokens (k) Output Tokens Aider SWE-Agent OpenHands EnvX GPT-4o GPT-4.1 Claude 3.5 GPT-4o GPT-4.1 Claude 3.7 GPT-4o GPT-4.1 Claude 3.7 GPT-4o GPT-4.1 Claude 3.7 5.56 11.11 16.67 17.58 38.89 64.81 21.30 55.56 72.22 42.59 68.52 74.07 1.85 7.41 12.96 10.19 31.48 42.59 14.82 42.59 48.15 33.33 46.30 51.85 10.67 14.83 7.48 275.53 301.11 552.79 760.53 465.94 9501.25 811.02 380.20 562.56 492.67 734.17 534.00 1282.70 2098.33 807.63 3990.31 1535.47 85033.05 4506.83 1648.43 5686. Table 1: Comparison of different LLMs across frameworks (Aider, SWE-Agent, OpenHands) with evaluation metrics: ECR, TPR, Input Tokens, Output Tokens, and Cost. Bold indicates best accuracy results. For the baselines, we follow the official experimental settings and the reporting result of GitTaskBench (Ni et al., 2025). 4.3 Experimental Analysis The main experimental results are reported in Table 1. On GitTaskBench, our system achieves state-ofthe-art performance for repository automation. With Claude 3.7 Sonnet as the backbone, our system attains TPR exceeding 50%, improves upon prior work by 7.6%, and achieves the best ECR to date at 74.07%. Furthermore, owing to the well-designed tool workflow, our system exhibits strong robustness across backbone models. On GPT-4.1, it improves ECR by 23.40 percentage points and TPR by 8.72 percentage points over the previous best. Moreover, with GPT-4o, we observe relative improvements of 100% in ECR and 124.90% in TPR, highlighting the substantial potential to enhance agentic capabilities. On the other hand, our system is more efficient than prior work in repository automation, especially with larger-parameter models. Compared with OpenHands (Wang et al., 2025b) which performs comparably yet consumes more than 10 the input and output tokens when using Claude 3.7 Sonnet. We conclude that our system is markedly more efficient while maintaining effectiveness. For smaller models, although our approach incurs additional tokens due to tool calls, it yields significant performance gains. Moreover, when comparing GPT-4o and GPT-4.1, which share the same architecture but differ in size, the token cost decreases with scale, likely because larger models plan more effectively and make fewer erroneous steps. This suggests considerable headroom for efficient agentic automation when stronger backbones are incorporated. 4.4 Case Study In this section, we demonstrate the potential of repository agents in addressing real-world tasks through agentic communication. As illustrated in Fig. 2, when tackling complex tasks that depend on multiple repositories, the system first transforms each repository into repository agent and generates corresponding agent cards containing domain knowledge and invocation methods. The router agent within the A2A system then coordinates these repository agents, invoking them individually and integrating their functionalities into coherent workflow. This workflow converts an input prompt into an output figure with specialized styles. This case study highlights the reliability of the agentization process enabled by EnvX and underscores its immense potential to harness the value of the open-source ecosystem for real-world applications. 7 Figure 2: Case study on repository agents collaboration. Three repositories are agentized by EnvX. Router agents in A2A system obtain the agent skills via agent cards, solve complex real-world tasks under the collaboration between repository agents."
        },
        {
            "title": "5 Discussion",
            "content": "EnvX demonstrates that agentization, which transforms heterogeneous repositories into interactive agents and coordinates them via the Agent-to-Agent (A2A) protocol, can reliably address practical tasks. Nevertheless, several limitations remain. First, our current evaluation primarily relies on scripted oracles and curated tasks, which leaves important gaps in coverage for long-horizon coordination, robustness under distribution shift, and security-in-the-loop failure modes. Second, while we have validated hundreds of A2A interactions in practice, the verification signals are still coarse-grained at times and thus constrain the automatic synthesis and selection of high-quality A2A agents. Looking ahead, we will (i) scale A2A validation and make it more reliable by systematically generating richer verification data and oraclescombining inputoutput pairs, property-based checks, and metamorphic relationsto provide precise, reproducible pass/fail signals for agent synthesis; (ii) strengthen the standardization of agent cards and skill schemas with explicit contracts, versioning, and provenance logging to support safe reuse; and (iii) study costquality trade-offs across data, tools, and model backbones to guide principled scaling of agentization. We believe these directions will transform A2A from validated prototype into dependable foundation for building, verifying, and maintaining large ecosystems of repository agents, thereby maximizing the potential of the open-source ecosystem."
        },
        {
            "title": "6 Conclusion",
            "content": "Overall, this research introduces EnvX, novel agent system that transforms raw open-source repositories into intelligent repository agents capable of providing comprehensive automation and communication services. We demonstrate the effectiveness and robustness of our approach through extensive experiments and real-world case studies, highlighting how each component of the methodology contributes to successful agentization. Beyond performance improvements, EnvX fosters sustainable ecosystem of collaborative agents by converting existing repositories into communicative agents and orchestrating their interactions to address complex real-world problems. We believe that agentizing repositories in this way will inspire future research on multi-agent collaboration and further advance the open-source community."
        },
        {
            "title": "References",
            "content": "Aider: Ai pair programming in your terminal. https://aider.chat/. Accessed: 2025-09-06. Deepak Bhaskar Acharya, Karthigeyan Kuppan, and Divya. Agentic ai: Autonomous intelligence for complex goalsa comprehensive survey. IEEe Access, 2025. Anthropic. Claude sonnet 3.7. https://www.anthropic.com, 2024. Large language model. Shahla Asadi, Rusli Abdullah, Yusmadi Yah, and Shah Nazir. Understanding institutional repository in higher learning institutions: systematic literature review and directions for future research. IEEE Access, 7:3524235263, 2019. Zhilong Chen, Chengzong Zhao, Boyuan Chen, Dayi Lin, Yihao Chen, Arthur Leung, Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Haoxiang Zhang, Aaditya Bhatia, Chong Chun Yong, and Ahmed E. Hassan. Repoforge: Training sota fast-thinking swe agent with an end-to-end data curation pipeline synergizing sft and rl at scale, 2025. URL https://arxiv.org/abs/2508.01550. DeepSeek-AI, Aixin Liu, Bei Feng, Zizheng Pan, et al. Deepseek-v3 technical report, 2025. URL https://arxiv.org/abs/2412.19437. Google. A2a: Agent2agent protocol, 2025. URL https://github.com/google/A2A. Accessed: 202504-21. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. MetaGPT: Meta programming for multi-agent collaborative framework. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=VtmBAGCN7o. Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. Understanding the planning of llm agents: survey, 2024. URL https://arxiv.org/abs/2402.02716. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for \"mind\" exploration of large language model society, 2023. URL https://arxiv.org/abs/2303.17760. Qinyu Luo, Yining Ye, Shihao Liang, Zhong Zhang, Yujia Qin, Yaxi Lu, Yesai Wu, Xin Cong, Yankai Lin, Yingli Zhang, Xiaoyin Che, Zhiyuan Liu, and Maosong Sun. Repoagent: An llm-powered open-source framework for repository-level code documentation generation, 2024. URL https: //arxiv.org/abs/2402.16667. Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Cheng Qian, Zihe Wang, Yujia Qin, Yining Ye, Yaxi Lu, Chen Qian, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, and Maosong Sun. Enhancing opendomain task-solving capability of LLMs via autonomous tool integration from GitHub. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar, editors, Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1725717277, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.845. URL https://aclanthology.org/2025. acl-long.845/. Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, and Yongbin Li. Alibaba lingmaagent: Improving automated issue resolution via comprehensive repository exploration. In Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering, pages 238249, 2025. Ziyi Ni, Huacan Wang, Shuo Zhang, Shuo Lu, Ziyang He, Wang You, Zhenheng Tang, Yuntao Du, Bill Sun, Hongzhang Liu, Sen Hu, Ronghao Chen, Bo Li, Xin Li, Chen Hu, Binxing Jiao, Daxin Jiang, and Pin Lyu. Gittaskbench: benchmark for code agents solving real-world tasks through code repository leveraging, 2025. URL https://arxiv.org/abs/2508.18993. OpenAI. Gpt-4.1 technical report. https://openai.com/research/gpt-4-1, 2024. Accessed: 202509-09. OpenAI, :, Aaron Hurst, Adam Lerer, Adam P. Goucher, Yuchen Zhang, Yujia Jin, Yunxing Dai, Yury Malkov, et al. Gpt-4o system card, 2024. URL https://arxiv.org/abs/2410.21276. Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun. Chatdev: Communicative agents for software development, 2024. URL https://arxiv.org/abs/2307.07924. Ranjan Sapkota, Konstantinos Roumeliotis, and Manoj Karkee. Ai agents vs. agentic ai: conceptual taxonomy, applications and challenges. arXiv preprint arXiv:2505.10468, 2025. Sainbayar Sukhbaatar, Arthur Szlam, and Rob Fergus. Learning multiagent communication with backpropagation, 2016. URL https://arxiv.org/abs/1605.07736. Huacan Wang, Ziyi Ni, Shuo Zhang, Shuo Lu, Sen Hu, Ziyang He, Chen Hu, Jiaye Lin, Yifu Guo, Ronghao Chen, Xin Li, Daxin Jiang, Yuntao Du, and Pin Lyu. Repomaster: Autonomous exploration and understanding of github repositories for complex task solving, 2025a. URL https://arxiv.org/abs/2505.21577. Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, and Graham Neubig. Openhands: An open platform for ai software developers as generalist agents, 2025b. URL https://arxiv.org/abs/2407.16741. John Yang, Carlos E. Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering, 2024a. URL https://arxiv.org/abs/2405.15793. Yingxuan Yang, Qiuying Peng, Jun Wang, and Weinan Zhang. Llm-based multi-agent systems: Techniques and business perspectives. 2024b. URL https://api.semanticscholar.org/CorpusID: 274165614. Yingxuan Yang, Huacan Chai, Yuanyi Song, Siyuan Qi, Muning Wen, Ning Li, Junwei Liao, Haoyi Hu, Jianghao Lin, Gaowei Chang, Weiwen Liu, Ying Wen, Yong Yu, and Weinan Zhang. survey of ai agent protocols, 2025a. URL https://arxiv.org/abs/2504.16736. Yingxuan Yang, Mulei Ma, Yuxuan Huang, Huacan Chai, Chenyu Gong, Haoran Geng, Yuanjian Zhou, Ying Wen, Meng Fang, Muhao Chen, Shangding Gu, Ming Jin, Costas Spanos, Yang Yang, Pieter Abbeel, Dawn Song, Weinan Zhang, and Jun Wang. Agentic web: Weaving the next web with ai agents, 2025b. URL https://arxiv.org/abs/2507.21206. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models, 2023. URL https://arxiv.org/abs/ 2210.03629. Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Yongji Wang, and JianGuang Lou. Large language models meet nl2code: survey, 2023. URL https://arxiv.org/abs/ 2212.09420. Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Tianlong Chen, and Dawei Cheng. G-designer: Architecting multi-agent communication topologies via graph neural networks, 2025a. URL https://arxiv.org/abs/2410.11782. Yiqun Zhang, Hao Li, Chenxu Wang, Linyao Chen, Qiaosheng Zhang, Peng Ye, Shi Feng, Daling Wang, Zhen Wang, Xinrun Wang, Jia Xu, Lei Bai, Wanli Ouyang, and Shuyue Hu. The avengers: simple recipe for uniting smaller language models to challenge proprietary giants, 2025b. URL https://arxiv.org/abs/2505.19797."
        }
    ],
    "affiliations": [
        "EnvX Team",
        "Fudan University",
        "Shanghai Innovation Institute",
        "Shanghai Jiao Tong University",
        "The University of Tokyo",
        "Zhejiang University"
    ]
}