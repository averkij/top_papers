{
    "paper_title": "A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects",
    "authors": [
        "Johan Lin√•ker",
        "Cailean Osborne",
        "Jennifer Ding",
        "Ben Burtenshaw"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have a variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building a more open future for AI."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 2 ] . [ 1 7 9 3 5 2 . 9 0 5 2 : r CARTOGRAPHY OF OPEN COLLABORATION IN OPEN SOURCE AI: MAPPING PRACTICES, MOTIVATIONS, AND GOVERNANCE IN 14 OPEN LARGE LANGUAGE MODEL PROJECTS Johan Linaker RISE Research Institutes of Sweden Lund, Sweden Jennifer Ding Boundary Object Studio London, UK Cailean Osborne University of Oxford Oxford, UK Ben Burtenshaw Hugging Face Antwerp, Belgium"
        },
        {
            "title": "ABSTRACT",
            "content": "The proliferation of open large language models (LLMs) is fostering vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building more open future for AI. Keywords Open source large language models artificial intelligence open collaboration open science"
        },
        {
            "title": "Introduction",
            "content": "The culture and practices of open collaboration in artificial intelligence (AI) research and development (R&D) have evolved significantly in the last 20 years. In 2007, 16 eminent AI scientists got together to bring attention to the fact that while the machine learning (ML) research community had produced many powerful algorithms, their true potential was unrealized because implementations were not openly shared [1]. The 2010s saw the emergence of open source software (OSS) ecosystems that have become key pillars of AI R&D [2], in particular foundational ML libraries like scikit-learn [3] and deep learning frameworks like PyTorch [4]. Platforms like arXiv became widely used to rapidly disseminate AI research [5] and initiatives like CommonCrawl [6] and ImageNet [7] facilitated collaborations on All authors contributed equally to this study. Corresponding author: johan.linaker@ri.se Cartography of Open Collaboration in Open Source AI Linaker et al. datasets for training AI models. While the open release of foundational ML models, such as BERT [8] and YOLO [9], led to rise in adoption and application of these models and the growth of the fields of Natural Language Processing and Computer Vision respectively, the development and adoption of open AI models in this period remained limited. Nowadays, AI R&D thrives on the activity of global practitioners from many different kinds of organizations, who engage to share knowledge and collaborate on the development and maintenance of various projects and artifacts in the wider open source AI ecosystem, spanning OSS, open datasets, open models, open science projects, open standards, and open hardware [10]. In particular, the widespread proliferation of open modelsthat is, AI models where the model parameters (i.e., weights and biases) and model architecture are publicly released under open source licenses along with model documentation [10]is fostering vibrant ecosystem of collaborative research and innovation in AI, with almost two million models, including many powerful large language models (LLMs), now hosted on Hugging Face Hub [11]. With growing community of millions of practitioners around the world releasing, reusing, and remixing millions of artifacts on daily basis, progress on open LLMs is accelerating and simultaneously branching into diverse application areas for domain and regional relevance. Researchers have begun to study developer practices in the burgeoning open source AI ecosystem, providing four key insights for this study. First, despite the proliferating number of open models, their reuse is highly concentrated; for example, only 1% of models on Hugging Face Hub account for 99% of all downloads [12]. Second, developers on Hugging Face Hub exhibit nomadic engagement patterns, engaging intensely with models upon their release but quickly migrating to newer models and focusing on model applications rather than sustained collaboration [13]. Third, model maintenance activity tends to focus on perfective tasks like performance enhancements, marking key difference from typical OSS maintenance activities like bug fixing or feature development [14]. Fourth, while most open LLMs follow develop-then-release approach with minimal collaboration before the release, grassroots projects like EleutherAI [15], the BigScience Workshop [16, 17], and Marin [18] have pioneered community-led development of open LLMs (e.g., Pythia, BLOOM) and related artifacts, including open datasets (e.g., ROOTS) and open source LLM training and evaluation frameworks (e.g., GPT-NeoX, LM Evaluation Harness, lighteval). Beyond these insights, we still have limited understanding of the open collaboration methods that are used throughout the lifecycle of open LLMs, from the earliest pre-training stages through to downstream reuse and derivative development by the wider community. This gap limits our ability to effectively foster the open source AI ecosystem, such as facilitating participation, connecting related projects, recommending or improving governance frameworks, and targeting support for under-resourced areas. We address this gap in our knowledge through an exploratory analysis of open collaboration on open LLMs, guided by the following research questions (RQs): (RQ1) Where and how does open collaboration take place across the open LLM lifecycle? (RQ2) What incentivizes engagement in the collaborative development of open LLMs? (RQ3) How are open collaborations on open LLMs coordinated and governed? To answer these RQs, we conducted semi-structured interviews with 17 developers from 14 open LLM projects, which represented diverse organizational contexts (grassroots projects, research institutes, startups, Big Tech companies) and geographic regions (North America, Europe, Africa, Asia), thus providing comprehensive perspective on emerging approaches to open LLM collaboration around the world. We make three key contributions to research and practice. First, open collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing range of artifacts that are used to develop, evaluate, and improve LLMs, including datasets (e.g., training, safety, alignment), benchmarks, open source frameworks, leaderboards, knowledge sharing forums, and compute partnerships. Second, open LLM developers are driven by variety of social, economic, and technological motivations, from democratizing access to AI and expanding language representation to ecosystem building and promoting open science. Third, the sampled open LLM projects exhibit five distinct governance models: single company projects, single research institute projects, multi-organizational research institute projects, non-profitsponsored grassroots projects, and company-sponsored grassroots projects. These governance models differ in the centralization of control and community engagement strategies used throughout the open LLM lifecycle. The paper is structured as follows. In 2, we define key terms. In 3, we survey prior work on open collaboration in AI R&D. In 4, we present our research design. In 5-7, we present the findings on collaboration on-ramps and challenges throughout the open LLM lifecycle (RQ1), developer motivations (RQ2), and collaboration and governance frameworks in open LLM projects (RQ3). In 8, we provide recommendations for diverse stakeholders seeking to support the global community of practitioners building more open future for AI. In 9, we conclude the paper. 2 Cartography of Open Collaboration in Open Source AI Linaker et al. i t I L O 4 1 r A u e i t b o p o p o C : 1 g 3 Cartography of Open Collaboration in Open Source AI Linaker et al."
        },
        {
            "title": "2 Key terms",
            "content": "2.1 LLMs LLMs are deep learning models, typically based on transformer architectures [19], that contain billions to trillions of parameters and are trained on extensive text corpora to learn statistical patterns in language, enabling them to generate coherent text, answer questions, and perform various language tasks without task-specific training. The term large language model was popularized by Brown et al. from OpenAI in their GPT-3 paper [20]. 2.2 Open Collaboration We define open collaboration as collaborative and coordinated production process between number of individuals, where publicly available common is used as input, and the output from the process is released back to the originating common [21, 22]. common in our context refers to an open LLM project and its various artifacts. This definition encompasses both direct collaborations (i.e. where two or more parties work together on the common) and indirect collaborations (i.e. development that is facilitated by open sharing, consisting mainly of reuse). 2.3 Open LLM development and reuse lifecycle We define the development and reuse lifecycle of open LLMs (henceforth: open LLM lifecycle) as the complete process from the beginning of the activities required to train an LLM through to how it is reused and redistributed after being publicly released in repository on platform like Hugging Face Hub, GitHub, or Modelscope. Our definition builds on Ding et al.s [23] ML model pipeline framework, which maps the technical pipeline of developing ML models, encompassing data collection, model training, and model deployment, alongside governance considerations that determine the possibility for input from external stakeholders (i.e., collaboration on-ramps). We extend this framework to consider not only the pre-release development pipeline of LLMs but also post-release development and reuse activities, such as model fine-tuning or the collection of community feedback, thus providing more comprehensive view of open collaboration that may take place throughout the complete lifecycle of an open LLM. In particular, we focus on three stages in this lifecycle: pre-training, post-training, and post-release reuse. 2.3.1 Pre-training Model pre-training is the initial and most resource-intensive stage in the development of LLMs. It involves training model from scratch on massive amounts of text data to learn general language understanding and generation capabilities. This foundational training allows the model to grasp grammar, context, and range of knowledge. Key inputs for this stage include datasets, compute resources, the underlying software frameworks, and the specific model architecture design and implementation. The outputs of pre-training are model checkpoints, which are snapshots of the trained model at its best evaluation state, and initial evaluations to assess its performance on benchmark tasks. The process often involves defining the models goals and requirements, followed by collecting and preparing pre-training data, ensuring its quality and relevance to the intended capabilities of the model. The resulting output of this process is often referred to as base model, which is the term we will use in this paper. 2.3.2 Post-training Model post-training is the refinement stage that focuses on making pre-trained (base) model specialized, aligned, or deployment-ready before being officially released. This pre-release stage typically involves techniques, such as supervised fine-tuning (SFT) using curated instruction-response pairs to teach the model to follow specific formats and tasks; reinforcement learning from human feedback (RLHF) or constitutional AI methods to align the model with human preferences and values; and safety filtering or guardrails to reduce harmful outputs. Key inputs include the pre-trained model checkpoints, supervised datasets, human preference data, and compute for iterative training. The process can also incorporate human annotators who provide feedback on model outputs, enabling the model to learn desired behaviors and response styles. Outputs of post-training include the refined model weights, safety evaluations, and performance benchmarks across various tasks. 2.3.3 Post-release reuse Open LLMs are uploaded to platforms like Hugging Face Hub, GitHub, or Modelscope, and once publicly available they can be reused in myriad of ways, including deployment across different environments, fine-tuning for specialized languages or domains, quantization to reduce computational requirements, knowledge distillation to create smaller models, and architectural modifications for specific hardware constraints, among others. This often involves taking 4 Cartography of Open Collaboration in Open Source AI Linaker et al. base model and making targeted modifications (e.g., finetune, quantize, distill models) to create derivative model that then may be shared back to the community by uploading them to repositories on the aforementioned platforms. This open ecosystem also facilitates community feedback, as users can share performance insights, identify failure modes, and suggest priorities for improvements based on real-world deployment experiences. Such feedback can reach base model developers through multiple channels, including GitHub issues for technical problems, discussions in Hugging Face Hub model repositories, and community communications via Discord, Slack, Reddit, or mailing lists."
        },
        {
            "title": "3 Related work",
            "content": "3.1 Open collaboration in AI R&D The practices and culture of open collaboration in AI R&D has undergone significant shifts in the last two decades. While researchers lamented the scarcity of OSS for ML in 2007 [1], nowadays AI R&D is hardly imaginable without open source ecosystems [2] and collaboration in grassroots communities like scikit-learn [24, 3], foundation-hosted ecosystems the LF AI & Data Foundation and PyTorch Foundation [25], as well as company-led ecosystems like PyTorch (prior to its donation to the Linux Foundation) and TensorFlow [26]. Beyond OSS, open collaboration in AI R&D encompasses collaboration on open datasets, open science practices, open standards, open hardware, and increasingly open models [10]. For example, platforms like arXiv are widely used to rapidly disseminate cutting-edge AI research [5], and initiatives like CommonCrawl [6] and ImageNet [7] maintain datasets for training AI models. Recently, open source AI practitioners have called for building an open human feedback ecosystem to faciliate AI alignment research, oriented around the sharing and collaborative annotation of user feedback to AI systems [27]. After years of debate about whether and how generative AI models, in particular LLMs, can be openly and responsibly released [28], since 2021 the practice of making LLM weights publicly available in open repositories has become popular choice for AI practitioners. In particular, model announcements or research paper publications are often accompanied by the model weights and other artifacts, similar to the former Papers with Code initiative [29]. As result, there are around 500 thousand datasets and almost 2 million models on Hugging Face Hub, which has emerged as primary platform where practitioners share, discuss, download, and build with models and datasets [30, 31]. growing corpus of research sheds light on the social dynamics of developer activity on Hugging Face Hub. While the number of models and datasets on the Hub is growing rapidly, activity on the platform is concentrated among small fraction of model repositories and developers, and the vast majority of models receive limited contributions and downloads [12, 13]. For example, 1% of models account for 99% of downloads [12]. Developer communities on the Hub exhibit distinct nomadic engagement patterns, where users engage intensely with models upon release but then migrate to newer models, creating successive activity spikes across different projects rather than sustained collaboration around individual models [13]. This nomadic behavior fundamentally differs from traditional OSS development, where communities typically form around stable repositories with long-term governance structures [13]. In addition, Castano et al. find that development activity in model repositories on the Hub differs from typical activity in OSS repositories on platforms like GitHub, with contributions to model repositories are typically oriented around perfective tasks that seek to improve model performance (e.g., optimization, fine-tuning, and evaluation) rather than corrective and adaptive tasks (e.g., bug fixes, feature additions). [14]. Model repositories tend to have user communities rather than developer communities, where users engage with models as tools for applications rather than as artifacts to be collaboratively developed or extended [13]. These user communities often focus on requests for documentation, support, or expanded access rather than direct contributions to model improvement [13]. While the majority of collaboration occurs post-release (e.g., fine-tuning, evaluation, or application development), number of grassroots projects have pioneered community-driven collaboration from the earliest stages of LLM development. The BigScience Workshop represents one of the most ambitious examples, engaging over 1,000 contributors from 66 nations and 250 organizations in coordinated effort to collaboratively develop the BLOOM model [17]. The project was coordinated by Hugging Face and benefited from French government support via subsidized access to the Jean-Zay supercomputer. It has been described as values-driven initiative, which engaged contributors with diverse motivations, such as developing skills, publishing research, and contributing to the ecosystem [16, 17]. Other notable examples include EleutherAIs community-driven approach to the development of community resources such as evaluation frameworks like the Open LLM Leaderboard, which facilitates community-driven benchmarking of LLMs [32]. Building on these precedents, newer projects like Marin are experimenting with even more radical forms of openness by creating an open labs that makes the entire research and development process of foundation models transparent from day one, leveraging established OSS development practices like GitHub-based workflows, pull requests, and community code review for foundation model development [18] The collaborative trend in open source AI has accelerated with the 2024-2025 period marking unprecedented releases of high-performing models, including DeepSeeks V3 series achieving competitive performance with proprietary mod5 Cartography of Open Collaboration in Open Source AI Linaker et al. els [33], Alibabas Qwen 2.5 extending context windows to 1 million tokens [34], and Googles Gemma 3 demonstrating efficient attention mechanisms [35]. In August 2025, OpenAI, which had been long opposed to open-sourcing its industry-leading models, released its gpt-oss-120b and gpt-oss-20b models under an Apache 2.0 license [36]. 3.2 Openness vs. Open Source in AI The proliferation of open models has generated much debate about definitions, as terms like open and open source are used inconsistently to describe AI models and systems that offer minimal transparency or reusability. . . alongside those that offer maximal transparency, reusability, and extensibility [37]. In addition, the community wrestles with open-washing, where developers market models that are released under restrictive licenses as open source, which contributes to further confusion [38, 10]. Several frameworks have been developed to clarify openness in AI. In terms of AI systems, the Open Source Initiative released the Open Source AI Definition version 1.0, which requires that an AI system and its constituent partsi.e., model weights, code, and training data or sufficiently detailed information of itare released under open source licenses for it to qualify as open source AI [39]. Taking different approach, Irene Solaiman proposes that the openness of generative AI systems can be plotted along six-tiered gradient, from fully open to fully closed, involving distinct release methods and cost-benefit considerations [40]. Similarly, Basdevant et al. propose that openness should be understood across the stack of AI systems, spanning infrastructure, model components, and product/UX [41]. Meanwhile, the Digital Public Goods Alliances definition of open source AI adds requirements on documented evidence of platform and technology neutrality, as well as ethical use cases [42]. In terms of AI models, the Model Openness Framework proposes three-tiered classification framework for evaluating the openness and completeness of models based on open science principles. Specifically, it breaks down models into constituent code, data, and documentation from models development lifecycle and classifies models based on the release of model components under open licenses [10]. Similarly, Garcia et al. recommend 10 simple rules for modelsharing based on open science principles [43]. Despite the different approaches of these various frameworks, they share the view that openness in AI R&D fosters greater transparency, reproducibility, and collaboration. 3.3 Motivations of open LLM developers Despite the growth of the open LLM ecosystem, research on motivations remains limited. To date, grassroots communities like EleutherAI and BigScience have articulated motivations rooted in transparency, academic freedom, and public benefit, positioning their work as democratizing access to advanced AI capabilities [17, 16]. By contrast, Meta has explicitly framed its Llama strategy around ecosystem development, with CEO Mark Zuckerberg explaining: Were doing it because... this is an ecosystem... just want everyone to be using it because the more people who are using it, the more the flywheel will spin for making Llama better [44]. The strategy to attract developers to corporate ecosystems was evidenced by the leaked Google memo, in which Google developers warned that they had no moat against open source and advocated for own[ing] the ecosystem by letting open source work for us [45]. However, these observations remain largely anecdotal, and systematic empirical investigation of the motivations driving participation in open LLM development has yet to be conducted. In light of this, prior work on the motivations in OSS development can inform our analysis of open LLM developers motivations. At the individual level, OSS developers are driven by diverse factors, including personal interest, ideological commitments, career development, and business opportunities [46, 47]. Importantly, motivations vary significantly based on whether they volunteer or are paid and their geographic context [48, 49]. Evidence of variations by geographical regions led Hossain to argue that, researchers studying open source should be mindful of geographic variation in what motivates participation and what forms participation may take, particularly outside of the code repository [50]. Corporate participation in OSS development is typically driven by strategic considerations based on business objectives [51, 52]. Primary motivations include reducing costs by leveraging community contributions and avoiding duplication of effort [53, 54], enabling the growth of business ecosystems around their products and platforms to create network effects and market advantages [26, 55], and influencing the development of open standards that favor their technological approaches [56, 57]. Additional strategic benefits include accelerating speed to market [58, 59], reducing dependence on dominant software vendors and avoiding vendor lock-in [59, 57], improving corporate reputation within OSS developer communities [60, 24], and recruiting talent from OSS developer communities [61, 56]. Academic and scientific OSS developers operate within different institutional contexts that shape their motivational frameworks. Academic developers are typically motivated by commitments to transparency, reproducibility, and open science principles that align with scholarly values and institutional expectations [62]. Their participation often serves research dissemination goals, enables collaborative scientific advancement, and fulfills growing institutional mandates for open research practices. Public sector motivations center on the principle that publicly funded software should be 6 Cartography of Open Collaboration in Open Source AI Linaker et al. publicly available, alongside broader goals of ensuring transparency, maintaining digital sovereignty, spurring innovation, promoting economic growth, and increasing vendor competition [63, 64]. Increasingly, governments are also funding OSS development as strategic investment to enhance national competitiveness in emerging technologies [65]. While the OSS literature provides theoretical foundation for understanding motivations in open LLM development, we note that important distinctions between OSS and open LLM development (e.g., specialized technical expertise, resource requirements, multitude of practitioner communities and artifacts, risks, etc) warrant dedicated investigation. 3.4 Governance and coordination in open LLM projects Governance in open LLM projects concerns how authority to shape the project and make decisions is established and exercised within project communities. This includes decision-making around the LLM itself and related artifacts such as data, software, and as well as who can join the collaboration and what roles they are able to play. Given the limited research on governance in open LLM projects, we can consider established frameworks from OSS governance literature, which provides established frameworks for understanding how collaborative projects coordinate development, make decisions, and manage communities. OSS governance structures vary primarily based on how authority is distributed within projects, ranging from autocratic models with centralized leadership to democratic approaches driven by community consensus [66, 67]. Projects can be characterized along spectrum from community-driven (where the community collectively owns and governs the project) to commercially-driven (where single entity maintains control while enabling external contributions) [68]. Common governance approaches include meritocratic systems where influence increases with the quality and quantity of contributions [69], and foundation-based governance structures that provide neutral oversight for larger projects requiring coordination across multiple stakeholders [70]. These models have evolved to address challenges around resource allocation, technical decision-making, community management, and long-term sustainability that are common across collaborative OSS development efforts. However, open LLM projects face additional governance challenges that warrant consideration: Strategic factors include defining project scope, vision, and intended applicationswhether targeting general-purpose use or specific domains (healthcare, finance), and whether prioritizing commercial integration, scientific research, or public access [37, 71]. Organizational factors regard the distribution of governance, e.g., to single organization (e.g., Meta and their Llama model), to neutral and collectively owned steward (the RWKV project hosted by the Linux AI & Data foundation), or informally and decentralized to all actors within the broader ecosystem (e.g., the BigScience Workshop and its BLOOM model) (cf. [72]). Cultural factors regard the will and potential for fostering an open collaboration within the ecosystem [73] and how to structure collaboration for multi-cultural and multi-disciplinary teams [17]. Legal factors encompass the application of different legal regimes of the different components of an AI model or system [10], managing copyright conditions of the dataset used for training and model outputs [74], along with legislative requirements on the preservation of privacy (e.g., GDPR in the EU) and transparency and governance [75]. Ethical factors consider the implications and potential use cases of an AI model. For example, while some ecosystems may reside on trust and community norms [76], the use of responsible licensing such as OpenRAIL [17] , others have shown how beliefs in technology neutrality trump the potential use cases that the technology may enable [77]. Business factors concerns the need for business models and innovation to promote co-opetition while enabling sustainable development and provisioning of services based on the open source AI system [78], while abiding with restrictions and calls for transparency [37]. 3.5 Summary Overall, this review of prior work reveals that critical gaps remain in our understanding of open collaboration methods throughout the lifecycle of open LLMs. First, collaboration practices across the full LLM lifecyclefrom initial development through to reusehave not been systematically mapped (RQ1). Second, evidence of individuals and organizations motivations remain mostly anecdotal, which warrants systematic, empirical analysis (RQ2). Third, the governance and coordination mechanisms that enable successful open LLM collaborations remain unstudied (RQ3). This study addresses these gaps through an exploratory analysis of open collaboration in 14 open LLM projects. 7 Cartography of Open Collaboration in Open Source AI Linaker et al."
        },
        {
            "title": "4 Methods & Data",
            "content": "4.1 Research aims and scope The goal of this study is to contribute to more comprehensive understanding of how open collaboration is practised and how it can be further enabled throughout the open LLM lifecycle, guided by RQ1-3 mentioned in the Introduction. We concentrate on LLMs given their importance in the open source AI ecosystem since 2021, which provides larger sample size and longer timeline of activity available for study compared to other types of models, such as multi-modal models. Furthermore, we concentrate on LLMs that have been shared on Hugging Face Hub, which provides relevant information about model release and reuse activity. To understand different practices for models that fall across the spectrum of model openness and licensing, our study includes open LLMs released under permissive licenses (e.g., Apache 2.0 or MIT) and open-weight LLMs released under restrictive licenses (e.g., research-only, acceptable use restrictions or commercial terms). For convenience, we refer to these models as open LLMs in this study.3 4.2 Research design We adopt qualitative research approach to understand the socio-technical dynamics of open collaboration in the context of LLM development and reuse. Our qualitative research design is suitable for gathering anecdotal knowledge from individuals situated in the problem context, while not necessarily limiting us to single or selective few cases. Furthermore, we anticipated that practices, norms and culture of collaboration would differ across LLM projects, organizational contexts, and geographies, and therefore qualitative interviews enabled us to capture this diversity. 4.2.1 Interviewee sampling In line with our exploratory research aims, we employed purposeful sampling to identify representatives from mature (beyond hobby-level), yet distinct cases of open LLM projects that involved open collaborative development during their development and/or reuse lifecycle [79]. To create starting set for our sample, we initially extracted LLMs from the Hugging Face API by filtering for text-generation models and only parent base models that had been finetuned, quantized, or adapted more than 100 times. These variables indicate maturity and activity in the base models development and reuse, and potentially also in the child models. Then, we filtered the dataset down to the 250 most downloaded models. We chose the number of downloads metric from Hugging Face API as proxy for activity and popularity of model. The number of downloads considers the last 30 days historically from the day the API is queried. Other metrics, such as likes, are cumulative and may give skewed distribution toward models that have been on the platform for longer period of time, but not necessarily actively used today. The initial sampling yielded 250 models with rich set of metadata obtained from the Hugging Face Hub API (see supplementary material). All models represented finetuned child model to parent base model. The models were categorized based on the entity who released the model to the Hugging Face Hub, and each author analyzed subset of the models to characterize type of releasing entity. The analysis leveraged online sources that could be connected with each entity, such as Hugging Face Hub, GitHub, the entities websites, news media, and social media postings. The categories were formulated through group discussions, and each categorization cross-confirmed by second author. Any disagreements were settled through the joint discussions. The categories that emerged were: Large Enterprises, including corporate organizations with staff count equal or more than 250.4 Smalland medium-sized enterprises, including organizations with staff count less than 250. Research institutes, including government-owned or private universities and research institutions. Non-profit / grassroots entities, including research-focused organizations without business models and revenue streams connected to their research. Individuals, including individuals who have shared the model in their private capacity. To filter for LLMs with the potentially highest levels of activity and socio-technical collaboration, we leverage the number of downloads as proxy for technical activity and the number of discussions in the models Hugging Face Hub repository as proxy for social activity per model. These are rough indicators but serve as an initial proxy to attain an ordered list for the continued sampling. Upon considering the diversity of organization types in our sample 3N.B. We use the abbreviation open LLMs as catch-all term for the 14 LLMs in our sample for convenience only. We explicitly do not intend to make any normative claims about the definition of an open LLM. 4https://single-market-economy.ec.europa.eu/smes/sme-fundamentals/sme-definition_en Cartography of Open Collaboration in Open Source AI Linaker et al. and verifying the willingness of representatives to be interviewed, we included the LLMs represented by interviewees I1-2 and I5-8 in our sample (see Table 1). However, something that stood out in this initial dataset and sample was the absence of community-driven open LLM projects, which our team was aware of based on our contextual awareness of the open source AI ecosystem. In line with our purposeful sampling approach, we complemented the initial sample with the LLMs represented by I3-4 and I9-17 for fuller picture of the open LLM landscape. Further information about the sampled models and the organizations driving their development can be found in the Appendix (see: Appendix B). 4.2.2 Interview process Following these insights from our analysis of the initial sample, we constructed an interview guide, which comprised questions about collaboration practices, on-ramps, and challenges throughout the open LLM lifecycle (RQ1); motivations (RQ2); and how open LLM collaborations are coordinated and governed (RQ3). Subsequently, we recruited interviewees from the target open LLM projects through email outreach and through personal networks. Interviewees were asked to confirm their informed consent before participating in the interview. The interviews were primarily conducted online with one or two of the authors present, who took turns in asking questions and taking notes. select number of interviews (I2, I5, I9) were conducted in person, following similar format. The interviews were semistructured, combining questions from the interview guide and spontaneous questions, and typically lasted between 30 to 60 minutes. The interviews were recorded for transcription purposes, and the recordings were transcribed using offline transcription software and managed following data management plan. 4.2.3 Data analysis After each interview, transcripts were coded using an abductive coding approach by one of the authors. The code book was initially constructed in alignment with the interview guide and the LLM lifecycle framework [23]. After an interview transcript had been coded, second author reviewed the codes, after which these and any other reflections were discussed and shared among the author team. After the third interview, the first level codes started to be categorised in second level codes (or themes), which was continuously iterated and revised after the joint discussions. The code book includes general section of themes touching on the interviewees overarching understanding of the open LLM ecosystem, incentives and drivers, and experience of open collaborative development of their open LLM. The dual coding approach was iterated for all interviews to mitigate researcher bias. We further carried out peerdebriefings on regular cadence to share our respective findings and come to collective understanding. After I10, we summarized our findings in tentative synthesis. While we agreed that the findings were starting to saturatefor example, as no additional high-level themes had emerged in recent interviewswe agreed to extend our investigation with I11-17 to broaden the diversity of our sample. After coding the 17th interview, we agreed that saturation was observable and concluded data collection and analysis."
        },
        {
            "title": "5 Collaboration Challenges and On-ramps throughout the Open LLM Lifecycle (RQ1)",
            "content": "In this section, we present our findings on where and how open collaboration takes place in each stage of the open LLM lifecycle, highlighting collaboration on-ramps and challenges at each stage. 9 Cartography of Open Collaboration in Open Source AI Linaker et al. n o m t , t , , g , l , d , o D , g T , , H , c X , t , l e D , t n a , o D l g , t e , , , c d e G , t , H , , , , c t e , p c s , o o , b d o , p c s o ) O e a 8 1 s d 1 , p c s . . ( s d 0 1 , o d , s a , u y b , p c s , i l , l a o e a 6 2 2 t a L , n X - a , 3 2 - e p 4 - 1 a L r n a r n o m t fi - , 1 . 3 - 3 l 3 - 2 e u s a y O t s G t i t s G t i I h l n S p k s e o e t o L p l s b i r i m S : 1 a c t e s a n e t S r n e a e e s o a i i r n a a e , p c s t t 8 4 - 2 I - , 1 I - h e c u o n I I - 1 2 3 4 5 6 a e l ) d C , p c s . . ( s d 1 1 1 O F t o - 8 . 3 - l - t t , , u E , S O t n r e ) B ( f fi - y a n e 7 , p c s n a v , b s d 5 6 l , L , m 2 - O fi - r t t n A 8 , l , C - O r I O , t n , m s t v g , o L 3 - 1 l B r M fi - n a a h L p n a o 0 1 - L S o u t e g g 9 , a v 2 - O L u s c s ) 2 ( 10 , , c , , p c s . . ( s d 9 4 b ) 2 e X , , H , a n , B s d 1 , , H G , r i , H , X , c M P O C , o d L t b , r a e , p c s s o , b t G , o , l l , a , p c s . . ( s d 6 2 ) d a a c A . . ( s d 3 ) r C e a 5 2 b , o l G , o , p c s s a 0 t d . a r f m e a e g g o s t t o o r s a t t e h . e p w r i y d v s o m n h . . 2 - 1 o T l , 7 - t M , 5 . 1 Q / 3 , 2 Q / 3 l m 3 Q t n & n C m ) 0 1 ( h - 1 1 3 1 i o C r t 4 1 , o l t ( e ) n s , s B - b - b - m a L , 4 . 0 - 7 - u 6 . 0 - 7 - u 8 - 1 . 3 - l 7 - u t s G t i h e m r o E , s y r e l P n a , I w f a L h a I e n F , - n O 5 1 6 1 7 1 Cartography of Open Collaboration in Open Source AI Linaker et al. Figure 2: Model Collaboration On-ramps and Challenges across the Open LLM Lifecycle Figure 3: Data Collaboration On-ramps and Challenges across the Open LLM Lifecycle Figure 4: Software Collaboration On-ramps and Challenges across the Open LLM Lifecycle 11 Cartography of Open Collaboration in Open Source AI Linaker et al. Figure 5: Evaluation Collaboration On-ramps and Challenges across the Open LLM Lifecycle Figure 6: Non-technical Collaboration On-ramps and Challenges across the Open LLM Lifecycle Figure 7: Compute Collaboration On-ramps and Challenges across the Open LLM Lifecycle 12 Cartography of Open Collaboration in Open Source AI Linaker et al. 5.1 Pre-training Stage Summary Open collaboration in the pre-training stage of the LLM lifecycle encompasses variety of artifacts and activities that lead up to the generation of pre-trained (base) model, spanning the curation of datasets, contributions to open source training frameworks (e.g., model architecture), non-technical tasks (e.g., documentation, community outreach), and forming partnerships for compute access. Collaboration challenges: During the pre-training stage, open collaboration is often limited by proprietary considerations, regulatory and geographical constraints, and the complexity of planning shared activities in the resourceand expertise-intensive process of pre-training an LLM. In some cases, model training processes are treated as corporate secrets, which restricts possibilities for knowledge sharing and open collaboration. In the context of training datasets, copyright restrictions and structural undervaluation of data curation In addition, there is often limited appetite for sharing curated work further impede collaborative efforts. training datasets due to the high costs and perceived value of such datasets. Software tools and infrastructure for pre-training models are commonly tailored to internal systems, and the technical, organization-specific expertise required for contributions limits the scope of external involvement. Lastly, open LLM developers, in particular grassroots projects, struggle to access to compute resources required for pre-training LLMs. Collaboration on-ramps: We identify several on-ramps that facilitate collaboration during the pre-training stage. Opportunities include interest in reproducing existing models, finetuning models for specific use cases, and integrating model architectures into open source LLM training frameworks. Data collaborations can be formed when there are shared interests to produce resource that can be useful for many. This takes the form of reusing existing datasets, releasing internally developed datasets, developing data curation partnerships, and engaging in community-driven data collection or e.g., for lowor medium-resource languages). There is also collaboration activity on the development of open source frameworks for training and evaluating LLMs. Non-technical contributionssuch as sharing knowledge, model cards, and best practicessupport learning and facilitate advancement of research ideas and practices. Additionally, developers form partnerships (e.g., with public and corporate providers) to secure access to the compute resources needed to train open LLMs. 5.1.1 Pre-training: Model Collaborations Collaboration on model development during the pre-training stage faces significant challenges due to organizational secrecy, technical task complexity, planning challenges limited by organizational practices and system security barriers, and rapid innovation cycles. Despite these obstacles, several developers have collaborated in different ways, including on the reproducibility of models, strategic partnerships between base and derivative model developers, and contributing expert advice to and sharing ideas among open LLM projects. Challenge: Organizations guard pre-training methods as competitive secrets. Many organizations treat information about their model development processes as competitive advantages, creating barriers to open collaboration. This culture of secrecy particularly affects the sharing of pre-training and post-training methodologies, where organizations are reluctant to share technical details that could benefit competitors. As I8 from Ai2 explains, The modelling part with pre-training and post-training is treated as, like, very closely guarded secret. We have informal chats, even like on the record are somewhat easy to make happen, but formal collaborations, that is different beast. Challenge: Resource-intensity limits spontaneous collaboration opportunities. The resource-intensive nature of LLM pre-training requires extensive upfront planning that can stifle organic collaboration opportunities. Developers must scope potential collaborations early in the development cycle because late-stage partnerships can fundamentally alter experimental approaches and resource allocation. For example, I8 from Ai2 notes that, [Collaborations] all need to be scoped out basically before we start working on something, because they will majorly alter the experimentation stage. While some spontaneous collaborations do sometimes emerge through ad hoc interactions at conferences or new hires, these typically remain limited to small-scale tests rather than core model development. Coordination of pre-training activity can be more challenging where organizational technical practices and security constraints around access to resources required for pre-training (e.g. servers, databases) present barriers, and thus disincentives for onboarding external collaborators. Challenge: Technical complexity restricts participation to experts. The technical complexity of LLM pre-training creates natural barriers to broad community participation, effectively limiting meaningful contributions to small teams of domain experts. This expertise bottleneck is particularly pronounced in regions with fewer AI specialists. I10 from 13 Cartography of Open Collaboration in Open Source AI Linaker et al. the SpeakLeash Foundation highlights this challenge: the training is [done] mostly by our internal team. Because one thing is that this is very specialized knowledge and not everyone has it... And currently, believe we do not have much more experts on this level in Poland. Developers recognize that scaling participation beyond core technical teams would be counterproductive, as I10 explains, it would be very unoptimized to have like 300 people involved in it. The BigScience Workshop similarly organized itself into smaller, expertise-based working groups per domain area. I4 explains, one working group focused on the retrieval augmentation experiment, another working group was looking at whether we were going to do full-length one-directional language model or sequence-to-sequence language model. Another working group was looking at the hardware, working with the cluster directly. Challenge: Fast-paced development cycles prevent sustained collaborations. The fast-paced nature of open LLM development makes it difficult to maintain long-term engagement and build lasting collaborative relationships in open LLM projects. I14 from Ant Group observes that, many AI open source projects are very short living. They do not live longer. They just appear for one or two months and they will disappear forever. On-ramp: Collaborative reproduction of existing models for broader access. Developers with complementary expertise collaborate on reproducing existing models to address licensing limitations and expand access within the open source community. These reproduction efforts leverage shared codebases and architectural similarities to accelerate development. For example, EleutherAI and Hugging Face collaborated on implementing Metas first Llama model, with I3 from EleutherAI noting that, this Llama implementation in Hugging Face is actually authored by mixture of Hugging Face staff and EleutherAI volunteers and was substantially based on our model code because the Llama model and our model are architecturally very similar. On-ramp: Strategic partnerships between foundation model and specialized model developers. The developers of base models and derivative models create formal and informal collaborations to enhance both model capabilities and regional representation. These collaborations involve information sharing, early access arrangements, and data contributions and partnerships that benefit the broader ecosystem. For example, AI Singapore has engaged with both the Llama team at Meta and the Gemma team at Google, with different levels of collaboration in each case. While the engagement with Meta involved communication through private Slack channels and early access arrangements, the collaboration with Google has been more extensive, including joint development work such as building SEA-LION v4 together. Both collaborations were motivated by the principle that it is net benefit if Southeast Asian languages and cultures are better represented across all models.. These engagements have included communication and information sharing regarding model roadmaps, discussion on specific features, and various forms of technical collaboration. On-ramp: External domain experts contribute specialized knowledge through advisory roles. External domain experts contribute specialized knowledge to collaborative projects through advisory roles, which is particularly valuable when core teams lack specific technical expertise. This enables projects to access high-level guidance without requiring full-time commitment from contributors. For example, I16 from Masakhane describes how, we ask for technical advice. So we did some project on machine translation evaluation. have not done this before, so we requested at Masakhane, and one professor from the U.S. was interested [and said,] Okay, can help. She has been doing machine translation for many, many years, so she contributed mostly on technical skills. 5.1.2 Pre-training: Data Collaborations Data collaborations during pre-training encompass dataset creation, curation, and validation activities that are essential for model development but face distinct challenges from model collaborations. While licensing complexities and cultural undervaluation of data work create significant barriers to sharing, several collaborative pathways have emerged including community-driven annotation efforts, inter-organizational data partnerships, and collaborative approaches to data provenance validation that help address quality and legal concerns (e.g., about licenses). Challenge: Copyright restrictions and legal complexity constrain dataset sharing. Copyright restrictions and rights-holder interventions create significant legal complexity that constrain both dataset creation and model release strategies, leading developers to implement careful filtering and dual-licensing approaches to ensure compliance with the law. I15 from the National Library of Norway explains: Recently there has been increased attention from rights holders to clarify what may be used for training and what may be released. This pressure prevents the use of permissive licenses such as MIT or Apache v2 when models are trained on copyright-restricted material, forcing developers to consider releasing dual modelsone under Apache license trained exclusively on open-access data. I15 explains that their team routinely consult legal counsel to ensure compliance, while grassroots projects like Masakhane rely on academic and community conventions and use licenses like CC BY 4.0 for commercial or non-commercial use, lacking resources for extensive legal consultation. Challenge: Data curation receives disproportionately less attention than model training. Data preparation and curation receive disproportionately less attention and resources compared to model training, creating systemic im14 Cartography of Open Collaboration in Open Source AI Linaker et al. balance that affects dataset quality and availability. This preference hierarchy reflects broader structural incentives in the AI ecosystem that prioritize visible technical achievements over foundational data work. I15 from the National Library of Norway observes, Everybody wants to train model. Everybody wants to build their expertise on training the models. It is been bit less competitive in the data preparation. To be honest, so nobody wants to do the data work. This imbalance not only affects resource allocation but also limits the pool of contributors willing to engage in the time-intensive work of dataset creation and validation. Challenge: Reluctance to share datasets due to high investment costs. Despite high demand for quality datasets, organizations remain reluctant to share curated data due to the substantial time investment required to prepare them and the perceived competitive value, creating an asymmetric ecosystem where data consumption exceeds contribution. The tedious nature of data curation, requiring hours to produce even small high-quality datasets, compounds this reluctance even when legal permissions exist. I15 from the National Library of Norway describes this challenge: Data curation is very tedious work, right? It is very boring work... traditionally to make dataset, fine tuning dataset, even making 500 or 1000 examples of this, right? It takes hours and hours and hours. And even if you technically are allowed to release it, not everybody is willing to release it. They want to have it themselves because they invested so much money in it. This lack of reciprocity presents fundamental structural barrier to building robust open data ecosystems. On-ramp: Building upon established foundational datasets (e.g., CommonCrawl or The Pile). Developers frequently collaborate by building upon established open datasets like CommonCrawl and The Pile, which serve as foundational sources that enable collaboration across the ecosystem. These data sources require different levels of processing, with some providing pre-cleaned data while others need extensive filtering and preparation before they can be used to pre-train model. I7 from BAAI explains their approach: they acquire training data from two primary sources: CommonCrawl and the Pile datasets, noting that CommonCrawl datasets require extra processing, while the Pile datasets are already pre-cleaned. I3 from EleutherAI confirms the former, as they had to build lifecycle for reverse engineering licensing of data available in Common Crawl. In addition, Hugging Faces SmolLM developers have leveragedopen datasets like DCLM from DataComp, which was collaboration between Toyota research and several other organizations on English data. On-ramp: Contribute specialized datasets to address ecosystem gaps. Developers contribute specialized datasets that address gaps in existing training data in the ecosystem, particularly for specific capabilities or domains that lack adequate coverage. These contributions often arise from experimental needs surfaced during model development and subsequently benefit the broader community. I9 from Hugging Face explains their motivation for creating the FineMath dataset: We tried to reproduce what DeepSeekMath did. They had really good math model, and they built math dataset for pre-training, but they did not release it. SSo, in this work, we kind of rebuilt datasets similar to what they have, except that it is open, and now everyone can train on it and get really good math performance. Similar efforts include creating high-quality code datasets to address training gaps identified during model development. On-ramp: Crowdsourced annotation improves dataset quality through distributed expertise. Large-scale community engagement enables organizations to improve dataset quality through distributed annotation and feedback, particularly valuable for multilingual datasets where native speaker expertise is essential. These collaborations leverage crowdsourcing platforms and social media to engage both technical and non-technical contributors. For example, I9 from Hugging Face explains that after they released their multilingual FineWeb 2 dataset, which was collaboration between the Hugging Face training datasets team and researchers at EPFL, they created space on Hugging Face Hub and invited crowd-sourced contributions via social media and received contributions from lot of people who participated from around the world, including people who did not have ML background, who helped with annotation and provided feedback on the quality of the data in their native language. The SpeakLeash Foundation similarly leveraged community engagement, deploying toxicity assessment survey that has received over 60,000 responses. On-ramp: Community projects collect culturally specific data for underrepresented languages. Communitydriven projects focus on collecting culturally specific and linguistically diverse data that would be missed in direct translations from high-resource languages, addressing representation gaps through targeted collaboration with native speakers. These initiatives require careful coordination to establish shared quality standards and cultural guidelines across diverse contributor communities. The Aya project at Cohere for AI exemplifies this approach, creating datasets through data donations focused on culturally sensitive and aware topics, for example question and answer pairs focused on targeted questions around history, literature, recipes, which would be missed in direct translation from high resource language data. I5 from Cohere for AI emphasizes the importance of native speaker involvement: it is really important to get the people [speaking the language] involved to do good job representing them in these models in the end. The potential for such collaborations is particularly strong for medium to low-resource languages where research communities recognize shared challenges. I11 from SCB 10X explains: think building datasets is one of the easiest things for us to collaborate. Because...Thai is like medium to low resource language. So there is not lot of high quality datasets. And lot of the research community in Thailand understands this. So everyones 15 Cartography of Open Collaboration in Open Source AI Linaker et al. like really willing to collaborate to build datasets, whether it is like domain specific data set ... or like medical data set, things like that. It is very easy for us to find partners to collaborate. On-ramp: Strategic partnerships enable access to high-quality regional language data. Inter-organizational partnerships enable access to high-quality regional data through strategic alliances that leverage complementary capabilities and shared objectives for language representation. These partnerships often extend beyond simple data exchange to include technical collaboration and capacity building. For example, AI Singapore maintains collaborations with Google Research for collecting and transcribing voice audio specifically for Southeast Asian languages, while also working with regional partners to encourage data release by emphasizing social good incentives. Furthermore, I6 from Meta explains that they work with various entities to provide data with different languages, as they try to diversify and broaden the language support of the Llama models, including partnerships with data providers in India for Indian dialects and languages. On-ramp: Universities and companies form data-expertise partnerships. Collaborations between companies and academic labs create mutually beneficial arrangements where companies provide data resources while academic labs contribute research expertise and validation. These partnerships often emerge from complementary needs and capabilities across sectors. For example, I15 from the National Library of Norway describes their role as the primary data contributor to joint research project with Norwegian universities, explaining, none of the others have been very interested in it as research area as universities focus more on technical ML, while, They really appreciate that we contribute with the open source datasets especially. The library also shares restricted data for research purposes with specific academic institutions under appropriate agreements. On-ramp: Community develops shared standards for trusted dataset licensing. Developers collaborate on addressing data provenance and mis-licensing issues by developing shared standards and validation processes that create trust in open training datasets. These efforts require community-wide coordination to establish transparent practices I3 from EleutherAI explains the challenge: license laundering or data laundering is and legal certainty. big issue, meaning when data is downloaded, refined, and uploaded several times, which makes determining the provenance of data difficult to assess. To address this, EleutherAI has developed collaborative approaches including reverse-engineering CommonCrawl licensing and creating gold list of organizations representing trusted sources with verified licensing and provenance, such as screened YouTube channels from academic, governmental, and nonprofit organizations. I3 explains that EleutherAI has put lot of effort into making available open datasets that are fully vetted for copyright as well as open LLMs trained on said datasets will add value to the open source AI ecosystem, giving researchers and developers greater sense of legal certainty. 5.1.3 Pre-training: Software Collaborations Software collaborations in pre-training focus on developing LLMs, in particular training and evaluation frameworks. While technical complexity and lack of standardization create barriers to collaboration, several collaborative pathways have emerged including open-source framework development, community contributions to evaluation tools, and strategic partnerships with hardware vendors to ensure portability across computing environments. Challenge: Technical complexity limits external contributions to core development teams. The technical expertise and effort required to develop and maintain LLM training tools and infrastructure limit external contributions to open source frameworks, with most development remaining centralized within core teams. I3 from EleutherAI explains that while EleutherAIs GPT NeoX library has received some external contributions from researchers and developers, who are using it professionally, either in academia or in industry, such contributions are rare due to expertise requirements. For example, when two volunteers contributed the mixture of experts architecture, I3 notes, Those kinds of contributions are quite rare, partially because the skill set is rare and partially because it is like huge amount of work if youre not receiving benefit from it. It is really massive amount of work. Challenge: Multiple competing frameworks fragment community effort and collaboration. The absence of standardized frameworks for training and evaluating LLMs creates ecosystem fragmentation that leads to duplication of effort across the community. For example, there are several open source frameworks for training and evaluating LLMs. While the diversity of frameworks can serve different use cases, the lack of convergence fragments collaboration. For example, I9 from Hugging Face comments, the frameworks we released, we are hoping that everyone can try to adopt them. For example, TRL is really now popular and kind of the go-to choice for post-training models and for Nanotron think there is also some other frameworks that are good, but think it would be nice if everyone tries to agree on one framework so that we all contribute to the same features. Challenge: Internal tool dependencies limit portability and open source value. Developers face practical constraints in open-sourcing software when tools are tightly coupled to internal infrastructure or have limited reusability, creating selective barriers to software sharing. While there is general motivation to open-source training tools and 16 Cartography of Open Collaboration in Open Source AI Linaker et al. infrastructure, practical considerations around value and portability influence release decisions. For example, I8 from Ai2 explains that, it is always goal to open-source their software for training infrastructure, unless it has very low value in open sourcing (e.g., specifically tied to their infrastructure or is not widely reusable) in which case they describe it in the model card. On-ramp: Open source LLM training frameworks reduce barriers to model training. Developers develop opensource training frameworks to enable broader community access to LLM training capabilities while benefiting from community feedback and contributions. These frameworks become foundational infrastructure that reduces barriers for other teams to train models. For example, I9 from Hugging Face explains their decision to develop Nanotron: they used to use framework for pre-training from Nvidia but opted to develop their open source framework nanotron for better flexibility and to have in-house knowledge about large scale pretraining. They also build widely-used libraries including transformers, TRL, the alignment handbook, and lighteval. I7 from BAAI emphasizes the critical importance of such frameworks: since [a] large model is so complex, without ...any open source code as the base, it will be very challenging for any team to develop the training code by themselves fully from scratch. It is impossible already. EleutherAIs GPT-NeoX exemplifies this impact, with I3 describing it as the most widely used open source library for training large-scale AI systems in the world. In addition, as we discuss below, the development of open source evaluation frameworks also represent key area of collaboration. On-ramp: Users contribute specialized capabilities developed for internal needs. Developers contribute features to existing frameworks when they develop capabilities for their own use cases and choose to share them with the broader community. These contributions often emerge from practical needs and are sometimes facilitated through supervision or support from the framework maintainers. For example, SynthLabs contributed RLHF finetuning support to EleutherAIs GPT-NeoX after initially developing it for their internal needs. I3 from EleutherAI explains, They built on top of our library the capability to do this kind of RLHF finetuning, and then came to us and said, Hey, we have this internal code. We want to contribute it back to the community. We have benefited from using your library lot. We want other people to benefit from the modifications that we have made. And so we partnered with them to help them bring that to the main branch so other people can use it. Similarly, I14 from Ant Group describes collaborative relationships with frameworks like SGLang by XAI, where they, proposed some requirements and gave feedback based on their experience of using the inference framework and SGLang delivered features based on their feedback. On-ramp: Collaborating on portability across technical environments. Developers have collaborated on porting frameworks or adding support for different underlying technologies, enabling adoption across different technical environments. The AI lab of the National Library of Norway has collaborated with Hugging Face to port PyTorch code to JAX due to their specific technical requirements. I15 explains, we did the port of their code to JAX. They had it in PyTorch and we really needed that code in JAX... That was lot back and forth working directly on the code with feedback on the exact part of the code and how to do things. While their internal code contained dataset-specific features that were unsuitable for inclusion in the general codebase, the core porting work benefited both organizations and the broader community. In addition, developers have collaborated with hardware vendors and compute providers. EleutherAI prioritizes portability as core design principle for GPT-NeoX, with I3 recognizing that training is both hardware and software problem. I3 goes on to explain that, Even if we do not have use case for particular supercomputer or particular context, we want to make sure that it is ready to go in that context before it becomes requirement for us. The portability of GPT-NeoX has been enhanced through contributions from Intel and AMD who, want the framework to run optimally on their accelerators, as well as partnerships with national supercomputers like the US Frontier supercomputer and EU-based supercomputers like Lumi and at the University of Barcelona. On-ramp: Community identifies and documents fixes for critical software issues Information collaborations occur when organizations report and document fixes to bugs identified in core open source software used for model pretraining. I8 from Ai2 describes case where their team found bug in how numbers have shuffled in PyTorch, and reported it to the team. I8 expands that this bug was also discovered by the team at answer.ai when that team released their Modern BERT paper... they called this bug explicitly in their tech report and it took think 48 hours for this bug to be fixed in mainline PyTorch... there is power in like documenting these, even the failures out so that, you know, the other places in the community can react to it and pick them up and fix them. 5.1.4 Pre-training: Evaluation Collaborations Evaluation collaborations during pre-training focus on developing benchmark datasets, frameworks, and tools that serve the communitys needs for consistent model capability comparison. These collaborations are particularly important because comprehensive evaluation requires diverse expertise and resources that no single organization can provide independently, making evaluation one of the most collaborative aspects of the pre-training stage. On-ramp: Open source evaluation frameworks enable consistent model comparison across community. The development of evaluation frameworks is an area of collaboration, serving shared community needs for consistent, Cartography of Open Collaboration in Open Source AI Linaker et al. reproducible model assessment while providing platforms for researchers to contribute new benchmarks and evaluation protocols. EleutherAIs LM Evaluation Harness is an example this model, enabling comparison of models across evaluation datasets in consistent, reproducible, and reliable manner. I3 highlights the value-add of evaluation collaborations: if you develop new evaluation protocol [and] implement it in our library, youre going to get access to all of these models for free, where you do not need to do the work to do the integration yourself. The frameworks reuse across the community, such as in Hugging Faces OpenLLM Leaderboard, demonstrates its collaborative impact. Hugging Face has built upon this foundation with lighteval, which I9 describes complements EleutherAIs LM Evaluation Harness by adding additional benchmarks and evaluation suites, including Stanfords HELM. I14 from Ant Group describes similar approach with their ARAIL framework, combining code, datasets, and benchmarks to enable reproducible results: Our main contribution is actually the code... But to validate the effectiveness of our training framework, we have to do some training, do some benchmarks. So we also open-source the corresponding datasets and that everyone can reproduce our training results. On-ramp: Creation of benchmarks for lowand medium-resource languages. Evaluation dataset development represents major collaborative opportunity that brings together diverse partners including academic institutions, language communities, and model developers to create comprehensive benchmarking frameworks for specific linguistic or cultural contexts. These collaborations often involve forking existing evaluation platforms and extending them for underrepresented languages and regions. AI Singapore collaborated with Stanfords HELM team to fork the project and are co-developing an open evaluation framework for Southeast Asian languages. Similarly, I12 from Typhoon describes their collaboration on SEA-HELM: we worked on collecting data for this leaderboard, like Thai exams data, and we basically implemented the code base to make it compatible with the HELM platform, while Stanford researchers handled evaluation execution to maintain objectivity. Masakhane has collaborated across multiple evaluation initiatives including Global MMLU with Cohere for AI, SEACrowd for Southeast Asian contexts, and various African evaluation datasets and leaderboards. On-ramp: Speakers of lowor medium-resource languages contribute language expertise to evaluation datasets. Language communities and domain experts contribute to evaluation dataset creation through crowdsourced efforts that capture cultural and linguistic nuances essential for comprehensive model assessment. These collaborations leverage community knowledge to identify and digitize evaluation materials that would otherwise remain inaccessible. Cohere for AI exemplifies this approach by leveraging language communities as human eyes and signal for understanding model performance across different languages, including campaigns to gather community contributions to global evaluation datasets by finding digitized exam questions from their countries. Similarly, the SpeakLeash Foundation has worked with their community to build datasets for identifying harmful or toxic language, receiving over 60,000 responses and developing specialized benchmarks like CPTU-Bench for complex Polish text understanding and Polish EQ-Bench for Polish emotional intelligence benchmarking. On-ramp: Unified leaderboards integrate diverse evaluation resources for comprehensive assessment of LLMs. Organizations collaborate by integrating evaluation datasets and benchmarks developed by various research groups into unified leaderboards and evaluation platforms, enabling comprehensive model comparison across diverse capabilities and contexts. This integration work requires technical coordination and shared standards to ensure compatibility and reliability. I12 from Typhoon describes how they brought Thai evaluation datasets made by various research groups into leaderboard and built an evaluation framework for it, including building ThaiExam by preparing data and integrating it with the HELM platform to make it available for the broader community. This collaborative approach ensures that evaluation resources developed by different organizations can be leveraged collectively to provide more comprehensive model assessment capabilities. 5.1.5 Pre-training: Non-technical Collaborations Non-technical collaborations during pre-training focus on knowledge sharing, community engagement, and research dissemination activities that support the broader ecosystem beyond code and data contributions. These collaborations include documenting experimental practices, sharing training experiences, coordinating community outreach efforts, and contributing to open science through transparent reporting of methodologies and lessons learned. On-ramp: Shared documentation of training experiences reduces community experimentation costs. Developers contribute to the communitys collective knowledge base by sharing experimental methodologies, evaluation practices, and detailed training logs that enable others to learn from their experiences and avoid common pitfalls. This knowledge sharing is particularly valuable given the complexity and resource intensity of LLM pre-training, where learning from others approaches can significantly reduce experimentation costs. I8 from Ai2 emphasizes the importance of such sharing: Specifically, when it comes to building, the more compute you want to put in your effort, the more design space what you can do to achieve your goal is like huge, right? And so learning how others either have approached similar problem or start or their final end stage of starting point, or just in general how they think about 18 Cartography of Open Collaboration in Open Source AI Linaker et al. problem. It is very valuable. They highlight examples including Clementine Fourriers evaluation work at Hugging Face and the companys detailed blog posts about FineWeb dataset and FineBench, noting, It was very interesting to learn about how she thinks about evaluation. Such contributions help establish best practices and shared understanding across the community. In addition, developers contribute to this knowledge base by documenting operational challenges, cluster management practices, and detailed training logs that provide invaluable troubleshooting resources for the community. These contributions capture institutional knowledge that would otherwise remain siloed within individual organizations. I8 from Ai2 particularly values comprehensive training documentation, citing examples from major projects: training logs from the BLOOM and OPT models by the BigScience Workshop and Meta respectively... Just like hundreds of pages of everything that can go wrong during pre-training. It was very useful ... you know, software is useful, but there is like this sort of shared knowledge that comes from doing this big project ... in the cases where they get written down, it is actually super, super useful contribution. They also mention the value of blog posts about cluster management practices, which help organizations navigate the complex operational aspects of large-scale training. I8 acknowledges the reciprocal nature of this sharing: We tried to pay back all the goodwill that we got in like the almost two technical reports. On-ramp: Content (e.g., blogs) can amplify projects visibility. Developers collaborate on community outreach efforts to promote awareness of technical contributions, share success stories, and build engagement around collaborative projects. This includes coordinated content creation and marketing efforts that amplify the impact of technical collaborations. The collaboration between EleutherAI and SynthLabs on RLHF finetuning exemplifies this approach, where both organizations published complementary blog posts about the technical contribution. I3 from EleutherAI explains their blog post is more focused on the open source ecosystem and explains the process of contributing SynthLabs internal fork upstream into GPT-NeoX. This coordinated approach ensures that collaborative contributions receive appropriate visibility and recognition while educating the community about collaboration processes and encouraging similar contributions. 5.1.6 Pre-training: Compute Collaborations Compute access represents one of the most critical barriers and collaborative opportunities in open LLM development, given the substantial computational resources required for training LLMs. While high costs and limited availability constrain the number of developers or organizations capable of developing LLMs independently, various collaborative arrangements have emerged including government-led supercomputer access, cloud provider credit programs, corporate partnerships, and national research infrastructure sharing initiatives. Challenge: Compute requirements constrain open collaboration. The massive computational requirements for LLM pre-training create fundamental access barriers that limit collaborative model development to organizations with substantial internal resources or partnership arrangements. This resource constraint affects even well-funded organizations and extends beyond raw compute to include the financial and technical complexity of managing large-scale training infrastructure. I3 from EleutherAI emphasizes the universal nature of this challenge: Resource access is really big deal. Most organizations do not just have on hand the kinds of computing resources required to train one of these models. So, figuring out how to make that happen is really important. The challenge affects projects at various scales, with I9 from Hugging Face noting that even for smaller models like SmolLM, There are significant research and development costs involved not only in running the training, but also finding the right training mixture and parameters. Even organizations like BAAI, which have sufficient internal resources for post-training, require external partnerships to access the compute needed for foundation model pre-training. On-ramp: Institutional partnerships with public supercomputing infrastructure can enable LLM training. National and institutional supercomputing centers actively seek partnerships with open LLM developers to validate their infrastructure while providing essential compute resources that enable large-scale model training projects. These partnerships often emerge from mutual benefits: computing centers need stress-testing and benchmarking, while developers need access to cutting-edge hardware. I4 from Hugging Face explains that BigScience Workshop originated from such partnership, as the origin of the BigScience Workshop was an invitation from an administrator of Jean Zay, French public cluster, for Hugging Face to stress-test it. Over time, this expanded through advocacy efforts to secure additional government investment in GPU infrastructure for the BLOOM model. Similarly, the SpeakLeash Foundation was approached by Polands Cyfronet supercomputing center during the construction of the Helios supercomputer. I10 explains, the super computing center was currently building the Helios supercomputer, which is currently the most powerful supercomputer in Poland. They got to know about us and they reached out to us and said, Hey, we need to run some benchmarks when we are building it. We need to run some synthetic benchmarks but we can also do something for all of useand lend some power to create an LLM, and we said, lets do it! In Canada, the national initiative, Compute Canada, to pool compute resources for academic institutions provide an on-ramp for researchers to to access compute resources that would otherwise be prohibitively expensive. I16 from Masakhane explains that, everybody pool resources together into what is called Compute Canada. and then you could assess 19 Cartography of Open Collaboration in Open Source AI Linaker et al. it. Every professor or every AI institute has quota. Millions of hours that can be used. So if you have really big compute tasks, you can push it to Compute Canada and then you can run the job. They characterize this as providing good enough compute, not excellent, but good enough for academic-scale projects, while acknowledging limitations compared to industry-scale resources like those needed for models at the Llama scale. On-ramp: Research credit programs enable academic access to enterprise-level infrastructure. Major cloud providers offer research credits and specialized programs that enable academic and open source projects to access enterprise-level compute infrastructure, often in exchange for open research publication requirements. These programs provide essential resources for organizations that lack internal compute infrastructure while advancing the providers research ecosystem engagement. For example, I15 from the National Library of Norway describes receiving substantial resources from Google Research Cloud as personal scholarships based on their other work, explaining: we got quite lot of resources from them because of the work Ive done on vaccine models earlier and the early work we did on BERT. So we train lot of these original models on TPUs that were given to us. And the only requirement there is really that research needs to be open and we need to publish on it. I16 from Masakhane similarly uses compute credits from Google and OpenAI to support their research initiatives, demonstrating how these programs enable resource-constrained academic and grassroots projects to develop open LLMs. On-ramp: Vendor partnerships can provide specialized resources and enable technical optimization. Beyond credits, open LLM developers have formed partnerships with hardware and cloud providers to access compute for training LLMs. These partnerships have involved technical collaboration on setup and optimization in addition to the provision of compute resources. For example, AI Singapore partnered with providers like Google, AWS, and NVIDIA, who work with their engineering teams to set up the training lifecycles on the hardware of these providers. Similarly, EleutherAI has formed partnerships with chip vendors like Intel and AMD to access specialized hardware configurations and supercomputing resources like the EUs Lumi supercomputer. 5.2 Post-training Stage Summary We observe relatively little open collaboration during the post-training stage of open LLMs, as most posttraining activities remain internal to organizations. However, the collaborations that do occur include sharing intermediate model checkpoints for testing and feedback with trusted partners, releasing curated post-training datasets, and leveraging open source benchmarks for model evaluation pre-release. Collaboration challenges: The post-training stage involves significant barriers to open collaboration. The technical complexity and resource intensity of post-training methods create high barriers to entry for external collaborators, while the competitive sensitivity around model capabilities and performance optimizations limits willingness to share intermediate training states or detailed methodologies. In addition, the rapid iteration cycles common in post-training make it challenging to coordinate external input, and the lack of standardized frameworks for collaborative post-training further constrains community involvement. Collaboration on-ramps: Despite limited collaboration during post-training, we observe at least three onramps for collaboration. First, the sharing of intermediate checkpoints with trusted partners for testing and feedback. Second, the curation of specialized post-training datasets. Third, the curation of evaluation datasets and the use of community-managed evaluation resources (e.g., open benchmarks, LLM leaderboards). 5.2.1 Post-training: Model Collaborations Post-training model collaborations are currently relatively limited and focus on performance testing and feedback collection. Unlike pre-training collaborations, these partnerships typically occur within smaller, trusted networks rather than involving broad community engagement. On-ramp: Sharing intermediate checkpoints with trusted partners for testing. Some developers share intermediate model checkpoints with selected partners to gather specialized feedback and test specific capabilities during the post-training process, enabling iterative improvement before the public release of the model. For example, I9 from Hugging Face explains that they had shared the intermediate checkpoint of the model with other startups, so that they could test them and then to see if we could add new capabilities to the model during post-training. Through these targeted collaborations, they got some feedback about the models and then had the final instruct model released, demonstrating how selective sharing enables quality improvement through external validation. 20 Cartography of Open Collaboration in Open Source AI Linaker et al. 5.2.2 Post-training: Data Collaborations On-ramp: Sharing specialized post-training datasets with the community. Developers share specialized posttraining datasets that enable other developers to improve their models. These releases can also have multiplier effects across the ecosystem. For example, I7 from BAAI mentions that they had, released post-training dataset called Infinity Instruct, which they had developed for post-training their models like Aquila, on Hugging Face Hub After three months, it had been used by external developers to post-train over 130 models. I7 explains her team is satisfied with the collaboration this facilitates, explaining that, We open-source our dataset, and lot of people use that to change their model, and they again open-source their model. So, we are happy to see this kind of open source cycle. 5.2.3 Post-training: Evaluation Collaborations Evaluation represents the most collaborative aspect of the LLM post-training stage, as developers heavily rely on community-developed benchmarks and evaluation infrastructure to assess model performance and communicate capabilities to users. This collaboration is essential given the breadth of capabilities that need assessment and the importance of comparative evaluation. On-ramp: Developers use community benchmark suites for comprehensive model assessment. Developers leverage extensive community-developed benchmark suites to conduct thorough model evaluation, recognizing that comprehensive assessment requires more evaluation capabilities than any single organization can develop independently. This reliance on community resources reflects both practical constraints and best practice recommendations from leading research groups. For example, I9 from Hugging Face describes testing SmolLM on very comprehensive list of benchmarks that test really different abilities and also some benchmarks that we did not monitor during the training to make sure ...that we do not overfit on them, following practices recommended by Ai2 in their OLMO paper. I7 from BAAI emphasizes the necessity of this approach: if we want to have full spectrum benchmark for the model, it is important to develop benchmarks for various capabilities, but it is impossible for us to develop all the benchmark by ourselves. Consequently, they use lot of open source benchmarks as part of our evaluation method. On-ramp: Community leaderboards enable transparent model performance comparisons. Organizations participate in community-managed evaluation platforms and leaderboards to facilitate transparent performance comparisons and provide users with standardized benchmarking information. This participation represents form of indirect collaboration, where organizations contribute evaluation results while benefiting from shared evaluation infrastructure. I7 from BAAI describes their evaluation workflow: after post-training, they benchmark their model against other open models. If the results are good, they release the model. They also submit their model to community-managed leaderboards, so that it is easier for the user to compare our models performance with other third parties performance. This process involves continuous monitoring during training, with developers evaluating several checkpoints on two to three day basis to ensure the curve and trend looks healthy and as expected, followed by comparative benchmarking against other open models using community standards and platforms. Cartography of Open Collaboration in Open Source AI Linaker et al. 5.3 Post-release Reuse Stage Summary Open collaboration in the reuse stage encompasses the downstream activities that occur after initial LLM release, spanning dissemination and adoption, derivative development, community feedback mechanisms, and collaborative improvements to associated datasets, software tools, and evaluation frameworks. These post-release collaborations often demonstrate greater openness and community engagement compared to the pre-training stage, with platforms like Hugging Face facilitating widespread distribution and reuse. Collaboration challenges: Model reuse collaborations face several structural limitations, including limited direct engagement between original developers and derivative model creators, with most collaboration happening indirectly through platform-mediated adoption rather than active co-development. Many organizations release code and models but lack resources to make them truly accessible for broader community use, requiring significant additional effort for documentation, generalization, and maintenance that extends beyond their primary research goals. Community engagement can be difficult to sustain over time, particularly for volunteer-based initiatives, and developers often struggle to balance providing support for diverse use cases while maintaining focus on their core objectives. Additionally, feedback mechanisms, while valuable, tend to be reactive rather than proactive, limiting opportunities for deeper collaborative development. Collaboration on-ramps: Despite these challenges, the model reuse stage offers numerous pathways for meaningful collaboration, particularly through established platforms that facilitate model dissemination, adoption, and community feedback. Organizations successfully collaborate through model adaptations and finetuning for specific domains (e.g., local languages, specialized applications), with many derivative projects building on open models like Llama, Pythia, and SEA-LION. Software tools and evaluation frameworks receive ongoing community contributions, including performance improvements, new features, and specialized benchmarks, with projects like GPT-NeoX and evaluation platforms benefiting from upstream contributions. Non-technical collaborations thrive through research publications that build on open artifacts, providing valuable insights back to original developers, while compute sharing initiatives help accelerate community projects and democratize access to computational resources needed for model development and evaluation. 5.3.1 Post-release: Model Collaborations Model collaborations during the post-release (or reuse) stage encompass the diverse ways developers and communities interact with and build upon released models, ranging from platform-mediated distribution to direct partnerships for specialized applications. While most collaboration occurs indirectly through adoption rather than active co-development, several pathways have emerged that enable meaningful engagement between model creators and users, including strategic partnerships, community feedback mechanisms, and domain-specific adaptations. Challenge: Network firewalls create international collaboration barriers. Geographical restrictions create friction for international collaboration in open LLM development, manifesting through both network firewalls and discriminatory licensing practices. I14 from Ant Group explains how the firewall in China creates collaboration barriers: we work internally because there is firewall. So, we just developed an internal model scope or model states in our internal GitLab, and regularly we upload our updates to GitHub and Hugging Face. We have regular update, for example, like once week, and we have some major updates like once per two months or three months. Challenge: Approval-based licensing discriminates against certain regions and organizations. LLMs that are released under restrictive licenses with gated access requirement (i.e., involving approval process) create barriers that can discriminate against certain regions or organizational affiliations. For example, I14 from Ant Group describes experiencing this exclusion when attempting to access Llama models: cannot apply for the [Llama] license because my identity says that Im in mainland China. On-ramp: Platforms like Hugging Face Hub democratize LLM access. Collaboration platforms serve as essential intermediaries that enable widespread model distribution and community access, effectively democratizing model availability beyond direct organizational relationships. These platforms provide standardized infrastructure that reduces barriers to model sharing and discovery. For example, I3 from EleutherAI explains their partnership approach: We have been collaborating with Hugging Face on model dissemination... Hugging Face platform is like the de facto way to share your models and to make things accessible to people. And so all of our models are released on the Hugging Face platform. Organizations like Masakhane similarly have created dedicated pages on Hugging Face Hub and GitHub where they centralize access to all their datasets and models, facilitating community engagement and reuse. 22 Cartography of Open Collaboration in Open Source AI Linaker et al. On-ramp: Government and enterprise partnerships enable customized model deployment. Organizations form strategic partnerships with governments and enterprises to enable adoption of open models for specific use cases, creating collaborative relationships that extend beyond simple model distribution to include technical support and customization guidance. These partnerships often serve as showcase examples that demonstrate model capabilities and encourage broader adoption. For example, I6 from Meta describes their government collaborations: We are working with the US government with llama and... have made Llama available for their use, while highlighting Singapores advanced adoption: One of the most forward-leaning governments Ive seen in terms of using these things is the Singapore government. Ive talked to fair amount with their AI team over there, and they deploy open models, including Llama, for ton of use cases. Similarly, I17 from Fraunhofer IAIS describes how Teuken 7B has been adopted by large German technology companies, including IONOS and Deutsche Telekom, with these companies actively promoting the model on social media. On-ramp: Adapting LLMs for local languages and contexts. Regional partnerships have focused on adapting base models for local languages and cultural contexts, often involving multiple stakeholders from geographic region working toward common goals like language representation. AI Singapore exemplifies this approach through the SEALION model ecosystem, where partners across Southeast Asia have fine-tuned the models for local applications. For example, organizations in Thailand (Visitec) and Indonesia (GoTo) have created derivatives, with GoTo developing customer service assistant integrated into their payments app that operates in Javanese, Sundanese, and Indonesian. This creates positive feedback loops where Many of these partners had contributed data and can now benefit from the open source model output, which further encourages future collaboration and motivation to share and pool resources. On-ramp: Community-driven feedback. Developers establish feedback mechanisms that enable community members to contribute feedback about model performance, limitations, and potential improvements. While feedback tends to be reactive rather than proactive, it provides valuable insights for model refinement. I8 from Ai2 acknowledges the value of community input: we are getting feedback from the community. That is always useful, while expressing interest in more structured engagement similar to the Aya projects approach of getting lot of language help for languages that they do not speak from the community. SpeakLeash also proactively collects community feedback through their public-facing interfaces for their Bielik model where Polish language community members could interact with the model and provide refinement suggestions, with the community ultimately contributing to numerous evaluation benchmarks developed for the project. On-ramp: Development of derivative models. Open model releases facilitate enable distributed practitioners to develop derivative LLMs without direct involvement by the developers of the base LLM. From finetune to experimentation, these community initiatives often explore directions that core teams do not or cannot pursue due to resource constraints. The Aya project illustrates this dynamic, where following model releases, collaborations within the community continue, both using the Aya models and to create further adaptations and derivations. For example, the Aya community built Maya (multimodal Aya) which the core Cohere for AI team was not actively involved in. Similarly, I16 from Masakhane describes their involvement in Lugha Llama, collaborative effort to fine-tune Llama for 20 African languages, which outperformed Llama on Global MMLU, demonstrating how community adaptations can achieve superior performance for specialized domains. On-ramp: Creating apps or demos to showcase model capabilities. Model developers collaborate with startups and enterprises to create demo applications that showcase model capabilities and explore potential use cases, benefiting both parties through technical validation and market visibility. These partnerships often involve fine-tuning and specialized applications that highlight the versatility of smaller or specialized models. I9 from Hugging Face describes their collaborations with startups around SmolLM: These are startups that do really nice things with these small models, so we were able to get some cool demos for our small models. They also collaborated with IBM to fine-tune the vision-language version for IBMs DocLing library, demonstrating that By specializing small models, you can achieve strong performance, close to that of larger models, while saving significantly on inference costs. On-ramp: Open LLM projects can catalyze follow-up community-driven initiatives. LLM releases can catalyze new collaborative initiatives that build upon lessons learned and resources developed, creating successive waves of community-driven projects with improved methodologies and focus. These follow-up projects often inherit infrastructure and knowledge while addressing limitations identified in earlier efforts. For example, I4 explains how the BigScience Workshop catalyzed the, the BigCode project, an open scientific collaboration working on the development and use of LLMs for code, came out of BigScience and was able to learn from what did not work in BigScience, including having more direction from the start and less experimental working groups. I4 characterizes BigCode as the spiritual successor in many ways that had different values, in part because it was in different medium, so software code. Similarly, I17 from Fraunhofer IAIS describes how Teuken 7Bs release has ignited new collaborations, including with Hessian AI and the University of Bonn, while attracting international interest from researchers who have offered to contribute language datasets for improving the model. 23 Cartography of Open Collaboration in Open Source AI Linaker et al. On-ramp: Partnerships on domain-specific applications. Some oganizations have focused on partnerships in specialized domains where model finetuning requires domain expertise. For example, I6 from Meta explains that they have focused on application of Llama for specific use cases like legal applications or medical applications. 5.3.2 Post-release: Data Collaborations Data collaborations during the post-release stage focus on the creation of datasets that help to improve the pre-trained LLM. These collaborations typically involve community-driven efforts to expand language coverage, develop specialized datasets for domains or tasks, or establish ongoing data collection mechanisms. On-ramp: LLM releases can catalyze community efforts to expand language coverage. Model releases catalyze ongoing community efforts to expand language coverage and improve data representation for underrepresented languages, often extending beyond the original project scope through sustained collaborative initiatives. These efforts leverage the infrastructure and momentum established during initial development while addressing gaps identified through community feedback. For example, I4 from the BigScience Workshop describes how BLOOMs release enabled continued development: developers extended BLOOM by adding new languages after most of the projects in the BigScience project had ended. This included both technical extensions, such as developer who built chat demo application from BLOOM for multilingual chat, and sustained data collection efforts, where an ongoing Arabic data initiative was able to expand its data sourcing by working with the BigScience Workshop, with I4 noting that lot of the work happened in parallel with the Arabic data sourcing for BigScience and kept going on. On-ramp: Creation of specialized datasets for emerging use cases. Open model releases inspire the development of specialized datasets that address specific use cases or methodological needs identified through model deployment and community experimentation. These derivative datasets often solve technical challenges that emerged during practical applications, contributing valuable resources back to the broader ecosystem. I8 from Ai2 explains how their open models enabled new dataset development: datasets and new model releases have emerged from Ai2s open models. This includes the Persona project which synthetically built attributes and personas used to improve data generation, which I8 characterizes as having been big unblocker for the team. These derivative datasets demonstrate how open model releases can catalyze innovation in data generation methodologies that benefit the broader community. On-ramp: Creating data collection platforms can enable long-term community engagement. Some developers have established data collection mechanisms following model releases to sustain ongoing community engagement and enable continuous improvement of language representation and model capabilities. These infrastructure investments create long-term collaborative platforms that extend the impact of initial model releases. For example, the Cohere for AI team built dedicated website for continuously collecting language data following their Aya model releases, creating sustainable mechanism for community members to contribute linguistic and cultural knowledge that can inform future model development and ensure continued expansion of language coverage and cultural representation. 5.3.3 Post-release: Software Collaborations Software collaborations during the post-release stage focus on maintaining and extending open-source frameworks and tools through community contributions, academic partnerships, and user feedback. While many organizations face resource constraints in making their software broadly accessible, collaborations emerge through specialized use cases, performance improvements, and adaptation needs that benefit both contributors and the broader ecosystem. Challenge: Resource constraints limit the ability to make open-sourced software generalizable. Developers often lack the resources necessary to transform internal tools into community-ready software, creating barriers to broader adoption despite open-source releases. The effort required to generalize, document, and maintain software for diverse use cases extends significantly beyond primary research objectives. For example, I15 from the National Library of Norway encountered this challenge with their Whisper model code: Absolutely everything is open, but that is more like principle, right? think there are two, three, maybe four people that has actually taken that code and used it as basis for their project... we have not put lot of effort into making this code generic. Also, we do not really have the resources for that. It is not our role to make general JAX training codes for Whisper out there, right? They acknowledge that It requires quite lot to get this up to level where absolutely everybody can use it and everything is well enough documented, highlighting the tension between open principles and practical resource constraints. On-ramp: Grant-funded research groups contribute significant framework improvements upstream. Academic research groups contribute significant improvements to open-source frameworks when they adapt tools in their projects, often contributing optimizations and features upstream that benefit the entire community. These collaborations typically emerge from grant-funded research projects that have both the resources and motivation to contribute back to the ecosystem. For example, I3 from EleutherAI describes substantial collaboration with Mila and the LAION project, who had received grant to train model on the US national Summit (now Frontier) supercom24 Cartography of Open Collaboration in Open Source AI Linaker et al. puter, used EleutherAIs GPT NeoX library to train their models. Their work resulted in the Red Pajamas models and dataset, with I3 explaining that this adaptation to get [the model] running easily on Summit was contributed upstream [to GPT-NeoX] by them because they wanted other people to be able to do the same things that they were able to do. Additional technical contributions have included advanced features like QLoRa implementation by Tim Detmers, who invented quantized low rank adaptation, helped to enable Quantized Low-Rank Adaptation (QLoRa) of models allowing them to run in very low resource settings. On-ramp: External users provide testing feedback and performance improvements. Developers receive contributions in the form of testing and feedback from external researchers and developers. These contributions often focus on improving usability, performance, and expanding applicability to new use cases. For example, I8 from Ai2 describes feedback on their OlmoOCR PDF parser: We got feedback from some folks at different organizations like... the folks in the Eleuther community who ... provide us with interesting test cases to use [and] we have academic collaborators who say... well, this could be useful for this set of manuscripts. You should consider whether it can work on transforming this. They also received practical contributions to their dataset analysis tools, including performance improvements from developer working on Korean language models who contributed performance-related data tools, which they ended up reusing themselves. I14 from Ant Group emphasizes that community feedback primarily focuses on code accessibility: There is rarely question about the reproducibility, but there are many questions about the readability. because you know our code is very engineering focused so it is not that easy to read for researchers... so we made some modifications given their suggestions. On-ramp: Framework adaptation and tool development. In some cases, developers develop and release new frameworks when existing tools do not meet their specific requirements, contributing specialized solutions that address gaps in the ecosystem. These contributions often emerge from practical needs during model development and can provide alternatives that serve different use cases or technical environments. For example, I17 from Fraunhofer IAIS describes developing their Modalities LLM framework after finding limitations with existing options: we changed it because it was not easy for us to use it out of the box, leading them to release their framework under MIT license alongside their Teuken 7B model, providing the community with additional options for LLM development. 5.3.4 Post-release: Evaluation Collaborations Evaluation collaborations during the post-release stage center on community-driven benchmarking platforms and continuous assessment initiatives that enable ongoing model comparison and performance tracking. These collaborations leverage shared evaluation infrastructure while expanding coverage through community contributions and maintaining up-to-date leaderboards that serve the broader ecosystems needs for transparent model comparison. On-ramp: Developers use shared evaluation tools to benchmark and compare LLM capabilities. Developers actively participate in community-managed benchmarking platforms that provide standardized evaluation frameworks and transparent model comparison capabilities, benefiting from shared evaluation infrastructure while contributing to ecosystem-wide performance tracking. These platforms serve as neutral ground for model comparison and help users make informed decisions about model selection. For example, I7 from BAAI explains their approach: we also submit [our models] onto some open community benchmarks. Usually, those kind of benchmarks are owned by some open source community. We submit our model onto them and use their benchmark to get another benchmark result, which will be easier for the users to compare our models performance with the performance of third parties models. This participation creates mutual value by providing developers with comparative context while enriching community benchmarking resources with additional model coverage. On-ramp: Continuous benchmarking. Evaluation platforms establish mechanisms for ongoing community contributions that expand benchmark coverage, update evaluation results, and incorporate new models and capabilities as the field evolves. These collaborative platforms create sustainable ecosystems where evaluation resources grow through distributed community effort rather than centralized development. I16 from Masakhane describes their AfroBench initiative: recently, we had this project called Afrobench... that tries to pull across all the resources that have been created across Africa. It is dataset, and then we create benchmark, and eventually we created leaderboard. The platform actively solicits contributions, with I16 explaining, we asked for contributors so as this paper gets out people are providing lot of feedback and people even contribute new evaluation so for example we have someone say okay have the results for gpt 4.1 we didnt cover it in our paper they provided all these results... we want to make this open that if you evaluate new model just give us the results and then well put it in the ranking. This approach enables continuous expansion and improvement of evaluation capabilities through community engagement. 25 Cartography of Open Collaboration in Open Source AI Linaker et al. 5.3.5 Post-release: Non-technical Collaborations Non-technical collaborations focus on research activities that build upon open artifacts to generate new insights, creating feedback loops where external research contributions inform future model development. On-ramp: Research on open artifacts provides valuable feedback to original developers. Researchers conduct research using open LLMs that generate valuable insights for the base model developers, providing indirect feedback that influences future development decisions. I8 from Ai2 describes the impact of external scientific research that uses open models and facilitates open model development. For example, they highlight the Fishing for Magikarp paper by Land & Bartolo [80], who found that unique token sequences (glitch tokens) lead to unpredictable but repeatable model failures, which can be at least partly traced to undertrained tokens, an hypothesis that is much easier to verify for models whose pretraining corpus is fully released. I8 notes that this research provided concrete insights about how vocabulary may impact stability of run during training...So, it was not like direct contribution, but it was finding that builds specifically on top of our artifacts and then it formed like whole line of exploration that made our models better. This demonstrates how transparency enables research that creates unexpected value for original developers."
        },
        {
            "title": "6 Motivations for engaging in the collaborative development of open LLMs (RQ2)",
            "content": "Summary We observe social, economic, and technological motivations that incentivize various stakeholders to participate in the collaborative development of open LLMs and related artifacts, as illustrated in Fig. 8. Social motivations: Democratizing AI access and development, knowledge sharing and community building, expanding language and cultural representation for underrepresented communities, providing mentorship and skills development opportunities, ensuring public accountability for publicly funded research (public money, public AI), gaining peer recognition, and pursuing ones passion for open source. Economic motivations: Building ecosystems to compete with leading AI companies, resource efficiency, gaining market recognition for expertise and capabilities, career development and recruitment, and business strategies that seek to enter markets and build ecosystems. Technological motivations: Promoting open science and reproducibility, standardizing LLM development and evaluation frameworks, demonstrating the competitive capabilities of small models, and leveraging technical advantages when building upon base LLMs rather than starting from scratch. 6.1 Social Motivations 6.1.1 Democratizing access and inclusion in AI development Democratizing access to state-of-the-art AI capabilities and ensuring broad inclusion in AI development is principal motivation for several open source AI developers. Organizations like AI Singapore conceptualize their work as public infrastructure that should remain open to prevent AI benefits from being concentrated within any single company or country. This democratization approach enables ecosystem building that brings together diverse stakekholders from public entities, philanthropic organizations, and private companies. For example, AI Singapore collaborates with both regional university labs and global technology companies like Google to collect data for Southeast Asian languages. Similarly, I4 from the BigScience Workshop emphasizes broad inclusion as the projects guiding value, investing significant resources in recruiting contributors beyond their personal networks. Furthermore, I5 from Cohere for AI describes how their community-driven approach brings together researchers from institutions of varying resources and prestige to collaborate, share knowledge, and advance AI research collectively. 6.1.2 Knowledge sharing and community building Building community of practice and enabling knowledge exchange is key motivation for many open LLM projects. This approach facilitates skill sharing, mutual learning, and the creation of more diverse contributor communities that strengthen the overall ecosystem. For example, I4 from the BigScience Workshop highlights how skill sharing and mutual learning were incentives for many volunteers. EleutherAI shares the mission of enabling access to open models while driving research innovation. I3 from EleutherAI describes how they provide platforms for researchers and peers Cartography of Open Collaboration in Open Source AI Linaker et al. Figure 8: Motivations of Open LLM Developers to meet, collaborate, and access necessary resources and infrastructure, with notable experts regularly joining their Discord community to help answer technical questions. 6.1.3 Expanding language and cultural representation in LLMs Expanding language and cultural coverage in LLM pre-training data is another primary motivation for many developers. In particular, these efforts seek to address the historical neglect of medium and low-resource languages in LLM development and ensure that LLMs serve global communities rather than only dominant language groups. Multiple projects demonstrate this motivation. Cohere for AIs Aya Initiative targeted coverage for 101 languages, while AI Singapore focused on 13 languages and dialects of Southeast Asia. Regional initiatives include SpeakLeashs focus on Polish language and culture, SCB 10Xs work on Thai language nuances, and the OpenGPT-X projects development of multimodal LLM performant in all 24 official EU languages. I11 from SCB 10X explains their motivation: The main motivation really came from [our head of AI strategy]. He wanted to build this model that was very open and would be very useful to all Thai people. Basically, the way he viewed it is language is something that is really cultural for us, and having the ability for Thai people to develop their own models, to understand the cultural nuances of Thai and to be able to integrate that into an LLM, that is something that we really want to do. The challenge of data accessibility compounds these representation issues. I16 from Masakhane describes how African datasets were historically collected but remained inaccessible to African researchers due to cost barriers: Prior to this community movement, many African datasets have been collected and Africans do not have access to them and have to pay... Their universities never prioritizes [access] because it is too expensive so eventually they do not get lot of research done. Eventually, we decided to address this by creating dataset. 27 Cartography of Open Collaboration in Open Source AI Linaker et al. 6.1.4 Mentorship and skills development Lowering barriers to AI research and creating mentorship opportunities, particularly for students, represents key incentive for organizations like Masakhane. They promote data collection and language skills as valuable contributions while providing comprehensive mentorship including programming, model training, GPU usage, experimental design, and academic writing. Several of their mentees have subsequently pursued graduate degrees abroad, demonstrating the programs effectiveness in developing AI talent. 6.1.5 Public accountability for publicly funded research For publicly funded R&D projects or labs, releasing outputs to the public represents both an ethical obligation and practical imperative. For example, I15 from the National Library of Norway explains their principle: We have the principle that we release whatever we are allowed to release here. We are paid by the government and so we should do that. Similarly, I17 from Fraunhofer IAIS emphasizes that because the compute resources used to train Teuken7B were funded by taxpayers (800,000 GPU hours for training plus additional experimentation hours), as this is taxpayers money it is good to give something back to the public. 6.1.6 Peer recognition Recognition motivates both individuals and organizations. I4 notes that open source communities and labs release models to get recognition and to shape the narrative around who is doing the best things and who is on top of their game. Individual recognition is also important for career development for individuals in academia and industry alike. 6.1.7 Personal passion Personal passion for open source motivates many individuals. For example, I14 from Ant Group comments that among the Chinese open source AI community, think 50% are PhD students with full passion and with 16 hours day they just sleep and work. 6.2 Economic Motivations 6.2.1 Ecosystem building for competitive advantage Open source provides strategic approach for building ecosystems where diverse stakeholder pool resources and avoid duplication to compete effectively with leading AI companies. This collective approach is particularly important for smaller organizations and regions lacking individual capacity to compete with major technology companies. For example, I1 from AI Singapore explains their ecosystem strategy of building foundations that are 70% complete, enabling others to develop the remaining 30% based on their specific needs. This approach allows smaller organizations to collaborate, pool resources like compute and data, enable model reuse, and avoid duplicated effort. Regional ecosystem building also represents crucial strategy for areas lacking major AI capabilities. For example, I11 from SCB 10X explains: we try to open source things because we want to foster innovation within Thailand and help the community grow, so that we can catch up with all the big tech players... We feel like we do not have the capacity to compete with, say, OpenAI. I17 from Fraunhofer IAIS emphasizes this need in the European context: in Europe we do not have companies that are as big in numbers as DeepSeek, let alone the US companies. So what we need in Europe instead is an ecosystem... Without open source, these ecosystems have no chance to grow fast or provide economic value. The BigScience Workshop demonstrates ecosystem benefits through the mobility of its contributors, who subsequently brought code, infrastructure, and techniques developed during the workshop to other organizations like Mistral and Cohere. The workshop also created direct benefits for Hugging Face as the coordinating organization, with I4 explaining that learnings from the collaboration shaped how the hub evolved, how the datasets library evolved, how the inference libraries, open source inference libraries that we are putting out evolved. 6.2.2 Resource efficiency through model reuse Economic considerations drive researchers and developers to derive models from existing LLMs rather than training new LLMs from scratch, enabling focused resource investment in fine-tuning for specific contexts not well covered by existing models. This approach is particularly valuable for organizations targeting specific languages or domains. For example, I11 from SCB 10X explains, [The project] is looking for solution that basically would be cheaper, so more cost-effective, and also more customizable. When it comes to open-source models, you can customize it 28 Cartography of Open Collaboration in Open Source AI Linaker et al. little more. Organizations like AI Singapore, SpeakLeash Foundation, and Typhoon leverage this approach to achieve specialized capabilities in Southeast Asian languages, Polish, and Thai respectively. Base model selection involves careful consideration of technical advantages for target applications. AI Singapore selected both Llama 3 and Gemma 2 models for complementary benefits, with I2 explaining that while Gemma better suits Southeast Asian languages due to tokenizer and data advantages, Llama offers superior ecosystem interoperability. Similarly, Cohere for AI chose Googles MT5 model for Aya 101 because of its broad language coverage across 100 languages, while SpeakLeash Foundation selected Mistral base models because they could achieve strong Polish language performance through fine-tuning. 6.2.3 Gaining recognition for expertise Gaining recognition for expertise is an important incentive for both companies and research institutes, enabling them to demonstrate capabilities and attract talent or funding. For example, I4 from the BigScience Workshop notes that open source participation allows developers and organizations to get recognition and shape the narrative around who is doing the best things and who is on top of their game. Similarly, I7 from BAAI describes how their open source strategy helps recruit top talent who might otherwise prefer to work in industry. Furthermore, for regions lacking major technology companies, this recognition becomes particularly valuable. I12 from SCB 10X explains: lot of parties in Thailand from industry who would like to be perceived as leader in the tech space here... if you only have proprietary, internal model, no one will know how good your model is. People will not talk about your stuff. Meanwhile, I14 from Ant Group describes corporate motivations to make their company famous because they contribute to the open source project [hoping] the project will mention their company name on the next release. 6.2.4 Career advancement Career advancement motivates researchers and developers, as working openly enables transparency and promotion of ones abilities to developer communities and potential employers. For example, I16 from Masakhane explains that for academic researchers open source and open science facilitate usage and citations of their work, which is key to academic career progression. 6.2.5 Business strategies (e.g., market entry, ecosystem expansion) Companies leverage open LLMs as strategic tools for market entry and ecosystem expansion. For example, I6 from Meta explains that they promote Llama models across third-party devices and platforms ranging from augmented reality glasses and mobile phones to medical devices. 6.3 Technological Motivations 6.3.1 Promoting open science and reproducibility Interests in open science and reproducibility drive many open LLM projects, with AI researchers seeking to recreate powerful closed-source models in transparent and reproducible ways. EleutherAI, the BigScience Workshop, and OpenGPT-X initially aimed to recreate OpenAIs GPT-2 and GPT-3 models. For example, I17 from Fraunhofer IAIS explains that he and his supervisor initiated their grant proposal for the OpenGPT-X project in order to build an open, reproducible GPT-3 in 2021 based on their scientific interest. Similarly, Hugging Faces SmolLM team and I14s lab at Ant Group sought to recreate DeepSeeks R1 model capabilities. I14 from Ant Group explains that DeepSeeks R1 release served as major motivator to reproduce the results and openly share the ingredients for doing so, particularly since DeepSeek only open sources its model weights, but not the datasets and the training frameworks. 6.3.2 Standardization Establishing open standards for LLM development enables researchers to build upon each others work effectively. For example, I3 from EleutherAI and I9 from Hugging Face explain that simplifying LLM pre-training motivated their development of the GPT-NeoX and nanotron libraries respectively. I9 emphasizes that, It would be nice if there was one pre-training framework everyone contributed to, but internal use cases and motivations often conflict. Some prefer production-ready frameworks, even if they come with more bloat, while others want lightweight frameworks with minimal features for easier experimentation. Hopefully, we can converge someday on balanced solution. The same motivation goes for standardizing evaluation tools. I7 from BAAI emphasizes their inability to evaluate models for every specific use case or domain, making community-developed benchmarks and evaluation frameworks essential. I3 from EleutherAI and I9 from Hugging Face also cite the ability to run systematic and reproducible LLM evaluations as key motivation for developing their LM Evaluation Harness and lighteval frameworks respectively. 29 Cartography of Open Collaboration in Open Source AI Linaker et al. 6.3.3 Demonstrating the capabilities of small models Advancing research on small models and proving their competitive capabilities against larger models is also motivation. For example, I9 from Hugging Face explains that SmolLM aimed to advance research on small models and prove that small models can compete with larger models, while being cheaper to operate."
        },
        {
            "title": "7 Governance and Community Engagement Approaches in Open LLM Projects (RQ3)",
            "content": "Summary We identify five organizational models in open LLM projects: In company projects (e.g. Metas Llama, Hugging Faces SmolLM), single company typically maintains centralized control of the LLM development process and may engage in selective collaborations with external stakeholders (e.g., in order to access specific expertise) prior to the release of the open LLM. Research institute projects include single research institute projects (e.g., SEA-LION, OLMO, Aquila) and multi-organizational research institute projects (e.g., OpenGPT-X). Grassroots projects encompass non-profit-sponsored grassroots projects (e.g., Pythia, Bielik, Aya) as well as company-sponsored grassroots projects (e.g., the BigScience Workshop). They utilize hybrid governance combining centralized project coordination with decentralized development and contributions. Community engagement strategies vary across these five organizational models as well as stages of the open LLM lifecycle, with less collaboration taking place during the pre-release stages due to structural constraints in the development of LLMs. Platforms like Discord, X, Slack, and Hugging Face Hub are commonly used for knowledge sharing and collaboration across distributed teams and developer communities. 7.1 Organizational Models and Governance Approaches in Open LLM Projects Open LLM developers coordinate their development processes using governance frameworks that reflect their institutional origins, resource constraints, and community engagement philosophies, including centralized control, distributed community-driven development, and hybrid approaches. We identify five organizational models: single company projects, single research institute projects, multi-organizational research institute projects, non-profit-sponsored grassroots projects, and company-sponsored grassroots projects, as illustrated in Fig. 9. Figure 9: Organizational models of open LLM projects 7.1.1 Company projects In single company projects, companies typically develop open LLMs through their internal processes, with limited external collaboration during the development stages. The LLMs are used and embedded in commercial products and services, thereby making up core components in their value offerings. The LLMs can also provide strategic tool for Cartography of Open Collaboration in Open Source AI Linaker et al. growing adoption through user communities and business ecosystems, and thereby drive both innovation and business value upstream to the companies. In these cases, the open LLM projects can be considered single company projects, similar to single companyor vendor-sponsored OSS projects. Meta and Hugging Face exemplify this centralized approach with their Llama and SmolLM projects respectively, which involved minimal external collaboration before the release of the models. The companies (or vendors) distribute decision power and authority, typically among its internal or contracted staff. With this authority, they make decisions and maintain final say on the design and implementation of the LLMs. The communities make up form of user community around the base models, while extending and enriching the models through post-release reuse and targeted modifications in derivative models (e.g., for specific languages or domains). The communities can make requests and input through communication channels and development platforms leveraged by the projects, something that the single company in turn can choose if and how to consider and respond to. Control of downstream use and any derivative models can be maintained through the companys licensing schema. For example, in the case of Metas Llama models which are released under the restrictive Llama Community License Agreement, the Llama trademark needs to be maintained in derivative model naming conventions and users above certain thresholds require special licenses. In essence, this limits the freedom of the user community, while still enabling their adoption and development of the base models under the current license terms. In some cases, companies initiate strategic collaborations with external stakeholder to gain access to specific expertise. For example, I11 from SCB 10X describes their partnership approach as existing on spectrum from formal agreements to casual collaborations where they jump in and help them. While their internal team handles most core work, they selectively engage external collaborators for specific tasks: We do outsource couple of people to help us on data collection and annotation as well and usually like other researchers who come help...There will be like some academic researcher in Thai university. We do have connections with them and we can ask them to come help. Such selective engagements allow companies to maintain control while accessing specialized expertise when needed. 7.1.2 Research institute projects Among research institutes, two governance models stand out among the sampled projects: single research institute and multi-organizational research institute open LLM projects. Single research institute projects. In single research institute projects, main research institute drives and has authority over the LLM development process, exemplified by Ai2 and AI Singapore. Still, there is high reliance of partners and donors to enable the research and model development, which extends soft power and influence beyond the single institutes. Collaboration with external partners can be characterized by bureaucratic constraints and formal procedures. For example, I1 from AI Singapore explains that as they are project at the National University of Singapore, on-boarding external contributions involve some bureaucracy involved in trying to formulate the scope of the partnerships with most contributions requiring contractual agreements. They must be clear about what theyre able to contribute or not...so that there is documentation for all of this so that everything is above board, especially when it comes to the fact that we are hosted by an academic institute that is renowned internationally. However, partnerships often exceed formal agreements: lot of the people who work with us end up contributing so much more than what is in the collaboration agreement, just because they want to do something good for the region. Multi-organizational research institute projects. Multi-organizational research institute projects bring several stakeholders together, typically through joint research and grant-funded projects. I15 from the National Library of Norway explains that collaborations are definitely driven through this kind of common financing from sources like the Norwegian Research Council or EU partnerships. Their neutral institutional position facilitates collaboration between competing organizations: as neutral actor, competing organizations have collaborated in quite few projects through us since we are sort of in the middle and we cannot sort of favor one party over another. The OpenGPT-X project is also formal multi-partner collaboration, involving 10 German organizations including research centers, universities, and companies with clearly defined work packages covering infrastructure optimization, data filtering, training, and evaluation. It is led by Fraunhofer IAIS and each partner had specific roles determined by the grant agreement, such as TU Dresden handling model evaluation and checkpointing procedures. The distribution of authority and decision power, and execution of it is therefore typically managed through joint partnership agreements. 7.1.3 Grassroots projects Grassroots projects have used hybrid governance approaches combining centralized coordination of critical infrastructure and decision-making, with decentralized community-driven development. Among the sampled projects, two models stand out: non-profit-sponsored and company-sponsored projects. 31 Cartography of Open Collaboration in Open Source AI Linaker et al. Non-profit-sponsored grassroots projects. the development and decision-making authority is maintained by core group of people who are hired or closely affiliated by nonprofit organization. The goal is typically to ensure the overall vision for the project, quality assurance and general productivity of its development, while still enabling community engagement and active collaboration. In non-profit-sponsored grassroots projects, EleutherAI operates with dual governance modes depending on project criticality, with I3 explaining, think that there isnt one governance to rule them all, but that governance structures and strategies are tools to accomplish your needs. For widely used tools like GPT-NeoX and LM Evaluation Harness, the core team maintain centralized control to ensure design consistency and avoid breaking previous implementations for the thousands of production users. I3 explains, We value community input... but that at the end of the day, that we are the decision makers... because our two big libraries that lot of people are using are used in production by dozens in the case of the training library and thousands in the case of the evaluation library. Simultaneously, EleutherAI supports bottom-up community projects through dedicated Discord channels where contributors self-organize independent initiatives. They also enable community leadership of official projects when staff bandwidth is limited: People come to us and say, Hey, this would be super cool. think you guys should do it. And we are like, Wed love to do that. We do not have someone who can be in charge of this right now. We are bandwidth constrained. Would you like to be in charge of it? I3 adds that their non-profit status provides flexibility that companies lack, as they are not concerned with building their ecosystem control or increasing others dependency on them. The SpeakLeash Foundation operates in similar way in empowering their community, including over 3,500 passive and 100 active Discord members. While project founders make critical decisions about training their Bielik models, the community operates in decentralized manner for other initiatives, such as educational adaptations. Their community created tools for data collection, quality assessment workflows, and human preference gathering applications, while contributing over 60,000 responses to toxicity assessment surveys. Another example of non-profit-sponsored grassroots project is that of Aya. Cohere for AI, the non-profit arm of the startup Cohere, positions themselves as initiators while empowering community contributors to shape the direction of projects. Their Aya project involved 3,000+ contributors, with I5 explaining that contributors from under-resourced languages showed particular passion: For many low resource languages, it is easier to collect data for because the people who speak those languages, they know it is low resource... theyve experienced it not being included in any language model. So, they are really passionate to contribute. Contributors could determine their involvement level and leadership roles, with the Cohere for AI team providing structure, pacing, and deadlines while maintaining that projects are clearly built by the community for the community. Company-sponsored grassroots projects. Company-sponsored grassroots projects differ from single company projects in that governance is more open and decentralized, while the sponsoring company typically has big influence and in some occasions the final say. prime example is that of the BigScience Workshop. The project organized community of over 1,000 volunteers from 250+ organizations into specialized working groups, though decision-making power remained concentrated with Hugging Face as the coordinating organization. While working groups covered areas like data, modeling, and organization, most Hugging Face employees participated, with 12-45 people working full-time on the project. Only Hugging Face interacted with compute administrators, and their Chief Scientific Officer held final decision authority. However, this committee approach faced efficiency challenges. I3 from EleutherAI comments: BigScience was done by committee and it left me with the impression that that was not great way to govern research project. It took lot of work, lot of time. Committees are very inefficient ways to reach consensus...when youre trying to kind of reach decision that can guide the behavior of dozens of people, it is not really about finding agreement. It is about finding compromise. This experience suggests that while inclusive, committee-based governance can create coordination overhead that may limit project efficiency. 7.2 Community Engagement Strategies and Platforms 7.2.1 Platform-mediated community building Different platforms serve distinct functions for communication and collaboration in the open source AI community, from real-time discussion and knowledge sharing to asynchronous collaboration and resource distribution. The choice of platforms impacts community dynamics and collaboration effectiveness. Discord is popular community hub and knowledge sharing platform, which enables real-time interaction and expertise sharing across diverse contributor communities. EleutherAIs Discord server functions as hub for conversation about AI technology, where, as I3 explains, experts join in on conversations regularly and help to answer questions, including developers from otherwise close sourced companies, as well as people who are just interested in AI technology. This creates valuable knowledge-sharing opportunities: Theyre able to come talk about it with other 32 Cartography of Open Collaboration in Open Source AI Linaker et al. researchers and this like mostly public environment, which is, think really great because, you know, we do not want knowledge to stay locked up. Similarly, I17 from Fraunhofer IAIS notes that Discord enables more lively scientific discussions compared to other platforms, facilitating community sharing of model modifications and optimizations. Slack is also widely used for coordination and partnerships, providing tools for communication and coordination in working groups and inter-organizational collaborations. For example, the BigScience Workshop used Hugging Face Slack for conversations and meeting coordination within and across working groups, with I4 explaining that it enabled working with people in different time zones and remains site for ongoing collaboration initiation. Multi-platform coordination is also common in projects spanning multiple regions and cultures. For example, Cohere for AI managed global coordination challenges through platform diversity, with I5 explaining they often held the same meeting in four different time zones and relied on Discord for asynchronous coordination and resource sharing. However, recruiting community leaders required adapting to local preferences: community leads for their 101 target languages preferred range of online platforms, including WhatsApp. 7.2.2 Community recruitment and growth strategies Targeted and open recruitment approaches enable projects to balance expertise needs with inclusive participation. The BigScience Workshop employed both strategies, starting with 200-300 targeted invites followed by open invitations that attracted around 1,000 participants. I4 explains how they sought to expand their recruitment efforts beyond their personal networks: definitely spent lot of time trying to look beyond that network for people who might be relevant, and then sending to the extent possible customized [invitations]... also trying to make sure to push in some of the directions that we were missing. So, for example, okay, so who is going to be interested in South America, who is going to be interested in if youre going to add African languages, who is going to be interested in working on that? They also recognized that expertise comes in several forms and emphasized that researchers could make both technical and non-technical contributions to the project. Fostering welcoming culture is crucial for organic community growth and sustaining community-driven projects. Cohere for AIs community spans from assistant professors in London to high school students in India, maintained through welcoming community norms. I5 explains their approach: think one of the main steps is just the creation of this Discord community and also how we are maintaining that community so it is very friendly open community there is no room really to be judgmental if you do not know something...we really have tried to set this tone and our community members are great at that. This culture enables bottom-up initiatives where connections form there can lead to research down the road. When project communities scale, it becomes valuable to hire full-time community manager who can animate the community. I16 from Masakhane explains their decision to hire community manager to be in charge of community and mentorship management and communications because previously they were reliant on volunteers, but volunteers move on due to life or job changes, and they want to continue running Masakhane as community initiative. 7.2.3 Community outreach and user engagement Showcase-driven engagement strategies is one way that open LLM developers are demonstrating the capabilities of their LLMs and seeking to increase adoption of their models and tools. For example, the Typhoon developers organized Typhoon Application Week to rally/grow the community and showcase applications. Rather than directly promoting usage, they have few examples of how we can use Typhoon in our workflow...just to kind of, like, inspire people or show people, hey, we can start using Typhoon in your workflow, in your applications. This approach builds community engagement through demonstration rather than direct marketing. Structured feedback collection and user support also enables open LLM developers to maintain relationships with their user communities while gathering improvement insights. AI Singapore created Developer Advocacy team to identify user needs and collect feedback in more structured way and expand the scope of the project beyond academic and technical aims. They provide early model access to partners for testing and feedback while accommodating community requests for different formats and deployment environments. I6 from Meta estimates their community size through platform metrics, noting 650 million downloads now of Llama models, derivatives, and there is like 60,000...basically, what would call forks, which are like models that have been finetuned and then re-uploaded. Collaborative events and networking create opportunities for relationship building in and beyond the projects community. I15 from the National Library of Norway describes participating in Hugging Face hackathons: Those have been very useful for us...You learn lot through those hackathons, right? But also because we get to know the people, both at Hugging Face, but also people from Sweden and Denmark, for instance, that we collaborated with later. So 33 Cartography of Open Collaboration in Open Source AI Linaker et al. those have been great meeting points. These events serve dual purposes of skill development and network building that enable future collaboration opportunities."
        },
        {
            "title": "8 Discussion",
            "content": "8.1 Implications for Research Our findings reveal that open collaboration on open LLMs extends far beyond the models themselves, encompassing interconnected artifacts that are used to develop LLMs, including training datasets, training frameworks, evaluation tools, compute partnerships, and knowledge sharing forums. These collaborations are driven by developers with diverse motivationsfrom democratizing AI access and development to building competitive ecosystemsand are coordinated various governance frameworks, from single company projects to non-profit-sponsored grassroots projects. Open collaboration on open LLMs and beyond. We find that collaboration in open LLM projects extends far beyond the models themselves, encompassing collaborations on interdependent artifacts that are crucial for developing and evaluating LLMs, including training and finetuning datasets, open source training and evaluation frameworks, open benchmarks, leaderboards, and compute partnerships. This finding challenges narrow model-focused views on open source AI, suggesting that research on open collaboration in open source AI requires wider perspective that considers how different artifacts and stakeholders interact throughout the development and reuse lifecycle of open LLMs. This finding expands Choksi et als [13] argument that the open source AI landscape should not be viewed as monolith but rather as fragmented constellation of both ephemeral and sustained developer communities with distinct expertise and interests, from technical optimization to domainor language-specific applications. Lifecycle-based collaboration patterns. We identify distinct collaboration patterns across LLM development stages that differ significantly from traditional OSS development practices. During pre-training, resource constraints and expertise requirements create selective collaboration through strategic partnerships (e.g., AI Singapore with Meta and Google), specialized contributions (e.g., an experts contribution of the mixture of experts architecture to EleutherAIs GPT-NeoX framework), and infrastructure sharing (BigScience Workshops access to the French governments supercomputer Jean Zay). The post-training stage exhibits limited but targeted collaboration through the sharing of model weights with trusted partners (e.g., Hugging Faces sharing of SmolLM weights with startups) and specialized dataset releases (e.g., BAAIs Infinity Instruct dataset). However, the post-release stage enables broad community participation through platform-mediated interactions including model fine-tuning (e.g., GoTos Javanese assistant from SEA-LION), evaluation contributions (e.g., AfroBenchs crowd-sourced benchmark expansion), and derivative development (e.g., the community-built Maya from Aya models). This lifecycle variation represents fundamental difference from typical OSS projects where collaboration remains relatively consistent across development stages. To speak in Raymonds terms [81], whether an open LLM initiative is developed with cathedral or bazaar approach may vary less from initiative to initiative but rather by lifecycle stage, with the pre-training and post-training stages generally taking cathedral approach due to the inherent structural factors. Social, economic, and technological motivations in open source AI. Open LLM developers have various motivations, including social motivations (e.g., democratizing AI, expanding language representation), economic motivations (e.g., ecosystem building, resource efficiency), and technological motivations (e.g., promoting open science, standardizing tools). The prominence of social motivationsparticularly around democratization and representationreflects the societal stakes of AI development, where concerns about concentration of power and technological sovereignty have become central to AI policy debates. Meanwhile, the economic motivations we observe suggest that open collaboration in AI is strongly intertwined with commercial strategies, as organizations recognize that open ecosystems can accelerate innovation, reduce costs, and establish competitive moats through network effects and ecosystem lock-in. Governance frameworks and organizational models in open LLM projects. We identify 5 distinct governance models in open LLM projects: single company projects, research institute projects, multi-institute projects, non-profitsponsored grassroots projects, and company-sponsored grassroots projects. In company projects, single company maintains centralized control throughout the pre-release LLM development stages, and may engage in strategic external partnerships to gain access to external expertise or resources. While the single company model has received attention in the OSS context [82], open source AI brings further nuances that need consideration, e.g., how to grow and engage the user communities across the various artifacts preand post release. Licensing practices and business model design is an important area for future work, exploring how they can help to support an open innovation and collaboration process, while ensuring business value for the company. 34 Cartography of Open Collaboration in Open Source AI Linaker et al. Public research institutes have used single institute and multi-organizational governance models. While similarities can be drawn to both singleand multi-company governance models in OSS [83], there are fundamental differences, e.g., in what incentivizes the organizations (e.g., science vs. profit), and how novel and valuable information is managed (e.g., open science vs. corporate trade secrets). Open collaboration may, hence, have larger potential in the context of projects operated by public research institutes. Yet, as these are governed by their respective funding sources, and complex partner and project agreements, openness can quite easily be stifled. Future work is needed to bring light on how open collaboration can be incentivized, enabled, and performed in the public research context at large. Grassroots projects employ hybrid governance models, combining centralized coordination with decentralized community development. Non-profit-sponsored projects like EleutherAI maintain dual governance modesmaintaining centralized control for critical tools and infrastructure (e.g., GPT-NeoX, LM Evaluation Harness) while supporting bottom-up community self-organization (e.g., through their Discord channel). Company-sponsored grassroots projects like the BigScience Workshop and Aya were coordinated by lead sponsor company Hugging Face and Cohere respectively but involved large volunteer communities.These grassroots models are the ones that showi the largest potential for open collaboration across our surveyed cases, and provide inspiration for both current and future open source AI projects, similar to community-driven OSS projects [84]. Future research may support the open source AI ecosystem to further expand on how governance and coordination practices can be designed and function both at small and high scale. Complexity further increases as consideration is required on how the peer-production model can accommodate the intricate dependencies across data, software and model collaborations and projects. While our analysis focused on open LLM project governance models, we note that, apart from copyright concerns and data licensing, the topics of responsible AI practices and safety considerations are largely absent in the findings. We note that this absence is striking given the growing policy focus on AI safety governance, especially as open models achieve near-parity with proprietary systems in reasoning, agentic capabilities, and multimodal generation. We recommend future research to investigate how open LLM developers are navigating AI safety considerations. Community engagement platforms. Platforms like Discord, X, Reddit, Slack, and Hugging Face Hub are popular platforms for knowledge sharing, discussions, and collaboration across geographic and organizational boundaries, with each serving distinct functions. Discord is widely used to facilitate knowledge sharing and community building (e.g., EleutherAIs server became hub for conversation about AI technology where experts help answer technical questions). Slack supports formal project coordination for structured collaborations. For example, in the BigScience Workshop, Slack enabled conversations and meeting coordination within and across working groups across time zones. Hugging Face Hub serves as the primary artifact sharing platform, functioning as the de facto way to share your models and to make things accessible to people. Platform choices also reflect cultural preferences. Cohere for AI discovered that community leaders across their 101 target languages preferred range of online platforms, including WhatsApp, requiring multi-platform coordination strategies. Given this distributed and multi-platform nature of open LLM collaboration, future research should adopt multi-platform approaches to capture the full scope of community interactions and coordination practices that span across these diverse platforms. 8.2 Recommendations for Practitioners Based on the interviews, we provide the following recommendations, presented in no particular priority order, for stakeholders seeking to support the global community of practitioners building more open future for AI. 8.2.1 AI researchers and developers Proactively engage with open source AI projects and communities. Do not wait for collaboration opportunities to find you; actively reach out to potential partners and communities. As I11 from SCB-10X advises: do not be shy and just reach out. Join Discord servers, participate in hackathons, and seek out opportunities to contribute to existing projects. Avoid reinventing the wheel. Before starting new project, check if solution already exists. As I12 from Typhoon emphasizes: Do not reinvent the wheel, lot of knowledge is out there. Building on existing foundations enables faster progress, is more resource efficient, and can lead to new collaborations. Experiment with open lab approaches following the Marin model. Experiment with open lab approaches that make the entire research process transparent by using OSS collaboration tools [18]. Build evaluation datasets to support targeted improvements in underrepresented languages. Invest in developing training and evaluation datasets for medium and low-resource languages that lack adequate representation in existing LLMs. 35 Cartography of Open Collaboration in Open Source AI Linaker et al. Develop open source tools and best practices for AI safety. As open models achieve near-parity with proprietary models, open source AI researchers and developers should develop and share tools and best practices for safe and responsible development, such as preventing malicious fine-tuning, verifying model integrity, and detecting misuse. Develop full-stack AI expertise beyond fine-tuning. I17 from Fraunhofer IAIS recommends mastering the entire AI pipeline from data collection to post training...own your data collection, your data filtering, your data processing, how you filter the model, how you evaluate your model. This comprehensive understanding can enable unique contributions and reduces dependence on commercial providers. Foster synergies between AI infrastructure providers, AI researchers, and industry. I17 from Fraunhofer IAIS recommends fostering synergies between researchers, compute providers, and industry partners to accelerate the translation of research into innovation, learning from the example of the Swiss AI initiative. Ensure fair compensation for inclusive participation. I16 from Masakhane emphasizes avoiding extractive relationships by understanding entry barriers for potential contributors, providing mentorship opportunities, and compensating contributors fairly. For example, I16 recommends asking contributors how they want to be recognized or compensated to maintain their motivation and overall community health. 8.2.2 AI companies Invest in ecosystems rather than competing alone. Particularly for companies outside major AI hubs, collaborative ecosystem development can collectively compete with industry giants. Pool resources for shared infrastructure, datasets, and standards while specializing in unique applications or regional needs. Explore hybrid governance frameworks. Learn from the grassroots project governance models, represented by EleutherAI, among others, which combines centralized control of critical production infrastructure by core team while enabling community engagement and the infusion of new ideas in bottom-up way. Invest and collaborate on data provenance and licensing clarity. While legal frameworks around training data usage may vary by jurisdiction (e.g., fair use or not), investing in clear data provenance can address practical and legal challenges faced by open LLM developers. Partner up and contribute to open source AI through compute donations. Grassroots projects and research institute projects are often dependent on the donation and provisioning of compute to train models. By contributing compute resources, companies can both support and benefit from open LLM projects. 8.2.3 Policymakers Fund public AI infrastructure, not just models. Public funding across the entire AI stack, including compute infrastructure, data curation, and OSS development and maintenance, can support the long-term sustainability of the open source AI ecosystem, while advancing crucial public interest areas, such as research, open source frameworks, and open benchmarks for AI safety. Support public interest projects via compute donations or subsidies. The examples of the French governments compute donation to the BigScience project and the crucial role of the Swiss National Supercomputing Centre in the Swiss AI initiatives development of the Apertus model highlight the role governments can play in funding the use of supercomputer infrastructure for the development of open LLMs that are designed for the public benefit. Support regional language and cultural representation through targeted initiatives. Fund collaborative projects like AI Singapores SEA-LION or Cohere for AIs Aya that engage native speaker communities in data collection and evaluation. This is especially relevant for public bodies representing cities, regions or countries with diverse language communities, as it can ensure that adoption of AI is paired with model capability improvements that will benefit all of these communities. Ensure public money, public AI principles with appropriate licensing. Require publicly funded AI research to use permissive licenses and release key artifacts (i.e., data, code, models, documentation) to maximize public benefit. Bridge the developer-policy gap on AI safety governance. Engage with open source AI developer communities to understand current safety best practices and support the development and adoption of open source safety tools, open benchmarks, and related resources, following the example of the UK AI Security Institute which maintains the open source Inspect framework for LLM safety evaluations. Promote unified definition of open source AI. The open LLM models surveyed come under various licensing conditions, complicating reuse and open collaboration of the models and across their communities. Using or requiring licenses that align with the OSIs Open Source AI definition in government-funded 36 Cartography of Open Collaboration in Open Source AI Linaker et al. projects could bring clarity about usage conditions, promote open innovation and policy goals relating to both interoperability and digital sovereignty. 8.2.4 Platform providers Enable multi-modal contribution pathways beyond code. Create infrastructure for data annotation, evaluation feedback, documentation, and non-technical contributions. Cohere for AIs success with 3,000+ contributors demonstrates the value of tools that make participation accessible. 8.2.5 Academic institutions Default to using licenses for open LLMs that uphold the four freedoms of open source, as proposed by the Open Source AI definition [39]. The use of open and standardized licenses that uphold the four freedoms of open sourceuse, study, modify, and redistributeenables collaboration within, beyond, and between research project lifespans, facilitating technology transfer, industrial applications, and advancements across scientific fields and disciplines. For example, the OpenMDW license is the first permissive license specifically designed for AI models which upholds all four freedoms of open source [85]. 8.2.6 Open source foundations Provide support structures for open LLM projects. Collaboration in open LLM projects across artifacts, such as as software, data and models, require diverse set of processes, governance models, and tools to function. Open source foundations can provide support structures and neutral grounds for stakeholders across industry, government, and academia to collaborate on the development of open LLMs and related artifacts. 8.3 Threats to Validity The validity of our research, as well as the threats to it, was informed by following guidance for qualitative software engineering research [86, 87]. 8.3.1 Internal Validity Internal validity concerns the extent to which causal relationships can be established and confounding factors are controlled [87]. We acknowledge several threats to internal validity. First, our purposeful sampling approach, whilst appropriate for exploratory research, may introduce selection bias as we prioritised models with high activity metrics (i.e., downloads and discussions in model repositories on Hugging Face Hub). This could systematically exclude smaller or emerging collaborative efforts that employ different practices and that lack significant network reach to publicize efforts. To address this concern, we additionally purposively sampled open LLM projects that are known to be spearheading open collaboration, such as EleutherAI and the BigScience Workshop. Second, our reliance on developer perspectives may create single-viewpoint bias, as we did not interview other stakeholders such as users or contributors, who might offer different insights into collaborative practices. Still, many of our interviewees take user and contributor role in the way they reuse extant resources (e.g., datasets) and base models in their work. Third, the retrospective nature of interviews may be subject to recall bias, where interviewees recollections of collaborative processes might be incomplete or influenced by subsequent experiences. Finally, social desirability bias may affect responses, as interviewees might present their collaborative practices in more positive light than reality. The two latter threats were addressed through reviewing on online sources about the models and the related collaborations (when possible) to provide contextual awareness to the analysis. 8.3.2 External Validity External validity concerns the generalizability of the findings [87]. We acknowledge that our qualitative analysis of 14 open LLM projects limits the generalizability of our findings, and the projects are certainly not representative of all open LLM projects. The sample represents specific subset of successful and well-known open LLM projects, potentially excluding smaller-scale, failed, or less visible collaborative efforts. Our sample also also does not represent emerging models of collaboration such as open labs (e.g., Marin) which have emerged toward the end of this research project [18]. Additionally, our focus on models hosted on Hugging Face Hub may not capture collaborative practices occurring on other platforms or through different distribution channels. While we acknowledge these limitations, we underscore that our research aim is exploratory and towards this end our sample provides diverse enough set to gain first glimpse into the context of open collaborative development of open LLMs and open source AI at large. 37 Cartography of Open Collaboration in Open Source AI Linaker et al. 8.3.3 Construct Validity Construct validity concerns the extent to which the measurements accurately represent the phenomenon under study [87]. Our use of download numbers and discussion counts in the model repositories on Hugging Face Hub as proxies for technical and social activity, respectively, may not fully capture the complexity of collaborative engagement. For instance, models with fewer downloads might still involve rich collaborative processes, whilst high download counts might reflect individual rather than collaborative usage. The categorisation of releasing entities into five types (large enterprises, SMEs, public research institutes, non-profit/grassroots, individuals) required subjective interpretation based on available online sources, potentially leading to misclassification. Additionally, our extended model lifecycle framework, whilst grounded in existing literature, represents our conceptual interpretation and may not align with how practitioners themselves understand collaboration boundaries and stages. 8.3.4 Reliability Reliability concerns the consistency and replicability of the data collection and analysis procedures [87]. To enhance reliability, all interviews were recorded and transcribed using offline transcription software to ensure accurate data capture. Our data coding and analysis process involved multiple authors using an abductive coding approach, with dual coding for all interviews to reduce potential biases that may arise when single author performs qualitative data analysis alone [88]. Audit trails were maintained throughout the research. Regular peer-debriefing sessions among the author team helped maintain consistency in interpretation and coding. In addition, we conducted member-checking by sending results to respondents for verification, increasing the reliability of the findings [89]. The iterative development of our code book, informed by the theoretical framework and refined through joint discussions, provides transparency in our analytical approach. Despite these efforts, we acknowledge that the subjective nature of qualitative coding means that different researchers might interpret the same data differently, and our findings remain inherently influenced by the research teams perspectives and prior knowledge of the open source AI ecosystem."
        },
        {
            "title": "9 Conclusion",
            "content": "This study contributes novel cartography of open collaboration in open source AI, shedding light on collaboration practices, motivations, and governance frameworks in 14 open LLM projects from diverse organizational contexts across North America, Europe, Africa, and Asia. This study makes three key contributions to research and practice. First, collaboration on open LLMs extends far beyond the models themselves, encompassing preand post-training datasets, benchmarks, open source training and evaluation frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships. Second, open LLM developers have variety of social, economic, and technological motivations, such as democratizing access to AI, expanding language representation, resource efficiency, and promoting open science. Third, the sampled open LLM projects exhibit five governance models (single company projects, research institute projects, multi-organizational research institute projects, non-profit-sponsored grassroots projects, and company-sponsored grassroots projects), which vary in the centralization of control and community engagement strategies used throughout the lifecycle of open LLMs. We concluded with practical recommendations for stakeholders who seek to support the global community of practitioners building more open future for AI. 38 Cartography of Open Collaboration in Open Source AI Linaker et al."
        },
        {
            "title": "A Acknowledgments",
            "content": "We would like to thank our research contributors from Ai2, AI Singapore, the BigScience Workshop, BAAI, Cohere Labs, EleutherAI, Hugging Face, Meta, the SpeakLeash Foundation, SCB 10X, Ant Group, the National Library of Norway, Masakhane, and OpenGPT-X for contributing their invaluable time and expertise to this study. In addition, we would like to thank Alek Tarkowski, Andrew Strait, Elizabeth Seger, Felix Sieker, Max Gahntz, Peter Cihon, and Matt White for their constructive feedback on previous versions of this manuscript."
        },
        {
            "title": "B Description of sampled open LLM projects",
            "content": "B.1 Allen Institute for AI (Ai2) Ai2 is US-based non-profit research institute that develops open models and tools to support science and education. Its OLMo language model series (e.g., OLMo 7B, OLMo 1.7 7B, OLMoE, and OLMo 2 7B/13B/32B ) is trained on openly licensed datasets, with transparent training documentation and reproducible code. Ai2 also develops fully open postraining pipelines (Tulu model series) and multimodal vision-language models (Molmo). Ai2 also contributes to throw software tools (e.g, OLMo Core, Open Instruct, OLMES) and benchmarks (e.g., ARC, HellaSwag). Hugging Face: 766 models, 265 datasets. See more: https://allenai.org/ and https://huggingface.co/allenai. B.2 AI Singapore AI Singapore is government-funded programme housed at the National University of Singapore. It develops open LLMs adapted to Southeast Asian languages and use cases, such as the SEA-LION model series and datasets covering Singlish, Malay, and other local languages. For example, they have released the SEA-PILE and SEA-HELM datasets for pre-training and evaluating LLMs for SEA languages. Its work supports Singapores national AI strategy, with international collaboration through the Open LLM Leaderboard and multilingual benchmarks. They also have website (https://sea-lion.ai/), playground for developer to chat with their models and create API keys to use their models (https://playground.sea-lion.ai/), and beta version of data hub for SEA data (https://aquarium.sea-lion.ai/). Hugging Face: 44 models, 18 datasets. See more: https://sea-lion.ai/ and https://huggingface.co/aisingapore. B.3 BigScience Workshop The BigScience Workshop was large-scale, year-long collaboration coordinated by Hugging Face in 202122, involving over 1,000 researchers globally from academia, civil society, and industry. Its main outputs were the BLOOM model, 176B-parameter multilingual LLM, and the ROOTS dataset, which contains over 60 multilingual corpora. The project also pioneered governance, and licensing norms for open LLMs, including the Responsible AI License (RAIL). Hugging Face: 162 models, 10 datasets. See more: https://bigscience.huggingface.co/blog/bloom and https://huggingface.co/bigscience. B.4 Beijing Academy of AI (BAAI) The Beijing Academy of AI is Chinese non-profit research institute supported by industry and academic institutions. BAAI has released several open LLMs, including the Aquila, OpenSeek and WuDao families, along with large-scale datasets such as CCI4.0-M2 (a Chinese-English mixed corpus). It forms the large-model open-source technical stack, FlagOpen, including open-sourced datasets, open-sourced benchmarks, open-sourced system software FlagOS and open-sourced algorithms FlagAI and lots of open-sourced models. Hugging Face: 149 models, 111 datasets. See more: https://huggingface.co/BAAI. B.5 Cohere Labs Cohere Labs (formerly Cohere for AI) is non-profit research lab affiliated with Cohere, Canadian AI company. It focuses on responsible open science and multilingual research. Key projects include Aya, family of models including Aya 101, Aya Expanse, and Aya Vision, as well as an open multilingual benchmark for over 200 languages. The group also supports ethical dataset creation and publishes detailed model documentation. Hugging Face: 16 models, 18 datasets. See more: https://cohere.com/research and https://huggingface.co/CohereLabs. 39 Cartography of Open Collaboration in Open Source AI Linaker et al. B.6 EleutherAI EleutherAI is grassroots research collective originally formed in response to OpenAIs decision not to release GPT3. It has produced several open LLMs, including GPT-J, GPT-NeoX, and the Pythia series, as well as the popular GPT-NeoX training framework. EleutherAI emphasises open access, research transparency, and critical reflection on model risks and limitations, often releasing detailed model cards and training logs. Hugging Face: 669 models, 226 datasets. See more: https://www.eleuther.ai/ and https://huggingface.co/EleutherAI. B.7 Hugging Face Hugging Face is an American startup that operates the Hugging Face platform for hosting, datasets, and tools. In addition to hosting third-party projects, Hugging Face develops its own models (e.g., SmolLM, BLOOM) and OSS libraries such as Transformers, Diffusers, and Evaluate. It plays central role in convening and coordinating the opensource AI ecosystem. The Hugging Face Smol Models Research team has 77 smol models (e.g SmolLM & SmolVLM) and 49 training datasets (e.g., FineWeb-Edu, Cosmopedia, Smollm-Corpus). See more: https://huggingface.co/ and https://huggingface.co/HuggingFaceTB. B.8 Meta Meta AI has developed the Llama series of large language models, including Llama 1, Llama 2, Llama 3, and Llama 4. These models are widely used in the open-source ecosystem and were released under commercially permissive license, the Llama Community License Agreement, which included an acceptable use policy and attribution. Meta also publishes research on training, evaluation, and alignment, and contributes tooling such as PyTorch, vLLM and open evaluation datasets. Hugging Face: 70 models, 11 datasets. See more: https://www.llama.com/ and https: //huggingface.co/meta-llama. B.9 SpeakLeash Foundation SpeakLeash is Polish non-profit organization developing open models and datasets for the Polish language, notably the Bielik family of models (v0.1-v3) trained on large-scale Polish corpora collected within Speakleash Foundations core project. They also release quantized Bielik models in order to increase the amount of people that can use them on even the least powerful machines. SpeakLeash collaborates with national infrastructure providers and academic institutions to improve Polish AI capabilities. Hugging Face: 67 models, 1 dataset. See more: https://speakleash. org/en/speakleash-a-k-a-spichlerz-english/ and https://huggingface.co/speakleash. B.10 SCB 10X Typhoon Project SCB 10X is the venture capital and innovation arm of SCBX group, one of Thailands largest financial technology business groups. Its Typhoon project aims to develop open-source language technologies optimized for Thai. Releases include large language models, vision models, and audio models, along with open curated datasets in Thai. The project supports local AI development and regional innovation. Hugging Face: 54 models, 26 datasets. See more: https://opentyphoon.ai/ and https://huggingface.co/scb10x. B.11 Ant Group Ant Group, is an affiliate fintech company of the Chinese technology firm Alibaba. Within Ant Group, there is team called inclusionAI, which works on open source projects, with focus on AI projects including LLMs and Reinforcement Learning (RL). Their Hugging Face profile states that their work is guided by the principles of fairness, transparency, and collaboration, and we are dedicated to creating models that reflect the diversity of the world we live in. Hugging Face: 28 models, 11 datasets See more: https://huggingface.co/inclusionAI and https://github.com/inclusionAI B.12 AI Lab, National Library of Norway The National Library of Norway hosts an AI Lab dedicated to developing open models for Norwegian and other Nordic languages. Projects include NB-BERT and the Norwegian Whisper fine-tuning series, used for speech-to-text transcription of library archives. The lab also releases high-quality datasets in Norwegian and other Nordic languages from the librarys archives and other public sector sources. Hugging Face: 166 models, 23 datasets. See more: https://ai.nb.no/ and https://huggingface.co/NbAiLab. 40 Cartography of Open Collaboration in Open Source AI Linaker et al. B.13 Masakhane Masakhane is community-led research collective focused on NLP for African languages. It works with researchers, linguists, and communities across Africa and the world to co-create datasets and train models in underrepresented and low-resource languages. Masakhanes decentralized, multilingual approach includes translation, language modelling, and speech recognition projects. Hugging Face: 359 models, 25 datasets. See more: https://www.masakhane.io/ home and https://huggingface.co/masakhane. B.14 OpenGPT-X OpenGPT-X was research consortium focused on the development of open LLMs that are made in Germany, involving 10 partners from business, research and the media. The project was led by Fraunhofer IAIS, German applied research institute, and funded by the German Ministry of Economic Affairs and Climate Action. The project aimed to build sovereign, open LLMs for European languages and use cases. Its flagship model Teuken 7B is performant in all 24 official EU languages [90]. OpenGPT-X has released derivative models, including Teuken-7Bv0.4 and Teuken-7B-v0.6. Hugging Face: 4 models, 0 datasets. See more: https://opengpt-x.de/en/ and https://huggingface.co/openGPT-X. 41 Cartography of Open Collaboration in Open Source AI Linaker et al."
        },
        {
            "title": "References",
            "content": "[1] S. Sonnenburg, M. L. Braun, S. O. Cheng, S. Bengio, L. Bottou, G. Holmes, Y. LeCun, K. R. Muller, F. Pereira, C. E. Rasmussen, G. Ratsch, B. Scholkopf, A. Smola, P. Vincent, J. Weston, and R. C. Williamson, The Need for Open Source Software in Machine Learning, Journal of Machine Learning Research, vol. 8, pp. 24432466, Oct. 2007. [2] M. Langenkamp and D. N. Yue, How Open Source Machine Learning Software Shapes AI, in Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, AIES 22, (New York, NY, USA), pp. 385395, Association for Computing Machinery, July 2022. [3] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, and others, Scikit-learn: Machine learning in Python, the Journal of machine Learning research, vol. 12, pp. 28252830, 2011. Publisher: JMLR. org. [4] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, PyTorch: An Imperative Style, High-Performance Deep Learning Library, in Advances in Neural Information Processing Systems (H. Wallach, H. Larochelle, A. Beygelzimer, F. d. Alche-Buc, E. Fox, and R. Garnett, eds.), vol. 32, Curran Associates, Inc., 2019. [5] arXiv, arXiv.org e-Print archive, 2024. [6] CommonCrawl, Common Crawl - Open Repository of Web Crawl Data, May 2024. [7] ImageNet, ImageNet, May 2024. [8] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2019. eprint: 1810.04805. [9] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, You Only Look Once: Unified, Real-Time Object Detection, 2016. eprint: 1506.02640. [10] M. White, I. Haddad, C. Osborne, Xiao-Yang, Liu, A. Abdelmonsef, and S. Varghese, The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI, Mar. 2024. arXiv:2403.13784 [cs]. [11] HuggingFace, Models - Hugging Face, Apr. 2024. [12] C. Osborne, J. Ding, and H. R. Kirk, The AI community building the future? quantitative analysis of development activity on Hugging Face Hub, Journal of Computational Social Science, June 2024. [13] M. Z. Choksi, I. Mandel, and S. Benthall, The Brief and Wondrous Life of Open Models, in Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency, FAccT 25, (New York, NY, USA), pp. 32243240, Association for Computing Machinery, June 2025. [14] J. Castano, S. Martƒ±nez-Fernandez, X. Franch, and J. Bogner, Analyzing the Evolution and Maintenance of ML Models on Hugging Face, Feb. 2024. arXiv:2311.13380 [cs]. [15] EleutherAI, EleutherAI Models, 2021. [16] J. Ding, C. Akiki, Y. Jernite, A. L. Steele, and T. Popo, Towards Openness Beyond Open Access: User Journeys through 3 Open AI Collaboratives, Jan. 2023. arXiv:2301.08488 [cs]. [17] C. Akiki, G. Pistilli, M. Mieskes, M. Galle, T. Wolf, S. Ilic, and Y. Jernite, BigScience: Case Study in the Social Construction of Multilingual Large Language Model, Dec. 2022. arXiv:2212.04960 [cs]. [18] D. Hall, A. Ahmed, C. Chou, A. Garg, R. Kuditipudi, W. Held, N. Ravi, H. Shandilya, J. Wang, J. Bolton, S. Karamcheti, S. Kotha, T. Lee, N. Liu, J. Niklaus, A. Ramaswami, K. Salahi, K. Wen, C. H. Wong, S. Yang, I. Zhou, and P. Liang, Introducing marin: An open lab for building foundation models. Blog post, May 2025. [19] A. Vaswani, Attention is all you need, Advances in Neural Information Processing Systems, 2017. [20] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, Language Models are Few-Shot Learners, in Advances in Neural Information Processing Systems (H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, eds.), vol. 33, pp. 18771901, Curran Associates, Inc., 2020. [21] J. Linaker and P. Runeson, Sustaining open data as digital commondesign principles for common pool resources applied to open data ecosystems, in Proceedings of the 18th international symposium on open collaboration, pp. 111, 2022. [22] Y. Benkler, Common wisdom: Peer production of educational materials, 2005. [23] J. Ding and A. L. Steele, Governance Opportunities in the Machine Learning Pipeline, June 2024. [24] C. Osborne, Open Source Software Developers Views on Public and Private Funding: Case Study on scikit-learn, in Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing, CSCW Companion 24, (New York, NY, USA), pp. 154161, Association for Computing Machinery, Nov. 2024. 42 Cartography of Open Collaboration in Open Source AI Linaker et al. [25] C. Osborne, Why Companies Democratise Artificial Intelligence: The Case of Open Source Software Donations, arXiv preprint arXiv:2409.17876, 2024. [26] C. Osborne, F. Daneshyan, R. He, H. Ye, Y. Zhang, and M. Zhou, Characterising Open Source Co-opetition in Companyhosted Open Source Software Projects: The Cases of PyTorch, TensorFlow, and Transformers, Proc. ACM Hum.-Comput. Interact., vol. 9, pp. CSCW046:1CSCW046:30, May 2025. [27] S. Don-Yehiya, B. Burtenshaw, R. Fernandez Astudillo, C. Osborne, M. Jaiswal, T.-S. Kuo, W. Zhao, I. Shenfeld, A. Peng, M. Yurochkin, A. Kasirzadeh, Y. Huang, T. Hashimoto, Y. Jernite, D. Vila-Suero, O. Abend, J. Ding, S. Hooker, H. Rose Kirk, and L. Choshen, The future of open human feedback, Nature Machine Intelligence, vol. 7, pp. 825835, June 2025. [28] I. Solaiman, M. Brundage, J. Clark, A. Askell, A. Herbert-Voss, J. Wu, A. Radford, G. Krueger, J. W. Kim, S. Kreps, M. McCain, A. Newhouse, J. Blazakis, K. McGuffie, and J. Wang, Release Strategies and the Social Impacts of Language Models, Nov. 2019. arXiv:1908.09203 [cs]. [29] D. Kang, T. Kang, and J. Jang, Papers with code or without code? Impact of GitHub repository usability on the diffusion of machine learning research, Information Processing & Management, vol. 60, no. 6, p. 103477, 2023. [30] R. Gorwa and M. Veale, Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries, Feb. 2024. arXiv:2311.12573 [cs]. [31] B. Laufer, H. Oderinwale, and J. Kleinberg, Anatomy of Machine Learning Ecosystem: 2 Million Models on Hugging Face, Aug. 2025. arXiv:2508.06811 [cs]. [32] S. Biderman, H. Schoelkopf, L. Sutawika, L. Gao, J. Tow, B. Abbasi, A. F. Aji, P. S. Ammanamanchi, S. Black, J. Clive, A. DiPofi, J. Etxaniz, B. Fattori, J. Z. Forde, C. Foster, J. Hsu, M. Jaiswal, W. Y. Lee, H. Li, C. Lovering, N. Muennighoff, E. Pavlick, J. Phang, A. Skowron, S. Tan, X. Tang, K. A. Wang, G. I. Winata, F. Yvon, and A. Zou, Lessons from the Trenches on Reproducible Evaluation of Language Models, 2024. eprint: 2405.14782. [33] DeepSeek-AI, D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi, X. Zhang, X. Yu, Y. Wu, Z. F. Wu, Z. Gou, Z. Shao, Z. Li, Z. Gao, A. Liu, B. Xue, B. Wang, B. Wu, B. Feng, C. Lu, C. Zhao, C. Deng, C. Zhang, C. Ruan, D. Dai, D. Chen, D. Ji, E. Li, F. Lin, F. Dai, F. Luo, G. Hao, G. Chen, G. Li, H. Zhang, H. Bao, H. Xu, H. Wang, H. Ding, H. Xin, H. Gao, H. Qu, H. Li, J. Guo, J. Li, J. Wang, J. Chen, J. Yuan, J. Qiu, J. Li, J. L. Cai, J. Ni, J. Liang, J. Chen, K. Dong, K. Hu, K. Gao, K. Guan, K. Huang, K. Yu, L. Wang, L. Zhang, L. Zhao, L. Wang, L. Zhang, L. Xu, L. Xia, M. Zhang, M. Zhang, M. Tang, M. Li, M. Wang, M. Li, N. Tian, P. Huang, P. Zhang, Q. Wang, Q. Chen, Q. Du, R. Ge, R. Zhang, R. Pan, R. Wang, R. J. Chen, R. L. Jin, R. Chen, S. Lu, S. Zhou, S. Chen, S. Ye, S. Wang, S. Yu, S. Zhou, S. Pan, S. S. Li, S. Zhou, S. Wu, S. Ye, T. Yun, T. Pei, T. Sun, T. Wang, W. Zeng, W. Zhao, W. Liu, W. Liang, W. Gao, W. Yu, W. Zhang, W. L. Xiao, W. An, X. Liu, X. Wang, X. Chen, X. Nie, X. Cheng, X. Liu, X. Xie, X. Liu, X. Yang, X. Li, X. Su, X. Lin, X. Q. Li, X. Jin, X. Shen, X. Chen, X. Sun, X. Wang, X. Song, X. Zhou, X. Wang, X. Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. Zhang, Y. Xu, Y. Li, Y. Zhao, Y. Sun, Y. Wang, Y. Yu, Y. Zhang, Y. Shi, Y. Xiong, Y. He, Y. Piao, Y. Wang, Y. Tan, Y. Ma, Y. Liu, Y. Guo, Y. Ou, Y. Wang, Y. Gong, Y. Zou, Y. He, Y. Xiong, Y. Luo, Y. You, Y. Liu, Y. Zhou, Y. X. Zhu, Y. Xu, Y. Huang, Y. Li, Y. Zheng, Y. Zhu, Y. Ma, Y. Tang, Y. Zha, Y. Yan, Z. Z. Ren, Z. Ren, Z. Sha, Z. Fu, Z. Xu, Z. Xie, Z. Zhang, Z. Hao, Z. Ma, Z. Yan, Z. Wu, Z. Gu, Z. Zhu, Z. Liu, Z. Li, Z. Xie, Z. Song, Z. Pan, Z. Huang, Z. Xu, Z. Zhang, and Z. Zhang, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025. eprint: 2501.12948. [34] Q. Team, Qwen2 technical report, 2024. [35] G. Team, A. Kamath, J. Ferret, S. Pathak, N. Vieillard, R. Merhej, S. Perrin, T. Matejovicova, A. Rame, M. Rivi`ere, and others, Gemma 3 technical report, 2025. [36] OpenAI, S. Agarwal, L. Ahmad, J. Ai, S. Altman, A. Applebaum, E. Arbus, R. K. Arora, Y. Bai, B. Baker, H. Bao, B. Barak, A. Bennett, T. Bertao, N. Brett, E. Brevdo, G. Brockman, S. Bubeck, C. Chang, K. Chen, M. Chen, E. Cheung, A. Clark, D. Cook, M. Dukhan, C. Dvorak, K. Fives, V. Fomenko, T. Garipov, K. Georgiev, M. Glaese, T. Gogineni, A. Goucher, L. Gross, K. G. Guzman, J. Hallman, J. Hehir, J. Heidecke, A. Helyar, H. Hu, R. Huet, J. Huh, S. Jain, Z. Johnson, C. Koch, I. Kofman, D. Kundel, J. Kwon, V. Kyrylov, E. Y. Le, G. Leclerc, J. P. Lennon, S. Lessans, M. Lezcano-Casado, Y. Li, Z. Li, J. Lin, J. Liss, Lily, Liu, J. Liu, K. Lu, C. Lu, Z. Martinovic, L. McCallum, J. McGrath, S. McKinney, A. McLaughlin, S. Mei, S. Mostovoy, T. Mu, G. Myles, A. Neitz, A. Nichol, J. Pachocki, A. Paino, D. Palmie, A. Pantuliano, G. Parascandolo, J. Park, L. Pathak, C. Paz, L. Peran, D. Pimenov, M. Pokrass, E. Proehl, H. Qiu, G. Raila, F. Raso, H. Ren, K. Richardson, D. Robinson, B. Rotsted, H. Salman, S. Sanjeev, M. Schwarzer, D. Sculley, H. Sikchi, K. Simon, K. Singhal, Y. Song, D. Stuckey, Z. Sun, P. Tillet, S. Toizer, F. Tsimpourlas, N. Vyas, E. Wallace, X. Wang, M. Wang, O. Watkins, K. Weil, A. Wendling, K. Whinnery, C. Whitney, H. Wong, L. Yang, Y. Yang, M. Yasunaga, K. Ying, W. Zaremba, W. Zhan, C. Zhang, B. Zhang, E. Zhang, and S. Zhao, gpt-oss-120b & gpt-oss-20b Model Card, Aug. 2025. arXiv:2508.10925 [cs]. [37] D. G. Widder, S. West, and M. Whittaker, Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI, Aug. 2023. [38] A. Liesenfeld and M. Dingemanse, Rethinking open source generative AI: open-washing and the EU AI Act, ACM, May 2024. [39] OSI, The Open Source AI Definition version 1.0, Oct. 2024. [40] I. Solaiman, The Gradient of Generative AI Release: Methods and Considerations, Feb. 2023. arXiv:2302.04844 [cs]. 43 Cartography of Open Collaboration in Open Source AI Linaker et al. [41] A. Basdevant, C. Francois, V. Storchan, K. Bankston, A. Bdeir, B. Behlendorf, M. Debbah, S. Kapoor, Y. LeCun, M. Surman, H. King-Turvey, N. Lambert, S. Maffulli, N. Marda, G. Shivkumar, and J. Tunney, Towards Framework for Openness in Foundation Models: Proceedings from the Columbia Convening on Openness in Artificial Intelligence, May 2024. arXiv:2405.15802 [cs]. [42] D. P. G. Alliance, Core considerations for exploring ai systems as digital public goods, July 2024. [43] I. K. Garcia, C. Erdmann, S. Gesing, M. Barton, L. Cadwallader, G. Hengeveld, C. R. Kirkpatrick, K. Knight, C. Lemmen, R. Ringuette, Q. Zhan, M. Harrison, F. M. Gabhann, N. Meyers, C. Osborne, C. Till, P. Brenner, M. Buys, M. Chen, A. Lee, J. Papin, and Y. Rao, Ten simple rules for good model-sharing practices, PLOS Computational Biology, vol. 21, p. e1012702, Jan. 2025. Publisher: Public Library of Science. [44] South Park Commons, Mark Zuckerberg on Llama, AI, & Minus One, Aug. 2024. [45] D. Patel and A. Ahmad, Google We Have No Moat, And Neither Does OpenAI, May 2023. [46] J. Linaker, G. Link, and K. Lumbard, Sustaining maintenance labor for healthy open source software projects through human infrastructure: maintainer perspective, in Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, pp. 3748, 2024. [47] G. von Krogh, S. Haefliger, S. Spaeth, and M. W. Wallin, Carrots and Rainbows: Motivation and Social Practice in Open Source Software Development, MIS quarterly, vol. 36, no. 2, pp. 649676, 2012. [48] K. R. Lakhani and R. G. Wolf, Why Hackers Do What They Do: Understanding Motivation and Effort in Free/Open Source Software Projects, Sept. 2003. [49] R. Subramanyam and M. Xia, Free/Libre Open Source Software development in developing and developed countries: conceptual framework with an exploratory study, Decision Support Systems, vol. 46, no. 1, pp. 173186, 2008. Place: Amsterdam Publisher: Elsevier B.V. [50] A. Hossain, Regional OSS Communities: The View From Dhaka, Bangladesh. 2021. [51] J. Linaker and B. Regnell, What to share, when, and where: balancing the objectives and complexities of open source software contributions, Empirical Software Engineering, vol. 25, pp. 37993840, 2020. [52] X. Li, Y. Zhang, C. Osborne, M. Zhou, Z. Jin, and H. Liu, Systematic Literature Review of Commercial Participation in Open Source Software, ACM Transactions on Software Engineering and Methodology, Aug. 2024. Just Accepted. [53] B. Birkinbine, Incorporating the Digital Commons: Corporate Involvement in Free and Open Source Software. University of Westminster Press, Feb. 2020. [54] K. Crowston, K. Wei, J. Howison, and A. Wiggins, Free/Libre open-source software development: What we know and what we do not know, ACM computing surveys, vol. 44, no. 2, pp. 135, 2012. Place: New York, NY Publisher: ACM. [55] N. Srnicek, Data, Compute, Labor, in Digital work in the planetary market (M. Graham and F. Ferrari, eds.), May 2022. [56] M. Fink, The business and economics of Linux and open source. Prentice Hall Professional, 2003. [57] J. Lerner and J. Tirole, Some Simple Economics of Open Source, The Journal of Industrial Economics, vol. 50, no. 2, pp. 197234, 2002. [58] P. Ahlawat, J. Boyne, D. Herz, F. Schmieg, and M. Stephan, Why You Need an Open Source Software Strategy, Apr. 2021. [59] H. Chesbrough, Measuring the Economic Value of Open Source, tech. rep., Linux Foundation, San Francisco, CA, USA, Mar. 2023. [60] M. Osterloh, S. Rota, and B. Kuster, Trust and Commerce in Open Source Contradiction?, pp. 129141, Jan. 2003. [61] P. J. Agerfalk and B. Fitzgerald, Outsourcing to an unknown workforce: exploring opensourcing as global sourcing strategy, MIS Quarterly, vol. 32, pp. 385409, June 2008. [62] W. Hasselbring, L. Carr, S. Hettrick, H. Packer, and T. Tiropanis, Open source research software, Computer, vol. 53, no. 8, pp. 8488, 2020. [63] K. Blind, S. Patsch, S. Muto, M. Bohm, T. Schubert, P. Grzegorzewska, and A. Katz, The impact of open source software and hardware on technological independence, competitiveness and innovation in the EU economy, tech. rep., European Commission, Brussels, Belgium, 2021. [64] C. Osborne, M. Boehm, and A. Jimenez Santamaria, The European Public Sector Open Source Opportunity: Challenges and Recommendations for Europes Open Source Future, tech. rep., The Linux Foundation, Brussels, Belgium, Sept. 2023. [65] C. Osborne, Public-private funding models in open source software development: case study on scikit-learn, May 2024. arXiv:2404.06484 [cs]. [66] P. B. De Laat, Governance of open source software: state of the art, Journal of Management & Governance, vol. 11, pp. 165177, 2007. [67] I. De Noni, A. Ganzaroli, and L. Orsi, The evolution of OSS governance: dimensional comparative analysis, Scandinavian Journal of Management, vol. 29, no. 3, pp. 247263, 2013. 44 Cartography of Open Collaboration in Open Source AI Linaker et al. [68] E. Capra and A. I. Wasserman, Framework for Evaluating Managerial Styles in Open Source Projects, in Open Source Development, Communities and Quality (B. Russo, E. Damiani, S. Hissam, B. Lundell, and G. Succi, eds.), (Boston, MA), pp. 114, Springer US, 2008. [69] S. Butler, J. Gamalielsson, B. Lundell, P. Jonsson, J. Sjoberg, A. Mattsson, N. Ricko, T. Gustavsson, J. Feist, S. Landemoo, and E. Lonroth, An Investigation of Work Practices Used by Companies Making Contributions to Established OSS Projects, in 2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering in Practice Track (ICSESEIP), pp. 201210, ACM, 2018. [70] S. OMahony, Nonprofit Foundations and Their Role in Community-Firm Software Collaboration, in Perspectives on Free and Open Source Software, pp. 393414, Cambridge, MA: MIT Press, 2005. [71] A. Lawson, M. Gerosa, S. Hendrick, and S. Biderman, 2023 open source generative ai survey report, 2023. [72] P. Runeson, T. Olsson, and J. Linaker, Open data ecosystemsan empirical investigation into an emerging industry collaboration concept, Journal of Systems and Software, vol. 182, p. 111088, 2021. [73] P. Heltweg and D. Riehle, Systematic Analysis of Problems in Open Collaborative Data Engineering, ACM Transactions on Social Computing, vol. 6, pp. 8:18:30, Dec. 2023. [74] S. Longpre, R. Mahari, A. Chen, N. Obeng-Marnu, D. Sileo, W. Brannon, N. Muennighoff, N. Khazam, J. Kabbara, K. Perisetla, et al., The data provenance initiative: large scale audit of dataset licensing & attribution in ai, 2023. [75] M. Wagner, M. Borg, and P. Runeson, Navigating the upcoming european union ai act, IEEE Software, vol. 41, no. 1, pp. 1924, 2023. [76] J. Phang, H. Bradley, L. Gao, L. J. Castricato, and S. Biderman, Eleutherai: Going beyond open science to science in the open, in Workshop on Broadening Research Collaborations, 2022. [77] D. G. Widder, D. Nafus, L. Dabbish, and J. Herbsleb, Limits and possibilities for ethical ai in open source: study of deepfakes, in Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, pp. 20352046, 2022. [78] Y. R. Shrestha, G. Von Krogh, and S. Feuerriegel, Building open-source ai, Nature Computational Science, vol. 3, no. 11, pp. 908911, 2023. [79] M. Q. Patton, Qualitative research & evaluation methods: Integrating theory and practice. Sage publications, 2014. [80] S. Land and M. Bartolo, Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models, Sept. 2024. arXiv:2405.05417 [cs]. [81] E. S. Raymond, The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary. Sebastopol: OReilly Media, Incorporated, 2001. [82] D. Riehle, The single-vendor commercial open course business model, Information Systems and e-Business Management, vol. 10, no. 1, pp. 517, 2012. [83] M. Schaarschmidt, G. Walsh, and H. F. von Kortzfleisch, How do firms influence open source software communities? framework and empirical analysis of different governance modes, Information and Organization, vol. 25, no. 2, pp. 99114, 2015. [84] T. A. Alrawashdeh, M. W. Elbes, A. Almomani, F. ElQirem, and A. Tamimi, User acceptance model of open source software: An integrated model of OSS characteristics and UTAUT, Journal of Ambient Intelligence and Humanized Computing, vol. 11, pp. 33153327, 2020. ISBN: 1868-5137 Publisher: Springer. [85] S. Winslow, M. White, D. Platz, J. Torres, J. McBroom, D. Rudin, R. Shatto, and M. Dolan, Openmdw license agreement v1.0. https://github.com/OpenMDW/OpenMDW, 2025. [86] P. Runeson and M. Host, Guidelines for conducting and reporting case study research in software engineering, Empirical software engineering : an international journal, vol. 14, no. 2, pp. 131164, 2008. Place: Boston Publisher: Springer US. [87] S. Easterbrook, J. Singer, M.-A. Storey, and D. Damian, Selecting Empirical Methods for Software Engineering Research, in Guide to Advanced Empirical Software Engineering (F. Shull, J. Singer, and D. I. K. Sj√∏berg, eds.), pp. 285311, London: Springer, 2008. [88] D. S. Cruzes and T. Dyba, Recommended Steps for Thematic Synthesis in Software Engineering, in 2011 International Symposium on Empirical Software Engineering and Measurement, pp. 275284, Sept. 2011. ISSN: 1949-3789. [89] Y. S. Lincoln and E. G. Guba, Naturalistic inquiry. Beverly Hills ; London: Sage, 1985. [90] M. Ali, M. Fromm, K. Thellmann, J. Ebert, A. A. Weber, R. Rutmann, C. Jain, M. Lubbering, D. Steinigen, J. Leveling, K. Klug, J. S. Buschhoff, L. Jurkschat, H. Abdelwahab, B. J. Stein, K.-H. Sylla, P. Denisov, N. Brandizzi, Q. Saleem, A. Bhowmick, L. Helmer, C. John, P. O. Suarez, M. Ostendorff, A. Jude, L. Manjunath, S. Weinbach, C. Penke, O. Filatov, F. Barth, P. Mirza, L. Weber, I. Wendler, R. Sifa, F. Kuch, A. Herten, R. Jakel, G. Rehm, S. Kesselheim, J. Kohler, and N. Flores-Herr, Teuken-7B-Base & Teuken-7B-Instruct: Towards European LLMs, Aug. 2025. arXiv:2410.03730 [cs]."
        }
    ],
    "affiliations": [
        "Boundary Object Studio London, UK",
        "Hugging Face Antwerp, Belgium",
        "RISE Research Institutes of Sweden Lund, Sweden",
        "University of Oxford Oxford, UK"
    ]
}