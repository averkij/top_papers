{
    "paper_title": "Structured Episodic Event Memory",
    "authors": [
        "Zhengxuan Lu",
        "Dongfang Li",
        "Yukun Shi",
        "Beilun Wang",
        "Longyue Wang",
        "Baotian Hu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency."
        },
        {
            "title": "Start",
            "content": "Zhengxuan Lu1,3, Dongfang Li2, Yukun Shi2, Beilun Wang1, Longyue Wang4, Baotian Hu2,3 1Southeast University, Nanjing, China 2Harbin Institute of Technology (Shenzhen), Shenzhen, China 3Shenzhen Loop Area Institute, Shenzhen, China 4Alibaba Group, Hangzhou, China 230249730@seu.edu.cn, lidongfang@hit.edu.cn 6 2 0 2 0 1 ] . [ 1 1 1 4 6 0 . 1 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of longterm interaction. To address this, we propose Structured Episodic Event Memory (SEEM), hierarchical framework that synergizes graph memory layer for relational facts with dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) have evolved into sophisticated agents capable of complex reasoning and long-term interaction (Achiam et al., 2023; Xi et al., 2025). However, LLM-based agents remain limited by their finite context windows and the lack of stable long-term memory system (Packer et al., 2023). This constraint causes reasoning capabilities to degrade over extended sessions, as the agent cannot effectively recall critical information once it exceeds the immediate context. Developing robust long-term memory is therefore central challenge in building autonomous agents. To address this, Retrieval-Augmented Generation (RAG) has emerged as standard paradigm to supplement LLMs with external knowledge (Lewis et al., 2020). Traditional RAG systems rely on vector similarity to retrieve local text passages (Karpukhin et al., 2020). While efficient, they often struggle with multi-hop reasoning tasks that require understanding the structural dependencies between disparate facts. Recent advancements, such as GraphRAG (Edge et al., 2024) and Mem0 (Chhikara et al., 2025), attempt to solve this by organizing information into graph databases. Nevertheless, these approaches face significant structural limitations. Most existing systems rigidly bind semantic content to fixed graph structures or predefined schemas. This rigidity mitigates the memory from dynamically reorganizing as new knowledge arrives. Consequently, these systems frequently suffer from scattered retrieval (Gutiérrez et al., 2025), where the retrieved context is fragmented into isolated pieces, failing to provide the coherent narrative required for complex reasoning. To bridge this gap, we propose Structured Episodic Event Memory (SEEM), hierarchical framework that transforms continuous interaction streams into cohesive dual-layer architecture. This system is composed of an Episodic Memory Layer (EML), which captures dynamic narrative progression by extracting and fusing structured Episodic Event Frames (EEFs) inspired by cognitive frame theories (Minsky, 1975; Fillmore, 1976), and complementary Graph Memory Layer (GML) that organizes static factual details into relational graph. Both layers are anchored to their original source passages via precise provenance pointers, which ensures that abstract memory units remain traceable to raw passages. During inference, these layers are synergized through hybrid retrieval process utilizing Reverse Provenance Expansion (RPE) mechanism, allowing the agent to reconstruct coherent and logically consistent context for complex reasoning. Extensive experiments are conducted on the LoCoMo (Maharana et al., 2024) Figure 1: Overview of the SEEM hierarchical memory architecture. The system transforms unstructured interaction passages into dual-layer representation, integrating semantic Graph Memory Layer for static facts with structured Episodic Memory Layer for event-centric details. This hierarchical design enables the agent to effectively synergize stable factual knowledge with dynamic narrative contexts for coherent long-term reasoning. and LongMemEval (Wu et al., 2025a) benchmarks. Our results demonstrate that SEEM consistently outperforms competitive memory-augmented and dense retrieval baselines. Notably, it surpasses HippoRAG 2 (Gutiérrez et al., 2025) by an absolute margin of 4.4% on LongMemEval. Moreover, supplemental tests under incremental construction settings confirm its stability and robustness for realworld sequential deployment. Our contributions are summarized as follows: We introduce SEEM, hierarchical framework that synergizes GML for relational facts with EML to capture dynamic narrative progression. We propose the EEFs and RPE mechanism, which transform interaction passages into multi-attribute cognitive units linked by provenance pointers to mitigate the scattered retrieval problem. We provide extensive empirical validation demonstrating that SEEM outperforms competitive memory-augmented and dense retrieval baselines in maintaining logical consistency and narrative coherence."
        },
        {
            "title": "2 Related Work",
            "content": "Vector-based RAG. RAG addresses the parametric constraints of LLMs by accessing external corpora via vector similarity (Lewis et al., 2020). However, standard RAG systems predominantly rely on flat vector spaces, which operate in de-contextualized manner (Gao et al., 2023). This often fails to capture the structural dependencies required for complex multi-hop reasoning, resulting in scattered retrieval where the retrieved context lacks the coherence necessary for consistent long-term interactions (Tang and Yang, 2024; Gutiérrez et al., 2025). Structured Semantic Memory. To bridge semantic gaps, structure-augmented approaches organize memory into knowledge graphs or hierarchical summaries. GraphRAG (Edge et al., 2024) and RAPTOR (Sarthi et al., 2024) utilize summaries to link related text segments, while HippoRAG 2 (Gutiérrez et al., 2025) leverages graph algorithms to facilitate associative retrieval. Despite these gains, such methods often suffer from lack of structural differentiation, where high-level thematic abstracts and fine-grained facts are entangled (Edge et al., 2024). Furthermore, heavy reliance on LLMgenerated summarization can introduce noise, causing performance on basic factual tasks to deteriorate compared to standard RAG (Cuconasu et al., 2024; Wu et al., 2025b). Episodic Memory. fundamental distinction exists between general semantic memory and episodic memory grounded in specific spatiotemporal contexts (Tulving et al., 1972). While recent systems such as Mem0 (Chhikara et al., 2025) and Graphiti (Rasmussen et al., 2025) track interaction histories, they may struggle to preserve coherent event contexts due to selective summarization or rigid entity-centric relations. Specifically, these methods frequently fail to integrate essential situational dimensions, including time, causality, and participants, into unified representation. Consequently, there remains need for hierarchical memory to handle the spatiotemporal dynamics of continuous interactions. In contrast, our proposed framework is designed to address this specific gap."
        },
        {
            "title": "3 Methodology",
            "content": "The SEEM framework transforms continuous stream of interaction passages into hierarchical memory architecture composed of two complementary layers. The Episodic Memory Layer (EML) focuses on capturing the narrative progression by extracting and fusing structured Episodic Event Frames (EEFs) while the Graph Memory Layer (GML) organizes static factual relations into structured relational graph. Both layers are grounded in original passages through system of provenance pointers, which maintain the link between abstract memory units and their raw passage. During inference, these layers are integrated through hybrid retrieval process utilizing the Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent and logically consistent context. 3.1 Problem Formulation The task of memory-augmented generation in longterm interactions is defined as follows. Given chronological sequence of interaction passages = {p1, p2, . . . , pT }, where each passage pt represents discrete unit of historical context, and current user query Q, the objective is to generate response that is factually consistent with and contextually relevant to q. We formulate this problem as the optimization of conditional probability (a q, P). Due to the significant length and semantic density of P, the task requires the construction of an intermediate memory representation to bridge the gap between historical evidence and current reasoning. The process is decomposed into two core stages: Memory Consolidation. We define transformation function Φ : that maps the raw interaction sequence into structured representation space M. This stage is designed to preserve essential thematic and relational information while mitigating the noise inherent in raw text. Conditioned Generation. retrieval augmented generation function G(q, M) is employed to identify relevant subset Msub based on the query q, leading to the final response generation: = arg max (a q, Msub; θ) (1) where θ denotes the parameters of the underlying generative model. Here, the core challenge lies in designing representation space that can effectively encode the narrative continuity and factual dependencies within P. The system must ensure that the transition from to maintains provenance, allowing the final generation process to be grounded in the original source evidence. 3.2 Episodic Memory Generation and Fusion To maintain coherent understanding of long-term interactions, we introduce structured episodic memory layer. Instead of storing raw interaction turns, we transform sequence of passages = {p1, p2, . . . , pT } into discrete, event-centric units. As illustrated in Figure 1, this process consists of two phases: (1) extracting structured episodic event frames from each passage and (2) performing associative consolidation to merge related frames. 3.2.1 Episodic Event Frame Extraction We treat each passage pt as source signal to be instantiated into cognitive frame. Following the principles of frame semantics (Fillmore, 1976), an EEF et encapsulates the structured semantics of pt. We employ an LLM-based agent, Fext, to parse pt into granular semantic roles and high-level summary. To ensure the abstract memory remains grounded, each frame is linked back to its source passage via provenance pointer ρeml . The formal definition is: et = Fext(pt; θ) ρeml = (cid:68) , vsum, (cid:110)(cid:10)vpar, vact, vtmp, (cid:69) (cid:11)(k)(cid:111)Nt k=1 vspa, vcau, vman (2) where vsum is the event summary, and the subsequent components represent semantic roles: Participants (vpar), Action (vact), Time (vtmp), Location (vspa), Causality (vcau), and Manner (vman). This hierarchical structure allows the agent to navigate memory through both thematic abstractions and precise textual anchors. 3.2.2 Associative Consolidation and Fusion To mitigate memory fragmentation, we implement an associative fusion mechanism that merges related observations into coherent scenes. When generating new candidate frame et, the system retrieves the most relevant historical frame eprev and uses an LLM-based judge to determine if they belong to the same event: δt Fjudge(et, eprev promptsim) (3) Figure 2: Overview of the associative consolidation and fusion. The Fext first transforms raw interaction passages into structured EEFs, which are then processed by Fjudge for the dynamic fusion of semantically related events. This mechanism aligns with associative consolidation to maintain coherent and synthesized episodic memory store. If δt = 1, the integration agent Ffuse performs an associative merge, synthesizing the attributes of both frames and updating the summary vsum. Note that we aggregate their provenance pointers, updating ρeml to point to the union of all involved source passages. This ensures that single consolidated frame can later serve as an entry point to all relevant evidence scattered across different turns. 3.3 Graph Memory Construction While the EML captures the narrative flow, the GML organizes static facts into consistent relational structure. 3.3.1 Fact Extraction and Grounding For each passage pt, the system extracts set of relational quadruples Kt to form schema-agnostic knowledge graph: Kt = {(s, r, o, τ ) s, E, R, τ } (4) where and are entities, is the relation, and τ denotes the temporal validity. Each node in the graph is also linked to its source passage via provenance pointers ρgml . To maintain graph integrity, we merge nodes that exceed vector similarity threshold, bridging lexical variations across different passages. 3.4 Hybrid Retrieval and Context Integration During inference, we integrate the structured facts from the GML with the narrative details from the EML through multi-stage retrieval process. 3.4.1 Relational Propagation and Passage Retrieval The system initiates retrieval by extracting structured quadruples from the query to ensure structural alignment with the GML. shared semantic encoder transforms each query-derived quadruple into dense vector representation. The retrieval engine then computes the semantic similarity between these query vectors and the pre-indexed embeddings of the facts store within the GML using cosine similarity. By ranking these scores across the relational space, the system identifies the most relevant facts to form the initial seed set Ktop. We then execute propagation algorithm (Haveliwala, 2002) using Ktop as the seed set to compute distribution over graph nodes. This relational traversal identifies the set of most relevant initial passages Pret = {p1, p2, . . . , pn} through their provenance pointers. 3.4.2 Reverse Provenance Expansion Initial retrieval often suffers from context fragmentation because critical details of an event may be scattered across multiple turns that lack direct lexical overlap with the query. To solve this, we use the EML as semantic bridge. We first retrieve the event frames associated with the initial passages: Eret = (cid:83) Φ(p), where Φ(p) identifies the pPret frames linked to passage p. We then implement the reverse provenance expansion mechanism. By accessing the aggregated provenance pointers ρeml(e) of each retrieved frame (as formed during the fusion phase in Section 3.2), we expand the evidence set to include all related passages: Pf inal = Pret (cid:91) ρeml(e) (5) eEret This ensures that if any fragment of an event is activated, all its constituent textual supports are included in the final context, providing complete narrative for reasoning. 3.4.3 Context Synthesis The final reasoning context is synthesized by serializing the expanded passages Pf inal, the structured event frames Eret, and the relational facts Ktop. This composite context enables the LLM to resolve temporal ambiguities and maintain logical consistency by cross-referencing high-level facts with nuanced episodic evidence. Finally, the agent generates the predictive response by conditioned on the query and the synthesized context C. We model this process as sequence generation task, where the LLM acts as decoder that maximizes the joint probability of the output tokens: (cid:89) (yi y<i, q, C; θ) = G(q, C) = arg max i=1 (6) where yi denotes the i-th token of the candidate answer a, and θ represents the parameters of the generator. By prepending the structured memory evidence directly to the input space, the model can perform integrated reasoning across both episodic and relational knowledge, ensuring that the final output is not only grounded in raw evidence but also guided by the high-level semantic structure captured during the memory construction phase."
        },
        {
            "title": "4 Experimental Setup",
            "content": "4.1 Datasets To rigorously evaluate the long-term memory and reasoning capabilities of our framework, we conduct experiments on two representative bench- (1) LongMemEval (Wu et al., 2025a) marks: serves as comprehensive testbed for memoryaugmented chat assistants, designed to simulate dynamic, evolving user-agent interactions. The dataset comprises 500 manually curated questions that assess five core memory competencies. These include information extraction (spanning single-session user, assistant, and preference details), multi-session reasoning for synthesizing fragmented information, temporal reasoning regarding event timelines, and knowledge updates to track changing user states. This benchmark is particularly challenging due to its requirement for maintaining factual consistency across extensible chat histories. (2) LoCoMo (Maharana et al., 2024) focuses on the comprehension of extremely long-term, open-domain conversations. Derived from long-form multi-session dialogues that span up to 32 sessions with an average of 16k tokens, this benchmark provides rigorous assessment of long-range dependency modeling. We utilize its question answering component, which consists of 1,986 samples categorized into five distinct reasoning types: single-hop and multi-hop reasoning for context retrieval, temporal understanding, opendomain knowledge integration, and adversarial reasoning to test robustness against hallucinations on unanswerable queries. 4.2 Metrics We evaluate SEEM using combination of lexical and semantic metrics to capture both surface-level similarity and high-level factual consistency. For LoCoMo, we employ token-level F1 (Maharana et al., 2024) and BLEU-1 (Papineni et al., 2002) for lexical comparison. To further assess semantic correctness and factual accuracy, we utilize LLMas-a-Judge (J). Specifically, the judge evaluates model responses using the multi-dimensional evaluation prompts introduced in Mem0 (Chhikara et al., 2025), with DeepSeek-V3.2 (Liu et al., 2025) serving as the underlying scoring engine. For LongMemEval, we strictly adhere to the evaluation protocol described in Wu et al. (2025a), which utilizes the LLM to perform binary assessments of answer correctness and reports the resulting accuracy. These metrics collectively provide rigorous basis for measuring performance across diverse long-term interaction scenarios. 4.3 Baselines We compare SEEM against the following approaches: KaLM-Embedding-V2.5 (Zhao et al., 2025) employs compact decoder-only architecture modified with bidirectional attention and meanpooling, leveraging high-quality data scaling and advanced training techniques to achieve competitive performance as versatile and efficient embedding model. NV-Embed-v2 (Lee et al., 2025) optiMethod LoCoMo LongMemEval Dense Retrieval KaLM-Embedding-V2.5 (Zhao et al., 2025) NV-Embed-v2 (Lee et al., 2025) Memory-based Frameworks Mem0 (Chhikara et al., 2025) A-MEM (Xu et al., 2025) HippoRAG 2 (Gutiérrez et al., 2025) SEEM (Ours) BLEU-1 F1 44.4 53.0 34.2 45.7 53.8 56.1 47.9 57. 43.3 44.6 58.3 61.1 64.6 74.7 54.1 61.9 76.2 78.0 Acc. 55.6 58.4 56.7 55.2 60.6 65. Table 1: Performance comparison on LoCoMo and LongMemEval. The best results are highlighted in bold. Method A-MEM HippoRAG 2 SEEM (Ours) Multi-hop (Count: 282) Temporal (Count: 321) Open-domain (Count: 96) Single-hop (Count: 841) Adversarial (Count: 446) 29.4 31.9 32.3 39.7 53.4 54.6 15.0 34.7 26.6 37.6 54.2 58. 78.3 94.2 96.9 Table 2: Detailed F1 performance breakdown across five question categories on the LoCoMo benchmark. Sample counts for each category are indicated in parentheses. Best results are highlighted in bold. mizes decoder-only LLM architecture by incorporating latent attention layer and bidirectional attention mechanisms to yield high-performance generalist text embeddings for dense retrieval. HippoRAG 2 (Gutiérrez et al., 2025) adopts neurobiologically grounded framework that synergizes Personalized PageRank with retrieval-augmented generation, facilitating complex multi-hop reasoning through the integration of dense vector retrieval and sparse knowledge graph structures. A-MEM (Xu et al., 2025) implements an agentic memory system inspired by the Zettelkasten method, enabling the dynamic construction and autonomous evolution of interconnected memory notes to refine knowledge representations over time. Mem0 (Chhikara et al., 2025) provides scalable memory architecture that dynamically extracts and consolidates conversational history into salient facts, supporting explicit operations to maintain long-term consistency in agentic interactions. 4.4 Implementation Details We standardize the backbone models across all methods to ensure fair comparison. We primarily employ Qwen3-Next-80B-A3B-Instruct (Yang et al., 2025) for both information extraction and downstream question answering tasks. To further demonstrate the model-agnostic robustness of the SEEM framework, we further conduct additional experiments using GPT-OSS-120B (Agarwal et al., 2025) as the backbone. Detailed results for this cross-model validation are provided in Appendix A.1. Regarding retrieval configurations, we align the hyperparameters based on the granularity of the retrieved units. For standard RAG baselines that rely on dense retrieval, we set the retrieval count to 5, fetching the top-5 original interaction messages. Similarly, for the memory-augmented baselines Mem0 and A-MEM, we retrieve the top10 processed memory chunks. For HippoRAG 2, which operates on session-based retrieval logic, we utilize the top-5 retrieved chunks to construct the context for final response generation. In our proposed SEEM framework, we configure the system to retrieve the top-5 relevant text chunks alongside their associated episodic memories to construct the reasoning context. To balance narrative continuity with information density, we employ selective RPE strategy. Specifically, the total size of the final expanded evidence set Pf inal is restricted to at most twice the initial retrieval budget."
        },
        {
            "title": "5 Results",
            "content": "5.1 Main Results Table 1 summarizes the performance of SEEM and several baseline methods on the LoCoMo and LongMemEval benchmarks, while Table 2 provides detailed breakdown across different question categories. Overall, experimental results indicate that SEEM yields the highest scores across most evaluation metrics, reflecting its capacity for managing long-term agentic memory. Comparison with Dense Retrieval. As shown in the first group of Table 1, while advanced dense retrieval models such as NV-Embed-v2 exhibit competitive performance in fetching local information, they remain limited by the absence of structured memory state. SEEM exceeds the performance of NV-Embed-v2 by 3.2% in F1 score and 3.3% in LLM-as-a-Judge (J) score on LoCoMo. This performance gap suggests that pure vector-based retrieval, although efficient, may not fully capture the intricate relational and temporal dependencies of long-term interactions. By integrating structured EEFs and relational quadruples, SEEM provides context that is more logically grounded compared to simple embedding-based matching. Comparison with Memory-based Frameworks. SEEM consistently outperforms the evaluated memory-based systems across both benchmarks. On LoCoMo, SEEM achieves an F1 score of 61.1 and score of 78.0, exceeding HippoRAG 2, by 2.8% and 1.5% respectively. It is observed that older memory frameworks yield lower performance scores, likely due to their reliance on flatter storage structures when processing extremely long interaction streams. In contrast, our hierarchical architecture facilitates an organized representation of complex event sequences. This trend is evident on LongMemEval, where SEEM achieves 65.0% accuracy, representing 4.4% absolute improvement over HippoRAG 2. Performance by Question Category. The categorical breakdown in Table 2 provides further insights into the frameworks strengths. SEEM exhibits superior performance in four out of five categories, with notable gains in single-hop and temporal reasoning. The advantage in temporal queries suggests that the event-centric indexing within the episodic layer effectively maintains chronological narrative flow. Furthermore, SEEM achieves high score in the adversarial category, indicating that its provenance-based grounding helps distinguish factual evidence from distractors. Conversely, SEEM shows lower performance in the open-domain category compared to HippoRAG 2. This suggests that for queries lacking specific narrative anchors, purely graph-based retrieval approach without episodic expansion may be more efficient. Figure 3: Impact of the initial retrieval size (Pret). Semantic vs. Lexical Performance. key observation is that the performance gains of SEEM are particularly evident in the LLM-as-a-Judge (J) and LongMemEval accuracy (Acc.) metrics. These metrics prioritize semantic alignment and factual correctness over surface-level word overlap (measured by BLEU-1). The scores in these categories indicate that SEEM does not merely retrieve relevant text but also reconstructs the underlying narrative logic. This synthesis is primarily driven by the RPE mechanism, which ensures that retrieved fragments are expanded into complete event contexts to support accurate reasoning. 5.2 Hyperparameter Sensitivity Analysis We analyze the impact of the initial retrieval size Pret on the reasoning performance of SEEM. This parameter controls the number of seed passages retrieved from the GML before any expansion occurs. Figure 3 shows the performance trends for F1 and as Pret varies from 3 to 10. We observe consistent improvement in both metrics as the initial retrieval window expands. Specifically, increasing Pret from 3 to 10 results in 5.9% gain in F1. Notably, SEEM does not exhibit the typical performance degradation often seen in traditional RAG systems when the context window grows. This positive correlation suggests that our framework can effectively leverage broader range of initial evidence to refine its final answer without being overwhelmed by the additional potential noise in the retrieved passages. 5.3 Ablation Study We conduct an ablation study to evaluate the individual contributions of the core components. We compare the full framework against four variants: (1) w/o Fact Provisioning, which excludes the inConfiguration SEEM (Full Model) w/o Fact Provisioning (Ktop) w/o Relational Propagation w/o RPE w/o EEF (Eret) LoCoMo BLEU56.1 55.2 54.5 55.1 53.5 F1 61.1 60.4 59.6 60.2 58.5 78.0 77.7 76.3 77.1 75.0 Table 3: Ablation study of key components in the SEEM framework on the LoCoMo benchmark. jection of relational quadruples; (2) w/o Relational Propagation, which replaces the graph-based seed set expansion with direct lexical retrieval; (3) w/o RPE, which disables the Reverse Provenance Expansion mechanism; and (4) w/o EEF, which removes the structured episodic event frames. Contribution of System Components. As shown in Table 3, the removal of any component leads to measurable decrease across all evaluation metrics, confirming their synergy. The relational propagation mechanism serves as the foundation for identifying relevant historical entries; its absence results in notable decline in the LLM Judge score, as the system struggles to navigate the global graph topology to locate non-contiguous passages. The RPE mechanism plays key role in enriching the retrieved context; its absence leads to fragmented evidence, which negatively impacts reasoning quality. The omission of fact provisioning primarily impacts the factual grounding of responses, as the LLM lacks the explicit logical constraints provided by the graph-based quadruples. Finally, the EEFs provide the necessary structure for eventcentric synthesis. The omission of EEFs requires the model to rely on unstructured text, which may lead to decrease in the coherence of the generated responses. Architectural Robustness. Experimental results indicate that SEEM maintains consistent performance threshold even under ablated configurations. Observationally, the core hierarchical architecture yields reasoning scores that exceed those of established baselines, even when specific modules are deactivated. This suggests that the fundamental separation of episodic and relational information provides structurally effective foundation for managing long-term context. These findings imply that the performance gains of SEEM are derived not only from auxiliary components but also from the underlying organization of its memory layers. The results demonstrate that while the hierarchical architecture ensures strong performance baseline, the integration of EEFs, RPE, fact provisioning, and relational propagation is essential to achieve optimal reasoning accuracy. 5.4 Case Study To qualitatively evaluate SEEM, we compare it against the gold standard and HippoRAG 2 on the LoCoMo (see Table 4). Our analysis focuses on three critical dimensions of agentic memory. Multi-attribute Grounding. Unlike raw text snippets, the EEF explicitly decomposes each interaction into granular roles such as Reason and Method. This structural decomposition allows the agent to distinguish between the intent and the action, which facilitates deeper social and causal reasoning across extended interaction histories. Narrative Synthesis. The framework achieves narrative synthesis through the Associative Fusion of conversational turns. By merging an inquiry and its corresponding response into single cohesive unit, the system effectively preserves the logical flow of the interaction. This consolidation approach also significantly reduces retrieval redundancy by avoiding the storage of fragmented conversational turns. Temporal Resolution. The frame exhibits sophisticated temporal grounding by processing reference dates alongside relative durations. For instance, by analyzing reference date of January 23, 2022 in conjunction with duration of three years, the system implicitly resolves the events origin to January 2019. Such precise resolution ensures chronological consistency and factual accuracy within the EML. In summary, SEEM ensures more grounded and logically consistent responses by transforming disparate interactions into structured, coherent agentic memory."
        },
        {
            "title": "6 Conclusion",
            "content": "We proposed SEEM, hierarchical framework addressing scattered retrieval in long-term interactions. By integrating episodic event frames with an associative fusion mechanism, the system synthesizes coherent narratives from fragmented observations, outperforming traditional RAG and graphbased baselines. Our method effectively maintains global context and provides scalable approach for enhancing the long-term reasoning capabilities of LLM-based agents in complex environments."
        },
        {
            "title": "Limitations",
            "content": "Despite its effectiveness, the framework faces limitations regarding computational efficiency, as the heavy reliance on LLMs for extracting frames and performing associative fusion increases latency and token costs compared to standard vector retrieval. Additionally, the system is susceptible to error propagation, where inaccuracies in the initial LLMbased extraction or fusion phases can permanently corrupt the structured memory store. Finally, the reliance on predefined semantic slots for event frames may limit the ability to capture abstract information that does not fit neatly into standard cognitive frame definitions."
        },
        {
            "title": "Ethical Considerations",
            "content": "The development of SEEM introduces considerations regarding the management and persistence of long-term interaction data. Unlike standard retrieval augmented generation which primarily accesses external corpora , SEEM transforms interaction streams into persistent episodic event frames and relational quadruples. While our experiments are conducted on publicly available benchmarks , real-world deployment of such memory framework involves the retention of user information over extended periods. It is essential that future applications implement data anonymization protocols and provide users with explicit control over their stored interaction histories, including the right to modify or delete specific memory frames. The framework is also subject to algorithmic bias and safety. Since SEEM relies on large language models for both episodic frame extraction and final response generation , it may inherit or amplify social biases present in these underlying models. The structured nature of event frames could potentially solidify these biases within the agents long-term memory, leading to biased reasoning in subsequent interactions. We recommend that developers implement content filtering and auditing mechanisms during the memory consolidation phase to mitigate these risks."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Sandhini Agarwal, Lama Ahmad, Jason Ai, Sam Altman, Andy Applebaum, Edwin Arbus, Rahul Arora, Yu Bai, Bowen Baker, Haiming Bao, and 1 others. 2025. gpt-oss-120b & gpt-oss-20b model card. arXiv preprint arXiv:2508.10925. Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. 2025. Mem0: Building production-ready ai agents with scalable long-term memory. arXiv preprint arXiv:2504.19413. Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri. 2024. The power of noise: Redefining retrieval for rag systems. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 719729. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, and Jonathan Larson. 2024. From local to global: graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130. Charles Fillmore. 1976. Frame semantics and the nature of language. Annals of the New York Academy of Sciences, 280(1):2032. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: survey. arXiv preprint arXiv:2312.10997, 2(1). Bernal Jiménez Gutiérrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, and Yu Su. 2025. From RAG to memory: Non-parametric continual learning for large language models. In Forty-second International Conference on Machine Learning. Taher Haveliwala. 2002. Topic-sensitive pagerank. In Proceedings of the 11th international conference on World Wide Web, pages 517526. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick SH Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In EMNLP (1), pages 67696781. Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. 2025. NV-embed: Improved techniques for training LLMs as generalist embedding models. In The Thirteenth International Conference on Learning Representations. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems, 33:9459 9474. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, and 1 others. 2025. The rise and potential of large language model based agents: survey. Science China Information Sciences, 68(2):121101. Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, and Yongfeng Zhang. 2025. A-mem: Agentic memory for llm agents. arXiv preprint arXiv:2502.12110. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41 others. 2025. Qwen3 technical report. Preprint, arXiv:2505.09388. Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Xin Zhang, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, and Min Zhang. 2025. Kalmembedding-v2: Superior training techniques and data inspire versatile embedding model. Preprint, arXiv:2506.20923. Aixin Liu, Aoxue Mei, Bangcai Lin, Bing Xue, Bingxuan Wang, Bingzheng Xu, Bochao Wu, Bowei Zhang, Chaofan Lin, Chen Dong, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenhao Xu, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, and 244 others. 2025. Deepseek-v3.2: Pushing the frontier of open large language models. Preprint, arXiv:2512.02556. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024. Evaluating very long-term conversational memory of llm agents. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13851 13870. Minsky. 1975. framework for representing knowledge. The psychology of computer vision. Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, and Joseph E. Gonzalez. 2023. Memgpt: Towards llms as operating systems. CoRR, abs/2310.08560. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL 02, page 311318, USA. Association for Computational Linguistics. Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, and Daniel Chalef. 2025. Zep: temporal knowledge graph architecture for agent memory. Preprint, arXiv:2501.13956. Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, and Christopher Manning. 2024. RAPTOR: Recursive abstractive processing for tree-organized retrieval. In The Twelfth International Conference on Learning Representations. Yixuan Tang and Yi Yang. 2024. Multihop-rag: Benchmarking retrieval-augmented generation for multihop queries. arXiv preprint arXiv:2401.15391. Endel Tulving and 1 others. 1972. Episodic and semantic memory. Organization of memory, 1(381-403):1. Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, KaiWei Chang, and Dong Yu. 2025a. Longmemeval: Benchmarking chat assistants on long-term interactive memory. In The Thirteenth International Conference on Learning Representations. Jinyang Wu, Shuai Zhang, Feihu Che, Mingkuan Feng, Pengpeng Shao, and Jianhua Tao. 2025b. Pandoras box or aladdins lamp: comprehensive analysis revealing the role of rag noise in large language models. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 50195039."
        },
        {
            "title": "A Supplemental Experimental Results",
            "content": "A.1 Cross-Model Generalization and Architectural Robustness To evaluate whether the performance gains of SEEM are model-dependent or derive from its underlying architecture, we conduct supplemental experiments on the LoCoMo benchmark by replacing the primary Qwen3-Next-80B-A3B-Instruct backbone with GPT-OSS-120B. This cross-model validation serves as controlled comparison, ensuring that the observed improvements are attributable to our hierarchical memory mechanisms rather than the inherent capabilities of specific LLM. Analysis of Results. As demonstrated in Table 5, SEEM maintains its performance leadership when integrated with the GPT-OSS-120B backbone, mirroring the trends observed with the Qwen3-Next80B-A3B-Instruct model. The consistent performance gains across these distinct large language models reinforce the conclusion that the advantages of our hierarchical episodic architecture are model-agnostic. By decoupling the memory organization mechanism from the specific underlying LLM, SEEM demonstrates robust generalization capabilities in narrative consistency and retrieval precision. These results confirm that the framework serves as versatile enhancement for various long-context reasoning agents regardless of their specific architectural implementations. A.2 Granular Category-wise Evaluation To further investigate the performance characteristics of SEEM across diverse reasoning challenges, we present granular analysis of the results on the LoCoMo and LongMemEval benchmarks, categorized by specific task dimensions. Analysis of LoCoMo Categories. As illustrated in Table 6, SEEM achieves superior performance across four out of five reasoning categories. The framework demonstrates significant advantages in Temporal and Multi-hop reasoning, outperforming competitive baselines by notable margin. These results suggest that the structured EEFs effectively capture chronological dependencies that are often overlooked by dense retrieval or static graph-based approaches. While HippoRAG 2 maintains competitive performance in Open-domain queries due to its focus on static entity indexing, SEEM prioritizes the reconstruction of complex narrative chains. This architectural focus is further evidenced by SEEMs higher resilience to adversarial distractors, indicating lower vulnerability to hallucinations compared to traditional retrieval-based systems. Analysis of LongMemEval Categories. The evaluation encompasses six distinct reasoning categories: Speaker-Specific (S-S) tasks focused on the user, assistant, or preferences; Multi-Session (Multi-S) interaction; Temporal reasoning; and Knowledge Update (K-Update). This comprehensive assessment further reinforces the efficacy of the SEEM architecture. As shown in Table 7, SEEM achieves the highest average accuracy, driven primarily by its strong performance in the Knowledge Update and Temporal reasoning categories. The frameworks capacity to resolve user-specific information highlights its effectiveness in grounding queries to the appropriate episodic context. While certain baselines demonstrate specialized strengths in preference-based retrieval, SEEM provides more balanced performance profile. This equilibrium is achieved by bridging high-level semantic abstractions with the granular requirements of long-term interaction history, ensuring consistent reasoning across diverse and evolving query types. A.3 Evaluation of Incremental Memory Construction To assess the practical applicability of SEEM in streaming interaction scenarios, we conduct an evaluation under an incremental construction setting. In this configuration, the complete sequence of interaction passages is partitioned into four chronological segments, which are processed by the memory system sequentially rather than in single batch. The results, summarized in Table 8, demonstrate that SEEM maintains highly stable performance across all evaluation metrics. The marginal discrepancy between the batch and incremental modes suggests that the associative fusion mechanism effectively preserves narrative coherence and structural integrity, even when information is presented in fragments. This minimal performance trade-off confirms the frameworks robustness for real-world deployment, where memory must evolve continuously in response to sequential updates without significant loss in reasoning integrity. Query Gold Answer HippoRAG 2 SEEM (Ours) Q1: What book did Melanie read from Carolines suggestion? (Multi-hop) Q2: How did John describe his kids reaction at the military memorial? (Single-hop) Q3: What day did Tim get into his study abroad program? (Temporal) \"Becoming Nicole\" The books title is not specified. \"Becoming Nicole\" by Amy Ellis Nutt Awestruck and humbled. John said the experience made an impact on his kids, but did not describe their specific reaction. They were awestruck and humbled. January 5, 2024 January 7, 2024 January 5, 2024 Table 4: Case study comparison between the gold answer and different memory frameworks. Method Dense Retrieval KaLM-Embedding-V2.5 (Zhao et al., 2025) NV-Embed-v2 (Lee et al., 2025) Memory-based Frameworks A-MEM (Xu et al., 2025) HippoRAG 2 (Gutiérrez et al., 2025) SEEM (Ours) Backbone LLM: GPT-OSS-120B LoCoMo BLEU-1 J 38.7 44.1 42.4 44.6 50.7 42.8 49.2 47.3 50.2 55.7 63.2 75. 63.0 73.6 77.1 Table 5: Performance comparison on LoCoMo based on GPT-OSS-120B. The best results are highlighted in bold."
        },
        {
            "title": "B Analysis",
            "content": "B.1 Structural Analysis of the Graph Memory Layer The GML provides the static factual foundation of the SEEM framework, complementing the dynamic nature of the EML. As summarized in Table 9, the structural statistics across various narrative partitions reflect high density of relational knowledge and entity connectivity. The internal composition of the graph highlights two critical capabilities of the system. The prevalence of temporal anchors indicates that vast majority of the extracted facts are grounded in specific temporal contexts, which is essential for resolving chronological dependencies in long-term reasoning. This structural density ensures that the GML can serve as reliable foundation for relational propagation, providing the necessary factual context for hybrid retrieval. B.2 Qualitative Analysis of Episodic Event Frames Figure 4 provides representative instance of consolidated EEF, illustrating the frameworks capacity for high-fidelity narrative synthesis. Several key advantages of the SEEM architecture are evident in this structured representation: Multi-attribute Grounding. Unlike raw text snippets, the EEF explicitly decomposes the interaction into fine-grained roles such as Reason and Method. This decomposition allows the agent to distinguish between intent and action, which facilitates deeper social and causal reasoning across extended interaction histories. Narrative Synthesis. The SEEM framework achieves narrative synthesis through the associative fusion of interaction pairs. By merging conversational inquiry and its corresponding response into single, cohesive episodic unit, the system preserves the logical continuity of the dialogue. This consolidation mechanism effectively captures the functional relationship between speaker turns while significantly reducing retrieval redundancy in the memory store. Temporal Resolution. The EEF exhibits sophisticated temporal grounding by processing the reference date alongside the relative duration. For instance, the system implicitly resolves an events origin to January 2019 by analyzing the reference date in conjunction with three-year duration. Method Multi-hop (Count: 282) Temporal (Count: 321) Open-domain (Count: 96) Single-hop (Count: 841) Adversarial (Count: 446) Correct Acc. Correct Acc. Correct Acc. Correct Acc. Correct Acc. A-MEM HippoRAG 2 NV-Embed-v2 SEEM (Ours) 154 173 148 177 54.61% 61.35% 52.48% 62.77% 90 203 205 219 28.04% 63.24% 63.86% 68.22% 45 59 56 52 46.88% 61.46% 58.33% 54.17% 496 659 647 668 58.98% 78.36% 76.93% 79.43% 430 416 417 432 96.41% 93.27% 93.50% 96.86% Table 6: Category-specific performance on the LoCoMo dataset. Sample counts for each reasoning category are provided in parentheses. The best results are highlighted in bold. Method S-S (User) (Count: 70) S-S (Asst.) (Count: 56) S-S (Pref.) (Count: 30) Multi-S (Count: 133) Temporal (Count: 133) K-Update (Count: 78) HippoRAG 2 NV-Embed-v2 SEEM (Ours) 82.86 80.00 91. 94.64 94.64 94.64 20.00 33.33 30.00 58.65 48.12 54.89 48.12 43.61 53.38 56.41 65.38 70.51 Mean 60.11 60.85 65.81 Table 7: Detailed performance comparison on the LongMemEval benchmark. Accuracy (%) is reported across six reasoning categories, with sample counts for each category provided in parentheses. The best results are highlighted in bold. Method BLEU-1 F1 SEEM (Batch) SEEM (Incremental) 56.1 55.6 61.1 60.6 78.0 77.6 tural efficiency ensures logically continuous memory state, which is essential for maintaining context during long-horizon agentic reasoning. Table 8: Comparison between Batch and Incremental Memory Construction in SEEM. Passages per Memory Number of Memory Frames This precise resolution ensures chronological consistency and factual integrity within the EML. By transforming ambiguous pronouns into structured attributes while maintaining strict textual grounding via provenance pointers, the EEF provides high-density semantic anchor. This structured representation ensures that retrieved context is not only chronologically accurate but also logically complete for downstream reasoning. 1 2 3 4 5 8 Total Memory Frames Total Passages Consolidation Ratio 371 79 20 3 4 1 478 629 1.32:1 Table 10: Distribution of consolidated episodic memory frames across constituent interaction passages in LoCoMo narrative partition. B.3 Analysis of Associative Fusion B.4 Redundancy Analysis of Dual-Layer We evaluate the structural impact of the associative fusion mechanism by analyzing the distribution of consolidated frames relative to the original interaction turns. As demonstrated in Table 10, SEEM reduces the total number of memory units by synthesizing fragmented turns into unified episodic frames. This consolidation mitigates semantic redundancy and improves retrieval density by grouping chronologically and logically linked interactions. The presence of multi-turn fusions indicates that the framework can bridge narrative sequences, transforming discrete conversational segments into more compact semantic representations. This strucRetrieval To verify the necessity of the dual-layer architecture, we analyze the global distribution of semantic redundancy between the GML and the EML. For each query in the LoCoMo dataset, we retrieve the corresponding structural quadruples from the GML and EEFs from the EML. We apply an LLM-based filter to the GML outputs to ensure precision, resulting in 1,282 valid retrieval pairs from the original 1,986 queries. The aggregate semantic overlap is quantified by computing the cosine similarity between their respective embeddings, with the overall distribution detailed in Table 11. Metric h1 h2 h4 h5 h6 h7 h8 h10 Average Entities Facts Temporal Anchors Synonymy Edges 1,242 1,749 1,557 11,732 902 1,320 1,213 5,439 1,845 2,534 2,294 19, 1,486 2,194 1,948 14,178 1,820 2,673 2,363 16,433 1,692 2,699 2,385 14,344 1,745 2,557 2,258 15,904 1,665 2,395 2,070 15,402 1,286 1,868 1,694 10, 1,575 2,348 2,056 12,459 1,525.8 2,233.7 1,983.8 13,652.4 Table 9: Structural statistics of the GML across 10 Narrative Partitions (h1h10) in the LoCoMo dataset. The metrics quantify the internal density of the GML, representing the static knowledge foundation of the SEEM framework. Example: Consolidated Episodic Memory Frame Summary: On January 23, 2022, at 2:01 pm, Joanna asked Nate how long he had had them, prompting Nate to respond that he had owned them for three yearssince approximately January 2019and that they brought him significant joy. Events (Structured EEF): Event 1: Participants Action Time Reason Method Joanna Joanna asked how long Nate had had them 2:01 pm on 23 January, 2022 Expressing affectionate curiosity about an object Nate possesses Through verbal inquiry Event 2: Participants Nate Action Time Reason Method Nate stated he had owned them for three years, and that they brought him tons of joy From approx. January 2019 to January 23, 2022 Responding to Joannas question about the duration of ownership Through verbal response Figure 4: An illustrative example of consolidated Episodic Event Frame (EEF) in the SEEM framework. This structured representation demonstrates how the associative fusion mechanism synthesizes multi-turn interactions into coherent, attribute-rich episodic units. Similarity Range Count Prop. (%)"
        },
        {
            "title": "C Prompt Templates and Agent",
            "content": "[0.25, 0.30) [0.30, 0.35) [0.35, 0.40) [0.40, 0.45) [0.45, 0.50) [0.50, 0.55) [0.55, 0.60) [0.60, 0.65) 1 12 106 398 497 224 40 4 Total Valid Pairs Mean Similarity 0.08 0.94 8.27 31.05 38.77 17.47 3.12 0.31 1282 0."
        },
        {
            "title": "Instructions",
            "content": "In this section, we provide the detailed prompt templates used in the SEEM framework. These prompts are designed to implement the formal functions defined in Section 3, specifically the extraction function Fext, the consolidation function Ff use, and the final generation function G. Table 11: Distribution of cosine similarity between retrieved quadruples (GML) and EEFs (EML) on the LoCoMo dataset. The mean similarity of 0.46 suggests that the GML and EML capture complementary semantic dimensions. This divergence confirms that the structural extraction and narrative synthesis capture distinct information even when grounded in the same interaction context, justifying the use of dual-layer architecture. Prompt 1: Episodic Event Frame Extraction (Fext) You are an expert at extracting episodic memories from conversation turns. Your task is to analyze single conversation turn (which may contain time information, speaker information, and text content), identify distinct events mentioned in the turn, and extract structured event details for each event. The input format is single conversation turn that may include: Time information Image descriptions in the format: [Image: <description>] The actual text content of the turn For each event, extract the following Structured Event Attributes (use null if not reliably determined): Participants: List of actors. Replace pronouns with specific names; include full names/roles. Action: List of substantive actions. CRITICAL: Each action MUST include the subject/actor. Format: Subject verb object. Time: Time, date, or duration. For continuous events, explicitly specify the range. Specify the events actual time, not just the conversation time. Location/Reason/Method: The venue, purpose, or means if explicitly stated. Guidelines: 1) Event Definition: Define an event as an occurrence with clear subject, action, and temporal context. 2) Coreference Resolution: Resolve pronouns to specific entities. 3) No Redundancy: Do not extract the act of speaking as separate event. 4) Output strict JSON. No markdown formatting. Output format (strict JSON): { } \"summary\": \"1-3 concise sentences...\", \"events\": [{ \"participants\": [], \"action\": [], \"time\": \"\", ... }] Figure 5: The structured prompt for Episodic Event Frame Extraction (Fext). This initial stage of the SEEM pipeline converts unstructured interaction logs into discrete, attribute-rich event units, providing the grounded anchors necessary for long-term temporal and multi-hop reasoning. Prompt 2: Associative Consolidation and Fusion (Ffuse) You are an expert at integrating episodic memories. Your task is to combine two episodic memories into single, comprehensive memory that preserves all important information from both memories. IMPORTANT: Event Integration Strategy LESS: When events from both memories describe the same occurrence (merge). EQUAL: When all events are distinct and unrelated. GREATER: When integration reveals new event relationships. Guidelines: 1. Conservative Merge: Only merge events that clearly describe the EXACT SAME occurrence. If events are part of sequence (Plan Execute), DO NOT merge them. 2. Entity Alignment: Unify participant names. 3. Conflict Resolution: Highest Priority: Evidence found in Original Passages. Use these original sources as the primary reference to cross-verify all episodic attributes and mitigate error propagation. 4. Summary Synthesis: Do NOT simply concatenate. Rewrite single, cohesive narrative describing progression or causal relationships. CRITICAL: Time Information Handling Rules 1. Same Event, Different Time: If one is more specific, prefer it; if complementary, combine into range. 2. Sequential Events: Events at different times MUST be kept separate. 3. Temporal Ordering: Arrange events in chronological order. Output Format: Strict JSON ONLY. Figure 6: The structured prompt for associative consolidation and fusion, designed to synthesize fragmented interaction logs into coherent Episodic Event Frames (EEFs). Prompt 3: Memory-Augmented Question Answering (G) You are reading-comprehension QA assistant operating in episodic-memory mode. Each query provides: (A) an Original Passages (Grounded Evidence) section (most trusted evidence); (B) an Episodic Memory Summary section (high-signal reference distilled from retrieved passages; use as guide and as supplemental evidence when not contradicted); (C) optionally, Relevant Facts section (high-signal reference quadruples; use to locate/verify key entities/relations and as supplemental evidence when not contradicted). Evidence Policy: 1. You MUST read (B) and (C) (if present). Treat them as high-signal hints to guide what to look for in (A). 2. If (A) is incomplete, you MAY answer using explicit (B)/(C) as supplemental references ONLY if they do not contradict (A). 3. If (B)/(C) conflicts with (A), trust (A) and ignore the conflicting parts of (B)/(C). Output Format: Thought: <reasoning> Answer: <answer only> (Constraint: The answer must be concise, definitive, and devoid of additional elaborations) Figure 7: The Inference Prompt for SEEMs Memory-Augmented Question Answering. By providing the model with distilled episodic summaries and graph-based facts alongside raw evidence, the system effectively mitigates the scattered retrieval problem in long-context interactions."
        }
    ],
    "affiliations": [
        "Alibaba Group, Hangzhou, China",
        "Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "Shenzhen Loop Area Institute, Shenzhen, China",
        "Southeast University, Nanjing, China"
    ]
}