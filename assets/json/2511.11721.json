{
    "paper_title": "A Meta-Heuristic Load Balancer for Cloud Computing Systems",
    "authors": [
        "Leszek Sliwko",
        "Vladimir Getov"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This paper presents a strategy to allocate services on a Cloud system without overloading nodes and maintaining the system stability with minimum cost. We specify an abstract model of cloud resources utilization, including multiple types of resources as well as considerations for the service migration costs. A prototype meta-heuristic load balancer is demonstrated and experimental results are presented and discussed. We also propose a novel genetic algorithm, where population is seeded with the outputs of other meta-heuristic algorithms."
        },
        {
            "title": "Start",
            "content": "This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 Meta-Heuristic Load Balancer for Cloud Computing Systems Leszek Sliwko University of Westminster, London, London, GB Vladimir Getov Faculty of Science and Technology, University of Westminster, London, United Kingdom AbstractThis paper presents strategy to allocate services on Cloud system without overloading nodes and maintaining the system stability with minimum cost. We specify an abstract model of cloud resources utilization, including multiple types of resources as well as considerations for the service migration costs. prototype meta-heuristic load balancer is demonstrated and experimental results are presented and discussed. We also propose novel genetic algorithm, where population is seeded with the outputs of other meta-heuristic algorithms. Keywords-cloud computing, load balancing, meta-heuristic I. INTRODUCTION Modern day applications are often designed in such way that they can simultaneously use resources from different computer environments. System components are not just properties of individual machines and in many respects they can be viewed as though they are deployed in single application environment. Distributed computing differs from traditional computing in many ways. The sheer physical size of the system itself means that thousands of machines may be involved, millions of users may be served and billions of API calls or other requests may need to be processed [24][29]. In recent years the most advanced technologies offer cloud solutions [11]. cloud system connects multiple individual servers and maintains the communication between them in order to process related tasks in several environments at the same time. Clouds are typically more cost-effective than single computers of comparable speed and usually enable applications to have higher availability than single machine. This makes the software even more attractive as service and is shaping the way software is built today [26]. Moreover, companies no longer need to be concerned about maintaining huge infrastructure of thousands of servers just so they have enough computing power for those critical hours when their service is in highest demand. Instead companies can simply rent thousands of servers for few hours [11]. Software as service, where functionality is delivered to end users directly from distributed data centers, is typical paradigm of the use of Cloud systems [26]. As of today, the biggest cloud systems offering elastic resource allocation are Amazon Web Services [22], Google App Engine [1], Microsoft Azure [27] Rackspace [27], Digital Ocean [24] and GoGrid [27]. few well-known examples of services backed up by cloud computing are Dropbox, Gmail, Facebook, Youtube and Rapidshare. This elasticity of resources, without paying premium for large-scale usage, is unprecedented in the history of IT [11]. However, it introduces new set of challenges and problems, which need to be solved. The cloud systems are usually made up of machines with very different hardware configurations and rapidly different capabilities. These systems can be provisioned as per the user's requirements [6] thus resource sharing is necessity. Resource management has been an active research area for considerable period of time and those systems usually feature specialized load balancing strategies. This research outlines the significance of resource management strategies in cloud systems. This class of system is characterized by dynamic changes in their environments. The conventional container for applications in cloud are virtual machines, which can be quickly booted up or shut down on demand [10] and therefore the strategy needs to be robust enough to accommodate rapid changes in available resource configurations. To solve this problem, number of strategies have been proposed and developed, with the majority focusing on achieving an optimal utilization of one resource exclusively [15][16][35]. In this paper, we specify an abstract model of cloud resources utilization (Section II), including multiple types of resources and consideration of service migration costs. Section III describes the research problem formulation. We then present the design of prototype meta-heuristic load balancer (Section IV), which can be used to manage mediumsize cloud systems. Sections and VI provide the details of the experiments setup and results. In Section VII we conclude This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 by discussing various employed strategies and highlight their advantages and weaknesses. II. MODEL OF CLOUD RESOURCES UTILIZATION Our model consists of nodes and services where the load balancer task is to keep good load balance through resource vector comparisons. In considering what is actually constituted as service in Cloud environment an example may be seen in popular Cloud environment such as Amazons EC2, where applications are deployed within the full Operating System Virtual Machine (VM). Depending on design, service might come also with preinstalled local database such as MySQL. One might argue the effectiveness of this approach, however this schema has many benefits such as the almost complete separation of execution contexts (although services might still share the same hardware if they are deployed on the same node) and complete control over local system environment parameters. Amazon EC2 uses the templates in Amazon Virtual Image format [2]. Currently there are more than 20000 images to select from. Services run constantly, which means they are not tasks which can be defined as finite piece of work to be done [15] and do require resources, which are provided by the nodes. Every node has certain amount of variable resource available, referred to in this paper as the available resources set. All resources on nodes are considered renewable and continuous, which means resources do not expire and cannot be depleted, assigning service to node only temporarily lowers available resource levels. To simplify the definition, both the resources needed by the service and the resources available on the node are described by the vector of integer values. There exist several types of resources, which can be utilized by the service, such as memory, CPU cycles, and disk I/O operations. The number of defined resources is potentially unlimited, but in this experiment we use four types: CPU, memory, maximum network bandwidth and I/O operations speed. Services might have their resource needs shaped differently. There will be services experiencing hourly, daily or weekly variability in usage [30]. in resource availability. During Cloud system environment is characterized by very dynamic changes its operations, some nodes might become idle or overloaded, additional resources might become available (new nodes might be added to network or demand for particular service decreases) or part of cloud network could go offline. Therefore to automatically migrate services to alternative nodes. to provide mechanism is critical it Distributed systems often store or process large amounts of state - state consists of data such as database, files, relations, session data and identifiers, which are frequently updated [29]. Service migration is similar to jobs checkpointing [7]. During service migration the service Virtual Machine is stopped and its state saved to state snapshot file. This file then gets copied over the network to an alternative node, where virtual machine is then restored. Therefore, service will always carry some of the system state within itself. Saved state size depends upon how much data application has in memory and persistent storage. When we move service to an alternative node, the state also has to be transferred. In this model, every service has its integer cost value assigned which is an abstract representation of the impact the service migration will have. Figure 1. System transformation and migration cost We consider the service migration cost value to be constant, as migration of certain service to any node will cause the same impact throughout the whole system. III. PROBLEM FORMULATION Let us define ( system as twice Λ = τ,η,ψ, a, r, as problem space and ) ) Λ,µ( . In the d-resource system ! optimization problem, we receive set ! ! of services as service assignment of mobile fixed nodes } . We call τ = t1, t2,..., tl and set η= n1, n2,..., nm µ:τ η { } { ! function, where each service has to be assigned to the node. We also consider: } { ψ= i1, i2,..., id resources. To illustrate, for } ψ= CPU, memory, network { as set of all different kinds of we could define !=! . as fixed available resources on is the available level (integer value) of ( )!\"# ! on the node ! . :ψη Ν 0{ } the nodes. resource :ψτ Ν 0{ } services. ri t( ) ! of service ! as fixed required resources for is the required level (integer value) of . as service migration cost function. resource :τ Ν 0{ } t( ) and its state and preparing service environment. means cost incurred migrating service executables This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015."
        },
        {
            "title": "For  every  node",
            "content": "!\"! we define set #! ! ( ) \" µ\"! { \" != }! . We also define = of all services assigned to the node :ψη Ν 0{ } as remaining resources on the nodes: fi n( ) = n( ) t( ) ri tAn (1)"
        },
        {
            "title": "We consider system",
            "content": ")µ!! ( as stable, if: , i.e.: fi n( ) 0 t( ) ri tAn n( ) , for every , !\"! !\"! (2)"
        },
        {
            "title": "Otherwise the system",
            "content": ")µ!! ( is overloaded. Each service function !µ transformation is initially assigned by service assignment the system . During !\"! can be reassigned ! to some node ( )! \" µµ ! !\"! ! service to any different node . The process of moving the service to different node is referred to as service migration and this feature generates service reassigning cost: µ0µ1 ( ) t( ) = \" $ # %$ 0, t( ), µ0 t( ) = µ1 t( ) µ0 t( ) µ1 t( ) ( )! \" µµ ! Every system transformation process transformation cost: µ0µ1 ( ) = µ0µ1 ( ) t( ) tτ (heuristic procedure where each job is assigned fixed continuous resource amount equal to 1/m) and HCRA (heuristic procedure for continuous resource allocation) algorithms [21], however the result quality is low. Exact methods have been explored, but either they have limitation of problem size or focus only on deriving new lower bounds as optimal solution can be found and verified only in small problem instances [19][28]. IV. LOAD BALANCER DESIGN The general approach to solve job scheduling problems is to employ meta-heuristic strategies [19]. One can argue that meta-heuristics might be non-acceptable as solving load balancing problem in that each scheduling event can be very time consuming and have high overheads [25]. However, the resource management in distributed system is nowhere near the dynamic and robustness level required on scheduling processes on CPU cores. Load balancer prototype was implemented in functional programming language Scala (version: 2.11.2). The source code of this load balancer is available at: (reference removed for review purposes). All computations were performed on MacBook Pro with the following specifications: Model MacBook Pro11,1 Operating System OS 10.9.4 has its system CPU Memory Storage 2.4GHz dual-core Intel Core i5 8GB 1600MHz memory 256GB PCIe-based flash storage (3) Java Virtual Machine 1.6.0_65-b14 Oracle Table 1. Experiment data System configuration The load balancer sequence was designed as follow: Consider initial service assignment !µ is optimal for !µ renders system , if !µ !µ ; service assignment )! ( \"µ! stable )µ!! ( . is stable for initial service assignment , for every stable system and: µ0µ ) ( ) ( µ0µ* ( )! N.b.: when \"µ! !µ considered optimal. We also consider two service assignment functions µ1 , the system transformation cost equals ! to be neighbors if: { τ :µ0 t( ) µ1 t( ) } = 1 as it is µ0 and (4) The d-resource system optimization problem (D-RSOP) is variant of classical Resource-Constrained Project Scheduling Problem (RCPSP), thus D-RSOP also belongs to the NP-hard (Nondeterministic Polynomial-time hard) problems class. Since its advent, RCPSP has been examined numerous times by researchers and numerous solutions have been proposed, implemented and tested [3][4][5][8][19][23]. RCPSP is solvable by simple heuristics such as the H1m This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 C. Simulated Annealing is general method for finding the global optimum by process inspired from annealing in metallurgy (heating and controlled cooling of material to increase the size of its crystals and reduce their defects [37]. This effect is implemented in the SA algorithm as slow decrease in the probability of accepting worse solutions as it explores the solution space. Previous research over use of this strategy in load balancing can be found [20]. D. Genetic Algorithm (GA) is search heuristic that mimics the process of natural selection. GA belong to the larger class of evolutionary algorithms, which generate solutions to optimization problems using techniques inspired by natural evolution, such as inheritance, mutation, selection, and crossover. Unmodified GA has been previously examined with good results [19]. In this research we have deployed variant with Genetic Drift step detailed in [33]. E. Seeded Genetic Algorithm (SDA) the generation of random solutions is the most costly step in GA strategy, sometimes taking up to 60-70% of total computation time. Therefore, we have implemented novel approach, where Genetic Drift step has been replaced with locally optimal solutions (i.e.: solutions seeding) found by Greedy, Tabu Search (TS) and Simulated Annealing (SA) algorithms. This approach should allow us to dramatically lower the total size of population (as individual genotypes are of better quality). Therefore, to test this approach, three respective strategy variations were created (SGA-Greedy, SGA-TS and SGASA). F. Full Scan (FS) this strategy performs full search over all available configurations. FS strategy is convergent meaning it is able to find the globally optimal solution in finite time, under appropriate modeling assumptions. Multiple optimization techniques have been implemented in this algorithm, including shaving and path cut [9] and largestmigration-cost-first. V. EXPERIMENTS SETUP The characteristics of Cloud workload in data center are not perfectly clear yet and as research shows these will significantly differ from traditional grid computing [10]. There exists only limited number of publicly available cloud system workload traces and those are generally anonymous and stripped of useful details [31]. The research community is mostly relying on simulations and models to conduct their experiments. The quality of input data and its realistic nature is very important factor as it has direct impact on the accuracy of results. There are number of papers examining and providing statistical analysis [10][17][31][32] of available workload traces and number of studies focus on creating reliable workload traces generator [12][36]. In this experiment we have generated system configuration based on the above research and also on our professional experience with working with Amazon EC2 cloud instances. We have selected set of services and nodes and proposed configuration shall be valid for the purpose of this experiment (table 2 and 3). Figure 2. Load balancer sequence The core of load balancer is decision-making module, which assigns services to nodes. Every decision has computation overhead, yet badly assigned services can cause global system instability. Therefore, load balancer has to maintain difficult balance between the speed and quality of its decisions. Selection of the most efficient algorithm is critical. Based on previous research [20], as well as our existing work not every algorithm will perform well with this problem. For the purpose of the experiment, we have selected several of the most promising strategies: A. Greedy is an algorithm that follows the problem solving heuristic of making the locally optimal choice at each stage with the hope of finding global optimum. In many problems, greedy strategy is effective; however, it usually does not produce an optimal solution in this research. Nevertheless, greedy heuristic will yield locally optimal solutions in very quick time. B. Tabu Search (TS) was introduced by Fred W. Glover in 1986 [13] and further formalized in 1989 [14]. This algorithm has been suggested by previous research on similar problem [18]. TS searches for an improved solution in immediate neighbors (solutions that are similar except for one or two minor details). TS enhances its performance by maintaining list of visited solutions so that the algorithm does not consider that possibility repeatedly. This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 Table 2. Experiment data nodes configuration Table 3. Experiment data services configuration VI. EXPERIMENTAL RESULTS Three of strategies (Greedy, Tabu Search and Simulated Annealing) were designed with the end state (i.e. no more steps were possible). If strategy finished before given time it was continuously re-run and the best result selected. Number of runs significantly varied per strategy, especially in the lower sizes of solution space (figure 3). Each algorithm creates number of candidate solutions during their run. Deciding if candidate solution is stable This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 (i.e.: no nodes are overloaded) tends to be the most expensive step in computations, with around 50-70% of CPU time (depending on tested strategy) spent on validation of solution feasibility routines. As an optimization, implementations were caching newly created solutions, meaning the same tasks assignment setup is never tested twice for being stable as the result is retrieved from memory. In the chart below (figure 4) we have plotted the average number of unique candidate solutions created in each test scenario. Figure 3. Runs count (per minute) Figure 4. Unique candidate solutions created (per minute) We designed five testing scenarios to see how each strategy copes with the increasing complexity of the problem. We have assumed new nodes are added only when new services are deployed [31] and demand for computing resources increases. We are simulating this scenario with enabling additional nodes (in each test two additional nodes This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 and ten more services are added). We have assumed that the load balancer will be run periodically, thus we have selected an arbitrary computation time, after which the best-found solution was selected as output result  (table 4)  . Computati on time Deployed services Enabled nodes Scenario Test Test II Test III Test IV Test 1-20 1-30 1-40 11-60 A-D A-F A-H A-J A-L 30 seconds 1 minute 2 minutes 4 minutes 8 minutes Search space size 306 408 5010 6012 Table 4. Experiment data tests I, II, III, IV and The Full Scan strategy was used only as benchmark if global optimal solution was found and such limit was not imposed. The Full Scan strategy was not able to finish scenarios Test IV and Test in reasonable time (24 hours and 5 days respectively). All other strategies results were plotted on the chart above (the lower system transformation costs are better). VII. RESULTS As it was demonstrated in previous research 17][25][33], when solving classical Resource-Constrained Project Scheduling Problem and its variants, more complex metaheuristics (e.g.: TS, SA, GA) perform significantly better than simple algorithms (e.g.: Greedy) Figure 5. Results A. Greedy very short execution time allowed strategy to be repeatedly run and therefore few stable solutions were found in each test. Result solutions were of average quality; the most time consuming step was the generation of solutions neighbors (e.g.: during the Test scenario, each step required 60 12 = 720 configurations to be examined). B. Tabu Search (TS) the main bottleneck in this approach was the last step where all of all same-value solutions had to be visited and marked as Tabu. Therefore, we have introduced maximum limit of dull (without bettering solution) moves the strategy will perform, before the strategy gives up and returns the actual solution. Overall, the TS algorithm was working very well in small instances of problem, which confirms results documented in [18]. C. Simulated Annealing (SA) strategy did require much larger number of computations, often reaching only fraction of runs in the same time as Greedy or TS. However, it did not require costly generation of all the solution neighbors, therefore re-runs count decreased at much slower pace than above strategies. This strategy benefited the most from introducing the solution cache. D. Genetic Algorithm (GA) variant was previously examined [33] and its main drawback is costly generation of random solutions in the Genetic Drift step, especially when more types of resources are considered and solution space grows in size. Performance was shown to be sufficient when examining two kinds of resources. However, due to the number of random generations required in order to create initial population the strategy performed quite poorly when This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 four resources were introduced. As in [19], the larger problem size, the lower quality found solution was. This becomes noticeably apparent in instances of larger problem, where ten or more nodes are involved. E. Seeded Genetic Algorithm (SGA) was the most interesting strategy in our experiment. The introduction of solutions seeding to replace the previously designed Genetic Drift step [33] in the Genetic Algorithm allowed us to downsize the available genetic pool to 25% of its original size, which greatly reduced the computation time (around 50-70%) required to find good solutions without reduction in quality. SGA returned the best results within the set time frame. In each case (Greedy vs. SGA-Greedy, TS vs. SGA-TS, SA vs. SGA-SA), the found solution was improved and generally less candidate solutions were examined (in Test ca.14% less candidates were visited). In this experiment the variant with TS strategy returned the best results. F. Full Scan strategy guarantees globally optimum solution is found. Over the course of research, this strategy has been heavily optimized: currently only about 9% of solutions tree is traversed, the strategy starts moving services with the highest migration costs first, algorithm cuts leaves as soon as partial solution is deemed unstable. However, this still cannot be considered an efficient strategy due to large number of computations required. In this experiment, Full Scan strategy was used to produce global optima solution only in minor instances of problem. VIII. CONCLUSIONS In this paper after analyzing the algorithms performance, we came to the following conclusions, which might help us design new and/or enhance already existing algorithms: 1. The meta-heuristic algorithms rely on traversing search space in small steps, meaning the next selected solution is usually similar to current one, but usually better. It might be beneficial to give higher priority to moving already-migrated services (as they already increased migration cost) and also prioritize moving services with smaller migration cost (due to reduced impact upon total migration cost). However, this step requires into problem-specific algorithms. knowledge building 2. The initial random generation of candidate solutions is expensive. This behavior is well visible in the upward trend in the number of candidate solutions created and tested (Figure 3) in Genetic Algorithms strategy. The number of tested solutions does not correlate with the quality of solutions and better results can be achieved if the solutions pool is initially created from already pre-computed set. 3. few strategies succeed in reaching certain solution level and they have difficulty to move out from this or recognize last state (e.g.: only one neighbor solution is better). Especially the Tabu Search is prone to this issue. In this implementation we encountered counter of steps without increasing quality of solution. When an arbitrary limit of steps is reached, strategy returns the current solution. However, we believe this can be handled in more intelligent way. In our experiments, we tested the load balancer on medium-sized networked system and found it capable of generating huge (6012 possible combinations) solution search space. We have also shown that increasing the number of tested resources did not hinder the performance of examined meta-heuristic strategies. In [33] we tested two resources, and in [34] we tested three resources. Finally in the current experiments four-resource metric was used. Without doubt there is an opportunity to develop this area of research to focus on even more complex configurations."
        },
        {
            "title": "REFERENCES",
            "content": "[1] Bedra, A. (2010) Getting started with Google app engine and Clojure. Internet Computing, IEEE 14, no. 4 85-88. [2] Beach, B. (2014) Amazon Machine Images In Pro Powershell for Amazon Web Services, pp. 115-134. Apress [3] Boctor, F. (1990) Some efficient multi-heuristic procedures resource-constrained project scheduling. European for Journal of Operational Research 49, no. 1 : 3-13. [4] Bouleimen, K. and Lecocq, H. (2003) new efficient simulated annealing algorithm for the resource-constrained project scheduling problem and its multiple mode version. European Journal of Operational Research 149, no. 2 : 268281. [5] Brucker, P. Andreas Drexl, Rolf Möhring, Klaus Neumann, and Erwin Pesch. (1999) Resource-constrained project scheduling: Notation, classification, models, and methods. European journal of operational research 112, no. 1 : 3-41. [6] Buyya, R. Chee Shin Yeo, Srikumar Venugopal, James Broberg, and Ivona Brandic. (2009) Cloud computing and emerging IT platforms: Vision, hype, and reality for delivering computing as the 5th utility. Future Generation computer systems 25, no. 6 : 599-616. [7] Chtepen, M., Filip HA Claeys, Bart Dhoedt, Filip De Turck, Piet Demeester, and Peter A. Vanrolleghem. (2009) Adaptive task checkpointing and replication: Toward efficient faulttolerant grids. Parallel and Distributed Systems, IEEE Transactions on 20, no. 2 : 180-190. [8] Demeulemeester, E. and Willy Herroelen. (1992) branchand-bound procedure for the multiple resource-constrained project scheduling problem. Management science 38, no. 12 : 1803-1818. [9] Demassey, S., Christian Artigues, and Philippe Michelon. (2005) Constraint-propagation-based cutting planes: An application to the resource-constrained project scheduling problem. INFORMS Journal on computing 17, no. 1: 52-65. [10] Di, Sheng, D. and Walfredo Cirne. (2012) Characterization and comparison of cloud versus grid workloads. In Cluster Computing (CLUSTER), 2012 IEEE International Conference on, pp. 230-238. IEEE [11] Fox, A. Rean Griffith, A. Joseph, R. Katz, A. Konwinski, G. Lee, D. Patterson, A. Rabkin, and I. Stoica. (2009) Above the clouds: Berkeley view of cloud computing. Dept. Electrical Eng. and Comput. Sciences, University of California, Berkeley, Rep. UCB/EECS 28: 13. [12] Ganapathi, A. Yanpei Chen, Armando Fox, Randy Katz, and David Patterson. (2010) Statistics-driven workload modeling for the cloud. In Data Engineering Workshops (ICDEW), 2010 IEEE 26th International Conference on, pp. 87-92. IEEE [13] Glover, F. (1986) Future paths for integer programming and links to artificial intelligence. Computers & Operations Research 13, no. 5: 533-549. [14] Glover, F. (1989) Tabu search-part I. ORSA Journal on computing 1, no. 3: 190-206. [15] Guo, L. Shuguang Zhao, Shigen Shen, and Changyuan Jiang. (2012) Task scheduling optimization in cloud computing This is the accepted authors version of the paper. The final published version is available in the 2015 IEEE 39th Annual Computer Software and Applications Conference, vol. 3, pp. 121-126. DOI: 10.1109/COMPSAC.2015.223 based on heuristic algorithm. Journal of Networks 7, no. 3: 547-553. [16] Ho, S. (2008) Hung-Sui Lin, Weei-Hurng Liauh, and ShinnJang Ho. OPSO: Orthogonal particle swarm optimization and its application to task assignment problems. Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on 38, no. 2: 288-298. [17] Iosup, A. Simon Ostermann, M. Nezih Yigitbasi, Radu Prodan, Thomas Fahringer, and Dick HJ Epema. (2011) Performance analysis of cloud computing services for many-tasks scientific computing. Parallel and Distributed Systems, IEEE Transactions on 22, no. 6: 931-945. [18] Józefowska J. Grzegorz Waligóra, and Jan Węglarz. (1996) tabu search algorithm for discrete-continuous scheduling problems Modern Heuristic Search Methods: 169-182. [19] Józefowska, J. Marek Mika, Rafal Różycki, Grzegorz search Waligóra, and metaheuristics for discretecontinuous scheduling problems. European Journal of Operational Research 107, no. 2: 354370. (1998) Local Jan Węglarz. [20] Józefowska, J. Marek Mika, Rafał Różycki, Grzegorz Waligóra, and Jan Węglarz. (2001) Simulated annealing for multi-mode resource-constrained project scheduling. Annals of Operations Research 102, no. 1-4: 137-155. [21] Józefowska, J. Marek Mika, Rafał Różycki, Grzegorz Waligóra, and Jan Węglarz. (2002) heuristic approach to allocating the continuous resource in discretecontinuous scheduling problems to minimize the makespan. Journal of Scheduling 5, no. 6: 487-499. [22] Jackson, K. Lavanya Ramakrishnan, Krishna Muriki, Shane Canon, Shreyas Cholia, John Shalf, Harvey J. Wasserman, and Nicholas J. Wright. (2010) Performance analysis of high performance computing applications on the amazon web services cloud. In Cloud Computing Technology and Science (CloudCom), 2010 IEEE Second International Conference on, pp. 159-168. IEEE [23] Kolisch, R. and Sönke Hartmann. (1999) Heuristic algorithms for the resource-constrained project scheduling problem: Classification and computational analysis. Springer US [24] Lardinois, F. Digital Oceans Journey From TechStars Reject To Cloud-Hosting Darling TechCrunch. March 23, 2014. Retrieved November from: 5, http://techcrunch.com/2014/03/23/digital-oceans-journeyfrom-techstars-reject-to-cloud-hosting-darling/ 2014. Available [25] Leung, J. ed. (2004) Handbook of scheduling: algorithms, models, and performance analysis. CRC Press [26] Laplante, P. Jia Zhang, and Jeffrey Voas. (2008) What's in Name? Distinguishing between SaaS and SOA. It Professional 10, no. 3: 46-50. [27] Li, A. Xiaowei Yang, Srikanth Kandula, and Ming Zhang. (2010) CloudCmp: comparing public cloud providers. In Proceedings of the 10th ACM SIGCOMM conference on Internet measurement, pp. 1-14. ACM [28] Lim, A. Hong Ma, Brian Rodrigues, Sun Teck Tan, and Fei Xiao. resourceconstrained project scheduling problem. Flexible Services and Manufacturing Journal 25, no. 1-2: 48-73. (2013) New meta-heuristics the for [29] Limoncelli, T. Strata R. Chalup, and Christina J. Hogan. The Practice of Cloud System Administration: Designing and Operating Large Distributed Systems. Vol. 2. Addison-Wesley Professional, 2014. [30] Mao, M. and Marty Humphrey. (2011) Auto-scaling to minimize cost and meet application deadlines in cloud workflows. In Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis, p. 49. ACM [31] Mishra, A. Joseph L. Hellerstein, Walfredo Cirne, and Chita R. Das. (2010) Towards characterizing cloud backend workloads: insights from google compute clusters. ACM SIGMETRICS Performance Evaluation Review 37, no. 4: 3441. [32] Moreno, I. Peter Garraghan, Paul Townend, and Jie Xu. (2013) An approach for characterizing workloads in google cloud to derive realistic resource utilization models. In Service Oriented System Engineering (SOSE), 2013 IEEE 7th International Symposium on, pp. 49-60. IEEE [33] Sliwko, L. (2008) reinforced evolution-based approach to multi-resource load balancing. Journal of Theoretical and Applied Information Technology, Vol. 4, No. 8: 717-724. [34] Sliwko, L. and Zgrzywa, A. (2007) Multi-resource load optimization strategy in agent-based systems Lecture Notes in Computer Science 4496: 348-357. [35] Tsitsiklis, J. Dimitri P. Bertsekas, and Michael Athans. (1986) Distributed asynchronous deterministic and stochastic gradient optimization algorithms. IEEE transactions on automatic control 31, no. 9: 803-812. [36] Wang, G. Ali Raza Butt, Henry Monti, and Karan Gupta. (2011) Towards synthesizing realistic workload traces for studying the hadoop ecosystem. In Modeling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS), 2011 IEEE 19th International Symposium on, pp. 400-408. IEEE [37] Weinberger, E. (1990) Correlated and uncorrelated fitness landscapes and how to tell the difference. Biological cybernetics 63, no. 5: 325-336."
        }
    ],
    "affiliations": [
        "Faculty of Science and Technology, University of Westminster, London",
        "University of Westminster, London"
    ]
}