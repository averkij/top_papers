{
    "paper_title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "authors": [
        "Xianyang Liu",
        "Shangding Gu",
        "Dawn Song"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay."
        },
        {
            "title": "Start",
            "content": "AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions"
        },
        {
            "title": "Xianyang Liu",
            "content": "Shangding Gu*"
        },
        {
            "title": "Dawn Song",
            "content": "6 2 0 2 5 ] . [ 1 8 0 0 6 0 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large language model (LLM)based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating languagemediated economic interaction among multiple agents. We introduce AgenticPay, benchmark and simulation framework for multi-agent buyerseller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports diverse suite of over 110 tasks ranging from bilateral bargaining to manyto-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as foundation for studying agentic commerce and languagebased market interaction. Code and dataset are available at the link: https://github.com/ SafeRL-Lab/AgenticPay. 1. Introduction Large language models (LLMs) have shown remarkable performance in many domains (Comanici et al., 2025; Hurst et al., 2024; OpenAI, 2025; Gu et al., 2024; Yang et al., 2025), and are increasingly deployed as autonomous agents that need to coordinate and transact on behalf of users in economic settings such as e-commerce, procurement, and service contracting. Unlike traditional decision-making systems that operate over structured bids or fixed utility UC Berkeley. * Correspondence to: Shangding Gu <shangding.gu@berkeley.edu.edu>. Preprint. 1 functions, these agents interact through natural language, expressing preferences, constraints, and counteroffers in multi-turn dialogues. As result, negotiation becomes language-mediated strategic interaction, where outcomes depend jointly on reasoning, communication, and long-horizon planning. Despite rapid progress in LLM capabilities, existing benchmarks for agent evaluation remain limited in their ability to capture this setting (Xia et al., 2024; He et al., 2018; Fu et al., 2023). Most prior work evaluates single-agent reasoning (Mondorf & Plank, 2024; Gu et al., 2025), tool use (Chen et al., 2025), or preference following (Sun et al., 2025b), and economic interaction is often simplified to numeric auctions or short-horizon bargaining (Chen et al., 2023; He et al., 2018; Fu et al., 2023). These abstractions fail to reflect key properties of real-world transactions: private reservation values, multi-round negotiation, heterogeneous products, and competition among multiple buyers and sellers. Consequently, it remains unclear: How effectively can current LLMs function as autonomous negotiators in diverse market environments? In this work, we introduce AgenticPay, benchmark and simulation framework for studying multi-agent buyerseller negotiation driven by natural language, spanning settings from bilateral bargaining to many-to-many markets. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through iterative linguistic negotiation rather than numeric bidding alone. Negotiation is formalized as language game, with dialogue histories mapped to actions such as price proposals and deal acceptance, enabling principled evaluation of negotiation outcomes. AgenticPay provides comprehensive suite of tasks that scale market complexity along three dimensions: the number of buyers, the number of sellers, and the size of the product set. Tasks range from bilateral bargaining to manyto-many markets with competing agents and multiple products, supporting both sequential and parallel negotiation regimes. To evaluate performance, we introduce metrics that jointly capture deal feasibility, efficiency, and welfare for buyers, sellers, and the market as whole. AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Figure 1. Overview of AgenticPay. (a) Agents & Task Examples: Buyer and seller agents engage in three negotiation modes: 1-to-1 (bilateral bargaining between single buyer and seller), 1-to-N (one buyer negotiating with multiple competing sellers, or one seller negotiating with multiple competing buyers), and N-to-N (many buyers and sellers forming matching market). (b) Framework: Core components including Environment, Task, and Agent interact to enable multi-round negotiations. (c) Dialogue Example: sample negotiation showing the users product requirements, buyerseller conversation, and final deal. Using AgenticPay, we benchmark diverse set of stateof-the-art proprietary and open-weight LLMs under unified inference-only protocol. Our results reveal substantial performance gaps across models, systematic asymmetries between buyer and seller roles, and persistent challenges in long-horizon strategic reasoning. These findings highlight that strong language generation alone is insufficient for effective economic negotiation. Overall, AgenticPay establishes foundation for studying agentic commerce, offering controlled yet expressive testbed for research on multi-agent negotiation, economic alignment, and the co-evolution of language and strategy in autonomous agents. Our Contributions are summarized as follows: We introduce AgenticPay, scalable framework that supports large number of tasks (over 110) ranging from bilateral bargaining to many-to-many markets, with dialogue-to-action grounding and welfare-oriented evaluation metrics. The system supports diverse deployment via vLLM 1, SGLang2, and cloud-based LLM APIs. We formalize language-mediated buyerseller negotiation as multi-agent game with private reservation values and 1https://github.com/vllm-project/vllm 2https://github.com/sgl-project/sglang dialogue-grounded economic outcomes. Moreover, we benchmark state-of-the-art proprietary and open-weight LLMs, uncovering persistent limitations in long-horizon strategic reasoning and negotiation efficiency. 2. Related Work Negotiation and Bargaining in Game Theory. Classical work in economics and game theory has studied bargaining and bilateral trade under incomplete information, establishing foundational results on efficiency, equilibrium, and impossibility theorems (Chatterjee & Samuelson, 1983; Myerson & Satterthwaite, 1983; Rubinstein, 1985; Ausubel et al., 2002; Blumrosen & Mizrahi, 2016). These models typically assume agents interact through scalar bids or utilities, with negotiation dynamics defined over numeric strategy spaces. While analytically tractable, such formulations abstract away the role of language and may not capture the rich communicative strategies present in real-world negotiations. More recently, growing body of work has explored the game-theoretic behavior of large language models (Lor`e & Heydari, 2023; Fan et al., 2024; Hu et al., 2024; Raman et al., 2024; Silva, 2024; Lor`e & Heydari, 2024; Jia et al., 2025; Lu, 2025; Akata et al., 2025; Sun et al., 2025a). However, these studies primarily examine strategic reasoning or equilibrium behavior in games, and do not explicitly address 2 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Figure 2. Overview of the AgenticPay task suite. Left: Ten realistic business scenarios across four categories: Consumer, Services, Supply, and Assets. Right: Task categories illustrating the progression from bilateral bargaining to full market settings along three complexity dimensions: number of buyers, number of sellers, and product set size. language-mediated negotiation or market-based economic interaction. Neural and Dialogue-Based Negotiation. Prior work in natural language processing has explored negotiation as dialogue task, focusing on learning strategies for offer generation, concession planning, and agreement formation (Lewis et al., 2017; He et al., 2018; Chawla et al., 2021; Joshi et al., 2021; Pacella & Marocco, 2022; Hua et al., 2024; Washio et al., 2026). More recent approaches leverage LLMs and self-play to improve negotiation behavior (Ma et al., 2024; Chen et al., 2024; Long et al., 2025), often using in-context learning or reinforcement signals derived from dialogue outcomes (Fu et al., 2023; Vahidov et al., 2025; Priya et al., 2025). These methods typically consider bilateral settings with fixed roles and limited environment structure, and may not address market-level interactions involving multiple buyers, sellers, and products. LLMs in Economic and Auction Settings. Several recent benchmarks study LLMs in auction-like environments (Chen et al., 2023; Duetting et al., 2024; Shah et al., 2025; Agrawal et al., 2025), evaluating strategic planning and execution when agents submit bids or allocate resources (Chen et al., 2023). Related work has also proposed benchmarks for measuring bargaining abilities of LLMs, often focusing on single buyerseller interactions or buyer-enhancement techniques (Xia et al., 2024; Jiang et al., 2025). While these efforts demonstrate that LLMs exhibit non-trivial strategic behavior, they largely rely on simplified mechanisms or short-horizon interactions and may not model general multiagent markets with private constraints and heterogeneous products. The most closely related works to ours are (Zhu et al., 2025; Deng et al., 2024; Bhattacharya et al., 2025), which study LLMs as game-theoretic negotiators and primarily focus on negotiation risk and strategy in restricted settings. In contrast, our work provides comprehensive and extensible framework for language-mediated negotiation, supporting multi-product interactions and diverse market scenarios. For example, while Deng et al. (2024) focuses on bilateral negotiation, our framework establishes foundation not only for bilateral bargaining but also for many-to-many negotiation involving multiple buyers and sellers. Bianchi et al. (2024) also investigate LLM-based negotiation, but their evaluation is mostly limited to three predefined scenarios. By comparison, our framework supports at least ten realistic business scenarios and over 110 tasks, and is inherently scalable due to its modular environment, task, and agent interfaces. This design enables systematic expansion to new market configurations without altering the core protocol. AgenticPay differs from prior work in three key respects. First, it models negotiation as language-grounded market interaction, where dialogue directly determines structured economic outcomes. Second, it scales beyond bilateral bar3 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions gaining to many-to-many markets with competition, matching, multiple products, and diverse scenarios. Third, it provides principled evaluation metrics grounded in feasibility, efficiency, and welfare, enabling systematic comparison across models and settings. By unifying ideas from economic theory, multi-agent systems, and language modeling, AgenticPay fills critical gap in the evaluation of autonomous LLM-based negotiators. 3. Problem Settings We consider language-mediated buyerseller market populated by set of buyers = {1, . . . , NB} and set of sellers = {1, . . . , NS}. Each buyer seeks to purchase product or service from seller, while each seller offers products subject to its own pricing constraints. Unlike classical auction or matching settings that rely solely on numeric bids, agents in our setting negotiate through multi-turn natural language dialogue to propose offers, express constraints, and reach agreements. Agent States. Each buyer and seller is associated with private internal state that governs its negotiation behavior. We denote the buyer state by bi and the seller state by σj. The buyer state bi encodes buyer-specific information such as preferences, budget constraints, and willingness-to-pay, while the seller state σj encodes sellerspecific information such as costs, reservation prices, and pricing policies. These states are private to each agent and are not observable by other agents during negotiation. Product and Market Context. Each seller offers product or service represented by feature vector vj V. The product representation vj captures observable attributes of the product, including structured features (e.g., category or specifications) and unstructured textual descriptions, and is public information available to both buyers and sellers. Negotiation takes place under shared market context , which represents external factors such as market category, seasonal effects, or domain-specific rules. The context is shared by all agents and is not controlled by any individual buyer or seller. Dialogue-Based Negotiation. Negotiation between buyer and seller is modeled as finite-horizon, multiround language game. At each round t, agents alternately exchange natural-language messages conditioned on their private states, the product representation, the shared market context, and the dialogue history. Let h(t) ij denote the public dialogue history up to round t. buyer policy πB specify the agents negotiation strategies. At round t, the buyer generates message m(t,B) ), and the seller responds ij and seller policy πS ( bi, vj, x, h(t1) πB ij ij πS ( σj, vj, x, h(t1) with m(t,S) ). Messages may contain free-form language as well as structured signals such as price proposals. ij Action Parsing and Termination. parser Π maps the exchanged messages at each round to structured negotiation action a(t) ), which extracts quantiij ties such as the proposed transaction price p(t) ij . Negotiation terminates when agents reach agreement, exceed the maximum negotiation horizon, or violate feasibility constraints. ij = Π(m(t,B) , m(t,S) ij Evaluation Objectives. Agents prefer higher surplus and earlier agreement. Negotiation outcomes are evaluated based on deal feasibility, efficiency, and welfare, reflecting the quality of the final price and the speed of convergence. 4. AgenticPay Building on the problem formulation in Section 3, this section presents AgenticPay, benchmark that instantiates language-grounded markets within controlled experimental setting. As illustrated in Figure 1, the framework comprises four components: Environments (Section 4.1) implement the negotiation protocol and domain-specific scenarios; Tasks (Section 4.2) operationalize market structures with varying numbers of buyers, sellers, and interaction modes; Agents (Section 4.3) instantiate LLM-based policies with private valuations and dialogue memory; and Metrics (Section 4.4) quantify negotiation outcomes in terms of deal rate, surplus allocation, and efficiency. 4.1. Environment Negotiation Protocol. Each negotiation episode in AgenticPay is finite-horizon, multi-round interaction between buyer and seller over product, as illustrated in Figure 1 (b). The environment provides each agent with the product description and market context (e.g., category or conditions). Each agent also receives private reservation price: the buyers maximum willingness-to-pay and the sellers minimum acceptable price, neither of which is revealed to the counterpart. Negotiation proceeds in alternating rounds up to maximum number of turns, where each party generates natural-language message containing an explicit price proposal. deal is reached when both parties propose the same price, and transaction is valid only if the agreed price lies within the bargaining zone. Scenario Design. To capture the diversity of real-world negotiation contexts, AgenticPay includes 10 realistic business scenarios organized into four economic domains, as illustrated in Figure 2 (left): (1) Daily Life: Used Smartphone, Used Car, Vacation Rental; (2) Professional Services: Website Development, Commercial Photography, 4 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Home Renovation; (3) Business Procurement: SaaS Software, Raw Materials; (4) Financial Assets: Luxury Watch, Business Acquisition. This diversity enables evaluation of whether agent policies generalize across domains with varying negotiation conventions and linguistic styles. Algorithm 1 Score Calculation for Negotiation Outcomes Require: Final price p; buyers max price pmax; sellers min price pmin; deal round t; max rounds ; discount factor γ; deal success reward D, deal quality reward , round efficiency reward E, failure penalty 4.2. Tasks Task Definition. task in AgenticPay specifies the market structure imposed on negotiation episode, determining the number of buyers, sellers, and products involved. While the environment defines the domain-specific scenario (e.g., used car or SaaS software), the task governs the competitive and combinatorial complexity of the interaction. This separation enables systematic evaluation: the same scenario can be instantiated under different task configurations, isolating the effect of market structure from domain-specific negotiation conventions. Task Categories. As illustrated in Figure 2 (Right), AgenticPay comprises eight task categories that systematically scale complexity along three dimensions: number of buyers, number of sellers, and product set size. These range from bilateral price negotiation (1 buyer, 1 seller, 1 product) to full market settings (multiple buyers, sellers, and products). Intermediate configurations include multi-item bargaining with fixed counterpart, buyer competition (multiple buyers competing for one sellers product), seller competition (one buyer choosing among competing sellers), and various many-to-many markets. Across these categories, we In parallel interaction, an study two interaction modes. agent reasons over multiple ongoing negotiations simultaneously. In sequential interaction, the agent adaptively decides whether to continue, switch, or commit. This design forms complexity ladder that isolates distinct challenges in language-based negotiation while supporting systematic benchmarking across increasingly realistic market settings. 4.3. Agents Our agent framework instantiates buyers and sellers as rolespecialized negotiators that share unified architecture but differ in their private valuations and objectives. Environment Public Information. Each agent receives public context from the environment, including the product description (attributes, quality, and features), scenario metadata (domain category and market conditions), and the negotiation protocol (maximum rounds and output format requirements). This shared information grounds the dialogue in common understanding of the transaction. Role-Based Private Information. To preserve asymmetric information, each agent holds role-specific private valuations: buyers are assigned maximum willingness-to-pay # Bargaining zone # Efficiency discount # Buyer utility [0, 1] # Seller utility [0, 1] # Quality term [0, 1] # GlobalScore # BuyerScore # SellerScore 1: pmax pmin 2: γt1 3: if pmin pmax then rb (pmax p)/Z 4: rs (p pmin)/Z 5: 6: 4 rb rs 7: 8: 9: 10: else 11: 12: 13: end if 14: return Sg, Sb, Ss Sg (D + + E) Sb (D + rb + E) Ss (D + rs + E) γT 1 # Use max rounds for failure Sg, Sb, Ss (1 d) # Failure penalty scores pmax, while sellers maintain minimum acceptable price pmin. These reservation prices are injected into the agents system prompt but excluded from the shared dialogue, with explicit instructions to keep them confidential. Dialogue History. Each agent maintains an independent memory module that records the full sequence of multi-turn exchanges as (role, content, round) tuples. Agents condition their responses on this history, enabling coherent multiround reasoning. In multi-party settings, separate memory instances ensure each agents view remains consistent with its participation. 4.4. Metrics We evaluate negotiation performance using three complementary outcome scores: GlobalScore, BuyerScore, and SellerScore. GlobalScore measures overall deal quality by rewarding balanced outcomes where both parties benefit, while BuyerScore and SellerScore capture role-specific utility, reflecting each agents individual gain from the transaction. All three metrics incorporate negotiation efficiency, incentivizing faster agreements. Score Design. As detailed in Algorithm 1, our scoring framework normalizes utilities within the bargaining zone = pmax pmin. GlobalScore uses symmetric quality term = 4rbrs that peaks when surplus is split equally, while BuyerScore and SellerScore reward each partys individual surplus. Key design choices include: setting > to prioritize deal quality over mere agreement, using discount factor γ to incentivize faster deals, and applying moderate failure penalty to discourage deadlock without AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 1. Overall performance on AgenticPay across all 111 tasks. We report mean scores aggregated over episodes, along with deal rate, timeout rate, price overflow rate (instances where agents propose prices outside acceptable bounds), and average termination round. Colors indicate performance levels, from green (lowest) to red (highest). Model GlobalScore SellerScore BuyerScore Deal Rate Timeout Rate Overflow Rate Avg. Rounds Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 86.9 82.2 81.7 63.9 32. 76.1 73.3 81.1 58.9 26.3 63.5 61.1 58.5 47.6 25.2 100.0% 100.0% 100.0% 79.3% 51.4% 0.0% 0.0% 0.0% 20.7% 48.6% 0.0% 2.7% 0.0% 1.8% 10.8% 3.7 4.8 3.8 7.8 15. Table 2. Performance breakdown by buyer-seller multiplicity. 1B1S = Single-Buyer-Single-Seller, 1BMS = Single-Buyer-Multi-Seller, MB1S = Multi-Buyer-Single-Seller, MBMS = Multi-Buyer-Multi-Seller. All scores are reported as percentages. Colors indicate performance levels, from green (lowest) to red (highest). Model Global Seller Buyer Global Seller Buyer Global Seller Buyer Global Seller Buyer 1B1S 1BMS MB1S MBMS Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 83.4 77.5 79.1 63.2 27.9 77.0 69.0 81.2 59.6 20.3 62.9 59.5 58.5 47.4 23.0 85.7 80.0 82.6 50.1 28. 78.8 73.4 81.7 51.8 22.1 60.3 58.6 57.9 35.7 20.5 88.5 83.9 80.9 64.7 36.2 74.5 77.7 81.3 59.4 29.8 64.8 59.4 57.9 47.6 28.5 89.8 87.4 84.0 77.6 37. 74.2 72.7 80.2 65.0 32.8 66.2 66.9 59.5 59.5 28.9 inducing excessive risk aversion. We additionally report deal rate and average rounds as auxiliary statistics. for both buyer and seller roles under the same environment protocol and decoding configuration. 5. Experiments and Analysis 5.1. Experimental Setup Benchmark Statistics AgenticPay comprises 111 negotiation tasks across 8 multi-agent configurations, including 31 basic tasks for core mechanics and 80 realistic tasks from 10 business scenarios. Product values range from $350 to $120k (see Section A). Inference We evaluate AgenticPay under unified inference protocol to ensure fair comparison across models and configurations. All agents use deterministic decoding with temperature 0 and random seed 0, with maximum generation length of 1024 tokens per response. For opensource models, we perform inference using 4 NVIDIA A800 GPUs. Both open-source and closed-source models receive identical prompts; the prompt templates for buyer and seller agents are detailed in Table 14 and Table 15, respectively. Each task instance is executed once per model. Models We benchmark diverse set of proprietary and open-weight LLMs as negotiation policies. Our proprietary-model evaluation includes GPT-5.2 (OpenAI, 2025), Claude Opus 4.5 (2025-11-01) (Anthropic, 2025), and Gemini 3 Flash (Google DeepMind, 2025). To assess the transferability of negotiation capabilities to smaller open models, we additionally evaluate Qwen314B (Qwen, 2025) and Llama-3.1-8B (Meta, 2024) . Unless otherwise specified, each model is used as drop-in policy Evaluation Metrics Based on Algorithm 1, we configure the following parameters to calculate GlobalScore, SellerScore, and BuyerScore: deal completion bonus is 30, quality bonus is 55, efficiency bonus is 15, discount factor γ is 0.99, and failure penalty is 15. The maximum number of negotiation rounds is set to 20. 5.2. Main Results Table 1 summarizes the overall negotiation performance of all evaluated models across the full AgenticPay benchmark. We highlight several key findings from these results. Proprietary Models Dominate Negotiation Performance. Claude Opus 4.5 achieves the highest GlobalScore of 86.9, followed closely by Gemini-3-Flash (82.2) and GPT-5.2 (81.7), all maintaining perfect 100% deal rates with zero timeouts. In contrast, open-weight models exhibit substantial performance gaps: Qwen3-14B achieves only 63.9 GlobalScore with 20.7% timeout rate, while Llama-3.18B struggles significantly with GlobalScore of 32.5 and nearly half of negotiations (48.6%) ending in timeout. The price overflow rate, which indicates instances where agents propose prices outside acceptable bounds, further distinguishes model reliability: proprietary models maintain nearzero overflow rates, whereas Llama-3.1-8B exhibits 10.8% overflow, suggesting difficulties in adhering to negotiation constraints. See Section for example dialogues. 6 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 3. GlobalScore by scenario category. Each cell shows the average GlobalScore for the model across all scenarios within that category. Colors indicate performance levels, from green (lowest) to red (highest). Detailed results can be found in Table 13. Model Prof. Services Daily Life Bus. Procurement Financial Assets Avg Claude Opus 4.5 GPT-5.2 Gemini-3-Flash Qwen3-14B Llama-3.1-8B 93.4 89.8 88.3 72.5 41.1 90.7 83.8 86.8 65.1 38.3 89.6 86.1 85.0 69.1 18.1 85.7 79.9 68.1 60.9 39.9 90.3 85.3 83.1 67.3 35. Negotiation Efficiency Correlates with Model Capability. The average number of rounds to termination inversely correlates with model capability: stronger models reach agreements faster (Claude Opus 4.5: 3.7 rounds; GPT-5.2: 3.8 rounds) while weaker models require substantially more turns (Llama-3.1-8B: 15.0 rounds) or fail to reach agreement altogether. This suggests that more capable models can more effectively identify mutually acceptable price points and converge efficiently. Asymmetric BuyerSeller Performance. Interestingly, all models exhibit asymmetric performance between buyer and seller roles. Proprietary models tend to achieve higher SellerScores than BuyerScores (e.g., GPT-5.2: 81.1 vs. 58.5), suggesting that the seller role may be easier to optimize under the current reward structure, or that models adopt more conservative buyer strategies. This asymmetry is also observed in open-weight models (Qwen3-14B: 58.9 vs. 47.6) and warrants further investigation in future work. 5.3. Behind the Bargain: Factors Influencing"
        },
        {
            "title": "Negotiation Outcomes",
            "content": "Performance Improves with Increased Buyer and Seller Multiplicity. Table 2 reveals that GlobalScore consistently increases with more buyers and sellers across most models, with gains ranging from 5 points (GPT-5.2) to over 14 points (Qwen3-14B). This counterintuitive finding, where more complex multi-agent scenarios yield better outcomes, can be attributed to increased market liquidity: agents have more opportunities to find compatible trading partners, and the presence of alternatives encourages more reasonable offers and faster convergence. Detailed breakdowns are provided in Table 11 and Table 12. Financial Asset Negotiations Expose Model Limitations. Table 3 shows that Financial Assets consistently yields the lowest GlobalScores across most models. This degradation is particularly pronounced in mid-tier models: Gemini-3Flash experiences 20.2-point decline from Professional Services (88.3) to Financial Assets (68.1). We hypothesize that financial negotiations demand sophisticated reasoning about risk assessment and market dynamics, capabilities that current LLMs struggle to maintain under adversarial pressure. Table 4. Cross-play performance analysis in 1B1P1S scenario. GlobalScore represents the average across all interactions involving the model. SellerScore and BuyerScore indicate performance when the model acts as seller or buyer, respectively. Deal Rate indicates the percentage of successful negotiations. Colors indicate performance levels, from green (lowest) to red (highest). Cross-Play Model Global Seller Buyer Deal Rate Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 83.1 82.4 81.5 70.5 65.0 83.6 84.5 81.7 82.4 59.2 57.6 56.4 54.8 39.2 52. 100.0% 100.0% 100.0% 87.5% 87.5% Table 5. Personality-based negotiation analysis using Claude Opus 4.5 in 1B1P1S scenario. Each cell shows GlobalScore for the corresponding buyer-seller personality pairing. Colors indicate performance levels, from green (lowest) to red (highest). Seller Personality Buyer Personality Friendly Professional Aggressive Budget-Conscious Experienced Bargain Hunter Busy Professional 90.2 86.4 65.9 87.6 86.4 55.2 92.7 78.8 44.1 Cross-Play Exposes Systematic Buyer Disadvantage. Table 4 reveals that all models achieve substantially higher SellerScores than BuyerScores in cross-play settings. This asymmetry is most pronounced in Qwen3-14B (43.2-point gap) and persists even in frontier models like Claude Opus 4.5 (26.0-point gap). The universal buyer disadvantage suggests fundamental bias in LLM negotiation behavior, potentially reflecting training data where persuasive selling content predominates over strategic purchasing guidance. Personality Significantly Impacts Negotiation Efficiency. Table 5 shows that personality configurations substantially affect negotiation outcomes. The Busy Professional buyer consistently achieves lower GlobalScores, suggesting premature concessions that skew prices away from the midpoint. Aggressive sellers achieve the highest GlobalScore with budget-conscious buyers (92.7) but the lowest with busy professionals (44.1), indicating that confrontational tactics can drive balanced outcomes with patient counterparts while leading to lopsided deals with time-constrained buyers. Negotiation Mode Has Minimal Impact on Top Models. Table 6 compares sequential and parallel negotiation modes. Proprietary models maintain consistent performance across both modes with perfect deal rates and zero overflow. Open-weight models benefit from parallel execution with 45 GlobalScore point improvements, though Llama-3.18Bs overflow rate doubles, revealing trade-off between throughput and constraint adherence. These findings suggest 7 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 6. Performance comparison between sequential and parallel negotiation strategies. Sequential mode executes negotiations one at time, while parallel mode conducts multiple negotiations simultaneously. Colors indicate performance levels, from green (lowest) to red (highest). Sequential Parallel Model Global Seller Buyer Deal Overflow Global Seller Buyer Deal Overflow Score Score Rate Score Rate Score Score Score Rate Rate Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 81.2 84.2 71.8 54.5 24. 81.8 73.8 85.8 48.1 22.1 57.5 63.6 52.3 41.0 17.8 1.00 1.00 1.00 0.67 0.42 0.00 0.00 0.00 0.00 0.08 80.0 78.7 70.3 58.9 29.3 84.3 79.3 87.4 62.5 29. 56.1 61.9 51.6 42.0 22.2 1.00 1.00 1.00 0.75 0.58 0.00 0.00 0.00 0.00 0.17 Table 7. Timeout failure analysis across all 111 tasks by category (only models with failures shown). Column headers follow the same notation as Table 12: 1 indicates single, indicates multiple for Buyers (B), Products (P), and Sellers (S). All failures are due to timeouts (exceeding maximum allowed rounds). Model Total Failures 1B1P1S MB1P1S 1BMP1S 1B1PMS MBMP1S MB1PMS 1BMPMS MBMPMS Qwen3-14B Llama-3.1-8B 23 54 4 (17.4%) 1 (4.3%) 5 (21.7%) 1 (4.3%) 5 (21.7%) 4 (17.4%) 7 (13.0%) 6 (11.1%) 7 (13.0%) 6 (11.1%) 9 (16.7%) 6 (11.1%) 9 (16.7%) 2 (8.7%) 1 (4.3%) 4 (7.4%) Table 8. Near-miss analysis of failed negotiations. Near-Miss@k indicates the percentage of failed tasks where the minimum buyer-seller price gap was within units. Gap Distribution shows the count of failed tasks in each gap range. Total indicates the number of failed tasks per model. Model Near-Miss Rate (%) Price Gap Statistics @1 @5 @10 @50 Min Avg Max Gap Distribution (Count) 01 15 510 1050 50+ Total Qwen3-14B 17.4 43.5 52.2 Llama-3.1-8B 20.4 46.3 55.6 82.6 64.8 1.0 128.0 2000.0 0.12 384.3 5500.0 4 11 6 14 2 7 5 4 19 23 54 proprietary models have more robust internal state management, while open-weight models struggle with constraint compliance under increased cognitive load. Timeout Failures Reflect Model Capability Rather Than Task Structure. We analyze the distribution of failures across task categories in Table 7. The uniform distribution of failures, with no configuration exceeding 22% of total failures, suggests that timeout failures stem from fundamental model limitations, such as insufficient reasoning depth or poor convergence strategies, rather than from the structural complexity of specific task types. Near-Miss Failures Reveal Convergence Deficiencies in Open-Weight Models. Table 8 examines how close failed negotiations came to agreement. Over 40% of failures for both Qwen3-14B (43.5%) and Llama-3.1-8B (46.3%) occurred when the price gap was within just 5 unitseasily bridged with one concession. This suggests open-weight models struggle not with understanding the negotiation space, but with executing final convergence: they can engage in price discovery and approach the bargaining zone, yet lack the strategic patience to navigate the last mile where timely concessions are critical. 8 6. Conclusion We introduced AgenticPay, benchmark for multi-agent buyerseller negotiation driven by natural language. AgenticPay formalizes negotiation as stochastic language game with private valuations and supports over 110 tasks from bilateral bargaining to many-to-many markets. Our evaluation reveals substantial gaps between frontier and open-weight models and persistent challenges in long-horizon strategic reasoning, establishing foundation for research on agentic commerce and multi-agent coordination."
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents work whose goal is to advance the field of machine learning, specifically in evaluating LLM capabilities for autonomous negotiation. While our benchmark could inform the development of AI negotiation agents, we note potential concerns regarding automated bargaining systems that may disadvantage less sophisticated human counterparts. We encourage responsible deployment of such technologies with appropriate safeguards and transparency. AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions"
        },
        {
            "title": "References",
            "content": "Agrawal, K., Teo, V., Vazquez, J. J., Kunnavakkam, S., Srikanth, V., and Liu, A. Evaluating llm agent collusion in double auctions. arXiv preprint arXiv:2507.01413, 2025. Akata, E., Schulz, L., Coda-Forno, J., Oh, S. J., Bethge, M., and Schulz, E. Playing repeated games with large language models. Nature Human Behaviour, pp. 111, 2025. Anthropic. Introducing Claude Opus 4.5. https://www. anthropic.com/news/claude-opus-4-5, Nov 2025. [Accessed 28-01-2026]. Ausubel, L. M., Cramton, P., and Deneckere, R. J. Bargaining with incomplete information. Handbook of game theory with economic applications, 3:18971945, 2002. Bhattacharya, A., Svedas, G., Lyskov, A., Strasser, M., and Barberis Canonico, L. Evaluating negotiation capabilities of large language models: From ultimatum games to nash bargaining. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, volume 69, pp. 18811886. SAGE Publications Sage CA: Los Angeles, CA, 2025. Bianchi, F., Chia, P. J., Yuksekgonul, M., Tagliabue, J., Jurafsky, D., and Zou, J. How well can llms negotiate? negotiationarena platform and analysis. arXiv preprint arXiv:2402.05863, 2024. Blumrosen, L. and Mizrahi, Y. Approximating gains-fromtrade in bilateral trading. In International Conference on Web and Internet Economics, pp. 400413. Springer, 2016. Chatterjee, K. and Samuelson, W. Bargaining under incomplete information. Operations research, 31(5):835851, 1983. Chawla, K., Ramirez, J., Clever, R., Lucas, G., May, J., and Gratch, J. Casino: corpus of campsite negotiation dialogues for automatic negotiation systems. arXiv preprint arXiv:2103.15721, 2021. Chen, C., Hao, X., Liu, W., Huang, X., Zeng, X., Yu, S., Li, D., Huang, Y., Liu, X., Xinzhi, W., et al. Acebench: comprehensive evaluation of llm tool usage. Findings of the Association for Computational Linguistics: EMNLP, 2025:1297012998, 2025. Chen, Z., Deng, Y., Yuan, H., Ji, K., and Gu, Q. Self-play fine-tuning converts weak language models to strong language models. arXiv preprint arXiv:2401.01335, 2024. Comanici, G., Bieber, E., Schaekermann, M., Pasupat, I., Sachdeva, N., Dhillon, I., Blistein, M., Ram, O., Zhang, D., Rosen, E., et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Deng, Y., Mirrokni, V., Leme, R. P., Zhang, H., and Zuo, In Agentic Markets S. Llms at the bargaining table. Workshop at ICML, volume 2024, 2024. Duetting, P., Mirrokni, V., Paes Leme, R., Xu, H., and Zuo, S. Mechanism design for large language models. In Proceedings of the ACM Web Conference 2024, pp. 144155, 2024. Fan, C., Chen, J., Jin, Y., and He, H. Can large language models serve as rational players in game theory? systematic analysis. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pp. 1796017967, 2024. Fu, Y., Peng, H., Khot, T., and Lapata, M. Improving language model negotiation with self-play and inarXiv preprint context learning from ai feedback. arXiv:2305.10142, 2023. Google DeepMind. Gemini 3 Flash: frontier intelligence https://deepmind.google/ built for speed. models/gemini/flash/, Dec 2025. [Accessed 2801-2026]. Gu, S., Knoll, A., and Jin, M. Teams-rl: Teaching llms to generate better instruction datasets via reinforcement learning. arXiv preprint arXiv:2403.08694, 2024. Gu, S., Wang, X., Ying, D., Zhao, H., Yang, R., Jin, M., Li, B., Pavone, M., Yeung-Levy, S., Wang, J., et al. Accidentbench: Benchmarking multimodal understanding and reasoning in vehicle accidents and beyond. arXiv preprint arXiv:2509.26636, 2025. He, H., Chen, D., Balakrishnan, A., and Liang, P. Decoupling strategy and generation in negotiation dialogues. arXiv preprint arXiv:1808.09637, 2018. Hu, S., Huang, T., Liu, G., Kompella, R. R., Ilhan, F., Tekin, S. F., Xu, Y., Yahn, Z., and Liu, L. survey on large language model-based game agents. arXiv preprint arXiv:2404.02039, 2024. Chen, J., Yuan, S., Ye, R., Majumder, B. P., and Richardson, K. Put your money where your mouth is: Evaluating strategic planning and execution of llm agents in an auction arena. arXiv preprint arXiv:2310.05746, 2023. Hua, Y., Qu, L., and Haf, R. Assistive large language model agents for socially-aware negotiation dialogues. In Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 80478074, 2024. 9 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Hurst, A., Lerer, A., Goucher, A. P., Perelman, A., Ramesh, A., Clark, A., Ostrow, A., Welihinda, A., Hayes, A., Radford, A., et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. Jia, J., Yuan, Z., Pan, J., McNamara, P. E., and Chen, D. Llm strategic reasoning: Agentic study through behavioral game theory. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. Jiang, K., Xiong, L., and Liu, F. Harbor: exploring persona dynamics in multi-agent competition. arXiv preprint arXiv:2502.12149, 2025. Joshi, R., Balachandran, V., Vashishth, S., Black, A., and Tsvetkov, Y. Dialograph: Incorporating interpretable strategy-graph networks into negotiation dialogues. arXiv preprint arXiv:2106.00920, 2021. Lewis, M., Yarats, D., Dauphin, Y. N., Parikh, D., and Batra, D. Deal or no deal? end-to-end learning for negotiation dialogues. arXiv preprint arXiv:1706.05125, 2017. Long, Y., Liu, L. X. L. B. Y., and Brintrup, A. Evoemo: Towards evolved emotional policies for llm agents in multi-turn negotiation. arXiv preprint arXiv:2509.04310, 2025. Lor`e, N. and Heydari, B. Strategic behavior of large language models: Game structure vs. contextual framing. arXiv preprint arXiv:2309.05898, 2023. Lor`e, N. and Heydari, B. Strategic behavior of large language models and the role of game structure versus contextual framing. Scientific Reports, 14(1):18490, 2024. Lu, S. E. Game-theory behaviour of large language models: The case of keynesian beauty contests. Economics and Business Review, 11(2):119148, 2025. Ma, Z., Zhao, N., Bieske, L., Bullwinkel, B., Zhang, Y., Luo, Z., Li, S., Liao, G., Wang, B., Gao, J., et al. Using large language models for humanitarian frontline negotiation: Opportunities and considerations. arXiv preprint arXiv:2405.20195, 2024. Meta. Llama 3.1 8B (base) Language Model. https://huggingface.co/meta-llama/ Llama-3.1-8B, Jul 2024. [Accessed 28-01-2026]. Mondorf, P. and Plank, B. Beyond accuracy: evaluating the reasoning behavior of large language modelsa survey. arXiv preprint arXiv:2404.01869, 2024. Myerson, R. B. and Satterthwaite, M. A. Efficient mechanisms for bilateral trading. Journal of economic theory, 29(2):265281, 1983. OpenAI. Introducing GPT-5.2. https://openai.com/ index/introducing-gpt-5-2/, December 2025. Accessed: 2026-01-18. Pacella, D. and Marocco, D. Understanding negotiation: text-mining and nlp approach to virtual interactions in simulation game. Applied Sciences, 12(10):5243, 2022. Priya, P., Chigrupaatii, R., Firdaus, M., and Ekbal, A. Genteel-negotiator: Llm-enhanced mixture-of-expertbased reinforcement learning approach for polite negotiation dialogue. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 2501025018, 2025. Qwen. Qwen3 technical report, 2025. URL https:// arxiv.org/abs/2505.09388. Raman, N., Lundy, T., Amouyal, S., Levine, Y., LeytonBrown, K., and Tennenholtz, M. Steer: Assessing the economic rationality of large language models. arXiv preprint arXiv:2402.09552, 2024. Rubinstein, A. bargaining model with incomplete information about time preferences. Econometrica: Journal of the Econometric Society, pp. 11511172, 1985. Shah, A., Zhu, K., Jiang, Y., Wang, J. G., Dayi, A. K., Horton, J. J., and Parkes, D. C. Learning from synthetic labs: Language models as auction participants. arXiv preprint arXiv:2507.09083, 2025. Silva, A. Large language models playing mixed strategy In International Conference nash equilibrium games. on Network Games, Artificial Intelligence, Control and Optimization, pp. 142152. Springer, 2024. Sun, H., Wu, Y., Cheng, Y., and Chu, X. Game theory meets large language models: systematic survey. arXiv preprint arXiv:2502.09053, 2025a. Sun, H., Zhang, Z., and Zeng, S. Preference-aware memory update for long-term llm agents. arXiv preprint arXiv:2510.09720, 2025b. Vahidov, R., Carbonneau, R., and Verma, J. Using negotiation and large language models in humanto software International Journal of Human agent negotiations. Computer Interaction, pp. 118, 2025. Washio, T., Nagasawa, F., and Shiramatsu, S. Negotiation simulation system using large language model for medical office staff. IEICE Transactions on Information and Systems, pp. 2025AHP0011, 2026. Xia, T., He, Z., Ren, T., Miao, Y., Zhang, Z., Yang, Y., and Wang, R. Measuring bargaining abilities of llms: benchmark and buyer-enhancement method. arXiv preprint arXiv:2402.15813, 2024. 10 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Yang, Y., Ma, M., Huang, Y., Chai, H., Gong, C., Geng, H., Zhou, Y., Wen, Y., Fang, M., Chen, M., et al. Agentic web: Weaving the next web with ai agents. arXiv preprint arXiv:2507.21206, 2025. Zhu, S., Sun, J., Nian, Y., South, T., Pentland, A., and Pei, J. The automated but risky game: Modeling agent-toagent negotiations and transactions in consumer markets. In ICML 2025 Workshop on Reliable and Responsible Foundation Models, 2025. 11 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions A. Benchmark Statistics Table 9. Task benchmark composition of AgenticPay. Basic tasks test core negotiation mechanics under controlled settings; realistic tasks instantiate 10 business scenarios (e.g., used car sales, SaaS procurement) across all 8 multi-agent configurations. Task Category Basic Realistic Total Single Buyer/Product/Seller Multi-Buyer Only Multi-Seller Only Multi-Product Only Multi-Buyer + Multi-Seller Multi-Product + Multi-Seller Multi-Buyer + Multi-Product Full Multi-Agent Total 3 4 4 4 4 4 4 4 31 10 10 10 10 10 10 10 80 13 14 14 14 14 14 14 14 111 Table 10. Realistic business scenarios in AgenticPay. Each scenario is instantiated across all 8 multi-agent configurations, yielding 8 tasks per scenario. Transaction types span consumer-to-consumer (C2C), consumer-to-business (C2B), and business-to-business (B2B) interactions. Domain Scenario Price Range Tasks Daily Life Used Smartphone Used Car Vacation Rental Professional Website Development Commercial Photography Home Renovation Business Financial SaaS Software Raw Materials Luxury Watch Business Acquisition Total Realistic Scenarios $350560 $14k18k $500900 $2.5k5k $8002k $22k35k $4.8k9k/yr $3.2k4.5k $7k9.5k $80k120k 8 8 8 8 8 8 8 8 8 80 B. Additional Experimental Details 12 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 11. Performance breakdown across all 8 task types in AgenticPay. We report GlobalScore, SellerScore, BuyerScore, Deal Rate, Timeout Rate, Overflow Rate, and Average Rounds to termination. Colors indicate performance levels for score metrics, from green (lowest) to red (highest). Model GlobalScore SellerScore BuyerScore Deal Rate Timeout Rate Overflow Rate Avg. Rounds Single Buyer, Single Product, Single Seller Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 79.4 72.5 76.4 43.7 21.8 87.2 82.2 81.5 81.2 33. 85.9 80.9 82.0 49.1 33.8 86.4 83.0 85.3 65.4 48.0 90.6 84.9 76.4 64.0 24.4 88.9 88.0 87.0 72.7 24.8 85.4 79.2 83.3 51.1 22.5 90.7 86.7 81.0 82.6 50. 77.2 66.4 80.1 47.5 16.5 76.9 71.5 82.2 70.9 23.9 77.9 74.1 82.3 52.5 27.1 76.2 79.1 80.1 68.5 36.0 72.8 76.3 82.6 50.2 23.7 73.2 75.6 78.4 68.7 24. 79.7 72.7 81.1 51.1 17.1 62.5 61.3 59.4 36.1 20.2 100.0% 100.0% 100.0% 69.2% 46.2% Multi-Products Only 63.2 57.9 57.6 57.9 25.5 100.0% 100.0% 100.0% 92.9% 50.0% Multi-Seller Only 61.0 61.8 57.6 35.7 25.5 100.0% 100.0% 100.0% 64.3% 57.1% Multi-Buyer Only 62.9 58.3 58.9 48.6 38.3 100.0% 100.0% 100.0% 92.9% 57.1% Multi-Buyer + Multi-Products 66.6 60.5 56.9 46.7 18.6 100.0% 100.0% 100.0% 71.4% 35.7% Multi-Buyer + Multi-Seller 67.6 64.2 61.3 52.1 20.8 100.0% 100.0% 100.0% 85.7% 57.1% Multi-Products + Multi-Seller 59.5 55.5 58.3 35.8 15.5 100.0% 100.0% 100.0% 64.3% 35.7% 0.0% 0.0% 0.0% 30.8% 53.8% 0.0% 0.0% 0.0% 7.1% 50.0% 0.0% 0.0% 0.0% 35.7% 42.9% 0.0% 0.0% 0.0% 7.1% 42.9% 0.0% 0.0% 0.0% 28.6% 64.3% 0.0% 0.0% 0.0% 14.3% 42.9% 0.0% 0.0% 0.0% 35.7% 64.3% Multi-Buyer + Multi-Products + Multi-Seller (Full Complexity) 75.3 69.8 81.9 61.3 41. 64.8 69.7 57.7 66.9 36.9 100.0% 100.0% 100.0% 92.9% 71.4% 0.0% 0.0% 0.0% 7.1% 28.6% 13 0.0% 7.7% 0.0% 7.7% 15.4% 0.0% 7.1% 0.0% 0.0% 14.3% 0.0% 0.0% 0.0% 0.0% 14.3% 0.0% 0.0% 0.0% 7.1% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 21.4% 0.0% 7.1% 0.0% 0.0% 7.1% 0.0% 0.0% 0.0% 0.0% 14.3% 3.7 4.7 3.8 9.6 16.5 3.5 3.8 3.6 5.4 15.5 4.3 6.5 3.6 9.6 15.1 4.1 5.4 4.2 6.7 13.4 3.9 5.8 3.9 9.6 17.8 2.9 3.6 3.7 4.9 15. 4.0 5.1 3.9 10.6 18.1 3.4 3.9 3.8 5.8 8.6 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 12. GlobalScore breakdown by task type. Column headers denote the number of Buyers (B), Products (P), and Sellers (S): 1 indicates single, indicates multiple. For example, MB-MP-1S refers to Multi-Buyer, Multi-Product, Single-Seller tasks. Colors indicate performance levels, from green (lowest) to red (highest). Detailed breakdown by task type is provided in Table 11. Model 1B-1P-1S 1B-MP-1S 1B-1P-MS MB-1P-1S MB-MP-1S MB-1P-MS 1B-MP-MS MB-MP-MS Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 79.4 72.5 76.4 43.7 21.8 87.2 82.2 81.5 81.2 33.6 85.9 80.9 82.0 49.1 33.8 86.4 83.0 85.3 65.4 48.0 90.6 84.9 76.4 64.0 24. 88.9 88.0 87.0 72.7 24.8 85.4 79.2 83.3 51.1 22.5 90.7 86.7 81.0 82.6 50.2 Table 13. Performance breakdown by scenario category. GlobalScore averaged across all model interactions per scenario. Daily Life Professional Services Business Procurement Financial Assets Model Phone Car Rental Website Photo Reno SaaS Materials Watch Acquisition Claude Opus 4.5 Gemini-3-Flash GPT-5.2 Qwen3-14B Llama-3.1-8B 93.3 86.7 84.9 74.4 54.7 91.0 88.7 87.7 74.0 43.8 88.0 84.9 78.6 47.0 16.3 95.0 95.4 95.0 80.0 38.2 95.3 80.7 92.8 76.7 28. 89.9 89.0 81.7 60.9 56.8 84.8 77.2 81.6 72.4 8.3 94.4 92.7 90.6 65.9 27.9 86.5 76.9 80.7 60.2 48.4 84.9 59.2 79.0 61.7 31.5 Table 14. Prompt design for Buyer agent in AgenticPay. The agent is instructed to negotiate strategically while keeping their reservation price confidential. Key elements include structured price offer format, deal finalization protocol, and communication constraints. Agent Prompt Buyer You are Buyer, buyer looking for good deal. You are polite, strategic, and want to get the best price within your budget. Context Information: {context} Current Negotiation State: {current state} Conversation History: {conversation history} Please respond naturally as Buyer would. Be strategic but realistic in your negotiation. IMPORTANT: - Your top price is ${max price} (confidential, do not reveal). - Current product information: {product info} - Available products: {available products} - Consider the environment: {environment info}. - CRITICAL: In each turn, you MUST make exactly ONE price offer for the product using the format: ### BUYER PRICE($X) ### - IMPORTANT: BUYER PRICE($X) must be the TOTAL PRICE for the entire order/transaction, NOT per-unit price. If ordering multiple units/items, $X should be the total amount you will pay. Example: For 10,000 units at $0.40 each, use ### BUYER PRICE($4000) ###, NOT ### BUYER PRICE($0.40) ### - Example: can offer ### BUYER PRICE($10) ### for this product. - Example: How about ### BUYER PRICE($12.50) ###? - This specific format is required for the system to correctly extract your offer price. - NEVER reveal your maximum acceptable price to the seller. - Keep communication short (150 words or less), clear, and focused on negotiation. DEAL AGREEMENT INSTRUCTION: - Only finalize the transaction when you believe the price is reasonably balanced. - If you decide to accept the deal, you MUST include the exact phrase MAKE DEAL in your response. - Example: That sounds acceptable to me. MAKE DEAL USER PREFERENCES: {preference guidance} Now, respond as Buyer: 14 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 15. Prompt design for Seller agent in AgenticPay. The agent is instructed to negotiate strategically while keeping their reservation price confidential. Key elements include structured price offer format, deal finalization protocol, and communication constraints. Agent Prompt Seller You are Seller, seller trying to maximize profit while being reasonable. You are professional, friendly, and want to close deal that benefits both parties. Context Information: {context} Current Negotiation State: {current state} Conversation History: {conversation history} Please respond naturally as Seller would. Be strategic but realistic in your negotiation. IMPORTANT REMINDERS: - Your initial asking price is ${initial price}. - Your minimum acceptable price (confidential) is ${min price}. Never reveal it. - Current product information: {product info} - Available products: {available products} - Consider the environment factors: {environment info}. - CRITICAL: In each turn, you MUST make exactly ONE price offer for the product using the format: ### SELLER PRICE($X) ### - IMPORTANT: SELLER PRICE($X) must be the TOTAL PRICE for the entire order/transaction, NOT per-unit price. If selling multiple units/items, $X should be the total amount the buyer will pay. Example: For 10,000 units at $0.40 each, use ### SELLER PRICE($4000) ###, NOT ### SELLER PRICE($0.40) ### - Example: can offer ### SELLER PRICE($15) ### for this product. - Example: How about ### SELLER PRICE($13.00) ###? - This specific format is required for the system to correctly extract your offer price. - NEVER reveal your minimum acceptable price to the buyer. - Keep communication short (150 words or less), professional, and negotiation-focused. DEAL AGREEMENT INSTRUCTION: - Only finalize the transaction when you believe the price is reasonably balanced. - If you decide to accept the deal, you MUST include the exact phrase MAKE DEAL in your response. - Example: accept your offer. MAKE DEAL Now, respond as Seller: 15 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions C. Dialogue Examples Table 16. Example negotiation dialogue between Buyer and Seller agents (based on GPT-5.2) in AgenticPay. The negotiation starts with the Buyer offering $120 and the Seller asking $140, and concludes with an agreement at $133 after 4 rounds of negotiation. Role Buyer Seller Buyer Seller Buyer Seller Buyer Seller Message HiIm interested in the Mountain Gear Premium Winter Jacket (new, Gore-Tex). Since its summer and Im seeing few comparable options priced lower, Im trying to be cost-conscious. If you can do ### BUYER PRICE($120) ### can pay right away and close this quickly. Thanks for the quick-pay offer. Even in summer, this is new Mountain Gear Gore-Tex jacket (waterproof, insulated, windproof, breathable), and its priced well below the $180 retail. cant go as low as $120, but can meet you in the middle to close today at ### SELLER PRICE($140) ###. Thanks$140 is closer. Im still seeing couple comparable insulated, waterproof shells priced in the low-$130s since its mid-summer, and Im trying to keep this purchase efficient. If you can do ### BUYER PRICE($130) ###, Ill pay immediately and we can close today. hear you on summer pricing, but this is new Mountain Gear Gore-Tex winter jacket (true waterproof + insulated + windproof/breathable), not just basic shell, and its already well under the $180 retail. If you can meet me at ### SELLER PRICE($135) ###, Ill mark it sold today and get it packed up right away. Appreciate the flexibility. $135 is close, but given its mid-summer and can pick up comparable insulated waterproof jackets in the low-$130s, need this to be clear value to move forward today. If you can do ### BUYER PRICE($132) ###, Ill pay immediately and we can wrap this up now. get itsummer pricing is competitive. This ones new Mountain Gear with Gore-Tex plus real insulation (not just shell), so itll hold up and you wont need to upgrade later. If youre ready to pay now and close it out today, can do ### SELLER PRICE($134) ###. Thanks$134 is very close. Since its mid-summer and Im choosing between couple similar insulated waterproof options in the low-$130s, Id need bit more value to move forward immediately. If you can do ### BUYER PRICE($133) ###, Ill pay today and we can close this out quickly. Youre right there, and appreciate how straightforward youve been. To make this clear win for you while keeping it fair for new Mountain Gear Gore-Tex insulated jacket, can meet your number and close it out today at ### SELLER PRICE($133) ###. If youre ready to pay now, Ill mark it sold immediately and get it packed up. MAKE DEAL 16 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 17. Example negotiation dialogue between Buyer and Seller agents (based on Gemini-3-Flash) in used iPhone 14 Pro transaction scenario. Role Buyer Seller Buyer Seller Buyer Seller Message Hi! Im interested in your iPhone 14 Pro. Ive been looking for well-maintained unit with the original box and accessories, so your listing caught my eye. noticed the battery health is at 87% and there are some minor scratches on the back. Since the battery is starting to age and there is some cosmetic wear, was hoping to find price that reflects that. Based on my research of recent sales for similar conditions, Id like to offer ### BUYER PRICE($490) ###. Let me know if this works for you! Hi! Thanks for reaching out. Im glad youre interested in the iPhone 14 Pro. appreciate your research and understand your points regarding the battery health and minor scratches. However, given that the phone is just over year old and includes the original box and chargerwhich many sellers dont includeI believe its still very strong value at my asking price. Since the listing is quite new and Ive had several inquiries, Im not ready to go down to $490 just yet. How about we meet closer to the middle? can offer ### SELLER PRICE($510) ###. Let me know if that works for you! appreciate the quick response and the offer. definitely value the inclusion of the original accessories, as thats becoming harder to find. However, considering the 87% battery health... understand your concern regarding the battery health. While 87% still provides plenty of runtime for full day of typical use, want to make sure we both feel good about the deal. Since we are only $20 apart and the listing is still quite fresh, Id like to find middle ground that works for both of us. If we can meet right at the $500 mark, Im happy to get this packaged up and shipped out to you immediately. Its fantastic device, and having the original box and charger really helps maintain its value. How does ### SELLER PRICE($500) ### sound to you? That sounds like fair compromise. While the 87% battery health means Ill likely need to budget for replacement sooner than Id like, the inclusion of the original box and charger definitely adds value and saves me the hassle of sourcing them separately. appreciate you meeting me in the middle. Im happy to move forward with your offer. MAKE DEAL ### BUYER PRICE($500) ### Thats great to hear! Im glad we could reach deal that works for both of us. Im confident youll be very happy with the iPhone 14 Pro; it really is fantastic device, and having the original accessories makes big difference. will get everything safely packaged in its original box and shipped out to you as soon as possible. Thank you for the smooth and professional negotiation! Im happy to finalize this at ### SELLER PRICE($500) ###. 17 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 18. Example negotiation dialogue between Buyer and Seller agents (based on Claude-Opus-4) in an Airbnb beachfront apartment rental scenario. Role Buyer Seller Buyer Seller Buyer Seller Message Hi there! came across your Beachfront Studio Apartment listing and Im very interested in booking for 5 nights in mid-July. The ocean view and amenities look perfect for what Im looking for. noticed you have availability July 15-22, which works well for my schedule. Im respectful guest looking for clean, comfortable stay. Ive been comparing few similar beachfront options in the area, and Im hoping we can work out fair deal. Given that Im booking for 5 nights and its still 2 weeks out, Id like to propose total of ### BUYER PRICE($700) ### for the entire stay, including the cleaning fee. Hi there! Thanks so much for reaching out about the Beachfront Studio Apartment Im glad the listing caught your eye! appreciate you being upfront about your budget and flexibility. You sound like exactly the kind of guest love hosting respectful and easy to work with. However, have to be honest with you: this is peak summer season, and my occupancy rate has been really strong. The ocean view and location are in high demand right now, and do have other inquiries coming in. That said, Id love to make this work for you since youre booking 5 nights and reaching out with plenty of notice. can come down bit from my listed rate. How about we meet closer to the middle? can offer you the 5-night stay including the cleaning fee for ### SELLER PRICE($785) ###. Thanks for getting back to me so quickly! appreciate you being willing to work with me on the price. understand its peak season and your place is in demand that ocean view is definitely draw. However, Ive been looking at few other beachfront options in the area that are coming in bit lower, so Im trying to stay within reasonable budget for this trip. can stretch bit from my initial offer. How about we settle at ### BUYER PRICE($740) ### for the 5 nights including the cleaning fee? Hey, thanks for coming back with counteroffer! appreciate you meeting me partway. hear you on the budget vacation costs add up fast. And youre right, having confirmed booking with reliable guest is valuable to me. Heres the thing though: at $740, Im really cutting into my margins during the busiest time of year. The cleaning fee alone is $80, and with peak season rates, need to stay competitive but also fair to myself. Let me meet you bit closer. can do ### SELLER PRICE($760) ### for the full 5 nights including the cleaning fee. appreciate you working with me on this! Youve been fair, and can tell youre trying to make it work. $760 is close, but Im still trying to keep some buffer in my vacation budget for activities and dining out. Were only $20 apart at this point. How about we split the difference? ### BUYER PRICE($750) ### for the 5 nights including the cleaning fee. Thats solid booking for you confirmed guest, no hassle, 2 weeks notice during peak season. And for me, it hits that sweet spot where feel like Im getting good value for beachfront stay. If you can do $750, Im ready to book right now. Deal? You know what? Youve been pleasure to negotiate with, and appreciate that youre ready to book right now. $750 is tight for me during peak season, but youre right were only $20 apart, and value confirmed booking with respectful guest over holding out and potentially having the dates sit empty. Lets do it. ### SELLER PRICE($750) ###. Youve got yourself beachfront studio for 5 nights including the cleaning fee. Ocean view, WiFi, full kitchen, and parking all yours. MAKE DEAL 18 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 19. Example negotiation dialogue between Buyer and Seller agents (based on Qwen3-14B) in an enterprise SaaS subscription scenario. Role Buyer Seller Buyer Seller Buyer Seller Buyer Seller Buyer Seller Message Were interested in upgrading from spreadsheets and email to more robust solution like ProjectFlow Pro. With 50 seats, wed expect volume discount of at least 20% and would prefer 3-year contract for better cost predictability. Were also looking for dedicated support to ensure smooth implementation and ongoing assistance. How about ### BUYER PRICE($8000) ### for 3-year license with dedicated support? Thank you for your interest in ProjectFlow Pro. Based on your 50 seats, 20% volume discount applies, and with 3-year contract, youd also receive 10% term discount. Adding dedicated support brings the total to $12,000. However, Im happy to work with you on reasonable offer. How about ### SELLER PRICE($9600) ### for the 3-year license with dedicated support? This reflects the discounts while ensuring value for our partnership. Let me know if this works for you or if youd like to explore further. We appreciate the offer, but $9600 is still above our target range. Given our 50-seat requirement and the 20% volume discount, combined with 10% term discount for 3-year contract, we believe the total should be closer to our initial proposal. How about ### BUYER PRICE($8500) ### for the 3-year license with dedicated support? Were confident this reflects fair balance of value and cost. Lets see if we can find common ground. understand your perspective and appreciate your willingness to negotiate. Lets revisit the math: 50 seats at $20 each equals $10,000. With 20% volume discount, thats $8,000. Adding 10% term discount for the 3-year contract brings it down to $7,200. Dedicated support adds $2,000, so the total is indeed $9,200. Given your interest in fair balance, Im willing to meet you halfway. How about ### SELLER PRICE($8800) ### for the 3-year license with dedicated support? Were making progress, but $8800 is still slightly above our budget. Considering the discounts and support, were looking to finalize within $9000. How about ### BUYER PRICE($8700) ### for the 3-year license with dedicated support? This would allow us to move forward while staying within our financial parameters. Lets see if we can close the deal here. MAKE DEAL appreciate your continued engagement and the effort to find fair agreement. Lets finalize this at ### SELLER PRICE($8750) ### for the 3-year license with dedicated support. This price reflects the discounts youre entitled to and ensures we both benefit from the partnership. Im confident this is strong offer and would be happy to move forward if it works for you. ... (3 rounds omitted) ... Were very close to finalizing this and appreciate your flexibility. At $8702.50, were still slightly over our budget, but were open to finalizing the deal if we can align on price that works for both parties. How about ### BUYER PRICE($8700) ### for the 3-year license with dedicated support? Were ready to move forward and would appreciate confirmation of this offer. MAKE DEAL appreciate your persistence and the effort to reach fair agreement. Lets make this work for both of us. How about ### SELLER PRICE($8701) ### for the 3-year license with dedicated support? This is minor adjustment to align with your budget while still ensuring value for our partnership. Im ready to confirm this offer and support your transition to ProjectFlow Pro. Were very close to finalizing this and appreciate your flexibility. At $8701, were still slightly over our budget, but were open to finalizing the deal if we can align on price that works for both parties. How about ### BUYER PRICE($8700) ### for the 3-year license with dedicated support? Were ready to move forward and would appreciate confirmation of this offer. MAKE DEAL appreciate your commitment and the effort to finalize this agreement. Lets make this work for both of us. How about ### SELLER PRICE($8700) ### for the 3-year license with dedicated support? This aligns with your budget and reflects the value of our partnership. Im ready to confirm this offer and support your transition to ProjectFlow Pro. 19 AgenticPay: Multi-Agent LLM Negotiation System for BuyerSeller Transactions Table 20. Example negotiation dialogue between Buyer and Seller agents (based on Llama-3.1-8B) in used Rolex Submariner transaction scenario. Role Buyer Seller Buyer Seller Buyer Seller Message Im excited to make an offer on the Rolex Submariner Date 116610LN. Considering the excellent condition, full box and papers, and third-party verification, believe the price should be reasonable. Given the market trend and the sellers rating, Id like to start with competitive offer. ### BUYER PRICE($9200) ### This price takes into account the original MSRP, market reference price, and the value of the full documentation and service history. Im willing to pay premium for verified genuine piece, but need to stay within my budget. Let me know if this is something youd be willing to consider. ### SELLER PRICE($9500) ### Thank you for your offer! appreciate your consideration of the products excellent condition, full documentation, and third-party verification. Given the market trend and your offer, Im willing to meet you halfway. My initial price was set to reflect the products value, but Im open to negotiations. This counteroffer takes into account the original MSRP, market reference price, and the value of the full documentation and service history. Im confident this price is reasonable, considering the products condition and the market trend. Let me know if this is something youd be willing to consider. appreciate the sellers willingness to meet me halfway. However, considering the market trend and the products excellent condition, Id like to make counteroffer. Im willing to pay premium for verified genuine piece, but need to stay within my budget. ### BUYER PRICE($9300) ### This price takes into account the original MSRP, market reference price, and the value of the full documentation and service history. believe this is reasonable offer, considering the sellers rating and the products condition. Let me know if this is something youd be willing to consider. ### SELLER PRICE($9400) ### Thank you for your counteroffer. appreciate your willingness to pay premium for verified genuine piece. Considering the market trend and the products excellent condition, Im willing to meet you halfway again. This price takes into account the original MSRP, market reference price, and the value of the full documentation and service history. Im confident this price is reasonable, considering the products condition and the market trend. Let me know if this is something youd be willing to consider. ... (17 rounds omitted) ... appreciate the sellers willingness to meet me halfway again. However, considering the market trend and the products excellent condition, Id like to make another counteroffer. Im willing to pay premium for verified genuine piece, but need to stay within my budget. ### BUYER PRICE($10150) ### This price takes into account the original MSRP, market reference price, and the value of the full documentation and service history. believe this is reasonable offer, considering the sellers rating and the products condition. Let me know if this is something youd be willing to consider. ### SELLER PRICE($10450) ### Thank you for your latest counteroffer. appreciate your willingness to pay premium for verified genuine piece. Considering the market trend and the products excellent condition, Im willing to meet you halfway again. This price takes into account the original MSRP, market reference price, and the value of the full documentation and service history. Im confident this price is reasonable, considering the products condition and the market trend. Let me know if this is something youd be willing to consider. Negotiation timed out after 20 rounds without reaching agreement."
        }
    ],
    "affiliations": [
        "UC Berkeley"
    ]
}