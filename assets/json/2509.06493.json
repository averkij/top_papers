{
    "paper_title": "Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers",
    "authors": [
        "Ran Xin",
        "Zeyu Zheng",
        "Yanchen Nie",
        "Kun Yuan",
        "Xia Xiao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \\texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \\texttt{BFS-Prover-V2} achieves 95.08\\% and 41.4\\% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search."
        },
        {
            "title": "Start",
            "content": "Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers Ran Xin1,,, Zeyu Zheng2,,, Yanchen Nie3,,, Kun Yuan3, Xia Xiao1, 1ByteDance Seed, 2Carnegie Mellon University, 3Peking University Equal contribution, Work done at ByteDance Seed, Corresponding authors"
        },
        {
            "title": "Abstract",
            "content": "The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces BFS-Prover-V2, system designed to address this dual scaling problem. We present two primary innovations. The first is novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs general reasoning model as high-level planner to iteratively decompose complex theorems into sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling team of parallel prover agents to collaborate efficiently by leveraging shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. BFS-Prover-V2 achieves 95.08% and 41.4% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search. Date: September 9, 2025 Correspondence: {ran.xin, x.xiaxiao}@bytedance.com 5 2 0 2 8 ] . [ 1 3 9 4 6 0 . 9 0 5 2 : r"
        },
        {
            "title": "Introduction",
            "content": "Automated Theorem Proving (ATP), subfield of mathematical logic and automated reasoning, represents one of the foundational ambitions of computer science [3]. The contemporary landscape of formal mathematics is increasingly dominated by interactive theorem provers (ITPs) or proof assistants. These systems, such as Coq, Isabelle, and Lean, require human user to guide the proof process, but they automate significant deductive tasks and, most importantly, provide machine-checkable guarantee of correctness [8]. Among these, the Lean4 programming language [19] has emerged as particularly vibrant ecosystem. key factor in its success is Mathlib [4], vast and comprehensive, community-driven library of formalized mathematics. Spanning over million lines of code, mathlib covers extensive areas of algebra, analysis, topology, and more, providing rich foundation for both advanced mathematical research and the development of verified systems. 1 The rise of Lean4 has coincided with the explosion in the capabilities of LLMs [7, 20, 24], opening new frontier in neuro-symbolic AI systems. The goal here is to integrate the intuitive yet powerful generation and search capabilities of LLMs with the absolute logical verification of formal systems. This research direction centers on key feedback loop: an LLM proposes intuitive proof steps, the Lean compiler provides rigorous verification, and RL [28] uses that verification to continuously improve the LLMs reasoning abilities [10, 12, 21, 34, 38]."
        },
        {
            "title": "1.1 A Duality of Scaling Challenges in LLM Provers and Reasoning Agents",
            "content": "The development of high-performance LLM-based provers, or any other reasoning agents, is contingent upon solving two fundamental and deeply interconnected scaling challenges. Training-time scaling. This refers to the techniques required to continuously enhance models foundational capabilities and tactical intuitions via training. common and significant obstacle in applying RL to LLMs is the phenomenon of performance plateaus: after an initial phase of rapid improvement, models often stagnate, with their capabilities ceasing to grow despite continued training [9, 18, 24, 29, 34, 35, 41, 42]. Overcoming this limitation requires carefully designed algorithms that can sustain learning over extended periods, enabling the model to transition from mastering simple problems to tackling increasingly complex theorems. Inference-time scaling. This addresses the application of trained model to solve novel theorems. Real-world mathematical problems often require deep, multi-step reasoning, the formulation of intermediate lemmas, and the exploration of an exponentially large search space of possible tactics. powerful base model, while necessary, is not sufficient. Without an effective search strategy, even competent model will be overwhelmed by the combinatorial search complexity. The challenge, therefore, is to design an inference architecture that can efficiently decompose complex problems into simpler parts, and strategically allocate computational resources to the most promising avenues of exploration [2, 5, 6, 11, 43]."
        },
        {
            "title": "1.2 Our Contributions\nThis paper presents BFS-Prover-V2, a comprehensive training and inference system for neural theorem\nproving in Lean4 that introduces novel solutions to the above scaling challenges. The primary contributions\nof this work are as follows:",
            "content": "Novel RL Scaling Techniques at Training: We develop distillation-free multi-stage expert-iteration framework [1, 26], form of off-policy RL, tailored for the domain of formal theorem proving. To sustain learning and overcome performance plateaus, we introduce suite of specialized techniques within the RL pipeline. These include an adaptive, perplexity-based data filtering strategy at the tactic level, which creates an automated curriculum for the agent, and periodic retraining mechanism that acts as soft reset to escape local optima in the model parameter space and increase model scaling potential. Planner-Enhanced Multi-Agent Tree Search System at Inference: For inference-time scaling, we introduce hierarchical reasoning architecture. general-purpose reasoning model, termed the Planner, iteratively decomposes complex theorems/goals into sequence of more manageable subgoals. These subgoals are then tackled by group of parallel prover agents that share common subgoal cache, dramatically decreasing search complexity of the system and enabling it to solve problems that are intractable for monolithic prover. State-of-the-Art Empirical Results: We validate the effectiveness of our dual scaling approach on established benchmarks. In particular, BFS-Prover-V2 achieves 95.08% and 41.4% on the MiniF2F and ProofNet test sets respectively, which largely outperforms previous LLM step-provers [32, 36] and is comparable with state-of-the-art whole proof generation models [17, 23, 30]."
        },
        {
            "title": "2 The BFS-Prover-V2 System",
            "content": "This section details the two core components of BFS-Prover-V2: (i) training pipeline, grounded in Markov Decision Process (MDP) [22] and scaled via adaptive filtering and periodic retraining; and (ii) an inference engine, which uses planner-enhanced multi-agent search for hierarchical reasoning. These components build upon the foundation of BFS-Prover-V1 [36] to specifically address the dual challenges of scaling at both 2 training and inference time. We provide visual overviews of these components in Fig. 1 and 4, with practical implementation parameters detailed in Section 3."
        },
        {
            "title": "2.1 A Step-Level Formulation: Theorem Proving as a Markov Decision Process",
            "content": "We formulate proof search in Lean4 tactic mode as multi-turn interaction between an agent and an environment, modeled as MDP. In this formulation, the LLM prover acts as the agent, and the Lean compiler, with its current tactic state, serves as the environment. This approach captures the sequential, stateful nature of constructing formal proof one step at time [19, 39]. The components of our MDP are defined as follows: State (S): state is the current tactic state as given by the Lean compiler. This includes the hypotheses, i.e., known facts, and the target goals to be proven. Action (A): The LLM acts as the policy of the MDP, taking the current state as input to generate tactic string, which is the action A. tactic is command that instructs the Lean compiler to perform deductive step, such as applying theorem, rewriting an expression, or breaking the goal into cases. Transition (P (S S, A)): The transition function is deterministically executed by the Lean compiler itself. When the agent submits tactic (action A) in given state S, the compiler attempts to apply it. If the tactic is valid and applicable, the compiler transitions to new state S. If the tactic is invalid or fails, the compiler returns an error message. Reward (R): reward of +1 is given for every state-action pair (S, A) that lies on successful proof path. All other (S, A) pairs that do not contribute to final proof receive reward of 0. This step-level, interactive formulation stands in sharp contrast to whole proof generation models [17, 23, 30], which treat theorem proving as one-shot, code generation task from theorem statement to full proof script. While simpler, the existing whole-proof approaches lack the ability to react to the intermediate states of proof and cannot be easily integrated into the interactive workflow of human mathematician [27, 31]. Our MDP-based approach, by design, trains an agent that functions as genuine Lean copilot, suggesting the next logical tactic at any point in the proof process [39]."
        },
        {
            "title": "2.2 Expert Iteration with Best-First Tree Search\nThe core training loop of BFS-Prover-V2 is an expert iteration pipeline, which may be viewed as a variant of\nthe AlphaZero algorithm [1, 26]. This approach enables the system to learn and improve its theorem-proving\ncapabilities from its own experience [25]. The process, illustrated in the inner loop of Fig. 1, includes two\nmajor alternating phases: proof generation and model refinement.",
            "content": "Phase 1: Proof Generation: In this phase, the current best version of the LLM prover, referred to as the expert, is tasked with solving large corpus of mathematical problems. For this work, we automatically formalized approximately 3 million problems [4, 13, 16, 33, 36, 40] to serve as the training ground. The expert model is coupled with the best-first tree search (BFS) algorithm used in BFS-Prover-V1 [36] to explore the vast space of possible proof paths. This combination of neural policy and systematic search allows the system to find proofs for problems that would be intractable for the model alone. Each successful proof found during this phase constitutes trajectory of (state, tactic) pairs. Across single round of expert iteration, the system performs approximately 107 tree searches, generating massive synthetic dataset. Phase 2: Model Refinement: The experience data generated in the first phase is then used to improve the LLM prover. In particular, the state-tactic pairs from the successful proof trajectories are used to update the models parameters. The updated model then becomes the new expert for the next round of iteration."
        },
        {
            "title": "2.3 Scaling up training: multi-stage expert iteration",
            "content": "A central challenge in scaling the expert iteration pipeline or RL in general is managing the vast quantity and variable quality of the self-generated data. Naively training on every successful tactic discovered during proof generation quickly leads to diminishing returns, performance stagnation, and mode collapse [18, 28, 36]. To sustain improvement over many iterations, we introduce two key algorithmic innovations: dynamic, 3 fine-grained data filtering strategy and periodic full-model retraining process. These techniques work in concert to form sophisticated, automated curriculum that continuously improves the agent capability in long horizon. The overall architecture of this pipeline is illustrated in Fig. 1, and we detail each of these innovations in the following subsections. Figure 1 Overview of the training-time scaling up architecture. The process begins with current expert model. The system then evaluates the models performance to check for plateau, which determines the subsequent path. If performance is improving, the model enters an inner expert iteration loop that involves generating new proofs, applying Adaptive Tactic Filtering, and refining the model. Conversely, if performance has plateaued, the system triggers the outer retraining loop, which consists of Data Re-synthesis, Aggressive Data Curation, and retraining the model from base checkpoint. Upon completion, this retraining loop yields new, improved expert model, which then serves as the starting point for the next cycle of evaluation and iteration."
        },
        {
            "title": "2.3.1 Adaptive Tactic Filtering: Learning from the ‘‘Just Right’’ Data",
            "content": "Instead of relying on coarse, problem-level filtering [29, 41], which often uses static metrics of difficulty, we adopt more dynamic and fine-grained approach at the tactic level. This strategy is guided by the empirical observation that the perplexity (negative log-probability) of tactics generated by the LLM follows roughly Gaussian distribution. The distribution, shown in Fig. 2, can be divided into three distinct regions, each with different implications for learning: The Low-Perplexity Tail: This region corresponds to tactics for which the model has very high confidence. These are typically simple, obvious steps, such as basic simplification or applying clear-cut hypothesis. Including these examples in the training batch offers no new learning signal; it merely reinforces what the model already knows well and can contribute to overfitting and reduction in exploratory capacity. The High-Perplexity Tail: This region represents tactics that the model finds highly surprising. Our case studies reveal that these are often not instances of brilliant, non-obvious reasoning. Instead, they frequently correspond to noisy or suboptimal choices, such as using powerful, general-purpose tactic with many unnecessary parameters on simple problem where more direct tactic would suffice. These fancy operations can be detrimental to training, as they may teach the model to generate overly complex or irrelevant tactics, leading to hallucinations and degrading its core reasoning ability. The Central Distribution: This is the goldilocks zone. The tactics in this region are neither too easy nor too noisy. They represent steps that are challenging for the model but still within its graspits zone of proximal development. By selectively training only on the data from this central part of the distribution, we ensure that the model is constantly learning at the edge of its capabilities. This adaptive filtering mechanism functions as fully automated and continuous form of curriculum learning. It does not rely on any external or predefined metric of difficulty. Instead, it uses the models own uncertainty Figure 2 Tactic-Level Data Filtering Based on the Perplexity Distribution. This histogram shows the probability distribution of tactic perplexity (represented as negative log-probability) from single round of expert iteration. We filter out the lowand high-perplexity tails, shown in red. The low-perplexity tail represents overly simple tactics the model is already confident in, while the high-perplexity tail often consists of noisy or unnecessarily complex tactics. By training only on the central part of the distribution (blue), we focus the models learning on challenging yet meaningful examples, which prevents overfitting and encourages smoother, more stable improvement in reasoning capabilities. (as measured by perplexity) as live, dynamic signal of what constitutes valuable training data at its current stage of development. This ensures smooth and stable evolution of the models internal policy distribution throughout the lengthy RL process, enabling sustained growth in performance."
        },
        {
            "title": "2.3.2 Periodic Retraining: A ‘‘Soft Reset’’ to Escape Local Optima",
            "content": "Even with adaptive filtering, after number of expert iteration updates, the models performance can still begin to plateau. This occurs because the models proof-finding style becomes entrenched. It develops strong biases towards certain types of tactics and proof strategies, effectively getting trapped in local optimum in the vast space of possible reasoning policies. It becomes very good at solving problems in particular ways, but loses the ability to discover novel approaches required for new and harder classes of problems. To escape local optima and reinvigorate the learning process, we introduce periodic soft reset procedure. This constitutes multi-stage expert-iteration process designed to increase the models entropy and reset its exploratory potential without losing the competence it has already gained. The procedure is as follows: 1. Re-synthesis and De-noise: The current best-performing prover is used to re-solve the entire corpus of problems it has encountered in all past iterations. Because the prover is now significantly more capable than it was in earlier rounds, it often finds proofs that are shorter, more direct, and more elegant. This step effectively uses the expert model to de-noise and improve upon its own past work, filtering out the redundant or circuitous steps that were present in the initial, less-informed proofs. 2. Aggressive Data Curation: The new, higher-quality proofs generated in the data re-synthesis phase are then subjected to an aggressive version of the tactic-level perplexity filtering described above. much larger portion of the data is discarded, retaining only the most crucial and informative tactic steps. 3. Retrain from base Checkpoint: The existing training data is completely replaced by this new, highly curated, and compact dataset. fresh model instance is then initialized from general pre-trained checkpoint and trained from scratch on this refined data. The resulting model, as illustrated in Fig. 3, initially exhibits temporary drop in performance on the benchmark. This is expected, as it has been trained on smaller, more focused dataset and has forgotten some of its previous stylistic biases. However, this new model possesses significantly higher exploratory potential. When it is reintroduced into the expert iteration loop, its increased capacity for exploration allows it 5 Figure 3 Sustained Performance Improvement through Expert Iteration and Periodic Retraining. This graph plots the provers performance on the MiniF2F benchmark against the number of expert iteration rounds. Performance steadily increases (blue circles) but eventually begins to plateau as the model settles into local optimum. To counteract this, we periodically conduct \"soft reset\" (red squares). This involves using the current expert model to re-solve all past problems to generate cleaner, more efficient dataset, which is then used to retrain the model from base checkpoint. This procedure allows the model to break out of its local optimum and continue improving, as evidenced by the significant performance jumps following each retraining phase. model scale-up to 32 billion parameters is also shown (green diamond). to discover novel proof strategies that were inaccessible to the previous, over-specialized model. Consequently, its performance rapidly recovers and then surpasses the previous peak, establishing new, higher performance ceiling. This periodic retraining, marked by the retrain events in Fig. 3, is critical mechanism for ensuring long-term, monotonic improvement across dozens of training rounds."
        },
        {
            "title": "2.4 Scaling up Inference: Planner-Enhanced Multi-Agent Search",
            "content": "While the reinforcement learning pipeline scales the LLMs intrinsic competence, solving genuinely difficult mathematical theorems requires sophisticated inference-time strategy to manage the immense search space. Many complex proofs in mathematics are not found through linear sequence of simple deductions but rather through hierarchical process of identifying and proving crucial intermediate results, or lemmas."
        },
        {
            "title": "2.4.1 Planner-Prover Paradigm for Hierarchical Reasoning",
            "content": "We introduce hierarchical inference architecture, shown in Fig. 4, that divides the labor of theorem proving between two distinct LLM agents: high-level planner and low-level prover. Planner: This is general-purpose reasoning LLM tasked with strategic decomposition. Given the current theorem statement and proof progress, its role is not to generate specific tactic but to propose high-level plan that includes series of intermediate subgoals. These subgoals are lemmas that, if proven, would simplify the main proof. By formulating these subgoals, the Planner effectively transforms single, monolithic, and potentially intractable search problem into structured sequence of smaller, more manageable ones. This decomposition substantially reduces the dimensionality of the search space that the Prover must explore. Prover: This is the specialized LLM tactic generator trained via our multi-stage expert iteration pipeline described in Section 2.3. It receives one subgoal at time from the Planner and uses its learned policy, in conjunction with BFS [36], to find formal proof for that specific subgoal. 6 Figure 4 Overview of the planner-enhanced multi-agent tree search architecture. The Planner agent decomposes the main theorem into sequence of simpler subgoals, which are managed in Shared Subgoal Cache and solved in parallel by multiple Prover agents. Successfully proven subgoals augment the main proofs context, while failures can trigger Dynamic Replanning loop. The inset provides toy example, demonstrating how proving intermediate lemmas (h1, h2, h3) facilitates the proof of the final goal. This division of labor mirrors the cognitive workflow of human mathematician, who might first sketch out the high-level structure of proof by identifying key lemmas (the Planners role) and then proceed to fill in the detailed, step-by-step deductions for each lemma (the Provers role). This hierarchical structure is powerful architectural pattern for tackling complex reasoning tasks."
        },
        {
            "title": "2.4.2 Operational Mechanics of Planner-Guided Search",
            "content": "As shown in Fig. 4, the interaction between the Planner and the Prover system unfolds in dynamic loop, allowing the plan to be revised based on the progress of the proof: 1. Initial Planning: At the start of proof attempt, the Planner is queried with the main theorem statement and its initial state. It returns list of proposed subgoals, formatted as Lean have statements. 2. Sequential Proof of Subgoals: The Prover system addresses the subgoals one by one. It takes the first subgoal in the queue and initiates tree search to find its proof. 3. Context Augmentation: Once subgoal is successfully proven, its statement is implanted into the main theorems context. From that point on, the proven subgoal is treated as known fact, equivalent to hypothesis, which can be used in the proofs of all subsequent subgoals and the main theorem itself. 4. Dynamic Replanning: If the Prover system fails to find proof for subgoal within given computational budget (i.e., it gets stuck), the process does not terminate. Instead, the Planner is re-queried. This time, however, the input to the Planner now includes all subgoals that were successfully proven before the system got stuck, in addition to the original theorem statement. Taking this new context into account, the Planner generates revised plan that refines the original proof strategy, often by decomposing the stuck subgoal into more granular sequence of intermediate steps. This dynamic and iterative loop between planning and proving makes the BFS-Prover-V2 system resilient to getting stuck, effectively scaling its inference-time capabilities to tackle complex theorems that would be intractable for monolithic tree search."
        },
        {
            "title": "2.4.3 Multi-Agent Collaboration via Focused Parallelism and Shared Subgoal Cache",
            "content": "To accelerate the proof search process and reduce wall-clock time, the Planner-Prover architecture is implemented within multi-agent framework. Instead of relying on single Prover agent, we deploy multiple parallel Prover instances that collaborate on the plan generated by the Planner. This collaboration is orchestrated by two key principles: strategy of focused parallelism and the use of shared subgoal cache. Focused parallelism: Rather than assigning different subgoals to different prover agents, our system concentrates the full computational power of all Prover instances on one subgoal at time. This approach is designed to overcome difficult reasoning bottlenecks that might be intractable for single agent working alone. Furthermore, this sequential method ensures computational efficiency by preventing agents from wasting resources on later subgoals that would be rendered invalid if an earlier step fails and triggers replan. Shared Subgoal Cache: This cache is the central communication and state-tracking mechanism, shared across all parallel Prover instances. It performs several critical functions: It stores the full sequence of subgoals generated by the Planner. It tracks the real-time status of each subgoal (e.g., Pending, Proving, Proven). It records the proof for any solved subgoal. This architecture creates cooperative sprint for each lemma in the plan. When new subgoal is designated as the active target, all Prover agents begin their own independent tree searches for that single subgoal in parallel. As soon as the first agent finds valid proof, it writes the result to the shared cache. This action signals all other agents to terminate their search, preventing redundant computation. The entire group of agents then proceeds to the next subgoal in the sequence."
        },
        {
            "title": "3 Practical Implementation and Benchmark Results",
            "content": "We now present practical implementation of the BFS-Prover-V2 system and its benchmark results. Model and Data: The LLM prover agent is built upon the Qwen2.5-Math-7B and Qwen2.5-32B models [37], which serve as the base for our policy optimization. The multi-stage expert iteration process was initialized with the checkpoint from BFS-Prover-V1 [36]. To construct large-scale training corpus, we autoformalized the NuminaMath-CoT and NuminaMath-1.5 datasets [13] using carefully designed prompts applied to generalpurpose models, augmented with Lean4 compiler feedback. Combined with data provided by Goedel-Prover [16], this process produced approximately 3 million formal statements. Prompts used for autoformalization can be found in Section C.1. All experiments are conducted in Lean v4.10.0 with LeanDojo [39]. Training setup: We refine the policy LLM after each expert iteration round using one of two Supervised Fine-Tuning (SFT) strategies, chosen based on the outcome of the round. For rounds with manageable data yield, we perform continuous finetune from the current best checkpoint for single epoch, using conservative cosine learning rate decay from 5 106 and decaying to 1 107. more comprehensive retrain from the base model is triggered under two conditions: either if the round produces very large volume of new data, or if model performance has stagnated. In the case of performance plateau, this retraining is combined with an aggressive data curation step to create new, refined dataset designed to break the local; see Section 2.3. This retraining process is conducted for 3 epochs with higher learning rate decaying from 2 105 and decaying to 1 106. Both strategies utilize global batch size of 1024. Inference configuration: Our inference process combines low-level Prover with high-level Planner, as detailed in Section 2.4. The Prover agents utilize Best-First Search (BFS) algorithm, with an implementation that follows BFS-Prover-V1 [36], where we set the sampling temperature to 1.3, the expansion width to 3, and length normalization factor of 2.0. For the high-level strategic Planner, we employ Gemini2.5-pro, while other general-purpose reasoning models can achieve comparable performance if properly prompted. Prompts used for Planner can be found in Section C.2. Benchmark results: We evaluated BFS-Prover-V2 on two key benchmarks: MiniF2F, test of high-school competition math, and ProofNet, which challenges reasoning over large undergraduate-level library. Our 8 system sets new state of the art for LLM step-provers, achieving 95.08% on the MiniF2F test set (95.49% on validation) and 41.4% on the ProofNet test set. The near-saturation performance on MiniF2F validates our iterative RL pipelines ability to master problem distribution. More importantly, the strong ProofNet result demonstrates successful generalization from the systems training corpuswhich consists mainly of high-school competition problemsto the more complex, library-dependent undergraduate problems. See detailed comparison with other LLM provers in Table 1."
        },
        {
            "title": "4 Conclusion",
            "content": "The primary contributions of this work are the design, implementation, and empirical validation of holistic system for scaling LLM-based step-provers. On the training side, our multi-stage expert iteration pipeline can successfully overcome common performance plateaus and enable sustained improvement over an extended training period. On the inference side, we introduced Planner-Prover paradigm that performs subgoal decomposition. By using high-level Planner to generate subgoals, we enable the system to tackle complex, multi-step theorems that are intractable for monolithic approaches. The state-of-the-art results on the MiniF2F and ProofNet benchmarks provide strong evidence for the efficacy of this integrated approach. Prover Method Step-level provers budget miniF2F-test miniF2F-valid ProofNet-test InternLM2.5-StepProver-7B [32] 256 32 600 Hunyuan-Prover-7B [14] BFS-Prover-V1-7B [36] 600 8 400 2048 2 accumulative 65.9% 68.4% 70.8% 73.0% MPS-Prover-7B [15] 64 4 800 8 72.54% accumulative BFS-Prover-V2-7B (this work) accumulative BFS-Prover-V2-32B (this work) accumulative w/ Planner accumulative Whole-proof provers DeepSeek-Prover-V2-671B [23] Kimina-Prover-72B [30] 8192 1024 w/ TTRL search accumulative Goedel-Prover-32B [17] w/ Self-correction Delta-Prover [43] Seed-Prover [6] 8192 1024 accumulative accumulative 75.8% 82.4% 86.1% 95.1% 88.9% 87.7% 92.2% 92.2% 92.6% 95.9% 99.6% 69.6% 27% - - - - - - - - - - - - 85.5% 95.5% 41.4% - 90.6% 37.1% - - - - - - - - - - - - Table 1 Comparison between BFS-Prover-V2 and other leading theorem provers. denotes concurrent work."
        },
        {
            "title": "Acknowledgements",
            "content": "We would like to thank Kai Shen from ByteDance Seed for his insightful discussions throughout this project."
        },
        {
            "title": "References",
            "content": "[1] Thomas Anthony, Zheng Tian, and David Barber. Thinking fast and slow with deep learning and tree search. Advances in neural information processing systems, 30, 2017. [2] Kaito Baba, Chaoran Liu, Shuhei Kurita, and Akiyoshi Sannai. Prover agent: An agent-based framework for formal mathematical proofs. arXiv preprint arXiv:2506.19923, 2025. [3] Wolfgang Bibel, Steffen Hölldobler, and Gerd Neugebauer. Deduction: automated logic. Academic Press London, 1993. [4] Mark Blokpoel. mathlib: scala package for readable, verifiable and sustainable simulations of formal theory. Journal of Open Source Software, 9(99):6049, 2024. [5] Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, and Fan Yang. Reviving dsp for advanced theorem proving in the era of reasoning models. arXiv preprint arXiv:2506.11487, 2025. [6] Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, et al. Seed-prover: Deep and broad reasoning for automated theorem proving. arXiv preprint arXiv:2507.23726, 2025. [7] Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. [8] Herman Geuvers. Proof assistants: History, ideas and future. Sadhana, 34(1):325, 2009. [9] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [10] Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward Ayers, and Stanislas Polu. Proof artifact co-training for theorem proving with language models. arXiv preprint arXiv:2102.06203, 2021. [11] Albert Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. arXiv preprint arXiv:2210.12283, 2022. [12] Guillaume Lample, Timothée Lacroix, et al. Hypertree proof search for neural theorem proving. Advances in Neural Information Processing Systems, 35:2633726349, 2022. [13] Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Huang, Kashif Rasul, Longhui Yu, Albert Jiang, Ziju Shen, et al. Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions. Hugging Face repository, 13(9):9, 2024. [14] Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, and Haitao Mi. Hunyuanprover: scalable data synthesis framework and guided tree search for automated theorem proving. arXiv preprint arXiv:2412.20735, 2024. [15] Zhenwen Liang, Linfeng Song, Yang Li, Tao Yang, Feng Zhang, Haitao Mi, and Dong Yu. Mps-prover: Advancing stepwise theorem proving by multi-perspective search and data curation. arXiv preprint arXiv:2505.10962, 2025. [16] Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, et al. Goedel-prover: frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025. [17] Yong Lin, Shange Tang, Bohan Lyu, Ziran Yang, Jui-Hui Chung, Haoyu Zhao, Lai Jiang, Yihan Geng, Jiawei Ge, Jingruo Sun, et al. Goedel-prover-v2: Scaling formal theorem proving with scaffolded data synthesis and self-correction. arXiv preprint arXiv:2508.03613, 2025. [18] Mingjie Liu, Shizhe Diao, Ximing Lu, Jian Hu, Xin Dong, Yejin Choi, Jan Kautz, and Yi Dong. Prorl: Prolonged reinforcement learning expands reasoning boundaries in large language models. arXiv preprint arXiv:2505.24864, 2025. [19] Leonardo de Moura and Sebastian Ullrich. The lean 4 theorem prover and programming language. In International Conference on Automated Deduction (CADE), pages 625635. Springer, 2021. 10 [20] OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. [21] Stanislas Polu, Jesse Michael Han, Kunhao Zheng, et al. Formal mathematics statement curriculum learning. arXiv preprint arXiv:2202.01344, 2022. [22] Martin Puterman. Markov decision processes. Handbooks in operations research and management science, 2: 331434, 1990. [23] ZZ Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, et al. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition. arXiv preprint arXiv:2504.21801, 2025. [24] ByteDance Seed, Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, et al. Seed1. 5-thinking: Advancing superb reasoning models with reinforcement learning. arXiv preprint arXiv:2504.13914, 2025. [25] David Silver and Richard Sutton. Welcome to the era of experience. Google AI, 1, 2025. [26] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science, 362(6419):11401144, 2018. [27] Peiyang Song, Kaiyu Yang, and Anima Anandkumar. Towards large language models as copilots for theorem proving in lean. arXiv preprint arXiv:2404.12534, 2024. [28] Richard Sutton. Reinforcement learning: An introduction. Bradford Book, 2018. [29] Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599, 2025. [30] Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, et al. Kimina-prover preview: Towards large formal reasoning models with reinforcement learning. arXiv preprint arXiv:2504.11354, 2025. [31] Sean Welleck and Rahul Saha. Llmstep: Llm proofstep suggestions in lean. arXiv preprint arXiv:2310.18457, 2023. [32] Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Jiayu Wang, Dahua Lin, and Kai Chen. Internlm2. 5-stepprover: Advancing automated theorem proving via expert iteration on large-scale lean problems. arXiv preprint arXiv:2410.15700, 2024. [33] Zijian Wu, Jiayu Wang, Dahua Lin, and Kai Chen. Lean-github: Compiling github lean repositories for versatile lean prover. arXiv preprint arXiv:2407.17227, 2024. [34] Huajian Xin, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, and Xiaodan Liang. Deepseek-prover: Advancing theorem proving in llms through large-scale synthetic data. arXiv preprint arXiv:2405.14333, 2024. [35] Huajian Xin, ZZ Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, et al. Deepseek-prover-v1. 5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024. [36] Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, and Kai Shen. Bfsprover: Scalable best-first tree search for llm-based automatic theorem proving. arXiv preprint arXiv:2502.03438, 2025. [37] An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, et al. Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122, 2024. [38] Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, and Dawn Song. Formal mathematical reasoning: new frontier in ai. arXiv preprint arXiv:2412.16075, 2024. [39] Kaiyu Yang, Aidan Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, and Animashree Anandkumar. Leandojo: Theorem proving with retrieval-augmented language models. Advances in Neural Information Processing Systems, 36, 2024. 11 [40] Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, and Kai Chen. Lean workbook: large-scale lean problem set formalized from natural language math problems. arXiv preprint arXiv:2406.03847, 2024. [41] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, et al. Dapo: An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476, 2025. [42] Yu Yue, Yufeng Yuan, Qiying Yu, Xiaochen Zuo, Ruofei Zhu, Wenyuan Xu, Jiaze Chen, Chengyi Wang, TianTian Fan, Zhengyin Du, et al. Vapo: Efficient and reliable reinforcement learning for advanced reasoning tasks. arXiv preprint arXiv:2504.05118, 2025. [43] Yichi Zhou, Jianqiu Zhao, Yongxin Zhang, Bohan Wang, Siran Wang, Luoxin Chen, Jiahui Wang, Haowei Chen, Allan Jie, Xinbo Zhang, et al. Solving formal math problems by decomposition and iterative reflection. arXiv preprint arXiv:2507.15225, 2025."
        },
        {
            "title": "A Case Studies",
            "content": "A.1 Proof Conciseness and Tactic Proficiency primary advantage of our step-level proof approach over the whole-proof paradigm is dramatic reduction in proof length. This conciseness stems from the interactive, step-by-step nature of our method. By engaging with the Lean environment incrementally, our model captures and leverages fine-grained tactic state information. This iterative feedback loop significantly enhances its proficiency with powerful, high-level tactics such as simp, linarith, and nlinarith, enabling it to solve complex goals in single step rather than through lengthy, explicit derivations. To illustrate this contrast, we present comparative analysis of proofs for two problems, aime_1984_p7 and amc12_2000_p1, generated by BFS-Prover-V2 and DeepSeek-Prover-V2. aime_1984_p7 For the problem aime_1984_p7, BFS-Prover-V2 produces remarkably concise proof, with the final two linessimp and linaritheffectively replacing over 2000 lines of substitution and simplification steps found in numerous have blocks within DeepSeek-Prover-V2s proof. BFS-Prover-V2 (step-level proof): theorem aime_1984_p7 ( : Z) ( 0 : , 1000 = - 3) ( 1 : , < 1000 = ( ( + 5) ) ) : 84 = 997 := by inhabit set_option maxRecDepth 1997 in have := 1 84 ( by norm_num ) norm_cast at <; > simp [ 0 , 1 ] at * <; > linarith DeepSeek-Prover-V2 (whole-proof): theorem aime_1984_p7 ( : Z) ( 0 : , 1000 = - 3) ( 1 : , < 1000 = ( ( + 5) ) ) : 84 = 997 := by have 2 : 1004 = 1001 := by have 2 1 : 1004 = 1004 - 3 := by apply 0 <; > norm_num rw [ 2 1 ] <; > norm_num have 3 : 1003 = 1000 := by have 3 1 : 1003 = 1003 - 3 := by apply 0 <; > norm_num rw [ 3 1 ] <; > norm_num 13 have 4 : 1002 = 999 := by have 4 1 : 1002 = 1002 - 3 := by apply 0 <; > norm_num rw [ 4 1 ] <; > norm_num -- ... ( approximately 2000 lines of similar calculations omitted ) ... have 1 9 3 : 89 = 998 := by have 1 9 3 1 : 89 = ( (89 + 5) ) := by apply 1 <; > norm_num rw [ 1 9 3 1 ] have 1 9 3 2 : (89 + 5) = 94 := by norm_num rw [ 1 9 3 2 ] rw [ 1 9 2 ] <; > norm_num <; > linarith have 1 9 4 : 84 = 997 := by have 1 9 4 1 : 84 = ( (84 + 5) ) := by apply 1 <; > norm_num rw [ 1 9 4 1 ] have 1 9 4 2 : (84 + 5) = 89 := by norm_num rw [ 1 9 4 2 ] rw [ 1 9 3 ] <; > norm_num <; > linarith rw [ 1 9 4 ] <; > norm_num amc12_2000_p1 For the problem amc12_2000_p1, the final line of BFS-Prover-V2s proofa single nlinarith call effectively replaces an extensive enumeration process in the whole-proof approach. DeepSeek-Prover-V2s proof requires approximately 80 lines to check all possible values for the three unknowns i, m, and o, whereas our model solves the problem concisely. BFS-Prover-V2 (step-level proof): theorem amc12_2000_p1 ( : N) ( 0 : = = = ) ( 1 : * * = 2001) : + + 671 := by obtain hi , hm , 2 := 0 obtain _ _ _ := <; > obtain _ _ _ := <; > obtain _ _ _ := <; > try omega any_goals ring_nf at 1 ; nlinarith ; ring_nf at * <; > try omega nlinarith [ mul_nonneg ( by positivity : 0 ) ( by positivity : 0 ) , mul_nonneg ( by positivity : 0 ) ( by positivity : 0 ) , mul_nonneg ( by positivity : 0 ) ( by positivity : 0 ) ] DeepSeek-Prover-V2 (whole-proof): theorem amc12_2000_p1 ( : N) ( 0 : = = = ) ( 1 : * * = 2001) : + + 671 := by -- ... ( approximately 80 lines of properties related to unknowns , , and omitted ) ... have h_main : + + 671 := by have 8 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 8 1 : 2001 := 2 have 8 2 : 2001 := 5 have 8 3 : > 0 := h_pos_i have 8 4 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 8 5 : 2001 := 8 1 have 8 6 : 2001 := 8 2 interval_cases <; > norm_num at 8 5 <; > omega exact 8 4 have 9 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 9 1 : 2001 := 3 have 9 2 : 2001 := 6 have 9 3 : > 0 := h_pos_m have 9 4 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 9 5 : 2001 := 9 1 have 9 6 : 2001 := 9 2 interval_cases <; > norm_num at 9 5 <; > omega exact 9 have 1 0 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 1 0 1 : 2001 := 4 have 1 0 2 : 2001 := 7 have 1 0 3 : > 0 := h_pos_o have 1 0 4 : = 1 = 3 = 23 = 29 = 69 = 87 = 667 = 2001 := by have 1 0 5 : 2001 := 1 0 1 have 1 0 6 : 2001 := 1 0 2 interval_cases <; > norm_num at 1 0 5 <; > omega exact 1 0 4 rcases 8 with ( rfl rfl rfl rfl rfl rfl rfl rfl ) <; > rcases 9 with ( rfl rfl rfl rfl rfl rfl rfl rfl ) <; > rcases 1 0 with ( rfl rfl rfl rfl rfl rfl rfl rfl ) <; > norm_num [ mul_assoc , mul_comm , mul_left_comm ] at 1 0 <; > ( try omega ) <; > ( try { 15 norm_num at 0 <; > ( try omega ) <; > ( try { ring_nf at 1 <; > omega }) }) <; > ( try { norm_num at 0 <; > ( try omega ) <; > ( try { ring_nf at 1 <; > omega }) }) <; > ( try { norm_num at 0 <; > ( try omega ) <; > ( try { ring_nf at 1 <; > omega }) }) <; > ( try { norm_num at 0 <; > ( try omega ) <; > ( try { ring_nf at 1 <; > omega }) }) <; > ( try omega ) <; > ( try { ring_nf at 1 <; > omega }) exact h_main 16 A.2 Novel Proof Strategies significant advantage of our step-level proof approach is its ability to discover novel proof strategies that whole-proof or human-proof methods typically would not consider. By exploring the proof space incrementally, our system can identify non-obvious connections and construct solutions that are often more elegant and insightful. We illustrate this capability by examining the problems imo_1963_p5 and algebra_amgm_sum1toneqn_prod1tonleq1, each of which highlights distinct advantage of our approach. imo_1963_p5 For the problem imo_1963_p5, our model, DeepSeek-Prover-V2, and Compfiles dataset provide step-level proof, whole-proof, and human-proof versions, respectively. Notably, both whole-proof and human-proof approaches employ similar strategies: multiplying both sides of the equation by 2 sin(π/7), then applying sum-to-product trigonometric identities for simplification. In contrast, BFS-Prover-V2 develops an entirely different approach: first transforming the left side of the equation into polynomial in cos(π/7) using double and triple angle formulas, then proving that cos(π/7) satisfies the corresponding polynomial equation. BFS-Prover-V2 (step-level proof): theorem imo_1963_p5 : Real . cos (π / 7) - Real . cos (2 * π / 7) + Real . cos (3 * π / 7) = 1 / 2 := by have : Real . pi / 7 = Real . pi / 7 * 1 := by ring have : 3 * Real . pi / 7 = Real . pi - 4 * Real . pi / 7 := by ring rw [h , cos_sub ] <; > norm_num have h2 := cos_two_mul ( Real . pi / 7) have h3 := cos_three_mul (π / 7) rw [ show 4 * Real . pi / 7 = Real . pi - 3 * Real . pi / 7 by ring , cos_sub ] simp [ h2 , h3 , cos_two_mul , sin_pi , cos_pi ] ring_nf at h2 h3 norm_num [ h2 , h3 , cos_pi_div_two ] ring_nf <; > have h4 := cos_pi <; > simp [ h4 ] ring_nf at * <; > norm_num rw [ sub_eq_zero ] nth_rewrite 1 [ sub_eq_zero ] ring_nf apply eq_of_sub_e q_zero let := cos ( Real . pi * (1 / 7) ) have := cos_three_mul ( Real . pi * (1 / 7) ) ring_nf at * apply eq_of_sub_e q_zero clear this h3 h2 apply eq_of_sub_e q_zero have := cos_three_mul ( Real . pi * (1 / 7) ) field_simp [ mul_assoc ] at * on_goal 1 = > ring replace : Real . pi * (1 / 7 : R) = Real . pi / 7 := by ring try rw [ this ]; norm_num have h5 := cos_three_mul ( Real . pi / 7) have : 3 * ( Real . pi / 7) = Real . pi - 4 * ( Real . pi / 7) := by ring simp [ this , cos_pi ] at h5 let := cos ( Real . pi / 7) 17 rcases lt_trichotomy 0 with hz hz hz any_goals simp_all [ show cos (4 * ( Real . pi / 7) ) = cos (2 * (2 * ( Real . pi / 7) ) ) by ring , cos_two_mul ] any_goals nlinarith [ cos_sq_ad d_sin_sq ( Real . pi / 7) , Real . sin_pi_div_two_sub , pow_two_nonneg ( cos ( Real . pi / 7) - 1) , pow_two_nonneg ( cos ( Real . pi / 7) + 1) ] contrapose hz refine not_lt .2 ? _ apply co _n on ne g_ of _ me m_ Icc <; > constructor <; > linarith [ pi_pos ] DeepSeek-Prover-V2 (whole-proof): theorem imo_1963_p5 : Real . cos ( Real . pi / 7) - Real . cos (2 * Real . pi / 7) + Real . cos (3 * Real . pi / 7) = 1 / 2 := by have h1 : 2 * Real . sin ( Real . pi / 7) * ( Real . cos ( Real . pi / 7) - Real . cos (2 * Real . pi / 7) + Real . cos (3 * Real . pi / 7) ) = Real . sin ( Real . pi / 7) := by have h1 1 : 2 * Real . sin ( Real . pi / 7) * Real . cos ( Real . pi / 7) = Real . sin (2 * Real . pi / 7) := by have h1 1 1 : Real . sin (2 * Real . pi / 7) = 2 * Real . sin ( Real . pi / 7) * Real . cos ( Real . pi / 7) := by have h1 1 2 : Real . sin (2 * Real . pi / 7) = Real . sin (2 * ( Real . pi / 7) ) := by ring rw [ h1 1 2 ] have h1 1 3 : Real . sin (2 * ( Real . pi / 7) ) = 2 * Real . sin ( Real . pi / 7) * Real . cos ( Real . pi / 7) := by rw [ Real . sin_two_mul ] <; > ring rw [ h1 1 3 ] <; > ring linarith have h1 2 : 2 * Real . sin ( Real . pi / 7) * Real . cos (2 * Real . pi / 7) = Real . sin (3 * Real . pi / 7) - Real . sin ( Real . pi / 7) := by -- ... ( approximately 20 lines of calculations omitted ) ... have h1 3 : 2 * Real . sin ( Real . pi / 7) * Real . cos (3 * Real . pi / 7) = Real . sin (4 * Real . pi / 7) - Real . sin (2 * Real . pi / 7) := by -- ... ( approximately 20 lines of similar calculations omitted ) ... have h1 4 : Real . sin (4 * Real . pi / 7) = Real . sin (3 * Real . pi / 7) := by -- ... ( approximately 20 lines of similar calculations omitted ) ... have h2 : Real . sin ( Real . pi / 7) > 0 := by apply Real . n_ s_ _ po _o f_ lt _ pi linarith [ Real . pi_pos , Real . pi_gt_three ] linarith [ Real . pi_pos , Real . pi_gt_three ] have h3 : Real . cos ( Real . pi / 7) - Real . cos (2 * Real . pi / 7) + Real . cos (3 * Real . pi / 7) = 1 / 2 := by have h3 1 : 2 * Real . sin ( Real . pi / 7) > 0 := by linarith have h3 2 : Real . cos ( Real . pi / 7) - Real . cos (2 * Real . pi / 7) + Real . cos (3 * Real . pi / 7) = 1 / 2 := by apply mul_left_cancel 0 ( show (2 * Real . sin ( Real . pi / 7) : R) = 0 by 18 linarith ) nlinarith [ Real . sin_le_one ( Real . pi / 7) , Real . sin_le_one (2 * Real . pi / 7) , Real . sin_le_one (3 * Real . pi / 7) , Real . sin_le_one (4 * Real . pi / 7) , Real . sin_le_one ( Real . pi / 7) ] exact h3 2 apply h3 Compfiles dataset (human-proof): theorem imo1963_p5 : Real . cos (π /7) - Real . cos (2*π /7) + Real . cos (3*π /7) = 1/2 := by rw [ show (2*π /7) = π - (5*π /7) by linarith ] rw [ Real . cos_pi_sub ] simp only [ sub_neg_eq_add ] have : 2 * Real . sin (π / 7) = 0 := by simp only [ ne_eq , mul_eq_zero , OfNat . ofNat_ne_zero , false_or ] apply ne_of_gt apply Real . n_ s_ _ po _o f_ lt _ pi simp only [ Nat . ofNat_pos , div_pos_iff_of_pos_right , Real . pi_pos ] trans 1 rw [ div_lt_one ( by linarith only ) ] linarith only [ Real . pi_le_four ] linarith only [ Real . pi_gt_three ] apply ( mul_right_inj ' ) . mp rw [ left_distrib , left_distrib ] have prod_sum : ( : R) , 2 * Real . sin * Real . cos = Real . sin ( + ) - Real . sin ( - ) := by intro rw [ Real . sin_add , Real . sin_sub ] linarith only rw [ prod_sum , prod_sum , prod_sum ] = 2 * π / 7 by linarith only ] rw [ show (π / 7 + π / 7) rw [ show (π / 7 - π / 7) by linarith only ] = 0 rw [ show (π / 7 + 5 * π / 7) = 6 * π / 7 by linarith only ] rw [ show (5 * π / 7 - π / 7) = 4 * π / 7 by linarith only ] rw [ show (π / 7 + 3 * π / 7) = 4 * π / 7 by linarith only ] rw [ show (3 * π / 7 - π / 7) = 2 * π / 7 by linarith only ] rw [ Real . sin_zero ] ring_nf rw [ Real . sin_pi_sub ] rw [ show (π - π * (6 / 7) ) = π / 7 by linarith ] congr linarith algebra_amgm_sum1toneqn_prod1tonleq For the problem algebra_amgm_sum1toneqn_prod1tonleq1, BFS-Prover-V2 and DeepSeek-Prover-V2 provide the step-level proof and whole-proof versions, respectively. The whole-proof model adopts it proceeds by manually handling cases (n = 0, some ai = 0, standard, first-principles approach: all ai > 0), and then takes the logarithm of the product and then applies the well-known inequality ln(x) 1 to each term, resulting in verbose proof. In contrast, BFS-Prover-V2 recognizes the 19 problem as special case of the Arithmetic Mean-Geometric Mean (AM-GM) inequality. It directly invokes the corresponding theorem from Mathlib, Real.geom_mean_le_arith_mean, demonstrating an ability to leverage high-level library theorems for more insightful and efficient proof. BFS-Prover-V2 (step-level proof): theorem e _ m _ 1 e _ d 1 l 1 ( : NNReal ) ( : N) ( 0 : (cid:80) in Finset . range , = ) : (cid:81) in Finset . range , 1 := by have := 0 revert 0 intro amgm let := Finset . range by_cases h1 : = 0 simp [ h1 ] have hn let µ := ( fun ( : N) = > ( : R) ) let : := fun _ = > 1 have w_nonneg : , 0 simp [w , zero_le_one ] have w_pos all_goals aesop ( add simp ) have w_nonneg : , 0 any_goals simp [ ] have w_pos simp [ ] have amgm_real : 0 < (cid:81) , : 0 < := by omega : 0 < (cid:81) in Finset . range , : ((cid:81) , µ ^ ( : R) ) ^ (((cid:80) , ( : R) ) 1 ) ((cid:80) , ( * µ : R) ) / ((cid:80) , ( : R) ) apply Real . m _m _l _ ri th _m an exact w_nonneg simp [w , , hn ] field_simp [µ] simp [µ, , ] at amgm_real norm_cast at amgm_real simp [ amgm ] at amgm_real by_cases : (cid:81) a_1 Finset . range , a_1 = 0 simp [ ] simp [ NNReal . coe_le_coe , amgm ] at amgm_real rw apply le_of_not_lt all_goals aesop ( add simp NNReal ) rw [NNReal . coe_one ] at amgm_real norm_cast at amgm_real contrapose ! amgm_real erw [ Real . one_lt_rpow_iff ] left all_goals aesop ( add simp [ Finset . range ]) [ div_self ] at amgm_real DeepSeek-Prover-V2 (whole-proof): theorem e _ m _ 1 e _ d 1 l 1 ( : NNReal ) ( : N) ( 0 : ((cid:80) in Finset . range , ) = ) : ((cid:81) in Finset . range , ) 1 := by 20 have 1 : ((cid:81) in Finset . range , ( : R) ) 1 := by have 2 : ((cid:80) in Finset . range , ( : R) ) = := by exact_mod_cast 0 by_cases 3 : = 0 simp [ 3 ] have 4 : 0 < := Nat . pos_of_ne_zero 3 by_cases 5 : , Finset . range ( : R) = 0 obtain , hi , 6 := 5 have 7 : ((cid:81) in Finset . range , ( : R) ) = 0 := by have 8 : Finset . range := hi have 9 : ( : R) = 0 := 6 have 1 0 : ((cid:81) in Finset . range , ( : R) ) = 0 := by calc ((cid:81) in Finset . range , ( : R) ) = (cid:81) in Finset . range , ( : R) := rfl _ = 0 := by apply Finset . prod_eq_zero 8 simp [ 9 ] exact 1 0 linarith have 5 ' : , Finset . range ( : R) > 0 := by intro hi have 6 : , Finset . range ( : R) = 0 := 5 have 7 : ( : R) = 0 := by intro have 8 : , Finset . range ( : R) = 0 := , hi , by simp_all contradiction have 8 : ( : R) > 0 := by have 9 : ( : R) 0 := by exact_mod_cast ( ) . prop contrapose ! 7 linarith exact 8 have 6 : ((cid:81) in Finset . range , ( : R) ) 1 := by have 7 : (cid:80) in Finset . range , Real . log (( : R) ) 0 := by have 8 : (cid:80) in Finset . range , Real . log (( : R) ) (cid:80) in Finset . range , (( : R) - 1) := by apply Finset . sum_le_sum intro hi have 9 : ( : R) > 0 := 5 ' hi have 1 0 : Real . log (( : R) ) ( : R) - 1 := by have 1 1 : Real . log (( : R) ) ( : R) - 1 := by linarith [ Real . og _ le_ su b_one _of_po 9 ] exact 1 1 exact 1 0 -- ... ( approximately 40 lines of calculations omitted ) ... have 2 : ((cid:81) in Finset . range , ) 1 := by have 3 : ((cid:81) in Finset . range , : R) 1 := by exact 1 have 4 : ((cid:81) in Finset . range , : R) = ((cid:81) in Finset . range , : R) := rfl have 5 : ((cid:81) in Finset . range , : R) = ((cid:81) in Finset . range , ( : R) ) := by simp have 6 : ((cid:81) in Finset . range , : R) 1 := by simpa [ 5 ] using 1 have 7 : ((cid:81) in Finset . range , : NNReal ) 1 := by 21 norm_cast at 6 <; > simp_all [ Finset . prod_range_succ ] <; > norm_num <; > linarith simpa using 7 exact 2 Despite the advantages of step-level proof in significantly reducing proof length and discovering novel proof strategies, step-level proof has one notable limitation: poor readability. The interactive nature of step-level proof generation, with its incremental tactic applications and state updates, often results in proofs that are more challenging for humans to follow and understand compared to the more structured and explanatory whole-proof or human-proof approaches. This trade-off between conciseness and readability represents crucial consideration when evaluating the practical utility of different proof generation paradigms. Illustration of Planner-Prover Paradigm with an IMO Problem To demonstrate the effectiveness of our Planner-Prover paradigm, we present an analysis of the solution process for challenging IMO problem: imo_1969_p2. In the following proof, the statements h_coeffs_polar, h_y_rewritten_with_polar, and h_y_collapsed_to_single_cos represent the dynamic replanning phase, while all other have statements belong to the initial planning phase. Unlike in conventional whole-proof methods, have statements in our framework are presented without the := by clause. This example highlights the crucial role of dynamic replanning in our system. Without dynamic replanning, the prover gets stuck at h_y_is_sinusoid, failing to complete the proof even after 7,200 attempts. With dynamic replanning, however, the system successfully completes the proof in just 800 attempts. The dynamic replanning process breaks down complex steps into smaller, more manageable subgoals, enabling the prover to navigate past critical bottlenecks. imo_1969_p2 - Part 1 theorem imo_1969_p2 ( : R) ( : N) ( : R) ( : R) ( 0 : 0 < ) ( 1 : , = (cid:80) in Finset . range , (( Real . cos ( + ) ) / (2^ ) ) ) ( 2 : = 0) ( 3 : = 0) : : Z, - = * Real . pi := by have h_cos_add : , Real . cos ( + ) = Real . cos ( ) * Real . cos - Real . sin ( ) * Real . sin simp [ cos_add , add_right_inj ] have h_y_sum_expanded : ( : R) , = (cid:80) in ( Finset . range : Finset N) , ( Real . cos ( ) * Real . cos - Real . sin ( ) * Real . sin ) / ((2 : N) ^ : R) simp [ 1 , h_cos_add ] have h_y_sum_split : ( : R) , = ((cid:80) in ( Finset . range : Finset N) , Real . cos ( ) * Real . cos / ((2 : N) ^ : R) ) - ((cid:80) in ( Finset . range : Finset N) , Real . sin ( ) * Real . sin / ((2 : N) ^ : R) ) intro <; > simp_rw [ h_y_sum_expanded ] simp [ sub_div , Finset . sum_sub_distrib ] have h_y_expand : ( : R) , = ((cid:80) in ( Finset . range : Finset N) , Real . cos ( ) / ((2 : N) ^ : R) ) * Real . cos - ((cid:80) in ( Finset . range : Finset N) , Real . sin ( ) / ((2 : N) ^ : R) ) * Real . sin intro x_exp simp only [ Finset . sum_mul , h_y_sum_split ] congr <; > symm <; > field_simp <; > ring have h_k_ge_one : 1 apply Nat . succ_le_of_lt <; > exact 0 have h_complex_repr : ( (cid:80) in ( Finset . range : Finset N) , Real . cos ( ) / ((2 : N) ^ : R) , (cid:80) in ( Finset . range : Finset N) , Real . sin ( ) / ((2 : N) ^ : R) : C) = (cid:80) in ( Finset . range : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) simp [ Complex . exp_mul_I , div_eq_inv_mul , Complex . ext_iff ] simp [ Complex . cos_ofReal_re , Complex . sin_ofReal_re ] <; > field_simp <; > norm_cast constructor <; > apply Finset . sum_congr <; > aesop field_simp [ _root_ . pow_add , show (4 : R) = 2 ^ 2 by norm_num ] <; > ring norm_num [ mul_comm _ 2 , pow_mul ] rewrite [ show (4 : R) ^ = (2 * 2 : R) ^ by ring , mul_pow ] <; > field_simp <; > ring have h_sum_split : ((cid:80) in ( Finset . range : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) = Complex . exp ( ( 0) * Complex . ) + (cid:80) in ( Finset . Icc 1 (k -1) : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) : Finset . range = insert 0 ( Finset . Icc 1 ( - 1) ) simp have h_range_split ext <; > rcases with ( _ _ ) <; > omega rw [ h_range_split , Finset . sum_insert ] norm_num [ pow_zero , eq_self_iff_true ] simp [ Nat . le_zero ] [ Nat . lt_succ_iff ] have h_abs_head : Complex . abs ( Complex . exp ( ( 0) * Complex . ) ) = 1 simp [ Complex . abs_exp , eq_self_iff_true ] have h_t ail_g eom_ sum _val : ((cid:80) in ( Finset . Icc 1 ( - 1) : Finset N) , 1 / ((2 : N) ^ : R) ) = 1 - 1 / (2 : R) ^ ( - 1) : (1 : R) have h_tight norm_cast at * <; > linarith clear h_tight h_sum_split h_complex_repr h_y_expand h_y_sum_split h_y_sum_expanded h_cos_add 2 3 1 0 induction ' <; > simp [ Finset . sum_Icc_succ_top , *] induction ' <; > simp_all [ Finset . sum_Icc_succ_top , pow_succ ] ring <; > ring_nf have h_abs_tail_le : Complex . abs ((cid:80) in ( Finset . Icc 1 (k -1) : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) 1 - 1 / (2 : R) ^ ( - 1) rw [ _tai l_ge om_ su m_ val ] apply ( Complex . abs . sum_le _ _ ) . trans_eq apply Finset . sum_congr rfl 23 intro _ simp [ Complex . abs_exp_ofReal_mul_I , Nat . cast_pow , Nat . cast_ofNat ] have h_abs_ tail_lt_ one : Complex . abs ((cid:80) in ( Finset . Icc 1 (k -1) : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) < 1 refine lt_of_le_of_lt h_abs_tail_le ? _ refine sub_lt_self _ ( by positivity ) have _ bs _ _ _r _ a ng : Complex . abs ((cid:80) in ( Finset . range : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) 1 - Complex . abs ((cid:80) in ( Finset . Icc 1 (k -1) : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) rw [ h_sum_split ] rw [ h_abs_head ] apply Complex . abs . le_add imo_1969_p2 - Part 2 have h_abs_ge_final : Complex . abs ((cid:80) in ( Finset . range : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) 1 / (2 : R) ^ (k -1) refine ' _root_ . trans _a _g _ by _ ev _ ri gl _ linarith [ h_abs_tail_le ] have h_abs_gt_zero : 0 < Complex . abs ((cid:80) in ( Finset . range : Finset N) , Complex . exp ( ( ) * Complex . ) / (((2 : N) ^ ) : R) ) linarith [ pow_two_nonneg (( - 1 : N) : R) ] have h_c mpl ex _ va l_ e_ ze ro : ( (cid:80) in ( Finset . range : Finset N) , Real . cos ( ) / ((2 : N) ^ : R) , (cid:80) in ( Finset . range : Finset N) , Real . sin ( ) / ((2 : N) ^ : R) : C) = 0 focus all_goals ( norm_num ; aesop ) have h_coeffs_polar : ( : R) , 0 < ((cid:80) in ( Finset . range : Finset N) , Real . cos ( ) / ((2 : N) ^ : R) ) = * Real . cos ((cid:80) in ( Finset . range : Finset N) , Real . sin ( ) / ((2 : N) ^ : R) ) = * Real . sin set := (cid:80) Finset . range , cos ( ) / ((2 : R) ^ ) use Complex . abs ((cid:80) Finset . range , Complex . exp ( ( ) * Complex . ) / ( 2 ^ ) ) let : := (cid:80) Finset . range , sin ( ) / 2^ have := Complex . _m _ _ _s _ _ ((cid:80) in Finset . range , Complex . exp (( : R) * Complex . ) / (2 : C) ^ ) use Complex . arg ((cid:80) in Finset . range , Complex . exp ( ( ) * Complex . ) / (2:R) ^ ) simp_all [ Complex . ext_iff ] 24 have _ _r i n_ h _ ol : ( : R) , 0 < , = * Real . cos * Real . cos - * Real . sin * Real . sin obtain , phi , hR_pos , h_cos_eq1 , h_sin_eq1 := use , phi <; > simp_all [ Complex . exp_mul_I , Complex . abs ] h_coeffs_polar have _ _ l e _ _ g _ : ( : R) , 0 < , = * Real . cos ( + ) rcases _ _r ri n _ it _ po with , ' , h_R_pos , h_y_ use , ' , h_R_pos <; > intros <; > simp [ h_y_ , cos_add ] <; > ring have h_y_is_sinusoid : ( : R) , 0 < ( , = * Real . cos ( - ) ) obtain , , _ , hy := _ _ l e _ _ g _ use , -a <; > aesop have h_roots_exist : ( : R) , 0 < = * Real . cos ( - ) = * Real . cos ( - ) rcases h_y_is_sinusoid with , , h_R_pos , h_y_R_a exact , , h_R_pos , by simp [ h_y_R_a ] , by simp [ h_y_R_a ] have h_cos_zero : ( : R) , 0 < Real . cos ( - ) = 0 Real . cos ( - ) = 0 rcases h_roots_exist with , , h_rPos , exact h_mEq , h_nEq , , h_rPos , by have := 2 ; have := 3 ; field_simp [ 1 ] at * <; > nlinarith , by have := 3 ; have := 2 ; field_simp [ 1 ] at * <; > nlinarith have _ t _ _ _ f _ t e : ( : R) ( 1 2 : Z) , - = (2 * ( 1 : R) + 1) * Real . pi / 2 - = (2 * ( 2 : R) + 1) * Real . pi / 2 rcases h_cos_zero with , , _ , h_m_cos_zero , h_n_cos_zero rw [ cos_eq_zero_iff ] at h_m_cos_zero exact , ( Classical . choose h_m_cos_zero ) , ( Classical . choose h_n_cos_zero h_n_cos_zero ) , by convert h_m_cos_zero . choose_spec , by convert h_n_cos_zero . choose_spec have h_m_minus_n_form : 1 2 : Z, - = ((2 * ( 1 : R) + 1) * Real . pi / 2) - ((2 * ( 2 : R) + 1) * Real . pi / 2) obtain , 1 , 2 , h_z_root_m , h_z_root_n := _ t _ _ _ f _ t e refine 1 , 2 ,? _ <; > linarith have h_ m_ in _n _ si pl fi ed : 1 2 : Z, - = ( ( 1 - 2 ) : R) * Real . pi rcases h_m_minus_n_form with 1 , 2 , h_form <; > exists <; > exists 2 <; > field_simp at h_form <; > linarith obtain 1 , 2 , h_m_sub_n_t 1 _t 2 := h_ m_ min _n _ si pl if ed <; > use 1 - 2 <; > linarith [ h_m_sub_n_t 1 _t 2 ]"
        },
        {
            "title": "C Prompts Used in This Work",
            "content": "C.1 Prompts for Autoformalization Our autoformalization pipeline operates in two stages to ensure syntactic correctness. First, an Initial Formalization Prompt (shown below) translates natural language problem into Lean 4 theorem statement. If the generated code fails to compile, an Error Feedback Prompt is then deployed to revise the statement, using the verbatim error message from the Lean compiler as direct feedback for revision."
        },
        {
            "title": "Prompt for Initial Formalization",
            "content": "You are an expert in math proof and the theorem prover: Lean. Given math problem that contains the question and all conditions, and its corresponding solution that contains solution steps and the correct answer, generate mathematically equivalent proof problem and rewrite it in the Lean 4 statement. You should follow the following procedures. a): Identify all questions and conditions in the given problem. b): Identify all solution steps and the correct answers in the given solution. c): With the questions and conditions in a) and correct answers in b), translate the (question, conditions, correct answer) tuple to mathematically equivalent proof problem that proves question == answer given conditions. d): Rewrite the math proof problem in c) to Lean 4 statement. Note that you should write the statement only, no proof is required. This also means you do not need to consider the solution steps either. The first priority is to ensure the generated Lean code can be built successfully. Consider using the following tips. Use broader import, e.g., import Mathlib, to bring in the entirety of the necessary library, and remove specific import of submodules, e.g., import Mathlib.LinearAlgebra.BasicReal3, accordingly. Add noncomputable before def only when necessary. Use by instead of begin end. Add sorry to skip the proof. You should strictly follow the below criteria to guarantee the lean statement is equivalent to the mathematical problem. Each definition used in Lean 4 statement should only directly appear in the conditions problem in a). Each definition should NOT come from and assume any knowledge directly from the solution step in b). Each condition in a) should be used as definition in Lean 4. For any implications appearing in the conclusions of the original problem, extract their antecedents and declare them as explicit assumptions before the colon, leaving only the consequent in the conclusion after the colon. For equations, structure the theorem in the form conditions : conclusions where conditions include variable definitions and domains, and conclusions are the solutions to the equation, avoiding implication or equivalence symbols. 26 Below are examples to illustrate the process: Example 1 (Number Theory): Lean 4 statement: theorem nt3_problem ( : N) ( hn : > 1) ( hp : Nat . Prime ) ( h1 : ( - 1) ) ( h2 : ( ^6 - 1) ) : : N, ( - = ^2) ( + = ^2) := by sorry problem: NT3. Let > 1 be positive integer and prime number such that (p 1) and (n6 1). Prove that at least one of the numbers and + is perfect square. Example 2 (Number Theory): Lean 4 statement: theorem nt4_problem ( : N) ( hx : > 0) ( hy : > 0) ( h1 : : N, 3 * + 4 * = ^2) ( h2 : : N, 4 * + 3 * = ^2) : 7 7 := by sorry problem: NT4. If the positive integers and are such that both 3x + 4y and 4x + 3y are perfect squares, prove that both and are multiples of 7. Example 3 (Algebra): Lean 4 statement: theorem sum_not_zero ( d : R) ( h1 : * * - = 1) ( h2 : * * - = 2) ( h3 : * * - = 3) ( h4 : * * - = -6) : + + + = 0 := by sorry problem: The real numbers a, b, c, satisfy simultaneously the equations abc = 1, bcd = 2, cda = 3, dab = 6. Prove that + + + = 0. Example 4 (Inequality): Lean 4 statement: theorem inequality_proof ( : R) ( ha : > 0) ( hb : > 0) ( hc : > 0) : 8 / (( + ) ^2 + 4* * * ) + 8 / (( + ) ^2 + 4* * * ) + 8 / (( + ) ^2 + 4* * * ) + ^2 + ^2 + ^2 8 / ( + 3) + 8 / ( + 3) + 8 / ( + 3) := by sorry 27 problem: The real numbers a, b, c, satisfy simultaneously the equations abc = 1, bcd = 2, cda = 3, dab = 6. Prove that + + + = 0. Now, use the same process for the following problem and solution: {problem} {solution}"
        },
        {
            "title": "Prompt for Error Feedback",
            "content": "You are an expert in math proof and the theorem prover: Lean. You are given the following math problem that contains the question and all conditions, and its corresponding solution that contains solution steps and the correct answer. {problem} {solution} mathematically equivalent proof problem that proves question == answer given conditions is generated and rewritten in the Lean 4 statement, as shown below: {Lean 4 statement} However, this lean code got error with lake build, and here is the error message: {error message} Please modify the lean code to ensure it can be built successfully with lake build. Here is few tips that might help: Use broader import, e.g., import Mathlib, to bring in the entirety of the necessary library, and remove specific import of submodules, e.g., import Mathlib.LinearAlgebra.BasicReal3, accordingly. Add noncomputable before def only when necessary. Use by instead of begin end. Add sorry to skip the proof. C.2 Prompts for Planner"
        },
        {
            "title": "Prompt for Initial Planning",
            "content": "You are an expert assistant specializing in Math Olympiads and the Lean 4 theorem prover. Your primary goal is to generate syntactically perfect, type-checkable Lean 4 intermediate step code snippets (plan) for given theorem. It is crucial to strictly adhere to the following rulesany violation will be considered an error. Task Given the following Lean 4 theorem tactic state, generate the core intermediate subgoals (have statements) needed for the proof. Mandatory Rules You must comply with every rule in this section. Failure to adhere to any single rule will result in an incorrect output. 28 1. Critical Rule: Explicitly Specify Set/Finset Types This is the most common and fatal point of error. You must explicitly declare the type for any Set or Finset literal. This rule is non-negotiable. - Correct : ({ { -1 , 0 , 1}} : Set Z) - Incorrect : { { -1 , 0 , 1}} 2. Omit the Proof: Never provide the proof. Only state the have statement itself. 3. Valid Lean 4 Code: The entire output block must be type-checkable in Lean 4.10.0 environment. 4. Use Existing Names: Use the exact, existing lemma and definition names from mathlib. Do not invent names. 5. No Undeclared Variables: Do not introduce any variables or constants not declared in the original theorem statement. 6. Explicit Multiplication: Multiplication must always use the * symbol. - Correct : * - Incorrect : ax 7. No Chained Inequalities: Never use chained inequalities. They must be split using logical AND . - Correct : <= <= - Incorrect : <= <= 8. Correct Logarithm Function: Real.log is only for the natural logarithm. For logarithms with specified base, you must use Real.logb. - Correct : Real . logb (2 : R) 8 - Incorrect : Real . log (2 : R) 8 9. Factorial Notation: In Lean, factorials must be written as (n)! or Nat.factorial n, not n!. - Correct : ( ) ! or Nat . factorial - Incorrect : ! 10. Numeric Types Must Be Explicitly Annotated: To avoid type ambiguity in Lean, any expression involving numeric operations must have at least one numbers type specified. - For division : (1 : R) / 2 = 0.5 , but (1 : Z) / 2 = 0. - For subtraction : (1 : Z) - 2 = -1 , but (1 : N) - 2 = 0. - Correct : ( : R) / , / ( : R) , ( : Z) - - Incorrect : / , - 11. Interval Notation: Do not use Icc, Ioo, Ico, Ioc, etc., to represent intervals. Only use inequalities. - Correct : <= <= - Incorrect : Icc 12. Complex Numbers: Use Complex.I for the imaginary unit and Complex.abs for the modulus/absolute value of complex number. 13. Avoid Common Inequality Theorems: Avoid using common inequality theorems like Holders or Jensens. For inequality problems, try to ensure each proof step only requires basic simplification. 29 14. Proving Equivalences: For proofs of equivalences (iff), ensure each have statement is an implication, where the antecedent is the left side of the equivalence (when proving left-to-right) or the right side (when proving right-to-left). 15. Real.pi Notation: Consistently use Real.pi instead of π. 16. Final Check: Before providing the plan, perform final review to ensure you have scrupulously followed all the rules above, especially the critical rule regarding Set/Finset. Below are examples to illustrate the process: Example 1: Theorem: theorem inga por e201 9_r 1_p 7 ( : R) ( hx : Real . tan = 5) : (6 + Real . sin (2 * ) ) / (1 + Real . cos (2 * ) ) = 83 := by Plan: have 1 : Real . sin = 5 * Real . cos have 2 : Real . sin ^ 2 = 25 * Real . cos ^ 2 have 3 : 26 * Real . cos ^ 2 = 1 have hsin2x_val : Real . sin (2 * ) = (5 : R) / (13 : R) have hcos2x_val : Real . cos (2 * ) = -(12 : R) / (13 : R) Example 2: Theorem: theorem problem4 ( : R) ( : : N, 5 124 = ( Real . logb ( : R) ((7 : R) ^ ( ^ 2 - 1) ) ) / ( Real . logb (( + 1 : R) ) ((7 : R) ^ ( ^ 2 - 4) ) ) ) : ((cid:81) in Finset . Icc (5 : N) 124 , ) = (41 : R) / 7 := by Plan: have h_prod_split : ((cid:81) in ( Finset . Icc 5 124 : Finset N) , ) = ((cid:81) in ( Finset . Icc 5 124 : Finset N) , (( ^ 2 - 1) / ( ^ 2 - 4 : R) ) ) * ((cid:81) in ( Finset . Icc 5 124 : Finset N) , ( Real . logb ( : R) (7 : R) / Real . logb (( + 1 : R) ) (7 : R) ) ) have h_tele scope_pa rt1 : ((cid:81) in ( Finset . Icc 5 124 : Finset N) , (( ^ 2 - 1) / ( ^ 2 - 4 : R) ) ) = (41 : R) / 21 have h_tele scope_pa rt2 : ((cid:81) in ( Finset . Icc 5 124 : Finset N) , ( Real . logb ( : R) (7 : R) / Real . logb (( + 1 : R) ) (7 : R) ) ) = 3 have h_final_product : (41 / 21 : R) * 3 = (41 : R) / 7 Example 3: Theorem: theorem mc1 2b_varian t_p ( : Finset R) ( 0 : ( : R) , 0 < 2 * Real . pi 2 - 4 * Real . sin + 3 * Real . cos (3 * ) = 0) : . card = 4 := by Plan: 30 have h_interval1 : , 0 < Real . pi / 2 (2 - 4 * Real . sin + 3 * Real . cos (3 * ) = 0) have h_interval2 : , Real . pi / 2 < 3 * Real . pi / 4 (2 - 4 * Real . sin + 3 * Real . cos (3 * ) = 0) have h_interval3 : , 3 * Real . pi / 4 < Real . pi (2 - 4 * Real . sin + 3 * Real . cos (3 * ) = 0) have h_interval4 : , Real . pi < 2 * Real . pi (2 - 4 * Real . sin + 3 * Real . cos (3 * ) = 0) have h_card_eq_4 : . card = 4 Now, use the same process for the following theorem: {theorem} You must follow all the instructions and mandatory rules above. After deep consideration, provide the Lean 4 intermediate step code snippets. While ensuring correctness, the more intermediate steps, the better."
        },
        {
            "title": "Prompt for Dynamic Replanning",
            "content": "You are an expert assistant specializing in Math Olympiads and the Lean 4 theorem prover, with particular talent for proof decomposition and overcoming difficult proof steps. Your primary goal is to refine an existing proof plan by inserting more granular, logically sound subgoals to help prover overcome specific, identified bottleneck. It is crucial to strictly adhere to the following rulesany violation will be considered an error. Task Given Lean 4 theorem, its initial proof plan, and specific have statement where prover has become stuck, your task is to generate new, complete proof plan. This new plan must include all the original steps, but with additional, simpler have statements inserted immediately before the stuck subgoal. These new steps must logically lead to the proof of the stuck subgoal, breaking down the complex reasoning into series of more manageable steps. Mandatory Rules You must comply with every rule in this section. Failure to adhere to any single rule will result in an incorrect output. (The first 16 rules are identical to those in the Prompt for Initial Planning and must be strictly followed.) In addition, the following task-specific rules apply: 17. Insert Before Stuck Step: The new auxiliary have statements must be inserted immediately before the provided stuck subgoal. 18. Provide Complete Plan: The output must be the entire, updated plan, including all original and new have statements in the correct order. Do not output only the new steps. 19. Logical Progression: The newly inserted steps must be logically sound and serve as direct prerequisites for proving the stuck subgoal. They should bridge the logical gap that caused the prover to get stuck. Below is an example to illustrate the process: Theorem: 31 theorem trig_identity_4x ( : R) : Real . sin (4 * ) = 4 * Real . sin * Real . cos * (1 - 2 * Real . sin ^ 2) := by Initial Plan: have h_ si 4x _ s_ 2 si 2x os 2x : Real . sin (4 * ) = 2 * Real . sin (2 * ) * Real . cos (2 * ) have h_final_identity : 2 * Real . sin (2 * ) * Real . cos (2 * ) = 4 * Real . sin * Real . cos * (1 - 2 * Real . sin ^ 2) Stuck Subgoal: have h_final_identity : 2 * Real . sin (2 * ) * Real . cos (2 * ) = 4 * Real . sin * Real . cos * (1 - 2 * Real . sin ^ 2) Refined Plan (Your Output): have h_ si 4x _ s_ 2 si 2x os 2x : Real . sin (4 * ) = 2 * Real . sin (2 * ) * Real . cos (2 * ) have h_sin2x : Real . sin (2 * ) = 2 * Real . sin * Real . cos have _ 2 _ _ m _ _ _ : Real . cos (2 * ) = Real . cos ^ 2 - Real . sin ^ have _c 2 x_ _ te _o f_ si : Real . cos (2 * ) = 1 - 2 * Real . sin ^ 2 have h_final_identity : 2 * Real . sin (2 * ) * Real . cos (2 * ) = 4 * Real . sin * Real . cos * (1 - 2 * Real . sin ^ 2) Now, use the same process for the following three items: {theorem} {initial_plan} {stuck_subgoal} You must follow all the instructions and mandatory rules above. After deep consideration, provide the complete, refined Lean 4 plan."
        }
    ],
    "affiliations": [
        "ByteDance Seed",
        "Carnegie Mellon University",
        "Peking University"
    ]
}