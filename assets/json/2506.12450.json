{
    "paper_title": "Language Surgery in Multilingual Large Language Models",
    "authors": [
        "Joanito Agili Lopo",
        "Muhammad Ravi Shulthan Habibi",
        "Tack Hwa Wong",
        "Muhammad Ilham Ghozali",
        "Fajri Koto",
        "Genta Indra Winata",
        "Peerat Limkonchotiwat",
        "Alham Fikri Aji",
        "Samuel Cahyawijaya"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for language-specific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), a novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLC's strong cross-lingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current large-scale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces a practical solution for enhancing their cross-lingual performance."
        },
        {
            "title": "Start",
            "content": "Joanito Agili Lopo1,2, Muhammad Ravi Shulthan Habibi1,3, Tack Hwa Wong1, Muhammad Ilham Ghozali1,3, Fajri Koto1,4, Genta Indra Winata1,5, Peerat Limkonchotiwat1,6, Alham Fikri Aji1,4, Samuel Cahyawijaya*1,7 1SEACrowd 2Kreasof AI 4MBZUAI 5Capital One 3Universitas Indonesia 7Cohere 6AI Singapore {amalopo99,muhammadravi251001,tackhwawong00}@gmail.com muhammad.ilham.gozali@gmail.com,samuelcahyawijaya@cohere.com 5 2 0 J 4 1 ] . [ 1 0 5 4 2 1 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for languagespecific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLCs strong crosslingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current largescale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces practical solution for enhancing their cross-lingual performance."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) have revolutionized natural language processing, demonstrating remarkable generalization capabilities across diverse tasks and languages (Brown et al., 2020; Le Scao et al., 2023; Anil et al., 2023; Team et al., 2025; Cohere et al., 2025; Singh et al., 2025). Their ability to adapt to new tasks in few-shot and even zeroshot settings highlights their efficiency and versatility (Bang et al., 2023; Susanto et al., 2025). *Equal contributions. 1Our code is published at https://github.com/ SEACrowd/itlc. Figure 1: We inspect the alignment in the middle layer representation of LLMs, allowing us to disentangle the language-specific and language-agnostic information. By exploiting this behavior, we are able to achieve Inference-Time Language Control (ITLC), alleviating the language confusion problem in LLMs. Prior works have identified naturally emerging representation alignment across layers in LLMs, particularly in the middle layers of LLMs (Chang et al., 2022; Zhao et al., 2024a). This emerging alignment in LLMs is the key factor in their ability to handle multiple languages (Cahyawijaya, 2024; Tang et al., 2024; Wilie et al., 2025), which is pivotal for their cross-lingual capabilities. However, several questions remain open, such as whether this emerging alignment behaves similarly to alignment in models trained with enforced alignment objectives (Reimers and Gurevych, 2020; Yang et al., 2019a; Feng et al., 2022; Limkonchotiwat et al., 2022, 2024), how this alignment can be utilized to further enhance LLMs, etc. In this work, we investigate the phenomenon of representation alignment in LLMs, focusing on its occurrence, distinction, and potential applications. We aim to confirm the presence of this representation alignment and contrast it with alignment in LLMs with strictly designed alignment, such as multilingual SentenceBERT (Reimers and Gurevych, 2019) or LaBSE (Feng et al., 2022). Our findings highlight that, unlike LLMs with strictly designed alignment, the naturally emerging alignment in recent LLMs demonstrates much stronger retention of language-specific information with 30% performance drop compared to LLMs with strictly designed alignment, with almost >90% performance drops relative to other non-aligned layers. Upon further investigation, we found potential method to disentangle language-specific and language-agnostic information in the aligned representation. By exploiting the disentangled languagespecific and language-agnostic information, we demonstrate simple but effective method to control the generation of language from such representation, enabling us to achieve Inference-Time Language Control (ITLC) as showcased in Figure 1. We demonstrate the effectiveness of ITLC in two downstream applications: 1) zero-shot crosslingual language generation and 2) mitigating language confusion in LLMs (Marchisio et al., 2024). Our contribution in this work is fourfold: We confirm the presence of representation alignment in LLMs, providing empirical evidence of this phenomenon (3.2). We contrast natural alignment with strictly designed alignment, highlighting their comparable impact on cross-lingual generalization while emphasizing their differences in alignment locations and the extent of languagespecific information retention (3.2). We investigate method to extract languagespecific information from aligned representations, showcasing the potential for languagespecific manipulation while preserving the semantic integrity of the generation (4.1). We introduce ITLC, novel method that enables cross-lingual language control and mitigates language confusion problems that retain semantic integrity in target languages (5)."
        },
        {
            "title": "2.1 Representation Alignment in LLMs",
            "content": "Representation alignment refers to the process by which semantically identical inputs expressed in different languages are mapped to similar internal embeddings within LLMs (Park et al., 2024; Wu and Dredze, 2020; Chang et al., 2022). Originally, representation alignment is strictly embedded into the modeling objective to ensure output consistency across languages and to enable generalization in cross-lingual transfer tasks (Pires et al., 2019; Wu and Dredze, 2019; Reimers and Gurevych, 2020; Feng et al., 2022; Choenni et al., 2024). Several studies have observed tendency for LLMs to align representations across different languages (Wendler et al., 2024; Zhao et al., 2024b; Mousi et al., 2024). This is done by measuring the similarity between embeddings of parallel sentences across different languages (Ham and Kim, 2021; Gaschi et al., 2023; Cahyawijaya, 2024). Several benchmark datasets can be used for this purpose. Our work measure the degree of alignment across various layers between strictly and naturally aligned models to contrast the two and understand its relation to language-specific and language-agnostic capabilities (Kulshreshtha et al., 2020; Libovický et al., 2020; Hua et al., 2024; Wilie et al., 2025) of LLMs."
        },
        {
            "title": "2.2 Latent Controllability in LLMs",
            "content": "LLMs controllability is crucial for ensuring that the systems adhere with human intentions. Through mechanisms such as adapter (Pfeiffer et al., 2020; Hu et al., 2022), prompting (Lin et al., 2021; Bai et al., 2022), latent manipulation (Madotto et al., 2020; Ansell et al., 2021), etc, we aim to gain control over the behavior of LLMs. Various aspects have been explored in LLM controllability, including internal knowledge (Madotto et al., 2020; Xu et al., 2022), styles & personas (Lin et al., 2021; Wagner and Ultes, 2024; Cao, 2024), languages (Üstün et al., 2020; Ansell et al., 2021), human values (Bai et al., 2022; Cahyawijaya et al., 2025a), etc. Recent works show that latent states in LLMs exhibit discernible patterns for distinguishing truthful outputs from hallucinated ones, suggesting an intrinsic awareness of fabrication (Li et al., 2023; Duan et al., 2024; Ji et al., 2024; Chen et al., 2024). Similar methods are also introduced for stylistic and safety control (Subramani et al., 2022; Kwak et al., 2023). These studies underscore the potential of latent interventions for precise control over LLM behavior. ITLC extends the latent manipulation methods for controlling the generated language in inference time, demonstrating how language-specific information can be extracted and manipulated without losing semantic meaning. This opens new avenues for controlling language Figure 2: Cross-lingual similarity across different layers in LaBSE and Qwen2.5-0.5B. LaBSE exhibits high cross-lingual similarity in its final layer, whereas Qwen2.5-0.5B shows this similarity in the middle layer. This difference suggests that the alignment of representations occurs at distinct positions within the two models. generation and mitigating confusion problems."
        },
        {
            "title": "Alignment in LLMs",
            "content": "Prior works (Chang et al., 2022; Zhao et al., 2024a; Cahyawijaya, 2024; Wilie et al., 2025; Payoungkhamdee et al., 2025) demonstrate the existence of emerging representation alignment in LLMs. We take step further to provide deeper understanding to this behavior by contrasting it with alignment in strictly-aligned LLMs. Specifically, we observe the correlation between the degree of alignment with the cross-lingual generalization and language identification (LID) capability, which are the proxies to their language-agnostic and language-specific capabilities, respectively."
        },
        {
            "title": "3.1 Experiment Settings",
            "content": "Modeling. As measure of alignment, we compute the average cosine similarity of the latent representation of sentence in one language with the representation of parallel sentences in the other languages. For the LLM with strictly designed alignment, we employ LaBSE (Feng et al., 2022). For the LLM with emerging representation alignment, we employ multilingual decoder-only LLM, i.e., Qwen2.5 (Qwen et al., 2025). Specifically, we employ Qwen2.5-0.5B with 500M parameters to have comparable scale with the LaBSE model with 471M parameters. For measuring the crosslingual generalization of LaBSE, we perform monolingual few-shot fine-tuning with SetFit (Pannerselvam et al., 2024) and evaluate on all other languages. For Qwen2.5-0.5B, we employ few-shot cross-lingual in-context learning. We incorporate 10 few-shot samples for SetFit and 2 for in-context learning. To measure the LID capability, we take the latent representation of both models in the first, middle, and last layers. In this case, we are interested in comparing the behavior between the strictly aligned representation in LaBSE and the emerging aligned representation in Qwen2.5-0.5B. Following Cahyawijaya et al. (2025b), we measure LID performance by linear probing and kNN to measure linear separability and cluster closeness within each language class. More details about the experiment are presented in Appendix A. Datasets. We employ set of multilingual evaluation datasets. To measure the degree of alignment, we employ 7 datasets: FLORES-200 (Team et al., 2022), NTREX-128 (Federmann et al., 2022), NusaX (Winata et al., 2023), NusaWrites (Cahyawijaya et al., 2023), BUCC (Zweigenbaum et al., 2017), Tatoeba (Tiedemann, 2020), and Bible Corpus (McCarthy et al., 2020). For cross-lingual evaluation, we incorporate 4 datasets: SIB200 (Adelani et al., 2024), INCLUDE-BASE (Sridhar et al., 2020), XCOPA (Ponti et al., 2020), and PAWSX (Yang et al., 2019b). For LID evaluation, we incorporate 3 datasets, i.e., FLORES-200, NTREX128, and NusaX. The detailed description of each"
        },
        {
            "title": "Dataset",
            "content": "LaBSE Qwen2.5-0.5B SIB200 INCLUDE-BASE XCOPA PAWS-X"
        },
        {
            "title": "Avg",
            "content": "0.210 -0.021 0.144 0.146 0.1198 0.123 0.142 -0.139 0.532 0.1645 Table 1: Pearson correlation between the downstream cross-lingual performance and the degree of alignment between the corresponding language pairs. dataset is shown in Appendix A."
        },
        {
            "title": "3.2 Experiment Result",
            "content": "Strictly and Naturally Aligned LLMs. LaBSE and Qwen2.5-0.5B demonstrate distinct patterns in cross-lingual representation alignment. As shown in Figure 2, LaBSE demonstrates distributed alignment strength across deeper layers, with the middle and last layers achieving high average similarity scores (0.758 and 0.754, respectively). This aligns with the training objective of LaBSE, which In aligns the representation on the last layer. contrast, Qwen2.5-0.5B exhibits more localized alignment pattern, with the middle layer showing strikingly higher average similarity (0.922) than both the first (0.591) and last (0.375) layers. This suggests that Qwen2.5-0.5B concentrates representation alignment sharply in the middle layer, achieving both higher and more stable cross-lingual representation. See detailed analysis in Appendix B.1. This result displays distinct layer-wise behaviors in retaining the language-specific and languageagnostic information within the two different types of LLMs. Specifically, for model with strict alignment, aligned representation is located in the layer where the objective is applied to the last layer in the case of LaBSE , while in LLMs with natural alignment, the aligned representation is formed in the middle layers and breaks as the representation goes closer into the last layer. This aligns with prior works (Chang et al., 2022; Tang et al., 2024; Zhao et al., 2024a; Wilie et al., 2025), which demonstrate the naturally representation alignment emerge in the middle layer of LLMs. Representation Alignment and Cross-lingual Generalization. We further measure the impact of the degree of representation alignment to the downstream cross-lingual generalization capability of the models. We measure the cross-lingual performance by training on one language and evaluating on the other languages in the datasets using the method described in 3.1 and correlate them with the cosine similarity of the corresponding language pair averaged across all alignment datasets. As shown in Table 1, the degree of alignment shows positive correlation to the downstream cross-lingual performance. Nonetheless, the correlation is weak, which is potentially caused by the few-shot tuning setting conducted on both models. Despite that, the positive correlation between degree of alignment and cross-lingual generalization on both strictly-aligned and naturally-aligned LLMs signifies the important role of representation alignment in improving the cross-lingual generalization of LLMs. See Appendix B.2 for detailed and further analysis. Representation Alignment and LanguageSpecific Information. As shown in Table 2, the LID performance of LaBSE and Qwen2.5-0.5B models evaluated using both KNN and linear probing reveals that the first layer consistently achieves the highest LID F1 scores across all datasets. For LaBSE, the aligned representation in the last layer exhibits notably weaker performance, particularly for the FLORES-200 and NusaX datasets. Similarly, in Qwen2.5-0.5B, the aligned representation in the middle layer shows weaker LID performance compared to the first and last layers. These empirical findings highlight three key insights: (1) language-specific information, such as surfacelevel features and general linguistic patterns, is more dominant in the early layers; (2) the degree of alignment is negatively correlated with the amount of language-specific information retained; and (3) unlike strictly aligned LLMs, the aligned representation in LLMs with emerging alignment retains more language-specific information, which potentially serves as the basis for determining the language of the generated sequence. 4 Inference-Time Language Control Building on the insights presented in 3, we explore method to control the language of the generated sequence with minimal semantic loss. Specifically, we develop method to extract languagespecific information at the layer where representation alignment occurs in LLMs. Using this information, we gather language-specific vectors from each language and use them to manipulate the language-specific information during the inference time. With this language-specific intervention, we"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "Layer",
            "content": "FLORES-200 NTREX-128 NusaX FLORES-200 NTREX-128 NusaX"
        },
        {
            "title": "First\nMiddle\nLast",
            "content": "95.13 94.18 70.89 88.35 78.85 3.92 93.29 92.68 74.36 90.43 81.30 1.63 97.30 94.51 65.44 81.78 45.37 0. 94.21 91.76 92.46 83.69 55.32 71.73 91.42 90.04 90.27 86.06 54.73 81.86 95.55 87.09 88.77 65.79 25.05 29. Table 2: LID performance by layer and classification method for LaBSE and QWEN2.5-0.5B. Red bold text highlights the LID scores on the layer where alignment occurs in each corresponding model. LID performance is consistently lower in layer where the representation is aligned across all models and classification methods. aim to steer the model toward utilizing languagespecific features, allowing us to perform InferenceTime Language Control (ITLC)."
        },
        {
            "title": "4.1 Methods",
            "content": "Latent Extraction. Latent extraction techniques are employed to isolate language-specific information from the models representations. Specifically, we extract Qwen2.5-0.5B (Qwen et al., 2025) hidden states to capture language-specific features at its middle representation. Given an input sequence from the FLORES-200 dataset (Team et al., 2022), we compute the hidden states Rd at specified layer, where = 896 is the embedding dimension of Qwen2.5-0.5B. Finally, we apply mean pooling to ensure that only meaningful token embeddings contribute to the final representation. Linear Discriminant Analysis. To disentangle language-specific information, we apply Linear Discriminant Analysis (LDA) to maximize class separability and reduce dimensionality. We use the Singular Value Decomposition (SVD) solver in order to handle high-dimensional embeddings efficiently and select the top eigenvectors corresponding to the largest eigenvalues to form Rdk. Let = {(hi, li)}N i=1 denote dataset of hidden states hi Rd labeled with language classes li {1, . . . , K}, this projects hidden states to lower-dimensional space = hT Rk. To validate the quality of the projection and select the optimal number of components k, we train neural network classifier with single linear layer on the projected training data z. We experiment with several values and evaluate classification accuracy on test set. Finally, we take = 100 because LID performance significantly drops on higher components, indicating major loss of language-specific information. More details on the LDA settings are shown in Appendix D.2 Language Vector. Using the LDA-projected space, we construct language vectors by leveraging the neural networks weights to identify active dimensions for each language. For each language we extract the weight matrix RKk from the neural networks linear layer, where ul,j represents the contribution of dimension {1, . . . , k} to language l. We define threshold τ = 0.01 and select active dimensions for language as Al = {j ul,j > τ }. The language vector vl Rk for language is computed as the mean of projected hidden states zi over samples of language l, restricted to active dimensions: vl[j] = (cid:40) 1 Nl 0, (cid:80) hil zi[j], if Al, otherwise, where Nl is the number of samples for language l, and zi[j] is the j-th component of the projected hidden state. Vector Injection. To enable injection, we project the language vector back to the original embedding space using the pseudo-inverse: vorig = vlW Rd. By applying this, we retain the original embedding of the input and modify it with the language vector inverse projection. For source language (e.g., English) and target language (e.g., Indonesian), we compute shift vector: δ = vorig + vorig , which is injected into the hidden states at the middle layer during inference: = + αδ, where is the original hidden state, α is scaling factor, and is the modified hidden state. Language Shift Strategy. We further divide the language vector injection into three strategies based on the temporal scope of application: (1) prompt only, (2) generated tokens only, and (3) both phases. Let h(m) Rd denote the hidden state at position in the middle layer m, and h(m) denotes its language-shifted counterpart: Prompt-Only (prompt-only): Applies injection exclusively to input prompt processing: h(m) = (cid:40) h(m) + αδ, [1, Tinput] h(m) > Tinput , Generated-Only (gen-only): Restricts injection to autoregressive generation: h(m) = (cid:40) , h(m) h(m) + αδ, [Tinput + 1, Ttotal] [1, Tinput] Prompt and Generated (prompt-and-gen): Applies injection throughout both phases: h(m) = h(m) + αδ, [1, Ttotal] where Tinput is the input prompt length and Ttotal = Tinput + the total sequence length after generating tokens. 5 Implication of Inference-Time Language Control (ITLC) We demonstrate the effectiveness of ITLC on two scenarios: 1) cross-lingual language control and 2) mitigating language confusion (Marchisio et al., 2024). Cross-lingual language control refers to guiding the model prompted on source language to switch and generate text in target language (e.g., ENXX or XXEN) by manipulating its latent representation while maintaining semantic relevance and linguistic fidelity across different languages. Mitigating language confusion, on the other hand, focuses on alleviating the limitation of LLMs to consistently generate text in the desired language, which can occur at the word level, line level, or entire response (Marchisio et al., 2024)."
        },
        {
            "title": "5.1 Experiment Setting",
            "content": "Figure 3: Language correctness (%) for Qwen2.5-0.5B across ENXX and XXEN Directions. The result of its instruct version is shown at Appendix D.3. the Dolly multilingual dataset subset 2 by taking 200 QA sentences in nine various languages from diverse regions and language families: Indonesian (ID), Thai (TH), Turkish (TR), Japanese (JA), French (FR), Spanish (ES), Arabic (AR), Chinese (ZH), and Korean (KO). We evaluate the performance with multiple automatic metrics: FastText LID (Joulin et al., 2016a,b) for language correctness, while BertScore (Zhang et al., 2020) and SacreBLEU (Papineni et al., 2002; Post, 2018) for generation quality. We conduct human evaluation with native annotators on English (EN), Indonesian (ID), and Thai (TH) in both ENXX and XXEN directions to further validate the generation quality. The human evaluation focuses on 30 samples covering 3 aspects: naturalness, promptcompletion relevance, and answer correctness using likert score ranging from [1. . . 5]. The human annotation guideline is presented in Appendix F. Mitigating Cross-lingual Language Confusion We evaluate the effectiveness of ITLC in mitigating language confusion on the base and instruct versions of Qwen2.5-0.5B. For the hyperparameter α, we use the optimal scaling parameter identified in our ablation study (see Appendix for details). We analyze the impact of language shift vectors extracted from both the base and instruct models (base shift vector δbase vs. instruct shift vector δinstruct) on cross-lingual control. We also investigate the influence of chat template formatting and few-shot examples on model behavior. Our evaluation focuses on cross-lingual settings where input and target languages differ, and reports the official metrics defined in Marchisio et al. (2024): Cross-lingual Language Control. we investigate cross-lingual language control using the Qwen2.5-0.5B model with α = 1.0. We utilize 2https://huggingface.co/datasets/CohereLabs/ aya_evaluation_suite/viewer/dolly_machine_ translated."
        },
        {
            "title": "Generated",
            "content": "EN ID ID EN What is investment banking? bank adalah Investment yang menawarkan layanan investasi dan jasa lainnya kepada para investor atau wirausahawan dalam rangka mendirikan berbagai jenis finansial seperti saham (aset pelanggan) . . . perusahaan sebuah"
        },
        {
            "title": "Tuliskan saya email pengantar ke pengacara\nuntuk mewakili saya di pengadilan untuk\ntiket lampu merah saya tidak pantas",
            "content": "Ill try to draft an outline for what might say in my speech as the \"tug of war\" between two candidates on behalf of people who want their lights out and someone elses lighted street: good man will tell me that . . . Table 3: Examples of generated outputs from Qwen2.5-0.5B-Instruct with injection. Overall, it shows that the language has successfully shifted to the desired target language and the answers are generally correct. Additional examples across different language pairs are provided in Appendix D.5."
        },
        {
            "title": "Model",
            "content": "Lang Shift Nat. Rel. Cor."
        },
        {
            "title": "AVG",
            "content": "19.29 0.00 6.05 0.00 7.78 10.88 7.13 0.0 7.54 6.52 62.90 62.80 60.70 62.00 63.30 64.00 63.80 63.60 63.10 62.91 14.30 15.97 15.97 15.97 10.97 7.17 11.88 0.00 4.11 10. 63.60 64.10 60.20 60.20 63.20 64.40 65.50 62.00 63.80 63.00 Table 4: Generation performance for different target languages with Qwen2.5-0.5B-Instruct. Baseline denotes the same model prompted in the same language as the desired target language. Language Confusion Pass Rate (LCPR), Line-level Pass Rate (LPR), and Word-level Pass Rate (WPR)."
        },
        {
            "title": "5.2.1 Cross-lingual Language Control.",
            "content": "Language Vector Impact. Our experiments demonstrate that the proposed ITLC method enables effective control over cross-lingual generation. As shown in Table 3, both ENXX and XXEN directions yield higher rate of correct language identification. This suggests that manipulating representations of language-specific spaces helps align the source language more closely with the target language in newly projected representation space. For more details results and comparisons are shown in Appendix D.3 and D.4. Interestingly, this space not only transforms the representation into the desired target language, but also carries rich semantic information that contributes to more meaningful and contextually accurate generation. This is further supported by the results in Table 4 (for qualitative evidence, refer to Ta-"
        },
        {
            "title": "ITLC",
            "content": "ENEN IDID THTH IDEN ENID THEN ENTH 3.93 1.83 1.70 3.40 2.77 1.73 1.10 3.47 1.50 1.33 2.33 2.50 1.30 1. 2.07 1.70 1.13 2.03 2.00 1.27 1.07 Table 5: Human evaluation of ITLC response quality. Nat., Rel., and Cor. respectively denote naturalness, relevance, and answer correctness ranging from [1. . . 5]. Baseline denotes the same model prompted in the same language as the desired target language. ble 3), where we compare our method against monolingual baselineprompted and completed entirely in the target languageas an upper bound. Notably, ITLC achieves comparable and, in many cases, surpasses the baseline in both metrics, indicating closer resulting generations to the ground truth answer in the target language. These findings highlight that the injection strategy enables effective cross-lingual generation while preserving semantic integrity. Human Evaluation We conduct human evaluation to validate our findings on language vector injection, with the overall results summarized in Table 5. Our method performs comparably to the Mono Baseline, demonstrating that ITLC successfully shifts language and performs cross-lingual generation close to the ideal performance for the target language. Notably, the direction toward Indonesian even outperforms its baseline by 12 points, suggesting particularly strong alignment in that case. Specifically, the XXEN direction suggests the presence of strong latent representations. In contrast, the ENXX direction shows re-"
        },
        {
            "title": "Method",
            "content": "Qwen2.5-0.5B Baseline + Q/A template (0-shot) + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) Qwen2.5-0.5B-Instruct"
        },
        {
            "title": "LCPR LPR WPR",
            "content": "29.41 44.68 56.78 65.71 71.35 78.93 19.75 35.36 50.63 66.41 80.46 85.08 73.45 75.94 76.16 74.24 67.67 77. Baseline (w/ chat template) + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) 63.00 63.53 57.69 58.79 79.50 75.34 76.05 75.56 81. 73.26 73.95 80.96 77.68 82.42 85.32 76.37 84.06 86.79 81.11 74.51 80.55 79.20 71.40 78.84 Table 6: Cross-lingual language confusion performance (Language Confusion Pass Rate (LCPR), Line-level Pass Rate (LPR), and Word-level Pass Rate (WPR)) of Qwen2.5-0.5B models. duced performance across both settings, highlighting persistent challenges in generating text for lowresource languages. Nonetheless, the Qwen2.50.5B-Instruct model used in this study is relatively small model, which limits the quality of its language generation. Despite this limitation, our results demonstrate that injecting the language vector into the latent space can effectively guide the model toward cross-lingual generation."
        },
        {
            "title": "5.2.2 Mitigating Language Confusion.\nCross-lingual Language Control and Prompt-\ning Efficacy. As shown in Table 6, our proposed\nmethod, ITLC, surpasses baseline configurations,\nincluding QA/chat templates and 5-shot prompting\nfor both base and instruct models in cross-lingual\nsettings. The prompt-and-gen strategy with lan-\nguage shift vectors achieves the strongest perfor-\nmance. For the base model, cross-lingual perfor-\nmance improves progressively with few-shot exam-\nples, as few-shot examples utilize English inputs\nwith explicit target-language, reinforcing input-\noutput alignment.3 In contrast, the instruct model\nexhibits minimal variation across few-shot config-\nurations, as its instruction-tuning inherently sup-\nports multilingual prompting without dependency\non few-shot quantity. These results demonstrate\nthat our approach enhances cross-lingual language",
            "content": "consistency while accommodating training objective differences between base and instruct models. Transferability of Language Vector to PostTrained Models. Interestingly, as shown on the Qwen2.5-0.5B Instruct in Table 6, applying language vectors gathered from the base model to the instruct model achieves comparable performance to its native instruct vectors which suggests the effectiveness of language shift from the base model for cross-lingual control even in the instruct model, despite the representation space of the model is already shifted by post-training which covers instruction tuning, preference-tuning and/or RLHF. This transferability indicates that the relative distance between language-specific and that the resulting language-specific features from the pre-training phase is robust to downstream adaptation, including tasks generalization from instruction-tuning and value alignment in RLHF and preferencetuning. This evidence implies that in the case of the Qwen2.5 model family the cross-lingual symmetry i.e., the geometric alignment between language representations constructed during the fine-tuning is preserved even after various downstream refinement of the model. The preservation of these relationships implies that languagespecific cues are retained as invariant properties across model versions, enabling consistent crosslingual language control through ITLC despite parameter updates during downstream fine-tuning, instruction-tuning, preference-tuning, and RLHF."
        },
        {
            "title": "6 Conclusion",
            "content": "Our work explores the phenomenon of representation alignment in LLMs, confirming its occurrence and elucidating its behavior compared to strictly designed alignment models. We have demonstrated the potential for disentangling language-specific and language-agnostic information, enabling effective language-specific manipulation without semantic loss. Furthermore, we have shown the practical applications of language control manipulation in enhancing language control and mitigating confusion problems. Our findings contribute to deeper understanding of representation alignment in LLMs and open new avenues for improving their performance in multilingual settings."
        },
        {
            "title": "Limitations",
            "content": "3Cross-lingual prompts follow the official format: English inputs with instructions like respond in <TARGET_LANG>. The study has several limitations that should be considered when interpreting the results. First, the coverage of LLMs is limited to specific set of models, particularly Qwen and LaBSE and only one model size (0.5B parameters), which may not be representative of all LLMs. The findings may not generalize to other models with different architectures or training data, as the behavior of representation alignment and language control can vary significantly across different LLMs. Future research should aim to include more diverse range of models to validate the generalizability of the results. Second, the evaluation is conducted on limited number of languages, especially the evaluation of the KNN-based LID method is limited to languages included in the FLORES-200, which may not capture the full spectrum of linguistic diversity. The study focuses on subset of languages, and the results may not extend to languages with different typological features or those that are underrepresented in the training data. Expanding the evaluation to include broader range of languages, especially low-resource languages, would provide more comprehensive understanding of the models capabilities and limitations. Additionally, the human evaluation is based on only 30 samples per language, which may not provide comprehensive assessment of the models performance. While the sample size is sufficient for preliminary analysis, larger dataset would be necessary to draw more robust conclusions. Increasing the number of samples and involving more diverse group of evaluators could enhance the reliability and validity of the findings."
        },
        {
            "title": "Ethical Considerations",
            "content": "The research involves the use of LLMs, which might raise ethical considerations regarding bias, fairness, and transparency on the generated results. To ensure ethical conduct, the study adheres to the following principles: (1) Bias Mitigation: The models used are evaluated for potential biases, and efforts are made to mitigate any identified biases. (2) Fairness: The evaluation is conducted across multiple languages from diverse regions and language families to ensure fairness and inclusivity. (3) Transparency: The methodology and results are presented transparently to allow for replication and verification. (4) Privacy: No personal data is used in the evaluation, and all data is anonymized to protect privacy. (5) Accountability: The researchers take responsibility for the ethical implications of the study and are committed to addressing any concerns that may arise. We also acknowledge that our research utilized AI tools for writing, rewriting, and generating code. Although these tools offer significant advantages in terms of efficiency and productivity, their use raises important ethical considerations. We recognize the potential for bias and errors inherent in AI-generated content and have taken steps to mitigate these risks through rigorous human review and validation. Furthermore, we are mindful of the potential impact on the broader software development community, particularly regarding job displacement and the need for upskilling. We believe that responsible AI integration should prioritize transparency, accountability, and the empowerment of human developers, ensuring that these tools augment rather than replace human expertise. This research aims to contribute to the ongoing dialogue on ethical AI development and usage, advocating for future where AI tools are harnessed responsibly to enhance human creativity and innovation in the field of software engineering."
        },
        {
            "title": "References",
            "content": "David Ifeoluwa Adelani, Hannah Liu, Xiaoyu Shen, Nikita Vassilyev, Jesujoba O. Alabi, Yanke Mao, Haonan Gao, and En-Shiun Annie Lee. 2024. SIB-200: simple, inclusive, and big evaluation dataset for topic classification in 200+ languages and dialects. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 226245, St. Julians, Malta. Association for Computational Linguistics. Rohan Anil, Andrew Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, and 1 others. 2023. Palm 2 technical report. arXiv preprint arXiv:2305.10403. Alan Ansell, Edoardo Maria Ponti, Jonas Pfeiffer, Sebastian Ruder, Goran Glavaš, Ivan Vulic, and Anna Korhonen. 2021. MAD-G: Multilingual adapter generation for efficient cross-lingual transfer. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 47624781, Punta Cana, Dominican Republic. Association for Computational Linguistics. Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, and 32 others. 2022. Constitutional ai: Harmlessness from ai feedback. Preprint, arXiv:2212.08073. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. 2023. multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the AsiaPacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675718, Nusa Dua, Bali. Association for Computational Linguistics. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, and 1 others. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. Samuel Cahyawijaya. 2024. Llm for everyone: Representing the underrepresented in large language models. Preprint, arXiv:2409.13897. Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko Ishii, and Pascale Fung. 2025a. High-dimension human value In Prorepresentation in large language models. ceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 53035330, Albuquerque, New Mexico. Association for Computational Linguistics. Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko Ishii, and Pascale Fung. 2025b. High-dimension human value In Prorepresentation in large language models. ceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 53035330, Albuquerque, New Mexico. Association for Computational Linguistics. Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Dea Adhista, Emmanuel Dave, Sarah Oktavianti, Salsabil Akbar, Jhonson Lee, Nuur Shadieq, Tjeng Wawan Cenggoro, Hanung Linuwih, Bryan Wilie, Galih Muridan, Genta Winata, David Moeljadi, Alham Fikri Aji, Ayu Purwarianti, and Pascale Fung. NusaWrites: Constructing high-quality 2023. corpora for underrepresented and extremely lowresource languages. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 921945, Nusa Dua, Bali. Association for Computational Linguistics. Lang Cao. 2024. Learn to refuse: Making large language models more controllable and reliable through knowledge scope limitation and refusal mechanism. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 36283646, Miami, Florida, USA. Association for Computational Linguistics. Tyler Chang, Zhuowen Tu, and Benjamin Bergen. 2022. The geometry of multilingual language model representations. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 119136, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024. INSIDE: LLMs internal states retain the power of hallucination detection. In The Twelfth International Conference on Learning Representations. Rochelle Choenni, Dan Garrette, and Ekaterina Shutova. 2024. How do languages influence each other? studying cross-lingual data sharing during lm fine-tuning. Preprint, arXiv:2305.13286. Team Cohere, :, Aakanksha, Arash Ahmadian, Marwan Ahmed, Jay Alammar, Milad Alizadeh, Yazeed Alnumay, Sophia Althammer, Arkady Arkhangorodsky, Viraat Aryabumi, Dennis Aumiller, Raphaël Avalos, Zahara Aviv, Sammie Bae, Saurabh Baji, Alexandre Barbet, Max Bartolo, Björn Bebensee, and 211 others. 2025. Command a: An enterprise-ready large language model. Preprint, arXiv:2504.00698. Hanyu Duan, Yi Yang, and Kar Yan Tam. 2024. Do llms know about hallucination? an empirical investigation of llms hidden states. Preprint, arXiv:2402.09733. Christian Federmann, Tom Kocmi, and Ying Xin. 2022. NTREX-128 news test references for MT evaluation of 128 languages. In Proceedings of the First Workshop on Scaling Up Multilingual Evaluation, pages 2124, Online. Association for Computational Linguistics. Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022. LanguagePreprint, agnostic bert sentence embedding. arXiv:2007.01852. Felix Gaschi, Patricio Cerda, Parisa Rastin, and Yannick Toussaint. 2023. Exploring the relationship between alignment and cross-lingual transfer in multilingual transformers. In Findings of the Association for Computational Linguistics: ACL 2023, pages 30203042, Toronto, Canada. Association for Computational Linguistics. Jiyeon Ham and Eun-Sol Kim. 2021. Semantic alignment with calibrated similarity for multilingual senIn Findings of the Association tence embedding. for Computational Linguistics: EMNLP 2021, pages 17811791, Punta Cana, Dominican Republic. Association for Computational Linguistics. Edward Hu, yelong shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations. Tianze Hua, Tian Yun, and Ellie Pavlick. 2024. mOthello: When do cross-lingual representation alignment and cross-lingual transfer emerge in multilingual models? In Findings of the Association for Computational Linguistics: NAACL 2024, pages 15851598, Mexico City, Mexico. Association for Computational Linguistics. Ziwei Ji, Delong Chen, Etsuko Ishii, Samuel Cahyawijaya, Yejin Bang, Bryan Wilie, and Pascale Fung. 2024. LLM internal states reveal hallucination risk faced with query. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, pages 88104, Miami, Florida, US. Association for Computational Linguistics. Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. 2016a. Fasttext.zip: Compressing text classification models. arXiv preprint arXiv:1612.03651. Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. 2016b. Fasttext.zip: Compressing text classification models. arXiv preprint arXiv:1612.03651. Saurabh Kulshreshtha, Jose Luis Redondo Garcia, and Ching-Yun Chang. 2020. Cross-lingual alignment methods for multilingual BERT: comparative In Findings of the Association for Compustudy. tational Linguistics: EMNLP 2020, pages 933942, Online. Association for Computational Linguistics. Jin Myung Kwak, Minseon Kim, and Sung Ju Hwang. 2023. Language detoxification with attributediscriminative latent space. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1014910171, Toronto, Canada. Association for Computational Linguistics. Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, and 1 others. 2023. Bloom: 176bparameter open-access multilingual language model. Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. 2023. Inferencetime intervention: Eliciting truthful answers from language model. In Thirty-seventh Conference on Neural Information Processing Systems. Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, and Sarana Nutanong. 2024. McCrolin: Multi-consistency crosslingual training for retrieval question answering. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 27802793, Miami, Florida, USA. Association for Computational Linguistics. Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, and Sarana Nutanong. 2022. CL-ReLKT: Cross-lingual language knowledge transfer for multilingual retrieval question answering. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 21412155, Seattle, United States. Association for Computational Linguistics. Zhaojiang Lin, Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya, Andrea Madotto, Yejin Bang, Etsuko Ishii, and Pascale Fung. 2021. XPersona: Evaluating multilingual personalized chatbot. In Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI, pages 102112, Online. Association for Computational Linguistics. Andrea Madotto, Samuel Cahyawijaya, Genta Indra Winata, Yan Xu, Zihan Liu, Zhaojiang Lin, and Pascale Fung. 2020. Learning knowledge bases with parameters for task-oriented dialogue systems. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 23722394, Online. Association for Computational Linguistics. Kelly Marchisio, Wei-Yin Ko, Alexandre Berard, Théo Dehaze, and Sebastian Ruder. 2024. Understanding and mitigating language confusion in LLMs. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 6653 6677, Miami, Florida, USA. Association for Computational Linguistics. Arya D. McCarthy, Rachel Wicks, Dylan Lewis, Aaron Mueller, Winston Wu, Oliver Adams, Garrett Nicolai, Matt Post, and David Yarowsky. 2020. The Johns Hopkins University Bible corpus: 1600+ tongues for typological exploration. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 28842892, Marseille, France. European Language Resources Association. Basel Mousi, Nadir Durrani, Fahim Dalvi, Majd Hawasly, and Ahmed Abdelali. 2024. Exploring alignment in shared cross-lingual spaces. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 63266348, Bangkok, Thailand. Association for Computational Linguistics. Jindˇrich Libovický, Rudolf Rosa, and Alexander Fraser. 2020. On the language neutrality of pre-trained multilingual representations. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 16631674, Online. Association for Computational Linguistics. Kathiravan Pannerselvam, Saranya Rajiakodi, Sajeetha Thavareesan, Sathiyaraj Thangasamy, and Kishore Ponnusamy. 2024. SetFit: robust approach for offensive content detection in Tamil-English codemixed conversations using sentence transfer finetuning. In Proceedings of the Fourth Workshop on Speech, Vision, and Language Technologies for Dravidian Languages, pages 3542, St. Julians, Malta. Association for Computational Linguistics. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics. Kiho Park, Yo Joong Choe, and Victor Veitch. 2024. The linear representation hypothesis and the geometry of large language models. In Proceedings of the 41st International Conference on Machine Learning, ICML24. JMLR.org. Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, and Sarana Nutanong. 2025. Towards better understanding of program-ofthought reasoning in cross-lingual and multilingual environments. Preprint, arXiv:2502.17956. Jonas Pfeiffer, Andreas Rücklé, Clifton Poth, Aishwarya Kamath, Ivan Vulic, Sebastian Ruder, Kyunghyun Cho, and Iryna Gurevych. 2020. AdapterHub: framework for adapting transformers. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 4654, Online. Association for Computational Linguistics. Telmo Pires, Eva Schlinger, and Dan Garrette. 2019. How multilingual is multilingual BERT? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 49965001, Florence, Italy. Association for Computational Linguistics. Edoardo Maria Ponti, Goran Glavaš, Olga Majewska, Qianchu Liu, Ivan Vulic, and Anna Korhonen. 2020. XCOPA: multilingual dataset for causal commonsense reasoning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 23622376, Online. Association for Computational Linguistics. Matt Post. 2018. call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186 191, Belgium, Brussels. Association for Computational Linguistics. Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, and 25 others. 2025. Qwen2.5 technical report. Preprint, arXiv:2412.15115. Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers and Iryna Gurevych. 2020. Making monolingual sentence embeddings multilingual usIn Proceedings of the ing knowledge distillation. 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 45124525, Online. Association for Computational Linguistics. Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Sebastian Ruder, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, and 5 others. 2025. Global mmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation. Preprint, arXiv:2412.03304. Advaith Sridhar, Rohith Gandhi Ganesan, Pratyush KuInclude: large mar, and Mitesh Khapra. 2020. scale dataset for indian sign language recognition. MM 20. Association for Computing Machinery. Nishant Subramani, Nivedita Suresh, and Matthew Peters. 2022. Extracting latent steering vectors from pretrained language models. In Findings of the Association for Computational Linguistics: ACL 2022, pages 566581, Dublin, Ireland. Association for Computational Linguistics. Yosephine Susanto, Adithya Venkatadri Hulagadri, Jann Railey Montalan, Jian Gang Ngui, Xian Bin Yong, Weiqi Leong, Hamsawardhini Rengarajan, Peerat Limkonchotiwat, Yifan Mai, and William Chandra Tjhi. 2025. Sea-helm: Southeast asian holistic evaluation of language models. Preprint, arXiv:2502.14301. Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, and Ji-Rong Wen. 2024. Language-specific neurons: The key to multilingual capabilities in large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 57015715, Bangkok, Thailand. Association for Computational Linguistics. Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Etienne Pot, Ivo Penchev, and 197 others. 2025. Gemma 3 technical report. Preprint, arXiv:2503.19786. NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Yan Xu, Etsuko Ishii, Samuel Cahyawijaya, Zihan Liu, Genta Indra Winata, Andrea Madotto, Dan Su, and Pascale Fung. 2022. Retrieval-free knowledgegrounded dialogue response generation with adapters. In Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, pages 93107, Dublin, Ireland. Association for Computational Linguistics. Yinfei Yang, Gustavo Hernandez Abrego, Steve Yuan, Mandy Guo, Qinlan Shen, Daniel Cer, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. 2019a. Improving multilingual sentence embedding using bidirectional dual encoder with additive margin softmax. arXiv preprint arXiv:1902.08564. Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. 2019b. PAWS-X: cross-lingual adversarial dataset for paraphrase identification. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3687 3692, Hong Kong, China. Association for Computational Linguistics. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Preprint, Evaluating text generation with bert. arXiv:1904.09675. Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, and Lidong Bing. 2024a. How do large language models handle multilingualism? In The Thirty-eighth Annual Conference on Neural Information Processing Systems. Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, and Lidong Bing. 2024b. How do large language models handle multilingualism? Preprint, arXiv:2402.18815. Pierre Zweigenbaum, Serge Sharoff, and Reinhard Rapp. 2017. Overview of the second BUCC shared task: Spotting parallel sentences in comparable corpora. In Proceedings of the 10th Workshop on Building and Using Comparable Corpora, pages 6067, Vancouver, Canada. Association for Computational Linguistics. Gabriel Mejia Gonzalez, Prangthip Hansanti, and 20 others. 2022. No language left behind: Scaling human-centered machine translation. Preprint, arXiv:2207.04672. Jörg Tiedemann. 2020. The tatoeba translation challenge realistic data sets for low resource and multilingual MT. In Proceedings of the Fifth Conference on Machine Translation, pages 11741182, Online. Association for Computational Linguistics. Ahmet Üstün, Arianna Bisazza, Gosse Bouma, and Gertjan van Noord. 2020. UDapter: Language adaptation for truly Universal Dependency parsing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 23022315, Online. Association for Computational Linguistics. Nicolas Wagner and Stefan Ultes. 2024. On the controllability of large language models for dialogue interaction. In Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 216221, Kyoto, Japan. Association for Computational Linguistics. Chris Wendler, Veniamin Veselovsky, Giovanni Monea, and Robert West. 2024. Do llamas work in English? on the latent language of multilingual transformers. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1536615394, Bangkok, Thailand. Association for Computational Linguistics. Bryan Wilie, Samuel Cahyawijaya, Junxian He, and Pascale Fung. 2025. High-dimensional interlingual representations of large language models. Preprint, arXiv:2503.11280. Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade Romadhony, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Pascale Fung, Timothy Baldwin, Jey Han Lau, Rico Sennrich, and Sebastian Ruder. 2023. NusaX: Multilingual parallel sentiment dataset for 10 Indonesian local languages. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 815834, Dubrovnik, Croatia. Association for Computational Linguistics. Shijie Wu and Mark Dredze. 2019. Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 833844, Hong Kong, China. Association for Computational Linguistics. Shijie Wu and Mark Dredze. 2020. Do explicit alignments robustly improve multilingual encoders? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 44714482, Online. Association for Computational Linguistics."
        },
        {
            "title": "A Details of All Evaluation Datasets",
            "content": "The following tables present the full details of dataset sizes used in this study. Refer to Table 7, Table 8, Table 9, Table 10 and Table 11."
        },
        {
            "title": "B Detail Experiment for Understanding\nRepresentation Alignment in LLMs",
            "content": "B.1 Cosine Similarity Distributions Across"
        },
        {
            "title": "Datasets",
            "content": "To better understand the representational behavior of the models, we analyzed the distribution of cosine similarity scores across layers. For LaBSE, the average cosine similarity increases from the first layer (mean = 0.6335, std = 0.0920) to the middle layer (mean = 0.7580, std = 0.1182), and remains comparably high in the last layer (mean = 0.7544, std = 0.1150). This trend suggests that semantic alignment becomes stronger toward the middle and final layers, with relatively low variability, indicating consistent behavior across input samples. These observations align with prior findings that intermediate layers in multilingual encoders often capture the most transferable features. In contrast, Qwen2.5-0.5B exhibits markedly different pattern. While the middle layer achieves the highest average similarity (mean = 0.9218, std = 0.0871), the first layer has lower mean and higher variance (mean = 0.5913, std = 0.1650), indicating less stable representations early in the network. Notably, the last layer shows substantial drop in similarity (mean = 0.3745) and sharp increase in variability (std = 0.3988), suggesting divergence in representational behavior, potentially due to task-specific tuning or greater representational fragmentation. This may help explain the weaker correlations between cosine similarity and task performance observed in Qwens final layers. These findings reinforce the role of middle layers in capturing semantically meaningful and transferable representations, particularly in instructiontuned or general-purpose multilingual models. See Figure 2 for the histogram plot and Figure 4 for the bar chart per alignment dataset. B.2 Additional Analysis For Alignment and"
        },
        {
            "title": "Downstream Correlation",
            "content": "SIB200 For LaBSE, correlation values are consistently strong and statistically significant across all layers. The first (Pearson = 0.323), middle (Pearson = 0.309), and last (Pearson = 0.210) layers all demonstrate meaningful positive correlations with performance (p 0), indicating that cosine similarity is well-aligned with task accuracy throughout the network. This suggests that SIB200 benefits from LaBSEs cross-lingual representations, especially in the earlier and middle layers. In contrast, Qwen2.5-0.5B shows very weak but statistically significant correlations (r 0.12 across all layers). While the trends are consistent, the effect sizes are negligible, suggesting that cosine similarity has limited practical influence on performance for Qwen2.5-0.5B on this dataset. INCLUDE-BASE For LaBSE, correlations between cosine similarity and performance are negligible and statistically non-significant across all layers, with Pearson values close to zero (0.041, 0.005, 0.021). This suggests no meaningful alignment between representational similarity and task accuracy. In contrast, Qwen2.5-0.5B exhibits weak but statistically significant positive correlations (Pearson range: 0.140.18), indicating that higher cosine similarity is marginally associated with improved performance. Despite the small effect sizes, these results highlight slight but consistent behavioural alignment in Qwen2.5-0.5B on this dataset. XCOPA For LaBSE, correlation values across layers are weak and statistically insignificant, suggesting minimal alignment between representational similarity and model performance. In contrast, Qwen2.5-0.5B exhibits strong and statistically significant positive correlation in the last layer (Pearson = 0.538, < 0.001), implying that deeper representations may be more predictive for XCOPA. PAWS-X LaBSE shows weak, non-significant positive correlations across layers. However, Qwen2.5-0.5B demonstrates strong positive correlation in the middle layer (Pearson = 0.532, 0.004), suggesting that intermediate representations capture more alignment-relevant features for paraphrase detection. As shown in Table 12, the correlation between cosine similarity and downstream performance varies by dataset, layer, and model architecture. The following sections provide detailed interpretations. Downstream Performance Relative to Random Baselines To provide clearer picture of cross-lingual generalization and behavior alignment, we present set of bar charts"
        },
        {
            "title": "Total",
            "content": "# Languages SIB200 INCLUDE-BASE XCOPA PAWS-X 143,705 890 1,100 345,807 41,820 22,638 5,500 14,000 185,525 23,528 6,600 359,807 205 44 11 Table 7: Dataset sizes and number of languages for downstream tasks. (a) Mean Cosine Similarity Score on LaBSE Model (b) Mean Cosine Similarity Score on Qwen2.5-0.5B Model Figure 4: Layer-wise cosine similarity distributions of LaBSE and Qwen2.5-0.5B models across different datasets. (a) Performance of LaBSE across downstream tasks compared to random baselines. (b) Performance of Qwen2.5-0.5B across downstream tasks compared to random baselines. Figure 5: Comparison of LaBSE and Qwen2.5-0.5B performance across various downstream tasks and their corresponding random baselines. # Languages"
        },
        {
            "title": "Total",
            "content": "# Languages"
        },
        {
            "title": "Dataset",
            "content": "FLORES-200 NTREX-128 NusaX NusaWrites BUCC Tatoeba BibleCorpus"
        },
        {
            "title": "Total",
            "content": "1,012 1,997 400 14,800 35,000 88,877 85,533 204 128 12 9 (language pairs) 4 (language pairs) 112 (language pairs) 828 (language pairs) Table 8: Total example counts and number of languages for alignment tasks. We only use test set for this alignment task."
        },
        {
            "title": "Total",
            "content": "# Languages FLORES-200 NTREX-128 NusaX 997 - 500 1012 1,997 400 2,009 1,997 400 204 128 Table 9: Total example counts per language and number of languages for for LID tasks. comparing the performance of LaBSE and Qwen2.5-0.5B across four downstream evaluation datasetsSIB200, INCLUDE-BASE, XCOPA, and PAWS-Xrelative to their respective random baselines. On XCOPA and PAWS-X, LaBSE yields nearrandom or below-random performance, indicating that its fixed representations struggle with crosslingual commonsense reasoning and paraphrase detection. For SIB200, LaBSE performs slightly above the random baseline, suggesting limited task sensitivity in multilingual sentence similarity settings. However, its performance on INCLUDEBASE remains weak, staying near or below the random baseline and highlighting deficiencies in broader multilingual alignment. In contrast, Qwen2.5-0.5B demonstrates stronger generalization on both SIB200 and INCLUDE-BASE, significantly outperforming its baseline and showing evidence of better cross-lingual task adaptation. However, it faces challenges on XCOPA and PAWS-X, where its performance hovers around or falls below baseline, pointing to possible limitations in zero-shot commonsense reasoning and paraphrase"
        },
        {
            "title": "Total",
            "content": "# Languages FLORES-200 Dolly 997 - 1012 1,800 2,009 -"
        },
        {
            "title": "Monolingual\nAya\nDolly\nOkapi\nNative prompts",
            "content": "Cross-lingual Okapi shareGPT Complex prompts 100 100 100 100 100 100 99 5 5 10 4 14 14 14 Table 11: Total example counts per language and number of languages for Language Confusion tasks, taken from Language Confusion Benchmark. Only test set is available. understanding across languages."
        },
        {
            "title": "These comparisons highlight",
            "content": "the differing strengths and weaknesses of encoder-only and decoder-only multilingual models across select zero-shot evaluation tasks. See Figure 5. B.3 Additional Analysis For Alignment and"
        },
        {
            "title": "LID Correlation",
            "content": "As shown in Table 13, the correlation between alignment (as measured by cosine similarity) and downstream LID performance varies notably across datasets, model architectures, and transformer layers. The following sections provide detailed interpretations for each dataset to contextualize these trends. FLORES-200. On the FLORES-200 dataset, we observe moderate negative correlation between cosine similarity and LID performance for both LaBSE and Qwen2.5-0.5B. The strength of the correlation increases in deeper layers, with the last layer showing the strongest correlation (r = 0.707, < 1031) for LaBSE. Qwen2.5-0.5B, however, exhibits its strongest negative correlation in the middle layer (r = 0.432, < 109), indicating that as the embeddings become more aligned (i.e., higher cosine similarity), the language identity signal tends to weaken, potentially due to semantic abstraction. The statistically significant p-values across all layers confirm the robustness of this relationship. These findings reinforce the idea that high alignment may come at the cost of LID separability, especially in final layers for LaBSE and middle layer for Qwen2.5-0.5B, where representations are more semantically homogenized. Table 10: Total example counts per language and number of languages for Language Control. NTREX-128. For NTREX-128, the correlation trends diverge between the two models. LaBSE"
        },
        {
            "title": "Pearson r",
            "content": "R2 p-value SIB200 INCLUDE-BASE"
        },
        {
            "title": "XCOPA",
            "content": "PAWS-X"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "First\nMiddle\nLast",
            "content": "0.323 0.309 0.210 0.060 0.123 0.043 -0.041 0.005 -0.021 0.183 0.142 0.168 -0.115 -0.026 0.144 0.292 -0.139 0. 0.141 0.270 0.146 0.228 0.532 0.369 0.104 < 10300 0.096 < 10300 0.044 < 10205 0.004 < 1017 0.015 < 1069 < 109 0.002 0.002 0.000 0.000 0.034 0.020 0.028 0.013 0.001 0. 0.085 0.019 0.289 0.020 0.073 0.021 0.052 0.283 0.136 0.233 0.884 0.545 < 107 < 104 < 106 0.458 0.867 0. 0.055 0.368 < 0.001 0.484 0.173 0.467 0.252 0.004 0.059 Table 12: Pearson correlation coefficients (r), R2, and p-values for the relationship between cosine similarity and task performance across different transformer layers on LaBSE and Qwen2.5-0.5B. Dashes () indicate missing values due to unavailable data. Dataset Model Layer Pearson R2 p-value FLORES-200 NTREXNusaX LaBSE Qwen2.5-0.5B LaBSE Qwen2.5-0.5B LaBSE Qwen2.5-0.5B First Middle Last First Middle Last First Middle Last First Middle Last First Middle Last First Middle Last 0.024 -0.122 -0.707 -0.142 -0.432 -0.278 0.254 -0.173 -0.621 -0.232 -0.476 -0.340 -0.566 -0.872 -0.455 -0.873 -0.045 0.001 0.732 0.015 0.084 0.500 < 1031 0.020 0.043 0.186 < 109 0.077 < 104 0.065 0.012 0.030 0.089 0.385 < 1011 0.054 0.021 0.226 < 106 0.001 0.115 0.320 0.760 0.207 0.763 0.002 0.112 0.002 0.218 0.002 0.910 Table 13: Pearson correlation coefficients (r), R2, and pvalues for the relationship between KNN LID F1 score using mean-pooled embedding and alignment cosine similarity across different transformer layers on LaBSE and Qwen2.5-0.5B. exhibits its strongest negative correlation in the the last layer (Pearson = 0.621, < 1011), with positive correlation in the first layer (Pearson = 0.254, = 0.012) and weak negative correlation in the middle (Pearson = 0.173, = 0.089). This suggests that early representations in LaBSE may still retain relatively distinct language features that diminish with depth. In contrast, Qwen2.5-0.5B shows more consistent negative correlations across all layers, particularly in the middle layer (Pearson = 0.476, < 106). These results highlight more uniform degradation of LID-relevant information in Qwens architecture compared to LaBSE. NusaX. For NusaX, alignment-LID correlations exhibit distinct patterns. LaBSE shows weak correlation in the first layer (Pearson = 0.566, = 0.112), highly negative correlation in the middle layer (Pearson = 0.872, = 0.002), and no measurable correlation in the last layer (), which we assume reflects perfect inverse relationship (Pearson 1) due to complete LID failure. Qwen2.5-0.5B follows similar pattern, with its most negative correlation in the middle layer (Pearson = 0.873, = 0.002) and negligible correlations in the first (Pearson = 0.455, = 0.218) and last layers (Pearson = 0.045, = 0.910). The correlations for both models are the most negative observed across all datasets, suggesting alignment disproportionately degrades language signals in low-resource settings. This extreme inverse relationship likely stems from the models lack of prior exposure to NusaX languages during training, limiting their ability to retain language identity in aligned embeddings."
        },
        {
            "title": "C LID Methods and Results",
            "content": "C.1 Methods To investigate language-specific information in multilingual representations, we analyze two distinct paradigms: (1) frozen embeddings from pretrained decoder-only LLMs (Qwen-2.5) and (2) specialized multilingual sentence encoders (LaBSE). We evaluate whether linguistic identity is recoverable from their hidden states and how pooling strategies affect clusterability (via nonparametric KNN retrieval) and linear separability (via supervised classification heads). KNN-based Language Identification. We hypothesize that language identity manifests as separable clusters in the hidden space, which can be detected via non-parametric nearest-neighbor retrieval. For both Qwen-2.5 and LaBSE, hidden states are extracted from the first (ℓ = 1), middle (ℓ = m), and final (ℓ = L) layers. Let Hℓ RT denote the hidden states at layer ℓ for sequence of length . Sentence-level embeddings are derived as follows: Qwen-2.5: Only mean pooling is applied: eℓ mean ="
        },
        {
            "title": "1\nT",
            "content": "T (cid:88) t=1 Hℓ Rd. LaBSE: Both CLS and mean pooling are compared: CLS = Hℓ eℓ [CLS], eℓ mean ="
        },
        {
            "title": "1\nT",
            "content": "T (cid:88) t=1 Hℓ Rd. For each layer ℓ {1, m, L} and pooling strategy pool {mean, CLS}, we construct reference sets: Rℓ pool = (cid:110)(cid:16) pool , y(j)(cid:17)(cid:111)200,204 eℓ,(i,j) i=1,j=1 , where y(j) is the language label for the j-th language in FLORES-200, and indexes the examples within each language. This results in total of 200 204 = 40, 800 reference embeddings. For Qwen-2.5, only Rℓ mean is used, while LaBSE employs both Rℓ CLS and Rℓ mean."
        },
        {
            "title": "CLS Mean",
            "content": "FLORES-200 NTREX-"
        },
        {
            "title": "LaBSE",
            "content": "Qwen2.5-0.5B"
        },
        {
            "title": "First\nMiddle\nLast",
            "content": "80.65 65.11 7.65 93.47 92.99 30.03 88.35 78.85 3.92 95.13 94.18 70. 83.69 55.32 71.73 94.21 91.76 92.46 87.02 71.37 3.45 92.21 92.33 22.91 90.43 81.30 1.63 93.29 92.68 74.36 86.06 54.73 81.86 91.42 90.04 90.27 64.12 33.89 0.54 89.16 88.00 56. 81.78 45.37 0.00 97.30 94.51 65.44 65.79 25.05 29.39 95.55 87.09 88. Table 14: F1 score for KNN and linear classifiers by layer and pooling on FLORES-200, NTREX-128, and NusaX. We evaluate on three test sets: Flores-200, NTREX-128, and NusaX. To ensure fair comparison, we retain only languages overlapping with the FLORES-200 train set: Loverlap = Ltest LFLORES-train, where Ltest is the language set of the test dataset, and LFLORES-train contains the 204 languages in the FLORES-200 train set. For test embedding eℓ test,pool, we compute its L2 distance to all reference embeddings in Rℓ pool: (cid:16) test,pool, eℓ,(i,j) eℓ ref,pool (cid:17) = (cid:13) test,pool eℓ,(i,j) (cid:13)eℓ (cid:13) {1, . . . , 200}, ref,pool (cid:13) 2 (cid:13) (cid:13) 2 , {1, . . . , 204}. The predicted language ˆytest is obtained via majority vote over the = 256 nearest neighbors: ˆytest = arg max lLoverlap (cid:88) 1(y(j) = l), (i,j)Nk where Nk denotes the set of indices for the top-k neighbors, and 1 is the indicator function. Linear Classification Head. To complement our non-parametric analysis, we probe the linear separability of language identity in Qwen-2.5 and LaBSE embeddings. This evaluates whether linguistic boundaries are geometrically aligned with hyperplanes in the hidden space, which would suggest that language control can be achieved through simple affine transformations. Similar to the KNN-based approach, embeddings are extracted identically. For each dataset {FLORES-200, NTREX-128, NusaX} and each layer ℓ {1, m, L} representing early, middle, and last layers respectively, we train separate linear layer to map embeddings eℓ Rd to language logits zℓ RC, where is the number of languages. The classifier for each layer is defined as: zℓ = Wℓeℓ + bℓ, Wℓ RCd, bℓ RC, with cross-entropy loss minimized during training. C.2 Results Our analysis reveals distinct layer-wise behaviors in language identification (LID) performance across LaBSE and Qwen2.5-0.5B models, focus on mean-pooled embedding. KNN-based Language Identification. The KNN method highlights significant performance variations across layers. As shown in Table 2, for LaBSE, the first layer achieves robust results, with mean F1 scores of 88.35% on FLORES-200, 90.43% on NTREX-128, and 81.78% on NusaX. Performance declines moderately in the middle layer, yielding 78.85% for FLORES-200, 81.30% for NTREX-128, and 45.37% for NusaX. The last layer exhibits catastrophic degradation, collapsing to 3.92%, 1.63%, and 0.00% on the respective datasets. This suggests that deeper LaBSE layers lose language-discriminative features critical for KNN classification. For Qwen2.5-0.5B, the first layer similarly outperforms middle layers, with mean F1 scores of 83.69% on FLORES-200, 86.06% on NTREX-128, and 65.79% on NusaX. The middle layer shows the weakest results across all datasets: 55.32%, 54.73%, and 25.05%, respectively, while the last layer partially recovers to 71.73%, 81.86%, and 29.39%. This non-monotonic trend suggests limited retention of language-specific signals in the middle layer of Qwen2.5-0.5B. general linguistic patterns. Table 14 further illustrate the comparative performance across layers and pooling techniques for both LaBSE and Qwen2.5-0.5B models. LaBSE, trained for semantic alignment, shows severe degradation in its final layer, with near-zero F1 scores across datasets, as deeper layers erase language-specific signals required for KNN classification. In contrast, Qwen2.5-0.5B, standard pretrained LLM, experiences performance dip in its middle layer but recovers partially in the final layer, retaining sufficient linguistic discriminability. This divergence underscores key architectural tradeoff: contrastive models like LaBSE discard lexical or syntactic patterns in deeper layers to prioritize semantic invariance, while standard LLMs preserve partial language-identifying features across layers despite progressive abstraction. Linear-probing-based Language Identification. For LaBSE, the First Layer consistently achieves the highest LID F1 scores across all datasets, with significant drop in performance observed in the Last Layer. The NusaX dataset delivers the best overall results, particularly in the First Layer, where it reaches 97.30% F1 score. However, the Last Layer shows notably weaker performance, especially for the FLORES-200 and NusaX datasets. These findings suggest that earlier layers of LaBSE retain more language-identification-relevant features, such as surface-level linguistic cues, compared to deeper layers (see Table 2). Similarly, in the Qwen2.5-0.5B model, the First Layer consistently outperforms the Middle Layer in LID F1 scores across all datasets. The NusaX dataset again produces the best results, with 95.55% F1 score, while NTREX-128 exhibits the lowest performance across all layers. These results indicate that the shallow First Layer of Qwen2.5-0.5B is more effective for language identification tasks than deeper layers, such as the Middle Layer, which shows weaker performance (refer to Table 2). Overall, both models show that their highest LID performance occurs in the First Layer, with F1 scores declining as the layers get deeper. The NusaX dataset consistently yields the best performance, while the Last Layer in LaBSE and the Middle Layer in Qwen2.5-0.5B exhibit the weakest results. These trends suggest that shallow layers retain more language-specific information, which is crucial for language identification, likely due to their greater focus on surface-level features and Classifier Comparison: KNN vs. Linear Head. As shown in Table 14, linear classifiers achieve superior F1 scores compared to KNN across layers, suggesting their ability to identify languagediscriminative features within linearly separable subspaces. However, linear methods exhibit attenuated performance gaps between layers, for instance, the difference between first and middle layers in Qwen2.5-0.5B is less than 5% with linear classifiers, while KNN reveals differences exceeding 30%. Similarly, LaBSEs linear classifier reduces the last-layer performance gap to under 25%, whereas KNN shows near-complete degradation. This contrast implies that parametric linear methods, while more accurate overall, may obscure layer-specific language information degradation In due to their reliance on learned projections. contrast, KNNs non-parametric nature might more directly reflect the geometric structure of embeddings, amplifying sensitivity to layer-wise shifts in language information quality. Pooling Method Comparison: CLS Token vs. Mean. As shown in Table 14, the effectiveness of pooling strategies varies across layers. In first and middle layers, mean pooling achieves superior performance, with F1 margins exceeding 10% over CLS token pooling under KNN. However, in last layers, CLS token pooling shows limited resilience under KNN, marginally outperforming mean pooling in isolated cases despite near-random overall performance. Linear classifiers amplify mean poolings advantage across all layers, suggesting its robustness to layer-specific degradation. This suggests that mean pooling better preserves language-discriminative signals across layers, likely due to its aggregation of token-level features. In contrast, the CLS token, optimized for semantic tasks, exhibits sharper performance declines in deeper layers, particularly under nonparametric methods like KNN. These observations highlight the interplay between pooling strategy, layer depth, and classification method in language identification tasks."
        },
        {
            "title": "D Language Control Results",
            "content": "D.1 Generation Hyperparameter The generation process for the language control and language confusion results uses specific hyperparameter to balance creativity and control. We set max_new_tokens=50 for language control and max_new_tokens=256 for language confusion, and set top_k to 50. We apply nucleus sampling with top_p=0.9, and use moderate temperature of 0.7 to encourage focused yet varied outputs. To reduce repetitive phrases, we apply repetition_penalty of 1.5. For input preparation, we follow the formatting conventions and parameters used by Qwen2.5-0.5 models. D.2 Language Vector Setting Linear Discriminant Analysis (LDA) is utilized to construct language vectors by extracting languagespecific features from the Qwen2.5-0.5B models scaled hidden states, optimizing cross-lingual control through class separability. We evaluate various component sizes (20, 40, 50, 100, 150, 203) to balance LID accuracy and unused variance, fitting an LDA model and training linear neural network (with 10 epochs, Adam optimizer, and CrossEntropyLoss) to achieve peak accuracy of approximately 90.63% at 100 components. The unused variance is minimized, ensuring retained discriminative information for injection (δ) with pruning, which enhances language targeting while the Figure 6 visually confirms this optimal trade-off. D.3 Language Correctness on Different Shift"
        },
        {
            "title": "Strategies",
            "content": "Comparing language correctness of Base and Instruct, respectively (Table 15 and Figure 3) reveals that the Qwen2.5-0.5B-Instruct model significantly enhances cross-lingual language control. It achieves 100% LID correctness with the Seq + Gen shift strategy in ENXX direction, compared to the Base models gen-only average of 87.6%. It suggests the impact of instruct model and our ITLC method in improving language separability and semantic transfer, as supported by prior human evaluations Table 5. Both models excel in XXEN direction (Instruct: 96.7%, Base: 96.0%), reflecting Englishs training dominance  (Table 4)  , though linguistic overlaps (e.g., Korean with Chinese) and weaker ENXX direction performance for low-resource languages like Chinese (Instruct: Language prompt-only gen-only prompt-and-gen ENXX XXEN ENXX XXEN ENXX XXEN ID TH TR JA FR ES ARB KO ZH 90.5 99.0 76.0 85.5 71.0 88.5 92.5 81.0 64.5 99.0 100.0 99.0 100.0 100.0 100.0 100.0 97.5 99.0 87.5 100.0 97.5 100.0 91.5 88.0 91.0 86.5 68.5 100.0 100.0 100.0 100.0 100.0 100.0 100.0 97.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 99.5 100. 95.0 100.0 89.0 98.5 95.0 100.0 100.0 91.5 95.0 Table 15: Language correctness (%) for Qwen2.5-0.5BInstruct across ENXX and XXEN Directions. 68.5% Generated Only) suggest that Seq + Gen is optimal for Instruct. D.4 Cross-lingual Generation Performance As shown in Tables 16 and 17, the Instruct model consistently outperforms the Base model in both ENXX and XXEN direction, particularly in semantic relevance (e.g., ROUGE for Indonesian prompt-and-gen: 13.6 vs. 14.1 and SacreBLEU: 16.89 vs. 12.20). Despite lower or even zero SacreBLEU in some ENXX direction cases (e.g., Thai and Korean), the Instruct model shows improved performance in low-resource directions for XXEN direction, indicating better semantic transfer. This aligns with human evaluations  (Table 5)  and confirms the effectiveness of our LDAbased injection method in enabling cross-lingual generation that maintains both flexibility and semantic fidelity, as further supported by upperbound comparisons  (Table 4)  . D.5 Additional Examples of Cross-lingual"
        },
        {
            "title": "Generation",
            "content": "Figure 7 and Figure 8 present several examples of generated outputs across multiple source languages (fr, tr, zh, ja, ar) targeting English. Overall, our ITLC method successfully shifts to the desired target language and demonstrates effective crosslingual generation. For instance, in the Japanese example in Figure 7, the input prompt is \"Help me come up with three new business ideas.\" The models response with \"I have already developed some ideas...\" (translate with Google Translate) shows that it semantically understands the question, although the correctness of the content remains somewhat limited. Another example, such as in the ENZH direction, shows that the model generates well-formed response in Simplified (Hans) Chinese. The output produces: \"Dear Mom and Dad, Hello everyone! My dear mother, am from... am member of the Figure 6: Controlling the number of language feature representations by using LDA performance accuracy (Left) and unused variance (Right) across number of components. prompt-only gen-only prompt-and-gen prompt-only"
        },
        {
            "title": "Instruct",
            "content": "gen-only prompt-and-gen"
        },
        {
            "title": "Language",
            "content": "BS"
        },
        {
            "title": "Rog",
            "content": "SB"
        },
        {
            "title": "ID\nTH\nTR\nJA\nFR\nES\nAR\nKO\nZH",
            "content": "51.8 58.5 47.7 60.1 51.8 39.3 59.8 53.4 53.0 0.9 4.9 1.0 9.1 9.5 0.7 0.8 0.8 4.9 2.36 3.20 0.00 2.22 9.54 1.41 1.45 0.00 2.36 BS 57.6 52.6 54.4 55.9 54.8 52.5 52.1 58.5 57."
        },
        {
            "title": "Rog",
            "content": "1.3 5.6 3.1 9.7 11.2 0.9 1.3 1.2 7.7 SB 0.00 3.46 0.00 7.05 5.86 0.00 0.00 0.00 6.02 BS 53.7 58.7 47.2 59.3 47.7 40.2 56.5 53.3 55."
        },
        {
            "title": "Rog",
            "content": "0.3 7.6 2.0 10.8 10.4 0.4 1.4 0.8 8.2 SB 0.00 3.75 8.12 7.33 4.62 4.97 4.20 10.68 10.60 BS 63.6 64.1 60.2 61.5 63.2 64.4 63.5 62.0 62."
        },
        {
            "title": "Rog",
            "content": "10.4 1.5 7.9 4.4 11.1 16.0 0.8 4.1 1.3 SB 14.30 15.97 1.43 15.97 10.97 7.17 4.75 3.58 0.00 BS 63.9 58.0 58.9 59.3 60.1 63.6 62.0 63.8 63."
        },
        {
            "title": "Rog",
            "content": "1.2 7.0 3.0 9.7 12.7 0.4 3.0 1.66 9.3 SB 0.00 15.97 9.65 4.82 4.10 11.88 4.11 0.00 6.90 BS 63.7 58.4 57.3 58.0 59.8 65.5 55.1 59.3 63."
        },
        {
            "title": "Rog",
            "content": "0.9 8.7 4.0 8.6 12.7 0.2 0.8 0.1 10.5 SB 0.00 4.93 0.00 5.37 2.74 6.57 2.63 0.00 5.37 Table 16: Comparison of Generative Performance for Base & Instruct in ENXX Direction. BS denote as BertScore (F1), Rog is ROUGE-1, and SB is for SacreBLEU. research and development...\"demonstrating clear semantic alignment with the prompt. However, as with the previous case, the accuracy and relevance of the content could still be limited."
        },
        {
            "title": "E Language Confusion Result",
            "content": "Ablation Study of Scaling for Different Language Vector Injection Strategies As shown in Table 19, Table 20 and Table 21 Our analysis reveals distinct optimal scaling factors for crosslingual LCPR across injection strategies: promptonly achieves peak performance at scaling 0.8 (65.71), gen-only at 0.6 (71.35), and prompt-andgen at 0.5 (78.93). Notably, prompt-and-gen outperforms other strategies, suggesting combined injection better preserves cross-lingual alignment. However, applying language vector shifts to monolingual4 tasks degrades performance as scaling increases. This suggests that applying shift vectors to monolingual inputs does not amplify languagespecific features but instead displaces the original distribution, degrading the performance. 4In monolingual (source = target) settings, δ = vorig is applied via = + αδ. Cross-lingual Language Control via Language Shift Vectors. As shown in Table 24 and Table 25, our method ITLC substantially improves cross-lingual language control, as evidenced by enhanced LCPR scores when applying language shift vectors. In cross-lingual settings, the prompt-andgen strategy achieves peak performance, with base shift vectors attaining 78.93% LCPR for the base model and 81.51% for the instruct model. While gen-only and seq-only strategies demonstrate moderate gains of 71.35% and 65.71% respectively for the base model, and 75.56% and 76.05% for the instruct model, they are consistently outperformed by the prompt-and-gen approach. Notably, base shift vectors achieve marginally higher LCPR compared to their instruct counterparts across both models, with 78.93% versus 76.06% LCPR for base model configurations and 81.51% versus 80.96% for the instruct model. This consistent advantage suggests that base vectors retain more language-specific information critical for cross-lingual adaptation, likely attributable to their training objectives emphasizing multilingual representation rather than task-specific alignment. detailed breakdown of the LCPR scores per language for both the base and instruct models is presented in Table 22 and prompt-only BS 59.5 62.1 53.2 62.1 61.8 63.2 62.4 59.3 56."
        },
        {
            "title": "Rog",
            "content": "14.1 13.7 11.1 14.1 16.7 16.8 15.0 13.3 13.3 SB 7.93 6.19 14.51 15.97 8.83 10.89 9.32 15.32 15."
        },
        {
            "title": "Base",
            "content": "gen-only prompt-and-gen prompt-only"
        },
        {
            "title": "Instruct",
            "content": "gen-only prompt-and-gen BS 59.8 60.6 60.6 57.9 58.5 60.0 56.9 61.1 56."
        },
        {
            "title": "Rog",
            "content": "13.8 14.3 13.2 14.3 14.7 15.4 13.3 16.7 13.5 SB 9.31 11.18 12.67 9.84 9.73 6.14 14.60 11.83 6.43 BS 59.9 62.2 55.2 61.5 60.6 63.5 63.1 60.7 56."
        },
        {
            "title": "Rog",
            "content": "14.1 14.4 11.8 15.2 15.6 16.7 15.1 16.8 13.2 SB 12.20 14.40 14.18 11.91 8.66 11.38 19.28 9.84 16.44 BS 62.5 62.0 62.0 62.7 64.2 64.9 63.3 63.2 62."
        },
        {
            "title": "Rog",
            "content": "13.9 13.8 12.8 14.9 17.1 18.1 14.4 16.3 14.9 SB 4.76 4.93 8.45 5.73 5.68 4.38 6.61 6.73 9.59 BS 63.9 62.3 62.5 63.2 64.9 65.4 63.1 61.5 62."
        },
        {
            "title": "Rog",
            "content": "15.7 15.4 14.3 17.0 18.0 18.5 15.3 14.4 14.5 SB 7.97 5.59 13.61 6.89 8.64 5.99 10.43 6.27 4.89 BS 62.2 62.1 61.8 62.4 64.5 64.8 62.3 61.0 61."
        },
        {
            "title": "Rog",
            "content": "13.6 13.8 13.1 14.7 17.2 17.6 13.7 13.0 13.9 SB 16.89 11.12 8.70 12.17 6.08 7.17 6.22 10.96 6."
        },
        {
            "title": "ID\nTH\nTR\nJA\nFR\nES\nAR\nZH\nKO",
            "content": "Table 17: Comparison of Generative Performance for Base & Instruct in XXEN Direction. BS denote as BertScore (F1), Rog is ROUGE-1, and SB is for SacreBLEU. Target Language Monolingual ITLC SacreBLEU BertScore (F1) SacreBLEU BertScore (F1) ID TH TR JA FR ES AR ZH KO 4.58 0.0 8.47 0.0 8.61 12.28 4.90 0.0 9.55 60.4 60.4 57.7 57.5 58.8 60.3 57.0 59.2 57.2 10.6 1.45 3.75 8.12 7.33 9.54 4.97 10.68 4.2 57.1 57.6 58.7 54.4 60.1 54.8 52.5 58.5 59.8 Table 18: Generation performance for different target languages with Qwen2.5-0.5B. Mono Baseline denotes the model prompted in the same language as the desired target language."
        },
        {
            "title": "Monolingual",
            "content": "Cross-lingual"
        },
        {
            "title": "LPR WPR",
            "content": "gen-0.1 gen-0.2 gen-0.3 gen-0.4 gen-0.5 gen-0.6 gen-0.7 gen-0.8 gen-0.9 gen-1.0 64.75 65.35 62.61 59.61 59.61 60.05 58.01 52.45 47.07 40.44 83.99 85.09 86.55 86.23 86.85 87.49 87.41 82.78 75.83 71.15 63.85 65.01 59.29 54.95 54.76 58.14 55.72 52.35 50.58 54.91 35.07 39.93 48.08 57.49 67.00 71.35 69.39 65.84 58.61 51.25 24.79 28.96 38.97 57.82 74.04 80.46 80.73 75.74 68.51 61. 74.92 75.92 71.16 64.37 66.07 67.67 66.57 65.93 63.73 61."
        },
        {
            "title": "Monolingual",
            "content": "Cross-lingual"
        },
        {
            "title": "LPR WPR",
            "content": "prompt-0.1 prompt-0.2 prompt-0.3 prompt-0.4 prompt-0.5 prompt-0.6 prompt-0.7 prompt-0.8 prompt-0.9 prompt-1.0 64.86 66.39 65.59 65.45 65.87 64.92 64.78 63.69 61.25 60.39 81.01 82.14 82.86 82.79 82.73 82.64 81.03 80.40 75.81 74.98 65.67 66.75 65.78 65.53 62.50 65.24 65.52 65.28 64.15 63.87 33.97 38.88 46.03 57.20 62.93 63.91 64.63 65.71 64.59 62.97 23.75 28.91 37.86 51.97 61.63 63.83 66.09 66.41 64.79 63. 74.74 75.37 72.56 72.27 73.43 73.20 71.74 74.24 73.30 72.79 Table 19: Performance (LCPR / LPR / WPR) of the Qwen2.5-0.5B model under the prompt-only setting with base shift vector, evaluated across different language vector scaling factors, α. Table 23. Impact of Few-Shot Prompting on Monolingual and Cross-lingual Performance. As shown in Table 13 and Table 14, for the base model, monolingual settings exhibit performance degradation with increasing few-shot examples, as LCPR drops from 65.27% to 54.47%. This decline likely arises from the inclusion of multilingual few-shot examples,5 creating conflicting linguisTable 20: Performance (LCPR / LPR / WPR) of the Qwen2.5-0.5B model under the generated-only setting with base shift vector, evaluated across different language vector scaling factors, α."
        },
        {
            "title": "Monolingual",
            "content": "Cross-lingual"
        },
        {
            "title": "LPR WPR",
            "content": "prompt-and-gen-0.1 prompt-and-gen-0.2 prompt-and-gen-0.3 prompt-and-gen-0.4 prompt-and-gen-0.5 prompt-and-gen-0.6 prompt-and-gen-0.7 prompt-and-gen-0.8 prompt-and-gen-0.9 prompt-and-gen-1.0 64.21 63.25 62.94 60.79 59.98 57.01 53.56 49.00 40.41 36.60 84.27 86.34 88.24 88.06 87.11 86.37 82.91 77.27 70.51 70.01 63.77 61.76 60.85 59.09 59.41 55.90 53.63 51.33 48.16 51.30 39.48 50.04 64.22 75.88 78.93 77.21 72.57 68.22 60.97 52.51 28.69 41.18 64.18 80.58 85.08 84.13 81.98 76.80 69.07 61. 75.74 75.07 72.53 75.78 77.15 74.90 71.51 70.08 66.44 63.82 Table 21: Performance (LCPR / LPR / WPR) of the Qwen2.5-0.5B model under the prompt-and-generated setting with base shift vector, evaluated across different language vector scaling factors, α. tic signals. In cross-lingual settings, LCPR improves progressively from 29.41% to 56.78%, as few-shot examples utilize English inputs with explicit target-language directives6, reinforcing input-output alignment. This indicates that the model demonstrates stronger cross-lingual adap5Few-shot examples are drawn directly from the original benchmark implementation, which includes languages distinct from the target language. 6Cross-lingual prompts follow the benchmarks original structure: English inputs with instructions like Respond in <TARGET_LANG>. Figure 7: Examples of generated outputs from Qwen2.5-0.5B-Instruct with injection in XXEN. tation with English-centric prompting. The instruct model exhibits minimal variation across few-shot configurations, with monolingual LCPR ranging between 74.52% and 75.59%, and crosslingual between 63.00% and 64.56%, suggesting its instruction-tuning enables robust multilingual prompting without dependency on few-shot examples. This stability implies that the instruct models training on aligned multilingual inputs maximizes its cross-lingual capability priori, rendering fewshot augmentation redundant. Chat/QA Template Efficacy Across Settings. As shown in Table 24 and Table 25, structured templates7 exhibit divergent impacts on monolingual and cross-lingual performance. For the base Qwen2.5-0.5B, introducing QA template (0-shot) degrades monolingual LCPR from 65.27% to 59.26% but improves cross-lingual performance from 29.41% to 44.68%, suggesting that taskspecific formatting disrupts monolingual focus while aiding cross-lingual alignment. Conversely, 7QA template: Q: A: format; chat template: modelspecific structure from instruction-tuning. the instruct model Qwen2.5-0.5B-Instruct maintains stable monolingual LCPR performance with its chat template from 74.79% to 74.52% , while achieving substantial cross-lingual gains from 38.75% to 63.00%. This contrast underscores critical trade-off: task-aligned templates enhance cross-lingual consistency for both models but introduce monolingual interference in base architectures. The instruct models robustness stems from its training on conversational formats, which harmonizes template usage with its intrinsic multilingual capabilities."
        },
        {
            "title": "F Annotation Guidelines",
            "content": "F.1 Context of the Annotation Task The annotation task involves evaluating the quality of cross-lingual language generation, where model generates responses in target language based on input prompts in source language. The goal is to assess how well the model performs in terms of naturalness, relevance, and answer correctness. This evaluation is crucial for understanding the models capabilities and identifying areas for Figure 8: Examples of generated outputs from Qwen2.5-0.5B-Instruct with injection in ENXX. improvement. dress the prompt. F.2 Detailed Scoring Guidelines F.2.1 Naturalness (1-5): 1: The response sounds very unnatural, robotic, or translated. It lacks fluency and typical language patterns of the target language, making it sound artificial and unnatural. 2: The response is somewhat unnatural, with noticeable awkwardness or unnatural word choices. It may sound stilted or forced. 3: The response is moderately natural, with some minor awkwardness but generally understandable. It flows reasonably well but has room for improvement. 4: The response is mostly natural, with only slight deviations from typical language use. It sounds almost native-like but may have minor imperfections. 5: The response is completely natural, indistinguishable from text written by native speaker. It flows smoothly and uses language patterns typical of the target language. F.2.2 Relevance (1-5): 1: The response is completely irrelevant to the input prompt. It fails to address the topic or question posed. 2: The response is somewhat relevant but misses key points or goes off-topic. It may touch on related ideas but does not fully ad3: The response is moderately relevant, addressing some aspects of the prompt but lacking completeness. It covers some key points but omits important details. 4: The response is highly relevant, addressing most key points of the prompt. It provides comprehensive answer but may miss minor details. 5: The response is completely relevant, fully addressing all aspects of the prompt. It covers all key points and provides thorough answer. F.2.3 Correctness (1-5): 1: The response contains major factual errors or inaccuracies. It provides incorrect information or contradicts known facts. 2: The response contains some factual errors or inaccuracies. It may be partially correct but includes misleading or incorrect details. 3: The response is mostly correct but may have minor inaccuracies or omissions. It is generally accurate but requires minor corrections. 4: The response is highly accurate, with only minor details potentially incorrect. It is reliable and trustworthy but may have small errors. 5: The response is completely accurate and factually correct. It provides precise and reliable information without any errors. Qwen2.5-0.5B + Q/A template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) Monolingual AVG AR DE EN ES FR HI ID IT JA KO PT RU TR VI ZH 65.27 92.68 63.57 45.29 70.99 59.46 59.26 59.56 71.46 50.98 74.57 62.64 56.12 72.37 65.25 52.24 60.05 41.22 51.59 66.87 57.53 53.90 64.04 50.61 52.52 65.04 50.91 55.18 73.01 62.51 54.16 66.91 50.36 53.80 68.50 63.79 54.47 68.36 67.17 49.14 71.24 62.67 2.02 0.00 2.04 0.00 6.00 6.32 7.89 68.70 60.71 81.21 85.55 55.04 94.27 72.47 37.96 89.11 65.58 63.10 46.40 69.64 61.47 76.76 42.58 58.63 85.57 67.18 67.88 36.74 78.44 49.31 80.84 50.66 60.78 56.79 69.51 57.44 35.07 42.73 45.60 66.81 48.13 50.90 64.74 70.36 53.43 29.06 61.98 48.50 54.37 57.60 44.07 55.76 62.89 72.09 39.24 59.63 49.35 78.60 34.68 59.03 47.25 69.72 60.08 31.92 53.69 48.92 78.94 37.62 51.87 57.79 63.69 94.24 67.06 32.69 70.51 47.82 60.05 93.86 59.82 59.98 94.70 59. 82.15 59.35 78.86 71.04 55.92 89.26 71.99 46.62 87.82 47.89 23.20 15.24 74.16 49.98 88.18 73.91 35.17 88.42 82.46 67.74 93.74 74.82 43.01 85.28 83.74 34.48 94.24 80.98 60.93 94.85 55.13 26.13 6.95 7.82 0.00 4.04 63.11 93.82 59.95 38.97 70.31 48.53 55.89 95.67 57.57 38.31 18.47 43.66 29.49 58.48 94.94 58.88 9.76 3. 0.00 4.04 6.00 72.45 63.44 85.45 76.42 52.98 87.61 65.56 44.49 86.68 72.47 43.50 85.43 76.10 27.18 90.30 75.99 57.39 86.19 71.94 56.36 85.67 80.18 25.30 89.33 76.51 67.98 87.82 AVG AR DE EN ES FR HI ID IT JA KO PT RU TR VI ZH Cross-lingual Qwen2.5-0.5B + Q/A template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) 29.41 29.98 36.11 44.68 47.08 49.89 47.42 43.69 52.73 49.36 50.88 53.62 53.16 63.00 56.57 55.03 61.82 52.35 56.78 67.70 57.20 65.71 83.36 62.48 71.35 79.36 82.60 78.93 96.23 79.77 + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) 63.08 81.38 65.14 68.70 82.17 79.48 76.06 94.23 82.17 5.48 5.88 37.29 34.14 12.45 10.36 32.04 42.23 37.63 33.72 27.75 37.52 35.01 58.09 59.10 57.08 50.16 24.36 17.90 48.78 62.13 48.29 46.28 50.48 56.13 58.55 10.13 62.77 57.21 25.30 37.61 48.29 66.68 54.92 46.57 43.33 67.67 60.27 27.93 40.40 52.86 65.56 58.32 48.10 31.48 61.12 63.58 65.21 65.78 28.84 38.33 54.44 71.05 65.83 54.10 42.52 62.67 68.08 64.14 64.13 12.06 71.80 65.13 30.72 43.88 61.73 77.83 64.57 57.66 42.55 63.01 62.19 21.43 71.42 67.88 37.83 44.35 57.55 76.36 68.56 58.15 41. 8.93 7.84 75.77 67.50 10.48 73.30 70.83 60.04 61.90 69.90 83.27 69.29 57.15 74.67 82.03 73.65 45.68 79.38 71.78 56.47 72.54 71.29 56.98 86.33 66.59 74.16 86.94 76.30 50.05 81.14 75.33 62.18 78.08 77.27 90.44 89.11 79.00 83.15 77.39 66.16 14.03 74.94 66.50 49.36 55.18 66.28 77.59 67.34 60.07 61.79 80.57 67.16 37.69 76.92 68.98 56.01 72.72 78.02 44.59 85.17 83.96 48.33 81.49 70.67 41.06 80.42 71.20 61.02 80.39 79.89 86.78 89.33 84.36 61.85 Table 22: Language Confusion Pass Rate (LCPR) of the base model across monolingual and cross-lingual settings, with detailed language-wise breakdown. F.3 Additional Notes Contextual Understanding: Annotators should consider the context of the input prompt and the intended audience when evaluating naturalness and relevance. response that is natural and relevant in one context may not be in another. Consistency: Annotators should strive for consistency in their annotations across different examples. This helps ensure that the evaluation is fair and reliable. Examples: Providing clear examples of each rating level for each category can help annotators understand the expected standards and make consistent judgments. Feedback: Encourage annotators to provide feedback on ambiguous cases or areas where the guidelines could be improved. This can help refine the annotation process and improve the quality of the evaluations. Qwen2.5-0.5B-Instruct + Chat template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) Monolingual AVG AR DE EN ES FR HI ID IT JA KO PT RU TR VI ZH 74.79 93.58 73.98 48.80 85.14 77.26 74.52 92.09 58.59 43.26 88.17 78.38 74.04 90.73 71.13 40.45 88.07 77.80 74.46 93.32 68.33 44.00 87.13 73.94 74.59 92.80 67.53 39.84 86.74 77.08 75.59 90.18 65.06 48.57 87.71 77.91 74.15 93.91 65.20 47.13 88.29 78. 0.00 0.00 4.04 7.67 4.04 0.00 3.96 84.86 68.60 76.09 85.08 81.02 93.78 80.58 84.47 88.63 81.37 84.41 79.98 84.94 84.31 87.47 85.37 75.98 93.51 75.02 82.54 81.83 86.58 80.82 88.01 82.06 68.82 92.66 78.43 83.85 81.20 79.84 82.20 87.31 87.13 70.33 92.17 78.88 80.62 79.95 82.77 82.63 91.38 89.91 73.06 91.64 81.06 82.06 80.39 89.78 82.45 92.64 83.44 80.46 92.20 77.72 84.10 78.72 84.82 82.77 88.62 82.06 66.08 90.74 67.33 95.38 66.65 26.10 90.89 81.03 67.00 94.18 66.43 67.73 94.02 63.95 13.12 89.30 71.87 83.17 76.72 85.44 76.09 86.10 16.00 86.38 48.05 91.88 87.25 68.22 13.08 77.38 70.97 68.02 75.42 84.97 41.77 83.31 70.00 97.22 80.41 66.67 80.31 65.43 81.93 48.58 83.76 71.83 96.95 7.77 0. 6.82 66.78 94.72 78.69 21.89 88.08 81.47 67.42 95.32 55.00 68.20 94.37 68.64 75.28 81.25 81.85 66.88 82.68 15.49 82.22 58.21 91.01 84.18 65.16 24.28 84.21 73.80 75.07 57.39 79.23 59.88 85.18 75.43 92.18 84.98 67.53 12.94 79.18 79.52 80.00 69.97 79.83 47.74 85.60 69.94 93.24 4.95 9.52 1.98 Cross-lingual AVG AR DE EN ES FR HI ID IT JA KO PT RU TR VI ZH Qwen2.5-0.5B-Instruct + Chat template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) 38.75 44.30 42.95 63.00 74.74 61.66 63.95 75.31 66.12 64.56 75.83 67.02 64.25 74.91 64.20 63.80 78.38 62.61 63.53 75.76 63.36 76.05 93.60 71.59 75.56 92.44 82.65 81.51 94.49 84.06 + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) 73.26 91.28 74.62 73.95 92.41 84.15 80.96 94.68 86.56 48.06 43.43 77.35 70.44 80.44 72.65 78.82 75.76 79.27 73.69 77.70 71.23 75.19 75.44 0.66 5.86 5.25 2.68 4.57 6.51 2.61 37.95 38.65 37.06 30.16 45.25 49.84 41.91 44.24 38.10 67.16 70.20 58.01 53.94 72.04 82.30 67.27 64.49 56.57 70.23 70.03 57.57 53.42 74.46 81.45 70.14 61.64 56.62 67.62 70.97 56.57 54.69 74.87 79.45 71.55 66.39 61.59 70.46 70.71 60.90 52.55 74.44 78.99 70.51 64.15 60.15 65.33 68.04 60.90 53.70 74.73 79.07 70.74 63.96 60.28 69.80 69.20 56.86 51.94 74.81 79.62 68.07 70.17 56.56 90.78 82.49 12.44 80.52 83.92 78.46 76.41 84.95 67.93 82.36 72.52 86.68 86.31 80.93 72.07 72.22 83.15 54.31 75.74 81.85 31.36 87.29 73.29 84.22 91.91 85.26 63.23 79.22 84.94 55.01 80.40 86.46 80.19 85.92 82.87 87.25 6. 87.32 76.08 82.48 83.50 71.94 77.84 83.83 54.01 78.22 74.54 83.48 82.26 77.59 64.81 71.76 83.04 62.62 73.90 85.09 23.87 84.18 72.57 77.07 88.33 82.43 65.21 74.37 86.26 64.68 78.02 88.78 65.62 87.66 81.74 89.12 Table 23: Language Confusion Pass Rate (LCPR) of the instruct model across monolingual and cross-lingual settings, with detailed language-wise breakdown. Method Monolingual Cross-lingual Method Monolingual Cross-lingual Qwen2.5-0.5B + Q/A template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) LCPR LPR WPR LCPR LPR WPR 65.27 59.26 56.12 51.59 52.52 54.16 54.47 81.58 59.91 55.38 49.70 51.51 52.95 53.62 65.15 73.35 73.70 70.98 72.07 74.15 70.40 29.41 44.68 47.42 49.36 53.16 55.03 56. 19.75 35.36 37.95 41.64 46.65 48.23 50.63 73.45 75.94 75.42 75.03 77.07 77.60 76.16 63.69 60.05 59.98 80.40 87.49 87.11 65.28 58.14 59.41 65.71 71.35 78. 66.41 80.46 85.08 74.24 67.67 77.15 Qwen2.5-0.5B-Instruct + Chat template (0-shot) + 1-shot + 2-shot + 3-shot + 4-shot + 5-shot + ITLC (apply base shift vector) + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) + ITLC (apply instruct shift vector) LCPR LPR WPR LCPR LPR WPR 74.79 74.52 74.04 74.46 74.59 75.59 74.15 82.61 83.66 82.75 83.47 84.11 84.45 82.87 77.94 77.12 76.52 74.07 76.27 77.52 76.37 38.75 63.00 63.95 64.56 64.25 63.80 63. 27.22 57.69 59.24 59.86 59.74 58.89 58.79 78.40 79.50 79.50 78.76 78.45 79.52 75.34 67.33 67.00 67.73 74.82 84.07 81.70 76.35 65.83 68.96 76.05 75.56 81. 77.68 82.42 85.32 81.11 74.51 80.55 + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) 63.11 55.89 58.48 79.95 86.38 87.24 64.18 55.32 57. 63.08 68.70 76.06 63.77 78.99 82.31 73.04 65.36 75.74 + prompt-only (α = 0.8) + gen-only (α = 0.6) + prompt-and-gen (α = 0.5) 66.78 67.42 68.20 74.96 83.64 82. 73.08 65.46 68.05 73.26 73.95 80.96 76.37 84.06 86.79 79.20 71.40 78.84 Table 24: Performance (LCPR / LPR / WPR) of base model under monolingual and cross-lingual settings. Table 25: Performance (LCPR / LPR / WPR) of instruct model under monolingual and cross-lingual settings."
        }
    ],
    "affiliations": [
        "AI Singapore",
        "Capital One",
        "Cohere",
        "Kreasof AI",
        "MBZUAI",
        "SEACrowd",
        "Universitas Indonesia"
    ]
}