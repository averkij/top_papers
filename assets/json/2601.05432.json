{
    "paper_title": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization",
    "authors": [
        "Yuxiang Ji",
        "Yong Wang",
        "Ziyu Ma",
        "Yiming Hu",
        "Hailang Huang",
        "Xuecai Hu",
        "Guanhua Chen",
        "Liaoni Wu",
        "Xiangxiang Chu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model \\textit{Thinking with Map} ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\\% to 22.1\\% compared to \\textit{Gemini-3-Pro} with Google Search/Map grounded mode."
        },
        {
            "title": "Start",
            "content": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization Yuxiang Ji1,2* Yong Wang2 Ziyu Ma2 Yiming Hu2 Hailang Huang2 Xuecai Hu2 Guanhua Chen3 Liaoni Wu1 Xiangxiang Chu2 1Xiamen University 2AMAP, Alibaba Group 3Southern University of Science and Technology https://amap-ml.github.io/Thinking-with-Map 6 2 0 2 ] . [ 1 2 3 4 5 0 . 1 0 6 2 : r (Up) The illustration of complete Thinking with Map process. (Bottom) Comparison with up-toFigure 1: date openand closed-source models on three geolocalization benchmarks. Our method is built upon the model Qwen3-VL-30B-A3B. POI represents Point of Interest."
        },
        {
            "title": "Abstract",
            "content": "The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-ofthought reasoning, and agentic capabilities, but overlook common strategy used by humans using maps. In this work, we first equip the model Thinking with Map ability and formulate it as an agent-in-the-map loop. We develop two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The *Work done during internship at AMAP, Alibaba Group. Project lead. RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-thewild images, we further present MAPBench, comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing openand closed-source models on most metrics, specifically improving Acc@500m from 8.0% to 22.1% compared to Gemini-3-Pro with Google Search/Map grounded mode. Figure 2: The Thinking with Map trajectories from parallel sampling. The abundant map-API results make the trajectories easily verified based on their causal relationships."
        },
        {
            "title": "Introduction",
            "content": "knowledge. Image geolocalization is challenging task to determine the latitude and longitude of an image as accurately as possible. Conventional vision research typically attributes this problem to classification (Seo et al., 2018; Weyand et al., 2016; Müller-Budack et al., 2018; Clark et al., 2023) or retrieval (Ji et al., 2025a,b; Haas et al., 2024; Yang et al., 2021; Jia et al., 2024) task, achieving localization by predicting region-level cell or retrieving the most similar image from geo-tagged database. Although these methods are well established in applications such as indoor localization (Taira et al., 2018; Sarlin et al., 2019) and landmark recognition (Arandjelovic et al., 2016; Noh et al., 2017; Weyand et al., 2020; Zheng et al., 2009), they treat the entire image as coupled feature for discrimination and fail to disentangle independent clues. This less interpretable paradigm is inherently constrained by the training data and is difficult to generalize to images in the wild. In the era of large vision-language models (LVLM), geolocalization can be viewed as natural testbed for vision, understanding and reasoning. Beyond single-image discriminative paradigm, it requires LVLMs to inspect visual clues (e.g., climate, architecture, and cultural context) in detail, and reason over the complex intersection of evidence to make the final prediction. This process is closer to how human beings behave when inferring image locations. Recent studies follow frontier models (DeepSeek-AI et al., 2025; OpenAI, 2025; Google DeepMind, 2025b; Bai et al., 2025; Seed, 2025; Wang et al., 2025a) to further enhance such behavior by using chain-of-thought (CoT) reasoning (Li et al., 2024, 2025a; Jia et al., 2025) and incorporating external tools within the reasoning chain (Lai et al., 2025; Su et al., 2025; Qian et al., 2025; Wang et al., 2025b). However, despite their increased reasoning capability, these methods still depend on the model internal reasoning ability over In contrast, human beings rarely rely on internal reasoning alone for geolocalization. When identifying visual clues, humans typically propose multiple location hypotheses and then verify them in turn using map tools. By querying points of interest (POIs), examining road topology, and checking spatial consistency, maps provide an essential mechanism for validating visual clues against realworld geography. Surprisingly, despite being the most fundamental tool for geolocalization, maps are almost absent from existing LVLM-based methods. To bridge this gap, we equip the LVLM with map tools for the first time, enabling the model to Think with Map. Specifically, we expose map interfaces such as keyword search, POI details lookup, and static map query as callable tools, allowing the model to retrieve information and verify visual clues in the structured map environment during reasoning. As illustrated in Figure 1, the process of Thinking with Map is multi-turn agentic behavior. The model invokes tools based on multiple visual clues, then cross-validates the gathered evidence to produce the final prediction. We further formulate this localization process as an agent-in-the-map loop, in which the agent iteratively proposes and verifies location hypotheses. Similar to human beings, when the model encounters an ambiguous image, it needs to go through an iterative process of repeated hypothesis generation and verification. However, simply increasing the reasoning budget to let the model explore sequentially not only leads to context explosion, but has also been found to yield marginal gains (Wen et al., 2025; Zheng et al., 2025a). Inspired by the success of Google Gemini in parallel thinking (Google DeepMind, 2025a), we also enable the model to explore multiple hypotheses in parallel paradigm. Unlike conventional reasoning tasks, Thinking with Map inherently leaves large number of map-API results in the reasoning trace. These factual outputs make the reasoning trajectory largely self-verifying. As Figures 2 and 4, we find that the LVLM can easily identify the better trajectory among multiple parallel Thinking with Map trajectories by causal relationships. Based on this observation, we introduce simple parallel sampling with verifier framework for test-time scaling (TTS) in Thinking with Map. To further improve the models pass@K performance and enable more effective parallel sampling, we conduct agentic Reinforcement Learning (RL) training for Thinking with Map. To evaluate our method, we propose MAPBench, which consists of up-to-date and broadly covered Chinese urban street-view and POI images. We categorize the data into two difficulty levels for further analysis of the models performance: easy cases are those that the model can localize at glance, while hard cases contain less distinctive clues and are unlikely to be encountered during pre-training. We also conduct rigorous evaluations on recently released benchmarks, including IMAGEO-Bench (Li et al., 2025b) and GeoBench (Wang et al., 2025b). The results show that our method consistently outperforms all open-source models by large margin and even surpasses Gemini-3-Pro (with Google Search/Map grounded mode) on most metrics. Our contributions are summarized as follows: We propose map-augmented agent for the world-wide image geolocalization, equipped with the model Thinking with Map ability. Building on the Thinking with Map capability, we propose parallel-and-verifier TTS method and further enhance it with agentic RL. We evaluate our method on the proposed MAPBench and other geolocalization benchmarks. The results show that our method outperforms all openand closed-source models on most metrics."
        },
        {
            "title": "2 Related Work",
            "content": "Worldwide Geolocalization. Predicting the geographic location of given image over the world is quite challenging task (Haas et al., 2024; Qian et al., 2025). Over the past decades, computer vision research primarily treats this task as retrieval or classification problem. The former relies on an enormous geo-tagged reference database as the retrieval gallery and introduces several largescale benchmarks (Hays and Efros, 2008; Berton et al., 2022; Berton and Masone, 2025). The latter partitions the Earth into structured geocells and Tool Name Parameter Output image_zoom_tool poi_input_tips poi_keyword_search poi_detail_query static_map_query satellite_map_query Zoom in bounding box Zoomed region image Query text POI keyword POI id Location center Location center Search Suggestions POI list POI details Static map image Satellite map image Table 1: The involved tools for Thinking with Map. predicts geographic coordinates either directly or hierarchically (Müller-Budack et al., 2018; Clark et al., 2023; Haas et al., 2024). Recent LVLMbased methods leverage the visual understanding and reasoning capabilities of frontier models to directly infer location from an image, without any database or map partitioning (Jia et al., 2025; Li et al., 2025a; Wang et al., 2024a; Li et al., 2025b; Huang et al., 2025). Although explicit reasoning reduces the black-box nature of the model, it cannot prevent hallucinations and biases of LVLMs. LVLM Powered Agent. As foundation models advance, researchers begin to focus on agentic capabilities and apply LVLM-powered agents to tasks that require interaction with open environments (Team et al., 2025; Li et al., 2025d; Gur et al., 2023; Yao et al., 2023). Recent works employ an end-to-end agentic RL (Feng et al., 2025; Wang et al., 2025c; Ji et al., 2025c; Dong et al., 2025; Chu et al., 2025; Yuan et al., 2025; Li et al., 2025c; Xiong et al., 2025) to improve tool use and long-horizon decision-making abilities of the base model in specific task environments, demonstrating broad vision. GeoVista (Wang et al., 2025b) applies this paradigm to geolocalization by optimizing models to use vision and search tools for localization. Some studies (Qian et al., 2025) also argue that general search tools offer very limited benefits for localization. Beyond RL, some works also try to improve agent performance via test-time scaling methods such as parallel sampling (Wen et al., 2025), sequential revision (Zhu et al., 2025), and multi-agent exploration (Qiao et al., 2025)."
        },
        {
            "title": "3 Method",
            "content": "In this section, we present Thinking with Map, map-augmented agent for improved LVLM-based geolocalization. The overview of our method can be viewed in Figure 3. We first present the definition and implementation of Thinking with Map ( 3.1). Then we use agentic RL to improve sampling efficiency by optimizing performance from pass@N to pass@K ( 3.2). Finally, we apply parallel TTS to explore multiple candidate hypotheses Figure 3: (a) The process of Thinking with Map, consists of an agent-in-the-map loop. During the loop, the agent implicitly maintains candidate pool of hypotheses. (b) The agentic reinforcement learning for Thinking with Map. (c) The parallel test-time scaling with verifier pipeline for Thinking with Map. during geolocalization, to gain performance from pass@K to pass@1 ( 3.3)."
        },
        {
            "title": "3.1 Thinking with Map\nUnlike direct discrimination or internal knowl-\nedge reasoning, we reformulate geolocalization as\na Thinking with Map process. As Figure 3 (a),\nit follows an agent-in-the-map iterative loop of\nproposing location hypotheses, map retrieval, cross-\nvalidation and decision convergence. Formally, we\nmodel Thinking with Map as an iterative interaction\nprocess between a policy model πθ and a structured\nmap environment Penv. Given a geolocalization\nquery qimage,text, at each iteration t the policy model\ncan either propose a hypothesis τt (optional) ex-\nplicitly/implicitly or verify existing hypotheses τ<t\nthrough tool-call actions αt to retrieve candidates\nwithin the map environment Penv. Then the map\ntool responses are treated as an observation ot, and\ntogether with all previous interaction history, form\nan evidence chain st for cross-validation over the\nstructured information:",
            "content": "st = {(τ0, α0, o0), ..., (τt, αt, ot)}, (1) pθ(τ, α, os0) = (cid:81)T 1 t=0 (cid:21) (cid:20) πθ(τtst)πθ(αtst, τt)Penv(ot+1αt) . (2) Let there be an implicit candidate pool Ct in this iterative process. Then the evidence chain st composed by propositions and map observation at each step can be regarded as maintenance update to the candidate pool: Ct+1 Update(Ct, st) L, (3) where is the overall location set. The policy model keeps maintaining this pool until it becomes sufficiently confident or the interaction budget is exhausted, and then selects the final answer from the candidate pool. Here we provide suite of map tools that human beings commonly use when looking for location in Table 1. Among these tools, POI search serves as the primary information source from the map engine, helping the model obtain location details for specific places. Static and satellite maps then enable the model to verify and cross-check the surrounding scene and places around candidate location. Due to the region-specific availability of map services, we employ two types of map API providers12 to enable global geolocalization. In addition, we provide an image_zoom_tool, which helps the model progressively inspect visual clues in large-scene images."
        },
        {
            "title": "3.2 RL for Map-augmented Agent\nTo enhance the model Thinking with Map capa-\nbility, we adopt a widely explored RL paradigm\nto improve agentic performance from pass@N\nto pass@K. Instead of some recent Qwen2.5-VL-\nbased works (Wang et al., 2025b; Lai et al., 2025;\nZheng et al., 2025b) that adopt a two-stage SFT-\nthen-RL training pipeline, we find that the Qwen3-\nVL model already shows basic tool-use ability after\nequipping it with map tools via the unified tool\ninterface. Therefore, we directly apply agentic RL\nfrom this base model.",
            "content": "1AMAP: https://lbs.amap.com/ 2Google Map: https://developers.google.com/maps Benchmark Im2GPS3K YFC100M OSV-5M Reference Number Image Source Up-to-date Difficulty Tiering Vo et al. (2017) Thomee et al. (2016) Astruc et al. (2024) 3,000 Flickr 100M Flickr 5M Mapillary IMAGEO-Bench Li et al. (2025b) 6,152 / 2,929 / GeoBench Wang et al. (2025b) 512 / 512 / 108 Mapillary/KartaView/Google Map Web/Mapillary/Planetary Computer MAPBench - 2,500 / 2,500 AMAP Table 2: The comparison of MAPBench and existing geolocalization benchmarks. As shown in Figure 3 (b), we adopt the Group Relative Policy Optimization (GRPO) (Shao et al., 2024) as the agentic RL algorithm. Specifically, for each geolocalization query q, the LVLM-based agent generates group of agent trajectories {Hi = (τ0, α0, o0, ..., τT , αT )}G i=1 based on the previous policy πθold. The policy πθ is then optimized by maximizing the advantages: JGRPO(θ) = qD,H Agent πold(q) (cid:34)"
        },
        {
            "title": "1\nG",
            "content": "G (cid:88) i=1 1 Hi Hi (cid:88) t=1 (cid:35) ˆri,t(θ) ˆA(Hi) βDKL (cid:0)πθ(Hq) πref(Hq)(cid:1) , (4) where ˆri,t(θ) is the importance sampling ratio, and clipping is applied in practice to stabilize RL training. We prompt the model to output answers in fixed JSON format for each query, enabling structured parsing for the verifiable reward function. For geolocalization tasks evaluated by continuous distance, we simply use piecewise discrete scheme that assigns different rewards to different distance ranges: = dis [0, 500m) 1, 0.8, dis [500m, 2km) 0.6, dis [2km, 10km) 0.4, dis [10km, 25km) 0.2, dis [25km, 200km) 0.1, dis [200km, 750km) 0, dis [750km, +) (5) This hierarchical reward reflects different localization granularity, e.g., 500m for fine-level and 25km for city-level. In our experiments, this simple design works well with group-based RL and provides discriminative learning signal."
        },
        {
            "title": "3.3 Parallel Test-time Scaling",
            "content": "After RL training, the reinforced model can perform image localization reasoning while interacting with map tools. However, as with how human beings guess locations, images with limited clues often require sequence of hypotheses and verification steps. Due to the limited memory and reflection capabilities (Li et al., 2025d; Liu et al., 2025), such long-horizon sequential reasoning is challenging task for LVLM-based agents. Fortunately, we find that Thinking with Map trajectories naturally contain many self-verifiable factual information from map APIs, as shown in Figure 2. Therefore, we adopt parallel-sampling pipeline with verifier, where the model explores multiple paths through lightweight independent samples and verifier aggregates the results. Formally, given geolocalization query and reinforced model πθ, we first sample set of Thinking with Map trajectories in parallel as: (cid:26) HHi = (cid:81)T 1 t=0 (cid:2)πθ(τtst)πθ(αtst, τt)Penv(ot+1αt)(cid:3) (cid:27)N . i=1 (6) Then we feed the set of Thinking with Map trajectories, together with the original image and simple instruction into LVLM-based verifier πverifier, which summarizes the evidence and selects the most plausible prediction as: Answer = πverifier(q, {H}N i=1, I). (7) As Figure 4, when we use Qwen3-VL-30B-A3B to perform parallel sampling with different numbers, verifier@N closely matches oracle best@N. In particular, when = 2 or 4, the performance loss introduced by the verifier is almost negligible. With this parallel test-time scaling, we enable the model to explore multiple Thinking with Map hypotheses and aggregate self-verifiable trajectories to produce the final answer. This approach transfers performance gains from pass@K to pass@1."
        },
        {
            "title": "4 Dataset",
            "content": "As Table 2, most existing geolocalization benchmarks use images collected earlier from Google Street View (Vo et al., 2017; Wang et al., 2024b, 2025b), Mapillary (Astruc et al., 2024), and Flickr (Thomee et al., 2016). In our early experiments, we identified several major issues with these datasets:"
        },
        {
            "title": "Method",
            "content": "MAPBench-test-easy (Acc@Dis, %) MAPBench-test-hard (Acc@Dis, %) Fine 500m Local 2km District 10km City 25km Region 200km Country 750km Fine 500m Local 2km District 10km City 25km Region 200km Country 750km GPT-o3 GPT-5 Gemini-3-Pro (w/. Google Search/Map) 7.68 9.02 20.86 35.23 34.39 48.28 86.64 87.48 74. 88.98 90.32 80.69 89.82 92.99 86."
        },
        {
            "title": "Closed Source Model",
            "content": "Qwen3-VL-235B-A22B GLOBE-7B GeoVista-7B (w/. Google Search) Qwen3-VL-30B-A3B + Thinking with Map + Reinforcement Learning + Parallel2 & Verifier + Parallel4 & Verifier"
        },
        {
            "title": "Open Source Model",
            "content": "9.35 0.17 0.33 4.01 33.10 41.51 43.65 44.98 34.06 6.53 4.17 21.87 40.28 50.88 54.38 55.02 86.14 42.21 28.21 68.61 53.68 76.88 79.93 80.27 88.48 58.29 39.39 71.95 56.89 79.35 82.27 82.27 90.82 73.70 47.74 75.63 59.94 83.07 85.12 85.79 92.32 95.49 93. 93.66 82.91 51.08 83.31 64.73 89.67 90.64 91.30 0.05 0.05 4.02 0.74 0.79 11.73 4.53 4.10 23.45 9.10 8.94 29.64 20.73 22.30 41. 0.63 0.05 0.00 0.21 10.83 12.33 13.70 14.86 3.42 0.85 0.53 1.89 12.05 14.67 16.45 17.40 13.41 6.34 4.16 10.36 16.08 26.89 28.98 29.88 19.31 11.35 6.52 14.20 19.06 31.62 33.79 34.37 32.88 27.68 10.94 28.56 25.58 42.58 44.32 45.21 44.13 47.45 67. 57.18 52.29 18.99 52.76 38.28 67.17 68.85 68.85 Table 3: Comparison of Thinking with Map with openand closed-source models on MAPBench. Results are reported as accuracy at multiple granularities (Acc@Dis). The bold indicates the best. Timeliness. Most of existing datasets are not up to date, and POIs shown in the images may no longer exist. As result, they fail to assess an LVLM-based geolocalization method that leverage current, real-world knowledge. Moreover, obsolete POIs can contradict information from map APIs or the web, which can mislead the agent and impact localization performance. Difficulty tiering. Because LVLMs are pretrained on massive amount of world knowledge and images, many landmark-style images can be easily recognized and even memorized coordinates. Such images mainly measure memorization, but fail to evaluate the reasoning ability and capability to acquire and use external knowledge. Global coverage. Although existing datasets appear geographically diverse, their image sources bias them toward Europe and North America, with no coverage of China. Based on these issues, we propose MAPBench, an up-to-date geolocalization benchmark with broad coverage across China. The MAPBench consists of 5,000 nearby street-view images centered on POIs, with no POI repeated across samples. We randomly split the dataset into 2,500 training samples and 2,500 test samples. Furthermore, we categorize test samples based on the zero-shot predictions of three base models GPT-5, GPT-o3, and Qwen3-VL-235B-A22B. The sample is labeled as easy if at least two models predict locations within 10km of the ground truth, and labeled as hard otherwise. The easy split evaluates the memorization and world knowledge of base model, while the hard split specifically assesses agentic capabilities. As result, 599 test samples are labeled as easy, while Figure 4: The comparison on parallel sampling. the remaining 1,901 test samples are labeled as hard."
        },
        {
            "title": "5.1 Experimental Setup",
            "content": "Models. We compare the proposed Thinking with Map against multiple series of state-of-the-art closed-source models, including GPT-o3 and GPT5 from OpenAI, and Gemini-3-Pro from Google. We also compare against large-scale open-source model Qwen3-VL-235B-A22B from Alibaba, as well as two open-source geolocalization methods GLOBE (Li et al., 2025a) and GeoVista (Wang et al., 2025b). Our method is built upon Qwen3VL-30B-A3B-Instruct. Datasets. To evaluate our method for worldwide geolocalization capability, in addition to the proposed MAPBench, we also include two recently released benchmarks IMAGEO-Bench (Li et al., 2025b) and GeoBench (Wang et al., 2025b). In particular, we use an IMAGEO-2 subset as it exhibits greater difficulty in our experiments. For"
        },
        {
            "title": "Method",
            "content": "GeoBench (Acc@Dis, %) IMAGEO-2-test (Acc@Dis, %) Fine 500m Local 2km District 10km City 25km Region 200km Country 750km Fine 500m Local 2km District 10km City 25km Region 200km Country 750km"
        },
        {
            "title": "Closed Source Model",
            "content": "GPT-o3 GPT-5 Gemini-3-Pro (w/. Google Search/Map) 33.08 33.30 37.79 50.75 46.90 47.22 61.99 59.64 51.61 64.45 63.17 53.64 67.67 67.13 56. 73.45 75.05 59.10 9.66 11.14 16.33 18.76 19.91 27.33 27.41 28.12 33.22 30.85 32.62 37.00 47.06 50.62 48."
        },
        {
            "title": "Open Source Model",
            "content": "Qwen3-VL-235B-A22B GLOBE-7B GeoVista-7B (w/. Google Search) Qwen3-VL-30B-A3B + Thinking with Map + Reinforcement Learning + Parallel2 & Verifier + Parallel4 & Verifier 19.38 11.21 6.85 12.21 49.82 52.57 55.61 57.94 46.68 43.69 26.55 40.47 59.05 64.01 67.06 69.16 66.60 69.15 45.50 66.60 66.64 72.83 75.23 76.17 71.52 71.72 51.17 71.52 68.28 74.53 76.17 77. 78.05 78.50 54.81 76.02 71.72 77.92 79.44 80.84 91.54 88.78 58.35 90.90 81.36 86.62 87.38 89.02 1.78 0.33 0.22 1.11 17.75 18.64 19.64 20.53 5.66 1.33 1.11 3.22 19.33 20.50 21.86 22.64 11.88 4.77 3.77 8.77 21.55 23.77 25.53 26.19 15.76 7.77 5.66 12.99 23.72 27.19 29.08 30. 34.07 31.74 12.54 34.52 31.93 42.59 45.06 46.06 67.04 72.78 62.67 62.38 65.37 20.08 65.82 47.36 72.41 74.14 75.69 Table 4: Comparison of Thinking with Map with openand closed-source models on GeoBench and IMAGEO. Results are reported as accuracy at multiple granularities (Acc@Dis). The bold indicates the best. MAPBench-test-all (Acc@Dis, %)"
        },
        {
            "title": "5.2 Main Results",
            "content": "RL Method Qwen3-VL-30B-A3B + image_zoom_tool + web_search_tool + map_tool Fine 500m 1.12 1.48 1.77 16.16 Local 2km 6.67 6.81 9.55 18. District 10km 24.29 23.27 26.05 25.07 City 25km 28.01 26.53 29.34 28.11 Region 200km Country 750km 39.82 35.36 36.73 33.80 60.07 53.60 49.73 44.61 Table 5: The ablation study on tool types. RL training, we use the MAPBench training set and 2,000 examples from IMAGEO-2, achieving globally covered samples. More details are in Appendix A."
        },
        {
            "title": "To analyze the model",
            "content": "Evaluation. localization accuracy at different granularities, we report acc@dis at six levels (500m@Fine, 2km@Local, 10km@District, 25km@City, 200km@Region and 750km@Country), with distance thresholds matching the reward settings. Specifically, prediction is considered correct if its distance to the ground truth is below the corresponding threshold. Settings. For closed-source models, we query them directly via APIs. Some of them have builtin tool-use capabilities, such as image manipulation tools of GPT-o3 and Google Search / Google Maps grounded mode of Gemini-3-Pro. For the two open-source geolocalization methods, we follow the original papers to set the corresponding inference hyperparameters, and equip GeoVista-7B with image_zoom_tool and web_search_tool via If not specified, we use unified tool interface. Qwen3-VL-235B-A22B as the verifier for the results of parallel sampling. More details are in Appendix B.1. As shown in Tables 3 and 4, our proposed Thinking with Map method achieves the best performance comparing with all openand closed-source models on most metrics across four test sets. In particular, for fine localization Acc@500m, our method outperforms the best closed-source model Gemini-3-Pro on MAPBench-test-hard by large margin, from 4.02% to 14.86%. The substantial gains on GeoBench and IMAGEO-2-test also show improvingAcc@500m from 37.79% to 57.94% and 16.33% to 20.53%, respectively. Due to the base model used in existing open-source geolocalization methods are relatively small (7B), their performance also cannot match closed-source models. On the other hand, our task directly predicts latitude and longitude, which differs from the models original training targets and can hurt performance. In our experiments, we find that the capability of base model can determine coarse-grained localization performance (e.g., Acc@25km and Acc@200km), while the search and map tools can greatly enhance fine-grained localization performance (e.g., Acc@500m). For example, on MAPBench-test-hard, all base models achieve nearly 0% accuracy for fine-localization, while only Gemini-3-Pro with Google Search/Map grounded mode and our method reach 4.02% and 14.86% respectively. However, directly integrating map tools can also lead to negative effects. Noisy information from the map tools (e.g., wrong search results) may introduce substantial bias in coarse localization, which is reflected by the performance drop in + Thinking with Map row. This performance drop is addressed after reinforcement Figure 5: The evolution of pass@K accuracy across RL training steps on MAPBench."
        },
        {
            "title": "Verifier Model",
            "content": "Fine 500m Local 2km District 10km City 25km Region 200km Country 750km Fine 500m Local 2km District 10km City 25km Region 200km Country 750km MAPBench-test-easy (Acc@Dis, %) MAPBench-test-hard (Acc@Dis, %) Verifier@"
        },
        {
            "title": "43.48\nQwen3-VL-30B-A3B\nQwen3-VL-235B-A22B 43.65\n43.81\nGPT-5",
            "content": "53.18 54.35 54.01 77.93 79.93 79.93 80.27 82.27 82.27 83.95 85.12 85.79 89.97 90.64 91.47 13.64 13.70 13. 16.34 16.45 16.61 28.34 28.98 28.45 32.95 33.79 33.21 42.99 44.32 43.89 Verifier@"
        },
        {
            "title": "44.15\nQwen3-VL-30B-A3B\nQwen3-VL-235B-A22B 44.98\n45.82\nGPT-5",
            "content": "53.85 55.02 54.85 79.26 80.27 80.94 81.10 82.27 83.11 85.12 85.79 86.96 90.13 91.30 92.31 14.65 14.86 14. 17.03 17.40 17.19 28.98 29.88 29.88 33.74 34.37 34.58 44.32 45.21 44.79 67.42 68.86 68.06 68.48 68.85 68. Table 6: The ablation study on verifier models. Verifier@N means verifier with parallel samples. learning training. Notably, our Thinking with Map method already outperforms the other approaches even before incorporating parallel TTS. When incorporating parallel TTS, our method achieves further performance gains, and the improvement is positively correlated with the number of parallel samples. This gain trend is consistent with that of the base model with parallel TTS in Figure 4."
        },
        {
            "title": "5.3 Quantitative Analysis",
            "content": "Different Tools. Here we explore how different types of tools affect the geolocalization task. We use Qwen3-VL-30B-A3B-Instruct as the base model and integrate three types of tools separately. The results in Table 5 align with our earlier discussion in 5.2. All three tool types improve fine-grained localizaiton (< 2km), but hurt coarsegrained localization (> 200km). Among them, image_zoom_tool and web_search_tool bring very marginal improvements, whereas map_tool yields clear gain from 1.12% to 16.16% on Acc@500m. Evolution of Pass@K across RL. Many recent studies (Yue et al., 2025) explore the impact of RLbased post-training on LVLMs. Here we evaluate the effect of RL on the geolocalization task by examining the evolution of pass@K accuracy throughout RL training, as shown in Figure 5. As RL training progresses, the prediction accuracy at all granularities shows lower variance, as Range@2/4 becoming smaller. This trend is consistent with the view that RL helps optimize performance from pass@K toward pass@1. Notably, accuracy at larger distance thresholds (i.e., Dis > 10km) shows clear upward trend under best@N. This suggests that RL also helps the model achieve stronger pass@K from pass@N (K < ). However, Best@500m shows little to no improvement, and can even limit exploration. Different Verifier Models. To further validate the role of the verifier and investigate what makes better verifier in parallel TTS, we experiment with different verifier models in Table 6. The results show that when the parallel size = 2, the choice of model has only minor impact, and 30B model is already sufficient to serve as strong verifier. As the parallel size increases, the verifying task becomes harder, and the impact of model capacity becomes correspondingly more important."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we propose map-augmented agent for image geolocalization, to enable model Thinking with Map. We model this process as an agentin-the-map loop of proposing hypotheses, map retrieval, cross-validation, and decision convergence. Based on this, we propose two-stage optimizaiton approach that combines agentic RL and parallel test-time scaling to gain pass@N capability within single query. Experimental results show that our method outperforms all openand closed-source models on most metrics."
        },
        {
            "title": "Limitation",
            "content": "In this work, we equip the agent with map tools, enabling the LVLM agent to do geolocalization by iteratively interacting within structured map environment. Although the model can perform evidence-grounded reasoning with map tools, we find that its map-use ability still falls far short of human performance. For example, we do not observe the model inferring orientation from relative spatial relationships, which is common strategy humans use when estimating locations. For agentic RL, our training data remain very limited, which constrains the model to learn in open environments. One promising avenue for future work is to investigate what emergent capabilities arise when scaling up this RL paradigm. Finally, we consider parallel TTS pragmatic interim solution that compensates for the current limitations of single agent. How to build single agent with stronger long-horizon problem-solving capabilities remains an open problem."
        },
        {
            "title": "7 Acknowledgment",
            "content": "We acknowledge the helpful discussion with Kaibin Tian, the author of SeekWorld (Tian et al., 2025), and our intern colleagues, Shidong Yang and Zengbin Wang for their assistance."
        },
        {
            "title": "References",
            "content": "Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic. 2016. Netvlad: Cnn architecture for weakly supervised place recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 52975307. Guillaume Astruc, Nicolas Dufour, Ioannis Siglidis, Constantin Aronssohn, Nacim Bouia, Stephanie Fu, Romain Loiseau, Van Nguyen Nguyen, Charles Raude, Elliot Vincent, and 1 others. 2024. Openstreetview-5m: The many roads to global visual geolocation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2196721977. Shuai Bai, Yuxuan Cai, Ruizhe Chen, Keqin Chen, Xionghui Chen, Zesen Cheng, Lianghao Deng, Wei Ding, Chang Gao, Chunjiang Ge, Wenbin Ge, Zhifang Guo, Qidong Huang, Jie Huang, Fei Huang, Binyuan Hui, Shutong Jiang, Zhaohai Li, Mingsheng Li, and 45 others. 2025. Qwen3-VL Technical Report. arXiv preprint. ArXiv:2511.21631 [cs]. Gabriele Berton and Carlo Masone. 2025. Megaloc: One retrieval to place them all. In Proceedings of the Computer Vision and Pattern Recognition Conference, pages 28612867. Gabriele Berton, Carlo Masone, and Barbara Caputo. 2022. Rethinking visual geo-localization for largescale applications. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 48784888. Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, and Yong Wang. 2025. GPG: Simple and Strong Reinforcement Learning Baseline for Model Reasoning. arXiv preprint. ArXiv:2504.02546 [cs]. Brandon Clark, Alec Kerrigan, Parth Parag Kulkarni, Vicente Vivanco Cepeda, and Mubarak Shah. 2023. Where We Are and What Were Looking At: Query Based Worldwide Image Geo-localization arXiv preprint. Using Hierarchies and Scenes. ArXiv:2303.04249 [cs]. DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, and 181 others. 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv preprint. ArXiv:2501.12948 [cs]. Guanting Dong, Hangyu Mao, Kai Ma, Licheng Bao, Yifei Chen, Zhongyuan Wang, Zhongxia Chen, Jiazhen Du, Huiyang Wang, Fuzheng Zhang, Guorui Zhou, Yutao Zhu, Ji-Rong Wen, and Zhicheng Dou. 2025. Agentic Reinforced Policy Optimization. arXiv preprint. ArXiv:2507.19849 [cs]. Lang Feng, Zhenghai Xue, Tingcong Liu, and Bo An. 2025. Group-in-Group Policy Optimization for LLM Agent Training. arXiv preprint. ArXiv:2505.10978 [cs]. Google DeepMind. 2025a. Advanced version of gemini with deep think officially achieves gold-medal standard at the international mathematical olympiad. Blog. Accessed: 2025-12-25. Google DeepMind. 2025b. Gemini 3 pro model card. Model card. Accessed: 2025-12-25. Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. 2023. real-world webagent with planning, long context understanding, and program synthesis. arXiv preprint arXiv:2307.12856. Lukas Haas, Michal Skreta, Silas Alberti, and Chelsea Finn. 2024. PIGEON: Predicting Image Geolocations. arXiv preprint. ArXiv:2307.05845 [cs]. James Hays and Alexei Efros. 2008. Im2gps: estimating geographic information from single image. In 2008 ieee conference on computer vision and pattern recognition, pages 18. IEEE. Jingyuan Huang, Jen-tse Huang, Ziyi Liu, Xiaoyuan Liu, Wenxuan Wang, and Jieyu Zhao. 2025. AI Sees Your Location, But With Bias Toward The Wealthy World. arXiv preprint. ArXiv:2502.11163 [cs]. Yuxiang Ji, Boyong He, Zhuoyue Tan, and Liaoni Wu. 2025a. Game4loc: uav geo-localization benchmark from game data. In AAAI. Yuxiang Ji, Boyong He, Zhuoyue Tan, and Liaoni Wu. 2025b. Mmgeo: Multimodal compositional In Proceedings of the geo-localization for uavs. IEEE/CVF International Conference on Computer Vision, pages 2516525175. Yuxiang Ji, Ziyu Ma, Yong Wang, Guanhua Chen, Xiangxiang Chu, and Liaoni Wu. 2025c. Tree Search for LLM Agent Reinforcement Learning. arXiv preprint. ArXiv:2509.21240 [cs]. Pengyue Jia, Yiding Liu, Xiaopeng Li, Yuhao Wang, Yantong Du, Xiao Han, Xuetao Wei, Shuaiqiang Wang, Dawei Yin, and Xiangyu Zhao. 2024. G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models. arXiv preprint. ArXiv:2405.14702 [cs]. Pengyue Jia, Yingyi Zhang, Xiangyu Zhao, and Sharon Li. 2025. GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization. arXiv preprint. ArXiv:2509.04334 [cs]. Xin Lai, Junyi Li, Wei Li, Tao Liu, Tianjian Li, and Hengshuang Zhao. 2025. Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search. arXiv preprint. ArXiv:2509.07969 [cs]. Ling Li, Yu Ye, Yao Zhou, Bingchuan Jiang, and Wei Zeng. 2024. Georeasoner: Geo-localization with reasoning in street views using large vision-language model. arXiv preprint arXiv:2406.18572. Lingyao Li, Runlong Yu, Qikai Hu, Bowei Li, Min Deng, Yang Zhou, and Xiaowei Jia. 2025b. From Pixels to Places: Systematic Benchmark for Evaluating Image Geolocalization Ability in Large Language Models. arXiv preprint. ArXiv:2508.01608 [cs]. Renda Li, Hailang Huang, Fei Wei, Feng Xiong, Yong Wang, and Xiangxiang Chu. 2025c. Adacurl: Adaptive curriculum reinforcement learning with invalid sample mitigation and historical revisiting. arXiv preprint arXiv:2511.09478. Xiaoxi Li, Wenxiang Jiao, Jiarui Jin, Guanting Dong, Jiajie Jin, Yinuo Wang, Hao Wang, Yutao Zhu, Ji-Rong Wen, Yuan Lu, and Zhicheng Dou. 2025d. DeepAgent: General Reasoning Agent with Scalable Toolsets. arXiv preprint. ArXiv:2510.21618 [cs]. Tengxiao Liu, Zifeng Wang, Jin Miao, I.-Hung Hsu, Jun Yan, Jiefeng Chen, Rujun Han, Fangyuan Xu, Yanfei Chen, Ke Jiang, Samira Daruki, Yi Liang, William Yang Wang, Tomas Pfister, and Chen-Yu Lee. 2025. Budget-Aware Tool-Use Enables Effective Agent Scaling. arXiv preprint. ArXiv:2511.17006 [cs]. Eric Müller-Budack, Kader Pustu-Iren, and Ralph Ewerth. 2018. Geolocation Estimation of Photos Using Hierarchical Model and Scene Classification. In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, Computer Vision ECCV 2018, volume 11216, pages 575592. Springer International Publishing, Cham. Series Title: Lecture Notes in Computer Science. Hyeonwoo Noh, Andre Araujo, Jack Sim, Tobias Weyand, and Bohyung Han. 2017. Large-scale image retrieval with attentive deep local features. In Proceedings of the IEEE international conference on computer vision, pages 34563465. OpenAI. 2025. Openai o3-mini system card. System card. Accessed: 2025-12-25. Zhaofang Qian, Hardy Chen, Zeyu Wang, Li Zhang, Zijun Wang, Xiaoke Huang, Hui Liu, Xianfeng Tang, Zeyu Zheng, Haoqin Tu, Cihang Xie, and Yuyin Zhou. 2025. Where on Earth? Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales. arXiv preprint. ArXiv:2510.10880 [cs]. Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, Rui Min, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, and Jingren Zhou. 2025. WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents. arXiv preprint. ArXiv:2509.13309 [cs]. Ling Li, Yao Zhou, Yuxuan Liang, Fugee Tsung, and Jiaheng Wei. 2025a. Recognition through Reasoning: Reinforcing Image Geo-localization with arXiv preprint. Large Vision-Language Models. ArXiv:2506.14674 [cs]. Paul-Edouard Sarlin, Cesar Cadena, Roland Siegwart, and Marcin Dymczyk. 2019. From coarse to fine: Robust hierarchical localization at large scale. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1271612725. Seed. 2025. Seed-1.8 model card. Model card. Accessed: 2025-12-25. Paul Hongsuck Seo, Tobias Weyand, Jack Sim, and Bohyung Han. 2018. CPlaNet: Enhancing Image Geolocalization by Combinatorial Partitioning of Maps. arXiv preprint. ArXiv:1808.02130 [cs]. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models. arXiv preprint. ArXiv:2402.03300 [cs]. Zhaochen Su, Peng Xia, Hangyu Guo, Zhenhua Liu, Yan Ma, Xiaoye Qu, Jiaqi Liu, Yanshu Li, Kaide Zeng, Zhengyuan Yang, and 1 others. 2025. Thinking with images for multimodal reasoning: Foundations, methods, and future frontiers. arXiv preprint arXiv:2506.23918. Hajime Taira, Masatoshi Okutomi, Torsten Sattler, Mircea Cimpoi, Marc Pollefeys, Josef Sivic, Tomas Pajdla, and Akihiko Torii. 2018. Inloc: Indoor visual localization with dense matching and view synthesis. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 71997209. Yunhao Tang, Kunhao Zheng, Gabriel Synnaeve, and Rémi Munos. 2025. Optimizing language models for inference time objectives using reinforcement learning. arXiv preprint arXiv:2503.19595. Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, Zhuofu Chen, Jialei Cui, Hao Ding, Mengnan Dong, Angang Du, Chenzhuang Du, Dikang Du, Yulun Du, Yu Fan, and 150 others. 2025. Kimi K2: Open Agentic Intelligence. arXiv preprint. ArXiv:2507.20534 [cs]. Bart Thomee, David Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. 2016. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):6473. Kaibin Tian, Zijie Xin, and Jiazhen Liu. 2025. SeekWorld: Geolocation is natural RL task for o3like visual clue-tracking. https://github.com/ TheEighthDay/SeekWorld. GitHub repository. Nam Vo, Nathan Jacobs, and James Hays. 2017. Revisiting im2gps in the deep learning era. In Proceedings of the IEEE international conference on computer vision, pages 26212630. Christian Walder and Deep Karkhanis. 2025. Pass@ policy optimization: Solving harder reinforcement learning problems. arXiv preprint arXiv:2505.15201. Yifei Wang, Feng Xiong, Yong Wang, Linjing Li, Xiangxiang Chu, and Daniel Dajun Zeng. 2025a. Position bias mitigates position bias: Mitigate position bias through inter-position knowledge distillation. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 14951512. Yikun Wang, Zuyan Liu, Ziyi Wang, Pengfei Liu, Han Hu, and Yongming Rao. 2025b. GeoVista: WebAugmented Agentic Visual Reasoning for Geolocalization. arXiv preprint. ArXiv:2511.15705 [cs]. Zhiqiang Wang, Dejia Xu, Rana Muhammad Shahroz Khan, Yanbin Lin, Zhiwen Fan, and Xingquan Zhu. 2024a. LLMGeo: Benchmarking Large Language Models on Image Geolocation In-the-wild. arXiv preprint. ArXiv:2405.20363 [cs]. Zhiqiang Wang, Dejia Xu, Rana Muhammad Shahroz Khan, Yanbin Lin, Zhiwen Fan, and Xingquan Zhu. 2024b. Llmgeo: Benchmarking large language models on image geolocation in-the-wild. arXiv preprint arXiv:2405.20363. Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Xing Jin, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li FeiFei, Lijuan Wang, Yejin Choi, and Manling Li. 2025c. RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning. arXiv preprint. ArXiv:2504.20073 [cs]. Hao Wen, Yifan Su, Feifei Zhang, Yunxin Liu, Yunhao Liu, Ya-Qin Zhang, and Yuanchun Li. 2025. ParaThinker: Native Parallel Thinking as New Paradigm to Scale LLM Test-time Compute. arXiv preprint. ArXiv:2509.04475 [cs]. Tobias Weyand, Andre Araujo, Bingyi Cao, and Jack Sim. 2020. Google landmarks dataset v2-a largescale benchmark for instance-level recognition and retrieval. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 25752584. Tobias Weyand, Ilya Kostrikov, and James Philbin. 2016. PlaNet - Photo Geolocation with Convolutional Neural Networks. volume 9912, pages 3755. ArXiv:1602.05314 [cs]. Feng Xiong, Hongling Xu, Yifei Wang, Runxi Cheng, Yong Wang, and Xiangxiang Chu. 2025. Hs-star: Hierarchical sampling for self-taught reasoners via difficulty estimation and budget reallocation. arXiv preprint arXiv:2505.19866. An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. 2023. Personalized showcases: Generating multi-modal explanations for recommenIn Proceedings of the 46th International dations. ACM SIGIR Conference on Research and Development in Information Retrieval, pages 22512255. Hongji Yang, Xiufan Lu, and Yingying Zhu. 2021. Cross-view Geo-localization with Layer-to-Layer In Advances in Neural Information Transformer. Processing Systems, volume 34, pages 2900929020. Curran Associates, Inc. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. ReAct: Synergizing Reasoning and Acting in Language Models. arXiv preprint. ArXiv:2210.03629 [cs]. Zhenlong Yuan, Xiangyan Qu, Chengxuan Qian, Rui Chen, Jing Tang, Lei Sun, Xiangxiang Chu, Dapeng Zhang, Yiwei Wang, Yujun Cai, and 1 others. 2025. Video-star: Reinforcing open-vocabulary arXiv preprint action recognition with tools. arXiv:2510.08480. Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Shiji Song, and Gao Huang. 2025. Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model? arXiv preprint arXiv:2504.13837. Tong Zheng, Hongming Zhang, Wenhao Yu, Xiaoyang Wang, Runpeng Dai, Rui Liu, Huiwen Bao, Chengsong Huang, Heng Huang, and Dong Yu. 2025a. Parallel-R1: Towards Parallel Thinking via Reinforcement Learning. arXiv preprint. ArXiv:2509.07980 [cs]. Yan-Tao Zheng, Ming Zhao, Yang Song, Hartwig Adam, Ulrich Buddemeier, Alessandro Bissacco, Fernando Brucher, Tat-Seng Chua, and Hartmut Neven. 2009. Tour the world: Building web-scale landmark recognition engine. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 1085 1092. Ziwei Zheng, Michael Yang, Jack Hong, Chenxiao Zhao, Guohai Xu, Le Yang, Chao Shen, and Xing Yu. 2025b. Deepeyes: Incentivizing\" thinking with images\" via reinforcement learning. arXiv preprint arXiv:2505.14362. King Zhu, Hanhao Li, Siwei Wu, Tianshun Xing, Dehua Ma, Xiangru Tang, Minghao Liu, Jian Yang, Jiaheng Liu, Yuchen Eleanor Jiang, Changwang Zhang, Chenghua Lin, Jun Wang, Ge Zhang, and Wangchunshu Zhou. 2025. Scaling Test-time Compute for LLM Agents. arXiv preprint. ArXiv:2506.12928 [cs]."
        },
        {
            "title": "RL Training",
            "content": "optimizer learning rate KL coefficient training epoch training batch size PPO mini batch size max response length max tool response length max turns group size"
        },
        {
            "title": "Parallel Testing",
            "content": "top top temperature AdamW 1e-6 0.001 2 64 16 4096 1024 8 16 60 0.95 1.0 Table 7: Hyperparameters for Thinking with Map RL training and parallel testing. IMAGEO-2 is subset of IMAGEO-Bench (Li et al., 2025b), and constructed from crowdsourced images from Google Map POIs. The original data are released by Yan et al. (2023), then compiled and filtered to final 2,929 images. We use 2,027 randomly sampled instances for training (as IMAGEO-2-train) and the remaining 902 instances for testing (as IMAGEO-2-test). GeoBench (Wang et al., 2025b) is recently released datasets composed of three types images, including 512 normal photos, 512 panoramas and 108 satellite images. The normal photos are sourced from Internet, the panoramas are collected via the Mapilary API, and the satellite images come from Sentinel-2 Level-2A imagery accessed through Microsoft Planetary Computer. We use all the data for testing. Here we provide more details of our proposed MAPBench. We uniformly and randomly sample 5,000 valid POIs across 20 cities in China, and for each POI we randomly select either street-view or storefront photo, forming final set of 5,000 images. This simple construction process ensures that the samples are both up-to-date and broadly coverage. Considering the worldwide coverage and timeliness of the image sources, in addition to our proposed MAPBench, we also use two recently released datasets for global images:"
        },
        {
            "title": "B Experiment Details",
            "content": "B."
        },
        {
            "title": "Implementation Details",
            "content": "Our agentic RL training is implemented on VeRL codebase. The specific hyperparameter settings for RL training and parallel testing are shown in Table 7. The RL training and other experiments are conducted on 32 NVIDIA H20 GPUs. Here we provide the prompt template for Thinking with Map and other base models as follows. They all pose straightforward geolocalization task and require the final answer to be returned"
        },
        {
            "title": "Verifier Model",
            "content": "Fine 500m Local 2km District 10km City 25km Region 200km Country 750km Fine 500m Local 2km District 10km City 25km Region 200km Country 750km GeoBench (Acc@Dis, %) IMAGEO-2-test (Acc@Dis, %) Verifier@"
        },
        {
            "title": "56.78\nQwen3-VL-30B-A3B\nQwen3-VL-235B-A22B 55.61\n60.51\nGPT-5\n57.48\nBest@2",
            "content": "66.82 67.06 72.90 69.86 Qwen3-VL-30B-A3B 57.71 Qwen3-VL-235B-A22B 57.94 63.32 GPT-5 61.92 Best@4 69.86 69.16 75.00 73.13 75.47 75.23 80.37 77.34 76.64 76.17 82.01 78.50 76.40 76.17 81.31 78. 77.80 77.57 83.64 79.44 79.44 79.44 84.11 80.84 87.38 87.38 90.65 88.79 19.76 19.64 21.64 19.76 21.75 21.86 24.20 22.09 Verifier@ 81.07 80.84 86.45 82.48 89.02 89.02 92.76 89.95 20.31 20.53 22.09 22.31 22.09 22.64 24.64 24.42 25.19 25.53 28.52 26.42 25.97 26.19 29.19 28. 28.41 29.08 31.63 30.52 29.41 30.19 33.07 33.74 45.62 45.06 49.06 48.72 45.84 46.06 49.39 53.05 74.25 74.14 75.69 78.36 74.14 75.69 77.36 82. Table 8: The ablation study of verifier models on GeoBench and IMAGEO. Verifier@N means verifier with parallel samples. trend. This further demonstrates the positive effect of RL on localization accuracy. In the second epoch (i.e., the latter half of training), the reward gradually oscillates and approaches to stable, which suggests that more data may be needed. B.3 Ablation Study on RL Algorithm We also try other RL algorithms for Thinking with Map agentic training, in particular Pass@KGRPO (Tang et al., 2025) and PKPO (Walder and Karkhanis, 2025). Results in Table 9 show that although these methods explicitly optimize for pass@K, they perform substantially worse than vanilla GRPO on our task. Therefore, we still use GRPO-trained model for parallel TTS. B.4 More Ablation Studies on Verifier Models Here we provide more ablation studies of verifier models on GeoBench and IMAGEO-2-test. As shown in Table 8, unlike the results on MAPBench, using verifier based on different base model (e.g., GPT-5) can even outperform the corresponding Best@N (Oracle). This suggests that the verifier is not merely selecting among existing candidates. In few cases, it also identifies more plausible answers along the Thinking with Map trajectory."
        },
        {
            "title": "Prompt Template for Thinking with\nMap",
            "content": "<image>You are given an image, and your task is to use your exceptional skills to determine the precise coordinates of the location depicted. Carefully examine the image, taking note of any distinctive features, POIs, landFigure 6: Reward dynamics across RL training. AMAP-test-all (Acc@Dis, %) RL Algorithm Fine 500m 19.33 GRPO Pass@K-GRPO 16.28 16.97 PKPO Local 2km 23.36 19.35 19.35 District 10km 38.89 27.52 26.43 City 25km 43.07 31.91 30. Region 200km Country 750km 52.29 40.46 36.68 72.57 60.48 50.41 Table 9: The ablation study of RL algorithm. in fixed JSON format. The only difference is that the former additionally provides guidance on tool use. The verifier prompt consists of the original geolocalization query together with multiple parallel Thinking with Map trajectories. The prediction format matches the requirements for the single-agent and base-model setting, that the answer must be in the same fixed JSON format. B.2 Training Dynamics of RL To better understand the benefits of agentic RL, we show the reward dynamics over RL training steps in Figure 6. From the reward curve, we find that the training reward increases from 0.25 in the early stage to 0.45 by the end, showing an overall upward {\"lat\": latitude, \"lon\": longitude, \"city\": city, \"country\": country}. Use signed values for latitude and longitude to indicate N/S and E/W. marks, vegetation, or other elements that could serve as clues. When extra information is needed to search for location or confirm precise coordinates, you can use the given tools to get the information from search engine and maps. Once you have gathered sufficient evidence, provide your best inference for the coordinates in the following JSON format: {\"lat\": latitude, \"lon\": longitude, \"city\": city, \"country\": country}. Use signed values for latitude and longitude to indicate N/S and E/W. If you cannot narrow it down, then provide your best guess."
        },
        {
            "title": "Prompt Template for Base Model",
            "content": "<image>You are given an image, and your task is to use your exceptional skills to determine the precise coordinates of the location depicted. Carefully examine the image, taking note of any distinctive features, POIs, landmarks, vegetation, or other elements that could serve as clues. After showing your thinking, provide your final answer in the JSON format: {\"lat\": latitude, \"lon\": longitude, \"city\": city, \"country\": country} Use signed values for latitude and longitude to indicate N/S and E/W. If you cannot narrow it down, then provide your best guess."
        },
        {
            "title": "Prompt Template for Verifier",
            "content": "You are strict geo-localization solver. You will be given an image, the original task, and multiple candidate answers from other agents. Synthesize the best final location. If candidates disagree, pick the most evidence-consistent and geographically plausible one. After thinking, provide your final answer in the JSON format:"
        }
    ],
    "affiliations": [
        "AMAP, Alibaba Group",
        "Southern University of Science and Technology",
        "Xiamen University"
    ]
}