{
    "paper_title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration",
    "authors": [
        "Qingni Wang",
        "Yue Fan",
        "Xin Eric Wang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference."
        },
        {
            "title": "Start",
            "content": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Qingni Wang * 1 2 Yue Fan * 2 Xin Eric Wang"
        },
        {
            "title": "Abstract",
            "content": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SAFEGROUND, an uncertaintyaware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SAFEGROUND leverages distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SAFEGROUND derives test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SAFEGROUND on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial systemlevel accuracy improvements. Across multiple GUI grounding models, SAFEGROUND improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference. 6 2 0 2 3 ] . [ 2 9 1 4 2 0 . 2 0 6 2 : r 1. Introduction Graphical User Interface (GUI) grounding is critical component for autonomous GUI agents, enabling visionlanguage models (VLMs) to translate natural language in- *Equal contribution 1University of California, Santa Barbara 2University of California, Santa Cruz. Correspondence to: Xin Eric Wang <ericxwang@ucsb.edu>. Preprint. February 4, 2026. 1 Figure 1. While existing models may commit costly errors on hard-to-undo actions (e.g., checkout), SAFEGROUND detects high uncertainty and defers the decision via cascading. This mechanism explicitly limits the risk of erroneous actions to user-specified tolerance. structions into executable screen coordinates (Nguyen et al., 2025; Cheng et al., 2024). Recent advances have substantially improved grounding accuracy across diverse GUI environments, making it increasingly feasible to deploy such agents in real-world applications (Fan et al., 2025; Hong et al., 2024). However, in practical GUI interactions, single incorrect grounding can trigger costly and hardto-reverse actions, including erroneous payment approvals or irreversible system configurations (Zhang et al., 2025). Despite these risks, existing GUI grounding models typically output only point predictions, offering no indication of when prediction is unreliable or should be deferred (Gawlikowski et al., 2022; Hu et al., 2023) as shown in Figure 1. The aforementioned limitation of existing GUI grounding models motivates the incorporation of uncertainty quantification (UQ) to enable safer decision-making. However, existing UQ techniques are poorly suited for GUI grounding and remain largely underexplored in this setting (Zhang et al., 2025). In particular, prior approaches suffer from several key limitations. (1) Uncertainty derived from model probabilities or logits (Hendrycks & Gimpel, 2017) assumes access to internal model states, making it infeasible for SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 2. Overview of SAFEGROUND. Given GUI input, the model performs multiple stochastic grounding samples to estimate predictive uncertainty. An uncertainty threshold τ is calibrated on held-out set under user-specified risk level (i.e, the maximum error rate). At test time, predictions with uncertainty τ are executed directly, while high-uncertainty cases are abstained or cascaded. Low-uncertainty cases exhibit concentrated region scores, low entropy, and low variance, whereas high-uncertainty cases show dispersed predictions and trigger safety-aware deferral. black-box vision-language models commonly used in GUI agents (Ye et al., 2024; Wang et al., 2025b). (2) Verbalized self-assessment (Kadavath et al., 2022) relies on strong instruction-following behavior and often fails when models do not explicitly reason about confidence. (3) Approaches that estimate uncertainty using ground-truth regions, such as Zhang et al. (2025), require annotation and cannot be applied at inference time. (4) Existing methods focus on producing uncertainty scores alone, without specifying how predictions should be acted upon at deployment time (e.g., whether to accept, defer, or abstain) despite this decision being critical in high-stakes GUI interactions (Geifman & El-Yaniv, 2017; Wang et al., 2025c). Collectively, these limitations expose clear gap between existing UQ approaches and the practical requirements of GUI grounding, where uncertainty must be reliable under limited model access and without test-time supervision (Lin et al., 2023). To address these challenges, we introduce SAFEGROUND, an uncertainty-aware framework that enables risk-aware predictions for existing state-of-the-art GUI grounding models, without requiring access to model internals. Concretely, as shown in Figure 2, SAFEGROUND first quantifies the predictive uncertainty of grounding outputs from the spatial distribution of multiple stochastic grounding samples from the same model. Then, given the model outputs with estimated uncertainty, we adopt Learn Then Test (LTT) calibration paradigm to select decision threshold that rigorously controls the false discovery rate (FDR) of accepted grounding predictions. This calibration procedure provides finite-sample guarantees: with high probability, the proportion of incorrect predictions among all accepted actions does not exceed user-specified risk level α. At inference time, SAFEGROUND enables principled selective prediction mechanism. Predictions deemed reliable under the calibrated threshold are executed directly, while highuncertainty cases are abstained from or deferred to stronger models for further processing. Furthermore, with the selective prediction, we realized the cascading inference, where even when the primary models base accuracy is limited, we can further leverage external resource to aid the prediction, achieving strong system-level accurarcy. We evaluate SAFEGROUND on the challenging ScreenSpotPro benchmark across multiple state-of-the-art GUI grounding models. Experimental results demonstrate that our proposed uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions. Especially, SAFEGROUND achieves reliable FDR control in practice and significantly improves overall system accuracy through selective deferral, validating its effectiveness for high-stakes GUI interaction scenarios. Empirically, SAFEGROUND demonstrates clear system-level accuracy gains across different risk levels. For instance, on ScreenSpot-Pro, uncertainty-aware cascading with Holo1.57B achieves 58.66% accuracy at risk level 0.34, improving over Gemini-only inference by 5.38% points. Our contributions can be summarized as follows: We propose SAFEGROUND, the first framework for uncertainty-aware selective GUI grounding with finitesample risk guarantees via calibration. We introduce distribution-aware uncertainty quantification that leverage the spatial dispersion and concentration of stochastic grounding predictions. We demonstrate that SAFEGROUND with uncertaintycalibrated selective prediction enables reliable FDR SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration control and improves system-level accuracy in cascading inference on the ScreenSpot-Pro benchmark. 2. Related Work 2.1. GUI Grounding GUI grounding maps natural language instructions to actionable interface elements or click locations in graphical user interfaces (Nguyen et al., 2025; Fan et al., 2025). Most existing GUI grounding methods formulate the problem as text-based coordinate prediction task, where models generate point locations conditioned on the input screenshot and instruction (Chen et al., 2023; Wang et al., 2024a; Qin et al., 2025a). Recently, motivated by how humans interact with digital interfaces, GUI-Actor introduces an attentionbased formulation that aggregates spatial evidence into single grounding decision (Wu et al., 2025b). These methods have achieved strong empirical accuracy across diverse GUI environments. However, most existing approaches produce deterministic point predictions and do not explicitly model predictive uncertainty, limiting their ability to assess decision reliability or defer actions under high uncertainty. 2.2. Uncertainty Estimation Uncertainty estimation is widely used to support reliable decision making in AI systems by quantifying the confidence of model predictions (Liu et al., 2025). In large language models, uncertainty has also been derived from probabilistic measures, semantic entropy, or verbalized selfreports (Hou et al., 2025; Wang et al., 2024b; Xu et al., 2025; Kuhn et al., 2023b). In GUI grounding, uncertainty estimation remains largely underexplored. Existing GUI grounding approaches typically rely on probabilistic uncertainty or verbalized uncertainty, both of which have been shown to be systematically miscalibrated, exhibiting mismatch between predicted confidence and actual grounding accuracy (Zhang et al., 2025). This misalignment motivates uncertainty estimation methods that rely solely on model outputs while providing more reliable signals for downstream decision-making, as considered in our work. 2.3. Learn then Test Calibration Learn Then Test (LTT) is post-hoc calibration paradigm that separates model learning from statistical risk control (Angelopoulos et al., 2022). Given fixed predictive model, LTT frames decision making as hypothesis testing problem over low-dimensional decision space, and uses held-out calibration data to identify parameters that satisfy user-specified risk constraints with finite-sample guarantees. Split conformal prediction (SCP) (Angelopoulos & Bates, 2022) follows this principle by leveraging data splitting and concentration-based confidence bounds to perform valid risk estimation. Prior work builds on this paradigm to enable reliable decision making in large foundation models (Jung et al., 2025; Wang et al., 2025a;c; Wang et al.). Our approach also builds on the LTT paradigm and extends it to GUI grounding through uncertainty-based calibration of spatial action decisions for the first time. 3. Methodology 3.1. Problem Formulation and Notations Let the GUI grounding model be function : R2, which takes UI screenshot and user instruction as input. Given an input pair (x, q), the model predicts coordinate ˆy = (ˆu, ˆv) R2 on the screen. Although the model produces single point prediction, the ground truth for target UI element is typically provided as spatial region on the screen, denoted by R2. predicted coordinate is considered correct if and only if it falls within the ground-truth region, which we conclude as an admission function : R2 P(R2) {0, 1} with 1 indicating correct prediction: A(cid:0)ˆy, B(cid:1) = (cid:40)1, if ˆy B, 0, otherwise. In current coordinate-based GUI grounding models, predictions are deterministic and are not accompanied by explicit uncertainty or confidence estimates, which leaves the trustworthiness of model outputs largely uncharacterized, and may cause users to place unwarranted trust in incorrect predictions, without any indication of potential failure. 3.2. Method Overview To address this issue, we propose SAFEGROUND, an uncertainty-aware GUI grounding framework that can be integrated with diverse state-of-the-art GUI grounding models without requiring access to internal model states, as illustrated in Figure 2. SAFEGROUND introduce user-specified risk level α (0, 1) that quantifies the maximum tolerable proportion of incorrect predictions, serving as high-level control signal for how conservatively the system should behave. The risk level α is then translated into an uncertainty threshold τ through calibration procedure. Specifically, the GUI grounding models predictive uncertainty, (cid:0)ˆy(MLG)(cid:1) for prediction ˆy(MLG), is estimated by SAFEGROUND through sampling multiple additional predictions from the GUI grounding model given the same input. The larger values of such uncertainty score indicate lower reliability. prediction ˆy is correct if (ˆy) τ and rejected otherwise, in which case it is deferred to stronger model. The threshold τ is chosen such that, among all admitted predictions, the fraction of incorrect ones, measured by the admission function A(ˆy, B), is controlled below α. 3 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration 3.3. Uncertainty Quantification regions: We first quantify model uncertainty by analyzing the distributional properties of the ranked region scores. Then, three complementary uncertainty measures are introduced, where they are designed to capture complementary failure modes of GUI grounding: local ambiguity among competing targets, global dispersion of belief across regions, and lack of dominant spatial concentration. Sampling-Based Spatial Distribution Construction To move beyond deterministic point predictions and capture the output distribution of GUI grounding models, we employ Monte Carlo (Gal & Ghahramani) sampling strategy followed by spatial aggregation, drawing inspiration from attention-based aggregation mechanisms in (Wu et al., 2025b). Specifically, for each input (x, q), we perform stochastic forward passes of the grounding model, generating set of coordinates = {ˆy(i)}K i=1, where ˆy(i) R2. These sampled coordinates are then projected onto discretized screen grid to estimate normalized local density map , which empirically characterizes the spatial distribution of the models predictions using only sampled outputs from the model. Intuitively, high density in localized area indicates model consistency and thus low uncertainty. To establish object-level representations, we aggregate connected high-density patches in into disjoint regions = {Rm}M m=1 through density-based clustering. Each region Rm is scored by its average probability density, denoted as Sm, serving as proxy for the likelihood that the region corresponds to the intended UI element. Regions are further ranked such that S(1) S(2) S(M ). More implementation details are provided in the Appendix B.3. Uncertainty Measurement 1. Top-Candidate Ambiguity (TA). To measure the distinctiveness of certain prediction from GUI grounding model, we compute the margin between the two leading candidates. vanishing margin indicates that the model is uncertain between multiple plausible targets (e.g., two identical exit buttons), therefore, we propose the uncertanty score measured by top-candidate ambiguity: UT = (cid:40) 1 S(1)S(2) S(1)+ϵ max(0.1, 1 S(1)), otherwise if 2 , (1) where ϵ ensures numerical stability. High UT signifies localized confusion at the decision boundary. Uncertainty Measurement 2. Informational Dispersion (IE). We assess global uncertainty using the entropy of the region score distribution. To ensure valid probabilistic interpretation, we induce categorical distribution over the 4 ˆpi = S(i) j=1 S(j) (cid:80)M , (2) and then we define the uncertainty score based on information dispersion as the normalized entropy: UIE = 1 log (cid:88) i=1 ˆpi log(ˆpi + ϵ). (3) Such measurement captures the dispersion of probability mass across regions; high UIE indicates that the models confidence is fragmented, failing to converge on single consistent hypothesis. Uncertainty Measurement 3. Concentration Deficit (CD). While entropy assesses global disorder, we explicitly quantify the lack of focus with another uncertainty score UCD by examining the quadratic concentration of the distribution: UCD = 1 (cid:88) i=1 ˆp2 (4) Unlike entropy, UCD is more sensitive to the dominance of the top candidates. Higher values of UCD indicate highly fragmented distribution, suggesting that the model lacks clear spatial focus and distributes confidence across multiple interface regions. Combined Uncertainty Score. Each uncertainty score captures distinct aspect of predictive dispersion, and no single measurement is universally dominant across all models and scenarios. To obtain unified and deployment-friendly uncertainty signal, we aggregate these three scores into single one via fixed weighted combination: UCOM (ˆy) = wCD UCD + wIE UIE + wT UT A. (5) We adopt single set of weights across all models to preserve plug-and-play interface without model-specific tuning. 3.4. Uncertainty Calibration for Selective Prediction Although the proposed uncertainty measures capture predictive uncertainty, they cannot fully distinguish between correct and incorrect predictions. To enable user-specified deployment, we further introduce selective prediction mechanism by calibrating statistically rigorous decision threshold τ on the uncertainty score, such that, among all accepted predictions, the proportion of incorrect predictions does not exceed desired level α. Following prior SCP-based frameworks, we hold out calibration set of data points: Dcal = {(xi, qi, i=1. For )}N SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration (cid:17) and (cid:16) ˆy(M LG) each calibration input pair (xi, qi), we produce ˆy(M LG) quantify its uncertainty score ui = . Given candidate threshold τ , we obtain the number of accepted predictions (cid:80)N 1{ui τ }, and the number of incorrect predictions (cid:80)N 1{ui τ, A(ˆy(M LG) ) = 0}. We then compute the false discovery rate (FDR) on Dcal under threshold τ : , i FDRcal(τ ) = (cid:80)N 1{ui τ, A(ˆy(M LG) (cid:80)N 1{ui τ } , ) = 0} (6) To provide finite-sample FDR guarantees for the accepted samples at test time, we first introduce an auxiliary lemma. Lemma 3.1 (ClopperPearson interval (Clopper & Pearson, 1934)). Let Bin(n, p) be the number of successes in i.i.d. Bernoulli trials with success probability p. For any δ (0, 1), define the Clopper-Pearson confidence interval (cid:104) pL(X), pU (X) (cid:105) = (cid:104) Beta1(cid:0) δ 2 ; X, + 1(cid:1) , Beta1(cid:0)1 δ 2 ; + 1, X(cid:1)(cid:105), (7) To rigorously constrain test-time FDR, we calibrate τ such upper 1δ (τ ) does not exceed the risk level α: that ˆFDR ˆτ = sup{τ : ˆFDR upper 1δ (τ ) α} (11) The choice of ˆτ maximizes the acceptance of model predictions (or minimizes the abstention rate), while maintaining marginal FDR control. For test sample (xtest, qtest, test) with the model prediction ˆy(M LG) and estimated uncertainty test (cid:17) (cid:16) ˆy(M LG) score utest = , by applying the calibrated detest cision threshold ˆτ , we establish the following guarantee (cid:16) (cid:16) Pr Pr A(cid:0)ˆy(M LG) test , test (cid:17) (cid:1) = 0 utest ˆτ (cid:17) α 1δ. (12) Cascading Inference. At inference time, for each test input (xtest, qtest), we first estimate the model uncertainty utest, and then perform selective prediction and escalating: If utest ˆτ , we define the sample as safe and accept the prediction of the primary model. If utest > ˆτ , we flag the sample as risky and escalate the input to stronger model to enhance performance. where Beta1(q; a, b) denotes the q-quantile from beta distribution with shape parameters and b. Then the interval has (at least) nominal coverage: 4. Experiment 4.1. Experimental Settings P(p [pL(X), pU (X)]) 1 δ. (8) , In our setting, = (cid:80)N 1{ui τ, A(ˆy(M LG) ) = 0} and = (cid:80)N 1{ui τ }. Since we focus on controlling the upper tail of the system FDR R(τ ) (thereby constraining test-time FDR), based on Lemma 3.1, we construct upper 1δ (τ ), high-probability upper confidence bound, for R(τ ), using its empirical estimate from the calibration data: ˆFDR ˆFDR upper 1δ (τ ) = Beta(1 δ; + 1, X) = sup{R : Pr(Bin(n, R) X) δ} , (9) where ˆFDR upper 1δ guarantees Pr (cid:0)R(τ ) ˆFDR upper 1δ (τ )(cid:1) 1 δ. (10) ˆFDR upper 1δ (τ ) can be interpreted as the largest Essentially, plausible value that the system FDR could take, given that an extremely small FDRcal(τ ) is observed on the calibration set at significance level δ. If the true system FDR were to exceed this bound, then observing FDRcal(τ ) in single realization would be statistically impossible at the level δ. formal proof of Eq. (10) is provided in Appendix A. 5 Models and Dataset We conduct our experiments over 6 GUI-grounding models, including Holo1.5 (Company, 2025), GUI-Actor (Wu et al., 2025a), UI-TARS-1.5 (Qin et al., 2025b), GTA1 (Yang et al., 2025): Holo1.5-3B, Holo1.5-7B, GUI-Actor-2VL-7B, GUI-Actor-2.5VL-7B, UI-TARS-1.5-7B and GTA1-7B. To assess reliability under high-stakes scenarios, we conduct all experiments on the challenging ScreenSpot-Pro (Li et al., 2025) benchmark. Additional dataset details are provided in the Appendix B.1. Evaluation Metrics To comprehensively evaluate both the discriminative ability of UQ methods and the reliability and effectiveness of SAFEGROUND, we adopt four complementary metrics: Area Under Receiver Operating Characteristic (AUROC), Area Under Accuracy-Rejection Curve (AUARC), FDR, and power (Lin et al., 2024; Wang et al., 2025c). AUROC measures the ability of uncertainty estimates to distinguish correct from incorrect predictions, while AUARC evaluates whether prediction accuracy improves as high-uncertainty samples are progressively rejected. FDR quantifies the proportion of incorrect predictions among the accepted samples. Power measures the proportion of correct samples that are retained after uncertainty-based selection, relative to the total number of correct samples. More details about the metrics can be found in Appendix B.2. SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Hyperparameters For uncertainty estimation, we sample each input 10 times with the decoding temperature set to 1.0 to compute the corresponding UQ score. The most likely generation ˆy(MLG) is obtained by uniformly sampling one output from the generated candidates. Specifically, when computing UQ scores, we partition the input into patches with patch size of 14 to obtain region-level scores Si for uncertainty estimation. We repeat the random calibrationtest split 100 times and report the mean and standard deviation (meanstd) over all runs. All confidence bounds are constructed at significance level of δ = 0.05. For the combined uncertainty score UCOM, we use fixed weighting scheme (wCD, wIE, wT A) = (0.6, 0.2, 0.2) across all models. 4.2. Evaluation of Uncertainty Estimation Following prior work (Kuhn et al., 2023a; Band et al., 2022), we evaluate the quality of uncertainty estimates using AUROC and AUARC, which measure the discriminative ability of uncertainty scores and their effectiveness for selective prediction, respectively. We compare our distribution-aware uncertainty with the probabilistic confidence (PC) baseline, defined as one minus the average token probability (Pouget et al., 2016). Table 2 reports AUROC results across six GUI grounding models. When PC is available, our method consistently achieves higher AUROC. , and on Holo1.5-7B from 0.6983 to 0.7526. For models where PC is not directly applicable (e.g., GUI-Actor variants), our method still attains strong AUROC values (up to 0.8155), demonstrating robust error discrimination under limited model access. Overall, these results suggest that modeling the spatial distribution of grounding predictions yields more informative uncertainty signals than token-level confidence alone. We further evaluate uncertainty quality using AUARC, which captures accuracy gains as high uncertainty predictions are progressively rejected. As shown in Table 3, our method consistently outperforms baselines across models. For example, on Holo1.5-3B, AUARC improves from 0.6444 to 0.6576 compared to PC. These results indicate that our uncertainty estimates are particularly effective for guiding selective prediction decisions. 4.3. Selective Prediction with FDR Guarantees While AUROC and AUARC evaluate the quality of uncertainty estimates, reliable deployment further requires translating these scores into principled decision rules with explicit risk guarantees. We therefore study selective prediction under false discovery rate (FDR) control. Table 1. System-level accuracy (%) of uncertainty-calibrated cascading under different risk levels. indicates infeasible risk levels. Parentheses show over the corresponding model baseline (no cascading). All reported accuracies are computed on the test split, with test ratio of 0.8. Risk Level Model 0.34 0.38 0.42 0.46 0.50 Gemini-only 53.28 Holo1.5-7B (+SAFEGROUND) 52.41 58.66 (+ 6.25) 57.87 (+ 5.46) 55.73 (+ 3.32) 53.20 (+ 0.79) 52.41 (+ 0.00) Holo1.5-3B (+SAFEGROUND) 45.45 53.44 (+ 7.99) 52.73 (+ 7.28) 52.02 (+ 6.57) 49.25 (+ 3.80) 47.35 (+ 1.90) UI-TARS-1.5-7B (+SAFEGROUND) 41.58 53.68 (+12.10) 54.70 (+13.12) 53.04 (+11.46) 50.43 (+ 8.85) 47.91 (+ 6.33) GUI-Actor-2.5VL-7B 45.69 (+SAFEGROUND) 55.18 (+ 9.49) 54.86 (+ 9.17) 53.60 (+ 7.91) 51.38 (+ 5.69) 49.17 (+ 3.48) GUI-Actor-2VL-7B 40.79 (+SAFEGROUND) 55.18 (+14.39) 53.28 (+12.49) 53.99 (+13.20) 52.96 (+12.17) 50.67 (+9.88) GTA1-7B (+SAFEGROUND) 46.88 53.12 (+ 6.24) 49.96 (+ 3.08) Table 2. AUROC comparison of uncertainty quantification methods across different models. The best results for each model are highlighted in bold. PC is the Probabilistic Confidence baseline. Model Uncertainty Score PC UCOM (Ours) Holo1.5-3B Holo1.5-7B GUI-Actor-2.5VL-7B UI-TARS-1.5-7B GUI-Actor-2VL-7B GTA1-7B 0.7576 0.6983 - 0.7844 - 0. 0.8056 0.7526 0.7793 0.8021 0.8155 0.6344 FDR Control Guarantee For each uncertainty method and risk level, we calibrate decision threshold on the calibration set using the ClopperPearson upper confidence bound (Clopper & Pearson, 1934), ensuring that the testtime FDR does not exceed the specified risk level with high probability. Figure 3 illustrates the empirical FDR on the test set across various user-specified risk levels (α). Notably, the evaluated risk levels start from minimum attainable value. This arises because the intrinsic limitations of the base model and the imperfect discriminative power of uncertainty estimates may cause some incorrect predictions to receive relatively low uncertainty scores, making them inseparable from correct ones by thresholding. As result, very stringent FDR requirements may be infeasible to satisfy, as no decision threshold can meet the risk constraint under such conditions (Wang et al., 2025a). Importantly, this does not undermine the safety guarantee, as the calibration stage explicitly determines whether user-specified risk level is achievable prior to deployment, providing principled fail-safe mechanism for high-stakes interactions. The results in Figure 3 show that for all tested models (e.g., Holo1.5, UI-TARS), the actual FDR is consistently bounded below the theoretical upper bound. This empirically verifies 6 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 3. Test-time FDR (meanstd) on the ScreenSpot-Pro dataset under different risk levels. larger volume of correct responses. These results indicate that UCOM is systematically less conservative than PC: it accepts larger fraction of correct predictions while still satisfying the same FDR constraint. 4.4. Cascading Inference Finally, we study the system-level benefits of uncertaintyaware decision making in cascaded inference setting. Given that powerful external models (e.g., Gemini) often incur latency and financial costs, our goal is to improve system accuracy by selectively invoking stronger models when the uncertainty of the base model exceeds calibrated threshold. Specifically, we fix the calibration split ratio to 0.2 and use the remaining 80% of the data as the test set to evaluate the cascaded system. At test time, predictions with uncertainty scores below or equal to the threshold are handled by the primary local grounding model, while highuncertainty cases are deferred to the stronger expert model, Gemini-3-pro (Team et al., 2023). Table 1 reports the accuracy of uncertainty-aware Gemini cascading under different risk levels. Across wide range of feasible risk levels, the proposed approach consistently improves system accuracy over both Gemini-only inference and the base models, demonstrating the effectiveness of uncertainty-aware cascading. At relatively small risk levels, uncertainty-aware cascading yields substantial accuracy gains. For instance, with Holo1.5-7B at risk level 0.34, the system achieves 58.66% accuracy, outperforming Gemini-only inference by 5.38%. As the risk level increases, the improvement gradually diminishes, since fewer highuncertainty samples are deferred to Gemini, and the system behavior approaches that of the base model. The effect is more pronounced for models such as Holo1.5-3B and UITARS-1.5-7B, where uncertainty-aware cascading improves accuracy by more than 7% to 13% over the base models at relatively small risk levels. We also report the cascading rate in Figure 5, i.e., the fraction of test samples deferred to Gemini. As the risk level increases, the cascading rate consistently decreases across all models, indicating that fewer uncertain cases are escalated to the expert model. This reflects the inherent trade-off between accuracy and expert Figure 4. Test-time power (mean) of our UCOM and PC baseline on the ScreenSpot-Pro dataset under different risk levels. Table 3. AUARC comparison of uncertainty quantification methods across different models. The best results for each model are highlighted in bold. Model Uncertainty Score Random PC UCOM (Ours) Holo1.5-3B Holo1.5-7B GUI-Actor-2.5VL-7B GUI-Actor-2VL-7B UI-TARS-1.5-7B GTA1-7B 0.4706 0.5345 0.4662 0.4130 0.4231 0.4769 0.6444 0.6686 0.6222 0.5521 0.6576 0.6705 0.7156 0.7166 0.6480 0.5511 that SAFEGROUND provides rigorous safety guarantees, ensuring that, with high probability, the error rate among accepted predictions is controlled at the specified level. Power Comparison In addition to FDR, we report power to further characterize the effectiveness of selective prediction. Higher power indicates that the uncertainty estimates more precisely identify truly risky cases, allowing the system to retain larger set of reliable predictions without violating the target FDR. Figure 4 compares the power of our method UCOM versus the PC baseline under identical risk levels. Across the evaluated models, UCOM demonstrates superior robustness, particularly at strict risk levels (e.g., 0.38) where PC often fails to yield valid predictions. Notably, the minimum attainable risk level at which PC can satisfy the FDR constraint is consistently higher than that of UCOM, indicating narrower feasible operating range for PC. UCOM consistently outperforms PC, retaining significantly SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Table 4. Ablation study of uncertainty components on GTA1, GUIActor-2VL, and Holo1.5 models. Best results within each model block are highlighted in bold. Model Uncertainty AUROC AUARC GTA1 GUI-Actor-2VL-7B Holo1.5-7B UT UIE UCD UCOM w/o UT UT UIE UCD UCOM w/o UCD UT UIE UCD UCOM w/o UCD 0.6228 0.5916 0.5917 0.6344 0.5917 0.4844 0.7731 0.7894 0.8155 0. 0.6296 0.7380 0.7529 0.7526 0.7303 0.5481 0.5390 0.5389 0.5511 0.5389 0.4335 0.6435 0.6505 0.7166 0.6221 0.6284 0.6670 0.6716 0.6705 0.6483 and removing the dominant component for given model leads to clear drop in both AUROC and AUARC. This indicates that combining complementary cues yields more robust, model-agnostic uncertainty estimate for selective prediction. Additional robustness analyses with respect to the uncertainty weighting are provided in the Appendix F. Sensitivity to Calibration-Test Split Ratio We further study the sensitivity of our method to the calibrationtest split ratio when using the combined uncertainty measure UCOM. Specifically, we vary the proportion of data allocated to the calibration set while keeping the target risk level fixed, and evaluate the resulting empirical FDR on the test set. As shown in Figure 7, across wide range of split ratios, the empirical FDR achieved by all three models remains consistently below the target upper bound. These results suggest that our approach does not rely on carefully tuned split ratio and can be applied robustly in practical settings. 5. Conclusion We presented SAFEGROUND, an uncertainty-aware framework that enables reliable and risk controlled GUI grounding under limited model access. By modeling spatial uncertainty from stochastic grounding samples, SAFEGROUND captures distributional signals that go beyond point predictions and provide effective discrimination between correct and incorrect predictions. Based on uncertainty estimation, we further calibrate decision thresholds with finite-sample guarantees, supporting deployment-time decision making in high-stakes GUI interactions. Extensive experiments demonstrate that SAFEGROUND achieves accurate uncertainty discrimination, rigorous FDR control, and improved system-level performance through selective prediction and cascading inference. We hope this work provides principled way for deploying GUI agents with safety guarantees. Figure 5. Cascading rate (fraction of test samples deferred to Gemini) across different risk levels. Figure 6. Effect of sampling size on uncertainty estimation quality for UI-TARS-1.57B. Figure 7. Test-time FDR results of various calibration test split ratios. invocation cost in uncertainty-aware cascading. 4.5. Sensitivity Analyses Sampling Efficiency We investigate the trade-off between computational cost and estimation quality by varying the sample count and measuring the resulting AUROC and AUARC. As shown in Figure 6, increasing the sample size from = 5 to = 10 yields improvement for both metrics, indicating that the proposed uncertainty estimates are already effective with small number of samples. In contrast, further increasing from 10 to 15 leads to only marginal changes. Based on this trade-off between performance and computational cost, we set = 10 as the default sampling size in all experiments. Ablation of Uncertainty Components We analyze the contribution of individual uncertainty components, UT , UIE, and UCD, across different GUI grounding models. As shown in Table 4, the most informative uncertainty cue is model-dependent. On GTA1, UT is the strongest single signal, whereas for GUI-Actor-2VL and Holo1.5, UCD is more effective, and UT alone is insufficient. Across all models, no single component consistently dominates. UCOM achieves stable performance in all settings, 8 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration"
        },
        {
            "title": "Impact Statement",
            "content": "This paper introduces SAFEGROUND, framework that significantly enhances the reliability and safety of autonomous GUI agents. By providing the first principled method for uncertainty quantification in GUI grounding with finite-sample statistical guarantees, our work addresses critical bottleneck in the real-world deployment of visual agents, the risk of high-stakes, irreversible errors (e.g., erroneous financial transactions). Beyond improving individual model reliability, the proposed selective deferral mechanism demonstrates that local models, when combined with uncertainty-aware cascading to powerful external experts, can achieve superior system-level accuracy with substantially reduced computational costs. This research provides foundational step toward trustworthy human-AI interaction in digital environments, ensuring that automated systems know when they dont know and make conservative decisions under ambiguous conditions."
        },
        {
            "title": "References",
            "content": "Angelopoulos, A. N. and Bates, S. gentle introduction to conformal prediction and distribution-free uncertainty quantification, 2022. URL https://arxiv.org/ abs/2107.07511. Angelopoulos, A. N., Bates, S., Cand`es, E. J., Jordan, M. I., and Lei, L. Learn then test: Calibrating predictive algorithms to achieve risk control, 2022. URL https://arxiv.org/abs/2110.01052. Band, N., Rudner, T. G. J., Feng, Q., Filos, A., Nado, Z., Dusenberry, M. W., Jerfel, G., Tran, D., and Gal, Y. Benchmarking bayesian deep learning on diabetic retinopathy detection tasks, 2022. URL https:// arxiv.org/abs/2211.12717. Chen, K., Zhang, Z., Zeng, W., Zhang, R., Zhu, F., and Zhao, R. Shikra: Unleashing multimodal llms referential dialogue magic, 2023. URL https://arxiv.org/ abs/2306.15195. Cheng, K., Sun, Q., Chu, Y., Xu, F., YanTao, L., Zhang, J., and Wu, Z. Seeclick: Harnessing gui grounding for advanced visual gui agents. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 93139332, 2024. Clopper, C. J. and Pearson, E. S. The use of confidence or fiducial limits illustrated in the case of the binomial. Biometrika, 1934. Company, H. Holo1.5 - open foundation models for computer use agents, 2025. URL https:// huggingface.co/collections/Hcompany/ holo15-68c1a5736e8583a309d23d9b. Fan, Y., Zhao, H., Zhang, R., Shen, Y., Wang, X. E., and Wu, G. GUI-bee: Align GUI action grounding to novel environments via autonomous exploration. In Christodoulopoulos, C., Chakraborty, T., Rose, C., and Peng, V. (eds.), Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, Suzhou, China, November 2025. Association for Computational Linguistics. Gal, Y. and Ghahramani, Z. Dropout as bayesian approximation: Representing model uncertainty in deep learning. In Proceedings of The 33rd International Conference on Machine Learning. Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M., Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R., Shahzad, M., Yang, W., Bamler, R., and Zhu, X. X. survey of uncertainty in deep neural networks, 2022. URL https://arxiv.org/abs/2107.03342. Geifman, Y. and El-Yaniv, R. Selective classification for deep neural networks. Advances in neural information processing systems, 30, 2017. Hendrycks, D. and Gimpel, K. baseline for detecting misclassified and out-of-distribution examples in neural networks. In International Conference on Learning Representations, 2017. URL https://openreview. net/forum?id=Hkg4TI9xl. Hong, W., Wang, W., Lv, Q., Xu, J., Yu, W., Ji, J., Wang, Y., Wang, Z., Dong, Y., Ding, M., and Tang, J. Cogagent: In ProceedA visual language model for gui agents. ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1428114290, June 2024. Hou, B., Zhang, Y., Andreas, J., and Chang, S. probabilistic framework for llm hallucination detection via belief tree propagation, 2025. URL https://arxiv.org/ abs/2406.06950. Hu, M., Zhang, Z., Zhao, S., Huang, M., and Wu, B. Uncertainty in natural language processing: Sources, quantification, and applications, 2023. URL https: //arxiv.org/abs/2306.04459. Jung, J., Brahman, F., and Choi, Y. Trust or escalate: LLM judges with provable guarantees for human agreement. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview. net/forum?id=UHPnqSTBPO. 9 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain, D., Perez, E., Schiefer, N., Hatfield-Dodds, Z., DasSarma, N., Tran-Johnson, E., Johnston, S., El-Showk, S., Jones, A., Elhage, N., Hume, T., Chen, A., Bai, Y., Bowman, S., Fort, S., Ganguli, D., Hernandez, D., Jacobson, J., Kernion, J., Kravec, S., Lovitt, L., Ndousse, K., Olsson, C., Ringer, S., Amodei, D., Brown, T., Clark, J., Joseph, N., Mann, B., McCandlish, S., Olah, C., and Kaplan, J. Language models (mostly) know what they know, 2022. URL https://arxiv.org/abs/2207.05221. Kuhn, L., Gal, Y., and Farquhar, S. Semantic uncertainty: Linguistic invariances for uncertainty estimaIn The Eleventh tion in natural language generation. International Conference on Learning Representations, 2023a. URL https://openreview.net/forum? id=VD-AYtP0dve. Kuhn, L., Gal, Y., and Farquhar, S. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation, 2023b. URL https: //arxiv.org/abs/2302.09664. Li, K., Meng, Z., Lin, H., Luo, Z., Tian, Y., Ma, J., Huang, Z., and Chua, T.-S. Screenspot-pro: Gui grounding for professional high-resolution computer use, 2025. URL https://arxiv.org/abs/2504.07981. Lin, Z., Trivedi, S., and Sun, J. Generating with confidence: Uncertainty quantification for black-box large language models. arXiv preprint arXiv:2305.19187, 2023. Lin, Z., Trivedi, S., and Sun, J. Generating with confidence: Uncertainty quantification for black-box large language models, 2024. URL https://arxiv.org/ abs/2305.19187. Liu, X., Chen, T., Da, L., Chen, C., Lin, Z., and Wei, H. Uncertainty quantification and confidence calibration in large language models: survey, 2025. URL https: //arxiv.org/abs/2503.15850. Nguyen, D., Chen, J., Wang, Y., Wu, G., Park, N., Hu, Z., Lyu, H., Wu, J., Aponte, R., Xia, Y., Li, X., Shi, J., Chen, H., Lai, V. D., Xie, Z., Kim, S., Zhang, R., Yu, T., Tanjim, M., Ahmed, N. K., Mathur, P., Yoon, S., Yao, L., Kveton, B., Kil, J., Nguyen, T. H., Bui, T., Zhou, T., Rossi, R. A., and Dernoncourt, F. Gui agents: survey, 2025. URL https://arxiv.org/abs/2412.13501. Pouget, A., Drugowitsch, J., and Kepecs, A. Confidence and certainty: distinct probabilistic quantities for different goals. Nature neuroscience, 19(3):366374, 2016. Qin, Y., Ye, Y., Fang, J., Wang, H., Liang, S., Tian, S., Zhang, J., Li, J., Li, Y., Huang, S., Zhong, W., Li, K., Yang, J., Miao, Y., Lin, W., Liu, L., Jiang, X., Ma, Q., Li, J., Xiao, X., Cai, K., Li, C., Zheng, Y., Jin, C., Li, C., Zhou, X., Wang, M., Chen, H., Li, Z., Yang, H., Liu, H., Lin, F., Peng, T., Liu, X., and Shi, G. Ui-tars: Pioneering automated gui interaction with native agents, 2025a. URL https://arxiv.org/abs/2501.12326. Qin, Y., Ye, Y., Fang, J., Wang, H., Liang, S., Tian, S., Zhang, J., Li, J., Li, Y., Huang, S., et al. Ui-tars: Pioneering automated gui interaction with native agents. arXiv preprint arXiv:2501.12326, 2025b. Team, G., Anil, R., Borgeaud, S., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Millican, K., et al. Gemini: family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. Wang, P., Bai, S., Tan, S., Wang, S., Fan, Z., Bai, J., Chen, K., Liu, X., Wang, J., Ge, W., Fan, Y., Dang, K., Du, M., Ren, X., Men, R., Liu, D., Zhou, C., Zhou, J., and Lin, J. Qwen2-vl: Enhancing vision-language models perception of the world at any resolution, 2024a. URL https://arxiv.org/abs/2409.12191. Wang, Q., Fan, Y., and Wang, X. E. Safer: Risk-constrained sample-then-filter in large language models, 2025a. URL https://arxiv.org/abs/2510.10193. Wang, Q., Geng, T., Wang, Z., Wang, T., Fu, B., and Zheng, F. Sample then identify: general framework for risk control and assessment in multimodal large language models. In The Thirteenth International Conference on Learning Representations, 2025b. URL https: //openreview.net/forum?id=9WYMDgxDac. Wang, Z., Wang, Q., Zhang, Y., Chen, T., Zhu, X., Shi, X., and Xu, K. SConU: Selective conformal uncertainty in large language models. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), July . Wang, Z., Duan, J., Yuan, C., Chen, Q., Chen, T., Zhang, Y., Wang, R., Shi, X., and Xu, K. Word-sequence entropy: Towards uncertainty estimation in free-form medical question answering applications and beyond, 2024b. URL https://arxiv.org/abs/2402.14259. Wang, Z., Duan, J., Wang, Q., Zhu, X., Chen, T., Shi, X., and Xu, K. Coin: Uncertainty-guarding selective question answering for foundation models with provable risk guarantees, 2025c. URL https://arxiv.org/ abs/2506.20178. Wu, Q., Cheng, K., Yang, R., Zhang, C., Yang, J., Jiang, H., Mu, J., Peng, B., Qiao, B., Tan, R., Qin, S., Liden, L., Lin, Q., Zhang, H., Zhang, T., Zhang, J., Zhang, D., and Gao, J. Gui-actor: Coordinate-free visual grounding 10 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration for gui agents, 2025a. URL https://arxiv.org/ abs/2506.03143. Wu, Q., Cheng, K., Yang, R., Zhang, C., Yang, J., Jiang, H., Mu, J., Peng, B., Qiao, B., Tan, R., et al. Gui-actor: Coordinate-free visual grounding for gui agents. arXiv preprint arXiv:2506.03143, 2025b. Xu, Z., Song, T., and Lee, Y.-C. Confronting verbalized uncertainty: Understanding how llms verbalized uncertainty influences users in ai-assisted decision-making. Int. J. Hum.-Comput. Stud., 197(C), March 2025. ISSN 10715819. doi: 10.1016/j.ijhcs.2025.103455. URL https: //doi.org/10.1016/j.ijhcs.2025.103455. Yang, Y., Li, D., Dai, Y., Yang, Y., Luo, Z., Zhao, Z., Hu, Z., Huang, J., Saha, A., Chen, Z., Xu, R., Pan, L., Savarese, S., Xiong, C., and Li, J. Gta1: Gui test-time scaling agent, 2025. URL https://arxiv.org/ abs/2507.05791. Ye, F., Yang, M., Pang, J., Wang, L., Wong, D. F., Yilmaz, E., Shi, S., and Tu, Z. Benchmarking LLMs via uncertainty quantification. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. URL https://openreview. net/forum?id=L0oSfTroNE. Zhang, S., Fu, P., Zhang, R., Yang, J., Du, A., Xi, X., Wang, S., Huang, Y., Qin, B., Luo, Z., and Luan, J. Hyperclick: Advancing reliable GUI grounding via uncertainty calibration, 2025. URL https://openreview.net/ forum?id=pXYwksqDyE. 11 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration"
        },
        {
            "title": "Limitation",
            "content": "Our uncertainty estimation relies on the variability in the sampled predictions to characterize spatial ambiguity. For highly deterministic models with limited sampling diversity, the resulting spatial distributions may be less informative. Despite these limitations, SAFEGROUND provides general and principled foundation for uncertainty-aware GUI grounding. A. Proofs upper 1δ (τ ) defined in Eq. (9) satisfies the In this section, we provide compelete proof that the upper confidence bound 1{ui τ } statistical guarantee in Eq. (9). Recall is the number of accepted calibration samples, and = (cid:80)N ) = 0} is the number of accepted incorrect calibration samples. In general, Bin(n, R) denotes the random variable representing the number of successes in Bernoulli trials when the system success probability is R. In our setting, it corresponds to the random variable counting the number of errors among samples when the system FDR is under given threshold τ . 1δ (τ ) = sup{R : Pr(Bin(n, R) X) δ}, where = (cid:80)N 1{ui τ, A(ˆy(M LG) ˆFDR ˆFDR , upper We define the cumulative distribution function (CDF) of the random variable ˆR(τ ) = Bin(n;R(τ )) rate over any accepted samples when the system FDR is R(τ ), as , corresponding to the error By the definition of ˆFDR upper 1δ (τ ), we have CDF(cid:0)r R(τ )(cid:1) = Pr (cid:0) ˆR(τ ) R(τ )(cid:1). CDF (cid:18) ˆFDR upper 1δ (τ ) (cid:19) = δ. If R(τ ) > ˆFDR upper 1δ (τ ), we have CDF (cid:0) (cid:16) Pr R(τ ) ˆFDR upper 1δ (τ ) R(τ )(cid:1) δ. Then, we have (cid:17) = 1 Pr 1 Pr (cid:16) R(τ ) > ˆFDR (cid:18) (cid:18) CDF upper 1δ (τ ) (cid:19) (cid:17) (cid:19). R(τ ) δ We further the Inverse Cumulative Distribution Function (ICDF): If CDF (cid:0) R(τ )(cid:1) δ, we have CDF1(cid:0)p R(τ )(cid:1) = sup {r : CDF (r R(τ )) p} . CDF1(cid:0)δ R(τ )(cid:1). We then obtain (cid:17) 1 Pr CDF1(cid:0)δ R(τ )(cid:1) (cid:16) Pr R(τ ) ˆFDR upper 1δ (τ ) (cid:19) . (cid:18) (13) (14) (15) (16) (17) is exactly the empirical error rate observed over the accepted samples in the calibration set, the probability that it Since is less than or equal to CDF1(cid:0)δ R(τ )(cid:1) does not exceed δ. Finally, we conclude (cid:16) Pr R(τ ) ˆFDR upper 1δ (τ ) (cid:17) 1 δ. (18) In this way, we obtain an upper bound on the system FDR at threshold τ with at least 1 δ confidence. At test time, by the exchangeability condition, we provide marginal guarantees of FDR control. B. Details of Experimental Settings B.1. Dataset ScreenSpot-Pro ScreenSpot-Pro consists of 1581 UI screenshots paired with natural language instructions that refer to target UI elements on the screen. Each target is annotated as spatial region rather than single point. Compared to earlier GUI grounding benchmarks, ScreenSpot-Pro features higher visual complexity, denser UI layouts, and more fine-grained distinctions between neighboring elements, making it particularly suitable for studying uncertainty-aware grounding. 12 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration B.2. Evaluation Metrics We evaluate uncertainty estimation quality and selective prediction performance using four complementary metrics: AUROC, AUARC, FDR, and power. All metrics are defined with respect to the admission function A(ˆy, B) {0, 1} introduced in Section 3.1, which indicates whether grounding prediction is admissible. Area Under Receiver Operating Characteristic (AUROC) Let (ˆy) denote an uncertainty score, where larger values indicate higher uncertainty. AUROC measures how well (ˆy) separates inadmissible predictions from admissible ones. Formally, AUROC is the area under the receiver operating characteristic curve obtained by thresholding (ˆy) to predict whether A(ˆy, B) = 0. higher AUROC indicates stronger discriminative ability of the uncertainty estimate. Area Under Accuracy-Rejection Curve (AUARC) AUARC evaluates selective prediction behavior by measuring how accuracy changes as predictions with high uncertainty are rejected. Let Sτ = {i : (ˆyi) τ } denote the set of accepted samples under threshold τ . The accuracy at τ is defined as Acc(τ ) = 1 Sτ (cid:88) iSτ A(ˆyi, i ). In practice, τ is chosen to correspond to target rejection rate, and AUARC is computed as the area under the curve of Acc(τ ) as function of the rejection rate. False Discovery Rate (FDR) Under given uncertainty threshold τ , the false discovery rate is defined as FDR(τ ) = (cid:80) I(cid:0)U (ˆyi) τ (cid:1) I(cid:0)A(ˆyi, i ) = 0(cid:1) (cid:80) I(cid:0)U (ˆyi) τ (cid:1) . FDR quantifies the proportion of inadmissible predictions among all accepted predictions and serves as the primary risk metric controlled by SAFEGROUND. Power Power measures the proportion of correct predictions retained by selective prediction under risk constraint and is defined as: Power(τ ) = (cid:80)N i=1 I(cid:0)U (ˆyi) τ (cid:1)I(cid:0)A(ˆyi, I(cid:0)A(ˆyi, ) = 1(cid:1) (cid:80)N i=1 ) = 1(cid:1) . Higher power indicates that more correct predictions are retained while satisfying the specified FDR constraint. B.3. Spatial Region Construction Given an input imageinstruction pair (x, q), we obtain set of sampled grounding predictions = {ˆy(i) = (x(i), y(i))}K i=1 via stochastic decoding. To lift these point-wise samples into spatial distribution, we discretize the screen into fixed grid of patches and map each sampled coordinate to its corresponding patch. Let Cu,v denote the number of samples falling into patch (u, v). We then normalize the resulting count map to obtain spatial probability distribution Pu,v = Cu,v u,v Cu,v (cid:80) , (19) which serves as an empirical estimate of the models predictive density over the output space. Region Extraction To identify object-level grounding hypotheses, we first filter low-density patches using an instanceadaptive threshold. Specifically, let Pmax = maxu,v Pu,v, and retain only patches satisfying Pu,v > βPmax, where β is fixed ratio (set to 0.3 in our experiments, following (Wu et al., 2025b)). We then group spatially adjacent retained patches (using 4-connected neighborhood) into connected components. This yields set of disjoint regions = {Rm}M m=1, each corresponding to plausible grounding target. SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration"
        },
        {
            "title": "Gemini",
            "content": "You are GUI agent that locates UI elements in screenshots. CRITICAL RULES: 1. You MUST output ONLY valid JSON, nothing else 2. Do NOT include any explanation, markdown formatting, or natural language 3. Do NOT wrap the response in code blocks (json) 4. Coordinates must be in PIXEL values (NOT normalized to 0-1000) 5. If you cannot find the element, output an empty list: [] Your response must be valid JSON array. Figure 8. system prompt example for Gemini-3-pro in ScreenSpot-Pro dataset. Region Scoring For each region Rm, we compute region-level score Sm = 1 Rm (cid:88) Pu,v, (u,v)Rm (20) i.e., the average probability density within the region. This score reflects the relative support assigned to the region by the sampled predictions while remaining invariant to region size. The resulting region scores {Sm}M m=1 are subsequently normalized and used to compute the uncertainty metrics described in Section 3.3. C. Threshold Calibration with Finite-Sample Guarantees This section details the threshold calibration procedure used in SafeGround to obtain finite-sample guarantees on selective prediction risk, based on ClopperPearson confidence bounds, as summarized in Algorithm 1. D. Prompt Template To ensure fair and reliable evaluation of large visionlanguage models on GUI grounding, we adopt strictly constrained prompt template for Gemini in the ScreenSpot-Pro benchmark, as illustrated in Figure 8, 9. E. Case Study We present qualitative examples to illustrate how the proposed uncertainty score reflects the reliability of GUI grounding predictions in practice in Figure 10, 11, 12, 13, 14. F. Additional Experimental Results Sensitivity to Sampling Temperature. We further examine the sensitivity of the proposed uncertainty measures to the sampling temperature used during stochastic decoding. Table 5 and Table 6 report AUROC and AUARC results on Holo1.5-3B (Company, 2025) under different temperature settings. As the temperature increases, UIE and UCD become more informative, reflected by consistent gains in AUROC. In contrast, margin-based uncertainty exhibits relatively limited sensitivity to temperature changes. UCOM shows dependence on the sampling temperature, reflecting its ability to adapt to changes in the diversity and dispersion of stochastic predictions, while remaining competitive across the evaluated temperature range. Sensitivity to Uncertainty Weighting. We examine the sensitivity of the proposed framework to the weighting scheme used in the combined uncertainty score UCOM. Starting from the default setting (wCD, wIE, wT A) = (0.6, 0.2, 0.2), we 14 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration"
        },
        {
            "title": "Gemini",
            "content": "Task: Point to the UI element matching this instruction: {instruction} Image size: {W} {H} pixels. Output format (JSON only, no markdown): [{\"point\": [y, x], \"label\": \"description\"}] Where: - point: [y, x] coordinates in PIXELS (NOT normalized to 0-1000) - is vertical (0 to {H}) - is horizontal (0 to {W}) If no element found, output: [] Example: [{\"point\": [60, 230], \"label\": \"submit button\"}] Figure 9. user prompt example for Gemini-3-pro in ScreenSpot-Pro dataset. Figure 10. An example of GUI grounding task using our uncertainty score. evaluate several alternative weighting configurations that moderately vary the relative contributions of the three uncertainty components, while keeping the weights normalized. Specifically, we consider the following weighting configurations for the combined uncertainty score UCOM: v1: (wCD, wIE, wT A) = (0.34, 0.33, 0.33); v2: (wCD, wIE, wT A) = (0.2, 0.2, 0.6); v3: (wCD, wIE, wT A) = (0.2, 0.6, 0.2); v4: (wCD, wIE, wT A) = (0.5, 0.25, 0.25); 15 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 11. An example of GUI grounding task using our uncertainty score. Figure 12. An example of GUI grounding task using our uncertainty score. v5: (wCD, wIE, wT A) = (0.25, 0.25, 0.5); v6: (wCD, wIE, wT A) = (0.25, 0.5, 0.25); original: (wCD, wIE, wT A) = (0.6, 0.2, 0.2). As shown in Figure 15, 16, 18, 19, 17, 20, across all evaluated models, both AUROC and AUARC exhibit only minor fluctuations under different weighting schemes. These results indicate that the proposed uncertainty aggregation is robust to moderate changes in the weighting scheme, supporting the use of fixed, model-agnostic combination in practice. SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 13. An example of GUI grounding task using our uncertainty score. Figure 14. An example of GUI grounding task using our uncertainty score. Table 5. AUROC of different uncertainty measures on Holo1.5-3B under varying sampling temperatures. Method Temp=0.3 Temp=0.5 Temp=0.7 Temp=1.0 UT UIE UCD UCOM 0.6258 0.6621 0.6689 0.6819 0.6270 0.6900 0.7078 0.7218 0.6297 0.7329 0.7590 0.7578 0.6404 0.7753 0.8060 0.8056 Table 6. AUARC of different uncertainty measures on Holo1.5-3B under varying sampling temperatures. Method Temp=0.3 Temp=0.5 Temp=0.7 Temp=1. UT UIE UCD UCOM 0.5373 0.5182 0.5219 0.5250 0.5247 0.5165 0.5205 0.5308 17 0.5186 0.5015 0.4977 0.4960 0.5709 0.6534 0.6578 0. 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Algorithm 1 SafeGround: ClopperPearson Threshold Calibration with Sampling-Based Spatial Uncertainty 1: Input: GUI grounding model ; calibration set Dcal = {(xi, qi, i=1; sample count K; patch grid size ; region threshold ratio β; admission function A(ˆy, B); risk level α; significance level δ; weights (wCD, wIE, wT A) )}N 2: Output: calibrated uncertainty threshold ˆτ 3: for = 1 to do 4: (Primary prediction) Obtain ˆy(M LG) (Sampling) Draw stochastic predictions Si = {ˆy(k) (Discretized density map) Initialize count map NHW 0 for = 1 to do (xi, qi) }K Map ˆy(k) to patch index (u, v) and set Cu,v Cu,v + 1 k=1 via stochastic decoding (cid:80) u,v Cu ,v end for Normalize to density Pu,v Cu,v (Region extraction) Pmax maxu,v Pu,v; mask Mu,v I{Pu,v > βPmax} Group 4-connected active patches in into Mi connected components via BFS, yielding regions Ri = {Ri,m}Mi (Region scoring) For each region Ri,m, compute Si,m 1 Sort scores in descending order: Si,(1) Si,(Mi) Induce categorical distribution ˆpi,j Si,(j) (Uncertainty components) 1 Si,(1)Si,(2) Mi 2 max(0.1, 1 Si,(1)), Mi = UT A,i (u,v)Ri,m ℓ=1 Si,(ℓ) Si,(1)+ϵ Pu,v Ri,m (cid:80)Mi (cid:80) (cid:40) , m=1 (cid:80)Mi log Mi j=1 ˆp2 i,j j=1 ˆpi,j log(ˆpi,j + ϵ) UIE,i 1 UCD,i 1 (cid:80)Mi (Combined uncertainty) ui wCDUCD,i + wIEUIE,i + wT AUT A,i (Error indicator) erri I{A(ˆy(M LG) 21: 22: end for 23: Sort uncertainties ascending: u(1) u(N ) with aligned err(1), . . . , err(N ) 24: Initialize the selected threshold ˆτ NULL 25: for = 1 to do 26: ) = 0} , Compute ClopperPearson upper bound: UCB BetaInv(1 δ; + 1, X) if UCB α then Update ˆτ τ (number of accepted samples) (number of errors among accepted) I{u(j) τ } I{u(j) τ err(j) = 1} j=1 Set candidate threshold τ u(t) (cid:80)N 27: j=1 28: (cid:80)N 29: 30: 31: end if 32: 33: end for 34: if ˆτ = NULL then 35: 36: else 37: 38: end if Return ˆτ Return The target risk level α is unattainable under calibration. 18 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 15. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for GTA1-7B. Figure 16. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for GUI-Actor-2.5VL-7B. Figure 17. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for GUI-Actor-2VL-7B. 19 SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 18. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for Holo1.5-7B. Figure 19. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for Holo1.5-3B. Figure 20. Sensitivity analysis of AUROC and AUARC to uncertainty weighting for UI-TARS-1.5-7B."
        }
    ],
    "affiliations": [
        "University of California, Santa Barbara",
        "University of California, Santa Cruz"
    ]
}