{
    "paper_title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
    "authors": [
        "Yilun Xu",
        "Weili Nie",
        "Arash Vahdat"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Sampling from diffusion models involves a slow iterative process that hinders their practical deployment, especially for interactive applications. To accelerate generation speed, recent approaches distill a multi-step diffusion model into a single-step student generator via variational score distillation, which matches the distribution of samples generated by the student to the teacher's distribution. However, these approaches use the reverse Kullback-Leibler (KL) divergence for distribution matching which is known to be mode seeking. In this paper, we generalize the distribution matching approach using a novel $f$-divergence minimization framework, termed $f$-distill, that covers different divergences with different trade-offs in terms of mode coverage and training variance. We derive the gradient of the $f$-divergence between the teacher and student distributions and show that it is expressed as the product of their score differences and a weighting function determined by their density ratio. This weighting function naturally emphasizes samples with higher density in the teacher distribution, when using a less mode-seeking divergence. We observe that the popular variational score distillation approach using the reverse-KL divergence is a special case within our framework. Empirically, we demonstrate that alternative $f$-divergences, such as forward-KL and Jensen-Shannon divergences, outperform the current best variational score distillation methods across image generation tasks. In particular, when using Jensen-Shannon divergence, $f$-distill achieves current state-of-the-art one-step generation performance on ImageNet64 and zero-shot text-to-image generation on MS-COCO. Project page: https://research.nvidia.com/labs/genair/f-distill"
        },
        {
            "title": "Start",
            "content": "One-step Diffusion Models with -Divergence Distribution Matching Yilun Xu NVIDIA yilunx@nvidia.com Weili Nie NVIDIA wnie@nvidia.com Arash Vahdat NVIDIA avahdat@nvidia.com 5 2 0 2 1 ] . [ 1 1 8 6 5 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Sampling from diffusion models involves slow iterative process that hinders their practical deployment, especially for interactive applications. To accelerate generation speed, recent approaches distill multi-step diffusion model into single-step student generator via variational score distillation, which matches the distribution of samples generated by the student to the teachers distribution. However, these approaches use the reverse KullbackLeibler (KL) divergence for distribution matching which is known to be mode seeking. In this paper, we generalize the distribution matching approach using novel -divergence minimization framework, termed -distill, that covers different divergences with different trade-offs in terms of mode coverage and training variance. We derive the gradient of the -divergence between the teacher and student distributions and show that it is expressed as the product of their score differences and weighting function determined by their density ratio. This weighting function naturally emphasizes samples with higher density in the teacher distribution, when using less mode-seeking divergence. We observe that the popular variational score distillation approach using the reverse-KL divergence is special case within our framework. Empirically, we demonstrate that alternative -divergences, such as forward-KL and Jensen-Shannon divergences, outperform the current best variational score distillation methods across image generation tasks. In particular, when using JensenShannon divergence, -distill achieves current state-of-theart one-step generation performance on ImageNet64 and zero-shot text-to-image generation on MS-COCO. Project page: https://research.nvidia.com/labs/genair/f-distill/ 1. Introduction Diffusion models [12, 58] are transforming generative modeling in visual domains, with impressive success in generating images [1, 43, 44], videos [13, 53], 3D objects [32, 75], motion [74, 76], etc. However, one of the key limitations of deploying diffusion models in real-world applications is their slow and computationally expensive sampling process that involves calling the denoising neural network iteratively. Early works on accelerating diffusion models relied on better numerical solvers for solving the ordinary differential equations (ODEs) or stochastic differential equations (SDEs) that describe the sampling process of diffusion models [15, 17, 29, 54, 67]. However, these methods can only reduce the number of sampling steps to around tens of steps, due to the discretization error, accumulated with fewer steps. More recently, distillation-based approaches aim at the ambitious goal of reducing the number of sampling steps to single network call. These approaches can be generally grouped into two categories: 1) trajectory distillation [9, 23, 28, 55, 59] which distills the deterministic ODE mapping between noise and data intrinsic in diffusion model to onestep student, and 2) distribution matching approaches [71, 72, 79, 82] that ignore the deterministic mappings, and instead, matches the distribution of samples generated by one-step student to the distribution imposed by pre-trained teacher diffusion model. Among the two categories, the latter often performs better in practice as the deterministic mapping between noise and data is deemed complex and hard to learn. Naturally, the choice of divergence in distribution matching plays key role as it dictates how the students distribution is matched against the teachers. Existing works [71, 72] often use variational score distillation [64] that matches the distribution of the student and teacher by minimizing the reverse-KL divergence. However, this divergence is known to be mode-seeking [2] and can potentially ignore diverse modes learned by the diffusion model. In this work, we propose novel generalization of the distribution matching distillation approach using the - divergence, termed -distill. The -divergence represents large family of divergences including reverse-KL, forwardKL, Jensen-Shannon (JS), squared Hellinger, etc. These divergences come with different trade-offs on how they penalize the student for missing modes in the teacher distribution and how they can be estimated and optimized using Monte Carlo sampling. Within our framework, we evaluate various -divergences based on these properties and observe different tradeoff. For instance, forward-KL has better mode coverage, but has large gradient variance; JS demonstrates moderate mode-seeking and gradient saturation, particularly in early training stages, but exhibits low variance. Our analysis reveals that no single -divergence consistently outperforms others across all datasets. We observe divergences with better mode coverage tendencies generally perform better on the CIFAR-10 dataset. However, on Figure 1. The gradient update for the one-step student in -distill. The gradient is product of the difference between the teacher score and fake score, and weighting function determined by the chosen -divergence and density ratio. The density ratio is readily available from the discriminator in the auxiliary GAN objective. weight the score difference in the areas where the teacher has low density. This is in line with the recent observation that score estimation in low-density regions can be inaccurate [18], and it allows our model to adaptively rely less on matching its score with the teachers unreliable score on such regions. Empirically, we validate the -distill framework on several image generation tasks. Quantitative results demonstrate that the less mode-seeking divergences in -distill consistently outperform previous best variational score distillation approaches. Notably, by minimizing the less mode-seeking and lower gradient variance Jensen-Shannon divergences, -distill achieves new state-of-the-art one-step generation performance on ImageNet-64 and zero-shot MS-COCO (using SD v1.5). Furthermore, our experiments confirm that the weighting function effectively assigns smaller weights to regions with larger score differences. Contributions. (i) We propose novel generalization of distribution matching distillation using -divergence, allowing flexibility in how the student distribution is matched against the teachers. (ii) We discuss different trade-offs with different choices of -divergence in terms of mode seeking, gradient saturation and variance. (iii) We provide practical guidelines on reducing the variance of gradient and estimating different terms in the objective efficiently. (iv) We empirically show that our proposed -distill achieves the state-ofthe-art FID score in one-step generation on the ImageNet-64 and zero-shot MS-COCO text-to-image benchmark. 2. Background 2.1. Diffusion models The goal of -distill is to accelerate the generation of pretrained (continuous-time) DMs [12, 58]. In this paper, we follow the popular EDM framework [17] for the notations and forward/backward processes. DMs perturb the clean data x0 pdata in fixed forward process using σ2(t)-variance Gaussian noise, where x0 Rd and denotes the time along the diffusion process. The resulting intermediate distribution is denoted as pt(xt) with xt Rd. For notation simplicity, we will use to replace xt, unless stated otherwise, throughout the paper. For sufficiently large σmax, this disFigure 2. Score difference and the weighting function on 2D example. is the weighting function in forward-KL. Observe that the teacher and fake scores often diverge in lower-density regions (darker colors in the bottom left figure indicate larger score differences), where larger estimation errors occur. The weighting function downweights these regions (lighter colors in the bottom right figure) during gradient updates for -distill. large-scale challenging datasets like ImageNet-64 and textto-image generation with Stable Diffusion (SD), divergences with lower variance achieve superior results. Our derivation of the -divergence distribution matching shows that the gradient of the objectives is the product of the difference in score between teacher and student (which also exists in prior works), and weighting function that depends on density ratio and the chosen -divergence (new in this work), as illustrated in Fig. 1. The density ratio can be readily obtained from the discriminator in the commonly used auxiliary GAN objective. We show that the previous DMD approach is special case of our approach that corresponds to constant weighting. We discuss how the newly derived weighting coefficient influences the tradeoffs discussed above and propose normalization techniques for stabilizing divergences with higher gradient variance. As shown in Fig. 2, we observe that the weight coefficient for -divergences with less mode-seeking tendency will down2 tribution is almost identical to pure random Gaussian noise. DMs leverage this observation to sample the initial noise ϵmax (0, σ2 maxI), and then iteratively denoise the sample by solving the following backward ODE/SDE, which guarantees that if σ(0) = 0, the final follows the data distribution pdata: dx = σ(t)σ(t)x log pt(x)dt (cid:125) (cid:123)(cid:122) Probability Flow ODE (cid:124) β(t)σ2(t)x log pt(x)dt + (cid:112)2β(t)σ(t)dωt (cid:125) (cid:123)(cid:122) (cid:124) Langevin Diffusion SDE , (1) where ωt is standard Wiener process and log pt(x) is the score function of the intermediate distribution pt(x). The score function is learned by neural network sϕ(x; σ(t)) trained with the denoising score matching objective [56, 62]. In Equation (1), the first term is the Probability Flow ODE, which guides samples from high to low noise levels. The second term is Langevin Diffusion SDE, which acts as an equilibrium sampler across different noise levels σ(t), effectively refining the samples and correcting errors during the sampling process [17, 67]. This component can be scaled by the time-dependent parameter β(t). Setting β(t) = 0 leads to pure ODE-based synthesis. However, solving the diffusion ODE and SDE typically involves considerable number of iterations (often tens or hundreds), posing significant challenge to the practical deployment of diffusion models. Although different kinds of accelerated samplers for diffusion ODE [17, 29, 54] and SDE [15, 17, 67] have been proposed, they usually still require > 20 sampling steps in practice to produce decent samples. 2.2. Variational score distillation recent line of works [71, 72] aim to distill the teacher diffusion models sϕ into single step generator Gθ, through variational score distillation (VSD), which is originally introduced for test-time optimization of 3D objects [64]. The goal is to enable student model Gθ to directly map the noise from the prior distribution p(z) = (z; 0, I) to the clean sample x0 at σ = 0 using x0 = Gθ(z), effectively bypassing the iterative sampling process. Let pϕ denote the distribution obtained by plugging in pre-trained diffusion models sϕ(x; σ(t)) in Equation (1), and let qθ denote the output distribution by the one-step generator Gθ (in the following text, we drop the subscript in pϕ and qθ for notation simplicity). Then, the gradient update for the generator can be formulated as follows: Et,z,ϵ [(sϕ(x; σ(t)) log qθ(x; σ(t))) θGθ(z)] (2) where = Gθ(z) + σ(t)ϵ and ϵ (0, I). Intuitively, the gradient encourages the generator to produce samples that lie within high-density regions of the data distribution. This is achieved through the teacher score term, sϕ(x; σ(t)), which guides the generated samples towards areas where the teacher model assigns high probability. To prevent mode collapse, the gradient also incorporates term that discourages the generator from simply concentrating on single high-density point in the teachers distribution. This is done by subtracting the score of the student distribution, log qθ(x; σ(t)). The gradient update is shown to perform distribution matching by minimizing the reverse-KL divergence between the teacher and student distributions [39, 72]. To estimate the score of the student distribution, previous works [64, 72] have employed another fake score network sψ(x, σ(t)) to approximate log qθ(x; σ(t)). The fake score network sψ(x, σ(t)) is dynamically updated with the standard denoising score matching loss, where the clean samples come from the generator Gθ during training. Thus, the VSD training alternates between the generator update and the fake score update, with two time-scale update rule for stabilized training [71]. Additionally, to further close the gap between the one-step generator and the multi-step teacher diffusion model, GAN loss is applied to the VSD training pipeline [71], where lightweight GAN classifier takes as input the middle features from the fake score network. 2.3. f-divergence In probability theory, an -divergence [41] quantifies the difference between two probability density functions, and q. Specifically, when is absolutely continuous with respect to q, the -divergence is defined as: Df (pq) = (cid:90) q(x)f (cid:19) (cid:18) p(x) q(x) dx where is convex function on (0, +) satisfying (1) = 0. This divergence satisfies several important properties, including non-negativity and the data processing inequality. Many commonly used divergences can be expressed as special cases of the -divergence by choosing an appropriate function . These include the forward-KL divergence, reverse-KL divergence, Hellinger distance, and Jensen-Shannon (JS) divergence, as shown in Table 1. In generative learning, -divergence has been widely applied to popular generative models, such as GANs [37], VAEs [63], energy-based models [73] and diffusion models [60]. 3. Method: general -divergence minimization In this section, we introduce general distillation framework, termed -distill, based on minimizing the -divergence between the teacher and student distributions. Since the student distribution is the push-forward measure induced by the one-step generator Gθ, it implicitly depends on the generators parameters θ. Due to this implicit dependency, directly calculating the gradient of -divergence, Df (pq), w.r.t θ presents challenge. However, the following theorem establishes the analytical expression for this gradient, revealing that it can be formulated as weighted version of the gradient employed in variational score distillation. Notably, these weights are determined by the density ratio of the generated samples. We state the theorem more generally by providing the gradient for pt and qt, where pt is the perturbed distribution through the diffusion forward process for the (r) h(r) Mode-seeking? Saturation? Variance reverse-KL softened RKL Jensen-Shannon squared Hellinger forward-KL Jeffreys log (r + 1) log ( 1 2r ) log (r + 1) log r+1 2 + 1 1 log (r 1) log(r) 1 1 r+1 r+1 1 1 4 2 + 1 Yes Yes Medium Medium No No No No Yes Yes No No - Low Low Low High High Table 1. Comparison of different -divergences as function of the likelihood ratio := p(x)/q(x) teachers distribution p, i.e., pt = p0 (0, σ2(t)I) (same for the student distribution q). Theorem 1. Let be the teachers generative distribution, and let be distribution induced by transforming prior distribution p(z) through the differentiable mapping Gθ. Assuming is twice continuously differentiable, then the gradient of -divergence between the two intermediate distribution pt and qt w.r.t θ is: θDf (ptqt) = Ez,ϵ (cid:34) (cid:18) pt(x) qt(x) (cid:19) (cid:18) pt(x) qt(x) (cid:19)2 log pt(x) (cid:123)(cid:122) (cid:125) teacher score (cid:124) log qt(x) (cid:123)(cid:122) (cid:125) fake score (cid:124) θGθ(z) (3) where p(z), ϵ (0, I) and = Gθ(z) + σ(t)ϵ Proof sketch. For simplicity, we prove the = 0 case in the main text. Similar proof applies for any > 0. θDf (p(x)q(x)) = θ (cid:90) q(x)f ( p(x) q(x) )dx = (cid:90) (cid:124) θq(x)f ( (cid:123)(cid:122) p(x) q(x) )dx (cid:125) (cid:90) (cid:124) θq(x)f ( p(x) q(x) (cid:123)(cid:122) II ) p(x) q(x) dx (cid:125) It can be shown that (I) / (II) arises from the term associated with the partial derivative of with respect to / q, respectively. Above we see that both partial derivatives (I) and (II) are in the form (cid:82) θq(x)g(x)dx where is differentiable function that is constant with respect to θ. Assuming that sampling from q(x) can be parameterized to = Gθ(z) for p(z), we can use the identity (cid:82) θq(x)g(x)dx = (cid:82) p(z)xg(x)θGθ(z)dz. The proof for the identity is provided in the Appendix. Using the identity we can simplify (I) and (II) to: (cid:90) (cid:90) (cid:90) = II = + p(z)f ( p(z)f ( p(x) q(x) p(x) q(x) p(x) q(x) p(z)f ( )x )x p(x) q(x) θGθ(z)dz ) p(x) q(x) p(x) q(x) θGθ(z)dz p(x) q(x) θGθ(z)dz Putting (I) and (II) in Eq. (3), we have: (cid:90) (cid:90) θDf = = p(z)f ( p(z)f ) p(x) q(x) (cid:18) p(x) q(x) θGθ(z)dz p(x) q(x) (cid:19)2 p(x) q(x) (cid:19) (cid:18) p(x) q(x) [x log p(x) log q(x)] θGθ(z)dz where the last identity is from the log derivative trick. We defer the completed proofs to Section in the supplementary material. Although the students generative distribution depends on the parameter θ, Theorem 1 provides an analytical expression for the gradient of -divergences between the teachers and students generative distributions. This gradient is expressed as the score difference between the teachers and students distributions, weighted by timedependent factor (pt(xt)/qt(xt)) (pt(xt)/qt(xt))2 determined by both the chosen -divergence and the density ratio. Crucially, every term in the theorem is tractable , enabling the optimization of distributional matching through general -divergence minimization. For notation convenience, let h(r) := (r)r2 denote the weighting function, and rt(x) := pt(x)/qt(x) denote the density-ratio at time t. It is worth noting that the gradient of the variational score distillation (Eq. (2)) can be recovered as special case of our framework by setting h(r) 1 in Eq. (3), which corresponds to minimizing the reverse-KL divergence (f (r) = log r). [57] also shows connection between f-divergence and score difference, expressing the former as time integral of the squared score difference in their Theorem 2. However, our formulation differs in two key aspects: (1) Their objectives gradient necessitates computing Jacobian-vector product, which can be computationally expensive. (2) While their -divergence is expressed as an integral of the score difference over time, our -divergence, Df (ptqt), depends only on the weighting and score at time t. In the following proposition, we further show that if the weighting function is continuous and non-negative on (0, +), then its product with score difference is the gradient of certain -divergence: Proposition 1. For any function that is continuous the expectation Ez,ϵ and non-negative on (0, +), [h (rt(x)) (x log pt(x) log qt(x)) θGθ(z)] corresponds to the gradient of an -divergence. Although we limit our study in this paper to canonical forms of -divergence, Proposition 1 allows us to use any continuous and non-negative scalar function as h. In practice, [72] suggests performing distributional matching all the time along the diffusion process, as teacher and student will have high discrepancy at smaller times, leading to optimization difficulties. We follow this setup and minimize the -divergence along the whole time range, i.e., L(θ) = (cid:82) 0 wtDf (ptqt)dt, where wt is time-dependent weight for equalizing the gradient magnitudes across times. The final objective function for -distill is as follows: (cid:104) Lf -distill(θ) = Et,x sg(cid:0)wth(rt(x))(x log pt(x) log qt(x))(cid:1)T (4) (cid:105) and sg where x=Gθ(z)+σ(t)ϵ, zp(z), ϵN (0, I), stands for stop gradient. The gradient of Eq. (4) equals the time integral of the gradient of -divergence in Theorem 1 (Eq. (3)). In practice, the score of student distribution log qt(xt) is approximated by an online diffusion model sψ(x, σ(t)). [71] augments the variational score distillation loss with GAN objective to further enhance performance. This is motivated by the fact that variational score distillation relies solely on the teachers score function and is therefore limited by the teachers capabilities. Incorporating GAN objective allows the student generator Gθ to surpass the teachers limitations by leveraging real data to train discriminator Dλ: LGAN(λ) = Et,xpdata,ϵ1 [log Dλ(x + σ(t)ϵ1)]+ Et,z,ϵ2[log(1 Dλ(Gθ(z) + σ(t)ϵ2))] where zp(z), ϵ1, ϵ2 (0, I). We incorporate the auxiliary GAN objective as in prior work, which offers the additional advantage of providing readily available estimate of the density ratio r(xt) required by the weighting function in Eq. (4). The density ratio is approximated as follows: r(xt) = pt(x)/qt(x) pdata,t/qt(x) = Dλ(xt, t)/(1 Dλ(xt, t)). In essence, the GAN discriminator Dλ provides direct estimate of the density ratio, facilitating the computation of the weighting function. 4. Comparing properties of -divergence In this section, we compare the properties across different distance measures in the -divergence family, in the context of diffusion distillation. We will inspect their three properties: mode-seeking, saturation, and variance during training. We summarize the comparison of different s, and their corresponding weighting function h, in Table 1. Mode-seeking. Mode-seeking divergences [2, 24], such as reverse-KL, encourage the generative distribution only to capture subset of the modes of data distribution, and tend to avoid assigning probability mass to regions of low data density when solving minq Df (pq) = (cid:82) qf (p/q)dx. This behavior, however, is undesirable for generative models 5 (a) (b) Figure 3. The absolute value of (a) and weighting function h(r) (b) in different -divergences. as it can lead to dropped modes and loss of diversity in generated samples. This phenomenon is observed in the variational score distillation loss [28] used in DMD [71, 72], which corresponds to minimizing the reverse-KL divergence in -distill . One way to characterize mode-seeking behavior is by examining the limit limr (r)/r [24]. lower growth rate of the limit indicates less mode-seeking (we defer detailed discussions to Sec C). Both reverse-KL and JS divergences exhibit this finite limit, with JS having slower growth rate (and thus, less mode-seeking behavior). In contrast, forward-KL has an infinite limit, echoing its well-known mode-covering property. It is noteworthy that in Table 1, divergences with stronger tendency towards mode-seeking also exhibit slower rate of increase in their weighting function h(r) as r. This behavior stems from the fact that (r) = h(r)/r2 also increases more slowly, thus tolerating larger density ratios p/q (i.e., allowing to disregard some modes in p), ultimately leading to mode-seeking behavior [52]. For example, in JS and forward-KL is an increasing function, while in reverse-KL stays constant. As result, the weighting function in less mode-seeking divergence will tend to downweight samples in low-density regions of teacher distribution. Saturation. challenge encountered by prior generative models, such as GANs [10], when utilizing -divergence is the issue of saturation. In the early stages of training, the generative and data distribution are often poorly aligned, resulting in samples from having very low probability under q, and vice versa. Consequently, the density ratio p/q tends to be either extremely large or near zero. This poses optimization issues when divergences have small gradients at both extremes. From Fig. 3a, we can see that squared Hellinger and JS divergences have smaller gradients at the extremes. Nevertheless, in diffusion distillation, the saturation issue can be mitigated by initializing the weights of the student model with the pre-trained diffusion models [71, 72]. Variance. The variance of the weighting function in the final objective (Eq. (4)) is essential to training stability in mini-batch training. We use the normalized variance Varq to characterize the variance of different s, ensuring scale-invariant comparison. Fig. 4a illustrates the normalized variance as (p/q) (p/q)2 /Eq[f (p/q) (p/q)2] (cid:17) (cid:16) FID Recall NFE Multi-step diffusion models EDM (Teacher) [17] RIN [14] DisCo-Diff [69] GANs BigGAN-deep [3] StyleGAN-XL [48] Diffusion distillation DSNO [80] Diff-Instruct [33] iCT [55] iCT-deep [55] Moment Matching [47] DMD [72] ECM [9] TCM [23] EMD [66] CTM [20] Adversarial distillation SiD [82] GDD [79] GDD-I [79] -distill reverse-KL (DMD2 [71]) forward-KL (ours) JS (ours) 2.35 1.23 1.22 4.06 1.52 7.83 5.57 4.02 3.25 3.00 2.62 2.49 2.20 2.20 1.92 1.88 1.52 1.42 1.16 1.27 1.21 1.16 0.68 0. 0.61 0.63 0.63 0.59 0.57 0.63 0.59 0.60 0.65 0.65 0.66 79 1000 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Table 3. FID score, Recall and NFE on ImageNet-64. 5. Experiment 5.1. Image generation We evaluate -distill on CIFAR-10 [21] and ImageNet 6464 [7] for class-conditioned image generation, and on zero-shot MS COCO 2014 [25] for text-to-image generation. We use COYO-700M [4] as the training set for text-to-image generation. We use pre-trained models in EDM [17] as teachers for CIFAR-10 / ImageNet-64, and Stable Diffusion (SD) v1.5 [42] for text-to-image generation. For hyper-parameters, we use batch size of 2048 / 512 / 1024 for CIFAR-10 / ImageNet-64 / COYO-700M. As DMD2 [71] is special case (reverse-KL) under the -distill framework, we borrow their tuned hyper-parameters, including learning rates, CFG guidance weight, update frequency for fake score and discriminator, and the coefficient for GAN loss in generator update. We posit that hyperparameters tuned for reverse-KL should generalize effectively to other divergences. In the text-to-image experiment, we observe that the estimation of density ratio (and thus the weighting function h) by the discriminator is inaccurate at the early stage of training. To address this, we warm up the discriminator by initializing the model with pre-trained reverse-KL model, which has constant h. We defer the training details to Section in the supplementary material. Our baseline comparisons include multi-step diffusion models and existing diffusion distillation techniques. We also re-implemented DMD2 [71] (reverse-KL) within our codebase. Furthermore, to isolate the impact of our proposed -distill objective, we conducted an ablation study by removing it and training solely with the GAN objective (denoted (a) (b) (a) Normalized variance versus the mean difference Figure 4. between two Gaussians. (b) Training losses of forward-KL w/ and w/o normalizations. function of the mean difference between two 1D unitvariance Gaussians. Notably, the variance of the forward-KL divergence and the Jefferys increases significantly as the distance between the Gaussians grows. In contrast, the Jensen-Shannon divergence and the squared Hellinger distance remain relatively stable. This stability contributes to the superior empirical performance of the low-variance Jensen-Shannon divergence in the experimental section. Practical considerations. To address the high variance often observed in weighting functions for less mode-seeking divergences (see Fig. 3b), we propose two-stage normalization scheme. The first stage normalizes the time-dependent density ratio rt, leveraging the fact the expectation of rt is 1, i.e., Eqt[rt] = 1. To enforce this property, we discretize the time range into bins and normalize the values of rt within each bin by their average. The second stage directly normalizes the weighting function by its average value within each mini-batch. This normalization is crucial because the training process involves both the -distill objective and the GAN objective. It ensures scale-invariance for the weightings, as the scale can vary significantly for different s. This also maintains the relative importance of the -distill objective w.r.t the GAN objective, providing stability and consistency across different choices of -divergence. Fig. 4b demonstrates that the loss exhibits much smaller variance after the above normalization techniques on ImageNet-64 using the forward-KL divergence. We provide an algorithm box in Alg 1. EDM [17] (NFE=35) 1.79 0.63 FID Recall Diffusion distillation Adversarial distillation SiD [82] CTM [19] GDD-I [79] -distill reverse-KL (, DMD2 [71]) softened RKL () squared Hellinger () JS () Jeffreys () forward-KL () 2.60 1.71 1.73 1.44 2.13 2.21 1.99 2.00 2.05 1.92 0.60 0.60 0.63 0.62 0.62 0.62 Table 2. FID and Recall scores on CIFAR-10. // stand for high/medium/low mode-seeking tendency for -divergence. 6 FID CLIP score Latency Multi-step diffusion models LDM [42] DALLE 2 [40] Imagen [45] eDiff-I [1] UniPC [78] Restart [67] Teacher SDv1.5 (NFE=50, CFG=3, ODE) SDv1.5 (NFE=200, CFG=2, SDE) GANs StyleGAN-T [49] GigaGAN [16] Diffusion distillation SwiftBrush [36] SwiftBrush v2 [6] HiPA [77] InstaFlow-0.9B [27] UFOGen [70] DMD [72] EMD [66] CFG=1.75 reverse-KL (DMD2 [71]) JS (ours) CFG=5 reverse-KL (DMD2 [71]) JS (ours) 12.63 10.39 7.27 6.95 19.57 13.16 8.59 7.21 13.90 9.09 16.67 8.14 13.91 13.10 12.78 11.49 9.66 8.17 7. 15.23 14.25 0.28* 0.29* 0.299 0.308 0.301 0.29* 0.29* 0.32* 0.287 0.292 0.309 0.311 3.7s 27s 9.1s 32.0s 0.26s 3.40s 2.59s 10.25s 0.10s 0.13s 0.09s 0.06s 0.09s 0.09s 0.09s 0.09s 0.09s 0.09s 0.09s 0.09s 0.09s Table 4. FID score together with inference latency on text-to-image generation, zero-shot MS COCO-30k 512 512. * denotes that the value is taken from the corresponding paper. as Adversarial distillation in the tables). Evaluations. We measure sample quality with Frechet Inception Distance (FID) [11]. For diversity, we use the Recall score [22]. For image-caption alignment, we report the CLIP score. We defer more evaluations to Appendix D.2 and D.3 on diversity and image quality. Results. We first experiment with all the -divergences in Table 1 on CIFAR-10. Table 2 shows that (1) all the variants under -distill outperform the adversarial distillation baseline, validating the effectiveness of distributional matching by -distill in addition to GAN objective. (2) -divergences with milder mode-seeking behavior generally yield better performance. Specifically, forward-KL and Jeffreys divergences, which lack mode-seeking properties, achieve significantly lower FID scores, and higher Recall scores, than divergences with mode-seeking characteristics (e.g., , reverse-KL, softened RKL). We also list some recent works for comparison. Note that GDD-I and CTM utilize external pre-trained feature extractors and extensive tuning for their GAN objective. In contrast, our approach simply employs the teacher model as feature extractor, as we primarily use this dataset to analyze the relative performance of different s. Table 3 and Table 4 report FID, Recall and CLIP score in two more challenging datasets. We report the inference latency on single NVIDIA A100 GPU for fair comparison on text-to-image generation, as in [71]. Our main findings are: (1) -distill with JS divergence achieves the current state-of-the-art one-step FID score on both ImageNet-64 and zero-shot MS COCO. Concretely, JS achieves FID scores of 1.16 on ImageNet-64, outperforming previous best-performing diffusion models, GANs, and distillation methods, except for GDD-I [79]. However, GDD-I solely applies the GAN objective to diffusion distillation, which is known to be unstable in large-scale settings. It is reflected in the worse Recall score of GDD-I, compared to JS in -distill. Furthermore, JS obtains an FID score of 7.42 on MS COCO, when using CFG=1.75, significantly outperforming previous distillation methods and approaching the performance of leading diffusion models like eDiff-I [1] (FID of 6.95). (2) Forward-KL and JS get better FID scores than reverse-KL. The two variants with less mode-seeking behavior continue to outperform the reverse-KL (DMD2 [71]). In addition, for CLIP score, we observed that the JS outperforms reverse-KL with varying CFG weight. In particular, JS still achieves decent CLIP score (0.292) while achieving state-of-the-art one-step FID score (7.42). When using higher CFG value 5 in distillation, the JS outperforms most of all the baselines except SwiftBruch v2 [6], which uses more advanced SD2.1 as teacher model and additional CLIP loss during training. (3) JS outperforms forward-KL due to smaller variance. While forward-KL can be less mode-seeking, it suffers from higher variance. Our experiments on ImageNet64 confirm that JS exhibits significantly more stable training process (Section D), resulting in better FID score. We further provide visual comparison of generated samples by teacher and student in Fig. 6. We observe that the generated images by one-step students generally have richer details and more aligned with the text prompts. We provide detailed prompts and extended samples in Sec in the supplementary material. 5.2. Behavior of in non-mode-seeking divergences As discussed in Section 4, -divergence with medium or no mode-seeking property has faster increasing second derivative , resulting in an increasing weighting function h(r) = (r)r2. This means that generated samples in the low-density regions of the data distribution will be downweighted accordingly, and the teacher models are prone to inaccurate score estimation in these regions [18]. To further understand the behavior of h, we study its relation with the score difference between teacher and fake score, i.e., sϕ(x; σ(t)) sψ(x, σ(t))2 on real datasets. Recall that the teacher sϕ approximates the true score, i.e., sϕ(x; σ(t)) log pt(x), and the online fake score approximate the generated distribution, i.e., sψ(x, σ(t)) log qt(x). We compute both and the score difference for 6.4k generated samples and sort them in ascending order of their score difference. Fig. 5 shows that the samples weighting generally goes in the opposite direction with its score difference when using non-mode-seeking divergences. This observation suggests that when using nonmode-seeking divergences, -distill effectively downweights samples in regions where the teacher and fake scores exhibit substantial discrepancies, which typically correspond to lowdensity regions of the true data distribution. (a) (b) (c) Figure 5. Normalized weighting function and score difference versus the index of 6.4k generated samples, sorted by the score difference, on (a) CIFAR-10 with forward-KL; (b) ImageNet-64 with JS; (c) SDv1.5 with JS. Figure 6. (a) Uncurated generated samples by the multi-step teacher diffusion models (top), and one-step student in -distill (bottom), using the same random seed. The teacher diffusion models use 35 and 50 steps on ImageNet-64 and Stable Diffusion v1.5, respectively. (b) Generated samples by reverse-KL and JS, using prompt in COYO: blue and white passenger train coming to stop. 6. Related work As the sampling process in diffusion models is essentially solving the ODEs or SDEs [58], many early works focus on reducing the sampling steps with faster numerical solvers [17, 26, 30, 54, 81]. However, they usually still require more than 20 steps due to the discretization error. Diffusion distillation has recently attracted more attention due to its promising goal of reducing the number of sampling steps to one single network call. It mainly includes two classes of distillation approaches: (1) Trajectory distillation, which trains one-step student model to mimic the deterministic sampling process of the teacher diffusion model. Knowledge distillation [31, 80] learns direct mapping from noise to data. Progressive distillation [35, 46] iteratively halves the number of sampling steps via distillation. Consistency models [9, 23, 28, 55, 59] lean consistency function that maps any noisy data along an ODE trajectory to the associated clean data. (2) Distribution matching, which aligns the distribution of the one-step student with that of the teacher diffusion model. Adversarial distillation [50, 51, 70] mainly relies on the adversarial training [10] to learn teacher outputs distribution. Another line of approaches implicitly minimizes various divergences, often via variational score distillation [65], such as reverse-KL [71, 72], forward KL [33, 66] and fisher divergence [82]. Score Implicit Matching [34] generalizes the fisher divergence [82] by relaxing the scorebased distance to have more general forms beyond squared L2. Our method lies in this category. Different from previous methods that only minimize particular distribution divergence, each of which may require vastly different training strategies [66, 71, 82], our method unifies the class of -divergences in principled way and thus offers better flexibility in distribution matching distillation. 7. Conclusions We have proposed -distill, novel and general framework for distributional matching distillation based on -divergence minimization. We derive gradient update rule comprising the product of weighting function and the score difference between the teacher and student distributions. -distill encompasses previous variational score distillation objectives while allowing less mode-seeking divergences. By leveraging the weighting function, -distill naturally downweights regions with larger score estimation errors. Experiments on various image generation tasks demonstrate the strong one-step generation capabilities of -distill."
        },
        {
            "title": "References",
            "content": "[1] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero KareDiff-I: Text-to-Image Diffusion ras, and Ming-Yu Liu. Models with Ensemble of Expert Denoisers. arXiv preprint arXiv:2211.01324, 2022. 1, 7 [2] Christopher M. Bishop. Pattern recognition and machine learning (information science and statistics). 2006. 1, 5, 14 [3] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural image synthesis. ArXiv, abs/1809.11096, 2018. 6, 16 [4] Minwoo Byeon, Beomhee Park, Haecheon Kim, Sungjun Lee, Woonhyuk Baek, and Saehoon Kim. Coyo-700m: Image-text pair dataset. https://github.com/kakaobrain/ coyo-dataset, 2022. 6 [5] M. Caron, H. Touvron, I. Misra, H. Jegou, J. Mairal, P. Bojanowski, and A. Joulin. Emerging properties in selfIn Proceedings of the supervised vision transformers. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021. 16 [6] Trung Dao, Thuan Hoang Nguyen, Thanh Le, Duc Vu, Khoi Nguyen, Cuong Pham, and Anh Tran. Swiftbrush v2: Make In your one-step diffusion model better than its teacher. European Conference on Computer Vision, pages 176192. Springer, 2025. 7, 17 [7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: large-scale hierarchical image database. In Computer Vision and Pattern Recognition (CVPR), 2009. [8] Corso et al. Particle guidance: non-iid diverse sampling with diffusion models. ICLR, 2024. 16 [9] Zhengyang Geng, Ashwini Pokle, William Luo, Justin Lin, and Zico Kolter. Consistency models made easy. arXiv preprint arXiv:2406.14548, 2024. 1, 6, 8 [10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 5, 8 [11] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium. In Advances in neural information processing systems, 2017. 7 [12] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. In Advances in Neural Information Processing Systems (NeurIPS), 2020. 1, 2, 16 [13] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David Fleet. Video diffusion models. Advances in Neural Information Processing Systems, 35:86338646, 2022. [14] A. Jabri, David J. Fleet, and Ting Chen. Scalable adaptive computation for iterative generation. In International Conference on Machine Learning, 2022. 6 [15] Alexia Jolicoeur-Martineau, Ke Li, Remi Piche-Taillefer, Tal Kachman, and Ioannis Mitliagkas. Gotta go fast when generating data with score-based models. ArXiv, abs/2105.14080, 2021. 1, 3 [16] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain Paris, and Taesung Park. Scaling up gans for text-to-image synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1012410134, 2023. 7 [17] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. ArXiv, abs/2206.00364, 2022. 1, 2, 3, 6, 8, 14, 16, 23, 24 [18] Tero Karras, Miika Aittala, Tuomas Kynkaanniemi, Jaakko Lehtinen, Timo Aila, and Samuli Laine. Guiding diffusion model with bad version of itself. arXiv preprint arXiv:2406.02507, 2024. 2, [19] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon. Consistency trajectory models: Learning probability flow ode trajectory of diffusion. ArXiv, abs/2310.02279, 2023. 6, 16 [20] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon. Consistency trajectory models: Learning probability flow ODE trajectory of diffusion. In The Twelfth International Conference on Learning Representations, 2024. 6 [21] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Toronto, ON, Canada, 2009. 6 [22] Tuomas Kynkaanniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall metric for assessing generative models. In Neural Information Processing Systems, 2019. 7 [23] Sangyun Lee, Yilun Xu, Tomas Geffner, Giulia Fanti, Karsten Kreis, Arash Vahdat, and Weili Nie. Truncated consistency models. arXiv preprint arXiv:2410.14895, 2024. 1, 6, 8 [24] Cheuk Ting Li and Farzan Farnia. Mode-seeking divergences: Theory and applications to gans. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, pages 83218350. PMLR, 2023. 5, 14 [25] Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick. Microsoft coco: Common objects in context. In European Conference on Computer Vision, 2014. [26] Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds. International Conference on Learning Representations, 2022. 8 [27] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, et al. Instaflow: One step is enough for high-quality diffusion-based text-to-image generation. In The Twelfth International Conference on Learning Representations, 2023. 7, 17 [28] Cheng Lu and Yang Song. Simplifying, stabilizing and scaling continuous-time consistency models. arXiv preprint arXiv:2410.11081, 2024. 1, 5, 8 [29] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: fast ode solver for diffusion probabilistic model sampling in around 10 steps. arXiv preprint arXiv:2206.00927, 2022. 1, 3 [30] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. arXiv preprint arXiv:2211.01095, 2022. 8 [31] Eric Luhman and Troy Luhman. Knowledge distillation in iterative generative models for improved sampling speed. arXiv preprint arXiv:2101.02388, 2021. 9 [32] Shitong Luo and Wei Hu. Diffusion probabilistic models for 3d point cloud generation. In CVPR, pages 28372845, 2021. 1 [33] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun, Zhenguo Li, and Zhihua Zhang. Diff-instruct: universal approach for transferring knowledge from pre-trained diffusion models. Advances in Neural Information Processing Systems, 36, 2024. 6, 8 [34] Weijian Luo, Zemin Huang, Zhengyang Geng, Zico Kolter, and Guo-jun Qi. One-step diffusion distillation through score implicit matching. arXiv preprint arXiv:2410.16794, 2024. 8, 16 [35] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans. On distillation of guided diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1429714306, 2023. 8 [36] Thuan Hoang Nguyen and Anh Tran. Swiftbrush: One-step text-to-image diffusion model with variational score distillation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 78077816, 2024. 7, [37] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. fgan: Training generative neural samplers using variational divergence minimization. Advances in neural information processing systems, 29, 2016. 3 [38] Ben Poole, Alexander A. Alemi, Jascha Narain SohlImproved generator obDickstein, and Anelia Angelova. jectives for gans. ArXiv, abs/1612.02780, 2016. 14 [39] Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. DreamFusion: Text-to-3D using 2D Diffusion. In The Eleventh International Conference on Learning Representations (ICLR), 2023. 3 [40] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical Text-Conditional Image Generation with CLIP Latents. arXiv preprint arXiv:2204.06125, 2022. 7 [41] Alfred Renyi. On measures of entropy and information. 1961. 3 [42] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-Resolution Image Synthesis with Latent Diffusion Models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. 6, 7 [43] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1068410695, 2022. 1, 14, 26 [44] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad Norouzi. Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding. In Advances in Neural Information Processing Systems (NeurIPS), 2022. 1 [45] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L. Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, Seyedeh Sara Mahdavi, Raphael Gontijo Lopes, Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. ArXiv, abs/2205.11487, 2022. [46] Tim Salimans and Jonathan Ho. Progressive distillation for fast sampling of diffusion models. International Conference on Learning Representations, 2022. 8 [47] Tim Salimans, Thomas Mensink, Jonathan Heek, and Emiel Hoogeboom. Multistep distillation of diffusion models via moment matching. arXiv preprint arXiv:2406.04103, 2024. 6 [48] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl: Scaling stylegan to large diverse datasets. ACM SIGGRAPH 2022 Conference Proceedings, 2022. 6, 16 [49] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and Timo Aila. Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis. In International conference on machine learning, pages 3010530118. PMLR, 2023. 7 [50] Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach. Adversarial diffusion distillation. arXiv preprint arXiv:2311.17042, 2023. 8 [51] Axel Sauer, Frederic Boesel, Tim Dockhorn, Andreas Blattmann, Patrick Esser, and Robin Rombach. Fast highresolution image synthesis with latent adversarial diffusion distillation. arXiv preprint arXiv:2403.12015, 2024. 8, 13 [52] Matt Shannon, Ben Poole, Soroosh Mariooryad, Tom Bagby, Eric Battenberg, David Kao, Daisy Stanton, and R. J. SkerryRyan. Non-saturating gan training as divergence minimization. ArXiv, abs/2010.08029, 2020. 5, 14, [53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. MakeA-Video: Text-to-Video Generation without Text-Video Data. In The Eleventh International Conference on Learning Representations (ICLR), 2023. 1 [54] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. ArXiv, abs/2010.02502, 2020. 1, 3, 8 [55] Yang Song and Prafulla Dhariwal. niques for training consistency models. arXiv:2310.14189, 2023. 1, 6, 8 Improved techarXiv preprint [56] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. In Proceedings of the 33rd Annual Conference on Neural Information Processing Systems, 2019. [57] Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of score-based diffusion models. Advances in neural information processing systems, 34:1415 1428, 2021. 4 [58] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. In International Conference on Learning Representations (ICLR), 2021. 1, 2, 8 [59] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. arXiv preprint arXiv:2303.01469, 2023. 1, 8 [60] Wenpin Tang. Fine-tuning of diffusion models via stochastic control: entropy regularization and beyond. arXiv preprint arXiv:2403.06279, 2024. 3 [61] Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based Generative Modeling in Latent Space. In Neural Information Processing Systems (NeurIPS), 2021. 16 driven human motion generation with diffusion model. arXiv preprint arXiv:2208.15001, 2022. 1 [77] Yifan Zhang and Bryan Hooi. Hipa: Enabling one-step text-toimage diffusion models via high-frequency-promoting adaptation. arXiv preprint arXiv:2311.18158, 2023. 7 [78] Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, and Jiwen Lu. Unipc: unified predictor-corrector framework for fast sampling of diffusion models. Advances in Neural Information Processing Systems, 36, 2024. 7 [79] Bowen Zheng and Tianming Yang. Diffusion models are innate one-step generators. arXiv preprint arXiv:2405.20750, 2024. 1, 6, 7, 16 [80] Hongkai Zheng, Weili Nie, Arash Vahdat, Kamyar Azizzadenesheli, and Anima Anandkumar. Fast sampling of arXiv preprint diffusion models via operator learning. arXiv:2211.13449, 2022. 6, 8 [81] Kaiwen Zheng, Cheng Lu, Jianfei Chen, and Jun Zhu. Dpmsolver-v3: Improved diffusion ode solver with empirical model statistics. Advances in Neural Information Processing Systems, 36, 2024. [82] Mingyuan Zhou, Huangjie Zheng, Zhendong Wang, Mingzhang Yin, and Hai Huang. Score identity distillation: Exponentially fast distillation of pretrained diffusion models for one-step generation. In Forty-first International Conference on Machine Learning, 2024. 1, 6, 8, 16 [62] Pascal Vincent. connection between score matching and denoising autoencoders. Neural Computation, 23(7):1661 1674, 2011. 3 [63] Neng Wan, Dapeng Li, and NAIRA HOVAKIMYAN. fdivergence variational inference. In Advances in Neural Information Processing Systems, 2020. 3 [64] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation. ArXiv, abs/2305.16213, 2023. 1, 3 [65] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation. Advances in Neural Information Processing Systems, 36, 2024. [66] Sirui Xie, Zhisheng Xiao, Diederik Kingma, Tingbo Hou, Ying Nian Wu, Kevin Patrick Murphy, Tim Salimans, Ben Poole, and Ruiqi Gao. Em distillation for one-step diffusion models. arXiv preprint arXiv:2405.16852, 2024. 6, 7, 8 [67] Yilun Xu, Mingyang Deng, Xiang Cheng, Yonglong Tian, Ziming Liu, and T. Jaakkola. Restart sampling for improving generative processes. ArXiv, abs/2306.14878, 2023. 1, 3, 7 [68] Yilun Xu, Ziming Liu, Yonglong Tian, Shangyuan Tong, Max Tegmark, and T. Jaakkola. Pfgm++: Unlocking the potential of physics-inspired generative models. In International Conference on Machine Learning, 2023. 16 [69] Yilun Xu, Gabriele Corso, Tommi Jaakkola, Arash Vahdat, and Karsten Kreis. Disco-diff: Enhancing continuous diffusion models with discrete latents. arXiv preprint arXiv:2407.03300, 2024. 6 [70] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufogen: You forward once large scale text-to-image generation via diffusion gans. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 81968206, 2024. 7, 8 [71] Tianwei Yin, Michael Gharbi, Taesung Park, Richard Zhang, Eli Shechtman, Fredo Durand, and William Freeman. Improved distribution matching distillation for fast image synthesis. arXiv preprint arXiv:2405.14867, 2024. 1, 3, 5, 6, 7, 8, 13, 16, 17 [72] Tianwei Yin, Michael Gharbi, Richard Zhang, Eli Shechtman, Fredo Durand, William Freeman, and Taesung Park. One-step diffusion with distribution matching distillation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 66136623, 2024. 1, 3, 5, 6, 7, 8, [73] Lantao Yu, Yang Song, Jiaming Song, and Stefano Ermon. Training deep energy-based models with f-divergence minimization. In International Conference on Machine Learning, pages 1095710967. PMLR, 2020. 3 [74] Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, and Jan Kautz. Physdiff: Physics-guided human motion diffusion model. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1601016021, 2023. 1 [75] Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic, Or Litany, Sanja Fidler, and Karsten Kreis. LION: Latent In AdPoint Diffusion Models for 3D Shape Generation. vances in Neural Information Processing Systems (NeurIPS), 2022. 1 [76] Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang, and Ziwei Liu. Motiondiffuse: Text11 One-step Diffusion Models with -Divergence Distribution Matching"
        },
        {
            "title": "Supplementary Material",
            "content": "A. Proofs In this section, we provide proofs for Theorem 1 and Proposition 1 in the main text. We will start with Lemma 1 before proving Theorem 1. Lemma 1. Assuming that sampling from qt(x) can be parameterized to = Gθ(z) + σ(t)ϵ for p(z), ϵ (0, I) and Gθ, are differentiable mappings. In addition, is constant with respect to θ. Then (cid:82) θqt(x)g(x)dx = (cid:82) (cid:82) p(ϵ)p(z)xg(x)θGθ(z)dϵdz. Proof. As qt and are both continuous functions, we can interchange integration and differentiation: (cid:90) θqt(x)g(x)dx = θ (cid:90) qt(x)g(x)dx (cid:90) (cid:90) = θ p(ϵ)p(z)g(Gθ(z) + σ(t)ϵ)dϵdz (cid:90) (cid:90) (cid:90) (cid:90) (cid:90) (cid:90) = = = p(ϵ)p(z)θg(Gθ(z) + σ(t)ϵ)dϵdz (5) p(ϵ)p(z)xg(Gθ(z) + σ(t)ϵ)θGθ(z)dϵdz p(ϵ)p(z)xg(x)θGθ(z)dϵdz where = Gθ(z) + σ(t)ϵ. We can interchange integration and differentiation again in Eq. (5) as is differentiable function. Theorem 1. Let be the teachers generative distribution, and let be distribution induced by transforming prior distribution p(z) through the differentiable mapping Gθ. Assuming is twice continuously differentiable, then the gradient of -divergence between the two intermediate distribution pt and qt w.r.t θ is: θDf (ptqt) = Ez,ϵ (cid:18) pt(x) qt(x) (cid:19) (cid:18) pt(x) qt(x) (cid:19)2 log pt(x) (cid:124) (cid:123)(cid:122) (cid:125) teacher score θGθ(z) log qt(x) (cid:125) (cid:123)(cid:122) fake score (cid:124) (6) where p(z), ϵ (0, I) and = Gθ(z) + σ(t)ϵ Proof. Note that both the intermediate student distribution qt and the sample have dependency on the generator parameter θ. In the proof, we simplify the expression (cid:82) (θqt(x))g(x)dx as (cid:82) θqt(x)g(x)dx for clarity. The total derivative of -divergence between teachers and students intermediate distribution is as follows: θDf (pt(x)qt(x)) = θ (cid:90) qt(x)f ( pt(x) qt(x) )dx = = = (cid:90) (cid:90) (cid:90) (cid:124) θqt(x)f ( θqt(x)f ( θqt(x)f ( (cid:123)(cid:122) pt(x) qt(x) pt(x) qt(x) pt(x) qt(x) (cid:90) (cid:90) (cid:90) (cid:124) )dx + )dx )dx (cid:125) qt(x)θf ( pt(x) qt(x) )dx θqt(x)f ( pt(x) qt(x) ) pt(x) q2 (x) pt(x) qt(x) (cid:123)(cid:122) II ) pt(x) qt(x) qt(x)f ( θqt(x)dx dx (cid:125) (7) Note that by notation θqt(x), we mean that only the first inisde each integral has gradient w.r.t θ. (I) / (II) is the term associated with the partial derivative of with respect to / q, respectively. Above we see that both partial derivatives (I) and (II) are in the form (cid:82) θqt(x)g(x)dx where is differentiable function that is constant with respect to θ. Using the identity in Lemma 1 again, we can simplify (I) and (II) to: (cid:90) (cid:90) (cid:90) (cid:90) = II = p(ϵ)p(z)f ( p(ϵ)p(z)f ( pt(x) qt(x) pt(x) qt(x) )x pt(x) qt(x) θGθ(z)dϵdz ) pt(x) qt(x) pt(x) qt(x) θGθ(z)dϵdz + (cid:90) (cid:90) p(ϵ)p(z)f ( pt(x) qt(x) )x pt(x) qt(x) θGθ(z)dϵdz Putting (I) and (II) in Eq. (7), we have: θDf (pt(x)qt(x)) = = (cid:90) (cid:90) (cid:90) (cid:90) p(ϵ)p(z)f ( p(ϵ)p(z)f θGθ(z)dϵdz pt(x) qt(x) (cid:19)2 pt(x) qt(x) (cid:19) (cid:18) pt(x) qt(x) ) pt(x) qt(x) (cid:18) pt(x) qt(x) (cid:19) (cid:18) pt(x) qt(x) =Ez,ϵ (cid:18) pt(x) qt(x) (cid:19)2 log pt(x) (cid:125) (cid:123)(cid:122) teacher score (cid:124) θGθ(z) log qt(x) (cid:125) (cid:123)(cid:122) fake score (cid:124) [x log pt(x) log qt(x)] θGθ(z)dϵdz where the last identity is from the log derivative trick, i.e., pt(x) qt(x) = pt(x) qt(x) [x log pt(x) log qt(x)]. the expectation Ez,ϵ is continuous and non-negative on (0, +), Proposition 1. For any function that [h (rt(x)) (x log pt(x) log qt(x)) θGθ(z)] corresponds to the gradient of an -divergence. Proof. To constitute valid -divergence, the requirement for is that is convex function on (0, +) satisfying (1) = 0. For any function that is continuous and non-negative function on (0, +), the function g(r) = h(r)/r2 is also continuous and non-negative function on (0, +). By the fundamental theorem of calculus, we know that there exists continuous function m(r) whose second derivative equals to g(r), i.e., m(r) = g(r). Let (r) = m(r) m(1), it is straightforward to see that (1) = 0 and (r) = h(r)/r2. In addition, is convex function on (0, +) as its second derivative is non-negative in this domain. Let = Gθ(z) + σ(t)ϵ, we can re-express the expectation as follows: Ez,ϵ [h (rt(x)) (x log pt(x) log qt(x)) θGθ(z)] = Ez,ϵ (cid:2)f (rt(x)) r2 = θDf (pt(x)qt(x)) (x) (x log pt(x) log qt(x)) θGθ(z)] where the last equation is by Theorem 1. B. Training details In this section, we provide training details for -distill on CIFAR-10, ImageNet-64 and COYO-700M (w/ SD v1.5 model). Table 5 shows the values of common training hyper-parameters on different datasets. For most hyper-parameters, we directly borrow the value from [71], which is special case in the -distill framework. Inspired by the three-stage training in [71], we also divide the ImageNet-64 training process into two stages with different learning rates. In the first stage, we train the model with learning rate of 2e-6 for 200k iterations, then fine-tune it with learning rate of 5e-7 for 180k iterations. We apply TTUR [71] for all the models. We further provide an algorithm box in Alg 1 for clarity. [71] uses the online fake score network as the feature extractor for the GAN discriminator. This complicates the training process, as there is an additional hyper-parameter balancing the denoising score-matching loss and GAN loss for updating the fake score network. To simplify the use of GAN in our framework, we use the fixed teacher network as the feature extractor, similar to LADD [51]. Unlike [71], including the fake score network as part of the learnable parameter in the GAN discriminator, the learnable parameter in the new setup is small classification head whose input is the feature from the teacher network. We empirically observe that the modification leads to better performance on CIFAR-10, as shown in Fig. 7a. We also include an ablation study (green line in Fig. 7b), which uses the fake score as feature extractor but does not update it in the GAN loss. The model behaves poorly in this case, as the fake score is constantly getting updated with denoising score-matching loss, validating the benefits of using the fixed teacher score as feature extractor. For evaluation, we report the FID / Recall score on 50K samples on CIFAR-10 and ImageNet-64, and 30K samples on zero-shot MS-COCO dataset. We report the CLIP score on 30K samples using MS-COCO datasets. 13 CIFAR-10 ImageNet-64 COYO-700M"
        },
        {
            "title": "Batch size\nFake score update frequency\nGAN loss weight\nGAN discriminator input resolution\nTotal iteration\nTeacher\nCFG weight",
            "content": "2048 5 1e-3 (32, 16, 8) 60K EDM [17] 1 512 5 3e-3 (8) 380K EDM [17] 1 1024 10 1e-3 (8) 60K Stable Diffusion v1.5 [43] 1.75 Adam optimizer Learning rate Learning rate for fine-tuning Weight decay γ in R1 regularization 1e-4 - 1e-2 1 2e-6 5e-7 1e-2 1e-5 - 1e-2 1 Table 5. Training configuration for -distill on different datasets. (a) (b) Figure 7. FID score versus training iteration on CIFAR-10. Fake score feature: fake score as the extractor, updating both the fake score and classification head in the GAN discriminator loss. Teacher score feature: teacher score as the extractor, updating classification head in the GAN discriminator loss. Teacher score feature, updating cls head: fake score as the extractor, updating classification head in the GAN discriminator loss. (a) is the zoomed-in visualization of (b). C. Properties of -divergence C.1. Mode-seeking behavior in f-divergence C.1.1. Classification by mode-seeking Mode-seeking, as described in Section 10.1.2 in [2], refers to the tendency of fitted generative models to capture only subset of the dominant modes in the data distribution. This occurs during the minimization of the -divergence minq Df (pq) between the true data distribution (p) and the learned generative distribution (q). An -divergence is considered mode-seeking if its minimization leads to this mode-seeking behavior in the corresponding generative model. The mode-seeking behavior in generative models translates into lack of diversity in practice. Most of the previous classifications of mode-seeking divergences are mainly based on empirical observations. For example, reverse-KL is widely considered mode-seeking, and forward-KL aims for the opposite (i.e., mode-coverage) [38]. Here, we applied the criteria proposed in [24] (see Definition 4.1 in the paper) to roughly classify the -divergence based on mode-seeking. Intuitively, smaller limit indicates higher tolerance of the corresponding -divergence for large density ratios (r = p/q). This allows the generative distribution to assign less probability mass to regions where the true distribution has low density without incurring significant penalty. Consequently, this behavior can lead to mode-seeking, where the model focuses on capturing only the dominant modes of the data distribution. Hence, we use the rate of the limit to classify divergence in the mode-seeking column in Table 1. C.1.2. Relation to the weighting function Another paper [52] classifies the mode-seeking divergence based on the increasing rate of the limits limr (r) and limr0 (r), through concept of tail weight. The tail weight associated with limr (r) (right tail weight) / 14 Algorithm 1 -distill Training 1: Input: Teacher diffusion model sϕ, fake score sψ, one-step student Gθ, discriminator Dλ, total iteration , batch size B, fake score update frequency τ , weighting function h, GAN loss coefficient wGAN, minimun/maximum value for ratio rmin/rmax. 2: for iteration in 0 . . . do 3: 4: 5: 6: 7: 8: 9: x1, ..., xB pdata, ϵ1, ..., ϵB (0, I), t1, ..., tB U{1, . . . , } Generate the data by student: yi = Gθ(ϵi) if iteration%τ = 0 then Compute and clip the density ratio: ri = clip(exp(Dλ(yi)), rmin, rmax) Normalize the weighting coefficient: ri = ri/ (cid:80) Compute the weighting coefficient: hi = h(ri) Normalize the weighting coefficient: hi = hi/ 1 Compute the empirical -distill loss Lf -distill(θ) based on Eq. (4) with (yi, ti, hi)B Compute the empirical GAN loss LGAN(θ) for generator with (yi, ti)B Update the student parameter θ by Lf -distill(θ) + wGAN LGAN(θ). hi ri (cid:80) i=1 Update student First-stage normalization Second-stage normalization i=1 and fake score sψ Update fake score and discriminator Update the fake score with denoising score-matching loss using (yi, ti)B Update the discriminator with empirical GAN loss LGAN(λ) for discriminator with (xi, yi, ti)B i=1. i=1 else 10: 11: 12: 13: 14: 15: 16: 17: end for end if Figure 8. Illustration of how the weighting function (red dotted line) in less mode-seeking divergence (forward-KL, = p/q) helps to learn the true data distribution p, compared to more mode-seeking divergence (reverse-KL, 1). We illustrate how using less mode-seeking divergence can better capture different modes, from skewed initial generative distribution q, with the help of the weighting function. limr0 (r) (left tail weight) describes how strongly the mode-seeking / mode-coverage behavior is penalized. larger rate of limit can be translated into higher penalty on mode-seeking. Table 6 demonstrates tail weights for different divergences. In general, less mode-seeking divergence will have larger right tail weight (rate of limr (r)) and smaller left tail weight (rate of limr0 (r)). As result, when using these canonical -divergences, the weighting function h(r) would be an increasing function if the divergence is less mode-seeking since h(r) = (r)r2. For example, in JS and forward-KL is an increasing function, while in reverse-KL, stays constant. An increasing tends to downweight regions with lower density in the true data distribution p. This corresponds to regions where the teacher score is less reliable. Fig. 8 illustrates the idea. reverse-KL softened RKL JS Rate of limr (r) Rate of limr0 (r) O(r2) O(r2) O(r3) O(r2) O(r2) O(r1) squared Hellinger O(r 3 2 ) O(r 3 2 ) forward-KL Jefferys O(r1) O(r1) O(r1) O(r2) Table 6. Right / left weight for different -divergences. We shift the tail weight in [52] by constant for clarity. 15 C.2. f-divergence and Fisher divergence line of work focuses on achieving distributional matching by minimizing the Fisher divergence or its variants [34, 82]. While -divergence-based distillation methods match the probability density functions pt (teacher distribution) and qt (student distribution), Fisher divergence-based distillation aims to match the distributions by minimizing the distance between their score functions. This equates to matching the gradients of the log probability density functions, log pt(x) and log qt(x): (f -divergence): min qt (cid:90) qt(x)f (cid:19) dx (cid:18) pt(x) qt(x) (cid:90) qt (General Fisher divergence): min qt(x)d(x log pt(x), log qt(x))dx (8) where is scalar-valued proper distance function satisfying d(x) 0 and d(x) = 0 if and only if = 0. When is squared ℓ2 distance, Eq. (8) reduces to Fisher divergence. In practice, directly minimizing the Fisher divergence in Equation 8 is challenging. Existing works often rely on certain assumptions and approximations to make this optimization tractable. For example, [34] imposes the stop gradient operation on the sampling distribution qt (first term in the integral in Eq. (8)). In addition, they typically use Monte-Carlo sampler [82], derived from Tweedies Formula, to estimate an intractable term in the gradient. D. Additional Results D.1. CIFAR-10 result with more baselines Due to space limits, we only include few results in the table for CIFAR-10  (Table 2)  in the main text. We provide more comprehensive comparison in Table 7. Please note that we mainly use this dataset for analyzing the difference of variants under the -distill family. Unlike previous works using pre-trained feature extractor [19, 79], we use simple classification head as discriminator on top of the teachers features, and do not tune hyper-parameter on this dataset. Multi-step diffusion models FID Recall NFE DDPM [12] LSGM [61] EDM [17] (teacher) PFGM++ [68] GANs BigGAN [3] StyleSAN-XL [48] Diffusion distillation Adversarial distillation SiD (α = 1) [82] SiD (α = 1.2) [82] CTM [19] GDD [79] GDD-I [79] -distill reverse-KL (, DMD2 [71]) softened RKL () squared Hellinger () JS () Jeffreys () forward-KL () 3.17 2.10 1.79 1.74 14.73 1. 2.60 1.93 1.71 1.73 1.66 1.44 2.13 2.21 1.99 2.00 2.05 1.92 1000 138 35 35 1 1 1 1 1 1 1 1 1 1 1 1 1 0.60 0.60 0.63 0.62 0.62 0.62 Table 7. FID and Recall scores on CIFAR-10. // stand for high/medium/low mode-seeking tendency for -divergence. D.2. Diversity evaluation based on in-batch similarity It is important to understand the diversity of generated samples given text prompt. We did not use Recall because it is unsuitable for measuring diversity in text-to-image generation, as it requires generating numerous samples per prompt. Furthermore, we found the Diversity score in [71] unreliable: higher CFG values in the teacher model, known to reduce diversity, will result in better Diversity scores. As result, we use the in-batch similarity [8] to measure the diversity. In-batch similarity [8] calculates the average pairwise cosine similarity of features within an image batch, with DINO [5] as the feature extractor. 16 SDv1.5 (NFE=50, CFG=3, ODE) SDv1.5 (NFE=50, CFG=8, ODE) 0.55 / 0.70 0.62 / 0.72 In-batch-sim CFG=1.75 reverse-KL (DMD2 [71]) JS (ours) CFG=5 reverse-KL (DMD2 [71]) JS (ours) 0.50 / 0.42 0.49 / 0.41 0.67 / 0.60 0.65 / 0. Table 8. In-batch similarity on MS COCO 2014 / Parti-Prompt Anime Photo Concept Art Painting SDv1.5 (CFG=3) SDv1.5 (CFG=8) InstaFlow [27] SwiftBrush [36] SwiftBrush v2 [6] CFG=1.75 reverse-KL (DMD2 [71]) JS (ours) CFG=5 reverse-KL (DMD2 [71]) JS (ours) 26.30 27.53 25.98 26.91 27.25 27.56 28. 26.32 27.21 27.62 26.20 26.32 27.33 27.71 26.52 26.85 27.86 27.98 25.86 26. 25.79 26.32 26.86 25.82 25.79 26.25 26.37 26.08 26.83 25.93 26.37 26.77 25.68 25.81 26.10 26.34 Table 9. HPSv2 score Table 8 reports the in-batch similarity score to measure the diversity of text-to-image tasks. We did not use Recall because it requires generating numerous samples per prompt. Our main finding is that JS outperforms reverse-KL in in-batch similarity across datasets and CFGs (two numbers are MS-COCO/Parti-Prompt subset [71] evaluations). JS shows larger diversity gain on higher CFG, suggesting it preserves more modes. D.3. Image quality evaluation based on HPSv2 We evaluate the HPSv2 score (higher is better) following the protocol in [6] to assess the image quality. In Table 9, we observe that JS consistently outperforms reverse-KL on almost all prompt categories. When CFG=5, JS performs competitively to 50-step teacher SDv.15 (CFG=8) and SwiftBrush v2. D.4. Training stability In section 4 and section C, we show that more mode-coverage divergence tends to have more rapidly increasing h, resulting in higher-variance gradient. Although we propose double normalization scheme in section 4, we show that it is insufficient on larger-scale COYO-700M when using the SD v.1.5 model. As shown in Fig. 9, the loss of forward-KL has significantly larger fluctuation than the one in JS. In addition, the forward-KL achieves much worse FID (8.70) compared to JS (7.45). We hypothesize that the inaccurate estimation of the density ratio by the discriminator on this dataset contributes to this phenomenon. We will leave the stabilization techniques for further work. D.5. Higher classifier-free guidance In this section, we experiment with applying higher classifier-free guidance (CFG) to -distill , by replacing the teacher score in the gradient (Eq. (3)) with the corresponding CFG version. In Fig. 10, Fig. 11 and Fig. 12, we compare the generated samples by one-step JS with CFG=5, and by SD v1.5 (NFE=50) with CFG=5 / CFG=8. The first three prompts in these figures are randomly chosen from COYO-700M, and the next three prompts are from [72]. We observe that, in general, the one-step student matches, or even outperforms, the teacher in most cases. In addition, JS produces more diverse samples compared to reverse-KL (RKL). We observe that both JS and revesre-KL (DMD2 [71]) diverges when using CFG=8. We first hypothesize that this is because the generated samples and the real data (COYO-700M) have larger domain gap, exacerbating the training instability in GAN. DMD [71, 72] uses LAION-Aesthetic 5.5+ as the training set, which is considered more saturated and has smaller domain gap with data generated by high CFG. However, we find that removing GAN loss does not resolve this issue.The training instability with high CFG might be linked to the weak teacher model (SD1.5), as our preliminary experiments with clipped teacher score prevented divergence. 17 Figure 9. Training dynamics of JS and forward-KL on COYO-700M. w/o GAN loss w/ GAN loss CIFAR-10 reverse-KL (DMD2) JS squared Hellinger forward-KL MS-COCO-30k reverse-KL (DMD2) JS 4.07 3.98 3.81 3.76 9.54 9. 2.13 2.00 1.99 1.92 8.17 7.42 Table 10. FID score for ablation study on GAN loss D.6. Ablation study on GAN loss The final training framework in the experimental section contains two losses: the -distill objective (Eq. (4)) and GAN loss. In this section, we conduct ablation studies on the GAN loss on CIFAR-10 and MS-COCO 2014 in -distill.As shown in Table 10, the relative ranking of FID scores by different f-divergence remains the same with or without GAN loss across datasets. E. Extended Samples We provide extended samples on CIFAR-10 (Fig. 13 (multi-step teacher), Fig. 14 (KL, -distill)); ImageNet-64 (Fig. 15 (multistep teacher), Fig. 16 (JS, -distill)); COYO-700M (SD v1.5) (Fig. 17 (multi-step teacher), Fig. 18 (JS, CFG=1.75, -distill), Fig. 19 (JS, CFG=5, -distill). The teacher and student models use the same random seeds and class labels/text prompts. We further provide the randomly sampled COYO-700M prompts for the generated samples in the main text and supplementary material below. 8 prompts for generated images in Fig. 6: man putting pan inside of an oven with his bare hand. man flying kite on the beach. hotel room filled with beige and blue furniture. large stone bench sitting next to rose bushes. Clock tower over crowd of people standing on bridge. blue and white passenger train coming to stop The clock shown above has someones name on it. large predatory bird sits on tree branch in an exhibit. 24 prompts for generated images in Fig. 17 and Fig. 18: large green gate sitting in front of red brick building. room in private house for loosening up and institutionalizing. train traveling down tracks next to brick building. couple of birds sitting on grass covered field. cat is laying on the other side of cactus. 18 Figure 10. Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M. 19 Figure 11. Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M. 20 black horse standing in desert field surrounded by mountain. Many difference birds in cages on display in an outdoor market area. group of people watching man skateboard. man riding on top of surfboard in the ocean. table with some plates of food on it An orange billboard truck driving down street in front of crowd of people. vase filled with lots of different colored flowers. large living room is seen in this image. black and white cat that is standing on all fours and has an elephant hat on its head. Silhouette of herd of elephants walking across the field Separate men sitting on park benches playing on phone and reading. wooden table topped with plates and bows filled with food cat curled up in sunny spot on table sleeping. woman going down the stairs with backpack on and suitcase in her hand. man riding red surfboard on wave in the ocean. couple of small dogs sit in basket on bike bike parked in front of parking meter. Two men riding mopeds, one with woman and boy riding along. BOY IS ON SKATE BOARD IN THE COURT 21 Figure 12. Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M. 22 Figure 13. 35-step generated CIFAR-10 samples, by EDM [17] (teacher). FID score: 1. Figure 14. One-step generated CIFAR-10 samples, by KL in -distill. FID score: 1.92 23 Figure 15. 79-step generated ImageNet-64 samples, by EDM [17] (teacher). FID score: 2.35 24 Figure 16. One-step generated ImageNet-64 samples, by JS in -distill. FID score: 1.16 Figure 17. 50-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by SD v1.5 model [43] (teacher). CFG=3. FID score: 8.59 26 Figure 18. One-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by JS in -distill, with CFG=1.75. FID score: 7.42 27 Figure 19. One-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by JS in -distill, with CFG=5."
        }
    ],
    "affiliations": [
        "NVIDIA"
    ]
}