{
    "paper_title": "LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation",
    "authors": [
        "Jude Khouja",
        "Karolina Korgul",
        "Simi Hellsten",
        "Lingyi Yang",
        "Vlad Neacs",
        "Harry Mayne",
        "Ryan Kearns",
        "Andrew Bean",
        "Adam Mahdi"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Assessing the reasoning capabilities of large language models (LLMs) is susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, a challenging benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerousquestion variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including Claud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to over estimating the reasoning capabilities of frontier models."
        },
        {
            "title": "Start",
            "content": "LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Jude Khouja * 1 Karolina Korgul * 1 Simi Hellsten * 2 3 Lingyi Yang 1 Vlad Neacs, 4 5 6 Harry Mayne 1 Ryan Kearns 1 Andrew Bean 1 Adam Mahdi 1 Abstract Assessing the reasoning capabilities of Large Language Models (LLMs) is susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, challenging benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including Claud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to overestimating the reasoning capabilities of frontier models. 1 5 2 0 2 ] . [ 2 2 7 9 2 0 . 3 0 5 2 : r 1. Introduction Recent advancements in Large Language Models (LLMs) have resulted in impressive performance on reasoning bench- *Equal contribution 1University of Oxford, Oxford, United Kingdom 2United Kingdom Linguistics Olympiad 3University of Glasgow, Glasgow, United Kingdom 4National University of Science and Technology POLITEHNICA Bucharest, Romania 5Hong Kong Linguistics Olympiad 6Asia-Pacific Linguistics Olympiad. Correspondence to: Jude Khouja <jude.khouja@oii.ox.ac.uk>. Preprint. 1Code and data: https://huggingface.co/spaces/ jkhouja/lingoly-too 1 marks (Kojima et al., 2022; OpenAI et al., 2024), achieving strong results on mathematical word problems (Cobbe et al., 2021), competition mathematics (Hendrycks et al., 2021) and various symbolic and algebraic reasoning tasks (Wei et al., 2022). However, the claim that LLMs can truly reason draws scepticism (Kambhampati, 2024; Mirzadeh et al., 2024; Jiang et al., 2024), in part because the scientific validity of benchmark findings is controversial. Cognitive agents can be said to reason when they apply abstract rules to prior information to obtain novel judgements or decisions (Koralus, 2022; Huang & Chang, 2023; Lampinen et al., 2024). Such rules may take the form of logical arguments or mathematical equivalences as well as more informal commonsense reasoning. Specific benchmark datasets can only partially represent general-purpose capabilities and benchmark evaluations in general struggle with construct validity, that is, measuring what they intend to measure (Raji et al., 2021). For benchmark to measure reasoning, reasoning must be both necessary and sufficient condition for high performance. However, it is difficult to establish the necessity of reasoning for task when models may have prior exposure to similar or identical tasks in pre-training and can rely on form of memorisation in solving the task. Several popular benchmark datasets are fully or partially exposed in pre-training, impeding their effectiveness in performance estimation (Li & Flanigan, 2024; Zhou et al., 2023). Taken together, these challenges raise questions around the mechanisms behind LLMs improved performance in reasoning tasks and the genuine abilities of frontier models. number of evaluation techniques can reduce the potential effect of memorisation. Prior works have used out-ofdistribution tasks, such as reasoning about low-resource languages to better approximate the reasoning abilities of LLMs (McCoy et al., 2023; Tanzer et al., 2024; Bean et al., 2024; Sanchez et al., 2024). Others have used synthetic templates to assess LLMs robustness to minor perturbations of popular benchmark problems (Jiang et al., 2024; Mirzadeh et al., 2024), or reported no context baselines (Bean et al., 2024) to identify instances when LLMs draw on information stored in their parameters and not presented in-context. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 1: LINGOLY-TOO benchmark overview. Framework for developing LINGOLY-TOO, starting from an original problem, annotating it and developing its orthographic template to generate several obfuscations. We combine these two approaches, beginning from linguistic reasoning tasks and applying orthographic2 perturbations to ensure that the problems are out-of-distribution. Linguistic reasoning is subset of general reasoning and has been previously assessed in LLMs via Linguistics Olympiad problems (Bean et al., 2024; Sanchez et al., 2024; ahin et al., 2020). Typical problems require combination of deductive, abductive and analogical reasoning for the purpose of understanding some aspect of the grammar of an unknown language. This domain offers parallel to mathematical reasoning, requiring similar generalised reasoning capabilities in less saturated context. In this paper, we introduce framework for the dynamic generation of obfuscated evaluation benchmarks for linguistic reasoning. By creating problems outside the distribution of LLM training sets, we aim to mitigate the effects of data exposure in assessing reasoning abilities of LLMs and enable scalable and controllable experiments. We apply this framework to extend LINGOLY, linguistic reasoning benchmark utilising problems from the UK Linguistics Olympiad (UKLO) in over 90 low-resource languages (Bean et al., 2024). LINGOLY-TOO is challenging reasoning benchmark that sheds light on current limits and gaps in the capabilities of state-of-the-art models in solving linguistics problems. Our main contributions are: (i) an orthography-based templatisation method for generating unseen linguistics prob2For glossary of terms, see Appendix A. lems based on natural human languages; (ii) LINGOLYTOO, benchmark for evaluating the linguistic reasoning abilities of LLMs; and (iii) an empirical evaluation of reasoning consistency in frontier models on unseen data. 2. The LINGOLY-TOO Benchmark LINGOLY-TOO consists of 27, 325 linguistic reasoning questions, which we dynamically generated through an obfuscation process that we explain in the following sections. To minimise the risk of contamination in pre-training, we used orthographic rulesets to obfuscate linguistics problems. These problems are drawn from UKLO past problems, which were standardised in the LINGOLY benchmark (Bean et al., 2024). We reused and adapted 82 of these standardised problem sheets. typical single problem in Linguistics Olympiad provides examples of words or phrases in language of focus (termed Problemese) alongside their translations into the language in which the problem is written (termed Solverese) (Bozhanov & Derzhanski, 2013). Each problem includes multiple questions and answers. Through logical reasoning, the solver is expected to deduce the underlying linguistic rules and structures and use them to determine single best answer to each question. Problem authors, who are volunteer linguists, research the Problemese languages before including them. We obtained permission from individual authors to include their work in this benchmark and discuss permissions from language communities in Section 6. 2 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Although these problems heavily feature low-resource languages, previous work has shown that examples of these languages have appeared in pre-training datasets, potentially allowing models to predict the answers without reasoning ability (Bean et al., 2024; Tanzer et al., 2024). To address this, we construct orthographic variations that obfuscate the original languages without changing the reasoning steps of the problems. This approach allows us to ensure that models have not memorised the correct responses, making the benchmark more robust measure of reasoning ability. Figure 1 provides an overview of our framework. In the rest of this section, we explain orthographic templatisation and describe the annotation details and process of generating LINGOLY-TOO benchmark. 2.1. Orthographic Templatisation In Linguistics Olympiads, obfuscation refers to any process by which problem is modified to prevent cheatingin most cases, by preventing internet searches (Asia Pacific Linguistics Olympiad, 2024; United Kingdom Linguistics Olympiad, 2021). It typically consists of removing the language name(s) and other metadata that could identify or point towards it (e.g. language family, number of speakers, area where it is spoken). For each problem, we created ruleset to generate acceptable permutations of the Problemese graphemes present in the data. To ensure that the problems solvability is not affected, acceptable permutations preserve phonetic and phonological distinctions relevant to solving the problem, as well as any loanwords or transparent English cognates that might aid in solving it. Names of people or deities are also preserved in the obfuscation process. 2.2. Annotation To prepare the text for obfuscation, we manually annotated 82 problems with special tags for later processing. We removed metadata such as language names, families and geographic regions that have no impact on solvability of problems. Annotations were performed manually and subsequently validated by two members of the team with expertise in Linguistics Olympiads. We also incorporated automated checks to validate the outputs. detailed description of the annotation process, including examples, is provided in Appendix B. 2.3. Data Generation Starting with the specific orthographic template for each problem, we randomly sampled permutations of the Problemese graphemes according to the rules of the template. We prevented identity mappings of the graphemes unless explicitly specified. We then obfuscated the problem by substituting the graphemes according to these mappings, and removed any special tokens used for annotations. We conducted second round of both human-expert manual inspection and automatic validation tests to ensure the correctness of the final data. Most problems permit far more permutations than is necessary for robust evaluations. Due to resource limits, we generated 6 obfuscations per problem to evaluate all models resulting in 27, 325 questions. On subsequent experiments involving subset of the models, we generated larger instance of the benchmark using 30 obfuscations per problem. 2.4. Evaluation Metrics We adopt exact match, binary metric calculated for each question and answer in problem. exact match takes the value 1 if the response text matches the correct answer text and 0 otherwise. Our goal is to capture all failure cases, including those where the permutation of the correct answers was minimal, following the approach of Bean et al. (2024) and Sanchez et al. (2024). The nature of the tasks is such that the correct answer often involves making small changes to words already present in the problem, so scores that offer partial credit may reward repetition of in-context words rather than actual reasoning. We define Mog as the average exact match score across all questions in single unobfuscated (original) problem and Mobf as the average exact match score for all questions in single obfuscated problem. We also define obf = Mobf Mog as the difference in exact match due to obfuscation. We note that obf is positive when the model improves on an obfuscated problem and negative when the models performance decreases compared to the original problem. To evaluate single model on the entire benchmark, we report the average score Mog for the 82 original (unobfuscated) problems and Mobf for all obfuscated versions of the 82 problems. Our pipeline breaks down problems into individual questions and generates prompts for each question in zero-shot setting. Each prompt consists of preamble (detailing background information about the language), context (providing examples from the language), all questions in problem sheet and finally the specific question to be answered. The exact template used is provided in Appendix D. Similar to Bean et al. (2024), we found that chain of thought prompting (Kojima et al., 2022; Wei et al., 2022) did not improve the performance (Kojima et al., 2022; Wei et al., 2022) and adopted zero-shot setting for our experiment (see Appendix for details ). To focus on reasoning performance rather than instructionfollowing, we applied post-processing steps to recapture improperly formatted responses. After post-processing, about 3 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 2: LINGOLY-TOO benchmark main results. (a) Mean exact match scores by model on LINGOLY-TOO Mog is on nonobfuscated problems and Mobf is on obfuscated problems. (b) obf for the 6 obfuscations of 57 problems (for brevity), showing performance changes by model. Red indicates performance drop for that particular obfuscation, while blue indicates an improvement. Results for all problems are in Appendix H. 0.2% of the responses remained unreadable and were scored as incorrect. Blank answers, which constituted 0.8% of responses from proprietary models and 5.4% from open models, were also considered incorrect (see Appendix G). Models For our main experiment on the smaller benchmark, we evaluated eleven LLMs: Claude 3.7 Sonnet, Claude 3.5 Sonnet, Gemini 1.5 Pro, GPT-4.5, GPT-4o, o1preview, o3-mini, DeepSeek R1, Phi-4, Llama 3.3 70B, and Aya 23 35B. For experiments on the larger benchmark, we evaluated eight models: Claude 3.5 Sonnet, Gemini 1.5 Pro, GPT-4o, Phi-4, Llama 3.3 70B, and Aya 23 35B, Llama 3.2 3B, Llama 3.2 1B. Further details about the models used in our experiments can be found inAppendix E. 3. Results 3.1. Model Performance Figure 2 shows mean exact match scores for eight models on both the original and obfuscated problems. Claude 3.7 Sonnet, which achieved the highest score on the obfuscated problems, scored mean Mobf = 0.43, followed by o1-preview (0.32) and o3-mini (0.31). The best open source model is DeepSeek R1 which scored 0.27. All remaining models scored below 0.30 indicating that the benchmark is challenging even for frontier models. 4 Compared to the problems in their original orthographies, all models drop in average performance on the obfuscated versions. Figure 2 shows obf across all obfuscations of 57 problems of the 82 problems (full scores can be found in Appendix H). Problems about higher resource languages generally show the largest negative average obf across all models such as Problem 76 (Finnish): 0.36, Problem 178 (Italian): 0.32, Problem 144 (Dutch): 0.21. However, within each individual problem, not all obfuscations had the same impact. In cases such as Problem 24 (Tadaksahak) and Problem 67 (Navajo), different obfuscations had varying effects, and in some cases, even led to improved model performance. The distribution of scores for sample of individual problems is found in Appendix I. We also find that the relative difficulty level of problems is largely maintained by the obfuscation process. UKLO categorises all problems into five difficulty levels. When we consider the strongest performing models, the easier problems (Breakthrough and Foundation) are the highest scoring problems both before and after obfuscation. Similarly, the most challenging problems (Round 2) remain the hardest. This is illustrated for OpenAI o1-preview in Figure 3. However, this trend does not hold for the weaker models, potentially since all scores are nearer zero. Additional results are displayed in Appendix I. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Model Answer Mog Mobf GPT-4o Digit Other Single Char Y/N Llama-3.3-70B Digit Other Single Char Y/N 0.16 0.07 0.03 0.62 0.19 0.02 0.05 0.19 0.08 0.01 0.03 0.31 0.11 0.01 0.04 0.49 Table 1: Model performance in the no context setting. The table shows mean scores in the no context setting (with insufficient information to answer questions). Scores are categorised by answer type. Other includes all remaining questions which do not fit the other response types. Experiment was conducted using our larger benchmark (30 obfuscations). to the original orthographies allowing the models in many cases to complete the problems without reasoning. We also evaluated LLMs ability to score on our benchmark by guessing the answer with incomplete information present in context. By adopting the no context setting from Bean et al. (2024), we conduct small experiment using our larger benchmark (30 obfuscations) with two models (Llama 3.3 70B and GPT-4o) due to resource constraints. We removed the context from the prompt, rendering the problems unsolvable by reasoning alone. Table 1 shows summary of the results in the no context setting for both tested models. When information is insufficient to solve the problem, mean Mog and Mobf for both models drop (Mobf in particular is low). For instance, GPT4o achieves Mog= 0.08 vs. Mobf = 0.02. When excluding cases with higher chance of guessing correctly (answers which are Yes/No, single character or numerical), Mobf drops to 0.01 for both models. This confirms that obfuscation effectively counteracts the effects of memorisation. In addition, we investigated the effect of language resourcedness on model performance by approximating the former with number of speakers of the language (in logarithmic scale) of the problem. We apply linear regression with resourcedness as predictor of the average score for the models grouped into open-source and closed-source. We repeat the process for Mog, Mobf and obf . While Mog improves for languages with more speakers (β = 0.056, < 0.01) for closed models and (β = 0.021, < 0.01) for open models, Mobf shows no clear relationship for the obfuscated problems (β = 0.003, = 0.26) for open models and (β = 0.002, = 0.726) for closed models. The performance drop obf also widens for problems with more speakers (β < 0, < 0.01 for both open-source and closedsource models). These results provide additional evidence Figure 3: Performance by problem difficulty level for o1preview. The relative difficulty level of problems is largely preserved by the obfuscation process. Categories as defined by UKLO. Figure 4: The effect of obfuscation is larger for highresource languages. Scores for each problem are averaged across all eight models in Figure 2. Active speaker numbers serves as proxy for language resourcedness. Speaker numbers are transformed by log(x + 1) to emphasise differences between low-resource languages. 3.2. Benchmark Validation Contamination To assess the impact of memorisation in the original problems, we generated bootstrapped distribution of scores across all versions of each problem. We sampled 500 sets, each containing one randomly selected version of each problem out of seven (including the original version). Figure 5 shows the empirical distribution of scores for the models on the bootstrapped sets. The performance of models on the original set of problems, mean Mog, consistently appears at the extreme right of the distribution, indicating that models are disproportionately better at solving the problems in their original orthography. Since we have constructed the obfuscations to preserve the logic of the problems, we attribute this difference to prior exposure 5 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 5: Score distribution across bootstrapped samples. Distribution of scores across 500 bootstrapped samples of our data by model. Each consists of 82 problems. Open source models are shown in orange while proprietary models are in blue. of the effectiveness of obfuscation in substantially reducing the effects of exposure to high-resource languages. Figure 4 shows scatter plots of scores for original and obfuscated problems averaged for eight models evaluated on the larger benchmark. Impact of Obfuscation on Humans To ensure that the reasoning element of the problems is preserved under obfuscation, we investigate the impact on human performance. We performed randomised controlled trial (RCT) with 172 participants recruited through Prolific. All participants were required to speak English, have no familiarity with other languages, and have at least an undergraduate degree. Participants were randomly assigned to two groups (unobfuscated and obfuscated), then presented with one of six problems, which were all chosen to be relatively easy to ensure novice test takers had realistic chance of solving them. There were two possible permutations of each obfuscated problem. The mean scores for those solving unobfuscated and obfuscated problems were 0.22 and 0.16, respectively. After fitting linear regression controlling for random variation in problem frequency, obfuscation is associated with 5.80 percentage point decrease in performance (p = 0.059). Furthermore, these results are supported by one-sided Mann Whitney test, which rejects the null hypothesis that the distributions of scores are identical (p = 0.041). This suggests obfuscation causes small drop in scores when the problems are taken by human participants without prior linguistics experience. In addition, the selected problems were externally audited by two International Linguistics Olympiad medallists, each given one set of obfuscations. The auditors confirmed that all problems remained solvable and that problem difficulty appeared consistent under obfuscation. The combined analysis implies that obfuscation does not change the reasoning steps required to solve the problem, but does cause small drop in human performance. We speculate that this may be because the resulting orthographies seem less familiar or naturalistic relative to English, causing the problems to be perceived as more challenging, and participants to exert less effort (Scasserra, 2008). This hypothesis is weakly supported by the finding that participants solving obfuscated problems spent less time on problems before submitting their answers (p = 0.071 under one-sided MannWhitney test). If LLMs reason in similar way to the participants in this RCT, we may expect small drops in performance under obfuscation, even in the absence of prior exposure to the Problemese language. However, we have no reason to expect large deterioration as indicated by the mean obf across models. Full methodological details, statistical analysis, and discussion are presented in Appendix K. Tokenisation As tokenisers of LLMs were trained on languages in their original orthography, we explored whether tokenisation can explain the variance (and drop) in model performance. Byte Pair Encoding (Gage, 1994), common tokenisation approach, takes into account transition frequency between characters. Since obfuscation produces less common sequences of characters, we hypothesise this may affect the tokenisation step. We select Aya-23-35B to explore alternate tokenisation strategies given it was explicitly trained for multilingualism. We compare three variations of 6 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Prompt type Unobfuscated Obfuscated Standard Dash Character 0.087 0.051 0.053 0.050 0.045 0. Table 2: Exact match results with varying input to the tokeniser. Performance of Aya-23-35B decreases when alternative tokenisation techniques are used, both on obfuscated and unobfuscated problems. Dash tokenisation inserts dash between each character in the Problemese data. Character tokenisation forces the model to tokenise each character individually. tokenisation: standard tokenisation, introducing dash between each character in the Problemese and tokenising each character separately. Since the problems span several lowresource languages which coule be tokenized sub-optimally, we suspect that the dense representations of the tokens are unlikely to be useful for solving the problems. These variations break up the tokenisation of the Problemese words to ensure that tokens do not cross semantically meaningful boundaries in the words which would make the problems more difficult. Table 2 shows that enforcing separation of the tokens does not improve model performance. For both obfuscated and original versions, exact match score decreases if the tokenisation of Problemese is altered. When comparing at the question level, using alternative tokenisations improved performance in less than one fifth of the cases. This suggests that the standard tokenisation of the obfuscated problems is not making the problems more difficult or is the sole explanation of failed reasoning in the model. For more details see Appendix J. 3.3. Impact of Data Exposure To explore the potential impact of data contamination on model performance, we conducted small study with our larger benchmark using LLama 3.2 1B and LLama 3.2 3B. We used subset of the obfuscated problems as training data to run supervised fine-tuning on both models. In order to inspect the effects of contamination by the degree of exposure as well as the type of generalisation affected, we split the data into the following disjoint sets: (1) Training and validation datasets (n = 12, 110 for train and = 3, 054 for validation); (2) Unseen questions and exposed obfuscations (n = 6, 864); (3) Unseen obfuscations (n = 7, 926); (4) Unseen obfuscations and questions (n = 2, 100); (5) Unseen problems (n = 20, 537). We fine-tuned two models using the training and validation splits and evaluate them on the remaining unseen subsets. We use the same prompts as in our evaluation experiments for both fine-tuning and evaluation phases. For multiplechoice questions, we randomly shuffle the order of the answer choices to minimise the risk of over-fitting. We finetune the instruction-tuned Llama 3.2 1B and 3B models for 1 epoch using AdamW with lr = 1e 5, weight decay of 0.01 and batch size of 8 for the 1B model and 4 for the 3B model. Results were comparable using other hyperparameter choices, though we did not carry out extensive hyperparameter search. We report the difference of exact match scores Mog and Mobf before and after fine-tuning to measure improved performance after fine-tuning. Table 3 shows the difference after fine-tuning for each split. As expected, both models improve significantly on the questions included in the training (0.71 for the 3B model and 0.58 for the 1B model). Both models also improve on unseen obfuscations split (0.38 and 0.32 respectively). Except for unseen obfuscations, both models show limited improvement on all other unseen splits (mean difference in scores for both models 0.4). The modest improvement on unseen questions is surprising given that these questions are continuations of the same training problems in their same obfuscations. This is more clearly evident when only considering answers which are altered by the obfuscation procedure with mean difference 0.02 in both models. The exception is the 3B models ability to improve 0.17 on unseen obfuscations of questions included in training. Overall, the results suggest overfitting on obfuscations present in training data. The naive inclusion of few examples of reasoning questions does not necessarily improve reasoning abilities in general. Yet, the positive change in score in unseen obfuscations suggests that level of transfer occurs when seeing multiple permutations of the same type of question. 4. Related Works 4.1. Reasoning in LLMs Prior works assess reasoning in LLMs within specific problem domains, such as mathematical word problems (Cobbe et al., 2021; Hendrycks et al., 2021; Chen et al., 2023; Shao et al., 2024), visual pattern-matching (Chollet, 2019), multi-step planning (Valmeekam et al., 2022; Kambhampati, 2024), and commonsense question-answering (Zelikman et al., 2022; Lin et al., 2020; Rajani et al., 2019; Talmor et al., 2019). Inference-time techniques, like chainof-thought (CoT) prompting, present promising direction for reasoning tasks (Wei et al., 2022; Kojima et al., 2022). These techniques bear superficial resemblance to Dual Process Theorys System 2 model of human decision-making (Evans & Stanovich, 2013; Kahneman, 2013), as LLMs expend additional deliberative effort to think for long time before responding (OpenAI et al., 2024). Recent work utilising reinforcement learning to optimise CoT strategies (Xu et al., 2025; Deepseek-AI, 2025; OpenAI et al., 2024) Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Model Answer Train Val Held out Held out Held out Q/O Held out Llama 3.2 1B Inst All Same Changed LLama 3.2 3B Inst All Same Changed 0.58 0.88 0.15 0.71 0.89 0.45 0.02 0.03 0.00 0.01 0.01 -0. 0.04 0.10 0.00 0.02 0.04 0.01 0.32 0.60 0.06 0.38 0.61 0.17 0.03 0.06 0.01 0.02 0.03 0.02 0.03 0.06 0.01 0.01 0.00 0.02 Table 3: Performance change after fine-tuning. Difference in mean exact match after fine-tuning on each of the held out splits. Answer changed refers to when obfuscation altered the correct answer, same refers to when the answer after obfuscation was not altered. Q: Questions, O: Obfuscations, Q/O: Questions and Obfuscations, P: Problems. shows impressive promise on relevant tasks (Valmeekam et al., 2024; McCoy et al., 2024; Guan et al., 2025). However, other research shows that LLMs do not reason perfectly, exhibiting human-like failures such as distractability (Shi et al., 2023) and content effects (Lampinen et al., 2024) on reasoning tasks. Unlike humans, LLMs exhibit varying performance across minor perturbations of reasoning problems, suggesting to some that they do not reason at all (Mirzadeh et al., 2024). LLMs also exhibit token bias (Jiang et al., 2024)a sensitivity to the probability of outputs, even in non-probabilistic settings (McCoy et al., 2019; 2023; Razeghi et al., 2022), which is not improved by inference-time scaling (McCoy et al., 2024). 4.2. Contamination in Reasoning Benchmarks Dataset contamination, when benchmark questions occur directly in training data, can damage the reliability of reasoning benchmarks (Zhou et al., 2023; Jacovi et al., 2023; Yang et al., 2023). Contamination allows LLMs to achieve high performance through memorisation, undermining the construct validity of the task (Bean et al., 2024). Prior efforts to mitigate and contextualise the effects of contamination in reported performance have utlized questions perturbations and incorporating synthetic variations to prompts. Perturbation can be achieved through the introduction of handcrafted adversarial content, like irrelevant context (Shi et al., 2023) or structural variations of the original questions (Patel et al., 2021). Closer to our work, other approaches generate synthetic variants of questions using templatisation (Jiang et al., 2024; Kumar et al., 2021). Mirzadeh et al. (2024) uses synthetic templates to produce variants of problems in the GSM8K dataset (Cobbe et al., 2021), taking unreasonably high performance on the original questions as evidence of memorisation. To measure memorisation on LINGOLY, Bean et al. (2024) report accuracy relative to no context baselinea score achieved on problems lacking the requisite context and thus only solvable by memorisation. Similarly, Patel et al. (2021) report accuracy on the MAWPS benchmark (Koncel-Kedziorski et al., 2016) where final questions, instead of prior context, are removed. Deng et al. (2024) introduce testlet-slot guessing, in which models are asked to fill out masked incorrect answer for multiple choice question, as an indication of memorised answers. An alternative approach to combat contamination makes use of linguistics problems in low-resource settings (Tanzer et al., 2024; Chi et al., 2024; Bean et al., 2024). Lowresource languages are low-probability settings for LLMs (Vaduguru et al., 2021; McCoy et al., 2023), making them effective settings for testing in-context reasoning (Tanzer et al., 2024; Bean et al., 2024). Prior benchmarks utilise problems from national (Bean et al., 2024) and international (Vaduguru et al., 2021; Sanchez et al., 2024) Linguistics Olympiads. 5. Limitations Coarse Metrics Exact Match uniformly penalises all incorrect answers, including partially correct ones, and limits insights into various failure modes. Yet, metrics such as BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004) are unsuitable for the very short answers common in our benchmark and chrF (Popovic, 2015) is sensitive to repeating related words from the context. In reality, Linguistics Olympiads typically award partial credit for answers which show partial understanding of the problems. Future work could explore alternative evaluation metrics that capture partial solutions or help discern partially correct answers. By operating on the solution steps in addition to final answers, novel evaluation scores could credit correct reasoning steps and allow deeper insights into prediction pathways in models. Limited Model Improvements Aside from our finetuning experiment around data contamination, we do not show clear ways in which model could be improved on this benchmark. Exploring other approaches such as few-shotlearning (Brown et al., 2020) or incorporating translation as an auxiliary task may prove more effective at developing systems with improved and generalisable capabilities. 8 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation 6. Conclusion In this work we introduced LINGOLY-TOO, challenging benchmark of linguistic reasoning problems. We apply orthographic templatisation to Linguistics Olympiad problems to produce obfuscated variants that preserve the same reasoning steps. We demonstrate through numerous experiments that obfuscation helps alleviate measurement bias due to data exposure and provides reasoning estimates that correlate with the ability to solve linguistic reasoning problems. We further show that the reasoning abilities of state-of-theart models remain inconsistent and that simple fine-tuning does not necessarily endow models with context-free and robust problem solving skills. This work establishes measure of reasoning that is robust to effects of data exposure and contributes to ongoing efforts targeting the inherent difficulty of fully understanding response generation in frontier models."
        },
        {
            "title": "Impact Statement",
            "content": "This paper aims to advance the field of machine learning. Constructing problems around the features of low-resource languages to create benchmark may lead to concerns about the benefit to the communities who speak these languages (Tanzer et al., 2024). For Linguistic Olympiads, problems are created from sources in the public domain and where the communities have already given linguist permission to publish information about the language. In this paper, we transform existing puzzles, and do not create new content in the languages. We restrict the dataset from training or redistribution so that new uses of these languages must come from the original sources."
        },
        {
            "title": "References",
            "content": "Aryabumi, V., Dang, J., Talupuru, D., Dash, S., Cairuz, D., Lin, H., Venkitesh, B., Smith, M., Campos, J. A., Tan, Y. C., et al. Aya 23: Open weight releases to further multilingual progress. arXiv preprint, 2024. URL https://arxiv.org/abs/2405.15032. Asia Pacific Linguistics Olympiad. Problems by year, URL https://aplo.asia/problems/ 2024. problems-by-year/. Bean, A. M., Hellsten, S., Mayne, H., Magomere, J., Chi, E. A., Chi, R. A., Hale, S. A., and Kirk, H. R. LINGOLY: benchmark of olympiad-level linguistic reasoning puzzles in low resource and extinct languages. In The 38th Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. URL https: //openreview.net/forum?id=cLga8GStdk. Bozhanov, B. and Derzhanski, I. Rosetta stone linguistic problems. In Derzhanski, I. and Radev, D. (eds.), Proceedings of the Fourth Workshop on Teaching NLP and CL, pp. 18, Sofia, Bulgaria, August 2013. Association for Computational Linguistics. URL https: //aclanthology.org/W13-3401/. Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners. arXiv preprint, 2020. URL https://arxiv.org/abs/2005.14165. Chen, W., Ma, X., Wang, X., and Cohen, W. W. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Transactions on Machine Learning Research, 2023. ISSN 28358856. URL https://openreview.net/forum? id=YfZ4ZPt8zd. Chi, N., Malchev, T., Kong, R., Chi, R., Huang, L., Chi, E., McCoy, R., and Radev, D. ModeLing: novel dataset for testing linguistic reasoning in language models. In Hahn, M., Sorokin, A., Kumar, R., Shcherbakov, A., Otmakhova, Y., Yang, J., Serikov, O., Rani, P., Ponti, E. M., Muradoglu, S., Gao, R., Cotterell, R., and Vylomova, E. (eds.), Proceedings of the 6th Workshop on Research in Computational Linguistic Typology and Multilingual NLP, pp. 113119, St. Julians, Malta, March 2024. Association for Computational Linguistics. URL https: //aclanthology.org/2024.sigtyp-1.14/. Chollet, F. On the measure of intelligence. arXiv preprint, 2019. URL http://arxiv.org/abs/ 1911.01547. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training Verifiers to Solve Math Word Problems. arXiv preprint, 2021. URL https://arxiv.org/abs/2110.14168. Deepseek-AI. DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning. arXiv preprint, 2025. URL https://arxiv.org/abs/ 2501.12948. Deng, C., Zhao, Y., Tang, X., Gerstein, M., and Cohan, A. Investigating data contamination in modern benchmarks for large language models. In Duh, K., Gomez, H., and Bethard, S. (eds.), Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pp. 87068719. Association for 9 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Computational Linguistics, 2024. doi: 10.18653/v1/2024. naacl-long.482. URL https://aclanthology. org/2024.naacl-long.482/. Evans, J. S. B. T. and Stanovich, K. E. Dual-process theories of higher cognition: Advancing the dePerspectives on Psychological Science, 8 bate. 1745- (3):223241, 6924. URL doi: https://journals.sagepub.com/doi/10. 1177/1745691612460685. 2013. ISSN 1745-6916, 10.1177/1745691612460685. Gage, P. new algorithm for data compression. The Users Journal, 12(2):2338, 1994. Guan, X., Zhang, L. L., Liu, Y., Shang, N., Sun, Y., Zhu, Y., Yang, F., and Yang, M. rStar-Math: Small llms can master math reasoning with self-evolved deep thinking. arXiv preprint, 2025. URL https://arxiv.org/ abs/2501.04519. Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J. Measuring mathematical problem solving with the MATH dataset. In Vanschoren, J. and Yeung, S. (eds.), Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, 2021. Huang, J. and Chang, K. C.-C. Towards reasoning in large language models: survey. In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp. 10491065, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-acl. 67. URL https://aclanthology.org/2023. findings-acl.67/. Jacovi, A., Caciularu, A., Goldman, O., and Goldberg, Y. Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evalIn Bouamor, H., Pino, J., and uation benchmarks. Bali, K. (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 50755084. Association for Computational Lindoi: 10.18653/v1/2023.emnlp-main. guistics, 2023. 308. URL https://aclanthology.org/2023. emnlp-main.308/. Jiang, B., Xie, Y., Hao, Z., Wang, X., Mallick, T., Su, W. J., Taylor, C. J., and Roth, D. peek into token bias: Large language models are not yet genuine reasoners. In AlOnaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 47224756, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main. 272. URL https://aclanthology.org/2024. emnlp-main.272/. Kahneman, D. Thinking, Fast and Slow. Psychology/Economics. Farrar, Straus and Giroux, first paperback edition edition, 2013. ISBN 978-0-374-53355-7. Kambhampati, S. Can large language models reason and plan? Annals of the New York Academy of Sciences, 1534 (1):1518, 2024. ISSN 0077-8923, 1749-6632. doi: 10. 1111/nyas.15125. URL http://arxiv.org/abs/ 2403.04121. Kohrt, M. The term graphemein the history and theory of linguistics. New trends in graphemics and orthography, pp. 8096, 1986. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35: 2219922213, 2022. Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman, N., and Hajishirzi, H. MAWPS: math word problem repository. In Knight, K., Nenkova, A., and Rambow, O. (eds.), Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 11521157. Association for Computational Linguistics, June 2016. doi: 10.18653/v1/N16-1136. URL https://aclanthology.org/N16-1136/. Koralus, P. Reason and Inquiry: The Erotetic Theory. Oxford University Press, 1st edition, 2022. ISBN 978-019-186254-0. URL https://doi.org/10.1093/ oso/9780198823766.001.0001. Kumar, V., Maheshwary, R., and Pudi, V. Adversarial examples for evaluating math word problem In Moens, M.-F., Huang, X., Specia, L., solvers. the Associaand Yih, S. W.-t. (eds.), Findings of tion for Computational Linguistics: EMNLP 2021, pp. 27052712. Association for Computational Linguistics, November 2021. doi: 10.18653/v1/2021.findings-emnlp. 230. URL https://aclanthology.org/2021. findings-emnlp.230/. Lampinen, A. K., Dasgupta, I., Chan, S. C. Y., Sheahan, H. R., Creswell, A., Kumaran, D., McClelland, J. L., and Hill, F. Language models, like humans, show content effects on reasoning tasks. PNAS Nexus, 3(7):pgae233, 2024. ISSN 2752-6542. doi: 10.1093/pnasnexus/pgae233. URL https://doi.org/10.1093/pnasnexus/ pgae233. Li, C. and Flanigan, J. Task contamination: Language models may not be few-shot anymore. Proceedings 10 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation of the AAAI Conference on Artificial Intelligence, 38 doi: 10.1609/aaai.v38i16. (16):1847118480, 2024. 29808. URL https://ojs.aaai.org/index. php/AAAI/article/view/29808. Lin, B. Y., Zhou, W., Shen, M., Zhou, P., Bhagavatula, C., Choi, Y., and Ren, X. CommonGen: constrained text generation challenge for generative commonsense reasoning. In Cohn, T., He, Y., and Liu, Y. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 18231840. Association for Computational Linguistics, 2020. doi: 10.18653/v1/2020.findings-emnlp. 165. URL https://aclanthology.org/2020. findings-emnlp.165/. Lin, C.-Y. ROUGE: package for automatic evaluaIn Text Summarization Branches tion of summaries. Out, pp. 7481, Barcelona, Spain, July 2004. Association for Computational Linguistics. URL https: //aclanthology.org/W04-1013/. McCoy, R. T., Pavlick, E., and Linzen, T. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. arXiv preprint, 2019. URL https: //arxiv.org/abs/1902.01007. McCoy, R. T., Yao, S., Friedman, D., Hardy, M., and Griffiths, T. L. Embers of autoregression: Understanding large language models through the problem they are trained to solve. arXiv preprint, 2023. URL http: //arxiv.org/abs/2309.13638. McCoy, R. T., Yao, S., Friedman, D., Hardy, M. D., and Griffiths, T. L. When language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1. arXiv preprint, 2024. URL https://arxiv.org/abs/2410.01792. Mirzadeh, I., Alizadeh, K., Shahrokhi, H., Tuzel, O., Bengio, S., and Farajtabar, M. GSM-Symbolic: Understanding the limitations of mathematical reasoning in large language models. arXiv preprint, 2024. URL http://arxiv. org/abs/2410.05229. OpenAI, El-Kishky, A., Selsam, D., Song, F., Parascandolo, G., Ren, H., Lightman, H., Chung, H. W., Akkaya, I., Sutskever, I., Wei, J., Gordon, J., Cobbe, K., Yu, K., Kondraciuk, L., Schwarzer, M., Rohaninejad, M., Brown, N., Zhao, S., Bansal, T., Kosaraju, V., and Zhou, W. Learning to reason with LLMs, 2024. URL https://openai.com/index/ learning-to-reason-with-llms/. 311318, USA, 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL https: //doi.org/10.3115/1073083.1073135. Patel, A., Bhattamishra, S., and Goyal, N. Are NLP models really able to solve simple math word problems? In Toutanova, K., Rumshisky, A., Zettlemoyer, L., Hakkani-Tur, D., Beltagy, I., Bethard, S., Cotterell, R., Chakraborty, T., and Zhou, Y. (eds.), the North Proceedings of American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 20802094. Association for Computational Linguistics, June 2021. doi: 10.18653/v1/2021.naacl-main. 168. URL https://aclanthology.org/2021. naacl-main.168/. the 2021 Conference of Popovic, M. chrF: character n-gram F-score for automatic MT evaluation. In Bojar, O., Chatterjee, R., Federmann, C., Haddow, B., Hokamp, C., Huck, M., Logacheva, V., and Pecina, P. (eds.), Proceedings of the Tenth Workshop on Statistical Machine Translation, pp. 392395, Lisbon, Portugal, September 2015. Association for Computational Linguistics. doi: 10.18653/v1/W15-3049. URL https://aclanthology.org/W15-3049/. Rajani, N. F., McCann, B., Xiong, C., and Socher, R. Explain yourself! Leveraging language models for commonsense reasoning. In Korhonen, A., Traum, D., and M`arquez, L. (eds.), Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 49324942. Association for Computational Linguistics, 2019. doi: 10.18653/v1/P19-1487. URL https://aclanthology.org/P19-1487/. Raji, D., Denton, E., Bender, E. M., Hanna, A., and Paullada, A. AI and the everything in the whole wide world benchmark. In Vanschoren, J. and Yeung, S. (eds.), Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, volume 1, 2021. Razeghi, Y., Logan IV, R. L., Gardner, M., and Singh, S. Impact of pretraining term frequencies on few-shot numerical reasoning. In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2022, pp. 840854, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022. findings-emnlp.59. URL https://aclanthology. org/2022.findings-emnlp.59/. Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. BLEU: method for automatic evaluation of machine translaIn Proceedings of the 40th Annual Meeting on tion. Association for Computational Linguistics, ACL 02, pp. Russell, J., Karpinska, M., and Iyyer, M. People who frequently use chatgpt for writing tasks are accurate and robust detectors of ai-generated text, 2025. URL https://arxiv.org/abs/2501.15654. 11 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation ahin, G. G., Kementchedjhieva, Y., Rust, P., and Gurevych, I. PuzzLing Machines: challenge on learning from small data. In Jurafsky, D., Chai, J., Schluter, N., and Tetreault, J. (eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 12411254, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main. 115. URL https://aclanthology.org/2020. acl-main.115/. Scasserra, D. The influence of perceived task difficulty on task performance, 2008. URL https://rdw.rowan. edu/etd/756. Shao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang, H., Zhang, M., Li, Y. K., Wu, Y., and Guo, D. DeepSeekMath: Pushing the limits of mathematical reasoning in open language models. arXiv preprinx arXiv:2402.03300, 2024. URL http://arxiv.org/ abs/2402.03300. Shi, F., Chen, X., Misra, K., Scales, N., Dohan, D., Chi, E. H., Scharli, N., and Zhou, D. Large language models can be easily distracted by irrelevant context. In International Conference on Machine Learning, pp. 31210 31227. PMLR, 2023. Sanchez, E., Alastruey, B., Ropers, C., Stenetorp, P., Artetxe, M., and Costa-juss`a, M. R. Linguini: benchmark for language-agnostic linguistic reasoning. arXiv preprint, 2024. URL https://arxiv.org/abs/ 2409.12126. Talmor, A., Herzig, J., Lourie, N., and Berant, J. CommonsenseQA: question answering challenge targeting commonsense knowledge. In Burstein, J., Doran, C., and Solorio, T. (eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 41494158. Association for Computational Linguistics, 2019. doi: 10.18653/v1/N19-1421. URL https://aclanthology.org/N19-1421/. Tanzer, G., Suzgun, M., Visser, E., Jurafsky, D., and MelasKyriazi, L. benchmark for learning to translate new language from one grammar book. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum? id=tbVWug9f2h. United Kingdom Linguistics Olympiad. Special arrangements for the 2021 competition, 2021. URL https: //archives.uklo.org/covid2021. United Kingdom Linguistics Olympiad. Past challenge puzzles: How far can you go?, 2023. URL https:// 12 www.uklo.org/past-exam-papers/. Accessed: 2025-01-28. Vaduguru, S., Sathe, A., Choudhury, M., and Sharma, D. M. Sample-efficient linguistic generalizations through program synthesis: Experiments with phonology problems. arXiv preprint, 2021. URL https://arxiv.org/ abs/2106.06566. Valmeekam, K., Olmo, A., Sreedharan, S., and Kambhampati, S. Large language models still cant plan (a benchmark for LLMs on planning and reasoning about change). In NeurIPS 2022 Foundation Models for Decision Making Workshop, 2022. URL https://openreview. net/forum?id=wUU-7XTL5XO. Valmeekam, K., Stechly, K., and Kambhampati, S. LLMs still cant plan; can LRMs? preliminary evaluation of OpenAIs o1 on PlanBench. In NeurIPS 2024 Workshop on Open-World Agents, 2024. URL https: //openreview.net/forum?id=Gcr1Lx4Koz. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain-ofthought prompting elicits reasoning in large language models. In 36th Conference on Neural Information Processing Systems, 2022. Xu, F., Hao, Q., Zong, Z., Wang, J., Zhang, Y., Wang, J., Lan, X., Gong, J., Ouyang, T., Meng, F., Shao, C., Yan, Y., Yang, Q., Song, Y., Ren, S., Hu, X., Li, Y., Feng, J., Gao, C., and Li, Y. Towards large reasoning models: survey of reinforced reasoning with large language models. arXiv preprint, 2025. URL http: //arxiv.org/abs/2501.09686. Yang, S., Chiang, W.-L., Zheng, L., Gonzalez, J. E., and Stoica, I. Rethinking benchmark and contamination for language models with rephrased samples. arXiv preprint, 2023. URL https://arxiv.org/abs/ 2311.04850. Zelikman, E., Wu, Y., Mu, J., and Goodman, N. STaR: Bootstrapping reasoning with reasoning. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum? id=_3ELRdg2sgI. Zhou, K., Zhu, Y., Chen, Z., Chen, W., Zhao, W. X., Chen, X., Lin, Y., Wen, J.-R., and Han, J. Dont make your LLM an evaluation benchmark cheater. arXiv preprint, 2023. URL http://arxiv.org/abs/2311.01964. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation A. Glossary Word cognate diacritic Meaning Word or word-part with the same historical origin as another. E.g. English father, German Vater, Swedish far. Symbol added to letter or other basic glyph; often called accent. (language) family Group of languages all derived from common ancestor. E.g. the Romance language family is derived from Latin. grapheme lexeme Letter or group of letters that typically represent single sound or suprasegmental feature. See (Kohrt, 1986) for discussion of other definitions in common usage. Basic unit of the lexicon (vocabulary) of language. E.g. sit, sits, sitting, sat are all inflected forms of the same lexeme. (transparent) loanword Word borrowed from another language. loanword is transparent if it is obviously loanword. E.g. Nepali pensil pencil. morpheme morphology n-graph orthography phonetics phonology Basic unit of meaning within word. E.g. help-less-ness consists of three morphemes. Branch of linguistics dealing with the internal structure and formation of words. Collection of letters representing single grapheme. E.g. th and sh are English digraphs. System for writing language, including the choice letters or other glyphs and spelling conventions. Branch of linguistics dealing with the production and perception of speech sounds or signs. Branch of linguistics dealing with the systematisation and organisation of sounds or signs within language. phonological distinction Distinction between two speech sounds that is treated as meaningful within language. Problemese semantics Solverese suprasegmental Unknown language that is the focus of Linguistics Olympiad problem. Branch of linguistics dealing with the study of meaning. Language that Linguistics Olympiad problem is written in; assumed to be the working language of the solver. Phonetic or phonological feature that extends beyond single speech sound. E.g. stress, intonation, pitch. syllabification Procedure for forming valid syllables out of string of speech sounds. syntax Branch of linguistics dealing with the organisation of words into phrases, clauses and sentences. Table 4: Glossary of linguistic terms. B. Annotations B.1. Annotation Process Annotation was the first step of obfuscation process in LINGOLY-TOO. The primary task was removing metadata included in the problem text such as language names, families, and geographic regions that were not relevant for solving the problem via reasoning, but could have allowed models to ascertain facts about the language, even when obfuscated. Problemese data that would be altered in later stages of obfuscation were also highlighted during annotation. All problem annotations were performed by single annotator to minimise the inconsistency between different problems. Two other members of the team had expertise in Linguistics Olympiads, one being Vice-Chair & Chair of Test Development at UKLO, and the other Secretary General & International Jury Chair of the Asia Pacific Linguistics Olympiad. They validated each of the annotated problems, identifying and documenting any errors or inconsistencies that needed correcting. Despite these checks, mistakes may remain as the result of human error. 13 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Problem Original Annotated 67 16 61 This problem is about the way in which Navajo speakers build sentences out of verb V. This problem is about the way in which $$$Language X$$$ speakers build sentences out of verb V. Ulwa is language spoken in Nicaragua. It contains quite few loanwords from English, which is spoken in the Bluefields area of the country. $$$Language X$$$ &&& &&& contains quite few loanwords from English &&& &&&. dinaldalusanda they were cleaning it @@@dinaldalusanda@@@ they were cleaning it t(in)ak+takaw+da ida tinaktakawda ida Table 5: Annotation examples. Each row is an extract from problem in LINGOLY-TOO. On the left, the extract appears in the original UKLO problem sheet. On the right, the extract after annotation. Problem 67 (Navajo by Babette Verhoeven) is an example of the language name annotation. Problem 16 (Ulwa by Richard Sproat) is example of the cultural context annotation. Problem 61 (Ilokano by Bozhidar Bozhanov) illustrates the annotation of Problemese in preparation for further obfuscation, and is an example of removing grading guidelines from the dataset to prepare it for checking exact matching. B.2. Annotation Categories Four categories of annotations were performed: language and place names, cultural context, Problemese data and grading guidelines. Each involved bracketing strings in the problem files with triplets of symbol not used elsewhere in the problems. Language and Place Names The English name of the Problemese language was replaced with Language wherever it appeared in the problem, and was annotated using $$$ tag (see row one in Table 5). If multiple non-English languages were mentioned in the problem, the second was replaced with Language and the third with Language Z. maximum of three languages appeared in any given problem. Where related terms such as geographic regions or people groups associated with those languages were relevant to the problem, they were replaced with e.g. Region X, and also annotated using the $$$ tag. Where two historical varieties of the same language were featured in the same problem, their names were replaced with Language and Language Y, and sentence clarifying their relationship was added. Cultural Context Any other metadata or cultural references that could indicate the origin of language but were not relevant to solving the problem were replaced with space, and annotated with &&& tag (see row two in Table 5). If it was not clear whether some part of the metadata might be useful in solving the problem, it was annotated with the $$$ tag, and edited in accordance with the principals in the previous paragraph. Problemese Data All Problemese data were annotated using an @@@ tag (see row three in Table 5). Where problems involved multiple languages, these were not distinguished in annotation. Instead, the permutations of graphemes used to alter the Problemese data were designed to preserve the distinctions between the languages. Many of the problems included pronunciation guides, since students sitting UKLO exams are not expected to have any prior linguistic knowledge. These pronunciation guides were not annotated, since the permutations of the graphemes used to alter the Problemese always preserved any relevant phonetic and phonological distinctions. Grading Guidelines Most UKLO answer sheets include marking guidelines for awarding partial credit, which are often accompanied by symbols such as +, and brackets written inside the correct answers. These were simply removed from the answer files (see row four in Table 5). C. Obfuscation Rulesets The core of the obfuscation procedure is the altering of the Problemese data. This is done by creating new orthography for the Problemese, which is simple permutation of the graphemes present in the original data. We created problem-specific rulesets governing acceptable permutations, which ensure that the solvability of the problem is preserved, and allow for the dynamic generation of new obfuscated variations of the problems in the benchmark. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation C.1. Methodology To determine the obfuscation ruleset for given problem, the following procedure was applied. Firstly, the set of graphemes present in the Problemese data was determined. This involved using the authors expert judgement on which strings should be analysed as n-graphs and therefore single graphemes, and which could be split into multiple units. common example was deciding when combination of letter with diacritic should be treated as single grapheme (as in Spanish n) or as multiple graphemes (as in Spanish a). This sometimes involved consulting literature on the language, but usually it was sufficient to consult the commentary on the problem provided by UKLO, as well as the authors own solutions to the problems. Note that grapheme could be substring of another graphemeconsider English as substring of sh. In this situation, the obfuscation algorithm would scan the annotated text left-to-right, and exchange the longest matching grapheme with its replacement under the obfuscation in greedy manner. We then determined what phonetic and phonological data needed to be preserved in the orthography. In many cases, more phonological data was preserved than strictly necessary, such as always keeping vowels and consonants separate. This was both to preserve alternative solving paths to the authors, which may have involved different set of phonological observations, and to allow for consistent syllabification across obfuscations. This data was then encoded in the obfuscation ruleset for the problem. C.2. Structure of an Obfuscation Ruleset An obfuscation ruleset for particular problem partitions the graphemes in the Problemese data into four types of structured collection: sets, tables, free-tables and fixed set. An obfuscation is choice of structure-preserving permutation of each of these collections, which combine to give permutation of all of the graphemes in the data. Sets set is simply collection of graphemes, with no extra structure that needs to be preserved. An obfuscation can therefore involve any permutation of the graphemes in set. Tables The graphemes in table are partitioned into tuples each of the same length, thought of as columns of table. The obfuscation then freely permutes these columns, while preserving the rows (index in the tuple) where the graphemes appear. For example, table {(p, b), (t, d), (k, g)} = d will have 3! = 6 ways to permute the 3 columns, hence 6 possible obfuscations: d obfuscations t , b , d , k , g , b Linguistically, this represents situation where plosives appear in voiceless/voiced pairs, and this data must be preserved, but the place of articulation of the plosives is not relevant, so may be permuted. Compare this to situation where only the voicedness was relevant, but not the voiceless/voiced pairs, which could be obfuscated by pair of sets {p, t, k}, {b, d, g}, allowing for 3! 3! = 36 possible obfuscations. Free-Tables These are generalisation of tables where some of the rows consist of collections of more than one element, together forming set. An choice of obfuscation is first choice of permutation of the columns, then choice of bijection from each original cell to the obfuscated cell. For example, free-table {(m, {p, b, }), (n, {t, d, s})} = p, b, t, d, has 2! (3!)2 = 72 possible obfuscations. An example is shown below, where the non-identity permutation of the columns was chosen. p, b, n t, d, obfuscation t, s, b, p, = (cid:55) (cid:55) (cid:55) (cid:55) n (cid:55) (cid:55) (cid:55) (cid:55) 15 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Linguistically, this represents situation where homorganic nasals are relevant, but otherwise place and manner of articulation are not relevant. Fixed Set Any grapheme not in any set, table or free-table was fixed by any permutation. Additionally, other strings that should not be changed during obfuscation could be specified as single grapheme within the fixed set. Such strings primarily fell into two categories: transparent loanwords or cognates, and names. Where words in the Problemese data had noticeable resemblances to English or another well-known language, such as Nepali pensil pencil or Yawalapiti amiku friend (cf. Portuguese amigo), and where these resemblances may have decreased the difficulty of the problem by providing starting point for reasoning, they were always preserved. The only times that transparent cognates were not preserved was when the problem did not involve the meanings of words, so recognition of the cognate would provide no advantage. Names of people (both real and fictional) and deities were also always preserved. The names of places and languages were preserved where possible, but not if it would consequently indicate the what the Problemese language was. C.3. Comparison to Obfuscation in Linguistics Olympiads This method of obfuscation is more severe than what is typically used by Linguistics Olympiads. Although most Linguistics Olympiads do not perform any intentional obfuscation, where it is done common notations are exchanged for other common notations as far as possible. For example, in UKLO 2021 A4 Sauk by Ryan Chi, long vowels were changed from being written with circumflex (e.g. ˆa) to being doubled (e.g. aa). This is typically sufficient to prevent search engines from returning relevant results, but has little effect on any advantage gained by having prior familiarity with the language. C.4. Effects of Obfuscation Across Linguistic Subdisciplines Given the difficulty of preserving phonological structure when altering Problemese data, there is risk that problems with stronger emphasis on phonology are accidentally rendered unsolvable during obfuscation. We demonstrate that this is not the case, at least on large scale, by categorizing the problems by their primary linguistic focus and comparing the effects of obfuscation. Linguistic Subdisciplines We partition the problems into six categories based on their primary linguistic focus as described by the Linguistic Subject classification provided by UKLO. Compounding problems focus on the meaning of lexemes given their structure and cultural context; morphology problems focus on how morphemes (word-parts) combine to form grammatical words; numbers problems focus on the structure and use of numeral phrases; phonology problems focus on the classification and structure of speech sounds, and their effects on grammar; semantics problems focus on how meaning impacts grammar; and syntax problems focus on how words combine to form grammatically valid phrases and sentences. Results Models perform comparably on the original problems across all subdisciplines, with the exception of numbers, where performance is significantly lower, although this may be due to numbers problems typically only appearing at higher difficulties in UKLO. The effect of obfuscation is also roughly uniform across subdisciplines (with the exception of numbers), suggesting that obfuscation does not especially impact phonology problems. Compounding problems may be more affected by obfuscation; we hypothesise that dictionaries and lexicons (which are typically the source material for compounding questions) are more likely to occur in model training data than full or sketch grammars (the typical sources for other problem types), giving models an advantage on the original versions of many compounding problems. C.5. Examples of Obfuscation Rulesets Problem 91, Somali (by Harold Somers). This problem involves determining the formation of 1sg and 3sg forms of Somali3 verbs. The solution is as follows: (i) The 1sg form adds -ay to the root, while the 3sg form adds -tay. (ii) After the guttural consonants q, c, x, , the so-called guttural consonants, we have the change d. (iii) Everywhere, we have the following changes: d; lt sh; dt d; dht dh. 3Somali is Cushitic language spoken by approximately 24 million people, primarily ethnic Somalis in East Africa and in diaspora. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 6: Performance by linguistic subdiscipline. Left: Averaged across all models. Models perform comparably across linguistic subdisciplines, with the exception of numbers problems. The effect of obfuscation is relatively even across subdisciplines. Right: Averaged across the four highest-scoring models (o1 Preview, Claude 3.5 Sonnet, GPT 4o, Gemini 1.5 Pro). Compounding problems are affected particularly severely by obfuscation. There are no names or loanwords in the Somali data that need to be preserved by the obfuscation, so the obfuscation ruleset will only depend on the phonology of the problem. All permutations should fix t, d, dh, sh, since they have phonological relationships which are relevant to the solution of the problem, and cannot be found in different family of consonants. The guttural consonants can be permuted amongst themselves but not with the other consonants, so form set {q, c, x, }. is treated specially within the solution, but any liquid could fill that role without substantially changing the difficulty of the problem, so we define set {l, r, w, y}. All other consonants featured in the Somali data form set {b, f, g, j, h, k, n, s}. The vowels form another set {a, e, i, o, u}. Problem 218, Stodsde (by Simi Hellsten). This problem involves understanding the formation of causative verbs in Stodsde.4 The solution involves understanding the structure of Stodsde syllable, and the changes that occur in each part of the syllable. No changes occur in the vowel, or consonants after the vowel. The part of syllable before the vowel has the following structure, divided into Slots 1-5. Each slot can only have consonants of certain type, and undergoes specific changes to form the causative. Slot 1 Slot Slot 3 Slot 4 Slot 5 Nasal Non-sib. fricatives Liquid (l or r) Ð if Slot 4 is sibilant otherwise plosive/sibilant fricative affricate, unless Slot 5 is nasal Any non-plosive + non-sib. Finally, everywhere in the verb, v, Ð, f, ì, if the following sound is voiceless. Again, the dataset contains no loanwords or names, so the obfuscation ruleset is fully determined by the relevant phonology. Since voicedness is relevant throughout, but not all voiced/voiceless pairs are given in the data, any permutation must preserve voicedness. We also fix Ð, hence ì. Since we cannot permute , we must fix all of Slot 1. Thus m, n, and are fixed, hence also f. For Slot 2, the remaining non-sibilant fricatives are the voiceless X, which cannot be permuted with anything, and voiced K, G, which can be permuted. In Slot 3, we can freely permute l, r. Slot 4 needs to distinguish between sibilants and sibilant affricates (which are paired), and simple plosives. Considering only those that appear in the Stodsde data, this means we must fix tùh; we can permute p, k, q, and b, d, g, while fixing the aspiration h; and we can permute the pairs (z, dz), (Z, dZ), and the pairs (s, ts), (sh, tsh). Finally, we can permute the vowels, and the remaining nasals N, ñ; has nothing it could permute with, so must also be fixed. The final obfuscation ruleset thus has fixed set {m, n, ì, Ð, X, v, f, tùh, h, j}; sets {K, G}, {l, r}, {p, k, q}, {b, d, g}, {N, ñ}, {u, @, 2, o, a, æ, i}; and tables {(z, dz),(Z, dZ)}, {(s, ts), (sh, tsh)}. D. Prompt Template Below is the prompt used across models. In the no context setting, {context} is removed. 4Stodsde is Gyalrongic language, spoken by approximately 4,000 people in Sichuan, China. 17 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Below is problem sheet from linguistics exam. You will first see the entire sheet, then be asked to respond to specific questions from the sheet. Your answers to the questions should rely only on reasoning about the information provided in the sheet. {question_body} Now respond to the following questions: {preamble} {context} {all_subquestions} {instructions} {formatted_output} {formatted output} tag is populated with an empty dictionary containing the keys of the expected answer for each part of the question. The {instructions} tag is populated based on the setting. For default prompt: Only respond with json output. Do not include anything other than the json in your response. Format your response as json file with the keys as provided below: in chain-of-thought setting, {instructions} is set to: Think step by step about your answer for each part of the question: in closed models when applicable, we precede the prompt with the following generic system message: You are helpful assistant. E. Evaluation Models In our experiments, we fixed prompts and system messages across models whenever possible. For closed models, we followed the recommendations of model providers and set the temperature to 0 whenever possible. For open models, we loaded them in full precision when possible or in 8-bit for larger models. All experiments were conducted using A100 and H100 GPUs for open source models except for Deepseek R1 5 for inference. Model Version Model Type Quantization CohereForAI/aya-23-35B claude-3-5-sonnet-20241022 claude-3-7-sonnet-20250219 deepseek/deepseek-r1 gemini-1.5-pro gpt-4o-2024-05-13 gpt-4.5-preview-2025-02-27 Aya 23 35B Claude 3.5 Sonnet Claude 3.7 Sonnet Deepseek R1 Gemini 1.5 Pro GPT 4o GPT 4.5 Llama 3.2 3B Inst meta-llama/Llama-3.2-3B-Instruct Llama 3.2 1B Inst meta-llama/Llama-3.2-1B-Instruct meta-llama/Llama-3.3-70B-Instruct Llama 3.3 70B o1-preview o1-preview o3-mini-2025-01-31 o3-mini Checkpoint will be shared in published version Open-source Ours 1B Checkpoint will be shared in published version Open-source Ours 3B Open-source microsoft/phi-4 Phi4 Open-source Proprietary Proprietary Open-source Proprietary Proprietary Proprietary Open-source Open-source Open-source Proprietary Proprietary 8-bit 8-bit 8-bit 5https://www.together.ai/models/deepseek-r1 18 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Model Total Empty Response Bad Parsing Aya 23 35B GPT 4o Gemini 1.5 Pro Llama 3.2 1B Inst Llama 3.2 3B Inst Llama 3.3 70BInstruct Ours 1B Ours 3B Phi4 Claude 3.5 Sonnet 27,325 27,325 27,325 27,276 27,325 27,325 27,325 27,325 27,325 27,325 1,602 536 0 10,687 1,022 1,202 3,073 2,809 2,086 7 0 169 56 0 0 0 0 0 0 140 Table 6: Summary of responses on larger benchmark (30 obfuscations). Model Total Empty Response Bad Parsing Aya 23 35B Claude 3.5 Sonnet Claude 3.7 Sonnet Deepseek R1 GPT 4.5 GPT 4o Gemini 1.5 Pro Llama 3.3 70B-Instruct Phi4 o1-preview o3-mini 6,995 6,995 6,995 6,995 6,995 6,995 6,995 6,995 6,995 6,995 6,995 370 8 22 128 0 176 16 316 287 148 38 0 0 0 0 6 0 0 0 0 0 Table 7: Summary of responses on smaller benchmark (6 obfuscations). F. Results for Chain-of-Thought During early iterations, we explored chain-of-thought (CoT) prompting technique as potentially beneficial for improving reasoning abilities in LLMs. However, we find that it performs worse than without CoT on both models that were tested. For models designed for reasoning, we do not explore CoT following recommendations of providers 6. We follow the same evaluation setup as our experiments except using the CoT prompt (Appendix D). Model Obfuscated Exact Match Exact Match (CoT) GPT 4o False True Llama 3.3 70B False True 0.330 0.149 0.128 0.077 0.238 0.114 0.013 0.014 G. Summary of Response Errors Below is summary of responses for all prompts by model. Llama 3.2 1B Inst performed particularly poorly with many responses that did not include json structure. It also resulted in 49 inference errors that were excluded from the analysis with negligible impact on the estimates for the model. H. Full Results 6https://platform.openai.com/docs/guides/reasoning 19 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation 20 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation I. Score Distribution Details Below is the distributions of scores for top performing models on sample of problems across their obfuscated versions. 21 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation J. Tokenisation Experiment J.1. Set-up key question when permuting the graphemes of language without further refining the models is the impact of the tokeniser. We explore this with the Aya 23 35B model by Cohere (Aryabumi et al., 2024), which was designed for multilingual applications (23 languages). The tokeniser of Aya 23 is based on the popular byte-pair encoding algorithm (BPE) (Gage, 1994). Since we report off-the-shelf model performance, we investigate changes in the performance if we alter the tokenisation of the Problemese portion of the prompt. When prompting this model, the Problemese sections are treated separately. In the first experiment, we break down the Problemese into unicode characters (with the NFD standardisation) and obtain separate tokenization for each character that we then concatenate together. In the second experiment, we add dashes in-between the characters of the Problemese to force some separation in the interpretation of multiple characters. The rest of the question is tokenised in the standard way, and the problem context and the Problemese are then concatenated together (in the order that they appear in the question) before being fed into the model. For this experiment we used 10 obfuscations of all problems except Problem 34 (which had long prompts taking up too much memory). We limited the model outputs to four times the length of the correct response length. After cleaning, the number of incorrectly processed responses is 32 questions for the standard tokenisation, 289 questions for the input with dashes, and 292 questions for the single character tokenisation (out of total of 10, 765 questions). This may partially account for the additional drop in the performance of the alternative tokenisations. J.2. Additional Results In Table 8 we see how the average model performance changes under alternative tokenisation for unobfuscated problems. For the unobfuscated case  (Table 8)  , the performance decreased for greater number of the problems than for the obfuscated case  (Table 9)  . This aligns with the greater drop in performance that we observe in Table 2. Prompt type Decreased Unchanged Increased Dash Character 57 58 19 19 5 4 Table 8: Performance change under alternative tokenisation for unobfuscated problems. Score for each problem was averaged over all questions within the problem for the two alternative tokenisation methods (Dash and Character) then compared to the score obtained using standard tokenisation and categorized into Increased, Decreased or Unchanged. Prompt type Decreased Unchanged Increased Dash Character 43 37 25 30 13 Table 9: Performance change under alternative tokenisation for obfuscated problems. For each alternative tokenisation, the score for each problem was averaged over all obfuscations then compared to the score obtained using standard tokenisation and categorized into Increased, Decreased or Unchanged. Finally, we show how the exact match scores vary under alternative tokenisations in Figure 7 by plotting (standard tokenisation score, alternative tokenisation score) for each problem. When the problems are not obfuscated (Figure 7(a) and (c)), the alternative tokenisation more frequently reduced the score to zero, indicating that the tokenisation of the original order may be capturing useful information. For the obfuscated cases (Figure 7(b) and (d)), there appeared to be more spread in the scores differences, and no instances of the catastrophic effect of changing from high exact match score under the standard tokenisation to score of zero. 22 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 7: Problem-level comparison of exact match scores between standard and alternative tokenisation. The dashed line represents the threshold where the score remains unchanged after altering the tokenisation. Point above the dashed line indicate better performance with alternative tokenisation, while points below the line indicate worse performance. (a) The problems are unobfuscated and we compare scores of standard tokenisation against dash tokenisation. (b) The problems are obfuscated and we compare scores of standard tokenisation against dash tokenisation. (c) The problems are unobfuscated and we compare scores of standard tokenisation against character-level tokenisation. (d) The problems are obfuscated and we compare scores of standard tokenisation against character-level tokenisation. Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation K. Human Evaluation Linguistic obfuscation does not change the reasoning steps required to solve the problem, and therefore it serves as method to robustly test reasoning capabilities whilst mitigating memorisation bias. However, obfuscation may change the difficulty level of problem through means other than changing the reasoning process. To measure the effect of obfuscation on problem difficulty, we carried out randomised controlled trial (RCT) with 172 human participants across 6 problems (all relatively easy). After controlling for random differences in problem frequency, obfuscation was found to be associated with 5.80 percentage points lower performance (p-value of 0.059). We speculate that this may be because the resulting character combinations are more unusual in naturally occurring languages, thus the problems are perceived as being harder. K.1. Methodology Experiment Design We used RCT with 172 participants. Each participant was assigned to one of two groups: one group solving unobfuscated problems (86 people) and another solving obfuscated versions (86 people). Participants were then assigned one of six problems and given up to 45 minutes to complete the problem. They were required to spend minimum of 30 minutes on the problem before submitting their answers. Responses were scored using exact match with the answers. All data collection was carried out through Qualtrics survey. Problem Inclusion Criteria and Design We used two criteria to select problems. First, we only considered Breakthrough and Foundation-level problems, designed to be taken by 10-14 year olds. Our intention was to ensure participants had realistic chance of solving the problem, and thus the responses would provide better signal of the effect of obfuscation. Second, we only considered problems where the language was not available through Google Translate, since this would have enabled participants to easily solve the problems. Two exceptions to this rule were Karelian, which is not available on Google Translate but was removed due to high similarity with Finnish, and Ligurian, which is available Google Translate without stress being indicated, which formed the basis of the problem. The selected six problems are below. Language Difficulty level Problem Original author(s) Warlpiri Umbrian Kabyle Tariana Ligurian Amele Breakthrough Breakthrough Breakthrough Foundation Foundation Foundation 207 191 160 210 147 88 Mary Laughren Michael Salter Kazune Sato, Simi Hellsten Babette Verhoeven, Simi Hellsten Kevin Liang Babette Verhoeven Table 10: Problems selected for the randomised controlled trial. All problems are Breakthrough and Foundation-level, designed to be taken by 10-14 year olds. None of these languages are available on Google translate in manner that would aid the solvability of the problem. UKLO problem is the listing of the problem in the UKLO past problems database (United Kingdom Linguistics Olympiad, 2023). Since all six problems and their solutions are easily accessible on the UKLO website, we rewrote elements of each problem. First, we rephrased the problem instructions so that quick internet search did not return the solutions. Second, we changed some of the lexemes in the Problemese such that the linguistic rules required to answer the questions were identical, but the specific words to translate were different. For example, in Kabyle we substituted the verb azzel to run with aker to steal, which follow the same conjugation pattern. All problems were minimally rewritten except from Umbrian, where the known vocabulary originates exclusively from inscriptions on the Iguvine Tablets, and thus is extremely small. Additionally, as in the LLM experiments, all background and cultural information was removed, and the language name was replaced by Language X. For each problem, we randomly sampled two obfuscation types. Participants who were assigned to the obfuscated group were randomly assigned one of the two obfuscated versions. Participant Inclusion Criteria Participants were recruited online using Prolific, crowdworker platform. First, all participants had to be English speaking and monolingual, reducing the risk that they may have had prior exposure to the Problemese language. Second, all participants were required to have minimum education level of an undergraduate degree. This served as proxy for ability and was chosen to ensure participants could reasonably complete the problems. 24 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Figure 8: Distributions of participant scores and self-reported difficulty. Left: Distribution of scores (%) across all six problems and problem types. Scores are highly skewed towards 0. The unobfuscated group had higher mean score. Right: Participant self-reported difficulty. Participants were asked the question On scale from 0 (very easy) to 10 (impossible), how challenging did you find this problem?. Responses are highly skewed towards 10 (impossible). The obfuscated and unobfuscated means are near identical. Despite the symmetric distributions, correlation between score and self-reported difficulty is 0.006. Participants were compensated in line with the UK aged-21 and over minimum wage of 11.44 per hour (experiments conducted January 2025). Additionally, participants received performance bonuses of 2.00 if they scored above 50% but less than 100%, and 6.00 if they scored 100%. The incentive structure was explained to participants before they started the problem. All ICML Publication Ethics protocols were followed and the experiment had prior approval by the research ethics committee at our institution. Further details about ethical approval have been removed from this paper for the peer review process but are available upon request. All participants were required to provide informed consent by signing the form shown in Section K.5. Controlling for Internet and LLM Use To control for the possibility that participants search for the solutions, each question was presented in image form, making it harder to directly copy and paste questions into an internet browser. Additionally, we added post-response trap question asking What do you think the language in the problem (Language X) was?. Given the obscurity of the chosen languages, we assumed correct answer to this question implied that participants had either found the solutions or were using language model, both of which were explicitly prohibited in the instructions. To mark responses to the trap question, we first automatically identified all entries which identified the correct language. Next, two authors with significant language model experience independently identified all responses which qualitatively appeared AI generated. Evidence suggests that people who frequently use state-of-the-art LLMs are good detectors of AI generated text, often outperforming commercial detection software (Russell et al., 2025). These included responses containing common language model phrases, excessively long responses and those demonstrating an unusually impressive knowledge of academic linguistics, such as claiming the Problemese was likely an agglutinative language. Each author independently marked responses, then discussed cases where they disagreed. Since suspected cheating in the trap question does not necessarily imply that the participant cheated in the main problem, these participants were left in the data for the main analysis. Results excluding these participants are reported as robustness check. K.2. Results and Analysis Participants found these problems hard, with mean performance across all problems at 18.85% Overall Performance (mean random guessing is 9.19%). Furthermore, the responses to the question On scale from 0 (very easy) to 10 (impossible), how challenging did you find this problem? reveal that many participants rates the problems near impossible, with 39.5% reporting difficulty of 9 or 10 out of 10. There is no significant difference in the distributions of self-reported difficulty across the participants taking obfuscated and unobfuscated problems. The total distributions of participant scores and self-reported difficulty are reported in Figure 8. Table 11 shows the mean score broken down by problem language and obfuscation type. The mean score for those solving the unobfuscated and obfuscated problems were 21.70% and 16.00%, respectively. Given the skew in the participant scores 25 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation (Figure 8 Left), we primarily used nonparametric tests to assess statistical significant. one-sided Mann-Whitney test to establish whether the distribution of scores under the original problems was greater than the distribution of obfuscated scores, rejects the null hypothesis of equal distributions, with p-value of 0.041. Problem Mean score: Mean score: original obfuscated Change in Random guessing score Warlpiri Umbrian Kabyle Tariana Ligurian Amele 39.88 (n=14) 18.67 (n=15) 27.69 (n=13) 7.14 (n=14) 22.86 (n=15) 15.00 (n=15) 44.64 (n=14) +4.76 11.54 (n=13) 7.13 12.00 (n=15) 15.69 7.14 0.00 (n=14) 24.76 (n=15) +1.90 3.33 (n=15) 11. All 21.70 (n=86) 16.00 (n=86) 5.70 20.83 0.00 5.00 0.00 28.57 0.00 9.19 Table 11: Human performance across original and obfuscated problems. Sample size is in brackets. All scores are out of 100%. Random guessing is the expected score from random answers, given the basic formatting instructions in each question are followed. To control for small perturbations in problem frequency caused by random allocation, we employed linear regression with heteroskedasticity-consistent standard errors to partially control for the skew. Table 11 shows the results, which suggest obfuscation is associated with 5.80 drop in performance (p-value of 0.059). Furthermore, using bootstrapping method with 10, 000 samples, we estimate 95% confidence interval of [11.849, 0.210]. Accounting for Suspected Cheating Our survey contained trap question designed to establish whether participants had discovered the solutions online or used an LLM. Responses to the trap questions were first automatically scored based on whether they correctly identified the Problemese language, then they were evaluated qualitatively by two of this papers authors. The two authors independently identified 15 and 17 responses, 14 of which were common between both lists. After discussion, it was decided that all 18 likely indicated internet or LLM use and should be removed for robustness checks. In addition, participants who had 50% missing data, and those with mean chrF score below 10 (visibly irrelevant answers, e.g. inputting random letters) were also removed. Table 12, Model 2 shows the results excluding these participant groups. The effect on the point estimate and standard error of obfuscation is negligible. Effect when Only Considering those Scoring Above Random Exactly 50% of participants scored below random guessing, highlighting the difficulty of these problems to an inexperienced test taker. For supplementary analysis, we considered whether the effect of obfuscation remained consistent when we only considered those who scored above random and therefore likely understood some of the problem. First, the likelihood of scoring above random depends on the problem type. In the group taking the unobfuscated problems, 57.0% of participants scored above random. In the group taking the obfuscate problems, only 43% scored above random. Furthermore, logistic regression predicting above random performance, suggests obfuscation is significant factor with p-value of 0.045  (Table 13)  . Second, after excluding individuals who scored below random guessing, the data can no longer be treated as the outcomes of an RCT, thus non-stratified tests such as the Mann-Whitney test are no longer appropriate. linear regression controlling for differences in problem frequency suggests that the coefficient on obfuscation is no longer significant in this subset (p-value of 0.196), though the point estimate (5.100) remains similar and this result could be an artifact of the small sample size. Data Availability An anonymised version of the dataset and notebook to generate results are available in the GitHub repository. K.3. External Audit of Problems To verify that the problems selected for the RCT remained solvable when rewritten and obfuscated, we asked two International Linguistics Olympiad (IOL) medallists to audit one set of permutations each. Both auditors were external to this research project and acted independently. Both had prior familiarity with the original UKLO problems. 26 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Intercept Obfuscation Kabyle Ligurian Tariana Umbrian Warlpiri (SE) Model 1 12.065 (3.59) 5.796 (3.07) 10.326 (5.50) 14.643 (5.22) (3.46) 5.595 5.983 (4.46) 33.095 (5.27) (SE) Model 2 12.765 (3.81) 5.805 (3.27) 12.395 (6.09) 17.276 (5.85) (3.88) 5.938 8.018 (5.38) 35.553 (5.15) (SE) Model 3 22.723 (5.63) (3.94) 5.100 12.939 (8.17) 25.745 (6.40) (7.85) 10.610 4.971 (6.56) 29.213 (6.35) Observations R2 Residual Std. Error Statistic 172 0.292 20.010 14.126 (df=6; 165) (df=165) 146 0.326 20.249 16.926 (df=6; 139) (df=139) 86 0.275 19.017 7.239 (df=79) (df=6; 79) Table 12: Linear regressions for participant score under different inclusion criteria. The dependent variable is participant score in all models. The participant inclusion criteria are as follows. Model 1: All participants (n=172). Model 2: Excluding participants who we suspect may have cheated, those who returned more than 50% missing data, and those with mean ChrF score below 10 (n=146). Model 3. Excluding participants who scored below random guessing (n=86). SE: Heteroskedasticity-consistent standard errors. df: Degrees of freedom. < .1; < .05; < .01 Intercept Obfuscation Kabyle Ligurian Tariana Umbrian Warlpiri Model 4 (SE) (0.40) 0.068 0.689 (0.34) (0.52) 0.597 0.139 (0.53) 1.890 (0.70) (0.54) 0.699 1.840 (0.63) Observations Pseudo 172 0.163 Table 13: logistic regression predicting above random guessing score. The dependent variable is binary variable indicating whether participants score was above random. Obfuscated problems are more likely to lead to below random guessing performance with coefficient significant at the 5% level. SE: Heteroskedasticity-consistent standard errors. df: Degrees of freedom. < .1; < .05; < .01 The auditors confirmed that all problems remain solvable via the same reasoning steps and were not significantly harder under the new orthographies. One auditor commented that problems appeared to be marginally harder since the languages appeared more unfamiliar and the other commented that they did not believe it made any difference. Both also mentioned that they personally found the problems harder since they knew the original orthographies and thus found the new versions disorienting, however this is not problem we would expect novice test takers to experience. K.4. Discussion The results suggest that obfuscation causes small but statistically significant drop in performance when taken by inexperienced test takers. This is despite the required reasoning steps and problem solvability remaining unchanged. The point estimate of the effect is 5.80 percentage points: approximately equivalent to half question per problem. If LLMs behave similarly to participants in this study, then we may expect some performance decrease even in cases where the model did not have prior exposure to the original Problemese language. Therefore, performance drops between unobfuscated and obfuscated problems should not be solely attributed to language exposure. However, our estimates for the impact of obfuscation are small; thus we would not expect large changes in performance given robust reasoning skills. We do not have strong evidence for why obfuscation appears to make problems harder. The external audit confirmed that the problems remained solvable via the same reasoning step, thus any changes to the problem difficulty are superficial only. We speculate that obfuscation may cause the orthography to appear less familiar or naturalistic relative to English, giving the perception that the problems are harder to solve, thus causing participants to exert less effort (Scasserra, 2008). 27 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Whilst the mean self-reported difficulty level is marginally higher in the obfuscated group (7.39 versus 7.48, Figure 8), the distributions are not significantly different under Mann-Whitney test. However, we do find that participants solving obfuscated problems spent less time on the problem before submitting their answers (p = 0.071 under one-sided Mann Whitey test), which would support this hypothesis. Alternatively, knowledge of English alone may have been sufficient to score marginally higher in the unobfuscated versions of some problems. In particular, Ligurian and Umbrian are both European languages descending from Latin. In Ligurian, this would have increased the familiarity of the language, e.g. vio:vet:a, violet or pasta, pasta, but would have offered no assistance when solving the reasoning problem. In Umbrian, knowledge of English may have directly helped, especially as the Latin translation were also provided (under the label of Language Y). For example, one question asked for translation of the Language (Latin) words populum and urbs into both Language (Umbrian) and English. Knowledge of the English words population and urban may have helped the participants locate the correct translations, community and town, from the text provided. While this may have offered marginal assistance in unobfuscated problems, the overall results are largely unchanged when Umbrian is excluded. Limitations These results are subject to several limitations. First, participants generally found these problems extremely challenging with only 50% of participants scoring above random. The significance of the results is partially driven by differences in scoring below random and it is unclear whether they would hold under different distributions of scores. As with all human evaluations, the results are highly specific to our demographic of participants (inexperienced test takers) and may not generalise outside of this. Second, we specifically chose relatively easy problems so that participants had realistic chance of solving them. As result, these results may not be indicative of the effect of obfuscation across the full distribution of problems. Third, despite our best efforts to prevent and identify cheating, there is risk these results are driven by the availability of online materials. This is problem with any form of online and unproctored assessment, which future studies might wish to address through in-person test taking. K.5. Informed Consent All participants were required to consent to participation in the study by signing the form below. Information breaking the anonymity of peer review has been redacted. Informed consent You are being invited to take part in research project led by [REDACTED]. Before you decide whether to participate, it is important for you to understand why the research is being done and what it will involve. [REDACTED] supports the practice of protecting human participants in research. Please take time to read the following information carefully and discuss it with others if you wish. We appreciate your interest in participating in this online task. What is this study? This research aims to measure how well people can solve linguistic reasoning problems. linguistic reasoning problem is set of questions that requires problem-takers to study new language that they have likely never seen before. The aim of the problem is to use example translations between English and the second language to decipher how this language works. You will then have to apply your deciphered knowledge to translate new words and phrases. In this research study, the second language may be written in non-standard way. At the start of the survey, you will be provided with further details about the specific problem. These details contain all information required to solve the task and no background knowledge of languages other than English is required. When you start the survey, you will be given some basic instructions, then will click through to the main problem. You will have up to 45:00 minutes to solve the question and write down your answers. There is countdown on the page which shows time remaining. After completing the problem, there is series of follow-up questions about your experience that will take around 3 minutes to complete. We will collect your responses to the reasoning problem and follow-up questions. How will be compensated? 28 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Compensation for this task is 7.63. In addition to the base compensation, this study has bonus system based on performance. Scoring 50% or higher will result in 2.00 bonus (9.63 total wage). Scoring 100% will result in 6.00 bonus (13.63 total wage). Please note that bonus payments will not be made automatically and may take up to week to reach your Prolific account. Further information and FAQs. You have been invited to participate as you are over the age of 18. Please read through this information before agreeing to participate (if you wish to). You may ask any questions before deciding to take part by contacting the researcher (details below). The research contact is [REDACTED], who is [REDACTED]. This project is being completed under the supervision of [REDACTED]. Do have to take part? No. Please note that participation is voluntary. If you do decide to take part, you may withdraw at any point for any reason before submitting your answers by pressing the Exit button or closing the browser. How will my data be used? We will not collect any data that could directly identify you. Your IP address will not be stored. We will take all reasonable measures to ensure that data remains confidential. The responses you provide will be stored in password-protected electronic file on [REDACTED]s secure servers and may be used in academic publications, conference presentations, reports or websites. Research data with Prolific IDs will be stored internally for three years after publication or public release of the work of the research. De-identified research data, without Prolific IDs, may be publicly released and therefore in the public domain. The data that we collect from you may be transferred to, stored and/ or processed at destination outside [REDACTED]. By submitting your personal data, you agree to this transfer, storing or processing. [REDACTED]. Who will have access to my data? [REDACTED] is the data controller with respect to your personal data and, as such, will determine how your personal data is used in the study. [REDACTED] will process your personal data for the purpose of the research outlined above. Research is task that we perform in the public interest. Further information about your rights with respect to your personal data is available from [REDACTED]. The data you provide may be shared with the researchers on this project, [REDACTED], [REDACTED] and any other author involved in the publication of the research. We would also like your permission to use the data in future studies and to share data with other researchers (e.g. in online databases). Data will be de-identified (Prolific IDs removed) before it is shared with other researchers or results are made public. Can withdraw my data? Yes, your data can be withdrawn up until 11:59 PM, 1st May 2025. To withdraw your data please contact [REDACTED] or Prolific. Your participation in this study is entirely voluntary, and you have the right to withdraw at any time before the deadline without penalty or negative consequences. If you choose to withdraw, any data collected from you will be deleted and not included in the final analysis. Who has reviewed this study? This project has been reviewed by, and received ethics clearance through, [REDACTED]. Who do contact if have concern or wish to complain? If you have concern about any aspect of this study, please speak to [REDACTED] or [REDACTED] and we will do our best to answer your query. We will acknowledge your concern within 10 working days and give you an indication of how it will be dealt with. If you remain unhappy or wish to make formal complaint, please contact [REDACTED] who will seek to resolve the matter as soon as possible: 29 Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation [REDACTED] Please note that you may only participate in this survey if you are 18 years of age or older. confirm that: have had the opportunity to ask questions and receive satisfactory answers. understand participation in this study is voluntary. understand that can withdraw my data from the study before 11:59 PM, 1st May 2025 without giving reason or negative consequences. understand who will have access to personal data provided, how the data will be stored and what will happen to the data at the end of the project. understand how to raise concern or make complaint. have read and understood the information on this sheet. consent do not consent"
        }
    ],
    "affiliations": [
        "Asia-Pacific Linguistics Olympiad",
        "Hong Kong Linguistics Olympiad",
        "National University of Science and Technology POLITEHNICA Bucharest, Romania",
        "United Kingdom Linguistics Olympiad",
        "University of Glasgow, Glasgow, United Kingdom",
        "University of Oxford, Oxford, United Kingdom"
    ]
}