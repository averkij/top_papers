{
    "paper_title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation",
    "authors": [
        "Giyeong Oh",
        "Saejin Kim",
        "Woohyun Cho",
        "Sangkyu Lee",
        "Jiwan Chung",
        "Dokyung Song",
        "Youngjae Yu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recently, LoRA and its variants have become the de facto strategy for training and sharing task-specific versions of large pretrained models, thanks to their efficiency and simplicity. However, the issue of copyright protection for LoRA weights, especially through watermark-based techniques, remains underexplored. To address this gap, we propose SEAL (SEcure wAtermarking on LoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a secret, non-trainable matrix between trainable LoRA weights, serving as a passport to claim ownership. SEAL then entangles the passport with the LoRA weights through training, without extra loss for entanglement, and distributes the finetuned weights after hiding the passport. When applying SEAL, we observed no performance degradation across commonsense reasoning, textual/visual instruction tuning, and text-to-image synthesis tasks. We demonstrate that SEAL is robust against a variety of known attacks: removal, obfuscation, and ambiguity attacks."
        },
        {
            "title": "Start",
            "content": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Giyeong Oh 1 Saejin Kim 1 Woohyun Cho 1 Sangkyu Lee 1 Jiwan Chung 1 Dokyung Song 2 Youngjae Yu 1 5 2 0 2 7 1 ] A . [ 2 4 8 2 9 0 . 1 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Recently, LoRA and its variants have become the de facto strategy for training and sharing task-specific versions of large pretrained models, thanks to their efficiency and simplicity. However, the issue of copyright protection for LoRA weights, especially through watermarkbased techniques, remains underexplored. To address this gap, we propose SEAL (SEcure wAtermarking on LoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds secret, non-trainable matrix between trainable LoRA weights, serving as passport to claim ownership. SEAL then entangles the passport with the LoRA weights through training, without extra loss for entanglment, and distributes the finetuned weights after hiding the passport. When applying SEAL, we observed no performance degradation across commonsense reasoning, textual/visual instruction tuning, and text-to-image synthesis tasks. We demonstrate that SEAL is robust against variety of known attacks: removal, obfuscation, and ambiguity attacks. 1. Introduction Recent years have witnessed an increasing demand for protecting deep neural networks (DNNs) as intellectual properties (IPs), mainly due to the significant cost of collecting quality data and training DNNs on it. In response, researchers have proposed various DNN watermarking methods for DNN copyright protection (Uchida et al., 2017; Darvish Rouhani et al., 2019; Zhang et al., 2018; Fan et al., 2019; Zhang et al., 2020; Xu et al., 2024; Lim et al., 2022), which work by secretly embedding identity messages into the DNNs during training. The IP holders can present the identity messages to verifier in the event of copyright dispute to claim ownership. 1Department of Artificial Intelligence, Yonsei University, Seoul, Republic of Korea 2Department of Computer Science and Engineering, Yonsei University, Seoul, Republic of Korea. Correspondence to: Dokyung Song <dokyungs@yonsei.ac.kr>, Youngjae Yu <youngjae4yu@gmail.com>. Figure 1: Overview of SEAL. (1) We begin with LoRAs weights and B, plus non-trainable passports C, Cp. (2) During training, and Cp are inserted between and A, forcing the model to rely on them and thus entangling the weights with the passports. (3) Afterward, is factorized via (C) = (C1, C2) and merged into and A, resulting in standard-looking LoRA weights and A. Meanwhile, Cp remains private for ownership verification. (Ding et al., 2023) recent Parameter Efficient FineTuning Meanwhile, (PEFT) strategies, particularly Low-Rank Adaptation (LoRA) (Hu et al., 2022), have revolutionized how many domain-specific DNNs - especially Large Language Models (LLMs) (AI@Meta, 2024; Jiang et al., 2023; Team et al., 2024; Yang et al., 2024) and Diffusion Models (DMs) (Rombach et al., 2022) - are built and shared. LoRAs efficacy stems from its lightweight adaptation layers, which introduce no additional inference overhead while preserving similar performance to fully fine-tuned models (Zhao et al., 2024; Jang et al., 2024; Mangrulkar et al., 2022). These qualities have led to surge in open-source adaptation, as evidenced by more than 100k publicly shared LoRA weights on platforms such as Hugging Face, Civit AI (Luo et al., 2024). In addition, several variants such as QLoRA (Dettmers et al., 2024), LoRA+ (Hayou et al., 2024), and DoRA (Liu et al., 2024b) have emerged to further optimize resource usage and boost efficient domain adaptation. Due to these factors, LoRAs training framework has been established as the de facto approach in open-source communities for customizing large Preprint version. 1 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation pretrained models to domain-specific tasks. 2. Preliminary Although LoRA-based methods rely on pretrained foundation models, their uniquely trained adaptation weights themselves represent valuable IP that merits protection. Unfortunately, existing white-box DNN watermarking schemes are not suitable for LoRA structure where weights are commonly released in open source, as they only support embedding identity messages in specific architecture-bounded components, such as kernels in convolutional layers (Uchida et al., 2017; Liu et al., 2021; Zhang et al., 2020; Lim et al., 2022). By contrast, some approaches focus on utilizing LoRA to protect the original pretrained weights rather than safeguarding the LoRA itself (Feng et al., 2024), exposing these methods failure to address LoRAs unique properties. To address this gap, we propose SEAL, the universal watermarking scheme designed to protect the copyright of LoRA weights. The key insight of SEAL is the integration of constant matrices, passports, between the LoRA weight, acting as hidden identity message that is difficult to extract, remove, modify, or even counterfeit, thus offering robust IP protection. During fine-tuning, these passports naturally direct gradients through themselves, eliminating the need for additional constraint losses. After fine-tuning, SEAL seamlessly decomposes the passport into two parts, each integrated into the up and down blocks, ensuring the final model is structurally indistinguishable from LoRA weights. We validate our SEAL against an array of attacksremoval (Han et al., 2016), obfuscation (Yan et al., 2023; Pegoraro et al., 2024), and ambiguity (Fan et al., 2019)demonstrating that any attempt to remove or disrupt the passport severely degrades model performance. SEAL imposes no performance degradation on the host task; in many cases, it matches or even surpasses the fidelity of standard LoRA weights across various tasks. In summary, our contributions are three-fold: 1. Simple yet Strong Copyright Protection for LoRA. We present SEAL, the universial watermarking scheme for protecting LoRA weights by embedding hidden identity message using constant matrix, passport, eliminating the need for additional loss terms, offering straightforward yet robust solution. 2. No Performance Degradation. We demonstrate applying SEAL does not degrade the performance of the In practice, SEAL consistently achieves host task. performance comparable to or even exceeding that of standard LoRA. 3. Robustness Against Attacks. We demonstrate SEALs resilience against various attacks, including removal, obfuscation, and ambiguity attacks, maintaining robust IP protection under severe adversarial conditions. 2.1. Low-Rank Adaptation LoRA (Hu et al., 2022) assumes that task-specific updates lie in low-rank subspace of the models parameter space. It freezes the pretrained weights Rba and trains two low-rank matrices Rra and Rbr. After training, the adapted weights are: = + = + BA (1) Because there are no activation functions between and B, one can simply add BA to for efficient integration into the pretrained model. 2.2. White-box DNN Watermarks White-box DNN watermarking techniques can be broadly categorized based on the location of secret embedding or verification: Weight-based. These methods directly embed secret bit sequence (e.g., {+1, 1}) into the model parameters. Verification often entails examining the trained weights to extract or validate the embedded bits (Uchida et al., 2017; Liu et al., 2021; Fernandez et al., 2024). Activation-based. Here, watermarks are embedded in the feature maps of specific layers. By injecting specialized inputs, one can detect the hidden signature from the activations that uniquely respond to the watermark (Darvish Rouhani et al., 2019; Lim et al., 2022). Output-based. These approaches ensure that the final output from the model contains watermark. Even in white-box scenario, the verification is primarily conducted on the models output rather than its internal parameters (Kirchenbauer et al., 2024; Fernandez et al., 2023; Feng et al., 2024). Passport-based. This line of work inserts an additional linear or normalization layer (passport layer) into the model, so that using the correct passport yields normal performance, while invalid passports degrade the accuracy. During ownership verification, the legitimate passport is presented to confirm the models fidelity, effectively distinguishing rightful owners from adversaries (Fan et al., 2019; Zhang et al., 2020). Unlike weight-, activation-, or output-based methods, passport-based watermarking ties model performance to hidden parameters (passports). It does not require special triggers or depend solely on model outputs. Instead, ownership is verified by passport that restores high accuracy, securely linking model weights and the embedded secret. 2 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Algorithm 1 SEAL Training Procedure Input: Pretrained weights , LoRA rank Passports C, Cp Training dataset D, Epochs Output: Public LoRA weights B, Private parameters B, A, C, Cp Initialize Rra, Rbr as trainable parameters. Set C, Cp Rrr as non-trainable passports. for = 1 to do for each batch (x, y) in do Randomly pick or Cp Compute = + BCA or = + BCpA Compute L(W , x, y) Backpropagate end for end for Decompose into C1, C2 where = C1C2 Set = BC1 and = C2A. return B, (Public), and keep B, A, C, Cp (Private) 2.3. Threat Model and Evaluation Criteria Attack Types. Under white-box setting, adversaries are assumed to have full access to the model weights. We idntify three primary attack categories: (1) Removal, where attackers prune unimportant parameters (LeCun et al., 1989; Han et al., 2016; Uchida et al., 2017; Darvish Rouhani et al., 2019), finetune the model without watermark constraints (Chen et al., 2021; Guo et al., 2021). (2) Obfuscation, where attackers restructure the architecture to disrupt watermark extraction (Yan et al., 2023; Pegoraro et al., 2024; Li et al., 2023a), all while preserving model functionality equivalently. (3) Ambiguity, where counterfeit keys or watermarks are forged to deceive verifiers into believing the adversary is the rightful owner (Fan et al., 2019; Zhang et al., 2020; Chen et al., 2023). Adversary Assumptions. We assume the adversary obtains the open-sourced weights but lacks have access to the original finetuning data and is unable to retrain from scratch. Consequently, they aim to preserve the models performance, as excessive degradation would nullify its value. While they know our watermarking scheme (Kerckhoffs principle), the secret key itself remains undisclosed. Evaluation Criteria. robust DNN watermark should satisfy two requirements (Uchida et al., 2017): Fidelity, meaning the watermark does not degrade the models original performance; and Robustness, ensuring the watermark resists removal, obfuscation, and ambiguity attacks. 3 Figure 2: Negative log singular value (CDF), collection of top-32 singular values. LoRA (blue) vs. SEAL (orange) across Llama-2, Mistral, and Gemma models. 3. SEAL: The Watermarking Scheme For clarity, the symbols used throughout this section are listed in Table 6. 3.1. Impact of the Constant Matrix between LoRA In Fig. 2, we compare the distributions of negative log singular values, log(σ), from standard LoRA model , N(B, A), against our proposed SEAL, N(B, A, C), approach on multiple models: Llama-2-7B/13B (Touvron et al., 2023), Mistral-7B-v0.1 (Jiang et al., 2023), and Gemma-2B (Team et al., 2024). For each trained model, we reconstruct the learned weight , collect the top-32 singular values σ from each module, and plot log(σ) in cumulative distribution function (CDF). We observe that the SEAL curves systematically shift to the right compared to LoRA. This shift implies that the learned subspace under SEAL is more evenly spread across multiple singular directions, rather than being dominated by just few large singular values. Such broad coverage in the singular spectrum can bolster robustness: altering or removing the watermark in one direction has limited effect, as the watermark is spread out in multiple directions. Further gradient-based analyses are provided in Appendix B. 3.2. Comparison with Existing Passport Methods Unlike prior passport-based methods (Fan et al., 2019; Zhang et al., 2020) that typically introduce an additional loss term (a regularization or constraint to embed the passport) and keep the passport layer trainable, SEAL employs non-trainable matrix inserted directly into LoRAs block, eliminating the need for auxiliary loss terms. Consequently, our approach differs from existing methods on two key frontsno extra loss and non-trainable passportmaking one-to-one comparison problematic. SEAL: Entangled White-box Watermarks on Low-Rank Adaptation 3.3. Entangling Passports during Training Algorithm 2 SEAL Verification by Extraction SEAL embeds the watermark during training by inserting the non-trainable, constant matrix between the trainable parameters and A. Doing so effectively entangles the given passport with and A. The concept of entanglement is superficially similar to the entanglement proposed by Jia et al. It involves indistinguishable distributions between host and watermarked tasks. In our context, we define entanglement as follows. Definition 3.1 (Entanglement). Given trainable parameters and B, and non-trainable parameter C, and are in entanglement via if and only if they produce the correct output for the host task when is present between them. As despicted Alg. 1, directly influences the computations of and during the forward pass, and modifies the gradient flow in the backward pass, thereby embedding itself through normal training process. The IP holder incorporates both and Cp during training, alternating them according to the batch size. 3.4. Hiding Passport for Distribution After successfully establishing the entanglement between the passport and other trainable parameters, the passport must be hidden before distribution. Therefore, we decompose the passport, C, of the IP holder into two matrices such that their product reconstructs C, as shown in Fig. 1. Definition 3.2 (Decomposition Function). For given constant C, function is decomposition function of where : (cid:55) (C1, C2) such that C1C2 = C. The decomposition function ensures that models trained with SEAL, which contain three matrices per layer, N(B, A, C), can be distributed in form that resembles standard LoRA implementations with only two matrices, N(B, A). In the decomposition process, the IP holder can camouflage the passport within the open-sourced weight by distributing its decomposed components into and A. An example of decomposition using SVD is fsvd(C) = (UC (cid:112) ΣC, (cid:112) ΣCV ), where = UCΣCV fsvd, the resulting component of N(B, A) is . Using SVD decomposition function, = (UC ΣC) and = ( (cid:112) (cid:112) ΣCV ) A. We will use fsvd as the default decomposition function unless otherwise specified. Notably, Cp is not distributed into either or A. 4 Input: Public weights (A, B), Claimant submits (A, B, C) Output: True or False Compute Cext = BBAA. if Cext (statistically) then return True else // Claimant passes return False // Claimant fails extraction end if 3.5. Extraction on Embedded Passport To extract the embedded passport from LoRA converted SEAL weight, N(B, A), we have to assume that and B, which are trained SEAL weights, are full rank matrices. Assumption 3.3 (Rank of trained SEAL weights). Trained SEAL weights and are full rank matrices with r. By Assumption 3.3, and have the pseudo-inverse A, such that AA = Ir, BB = Ir where Ir Rrr is the identity matrix. As shown in Alg. 2, the method for extracting the passport from BA is multiplying A, in the right/left side of BA, respectively. Thus, only the legitimate owner, who has original SEAL weights and A, can extract the concealed passport, C, from N(B, A). 3.6. Passport-based Ownership Verification 3.6.1. EXTRACTION Yan et al. demonstrate that it is possible to neutralize the extraction process of watermarking schemes by altering the distribution of parameters while maintaining functional invariance. Given that the adversary is aware of SEAL and we assume white-box scenario, the adversary could generate the triplet (cid:101)A, (cid:101)B, (cid:101)C for the verifier during the extraction process such that rank( (cid:101)A) = and , (cid:101)B = BA (cid:101)A (cid:101)C In this process, even if (cid:101)C = C, which is the truly distributed passport, the verifier could be confused about who the legitimate owner is. For this reason, extraction should only be used when the legitimate owner is attempting to verify whether their passport is embedded in suspected model. It should not be relied upon in scenarios where third-party verifier is required for contested model, as it is vulnerable in such cases. Therefore, it is crucial to leverage the inherent characteristic of passport-based schemeswhere performance degradation occurs if the correct passport is not presentedallowing third-party verifier to determine the legitimate owner accurately (Fan et al., 2019). SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Algorithm 3 SEAL Verification by Fidelity N(B, A, Ca) = N(B, A, Cb). Define Input: Suspected (B, A); Claimant submits (B, A, Ca, Cb); Threshold ϵT ; Task ; Measurement MT Output: True or False // 1) Check if claimants parameters reconstruct (B, A) if Ca = BA then := (cid:12) (cid:12) MT (N(B, A, Ca)) MT (N(B, A, Cb))(cid:12) (cid:12), (cid:0)MT , ϵT , N(B, A, )(cid:1) = (cid:40) if ϵT , True, False, otherwise. (cid:12) MT (N(B, A, Ca)) MT (N(B, A, Cb))(cid:12) (cid:12) // 2) Evaluate fidelity gap (cid:12) if ϵT then return True // Ownership verified else return False // Passport validation failed In practice, the legitimate owner can submit (B, A, C, Cp), achieving ϵT . Any adversary forging ( (cid:101)C, (cid:101)Cp-adv) lacks the entanglement from training, and fails to keep within the threshold. See Appendix for an extended discussion. end if else return False end if 4. Experiments // Parameters mismatch 4.1. Experimental Setup 4.1.1. FIDELITY 3.6.2. MEASURING FIDELITY Recall that SEAL entails two passports, (C, Cp), both entangled with the LoRA weights (B, A). To gauge how similarly these two passports preserve the models performance, we define fidelity gap: ϵT = (cid:12) (cid:12) (cid:12)MT (cid:0)N(B, A, C)(cid:1) MT (cid:0)N(B, A, Cp)(cid:1)(cid:12) (cid:12) (cid:12), where MT is the task-specific metric for the adaptation layer N(B, A, ) on task . small ϵT indicates that and Cp yield near-identical performance, implying they were jointly entangled during training. By contrast, if two passports are not entangled with (B, A), switching between them would degrade the models accuracy, producing large ϵT . In legitimate setting, the owners (C, Cp) should incur almost no performance difference (ϵT close to zero). An attacker forging second passport, however, cannot maintain the same fidelity gap without retraining the entire LoRA model. Hence, ϵT naturally serves as verification criterion for rightful ownership. Detailed formulation is in Sec. 3.6.3 3.6.3. VERIFICATION The fundamental idea behind passport-based watermarking is that any forged passport significantly degrades the models performance (Fan et al., 2019), resulting in fidelity gap > ϵT . As shown in Alg. 3, the suspected model (B, A) is first checked against the claimants (B, A, Ca) to ensure they reconstruct the same adaptation weights. If so, we measure between Ca and Cb (the two passports) via the task metric MT . Def. 3.4 then concludes that ownership is verified if and only if ϵT : Definition 3.4 (Verification Process). Assume N(B, A) = 5 To demonstrate that the performance of models after embedding SEAL passports does not degrade, we conducted experiments across both language and image modalities. Initially, we evaluate our model by comparing it with various open-source Large Language Models (LLMs) such as LLaMA-2-7B/13B (Touvron et al., 2023), LLaMA-3-8B (AI@Meta, 2024), Gemma-2B (Team et al., 2024), and Mistral-7B-v0.1 (Jiang et al., 2023) on commonsense reasoning tasks. Next, we verify the models effectiveness on instruction tuning tasks. Following this, we extend our approach to the Vision Language Model (VLM) (Liu et al., 2024a) by evaluating the models performance on visual instruction tuning. Finally, we assess SEALs capabilities on image-generative tasks (Rombach et al., 2022). 4.1.2. ROBUSTNESS We evaluated the robustness of SEAL against removal, obfuscation and ambiguity attacks by evaluating fidelity scores in commonsense reasoning tasks. For removal and obfuscation attacks, the presence of the extracted watermark was confirmed through hypothesis testing. For ambiguity attacks, fidelity scores were used to verify genuine versus counterfeit passports, as defined in Def. 3.4. 4.2. Commonsense Reasoning Task Table 1 presents the performance comparison across commonsense reasoning tasks: BoolQ (Clark et al., 2019), PIQA (Bisk et al., 2020), SIQA (Sap et al., 2019), HellaSwag (Zellers et al., 2019), Wino. (Sakaguchi et al., 2021), ARC-e, ARC-c (Clark et al., 2018), and OBQA (Mihaylov et al., 2018). The dataset combines multiple sources, as detailed in (Hu et al., 2023). We train LLMs on 3-epochs on the combined dataset. The experimental results emphasize that SEAL can be seamlessly integrated into existing LoRA architectures, without affecting performance degradation. SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Table 1: Commonsense Reasoning Performance (3-run Avg.). Scores are averaged over three random seeds, with standard deviation shown in smaller font for the last column. SEAL denotes using constant matrix from normal distribution. LLaMA-2-7B LLaMA-2-13B LLaMA-3-8B Gemma-2B Mistral-7B-v0.1 BoolQ PIQA SIQA HellaSwag Wino. ARC-e ARC-c OBQA Avg. Method LoRA 73.75 82.99 79.85 72.70 85.27 81.27 SEAL (Ours) SEAL (Ours) 73.19 86.31 81.95 75.57 86.98 81.39 LoRA SEAL (Ours) 75.34 87.41 83.28 SEAL (Ours) 75.67 88.63 83.21 74.76 88.22 80.96 LoRA SEAL (Ours) 73.88 88.23 82.29 SEAL (Ours) 75.78 90.37 83.25 67.05 83.19 77.26 LoRA SEAL (Ours) 66.56 81.79 77.65 SEAL (Ours) 66.70 82.50 78.88 75.92 90.72 81.78 LoRA SEAL (Ours) 73.08 87.52 81.92 SEAL (Ours) 76.92 90.42 82.51 85.80 81.67 1.03 85.00 82.73 0.14 86.80 83.78 0.27 86.67 84.98 0.17 86.73 85.60 0.34 88.53 86.56 0.10 86.30 85.10 1.39 86.27 85.94 0.29 90.60 88.02 0.11 79.87 78.43 0.32 79.20 77.55 0.04 79.87 78.68 0.11 88.30 87.07 0.27 88.13 84.84 0.44 91.73 87.85 0. 85.06 86.15 85.79 87.07 86.69 88.55 88.53 90.08 88.42 90.68 89.29 91.72 86.08 90.09 88.35 91.67 89.92 93.49 79.74 83.91 79.16 82.79 80.19 83.81 88.69 93.10 87.97 90.19 90.08 93.31 86.14 90.15 91.21 91.82 93.33 93.95 92.00 94.84 96.05 87.07 84.82 87.57 94.68 91.23 94.57 73.63 74.60 75.51 78.78 79.61 81.46 82.41 82.00 84.73 69.34 68.40 69.97 83.36 78.70 83.25 Table 2: Fidelity across various tasks involves Inst. Tune (instruction tuning), MT-B (MT-Bench) and t2i task. Visual Inst. Tune score averages over seven vision-language tasks (see Appendix). CLIP-I and DINO demonstrate subject fidelity scores, while CLIP-T shows prompt fidelity scores. Task Inst. Tune Textual Visual Text-to-Image Metric MT-B Acc. CLIP-T CLIP-I DINO. LoRA SEAL 5.83 5.81 66.9 63.1 0.20 0. 0.80 0.80 0.68 0.67 4.3. Textual Instruction Tuning Table 2 shows the scores for LLaMA-2-7B, instruction tuned with both LoRA and SEAL, using Alpaca dataset (Taori et al., 2023) with 3-epochs. The scores are averaged ratings given by gpt-4-0613 on scale of 1 to 10 for the models responses to questions from MT-Bench (Zheng et al., 2023). Since the Alpaca dataset is optimized for single-turn interactions, the average score for single-turn performance from MT-Bench is used. The results indicate that SEAL achieves performance comparable to LoRA, thereby confirming its fidelity. 4.4. Visual Instruction Tuning Table 2 shows the average performance across seven visual instruction tuning benchmarks (Goyal et al., 2017; Hudson & Manning, 2019; Gurari et al., 2018; Lu et al., 2022; Singh et al., 2019; Li et al., 2023b; Liu et al., 2023) for LoRA and SEAL on LLaVA-1.5 (Liu et al., 2024a) with detailed elaboration in Appendix F.3. As shown in Table 2, the performance of SEAL is comparable to that of LoRA. 4.5. Text-to-Image Synthesis The experimentation with the Stable Diffusion model (Rombach et al., 2022) in conjunction with the dataset of DreamBooth (Ruiz et al., 2023) trained with LoRA elucidates the versatility SEAL when integrated into diverse architectures. Table 2 provides detailed comparison of subject fidelity, CLIP-I (Radford et al., 2021), DINO. (Caron et al., 2021), and prompt fidelity, CLIP-T, using the methods employed in (Nam et al., 2024). Our results confirm that SEAL maintains high fidelity and prompt accuracy without any degradation in model performance. 4.6. Integrating with LoRA Variants Table 3: Average Commonsense Reasoning Performance on Llama-2-7B for LoRA, DoRA, and SEAL. The notation SEAL+DoRA signifies that the SEAL approach has been applied in conjunction with the DoRA variant. Hyperparameter settings are in Appendix F. Method Wall Time (h) Avg. LoRA DoRA SEAL SEAL + DoRA 12.0 18.5 19.6 27.8 81.67 1.03 81.98 0.26 83.78 0.27 81.88 1.08 Thanks to its flexible framework, SEAL can easily be applied to wide variety of LoRA variants. In Table 3, we use DoRA (Liu et al., 2024b) as case study to demonstrate that 6 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Figure 3: Pruning Attack. The x-axis represents the zeroing ratio of the smallest parameters of N(B, A) based on their L1 norms, the left y-axis shows the fidelity score on commonsense reasoning tasks, and the right y-axis displays the log(p-value) on log scale. If log(p-value) is above 3.3 (i.e., p-value < 5 104), detecting the watermark succeeds. The graphs show that as the zeroing ratio increases, the fidelity score decreases. This indicates the watermark remains detectable until 99.9% of the weights are zeroed, which significantly degrades the host tasks performance. SEAL can seamlessly integrate with diverse LoRA-based methods, as exemplified by SEAL+DoRA. jecting the hypothesis implies that the extracted watermark is not random noise but exists within the model. Even without any hyperparameter optimization, SEAL +DoRA matches accuracy of DoRA, highlighting that these variants can coexist with SEAL in single pipeline without interference. Further details on how SEAL applies to other LoRA variants, including matmul-based and other multiplicative approaches (Edalati et al., 2022; Hyeon-Woo et al., 2021), can be found in Appendix and E. Table 4: Finetuning Attack. The detectability of passport on SEAL across either the same or different datasets. Tasks Acc. MT-B p-value C3e I3e 83.1 - I3e C1e 60.2 C3e I1e 0.24 C3e C1e 82.9 I3e I1e - - 5.81 4.94 3.56 - 3.78 - - 1.71 101171 2.81 10178 3.86 103111 9.08 106 4.7. Pruning Attack Pruning attacks were performed on trained SEAL weights by zeroing out N(B, A) based on their L1 norms. And we extract passport, C, on pruned weight. We used statistical testing instead of Bit Error Rate (BER) because, unlike prior work (Uchida et al., 2017; Fernandez et al., 2024; Zhang et al., 2020; Feng et al., 2024) that used small number of bits, 102, the amount of our passport bits is approximately 105, necessitating different approach. In hypothesis testing, if the p-value is smaller than our significance level (α = 0.0005), we reject the null hypothesis, the extracted watermark is an irrelevant matrix with C. Re7 Fig. 3 illustrates the fidelity score and log(p-value) obtained by zeroing the smallest parameters of N(B, A), based on L1 norms. The results demonstrate that removing the watermark necessitates zeroing 99.9% of the weights, which severely impacts the host tasks performance, thereby confirming SEALs robustness against pruning attacks. 4.8. Finetuning Attack In this experiment, we aimed to assess the robustness of SEALs watermark under finetuning attacks. The notation Tne represents task fine-tuned for epochs. Specifically, we resumed training on SEAL weights, N(B, A), that had been trained for 3 epochs on two tasks: commonsense reasoning (C3e) and instruction tuning with Alpaca dataset (Taori et al., 2023) (I3e). The notation T3e 1e represents post-finetuning with the respective dataset for 1 additional epoch using standard LoRA training, where and are the trainable parameters. These finetuning scenarios were designed to simulate an adversarial attack, where the model is fine-tuned either on the original or different dataset, such as finetuning on Alpaca for one epoch ( I1e) or on commonsense reasoning for one epoch ( C1e). After finetuning, we evaluated the robustness of the embedded watermark by extracting it and measuring the p-value. The results demonstrated p-value significantly lower than 5e-4, with = 163840, indicating the passport remains detectable. 4.9. Structural Obfuscation Attack. Structural obfuscation attacks target the structure of DNN models while maintaining their functionality (Yan et al., SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Figure 4: Ambiguity Attacks. Fidelity score, MT (N(A, B, Ct), as average accuracy on Commonsense Reasoning tasks, , with the passport Ct, which is the inference time passport. The x-axis represents the dissimilarity, γ, where Ct = (1 γ)Cp + γ (cid:101)Cp-adv. Cp is the concealed passport, and (cid:101)Cp-adv is the adversary matrix. When γ > 0.6, the difference between fidelity scores significantly drops below the threshold of the verification process, ϵT , as shown in Table 5. Table 5: Fidelity performance, MT , table for each passport on commonsense reasoning task, . Model Ct = Ct = Cp LLaMA-2-7B Mistral-7B-v0.1 Gemma-2B 82.2 84.2 76.3 82.7 87.9 76.6 ϵT 0.5 3.7 0. Figure 5: Structural Obfuscation Attack on SEAL weight of Gemma-2B via SVD. The original rank is 32, and the ranks are obfuscated from 31 down to 1. 2023; Pegoraro et al., 2024). In the case of LoRA, an adversary cannot change the input dimension or the output dimension b, but they can modify the rank of the matrices Rra and Rbr. However, even if is changed, Nobf remains functionally equivalent to N, ensuring the distributed passport remains detectable. To mitigate the effects of structural obfuscation with minimal impact on the host task, we decompose N() using SVD and modify it based on its singular values, sorting by large singular values and discarding the smaller ones, resulting in Nsvd. Fig. 5 shows the results of performing structural obfuscation via SVD. The original rank is 32, and the results are obfuscated from rank 31 down to 1. The fidelity score remains unchanged, and the passport is still detectable, demonstrating SEALs robustness against structural obfuscation attacks. 4.10. Ambiguity Attack In the context of SEAL, ambiguity attacks pose significant threat when an adversary attempts to create counterfeit passports that can bypass the verification process by generating functionally equivalent weights. Even under the worst-case assumption that the adversary successfully separates N(B, A) into N( (cid:101)B, (cid:101)C, (cid:101)A), they must generate another passport, (cid:101)Cp-adv, to form the required quadruplet for the verification by Def. 3.4. Table 5 provides the verification thresholds ϵT . As depicted in Fig. 4, the adversary would need to generate counterfeit passport (cid:101)Cp-adv that is more than 60% similar to Cp to avoid significant drop below ϵT . Given the concealed nature of Cp, achieving this level of similarity is practically impossible, which highlights the effectiveness of our approach in maintaining the security of the ownership verification process. In conclusion, SEAL significantly reduces the risk of ambiguity attacks by ensuring that counterfeit passports generated without knowledge of Cp are unlikely to maintain the required fidelity score. 5. Conclusion We introduced SEAL, novel watermarking scheme specifically tailored for LoRA weights. By inserting constant matrix during LoRA training and factorizing it afterward, our approach enables robust ownership verification without impairing the models performance. Empirical results on commonsense reasoning, instruction tuning, and text-toimage tasks confirm both high fidelity and strong resilience 8 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation against removal, obfuscation, and ambiguity attacks. Although our experiments focus on LoRA, the core ideausing non-trainable matrix to entangle trainable parametersmay extend to other parameter-efficient finetuning (PEFT) methods or larger foundation models. Future work will explore generalized forms of this embedding mechanism, aiming to protect broader range of adaptation techniques while maintaining minimal overhead."
        },
        {
            "title": "Impact Statement",
            "content": "Our scheme helps content creators and organizations safeguard intellectual property in lightweight, easily distributed LoRA-based models. This fosters more open collaboration in AI communities by alleviating concerns about unauthorized use or redistribution of finetuned checkpoints. However, no defense is fully immune to new adversarial strategies, and watermarking could be misused to embed covert or unethical content. We thus advocate for transparent guidelines and continuous evaluation to ensure that watermarking remains fair and dependable approach for protecting intellectual property in open-source AI."
        },
        {
            "title": "References",
            "content": "AI@Meta. Llama 3 model card. URL https://github.com/meta-llama/llama3/ blob/main/MODEL_CARD.md. 2024. Bisk, Y., Zellers, R., Gao, J., Choi, Y., et al. Piqa: Reasoning about physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pp. 74327439, 2020. Caron, M., Touvron, H., Misra, I., Jegou, H., Mairal, J., Bojanowski, P., and Joulin, A. Emerging properties in self-supervised vision transformers. In Proceedings of the International Conference on Computer Vision (ICCV), 2021. Chen, X., Wang, W., Bender, C., Ding, Y., Jia, R., Li, B., and Song, D. Refit: unified watermark removal framework for deep learning systems with limited data. In Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security, ASIA CCS 21, pp. 321335, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450382878. doi: 10.1145/3433210.3453079. URL https://doi. org/10.1145/3433210.3453079. Chen, Y., Tian, J., Chen, X., and Zhou, J. Effective ambiguity attack against passport-based dnn intellectual property protection schemes through fully connected layer substitution. In Proceedings of the IEEE/CVF Conference 9 on Computer Vision and Pattern Recognition, pp. 8123 8132, 2023. Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., and Toutanova, K. Boolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044, 2019. Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018. Darvish Rouhani, B., Chen, H., and Koushanfar, F. Deepsigns: An end-to-end watermarking framework for ownership protection of deep neural networks. In Proceedings of the twenty-fourth international conference on architectural support for programming languages and operating systems, pp. 485497, 2019. Dettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems, 36, 2024. Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., et al. Parameterefficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence, 5(3):220235, 2023. Edalati, A., Tahaei, M., Kobyzev, I., Nia, V. P., Clark, J. J., and Rezagholizadeh, M. Krona: Parameter efficient tuning with kronecker adapter. arXiv preprint arXiv:2212.10650, 2022. Fan, L., Ng, K. W., and Chan, C. S. Rethinking deep neural network ownership verification: Embedding passports to defeat ambiguity attacks. Advances in neural information processing systems, 32, 2019. Feng, W., Zhou, W., He, J., Zhang, J., Wei, T., Li, G., Zhang, T., Zhang, W., and Yu, N. Aqualora: Toward white-box protection for customized stable diffusion models via watermark lora. In Forty-first International Conference on Machine Learning, 2024. Fernandez, P., Couairon, G., Jegou, H., Douze, M., and Furon, T. The stable signature: Rooting watermarks in latent diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 22466 22477, 2023. Fernandez, P., Couairon, G., Furon, T., and Douze, M. FuncIn tional invariants to watermark large transformers. ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 48154819. IEEE, 2024. SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the in vqa matter: Elevating the role of image understanding in visual question answering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 69046913, 2017. Guo, S., Zhang, T., Qiu, H., Zeng, Y., Xiang, T., and Liu, Y. Fine-tuning is not enough: simple yet effective watermark removal attack for dnn models. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2021. Gurari, D., Li, Q., Stangl, A. J., Guo, A., Lin, C., Grauman, K., Luo, J., and Bigham, J. P. Vizwiz grand challenge: Answering visual questions from blind people. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 36083617, 2018. Han, S., Mao, H., and Dally, W. J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. International Conference on Learning Representations, 2016. Hayou, S., Ghosh, N., and Yu, B. Lora+: Efficient low rank adaptation of large models. In Forty-first International Conference on Machine Learning, 2024. Hu, E. J., yelong shen, Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022. URL https: //openreview.net/forum?id=nZeVKeeFYf9. Hu, Z., Wang, L., Lan, Y., Xu, W., Lim, E.-P., Bing, L., Xu, X., Poria, S., and Lee, R. LLM-adapters: An adapter family for parameter-efficient fine-tuning of large language models. In Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 52545276, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main. 319. URL https://aclanthology.org/2023. emnlp-main.319. Hudson, D. A. and Manning, C. D. Gqa: new dataset for real-world visual reasoning and compositional question answering. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 6700 6709, 2019. Hyeon-Woo, N., Ye-Bin, M., and Oh, T.-H. Fedpara: Lowrank hadamard product for communication-efficient federated learning. arXiv preprint arXiv:2108.06098, 2021. Jang, U., Lee, J. D., and Ryu, E. K. Lora training in the ntk regime has no spurious local minima. arXiv preprint arXiv:2402.11867, 2024. Jia, H., Choquette-Choo, C. A., Chandrasekaran, V., and Papernot, N. Entangled watermarks as defense against model extraction. In 30th USENIX security symposium (USENIX Security 21), pp. 19371954, 2021. Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023. Kirchenbauer, J., Geiping, J., Wen, Y., Shu, M., Saifullah, K., Kong, K., Fernando, K., Saha, A., Goldblum, M., and Goldstein, T. On the reliability of watermarks for In The Twelfth International large language models. Conference on Learning Representations, 2024. Kopiczko, D. J., Blankevoort, T., and Asano, Y. M. Vera: Vector-based random matrix adaptation. In The Twelfth International Conference on Learning Representations, 2024. LeCun, Y., Denker, J., and Solla, S. Optimal brain damage. Advances in neural information processing systems, 2, 1989. Li, F.-Q., Wang, S.-L., and Liew, A. W.-C. Linear functionality equivalence attack against deep neural network watermarks and defense method by neuron mapping. IEEE Transactions on Information Forensics and Security, 18:19631977, 2023a. Li, Y., Du, Y., Zhou, K., Wang, J., Zhao, W. X., and Wen, J.-R. Evaluating object hallucination in large visionarXiv preprint arXiv:2305.10355, language models. 2023b. Lim, J. H., Chan, C. S., Ng, K. W., Fan, L., and Yang, Q. Protect, show, attend and tell: Empowering image captioning models with ownership protection. Pattern Recognition, 122:108285, 2022. Liu, H., Weng, Z., and Zhu, Y. Watermarking deep neural networks with greedy residuals. In ICML, pp. 69786988, 2021. Liu, H., Li, C., Wu, Q., and Lee, Y. J. Visual instruction tuning. Advances in neural information processing systems, 36, 2024a. Liu, S.-Y., Wang, C.-Y., Yin, H., Molchanov, P., Wang, Y.-C. F., Cheng, K.-T., and Chen, M.-H. DoRA: Weight-decomposed low-rank adaptation. arXiv preprint arXiv:2402.09353, 2024b. Liu, Y., Duan, H., Zhang, Y., Li, B., Zhang, S., Zhao, W., Yuan, Y., Wang, J., He, C., Liu, Z., et al. Mmbench: Is your multi-modal model an all-around player? arXiv preprint arXiv:2307.06281, 2023. 10 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Loshchilov, I. and Hutter, F. Decoupled weight decay regIn International Conference on Learning ularization. Representations, 2019. Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., and Kalyan, A. Learn to explain: Multimodal reasoning via thought chains for science question answering. Advances in Neural Information Processing Systems, 35:25072521, 2022. Luo, M., Wong, J., Trabucco, B., Huang, Y., Gonzalez, J. E., Chen, Z., Salakhutdinov, R., and Stoica, I. Stylus: Automatic adapter selection for diffusion models. arXiv preprint arXiv:2404.18928, 2024. Mangrulkar, S., Gugger, S., Debut, L., Belkada, Y., Paul, S., and Bossan, B. Peft: State-of-the-art parameterhttps://github. efficient fine-tuning methods. com/huggingface/peft, 2022. Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. Can suit of armor conduct electricity? new dataset for open book question answering. In EMNLP, 2018. Nam, J., Kim, H., Lee, D., Jin, S., Kim, S., and Chang, S. Dreammatcher: Appearance matching self-attention for semantically-consistent text-to-image personalization, 2024. Pegoraro, A., Segna, C., Kumari, K., and Sadeghi, A.-R. Deepeclipse: How to break white-box dnn-watermarking schemes. arXiv preprint arXiv:2403.03590, 2024. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I. Learning transferable visual models from natural language suIn Meila, M. and Zhang, T. (eds.), Propervision. ceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 87488763. PMLR, 1824 Jul 2021. URL https://proceedings.mlr.press/ v139/radford21a.html. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1068410695, June 2022. Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., and Aberman, K. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2250022510, 2023. Sakaguchi, K., Bras, R. L., Bhagavatula, C., and Choi, Y. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM, 64(9):99106, 2021. Sap, M., Rashkin, H., Chen, D., LeBras, R., and Choi, Y. Socialiqa: Commonsense reasoning about social interactions. arXiv preprint arXiv:1904.09728, 2019. Singh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X., Batra, D., Parikh, D., and Rohrbach, M. Towards vqa models that can read. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 83178326, 2019. Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, T. B. Stanford alpaca: An instruction-following llama https://github.com/tatsu-lab/ model. stanford_alpaca, 2023. Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivi`ere, M., Kale, M. S., Love, J., et al. Gemma: Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295, 2024. Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. Llama 2: Open foundation and finetuned chat models. arXiv preprint arXiv:2307.09288, 2023. Uchida, Y., Nagai, Y., Sakazawa, S., and Satoh, S. Embedding watermarks into deep neural networks. In Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, ICMR 17, pp. 269277, New York, NY, USA, 2017. Association for Computing Machinery. ISBN 9781450347013. doi: 10.1145/ 3078971.3078974. URL https://doi.org/10. 1145/3078971.3078974. Xu, H., Xiang, L., Ma, X., Yang, B., and Li, B. Hufu: modality-agnositc watermarking system for pre-trained transformers via permutation equivariance. arXiv preprint arXiv:2403.05842, 2024. Yan, Y., Pan, X., Zhang, M., and Yang, M. Rethinking white-box watermarks on deep learning models under neural structural obfuscation. In 32nd USENIX Security Symposium (USENIX Security 23), pp. 23472364, 2023. Yang, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Li, C., Liu, D., Huang, F., Wei, H., et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115, 2024. Yeh, S.-Y., Hsieh, Y.-G., Gao, Z., Yang, B. B., Oh, G., and Gong, Y. Navigating text-to-image customization: From lycoris fine-tuning to model evaluation. In The Twelfth 11 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation International Conference on Learning Representations, 2023. Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y. Hellaswag: Can machine really finish your sentence? arXiv preprint arXiv:1905.07830, 2019. Zhang, J., Gu, Z., Jang, J., Wu, H., Stoecklin, M. P., Huang, H., and Molloy, I. Protecting intellectual property of deep neural networks with watermarking. In Proceedings of the 2018 on Asia conference on computer and communications security, pp. 159172, 2018. Zhang, J., Chen, D., Liao, J., Zhang, W., Hua, G., and Yu, N. Passport-aware normalization for deep model protection. Advances in Neural Information Processing Systems, 33: 2261922628, 2020. Zhang, L., Zhang, L., Shi, S., Chu, X., and Li, B. Lora-fa: Memory-efficient low-rank adaptation for large language models fine-tuning. arXiv preprint arXiv:2308.03303, 2023a. Zhang, Q., Chen, M., Bukharin, A., He, P., Cheng, Y., Chen, W., and Zhao, T. Adaptive budget allocation for parameter-efficient fine-tuning. In The Eleventh International Conference on Learning Representations, 2023b. Zhao, J., Wang, T., Abid, W., Angus, G., Garg, A., Kinnison, J., Sherstinsky, A., Molino, P., Addair, T., and Rishi, D. Lora land: 310 fine-tuned llms that rival gpt-4, technical report. arXiv preprint arXiv:2405.00732, 2024. Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E. P., Zhang, H., Gonzalez, J. E., and Stoica, I. Judging llm-as-a-judge with mt-bench and chatbot arena, 2023. 12 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation A. Notation Table 6: Notation table for SEAL. Key symbols and their definitions. Symbol Description B, B, W N() C, Cp (cid:101)B, (cid:101)A, (cid:101)C ( (cid:101)Cp-adv) Ct () MT () () ϵT Pretrained model weight (size a) on which LoRA is applied. LoRAs trainable up and down blocks, where Rbr, Rra, and min(b, a). Publicly released LoRA weights after distributing the passport (see Def.3.2). These have the same shape as B, A. The weight offset from LoRA (or SEAL). For instance, = or depending on context. The adaptation layer operator; e.g., N(B, A) for standard LoRA, or N(B, A, C) for SEAL. Non-trainable passports in SEAL. is the main passport hidden into B, A; Cp is an additional passport for ownership verification. Both are in Rrr. An adversarial factorization of publicly released weights (B, A) that an attacker attempts to construct; e.g. (cid:101)B (cid:101)C (cid:101)A = BA. In some scenarios, an attacker may generate (cid:101)Cp-adv to forge an additional passport. These have the same shape as B, A, respectively. runtime passport (e.g., used in inference or verification) for given B, A. Decomposition function that takes and returns two factors (C1, C2) such that C1C2 = C. For example, fsvd uses Singular Value Decomposition (SVD). The host task (e.g., instruction following, QA), to which LoRA (SEAL) is adapted. fidelity score or performance metric (e.g., accuracy) of the adaptation layer on task . The verification process (function) that checks authenticity of passports (Sec. 3.6.3). It outputs True or False. threshold used in the verification stage to decide ownership claims. B. Training Process of SEAL B.1. Forward Path In SEAL, the forward path produces the output by adding learnable offset on top of the base weights : = + = + BCA. (2) Here, and are trainable matrices, while is fixed passport matrix that carries the watermark. Unlike traditional LoRA layers that use = BA alone, SEAL inserts between and A. This additional matrix: Forces the resulting offset to pass through an extra linear transformation, potentially mixing or reorienting the learned directions. Ties the final weight update to the presence of C; removing or altering would disrupt and hence the models functionality. If were diagonal, it would merely scale each dimension independently, which can be easier to isolate or undo. However, when is full (non-diagonal) matrix, the learned offset may exhibit more complex structures, as the multiplication by intermixes channels or dimensions. Such design can lead to more wider singular value distribution (see Fig. 6), where the watermark is spread across multiple directions, thus making it less prone to straightforward removal. B.2. Backward Path The backward path computes gradients of the loss function ϕ with respect to and B, revealing how influences the updates. Let := BCA and Φ := ϕ(x), (3) 13 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Figure 6: KDE of log(σ) for LoRA vs. SEAL. We extract the top-32 singular values σ from each module of the finetuned (for rank=32 N()) and plot log(σ) via kernel density estimate (KDE). where represents applying to some input x. Then, by the chain rule, Φ Φ = (BC)T ϕ = BT ϕ , = ϕ (CA)T = ϕ AT . (4) (5) These expressions highlight two key points: (1) Transformation of Gradients. Each gradient, and B, is multiplied (from the left or right) by . If were diagonal, this would reduce to element-wise scaling of the gradient, which is relatively simple to reverse or interpret. In contrast, full applies more general linear transformationpotentially rotation or mixingto the gradient directions. (2) Entanglement of Learnable Parameters. Because is fixed but non-trivial, both and are continually updated in manner dependent on C. Over many gradient steps, = BCA becomes entangled across multiple dimensions; single-direction modifications in or cannot easily isolate the watermark without affecting other directions. Impact on Singular Values. This interplay of forward and backward paths explains why = BCA often ends up with different singular value spectrum than that of simpler = BA. Intuitively, placing between and introduces: Additional mixing in the forward pass: The matrix product can redistribute any localized pattern in or across more directions. Gradient reorientation in the backward pass: The terms in Eqs. (4)(5) reshape how errors flow back to and A, potentially encouraging them to explore broader subspace. As result, the learned update may exhibit less concentrated singular value distribution, meaning it is not dominated by just few principal components. Instead, it becomes harder to nullify or compress the watermark without causing broader distortion in the model. Practical Advantage. Because is effectively spread across multiple singular directions, any attempt to remove or alter the watermark by targeting handful of directions is likely to degrade performance. Thus, from both the forward and backward perspectives, serves as robust vehicle for embedding the watermark: 1. It cannot be trivially factored out without retraining and (forward path). 2. Its mixing effect on gradients entangles the learned parameters, creating more diffuse subspace in which the watermark resides (backward path). These properties collectively bolster SEALs resistance to watermark removal attacks, while minimally affecting the primary task performance. 14 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation C. On Forging Multiple Passports from Single Factorization This section clarifies why an adversary cannot simply factorize the released LoRA weights (B, A) into some ( (cid:101)B, (cid:101)C, (cid:101)A) and then create an additional passport (cid:101)Cp-adv in order to circumvent our multi-passport verification. We also reiterate that SEAL is intentionally indistinguishable from standard LoRA, so an attacker generally cannot even discern that SEAL was used. C.1. Indistinguishability from Standard LoRA By design, the publicly distributed weights are simply Rbr and Rra, analogous to standard LoRA. No additional matrix parameters (or suspicious metadata) are visible. Hence, without insider knowledge, an attacker cannot tell priori if (B, A) derives from SEAL or conventional LoRA finetuning. This alone imposes significant hurdle: Attacker must first discover (or guess) that SEAL was used. Only then might they attempt forging hidden passports. C.2. Attempting Single Factorization for Two Passports Assume, hypothetically, that an attacker somehow knows given (B, A) came from SEAL. They might try factorization of the form: (B, A) ( (cid:101)B, (cid:101)C, (cid:101)A), so that (cid:101)B (cid:101)C (cid:101)A = BA. Then they could designate (cid:101)C as forged version of the original C. Creating Second Passport. Furthermore, to break multi-passport verification (see Sec. 3.6.3), the attacker would need another passport, (cid:101)Cp-adv, that also yields near-identical fidelity scores: MT (N( (cid:101)B, (cid:101)A, (cid:101)C)) MT (N( (cid:101)B, (cid:101)A, (cid:101)Cp-adv)) (for all relevant data for task, ). However, this requires that (cid:101)B, (cid:101)A be simultaneously entangled with two distinct passports, which is nontrivial for single factorization. C.3. Why Single Factorization Cannot Produce Two Entangled Passports Concurrent Entanglement is Required. In SEAL, and are co-trained (entangled) with both and Cp at the same time during finetuning. This ensures that, for any batch, either or Cp is used, such that B, adapt to both passports. Merely performing post-hoc factorization on (B, A) does not replicate this simultaneous learning process. One Factorization Yields One Mapping. single factorization typically captures one equivalence, e.g. (cid:101)C. Generating an additional (cid:101)Cp-adv that also achieves the same function (or fidelity) using the same (cid:101)B, (cid:101)A is significantly more constrained problem. In practice, an attacker would need to re-finetune ( (cid:101)B, (cid:101)A) twice, once for each passport, effectively mimicking the original trainingbut without knowledge of the original dataset D. Costly and Uncertain Outcome. Even if the attacker invests major computational resources, re-training two passports from scratch is as expensive as (or more expensive than) training brand-new LoRA model. Moreover, success is not guaranteed, since the attacker must ensure (cid:101)Cp-adv = (cid:101)C but still replicates near-identical behavior on the entire dataset, all while not knowing the original dataset or training schedule. C.4. Proof of Non-Existence of Two Distinct Passports from One Factorization Assumptions. We assume the attacker fixes rank-r matrices (cid:101)B Rbr, (cid:101)A Rra with rank( (cid:101)B) = rank( (cid:101)A) = r. This aligns with standard LoRA dimensionality and preserves maximum utility (see Remark C.4 below). 15 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Statement. Suppose the attacker finds two different passports, (cid:101)C = (cid:101)Cp-adv, each in Rrr, satisfying We show this leads to contradiction. (cid:101)B (cid:101)C (cid:101)A = (cid:101)B (cid:101)Cp-adv (cid:101)A = BA. Pseudo-inverse argument (short version). If the attacker specifically uses the pseudoinverse-based approach, (cid:101)C = (cid:101)B (BA) (cid:101)A, (cid:101)Cp-adv = (cid:101)B (BA) (cid:101)A, then clearly (cid:101)C = (cid:101)Cp-adv, contradicting (cid:101)C = (cid:101)Cp-adv. More general linear algebra argument (rank-r). Even without explicitly constructing (cid:101)B or (cid:101)A, one can show: (cid:1) = (cid:101)B (cid:0) (cid:101)C (cid:101)Cp-adv (cid:101)C (cid:101)Cp-adv (cid:101)A = O. (cid:1) (cid:0) Since (cid:101)B, (cid:101)A each have rank r, this forces (cid:101)C (cid:101)Cp-adv = O, implying (cid:101)C = (cid:101)Cp-adv. Hence, no two distinct passports can arise from the same factorization ( (cid:101)B, (cid:101)A). (cid:101)C = (cid:101)Cp-adv = (cid:101)C (cid:101)Cp-adv = O. (Contradiction) (6) If (cid:101)B or (cid:101)A has rank < r, then infinitely many (cid:101)C can satisfy (cid:101)B (cid:101)C (cid:101)A = BA. Remark on rank-deficient factorizations. However, such rank-deficient choices almost always degrade the models fidelity (losing degrees of freedom), thus failing to preserve the same performance as (B, A). Consequently, attackers seeking to maintain full utility have no incentive to choose rank-deficient (cid:101)B, (cid:101)A. Therefore, we assume rank( (cid:101)B) = rank( (cid:101)A) = to ensure that (BA) is matched faithfully. C.5. No Practical Payoff for Such an Attack 1. Attackers Typically Lack Data. To even begin constructing ( (cid:101)C, (cid:101)Cp-adv), attackers must have access to the original training data (or certain proportion of dataset with similar distribution) and be certain SEAL was used. Both are high barriers. Training dataset is not part of SEAL, and is mostly proprietary. It does not violate Kerckhoffs principal. 2. Equivalent to Costly Re-Training. Producing two passports that match all fidelity checks essentially replicates the original multi-passport entanglement from scratch. This yields no distinct advantage over simply training new LoRA. 3. Cannot Disprove Legitimate Ownership. Even if they succeed in forging (cid:101)C, (cid:101)Cp-adv, the legitimate owners original pair (C, Cp) still correctly verifies, preserving the rightful ownership claim. C.6. Conclusion In summary, forging multiple passports from single factorization of (B, A) is infeasible because SEALs multi-passport structure relies on concurrent entanglement of B, with both passports and Cp during training. single post-hoc factorization can at best replicate one equivalent mapping, but not two functionally interchangeable mappings without re-finetuning process that is as expensive and uncertain as building new model. Furthermore, since SEAL weights are indistinguishable from standard LoRA, the attacker generally cannot even detect the scheme in the first place. Therefore, this approach does not offer viable pathway to break or circumvent SEALs multi-passport verification procedure. D. Extensions to Matmul-based LoRA Variants Beyond the canonical LoRA (Hu et al., 2022) formulation, numerous follow-up works propose modifications and enhancements while still employing matrix multiplication (matmul) as the underlying low-rank adaptation operator. In this section, we illustrate how SEAL is compatible or can be adapted to these matmul-based variants. Although we do not exhaustively enumerate every LoRA-derived approach, the general principle remains: if the adaptation primarily uses matrix multiplication (possibly with additional diagonal, scaling, or regularization terms), then SEAL can often be inserted by embedding non-trainable passport between the up and down blocks. 16 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation D.1. LoRA-FA (Zhang et al., 2023a) LoRA-FA (LoRA with frozen down blocks) modifies LoRA by keeping the down block frozen during training, while only the up block is trained. Structurally, however, it does not alter the fundamental matmul operator. Consequently, integrating SEAL follows the same procedure as standard LoRA: one can embed the passport into the product without requiring any special adjustments. The difference in training rules (i.e. freezing A) does not affect how is placed or how it is decomposed into (C1, C2) for final public release. D.2. LoRA+ (Hayou et al., 2024) LoRA+ investigates the training dynamics of LoRAs up (B) and down (A) blocks. In particular, it emphasizes the disparity in gradient magnitudes and proposes using different learning rates: η GA, λ η GB, where λ 1 is scale factor, η is the base learning rate, and GA, GB are the respective gradients. LoRA+ does not alter the structural operator (still matrix multiplication). Therefore, SEAL can be employed by introducing Rrr between and A, yielding = A. The difference in gradient scaling does not impact the usage of non-trainable passport matrix C. D.3. VeRA (Kopiczko et al., 2024) VeRA introduces two diagonal matrices, Λb and Λd, to scale different parts of the low-rank factors: = Λb Λd A, where B, may be random, frozen, shared across layers and the diagonal elements in Λb, Λd are trainable. Despite these diagonal scalings, the core operator remains matrix multiplication. Hence, embedding passport is still feasible. By leveraging the commutative property of diagonal matrices and (assuming commutes with Λd in the sense that one can re-factor into C1ΛdC2 or ΛdC), SEAL can be inserted: which is functionally identical to Λb Λd except for the hidden passport = C1C2. Implementing SEAL in VeRA may require converting the final trained weights back into standard (B, A) form plus diagonal scaling term, but the fundamental principle is straightforward. = Λb (B C1) Λd (C2 A), D.4. AdaLoRA (Zhang et al., 2023b) AdaLoRA applies dynamic rank-allocating approach inspired by SVD. It factorizes the weight update into: = Λ Q, where Λ is diagonal matrix, and P, are regularized to maintain near-orthogonality. Since diagonal matrices commute under multiplication (up to re-factorization), one can embed passport by decomposing it (f (C) (C1, C2)). In essence, = C1 Λ C2 = Λ Q, where = C1 and = C2Q. This preserves the rank-r structure and does not disrupt AdaLoRAs optimization logic. Regularization terms that enforce and QQT remain valid, though one may incorporate C1, C2 into the initialization or adapt them carefully so as not to degrade the orthogonality constraints. D.5. DoRA (Liu et al., 2024b) DoRA modifies the final LoRA update using column-wise norm factor: = c + c (cid:0)W + (cid:1), 17 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation where computes column-wise norms and the ratio is (by design) often detached from gradients to reduce memory overhead. Replacing with in DoRA does not alter the external gradient manipulation logic, since is non-trainable. Thus, c + c remains valid. The presence of does not interfere with DoRAs approach to scaling or norm-based constraints. (cid:0)W + A(cid:1) = D.6. Variants with Non-Multiplicative Operations All of the above variants preserve the core LoRA assumption of matrix multiplication operator for the rank-r adaptation. However, certain approaches introduce non-multiplicative adaptations (e.g., Hadamard product, Kronecker product, or other specialized transforms). In the following section, for these cases, which discuss how SEAL can be generalized to any bilinear or multilinear operator . E. Extensions to Generalized Low-Rank Operators In the main text, we considered standard LoRA (Hu et al., 2022) that uses matrix multiplication operator: = A, where Rbr, Rrr, and Rra. Recent work has explored alternative low-rank adaptation mechanisms beyond simple matmul, such as Kronecker product-based methods (Edalati et al., 2022; Yeh et al., 2023) or even elementwise (Hadamard) product (Hyeon-Woo et al., 2021) forms. Our approach can be extended in straightforward manner to these generalized operators, which we denote as . E.1. General Operator Let be any bilinear or multilinear operator used for low-rank adaptation.1 We can then write the trainable adaptation layer as = A, where B, are the trainable low-rank parameters, and is the non-trainable passport in SEAL. During training, and are optimized in conjunction with held fixed (just as in the matrix multiplication case). Decomposition Function for Operator . To distribute into (B, A) after training, we require decomposition function : (cid:55) (C1, C2) such that = C1 C2. For example, under the Kronecker product , one could define (C) to split into smaller block partitions, or use an SVD-like factorization in an appropriate transformed space. Under the Hadamard product, (C) could involve elementwise roots or other transformations. Once C1 and C2 are obtained, we apply: = C1 , = C2 A, so that A = (B C1) (C2 A) = (C1 C2) = A. Hence, the final distributed weights (B, A) for public remain functionally equivalent to using B, A, C. E.2. Implications and Future Directions Broader Applicability. By permitting to be any bilinear or multilinear operator (Kronecker, Hadamard, etc.), SEAL naturally extends beyond the canonical matrix multiplication used in most LoRA implementations. This flexibility can be valuable for advanced parameter-efficient tuning methods (Edalati et al., 2022; Hyeon-Woo et al., 2021; Yeh et al., 2023). 1Here, bilinear means (X ) is linear in both and when one is held fixed, e.g. standard matrix multiplication, Kronecker product, or Hadamard product. 18 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Table 7: Hyperparameter configurations of SEAL and LoRA for Gemma-2B, Mistral-7B-v0.1, LLaMA2-7B/13B, and LLaMA3-8B on the commonsense reasoning. All experiments are done with 4x A100 80GB (for LLaMA-2-13B) and 4x RTX 3090 (for the other models) with approximately 15 hours."
        },
        {
            "title": "Models",
            "content": "Gemma-2B Mistral-7B-v0.1 LLaMA-2-7B LLaMA-2-13B LLaMA-3-8B"
        },
        {
            "title": "Method\nr\nalpha\nDropout\nLR\nOptimizer\nLR scheduler\nWeight Decay\nWarmup Steps\nTotal Batch size\nEpoch\nTarget Modules",
            "content": "LoRA SEAL LoRA SEAL LoRA SEAL LoRA SEAL LoRA SEAL 32 32 0.05 2e-4 2e-5 2e-5 2e-5 2e2e-5 2e-4 2e-5 2e-4 2e-5 AdamW (Loshchilov & Hutter, 2019) Linear 0 100 16 3 Query Key Value UpProj DownProj Same Security Guarantees. The central watermarking principle (embedding non-trainable passport into the adaptation) does not change. An adversary attempting to re-factor A to recover faces the same challenges described in the main text and Appendix Cnon-identifiability, cost of reconstruction, and multi-passport verification barriers. Potential Operator-Specific Designs. Certain operators (e.g., Kronecker product) may admit additional constraints or factorization strategies that could be exploited for improved stealth or efficiency. Investigating these is an interesting direction for future work. In summary, SEAL can be generalized to other operators by treating as non-trainable factor and defining suitable decomposition function (C) such that = C1 C2. This allows us to hide the passport just as in the matrix multiplication case, thereby preserving the main SEAL pipeline for more complex LoRA variants. F. Training Details F.1. Commonsense Reasoning Tasks We conduct evaluations on commonsense reasoning tasks using eight distinct sub-tasks: Boolean Questions (BoolQ) (Clark et al., 2019), Physical Interaction QA (PIQA) (Bisk et al., 2020), Social Interaction QA (SIQA) (Sap et al., 2019), Narrative Completion (HellaSwag) (Zellers et al., 2019), Winograd Schema Challenge (Wino) (Sakaguchi et al., 2021), ARC Easy (ARC-e), ARC Challenge (ARC-c) (Clark et al., 2018), and Open Book QA (OBQA) (Mihaylov et al., 2018). We benchmark SEAL and LoRA against LLaMA-2-7B/13B (Touvron et al., 2023), LLaMA-3-8B (AI@Meta, 2024), Gemma-2B (Team et al., 2024), and Mistral-7B-v0.1 (Jiang et al., 2023) across these commonsense reasoning tasks. The hyperparameters used for these evaluations are listed in Table 14. F.2. Textual Instruction Tuning We conducted textual instruction tuning using Alpaca dataset (Taori et al., 2023) on LLaMA-2-7B (Touvron et al., 2023), trained for 3 epochs. The hyperparameters used for this process are detailed in Table 8. F.3. Viusal Instruction Tuning We compared the fidelity of SEAL, LoRA, and FT on the visual instruction tuning tasks with LLaVA-1.5-7B (Liu et al., 2024a). To ensure fair comparison, we used the same original model provided by (Liu et al., 2024a) uses the same configuration as the LoRA setup with the same training dataset. We adhere to (Liu et al., 2024a) setting to filter the training 19 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Table 8: Hyperparameter configurations of SEAL and LoRA for Instruction Tuning. All experiments are done with 1x A100 80GB for approximately 2 hours. All w/o LM HEAD are Query, Key, Value, Out, UpProj, DownProj, GateProj."
        },
        {
            "title": "Model",
            "content": "LLaMA-2-7B"
        },
        {
            "title": "SEAL",
            "content": "Method alpha Dropout LR LR scheduler Optimizer Weight Decay Total Batch size Epoch Target Modules All w/o LM HEAD 32 32 0.0 2e-5 Cosine AdamW 0 8 3 Table 9: Performance comparison of different methods across seven visual instruction tuning benchmarks Method # Params (%) VQAv2 GQA VisWiz SQA VQAT POPE MMBench Avg FT LoRA SEAL 100 4.61 4.61 78.5 79.1 75.4 61.9 62.9 58.3 50.0 47.8 41.6 66.8 68.4 66. 58.2 58.2 52.9 85.9 86.4 86.0 64.3 66.1 60.5 66.5 66.9 63.1 Table 10: Hyperparameters for visual instruction tuning. All experiments were performed with 4x A100 80GB with approximately 24 hours Model Method alpha LR LR scheduler Optimizer Weight Decay Warmup Ratio Total Batch size LLaVA-1.5-7B LoRA SEAL 128 128 2e-4 2e-5 Linear AdamW 0 0.03 data and design the tuning prompt format. The finetuned models are subsequently assessed on seven vision-language benchmarks: VQAv2(Goyal et al., 2017), GQA(Hudson & Manning, 2019), VisWiz(Gurari et al., 2018), SQA(Lu et al., 2022), VQAT(Singh et al., 2019), POPE(Li et al., 2023b), and MMBench(Liu et al., 2023). F.4. Text-to-Image Synthesis The DreamBooth dataset (Ruiz et al., 2023) encompasses 30 distinct subjects from 15 different classes, featuring diverse array of unique objects and live subjects, including items such as backpacks and vases, as well as pets like cats and dogs. Each of the subjects contains 4-6 images. These subjects are categorized into two primary groups: inanimate objects and live subjects/pets. Of the 30 subjects, 21 are dedicated to objects, while the remaining 9 represent live subjects/pets. For subject fidelity, following (Ruiz et al., 2023), we use CLIP-I, DINO. CLIP-I, an image-text similarity metric, compares the CLIP (Radford et al., 2021) visual features of the generated images with those of the same subject images. DINO (Caron et al., 2021), trained in self-supervised manner to distinguish different images, is suitable for comparing the 20 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Table 11: DreamBooth text prompts used for evaluation of inanimate objects and live subjects. Prompts for Non-Live Objects {} in the jungle {} in the snow {} on the beach {} on cobblestone street {} on top of pink fabric {} on top of wooden floor {} with city in the background {} with mountain in the background {} with blue house in the background {} on top of purple rug in forest {} with wheat field in the background {} with tree and autumn leaves in the background {} with the Eiffel Tower in the background {} floating on top of water {} floating in an ocean of milk {} on top of green grass with sunflowers around it {} on top of mirror {} on top of the sidewalk in crowded street {} on top of dirt road {} on top of white rug red {} purple {} shiny {} wet {} cube shaped {} Prompts for Live Subjects {} in the jungle {} in the snow {} on the beach {} on cobblestone street {} on top of pink fabric {} on top of wooden floor {} with city in the background {} with mountain in the background {} with blue house in the background {} on top of purple rug in forest {} wearing red hat {} wearing santa hat {} wearing rainbow scarf {} wearing black top hat and monocle {} in chef outfit {} in firefighter outfit {} in police outfit {} wearing pink glasses {} wearing yellow shirt {} in purple wizard outfit red {} purple {} shiny {} wet {} cube shaped {} visual attributes of the same object generated by models trained with different methods. For prompt fidelity, the image-text similarity metric CLIP-T compares the CLIP features of the generated images and the corresponding text prompts without placeholders, as mentioned in (Ruiz et al., 2023; Nam et al., 2024). For the evaluation, we generated four images for each of the 30 subjects and 25 prompts, resulting in total of 3,000 images. The prompts used for this evaluation are identical to those originally used in (Ruiz et al., 2023) to ensure consistency and comparability across models. These prompts are designed to evaluate subject fidelity and prompt fidelity across diverse scenarios, as detailed in Table 11 Fig. 7 visually compares LoRA and SEAL on representative subjects from the DreamBooth dataset. The top row shows example reference images for each subject, the middle row shows images generated by LoRA, and the bottom row shows images from our SEAL. Qualitatively, both methods faithfully capture key attributes of each subject (e.g., shape, color, general pose) and produce images of comparable visual quality. That is, SEAL does not degrade or alter the original subjects appearance relative to LoRA, suggesting that incorporating the constant matrix does not introduce noticeable artifacts or reduce fidelity. These results align with the quantitative metrics on subject and prompt fidelity, indicating that SEAL maintains quality level on par with LoRA while embedding watermark in the learned parameters. SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Figure 7: Comparison of LoRA and SEAL in Text-to-Image Synthesis Table 12: Hyperparameter configurations of SEAL and LoRA for Text-to-Image Synthesis. All experiments are done with 4x RTX 4090 with approximately 15 minutes per subject. Model Stable Diffusion 1.5 Method alpha Dropout LR LR scheduler Optimizer Weight Decay Total Batch size Steps Target Modules LoRA SEAL 32 32 0.0 5e-5 1e-5 Constant AdamW 1e-2 32 300 Out AddK AddV Table 13: Hyperparameter configurations of Finetruning Attack on SEAL which trains on 3-epoch. We resume training on N(B, A), which passport is distributed in B, via fsvd. Model LLaMA-2-7B Method alpha LR Optimizer LR scheduler Weight Decay Warmup Steps Batch size Epoch Target Modules Query Key Value UpProj DownProj LoRA 32 32 2e-5 AdamW Linear 0 100 16 1 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Table 14: Hyperparameter configurations of Integrating with DoRA. Model Method alpha Dropout LR Optimizer LR scheduler Weight Decay Warmup Steps Total Batch size Epoch Target Modules LLaMA-2-7B 2e2e-4 LoRA SEAL DoRA SEAL+DoRA 32 32 0.05 2e-4 AdamW Linear 0 100 16 3 Query Key Value UpProj DownProj 2e-5 23 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Figure 8: Passport Example. Left: 3232 grayscale bitmap (cropped and downsampled from YouTube clip2) serves as our non-trainable passport C. Right: The passport partially recovered (from 10% zeroed SEAL weight on LLaMA-2-7B). G. Ablation Study G.1. Passport Example In order to provide concrete illustration of our watermark extraction process, we construct small 3232 grayscale image as the passport (or Cp). Specifically, we sampled 100 frames from publicly available YouTube clip, applied center-cropping on each frame, converted them to grayscale, and then downsampled to 3232. From these frames, we selected one representative image (shown in Fig. 8) to embed as the non-trainable matrix in our SEAL pipeline Sec. 3.3. This tiny passport image, while derived from movie clip, is both unrecognizable at 3232 and used exclusively for educational, non-commercial purposes. Nevertheless, it visually demonstrates how low-resolution bitmap can be incorporated into the models parameter space and later extracted (possibly with minor distortions) to verify ownership. G.2. Rank Ablation To evaluate versatility of the proposed SEAL method under varying configurations, we conducted additional experiments focusing on different rank settings (4, 8, 16). The results are summarized in Table 15. We used the Gemma-2B model (Team et al., 2024) on commonsense reasoning tasks, as described previously. For comparison, we included the results of LoRA with = 32 and SEAL with = 32 as mentioned in Table 2. Table 15: Accuracy across various rank settings on commonsense reasoning tasks. The table includes results for rank configurations (4, 8, 16) of SEAL, as well as LoRA r=32 and SEAL r=32. Rank BoolQ PIQA SIQA HellaSwag Wino. ARC-c ARC-e OBQA Avg. 4 8 16 32 65.05 64.83 66.24 66.45 78.18 81.23 82.32 82. 75.64 77.02 77.94 78.20 LoRAr=32 65.96 78.62 75.23 76.16 83.92 86.10 83. 79.20 73.56 77.35 79.24 79.95 76.64 65.02 68.43 67.32 68.09 79.13 81.65 83.00 83.12 82. 62.80 74.80 79.20 78.60 79.40 73.76 76.87 77.61 77.57 72.40 73.75 G.3. Impact of the Size of Passport To analyze how the magnitude of the passport influences the final output, we train the model with = A, but at inference time remove (i.e., N(B, A, )) to observe the resulting images under different standard deviations std of C. Specifically, we sample (0, std2) with std {0.01, 0.1, 1.0, 10.0, 100.0} and keep and trainable. Fig. 9 shows that lower std (e.g., 0.01) produces markedly different images relative to the vanilla model without C, while higher std (e.g., 10.0 or 100.0) yields outputs closer to the vanilla Stable Diffusion model3. 2https://www.youtube.com/watch?v=2zHHkSu1br4 3https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5. The original weight had been taken down. 24 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation Why does std of affect N(B, A, )? Recall that = A. If std(C) is very small (e.g., 0.01), then during training, the product must still approximate the desired update . Because is tiny, and tend to have relatively large values to compensate. Consequently, when we remove at inference time (use N(B, A, )), these enlarged and inject strong perturbations, manifesting visually as high-frequency artifacts. Conversely, if std(C) is very large (e.g., 10.0 or 100.0), then to avoid destabilizing training, and remain smaller in scale. Hence, removing at inference, N(B, A, ), introduces only minor differences from the original model, leading to outputs that closely resemble the vanilla Stable Diffusion model. Figure 9: Effect of passport standard deviation (std) on SEAL weight. std = σ: Outputs are using only SEAL weight without (0, σ2), N(B, A, ). Vanilla SD 1.5: output from vanila Stable Diffusion 1.5 with same prompt. Quantitative Comparison. In addition to the qualitative results, Table 16 compares Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM) between images generated using only trained SEAL weights without C, N(B, A, ), at various passport std values. Lower std (e.g., 0.01) shows significantly lower PSNR and SSIM, indicating large deviations (i.e., stronger perturbations) from the vanilla output. As std increases to 10.0 or 100.0, the outputs become more aligned with the vanilla model, reflected by higher PSNR/SSIM scores. Table 16: Comparision of PSNR and SSIM values for images generated without (0, σ2), using only N(B, A, ), under varying standard deviations of the passport C, with images generated under vanilla SD 1.5 model. Obj. 1: Cat, Object 2: Backpack dog, Obj. 3: Ducky toy. Object names are same as (Ruiz et al., 2023) Ref. Metric Obj.1 Obj.2 Obj.3 SSIM PSNR SSIM PSNR SSIM PSNR 0.01 0.104 7.80 0.102 7.91 0.115 8.08 Standard Deviation of 10.0 1.0 0. 0.936 30.87 0.941 33.15 0.959 32.92 0.987 43.64 0.993 47.24 0.992 45. 0.691 19.02 0.652 18.51 0.651 18.39 25 100.0 0.998 53. 0.998 54.21 0.998 53.58 SEAL: Entangled White-box Watermarks on Low-Rank Adaptation H. Extending to Multiple Passports and Data-based Mappings So far, our main exposition has treated the watermark matrices and Cp, constant passports. However, SEAL naturally extends to setting in which one maintains multiple passports {C1, C2, . . . , Cm} (similarly {D1, D2, . . . Dn), each possibly tied to distinct portion of the training set, or to distinct sub-task within the same model. Formally, suppose that during mini-batch updates Alg. 1 randomly picks one passport Ci associated with (x, y). Then line 10 of Alg. 1 becomes: pick Ci s.t. (x, y) (cid:55) Ci, + Ci A. One can store simple mapping function ϕ : (x, y) (cid:55) {1, . . . , m} to tie each batch to its specific passport. Distributed or Output-based Scenarios. Another angle is to use multiple passports not only at training time but also during inference. For instance, given family {C1, . . . , Cm}, one could selectively load Ci to induce different behaviors or tasks in an otherwise single LoRA model. In principle, if each Ci is entangled with (B, A), switching passports at inference changes the effective subspace. This may be viewed as distributed watermark approach: where each Ci can be interpreted as unique key that enables (or modifies) certain model capabilities, separate from the main training objective. Though we do not explore this direction in detail here, it points to broader usage possibilities beyond simply verifying ownership, such as controlled multi-task inferences and individually licensed feature sets."
        }
    ],
    "affiliations": [
        "Department of Artificial Intelligence, Yonsei University, Seoul, Republic of Korea",
        "Department of Computer Science and Engineering, Yonsei University, Seoul, Republic of Korea"
    ]
}