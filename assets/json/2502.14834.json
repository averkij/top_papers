{
    "paper_title": "LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models",
    "authors": [
        "Shangqing Tu",
        "Yucheng Wang",
        "Daniel Zhang-Li",
        "Yushi Bai",
        "Jifan Yu",
        "Yuhao Wu",
        "Lei Hou",
        "Huiqin Liu",
        "Zhiyuan Liu",
        "Bin Xu",
        "Juanzi Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Existing Large Vision-Language Models (LVLMs) can process inputs with context lengths up to 128k visual and text tokens, yet they struggle to generate coherent outputs beyond 1,000 words. We find that the primary limitation is the absence of long output examples during supervised fine-tuning (SFT). To tackle this issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158 examples, each with multiple input images, an instruction, and corresponding outputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that maintain high-fidelity to the input images, we employ Direct Preference Optimization (DPO) to the SFT model. Given the high cost of collecting human feedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which breaks long outputs into segments and uses iterative corrections to form preference pairs with the original outputs. Additionally, we develop MMLongBench-Write, a benchmark featuring six tasks to evaluate the long-generation capabilities of VLMs. Our 7B parameter model, trained with LongWriter-V-22k and IterDPO, achieves impressive performance on this benchmark, outperforming larger proprietary models like GPT-4o. Code and data: https://github.com/THU-KEG/LongWriter-V"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 0 2 ] . [ 1 4 3 8 4 1 . 2 0 5 2 : r LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models Shangqing Tu1,Yucheng Wang1, Daniel Zhang-Li1, Yushi Bai1, Jifan Yu1, Yuhao Wu2, Lei Hou1, Hui-Qin Liu1, Zhiyuan Liu1, Bin Xu1, Juanzi Li1 1Tsinghua University, 2Singapore University of Technology and Design https://github.com/THU-KEG/LongWriter-V"
        },
        {
            "title": "Abstract",
            "content": "Existing Large Vision-Language Models (LVLMs) can process inputs with context lengths up to 128k visual and text tokens, yet they struggle to generate coherent outputs beyond 1,000 words. We find that the primary limitation is the absence of long output examples during supervised fine-tuning (SFT). To tackle this issue, we introduce LongWriter-V22k, SFT dataset comprising 22,158 examples, each with multiple input images, an instruction, and corresponding outputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that maintain high-fidelity to the input images, we employ Direct Preference Optimization (DPO) to the SFT model. Given the high cost of collecting human feedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which breaks long outputs into segments and uses iterative corrections to form preference pairs with the original outputs. Additionally, we develop MMLongBench-Write, benchmark featuring six tasks to evaluate the long-generation capabilities of VLMs. Our 7B parameter model, trained with LongWriter-V22k and IterDPO, achieves impressive performance on this benchmark, outperforming larger proprietary models like GPT-4o."
        },
        {
            "title": "Introduction",
            "content": "Recent advancements in Large Vision-Language Models (LVLMs) have significantly enhanced their capabilities in processing visual and textual inputs (Alayrac et al., 2022; Zhang et al., 2024). Notably, there have been substantial breakthroughs in the long-context capabilities of VLMs (Xue et al., 2024; Shu et al., 2024). For instance, Qwen2VL (Wang et al., 2024a) can now understand videos up to 20 minutes, with context window of 32k tokens. This progress has significantly expanded the scope of tasks that VLMs can handle, making them more applicable to real-world scenarios. *Equal contribution. 1 However, despite the increased input context window, the effective output length of VLMs remains limited. To verify this limitation, we collect benchmark comprising six tasks that require VLMs to generate long texts based on visual inputs (as shown in Figure 1). By adjusting the required output length in the instructions, we found that all existing models struggle to generate outputs exceeding 1,000 words (Section 2). In real-world scenarios, such long-output queries are common user demands (Chou et al., 2024). For example, (1) creative writing tasks may require generating detailed stories or essays based on visual prompts (Hong et al., 2023), and (2) professional writing tasks may involve writing comprehensive reports or analyses from visual data (Hartsock and Rasool, 2024). To meet these practical needs, it is essential to enhance the long-output capabilities of VLMs. To investigate the reasons behind the limited long-output capability of VLMs, we are inspired by the LongWriter (Bai et al., 2024), which adjusts the output length distribution of the supervised finetuning (SFT) data to observe changes in model output length. Our experiments revealed that the proportion of long-output examples in the SFT data determines the models output length. This finding explains why VLMs typically have an output length limit of around 1,000 words. Existing visual instruction tuning datasets (Schuhmann et al., 2022), such as LLaVA (Liu et al., 2024a), mainly contain tasks like grounding (Liu et al., 2024b) and caption generation (Wang et al., 2022), with most outputs being less than 300 words (Lin et al., 2014). To fill the gap, we select long-output instructionimage pairs from MMEvol (Luo et al., 2024) as inputs. In addition to single-image inputs, we also constructed other forms of data, including multiimage inputs and backtranslated instructions (Wang et al., 2024b), to enrich the diversity of the input data. To generate long outputs, we propose planand-write approach: LongWriter-Agent-V. This Figure 1: Left: Six examples for each type of task in MMLongBench-Write. They are divided into two categories: professional writing and creative writing. The former requires professional knowledge, while the latter does not. Right: The joint distribution of the number of input images and the expected output length for data in both categories. Most data requires 1000+ word output with given images, challenging the long-generation capabilities of VLMs. method involves providing input images and writing instructions to GPT-4o to first generate an outline and then sequentially write the text in segments. Through this approach, we collect LongWrite-V22k, dataset of 22k long-output examples. Using LongWrite-V-22k for SFT, the output length of Qwen2.5-VL-7B-Instruct (Team, 2025) can be extended beyond 3,000 words. However, longer outputs often introduce issues such as repetition and hallucination (Favero et al., 2024). To improve the fidelity of long outputs, we adapted the approach from RLHF-V (Yu et al., 2024a), where human experts revise the models outputs to form preference pairs for Direct Preference Optimization (DPO). Since traditional DPO (Rafailov et al., 2024) is typically performed on short texts of around 300 words, and LongWriter-Vs output length can exceed 3,000 words, the annotation cost is extremely high. To enhance the efficiency of preference data utilization, we proposed IterDPO, which divides long outputs into segments, treating each segments revision as preference pair. This method allows the model to learn fine-grained human corrections for each segment and effectively multiplies the use of single long-output preference pair by times. Through LongWriter-V-22k SFT and IterDPO, our 7B model achieves impressive performance in both output length and quality, surpassing powerful VLMs like GPT-4o. In summary, our contributions are as follows: We construct MMLongBench-Write to evaluate the long-output capabilities of VLMs and find that the output length limit of existing VLMs is around 1,000 words. We collect the SFT dataset LongWrite-V-22k, enabling VLMs for 3,000+ word generation. We propose IterDPO, which effectively improves the text quality of long-output VLM."
        },
        {
            "title": "2 Preliminaries",
            "content": "In the preliminary experiments, we first collect MMLongBench-Write, benchmark with visual inputs and long-output requirements. Then, we conduct an evaluation on this benchmark to explore the maximum output length of VLMs. Besides, we reveal that the main reason for bounded output length lies in the length distribution of SFT data. MMLongBench-Write. The ability to write long texts based on visual inputs is fundamental skill in various real-world applications and can be broadly categorized into professional writing and creative writing, depending on whether specialized knowledge is required (Taavitsainen and Pahta, 2000). To evaluate how well that VLMs master the two skills, we design three specific tasks for each skill. For each task, we curate 20 representative instructions with input images as test data. To ensure diversity, half instructions are in English and half are in Chinese. Figure 1 shows six examples of the benchmark and data distribution. It highlights that professional writing tasks typically involve more input images and require longer output lengths. LongWrite-V-Ruler. To explore the maximum output length of VLMs, we select 8 examples from MMLongBench-Write benchmark, with four 2 Figure 2: LongWriter-V-Ruler test across different output length requirements. The horizontal line show the overall upper bound for current VLMs. Figure 3: LongWriter-V-Ruler test for Qwen2-VL-7BInstruct trained on 10k SFT data samples with different average output lengths. samples in English and four in Chinese. As depicted in Figure 1, each instruction is in the form of \"Write an L-word article for the given pictures\". We construct diverse test set by changing the length requirement L. This test set uses {500, 1000, 2000, 4000}, which consists of 32 test prompts in total. Evaluation Result. We conduct the LongWrite-VRuler test on three open-source VLMs and three proprietary models. In Figure 2, we plot the required output length (x-axis) and the corresponding average output length (y-axis) for 12 instructions. We can observe that there exists an upper bound of 1000 output length for all models. Preliminary Experiment. As the controlled experiments in LongWriter (Bai et al., 2024) has revealed that the maximum output length of LLM is correlated with the maximum output length of SFT data, we further explore how the average output length of SFT data can influence the long-generation capabilities of VLM. We fine-tune Qwen2-VL-7BInstruct (Wang et al., 2024a) on three visual instruction datasets sampled from our final SFT data. Each dataset has 10k examples with different average output length respectively (0.8k, 1.8k and 2.8k). Figure 3 shows the trained models performance on LongWrite-V-Ruler, we observe that the models maximum output length increases with the average output length of SFT data. Besides, we find that the number of long-output examples is crucial for extending the output length of VLMs. For example, the training set with an average length of 1.8k contains 1% data exceeding 4k output length, but the model trained on it fails to generate 4k tokens (orange line). In contrast, the model trained with 21% data exceeding 4k output length is able to do that (blue line). This result indicates that the main reason that limits the VLMs output length is lack of enough long-output examples in SFT data."
        },
        {
            "title": "3 LongWriter-V: Data and Training",
            "content": "In this section, we will introduce the data collection and training process for unlocking the long generation capability of vision-language models."
        },
        {
            "title": "3.1 Data Collection",
            "content": "Figure 4 depicts the overall pipeline of our data collection process, which consists of two phases: SFT and DPO data collection."
        },
        {
            "title": "3.1.1 SFT Data Collection",
            "content": "Existing VLMs fail to directly generate texts exceeding 1k tokens, so we develop two-stage method to generate long texts as SFT data. LongWrite Agent-V. Before introducing our method, we first formalize the tasks objective. Given several input images and an user instruction x, our goal is to generate text that aligned with users length and quality requirements: = arg max (sl(y) + sq(y))Pθ(yv, x) (1) where sl and sq is the scoring function for judging the length and quality of the output, respectively. Pθ is the function representing the end-to-end solution, while existing VLMs may not be directly applied as their maximum output lengths are below 1k. To utilize off-the-shelf VLMs, we propose 3 Figure 4: SFT and DPO data collection pipeline of LongWriter-V. The SFT data includes both single-image and multi-image input for long text output. The DPO data contains human revision over each paragraph of VLMs long output. We conduct iterative direct preference optimization to learn the fine-grained human feedback. two-stage method for generating long texts. Inspired by the plan-and-write method from LongWriter (Bai et al., 2024), we first prompt the VLM to generate an outline that structures the output, plans the content, and specifies the word count for each paragraph. This outline breaks down the complex long-output task into manageable sub-tasks. Next, we use the VLM to fill in each paragraph and concatenate them to form the final output: = arg max P1(ov, x) arg max (sl(y)+sq(y))P2 P2(yv, x, o) = (cid:89) i=0 p(yiv, x, oi, y<i) (2) (3) where P1 is the modeling function for first stage, which takes input images and instruction to write an n-paragraph outline = {oi, = 1, ..., n}. P2 refers to the second stage, where the VLM outputs the content yi paragraph by paragraph based on the input information, outline oi and previous paragraphs y<i. In practice, we design two detailed prompts for guiding VLM to implement the two stages, which are listed in Appendix B.2. Visual Instruction Collection. To collect longoutput visual instructions for SFT, we choose MMEvol (Luo et al., 2024) as our primary data source. MMEvol is large-scale, opendomain dataset containing 480k image-text instruction pairs, sourced from diverse datasets such as LLaVA-Instruct (Liu et al., 2024a) and ShareGPT4V (Chen et al., 2024a). However, the average output length in this dataset is relatively short (54.85 tokens), necessitating filtering process to identify long-output instructions. We first check the original response length of ach example and select those with output length over 128, yielding 55,835 valid data. Next, we utilized GPT-4o to verify whether each instruction genuinely requires long output and whether the associated image was sufficiently relevant to the instruction. Finally, we get 8,115 single-image instructions. Multi-image Instruction Generation. As the original data in MMEvol only has one image for each instruction, we synthesize some multi-image instructions to increase the diversity of SFT data. 4 We select three subsets of MMEvol: wikiart, weblandmark, web-celebrity. Each subset contains hundreds of images in the same category. For example, images in web-landmark are all landmark pictures taken from different world attractions. We randomly sample 2 or 4 same-category images and then ask gpt-4o to generate an instruction that require long output for these images. We obtain 6,313 multi-image instructions in this way. Apart from synthetic data, we also collect natural multi-image data from an open-source PPT dataset, Zenodo10K (Zheng et al., 2025). We transform these slides into images to use them as visual inputs and set the instruction as \"Write lecture script for these slides\". We choose those slides that has at least 2 pages and at most 30 pages, resulting in 7,730 data. Backtranslation. Through above processes, we collect 22,158 single-image and multi-image instructions in total. Using the LongWrite AgentV pipeline, we generate long output for each visual instruction as SFT data. We call this training data LongWrite-V-22k. But most instructions dont specify the exact word count requirement, models trained on these data may lack the ability to follow the writing instruction with word count requirements. Therefore, we sample 5,000 data from LongWrite-V-22k and calculate the length of the output then add requirement \"Please write L-word in total.\" to the end of the instruction and use gpt-4o-mini for rephrasing the instruction to maintain consistency. This is inspired by previous backtranslation (Li et al., 2023) method on training long-output LLMs (Pham et al., 2024)."
        },
        {
            "title": "3.1.2 DPO Data Collection",
            "content": "The SFT data aims to extend VLMs output length. But the longer outputs may bring more hallucinations and repetitions. So the follow up question is: how to improve the generation fidelity of long output VLM? Previous works often adapt direct preference optimization (Rafailov et al., 2024; Liu et al., 2024c) to correct the hallucinations of VLMs. We follow the data format in RLHF-V (Yu et al., 2024a) which utilizes the human-annotated segment-level corrections on VLMs outputs as feedback. VLM Output Collection. To collect long responses, we select 100 slides that were not included in LongWrite-V-22k for VLM to generate scripts. These slides were previously used for teaching on MOOC platforms (Yu et al., 2020) and cover 10 subjects such as Computer Science, Math and Physics. Each subject may contain 4 to 16 Figure 5: Output length statistics of LongWrite-V-22k. slides and each slide may have 10 to 30 pages. We use LongWriter-V-7B, the VLM trained on our SFT data, to generate scripts for each slide. The long scripts are segmented by sections and aligned with each page of the given slide. We find that LongWriter-V-7B tends to output fewer sections than the number of total pages, which is one of the issues that we would ask human annotators to fix. Human Revision Collection. To get high-quality feedback on the flawed output of SFT model, we hire 10 college students from 10 different majors corresponding to the subjects of our slides. We required annotators to have GPA above 3.8 to ensure their expertise. To facilitate the annotation process, we build an online platform (See Appendix C.1). Each annotator will get slides that match with their major.The platform displays each slide page alongside the corresponding script segment generated by the SFT model. We ask annotators to check and revise each pages script for the following error types: factual errors, missing information, relevance to the image, coherence of sentences, and repetition of words. After completing the annotation of slide, our authors will review the annotation quality. Ultimately, we get 72 valid scripts with fine-grained human corrections."
        },
        {
            "title": "3.2 Training",
            "content": "Supervised Fine-tuning. We conduct model training based on two open-source VLMs with different parameter sizes: Qwen2.5-VL-7B-Instruct and Qwen2.5-VL-72B-Instruct (Team, 2025). We choose Qwen2.5-VL series as base model because they support context window of 32k tokens. By resizing the input images width and height to 280x280, the Qwen2.5-VL models can process up to 30 images. As shown in Figure 5, the output length in LongWrite-V-22k are distributed between 0 and 10k with two peaks around 0 and 1.5k. The 5 peak at 0 indicates some short output data is mixed in the LongWrite-V-22k, which are mainly the results of those simple instructions. To get better length distribution, we sample 10k data from LongWrite-V-22k with an average output length of 2.8k as training data. We then fine-tune the two models for 3 epochs with learning rate of 1e-5 for Qwen2.5-VL-7B-Instruct and 7e-6 for Qwen2.5VL-72B-Instruct, resulting in two SFT models: LongWriter-V-7B and LongWriter-V-72B. Iterative Direct Preference Optimization. After SFT phase, DPO (Rafailov et al., 2024) is widelyused method to optimize VLMs output quality, which learns from dataset of preference pairs = {(v, x, yw, yl)}, where the winning output yw is preferred over the losing output yl given the same visual input and text input x. The optimization objective of DPO is to maximize the difference between likelihood of preference pairs: LDPO(πθ; πref) = E(v,x,yw,yl)D [log σ(β log πθ(ywv, x) πref(ywv, x) β log πθ(ylv, x) πref(ylv, x) )] (4) In our annotation process, represents the images of slide, is the instruction for generating scripts, yl is the flawed output script of VLM and yw is the slides lecture after human revision. However, collecting human feedback on long output is very time-consuming and expensive. As mentioned in Section 3.1.2, we gather 72 preference pairs on the scripts, which costs one week and around 1,000 $ to finish. To make most use of these data, we propose to iteratively learn the fine-grained human correctional feedback on the long output. As the yw = {yi w, = 1, ...N } is revised script for an page slide, we increasingly view each pages script yi as winning segment over the flawed script: LIterDPO(πθ; πref) = E(v,x,yw ,yl)D (cid:88) [log σ(β log πθ(yi πref(yi vi, x) vi, x) β log i=1 πθ(yi πref(yi vi, x) vi, x) )] , yi (5) where yi is the revised and unrevised scripts until page i, and vi are the corresponding images. We view yi as new wining response over the flawed output yi , this can help VLM learn the fine-grained feedback on the long output and extend the number preference pairs for times. In this way, we get 1,477 iterative pairs for training. Apart from human feedback, we also utilize AI feedback by employing the gpt4o as the reward model. Following RLAIF (Yu et al., 2024b), we sample responses from the SFT model for 1,367 long-output instructions and use GPT-4o for assigning length and quality scores for the responses to construct preference pairs. Our final DPO model is trained with 2,844 mixed preference pairs,"
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "Metric. Following Bai et al. (2024), we evaluate the VLMs output length and quality using two metrics: Sl and Sq. Sl is the output score that measures how close that the VLMs output length lv is to the required length lr: if lv > lr, 100 max Sl = (cid:16) (cid:16) 0, 1 (lv/lr1) 0, 1 (lr/lv1) 3 (cid:17) (cid:17) 100 max if lv lr. (6) We also use gpt-4o-2024-08-06 to assign the quality score Sq for six aspects: Relevance, Accuracy, Coherence, Clarity, Breadth and Depth, and Reading Experience. We list the scoring prompt in Appendix D. Note that we have asked gpt-4o not to take the output length into account so that the quality score is independent with the length score. The overall score is the mean of Sl and Sq. Baselines. We evaluate 3 proprietary VLMs, 3 on about MMLongBench-Write models are listed in Table 3). Given that LLMs can also process visual instructions via reading the image caption (Ma et al., 2024), we first use gpt-4o to describe the input images and then feed the caption and writing instruction to the LLM. open-source VLMs (model details"
        },
        {
            "title": "4 LLMs",
            "content": "and"
        },
        {
            "title": "4.2 Main Results",
            "content": "We report the performance of baselines and our trained models in Table 1. To study the effective output length of models, we divide the MMLongBench-Write benchmark into four subsets based on the instructions required word count: 01500 words, 1500-2000 words, 2000-3000 words, and over 3000 words. The highest length and quality scores for each subset among models are in bold. We have three observations on the results: (1) Most existing models struggle to satisfy the length requirement over 2000 words, while LongWriter-V models can generate enough words for such instructions. By checking the length score Sl across different length intervals, we find that most models 6 Model Sl Sq Sl Sq Sl Sq Sl Sq Sl Sq Overall [0,1500) [1500,2000) [2000,3000) [3000,4000) Caption + LLMs GLM-4-9B-Chat GPT-4o-2024-08-06 Mistral-Large-Instruct-2407 DeepSeek-R1 Open-source VLMs MiniCPM-V2.6 Qwen2.5-VL-7B-Instruct Qwen2.5-VL-72B-Instruct Proprietary VLMs Claude-3-Opus-20240229 GPT-4o-2024-08-06 Gemini-1.5-Pro Our trained VLMs LongWriter-V-7B LongWriter-V-7B-DPO LongWriter-V-72B 71.3 77.1 78.9 82. 54.1 54.4 83.3 61.7 62.7 83.0 81.8 84.6 84.9 62.0 66.6 69.6 70.3 30.3 45.3 79.9 41.5 42.7 74. 82.5 86.2 84.3 80.6 87.5 88.2 94.5 77.8 63.5 86.7 82.0 82.6 91.2 81.1 82.9 85.5 87.9 86.7 89.7 87. 56.1 62.9 80.0 52.0 86.6 88.7 63.3 69.5 73.2 72.2 81.2 84.7 92.4 68.9 51.1 78.4 64.7 91.2 93. 72.8 82.5 83.3 65.7 68.9 70.9 73.4 31.3 46.6 84.5 42.8 37.7 78.1 87.8 90.5 86.2 82.4 88.3 89.9 95. 81.7 70.5 90.3 87.5 83.1 91.8 86.4 86.9 89.3 44.7 58.7 58.4 59.8 15.0 37.6 71.6 36.1 34.2 62. 81.2 87.1 88.4 76.7 85.8 83.0 92.0 69.4 50.6 79.7 74.6 71.6 86.2 69.2 69.0 75.8 24.2 33.5 47.2 38. 4.5 16.1 65.3 23.3 14.2 50.5 86.8 87.4 81.4 93.5 97.2 94.9 95.8 86.1 67.6 91.7 89.8 88.4 95. 87.5 85.2 85.2 Table 1: Evaluation results (%) on MMLongBench-Write. Note that LLMs are tested with input images transformed into captions. We report scores on different subsets of the benchmark, where [0,1000) means the expected output length falls within 0 to 1000 tokens. S, Sl, Sq is the overall score, length score and quality score respectively. perform poorly on the [2000, 3000) range, with their Sl below 70. In contrast, our LongWriter-V models can generate outputs with effective length and high quality even on the range of [3000, 4000). (2) The scaling law effect on our benchmark is striking: smaller models like Qwen2.5-VL-7B-Instruct perform poorly in our evaluation with an overall score of 54.4, while its larger counterpart Qwen2.5VL-72B-Instruct achieves notably higher score of 83.3. Besides, after training the two VLMs on our LongWrite-V-22k data, both models improve significantly on long generation. The performance gap between the two sizes models is narrowed after SFT (LongWriter-V-7Bs 81.8 vs. LongWriter-V-72Bs 84.9). (3) DPO can improve both the VLMs output quality and the ability to follow the length requirements of long generation. LongWriter-V-7B-DPO, which is the model trained on LongWriter-V-7B with 2,844 preference pairs, achieves improvement on both Sl (+3.7) and Sq (+1.8), showing that DPO is effective for boosting the long generation capabilities of VLMs."
        },
        {
            "title": "4.3 Human Evaluation",
            "content": "As the quality score Sq is assigned by the GPT4o automatically, the evaluation results may have bias as LLM tends to favor the responses generated by itself (Wang et al., 2023; Li et al., 2024a). To get more fair quality comparison for the models, we conduct human evaluation to capture the actual human preferences on model responses. Specifically, we select responses from four models: the three models trained by us and the GPT4o-2024-08-06 baseline. We ask two human annotators to vote for their preferred response between two selected models on the 120 responses of MMLongBench-Write. For each annotator, we collect 720 votes and calculate the average win rate among models using two annotators feedback. The results are shown in Figure 6, where we surprisingly find that two of our trained models receive more votes from humans in the comparison with the GPT-4o-2024-08-06 baseline. While in the automatic quality score comparison, the two models also surpass the GPT-4o on the quality score. This indicates that our trained models have gained some advantages over the GPT-4o baseline in the human preference, which is consistent with the automatic evaluation on the quality score of responses."
        },
        {
            "title": "4.4 Ablation Study",
            "content": "We conduct ablation experiments on both the SFT and DPO process of LongWriter-V models. For the LongWriter-V-7B model trained on LongWriteV-22k data, we control the three data sources of LongWrite-V-22k to observe how they contribute to the final performance of the SFT model. We run the SFT process on Qwen2.5-VL-7B-Instruct with7 Model Sl Sq SP LongWriter-V-7B w/o single-image data w/o multi-image data w/o backtranslation LongWriter-V-7B-DPO w/o iterative pairs w/o 1.4k gpt4o feedback 81.8 79.6 66.5 80.7 84.6 84.6 80. 82.5 79.5 60.3 80.0 86.3 87.4 78.7 81.1 79.6 72.7 81.3 82.9 81.8 82.7 83.1 83.4 29.3 82.4 85.8 83.3 71. Table 2: Scores (%) on MMLongBench-Write for models trained under different conditions, where S, Sl and Sq is the overall, length and quality score on all tasks and SP is the overall score on the PPT script task. DocURL (Deng et al., 2024), LongViTU (Wu et al., 2025), ShareGPT4Video (Chen et al., 2024b), LongVideoBench (Wu et al., 2024a) and LVBench (Wang et al., 2024c). However, the longoutput generation abilities of VLMs have been less explored. In our work, we find that current VLMs struggle to generate an output with over 1000 tokens, which is much shorter than their max input context length (>16,000 tokens) (Wang et al., 2024a). To fill this gap, we explore how to extend the maximum output length of VLMs. Although we show that supervised fine-tuning can align VLMs with users instructions on length requirements, it is also important to improve the quality of long output (Wu et al., 2024b). Previous works mainly focus on how to improve VLMs generation quality on short output tasks via post training methods such as RLHF-V (Yu et al., 2024a), RLAIF-V (Yu et al., 2024b), POVID (Zhou et al., 2024) and MIA-DPO (Liu et al., 2024c). However, none of these methods have explored how to effectively use human correctional feedback on long output for aligning VLMs. We propose to iteratively use each segment of the revised long output as the preferred response, which extends the number of preference pairs and successfully improves the long generation quality of VLM."
        },
        {
            "title": "6 Conclusion",
            "content": "Our work introduces MMLongBench-Write, comprehensive benchmark for evaluating long-generation tasks with visual inputs, and LongWriter-V-22k, novel supervised fine-tuning dataset designed to enhance the long-output capabilities of VLMs. Furthermore, our proposed IterDPO method effectively leverages human feedback to improve the fidelity of long outputs, addressing issues such as hallucination. Future Figure 6: Human evaluation results on MMLongBenchWrite, where each block of the matrix represents the model of the rows win rate over the model of the column. The win rate is voted by two annotators. out (w/o) single-image, multi-image or backtranslation data respectively and evaluate the trained models on MMLongBench-Write. As shown in Table 2, removing any of these data sources may lead to decline in the overall score, where multi-image data is the most essential one, causing decrease of 15.3 overall score. These results indicate that these sources are useful for training long output VLMs. To explore the effectiveness of our iterative DPO strategy over the small size preference data on longoutput VLM alignment, we run the DPO process without those extra pairs extended by the iterative strategy. Results in Table 2 demonstrates that the model gains +1.1 length score but -1.1 quality score and -2.5 PPT task score over the DPO model with full data, which means the extended data is useful for the generation quality and the PPT script task. To examine the effectiveness of mixing AI preference pairs, we then train the SFT model with the human revised preference pairs only, resulting in even worse performance (-1.1 overall score against the SFT model). This suggests that incorporating AI-generated pairs can improve model performance by providing additional training signals."
        },
        {
            "title": "5 Related Work",
            "content": "Recent advancements in Vision-Language Models have focused on enhancing their ability to process long-context inputs (Ge et al., 2024; Li et al., 2024b; Chen et al., 2024c). There are abundant benchmarks and datasets that designed for multimodal long context understanding including MMLongBench-Doc (Ma et al., 2024), Long8 training research may explore more efficient strategies and larger datasets to further push the boundaries of long-output generation in VLMs."
        },
        {
            "title": "Limitations",
            "content": "We acknowledge some limitations in our work, which are listed below: 1. Dataset Size: The size of our LongWriter-V-22k dataset may not be sufficiently large to fully capture the diversity of longoutput generation tasks. While this dataset size is adequate for initial exploration and training, it may limit the robustness of our findings and the generalizability of our models performance. Expanding the dataset to include more examples would require significant additional resources, both in terms of data collection and annotation costs. 2. Language Limitation: The current dataset and benchmark are limited to English and Chinese only. This restricts our ability to evaluate the performance of VLMs across multiple languages, which is crucial for real-world applications where multilingual support is often required. Future work should consider expanding the dataset to include other languages to provide more comprehensive evaluation of VLMs long-output capabilities. 3. Human Feedback Efficiency: While our IterDPO method significantly improves the efficiency of utilizing human feedback for long outputs, the process of collecting high-quality human corrections remains time-consuming and costly. This limits the scalability of our approach and the frequency with which we can update and refine the training data. Future work should explore more efficient methods for obtaining and incorporating human feedback to further enhance model performance."
        },
        {
            "title": "Ethical Consideration",
            "content": "While our work on enhancing the long-output capabilities of Vision-Language Models represents significant advancement, VLMs may still generate inaccurate or misleading information, especially when dealing with common knowledge not explicitly present in the context. This can lead to the propagation of false information if not properly managed. Therefore, additional safeguards and verification mechanisms should be implemented when deploying these models in user-facing applications. Our training data has been desensitized to protect individual privacy. All the data sources we used are public available with permissible licenses, including MMEvol (Luo et al., 2024) and Zenodo10K (Zheng et al., 2025)."
        },
        {
            "title": "References",
            "content": "Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. 2022. Flamingo: visual language model for few-shot learning. Advances in neural information processing systems, 35:2371623736. Anthropic. 2024. Anthropic: Introducing the next generation of claude. Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. 2024. Longwriter: Unleashing 10,000+ word generation from long context llms. arXiv preprint arXiv:2408.07055. Lin Chen, Jinsong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, and Dahua Lin. 2024a. Sharegpt4v: Improving large multi-modal models with better captions. In European Conference on Computer Vision, pages 370387. Springer. Lin Chen, Xilin Wei, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Bin Lin, Zhenyu Tang, et al. 2024b. Sharegpt4video: Improving video understanding and generation with better captions. arXiv preprint arXiv:2406.04325. Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, et al. 2024c. Internvl: Scaling up vision foundation models and aligning for In Proceedings of generic visual-linguistic tasks. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2418524198. Christopher Chou, Lisa Dunlap, Koki Mashita, Krishna Mandal, Trevor Darrell, Ion Stoica, Joseph Gonzalez, and Wei-Lin Chiang. 2024. Visionarena: 230k real world user-vlm conversations with preference labels. arXiv preprint arXiv:2412.08687. Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, ZhongZhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, et al. 2024. Longdocurl: comprehensive multimodal long document benchmark integrating understanding, reasoning, and locating. arXiv preprint arXiv:2412.18424. Alessandro Favero, Luca Zancato, Matthew Trager, Siddharth Choudhary, Pramuditha Perera, Alessandro Achille, Ashwin Swaminathan, and Stefano Soatto. 2024. Multi-modal hallucination control by visual information grounding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1430314312. Junqi Ge, Ziyi Chen, Jintao Lin, Jinguo Zhu, Xihui Liu, Jifeng Dai, and Xizhou Zhu. 2024. V2pe: Improving multimodal long-context capability of visionlanguage models with variable visual position encoding. arXiv preprint arXiv:2412.09616. Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang. 2024. Chatglm: family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793. Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2024a. Visual instruction tuning. Advances in neural information processing systems, 36. Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang, Hang Su, et al. 2024b. Grounding dino: Marrying dino with grounded pre-training for open-set object detection. In European Conference on Computer Vision, pages 3855. Springer. Ziyu Liu, Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Haodong Duan, Conghui He, Yuanjun Xiong, Dahua Lin, and Jiaqi Wang. 2024c. Mia-dpo: Multi-image augmented direct preference optimization for large vision-language models. arXiv preprint arXiv:2410.17637. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, et al. 2024. Mmevol: Empowering multimodal large language models with evol-instruct. arXiv preprint arXiv:2409.05840. Iryna Hartsock and Ghulam Rasool. 2024. Visionlanguage models for medical report generation and visual question answering: review. Frontiers in Artificial Intelligence, 7:1430984. Xudong Hong, Asad Sayeed, Khushboo Mehra, Vera Demberg, and Bernt Schiele. 2023. Visual writing prompts: Character-grounded story generation with curated image sequences. Transactions of the Association for Computational Linguistics, 11:565581. Albert Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. arXiv preprint arXiv:2310.06825. Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu. 2024a. Llms-as-judges: comprehensive survey on llm-based evaluation methods. arXiv preprint arXiv:2412.05579. Mukai Li, Lei Li, Shansan Gong, and Qi Liu. 2024b. Giraffe: Design choices for extending the context length of visual language models. arXiv preprint arXiv:2412.12735. Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer, Jason Weston, and Mike Lewis. 2023. Self-alignment with instruction backtranslation. arXiv preprint arXiv:2308.06259. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer Vision ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part 13, pages 740755. Springer. Yubo Ma, Yuhang Zang, Liangyu Chen, Meiqi Chen, Yizhu Jiao, Xinze Li, Xinyuan Lu, Ziyu Liu, Yan Ma, Xiaoyi Dong, et al. 2024. Mmlongbench-doc: Benchmarking long-context document understanding with visualizations. arXiv preprint arXiv:2407.01523. OpenAI. 2024. Openai: Hello gpt-4o. Chau Minh Pham, Simeng Sun, and Mohit Iyyer. 2024. Suri: Multi-constraint instruction following for long-form text generation. arXiv preprint arXiv:2406.19371. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher Manning, Stefano Ermon, and Chelsea Finn. 2024. Direct preference optimization: Your language model is secretly reward model. Advances in Neural Information Processing Systems, 36. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. 2022. Laion-5b: An open large-scale dataset for training next generation imagetext models. Advances in Neural Information Processing Systems, 35:2527825294. Yan Shu, Peitian Zhang, Zheng Liu, Minghao Qin, Junjie Zhou, Tiejun Huang, and Bo Zhao. 2024. Video-xl: Extra-long vision language model for arXiv preprint hour-scale video understanding. arXiv:2409.14485. Irma Taavitsainen and Päivi Pahta. 2000. Conventions of professional writing: The medical case report in historical perspective. Journal of English Linguistics, 28(1):6076. Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, et al. 10 2024. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530. moocs. In Proceedings of the 58th annual meeting of the association for computational linguistics, pages 31353142. Tianyu Yu, Yuan Yao, Haoye Zhang, Taiwen He, Yifeng Han, Ganqu Cui, Jinyi Hu, Zhiyuan Liu, Hai-Tao Zheng, Maosong Sun, et al. 2024a. Rlhf-v: Towards trustworthy mllms via behavior alignment from finegrained correctional human feedback. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1380713816. Tianyu Yu, Haoye Zhang, Yuan Yao, Yunkai Dang, Da Chen, Xiaoman Lu, Ganqu Cui, Taiwen He, Zhiyuan Liu, Tat-Seng Chua, et al. 2024b. Rlaifv: Aligning mllms through open-source ai feedback for super gpt-4v trustworthiness. arXiv preprint arXiv:2405.17220. Jingyi Zhang, Jiaxing Huang, Sheng Jin, and Shijian Lu. 2024. Vision-language models for vision tasks: survey. IEEE Transactions on Pattern Analysis and Machine Intelligence. Hao Zheng, Xinyan Guan, Hao Kong, Jia Zheng, Hongyu Lin, Yaojie Lu, Ben He, Xianpei Han, and Le Sun. 2025. Pptagent: Generating and evaluating presentations beyond text-to-slides. Preprint, arXiv:2501.03936. Yiyang Zhou, Chenhang Cui, Rafael Rafailov, Chelsea Finn, and Huaxiu Yao. 2024. Aligning modalities in vision large language models via preference finetuning. arXiv preprint arXiv:2402.11411. Qwen Team. 2025. Qwen2.5-vl. Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, and Lijuan Wang. 2022. Git: generative image-to-text transformer for vision and language. arXiv preprint arXiv:2205.14100. Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. 2023. Large language models are not fair evaluators. arXiv preprint arXiv:2305.17926. Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, et al. 2024a. Qwen2-vl: Enhancing vision-language models perception of the world at any resolution. arXiv preprint arXiv:2409.12191. Tiannan Wang, Jiamin Chen, Qingrui Jia, Shuai Wang, Ruoyu Fang, Huilin Wang, Zhaowei Gao, Chunzhao Xie, Chuou Xu, Jihong Dai, et al. 2024b. Weaver: Foundation models for creative writing. arXiv preprint arXiv:2401.17268. Weihan Wang, Zehai He, Wenyi Hong, Yean Cheng, Xiaohan Zhang, Ji Qi, Xiaotao Gu, Shiyu Huang, Bin Xu, Yuxiao Dong, et al. 2024c. Lvbench: An extreme long video understanding benchmark. arXiv preprint arXiv:2406.08035. Haoning Wu, Dongxu Li, Bei Chen, and Junnan Li. 2024a. Longvideobench: benchmark for longcontext interleaved video-language understanding. arXiv preprint arXiv:2407.15754. Rujie Wu, Xiaojian Ma, Hai Ci, Yue Fan, Yuxuan Wang, Haozhe Zhao, Qing Li, and Yizhou Wang. 2025. Longvitu: Instruction tuning for long-form video understanding. arXiv preprint arXiv:2501.05037. Yuhao Wu, Ming Shan Hee, Zhiqing Hu, and Roy KaWei Lee. 2024b. Longgenbench: Benchmarking long-form generation in long context llms. arXiv preprint arXiv:2409.02076. Fuzhao Xue, Yukang Chen, Dacheng Li, Qinghao Hu, Ligeng Zhu, Xiuyu Li, Yunhao Fang, Haotian Tang, Shang Yang, Zhijian Liu, et al. 2024. Longvila: Scaling long-context visual language models for long videos. arXiv preprint arXiv:2408.10188. Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li, Weilin Zhao, Zhihui He, et al. 2024. Minicpm-v: gpt-4v level mllm on your phone. arXiv preprint arXiv:2408.01800. Jifan Yu, Gan Luo, Tong Xiao, Qingyang Zhong, Yuquan Wang, Wenzheng Feng, Junyi Luo, Chenyu Wang, Lei Hou, Juanzi Li, et al. 2020. Mooccube: large-scale data repository for nlp applications in"
        },
        {
            "title": "A Model Cards",
            "content": "Table 3 demonstrates the detailed information of the LLMs and VLMs evaluated in our experiments."
        },
        {
            "title": "Context window Max output tokens",
            "content": "Large Language Models GLM-4-9B-chat (GLM et al., 2024) Mistral-Large-Instruct (Jiang et al., 2023) Mistral-Large-Instruct-2407 Deepseek-r1 (Guo et al., 2025) deepseek-reasoner - 128,000 tokens 128,000 tokens 64,000 tokens Vison Language Models MiniCPM-V2.6 (Yao et al., 2024) Qwen2.5-VL-7B (Team, 2025) Qwen2.5-VL-72B (Team, 2025) Claude 3 Opus (Anthropic, 2024) Gemini-1.5-pro (Team et al., 2024) GPT-4o (OpenAI, 2024) MiniCPM-V-2-6 Qwen2.5-VL-7B-Instruct Qwen2.5-VL-72B-Instruct claude-3-opus-20240229 gemini-1.5-pro gpt-4o-2024-0832,000 tokens 32,000 tokens 32,000 tokens 200,000 tokens 2,000,000 tokens 128,000 tokens Table 3: Model cards. - - 8,000 tokens - - - 4,096 tokens 8,192 tokens 8,192 tokens"
        },
        {
            "title": "B Model Prompts",
            "content": "B.1 Prompts for Collecting Visual Instructions Prompt for selecting user requests that require 1,000+ word response. You will receive an image and an instruction from user to an AI assistant, please determine whether the instruction requires the AI assistant to write an article for the given image, and the length of the article is more than 1,000 words in English (or 1,000 characters in Chinese). If the instruction does not mention the word requirement, please determine whether the users intention of the response length is more than 1,000 words. If the instruction is irrelated with the image, please reply no. Instruction: {User Instruction} Prompt for constructing multi-image instruction. You will receive {Image Number} images and an instruction from user to an AI assistant, this original instruction is targeted for the first image solely. Now please rewrite this instruction to challenging long-output one that need using visual information from all the input images, and the length of the expected output should be more than 2,000 words in English (or 2,000 characters in Chinese). Here are three examples of challenging long-output instructions: Example instruction 1: {Example Instruction 1} Example instruction 2: {Example Instruction 2} Example instruction 3: {Example Instruction 3} Now, you should rewrite the following instruction: Instruction: {User Instruction } Please rewrite this user instruction to challenging long-output instruction that requires the use of all the input images. Please output only the rewritten instruction, do not output other content. B.2 Prompts for the LongWrite Agent-V Pipeline Prompt for planning the writing outline. You are an expert planner. Your task is to break down writing task into clear subtasks based on the provided images and writing instruction. 12 Please analyze the images and writing instruction carefully, then create detailed outline in this format: Section 1 - Main Point: [Key points to cover based on images and instruction] - Word Count: [200-1000 words] Section 2 - Main Point: [Key points to cover based on images and instruction] - Word Count: [200-1000 words] ... Make each section focused and specific while ensuring the full outline: 1. Covers all key content from both images and writing instruction 2. Flows logically from section to section 3. Has reasonable word count targets (200-1000 words per section) 4. Forms cohesive whole that fulfills the writing instruction Writing instruction: {User Instruction} Output only the outline with no other text. Prompt for generating each paragraph according to the writing outline. You are an expert writer. Your task is to write the next section of longer piece based on: 1. The provided images and writing instruction 2. The outline plan 3. Previously written sections Writing instruction: {User Instruction} Outline plan: {PLAN} Previous sections: {TEXT} Please write section {STEP} following these guidelines: 1. Focus on the main points specified in the outline 2. Stay within the target word count 3. Flow naturally from previous sections 4. Integrate relevant details from the images 5. Maintain consistent tone and style 6. Write only this section, not full conclusion Output only the new section with no other text."
        },
        {
            "title": "C Annotation Details",
            "content": "C.1 Annotation Platform Our annotation platform consists of two main pages: annotation page and admin page. Annotation page. This page provides the core annotation interface for users. As shown in Figure 7, after logging in, users first see course selection interface where they can view available courses in their major. Each course is displayed with progress bar showing completion status and the total number of annotated pages. After selecting course, users enter the annotation interface shown in Figure 8, where the page is divided into three columns: the lecture slide, original transcript, and annotation area. Users can navigate through slides using pagination controls and save their annotations for each slide individually. Admin page. This page provides administrative oversight of the annotation process. As shown in Figure 9, administrators can monitor annotation progress across all majors and courses, with detailed statistics grouped by annotators major. The interface displays progress bars and completion rates for each course, helping administrators track the overall project status. When reviewing annotations, administrators can examine both original and modified scripts side by side, as shown in Figure 10. 13 Figure 7: Screenshot of the annotation page (course selection). After logging in, annotators can view available courses in their major, with progress bars showing completion status and the number of annotated pages. 14 Figure 8: Screenshot of the annotation page (annotation). The page displays the lecture slide (left), original transcript (middle), and annotation area (right). Users can modify transcripts while viewing the corresponding slides and track their annotation status. 15 Figure 9: Screenshot of the admin page (progress overview). Administrators can monitor annotation progress across different majors, view detailed statistics for each course, and track overall completion status. 16 Figure 10: Screenshot of the admin page (review interface). Reviewers can examine both original and modified scripts side by side. 17 C.2 Annotation Guidelines Guidelines for the data annotators: 1. Click on Register in the left bottom part of the annotation page if this is the first time that you enter our system. You should choose your major, username and password during registration. We will assign annotation tasks according to your major. You can return to the annotation page and login via your username and password. 2. After logging in, you will see list of PPTs that require modifications to the presentation scripts. Click on Start Annotating to proceed. 3. After opening PPT, you will see the original script for each slide. These scripts are generated by AI and may have issues such as factual errors, missing information from the PPT, irrelevance to the topic, awkward phrasing, or repetitive wording. Your task is to edit the script for each slide in the \"Annotation Area.\" After making your changes, click on \"Save Annotations.\" 4. Note that this is one-way system. If you press the browsers back button, the login process will restart (there are only three pages: login, list, and annotation). If you want to return to the list page from the annotation page, you can click on \"Return to Course List\" at the top. Remember to save your annotations promptly after completing them! Click \"Save Annotations\" immediately after finishing your annotations! If the PPT is not clear enough, you can use the button at the top-right corner of the image to enlarge it to full screen. 5. If you have finished marking PPT, you can contact us for acceptance inspection. We will check each page for the following: - Whether there are factual errors. - Whether too much information from the PPT is missing in the script. - Whether the content is irrelevant to the topic. - Whether the sentences are awkward or not smooth. - Whether there is repetitive wording. 6. Compensation: - If every page of the PPT passes the acceptance inspection, you will receive base payment of 80 CNY for each PPT. - If PPT fails the acceptance inspection three or more times, each subsequent failure will result in deduction of 20 CNY from the payment, to compensate for the time spent by the inspector. - If the original script of the PPT is empty on six or more pages, and the PPT passes the acceptance inspection, you will receive an additional 20 CNY in compensation for the time spent by the annotator in writing the script from scratch. After reading the above requirements, start data annotation now! C.3 Data Collection Cost We spend approximately 7,000 CNY on human correction data collection."
        },
        {
            "title": "D More Evaluation Details",
            "content": "D.1 Evaluation Setting In the Image + VLM setting, we set the generation sampling parameters to max_new_tokens=8192. In the Caption + LLM setting, for the first model call where we use gpt-4o for generating the caption, we set max_new_tokens=1024. For the following model call where the LLM outputs the final response for the writing instruction and caption, we set max_new_tokens=8192 except for claude-3-opus, which we set max_new_tokens=4096. D.2 Evaluation Prompts Prompt for gpt-4o on generating caption for the Caption + LLM setting. 18 Please provide detailed and comprehensive description of the image, paying special attention to both visual elements and textual content. Consider the following aspects: 1. Main Subject(s): - What are the primary objects, people, or figures in the image? - Their positioning, size, and prominence - Any diagrams, charts, or graphical elements 2. Textual Content: - All text visible in the image, including: * Headers, titles, or captions * Labels or annotations * Body text or paragraphs * Numbers, equations, or mathematical notation - The relationship between text and visual elements 3. Visual Details: - Colors, lighting, and overall composition - Textures and materials visible - Any notable patterns, designs, or visual hierarchies - Quality and clarity of text/figures 4. Information Structure: - How information is organized (e.g., flowcharts, tables, lists) - Connections or relationships indicated by arrows or lines - Legend or key elements if present - Reading order or flow of information 5. Technical Elements: - Presence of graphs, charts, or scientific figures - Any coordinate systems or axes - Units of measurement or scales - Technical symbols or notation 6. Context and Purpose: - The apparent purpose of the image (educational, technical, decorative, etc.) - Target audience or field of study - Any relevant domain-specific context Please provide clear, structured description that captures both the visual and textual elements, ensuring no significant details are omitted. Prompt for LLMs on generating response for the Caption + LLM setting. Please analyze the following image captions and writing requirement carefully, then provide detailed response that: 1. Directly addresses the writing requirement 2. Incorporates relevant details from the image captions 3. Uses clear, well-structured writing 4. Maintains appropriate tone and style for the context Writing requirement: {User Instruction} Image captions: {CAPTIONS} Please provide comprehensive response that fully satisfies the writing requirement while effectively utilizing the information from the image captions. Prompt for gpt-4o on scoring the quality of responses. You are an expert in evaluating text quality. Please evaluate the quality of an AI assistants response to users writing request with several corresponding images. Be as strict as possible. 19 You need to evaluate across the following six dimensions, with scores ranging from 1 to 5. The scoring criteria from 5 to 1 for each dimension are as follows: 1. Relevance: From content highly relevant and fully applicable to the users request and images to completely irrelevant or inapplicable. 2. Accuracy: From content completely accurate with no factual errors or misleading information to content with numerous errors and highly misleading. 3. Coherence: From clear structure with smooth logical connections to disorganized structure with no coherence. 4. Clarity: From clear language, rich in detail, and easy to understand to confusing expression with minimal details. 5. Breadth and Depth: From both broad and deep content with lot of information to seriously lacking breadth and depth with minimal information. 6. Reading Experience: From excellent reading experience, engaging and easy to understand content to very poor reading experience, boring and hard to understand content. Please evaluate the quality of the following response to users request according to the above requirements. <User Request> {INST} </User Request> <Response> {RESPONSE} </Response> Please evaluate the quality of the response. You must first provide brief analysis of its quality, then give comprehensive analysis with scores for each dimension. The output must strictly follow the JSON format: \"Analysis\": ..., \"Relevance\": ..., \"Accuracy\": ..., \"Coherence\": ..., \"Clarity\": ..., \"Breadth and Depth\": ..., \"Reading Experience\": .... You do not need to consider whether the response meets the users length requirements in your evaluation. Ensure that only one integer between 1 and 5 is output for each dimension score. D.3 Deployment Details All the experiments were conducted on an Ubuntu 20.04.4 server equipped with 104 Intel Xeon(R) Platinum 8470 CPU cores, and graphic cards that contained 8 NVIDIA A800 SXM 80GB GPUs. Besides, the CUDA version is 12.2. The supervised fine-tuning (SFT) phase for LongWriter-V-7B on the LongWriteV-22k dataset took approximately six hours using 8 GPUs. For the LongWriter-V-72B model, the SFT process required 72 hours with the same GPU configuration. The Direct Preference Optimization (DPO) process for LongWriter-V-7B, using 2,844 mixed preference pairs, completed in 1.5 hours. 20 D.4 Case Study Figure 11: Input images of the example for the PPT script generation task. To illustrate the actual outputs of our tested models, we select case from MMLongBench-Write. As shown in Figure 11, this case includes 15 input images. The instruction for this case is as follows: Write 3000-word lecture script based on these PPT images. The script should be suitable for teacher to read aloud in class and must not contain any unreadable content. It should align with the teaching goals of the PPT without merely repeating its content. The script should be clear, well-structured, and possess educational and inspirational value. Please output the script directly, without additional content such as subtitles or questions, and ensure it is fully readable. We present the responses from GPT-4o-2024-08-06, LongWriter-V-72B, and LongWriter-V-7B-DPO below: Response of GPT-4o-2024-08-06: Ladies and gentlemen, welcome to todays lecture on Mechanical Energy. Our focus will be on understanding the fundamental concepts of kinetic energy, potential energy, and the roles of air resistance and friction. These concepts are not just theoretical; they have practical implications in our daily lives, especially in the context of transportation. Lets begin by considering the significance of transportation in energy consumption. In the United States, transportation accounts for approximately 28% of total energy use, which translates to about 30 exajoules per year. This sector also contributes to one-third of the countrys CO2 emissions. Understanding the mechanics behind transportation can help us devise strategies to reduce energy use and emissions. First, lets delve into kinetic energy, which is the energy of motion. The formula for kinetic energy is Ekin = 1 2 mv2, where is mass and is velocity. Consider baseball thrown at 100 mph; its kinetic energy is around 150 joules. While this is small amount of energy, it illustrates the concept effectively. Now, imagine car like Toyota Camry with four passengers moving at 60 mph. The kinetic energy here is approximately 700 kilojoules, demonstrating how energy scales with mass and velocity. Lets explore practical example: road trip from Boston to New York, distance of 210 miles. Suppose the car in question achieves 30 miles per gallon and consumes 7 gallons of fuel for the trip, equating to 840 megajoules of energy. However, not all this energy is used for motion. The kinetic energy required is only about 0.7 megajoules. So, where does the rest of the energy go? Factors like engine efficiency, air resistance, and friction play significant roles. Next, well explore potential energy, which is stored energy based on an objects position or configuration. fundamental principle here is energy conservation: energy cannot be created or destroyed, 21 2 kx2. only transformed. Consider ball rolling uphill; kinetic energy is converted into potential energy. The potential energy, , is given by = mgh, where is the acceleration due to gravity, and is height. Springs are another example, where potential energy is stored as = 1 Now, lets consider potential energy in the context of forces and work. For mass subject to force, the work done is the force multiplied by the distance moved. This work results in energy transfer, such as converting potential energy to kinetic energy. In vector terms, for motion in line, force is related to potential energy by = dU dx . Lets apply these concepts to real-world scenarios. Consider an airplane cruising at altitude; its kinetic energy is significant. But potential energy also plays crucial role, especially at high altitudes. Other applications include using potential energy to pump water uphill or using elevators and cranes. Returning to our road trip example, we must consider the potential energy effects of hills. constant speed of 60 mph with elevation gains requires additional energy. Suppose the car gains 50 feet per mile; the energy needed per hill becomes substantial. Despite this, the total energy for hills remains less than the energy output from the engine, highlighting the inefficiency of energy conversion in transportation. Air resistance and friction are also critical factors in energy consumption. As car moves, it collides with air molecules, creating wake. This interaction results in energy loss, calculated using the drag coefficient. For example, Toyota Camry traveling from Boston to New York loses considerable amount of energy to air resistance. The drag force depends on factors like speed and surface area, and reducing these can improve efficiency. Finally, lets summarize our findings. The total energy expenditure for our road trip includes kinetic energy, potential energy of hills, rolling resistance, and air resistance. The gasoline energy far exceeds these values, illustrating the inefficiency of internal combustion engines, which are only about 25% efficient. This inefficiency is even more pronounced in city driving, where acceleration and rolling resistance dominate. To reduce transport energy costs, we can apply simple physics principles. Driving at lower speeds, streamlining vehicles, inflating tires, using more efficient engines, and employing regenerative braking are effective strategies. In an ideal world, with these measures and advanced technologies like vacuum tunnels, we could drastically reduce transport energy expenditure. In conclusion, understanding mechanical energy, particularly in transportation, provides insights into improving energy efficiency and reducing environmental impact. As we continue to innovate and apply these principles, we move closer to more sustainable future. Thank you for your attention. Please review your lecture notes in preparation for our next topic: Heat. Response of LongWriter-V-72B: 1. Today, we delve into mechanical energy, crucial topic in physics with broad applications, especially in transportation. The U.S. dedicates nearly 28% of its energy to transport, amounting to about 30 exajoules annually and contributing to third of the nations CO2 emissions. Grasping this impact is essential for developing sustainable solutions. Well examine how kinetic and potential energy, along with friction and air resistance, shape transport dynamics. This understanding not only illuminates our current energy use but also fuels innovation for future efficiency. As we proceed, reflect on how these principles connect to real-world challenges and inspire advancements in energy conservation. 2. Building on our introduction to mechanical energy, lets examine its pivotal role in transportation. The U.S. dedicates around 28% of its energy to this sector, which consumes approximately 30 exajoules annually and accounts for third of the countrys CO2 emissions. This underscores the necessity for sustainable practices. To tackle these challenges, we must understand kinetic and potential energy, as well as friction and air resistance. Kinetic energy is the energy of motion, while potential energy is stored energy with the potential to perform work. Friction and air resistance are forces that impede motion, impacting energy efficiency. Grasping these concepts is crucial for 22 optimizing transportation systems. As we delve deeper, consider how these principles can inform innovations in energy conservation and efficiency, driving progress toward more sustainable future. 3. Lets delve into kinetic energy, the energy moving object possesses. The formula for kinetic energy is Ekin = 1 2 mv2, where represents mass and represents velocity. This equation reveals that kinetic energy is proportional to an objects mass and the square of its speed. Consider baseball traveling at 100 mph. Its kinetic energy is approximately 150 joules. Now, think about Camry carrying four passengers moving at 60 mph; its kinetic energy jumps to around 700 kilojoules. This comparison illustrates how both mass and velocity significantly affect kinetic energy. To further clarify, lets examine the energy needed for 100 pitches of baseball. This amounts to about 15 kilojoules, small fraction of the 10 megajoules of energy person typically consumes daily through food. These examples highlight the importance of understanding kinetic energy in various contexts, from sports to transportation. As we proceed, consider how these principles apply to real-world scenarios and how they can inform innovations in energy efficiency and sustainability. 4. Lets delve into real-world application of energy principles by considering road trip from Boston to New York in Camry with four passengers. This 210-mile journey requires about 7 gallons of gasoline, equating to roughly 840 megajoules of energy. But where does this energy go? Firstly, kinetic energy is factor; 4000-pound car at 60 mph possesses about 0.7 megajoules of kinetic energy. Yet, this is small portion of the total energy used. We must also consider the engines efficiency, typically around 25%, meaning much of the energy is lost as heat. Moreover, friction and air resistance play significant roles. These forces oppose the cars motion, necessitating additional energy to maintain speed. Climbing hills further increases energy demands, converting kinetic energy into potential energy. This scenario prompts us to question the necessity of such energy expenditures. Are there ways to optimize our vehicles and driving habits to enhance efficiency? Reflect on how understanding these principles can lead to more sustainable practices in transportation. By grasping where energy is utilized and wasted, we can explore innovative solutions to reduce consumption and environmental impact. 5. Now, lets turn our attention to potential energy, fundamental idea in physics. It represents stored energy within system, ready to perform work. The principle of energy conservation is key here: energy cannot be created or destroyed, only transformed from one form to another. Consider lifting an object; as it ascends, its kinetic energy converts into potential energy, expressed as = mgh, where is mass, is gravitational acceleration, and is height. This potential energy can revert to kinetic energy if the object falls. practical example is compressed spring. The energy you expend to compress it becomes potential energy, = 1 2 kx2, with as the spring constant and as the displacement. When released, this energy transforms back into kinetic energy. Understanding potential energy is vital for analyzing systems and predicting motion. It enables us to calculate energy transformations and optimize processes, from elevators to water pumps. Reflect on how these concepts apply to everyday technologies and how they might inspire innovations in energy storage and efficiency. 6. Building on our understanding of potential energy, lets explore its relationship with forces and work. When an object is displaced in potential field, like gravity or spring, force acts upon it. This force is derived from the potential energy gradient, expressed as = dU dx , where is potential energy and is position. Work is done when force moves an object over distance, quantified as = d. In the context of potential energy, this work equates to the change in potential energy, . For instance, lifting an object increases its gravitational potential energy, while compressing spring increases its elastic potential energy. These concepts are crucial in physics, as they enable us to analyze and predict system behavior. By understanding the forces and work involved, we can optimize energy use in various applications, from 23 r2 ˆr, which is the familiar inverse-square law of gravity. designing efficient machines to developing renewable energy systems. Consider how these principles apply to real-world scenarios and inspire innovations in energy efficiency and sustainability. 7. Expanding on our discussion, lets delve into potential energy in two and three dimensions using vectors. In 2D and 3D spaces, potential energy becomes function of multiple variables, such as (x, y, z). The gradient of potential energy, denoted as , is vector that points in the direction of the greatest increase in potential energy. The force acting on an object can be derived from this gradient, expressed as = . The negative sign indicates that the force acts in the direction of decreasing potential energy. For example, in gravitational field, the potential energy is given by = GM , where is the gravitational constant, and are masses, and is the distance between them. The corresponding force is = = GM Understanding these vector relationships is essential for analyzing complex systems, such as planetary motion or electromagnetic interactions. It allows us to predict and explain the behavior of objects under various forces, inspiring innovations in fields like robotics and aerospace engineering. Reflect on how these principles apply to real-world technologies and consider their potential to drive future advancements. 8. Lets delve into the practical applications of potential energy, beginning with aircraft. At cruising altitude, 747 carries substantial potential energy, calculated as = mgh, where is the aircrafts mass, is gravitational acceleration, and is its height. For 747 at 40,000 feet, this equates to about 41 gigajoules. Potential energy is also pivotal in energy storage systems. Pumped-storage hydroelectricity is prime example, where water is pumped uphill to reservoir during off-peak hours. When demand rises, the water is released to generate electricity, effectively converting stored potential energy into kinetic energy, which then powers turbines. In urban settings, potential energy is harnessed in elevators and cranes. Elevators utilize counterweights to minimize energy consumption during vertical movement, while cranes employ potential energy to lift heavy loads efficiently. These examples underscore the significance of potential energy in modern engineering and its role in sustainable energy solutions. Reflect on how these principles can inspire innovations in energy efficiency and storage, contributing to greener future. 9. Lets revisit our road trip scenario to delve into the role of potential energy. Even though Boston and New York are at sea level, the journey between them involves elevation changes that significantly impact energy consumption. As you ascend hills, your vehicle converts kinetic energy into potential energy, stored due to increased height. This process demands extra energy, which is then partly recovered as you descend, converting potential energy back into kinetic energy. However, not all energy is recaptured due to losses from friction and air resistance. Understanding these dynamics is vital for optimizing vehicle efficiency. By analyzing elevation profiles, we can better predict energy requirements and improve fuel economy. This knowledge not only enhances road trip efficiency but also informs the development of smarter navigation systems and more fuel-efficient vehicles. Consider how these principles might be applied to other modes of transport, such as trains or ships, to reduce energy usage and environmental impact. Reflect on potential innovations that could further minimize energy loss, contributing to sustainable transportation solutions. 10. To estimate the energy impact of hills during road trip, consider car traveling at steady 60 mph, encountering 50-foot elevation gain per mile. This incline necessitates additional energy to elevate the vehicle, calculated using the potential energy formula = mgh, where is the cars mass, is gravitational acceleration, and is the height increase. For 1800 kg car, the energy required to climb each hill is approximately 260 kJ. Over 210-mile trip, this accumulates to about 27 MJ. However, descending the hills doesnt fully recover this energy 24 due to energy losses from braking and friction. These calculations highlight the significant energy demands of hilly terrains. By understanding these dynamics, we can develop strategies to optimize fuel efficiency, such as using regenerative braking systems to capture energy during descents. Reflect on how this knowledge can inform route planning and vehicle design to enhance efficiency and sustainability. Consider potential innovations that could further minimize energy loss, contributing to greener future in transportation. 11. Now, lets delve into the impact of air resistance on vehicle energy efficiency. As car moves, it displaces air molecules, creating drag that reduces efficiency. The energy lost to air resistance can be calculated using the formula Eair = 1 2 cd(mair)v2, where cd is the drag coefficient, mair is the mass of displaced air, and is the velocity. For typical car traveling at 60 mph, this results in substantial energy loss. The loss increases with the square of the velocity, meaning higher speeds lead to significantly greater energy expenditure. For instance, Toyota Camry traveling from Boston to New York at 60 mph loses about 133 MJ to air resistance, but this increases to 236 MJ at 80 mph. Understanding these dynamics is crucial for enhancing vehicle efficiency. Designing more aerodynamic vehicles with lower drag coefficients can mitigate these losses. Additionally, maintaining optimal speeds can drastically improve fuel efficiency. Reflect on how these principles can be applied to everyday driving to reduce energy consumption and environmental impact. Consider potential innovations in vehicle design and technology that could further minimize air resistance and contribute to sustainable transportation solutions. 12. Lets delve deeper into the energy lost to air resistance during road trip. For Toyota Camry traveling from Boston to New York at 60 mph, approximately 133 MJ is lost to air resistance. This significant amount highlights the impact of aerodynamics on fuel efficiency. Increasing speed exacerbates this issue. At 80 mph, the energy loss rises to about 236 MJ, demonstrating that higher speeds demand more energy to overcome air resistance. This is because the energy loss is proportional to the square of the velocity. In addition to air resistance, rolling resistance also plays role. This is the energy lost due to tire deformation and road friction. For typical car, rolling resistance can account for around 54 MJ over the same distance. Understanding these factors is crucial for improving vehicle efficiency. Designing more aerodynamic vehicles and maintaining optimal speeds can significantly reduce energy loss. Keeping tires properly inflated is another simple yet effective way to minimize rolling resistance. Reflect on how these principles can be applied to everyday driving to enhance efficiency and reduce environmental impact. Consider potential innovations in vehicle design and technology that could further mitigate these energy losses, contributing to sustainable transportation solutions. 13. Now, lets wrap up our energy analysis for the road trip from Boston to New York. We start with kinetic energy, about 2 MJ, accounting for stops along the way. Then, theres the 27 MJ for potential energy, spent on climbing hills. Rolling resistance adds another 54 MJ, and air resistance claims significant 133 MJ. Altogether, these factors total 216 MJ of energy used. However, the gasoline used provides 840 MJ, indicating an overall efficiency of roughly 25%. This means only quarter of the fuels energy is utilized for motion, with the rest lost as heat and other inefficiencies. This analysis underscores the inefficiencies in automobile energy usage. By grasping these components, we can pinpoint areas for improvement. For instance, enhancing aerodynamics, reducing rolling resistance, and optimizing vehicle weight can boost efficiency. Reflect on how these insights can inform future innovations in vehicle design and technology. Consider how better understanding these dynamics can lead to more sustainable and efficient transportation solutions, reducing our environmental impact. 14. To enhance transport efficiency, we can apply fundamental physics principles. Reducing air resistance is key, as it significantly impacts energy consumption. By traveling at lower speedsopting 25 for 60 mph instead of 80 mphwe diminish drag and boost fuel efficiency. Streamlined vehicle designs also help cut through air more effortlessly. Public transportation offers another efficient alternative, as buses and trains inherently possess lower per capita drag. Maintaining vehicles with properly inflated tires is crucial, as it reduces rolling resistance and conserves energy. Innovative technologies, like regenerative braking, capture energy during braking, which can be reused, enhancing overall efficiency. This technology is particularly effective in stop-and-go traffic, maximizing energy savings. Looking ahead, concepts such as vacuum tunnels and magnetic levitation could revolutionize transportation by drastically reducing air and rolling resistance. While these ideas are futuristic, they demonstrate the potential for significant advancements in energy efficiency. Reflect on how these principles and innovations might be integrated into everyday travel. Consider their role in reducing environmental impact and fostering sustainable transportation solutions. 15. In conclusion, weve delved into the core concepts of mechanical energy, emphasizing kinetic and potential energy, and the effects of air resistance and friction. These elements are pivotal in understanding energy consumption in transportation. We learned that kinetic energy, calculated as 1 2 mv2, is essential for vehicle motion. Meanwhile, potential energy, expressed as mgh, becomes significant when navigating hills or elevated terrains. Air resistance, quantified by 1 2 cdAρv2, plays crucial role in energy efficiency, especially at higher speeds. Minimizing this resistance can markedly enhance fuel economy. Our energy analysis of road trip revealed that out of the 840 MJ provided by gasoline, only 216 MJ is used for motion, highlighting the need for more efficient engines and innovative technologies. Looking ahead, well explore the concept of heat and its impact on energy systems. encourage you to review your lecture notes and reflect on how these principles can be applied to real-world challenges. Thank you for your attention, and look forward to continuing our exploration of physics in the next session. Response of LongWriter-V-7B-DPO: **1. Kinetic Energy** Lets continue our exploration of mechanical energy by examining kinetic energy, an essential element of transportation. The formula for kinetic energy is Ekin = 1 2 mv2, where is the mass and is the speed. This formula reveals kinetic energys direct relationship with both mass and velocity squared. Imagine baseball traveling at 100 mph. Its kinetic energy can be calculated using the formula, revealing the significant energy involved in fast-moving objects. Now, consider car with four passengers traveling from Boston to New York. The kinetic energy involved in this journey highlights the extensive energy requirements in transportation. Beyond calculations, understanding kinetic energys role is vital. It affects how vehicles accelerate, brake, and navigate, influencing both safety and efficiency. Recognizing these dynamics encourages us to critically consider transportation systems energy use and environmental impact. As we move forward, think about how kinetic energy considerations might lead to advancements in more efficient and sustainable transport methods. Reflect on the broader implications for energy use and conservation in our daily lives. **2. Mechanical Energy** Transportation is major player in the U.S. energy scene, using up about 28% of the nations energy resources. In 2001, transportation sector energy consumption was roughly 30 Exajoules annually, accounting for approximately one-third of the U.S. CO2 emissions. Grasping the mechanics of transportation is essential to tackle energy use and environmental concerns effectively. Within transportation, the kinetic and potential energy involved in vehicles movement are crucial. Kinetic energy relates to moving vehicles, impacting acceleration, speed, and braking. In contrast, potential energy arises from height or position, like when car climbs hill. Both types of energy are interwoven with the forces of friction and air resistance, which dissipate energy and affect efficiency. 26 Analyzing these energy forms helps us critically assess the efficiency and sustainability of our transportation methods. As we delve deeper, consider how solid foundation in these mechanical principles can inspire innovations for more energy-efficient future. Reflect on the potential to minimize environmental impact while maximizing energy use in transportation systems. **3. Kinetic Energy** Lets delve deeper into the concept of kinetic energy, which is crucial for understanding transportation. The formula for kinetic energy is Ekin = 1 2 mv2, where is the mass and is the speed. This formula reveals that kinetic energy is directly proportional to the mass and the square of the velocity. Imagine baseball traveling at 100 mph. Its kinetic energy can be calculated to appreciate the energy of fast-moving objects. Now, consider car with four passengers on journey from Boston to New York. The kinetic energy involved highlights the significant energy requirements in transportation. Kinetic energy plays vital role in transportation by influencing everything from fuel efficiency to emissions. Understanding these energy dynamics encourages critical thinking about how we can enhance transportation systems to make them more efficient and environmentally friendly. Reflect on how these principles might inspire innovations in the design and operation of vehicles. For instance, think about how reducing cars mass or modifying its speed can substantively affect its kinetic energy. How might these changes lead to greater fuel efficiency and lower emissions? Grasping these concepts not only enhances appreciation for mechanical principles but also encourages us to envision sustainable future. **4. Transport Energy Example: Road Trip** Lets examine practical example of transport energy using road trip from Boston to New York. This journey covers about 210 miles and requires Camry with four passengers. To begin, we calculate the energy consumption. The cars fuel efficiency is 30 miles per gallon, and gasoline contains roughly 120 megajoules per gallon. Thus, for this trip, the Camry will consume 7 gallons of gasoline, totaling approximately 840 megajoules of energy. But where does all this energy go? Part of it is used to overcome kinetic energythe energy of motionwhile the car travels at speeds of around 60 miles per hour. The remaining energy is used to counteract forces like friction and air resistance, which work to slow the car down. This example prompts us to ponder: Is the full 840 megajoules truly necessary? Are there ways to optimize energy use? By reflecting on these questions, we can explore strategies to enhance efficiency and sustainability in transportation. Understanding energy expenditure in road trips allows us to critically evaluate transportation systems. It invites us to consider how reducing friction, optimizing speed, and improving fuel efficiency could lead to substantial energy savings. Such insights are vital for developing more sustainable transportation methods. As we proceed, think about how these principles can be applied to other forms of transport. How might they help us craft future with lower energy costs and smaller environmental footprint? **5. Potential Energy** Now, lets turn our attention to potential energy, crucial component of mechanical energy. Potential energy is the energy stored in an object due to its position or configuration. classic example is ball placed atop hillits height confers potential energy, which can be converted into kinetic energy as it rolls down the hill. Grasping the conservation of energy is essential. This principle tells us that energy cannot be created or destroyed, only transformed from one form to another. As the ball rolls, its potential energy diminishes, and kinetic energy increases. At the same time, the force of gravity acts upon the ball, driving its descent and converting energy from one form to another. Another instance is stretched spring. The potential energy stored in the spring is due to its deformed state. When released, this energy is transferred into kinetic energy as the spring unravels. These examples illustrate how potential energy manifests and evolves. By exploring these principles, we gain insights into energy efficiency and sustainability. Understanding these dynamics is vital for developing systems that minimize energy waste and maximize output. 27 As we proceed, think about applying these concepts to technological innovations. How can the principles of potential energy and conservation be harnessed to promote more sustainable future? Reflect on these possibilities as we delve deeper into the interplay of energy forms. **6. Potential Energy, Forces, and Work** Lets delve into the connection between potential energy, forces, and work. Consider mass under the influence of force = kx, which is spring force arising from potential energy function (x). The negative sign indicates that the force tends to reduce potential energy. Newtons second law, = ma = mx, describes the force as the mass times its acceleration. This equation reveals how forces influence the motion of objects, altering their kinetic energy. When force acts over distance, it performs work. The work done by force is given by = (cid:82) (x) dx. In the case of spring, the work performed equals the change in potential energy, = . Conservation of energy is pivotal. It states that the total energy, the sum of kinetic energy Ek and potential energy , remains constant in the absence of external dissipative forces. Mathematically, Ek + = constant. This principle is fundamental in many areas of physics and engineering, as it allows us to analyze complex systems by tracking energy flow and conservation. Reflect on how these principles can be applied to real-world scenarios, such as oscillating systems or mechanical devices. How can an understanding of forces and potential energy aid in designing more efficient systems? As we proceed, consider these applications and the broader implications for energy efficiency and sustainability. **7. Potential Energy and Vectors** Now, lets delve into the role of vectors in potential energy and force expressions. When objects move along line, we use one-dimensional vector, = mx, to depict the force. This vector form emphasizes the direction and magnitude of the force acting on an object. In two or three dimensions, we employ three-dimensional vectors to fully capture the forces effect. three-dimensional vector force is expressed as = ma = d2x The potential energy landscape varies in complexity with dimensions. For system with potential energy function (x, y, z), the force can be expressed as gradient vector: = = (cid:16) dt2 = (mx, my, mz). (cid:17) x , y , z . r2 ˆr. This equation illustrates how key example is gravitational force, given by = = GM gravity acts to decrease potential energy, always pointing towards the center of mass. Understanding vector representations of potential energy and forces allows us to analyze complex systems, such as planetary orbits and mechanical structures. How can the principles of vector calculus and potential energy aid in solving real-world engineering challenges? Reflect on these applications as we continue to explore the connections between these mathematical concepts and their significance in physics and beyond. **8. Potential Energy: Applications** Lets examine some practical applications of potential energy. Consider an airplane at high altitude. The potential energy an airplane possesses is given by = mgh, where is the mass, is the acceleration due to gravity, and is the height. For 747 traveling at 900 km/h, this potential energy can reach an impressive 11 gigajoules at an altitude of 40,000 feet. Potential energy is equally important on smaller scale. Take, for example, water pumps that lift water uphill to storage tanks. This process converts electrical energy into potential energy, allowing the water to be stored until needed. Similarly, elevators and cranes utilize potential energy to lift loads against gravity, showcasing the versatility of potential energy in both engineering and everyday life. These examples highlight the significance of potential energy in both everyday applications and large-scale industrial processes. Understanding potential energy not only helps in appreciating the efficiency of various machines but also prompts us to think creatively about energy storage and utilization in new technologies. As we proceed, consider how these principles can be applied to sustainable energy solutions. How 28 can the understanding of potential energy contribute to developing more efficient energy systems? Reflect on these possibilities as we continue to explore the dynamic interplay between energy forms and their applications in the world around us. **9. Back to the Road Trip** Lets return to our road trip scenario, where we calculated an energy expenditure of 840 megajoules for 4000 lb car traveling at 60 mph from Boston to New York. Both cities are at sea level, so does potential energy play role here? Surprisingly, even at sea level, potential energy is significant due to the roads elevation profile. As you travel, the roads elevation changes can alter the cars potential energy. Climbing hill increases potential energy, while descending allows some energy recapture through kinetic energy. On our typical road trip, minor elevation changes occur, particularly on highways like I-95, which have noticeable elevation gains. These variations in elevation mean that potential energy is not just theoretical concept but practical consideration in energy accounting. Taking potential energy into account can influence how we approach fuel efficiency. Understanding these energy dynamics encourages us to think critically about optimizing vehicle efficiency and considering the natural landscapes impact on energy use. As we continue, think about how these principles can be applied to other real-world situations. How can recognizing potential energy help us in everyday activities or in the design of efficient transportation systems? Reflect on these possibilities and their potential to enhance our understanding of energy in the world around us. **10. Estimate Effects of Hills** When planning road trip from Boston to New York, examining the impact of hills on energy use is essential. Even with constant speed of 60 mph, elevation changes significantly affect vehicles energy consumption. Each mile gained in elevation requires approximately 50 feet of elevation gain. Assuming this scenario, 27 megajoules of energy are needed just to tackle the hillsthis calculation is based on the energy cost of climbing hill, mgh, where is the mass, is the acceleration due to gravity, and is the height gained. This energy is partly recovered when descending, but not entirely, due to friction and other losses. Thus, some energy is recaptured on the way down, not all of it is regained. The implications for energy use are noteworthy. Even minor hills can result in substantial portion of the total energy expenditure during journey. This highlights the need to consider elevation changes when evaluating energy efficiency in driving. These calculations encourage critical thinking about route planning and energy efficiency. As we delve deeper into energy use in transportation, think about how overcoming hills affects overall fuel consumption and what strategies could reduce this impact. How might engineering solutions or driving habits be improved to address these challenges? **11. Air Resistance and Friction** During road trip, dealing with air resistance is an inevitable challenge that hampers cars efficiency. As vehicle moves, it interacts with air molecules, creating resistance that reduces fuel efficiency. This air resistance, or drag, is calculated using the formula Eair = 1 2 cd(mair)v2, where cd is the drag coefficient, mair is the mass of air displaced, and is the velocity of the vehicle. The drag coefficient varies with vehicles design; for typical cars, cd is approximately 1/3. This formula reveals that energy lost to air resistance is directly linked to the vehicles speed and the density of the air. At higher speeds, the energy loss escalates significantly. Streamlining cars design can substantially decrease this energy loss. By reducing the drag coefficient and minimizing surface area, vehicles can cut down on air resistance and improve fuel efficiency. This principle is evident in the aerodynamic designs of modern vehicles. Understanding these dynamics not only highlights the importance of engineering in enhancing vehicle efficiency but also encourages us to think critically about optimizing energy use in transportation. As we proceed, consider how these principles can be applied to create more sustainable transportation 29 2 cd(AD)ρv2, we can estimate this energy loss. methods. How might these ideas influence the future of car design and other forms of travel? Reflect on these possibilities and their potential to transform our approach to energy efficiency in the coming years. **12. Total Energy Lost to Air Resistance** Now, lets delve into the energy lost due to air resistance during road trip from Boston to New York. Using the formula derived earlier, Wair = 1 The drag coefficient (cd) for typical car is about 0.33. For journey of 330 kilometers at speed of 27.7 meters per second, the total energy lost to air resistance is approximately 133 megajoules. But how does this stack up with other energy expenditures during the trip? Consider that rolling resistance and hills each consume around 54 and 27 megajoules, respectively. Compared to the 210 megajoules total energy available from the gasoline burned, significant portion is attributed to air resistance. This analysis highlights the importance of reducing air resistance to enhance fuel efficiency. Streamlining cars design, increasing tire pressure, and maintaining moderate speed can mitigate this energy loss. Exploring these strategies offers promising avenues to optimize vehicle efficiency. As we wrap up this lecture, think about how these insights might be applied to real-world transportation challenges. How can we harness these principles to foster more sustainable travel options? Reflect on these possibilities and their potential to transform our approach to energy efficiency in the years ahead. **13. Final Energy Accounting** Lets recap the various energy expenditures during our hypothetical road trip from Boston to New York. We began by accounting for kinetic energy, estimating about 2 megajoules necessary for maintaining speed and managing stoplights. Adding to this, the energy required to conquer hills amounts to around 27 megajoules, considering an average elevation gain of 50 feet per mile. Rolling resistance also claims approximately 54 megajoules, emulating 1% grade, while air resistance incurs substantial 133 megajoules, assuming constant speed of 60 mph. The total energy usage for this journey is roughly 216 megajoules. Its crucial to recognize that these calculations are based on 25% efficient internal combustion engine, with 840 megajoules of gasoline energy consumed during 330 km trip. This energy accounting highlights the impact of various factors on fuel efficiency. It directs our attention to optimization possibilities, such as enhancing engine efficiency, reducing air resistance, and exploring alternative propulsion systems. As we analyze city driving conditions, which are heavily influenced by acceleration, rolling resistance, and stoplights, we must consider how these elements differ from long highway trips. City driving tends to consume more energy due to frequent stopping and starting. This examination of energy use in transportation prompts us to contemplate future innovations. How can we refine our approach to energy efficiency in vehicles? Reflect on these potential advancements and their possible transformation of our relationship with energy. **14. Reducing Transport Energy Costs** Now, lets explore how to cut down on transport energy costs. key piece of advice is to drive at lower speeds, as air resistance (Wair) is proportional to the square of the speed. Thus, choosing speed of 60 mph instead of 80 mph can significantly cut down on energy use. Designing vehicles to be more streamlined is another effective strategy. By reducing the drag coefficient (cd) and the vehicles cross-sectional area (A), we can greatly lessen air resistance. Additionally, mass transit systems offer sustainable solution by carrying more passengers, thereby reducing the energy required per person. Proper tire inflation is often overlooked but is crucial for reducing rolling resistance. Ensuring tires are adequately inflated can enhance fuel efficiency by decreasing the force needed to roll the tires. Modern engines, like those in Toyota hybrids, also play vital role. They optimize the energy used during acceleration and deceleration, improving overall efficiency. Regenerative braking systems are 30 another feature that capture energy during braking, storing it for future use. Looking to the future, technologies such as vacuum tunnels and space-based railways offer theoretically near-zero energy solutions. Although not yet practical, these concepts hold promise for future transportation. Implementing these strategies can lead to substantial energy cost reductions and more sustainable future. As you consider these ideas, think about their application in your daily life. How can you contribute to energy efficiency in transportation? Reflect on these possibilities and their potential to transform our approach to energy use in the years ahead. **15. Lecture Summary and Next Steps** In todays lecture, we delved into mechanical energy, starting with the fundamentals of kinetic and potential energy and their roles in transportation. We examined how factors like air resistance and friction impact energy efficiency during road trip. Understanding these concepts is essential as they directly influence fuel consumption and emissions. We covered strategies to reduce energy costs, such as maintaining optimal speed, enhancing vehicle design, and utilizing advanced engine technologies. Our aim is to spark practical applications in everyday driving and future innovations. Next, we will explore the topic of heat, critical area in understanding energy efficiency and thermodynamics. This new journey will build on the mechanical energy principles we just discussed, promising to be both engaging and thought-provoking. Review your notes and reflect on the connections between these subjects as you prepare for the upcoming lecture. Your participation and engagement will be key as we continue to explore these vital topics."
        }
    ],
    "affiliations": [
        "Singapore University of Technology and Design",
        "Tsinghua University"
    ]
}