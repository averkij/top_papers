{
    "paper_title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
    "authors": [
        "Huaxiaoyue Wang",
        "Sunav Choudhary",
        "Franck Dernoncourt",
        "Yu Shen",
        "Stefano Petrangeli"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers."
        },
        {
            "title": "Start",
            "content": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement Huaxiaoyue Wang1, Sunav Choudhary2, Franck Dernoncourt2, Yu Shen2, Stefano Petrangeli2 1Cornell University, 2Adobe Research yukiwang@cs.cornell.edu, {schoudha, dernonco, shenyu, petrange}@adobe.com 6 2 0 2 6 1 ] A . [ 1 7 4 7 1 1 . 1 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design dataa collection of real-world designs that implicitly captures designers principlesto learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset shows that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers. 1. Introduction Graphic design serves as powerful form of visual communications, where stylistic choices influence mood and perception. Recent advances have enabled everyday users to generate visually appealing designs from natural language instructions and assets [19, 22, 52]. Yet, in practice, graphic design is rarely one-shot process. Designers often iterate through multiple stylistic directions, task that remains time-consuming and challenging for non-experts. Thus, the ability to improve designs stylistically based on language instructions, as shown in Fig. 1, is equally important."
        },
        {
            "title": "Computational works for graphic designs have studied",
            "content": "layout generation [12, 16, 17, 26, 49, 55, 62], design completion [12, 23], typography synthesis [10, 46], and more. closely related area is design improvementjudging designs and improving layouts for aesthetics. Existing methods primarily focus on spatially rearranging elements to improve visual appeal, but they do not condition such edits on design styles [11, 14, 24, 28, 29, 31]. Meanwhile, recent works demonstrate the effectiveness of leveraging pretrained knowledge in Vision Language Models (VLMs) for layout generation [7, 27, 37, 45, 56], opening opportunities for language-conditioned design tasks. However, Fig. 1 shows that directly prompting VLMs for stylistic improvements often produces edits that lack details and diversity, even though they may implicitly encode design principles during pretraining. We posit that this limitation stems from the VLMs pretrained knowledge being too general and lacking alignment with specific domain data. Our key insight is to leverage existing design data to explicitly learn design knowledge and use it to guide stylistic improvement. Collections of real-world designs often include designer-provided tags such as abstract or elegant. Each design reflects the designers underlying stylistic principles, providing rich source for learning design knowledge. However, directly using these designs as input to VLMs is ineffective because designs sharing the same tag can still significantly differ from each other visually as shown in Fig 1, making it challenging to extract finegrained, actionable knowledge. To address this, we propose PRISM (PRior-Informed Stylistic Modification), framework that effectively learns and utilizes design knowledge base via three-stage process: style space partitioning, style knowledge extraction, and prior-informed edits at inference time. (1) Partitioning the Style Space: In order to handle variances and capture diversity within style, we compute pairwise distances that capture semantic and spatial relationships between all designs before identifying visually coherent clusters via K- (2) Extracting Style Knowledge: With all the medoids. clusters, the goal is to learn set of compact, actionable knowledge that can be used by the downstream design im1 Figure 1. user provides design to improve and natural language instruction. PRISM leverages existing design data to generate diverse improvements that align with the requested style. In contrast, approaches that solely rely on VLMs pretrained knowledge on styles produce outputs that fail to match the design data. provement module. Thus, we employ contrastive summarization process that aligns extracted knowledge with designs in the same cluster while remaining discriminative from others. (3) Prior-Informed Editing During Inference: To make improvements that align with the original data during inference, we integrate learned knowledge as priors into Retrieval-Augmented Generation (RAG) pipeline, enabling proportional retrieval of relevant design knowledge for style-aware edits. Our key contributions are: 1. method for leveraging design data to construct design knowledge base for design improvement. We aggregate the data into meaningful subsets before distilling each into concise, distinctive design knowledge. 2. An inference mechanism for style-aware improvement that retrieves appropriate design knowledge proportionally to the original data distribution. 3. Experiments on the Crello dataset showing that PRISM achieves highest average style alignment (0.847 0.999) compared to the best baseline. User studies validate this result, and show that designers prefer PRISM across multiple design axis. 2. Related Works Graphic Design Improvement. Fundamentally, we tackle the problem of design improvement, which inherently involves evaluating the current design. Prior works have solely focused on design evaluation using heuristics [3, 8, 15, 33, 35, 57], deep learning [28, 29, 48, 61] or large pretrained models such as VLMs [14, 31]. Other works aim to enhance designs aesthetics by improving layouts [11, 20, 24, 36, 41, 58]. However, their methods primarily adjust the assets positions and sizes and do not condition edits on specific design style. In contrast, our work focuses on stylistic design improvement by leveraging learned design knowledge to edit colors, fonts, assets, and layouts in order to achieve the requested style. LLMs and VLMs for Graphic Design. LLMs and VLMs have shown initial success in generating layouts given assets [2, 57, 27, 37, 45, 51, 53, 56], but their generation process is not steered by design styles. The closest works to ours are VLM-based systems that construct complete designs given combination of natural language and assets [19, 22, 39, 52, 59]. These systems typically adopt hierarchical pipeline, where an image diffusion model generates the background and other modules handle text and layout. Despite supporting mult-modal input, their ability to produce diverse design styles remains limited. For example, IGD [39] can only condition its background on imitating single reference image, while CreatiPoster [59] and BannerAgency [52] heavily rely on detailed textual descriptions of stylistic elements, increasing the prompting burden for everyday users. Our work complements these approaches by enriching the VLM-based systems with learned design knowledge, enabling stylistic improvement that aligns with the provided design data. Knowledge-Augmented Generation. Retrievalaugmented generation improves LLM performance by augmenting the input with relevant information [13, 25]. Our work is closely related to approaches that automatically Figure 2. PRISM Overview. Given design data with style abstract, the (1) Style Space Partitioning stage identifies visually distinctive clusters. Then, (2) Knowledge Extraction focuses on learning concise, actionable knowledge from these clusters. Under contrastive framework, the VLM compares and contrast positive and negative examples before generating the knowledge. We highlight two examples of how positive/negative designs influence specific lines in the guideline. During inference, (3) Prior-Informed Edits proportionally retrieves relevant design knowledge based on the original design data distribution, thereby outputting diverse improvements that also align with data. construct knowledge bases for retrieval [9, 32, 38, 50, 60]. Some works in LLM agents generate knowledge given pair of positive and negative trajectories. To obtain these pairs, Qiao et al. requires simulator to collect agent trajectories as negative examples, while others [9, 32, 50, 60] also depend on reward functions to identify high-reward trajectories as positive examples. Another line of work explicitly train high-level planners that generate guidelines to steer frozen low-level policy [47, 54], but they also require execution reward signals for optimization. These strategies are impractical for design tasks, as we lack simulators and ground-truth reward functions that reflect real-world distributions of user-provided designs. In contrast, our work only leverages an easily acquired collection of high-quality designs and automatically curates positive and negative sets to learn meaningful design knowledge. 3. Approach We introduce PRISM (Prior-Informed Stylistic Modification) to address the test-time adaptation problem of aligning VLMs to domain-specific design data and enabling styleaware design improvements. We assume access to collection of designs, each annotated with stylistic tags (e.g., abstract, elegant). This type of data is accessible from benchmarks (e.g,. Crello [55]) or available as proprietary datasets. PRISM consists of three main stages to leverage this design data, shown in Fig 2. In order to handle variances within style, stage 1 explicitly identify meaningful clusters. Then, each cluster from stage 1 needs to be captured in concise, transferrable form, so stage 2 explicitly learns design knowledge via contrastive learning framework. To effectively utilize the learned knowledge during inference, stage 3 proportionally retrieves the appropriate design data, enabling design improvements that matches the distribution of the provided design data. 3.1. Style Space Partitioning Designs that share the same stylistic tag still have highly varied visuals. Thus, this stage aims to handle this variance and capture diversity within style by organizing the data into visually coherent clusters. This process requires an effective visual distance metric to measure similarity between two designs and suitable clustering algorithm. To capture both semantic and spatial relationships between designs, we adopt the GRAph-based Design (GRAD) distance proposed by Nag et al.. The GRAD distance represents each design as graph, where each vertex corresponds to an image patch and each edge is the cosine distance between patch embeddings from image encoders such as CLIP [40] or DINOv2 [34]. By applying optimal transport to match these graphs, the GRAD distance captures fine-grained structural similarities that distance approaches based on global image embeddings often miss. 3 For clustering, we first aggregate all the designs that have the same style by their stylistic tags before computing the pairwise GRAD distances between all of them. Then, we cluster the designs via the K-medoids algorithm [42], where controls the number of clusters. Each cluster is represented by its medoidthe design closest to all the others in the cluster. We sweep (empirically from 2 to 5) and select the value that yields the highest silhouette score, which measures the cluster quality [44]. 3.2. Style Knowledge Extraction Each cluster identified during the style space partitioning stage is distilled into concise design knowledge for downstream tasks. This knowledge must satisfy two desiderata. First, it should be actionable, offering concrete example attributes for elements such as text and shapes. Second, it should be discriminative, capturing unique type of visual characteristics within the style. We introduce contrastive learning framework. Given cluster to learn, we sort the designs by their distances to the medoid and select positive examples (including the medoid and its nearest neighbors). Other clusters under the same stylistic tag provide discriminative signals, so we construct the negative examples under the same scheme, using negative examples. Empirically, we set = 25 and = 10. Conditioning on these visual examples, the VLM first analyzes the positive designs in detail to identify recurring themes before examining for broader patterns. It repeats the process for the negative examples, focusing on features that discriminate the positives from the negatives. Fig. 2 shows example reasoning outputs during this stage. Finally, the VLM synthesizes its finding into the design knowledge, containing must-have features that capture what most positive designs have in common (e.g,. use large, flat abstract shapes (organic/geometric)), optional attributes that describes what some positive designs share (e.g., add decorations such as lines, dots...), and must-not-have decisions that highlight what makes negative designs different from the positive ones (e.g., do not use gradients, neon effects, or soft watercolor...). After generating the knowledge, we summarize each document into single-sentence via an LLM for efficient retrieval. The resulting knowledge base indexes each entry by its style tag, summary, and the detailed guidelines. 3.3. Prior-Informed Edits the user provides suboptimal deAt inference time, sign and language instruction. Building on RetrievalAugmented Generation (RAG), PRISM first identifies the design styles that align with the instruction. Depending on how many variations the user wants, PRISM retrieve the design knowledge differently. If only one is requested, we compute the Sentence-BERT [43] embedding of the instruction combined with caption of the provided design, then retrieve the knowledge with the closest summary. If multiple variations are needed, we sample knowledge proportionally to the cluster size, ensuring outputs reflect the original data distribution. For the downstream design improvement, we adapt the hierarchical pipeline in prior works COLE [22] and OpenCole [19]. The retrieved design knowledge is incorporated into the prompt of VLM planner that generates concrete design plan based on the original design and user instructions. This plan is then used by an image diffusion model to produce the edited design. 4. Quantitative Experiments 4.1. Setup Datasets. We evaluate PRISM on the benchmark graphic design dataset Crello [55]1, which contains 19479 designs for training, 1852 for validation, and 1971 for test. We combine the training and validation set to be the reference design data. Each design has list of associated keywords, which we use to identify the design style. There are 15 major design styles, each containing at least 100 designs, that our approach should align to: abstract, artistic, bright, cheerful, classic, colorful, corporate, dynamic, elegant, floral, geometric, graphic, modern, natural, simple. With these styles, we evaluate how well method is able to improve design given natural language instruction, such as make my design look more abstract. We expect that performant method would output stylistic designs that resemble the data. Details on how we identify the design style from keywords and construct the design data are in Appendix. Baselines. Fig. 3 visualizes the input and output of the baselines. We compare PRISM against prior work OpenCole [19], which we slightly modify to be able to improve designs instead of only generating new designs. In addition to language instructions, it now also conditions on the users original design to generate design plan before using that plan to edit the design via an image diffusion model. Note that OpenCole does not explicitly receive any design knowledge as input. To test our hypothesis that LLMs internal knowledge is misaligned from design data, we compare against Prompt2Diverse, which directly prompts an LLM to generate diverse design knowledge about design style without accessing any data. Here, matches the number of design knowledge that PRISM generates for the same style. For baselines that use design data, we compare against Data2One and Data2Diverse. When learning knowledge for style, they only randomly sample = 25 examples instead of identifying meaningful design clusters like PRISM. This set up also means that 1Original images from Crello dataset by Yamaguchi et al. available at https://huggingface.co/datasets/cyberagent/ crello, licensed under CDLA-Permissive-2.0 license 4 Figure 3. Main Results. We report the average fidelity and diversity with standard error across 15 styles. PRISM achieve the highest value for both metrics. On the left, we also visualize different methods input/output. Figure 4. Qualitative Results. We show 3 styles, each representative of PRISMs different performance. abstract is one where PRISM achieves the highest rank for both fidelity and diversity. artistic is where one is high (fidelity). modern is where both ranks are lower. both approaches lack PRISMs contrastive learning framework because they only have positive examples. In terms of outputs, Data2One learns one design knowledge per style, while Data2Diverse tries to infer diverse design knowledge, where matches PRISMs for style. Implementation Details. For all approaches, we use gpt-4.1 to extract design knowledge and generate design plans. We use gpt-image-1 for making the design improvement conditioning on the design plan and the original design. For PRISMs data curation step, the GRAD distances is computed using CLIP [40] embeddings from CLIP-ViT-L-14-laion2B-s32B-b82K model provided by OpenCLIP [18]. For each design style, the test set is constructed by sampling 3 test design and 3 programmatically perturbed test design from 3 other design styles. This results in 18 test designs to improve per style. For each test design, all approaches generate the same amount of design improvements, resulting in around 180 improved designs per style. More details are in Appendix. Metrics. For each style in the design data, there is collection of real designs {Xi}. Each method also has corresponding set of generated design improvements {Yj}. Note that is the same size across all approaches for style for fair comparisons. We use the fidelity and diversity metric proposed by Naeem et al. to evaluate how well the two real and generated distribution matches. This metric relies on visual distance metric d(, ) to measure the distance between two designs, so we set it to be the same GRAD distance used in Section 3.1. Fidelity measures the degree to which the generated samples resemble the real ones and concretely counts how many real-sample neigh5 rank of 4.07/5. Its poor performance suggests that directly prompting the LLM to generate variants of design knowledge within style leads to greater misalignment from realworld design data. Interestingly, although the OpenCole baseline does not explicitly inject any design knowledge during downstream design improvement, its performance is comparable to Data2One and Data2Diverse, which both have access to data. We closely analyze this phenomenon in Section 4.3. Diversity. PRISM achieves the highest diversity of 0.683 and the best rank of 2.64/5 with Data2Diverse being close second. Comparing the rankings reveals two distinct performance groups. Methods that explicitly inject different variants of design knowledgePRISM, Data2Diverse, Prompt2Diverseachieve diversity ranks of 2.64, 2.75, 2.84 respectively. In contrast, methods that either omit design knowledge or inject only one design knowledge per style (OpenCole, Data2One) obtain diversity ranks of 3.27 and 3.49 respectively. The existence of these two groups support our hypothesis that explicitly steering downstream tasks with design knowledge leads to more diverse outputs. In addition, leveraging the design data helps lead to enhances diversity by providing signals aligned with real-world distributions. 4.3. How important is the data curation step? We analyze why the data-driven baselines Data2One and Data2Diverse fail to outperform the baseline OpenCole in fidelity and why PRISM avoids these pitData2One and Data2Diverse learn design falls. knowledge from randomly sampled designs within style. Such sampling scheme creates two issues. First, these samples have high variance. We quantify this variance using the average pairwise distance between example designs as measure of this variance. Fig. 7 show that PRISM has significantly lower average distances of 0.146 compared to the baselines 0.536. Note that Data2One and Data2Diverse have the same metric value because they have the exact same inputs, and Fig. 6 also provides an example of their inputs. Second, these samples do not guarantee meaningful clusters. We run K-medoids on each approachs input before calculating the silhouette score [44], which measures the cluster quality and higher is better. Again, PRISM achieve higher silhouette score of 0.666 compared to the baselines. These numerical differences manifest in the design knowledge that different approaches learn. While PRISM learns concrete, distinct patterns, Data2One is only able to learn general guidelines due to the variance in the input set, while Data2Diverse identifies superfluous subsets. These findings highlight an important insight: data alone does not ensure improvement. Instead, careful incorporation of design data is essential for effective learning. Figure 5. Expected Ranks. We report the expected ranks across all styles. PRISM achieves the best rank in both fidelity and diversity, showing its ability to balance the two metrics. borhood spheres contain Yj, so fidelity := 1 kM (cid:88) (cid:88) j=1 i=1 1[d(Yj, Xi) d(Xi, NNk(Xi))] (1) where NNk(Xi) is the k-th closet real design to Xi. Diversity measures whether the generated samples cover the full variability of the real samples and concretely calculates the ratio of real samples that are covered by the fake samples, so diversity :="
        },
        {
            "title": "1\nN",
            "content": "i=1 (cid:88) 1[j s.t. d(Yj, Xi) d(Xi, NNk(Xi))]. (2) Because each design style has different number of designs , we unify k, which controls the nearest neighbor, to be = αN and α = 0.05. For all reported results, we perform 10,000 bootstrap resamples of the real and generated data to obtain robust estimate of the expected performance. 4.2. Overall Results Fig. 3 reports the average fidelity and diversity, and Fig. 4 shows some qualitative results. We also compute the expected rank to access the relative performance in Fig. 5. Overall, PRISM outperforms other methods in balancing the trade-off between fidelity and diversity. Fidelity. PRISM achieves the highest fidelity of 0.999 and the best average rank of 1.49/5, where 1 represents always being the best, showing that PRISM consistently outperforms baselines in guiding design improvements that resemble the provided data. Meanwhile, Prompt2Diverse performs the worse, with an average fidelity of 0.744 and 6 Figure 6. Qualitative Comparison of Knowledge Learned by Different Data-Driven Approaches. Baselines Data2One and Data2Diverse use randomly sample designs as input, which results in high variance. Conditioning on these, Data2One learns design knowledge that is too general and lacks detail. Data2Diverse infers subsets from the noisy data, resulting in knowledge that contrast on arbitrary decisions. In contrast, PRISM receive inputs that have less variance because of its data curation step, allowing it to learn meaningfully diverse knowledge that results in diverse outputs. PRISM and improves its alignment with the data. We propose leveraging the positive and negative samples to evaluate the current knowledges discriminative power and provide signals for refinement. At high level, the goal is to enhance the knowledge so that it accurately characterizes positive designs while remaining distinct from negative ones. For the set of positive and negative example design, we employ VLM-based judge to evaluate whether each example is well described by the current knowledge. Feedback from false positives and false negatives is aggregated to guide subsequent refinement steps. Additional implemnetation details are in the Appendix. Results. We conduct experiments running 3 refinement iterations. As shown in Fig. 8, fidelity generally increases with each iteration. Notably, all 3 iterations achieve higher fidelity compared to the original knowledge with an average fidelity of 0.965. Meanwhile, the diversity values tend to fluctuate without any significant gain. We provide more indepth discussion and qualitative example illustrating the improvement process in the Appendix. 4.5. Ablation Studies How to best utilize the design clusters during knowledge extraction? We ablate on the type of inputs during the style knowledge extraction stage. Because PRISM learn design knowledge from decent number of positive (i = 25) and negative (j = 10) designs, we empirically include the first 5 designs as individual examples while formatting the remaining examples as collages for positives and negatives reFigure 7. Quantitative Analysis on Data-Drive Baselines Low Fidelity. (Left) computes the average GRAD distance between input examples. Lower intra-distance means that there is less variance in the input. (Right) We run K-medoids on each set of input before computing the silhouette score. higher silhouette suggests that input contains more meaningful subsets. Figure 8. Knowledge Refinement Results. We ran 3 round of knowledge refinement. We report the average fidelity and diversity across 7 styles where PRISMs fidelity is close to baselines. 4.4. How can the contrastive framework iteratively refine PRISM generated knowledge? During knowledge extraction, we can iteratively apply the contrastive framework to refine the knowledge learned by 7 Method PRISM Fidelity Diversity 0.999 0.032 0.684 0.043 PRISM (No Neg) PRISM (No Individual) PRISM (No Collage) 0.941 0.044 0.949 0.048 0.993 0.051 0.684 0.047 0.657 0.038 0.642 0.044 PRISM (No Prop-Retrieve) 0.982 0.034 0.658 0.043 Table 1. PRISM Ablations. We report the average fidelity and diversity across all 15 styles. Figure 9. Aggregated User Study Results. We report the average user preference on each option. The first three questions ask the users which approachs design improvement aligns to the design style in terms of color scheme/decorations/text layouts. The last one ask the user which approachs output look more diverse. spectively. Thus, we explore PRISM (No Neg), which only provides positive examples, PRISM (No Collage), which provides all examples as independent designs, and PRISM (No Individual), which only provides collages as input. Table. 1 show that having the negative examples benefit fidelity as PRISM and other ablations all have higher fidelity compared to the baseline PRISM (No Neg) of 0.965. Meanwhile, for diversity, having both the individual designs and collages seem to lead to slightly higher diversity compared to ones that remove one of the inputs. What is the effect of proportional retrieval during inference? PRISM sample design knowledge proportionally to the original design data distribution, so clusters with more designs are used more frequently. To evaluate this mechanism, we experiment on PRISM(No Prop-Retrieve), which instead samples all appropriate design knowledge uniformly. Table. 1 show that proportional retrieval lead to both higher fidelity (1.003 1.018) and diversity (0.604 0.630). 5. User Study Setup. To evaluate how well human preferences align with our quantitative metric, we conduct user study involving 30 designers on the Prolific crowd-sourcing plat8 form [1]. We investigate whether PRISM can make design improvements that align with the design data compared to the most competitive baseline Data2Diverse (as seen in Fig. 3). Each designer is presented with control and 15 test cases in random order, where each test case corresponds to one of the design styles. For each test case, the designer is provided with the original design, language instruction, two sets of design improvements from PRISM and Data2Diverse respectively (presented in random order, and blindly), and some reference examples to help the designer understand the design style. The designers are asked to compare the two approaches on whether the outputs align with the requested style across different design aspects: color scheme, decorations, text layouts. They also judge which approachs output looks visually more diverse. Details in the Appendix. Results and Analysis. Fig. 9 shows that designers consistently judged PRISM as being more effective in creating designs that are more visually aligned to the requested design style. Designers also choose PRISM 66.2% of the times as the approach with more diverse improvements. We further analyze styles where Data2Diverses quantitative performance was close to PRISMsuch as colorful, dynamic, graphicsshown in Fig. 10 in the Appendix. Although quantitative metrics are similar, the user study reveals that PRISM outperforms Data2Diverse in stylistic alignment, except for color scheme in the colorful style. This outcome is reasonable, as colorful designs are relatively easy to interpret without detailed data analysis. Similarly, users favor PRISM for diversity in most cases except the floral style, where outputs from both methods appear visually similar. 6. Conclusion We investigate the problem of stylistic design improvement using VLMs, where the VLMs pretrained knowledge is often too general and lacks alignment with specific domain data. Our key insight is to leverage existing design data to explicitly learn design knowledge. We present PRISM that first cluster the designs then employs contrastive framework to learn distinctive design knowledge that captures different visual varieties. At inference time, PRISM proportionally retrieves appropriate design knowledge so that the improvements reflect the original data distribution. efficiently strategies We recognize few limitations of PRISM: (1) it currently treats the design data as static set, whereas Future work will design data may evolve over time. incorporating new explore for information and updating design knowledge; the optimal representation of design knowledge may depend on the downstream module. We plan to investigate learning design knowledge adapter that uses downstream execution signals to determine the most effective way to translate design knowledge for specific tasks. (2)"
        },
        {
            "title": "References",
            "content": "[1] Prolific. https://www.prolific.com, 20142024. Accessed: YYYY-MM-DD. 8 [2] Anonymous. Anylayout: Versatile advertising poster layout generation with MLLMs. In Submitted to The Fourteenth International Conference on Learning Representations, 2025. under review. 2 [3] Michael Bauerly and Yili Liu. Computational modeling and experimental investigation of effects of compositional elements on interface and design aesthetics. International Journal of Human-Computer Studies, 64(8):670682, 2006. 2 [4] Steven Bird and Edward Loper. NLTK: The natural language In Proceedings of the ACL Interactive Poster and toolkit. Demonstration Sessions, pages 214217, Barcelona, Spain, 2004. Association for Computational Linguistics. 2 [5] Xiaohui Chen, Yongfei Liu, Yingxiang Yang, Jianbo Yuan, Quanzeng You, Li-Ping Liu, and Hongxia Yang. Reason out your layout: Evoking the layout master from large language models for text-to-image synthesis, 2023. 2 [6] Chin-Yi Cheng, Ruiqi Gao, Forrest Huang, and Yang Li. Colay: Controllable layout generation through multiconditional latent diffusion, 2024. [7] Yutao Cheng, Zhao Zhang, Maoke Yang, Hui Nie, Chunyuan Li, Xinglong Wu, and Jie Shao. Graphic design with large multimodal model. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 24732481, 2025. 1, 2 [8] John G. Byrne David Chek Ling Ngo, Lian Seng Teo. mathematical theory of interface aesthetics. Visual Mathematics, 10(8):00, 2000. 2 [9] Yao Fu, Dong-Ki Kim, Jaekyeom Kim, Sungryull Sohn, Lajanugen Logeswaran, Kyunghoon Bae, and Honglak Lee. Autoguide: Automated generation and selection of contextaware guidelines for large language model agents. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. 3 [10] Yifan Gao, Jinpeng Lin, Min Zhou, Chuanbin Liu, Hongtao Xie, Tiezheng Ge, and Yuning Jiang. Textpainter: Multimodal text image generation with visual-harmony and textIn Proceedings of the comprehension for poster design. 31st ACM International Conference on Multimedia, page 72367246, New York, NY, USA, 2023. Association for Computing Machinery. 1 [11] Sahil Goyal, Abhinav Mahajan, Swasti Mishra, Prateksha Udhayanan, Tripti Shukla, Joseph, and Balaji Vasan Srinivasan. Design-o-meter: Towards evaluating and refining graphic designs. In 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), pages 5676 5686, 2025. 1, 2 [12] Kamal Gupta, Justin Lazarow, Alessandro Achille, Larry Davis, Vijay Mahadevan, and Abhinav Shrivastava. Layouttransformer: Layout generation and completion with selfIn Proceedings of the IEEE/CVF International attention. Conference on Computer Vision, pages 10041014, 2021. 1 [13] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. Retrieval augmented language model preIn Proceedings of the 37th International Confertraining. ence on Machine Learning, pages 39293938. PMLR, 2020. 2 [14] Daichi Haraguchi, Naoto Inoue, Wataru Shimoda, Hayato Mitani, Seiichi Uchida, and Kota Yamaguchi. Can gpts evalIn SIGuate graphic design based on design principles? GRAPH Asia 2024 Technical Communications, New York, NY, USA, 2024. Association for Computing Machinery. 1, 2 [15] Steven Harrington, Fernando Naveda, Rhys Price Jones, Paul Roetling, and Nishant Thakkar. Aesthetic measures for automated document layout. In Proceedings of the 2004 ACM symposium on Document engineering, pages 109111, 2004. 2 [16] Daichi Horita, Naoto Inoue, Kotaro Kikuchi, Kota Yamaguchi, and Kiyoharu Aizawa. Retrieval-augmented layout transformer for content-aware layout generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6776, 2024. 1 [17] Hsiao Yuan Hsu, Xiangteng He, Yuxin Peng, Hao Kong, and Qing Zhang. Posterlayout: new benchmark and approach for content-aware visual-textual presentation layout. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 60186026, 2023. 1 [18] Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John Miller, Hannaneh Hajishirzi, Ali Farhadi, and Ludwig Schmidt. Openclip, 2021. 5 [19] Naoto Inoue, Kento Masui, Wataru Shimoda, and Kota Yamaguchi. Opencole: Towards reproducible automatic graphic design generation, 2024. 1, 2, [20] Shoma Iwai, Atsuki Osanai, Shunsuke Kitada, and Layout-corrector: Alleviating layShinichiro Omachi. out sticking phenomenon in discrete diffusion model. In European Conference on Computer Vision, pages 92110. Springer, 2024. 2 [21] Hawon Jeong, ChaeHun Park, Jimin Hong, Hojoon Lee, and Jaegul Choo. The comparative trap: Pairwise comparisons amplifies biased preferences of llm evaluators, 2025. 1 [22] Peidong Jia, Chenxuan Li, Yuhui Yuan, Zeyu Liu, Yichao Shen, Bohan Chen, Xingru Chen, Yinglin Zheng, Dong Chen, Ji Li, Xiaodong Xie, Shanghang Zhang, and Baining Guo. Cole: hierarchical generation framework for multilayered and editable graphic design, 2024. 1, 2, 4 [23] Kotaro Kikuchi, Ukyo Honda, Naoto Inoue, Mayu Otani, Edgar Simo-Serra, and Kota Yamaguchi. Multimodal markup document models for graphic design completion. In Proceedings of the 33rd ACM International Conference on Multimedia, page 1102211031, New York, NY, USA, 2025. Association for Computing Machinery. 1 [24] Wenyuan Kong, Zhaoyun Jiang, Shizhao Sun, Zhuoning Guo, Weiwei Cui, Ting Liu, Jianguang Lou, and Dongmei Zhang. Aesthetics++: Refining graphic designs by exploring design principles and human preference. IEEE Transactions on Visualization and Computer Graphics, 29(6):30933104, 2023. 1, 2 [25] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen-tau Yih, Tim Rocktaschel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented genIn Advances in eration for knowledge-intensive nlp tasks. Neural Information Processing Systems, pages 94599474. Curran Associates, Inc., 2020. 2 [26] Jianan Li, Jimei Yang, Jianming Zhang, Chang Liu, Christina Wang, and Tingfa Xu. Attribute-conditioned layout gan for automatic graphic design. IEEE Transactions on Visualization and Computer Graphics, 27(10):40394048, 2021. 1 [27] Jiawei Lin, Jiaqi Guo, Shizhao Sun, Zijiang Yang, JianGuang Lou, and Dongmei Zhang. Layoutprompter: Awaken In Advances the design ability of large language models. in Neural Information Processing Systems, pages 43852 43879. Curran Associates, Inc., 2023. 1, 2 [28] Xin Lu, Zhe Lin, Hailin Jin, Jianchao Yang, and James Wang. Rapid: Rating pictorial aesthetics using deep learning. In Proceedings of the 22nd ACM international conference on Multimedia, pages 457466, 2014. 1, [29] Naila Murray, Luca Marchesotti, and Florent Perronnin. Ava: large-scale database for aesthetic visual analysis. In 2012 IEEE conference on computer vision and pattern recognition, pages 24082415. IEEE, 2012. 1, 2 [30] Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi, and Jaejun Yoo. Reliable fidelity and diverIn Proceedings of the sity metrics for generative models. 37th International Conference on Machine Learning, pages 71767185. PMLR, 2020. 5 [31] Sayan Nag, Joseph, Koustava Goswami, Vlad Morariu, and Balaji Vasan Srinivasan. Agentic design review system, 2025. 1, 2, 3 [32] Hadi Nekoei, Aman Jaiswal, Patrice Bechard, Oleh Shliazhko, Orlando Marquez Ayala, Mathieu Reymond, Massimo Caccia, Alexandre Drouin, Sarath Chandar, and Alexandre Lacoste. Just-in-time episodic feedback hinter: Leveraging offline knowledge to improve llm agents adaptation, 2025. 3 [33] David Chek Ling Ngo and John Byrne. Another look at model for evaluating interface aesthetics. International Journal of Applied Mathematics and Computer Science, 11(2): 515535, 2001. 2 [34] Maxime Oquab, Timothee Darcet, Theo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual features without supervision. arXiv preprint arXiv:2304.07193, 2023. [35] Peter ODonovan, Aseem Agarwala, and Aaron Hertzmann. IEEE Learning layouts for single-pagegraphic designs. transactions on visualization and computer graphics, 20(8): 12001213, 2014. 2 [36] Xufang Pang, Ying Cao, Rynson W. H. Lau, and Antoni B. Chan. Directing user attention via visual flow on web designs. ACM Trans. Graph., 35(6), 2016. 2 [37] Sohan Patnaik, Rishabh Jain, Balaji Krishnamurthy, and Mausoom Sarkar. Aesthetiq: Enhancing graphic layout design via aesthetic-aware preference alignment of multimodal large language models. In Proceedings of the Com10 puter Vision and Pattern Recognition Conference, pages 2370123711, 2025. 1, 2 [38] Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen. Agent planning with world knowlIn The Thirty-eighth Annual Conference on edge model. Neural Information Processing Systems, 2024. [39] Yadong Qu, Shancheng Fang, Yuxin Wang, Xiaorui Wang, Zhineng Chen, Hongtao Xie, and Yongdong Zhang. Igd: Instructional graphic design with multimodal layer generation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 1821818228, 2025. 2 [40] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 87488763. PmLR, 2021. 3, 5 [41] Soliha Rahman, Vinoth Pandian Sermuga Pandian, and Matthias Jarke. Ruite: Refining ui layout aesthetics using transformer encoder. In Companion Proceedings of the 26th International Conference on Intelligent User Interfaces, page 8183, New York, NY, USA, 2021. Association for Computing Machinery. 2 [42] LKPJ Rdusseeun and Kaufman. Clustering by means of In Proceedings of the statistical data analysis medoids. based on the L1 norm conference, neuchatel, switzerland, page 28, 1987. 4 [43] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks, 2019. [44] Peter J. Rousseeuw. Silhouettes: graphical aid to the interpretation and validation of cluster analysis. Journal of Computational and Applied Mathematics, 20:5365, 1987. 4, 6 [45] Jaejung Seol, Seojun Kim, and Jaejun Yoo. Posterllama: Bridging design ability of language model to content-aware layout generation. page 451468, Berlin, Heidelberg, 2024. Springer-Verlag. 1, 2 [46] Wataru Shimoda, Daichi Haraguchi, Seiichi Uchida, and Kota Yamaguchi. Towards diverse and consistent typography In Proceedings of the IEEE/CVF Winter Congeneration. ference on Applications of Computer Vision (WACV), pages 72967305, 2024. 1 [47] Shuzheng Si, Haozhe Zhao, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, and Maosong Sun. goal without plan is just wish: Efficient and effective global planner training for long-horizon agent tasks, 2025. 3 [48] Sou Tabata, Hiroki Yoshihara, Haruka Maeda, and Kei Yokoyama. Automatic layout generation for graphical deIn ACM SIGGRAPH 2019 Posters, New sign magazines. York, NY, USA, 2019. Association for Computing Machinery. 2 [49] Jerry Talton, Lingfeng Yang, Ranjitha Kumar, Maxine Lim, Noah Goodman, and Radomır Mˇech. Learning design patterns with bayesian grammar induction. In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology, page 6374, New York, NY, USA, 2012. Association for Computing Machinery. the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22, pages 49955001. International Joint Conferences on Artificial Intelligence Organization, 2022. AI and Arts. 1 [50] Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, Fang Wu, He Zhu, et al. Agent kb: Leveraging cross-domain arXiv preprint experience for agentic problem solving. arXiv:2507.06229, 2025. 3 [51] Zecheng Tang, Chenfei Wu, Juntao Li, and Nan Duan. LayoutNUWA: Revealing the hidden layout expertise of large language models. In The Twelfth International Conference on Learning Representations, 2024. 2 [52] Heng Wang, Yotaro Shimose, and Shingo Takamatsu. Banneragency: Advertising banner design with multimodal llm agents, 2025. 1, 2 [53] Haoran Wang, Bo Zhao, Jinghui Wang, Hanzhang Wang, Huan Yang, Wei Ji, Hao Liu, and Xinyan Xiao. Sega: stepwise evolution paradigm for content-aware layout generation with design prior. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 19321 19330, 2025. 2 [54] Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, XWang, and Sujian Li. MPO: Boosting LLM agents with meta plan optimization. In Findings of the Association for Computational Linguistics: EMNLP 2025, pages 39143935, Suzhou, China, 2025. Association for Computational Linguistics. [55] Kota Yamaguchi. Canvasvae: Learning to generate vector graphic documents. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 54815489, 2021. 1, 3, 4, 2 [56] Tao Yang, Yingmin Luo, Zhongang Qi, Yang Wu, Ying Shan, and Chang Wen Chen. Posterllava: Constructing unified multi-modal layout generator with llm, 2024. 1, 2 [57] Mathieu Zen and Jean Vanderdonckt. Towards an evaluation of graphical user interfaces aesthetics based on metrics. In 2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS), pages 1 12. IEEE, 2014. 2 [58] Jiahao Zhang, Ryota Yoshihashi, Shunsuke Kitada, Atsuki Osanai, and Yuta Nakashima. Vascar: Content-aware layout generation via visual-aware self-correction. arXiv preprint arXiv:2412.04237, 2024. 2 [59] Zhao Zhang, Yutao Cheng, Dexiang Hong, Maoke Yang, Gonglei Shi, Lei Ma, Hui Zhang, Jie Shao, and Xinglong Wu. Creatiposter: Towards editable and controllable multilayer graphic design generation, 2025. 2 [60] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. Expel: Llm agents are experiential learners. In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence and Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence and Fourteenth Symposium on Educational Advances in Artificial Intelligence. AAAI Press, 2024. [61] Nanxuan Zhao, Ying Cao, and Rynson W. H. Lau. What characterizes personalities of graphic designs? ACM Trans. Graph., 37(4), 2018. 2 [62] Min Zhou, Chenchen Xu, Ye Ma, Tiezheng Ge, Yuning Jiang, and Weiwei Xu. Composition-aware graphic layout gan for visual-textual presentation designs. In Proceedings of 11 PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement"
        },
        {
            "title": "Table of Contents",
            "content": "7. Iterative Knowledge Refinement . . 7.1. Overall Approach . . 7.2. Implementation Details . . . . . 8. User Study 8.1. Setup . . 8.2. Per-Style Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9. Quantitative Experiments . . . . . 9.1. Design Data . . 9.2. Implementation Details . . 9.3. Per-Style Results . 9.4. Iterative Knowledge Refinement Details . . . . . . . . . . . . . . . . . . . . . . . 1 1 1 2 2 2 2 2 3 3 3 7. Iterative Knowledge Refinement The knowledge extraction stage described in Sec. 3.2 aims to extract compact, discriminative design knowledge for each cluster identified during the style space partitioning stage ( Sec. 3.1). By contrasting these positive and negative examples, the VLM synthesizes design knowledge that captures unique type of visual characteristics within style. This contrastive framework naturally extends to provide feedback signals for iteratively improving the extracted knowledge. 7.1. Overall Approach The goal of knowledge refinement is to refine the learned knowledge so that it is more data-aligned and discriminative. Thus, we introduce iterative knowledge refinement, which leverages the contrastive signals to identify weaknesses and suggest improvements. Specifically, the process involves detecting misaligned designs, generating feedback, and refining the knowledge accordingly. Let k0 denote the initial knowledge for cluster. Let D+ = {X +} be the set of positive designs belonging to this cluster and = {X } be the set of negative designs from other clusters. Algorithm 1 shows the overall computation. Identify Misaligned Designs. To identify where the current knowledge fails to align to the data, we introduce Design Classifier c(k, X) that determines whether design aligns with the knowledge k. Ideally, discriminative knowledge should align with designs that are pos1 Algorithm 1 PRISM Iterative Knowledge Refinement Initial Knowledge k0, Positive Examples D+, Input: Negative Examples D, Refinement Iterations , Design Classifier c(k, X), Feedback Generator (k, X), Knowledge Refiner r(k, H) for = 0 to do Feedback History Ht // Collect feedback from false negatives FNt = {X + D+ c(kt, +) = 0} Ht Ht {f (kt, +) + FNt} // Collect feedback from false positives FPt {X c(kt, ) = 1} Ht Ht {f (kt, ) FPt} // Refine knowledge using feedback kt+1 r(kt, Ht) end for Return kT itive examples (so + D+, c(k, +) = 1) and distinguish designs that are negative examples (so D+, c(k, ) = 0). We run classifiers on all examples to identify the false negatives and false positives. Implementation details are provided in Sec. 7.2. Generate Feedback. Given the set of false negatives and false positives, we collect feedback on how to improve the current knowledge. Thus, we define Feedback Generator (k, X) that analyzes why the design is misclassified before generating actionable advices on how to improve the design. We accumulate all the feedback as for the next step. Refine Knowledge. Given all the feedback H, the goal of the Knowledge Refiner r(k, H) is to analyze all the feedback before editing the current knowledge. This newly refined knowledge is used in the next iteration. 7.2. Implementation Details Design Classifier. To access how well learned design knowledge aligns with design, we formulate the task as multi-class classification problem by asking: which design knowledge does design align with the most strongly? Specifically, each cluster represents class and has an associated learned design knowledge. Naively, we can frame it as multiple choice problem where we ask VLM to choose among set of design knowledge which one is best describes design. However, as prior works show that pairwise comparison is more reliable [21], we also leverage pairwise comparison to perform multi-class classification. Figure 10. User Study Qualitative Examples. For each style, we show the quantitative metric as well as the average user preferences across different questions. Below each shows the original design, the language instruction, two approachs output (during the study, the user does not know which output corresponds to what approach), and representative examples of style. Specifically, for each pair of design knowledge, we prompt VLM to decide which one best describes design. The design knowledge with the highest amount of pairwise wins is the classification label (tie-breaking randomly). Then, the classifier c(k, X) = 1 if design is classified to align the most with the knowledge and c(k, X) = 0 if design aligns the most with knowledge other than that correspond to other clusters. Hyperparameter. We use gpt-4.1 as the VLM, querying it with temperature 0.3. 8. User Study 8.1. Setup The goal is to evaluate how well do designer preferences align with our quantitative metric by specifically comparing PRISM against the most competitive baseline Data2Diverse. For each test case (each corresponds to design style), the user is provided with the original design to improve, language instruction, two approaches output, and reference examples to help the design understand the design style. Example test cases are shown in Fig. 10. For each style, we select the specific outputs where the two approaches are close in their raw fidelity score. Each test case contains the following questions with options is Better, is Better, Cannot Decide: 1. Which approachs outputs are more aligned with the color scheme of the example {design style} designs? 2. Which approachs outputs are more aligned with the decorations of the example {design style} designs? 3. Which approachs outputs are more aligned with the text effects of the example {design style} designs? 4. Which approachs outputs look more diverse? 8.2. Per-Style Results We report the per-style user preferences in Fig. 11. Among all the styles, 11/15 have the users preferring PRISM over Data2Diverse across all questions. 3/15 (colorful, floral, simple) have the users preferring the baseline Data2Diverse on one or two questions. 1/15 (classic) have the users preferring the baseline Data2Diverse on all questions. 9. Quantitative Experiments 9.1. Design Data We combine the train set (19479) and the validation set (1852) from the Crello [55] dataset to create the overall pool of design. The first step is to identify the design style for each design. Each design has list of associated keywords, where some are about the topics and others are about styles (e.g., quote, bright, colorful, abstract, graphic, font, t-shirt, tshirt, typography). We use NLTKs [4] part of speech tagger to identify keywords that are adjectives before using an LLM (gpt-4.1) to identify adjectives that describe design style. The second step is to identify design styles that have sufficient amount of data: we only keep design styles that have more than 100 designs. The third step is to filter out repetitive designs within each style. Given all the designs that share the design style, we keep the largest designs among ones that have the same title (because they are just different cropped version of the same content) and we also keep the largest designs among ones that have close average perceptual hash (differences less than 10). In the end, we acquired 15 design styles: abstract, artistic, bright, cheerful, classic, colorful, corporate, dynamic, elegant, flo2 Figure 11. User Study Per-Style Preferences. We report the average user preferences for each design style. PRISMs value is close to the baselines (bright, classic, floral). Fig. 13 shows the qualitative example. The design knowledge from the PRISMs Iteration 0 lacks sufficient details, making it misclassify negative example as belonging to the cluster that it represents. Using information about false positive, we generate feedback that aims to make the design knowledge more concrete and discriminative. The resulting design knowledge in Iteration 1 achieves higher fidelity (0.898 0.978) and slightly higher diversity (0.610 0.658). With the new details, emphasis, and new guidelines, this new refined knowledge successfully distinguishes the negative example, where Iteration 0 fails. ral, geometric, graphic, modern, natural, simple. 9.2. Implementation Details Design knowledge is generated at temperature 0.3. During inference, given design to improve and the language instruction, the general pipeline is to generate design plan before generating design improvements conditioning on that plan. For baselines generates zero or only one design knowledge (OpenCole, Data2One), we set the design plan generation temperature to 0.7 to encourage more diversity. Meanwhile, approaches with more than one design knowledge (Prompt2Diverse, Data2Diverse, PRISM) generates design plan at lower temperature of 0.3. Image generation does not have temperature hyperparameter. 9.3. Per-Style Results We present per-style results in Fig. 12. PRISM has the highest fidelity on 11/15 styles and the highest diversity on 5/15 styles, matching the results when we compute the expected ranks across all styles in Fig. 5. 9.4. Iterative Knowledge Refinement Details We study the effect of knowledge refinement on styles where PRISM fails to have the highest fidelity and diversity (colorful, dynamic, graphic, modern) and where 3 Figure 12. Per-Style Average Fidelity and Diversity. We report the bootstrapped average fidelity and diversity for each of the 15 styles. We categorize the styles into 3 categories: (1) PRISM has the highest fidelity and diversity (2)PRISM only has the highest fidelity (but not diversity) (3) other baselines have the highest fidelity and diversity. 4 Figure 13. Iterative Knowledge Refinement Qualitative Example. Left shows design knowledge learned during PRISM iteration 0. It fails to distinguish negative example. From these failure cases, we generate feedback that is used to refine the knowledge. Right shows iteration 1s refined knowledge, where additional details and new guidelines are added. Iteration 1 succeeds in distinguish the same negative example. Bottom row shows qualitative example of improved designs guided by knowledge from different iterations. For the two design knowledge, similarities are highlighted in gray, while edits are highlighted in green."
        }
    ],
    "affiliations": [
        "Adobe Research",
        "Cornell University"
    ]
}