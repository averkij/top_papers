{
    "paper_title": "DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling",
    "authors": [
        "Minzheng Wang",
        "Xinghua Zhang",
        "Kun Chen",
        "Nan Xu",
        "Haiyang Yu",
        "Fei Huang",
        "Wenji Mao",
        "Yongbin Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have made dialogue one of the central modes of human-machine interaction, leading to the accumulation of vast amounts of conversation logs and increasing demand for dialogue generation. A conversational life-cycle spans from the Prelude through the Interlocution to the Epilogue, encompassing various elements. Despite the existence of numerous dialogue-related studies, there is a lack of benchmarks that encompass comprehensive dialogue elements, hindering precise modeling and systematic evaluation. To bridge this gap, we introduce an innovative research task $\\textbf{D}$ialogue $\\textbf{E}$lement $\\textbf{MO}$deling, including $\\textit{Element Awareness}$ and $\\textit{Dialogue Agent Interaction}$, and propose a novel benchmark, $\\textbf{DEMO}$, designed for a comprehensive dialogue modeling and assessment. Inspired by imitation learning, we further build the agent which possesses the adept ability to model dialogue elements based on the DEMO benchmark. Extensive experiments indicate that existing LLMs still exhibit considerable potential for enhancement, and our DEMO agent has superior performance in both in-domain and out-of-domain tasks."
        },
        {
            "title": "Start",
            "content": "DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling Minzheng Wang1,2, Xinghua Zhang3, Kun Chen1,2, Nan Xu2 Haiyang Yu3, Fei Huang3, Wenji Mao2,1* Yongbin Li3* 1 School of Artificial Intelligence, University of Chinese Academy of Sciences 2 MAIS, Institute of Automation, Chinese Academy of Sciences 3 Tongyi Lab, Alibaba Group (cid:66): {wangminzheng2023, wenji.mao}@ia.ac.cn, shuide.lyb@alibaba-inc.com 4 2 0 2 6 ] . [ 1 5 0 9 4 0 . 2 1 4 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have made dialogue one of the central modes of humanmachine interaction, leading to the accumulation of vast amounts of conversation logs and increasing demand for dialogue generation. conversational life-cycle spans from the Prelude through the Interlocution to the Epilogue, encompassing various elements. Despite the existence of numerous dialogue-related studies, there is lack of benchmarks that encompass comprehensive dialogue elements, hindering precise modeling and systematic evaluation. To bridge this gap, we introduce an innovative research taskDialogue Element MOdeling, including Element Awareness and Dialogue Agent Interaction, and propose novel benchmark, DEMO, designed for comprehensive dialogue modeling and assessment. Inspired by imitation learning, we further build the agent which possesses the adept ability to model dialogue elements based on the DEMO benchmark. Extensive experiments indicate that existing LLMs still exhibit considerable potential for enhancement, and our DEMO agent has superior performance in both in-domain and out-of-domain tasks1."
        },
        {
            "title": "Introduction",
            "content": "Under the compelling drive of large language models (LLMs), the development of intelligent language interfaces is undergoing an unprecedented transformation, with dialogue emerging as one of the central modes of human-machine interaction (Ross et al., 2023; Sergeyuk et al., 2024; Wu et al., 2024). The relentless evolution of LLMs has penetrated increasingly complex interaction environments, necessitating an enhancement of the LLMs expressive intelligence (Chang and Chen, *Corresponding authors. 1The code and benchmark are available at https:// github.com/MozerWang/DEMO 1 Figure 1: Overview of task: Dialogue Element Modeling, which focuses on two main aspects: Element Awareness and Dialogue Agent Interaction. We have formulated the comprehensive elements of the Prelude, Interlocution, and Epilogue stages of complete dialogue. 2024; Zhou et al., 2024a) and sharp sensitivity to the pivotal elements within interactions (Tang et al., 2023; Xu et al., 2024). By meticulously analyzing vast dialogue logs, we can gain valuable insights about critical elements of dialogues, such as personality traits, scenarios, and interaction goals. These insights are vital for the ongoing improvement and optimization of human-machine interaction systems. Typically, dialogue is conducted with goaloriented focus, relying upon profound understanding of its core elements (Searle, 1969; Austin, 1975; Watzlawick et al., 2011). Participants navigate towards their goal within the constraints of the scene, utilizing strategy to interact with their environment, ultimately producing content with intent. In reality, the dialogues life-cycle spans from the Prelude through the Interlocution to the Epilogue, encompassing various elements (Schegloff, 2007; Hutchby and Wooffitt, 2008). However, the current datasets inadequately cover these comprehensive aspects (Zhang et al., 2024), only concentrating on dialogue generation within pre-established set-"
        },
        {
            "title": "Goal Scene Persona Utterance Dialogue Analysis Generation Multilingual",
            "content": "DialyDialog (Li et al., 2017) DialogSum (Chen et al., 2021) SODA (Kim et al., 2023a) CharacterGLM (Zhou et al., 2023a) Persona-Chat (Jandaghi et al., 2023) SOTOPIA (Zhou et al., 2024c) Ditto (Lu et al., 2024) DEMO (Ours) Table 1: The overview of our DEMOs characteristics in comparison to those in the related work. DEMO encompasses comprehensive dialogue elements and tasks applicable to both English and Chinese. tings (Liu et al., 2022; Kim et al., 2023a; Zhou et al., 2023a) or predicting selective elements based on dialogue content (Jiang et al., 2023; Ramprasad et al., 2024; Zhou et al., 2023b). The absence of data containing these comprehensive and nuanced dialogue elements hinders the multifaceted modeling and thorough evaluation of dialogue. To tackle the complex challenges, we systematically construct the dialogue framework and define an innovative research task: Dialogue Element MOdeling. Furthermore, we introduce tailordesigned benchmark DEMO to facilitate comprehensive dialogue modeling and assessment. Concretely, our proposed task focuses on two core competencies of models: (1) Element Awareness, which entails reverse engineering to decompose dialogue elements, and (2) Dialogue Agent Interaction, which involves goal-directed multi-turn dialogue modeling driven by elements. We meticulously design data synthesis framework, contributing to novel benchmark for dialogue modeling that encompasses multifaceted elements applicable to both English and Chinese. Besides, inspired by imitation learning (Schaal, 1996; Bain and Sammut, 1999), we amass substantial collection of expert experiences and build DEMO agent endowed with dialogue element modeling. We conduct extensive evaluations of both advanced closed-source and open-source LLMs alongside the DEMO agent and provide an in-depth analysis of their performance in dialogue element modeling. The results indicate that current LLMs still have significant room for improvement in this task. The DEMO agent demonstrates exceptional dialogue element modeling proficiency, exhibits extraordinary social intelligence generalization, and maintains general performance. The contributions of our work can be summarized below: We re-formulate dialogue interaction and propose pioneering research task of Dialogue Element Modeling, focusing on element awareness and dialogue agent interaction to model the comprehensive dialogue process. We innovate the dialogue element construction framework to develop novel, comprehensive benchmark for dialogue element modeling, crafting the DEMO agent for this task. Through extensive experiments, we conduct broad evaluation of current mainstream models, confirming the DEMO agents superior performance in both in-domain and out-ofdomain tasks."
        },
        {
            "title": "2.1 A System of Dialogue Elements",
            "content": "The dialogue is conducted with goal-oriented focus, relying upon deep understanding of its core elements (Searle, 1969; Austin, 1975; Watzlawick et al., 2011). Participants strategically navigate towards their objectives within the scenes constraints, engaging with their environment to produce content with clear intent. The life-cycle of dialogue spans from the prelude through the interlocution to the epilogue, encompassing various dialogue elements (Schegloff, 2007; Hutchby and Wooffitt, 2008). In the prelude, the focus is on the motivation and necessary elements of the dialogue (Goffman, 1981; Schiffrin, 1994), which include the participants backgrounds, the time and place, the topic, and the goals of both parties. During the interlocution, attention is given to the elements intrinsic to each response, such as the intentions participants aim to convey, their current emotions and feelings, and the dialogue strategies employed (Goffman, 1981; Brown and Levinson, 2 1987). The epilogue involves summarizing the entire dialogue, assessing the fulfillment of both parties goals, and examining the flow of information throughout the dialogue (Schegloff, 1973; Drew and Holt, 1998). For detailed dialogue element system, please refer to Figure 3. By analyzing the elements of these stages, deeper understanding of the dialogues structure and dynamics can be achieved, thereby facilitating comprehensive dialogue modeling."
        },
        {
            "title": "2.2 Task",
            "content": "The task of dialogue element modeling focuses on two main aspects: Element Awareness and Dialogue Agent Interaction. Specifically, (1) Element Awareness examines the models ability to analyze complete dialogue, determining whether it can reverse-engineer elements such as goal, persona, and scene from the entire conversation and analyze elements at the utterance level. (2) Dialogue Agent Interaction assesses the models goal-oriented interaction capability, evaluating whether it can achieve its goal within given environment through limited number of interaction rounds."
        },
        {
            "title": "2.2.1 Element Awareness",
            "content": "The Element Awareness primarily focuses on offline single-turn inference. Given an entire dialogue, it aims to model the key elements that contribute to the conversation. It has four tasks: (1) Goal Recognition, (2) Persona Modeling, (3) Scene Reconstruction, and (4) Utterance Mining. Goal Recognition This task tends to attain the goal elements from the given dialogue D. Dialogues are arguably goal-driven (Searle, 1969; Austin, 1975), and this task aims to identify the behavioral motivations of participants using the model πϕ. Specifically, the model needs to identify each persons dialogue goal g1 and g2, and the extent to which those goals are achieved. This process can be formally defined as πϕ(g1, g2, sD). Persona Modeling The task requires constructing the persona of the two dialogue participants from the given dialogue D. Personality, experiences, educational background, and interests often influence the manner of interaction (Grice, 1975; Austin, 1975), establishing mapping relationship between persona and dialogue content. This task requires the model to infer from effect to cause, as well as reverse modeling persona from dialogue content. Specifically, based on the dialogue content D, the model πϕ aims to infer persona p1 and p2, including the gender, age, personality, speaking style, hobby, and background of the two participants. This task can be formally defined as πϕ(p1, p2D). Scene Reconstruction This task requires reasoning and summarizing scene elements from the given dialogue D. The context specifies the dialogue topic, interaction type, and the relationship and familiarity between the participants, crucial elements for making the dialogue more dynamic and nuanced (Reeves and Nass, 1996; Pickering and Garrod, 2004). Specifically, this task requires the model πϕ to reconstruct the pre-existing relationship, interaction type, and dialogue topic before the conversation starts, as well as to deduce the information flow throughout the dialogue and summarize the conversation for each participant. This task can be formalized as: πϕ(SD). Utterance Mining The task involves the extraction of utterance-level implicit information from given dialogue D. In dialogues, each response typically conveys rich information (Goffman, 1981; Brown and Levinson, 1987), with participants employing conversational strategies, expressing standpoints and emotions, and aiming to realize their intentions for dialogue goal attainment. Specifically, given the content of dialogue D, the model πϕ is required to extract the intention, sentiment, emotion, stance, and strategy expressed by particular utterance. This task can be formalized as follows: πϕ(UD)"
        },
        {
            "title": "2.2.2 Dialogue Agent Interaction",
            "content": "The Dialogue Agent Interaction refers to the twoparty goal-directed online multi-turn dialogue interaction in language space. This task encompasses wide range of interaction types, both cooperative and non-cooperative, including persuasion, argument, empathy, negotiation, and more. It can be regarded as an incomplete information game (Reif, 1984). It examines the dialogue interaction capability of the model in modeling dialogue content driven by dialogue elements through dynamic inference. This task can be formulated as Markov Decision Process (MDP) (Bellman, 1957). State The persona, goal, scene, and dialogue history in each episode denote the state. We predefined diverse episodes to serve as the initial state. Some elements in the state are invisible, such as the other partys goal and background information, whose visibility depends on the familiarity between the parties. As the interactions progress dynamically, the dialogue history is continuously 3 Figure 2: Overview of our DEMO synthesis framework, which consists of five steps: (1) Goal and Scene Distillation, (2) Persona Design, (3) Conflict Assessment, (4) Dialogue Generation, (5) Quality Control. The process of DEMO Agent train is also shown in this figure. updated, thereby evolving the states while the persona, goal, and scene stay unchanged. The global state at timestep is represented as Dt, which includes the dialogue content generated after the t-th turn along with other constant dialogue elements. Meanwhile, local states tied to specific sub-action sets are enhanced by combining the global state Dt with the history of the previous t-1 dimensional sub-action choices. Action The interaction unfolds between two players, A1 and A2. At each turn t, according to the observation of the interaction history, the player selects an action that consists of one utterance Ut generated by one of the players. Transition In our setting, the transition function adds the utterance to the interaction history while the persona, goal, and scene stay unchanged in state representation. The dialogue history can be represented as an alternating sequence of utterances generated by two players, denoted by {U1, U2, U3, ..., Ut 1, Ut}. The interaction repeats until the dialogue goal is achieved or the maximum number of turns is reached. Reward After each round, reward function can be called on the current state to quantify how well each player has been doing. The design of the reward function is critical and diverse. In our setting, we only consider the reward of the last interaction turn. To comprehensively examine the models dialogue interaction capabilities, we devised multidimensional reward framework. This framework articulates detailed scoring criteria and ranges for each dimension, utilizing the prompt GPT-4o as reward function to evaluate the dialogue. We assess the following four dimensions: (1) Goal Achievement (0-10): the extent to which the dialogue goals of both parties are fulfilled; (2) Believability (0-10): the extent to how well participants comprehend and align with dialogue elements; (3) Skillfulness (010): the ability of participants to analyze dialogue history, mine utterances, and provide appropriate responses; (4) Realistic (0-10): the extent to which the response content appears human-like and vivid, as opposed to being virtual and overtly machinegenerated."
        },
        {
            "title": "3.1 Overview",
            "content": "DEMO is our newly developed benchmark specifically designed for modeling and evaluating the dialogue element modeling capabilities of LLMs. It includes both Chinese and English languages. To evaluate element awareness, we have total of 4,000 evaluation samples, with maximum of 26 dialogue turns and an average of 18.3 turns, covering 23 distinct dialogue elements. Each of the four tasks contains 1,000 test samples. In terms of dialogue agent interaction, DEMO provides 1,000 episodes that cover wide array of cooperative and non-cooperative interaction types, including persuasion, argument, empathy, and negotiation, among others. Examples of specific tasks from the evaluation set are illustrated in Appendix D."
        },
        {
            "title": "3.2 Construction Framework for Benchmark",
            "content": "Our framework is depicted in Figure 2. We follow the structured dialogue system to sequentially annotate the elements of prelude, interlocution, and epilogue. First, based on Goal and Scene Distillation and Persona Design, we generate the three prelude elements: goal, scene, and persona. Then, through the Conflict Assessment, we ensure that the 4 Model Proprietary LLM GPT-4o Claude-3.5-Sonnet GPT-4o-mini Claude-3.5-Haiku Open-sourced LLM Qwen2-72B-Instruct Llama-3.1-70B-Instruct Backbone LLM Qwen2-7B-Instruct Llama3.1-8B-Instruct DEMO Agent DEMO-Qwen2-7B DEMO-Llama3.1-8B Element Awareness Dialogue Agent Interaction Overall Goa. er. Sce. tt. Avg Goa. Bel. Ski. Rea. Avg 5.975 5.979 5.802 5.492 5.357 5.559 4.051 4.145 3.586 3.858 4.406 3.643 6.167 6.221 5.748 6. 5.702 6.078 7.308 6.243 7.002 6.304 6.921 7.051 5.875 5.647 5.534 5.431 5.596 5.593 8.190 7.571 7.551 7. 8.447 7.223 9.181 9.174 9.082 9.115 9.204 7.914 8.614 8.432 8.316 8.402 8.699 7.222 8.537 8.840 8.163 7. 8.175 6.753 8.631 8.504 8.278 8.212 8.631 7.278 6.793 6.599 6.449 6.358 6.608 6.154 5.306 5. 3.981 3.287 5.459 5.403 6.347 6.523 5.244 5.189 6.698 5.831 8.112 6. 6.895 5.519 6.278 4.974 6.996 5.623 5.828 5.335 6.625 8.864 6.534 5.229 1.075 1.567 0.797 0.752 0.752 1.178 1.586 1.067 0.797 - 6.543 5.623 6.341 7.688 6.945 0.077 0.652 0.752 1.140 0.819 1.114 1.522 1.496 1.404 2.084 1.006 3.946 - 3. 6.378 7.707 8.073 5.906 7.914 7. 8.063 7.864 6.008 7.926 7.015 Table 2: The results of various LLMs on the DEMO. The highest score among different LLMs is highlighted in bold, and the second highest is underlined. And values represent the improvement over the baseline. Element Awareness has four tasks:(1) Goa: Goal Recognition, (2) Per: Persona Modeling, (3) Sce: Scene Reconstruction, and (4) Utt: Utterance Mining. Dialogue Agent Interaction assesses the performance from four dimensions: (1) Goa: Goal Achievement, (2) Bel: Believability,(3) Ski: Skillfulness,(4) Rea: Realistic. Overall: The overall score is the average of the element awareness and dialogue agent interaction. combined prelude elements are coherent. Subsequently, using the coherent elements, we generate the corresponding interlocution and epilogue elements through Dialogue Generation. Finally, after rigorous Quality Control, we revise and inspect the data to establish the final benchmark. The following are details. Goal and Scene Distillation In this initial stage, we distillate the goals and scenes from the given dialogue. By leveraging an instance-driven paradigm, we diversify data from the large-scale dialogue corpus. We utilize SODA (Kim et al., 2023a) and LCCC (Wang et al., 2020) as our seed corpora, which include millions of English and Chinese dialogues encompassing various aspects of social commonsense. Specifically, we employ Qwen272B-Instuct to extract each participants goals and the conversation scene from each dialogue. Finally, we get 2.6 Million goal and scene data. Persona Design In parallel with the previous phase, we established comprehensive and diverse persona collection. The creation of personas is divided into two parts: (1) Designing the persona attributes pool and (2) Inspiring prompting. Referring to (Zhou et al., 2023a, 2024c; Chen et al., 2024; Yang et al., 2024b), we consider the following attributes: name, gender, age, Big Five traits (McCrae and John, 1992), moral values (Graham et al., 2011), social skills (Yang et al., 2024c), personal values (Schwartz, 1992), and decision style (Scott and Bruce, 1995). Based on these characteristics, we combine them and then leverage Qwen2-72B-Instuct for more detailed persona modeling. By prompting the LLM with diverse web texts, as (Chan et al., 2024) suggests, we generate wide-ranging selection of personas. Ultimately, the LLM produces detailed information on each persons background, hobbies, education, occupation, culture, relationships, and speaking style. At this stage, we have modeled 200,000 diverse personas. Conflict Assessment Before generating dialogues, we must ensure the quality of our gathered prelude element, including scene, goal, and persona. We rely on LLM to assess the coherence and consistency of these combinations, checking for issues like character identity contradictions, misalignment between persona and goal, or unsuitable pairings of dialogue participants. To facilitate this process, we employ self-reflection techniques where the model is prompted to articulate its reasoning and evaluation results. For combinations deemed reasonable, we further instruct the model to provide additional details about the relationship and familiarity between participants, as well as the mode of communication. At this stage, we retain only 30% of the considered reasonable combinations. To manage data distribution effectively, we categorize all combinations into ten types based on the dialogue goal and extract the relevant combinations accordingly. Dialogue Generation Upon establishing reason5 able combinations, we proceed to generate interlocution and epilogue elements. Leveraging the LLMs role-play capabilities (Zhou et al., 2023a, 2024c; Chen et al., 2024), we prompt it to create dialogues that align with specified persona, goal, and scene. We also prompt the advanced LLMs to analyze each utterance with its associated intention, sentiment, emotion, stance, and strategy, culminating in comprehensive output that includes the information flow and dialogue summary. To form our benchmark, we curate 1,800 distinct combinations, utilizing the more advanced GPT-4o model for generation. Quality Control To ensure the accuracy of benchmark annotations, we employ three-step verification process: (1) Advanced-LLM Annotation: Two of the most advanced LLMs, GPT-4o and Claude3.5-Sonnet, independently review and validate the quality of annotations. They examine each entry, editing any unreasonable or low-quality labels to maintain consistency and accuracy. (2) Voting: We implement the voting method to finalize the benchmark. (3) Manual Check: After the voting process, We engage two Ph.D students to further examine and assess the quality of data annotation following our pre-established quality control standards. After multiple rounds of data quality checks, we format the element to define the final benchmark."
        },
        {
            "title": "3.3 DEMO Agent Training",
            "content": "Humans have the ability to learn efficiently through observing and imitating the behavior of others (Schaal, 1996; Ross et al., 2011; Torabi et al., 2018). Drawing inspiration from this, we propose enhancing the performance of LLMs in dialogue element modeling tasks by integrating behavioral learning methods. This approach centers on acquiring insights through interactions with expert models and developing an imitation policy. Behavioral learning, also known as behavior cloning (Bain and Sammut, 1999; Ross and Bagnell, 2010; Hanna and Stone, 2017; Wang et al., 2024b), is method for extracting and distilling expert policies from high-quality data, particularly from models with advanced capabilities. In the context of dialogue element modeling, this method involves gaining an understanding of element awareness in singleturn reasoning and achieving nuanced expression in multi-turn interactions. During the benchmark construction process, we accumulated substantial and diverse collection of unlabeled data, which will serve as the tasks state source to enhance dialogue Human Goa. Per. Sce. Utt. Avg. Rater1 Rater2 0.801 0.749 0.873 0.767 0.719 0.775 0.747 0.792 0.821 0. Table 3: The Kappa consistency results between LLM annotations and two human raters on different elements modeling. After excluding all elements overlapping with the benchmark, selected batch of unlabeled data was curated. Specifically, GPT-4o was employed as the expert model to simulate dialogue modeling on analogous tasks, thus circumventing the reliance on costly human expertise. Through single-turn and multi-turn interactions with the expert model, we successfully amassed wealth of expert experience, which will be utilized to refine and update the models policy. We specialize the language model πθ towards dialogue element modeling with the expert experience L. The process of policy updating is efficiently executed through Low-Rank Adaptation (LoRA) (Hu et al., 2022)."
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "Models We evaluate ten advanced LLMs, including API-based LLMs: GPT-4o, GPT-4o-mini (Hurst et al., 2024), Claude3.5-Sonnet (Anthropic, 2024b), Claude3.5-Haiku (Anthropic, 2024a) and Opensourced LLMs: Qwen2-72B-Instruct, Qwen27B-Instruct (Yang et al., 2024a), Llama3.1-70BInstruct, Llama3.1-8B-Instruct (Dubey et al., 2024). Evaluation Metric Evaluating the unpredictable behaviors of LLMs, traditional metrics such as BLEU and Rouge-L may yield inaccurate responses. Recent research (Zhang et al., 2023; Zheng et al., 2023; Kim et al., 2023b) indicates that the GPT-4 evaluator demonstrates high consistency with human evaluation while reducing costs, making it reasonably reliable annotator. Building on these considerations and following these work (Perez et al., 2022; Zhou et al., 2024c; Wang et al., 2024a), we prompt GPT-4o as judge to evaluate the models output based on the golden answer for the element awareness task from several aspects, scoring from 0 to 10. For the detailed prompts, please refer to the Appendix C. Implement Details To ensure the stability of the evaluation, we set the temperature of the evaluator to 0. For element awareness, we set the temperature of the LLM to 0 to ensure reproducibility. For dia6 logue agent interaction, we set the temperature of the LLM to 1 to encourage diversity. We use fixed version of the above models to help reproducibility, and please refer to the Appendix A. For API-Based LLMs, we directly utilize the Azure API for testing. As for open-source models, we conduct experiments accelerated by the vLLM framework (Kwon et al., 2023). The details about training are shown in Appendix B. All the experiments are conducted on server with 8A100 80GB."
        },
        {
            "title": "4.2 Main Results",
            "content": "We assess ten advanced LLMs on the DEMO benchmark. The main results are shown in Table 2. Model Analysis GPT-4o shows the best overall performance, maintaining great performance across all dimensions. Analyzing from the perspective of parameter size, the models performance aligns with the Scaling Law, indicating that models with larger parameters can more effectively extract features and possess stronger expressive capabilities, whereas models with smaller parameters perform worse. Additionally, the gap between open-source and closed-source models is narrowing. For instance, large parameter open-source models like Qwen have achieved state-of-the-art performance in dialogue agent interaction tasks, with overall performance differences from GPT-4o being minimal. Task Analysis There remains significant room for improvement in the overall performance of current models, particularly in tasks involving feature perception. Accurately and directly modeling various elements (such as persona modeling) from dialogue content is still challenging, potentially requiring multi-step reasoning or additional clues. In dialogue agent interaction tasks, current LLMs exhibit excellent expressive capabilities, adeptly adhering to settings and generating relatively realistic dialogue content. Humans are inherently social, striving to achieve social objectives in daily interactions. Goal achievement is crucial feature of intelligence; thus, the ability to perceive targets and collaborate to achieve individual goals reflects models higher-order capabilities. However, their ability to achieve self-set goals through multi-turn interactions requires enhancement. DEMO Agent By learning through expert experience imitation, the DEMO agent has achieved significant improvements across two different backbones, with an average task improvement of 0.9. Specifically, the agent utilizing the LLaMA backbone achieved SOTA performance in element awareness tasks. Meanwhile, the agent built on the Qwen backbone secured the second-highest score, surpassed only by GPT-4o. The DEMO Agent has also surpassed or performed on par with models with larger parameters, such as Claude-3.5-Sonnet and the Qwen2-72B-Instruct. This demonstrates the effectiveness of imitation learning and expert experience. However, this method has performance ceiling limited by the capabilities of the expert model. Fully leveraging additional modeling cues to develop the capacity between feature perception and intelligent expression will be primary focus of our future work. we also use Kappa score (Fleiss, 1971) to measure our annotation quality. Data Quality In Section 3.2, it is mentioned that our data annotation process includes advanced LLMs annotation and manual checks. The data quality inspection process is performed by two experienced annotators, with consistency Kappa value of 0.84 between them. Their Kappa consistency results with different elements annotated by the LLM are shown in Table 3. The LLM shows high consistency with the two annotators, demonstrating performance comparable to humans. Additionally, we conducted manual verification of the data, achieving an accuracy rate of 91.17%. These results have all validated the quality of our test data."
        },
        {
            "title": "4.3 How about the out-of-domain",
            "content": "performance? The DEMO agent has demonstrated impressive results in dialogue element modeling within the domain. However, the question remains: can this capability extend to tasks beyond that domain? To evaluate the generalization ability of the dialogue element modeling, we selected SOTOPIA (Zhou et al., 2024c) as our testing environment. SOTOPIA assesses social intelligence through tasks encompassing various social interactions, including competition, accommodation, and persuasion. In this environment, two LLMs are prompted to act as role-playing social agents, engaging with each other through verbal, non-verbal, and action-based communication. SOTOPIA also designed sevendimension framework to capture the complexity of what makes social interactions successful. For each task, agents are scored along each designed dimension at the end of an interaction. The results are shown in Table 4. All our DEMO Agents have shown remarkable generalization capabilities in social intelligence tasks, with notable"
        },
        {
            "title": "Overall",
            "content": "Qwen2-7B-Instruct DEMO-Qwen2-7B Llama3.1-8B-Instruct DEMO-Llama3.1-8B -0.05 -0.02 -0.50 -0.19 0.00 0.00 -0.01 0.00 0.73 0.82 -0.16 0.29 1.83 2.32 -0.60 0.85 3.41 4.52 2.21 2. 6.07 6.40 3.39 3.77 8.64 8.94 8.63 8.41 2.95 3.28(0.33) 1.85 2.29 (0.44) Table 4: Evaluation results on SOTOPIA hard episodes, which scored from seven social dimensions: believability (BEL), relationship (REL), knowledge (KNO), secret (SEC), social rules (SOC), financial and material benefits (FIN), and goal completion (GOA). The overall score is the average of the seven social dimensions reflecting the overall social intelligence. GPT-4o rates each dimension."
        },
        {
            "title": "HHH",
            "content": "Qwen2-7B-Instruct DEMO-Qwen2-7B Llama3.1-8B-Instruct DEMO-Llama3.1-8B 69.04 68.37 65.94 66.06 (0.12) 45.70 46.15(0.45) 46.61 45.25 Table 5: The evaluation results of the LLMs general capability and alignment performance, using the accuracy score. performance improvements in the SOTOPIA hard task. This overall enhancement is evident in three key dimensions: relationship handling, knowledge application, and goal completion, which are critical intelligence features. These advancements demonstrate that the model has mastered essential interactive policy through imitation learning, drawing from the modeling experience of expert dialogue elements. As result, its social intelligence capabilities have significantly increased. The model can now understand and respond more effectively to emotions and intentions in complex social scenarios, exhibiting an intelligence level that surpasses the base models."
        },
        {
            "title": "4.4 Does the catastrophic forgetting problem",
            "content": "exist? In addition to confirming the models great performance in dialogue element modeling, evaluating whether the other capabilities remain unaffected is equally crucial. Continued training can sometimes lead to catastrophic forgetting, where the model loses previously acquired knowledge, disrupting its initial alignment. We use the Helpful, Honest, Harmless (HHH) (Askell et al., 2021) dataset to assess the impact on alignment performance. This involves multiple-choice task to measure the models ability to select better answers from two given options. When presented with both options, we calculate the models tendency to favor one answer over the other. To assess the models general capabilities, we employ the MMLU (Hendrycks et al., 2021), using 5-shot evaluation based on next-word prediction. Accuracy serves as the evaluation metric across all three benchmarks. The results are presented in Table 5. From the table, it is evident that DEMO Agents retain the overall capabilities of the base model. Although few did not exhibit enhancements, our models performed comparably to the base model. They did not experience significant issues with catastrophic forgetting, indicating that the dialogue element modeling operates independently of the general capabilities."
        },
        {
            "title": "5 Related Work",
            "content": "We introduce the related work based on the causal relationships generated in dialogues, which is divided into two parts: (1) Dialogue Analysis: from effect to cause, inferring dialogue elements based on the dialogue content. (2) Dialogue Generation: from cause to effect, generating dialogue content according to the dialogue settings."
        },
        {
            "title": "5.1 Dialogue Analysis",
            "content": "The goal of dialogue analysis is to mine and analyze critical elements (such as intent, profiles, summary, etc.) from the dialogue data (Zhang et al., 2024), which can extract actionable insights and drive empowerment. In the era of small language models, dialogue analysis did not form systematic task but was broken down into atomic tasks, such as slot filling and intent classification (Qin et al., 2020; Louvan and Magnini, 2020; Jiang et al., 2023), dialogue summary (Chen et al., 2021; Fabbri et al., 2021; Ouyang et al., 2023; Ramprasad et al., 2024) and persona extraction (Wang et al., 2022; Zhou et al., 2023b), etc. In the era of LLM, recent work (Zhang et al., 2024) performed thorough review and systematized conversation analysis task. There is scarcity of datasets that encompass all essential elements of conversations, making it chal8 lenging to model accurately and evaluate the dialogue background information, which affects the development of dialogue modeling."
        },
        {
            "title": "5.2 Dialogue Generation",
            "content": "The related work on dialogue generation primarily focuses on constructing dialogue datasets and designing steering-based methods for dialogue modeling. Task-oriented dialogue (Rashkin et al., 2019; Sun et al., 2021; Liu et al., 2022) focuses on completing specific tasks, emphasizing task completion rather than generalization. Open-domain dialogue (Li et al., 2017; Wang et al., 2020; Kim et al., 2023a) is mainly designed for \"chit-chat\" between users, with more general tasks and greater focus on immersion. Recently, several role-playing works (Zhou et al., 2023a; Lu et al., 2024; Chen et al., 2024; Yang et al., 2024b; Zhou et al., 2024b) have emerged, which place more emphasis on dialogue engagement and character consistency. However, there is limited guidance for dialogue modeling, and there is lack of reward modeling for goaloriented dialogues during interactions. Inspired by social intelligence work SOTOPIA (Zhou et al., 2024c), we have defined more comprehensive dialogue generation task space, considering more dialogue modeling elements. We evaluate dialogue interaction capabilities through multi-turn online interactions and introduce element awareness tasks to thoroughly assess the models dialogue element modeling ability in both Chinese and English languages."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we redefine the dialogue framework and introduce new research task: Dialogue Element Modeling. This task involves two fundamental capabilities: element awareness and dialogue agent interaction, which enhance the complex modeling and comprehensive evaluation of dialogue systems. We have developed process for constructing dialogue elements and created benchmark, DEMO, which includes comprehensive dialogue elements suitable for both English and Chinese. Additionally, we have developed the DEMO agent specifically for dialogue element modeling. Through extensive experiments, we assess the performance of several advanced LLMs, revealing that there is still room for improvement in our task. Moreover, the results demonstrate that our DEMO agent delivers excellent performance in both in-domain and out-of-domain scenarios."
        },
        {
            "title": "7 Limitations",
            "content": "To improve the quality of DEMO, we employed two state-of-the-art LLMs, GPT-4o and Claude3.5-Sonnet, to annotate and verify our benchmark. Additionally, we engaged two Ph.D. candidates to assess the benchmarks quality. This process is both time-consuming and costly. The performance of our DEMO agent is constrained by the capabilities of the expert model. The interplay between element awareness and intelligent tasks remains insufficiently understood. joint learning approach that integrates reasoning and generation processes could enhance the modeling of dialogue elements. Currently, the full potential of the models capabilities has yet to be realized."
        },
        {
            "title": "References",
            "content": "AI Anthropic. 2024a. Claude 3.5 haiku model card addendum. Claude-3.5-Haiku Model Card. AI Anthropic. 2024b. Claude 3.5 sonnet model card addendum. Claude-3.5-Sonnet Model Card. Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021. general language assistant as laboratory for alignment. arXiv preprint arXiv:2112.00861. John Langshaw Austin. 1975. How to do things with words. Harvard university press. Michael Bain and Claude Sammut. 1999. framework for behavioural cloning. In Proceedings of Machine Intelligence, page 103129. Richard Bellman. 1957. markovian decision process. Journal of mathematics and mechanics, pages 679 684. Penelope Brown and Stephen Levinson. 1987. Politeness: Some universals in language usage. 4. Cambridge university press. Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. 2024. Scaling synthetic data creation with 1,000,000,000 personas. arXiv preprint arXiv:2406.20094. Wen Chang and Yun-Nung Chen. 2024. Injecting salespersons dialogue strategies in large language models with chain-of-thought reasoning. In Findings of ACL, pages 37983812. Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu, Aili Chen, Nianqi Li, Lida Chen, Caiyu 9 Hu, Siye Wu, Scott Ren, Ziquan Fu, and Yanghua Xiao. 2024. From persona to personalization: survey on role-playing language agents. Transactions on Machine Learning Research. Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. 2023. Faithful persona-based conversational dataset generation with large language models. arXiv preprint arXiv:2312.10007. Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang. 2021. DialogSum: real-life scenario dialogue summarization dataset. In Findings of ACL, pages 5062 5074. Sheng Jiang, Su Zhu, Ruisheng Cao, Qingliang Miao, and Kai Yu. 2023. SPM: split-parsing method for joint multi-intent detection and slot filling. In Proceedings of ACL: Industry Track, pages 668675. Paul Drew and Elizabeth Holt. 1998. Figures of speech: Figurative expressions and the management of topic transition in conversation. Language in society, 27(4):495522. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Alexander Fabbri, Faiaz Rahman, Imad Rizvi, Borui Wang, Haoran Li, Yashar Mehdad, and Dragomir Radev. 2021. ConvoSumm: Conversation summarization benchmark and improved abstractive summarization with argument mining. In Proceedings of ACL, pages 68666880. Joseph Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological bulletin, 76(5):378. Erving Goffman. 1981. Forms of talk. University of Pennsylvania. Jesse Graham, Brian Nosek, Jonathan Haidt, Ravi Iyer, Spassena Koleva, and Peter Ditto. 2011. Mapping the moral domain. Journal of personality and social psychology, 101(2):366. HP Grice. 1975. Logic and conversation. Syntax and semantics, 3. Josiah Hanna and Peter Stone. 2017. Grounded action transformation for robot learning in simulation. In Proceedings of AAAI, volume 31. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring massive multitask language understanding. In Proceedings of ICLR. Edward Hu, yelong shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In Proceedings of ICLR. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Ian Hutchby and Robin Wooffitt. 2008. Conversation analysis. Polity. Hyunwoo Kim, Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Bras, Malihe Alikhani, Gunhee Kim, Maarten Sap, and Yejin Choi. 2023a. SODA: Million-scale dialogue distillation with social commonsense contextualization. In Proceedings of EMNLP, pages 1293012949. Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al. 2023b. Prometheus: Inducing fine-grained evaluation capability in language models. In Proceedings of ICLR. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of SOSP. Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. DailyDialog: manually labelled multi-turn dialogue dataset. In Proceedings of IJCNLP, pages 986995. Zeming Liu, Jun Xu, Zeyang Lei, Haifeng Wang, ZhengYu Niu, and Hua Wu. 2022. Where to go for the holidays: Towards mixed-type dialogs for clarificaIn Proceedings of ACL, pages tion of user goals. 10241034. Samuel Louvan and Bernardo Magnini. 2020. Recent neural methods on slot filling and intent classification In for task-oriented dialogue systems: survey. Proceedings of COLING, pages 480496. Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. 2024. Large language models are superpositions of all characters: Attaining arbitrary role-play via self-alignment. In Proceedings of ACL, pages 7828 7840. Robert McCrae and Oliver John. 1992. An introduction to the five-factor model and its applications. Journal of personality, 60(2):175215. Siru Ouyang, Jiaao Chen, Jiawei Han, and Diyi Yang. 2023. Compositional data augmentation for abstractive conversation summarization. In Proceedings of ACL, pages 14711488. Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022. Red teaming language models with language models. In Proceedings of EMNLP, pages 34193448. 10 Martin Pickering and Simon Garrod. 2004. Toward mechanistic psychology of dialogue. Behavioral and brain sciences, 27(2):169190. Libo Qin, Xiao Xu, Wanxiang Che, and Ting Liu. 2020. AGIF: An adaptive graph-interactive framework for joint multiple intent detection and slot filling. In Findings of EMNLP, pages 18071816. Sanjana Ramprasad, Elisa Ferracane, and Zachary Lipton. 2024. Analyzing LLM behavior in dialogue summarization: Unveiling circumstantial hallucination trends. In Proceedings of ACL, pages 1254912561. Hannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan Boureau. 2019. Towards empathetic opendomain conversation models: new benchmark and dataset. In Proceedings of ACL, pages 53705381. Byron Reeves and Clifford Nass. 1996. The media equation: How people treat computers, television, and new media like real people. Cambridge, UK, 10(10):1936. John Reif. 1984. The complexity of two-player games of incomplete information. Journal of computer and system sciences, 29(2):274301. Stéphane Ross and Drew Bagnell. 2010. Efficient reductions for imitation learning. In Proceedings of AISTATS, volume 9, pages 661668. Stephane Ross, Geoffrey Gordon, and Drew Bagnell. 2011. reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of AISTATS, volume 15, pages 627635. Steven Ross, Fernando Martinez, Stephanie Houde, Michael Muller, and Justin Weisz. 2023. The programmers assistant: Conversational interaction with large language model for software development. In Proceedings of IUI, pages 491514. Stefan Schaal. 1996. Learning from demonstration. In Proceedings of NeurIPS, volume 9. Emanuel Schegloff. 1973. Opening up closings. Semiotica. Emanuel Schegloff. 2007. Sequence organization in interaction: primer in conversation analysis. Cambridge University Press. Deborah Schiffrin. 1994. Approaches to discourse. Shalom Schwartz. 1992. Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries. Advances in experimental social psychology. Susanne Scott and Reginald Bruce. 1995. Decisionmaking style: The development and assessment of new measure. Educational and psychological measurement, 55(5):818831. John Searle. 1969. Speech acts: An essay in the philosophy of language. Cambridge University. Agnia Sergeyuk, Sergey Titov, and Maliheh Izadi. 2024. In-ide human-ai experience in the era of large language models; literature review. In Proceedings of IDE Workshop, pages 95100. Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert, Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, and Claire Cardie. 2021. Adding chit-chat to enhance task-oriented dialogues. In Proceedings of NAACL, pages 15701583. Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, Ruifang He, and Yuexian Hou. 2023. Enhancing personalized dialogue generation with contrastive latent variables: Combining sparse and dense persona. In Proceedings of ACL, pages 54565468. Faraz Torabi, Garrett Warnell, and Peter Stone. 2018. Behavioral cloning from observation. In Proceedings of IJCAI, pages 49504957. Minzheng Wang, Longze Chen, Fu Cheng, Shengyi Liao, Xinghua Zhang, Bingli Wu, Haiyang Yu, Nan Xu, Lei Zhang, Run Luo, Yunshui Li, Min Yang, Fei Huang, and Yongbin Li. 2024a. Leave no document behind: Benchmarking long-context LLMs with extended multi-doc QA. In Proceedings of EMNLP, pages 56275646. Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Yonatan Bisk, Graham Neubig, and Hao Zhu. 2024b. SOTOPIA-π: Interactive learning of socially intelligent language agents. In Proceedings of ACL, pages 1291212940. Yida Wang, Pei Ke, Yinhe Zheng, Kaili Huang, Yong Jiang, Xiaoyan Zhu, and Minlie Huang. 2020. large-scale chinese short-text conversation dataset. In Proceedings of NLPCC, pages 91103. Zhilin Wang, Xuhui Zhou, Rik Koncel-Kedziorski, Alex Marin, and Fei Xia. 2022. Extracting and inferring personal attributes from dialogue. In Proceedings of NLP4ConvAI Workshop, pages 5869. Paul Watzlawick, Janet Beavin Bavelas, and Don Jackson. 2011. Pragmatics of human communication: study of interactional patterns, pathologies and paradoxes. WW Norton & Company. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. 2024. Autogen: Enabling next-gen llm applications via multi-agent conversations. In Proceedings of COLM. Junjielong Xu, Ziang Cui, Yuan Zhao, Xu Zhang, Shilin He, Pinjia He, Liqun Li, Yu Kang, Qingwei Lin, Yingnong Dang, et al. 2024. Unilog: Automatic logging via llm and in-context learning. In Proceedings of ICSE, pages 112. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024a. Qwen2 technical report. arXiv preprint arXiv:2407.10671. 11 Model Proprietary LLM GPT-4o Claude-3.5-Sonnet GPT-4o-mini Claude-3.5-Haiku Open-sourced LLM Qwen2-72B-Instruct LLaMA3.1-8B-Instruct Qwen2-7B-Instruct Version Implement gpt-4o-2024-08-06 claude-3-5-sonnet-20241022 gpt-4o-mini-2024-07-18 claude-3-5-haiku-20241022 Qwen2-72B-Instruct LLaMA3.1-8B-Instruct Qwen2-7B-Instruct API API API API vLLM vLLM vLLM Table 6: The detailed versions of our used LLMs. Figure 3: Overview of the system of dialogue elements. Maarten Sap. 2024c. SOTOPIA: Interactive evaluation for social intelligence in language agents. In Proceedings of ICLR."
        },
        {
            "title": "A Involved Model Versions",
            "content": "We provide the detailed version number of all the models we used in our experiments. When we mention each name like GPT-4o or Qwen2-72B in our main section, we actually refer to those model versions in Table 6. Such information helps researchers reproduce our results."
        },
        {
            "title": "B Training Setting",
            "content": "We use qwen2-7b-instruct and llama3.1-8b-instruct as our backbones. Our total batch size is 32, with cut-off length of 8192, and the learning rate is set to 1.0e-4. We train for 3 epochs, using cosine annealing with warm-up ratio of 0.1. For checkpoint selection, we use 10% of the training data as validation set, which is not used in training but only to validate the checkpoints loss. We select the checkpoint with the lowest validation loss. We use the llama-factory framework (Zheng et al., 2024) to assist in our training. Bohao Yang, Dong Liu, Chen Tang, Chenghao Xiao, Kun Zhao, Chao Li, Lin Yuan, Guang Yang, Lanxiao Huang, and Chenghua Lin. 2024b. Simschat: customisable persona-driven role-playing agent. arXiv preprint arXiv:2406.17962. Diyi Yang, Caleb Ziems, William Held, Omar Shaikh, Michael Bernstein, and John Mitchell. 2024c. Social skill training with large language models. arXiv preprint arXiv:2404.04204. Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, and Yongbin Li. 2023. Wider and deeper llm networks are fairer llm evaluators. arXiv preprint arXiv:2308.01862. Xinghua Zhang, Haiyang Yu, Yongbin Li, Minzheng Wang, Longze Chen, and Fei Huang. 2024. The imperative of conversation analysis in the era of llms: survey of tasks, techniques, and trends. arXiv preprint arXiv:2409.14195. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. In Proceedings of NeurIPS, volume 36, pages 4659546623. Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, and Zheyan Luo. 2024. LlamaFactory: Unified efficient fine-tuning of 100+ language models. In Proceedings of ACL, pages 400410, Bangkok, Thailand. Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Pei Ke, Guanqun Bi, Libiao Peng, JiaMing Yang, Xiyao Xiao, Sahand Sabour, Xiaohan Zhang, Wenjing Hou, Yijia Zhang, Yuxiao Dong, Hongning Wang, Jie Tang, and Minlie Huang. 2024a. CharacterGLM: Customizing social characters with large language models. In Proceedings of EMNLP: Industry Track, pages 1457 1476. Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, et al. 2023a. Characterglm: Customizing chinese conversational ai characters with large language models. arXiv preprint arXiv:2311.16832. Wangchunshu Zhou, Qifei Li, and Chenle Li. 2023b. Learning to predict persona information for dialogue personalization without explicit persona description. In Findings of ACL, pages 29792991. Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, and Maarten Sap. 2024b. Is this the real life? is this just fantasy? the misleading success of simulating social interactions with LLMs. In Proceedings of EMNLP, pages 2169221714. Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and 12 GPT4o-as-the-Judge C.1 Dialogue Agent Interaction You are an impartial and harsh judge evaluating conversation quality. Your task is to rigorously and meticulously assess the following dialogue based on specific criteria. [Criteria] 1. goal achievement (0-10): - How well the dialogue participants achieve their goals. - Identify each participants goals from the provided background information. Analyze the progress made towards these goals throughout the conversation. 0 points: Neither participant makes any progress towards their goals. 10 points: Complete success; both participants fully achieve all their goals. 2. believability (0-10): - What the extent to which the dialogue participants understand and align with Background Information. How well these elements are reflected in their expressions. - Two Participants should correctly understand the backgrpund information and perceive goals, and all the responses should not conflict with these elements. For example: speaking style must not conflict with the character portrait, the content of the response must not conflict with the background information, and the content of the response must not conflict with the respective goals. 0 points: Significant inconsistencies or misunderstandings of background information; Scene, Persona, and Goals cannot be inferred from the dialogue content. 10 points: Perfect alignment with all background elements, demonstrating thorough understanding of the conversations context; Background information can be fully deduced from the dialogue content. 3. skillful (0-10): - To what extent can the participants think and generate appropriate responses based on the conversation history. - The participants in the conversation should correctly understand the dialogue history before responding, and then think about the intention, sentiment, emotion, stance, and strategy to be expressed, so as to generate appropriate responses. 0 points: Poor understanding of dialogue history; responses are often inappropriate and lack strategy. 10 points: All responses can fully utilize the conversation strategy, understand the intentions of both parties, and conform to the conversation history. 4. realistic (0-10): - Evaluate how realistic the conversation is, as opposed to being simulated, fictitious or implausible. - The dialogue should feel natural and human-like, mirroring real-life interactions. AI-generated conversations often exhibit certain telltale signs: Excessive politeness or formality, overly detailed or lengthy responses, lack of emotional expression, difficulty with implicit meanings, repetitive phrasing or response patterns, poor conversational flow or awkward transitions. 0 points: Conversation is clearly AI-generated. 5 points: Mix of realistic and artificial elements. 10 points: Entirely believable as conversation between two real people. [Background Information] Time: <time> Location and environment: <location> Dialogue Medium: <talkway> Dialogue Topic: <topic> Participants: <person1> and <person2> Relationship between the dialogue participants: <relationship> Familiarity level between the dialogue participants: <familiarity> Information about <person1>: <person1 bg> Information about <person2>: <person2 bg> [Dialogue Goal] Goal of <person1>: <goal1> Goal of <person2>: <goal2> [Dialogue Content] <dialogue> [Requirement] 1. Reiterate the dialogue content and background information. 2. Analyze how well the dialogue meets each criterion. 3. Provide scores and reasons in JSON format as specified below. 4. Please note that the scoring for each criteria is independent and should not be influenced by each other. [Output Format] ˋˋˋjson { \"goal achievement\": { \"reason\": <reason for goal achievement>, \"score\": <0-10> }, \"naturalness\": { \"reason\": \"<reason for naturalness score>\", \"score\": <0-10> }, \"coherence\": { \"reason\": \"<reason for coherence score>\", \"score\": <0-10> }, \"smoothness\": { \"reason\": \"<reason for smoothness score>\", \"score\": <0-10> } } ˋˋˋ Now, start your evaluation: 13 C.2 Goal Recognition You are an impartial and harsh judge evaluating conversation quality. Your task is to rigorously and meticulously assess the performance of the AI assistant in Dialogue Analysis (Goal) strictly based on specific criteria. [Criteria] - Accuracy: To what extent is the assistants answer semantically consistent with the gold standard? - Hallucination: There should be no hallucinations and friction. The assistant should not introduce any information not present in or not implied by the gold answer. [Gold Answer] {answer} [The Assistants Predicted Answer] {prediction} [Requirement] 1. The assistant receives an overall score on scale of 0 to 10, where higher score indicates better overall performance. Please note that if the assistants answer fully meet the above criteria, its overall rating should be the full marks (10). Please note that the gold answer can be considered as correct answer to the instruction. 2. Analyze how well the Assistants performance meets each criterion. 3. Please first provide comprehensive explanation of your evaluation, avoiding any potential bias. Then, output line indicating the score of the Assistant. 4. Please note that the scoring for each criteria is independent and should not be influenced by each other. [Output Format] ˋˋˋjson { \"Accuracy\": { \"reason\": <reason for accuracy score>, \"score\": <0-10> }, \"Hallucination\": { \"reason\": \"<reason for hallucination score>\", \"score\": <0-10> } } ˋˋˋ Now, start your evaluation: C.3 Persona Modeling You are an impartial and harsh judge evaluating conversation quality. Your task is to rigorously and meticulously assess the performance of the AI assistant in Dialogue Analysis (Persona) strictly based on specific criteria. [Criteria] - Accuracy: To what extent is the assistants answer semantically consistent with the gold standard? - Hallucination: There should be no hallucinations and friction. The assistant should not introduce any information not present in or not implied by the gold answer. [Gold Answer] {answer} [The Assistants Predicted Answer] {prediction} [Requirement] 1. The assistant receives an overall score on scale of 0 to 10, where higher score indicates better overall performance. Please note that if the assistants answer fully meet the above criteria, its overall rating should be the full marks (10). Please note that the gold answer can be considered as correct answer to the instruction. 2. Analyze how well the Assistants performance meets each criterion. 3. Please first provide comprehensive explanation of your evaluation, avoiding any potential bias. Then, output line indicating the score of the Assistant. 4. Please note that the scoring for each criteria is independent and should not be influenced by each other. [Output Format] ˋˋˋjson { \"Accuracy\": { \"reason\": <reason for accuracy score>, \"score\": <0-10> }, \"Hallucination\": { \"reason\": \"<reason for hallucination score>\", \"score\": <0-10> } } ˋˋˋ Now, start your evaluation: C.4 Scene Reconstruction You are an impartial and harsh judge evaluating conversation quality. Your task is to rigorously and meticulously assess the performance of the AI assistant in Dialogue Analysis (Scene) strictly based on specific criteria. 14 [Criteria] - Accuracy: To what extent is the assistants answer semantically consistent with the gold standard? - Hallucination: There should be no hallucinations and friction. The assistant should not introduce any information not present in or not implied by the gold answer. [Gold Answer] {answer} [The Assistants Predicted Answer] {prediction} [Requirement] 1. The assistant receives an overall score on scale of 0 to 10, where higher score indicates better overall performance. Please note that if the assistants answer fully meet the above criteria, its overall rating should be the full marks (10). Please note that the gold answer can be considered as correct answer to the instruction. 2. Analyze how well the Assistants performance meets each criterion. 3. Please first provide comprehensive explanation of your evaluation, avoiding any potential bias. Then, output line indicating the score of the Assistant. 4. Please note that the scoring for each criteria is independent and should not be influenced by each other. [Output Format] ˋˋˋjson { \"Accuracy\": { \"reason\": <reason for accuracy score>, \"score\": <0-10> }, \"Hallucination\": { \"reason\": \"<reason for hallucination score>\", \"score\": <0-10> } } ˋˋˋ Now, start your evaluation: C.5 Utterance Mining You are an impartial and harsh judge evaluating conversation quality. Your task is to rigorously and meticulously assess the performance of the AI assistant in Dialogue Analysis (Utterance) strictly based on specific criteria. [Criteria] - Accuracy: To what extent is the assistants answer semantically consistent with the gold standard? - Hallucination: There should be no hallucinations and friction. The assistant should not introduce any information not present in or not implied by the gold answer. [Gold Answer] {answer} [The Assistants Predicted Answer] {prediction} [Requirement] 1. The assistant receives an overall score on scale of 0 to 10, where higher score indicates better overall performance. Please note that if the assistants answer fully meet the above criteria, its overall rating should be the full marks (10). Please note that the gold answer can be considered as correct answer to the instruction. 2. Analyze how well the Assistants performance meets each criterion. 3. Please first provide comprehensive explanation of your evaluation, avoiding any potential bias. Then, output line indicating the score of the Assistant. 4. Please note that the scoring for each criteria is independent and should not be influenced by each other. [Output Format] ˋˋˋjson { \"Accuracy\": { \"reason\": <reason for accuracy score>, \"score\": <0-10> }, \"Hallucination\": { \"reason\": \"<reason for hallucination score>\", \"score\": <0-10> } } ˋˋˋ Now, start your evaluation: 15 Test Case To facilitate understanding of DEMO tasks, we present examples of element awareness and dialogue agent interaction in the following. D.1 Goal Recognition Dialogue history: <dialogue history> This is complete dialogue. You need to analyze and understand this conversation, and then deduce information about the GOAL following the specified output format. Output format: ˋˋˋjson { \"goal\": { \"goal1\": \"Dialogue goal of participant 1\", \"goal2\": \"Dialogue goal of participant 2\", \"goal completion\": \"An integer from 0-10 (Comprehensively analyze to what extent the participants achieved their respective goals. 0 represents the lowest degree of goal achievement, 10 represents complete achievement of both parties goals.)\", \"reason\": \"Detailed reasons for the goal completion score\" } } ˋˋˋ Your output is:\"\"\" D.2 Persona Modeling Dialogue history: <dialogue history> This is complete dialogue. You need to analyze and understand this conversation, and then deduce information about the PERSONA following the specified output format. Output format: ˋˋˋjson { \"persona\": { \"participant1\": { \"name\": \"Name of participant 1\", \"gender\": \"M/F/Unknown\", \"age\": \"Childhood: 6-11 years old / Adolescence: 12-15 years old / Youth: 15-24 years old / Adulthood: 25-40 years old / Middle age: 40-60 years old / Old age: 60 years and above / Advanced age: 70 years and above\" \"big five\": [ [ \"Openness\", \"High\" or \"Low\" ], [ \"Conscientiousness\", \"High\" or \"Low\" ], [ \"Extraversion\", \"High\" or \"Low\" ], [ \"Agreeableness\", \"High\" or \"Low\" ], [ \"Neuroticism\", \"High\" or \"Low\" ] ], \"education\": \"Education description\", \"occupation\": \"Occupation description\", \"culture\": \"Cultural background of the person\", \"speaking style\": \"Speaking style and language habits\" \"hobby\": \"Hobby description\", }, \"participant2\": { \"name\": \"Name of participant 2\", ...(Same as above) } } } ˋˋˋ Your output is:\"\"\" D.3 Scene Reconstruction Dialogue history: <dialogue history> This is complete dialogue. You need to analyze and understand this conversation, and then deduce information about the SCENE following the specified output format. Output format: ˋˋˋjson 16 { \"scene\": { \"topic\": \"Dialogue topic\", \"relationship\": \"Relationship between dialogue participants\", \"familiarity\": \"An integer from 0-10 (Degree of familiarity between dialogue participants. 0: Strangers; 1: Meet for the first time; 2: Heard of each other but dont know each other; 4: Met multiple times, slightly familiar; 6: Know and are familiar with each others background information; 8: Stay together and are familiar with each other; 10: Close relationship, stay together for many years, are very familiar with each others habits, secrets, and temper)\", \"talkway\": \"Dialogue mode (face-to-face conversation, phone call, video call, instant messaging, email, social media, letter, etc.)\", \"workflow\": [ \"Step 1\", \"Step 2\", ...(represents the workflow of the entire dialogue, referring to the structure or sequence of information exchange during the dialogue. It is series of steps, such as what participant 1 did first, what participant 2 did, etc. These steps do not correspond to each sentence and are more of summary of the information exchange throughout the dialogue.) ], \"summary\": [ \"Participant 1 dialogue summary\", \"Participant 2 dialogue summary\" ] } } ˋˋˋ Your output is:\"\"\" D.4 Utterance Mining Dialogue history: <dialogue history> Utterance to analyze: <utterance> Based on the dialogue history, carefully analyze and provide the intent, sentiment, emotion type, stance, and strategy of the \"utterance to analyze\" according to the output format. Output format: ˋˋˋjson { \"person\": \"Participant Name\", \"content\": \"Specific dialogue content\", \"intent\": \"Intent of this utterance\", \"sentiment\": \"Positive/Negative/Neutral\", \"emotion\": \"Anger/Contempt/Disgust/Enjoyment/Fear/Sadness/Surprise, etc.\", \"stance\": [ { \"aspect\": \"Aspect1/Event1 involved\", \"viewpoint\": \"Expressed viewpoint/stance\" }, ... ], \"strategy\": { \"description\": \"Strategy description\", \"type\": \"Dialogue trend change caused by strategy (e.g., guiding the conversation, resolving conflict, intensifying conflict, changing viewpoints, etc.)\" } } ˋˋˋ Your output is: D.5 Dialogue Agent Interaction You need to generate reasonable dialogue content based on the provided dialogue background information, dialogue history, and dialogue goal. [Dialogue Background Information] Time: <time> Dialogue Mode: <talkway> Participants: <person1> and <person2> Location and environment of participants: <location> Information about <person1>: <p1 background> Information about <person2>: <p2 background> Relationship between the dialogue participants: <relationship> Familiarity level between the dialogue participants: <familiarity> (A value from 0-10, with 10 indicating the highest familiarity) Dialogue Topic: <topic> [Dialogue History] <dialogue history> 17 [Dialogue Goal] You are <person1>, your goal is: <p1 goal>. The other dialogue participant is <person2>. The other partys goal is unknown, and you need to guess and perceive the other persons dialogue goal. You need to write the response for Turn #<turn>. You can choose between \"Continue the dialogue\" and \"End the dialogue\". Note: You can \"End the dialogue\" if: 1. You have achieved the conversation goal; 2. The conversation between the two parties has ended; [\"Continue the dialogue\" Output Format] ˋˋˋjson { \"person\": \"Participant Name\", \"content\": \"Specific dialogue content\" } ˋˋˋ [\"End the dialogue\" Output Format] ˋˋˋjson { \"person\": \"Participant Name\", \"content\": \"*ENDING*\" } ˋˋˋ Your output is:"
        }
    ],
    "affiliations": [
        "MAIS, Institute of Automation, Chinese Academy of Sciences",
        "School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "Tongyi Lab, Alibaba Group"
    ]
}