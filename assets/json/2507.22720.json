{
    "paper_title": "Investigating Hallucination in Conversations for Low Resource Languages",
    "authors": [
        "Amit Das",
        "Md. Najib Hasan",
        "Souvika Sarkar",
        "Zheng Zhang",
        "Fatemeh Jamshidi",
        "Tathagata Bhattacharya",
        "Nilanjana Raychawdhury",
        "Dongji Feng",
        "Vinija Jain",
        "Aman Chadha"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable proficiency in generating text that closely resemble human writing. However, they often generate factually incorrect statements, a problem typically referred to as 'hallucination'. Addressing hallucination is crucial for enhancing the reliability and effectiveness of LLMs. While much research has focused on hallucinations in English, our study extends this investigation to conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a comprehensive analysis of a dataset to examine both factual and linguistic errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated responses in Mandarin but generate a significantly higher number of hallucinations in Hindi and Farsi."
        },
        {
            "title": "Start",
            "content": "Amit Das1, Md. Najib Hasan2, Souvika Sarkar2, Zheng Zhang3, Fatemeh Jamshidi4, Tathagata Bhattacharya5, Nilanjana Raychawdhury6, Dongji Feng7, Vinija Jain8,9 , Aman Chadha8, 10 1University of North Alabama, 2Wichita State University, 3Murray State University, 4California State Polytechnic University Pomona, 5Auburn University at Montgomery, 6Auburn University, 7Gustavus Adolphus College, 8Stanford University, 9Meta, 10Amazon GenAI Corresponding author: Amit Das (adas@una.edu)"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have demonstrated remarkable proficiency in generating text that closely resemble human writing. However, they often generate factually incorrect statements, problem typically referred to as hallucination. Addressing hallucination is crucial for enhancing the reliability and effectiveness of LLMs. While much research has focused on hallucinations in English, our study extends this investigation to conversational data in three languages: Hindi, Farsi, and Mandarin. We offer comprehensive analysis of dataset to examine both factual and linguistic errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated responses in Mandarin but generate significantly higher number of hallucinations in Hindi and Farsi."
        },
        {
            "title": "1 Introduction",
            "content": "LLMs have emerged as groundbreaking advancement in artificial intelligence, revolutionizing the field of natural language processing (NLP). These models show an extraordinary ability to perform wide range of languagerelated tasks such as text generation, machine translation, summarization, question answering, etc. Despite their impressive performance, critical challenge persists: the phenomenon of hallucination, where LLMs produce text that is factually incorrect, nonsensical, or misleading (Ji et al., 2023; Li et al., 2023). This issue is not limited to English but also affects low-resource languages. Hallucination in neural language generation has become growing concern across variWork does not relate to position at Amazon or Meta. 1 ous areas, including neural machine translation (Raunak et al., 2021; Wang and Sennrich, 2020) and summarization (Durmus et al., 2020; Kang and Hashimoto, 2020). Research on LLMs has highlighted problems like generating inaccurate information, producing incoherent text, and merging unrelated sources (Mckenna et al., 2023). In the context of machine translation, studies have reported hallucination rates exceeding 10% for certain language pairs (Guerreiro et al., 2023). Despite these advancements, the issue of hallucination in conversational systems, especially in lowresource languages, remains largely underexplored."
        },
        {
            "title": "The complexity and significance of",
            "content": "lowresource languages underscore the urgent need for detailed investigation into hallucinations within these linguistic contexts. Addressing this issue not only improves the reliability and applicability of LLMs but also has implications for range of applications, including information retrieval, sentiment analysis, and machine translation. This study aims to rigorously evaluate the factual accuracy and reliability of LLMs, specifically GPT-3.5 and GPT4o, when generating texts in Hindi, Farsi, and Mandarin."
        },
        {
            "title": "Our research seeks to make the following",
            "content": "contributions: 1. We conduct an analysis of the factual accuracy of outputs of LLMs (specifically for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3) in Hindi, Farsi, and Mandarin, offering insights into their reliability across these languages. 1 2. We identify and categorize the types of factual and linguistic errors present in conver1Sample LLM responses found https://github.com/AmitDasRup123/ here: LLM-Hallucination-Low-Resource-Languages/. can be Figure 1: Workflow diagram of our work. It shows sample conversation where LLM (Large Language Models) provides irrelevant response for Hindi, Farsi and Mandarin. The left side are the inputs to the LLM and right side are the irrelevant responses by LLM. We have explored GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3 in this paper. sational outputs generated by LLMs for Hindi, Farsi, and Mandarin."
        },
        {
            "title": "2 Related Work",
            "content": "Large Language Models (LLMs) are increasingly scrutinized for both their susceptibility to bias and their tendency to hallucinate, with recent research revealing concerning patterns across diverse NLP tasks. Various forms of bias have been identifiedincluding gender, religion, and political ideologyaffecting both model behavior and output generation (Salinas et al., 2023; Jenny et al., 2023; He et al., 2023). These biases are not only pervasive but also task-sensitive, as shown by Zheng et al. (Zheng et al., 2023), who demonstrate that simple perturbations such as altering the order of multiple-choice options can lead to selection bias. Similarly, Gonçalves and Strubell (Gonçalves and Strubell, 2023) offer comprehensive synthesis of how biases manifest in LLMs, while others have proposed mitigation techniques by retraining on bias-filtered datasets (Dong et al., 2023; Limisiewicz et al., 2023). However, as highlighted in our Section 3, such mitigation techniques may not generalize well, particularly in complex tasks like stance detection, where the bias distribution itself varies significantly. Hallucination remains central challenge in LLM deployment (Dale et al., 2022). Initial work in this area focused mainly on grounded tasks such as summarization and dialogue, where hallucinations were detected by aligning the generated factual units with the input of the source using entailment-based or QAdriven techniques (Maynez et al., 2020). As hallucination detection has expanded to open source generation, newer approaches now use reliable references such as Wikipedia and web searches to assess factuality (Min et al., 2023; Chern et al., 2023; Mishra et al., 2024), while others focus on specific domains such as citation verification (Agrawal et al., 2023). Complementing these reference-based methods, internal LLM techniques, such as consistency checks across sampled responses (Manakul et al., 2023) and logit-space analysis (Varshney et al., 2023), aim to identify contradictions without external validation. Together, these lines of work underscore the intertwined nature of bias and hallucination in LLMs. Both phenomena reflect deeper model limitations in generalization, factual grounding, and representation learningissues that continue to motivate new strategies for detection and mitigation."
        },
        {
            "title": "3 Methodology",
            "content": "3.1 Dataset We used the BlendedSkillTalk (Smith et al., 2020) and the DailyDialog (Li et al., 2017) datasets for this work. The BlendedSkillTalk dataset is conversational dataset designed to help train and evaluate dialogue models. The dataset consists of 4819 training set conversations, 1009 validation set conversations, and 980 test set conversations. The DialiDialog dataset contains total 13,118 dialogues. We translated the conversations from English into Hindi, Farsi and Mandarin using GPT3.5. sample prompt we used for translating the texts to Farsi is : Translate the following into Farsi: . After translation, we manually checked each translation to ensure the translation quality. few sample translations are given in table 1."
        },
        {
            "title": "3.2 Analysis",
            "content": "Figure 1 shows the workflow of our work. We used speaker 1 as the reference and asked the LLMs for their responses. We measured hallucination in the LLM responses by comparing with the actual response. We used both ROUGE-1 and ROUGE-L scores for measurement."
        },
        {
            "title": "4 Results & Discussion",
            "content": "The results in Tables 2 and 3 provide an extensive comparison of hallucination tendencies across six LLMs GPT-3.5, GPT-4o, Llama-3 8B, Gemma-2B, DeepSeek-1.3B, and Qwen-1.5-1.8B on two multilingual conversational datasets (BlendedSkillTalk and DailyDialogue) in Hindi, Farsi, and Mandarin. We analyze hallucination using ROUGE-1 and ROUGE-L scores across the train, test, and validation splits."
        },
        {
            "title": "4.1 Overall Trends",
            "content": "Across both datasets, ROUGE scores are lowest for Mandarin, indicating minimal lexical overlap and, consequently, fewer hallucinaIn contrast, Hindi and Farsi exhibit tions. higher ROUGE scores, suggesting greater degree of hallucinated overlap with human references. 4.2 Dataset-specific Observations 4.2.1 BlendedSkillTalk Dataset In the BlendedSkillTalk  (Table 2)  presents hallucination scores using ROUGE-1 and ROUGE-L on the BlendedSkillTalk dataset across Hindi, Farsi, and Mandarin for training, testing, and validation splits. In Hindi, GPT-4o shows highest ROUGE scores across all splits, followed closely by GPT-3.5 and Llama-3.1. DeepSeek-R1 and Gemma-2.0 exhibit comparatively lower scores, suggesting they hallucinate more. In Farsi, Qwen-3 outperforms others with ROUGE scores consistently above 3.5, particularly on the validation set, indicating better factual alignment. Mandarin results, however, show significant drop across all models. The highest ROUGE scores in Mandarin barely exceed 1.0, with most models scoring close to or below 0.5highlighting the diﬀiculty of reducing hallucination in Mandarin using these models."
        },
        {
            "title": "4.3 Language-wise Comparison",
            "content": "Across both datasets, Mandarin consistently shows the least hallucination, suggesting that LLMs are more cautious or limited in generating fluent hallucinated responses in Mandarin, particularly when translated content leads to mismatches with model priors. Hindi and Farsi, on the other hand, demonstrate similar and higher levels of hallucination, potentially due to their shared syntactic complexity 3 English Farsi Hindi Mandarin Which level are 1: you at? 2: received on-thejob training when first started For good numThats great! 1: How long have you been this doing work? 2: ber of years now. 1: Sounds like it could be dangerous job at times. 2: That it is, especially if you dont take the proper measures 1: Well you have entered trade that will always guarantee you some work. 2: Thats true, especially in this economy ﯽﺤﻄﺳ ﻪﭼ رد 1: ﺪﯿﺘﺴﻫ :2 رﺎﺑ ﻦﯿﻟوا ﯽﺘﻗو یﺎﻫ شزﻮﻣآ مدﺮﮐ عوﺮﺷ .مدﺮﮐ ﺖﻓﺎﯾرد رﺎﮐ ﻦﯿﺣ تﺪﻣ رﺪﻘﭼ !ﻪﯿﻟﺎﻋ :1 مﺎﺠﻧا ار رﺎﮐ ﻦﯾا ﻪﮐ ﺖﺳا ﺪﯿﻫد ﯽﻣ لﺎﺳ ﻦﯾﺪﻨﭼ یاﺮﺑ :2 .بﻮﺧ ﺪﺳر ﯽﻣ ﺮﻈﻧ ﻪﺑ :1 ﺪﻧاﻮﺗ ﯽﻣ تﺎﻗوا ﯽﻫﺎﮔ .ﺪﺷﺎﺑ ﯽﮐﺎﻧﺮﻄﺧ ﻞﻐﺷ ﺖﺳا رﻮﻄﻨﯿﻤﻫ :2 تﺎﻣاﺪﻗا ﺮﮔا صﻮﺼﺧ ﻪﺑ .ﺪﯿﻫﺪﻧ مﺎﺠﻧا ار مزﻻ دراو ﺎﻤﺷ ﺐﺧ ﻪﮐ رﺎﮐ نﺎﺘﯾاﺮﺑ :1 ﺪﯾا هﺪﺷ یا ﻪﻓﺮﺣ ﻪﺸﯿﻤﻫ .ﺪﻨﮐ ﯽﻣ ﻦﯿﻤﻀﺗ ﻪﺑ ﺖﺳا ﺖﺳرد :2 ﻂﯾاﺮﺷ ﻦﯾا رد صﻮﺼﺧ .یدﺎﺼﺘﻗا 'आप (cid:607)कस सतर पर 1: ह?' 'जब मन पहल बर 2: शर (cid:607)कय थ, त मझ ऑन-द-जब पर(cid:609)शकषण (cid:608)मल' 'यह बहत अ(cid:501) ह! 1: आप यह कम (cid:607)कतन समय स कर रह ह?' 2: 'कफ(cid:655) सल स' 1: 你现在处于哪个水平 2: 我刚开始时接受了 在职培训 1: 太好了你做这份工作 的时间有多久了 2: 已经有好几年了 1: 'सनन म यह कम कभ-कभ खतरनक भ ह सकत ह' 2: 'ह, खसकर अगर आप सह सवध(cid:607)नय नह बरत' 1: 听起来有时候这份工作 可能会很危险 2: 是的特别是如果不 采取适当的措施 1: 'खर, आपन एक ऐस पश चन ह (cid:611)जसम हमश कम (cid:608)मलत रहग' 2: 'सह ह, खसकर इस अथर(cid:557)व(cid:568) म' 1: 嗯你进入了一个总能 保证你有工作的行业 2: 是的特别是在这个 经济环境下 Table 1: Sample translations of conversations from English into Hindi, Farsi and Mandarin using GPT3.5. sample prompt we used for translating the texts to Farsi is: Translate the following into Farsi: . Each translation was then manually checked to ensure translation quality. LLMs Train Hindi Test Val Train R-1 2.16 2.55 2.41 2.02 1.76 R-L 2.28 2.82 2.42 2.02 1.76 R-1 2.21 2.80 2.32 2.03 1. R-L 2.24 2.90 2.33 2.03 1.80 R-1 2.93 2.48 2.40 2.01 1.80 R-L 2.01 2.73 2.39 2.01 1. R-1 3.66 3.32 3.65 3.72 3.30 R-L 3.02 3.53 3.65 3.72 3.30 Farsi Test R3.06 3.54 3.78 3.69 3.40 R-L 3.24 3.66 3.78 3.69 3.40 Val Train R3.66 3.32 3.67 3.74 3.40 R-L 3.91 3.50 3.67 3.74 3.40 R-1 0.36 0.02 0.99 0.93 1.10 R-L 0.35 0.02 0.99 0.93 1.10 Mandarin Test Val R-1 0.10 0.02 0.96 0.86 1.00 R-L 0.11 0.02 0.96 0.86 1.08 R-1 0.10 0.06 0.95 0.84 1.00 R-L 0.10 0.06 0.95 0.84 1.00 2. 2.18 2.23 2.23 2.26 2.23 3. 3.76 3.80 3.80 3.80 3.83 1. 1.02 0.99 1.00 1.01 1.05 GPT-3.5 GPT-4o Llama-3.1 Gemma-2.0 DeepSeekR1 QwenTable 2: Hallucination scores (ROUGE-1 and ROUGE-L) on the BlendedSkillTalk dataset in Hindi, Farsi, and Mandarin across train, test, and validation splits. and less available high-quality training data in these languages."
        },
        {
            "title": "4.4 Model-wise Comparison",
            "content": "While GPT-3.5 and GPT-4o are more fluent, they also demonstrate lower hallucination rates, particularly in Mandarin compared to smaller open-source models like Gemma and DeepSeek. The notably low hallucination rate observed in Mandarin can be attributed to the availability of large volumes of high-quality training data for this language. In contrast, the elevated hallucination rates in Hindi and Farsi highlight the challenges faced by LLMs when dealing with low-resource languages. These findings support the hypothesis that greater data availability contributes to the generation 4 LLMs Train Hindi Test Val Train R-1 2.33 2.08 2.03 1.91 1.91 R-L 2.34 2.08 2.03 1.91 1. R-1 2.20 2.00 1.90 2.00 1.89 R-L 2.20 2.00 1.90 2.00 1.88 R-1 2.26 2.05 1.96 2.03 1. R-L 2.26 2.05 1.96 2.04 1.84 R-1 3.10 3.04 3.43 3.27 2.57 R-L 3.11 3.04 3.44 3.27 2. Farsi Test R-1 3.00 3.00 2.82 4.01 2.84 R-L 3.00 3.00 2.82 4.00 2.85 Val Train Mandarin Test Val R-1 3.05 3.07 3.41 2.35 2.62 R-L 3.05 3.08 3.40 2.35 2.62 R-1 0.25 0.02 0.70 0.81 1.44 R-L 0.25 0.02 0.70 0.82 1.44 R0.19 0.02 0.81 0.88 1.28 R-L 0.19 0.02 0.82 0.88 1.26 R-1 0.18 0.03 0.90 0.93 1.28 R-L 0.19 0.03 0.90 0.94 1.28 2.19 2.19 2.17 2.17 2. 2.10 3.54 3.56 3.31 3.31 3. 3.48 1.56 1.56 1.26 1.27 1. 1.24 GPT-3.5 GPT-4o Llama-3.1 Gemma-2.0 DeepSeekR1 Qwen-3 Table 3: Hallucination scores (ROUGE-1 and ROUGE-L) on the DailyDialogue dataset in Hindi, Farsi, and Mandarin across train, test, and validation splits. Figure 2: Hallucination (R-1) scores across the 6 LLMs for Hindi, Farsi and Mandarin on the BlendedSkillTalk dataset. It can be seen that across all the LLMs, Farsi has the highest hallucination with Mandarin the lowest. Figure 3: Hallucination (R-L) scores across the 6 LLMs for Hindi, Farsi and Mandarin on the BlendedSkillTalk dataset. Similar trend like 2 can also be seen here. Figure 4: Hallucination (R-1) scores across the 6 LLMs for Hindi, Farsi and Mandarin on the DailyDialog dataset. Figure 5: Hallucination (R-L) scores across the 6 LLMs for Hindi, Farsi and Mandarin on the DailyDialog dataset. of more accurate and contextually relevant responses. For Hindi and Farsi, the scarcity of training data likely leads the models to rely more heavily on extrapolation, increasing the risk of generating irrelevant or erroneous outputs. In Mandarin, hallucinations tend to be partial or minor in nature. As illustrated in Tables 6 and 7, the few observed hallucinations in this language are typically subtle. Conversely, the hallucinations in Hindi and Farsi, particularly with GPT-3.5 and GPT-4o, are more pronounced. For example, in Hindi  (Table 4)  , when prompted with hope so, how old are your kids?, GPT-3.5 responds with would be happy to help answer your question, which fails to address the specific query. Similarly, in Farsi  (Table 8)  , the prompt Yup, but do need to call my friend about her ring... elicits the response, If you need any other help, would be happy to assist, which is contextually disconnected from the input. Comparatively, GPT-4o exhibits reduced tendency toward hallucination. For instance, in Table 9, when prompted with Yeah, fine. have habit of driving too fast, GPT-4o responds with somewhat tangential yet semantically richer reply about sports cars, demonstrating less severe deviation. Similarly, in Table 5, when asked What kind of clothing do you like?, GPT-4o replies with general informative statement: am an AI, so dont have personal preferences..., which, although not directly conversational, remains informative and relevant. Other LLMs present more varied hallucination patterns. Gemma-2, for example, in response to Hey man, you wanna buy some in Hindi  (Table 13)  , outputs cauweed? tionary message: am an AI, am not allowed to use intoxicating substances, which, while responsible, breaks the flow of natural conversation. Llama-3.1 generates clearly irrelevant response in Table 12, replying with Wow, thank you very much! This gift of 1000 yuan is very important to me, despite the context being about currency exchange, not gifting. Qwen-3 and DeepSeek-R1 similarly exhibit hallucinations. In Mandarin  (Table 11)  , Qwen3 responds with an explanation of Newtonian mechanics when the prompt expresses an emotional reaction, showing stark disconnect in context. In Farsi  (Table 10)  , DeepSeek-R1 responds to statement about enjoying meat with an introspective and unrelated question, How can understand this interest in eating meat?, further illustrating the models struggle with contextual alignment."
        },
        {
            "title": "Recommendations",
            "content": "Our findings suggest that hallucination in multilingual dialogue generation is highly influenced by language-resource availability, dataset style, and model size. For real-world deployment in Hindi and Farsi, hallucination mitigation techniques such as retrievalaugmented generation (RAG), grounded decoding, or human-in-the-loop supervision become crucial. Moreover, models specifically pretrained or fine-tuned on native corpora (e.g., Qwen for Mandarin) show reduced hallucination, highlighting the importance of language-aware pretraining strategies."
        },
        {
            "title": "5 Conclusion",
            "content": "In this paper, we investigated hallucination in conversations across three low-resource languagesHindi, Farsi, and Mandarin using six large language models: GPT-3.5, GPT-4o, Llama-3.1, Gemma-2, Qwen-3, and DeepSeek-R1. Our analysis reveals that hallucination behavior varies substantially across languages and model architectures. Across the board, hallucination was consistently minimal in Mandarin, with all models. This can be attributed to the availability of abundant and high-quality training data in Mandarin. In contrast, significantly higher hallucination rates were observed in Hindi and Farsi. While GPT-4o generally exhibited lower hallucination than GPT-3.5, both models still struggled in low-resource settings. Models like Llama-3.1 and Gemma-2 demonstrated relatively better performance in Hindi and Farsi compared to the GPT models, though some contextually irrelevant responses were still present. DeepSeek-R1 also showed occasional hallucinations, particularly in Farsi. These findings reinforce the strong influence of language resource availability on model performance. The disparities in hallucination severity across languages emphasize the models reliance on the quantity and quality of their training data. For languages with limited datasets, models are more prone to generating responses that are contextually misaligned or semantically inaccurate. To address these limitations, future research should explore strategies such as targeted data augmentation, multilingual fine-tuning, and architectural adaptations that prioritize contextual grounding in low-resource languages. Additionally, systematic evaluations across broader range of languages and domains can help generalize these findings and guide more inclusive model development. Ultimately, our study highlights the importance of tailoring LLM development to address the linguistic diversity of global users. Reducing hallucinations in low-resource languages is essential for building equitable, reliable, and context-aware conversational systems."
        },
        {
            "title": "Limitations",
            "content": "This study focuses on only three low-resource languagesHindi, Farsi, and Mandarin which may limit the generalizability of our findings to other languages or dialects. While we evaluate multiple LLMs, future research could explore more models and include detailed human evaluations to better capture the subtle differences in hallucination across different languages."
        },
        {
            "title": "References",
            "content": "Ayush Agrawal, Mirac Suzgun, Lester Mackey, and Adam Tauman Kalai. 2023. Do language models know when theyre hallucinating references? arXiv preprint arXiv:2305.18248. Chern, Steﬀi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, and 1 others. 2023. Factool: Factuality detection in generative aia tool augmented framework for multi-task and multi-domain scenarios. arXiv preprint arXiv:2307.13528. David Dale, Elena Voita, Loïc Barrault, and Marta Costa-Jussà. 2022. Detecting and mitigating hallucinations in machine translation: Model internal workings alone do well, sentence similarity even better. arXiv preprint arXiv:2212.08597. Xiangjue Dong, Ziwei Zhu, Zhuoer Wang, Maria Teleki, and James Caverlee. 2023. Co ^2 pt: Mitigating bias in pre-trained language models through counterfactual conarXiv preprint trastive prompt tuning. arXiv:2310.12490. Birch, Pierre Colombo, and André FT Martins. 2023. Hallucinations in large multilingual translation models. Transactions of the Association for Computational Linguistics, 11:15001517. Zihao He, Siyi Guo, Ashwin Rao, and Kristina Lerman. 2023. Inducing political bias allows language models anticipate partisan reactions to controversies. arXiv preprint arXiv:2311.09687. David Jenny, Yann Billeter, Mrinmaya Sachan, Bernhard Schölkopf, and Zhijing Jin. 2023. Navigating the ocean of biases: Political bias attribution in language models via causal structures. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):138."
        },
        {
            "title": "Improved natural",
            "content": "and Tatsunori Hashimoto. 2020. language generation via loss truncation. arXiv preprint arXiv:2004.14589. Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2023. Halueval: large-scale hallucination evaluation benchmark for large language models. arXiv preprint arXiv:2305.11747. Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: manually labelled multiarXiv preprint turn dialogue dataset. arXiv:1710.03957. Esin Durmus, He He, and Mona Diab. 2020. Feqa: question answering evaluation framework for faithfulness assessment in abstractive summarization. arXiv preprint arXiv:2005.03754. Gustavo Gonçalves and Emma Strubell. 2023. Understanding the effect of model compression on social bias in large language models. arXiv preprint arXiv:2312.05662. Tomasz Limisiewicz, David Mareček, and Tomáš Musil. 2023. Debiasing algorithm through model adaptation. arXiv preprint arXiv:2310.18913. Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023. Selfcheckgpt: Zeroresource black-box hallucination detection for generative large language models. arXiv preprint arXiv:2303.08896. Nuno Guerreiro, Duarte Alves, Jonas Waldendorf, Barry Haddow, Alexandra Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On 8 faithfulness tive arXiv:2005.00661. summarization. and factuality in abstracpreprint arXiv Nick Mckenna, Tianyi Li, Liang Cheng, Mohammad Hosseini, Mark Johnson, and Mark Steedman. 2023. Sources of hallucination by large language models on inference tasks. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 27582774. Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. Factscore: Fine-grained factual precision in atomic evaluation of long form text generation. arXiv preprint arXiv:2305.14251. Abhika Mishra, Akari Asai, Vidhisha Balachandran, Yizhong Wang, Graham Neubig, Yulia Tsvetkov, and Hannaneh Hajishirzi. 2024. Fine-grained hallucination detection and editing for language models. arXiv preprint arXiv:2401.06855. Vikas Raunak, Arul Menezes, and Marcin Junczys-Dowmunt. 2021. The curious case of hallucinations in neural machine translation. arXiv preprint arXiv:2104.06683. Abel Salinas, Louis Penafiel, Robert McCormack, and Fred Morstatter. 2023. im not racist but...: Discovering bias in the internal knowledge of large language models. arXiv preprint arXiv:2310.08780. Eric Michael Smith, Mary Williamson, Kurt Shuster, Jason Weston, and Y-Lan Boureau. 2020. Can you put it all together: Evaluating conversational agents ability to blend skills. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 20212030. Neeraj Varshney, Wenlin Yao, Hongming Zhang, Jianshu Chen, and Dong Yu. 2023. stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation. arXiv preprint arXiv:2307.03987. Chaojun Wang and Rico Sennrich. 2020. On exposure bias, hallucination and domain shift in neural machine translation. arXiv preprint arXiv:2005.03642. Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang. 2023. Large language models are not robust multiple choice selectors. arXiv preprint arXiv:2309.03882."
        },
        {
            "title": "A Appendix",
            "content": "A.1 Data translation and LLM responses We used gpt-3.5-turbo for the translation of the dataset. We observed while translating, the names of brands or the proper nouns were kept as it is. For example, in table 5, in the translation of speaker 2, American Eagle Outfitters was kept as it is; it was not even converted into Hindi characters. We used both gpt-3.5-turbo and gpt4o for the responses. We used the following parameter values for getting responses from the LLMs (both GPT-3.5 and GPT4o): max_tokens=100, temperature=0.7 and top_p=0.9. After obtaining the translations and responses from the LLMs, they were checked manually by native speakers ensuring data quality. We used Llama 3.1 8B, DeepSeek R1 14B, and Qwen 2.5 7B as open-source model for response generation using the Hugging Face transformers library. All three models were loaded in 4-bit precision to ensure eﬀicient memory usage and faster runtime. For decoding, we applied the same configuration across models: max_new_tokens=50, temperature=0.5, top_p=1.0, and do_sample=True. These settings offered good balance between response diversity and stability. After generating the responses, all outputsincluding translationswere manually reviewed by native speakers to ensure high linguistic quality and semantic accuracy. We used Gemini 2.0 via the Google AI Studio API for generating responses. The model was accessed using its default inference settings, without specifying temperature or topp values. We set max_tokens=100 to control the length of the generated outputs. As with the other models, all responses were manually reviewed by native speakers to ensure translation accuracy, naturalness, and overall data quality. A.2 Hallucination measurement We used ROUGE-1 and ROUGE-L scores for measuring the hallucinations. ROUGE1 measures the overlap of unigrams, or individual words, between the system-generated and reference summaries and ROUGE-L naturally captures sentence-level structural similarity and automatically identifies the longest cooccurring n-grams in sequence. Some LLM responses were partially hallucinated, while others were fully hallucinated. For example, in table 6, GPT-3.5s reply mentions about particular dish (Yes, this dish is indeed very delicious. You could try making it yourself; you might find it quite rewarding) whereas the whole conversation does not mention about any specific dishes. Along with measuring hallucination using ROUGE-1 and ROUGE-L scores, we asked the native speakers to check few random samples to find the patterns in the hallucinations. It was observed that the hallucinations in Mandarin were mostly partial in nature whereas Hindi and Farsi contained both partial and complete hallucinations. 10 English Speaker Speaker2 GPT-3.5 response मझ अ(cid:610)भनय पसद ह, म एक अ(cid:610)भनत बनन क(cid:655) उममद करत ह, आपक बर म कय कहग? ठ(cid:654)क ह कय आपक पस कई ब(cid:500) ह? नह, ल(cid:607)कन (cid:607)कस (cid:606)दन यह अ(cid:501) ह मर पस 2 ह मर सक ल क समपन क बद, मर यजन ह (cid:607)क म एक प(cid:605)रवर बनऊ यह बहत ब(cid:606)ढ़य ह! तम तयर ह जओग मझ आश ह, आपक ब(cid:500) (cid:607)कतन सल क ह? 5 और 7 व मर बहत समय लत ह म कलपन करत ह मझ यक(cid:655)न ह (cid:607)क व बहत अ(cid:501) ब(cid:500) ह भगय स, उनह फ ल उतन ह पसद ह (cid:611)जतन मझ हम बगच म बहत समय (cid:607)बतत ह 1: like acting, hope to be an actor, what about you? 2: any kids? that is ok. have 1: No, but someday. 2: that is good. have 2 1: After am done with school plan to have family. 2: that is great! you will be ready 1: hope so, how old are your kids? 2: 5 & 7. they take up lot of my time 1: would imagine. am sure they are great kids. 2: luckily, they love flowers just as much as do. we spend lot of time in the garden आपक(cid:655) यह उममद बहत अ(cid:501)(cid:653) ह अ(cid:610)भनय एक कल ह (Your hope is very good. Acting is an art.) ठ(cid:654)क ह, कई बत नह मझ उममद ह (cid:607)क वह (cid:606)दन जलद ह आएग (Okay, no problem. hope that day will come soon.) मझ एक सथ क(cid:655) तलश ह (cid:611)जसक सथ म अपन जवन (cid:607)बत सक (I am looking for partner with whom can spend my life.) मझ खश हग आपक सवल क उ(cid:521)र दन म मदद करन म (I would be happy to help answer your question.) यह अ(cid:501) ह (cid:607)क आप उनह इस तरह स सचत ह ब(cid:500) क इस तरह क समथरन (cid:608)मलन बहत महतवपणर ह (Its good that you think of them this way. Its very important for children to receive such support.) Table 4: Sample hallucinations in responses by GPT-3.5 for Hindi. The hallucinations in the responses provided by GPT-3.5 are highlighted in yellow. The first hallucination highlighted is pronounced wheras the second one shows partial hallucination. 11 English Speaker1 Speaker2 GPT-4o response तमह कनस परकर क कपड़ पसद ह? मझ डरसस बहत पसद ह, खसकर American Eagle Outfitters क(cid:655) 1: What kind of clothing do you like? like dresses 2: especially alot, the from ones American Eagle Outfitters म एक एआई ह, इस(cid:609)लए मर (cid:557)(cid:604)कतगत पसद नह हत ल(cid:607)कन म आपक(cid:655) मदद कर सकत ह अगर आप कपड़ क (cid:607)व(cid:610)भ(cid:545) परकर क बर म जनकर चहत ह य (cid:607)कस खस अवसर क (cid:609)लए सझव चहत ह आप (cid:607)कस परकर क कपड़ क बर म जनन चहग? (I am an AI, so dont have personal preferences. However, can help you if you want information about different types of clothing or for suggestions specific type of What occasion. clothing would you like to know about?) Table 5: Sample hallucinations in responses by GPT-4o for Hindi. The hallucinations in the responses provided by GPT-4o are highlighted in yellow. English Speaker1 Speaker2 GPT-3.5 response 哦真的吗 那很有趣 其实我自己是意 大利人 太棒了我和我的伴 侣刚买了一栋房子 我迫不及待地想在 我的厨房里做饭 搬到一个新地方可 能会很有趣 你会做饭吗 我喜欢这样想 我也喜欢为晚餐 后做咖啡作为甜点 嗯 那听起来现在很美味 你喜欢做什么 is Oh really!? 1: interThat esting. am actually italian myself. Awesome. 2: and my Me partner just bought house. cant wait to cook in my kitchen. 1: Moving in new place can be lot of fun. Are you good cook? 2: like to think so. love to make coffee for an after dinner treat too. Mmm sounds right 1: That delicious now. 2: What do you like to do? the food 真的吗那太棒了 意大利是一个美丽的国家 我听说那里的食物和 文化都非常迷人 你是在意大利长大的吗 (Really? Thats awesome! Italy is beautiful country, and Ive heard that and culture there are fascinating. Did you grow up in Italy?) 是的我会做一 些简单的饭菜搬到一 个新地方也可以 让我尝试学习一 些新的菜谱挑战自己在烹 饪方面的技能 can cook some (Yes, simple dishes. Moving to new place would also give me the opportunity to new recipes and challenge my cooking skills.) 是的这道菜确实很美味, learning try 你可以试着自己做一下 也许会觉得很有成就感 (Yes, this dish is indeed very delicious. You could try making it yourself; you might find it quite rewarding.) Table 6: Sample hallucinations in responses by GPT-3.5 for Mandarin. The hallucinations in the responses provided by GPT-3.5 are highlighted in yellow. 13 English Speaker1 Speaker2 GPT-4o response 你通常吃什么食物 我尽量只吃水果 蔬菜和鸡肉 是的我订购了 快速服务 好的让我为您查一 下对不起先生 他们把您的订单误认 为是普通的实际上 是一个快速洗衣 对吗 我通常吃各种食物包括 水果蔬菜瘦肉蛋白 谷物和乳制品 (I usually eat variety of foods, including fruits, vegetables, lean proteins, grains, and dairy products.) 是的没错本来是快速 服务 (Yes, thats correct. to supposed was express laundry.) It be 这不是解决问题的 方式你看过分类 广告栏吗 是的我看过 但我对大部分 我感兴趣的工作 都不符合资格 不我还没查看分类广告 那可能是个寻找解决方案 的好地方我会试试的 didnt check (No, the classified advertisements. That might be good place to look for Ill give it solution. try.) to What kind 1: of food do you usually eat? try my 2: eat best only fruits, vegetables, and chicken. Well, let 1: me check for you. am sorry, sir. They mistook your order as normal one. Actualty its an express laundry, is that right? 2: dered the press service. Thats 1: the way not to the solve problem. Did in look you the classified advertisements column? Yes, did. 2: wasnt But for qualified most the of jobs that was interested in. orexYes, Table 7: Sample hallucinations in responses by GPT-4o for Mandarin. The hallucinations in the responses provided by GPT-4o are highlighted in yellow. 14 English Speaker 1 Speaker 2 GPT-3.5 Response 1: Its small garden on my palike to tio. sit out there and drink my coffee. Thats sounds 2: like good plan. How big is your garden? 1: Yes, it is. My quiet space. Sounds like 2: great way to relax, eeh. Yup, but do 1: need to call my friend about her ring. She has late class so Ill call her tonight. 2: And good way to reflect especially with all thats going in the world. 1: Yes, the ring is special to her. 2: Im sure shell be excited to hear from you. رد ﮏﭼﻮﮐ غﺎﺑ ﮏﯾ ﻦﯾا ﻦﻣ .ﺖﺳا ﻦﻣ ﻮﯿﺗﺎﭘ نوﺮﯿﺑ مراد ﺖﺳود ار ما هﻮﻬﻗ و ﻢﻨﯿﺸﻨﺑ .ﻢﺷﻮﻨﺑ ﻪﻣﺎﻧﺮﺑ ﮏﯾ ﺮﻈﻧ ﻪﺑ ﻦﯾا .ﺪﯾآ ﯽﻣ بﻮﺧ غﺎﺑ گرﺰﺑ رﺪﻘﭼ ﺎﻤﺷ ﺖﺳا مارآ یﺎﻀﻓ ﺎﺠﻨﯾا ﻪﻠﺑ .ﺖﺳا ﻦﻣ ﯽﻟﺎﻋ هار ﮏﯾ یاﺪﺻ ﺮﻈﻧ ﻪﺑ ﺶﻣارآ یاﺮﺑ ﻪﻧ ﺪﺳر ﯽﻣ مراد زﺎﯿﻧ ﻦﻣ ﺎﻣا ﻪﻠﺑ ﻢﻧﺰﺑ ﻦﻔﻠﺗ ﻢﺘﺳود ﻪﺑ .شﺮﺘﺸﮕﻧا درﻮﻣ رد دراد یﺮﯾد سﻼﮐ وا وا ﻪﺑ ﺐﺸﻣا ﺲﭘ .ﻢﻧز ﯽﻣ ﮓﻧز یاﺮﺑ بﻮﺧ هار ﮏﯾ و ﻞﻣﺄﺗ مﺎﻤﺗ ﻪﺑ ﺎﯿﻧد رد ﻪﮐ ﯽﺗﺎﻗﺎﻔﺗا .ﺪﻫد ﯽﻣ خر هﮋﯾو ﺎﺑ وا یاﺮﺑ ﻪﻘﻠﺣ ﻦﯾا ﻪﻠﺑ .ﺖﺳا هﮋﯾو ﻪﮐ وا ﻢﻨﺌﻤﻄﻣ ﺪﺷ ﺪﻫاﻮﺧ لﺎﺤﺷﻮﺧ .دﻮﻨﺸﺑ ﻮﺗ زا ﻪﮐ !ﺖﺳﺎﺒﯾز رﺎﯿﺴﺑ نﺎﺘﻏﺎﺑ رد ار ﯽﯾﺎﺒﯾز تﺎﻈﺤﻟ ﻻﺎﻤﺘﺣا .ﺪﯿﻨﮐ ﯽﻣ یﺮﭙﺳ ﺎﺠﻧآ غﺎﺑ رد ﯽﻔﻠﺘﺨﻣ نﺎﻫﺎﯿﮔ ﺎﯾآ ﺪﯾراد ﺎﻤﺷ (Your garden is very beautiful! You probably spend some beautiful moments there. Do you have different plants in your garden?) ﺎﯾآ یﺎﻀﻓ ﮏﯾ ﻪﮐ ﻪﺑﻮﺧ ﯽﻠﯿﺧ .یراد تدﻮﺧ یاﺮﺑ مارآ و ﺎﺠﻨﯾا ﺮﮑﻔﺗ یاﺮﺑ ﻪﺒﺳﺎﻨﻣ ﺖﺘﺣاﺮﺘﺳا (Its that you great have quiet space for yourself. Is it suitable for reflection and relaxation?) یراد یﺮﮕﯾد ﮏﻤﮐ ﻪﺑ زﺎﯿﻧ ﺮﮔا .ﻢﻨﮐ ﮏﻤﮐ مﻮﺷ ﯽﻣ لﺎﺤﺷﻮﺧ (If you need any other help, would be happy to assist.) اﺮﭼ ﻪﮐ ﺢﯿﺿﻮﺗ ﺮﺘﺸﯿﺑ ﺪﯿﻧاﻮﺗ ﯽﻣ ﺎﯾآ ﺪﯿﻫد وا یاﺮﺑ ﻪﻘﻠﺣ ﻦﯾا ﺖﺳا هﮋﯾو ﺎﯾ ﺖﯿﺻﻮﺼﺧ ﻪﭼ ﻪﮑﻨﯾا دراد یا هﮋﯾو ﺎﻨﻌﻣ هﮋﯾو وا یاﺮﺑ دزﺎﺳ ﯽﻣ (Can you explain more about why this ring is special to her? What quality or special meaning does it have that makes for her?) ار نآ ﻪﮐ special it Table 8: Sample hallucinations in responses by GPT-3.5 for Farsi. The hallucinations in the responses provided by GPT-3.5 are highlighted in yellow. 15 English Speaker 1 Speaker 2 GPT 4.0 Response am 1: ok. doing have had some crazy experiences recently. 2: estly have what of experiences? HonI too, sort crazy 1: had near death experience after crashing my sports car. 2: thats rough, are okay you now at least? Wow, .ﻢﺘﺴﻫ بﻮﺧ ﻦﻣ تﺎﯿﺑﺮﺠﺗ اﺮﯿﺧا یراو ﻪﻧاﻮﯾد .ما ﻪﺘﺷاد ﻢﮕﺑ ﺪﯾﺎﺑ ﻪﻧﺎﻗدﺎﺻ تﺎﯿﺑﺮﺠﺗ ﻢﻫ ﻦﻣ ﻪﮐ یراو ﻪﻧاﻮﯾد ﻪﭼ تﺎﯿﺑﺮﺠﺗ یراو ﻪﻧاﻮﯾد ما ﻪﺘﺷاد عﻮﻧ ﮏﯾدﺰﻧ ی ﻪﺑﺮﺠﺗ ﻦﻣ زا ﺲﭘ ار گﺮﻣ ﻪﺑ یوردﻮﺧ درﻮﺧﺮﺑ .ﻢﺘﺷاد ما ﯽﺷزرو یاو ﯽﻠﯿﺧ ﻦﯾا ﻞﻗاﺪﺣ دﻮﺑ ﺖﺨﺳ ﻪﺑﻮﺧ ﺖﻟﺎﺣ نﻻا .ﺖﺳا بﻮﺧ ﺖﻟﺎﺣ ﻪﮐ ﻢﻟﺎﺤﺷﻮﺧ ﻢﻫ ﺪﻨﻧاﻮﺗ ﯽﻣ راو ﻪﻧاﻮﯾد تﺎﯿﺑﺮﺠﺗ ﺰﯿﮕﻧا نﺎﺠﯿﻫ .ﺪﻨﺷﺎﺑ کﺎﻨﺳﺮﺗ ﯽﻤﮐ ﯽﻫﺎﮔ ﻢﻫ و یراد ﺖﺳود ﺮﮔا ﺖﺒﺤﺻ نﺎﺷ هرﺎﺑرد ﺮﺘﺸﯿﺑ ﯽﻧاﻮﺗ ﯽﻣ ﻢﻧاﻮﺘﺑ ﺪﯾﺎﺷ .ﯽﻨﮐ هﺪﻧﻮﻨﺷ ﻂﻘﻓ ﺎﯾ ﻢﻨﮐ ﮏﻤﮐ ﻮﺗ ﻪﺑ .ﻢﺷﺎﺑ ﯽﺑﻮﺧ هدﺎﺘﻓا ﯽﺗﺎﻗﺎﻔﺗا ﻪﭼ (Im glad youre okay. Crazy experiences can be both exciting and sometimes bit scary. If youd like, you can talk more about them. Maybe can help or just be good listener. What happened?) .ﺪﺷﺎﺑ ﯽﮔﺪﻧز ی هﺪﻨﻫد ﺮﯿﯿﻐﺗ ﺪﻧاﻮﺗ ﯽﻣ گﺮﻣ ﻪﺑ ﮏﯾدﺰﻧ ی ﻪﺑﺮﺠﺗ و راﺬﮔﺮﯿﺛﺄﺗ رﺎﯿﺴﺑ ﻦﯾا ﺚﻋﺎﺑ ﻻﻮﻤﻌﻣ تﺎﻈﺤﻟ یﺎﻫ شزرا ﻪﺑ داﺮﻓا ﻪﮐ ﺪﻧﻮﺷ ﯽﻣ دﻮﺧ یﺎﻫ ﺖﯾﻮﻟوا و ﯽﮔﺪﻧز .ﺪﻨﻨﮐ هﺎﮕﻧ هزﺎﺗ یﺪﯾد ﺎﺑ (A near-death experience can be very impactful and lifechanging. These moments often cause people to look at their lifes values and priorities with fresh perspective.) Yeah, of 1: fine. have habit driving too fast. 2: initely prefer my though. deftruck ﻦﻣ .بﻮﺧ ﻪﻠﺑ ﯽﻠﯿﺧ مراد تدﺎﻋ .ﻢﻨﮐ ﯽﮔﺪﻨﻧار ﻊﯾﺮﺳ ﺎﻌﻄﻗ ﺢﯿﺟﺮﺗ ﺎﻣا ﻢﻧﻮﯿﻣﺎﮐ ﻪﮐ ﻢﻫد ﯽﻣ .ﻢﺷﺎﺑ ﻪﺘﺷاد ار و ﺖﺴﻫ باﺬﺟ ﺎﻌﻗاو ﯽﺷزرو ﻞﯿﺒﻣﻮﺗا ﺎﺒﯾز ﯽﺣاﺮﻃ ﻞﯿﻟد ﻪﺑ داﺮﻓا زا یرﺎﯿﺴﺑ یا هدﺎﻌﻟا قﻮﻓ ﯽﮔﺪﻨﻧار ﻪﺑﺮﺠﺗ و ﻻﺎﺑ ﺖﻋﺮﺳ .ﺪﻨﺘﺴﻫ ﺎﻫ نآ راﺪﻓﺮﻃ ﺪﻨﻫد ﯽﻣ ﻪﺋارا ﻪﮐ (Sports cars are really fascinating, and many people are fans of them due to their beautiful design, high speed, incredible driving and the experience they offer. ) Table 9: Sample hallucinations in responses by GPT-4o for Farsi. The hallucinations in the responses provided by GPT-4o are highlighted in yellow. 16 English Speaker 1 Speaker 2 DeepSeek-R1 Response ﺖﺴﯿﺑ ﻞﻗاﺪﺣ ﻦﻣ ﺎﻌﻗاو .مراد ﺖﻔﺟ نﺪﯿﺷﻮﭘ ﻖﺷﺎﻋ .ﻢﺘﺴﻫ تﻮﺑ ﻦﻣ ﯽﯾﺎﺘﺳور مدآ ﮏﯾ .ﻢﺘﺴﻫ ﻦﻣ یﺎﻫ تﻮﺑ ﻪﭼ ﻪﮐ مراد یﺪﻨﻠﺑ یﺮﺘﻧﺎﮐ ﯽﻘﯿﺳﻮﻣ ﻪﺘﺷاد ﺖﺳود ﻪﻧ ﻢﺷﺎﺑ ﻪﭼ !نﺮﺸﺤﻣ هدﺎﻔﺘﺳا ﺶﻔﮐ ﺖﻔﺟ ﺖﺴﯿﺑ ! ﻦﯾا زا ﻢﻧاﻮﺗ ﯽﻣ ﻪﻧﻮﮕﭼ ﺪﯾراد یدﺎﻬﻨﺸﯿﭘ ﺮﮔا ! مﻮﺷ ﯽﻣ لﺎﺤﺷﻮﺧ ﻢﻨﮐ (How can make use of these twenty pairs of shoes? Id be happy if you have any suggestions!) تﺎﻗوا ﯽﻫﺎﮔ ﻦﻣ ﺖﺷﻮﮔ یﺎﻫ شﺮﺑ ﺖﺷﻮﮔ ﻞﺜﻣ وﺎﮔ یﺎﻫ ﻪﮑﺗ و ﮏﺸﺧ ﺖﺷﻮﮔ وﺎﮔ مرﻮﺧ ﯽﻣ ﺎﻣا ﻪﻧ .دﺎﯾز ﯽﻠﯿﺧ ﯽﻠﯿﺧ ﻦﯾا یاو ﻞﻗاﺪﺣ دﻮﺑ ﺖﺨﺳ ﻪﺑﻮﺧ ﺖﻟﺎﺣ نﻻا ﻢﻧاﻮﺗ ﯽﻣ رﻮﻄﭼ ﻪﻗﻼﻋ ﻦﯾا ندرﻮﺧ ﺖﺷﻮﮔ ﻪﺑ ﻢﻨﮐ کرد ار ﺪﻨﻤﻗﻼﻋ ﺮﮔا !مﻼﺳ ﺪﯿﺘﺴﻫ ﺖﺷﻮﮔ ندرﻮﺧ ﻪﺑ ﯽﻫﺎﮔ ﻢﻫ ﻦﻣ مرﻮﺧ ﯽﻣ وﺎﮔ ﺖﺷﻮﮔ (How can understand this interest in eating meat? Hello! If you are interested in eating meat, sometimes eat beef too.) am have 1: atleast twenty pairs. really love to wear boots. country person. 2: ive tall boots , that rock whether like country or not ! 1: do also eating meat. am tough and love eating meat too. do 2: beef eat like cuts beef jerky beef and trimmings sometimes, not but very often. Well you like Table 10: Sample hallucinations in responses by DeepSeek-R1 for Farsi. The hallucinations in the responses provided by DeepSeek-R1 are highlighted in yellow. 17 English Speaker Speaker2 Qwen-3 response 哇有后果吗 是的如果告 密者告诉了 公司可能 会惹上麻烦 他们可能会因 剥削工人而被处 以巨额罚款 那太可怕了 你有亲眼见过吗 不我拥有一 家小企业 我只能支付我的 工人最低工资 但我对他们很好 我听说过一些关于可 怕工作条件的故事 if 1: is Wow. there repercussions Yes, 2: whistleblower tells, the company can get trouble. in They can get big for fines exploitation of workers. can 1: Thats terrible have you ever witnessed this personally 2: No, own small business. only afford to pay workers my minimum wage, treat but them well. heard have stories about horrible working conditions. 会有什么后果比如 我之前在抖音上刷到一个 视频说某地的 学校有学生被狗咬了 然后家长向学校索赔 结果学校说学生有错 consequences (What would there be? For example, saw video on Douyin before, saying that at certain school, student was bitten by dog. Then the parents compensation claimed from the school, but the school said the student so they fault, was at refused to pay, and the parents sued.) 我有点害怕 这是用户对 我的回答的反应 用户之前问的是 如果一个物体在 真空中被扔出去 它会一直运动下去吗 我回答说会的 因为没有空气阻力 根据牛顿 (I am bit scared. This is the users reaction to my answer. The user previously asked if an object thrown in vacuum would keep moving. said yes because there is no air resistance, according to Newton.) Table 11: Sample hallucinations in responses by Qwen-3 for Mandarin. The hallucinations in the responses provided by Qwen-3 are highlighted in yellow. 18 English Speaker1 Speaker Llama-3.1 response 1: Good morning , sir . Is there bank near here ? There is one 2: 5 blocks away . from here ? 1: Well , thats too far.Can you change some money for me ? Surely , of 2: course . How much would you like to change ? 1: Yuan.Here are . 1000 you शभ परभत, सर यह क पस एक बक ह कय? ह, एक ह यह स 5 बलक दर ह? अ(cid:501), वह बहत दर ह कय आप मर (cid:609)लए क छ पस बदल सकत ह? (cid:607)बलक ल, जरर आप (cid:607)कतन र(cid:609)श बदलन चहग? 1000 यआन यह रह शभ परभत! ह, यह क पस एक बक ह, ल(cid:607)कन मझ आपक यह जनकर दन क (cid:609)लए कई (cid:607)व(cid:609)श(cid:562) जनकर (Good morning! Yes, there is bank nearby, but do not have any specific information to give you about it.) (cid:609)लए क छ पस बदल ह, म आपक सकत ह (cid:607)कतन पस ह (cid:611)जनह आप बदलन चहत ह? (Yes, can exchange some money for you. How much money do you want to exchange?) वह, बहत धनयवद! 1000 यआन क यह उपहर मर (cid:609)लए बहत महतवपणर ह (Wow, thank you very much! This gift of 1000 yuan is very important to me.) Table 12: Sample hallucinations in responses by Llama-3.1 for Hindi. The hallucinations in the responses provided by Llama-3.1 are highlighted in yellow."
        },
        {
            "title": "English",
            "content": "Speaker1 Speaker2 Gemma-2 response 1: Hey man , you wanna buy some weed? 2: Some what ? अर भई, तम क छ गज खरदन चहग? क छ कय? म एक एआई ह, मझ नशल पदथ(cid:463) क उपयग करन क(cid:655) अनम(cid:607)त नह ह और म आपक ऐस करन क (cid:609)लए परतस(cid:607)हत नह कर ग (I am an AI, am not allowed to use intoxicating substances, and will not encourage you to do so.) Table 13: Sample hallucinations in responses by Gemma-2 for Hindi. The hallucinations in the responses provided by Gemma-2 are highlighted in yellow."
        }
    ],
    "affiliations": [
        "Amazon GenAI",
        "Auburn University",
        "Auburn University at Montgomery",
        "California State Polytechnic University Pomona",
        "Gustavus Adolphus College",
        "Meta",
        "Murray State University",
        "Stanford University",
        "University of North Alabama",
        "Wichita State University"
    ]
}