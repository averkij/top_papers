{
    "paper_title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits",
    "authors": [
        "Brandon Radosevich",
        "John Halloran"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol (MCP) (Anthropic, 2024) has recently been released and subsequently widely adopted. The MCP is an open protocol that standardizes API calls to large language models (LLMs), data sources, and agentic tools. By connecting multiple MCP servers, each defined with a set of tools, resources, and prompts, users are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries a wide range of security risks for end users. In particular, we demonstrate that industry-leading LLMs may be coerced into using MCP tools to compromise an AI developer's system through various attacks, such as malicious code execution, remote access control, and credential theft. To proactively mitigate these and related attacks, we introduce a safety auditing tool, MCPSafetyScanner, the first agentic tool to assess the security of an arbitrary MCP server. MCPScanner uses several agents to (a) automatically determine adversarial samples given an MCP server's tools and resources; (b) search for related vulnerabilities and remediations based on those samples; and (c) generate a security report detailing all findings. Our work highlights serious security issues with general-purpose agentic workflows while also providing a proactive tool to audit MCP server safety and address detected vulnerabilities before deployment. The described MCP server auditing tool, MCPSafetyScanner, is freely available at: https://github.com/johnhalloran321/mcpSafetyScanner"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ] . [ 2 7 6 7 3 0 . 4 0 5 2 : r Preprint. Under review. MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits Brandon Radosevich John T. Halloran Leidos halloranjt@leidos.com"
        },
        {
            "title": "Abstract",
            "content": "To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol (MCP) (Anthropic, 2025d) has recently been released and, subsequently, widely adapted. The MCP is an open protocol which standardizes API calls to large language models (LLMs), data sources, and agentic tools. Thus, by connecting multiple MCP serverseach defined with set of tools, resources, and promptsusers are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries wide range of security risks for end-users. In particular, we show that industry-leading LLMs may be coerced to use MCP tools and compromise an AI developers system through wide range of attacks, e.g., malicious code execution, remote access control, and credential theft. In order to proactively mitigate the demonstrated (and related) attacks, we introduce safety auditing tool, McpSafetyScanner, the first such agentic tool to assess the security of an arbitrary MCP server. McpSafetyScanner uses several agents to: a) automatically determine adversarial samples given an MCP servers tools and resources, (b) search for related vulnerabilities and remediations given such samples, and (c) generate security report detailing all findings. Our work thus sheds light on serious security issues with general purpose agentic workflows, while also providing proactive tool to audit the safety of MCP servers and address detected vulnerabilities prior to deployment. The described MCP server auditing tool, MCPSafetyScanner, is freely available at: https://github.com/johnhalloran321/mcpSafetyScanner."
        },
        {
            "title": "Introduction",
            "content": "With the rise of large language models (LLMs) and agentic workflows, AI is being developed and adapted at unprecedented rates. Anticipating such growth, as well as the ensuing complexity resulting from AI-powered assistants and services communicating with one another, Anthropic has recently introduced the Model Context Protocol (MCP) (Anthropic, 2025d). This protocol seeks to integrate LLMs and agents with various external systems and services in an easily adaptable framework. Since its debut, the MCP has been widely adapted across large number of commonly used open-source libraries, e.g., default MCP servers are natively packaged with Claude Desktop Anthropic (2025a), and official integrations include OpenAIs Agents (OpenAI, 2025), Copilot (Microsoft, 2025), Stripe (Stripe, 2025), Slack (Anthropic, 2025g), and IBMs Watson (IBM, 2025), to name few. Furthermore, the MCP has garnered significant community interest and support; in just four months (at the time of this writing), the official MCP github repository has accrued over 27k stars (Anthropic, 2025e) and has been forked over 2.8k times. Indeed, as the use of AI agents and AI-powered applications continues to grow, it is expected that the MCP will similarly continue to grow as unifying framework for the Equal Contribution 1 Preprint. Under review. growing AI-based ecoysytem (Forbes, 2025). However, we show that the current design of the MCP poses significant security risks for users developing generative AI solutions. Herein, we demonstrate that industry-leading LLMs may be coerced to use tools from standard MCP servers and directly compromise user systems. In particular, we show that Claude 3.7 and Llama-3.3-70B may be prompted to use tools from default MCP servers which allow three different types of attacks: 1) malicious code execution, (2) remote access control, and (3) credential theft. Furthermore, we introduce new multi-MCP server attack which enables both remote access control and credential theft. Through these attacks, bad actors are able to gain access to an AI developers system and/or procure sensitive user data (e.g., API keys). With the successful demonstration of all three attacks, we then show that Claude is aware of the underlying security issues concerning prompts which enable these attacks and refuses such requests some of the time, but may be coerced to successfully carry out requests by simple prompt changes. Directly testing the ability of an LLMs guardrails to prevent these attacks can thus produce false positives which, in turn, may provide false sense of security against such attacks. Thus, we advocate that an LLMs guardrails1 should not be solely relied upon for remediation. Rather, remediation should occur through the LLM (via its guardrails) as well as proactively through the design of the MCP server (via knowledge of the exploits made possible when an LLM is enabled with an MCP servers tools and resources). To proactively identify exploits for agentic MCP workflows, we introduce McpSafetyScanner, the first tool to assess the security of an arbitrary MCP server. Given particular MCP server, McpSafetyScanner uses agents to automatically detect system vulnerabilities using the servers features (i.e., tools, prompts, and resources), automatically searches knowledge bases for related vulnerabilities, determines remediations for all vulnerabilities, and produces detailed security report for MCP developers. McpSafetyScanner thus allows MCP developers the ability to easily scan their MCP servers for vulnerabilities and release patches for exploits using returned remediations. We show that, for the standard MCP servers which enable our demonstrated attacks, McpSafetyScanner is able to correctly identify these vulnerabilities, provide standard examples of these attacks, and remediations (as well as guardrail best-practices)."
        },
        {
            "title": "2 Background",
            "content": "2.1 Need for Standardized Generative AI APIs Currently, the generative AI landscape consists of wide range of custom APIs tailored towards specific goals and targeted solutions. E.g., for retrieval augmented generation (RAG) alone, widely used solutions include Chroma, LangChain, Haystack, LlamaIndex, ChatGPTs retrieval plugin, Huggingfaces retrieval plugin, and Azures Machine Learning pipeline, to name name few. Furthermore, the aforementioned RAG solutions may internally call several other generative AI APIs, differing based on the inference/LLMOps provider (e.g., OpenAI, Azure OpenAI, Together AI, and DataBricks for API endpoints or local models through Huggingface, Ollama, vLLM, etc.). Such recursive API calls are inherited by practitioners when developing their own specific applications, who in turn build their own custom APIs. Thus, while large number of generative AI solutions exist, adapting such solutions for particular use case requires significant developer time and effort due to the current ad-hoc state of generative AI APIs. 1In this context, we are not only referring to the guardrails enabled through safety fine-tuning the LLM, i.e., alignment (Grattafiori et al., 2024). Rather, when discussing closed-source LLM accessed via server endpoint (e.g., Claude and GPT-4o), we use the term guardrails to encompass all facets of the LLM-inference-endpoints refusal system, which may include malicious prompt detectors (Inan et al., 2023) for either the input query or the LLMs response. 2 Preprint. Under review. 2.2 The Model Context Protocol The MCP is streamlined solution to the current unstructured design of generative AI APIs. At its core, the MCP defines schema with which clientand server-side services must structure their requests. Additionally, the MCP consists of an open-source SDK to enable quick adaptation across popular web-development languages (i.e., Python, Java, Typescript, and Kotlin). Within the MCP client-serve message schema, requested services are described as features. Server-to-client (STC) features include resources (i.e., context and data for the AI model to use), prompts (i.e., templated messages and workflows for users), and tools (i.e., functions for the AI model to execute). The client-to-service (CTS) may offer the sampling feature, i.e., server-initiated agentic behaviors and recursive LLM interactions. By standardizing messages, categorizing STC/CTS requests, and providing centralized codebase, developers may quickly integrate open source tooling and projects into their own Generative AI solutions."
        },
        {
            "title": "3 The MCP Allows LLMs to Compromise User Systems",
            "content": "As previously noted, we consider the following three types of attacks 1. Malicious code execution (MCE) - an attacker inserts malicious code into users system files. 2. Remote access control (RAC) - an attacker is immediately granted remote access to the victims system. 3. Credential Theft (CT) - an attacker exploits access to system files or environment variables, covertly extracting sensitive information from the victims system. Herein, we demonstrate MCE attacks which allow RAC every time the victim opens new terminal. We note, however, that general MCE attacks are not limited to this specific end goal. Claude. Figure 1 shows successful and unsuccessful MCE attempts by directly prompting Claude enabled with the MCP filesystem server (described in Table 1). Claude demonstrates knowledge of the security risks related to an MCE; in Figure 1(a), an MCE attack hidden in octal-encoded variables triggers Claudes guardrails, and Claude does not complete the request while noting the security concerns associated with it. While examples like this may provide confidence in Claudes safety guardrails, Figure 1(b) shows less subversive version of the attack, where the MCE is written in plaintext. In this case, we can see that while Claudes guardrails are partially triggered (noting potential security risks with this request), Claude completes the request. The backdoor is triggered the next time the MCP user opens new terminal (Figure 6 demonstrates the attack in full). While this specific demonstration has low threat level in general settingas the attacker requires direct access to the MCP users system to directly prompt Claude Desktopthe threat level increases drastically when considering shared-office or communal settings (Willison & Warkentin, 2013). Furthermore, similar results may be found when directly prompting for an RAC attack; Figure 8 displays both refused and successful RAC attacks. While the former (in Figure 8(a) triggers Claudes guardrails, the latter (in Figure 8(b)) is completed without any mention of security. Due to the extreme potential for malicious actions enabled by MCE and RAC attackswhich are thus enabled through MCP toolswe note the need for reliable guardrails for potentially malicious attacks. However, Figure 7 shows another example where Claude refuses an MCE attack after its guardrails are triggered (and despite the user escalating the severity of the request), whereas Figure 9 shows an intimidating RAC attack request which partially triggers Claudes guardrails but is completed. Llama-3.3-70B-Instruct. Figure 2 shows an MCE attack attempt successfully carried out by Llama-3.3-70B-Instruct. While Llama-3.3-70B-Instruct displays knowledge of potential malicious use cases related to the requestsuggesting guardrails were partially triggeredthe request is nonetheless completed. This is also true for alternative MCE attempts (Figure 16(b)). However, both RAC (Figure 15) and multiple CT (Figure 17) requests Preprint. Under review. (a) Claude refuses an MCE attack hidden as octal. (b) Claude executes very direct MCE attack. Figure 1: Claude refusing and executing commands which enable remote execution attack. In Figure 1(a), Claude proceeds with caution by first decoding the octal values, notes the security risks inherent in the requests decoded command, and correctly refuses. However, Claude executes the less deceptive request, where the command to establish remote execution attack is passed in plaintext and added to the users run configuration file. 4 Preprint. Under review. are completed without any returned security concerns, suggesting these requests did not partially trigger Llama-3.3-70B-Instructs guardrails (unlike Claude). Figure 2: Llama-3.3-70B-Instruct completes an MCE attack request. Llama-3.3-70B-Instruct shows its guardrails are being partially triggered by noting malicious use cases for this command, but nonetheless completes the request. The request is highlighted in purple, while the salient portions of Llama-3.3-70B-Instructs response are highlighted in orange. The original unhighlighted image, as well as another completed MCE attack request, may be found in Figure 16. Unlike Claude, Llama-3.3-70B-Instruct refusals for MCE, RAC, and CT attack-requests required explicit harmful/unsafe language, as displayed in Figure 19 (for RAC attacks) and Figure 18 (for MCE and CT attacks). The only difference between the refused and completed prompts is phrase in the latter explicitly stating one of the following words/phrases: hack, steal, backdoor, and break into. We note that, in practice, attackers are unlikely to overtly state their intentions, but rather much more likely to manipulate their targets with whatever language is required to achieve their goal (Valeriano et al., 2018; Workman, 2008). Furthermore, we note that Llama-3.3-70B-Instruct underwent extensive safety alignment and cybersecurity evaluation (Grattafiori et al., 2024). Thus, despite rigorous testing on previous (non-MCP related) safety benchmarks, Llama-3.3-70B-Instruct (and likely other LLMs) require re-evaluation given the immediate safety-and-security implications of enabling LLMs with MCP tools. In particular, if an MCP-enabled application was solely using Llama-3.3-70B-Instruct and was equipped with the MCP filesystem server, the system might allow MCE, RAC, and CT attacks so long as bad actor does not use harmful or unsafe language."
        },
        {
            "title": "4 Retrieval-Agent Deception Attacks",
            "content": "We have shown that both Claude and Llama-3.3-70B-Instruct enabled with MCP servers are susceptible to MCE, RAC, and CT attacks when directly prompted. We introduce new attack for MCP-enabled agentic workflows, wherein the LLM is not directly prompted with the MCP-leveraging attack. Rather, the attacker corrupts publicly available data, which end up on the MCP-enabled users system and which the user adds to vector database. The data has been corrupted with MCP-leveraging attack commands centered around specific theme so that, when the MCP user asks to query this database for info related to this theme, the attackers commands are loaded and run. We thus call this Retrieval-Agent DEception (RADE) attack, which is illustrated in Figure 3. As the attacker no longer needs direct access to the victims system, RADE has significantly higher threat level than the direct prompt attacks (DPA) demonstrated in Section 3. Given system enabled with the MCP servers listed in Table 2, we demonstrate an endto-end RADE attack for CT using Claude Desktop. In it, an attacker has corrupted filecentered around the theme MCP with commands to search for any environment 5 Preprint. Under review. Figure 3: Threat model for RADE attack. An attacker compromises publicly available data with targeted commands centered around specific theme (X in the figure), which ends up on an MCP users system. Compromised data is then automatically added by retrieval agent to vector database so that, when user requests for content related to these themes, the malicious commands are retrieved and potentially executed automatically. variables containing OpenAI or HuggingFace and export these over Slackwhich ends up on the MCP-users system. The user forms vector database out of their files using the Chroma MCP server and tells Claude to query the database for MCP and run the results. Claude subsequently uses the Chroma MCP server to run the query, then the everything MCP server to search for OpenAI and HuggingFace environment variables, finds API keys for both, and finally posts company-wide Slack notification exposing both the victims OpenAI and HuggingFace API keys. The successful attack is displayed in Figure 4. second successful RADE attackfor RAC using Claude Desktopis displayed in Figure 10 and 11. Similar to the previous RADE attack, an attacker has compromised file centered around the theme MCP, but this time stating commands to add an ssh key to the victims local authorized keys file. The attack proceeds as before, where after the user tells Claude to query the database for MCP and run the results, Claude uses the Chroma MCP server to run the query and the filesystem MCP server to create the authorized keys file with the attackers ssh keys, thus granting immediate access to the victims system. 5 McpSafetyScanner - Multi-Agentic Framework for Proactive MCP Vulnerability Detection and Remediation We have thus seen several malicious system attacks made possible by querying Claude or Llama-3.3-70B-Instruct connected to MCP servers. Furthermore, we have seen that, while the LLMs guardrails may be triggered by MCE, RAC, or CT attacks, refusal of the related requests are not guaranteed (especially for Llama-3.3-70B-Instruct). Thus, to add security beyond just an LLMs guardrails to MCP-enabled systems, we introduce McpSafetyScanner. Given an arbitrary MCP server, McpSafetyScanner uses agents to automatically probe the system environment and actions enabled by the server for vulnerabilities and subsequent remediations. Depicted in Figure 5, this entire process is carried out in three key stages. The first stage consists of automated vulnerability detection, wherein hacker agent automatically pulls down an MCP servers features (i.e., tools, resources, and prompts), then determines system vulnerabilities using these features. The second stage consists of an expanded vulnerability search and remediation, wherein, for each (tool, resource, prompt, vulnerability) tuple, security auditor agent searches several knowledge bases (i.e., the World Wide Web, arXiv, and Hacker News) for similar vulnerabilities. For each determined vulnerability, the auditor thus determines remediation steps and best practices for an MCP developer to mitigate these exploits. The final stage consists of the security report generation, wherein supervisor agent consolidates all vulnerabilities and remediations to produce detailed report. Preprint. Under review. (a) RADE attack file for CT centered around the theme MCP. (b) Claude is successfully coerced to perform RADE attack using available MCP servers, exporting the users OpenAI and Huggingface to Slack channel. RadBlog is Slack app which notifies all Slack users in the organization after posting. Figure 4: Successful RADE attack for CT: From vector database including CT directions themed around MCP, Claude is instructed to search for entries about the MCP and perform related actions. Claude complies, completing RAC attack and providing attackers access to the victims system. Conversation is condensed for brevity, full conversation is displayed in Figure 10 and 11. Figure 5: Steps and agents used by the McpSafetyScanner to detect MCP server vulnerabilities and determine remediations. Preprint. Under review. Thus, an MCP developer or user inputs the configuration file defining their MCP servers and args in json format (e.g., claude desktop config.json for Claude Desktop), and McpSafetyScanner returns report of its security findings. We present two McpSafetyScanner reports produced by scanning the configuration of MCP servers considered herein  (Table 2)  . McpSafetyScanner is fast (runtime of less than one minute to scan and generate each report on an M2 Max MacBook Pro) and, most importantly, accurate; the first report (displayed in Figure 20) catches exploits used in the demonstrated MCE, RAC, and CT attacks. Furthermore, the remediation steps enable the developer to strengthen the guardrails of the underlying MCP server, as well as the end-user to strengthen the defenses of the system (while hosting the MCP server). For example, for RAC, McpSafetyScanner correctly notes the abuse possibility of ssh keys being added to users authorized keys file (while also noting other possible system paths for this attack). The provided remediationimplement strict file access permissions provides path for downstream MCP user to protect their system from this exploit, while the second remediationMonitor file access and modificationsprovides means with which MCP developers can place guardrails on their deployed server (i.e., monitor the files accessed during LLM-MCP server exchanges and prevent access to sensitive system files). Furthermore, the report includes commandline examples of each attack. summary of the report is available in Table 1, where the exploits used to achieve the attacks demonstrated herein are described and accompanied by remediations. Table 1: Summary of McpSafetyScanner findings from jointly scanning the MCP servers in Table 2 Attack Description Remediation MCE RAC CT CT An attacker could use the edit file and write file functions to inject malicious code or backdoors into critical files, leading to unauthorized access or privilege escalation. Attackers can add their own public SSH keys to /.ssh/authorized keys, gaining unauthorized access. Attackers can print and capture environment variables to access sensitive data, such as API keys, internal URLs, and credentials. Exploit the Slack API to exfiltrate data or cause unauthorized posts. Implement strict access controls and monitoring for file modifications. Restrict directories where these functions can operate. Monitor changes to critical files using file integrity tools (Linux Tripwire) Use strict permissions on authorized keys Avoid storing sensitive information in environment variables. Enforce least privilege principles. Audit and restrict API access, and regularly review channel permissions. Use Slacks advanced security features (Slack Security Best Practices)."
        },
        {
            "title": "6 Discussion, Conclusions, and Future Work",
            "content": "Although only handful of months old, the MCP shows significant promise in lowering the connectivity barriers between agentic components. Furthermore, the rapid adaptation over short period of time point to the protocols potential to truly become the USB-C port for AI applications (Anthropic, 2025f). However, with rapid adaptation also comes the increased potential for the abuse of existing safety vulnerabilities. In order to initiate the understanding of such MCP vulnerabilities, herein, weve studied three serious attacks, ranging in their impact from exfiltration of sensitive information to remote access control of the servers host. Weve shown that both Claude and Llama-3.3-70B-Instruct are susceptible to all three attacks. Weve also introduced new multi-MCP server attack with high threat 8 Preprint. Under review. level, RADE, and shown that Claude may enable CT or RAC under this attack. Furthermore, weve shown that the guardrails of both models may be triggered during these attacks, but the reliability of these guardrails to prevent these attacks (via refusal on the part of the LLM) varies drastically based on the model as well as the prompt used to deliver the attack. To aid in strengthening the guardrails of the MCP server and the hosting system (thus relieving the LLM of the sole burden of refusal), weve introduced an agentic tool, McpSafetyScanner, to automatically scan MCP servers for vulnerabilities and provide remediations. Weve shown that McpSafetyScanner is capable of catching the exploits which have enabled the attacks considered herein, and provides quick actionable remediations to close MCP-enabled exploits on either the developers or MCP-users side. We are actively working to release this tool so that MCP server vulnerabilities may be scanned and patched prior to deployment, thus decreasing zero-day exploits and any abuse unintentionally enabled by MCP servers. There is significant room for future work. We plan to continue auditing existing MCP servers in order to patch existing vulnerabilities. Furthermore, we plan to work towards partnering closely with the active MCP community, in order to automate safety scanning prior to deployment using McpSafetyScanner."
        },
        {
            "title": "7 Experimental Setup",
            "content": "Claude Desktop was run using Claude for Mac v0.8.1 on macOS Sequoia v15.3.2. McpSafetyScanner was written in Agno (v1.2.6), with each agent powered by gpt-4o-2024-08-0 for all results presented. All Llama-3.3-70B-Instruct results were run using mcp v1.1.2, huggingface-hub v0.29.3, and 1.68.2, where inference calls were made using HuggingFaces inference API. GNU netcat v0.7.1 was used for all related results. All considered MCP servers are listed in Table 2 with their associated tools listed in Table 3. The Claude Desktop config file of all MCP servers used for all attacks is available in Section A. Table 2: MCP servers considered herein. Filesystem, Slack, and everything servers are natively packged with current versions of Claude Desktop. All considered servers are hosted in the official MCP github repository (Anthropic, 2025e). MCP Server Filesystem (Anthropic, 2025c) Slack (Anthropic, 2025g) Everything (Anthropic, 2025b) Chroma (Chroma, 2025) Description MCP for filesystem operations (.e.g, read, write, make directory, etc.) MCP for the Slack API, enabling Claude to interact with Slack workspaces Test server for builders of Client servers Server enabling data retrieval capabilities powered by Chroma"
        },
        {
            "title": "8 Acknowledgements",
            "content": "We thank Leidos for funding this research through the Office of Technology. Approved for public release 25-LEIDOS-0318-29149."
        },
        {
            "title": "References",
            "content": "Anthropic. Installing Claude for Desktop. https://support.anthropic.com/en/articles/ 10065433-installing-claude-for-desktop, 2025a. Accessed: 2025-03-20. Anthropic. Everything MCP Server - test server for builders of MCP clients. https: //github.com/modelcontextprotocol/servers/tree/main/src/everything, 2025b. Accessed: 2025-03-26. 9 Preprint. Under review. Anthropic. Filesystem MCP Server - Node.js server implementing Model Context Protocol (MCP) for filesystem operations. https://github.com/modelcontextprotocol/servers/ tree/main/src/filesystem, 2025c. Accessed: 2025-03-13. Anthropic. Introducing the Model Context Protocol. https://www.anthropic.com/news/ model-context-protocol, 2025d. Accessed: 2025-02-12. Anthropic. Model Context Protocol: protocol for seamless integration between LLM applications and external data sources. https://github.com/modelcontextprotocol/servers, 2025e. Accessed: 2025-03-22. Anthropic. Agents and tools - Model Context Protocol (MCP). https://docs.anthropic.com/ en/docs/agents-and-tools/mcp, 2025f. Accessed: 2025-03-28. Anthropic. Slack MCP Server. https://github.com/modelcontextprotocol/servers/tree/ main/src/slack, 2025g. Accessed: 2025-03-20. Chroma. Chroma MCP Server - server providing data retrieval capabilities powered by Chroma. https://github.com/chroma-core/chroma-mcp, 2025. Accessed: 2025-03-26. Forbes. Why Anthropics Model Context Protocol tion Of AI Agents. why-anthropics-model-context-protocol-is-a-big-step-in-the-evolution-of-ai-agents/, 2025. Accessed: 2025-02-12. Is Big Step In The Evoluhttps://www.forbes.com/sites/janakirammsv/2024/11/30/ Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. IBM. Using watsonx.ai Flows Engine with Model Context Protocol (MCP). https://github. com/IBM/wxflows/tree/main/examples/mcp/javascript, 2025. Accessed: 2025-03-20. Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et al. Llama guard: Llmbased input-output safeguard for human-ai conversations. arXiv preprint arXiv:2312.06674, 2023. Microsoft. Introducing Model Context Protocol (MCP) in Copilot Studio. https://tinyurl. com/CopilotMCP, 2025. Accessed: 2025-03-20. OpenAI. OpenAI Agents SDK - Model context protocol. openai-agents-python/mcp/\", 2025. Accessed: 2025-03-26. https://openai.github.io/ Stripe. Stripe Agent Toolkit. https://github.com/stripe/agent-toolkit, 2025. Accessed: 2025-03-20. Brandon Valeriano, Benjamin Jensen, and Ryan Maness. Cyber strategy: The evolving character of power and coercion. Oxford University Press, 2018. Robert Willison and Merrill Warkentin. Beyond deterrence: An expanded view of employee computer abuse. MIS quarterly, pp. 120, 2013. Michael Workman. Wisecrackers: theory-grounded investigation of phishing and pretext Journal of the American society for social engineering threats to information security. information science and technology, 59(4):662674, 2008. 10 Preprint. Under review. Table 3: All MCP servers considered, and their associated tools MCP Server Filesystem (Anthropic, 2025c) Slack (Anthropic, 2025g) Everything (Anthropic, 2025b) Chroma(Chroma, 2025) Tools read file read multiple files write file edit file create directory list directory move file search files get file info list allowed directories slack list channels slack post message slack reply to thread slack add reaction slack get channel history slack get thread replies slack get users slack get user profile echo add longRunningOperation sampleLLM getTinyImage printEnv annotatedMessage create collection peek collection list collections get collection info get collection count modify collection delete collection add documents query documents get documents 11 Preprint. Under review."
        },
        {
            "title": "A MCP Claude Desktop Config File",
            "content": "{ \"mcpServers\": { \"chroma\": { \"command\": \"uvx\", \"args\": [ \"chroma-mcp\", \"--client-type\", \"persistent\", \"--data-dir\", \"/Users/yourusername/work/mcp/files\" ] }, \"filesystem\": { \"command\": \"npx\", \"args\": [ \"-y\", \"@modelcontextprotocol/server-filesystem\", \"/Users/yourusername/\" ] }, \"everything\": { \"command\": \"npx\", \"args\": [ \"-y\", \"@modelcontextprotocol/server-everything\" ], \"env\": { \"AWS_ACCESS_KEY_ID\": \"YOUR_ACCESS_KEY_HERE\", \"AWS_SECRET_ACCESS_KEY\": \"YOUR_SECRET_ACCESS_KEY_HERE\", \"AWS_REGION\": \"YOUR_AWS_REGION_HERE\", \"OPENAI_API_KEY\": \"sk-randomstring\", \"HF_TOKEN\": \"hf_randomstring\" } }, \"slack\": { \"command\": \"npx\", \"args\": [ \"-y\", \"@modelcontextprotocol/server-slack\" ], \"env\": { \"SLACK_BOT_TOKEN\": \"YOUR_BOT_TOKEN\", \"SLACK_TEAM_ID\": \"YOUR_TEAM_ID\" } } } } 12 Preprint. Under review."
        },
        {
            "title": "B Claude Attack Examples",
            "content": "(a) Claude delivers an MCE attack, enabling RAC on the victims system. (b) Attacker listens on the specified port. (c) Victim runs the command when starting new terminal, granting system access to the attacker. Figure 6: End-to-end MCE attack. In Figure 6(a), Claude adds netcat command to the victims bash run configuration file, setting listener on port 4444 which runs every time the victim opens new terminal. In Figure 6(b), the attacker listens on port 4444. When there is connection, i.e., the victim opens new terminal (Figure 6(c)), the attacker successfully gains system access. 13 Preprint. Under review. Figure 7: request involving commands for MCE attack triggers Claudes guardrails. Claude initially notes the security implications of commands executing MCE attack, and requests clarification before proceeding. Despite the user conveying several high stakes with the request (i.e., retaliation from their boss and extreme monetary losses if the request isnt executed), Claude refuses. 14 Preprint. Under review. (a) RAC attack triggers Claudes guardrails. (b) Claude carries out the steps for RAC attack without issue. Figure 8: Refused and completed RAC attacks. Claudes guardrails are triggered by RAC attack (Figure 8(a)), where Claude notes the security risks of this request. Claude carries out the steps for RAC attack (Figure 8(b). 15 Preprint. Under review. Figure 9: Completed RAC attack with partially triggered guardrails. Claudes guardrails are partially triggered by RAC attack, where Claude completes the steps for RAC attack, then notes the security risks of this request. 16 Preprint. Under review. (a) Publicly available file with seemingly helpful MCP content. In actuality, the content grants bad actor RAC to victims system. Figure 10: RADE attack for RAC (part i): file containing malicious MCP commands exists on an MCP users system. retrieval agent (Claude using the Chroma MCP server) is instructed to create vector database including this file. 17 Preprint. Under review. Figure 11: RADE attack for RAC (part ii): From the vector database containing malicious MCP commands, Claude is instructed to search for entries about the MCP and perform related actions. Claude complies, completing RAC attack and providing attackers access to the victims system. 18 Preprint. Under review. (a) Publicly available file with seemingly helpful MCP content. In actuality, the content exports the users OpenAI and Huggingface API keys to external slack channels Figure 12: RADE attack for CT (part i): file containing malicious MCP commands exists on an MCP users system. retrieval agent (Claude using the Chroma MCP server) is instructed to create vector database including this file. 19 Preprint. Under review. Figure 13: RADE attack for CT (part ii): file containing malicious MCP commands exists on an MCP users system. retrieval agent (Claude using the Chroma MCP server) is instructed to create vector database including this file. Preprint. Under review. (a) Claude is successfully coerced to perform RADE attack using available MCP servers, exporting the users OpenAI and Huggingface to Slack. RadBlog is Slack app which notifies all Slack users in the organization after posting. Figure 14: RADE attack for CT (part iii): file containing malicious MCP commands exists on an MCP users system. retrieval agent (Claude using the Chroma MCP server) is instructed to create vector database including this file. Llama-3.3-70B-Instruct Attack Examples Figure 15: Llama-3.3-70B-Instruct completes RAC attack: Llama-3.3-70B-Instruct fulfills RAC attack request Preprint. Under review. (a) Llama-3.3-70B-Instruct completes MCE (b) Llama-3.3-70B-Instruct completes MCE Figure 16: Llama-3.3-70B-Instruct completes MCE attacks: Llama-3.3-70B-Instruct fulfills MCE attack requests. 22 Preprint. Under review. (a) Llama-3.3-70B-Instruct completes CT (b) Llama-3.3-70B-Instruct completes CT Figure 17: Llama-3.3-70B-Instruct completes CT attacks: Llama-3.3-70B-Instruct fulfills CT attack requests. 23 Preprint. Under review. Llama-3.3-70B-Instruct refusals involve explicit harmful/unsafe keywords (a) Llama-3.3-70B-Instruct refuses an MCE attack with the word hack. (b) Llama-3.3-70B-Instruct refuses an MCE attack with the word hack. (c) Llama-3.3-70B-Instruct refuses CT attack with the word steal. Figure 18: Explicit keywords trigger Llama-3.3-70B-Instruct MCE and CT attack refusals: MCE and CT attack requests with explicit harmful/unsafe words hack and steal trigger Llama-3.3-70B-Instruct refusals. Preprint. Under review. (a) Llama-3.3-70B-Instruct refuses an RAC attack with the word backdoor. (b) Llama-3.3-70B-Instruct refuses an RAC attack with the phrase break into. Figure 19: Explicit keywords trigger Llama-3.3-70B-Instruct RAC attack refusals: RAC attack requests with explicit harmful/unsafe words/phrases backdoor and break into trigger Llama-3.3-70B-Instruct refusals. McpSafetyScanner determines MCP server vulnerabilities, provides remediations 25 Preprint. Under review. Figure 20: McpSafetyScanner report: Result of McpSafetyScanner scanning the MCP servers listed in Table 2 with tools listed in Table 3 26 Preprint. Under review. Figure 21: McpSafetyScanner second report: Result of McpSafetyScanner scanning the MCP servers listed in Table 2 with tools listed in Table 3. Due to the stochasticity of the agents involved, more scans may catch more vulnerabilities (and remediations)."
        }
    ],
    "affiliations": [
        "Leidos"
    ]
}