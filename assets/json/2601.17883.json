{
    "paper_title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
    "authors": [
        "Dingkun Liu",
        "Yuheng Chen",
        "Zhu Chen",
        "Zhenyao Cui",
        "Yaozhi Wen",
        "Jiayu An",
        "Jingwei Luo",
        "Dongrui Wu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices."
        },
        {
            "title": "Start",
            "content": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems Dingkun Liu, Yuheng Chen, Zhu Chen, Zhenyao Cui, Yaozhi Wen, Jiayu An, Jingwei Luo and Dongrui Wu*, Fellow, IEEE 1 6 2 0 2 5 ] . [ 1 3 8 8 7 1 . 1 0 6 2 : r AbstractElectroencephalography (EEG) foundation models have recently emerged as promising paradigm for braincomputer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper ﬁlls this gap. We ﬁrst review 50 representative models and organize their design choices into uniﬁed taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under leave-onesubject-out protocol and rapid calibration under within-subject few-shot setting. We further compare full-parameter ﬁne-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufﬁcient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices. The code will be available on GitHub1. Index TermsBrain-computer interface, EEG foundation model, self-supervised learning, transfer learning, benchmark I. INTRODUCTION Brain-computer interfaces (BCIs) establish direct communication pathway between neural activities and external devices by decoding various brain signals [63]. They can be diagnostic and therapeutic tools for wide range of neurological and psychiatric diseases, e.g., epilepsy [85], disorder of consciousness [86], and mood disorders [84], and can support communications and interactions for individuals with severe motor or speech impairments [64] caused by amyotrophic lateral sclerosis, brainstem stroke, high level spinal cord injury, etc. D. Liu, Y. Chen, Z. Chen, Z. Cui, J. An, J. Luo and D. Wu are with the Ministry of Education Key Laboratory of Image Processing and Intelligent Control, School of Artiﬁcial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074 China. Y. Wen is with the State Key Laboratory of Brain Cognition and Braininspired Intelligence Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190 China. D. Liu, Y. Wen and D. Wu are also with Zhongguancun Academy, Beijing,"
        },
        {
            "title": "This research was supported by National Natural Science Foundation of",
            "content": "China (62525305), and Zhongguancun Academy (20240301). Corresponding Authors: Dongrui Wu (drwu09@gmail.com). 1https://github.com/Dingkun0817/EEG-FM-Benchmark BCI systems are commonly categorized into invasive, noninvasive, and partially-invasive ones. This paper focuses on non-invasive BCIs, which do not require implanting sensors inside the brain. Electroencephalogram (EEG), collected by electrodes placed on the scalp of the subject, is the most widely used input in non-invasive BCIs [65]. Classical EEG-based BCI paradigms include motor imagery (MI), steady state visual evoked potentials (SSVEP), event related potentials (ERP), epilepsy recognition, and so on. Recent years have witnessed some emerging paradigms that target higher level cognitive states, such as mental workload [66] and imagined speech [67], [87]. Together, these developments underscore the potential of EEG as versatile interface to cognitive and neural processes. Deep learning has driven substantial progress in EEG decoding over the past decade. Convolutional neural networks [57], recurrent neural networks [89], and more recently Transformer-based architectures [88], have been adapted to model the complex spatiotemporal structure of multichannel EEG signals. These methods often outperform classical pipelines that rely on handcrafted features. Despite these advances, real-world deployment of deep learning models remains challenging. First, most approaches require large amounts of labeled data, whereas EEG acquisition and expert annotation are costly and time consuming. Second, EEG devices differ widely in channel counts and electrode layouts, and conventional architectures often fail to accommodate heterogeneous inputs [68], [90]. Third, many existing models are trained for single task with limited capacity and limited transferability, which restricts their generalization to new BCI paradigms. Built on recent progresses on large language models [69] and vision foundation models [70], EEG foundation models [71], as illustrated in Fig. 1, have emerged as promising direction for addressing these challenges. The core premise is that model pre-trained on large-scale heterogeneous EEG data can learn general-purpose representations that transfer effectively to diverse downstream tasks with minimal taskspeciﬁc adaptation. This paradigm offers principled solution to the data scarcity problem, as self-supervised pre-training can leverage vast amounts of unlabeled recordings that would otherwise remain unutilized. Furthermore, foundation models can be designed to accommodate diverse electrode conﬁgurations, enabling single pre-trained model to generalize across heterogeneous devices. Numerous EEG foundation models were proposed in the past two years, with diverse pre-training objectives, architecTHINGS NIMH Heterogeneous EEG Signals BCI Foundation Models Various Paradigms Fig. 1: Overview of BCI foundation models. Models are pretrained on large scale heterogeneous EEG data collected from devices with diverse electrode conﬁgurations across various paradigms. Through self-supervised pre-training, the learned representations may generalize to wide range of downstream tasks. tures, and target applications. Some models focus on generalpurpose representation learning across multiple paradigms, whereas others on speciﬁc clinical or cognitive applications. Pre-training strategies range from masked signal reconstruction and contrastive learning to codebook-based discrete modeling and autoregressive sequence prediction. Architecturally, these models have evolved from Transformer-based encoders to Mamba-based designs that offer improved efﬁciency for long sequences. The scale of pre-training data has also increased substantially, with some recent models leveraging thousands of hours of EEG recordings from dozens of public datasets. Unfortunately, different studies evaluated their proposed models on different datasets using inconsistent protocols, making direct comparison difﬁcult. Moreover, several fundamental questions regarding the capabilities and limitations of these models have not been rigorously examined. These considerations motivate the following three research questions in this paper: Q1. Can EEG foundation models extract generalizable EEG representations, so that they can be easily adapted to various different downstream tasks? Q2. Do EEG foundation models consistently and signiﬁcantly outperform traditional and deep learning methods trained from scratch using only the ﬁne-tuning data? Q3. Does the scaling law principle hold for EEG foundation models? Speciﬁcally, do larger model sizes and greater volumes of pre-training data lead to better generalization performance on downstream BCI tasks? Our main contributions are: comprehensive overview of existing BCI foundation models. We survey 50 BCI foundation models, constituting the most comprehensive collection to date. We provide detailed and structured comparison of their technical designs, encompassing basic information, pretraining data scale, preprocessing pipelines, pre-training strategies, and architectural choices. We propose uniﬁed taxonomic framework for EEG foundation models that organizes existing work into coherent design space."
        },
        {
            "title": "Fair and comprehensive benchmarking for open source",
            "content": "EEG foundation models. We systematically compare full parameter ﬁne-tuning with classiﬁcation head ﬁne-tuning across various models and tasks to assess whether pre-trained encoders provide broadly transferable EEG representations. Beyond the commonly used leave one subject out (LOSO) scenario, we introduce within-subject few-shot adaptation scenario in which the ﬁne-tuning data volume is approximately 1/20 1/100 of that typically used in LOSO protocols. We comprehensively compare traditional machine learning methods, CNN-based models, and Transformer-based models trained from scratch against ﬁne-tuned EEG foundation models to evaluate whether conventional approaches remain competitive. We evaluate EEG foundation models of varying parameter sizes pre-trained on diverse datasets to investigate whether larger model necessarily leads to better generalization performance. The remainder of this paper is organized as follows. Section II reviews 50 different BCI foundation models. Section III presents the benchmark. Section IV discusses the limitations and open problems. Section draws conclusions. II. OVERVIEW OF EXISTING BCI FOUNDATION MODELS This section introduces the conceptual framework of BCI foundation models, provides comprehensive summary of existing approaches, and organizes prevalent pre-training strategies into uniﬁed taxonomic framework, as shown in Fig. 2. A. Advances and Trends of BCI Foundation Models Fig. 3 presents overviews of 50 existing BCI foundation models. As shown in Fig. 3(a), 18.0% of the surveyed studies were published in 2024 and 64.0% in 2025 or 2026, indicating clear surge in research activity. This accelerated progress is accompanied by increasing diversity in model scope, signal modalities, backbone architectures, and training methodologies. Table summarizes the 50 surveyed models in chronological order, reporting the afﬁliation of the ﬁrst author, publication date, targeted modality, pre-training data scale, computational cost, and parameter size (bold represents open source). Model scope has begun to bifurcate. As shown in Fig. 3(b), while most studies aim to develop generalized EEG foundation models, nontrivial subset focuses on paradigm-speciﬁc foundation models. In practical BCI deployment, the target paradigm is often known prior to downstream data collection. Motivated by this observation, paradigm-speciﬁc models are pre-trained exclusively on data from single paradigm to Normalization / Alignment (z-score / CAR / EA / EMA)"
        },
        {
            "title": "Data Preprocessing",
            "content": "Channel Selection / Unify (a)"
        },
        {
            "title": "Original EEG Signals Reconstruction",
            "content": "(d)"
        },
        {
            "title": "Codebook Reconstruction",
            "content": "MASK MASK Encoder Decoder MASK (b) e e N a l"
        },
        {
            "title": "Embedded Tokens Reconstruction",
            "content": "M M Encoder Decoder (c) Frequency Domain Reconstruction (Amplitude / Phase / Spectrogram) Encoder Decoder MASK MASK Encoder Decoder e e u M M M"
        },
        {
            "title": "Codebook",
            "content": "(cid:1874)(cid:2870) (cid:1874)(cid:2871) (cid:1874)(cid:2869) Look up (cid:1874)(cid:2872) (cid:1874)(cid:2921)"
        },
        {
            "title": "Codebook \nIndex",
            "content": "(e) Causal Reconstruction (Original Signals / Embedded Tokens) 1 2 3 5 6 7 Causal Transformer Blocks / Large Language Models 2 3 4 5 6 Fig. 2: EEG foundation model pre-training pipeline. Raw EEG trials are ﬁrst standardized through channel selection or uniﬁcation, followed by dataset dependent preprocessing and normalization/alignment. The standardized signal is then used for self-supervised pre-training with representative objectives: (a) Masked reconstruction of raw EEG signals in the time domain; (b) Masked reconstruction of embedded tokens after tokenization; (c) Frequency domain reconstruction, where the target can be the spectrogram, spectral amplitude, or phase related representation; (d) Codebook based reconstruction, where tokenizer maps the signal to discrete codebook indices or codebook embeddings and the model learns to predict the corresponding discrete units; and, (e) Autoregressive or causal reconstruction using causal masking, implemented with causal Transformer blocks or large language models. *HQHUDOL]HG &OLQLF (3$' ((* ((*L((* (PRWLRQ'HFRGLQJ 0RWRU,PDJHU L((* 2WKHUV 7UDQVIRUPHU 66 2WKHUV (a) Year of Publication (b) Model Scope (c) Signal Modality (d) Backbone Architecture 5DZ6LJQDOV 2WKHU5HFRQVWUXFWLRQ !0 00 +] +] 5DQGRP 5DQGRP &DVXDO ZR5HFRQVWUXFWLRQ )UHTXHQF 00 +] 2WKHUV &DVXDO 2WKHUV 7RNHQV )UHTXHQF 5DZ6LJQDOV 5DZ6LJQDOV 7RNHQV (e) Model Size (f) EEG Resampling Rate (g) Masking Strategy (h) Pre-training Objective Fig. 3: Overview of 50 existing EEG foundation models."
        },
        {
            "title": "Author",
            "content": "Afﬁliation"
        },
        {
            "title": "Journal",
            "content": "BENDR [1]"
        },
        {
            "title": "UofT",
            "content": "2021, Front. Hum. Neuro. BrainBERT [2] MBrain [3] BIOT [4] Brant [5] LaBraM [6] Mentality [7] Neuro-GPT [8] MEET [10] EEGFormer [9] BrainWave [11] NeuroLM [12] Brant-X [13] FoME [14] EEGPT [15] BrainGPT [17] GEFM [18] CBraMod [16] CEReBrO [19] LEAD [20] FEMBA [21] LCM [22] TFM [23]"
        },
        {
            "title": "UMASS",
            "content": "2023, ICLR 2023, KDD 2023, NeurIPS 2023, NeurIPS 2024, ICLR 2024, ICLR Workshop 2024, ISBI Feb 2024, 2025, ICLR 2024, KDD Sep 2024, 2024, NeurIPS Oct 2024, 2025, EMBC 2025, ICLR Jan 2025, Feb 2025, Feb 2025, Feb 2025,"
        },
        {
            "title": "UIUC",
            "content": "2025, NeurIPS Workshop ALFEE [24] TJU (Tongji) May 2025, BrainOmni [25]"
        },
        {
            "title": "AI Lab",
            "content": "2025, NeurIPS EEG + MEG E3GT [26] CodeBrain [27]"
        },
        {
            "title": "NUS",
            "content": "UniMind [28]"
        },
        {
            "title": "AI Lab",
            "content": "Jun 2025, Jun 2025, Jun 2025, CSBrain [29]"
        },
        {
            "title": "SHA AI Lab",
            "content": "2025, NeurIPS TABLE I: Comparative overview of EEG foundation models. Pre-training"
        },
        {
            "title": "Cost",
            "content": "4 3090 8 A6000 EEG + ECG 58,021h Dec 2023, TBME EEG (Emotion) 2024, AAAI SSS"
        },
        {
            "title": "EEG",
            "content": ""
        },
        {
            "title": "Parameters",
            "content": "4.0M 43.2M 3.2M"
        },
        {
            "title": "Data Size",
            "content": "1.5TB 43.7h 470h 2528h 2500h 5,656h 1.7TB 40,907h 25,000h 4TB 4 A100, 67.2h 68M / 104M / 249M / 506M 8 A800 5.8M / 46M / 369M 1 3090 0.16M 30M / 61M / 215M 1.9M / 2.3M / 3.2M / 5.8M 4 A100, 100h 115M / 204M / 459M / 1065M 8 A100 2 A100 26,000h 6 4090, 350h 8 3090 254M / 500M / 1696M >1B 476M / 745M 4.7M / 25M 37,500K trials 8 A800, 20h 1.5M / 11.3M / 184M / 1.1B 27,062h 4 A5000, 120h 4.0M >20,000h 4 2080 Ti 3.58M / 39.95M / 85.15M 730.48h 21,000h 1,900h 25,000h 2,653h 26,496h 9,246h 4 A5000 7.9M / 47.7M / 77.8M / 389M 33.9M 1.9M 8 A100 16M / 44M / 120M / 300M / 540M 16 A100, 18h A100 8.4M / 33M 96.4M 3.9M - 146.8M 929K trials 8 A800, 21.78h 0.5B / 1.8B / 7B 9,000h 4 A100, 101h 8 4090 16,724h 1 A5000, 120h 4.9M 3.3M 5.2M 97.1M 12.8M 5M / 19M / 151M 6.3M 3.3M 7.69M 57M / 427M / 912M / 1.9B 26.42M 0.3M - 2.6M 3.1M / 6.0M 5.9M 357,000h 2,180h 28,000h 1,153h >1,000h 8,782h 4 A100 5 A800 32 A100 4 H100 4 8 A6000 4 V100 61,415h 1 A100, 260h 12M / 69M / 408M 21,928h 2,123h 1,267h >1,000h >17,200h 1 8 A100 8 L40S 2 A6000 Ada 1 A5000, 7h 1.0M 7.0M / 43M / 311.4M 124M / 354M / 1555M 1.0M"
        },
        {
            "title": "EEG",
            "content": "iEEG iEEG iEEG"
        },
        {
            "title": "EEG",
            "content": "EEG + iEEG"
        },
        {
            "title": "EEG",
            "content": "EEG + EXG EEG + iEEG"
        },
        {
            "title": "EEG",
            "content": "EEG (AD)"
        },
        {
            "title": "EEG",
            "content": "EEG + EMG"
        },
        {
            "title": "EEG",
            "content": "EEG (Emotion)"
        },
        {
            "title": "EEG",
            "content": "EEG (MI) 50,355 trials 1 3090, 3h Jul 2025, RBME EEG + EXG (Sleep) 482,270 trials Aug 2025, Aug 2025,"
        },
        {
            "title": "EEG",
            "content": ">1,000K trials 8 4090 4 A100 Aug 2025, NN EEG (Epilepsy) 6 4090, 58h DMAE-EEG [30] EEGMamba [31] MIRepNet [32] PSGFM [33] EEGDM [34] CoMET [35] EpilepsyFM [36] SingLEM [37] BrainPro [38] Uni-NTFM [39] ELASTIQ [40] BioCodec [41] HEAR [42] NeuroRVQ [43]"
        },
        {
            "title": "ICL",
            "content": "Jul 2025, TNNLS Jul 2025, NN Jul 2025, Sep 2025, Sep 2025, Sep 2025, Sep 2025, Oct 2025, Oct 2025, Oct 2025, REVE [44] LAB-STICC 2025, NeurIPS mdJPT [45]"
        },
        {
            "title": "SUSTech",
            "content": "LUNA [46] THD-BAR [47] EEG-X [48] SAMBA [49] DeeperBrain [50]"
        },
        {
            "title": "ZJU",
            "content": "Oct 2025, Oct 2025, 2025, NeurIPS Nov 2025, Nov 2025, Jan, 2026, prioritize domain-aligned representation learning, potentially at the expense of cross-paradigm generalizability. The distribution of signal modalities further reﬂects this diversity. Fig. 3(c) shows that non-invasive scalp EEG remains the dominant modality, largely because it does not require surgical implantation and is substantially easier to collect at scale than invasive recordings. However, scalp EEG signals are attenuated and spatially blurred due to volume conduction through the scalp and skull, which limits both signal strength and spatial resolution [72]. To improve robustness and enrich the supervisory signal, several studies incorporate auxiliary physiological modalities such as electrocardiogram (ECG) [4], electromyogram (EMG) [13], or magnetoencephalography (MEG) [25], suggesting that representation learning can beneﬁt from correlated biosignals. From an architectural perspective, Fig. 3(d) indicates that Transformer-based backbones dominate current EEG foundation models. Model capacity and training resources, however, exhibit substantial variability rather than monotonic scaling trend. Fig. 3(e) reveals wide distribution of parameter scales, and Table conﬁrms that model sizes range from fewer than one million parameters to several billion parameters. In summary, BCI foundation models have entered phase of rapid exploration characterized by diverse model scopes, modalities, architectures, and pre-training strategies. However, existing models employed heterogeneous pre-training objectives and were evaluated under diverse downstream scenarios and ﬁne-tuning protocols, which complicates the derivation of consistent conclusions on the factors that truly drive generalization. This observation motivates the uniﬁed framework illustrated in Fig. 2, which standardizes the major design axes of EEG foundation models. The need for systematic comparison further calls for comprehensive benchmark, which is presented in Section III. B. Deﬁnition of BCI Foundation Models EEG foundation models aim to learn transferable and generalizable neural representations from large scale EEG data. In contrast to conventional BCI pipelines that are optimized for single task and dataset, often through hand crafted features and supervised training from scratch, BCI foundation models are typically pre-trained on heterogeneous EEG data collected under different devices and paradigms. After pretraining, they can be adapted to downstream BCI tasks using ﬁne-tuning or prompting, with the expectation of improved generalization and reduced dependence on task speciﬁc labels. Due to their versatility, foundation models have become prominent research direction in the BCI community. commonly used deﬁnition of an AI foundation model is [73]: Deﬁnition 2.1 (Foundation Model): foundation model is any model that is trained on broad data and can be adapted to wide range of downstream tasks. While this deﬁnition captures the essence of general purpose foundation models, the design of EEG foundation models exhibits several domain-speciﬁc characteristics: (1) BCI-FMs are pre-trained on large scale EEG data, including both scalp EEG and intracranial EEG (iEEG). Additionally, other physiological signals such as electrocardiogram (ECG) and electromyogram (EMG) may serve as auxiliary data during pre-training. (2) General-purpose foundation models are expected to handle highly heterogeneous downstream tasks, such as semantic segmentation, object detection, long form question answering, and video generation [74]. In contrast, current EEG foundation models primarily target classiﬁcation tasks across various electrode conﬁgurations and BCI paradigms. (3) EEG data acquisition is resource-intensive, requiring participant recruitment, paradigm design, and stringent environmental control. As result, EEG corpora are typically smaller than text or image corpora, and current EEG foundation models are often trained with considerably fewer parameters and lower computational budgets. Based on these domain speciﬁc considerations, we propose the following deﬁnition for BCI foundation models: Deﬁnition 2.2 (BCI Foundation Model): BCI foundation model is pre-trained on large scale electrophysiological data, and can be adapted through ﬁne-tuning or prompting to heterogeneous EEG devices and downstream BCI tasks (categories). C. Problem Deﬁnition } } (m) {D (m) = Assume the pre-training corpus be (m) m=1, Dpre = Nm i=1, is the number of datasets and where { Nm is the number of trials in dataset m. Each raw trial is multi-channel time series (m) RCmTm, where Cm is the channel count and Tm is the number of sampled time points. τj} j=1, where each task { τj speciﬁes paradigm, device conﬁguration, and label Cj. For each task τj, we deﬁne labeled dataset: space of size Nj , y(j) (j) k=1, task = ) } RCj Tj , y(j)"
        },
        {
            "title": "Let the downstream task be",
            "content": "(τj ) = (X (j) 1, 2, . . . , (1) = D . { Cj} { (j)"
        },
        {
            "title": "We further denote the corpus of all downstream task datasets\nas",
            "content": "Ddown = (j) task} j=1. {D BCI foundation model is expected to be pre-trained on . Let fΘ Dpre and then adapted to each downstream task in denote pre-trained model with parameters Θ, which maps an Cj classes for task input trial to predictive distribution over τj. The pre-training stage estimates (2) Θ = arg min Θ Nm Xm=1 Xi="
        },
        {
            "title": "Lpre",
            "content": "(cid:16) (m) ; Θ , (cid:17) (3) where deﬁned on the pre-training corpus Lpre denotes self-supervised pre-training objective For each downstream task τj, we split its labeled dataset Dpre. into ﬁne-tuning set and test set: (j) task = with (j) ft (j) te , (j) ft (j) te = , (4) (j) ft = (X (j) , y(j) ) } { nj k=1, (j) te = (X (j) , y(j) ) } { Nj k=nj +1. 6 = 6 8 3 ( 8 7 / 8 7 % $ 8 9 ( 8 7 5 $ 8 7 , 0 H ' ( ( 6 9 , ' ( Q L % $ 8 7 9 ( 8 7 $ 9 , , 0 ' ( & $ ) H ' ( ( 6 7 , 0 % ) ' ( + & H O 6 ( ( 6 & , & % L K 9 ' & 0 + % $ 8 7 9 ( 8 3 ( 8 7 = 8 7 / 6 , 8 7 H $ 8 7 ' ( ( 6 $ 9 , 9 ' ( ( 6 L K 3 & , & % L K 3 ( 6 (a) Pre-training Dataset Usage (b) Downstream Dataset Usage (c) Combined Usage Fig. 4: Dataset usage statistics across existing EEG foundation models. (a) Frequency ranking of datasets used during pretraining; (b) Frequency ranking of downstream datasets used for generalization evaluation; and, (c) Frequency ranking of datasets used in pre-training or downstream evaluation. (j) te after ﬁne-tuning on We expect BCI pre-trained model could achieve strong (j) ft . generalization performance on 1) Data Collection and Curation: Constructing EEG foundation models begins with data collection, where the primary sources include public datasets and self-collected recordings. Fig. 4 presents the frequency of dataset usage in pre-training and downstream evaluation across existing EEG foundation models. Most existing approaches aim to develop generalpurpose models that accommodate various paradigms, and therefore aggregate large volumes of unlabeled data spanning diverse tasks for pre-training. inHowever, directly collected EEG data often exhibit consistent quality, including recordings from poor-performing subjects, corrupted channels, and various artifacts. Curating large-scale, high-quality dataset is therefore critical for effective foundation model training [76]. Common curation strategies include subject-level screening to exclude participants with abnormally low task performance or excessive noise, and channel-level screening to remove channels exhibiting persistent artifacts or disconnections. Filtering out such noisy data facilitates more stable optimization and improves the quality of learned representations. 2) Data Preprocessing: EEG signals exhibit substantial variability across subjects and devices. Variations in electrode placement, impedance, environmental noise, and physiological state can induce considerable distribution shifts, which may impair large scale pre-training and downstream transfer. Therefore, BCI foundation model pipelines incorporate preprocessing and normalization to reduce nuisance variability and stabilize optimization, the speciﬁc information is shown in Table II. To maintain notational consistency throughout this section, we denote raw trial by for the model input after preprocessing. Speciﬁcally, we deﬁne preprocessing operator RCT and use the symbol = (X), (5) represents speciﬁc alignment or normalization where strategy. Channel Uniﬁcation. EEG signals exhibit substantial spatial heterogeneity, as different devices adopt varying electrode layouts and channel counts. This heterogeneity makes it difﬁcult to directly reuse conventional task-speciﬁc models across datasets. In contrast, many Transformer-based backbones can process variable-length token sequences, which has enabled broader set of strategies to accommodate heterogeneous channel conﬁgurations. Among the surveyed EEG foundation models, the prevailing solutions can be categorized as follows. (1) Common montage pre-training. straightforward strategy is to restrict pre-training to datasets that share common set of channels, typically using ﬁxed montage with standardized channel count, and subsequently transfer to downstream tasks within the same montage family. (2) Template-based channel mapping. Another line of work deﬁnes channel-level or region-level template. Channels present in the recording that match the template are retained directly, while missing channels are mapped into the template space through interpolation or related mapping functions. (3) Spatial encoding for channel structure. Since simple channel selection does not explicitly model spatial relationships, several models augment the input with channel position encodings. Both ﬁxed spatial encodings derived from electrode coordinates and learnable channel embeddings have been employed to inject spatial inductive bias. (4) Channel projection to uniﬁed space. Some pipelines predeﬁne target channel space and incorporate an input projection module, often implemented as convolutional layers, to map the raw channels into this uniﬁed space before the Transformer backbone. This strategy explicitly learns dataset-agnostic channel transformation and can be combined with tokenization. Representative models adopting this approach include EEGFormer and Uni-NTFM. Resampling and bandpass ﬁltering. Resampling and ﬁltering are widely adopted to standardize temporal resolution and suppress nuisance components in EEG signals. Fig. 3(f) summarizes the resampling choices across the surveyed studies. Speciﬁcally, 50.0% of the studies resample signals to 200 Hz, while 34.1% resample to 250 Hz or 256 Hz. Bandpass ﬁltering is commonly applied to attenuate slow drifts and high-frequency noise, and notch ﬁlters at 50 Hz or 60 Hz"
        },
        {
            "title": "Model",
            "content": "Resampling (Hz)"
        },
        {
            "title": "Stride Overlap",
            "content": "TABLE II: Preprocessing of EEG foundation models."
        },
        {
            "title": "BENDR\nBrainBERT\nMBrain\nBIOT",
            "content": "Brant LaBraM Mentality Neuro-GPT MEET EEGFormer BrainWave NeuroLM Brant-X FoME EEGPT BrainGPT GEFM CBraMod CEReBrO LEAD FEMBA LCM TFM ALFEE BrainOmni E3GT CodeBrain UniMind CSBrain DMAE-EEG EEGMamba MIRepNet PSGFM EEGDM CoMET EpilepsyFM SingLEM BrainPro Uni-NTFM ELASTIQ BioCodec HEAR NeuroRVQ REVE mdJPT LUNA THD-BAR EEG-X SAMBA DeeperBrain 256 200 / 500 (EEG / ECG) 250 200 200 250 200 250 >1000 1000 200 250 256 256 256 200 128 / 64 / 32 250 256 200 256 256 125 200 200 200 200 250 100 200 200 200 128 200 200 200 250 / 1000 (EEG / EMG) 200 200 200 125 256 200 128 200 120 Hz (P300) 0.1 Hz + 60 Hz notch 0.1-75 Hz + 50 Hz notch 60&120 Hz notch 0.5-100 Hz + 60 Hz notch 1-50 Hz 0.01fs 3 Hz + 50/60 Hz notch 0.1-75 Hz + 50 Hz notch 45 Hz (EM) 0.5-100.5 Hz + 50 / 60 Hz notch 38 Hz / 30 Hz / 120 Hz 0.1-100 Hz 0.3-75 Hz + 60 Hz notch 0.5-45 Hz 0-38 Hz (MI) 0.1-75 Hz + 50 Hz notch (TUH) 50 / 60 Hz notch 0.1-96 Hz + 50 / 60 Hz notch 0.1-50 Hz 0.3-75 Hz + 60 Hz notch 0.1-75 Hz + 50 / 60 Hz notch 0.3-75 Hz + 60 Hz notch 0.3-75 Hz + 50 / 60 Hz notch 8-30 Hz 0.1-75 Hz + 50 Hz notch 0.5-70 Hz 0.5-70 Hz + 50 Hz notch 0.5-50 Hz + 50 Hz notch 0.5-50 Hz + 50 Hz notch 0.3-40 Hz (MI) / 0.3-70 Hz 0.5-100 Hz 1-75 Hz 0.5-99.5 Hz 0.5-47 Hz 0.1-75 Hz + 50 / 60 Hz notch 0.1-75 Hz + 50 / 60 Hz notch 0.3-75 Hz + 50 / 60 Hz notch Norm [-1,1] STFT + z-score Norm (0, 1) Norm P95(x) Norm [-1,1] z-score Instance Norm Norm [-1,1] z-score (only EM) EMA EA / CAR / z-score z-score Norm [-1,1] z-score Quantile Norm CAR z-score z-score CAR Norm 100 z-score Norm [-1,1] Norm [-1,1] Zero-mean + EA IQR Scaling Norm [-1,1] Norm [-1,1] z-score Norm (-1,1) Norm [-1,1] z-score CAR z-score ICA + CAR z-score IQR Scaling Norm [-1,1] 19 19 / (EEG / iEEG) 16 / 12 (EEG / ECG) 375 ms 200 ms 1 1 375 ms 25 ms 1 0.5 19 22 3232 Map 19 19 64 19 22 16 90 16 8 19 19 10 Regions 45 1 62 8 Regions 1 60 5 Regions 65 1 60 6 1 1 10 10 1.8 2 1 1 1s 1s 6 6 250 ms 250 ms 125 ms 1 1 1 = 64 = 64 = 128 = 64 128 ms 1s 1s 2 4 1s NA 1s NA 30s NA 250ms 1s 1s 0.1s NA 0.5s NA 1s 1 5s = 40 1s 1s 1 0.5s 1s 1 1 1s NA 1s NA 30s NA 250ms 1s 0.75s 0.1s NA 0.5s NA 0.1 2s = 40 1s 0.75s 1 % ! % ! % % ! % % % % % % ! % % ! ! % ! ! % % NA % % NA % NA % % ! % NA % NA % ! ! % % ! % are frequently employed to reduce power-line interference. Model-speciﬁc resampling and ﬁltering conﬁgurations are summarized in Table II. Normalization and Marginal Alignment. Below we describe several widely adopted normalization or data alignment approaches used in preprocessing. (1) z-score Normalization. z-score normalization rescales each channel to zero-mean and unit variance, ensuring comparable magnitude across channels. This technique is widely employed in the preprocessing stage of BCI foundation models. For trial X, the channel-wise statistics are deﬁned as After this transformation, the mean covariance of the aligned trials becomes the identity matrix, thereby reducing discrepancies in second-order statistics across subjects. Representative foundation models adopting EA include EEGPT [15] and MIRepNet [32]. (4) Exponential Moving Average (EMA) Normalization. To handle gradual drift in long recordings, some approaches adopt exponential moving average normalization, in which normalization statistics are updated sequentially. RC denote the multichannel sample at time t. Let xt EMA maintains exponentially decaying estimates of the ﬁrst and second moments as follows: µc ="
        },
        {
            "title": "1\nT",
            "content": "T Xt=1 Xc,t,"
        },
        {
            "title": "1\nT",
            "content": "T Xt=1 σc = t (Xc,t µc)2 + ǫ, (6) (7) and the normalized signal is given by Gz(X)c,t = Xc,t σc µc , where ǫ > 0 is small constant for numerical stability. Depending on the protocol, the statistics can be computed per trial, per session, or over the entire training set. Representative foundation models that adopt z-score normalization include BrainBERT [2], Neuro-GPT [8], Brant-X [13], EEGPT [15], BrainGPT [17], LEAD [20], ALFEE [24], BrainOmni [25], UniMind [28], EpilepsyFM [36], BioCodec [41], REVE [44], and LUNA [46]. (2) Common Average Reference (CAR). Another standard preprocessing technique is CAR, which suppresses common mode activity shared across all channels. Let 1C RC denote an all-ones vector. CAR transforms as follows: (8) Gcar(X) = X"
        },
        {
            "title": "1\nC",
            "content": "1C1 X. The underlying assumption of CAR is that signals recorded at all electrodes contain common noise component, such as reference electrode drift or environmental interference. By subtracting the instantaneous average across all electrodes from each individual electrode, CAR effectively attenuates this common mode component while preserving spatially localized neural activity. Representative foundation models employing CAR include EEGPT [15], E3GT [26], HEAR [42], and mdJPT [45]. (3) Euclidean Alignment (EA). EA [75], [83] performs subject-wise or session-wise whitening to reduce covariance shifts and improve cross-subject consistency. Assume subject contains trials i=1, where each RCT . EA ﬁrst computes the mean covariance Xi matrix as Xi} { = 1 Xi=1 XiX , and then applies the whitening transformation Gea(Xi) = R1/2Xi. (9) (10) mt = αmt1 + (1 st = αst1 + (1 α)xt, α)xt (11) (12) xt, where α (0, 1) is the decay factor and denotes the element-wise product. The variance estimate is given mt, and the normalized sample is by vt = st computed as mt Gema(x)t = mt xt vt + ǫ . (13) EMA normalization is particularly suitable for online or streaming settings, as it does not require precomputed global statistics and can adapt to non-stationarities in the signal. representative foundation model employing EMA normalization is FoME [14]. (5) Summary. z-score normalization, CAR, and EMA normalization are widely adopted as generic preprocessing components, whereas EA provides an explicit mechanism to reduce session-level covariance shifts. In praccan be instantiated as composition of these tice, operations. For notational simplicity, we use the uniﬁed (X) to denote the preprocessed model notation input throughout the remainder of this section. = 3) Model Pre-training: Most EEG foundation models are pre-trained with self-supervised objectives that remove or corrupt part of the input and require the model to recover the masked information. Table III summarizes the pre-training strategies of 50 foundation models, and Fig. 3 highlights eight empirical trends across these models. Several insights can be drawn from this analysis. First, Transformer-based backbone is adopted by approximately 82.0% of the models. Second, masked reconstruction constitutes the dominant pre-training paradigm. Among masking strategies, random masking is the most prevalent choice, accounting for approximately 70.8%, while causal masking and mixed masking together occupy smaller portion. Third, regarding reconstruction targets, raw signal reconstruction is the most frequent strategy, accounting for approximately 24.0%, while token reconstruction and hybrid approaches that combine raw and token reconstruction together constitute comparable fraction. Codebook-based objectives and frequency-domain objectives appear less frequently as standalone targets, but they are often employed as auxiliary supervision in multi-target designs. Based on these observations, we organize the mainstream pre-training strategies into ﬁve categories: masked reconstruction of raw signals, masked reconstruction of embedded tokens, frequency-domain 9 FFN 3076 NA 3072 TABLE III: Pre-training strategy of EEG foundation models. Model Masking strategy Reconstruction objective Loss function Encoder depth Attn-head model BENDR Random Mask Embedded Tokens BrainBERT Random Mask Spectrogram MBrain Random Mask NA BIOT Brant LaBraM Mentality Random Mask Random Mask Random Mask Embedded Tokens Raw Signals EEG Codebook Index Raw Signals Neuro-GPT Causal Mask Embedded Tokens MEET EEGFormer NA BrainWave Random Mask NeuroLM Causal Mask Brant-X FoME EEGPT NA Random Mask Random Mask BrainGPT Causal Mask NA Spectral Amplitude Spectrogram Codebook Index NA Raw Signals Raw Signals Raw Signals GEFM Random Mask Embedded Tokens CBraMod CEReBrO LEAD FEMBA LCM TFM Random Mask Random Mask NA Random Mask Random Mask Random Mask Raw Signals Embedded Tokens NA Raw Signals Embedded Tokens Embedded Tokens ALFEE Random & Causal Mask Raw Signals + PSD BrainOmni Random Mask Codebook Index E3GT Random Mask SpecKMeansLabels CodeBrain Random Mask Codebook Index UniMind CSBrain NA NA Random Mask Raw Signals DMAE-EEG Random Mask Raw Signals + Embedded Tokens EEGMamba Random Mask Raw Signals MIRepNet Random Mask Embedded Tokens PSGFM EEGDM CoMET Random Mask SpecKMeansLabels NA Random Mask Velocity Raw Signals EpilepsyFM Random Mask EEG Codebook Index SingLEM BrainPro Random Mask Random Mask Embedded Tokens Raw Signals Uni-NTFM Random Mask Time + Band Power ELASTIQ Random & Causal Mask Embedded Tokens BioCodec HEAR NA NA Time + Frequency Codebook + Frequency NeuroRVQ Random Mask EEG Codebook Index REVE mdJPT LUNA Random Mask Raw Signals NA NA Random Mask Embedded Tokens THD-BAR Causal Mask Codebook Index EEG-X SAMBA Random Mask Random Mask Noised-Removed Signals Time + Frequency DeeperBrain Random Mask Raw Signals + Neuro Info Let cl Lspec mse NA Let cl Lrs mse Lci cls mse + Lspec Lrs mse Lsa Let mse Lcls mse + Lcbe mse Lci nll + Lf ine cl Lcoarse cl Lrs mse mse + Lemb mse Lrs Lrs mse Let cl Lrs mse Let mse + Laux Lemb + Lcls cl Lemb cl Lrs s-l1 + λLet Lci cls mse Lrs mse + Lrs SD mse Lci cls Lskl cls Lci cls Lcce Lrs mse mse + Let Lrs Lrs mse Let mse mse + Lcls Lskl cls Lv mse cl mse + Lglob Lrs Lci cls hubert + Let hubert + Lumt Lmt mse wmse + Ldec Lrs mse + Lbp Lemb Let hubert + Lstf Lrs mse mse + Laux + Laux Lrs + Lstf 2 1 mse + Lf req Lce mse Lci cls mae + Laux LCDA + LISA Let mse Lci cls Lnrs mse + Lteastu kd + Laux mae + Lf req Los hubert + Lni mse Lrs hubert 8 6 NA 4 17 768 NA 8 16 1536 NA 256 2048 12 / 24 / 48 10 / 16 / 16 200 / 400 / 800 / 1600 / 3200 NA 6 3 / 6 / 12 6 / 8 / 12 NA NA 1080 NA 3 / 12 / 16 768 / 768 / 1024 3072 / 3072 / 4096 16 768 2048 12 / 24 / 48 12 / 16 / 25 768 / 1024 / 3072 / 4096 / 6400 16 3072 / 3 / 9 / 12 / 20 4 / 8 / 14 / 28 128 / 256 / 896 / 1792 512 / 1024 / 3584 / 7168 12 8 / 10 / 12 12 NA 8 8 12 8 NA 8 1536 200 3076 400 192 / 576 / 768 / 2304 / 3072 128 NA 64 NA 12 12 NA 12 12 NA 6 NA 8 / 16 256 / 512 1024 / 2048 12 NA 10 8 NA 8 NA 768 NA 1152 200 NA 256 768 NA 3072 NA 800 NA 1024 NA 6 / 6 / 12 4 / 8 / 16 256 / 512 / 1024 1024 / 2048 / 4096 4 + 12 4 12 / 12 / 16 / 24 12 2 6 / 12 10 4 + 8 32 8 4 / 8 10 200 128 256 / 512 / 512 / 768 256 128 200 64 1024 800 4 / 22 / 22 8 / 8 / 19 512 / 512 / 1250 1365 / 1365 / 3333 8 128 8 / 10 / 24 8 / 12 / 16 256 / 576 / 1024 / 2304 / 4096 12 / 24 / 48 12 / 16 / 25 768 / 1024 / 1600 3072 / 4096 / 6400 NA 12 8 NA 8 NA 200 64 NA 800 + Ldt cls 6 / 8 / 16 / 18 / 22 4 / 4 / 8 / 8 / 12 384 / 512 / 640 / 896 / 1152 256 / 512 / 512 / 768 / 768 reconstruction, codebook-based objectives, and autoregressive pre-training. patches, where RCT , we denote the model Given raw EEG trial (X). Since EEG is = input after preprocessing by typically sampled at high temporal resolution, most EEG foundation models further aggregate time steps into patches to reduce sequence length and capture local temporal structure. Let the patch length be and the stride be S, with overlap along the temporal axis into Np = S. We segment Np = T (cid:22) (cid:23) + 1, and denote the resulting patch tensor by = X) ( RNpCM , denotes the patching operator. The k-th patch of where channel is denoted by pk,c RM . (14) (15) a) Masked Reconstruction of Raw Signals: Raw signal reconstruction is the most prevalent pre-training strategy, employed by representative models such as Brant, FoME, CBraMod, CSBrain, EEGMamba, BrainPro, REVE, and EEGX. For mask-based reconstruction pre-training, masking is applied directly to the patched raw signal: Pmsk = Mx(P ), (16) and the encoder consumes the masked patches. The model learns to reconstruct the original patches using the canonical mean squared error loss: . (17) = be Dφ Eθ(Pmsk) (cid:1) (cid:0) , rs mse = (cid:13) (cid:13) be 2 2 (cid:13) (cid:13) This approach is intuitive because it directly constrains the encoder to preserve waveform structure and cross-channel dependencies, which are critical for event-related components and oscillatory bursts. However, non-invasive EEG typically exhibits low signal-to-noise ratio and contains substantial nuisance variability arising from artifacts, impedance ﬂuctuations, and background activity. When the pre-training target is the waveform itself, model with sufﬁcient capacity may devote representation power to reconstructing idiosyncratic noise patterns that are not predictive for downstream tasks and the risk is ampliﬁed when the masking ratio is inappropriate. rs w-mse rs s-l1, BrainPro uses weighted variant"
        },
        {
            "title": "Several works have therefore attempted to modify",
            "content": "rs mse to improve robustness. For example, FEMBA employs the smooth ℓ1 loss Ldec, and REVE incortogether with decomposition loss Laux. EEG-X further emphasizes porates an auxiliary loss nrs denoising by reconstructing noise-removed signals via mse and incorporates teacher-student distillation , which aligns with the practical need to suppress artifacts rather than reproduce them. Overall, raw signal reconstruction serves as strong baseline when data quality is controlled and masking is sufﬁciently challenging, but it beneﬁts from explicit regularization that discourages memorization of noise. tea-stu kd b) Masked Reconstruction of Embedded Tokens: Token reconstruction is conceptually similar to raw signal reconstruction, but operates in learned embedding space. In this approach, EEG signals are ﬁrst passed through neural tokenizer or patch embedding module, typically implemented as CNN, to obtain embedded tokens, and the model is trained to reconstruct these representations. This strategy is adopted by models such as BENDR, BIOT, GEFM, CEReBrO, LUNA, ELASTIQ, and MIRepNet. or alternatively employs contrastive learning objective in et the embedding space, denoted by cl and related terms in Table III. Compared to raw signal reconstruction, token-level objectives aim to reduce sensitivity to amplitude scaling and local waveform noise, as the tokenizer compresses the input into representation that can be designed to emphasize spatiotemporal structure. This design often improves optimization stability for large encoders and naturally supports patch-based processing, which is consistent with the high prevalence of patching observed in Fig. 3. However, the learned representation inherits the inductive bias of the tokenizer. If tokenization is too coarse, ﬁne-grained transient features may be lost. Conversely, if tokenization is too shallow, the objective may degenerate into reconstruction of near-identity embeddings. Several models address this tension by combining token-level objectives with auxiliary terms. Laux to enrich the learning signal. CEReBrO incorporates emb cl with weighted LCM combines contrastive learning et et reconstruction term λ mse with mse. MIRepNet integrates classiﬁcation loss Lcls to bias the representation toward discriminative structure relevant to its target paradigm. These examples suggest that token reconstruction often beneﬁts from complementary objectives that encourage global semantic learning rather than pure local reconstruction. c) Frequency-Domain Reconstruction: This family of methods deﬁnes the reconstruction target in the spectral domain to emphasize oscillatory structure. Following the uniﬁed (X) denote the preprocessed trial and notation, let RNpCM denote the patched signal. We = X) ( that maps to introduce spectral transform operator frequency-domain representation: = G = (P ). (21) , may represent spectroDepending on the choice of gram, spectral amplitude, band power, or an amplitude-phase from masked decomposition. pre-trained model predicts inputs and minimizes spectral reconstruction loss. Spectrogram reconstruction. Let frequency transform, and deﬁne Fspec denote time-"
        },
        {
            "title": "A decoder predicts",
            "content": "Sspec = Fspec(P ). Sspec and optimizes (22) This objective is adopted by BrainBERT and BrainWave. spec mse = Sspec (cid:13) (cid:13)"
        },
        {
            "title": "Sspec",
            "content": "For token-based pre-training, each patch is mapped into an Spectral amplitude reconstruction. Let embedding through tokenizer: amplitude, yielding = Tψ(P ), RNpd, (18) where denotes the embedding dimension. Masking is then applied in the token space: Zmsk = Mz(Z). (19) The model learns to predict the original token embeddings: = Dφ Eθ(Zmsk) (cid:1) (cid:0) , et mse = Z (cid:13) (cid:13) , 2 2 (cid:13) (cid:13) (20) Samp = Famp(P )."
        },
        {
            "title": "The corresponding objective is",
            "content": "amp mse = Samp (cid:13) (cid:13) b"
        },
        {
            "title": "Samp",
            "content": "2 2 (cid:13) (cid:13) which is employed by EEGFormer. Some approaches additionally align predictions with codebook-related embeddings through cb mse = L"
        },
        {
            "title": "Ecb",
            "content": "Ecb (cid:13) (cid:13) 2 2 (cid:13) (cid:13) , (26) . (23) 2 2 (cid:13) (cid:13) Famp extract spectral (24) (25) , where Ecb denotes the selected codebook embeddings and Ecb denotes the corresponding predictions. Band power reconstruction. Let features, yielding Fbp compute band power (27) Sbp = Fbp(P )."
        },
        {
            "title": "The reconstruction objective is",
            "content": "bp mse = Sbp (cid:13) (cid:13) b"
        },
        {
            "title": "Sbp",
            "content": "2 2 (cid:13) (cid:13) , (28) which is employed by Uni-NTFM as frequency-domain supervision signal. Amplitude-phase reconstruction. HEAR supervises compact Fourier representation of each temporal patch. Let deFfour its frequency-domain transform: note an EEG patch and (29) Sfour = Sfour = ). Ffour(P ), Ffour( For models that jointly supervise amplitude and phase, we decompose Sfour = , where A(i,j) and ψ(i,j) A(i,j), ψ(i,j)} denote the ground-truth amplitude and phase of patch (i, j), Sfour = respectively. Similarly, represents the reconstructed counterparts. The frequency loss employed by HEAR is formulated as ψ(i,j)} A(i,j), { { CiTi/w Xi=1 A(i,j) four mse = Xj=1 (cid:16)(cid:13) 2 2 + (cid:13) (cid:13) A(i,j) (cid:13) 2 2 (cid:17) (cid:13) (cid:13) (30) where Ci denotes the number of channels, Ti denotes the number of time points, and denotes the patch length. Both terms employ squared ℓ2 norms, penalizing amplitude and phase discrepancies equally. ψ(i,j) (cid:13) (cid:13) ψ(i,j) , Multi-scale spectral reconstruction. BioCodec employs richer spectral loss based on short-time Fourier transforms (STFT) computed at multiple scales. The composite spectral feature at scale is deﬁned as: log Φi(x) = Si(x) Si(x) , cos (cid:1) (cid:0) Si(x) , sin (cid:0) , (cid:1)i ) denotes the STFT with window length 2i, and where Si( and represent the original and reconstructed waveforms, respectively. The log-magnitude and phase components are weighted as [1.0, 0.2, 0.2], respectively. The two frequency losses reported in Table III are: (31) stft ℓ1 = stft ℓ2 = nh Φi(x) Xi=nl(cid:13) (cid:13) nh Φi(x) Xi=nl(cid:13) (cid:13) Φi( x) (cid:13) (cid:13) Φi( x) , 1 2 2 , (32) (33) (cid:13) (cid:13) where nl and nh deﬁne the lower and upper bounds of the scale set. The ℓ1 loss encourages sparsity, while the ℓ2 loss penalizes large spectral deviations. The motivation for frequency-domain reconstruction is neurophysiological. Many BCI paradigms are characterized by rhythmic modulations in speciﬁc frequency bands, and spectral supervision emphasizes oscillatory regularities that are comparatively robust to amplitude scaling and certain artifacts. This property can mitigate the tendency of raw waveform regression to memorize recording-speciﬁc noise, which is 11 practical concern for non-invasive EEG with low signal-tonoise ratio. The limitation is that the chosen transform may underrepresent transient dynamics or phase information, depending on the speciﬁc representation employed. Consequently, frequency-domain reconstruction is often adopted as the primary objective when rhythmic structure dominates the signal of interest, or combined with time-domain target within the same model. For example, Mentality and SAMBA jointly optimize raw signal and frequency-domain supervision to capture complementary temporal and spectral characteristics. d) Codebook-Based Objectives.: Codebook-based pretraining introduces discrete units that can be predicted as indices or reconstructed as codebook embeddings. Models such as LaBraM, BrainOmni, CodeBrain, EpilepsyFM, NeuroRVQ, NeuroLM, and THD-BAR adopt codebook index supervision, as reﬂected in Table I. Let quantizer map embeddings to discrete indices: = (Z), { 1, 2, . . . , L, } (34) where denotes the codebook size and denotes the sequence length. common formulation predicts an index [0, 1]LK and optimizes cross-entropy loss: distribution ci cls = L"
        },
        {
            "title": "Lce",
            "content": "(cid:16) Xℓ=1 Iℓ, Pℓ . (cid:17) (35) index modeling employs negative logAutoregressive ci likelihood objectives such as nll, which is adopted by NeuL roLM and THD-BAR. An alternative branch aligns predicted embeddings with codebook embeddings, represented by or related terms, as employed by HEAR. ce mse The primary advantage of codebook-based objectives is that discretization can suppress low-amplitude noise and provides compact symbolic sequence that is compatible with largescale sequence modeling. This design also facilitates causal generation and prompt-based adaptation when combined with decoder-only architectures. However, codebook learning introduces additional design considerations, including codebook size, commitment regularization, and update schedules. If not carefully controlled, the codebook can collapse or exhibit highly imbalanced usage, which undermines representation quality. Several surveyed models mitigate these issues through carefully designed quantizers or by decoupling codebook learning from masked modeling, though this generally increases training complexity and implementation overhead. e) Autoregressive Pre-training: Autoregressive pretraining enforces causal factorization and is instantiated by models such as Neuro-GPT, BrainGPT, NeuroLM, and THDBAR. Notably, NeuroLM and THD-BAR additionally pre-train codebook to facilitate reconstruction. For token sequences, the objective can be formulated as log pΘ arg max Θ Xe XDpre Xℓ=1 Zℓ (cid:0) Z1:ℓ1 , (cid:1) (36) while for codebook indices it naturally corresponds to likelihood-based objectives such as = X), Tψ( ci nll. Autoregressive modeling is appealing because it aligns with decoder-only Transformer architectures and supports sequence continuation and prompting. It also provides principled framework for modeling temporal dynamics. However, strictly causal objectives can be more challenging to optimize than bidirectional masked reconstruction, particularly when tokens are high-dimensional or when the temporal discretization is not well matched to EEG dynamics. Furthermore, causal objectives may emphasize short-range predictability, which can bias the representation toward local continuity rather than task-relevant global structure, unless the model architecture and context length are sufﬁciently expressive. rs mse and spec mse ; EEGPT, which combines f) Hybrid Objectives and Practical Selection: Several models adopt hybrid designs that combine two or more complementary targets. Examples include Mentality, which rs combines mse with emb an embedding reconstruction term mse ; DMAE-EEG, which et combines mse; and SAMBA, which combines timedomain and frequency-domain reconstruction. These hybrid formulations should be interpreted as deliberate design choices to constrain the representation from complementary perspectives, rather than an indiscriminate aggregation of all available losses. rs mse and L In practice, the appropriate pre-training objective depends on the intended deployment setting. When cross-dataset heterogeneity and low signal-to-noise ratio are the dominant challenges, token-level and codebook-based objectives often provide stronger invariances than raw waveform regression. When rhythmic structure is central to the target paradigm, frequency-domain supervision can be beneﬁcial, particularly when paired with time-domain constraint. When promptbased adaptation or causal generation is required, autoregressive objectives become natural choice, although they may require careful tokenization and context design to avoid overly local predictions. tok mse and amp mse , codebook index losses such as g) Summary.: Existing EEG foundation models largely adhere to masked prediction paradigm, but differ substantially in their target space and implied inductive biases. Table summarizes these design choices through the reconstruction raw mse and objective and loss function columns, encompassing spec its robust variants, mse ci and nll, as well as additional auxiliary terms that reﬁne the learning signal. This taxonomy provides consistent framework for comparing pre-training strategies under heterogeneous EEG settings and clariﬁes why different approaches may be preferable for speciﬁc BCI paradigms and deployment constraints. Detailed experimental analysis is presented in the following section. , spectral losses such as ci cls and tok cl L L 4) Downstream Generalization: After pre-training on largescale EEG corpora, downstream evaluation is required to assess whether the learned representations transfer effectively to practical BCI tasks. Fig. 4 (b) summarizes the most frequently used downstream datasets. These datasets span multiple representative paradigms. For example, TUAB, TUEV, and CHBMIT are clinical EEG datasets; BCIC-IV-2A and PhysioNetMI are motor imagery datasets; FACED, SEED, and SEED-V are emotion recognition datasets; and Sleep-EDF is sleeprelated dataset. This distribution indicates that downstream 12 evaluation in existing work is largely concentrated on clinical applications, motor imagery, affective decoding, and sleep analysis. downstream task τj is associated with dataset is partitioned into ﬁne-tuning set Following the problem deﬁnition in Section II-C, each (j) task, which (j) ft and held-out test set (j) te . Given pre-trained model fΘ , task-speciﬁc ﬁne-tuning D"
        },
        {
            "title": "D\nestimates",
            "content": "Θ = arg min Θ X(X,y)D(j) ft (j) cls y, fΘ(X) (cid:1) (cid:0) , (37) (j) cls denotes supervised loss for task τj . The ﬁnewhere tuned model fΘ is then evaluated on the held-out test set. Taking classiﬁcation accuracy as an example, the evaluation is formulated as follows: = arg max c{1,2,...,Cj } fΘ (X) , ic Acc(τj ) = 1 (j) te X(X,y)D(j) te 1( = y) , ) denotes the indicator function. (38) (39) where 1( Regarding evaluation scenarios, most existing studies adopt leave-one-subject-out (LOSO) setting or perform subjectdisjoint splits into training, validation, and test sets. Such protocols are valuable for assessing cross-subject generalization, as the test subject remains unseen during ﬁne-tuning. However, these protocols typically require substantial amount of labeled data from the same device and paradigm for ﬁne-tuning, since data from multiple training subjects are aggregated for adaptation. This requirement can be restrictive in practical deployment scenarios where only limited calibration data may be available for new user. In principle, foundation model is expected to reduce dependence on task-matched labeled data and enable effective adaptation with minimal calibration. This motivates the need for more comprehensive evaluation suite that encompasses both data-rich cross-subject transfer and data-limited calibration regimes under consistent protocols. Section III presents our benchmark design, which is constructed to address these complementary requirements. III. BENCHMARK OF BCI FOUNDATION MODELS This section presents comprehensive benchmark for EEG foundation models. We evaluate 12 open-source foundation models and 7 traditional baselines, including conventional machine learning and deep learning methods, on 13 datasets spanning 9 representative BCI paradigms. To assess model generalization under realistic deployment constraints, we design set of comprehensive and fair evaluation scenarios. An overview of the datasets and evaluation scenarios is illustrated in Fig. 5. A. Datasets Fig. 4 (b) summarizes the downstream datasets most frequently adopted in prior studies, where clinical EEG, motor 13 (a) Motor Imagery P300 SSVEP (b) Leave-One-Subject-Out (LOSO) Scenario (cid:252) BNCI2014001 (cid:252) BNCI2014004 (cid:252) BNCI2015001 (cid:252) BNCI2014008 (cid:252) BNCI2014009 (cid:252) Nakanishi2015 Labeled Fine-tuning Data Clinical Detection Emotion Recognition Visual Decoding Pre-trained EEG Foundation Models"
        },
        {
            "title": "Linear\nProbing",
            "content": "(cid:252) CHB-MIT (cid:252) TUAB (cid:252) SEED (cid:252) Things-EEG2 Within-Subject (Few-Shot) Scenario Fatigue Detection Sleep Stage Analysis Workload Detection Labeled Fine-tuning Data (cid:252) SEED-VIG (cid:252) Sleep-EDFx (cid:252) EEGMat Pre-trained EEG Foundation Models"
        },
        {
            "title": "Linear\nProbing",
            "content": "Fig. 5: Overview of datasets and evaluation scenarios used in the benchmark. (a) The 13 downstream datasets spanning 9 representative BCI paradigms, including motor imagery, P300, SSVEP, clinical detection, emotion recognition, visual decoding, fatigue detection, sleep stage analysis, and workload detection; (b) Illustration of the two evaluation scenarios: the leave-onesubject-out (LOSO) scenario, which aggregates labeled data from multiple subjects for ﬁne-tuning and evaluates on held-out subject, and the within-subject few-shot scenario, which uses only small amount of labeled data from the target subject for adaptation. TABLE IV: Summary of the EEG datasets in benchmarking."
        },
        {
            "title": "Number of\nChannels",
            "content": "Sampling Rate (Hz) Trial Length (seconds)"
        },
        {
            "title": "Labels",
            "content": "MI P"
        },
        {
            "title": "Clinic",
            "content": "BNCI2014001 BNCI2014004 BNCI2015001 BNCI2014009 BNCI2014008 9 9 12 10 8 CHB-MIT TUAB 23 2,"
        },
        {
            "title": "Sleep",
            "content": "Sleep-EDFx"
        },
        {
            "title": "SSVEP",
            "content": "Nakanishi"
        },
        {
            "title": "Visual Decoding",
            "content": "Things-EEG"
        },
        {
            "title": "Fatigue",
            "content": "SEED-VIG 78 15 9 36 21 22 3 13 16 8 18 21 2 8 19 63 17 250 250 512 256 256 250 100 200 256 500 200 4 4.5 5 0.8 1 4 10 30 4 4 1 8 2,592 1,400 2,400 5,760 33, 29,840 53,604 Classiﬁcation Classiﬁcation Classiﬁcation Classiﬁcation Classiﬁcation Classiﬁcation Classiﬁcation left / right hand, feet, tongue left hand, right hand right hand, both feet target, non-target target, non-target interictal, ictal normal, abnormal 414,961 Classiﬁcation W, N1, N2, N3, REM 50,910 Classiﬁcation positive, neutral, negative 1,620 1,080 18,540 18,585 Classiﬁcation 9.2514.75 Hz (0.5 Hz interval) Classiﬁcation low, high"
        },
        {
            "title": "Retrieve",
            "content": "200 images matching"
        },
        {
            "title": "PERCLOS",
            "content": "imagery, emotion recognition, and sleep staging emerge as the dominant evaluation paradigms. However, this concentration the on limited set of paradigms may not fully reﬂect generalization capability of foundation models across diverse BCI applications. To address this limitation, we select 13 datasets spanning 9 paradigms for downstream evaluation, providing broader coverage of representative BCI scenarios. The dataset characteristics are summarized in Table IV, with detailed descriptions provided in Appendix B. B. Evaluation Scenarios Most existing EEG foundation model studies evaluated downstream transfer under leave-one-subject-out (LOSO) scenario or subject-disjoint splits into training, validation, and test sets. While this setting is widely adopted, it remains unclear whether it provides comprehensive assessment of foundation model generalization and whether it aligns with practical deployment requirements. a) LOSO Scenario: The LOSO scenario evaluates crosssubject generalization within the same task and headset conﬁguration. Concretely, model is ﬁne-tuned using labeled data from subset of subjects recorded with the same EEG device and paradigm, and is subsequently evaluated on heldout subjects. The primary advantage of LOSO is that the target subject is evaluated in zero-calibration manner, as no labeled data from the test subject are used during ﬁnetuning. However, LOSO has two important limitations. First, it typically requires substantial amount of labeled data from multiple subjects, which increases the ﬁne-tuning cost. Second, implicitly assumes the availability of corpus collected with the same device conﬁguration and task as the target deployment setting, which may not hold in practice, particularly for new devices or customized paradigms. it In our benchmark, LOSO ﬁne-tuning followed the common practice of using all available trials from the ﬁnetuning subjects for most datasets. However, for the MI and P300 datasets (BNCI2014001, BNCI2014004, BNCI2015001, BNCI2014009, and BNCI2014008), we used only single session from each subject for ﬁne-tuning. For CHB-MIT, we used the ictal segments together with the 10-minute pre-ictal segments of each seizure for model adaptation and evaluation. For TUAB, we used the ﬁrst 3 minutes of each recording as input segments. For Things-EEG2, we used three repetitions per image. For Sleep-EDFx and TUAB, which contain large number of subjects, we adopted ten-fold subject split, where subjects were evenly partitioned into ten folds for crossvalidation. b) Within-Subject Few-Shot Scenario: To better reﬂect deployment settings where only limited calibration data are available for new user, we designed within-subject fewshot evaluation protocol. In this setting, the model was ﬁnetuned using small labeled subset from the target subject and evaluated on the remaining data of the same subject. The within-subject scenario offers two advantages. First, it substantially reduces the amount of ﬁne-tuning data and lowers the adaptation cost. Second, it does not require an external training corpus that matches the target device and paradigm, thereby supporting rapid personalization for new devices, tasks, and users. The primary limitation is that it requires collecting labeled calibration data from the target user during deployment, which may be inconvenient in certain applications. for datasets the MI Speciﬁcally, (BNCI2014001, BNCI2014004, and BNCI2015001), we ﬁne-tuned using 30% of one session from the target subject, with fewer than 30 trials per class. For P300 datasets, we ﬁne-tuned using 10% of one session for BNCI2014009 and 5% of one session for BNCI2014008. For CHB-MIT, we ﬁne-tuned using the ﬁrst seizures ictal segments from the target subject together with its 10-minute pre-ictal segment, and evaluated on the remaining seizures ictal segments with their corresponding pre-ictal segments. For Sleep-EDFx, we used 10% of the target subjects data for ﬁne-tuning. For SEED, we used one video per class for ﬁne-tuning. For Nakanishi2015 and EEGMat, we ﬁne-tuned using 80% and 60% of the target subjects data, respectively. For Things-EEG2, we adopted the same setting as in LOSO and used three repetitions per image. For SEED-VIG, we ﬁne-tuned using 10% of the data from single subject. We did not include within-subject few-shot setting for TUAB, as each subject is associated with 14 ﬁxed diagnostic label (normal or abnormal). c) Fine-Tuning Strategies: For both LOSO and withinsubject few-shot scenarios, we compared two ﬁne-tuning strategies to assess the quality of pre-trained representations. The ﬁrst strategy, full-parameter ﬁne-tuning, updated all model parameters during ﬁne-tuning, allowing the entire network to be optimized for the downstream task. The second strategy, linear probing, froze the pre-trained encoder and trained only the classiﬁcation head, which directly evaluated the transferability of the learned representations without task-speciﬁc feature adaptation. By comparing these two strategies, we aimed to disentangle the contributions of pre-trained representations from those of end-to-end ﬁne-tuning. d) Summary: The LOSO and within-subject few-shot protocols evaluate complementary aspects of generalization. LOSO measures cross-subject transfer under ﬁxed paradigm and device conﬁguration without test-subject calibration, whereas within-subject few-shot evaluates rapid personalization with limited calibration data. Furthermore, the comparison between full-parameter ﬁne-tuning and linear probing provides insights into the quality and transferability of pre-trained representations. By reporting results under both scenarios with both ﬁne-tuning strategies, our benchmark provides more comprehensive assessment of EEG foundation model generalization and better reﬂects practical deployment constraints. C. Evaluated Approaches In this benchmark, we compared traditional machine learning baselines, 6 deep learning models (including 3 CNN-based and 3 Transformer-based architectures), and 12 EEG foundation models. The following provides detailed description of each category. a) Traditional Machine Learning Baselines.: For each dataset, we selected paradigm-speciﬁc traditional machine learning algorithm as the baseline, which remains competitive against deep learning methods in the respective domain. CSP+LDA (linear discriminant analysis) [51] was used for BNCI2014001, BNCI2014004, BNCI2015001, TUAB, SEED, and EEGMat. xDAWN+LDA [52] was employed for the P300 datasets BNCI2014009 and BNCI2014008. PSD+SVM (Power Spectral Density with Support Vector Machine) [53] was used for CHB-MIT. PSD+LDA [54] was applied to SleepEDFx. TRCA (task-related component analysis) [55] was used for Nakanishi2015. PSD+Ridge [56] was employed for SEEDVIG. b) Deep Learning Baselines: We evaluated six taskspeciﬁc deep learning models trained from scratch. For CNNbased architectures, we included EEGNet [57], ShallowConvNet [58], and LMDA-Net [59]. For Transformer-based architectures, we included CNN-Transformer [60], Deformer [61], and Conformer [62]. These models represent widely adopted architectures in the EEG decoding and serve as strong baselines for comparison with foundation models. c) EEG Foundation Models: We evaluated all EEG foundation models with publicly available code and pre-trained weights, including BENDR [1], BIOT [4], LaBraM [6], NeuroGPT [8], EEGPT [15], CBraMod [16], TFM [23], BrainOmni [25], EEGMamba [31], MIRepNet [32], SingLEM [37], and LUNA [46]. Among these, MIRepNet is paradigmspeciﬁc foundation model designed exclusively for motor imagery tasks, while the remaining 11 models are generalpurpose EEG foundation models intended to support multiple BCI paradigms. D. Main Results The main results are summarized in Tables and VI. We reported balanced classiﬁcation accuracy (BCA) as the primary metric for all classiﬁcation tasks. We adopted 2-way accuracy for the Things-EEG2 dataset and root mean square error (RMSE) for the SEED-VIG regression task. Comprehensive per-subject results are provided in Appendix C. 1) Can Foundation Models Learn Generalized Representations?: Tables and VI present the performance of 12 EEG foundation models across 13 downstream datasets. notable observation was that head-only ﬁne-tuning (linear probing) consistently yielded inferior, and in many cases substantially lower, performance compared to full-parameter ﬁne-tuning for most foundation models. This ﬁnding suggested that adapting foundation models to diverse downstream tasks cannot rely solely on features extracted by pre-trained encoders; taskspeciﬁc ﬁne-tuning of the encoder parameters remains essential. While several models such as EEGPT exhibited superior head-only performance relative to full ﬁne-tuning, neither adaptation strategy achieved consistently strong results across the benchmark. Furthermore, EEG foundation models exhibited considerable variability in their task-speciﬁc performance. For instance, CBraMod demonstrated competitive results across most tasks, achieving ﬁrst and second place on the SEED dataset under LOSO and few-shot scenarios, respectively. However, it yielded the highest RMSE among all evaluated methods on SEED-VIG in the LOSO scenario. Similarly, LUNA attained state-of-the-art performance on TUAB but failed to generalize effectively to paradigms beyond clinical applications, limitation likely attributable to its pre-training exclusively on TUEG and Siena datasets. An encouraging ﬁnding emerged from the Nakanishi2015 dataset, an SSVEP paradigm with extremely limited ﬁnetuning data (12 trials per class). Despite this constraint, several foundation models, including BENDR, EEGPT, and Neuro-GPT, achieved strong performance. Since the SSVEP paradigm relies on decoding neural responses to target stimuli ﬂickering at distinct frequencies, the resulting signals exhibit pronounced periodicity and temporal structure. Consequently, the masked reconstruction objectives employed during pretraining may endow these models with enhanced capability to capture temporal dynamics in EEG signals. Fig. 6 visualizes the encoder features using t-SNE. We selected Subject 2 from BNCI2014008 and Subject 7 from SEED, both of which exhibited relatively strong performance compared to other subjects in their respective datasets. The visualization revealed that full-parameter ﬁne-tuning yielded more discriminative feature structures than linear probing, with clearer separation between classes in the embedding space. In summary, pre-trained EEG foundation models demonstrated capacity to extract transferable representations to 15 certain extent. However, this generalization capability remained insufﬁciently robust: the majority of models required full-parameter ﬁne-tuning on downstream tasks and could not directly leverage pre-trained encoders to obtain features for effective decoding. Even the best-performing foundation models in our evaluation exhibited notable performance degradation on speciﬁc tasks, indicating that achieving truly universal EEG representations remains an open challenge. 2) Can Foundation Models Consistently Outperform Specialist Models?: With the proliferation of EEG foundation models, whether traditional deep learning methods remain competitive is question worth investigating. We compared existing foundation models against seven specialist models, including 1 traditional machine learning method, 3 CNNbased methods, and 3 Transformer-based methods. These specialist models were trained from scratch using the same ﬁne-tuning data as the foundation models and evaluated on identical test sets. Fig. 7(a) and (b) present the ranking of each model based on the number of top-1 and top-3 placements across all tasks and scenarios. Notably, EEGNet demonstrated remarkable performance despite having only 2K parameters. Among the top ﬁve models in both Fig. 7(a) and (b), four were specialist models. Furthermore, Fig. 7(c) and (d) compare the total number of top-1 and top-3 placements achieved by specialist models versus EEG foundation models. To ensure fair comparison given the larger number of foundation models, we selected the seven foundation models with the highest top-3 counts for this analysis. Specialist models achieved 15 ﬁrst-place ﬁnishes and 47 top-3 placements, outperforming the selected foundation models. These results indicate that traditional deep learning architectures remain highly competitive in the era of foundation models. 3) Do Larger EEG Models Achieve Better Performance?: Table VII and Fig. 8 present the overall ranking, average ranking, and model size of various EEG decoding models across 13 datasets under both LOSO and few-shot scenarios. CBraMod achieved the highest overall ranking with an average rank of 5.96 and model size of 4.0M parameters. EEGNet, widely utilized lightweight EEG decoding backbone, attained second place with only 2K parameters. These results demonstrated that larger models do not necessarily yield better performance. This observation may be attributed to two factors: (1) EEG data acquisition incurs high costs in terms of time, labor, and resources, resulting in limited data availability and substantial noise levels, with notable lack of large-scale, high-quality datasets [76]; (2) existing pre-training strategies for foundation models may be suboptimal, suggesting that developing pretrained decoding models capable of learning universal representations remains an essential research direction. E. Comparison of Different Fine-tuning Ratios In the within-subject few-shot scenario, pre-trained model is expected to achieve satisfactory performance with minimal calibration data. We conducted an analysis on different ﬁnetuning data ratios, varying from 10%, 30%, 50%, 70% to 90%. For this comparison, we selected the top three specialist models (EEGNet, ShallowConv, and LMDA) and the top TABLE V: Benchmark performance. The best metrics are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "BNCI2014001 BNCI2014004 BNCI2015001 BNCI2014009 BNCI2014008 CHB-MIT"
        },
        {
            "title": "TUAB",
            "content": ""
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) Traditional ML EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base Traditional ML EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 38.19 44.970.57 44.800.50 46.800.31 39.150.56 41.530.67 41.641.23 51.110.25 34.270.93 46.931.43 46.970.71 32.241.45 53.030.22 32.020.66 41.580.80 40.930.83 45.720.54 30.570.10 28.860.50 32.180.41 30.881.00 42.590.27 48.241.04 37.371.25 41.450.50 28.340.30 39.780.36 39.630.58 34.320.20 33.420.22 29.210.57 60.62 50.221.14 52.870.88 51.130.76 51.271.10 42.210.73 57.191.32 44.901.31 48.600.72 37.130.92 42.180.23 34.990.25 50.341.18 33.300.46 39.000.19 37.600.27 38.040.45 28.940.73 31.941. 31.430.85 47.950.53 35.380.45 49.821.55 35.860.54 27.610.55 27.781.05 40.610.31 38.710.36 33.840.40 29.870.18 34.730.05 73.24 76.380.59 74.230.39 74.880.67 71.200.42 74.860.82 74.170.49 73.350.06 70.221.32 76.971.08 77.700.70 71.370.16 75.450.35 60.123.00 70.130.89 69.300.89 73.300.57 67.310.18 56.173.14 60.461.06 61.352.11 65.050.23 75.571.26 72.082.07 69.270.55 50.971.13 66.050.53 67.480.25 61.940.31 63.690.36 51.100.65 79.20 75.533.67 74.520.71 75.111.63 75.770.38 73.022.13 80.170.25 71.701.46 68.430.42 69.761.23 75.251.58 62.070.74 77.390.35 58.922.41 63.300.98 61.840.76 65.071.86 56.751.66 56.500. 55.272.40 67.151.64 59.831.22 76.691.35 65.882.18 70.380.90 51.301.08 59.790.60 59.100.30 59.020.34 56.511.27 55.610.89 56.42 63.401.32 63.890.80 61.400.94 59.641.41 63.061.17 59.102.14 62.680.49 63.941.20 64.141.03 60.621.63 59.881.39 63.470.36 55.351.46 61.880.30 60.640.39 61.530.50 54.470.62 55.711.37 53.851.11 63.430.63 61.970.17 61.240.50 63.002.89 59.930.29 53.430.53 61.540.54 60.380.19 56.380.27 54.080.20 56.720.41 75.89 72.080.39 73.790.66 73.791.50 71.631.36 70.321.28 77.101.49 56.590.25 68.431.48 61.390.65 61.900.90 59.170.87 70.300.72 55.340.28 61.591.54 59.860.83 60.240.48 52.120.63 60.361. 50.950.90 67.801.21 59.740.86 65.600.86 60.872.36 60.810.06 53.731.18 63.210.76 60.891.07 54.250.65 53.750.32 57.560.18 65.14 78.390.44 78.050.62 78.450.46 61.501.71 76.890.14 62.220.97 73.460.28 58.140.33 70.310.24 75.970.53 62.771.85 77.300.28 53.100.48 70.480.23 70.870.29 76.010.05 71.980.56 51.670.54 61.242.07 51.040.12 67.750.32 58.700.26 66.530.05 58.630.54 51.560.51 61.340.42 69.500.69 74.130.30 72.520.05 52.160.50 54.45 68.990.51 57.130.93 60.280.82 50.320.52 65.380.32 53.380.31 59.271.03 52.190.16 60.060.58 55.020.97 52.021.14 56.851.03 51.420.87 57.020.36 59.751.14 65.500.46 57.700.41 51.660. 52.030.18 53.030.78 55.150.21 50.650.31 53.180.97 50.180.15 51.120.83 56.330.16 58.370.35 65.790.16 63.660.96 51.420.19 58.69 72.290.17 69.920.05 71.740.12 51.930.16 57.751.21 53.100.06 65.010.18 54.770.21 63.070.97 68.590.25 58.240.40 69.910.06 52.990.29 61.400.17 59.310.06 68.180.05 63.420.13 50.000.04 67.110.76 53.190.66 56.820.60 50.080.04 57.260.17 53.310.14 51.930.63 51.330.14 58.930.43 63.650.11 61.890.03 49.990.02 56.65 70.911.17 55.970.20 63.580.30 50.230.29 64.360.93 51.090.40 58.331.00 52.120.27 54.670.67 61.610.14 51.930.41 58.000.99 51.210.28 56.340.33 56.180.14 61.120.35 56.380.28 50.290. 51.750.70 51.620.47 52.960.24 50.880.02 51.340.18 51.430.09 50.930.36 52.960.05 54.330.30 61.450.09 58.270.40 50.790.15 69.090.04 77.360.54 80.180.22 77.470.41 76.340.61 79.770.14 78.580.56 75.500.93 74.850.33 70.870.59 73.270.27 66.912.89 74.230.19 63.460.60 75.920.21 60.781.82 78.120.61 53.220.68 69.790.62 68.840.36 70.450.24 70.940.69 75.210.52 56.830.75 71.810.26 50.500.11 67.430.45 77.710.35 88.450.48 85.810.44 86.800.55 87.660.33 86.880.33 91.580.34 54.140.33 79.600.51 71.310.29 83.090.59 63.740.28 88.540.16 59.550.57 79.500.42 56.701.49 72.300. 50.070.18 73.411.06 66.930.88 71.681.57 66.711.20 87.770.73 53.320.37 82.180.17 51.070.11 71.110.20 66.030.25 77.030.67 79.810.12 62.691.52 73.200.73 81.480.21 77.780.04 79.090.16 51.761.39 76.230.27 79.500.17 77.670.17 79.980.11 75.650.07 72.920.25 80.490.29 80.900.10 50.801.02 81.920.07 58.330.66 51.581.17 78.320.11 79.640.15 77.510.09 78.040.04 68.250.09 77.030.37 79.320.30 78.240.04 51.530.13 75.880.17 TABLE VI: Benchmark performance. The best metrics are marked in bold, and the second best by an underline (continued)."
        },
        {
            "title": "Approach",
            "content": "Sleep-EDFx"
        },
        {
            "title": "SEED",
            "content": "Nakanishi"
        },
        {
            "title": "EEGMat",
            "content": "Things-EEG2 SEED-VIG"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) Traditional ML EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base Traditional ML EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 51.780.22 73.750.19 74.860.42 74.580.34 75.740.48 78.730.09 68.402.87 71.450.43 66.350.23 63.560.03 59.090.25 62.931.06 72.300.18 67.380.25 66.680.42 67.230.48 71.030.36 54.780.12 60.590.19 62.730.24 57.950.58 55.670.87 52.560.30 56.950.46 51.960.13 34.770.13 58.140.22 59.00 48.290.54 55.290.49 46.752.12 64.770.61 52.260.38 63.310.48 37.340.24 61.750.48 35.990.23 54.500.29 56.380.16 57.720.08 58.820.14 61.500.62 29.711.75 66.020. 21.580.06 59.420.10 49.200.10 49.690.62 61.990.47 41.330.26 49.560.26 46.300.18 22.510.24 61.990.07 48.91 48.571.34 53.410.12 50.120.43 44.561.40 51.050.97 48.761.23 52.500.85 49.040.90 52.230.92 49.670.38 48.743.41 53.610.61 36.660.26 38.020.03 44.720.18 52.190.04 50.161.48 49.960.35 34.690.10 51.080.77 52.460.05 49.670.38 50.041.03 51.830.07 35.280.04 44.270.11 44.060.26 51.900.15 35.690.04 42.770.22 53.38 52.120.47 51.970.26 53.201.39 51.951.06 52.190.30 55.671.63 41.030.54 48.410.56 47.000.92 55.900.09 40.480.44 55.820.39 35.400.15 46.740.39 44.410.12 51.330.27 47.012.01 46.060. 34.000.16 48.100.65 49.460.14 52.030.10 42.900.42 52.320.39 34.280.44 43.540.14 43.620.15 49.360.03 34.620.05 42.270.19 94.07 95.880.18 69.610.86 85.120.94 46.340.34 97.180.13 33.601.08 92.940.30 72.353.04 79.180.73 87.350.40 88.313.30 85.390.60 12.840.68 78.330.23 50.881.99 70.080.94 33.541.23 8.520.22 57.614.18 68.313.34 53.270.83 72.391.75 85.474.26 17.410.28 10.880.58 73.770.66 24.940.15 17.820.03 17.900.22 9.340.34 98.77 66.674.00 51.232.02 49.491.96 61.631.19 71.601.90 41.363.07 85.910.29 84.671.48 77.882.14 76.441.48 75.728.11 62.351.15 11.731.26 82.000.52 52.881.29 44.030.15 33.022.63 8.950. 29.122.45 78.195.09 66.980.50 52.671.24 77.783.81 24.281.77 10.081.72 82.000.52 23.562.52 20.990.50 19.140.91 9.471.72 67.41 66.600.63 72.221.24 67.471.21 70.772.49 71.730.37 70.490.93 54.320.71 70.771.49 65.741.61 72.621.35 58.021.02 68.430.72 63.021.95 57.500.80 51.510.76 49.970.04 49.850.16 50.000.00 51.511.57 66.451.24 64.480.56 68.581.89 59.380.53 60.340.27 62.440.09 62.500.50 50.400.69 50.060.09 50.400.43 49.970.39 95.60 60.571.29 69.371.43 54.780.22 51.080.95 52.010.39 68.331.71 52.160.22 86.113.16 65.741.50 71.223.69 65.592.51 79.321.15 77.550.95 58.720.79 51.081.86 50.080.11 50.460.19 50.620. 49.461.52 77.083.95 70.222.94 70.601.43 67.051.22 60.492.25 58.266.15 59.411.22 52.161.47 50.150.22 49.691.42 50.080.11 74.423.67 72.030.38 78.720.86 59.052.13 78.470.65 64.000.91 71.470.39 50.570.22 75.150.93 80.281.08 74.901.35 75.880.89 50.480.45 66.831.16 67.130.39 74.480.12 61.974.80 63.680.55 54.870.75 48.353.15 59.651.31 66.200.99 66.420.49 75.801.19 49.430.95 60.750.25 63.850.95 73.400.29 63.120.48 49.200.32 89.250.60 64.520.56 84.530.94 57.500.94 82.950.72 59.900.19 65.850.49 49.222.46 83.750.74 81.021.10 64.351.28 84.830.43 50.400.55 67.950.25 67.700.21 86.120.65 52.001.27 51.870. 56.871.17 51.830.53 60.670.47 65.370.33 66.301.97 81.670.38 49.771.25 63.770.50 63.270.72 78.500.33 75.900.53 50.430.56 0.2489 0.25610.0092 0.22900.0029 0.23890.0029 0.25560.0140 0.25120.0053 0.24050.0044 0.24120.0025 0.34270.0627 0.22810.0035 0.25090.0055 0.24020.0025 0.27180.0019 0.22830.0026 0.24340.0003 0.25490.0055 0.22970.0010 0.23490.0004 0.23420.0043 0.30680.0017 0.23490.0011 0.23340.0010 0.24430.0035 0.23350.0043 0.27650.0020 0.24170.0004 0.24470.0012 0.23600.0032 0.23430.0002 0.26320.0006 0.23670.0013 0.17640.0013 0.20820.0045 0.38390.0063 0.20270.0110 0.15380.0100 0.29020.0167 0.14210.0034 0.24360.0023 0.22300.0414 0.19560.0017 0.18800.0035 0.19900.0007 0.20510.0036 0.22080.0058 0.21460.0089 0.19230.0062 0.17740.0018 0.22710.0021 0.16760. 0.22710.0015 0.29370.0419 0.19350.0020 0.20150.0051 0.20040.0062 0.18950.0075 0.22080.0058 0.22020.0035 0.18610.0031 0.17120.0014 0.27520.0075 0.16540.0009 18 20 10 0 20 30 20 10 0 20 10 5 0 5 10 5 0 5 10 BNCI2014008-EEGNet BNCI2014008-LMDA BNCI2014008-CBraMod (full) BNCI2014008-CBraMod (linear) target 30 target 20 target target non-target non-target non-target non-target 20 10 0 10 10 5 0 5 10 10 0 10 20 15 30 20 10 0 10 30 30 20 10 0 20 30 20 10 0 20 40 20 0 20 20 (a) (b) (c) (d) BNCI2014008-BENDR (full) BNCI2014008-BENDR (linear) BNCI2014008-BIOT (full) BNCI2014008-BIOT (linear) target target target target non-target 15 non-target non-target non-target 10 5 0 5 15 20 10 0 10 20 10 0 10 20 40 30 20 10 0 20 30 20 15 10 0 5 10 15 30 10 0 10 20 30 10 0 10 20 30 (e) (f) (g) (h) SEED-EEGNet SEED-LMDA SEED-CBraMod (full) SEED-CBraMod (linear) positive positive positive positive 30 negative negative negative negative 20 neutral neutral neutral neutral 5 0 5 10 10 10 20 30 20 10 10 20 30 60 40 0 20 40 60 20 0 10 20 30 40 40 20 0 20 40 20 10 0 10 20 40 (i) (j) (k) (l) SEED-BENDR (full) SEED-BENDR (linear) SEED-BIOT (full) SEED-BIOT (linear) positive negative neutral 8 6 4 2 0 4 6 positive 10 negative positive positive negative 10 negative neutral neutral neutral 5 0 5 10 0 5 10 30 20 0 10 20 30 40 5 0 5 10 15 5 0 5 10 15 20 10 0 10 20 (m) (n) (o) (p) Fig. 6: t-SNE visualization of the BNCI2014008 and SEED datasets. three EEG foundation models (CBraMod, Neuro-GPT, and LaBraM). The results are presented in Fig. 9. All models exhibited signiﬁcant performance improvements as the amount of ﬁne-tuning data increased, which aligns with intuitive expectations. However, minimal calibration or even calibrationfree adaptation remains critical requirement for practical deployment. Developing models that can rapidly adapt to downstream tasks with limited data remains an open and pressing challenge. IV. DISCUSSION This section presents additional discussions. A. Paradigm-Speciﬁc Foundation Models In real-world applications, the paradigm for downstream task is generally determined prior to data collection. For example, stroke patients requiring exoskeleton-assisted rehabilitation are naturally suited to MI-based systems [77], while epilepsy monitoring demands epilepsy-speciﬁc approaches [78]. Therefore, when user information such as patient demographics and target applications is available, employing paradigm-speciﬁc foundation model for direct adaptation represents practical and effective strategy. In recent years, several researchers have attempted to develop paradigm-speciﬁc foundation models tailored to particular tasks, such as MEET [10] for emotion recognition, 19 * ( ( H 1 H U I R & X 1 * 3 / 0 D R W ) ' H U R 0 U % & % / 0 H D Q % $ & $ ' / 1 8 / O D 6 G U 7 Q H 1 U P H U * & 0 R R ) ' % & L Q & R ( ( / 0 D H 1 X D 6 G U 7 7 $ ' * / % $ V 7 1 & ( % 5 ' 1 2 , % E 0 ) 7 D 0 8 / * ( ( (a) Ranking by top-1 counts for each model. (b) Ranking by top-3 counts for each model. 6SHFLDOLVW0RGHOV ((*)RXQGDWLRQ0RGHOV 6SHFLDOLVW0RGHOV ((*)RXQGDWLRQ0RGHOV (c) Top-1 counts: specialist models vs. foundation models. (d) Top-3 counts: specialist models vs. foundation models. Fig. 7: Comparison of ranking performance between specialist models and foundation models. (a) and (b) show the number of top-1 and top-3 placements for individual models across all tasks and scenarios. (c) and (d) compare the aggregate top-1 and top-3 counts between specialist models and the seven best-performing foundation models. MIRepNet [32] for motor imagery, PSGFM [33] for sleep staging, and EpilepsyFM [36] for epilepsy detection. Among these, we compared MIRepNet, which provides open-source pre-trained weights, against existing general-purpose foundation models on MI tasks. Tables XV to XX in Appendix present detailed results on three MI datasets: BNCI2014001, BNCI2014004, and BNCI2015001. MIRepNet achieved stateof-the-art performance in terms of both subject-averaged accuracy and Cohens Kappa. This superior performance may be attributed to the fact that paradigm-speciﬁc foundation models are pre-trained exclusively on datasets from the target task and incorporate neurophysiological principles relevant to that paradigm in their pre-training strategies. Consequently, the pre-trained encoder is capable of extracting task-speciﬁc representations that facilitate rapid adaptation to downstream applications. Given that the required paradigm is typically known before data acquisition in practical BCI deployment, developing paradigm-speciﬁc pre-trained foundation models represents viable and promising research direction. Furthermore, whether auxiliary data from other paradigms can enhance pre-training for target paradigm remains an open question worthy of further investigation. B. Effectiveness of EA As mentioned in Section II-C2, Euclidean alignment (EA) [75], [83] aligns the marginal distributions across EEG trials. Fig. 10 illustrates that trials from different subjects are mapped onto common feature space after applying EA. We compared model performance with and without EA on the BNCI2014001 dataset. As shown in Fig. 11, incorporating EA during training or ﬁne-tuning improved generalization performance for the majority of models. V. CONCLUSION This paper has presented comprehensive benchmark for EEG foundation models in BCIs. We reviewed 50 studies and distilled their common pipeline components and pre-training objectives into uniﬁed framework that enables structured comparison across heterogeneous devices and paradigms. Based on this analysis, we established benchmark that evaluates 12 open-source EEG foundation models alongside competitive specialist baselines across 13 datasets spanning 9 representative BCI paradigms, under both cross-subject LOSO and within-subject few-shot evaluation protocols. The experimental results indicate that current EEG foundation models have not yet achieved universally transferable Fig. 8: Overall ranking of EEG foundation models with respect to release date and model size (bubble size indicates parameter count; lower rank is better). representations. Speciﬁcally, full-parameter ﬁne-tuning consistently provides substantial advantages over linear probing, suggesting that pre-trained encoders cannot be directly employed as ﬁxed feature extractors across diverse downstream tasks. Furthermore, specialist models trained from scratch remain highly competitive, and increasing model size alone does not guarantee improved generalization. These ﬁndings highlight the need for future research on advancing pretraining strategies, as well as enhancing robustness to noise and cross-task heterogeneity. We hope that this benchmark serves as standardized reference and accelerates the development of more reliable and practical foundation models for brain-computer interfaces."
        },
        {
            "title": "REFERENCES",
            "content": "[1] D. Kostas, S. Aroca-Ouellette, and F. Rudzicz, BENDR: Using transformers and contrastive self-supervised learning task to learn from massive amounts of EEG data, Frontiers in Human Neuroscience, vol. 15, p. 653659, 2021. [2] C. Wang, V. Subramaniam, A. U. Yaari, G. Kreiman, B. Katz, I. Cases, and A. Barbu, BrainBERT: Self-supervised representation learning for intracranial recordings, Kigali, Rwanda, May 2023. [3] D. Cai, J. Chen, Y. Yang, T. Liu, and Y. Li, Mbrain: multi-channel self-supervised learning framework for brain signals, in Proc. of the 29th ACM SIGKDD Conf. on Knowledge Discovery and Data Mining, Long Beach, CA, Aug. 2023, pp. 130141. [4] C. Yang, M. Westover, and J. Sun, BIOT: Biosignal transformer for cross-data learning in the wild, Advances in Neural Information Processing Systems, vol. 36, pp. 78 24078 260, Dec. 2023. [5] D. Zhang, Z. Yuan, Y. Yang, J. Chen, J. Wang, and Y. Li, Brant: Foundation model for intracranial neural signal, Advances in Neural Information Processing Systems, vol. 36, pp. 26 30426 321, Dec. 2023. [6] W. Jiang, L. Zhao, and B.-l. Lu, Large brain model for learning generic representations with tremendous EEG data in BCI, in The Twelfth Intl Conf. on Learning Representations, Vienna, Austria, May 2024. [7] S. Panchavati, C. Arnold, and W. Speier, Mentality: mambabased approach towards foundation models for EEG, arXiv preprint arXiv:2509.02746, 2025. [8] W. Cui, W. Jeong, P. Tholke, T. Medani, K. Jerbi, A. A. Joshi, and R. M. Leahy, Neuro-GPT: Towards foundation model for EEG, in IEEE Intl Symposium on Biomedical Imaging (ISBI). IEEE, 2024, pp. 15. [9] Y. Chen, K. Ren, K. Song, Y. Wang, Y. Wang, D. Li, and L. Qiu, EEGFormer: Towards transferable and interpretable large-scale EEG foundation model, in AAAI 2024 Spring Symposium on Clinical Foundation Models, Stanford, CA, Mar. 2024. [10] E. Shi, S. Yu, Y. Kang, J. Wu, L. Zhao, D. Zhu, J. Lv, T. Liu, X. Hu, and S. Zhang, MEET: multi-band EEG transformer for brain states decoding, IEEE Trans. on Biomedical Engineering, vol. 71, no. 5, pp. 14421453, 2023. [11] Z. Yuan, F. Shen, M. Li, Y. Yu, C. Tan, and Y. Yang, Brainwave: brain signal foundation model for clinical applications, arXiv preprint arXiv:2402.10251, 2024. [12] W. Jiang, Y. Wang, B.-l. Lu, and D. Li, NeuroLM: universal multitask foundation model for bridging the gap between language and EEG signals, in The Thirteenth Intl Conf. on Learning Representations, Vienna, Austria, May. 2024. [13] D. Zhang, Z. Yuan, J. Chen, K. Chen, and Y. Yang, Brant-X: uniﬁed physiological signal alignment framework, in Proc. of the 30th ACM SIGKDD Conf. on Knowledge Discovery and Data Mining, Barcelona, Spain, Aug. 2024, pp. 41554166. [14] E. Shi, K. Zhao, Q. Yuan, J. Wang, H. Hu, S. Yu, and S. Zhang, FoME: foundation model for EEG using adaptive temporal-lateral attention scaling, arXiv preprint arXiv:2409.12454, 2024. [15] G. Wang, W. Liu, Y. He, C. Xu, L. Ma, and H. Li, EEGPT: Pretrained transformer for universal and reliable representation of EEG signals, Advances in Neural Information Processing Systems, vol. 37, pp. 39 24939 280, Dec. 2024. [16] J. Wang, S. Zhao, Z. Luo, Y. Zhou, H. Jiang, S. Li, T. Li, and G. Pan, 21 D X F $ D X F $ %1&,((*1HW %1&,6KDOORZ&RQY %1&,/0'$ D X F $ D X F $ %1&,&%UD0RG %1&,1HXUR*37 %1&,/D%UD0 D X F $ D X F $ (a) Accuracy comparison on the BNCI2014001 dataset across different ﬁne-tuning ratios. 1DNDQLVKL((*1HW 1DNDQLVKL6KDOORZ&RQY 1DNDQLVKL/0'$ D X F $ D X F $ D X F $ D X F $ 1DNDQLVKL&%UD0RG 1DNDQLVKL1HXUR*37 1DNDQLVKL/D%UD D X F $ D X F $ (b) Accuracy comparison on the Nakanishi2015 dataset across different ﬁne-tuning ratios. Fig. 9: Performance comparison across different ﬁne-tuning data ratios on the BNCI2014001 dataset (MI paradigm) and the Nakanishi2015 dataset (SSVEP paradigm). TABLE VII: Overall ranking of EEG foundation models and specialist models across 13 datasets under LOSO and few-shot scenarios."
        },
        {
            "title": "Model",
            "content": "Avg. Rank Model Size 1 2 3 4 6 7 8 9 10 12 13 14 15 16 18 19 CBraMod (FM)"
        },
        {
            "title": "DeFormer",
            "content": "Neuro-GPT (FM) LaBraM (FM) EEGMamba (FM)"
        },
        {
            "title": "Traditional ML",
            "content": "BENDR (FM) BIOT (FM) CNN-T EEGPT (FM) BrainOmni-Tiny (FM) BrainOmni-Base (FM) LUNA-Base (FM) SingLEM (FM) TFM (FM) 5.96 6.84 7. 7.12 7.16 7.24 8.56 8.92 9. 9.22 9.88 11.00 11.20 11.32 11. 11.90 13.76 14.16 15.24 4.0M 2K 36K 3K 0.8M 0.16M 5.8M 3.3M 0.16M 4.0M 3.2M 2.8M 25M 8.4M 33M 7.0M 3.3M 1.9M 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW 6XEMHFW (a) (b) t-SNE visualization of EEG trials Fig. 10: from the BNCI2014004 dataset. (a) Before EA; (b) After EA. Different colors represent trials from different subjects. CBramod: criss-cross brain foundation model for EEG decoding, in The Thirteenth Intl Conf. on Learning Representations, Singapore, Apr. 2025. [17] T. Yue, S. Xue, X. Gao, Y. Tang, L. Guo, J. Jiang, and J. Liu, EEGPT: Unleashing the potential of EEG generalist foundation model by autoregressive pre-training, arXiv preprint arXiv:2410.19779, 2024. [18] L. Wang, T. Suzumura, and H. Kanezashi, GEFM: Graph-enhanced EEG foundation model, in 2025 47th Annual Intl Conf. of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, 2025, pp. 17. [19] A. Dimofte, G. A. Bucagu, T. M. Ingolfsson, X. Wang, A. Cossettini, L. Benini, and Y. Li, CERebro: Compact encoder for representations of brain oscillations using efﬁcient alternating attention, arXiv preprint arXiv:2501.10885, 2025. [20] Y. Wang, N. Huang, N. Mammone, M. Cecchi, and X. Zhang, LEAD: Large foundation model for EEG-based alzheimers disease detection, arXiv preprint arXiv:2502.01678, 2025. [21] A. Tegon, T. M. Ingolfsson, X. Wang, L. Benini, and Y. Li, FEMBA: Efﬁcient and scalable EEG analysis with bidirectional mamba foundation model, arXiv preprint arXiv:2502.06438, 2025. [22] C.-S. Chen, Y.-J. Chen, and A. H.-W. Tsai, Large cognition model: Towards pretrained EEG foundation model, arXiv preprint arXiv:2502.17464, 2025. [23] J. Pradeepkumar, X. Piao, Z. Chen, and J. Sun, Tokenizing singlechannel EEG with time-frequency motif learning, in NeurIPS 2025 Workshop on Learning from Time Series for Health, San Diego, CA, Dec. 2025. [24] W. Xiong, J. Lin, J. Li, J. Li, and C. Jiang, ALFEE: Adaptive large foundation model for EEG representation, arXiv preprint arXiv:2505.06291, 2025. [25] Q. Xiao, Z. Cui, C. Zhang, S. Chen, W. Wu, A. Thwaites, A. Woolgar, B. Zhou, and C. Zhang, Brainomni: brain foundation model for uniﬁed EEG and MEG signals, Advances in Neural Information Processing Systems, Dec. 2025. [26] M. Ogg, R. Hingorani, D. Luna, G. W. Milsap, W. G. Coon, and C. A. Scholl, EEG foundation models for BCI learn diverse features of electrophysiology, arXiv preprint arXiv:2506.01867, 2025. [27] J. Ma, F. Wu, Q. Lin, Y. Xing, C. Liu, Z. Jia, and M. Feng, Codebrain: Towards decoupled interpretability and multi-scale architecture for EEG foundation model, arXiv preprint arXiv:2506.09110, 2025. [28] W. Lu, C. Song, J. Wu, P. Zhu, Y. Zhou, W. Mai, Q. Zheng, and W. Ouyang, Unimind: Unleashing the power of LLMs for uniﬁed multitask brain decoding, arXiv preprint arXiv:2506.18962, 2025. [29] Y. Zhou, J. Wu, Z. Ren, Z. Yao, W. Lu, K. Peng, Q. Zheng, C. Song, W. Ouyang, and C. Gou, CSBrain: cross-scale spatiotemporal brain foundation model for EEG decoding, Advances in Neural Information Processing Systems, Dec. 2025. [30] Y. Zhang, Y. Yu, H. Li, A. Wu, X. Chen, J. Liu, L.-L. Zeng, and D. Hu, DMAE-EEG: pretraining framework for EEG spatiotemporal representation learning, IEEE Trans. on Neural Networks and Learning Systems, 2025. [31] J. Wang, S. Zhao, Z. Luo, Y. Zhou, S. Li, and G. Pan, EEGMamba: An EEG foundation model with mamba, Neural Networks, p. 107816, 2025. [32] D. Liu, Z. Chen, J. Luo, S. Lian, and D. Wu, MIRepnet: pipeline and foundation model for EEG-based motor imagery classiﬁcation, arXiv preprint arXiv:2507.20254, 2025. [33] W. G. Coon and M. Ogg, Foundation models reveal untapped health information in human polysomnographic sleep data, medRxiv, pp. 202507, 2025. [34] J. H. Puah, S. K. Goh, Z. Zhang, Z. Ye, C. K. Chan, K. S. Lim, S. L. Fong, K. S. Woon, and C. Guan, EEGDM: EEG representation learning via generative diffusion model, arXiv preprint arXiv:2508.14086, 2025. [35] A. Li, Z. Wang, L. Yang, Z. Wang, T. Xu, H. Hu, and M. M. Van Hulle, CoMET: contrastive-masked brain foundation model for universal EEG representation, arXiv preprint arXiv:2509.00314, 2025. [36] Z. Li, N. Zhu, Y. Chen, B. Chen, Q. Dong, L. Gan, S. Zhao, Z. Yan, and T. Zhang, EpilepsyFM: domain-speciﬁc foundation model for epileptic representation learning using EEG signals, Neural Networks, p. 108060, 2025. [37] J. Sukhbaatar, S. Imamura, I. Inoue, S. Murakami, K. M. Hassan, S. Han, I. Chanpornpakdi, and T. Tanaka, SingLEM: Single-channel large EEG model, arXiv preprint arXiv:2509.17920, 2025. [38] Y. Ding, M. Jiang, W. Jiang, S. Zhang, X. Zhou, C. Liu, S. Li, Y. Li, and C. Guan, Brainpro: Towards large-scale brain state-aware EEG representation learning, arXiv preprint arXiv:2509.22050, 2025. [39] Z. Chen, Y. Zhang, Q. Lan, T. Liu, H. Wang, Y. Ding, Z. Jia, R. Chen, K. Wang, and X. Zhou, Uni-NTFM: uniﬁed foundation model for eeg signal representation learning, arXiv preprint arXiv:2509.24222, 2025. [40] M. Jiang, S. Zhang, Z. Yang, M. Wu, W. Jiang, Z. Guo, W. Zhang, R. Liu, S. Zhang, Y. Li et al., ELASTIQ: EEG-language alignment with semantic task instruction and querying, arXiv preprint arXiv:2509.24302, 2025. [41] K. Avramidis, T. Feng, W. Jeong, J. Lee, W. Cui, R. M. Leahy, and S. Narayanan, Neural codecs as biosignal tokenizers, arXiv preprint arXiv:2510.09095, 2025. [42] Z. Chen, C. Qin, W. You, R. Liu, C. Chu, R. Yang, K. C. Tan, and J. Wu, HEAR: An EEG foundation model with heterogeneous electrode adaptive representation, arXiv preprint arXiv:2510.12515, 2025. [43] K. Barmpas, N. Lee, A. Koliousis, Y. Panagakis, D. A. Adamos, N. Laskaris, and S. Zafeiriou, NeuroRVQ: Multi-scale EEG tokenization for generative large brainwave models, arXiv preprint arXiv:2510.13068, 2025. [44] Y. El Ouahidi, J. Lys, P. Tholke, N. Farrugia, B. Pasdeloup, V. Gripon, K. Jerbi, and G. Lioi, REVE: foundation model for EEG-adapting to any setup with large-scale pretraining on 25,000 subjects, in The Thirty-ninth Annual Conf. on Neural Information Processing Systems, San Diego, CA, Dec. 2025. 23 ZR($ Z($ D X F $ H 1 * ( ( Q & R O K 6 $ ' 0 / H U I R & 5 ' 1 ( % 2 , % 0 U % / R U % & Fig. 11: Impact of EA on model performance on the BNCI2014001 dataset. [45] Q. Zhang, J. Zhong, Z. Li, X. Shen, and Q. Liu, Multi-dataset joint pretraining of emotional EEG enables generalizable affective computing, arXiv preprint arXiv:2510.22197, 2025. [46] B. Doner, T. M. Ingolfsson, L. Benini, and Y. Li, LUNA: Efﬁcient and topology-agnostic foundation model for EEG signal analysis, arXiv preprint arXiv:2510.22257, 2025. [47] W. Yang, W. Yan, W. Liu, Y. Ma, and Y. Li, THD-BAR: Topology hierarchical derived brain autoregressive modeling for EEG generic representations, in The Thirty-ninth Annual Conf. on Neural Information Processing Systems, San Diego, CA, Dec. 2025. [48] N. M. Foumani, S. Ghane, N. Nguyen, M. Salehi, G. I. Webb, and G. Mackellar, EEG-X: Device-agnostic and noise-robust foundation model for EEG, arXiv preprint arXiv:2511.08861, 2025. [49] J. Hong, G. Mackellar, and S. Ghane, SAMBA: Toward long-context EEG foundation model via spatial embedding and differential mamba, arXiv preprint arXiv:2511.18571, 2025. [50] J. Wang, S. Zhao, Y. Zhou, Y. Kang, S. Li, and G. Pan, DeeperBrain: neuro-grounded EEG foundation model towards universal BCI, arXiv preprint arXiv:2601.06134, 2026. [51] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K.-R. Muller, Optimizing spatial ﬁlters for robust EEG single-trial analysis, IEEE Signal Processing Magazine, vol. 25, no. 1, pp. 4156, 2007. [52] B. Rivet, A. Souloumiac, V. Attina, and G. Gibert, xDAWN algorithm to enhance evoked potentials: application to braincomputer interface, IEEE Trans. on Biomedical Engineering, vol. 56, no. 8, pp. 20352043, 2009. [53] M. Zuo, B. Yu, and L. Sui, Classiﬁcation of EEG evoked in 2d and 3d virtual reality: traditional machine learning versus deep learning, Biomedical Physics & Engineering Express, vol. 11, no. 1, p. 015005, 2024. [54] U. Lal, S. Mathavu Vasanthsena, and A. Hoblidar, Temporal feature extraction and machine learning for classiﬁcation of sleep stages using telemetry polysomnography, Brain Sciences, vol. 13, no. 8, p. 1201, 2023. [55] M. Nakanishi, Y. Wang, X. Chen, Y.-T. Wang, X. Gao, and T.-P. Jung, Enhancing detection of SSVEPs for high-speed brain speller using task-related component analysis, IEEE Trans. on Biomedical Engineering, vol. 65, no. 1, pp. 104112, 2017. [56] W. Wu, W. Sun, Q. J. Wu, Y. Yang, H. Zhang, W.-L. Zheng, and B.-L. Lu, Multimodal vigilance estimation using deep learning, IEEE Trans. on Cybernetics, vol. 52, no. 5, pp. 30973110, 2020. [57] V. J. Lawhern, A. J. Solon, N. R. Waytowich, S. M. Gordon, C. P. Hung, and B. J. Lance, EEGNet: compact convolutional neural network for EEG-based braincomputer interfaces, Journal of Neural Engineering, vol. 15, no. 5, p. 056013, 2018. [58] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, M. Glasstetter, K. Eggensperger, M. Tangermann, F. Hutter, W. Burgard, and T. Ball, Deep learning with convolutional neural networks for EEG decoding and visualization, Human Brain Mapping, vol. 38, no. 11, pp. 5391 5420, 2017. [59] Z. Miao, M. Zhao, X. Zhang, and D. Ming, LMDA-Net: lightweight multi-dimensional attention network for general EEG-based braincomputer interfaces and interpretability, NeuroImage, vol. 276, p. 120209, 2023. [60] W. Y. Peh, Y. Yao, and J. Dauwels, Transformer convolutional neural networks for automated artifact detection in scalp EEG, in 2022 44th Annual Intl Conf. of the IEEE Engineering in Medicine & Biology Society (EMBC). IEEE, 2022, pp. 35993602. [61] Y. Ding, Y. Li, H. Sun, R. Liu, C. Tong, C. Liu, X. Zhou, and C. Guan, EEG-Deformer: dense convolutional transformer for brain-computer interfaces, IEEE Journal of Biomedical and Health Informatics, vol. 65, pp. 104112, 2024. [62] Y. Song, Q. Zheng, B. Liu, and X. Gao, EEG conformer: Convolutional transformer for EEG decoding and visualization, IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 31, pp. 710719, 2022. [63] L. F. Nicolas-Alonso and J. Gomez-Gil, Brain computer interfaces, review, Sensors, vol. 12, no. 2, pp. 12111279, 2012. [64] U. K. Patel, A. Anwar, S. Saleem, P. Malik, B. Rasul, K. Patel, R. Yao, A. Seshadri, M. Yousufuddin, and K. Arumaithurai, Artiﬁcial intelligence as an emerging technology in the current care of neurological disorders, Journal of Neurology, vol. 268, no. 5, pp. 16231642, 2021. liberata Ullo, Comparative analysis to identify efﬁcient technique for interfacing BCI system, in IOP Conference Series: Materials Science and Engineering, IOP Publishing, 2020, p. 012062. vol. 925, no. 1. [65] M. K. Kumar, B. Parameshachari, S. Prabu, and S. [66] F. Dehais, A. Lafont, R. Roy, and S. Fairclough, neuroergonomics approach to mental workload, engagement and human performance, Frontiers in Neuroscience, vol. 14, p. 268, 2020. [67] T. Proix, J. Delgado Saa, A. Christen, S. Martin, B. N. Pasley, R. T. Knight, X. Tian, D. Poeppel, W. K. Doyle, O. Devinsky et al., Imagined speech can be decoded from low-and cross-frequency intracranial EEG features, Nature Communications, vol. 13, no. 1, p. 48, 2022. [68] D. Liu, S. Li, Z. Wang, W. Li, and D. Wu, SDDA: Spatial distillation based distribution alignment for cross-headset eeg classiﬁcation, IEEE Trans. on Biomedical Engineering, 2025. [69] H. Naveed, A. U. Khan, S. Qiu, M. Saqib, S. Anwar, M. Usman, N. Akhtar, N. Barnes, and A. Mian, comprehensive overview of large language models, ACM Trans. on Intelligent Systems and Technology, vol. 16, no. 5, pp. 172, 2025. [70] X. Liu, T. Zhou, C. Wang, Y. Wang, Y. Wang, Q. Cao, W. Du, Y. Yang, J. He, Y. Qiao et al., Toward the uniﬁcation of generative and discriminative visual foundation model: survey, The Visual Computer, vol. 41, no. 5, pp. 33713412, 2025. [71] Y. Yuxuan, W. Hongbo, C. Li, P. Yiheng, and J. Luo, Foundation models for EEG decoding: current progress and prospective research, Journal of Neural Engineering, 2025. [72] B. Burle, L. Spieser, C. Roger, L. Casini, T. Hasbroucq, and F. Vidal, Spatial and temporal resolutions of EEG: Is it really black and white? scalp current density view, International Journal of Psychophysiology, vol. 97, no. 3, pp. 210220, 2015. [73] J. Schneider, C. Meske, and P. Kuss, Foundation models: new paradigm for artiﬁcial intelligence, Business & Information Systems Engineering, vol. 66, no. 2, pp. 221231, 2024. [74] M. Awais, M. Naseer, S. Khan, R. M. Anwer, H. Cholakkal, M. Shah, M.-H. Yang, and F. S. Khan, Foundation models deﬁning new era in vision: survey and outlook, IEEE Trans. on Pattern Analysis and Machine Intelligence, 2025. [75] H. He and D. Wu, Transfer learning for brain-computer interfaces: Euclidean space data alignment approach, IEEE Trans. on Biomedical Engineering, vol. 67, no. 2, pp. 399410, 2020. [76] D. Liu, Z. Chen, and D. Wu, CLEAN-MI: scalable and efﬁcient imagery pipeline for constructing high-quality neurodata in motor paradigm, arXiv preprint arXiv:2506.11830, 2025. [77] J. Li, X. Gu, S. Qiu, X. Zhou, A. Cangelosi, C. K. Loo, and X. Liu, survey of wearable lower extremity neurorehabilitation exoskeleton: Sensing, gait dynamics, and humanrobot collaboration, IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 54, no. 6, pp. 36753693, 2024. [78] B. Hermann, D. W. Loring, and S. Wilson, Paradigm shifts in the neuropsychology of epilepsy, Journal of the International Neuropsychological Society, vol. 23, no. 9-10, pp. 791805, 2017. [79] I. Obeid and J. Picone, The temple university hospital EEG data corpus, Frontiers in Neuroscience, vol. 10, p. 196, 2016. [80] P. PhysioBank, Physionet: components of new research resource for complex physiologic signals, Circulation, vol. 101, no. 23, pp. e215 e220, 2000. [81] M. Tangermann, K.-R. Muller, A. Aertsen, N. Birbaumer, C. Braun, C. Brunner, R. Leeb, C. Mehring, K. J. Miller, G. R. Muller-Putz et al., Review of the BCI competition IV, Frontiers in Neuroscience, vol. 6, p. 55, 2012. [82] B. Kemp, A. Zwinderman, B. Tuk, H. Kamphuisen, and J. Oberye, Sleep-edf database expanded, Physionet Org, 2018. [83] D. Wu, Revisiting Euclidean alignment learning in EEG-based brain-computer interfaces, Journal of Neural Engineering, vol. 22, p. 031005, 2025. transfer for [84] D. Wu, B.-L. Lu, B. Hu, and Z. Zeng, Affective brain-computer interfaces (aBCIs): tutorial, Proc. of the IEEE, vol. 11, no. 10, pp. 13141332, 2023. [85] Z. Wang, S. Li, and D. Wu, Canine EEG helps human: Crossspecies and cross-modality epileptic seizure detection via multi-space alignment, National Science Review, vol. 12, no. 6, p. nwaf086, 2025. [86] Y. Li, J. Pan, J. Long, T. Yu, F. Wang, Z. Yu, and W. Wu, Multimodal BCIs: Target detection, multidimensional control, and awareness evaluation in patients with disorder of consciousness, Proc. IEEE, vol. 104, no. 2, pp. 332352, 2016. [87] Z. Jia, H. Wang, Y. Shen, F. Hu, J. An, K. Shu, and D. Wu, Magnetoencephalography (MEG) based non-invasive Chinese speech decoding, Journal of Neural Engineering, vol. 22, p. 066014, 2025. [88] Z. Wang, H. Wang, T. Jia, X. He, S. Li, and D. Wu, DBConformer: Dual-branch convolutional transformer for EEG decoding, IEEE Journal of Biomedical and Health Informatics, 2026, in press. [89] H. Cui, A. Liu, X. Zhang, X. Chen, J. Liu, and X. Chen, EEG-based subject-independent emotion recognition using gated recurrent unit and minimum class confusion, IEEE Trans. on Affective Computing, vol. 14, no. 4, pp. 27402750, 2023. [90] X. Chen, S. Li, and D. Wu, AFPM: Alignment-based frame patch modeling for cross-dataset EEG decoding, Science China Information Sciences, 2026, in press. APPENDIX PRE-TRAINING AND DOWNSTREAM DATASETS The pre-training and downstream datasets utilized by existing EEG foundation models are summarized in Tables VIII - IX. 24 TABLE VIII: Summary of the pre-trained and downstream datasets utilized in BCI foundation models. Pre-training"
        },
        {
            "title": "Mentality",
            "content": "Neuro-GPT"
        },
        {
            "title": "Clinic",
            "content": "PhysionetMI BCIC-IV-2A Margaux2012 Citi2010 Sleep-EDF"
        },
        {
            "title": "TUSZ\nPrivate",
            "content": "CHB-MIT IIIC Seizure TUAB TUEV HAR PTB-XL"
        },
        {
            "title": "MAYO\nFNUSA\nPrivate",
            "content": "TUAB TUEV MoBI SEED-V MI / ME MI / ME ERN / ERP ERN / ERP Sleep"
        },
        {
            "title": "Clinic\nClinic",
            "content": "Clinic Clinic Clinic Clinic MI / ME (ECG)"
        },
        {
            "title": "Clinic\nClinic\nClinic",
            "content": "Clinic Clinic MI / ME Emotion"
        },
        {
            "title": "Clinic",
            "content": "BCIC-IV-2A MI / ME Clinic Clinic Clinic Clinic Clinic MI / ME MI / ME MI / ME Emotion Emotion Emotion Emotion Emotion Resting Resting ERN / ERP ERN / ERP"
        },
        {
            "title": "Clinic",
            "content": "Siena TUAR TUEP TUSZ TUSL BCIC IV-1 Grasp and Lift PhysionetMI Emobrain SEED SEED-IV SEED-GER SEED-FRA RS-EEG SPIS InriaBCI TVNT RAW Private"
        },
        {
            "title": "TUEG",
            "content": "Siena TUEG Schizophrenia-81 Stroke-50 PD-31 AD-184 CAP HMC Sleep-EDF SRM Private IowaDataset UNMDataset"
        },
        {
            "title": "Emotion",
            "content": "SEED-IV"
        },
        {
            "title": "TUAB\nTUAR\nTUSL\nTUSZ\nNeonate",
            "content": "AD-65 CHB-MIT MDD-64 Depression-122 Schizophrenia-28 ADHD-Adult ADHD-Child SD-"
        },
        {
            "title": "Clinic",
            "content": "Clinic Clinic Clinic Clinic Clinic Clinic Sleep Sleep Sleep Resting 25 TABLE IX: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued). TABLE X: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued). Models CEReBrO LEAD FEMBA LCM TFM ALFEE BrainOmni Models Pre-training Downstream Datasets Paradigms Datasets Paradigms TUEG Siena BCIC IV-1 Grasp and Lift PhysionetMI SEED-FRA SEED-GER SEED-IV SEED-V Emobrain RS-EEG SPIS Inria BCI TVNT Private RAW CAP ISRUC HMC TUEG CHB-MIT MAYO FNUSA PhysionetMI SEED SEED-IV Sleep-EDFx PhysionetMI HGD SEED TSU M3CV Clinic Clinic MI / ME MI / ME MI / ME Emotion Emotion Emotion Emotion Emotion Resting Resting ERN / ERP ERN / ERP Sleep Sleep Sleep Clinic Clinic Clinic Clinic MI / ME Emotion Emotion Sleep MI / ME MI / ME Emotion SSVEP NeuroLM Brant-X FoME EEGPT FACED SEED SEED-FRA SEED-GER SEED-IV SEED-V THINGS-EEG-10Hz THINGS-EEG-5Hz IMG (Private) Emotion Emotion Emotion Emotion Emotion Emotion Visual Visual Cross-modal BrainGPT TUEG Clinic GEFM TUEG Clinic CBraMod TUAB TUEV TUSL SEED HMC EEGMat Clinic Clinic Clinic Emotion Sleep Workload FoG DREAMER Sleep-EDF-20 Sleep-EDF-78 Jaramillo2021 AFDB TUEV MAYO FNUSA SEED Sleep-EDFx TUAB TUEV BCIC-IV-2A BCIC-IV-2B Sleep-EDFx KaggleERN PhysioP300 MIBCI BCIC IV-1 DEAP FACED SEED-IV SEED-V Sleep-EDF HMC EEGMat STEW IMG (Private) SPE PhysionetMI PhysionetP300 Perrin2012 CHB-MIT TUEV TUAB PhysionetMI SHU-MI FACED SEED-V ISRUC Clinic Emotion Sleep Sleep Clinic (EEG+EOG) ECG Clinic Clinic Clinic Emotion Sleep Clinic Clinic MI / ME MI / ME Sleep ERN / ERP ERN / ERP MI / ME MI / ME Emotion Emotion Emotion Emotion Sleep Sleep Workload Workload Cross-modal Cross-modal MI / ME ERN / ERP ERN / ERP Clinic Clinic Clinic MI / ME MI / ME Emotion Emotion Sleep Pre-training Downstream Datasets TUAB Neonate MoBI SEED ADFTD CNBPM Cognision CAUEEG Paradigms Clinic Clinic MI / ME Emotion Clinic Clinic TUAB TUAR TUSL BCIC-IV-2A BCIC-IV-2B TUAB TUEV CHB-MIT IIIC Seizure EESM23 TUAB TUEV TUSL SEED HMC EEGMat Clinic Clinic Clinic MI / ME MI / ME Clinic Clinic Clinic Clinic Sleep Clinic Clinic Clinic Emotion Sleep Workload AD65 MDD PD31 TUAB TUEV WBCIC SHU PhysionetMI FACED Clinic Clinic Clinic Clinic Clinic MI / ME MI / ME Emotion SomatoMotor MI / ME (EMEG) Emotion (MEG) MEG-MMI ASD (MEG) ASD74 Datasets TUEG Paradigms Clinic BrainLat P-ADIC Depression FEPCR PD-RS TDBrain TUEP BACA-RS MCEF-RS PEARL-Neuro SRM-RS AD-Auditory TUEG PhysionetMI SEED TSU TUAB TUEV CHB-MIT IIIC Seizure TUEG Siena BCIC IV-1 Grasp and Lift PhysionetMI SEED-IV SEED-V SEED-GER SEED-FRA Emobrain RS-EEG SPIS InriaBCI TVNT RAW MusicEEG HFO Awakening Go-Nogo Features-EEG SRM PEARL-Neuro RestCog HBN-EEG MEG-MASC MEG-Narrative SMN4Lang ASWR-MEG Kymata-SOTO MIND THINGS-MEG ImageLine OMEGA CC700 AversiveMEG ASWR-MEG NeuroMorph Clinic Clinic Clinic Clinic Clinic Clinic Clinic Resting Resting Resting Resting ASSR Clinic MI / ME Emotion SSVEP Clinic Clinic Clinic Clinic Clinic Clinic MI / ME MI / ME MI / ME Emotion Emotion Emotion Emotion Emotion Resting Resting ERN / ERP ERN / ERP Emotion Sleep Sleep Visual Visual Resting Listening (MEG) Listening (MEG) Listening (MEG) Listening (MEG) Listening (MEG) Clinic (MEG) Visual (MEG) Visual (MEG) Resting (MEG) (MEG) (MEG) (MEG) (MEG) TABLE XI: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued). Pre-training Downstream 26 TABLE XII: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued). Datasets Paradigms Datasets Paradigms Models Pre-training Downstream TUEG Clinic TUEG Clinic NA NA TUEG Clinic Models E3GT CodeBrain UniMind CSBrain DMAE-EEG TUEG Siena Physionet B-SNIP1 RAW BNCI2014002 PhysionetMI Dreyer2023 Weibo2014 Zhou2016 Lee2019 Cho2017 SHHS MESA MrOS WSC SOF CFS NCHSDB TUEV Clinic Clinic Sleep Resting MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME Sleep Sleep Sleep Sleep Sleep Sleep Sleep Clinic Stieger2021 SEED HBN M3CV MI / ME Emotion EEGMamba MIRepNet PSGFM EEGDM CoMET PhysionetMI PhysioP300 Won2022 MI / ME ERN / ERP CHB-MIT TUEV TUAB SHU-MI FACED SEED-V ISRUC S1 ISRUC S1 BCIC2020-3 MentalArithmetic Clinic Clinic Clinic MI / ME Emotion Emotion Sleep Sleep Imagined Speech Mental Stress TUAB TUEV TUSL SHU-MI SEED SEED-IV HMC Sleep-EDF SHHS EEGMat CHB-MIT Siena TUEV TUAB TUSL BCIC-IV-2A PhysionetMI SHU-MI FACED SEED-V ISRUC HMC BCIC2020-3 SEED-VIG MentalArithmetic Mumtaz PhysionetMI MultiM11 CHB-MIT PhysionetMI FACED ISRUC BCIC20203 MODMA BCIC-IV-2A BNCI2015001 BCIC-IV-2B AlexMI Sleep-EDF Dreem HomePAP APPLES TUEV CHB-MIT TUAB TUEV BCIC-IV-2A BCIC-IV-2B Large-5F FACED THUBenchmark PhysionetP300 KaggleERN BCIC2020Clinic Clinic Clinic MI / ME Emotion Emotion Sleep Sleep Sleep Workload Clinic Clinic Clinic Clinic Clinic MI / ME MI / ME MI / ME Emotion Emotion Sleep Sleep Imagined Speech Vigilance Mental Stress Mental Disorder MI / ME MI / ME Clinic MI / ME Emotion Sleep Imagined Speech MDD Diagnosis MI / ME MI / ME MI / ME MI / ME Sleep Sleep Sleep Sleep Clinic Clinic Clinic Clinic MI / ME MI / ME MI / ME Emotion SSVEP ERN / ERP ERN / ERP Imagined Speech Datasets TUEP TUSL TUSZ Private-1 Lin2025 Lopez2015 Veloso2017 Cho2017 Kaya2017 Schalk2009 Xiang2024 Babayan2021 Gu2024 Mou2024 Xue2025 TUEP TUSZ TUSL Grasp and Lift PhysionetMI Lee2019 HGD Emobrain SEED SEED-IV SEED-GER SEED-FRA RS-EEG SPIS RAW Private CAUEEG TUEG Siena BCIC IV-1 Emobrain SEED-IV SEED-V SEED-GER SEED-FRA REEG-BACA RS-EEG RAW Stieger2021 SEED-FRA SEED-GER SEED-SD Chisco ThinkOutLoud EpilepsyFM SingLEM BrainPro Uni-NTFM ELASTIQ Paradigms Datasets Paradigms Clinic Clinic Clinic Clinic Clinic Clinic Clinic MI / ME MI / ME MI / ME Sleep Sleep SSVEP Cognitive RSVP Clinic Clinic Clinic MI / ME MI / ME MI / ME MI / ME Emotion Emotion Emotion Emotion Emotion Resting Resting Clinic Clinic Clinic MI / ME Emotion Emotion Emotion Emotion Emotion Resting Resting MI / ME Emotion Emotion Sleep & Emotion Imagined Speech TUAB TUEV CHB-MIT Private-1 Private-2 Private-3 Clinic Clinic Clinic Clinic Clinic Clinic Dreyer2023 WBCIC-MI-2C WBCIC-MI-3C N-back-2C DSR-2C WG-2C MI / ME MI / ME MI / ME Cognitive DSR Word Generation BCIC-IV-2A SHU-MI FACED SEED-V SEED-VII MI / ME MI / ME Emotion Emotion Emotion TUAB TUEV TUSL BCIC-IV-2A SEED HMC EEGMat ADFTD TDBrain Clinic Clinic Clinic MI / ME Emotion Sleep Workload NDD Mental Disorder OpenBMI BCIC-IV-2A BCIC-Upperlimb SHU-MI HighGamma Cho2017 Shin2017A PhysionetMI FACED SEED SEED-IV SEED-V SEED-VII OpenBMI eldBETA Wang2016 BETA EEGMat BCIC2020-3 ADHD-AliMotie MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME Emotion Emotion Emotion Emotion Emotion SSVEP SSVEP SSVEP SSVEP Workload Imagined Speech ADHD TABLE XIII: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued)."
        },
        {
            "title": "Models",
            "content": "Pre-training"
        },
        {
            "title": "TUEG",
            "content": "emg2qwerty"
        },
        {
            "title": "PhysionetMI",
            "content": "BCIC-IV-2A Sleep-EDF"
        },
        {
            "title": "Clinic",
            "content": "MI / ME MI / ME"
        },
        {
            "title": "KaggleERN",
            "content": "ERN / ERP N"
        },
        {
            "title": "TUAB",
            "content": "CHB-MIT"
        },
        {
            "title": "Clinic",
            "content": "BCI-IV-1 BCI-IV-2B"
        },
        {
            "title": "OpenBMI",
            "content": "MI / ME BCI-IV-2A"
        },
        {
            "title": "HMC",
            "content": "Sleep-EDFx"
        },
        {
            "title": "HGD",
            "content": "MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME MI / ME PhysionetP300 ERN / ERP"
        },
        {
            "title": "KaggleERN",
            "content": "ERN / ERP"
        },
        {
            "title": "Migrainedb",
            "content": ""
        },
        {
            "title": "HighGamma",
            "content": "MI / ME Sleep-EDF Pavlov2022 Schalk"
        },
        {
            "title": "Resting",
            "content": "BCIC IV-1 MI / ME"
        },
        {
            "title": "Grasp and Lift",
            "content": "MI / ME"
        },
        {
            "title": "PhysionetMI",
            "content": "MI / ME"
        },
        {
            "title": "SPIS",
            "content": "Trujillo"
        },
        {
            "title": "Inria BCI",
            "content": "ERN / ERP bi2015a ERN / ERP Trujillo"
        },
        {
            "title": "MOABB",
            "content": "MI / ME"
        },
        {
            "title": "PhysionetMI",
            "content": "MI / ME BCIC-IV-2A ERN / ERP"
        },
        {
            "title": "Clinic",
            "content": "MI / ME MI / ME"
        },
        {
            "title": "SEED",
            "content": "SEED-IV SEED-V SEED-VII"
        },
        {
            "title": "Clinic",
            "content": "BCIC2020-"
        },
        {
            "title": "SEED",
            "content": "SEED-IV SEED-V SEED-VII"
        },
        {
            "title": "Clinic",
            "content": "SEED-V"
        },
        {
            "title": "REVE",
            "content": "mdJPT"
        },
        {
            "title": "LUNA",
            "content": "27 TABLE XIV: Summary of the pre-trained and downstream datasets utilized in BCI foundation models (continued)."
        },
        {
            "title": "Models",
            "content": "Pre-training"
        },
        {
            "title": "Paradigms",
            "content": "THD-BAR EEG-X"
        },
        {
            "title": "Grasp and Lift",
            "content": "SEED-IV SEED-V SEED-GER SEED-FRA"
        },
        {
            "title": "EmoBrain",
            "content": "RS-EEG"
        },
        {
            "title": "Siena",
            "content": "PhysioNet 2018 ds006171 ds006547 ds006480 ds006525 ds"
        },
        {
            "title": "RAW",
            "content": "ds006367 ds006370 ds006437 ds006446 ds"
        },
        {
            "title": "Clinic",
            "content": "MI / ME MI / ME"
        },
        {
            "title": "Resting",
            "content": "ERN / ERP ERN / ERP"
        },
        {
            "title": "Attention",
            "content": ""
        },
        {
            "title": "Imagined Speech",
            "content": ""
        },
        {
            "title": "TUEV",
            "content": "BCIC IV-"
        },
        {
            "title": "DEAP",
            "content": "Sleep-EDF"
        },
        {
            "title": "Clinic",
            "content": "MI / ME"
        },
        {
            "title": "Workload",
            "content": "BCIC-IV-2A Kalunga"
        },
        {
            "title": "Crowdsourced",
            "content": "MI / ME"
        },
        {
            "title": "SSVEP",
            "content": ""
        },
        {
            "title": "GrosseWentrup",
            "content": "BCIC-IV-2A BCIC-III-II BCIC-II-IIb"
        },
        {
            "title": "DriverDistraction",
            "content": "CHB-MIT"
        },
        {
            "title": "PhysionetMI",
            "content": "BCIC-IV-2A SHU-MI"
        },
        {
            "title": "FACED",
            "content": "SEED-V SEED-VII"
        },
        {
            "title": "ISRUC",
            "content": "SEED-VIG"
        },
        {
            "title": "Clinic",
            "content": "MI / ME MI / ME MI / ME ERN / ERP ERN / ERP"
        },
        {
            "title": "Workload",
            "content": ""
        },
        {
            "title": "Clinic",
            "content": "MI / ME MI / ME MI / ME"
        },
        {
            "title": "Vigilance",
            "content": "BCIC2020-"
        },
        {
            "title": "APPENDIX B\nDATASET DESCRIPTIONS",
            "content": "The 13 datasets used in this benchmark are summarized below. 1) BNCI2014001 contains EEG data from 9 subjects performing four motor imagery tasks: left hand, right hand, both feet, and tongue. Each subject participated in two sessions, with each session consisting of 6 runs, yielding total of 288 trials per session. 2) BNCI2015001 contains EEG data from 12 subjects performing sustained motor imagery of the right hand 28 channels. 11) EEGMat is cognitive workload dataset collected from 36 subjects during mental arithmetic tasks. EEG was recorded using 19 channels at 500 Hz following the international 1020 system. Subjects were categorized into good and poor performers based on task accuracy, enabling analysis of individual differences in workloadrelated brain activity. 12) Things-EEG2 is large-scale dataset for visual object decoding, containing EEG recordings from 10 participants viewing natural object images. The dataset comprises 16,740 image presentations covering 1,854 object classes from the THINGS image collection, supporting research on neural representations of visual semantics. 13) SEED-VIG is dataset for EEG-based vigilance estimation collected during simulated driving. Vigilance levels are quantiﬁed using the PERCLOS (percentage of eye closure) metric derived from eye-tracking data. EEG was recorded at 200 Hz using 17 channels and segmented into 8-second epochs, supporting continuous vigilance prediction as regression task."
        },
        {
            "title": "APPENDIX C\nBENCHMARK RESULTS",
            "content": "The detailed benchmark results for each subject are presented in Tables XV - L. and both feet. The data were recorded at 512 Hz using 13 electrodes, with bandpass ﬁlter between 0.5 and 100 Hz and notch ﬁlter at 50 Hz. 3) BNCI2014004 contains EEG data from 9 right-handed subjects performing two motor imagery tasks: left hand and right hand. Each subject participated in ﬁve sessions, with the ﬁrst two sessions for screening without feedback and the remaining three sessions with feedback. The data were recorded using three bipolar EEG channels (C3, Cz, C4) at 250 Hz, with 120 trials per subject for each motor imagery class. 4) BNCI2014009 contains P300 evoked potentials from 10 healthy subjects performing 6 6 matrix speller task under overt attention conditions. EEG was recorded from 16 channels (Fz, FCz, Cz, CPz, Pz, Oz, F3, F4, C3, C4, CP3, CP4, P3, P4, PO7, PO8) at 256 Hz with 0.120 Hz bandpass ﬁltering. Each subject completed four sessions with three runs per session. 5) BNCI2014008 contains P300 evoked potentials from 8 subjects with amyotrophic lateral sclerosis (ALS) performing 6 6 matrix speller task. EEG was recorded from 8 channels (Fz, Cz, Pz, Oz, P3, P4, PO7, PO8) at 256 Hz with 0.130 Hz bandpass ﬁltering. Each subject completed seven runs of ﬁve-character spelling, yielding 35 trials in total. 6) CHB-MIT contains EEG recordings from 23 pediatric subjects with intractable seizures, recorded using 16is channel bipolar montage at 256 Hz. The dataset used for seizure detection, binary classiﬁcation task to identify the presence of epileptic seizures from EEG signals. 7) TUAB (Temple University Hospital Abnormal) is large-scale clinical EEG dataset from the TUH EEG Corpus, containing recordings from 2,383 adult patients with over 1,000 hours of data in total. The dataset is used for abnormal EEG detection, binary classiﬁcation task to distinguish pathological brain activity from normal recordings. 8) Sleep-EDFx (Sleep-EDF Expanded) is polysomnographic dataset containing 197 whole-night recordings from 78 healthy subjects. Each recording includes EEG signals from FpzCz and PzOz derivations, annotated into ﬁve sleep stages: Wake, N1, N2, N3, and REM. The dataset serves as standard benchmark for automatic sleep stage classiﬁcation. 9) SEED (SJTU Emotion EEG Dataset) is benchmark dataset for EEG-based emotion recognition, containing recordings from 15 subjects who watched 15 ﬁlm clips across three sessions spaced one week apart. The 62channel EEG was recorded at 1,000 Hz using an ESI NeuroScan system, with each clip labeled as positive, neutral, or negative. 10) Nakanishi2015 is an SSVEP benchmark dataset for multi-class target identiﬁcation. It contains EEG recordings from 9 subjects responding to 12 visual stimuli with frequencies ranging from 9.25 to 14.75 Hz. Each subject completed 15 blocks of 12 trials, yielding 180 trials per subject. EEG was recorded at 256 Hz using 8 occipital TABLE XV: Accuracies (%) on BNCI2014001. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject (LOSO)"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base 45.83 61.23 68.17 66.55 56.83 56.48 60.88 47.92 37.15 51.97 59.72 39.81 54.51 32.87 43.17 42.82 54.75 72.11 34.26 31.94 31.37 34.95 47.92 54.63 46.30 49.31 32.87 45.37 43.17 39.35 73.26 37.04 38.31 78.43 62.42 61.11 62.25 60.78 51.47 63.24 36.76 61.93 43.46 52.12 46.08 56.37 38.73 45.10 47.22 45.42 72.28 33.82 46. 31.86 56.21 39.54 55.23 46.08 28.59 26.47 47.06 44.28 35.95 35.95 32.35 48.37 27.43 26.85 31.13 32.64 31.48 24.54 26.27 43.98 31.60 37.04 32.18 26.50 46.99 30.79 35.3 32.52 38.19 39.58 26.39 26.16 26.16 32.41 33.22 38.43 30.79 31.37 27.66 32.29 32.29 30.56 25.93 33.45 25.46 54.90 33.66 47.22 43.63 46.24 36.93 50.98 38.89 43.79 32.03 29.08 28.27 46.57 29.74 36.76 33.99 33.82 53.96 26.14 25. 30.72 41.34 29.25 41.01 26.80 28.10 26.80 33.66 35.13 29.08 29.08 30.23 26.63 52.78 69.56 52.89 66.09 50.93 60.53 57.29 56.60 39.35 59.03 62.62 34.14 63.19 33.91 49.88 49.42 64.12 78.36 30.21 36.69 35.76 30.67 49.42 62.85 38.77 55.67 33.22 48.84 46.64 40.97 75.12 34.72 39.00 76.96 66.34 65.69 65.52 68.46 57.84 77.12 48.69 56.54 37.75 53.59 33.66 69.61 35.13 43.46 39.87 44.12 82.67 28.43 39. 33.66 53.43 39.38 60.29 35.29 27.29 31.70 44.44 40.85 42.32 42.32 30.07 45.10 30.21 35.07 37.62 35.65 32.29 34.26 31.48 40.74 33.45 36.57 34.49 28.47 47.92 32.41 32.99 32.18 37.15 46.88 30.90 28.01 31.48 29.40 37.62 47.45 34.38 34.61 28.70 31.25 32.52 30.32 39.70 34.72 27.66 46.57 37.42 45.92 41.01 34.64 32.35 44.61 38.40 30.07 30.07 36.27 31.05 38.40 28.92 39.05 35.95 37.09 50.00 27.29 24. 33.33 37.25 28.76 42.81 32.68 29.74 27.94 34.48 35.62 31.05 31.05 25.00 27.61 30.21 25.12 27.43 27.78 26.04 26.62 26.85 59.26 33.10 43.17 31.71 27.66 43.29 28.01 38.08 37.85 29.86 37.73 33.56 25.00 33.22 25.00 40.86 32.87 31.83 29.28 26.85 34.61 36.00 28.12 36.34 35.76 25.00 34.80 29.90 31.05 28.59 31.37 23.04 32.52 55.88 36.76 34.15 28.92 26.96 39.38 21.73 31.54 30.07 31.86 47.19 26.14 26. 30.07 41.01 36.44 36.11 28.27 26.80 22.88 34.31 28.92 28.92 28.92 31.21 23.86 23.61 28.47 27.78 31.02 28.24 29.28 30.56 46.18 29.17 40.28 37.27 30.90 44.91 27.08 37.38 38.19 38.54 40.74 30.21 28.59 27.20 31.48 39.35 33.33 34.49 29.17 24.65 36.11 36.11 35.42 33.10 33.10 25.12 42.16 31.05 37.75 34.48 37.42 26.96 44.93 42.65 34.31 30.39 35.29 32.84 30.07 29.25 29.08 28.59 32.35 43.23 30.07 25. 26.31 38.56 29.58 41.18 29.25 26.47 26.14 30.72 29.74 30.56 30.56 27.29 26.31 36.81 32.18 31.25 29.51 27.20 31.02 23.84 64.00 29.63 50.81 39.81 30.79 54.75 29.86 41.78 42.82 42.59 51.39 30.79 25.00 37.96 23.50 41.67 39.81 36.11 32.75 25.93 39.00 38.66 36.57 59.49 35.30 27.43 77.45 56.21 52.45 49.67 62.25 34.80 65.52 46.57 59.97 35.13 36.27 31.37 56.54 35.13 37.42 37.75 29.74 80.20 32.03 31. 34.48 52.94 35.46 46.08 33.99 25.65 24.18 43.30 40.20 29.25 29.25 32.19 37.91 57.29 60.88 65.74 67.36 51.04 55.90 63.77 51.50 43.06 50.58 65.62 34.49 60.19 37.50 48.15 47.11 50.35 70.72 29.75 28.36 33.22 39.81 45.25 64.12 42.48 56.60 26.97 45.25 45.60 30.32 64.70 31.25 28.36 75.49 68.46 68.30 71.08 69.28 60.95 77.45 45.75 59.31 43.95 59.31 41.01 61.93 39.54 43.14 41.67 45.92 79.70 27.12 33. 27.61 60.46 37.75 71.24 44.93 28.10 29.90 48.69 47.88 37.58 37.58 28.76 38.07 39.58 65.39 61.23 64.58 48.26 55.09 53.82 49.77 31.94 52.89 59.26 37.38 61.57 35.76 47.45 45.49 55.90 50.35 29.05 29.98 33.22 30.67 48.03 60.65 41.20 54.28 28.24 45.25 45.72 37.27 46.64 25.46 26.50 58.82 66.50 66.34 63.89 50.98 55.56 58.33 50.49 54.74 47.22 48.69 43.63 54.25 41.50 45.42 43.30 41.99 60.23 29.41 34. 34.80 50.33 42.32 54.41 45.42 27.78 33.99 48.86 45.75 39.87 39.87 31.70 38.73 38.19 44.970.57 44.800.50 46.800.31 39.150.56 41.530.67 41.641.23 51.110.25 34.270.93 46.931.43 46.970.71 32.241.45 53.030.22 32.020.66 41.580.80 40.930.83 45.720.54 54.210.24 30.570.10 28.860.50 32.180.41 30.881.00 42.590.27 48.241.04 37.371.25 41.450.50 28.340.30 39.780.36 39.630.58 34.320.20 50.480.28 33.420.22 29.210.57 60.62 50.221.14 52.870.88 51.130.76 51.271.10 42.210.73 57.191.32 44.901.31 48.600.72 37.130.92 42.180.23 34.990.25 50.341.18 33.300.46 39.000.19 37.600.27 38.040.45 63.270.47 28.940.73 31.941. 31.430.85 47.950.53 35.380.45 49.821.55 35.860.54 27.610.55 27.781.05 40.610.31 38.710.36 33.840.40 33.840.40 29.870.18 34.730.05 TABLE XVI: Cohens Kappa (%) on BNCI2014001. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject (LOSO)"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base 27.78 48.30 57.56 55.40 42.44 41.98 47.84 30.56 16.21 35.96 46.30 19.75 39.35 10.49 24.23 23.77 39.66 62.81 12.35 9.26 8.49 13.27 30.56 39.51 28.40 32.41 10.49 27.16 24.23 19.14 64.35 16.05 17.75 71.24 49.89 48.15 49.67 47.71 35.29 50.98 15.68 49.24 24.62 36.16 28.10 41.83 18.30 26.80 29.63 27.23 63.02 11.76 29. 9.15 41.61 19.39 40.31 28.10 4.79 1.96 29.41 25.71 14.60 60.11 9.80 31.15 3.24 2.47 8.18 10.19 8.64 0.15 1.85 25.31 8.80 16.05 9.57 2.47 29.32 7.72 13.74 10.03 17.59 20.37 1.85 1.54 1.85 9.88 10.96 17.90 7.72 8.49 3.55 9.72 9.72 7.41 1.23 11.27 0.62 39.87 11.55 29.63 24.84 28.32 15.90 34.64 18.52 25.06 9.37 5.45 4.36 28.76 6.32 15.69 11.98 11.76 38.62 1.53 0. 7.63 21.79 5.66 21.35 2.40 4.14 2.40 11.55 13.51 5.45 29.52 6.97 2.18 37.04 59.41 37.19 54.78 34.57 47.38 43.06 42.13 19.14 45.37 50.15 12.19 50.93 11.88 33.18 32.56 52.16 71.30 6.94 15.59 14.35 7.56 32.56 50.46 18.36 40.90 10.96 31.79 28.86 21.30 66.82 12.96 18.67 69.28 55.12 54.25 54.03 57.95 43.79 69.50 31.59 42.05 16.99 38.13 11.55 59.48 13.51 24.62 19.83 25.49 76.89 4.58 19. 11.55 37.91 19.17 47.06 13.73 3.05 8.93 25.93 21.13 23.09 62.45 6.75 26.80 6.94 13.42 16.82 14.20 9.72 12.34 8.64 20.99 11.26 15.43 12.66 4.63 30.55 9.88 10.65 9.57 16.20 28.40 7.87 4.01 8.64 5.86 16.82 29.94 12.50 12.81 4.94 8.33 10.03 7.10 19.60 12.96 3.55 28.76 16.56 27.89 21.35 12.85 9.80 26.14 17.86 6.75 6.75 15.03 8.06 17.87 5.23 18.74 14.60 16.12 33.61 3.05 -1. 11.11 16.34 5.01 23.75 10.24 6.32 3.92 12.64 14.16 8.06 14.06 0.00 3.49 S4 6.94 0.92 3.24 3.70 1.39 2.16 2.47 45.68 10.80 24.23 8.95 3.55 24.38 4.01 17.44 17.13 6.48 17.75 11.42 0.00 10.96 0.00 21.14 10.49 9.10 5.71 2.47 12.81 14.66 4.17 15.12 14.35 0.00 13.07 6.54 8.06 4.79 8.50 0.00 10. 41.17 15.69 12.20 5.23 2.83 19.17 -4.36 8.71 6.75 9.15 29.79 1.53 2.61 6.75 21.35 15.25 14.81 4.36 2.40 -2.83 12.42 5.23 5.23 17.48 8.28 -1.53 S5 -1.85 4.63 3.70 8.02 4.32 5.71 7.41 28.24 5.56 20.37 16.36 7.87 26.54 2.78 16.51 17.59 18.06 21.76 6.94 4.78 3.70 8.64 19.14 11.11 12.65 5.56 -0.46 14.81 14.81 13.89 10.80 10.80 0. 22.88 8.06 16.99 12.63 16.56 2.62 26.58 23.53 12.42 7.19 13.73 10.46 6.75 5.66 5.45 4.79 9.80 24.40 6.75 0.00 1.74 18.08 6.10 21.57 5.66 1.96 1.53 7.63 6.32 7.41 14.22 3.05 1.74 S6 S7 Avg. 15.74 9.57 8.33 6.02 2.93 8.02 0.46 52.00 6.17 34.42 19.75 7.71 39.66 6.48 22.38 23.77 23.46 30.25 7.72 0.00 17.28 -2.01 22.22 19.75 14.81 10.34 1.23 18.67 18.21 15.43 45.99 13.73 3.24 69.93 41.61 36.60 32.90 49.67 13.07 54.03 28.76 46.62 13.51 15.03 8.49 42.05 13.51 16.56 16.99 6.32 73.61 9.37 8. 12.64 37.25 13.94 28.10 11.98 0.87 -1.09 24.40 20.26 5.66 45.71 9.59 17.21 43.06 47.84 54.32 56.48 34.72 41.20 51.70 35.34 24.08 34.11 54.17 12.65 46.91 16.67 30.86 29.48 33.80 59.72 6.33 4.48 10.96 19.75 27.01 52.16 23.30 42.13 2.62 27.01 27.47 7.10 52.93 8.33 4.48 67.32 57.95 57.73 61.44 59.04 47.93 69.93 27.67 45.75 25.27 45.75 21.35 49.24 19.39 24.18 22.22 27.89 72.94 2.83 10. 3.49 47.28 16.99 61.66 26.58 4.14 6.54 31.59 30.50 16.78 46.64 5.01 17.43 19.44 53.86 48.30 52.78 31.02 40.12 38.43 33.02 9.26 37.19 45.68 16.51 48.77 14.35 29.94 27.31 41.20 33.95 5.40 6.64 10.96 7.56 30.71 47.53 21.60 39.04 4.32 27.01 27.62 16.36 28.86 0.62 2.01 45.10 55.34 55.12 51.85 34.64 40.74 44.45 33.99 39.65 29.63 31.59 24.84 39.00 22.00 27.23 24.40 22.66 47.15 5.88 13. 13.07 33.77 23.09 39.22 27.23 3.70 11.98 31.81 27.67 19.83 37.55 8.93 18.30 17.59 26.630.75 26.400.67 29.060.40 18.860.74 22.030.89 22.191.64 34.810.34 12.361.23 29.241.91 29.290.94 9.651.93 37.380.30 9.360.87 22.101.07 21.241.10 27.620.72 38.480.45 7.420.13 5.140.66 9.570.54 7.841.34 23.460.37 30.981.39 16.501.66 21.930.66 4.460.40 19.700.48 19.510.77 12.430.27 33.970.37 11.230.30 5.610.76 47.49 33.621.51 37.161.17 34.831.01 35.031.47 22.950.97 42.921.75 26.531.76 31.470.95 16.171.22 22.900.30 13.310.34 33.791.58 11.060.61 18.670.26 16.800.36 17.380.59 51.110.55 5.250.98 9.251. 8.571.13 30.600.71 13.850.60 33.092.07 14.480.72 3.490.73 3.701.39 20.820.42 18.280.48 11.790.54 36.422.25 6.490.24 12.980.07 TABLE XVII: Accuracies (%) on BNCI2014004. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base 77.50 73.33 72.71 75.42 66.04 68.12 73.54 68.75 68.75 80.21 73.12 62.92 73.33 54.17 68.75 63.75 66.46 77.50 64.79 58.54 55.62 63.96 66.25 68.12 65.21 62.91 53.75 66.46 65.21 59.17 78.75 58.75 47.08 83.93 73.81 74.11 81.25 71.13 63.39 88.69 65.18 69.35 61.61 66.07 58.63 66.37 54.17 55.36 50.30 56.55 84.52 57.44 51. 52.68 68.15 56.85 70.24 59.23 56.55 52.38 56.85 52.98 50.60 73.21 58.33 50.60 54.17 59.72 60.56 54.17 53.06 56.67 51.11 68.06 57.78 64.17 66.39 66.11 64.44 51.11 58.89 61.39 70.56 66.94 60.56 53.61 55.00 51.94 47.78 65.56 65.00 53.89 46.67 55.28 60.00 61.39 62.50 53.61 51.94 58.33 53.57 56.35 52.78 57.54 48.81 55.16 56.35 49.21 48.41 57.94 55.95 50.40 51.98 56.35 54.76 56.75 57.54 52.38 51. 51.59 50.79 49.21 65.48 61.11 52.78 55.16 58.33 55.16 57.94 58.33 46.43 50.79 53.75 55.42 55.83 52.71 51.04 57.50 54.17 71.04 51.46 58.54 59.38 61.88 54.17 60.83 62.50 58.54 70.21 60.21 56.46 52.50 58.96 49.38 52.71 58.75 65.62 49.38 56.46 57.50 59.58 55.62 64.17 59.17 49.38 51.79 52.08 44.35 45.54 52.68 47.92 54.76 79.76 51.49 58.04 61.61 55.36 54.17 55.36 49.40 47.02 59.82 60.42 52.38 51. 51.79 52.08 56.25 65.18 58.93 53.27 53.57 54.46 46.43 51.79 63.99 56.55 51.79 91.25 94.58 91.46 96.46 97.08 97.50 97.50 68.75 91.25 91.88 87.92 72.71 92.71 63.33 63.75 65.62 64.58 96.04 69.79 66.25 56.25 80.00 83.54 79.79 74.58 96.66 49.79 58.12 59.38 55.42 95.62 64.38 48.33 100.00 98.21 98.51 98.51 97.92 97.92 97.62 53.87 90.48 96.43 78.57 57.14 98.21 53.87 65.48 60.71 62.50 98.81 61.31 50. 50.00 83.63 77.08 75.00 68.45 89.88 49.70 52.08 61.01 57.74 96.43 54.46 49.70 85.62 82.92 77.50 81.67 78.12 80.62 87.92 96.67 73.75 88.54 95.42 90.00 91.25 72.71 92.29 90.21 95.00 85.62 76.88 52.08 71.25 63.12 71.04 96.46 89.17 66.87 51.04 89.38 90.42 76.25 84.17 72.50 53.96 87.50 84.23 78.57 78.57 87.20 84.52 89.29 100.0 88.10 97.02 98.81 83.04 98.81 92.56 92.86 92.86 92.26 88.99 53.87 75. 68.75 82.74 65.48 97.32 88.39 95.54 62.20 80.36 79.46 83.33 85.42 57.74 73.21 83.12 83.96 70.83 82.08 76.88 82.71 76.25 68.96 64.38 77.08 68.75 64.17 81.25 58.12 63.12 62.08 68.12 79.79 73.33 50.21 57.71 65.62 60.21 65.21 63.12 81.05 51.46 56.67 59.17 63.54 83.96 59.38 53.12 88.39 77.68 78.87 75.60 76.49 71.73 81.85 83.63 63.69 50.30 76.49 61.01 82.14 45.54 63.10 63.39 65.77 82.44 55.06 49. 53.27 61.61 47.92 84.23 65.18 65.18 42.86 59.23 61.01 60.12 70.83 54.76 44.94 63.12 73.54 74.38 73.12 68.12 70.42 72.29 87.71 72.71 78.12 85.00 83.12 76.25 63.12 81.25 79.58 83.54 69.79 72.29 55.21 69.38 52.71 62.71 81.67 79.17 64.58 52.92 80.00 80.42 67.71 72.08 74.79 50.00 67.86 70.83 64.58 67.56 65.77 70.83 75.89 91.67 59.82 74.11 79.46 63.69 78.27 55.36 65.18 77.38 74.70 81.25 61.90 52. 61.90 52.08 59.82 81.55 61.61 56.85 51.49 61.31 66.96 58.63 67.26 65.77 51.49 68.75 76.67 77.92 73.96 70.83 75.42 74.17 74.79 72.50 77.29 80.42 77.50 72.08 62.71 76.04 76.88 80.21 85.00 70.00 50.42 67.92 61.88 70.00 85.21 79.58 69.79 46.88 69.17 68.54 63.54 83.96 77.29 58.54 87.50 84.23 82.74 84.52 84.82 86.01 88.69 63.69 73.81 83.93 86.01 62.20 82.74 62.80 66.96 59.52 69.64 86.90 63.10 68. 58.04 77.68 73.51 81.25 67.56 83.93 51.19 65.77 59.52 66.96 88.39 59.52 70.24 81.88 87.29 86.88 84.38 79.58 84.79 80.62 55.42 79.38 76.88 82.92 63.96 73.54 55.00 64.58 65.62 61.04 84.79 61.67 66.67 52.08 63.54 71.25 79.38 67.29 78.33 49.79 61.88 64.58 54.79 89.38 53.33 47.50 87.50 85.12 92.56 91.67 88.39 86.01 89.58 51.19 69.94 58.04 72.32 61.61 85.42 58.63 55.06 50.60 47.62 88.99 53.27 56. 49.40 75.60 52.38 69.94 62.50 79.46 43.15 49.70 49.40 44.05 87.50 55.06 57.74 73.24 76.380.59 74.230.39 74.880.67 71.200.42 74.860.82 74.170.49 73.350.06 70.221.32 76.971.08 77.700.70 71.370.16 75.450.35 60.123.00 70.130.89 69.300.89 73.300.57 78.410.52 67.310.18 56.173.14 60.461.06 61.352.11 65.050.23 75.571.26 72.082.07 69.270.55 50.971.13 66.050.53 67.480.25 61.940.31 79.400.06 63.690.36 51.100.65 79.20 75.533.67 74.520.71 75.111.63 75.770.38 73.022.13 80.170.25 71.701.46 68.430.42 69.761.23 75.251.58 62.070.74 77.390.35 58.922.41 63.300.98 61.840.76 65.071.86 81.101.37 56.751.66 56.500. 55.272.40 67.151.64 59.831.22 76.691.35 65.882.18 70.380.90 51.301.08 59.790.60 59.100.30 59.020.34 76.821.41 56.511.27 55.610.89 TABLE XVIII: Cohens Kappa (%) on BNCI2014004. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba MIRepNet SingLEM LUNA-Base 55.00 46.67 45.42 50.83 32.08 36.25 47.08 37.50 37.50 60.42 46.25 25.83 46.67 8.33 37.50 27.50 32.92 55.00 29.58 17.08 11.25 27.92 32.50 36.25 30.42 25.83 7.50 32.92 30.42 18.33 57.50 14.88 -5.83 67.86 47.62 48.21 62.50 42.26 26.79 77.38 30.36 38.69 23.21 32.14 17.26 32.74 8.33 10.71 0.60 13.10 69.23 17.50 3. 5.36 36.31 13.69 40.48 18.45 13.10 4.76 13.69 5.95 1.19 47.17 16.67 1.19 8.33 19.44 21.11 8.33 6.11 13.33 2.22 36.11 15.56 28.33 32.78 32.22 28.89 2.22 17.78 22.78 41.11 33.89 21.11 7.22 10.00 3.89 -4.44 31.11 30.00 7.78 -6.67 10.56 20.00 22.78 25.00 4.76 3.89 16.67 7.14 12.70 7.14 15.08 0.00 10.31 12.70 0.00 2.38 15.87 11.90 3.97 3.97 12.70 9.52 13.49 17.84 7.22 3. 3.17 1.59 -1.59 30.95 22.22 5.56 10.32 16.67 10.32 15.87 18.15 -7.14 1.59 7.50 10.83 11.67 5.42 2.08 15.00 8.33 42.08 3.33 17.08 18.75 23.75 8.33 21.67 25.00 17.08 40.42 20.42 12.92 5.00 17.92 -1.25 5.42 17.50 31.25 -1.25 12.92 15.00 19.17 11.25 28.33 4.76 -1.25 3.57 4.17 0.00 0.60 5.36 0.00 9.53 59.52 4.76 16.07 23.22 10.71 8.34 10.71 1.19 -5.95 19.64 20.47 18.33 3. 3.57 4.17 12.50 30.36 17.86 6.55 7.14 8.93 -7.14 3.57 27.99 13.10 3.57 82.50 89.17 82.92 92.92 94.17 95.00 95.00 37.50 82.50 83.75 75.83 45.42 85.42 26.67 27.50 31.25 29.17 92.08 39.58 32.50 12.50 60.00 67.08 59.58 49.17 93.33 -0.42 16.25 18.75 10.83 91.25 22.62 -3.33 100.00 96.43 97.02 97.02 95.83 95.83 95.24 8.93 80.95 92.86 57.14 14.29 96.43 7.74 30.95 21.43 25.00 97.62 28.75 0. 0.00 67.26 54.17 50.00 36.90 79.76 -0.60 4.17 22.02 15.48 92.85 8.93 -0.60 71.25 65.83 55.00 63.33 56.25 61.25 75.83 93.33 47.50 77.08 90.83 80.00 82.50 45.42 84.58 80.42 90.00 71.25 53.75 4.17 42.50 26.25 42.08 92.92 78.33 33.75 2.08 78.75 80.83 52.50 68.33 7.74 7.92 75.00 68.45 57.14 57.14 74.41 69.05 78.57 100.00 76.19 94.05 97.62 66.07 97.62 85.12 85.71 85.71 84.52 77.96 45.00 50. 37.50 65.48 30.95 94.64 76.79 91.07 24.40 60.71 58.93 66.67 71.02 15.48 46.43 66.25 67.92 41.67 64.17 53.75 65.42 52.50 37.92 28.75 54.17 37.50 28.33 62.50 16.25 26.25 24.17 36.25 59.58 46.67 0.42 15.42 31.25 20.42 30.42 26.25 62.08 2.92 13.33 18.33 27.08 67.92 10.12 6.25 76.79 55.36 57.74 51.19 52.97 43.45 63.69 67.26 27.38 3.57 52.97 22.03 64.28 -8.93 26.19 26.79 31.55 65.07 18.75 -0. 6.55 23.21 -4.17 68.45 30.36 30.36 -14.29 18.45 22.02 20.24 43.23 9.52 -10.12 26.25 47.08 48.75 46.25 36.25 40.83 44.58 75.42 45.42 56.25 70.00 66.25 52.50 26.25 62.50 59.17 67.08 39.58 44.58 10.42 38.75 5.42 25.42 63.33 58.33 29.17 5.83 60.00 60.83 35.42 44.17 23.81 0.00 35.71 41.67 29.16 35.12 31.55 41.66 51.78 83.33 19.64 48.21 58.93 27.38 56.55 10.71 30.36 54.76 49.40 62.66 49.58 4. 23.81 4.17 19.64 63.10 23.21 13.69 2.98 22.62 33.93 17.26 35.41 31.55 2.98 37.50 53.33 55.83 47.92 41.67 50.83 48.33 49.58 45.00 54.58 60.83 55.00 44.17 25.42 52.08 53.75 60.42 70.00 40.00 0.83 35.83 23.75 40.00 70.42 59.17 39.58 -6.25 38.33 37.08 27.08 67.92 26.19 17.08 75.00 68.45 65.48 69.05 69.65 72.02 77.38 27.38 47.62 67.86 72.02 24.41 65.48 25.60 33.93 19.05 39.29 73.89 54.58 37. 16.07 55.36 47.02 62.50 35.12 67.86 2.38 31.55 19.05 33.93 76.75 19.05 40.48 63.75 74.58 73.75 68.75 59.17 69.58 61.25 10.83 58.75 53.75 65.83 27.92 47.08 10.00 29.17 31.25 22.08 69.58 23.33 33.33 4.17 27.08 42.50 58.75 34.58 56.67 -0.42 23.75 29.17 9.58 78.75 6.55 -5.00 75.00 70.24 85.12 83.33 76.78 72.02 79.17 2.98 39.88 16.07 44.64 23.21 70.83 17.26 11.31 1.19 -4.76 78.01 6.67 13. -1.19 51.19 4.76 39.88 25.00 58.93 -13.69 -0.60 -1.19 -11.90 75.06 10.12 15.48 46.48 52.761.17 48.460.78 49.771.34 42.390.84 49.721.64 48.350.97 46.700.12 40.432.63 53.942.16 55.401.40 42.750.32 50.890.70 20.256.00 40.261.78 38.601.79 46.601.13 56.821.04 34.610.36 12.336.28 20.932.12 22.704.23 30.110.46 51.142.52 44.174.14 38.551.11 1.942.27 32.101.06 34.950.51 23.870.62 58.800.12 13.493.33 2.191.30 58.40 51.067.35 49.031.42 50.223.27 51.550.76 46.034.26 60.340.50 43.412.92 36.860.84 39.532.45 50.513.15 24.141.49 54.780.70 17.844.81 26.611.97 23.681.52 30.143.73 62.532.66 27.380.72 13.011. 10.544.79 34.303.28 19.662.43 53.372.71 31.774.35 40.761.80 2.602.16 19.581.20 18.210.59 18.030.69 54.182.61 13.032.53 11.221.77 TABLE XIX: Accuracies (%) on BNCI2015001. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 S10 Avg."
        },
        {
            "title": "Specialist\nModels",
            "content": "CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 58.00 91.50 94.33 65.67 53.00 82.67 52.83 Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 63.83 83.33 66.83 74.00 67.67 54.83 63.83 BrainOmni-Tiny 63.00 BrainOmni-Base 67.17 58.17 70.50 51.17 57.17 EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 53.83 88.17 68.67 81.00 80.00 58.00 55.50 BrainOmni-Tiny 61.67 BrainOmni-Base 61.17 51.50 98.83 46.83 50.00 EEGMamba MIRepNet SingLEM LUNA-Base"
        },
        {
            "title": "Specialist\nModels",
            "content": "CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 97.14 50.00 70.71 50.00 62.62 50.00 75.48 Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot)"
        },
        {
            "title": "Foundation\nModels",
            "content": "BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 61.67 80.71 84.29 67.62 72.38 95.95 71.67 BrainOmni-Tiny 75.00 BrainOmni-Base 68.10 83.57 95.48 54.29 77.14 EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 52.38 74.05 77.62 50.24 78.81 91.67 69.52 BrainOmni-Tiny 75.24 BrainOmni-Base 69.29 66.67 96.19 56.90 69.76 EEGMamba MIRepNet SingLEM LUNA-Base 55.50 96.50 82.00 89.50 87.33 78.17 64.83 63.50 85.50 75.00 71.83 72.67 78.17 64.33 68.17 61.17 81.50 95.33 52.33 65.33 53.67 86.83 66.33 74.67 77.50 84.67 66.67 66.83 64.33 60.67 95.33 49.83 79.67 94.29 95.71 94.05 97.38 93.10 94.05 97.38 61.67 93.57 81.19 88.57 78.81 90.71 75.71 75.95 79.29 75.71 95.24 53.81 90.00 50.00 95.00 71.91 91.67 79.52 57.86 59.05 72.86 77.14 60.00 89.76 56.19 86. 51.50 72.00 62.67 56.00 62.67 68.17 52.00 68.33 76.50 64.17 56.33 63.83 62.67 60.33 65.50 65.33 59.50 61.17 56.67 58.50 57.33 66.83 64.17 66.67 68.83 65.67 57.17 62.00 63.17 61.00 77.00 55.50 52.83 89.29 91.67 83.81 87.38 87.62 91.67 92.62 54.29 89.29 63.10 67.38 58.10 75.24 56.67 65.00 64.29 60.71 91.67 50.00 60.95 54.76 88.81 63.57 89.52 69.29 57.86 52.14 67.62 61.90 58.33 93.10 48.33 56. 82.00 72.00 70.17 73.67 69.67 67.50 67.50 64.50 78.67 70.33 74.33 69.33 69.50 59.67 66.50 66.17 75.67 83.33 51.17 59.50 55.00 81.33 66.83 64.83 73.67 63.17 60.33 70.50 66.00 59.33 83.83 53.50 72.67 86.43 87.14 79.52 82.38 75.00 79.76 83.33 53.81 80.24 61.90 68.33 70.48 75.24 53.10 59.52 61.43 60.95 85.00 50.24 77.38 47.86 80.47 62.86 74.05 67.86 60.24 56.19 68.57 64.29 54.29 81.67 53.57 69. 64.00 60.17 61.00 55.33 69.00 57.33 73.17 58.83 58.00 74.67 59.00 57.33 75.17 51.83 67.00 64.33 71.50 84.50 53.83 50.00 51.83 53.67 64.33 63.50 61.33 50.17 50.33 66.00 68.83 51.00 75.67 53.83 50.00 80.00 83.81 80.95 88.10 82.86 80.00 89.76 53.81 61.67 51.43 57.38 50.48 79.05 50.00 55.95 52.14 51.43 92.38 51.19 51.43 54.05 63.57 50.48 63.81 53.57 52.38 51.43 64.05 54.05 49.76 85.24 48.81 54. 58.00 54.67 63.00 63.17 58.50 63.67 57.50 68.67 57.50 68.17 61.17 57.00 65.17 53.33 67.50 58.83 56.33 69.83 63.67 55.50 55.00 59.33 64.17 56.00 59.17 64.67 50.50 65.50 62.67 60.50 66.67 61.83 58.83 59.29 72.86 72.62 67.38 69.29 65.00 69.05 55.48 61.90 60.71 48.10 49.76 62.14 55.00 57.86 56.67 54.05 72.38 53.81 51.43 45.00 62.62 61.91 48.10 57.86 72.14 47.62 52.62 55.24 53.10 67.62 48.33 51. 49.00 61.50 68.83 66.50 54.83 72.33 65.00 63.50 61.00 58.00 65.50 59.33 60.83 55.00 58.00 56.17 62.83 73.33 54.50 63.33 57.17 55.67 62.67 59.00 60.67 61.67 53.50 60.50 59.17 59.67 66.00 54.83 51.67 84.29 85.00 76.19 81.90 72.38 81.90 84.76 58.81 70.95 64.52 65.71 59.29 75.48 52.62 63.81 61.43 59.05 88.10 54.52 60.71 49.29 78.10 59.28 79.52 63.57 60.48 52.86 67.38 63.10 53.10 70.24 53.57 52. 50.00 51.33 55.83 57.83 54.00 55.83 53.33 60.50 52.50 57.83 53.83 55.67 61.83 49.50 55.50 56.83 55.83 58.17 51.33 50.00 47.33 51.17 60.83 61.83 55.83 49.00 49.50 57.83 52.83 57.50 66.67 55.00 49.83 54.29 47.86 64.76 64.05 57.14 49.52 55.95 56.90 52.14 55.24 55.48 54.05 54.76 52.38 59.29 55.71 54.05 62.38 49.76 50.95 50.71 49.29 57.38 57.14 47.62 53.57 54.52 62.62 57.62 50.48 54.29 56.90 46. 57.00 49.67 52.00 51.00 53.67 54.33 56.83 63.67 54.83 58.33 54.67 52.17 59.00 52.00 57.00 55.33 51.50 64.17 59.17 49.67 53.50 59.83 58.83 53.67 57.17 51.67 49.83 57.33 56.17 58.50 59.67 56.17 52.50 59.29 55.24 50.48 55.24 64.05 58.33 58.57 52.86 53.33 55.48 51.67 54.52 55.48 49.29 58.57 57.14 57.14 67.62 51.67 48.57 47.62 58.10 54.76 53.57 53.81 53.10 50.00 60.00 55.95 51.19 61.19 56.43 40. 50.00 49.67 55.50 57.67 51.00 56.17 55.50 66.17 56.17 66.33 55.33 56.5 66.83 54.33 61.83 61.50 60.33 67.67 52.83 58.83 53.17 53.00 59.00 54.33 58.33 64.00 50.67 61.00 61.67 54.67 68.50 55.17 61.67 65.00 59.52 64.52 65.95 64.29 68.33 64.52 61.43 63.10 50.24 61.19 55.48 63.10 49.05 58.81 51.90 59.52 72.38 47.86 55.95 52.38 53.09 50.00 66.19 56.90 49.76 50.95 58.33 58.81 47.14 66.90 47.14 53. 50.00 50.50 51.50 50.83 51.17 50.00 59.00 55.33 49.33 53.33 51.17 52.00 51.50 50.50 55.83 57.83 50.00 55.00 55.50 50.33 56.00 51.00 50.83 50.33 53.67 51.83 45.50 54.67 52.50 51.33 57.17 53.17 49.67 73.57 85.95 91.43 91.90 76.67 70.95 92.38 54.29 64.76 56.43 54.76 55.48 61.19 50.71 56.67 56.67 54.52 90.00 59.29 50.00 54.52 59.29 53.81 60.95 53.10 65.24 49.05 59.52 60.24 56.67 65.48 62.62 55. 52.00 51.33 49.83 49.67 50.83 50.50 51.67 55.33 54.00 56.67 50.33 55.00 56.17 49.50 56.67 57.00 55.17 51.83 51.50 50.33 52.33 54.33 57.00 49.00 49.83 54.67 51.67 54.67 56.00 50.83 52.33 53.33 51.33 67.86 50.24 56.43 53.81 54.52 54.29 61.43 54.05 49.52 52.14 56.67 51.19 55.24 47.86 52.62 53.57 52.14 57.14 49.05 49.76 52.86 51.19 53.33 52.38 48.57 55.48 51.43 49.76 53.10 50.24 48.57 56.19 54. 56.42 63.401.32 63.890.80 61.400.94 59.641.41 63.061.17 59.102.14 62.680.49 63.941.20 64.141.03 60.621.63 59.881.39 63.470.36 55.351.46 61.880.30 60.640.39 61.530.50 69.570.54 54.470.62 55.711.37 53.851.11 63.430.63 61.970.17 61.240.50 63.002.89 59.930.29 53.430.53 61.540.54 60.380.19 56.380.27 72.310.64 54.080.20 56.720.41 75.89 72.080.39 73.790.66 73.791.50 71.631.36 70.321.28 77.101.49 56.590.25 68.431.48 61.390.65 61.900.90 59.170.87 70.300.72 55.340.28 61.591.54 59.860.83 60.240.48 80.810.41 52.120.63 60.361.69 50.950.90 67.801.21 59.740.86 65.600.86 60.872.36 60.810.06 53.731.18 63.210.76 60.891.07 54.250.65 73.350.78 53.750.32 57.560. TABLE XX: Cohens Kappa (%) on BNCI2015001. The best metrics are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 S"
        },
        {
            "title": "Specialist\nModels",
            "content": "CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 16.00 83.00 88.67 31.33 6.00 65.33 5.67 Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 27.67 66.67 33.67 55.00 35.33 9.67 27.67 BrainOmni-Tiny 26.00 BrainOmni-Base 34.33 16.33 41.00 2.33 14.33 EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 7.67 76.33 37.33 62.00 60.00 16.00 11.00 BrainOmni-Tiny 23.33 BrainOmni-Base 22.33 3.00 97.67 -6.33 0.00 EEGMamba MIRepNet SingLEM LUNA-Base"
        },
        {
            "title": "Specialist\nModels",
            "content": "CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 94.29 0.00 41.43 0.00 25.24 0.00 50.95 Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot)"
        },
        {
            "title": "Foundation\nModels",
            "content": "BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 23.33 61.43 68.57 35.24 44.76 91.90 43.33 BrainOmni-Tiny 50.00 BrainOmni-Base 36.19 67.14 90.96 8.57 54.29 EEGMamba MIRepNet SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 4.76 48.09 55.24 0.48 57.62 83.33 39.05 BrainOmni-Tiny 50.48 BrainOmni-Base 38.57 33.33 92.38 13.81 39.52 EEGMamba MIRepNet SingLEM LUNA-Base 11.00 93.00 64.00 79.00 74.67 56.33 29.67 27.00 71.00 50.00 52.00 45.33 56.33 28.67 36.33 22.33 63.00 90.67 4.67 30.67 7.33 73.67 32.67 49.33 55.00 69.33 33.33 33.67 28.67 21.33 90.67 -0.33 59.33 88.57 91.43 88.09 94.76 86.19 88.09 94.76 23.34 87.14 62.38 77.15 57.62 81.43 51.43 51.91 58.57 51.43 90.49 7.62 80.00 0.00 90.00 43.81 83.33 59.05 15.71 18.10 45.71 54.29 20.00 79.69 12.38 72. 3.00 44.00 25.33 12.00 25.33 36.33 4.00 36.67 53.00 28.33 17.67 27.67 25.33 20.67 31.00 30.67 19.00 22.33 13.33 17.00 14.67 33.67 28.33 33.33 37.67 31.33 14.33 24.00 26.33 22.00 54.00 11.00 5.67 78.57 83.33 67.62 74.76 75.24 83.33 85.24 8.57 78.57 26.19 34.76 16.19 50.47 13.33 30.00 28.57 21.43 83.41 0.00 21.90 9.52 77.62 27.14 79.05 38.57 15.71 4.29 35.24 23.81 16.67 86.21 -3.33 13. 64.00 44.00 40.33 47.33 39.33 35.00 35.00 29.00 57.33 40.67 49.00 38.67 39.00 19.33 33.00 32.33 51.33 66.67 2.33 19.00 10.00 62.67 33.67 29.67 47.33 26.33 20.67 41.00 32.00 18.67 67.67 7.00 45.33 72.86 74.29 59.05 64.76 50.00 59.52 66.67 7.62 60.00 23.81 36.67 40.95 50.48 6.19 19.05 22.86 21.90 70.13 0.48 54.76 -4.29 60.95 25.71 48.10 35.71 20.48 12.38 37.14 28.57 8.57 63.84 7.14 38. 28.00 20.33 22.00 10.67 38.00 14.67 46.33 17.67 16.00 49.33 23.67 14.67 50.33 3.67 34.00 28.67 43.00 69.00 7.67 0.00 3.67 7.33 28.67 27.00 22.67 0.33 0.67 32.00 37.67 2.00 51.33 7.67 0.00 60.00 67.62 61.91 76.19 65.71 60.00 79.52 7.62 23.33 6.19 14.76 2.38 58.09 0.00 11.91 4.29 2.86 84.78 2.38 2.86 8.10 27.14 0.95 27.62 7.14 4.76 2.86 28.10 8.10 -0.48 70.64 -2.38 9. 16.00 9.33 26.00 26.33 17.00 27.33 15.00 37.33 16.33 36.33 24.33 14.00 30.33 6.67 35.00 17.67 12.67 39.67 27.33 11.00 10.00 18.67 28.33 12.00 18.33 29.33 1.00 31.00 25.33 21.00 33.33 23.67 17.67 18.57 45.71 45.24 34.76 38.57 30.00 38.10 10.96 24.29 21.43 2.86 3.81 24.29 10.00 15.71 13.33 8.10 45.24 7.62 2.86 -10.00 25.24 23.81 -3.81 15.71 44.29 -4.76 5.24 10.48 6.19 35.29 -3.33 2. -2.00 23.00 37.67 33.00 9.67 44.67 30.00 27.00 22.00 16.00 28.00 18.67 21.67 10.00 16.00 12.33 25.67 46.67 9.00 26.67 14.33 11.33 25.33 18.00 21.33 23.33 7.00 21.00 18.33 19.33 32.00 9.67 3.33 68.57 70.00 52.38 63.81 44.76 63.81 69.53 17.62 41.90 29.05 31.43 18.57 50.95 5.24 27.62 22.86 18.10 76.23 9.05 21.43 -1.43 56.19 18.57 59.05 27.14 20.95 5.71 34.76 26.19 6.19 40.62 7.14 4. 0.00 2.67 11.67 15.67 8.00 11.67 6.67 21.00 5.33 15.67 11.00 11.33 23.67 -1.00 11.00 13.67 11.67 16.33 2.67 0.00 -5.33 2.33 21.67 23.67 11.67 -2.00 -1.00 15.67 5.67 15.00 33.33 10.00 -0.33 8.57 0.00 29.53 28.10 14.29 6.19 11.91 13.81 4.76 10.48 10.95 9.05 9.52 4.76 18.57 11.43 8.10 25.55 -0.48 1.90 1.43 1.91 14.76 14.29 -4.76 7.14 9.05 25.24 15.24 0.95 9.47 13.81 -7. 14.00 0.00 4.00 2.00 7.33 8.67 13.67 27.33 9.67 16.67 9.00 4.33 18.00 4.00 14.00 10.67 3.00 28.33 18.33 -0.67 7.00 19.67 17.67 7.33 14.33 3.33 -0.33 14.67 12.33 17.00 19.33 12.33 5.00 18.57 10.95 3.33 10.48 28.09 16.67 17.14 7.14 8.57 10.95 3.33 9.05 10.95 -1.43 17.14 14.29 14.29 35.11 3.33 -2.86 -4.76 16.19 9.52 7.14 7.62 6.19 0.00 20.00 11.90 2.38 21.67 12.86 -18. 0.00 0.33 11.00 15.67 2.33 12.67 11.33 32.33 12.33 32.67 6.00 13.00 33.67 8.67 23.67 23.00 20.67 35.33 5.67 17.67 6.33 6.00 18.00 8.67 16.67 28.00 1.33 22.00 23.33 9.33 37.00 10.33 23.33 30.00 19.05 29.05 31.90 28.57 36.67 29.05 22.86 25.71 0.48 22.38 10.95 26.19 -1.90 17.62 3.81 19.05 44.92 -4.29 11.90 4.76 6.19 0.00 32.38 13.81 -0.48 1.90 16.67 17.62 -5.71 34.42 -5.71 6. 0.00 1.00 3.00 1.67 2.33 0.00 18.00 10.67 0.00 6.67 2.33 5.00 3.00 1.00 11.67 15.67 0.00 10.00 11.00 0.67 12.00 2.00 1.67 0.67 7.33 3.67 -9.00 9.33 5.00 2.67 14.33 6.33 -0.67 47.14 71.91 82.86 83.81 53.33 41.91 84.76 10.00 28.09 12.86 9.52 10.95 22.38 1.43 13.33 13.33 9.05 80.01 18.57 0.00 9.05 18.57 7.62 21.90 6.19 30.48 -1.90 19.05 20.48 13.33 32.33 25.24 11. S11 4.00 2.67 0.67 1.00 2.00 3.00 3.33 10.67 8.00 13.33 5.67 10.00 12.33 -1.00 13.33 14.00 10.33 3.67 3.00 0.67 4.67 8.67 14.00 -2.00 -0.33 9.33 3.33 9.33 12.00 1.67 4.67 6.67 2.67 35.71 0.95 12.86 7.62 9.05 8.57 22.86 8.10 2.86 7.14 13.33 3.33 10.95 -4.29 6.19 7.14 4.29 15.20 -1.90 -0. 5.71 2.38 6.67 4.76 -2.86 10.95 2.86 -0.48 6.19 0.48 -1.15 12.38 8.10 Avg. 12.83 26.802.63 27.781.59 22.811.88 19.282.82 26.112.35 18.194.28 25.360.98 27.892.40 28.282.05 23.642.90 19.752.77 26.950.73 10.692.93 23.750.60 21.280.79 23.060.99 39.141.08 8.941.24 11.422.74 7.692.23 26.861.27 23.940.34 22.471.01 26.005.79 19.860.57 6.861.07 23.081.09 20.750.38 12.750.54 44.611.28 8.170.41 13.440.82 51.79 44.170.77 47.581.33 47.583.01 43.252.72 40.632.56 54.212. 13.170.50 36.942.63 22.781.30 23.811.80 18.331.75 40.601.43 10.670.56 23.183.08 19.721.65 20.480.96 61.840.88 4.251.25 20.713.37 1.901.80 35.592.42 19.481.72 31.191.73 21.754.72 21.630.11 7.462.37 26.431.53 21.792.14 8.491.29 47.121.34 7.500.64 15.120.35 TABLE XXI: Classiﬁcation AUCs (%) on BNCI2014008. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base S0 74.40 76.93 73.45 76.73 53.91 75.63 53.30 69.76 55.13 67.66 73.03 65.53 75.20 52.43 61.85 63.64 76.25 63.73 50.38 69.81 51.05 58.78 65.75 76.53 52.54 52.58 58.63 59.65 70.53 57.87 49.31 54.34 69.36 51.21 57.96 49.60 59.07 51. 55.33 51.29 51.41 64.53 52.92 53.08 49.76 56.33 56.10 65.63 56.31 48.68 50.42 49.70 52.15 63.01 51.47 51.17 50.98 51.51 51.91 67.98 55.98 48.46 S1 73.89 76.03 73.71 74.53 57.47 71.69 60.63 72.57 60.40 69.99 72.86 66.03 74.54 57.74 67.89 59.21 71.80 65.23 52.96 69.32 59.85 62.25 66.77 73.50 59.48 53.73 62.34 63.74 66.92 64.73 55. 56.74 75.53 62.73 66.22 53.85 68.02 51.99 60.50 57.25 61.08 59.94 52.85 61.36 54.41 55.36 56.42 59.70 54.49 54.51 52.76 56.72 54.67 54.45 52.84 57.01 52.79 54.63 55.07 63.07 54.40 54.51 S2 82.98 84.89 81.35 83.30 53.13 80.11 54.95 77.16 55.25 76.62 80.00 70.92 79.23 51.39 71.98 66.65 83.19 70.46 50. 75.91 52.65 63.97 72.18 82.98 53.90 49.84 67.43 68.53 76.71 66.46 50.80 64.61 81.07 54.72 68.01 50.80 78.98 50.00 67.41 50.39 58.25 72.83 57.11 57.86 51.70 60.86 59.19 69.71 52.20 49.73 52.32 51.06 56.10 64.93 54.44 50.38 50.53 55.09 55.71 71.60 58.84 49.62 S3 73.59 75.86 73.90 75.88 51.42 71.61 51. 71.93 53.79 67.90 72.65 62.90 74.19 50.33 63.91 62.53 71.68 69.31 49.99 71.31 51.88 60.45 65.16 71.55 53.03 50.19 59.75 60.32 66.68 67.22 48.82 48.32 71.74 53.05 67.30 49.75 69.27 50.29 60.25 49.53 56.45 51.91 49.41 57.06 50.80 54.91 53.10 49.43 50.96 49.23 50.11 49.68 52.32 55.73 48.58 50.53 48.91 51.08 50.92 48.57 51.83 49.05 73.49 79.61 76.49 79.79 60.06 73.60 63.47 77.50 62.31 70.97 76.13 66.93 79.31 57.63 62.48 57.31 69.22 65.62 58.14 75.25 62.32 58.25 54.56 76.15 61.97 55.35 55.87 57.93 61.34 59.39 58.71 62.07 76.27 64.58 64.38 52.90 65.80 50.15 61.02 61.01 57.63 66.77 59.04 60.81 52.11 57.39 58.56 64.32 58.81 57.45 57.56 56.15 55.50 62.24 60.60 59.07 52.89 56.79 57.40 64.95 60.19 57. S5 75.63 79.52 78.36 78.38 51.51 72.84 51.56 69.69 54.02 69.31 74.66 62.77 76.98 52.84 59.92 60.15 70.17 71.48 52.36 74.20 52.36 57.67 68.31 70.34 53.24 51.70 56.22 57.99 64.16 71.82 51.64 67.53 81.01 60.74 72.99 49.39 75.80 50.39 61.34 52.20 63.12 71.69 54.15 62.99 51.90 68.76 67.88 70.32 64.05 48. 57.65 51.22 54.56 69.05 53.71 48.51 50.60 61.07 60.98 68.83 69.30 48.26 S6 76.78 81.46 78.21 81.69 57.31 78.54 59.21 74.84 64.09 73.28 73.44 68.20 81.00 58.92 70.40 62.83 75.15 71.66 56.34 73.40 57.78 66.59 71.08 75.59 57.98 57.11 67.23 68.12 71.47 72.02 54.56 63.52 80.66 62.24 70.10 52.63 73.40 56. 64.66 58.05 59.22 69.54 61.42 62.99 54.73 67.12 65.27 65.26 65.36 53.02 59.41 51.36 61.65 65.60 59.70 52.74 53.10 63.49 62.71 68.46 65.37 52.57 S7 83.04 84.91 84.30 84.50 53.63 81.41 52.99 80.44 55.59 70.34 81.46 69.59 80.77 52.72 71.91 70.58 77.70 76.71 54.30 77.15 52.14 64.03 79.97 79.15 56.46 52.42 68.05 70.87 75.36 76.35 58. 71.84 90.82 74.24 87.72 53.06 89.34 51.14 78.47 55.60 79.52 80.14 59.06 85.15 50.36 74.79 73.90 81.23 79.35 53.32 60.24 52.95 60.06 78.36 59.68 53.45 50.83 64.41 66.05 80.03 76.93 54.69 Avg. 76.72 79.900.11 77.470.02 79.350.10 54.800.35 75.680.48 55.980.02 74.240.10 57.570.07 70.761.04 75.530.08 66.610.69 77.650.09 54.250.29 66.290.16 62.860.12 74.400.04 69.280.25 53.170. 73.291.01 55.000.81 61.500.24 67.970.50 75.720.32 56.070.10 52.870.94 61.940.27 63.390.33 69.140.05 66.980.04 53.430.08 61.12 78.311.49 60.440.23 69.340.54 51.500.64 72.461.09 51.510.46 63.621.49 54.420.29 60.830.52 67.170.42 55.751.32 62.660.96 51.970.35 61.940.44 61.300.47 65.700.47 60.190.91 51.830.13 55.061.08 52.360.64 55.880.23 64.171.36 55.130.40 52.860.34 51.330.50 57.260.22 57.590.23 66.690.32 61.610.45 51.780.05 TABLE XXII: Balanced classiﬁcation accuracies (%) on BNCI2014008. The best BCAs are marked in bold, and the second best by an underline."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base S0 55.06 69.66 66.29 68.94 50.16 57.00 51.01 59.21 52.90 59.58 66.03 56.11 66.92 51.49 57.80 59.39 69.25 56.49 50.00 64.33 50.73 54.62 50.00 55.44 50.07 51.27 50.26 56.63 65.02 54.60 49.99 52.71 63.04 49.95 55.96 50.12 54.62 50. 52.64 50.20 49.86 58.67 50.60 51.03 49.45 53.73 53.31 60.07 53.14 49.97 50.25 49.51 49.79 50.02 49.86 50.87 50.78 51.22 51.70 62.67 53.67 49.43 S1 58.16 69.00 68.30 67.62 53.36 58.14 57.29 64.15 57.26 61.95 67.03 58.62 67.88 55.53 61.86 56.77 65.84 60.53 50.00 63.35 56.44 56.61 50.24 56.53 57.29 52.89 51.07 59.12 62.49 59.72 49. 52.42 68.10 58.63 60.99 50.64 62.33 51.24 56.84 55.10 55.73 56.80 50.60 57.18 52.69 53.38 54.06 57.24 52.69 51.72 50.85 54.23 52.81 50.31 51.31 55.36 52.23 51.93 53.75 59.14 53.54 52.76 S2 62.73 76.86 74.02 75.95 51.38 61.30 51.53 66.81 53.87 68.58 72.65 62.15 71.50 51.09 65.92 62.07 74.47 65.22 50. 69.30 51.64 58.50 50.30 64.61 51.28 49.68 52.79 63.25 68.57 62.24 49.98 59.10 73.39 52.22 61.85 50.17 70.14 50.03 61.07 49.66 52.27 65.52 51.75 53.97 51.14 55.43 54.04 64.04 50.47 50.07 50.50 50.87 53.39 50.00 50.72 50.77 50.50 51.29 53.18 64.82 55.99 50.34 S3 63.89 69.85 67.11 70.29 50.58 59.57 49. 64.35 52.56 61.94 66.24 56.48 68.20 50.32 60.26 59.81 66.76 63.80 50.02 65.75 50.55 56.89 50.10 57.69 52.24 49.72 51.28 57.02 62.04 62.32 49.95 48.81 65.52 50.88 62.08 49.88 61.34 50.39 56.18 50.13 51.50 51.33 49.83 54.02 50.18 52.97 52.63 49.64 51.33 49.97 49.71 49.62 51.28 50.00 49.87 50.37 49.23 50.60 49.96 48.77 51.26 49.40 53.66 71.71 67.45 71.17 54.02 54.70 59.88 70.22 58.98 63.16 69.41 57.66 70.32 55.43 59.61 55.00 64.54 60.73 50.00 68.62 60.25 55.49 49.98 56.46 58.46 53.99 51.27 55.28 57.49 56.31 50.02 56.75 68.72 59.61 61.40 50.23 59.04 49.30 55.45 52.91 52.61 61.79 53.40 56.93 50.86 54.04 53.99 61.00 56.75 50.00 52.93 54.17 52.85 50.18 52.07 52.10 51.73 53.53 53.79 60.81 57.60 52. S5 55.24 71.87 70.63 69.65 50.65 50.77 50.03 58.96 52.24 60.98 67.57 55.26 69.99 52.25 56.32 56.82 64.53 65.08 50.00 67.86 51.45 54.98 50.00 52.20 51.78 51.22 50.51 55.03 59.56 65.07 50.00 61.05 72.74 54.61 64.93 49.48 65.89 50.53 56.28 50.91 55.32 64.22 50.88 57.87 51.76 59.83 59.03 64.54 57.25 50. 52.50 50.94 52.33 50.51 50.06 49.45 50.20 54.18 56.21 63.33 63.63 50.00 S6 63.33 73.18 70.27 74.13 54.78 63.29 55.33 66.45 58.96 66.89 66.98 60.02 72.82 56.01 64.17 59.36 69.34 65.87 50.00 67.14 54.00 59.66 50.02 57.57 55.31 54.94 51.63 62.17 65.53 66.01 49.99 58.51 73.07 58.67 63.50 50.70 64.68 55. 58.83 54.39 54.77 61.80 55.34 58.13 53.41 58.32 58.32 58.47 59.74 50.33 53.81 51.57 55.10 55.80 55.06 50.95 52.67 56.41 57.93 59.65 60.76 51.11 S7 57.50 76.22 75.25 76.21 50.54 57.27 49.84 69.95 51.41 61.51 72.84 59.65 71.65 51.80 65.29 65.26 70.68 69.61 50.00 70.50 50.48 57.83 50.00 57.56 50.05 51.72 51.80 62.94 68.50 68.84 50. 63.88 82.72 63.20 77.89 50.65 76.84 51.30 69.32 53.66 65.33 72.72 53.07 74.89 50.16 63.01 64.07 73.97 69.67 50.20 53.42 52.07 56.15 50.26 51.76 51.56 50.11 54.55 58.11 72.44 69.69 50.53 Avg. 58.69 72.290.17 69.920.05 71.740.12 51.930.16 57.751.21 53.100.06 65.010.18 54.770.21 63.070.97 68.590.25 58.240.40 69.910.06 52.990.29 61.400.17 59.310.06 68.180.05 63.420.13 50.000. 67.110.76 53.190.66 56.820.60 50.080.04 57.260.17 53.310.14 51.930.63 51.330.14 58.930.43 63.650.11 61.890.03 49.990.02 56.65 70.911.17 55.970.20 63.580.30 50.230.29 64.360.93 51.090.40 58.331.00 52.120.27 54.670.67 61.610.14 51.930.41 58.000.99 51.210.28 56.340.33 56.180.14 61.120.35 56.380.28 50.290.12 51.750.70 51.620.47 52.960.24 50.880.02 51.340.18 51.430.09 50.930.36 52.960.05 54.330.30 61.450.09 58.270.40 50.790.15 TABLE XXIII: Classiﬁcation AUCs (%) on BNCI2014009. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 72.41 81.81 85.92 80.62 58.56 82.99 60.43 78.31 58.00 73.85 79.72 67.26 80.73 49.69 72.28 73.87 73.81 77.88 54.24 74.20 55.88 74.94 75.31 74.75 69.70 50.03 75.20 73.62 76.84 78.88 52.89 55.19 71.22 59.54 65.62 47.29 68.34 58.17 62.93 49.31 68.94 63.17 56.05 58.27 51.30 61.56 62.39 56.84 61.35 45. 47.64 54.73 60.11 62.93 56.46 52.81 50.80 59.53 58.29 56.71 65.80 46.18 78.53 88.18 86.56 89.16 71.51 88.38 60.00 83.86 66.47 84.09 87.30 77.29 89.29 51.74 82.17 81.03 89.35 76.73 48.72 75.67 57.05 76.95 86.01 85.42 72.28 49.56 77.97 80.05 83.58 79.35 48.66 59.02 76.32 62.57 63.31 49.01 75.70 53.00 58.96 53.39 72.99 78.70 64.50 55.52 53.42 81.78 80.21 80.08 67.66 52. 64.17 55.57 67.83 71.00 66.61 51.58 50.04 76.17 76.41 81.48 67.14 51.89 68.27 73.04 74.76 73.42 60.30 73.35 66.98 73.26 63.50 72.61 72.79 67.04 72.23 52.98 69.53 68.66 72.51 70.61 56.50 69.76 63.37 64.55 71.95 72.22 63.64 51.46 66.15 68.11 72.91 69.98 51.25 53.24 68.12 58.28 66.49 50.65 67.71 55.75 61.53 51.76 60.47 64.51 51.78 58.25 51.04 59.59 61.06 57.89 61.88 59. 63.67 50.34 50.38 60.88 55.62 54.14 52.62 58.10 59.31 58.31 62.28 49.47 72.34 86.03 83.29 88.89 64.32 85.65 68.34 85.00 58.13 86.72 80.07 73.50 89.93 55.67 81.15 82.95 87.50 88.82 54.74 78.38 61.23 78.26 79.15 83.44 71.76 55.07 78.96 80.28 83.06 87.55 56.03 73.40 79.35 63.52 70.39 46.04 73.86 52.51 67.61 50.41 71.84 72.27 59.12 63.13 54.98 74.27 73.73 73.40 67.01 47. 58.95 51.40 67.57 64.46 60.09 54.06 52.35 70.16 71.18 71.55 72.75 46.49 84.86 92.46 93.78 92.10 76.97 92.20 81.42 91.37 58.09 87.02 91.13 75.28 92.35 54.71 82.47 84.86 91.77 83.36 54.66 85.47 59.04 83.32 90.47 91.49 82.54 53.09 80.52 83.82 87.13 83.42 54.36 63.96 85.28 73.78 77.57 50.61 86.82 56.92 74.63 59.51 78.41 79.53 70.92 70.60 56.78 82.33 76.53 84.78 68.94 58. 56.83 60.48 74.32 69.47 72.44 60.21 50.48 74.43 72.51 85.81 71.41 59.73 71.73 85.42 82.81 84.28 65.45 84.76 71.99 83.54 59.38 79.56 76.83 66.88 82.36 57.17 70.85 69.26 77.34 74.81 59.86 77.36 57.23 70.28 77.15 79.25 74.06 56.83 69.37 68.00 73.25 74.32 58.31 61.38 74.85 54.73 60.54 50.52 71.00 54.01 57.10 56.36 63.67 70.86 55.86 60.99 52.78 69.25 67.14 71.79 63.03 50. 55.84 50.60 56.70 64.67 62.87 50.07 50.77 66.24 64.51 73.59 60.12 45.02 69.54 84.73 85.49 82.66 61.77 85.98 71.18 78.39 65.13 77.32 80.56 72.27 84.61 51.10 73.67 73.45 80.38 71.88 56.15 72.86 59.71 71.23 80.02 80.64 72.56 51.10 71.52 73.01 75.06 71.85 55.55 57.65 62.88 54.91 56.76 45.63 60.93 52.95 55.81 45.72 61.57 66.18 50.45 57.38 48.27 58.25 56.35 63.04 58.83 51. 48.53 48.57 56.21 60.13 55.45 56.48 53.45 55.79 54.36 64.42 60.60 52.91 78.35 85.83 85.70 86.18 68.54 86.37 65.33 84.11 58.95 79.80 82.15 69.97 86.71 52.59 74.37 74.63 82.52 78.38 51.96 76.41 57.36 69.23 79.46 81.86 64.58 48.81 71.29 72.47 77.07 79.16 52.62 55.08 77.21 54.78 72.92 49.38 75.58 49.42 61.91 51.87 64.12 69.63 57.35 59.66 44.78 65.71 64.90 59.72 64.67 51. 64.81 45.91 53.23 64.22 61.25 52.98 48.62 62.22 58.25 60.49 69.07 52.90 88.25 96.47 95.04 96.37 67.77 97.36 75.87 94.71 81.05 94.53 94.97 86.35 96.44 58.46 91.60 91.75 95.76 87.36 65.72 91.71 73.74 86.20 93.85 93.72 80.25 56.73 89.12 90.25 94.11 89.25 65.43 68.84 88.36 70.45 82.93 55.93 85.37 63.22 77.51 67.56 82.12 79.64 68.83 71.97 56.60 88.30 84.76 81.74 68.84 63. 69.68 65.09 72.56 75.83 67.55 65.38 50.67 82.03 77.76 84.51 74.56 65.85 90.35 90.22 92.26 93.13 62.83 93.55 71.49 93.95 66.74 89.39 90.50 84.37 92.66 52.63 77.75 79.86 84.63 82.58 57.55 84.57 62.47 79.90 89.64 92.22 77.94 53.13 79.51 76.35 84.91 87.09 55.48 76.21 90.02 75.23 79.94 52.39 92.15 51.50 71.95 57.72 81.43 80.49 65.32 69.82 54.20 79.21 73.76 84.24 80.25 60. 73.84 57.85 68.55 79.71 70.13 59.94 52.99 71.57 71.78 84.31 84.70 58.88 77.46 86.420.22 86.560.15 86.680.34 65.802.39 87.060.14 69.300.54 84.650.36 63.550.13 82.490.35 83.600.26 74.023.43 86.730.10 53.670.78 77.580.23 78.030.15 83.560.02 79.240.90 56.010.52 78.641.45 60.710.30 75.490.15 82.300.29 83.500.50 72.930.20 52.580.30 75.960.58 76.600.10 80.790.06 80.090.04 55.060.33 62.40 77.360.73 62.781.47 69.652.03 49.740.31 75.751.50 54.750.50 64.991.11 54.361.13 70.560.70 72.501.90 60.022.03 62.561.80 52.420.48 72.023.18 70.090.36 71.350.40 66.250.32 54.080. 60.390.47 54.050.34 62.740.35 67.335.05 62.854.35 55.770.37 51.281.92 67.620.35 66.440.66 72.120.16 68.841.09 52.930.19 TABLE XXIV: Balanced classiﬁcation accuracies (%) on BNCI2014009. The best BCAs are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base xDAWN+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 59.27 73.96 73.51 70.14 57.33 71.22 56.25 64.79 53.61 61.56 72.05 57.50 66.42 50.49 65.52 67.47 69.76 68.99 50.76 57.71 50.00 67.50 55.45 57.15 57.15 49.90 58.85 65.49 70.31 71.35 53.30 50.43 62.85 53.29 59.16 48.50 58.02 54.75 59.56 49.87 57.82 52.39 51.87 57.18 50.77 50.87 54.61 55.23 56.73 47. 49.95 52.97 52.90 50.00 50.64 50.00 51.59 52.59 53.92 52.98 60.53 46.49 69.79 79.17 79.83 79.13 66.67 77.47 56.56 73.54 57.08 69.20 80.52 62.67 74.76 52.08 71.74 73.26 78.99 69.58 49.17 57.99 49.93 66.91 54.48 62.99 55.52 48.96 59.13 71.56 74.17 70.45 48.78 54.57 65.24 55.03 53.58 51.38 66.61 49.09 54.20 49.27 63.17 55.36 51.64 53.56 52.42 61.21 64.46 72.14 56.82 51. 50.42 53.45 61.96 50.00 56.81 50.22 49.46 61.71 65.95 71.77 62.98 51.77 62.71 68.09 68.02 69.72 56.77 67.36 60.21 68.68 57.22 65.28 66.42 59.27 67.81 52.40 64.65 62.47 67.64 64.41 52.95 60.87 50.62 60.80 56.42 63.12 58.09 50.83 60.90 61.46 68.78 65.87 48.37 51.34 61.19 54.18 57.09 49.66 59.21 54.93 54.40 51.07 51.74 50.00 51.22 53.63 49.99 51.33 55.86 55.76 56.86 54. 49.77 51.38 50.24 49.96 50.95 49.96 53.40 52.06 50.86 56.72 56.82 49.55 59.17 77.60 76.32 81.56 60.49 73.19 61.77 72.33 56.15 73.96 72.33 62.29 81.98 55.07 73.44 75.35 79.76 80.87 52.50 60.80 50.80 66.98 59.17 65.83 56.98 52.95 64.17 73.85 75.00 79.83 53.44 61.02 71.32 57.65 59.86 47.02 62.45 51.50 61.02 50.83 63.08 54.17 52.90 55.73 53.23 56.93 62.42 64.76 58.08 50. 50.50 50.48 53.93 50.00 53.98 50.00 51.21 56.65 59.42 63.48 67.14 47.62 74.27 83.89 84.24 84.72 67.12 84.55 72.22 80.17 54.86 75.76 83.89 64.24 85.76 54.51 75.45 76.35 84.51 76.22 53.96 63.44 50.45 74.06 67.05 77.53 65.87 52.36 63.54 76.53 79.06 73.75 52.78 56.30 76.36 65.09 65.92 50.15 74.99 54.41 63.49 53.14 64.48 62.09 53.48 60.83 54.41 65.92 63.99 76.41 58.43 50. 53.21 56.05 61.84 50.34 56.85 51.10 51.54 61.29 64.25 75.39 65.37 53.42 54.48 77.12 76.84 75.62 59.62 72.43 65.45 72.05 56.08 64.13 69.62 57.12 69.83 54.13 65.14 63.54 67.53 67.78 51.35 59.24 50.49 61.94 54.06 59.83 55.21 54.79 56.56 65.24 69.03 69.31 51.98 53.77 67.33 52.43 54.85 50.82 61.87 54.31 54.13 52.65 56.50 60.17 52.53 54.67 51.37 56.73 57.21 66.25 54.13 49. 52.45 50.62 53.71 50.46 51.67 49.92 51.93 57.22 59.25 68.06 56.58 46.18 55.31 74.90 71.91 70.24 58.75 68.92 58.65 64.44 55.24 60.38 72.40 57.43 72.22 50.38 68.30 66.98 73.65 65.56 52.43 55.56 50.66 64.51 51.91 58.37 54.93 51.53 55.62 64.34 69.03 64.51 51.49 50.77 57.62 54.58 51.06 47.94 54.14 51.15 53.49 49.56 52.43 51.19 49.27 53.08 48.58 52.23 53.12 57.79 53.03 50. 50.53 49.50 52.23 49.96 49.68 49.65 52.00 52.27 51.97 59.53 58.62 52.86 67.29 75.69 75.83 78.58 63.58 75.42 58.89 70.21 56.39 69.51 73.85 59.86 77.88 52.78 64.93 67.60 73.51 71.01 51.42 62.19 50.21 63.30 54.41 62.43 53.40 48.75 57.43 65.52 70.49 71.77 50.56 50.32 68.86 52.72 60.77 52.71 64.29 49.83 57.34 49.87 56.50 51.76 50.95 55.10 45.41 52.60 54.05 54.57 55.31 49. 51.56 50.97 50.85 50.38 50.75 49.81 48.15 52.10 50.83 55.70 61.38 50.71 76.04 90.76 90.56 88.72 63.78 91.81 70.14 85.66 73.09 84.86 86.74 73.89 91.67 57.26 84.20 82.99 87.85 79.51 50.00 70.28 54.06 76.88 65.83 78.96 67.53 54.51 70.80 81.70 87.26 81.28 58.40 57.23 78.37 63.84 70.08 53.82 75.74 59.90 70.00 62.18 70.20 52.26 54.90 64.30 54.59 59.19 67.49 74.20 59.80 55. 53.44 59.41 55.47 51.34 57.68 50.15 50.67 58.27 62.13 77.93 69.01 60.88 73.02 82.74 83.44 86.11 60.90 86.56 62.05 82.74 61.67 78.40 81.91 73.40 84.65 51.94 71.42 72.71 76.91 75.83 52.15 64.38 53.19 74.62 68.23 79.06 61.63 51.04 66.35 69.27 78.12 77.12 52.53 58.72 80.73 62.50 70.40 51.22 76.44 53.94 65.06 53.50 64.69 60.83 51.45 60.47 53.43 63.16 64.34 77.86 67.79 56. 58.50 55.49 58.40 54.02 52.75 50.95 51.21 59.18 65.12 76.33 78.15 54.72 65.14 78.390.44 78.050.62 78.450.46 61.501.71 76.890.14 62.220.97 73.460.28 58.140.33 70.310.24 75.970.53 62.771.85 77.300.28 53.100.48 70.480.23 70.870.29 76.010.05 71.980.56 51.670.54 61.242.07 51.040.12 67.750.32 58.700.26 66.530.05 58.630.54 51.560.51 61.340.42 69.500.69 74.130.30 72.520.05 52.160.50 54.45 68.990.51 57.130.93 60.280.82 50.320.52 65.380.32 53.380.31 59.271.03 52.190.16 60.060.58 55.020.97 52.021.14 56.851.03 51.420.87 57.020.36 59.751.14 65.500.46 57.700.41 51.660. 52.030.18 53.030.78 55.150.21 50.650.31 53.180.97 50.180.15 51.120.83 56.330.16 58.370.35 65.790.16 63.660.96 51.420.19 TABLE XXV: Root Mean Square Error (RMSE) in SEED-VIG. The best RMSEs are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 S"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 0.2986 0.1518 0.1809 0.1395 0.2862 0.1740 0.2218 0.2117 0.1521 0.1643 0.2076 0.2789 0.1631 0.2077 0.1887 0.1728 0.1883 0.1901 0.1633 0.3846 0.1988 0.2181 0.3119 0.2553 0.1809 0.2930 0.3006 0.1781 0.1714 0.3629 0.2770 0.1936 0.2419 0.4239 0.1569 0.1174 0.2196 0.1231 0.3212 0.1387 0.2022 0.1502 0.1869 0.1672 0.2552 0.1574 0.1522 0.1487 0.2019 0. 0.2886 0.1359 0.1737 0.1619 0.1878 0.1527 0.2552 0.2064 0.1335 0.1361 0.3449 0.1165 0.1886 0.3864 0.3228 0.1609 0.1654 0.2165 0.2354 0.1851 0.2202 0.1822 0.2549 0.1723 0.2182 0.1986 0.1751 0.1857 0.1670 0.1834 0.2063 0.3026 0.1956 0.2067 0.1735 0.1626 0.2647 0.2212 0.1706 0.1919 0.1911 0.2122 0.1728 0.1462 0.1726 0.3460 0.1824 0.1497 0.2886 0.1320 0.1768 0.1619 0.1704 0.1746 0.1651 0.1821 0.1788 0.2051 0.1798 0.1619 0.1918 0. 0.1591 0.1475 0.1631 0.1700 0.1679 0.1952 0.1788 0.1915 0.1797 0.1596 0.1972 0.1657 0.3192 0.4450 0.3684 0.3758 0.2435 0.2887 0.2721 0.2493 0.2336 0.2085 0.3934 0.2340 0.2880 0.2074 0.2482 0.2904 0.2697 0.2327 0.2221 0.2419 0.2259 0.1953 0.2305 0.2561 0.3394 0.1935 0.2204 0.2366 0.2558 0.1981 0.2292 0.1170 0.1316 0.2623 0.1295 0.1144 0.2848 0.1192 0.183 0.1340 0.1480 0.1619 0.1620 0.1440 0.1837 0.1803 0.2028 0.1466 0.1633 0. 0.1342 0.1303 0.1258 0.1695 0.1613 0.1231 0.1837 0.1623 0.1812 0.1347 0.2214 0.1477 0.2643 0.1933 0.2217 0.2198 0.2600 0.3162 0.3173 0.2338 0.4984 0.4225 0.2025 0.2033 0.5829 0.3092 0.2396 0.2537 0.2412 0.3071 0.2810 0.2996 0.3572 0.2590 0.2422 0.1728 0.2431 0.2522 0.2317 0.2356 0.2293 0.2464 0.2684 0.2600 0.1888 0.4605 0.1725 0.1681 0.3235 0.1634 0.21 0.1966 0.1917 0.1900 0.1833 0.1969 0.1995 0.2129 0.1812 0.1714 0.2139 0. 0.3921 0.1944 0.2809 0.1936 0.1956 0.2375 0.1995 0.2336 0.2008 0.1706 0.2328 0.1670 0.2820 0.2665 0.2833 0.2790 0.2610 0.2636 0.2703 0.2546 0.2822 0.2412 0.2836 0.2731 0.3064 0.2825 0.2726 0.2718 0.2758 0.2886 0.2732 0.3585 0.2635 0.2770 0.3033 0.2861 0.2832 0.3049 0.2904 0.2758 0.2946 0.3016 0.2916 0.1441 0.2967 0.3985 0.2593 0.2188 0.3751 0.2116 0.3537 0.1291 0.3057 0.2753 0.2911 0.3016 0.3158 0.2776 0.2600 0.2683 0.3423 0. 0.2058 0.1209 0.1611 0.2856 0.2906 0.1338 0.3158 0.2744 0.2714 0.2615 0.3555 0.2603 0.1505 0.1276 0.1342 0.1324 0.1525 0.1755 0.2135 0.1715 0.1522 0.1304 0.1477 0.1468 0.1893 0.1351 0.1615 0.1696 0.1504 0.1436 0.1316 0.2184 0.1285 0.1348 0.1397 0.1394 0.2828 0.1396 0.1392 0.1498 0.1512 0.1754 0.1336 0.1994 0.1395 0.4335 0.1299 0.1591 0.2957 0.1292 0.1378 0.2570 0.1349 0.1384 0.1288 0.1873 0.1550 0.1765 0.1405 0.1457 0.1294 0. 0.2329 0.2230 0.2195 0.1489 0.1281 0.2099 0.1550 0.1651 0.1404 0.1385 0.1673 0.1268 0.1423 0.1443 0.1150 0.1491 0.1669 0.1410 0.1308 0.1692 0.1613 0.1261 0.1776 0.1403 0.1611 0.1367 0.1708 0.1857 0.1239 0.1817 0.1362 0.2048 0.1127 0.1195 0.1579 0.1506 0.1463 0.1332 0.1483 0.1262 0.1535 0.1483 0.1311 0.1450 0.1166 0.3603 0.1179 0.1004 0.2510 0.1217 0.1257 0.1517 0.1222 0.1301 0.1184 0.1203 0.1262 0.1633 0.1780 0.1286 0.1225 0. 0.1682 0.1485 0.1563 0.1403 0.1177 0.1501 0.1262 0.1755 0.1291 0.1220 0.1825 0.1120 0.2458 0.3423 0.2960 0.2789 0.3070 0.3724 0.2798 0.3345 2.0075 0.3143 0.2609 0.2626 0.3579 0.2804 0.2350 0.2637 0.2641 0.2614 0.2643 0.3323 0.2900 0.3450 0.2883 0.1767 0.3635 0.2881 0.2200 0.2892 0.3214 0.2979 0.2832 0.2417 0.2400 0.5759 0.1740 0.2268 0.3823 0.1212 0.2774 0.1890 0.1889 0.1733 0.1870 0.5143 0.2204 0.2058 0.1194 0.1342 0.2189 0. 0.3348 0.2066 0.2738 0.1850 0.1923 0.2599 0.2204 0.1807 0.1342 0.1437 0.2580 0.1155 0.1408 0.1173 0.1537 0.1188 0.2060 0.1508 0.1731 0.1841 0.1625 0.1278 0.1672 0.1397 0.1504 0.1679 0.1390 0.1725 0.1297 0.1389 0.1493 0.2218 0.1517 0.1440 0.1366 0.1449 0.1589 0.1476 0.1214 0.1317 0.1526 0.1575 0.1297 0.1127 0.1163 0.3616 0.1008 0.1003 0.3235 0.0989 0.1391 0.1135 0.1248 0.1293 0.1223 0.1579 0.1285 0.1362 0.1196 0.1241 0.1294 0. 0.2021 0.1163 0.1603 0.1287 0.1342 0.1359 0.1285 0.1356 0.1130 0.1166 0.1876 0.1138 0.2209 0.1643 0.2130 0.1484 0.2359 0.2188 0.3430 0.2553 0.2341 0.2668 0.2670 0.2060 0.2909 0.2041 0.1935 0.2072 0.1489 0.2046 0.2144 0.2449 0.2227 0.2301 0.1696 0.1648 0.2387 0.1470 0.1876 0.1746 0.1673 0.1928 0.1503 0.2583 0.1552 0.5374 0.1438 0.1351 0.2508 0.1319 0.1587 0.1886 0.1571 0.1611 0.1549 0.1922 0.1652 0.1728 0.1796 0.1631 0.1553 0. 0.3342 0.2232 0.2258 0.1768 0.1641 0.2148 0.1652 0.1989 0.1541 0.1536 0.1960 0.1432 0.1552 0.2006 0.1367 0.1425 0.1886 0.1707 0.2548 0.1578 0.2010 0.1723 0.2270 0.1536 0.1702 0.1505 0.1608 0.1980 0.1644 0.1406 0.1328 0.2216 0.1648 0.1538 0.1397 0.1568 0.1423 0.1402 0.1280 0.1321 0.1290 0.1522 0.1329 0.1064 0.1347 0.2940 0.1293 0.1002 0.1971 0.1131 0.1469 0.0898 0.1363 0.1347 0.1314 0.1457 0.1408 0.1669 0.1834 0.1274 0.1391 0. 0.1182 0.0860 0.1154 0.1383 0.1374 0.1044 0.1408 0.1461 0.1423 0.1210 0.1869 0.1286 40 TABLE XXVI: Root Mean Square Error (RMSE) in SEED-VIG. The best RMSEs are marked in bold, and the second best by an underline (continued)."
        },
        {
            "title": "Approach",
            "content": "S11 S12 S13 S14 S15 S17 S18 S19 S20 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 0.3325 0.3956 0.3256 0.4162 0.4165 0.3223 0.3417 0.3027 0.3143 0.3970 0.2801 0.3370 0.4254 0.3259 0.3531 0.5224 0.3218 0.3653 0.3974 0.4328 0.3177 0.3289 0.3804 0.4045 0.5335 0.3779 0.3772 0.4268 0.3608 0.3737 0.3661 0.1551 0.3122 0.3172 0.2795 0.1446 0.3766 0.1455 0.4155 0.1716 0.2550 0.2819 0.3240 0.2116 0.3439 0.3204 0.2822 0.2462 0.3316 0. 0.1692 0.1753 0.1741 0.3035 0.3201 0.1763 0.3439 0.3425 0.3042 0.2367 0.4336 0.2313 0.2546 0.3087 0.2457 0.3128 0.3413 0.3495 0.2076 0.2982 0.2720 0.2042 0.3105 0.2994 0.2917 0.2366 0.3049 0.2575 0.2420 0.2183 0.2627 0.3788 0.2284 0.2365 0.2879 0.3240 0.2452 0.2946 0.3308 0.2840 0.2461 0.3547 0.2817 0.2992 0.1603 0.3825 0.1416 0.1114 0.1687 0.1229 0.2036 0.2337 0.1740 0.1680 0.1757 0.1278 0.1940 0.1711 0.1794 0.1588 0.1764 0. 0.3690 0.2752 0.3135 0.1981 0.1789 0.2235 0.1940 0.2059 0.1733 0.1366 0.2904 0.1382 0.2191 0.2731 0.2382 0.2343 0.2450 0.2493 0.2125 0.2440 0.2228 0.2028 0.2266 0.2371 0.2203 0.2136 0.2214 0.2156 0.2076 0.2016 0.2194 0.2865 0.2128 0.2119 0.2262 0.2265 0.2201 0.2381 0.2548 0.2024 0.2148 0.2444 0.2188 0.2731 0.2282 0.4472 0.3108 0.2042 0.2609 0.1855 0.2529 0.2228 0.2344 0.2237 0.2210 0.2385 0.2545 0.2489 0.2084 0.2208 0.2453 0. 0.3362 0.2257 0.3128 0.2398 0.2218 0.2628 0.2545 0.2260 0.2111 0.2152 0.2872 0.2020 0.1703 0.2051 0.1856 0.1865 0.2343 0.2954 0.1788 0.2298 0.1996 0.1703 0.1687 0.1711 0.2485 0.1852 0.2122 0.2155 0.2735 0.2022 0.2061 0.2331 0.2330 0.2406 0.1788 0.1661 0.2762 0.1938 0.1607 0.2181 0.2219 0.1995 0.1688 0.1323 0.1440 0.3398 0.1487 0.1323 0.2288 0.1273 0.1872 0.1500 0.1653 0.1728 0.1634 0.1581 0.1776 0.1565 0.2023 0.1667 0.1791 0. 0.1691 0.1374 0.1562 0.1757 0.1675 0.1341 0.1776 0.1686 0.1766 0.1615 0.2120 0.1594 0.3184 0.3506 0.2009 0.3086 0.2644 0.2303 0.2395 0.2617 0.1992 0.1869 0.2201 0.3126 0.2672 0.2867 0.2855 0.4240 0.2779 0.3014 0.3113 0.4012 0.2618 0.2318 0.3378 0.3490 0.3189 0.3302 0.3559 0.3448 0.3114 0.3797 0.3263 0.1699 0.3110 0.2967 0.4559 0.2438 0.5325 0.2125 0.3665 0.1614 0.2809 0.2285 0.2726 0.2596 0.2917 0.2667 0.2345 0.2485 0.3469 0. 0.2027 0.1609 0.1878 0.2535 0.2616 0.1643 0.2917 0.2752 0.2294 0.2371 0.4110 0.1928 0.2466 0.2449 0.1842 0.2624 0.2416 0.1736 0.1628 0.2614 0.2570 0.1847 0.2782 0.2261 0.1623 0.1743 0.2659 0.1959 0.2106 0.2196 0.2118 0.2653 0.2048 0.2065 0.1862 0.2387 0.2845 0.1962 0.2391 0.1805 0.2265 0.2495 0.2102 0.2425 0.1347 0.4746 0.1362 0.1097 0.1688 0.1194 0.2220 0.2767 0.1458 0.1281 0.1446 0.1389 0.2034 0.1792 0.1363 0.1385 0.2049 0. 0.3310 0.2850 0.2867 0.1513 0.1448 0.2728 0.2034 0.1937 0.1386 0.1265 0.2574 0.1434 0.2548 0.2563 0.1952 0.2570 0.2806 0.2007 0.1537 0.2091 0.2473 0.1977 0.1928 0.2882 0.1680 0.2219 0.2439 0.2162 0.2312 0.2013 0.1816 0.3836 0.2049 0.2421 0.3147 0.2810 0.2028 0.3120 0.3363 0.2235 0.2209 0.3364 0.2817 0.1232 0.3596 0.3768 0.3642 0.1948 0.3306 0.1448 0.3583 0.1718 0.2348 0.2171 0.2750 0.2215 0.3094 0.2781 0.2088 0.1833 0.3572 0. 0.1329 0.3807 0.1398 0.2473 0.2675 0.2247 0.3094 0.2750 0.2099 0.1866 0.3989 0.1607 0.1535 0.1148 0.1263 0.1272 0.1600 0.1941 0.1170 0.1834 0.2708 0.1669 0.2230 0.1671 0.2296 0.1948 0.1469 0.1776 0.1407 0.1845 0.1661 0.2072 0.1695 0.2215 0.1175 0.1226 0.1570 0.1284 0.1178 0.1388 0.1403 0.1571 0.1143 0.1029 0.1173 0.3002 0.1144 0.0785 0.2544 0.0874 0.1143 0.1181 0.1232 0.1213 0.1220 0.1348 0.1189 0.1460 0.1247 0.1228 0.1194 0. 0.1203 0.0990 0.1187 0.1312 0.1304 0.1168 0.1189 0.1653 0.1182 0.1207 0.1890 0.0997 0.4711 0.3752 0.3681 0.4555 0.3743 0.4119 0.4354 0.3702 0.5685 0.4418 0.4635 0.4336 0.4765 0.3753 0.5252 0.4315 0.4382 0.4124 0.4319 0.4328 0.4567 0.3660 0.4251 0.3908 0.5323 0.4100 0.4642 0.4731 0.4349 0.4218 0.4635 0.1772 0.3719 0.3114 0.3479 0.1537 0.3026 0.1281 0.4058 1.3133 0.2960 0.3289 0.3642 0.2383 0.3571 0.3914 0.2941 0.2689 0.4225 0. 0.2435 2.5759 0.1985 0.3379 0.3423 0.3644 0.3571 0.3608 0.3000 0.2614 0.4027 0.3184 0.3976 0.3146 0.3136 0.3119 0.3374 0.3607 0.2889 0.2981 0.3404 0.2807 0.3151 0.3611 0.3390 0.3002 0.3673 0.3263 0.3567 0.3536 0.3546 0.3897 0.3328 0.3327 0.3820 0.3342 0.3921 0.3347 0.3450 0.3416 0.3253 0.3640 0.3391 0.1044 0.2997 0.3624 0.2621 0.2654 0.2781 0.2461 0.3605 0.1126 0.3151 0.2585 0.2847 0.2686 0.3174 0.2934 0.2718 0.2518 0.3785 0. 0.1244 0.1191 0.1183 0.2943 0.2971 0.1222 0.3174 0.3422 0.2678 0.2549 0.3662 0.2301 0.2489 0.25610.0092 0.22900.0029 0.23890.0029 0.25560.0140 0.25120.0053 0.24050.0044 0.24120.0025 0.34270.0627 0.22810.0035 0.25090.0055 0.24020.0025 0.27180.0019 0.22830.0026 0.24340.0003 0.25490.0055 0.22970.0010 0.23490.0004 0.23420.0043 0.30680.0017 0.23490.0011 0.23340.0010 0.24430.0035 0.23350.0043 0.27650.0020 0.24170.0004 0.24470.0012 0.23600.0032 0.23430.0002 0.26320.0006 0.23670.0013 0.17640.0013 0.20820.0045 0.38390.0063 0.20270.0110 0.15380.0100 0.29020.0167 0.14210.0034 0.24360.0023 0.22300.0414 0.19560.0017 0.18800.0035 0.19900.0007 0.20510.0036 0.22080.0058 0.21460.0089 0.19230.0062 0.17740.0018 0.22710.0021 0.16760. 0.22710.0015 0.29370.0419 0.19350.0020 0.20150.0051 0.20040.0062 0.18950.0075 0.22080.0058 0.22020.0035 0.18610.0031 0.17120.0014 0.27520.0075 0.16540.0009 TABLE XXVII: Correlation Coefﬁcient (CC) in SEED-VIG. The best CCs are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 S"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 0.5198 0.9086 0.9244 0.8850 0.2768 0.8462 0.7444 0.7231 0.8903 0.8946 0.7564 0.7147 0.8478 0.7696 0.8270 0.8758 0.8899 0.7883 0.8849 0.0646 0.8613 0.8143 0.7031 0.8923 0.7952 0.6200 0.8540 0.8914 0.8837 0.2197 0.8774 0.7536 0.7476 0.2673 0.8435 0.9309 0.8860 0.9398 0.1382 0.8889 0.7485 0.8655 0.8351 0.8878 0.5065 0.8750 0.9131 0.8745 0.6939 0. 0.1344 0.8874 0.8737 0.8401 0.8417 0.8692 0.4886 0.8442 0.9083 0.8977 0.1562 0.9161 0.2097 0.0000 0.0000 0.3588 0.0000 0.0965 0.0000 0.1267 0.0907 0.1274 0.0500 0.1150 0.0973 0.2279 0.2189 0.2336 0.1830 0.0650 0.1471 0.0420 0.0101 0.0658 0.0921 0.1802 0.0403 0.0437 0.1980 0.3108 0.1842 0.1981 0.2164 0.2109 0.1740 0.0019 0.0233 0.4047 0.2823 0.6335 0.0407 0.1230 0.0365 0.0787 0.1137 0.1933 0.0281 0.1253 0.1149 0.2324 -0.0088 0. 0.0000 0.3082 0.1142 0.1459 0.0755 0.1512 0.0015 0.1310 0.1156 0.2681 -0.0082 0.1181 0.6967 0.7628 0.7713 0.6897 0.4097 0.6380 0.7264 0.5133 0.5345 0.7181 0.7611 0.6268 0.6755 0.3340 0.5358 0.5388 0.6663 0.6399 0.5793 0.0149 0.3812 0.6642 0.4517 0.5139 0.6007 0.2327 0.5035 0.6191 0.5305 0.3002 0.5241 0.4806 0.6263 0.1119 0.6016 0.7817 0.6592 0.8333 0.0323 0.2868 0.4122 0.4544 0.3437 0.6013 0.1265 0.4272 0.5710 0.4908 0.2152 0. 0.0137 0.3110 0.3301 0.3909 0.3781 0.4405 0.0163 0.3157 0.4890 0.6017 0.0703 0.4375 0.4877 0.5818 0.4348 0.3258 0.2972 0.2934 0.2970 0.3951 0.3428 0.2799 0.4091 0.4923 0.3276 0.3263 0.4230 0.5875 0.5991 0.4890 0.5445 0.0264 0.3693 0.4647 0.4238 0.6042 0.4324 0.2654 0.4359 0.6568 0.5438 0.0923 0.5591 0.7401 0.4365 0.4057 0.4799 0.6009 0.5088 0.6405 0.0986 0.8558 0.2559 0.3109 0.4294 0.5462 0.2376 0.3631 0.5189 0.5202 0.1245 0. 0.0110 0.8612 0.7309 0.3225 0.4421 0.7802 0.2409 0.2634 0.5477 0.5187 0.0588 0.5891 0.5218 0.5747 0.4839 0.6412 0.6544 0.6298 0.5771 0.6449 0.5684 0.7558 0.6607 0.6051 0.4693 0.5118 0.5837 0.6151 0.6160 0.4754 0.6064 0.0465 0.5985 0.6547 0.4578 0.6122 0.5398 0.4322 0.6462 0.5860 0.5281 0.3905 0.6094 0.7063 0.4916 0.1718 0.6406 0.7924 0.7292 0.8331 0.1354 0.8015 0.4316 0.5694 0.5130 0.6542 0.4234 0.5909 0.6450 0.6018 0.2443 0. 0.0509 0.8200 0.7113 0.5521 0.6197 0.7564 0.3574 0.6188 0.6330 0.6247 0.1310 0.6285 0.1122 0.2428 0.2310 0.1284 0.1490 0.1677 0.2283 0.1286 0.0213 0.3703 0.1901 0.2064 0.1232 0.0446 -0.0371 -0.0376 0.0550 0.3078 0.0143 0.0000 0.1590 0.3032 0.0957 0.1252 0.1146 -0.0319 -0.0596 -0.1028 0.0428 0.0615 -0.1136 0.5018 0.0376 0.0362 0.0591 0.2742 0.0085 0.2106 0.0317 0.2550 0.1092 0.0962 0.1133 0.1298 0.0731 0.1880 0.1284 0.0932 -0.0031 0. 0.0143 0.4030 0.3391 0.0524 0.0850 0.4587 -0.0204 0.2200 0.1366 0.1561 0.0038 0.1496 0.0000 0.3931 0.4500 0.3926 0.1744 0.4134 0.4708 0.2706 0.5438 0.2166 0.4666 0.3091 0.0376 0.3293 0.1734 0.2247 0.1444 0.0822 -0.0212 0.0068 0.5362 0.2936 0.2240 0.2722 0.2297 0.0056 0.3463 0.1658 0.2429 0.1505 0.3078 0.4671 0.1450 0.0002 0.1181 0.6333 0.3118 0.5435 0.0415 0.4342 0.1519 0.1511 0.1299 0.3835 0.1653 0.1270 0.2684 0.1286 0.0288 0. 0.0297 0.5079 0.2958 0.1176 0.2036 0.4020 0.0900 0.1248 0.1679 0.2069 -0.0029 0.2369 0.6737 0.7300 0.8661 0.8624 0.5294 0.7577 0.8690 0.6890 0.1724 0.8592 0.8350 0.7409 0.7804 0.8360 0.8219 0.8688 0.8679 0.8787 0.8963 0.1697 0.7399 0.8391 0.7239 0.8710 0.7313 0.7035 0.8572 0.8603 0.8070 0.3070 0.8815 0.7035 0.2980 0.1538 0.7738 0.5343 0.7431 0.8849 0.0646 0.8232 0.6661 0.7082 0.7743 0.3146 0.5505 0.7675 0.8826 0.8304 0.4286 0. 0.0214 0.8022 0.5972 0.6340 0.8543 0.6655 0.5261 0.7672 0.8988 0.8234 0.1066 0.8856 0.1956 0.5399 0.2337 0.4727 0.4185 0.1776 0.3256 0.3737 0.3294 0.4848 0.1370 0.0906 0.3272 0.3295 0.2381 0.3408 0.2221 0.4233 0.4111 0.0000 0.2214 0.3024 0.1739 0.1014 0.1861 0.1726 0.2764 0.2713 0.2255 0.1617 0.2070 0.8335 0.4820 0.1758 0.5925 0.6335 0.5048 0.6352 0.0000 0.8456 0.3049 0.2282 0.3906 0.4261 0.1062 0.2186 0.5929 0.4573 0.0592 0. 0.1524 0.3688 0.4032 0.2447 0.2513 0.3351 0.4261 0.3748 0.3353 0.4271 0.4118 0.2785 0.3733 0.2699 0.2102 0.2690 0.3132 0.3122 0.3194 0.0000 0.3637 0.3411 0.1302 0.2414 0.2329 0.1485 0.1543 0.2769 0.2518 0.0964 0.2705 0.6832 0.1535 0.1688 0.1871 0.3082 0.1648 0.4733 0.0100 0.8410 0.0892 0.0690 0.0914 0.2454 0.0438 0.0413 0.1915 0.2250 0.0293 0.2315 0.0498 0.8325 0.6732 0.2287 0.4434 0.7983 0.2136 0.3198 0.5979 0.4560 -0.0348 0. 0.2143 0.7988 0.8330 0.0274 -0.0114 0.8314 -0.0011 0.0812 0.1862 0.2591 0.0063 0.1851 0.3600 0.2927 0.4544 0.3763 0.1913 0.2401 0.0699 0.4128 0.4559 0.4221 0.3324 0.3649 0.4253 0.2325 0.2788 0.2923 0.3158 0.3132 0.2134 0.0215 0.3926 0.4738 0.3000 0.3519 0.2124 0.1819 0.3233 0.3190 0.3330 0.2343 0.2960 0.4440 0.2769 0.0025 0.2097 0.6664 0.3015 0.6051 0.0192 0.6683 0.1040 0.2069 0.1606 0.4629 0.1741 0.2259 0.3720 0.3841 0.0345 0. 0.2644 0.7038 0.4118 0.2270 0.2119 0.4807 0.1528 0.2719 0.3970 0.4439 0.0295 0.3334 42 TABLE XXVIII: Correlation Coefﬁcient (CC) in SEED-VIG. The best CCs are marked in bold, and the second best by an underline (continued)."
        },
        {
            "title": "Approach",
            "content": "S11 S12 S13 S14 S15 S17 S18 S19 S20 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base PSD+Ridge EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 0.7425 0.7512 0.8175 0.5047 0.4985 0.8158 0.6501 0.7381 0.7398 0.6880 0.7999 0.6823 0.5184 0.6470 0.5799 0.5563 0.7072 0.6576 0.5066 0.0467 0.6823 0.7218 0.6705 0.6788 0.6434 0.5331 0.6011 0.6250 0.7328 0.4188 0.7524 0.3635 0.6045 0.0195 0.6699 0.9346 0.8340 0.9342 0.0721 0.1265 0.7507 0.6955 0.5574 0.8386 0.5228 0.5774 0.7404 0.7663 0.4961 0. 0.0159 0.1166 0.0989 0.6396 0.6426 0.0959 0.4418 0.5604 0.6623 0.7850 0.0484 0.7991 0.5121 0.7363 0.8256 0.6273 0.2257 0.8056 0.8492 0.5333 0.6585 0.7985 0.8056 0.6947 0.5132 0.7463 0.6605 0.7365 0.7119 0.7121 0.8114 0.0945 0.7486 0.7174 0.5040 0.6007 0.7606 0.5479 0.7149 0.7391 0.5963 0.5047 0.7196 0.6049 0.7190 0.3899 0.7318 0.8787 0.7959 0.8628 0.1978 0.7786 0.6323 0.6011 0.5482 0.8039 0.4890 0.6744 0.6854 0.6851 0.4971 0. 0.0079 0.7075 0.5975 0.5385 0.6249 0.7922 0.3966 0.7264 0.6773 0.7458 0.1077 0.7660 0.4216 0.4771 0.5585 0.4702 0.4278 0.5001 0.5833 0.4009 0.4418 0.5829 0.6253 0.4032 0.4776 0.5048 0.4509 0.5753 0.5562 0.5483 0.5387 0.0550 0.4553 0.5229 0.4089 0.4259 0.5867 0.2712 0.4741 0.5853 0.5054 0.2370 0.5507 0.5820 0.3789 0.0760 0.2876 0.6432 0.4658 0.7132 0.0515 0.7383 0.1511 0.3567 0.2984 0.4414 0.1809 0.3430 0.5041 0.4254 0.0998 0. 0.0198 0.7334 0.4672 0.3419 0.4294 0.6629 0.0832 0.2806 0.5152 0.4320 0.0307 0.5320 0.4431 0.4507 0.4405 0.4962 0.3998 0.2724 0.4974 0.2671 0.3077 0.5464 0.4680 0.4159 0.5624 0.4206 0.3717 0.4265 0.4197 0.4981 0.2750 0.0228 0.3129 0.4506 0.3394 0.3922 0.3329 0.0127 0.4196 0.3928 0.4090 0.2126 0.3105 0.6068 0.5291 0.1505 0.4468 0.6376 0.3871 0.6815 0.0000 0.4936 0.2321 0.2533 0.2618 0.4419 0.2161 0.3869 0.3396 0.3480 0.1222 0. 0.0350 0.5989 0.4859 0.2363 0.2918 0.6080 0.0926 0.3758 0.2131 0.4263 0.0280 0.3045 0.5063 0.7983 0.8090 0.6890 0.5263 0.7546 0.7426 0.6846 0.7974 0.8268 0.7976 0.6868 0.6705 0.5448 0.6134 0.5679 0.7255 0.5736 0.4227 0.0000 0.6689 0.7062 0.5651 0.6915 0.7095 0.4305 0.5756 0.6399 0.4956 0.1385 0.6137 0.5026 0.5761 0.1447 0.4407 0.8132 0.7877 0.8682 0.0539 0.6114 0.5646 0.7063 0.6280 0.7561 0.4284 0.6405 0.7903 0.6494 0.2625 0. 0.0103 0.6161 0.3684 0.6394 0.7176 0.5612 0.4619 0.5715 0.7607 0.6989 0.0543 0.8127 0.6157 0.6666 0.7443 0.5058 0.6796 0.7037 0.7995 0.5670 0.3278 0.6739 0.7320 0.4240 0.6806 0.7479 0.6233 0.7642 0.5669 0.6915 0.7779 0.0413 0.5535 0.6261 0.6105 0.6352 0.4571 0.6168 0.6832 0.7155 0.6582 0.2291 0.7040 0.6850 0.7771 0.1633 0.7784 0.8775 0.8011 0.8868 0.0164 0.5787 0.7605 0.7785 0.7682 0.7821 0.4311 0.7381 0.8283 0.7503 0.1811 0. 0.0593 0.6306 0.5422 0.7598 0.8151 0.6185 0.3493 0.7862 0.8351 0.7836 -0.0106 0.8016 0.7274 0.8440 0.8694 0.8048 0.5103 0.8634 0.9072 0.8131 0.5684 0.8779 0.8640 0.7389 0.8901 0.7738 0.7727 0.8145 0.8273 0.8177 0.8613 0.0349 0.8182 0.7860 0.7238 0.8319 0.8430 0.5776 0.7918 0.8633 0.8307 0.3426 0.8399 0.2461 0.5053 0.0205 0.5598 0.8602 0.8312 0.9219 0.2014 0.0453 0.7838 0.7729 0.7124 0.8479 0.4831 0.7563 0.8727 0.8486 0.1911 0. 0.0127 0.0367 0.2299 0.7115 0.8083 0.0892 0.4840 0.7418 0.8582 0.8529 0.0576 0.8872 0.3163 0.5182 0.4415 0.3974 0.2959 0.4499 0.4777 0.3256 0.3139 0.4035 0.4544 0.4207 0.5050 0.2662 0.3273 0.2746 0.3450 0.4599 0.2370 0.0173 0.4504 0.3652 0.3873 0.3585 0.4032 0.3828 0.4223 0.2739 0.4037 0.1815 0.4987 0.4745 0.3264 0.0977 0.2919 0.7783 0.2805 0.6951 0.3627 0.4592 0.3170 0.2913 0.2248 0.5050 0.2158 0.3500 0.5282 0.3644 0.0636 0. 0.0000 0.5919 0.1789 0.2889 0.2904 0.2571 0.3287 0.3196 0.4841 0.4086 -0.0118 0.5759 0.0832 0.5550 0.5858 0.2411 0.5074 0.5214 0.5022 0.5704 0.1124 0.4935 0.4803 0.2973 0.4180 0.2932 0.2743 0.3298 0.3072 0.3784 0.2055 0.0236 0.0472 0.5581 0.0618 0.2493 0.3096 0.1461 0.1335 0.2305 0.2276 -0.0021 0.1557 0.7124 0.2618 0.2767 0.4270 0.9189 0.6768 0.9464 0.0214 0.1701 0.6145 0.4168 0.2743 0.7750 0.1745 0.3166 0.6759 0.6822 0.0112 0. 0.0247 0.0651 0.7319 0.3351 0.4037 0.3850 0.2176 0.2518 0.6636 0.6992 0.0263 0.5053 0.5362 0.7253 0.7832 0.7105 0.2711 0.7117 0.7820 0.6248 0.5144 0.7655 0.7509 0.7095 0.7151 0.6924 0.6595 0.7129 0.7218 0.6842 0.7493 0.0876 0.7383 0.7063 0.6192 0.7030 0.7209 0.5387 0.6736 0.7453 0.6821 0.3491 0.7419 0.5326 0.4636 0.0180 0.6011 0.7281 0.6832 0.7931 0.1117 0.4384 0.2879 0.6063 0.5410 0.6481 0.3031 0.4617 0.7119 0.6499 0.0461 0. 0.0449 0.3955 0.2997 0.5161 0.5501 0.4353 0.2696 0.5155 0.7239 0.6291 0.0379 0.7370 0.4185 0.56460.0009 0.57120.0076 0.51550.0047 0.36480.1177 0.52350.0135 0.54180.0147 0.48470.0114 0.43180.0297 0.58160.0074 0.56130.0095 0.47700.0022 0.49600.0170 0.46900.0037 0.45750.0048 0.50320.0094 0.51240.0022 0.51410.0033 0.47530.0149 0.03640.0001 0.48140.0032 0.54180.0018 0.41270.0205 0.49200.0018 0.47060.0021 0.32530.0072 0.47740.0028 0.50790.0018 0.48160.0008 0.22970.0005 0.50110.0008 0.56360.0038 0.42910.0192 0.12330.0168 0.46500.0154 0.69600.0199 0.55410.0219 0.73980.0235 0.07490.0109 0.53640.0117 0.40020.0052 0.43890.0171 0.41470.0118 0.55640.0010 0.28000.0063 0.43780.0094 0.56550.0052 0.52420.0069 0.18180.0115 0.55740. 0.04050.0056 0.55830.0175 0.47200.0188 0.40690.0237 0.46270.0140 0.53050.0078 0.24720.0204 0.43270.0133 0.54630.0028 0.55800.0052 0.04210.0057 0.55590.0016 43 TABLE XXIX: Classiﬁcation accuracies (%) on TUAB. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Specialist\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "CSP+LDA"
        },
        {
            "title": "LMDA",
            "content": "CNN-T"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "TFM",
            "content": "67.01 75.88 80.01 55.08 75.73 82. 78.26 78.78 50.32 75.85 79.28 76. 80.14 74.76 BrainOmni-Tiny 70.69 BrainOmni-Base 81."
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base LUNA-Large LUNA-Huge"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "TFM",
            "content": "80.44 49.49 83.15 80.12 81.53 57. 50.32 77.90 79.61 76.41 78.62 66. BrainOmni-Tiny 76.74 BrainOmni-Base 79."
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base LUNA-Large LUNA-Huge 78.21 51.57 75. 74.98 75.53 65.16 78.02 79.37 63. 77.69 81.94 78.34 78.45 51.81 76. 79.78 77.90 80.70 76.97 74.42 81. 80.49 49.21 81.29 81.17 80.45 59. 51.81 78.34 79.90 77.90 79.14 68. 77.79 77.44 78.86 51.64 75.76 76. 75.76 67.06 75.68 79.00 65.58 71. 80.53 77.25 78.43 49.08 76.26 79. 77.95 79.93 74.90 69.65 78.52 80. 50.81 81.68 79.70 80.13 58.21 49. 77.82 79.43 78.00 76.99 69.24 76. 79.51 77.43 51.82 76.09 75.10 75. 65.41 77.91 79.34 55.30 68.19 79. 77.56 79.67 49.04 75.85 78.66 78. 78.99 75.45 73.90 79.33 81.19 51. 80.42 78.66 80.00 57.96 49.04 78. 79.05 77.88 77.92 67.93 76.24 79. 77.75 51.63 75.81 75.08 75.04 65. 77.16 80.04 70.41 73.36 81.01 77. 78.81 61.51 76.64 79.69 77.39 79. 75.44 73.17 81.24 81.18 51.06 82. 80.00 80.98 58.64 51.57 78.75 79. 77.81 77.31 68.99 77.33 80.01 78. 51.43 76.54 76.00 76.71 63.65 79. 80.58 60.98 75.70 82.45 77.85 79. 50.73 76.57 80.40 79.23 80.33 76. 75.88 82.21 81.96 52.01 82.69 81. 81.79 58.32 50.73 78.78 80.22 78. 78.26 69.25 78.15 80.80 79.00 51. 77.85 77.77 77.70 68.40 76.19 79. 67.43 73.68 82.11 77.48 79.42 51. 76.12 79.46 76.97 79.68 75.92 72. 81.58 81.23 48.64 82.34 80.07 80. 58.31 51.16 78.80 79.25 77.31 78. 68.68 76.74 79.45 78.95 51.36 74. 73.89 74.52 65.69 77.17 79.67 53. 68.20 82.14 77.71 79.44 52.85 76. 80.61 78.21 80.28 75.60 74.50 77. 81.23 55.79 82.25 80.40 81.54 57. 60.94 78.55 80.91 77.26 78.38 67. 77.53 78.04 78.48 51.76 76.33 77. 77.36 66.18 77.54 79.91 61.63 75. 81.39 77.11 79.17 50.63 76.05 78. 77.58 80.29 75.76 71.60 80.51 80. 49.69 81.47 80.38 80.44 58.43 50. 77.85 78.91 77.31 77.51 67.99 76. 79.39 77.50 51.13 75.75 75.55 75. 66.58 75.23 80.19 73.46 72.29 81. 78.29 79.47 50.51 76.09 78.52 76. 79.59 75.36 72.79 81.30 79.81 49. 81.55 79.82 80.97 58.26 50.51 77. 79.40 76.43 77.94 67.58 76.56 79. 77.71 51.11 74.77 75.03 75.06 66.030. 77.030.67 79.810.12 62.691.52 73.200.73 81.480.21 77.780. 79.090.16 51.761.39 76.230.27 79.500.17 77.670.17 79.980. 75.650.07 72.920.25 80.490.29 80.900.10 50.801.02 81.920. 80.220.17 80.870.24 58.330.66 51.581.17 78.320.11 79.640. 77.510.09 78.040.04 68.250.09 77.030.37 79.320.30 78.240. 51.530.13 75.880.17 75.720.07 75.920.07 44 TABLE XXX: Cohens Kappa (%) on TUAB. The best metrics are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg. 27. 58.67 61.08 20.50 51.00 64.83 55. 36.63 52.50 59.51 33.66 46.44 63. 54.63 30.71 54.22 59.19 0.74 34. 63.86 55.02 32.16 55.06 59.64 22. 50.03 62.70 54.02 32.80 50.76 60. 47.21 44.05 61.91 56.18 31.890.52 54.071. 59.480.24 24.313.77 46.031.34 62.840.41 55.380.09 58. 58.63 58.66 58.12 58.63 58.070."
        },
        {
            "title": "Specialist\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "CSP+LDA"
        },
        {
            "title": "LMDA",
            "content": "CNN-T"
        },
        {
            "title": "Conformer",
            "content": "33.95 51.73 59.95 9.59 51.32 65. 56.44 29.97 55.97 58.57 26.14 54. 63.61 56.50 34.34 51.53 58.09 31. 44.72 61.18 54.59 31.04 55.97 58. 11.37 37.22 59.41 55."
        },
        {
            "title": "BENDR",
            "content": "57.50 56.83 56.94 59."
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "TFM",
            "content": "0.00 51.67 79.19 53.37 60.22 49. BrainOmni-Tiny 41.18 0.00 52.98 79.43 55. 61.23 53.72 49.15 BrainOmni-Base 62.37 62."
        },
        {
            "title": "EEGMamba",
            "content": "60.80 60."
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base LUNA-Large LUNA-Huge 0.00 66.23 60. 63.06 0.00 62.47 62.23 60.83 0. 52.54 79.81 55.96 59.94 49.91 39. 57.23 61.69 0.00 63.45 59.44 60. 0.00 51.79 78.95 57.08 58.11 50. 47.67 58.43 62.44 0.00 60.86 57. 60.04 30.14 54.28 59.92 39.51 46. 61.77 55.66 57.51 19.41 53.24 79. 54.59 59.54 50.63 46.33 62.29 62. 0.00 64.50 59.68 61.88 Cross-subject 0. 53.09 80.22 58.40 60.47 52.47 51. 64.28 63.79 0.00 65.19 63.61 63. 0.00 51.88 79.06 53.59 58.95 51. 44.87 62.66 62.15 0.00 64.37 60. 61."
        },
        {
            "title": "BENDR",
            "content": "15.62 19.27 16.49 15.96 17.44 16. 16."
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "TFM",
            "content": "0.00 55.75 79.53 52.67 57.19 31. BrainOmni-Tiny 53.39 BrainOmni-Base 58."
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base LUNA-Large LUNA-Huge 56.34 3.12 50. 49.85 50.91 0.00 56.54 79.72 55. 58.12 37.25 55.43 55.11 57.53 3. 51.59 52.83 51.49 0.00 55.72 79. 56.08 54.05 38.61 53.26 59.04 54. 3.67 52.16 50.32 51.11 0.00 57. 79.22 55.83 55.94 36.19 52.77 59. 55.62 3.35 51.61 50.35 50.29 0. 57.36 79.49 55.50 54.45 37.43 54. 59.89 56.77 2.83 52.90 51.77 53. 0.00 57.42 80.10 57.76 56.41 38. 56.24 61.51 57.88 3.61 55.62 55. 55.21 0.00 57.27 78.94 54.56 56. 36.89 53.22 58.29 57.51 2.78 49. 47.30 48.59 0.00 52.46 80.19 56. 60.21 50.75 48.45 55.7 62.22 13. 64.28 60.66 62.91 15.63 19.37 56. 80.57 54.56 56.51 35.03 54.72 56. 56.63 3.36 52.58 54.14 54.43 0. 52.01 78.81 55.04 60.47 51.33 43. 60.66 61.09 0.00 62.85 60.68 60. 0.00 51.90 78.10 52.40 58.86 50. 44.35 62.26 59.32 0.00 62.85 59. 61.49 1.942.75 52.360.52 79.320.19 55.210.33 59.800. 51.110.10 45.620.50 60.820.65 61.660.21 1.351.86 63.710. 60.290.37 61.630.43 16.73 16.62 16.701.32 0. 55.55 78.73 54.45 54.85 35.65 52. 58.53 54.78 2.15 51.32 50.91 51. 0.00 54.66 79.04 52.87 55.49 34. 52.79 58.58 55.06 2.16 49.21 49. 50.04 1.942.74 56.500.22 79.490.16 54.990.21 55.940. 36.180.16 53.930.67 58.540.64 56.310.08 3.030.25 51.630. 51.250.16 51.700.11 45 TABLE XXXI: Classiﬁcation Top-5 accuracies (%) on Things-EEG2. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 7.33 10.00 11.33 3.33 14.00 5.67 9.67 2.67 15.67 15.17 11.67 12.33 2.50 10.00 8.67 12.33 9.00 5.67 3.17 2.83 4.00 8.67 7.83 9.50 2.50 5.50 5.50 8.00 6.67 2.50 21.67 5.83 22.50 5.50 15.33 5.17 5.50 2.83 17.67 11.83 5.83 17.67 3.00 5.83 5.67 18.17 4.00 2. 4.33 1.83 5.83 3.83 7.17 12.67 4.00 3.00 3.67 12.33 11.17 2.33 12.17 12.67 16.33 6.50 17.33 8.67 10.00 2.67 18.83 17.33 15.67 19.17 2.33 7.17 7.67 17.83 4.83 5.67 4.83 2.33 6.17 8.50 8.33 15.50 2.67 5.50 7.17 16.00 8.17 2.50 36.33 6.67 22.50 5.33 22.33 4.33 7.17 2.50 21.33 15.50 7.50 13.67 2.67 6.33 8.83 24.83 2.33 2. 4.50 3.00 5.00 7.17 6.00 14.83 2.50 6.83 4.83 14.50 9.17 2.50 12.67 9.67 15.83 4.33 16.50 8.50 10.50 2.17 13.50 14.83 14.17 15.83 2.50 10.17 10.50 13.83 4.33 5.33 3.00 2.83 4.67 8.00 5.50 12.17 2.67 5.50 8.33 12.17 5.00 2.50 35.67 5.17 28.17 4.50 24.17 3.00 7.33 2.67 23.67 14.67 8.00 13.50 2.33 8.67 8.83 21.50 2.83 3. 4.50 2.33 4.83 7.17 9.33 22.00 1.83 7.83 6.67 16.67 16.67 2.83 8.17 10.67 15.50 4.33 17.33 6.33 11.67 2.67 18.67 15.83 14.00 14.67 2.83 7.83 8.50 12.83 6.83 5.50 4.50 2.67 4.83 7.83 9.50 13.67 1.67 6.00 5.33 12.17 7.00 2.50 43.67 7.50 32.67 4.33 30.50 4.67 8.83 2.50 37.17 22.17 8.67 42.00 2.33 11.33 10.50 34.33 3.00 2. 4.50 2.50 5.83 9.50 11.17 29.17 3.00 7.50 7.83 21.17 21.17 2.83 11.83 11.17 15.67 4.83 21.17 5.83 11.50 2.50 12.67 16.33 13.67 15.83 3.17 6.67 8.00 15.83 8.83 6.83 3.17 2.67 4.83 9.17 8.17 12.50 3.17 5.33 5.83 13.83 5.50 2.50 32.33 5.00 19.17 6.17 18.50 4.50 7.83 2.50 18.33 17.67 6.83 17.83 2.67 11.00 8.67 16.00 2.67 2. 3.67 2.50 7.00 9.50 8.00 19.83 2.83 7.00 6.50 13.00 18.33 2.50 9.00 9.83 13.67 4.67 19.33 8.00 9.00 3.00 10.33 16.50 12.67 12.50 2.50 10.00 7.67 14.00 4.67 5.00 3.83 2.83 4.67 7.50 9.17 11.33 2.67 4.67 7.83 10.83 6.00 2.50 36.50 9.50 28.83 4.67 24.67 5.00 5.50 2.67 23.00 20.67 9.67 22.50 2.67 7.67 7.50 26.50 3.50 2. 4.00 1.83 8.17 9.50 11.50 18.33 3.00 8.17 7.17 15.33 12.67 2.17 8.67 12.00 15.67 4.67 19.67 5.50 9.00 3.00 14.67 16.83 14.67 15.17 2.50 9.67 9.00 16.17 8.50 6.33 4.50 2.67 6.83 7.17 9.33 14.17 3.33 6.17 5.33 14.50 7.17 2.50 35.83 8.17 23.50 5.17 18.83 4.67 8.67 2.33 21.50 12.00 5.00 27.50 3.00 7.67 8.83 26.67 2.50 2. 3.50 3.00 5.83 9.00 5.67 19.00 2.33 7.33 6.67 16.00 14.50 2.17 10.83 10.50 15.67 4.50 19.67 6.17 9.83 2.83 18.50 17.00 13.50 13.67 2.67 6.17 10.17 14.67 6.67 6.17 3.17 2.83 4.83 8.00 7.33 10.17 3.83 5.33 6.83 13.17 6.17 2.50 45.67 7.00 32.67 5.67 29.83 5.33 11.00 3.17 31.17 22.67 9.83 40.00 2.83 13.50 10.50 32.50 2.50 2. 4.50 3.00 6.50 11.83 11.50 25.50 2.83 10.00 10.17 23.50 23.50 2.67 9.83 9.83 15.83 5.00 17.33 6.83 10.83 2.50 18.17 15.67 15.00 15.83 3.00 10.50 8.50 13.67 8.00 6.33 5.00 2.67 5.50 6.67 7.33 13.17 2.17 5.33 6.50 13.67 8.33 2.50 36.67 4.67 23.83 4.00 21.17 4.33 5.50 2.67 19.17 15.50 5.33 18.67 2.17 6.83 5.83 24.17 2.67 2. 3.67 2.83 5.00 4.33 5.83 17.67 3.50 6.00 4.33 17.50 13.67 2.50 13.00 10.33 14.83 4.33 15.17 6.83 11.33 2.83 14.17 16.17 13.17 15.67 2.50 9.50 8.00 14.33 3.83 5.50 2.67 2.33 5.67 6.83 8.83 14.83 3.00 6.50 8.83 14.50 7.33 2.50 43.00 10.67 32.50 5.83 28.00 6.33 15.17 2.33 27.33 22.83 9.50 36.17 3.33 9.00 11.33 34.50 2.67 3. 6.50 2.17 7.50 10.17 11.67 26.17 3.00 9.17 10.00 22.00 18.50 2.33 10.351.25 10.670.45 15.031.27 4.650.50 17.750.74 6.830.44 10.330.37 2.680.22 15.520.96 16.170.09 13.820.13 15.070.18 2.650.04 8.770.48 8.670.08 14.550.25 6.551.26 5.830.25 3.780.42 2.670.12 5.200.39 7.830.06 8.130.15 12.700.11 2.770.34 5.580.45 6.750.57 12.880.48 6.730.64 2.200.00 36.730.55 7.020.42 26.630.89 5.120.14 23.331.57 4.730.26 8.250.21 2.620.19 24.030.78 17.550.49 7.620.97 24.950.18 2.700.40 8.780.19 8.650.64 25.920.48 2.870.14 2.770. 4.370.51 2.500.07 6.150.57 8.200.47 8.780.73 20.520.17 2.880.13 7.280.18 6.780.28 17.200.49 15.930.31 2.480.10 46 TABLE XXXII: Classiﬁcation 2-Way accuracies (%) on Things-EEG2. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 65.33 69.83 76.50 60.33 79.00 63.00 70.33 50.33 76.33 82.17 74.17 73.67 50.83 69.00 67.50 74.83 73.00 62.00 52.83 50.17 59.50 67.50 68.83 75.00 49.67 62.17 64.33 70.00 61.33 48.50 84.50 59.67 81.50 59.17 79.00 54.00 57.67 49.50 83.17 76.00 64.00 81.50 50.67 61.00 63.17 84.00 56.00 51. 55.67 51.17 58.00 59.67 63.17 76.00 52.83 57.67 58.50 71.17 70.67 51.50 80.17 75.83 78.67 62.67 80.17 66.17 73.17 53.00 78.17 82.33 76.33 78.83 51.50 63.00 68.83 74.67 58.33 63.00 58.00 34.67 64.33 69.33 64.83 78.33 47.50 60.17 64.83 75.83 66.33 48.17 90.00 65.83 82.17 57.67 81.50 63.17 66.17 53.50 79.67 84.00 64.50 80.17 47.17 64.17 67.00 86.83 51.33 54. 56.17 54.17 57.33 64.33 62.00 79.33 47.50 60.50 58.67 80.67 71.17 53.50 78.17 70.83 74.50 59.33 78.67 63.17 69.83 49.67 68.83 80.67 72.17 73.50 51.83 67.17 68.00 72.67 58.83 63.33 55.00 51.33 56.17 63.00 68.00 72.83 50.33 62.50 64.17 74.33 62.67 49.67 91.17 63.50 89.17 57.67 87.17 52.00 63.83 32.50 84.83 77.67 67.83 73.83 49.33 67.33 65.83 87.17 52.67 50. 60.33 50.83 58.00 62.67 68.50 85.50 48.00 61.33 62.00 79.00 78.67 50.50 66.00 70.67 79.50 56.83 79.17 64.00 71.33 52.33 78.50 79.83 74.67 76.67 53.33 63.33 67.83 74.00 61.67 62.83 58.33 48.50 59.83 66.50 66.33 76.67 47.50 57.67 62.17 73.17 62.67 48.83 90.50 64.50 89.33 58.17 85.50 59.83 68.33 48.83 89.67 82.33 67.83 92.17 51.83 69.83 71.33 87.00 49.50 53. 61.17 52.67 61.00 66.17 68.50 86.17 47.67 65.33 67.00 80.67 79.50 51.67 76.50 72.83 80.67 60.00 78.67 63.83 73.33 51.67 71.83 79.17 77.17 76.33 49.00 67.00 62.67 74.50 66.67 68.50 50.83 48.17 57.83 68.00 66.33 75.67 49.17 60.17 59.00 71.50 62.00 47.33 87.50 62.00 75.67 54.83 78.17 59.67 63.67 50.17 76.50 77.00 64.83 81.67 52.17 71.33 69.00 80.17 49.50 49. 55.50 55.00 62.83 63.83 68.17 76.00 47.67 67.33 65.83 75.83 72.33 48.50 77.17 75.00 80.33 60.17 78.50 63.17 71.17 50.67 70.50 78.67 73.50 76.33 48.33 66.00 66.83 74.83 59.00 59.67 55.83 51.33 60.00 66.33 64.33 75.50 46.67 63.50 65.67 72.33 59.83 49.50 87.50 67.67 83.50 57.67 82.67 58.50 63.83 52.67 83.00 80.00 63.33 86.17 49.50 71.00 69.67 85.83 52.00 50. 55.50 49.67 65.33 66.50 67.50 83.17 48.00 65.83 64.50 78.00 75.00 50.00 74.00 74.33 79.33 58.50 76.83 62.33 70.17 49.17 73.00 81.50 78.33 78.50 49.50 70.17 69.33 73.33 62.33 64.50 54.67 50.00 60.33 64.00 65.83 77.50 50.17 61.17 67.00 74.83 65.67 50.33 88.83 62.33 83.83 58.00 81.00 61.17 68.83 52.00 82.83 78.33 59.17 87.00 51.67 62.83 65.33 86.67 52.17 53. 54.83 52.17 61.67 63.67 61.00 81.83 53.50 60.33 61.50 77.33 76.50 48.17 76.00 69.83 81.00 60.00 77.67 65.33 73.17 50.33 81.67 78.33 75.33 73.67 51.00 66.67 67.50 75.50 61.00 63.50 49.67 51.17 56.67 67.33 69.50 73.50 51.17 57.83 65.50 74.17 64.17 52.00 91.00 65.50 90.17 59.00 86.83 68.00 75.17 51.00 90.00 88.83 65.67 92.50 53.67 74.83 69.50 89.33 54.83 50. 55.67 51.00 61.50 73.00 74.00 86.33 49.33 69.17 67.67 81.67 82.33 51.00 74.00 71.50 79.33 59.00 78.50 64.83 69.67 49.33 80.67 81.00 73.50 77.83 50.33 68.50 66.50 75.17 61.33 65.00 58.17 49.50 61.33 65.00 63.50 76.00 50.50 63.33 63.83 72.83 64.50 48.67 89.00 60.00 81.67 54.00 82.00 55.83 58.83 49.50 81.17 78.00 60.00 81.17 50.17 65.50 63.00 83.83 50.67 51. 57.00 52.50 58.50 63.17 61.67 78.17 53.50 62.83 62.50 78.00 73.67 48.83 76.83 69.67 77.33 53.67 77.50 64.17 72.50 49.17 72.00 79.17 73.83 73.50 49.17 67.50 66.33 75.33 57.50 64.50 55.33 48.67 60.50 65.00 66.67 77.00 51.67 59.00 62.00 75.00 62.00 49.00 92.50 74.17 88.33 58.83 85.67 66.83 72.17 52.50 86.67 88.00 66.33 92.17 47.83 71.67 73.17 90.33 51.33 54. 56.83 49.17 62.50 70.67 68.50 84.17 49.67 67.33 64.50 82.67 79.17 50.67 74.423.67 72.030.38 78.720.86 59.052.13 78.470.65 64.000.91 71.470.39 50.570.22 75.150.93 80.281.08 74.901.35 75.880.89 50.480.45 66.831.16 67.130.39 74.480.12 61.974.80 63.680.55 54.870.75 48.353.15 59.651.31 66.200.99 66.420.49 75.801.19 49.430.95 60.750.25 63.850.95 73.400.29 63.120.48 49.200.32 89.250.60 64.520.56 84.530.94 57.500.94 82.950.72 59.900.19 65.850.49 49.222.46 83.750.74 81.021.10 64.351.28 84.830.43 50.400.55 67.950.25 67.700.21 86.120.65 52.001.27 51.870. 56.871.17 51.830.53 60.670.47 65.370.33 66.301.97 81.670.38 49.771.25 63.770.50 63.270.72 78.500.33 75.900.53 50.430.56 TABLE XXXIII: Classiﬁcation accuracies (%) on SEED. The best accuracies are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S2 S3 S4 S6 S7 S8 S9 S10 S12 S13 S14 Avg. 47 Specialist Models CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 33.68 46.91 45.02 58.93 37.07 58.66 38.66 59.63 41.07 57.13 62.67 48.00 59.13 52.68 34.47 32.40 39.06 47.20 54.10 43.64 53.91 41.42 65.06 59.62 39.16 55.98 48.72 53.87 62.87 31.57 38.14 48.57 36.32 55.76 52.64 57.65 50.71 69.46 54.11 48.23 66.54 59.75 60.77 68.07 34.47 33.02 41.07 50.85 59.70 41.44 60.80 38.19 67.78 50.91 53.78 51.10 55.17 50.36 58.90 38.79 31.58 33.36 44.49 56.87 37.94 32.16 38.35 60.03 61.22 51.66 52.70 44.89 43.86 45.98 33.34 33.70 52.11 38.85 58.35 47.96 56.47 44.99 67.22 52.46 42.97 66.27 49.66 59.12 66.39 29.31 34.32 38.19 38.48 44.62 45.55 55.77 43.40 67.18 53.04 36.27 65.67 46.66 61.01 60.07 41.12 Full Fine-tuning Foundation Models Cross-subject Linear Probing Foundation Models BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 35.59 51.03 48.96 63.97 44.02 47.92 50.96 70.85 52.18 53.67 61.15 55.65 52.97 62.99 35.64 30.39 38.67 61.27 52.75 44.52 34.04 47.53 68.84 53.10 54.69 53.43 48.07 51.21 52.89 44.16 50.65 49.88 49.68 58.21 46.86 51.24 46.39 68.73 51.46 49.35 62.18 44.49 48.67 49.86 55.87 59.11 43.80 41.78 55.96 41.30 51.03 40.25 64.99 49.29 38.73 61.13 37.47 57.62 52.38 50.18 59.89 43.72 41.81 54.49 46.86 50.76 36.11 58.77 43.02 40.25 50.77 47.45 53.91 58.05 45.28 52.38 48.88 57.81 68.99 54.67 60.00 39.78 58.92 52.37 54.65 60.68 49.42 54.47 54.59 36.50 34.08 35.39 34.90 39.20 37.20 36.23 34.43 39.02 40.24 36.20 41.69 37.77 34.80 34.33 34.41 BrainOmni-Tiny 40.33 36.59 36.06 36.52 36.01 40.60 37.03 38.53 36.91 37.96 38.99 36.64 37.99 40.71 39.43 BrainOmni-Base 36.19 38.74 39.50 38.59 41.14 56.50 42.20 49.95 45.83 49.53 51.14 49.02 47.64 47.15 37.73 33.94 44.08 46.17 59.75 53.46 53.77 47.08 70.52 46.87 60.42 66.07 54.40 35.09 64.67 46.50 63.73 44.47 43.62 51.07 44.40 50.55 40.42 51.30 39.72 54.86 60.26 54.29 42.03 53.52 58.10 37.20 49.37 47.97 59.87 46.03 55.48 49.63 50.23 52.95 61.74 54.89 46.90 59.89 43.56 33.66 EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 34.09 33.72 34.55 34.52 33.68 34.62 34.76 35.33 35.85 35.43 34.40 34.16 34.37 34.31 36.58 33.32 42.47 47.91 58.52 43.13 62.02 47.60 63.37 50.75 50.40 58.79 50.96 56.36 66.41 34.16 55.78 47.94 47.27 57.83 45.88 56.05 41.25 66.19 41.30 53.22 64.05 51.86 37.85 61.70 58.80 59.11 43.80 41.78 55.96 41.30 51.03 40.25 64.99 49.29 38.73 61.13 37.47 57.62 52.38 50.18 36.59 41.88 44.39 56.24 43.17 43.02 47.87 68.63 50.60 52.82 66.23 56.32 50.62 57.24 34.93 33.49 37.94 48.63 65.30 41.19 63.29 42.94 70.85 51.16 64.24 60.06 55.23 43.14 58.95 40.98 33.07 35.35 34.18 36.41 35.44 36.15 34.14 36.20 37.35 34.86 37.30 34.86 34.63 34.32 34.96 BrainOmni-Tiny 37.47 38.24 40.39 37.36 40.99 52.55 42.25 49.24 48.08 46.09 51.37 47.14 48.18 48.33 36.36 BrainOmni-Base 36.63 38.84 40.58 37.95 41.00 52.06 42.94 47.14 46.52 47.51 51.06 46.40 46.30 49.60 36.42 30.25 39.07 49.33 58.90 52.50 56.51 48.48 71.22 45.05 58.24 62.82 53.20 40.51 61.75 50.71 33.83 33.89 34.72 35.17 34.86 38.33 35.43 37.20 34.82 36.10 36.91 38.60 35.22 33.92 36.29 33.07 33.22 43.24 33.40 41.40 63.09 37.33 47.05 45.59 49.29 47.15 45.78 35.52 50.41 35. EEGMamba SingLEM LUNA-Base Specialist Models CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 63.57 53.79 40.81 58.27 49.01 60.11 54.37 63.01 68.27 61.29 67.76 40.55 32.02 54.23 33.57 34.47 45.10 37.60 61.48 43.63 33.21 54.85 68.52 75.38 56.71 63.06 53.58 60.94 53.38 39.84 33.54 62.63 35.87 71.63 45.31 38.73 48.97 67.01 67.45 61.42 64.67 54.79 32.16 54.91 40.49 36.76 57.05 45.86 74.88 43.53 37.88 46.24 66.04 60.88 58.44 64.91 50.81 42.43 55.59 56.69 37.30 58.52 45.27 78.09 46.25 35.27 37.02 64.03 67.03 57.86 63.73 54.69 33.01 48.76 52.37 33.55 61.32 40.61 76.14 48.33 40.38 38.90 70.33 65.99 63.53 64.14 53.77 33.84 52.94 39.01 55.22 49.95 40.89 54.50 43.92 66.46 56.62 65.81 61.94 58.32 68.36 51.14 33.09 56.32 72.54 Full Fine-tuning Foundation Models Within-subject (Few-shot) Linear Probing Foundation Models BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 33.27 37.21 38.66 41.62 35.72 34.82 34.69 54.40 69.39 41.97 41.20 44.82 30.86 37.39 39.42 32.62 49.79 41.24 64.11 37.25 40.31 34.14 58.95 69.30 55.93 68.63 51.96 32.45 41.72 47.75 32.05 42.37 41.58 47.87 45.61 38.97 43.75 63.33 55.16 58.53 61.32 51.86 32.82 53.24 36.61 57.98 55.36 39.50 42.30 43.95 59.82 60.21 65.28 62.23 57.98 66.90 51.76 37.39 62.71 75.10 35.48 33.31 36.79 34.40 36.21 40.40 37.59 55.39 53.88 37.78 51.41 38.81 38.87 40.32 36.52 32.12 69.34 43.87 74.02 49.77 47.39 48.35 65.40 64.33 55.00 65.39 54.20 30.25 51.69 86.20 38.70 34.72 35.01 35.34 36.40 33.32 34.38 37.51 38.17 33.38 36.52 35.65 32.66 33.81 35.39 BrainOmni-Tiny 47.29 36.73 39.01 38.76 42.30 54.69 44.19 56.52 53.32 42.83 50.86 48.65 39.29 48.16 58.47 BrainOmni-Base 32.44 39.40 40.54 38.49 43.54 35.66 41.36 56.03 54.58 44.99 53.32 49.95 44.22 47.72 43.84 27.25 58.84 43.28 69.66 50.78 51.68 53.24 63.81 61.58 54.33 62.01 52.90 29.26 50.29 41.09 41.24 34.80 40.44 41.03 39.41 47.08 45.47 41.73 57.05 50.50 57.86 48.91 43.01 43.64 72.95 33.69 43.44 40.87 50.12 41.95 35.25 40.69 57.61 55.75 52.02 63.38 45.39 31.03 56.02 43.65 EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 32.50 32.33 34.42 34.58 35.58 33.04 33.70 34.23 34.58 33.58 35.85 33.22 34.13 33.95 34.39 32.33 52.16 43.49 61.86 32.60 41.47 34.36 66.46 66.89 54.51 63.10 52.77 27.17 41.96 50.33 39.01 53.55 45.36 53.08 41.03 42.30 35.67 63.30 62.40 47.94 64.67 55.07 33.80 44.45 60.23 34.77 55.84 35.97 59.53 50.97 51.82 49.25 68.88 42.36 53.10 66.03 56.32 56.70 63.04 35.90 33.30 40.04 38.89 47.27 45.53 33.55 36.62 51.55 61.68 44.12 60.00 45.75 31.82 34.95 38.46 35.74 59.47 47.90 74.36 45.72 57.40 36.92 65.50 64.03 50.10 63.97 53.16 35.33 46.69 48.42 36.02 32.18 33.27 33.76 35.45 33.12 33.93 35.92 37.18 33.46 35.74 33.59 32.56 33.54 34.49 BrainOmni-Tiny 33.73 38.63 39.84 38.52 44.35 35.13 41.16 54.11 52.77 42.92 49.90 47.49 44.57 46.47 43.58 BrainOmni-Base 32.92 38.38 39.19 39.13 42.97 36.05 41.16 53.17 53.03 43.22 51.27 47.66 45.92 46.21 43.95 39.47 50.06 43.88 57.51 43.92 50.82 46.76 62.43 60.06 50.62 58.63 50.06 33.17 51.13 41.89 35.44 34.69 33.58 32.41 33.90 35.48 33.95 34.46 35.61 34.77 35.92 36.42 34.40 33.38 34.84 35.31 36.74 40.44 42.07 35.07 33.87 38.33 47.49 56.02 49.56 52.94 47.46 32.07 49.46 37.21 EEGMamba SingLEM LUNA-Base 48.91 48.571.34 53.410.12 50.120.43 44.561.40 51.050.97 48.761.23 52.500.85 49.040.90 52.230.92 49.670.38 48.743.41 53.610.61 36.660.26 38.020.03 44.720.18 52.190.04 50.161.48 49.960.35 34.690.10 51.080.77 52.460.05 49.670.38 50.041.03 51.830.07 35.280.04 44.270.11 44.060.26 51.900.15 35.690.04 42.770. 53.38 52.120.47 51.970.26 53.201.39 51.951.06 52.190.30 55.671.63 41.030.54 48.410.56 47.000.92 55.900.09 40.480.44 55.820.39 35.400.15 46.740.39 44.410.12 51.330.27 47.012.01 46.060.68 34.000.16 48.100.65 49.460.14 52.030.10 42.900.42 52.320.39 34.280.44 43.540.14 43.620.15 49.360.03 34.620.05 42.270.19 TABLE XXXIV: Cohens Kappa (%) on SEED. The best metrics are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S2 S4 S5 S6 S7 S8 S10 S11 S12 S13 S14 Avg. 48 Specialist Models CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer -1.19 -0.79 6.58 0.03 -4.14 -0.06 1.95 8.86 4. 37.92 20.03 31.48 15.43 31.17 12.77 47.38 39.23 2.94 20.93 17.19 38.53 9.48 23.44 12.50 25.79 39.56 12.22 40.93 1.21 -2.98 28.65 39.11 10.36 35.85 44.10 21.48 38.18 29.26 34.28 23.18 30.47 44.16 33.66 28.73 36.16 26.52 54.04 30.76 22.86 49.85 39.62 40.90 51.99 51.66 25.92 30.99 27.16 33.05 25.64 38.40 39.94 41.69 27.67 29.11 17.63 16.44 18.86 37.54 21.60 34.60 18.05 50.65 28.22 15.10 49.46 24.57 38.29 49.53 17.28 18.25 33.65 15.69 50.61 29.10 0.00 -4.00 0.00 8.76 -1.03 -6.78 48.50 20.39 41.40 39.97 11.86 16.22 35.20 6.86 6.28 8.23 8. 8.23 7.31 9.62 4.97 Full Fine-tuning Foundation Models Cross-subject Linear Probing Foundation Models 1.56 41.83 29.27 17.28 BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 27.01 22.60 46.05 16.30 21.77 26.73 56.23 27.63 30.68 41.57 33.32 29.51 44.16 8.58 3.63 3.31 -3.51 21.75 53.17 29.02 32.03 29.99 21.74 27.13 29.35 16.43 25.95 25.15 23.81 37.55 19.96 26.93 20.13 52.97 26.71 24.43 43.06 16.90 23.37 24.85 34.02 38.80 16.39 11.96 34.18 12.45 26.12 11.20 47.33 23.35 36.51 28.34 25.72 37.53 13.40 11.00 25.57 21.27 30.93 36.92 18.25 39.91 16.25 11.92 31.87 20.58 25.35 28.61 23.79 36.38 53.53 31.40 39.86 10.03 38.13 28.13 32.22 40.81 24.40 31.96 31.95 3.99 1.76 0.80 1.19 5.54 8.10 2.60 BrainOmni-Tiny 9.71 10.26 BrainOmni-Base 4.48 5.47 11.12 34.75 13.56 24.20 17.94 24.23 26.95 23.37 21.48 21.13 -0.47 46.91 19.50 45.57 17.32 14.62 26.04 15.71 25.28 11.46 26.15 32.52 40.33 31.32 13.33 29.70 36.57 -0.77 6.64 3.53 4.15 8.65 16.86 18.52 39.55 29.61 30.02 21.19 55.73 19.48 40.78 49.07 31.73 24.37 21.21 39.86 18.53 33.08 24.69 24.70 28.88 42.69 32.41 20.56 39.81 15.82 EEGMamba SingLEM LUNA-Base 8.67 3.72 8. 2.11 3.05 9.05 12.69 7.48 1.34 4.76 4.25 9.77 9.79 3.95 7.73 6. 6.35 3.69 4.40 5.97 1.69 5.82 41.75 5.19 8. 8.98 3.09 6.98 1.31 0.97 2. 3.43 1.88 1.54 1.64 0.28 1. 1.31 BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 0.29 1.11 2.77 14.44 21.12 37.67 15.25 43.09 21.87 44.82 25.43 26.05 38.15 26.29 34.50 49.56 0.96 1.04 33.89 22.52 20.11 36.57 18.24 33.63 12.63 49.14 10.73 30.02 46.07 28.10 6.98 38.80 16.39 11.96 34.18 12.45 26.12 11.20 47.33 23.35 5.45 0.73 -0.81 BrainOmni-Tiny 6.19 BrainOmni-Base 5.00 -4.37 0.74 0.78 4.50 -0.47 42.55 38.03 7.26 36.51 28.34 25.72 2.49 22.37 47.98 11.90 44.81 15.14 56.32 26.26 46.42 40.30 33.19 15.32 38.58 12.28 2.15 0.61 5.12 3.41 10.54 10.75 3.49 23.64 38.29 28.32 34.24 23.19 56.74 16.67 37.52 44.27 30.04 11.08 42.67 25.85 4.07 1.73 1.92 2.60 15.05 13.60 15.58 34.33 14.59 13.40 22.13 52.89 25.30 29.52 49.40 34.29 25.31 35.69 7.93 2.85 8.01 8.85 9.48 0.71 0. 2.50 0.59 11.14 28.90 13.68 23.14 21.65 18.74 27.27 20.76 22.04 22.60 11.12 28.15 14.49 19.85 19.03 20.90 26.84 19.53 19.37 24.53 5.48 7.78 3.91 19.68 17.50 23.64 21.02 18.29 EEGMamba SingLEM LUNA-Base 1.97 7.17 12.05 44.75 4.11 6.42 7.33 0.57 25. 2.52 1.66 2.82 6.02 2.34 0.72 41.75 1.26 0. 3.40 3.72 8.98 1.72 1.65 5. 5.06 Specialist Models CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 6.49 4.17 45.65 30.60 11.64 37.66 23.21 40.53 31.45 44.11 52.58 41.78 51.43 11.19 1.81 -0.09 4.91 45.78 50.76 37.22 45.50 32.16 5.86 55.28 49.01 45.52 46.11 30.99 -0.04 33.43 25.04 11.66 31.78 15.54 49.68 34.78 48.42 42.74 37.94 52.45 26.91 -0.05 31.21 31.90 52.78 63.07 34.83 44.69 30.36 41.56 29.98 8.49 23.26 50.20 51.15 42.56 46.92 32.22 9.68 32.98 19.18 48.74 41.32 38.20 47.45 26.68 14.38 34.10 34.99 24.17 27.99 5.76 30.20 7.40 8.36 34.40 58. 0.33 42.15 15.55 17.04 8.88 44.12 57.39 17.03 7.77 36.14 19.52 62.19 14.33 37.68 18.25 67.04 18.38 4.17 42.24 11.61 64.09 21.92 10.92 1.42 2.60 1.53 0.00 0.12 Full Fine-tuning Foundation Models Within-subject (Few-shot) Linear Probing Foundation Models 9.54 5.40 3.09 10.81 9.01 BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM 3.47 5.62 12.56 8.27 24.56 12.04 46.12 6.51 13.30 12.59 21.81 17.62 31.37 54.10 13.27 11.79 17.20 1.91 -0.19 38.09 54.07 34.16 52.98 27.82 0.83 -1.31 15.30 44.71 32.41 38.05 41.84 27.94 -1.62 13.64 15.60 39.68 40.17 47.60 43.31 37.45 50.27 27.85 37.28 33.44 8.02 1.61 6.54 0.05 3.17 54.04 16.20 60.97 24.49 21.52 22.53 47.75 46.43 32.73 47.91 31.34 -1.24 2.14 3.59 1.45 8.10 5.11 BrainOmni-Tiny 21.25 8.86 BrainOmni-Base -1.48 38.30 15.29 54.37 25.61 28.25 29.47 45.32 42.20 31.66 42.93 29.68 -8.43 8.87 10.97 11.70 2.14 12.45 16.04 11.51 25.38 11.98 0.13 6.89 8.26 13.35 21.63 30.59 4.22 44.17 62.50 4.71 10.51 28.23 79.29 4.42 2.95 0.94 0.39 13.21 31.96 16.30 34.49 29.84 14.21 26.16 23.31 10.12 22.37 37.49 11.81 33.68 31.68 17.51 29.96 25.13 16.63 21.57 15.49 15.04 26.34 10.56 21.27 18.30 12.59 35.25 26.05 36.74 23.64 14.63 15.01 59.39 33.98 14.87 3.40 -2.02 0.44 1.10 7.72 8.64 -2.82 -0.72 EEGMamba SingLEM LUNA-Base 10.42 35.99 33.39 28.52 45.18 18. 2.86 8.74 11.32 3.01 8.30 7.97 32.72 30.65 10.77 27.16 -4. -1.83 0.80 4.13 4.37 6.10 7. 7.03 4.87 BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM -1.19 -1.45 8.53 1.96 0.11 3.87 4.10 BrainOmni-Tiny 0.24 BrainOmni-Base -0.84 9.60 2.89 2.62 EEGMamba SingLEM LUNA-Base 3. 1.84 2.35 8.71 3.19 -1.47 0.64 1.08 3.10 1.19 -8.03 2.55 1.35 -0.21 0.30 49.41 50.41 32.19 44.69 28.68 44.60 43.49 22.27 46.96 32. -0.40 -1.46 1.80 1.71 28.00 15.50 42.77 12.99 30.47 18.44 29.53 11.00 14.12 34.03 9.79 1.28 39.64 22.48 61.46 17.63 36.53 0.27 0.76 -1.75 3.56 7.89 7.92 4.82 8.82 7.65 25.27 16.15 36.23 15.35 26.88 19.74 43.24 40.04 25.97 37.99 25.38 1.77 1.05 2.07 4.71 2.18 20.50 33.92 24.34 29.71 21.72 7.21 5.87 0.86 1.50 13.92 24.71 17.55 39.95 39.23 26.26 27.23 24.11 53.19 12.44 29.88 49.02 34.42 35.02 44.35 3.76 3.23 6.84 20.94 17.82 4.46 21.22 21.99 5.59 0.97 1.50 0.16 3.61 11.40 30.73 29.05 14.65 24.95 21.37 17.07 19.85 14.92 11.40 29.29 29.41 15.04 26.99 21.59 19.17 19.43 15.52 27.47 11.77 2.14 0.07 5.16 24.28 27.06 42.54 16.44 40.05 18.68 47.90 46.24 25.31 46.27 30.06 0.26 0.35 3.51 0.41 -1.46 11.00 13.29 3.06 16.04 14.13 0.14 10.01 8. 1.63 1.61 -0.16 0.00 4.76 -1.19 3.40 1.54 0.84 1.50 3.48 5. 3.95 22.99 22.931.95 29.870.15 25.390.62 16.772.09 26.421.49 23.211.81 28.701.23 23.711.38 28.391.39 24.670.59 23.065.22 30.350.94 4.790.42 5.960.06 16.970.31 28.110.06 24.952.30 24.830.51 1.750.16 26.591.18 28.630.07 24.670.59 24.931.58 27.970.11 2.320.13 16.300.16 15.950.40 27.840.22 3.250.06 14.030.34 30.20 28.070.71 28.040.39 29.992.00 28.141.58 28.410.45 33.672.45 11.710.81 22.810.90 20.591.34 34.010.13 10.740.66 33.960.59 3.210.20 20.190.58 16.640.19 27.160.41 20.603.09 19.150. 1.000.25 22.230.92 24.360.22 27.820.14 14.480.63 28.730.59 1.430.55 15.310.20 15.430.21 24.180.05 1.940.08 13.500.27 TABLE XXXV: Classiﬁcation accuracies (%) on Nakanishi2015. The best accuracies are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject (LOSO)"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) TRCA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base TRCA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 91.67 92.78 56.85 62.59 29.26 93.33 22.41 85.56 53.33 48.33 72.59 64.63 73.33 8.70 45.56 27.41 66.30 13.15 7.96 29.63 49.44 22.96 51.67 74.63 13.70 10.19 60.19 15.74 18.89 11.85 8.89 97.22 15.74 33.33 5.56 31.48 17.59 40.74 73.15 69.44 61.11 40.74 55.56 49.07 12.96 60.19 25.00 30.56 25.93 7. 7.41 65.74 57.41 42.59 86.11 17.59 13.89 60.19 19.44 12.96 12.96 12.04 72.78 78.70 29.63 42.59 19.63 86.85 12.59 62.96 40.37 37.22 61.67 57.96 47.59 7.41 39.63 31.67 44.07 14.26 7.04 18.70 26.48 22.41 42.96 59.44 11.48 9.26 42.78 15.37 12.96 13.89 7.96 94.44 27.78 11.11 9.26 10.19 17.59 8.33 16.67 50.93 26.85 21.30 16.67 12.04 7.41 24.07 12.04 19.44 10.19 11. 8.33 51.85 19.44 19.44 45.37 17.59 12.96 24.07 8.33 15.74 16.67 10.19 85.00 92.96 71.11 81.48 42.59 94.81 25.56 90.37 79.44 83.15 77.04 92.78 84.44 12.59 82.59 27.04 68.52 43.15 8.89 50.93 80.19 53.15 57.41 76.85 12.59 10.37 59.81 17.59 9.81 17.04 8.33 100.00 12.04 38.89 11.11 27.78 54.63 35.19 86.11 92.59 74.07 54.63 71.30 38.89 12.04 76.85 16.67 25.93 26.85 9. 15.74 79.63 50.00 26.85 71.30 17.59 10.19 76.85 12.96 16.67 13.89 7.41 100.00 100.00 83.89 98.89 55.00 100.00 45.37 100.00 87.78 98.52 98.33 100.00 99.63 14.44 98.89 67.04 76.11 35.93 8.33 70.37 82.22 65.74 88.33 99.44 17.59 12.96 93.89 27.96 22.04 29.26 9.81 100.00 84.26 43.52 52.78 76.85 96.30 49.07 100.00 87.96 92.59 90.74 92.59 80.56 17.59 96.30 75.00 44.44 44.44 9. 28.70 83.33 69.44 64.81 95.37 20.37 12.04 96.30 31.48 17.59 20.37 11.11 99.44 99.63 36.48 87.59 41.67 99.63 24.63 99.44 45.00 73.70 90.74 87.78 81.11 10.00 69.81 59.63 59.81 22.22 9.81 59.26 60.37 61.11 65.74 82.59 8.70 10.19 74.81 32.59 14.81 14.81 10.56 100.00 95.37 82.41 95.37 94.44 97.22 55.56 98.15 90.74 96.30 94.44 81.48 77.78 8.33 93.52 88.89 47.22 17.59 11. 21.30 88.89 78.70 50.93 44.44 25.93 9.26 93.52 40.74 17.59 19.44 10.19 100.00 100.00 92.96 99.63 63.15 100.00 45.37 100.00 87.04 100.00 97.96 98.52 99.63 19.26 99.63 64.81 78.52 56.48 8.70 84.26 88.15 82.96 92.22 100.00 27.41 15.93 91.11 30.74 22.04 20.74 9.44 100.00 89.81 87.04 94.44 83.33 100.00 44.44 100.00 95.37 98.15 98.15 96.30 87.96 14.81 99.07 86.11 70.37 48.15 10. 48.15 67.59 89.81 88.89 96.30 33.33 8.33 99.07 35.19 34.26 32.41 9.26 99.44 99.44 80.37 95.56 54.07 100.00 32.78 98.89 100.00 90.93 100.00 61.30 100.00 53.33 99.44 99.44 84.26 97.78 50.37 100.00 40.37 99.44 83.15 91.48 93.70 97.78 95.56 16.11 86.11 59.07 68.15 42.78 8.52 61.11 76.67 61.30 76.30 96.67 20.00 11.67 81.30 26.85 15.37 21.30 8. 100.00 85.19 58.33 72.22 85.19 92.59 41.67 99.07 85.19 92.59 95.37 95.37 81.48 12.96 96.30 35.19 33.33 48.15 6.48 30.56 82.41 89.81 52.78 66.67 38.89 7.41 96.30 17.59 18.52 23.15 10.19 99.26 92.41 97.96 96.30 99.07 96.85 16.11 96.48 55.19 87.22 55.19 9.07 79.07 92.59 74.07 83.33 87.22 27.96 7.04 70.19 27.96 15.37 21.11 8.89 100.00 100.00 65.74 85.19 87.96 100.00 60. 100.00 97.22 100.00 100.00 99.07 93.52 12.04 100.00 71.30 47.22 57.41 10.19 60.19 93.52 93.52 43.52 99.07 34.26 11.11 100.00 25.93 15.74 17.59 5.56 99.44 82.59 82.22 97.78 96.30 90.37 10.93 86.30 66.11 82.04 18.70 8.33 65.19 58.70 35.74 93.52 92.41 17.22 10.37 89.81 29.63 29.07 11.11 11.85 97.22 89.81 40.74 19.44 57.41 68.52 37.04 100.00 92.59 59.26 92.59 73.15 39.81 7.41 91.67 65.74 77.78 18.52 5. 41.67 90.74 54.63 84.26 95.37 12.96 5.56 91.67 20.37 39.81 15.74 9.26 94.07 95.880.18 69.610.86 85.120.94 46.340.34 97.180.13 33.601.08 92.940.30 72.353.04 79.180.73 87.350.40 88.313.30 85.390.60 12.840.68 78.330.23 50.881.99 70.080.94 33.541.23 8.520.22 57.614.18 68.313.34 53.270.83 72.391.75 85.474.26 17.410.28 10.880.58 73.770.66 24.940.15 17.820.03 17.900.22 9.340.34 98.77 66.674.00 51.232.02 49.491.96 61.631.19 71.601.90 41.363.07 85.910.29 84.671.48 77.882.14 76.441.48 75.728.11 62.351.15 11.731.26 82.000.52 52.881.29 44.030.15 33.022.63 8.950. 29.122.45 78.195.09 66.980.50 52.671.24 77.783.81 24.281.77 10.081.72 82.000.52 23.562.52 20.990.50 19.140.91 9.471.72 TABLE XXXVI: Cohens Kappa (%) on Nakanishi2015. The best metrics are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 Avg."
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning Cross-subject (LOSO)"
        },
        {
            "title": "Foundation\nModels",
            "content": "Full Fine-tuning"
        },
        {
            "title": "Foundation\nModels",
            "content": "Within-subject (Few-shot) TRCA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base TRCA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM BrainOmni-Tiny BrainOmni-Base EEGMamba SingLEM LUNA-Base 90.91 92.12 52.93 59.19 22.83 92.73 15.35 84.24 49.09 43.64 70.10 61.41 70.91 0.40 40.61 20.81 63.23 5.25 -0.40 23.23 44.85 15.96 47.27 72.32 5.86 2.02 56.57 8.08 11.52 3.84 0.61 96.97 8.08 27.27 -3.03 25.25 10.10 35.35 70.71 66.67 57.58 35.35 51.52 44.44 5.05 56.57 18.18 24.24 19.19 -1. -1.01 62.63 53.54 37.37 84.85 10.10 6.06 56.57 12.12 5.05 5.05 4.04 70.30 76.77 23.23 37.37 12.32 85.66 4.65 59.60 34.95 31.52 58.18 54.14 42.83 -1.01 34.14 25.45 38.99 6.46 -1.41 11.31 19.80 15.35 37.78 55.76 3.43 1.01 37.58 7.68 5.05 6.06 -0.40 93.94 21.21 3.03 1.01 2.02 10.10 0.00 9.09 46.46 20.20 14.14 9.09 4.04 -1.01 17.17 4.04 12.12 2.02 3. 0.00 47.47 12.12 12.12 40.40 10.10 5.05 17.17 0.00 8.08 9.09 2.02 83.64 92.32 68.48 79.80 37.37 94.34 18.79 89.49 77.58 81.62 74.95 92.12 83.03 4.65 81.01 20.40 65.66 37.98 0.61 46.46 78.38 48.89 53.54 74.75 4.65 2.22 56.16 10.10 1.62 9.49 0.00 100.00 4.04 33.33 3.03 21.21 50.51 29.29 84.85 91.92 71.72 50.51 68.69 33.33 4.04 74.75 9.09 19.19 20.20 1. 8.08 77.78 45.45 20.20 68.69 10.10 2.02 74.75 5.05 9.09 6.06 -1.01 100.00 100.00 82.42 98.79 50.91 100.00 40.40 100.00 86.67 98.38 98.18 100.00 99.60 6.67 98.79 64.04 73.94 30.10 0.00 67.68 80.61 62.63 87.27 99.39 10.10 5.05 93.33 21.41 14.95 22.83 1.62 100.00 82.83 38.38 48.48 74.75 95.96 44.44 100.00 86.87 91.92 89.90 91.92 78.79 10.10 95.96 72.73 39.39 39.39 1. 22.22 81.82 66.67 61.62 94.95 13.13 4.04 95.96 25.25 10.10 13.13 3.03 99.39 99.60 30.71 86.46 36.36 99.60 17.78 99.39 40.00 71.31 89.90 86.67 79.39 1.82 67.07 55.96 56.16 15.15 1.62 55.56 56.77 57.58 62.63 81.01 0.40 2.02 72.53 26.46 7.07 7.07 2.42 100.00 94.95 80.81 94.95 93.94 96.97 51.52 97.98 89.90 95.96 93.94 79.80 75.76 0.00 92.93 87.88 42.42 10.10 3. 14.14 87.88 76.77 46.46 39.39 19.19 1.01 92.93 35.35 10.10 12.12 2.02 100.00 100.00 92.32 99.60 59.80 100.00 40.40 100.00 85.86 100.00 97.78 98.38 99.60 11.92 99.60 61.62 76.57 52.53 0.40 82.83 87.07 81.41 91.52 100.00 20.81 8.28 90.30 24.44 14.95 13.54 1.21 100.00 88.89 85.86 93.94 81.82 100.00 39.39 100.00 94.95 97.98 97.98 95.96 86.87 7.07 98.99 84.85 67.68 43.43 2. 43.43 64.65 88.89 87.88 95.96 27.27 0.00 98.99 29.29 28.28 26.26 1.01 99.39 99.39 78.59 95.15 49.90 100.00 26.67 98.79 100.00 90.10 100.00 57.78 100.00 49.09 99.39 99.39 82.83 97.58 45.86 100.00 34.95 99.39 81.62 90.71 93.13 97.58 95.15 8.48 84.85 55.35 65.25 37.58 0.20 57.58 74.55 57.78 74.14 96.36 12.73 3.64 79.60 20.20 7.68 14.14 0. 100.00 83.84 54.55 69.70 83.84 91.92 36.36 98.99 83.84 91.92 94.95 94.95 79.80 5.05 95.96 29.29 27.27 43.43 -2.02 24.24 80.81 88.89 48.48 63.64 33.33 -1.01 95.96 10.10 11.11 16.16 2.02 99.19 91.72 97.78 95.96 98.99 96.57 8.48 96.16 51.11 86.06 51.11 0.81 77.17 91.92 71.72 81.82 86.06 21.41 -1.41 67.47 21.41 7.68 13.94 0.61 100.00 100.00 62.63 83.84 86.87 100.00 56. 100.00 96.97 100.00 100.00 98.99 92.93 4.04 100.00 68.69 42.42 53.54 2.02 56.57 92.93 92.93 38.38 98.99 28.28 3.03 100.00 19.19 8.08 10.10 -3.03 99.39 81.01 80.61 97.58 95.96 89.49 2.83 85.05 63.03 80.40 11.31 0.00 62.02 54.95 29.90 92.93 91.72 9.70 2.22 88.89 23.23 22.63 3.03 3.84 96.97 88.89 35.35 12.12 53.54 65.66 31.31 100.00 91.92 55.56 91.92 70.71 34.34 -1.01 90.91 62.63 75.76 11.11 -3. 36.36 89.90 50.51 82.83 94.95 5.05 -3.03 90.91 13.13 34.34 8.08 1.01 93.54 95.510.19 66.850.94 83.771.03 41.460.37 96.920.14 27.561.18 92.300.32 69.833.32 77.280.80 86.200.44 87.253.60 84.060.66 4.920.74 76.360.25 46.422.17 67.361.02 27.501.34 0.200.24 53.764.57 65.433.64 49.020.91 69.881.91 84.154.65 9.900.31 2.780.63 71.380.72 18.110.16 10.350.03 10.440.24 1.100.37 98.65 63.644.36 46.802.20 44.892.14 58.141.30 69.022.08 36.033.34 84.620.32 83.281.61 75.872.34 74.301.61 73.518.85 58.921.26 3.701.37 80.360.57 48.601.41 38.950.16 26.942.87 0.670. 22.672.67 76.215.56 63.970.55 48.371.36 75.764.16 17.401.93 1.911.87 80.360.57 16.612.75 13.800.55 11.780.99 1.231.87 51 TABLE XXXVII: Classiﬁcation accuracies (%) on EEGMat. The best accuracies are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S2 S3 S5 S6 S7 S8 S9 S11 S12 S13 S14 S15 S17 S18 Cross-subject Within-subject (Few-shot) Specialist Models CSP+LDA 83.33 50.00 50.00 50.00 100.00 53.33 93.33 80.00 56.67 76.67 73.33 46.67 50.00 50.00 50.00 76.67 70.00 50.00 93.33 EEGNet 58.89 51.11 50.00 94.44 90.00 54.44 63.33 61.11 70.00 83.33 85.56 57.78 53.33 40.00 48.89 65.56 46.67 63.33 84.44 ShallowConv 68.89 58.89 61.11 75.56 86.67 57.78 86.67 66.67 65.56 91.11 94.44 83.33 56.67 47.78 53.33 63.33 74.44 70.00 97.78 LMDA CNN-T 68.89 58.89 47.78 91.11 82.22 81.11 63.33 55.56 71.11 85.56 75.56 58.89 38.89 61.11 55.56 70.00 50.00 75.56 75.56 68.89 67.78 53.33 57.78 74.44 73.33 70.00 62.22 81.11 74.44 84.44 73.33 36.67 42.22 48.89 62.22 83.33 70.00 65.56 DeFormer 77.78 57.78 54.44 82.22 94.44 50.00 87.78 73.33 65.56 85.56 92.22 76.67 45.56 40.00 61.11 65.56 71.11 92.22 64.44 Conformer 78.89 64.44 55.56 71.11 88.89 55.56 90.00 64.44 65.56 76.67 100.00 88.89 51.11 47.78 53.33 61.11 74.44 64.44 92.22 Full Fine-tuning BENDR 48.89 52.22 61.11 52.22 46.67 50.00 43.33 45.56 66.67 62.22 41.11 68.89 48.89 47.78 58.89 56.67 53.33 56.67 62.22 BIOT 84.44 54.44 54.44 80.00 76.67 54.44 60.00 62.22 75.56 78.89 81.11 71.11 48.89 64.44 55.56 70.00 77.78 92.22 86. LaBraM 67.78 68.89 70.00 74.44 81.11 62.22 63.33 60.00 64.44 77.78 66.67 65.56 41.11 57.78 63.33 61.11 62.22 53.33 53.33 Neuro-GPT 82.22 82.22 51.11 76.67 77.78 58.89 88.89 70.00 78.89 85.56 93.33 81.11 43.33 42.22 54.44 63.33 81.11 81.11 94.44 EEGPT 54.44 62.22 53.33 68.89 43.33 51.11 61.11 48.89 64.44 70.00 53.33 54.44 37.78 50.00 58.89 65.56 60.00 61.11 61. Foundation Models CBraMod 75.56 56.67 65.56 56.67 64.44 64.44 58.89 60.00 66.67 77.78 75.56 64.44 31.11 55.56 52.22 55.56 73.33 81.11 50.00 TFM 67.78 40.00 55.56 78.89 78.89 57.78 56.67 53.33 70.00 78.89 70.00 58.89 32.22 36.67 43.33 82.22 61.11 62.22 81.11 BrainOmni-Tiny 60.00 51.11 70.00 70.00 54.44 56.67 50.00 55.56 55.56 65.56 47.78 60.00 36.67 47.78 63.33 61.11 57.78 48.89 57. BrainOmni-Base 60.00 53.33 51.11 54.44 51.11 55.56 57.78 50.00 52.22 43.33 54.44 53.33 57.78 46.67 51.11 46.67 46.67 56.67 46.67 EEGMamba 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 SingLEM 50.00 48.89 50.00 51.11 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 51.11 50.00 50.00 50.00 50.00 LUNA-Base 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 BENDR 42.22 55.56 43.33 51.11 50.00 45.56 53.33 48.89 54.44 60.00 48.89 48.89 57.78 45.56 48.89 58.89 62.22 50.00 56.67 BIOT 55.56 57.78 61.11 74.44 63.33 46.67 82.22 63.33 76.67 64.44 74.44 84.44 41.11 44.44 64.44 58.89 63.33 70.00 75.56 LaBraM 71.11 64.44 72.22 58.89 65.56 55.56 66.67 68.89 71.11 68.89 62.22 65.56 48.89 51.11 67.78 67.78 64.44 61.11 68.89 Neuro-GPT 75.56 72.22 51.11 75.56 70.00 74.44 87.78 70.00 72.22 84.44 80.00 60.00 51.11 32.22 55.56 58.89 73.33 71.11 87.78 Linear Probing Foundation Models EEGPT 60.00 61.11 53.33 73.33 55.56 51.11 55.56 50.00 71.11 80.00 43.33 56.67 33.33 48.89 58.89 66.67 53.33 70.00 70.00 CBraMod 58.89 63.33 63.33 58.89 54.44 48.89 63.33 52.22 82.22 62.22 43.33 54.44 36.67 67.78 58.89 54.44 71.11 76.67 72.22 TFM 63.33 51.11 54.44 80.00 70.00 63.33 55.56 54.44 75.56 72.22 41.11 57.78 22.22 47.78 57.78 78.89 63.33 50.00 87.78 BrainOmni-Tiny 55.56 53.33 60.00 74.44 64.44 56.67 52.22 55.56 68.89 67.78 71.11 71.11 44.44 45.56 64.44 64.44 61.11 60.00 74. BrainOmni-Base 50.00 54.44 48.89 52.22 50.00 54.44 52.22 54.44 52.22 43.33 55.56 47.78 48.89 53.33 44.44 50.00 52.22 51.11 48.89 EEGMamba 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 51.11 SingLEM 40.00 53.33 55.56 42.22 45.56 48.89 44.44 66.67 50.00 44.44 37.78 48.89 55.56 42.22 54.44 58.89 37.78 48.89 47.78 LUNA-Base 50.00 51.11 50.00 51.11 50.00 55.56 50.00 47.78 50.00 48.89 50.00 50.00 50.00 50.00 50.00 50.00 55.56 48.89 50.00 Specialist Models CSP+LDA 91.67 100.00 91.67 100.00 91.67 100.00 100.00 100.00 100.00 75.00 91.67 91.67 100.00 91.67 100.00 100.00 100.00 100.00 91.67 EEGNet 55.56 50.00 61.11 75.00 61.11 72.22 55.56 33.33 75.00 50.00 75.00 52.78 86.11 52.78 63.89 88.89 80.56 55.56 75. ShallowConv 41.67 52.78 61.11 63.89 61.11 69.44 75.00 61.11 61.11 52.78 55.56 66.67 83.33 83.33 66.67 83.33 58.33 69.44 77.78 LMDA CNN-T 44.44 61.11 52.78 80.56 27.78 30.56 52.78 33.33 44.44 44.44 44.44 77.78 58.33 50.00 63.89 44.44 61.11 55.56 55.56 50.00 50.00 50.00 61.11 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50. DeFormer 58.33 58.33 50.00 55.56 36.11 30.56 61.11 41.67 41.67 61.11 47.22 55.56 47.22 47.22 50.00 30.56 58.33 55.56 66.67 Conformer 63.89 97.22 86.11 91.67 77.78 50.00 61.11 72.22 63.89 75.00 69.44 61.11 72.22 63.89 63.89 58.33 77.78 55.56 77.78 BENDR 47.22 58.33 47.22 58.33 55.56 52.78 58.33 47.22 61.11 61.11 36.11 66.67 55.56 63.89 55.56 55.56 52.78 50.00 52. Full Fine-tuning BIOT 58.33 77.78 72.22 97.22 88.89 52.78 88.89 86.11 100.00 91.67 80.56 88.89 58.33 100.00 88.89 100.00 91.67 100.00 88.89 LaBraM 66.67 77.78 47.22 63.89 55.56 61.11 58.33 27.78 75.00 58.33 75.00 69.44 63.89 75.00 61.11 80.56 86.11 52.78 75.00 Neuro-GPT 58.33 63.89 83.33 91.67 69.44 55.56 80.56 30.56 63.89 63.89 69.44 86.11 80.56 80.56 66.67 55.56 86.11 69.44 91.67 EEGPT 44.44 47.22 61.11 66.67 55.56 52.78 61.11 61.11 77.78 58.33 75.00 61.11 72.22 80.56 77.78 86.11 72.22 58.33 77.78 Foundation Models CBraMod 47.22 86.11 80.56 66.67 55.56 91.67 80.56 83.33 86.11 100.00 72.22 83.33 94.44 97.22 69.44 80.56 100.00 94.44 86. TFM 63.89 80.56 50.00 86.11 97.22 83.33 75.00 75.00 83.33 58.33 66.67 86.11 72.22 83.33 86.11 88.89 94.44 77.78 83.33 BrainOmni-Tiny 44.44 77.78 52.78 58.33 58.33 50.00 52.78 25.00 55.56 75.00 52.78 63.89 55.56 61.11 58.33 52.78 66.67 47.22 77.78 BrainOmni-Base 55.56 55.56 50.00 47.22 50.00 50.00 50.00 52.78 58.33 44.44 50.00 66.67 52.78 44.44 52.78 58.33 41.67 52.78 38.89 EEGMamba 50.00 50.00 50.00 50.00 50.00 50.00 52.78 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 52.78 50.00 50.00 50. SingLEM 50.00 55.56 50.00 50.00 50.00 58.33 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 52.78 50.00 50.00 50.00 50.00 LUNA-Base 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 61.11 50.00 50.00 50.00 50.00 50.00 61.11 50.00 50.00 BENDR 50.00 36.11 55.56 36.11 58.33 50.00 47.22 41.67 55.56 36.11 52.78 58.33 47.22 36.11 52.78 38.89 52.78 50.00 66. BIOT 52.78 69.44 63.89 86.11 66.67 61.11 86.11 63.89 86.11 86.11 86.11 91.67 50.00 88.89 69.44 88.89 86.11 80.56 77.78 LaBraM 80.56 66.67 55.56 69.44 58.33 86.11 72.22 47.22 91.67 69.44 69.44 66.67 72.22 52.78 61.11 77.78 77.78 72.22 80.56 Neuro-GPT 58.33 58.33 83.33 83.33 72.22 61.11 75.00 33.33 63.89 86.11 69.44 77.78 80.56 83.33 63.89 61.11 77.78 66.67 83. Linear Probing Foundation Models EEGPT 36.11 63.89 58.33 77.78 55.56 50.00 66.67 58.33 77.78 61.11 77.78 75.00 80.56 88.89 66.67 91.67 75.00 50.00 80.56 CBraMod 63.89 63.89 50.00 55.56 66.67 61.11 66.67 52.78 50.00 61.11 61.11 72.22 58.33 61.11 63.89 44.44 72.22 61.11 69. TFM 38.89 44.44 63.89 63.89 69.44 55.56 63.89 58.33 63.89 44.44 66.67 52.78 55.56 58.33 50.00 55.56 61.11 52.78 66.67 BrainOmni-Tiny 44.44 69.44 50.00 58.33 55.56 41.67 58.33 33.33 63.89 77.78 52.78 55.56 58.33 58.33 58.33 58.33 72.22 47.22 77.78 BrainOmni-Base 41.67 47.22 41.67 52.78 63.89 47.22 50.00 47.22 52.78 47.22 41.67 63.89 61.11 58.33 63.89 61.11 47.22 47.22 50.00 EEGMamba 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 55.56 50.00 50.00 50.00 50. SingLEM 58.33 61.11 47.22 61.11 36.11 41.67 36.11 36.11 50.00 61.11 44.44 41.67 30.56 58.33 55.56 41.67 55.56 61.11 55.56 LUNA-Base 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 52 TABLE XXXVIII: Classiﬁcation accuracies (%) on EEGMat. The best accuracies are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S19 S20 S22 S23 S24 S25 S26 S28 S29 S30 S31 S32 S34 S35 Avg. Specialist Models CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 96.67 90.00 70.00 70.00 36.67 56.67 50.00 83.33 60.00 93.33 50.00 50.00 63.33 70.00 56.67 80.00 96.67 92.22 85.56 64.44 64.44 65.56 67.78 68.89 61.11 71.11 62.22 65.56 56.67 60.00 67.78 62.22 78.89 81.11 66.600.63 94.44 73.33 77.78 76.67 81.11 84.44 86.67 70.00 60.00 92.22 52.22 57.78 56.67 62.22 63.33 72.22 78.89 72.221.24 82.22 65.56 64.44 91.11 71.11 50.00 73.33 71.11 77.78 62.22 60.00 73.33 43.33 51.11 70.00 87.78 67.78 67.471.21 90.00 88.89 66.67 93.33 75.56 73.33 68.83 71.11 71.11 62.22 51.11 83.33 72.22 84.44 87.78 90.00 67.78 70.772.49 97.78 75.56 82.22 77.78 83.33 83.33 82.22 70.00 58.89 83.33 50.00 62.22 62.22 68.89 56.67 74.44 75.56 71.730.37 94.44 61.11 75.56 61.11 85.53 76.67 85.56 71.11 58.89 90.00 50.00 52.22 53.33 65.53 64.44 70.00 77.78 70.490. 67.41 Full Fine-tuning Foundation Models Cross-subject Linear Probing Foundation Models BIOT EEGPT LaBraM BENDR CBraMod Neuro-GPT 55.56 56.67 51.11 56.67 46.67 60.00 56.67 47.78 65.56 50.00 61.11 53.33 54.44 48.89 52.22 61.11 54.44 54.320.71 96.67 76.67 76.67 78.89 72.22 77.78 77.78 65.56 67.78 74.44 55.56 80.00 38.89 70.00 65.55 77.78 66.67 70.771.49 64.44 83.33 58.89 83.33 75.56 68.89 78.83 65.56 72.22 61.11 56.67 60.00 40.00 60.00 67.78 77.78 77.78 65.741.61 98.89 70.00 76.67 71.11 80.00 78.89 71.11 67.78 63.33 86.67 52.22 74.44 48.89 56.67 77.78 76.67 76.67 72.621.35 82.22 63.33 62.22 63.33 63.33 56.67 60.00 61.11 68.89 54.44 54.44 47.78 42.22 50.00 56.67 70.00 52.22 58.021.02 82.22 65.56 73.33 98.89 86.67 62.22 81.11 60.00 63.33 91.11 54.44 90.00 70.00 64.44 68.89 92.22 73.33 68.430.72 87.78 71.11 67.78 75.56 64.44 64.44 62.22 63.33 66.67 64.44 52.22 78.89 44.44 54.44 67.78 68.89 48.89 63.021.95 BrainOmni-Tiny 60.00 75.56 47.78 67.78 58.89 61.11 56.67 51.11 73.33 51.11 48.89 48.89 47.78 60.00 53.33 64.44 73.33 57.500.80 BrainOmni-Base 44.44 42.22 52.22 54.44 51.11 48.89 64.44 41.11 56.67 53.33 61.11 46.67 44.44 50.00 51.11 52.22 51.11 51.510.76 48.89 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 49.970.04 50.00 50.00 48.89 50.00 50.00 46.67 46.67 50.00 50.00 52.22 50.00 48.89 50.00 50.00 50.00 50.00 50.00 49.850.16 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.000.00 LUNA-Base EEGMamba SingLEM TFM BIOT EEGPT LaBraM BENDR CBraMod Neuro-GPT 52.22 53.33 57.78 63.33 40.00 56.67 52.22 50.00 53.33 52.22 46.67 50.00 53.33 42.22 55.56 52.22 41.11 51.511.57 97.78 78.89 66.67 87.73 70.00 74.44 65.56 68.89 65.56 78.89 47.78 71.11 44.44 64.44 51.11 78.89 57.78 66.451.24 88.89 74.44 62.22 77.78 54.44 54.44 57.78 66.67 72.22 46.67 48.89 57.78 51.11 52.22 70.00 86.67 77.78 64.480.56 98.89 82.22 64.44 63.33 77.78 70.00 77.78 57.78 51.11 87.78 46.67 87.78 57.78 58.89 64.44 75.56 43.33 68.581.89 82.22 62.22 66.67 66.67 54.44 50.00 58.89 64.44 70.00 55.56 56.67 58.89 41.11 52.22 54.44 73.33 57.78 59.380.53 70.00 55.56 45.56 67.78 58.89 68.89 52.22 63.33 67.78 64.44 50.00 58.89 44.44 57.78 72.22 70.00 61.11 60.340.27 93.33 66.67 52.22 80.00 71.11 71.11 53.33 64.44 70.00 64.44 48.89 70.00 44.44 48.89 76.67 74.44 51.11 62.440.09 BrainOmni-Tiny 72.22 73.33 61.11 80.00 66.67 73.33 56.67 55.56 61.11 54.44 62.22 57.78 42.22 62.22 62.22 68.89 74.44 62.500.50 BrainOmni-Base 48.89 56.67 50.00 43.33 51.11 47.78 48.89 41.11 48.89 52.22 48.89 51.11 57.78 53.33 48.89 52.22 48.89 50.400.69 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 51.11 50.00 50.00 50.00 50.00 50.00 50.00 50.060.09 42.22 58.89 46.67 73.33 56.67 54.44 55.56 54.44 66.67 47.78 55.56 41.11 54.44 45.56 48.89 43.33 45.56 50.400.43 55.56 44.44 51.11 43.33 50.00 50.00 50.00 43.33 42.22 50.00 50.00 60.00 50.00 50.00 50.00 50.00 50.00 49.970. LUNA-Base EEGMamba SingLEM TFM Specialist Models CSP+LDA 100.00 100.00 100.00 91.67 100.00 100.00 66.67 100.00 100.00 100.00 83.33 100.00 100.00 100.00 100.00 91.67 91.67 95.60 EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 91.67 61.11 55.56 72.22 61.11 55.56 47.22 52.78 66.67 55.56 47.22 36.11 30.56 55.56 58.33 55.56 58.33 60.571.29 97.22 75.00 88.83 69.44 77.78 77.78 44.44 61.11 77.78 91.67 47.22 69.44 75.00 83.33 58.33 61.11 97.22 69.371.43 72.22 61.11 61.11 69.44 66.67 55.56 44.44 33.33 75.00 61.11 44.44 66.67 33.33 72.22 58.33 61.11 52.78 54.780.22 50.00 50.00 50.00 50.00 50.00 58.33 50.00 50.00 50.00 52.78 50.00 50.00 50.00 66.67 50.00 50.00 50.00 51.080.95 63.89 61.11 55.56 58.33 63.89 50.00 55.56 58.33 55.56 50.00 27.78 55.56 44.44 61.11 44.44 55.56 58.33 52.010.39 91.67 86.11 80.56 63.89 66.67 66.67 50.00 50.00 72.22 63.89 38.89 86.11 58.33 47.22 61.11 61.11 77.78 68.331.71 Full Fine-tuning Foundation Models Within-subject (Few-shot) Linear Probing Foundation Models BIOT EEGPT LaBraM BENDR CBraMod Neuro-GPT 30.56 55.56 41.67 61.11 44.44 50.00 55.56 52.78 50.00 52.78 38.89 50.00 47.22 55.56 66.67 41.67 47.22 52.160.22 100.00 91.67 77.78 91.67 75.00 91.67 69.44 91.67 75.00 94.44 94.44 86.11 75.00 100.00 91.67 97.22 86.11 86.113.16 91.67 80.56 58.33 83.33 69.44 61.11 58.33 44.44 72.22 63.89 58.33 86.11 50.00 63.89 63.89 63.89 66.67 65.741.50 97.22 91.67 86.11 75.00 72.22 77.78 58.33 52.78 72.22 88.89 44.44 97.22 38.89 58.33 72.22 69.44 63.89 71.223.69 91.67 77.78 61.11 75.00 83.33 69.44 55.56 55.56 75.00 58.33 61.11 63.89 25.00 52.78 72.22 72.22 63.89 65.592.51 100.00 100.00 75.00 100.00 77.78 80.56 69.44 38.89 88.89 94.44 38.89 100.00 72.22 47.22 75.00 80.56 61.11 79.321.15 100.00 91.67 88.89 83.33 72.22 69.44 72.22 55.56 77.78 83.33 47.22 86.11 52.78 69.44 86.11 80.56 83.33 77.550.95 BrainOmni-Tiny 86.11 69.44 75.00 47.22 61.11 38.89 52.78 33.33 63.89 58.33 72.22 69.44 27.78 69.44 66.67 72.22 63.89 58.720.79 BrainOmni-Base 55.56 47.22 58.33 44.44 50.00 66.67 50.00 50.00 58.33 47.22 47.22 30.56 41.67 58.33 47.22 58.33 55.56 51.081.86 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 47.22 50.080.11 50.00 50.00 52.78 52.78 52.78 47.22 47.22 50.00 50.00 50.00 50.00 50.00 50.00 50.00 52.78 44.44 50.00 50.460.19 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.620.44 LUNA-Base EEGMamba SingLEM TFM BIOT EEGPT LaBraM BENDR CBraMod Neuro-GPT 33.33 44.44 61.11 44.44 36.11 52.78 50.00 50.00 61.11 50.00 55.56 58.33 44.44 47.22 63.89 66.67 38.89 49.461.52 97.22 83.33 80.56 83.33 75.00 80.56 61.11 63.89 72.22 83.33 75.00 83.33 50.00 91.67 86.11 80.56 86.11 77.083.95 94.44 91.67 55.56 75.00 80.56 52.78 52.78 47.22 61.11 83.33 69.44 75.00 83.33 77.78 44.44 69.44 86.11 70.222.94 91.67 83.33 91.67 72.22 69.44 75.00 44.44 55.56 80.56 83.33 50.00 83.33 47.22 75.00 63.89 66.67 69.44 70.601.43 91.67 80.56 55.56 72.22 80.56 69.44 61.11 55.56 75.00 58.33 63.89 66.67 38.89 55.56 61.11 66.67 69.44 67.051.22 75.00 86.11 55.56 66.67 50.00 63.89 47.22 52.78 72.22 52.73 47.22 72.22 58.33 55.56 47.22 63.89 55.56 60.492.25 83.33 72.22 55.56 66.67 47.22 61.11 44.44 58.33 66.67 58.33 47.22 72.22 50.00 52.78 61.11 50.00 63.89 58.266.15 BrainOmni-Tiny 83.33 75.00 69.44 61.11 72.22 47.22 50.00 27.78 61.11 63.89 61.11 66.67 33.33 61.11 66.67 83.33 63.89 59.411.22 BrainOmni-Base 44.44 63.89 47.22 52.78 63.89 50.00 55.56 50.00 52.78 44.44 63.89 44.44 61.11 52.78 38.89 61.11 44.44 52.161.47 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.150.22 72.22 55.56 41.67 44.44 55.56 55.56 27.78 36.11 50.00 44.44 52.78 72.22 36.11 58.33 41.67 63.89 47.22 49.691.42 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 50.00 52.78 50.00 50.00 50.00 50.00 50.00 50.00 50.080.11 LUNA-Base EEGMamba SingLEM TFM 53 TABLE XXXIX: Cohens Kappa (%) on EEGMat. The best metrics are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S2 S3 S4 S6 S7 S8 S9 S10 S12 S13 S14 S15 S16 S18 Cross-subject Within-subject (Few-shot) Specialist Models CSP+LDA 66.67 0. 0.00 0.00 100.00 6.67 86.67 60.00 13.33 53.33 46.67 -6.67 0.00 0.00 0.00 53.33 40.00 0.00 86.67 EEGNet 17.78 2.22 0.00 88.89 80.00 8.89 26.67 22.22 40.00 66.67 71.11 15.56 6.67 -20.00 -2.22 31.11 -6.67 26.67 68.89 ShallowConv 37.78 17.78 22.22 51.11 73.33 15.56 73.33 33.33 31.11 82.22 88.89 66.67 13.33 -4.44 6.67 26.67 48.89 40.00 95.56 LMDA CNN-T 37.78 17.78 -4.44 82.22 64.44 62.22 26.67 11.11 42.22 71.11 51.11 17.78 -22.22 22.22 11.11 40.00 0.00 51.11 51.11 37.78 35.56 6.67 15.56 48.89 46.67 40.00 24.44 62.22 48.89 68.89 46.67 -26.67 -15.56 -2.22 24.44 66.67 40.00 31.11 DeFormer 55.56 15.56 8.89 64.44 88.89 0.00 75.56 46.67 31.11 71.11 84.44 53.33 -8.89 -20.00 22.22 31.11 42.22 84.44 28.89 Conformer 57.78 28.89 11.11 42.22 77.78 11.11 80.00 28.89 31.11 53.33 100.00 77.78 2.22 -4.44 6.67 22.22 48.89 28.89 84.44 Full Fine-tuning BENDR -2. 4.44 22.22 4.44 -6.67 0.00 -13.33 -8.89 33.33 24.44 -17.78 37.78 -2.22 -4.44 17.78 13.33 6.67 13.33 24.44 BIOT 68.89 8.89 8.89 60.00 53.33 8.89 20.00 24.44 51.11 57.78 62.22 42.22 -2.22 28.89 11.11 40.00 55.56 84.44 73. LaBraM 35.56 37.78 40.00 48.89 62.22 24.44 26.67 20.00 28.89 55.56 33.33 31.11 -17.78 15.56 26.67 22.22 24.44 6.67 6.67 Neuro-GPT 64.44 64.44 2.22 53.33 55.56 17.78 77.78 40.00 57.78 71.11 86.67 62.22 -13.33 -15.56 8.89 26.67 62.22 62.22 88.89 EEGPT 8.89 24.44 6.67 37.78 -13.33 2.22 22.22 -2.22 28.89 40.00 6.67 8.89 -24.44 0.00 17.78 31.11 20.00 22.22 22.22 Foundation Models CBraMod 51.11 13.33 31.11 13.33 28.89 28.89 17.78 20.00 33.33 55.56 51.11 28.89 -37.78 11.11 4.44 11.11 46.67 62.22 0.00 TFM 35.56 -20.00 11.11 57.78 57.78 15.56 13.33 6.67 40.00 57.78 40.00 17.78 -35.56 -26.67 -13.33 64.44 22.22 24.44 62.22 BrainOmni-Tiny 20.00 2.22 40.00 40.00 8.89 13.33 0.00 11.11 11.11 31.11 -4.44 20.00 -26.67 -4.44 26.67 22.22 15.56 -2.22 15.56 BrainOmni-Base 20.00 6.67 EEGMamba SingLEM LUNA-Base 0.00 0.00 0.00 0.00 -2.22 0. 2.22 0.00 0.00 0.00 8.89 0. 2.22 0.00 2.22 11.11 15.56 0.00 4.44 -13.33 8.89 6.67 15.56 -6.67 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 2. 0.00 2.22 0.00 -6.67 -6.67 13.33 -6.67 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 BENDR -15.56 11.11 -13.33 2. 0.00 -8.89 6.67 -2.22 8.89 20.00 -2.22 -2.22 15.56 -8.89 -2.22 17.78 24.44 0.00 13.33 BIOT 11.11 15.56 22.22 48.89 26.67 -6.67 64.44 26.67 53.33 28.89 48.89 68.89 -17.78 -11.11 28.89 17.78 26.67 40.00 51.11 LaBraM 42.22 28.89 44.44 17.78 31.11 11.11 33.33 37.78 42.22 37.78 24.44 31.11 -2.22 2.22 35.56 35.56 28.89 22.22 37.78 Neuro-GPT 51.11 44.44 2.22 51.11 40.00 48.89 75.56 40.00 44.44 68.89 60.00 20.00 2.22 -35.56 11.11 17.78 46.67 42.22 75. Linear Probing Foundation Models EEGPT 20.00 22.22 6.67 46.67 11.11 2.22 11.11 0.00 42.22 60.00 -13.33 13.33 -33.33 -2.22 17.78 33.33 6.67 40.00 40.00 CBraMod 17.78 26.67 26.67 17.78 8. -2.22 26.67 4.44 64.44 24.44 -13.33 8.89 -26.67 35.56 17.78 8.89 42.22 53.33 44.44 TFM 26.67 2.22 8.89 60.00 40.00 26.67 11.11 8.89 51.11 44.44 -17.78 15.56 -55.56 -4.44 15.56 57.78 26.67 0.00 75.56 BrainOmni-Tiny 11.11 6.67 20.00 48.89 28.89 13.33 4.44 11.11 37.78 35.56 42.22 42.22 -11.11 -8.89 28.89 28.89 22.22 20.00 48.89 BrainOmni-Base 0. EEGMamba 0.00 8.89 0.00 -2.22 0. 4.44 0.00 0.00 0.00 8.89 0. 4.44 0.00 8.89 0.00 4.44 -13.33 11.11 -4.44 -2.22 6.67 -11.11 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 4.44 0.00 2.22 0. -2.22 2.22 SingLEM -20.00 6.67 11.11 -15.56 -8.89 -2.22 -11.11 33.33 0.00 -11.11 -24.44 -2.22 11.11 -15.56 8.89 17.78 -24.44 -2.22 -4.44 LUNA-Base 0. 2.22 0.00 2.22 0.00 11.11 0.00 -4.44 0. -2.22 0.00 0.00 0.00 0.00 0. 0.00 11.11 -2.22 0.00 Specialist Models CSP+LDA 83.33 100.00 83.33 100.00 83.33 100.00 100.00 100.00 100.00 50.00 83.33 83.33 100.00 83.33 100.00 100.00 100.00 100.00 83.33 EEGNet 11.11 0.00 22.22 50.00 22.22 44.44 11.11 -33.33 50.00 0.00 50.00 5.56 72.22 5.56 27.78 77.78 61.11 11.11 50.00 ShallowConv -16.67 5.56 22.22 27.78 22.22 38.89 50.00 22.22 22.22 5.56 11.11 33.33 66.67 66.67 33.33 66.67 16.67 38.89 55.56 LMDA CNN-T -11.11 22.22 5.56 61.11 -44.44 -38.89 5.56 -33.33 -11.11 -11.11 -11.11 55.56 16.67 0.00 27.78 -11.11 22.22 11.11 11. 0.00 0.00 0.00 22.22 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 DeFormer 16.67 16.67 0.00 11.11 -27.78 -38.89 22.22 -16.67 -16.67 22.22 -5.56 11.11 -5.56 -5.56 0.00 -38.89 16.67 11.11 33.33 Conformer 27.78 94.44 72.22 83.33 55.56 0.00 22.22 44.44 27.78 50.00 38.89 22.22 44.44 27.78 27.78 16.67 55.56 11.11 55.56 BENDR -5.56 16.67 -5.56 16.67 11.11 5.56 16.67 -5.56 22.22 22.22 -27.78 33.33 11.11 27.78 11.11 11.11 5. 0.00 5.56 Full Fine-tuning BIOT 16.67 55.56 44.44 94.44 77.78 5.56 77.78 72.22 100.00 83.33 61.11 77.78 16.67 100.00 77.78 100.00 83.33 100.00 77.78 LaBraM 33.33 55.56 -5.56 27.78 11.11 22.22 16.67 -44.44 50.00 16.67 50.00 38.89 27.78 50.00 22.22 61.11 72.22 5.56 50.00 Neuro-GPT 16.67 27.78 66.67 83.33 38.89 11.11 61.11 -38.89 27.78 27.78 38.89 72.22 61.11 61.11 33.33 11.11 72.22 38.89 83.33 Foundation Models EEGPT -11.11 -5.56 22.22 33.33 11.11 5.56 22.22 22.22 55.56 16.67 50.00 22.22 44.44 61.11 55.56 72.22 44.44 16.67 55. CBraMod -5.56 72.22 61.11 33.33 11.11 83.33 61.11 66.67 72.22 100.00 44.44 66.67 88.89 94.44 38.89 61.11 100.00 88.89 72.22 TFM 27.78 61.11 0.00 72.22 94.44 66.67 50.00 50.00 66.67 16.67 33.33 72.22 44.44 66.67 72.22 77.78 88.89 55.56 66.67 BrainOmni-Tiny -11.11 55.56 5.56 16.67 16.67 0.00 5.56 -50.00 11.11 50.00 5.56 27.78 11.11 22.22 16.67 5.56 33.33 -5.56 55. BrainOmni-Base 11.11 11.11 0.00 -5.56 EEGMamba 0.00 0.00 0. SingLEM 0.00 11.11 0.00 LUNA-Base 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 5.56 0.00 16.67 0.00 0.00 0. 0.00 5.56 16.67 -11.11 0.00 33.33 5.56 -11.11 5.56 16.67 -16.67 5.56 22.22 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 22.22 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 5.56 0. 5.56 0.00 0.00 0.00 0.00 0. 0.00 22.22 0.00 0.00 0.00 0.00 BENDR 0.00 -27.78 11.11 -27.78 16.67 0. -5.56 -16.67 11.11 -27.78 5.56 16.67 -5.56 -27.78 5.56 -22.22 5.56 0.00 33.33 BIOT 5.56 38.89 27.78 72.22 33.33 22.22 72.22 27.78 72.22 72.22 72.22 83.33 0.00 77.78 38.89 77.78 72.22 61.11 55.56 LaBraM 61.11 33.33 11.11 38.89 16.67 72.22 44.44 -5.56 83.33 38.89 38.89 33.33 44.44 5.56 22.22 55.56 55.56 44.44 61. Neuro-GPT 16.67 16.67 66.67 66.67 44.44 22.22 50.00 -33.33 27.78 72.22 38.89 55.56 61.11 66.67 27.78 22.22 55.56 33.33 66.67 EEGPT -27.78 27.78 16.67 55.56 11.11 0.00 33.33 16.67 55.56 22.22 55.56 50.00 61.11 77.78 33.33 83.33 50.00 0.00 61.11 Linear Probing Foundation Models CBraMod 27.78 27.78 0.00 11.11 33.33 22.22 33.33 5.56 0.00 22.22 22.22 44.44 16.67 22.22 27.78 -11.11 44.44 22.22 38.89 TFM -22.22 -11.11 27.78 27.78 38.89 11.11 27.78 16.67 27.78 -11.11 33.33 5.56 11.11 16.67 0.00 11.11 22.22 5.56 33.33 BrainOmni-Tiny -11.11 38.89 0.00 16.67 11.11 -16.67 16.67 -33.33 27.78 55.56 5.56 11.11 16.67 16.67 16.67 16.67 44.44 -5.56 55. BrainOmni-Base -16.67 -5.56 -16.67 5.56 27.78 -5.56 EEGMamba 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 -5.56 0. 5.56 0.00 -5.56 -16.67 27.78 22.22 16.67 27.78 22.22 -5.56 -5.56 0.00 0.00 0. 0.00 0.00 11.11 0.00 0.00 0.00 0.00 0. SingLEM 16.67 22.22 -5.56 22.22 -27.78 -16.67 -27.78 -27.78 0.00 22.22 -11.11 -16.67 -38.89 16.67 11.11 -16.67 11.11 22.22 11.11 LUNA-Base 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 TABLE XL: Cohens Kappa (%) on EEGMat. The best metrics are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S19 S20 S21 S23 S24 S25 S26 S27 S29 S30 S31 S32 S33 S35 Avg. 54 CSP+LDA EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM Specialist Models Foundation Models EEGMamba SingLEM LUNA-Base 0.00 66.67 20.00 86. 64.44 31.11 28.89 82.22 42.22 93.33 80.00 40.00 40.00 -26.67 13.33 84.44 71.11 28.89 28.89 31.11 35.56 37.78 22.22 42.22 24.44 31.11 13.33 20.00 35.56 24.44 57.78 62.22 33.211.26 88.89 46.67 55.56 53.33 62.22 68.89 73.33 40.00 20.00 84.44 15.56 13.33 24.44 26.67 44.44 57.73 44.442.49 40.00 75.56 35.56 34.942.42 66.67 44.44 68.89 75.56 80.00 35.56 41.544.98 24.44 24.44 37.78 13.33 48.89 51.11 43.460.75 31.11 28.89 40.00 55.56 40.991.87 4.44 95.56 51.11 64.44 55.56 66.67 66.67 64.44 40.00 17.78 66.67 80.00 77.78 33.33 86.67 51.11 46.67 37.78 42.22 42.22 24.44 88.89 22.22 51.11 22.22 71.11 53.33 71.11 42.22 17.78 80.00 46.67 42.22 55.56 24.44 20.00 46.67 -13.33 2. 26.67 40.00 13.33 60.00 93.33 34.81 0.00 6.67 0.00 4. 0.00 0.00 2.22 0.00 0.00 2. 4.44 6.67 8.89 8.89 -2.22 22. 22.22 11.11 13.33 13.33 -6.67 20.00 13.33 -4.44 31.11 64.44 26.67 24.44 26.67 26.67 13.33 20.00 22.22 37.78 64.44 31.11 46.67 97.78 73.33 24.44 62.22 20.00 26.67 82.22 8.641.43 93.33 53.33 53.33 57.78 44.44 55.56 55.56 31.11 35.56 48.89 11.11 60.00 -22.22 40.00 31.11 55.56 33.33 41.542.99 28.89 66.67 17.78 66.67 51.11 37.78 57.78 31.11 44.44 22.22 13.33 20.00 -20.00 20.00 35.56 55.56 55.55 31.433.22 48.89 -2.22 13.33 55.56 53.33 53.33 45.252.71 97.78 40.00 53.33 42.22 60.00 57.78 42.22 35.56 26.67 73.33 -4.44 -15.56 0.00 16.052.04 13.33 40.00 30.00 40.00 28.89 37.78 84.44 46.67 36.851.44 26.053.90 57.78 -11.11 8.89 28.89 46.67 15.001.60 3.021.52 4.44 -0.060.09 -0.310.31 0.000. 75.56 42.22 35.56 51.11 28.89 28.89 24.44 26.67 33.33 28.89 -2.22 -2.22 -4.44 20.00 -2.22 28.89 -17.78 13.33 22.22 -6.67 -11.11 0.00 35.56 37.78 -2.22 -6.67 -6. 46.67 -2.22 -2.22 -2.22 0.00 0. 8.89 0.00 0.00 0.00 6.67 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 2.22 2.22 4.44 0. 0.00 0.00 8.89 2.22 2.22 6. 0.00 0.00 0.00 0.00 0.00 0. 4.44 0.00 2.22 8.89 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 4.44 8.89 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 4.44 BrainOmni-Tiny 20.00 51.11 -4.44 35.56 17.78 22.22 13.33 BrainOmni-Base -11.11 -15.56 4. Full Fine-tuning Cross-subject BENDR 4.44 6.67 15.56 26.67 -20.00 13. 4.44 0.00 6.67 BIOT 95.56 57.78 33.33 75.56 40.00 48.89 31.11 37.78 31.11 57.78 -4.44 42.22 -11.11 28.89 LaBraM 77.78 48.89 24.44 55.56 8.89 8.89 15.56 33.33 44.44 -6.67 -2.22 15.56 Neuro-GPT 97.78 64.44 28.89 26.67 55.56 40.00 55.56 15. 2.22 Linear Probing Foundation Models EEGPT 64.44 24.44 33.33 33.33 8. 0.00 CBraMod 40.00 11.11 -8.89 35.56 17.78 37.78 TFM 86.67 33.33 4. 60.00 42.22 42.22 4.44 6.67 17.78 28.89 40.00 11.11 13.33 17.78 -17.78 4.44 26.67 35.56 28.83 28.89 40.00 28.89 -2.22 40.00 -11.11 -2.22 53.33 48. 0.00 4.44 4.44 2.22 2.22 0. -6.67 6.67 -15.56 11.11 4.44 -17.78 3.023.14 57.78 15.56 32.902.49 40.00 73.33 55.56 28.951.11 75.56 -6.67 75.56 15.56 17.78 28.89 51.11 -13.33 37.163.78 46.67 15.56 18.771.06 17.78 -11.11 15.53 44.44 40.00 22.22 20.680.53 24.880.17 24.44 15.56 -15.56 24.44 24.44 37.78 48.89 25.000.99 0.801.37 -2.22 -2.22 0.120.17 0.800.86 -0.060.78 -8.89 -2.22 -13.33 -8.89 15.56 20. -2.22 0.00 0.00 8.89 0.00 0. 0.00 2.22 6.67 0.00 0.00 0. 0.00 0.00 0.00 0.00 2.22 4. 4.44 0.00 8.89 2.22 BrainOmni-Tiny 44.44 46.67 22.22 60.00 33.33 46.67 13.33 11.11 22.22 BrainOmni-Base -2.22 13. 0.00 -13.33 2.22 -4.44 -2.22 -17.78 -2.22 EEGMamba 0.00 0.00 0. 0.00 0.00 SingLEM -15.56 17.78 -6.67 46.67 13.33 LUNA-Base 11.11 -11.11 2.22 -13.33 0. 0.00 8.89 0.00 0.00 11.11 0. 8.89 0.00 0.00 -13.33 -15.56 0.00 33.33 -4.44 11.11 -17.78 8.89 CSP+LDA 100.00 100.00 100.00 83.33 100.00 100.00 33.33 100.00 100.00 100.00 66.67 100.00 100.00 100.00 100.00 83.33 83. 91.20 Specialist Models EEGNet ShallowConv LMDA CNN-T DeFormer Conformer 5.56 33.33 11.11 -5.56 -27.78 -38.89 11.11 16.67 11.11 16.67 21.142.57 83.33 22.22 11.11 44.44 22.22 11.11 -5.56 94.44 50.00 77.78 38.89 55.56 55.56 -11.11 22.22 55.56 83.33 -5.56 38.89 50.00 66.67 16.67 22.22 94.44 38.732.86 9.570.44 44.44 22.22 22.22 38.89 33.33 11.11 -11.11 -33.33 50.00 22.22 -11.11 33.33 -33.33 44.44 16.67 22.22 2.161.90 4.010.79 44.44 27.78 -22.22 72.22 16.67 -5.56 22.22 22.22 55.53 36.733.43 0.00 -44.44 11.11 -11.11 22.22 -11.11 11.11 16.67 83.33 72.22 61.11 27.78 33.33 33. 27.78 22.22 11.11 16.67 27.78 11.11 16.67 11.11 33.33 16.67 0.00 5. 0.00 0.00 0.00 0.00 0.00 0. 0.00 5.56 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 Full Fine-tuning Foundation Models Within-subject (Few-shot) 0.00 5.56 11.11 BIOT EEGPT LaBraM BENDR CBraMod Neuro-GPT 5.56 -22.22 0. -5.56 11.11 33.33 -16.67 -5.56 94.44 83.33 72.22 50.00 44.44 55.56 16.67 -38.89 11.11 -16.67 22.22 -11.11 0.00 4.320.44 100.00 83.33 55.56 83.33 50.00 83.33 38.89 83.33 50.00 88.89 88.83 72.22 50.00 100.00 83.33 94.44 72.22 72.226.31 27.78 27.78 27.78 33.33 31.483.00 83.33 61.11 16.67 66.67 38.89 22.22 16.67 -11.11 44.44 27.78 16.67 72.22 44.44 77.78 -11.11 94.44 -22.22 16.67 44.44 38.89 27.78 42.447.37 44.44 44.44 27.78 31.175.02 83.33 55.56 22.22 50.00 66.67 38.89 11.11 11.11 50.00 16.67 22.22 27.78 -50.00 5.56 100.00 100.00 50.00 100.00 55.53 61.11 38.89 -22.22 77.78 88.89 -22.22 100.00 44.44 -5.56 50.00 61.11 22.22 58.642.31 100.00 83.33 77.78 66.67 44.44 38.89 44.44 11.11 55.56 66.67 -5.56 72.22 38.89 72.22 61.11 66.67 55.091.89 BrainOmni-Tiny 72.22 38.89 50.00 -5.56 22.22 -22.22 5.56 -33.33 27.78 16.67 44.44 38.89 -44.44 38.89 33.33 44.44 27.78 17.441.57 2.163.71 BrainOmni-Base 11.11 -5.56 16.67 -11.11 0.00 0.150.22 0.930.38 1.230.87 16.67 -5.56 -5.56 -38.89 -16.67 16.67 -5.56 16.67 11.11 5.56 -11.11 0.00 -5.56 -5. LUNA-Base EEGMamba SingLEM 33.33 -5.56 TFM 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 5.56 0.00 0. 0.00 0.00 0.00 0.00 5.56 0. 0.00 0.00 0.00 0.00 0.00 5. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 5.56 5.56 BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM Linear Probing Foundation Models 5. 0.00 0.00 5.56 0.00 0.00 22. -33.33 -11.11 22.22 -11.11 -27.78 5.56 88.89 83.33 11.11 50.00 61.11 94.44 66.67 61.11 66.67 50.00 61.11 22.22 27.73 44.44 66.67 50.00 66.67 11.11 16.67 -11.11 -5.56 27.78 33.33 -22.22 -1.083.03 83.33 72.22 61.11 72.22 54.177.89 -5.56 22.22 66.67 38.89 50.00 66.67 55.56 -11.11 38.89 72.22 40.435.87 83.33 66.67 83.33 44.44 38.89 50.00 -11.11 11.11 61.11 66.67 66.67 -5.56 50.00 27.78 33.33 38.89 41.202.85 83.33 61.11 11.11 44.44 61.11 38.89 22.22 11.11 50.00 16.67 27.78 33.33 -22.22 11.11 22.22 33.33 38.89 34.102.43 -5.56 44.44 16.67 11.11 -5.56 27.78 11.11 20.994.51 5.56 50.00 72.22 11.11 33.33 27.78 16.5112.29 22.22 0.00 -44.44 22.22 27.78 22.22 33.33 -33.33 22.22 33.33 66.67 27.78 18.832.43 4.322.94 11.11 0.310.44 -0.622.84 0.150.22 66.67 44.44 11.11 33.33 -5.56 22.22 -11.11 16.67 33.33 16.67 -5.56 44.44 44.44 11.11 -16.67 -11.11 11.11 11.11 -44.44 -27.78 0.00 -11.11 5. 44.44 -27.78 16.67 -16.67 27.78 -5.56 5.56 -11.11 27.78 -11.11 22.22 5.56 -22.22 22.22 -11.11 27.78 -5.53 27.78 44. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 5.56 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 5.56 0.00 0.00 0.00 0. 0.00 5.56 0.00 0.00 0.00 0. 5.56 BrainOmni-Tiny 66.67 50.00 38.89 22.22 44.44 -5.56 BrainOmni-Base -11.11 27.78 -5.56 EEGMamba SingLEM LUNA-Base TABLE XLI: Classiﬁcation AUCs (%) on CHB-MIT. The best AUCs are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S1 S2 S3 S4 S5 S7 S8 S9 S10 S11 Specialist Models Foundation Models Full Fine-tuning Cross-subject Linear Probing Foundation Models Specialist Models Foundation Models Full Fine-tuning Linear Probing Foundation Models Within-subject (Few-shot) PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge 87.68 99.50 99.90 99. 98.86 99.93 99.91 99.26 99.17 98. 97.21 88.74 98.96 75.76 99.61 79. 98.25 98.65 98.64 53.46 93.74 92. 95.83 94.81 97.95 47.32 93.51 52. 75.69 76.19 91.59 98.58 99.81 98. 99.47 99.35 99.26 99.37 53.76 92. 98.34 99.48 86.93 99.67 55.04 98. 53.19 94.89 94.75 98.06 53.28 98. 96.60 88.61 87.74 99.89 45.89 99. 52.46 77.55 98.33 94.98 87.33 98. 97.39 96.44 90.07 98.25 98.15 96. 98.07 97.61 90.37 85.16 95.82 82. 91.50 87.84 96.77 97.42 97.94 55. 91.33 88.15 79.16 80.71 90.81 76. 89.46 50.77 93.80 95.50 98.15 94. 96.52 95.74 95.94 96.64 96.78 99. 68.04 50.00 93.17 95.26 84.66 93. 59.21 95.98 82.59 88.20 95.88 95. 49.62 50.00 95.70 88.53 88.75 93. 51.30 92.52 62.35 94.93 95.96 96. 90.45 95.99 99.03 93.43 97.24 96. 98.53 96.22 98.59 97.36 94.46 65. 96.63 69.66 98.58 63.77 99.22 98. 98.13 52.28 62.81 74.41 93.39 87. 89.81 64.40 86.45 51.07 80.35 93. 97.13 98.79 99.85 99.85 99.30 97. 99.61 99.55 61.26 85.71 65.99 94. 61.10 88.07 76.23 86.95 53.09 89. 94.73 97.83 50.83 85.89 67.80 79. 60.77 91.55 70.16 85.89 47.89 74. 95.28 84.74 56.32 95.61 95.29 90. 95.99 97.13 95.30 96.93 97.49 92. 91.04 78.52 95.90 81.30 94.08 70. 90.03 94.03 90.34 57.24 90.72 80. 79.76 78.83 90.56 63.69 87.72 50. 96.30 91.86 95.18 82.77 97.02 87. 84.72 90.82 95.38 98.13 57.05 40. 56.11 55.86 61.43 45.04 60.82 53. 53.18 64.80 63.40 74.12 48.64 44. 54.56 40.76 62.50 33.65 50.16 50. 51.50 48.65 69.36 54.79 96.28 91. 94.16 95.63 95.70 93.73 86.09 73. 89.86 71.01 70.62 50.77 94.48 81. 90.37 60.02 85.50 84.89 88.10 55. 97.45 57.29 71.20 55.21 96.02 81. 88.37 42.11 92.13 93.76 92.54 99. 99.91 99.71 99.82 99.61 99.90 98. 64.08 94.53 91.27 96.54 92.47 99. 73.79 98.27 53.13 85.31 86.30 81. 49.56 85.59 94.17 88.51 92.90 99. 61.08 98.59 50.44 80.25 87.05 77. 64.13 78.02 86.96 80.83 85.79 87. 85.77 84.40 65.48 84.55 73.47 74. 73.59 68.19 82.35 59.43 89.08 90. 84.74 50.80 61.84 64.97 70.61 79. 84.76 58.40 62.88 45.02 62.60 66. 59.66 93.77 53.09 70.89 77.09 97. 51.78 62.42 51.19 98.94 84.01 91. 70.21 98.39 64.11 94.27 53.98 47. 47.78 49.98 48.41 95.38 76.81 78. 78.64 97.50 58.58 95.78 55.79 59. 42.18 55.12 91.22 91.87 99.07 94. 95.67 95.76 97.42 98.02 97.15 93. 94.77 83.16 97.04 87.39 91.60 74. 96.92 95.63 97.33 59.08 99.17 76. 94.51 87.74 95.73 80.31 92.60 62. 91.93 90.99 92.06 97.76 96.43 95. 99.29 93.42 96.72 93.66 81.93 91. 93.56 90.82 72.78 96.89 74.19 89. 65.12 92.95 89.05 90.26 48.93 78. 90.01 85.02 74.25 96.67 70.24 89. 54.21 84.25 86.47 85.78 95.00 75. 94.44 86.41 85.60 90.85 96.56 87. 89.82 78.85 78.83 77.23 98.42 68. 95.39 81.41 97.66 97.00 97.42 54. 80.13 52.17 72.06 86.32 93.18 47. 87.38 55.24 80.79 77.86 94.27 98. 98.94 98.35 99.27 99.43 99.40 98. 95.17 97.56 99.66 99.83 97.38 99. 69.25 98.74 98.40 98.36 98.48 99. 50.91 97.77 98.61 99.68 97.52 99. 55.01 99.78 52.94 98.37 97.78 97. 98.39 98.44 98.42 97.54 97.95 96. 91.95 93.33 88.69 90.15 90.29 83. 96.71 71.08 97.88 82.35 85.37 89. 89.56 56.71 97.37 88.28 88.13 86. 89.75 55.14 94.52 48.86 80.94 77. 68.69 98.83 99.01 97.65 98.13 98. 98.80 97.62 48.64 94.03 81.83 94. 60.24 98.76 57.86 83.53 52.43 69. 63.36 65.69 49.45 94.92 81.62 84. 60.32 99.07 49.21 92.38 50.65 60. 65.36 61.12 96.49 98.44 98.26 97. 96.05 98.02 97.13 96.41 75.08 91. 80.11 70.23 95.97 57.70 92.01 50. 88.83 86.30 91.52 51.49 62.72 88. 77.61 85.13 99.27 75.19 89.55 49. 78.13 74.12 76.78 99.78 99.43 98. 97.58 99.81 99.92 99.82 53.93 93. 99.48 98.98 93.93 99.49 70.40 96. 55.54 78.08 83.66 83.03 49.08 88. 97.60 92.01 95.79 98.93 61.55 97. 50.56 80.43 79.38 82.75 97.08 99. 99.28 97.48 98.83 99.02 99.00 99. 96.92 99.39 98.52 95.59 97.64 79. 98.57 79.07 96.14 96.05 97.06 59. 92.10 98.01 99.59 95.89 96.60 70. 96.26 49.25 95.60 91.86 97.02 96. 99.72 99.45 98.74 99.57 99.87 98. 53.94 96.42 97.39 99.11 67.69 99. 59.36 72.48 51.80 79.28 94.50 83. 48.03 81.32 97.21 72.17 79.10 99. 55.29 89.90 53.99 73.09 90.45 71. 63.53 58.59 58.85 64.77 57.31 61. 55.21 59.86 66.43 63.84 50.57 59. 66.18 52.44 64.19 49.69 61.76 58. 52.97 50.23 75.87 60.15 55.63 57. 66.89 57.49 73.41 49.66 64.80 63. 68.87 59.56 67.67 62.96 67.15 78. 57.90 80.79 49.82 70.11 62.90 66. 51.36 81.17 49.02 62.98 51.52 63. 64.34 63.70 49.88 70.13 62.54 56. 48.54 79.98 49.03 72.53 50.41 69. 69.34 70.15 TABLE XLII: Classiﬁcation AUCs (%) on CHB-MIT. The best AUCs are marked in bold, and the second best by an underline (continued). Scenario Tuning Model Type Approach S12 S13 S14 S15 S17 S18 S19 S20 S21 Avg. 56 Specialist Models Foundation Models Full Fine-tuning Cross-subject Linear Probing Foundation Models Specialist Models Foundation Models Full Fine-tuning Linear Probing Foundation Models Within-subject (Few-shot) PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge 68.26 59.13 63.10 75.46 79.56 64.15 67.74 63.68 73.96 75.72 66.13 71.10 74.84 65.60 61.15 55.28 68.04 62.97 57.43 53.41 80.09 70.92 70.81 77.51 68.58 43.87 53.85 49.99 65.82 57.92 67.72 96.33 96.93 97.63 95.30 93.80 96.64 95. 76.86 85.87 90.70 88.55 82.33 92.69 58.01 84.82 74.59 63.97 67.68 65.51 50.23 83.09 90.38 78.44 84.79 92.00 52.49 90.79 54.09 66.57 57.34 67.43 73.36 7.95 8.07 18.44 56.84 25.06 8.40 32.12 13.90 35.40 31.27 34.81 19.72 41.65 31.59 50.81 39.11 41.05 35.44 51.43 9.96 58.04 25.74 41.70 13.82 33.47 47.82 43.31 22.63 19.95 28.91 69.40 83.43 81.17 84.65 73.78 89.42 87. 55.84 93.03 97.67 98.17 94.76 96.61 62.15 96.39 62.04 78.91 90.63 88.30 50.70 93.82 95.95 95.31 96.39 97.24 48.71 93.02 46.60 71.07 88.85 80.55 39.34 83.28 79.66 69.35 47.28 88.04 73.25 85.02 67.90 82.94 85.30 76.17 67.06 65.14 85.91 72.68 69.01 83.61 67.08 52.23 62.18 76.62 82.76 80.12 81.13 66.93 86.12 48.21 82.27 86.45 79.75 91.55 97.17 91.85 95.69 91.16 95.46 96. 52.49 50.00 94.16 96.39 76.12 94.40 61.50 81.14 60.38 71.15 85.48 87.24 50.30 50.00 88.68 92.23 76.34 94.87 53.03 95.29 51.30 82.08 87.79 82.59 81.41 84.11 85.00 78.94 82.91 84.77 76.97 77.61 85.80 84.35 71.79 60.93 88.07 50.38 85.54 53.21 88.97 82.67 84.21 53.63 78.07 78.26 61.37 72.23 82.68 51.13 68.98 47.28 72.67 74.95 82.25 75.86 75.83 69.77 76.04 83.92 55.01 78. 54.21 89.78 77.93 88.90 86.34 85.43 57.19 86.08 57.25 81.41 84.62 84.63 59.10 83.90 75.47 71.54 85.03 86.58 50.75 88.34 58.78 77.34 72.83 76.63 62.20 97.47 99.49 97.12 90.73 99.14 98.65 98.98 97.53 95.49 92.15 90.35 97.02 80.20 94.49 73.99 98.95 98.94 96.96 57.24 85.66 90.36 93.88 93.71 96.59 71.34 97.42 61.54 88.55 77.47 96.64 95.94 99.51 99.33 98.77 97.18 99.33 99. 77.27 96.56 90.44 99.46 80.22 99.60 74.44 90.32 55.75 90.96 89.57 94.44 53.22 96.70 89.19 87.41 82.38 99.49 68.51 90.05 54.67 91.05 90.76 87.04 15.81 93.76 95.08 85.97 87.12 82.23 87.60 93.09 76.55 71.33 91.42 88.34 84.66 65.13 92.53 56.72 92.07 89.75 92.78 52.30 79.55 57.60 91.34 88.10 77.46 53.24 76.34 50.78 85.59 85.99 90.89 85.20 94.10 93.63 93.21 88.56 92.67 93. 54.16 81.85 88.25 96.33 93.63 90.00 60.04 86.04 47.44 88.23 84.62 89.29 51.39 68.42 82.41 87.16 94.73 89.31 44.51 86.23 40.81 85.86 80.51 90.38 92.62 92.25 100.00 99.87 99.47 99.96 98.93 99.37 97.39 95.06 95.93 88.96 97.76 75.32 99.63 57.71 99.80 99.29 98.57 60.38 99.75 92.27 99.28 95.90 95.80 71.83 99.60 40.26 97.58 80.45 99.80 99.67 100.00 99.74 100.00 100.00 99.99 100. 74.81 97.00 100.00 99.98 94.67 100.00 81.00 100.00 42.17 99.94 99.78 99.86 47.61 98.78 99.81 98.73 96.83 100.00 51.32 100.00 39.92 98.77 97.90 100.00 57.13 92.38 95.95 82.07 84.34 92.32 93.77 88.40 68.56 74.66 72.97 71.69 80.27 51.56 84.35 48.51 69.00 68.96 63.34 47.84 81.58 85.35 79.47 80.21 74.47 38.47 95.36 49.01 58.69 70.31 70.85 93.67 98.53 93.87 99.48 99.05 97.70 92. 51.31 50.00 98.62 99.62 78.40 99.69 66.93 99.64 49.21 96.92 96.04 96.68 51.77 50.00 96.59 93.40 83.24 99.73 61.30 99.57 47.19 94.58 98.08 89.56 56.00 83.81 95.70 84.44 95.06 92.61 83.62 94.60 92.92 83.18 92.43 74.35 97.02 57.36 86.69 65.38 94.73 97.56 95.99 53.59 79.34 78.85 96.54 79.63 89.88 53.35 84.50 53.52 83.77 81.33 90.63 98.83 99.90 99.88 99.76 99.88 99.79 99. 43.70 98.09 88.15 99.56 71.69 99.91 65.13 96.64 59.10 92.46 92.29 92.61 57.71 94.59 83.43 90.63 79.61 99.74 58.84 98.60 49.12 92.73 91.10 92.84 97.75 91.65 99.74 97.61 96.58 99.58 99.63 97.52 99.00 99.27 99.18 88.14 99.84 87.37 96.74 88.56 97.07 95.73 94.48 55.26 94.93 97.37 98.48 93.93 95.08 65.81 93.23 60.32 90.36 91.26 96.21 99.17 99.93 99.14 99.94 94.91 99.96 99. 81.53 98.89 97.46 99.20 97.28 99.79 75.84 90.19 87.34 82.64 84.98 89.89 50.76 97.24 96.64 89.02 97.98 99.72 59.34 93.04 54.19 75.94 84.48 80.20 91.97 98.38 99.33 99.50 99.40 96.10 98.24 97.90 97.66 95.41 96.17 80.28 97.37 74.74 98.72 82.37 98.60 98.70 99.19 55.99 83.41 92.73 95.69 81.32 93.98 50.06 94.45 48.98 90.67 86.80 95.07 97.96 99.79 99.52 99.66 99.68 99.50 98. 73.46 97.68 98.29 99.66 95.42 99.29 59.96 95.41 81.66 94.11 98.54 98.98 51.00 93.89 96.82 93.54 97.04 99.06 55.39 96.83 58.32 74.93 92.89 78.07 76.51 85.440.97 88.790.12 86.260.01 87.580.21 88.630.53 86.430.39 87.430.07 84.080.12 84.820.27 82.830.16 75.531.72 87.430.51 69.160.82 87.540.16 67.131.99 86.990.62 87.210.44 85.620.69 54.320.66 79.991.11 78.210.13 81.430.57 80.911.09 85.250.26 59.880.55 84.340.03 50.490.20 79.640.11 78.510.03 83.940.05 92.290.02 93.590.69 92.610.25 93.870.31 94.460.43 92.210.41 94.210. 62.370.37 84.480.30 88.930.39 93.420.52 80.480.28 93.800.38 64.851.19 88.600.52 60.912.32 82.270.58 84.800.18 85.690.59 50.891.07 81.820.88 87.330.23 83.961.21 82.660.79 93.290.27 55.730.29 91.120.17 51.660.52 78.750.43 83.450.20 80.800.19 TABLE XLIII: Balanced classiﬁcation accuracies (%) on CHB-MIT. The best BCAs are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S2 S3 S5 S6 S7 S8 S9 S11 57 Specialist Models Foundation Models Full Fine-tuning Cross-subject Linear Probing Foundation Models Specialist Models Foundation Models Full Fine-tuning Linear Probing Foundation Models Within-subject (Few-shot) PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge 83.80 96. 97.66 98.31 92.69 98.18 95.97 96. 93.93 82.99 92.16 80.62 87.52 68. 92.03 72.05 90.29 92.80 89.77 50. 85.78 76.69 88.11 87.92 96.26 46. 86.62 52.27 70.11 72.25 85.62 93. 90.59 81.89 88.59 95.66 90.89 96. 50.18 86.35 89.06 90.61 77.72 91. 51.67 89.97 51.22 81.92 77.65 90. 50.15 91.53 67.03 75.12 78.97 91. 47.83 95.21 50.93 72.77 73.22 79. 79.44 92.11 93.91 93.15 77.10 93. 92.37 89.98 94.48 87.90 80.79 75. 84.25 76.22 85.59 76.01 89.19 91. 93.34 55.34 87.80 81.85 72.28 74. 86.69 72.25 82.99 50.25 84.40 84. 94.78 82.81 96.22 92.12 94.17 96. 93.07 96.24 54.87 50.00 69.99 85. 57.30 91.40 56.76 89.77 69.87 77. 81.81 89.68 50.62 50.00 76.20 72. 60.86 87.73 48.42 81.44 53.25 86. 80.44 84.29 74.27 93.94 95.79 91. 84.21 82.27 94.42 78.67 88.06 75. 82.30 61.96 78.73 60.27 90.79 58. 95.65 92.18 91.51 51.59 68.50 73. 76.64 73.92 86.91 54.36 68.37 50. 59.97 72.84 63.81 82.67 98.79 98. 96.92 91.14 97.02 98.19 52.72 80. 59.09 81.19 50.49 83.63 70.01 77. 49.74 78.15 88.58 94.85 49.63 77. 57.39 71.03 50.76 87.02 63.07 78. 49.89 66.68 89.27 76.66 64.11 91. 89.89 87.03 87.60 92.27 90.89 89. 83.23 79.82 84.46 68.62 87.87 74. 84.62 64.11 81.01 83.40 80.89 55. 84.14 73.65 72.84 65.67 85.63 59. 80.77 50.85 70.97 74.07 82.43 77. 84.66 77.22 76.72 85.64 74.60 92. 51.01 48.12 61.78 56.44 62.97 61. 57.10 55.27 53.13 56.84 57.85 73. 49.74 61.26 59.57 46.60 64.15 52. 49.74 55.34 50.06 42.88 61.22 47. 91.05 61.96 61.29 67.41 81.60 66. 64.39 58.40 77.96 66.49 58.62 48. 82.14 69.98 75.15 54.97 73.98 76. 75.04 54.31 80.38 54.99 65.41 54. 74.08 75.62 76.49 45.58 71.00 65. 69.33 87.12 97.01 95.89 96.38 86. 94.21 95.73 53.11 94.14 80.11 89. 84.20 98.41 68.68 94.09 53.25 79. 79.87 80.22 49.64 78.34 85.01 78. 83.27 98.32 57.68 93.23 52.58 72. 79.54 74.92 49.18 69.03 68.82 72. 78.76 69.06 65.20 68.98 65.00 56. 52.46 62.70 66.90 62.86 71.44 55. 78.78 75.76 72.13 49.61 60.43 60. 52.87 71.95 73.41 55.27 59.60 45. 58.60 55.45 55.28 52.94 49.54 52. 49.99 68.00 49.78 69.49 49.99 90. 50.00 67.68 49.95 89.16 52.43 62. 50.51 50.00 50.00 50.00 50.00 86. 50.00 50.49 50.46 83.53 50.52 81. 50.38 49.83 49.89 54.53 87.97 88. 93.27 84.68 89.43 91.90 90.40 92. 93.16 78.67 88.80 75.41 90.43 78. 81.23 70.74 90.50 89.69 90.61 55. 74.07 67.12 83.54 80.38 86.23 72. 84.86 57.44 89.25 87.29 89.18 87. 93.05 90.68 93.79 90.79 88.98 93. 54.75 90.30 63.73 69.10 58.49 93. 69.25 83.44 55.46 88.80 86.69 88. 51.17 79.48 61.98 70.24 60.99 93. 64.20 79.96 52.52 81.11 88.10 84. 84.67 72.41 82.61 76.37 73.36 78. 86.45 66.06 74.04 58.77 59.54 68. 73.33 62.46 86.87 67.29 86.84 85. 85.76 52.89 70.26 52.01 57.58 71. 80.12 49.54 77.01 55.36 67.99 70. 86.51 91.42 95.08 91.91 96.46 90. 94.66 94.73 82.77 91.46 93.76 97. 94.73 96.46 63.71 96.28 96.91 95. 95.61 95.34 49.69 92.96 95.53 94. 94.98 95.78 52.96 96.79 52.09 96. 97.04 95.70 96.18 75.50 81.86 65. 74.23 65.28 65.36 73.98 51.74 81. 82.21 73.45 68.42 62.90 63.50 63. 56.53 55.75 56.48 54.93 49.86 77. 79.13 78.37 58.13 52.17 61.75 49. 55.20 52.95 49.53 95.21 95.02 93. 92.95 93.42 95.17 96.28 49.64 92. 70.19 83.02 58.51 94.95 55.24 72. 51.62 67.22 62.16 60.06 50.42 84. 71.52 74.76 60.02 93.35 50.73 77. 50.03 62.58 63.10 60.97 89.68 95. 93.33 89.04 88.74 92.26 88.16 88. 63.94 81.58 72.32 62.44 87.55 50. 61.82 48.13 74.93 61.71 75.19 52. 47.56 73.23 69.78 75.48 84.60 69. 69.53 49.81 54.78 50.75 48.86 96. 98.16 90.21 95.30 94.09 97.65 97. 50.07 86.33 86.27 95.58 76.71 95. 64.10 88.84 50.60 72.54 73.85 66. 50.17 82.97 77.04 80.37 81.63 95. 58.08 90.65 50.52 74.73 73.65 76. 93.17 94.92 93.44 88.50 92.49 90. 84.17 95.97 91.76 96.37 85.59 84. 89.74 72.20 88.02 69.17 85.73 87. 88.89 55.94 79.93 79.17 92.85 88. 76.93 61.61 76.88 51.08 88.85 83. 92.52 51.74 97.23 93.07 94.24 96. 96.09 97.34 50.09 92.63 51.28 63. 50.00 96.71 53.91 68.37 50.15 50. 76.66 59.57 50.00 80.58 53.15 50. 50.00 95.56 50.50 71.41 50.24 57. 77.28 55.12 51.31 52.97 52.26 56. 55.71 62.41 58.91 52.85 63.23 54. 51.73 55.70 62.01 52.66 54.04 51. 51.18 52.93 54.03 50.62 68.38 52. 51.33 52.99 61.03 58.55 61.92 50. 66.85 64.65 70.39 55.22 68.02 58. 63.08 66.75 54.26 71.35 49.99 67. 51.00 68.08 50.39 67.18 49.83 57. 50.16 54.14 55.32 50.48 49.78 58. 51.82 51.68 50.30 70.16 49.17 63. 50.19 63.19 52.91 64.17 TABLE XLIV: Balanced classiﬁcation accuracies (%) on CHB-MIT. The best BCAs are marked in bold, and the second best by an underline (continued). Scenario Tuning Model Type Approach S12 S13 S15 S16 S17 S18 S19 S21 S22 Avg. 58 Specialist Models Foundation Models Full Fine-tuning Cross-subject Linear Probing Foundation Models Specialist Models Foundation Models Full Fine-tuning Linear Probing Foundation Models Within-subject (Few-shot) PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge PSD+SVM EEGNet ShallowConv LMDA CNN-T DeFormer Conformer BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge BENDR BIOT LaBraM Neuro-GPT EEGPT CBraMod TFM EEGMamba SingLEM LUNA-Base LUNA-Large LUNA-Huge 56.12 54.37 54.55 61.56 70.90 55.98 56.59 56.70 62.23 59.47 58.81 63.01 58.18 61.89 52.26 52.45 61.62 55.83 54. 51.95 56.87 65.36 61.24 67.50 60.81 46.44 50.99 50.10 63.78 55.78 59.00 72.84 87.90 90.18 85.23 89.72 89.18 88.84 56.44 76.14 79.61 77.87 73.68 86.16 55.78 58.35 63.97 52.65 55.44 56.41 49.98 58.04 77.29 71.10 71.44 75.72 52.53 69.41 54.63 53.68 53.99 53.27 51.04 30.62 38.57 39.29 55.64 41.81 21.68 48.57 37.74 50.92 45.64 42.65 44.28 44.32 43.64 42.78 52.89 54.06 42. 51.62 24.85 56.90 39.35 48.01 33.79 41.11 48.51 45.47 31.50 29.40 32.93 53.15 70.06 78.94 65.05 68.65 79.20 82.31 50.00 68.66 53.60 80.63 54.50 76.56 55.30 79.47 49.97 51.80 61.44 57.84 50.00 74.08 50.00 81.42 66.12 80.55 50.95 77.32 50.07 62.17 70.07 70.92 49.86 54.02 69.35 58.09 51.79 74.85 68.84 62.03 55.77 72.57 70.32 67.15 54.76 61.89 76.33 60.07 63.44 61.23 53. 51.68 52.78 69.54 73.59 72.61 54.34 62.13 65.25 48.77 50.69 54.01 50.80 77.52 91.11 81.99 89.46 86.32 89.72 93.00 50.77 50.00 81.53 86.13 59.71 88.94 57.39 74.28 56.27 65.62 75.29 79.71 50.50 50.00 71.94 79.58 53.47 89.33 51.50 86.65 51.88 64.11 77.90 64.94 49.27 75.54 75.29 74.02 57.07 74.82 72.63 58.28 72.12 60.03 64.96 54.61 71.82 47.14 78.58 54.61 79.78 75.13 76. 55.87 66.40 62.44 49.10 59.64 77.23 47.62 63.26 48.19 53.68 57.88 70.66 50.00 52.91 53.10 50.00 74.69 49.93 74.27 51.54 78.04 50.00 56.67 50.00 66.94 49.93 70.99 49.96 53.96 57.81 63.88 50.00 73.09 50.00 51.09 52.20 72.25 50.31 80.53 49.77 66.69 58.85 66.86 50.00 94.87 91.68 88.82 64.55 96.25 95.31 90.60 76.85 71.66 81.19 76.75 60.88 68.85 83.41 62.24 94.30 94.60 83. 53.94 78.24 81.37 84.57 84.60 78.56 58.64 86.79 56.62 70.40 67.62 67.34 86.44 96.50 96.94 95.22 91.67 96.17 96.67 60.61 91.44 72.67 90.72 63.83 96.50 67.72 79.89 51.61 85.00 82.33 88.33 51.06 83.83 69.89 75.44 73.44 96.33 61.61 81.94 52.78 80.94 82.78 77.39 50.00 86.18 86.05 79.03 73.09 80.38 80.66 83.32 71.03 58.89 83.05 74.61 63.14 59.67 70.16 55.30 79.55 80.31 78. 51.14 73.37 55.99 84.47 81.87 65.85 52.52 65.32 51.80 71.90 68.28 72.91 68.64 86.13 86.10 86.23 83.71 87.18 87.45 50.44 77.56 77.81 89.30 60.27 84.86 55.30 77.94 49.18 83.68 72.40 84.20 50.42 65.05 55.71 77.08 69.48 79.69 44.13 76.84 50.24 77.06 74.70 80.23 84.62 82.05 95.30 96.15 93.48 96.15 98.29 83.22 91.91 79.03 75.90 68.75 90.60 71.44 91.66 58.55 91.03 92.74 90. 59.84 93.68 73.90 74.73 65.05 93.16 66.76 88.24 43.40 90.42 70.80 90.17 87.50 95.83 97.56 100.00 96.67 97.50 100.00 57.06 87.44 97.50 99.56 76.67 99.17 73.78 99.06 46.50 82.89 64.78 80.78 49.06 53.22 88.33 92.11 85.00 100.00 52.33 100.00 45.33 97.39 54.11 95.78 49.96 75.56 76.33 69.55 59.63 81.35 83.68 66.16 71.12 52.87 72.43 63.55 59.83 53.00 75.38 52.69 63.06 67.19 62. 49.31 80.90 54.55 62.60 65.41 69.86 45.70 67.19 49.47 65.27 71.98 77.87 84.23 95.03 85.88 94.58 89.06 91.24 91.91 50.27 50.00 77.32 91.95 50.49 92.99 58.52 92.23 50.05 88.49 85.15 69.02 49.92 50.00 55.65 75.87 54.47 95.90 55.47 88.06 50.06 80.67 92.74 78.41 50.00 57.77 64.94 56.69 68.34 71.57 64.63 65.96 57.94 55.44 66.88 57.37 66.58 52.12 54.09 54.98 70.98 63.18 67. 51.49 55.73 65.02 58.39 56.95 71.09 52.52 61.27 53.37 60.91 56.27 59.91 74.17 99.44 97.98 94.90 97.36 98.49 99.33 49.36 92.63 50.88 98.53 49.96 92.75 59.83 90.11 55.30 83.20 83.61 83.48 49.81 87.78 52.78 72.92 50.40 93.55 53.97 94.66 50.70 86.55 85.01 85.88 87.22 90.78 95.19 92.44 89.22 96.19 95.56 86.56 95.30 91.48 95.37 79.89 93.11 78.89 92.33 81.78 91.41 90.59 86. 52.11 87.37 91.00 93.67 82.67 88.04 59.15 86.41 56.63 83.07 84.56 90.85 93.54 97.52 92.17 99.31 91.50 97.63 97.93 60.72 96.87 90.52 93.83 76.46 96.37 69.15 81.87 78.35 75.37 73.48 81.76 49.83 82.26 86.67 79.20 85.44 96.54 56.20 79.78 51.50 71.28 74.78 73.37 66.25 93.24 92.68 95.52 96.10 83.17 92.78 84.20 88.98 76.45 79.72 72.82 85.19 67.94 93.32 69.67 94.20 94.81 93. 55.64 77.86 84.51 76.37 71.72 87.10 47.10 81.55 49.01 71.19 73.95 74.79 84.93 98.59 96.28 97.83 91.30 95.57 95.09 58.78 91.24 82.35 98.09 78.91 95.89 54.30 88.07 70.35 88.48 88.11 91.46 49.96 86.56 74.87 75.76 86.44 95.17 54.41 90.57 54.89 69.15 84.43 72.65 69.090.04 77.360.54 80.180.22 77.470.41 76.340.61 79.770.14 78.580.56 75.500.93 74.850.33 70.870.59 73.270.27 66.912.89 74.230.19 63.460.60 75.920.21 60.781.82 78.120.61 77.140.14 75.840. 53.220.68 69.790.62 68.840.36 70.450.24 70.940.69 75.210.52 56.830.75 71.810.26 50.500.11 67.430.45 66.310.27 71.110.88 77.710.35 88.450.48 85.810.44 86.800.55 87.660.33 86.880.33 91.580.34 54.140.33 79.600.51 71.310.29 83.090.59 63.740.28 88.540.16 59.550.57 79.500.42 56.701.49 72.300.26 73.301.66 75.520.92 50.070.18 73.411.06 66.930.88 71.681.57 66.711.20 87.770.73 53.320.37 82.180.17 51.070.11 71.110.20 73.700.41 72.780.30 59 TABLE XLV: Cohens Kappa (%) on Sleep-EDFx. The best metrics are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Specialist\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "PSD+LDA"
        },
        {
            "title": "LMDA",
            "content": "CNN-T"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base 56.10 63.53 68.04 68.32 67. 72.88 59.78 76.15 65.95 63.60 54. 60.45 66.75 62.76 60.39 61.85 65. 40.53 47.70 52.84 53.15 52.92 38. 49.83 33.69 12.25 47.75 59.27 64. 73.86 71.47 72.69 76.44 68.40 79. 69.48 67.09 53.42 61.84 71.36 63. 62.47 63.99 69.71 48.72 48.52 55. 55.33 60.78 38.57 51.59 29.94 10. 52.82 63.88 67.99 73.79 73.13 73. 78.41 66.12 80.45 69.78 66.24 57. 63.40 71.34 65.59 63.43 65.96 70. 49.01 51.40 57.35 56.25 50.73 42. 53.69 35.53 11.92 56.15 56.79 64. 70.82 67.84 69.17 73.18 59.30 77. 67.20 63.43 53.97 59.13 67.44 60. 58.05 61.68 64.22 47.65 47.02 50. 50.77 49.04 34.84 50.69 31.04 10. 47.18 57.29 57.62 70.45 67.83 70. 72.55 58.51 77.56 66.54 62.52 53. 62.45 66.69 60.84 60.18 60.32 63. 48.01 46.62 51.52 51.70 58.73 35. 49.36 30.86 9.41 50.25 57.88 59. 74.03 71.82 70.47 76.14 63.49 79. 68.20 65.47 56.30 63.43 69.89 60. 61.11 64.20 67.19 44.00 46.09 52. 53.39 41.03 31.92 49.95 26.89 10. 48.95 61.43 66.20 69.73 69.69 69. 74.63 60.56 78.10 66.66 64.54 50. 59.18 68.24 61.70 58.83 62.02 69. 46.38 47.44 50.99 50.29 47.84 36. 50.26 30.37 9.91 49.64 61.09 66. 73.05 72.17 73.14 75.42 66.83 78. 71.01 68.31 60.33 63.50 71.78 65. 68.97 68.07 68.65 47.20 53.73 59. 59.57 40.59 45.32 56.49 33.56 10. 56.21 54.35 63.21 69.78 65.08 66. 71.62 54.80 77.16 65.31 63.22 52. 61.10 65.67 61.96 59.06 61.75 64. 45.67 46.74 53.28 50.26 51.59 38. 49.58 32.59 10.65 50.40 60.02 69. 74.67 71.87 72.74 77.20 67.53 80. 70.37 62.94 58.40 65.52 71.95 64. 66.28 67.16 65.35 51.10 54.46 57. 55.37 51.98 41.96 55.97 32.30 10. 55.43 58.810.18 64.360.46 71.820.32 69.920.12 70.530.29 74.850.23 62.530.54 78.420.19 68.050.14 64.740.60 55.020.12 62.001.29 69.110.28 62.770.24 61.880.34 63.700.74 66.900.18 46.830.11 48.970.16 54.080.18 53.610.67 50.524.11 38.500.12 51.740.55 31.680.04 10.600.10 51.480.08 TABLE XLVI: Balanced classiﬁcation accuracies (%) on Sleep-EDFx. The best BCAs are marked in bold, and the second best by an underline."
        },
        {
            "title": "Approach",
            "content": "S0 S1 S2 S3 S4 S6 S7 S8 S9 Avg."
        },
        {
            "title": "Specialist\nModels",
            "content": "Full Fine-tuning Cross-subject"
        },
        {
            "title": "Foundation\nModels",
            "content": "PSD+LDA"
        },
        {
            "title": "LMDA",
            "content": "CNN-T"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base"
        },
        {
            "title": "LaBraM",
            "content": "Neuro-GPT"
        },
        {
            "title": "SingLEM",
            "content": "LUNA-Base 50.10 72.61 71.21 71.89 73. 76.20 65.74 68.37 64.23 62.67 59. 57.46 70.05 65.93 65.22 65.25 68. 48.81 58.35 60.17 56.23 51.08 53. 55.02 52.38 35.47 54.87 51.22 73. 75.28 74.39 75.88 79.32 69.70 72. 67.27 64.24 58.45 62.29 72.99 67. 66.62 67.45 69.91 55.96 60.80 63. 58.46 59.04 50.79 57.19 50.55 34. 57.74 54.46 76.61 76.94 77.64 76. 81.04 71.25 72.50 67.63 63.63 61. 64.94 74.26 70.51 69.51 69.48 74. 56.68 63.02 65.30 60.02 53.49 55. 57.55 55.26 36.56 62.11 52.93 73. 74.56 73.91 74.88 78.35 69.89 72. 66.25 62.91 57.98 62.73 71.49 65. 65.03 65.39 69.50 55.64 60.09 61. 57.11 57.05 51.87 56.13 52.24 34. 57.14 50.65 71.52 75.21 73.72 76. 78.19 67.08 72.26 66.37 63.32 58. 64.02 72.00 67.62 65.41 67.20 69. 56.52 60.69 62.19 58.46 56.04 50. 57.09 52.57 34.83 57.17 50.79 72. 76.35 75.17 76.70 79.99 70.07 72. 67.16 64.06 61.04 65.59 73.37 66. 66.35 68.24 72.39 53.80 58.98 62. 58.54 56.79 48.93 55.97 49.67 34. 57.13 53.69 73.94 73.75 74.84 73. 77.53 68.00 70.03 64.43 63.71 55. 60.59 70.94 66.18 64.16 65.81 72. 55.01 58.61 61.71 56.62 57.66 51. 57.26 50.40 33.72 58.12 51.11 73. 73.93 75.13 77.56 78.57 68.04 70. 67.88 63.71 61.36 64.60 73.63 67. 68.44 68.28 71.24 53.53 61.45 63. 58.15 52.46 55.53 58.13 51.98 34. 59.53 49.63 73.22 73.90 72.84 74. 76.94 63.71 70.09 63.95 63.46 56. 62.29 70.18 66.63 66.15 65.63 69. 53.71 60.17 61.49 56.22 58.66 53. 55.73 51.93 34.26 57.64 53.23 76. 77.52 76.27 77.08 81.19 70.53 73. 68.33 63.84 60.55 64.78 74.09 69. 69.90 69.59 73.10 58.18 63.72 65. 59.70 54.44 54.76 59.40 52.56 34. 59.96 51.780.22 73.750.19 74.860.42 74.580.34 75.740.48 78.730.09 68.402.87 71.450.43 66.350.23 63.560.03 59.090.25 62.931.06 72.300.18 67.380.25 66.680.42 67.230.48 71.030.36 54.780.12 60.590.19 62.730.24 57.950.58 55.670.87 52.560.30 56.950.46 51.960.13 34.770.13 58.140.22 60 TABLE XLVII: Cohens Kappa (%) on Sleep-EDFx. The best metrics are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S0 S1 S3 S4 S5 S6 S7 S9 S10 S11 S12 S13 S15 S16 S17 S18 S19 Within-subject (Few-shot) Specialist Models PSD+LDA 76.05 76.34 71.08 72.37 70.51 71.57 78.11 75.49 69.06 73.75 74.44 54.00 64.18 62.49 81.67 70.96 60.14 60.24 75.96 64.20 EEGNet 68.07 66.92 65.91 65.31 64.62 58.55 70.20 66.64 60.08 64.74 67.14 49.53 54.38 56.74 67.67 66.85 53.43 55.28 70.70 51.05 ShallowConv 79.86 75.38 74.20 78.72 73.63 65.23 79.29 75.15 70.52 72.05 78.05 63.33 66.42 75.73 82.40 72.67 51.99 62.81 76.39 65.52 LMDA CNN-T 68.53 60.54 64.10 71.80 56.80 60.37 64.88 64.24 65.13 57.15 56.75 51.41 55.35 32.78 60.03 57.98 33.87 41.19 72.18 47.23 78.99 79.04 83.43 82.28 76.73 64.38 77.43 81.90 76.95 75.15 79.48 65.79 57.00 60.84 72.67 74.04 75.59 64.08 79.52 63.98 DeFormer 74.48 76.89 76.21 74.37 71.64 75.37 77.22 76.09 69.98 69.73 75.19 48.38 65.95 63.33 70.70 74.74 65.84 61.88 75.98 55.29 Conformer 80.60 68.84 80.33 81.97 73.85 69.94 73.32 82.02 65.89 68.86 75.48 68.09 65.76 67.50 86.49 74.70 68.47 49.82 73.78 61.65 Full Fine-tuning BENDR 55.59 68.93 66.95 63.25 61.82 31.11 63.89 57.70 50.14 64.17 69.36 43.97 49.18 15.14 59.99 59.58 45.07 30.47 64.01 54. BIOT 77.86 78.96 79.65 82.10 73.79 64.71 72.43 76.51 71.83 71.32 77.09 65.99 69.11 70.88 69.57 75.15 70.14 59.66 78.63 53.91 LaBraM 52.97 57.26 42.52 47.91 38.57 41.87 34.22 56.70 47.83 57.29 48.81 50.48 23.72 14.45 59.28 51.19 23.61 32.71 60.63 26.48 Neuro-GPT 70.34 64.86 72.32 75.45 67.42 58.35 65.32 67.14 63.94 66.34 71.14 47.27 57.54 71.05 70.95 67.26 63.64 48.46 71.57 45. Foundation Models EEGPT 61.83 70.02 65.65 73.44 70.04 64.73 71.51 71.36 64.45 68.95 54.70 49.13 67.99 68.83 75.28 68.66 65.77 59.06 61.58 60.82 CBraMod 73.38 71.99 75.45 76.20 67.65 60.18 59.49 71.28 70.19 67.81 72.29 59.26 57.82 56.25 69.93 66.55 64.52 55.59 73.31 52.59 TFM 75.79 71.85 75.82 79.93 67.52 68.54 73.64 69.02 71.57 71.01 68.08 59.42 64.78 70.69 79.76 73.93 55.12 54.44 75.04 57.66 EEGMamba 77.63 69.81 67.89 79.15 69.94 68.04 70.17 78.79 72.42 68.73 66.37 62.53 59.57 70.69 80.40 72.67 59.72 54.44 76.45 57.82 SingLEM 4.50 16.19 9.17 22.44 26.75 3.48 20.81 21.67 4.84 38.48 2.99 14.48 1.94 4.99 16.88 43.65 4. 1.69 32.92 8.30 LUNA-Base 83.07 82.58 77.88 81.08 70.27 77.43 67.35 70.57 79.43 66.25 74.71 42.81 69.10 71.91 82.17 67.57 57.96 60.72 81.58 55.50 BENDR 3.44 4. 6.69 2.02 8.14 5.18 7.24 2. 2.93 6.01 4.34 2.59 2.05 1. 2.52 3.69 3.15 1.45 2.59 4. BIOT 73.21 70.24 70.06 73.59 70.03 58.03 67.18 59.88 64.22 69.90 60.71 41.38 61.11 74.19 67.18 65.66 68.44 52.24 73.55 44.73 LaBraM 68.54 68.82 67.58 72.16 65.28 58.02 66.82 70.84 63.82 68.90 60.59 55.30 56.66 66.44 70.82 67.68 56.44 49.30 71.69 55.62 Linear Probing Foundation Models Neuro-GPT 65.95 57.41 67.73 65.52 61.25 52.08 60.04 54.69 62.19 60.12 57.49 40.73 54.52 65.22 66.28 59.97 57.16 39.34 67.75 39.80 EEGPT 81.36 80.86 81.19 84.84 75.15 81.15 80.40 86.59 84.55 80.78 76.89 34.70 79.14 80.91 90.95 71.38 74.36 67.78 70.50 65.17 CBraMod 56.36 60.74 42.16 66.38 57.75 46.21 51.43 49.31 40.26 56.35 42.52 49.19 22.85 45.42 50.51 37.19 35.17 29.12 59.26 30. TFM 63.21 55.67 60.55 65.88 55.74 49.10 63.18 54.81 58.06 53.77 44.22 53.40 50.61 44.00 63.11 62.62 43.07 37.79 67.39 51.84 EEGMamba 45.54 39.27 41.52 52.38 48.35 31.13 41.62 42.18 41.06 41.53 30.41 48.26 23.87 34.60 39.61 34.67 21.88 18.55 46.05 21.97 SingLEM 2. 1.67 3.43 2.49 4.37 -0.16 2.13 2.13 3. 0.90 2.87 1.13 1.08 1.73 1. 1.03 1.80 0.13 1.34 1.33 LUNA-Base 82.24 62.75 77.03 70.49 62.64 68.62 64.03 66.64 77.24 61.20 55.92 40.12 67.01 66.21 75.85 61.20 28.38 48.35 79.92 54.13 Scenario Tuning Model Type Approach S20 S22 S23 S24 S25 S26 S28 S29 S30 S31 S32 S34 S35 S36 S37 S38 Within-subject (Few-shot) Specialist Models PSD+LDA 56.91 70.77 43.60 64.76 71.03 65.69 61.75 65.46 70.38 56.23 63.89 60.88 64.81 64.82 69.85 60.83 68.23 49.04 69.01 54.77 EEGNet 44.28 66.99 24.39 38.33 70.58 60.23 53.63 52.13 62.99 51.16 60.97 54.90 52.54 63.78 58.87 51.54 72.69 56.03 66.98 52. ShallowConv 45.81 73.15 27.15 47.40 74.47 70.56 64.35 57.22 68.92 50.98 69.95 66.30 68.01 67.94 74.11 59.68 73.04 57.94 72.25 53.23 LMDA CNN-T 35.99 64.28 26.06 23.22 62.28 57.07 50.66 50.96 56.42 36.74 51.78 53.09 43.59 64.96 70.29 33.72 53.26 53.31 54.86 54.86 41.63 75.49 46.46 56.48 77.43 71.11 69.96 51.61 77.69 60.33 68.56 64.71 65.69 68.83 78.87 54.12 44.41 59.72 61.77 56. DeFormer 47.56 73.72 54.94 55.71 76.61 72.33 65.82 52.38 72.68 50.21 70.40 59.09 62.71 71.55 74.21 63.50 72.04 62.42 70.62 65.35 Conformer 54.91 63.04 29.08 67.98 74.26 73.97 67.92 64.09 75.67 55.48 64.22 61.94 58.42 70.13 75.56 49.96 63.64 56.34 71.84 56.33 Full Fine-tuning BENDR 55.80 57.68 39.03 26.46 73.48 67.98 56.02 41.51 61.39 47.62 46.17 54.12 44.69 66.84 72.96 23.72 26.99 50.10 72.78 48.20 BIOT 40.49 67.64 41.78 51.36 68.25 71.94 71.24 61.64 76.44 52.92 68.21 63.57 66.82 67.97 69.84 57.30 66.06 58.26 63.74 53.99 LaBraM 16.85 44.12 40.11 38.68 55.82 37.66 45.85 26.30 57.02 35.74 26.04 52.51 26.58 43.68 50.47 38.76 51.96 40.98 48.12 45.10 Neuro-GPT 37.23 61.90 31.29 59.55 68.92 71.17 58.31 45.43 66.43 51.18 62.86 56.44 58.62 66.04 68.86 53.01 69.49 58.88 61.84 53.06 Foundation Models EEGPT 47.56 57.43 59.14 45.56 59.67 51.35 71.44 63.59 60.88 65.62 46.97 58.68 62.81 56.86 60.44 53.14 45.22 40.34 46.24 47.60 CBraMod 43.87 65.12 21.66 53.89 65.89 66.22 56.14 61.64 69.89 53.75 59.87 58.69 66.41 70.45 62.37 56.99 59.26 59.35 58.00 54. TFM 60.46 68.95 40.50 65.36 68.84 72.52 64.26 63.31 72.42 56.66 64.16 57.99 68.64 68.53 72.78 60.86 75.71 57.45 68.44 54.98 EEGMamba 46.02 57.72 31.69 58.61 69.05 66.89 64.01 61.45 75.92 56.43 69.31 58.39 43.21 66.43 61.72 59.50 70.61 62.55 67.38 56.75 SingLEM 15.99 8.68 18.09 22.70 23.05 7.10 40.27 2.62 35.41 9. 2.58 40.08 19.41 53.17 37.36 4.58 1.31 8.05 18.10 16.50 LUNA-Base 55.38 70.07 28.33 55.10 76.92 79.01 69.66 63.93 70.95 57.81 67.68 74.97 69.24 71.36 77.41 50.15 60.91 54.41 69.12 58.69 BENDR 4.24 3.21 5.30 1.47 7.79 4. 5.00 1.90 3.51 1.18 0.76 2. 1.14 2.96 8.90 4.70 0.92 4. 4.29 2.46 BIOT 41.03 63.56 46.77 56.67 61.95 68.80 62.42 49.63 74.44 47.58 60.67 60.17 53.69 63.32 64.16 50.47 63.87 53.62 40.41 48.80 LaBraM 53.94 66.83 32.43 59.41 67.69 62.01 58.43 52.61 64.01 48.19 60.55 53.92 53.34 66.40 68.00 64.20 75.25 53.90 70.19 57. Neuro-GPT 38.25 58.63 30.76 55.99 59.61 64.11 52.68 49.14 64.79 39.29 58.54 52.03 48.41 60.22 58.31 52.62 69.79 54.23 55.01 52.57 Linear Probing Foundation Models EEGPT 57.20 79.65 76.10 62.65 76.57 76.75 78.09 74.32 67.34 72.42 69.43 73.63 35.01 73.66 54.59 64.73 77.41 51.80 74.02 63. CBraMod 35.61 57.81 20.49 39.23 61.97 52.40 42.34 48.07 64.24 34.13 45.61 45.29 14.82 38.93 53.17 31.55 58.36 47.82 55.21 44.29 TFM 50.40 63.15 40.69 55.49 60.70 54.77 45.25 38.95 57.87 43.67 47.25 52.16 48.97 63.05 66.30 46.90 37.44 49.51 52.16 50.41 EEGMamba 25.16 30.52 20.77 28.27 46.50 27.97 33.60 45.55 45.60 26.46 27.18 36.33 16.95 30.73 34.03 36.64 35.85 34.37 20.77 26. SingLEM 0.68 1.61 1.46 0.56 1. 0.88 2.79 3.04 1.78 1.69 1. 1.17 2.74 -0.35 4.77 1.85 -0.47 3.18 0.91 1. LUNA-Base 46.98 67.18 20.24 50.07 70.08 68.63 66.45 56.21 67.50 49.61 65.08 69.93 64.18 66.70 63.30 53.78 62.76 36.52 58.52 62.46 61 TABLE XLVIII: Cohens Kappa (%) on Sleep-EDFx. The best metrics are marked in bold, and the second best by an underline (continued). Scenario Tuning Model Type Approach S40 S41 S42 S43 S45 S46 S47 S48 S49 S51 S52 S53 S54 S55 S57 S58 S59 Specialist Models PSD+LDA 60.81 79.48 57.11 62.76 68.15 72.18 34.91 70.09 65.06 35.52 65.74 68.05 67.14 61.19 60.39 63.43 38.45 64.77 55.56 56. EEGNet 50.38 64.13 58.96 55.70 63.84 64.56 29.35 58.49 52.60 27.76 53.26 47.94 63.90 56.26 63.56 47.90 33.88 54.83 28.16 56.34 ShallowConv 62.44 76.83 67.35 61.78 72.67 68.42 36.94 61.12 63.81 25.67 53.44 56.91 63.39 62.93 63.05 59.87 50.78 62.06 35.74 61.59 LMDA CNN-T 47.38 69.64 37.59 51.89 57.61 59.41 21.42 48.23 45.17 21.05 33.30 28.06 57.72 43.58 59.97 42.24 23.54 39.14 28.18 43.34 58.41 74.38 66.03 56.76 79.10 57.96 26.74 54.55 68.41 24.70 59.89 63.16 61.25 61.30 53.36 60.27 49.76 45.95 35.16 65.55 DeFormer 63.82 75.53 67.95 59.28 67.85 65.33 37.83 67.75 61.26 30.30 30.92 69.33 69.16 62.23 60.77 66.81 52.39 59.73 31.10 61.72 Conformer 56.19 69.18 67.74 48.95 62.50 64.98 40.67 77.18 56.99 28.16 60.73 56.52 59.94 61.42 52.65 61.10 45.71 50.14 47.21 62. Full Fine-tuning BENDR 24.16 55.50 65.60 55.61 57.28 67.43 10.71 57.21 55.80 39.68 26.37 23.95 49.50 43.92 65.75 49.79 35.91 59.58 21.22 51.09 BIOT 64.49 75.89 72.74 55.64 66.89 67.98 30.87 72.92 63.19 32.39 62.53 63.80 65.50 59.80 58.37 58.55 49.49 51.21 34.91 51.62 LaBraM 43.33 47.94 34.71 40.40 40.45 63.54 24.73 32.99 63.97 13.30 32.04 16.24 22.64 34.22 54.66 23.16 25.54 39.72 22.16 34.67 Neuro-GPT 59.09 70.05 62.35 48.72 58.29 66.76 29.96 64.35 60.49 29.04 59.47 66.56 59.87 61.37 57.56 59.24 53.67 47.32 30.26 50.75 Foundation Models EEGPT 62.65 67.78 57.64 50.32 64.54 55.30 49.60 68.83 50.79 42.00 47.60 44.08 56.67 61.17 39.16 48.04 37.62 42.35 57.78 56. CBraMod 58.36 72.36 38.89 52.23 62.08 68.77 26.60 64.76 64.86 29.63 56.45 56.98 62.01 65.59 51.66 54.16 57.79 44.91 40.24 58.91 TFM 64.10 74.65 62.82 54.17 65.94 70.01 36.03 67.63 65.10 35.05 64.78 63.78 65.80 62.84 58.26 58.55 45.61 52.29 42.90 60.20 EEGMamba 51.02 77.73 50.95 54.77 71.38 62.59 24.99 71.74 61.30 30.19 53.90 53.00 63.07 55.75 54.75 60.02 40.34 50.58 40.79 53. SingLEM 26.36 24.24 7.97 12.68 29.89 30.22 3.59 44.01 32.08 1.48 25.42 3.51 16.37 7.59 20.93 2.49 5.55 13.42 8.42 8.78 LUNA-Base 66.60 78.98 50.91 63.31 73.80 64.01 63.40 64.70 56.64 33.83 59.72 49.49 65.37 63.84 62.10 64.86 60.17 62.53 38.72 63. BENDR 3.02 2.94 2.81 5.00 3. 2.50 -0.83 3.11 1.46 2.00 3.63 0.60 5. 2.29 2.85 6.16 11.61 4.20 3.33 1.97 BIOT 55.86 69.45 55.32 49.49 62.64 62.09 14.54 68.60 59.21 33.50 62.73 58.83 57.32 58.20 51.66 55.27 44.48 42.50 32.65 49.05 LaBraM 56.34 69.03 53.79 54.73 61.84 66.17 31.72 62.37 64.14 32.64 59.52 67.60 62.44 56.09 53.11 48.02 34.22 50.16 38.46 50.83 Neuro-GPT 55.26 64.23 56.97 47.14 55.05 59.89 29.11 59.13 55.39 27.25 50.53 63.04 56.03 53.78 49.95 49.49 36.83 43.48 28.66 41.97 Within-subject (Few-shot) Linear Probing Foundation Models EEGPT 72.83 81.15 80.54 58.80 68.18 67.70 57.41 71.71 78.10 50.99 68.03 74.12 70.37 72.32 61.54 58.86 63.47 69.49 56.20 62.73 CBraMod 36.44 62.94 40.24 47.19 31.63 53.57 18.68 52.33 54.39 14.64 43.71 22.77 39.71 44.01 49.55 11.80 18.73 24.64 31.24 36. TFM 56.17 53.98 30.79 48.19 54.54 68.64 19.15 53.59 58.37 24.71 53.81 51.73 56.22 50.51 53.44 48.79 19.12 46.50 27.99 35.12 EEGMamba 33.83 53.96 30.99 24.38 36.71 47.89 23.45 45.09 40.29 19.34 26.74 26.40 44.99 23.92 34.73 25.22 18.79 28.15 20.44 20.70 SingLEM 2. 2.20 0.97 2.47 2.89 3.04 2. 2.55 0.69 0.33 2.74 1.66 1. 2.40 2.21 2.86 2.95 1.68 1. 1.39 LUNA-Base 67.89 77.18 58.74 60.19 70.68 62.73 57.75 71.15 57.12 28.30 60.78 45.64 62.87 49.03 61.75 57.72 30.69 56.35 29.52 55.13 Scenario Tuning Model Type Approach S60 S61 S62 S63 S64 S66 S67 S68 S69 S70 S72 S73 S74 S75 S76 Avg. PSD+LDA 62.80 53.51 61.26 56.24 61.89 59.01 46.51 64.63 54.97 49.33 56.25 53.87 62.94 61.34 48.01 58.08 62.80 69.64 62.90 Within-subject (Few-shot) Specialist Models EEGNet 59.52 47.53 67.36 59.21 53.58 55.27 42.55 57.49 55.15 48.69 51.51 55.28 46.34 54.77 46.91 59.37 50.64 53.98 ShallowConv 65.26 48.71 74.65 59.74 60.64 47.28 51.80 68.31 58.58 54.40 59.07 59.81 54.39 61.11 50.27 68.64 62.01 70.94 LMDA CNN-T 63.41 48.28 62.81 47.92 47.07 48.66 22.77 58.26 49.36 47.45 42.36 53.18 30.52 53.14 40.93 57.96 48.85 54.79 67.76 46.96 73.48 58.94 61.83 57.13 56.89 59.52 49.81 58.19 60.15 48.63 3.15 63.43 55.09 64.69 65.61 75.86 DeFormer 64.71 51.12 73.00 58.13 60.58 52.78 48.79 65.23 54.80 58.59 54.11 59.20 57.37 56.87 48.00 67.09 60.25 71.50 Conformer 60.25 31.18 73.38 73.56 52.24 49.08 55.70 51.85 43.90 58.64 56.16 58.74 44.97 55.27 49.46 70.40 63.14 64. Full Fine-tuning BENDR 57.19 60.27 69.17 54.79 61.49 45.67 18.32 53.11 61.95 43.57 49.05 60.62 13.28 54.83 46.31 58.82 54.01 55.76 BIOT 64.70 50.29 73.79 54.58 47.55 42.69 49.54 67.05 51.33 54.91 56.75 58.21 69.12 54.63 47.07 59.73 59.74 70.04 LaBraM 55.07 54.87 46.16 35.94 55.38 45.00 6.03 23.64 37.45 25.01 28.92 38.42 3.97 27.85 33.78 33.19 44.81 23.88 Neuro-GPT 57.03 44.41 65.17 56.46 47.86 49.83 51.14 61.63 52.84 60.28 53.13 56.91 57.19 57.43 42.13 63.95 55.36 60.22 Foundation Models EEGPT 54.08 41.03 45.14 57.85 53.36 48.53 46.64 43.99 44.20 51.11 56.62 58.75 41.57 53.75 52.11 47.17 65.83 60. CBraMod 58.44 46.68 61.27 53.43 48.14 48.21 45.38 64.94 51.57 63.17 60.63 52.82 57.19 59.74 42.43 65.58 55.96 61.88 TFM 63.04 44.72 66.50 54.04 56.62 51.51 56.53 62.55 52.12 57.76 50.21 59.29 56.72 57.70 43.89 64.21 58.37 67.15 EEGMamba 61.95 46.89 56.56 56.95 51.12 49.35 60.19 60.88 52.47 56.40 54.58 57.89 55.44 62.92 48.62 65.27 59.51 63. SingLEM 39.84 41.00 12.50 10.74 36.29 33.83 1.74 34.60 41.09 19.24 4.87 40.49 0.12 26.68 23.41 9.43 35.96 9.75 LUNA-Base 62.14 60.25 71.10 69.76 48.76 61.14 47.53 58.33 63.47 58.99 68.31 62.62 67.36 59.83 51.61 62.24 67.51 73.02 BENDR 9. 4.60 2.67 0.75 4.75 2.15 1. 1.31 2.10 3.18 4.21 8.89 0. 2.43 3.59 4.07 2.58 2.15 BIOT 57.28 41.96 67.84 43.38 47.84 40.41 47.14 63.19 45.72 56.14 54.36 55.42 58.61 53.74 39.15 51.65 56.52 62.05 LaBraM 57.02 48.31 57.61 52.37 53.96 50.47 45.51 64.55 51.34 52.53 49.98 51.71 59.74 63.32 43.08 58.88 58.53 55.23 Neuro-GPT 52.26 41.15 60.33 46.91 50.44 47.13 40.23 57.64 48.46 51.36 48.73 51.24 55.26 53.81 40.19 60.21 50.68 49.54 EEGPT 71.08 63.27 75.31 65.74 59.82 66.93 62.70 66.27 70.66 53.46 62.80 69.75 67.73 65.01 61.75 63.05 67.40 72.25 CBraMod 50.52 35.47 52.12 42.01 41.14 44.48 27.05 52.74 43.21 49.10 41.42 39.52 10.82 57.06 22.37 50.99 48.71 43.69 TFM 48.75 34.98 55.75 39.50 50.55 41.28 46.40 64.09 50.74 49.30 43.14 52.01 36.84 44.16 33.18 56.63 51.61 51.05 EEGMamba 33.48 46.24 29.58 30.60 31.98 38.55 17.06 36.89 33.69 32.24 27.26 36.61 25.21 48.44 28.62 25.50 38.80 30.06 SingLEM 2.33 4.42 0.79 2. 1.34 2.30 1.49 1.47 1.28 2. 1.12 1.49 1.08 -0.04 3.19 1.80 2.64 1. LUNA-Base 58.36 50.65 70.31 63.47 46.58 49.42 48.31 58.00 63.53 51.08 64.09 61.29 64.01 51.64 47.27 57.84 55.99 68.00 Linear Probing Foundation Models 55.850.12 63.130. 49.692.06 62.440.15 63.030.19 61.990.67 50.550.52 62.430. 38.730.33 58.130.10 56.380.16 58.590.03 62.310.09 60.130. 18.364.96 64.380.22 3.540.14 56.450.13 57.910.11 52.810. 69.440.71 42.390.31 49.800.41 33.220.30 1.850.18 58.810. 62 TABLE XLIX: Balanced classiﬁcation accuracies (%) on Sleep-EDFx. The best BCAs are marked in bold, and the second best by an underline. Scenario Tuning Model Type Approach S1 S2 S3 S4 S5 S7 S8 S9 S10 S11 S13 S14 S15 S16 S17 S19 Specialist Models PSD+LDA 71.43 73.06 67.93 64.96 68.87 62.69 68.73 64.23 66.30 66.07 54.66 51.15 67.60 62.80 73.51 70.79 54.38 59.56 63.48 63.97 EEGNet 58.14 54.34 53.86 50.42 54.41 54.70 56.53 58.14 55.69 53.49 46.63 42.77 49.06 43.13 55.60 61.21 48.94 46.11 58.51 47. ShallowConv 69.50 67.90 57.19 65.42 64.58 61.73 65.33 65.27 63.85 63.55 53.22 50.21 64.40 62.98 69.71 67.44 55.37 55.59 61.95 62.19 LMDA CNN-T 59.61 53.53 52.33 58.97 46.58 52.21 56.92 56.80 62.22 52.15 46.31 44.57 55.39 35.66 54.66 59.04 43.11 42.31 60.06 47.75 74.44 78.51 73.99 73.40 76.30 67.55 72.20 73.76 76.20 69.53 68.73 64.50 65.99 67.89 69.73 77.11 70.39 62.68 72.12 65. DeFormer 63.51 58.19 61.45 55.23 58.15 66.52 63.11 67.33 61.94 54.27 53.46 40.62 58.59 47.15 58.51 65.45 55.79 50.26 59.66 46.04 Conformer 72.04 70.56 70.92 75.80 75.44 66.47 65.62 76.07 69.83 58.89 60.29 57.31 67.35 72.64 80.12 72.55 67.28 56.72 64.59 72.69 Full Fine-tuning BENDR 41.33 41.63 44.26 39.63 39.79 28.08 39.81 42.19 39.41 41.39 38.87 30.60 36.16 23.54 42.18 42.19 37.61 28.67 44.39 37.69 BIOT 70.66 74.93 71.62 71.67 72.42 64.21 63.56 71.11 68.01 66.84 68.67 52.75 67.29 73.97 63.09 70.72 66.35 56.95 67.44 60.54 LaBraM 47.00 40.82 41.57 37.84 36.90 33.22 39.13 49.57 41.99 45.54 33.61 38.68 31.36 28.25 46.40 44.90 32.42 32.59 48.69 31.90 Foundation Models Within-subject (Few-shot) Neuro-GPT 63.93 63.59 64.77 67.73 66.01 59.67 60.60 65.60 61.99 61.23 61.14 42.66 60.19 71.23 60.78 65.68 58.06 45.15 59.84 53.00 EEGPT 61.83 70.02 65.65 73.44 70.04 64.73 71.51 71.36 64.45 68.95 54.70 49.13 67.99 68.83 75.28 68.66 65.77 59.06 61.58 60.82 CBraMod 66.40 72.50 71.67 68.04 71.63 60.43 58.03 64.41 68.92 66.54 61.12 50.87 62.08 69.80 65.20 64.70 59.97 52.07 61.80 60.76 TFM 68.03 67.59 68.32 69.76 62.31 62.22 65.84 62.83 67.48 63.78 60.06 53.63 66.11 69.78 69.85 69.19 55.66 56.53 61.79 60.60 EEGMamba 71.71 73.13 63.93 73.99 71.07 70.88 76.88 73.53 71.36 67.14 58.61 57.41 68.08 74.31 72.31 72.99 60.86 58.27 67.17 64.43 SingLEM 22.74 27.26 28.85 30.49 33.02 22.78 30.11 32.80 23.93 36.50 23.92 27.84 21.11 23.64 29.83 39.08 24.26 21.47 35.73 24.80 LUNA-Base 73.02 79.75 64.45 74.31 76.29 73.38 67.14 66.86 74.96 69.57 75.10 47.60 70.83 74.02 74.56 71.74 62.72 60.59 75.08 67.71 BENDR 21.30 21.08 22.16 20.42 22.88 21.30 22.33 20.83 20.98 22.13 21.13 20.72 20.66 20.40 20.77 21.40 21.51 20.55 21.06 21.66 BIOT 68.16 73.50 67.74 67.55 69.08 63.49 63.53 62.00 67.98 65.02 64.42 46.22 65.26 73.10 61.21 68.82 67.66 58.12 62.44 54.59 LaBraM 58.55 55.00 53.29 56.38 56.84 51.34 55.67 60.75 53.91 58.46 45.03 43.09 52.53 53.73 57.40 58.08 52.17 46.31 56.51 51.70 Linear Probing Foundation Models Neuro-GPT 58.88 54.71 55.81 54.71 57.25 50.89 55.14 54.65 61.11 52.29 51.32 37.51 54.50 61.05 56.74 56.98 51.63 41.27 56.42 44.11 EEGPT 68.87 72.70 70.07 74.38 72.60 72.40 75.90 77.16 72.93 74.06 63.97 39.91 70.58 76.17 77.90 70.82 66.06 59.09 64.15 73.34 CBraMod 48.55 43.39 37.37 49.31 51.53 39.71 47.20 48.90 40.98 46.10 34.78 36.77 29.06 38.33 43.10 40.65 43.08 36.59 50.31 36.76 TFM 60.47 56.56 58.80 60.58 57.52 54.86 58.36 53.35 60.11 55.83 51.34 50.30 57.04 40.08 61.82 61.60 47.90 45.29 55.17 52.11 EEGMamba 52.94 52.86 56.32 63.90 57.19 51.58 65.14 56.68 51.88 52.30 40.14 52.42 46.21 54.14 52.90 55.56 45.08 38.39 56.14 44.44 SingLEM 22.69 22.69 26.21 22.15 24.16 19.86 24.23 22.78 23.31 21.28 24.61 22.60 21.37 20.78 21.79 22.20 20.72 20.58 20.86 20.48 LUNA-Base 70.66 67.82 71.30 66.05 68.96 65.57 57.78 65.64 70.81 65.69 67.31 46.73 63.66 73.14 67.23 66.90 47.44 57.57 69.13 63.93 Scenario Tuning Model Type Approach S20 S22 S23 S24 S25 S26 S28 S29 S30 S31 S32 S34 S35 S36 S37 S38 Within-subject (Few-shot) Specialist Models PSD+LDA 54.69 68.60 48.39 54.26 66.12 67.81 57.84 63.36 65.19 64.18 55.56 67.16 61.15 52.31 53.35 61.75 55.62 41.53 60.22 56.44 EEGNet 42.17 43.88 38.46 35.80 48.31 44.94 47.06 56.28 58.02 54.08 45.02 51.52 56.92 55.01 61.04 40.22 40.88 39.61 48.42 45. ShallowConv 39.95 53.58 45.30 41.39 52.00 63.52 63.78 57.52 66.14 59.44 54.03 62.14 64.27 58.05 66.18 53.28 41.40 42.92 50.36 49.34 LMDA CNN-T 36.63 43.47 43.62 27.69 45.48 44.92 45.67 52.97 64.59 51.51 40.44 48.96 50.97 58.71 64.28 36.42 35.22 39.84 41.77 45.81 56.95 72.96 58.08 54.21 74.90 74.43 77.32 55.17 77.85 68.72 71.63 73.33 68.26 68.27 76.89 63.81 39.11 55.93 60.75 67. DeFormer 40.67 45.60 47.49 42.25 49.11 53.21 55.35 51.78 65.85 55.54 49.50 55.72 60.47 61.16 66.60 45.46 39.74 41.91 44.62 47.75 Conformer 56.84 55.33 48.22 65.52 71.82 70.38 72.68 63.47 76.80 66.07 58.03 65.65 59.42 60.30 71.80 62.25 62.18 52.98 66.69 62.99 Full Fine-tuning BENDR 36.81 34.18 37.00 27.37 41.18 39.48 39.61 37.34 41.54 36.62 32.48 39.28 46.84 47.84 55.24 25.96 25.36 34.55 39.97 34.30 BIOT 54.57 57.45 47.34 54.73 66.70 75.05 72.23 57.57 71.04 57.07 56.74 67.68 63.05 61.64 66.94 63.28 65.15 48.31 58.56 59.69 LaBraM 25.74 32.06 37.04 32.67 35.82 30.58 37.98 34.06 51.15 35.93 26.13 42.59 36.99 42.29 47.91 34.13 32.39 32.24 34.31 37.34 Neuro-GPT 36.57 54.77 47.04 46.82 56.53 64.71 62.92 45.51 70.81 54.01 50.94 60.86 56.94 57.03 64.72 56.80 48.49 43.54 52.47 52.49 Foundation Models EEGPT 47.56 57.43 59.14 45.56 59.67 51.35 71.44 63.59 60.88 65.62 46.97 58.68 62.81 56.86 60.44 53.14 45.22 40.34 46.24 47.60 CBraMod 49.51 61.89 43.23 51.93 64.33 72.27 60.73 60.97 73.21 58.11 52.69 63.50 60.42 58.42 65.95 58.76 60.79 45.16 57.77 59. TFM 52.63 59.03 46.29 51.26 62.02 70.00 64.08 60.66 68.80 61.68 54.16 61.00 65.55 59.84 68.04 60.11 55.25 48.43 61.72 58.54 EEGMamba 53.15 57.55 53.61 59.85 63.77 70.57 70.13 62.42 78.91 65.95 62.79 64.80 58.37 61.12 61.53 66.48 56.22 49.47 60.52 63.82 SingLEM 26.41 24.57 30.85 28.43 31.31 23.99 39.97 21.48 38.85 25.10 22.40 38.59 35.61 47.94 45.24 23.28 21.08 24.90 29.34 26. LUNA-Base 68.35 68.45 48.80 58.97 72.00 74.14 71.46 59.23 74.22 68.28 69.98 67.94 63.13 59.78 73.15 64.61 62.44 66.74 67.03 59.36 BENDR 21.02 20.62 22.02 20.23 21.92 21.12 21.55 20.74 21.03 20.28 20.26 21.14 25.80 25.86 28.07 21.28 20.18 21.35 21.29 20.67 BIOT 51.37 60.42 45.72 57.21 68.83 72.71 70.68 51.99 73.03 53.64 54.71 66.32 55.64 63.64 62.41 60.84 54.92 46.76 49.43 56. LaBraM 43.69 46.82 43.05 44.01 47.45 48.20 52.18 51.85 54.93 49.58 42.58 53.48 54.94 54.79 60.68 47.86 41.59 40.72 48.36 46.71 Neuro-GPT 38.40 48.52 43.60 46.09 47.09 54.88 53.20 50.30 63.87 42.75 48.66 54.64 54.24 54.39 58.74 52.15 52.44 42.54 44.82 49.51 Linear Probing Foundation Models EEGPT 52.98 58.69 65.20 45.13 63.83 70.48 74.94 68.59 67.32 67.99 58.23 62.27 54.02 61.57 59.69 60.24 59.74 44.29 64.12 47.76 CBraMod 35.35 43.70 36.74 32.73 43.61 42.57 42.28 48.85 54.44 34.57 44.13 48.60 37.37 46.87 52.62 30.19 42.26 43.78 39.05 43.77 TFM 44.03 53.07 40.67 41.74 48.41 53.28 51.60 49.26 62.86 54.53 45.34 54.37 50.38 54.96 57.98 51.23 36.02 41.56 46.23 50. EEGMamba 34.07 44.46 41.81 31.16 48.03 47.24 51.72 51.28 64.86 47.98 41.74 53.14 38.36 46.57 47.86 46.39 43.24 38.01 41.60 46.96 SingLEM 22.16 21.63 21.90 19.87 21.59 21.01 23.64 22.43 24.62 21.74 21.32 21.82 26.59 25.05 30.16 21.48 20.48 21.79 23.37 21.54 LUNA-Base 67.75 65.06 44.86 54.95 67.27 67.79 66.88 60.14 72.59 58.46 65.79 62.15 60.84 57.93 64.59 65.02 63.21 53.34 61.59 60. 63 TABLE L: Balanced classiﬁcation accuracies (%) on Sleep-EDFx. The best BCAs are marked in bold, and the second best by an underline (continued). Scenario Tuning Model Type Approach S41 S42 S43 S44 S45 S47 S48 S49 S50 S51 S53 S54 S55 S56 S57 S59 Specialist Models PSD+LDA 59.46 74.13 57.22 62.63 70.36 58.04 53.13 67.96 70.65 40.97 55.67 57.74 59.62 58.24 58.23 64.30 34.91 45.94 59.78 55.52 EEGNet 47.10 53.53 44.73 46.44 61.93 44.32 42.13 54.34 45.10 35.09 38.44 35.91 49.83 44.05 44.62 43.49 34.12 43.43 39.93 51. ShallowConv 60.75 70.65 56.67 58.53 70.56 46.68 51.98 61.58 55.58 33.39 38.76 38.40 47.89 52.59 53.30 52.45 39.61 47.89 43.81 57.49 LMDA CNN-T 49.21 62.67 42.43 50.75 60.69 43.64 42.73 48.26 40.86 28.87 30.79 29.19 44.80 39.68 47.44 39.42 29.73 36.64 39.23 48.87 71.05 76.11 69.04 73.02 79.44 44.92 51.49 65.71 77.53 45.01 51.08 63.56 57.63 75.15 65.70 56.95 45.85 47.59 45.67 68. DeFormer 56.30 69.29 52.96 53.22 62.77 43.87 54.71 58.60 48.95 34.51 29.67 39.49 51.37 46.50 50.29 52.21 44.49 44.13 39.48 53.39 Conformer 60.02 68.23 65.21 63.30 67.76 60.65 56.11 75.93 71.74 47.85 54.51 65.00 56.96 70.55 60.03 67.22 58.71 60.61 45.84 64.46 Full Fine-tuning BENDR 26.20 39.25 39.77 36.18 47.90 41.01 23.15 39.77 36.98 32.15 26.47 24.86 34.72 31.67 40.37 37.62 29.44 36.75 28.21 41.12 BIOT 64.10 71.91 61.93 56.34 70.69 58.65 47.73 73.28 70.75 38.66 56.97 62.12 57.03 73.67 69.96 51.49 49.11 50.22 47.67 56.31 LaBraM 36.38 40.49 32.12 33.46 44.52 40.93 30.74 36.17 41.71 26.03 29.09 24.01 29.10 30.56 36.92 29.54 28.10 30.82 30.65 39.92 Neuro-GPT 55.56 67.11 56.87 53.40 69.37 48.44 48.93 63.28 54.63 32.43 42.70 43.39 48.74 52.69 49.67 54.43 42.47 40.80 42.93 50.54 Foundation Models EEGPT 62.65 67.78 57.64 50.32 64.54 55.30 49.60 68.83 50.79 42.00 47.60 44.08 56.67 61.17 39.16 48.04 37.62 42.35 57.78 56.72 CBraMod 61.46 72.27 54.58 54.17 70.95 52.88 50.42 66.21 57.74 34.05 41.52 51.79 53.38 66.14 48.44 49.54 46.54 45.29 41.07 57. TFM 64.81 70.08 58.67 60.04 70.39 53.51 50.30 68.24 61.13 39.62 51.76 46.94 56.34 66.35 54.15 55.68 41.92 45.40 45.73 60.17 EEGMamba 61.74 76.66 61.31 64.53 79.58 52.31 51.51 74.24 60.82 34.92 42.73 42.22 63.72 65.01 56.61 63.19 45.79 43.41 55.42 60.69 SingLEM 31.33 35.50 25.69 24.50 41.75 32.50 23.66 41.61 33.48 20.56 30.69 24.06 29.17 24.17 32.09 22.06 22.07 25.35 24.90 24. LUNA-Base 65.57 72.51 65.67 68.69 72.90 66.71 58.23 65.83 73.54 49.38 56.58 58.92 68.09 74.64 61.07 66.75 60.55 69.79 54.23 60.34 BENDR 20.70 20.77 20.65 21.55 22.05 20.88 19.73 20.69 20.68 20.50 21.04 20.08 21.63 20.59 20.73 22.24 23.36 21.15 21.20 20.77 BIOT 58.07 67.88 51.47 57.13 68.19 61.21 40.78 71.93 66.80 46.98 59.97 55.47 59.50 67.13 59.85 59.54 50.44 40.04 48.45 52. LaBraM 48.17 59.70 47.90 45.96 61.16 48.60 45.77 59.29 50.60 33.19 42.12 38.96 47.54 45.35 47.42 43.32 34.81 39.36 39.60 50.20 Neuro-GPT 51.32 59.31 54.66 46.89 59.17 46.54 45.84 57.62 51.41 31.74 39.87 43.92 45.47 47.06 48.21 48.19 36.70 40.47 36.68 44.46 Within-subject (Few-shot) Linear Probing Foundation Models EEGPT 68.84 68.38 65.67 59.45 76.24 62.24 56.92 71.25 61.03 46.30 51.27 56.83 59.79 69.72 46.04 54.67 46.45 47.97 66.12 62.32 CBraMod 40.74 50.15 41.32 45.81 49.45 43.43 39.31 48.71 48.51 25.43 33.07 29.44 34.55 40.52 44.47 31.31 29.04 30.19 31.40 40.71 TFM 55.13 53.86 46.22 56.51 57.93 46.82 41.72 51.65 50.35 33.61 43.58 36.76 46.35 49.07 48.69 49.01 32.15 41.03 36.60 47.42 EEGMamba 52.35 63.95 51.13 44.36 59.98 44.95 45.90 59.62 43.05 29.70 31.92 32.40 52.34 43.45 43.61 44.38 28.36 33.65 35.56 40.57 SingLEM 22.16 23.53 21.40 21.52 24.44 23.46 22.09 22.49 20.23 19.44 22.93 20.97 23.65 21.91 22.61 23.15 21.60 23.00 21.64 21.92 LUNA-Base 66.68 72.52 65.06 60.78 73.41 65.69 57.20 70.48 72.25 45.17 51.50 51.51 62.95 66.16 45.88 62.44 49.83 64.07 47.66 56.47 Scenario Tuning Model Type Approach S60 S62 S63 S64 S65 S66 S68 S69 S70 S71 S72 S74 S75 S76 S77 Avg. PSD+LDA 57.94 51.89 51.16 53.80 52.38 60.31 49.13 57.55 46.74 46.51 50.56 45.97 43.09 54.74 57.13 49.21 68.67 69.13 59.00 Within-subject (Few-shot) Specialist Models EEGNet 51.35 39.86 48.26 61.88 46.68 49.67 40.97 43.36 46.51 50.60 53.91 54.57 36.35 48.85 47.81 43.78 51.36 49. ShallowConv 58.81 43.80 52.18 64.33 54.97 42.65 43.25 48.52 48.78 54.99 55.63 58.16 38.84 50.74 50.27 50.94 61.77 63.64 LMDA CNN-T 56.78 40.88 47.57 57.94 46.92 44.92 29.74 42.96 44.27 48.39 49.38 53.81 27.94 48.76 45.02 41.87 50.12 54.38 63.12 50.56 62.13 67.20 64.24 64.05 60.96 60.90 50.66 58.49 66.13 56.38 23.03 54.75 68.19 67.60 74.67 71. DeFormer 58.95 43.00 52.05 62.33 50.79 48.26 41.87 47.62 48.04 54.09 53.76 58.46 40.62 49.66 46.30 48.60 57.85 62.58 Conformer 59.16 40.41 71.33 72.61 57.02 48.56 62.95 57.95 41.74 61.06 57.13 59.60 58.43 49.32 63.54 61.48 71.00 61.97 Full Fine-tuning BENDR 44.21 40.99 39.61 44.69 41.17 35.85 25.23 34.58 39.62 42.07 44.96 51.62 24.38 46.44 36.55 36.45 39.00 38.93 BIOT 59.13 51.99 58.02 63.50 53.85 45.36 52.79 65.30 48.62 55.09 64.63 63.80 62.67 58.37 64.13 58.05 66.93 68.26 LaBraM 46.88 40.31 32.62 39.58 43.94 38.30 23.19 29.18 33.20 34.99 37.62 42.14 21.44 36.42 34.27 29.40 39.29 31.37 Foundation Models Neuro-GPT 53.29 41.63 54.89 59.50 54.06 49.78 45.11 48.27 44.51 57.27 55.65 57.89 41.77 51.41 55.32 48.97 57.69 59.06 EEGPT 54.08 41.03 45.14 57.85 53.36 48.53 46.64 43.99 44.20 51.11 56.62 58.75 41.57 53.75 52.11 47.17 65.83 60.97 CBraMod 56.79 41.98 54.93 63.40 56.10 49.37 41.30 53.05 44.40 58.76 63.30 54.45 49.71 52.63 55.13 48.59 63.11 63. TFM 60.07 44.34 56.48 62.46 57.36 51.08 46.30 56.96 47.42 57.68 57.96 63.02 50.97 50.57 55.21 53.22 61.35 63.97 EEGMamba 59.00 47.99 63.63 59.58 57.88 57.21 52.25 56.88 49.43 54.89 62.45 59.18 46.36 53.82 67.21 48.71 69.07 65.74 SingLEM 38.24 36.23 28.12 32.48 37.72 35.85 20.82 33.84 36.18 34.95 28.24 46.64 20.25 32.85 31.97 24.40 37.37 25. LUNA-Base 60.22 58.03 74.22 69.41 54.17 65.36 49.04 59.74 50.66 59.64 71.28 64.98 53.04 69.84 70.01 66.23 74.34 71.84 BENDR 23.41 21.59 20.72 25.26 21.50 20.71 20.50 20.23 20.54 25.96 26.57 28.55 20.01 20.85 21.17 21.21 21.05 20.79 BIOT 55.05 52.74 62.88 54.31 55.22 45.40 56.48 68.79 44.02 55.08 61.79 58.33 47.02 55.21 62.33 58.08 66.72 65. LaBraM 48.88 42.21 45.29 54.86 48.89 46.44 41.62 46.09 42.90 51.32 52.26 54.68 38.89 51.88 46.77 41.19 53.75 50.68 Neuro-GPT 47.09 38.72 50.07 55.22 50.05 45.68 37.36 46.01 43.45 52.09 55.55 54.07 43.43 50.87 50.50 47.30 54.17 50.49 EEGPT 64.67 45.89 54.05 60.37 58.13 56.29 45.50 60.95 51.13 58.10 64.59 66.04 48.75 58.82 61.01 50.81 69.67 62. CBraMod 39.73 36.91 45.68 47.68 44.06 43.71 32.51 41.59 41.34 50.74 47.79 46.89 22.69 49.71 39.86 39.78 44.06 45.47 TFM 51.67 39.59 43.66 55.12 50.99 45.99 39.11 48.10 42.83 50.54 52.75 55.94 33.56 43.53 47.49 45.70 50.71 56.34 EEGMamba 39.44 41.58 42.49 43.70 48.77 47.00 28.40 40.30 39.24 45.96 48.36 47.51 29.46 48.09 50.50 31.76 57.41 47. SingLEM 21.83 23.67 21.00 26.56 21.67 22.71 21.54 21.69 19.76 26.86 25.06 27.46 21.97 19.61 22.83 22.84 23.65 21.72 LUNA-Base 57.75 55.00 71.46 66.33 56.95 56.68 57.61 63.97 48.94 57.41 67.39 60.42 51.27 62.93 65.87 63.96 63.27 66.05 Linear Probing Foundation Models 48.290.54 55.290.49 46.752.12 64.770.61 52.260.38 63.310. 37.340.24 61.750.48 35.990.23 54.500.29 56.380.16 57.720. 58.820.14 61.500.62 29.711.75 66.020.06 21.580.06 59.420. 49.200.10 49.690.62 61.990.47 41.330.26 49.560.26 46.300. 22.510.24 61.990."
        }
    ],
    "affiliations": [
        "Ministry of Education Key Laboratory of Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074 China",
        "State Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190 China",
        "Zhongguancun Academy, Beijing, China"
    ]
}