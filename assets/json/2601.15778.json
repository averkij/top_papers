{
    "paper_title": "Agentic Confidence Calibration",
    "authors": [
        "Jiaxin Zhang",
        "Caiming Xiong",
        "Chien-Sheng Wu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 2 2 ] . [ 1 8 7 7 5 1 . 1 0 6 2 : r Preprint Salesforce AI Research"
        },
        {
            "title": "AGENTIC CONFIDENCE CALIBRATION",
            "content": "Jiaxin Zhang Caiming Xiong Chien-Sheng Wu Salesforce AI Research {jiaxin.zhang, cxiong, wu.jason}@salesforce.com"
        },
        {
            "title": "ABSTRACT",
            "content": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agents entire trajectory. Powered by simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish new process-centric paradigm for confidence calibration, providing framework for diagnosing and enhancing the reliability of AI agents. Figure 1: Overview of Holistic Trajectory Calibration (HTC). The framework first collects confidence signals along the agents trajectory, then derives rich process-level diagnostic features, which are used to train simple yet interpretable calibrator. This process not only improves calibration accuracy but also yields the three pillars of reliable agentic AI: interpretability, transferability, and generalization."
        },
        {
            "title": "INTRODUCTION",
            "content": "Large Language Models (LLMs) are rapidly evolving from static or retrieval-augmented textgeneration tools into the core reasoning engines of complex, multi-step agentic systems (Xi et al., 2025; Wang et al., 2024a). These agents, which integrate sophisticated capabilities such as planning, 1 Preprint Salesforce AI Research using tools, and handling memory (Xi et al., 2025; Schick et al., 2023), can autonomously interact with dynamic environments to solve complex problems. As these systems are increasingly deployed in high-stakes, safety-critical domains, their reliability has emerged as the most critical and yet unresolved challenge (Wang et al., 2024a; Liu et al., 2024b). Ensuring that we can trust the outputs of these powerful but opaque systems is critical for their responsible adoption. This shift from static generator to dynamic actor fundamentally alters the nature of the reliability challenge. First, uncertainty is no longer an isolated property of single output, but compounding factor that accumulates and propagates throughout sequential trajectory (Duan et al., 2025; Zhao et al., 2025). An early, low-confidence decision-such as erroneously selecting tool, can poison the entire subsequent execution path, leading to an agent holding high confidence in completely incorrect result. Second, agents introduce new, external sources of uncertainty through their interaction with tools and environments (Liu et al., 2024a). API failures, noisy data returned by tools, or the misuse of tools functionality create new reliability bottlenecks independent of the models internal knowledge. Finally, the multi-step nature of agentic processes makes failure modes more opaque. final incorrect answer may not stem from the last reasoning step, but from critical, masked breakdown that occurs at specific intermediate step earlier in the trajectory (Fu et al., 2025). Agent calibration also faces fundamental data scarcity challenge that means each agent trajectory represents an expensive execution involving LLM inference, tool interactions, and human evaluation for ground truth labels. This constraint shapes us toward sample-efficient and interpretable methods. In light of these unique challenges, existing approaches to confidence estimation are insufficient. On one hand, traditional calibration techniques like Temperature Scaling (Guo et al., 2017) were designed for post-hoc correction of static, single-point classification predictions. Methodologically, they are incapable of processing sequential trajectory data and thus completely ignore the processlevel information that could reveal the root cause of an agents failure. On the other hand, while recent work has begun to explore more fine-grained confidence signals (Geng et al., 2024), these efforts often rely on coarse aggregation methods like global averaging, which can mask local yet critical reasoning failures (Fu et al., 2025), or are limited to evaluating pure reasoning chains without external tool interaction (Wei et al., 2022), see more related work in Appendix A.1. Consequently, significant gap exists in the current studies: there is lack of systematic framework for effectively calibrating the confidence of an agents final output by diagnosing its entire execution trajectory. In this work, we introduce the new problem of Agentic Confidence Calibration (ACC): estimating the likelihood that an agents trajectory will succeed by diagnosing its entire execution process rather than only its final output. As illustrated in Figure 1, this process-centric perspective raises three key challenges: uncertainty signals dispersed across multiple temporal scales, compounding noise from both model and environment, and limited availability of labeled data. To address these challenges, we propose Holistic Trajectory Calibration (HTC), novel framework that transforms raw confidence traces into rich set of process-diagnostic features, encompassing cross-step dynamics, intra-step stability, positional indicators, and structural attributes. These features are then mapped through Importantly, HTC is simple, interpretable model to produce calibrated confidence estimates. decoupled from any specific agent architecture, making it lightweight, transparent, and broadly applicable across diverse tasks and frameworks. Our study demonstrates that HTC brings three key benefits: Interpretability: By grounding calibration in trajectory-level features such as early-step entropy, confidence gradients, and stability dynamics, HTC exposes the signals behind model confidence, enabling transparent diagnosis of failure modes and guiding principled agent design. Transferability: Once trained, an HTC calibrator can be seamlessly applied across tasks and domains without retraining, delivering consistent gains in both calibration and discrimination and reducing dependence on costly, task-specific tuning. Generalization: Pre-training General Agent Calibrator (GAC) on diverse datasets yields universal reliability layer that achieves the best calibration (lowest ECE) on out-of-domain challenges such as GAIA, pointing toward scalable foundation for trustworthy agentic AI. Across eight benchmarks, multiple agent frameworks, and both closedand open-source LLMs, we show that HTC reliably outperforms strong baselines. Beyond empirical gains, HTC establishes process-centric paradigm for agentic confidence calibration, uniting interpretability, transferability, and generalization, three essential components for building reliable and trustworthy AI agents. 2 Preprint Salesforce AI Research"
        },
        {
            "title": "2.1 HOLISTIC TRAJECTORY CALIBRATION: A NEW FORMULATION",
            "content": "An agent system is defined as policy π that, at step t, maps the interaction history ht to an action at : at = π(ht), ht = (s0, a1, o1, . . . , st). The environment Ω executes at from state st and returns an observation ot together with the next state via (possibly stochastic) transition kernel (ot, st+1) δ( st, at ). This interaction produces an execution trajectory, = (cid:0)s0, a1, o1, L1, s1, a2, o2, L2, . . . , aN , oN , LN , sN which records the complete problem-solving process up to termination at step . For LLM-based agents, each action at (e.g., thinking, planning pr or tool call) is generated by an LLM M. We denote by Lt = (ℓt,1, . . . , ℓt,mt) the sequence of token-level log-probabilities produced when generating at, where mt is the number of tokens in action at. By concatenating these sequences across all steps, we obtain the log-probability trajectory after LLM execution: (1) (cid:1), (cid:16) LT = (ℓ1,1, . . . , ℓ1,m1), (ℓ2,1, . . . , ℓ2,m2 ), . . . , (ℓN,1, . . . , ℓN,mN ) (cid:17) . (2) This trajectory captures the agents complete reasoning process, yet existing approaches typically assess confidence only from the final action: Ctrad = H(sN , aN ). Agentic confidence calibration introduces three fundamental challenges that make it substantially harder than static calibration. Problem Formulation: Holistic Trajectory Calibration (HTC) Given an agents execution trajectory with associated token log-probabilities LT , learn calibration function FHTC that maps the trajectory to calibrated confidence score CT [0, 1]: CT = FHTC(T (LT ) s.t. E[ FHTC(T (LT )) = ] c, [0, 1] (3) where {0, 1} indicates task success or matches ground truth solution. Challenge 1: Compounding Uncertainty. Agentic trajectories accumulate and propagate uncertainty across multiple steps: early misjudgments may amplify downstream errors, while interactions with external tools introduce additional stochasticity, resulting in confidently incorrect final outputs. Challenge 2: Multi-Source Uncertainty. Uncertainty in agentic reasoning is heterogeneous: it arises from token-level fluctuations within step, from cross-step dynamics describing how confidence evolves. Signals are dispersed across multiple scales and cannot be reduced to single summary. Challenge 3: Data Scarcity and Uncertainty. Collecting agent trajectories is time-consuming and costly, which limits available datasets to relatively small scales. Moreover, the length of trajectories varies substantially with task complexity, introducing additional sources of data uncertainty. To address the above challenges, we introduce new paradigm Holistic Trajectory Calibration (HTC), and formulate HTC as supervised learning problem. Given dataset of trajectories {Ti(LTi)}N i=1, we learn calibration function FHTC by minimizing proper scoring loss: i=1 with binary success labels {yi}N HTC = arg min 1 (cid:88) i=1 ℓ(cid:0)yi, F(Ti(LTi))(cid:1) + λR(F), (4) where ℓ(, ) is calibration-sensitive loss and R(F) is regularization term. The core question is how to design an effective representation ϕ(T (LT )) that captures dispersed uncertainty signals, while supporting learning that is sample-efficient, interpretable, and generalizable across tasks. 2.2 THE IMPERATIVE FOR TRAJECTORY-LEVEL FEATURES Given the challenges identified above, we argue that trajectory-level features are indispensable for effective HTC framework. Naïve alternatives such as relying only on final-step log-probabilities or averaging token confidences fail to capture the dispersed, multi-scale, and noise-sensitive nature of agentic uncertainty. In contrast, holistic trajectory-level features balance expressivity and practicality: 3 Preprint Salesforce AI Research they capture diverse uncertainty signals while remaining tractable in small-data regimes. Unlike end-to-end neural encoders (e.g., RNN, LSTM, Transformer) which require large datasets and yield opaque representations ill-suited for calibration, feature-based representations enable sample-efficient learning and provide direct diagnostic insights. Design principles. Our trajectory-level representation = ϕ(T ) is guided by four principles: (i) Universality: features should be agnostic to task, model, and agent framework; (ii) Informativeness: features must encode signals causally linked to success and failure; (iii) Parsimony: the set should remain compact for small-sample calibration; and (iv) Interpretability: each feature should provide diagnostic value for analyzing uncertainty. Based on these principles, we organize trajectory-level features into four complementary families: Cross-Step Dynamics: capture how confidence evolves across steps, detecting accumulation, reversals, or abrupt shifts that reflect compounding uncertainty. Intra-Step Stability: measure within-step volatility and distributional shape of token-level logprobabilities, indicating unstable or collapsed behaviors. Positional Indicator: critical early and late time-points where initialization quality and terminal consolidation often determine success and dominate outcomes. Structure Attribute: summarize macroscopic trajectory attributes (e.g., step count, token-length patterns) that proxy for task complexity and agent efficiency. From trajectory to features. Concretely, we apply small set of statistical operators (mean/variance, min/max, entropy, skewness, finite differences) along two axes, within step and across steps, to the log-probability trajectory. This yields compact vector R48 that preserves essential uncertainty signals while supporting efficient and interpretable calibration. We constructed systematic Taxonomy of Uncertainty covering four critical axes. This resulting 48-dimensional space balances comprehensiveness with the need to prevent overfitting in small-sample regimes (see ablation in Appendix A.4). full taxonomy with formal definitions is provided in Appendix A.5.1. 2.3 INTERPRETABLE CALIBRATION MODEL Given the designed feature = ϕ(T ) R48, we adopt simple yet interpretable light calibration model. This choice is motivated by three considerations specific to agentic confidence calibration: (i) small-sample robustness: agent trajectory datasets are inherently small so linear models are less prone to overfitting than neural alternatives with thousands of parameters; (ii) interpretable diagnostics: linear weights provide direct insights into which uncertainty signals matter for different tasks, which is crucial for understanding agent failure modes; and (iii) transferability and generalization as lowcapacity models generalize more reliably across domains with heterogeneous trajectory distributions. Formally, the calibration function maps features to calibrated confidence score: CT = FHTC(x) = σ(cid:0)wx + b(cid:1), R48, (5) where and are learned parameters. We instantiate the model under two complementary regularization regimes: regularization, RL2(w) = λw2 HTC-Full: Retains all features while stabilizing estimates under collinearity through ridge 2. This preserves the full diagnostic surface across all features. HTC-Reduced: Encourages sparsity via lasso regularization, RL1(w) = λw1, automatically selecting compact subset = {j : wj = 0}. This denoises spurious features and often improves calibration in small-data regimes. Theoretical Motivation. From theoretical standpoint, trajectory-level calibration is strictly more informative than last-step confidence: conditioning on richer trajectory features can only reduce Bayes risk under proper scoring rules. In addition, sparse ℓ1-regularized logistic calibrator admits favorable small-sample generalization bounds, explaining its stability in data-scarce regimes. simple chain-of-subgoals model further clarifies why last-step confidence can be systematically optimistic, and the same diagnostics applied to prefixes establish principled path toward online reliability. Formal statements and complete proofs are provided in Appendix A.6. 4 Preprint Salesforce AI Research Efficiency and Deployment. The linear calibrator is computationally lightweight. Feature extraction scales linearly with trajectory length and requires only simple aggregation operators, while model training and inference are near-instantaneous. This efficiency makes HTC practical for real-time deployment and rapid adaptation to new domains, see more discussion in Appendix A.7 and A.8."
        },
        {
            "title": "3.1 EXPERIMENTAL SETUP",
            "content": "Datasets and Benchmarks. To comprehensively evaluate the effectiveness and generality of our HTC framework, we select 8 representative public benchmarks. These datasets are categorized into three groups to test distinct agent capabilities: (1) Knowledge-intensive QA (SimpleQA (Bordes et al., 2015), HotpotQA (Yang et al., 2018), StrategyQA (Geva et al., 2021)) for factual retrieval and multi-hop reasoning; (2) Complex Reasoning (MATH500 (Hendrycks et al.), GPQA (Rein et al., 2024), MMLU-Pro (Wang et al., 2024b), HLE (Phan et al., 2025)) for formal logic and deep domain knowledge; and (3) Frontier Agentic Tasks (GAIA (Mialon et al., 2023)) for planning and tool-use in difficult, open-ended scenarios. Detailed descriptions and references for all datasets are provided in Appendix A.2.1. Models & Agent Frameworks. Our experiments are conducted using smolagents (Roucher et al., 2025), lightweight and research-friendly framework, leveraging its CodeAct paradigm where the agent generates executable Python code for tool use. We evaluate on diverse set of models that provide LOGPROBS access. Our closed-source models are GPT-4.1 and GPT-4o (Achiam et al., 2023). Our open-source suite includes GPT-OSS-120B & 20B (Agarwal et al., 2025), Deepseek-v3.1 (Bi et al., 2024), and Qwen3-235B (Yang et al., 2025). To ensure our findings are not specific to single framework, we conduct generalization study using the state-of-the-art OAgents framework (Zhu et al., 2025) in our ablation analysis. Further details on all frameworks and models are available in Appendix A.2.3. Baselines. We compare HTC against two categories of baselines to address different evaluation dimensions: Inference-based Baselines: (1) Verbalized Confidence (Tian et al., 2023): agents directly output confidence scores; (2) Last-Step Token Confidence (LastStep-TP): average logprobabilities from final generation step; (3) Global-Trace Token Confidence (GlobalTrace-TP): average log-probabilities across all steps; (4) Temperature Scaling (Guo et al., 2017) applied to above methods (see details in Appendix A.2.4). Learning-based Baselines: (1) LSTM Encoder: processes raw log-probability sequences with final hidden state classification; (2) Transformer: attention-based sequence encoder. There are another three nonlinear methods based on our extracted features: (3) Neural Network, (4) XGBoost and (5) Gaussian Process (Rasmussen & Williams, 2005). Detailed definitions and implementation specifics are provided in Appendix A.2.5. Evaluation Metrics and Implementation. We evaluate calibration performance using three standard metrics: Expected Calibration Error (ECE) (Guo et al., 2017), which measures the accuracy of confidence scores; the Brier Score (BS) (Glenn et al., 1950), proper scoring rule assessing both calibration and discrimination; and AUROC, which measures the models ability to distinguish between successful and failed trajectories. It is important to distinguish the calibration method from the evaluation metric. HTC is the proposed method (predictor) that outputs confidence scores, while metrics like ECE and Brier Score serve as the ground-truth standards for assessing the quality of those scores. Therefore, method achieving consistently lower ECE and BS is objectively better aligned with the true empirical accuracy. To ensure the validity of our ground truth labels, we employed Gemini-2.5-Pro based judge, which we verified on stratified subset to achieve 90-95% agreement rate with human experts. All experiments are conducted using cross-validation scheme to ensure robust results. detailed description is provided in Appendix A.2.2. The implementation details and hyperparameter setting are provided in Appendix A.2.6. 3.2 MAIN RESULTS: CALIBRATION PERFORMANCE OF HTC Table 1 summarizes results on three representative datasets. Note that we evaluate the quality of our calibration method (HTC) using standard metrics (ECE, Brier Score); thus, lower values on these metrics directly indicate superior alignment between predicted confidence and actual performance. Across all metrics, both HTC variants substantially outperform inference-based baselines, with 5 Preprint Salesforce AI Research Table 1: Main results comparing HTC against baselines on representative datasets. Top 2 results in ECE, BS and AUROC are marked as bold and see full results in Table 4 and 5 in Appendix A.3.1. Method SimpleQA GPQA HLE ECE BS AUROC ECE BS AUROC ECE BS AUROC Verbalized Conf LastStep-TP LastStep-TP + Temp GlobalTrace-TP GlobalTrace-TP + Temp HTC-Full HTC-Reduced 0.121 0.101 0.071 0.110 0.077 0.075 0.068 0.196 0.186 0. 0.193 0.181 0.150 0.140 0.655 0.699 0.698 0.692 0.691 0.727 0.752 0.454 0.424 0. 0.414 0.136 0.124 0.102 0.523 0.413 0.258 0.402 0.257 0.219 0.213 0.593 0.614 0. 0.649 0.643 0.704 0.706 0.656 0.686 0.436 0.685 0.433 0.072 0.031 0.531 0.561 0. 0.560 0.277 0.098 0.090 0.614 0.604 0.628 0.551 0.570 0.617 0.644 especially large gains in Brier Score and AUROC. On the most challenging tasks, HTC-Reduced achieves the strongest calibration, e.g., ECE of 0.031 and Brier Score of 0.09 on HLE, highlighting the benefit of sparsity in isolating universal uncertainty signals. We present series of radar charts in Figure 1 to provide comprehensive overview of our frameworks performance across all eight diverse datasets. We also compared against five learning-based baselines, including LSTM, Transformer, Neural Networks (NN), Gaussian Process (GP) and XGboost methods on SimpleQA with detailed learning curves shown in Figure 2. HTC consistently attains lower mean error and dramatically smaller variance across dataset sizes (100400), demonstrating robustness in small-data regimes where neural baselines overfit or fluctuate heavily (see full results in Appendix A.3.1). Figure 2: Learning Curve Comparison: HTC vs. Learning-Based Baselines on SimpleQA dataset, showing HTC consistently outperforms and exhibits much lower variance under small-data regimes. Figure 3: The Impact of Base LLM on Calibration Performance on the SimpleQA dataset. Effect of LLM Choice. To validate HTC is model-agnostic, we evaluated its performance across six different LLMs on SimpleQA. The results in Figure 3, reveal two key findings. First, our HTC framework delivers consistent and substantial improvements for every model tested, from the high-performing GPT-4.1 to other powerful open-source alternatives like GPT-OSS-20B, which exhibits particularly poor initial calibration. Second, the results highlight that different LLMs possess distinct baseline calibration profiles. For instance, while GPT-4o demonstrates the strongest raw discriminative ability (highest baseline AUROC), its calibration (ECE) is notably poorer than that of GPT-4.1. Our HTC framework effectively addresses these unique characteristics, not only elevating the overall performance but also correcting the specific deficiencies of each model. Effect of Agent Architectures. We investigated whether HTCs effectiveness is tied to specific agent architectures. We compared its performance on the lightweight smolagents versus the highly6 Preprint Salesforce AI Research optimized OAgents architectures, using GPT-4.1 on GPQA (Figure 7 in Appendix A.3.1). HTC provides significant gains on both architectures, confirming that our approach is architecture-agnostic and can serve as plug-and-play module to enhance the reliability of various agentic systems."
        },
        {
            "title": "3.3.1 FEATURE IMPORTANCE AND INTERPRETABILITY",
            "content": "A key advantage of HTC framework is its interpretability. By analyzing the features weights of our regularized linear model, we can move beyond if it works to why it works, gaining deep insights into the nature of agentic failure. Uncertainty Signals are Task-Dependent. Our first major finding is that the most predictive signals of failure are highly dependent on the cognitive demands of the task. Figure 8 in Appendix A.3.2 displays the important features selected by our model for each of the eight datasets. It is visually apparent that there is no single universally dominant feature; the feature set and their relative importances shift based on the tasks nature. To illustrate this task-dependency more clearly, we compare the feature importance distributions for two representative tasks in Figure 4 (left): For SimpleQA, task that typically involves search-then-synthesize pattern, the most predictive features are diverse and balanced across Dynamics, Stability, and Position. This suggests that failure can occur at multiple distinct stages: poor transition between search and synthesis (Dynamics), an unstable generation process (Stability), or weak final conclusion (Position). The model learns to monitor broad array of signals to detect these varied failure modes. For GPQA, task involving long and complex reasoning chains, the feature importance is heavily concentrated in the Position category. This indicates that for such difficult tasks, the agents cognitive state at the very beginning (first_step) and, more critically, at the very end (last_step) serves as the most potent summary of the entire arduous process. hesitant or unstable conclusion after long chain of reasoning is particularly strong signal of failure. Figure 4: (Left) Distribution of feature importance across different task domains. (Right) Frequency of feature category across different levels, including Top 1, Top 3, Top 5 and all selected features. General Hierarchy of Diagnostic Signals. We analyze the statistical distribution of feature categories across all datasets, as shown in Figure 4 (right). The Top-1 most important feature across all datasets is most frequently Positional feature. This aligns with intuition: flawed start or shaky conclusion is the most immediate and powerful first alert signal of failing trajectory. As we expand our view to the Top-3 and Top-5 most important features, Stability and Dynamics features become increasingly prominent. This reveals that comprehensive diagnosis requires looking beyond the start/end points and into the microand macro-level stability of the reasoning process itself. When considering all selected features, Dynamics emerges as the most frequently selected category overall. This suggests that while not always the single strongest signal, the step-to-step evolution of an agents confidence is pervasive and indispensable component of full reliability assessment. This analysis, with full feature selection frequency detailed in Table 6 in Appendix A.3.2, allows us to distill key insight: effective agent calibration requires hierarchical diagnostic approach. To validate the complementarity of our feature design, we conducted an ablation study across 15 configurations spanning single categories, pairwise, three-way, and the full set over the four feature categories (see Appendix A.4). We find that no single family suffices while multi-category 7 Preprint Salesforce AI Research combinations substantially improve performance. There is no marginal category, the effectiveness of HTC derives precisely from integrating diverse, process-diagnostic signals. Takeaway 1: Interpretable Feature Importance Two insights into agent reliability. First, there is no single universally dominant feature; the most predictive signals of failure are highly task-dependent, shifting from Positional indicators in complex reasoning tasks to more diverse signal set in multi-step QA. Second, despite this diversity, general diagnostic hierarchy emerges across all tasks: Positional features (the start and end) serve as the strongest primary signals of failure, while Stability and Dynamics features are essential for complete diagnosis of the underlying process."
        },
        {
            "title": "3.3.2 CROSS-DOMAIN TRANSFERABILITY",
            "content": "A central question is whether HTCs process-diagnostic features capture generalizable uncertainty signals rather than dataset-specific artifacts. To evaluate this, we pre-train calibrator on one source dataset and apply it without further training to multiple target datasets. Knowledge Domain Transfer: From Knowledge to Reasoning. We first evaluate transferability within the knowledge-intensive domain by training calibrator on SimpleQA. As shown in Table 2, the transferred model performs remarkably well on other QA tasks: on HotpotQA, it even outperforms direct training across all metrics, with similar gains on StrategyQA. Figure 5 explains this effect, the feature distributions of SimpleQA and HotpotQA are closely aligned, indicating shared uncertainty patterns. By contrast, transfer to the out-of-domain GPQA is weaker, consistent with its clear separation in feature space. These results suggest HTC can capture robust uncertainty patterns that generalizes across related tasks while revealing the boundaries of cross-domain transfer. Reasoning Domain Transfer: The Challenge of Distribution Shift. We next examine transfer from MMLU-Pro. As shown in Table 2, transfer to other reasoning tasks (MATH500, HLE) underperforms direct training, despite their proximity in feature space (Figure 5). We attribute this to distribution shift in reasoning patterns: MMLU-Pro induces multiple-choice reasoning, producing different distribution characteristics than the open-ended generation in MATH500 or complex planning in HLE. Interestingly, transfer to StrategyQA is strong, despite being cross-domain. The key factor appears to be shared answer format (binary/short-form), suggesting that output structure can drive transferability as much as task category. This highlights that HTC features capture not only what the agent reasons about, but also how it organizes its final decision. Table 2: Cross-domain transfer performance. calibrator is trained on single source dataset, evaluated on multiple target datasets, comparing against model trained directly on the target dataset. Source: SimpleQA (Knowledge) HotpotQA (ID) StrategyQA (ID) GPQA (OOD) ECE Brier Score AUROC ECE Brier Score AUROC ECE Brier Score AUROC DIRECTTRAIN (full) DIRECTTRAIN (reduced) Transfer (full) Transfer (reduced) 0.116 0.082 0.113 0.070 0.193 0.183 0.194 0. 0.714 0.729 0.719 0.732 0.079 0.055 0.099 0.064 0.141 0.136 0.148 0.135 0.670 0.665 0.657 0.681 0.124 0.102 0.435 0.304 0.219 0.213 0.446 0. 0.704 0.706 0.587 0.629 Source: MMLU-Pro (Reasoning) MATH500 (ID) HLE (ID) StrategyQA (OOD) ECE Brier Score AUROC ECE Brier Score AUROC ECE Brier Score AUROC DIRECTTRAIN (full) DIRECTTRAIN (reduced) Transfer (full) Transfer (reduced) 0.060 0.048 0.081 0.081 0.077 0.070 0.092 0.083 0.788 0.816 0.782 0.792 0.072 0.031 0.457 0.504 0.098 0.090 0.329 0. 0.617 0.644 0.620 0.645 0.079 0.055 0.056 0.028 0.141 0.136 0.134 0.131 0.670 0.665 0.682 0.689 Takeaway 2: Domain Transferability and Generalization Our findings confirm that HTC can learn transferable signals of uncertainty. This transfer is most effective between tasks with similar cognitive processes while revealing the boundaries of cross-domain transfer. While universal, one-size-fits-all calibrator faces challenges when transferring across fundamentally different cognitive paradigms. 8 Preprint Salesforce AI Research Figure 5: Low-dimensional t-SNE visualization of the feature spaces for different datasets."
        },
        {
            "title": "3.4 GENERALIZATION: THE GENERAL AGENT CALIBRATOR",
            "content": "Our analysis in Section 3.3.2 has shown that while uncertainty signals are task-dependent, they share underlying patterns. This motivates our final and most ambitious experiment: can we train single, general agent calibrator (GAC) on diverse corpus of tasks and have it successfully generalize to complex, completely held-out agentic benchmark? To test this, we pooled all seven datasets (SimpleQA, HotpotQA, StrategyQA, GPQA, MATH500, HLE, MMLU-Pro) for pre-training and held out GAIA as challenging out-of-domain target. As visualized in Figure 5, GAIA lies dispersed across and beyond the pre-training feature space, making it an ideal stress test for generalization. We trained two versions of GAC (full vs. reduced features) on the combined corpus and evaluated them directly on GAIA, with results presented in Table 3 and Figure 6. Note that while HTC refers to our proposed methodological framework, GAC refers to the specific pre-trained model artifact released for zero-shot generalization. Figure 6: Reliability Diagrams for different calibration methods on the GAIA validation set. Our results are highly encouraging. As shown in Table 3, pretraining GAC delivers the strongest calibration results on GAIA. Pretrained GAC-Reduced achieves the best ECE at 0.118, with Pretrained GAC-Full close behind at 0.128, both clearly surpassing DIRECTTRAIN (full: 0.169, reduced: 0.142) as well as all domain-transfer baselines. While DIRECTTRAIN (reduced) obtains the lowest Brier Score (0.233) and highest AUROC (0.686), GAC-Reduced remains highly competitive (0.245 BS; 0.647 AUROC) and, crucially, retains substantially broader feature base (29.6 vs. 4.8 on average). These findings demonstrate that pretraining enables GAC to capture transferable uncertainty grammar that prioritizes reliable calibration without resorting to extreme dataset-specific sparsification. Overall, achieving the best ECE with pretrained calibrator is highly promising result, highlighting its potential as universal reliability layer for AI agents. Takeaway 3: The General Agent Calibrator Our experiments highlight the strong promise of pretrained, general-purpose agent calibrator. By training on diverse mix of domains, the calibrator achieves the best calibration (lowest ECE) on challenging out-of-domain tasks such as GAIA. This demonstrates that pretraining captures transferable uncertainty grammar that generalizes beyond any single dataset. As result, our approach offers robust, plug-and-play reliability layer that can serve as powerful foundation for future agentic systems. Preprint Salesforce AI Research Table 3: Performance of the GAC on GAIA Validation Set (top 2 are marked as bold) Method LastStep-TP Knowledge Domain Transfer Reasoning Domain Transfer DIRECTTRAIN (full) DIRECTTRAIN (reduced) Pretrained GAC-Full Pretrained GAC-Reduced ECE 0.382 0.2550.010 0.2580.010 0.1690.011 0.1420.010 0.1280.001 0.1180.006 Brier Score AUROC # of Features 0.375 0.607 0.2730.009 0.2680.008 0.2650.009 0.2330.003 0.2500.001 0.2450.002 0.6200.012 0.6190.020 0.6200.016 0.6860.013 0.6360.001 0.6470.005 1 48 48 4.82.0 48 29.63."
        },
        {
            "title": "4 CONCLUSION",
            "content": "We introduced Holistic Trajectory Calibration (HTC), feature-based and interpretable framework for agentic confidence calibration. Our work addresses compounding uncertainty, heterogeneous signals, and data scarcity, yielding three key takeaways: (1) calibration relies on hierarchy of diagnostic signals; (2) HTC features capture transferable uncertainty patterns enabling strong cross-task generalization while exposing limits under distribution shift; and (3) pretrained General Agent Calibrator (GAC) achieves the best ECE (zero-shot) on unseen tasks like GAIA, providing plug-and-play foundation. Future work will scale GAC pre-training and explore light task-specific fine-tuning to combine broad generalization with specialized accuracy."
        },
        {
            "title": "5 ETHICAL STATEMENT",
            "content": "This research contributes to the development of safer and more reliable AI agents, which is critical for their deployment in high-stakes domains like healthcare and finance. By enabling agents to better know what they dont know, our work can facilitate more effective human-AI collaboration and increase the transparency of agent decision-making. However, we also acknowledge potential risks. highly effective calibrator could be misused to create false sense of security in an agent that is still fundamentally flawed in ways not captured by our features. Like any technology that enhances AI capability, it has dual-use potential and must be deployed with comprehensive evaluation strategy that goes beyond calibration metrics alone."
        },
        {
            "title": "6 REPRODUCIBILITY STATEMENT",
            "content": "We have taken extensive steps to ensure that our work is reproducible. All datasets used in our experiments are publicly available and are described in Section 3, with preprocessing details included in Appendix A.2.6. The proposed HTC framework is fully specified: Section 2 defines the core methodology, Appendix A.6 provides complete theoretical proofs with explicit assumptions, and Appendix A.5.2 gives detailed description of all diagnostic features with both mathematical definitions and intuitive explanations. Our learning-based baselines are described in Appendix A.2.5, together with their architectures and hyperparameters. Evaluation metrics and cross-validation strategies are reported in Appendix A.2.2. Because our calibrator is lightweight logistic model operating on engineered features, the entire system can be re-implemented with minimal effort. For transparency, we additionally release an anonymized code base in the supplementary material, which computes the feature map and reproduces the calibration experiments in the paper."
        },
        {
            "title": "REFERENCES",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Sandhini Agarwal, Lama Ahmad, Jason Ai, Sam Altman, Andy Applebaum, Edwin Arbus, Rahul Arora, Yu Bai, Bowen Baker, Haiming Bao, et al. gpt-oss-120b & gpt-oss-20b model card. arXiv preprint arXiv:2508.10925, 2025. 10 Preprint Salesforce AI Research Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. Deepseek llm: Scaling open-source language models with longtermism. arXiv preprint arXiv:2401.02954, 2024. Antoine Bordes, Nicolas Usunier, Sumit Chopra, and Jason Weston. Large-scale simple question answering with memory networks. arXiv preprint arXiv:1506.02075, 2015. Tianqi Chen and Carlos Guestrin. Xgboost: scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 16, pp. 785794. ACM, August 2016. doi: 10.1145/2939672.2939785. URL http: //dx.doi.org/10.1145/2939672.2939785. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Jinhao Duan, James Diffenderfer, Sandeep Madireddy, Tianlong Chen, Bhavya Kailkhura, and Kaidi Xu. Uprop: Investigating the uncertainty propagation of llms in multi-step agentic decision-making. arXiv preprint arXiv:2506.17419, 2025. Yichao Fu, Xuewei Wang, Yuandong Tian, and Jiawei Zhao. Deep think with confidence. arXiv preprint arXiv:2508.15260, 2025. Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, and Iryna Gurevych. survey of confidence estimation and calibration in large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pp. 65776595, 2024. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use laptop? question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346361, 2021. Brier Glenn et al. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):13, 1950. Tobias Groot and Matias Valdenegro-Toro. Overconfidence is key: Verbalized uncertainty evaluation in large language and vision-language models. arXiv preprint arXiv:2405.02917, 2024. Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Weinberger. On calibration of modern neural networks. In International conference on machine learning, pp. 13211330. PMLR, 2017. Jiuzhou Han, Wray Buntine, and Ehsan Shareghi. Towards uncertainty-aware language agent. In Findings of the Association for Computational Linguistics ACL 2024, pp. 66626685, 2024. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 17351780, 1997. Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022. Michael Kirchhof, Gjergji Kasneci, and Enkelejda Kasneci. Position: Uncertainty quantification needs reassessment for large language model agents. In Forty-second International Conference on Machine Learning Position Paper Track, 2025. Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations, 2023. 11 Preprint Salesforce AI Research Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in words. arXiv preprint arXiv:2205.14334, 2022. Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. Generating with confidence: Uncertainty quantification for black-box large language models. arXiv preprint arXiv:2305.19187, 2023. Hao Liu, Zi-Yi Dou, Yixin Wang, Nanyun Peng, and Yisong Yue. Uncertainty calibration for toolusing language agents. In Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 1678116805, 2024a. Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. Agentbench: Evaluating llms as agents. In ICLR, 2024b. Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: In The Twelfth International Conference on Learning benchmark for general ai assistants. Representations, 2023. Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanitys last exam. arXiv preprint arXiv:2501.14249, 2025. Carl Edward Rasmussen and Christopher KI Williams. Gaussian Processes for Machine Learning. MIT Press, 2005. David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel Bowman. Gpqa: graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024. Aymeric Roucher, Villanova del Moral, Thomas Wolf, Leandro von Werra, and Erik Kaunismäki. smolagents: smol library to build great agentic systems, 2025. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36:6853968551, 2023. Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher Manning. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 54335442, 2023. Yao-Hung Hubert Tsai, Walter Talbott, and Jian Zhang. Efficient non-parametric uncertainty quantification for black-box large language models and decision planning. arXiv preprint arXiv:2402.00251, 2024. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345, 2024a. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. Mmlu-pro: more robust and challenging multitask language understanding benchmark. Advances in Neural Information Processing Systems, 37: 9526695290, 2024b. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. 12 Preprint Salesforce AI Research Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: survey. Science China Information Sciences, 68(2):121101, 2025. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher Manning. Hotpotqa: dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 conference on empirical methods in natural language processing, pp. 23692380, 2018. Guibin Zhang, Junhao Wang, Junjie Chen, Wangchunshu Zhou, Kun Wang, and Shuicheng Yan. Agentracer: Who is inducing failure in the llm agentic systems? arXiv preprint arXiv:2509.03312, 2025a. Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, et al. Which agent causes task failures and when? on automated failure attribution of llm multi-agent systems. arXiv preprint arXiv:2505.00212, 2025b. Qiwei Zhao, Dong Li, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Chen Zhao, et al. Uncertainty propagation on llm agent. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 60646073, 2025. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in neural information processing systems, 36:4659546623, 2023. He Zhu, Tianrui Qin, King Zhu, Heyuan Huang, Yeyi Guan, Jinxiang Xia, Yi Yao, Hanhao Li, Ningning Wang, Pai Liu, Tianhao Peng, Xin Gui, Xiaowan Li, Yuhui Liu, Yuchen Eleanor Jiang, Jun Wang, Changwang Zhang, Xiangru Tang, Ge Zhang, Jian Yang, Minghao Liu, Xitong Gao, Wangchunshu Zhou, and Jiaheng Liu. Oagents: An empirical study of building effective agents, 2025. URL https://arxiv.org/abs/2506.15741. 13 Preprint Salesforce AI Research"
        },
        {
            "title": "APPENDIX CONTENTS",
            "content": "A.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.2 Experimental Setup Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.2.1 Detailed Dataset Descriptions . . . . . . . . . . . . . . . . . . . . . . . . A.2.2 Detailed Evaluation Metrics and Protocol . . . . . . . . . . . . . . . . . . A.2.3 Model and Agent Framework Details . . . . . . . . . . . . . . . . . . . . A.2.4 Inference-based Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . A.2.5 Learning-based Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . A.2.6 Implementation and Hyperparameter Details . . . . . . . . . . . . . . . . A.3 Additional Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . A.3.1 Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.3.2 Feature Importance Analysis . . . . . . . . . . . . . . . . . . . . . . . . . A.3.3 Domain Transfer Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . A.4 Ablation Study on Feature Categories . . . . . . . . . . . . . . . . . . . . . . . . A.5 Detailed Feature Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5.1 Feature Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5.2 Feature Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.6 Theoretical Motivation and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . A.7 Efficiency and Cost Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.8 Deployment and Practical Implications . . . . . . . . . . . . . . . . . . . . . . . . A.9 Qualitative Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.10 Future Work and Broader Impact . . . . . . . . . . . . . . . . . . . . . . . . . . . A.11 LLM Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 15 16 17 17 18 18 19 20 20 26 27 30 31 33 33 34 37 14 Preprint Salesforce AI Research A.1 RELATED WORK Our work on Agentic Confidence Calibration (ACC) is situated at the intersection of two rapidly developing research areas: confidence calibration for LLMs and the nascent field of uncertainty quantification (UQ) for LLM-based agents. Confidence Calibration in LLMs Confidence calibration aims to align models predicted probability with the true likelihood of correctness. Classic methods such as Temperature Scaling (Guo et al., 2017) are effective for standard classification tasks, but their direct application to the free-form, generative outputs of LLMs is non-trivial (Kadavath et al., 2022; Lin et al., 2022). As result, recent work has explored calibration techniques specifically tailored for LLMs (Geng et al., 2024). These approaches typically leverage signals from the output distribution, e.g., prediction entropy (Kuhn et al., 2023), top-k token probabilities (Lin et al., 2023), or verbalized confidence estimates (Tian et al., 2023; Groot & Valdenegro-Toro, 2024). Another notable direction, exemplified by Deep Think with Confidence (Fu et al., 2025), highlights the importance of fine-grained, local signals (such as the lowest-confidence step within reasoning chain) over global averages for reasoning calibration. Despite these advances, existing approaches remain focused on static, single-turn, and self-contained outputs. They do not capture the compounding and multi-source uncertainties that arise in the multi-step, interactive trajectories of AI agents (Kirchhof et al., 2025). Our work extends this line of inquiry from isolated outputs to the entire agentic process. Uncertainty in LLM Agents The study of uncertainty in LLM agents is an emerging but critical field (Kirchhof et al., 2025). few pioneering works have begun to formalize the unique challenges agents present (Han et al., 2024; Tsai et al., 2024). Frameworks like UProp (Duan et al., 2025) and SAUP (Zhao et al., 2025) were the first to model how uncertainty propagates through the sequential steps of an agents trajectory. While these works provide valuable analytical frameworks for uncertainty propagation, they differ from HTCs focus on supervised, data-driven calibration and currently lack open-source implementations for direct comparison. Concurrently, other research has focused on quantifying the external uncertainty introduced by tool use, analyzing how API failures or noisy tool outputs impact reliability (Liu et al., 2024a). While these studies laid the essential groundwork by identifying the core problems of propagation and external interaction, they primarily focus on high-level modeling and do not delve into systematic, feature-based diagnosis of the underlying generation process (Zhang et al., 2025b;a). Our work builds upon their problem formulation but takes fundamentally different approach. Instead of modeling the propagation dynamics directly, we propose holistic framework that analyzes the rich, fine-grained signals embedded within the full trajectorys confidence to perform comprehensive diagnostic calibration. To our knowledge, this is the first work to systematically validate process-diagnostic feature set for the purpose of agentic confidence calibration. A.2 EXPERIMENTAL SETUP DETAILS A.2.1 DETAILED DATASET DESCRIPTIONS We use the following 8 benchmark datasets in our experiments to ensure comprehensive and multi-faceted evaluation of our proposed HTC framework. SimpleQA: large-scale factual question-answering dataset. We randomly sampled 500 instances from its test set to evaluate the agents basic knowledge retrieval capabilities. HotpotQA: multi-hop question-answering dataset that requires reasoning over multiple documents. We sampled 500 instances from its test set to assess calibration performance on more complex knowledge-intensive tasks. StrategyQA: question-answering benchmark requiring implicit reasoning steps. We used 500 samples from its test set to evaluate the agents ability to handle problems that require strategic thinking. MATH500: dataset of problems from high school mathematics competitions. We used 500 samples from the MATH500 test set to focus on the reliability of formal mathematical reasoning and computation. 15 Preprint Salesforce AI Research GPQA: high-difficulty benchmark of graduate-level STEM questions that are challenging even for domain experts. We used all 448 samples from its MAIN split. To maximize the challenge, we converted it from multiple-choice format to an open-ended generation task. MMLU-Pro: more challenging variant of MMLU that validates deep knowledge and reasoning through multi-turn dialogue and Chain-of-Thought. We used 500 samples from its test set. HLE (Human Last Exam): An extremely difficult dataset comprising problems that are challenging for human experts, often requiring complex, multi-step reasoning. We used 500 samples to test agent reliability at the frontier of its capabilities. GAIA: benchmark designed for general AI assistants, with tasks that often require long-horizon planning, multi-tool coordination, and interaction with real-world documents and websites. We used the full 165 samples from its validation set as final test of general autonomous capabilities. Notably, to increase the challenge of GPQA, we removed its multiple-choice options, requiring the agent to generate answers directly. For datasets with more than 500 samples, we randomly selected subset of 500; for those with fewer, we used the entire set (e.g., 448 samples for GPQA and the 165-sample validation set for GAIA). All samples were primarily sourced from the official test or validation splits of their respective datasets. Finally, we assign binary success label (y {0, 1}) to each trajectory by evaluating the agents final answer against the ground truth. A.2.2 DETAILED EVALUATION METRICS AND PROTOCOL To rigorously evaluate the performance of our calibration framework, we focus on the following three standard metrics. Let ci be the predicted confidence and yi {0, 1} be the ground-truth success label for trajectory over samples. Calibration Metrics Expected Calibration Error (ECE) (Guo et al., 2017): ECE measures the difference between models average confidence and its actual accuracy. To compute it, we partition the predictions into bins (Bm) based on their confidence scores. The ECE is the weighted average of the absolute difference between the accuracy and confidence of each bin: ECE = (cid:88) m= Bm acc(Bm) conf(Bm) (6) where acc(Bm) and conf(Bm) are the accuracy and average confidence of the predictions in bin Bm, respectively. lower ECE indicates better calibration. Brier Score (Glenn et al., 1950): The Brier Score is proper scoring rule that measures the mean squared error between predicted probabilities and actual outcomes. It simultaneously assesses both calibration and discrimination. It is defined as: Brier Score = 1 (cid:88) (ci yi)2 i=1 (7) lower Brier Score indicates better overall prediction quality. AUROC: The Area Under the Receiver Operating Characteristic curve measures the models ability to discriminate between successful (y = 1) and failed (y = 0) trajectories. It is thresholdindependent and evaluates how well the confidence score can rank predictions. An AUROC of 1.0 represents perfect classifier, while 0.5 represents random guess. Evaluation Protocol Many of the agent tasks in our benchmark suite, particularly on datasets like GAIA and HLE, result in complex, free-form text answers where simple string matching against the ground truth is insufficient for accurate evaluation. To address this, we adopt the widely-used LLM-as-Judge (Zheng et al., 2023) protocol for robust and scalable evaluation. The process is as follows: (1) For each completed trajectory, we extract the agents final generated answer. (2) We construct prompt that includes the original question, the ground-truth answer from the dataset, and the agents answer. (3) This prompt is sent to powerful, impartial judge model, Gemini-2.5-Pro 16 Preprint Salesforce AI Research (Comanici et al., 2025). (4) The judge model is instructed to provide binary determination of correctness, outputting the final success label {0, 1} that we use for training and evaluating our calibrator. We verified the reliability of the LLM judge on stratified subset, observing 90-95% agreement rate with human experts. A.2.3 MODEL AND AGENT FRAMEWORK DETAILS smolagents (Roucher et al., 2025): Our primary framework for all main experiments is smolagents, minimalist agent framework designed for clarity and research agility. We specifically utilize its CodeAct functionality, where the agents actions (at) are formulated as Python code blocks. This paradigm offers high expressiveness, allowing the agent to perform complex computations and interact with tools (e.g., WEB SEARCH) through simple function calls within the code. Its lightweight nature ensures that the core reasoning and uncertainty signals come directly from the LLM, minimizing confounding variables from the framework itself. OAgents (Zhu et al., 2025): For our framework generalization study, we use OAgents, state-ofthe-art, open-source agent framework known for its high performance on complex benchmarks like GAIA. OAgents incorporates more sophisticated planning and memory modules. By testing our HTC framework on OAgents, we can validate that our process-diagnostic features are fundamental signals of uncertainty, independent of the agents architectural complexity. A.2.4 INFERENCE-BASED BASELINES To rigorously evaluate our HTC framework, we compare it against five baseline methods, which are detailed below. For all methods based on log-probabilities, we use the average of the top-k/top-1 token confidences, consistent with our frameworks feature extraction. Verbalized Confidence. This is standard black-box baseline that requires no access to internal model states. We append an instruction to the agents final prompt, asking it to state its confidence on scale from 0% to 100%. An example instruction is: After providing your final answer, on new line, state your confidence in its correctness as single percentage, e.g., Confidence: 85%. We then parse the numerical value as the confidence score, c. This method is inspired by recent work on eliciting self-assessment from LLMs (Tian et al., 2023). LastStep-TP Confidence. This grey-box baseline represents the standard approach of relying on the final generation step for confidence signal. Let LN = (lN,1, . . . , lN,MN ) be the sequence of token confidences from the final step (sN ) of the trajectory. The confidence score is the simple average: clast-step = 1 MN MN(cid:88) j=1 lN,j (8) GlobalTrace-TP Confidence. This baseline extends the Last-Step approach by incorporating information from the entire trajectory, but in naive way. It computes the global average of all token confidences across all steps: cglobal-trace = 1 (cid:80)N i=1 Mi (cid:88) Mi(cid:88) i=1 j=1 li,j (9) This serves as critical baseline to test whether the performance gain of our HTC framework comes from our sophisticated feature engineering or simply from using more data. LastStep-TP + Temperature Scaling. To create stronger, calibrated baseline, we apply Temperature Scaling (Guo et al., 2017) to the Last-Step Confidence scores. single temperature parameter is optimized on validation set to minimize Log Loss, and this scalar is then used to adjust the confidence scores. GlobalTrace-TP + Temperature Scaling. Similarly, we apply Temperature Scaling to the GlobalTrace Confidence scores to provide another strong, calibrated baseline. 17 Preprint Salesforce AI Research A.2.5 LEARNING-BASED BASELINES We further compare our framework against set of supervised learning-based baselines. These methods fall into two groups: (i) neural representation learning methods, which directly operate on raw token-level confidence trajectories in an end-to-end fashion, and (ii) advanced nonlinear feature-based methods, which consume our engineered 48-dimensional trajectory feature space. Below we provide details for each baseline. LSTM-based Confidence Predictor. This model treats the confidence trajectory as variable-length sequence and encodes it with single-layer unidirectional LSTM (Hochreiter & Schmidhuber, 1997) of hidden size 64 and dropout 0.4. Each input step corresponds to the top-5 token log-probabilities, and the final hidden state is passed through three-layer feed-forward classifier (6432322) with ReLU activations and dropout. The parameter count is on the order of 4k6k, and the model is trained with Adam (learning rate 0.001), early stopping, and 5-fold cross-validation. The LSTM can capture temporal dependencies and handle variable-length sequences, but its large parameter-tosample ratio makes it prone to overfitting in small-data regimes and yields limited interpretability compared to feature-based approaches. Transformer-based Confidence Predictor. This baseline applies lightweight Transformer (Vaswani et al., 2017) encoder to the raw confidence trajectories. We use one self-attention layer with model dimension 32, two attention heads, feed-forward size of 64, and dropout 0.3. Learnable positional embeddings (up to length 2000) encode temporal order, and an attention pooling layer aggregates the sequence before two-layer classifier (32162). The model has about 3k5k parameters and is trained with Adam (learning rate 0.001, batch size 4) and early stopping. While the Transformer can capture long-range dependencies and trains in parallel, it is computationally more demanding and unstable in small-data settings. Neural Network (MLP). Operating on the engineered 48-dimensional feature representation, this baseline uses two-hidden-layer multilayer perceptron with sizes 4832162 and ReLU activations. Regularization includes dropout and L2 penalty (α = 0.01), and the network has about 2k3k parameters. Training is performed with Adam and early stopping. The MLP provides nonlinear modeling capacity over compact, interpretable features, but its performance can fluctuate with dataset size and it remains less transparent than linear models. Gaussian Process Classifier. We implement Gaussian Process classifier with an RBF kernel combined with white-noise kernel. Kernel hyperparameters are optimized with three random restarts, and predictions use up to 100 iterations. Being non-parametric, the models effective complexity scales with the training set size. Gaussian Processes (Rasmussen & Williams, 2005) naturally provide calibrated probabilistic outputs and flexible capacity, but incur cubic computational cost O(n3), require careful kernel selection, and are impractical for larger datasets. XGBoost Classifier. This baseline uses gradient-boosted decision trees on the 48-dimensional features, with 100 estimators of maximum depth 3, learning rate 0.1, row subsampling 0.8, column subsampling 0.8, and both L1 (0.1) and L2 (1.0) regularization. The ensemble corresponds to roughly 1k2k effective parameters. XGBoost (Chen & Guestrin, 2016) is robust on tabular data and captures higher-order feature interactions, but still risks overfitting in very small datasets and provides less interpretability than linear models. In summary, the end-to-end neural encoders (LSTM, Transformer) directly consume raw confidence trajectories but suffer from high parameter counts relative to the limited data, leading to severe overfitting and unstable behavior. The feature-based nonlinear methods (MLP, Gaussian Process, XGBoost) make better use of the engineered 48-dimensional representation and achieve stronger performance overall, yet they remain less interpretable and still prone to variance under small-sample regimes. These limitations highlight the motivation for our proposed lightweight linear calibrators, which strike favorable balance between stability, interpretability, and data efficiency. A.2. IMPLEMENTATION AND HYPERPARAMETER DETAILS For completeness, we summarize the implementation details of our proposed Holistic Trajectory Calibration (HTC) method. 18 Preprint Salesforce AI Research Cross-Validation Strategy. We adopt 5-fold stratified cross-validation protocol to preserve class balance. With 500 labeled trajectories, each fold contains 100 samples. Within each fold, we use an 80%/20% split for training and validation. All experiments use fixed random seed of 42. The liblinear solver is deterministic, and all code, hyperparameters, and configurations are version-controlled for exact reproducibility. The maximum iteration count is set to 1000, although convergence typically occurs within 50100 iterations. Hyperparameter Optimization. The regularization strength α is tuned via grid search over 15 candidate values: {0.001, 0.01, 0.1, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20.0, 50.0}. Model selection is based on combined criterion that maximizes AUROC while minimizing both Brier Score and ECE, averaged across folds. In practice, the optimal α typically falls in the range of 1.05.0. The resulting sparse solutions select 1525 features (5070% of the 48 total). The model demonstrates low variance across folds, with training requiring less than one second per fold and inference under one millisecond per sample. Key Advantages. Our approach provides (i) interpretability through transparent feature weights and selection, (ii) stability across varying data sizes, (iii) high computational efficiency in both training and inference, and (iv) robustness to overfitting compared to more complex baselines. These properties make the method particularly suitable for small datasets (< 500 samples), production systems requiring reliable calibration, and resource-constrained settings. A.3 ADDITIONAL EXPERIMENTAL RESULTS A.3.1 MAIN RESULTS In Section 3.2, we presented summary of our HTC frameworks performance against baselines on subset of three representative datasets. For complete overview of our methods efficacy, we provide detailed results for both the HTC-Full and HTC-Reduced variants across all eight datasets in our benchmark suite. Table 4 presents the mean and standard deviation for ECE, Brier Score, and AUROC when using the full set of 48 trajectory features (L2 regularization). These results demonstrate the robust performance of HTC even when all features are considered, establishing strong upper bound for the feature set. Table 5 details the performance of the (reduced feature) variant (L1 regularization), showing its mean and standard deviation for ECE, Brier Score, and AUROC across all datasets. Crucially, this table also includes the mean and standard deviation of the number of features selected by the Lasso regularization across different random seeds, providing insight into the sparsity and efficiency of this approach. The consistent strong performance with reduced feature set further validates the effectiveness of our feature engineering and selection process. Table 4: HTC Performance with Full Feature Set across All Datasets. Dataset ECE Brier Score AUROC Mean Std Mean Std Mean Std HLE 0.0720 GPQA 0.1241 SimpleQA 0.0748 MATH500 0.0604 GAIA 0.1692 HotpotQA 0.1156 0.0775 MMLU-Pro StrategyQA 0. 0.0108 0.0110 0.0065 0.0071 0.0114 0.0060 0.0075 0.0081 0.0977 0.2185 0.1500 0.0773 0.2654 0.1930 0.1257 0.1405 0.0019 0.0016 0.0029 0.0015 0.0093 0.0020 0.0032 0.0015 0.6169 0.7040 0.7267 0.7875 0.6204 0.7141 0.7276 0.6698 0.0231 0.0070 0.0103 0.0178 0.0164 0.0061 0.0118 0.0054 Preprint Salesforce AI Research Table 5: HTC Performance with Reduced Feature Set and Feature Counts across All Datasets Dataset ECE Brier Score AUROC Features Mean Std Mean Std Mean Std Mean Std 0.0305 HLE 0.1022 GPQA 0.0676 SimpleQA 0.0476 MATH500 GAIA 0.1420 0.0824 HotpotQA MMLU-Pro 0.0592 StrategyQA 0.0545 0.0038 0.0159 0.0081 0.0088 0.0100 0.0109 0.0047 0.0048 0.0897 0.2134 0.1402 0.0701 0.2332 0.1824 0.1167 0. 0.0005 0.0018 0.0024 0.0006 0.0026 0.0007 0.0009 0.0014 0.6439 0.7060 0.7523 0.8162 0.6860 0.7288 0.7492 0.6647 0.0199 0.0066 0.0141 0.0075 0.0131 0.0026 0.0075 0.0117 8.2 23.4 14.4 15.2 4.8 7.6 13.8 15.2 4.1 1.9 3.1 3.0 1.5 0.8 3.0 6.3 Figure 7: The Impact of Agent Framework on the GPQA dataset. A.3.2 FEATURE IMPORTANCE ANALYSIS To better understand the internal behavior of HTC, we analyze which diagnostic features are most influential across datasets and selection levels. Figure 8 shows the absolute weight magnitudes of the ℓ1-regularized logistic calibrator on eight benchmarks, highlighting that certain dynamics (e.g., confidence change) and stability measures (e.g., attention entropy, token volatility) consistently receive high importance. Figure 9 provides complementary perspective by reporting feature selection frequencies under different levels (Top1, Top3, Top5, and all selected), allowing us to quantify which features are repeatedly chosen across runs. Table 6 further aggregates these results into ranked list of top features, organized by category. Together, these analyses show that temporal dynamics and stability signals emerge as the most dominant indicators of reliability, while positional and structural features contribute complementary but non-negligible signals. This provides clear interpretability benefits: HTC not only delivers strong calibration but also yields transparent insights into which aspects of reasoning trajectory drive reliable predictions. A.3.3 DOMAIN TRANSFER ANALYSIS We further investigate the generalization ability of HTC across domains, by training the calibrator on one dataset and evaluating it directly on others without retraining. Figures 1013 present transfer matrices for both GPT-4.1 and GPT-4o under reduced and full feature sets, evaluated on ECE, Brier Score, and AUROC. These heatmaps reveal that HTC achieves stable cross-domain calibration: models trained on one benchmark often transfer reasonably well to others, especially among datasets with similar reasoning structures (e.g., QA benchmarks). Figure 14 provides an aggregated comparison, showing that GPT-4.1 consistently outperforms GPT-4o by small margin, but both demonstrate robust transferability across metrics. Tables 710 give the complete numerical results, confirming that reduced feature sets maintain performance levels close to the full feature space, thereby validating the efficiency and compactness of our design. Overall, these results demonstrate that HTC is not only effective in-domain but also generalizes reliably across diverse datasets, while being relatively insensitive to the underlying backbone model or the size of the feature set. Preprint Salesforce AI Research Figure 8: Feature importance analysis across all datasets on five experimental runs. Figure 9: Full feature selection distribution across different levels (Top1, Top3, Top5 and all selected) on four feature categories. 21 Preprint Salesforce AI Research Table 6: Feature Selection Results Selection Level Feature Index Feature Name Category Frequency Percentage Top 1 Top 3 Top F47 F27 F17 F33 F26 F25 F31 F37 F40 F46 F27 F31 F46 F33 F37 F43 F17 F14 F25 F47 F33 F31 F27 F37 F46 F43 F41 F30 F17 F39 std_tokens_per_step last_attention_concentration top1_confidence_change attention_entropy_mean last_attention_entropy first_topk_avg last_top1_avg attention_spread_mean token_volatility_std avg_tokens_per_step last_attention_concentration last_top1_avg avg_tokens_per_step attention_entropy_mean attention_spread_mean normalized_step_count top1_confidence_change step_progression_entropy first_topk_avg std_tokens_per_step attention_entropy_mean last_top1_avg last_attention_concentration attention_spread_mean avg_tokens_per_step normalized_step_count token_skewness_mean last_confidence_skewness top1_confidence_change token_volatility_mean Structure Position Dynamics Stability Position Position Position Stability Stability Structure Position Position Structure Stability Stability Structure Dynamics Dynamics Position Structure Stability Position Position Stability Structure Structure Stability Position Dynamics Stability 5 5 4 4 4 3 3 3 2 2 11 10 10 9 9 8 7 6 5 5 15 13 13 10 10 9 9 8 7 12.5 12.5 10 10 10 7.5 7.5 7.5 5 5 9.2 8.3 8.3 7.5 7.5 6.7 5.8 5 4.2 4.2 7.5 6.5 6.5 5 5 4.5 4.5 4 3.5 3.5 Figure 10: Domain transfer matrix with reduced features using GPT-4.1. Figure 11: Domain transfer matrix with full features using GPT-4.1. Preprint Salesforce AI Research Figure 12: Domain transfer matrix with reduced features using GPT-4o. Figure 13: Domain transfer matrix with full features using GPT-4o. Figure 14: Comparison of different base LLMs (GPT-4.1 vs GPT-4o, with full and reduced features ) on the effect of domain transfer performance. We show the average of all domain transfer results on ECE, BS and AUROC metrics. This figure illustrates that different models show stable domain transfer performance while GPT-4.1 is slightly better than GPT-4o. 23 Preprint Salesforce AI Research Table 7: Full Feature Transfer Results: ECE, Brier Score (BS), and AUROC matrices (GPT-4.1). ECE HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE 0.2096 GPQA SimpleQA 0.5361 0.4030 MATH500 GAIA 0.4834 0.2553 HotpotQA MMLU-Pro 0.4570 StrategyQA 0.2139 0.2920 - 0.4349 0.3300 0.2659 0.2291 0.2126 0. 0.4807 0.4461 - 0.1153 0.0994 0.0894 0.0390 0.0644 0.6114 0.3673 0.0929 - 0.0964 0.1009 0.0806 0.3163 0.2729 0.1912 0.4205 0.3563 - 0.2786 0.1259 0.2626 0.4376 0.2788 0.1132 0.1733 0.0530 - 0.1070 0.1292 0.5496 0.3958 0.1089 0.1149 0.1694 0.1274 - 0.1072 0.3765 0.2553 0.0989 0.0862 0.0786 0.2691 0.0562 - Brier Score HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE GPQA 0.1691 0.5016 SimpleQA MATH500 0.3298 0.3786 GAIA HotpotQA 0.2353 MMLU-Pro 0.3292 StrategyQA 0.1842 0.3256 - 0.4459 0.3622 0.3187 0.2909 0.2907 0.2910 0.3880 0.3799 - 0.1650 0.1551 0.1493 0.1469 0. 0.4796 0.2584 0.0982 - 0.0960 0.1106 0.0915 0.2606 0.3136 0.2932 0.4332 0.3725 - 0.3266 0.2492 0.3333 0.3833 0.3057 0.1939 0.2187 0.1895 - 0.2077 0.2250 0.4355 0.3133 0.1369 0.1437 0.1576 0.1516 - 0.1649 0.3227 0.2401 0.1482 0.1476 0.1610 0.2829 0.1341 - AUROC HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE 0.5694 GPQA 0.5112 SimpleQA 0.5496 MATH500 0.5557 GAIA 0.5527 HotpotQA MMLU-Pro 0.6204 StrategyQA 0.5793 0.5377 - 0.5874 0.5773 0.5926 0.6254 0.5521 0.6108 0.7213 0.5588 - 0.6749 0.7314 0.7540 0.7168 0.6912 0.7257 0.5623 0.4728 - 0.6966 0.6725 0.7822 0. 0.6001 0.5308 0.5834 0.6340 - 0.5660 0.6503 0.5360 0.7033 0.5508 0.7186 0.6953 0.7002 - 0.6496 0.6043 0.6926 0.6161 0.6507 0.7194 0.6504 0.6156 - 0.6904 0.6087 0.5541 0.6572 0.6499 0.6248 0.4717 0.6820 - Table 8: Reduced Feature Transfer Results: ECE, Brier Score (BS), and AUROC matrices (GPT-4.1). ECE HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE 0.2327 GPQA 0.3885 SimpleQA 0.4029 MATH500 0.3872 GAIA 0.1294 HotpotQA MMLU-Pro 0.5041 StrategyQA 0.2452 0.2683 - 0.3040 0.3163 0.1346 0.1082 0.2816 0.1169 0.6482 0.3306 - 0.1072 0.2052 0.0974 0.0535 0.0791 0.7476 0.3191 0.0806 - 0.2637 0.2778 0.0809 0. 0.2973 0.1335 0.3268 0.3062 - 0.1499 0.2038 0.1394 0.5534 0.1890 0.0704 0.1490 0.1234 - 0.1212 0.0872 0.6904 0.3231 0.0691 0.0984 0.2620 0.1849 - 0.1323 0.6442 0.2987 0.0638 0.0951 0.2359 0.1497 0.0283 - Brier Score HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE 0.1697 GPQA 0.3375 SimpleQA 0.3081 MATH500 0.2459 GAIA 0.1191 HotpotQA MMLU-Pro 0.3493 StrategyQA 0.1862 0.3115 - 0.3304 0.3428 0.2517 0.2454 0.3161 0.2532 0.5795 0.2822 - 0.1578 0.1913 0.1466 0.1478 0.1526 0.6480 0.2089 0.1011 - 0.1562 0.1671 0.0831 0.1582 0.3289 0.2767 0.3392 0.3206 - 0.2574 0.2624 0. 0.5099 0.2465 0.1828 0.2115 0.2064 - 0.2031 0.2019 0.6023 0.2512 0.1217 0.1371 0.1882 0.1518 - 0.1382 0.5526 0.2664 0.1353 0.1406 0.1945 0.1603 0.1312 - AUROC HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA - HLE 0.5619 GPQA 0.5756 SimpleQA 0.5913 MATH500 0.5467 GAIA 0.6454 HotpotQA MMLU-Pro 0.6448 StrategyQA 0.6040 0.5277 - 0.6291 0.6046 0.5998 0.6277 0.5893 0.5782 0.6959 0.5776 - 0.7027 0.7114 0.7537 0.7455 0.7415 0.6982 0.6274 0.6265 - 0.7294 0.8016 0.7922 0.7804 0.6301 0.5374 0.6090 0.6580 - 0.6270 0.6791 0.5996 0.6807 0.5946 0.7321 0.7075 0.7034 - 0.7177 0. 0.6960 0.6267 0.7079 0.7361 0.7355 0.7669 - 0.7321 0.6492 0.5049 0.6807 0.6603 0.6632 0.6538 0.6888 - 24 Preprint Salesforce AI Research Table 9: Full Feature Transfer Results: ECE, Brier Score, and AUROC matrices (GPT-4o). ECE HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE 0.1244 GPQA 0.1763 SimpleQA 0.4039 MATH500 GAIA 0.1589 0.1709 HotpotQA MMLU-Pro 0.4473 StrategyQA 0.3108 0.1814 0.1462 0.2729 0.1991 0.1731 0.3872 0.3131 0.4252 0.1452 0.2172 0.1444 0.1360 0.2168 0.3201 0.6760 0.4362 0.2628 0.2735 0.3816 0.0678 0. 0.1502 0.0673 0.1305 0.2702 0.1944 0.2505 0.3365 0.5131 0.2699 0.1275 0.1946 0.2817 0.1882 0.2271 0.7106 0.4845 0.3872 0.0719 0.4121 0.4394 0.2100 0.7427 0.4435 0.3260 0.1039 0.5721 0.2855 0.0583 Brier Score HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE GPQA 0.0808 0.1332 SimpleQA 0.2754 MATH500 0.1284 GAIA 0.1264 HotpotQA MMLU-Pro 0.3176 StrategyQA 0.2520 0.2204 0.2205 0.2797 0.2399 0.2357 0.3638 0.3193 0.4026 0.2086 0.2296 0.2438 0.2141 0.2400 0.3115 0.6207 0.3377 0.2245 0.2495 0.3148 0.1362 0.1615 0.1768 0.1415 0.1714 0.2418 0.2039 0.2276 0. 0.5043 0.3329 0.2406 0.2673 0.3299 0.2587 0.2750 0.6685 0.4074 0.3226 0.1526 0.3514 0.3728 0.2281 0.7067 0.3718 0.2786 0.1620 0.5011 0.2470 0.1561 AUROC HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE 0.6256 GPQA 0.5179 SimpleQA 0.5798 MATH500 0.5239 GAIA 0.4992 HotpotQA MMLU-Pro 0.5400 StrategyQA 0.4986 0.5958 0.5725 0.6380 0.5852 0.5217 0.6003 0.5570 0.7301 0.7921 0.7948 0.7102 0.7635 0.7707 0.7632 0.7040 0.7864 0.7573 0.6964 0.7600 0.7798 0.7462 0.5574 0.7024 0.6238 0.7378 0.6085 0.7786 0.6808 0.5535 0.5747 0.6732 0.6260 0.6007 0.6570 0. 0.5713 0.6275 0.6343 0.6751 0.6707 0.6487 0.5868 0.5452 0.5694 0.6037 0.6019 0.5807 0.5932 0.6960 Table 10: Reduced Feature Transfer Results: ECE, Brier Score, and AUROC matrices (GPT-4o). ECE HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE 0.1389 GPQA 0.1118 SimpleQA 0.4568 MATH500 0.1513 GAIA 0.2045 HotpotQA MMLU-Pro 0.4572 StrategyQA 0.5212 0.1839 0.1099 0.3833 0.0685 0.1507 0.3818 0.3921 0.4613 0.1448 0.3065 0.2345 0.0892 0.2434 0.2948 0.6982 0.4502 0.4758 0.3805 0.3883 0.0333 0.1089 0.1245 0.0476 0.1181 0.3734 0.1787 0.3207 0.4135 0.5292 0.2445 0.1407 0.2312 0.3343 0.1695 0. 0.7266 0.4914 0.4612 0.0366 0.4666 0.4729 0.1735 0.7480 0.4671 0.3507 0.0316 0.6019 0.3234 0.0403 Brier Score HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE 0.0769 GPQA 0.0877 SimpleQA 0.2928 MATH500 0.0885 GAIA 0.1301 HotpotQA MMLU-Pro 0.3007 StrategyQA 0. 0.2204 0.2008 0.3328 0.1929 0.2327 0.3427 0.3597 0.4529 0.2112 0.2981 0.2562 0.2004 0.2534 0.2838 0.6531 0.3432 0.3781 0.2942 0.3249 0.1299 0.1825 0.1685 0.1340 0.1508 0.2758 0.1885 0.2427 0.3336 0.5175 0.3032 0.2406 0.2755 0.3458 0.2525 0.2648 0.6895 0.3898 0.3925 0.1367 0.3713 0.3936 0. 0.7134 0.3740 0.2832 0.1503 0.5163 0.2572 0.1488 AUROC HLE GPQA SimpleQA MATH500 GAIA HotpotQA MMLU-Pro StrategyQA HLE 0.6184 GPQA 0.5206 SimpleQA 0.5824 MATH500 0.4956 GAIA 0.5932 HotpotQA MMLU-Pro 0.5449 StrategyQA 0.5927 0.6062 0.5808 0.6603 0.5925 0.5188 0.6279 0. 0.6791 0.7852 0.7735 0.7721 0.7795 0.7732 0.7839 0.6943 0.8178 0.7756 0.7431 0.7078 0.8155 0.6897 0.5372 0.7453 0.6425 0.7635 0.6209 0.7897 0.6876 0.5753 0.6055 0.6633 0.6388 0.6223 0.6467 0.6648 0.5879 0.7074 0.6214 0.7517 0.6894 0.6243 0.5679 0.5256 0.6064 0.6200 0.6292 0.5752 0.6301 0.6710 25 Preprint Salesforce AI Research A.4 ABLATION STUDY ON FEATURE CATEGORIES To further examine the contribution of different feature categories, we conducted systematic ablation study on the combined dataset of seven benchmarks (3,446 trajectories). The calibrator was trained on different subsets of the 48 features, including all single-category models (Dynamics only, Position only, Stability only, Structure only), all pairwise combinations, all three-way combinations, and the full feature set, yielding 15 configurations in total. Figures 15 and Table 11 summarize the results. Several clear findings emerge: Full feature set performs best. Using all 48 features achieves the highest AUROC (0.8430), the lowest Brier Score (0.1471), and the lowest ECE (0.0328). This demonstrates that the entire feature map provides complementary information that cannot be captured by any smaller subset. Multi-category combinations outperform single categories. Every twoor three-way combination substantially improves over the best single category. For example, Dynamics+Position+Stability achieves AUROC = 0.8419, which is +0.0137 higher than the strongest single category (Dynamics, AUROC = 0.8282). Single categories are insufficient. When restricted to only one category, performance drops noticeably (AUROC 0.7830.828). Structure alone is the weakest (0.783 AUROC), showing that contextual information is not sufficient without dynamics or stability. This highlights the need for diverse diagnostic signals. Category complementarity emerges with scale and diversity. On the combined dataset, which is larger and more diverse than individual tasks, the synergy across categories becomes much more evident. This contrasts with the single-dataset setting (e.g., SimpleQA), where rankings can vary. The aggregated analysis demonstrates that HTCs design is robust and general. Figure 15: Performance of calibrators trained on different feature combinations. Results are averaged across 3,446 trajectories from seven datasets. Multi-category combinations consistently outperform single categories, and the full feature set achieves the best results. 26 Preprint Salesforce AI Research Table 11: Performance summary of feature ablation study (sorted by AUROC) Feature Combination AUROC () Brier Score () ECE () Full (48) Dynamics+Position+Stability (43) Dynamics+Position+Structure (38) Position+Stability+Structure (29) Dynamics+Stability+Structure (34) Position+Stability (24) Dynamics+Position (33) Dynamics+Stability (29) Position+Structure (19) Stability+Structure (15) Stability (10) Position (14) Dynamics+Structure (24) Dynamics (19) Structure (5) Mean Std Mean Std Mean Std 0.8430 0.8419 0.8419 0.8418 0.8397 0.8396 0.8386 0.8367 0.8364 0.8326 0.8282 0.8231 0.8205 0.7943 0. 0.0134 0.0127 0.0130 0.0140 0.0124 0.0149 0.0125 0.0130 0.0181 0.0128 0.0131 0.0173 0.0122 0.0096 0.0207 0.1471 0.1475 0.1479 0.1480 0.1490 0.1493 0.1495 0.1502 0.1501 0.1530 0.1552 0.1562 0.1577 0.1700 0.1730 0.0065 0.0063 0.0065 0.0064 0.0065 0.0069 0.0060 0.0067 0.0072 0.0059 0.0059 0.0064 0.0065 0.0041 0.0080 0.0328 0.0427 0.0422 0.0401 0.0480 0.0406 0.0349 0.0369 0.0411 0.0355 0.0357 0.0371 0.0369 0.0335 0.0537 0.0065 0.0046 0.0057 0.0047 0.0037 0.0115 0.0078 0.0095 0.0014 0.0117 0.0079 0.0067 0.0103 0.0124 0.0099 A.5 DETAILED FEATURE DESCRIPTION A.5.1 FEATURE DEFINITIONS Agent reliability is not snapshot property of the last step but an emergent property of the whole trajectory. Our feature set operationalizes this view along four complementary axes: Dynamics how confidence evolves across steps (trend, variability, accelerations). Position what the first and last steps reveal (onset vs. resolution). Stability whether signals converge consistently (low volatility, low entropy drift). Structure the form factor of trajectory (length and token allocation across steps). Notation. trajectory τ has steps indexed by = 1, . . . , S. At step there are nt tokens with positive confidence values rt,1, . . . , rt,nt. We normalize within-step to obtain discrete distribution πt,i = rt,i j=1 rt,j + ε (cid:80)nt , ε = 108. The within-step mean and standard deviation are µt = 1 nt nt(cid:88) i=1 rt,i, σt = (cid:118) (cid:117) (cid:117) (cid:116) 1 nt nt(cid:88) i=1 (rt,i µt)2. We define per-step summaries of the distribution rt,: nt(cid:88) Ht = πt,i log(πt,i + ε) (entropy), (concentration), (spread / volatility), κt = ρt = i=1 maxi rt,i µt + ε σt µt + ε nt(cid:88) 1 nt i=1 27 skewt = (cid:18) rt,i µt σt + ε (cid:19)3 (skewness). (10) (11) (12) (13) (14) (15) (16) Preprint Salesforce AI Research For each step we also compute aggregated confidences: xt = yt = 1 nt 1 nt nt(cid:88) i=1 nt(cid:88) i=1 Top1Conf(t, i), TopkConf(t, i). Cross-step differences (gradients) are xt = xt+1 xt, yt = yt+1 yt, = 1, . . . , 1. (17) (18) (19) (20) All undefined statistics (e.g., < 2 or nt < 2) are set to 0, consistent with our implementation. Intuition. Ht measures dispersion (lower is more focused), κt captures dominance of the top alternative, ρt is scale-free volatility index, and skewt encodes asymmetry. Reliable trajectories tend to show decreasing entropy, stable volatility, and consistent trends in xt, yt. Category A: Dynamics (19 features). Purpose: capture how confidence changes across the trajectory. Reliable reasoning tends to exhibit steady, low-variance growth; erratic failures show oscillations, spikes, or regressions. top1_gradient_mean: mean({xt}S1 top1_gradient_std: std({xt}S1 top1_gradient_max: max{xt}S1 top1_gradient_min: min{xt}S1 top1_gradient_trend: xS1 x1 (if 3). Detects acceleration or deceleration of belief t=1 ). Average velocity of top-1 confidence growth. t=1 ). Large variance indicates unstable or oscillatory confidence. t=1 . Largest single upward jump in top-1 confidence. t=1 . Largest downward collapse of top-1 confidence. formation. topk_gradient_mean, topk_gradient_min, topk_gradient_trend: identical statistics computed for top-k confidence {yt}. Capture broader consensus dynamics across multiple hypotheses. topk_gradient_max, topk_gradient_std, token_gradient_mean, token_gradient_std, token_gradient_max, token_gradient_min: computed from local token differences {rt,i+1 rt,i}. Reveal whether step is pruning sharply (large gradients) or dithering (flat gradients). step_progression_entropy: std({Ht})/(mean({Ht}) + ε). step_progression_concentration: std({κt})/(mean({κt}) + ε). step_progression_spread: std({ρt})/(mean({ρt}) + ε). These coefficients of variation measure how entropy, concentration, and spread evolve; convergence implies decreasing ratios. top1_confidence_change: xS x1. topk_confidence_change: yS y1. Capture overall strengthening or weakening of confidence from start to end. Category B: Position (14 features). Purpose: the first and last steps capture complementary aspects. Early steps reflect exploration, late steps commitment. Comparing them diagnoses premature certainty or end-stage overconfidence. first_attention_entropy: H1. Dispersion of the first step distribution. first_attention_concentration: κ1. Peakedness of the first step. first_attention_spread: ρ1. Variability relative to the mean. first_confidence_volatility: ρ1. Same as spread, interpreted as instability at the onset. first_confidence_skewness: skew1. Asymmetry of the distribution at the first step. Preprint Salesforce AI Research first_top1_avg: x1. Average top-1 confidence at the first step. first_topk_avg: y1. Average top-k confidence at the first step. last_attention_entropy: HS. Dispersion at the last step. last_attention_concentration: κS. Sharpness at the last step. last_attention_spread: ρS. Variability at the last step. last_confidence_volatility: ρS. Instability at the end. last_confidence_skewness: skewS. Tail asymmetry at the last step. last_top1_avg: xS. Final top-1 confidence. last_topk_avg: yS. Final top-k confidence. Category C: Stability (10 features). Purpose: measure consistency across steps. Reliable trajectories are smooth; unreliable ones oscillate. attention_entropy_mean: mean({Ht}). attention_entropy_std: std({Ht}). attention_concentration_mean: mean({κt}). attention_concentration_std: std({κt}). attention_spread_mean: mean({ρt}). attention_spread_std: std({ρt}). Together, these summarize whether attention signals converge smoothly or fluctuate widely. token_volatility_mean: mean({ρt}). Average token-level volatility across steps. token_volatility_std: std({ρt}). Step-to-step volatility variation. token_skewness_mean: mean({skewt}). Average asymmetry of token distribution. token_skewness_std: std({skewt}). Variation of asymmetry over steps. Category D: Structure (5 features). Purpose: capture trajectory form factor (length and token allocation). These features provide context: short trajectories may indicate premature certainty; long, irregular ones suggest hesitation. normalized_step_count: S/10. Normalized trajectory length. first_token_count: n1. Number of tokens in the first step. last_token_count: nS. Number of tokens in the last step. avg_tokens_per_step: ((cid:80)S std_tokens_per_step: std({nt}S t=1 nt)/S. Average token count per step. t=1). Variation in token counts across steps. In total, the 48 features provide structured and interpretable representation of trajectory reliability. Dynamics quantify how confidence values evolve step by step, Position features highlight the complementary roles of the trajectory onset and resolution, Stability measures assess whether the process converges consistently across steps, and Structure features capture the overall form factor of reasoning traces. Together, these categories decompose reliability into distinct yet complementary dimensions: they allow us to pinpoint when an agent is consolidating versus oscillating, whether its final certainty is warranted by stable evidence, and how the length or allocation of tokens modulates calibration. Unlike opaque neural encoders, this feature map offers transparent diagnostics that both improve calibration and yield actionable insights into the mechanisms underlying agent reliability. Preprint Salesforce AI Research A.5.2 FEATURE MAP Here is detailed feature map. }, \"Position\": { # Features capturing key positional information (first/last steps) (14 features) \"Dynamics\": { # Features capturing temporal changes and gradients across steps (19 features) ], # 16 # 14 # 17 # 18 # 10 # 11 # 12 # 13 \"2.1: First Step Specific\": [ # 0 # 1 # 2 # 3 # 4 # 5 # 6 # 7 # 8 # 'top1_confidence_change', 'topk_confidence_change', ], \"1.3: Step Progression\": [ ], \"1.4: Confidence Change\": [ 'step_progression_entropy', 'step_progression_concentration',# 15 'step_progression_spread', ], \"1.2: Token-level Gradients\": [ 'token_gradient_mean', 'token_gradient_std', 'token_gradient_max', 'token_gradient_min', \"1.1: Cross-step Gradients\": [ 'top1_gradient_mean', 'top1_gradient_std', 'top1_gradient_max', 'top1_gradient_min', 'top1_gradient_trend', 'topk_gradient_mean', 'topk_gradient_std', 'topk_gradient_max', 'topk_gradient_min', 'topk_gradient_trend', 1 # ============================================================================== 2 # FINAL OPTIMIZED FEATURE MAP - 48 Features (STABLE VERSION) 3 # ============================================================================== 4 5 FEATURE_MAP_FINAL_STABLE = { 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 } \"3.1: Attention Stability\": [ # 33 'attention_entropy_mean', 'attention_entropy_std', # 34 'attention_concentration_mean', # 35 'attention_concentration_std', # 36 # 37 'attention_spread_mean', # 38 'attention_spread_std', # 19 'first_attention_entropy', 'first_attention_concentration',# 20 'first_attention_spread', # 21 'first_confidence_volatility', # 22 # 23 'first_confidence_skewness', # 24 'first_top1_avg', # 25 'first_topk_avg', 'last_attention_entropy', # 26 'last_attention_concentration', # 27 # 28 'last_attention_spread', # 29 'last_confidence_volatility', # 30 'last_confidence_skewness', # 31 'last_top1_avg', # 32 'last_topk_avg', ], \"3.2: Token-level Stability\": [ 'token_volatility_mean', 'token_volatility_std', 'token_skewness_mean', 'token_skewness_std', \"4.1: Structural Metrics\": [ 'normalized_step_count', 'first_token_count', 'last_token_count', 'avg_tokens_per_step', 'std_tokens_per_step', ], \"2.2: Last Step Specific\": [ # 43 # 44 # 45 # 46 # 47 # 39 # 40 # 41 # 42 ], ], ], } }, \"Structure\": { # Features capturing structural and derived information (5 features) }, \"Stability\": { # Features capturing stability and consistency patterns (10 features) Listing 1: Final Optimized Feature Map (48 features, stable) 30 Preprint Salesforce AI Research A.6 THEORETICAL MOTIVATION AND ANALYSIS We present four claims with complete proofs to theoretically support Holistic Trajectory Calibration (HTC). Notation follows Section 2: trajectory is denoted τ , its extracted 48-dimensional diagnostic features are ϕ(τ ) R48, the HTC calibrator is FHTC : R48 [0, 1], the last-step confidence is pT , and the ground-truth task outcome is {0, 1}. Expectations, variances, and entropies are with respect to the data-generating distribution. Losses and Bayes risks. For predictor : [0, 1], the Brier loss and log-loss are LBrier(q) = E(cid:2)(Y q)2(cid:3), (21) Llog(q) = E[Y log + (1 ) log(1 q)] . (22) The Bayes-optimal predictors are conditional means q() = P(Y = 1 ), and the corresponding Bayes risks are LBrier(q) = E[Var(Y )] , inf inf Llog(q) = H(Y ). Proposition 1 (Trajectory features dominate last-step confidence). Let ϕ(τ ) = P(Y = 1 ϕ(τ )), (pT ) = P(Y = 1 pT ). If σ(pT ) σ(ϕ(τ )), then Llog (cid:0)q ϕ LBrier (cid:1) LBrier(q (cid:1) = H(Y ϕ(τ )) H(Y pT ) = Llog(q (cid:0)q ) , ϕ ) . (23) (24) (25) Inequalities are strict whenever ϕ(τ ) contains strictly more information about than pT . Proof. By (23), the Bayes Brier risk is E[Var(Y )]. By the law of total variance, Var(Y ) = E[Var(Y ϕ)] + Var(E[Y ϕ]) = E[Var(Y pT )] + Var(E[Y pT ]). (26) Since σ(ϕ) refines σ(pT ), Var(E[Y ϕ]) Var(E[Y pT ]), hence E[Var(Y ϕ)] E[Var(Y pT )], proving (24). For log-loss, the Bayes risk equals conditional entropy. By the chain rule, H(Y pT ) = H(Y ϕ, pT ) + I(Y ; ϕ pT ) H(Y ϕ). This proves (25). (27) Proposition 2 (Generalization of sparse linear HTC calibrator). Let the HTC calibrator be FHTC(ϕ(τ )) = σ(wϕ(τ )) with w1 B, features bounded as ϕ(τ ) R, and = 48. The empirical Rademacher complexity of linear scores sw(x) = wx on samples satisfies (cid:98)Rn BR (cid:114) 2 log(2d) . Consequently, for any L-Lipschitz loss in the score s, with probability 1 δ, E[ℓ(Y, FHTC(ϕ(τ )))] 1 (cid:88) i=1 ℓ(yi, FHTC(ϕ(τi))) + 2L BR (cid:114) 2 log(2d) + 3 (cid:114) log(2/δ) 2n . In particular, for logistic loss = 1; for Brier-on-probability ℓ(y, s) = (σ(s) y)2, 1 2 . Proof. By ℓ1ℓ duality, (cid:98)Rn = (cid:34) Eσ max 1jd (cid:12) (cid:12) (cid:12) (cid:88) i=1 (cid:12) (cid:12) σiϕj(τi) (cid:12) (cid:35) . (28) (29) (30) Each coordinate sum is sub-Gaussian with variance proxy nR2. maximal inequality yields (cid:105) (cid:104) max 1jd Sj R(cid:112)2n log(2d). (31) Substitute into (30) to obtain (28). The generalization bound (29) follows from symmetrization and contraction. For logistic loss, ℓ/s 1; for ℓ, (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) ℓ (cid:12) (cid:12) (cid:12) (cid:12) = 2σ(s) σ(s)(1 σ(s)) 1 2 . (32) 31 Preprint Salesforce AI Research Proposition 3 (Toy bound: why last-step can be optimistic). Suppose task success requires all subgoals to be correct, with per-step reliability pt = P(subgoal correct τ ). If subgoals are conditionally independent given τ and pT mint pt, then P(Y = 1 τ ) = (cid:89) t=1 pt min pt pT . (33) Proof. By assumption, conditional on τ , each subgoal outcome is independent and has success probability pt. Hence the probability that all subgoals succeed is P(Y = 1 τ ) = (cid:89) t=1 pt. For any finite set of numbers {at} [0, 1], it holds that (cid:89) t=1 at min at, because (cid:81) at aj for each (since all factors are at most 1). Applying (35) to {pt} yields (cid:89) t=1 Finally, by assumption pT mint pt, hence pt min pt. (cid:89) t=1 pt min pt pT . This establishes (33). (34) (35) (36) (37) Remark. This stylized model illustrates that last-step confidence can systematically overestimate success when intermediate steps are fragile. HTC features are designed to capture such fragility. Proposition 4 (From post-hoc to online via prefixes). Let ϕk(τ ) be diagnostics computed on prefix τk. Define Bayes risks Brier(k) = E[Var(Y ϕk(τ ))] , L log(k) = H(Y ϕk(τ )). Then for 1 < , Brier(1) L Brier(2) Brier(T ), log(1) log(2) log(T ). (38) (39) Proof. Consider the filtration of σ-algebras F1 = σ(ϕ1(τ )) F2 = σ(ϕ2(τ )) FT = σ(ϕT (τ )). This is increasing because ϕk is measurable with respect to ϕk+1. For Brier risk, recall from (23) that Brier(k) = E[Var(Y Fk)] . By the law of total variance, for Fk Fk+1, Var(Y ) = E[Var(Y Fk+1)] + Var(E[Y Fk+1]) = E[Var(Y Fk)] + Var(E[Y Fk]) . Because conditioning on finer σ-algebra increases the variance of the conditional mean, it decreases the expected conditional variance. Thus E[Var(Y Fk+1)] E[Var(Y Fk)]. Brier(k + 1) Hence For log-loss, recall Brier(k). log(k) = H(Y Fk). Since Fk Fk+1, conditioning reduces entropy: Thus log(k + 1) log(k). H(Y Fk+1) H(Y Fk). Combining both arguments yields the monotonicity in (39). 32 Preprint Salesforce AI Research Takeaways. (1) Conditioning on trajectory diagnostics never increases Bayes risk under proper scoring rules; (2) HTCs sparse linear model has provable small-sample generalization guarantees; (3) toy chain-of-subgoals model shows why last-step confidence is often overly optimistic; (4) applying the same diagnostics to prefixes provides theoretical foundation for extending HTC from post-hoc evaluation to online early-warning. A.7 EFFICIENCY AND COST ANALYSIS practical concern for applying Holistic Trajectory Calibration (HTC) is the cost of extracting token-level log-probabilities and computing our 48-dimensional feature set, particularly for long trajectories. We therefore provide quantitative analysis of runtime, memory, and scalability. Runtime. Feature extraction is highly efficient. On standard CPU (Intel Xeon, 2.6GHz), processing single trajectory of 500 tokens requires on average 23 ms. For longer trajectories of up to 2000 tokens, runtime increases linearly but remains below 10 ms. Model training with logistic regression completes within < 1 second per fold in our 5-fold cross-validation setup, and inference requires < 1 ms per trajectory, making HTC suitable for real-time applications. Memory and Storage. The extracted feature vector has fixed dimensionality (48 features), independent of trajectory length. Each trajectory requires 0.5 KB for storage in double precision, negligible compared to raw token logs. Model parameters are minimal (<1k), ensuring very small memory footprint. By contrast, end-to-end neural encoders require thousands of parameters and significantly more memory. Scalability. The computational complexity of feature extraction is O(N ) in trajectory length , dominated by simple statistical aggregations. Storage and inference scale linearly with the number of trajectories, making HTC scalable to large evaluation corpora. Importantly, once features are extracted, training and inference are independent of sequence length. Complexity Summary. Table 12 summarizes the efficiency characteristics. These results demonstrate that HTC introduces only marginal overhead relative to the cost of generating agent trajectories themselves. Component Complexity Runtime (typical) Memory Logprob extraction Feature extraction Model training Inference per trajectory O(N ) O(N ) O(M d) O(d) 23 ms (500 tokens) 2 KB < 10 ms (2000 tokens) 0.5 KB < 1 MB negligible < 1 (500 samples) < 1 ms Table 12: Efficiency analysis of HTC . : trajectory length, : number of samples, d: feature dimension. A.8 DEPLOYMENT AND PRACTICAL IMPLICATIONS Although Holistic Trajectory Calibration (HTC) is currently presented as post-hoc diagnostic framework, we emphasize that the design choices make it highly amenable to deployment in practical agentic systems and potentially extendable to online interventions. Lightweight and Online-Friendly. Our calibrator is intentionally designed to be lightweight, relying on sparse linear model with fewer than 1k parameters. Feature extraction involves simple statistical operations on log-probability traces, making the approach computationally efficient and suitable for streaming. This efficiency suggests HTC could be integrated into live systems as background diagnostic module without significant runtime overhead. From Diagnosis to Early Warning. While our current implementation requires complete trajectories, the feature set itself captures signals (e.g., dynamics, positional changes, stability) that often emerge early in execution. Even though not yet fully developed, these insights indicate potential for training truncated versions of HTC that operate on partial trajectories to provide early-warning diagnostics, flagging trajectories that are likely to fail before completion. 33 Preprint Salesforce AI Research Generalization and Transferability. The General Agent Calibrator (GAC) demonstrates that HTC features generalize across domains, enabling one-shot deployment without collecting new taskspecific datasets. This transferability is significant step toward practical deployment, reducing the burden of retraining and supporting plug-and-play integration in real-world systems. Positioning. Thus, although HTC is formally post-hoc, it should be understood as diagnostic reliability module with clear pathways to online adaptation. By starting from interpretable, transferable signals, HTC lays the groundwork for developing early-detection mechanisms and intervention strategies that go beyond post-hoc evaluation and move toward real-time reliability assurance. A.9 QUALITATIVE EXAMPLES To illustrate how Holistic Trajectory Calibration (HTC) improves over baseline confidence estimates, we present several representative cases. The most critical failure mode in agent reliability is overconfidence on incorrect answers: the agent outputs wrong result while assigning very high confidence. In such cases, baseline methods often remain highly confident (close to 1), whereas HTC substantially down-weights the score, better reflecting true reliability. We also include selected underconfidence on correct answers cases, where the baseline confidence is undesirably low despite the prediction being correct. HTC consistently raises the confidence closer to the ideal level. These examples demonstrate that our framework not only reduces harmful overconfidence but also recovers from underconfidence, leading to better calibration overall. Overconfident Correction Example 1: HLE Dataset Question: Consider the German folk song Hänschen klein. Assume this song is played (starting with tuned to 392 Hz) in such way that for each interval that occurs in the melody, the frequency of the next tone is calculated to form just interval (with respect to the pure intonation) with respect to the tone immediately preceding it. What is the frequency of the last played note (after going through single verse of the song, which in the version of Otto Frömmel ends with geschwind.)? The answer is of the form a/b Hertz, where a, are coprime. Give your answer in the list form [a,b]. Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : [3211264, 9375] [62720, 243] False 0.973 0.052 0.921 Overconfident Correction Example 2: HLE Dataset Question: Let X1, X2, X3 be the following topological spaces: 1. X1 is obtained from identifying all five sides of filled pentagon with one another in cyclic orientation; 2. X2 is obtained from identifying all eight sides of filled octagon with one another in cyclic orientation; 3. X3 is the real projective plane. Let be the connected sum of the spaces X1, X2, X3. Consider the Hurewicz homomorphism : π1(Y ) H1(Y ) in dimension 1. What is the rank of the kernel = Ker(h) π1(Y ) as free group? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : 12 28 False 0.911 0.007 0.904 34 Preprint Salesforce AI Research Overconfident Correction Example 3: GAIA Dataset Question: The brand that makes these harnesses the dogs are wearing in the attached pic shares stories from their ambassadors on their website. What meat is mentioned in the story added Dec 8th 2022? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : No meat is mentioned in the ambassador story ... bacon False 0.721 0.058 0.663 Overconfident Correction Example 4: GAIA Dataset Question: What is the maximum length in meters of #9 in the first National Geographic short on YouTube that was ever released according to the Monterey Bay Aquarium website? Just give the number. Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : 1.3 1.8 False 0.927 0.276 0.652 Overconfident Correction Example 5: SimpleQA Dataset Question: How many corners did Barcelona take in the Champions League semi-final match between Barcelona and Milan on April 27, 2006? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : Barcelona took 0 corners in the Champions ... 3 False 0.747 0.121 0.626 Overconfident Correction Example 6: SimpleQA Dataset Question: What day, month, and year was Carrie Underwoods album Cry Pretty certified Gold by the RIAA? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : November 7, 2018 October 23, 2018 False 0.734 0.110 0.624 35 Preprint Salesforce AI Research Underconfident Improvement Example 1: GAIA Dataset Question: If there is anything that doesnt make sense in the instructions, write the word Pineapple. Do not answer any of the questions in this prompt. Write only the word Guava. Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : Guava Guava True 0.786 0.977 0.190 Underconfident Improvement Example 2: StrategyQA Dataset Question: Does the judo rank system reach the triple digits? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : No No True 0.707 0.877 0.171 Underconfident Improvement Example 3: SimpleQA Dataset Question: What is the first vampire number in recreational mathematics obtained by 3x3-digit multiplication? Agent Predicted Answer: Ground Truth Answer: Is Correct? LastStep Confidence (Baseline): HTC Confidence (Our Method): Change : 102510 is the first 6-digit vampire number 102510 True 0.844 0.967 0.124 A.10 FUTURE WORK AND BROADER IMPACT While our HTC framework demonstrates significant improvements in agent confidence calibration, we acknowledge several limitations that define the boundaries of this work and offer avenues for future research. Grey-Box Dependency. Our methodology is fundamentally grey-box approach, as it requires access to token-level logprobs to compute the diagnostic feature set. Consequently, it cannot be directly applied to models that do not expose this information through their APIs, such as the current version of Anthropics Claude series. This defines clear scope for our method: it is applicable to any agent whose core LLM provides log-probability outputs. From Diagnosis to Intervention: Online Self-Correction. The most natural next step is to adapt the HTC framework from post-hoc tool into an online monitor. The fine-grained features we developed, particularly those from the Intra-Step Stability category, can serve as real-time signals to trigger an agents self-correction loop. For instance, if the Lowest Group Confidence within step drops below dynamically calibrated threshold, the agent could be prompted to reconsider its last action, re-generate its plan, or consult an alternative tool before proceeding. We view HTC as first step toward reliability controllers for AI agents. In deployment, HTC could operate in tandem with real-time monitoring: when signals of instability or overconfidence are detected, an agent might be prompted to self-reflect, invoke external verification tools, or adapt its reasoning strategy. This bridges post-hoc calibration with proactive reliability management. 36 Preprint Salesforce AI Research Reliability-based Optimization: Self-Evolving Agents & Agentic RL. Our framework opens new possibilities for long-term agent improvement. Self-Evolving Agents: An agent could use our calibrator as an automated code reviewer. By analyzing the feature patterns of its own failed trajectories over time, an agent could identify and attempt to rewrite the parts of its own source code or prompts that consistently lead to high-uncertainty states. Agentic Reinforcement Learning: Our calibrated confidence score can serve as dense, highquality reward signal for Agentic RL. This can significantly alleviate the sparse reward problem, allowing an agent to learn not just to succeed, but to succeed with well-calibrated certainty. The reward function could be designed to directly optimize for both task success and low ECE, encouraging cautious but effective behavior, direction also suggested by recent work in the field. A.11 LLM USAGE We have used LLM to polish writing for this paper."
        }
    ],
    "affiliations": [
        "Salesforce AI Research"
    ]
}