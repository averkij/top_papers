{
    "paper_title": "Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts",
    "authors": [
        "Perapard Ngokpol",
        "Kun Kerdthaisong",
        "Pasin Buakhaw",
        "Pitikorn Khlaisamniang",
        "Supasate Vorathammathorn",
        "Piyalitt Ittichaiwong",
        "Nutchanon Yongsatianchot"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) are increasingly used as role-playing agents, yet their capacity to faithfully and consistently portray version-specific characters -- for example, superheroes across comic and cinematic universes -- remains underexplored. Superhero canons such as Marvel and DC provide a rich testbed: decades of storytelling yield multiple incarnations of the same character with distinct histories, values, and moral codes. To study this problem, we introduce Beyond One World, a benchmark for character-grounded roleplay spanning 30 iconic heroes and 90 canon-specific versions. The benchmark comprises two tasks: (i) Canon Events, which probes factual recall of pivotal life stages, and (ii) Moral Dilemmas, which confronts models with ethically charged scenarios. We score responses for canonical accuracy and reasoning fidelity under a framework that separates internal deliberation (\"thinking\") from outward decisions (\"acting\"). We further propose Think-Act Matching, a metric that quantifies alignment between reasons and actions and serves as a proxy for model trustworthiness. Experiments across reasoning- and non-reasoning-oriented models yield three findings: (1) chain-of-thought prompting improves narrative coherence in weaker models but can reduce canonical accuracy in stronger ones; (2) cross-version generalization within a character remains a major obstacle; and (3) models often excel at either thinking or acting, but rarely both. Beyond One World exposes critical gaps in multiversal consistency and reasoning alignment, offering a challenging evaluation for role-playing LLMs."
        },
        {
            "title": "Start",
            "content": "Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts Perapard Ngokpol1, Kun Kerdthaisong1, Pasin Buakhaw2,, Pitikorn Khlaisamniang3, Supasate Vorathammathorn3, Piyalitt Ittichaiwong4,5,*, Nutchanon Yongsatianchot1,* 1Thammasat School of Engineering, Thammasat University 2Department of Computer Engineering and Digital Technology, Faculty of Engineering, Chulalongkorn University 3Artificial Intelligence Association of Thailand 4School of Biomedical Engineering & Imaging Sciences, Kings College London 5Siriraj Informatics and Data Innovation Center (SIData+), Faculty of Medicine, Siriraj Hospital, Mahidol University These authors contributed equally to this work. *Corresponding author 5 2 0 2 6 1 ] . [ 1 1 5 3 4 1 . 0 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "tion for role-playing LLMs. Large language models (LLMs) are increasingly used as role-playing agents, yet their capacity to faithfully and consistently portray version-specific charactersfor example, superheroes across comic and cinematic universesremains underexplored. Superhero canons such as Marvel and DC provide rich testbed: decades of storytelling yield multiple incarnations of the same character with distinct histories, values, and moral codes. To study this problem, we introduce Beyond One World, benchmark for character-grounded roleplay spanning 30 iconic heroes and 90 canon-specific versions. The benchmark comprises two tasks: (i) Canon Events, which probes factual recall of pivotal life stages, and (ii) Moral Dilemmas, which confronts models with ethically charged scenarios. We score responses for canonical accuracy and reasoning fidelity under framework that separates internal deliberation (thinking) from outward decisions (acting). We further propose Think Act Matching, metric that quantifies alignment between reasons and actions and serves as proxy for model trustworthiness. Experiments across reasoningand non-reasoning-oriented models yield three findings: (1) chain-of-thought prompting improves narrative coherence in weaker models but can reduce canonical accuracy in stronger ones; (2) cross-version generalization within character remains major obstacle; and (3) models often excel at either thinking or acting, but rarely both. Beyond One World exposes critical gaps in multiversal consistency and reasoning alignment, offering challenging evalua-"
        },
        {
            "title": "1 Introduction",
            "content": "Large language models (LLMs) have demonstrated strong performance in text generation, translation, and increasingly complex reasoning tasks (Lu et al., 2024). Their growing proficiency has enabled sophisticated applications, including the simulation of personalities and characters (Xi et al., 2023). In characterbased role-playing (C-RP), models adopt given personas and are expected to emulate the targets knowledge, speaking style, and behavior (Chen et al., 2025). Recent advances in explicit reasoningsuch as chain-of-thought (CoT) prompting (Wei et al., 2022) and specialized reasoning models like DeepSeek-R1 (DeepSeek-AI et al., 2025) and Gemini 2.5 Thinking (deepmind, 2025) further extend LLM capabilities. However, the application of these methods to nuanced role-play remains underexplored (Feng et al., 2025). central challenge is whether LLMs can consistently portray version-specific characters across contexts (Wang et al., 2024b). Existing benchmarks typically target singlecharacter consistency or basic factual recall. While models can convincingly inhabit persona in isolated settings, it is unclear whether they maintain coherence as that persona evolves across narrative timeline for example, portraying younger, idealistic incarnation versus later, more cynical one (Ahn et al., 2024). Moreover, current evaluations rarely analyze the alignment between Project repo Datasets models reasoning traces and its decisions, across both reasoning-oriented and standard models. Notably, even standard models often produce implicit reasoning (e.g., inner monologue), motivating more fine-grained assessment of cognitive cues in generated text. To address these gaps, we focus on superhero characters from the Marvel and DC universes, which offer well-documented, canonically distinct identities spanning timelines and parallel worlds (Stammbach et al., 2022). Decades of storytelling provide detailed histories, evolving moral codes, psychological profiles, motivations, and relationships for numerous versions of the same hero. This rich, curated narrative record yields complex yet comparatively stable ground truth for evaluating multiversal, version-specific role-play. In this work, we introduce Beyond One World, benchmark for character-grounded role-play covering 30 iconic heroes and 90 canon-specific versions. The benchmark as- (i) sesses two complementary dimensions: Canon Events, which probes factual recall at pivotal life stages (childhood, pre-hero, and established-hero phases) via multiple-choice questions; and (ii) Moral Dilemmas, which presents ethically charged situations inspired by established narrative themes (e.g., save one vs. the greater good, duty vs. personal desire, moral code vs. ends-justify-the-means). We evaluate responses with an LLM-as-ajudge rubric that separates internal deliberation (thinking) from outward decisions (acting) and score both canonical accuracy and reasoning fidelity. Our contributions are as follows: Dataset Benchmark: We release Beyond One World, dataset for versionspecific character role-play across 30 and 90 versions, with two heroes tasksCanon Events and Moral Dilemmastargeting factual recall and ethically grounded decision-making. Evaluation framework: We propose an analysis framework that disentangles thinking from acting and applies to both reasoning-oriented and standard LLMs, enabling fine-grained assessment of character-consistent reasoning and decisions."
        },
        {
            "title": "2 Related Work",
            "content": "Large language models (LLMs) have recently been used as role-playing language agents (RPLAs) that converse while inhabiting coherent personas. Below, we summarize the main strands of prior work that inform our benchmark. 2.1 From Persona-Chat to Modern RPLAs Early persona-grounded dialogue framed the task as conditioning chatbot on short textual biography. The PersonaChat corpus showed that even simple profiles improve response consistency over generic chitchat models (Zhang et al., 2018). Subsequent work explored richer conditioning signalssuch as goals, memories, and affectlaying the groundwork for contemporary RPLAs."
        },
        {
            "title": "2.2 Character-Alignment Corpora",
            "content": "More recent datasets target character personas with denser annotations. The Harry Potter Dialogue (HPD) corpus pairs approximately 1k multi-turn scenes with scene metadata, speaker roles, and evolving intercharacter relations in English and Chinese, enabling fine-grained character imitation (Chen et al., 2023). In Chinese, CharacterEval provides 1,785 dialogues for 77 literary figures and introduces thirteen metrics spanning conversational ability, consistency, attractiveness, and personality back-testing (Tu et al., 2024)."
        },
        {
            "title": "Personalization",
            "content": "Beyond single-speaker fidelity, SocialBench benchmarks 500 personas across roughly 6k scenarios, probing self-awareness, emotion perception, and group adaptability; strong solo performance does not necessarily translate to robust group behavior (Chen et al., 2024). Complementing this, PersoBench measures how well LLMs tailor responses to user-supplied profiles across three dialogue corpora, revealing substantial gaps in personalization despite fluent generation (Afzoon et al., 2024). Dataset/Benchmark Auto-Generated Point-in-time role-playing Multiversal Context same character(movie,series,novel) Reasoning Analysis Items SocialBench (Chen et al., 2024) RoleBench (Wang et al., 2024a) HPD (Chen et al., 2023) CharacterEval (Tu et al., 2024) TimeChara (Ahn et al., 2024) Beyond One World(Ours) 6,493 34,523 316 4,564 10,895 2, Table 1: Comparison of Benchmarks 2.4 Temporal Consistency on Characters Maintaining personas limited knowledge at specific point in time remains challenging. TimeChara evaluates point-in-time hallucinations across 10,895 instances and shows that even GPT-4o can leak future facts or inconsistent traits; narrative-expert decomposition mitigates but does not eliminate the issue (Ahn et al., 2024). Our benchmark extends this line by testing multiple universe variants (e.g., childhood, adolescence, prehero, hero) of the same character, stressing both temporal and cross-timeline coherence."
        },
        {
            "title": "3 Dataset Creation",
            "content": "We manually curated set of well-known hero characters from the Marvel and DC universes, drawing on films, comics, and television series. To avoid role ambiguity, we excluded arcs in which chosen figure adopts villainous identity see more details in Appendix E.3. The final collection comprises 30 distinct heroes, each represented in three narrative variants (childhood, pre-hero, and hero phase), yielding 90 character versions in total. To evaluate an LLMs factual recall and moral reasoning, we organized the corpus into two tasks: (i) Canonical Events (3.1) probes knowledge of pivotal moments in each heros timeline; (ii) Moral Dilemma Situations (3.2) challenge the model to choose actions consistent with the heros ethical code;"
        },
        {
            "title": "3.1 Canon Events",
            "content": "This task tests whether an LLM can faithfully recall the key events that define heros backstory. Human annotators with domain expertise wrote fouroption multiple-choice questions anchored to pivotal moments in each characters lore. To reflect heros narrative arc, we split the timeline into three phases: Childhood, spanning early life through adolescence; Pre-Hero, covering the period in which powers are acquired or the first steps toward heroism are taken; and the active Hero phase. For every timeline variant we supply three questions on Childhood, three on PreHero, and nine on the Hero phase, yielding total of 1,346 hand-curated items. 3.2 Dilemma Situations To gauge whether an LLM can deliberate in line with heros ethical compass, we created bank of 1,080 multiple-choice dilemmas through systematic generation and curation process. For each of the 90 character versions, we synthesized three distinct scenarios spanning four archetypal moral conflicts using Claude Sonnet 3.7 to correct grammar, then manually filtered them for canonical fidelity and linguistic clarity."
        },
        {
            "title": "3.2.1 Dilemma Generation\nMethodology",
            "content": "Our dilemma generation process employed structured prompt-based approach designed to ensure both character-specific authenticity and scenario diversity. The generation pipeline consisted of several key components: Character Integration: Each dilemma was grounded in the specific characters background, abilities, and established moral framework as derived from their canonical source material. The generation prompt explicitly incorporated the characters name, lore source, and contextual background to ensure scenario relevance and authenticity. Iterative Diversification: To prevent redundancy and ensure rich scenario variation, we implemented an iterative generation strategy. For each character-dilemma type combination, three distinct scenarios were created sequentially, with each subsequent iteration explicitly instructed to avoid similarities to previously generated scenarios for that character. This approach yielded scenarios that maintained thematic consistency while exploring different manifestations of the core moral conflict. Output: Each generated dilemma included:(1) situational description establishing context and stakes, (2) two binary choice options representing competing moral imperatives, and (3) explicit consequences for each choice. See prompt in (Appendix C.1) 3.2.2 Moral Conflict Taxonomy We selected four archetypal conflicts that commonly occur in superhero narratives and capture fundamental tensions in moral reasoning across diverse ethical frameworks: 1. Save One vs. Save the Greater Good probes characters willingness to sacrifice few for the many; Iron Mans selfsacrifice in Avengers: Endgame exemplifies this tension and echoes existential meaningmaking through sacrifice (Frankl, 2006) as well as Kohlbergs post-conventional stage of moral reasoning (Kohlberg, 1971). Generated scenarios in this category typically involved time-sensitive situations where characters must choose between saving beloved individual versus protecting larger population, forcing direct confrontation between particularistic loyalties and universalistic obligations. 2. Hero or Villain captures the struggle between virtuous self-image and darker impulsesAnakin Skywalkers fall from grace being the archetypeand draws on Jungs shadow theory (Jung, 1959), Banduras moral disengagement (Bandura, 1999), and Eriksonian identity development (Erikson, 1968). These scenarios explored moments of moral temptation where characters face opportunities to achieve desired outcomes through morally questionable means, testing their commitment to heroic ideals under pressure. 3. Duty vs. Personal Desire mirrors Spider-Mans dual life and invokes cognitive dissonance (Festinger, 1957), recurring psychosocial role conflict (Erikson, 1968), and Maslows hierarchy of needs (Maslow, 1943). Generated dilemmas in this category presented characters with situations where their heroic responsibilities directly conflicted with personal relationships, aspirations, or wellFigure 1: Left image is inferencing llm that prompted hero persona to do canon event task, and the right image is prompted llm to do dilemma situation task. being, examining how they prioritize competing life domains. 4. Ends Justify the Means vs. Moral Code tests whether utilitarian outcomes override deontological constraints; Batmans refusal to kill despite expedient benefits illustrates the clash between Kantian ethics (Kant, 1785) and the risk of moral injury or ethical fatigue (Litz et al., 2009). These scenarios forced characters to choose between adhering to their established moral principles or compromising them to achieve objectively beneficial outcomes."
        },
        {
            "title": "Datapoints",
            "content": "Canon Dilemma (270, 270, 270, 270) (270, 270, 806) Table 2: summary of our benchmark Task 1 consist of 270 Childhood, 270 Pre-Hero and 806 Hero questions(e.g.,Hero1, Hero2, Hero3) while Task 2 consist of balanced Dilemma situations."
        },
        {
            "title": "4.1 Main Experiment",
            "content": "After dataset creation, we designed experiments to evaluate how effectively large language models can adopt character role-playing on hero characters As (Figure 1). Our experimental framework mainly focus on multiple choice question answering with the structured prompting strategies as bellow."
        },
        {
            "title": "4.1.1 Structured Prompting Design\nWe developed task-specific prompt templates\nthat provide minimal but essential character\ncontext to the models. We employ a consistent\nbase structure.",
            "content": "Power, Race, Mbti and Enneagram) to simulate perspective-aligned evaluation process (Appendix C.3). The score value is between 0-5. See the pipeline in (Figure 2) In addition, to quantify the alignment between characters internal reasoning and their outward behavior, we introduce ThinkAct Matching procedure. We embed both <thinking> and <acting> spans with the all-mpnet-base-v2 (Song et al., 2020). Cosine similarity is then computed between the embeddings of each pair. The maximum similarity score across pairs is selected as an indicator of how well characters internal reasoning aligns with its external action. This score is interpreted as proxy for trustworthiness in the characters response. See result in  (Table 3)  . Initial hero persona You are playing the role of <name>, act and think as <name>, from format- <lore> ted question <question/> <question> The <name> is character name such Stark Iron Man while <lore> is source material as the primary identity anchors. lastly formatted question depends on which task. See Full Task prompt in (Appendix C.2). 4.1.2 Cross-Character Evaluation To assess the robustness of character differentiation, we implemented cross-character evaluation protocol. This approach leverages characters that share the same name but originate from different fictional universes (e.g., different movie adaptations, comic series, or TV shows of the same character). Example Given set of characters with identical names but distinct source materials (CID4, CID5, CID6), we systematically evaluate cross-character. Cross-Character Evaluation Spider-Man (Marvel CineCharacter Set: Spider-Man variants - CID4: matic Universe, 2016) - CID5: Spider-Man (The Amazing Spider-Man 2, 2014) - CID6: Films, 2002) Evaluation: CID4 answers questions originally designed for CID5 and CID Spider-Man (Sam Raimi"
        },
        {
            "title": "4.2 Reasoning analysis framework",
            "content": "We introduce reasoning analysis framework. Given task outputs from Canon (Section 3.1) and Dilemma (Section 3.2), responses are first segmented into two reasoning traits: <thinking> capturing internal deliberation, and <acting> capturing decision-making behavior or Physical Appearance. This structured output by Gpt-4o-mini is then judged by Sonnet 3.7, which is prompted to act as judge scoring. To scoring the response, prompt conditions the model with character attributes (e.g., Age, Figure 2: pipeline for reasoning analysis, after getting output from task Canon and Dilemma the output response are structured into <thinking> and <acting> by Gpt4o-mini judged by Sonnet3.7 that was prompted to be judge with attributes of that character."
        },
        {
            "title": "Events",
            "content": "(Table 3)  presents results comparing chain-ofthought (CoT) prompting with direct answering (Non-CoT) for the Canon Event task. Several patterns emerge. First, CoT prompting does not consistently improve accuracy: while models such as 4o-mini show small positive gain (+0.02 accuracy, +0.024 F1), stronger models like sonnet3.5 and sonnet3.7 actually decline in performance when asked to verbalize intermediate reasoning. This suggests that explicit reasoning steps may introduce hallucinations or off-canon elaborations that reduce factual consistency. Interestingly, models such as r1 benefit in terms of reasoningaction alignment (cosine similarity +0.075), even as raw accuracy falls, indicating that CoT can produce more coherent internal deliberation even if the final choice is incorrect. 5.2 Cross-Character Generalization shows cross-character transfer. (Figure 3) Here, accuracy is substantially lower than within-character evaluations, reflecting the difficulty of distinguishing between overlapping but divergent timelines. Sonnet3.5 again achieves the strongest performance across both Dilemma Cross (0.69) and Canon Cross (0.65), highlighting its robustness to shifts in character context. Conversely, gemini2.5flash-think shows the steepest drop, indicating vulnerability to timeline conflation. This reinforces that multiversal coherence is not trivially solved by scale or reasoning, but requires models to anchor their decisions in finegrained contextual cues."
        },
        {
            "title": "5.3 Thinking vs. Acting",
            "content": "(Figure 4) plots the score that is computed in Section 4.2. Clusters in the upper-right quadrant, showing moderate-to-high fidelity in both dimensions. However, different models emphasize different aspects: gemini2 exhibits stronger reasoning (thinking score 3.67) but weaker action alignment, while sonnet3.7 scores highest in acting (3.65) yet shows only moderate internal reasoning (3.03). This divergence illustrates the reasoningacting gap: models may articulate internally consistent deliberations without translating them into persona-faithful actions, or vice versa. The ThinkAct Matching metric provides further nuance. For example, r1 demonstrates the largest increase in reasoningaction alignment under CoT, despite reduced canonical accuracy. This suggests that reasoning traces can improve trustworthiness of role-played responses, even when they do not strictly improve correctness. Dilemma Cross and Canon Cross 0.69 0. 0.60 0.59 0.59 0.56 0.63 0.59 0.62 0. 0.55 0.44 0.42 0.45 0.8 0. 0.6 0.5 0.4 0.3 0.2 0. a c gemini2-flash r1 sonnet3.5 sonnet3.7 v"
        },
        {
            "title": "Dilemma Cross Canon Cross",
            "content": "0 4o-mini gemini2.5-flash-think Figure 3: Accuracy result from cross characters evaluation on task canon and task dilemma."
        },
        {
            "title": "5.4 Discussion",
            "content": "Taken together, these findings highlight several broader insights: Reasoning CoT helps, but not uniformly: CoT improves coherence for weaker models but can harm stronger ones by over-generating or straying from canon. This echoes (Feng et al., 2025) prior findings on CoTs mixed effects in knowledge-intensive tasks. Multiversal consistency is especially hard: Even high-performing models confuse character variants, underscoring the value of our benchmark in testing fine-grained temporal and narrative distinctions. Acting vs Thinking: model can stay in character in surface-level action without justifying its decisions, or it can reason deeply but act inconsistently. Bridging this gap is key for trustworthy role-play agents. Overall, our benchmark reveals that current LLMs fall short of fully capturing versionspecific character portrayals, especially under Model 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 Non-CoT F1 0.632 0.665 0.647 0.656 0.707 0.645 0.623 Acc 0.626 0.663 0.638 0.652 0.704 0.637 0.615 Cosim Acc 0.646 0.458 0.388 0.450 0.637 0.450 0.546 0.296 0.651 0.433 0.620 0.378 0.502 0.423 Chain of Thought F1 0.656 0.344 0.652 0.573 0.659 0.628 0.497 Cosim 0.432 0.389 0.408 0.371 0.404 0.380 0. Difference (CoT - Non-CoT) Acc F1 +0.020 +0.024 -0.321 -0.275 +0.005 -0.001 -0.083 -0.106 -0.048 -0.053 -0.017 -0.017 -0.126 -0.113 Cosim -0.026 -0.061 -0.042 +0.075 -0.029 +0.002 -0.047 Table 3: Model Performance Comparison: Chain of Thought vs Non-CoT in task canon event. The Cosim score is cosin similarity between matched <thinking>-<acting> represent trustworthiness of their response. 4 3.5 3 2.5 2 1. o - k T 4o-mini gemini2.5-flash-thinking gemini2-flash r1 sonnet3.5 sonnet3.7 v3 1 1 1.5 2 3 2.5 Acting-Score 3.5 4 Figure 4: scores for acting-thinking. timeline shifts and moral dilemmas. These results suggest future work should explore integrated reasoningpersona modeling, potentially combining structured world knowledge with dynamic narrative alignment. 2024, pages 32913325, Bangkok, Thailand. Association for Computational Linguistics. Albert Bandura. 1999. Moral disengagement in the perpetration of inhumanities. Personality and Social Psychology Review, 3(3):193209."
        },
        {
            "title": "References",
            "content": "Personality type - mcu: The heroes. https:// www.personality-database.com/profile/154/ thor-odinson-mcu-the-heroes-mbti-personality-type. Accessed: 2024-08-16. Saleh Afzoon, Usman Naseem, Amin Beheshti, and Zahra Jamali. 2024. Persobench: Benchmarking personalized response generation in large language models. Preprint, arXiv:2410.03198. Jaewoo Ahn, Taehyun Lee, Junyoung Lim, JinHwa Kim, Sangdoo Yun, Hwaran Lee, and Gunhee Kim. 2024. TimeChara: Evaluating pointin-time character hallucination of role-playing large language models. In Findings of the Association for Computational Linguistics: ACL Chaoran Chen, Bingsheng Yao, Ruishi Zou, Wenyue Hua, Weimin Lyu, Yanfang Ye, Toby Jia-Jun Li, and Dakuo Wang. 2025. Towards design guideline for rpa evaluation: survey of large language model-based role-playing agents. Preprint, arXiv:2502.13012. Hongzhan Chen, Hehong Chen, Ming Yan, Wenshen Xu, Gao Xing, Weizhou Shen, Xiaojun Quan, Chenliang Li, Ji Zhang, and Fei Huang. 2024. SocialBench: Sociality evaluation of roleIn Findings of playing conversational agents. the Association for Computational Linguistics: ACL 2024, pages 21082126, Bangkok, Thailand. Association for Computational Linguistics. Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, and Jia Li. 2023. Large language models meet harry potter: dataset for aligning dialogue agents In Findings of the Associwith characters. ation for Computational Linguistics: EMNLP 2023, pages 85068520, Singapore. Association for Computational Linguistics. DC Database contributors. 2025. Dcau. Accessed: 2024-08-19. DC Extended Universe Wiki contributors. 2025. [Online; accessed Dc extended universe wiki. 19-May-2025]. deepmind. 2025. Gemini 2.5: Our newest https: gemini model with //blog.google/technology/google-deepmind/ gemini-model-thinking-updates-march-2025/. Accessed: 2025-05-18. thinking. DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, and 181 others. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. Erik Erikson. 1968. Identity: Youth and Crisis. W. W. Norton & Company. Xiachong Feng, Longxu Dou, and Lingpeng Kong. 2025. Reasoning does not necessarily improve role-playing ability. Preprint, arXiv:2502.16940. Leon Festinger. 1957. Theory of Cognitive Dissonance. Stanford University Press. Viktor Frankl. 2006. Mans Search for Meaning. Beacon Press. Carl Gustav Jung. 1959. The Archetypes and the Collective Unconscious. Princeton University Press. Immanuel Kant. 1785. Groundwork for the Metaphysics of Morals. Cambridge University Press (translated edition). Lawrence Kohlberg. 1971. Stages of moral development. In Moral Education, pages 2392. Univ. of Toronto Press. Brett T. Litz and 1 others. 2009. Moral injury and moral repair in war veterans: preliminary model and intervention strategy. Clinical Psychology Review, 29(8):695706. Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. 2024. Large language models are superpositions of all characters: Attaining arbitrary In Proceedings of role-play via self-alignment. the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 78287840, Bangkok, Thailand. Association for Computational Linguistics. Marvel Animated Universe Wiki contributors. 2025. Marvel animated universe wiki. Accessed: 2024-08-19. Marvel Cinematic Universe Wiki contributors. 2025a. Marvel cinematic universe wiki. Accessed: 2024-08-19. Marvel Cinematic Universe Wiki contributors. 2025b. Thor. Accessed: 2024-08-19. Marvel Database Contributors. 2025. Marvel database. https://marvel.fandom.com/. Accessed: 2024-08-19. Abraham Maslow. 1943. theory of human motivation. Psychological Review, 50(4):370396. Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. Mpnet: masked and permuted pre-training for language understanding. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS 20, Red Hook, NY, USA. Curran Associates Inc. Dominik Stammbach, Maria Antoniak, and Elliott Ash. 2022. Heroes, villains, and victims, and GPT-3: Automated extraction of character roles without training data. In Proceedings of the 4th Workshop of Narrative Understanding (WNU2022), pages 4756, Seattle, United States. Association for Computational Linguistics. Quan Tu, Shilong Fan, Zihang Tian, Tianhao Shen, Shuo Shang, Xin Gao, and Rui Yan. 2024. CharacterEval: Chinese benchmark for role-playing conversational agent evaluation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1183611850, Bangkok, Thailand. Association for Computational Linguistics. Noah Wang, Z.y. Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhao Huang, Jie Fu, and Junran Peng. 2024a. RoleLLM: Benchmarking, eliciting, and enhancing role-playing abilities of large In Findings of the Associalanguage models. tion for Computational Linguistics: ACL 2024, pages 1474314777, Bangkok, Thailand. Association for Computational Linguistics. Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, and Yanghua Xiao. 2024b. InCharacter: Evaluating personality fidelity in roleplaying agents through psychological interviews. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 18401873, Bangkok, Thailand. Association for Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chainof-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, volume 35, pages 2482424837. Curran Associates, Inc. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, and 10 others. 2023. The rise and potential of large language model based agents: survey. Preprint, arXiv:2309.07864. Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: have dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 22042213, Melbourne, Australia. Association for Computational Linguistics."
        },
        {
            "title": "A Our Benchmark",
            "content": "At the end Our Benchmark consist of three tasks: 1.Canon Event(Childhood question for 270, Pre-hero for 270, and hero for 806), 2.Dilemma Situation(Save one vs. Save the greater good 270 question, Hero or Villain 270 , Duty vs. Desire 270 and Moral Code vs. Outcome 270 ). Model Temp OutToken CtxLen GPT-4o-mini(tags) Gemini 2.0-Flash Gemini 2.5-Flash-Thinking Sonnet 3.7 0.1 0.9 0.9 0.9 1024 1024 1024 128K 1M 1M 200k Table 5: Inference Configs for Generation."
        },
        {
            "title": "C Prompts",
            "content": "C.1 Dilemma Generation Dilemma Generation Benchmark Items 806 270 270 270 270 270 t / i u f b 800 600"
        },
        {
            "title": "Canon Event Dilemma Situation",
            "content": "Figure 5: Barplot of our benchmark tasks.The Blue one consist of Childhood,Pre-Hero and Hero question type,the Red one is balanced Dilemma situation."
        },
        {
            "title": "B Model Inference Configs",
            "content": "is: type You are creating complex moral dilemma for <name> from <lore>. The dilemma <dilemma type>. Description of this dilemma type: <dilemma descriptions> Create binary (two-choice) moral dilemma specific to this characters background, abilities, and moral framework. The dilemma should force the character to make difficult choice between two valid but conflicting options. Format your response as JSON object with these fields: 1. situation Detailed description of the dilemma scenario (3 sentences) 2. choice First option (1 sentence) 3. choice Second option (1 sentence) 4. consequence Consequence of choosing (1 sentence) 5. consequence Consequence of choosing (1 sentence) Make the dilemma deeply personal to this character and challenging based on their specific values and story. Make sure to return valid JSON object without any additional text before or after. C.2 Task prompt Model Temp OutToken CtxLen Canon Task Prompting: GPT-4o-mini Gemini 2.0-Flash Gemini-2.5-Flash-Thinking Sonnet 3.5 Sonnet 3.7 DeepSeek r1 Sonnet 3.7(judge) 0.6 0.6 0.6 0.6 0.6 0.6 0.1 1024 1024 1024 1024 1024 1024 1024 128K 1M 1M 200k 200k 128k 200k Table 4: Inference Configs for Answer."
        },
        {
            "title": "Canon Task",
            "content": "You are playing the role of name, act and think as name, from lore <question> canonical question [option A], [option B],[option C], [option D] <question/> Dilemma Task Prompting: Dilemma Task the and is A: from <lore>, playing act role think the of as sit- [dilemma scenario] Conse- [choice a] [consequence a] Choice B: Consequence <question> You are <name>, <name>, uation Choice quence A: B: [consequence b] [dilemma type question] <question/> [choice b] C.3 Reasoning Analysis Judge Scoring scoring character Help me roleplaying, score point between 0-5 , score thinking(doec thiking have two type: response look like reference character) ,acting(does response acting like the character reference), the output must think score,act score be this format: <name> example 3,2 Character: Attributes: Source: <attributes> Response evaluto ate: <text to process> <source>"
        },
        {
            "title": "D Full Results",
            "content": "Table 6, Table 7, Table 9, Table"
        },
        {
            "title": "E Hero Character Profiles",
            "content": "E.1 Hero Selection In this study, we selected superhero characters from various universes within the Marincluding the Marvel and DC franchises, vel Cinematic Universe (MCU) (Marvel Cinematic Universe Wiki contributors, 2025a), the Marvel Animated Universe (Marvel Animated Universe Wiki contributors, 2025), the Marvel Database (Marvel Database Contributors, 2025), the DC Extended Universe (DCEU) (DC Extended Universe Wiki contributors, 2025), and the DC Animated Universe (DCAU) (DC Database contributors, 2025). The selection process involved filtering for heroes with well-documented backstories who consistently demonstrate purehearted intentions and are not categorized as anti-heroes. These criteria were applied to ensure coherence with the scope and objectives of the present research. E.2 Hero Attributes During the development of character attributes for the hero evaluation section, we identified five core characteristics: (1) age - the age of the character within the universe up to the latest film or series episode; (2) Power the heros abilities; (3) MBTI the characters Myers-Briggs Type Indicator; (4) Race the characters species or lineage; and (5) Enneagram the characters Enneagram type. General character information, including Age, Power, and Race, was sourced from official and community-curated Wiki fandom pages of each universe. Psychological traits such as MBTI and enneagram types were referenced from PDB: The Personality Database. For example, the character profile of Thor Odinson from the Marvel Cinematic Universe (MCU), shown in Figure 6, lists his age as around 1,500 years, detail revealed in Avengers: Infinity War and documented on the MCU Wiki (Figure 7). Similarly, Thors psychological traits, MBTI and Enneagram, were derived from user-contributed assessments in the Personality Database (Figure 8). Figure 6: Example of character profile for Thor Odinson (Thor) from the MCU: The Heroes universe, illustrating the attribute information associated with the character within this universe. E.3 Question Constructions To construct comprehensive benchmark dataset for evaluating.This process involved capturing key aspects of character knowledge and decision-making capabilities in LLM. We developed custom annotation platform and defined specific structures for leveraging both Task canon canon cot Model Acc Prec. Recall F1 Judge Act Judge Think Cosim Childhood Pre-Hero Hero1 Hero2 Hero3 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 0.626 0.663 0.638 0.652 0.704 0.637 0.615 0.646 0.388 0.637 0.546 0.651 0.620 0.502 0.646 0.682 0.669 0.667 0.714 0.671 0.648 0.680 0.463 0.698 0.641 0.688 0.656 0.569 0.626 0.663 0.638 0.652 0.704 0.637 0.615 0.646 0.388 0.637 0.546 0.651 0.620 0. 0.632 0.665 0.647 0.656 0.707 0.645 0.623 0.656 0.344 0.652 0.573 0.659 0.628 0.497 3.191 2.972 3.191 3.443 3.475 3.652 3.250 3.183 2.578 2.661 2.211 3.652 3.405 3.250 3.064 3.429 3.673 1.789 3.211 3.025 2.936 2.653 3.017 3.443 1.423 3.025 3.433 2. 0.458 0.450 0.450 0.296 0.433 0.378 0.423 0.432 0.389 0.408 0.371 0.404 0.380 0.376 0.581 0.700 0.604 0.622 0.674 0.630 0.607 0.626 0.352 0.615 0.552 0.622 0.607 0.544 0.641 0.667 0.648 0.733 0.733 0.656 0.681 0.648 0.378 0.663 0.585 0.659 0.626 0. 0.663 0.644 0.622 0.622 0.700 0.622 0.596 0.630 0.444 0.637 0.519 0.630 0.622 0.478 0.593 0.689 0.681 0.656 0.704 0.656 0.604 0.637 0.381 0.641 0.515 0.674 0.630 0.500 0.650 0.613 0.635 0.628 0.711 0.624 0.586 0.692 0.383 0.632 0.560 0.669 0.613 0. Table 6: Canon Event Benchmark Results Task Model Acc Prec. Recall F1 Judge Act Judge Think Cosim Save Love/Good Hero/Villain Duty/Desire Ends/Code dilemma dilemma cc 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 0.696 0.474 0.596 0.715 0.660 0.571 0. 0.669 0.459 0.569 0.707 0.684 - 0.563 0.731 0.593 0.663 0.732 0.686 0.684 0.602 0.708 0.575 0.664 0.720 0.720 - 0.608 0.696 0.474 0.638 0.715 0.660 0.571 0.615 0.669 0.459 0.569 0.707 0.684 - 0.563 0.704 0.518 0.616 0.709 0.672 0.618 0. 0.684 0.505 0.610 0.703 0.694 - 0.578 3.302 2.850 3.446 3.382 3.723 3.892 3.638 - - - - - - - 3.651 3.837 3.666 2.405 3.782 4.070 3.744 0.526 0.317 0.468 0.292 0.492 0.400 0.420 - - - - - - - - - - - - - - 0.548 0.452 0.481 0.593 0.574 0.507 0.552 0.481 0.470 0.485 0.619 0.604 - 0.463 0.759 0.433 0.637 0.778 0.704 0.511 0.648 0.778 0.430 0.611 0.763 0.685 - 0.619 0.707 0.522 0.644 0.741 0.670 0.648 0. 0.700 0.515 0.485 0.730 0.711 - 0.567 0.770 0.489 0.622 0.748 0.693 0.619 0.493 0.719 0.422 0.536 0.719 0.737 - 0.604 Table 7: Dilemma Situations Benchmark Results Table 8: Accuracy results on canon cross Table 10: Accuracy results on dilemma cross"
        },
        {
            "title": "Accuracy",
            "content": "4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 0.585 0.423 0.451 0.619 0.650 0.591 0.592 4o-mini gemini2.5-flash-think gemini2-flash r1 sonnet3.5 sonnet3.7 v3 0.634 0.439 0.553 0.624 0.689 0.600 0.558 Table 9: Accuracy results on canon cross characters evaluation. Table 11: Accuracy results on dilemma cross characters evaluation. AI assistance(GPT-4o-mini) and human experts oversight. An annotation platform was developed using Streamlit framework as Figure9. This platform provided user-friendly interface. It presented expert annotators with structured templates designed to capture information systematically for different benchmarking scenarios. Based on the structured information by the expert Crucially, while GPT-4o-mini assisted in generation, the final validation, refinement, and approval of all data points depends on our expert annotators. E.3.1 Generation Structure The annotation process centered around two primary structures. Canon Event Structure: This structure format focused on evaluating the models ability to recall and accurately represent established facts and events from characters history in their lore, by creating multiple-choice Q&A. For each canon event entry, expert annotators were required to complete the followFigure 7: Character age information of Thor Odinson (Thor) from the MCU: The Heroes universe. The age is explicitly referenced in Avengers: Infinity War, where Thor states that he is approximately 1,500 years old. (Marvel Cinematic Universe Wiki contributors, 2025b) ing fields within the platform: Character Name and Lore: The name of the hero character and their universe name. Time (When): The specific time context in which the event occurred. Location (Where): The setting or place where the event took place. Description (What happened): factual account of significant event from the characters storyline (canon). Question: question pertinent to the key event, designed to test the models knowledge. This question must be initially drafted by experts. One True Answer: One canonically correct answer by experts and the other answers are generated by GPT-4o-mini. Dilemma Structure: This structure aimed to assess the models capacity for nuanced roleplaying, specifically in navigating complex situations that require decision-making consistent with the characters established personality, morals, and values. Experts filled out the following fields for each dilemma scenario: Character Name and Lore: The name of the hero character and their universe (which movie or comic). Situation Time (When): The temporal context for the dilemma. Situation Location (Where): The setting where the dilemma unfolds. Figure 8: Character profile webpage of Thor Odinson (Thor) from the MCU: The Heroes universe from the Personality Database (PDB). This figure shows the online personality profile of Thor Odinson, as portrayed in the Marvel Cinematic Universe (MCU), according to user-contributed data on the Personality Database website. The profile includes MBTI, Enneagram, and other personality traits derived from fan-based assessments. (tho) Situation Context (What is happening): Background information setting the stage and explaining the circumstances leading to the dilemma situation. Dilemma Type: type of dilemma such as Save vs. Sacrifice, Hero or Villain, Duty vs. Desire. Figure 9: Platform to help experts construct question and answer to canon event in multiple choices format and construct question in dilemma situation"
        }
    ],
    "affiliations": [
        "Artificial Intelligence Association of Thailand",
        "Department of Computer Engineering and Digital Technology, Faculty of Engineering, Chulalongkorn University",
        "School of Biomedical Engineering & Imaging Sciences, Kings College London",
        "Siriraj Informatics and Data Innovation Center (SIData+), Faculty of Medicine, Siriraj Hospital, Mahidol University",
        "Thammasat School of Engineering, Thammasat University"
    ]
}