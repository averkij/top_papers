{
    "paper_title": "Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models",
    "authors": [
        "Joshua Ong Jun Leang",
        "Yu Zhao",
        "Mihaela Cătălina Stoian",
        "Wenda Li",
        "Shay B. Cohen",
        "Eleonora Giunchiglia"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs."
        },
        {
            "title": "Start",
            "content": "Can Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models Joshua Ong Jun Leang 1 2 Yu Zhao 2 Mihaela Catalina Stoian 1 Wenda Li 2 Shay B. Cohen 2 Eleonora Giunchiglia 1 6 2 0 2 3 1 ] . [ 1 6 8 5 2 1 . 2 0 6 2 : r Abstract While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce MCDIFFUSE, framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). MCDIFFUSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while MCDIFFUSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs. 1. Introduction While autoregressive models (ARMs; Liu et al. 2024; Yang et al. 2025a) have achieved remarkable progress across wide range of reasoning tasks (Wei et al., 2022; Leang et al., 2025a; Lyu et al., 2023), their inference is fundamentally limited by the sequential constraint of autoregressive decoding. Masked Diffusion Models (MDMs; Bie et al. 2025; Ye et al. 2025) have been proposed to overcome the limitations of current ARMs through an iterative denoising process with 1Imperial College London 2University of Edinburgh. Correspondence to: Joshua Ong Jun Leang <j.ong25@imperial.ac.uk>, Eleonora Giunchiglia <e.giunchiglia@imperial.ac.uk>. Preprint. 1 no fixed generation order. MDMs enable non-sequential order decoding by assuming conditional independence among target tokens and offer the potential to discover generation orders beyond rigid left-to-right trajectories (Li et al., 2023; Kim et al., 2025; Fu et al., 2025). While MDMs offer inference efficiency, they often underperform compared to ARMs (Nie et al., 2025). One critical reason is that such generation can lead to interdependent tokens generated simultaneously without mutual conditioning, making output quality sensitive to the generation order (Li et al., 2025). Recently, the plan-and-infill framework (Li et al., 2025) has emerged as promising approach for optimising generation orders in MDMs, where each denoising iteration comprises two steps: planning phase that selects sub-sequence (slot) from the set of currently masked subsequences, and an infilling phase that generates tokens within this selected slot autoregressively. While this framework alleviates the difficulty of generating tokens with strong local, inner-slot dependency (Li et al., 2025), the inter-slot generation order remains critical to output quality, as errors in ordering can induce unmodelled dependencies that propagate across iterations and undermine global coherence. Identifying such orderings is challenging due to the vast combinatorial space of possible slot permutations. Consequently, heuristic planners, such as confidence-based selection used in current MDMs (Ye et al., 2025; Schuster et al., 2022), often fail to account for long-range dependencies, leading to performance degradation. To overcome the difficulty of reliably selecting slots for infilling (i.e., the planning phase), we introduce Monte Carlo Diffusion Search (MCDIFFUSE), training-free framework that formulates slot selection as decision-making problem. Rather than seeking provably optimal schedule (Figure 1), MCDIFFUSE performs targeted lookahead over the combinatorial space of slot orderings using Monte Carlo Tree Search (MCTS; Kocsis & Szepesvari 2006) with priorguided expansion (Silver et al., 2017). In particular, the search integrates the models intrinsic confidence scores as prior probabilities and uses hybrid reward mechanism combining immediate denoising quality with rollout-based estimation of long-term trajectory coherence. By simulating Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Figure 1. Overview of MCDIFFUSE. We formulate slot selection as sequential decision-making process optimised via Monte Carlo Tree Search. As illustrated in the Statistics box, the models greedy prior (P (a = 1 s0) = 0.37) favours immediately generating the function definition (i.e., slot 2: def get max length(words):). However, through look-ahead simulations, the search algorithm discovers that starting with the syntax declaration (i.e., slot 1: python) yields higher long-term Q-value (i.e., Q(s0, = 1) = 1.20 for slot 1 vs. Q(s0, = 2) = 0.88 for slot 2), allowing the model to override the biased local prior and ensure global coherence. future generation steps, MCDIFFUSE identifies slot orderings that reduce error propagation across iterations, thereby improving generation quality. We evaluate MCDIFFUSE across six reasoning benchmarks, where it consistently outperforms current MDMs and the state-of-the-art plan-and-infill method, ReFusion (Li et al., 2025). Specifically, MCDIFFUSE achieves absolute accuracy gains of 19.45% on MBPP (Austin et al., 2021) and 4.9% on MATH500 (Hendrycks et al., 2021). MCDIFFUSE narrows the performance gap between diffusion and autoregressive models, matching or exceeding autoregressive performance on five out of six reasoning benchmarks under identical experimental conditions. These results demonstrate the critical importance of strategic slot planning in MDMs and confirm the effectiveness of MCDIFFUSEs trajectory exploration approach. We further provide comprehensive analysis revealing two key insights into MCDIFFUSEs success. (1) While MCDIFFUSE predominantly adheres to sequential (left-to-right) generation, it strategically deviates to non-sequential orderings for critical subset of samples, achieving higher accuracy on these cases and demonstrating that incorporating non-sequential generation is essential for maximising performance on reasoning tasks. (2) Unlike traditional MCTS (Guan et al., 2025; Yang et al., 2025b) applied to ARMs, our approach prioritises exploration over simulation depth. We find that an increasing number of simulations does not consistently improve performance. Instead, large exploration constant is necessary to overcome the models confidence priors and discover effective slot orderings, indicating that the primary challenge in slot planning lies in initiating search down low-prior branches to ensure sufficient exploration breadth, escaping bias towards locally confident but globally incoherent initial priors (Section 6). In summary, our contributions are: 1) we propose MCDIFFUSE, training-free framework that tailors MCTS specifically for searching slot orderings in MDMs, effectively closing the performance gap with ARMs; 2) we provide empirical analysis revealing that strategic non-sequential generation is critical to performance, validating MCTS as an effective approach for slot orderings; 3) we show that exploration breadth is critical to slot planning, requiring large exploration constant to escape biased confidence priors and discover better orderings. 2. Background Markov Decision Process. Sequential decision-making problems are typically modelled as Markov Decision Process (MDP; Bellman 1957). Formally, an MDP is tuple S, A, , R, where is the state space representing all 2 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models of the possible configurations of the environment, and is the action space. At every time step t, an agent in state st selects an action A, upon which the environment transitions to successor state st+1 according to the transition probability function (st+1 st, a). The agent receives reward specified by the reward function R, and the objective is to learn policy that maximises the expected cumulative reward over time. Monte Carlo Tree Search. Monte Carlo Tree Search (MCTS) is heuristic search algorithm that approximates optimal policies in MDPs by combining tree search with Monte Carlo simulation to balance exploration and exploitation (Coulom, 2006). In the tree, each node represents state and each edge represents an action A. MCTS proceeds through repeated simulations, each consisting of four phases: (i) selection, (ii) expansion, (iii) simulation, and (iv) backpropagation. During (i) selection, the search starts from the root node corresponding the current state and traverses the tree by selecting child nodes according to bandit-based policy. Upon reaching leaf node, the (ii) expansion step instantiates child nodes corresponding to previously unexplored actions available at that state. One of these newly created children is then selected for evaluation. To estimate its value, (iii) simulation (or rollout) is performed by sampling trajectory from the current state until terminal condition is met, often using user-defined lightweight policy to guide action selection. Finally, during (iv) backpropagation, the cumulative reward resulting from the simulation is propagated backward up the tree. After backpropagation, new simulation begins again from the root. This process repeats until predefined computational budget is exhausted. common policy choice used during the selection phase is the Upper Confidence Bounds for Trees (UCT; Kocsis & Szepesvari 2006): UCT(s, a) = Q(s, a) + cuct (cid:115) ln Ns , (1) where Q(s, a) is the empirical mean return over all rollouts in which action was selected from state s, Ns is the number of visits of state s, and is the number of times action was selected from s. Visit counts are initialised to zero upon node instantiation and are updated at each iteration of the algorithm during backpropagation. The constant cuct > 0 controls the explorationexploitation trade-off, i.e., larger cuct value corresponds to higher exploration. Neural-guided MCTS. In high-dimensional action spaces, modern MCTS variants such as AlphaZero (Silver et al., 2017) replace stochastic rollouts with learned value functions and incorporate neural policy priors to guide exploration. These methods typically employ the PredictorUpper Confidence Tree (PUCT) algorithm which selects 3 children using the criterion defined as: PUCT(s, a) = Q(s, a) (cid:124) (cid:123)(cid:122) (cid:125) Exploitation term + (a s) , (2) (cid:124) (cid:123)(cid:122) Exploration term Ns 1 + (cid:125) where (a s) denotes the prior probability of selecting action in state s, as predicted by neural policy πθ. The policy prior might be learnt independently (e.g., via reinforcement or imitation learning (Silver et al., 2017; Granter et al., 2017)) or jointly with MCTS by training the network to match the search-induced action distribution (Schrittwieser et al., 2020). The exploration term biases early search toward actions with high prior probability while ensuring that the influence of the prior diminishes as visit counts increase. This mechanism effectively reduces the search effort by focusing exploration on semantically plausible actions and is particularly well suited for inference-time optimisation. The definition of Q(s, a), Ns, and is as in Equation 1. 3. MCDIFFUSE In this section, we formulate the slot planning as an MDP (Section 3.1), and introduce our MCTS-based slot planning approach for determining infilling orders (Section 3.2). 3.1. Problem Formulation Suppose we have generative model with parameters θ that produces text as sequence = (x1, . . . , xK) of contiguous and disjoint slots, i.e., strings each with tokens. While tokens within each slot are generated autoregressively, slots themselves may be generated in an arbitrary order. Our goal is to determine an ordering of the slots that reflects how the generation of one slot influences the others. We represent such ordering as permutation (σ1, σ2, . . . , σK), where σt is the index of the slot generated at step t, with = 1, . . . , K. We formulate this optimisation problem as deterministic MDP S, A, , R, whose components are defined below. State space (S): state encodes which slots have been generated so far and the corresponding partially filled sequence. Formally, state st visited at step is defined as pair (σ0:t, xt), where σ0:t = (σ1, . . . , σt) represents the prefix of σ containing the indexes of the slots generated up to step t, while xt = (x1 ) is the current (possibly partially filled in) text sequence. For any slot index {σ1, . . . , σt}, the corresponding slot xk is populated with the special [MASK] token. The first state (t = 0) is initialised with σ0:0 = 1 and x0 = [MASK]K, where [MASK]K indicates sequence of [MASK] tokens. , . . . , xK Action space (A): An action corresponds to selecting the index of one of the masked slots. Hence, for every A, 1We use to denote an empty sequence. Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models {1, . . . , K}. At step t, the admissible2 action set will be At = {k {1, . . . , K} {σ1, . . . , σt}}. Example 3.1. Consider Figure 1, where the following prompt is given Write Python function to find the length of the longest word, and where the target response is partitioned into = 8 slots (e.g., slot 1: python, slot 2: def get max length(words):, etc.). The intial state s0 has all slots masked. If slot 1 is selected (a = 1), then the successor state becomes s1, where slot 1 is infilled (e.g., with python) and the other slots are still masked (see bottom left side of the Figure). Transition function (T ): In our formulation the transition function is deterministic, and hence, given state st and an action = σt+1, (st+1 st, a) assigns probability 1 to unique successor state. Since the slot chosen by the action is infilled via argmax decoding of the generative model, st+1 = (σ0:t σt+1, xt+1), where is used to indicate that we concatenate the index σt+1 to the sequence σ0:t, while the updated sequence xt+1 is identical to xt except at position σt+1, in which the mask is replaced by the models predicted tokens. Reward function (R): In the absence of ground-truth references during inference, we rely on the models intrinsic confidence estimates to guide the tree search. Following recent work on confidence-based generation showing confidence correlates positively with downstream accuracy (Leang et al., 2025b; Nie et al., 2025; Prabhudesai et al., 2025), we define rewards based on the probability the model assigns to its own predictions. We define the reward as the slot-level confidence: Selection. Starting from the root node s0, the algorithm recursively traverses the search tree by selecting actions according to the PUCT criterion in Equation (2) until an unexpanded leaf node is reached. For previously unvisited stateaction pairs, the corresponding value estimates are initialised as Q(s, a) = 0. Example 3.2. (contd Example 3.1) At the root state s0, MCTS evaluates the admissible actions corresponding to the first slot to be filled. The prior (a s0) computed from the slot level confidence (as detailed in Equation (4)), favours generating the function definition (i.e, slot 2). However, the Q-values estimated via look-ahead simulations assign higher long-term value to starting with the syntax declaration (slot 1): Q(s0, 1) = 1.2, Q(s0, 2) = 0.88. Since PUCT balances the empirical value Q(s0, a) and the prior (a s0), the action = 1 is selected despite the lower prior. This choice reflects the structural dependency in the program: generating the syntax declaration first induces more coherent trajectory, as it conditions the remaining slots, enforces the overall code structure, and simplifies indentation handling, which is central to Python. Expansion. When an unexpanded leaf node corresponding to state st is reached, we expand the node by creating child nodes for all admissible actions At. For each newly created state-action pair (s, a), visit counts Ns, and accumulated value (s, a) are initialised to zero. The prior over actions is obtained by forward pass of the generative model conditioned on the current state st, from which we extract the slot-level confidence score R(st, a) for each unfilled slot. These scores are normalised to form the action prior: R(st, a) = 1 i= (cid:88) Pθ(xσt+1 t+1 [i] xt, xσt+1 t+1 [< i], Prompt), (a st) = (cid:80) R(st, a) aAt R(st, a) , (4) t+1 [i] (resp. xσt+ (3) where xσt+1 t+1 [< i]) denotes the i-th token (resp. all tokens up to the i-th) of the slot at index σt+1, and is the slot size. At every step t, the reward R(st, a) thus quantifies the generation quality slot filled following the action (i.e., the one at index σt+1) as the mean probability assigned by the generative model across all tokens within that slot: 3.2. Slot Planning via Monte Carlo Tree Search To solve the MDP defined above without training auxiliary networks, we adapt MCTS to guide slot ordering by designing rollout-based confidence estimator that captures future coherence beyond immediate slot-level confidence rather than relying on greedy local heuristics. We describe the four phases of the resulting MCTS procedure below. 2An action is admissible at step if the corresponding slot has not yet been filled; At shrinks at each trajectory as slots are selected and At = for > 0. 4 Following expansion, child node is selected according to the PUCT criterion to initiate the simulation phase. Example 3.3. (contd Example 3.2) After selecting = 1 at the root, the search reaches state s1, where only one slot has been infilled. During the expansion step at s1, child nodes are created for the remaining admissible actions {2, 3, . . . , 8}. Conditioned on the filled slots at s1, the model induces new prior distribution over the remaining admissible slots. Simulation. To evaluate an expanded leaf corresponding to state st, we estimate the value of taking action by combining the immediate slot-level reward with stochastic rollout estimate: (st, a) = λ R(st, a) + (1 λ) Eπroll[G]. The mixing coefficient λ balances immediate local confidence against long-term trajectory quality. This balance is important as evaluating leaf node solely based on the (5) Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Algorithm 1 Simulation Step 1: Input: Current state st, temperature τ , mixing coefficient λ, slot-level confidence scores {R(st, a)}aAt // Copy state for lookahead 2: Output: Rollout estimate 3: sr st 4: 0, 0 5: while sr has unfilled slots do 6: Ar {indices of unfilled slots in sr} 7: 8: // Stochastic selection based on temperature Compute probabilities πroll(a sr) exp(R(sr, a)/τ ) for all Ar Sample next slot action {πroll(a sr)} sr (sr, a) by filling slot + 1 9: 10: + R(sr, a) 11: 12: 13: end while 14: G/T if > 0 else 0 15: return // Simulate infill // Weighted combination immediate confidence R(st, a) can be misleading: slot that appears highly confident in isolation may constrain the models predictions for remaining slots, leading to poor overall generation quality. The rollout term approximates the remaining return by continuing slot infilling from the successor state st+1 = (st, a) until terminal state is reached. At each rollout step r, given state sr, we compute R(sr, a) for all admissible actions Ar and sample the next slot according to temperature-scaled (according to τ ) softmax policy: exp(R(sr, a)/τ ) πroll(a sr) = (cid:80) aAr The trajectory score is the average reward accumulated along the rollout, exp(R(sr, a)/τ ) . (6) = 1 T (cid:88) R(si, ai), (7) i=1 where (si, ai) are the stateaction pairs with ai {πroll(a si)} encountered during the rollout and is the rollout length. Example 3.4. (contd Example 3.3) From the newly expanded node, the rollout policy stochastically fills the remaining slots to estimate trajectory value. For example, it might sample the path: fill slot 3 ( if not words:) slot 8 (closing tag ) slot 2 (function header def get max length(words):). We provide the pseudocode for the rollout process in Algorithm 1. Further, in Section B, we present concrete numerical example of how the rollout values are calculated. Backpropagation. After evaluating leaf node, the estimated value (s, a) is recursively propagated back to the root along the traversal path. For each visited (state, action) pair (s, a), we update the visit counts Ns Ns + 1, a + 1, (8) and accumulate the total value associated with the edge (s, a) as (s, a) (s, a) + (s, a). (9)"
        },
        {
            "title": "The empirical mean action value is then given by",
            "content": "Q(s, a) = (s, a) , (10) which serves as the exploitation term in the PUCT selection rule. After Nsim simulations, we select the next action at the root of the current search tree, i.e., the current state st, using the robust child criterion = arg max aAt"
        },
        {
            "title": "N a\nst",
            "content": "(11) , which chooses the action most frequently selected during search. While PUCT guides exploration during the selection phase of tree search, the final action selection relies solely on visit counts, eliminating the exploration bonus at decision time. We execute to transition to st+1 and MCTS again with st+1 as the new root state, repeating this process until all slots are filled. Example 3.5. (contd Example 3.4) The high value obtained from constructing syntactically valid Python function is propagated up the tree. As the last step of our MCTS-based algorithm, the root node updates its statistics for action = 1 (including the mean value estimates and visit counts), reinforcing the starting with the syntax declaration (in Markdown), rather than generating directly the code, yields the preferred generation path. Finally, after Nsim simulations are completed, single child of the root node is selected In the context corresponding to the highest visit count. of Figure 1, this results in selecting the blue node (corresponding to transitioning from state s0 to s1 through action = 1), which now marks the syntax declaration as the next slot to be infilled. While Algorithm 1 details our core value estimation strategy (the rollout), the full algorithm for slot selection is provided in Section A. Further, in Section F, we provide concrete, step-by-step walkthrough of the four MCTS phases of our approach, across multiple simulations. 4. Experimental Setup Evaluation Benchmarks and Metrics. We evaluate on six benchmarks, ranging from mathematical reasoning, code generation, and general knowledge: GSM8K (Cobbe et al., 2021), MATH500 (Hendrycks et al., 2021), MBPP (Austin et al., 2021), HumanEval (Chen, 2021), ARC Challenge (Clark et al., 2018), and GPQA-Diamond (Rein et al., 2024). For all evaluations, we use the Pass@1 metric. To ensure fair comparison, we re-evaluate all baselines using chain-of-thought prompting (Kojima et al. 2022; i.e., lets think step by step), allowing models to generate intermediate reasoning steps before producing final answers. All Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Model GSM8K MATH500 ARC GPQA-Diamond MBPP HumanEval Average Autoregressive Models Llama-3.1 8B 83.48% 0.64% 35.90% 1.56% 83.32% 0.06% 88.02% 2.25% 46.50% 0.71% 87.80% 0.12% Qwen2.5 7B 88.21% 2.09% 46.20% 0.28% 88.40% 0.12% Qwen3 8B 31.14% 2.37% 16.94% 2.49% 23.13% 8.39% 25.49% 1.38% 59.76% 0.86% 53.18% 64.90% 1.22% 71.78% 4.22% 62.66% 69.81% 1.41% 76.24% 2.09% 65.33% Diffusion Models LLaDA 8B Dream 7B ReFusion 7B 84.50% 1.73% 36.70% 2.12% 84.09% 2.11% 84.31% 0.22% 42.90% 0.42% 84.95% 0.05% 85.64% 0.59% 42.90% 0.71% 87.98% 0.49% + Sequential 77.56% 2.03% 38.90% 0.71% 87.09% 0.88% 66.87% 1.93% 29.10% 0.71% 80.98% 0.60% + Random 21.39% 1.20% 25.42% 0.04% 30.45% 0.09% 33.43% 0.71% 27.63% 3.54% 32.16% 3.49% 35.40% 0.00% 49.04% 53.23% 4.00% 57.24% 5.06% 58.01% 54.12% 6.64% 62.05% 1.10% 60.52% 50.58% 0.00% 62.18% 2.21% 58.29% 21.40% 1.65% 32.60% 1.13% 43.10% MCDIFFUSE 87.91% 1.02% 47.80% 0.85% 88.68% 0.39% 34.78% 0.27% 73.57% 1.61% 78.37% 0.45% 68.52% Table 1. Performance comparison on reasoning and code generation benchmarks (mean and standard deviation). MCDIFFUSE achieves the highest average performance, outperforming both autoregressive and diffusion models. Notably, MCDIFFUSE demonstrates superior performance on MATH500, ARC, GPQA-Diamond, MBPP, and HumanEval, while remaining highly competitive on GSM8K. results averaged over three independent runs and reported with standard errors. (Details appear in Section C.) Models. We use ReFusion (Li et al., 2025) as our base model, as it is, to the best of our knowledge, the only available slot-and-infill diffusion language model. We compare MCDIFFUSE against eight baselines: the vanilla ReFusion model, ReFusion with random slot ordering and sequential slot ordering, LLaDA-8B-Instruct (Nie et al., 2025) and Dream 7B (Ye et al., 2025) as diffusion-based baselines, with Qwen2.5 7B (Team et al., 2024) and Qwen3 8B (Yang et al., 2025a) as our autoregressive baseline. Hyperparameters. For the hyperparameters mentioned in Section 3.2, we set λ = 0.3 to penalise slot orderings that achieve high immediate confidence and force subsequent slots into low-probability regions, guiding the search towards globally coherent generation trajectories. We also use = 50, Nsim = 256, and τ = 0.5. Detailed explanations of hyperparameter choice and sensitivity analysis are presented in Section 6 and Section C.2. 5. Experimental Results Table 1 reports the performance of MCDIFFUSE across six benchmarks, compared against both masked diffusion models (MDMs) and autoregressive models (ARMs). The results highlight three main phenomena: 1. MCDIFFUSE outperforms both MDMs and ARMs baselines across five out of six benchmarks. Additionally, MCDIFFUSE significantly outperforms all MDMs across all six benchmarks. For instance, MCDIFFUSE achieves performance increases of 25.98% on HumanEval and 4.00% on MATH500 compared to ReFusion, with more substantial gains on traditional MDMs. (Li et al., 2025). 2. Coding tasks benefit more from MCTS slot planning. MCDIFFUSE yields substantially larger gains on code-generation benchmarks, achieving improvements of 16.32% on HumanEval and 19.45% on MBPP. In contrast, improvements on multiple-choice reasoning benchmarks are more modest (ARC Challenge: 0.7%; GPQA: 4.33%). This pattern suggests that tasks involving structured program synthesis benefit more from strategic slot planning, as dependencies between code componentssuch as variable declarations, function definitions, and control flowinduce ordering constraints that can be effectively explored by MCTS. Further analysis in Section D.2 further confirms this hypothesis. 3. MCDIFFUSE produces more compact and coherent reasoning. Under identical experimental conditions with chain-of-thought prompting, ARMs often produce lengthy reasoning sequences that may become incoherent or incomplete, particularly when the reasoning chain exceeds the models effective context length on tasks, like GPQADiamond, that require extensive reasoning (see Section for some qualitative examples). In contrast, MCDIFFUSE generates more compact reasoning. For example, on MATH500 MCDIFFUSE produces sequences of average length equal to 152.2 while Qwen2.5 7B has average prediction length equal to 436.0 while getting worse accuracy. The length reduction is consistent across the three benchmarks that require extensive reasoning (i.e., GSM8K, MATH500 and GPQA) and is always statistically significant (p < 0.001) as reported in Section D.1. We compare the performance of MCDIFFUSE and autoregressive models at their maximum token lengths in Section D.3. 6. Analysis and Discussion We provide detailed analysis to better understand when and why MCTS-based slot planning improves generation performance. In particular, we examine how often non6 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Figure 2. Relationship between generation sequentiality and accuracy on the MBPP dataset. Each dot represents sample plotted by its accuracy and sequentiality rate. Darker dots denote higher density, reflecting multiple instances with identical sequentiality. Solid lines denote average accuracy trends computed by binning sequentiality rates for ReFusion and MCDIFFUSE, while the dashed line indicates the overall accuracy of sequential (left-to-right) baseline. sequential ordering decisions arise and when they matter, how exploration and simulation budget affect accuracy, and what computational trade-offs are introduced by searchbased planning. Together, these analyses shed light on the practical behavior and efficiency of MCDIFFUSE beyond aggregate benchmark results. When Do Non-Sequential Slot Orderings Matter? We observe that the majority of slot-ordering decisions made by MCDIFFUSE follow sequential, left-to-right pattern, consistent with standard autoregressive decoding (91.1% for coding tasks and 93.8% for mathematical reasoning tasks). As shown in Figure 2, most instances concentrate at high sequentiality rates, indicating that the sequential order serves as an effective default strategy across tasks. Despite their relative rarity, non-sequential decisions play disproportionate role in performance improvements. Among instances where MCDIFFUSE succeeds while the sequential autoregressive baseline fails (13.2% of the dataset), 60.7% involve at least one non-sequential ordering decision. This effect is also reflected in Figure 2, where higher accuracy is often associated with intermediate sequentiality rates rather than strictly sequential generation. Together, these observations suggest an effective exploration-exploitation trade-off: the search policy largely exploits the reliable sequential prior, while selectively deviating from it to resolve challenging constraints that confound greedy left-to-right decoding. This indicates that even sparse, well-timed departures from the sequential order can yield meaningful accuracy improvements when guided by informed slot planning. Further example and analysis are provided in Figure 4 7 Figure 3. Impact of exploration constant (c) and simulation budget (Nsim) on task performance. Config Mean (bits) Std Median Concentration Low Exploration (c = 2) = 30 = 270 1.4062 1.1842 0.3785 0.4043 1.4824 1.1492 High Exploration (c = 100) = 30 = 270 1.4176 1.4340 0.3771 0.3768 1.5058 1.5211 0.4958 0.6118 0.4954 0. Table 2. Impact of simulation count (Nsim) and exploration constant (c) on policy entropy, and concentration. Under low exploration = 2, entropy decreases with more simulations, while under high exploration = 100, entropy remains stable. and Section G. How Do Exploration and Simulation Budget Affect Performance? We analyse the interaction between the exploration constant (c) and the simulation budget (Nsim) and their impact on the models performance. As shown in Figure 3 and Figure 8 in Section I, increasing the exploration budget consistently improves accuracy across benchmarks, indicating that stronger exploration is necessary to overcome the local confidence bias induced by the baselines predictions. On the other hand, increasing the simulation budget (Nsim) does not guarantee an improvement in performance: at low exploration budget (c = 2.0) increasing Nsim from 30 to 270 simulations leads to decrease in accuracy on both MBPP and MATH500. This phenomenon is explained by the entropy analysis in Table 2: under low exploration (c = 2), mean entropy drops from 1.41 to 1.18 bits as Nsim increases, indicating premature convergence towards locally confident but globally myopic orderings. Conversely, with high exploration (c = 100), entropy remains stable 1.43bits), allowing the search to maintain breadth and discover effective orderings. This suggests that, under insufficient exploration pressure, additional simulations reinforce early, locally confident but globally myopic slot orderings. Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models 7. Related work Monte Carlo Tree Search. MCTS (Kocsis & Szepesvari, 2006; Coulom, 2006) has proven highly effective for sequential decision-making (Chaslot et al., 2008; Browne et al., 2012; van Krieken et al., 2025), achieving notable success in game-playing agents such as AlphaGo (Granter et al., 2017) and AlphaZero (Silver et al., 2017). Recently, MCTS has been extensively applied to enhance LLM Reasoning, including math (Gao et al., 2024; Xie et al., 2024; Wu et al., 2024), coding (Wang et al., 2025), and others. MCTS has also been applied to visual diffusion models (Yoon et al., 2025a;b; Ramesh & Mardani, 2025) for improving generation quality. To the best of our knowledge, our work represents the first application of MCTS to MDMs for text generation, specifically addressing slot ordering. Masked Diffusion Models (MDMs). MDMs, originally successful in visual domains (Song et al., 2021; Ho et al., 2020), have emerged as promising paradigm for nonautoregressive sequence generation (Nie et al., 2025; Bie et al., 2025; Gong et al., 2024), particular within the coding domain (Gong et al., 2025; Zhao et al., 2025). However, MDMs still struggle to match the performance of autoregressive models (ARMs) on complex reasoning tasks (Zhu et al., 2025). Architectures such as BD3LM (Arriola et al., 2025), Eso-LMs (Sahoo et al., 2025), and ReFusion (Li et al., 2025) have explored various decoding approaches to bridge this gap. Probabilistic methods such as top (Nie et al., 2025), low entropy (Ben-Hamu et al., 2025) and probability margins between top candidates (Kim et al., 2025) have been widely used in decoding within text MDMs. 8. Conclusion Figure 4. Comparison of ReFusion and MCDIFFUSE on coding prompt from MBPP. Superscripts denote the infilling slot order and colours indicate the specific generation step. Regarding computational overhead, generation time scales approximately linearly with Nsim while varying causes negligible cost as it only affects selection without requiring additional forward passes. We observe an accuracyefficiency trade-off: although Nsim = 270 achieves highest accuracy, the improvement over Nsim = 30 < 2% while computational cost increases ninefold. high-exploration, low-budget configuration achieves substantial gains such as 13.62% improvement on MBPP while maintaining reasonable inference time. (Detailed analysis and comparison with ReFusion can be found in Section H.) These results highlight that the primary challenge in nonautoregressive slot planning is not search depth, but sufficient breadth to escape local optima. How does MCTS mitigate local optima in slot-based generation? We give an intuition through the qualitative example in Figure 4. In the Figure, ReFusion selects and fills multiple high-confidence slots simultaneously from the start (slots 1, 2, and 3) in its attempt to maximise throughput. Specifically, it greedily fills slot 1 with an unnecessary import statement (i.e., Import reverse ), likely driven by generic prior that Python scripts often begin with imports. However, because ReFusion cannot backtrack to correct this early commitment, this unnecessary slot forces the subsequent generation into syntactically broken state (e.g., merging the import line directly into part of function definition header). On the other hand, MCDIFFUSE avoids this issue through its lookahead capability. By simulating the full trajectory before committing, it detects that starting with an import leads to lower long-term coherence for this specific task, and instead correctly prioritises the function definition (by filling in slot 1 with def and then slot 2 with check(n): to complete the header of the function definition) as the most effective starting point. We introduce MCDIFFUSE, training-free framework that enhances MDMs through strategic slot selection. By formulating slot ordering as decision-making and using MCTS with designated adaptations confidence-aware value propagation and adaptive exploration budgets MCDIFFUSE systematically navigates the combinatorial space of generation orders without additional training. Through experiments across six reasoning benchmarks, MCDIFFUSE demonstrates consistent improvements over existing MDM baselines and competitive performance with ARMs under identical experimental conditions, with particularly strong gains on code generation tasks. Our analysis reveals that (1) while MCDIFFUSE mainly adheres to sequential ordering, strategic deviations to non-sequential generation are essential for maximising performance, and (2) rather than increasing the number of simulations, significant exploration breadth is needed to overcome the models priors and discover effective slot orderings. Together, These findings establish MCDIFFUSE as an effective approach for enhancing slot selection and infilling within MDMs. 8 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models"
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents work whose goal is to apply controlled plan-and-infill search method using MCTS to masked diffusion models without requiring additional training, with applications in mathematical reasoning, coding, and general scientific reasoning tasks within language models. This could improve how diffusion models process generations by exploring multiple search paths with lookahead, reducing propagation of unmodelled dependencies across iterations that undermine global coherence. Our analysis on models requiring combination of sequential and non-sequential generation strategies for maximised performance could be useful for future work on improving LLM reasoning, merging the realm between diffusion models and autoregressive models. Lastly, our results on large exploration constants being necessary to overcome the models confidence priors could bring societal impact towards the potential of structured plan-and-infill methods, or any diffusion-guided generation paradigms. There are potential societal consequences of our work, none of which we feel must be specifically highlighted here."
        },
        {
            "title": "References",
            "content": "Arriola, M., Sahoo, S. S., Gokaslan, A., Yang, Z., Qi, Z., Han, J., Chiu, J. T., and Kuleshov, V. Block diffusion: Interpolating between autoregressive and diffusion language models. In International Conference on Learning Representations, 2025. Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al. Program synthesis with large language models. ArXiv preprint, abs/2108.07732, 2021. Bellman, R. markovian decision process. Indiana University Mathematics Journal, 6:679684, 1957. Ben-Hamu, H., Gat, I., Severo, D., Nolte, N., and Karrer, B. Accelerated sampling from masked diffusion models via entropy bounded unmasking. ArXiv preprint, abs/2505.24857, 2025. Bie, T., Cao, M., Chen, K., Du, L., Gong, M., Gong, Z., Gu, Y., Hu, J., Huang, Z., Lan, Z., et al. Llada2. 0: Scaling up diffusion language models to 100b. ArXiv preprint, abs/2512.15745, 2025. Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P., Tavener, S., Perez, D., Samothrakis, S., and Colton, S. survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 4(1):143, 2012. Chaslot, G. M.-B., Winands, M. H., and van Den Herik, H. J. Parallel monte-carlo tree search. In International Conference on Computers and Games, pp. 6071. Springer, 2008. Chen, M. Evaluating large language models trained on code. ArXiv preprint, abs/2107.03374, 2021. Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge. ArXiv preprint, abs/1803.05457, 2018. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems. ArXiv preprint, abs/2110.14168, 2021. Coulom, R. Efficient selectivity and backup operators in monte-carlo tree search. In International conference on computers and games, pp. 7283. Springer, 2006. Fu, H., Huang, B., Adams, V., Wang, C., Srinivasan, V., and Jiao, J. From bits to rounds: Parallel decoding with exploration for diffusion language models. ArXiv preprint, abs/2511.21103, 2025. Gao, Z., Niu, B., He, X., Xu, H., Liu, H., Liu, A., Hu, X., and Wen, L. Interpretable contrastive monte carlo tree search reasoning. ArXiv preprint, abs/2410.01707, 2024. Gong, S., Agarwal, S., Zhang, Y., Ye, J., Zheng, L., Li, M., An, C., Zhao, P., Bi, W., Han, J., et al. Scaling diffusion language models via adaptation from autoregressive models. ArXiv preprint, abs/2410.17891, 2024. Gong, S., Zhang, R., Zheng, H., Gu, J., Jaitly, N., Kong, L., and Zhang, Y. Diffucoder: Understanding and improving masked diffusion models for code generation. ArXiv preprint, abs/2506.20639, 2025. Granter, S. R., Beck, A. H., and Papke Jr, D. J. Alphago, deep learning, and the future of the human microscopist. Archives of pathology & laboratory medicine, 141(5): 619621, 2017. Guan, X., Zhang, L. L., Liu, Y., Shang, N., Sun, Y., Zhu, Y., Yang, F., and Yang, M. rstar-math: Small llms can master math reasoning with self-evolved deep thinking. ArXiv preprint, abs/2501.04519, 2025. Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021. 9 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Ho, J., Jain, A., and Abbeel, P. Denoising diffusion In Larochelle, H., Ranzato, M., probabilistic models. Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. Kim, J., Shah, K., Kontonis, V., Kakade, S., and Chen, S. Train for the worst, plan for the best: Understanding token ordering in masked diffusions. ArXiv preprint, abs/2502.06768, 2025. Kocsis, L. and Szepesvari, C. Bandit based monte-carlo planning. In European conference on machine learning, pp. 282293. Springer, 2006. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot In Koyejo, S., Mohamed, S., Agarreasoners. wal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. Leang, J. O. J., Gema, A. P., and Cohen, S. B. Comat: Chain of mathematically annotated thought improves mathematical reasoning. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pp. 2025620285, 2025a. Leang, J. O. J., Zhao, Z., Gema, A. P., Yang, S., Kwan, W.-C., He, X., Li, W., Minervini, P., Giunchiglia, E., and Cohen, S. B. Picsar: Probabilistic confidence selection and ranking for reasoning chains. ArXiv preprint, abs/2508.21787, 2025b. Li, J.-N., Guan, J., Wu, W., and Li, C. Refusion: diffusion large language model with parallel autoregressive decoding. ArXiv preprint, abs/2512.13586, 2025. Li, Y., Zhou, K., Zhao, W. X., and Wen, J. Diffusion models for non-autoregressive text generation: survey. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, China, pp. 6692 6701. ijcai.org, 2023. doi: 10.24963/IJCAI.2023/750. Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C., Zhang, C., Ruan, C., et al. Deepseek-v3 technical report. ArXiv preprint, abs/2412.19437, 2024. Lyu, Q., Havaldar, S., Stein, A., Zhang, L., Rao, D., Wong, E., Apidianaki, M., and Callison-Burch, C. Faithful chain-of-thought reasoning. In Park, J. C., Arase, Y., Hu, B., Lu, W., Wijaya, D., Purwarianti, A., and Krisnadhi, A. A. (eds.), Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 305329, Nusa Dua, Bali, 2023. Association for Computational Linguistics. doi: 10.18653/v1/ 2023.ijcnlp-main.20. Nie, S., Zhu, F., You, Z., Zhang, X., Ou, J., Hu, J., Zhou, J., Lin, Y., Wen, J.-R., and Li, C. Large language diffusion models. ArXiv preprint, abs/2502.09992, 2025. Prabhudesai, M., Chen, L., Ippoliti, A., Fragkiadaki, K., Liu, H., and Pathak, D. Maximizing confidence alone improves reasoning. ArXiv preprint, abs/2505.22660, 2025. Ramesh, V. and Mardani, M. Test-time scaling of diffusion models via noise trajectory search. ArXiv preprint, abs/2506.03164, 2025. Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael, J., and Bowman, S. R. Gpqa: graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024. Sahoo, S. S., Yang, Z., Akhauri, Y., Liu, J., Singh, D., Cheng, Z., Liu, Z., Xing, E., Thickstun, J., and Vahdat, A. Esoteric language models. ArXiv preprint, abs/2506.01928, 2025. Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et al. Mastering atari, go, chess and shogi by planning with learned model. Nature, 588(7839): 604609, 2020. Schuster, T., Fisch, A., Gupta, J., Dehghani, M., Bahri, D., Tran, V., Tay, Y., and Metzler, D. Confident adaptive language modeling. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui, F., Sifre, L., van den Driessche, G., Graepel, T., and Hassabis, D. Mastering the game of Go without human knowledge. Nature, 550(7676):354359, 2017. Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modIn 9th eling through stochastic differential equations. International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. 10 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Zhu, F., Wang, R., Nie, S., Zhang, X., Wu, C., Hu, J., Zhou, J., Chen, J., Lin, Y., Wen, J.-R., et al. Llada 1.5: Variance-reduced preference optimization for large language diffusion models. ArXiv preprint, abs/2505.19223, 2025. Team, Q. et al. Qwen2 technical report. ArXiv preprint, abs/2407.10671, 2024. van Krieken, E., Minervini, P., Ponti, E., and Vergari, A. Neurosymbolic diffusion models. ArXiv preprint, abs/2505.13138, 2025. Wang, Y., Ji, P., Yang, C., Li, K., Hu, M., Li, J., and Sartoretti, G. Mcts-judge: Test-time scaling in llm-as-ajudge for code correctness evaluation. ArXiv preprint, abs/2502.12468, 2025. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain-of-thought prompting elicits reasoning in large language models. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. Wu, J., Feng, M., Zhang, S., Che, F., Wen, Z., Liao, C., and Tao, J. Beyond examples: High-level automated reasoning paradigm in in-context learning via mcts. ArXiv preprint, abs/2411.18478, 2024. Xie, Y., Goyal, A., Zheng, W., Kan, M.-Y., Lillicrap, T. P., Kawaguchi, K., and Shieh, M. Monte carlo tree search boosts reasoning via iterative preference learning. ArXiv preprint, abs/2405.00451, 2024. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical report. ArXiv preprint, abs/2505.09388, 2025a. Yang, W., Liao, M., and Fan, K. Markov chain In of thought for efficient mathematical reasoning. Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pp. 71327157, 2025b. Ye, J., Xie, Z., Zheng, L., Gao, J., Wu, Z., Jiang, X., Li, Z., and Kong, L. Dream 7b: Diffusion large language models. ArXiv preprint, abs/2508.15487, 2025. Yoon, J., Cho, H., Baek, D., Bengio, Y., and Ahn, S. Monte carlo tree diffusion for system 2 planning. ArXiv preprint, abs/2502.07202, 2025a. Yoon, J., Cho, H., Bengio, Y., and Ahn, S. Fast monte carlo tree diffusion: 100x speedup via parallel sparse planning. ArXiv preprint, abs/2506.09498, 2025b. Zhao, S., Gupta, D., Zheng, Q., and Grover, A. d1: Scaling reasoning in diffusion large language models via reinforcement learning. ArXiv preprint, abs/2504.12216, 2025. Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models A. Detailed MCDIFFUSE Algorithm This section details the constituent phases of the MCDIFFUSE algorithm. While the main text above outlines the stochastic confidence rollout used for value estimation (Algorithm 1), here we provide the complete pseudo-code for selecting the next slot. In particular, Algorithm 2 outlines the overall slot selection framework. The specific subroutines are detailed in Algorithm 3 (SELECT), Algorithm 4 (EXPAND), and Algorithm 5 (BACKPROPAGATE). Note that, in Algorithm 2, the ROLLOUT function call refers directly to Algorithm 1. Additionally, the SELECTCHILD function applies the same PUCT criterion as Algorithm 3 (SELECT), but performs only single selection step from the current node. Algorithm 2 MCTS-based Slot Selection for MCDIFFUSE st 0, (st, a) // 1. Selection: traverse tree using PUCT to reach leaf sleaf SELECT(sroot, c) // 2. Expansion: if leaf is non-terminal and unexpanded, expand it if sleaf is not terminal and sleaf has no children then 1: Input: Current state st = (σt, xt), slot-level confidence scores {R(st, a)}aAt 2: Parameters: Number of simulations Nsim, exploration constant c, temperature τ , mixing coefficient λ 3: Output: Next action At (slot index to fill next) 4: // Initialise root node and global statistics 5: sroot st 6: Nst 0 // Total visits to root state 7: for all At: 8: // Normalise confidence scores to obtain priors 9: {P (a st)}aAt Normalise(R(st, a)aAt ) 10: for 1 to Nsim do 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: end for 25: // Select action with most visits 26: arg maxaAt st 27: return end if // 3. Simulation: mix immediate confidence with rollout value λ R(sleaf, seval.action) + (1 λ) ROLLOUT(seval, τ, {R(seval, a)}) // 4. Backpropagation: update statistics to root BACKPROPAGATE(seval, V, sroot) EXPAND(sleaf, {R(sleaf, a)}) // Creates children, initialises stats seval SELECTCHILD(sleaf, c) // Pick one child seval sleaf else // seval.action is the action that led to seval Algorithm 3 SELECT 1: Input: Current state s, exploration constant 2: Output: Selected leaf node 3: while has children do 4: 5: // Calculate PUCT for all valid actions from state (cid:17) arg maxaA(s) child(s, a) Q(s, a) + (a s) Ns 1+N (cid:16) 6: 7: end while 8: return // Traverse to the child node corresponding to action B. Stochastic Confidence Rollout Example As described in Section 3, we use stochastic confidence rollouts to estimate the long-term value of partial generation states during MCTS simulation. In particular, Algorithm 1 performs the temperature-scaled stochastic sampling over remaining unfilled slots, where slots with higher model confidence receive proportionally higher selection probability but are not deterministically chosen. This stochasticity enables exploration of diverse completion paths, capturing the models uncertainty about optimal slot orderings while maintaining bias towards high-confidence regions of the generation space. This section provides the detailed algorithm and concrete numerical example to illustrate the rollout mechanism. 12 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Algorithm 4 EXPAND aAs R(s, a) 1: Input: State s, slot-level confidence scores {R(s, a)} 2: // Identify valid actions (indices of currently unfilled slots) 3: As {indices of unfilled slots in s} 4: Rtotal (cid:80) 5: // Create child node for each and initialise its statistics 6: for each action As do 7: 8: 9: 10: end for 0, (s, a) 0 (a s) R(s, a)/Rtotal Create child node for action and link as child(s, a) // Normalise to get prior probability Algorithm 5 BACKPROPAGATE // Get action that led from to // Get parent node of 1: Input: State s, values estimated during rollout, root sroot 2: while = sroot do parent of 3: action from to 4: // Update statistics for the edge (p, a) 5: 6: + 1 7: (p, a) (p, a) + (p, a) 8: Q(p, a) (p, a)/N 9: 10: Np Np + 1 11: 12: end while // Update total visits for parent state // Move up the tree Consider state where slots 0 and 1 are filled, and we must evaluate the path forward for slots {2, 3, 4} with confidences R(s, 2) = 0.45, R(s, 3) = 0.82, R(s, 4) = 0.63 and temperature = 0.5. Iteration 1: The rollout computes the sampling distribution: p2 = exp(0.45/0.5) (cid:80) p3 = exp(0.82/0.5) (cid:80) p4 = exp(0.63/0.5) (cid:80) = = = 2.460 11.140 5.155 11.140 3.525 11.140 = 0.221 = 0.463 = 0. The algorithm samples = 3 (higher confidence slot has higher probability but selection is stochastic). Accumulated reward: Vtotal = 0.82, = 1. Iteration 2: With remaining slots {2, 4}: Sample = 4. Update: Vtotal = 1.45, = 2. p2 = 0.411, p4 = 0.589 Iteration 3: Only slot 2 remains, select deterministically. Final: Vtotal = 1.90, = 3. Return: (s) = 1.90/3 = 0.633, representing the expected quality of completing generation from this state. This stochastic sampling enables the rollout to explore different completion paths, capturing the models uncertainty about optimal slot ordering. C. Experimental Setup C.1. Additional Implementation Details To ensure fair comparison across all methods, we maintain consistent hyperparameters throughout our experiments. All models use an evaluation length of 512 tokens following the configuration from (Li et al., 2025), with increasing token to Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models 1024 for MBPP due to task complexity. We employ greedy decoding with temperature 0.0 across all settings, with zero-shot learning. For ReFusion (Li et al., 2025), we adopt the default configuration: slot size 8, 2 serial blocks, slot threshold 0.9, and token threshold 0.9. For MCDIFFUSE, we configure 30 MCTS simulations, slot size 4, 32 serial blocks, slot threshold 0.5, token threshold 0.6, and exploration constant = 10.0. Autoregressive baselines employ greedy decoding with temperature 0.0 and top p=1.0. All evaluations are conducted on 4 NVIDIA H100 GPUs. We average all across 3 seeds for consistency, using Seed = 21, 42, 84. C.2. Additional Hyperparameter Tuning We further perform an additional hyperparameter tuning on the temperature, τ , and λ. However, due to computational cost, we are unable to find the optimal grid search using all four hyperparameters stated in Section 6. We take hyperparameter tuning of cpuct of 50.0 with simulation of 256 to find the optimal budget. We perform the hyperparameter tuning on MATH-500 dataset. Table 3. Grid Search Results for MATH500: Accuracy (%) by τ and λ τ λ 0.0 0.3 0.5 0.7 0.9 1. 0.1 0.3 0.5 0.7 1.0 43.20 44.80 45.60 45.00 43.60 44.40 47.00 48.20 47.20 44.80 43.80 46.20 47.20 46.40 44.20 44.00 46.40 47.40 46.60 44.20 43.40 45.20 45.80 45.40 43. 43.00 44.60 44.80 44.20 43.00 Based on the table, we can observe that the best hyperparameter tuning lies on τ = 0.5, and λ = 0.3. This is because strikes critical balance in the exploration-exploitation trade-off: it introduces sufficient stochasticity to prevent the search from converging prematurely on local optima (a failure mode observed at lower temperatures), while maintaining enough coherence to avoid the semantic degeneration typical of higher entropy distributions. Furthermore, λ = 0.3 indicates that the value estimation benefits significantly from prioritizing long-term rollout feedback over immediate confidence. In our formulation, lower λ shifts the weight towards the Monte Carlo rollout return rather than the immediate policy prior. This suggests that for complex mathematical reasoning, the verifiability of full solution path (the rollout) is more reliable signal than the models local token probabilities, though the immediate confidence remains necessary as regularizing prior to guide the initial search direction. D. Experimental Results and Tests D.1. Analysis Between Token Length and Accuracy Table 4. Token efficiency and accuracy comparison between MCDIFFUSE and Qwen2.5-7B across benchmark datasets. All reductions are statistically significant (p < 0.001). Token Count Accuracy (%) Dataset MCDIFFUSE Qwen2.5 Reduction MCDIFFUSE Qwen2.5 Improvement MBPP ARC MATH500 GSM8K GPQA HumanEval 44.0 91.3 152.2 184.0 34.6 63.6 368.2 88.05% 332.8 72.55% 436.0 65.08% 276.2 33.39% 534.3 93.53% 256.3 75.19% 72.43 88.40 48.40 88.63 34.78% 78.37% 64.04 87.88 46.00 86.43 16.94% 71.78% +8.39 +0.52 +2.40 +2.20 +17.84 +6.59 Table 4 demonstrates that MCDIFFUSE achieves significant improvements in both token efficiency and accuracy compared to the autoregressive baseline. Across all benchmarks, MCDIFFUSE reduces token consumption by an average of 64.77% (p < 0.001) while simultaneously improving accuracy by 3.38% percentage points. The efficiency gains are particularly great on code generation tasks, with MBPP exhibiting an 88.05% token reduction alongside an 8.39% improvement. This 14 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models pattern suggests that MCDIFFUSE is especially effective at identifying compact reasoning paths for structured generation tasks. Even on datasets where accuracy improvements are modest (e.g., ARC with +0.52%), the token reduction remains substantial at 72.55%, indicating that MCDIFFUSE consistently produces more concise solutions without sacrificing correctness. The inverse relationship between token reduction and task complexity is evident: while MBPP and ARC show the largest reductions (88.05% and 72.55% respectively), GSM8K exhibits more moderate 33.39% reduction, likely due to the sequential nature of multi-step arithmetic reasoning. Nevertheless, the consistent improvements across all benchmarks validate that MCTS-guided slot selection enables more efficient exploration of the solution space compared to purely confidence-based ordering. Figure 5 provides clear visualisation of the token reduction. Figure 5. Comparison of token reduction across models. We observe that MCDIFFUSE significantly reduces tokens while generating responses, demonstrating the compactness and coherence of using MCDIFFUSE. D.2. Task-Specific Improvements To investigate whether MCTS-based slot planning benefits different task types differentially, we analyse the absolute accuracy improvements from ReFusion to MCDIFFUSE across our evaluation benchmarks. Coding tasks (MBPP, HumanEval) demonstrate substantially larger improvements compared to reasoning and multiple-choice tasks. As shown in Table 5, this difference is statistically significant (t = 2.97, = 0.041, Cohens = 3.21), with coding tasks exhibiting 3.13 higher improvements. We observe similar behaviour with Qwen3, given its similar architecture to Qwen2.5. This suggests that MCTS-based planning particularly benefits domains with strict structural dependencies, such as variable declarations, function definitions, and control flow sequences, where slot ordering critically affects semantic validity. Table 5. Statistical comparison of MCTS improvements between coding and non-coding tasks. Metric Values Difference t-statistic p-value Cohens Significance 7.43% (3.13) 2.97 0.041 3.21 < 0.05 D.3. Impact of Extended Token Length on Autoregressive Models We compare the total completion token lengths between autoregressive models and MCDIFFUSE. Specifically, we evaluate Qwen2.5 7B, Qwen3 8B, and MCDIFFUSE by extending their maximum token lengths to match their respective baselines: 32,768 tokens for both Qwen2.5 and Qwen3, and 1,024 tokens for ReFusion. Due to the nature of ReFusion and other existing MDMs (Nie et al., 2025; Zhao et al., 2025; Zhu et al., 2025; Li et al., 2025; Gong et al., 2025), the models reasoning capabilities could not be extended for fair comparison; however, we acknowledge that investigating token length extensions for diffusion-based models represents promising direction for enhancing LLM reasoning capabilities. We restrict our analysis to MATH500, GSM8K, and GPQA-Diamond, as these are the only benchmarks mentioned in Section 4 with incomplete baseline results. 15 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models Table 6. Comparison of ReFusion-MCTS, Qwen2.5, and Qwen3 benchmarks. Model Context GSM8K MATH500 GPQA MCDIFFUSE Llama3.1 7B Qwen2.5 7B Qwen3 8B 1024 8096 32768 32768 90.63% 84.91% 89.99% 88.17% 37.19% 54.60% 37.71% 39.40% 63.40% 35.94% 68.00% 41.96% Table 6 demonstrates that MCDIFFUSE achieves competitive performance while using significantly fewer tokens (1024 vs 32,768). Specifically,MCDIFFUSE marginally outperforms both Qwen2.5 7B and Qwen3 8B on GSM8K. On GPQA,MCDIFFUSE surpasses Qwen2.5 but underperforms relative to Qwen3 8B. However, MCDIFFUSE exhibits weaker performance on MATH500, benchmark requiring complex mathematical reasoning. Extending ReFusion to 4096 tokens leads to the same performance. In this case, we attribute this limitation to the inherent constraint of ReFusion and existing diffusion models, which cannot generate sequences beyond their predetermined token limit. We hypothesise that extending the maximum token length of diffusion-based models could substantially improve their reasoning capabilities. Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models E. Example of ReFusion Generation Length Correspond To Autoregressive E.1. Example 1 McDiffuSE Generation (Correct, 278 tokens) Question: merchant wants to make choice of purchase between 2 purchase plans: jewelry worth $5,000 or electronic gadgets worth $8,000. His financial advisor speculates that the jewelry market will go up 2.5% while the electronic gadgets market will rise 1.2% within the same month. If the merchant is looking to maximise profit at the end of this month by making choice, how much profit would this be? Ground Truth: 125 Generated Solution: Step 1: Calculate the future value of the jewelry purchase. Future value = Current value + (Current value Percentage increase) Future value = $5,000 + ($5,000 0.025) = $5,000 + $125 = $5,125 Step 2: Calculate the future value of the electronic gadgets purchase. Future value = $8,000 + ($8,000 0.012) = $8,000 + $96 = $8,096 Step 3: Calculate the profit for each purchase plan. For the jewelry purchase: Profit = $5,125 - $5,000 = $125 For the electronic gadgets purchase: Profit = $8,096 - $8,000 = $96 Step 4: Compare the profits and choose the purchase plan with the highest profit. The jewelry purchase has higher profit of $125 compared to the electronic gadgets purchase with profit of $96. The final answer is: $125 Answer: Qwen2.5-7B Generation TRUNCATED (512 tokens) Generated Solution (Truncated): Step 1: Calculate the value of the jewelry after the market increase Initial value of jewelry: $5,000 Speculated market increase: 2.5% First, convert the percentage increase to decimal: 2.5% = 2.5 Next, calculate the increase in value: Increase in value = 5000 0.025 = 125 Finally, add the increase to the initial value: Final value of jewelry = 5000 + 125 = 5125 Step 2: Calculate the value of the electronic gadgets after the market increase 100 = 0. Initial value of electronic gadgets: $8,000 Speculated market increase: 1.2% First, convert the percentage increase to decimal: 1.2% = 1.2 Next, calculate the increase in value: Increase in value = 8000 0.012 = 96 Finally, add the increase to the initial value: Final value of electronic gadgets = 8000 + 96 = 8096 Step 3: Determine the profit for each purchase Profit from jewelry: Profit = 5125 5000 = 125 Profit from electronic gadgets: Profit = 8096 8000 = 96 Step 4: Compare the profits Since $125 > $96, the merchant should choose to purchase the jewelry to [TRUNCATED] 100 = 0.012 17 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models E.2. Example 2 McDiffuSE Generation (Correct, 319 tokens) Question: Which of the following actions will increase the gravitational force between two masses, m1 and m2, by the greatest amount? Ground Truth: r2 Generated Solution: The gravitational force between two masses is given by the formula = m1m2 , where is the gravitational constant, m1 and m2 are the masses, and is the distance between the masses. To increase the gravitational force, we need to increase the numerator (m1 m2) and decrease the denominator (r2). Option (A): Halving the mass of m1 and halving the distance between m1 and m2 will decrease the numerator by half and decrease the denominator by quarter, resulting in net decrease in the gravitational force. Option (B): Halving the mass of m1 and doubling the distance between m1 and m2 will decrease the numerator by half and increase the denominator by quarter, resulting in net decrease in the gravitational force. Option (C): Doubling the mass of m1 and halving the distance between m1 and m2 will increase the numerator by factor of 2 and decrease the denominator by quarter, resulting in net increase in the gravitational force. Option (D): Doubling the mass of m1 and doubling the distance between m1 and m2 will increase the numerator by factor of 2 and increase the denominator by quarter, resulting in net increase in the gravitational force. Comparing the options, we can see that option (C) will result in the greatest increase in the gravitational force, as it increases the numerator by factor of 2 and decreases the denominator by quarter. The final answer is: Answer: Qwen2.5-7B Generation TRUNCATED (512 tokens) Generated Solution (Truncated): To determine which action will increase the gravitational force between two masses, m1 and m2, by the greatest amount, we need to consider the formula for gravitational force: = m1m2 r2 where is the gravitational force, is the gravitational constant, m1 and m2 are the masses, and is the distance between the centres of the two masses. Lets analyse each option step by step: Option (A): Halve the mass of m1 and halve the distance between m1 and m2. New force: = m1 2 m2 (cid:0) (cid:1)2 = m1m2 2 r2 4 = m1m2 2 4 r2 = 2 m1m2 r2 = 2F The force is doubled. Option (B): Halve the mass of m1 and double the distance between m1 and m2. New force: = m1 2 m2 (2r)2 = m1m2 4r2 = 1 8 m1m2 r2 = 1 The force is reduced to one-eighth. Option (C): Double the mass of m1 and halve the distance between m1 and m2. New force: = 2m1 m2 (cid:0) 2 (cid:1)2 = 2m1m2 r2 = 8 m1m2 [TRUNCATED] 18 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models E.3. Example 3 McDiffuSE Generation (Correct, 403 tokens) Question: Find all values of that satisfy the equation = Ground Truth: = 5 11 2x + 4. Generated Solution: To solve the equation = Step 1: Isolate the square root term 11 2x + 4, we will first isolate the square root term and then square both sides of the equation to eliminate the square root. = 11 2x + 4 4 = 11 2x Step 2: Square both sides of the equation (x 4)2 = (cid:0) 11 2x(cid:1)2 x2 8x + 16 = 11 2x Step 3: Rearrange the equation to form quadratic equation x2 8x + 16 11 + 2x = 0 x2 6x + 5 = 0 Step 4: Solve the quadratic equation x2 6x + 5 = 0 (x 1)(x 5) = 0 = 1 or = Step 5: Check the solutions in the original equation = 1 : 1 = = 5 : 5 = (cid:113) (cid:113) 11 2(1) + 4 1 = 11 2(5) + 4 5 = 9 + 4 1 = 3 + 4 1 = 7 (False) 1 + 4 5 = 1 + 4 5 = 5 (True) The final answer is: 5 Answer: Qwen2.5-7B Generation TRUNCATED (512 tokens) Generated Solution (Truncated): To solve the equation = 1. Isolate the square root term: 11 2x + 4, we will follow these steps: 2. Square both sides to eliminate the square root: Simplifying both sides: 3. Expand the left-hand side: 4. Move all terms to one side to form quadratic equation: Simplifying: 5. Factor the quadratic equation: 6. Solve for x: 4 = 11 2x (x 4)2 = ( 11 2x)2 (x 4)2 = 11 2x x2 8x + 16 = 11 2x x2 8x + 16 11 + 2x = 0 x2 6x + 5 = 0 (x 1)(x 5) = 0 1 = 0 or 5 = 0 = 1 or = 7. Verify the solutions by substituting them back into the original equation: For = 1: (cid:113) 11 2(1) + 4 1 = 9 + 4 1 = 3 + 4 1 = 7 So, = 1 is not solution. For = 5: 1 = (cid:113) 11 2(5) + 4 5 = 5 = 1 + 4[TRUNCATED] 19 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models F. Complete MCTS Example Walkthrough F.1. Problem Setup We demonstrate the MCTS algorithm on MATH500 problem with 4 remaining slots to fill. The model provides slot confidences: R(s, 0) = 0.35, R(s, 1) = 0.78, R(s, 2) = 0.52, R(s, 3) = 0.41. F.2. Simulation 1: Initial Exploration Selection: Start at ROOT (leaf node, no children). Expansion: Compute priors by normalizing confidences: (a s) = R(s, a) R(s, a) (cid:80) (a = 0 s) = 0.35/2.06 = 0.170, (a = 1 s) = 0.379, (a = 2 s) = 0.252, (a = 3 s) = 0. Create 4 children. Select child with highest PUCT: PUCT(a) = Q(s, a) + (a s) PUCT(slot 1) = 0 + 1.4 0.379 = 0.531 (max) (cid:112)N (s) 1 + (s, a) 1 1 + 0 Simulation: Perform stochastic rollout from state with slot 1 filled: Immediate reward: r1 = 0.78 Rollout: Sample slots {2, 3, 0} stochastically, collect rewards {0.52, 0.41, 0.35} Rollout value: Vrollout = (0.52 + 0.41 + 0.35)/3 = 0.427 Combined: = 0.3 0.78 + 0.7 0.427 = 0. Backpropagation: Update Child1 and ROOT: (Child1) = 1, Q(Child1) = 0.533 F.3. Simulation 2: Deepening the Tree Selection: Recompute PUCT at ROOT with (ROOT) = 1: PUCT(slot 0) = 0 + 1.4 0.170 2 1 PUCT(slot 1) = 0.533 + 1.4 0.379 = 0.337 2 2 = 0.909 (max) Select Child1 again (highest PUCT despite 1 visit). Expansion: Child1 is now leaf with filled slots {1}. Expand with remaining slots {0, 2, 3}, creating 3 grandchildren. Simulation & Backpropagation: Select Child1,2 (slot 2 after slot 1), perform rollout, get reward 0.422. Backpropagate to Child1,2, Child1, and ROOT. 20 Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models F.4. Final Selection After 4 simulations, the tree has visit counts: Visits = {slot 0 : 1, slot 1 : 2, slot 2 : 1, slot 3 : 0} Decision: Select slot 1 (most visits). F.5. Key Observation Although slot 1 had the highest initial confidence (0.78), MCTS confirmed this choice through exploration: rollouts from state {1} consistently found high-value completion paths, increasing confidence that slot 1 is the optimal first choice. G. Analysis Between Sequence Rate and accuracy Figure 6. Plot with axis being the sequential rate and axis being the accuracy. ReFusion exhibits positive correlation between sequential rate and accuracy, whilst MCDIFFUSE achieves optimal performance at approximately 90% of sequential generation. This demonstrates that while predominantly sequential ordering is beneficial, strategic non-sequential generation leads to improved performance, mirroring human behaviour in coding tasks. Figure 6 demonstrates comparative analysis of sequential slot selection behaviour and its relationship to accuracy on the MBPP code generation benchmark for both ReFusion (baseline) and MCDIFFUSE. The baseline ReFusion method (left panel, 58.81% accuracy) shows weak positive correlation between sequential ordering and task success. In contrast, MCDIFFUSE (right panel, 72.43% accuracy) demonstrates more strategic approach while achieving substantially higher accuracy. The trend lines reveal that both methods benefit from sequential structure to some degree, consistent with code generations inherent ordering dependencies (e.g., variable declarations preceding usage); however, MCTSs selective deviation from strict left-to-right generation (8.2% non-sequential exploration) enables it to avoid error propagation and handle complex logical dependencies more effectively. This strategic flexibility, rather than rigid adherence to sequential ordering, accounts for the performance gain, validating the hypothesis that optimal slot planning must adaptively balance sequential structure with non-sequential exploration. H. More Efficiency Analysis of MCDIFFUSE In this section, we further answer the question: what is the overhead caused by MCTS-Based Slot Planning?. We compare the generation time of ReFusion with and without MCTS-based slot planning. As shown in Figure 7, generation time scales approximately linearly with the number of simulations Nsim. In contrast, varying the exploration constant causes negligible overhead, as it only affects the selection criterion without requiring additional forward passes. This observation suggests that as expected computational cost is controlled primarily through the simulation budget. The data reveals an accuracy-efficiency trade-off. While the highest accuracy is achieved with Nsim = 270, the improvement Can Have Your Order? MCTS for Slot Filling Ordering in Diffusion Language Models (a) MBPP coding tasks (b) MATH500 mathematical tasks Figure 7. Accuracy versus generation time across different hyperparameter settings on coding and mathematical reasoning tasks. over Nsim = 30 is marginal (typically < 2%), whereas the computational cost increases ninefold. This supports our earlier finding that simulation budgets suffice when exploration is adequate. Although MCTS introduces additional overhead compared to the baseline ReFusion inference, high-exploration, low-budget configuration (e.g., = 100, Nsim = 30) achieves substantial accuracy gains, such as 13.62% improvement on MBPP, while maintaining reasonable inference time. Hardware details are provided in in Section C.1. In addition to the analysis of coding tasks as show in Figure 7b, we present the analysis using mathematical task MATH500 in Figure 7a. The results show similar trend: there is clear linear relationship between the number of simulations Nsim and computational time, while the exploration constant incurs negligible overhead. I. More Analysis on The Impact of Exploration and Simulation Budget In addition to the analysis of coding tasks as shown in Figure 2, we provide the MATH500 mathematical reasoning task in Figure 8. We found similar trend with coding tasks, where higher exploration constant obtains higher accuracy. Figure 8. Impact of exploration constant (cpuct) and simulation budget on task performance on MATH500 mathematical reasoning tasks."
        }
    ],
    "affiliations": [
        "Imperial College London",
        "University of Edinburgh"
    ]
}