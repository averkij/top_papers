{
    "paper_title": "The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang",
    "authors": [
        "Fenghua Liu",
        "Yulong Chen",
        "Yixuan Liu",
        "Zhujun Jin",
        "Solomon Tsai",
        "Ming Zhong"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) achieve gold-medal performance across many benchmarks, yet it remains unclear whether such success reflects genuine reasoning or pattern matching. From a cognitive science perspective, an informative test is whether models can master an unfamiliar language through explicit metalinguistic deductive learning, a paradigm where human learners can reliably internalise grammatical systems through metalinguistic reasoning. We address this question with Camlang, a novel constructed language that exhibits naturalistic yet unattested feature combinations. Camlang consists of two explicit resources, a grammar book and a bilingual dictionary, which mirror adult second-language learning via explicit grammar rules and lexical lookup, and enable us to disentangle errors in morpho-syntax, lexical semantics, and sentence-level reasoning. Human experiments show that these resources are sufficient for participants to acquire Camlang and successfully solve Camlang tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang, creating Camlang-CSQA-v0, the first task in a broader suite where solving questions requires applying grammar rules and lexical mappings. Experimental results show that GPT-5 achieves 98\\% EM accuracy in English but only 47\\% in Camlang, far below human performance at 87\\%, while other state-of-the-art reasoning LLMs perform even worse. Human verification further reveals that most model successes stem from shallow lexical alignment while GPT-5 shows emerging metalinguistic awareness to a limited extent but not systematic grammatical mastery as humans. Camlang establishes a cognitively grounded evaluation paradigm that exposes fundamental gaps between current models and human metalinguistic competence."
        },
        {
            "title": "Start",
            "content": "Working in Progress The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang Fenghua Liu1 Yulong Chen1 Yixuan Liu2 Zhujun Jin1 Solomon Tsai1 Ming Zhong3 1 University of Cambridge fl457@cam.ac.uk 2 University of Oxford 3 UIUC yc632@cam.ac.uk 5 2 0 A 0 3 ] . [ 1 5 2 4 0 0 . 9 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) achieve gold-medal performance across many benchmarks, yet it remains unclear whether such success reflects genuine reasoning or pattern matching. From cognitive science perspective, an informative test is whether models can master an unfamiliar language through explicit metalinguistic deductive learning, paradigm where human learners can reliably internalise grammatical systems through metalinguistic reasoning. We address this question with Camlang, novel constructed language that exhibits naturalistic yet unattested feature combinations. Camlang consists of two explicit resources, grammar book and bilingual dictionary, which mirror adult second-language learning via explicit grammar rules and lexical lookup, and enable us to disentangle errors in morpho-syntax, lexical semantics, and sentence-level reasoning. Human experiments show that these resources are sufficient for participants to acquire Camlang and successfully solve Camlang tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang, creating CamlangCSQA-v0, the first task in broader suite where solving questions requires applying grammar rules and lexical mappings. Experimental results show that GPT-5 achieves 98% EM accuracy in English but only 47% in Camlang, far below human performance at 87%, while other state-of-the-art reasoning LLMs perform even worse. Human verification further reveals that most model successes stem from shallow lexical alignment while GPT-5 shows emerging metalinguistic awareness to limited extent but not systematic grammatical mastery as humans. Camlang establishes cognitively grounded evaluation paradigm that exposes fundamental gaps between current models and human metalinguistic competence. Note: This ArXiv paper presents ongoing work. The current experimental results are preliminary, based on our existing data. We may further revise Camlang and will extend the tasks in our benchmark, perform additional experiments, and update the analysis in future versions."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) have performed remarkably in language tasks, demonstrating versatility and adaptability (Meta, 2024; OpenAI, 2023; 2024; DeepSeek-AI, 2025; OpenAI, 2025). Yet, fundamental question arising from this observed performance remains unresolved: are these models truly competent in understanding human language, or are they merely performing statistical pattern matching from their massive training corpora? This debate is central to both AI and cognitive science, and has sparked discussion on whether modern LLMs possess human-like understanding and reasoning (Chomsky et al., 2023; Hinton, 2024). Validating such claims requires an evaluation setting where success cannot be gauged exclusively through memory or recalling patterns from training data, but instead depends on the ability to acquire and apply linguistic competence through an understanding of the underlying systems which constitute natural languages. 1 Working in Progress One natural way to test this ability is to present LLMs in language they have never encountered before, mirroring the explicit rulebased learning scenarios found in human second language (L2) acquisition (Klein, 1986; Ellis, 2005). Cognitive science research shows that adult learners can successfully acquire grammatical rules and vocabulary of new language and apply them to novel cases when they use their native language as an explanatory medium (Lichtman, 2012; Rebuschat & Williams, 2012).1 Such success builds on their domain-general reasoning and metalinguistic skills, which enable learners to systematically internalise the explicitly presented rules and map the new vocabulary onto pre-existing knowledge in the mental lexicon (Gombert, 1992; Bialystok, 2001b; Nagy, 2007). Controlled experiments in psycholinguistics and neuroscience further show that human adults can acquire unfamiliar language systems from grammar rules, and subsequently integrate these rules with their existing semantic and reasoning abilities (Reber, 1967; Kim et al., 1997; Musso et al., 2003). This leads to the central question of this paper: can LLMs learn and use an unseen language when given only explicit grammar rules and vocabulary like human learners? Existing LLM evaluation protocols are ill-suited to investigate this question. Most LLM benchmarks are built for English (Wang et al., 2018; 2019; Talmor et al., 2019; Chen et al., 2024) and thus inevitably share real-world linguistic distributions with pre-training data (Balloccu et al., 2024), making it difficult to distinguish the application of linguistic knowledge and reasoning from pattern matching. Even evaluations on extremely low-resource or endangered languages are prone to data leakage (Artetxe et al., 2020; Chen et al., 2023b; Zhang et al., 2024), due to the fact that their grammar books, dictionaries, and sample texts are often well-documented and publicly available online.2 While potential alternative is to train an LLM exclusively on one language (e.g., English) and test it on another (e.g., Mandarin Chinese) to ensure novelty in the tested language (Chirkova & Nikoulina, 2024), this is impractical for modern LLM systems. Most state-of-the-art LLMs are inherently multilingual (Katz et al., 2024; DeepSeek-AI, 2025), and training fully monolingual model solely for this evaluation would be prohibitively costly. It would also limit the models general capabilities, making the results less informative about the potential of leading systems (Qorib et al., 2025). In this work, we introduce Camlang, typologically novel constructed language. Camlang is constructed through principled design process that combines typologically attested features in novel configuration and encodes them in two explicit resources: grammar book and bilingual dictionary. The grammar book specifies phonological, morphological, and syntactic rules, while the dictionary provides lexicon generated and expanded via controlled mechanisms (root generation, derivation, compounding, and loans), ensuring that the language is both plausible and learnable for humans and computational models. Camlang offers three key advantages. First, the novelty ensures that evaluation cannot be reduced to recalling seen distributions, but instead tests whether models can generalise linguistic competence to genuinely unfamiliar system. Second, the grammarlexicon separation enables fine-grained diagnosis of model behaviour, making it possible to distinguish failures of structural parsing from those of semantic interpretation or lexical lookup. Furthermore, human learnability guarantees that the benchmark reflects cognitively realistic language acquisition, providing meaningful point of comparison between human learners and models. Together, these properties make Camlang cognitively grounded and leakage-free benchmark for testing whether LLMs can go beyond statistical pattern recognition and engage in explicit deductive language learning. Using the Camlang grammar book and EnglishCamlang dictionary, we construct small test set, Camlang-CSQA-v0, by manually translating questions and answers from CommonsenseQA (Talmor et al., 2019) into Camlang. Since LLMs already excel at CommonsenseQA in English (Krause & Stolzenburg, 2023; Davis, 2023), the bottleneck of Camlang-CSQA-v0 shifts from commonsense reasoning to applying explicit grammar rules and lexical mappings. The resulting dataset allows us to isolate the ability to integrate newly learned 1Note this is opposed to infant bi-/multi-lingual acquisition (Williams & Rebuschat, 2016; Hummel, 2021), which typically relies on natural, implicit linguistic stimulus from the environment. 2Such as Kalamang: https://langsci-press.org/catalog/book/344. 2 Working in Progress grammatical knowledge with pre-existing world knowledge in controlled setting, directly paralleling explicit second-language learning in human adults, and serves as pilot benchmark for scaling Camlang to broader evaluation tasks. Our experiments compare multiple state-of-the-art reasoning LLMs, including GPT-5 (OpenAI, 2025) and DeepSeek-R1 (DeepSeek-AI, 2025), with human participant. Results reveal sharp contrast: while models achieve 8598% EM accuracy on the English version, their performance drops sharply to 2147% on Camlang. The human participant reaches nearnative accuracy (87%) using only the grammar and dictionary, which also demonstrates the practical learnability of Camlang. This suggests that, unlike human learners who naturally integrate dictionary lookup into their reasoning pipeline, current LLMs struggle to operationalise external resources when faced with Camlangs morphological complexity, often defaulting to internal pattern matching. Human verification further reveals an important nuance that GPT-5s reasoning traces are more often incomplete rather than incorrect, indicating degree of metalinguistic awareness and partial rule-following ability, while it falls short of systematic grammatical mastery. In contrast, other LLMs, such as DeepSeek-R1 and GPT-o3 (OpenAI, 2024), show little evidence of such awareness, with most of their successes attributable to shallow lexical alignment. Together, these findings establish Camlang as both reliable diagnostic resource and controlled benchmark for probing reasoning in unfamiliar languages. In summary, the contribution of this paper includes: It introduces typologically plausible yet novel language, equipped with grammar book and dictionary. We provide cognitive grounding by empirically validating Camlans learnability through human experiments. By adapting CommonsenseQA into Camlang, we test not only grammatical rule acquisition but also the integration of explicit rules with commonsense reasoning. We complement standard EM accuracy with human verification of reasoning traces, exposing the reliance of LLMs on shallow alignment rather than genuine metalinguistic deductive reasoning. Beyond Camlang-CSQA-v0, we are currently extending Camlang to broader suite of tasks (e.g., translation, parsing, and mathematical reasoning) and are exploiting its explicit grammar and dictionary for fine-grained diagnostic analyses, such as error localisation, rule generalisation, and learning-curve studies, ultimately establishing Camlang as versatile testbed for probing the limits of LLM reasoning and their convergence with, or divergence from, human-like linguistic intelligence."
        },
        {
            "title": "2 Related Work",
            "content": "2.1 Natural Language Evaluation and Benchmarks Early benchmarks such as GLUE (Wang et al., 2018), SuperGLUE (Wang et al., 2019), and CommonsenseQA (Talmor et al., 2019) focus on general natural language understanding (NLU) and knowledge reasoning. While initially challenging, these benchmarks have been soon surpassed at human-level performance by LLMs (Chen et al., 2023a; Hu et al., 2024; OpenAI, 2024; Wang et al., 2025), motivating the development of more challenging benchmarks that target multi-step reasoning and specialised knowledge (Hendrycks et al., 2021; Srivastava et al., 2023; Patel et al., 2024; Gao et al., 2024; Chen et al., 2024). Subsequent evaluations focused on tasks that are challenging even for human experts, yet where LLMs have demonstrated remarkable success, such as the U.S. Bar Exam (Katz et al., 2024), USMLE (Kung et al., 2023), MATH (Hendrycks et al., 2021), AIME (AIME, 2025), and even International Mathematical Olympiad problems. While these results are impressive, they are all conducted in familiar natural languages and established task formats, allowing LLMs to exploit potential memorisation or pattern In contrast, our work employs controlled constructed matching from training data. 3 Working in Progress language to eliminate prior exposure, enabling cleaner assessment of models ability to learn and apply entirely new linguistic and reasoning rules from scratch. 2.2 Artificial, Constructed, and Programming Languages in NLP Constructed language (Conlang) in cognitive science has long been used to study how humans acquire grammatical structure from limited exposure (Reber, 1967; Marcus et al., 1999). Inspired by these paradigms, NLP researchers have proposed controlled synthetic benchmarks such as SCAN (Lake & Baroni, 2018), NACS (Bastings et al., 2018), and gSCAN (Ruis et al., 2020) to evaluate compositional generalisation of NLP systems. More recently, White & Cotterell (2021) and Hopkins (2022) use artificial languages to probe the inductive biases of neural language models and to improve ecological validity, respectively. Kallini et al. (2024) extend this line of work by creating impossible languages via systematic violations of linguistic universals, demonstrating that LLMs learn naturalistic languages far more efficiently than impossible ones. In contrast, our Camlang is deliberately designed to be typologically plausible yet absent from attested natural languages, ensuring novelty without introducing unnatural structures. This allows us to test whether LLMs can integrate explicitly presented grammatical rules with pre-existing semantic and commonsense reasoning to solve downstream tasks, moving beyond pure grammatical learnability to functional language use. Beyond artificial grammars, programming languages have also been used as testbeds for evaluating LLMs rule-following and compositional abilities (Chen et al., 2021; Li et al., 2022). While such languages provide fully formal and unambiguous setting, they differ fundamentally from natural language: programming languages are intentionally engineered for executability and determinism, lacking paraphrastic variation, pragmatic inference, and the typological diversity of human languages (Clark, 1996; Allamanis et al., 2018; Chomsky, 2014). In contrast, our Camlang is designed to be typologically plausible and naturalistic while still controlled, enabling us to probe whether LLMs can integrate explicit grammatical instruction with semantic and commonsense reasoning in way that is closer to natural language learning. Most importantly, the emphasis on naturalness distinguishes our approach from the above systems. If constructed language were based on unattested or linguistically implausible rules (Kallini et al., 2024), the evaluation would risk collapsing into test of symbol manipulation rather than language learning, producing results that are uninterpretable for both cognitive and NLP perspectives. By ensuring that Camlangs grammatical features are all attested in human languages and that their combinations respect known typological constraints, we guarantee that it remains within the distribution of humanly possible languages. This design choice makes our evaluation cognitively comparable to adult second-language learning and scientifically credible as evidence of whether LLMs can acquire and apply genuine linguistic competence from explicit description. 2.3 Cross-lingual Evaluation on Low-resource Languages Evaluation of LLMs on low-resource languages has relied on multilingual benchmarks such as XQuAD (Artetxe et al., 2020), TyDi QA (Clark et al., 2020), and FLORES (Guzman et al., 2019), as well as task-specific datasets in certain low-resource languages (Adebara & Abdul-Mageed, 2022; Chen et al., 2023b; Zhang et al., 2025). While these datasets cover broad range of typologically diverse languages, many are derived from publicly available sources such as Wikipedia, parallel corpora, or well-documented analyses and dictionaries. This leads to the data leakage problem that example sentences may have been seen during model pre-training (Carlini et al., 2023; Dong et al., 2023), allowing models to recall rather than genuinely learn the target language. Recent work has turned to controlled settings based on Olympiad-in-Linguistics-style puzzles and unseen-language tasks (Chi et al., 2024; Goyal & Dan, 2025; Zhang et al., 2024; Lian et al., 2025), which construct problems from scratch to test grammatical rule induction from minimal examples. However, these puzzles often focus on isolated phenomena without providing coherent, system-wide grammar. In contrast, our Camlang offers 4 Working in Progress fully specified, typologically plausible yet unattested language with systematic grammar and lexicon, enabling controlled and repeatable evaluation of whether LLMs can learn and consistently apply explicit grammatical rules, and integrate them with pre-existing commonsense knowledge in downstream reasoning tasks. 2.4 Human Adults Language Learning and Metalinguistic Skills Second-language acquisition research shows that adults are capable of learning grammatical rules through explicit instruction (Krashen, 1982; Ellis, 2005). Metalinguistic awarenessthe ability to reflect on and manipulate linguistic formhas been shown to facilitate grammar learning (Tunmer & Herriman, 1984; Thomas, 1992; Nagy & Anderson, 1995), particularly among bilinguals (Bialystok, 2001a). Psycholinguistic studies further demonstrate that learners can acquire novel morphosyntactic systems from written descriptions alone, and then apply these rules in new contexts by integrating them with existing semantic and reasoning abilities. In NLP, recent work has examined whether LLMs can similarly make use of explicit linguistic descriptions. For example, prior work has shown that prompting LLMs to generate grammatical explanations (Scheinberg et al., 2025) or providing them with grammar books and dictionaries (Behzad et al., 2024; Hus & Anastasopoulos, 2024; Zhang et al., 2024) can improve performance on grammar judgment and low-resource translation tasks. Compared to them, our work greatly differs in two ways. First, instead of relying on existing natural languages, where partial exposure through pre-training cannot be excluded, we use Camlang, fully constructed, typologically plausible yet unattested language, ensuring zero data contamination. Second, our grammar book is complete and systematically designed, covering multiple levels of linguistic structure and enabling targeted assessment of whether LLMs can internalise and consistently apply explicit grammatical rules. By integrating this with commonsense reasoning tasks, we create controlled setting to test whether LLMs can combine newly learned linguistic rules with pre-existing world knowledge for functional language use."
        },
        {
            "title": "3 The Camlang Language",
            "content": "Camlang is constructed language designed to evaluate whether LLMs can understand and apply new linguistic knowledge from explicit rules, rather than from prior pre-trained knowledge. In this work, the term constructing the language refers specifically to the creation of two resources: grammar book, written in English with Camlang samples, that systematically describes the phonology, morphology, syntax, and other aspects of the language, and an EnglishCamlang bilingual dictionary, covering all relevant lexical stems used in the evaluation tasks.3 Note that we describe Camlang as an unseen language not because each of its individual linguistic features is unattested in other natural languages, but because the combination of features in Camlang is, to the best of our knowledge,4 absent from any known language. The subsequent subsections provide detailed description of the Camlang language and its construction. We first introduce the design principles of Camlang in 3.1. Then, we detail our construction and implementation in 3.2. In 3.3, we present high-level linguistic description of the language, focusing on its major phonological, morphological, and syntactic characteristics. Finally, in 3.4, we provide an empirical evaluation of Camlang in broader context, demonstrating its clarity, learnability and novelty as naturalistic system while confirming that it is distinct from other known languages. 3Unless otherwise specified, in the later sections, the terms grammar book and dictionary refer to the Camlang resources we create. 4We acknowledge the possibility that language similar to Camlang may exist or have existed, but has not been documented in the linguistic record to our knowledge. 5 Working in Progress 3.1 Design Principles and Philosophies As stated, our goal is to simulate adult language learning for new language in order to evaluate the reasoning abilities of LLMs. To serve this purpose, the language must reasonably resemble genuine human languages rather than arbitrary symbol systems (Kallini et al., 2024), which makes naturalness primary consideration. If the grammar were constructed with arbitrary, unattested rules, the evaluation would reduce to symbol-manipulation game rather than meaningful simulation of language learning. In such cases, both humans and models can fail simply because the rules are unnatural or even unlearnable, making results uninterpretable. At the same time, Camlang should be sufficiently rich to cover diverse grammatical phenomena, novel enough to avoid coinciding with attested languages, and compositional so that its rules apply systematically and productively. Thus, the development of Camlang is driven by the below principles: Naturalness, to ensure plausibility as human language; Richness, to cover wide spectrum of grammatical phenomena; Novelty, to avoid the overlaps of the overall combination of linguistic features with attested languages; Compositionality, to guarantee systematic and productive rule application. Together, these principles provide both practical foundation and criteria. Naturalness. Naturalness requires that the constructed language could, in principle, exist as human language on Earth, and thus must fall within the distribution of humanly possible languages. We further distinguish three types of criteria for naturalness: (1) naturalness involves fundamental properties of human language, such as design features (Hockett & Hockett, 1960) and the capacity for recursion (Hauser et al., 2002), and; (2) naturalness requires that the grammatical features employed are attested in human languages. Unattested and empirically unproven innovations (Kallini et al., 2024), such as phonological rule turning every second phoneme into /a/ if the word begins with /b/, should be excluded, and; (3) naturalness concerns the probabilities of feature combinations, where certain features as rarely co-occurring and others as mutually implicative (Greenberg et al., 1963). These linguistic universals (Greenberg et al., 1963; Gorrie; Moravcsik, 1978) constitute the most complex constraints that Camlang must respect to remain naturalistic. Richness. We aim to make the language rich enough for our purposes (Haspelmath, 2005; Evans & Levinson, 2009). In particular, (1) it should possess diverse range of grammatical features, allowing us to analyse which features are more challenging for LLMs and what kinds of linguistic reasoning are lacking in LLMs, and; (2) it should possess enough vocabulary and grammatical constructions to cover basic language usages, and; (3) it should allow one meaning to be expressed in alternative stylistically differentiated ways. Also, it should be noted that Camlang is not intended to match the full richness and complexity of natural language such as English. Instead, it is controlled, moderately complex system designed to probe specific aspects of LLM language learning. Novelty. The constructed language is intended to be novel language, with unseen lexicon and grammar. Therefore, it is important to limit coincidences and overlaps with other languages that we know to our knowledge (Comrie, 1989; Evans & Levinson, 2009). In particular, we consider two aspects: (1) from the lexicon aspect, the linguistic forms (spellings, in this case) should avoid coinciding with linguistic forms of other languages that mean the same thing, and; (2) from the grammar aspect, it should also be different from those of other languages to significant extent. We emphasise again that the grammatical features are all attested in human languages, so the novelty refers to novel combinations of features, which means that the underlying logic of this language should differ from other languages. Compositionality. The grammar of the constructed language is intended to be learnable with explicit description and demonstrative examples only. Therefore, it must be composi6 Working in Progress tional, in the sense that grammar rules are factorised and composed productively (Chomsky, 2014): any word stem of given part-of-speech (PoS) can take the specified inflectional slots, and functional categories always co-occur according to fixed linear orders and scope relations, unless exceptional rules or items, which should remain peripheral, are specifically mentioned in the grammar book. This ensures that the legality and linearisation of unseen morpheme combinations are decidable from the grammar book alone. Other Considerations. Apart from the above four main principles, the design of the constructed language must also be regular, concise, and straightforward enough to ensure tractability so that both humans and computational models can process it reliably and efficiently. Meanwhile, we deliberately abstract away from peripheral world-building considerations, such as putative geography (Janda, 2013), sociocultural embedding (Lantolf & Pavlenko, 1995), or franchise-specific lore (Androic, 2019) (e.g., Tolkienian settings or Parseltongue), and treat the constructed language purely as typologically plausible testbed for explicit-rule learning. It should also be noted that the main considerations sometimes lead to contradictions. For example, more naturalistic feature combination is more common and therefore less novel, and richer grammar with more features is less naturalistic due to the greater number of uncommon features and marked feature combinations. This requires the four considerations to be balanced in trade-off in our implementation. 3.2 Construction and Implementation As discussed in 2.2, we have not seen any attempt to construct full-fledged plausibly human language for research purposes. Conlanging, or the construction of new full-fledged languages, is practised mostly for personal recreation, interlanguage communication (Auxlangs such as Esperanto (Janton, 1993) and Interlingua (Lu et al., 2018)), or world-building in fiction, most often without the need for rigorous scientific methodology. Therefore, the construction and implementation of Camlang as research tool is mostly exploratory and pioneering to our knowledge. Unlike existing conlangs (Lake & Baroni, 2018; Bastings et al., 2018), Camlang is designed with explicit operational goals: it must be both learnable by humans and usable by computational models. To this end, Camlang is grounded in two resources: grammar book and dictionary. The grammar book specifies how meanings are compositionally expressed through phonology, morphology, and syntax, while the dictionary documents the lexical inventory and its distribution. Together, these artefacts provide the operational foundation that enables both humans and models to learn and use the language. The design of Camlangs grammar and dictionary is primarily led by Cambridge linguistics student with prior experience in conlanging. Another three linguistics students from Cambridge and Oxford serve as core contributors in the refinement process. This ensures that all features are systematically analysed from multiple perspectives. We next describe the conception and organisation of the initial grammar book ( 3.2.1) and dictionary ( 3.2.2). We then explain how these resources evolves through iterative human translation exercises and revisions ( 3.2.3), resulting in the final versions used in our experiments. 3.2.1 Grammar Book The grammar book is the central artefact of Camlang, specifying how meanings are compositionally expressed through phonology, morphology, and syntax. We first describe how the characteristic features of Camlang are chosen and detailed, and then the organisation of the grammar book. Feature Selection. The naturalness and novelty principles dictate that Camlangs features must all be attested but combined in an innovative configuration. With this goal, we start by creating the defining features of Camlang via the selection of existing features from language groups with distinct typologies, including but not limited to: vowel harmony from Turkic languages (Korn, 1969), consonant mutation from Celtic languages (Green, 2006), and Working in Progress an active left periphery from Romance languages (Beninc`a, 2004). To achieve richness and compositionality goals most directly, the author designed Camlang to have highly regular, rich morphology with prevalent simple exponence. Specification. With the features preliminarily decided, we translate them into explicit phonological, morphological, and syntactic rules. We deliberately merge morphology and syntax in the grammar book into single component (Morphosyntax), because many syntactic functions in Camlang are morphologically realised, and their description requires treating the two levels jointly. Phonology Specification. In line with the novelty principle, the phonological traits borrowed from attested languages are systematically reinterpreted within Camlangs original phoneme inventory and orthography, rather than copied directly. For instance, both voiced and voiceless stops undergo aspirate mutation into voiceless aspirated stopsa pattern distinct from Middle Welsh, where only voiceless stops undergo aspirate mutation while voiced stops remain unaffected. Morphosyntax Specification. To achieve richness and compositionality, we first identify core grammatical categories such as nominal number, verbal aspect, and clause types. We then associate these categories with plausible morphological and syntactic patterns, including prefixation, suffixation, and verb fronting, and assign functional morphemes phonological shapes consistent with the designed phonology. For instance, yesno questions are encoded both by verb fronting and by the attachment of proclitic (nAs=) containing harmonising vowel underspecified for backness, in accordance with vowel harmony. Organisation. Language is conventionally described in modular sequence, proceeding from phonetics, phonology, morphology, and syntax to semantics and pragmatics, gradually moving from linguistic form to linguistic meaning (Fromkin et al., 2017). In our case, phonetics is first excluded, since Camlang is not intended to be spoken. Accordingly, the initial grammar book is organised as: Orthography and Phonology, reflecting the rich phonological system and rules that drastically alter the written form; Nominal Morphology, Verbal Morphology, and Derivational Morphology, capturing the highly productive morphology of Camlang; Morphosyntax, which subsumes syntax due to the strong interactions between syntactic structures and morphological marking. It should be noted that semantics and pragmatics are left largely unspecified in the initial version, both because our evaluation focuses on formal structure and because the dictionary captures much of the semantic content. As about to be discussed in 3.2.3, the grammar book has been incrementally changed during refinement. 3.2.2 Dictionary The dictionary records the forms and meanings of Camlang lexemes and multi-word expressions, and thus serves as an indispensable reference for both humans and models. Guided by our design principles, we pursue two objectives: (1) plausible, naturalistic distribution of lexical items in form and origin; and (2) minimal arbitrariness to support human and machine learnability. Lexical Sourcing and Formation. To meet these objectives, we balance five sourcing mechanisms. Generated Roots (Native Camlang Word). Given the phoneme inventory and phonotactics, we implement root generator that samples monoand disyllabic 8 Working in Progress forms from slot-conditioned probability table (see Appendix B). We select newly generated form whenever novel root is required, discarding accidental duplicates unless deliberate homonymy is desired. More basic concepts tend to receive monosyllabic roots, more complex ones disyllabic roots (mimicking synchronically opaque derivations). Sound symbolism occasionally informs choices, e.g., high front vowels for sharp objects vs. low round vowels for round objects ( Cwiek et al., 2022). Derived Words. We exploit derivational morphology (Tyler & Nagy, 1989) to limit the number of independent roots. Many derivatives are synchronically transparent and compositional, e.g., cak (to work) + -mA4 (deverbal nominaliser) cakma (work); others are conventionalised and semantically opaque, e.g., kok (to look) + -GA4s (abstract nominaliser) kokkys (hope), both attested cross-linguistically.5 Derivation also includes calques (loan translations), e.g., soruk (compute) + pI4- (agent) pusoruk computer (Shuttleworth, 2014). Compounds. For semantically decomposable complex concepts (Weiskopf, 2007), we form compounds from existing words, thereby limiting new roots and maintaining agglutinative consistency, e.g., kityb-chog (desk) from kityb (book) + cog (table), usually orthographically marked with hyphen and morphologically marked with the ezafe proclitic on the compound head or rightmost item. Opaque Loans. To simulate superstratal influence (Kahane, 1986), controlled portion of items is adapted from archaic or less familiar sources, e.g., reconstructed forms, whose phonological shapes differ from the native stock. These items model historically plausible borrowing while remaining difficult for models to identify by external knowledge trivially. Transparent loans. To reflect cross-linguistic diffusion of modern concepts (Wierzbicka, 2006), small set of items is adapted from major languages, e.g., rajdiw radio, remaining recognisable in meaning despite phonological adaptation. Together with opaque loans, this yields realistic loan profile. Semantic Mapping Policy. We do not engineer semantics to be adversarial. Instead, where possible, Camlang lexemes map one-to-one to English equivalents. Nevertheless, motivated sense splits or mergers are permitted, e.g., n. at play (with toys) vs. get play (sports/instruments) and gomlun. (usually/generally), reflecting attested partitions of semantic space via metaphor/metonymy. Dictionary Structure and Readability. Entries are alphabetised by the underlying form (the morphophonological base). For each entry, we record: (1) English gloss (and relevant subcategorisation, e.g., genitive vs. accusative complements); (2) part of speech and honorific status; (3) underlying form; (4) surface citation form; and (5) etymology. (5) is not released to models to avoid leakage of external knowledge. (3) and (4) anchor morphological analysis by distinguishing underlying from surface realisation. Since Camlang is morphologically rich, many surface forms are not listed verbatim. Thus, the dictionarys underlying forms serve as lemmata for analysis and retrieval, both for humans and models. 3.2.3 Iterative Refinement Starting from the initial grammar book and dictionary, we perform iterative refinements with three aims: (1) to improve learnability and typological plausibility by removing unnecessary complexities and outliers; (2) to expand the lexicon and specify constructions required for naturalistic expression of complex meanings; and (3) to simulate Camlangs plausible historical development, so that new features arise via naturalistic grammaticalisation rather than arbitrary design. 5We use transparent/opaque in the synchronic sense; c.f., standard discussions of derivational semantics (Beard, 2017). 9 Working in Progress In each round, four annotators (linguistics undergraduates from Cambridge and Oxford who have experience in constructed languages and L2 acquisition) independently translated set of English sentences or dialogues using the current grammar and dictionary. The source material increases in form and expressive complexity across rounds: starting with simple declaratives (e.g., ROCStories (Mostafazadeh et al., 2016)), moving to short daily dialogues, and culminating in longer interview-style exchanges.6 Translation divergences are then used diagnostically to locate missing constructions, underspecified rules, or structural inconsistencies. The discussion also leads to fixes incorporated into the next grammar and dictionary revision. Note that differences across translations are not treated as errors, since Camlang permits paraphrastic variation and multiple acceptable syntactic and pragmatic realisations. Only divergences indicating under-specification or inconsistency trigger revisions. For lexical expansion, new stems are added only when required to express concepts absent from the current dictionary. After refinement, we further manually review and provide feedback on contradictions or underspecified interactions. We stop after Round 3 when no further feedback beyond minor editorial clarifications is provided. Across all rounds, each annotator works with total of 2,263 tokens, 737 types, and 207 sentences. While modest in size, this corpus fits our purpose to assess whether the grammardictionary specification affords adequate coverage of naturalistic expressions across diverse syntactic structures and discourse contexts. Here, we summarise the major refinements to the grammar book in each round: Round 1. The discussion and refinement focus on surface-form consolidation and core nominal/clausal regularisation. The refinement mainly addresses the standardisation of orthographyphonology conventions (Venezky & Massaro, 2013) and re-organisation of the nominal system around simple exponence, together with the grammaticalisation of oblique pronouns into pronominal clitics (Borer, 2020) (remaining disharmonic) and reanalysis of the accusative/genitive contrast with postpositions as dynamicstative opposition (Koopman, 2010). We also fix the basic case assignment and ordering for double-complement predicates. Round 2. This round focuses on systematising the behaviour of clitics, reworking some high-frequency morphemes forms while adding sources of stylistic variation. In particular, we specify clitic stacking and movement rules explicitly (Roberts, 2010), and streamline the core paradigms (pronouns, TAM, information-structure and interrogative markers) to improve distinctiveness and clarity. In addition, we adopt limited periphrastic resources (do-support and light verbs), and replace originally arbitrary evidential contrast and agreement morphology with diachronically motivated ones, while introducing vowelglide dissimilation rule to increase phonological opacity (McCarthy, 1999). When annotating the dialogues, we recognise that the lack of pragmatic architecture limited the stylistic scope of Camlang. In response, we devise topic-based honourific register (Agha, 2006), introducing level of controlled pragmatic application to account for the range of contexts in which conversation might take place (Parsons et al., 2017). Round 3. We mainly demarcate functions of some grammatical categories and advanced Camlangs macro-typology in diachronically naturalistic way (Greenberg, 1995). In particular, we separate the definiteness function from the linker by introducing an independent definite marker, and introduce full reduplication to meet typological expectations (Haspelmath, 2005). We further establish firstperson inclusive/exclusive split and make specificity-driven Differential Object Marking explicit (Rodrıguez-Mondo nedo, 2007). We codify situations of use of mood, modality, evidentiality and epistemic markers. And we turn Camlang from agglutinative to polysynthetic via grammaticalisation of pronominal clitics into obligatory head-markers.7 We also structured mathematical expressions for future applications. 6https://www.ox.ac.uk/sites/files/oxford/media wysiwyg/Interview%20Podcast%20-%20Tran script.pdf 7A historically canonical development captured as morphosyntactic cycle (Humboldt, 1905). 10 Working in Progress Category # % 698 Native Word Derived Word 588 Compound Word 103 Opaque Loan 80 42 Transparent Loan 46.19 38.91 6.82 5.29 2.78 Table 1: The distribution of lexical sourcing and formation as in the dictionary by the experiment time. After refinement, we also add General Description section, which summarises the languages major features. The resulting grammar book contains 453 sentences and 9,477 tokens. For the dictionary, new entries are added on demand for texts, and forms are amended only when grammar changes (e.g., orthography or derivational rules) impact citation forms. At the time of experiments, the dictionary contains 1,511 entries. We show the distribution of the lexical sourcing and formation as in Table 1. Using the annotated data from the above procedure, we also measure the cross-annotator consistency across the three rounds as an indirect indicator of Camlangs learnability under an explicit grammar and dictionary (metrics and results in 3.4). 3.3 The Overview of Camlang To avoid potential data leakage to LLMs, we do not release the full grammar book and dictionary at this stage. Instead, we provide high-level overview of the linguistic profile of Camlang. We also provide profile of the World Atlas of Language Structures (WALS)-style features in Appendix A. Phonology. Camlang has 50 consonantal phonemes, among which 30 do not appear in native citation forms, but result from loaning or consonant mutation, an important morphophonological process that operates at cliticisation boundaries. The inventory is largely symmetric with four places of articulation, and each phoneme can appear at both onset and coda. Camlang has Turkic-type harmonic 8-vowel system with vowel reduction, which neutralises contrast between three vowels at unstressed positions. Camlang has strict (C)V(C) phonotactics that prohibits adjacent vowels, often satisfied by epenthesis. The combination of these features means learners of Camlang must apply phonological rules in the specified sequence in order to derive surface forms from underlying forms or reversely. For example: (1) lichewcymys ur Segmented: Morphemic: Gloss: lilI= 2SG= chew x= EZ= -cy -RED -PROG -my mA4 -NMLS -s ur -s -GEN =jUr =at cew answer when you are answering The Camlang word in Case 1 consists of seven morphemes, none of which appear in underlying form. Learners cannot comprehend or produce this word if they do not apply relevant phonological rules, because the ungrammatical result of simple morphemic concatenation, *lixcewcemasjur, would never appear. Morphosyntax. Camlang is polysynthetic language with obligatory head-marking morphology, consistent pro-drop, and predominant simple exponence. For derivation and inflection, Camlang uses both affixes and clitics extensively. Camlang has slight preference for suffixation over prefixation and circumfixation, and slight preference for procliticsation over encliticisation. Camlangs nouns are marked for many grammatical functions, such Working in Progress as definiteness, plurality, and case, and can take postpositional enclitics. Their possessors are marked with proclitics. Camlangs verbs are marked categories such as for valency, aspect, tense, evidentiality, mood, and finiteness. Finite subjects are marked on verbs with agreement suffixes while other arguments are marked with proclitics. Nonfinite verb forms like nominalisations are extensively used in complex constructions realised as subordination in English. The combination of these features means learners of Camlang must use morphosyntactic knowledge to analyse syntactic dependencies and grammatical functions when comprehending or producing agglutinative word forms, which is more challenging for learners with analytic mother tongue languages or training languages like English and Mandarin Chinese. For example, the written word in Case 1 contains semantic information equivalent to that of an English subordinate clause due to its morphological complexity, and would be incomprehensible if the learner fails to perform morphological segmentation and analysis according to specific grammar points. Due to the heavy functional load taken by Camlangs morphology, its syntactic configurations are relatively simple. Structurally, all projections lower than the Complementiser Phrase 8 in Camlang are head-final, giving SOV default word order. The active left-periphery hosts the information-structural functions of topicalisation and focalisation, and other word orders are used in many marked clause types. Otherwise, word orders are usually fixed and decided by the hierarchical structure. Sociopragmatics. Camlang does not exhibit T/V distinction in second-person reference forms (Raymond, 2016), but showcases lexicalised register as found in languages like Thai (Iwasaki & Horie, 2005), with some concepts being denotable by an ordinary linguistic variant and an honorific linguistic variant. Moreover, morphosyntactic constructions may be used as stylistic devices to give the text more native, natural style as opposed to more foreign, translationese style. Camlangs sociopragmatic description is currently underdeveloped, but we hope to enrich it from this basis and use it to explore discourserelated tasks. 3.4 Analysis and Evaluation on Camlang 3.4.1 Grammar Clarity and Practical Learnability We assume that if the grammardictionary specification is sufficiently explicit and internally consistent, then the Camlang learners will converge on the same morphological choices and on similar clause-level linearization for given English input (Reber, 1967; Ellis, 2005; Lake & Baroni, 2018). In 3.2.3, we iteratively refine the grammar and dictionary through three rounds of translation by four annotators. We thus analyse the cross-annotator consistency as indirect evidence about the language learnability.9 We calculate the averaged ROUGE (Lin, 2004) scores between different annotators at different rounds, and report the results at two granularities. At the word-level, we tokenise the Camlang sentences by spaces. At the morpheme-(surface morph) level, we manually tokenise words into morphemes according to the grammar/dictionary. The results are shown in Table 2. Generally, from Round 1 to Round 3, ROUGE increases consistently at both granularities (word: R1 46.2362.91, R2 19.0940.99, RL 44.2760.10; morpheme: R1 67.5175.04, R2 36.2755.40, RL 61.8969.88). The largest gains in ROUGE-2 indicate increasing stability of local combinations (affix order, clitic/particle placement), while gains in ROUGE-L point to more constrained global clause linearisation. These trends persist despite rising source complexity across different rounds (from simple declaratives to longer complex dialogues), suggesting that the grammardictionary specification became operationally clearer and 8for Complementiser Phrase, see Chapter 9 of Radford (2004) 9Our use of learnability is empirical, different from classical notions, such as (Gold, 1967) and (Valiant, 1984). In L2 acquisition, the learnability/teachability hypothesis has also been discussed (Pienemann, 1989). We do not claim formal identifiability here and focus on practical learnability under explicit instruction. 12 Working in Progress Round Word Morpheme R1 R2 RL R1 R2 RL 1 2 3 46.23 57.96 62.91 19.09 33.69 40. 44.27 56.67 60.10 67.51 72.97 75.04 36.27 50.35 55.40 61.89 68.39 69.88 Table 2: Averaged ROUGE scores across annotators by round at word and morpheme levels. thus affords practical learnability under explicit instruction. Morpheme-level scores are consistently higher than word-level ones (e.g., Round 3 RL 69.88 vs. 60.10). Decomposing words exposes shared functional structure (affixes, clitics, and morphotactic slots) and reduces lexical sparsity, thereby increasing the chance of n-gram overlap across independently produced translations. This is in line with our morphologically rich design. Accordingly, higher morpheme-level ROUGE indicates convergence on the same grammatical machinery (choice of functional morphemes and slot order) rather than mere coincidence at the word level. It should be noted that, because EM metrics are boundary-conventionsensitive, morpheme-level ROUGE should be read as conservative estimate. We acknowledge that the present analysis only considers the mapping from English into Camlang, i.e., the production aspect. fuller account of practical learnability would also require examining comprehension in the opposite direction, i.e., the comprehension aspect (VanPatten, 2004; Pickering & Garrod, 2013). We complement it later in 5, where one human participant is asked to solve the commonsense question answering task given the grammar book and dictionary, and achieves an accuracy around 87%, thereby addressing this aspect of bidirectional learnability. 3.4.2 Novelty and Typological Positioning Following (Georgi et al., 2010), we adapt WALS-style feature-based method to compare the similarity between two languages. WALS (Haspelmath, 2005) is the most widely used and largest typological database, covering 2,662 languages with 144 chapters of features across domains such as phonology, morphology, and word order.10 Since typological inventories are sparse and some features are not directly comparable across languages, we restrict comparison to the intersection of features available for both languages. We manually construct WALS-style typological profile for Camlang based on its grammar and dictionary, aligning each relevant structural property with the corresponding WALS feature value (Appendix A). Overall, Camlang contains 134 features. Let FX and FY be the sets of features encoded for languages and Y, respectively. We restrict comparison to their overlap FX FY, in order to avoid spurious differences due to missing values and to ensure comparability. For each feature in the overlap, we assign an indicator score: (cid:40) δ (X, Y) = if (X) = (Y), 1, 0, otherwise, (1) where (X) and (Y) are the values of feature in languages and Y, respectively. The overall similarity is then defined as the proportion of matched features: sim(X, Y) = FX FY δ (X, Y) FX FY . (2) Following Georgi et al. (2010), we set minimum overlap threshold and report results across different settings (20, 30, 40 and 50 features). For comparison, we compute the similarities between each top neighbour of Camlang and all other languages under the same minimum-overlap setting, and the similarities between Camlang and high-resource languages. 10https://wals.info/chapter/s1 13 Working in Progress Rank Code Similarity FX FY Name Genus Family Top1 Top2 Top3 Top4 Top5 Top1 Top2 Top3 Top4 Top5 awa gam kum knn bho bho sid sna guj pba dji Top1 raw Top2 tvo Top3 Top4 mns bel Top Top1 mns kty Top2 ttu Top3 pan Top4 dgr Top5 0.96 0.95 0.91 0.89 0.82 0.82 0.81 0.80 0.75 0.75 0.74 0.70 0.68 0.68 0.67 0.68 0.67 0.67 0.66 0.65 20 overlap Awadhi Gamo Kumauni Kinnauri Bhojpuri 30 overlap Bhojpuri Sidaama Shina Gujarati Pima Bajo 40 overlap Djingili Rawang Tatar Mansi Belhare 50 overlap Mansi Khanty Tsova-Tush Panjabi Dagur Indic Ta-Ne-Omotic Indic Bodic Indic Indo-European Afro-Asiatic Indo-European Sino-Tibetan Indo-European Indic H. East Cushitic Indic Indic Tepiman Indo-European Afro-Asiatic Indo-European Indo-European Uto-Aztecan Djingili Nungish Turkic Ugric Himalayish Mirndi Sino-Tibetan Turkic Uralic Sino-Tibetan Ugric Ugric Nakh Indic Mongolic Uralic Uralic Nakh-Daghestanian Indo-European Mongolic 27 20 23 28 33 33 32 30 36 32 42 40 41 59 43 59 66 51 65 55 Table 3: Camlangs top neighbours with 20, 30, 40, and 50 overlapping features. High similarities at this threshold are based on very small overlaps. Results on 40 and 50 features are more stable and typologically meaningful. H. East Cushitic is Highland East Cushitic. Table 3 presents Camlangs closest neighbours under different feature-overlap thresholds. At lower thresholds (20, 30), Camlang appears close to Indic languages such as Awadhi, Kumauni, and Bhojpuri, as well as Afro-Asiatic and Sino-Tibetan languages. However, these results are based on small overlaps and are less stable. More meaningful comparisons emerge at higher thresholds (40, 50), where Camlangs closest neighbours include Djingili (Mirndi), Rawang (Sino-Tibetan), Tatar (Turkic), Mansi (Ugric), and Dagur (Mongolic), with similarities in the 0.670.74 range. These results suggest that Camlang does not collapse into any single language family, but rather occupies mixed region of typological space, combining features from multiple families in stable and coherent way. Table 4 further compares Camlangs top-1 neighbours against their own closest languages. Natural languages such as Awadhi (an Indo-Aryan language) and Bhojpuri (also an IndoAryan language) have higher similarities with their genealogical relatives (e.g., Indic languages), with near-perfect similarity scores. Conversely, in cases such as Djingili and Mansi, Camlang itself ranks among their top neighbours, often alongside typologically distant families such as Korean, Basque, or Quechuan. This contrast highlights that Camlang is sufficiently naturalistic to be typologically comparable to real languages, yet it is distinct in that it spans across multiple genealogical groups rather than grouping tightly with one family. Table 5 shows that Camlang maintains relatively low similarity with major high-resource languages such as English (0.44), French (0.42), Mandarin (0.45), and Japanese (0.49), confirming that it does not trivially overlap with the typological profiles of widely studied languages. Camlang shows higher similarity with Turkish (0.63, based on 133 overlapping features). This is consistent with our design that Camlang incorporates typological traits such as vowel harmony and agglutinative morphology that are characteristic of Turkic 14 Working in Progress Rank Code Similarity FX FY Name Genus Family Awadhis (Indic, Indo-European) top neighbours 20 overlap Top1 Top2 Top3 Top4 Top5 ttu knn sna guj kty Top8 - hin Top1 hop Top2 kor Top3 Top4 ttu Top5 mgg Top - Top1 Top2 Top3 Top4 Top5 Top1 Top2 Top3 Top4 Top5 Top6 kor - hin ket bsq ntu qim geo ket ain - 27 25 25 21 1.00 1.00 1.00 1.00 0.96 Tsova-Tush Kinnauri Shina Gujarati Khanty ... Camlang Bhojpuris (Indic, Indo-European) top neighbours 30 overlap Nakh Bodic Indic Indic Ugric 0.96 27 - Nakh-Daghestanian Sino-Tibetan Indo-European Indo-European Uralic - 33 33 30 30 31 0.97 0.91 0.90 0.90 0.84 Hindi Hopi Korean Tsova-Tush Mangghuer ... Camlang Djingilis (Djingili, Mirndi) top neighbours 40 overlap Indic N. Uto-Aztecan Korean Nakh Mongolic 0.82 33 - Indo-European Uto-Aztecan Korean Nakh-Daghestanian Mongolic 0.74 0.74 0.71 0.71 0.70 Korean Camlang Hindi Ket Basque Mansi (Urgic, Uralic) top neighbours 50 overlap Korean - Indic Yeniseian Basque 46 42 48 41 47 0.77 0.74 0.72 0.71 0.69 0.68 51 60 58 52 55 59 Nenets Quechua Georgian Ket Ainu Camlang Samoyedic Quechuan Kartvelian Yeniseian Ainu - - Korean - Indo-European Yeniseian Basque Uralic Quechuan Kartvelian Yeniseian Ainu - Table 4: Top neighbours of Camlang compared with their own closest languages under the same overlap thresholds. N. Uto-Aztecan is Northern Uto-Aztecan. Code Similarity eng fre tur mnd jpn 0.44 0.42 0.63 0.45 0.49 FX FY 131 130 133 128 126 Name Genus Family English French Turkish Mandarin Japanese Germanic Romance Turkic Chinese Japanese Indo-European Indo-European Turkic Sino-Tibetan Japanese Table 5: Comparison between Camlang and high-resource languages. languages ( 3.2.1). Taken together, these results demonstrate that while Camlang remains distinct from common high-resource languages, it naturally aligns more closely with Turkic languages, reinforcing both its novelty as constructed language. 3.4.3 Richness Analysis We measure the richness of Camlang by comparing its WALS features with other languages. Figure 1 shows the distribution of feature counts across documented languages. We see that most languages are annotated with only few dozen features, which can be attributed to limited documentation and scarce resources for many low-resource and endangered languages. As result, their typological richness in WALS is insufficiently captured. Using such languages for evaluation would cannot provide comprehensive test of linguistic competence and risk biasing the evaluation towards narrow subset of phenomena. In 15 Working in Progress Figure 1: Distribution of WALS features in documented languages (with selected languages highlighted). contrast, Camlang has 134 features, placing it above 97.52% of WALS languages. Compared to high-resource languages such as English (159), French (158), and Mandarin (153), while Camlang does not aim to replicate the full complexity of natural languages, it ensures sufficient typological richness to support systematic evaluation."
        },
        {
            "title": "4 The Camlang-CSQA-v0 Test Set",
            "content": "With the grammar book and dictionary stabilised, we construct Camlang-CSQA-v0, smallscale multiple-choice dataset of commonsense questions in the Camlang language, derived from CommonsenseQA (Talmor et al., 2019). We choose CommonsenseQA (Talmor et al., 2019) as the source task because it is wellestablished benchmark for evaluating commonsense reasoning in NLP, consisting of daily scenarios that require integrating world knowledge and simple reasoning. Moreover, prior work has shown that the knowledge required to answer CommonsenseQA is already well represented in current LLMs (Aggarwal et al., 2021; Krause & Stolzenburg, 2023; Bian et al., 2024). By translating the task into Camlang, the challenge no longer lies in retrieving commonsense knowledge itself, but in whether models can correctly interpret the grammar book and dictionary and apply explicit rules to integrate this unfamiliar linguistic input with their existing commonsense knowledge. 4.1 Task Definition The task is multiple-choice question answering in Camlang. Each instance consists of commonsense question and six candidate answers, including one none of the above option. The systems are required to select the single correct answer based on the Camlang input, with access to the grammar book and dictionary. 4.2 Data Selection and Pre-processing We first randomly select 50 instances from the CommonsenseQA test set.11 In practice, we observe that some instances are either less reasonable or contain ambiguous answer 11https://huggingface.co/datasets/tau/commonsense qa/ 16 Working in Progress Figure 2: Word count distribution of questions in English and Camlang. The x-axis indicates the number of words per question, and the y-axis indicates the number of questions. options. We first modify or replace such options to ensure that the correct answer is more reasonable. Instances with ambiguous questions are removed. Another problem is that the Camlang dictionary is limited and cannot cover all entities in CommonsenseQA. To avoid continuously expanding the dictionary with low-frequency words, we thus replace or modify such entities with semantically similar ones already present in the dictionary, if they are not essential for reasoning or answer selection. For example, given the question How could weasel go to another continent? with the correct answer by ship, we replace weasel with cat, which is already covered by the dictionary. In addition, we insert an extra option none of the above into each instance. After this adjustment, we manually select the gold answers, since the CommonsenseQA test set does not provide them. The resulting set of multiple-choice instances is then translated from English into Camlang, yielding cleaner set of 47 questions. 4.3 Annotation Given the English questions and multiple-choice options, we ask the core annotator, who participates in Camlang development, to translate them into Camlang, with reference to the grammar book and dictionary. The translation is not required to follow English syntax in word-to-word manner; instead, the annotator is allowed to adapt the sentences according to the typological characteristics of Camlang. When no reasonable substitution is available in the existing dictionary, the annotator extends the lexicon with new entries. In addition to the translated sentences, we also provide gloss-level annotation, which specifies the morpheme-by-morpheme alignment and thereby ensures both accuracy and interpretability of the annotation. For example, given the question How could cat go to another continent?, we interpret the gloss as cat=TOP how go-INF=can another continent-GEN?. After the initial annotation, second annotator, who is also involved throughout the grammar design process, reviews and revises the translations to ensure consistency and correctness. 4.4 Dataset Statistics We analyse the length of questions before and after translation. Lengths are measured in words, where both English and Camlang are tokenised by spaces. The distribution is shown in Figure 2. On average, English questions contain 12.34 words, whereas their Camlang counterparts are shorter with 7.32 words. We observe three main trends. First, both English and Camlang questions are concentrated between 615 words, reflecting the original distribution of CommonsenseQA. Second, Camlang exhibits higher proportion of very short questions (05 words), owing to its 17 Working in Progress morphological compactness: information that requires separate function words in English (e.g., auxiliaries, prepositions) is often expressed via affixes or clitics in Camlang. Third, English questions extend to much longer tails (over 20 words), while no Camlang question exceeds 20 words. This indicates that translation into Camlang systematically yields more compact formulations, while preserving the semantic content needed for reasoning."
        },
        {
            "title": "5 Experiments",
            "content": "With the grammar book, dictionary, and Camlang-CSQA-v0, we conduct experiments to evaluate both human and model performance. This pilot experiment serves two main purposes. First, we assess the Camlang evaluation paradigm by testing whether human participants, given only the grammar book and dictionary, can comprehend questions encoded in Camlang, thereby validating that our method supports metalinguistic deductive learning. Second, we investigate whether LLMs can interpret the explicit grammatical rules and apply them to perform deductive reasoning in an unfamiliar language. 5.1 Experimental Setup We conduct experiments on Camlang-CSQA-v0 in zero-shot setting. 5.1.1 Baseline Systems and Implementation Details We consider strong reasoning models as our baseline systems. For comparison, we also include general-purpose model and human participant: GPT-4o (2024-11-20): general-purpose LLM from OpenAI (OpenAI, 2024). GPT-o4-mini (2025-04-16): lightweight, efficient reasoning LLM (OpenAI, 2024). GPT-o3 (2025-04-16): OpenAIs most capable model in the o-series of reasoning models (OpenAI, 2024). GPT-5 (2025-08-07): The most recent LLMs from OpenAI, featuring substantial improvements in coding and reasoning (OpenAI, 2025). DeepSeek-R1 (2025-05-28): An open-source reasoning LLM from DeepSeek, focusing on strong logical and reasoning capabilities (DeepSeek-AI, 2025). Human Participant: first-year undergraduate student in Linguistics at Oxford. For OpenAI models, we consider two configurations enabled by the API interface: (1) Toolsenabled: we upload the grammar book (.md) and the dictionary (.xlsx) as files and allow the model to call File Search and Code Interpreter, respectively, and; (2) Context-only: we prepend the full text of the grammar book and textual export of the dictionary to the input as context, with tools disabled. For DeepSeek-R1, we use the context-only configuration as it does not support such tools. For reasoning models (o3, o4-mini, and GPT-5), we set the reasoning effort to high. For GPT-4o, we set temperature and top-p to 0. For the other models, these two parameters are not exposed, and we therefore use the default configuration. We add prompts before the question to instruct the LLMs to explicitly make use of the grammar book and dictionary, and conclude its output with sentence of the form The final answer is X, where is an option (e.g., or B). The detailed prompts are shown in Appendix C. In addition to choosing an answer option, the human participant is asked to write explanations to demonstrate their choice, simulating the reasoning steps of LLM, which is later used for evaluation and analysis. We also run the systems on the English version of our testing instances without the grammar book and dictionary to provide controlled comparison. For human participant, to avoid leakage, we ask the annotator to complete the English questions after the Camlang questions. Working in Progress Model 4o (tool) 4o (context) DS (context) o4-mini (tool) o3 (tool) o3 (context) GPT-5 (tool) GPT-5 (context) Random Human Camlang English ACC (%) Time (s) ACC (%) Time (s) 21.28 21.28 40.43 25. 27.66 46.81 42.55 46.81 16.67 87.23 75.04 31.98 263. 413.84 566.09 158.23 475.34 101.70 - 670.91 89. 85.11 91.49 97.87 95.74 16.67 91. 19.49 58.70 14.20 7.86 16.46 - 17.50 ACC 68.08 68.08 44.68 65.96 70.21 51. 53.19 48.93 - 4.26 Table 6: Exact match results on Camlang-CSQA-v0 (ACC: exact match accuracy, Time: average inference time per instance). The last column reports the accuracy drop from English to Camlang. 5.2 Exact Match Results 5.2.1 Evaluation Method Following standard practice in reasoning benchmarks, we report average accuracy using exact matching (EM). In this setting, prediction is considered as correct if and only if the models output contains final answer of the form The final answer is X, and the value exactly matches the gold option. If response contains multiple such phrases, we take the last one as the final prediction. 5.2.2 Result Discussion We first discuss the EM results as shown in Table 6. All observations in this subsection are based on the EM accuracy only, which should not be interpreted as direct evidence of metalinguistic deductive reasoning. Performance Gap between Camlang and English. All models achieve strong performance on the English version of CommonsenseQA (8598% accuracy), confirming that the underlying commonsense reasoning task itself is not the bottleneck. The sharp performance drop on Camlang (2147%) therefore isolates the difficulty to the metalinguistic reasoning from grammar and dictionary into meaning, which current LLMs fail to operationalise. Since Camlang requires first parsing questions through explicit grammar and dictionary lookup before reasoning about commonsense relation and knowledge, the drop in accuracy reflects models inability to perform metalinguistic reasoning in an unknown language. Reasoning Models vs. General-Purpose Models. Among LLMs, reasoning systems such as GPT-5 and GPT-o3 achieve the highest accuracies on Camlang (both 46.81% in the context-only setting), while DeepSeek-R1 reaches 40.43%. In contrast, GPT-4o performs near chance level (21.28%), only slightly above the random baseline of 16.67%. This suggests that reasoning-oriented models show greater robustness when faced with Camlangs grammar-mediated encoding, though their performance remains far from human. This is consistent with that Camlang-CSQA indeed requires grammar rule processing before commonsense deduction. However, whether models actually follow this reasoning path is further examined through human verification in 5.3. Impact of Resource Access Methods. Interestingly, we observe that tool use does not always improve the model performance. For both GPT-5 and GPT-o3, the context-only 19 Working in Progress configuration outperforms the tools-enabled configuration (46.81 vs. 42.55 for GPT-5; 46.81 vs. 27.66 for GPT-o3). The longer inference times in tool mode do not correlate with higher accuracy, indicating clear decoupling between time cost and successful rule use. While CommonsenseQA questions are relatively short multiple-choice instances, the tool setting requires the systems to repeatedly query the grammar book or dictionary, which can add complexity and latency without improving final accuracy. Another salient factor is that tool-based lookup operates over dictionary stems, while Camlang is morphologically rich and produces many inflected surface forms that may not directly appear in the dictionary. In our setup, unless the model can lemmatise first based on the grammar book, direct tool queries may fail to retrieve relevant entries. By contrast, in the context-only setting, the full grammar and dictionary are embedded directly into the input, allowing the model to match morphologically related forms through context and thereby avoiding lookup failures. The result suggests that LLMs struggle to operationalise grammar book and dictionary lookup as part of their reasoning pipeline, even when the API explicitly provides such capabilities. Human Performance and Learnability Evidence. Compared to LLMs, the human participant achieves much higher accuracy on Camlang (87.23%), only slightly lower than their 91.49% on English (a drop of 4.26%). This sharp contrast shows that the difficulty for LLMs lies not in the commonsense reasoning component itself, but in the metalinguistic deductive reasoning of Camlang. Although solving Camlang questions takes considerably longer for humans (670.9s vs. 17.7s), they are able to systematically parse the grammar, consult the dictionary, and integrate the results into reasoning. These results are consistent with Camlang being learnable via explicit use of the grammar and dictionary as in 3.2.3 (cross-annotator translation consistency in the English Camlang direction). 5.3 Human Verification and Analysis on Model Outputs Although reasoning LLMs such as GPT-5 and GPT-o3 achieve nearly 47% EM accuracy on Camlang, these numbers alone do not reveal whether correct answers result from genuine reasoning, or from alternative shortcuts such as exploiting surface regularities or relying on English priors. We therefore turn to human verification of reasoning traces to assess whether correct predictions indeed reflect rule mastery. 5.3.1 Evaluation Method We further verify whether the intermediate reasoning steps of model outputs are correct when their final answers match the gold label. In particular, our analysis considers three aspects: Parsing of the Question: whether the model correctly and completely identified the syntactic structure of the input question (e.g., clause boundaries, argument roles) according to the grammar book. Understanding of the Question Meaning: whether the model accurately captured the intended semantic interpretation of the question. Understanding of answer Option Meaning: whether the model correctly interpreted the meanings of all answer options from the dictionary. We explicitly separate parsing from meaning to distinguish errors in recognising formal structure (syntactic misparsing) from errors in semantic interpretation (misunderstanding word or sentence meaning). For instance, model may arrive at the right meaning despite an incomplete parse by directly mapping key words from the dictionary, or conversely, may parse structure correctly but still misinterpret semantic roles (see 6, where we present case studies with annotations). We do not examine the parsing of options, since most options consist of single Camlang word translated from one or two English words, leaving little structural ambiguity. For each aspect, model outputs are categorised into four labels: (1) correct and complete (Crt+&Com+); (2) incorrect and complete (Crt-&Com+); (3) correct and incomplete 20 Working in Progress Model SHV ACC (%) MHV ACC (%) LHV ACC (%) EM ACC (%) 4o (tool) 4o (context) DS (context) o4-mini (tool) o3 (tool) o3 (context) GPT-5 (tool) GPT-5 (context) Human 0.00 0.00 0.00 0.00 0.00 0. 2.13 0.00 55.32 0.00 0.00 2.13 2.13 2.13 6. 2.13 19.15 59.57 0.00 0.00 4.26 6.38 6.38 10. 17.02 29.79 68.09 21.28 21.28 40.43 25.53 27.66 46. 42.55 46.81 87.23 Table 7: Human verification results on Camlang-CSQA-v0. SHV: strict correctness and completeness across all aspects. MHV: requires correct parsing but tolerates incomplete semantic understanding. LHV: allows incomplete but not incorrect interpretations, capturing partial or shortcut reasoning. The last column presents exact-match accuracy (EM ACC) for reference. (Crt+&Com-); and (4) incorrect and incomplete (Crt-&Com-). Each instance is first annotated by one annotator and then reviewed by another, and disagreements are subsequently resolved through discussion to reach final consensus.12 To provide better comparison, we report three human verification-based metrics by jointly evaluating all three aspects (question parsing, question meaning, and answer option understanding): Strict Human-Verified Accuracy (SHV ACC): an instance is correct only if it is labelled as Crt+&Com+ in all three aspects, reflecting full and faithful rule understanding and application. Moderate Human-Verified Accuracy (MHV ACC): an instance is counted as correct if the question parsing is Crt+&Com+, while question and option understanding may contain incomplete but not incorrect or incorrect and incomplete labels. This metric requires accurate parsing but tolerates minor omissions in semantic interpretation. Lenient Human-Verified Accuracy (LHV ACC): an instance is counted as correct if question and option understanding contain only incomplete (but not incorrect) labels, regardless of whether parsing is incomplete. This captures cases where reasoning succeeds through partial lexical mapping or shallow shortcuts without full grammatical parsing. Note that SHV/MHV/LHV are accuracy-style metrics, defined as the number of instances meeting the respective criteria divided by all test instances (not just EM-correct ones). Such tiered comparison allows us to distinguish genuine rule mastery (SHV), parsing-sensitive correctness (MHV), and shortcut-based reasoning (LHV). 5.3.2 Result Discussion We report the human verified results in Table 7. Overall, we find salient gap between humans and LLMs. Humans maintain strong performance across all verification criteria, confirming that Camlang is operationally learnable through explicit use of the grammar and dictionary. By contrast, LLMs achieve non-trivial EM accuracy scores but almost entirely fail under SHV and MHV, indicating that most correct predictions do not arise from metalinguistic deductive reasoning. These trends highlight two general conclusions: (1) EM substantially overestimates models reasoning ability, and; (2) Camlang effectively exposes 12Across 169 instances times 3 aspects (507 annotation in total), only 9 required discussion. 21 Working in Progress the limits of LLMs in integrating explicit formal rules into their reasoning pipeline. We next discuss the results in detail. Sharp decline from EM to SHV. Across all LLMs, SHV accuracy is near to zero, even for GPT-5 (context), which achieves 46.81% EM. This sharp drop suggests that many EM-correct predictions are not supported by faithful grammatical reasoning, but more likely arise from shortcuts such as partial lexical matching or reliance on English priors. By contrast, humans reach 55.32% SHV, demonstrating that they can systematically parse questions, reconstruct meanings, and interpret options using explicit rules. The contrast reveals that EM alone substantially overstates LLM competence, while SHV directly tests whether Camlangs grammar is truly mastered. At the same time, we acknowledge that SHV is deliberately strict. LLMs and humans may have partially engaged with the grammar but omitted intermediate explanations they deemed unnecessary, in particular for reasoning LLMs, leading to incomplete labels. Thus, we further analyse MHV and LHV. Partial Success and Shortcut Reasoning under MHV and LHV. Under MHV, which tolerates incomplete semantics but requires correct parsing, only GPT-5 (context) reaches 19.15%, while others remain close to zero. This confirms that LLMs rarely manage accurate structural parsing. LHV further relaxes the criteria by including incomplete-but-not-incorrect interpretations. Here, GPT-5 (context) rises to 29.79% and GPT-5 (tool) to 17.02%, while o3 (context) reaches 10.64%. These gains suggest that stronger models sometimes align Camlang words with dictionary entries sufficiently to guess the right answer, even without full parsing. In other words, their success often comes from shallow alignment rather than genuine metalinguistic deduction. Moreover, the divergence from EM to LHV makes clear that EM can substantially overestimate grammatical reasoning ability. In particular, EM remains non-trivial for LLMs such as DeepSeek-R1 and o4-mini, while LHV is near zero. This comparison indicates that, for those LLMs, many EM-correct cases arise from shallow heuristics rather than rule-guided parsing. Human vs. LLMs. Humans consistently outperform all LLMs by wide margins under every metric: 55.32% SHV, 59.57% MHV, and 68.09% LHV. The drop between EM and SHV indicates humans also resort to shortcuts, such as inferring from lexical cues or skipping minor structures. However, the high LHV, MHV, and SHV further support that humans can reliably parse the surface syntax and identify the intended hierarchical structure of Camlang sentences. 5.4 Error Analysis We now show the fine-grained error analysis  (Table 8)  , examining the distribution of correctness and completeness labels across question parsing, question meaning, and option meaning as evaluated in 5.3. Table 8 shows the distribution statistics. 5.4.1 Analysis across Aspects The distribution of verification labels reveals systematic asymmetries across dimensions. Correct Parsing vs. Correct Meaning. Across most LLMs (except o4-mini), parsing is disproportionately weaker than meaning. For example, DeepSeek-R1 shows 26.31% (21.05% Crt+&Com+ + 5.26% Crt+&Com-) of EM-correct cases as in parsing, while 31.58% in question meaning. This indicates tendency to infer plausible semantics directly from lexical cues or commonsense priors without faithfully reconstructing syntactic structure, form of meaning without parsing. In contrast, humans maintain high correctness in both parsing (82.93% Crt+&Com+ + 9.76% Crt+&Com- = 92.69%) and meaning (85.37 % Crt+&Com+ + 2.44 Crt+&Com- = 87.81%), confirming that they rely on explicit metalinguistic reasoning and interpretation rather than semantic guessing. 22 Working in Progress Model # EM Label Q. Parsing Q. Meaning O. Meaning 4o (tool) 10 4o (context) DS (context) 19 o4-mini (tool) 12 o3 (tool) o3 (context) 22 GPT-5 (tool) 20 GPT-5 (context) Human 41 Crt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & ComCrt+ & Com+ Crt+ & ComCrt- & Com+ Crt- & Com- # 0 0 0 10 0 0 0 10 4 1 11 3 2 4 4 2 5 4 1 3 7 2 8 4 8 2 6 10 5 4 3 34 4 2 1 % 0.00 0.00 0.00 100.00 0.00 0.00 0.00 100. 21.05 5.26 57.89 15.79 16.67 33.33 33.33 16.67 38.46 30.77 7.69 23.07 31.82 9.09 36.36 22.73 20.00 40.00 10.00 30.00 45.45 22.73 18.18 13. 82.93 9.76 4.88 2.44 # 0 0 0 10 0 0 0 10 6 0 11 2 1 2 6 9 2 2 0 15 1 5 1 7 6 2 5 13 3 3 3 35 1 5 0 % 0.00 0.00 0.00 100.00 0.00 0.00 0.00 100.00 31.58 0.00 57.89 10.53 8.33 16.67 50.00 25.00 69.23 15.38 15.38 0.00 68.18 4.55 22.73 4. 35.00 30.00 10.00 25.00 59.09 13.64 13.64 13.64 85.37 2.44 12.20 0.00 # 0 0 0 10 0 0 0 9 2 8 0 1 9 0 2 2 5 2 4 6 8 8 0 4 8 2 7 0 20 0 34 3 3 1 % 0.00 0.00 0.00 100.00 0.00 0.00 0.00 100.00 47.37 10.53 42.11 0.00 8.33 75.00 0.00 16. 15.38 38.46 15.38 30.77 27.27 36.36 36.36 0.00 20.00 40.00 10.00 35.00 0.00 90.91 0.00 9.09 82.93 7.32 7.32 2.44 Table 8: Distribution of human verification labels for each model, over exact-match-correct instances. Each aspect is broken down into counts (#) and percentages (%). Note that percentages here are computed within each models EM-correct instances. (1) Crt+ & Com+, (2) Crt+ & Com-, (3) Crt- & Com+, and (4) Crt- & Comcorrespond to (1) correct and complete, (2) correct and incomplete, (3) incorrect and complete, and (4) incorrect and incomplete, respectively. Question vs. Option Meaning. Another consistent pattern is that some models perform better on interpreting options than on questions. For instance, o4-mini achieves 8.33% Crt+&Com+ and 75% Crt+&Comin option meaning, indicating that despite missing interpretation, its understanding of options is mostly correct. This contrast suggests that understanding full questions is considerably harder than interpreting isolated options, because questions require reconstructing relationships among multiple words according to the grammar book, rather than mapping single words to dictionary entries. In other words, option meaning can often be resolved through shallow lexical lookup, whereas question interpretation demands faithful parsing of clause structures and argument roles. 23 Working in Progress Humans, by contrast, show no such imbalance, with parsing and both meaning dimensions converging at high levels. Complete vs. Incomplete Reasoning. Strong reasoning models such as GPT-5 (context) reach relatively high proportions of Crt+&Com+ in parsing (45.45%) and question meaning (59.09%), yet collapse to 0 in option meaning. Instead, almost all option cases fall into Crt+&Com-, reflecting reasoning traces where partial lexical alignment is visible but the full interpretation is not explicitly documented. It suggests that models often omit parts of the reasoning they deem unnecessary, leaving incomplete chains in the written output."
        },
        {
            "title": "5.4.2 Analysis across Systems",
            "content": "As general-purpose LLM, both tool and context settings of GPT-4o fail almost completely, where all EM-correct cases fall into the Crt-&Comcategory across parsing, question meaning, and option meaning. This indicates that GPT-4o shows almost no evidence of rule-based reasoning in its traces, and its EM-level success likely comes from random guessing or coincidental alignment with commonsense priors. Amongst reasoning LLMs, both DS and o4-mini exhibit partial success via shortcuts rather than full parsing. For DS, option interpretation shows some strength: 11 out of 19 EMcorrect cases contain at least partially correct option meanings, yet parsing is mostly incorrect (Crt-&Com+). This reflects meaning without parsing behaviour: the model often guesses semantics from lexical cues and world knowledge, bypassing formal structure. In contrast, o4-minis parsing and question meaning remain poor, but 10 (1+9) out of 12 EM-correct cases contain at least partially correct option meanings (mostly Crt+&Com-), indicating reliance on shallow lexical shortcutsmatching familiar words without reconstructing the questions syntax. Across both settings, o3 produces partially correct outputs in all three aspects, but rarely aligns them into complete reasoning step. In the context setting (#EM=22), question meaning is its relative strength (Crt+&Com+ 15/22 = 68.18%), while question parsing is more scattered (Crt+&Com+ 31.82%, Crt-&Com+ 36.36%), indicating that the model often delivers complete but incorrect parse. Option meaning is fragmented (Crt+&Com+ 27.27%, Crt+&Com36.36%, Crt-&Com+ 36.36%). The tool setting (#EM=13) follows similar pattern: question meaning is relatively strong (Crt+&Com+ 69.23%), but option meaning shows weaker completeness (Crt+&Com+ 15.38%, Crt+&Com38.46%). GPT-5, particularly in the context setting (#EM=22), achieves the highest totals across parsing (Crt+&Com+ 45.45%, Crt+&Com22.73%) and question meaning (Crt+&Com+ 59.09%). However, option meaning is almost entirely incomplete (Crt+&Com20/22 = 90.91%, Crt+&Com+ 0%), showing that while the model can consistently map options to dictionary entries, it rarely produces full, verifiable reasoning trace. This pattern suggests emerging metalinguistic awareness to limited extent, where GPT-5 is often incomplete rather than incorrect, but still lacks the systematic, end-to-end grammatical mastery achieved by humans. The tool setting (#EM=20) performs weaker overall, with higher proportions of Crt-&Comacross all aspects (30% in parsing, 25% in question meaning, 35% in option meaning), reflecting failures in handling morphological variation and retrieval. Such evidence shows that GPT-5 has the strongest potential, but its reasoning remains fragmented, revealing only partial metalinguistic competence compared to humans systematic grammar-based reasoning. Humans consistently rely on structured grammar-based reasoning, in sharp contrast to LLMs shortcut-based strategies. Over 80% of their EM-correct cases are fully correct and complete in parsing, question meaning, and option meaning."
        },
        {
            "title": "6 Qualitative Analysis and Case Study",
            "content": "To better demonstrate our analysis and model behaviour, we present case studies and qualitative analysis, featuring the selected systems. The case is shown in Table 9, with corresponding English translation and human-annotated morphemic and gloss. We choose this case as its meaning is relatively simple, and it receives correct EM answers from all 24 Working in Progress Type Question Option Morphemic Gloss Stems Camlang (English) nosn. us ner. meni myva ghot? (A child wants to survive. What does he need to do?) A. n. aw ghot (he needs to study) B. dit ghot (he needs to fall down) C. n. at ghot (he needs to play) D. wecmylirsi irwec ghot (he needs to ask questions) E. ghot (he needs to eat) [correct] F. nepli cewmyl nak (none of the above answers) nos = n. A. us -m = jer -. me -nI. mInfa -m = ot -. child = TOP. live-INF=want-3SG. what-ACC. WH=ACC-doINF=need-3SG nos: (n.) child, kid; us: (v.) live, survive; jer: (v.) want; me: (pro.) Wh; fa: (v.) do, make, create; xot: (v.) must, need, require; n. aw: (v.) learn, study (+ACC object); dit: (n.) fall, fall down; n. at: (n.) play; wecmyl: (n. ORD) question; wec: (v.) ask (someone GEN something ACC); e: (v.) eat; nepli: (adj. ORD) true, correct; cewmyl: (n.) answer; e: (v.) eat; nak: (v.) do not have, do not exist Table 9: Example Camlang case from Camlang-CSQA-v0, with morphemic segmentation and interlinear gloss. Models Q. Parsing Q. Meaning O. Meaning 4o (tool) DS (context) o3 (context) GPT-5 (tool) GPT-5 (context) Human Crt-&ComCrt-&Com+ Crt-&ComCrt-&ComCrt+&ComCrt+&Com+ Crt-&ComCrt+&Com+ Crt+&Com+ Crt-&ComCrt+&Com+ Crt+&Com+ Crt-&ComCrt+&Com+ Crt-&Com+ Crt-&ComCrt+&ComCrt+&Com+ Table 10: Human-annotated labels for the same case as in Table 9. systems, while the responses differ greatly in the correctness and completeness of analysis. We present the human-evaluated labels from different aspects in Table 10. Human Interpretation. The question sentence nosn. us ner. meni myva ghot? is parsed as follows. First, nos=n. combines nos (child) with the topic marker -n. A, yielding as for the child. Next, us-m= nerforms (he) wants to live, where us (live) takes the infinitive marker -m=, and ner (want) carries 3SG agreement. The second clause meni myva ghot? consists of the H-pronoun meni (what-ACC), the Hhead marking my= plus fa-m= (do-INF) (orthographically myva), and the modal ghot- (need-3SG) yielding what does he need to do? Together, the full sentence means child wants to survive. What does he need to do? All candidate answers (AE) share the modal ghot- (need-3SG), which attaches to preceding stem or phrase to form the structure he needs to X. Option n. aw ghot combines n. aw (learn, study) with the modal, yielding he needs to study. Option dit ghot combines dit (fall) with the modal, yielding he needs to fall. Option n. at ghot combines n. at (play) with the modal, yielding he needs to play. Option wecmylirsi irwec ghot combines the phrase wecmylirsi irwec (questions-GEN.PL ask-3pl.ACC, i.e., ask them questions) with the modal, yielding he needs to ask them questions. Option ghot combines (eat) with the modal, yielding he needs to eat. Finally, Option nepli cewmyl nak is not formed with the modal but instead consists of nepli (true), cewmyl (answers), and nak (not exist), yielding true answers do not exist. 25 Working in Progress To determine the correct answer, lets break down the sentence and options using the resources provided. GPT-4o (tool) ### Sentence Analysis 1. nosn. us ner. - nosn. a: This word wasnt found in the search results, but based on the structure, it might be noun or verb. - us: This word wasnt found in the search results, but it could be an adjective or adverb. - ner: This word wasnt found in the search results, but it might be verb or noun. 2. meni myva gh ot? - meni: This is an interrogative form, similar to what. - myva: This word wasnt found in the search results, but it could be verb or noun. - gh ot: This word wasnt found in the search results, but it might be verb or noun. ### Options Analysis - A: n. aw gh ot - B: dit gh ot - C: n. at gh ot - D: wecmylirsi irwec gh ot - E: gh ot - F: nepli cewmyl nak ### Reasoning Given the interrogative meni, the sentence is likely asking question about an action or state related to gh ot. The options seem to provide different actions or states. - gh ot appears in several options, suggesting it might be key verb or noun in the sentence. - The structure of the sentence and options suggests focus on an action or state, possibly related to gh ot. ### Conclusion Without specific translations for each word, the best approach is to match the structure and common elements. Since gh ot appears in multiple options, it is likely central to the question. The options with gh ot are A, B, C, D, and E. Given the lack of specific translations, the choice is somewhat speculative. However, based on the structure and commonality, Option E: gh ot seems to be simple and direct match. The final answer is E. Table 11: GPT-4o (tool) output of the case example. GPT-4o. We present the output of 4o as shown in Table 11. Compared with human interpretation, GPT-4o provides no genuine parsing or semantic interpretation of the question. In particular, it fails to identify any morphological markers and produces only vague guesses such as might be noun or verb showing complete lack of morphological grounding. At the level of meaning, 4o does not reconstruct the first clause (a child wants to live) nor the second clause as modal question (what does he need to do?). Instead, it merely speculates that meni is interrogative and ghot is important, without attributing to ghot its modal sense of need. Also, 4o does not offer any lexical analysis of the options and 26 Working in Progress DeepSeek-R1 The question in Camlang is: nosn. us ner. meni myva gh ot? - nosn. means the child (with topic marker =n. A). - us means to live/survive. - ner is the 3rd person singular present form of jer (to want), with nasal mutation from object proclitic n= (for 3sg ACC), so wants it. - The first sentence translates to: The child wants to live. - The question meni myva gh ot? has: - meni = what (ACC). - myva is not standard verb; it may be mishearing or variant of mava (to constitute/make up), but contextually it doesnt fit. - gh ot = need/must (from ot). The question asks: What does [the child] need to do? given the context of survival. Options: - A: n. aw gh ot need to learn/study (n. aw = learn, ORD). Not essential for survival. - B: dit gh ot need to fall (dit = fall). Illogical for survival. - C: n. at gh ot need to play (n. at = play, ORD). Not critical for survival. - D: wecmylirsi irwec gh ot need to ask them questions (wecmylirsi = questions-GEN.PL, irwec = ask-3pl.ACC). Unrelated to living. - E: gh ot need to eat (e = eat, ORD). Eating is fundamental for survival. - F: nepli cewmyl nak true answers do not exist (nepli = true, cewmyl = answers, nak = not exist). Not an action. The child needs to eat to survive, making the correct choice. The final answer is E. Table 12: DeepSeek-R1 output of the case example. simply notices that ghot appears across candidates, choosing the shortest and simplest one. The correct answer is therefore obtained by superficial matching rather than by parsing or understanding, effectively resembling random guessing. DS. We present the output of DS as shown in Table 12. For question parsing, DS correctly identifies the topic marker in nos=n. and the structure us-m= ner-, but it misanalyses myva as possible variant of mava (make up) and fails to recognise it as my= fa-m= with the modal ghot- (need to do X). This leads to incomplete correctness, although the analysis remains largely comprehensive. Moreover, given the incorrect parsing, DS provides correct interpretations of the question The child wants to live. What does he need to do? and options, which match the human reference exactly and are both correct and complete. This provides further evidence that DS relies on contextual pattern matching triggered by the survival scenario and the modal ghot, rather than on reconstructing the full syntactic structure. o3 (context). The output of GPT-o3 (context) is shown in Table 13. It correctly analyses nos=n. and us n=jer-, and further provides literal interlinear gloss. However, it misparses the second clause as meni mI=ghot (what.ACC WH.ACC=need-3SG), overlooking the fa-m= element in myva. Despite incorrect parsing, o3 captures the intended reading that the child needs (to do) something given the survival context. Moreover, while covering all options, it incorrectly treats option (wecmylirsi irwec ghot) as long NP rather than an action phrase (ask them questions), and motivates ghot via an unsupported alternation, i.e. e-m=xot ghot in casual style. Working in Progress Step-by-step reasoning GPT-o3 (context) 1. Lexical meanings nos child ( Vocab ) =n. is the topic clitic ( NM1E4, MS6A1 ) us to live, survive ( Vocab ) jer to want nasal mutation after n-clitic gives ner ( OP1B3 ) meni what-ACC ( wh-word with -nI accusative; cf. MS4B1 example meni . . . ) ot need, must preceded by nasal wh-object clitic mI=, nasalfricative coalescence yields gh ot ( OP1D1 ) 2. Literal gloss of the two sentences nos=n. us n=jer-. child.TOP live 3SG.ACC=want-3SG As for the child, (he) wants to live. meni mI=gh ot ? what.ACC WH.ACC=need-3SG ? What does (he) need? 3. Required answer: verb meaning an action that is necessary for child to keep living. Among the choices: n. aw study; dit fall; n. at play (with toys); is long NP, not an action; eat. Obviously, eating is the basic requirement for staying alive, matching the context of the question. 4. Surface form gh ot (must eat): e-m=x ot phonotactically may also be written gh ot in casual style, paralleling the model sentence xaxsy gh ot ny in VM8C1. Therefore option best answers the question. The final answer is Table 13: GPT-o3 (context) output of the case example. GPT-5 (tool and context). The outputs of GPT-5 (tool) and GPT-5 (context) are shown in Table 14. Compared with other systems, the responses of GPT-5 are relatively shorter and simpler, omitting many reasoning steps (although we set both verbosity and reasoning effort as high). In the tool setting, GPT-5 only notes the topic marker in nos=n. and the modal ghot, but it ignores the internal structure of us-m= nerand fails to analyse myva as my= fa-m=. Its paraphrase of the question as What do we need (to do)?, omitting the explicit subject and survival context, and it incorrectly rules out other verb options as ungrammatical nouns. In contrast, the context setting gives more accurate interpretation. It correctly identifies nos=n. and us and renders the question as For child to live, what is needed?. Although it still does not parse myva as my= fa-m=, it provides correct overall meaning and selects the right option without analysing the distractors."
        },
        {
            "title": "7 Conclusion and Future Work",
            "content": "We presented Camlang, typologically plausible yet unattested constructed language equipped with grammar book and dictionary, designed to evaluate whether LLMs can 28 Working in Progress GPT-5 (tool) Reasoning: - nosn. ends with the topic marker =n. A, so the first sentence sets nos . . . as the sentence topic; that matches how topics are marked in Camlang (e.g., san. =n. today=TOP) . - The second sentence is wh-question with meni what, which is exactly how wh-questions are formed in Camlang (wh-expression fronted; no yes-no proclitic) . - gh ot is the modal verb need, and Camlang modals take infinitive complements (not nouns). The grammar illustrates this with eat as the infinitive complement: xaxsy gh ot ny need to eat something and pyje . . . gh otly Do you need to eat . . . ? . - Therefore, the natural answer to What do we need (to do)? is verb in the infinitive domain, i.e., eat as the complement of gh ot. The other options are either nouns used as complements to gh ot (ungrammatical for modals) or use nak, the negative copula for adjectival/postpositional predicates, which is irrelevant here . So, among the choices, only E: gh ot matches the required INF + need structure for modals in Camlang . The final answer is E. GPT-5 (context) nos=n. = topic as for the child; us = live, survive; meni . . . gh ot? = what is needed? So the question asks: For child to live, what is needed? Among the options, the only sensible minimal requirement expressed is gh ot = (one) needs to eat. The final answer is E. Table 14: GPT-5 (tool) and GPT-5 (context) outputs of the case example. engage in explicit metalinguistic deductive reasoning. Through the construction of CamlangCSQA-v0, we showed that while humans can successfully acquire Camlang and integrate it with commonsense reasoning with existing knowledge, current state-of-the-art LLMs fall short, often relying on shallow alignment rather than systematic grammatical mastery. As this is an ongoing project, we plan to expand Camlang and our evaluation framework in several directions. First, we will scale Camlang to broader suite of tasks, including translation, grammar questions, and mathematical reasoning, in order to probe different aspects of linguistic and cognitive competence. Second, we will extend the human experiments to larger pool of participants, providing stronger empirical evidence on Camlangs learnability. Third, we will perform more comprehensive model evaluations."
        },
        {
            "title": "Author Contributions",
            "content": "Fenghua Liu is the core contributor to the Camlang development, Camlang-CSQA-v0 annotation, human verification evaluation, and contributes to the paper writing, in particular for the Camlang language section ( 3) and case study section ( 6). Yulong Chen proposes the idea, leads the project, conducts the LLM experiments and evaluation, and drafts this manuscript. Yixuan Liu, Zhujun Jin and Solomon Tsai contribute to the Camlang development, in particular, the refinement process. Yixuan Liu additionally contributes to the proofreading and revision of this manuscript, and the human participant experiment. Zhujun Jin additionally contributes to the evaluation in 3.4. Ming Zhong contributes to the discussion. 29 Working in Progress"
        },
        {
            "title": "Acknowledgments",
            "content": "We appreciate Theresa Biberauer and Dora Alexopoulou for their suggestions and evaluation during the development of Camlang. We also thank Meiru Zhang, Sana Kidwai, Rami Aly, Leyang Cui, Weiwei Sun, Yufang Hou, Fei Xia, and Bonnie Webber for their discussion of this work. This work receives financial support from Cambridge Language Sciences and AI@Cam (NRBF.GAAB). Yulong Chen is further supported by the ERC grant AVERITEC (GA 865958)."
        },
        {
            "title": "References",
            "content": "Ife Adebara and Muhammad Abdul-Mageed. Towards afrocentric nlp for african languages: Where we are and where we can go. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 38143841, 2022. Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal, Dinesh Khandelwal, Parag Singla, and Dinesh Garg. Explanations for commonsenseqa: New dataset and In Proceedings of the 59th Annual Meeting of the Association for Computational models. Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 30503065, 2021. Asif Agha. Language and social relations, volume 24. Cambridge University Press, 2006. AIME. Aime benchmark, 2025. Available at https://www.vals.ai/benchmarks/aime-202 5-08-12. Miltiadis Allamanis, Earl Barr, Premkumar Devanbu, and Charles Sutton. survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR), 51(4): 137, 2018. Stjepan Androic. Dialects of English in Fantasy Films and Videogames. PhD thesis, University of Zagreb. University of Zagreb, Faculty of Humanities and Social . . . , 2019. Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. On the cross-lingual transferability of monolingual representations. In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 46234637, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.421. URL https://aclanthology.org/2020.acl-main. 421/. Simone Balloccu, Patrıcia Schmidtova, Mateusz Lango, and Ondˇrej Duˇsek. Leak, cheat, repeat: Data contamination and evaluation malpractices in closed-source llms. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 6793, 2024. Jasmijn Bastings, Marco Baroni, Jason Weston, Kyunghyun Cho, and Douwe Kiela. Jump to better conclusions: Scan both left and right. arXiv preprint arXiv:1809.04640, 2018. Robert Beard. Derivation. The handbook of morphology, pp. 4465, 2017. Shabnam Behzad, Amir Zeldes, and Nathan Schneider. To ask LLMs about English In Yaser Al-Onaizan, Mohit grammaticality, prompt them in different language. Bansal, and Yun-Nung Chen (eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 1562215634, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-emnlp.916. URL https://aclanthology.org/2024.findings-emnlp.916/. Paola Beninc`a. The left periphery of medieval romance. 2004. Ellen Bialystok. Bilingualism in development: Language, literacy, and cognition. Cambridge University Press, 2001a. Working in Progress Ellen Bialystok. Metalinguistic aspects of bilingual processing. Annual review of applied linguistics, 21:169181, 2001b. Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, Ben He, Shanshan Jiang, and Bin Dong. Chatgpt is knowledgeable but inexperienced solver: An investigation In Proceedings of the 2024 Joint of commonsense problem in large language models. International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pp. 30983110, 2024. Hagit Borer. The syntax of pronominal clitics, volume 19. BRILL, 2020. Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models. In 32nd USENIX security symposium (USENIX Security 23), pp. 52535270, 2023. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. Yulong Chen, Yang Liu, Ruochen Xu, Ziyi Yang, Chenguang Zhu, Michael Zeng, and Yue Zhang. UniSumm and SummZoo: Unified model and diverse benchmark for few-shot summarization. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1283312855, Toronto, Canada, July 2023a. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.718. URL https://aclanthology.org/2023.acl-long.718/. Yulong Chen, Huajian Zhang, Yijie Zhou, Xuefeng Bai, Yueguan Wang, Ming Zhong, Jianhao Yan, Yafu Li, Judy Li, Xianchao Zhu, and Yue Zhang. Revisiting cross-lingual summarization: corpus-based study and new benchmark with improved annotation. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 93329351, Toronto, Canada, July 2023b. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.519. URL https://aclanthology.org/2023.acl-long.519/. Yulong Chen, Yang Liu, Jianhao Yan, Xuefeng Bai, Ming Zhong, Yinghao Yang, Ziyi Yang, Chenguang Zhu, and Yue Zhang. See what llms cannot answer: self-challenge framework for uncovering llm weaknesses. arXiv preprint arXiv:2408.08978, 2024. Nathan Chi, Teodor Malchev, Riley Kong, Ryan Chi, Lucas Huang, Ethan Chi, Thomas McCoy, and Dragomir Radev. Modeling: novel dataset for testing linguistic reasoning in language models. arXiv preprint arXiv:2406.17038, 2024. Nadezhda Chirkova and Vassilina Nikoulina. Zero-shot cross-lingual transfer in instruction tuning of large language models. In Proceedings of the 17th International Natural Language Generation Conference, pp. 695708, 2024. Noam Chomsky. Aspects of the Theory of Syntax. Number 11. MIT press, 2014. Noam Chomsky, Ian Roberts, and Jeffrey Watumull. The false promise of ChatGPT. New York Times (Op-Ed), Mar 8 2023. URL: https://www.nytimes.com/2023/03/08/opinion /noam-chomsky-chatgpt-ai.html. Herbert Clark. Using language. Cambridge university press, 1996. Jonathan Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki. Tydi qa: benchmark for information-seeking question answering in ty pologically di verse languages. Transactions of the Association for Computational Linguistics, 8:454470, 2020. Bernard Comrie. Language universals and linguistic typology: Syntax and morphology. University of Chicago press, 1989. 31 Working in Progress Aleksandra Cwiek, Susanne Fuchs, Christoph Draxler, Eva Liina Asu, Dan Dediu, Katri Hiovain, Shigeto Kawahara, Sofia Koutalidis, Manfred Krifka, Partel Lippus, et al. The bouba/kiki effect is robust across cultures and writing systems. Philosophical Transactions of the Royal Society B, 377(1841):20200390, 2022. Ernest Davis. Benchmarks for automated commonsense reasoning: survey. ACM Computing Surveys, 56(4):141, 2023. DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. How abilities in large language models are affected by supervised fine-tuning data composition. arXiv preprint arXiv:2310.05492, 2023. Rod Ellis. Principles of instructed language learning. System, 33(2):209224, 2005. ISSN 0346-251X. doi: https://doi.org/10.1016/j.system.2004.12.006. URL https://www.scienc edirect.com/science/article/pii/S0346251X05000138. Nicholas Evans and Stephen Levinson. The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and brain sciences, 32(5): 429448, 2009. Victoria Fromkin, Robert Rodman, Nina Hyams, Mengistu Amberber, Felicity Cox, and Rosalind Thornton. An Introduction to Language with Online Study Tools 12 Months. Cengage AU, 2017. Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, Zhengyang Tang, Benyou Wang, Daoguang Zan, Shanghaoran Quan, Ge Zhang, Lei Sha, Yichang Zhang, Xuancheng Ren, Tianyu Liu, and Baobao Chang. Omni-math: universal olympiad level mathematic benchmark for large language models, 2024. Ryan Georgi, Fei Xia, and William Lewis. Comparing language similarity across genetic and typologically-based groupings. In Chu-Ren Huang and Dan Jurafsky (eds.), Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pp. 385 393, Beijing, China, August 2010. Coling 2010 Organizing Committee. URL https: //aclanthology.org/C10-1044/. Mark Gold. Language identification in the limit. Information and control, 10(5):447474, 1967. Jean Emile Gombert. Metalinguistic development. University of Chicago Press, 1992. Colin Gorrie. Reduplication: typological overview. Satyam Goyal and Soham Dan. Iolbench: Benchmarking llms on linguistic reasoning. arXiv preprint arXiv:2501.04249, 2025. Antony Green. The independence of phonology and morphology: The celtic mutations. Lingua, 116(11):19461985, 2006. Joseph Greenberg. The diachronic typological approach. Approaches to language typology, pp. 14566, 1995. Joseph Greenberg et al. Some universals of grammar with particular reference to the order of meaningful elements. Universals of language, 2:73113, 1963. Francisco Guzman, Peng-Jen Chen, Myle Ott, Juan Pino, Guillaume Lample, Philipp Koehn, Vishrav Chaudhary, and MarcAurelio Ranzato. The FLORES evaluation datasets for lowresource machine translation: NepaliEnglish and SinhalaEnglish. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural 32 Working in Progress Language Processing (EMNLP-IJCNLP), pp. 60986111, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1632. URL https://aclanthology.org/D19-1632/. Martin Haspelmath. The world atlas of language structures. Oxford University Press, 2005. Marc D. Hauser, Noam Chomsky, and W. Tecumseh Fitch. The faculty of language: What is it, who has it, and how did it evolve? Science, 298(5598):15691579, 2002. doi: 10.1126/sc ience.298.5598.1569. URL https://www.science.org/doi/abs/10.1126/science.298.55 98.1569. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. Proceedings of the International Conference on Learning Representations (ICLR), 2021. Geoffrey Hinton. Interview on ai and human-like understanding (nobel prize, dec 2024). Nobel Prize Outreach Interview, 2024. URL: https://www.nobelprize.org/prizes/phys ics/2024/hinton/interview/. Charles Hockett and Charles Hockett. The origin of speech. Scientific American, 203(3): 8897, 1960. Mark Hopkins. Towards more natural artificial languages. In Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL), pp. 8594, 2022. Bokai Hu, Sai Ashish Somayajula, Xin Pan, and Pengtao Xie. Improving the language understanding capabilities of large language models using reinforcement learning, 2024. Wilhelm von Humboldt. 5. Uber das Entstehen der grammatischen Formen, und ihren Einfluss auf die Ideenentwicklung, pp. 285313. De Gruyter, Berlin, Boston, 1905. ISBN 9783110833751. doi: doi:10.1515/9783110833751-005. URL https://doi.org/10.1515/9783110833751-0 05. Kirsten Hummel. Introducing second language acquisition: Perspectives and practices. 2021. Jonathan Hus and Antonios Anastasopoulos. Back to school: Translation using grammar books. arXiv preprint arXiv:2410.15263, 2024. Sh oichi. Iwasaki and Inkapiromu Puriya. Horie. reference grammar of Thai. Cambridge University Press, Cambridge, 2005. ISBN 0521650852. Laura Janda. geography of case semantics: The Czech dative and the Russian instrumental, volume 4. Walter de Gruyter, 2013. Pierre Janton. Esperanto: Language, literature, and community. Suny Press, 1993. Henry Kahane. typology of the prestige language. Language, 62(3):495508, 1986. Julie Kallini, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, and Christopher Potts. Mission: Impossible language models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1469114714, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.787. URL https://aclanthology.org/2024.acl-long.787/. Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. Gpt-4 passes the bar exam. Philosophical Transactions of the Royal Society A, 382(2270):20230254, 2024. Karl HS Kim, Norman Relkin, Kyoung-Min Lee, and Joy Hirsch. Distinct cortical areas associated with native and second languages. Nature, 388(6638):171174, 1997. Wolfgang Klein. Second language acquisition. Cambridge University Press, 1986. 33 Working in Progress Hilda Koopman. Prepositions, postpositions, circumpositions, and particles. Mapping spatial PPs, 6:2673, 2010. David Korn. Types of labial vowel harmony in the turkic languages. Anthropological linguistics, 11(3):98106, 1969. Stephen Krashen. Principles and practice in second language acquisition. 1982. Stefanie Krause and Frieder Stolzenburg. Commonsense reasoning and explainable artificial intelligence using large language models. In European Conference on Artificial Intelligence, pp. 302319. Springer, 2023. Tiffany Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepa no, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, et al. Performance of chatgpt on usmle: potential for ai-assisted medical education using large language models. PLoS digital health, 2(2):e0000198, 2023. Brenden Lake and Marco Baroni. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In International conference on machine learning, pp. 28732882. PMLR, 2018. James Lantolf and Aneta Pavlenko. Sociocultural theory and second language acquisition. Annual review of applied linguistics, 15:108124, 1995. Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Remi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. Science, 378(6624):10921097, 2022. Da-Chen Lian, Ri-Sheng Huang, Pin-Er Chen, Chunki Lim, You-Kuan Lin, Guan-Yu Tseng, Zi-Cheng Yang, and Shu-Kai Hsieh. Lingbench++: linguistically-informed benchmark and reasoning framework for multi-step and cross-cultural inference with llms. arXiv preprint arXiv:2507.16809, 2025. Karen Melissa Lichtman. Child-adult differences in implicit and explicit second language learning. University of Illinois at Urbana-Champaign, 2012. Chin-Yew Lin. Rouge: package for automatic evaluation of summaries. In Text summarization branches out, pp. 7481, 2004. Yichao Lu, Phillip Keung, Faisal Ladhak, Vikas Bhardwaj, Shaonan Zhang, and Jason Sun. neural interlingua for multilingual machine translation, 2018. URL https: //arxiv.org/abs/1804.08198. Gary Marcus, Sugumaran Vijayan, Shoba Bandi Rao, and Peter Vishton. Rule learning by seven-month-old infants. Science, 283(5398):7780, 1999. John McCarthy. Sympathy and phonological opacity. Phonology, 16(3):331399, 1999. Meta. The llama 3 herd of models, 2024. Edith Moravcsik. On the distribution of ergative and accusative patterns. Lingua, 45(3-4): 233279, 1978. Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, and James Allen. corpus and cloze evaluation for deeper understanding of commonsense stories. In Kevin Knight, Ani Nenkova, and Owen Rambow (eds.), Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 839 849, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1098. URL https://aclanthology.org/N16-1098/. Mariacristina Musso, Andrea Moro, Volkmar Glauche, Michel Rijntjes, urgen Reichenbach, Christian uchel, and Cornelius Weiller. Brocas area and the language instinct. Nature neuroscience, 6(7):774781, 2003. 34 Working in Progress William Nagy. Metalinguistic awareness and the vocabulary-comprehension connection. Vocabulary acquisition: Implications for reading comprehension, pp. 5277, 2007. William Nagy and Richard Chase Anderson. Metalinguistic awareness and literacy acquisition in different languages. Center for the Study of Reading Technical Report; no. 618, 1995. OpenAI. Gpt-4 technical report, 2023. OpenAI. Introducing O3 and O4-mini. OpenAI Blog (Apr 2024), 2024. Available at https://openai.com/index/introducing-o3-and-o4-mini/. OpenAI. Gpt-4o system card, 2024. OpenAI. Introducing GPT-5. OpenAI Blog (Aug 2025), 2025. Available at https://openai .com/index/introducing-gpt-5/. Lauren Parsons, Reinie Cordier, Natalie Munro, Annette Joosten, and Renee Speyer. systematic review of pragmatic language interventions for children with autism spectrum disorder. PloS one, 12(4):e0172242, 2017. Nisarg Patel, Mohith Kulkarni, Mihir Parmar, Aashna Budhiraja, Mutsumi Nakamura, Neeraj Varshney, and Chitta Baral. Multi-LogiEval: Towards evaluating multi-step logical reasoning ability of large language models. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 2085620879, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.1160. URL https://aclanthology.org/2024.emnlp-main.1160/. Martin Pickering and Simon Garrod. An integrated theory of language production and comprehension. Behavioral and brain sciences, 36(4):329347, 2013. Manfred Pienemann. Is language teachable? psycholinguistic experiments and hypotheses. Applied linguistics, 10(1):5279, 1989. Muhammad Reza Qorib, Junyi Li, and Hwee Tou Ng. Just go parallel: Improving the multilingual capabilities of large language models. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 33411 ISBN 33424, Vienna, Austria, July 2025. Association for Computational Linguistics. 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.1602. URL https://aclanthology.o rg/2025.acl-long.1602/. Andrew Radford. English syntax: An introduction. Cambridge University Press, 2004. Chase Wesley Raymond. Linguistic reference in the negotiation of identity and action: Revisiting the t/v distinction. Language, 92(3):636670, 2016. ISSN 00978507, 15350665. URL http://www.jstor.org/stable/44164110. Arthur Reber. Implicit learning of artificial grammars. Journal of verbal learning and verbal behavior, 6(6):855863, 1967. Patrick Rebuschat and John Williams. Implicit and explicit knowledge in second language acquisition. Applied Psycholinguistics, 33(4):829856, 2012. Ian Roberts. Agreement and head movement: Clitics, incorporation, and defective goals, volume 59. MIT press, 2010. Miguel Rodrıguez-Mondo nedo. The syntax of objects: Agree and differential object marking. University of Connecticut, 2007. Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden Lake. benchmark for systematic generalization in grounded language understanding. Advances in neural information processing systems, 33:1986119872, 2020. 35 Working in Progress Russell Scheinberg, Ameeta Agrawal, Amber Shore, and So Young Lee. Explain-thenprocess: Using grammar prompting to enhance grammatical acceptability judgments. arXiv preprint arXiv:2506.02302, 2025. Mark Shuttleworth. Dictionary of translation studies. Routledge, 2014. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Shoeb, Abubakar Abid, Adam Fisch, Adam Brown, Adam Santoro, Aditya Gupta, Adri Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on machine learning research, 2023. Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 41494158, 2019. Jacqueline Thomas. Metalinguistic awareness in second-and third-language learning. Advances in psychology, 83:531545, 1992. William Tunmer and Michael Herriman. The development of metalinguistic awareness: conceptual overview. Metalinguistic awareness in children: Theory, research, and implications, pp. 1235, 1984. Andrea Tyler and William Nagy. The acquisition of english derivational morphology. Journal of memory and language, 28(6):649667, 1989. Leslie Valiant. theory of the learnable. Communications of the ACM, 27(11):11341142, 1984. Bill VanPatten. Processing instruction: Theory, research, and commentary. Routledge, 2004. Richard Venezky and Dominic Massaro. The role of orthographic regularity in word recognition. In Theory and practice of early reading, pp. 85107. Routledge, 2013. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Glue: multi-task benchmark and analysis platform for natural language understanding. In International Conference on Learning Representations, 2018. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Superglue: stickier benchmark for generalpurpose language understanding systems. Advances in neural information processing systems, 32, 2019. Xinming Wang, Jian Xu, Aslan Feng, Yi Chen, Haiyang Guo, Fei Zhu, Yuanqi Shao, Minsi Ren, Hongzhu Yi, Sheng Lian, et al. The hitchhikers guide to autonomous research: survey of scientific agents. 2025. Daniel A. Weiskopf. Compound nominals, context, and compositionality. Synthese, 156(1): 161204, 2007. ISSN 00397857, 15730964. URL http://www.jstor.org/stable/27653511. Jennifer White and Ryan Cotterell. Examining the inductive bias of neural language models with artificial languages. arXiv preprint arXiv:2106.01044, 2021. Anna Wierzbicka. The concept of dialoguein cross-linguistic and cross-cultural perspective. Discourse Studies, 8(5):675703, 2006. John Williams and Patrick Rebuschat. Implicit learning and second language acquisition. Routledge Evanston, IL, USA, 2016. Chen Zhang, Xiao Liu, Jiuheng Lin, and Yansong Feng. Teaching large language models an unseen language on the fly. arXiv preprint arXiv:2402.19167, 2024. 36 Working in Progress Chen Zhang, Jiuheng Lin, Xiao Liu, Zekai Zhang, and Yansong Feng. Read it in two steps: Translating extremely low-resource languages with code-augmented grammar books. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 39773997, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acllong.202. URL https://aclanthology.org/2025.acl-long.202/. 37 Working in Progress"
        },
        {
            "title": "A Typological Features of Camlang",
            "content": "To compare Camlang with other known languages, we manually annotate its profile using the features from the World Atlas of Language Structures (WALS) (Haspelmath, 2005). The full set of features is presented in Table 15. For the fairness of future evaluation and to avoid the possibility that models exploit detailed typological cues for grammar guessing, we do not provide fine-grained feature descriptions. Also, for simplicity, we do not show features that are not applicable. Table 15: WALS-style features of Camlang ID Name Area Camlang Consonant Inventories 1A Vowel Quality Inventories 2A Consonant-Vowel Ratio 3A Voicing in Plosives and Fricatives 4A Voicing and Gaps in Plosive Systems 5A Uvular Consonants 6A Glottalized Consonants 7A Lateral Consonants 8A The Velar Nasal 9A Vowel Nasalization 10A Front Rounded Vowels 11A Syllable Structure 12A Tone 13A 14A Fixed Stress Locations 15A Weight-Sensitive Stress 16A Weight Factors in Weight-Sensitive Stress 17A 18A 19A 20A 21A 21B 22A 23A 24A 25A 25B 26A 27A 28A 29A 30A 31A 32A 33A 34A Systems Rhythm Types Absence of Common Consonants Presence of Uncommon Consonants Fusion of Selected Inflectional Formatives Exponence of Selected Inflectional Formatives Exponence of Tense-Aspect-Mood Inflection Inflectional Synthesis of the Verb Locus of Marking in the Clause Locus of Marking in Possessive Noun Phrases Locus of Marking: Whole-language Typology non zero marking Prefixing vs. Suffixing in Inflectional Morphology Reduplication Case Syncretism Syncretism in Verbal Person/Number Marking Number of Genders Sex-based and Non-sex-based Gender Systems Systems of Gender Assignment Coding of Nominal Plurality Occurrence of Nominal Plurality Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Phonology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Morphology Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category 5 3 5 4 2 1 1 4 1 2 2 2 1 1 8 1 5 1 1 1 1 1 5 3 3 2 3 1 4 3 1 1 1 2 6 Continued on next page Working in Progress ID 35A 36A 37A 38A 39A 40A 41A 42A 43A 44A 45A 46A 47A 48A 49A 50A 51A 52A 53A 54A 55A 56A 57A 58A 58B 59A 60A 61A 62A 63A 64A 65A 66A 67A 68A 69A 70A 71A 72A 73A 74A 75A 76A 77A 78A 79A Name Area Camlang Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Nominal Category Plurality in Independent Personal Pronouns The Associative Plural Definite Articles Indefinite Articles Inclusive/Exclusive Distinction in Independent Pronouns Inclusive/Exclusive Distinction in Verbal Inflection Distance Contrasts in Demonstratives Pronominal and Adnominal Demonstratives Third Person Pronouns and Demonstratives Gender Distinctions in Independent Personal Pronouns Nominal Category Politeness Distinctions in Pronouns Nominal Category Indefinite Pronouns Nominal Category Intensifiers and Reflexive Pronouns Nominal Category Person Marking on Adpositions Nominal Category Number of Cases Nominal Category Asymmetrical Case-Marking Nominal Category Position of Case Affixes Nominal Category Comitatives and Instrumentals Nominal Category Ordinal Numerals Nominal Category Distributive Numerals Numeral Classifiers Nominal Category Conjunctions and Universal Quantifiers Nominal Category Position of Pronominal Possessive Affixes Nominal Category Obligatory Possessive Inflection Number of Possessive Nouns Possessive Classification Genitives, Adjectives and Relative Clauses Adjectives without Nouns Action Nominal Constructions Noun Phrase Conjunction Nominal and Verbal Conjunction Perfective/Imperfective Aspect The Past Tense The Future Tense The Perfect Position of Tense-Aspect Affixes The Morphological Imperative The Prohibitive Imperative-Hortative Systems The Optative Situational Possibility Epistemic Possibility Overlap between Situational and Epistemic Modal Marking Semantic Distinctions of Evidentiality Coding of Evidentiality Suppletion According to Tense and Aspect Nominal Syntax Nominal Syntax Nominal Syntax Nominal Syntax Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Verbal Categories Nominal Syntax Nominal Syntax Nominal Syntax Nominal Syntax Verbal Categories Verbal Categories Verbal Categories 8 4 3 2 5 5 2 1 1 1 2 1 2 3 2 1 2 4 1 1 1 1 1 1 1 6 4 2 1 2 1 1 2 3 2 2 1 1 1 2 3 3 2 2 4 Continued on next page 39 Working in Progress Name Area Camlang ID 79B 80A 81A 82A 83A 84A 85A 86A 87A 88A 89A 90A 90B 91A 92A 93A 94A 95A 96A 97A 98A Suppletion in Imperatives and Hortatives Verbal Categories Verbal Categories Verbal Number and Suppletion word order Order of Subject, Object and Verb word order Order of Subject and Verb word order Order of Object and Verb word order Order of Object, Oblique, and Verb word order Order of Adposition and Noun Phrase word order Order of Genitive and Noun word order Order of Adjective and Noun word order Order of Demonstrative and Noun word order Order of Numeral and Noun word order Order of Relative Clause and Noun word order Prenominal relative clauses word order Order of Degree Word and Adjective word order Position of Polar Question Particles Position of Interrogative Phrases in Conword order tent Questions Order of Adverbial Subordinator and Clause Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase Relationship between the Order of Object and Verb and the Order of Relative Clause and Noun Relationship between the Order of Object and Verb and the Order of Adjective and Noun Alignment of Case Marking of Full Noun Phrases Alignment of Case Marking of Pronouns simple clauses word order word order word order word order 99A 100A Alignment of Verbal Person Marking 101A Expression of Pronominal Subjects 102A Verbal Person Marking 103A Third Person Zero of Verbal Person Marksimple clauses simple clauses simple clauses simple clauses simple clauses ing 104A Order of Person Markers on the Verb 105A Ditransitive Constructions: The Verb simple clauses simple clauses Give 106A Reciprocal Constructions 107A Passive Constructions 108A Antipassive Constructions 108B Productivity of the Antipassive Construction simple clauses simple clauses simple clauses simple clauses 109A Applicative Constructions 109B Other Roles of Applied Objects 111A Nonperiphrastic Causative Construcsimple clauses simple clauses simple clauses tions 112A Negative Morphemes 113A Symmetric and Asymmetric Standard simple clauses simple clauses Negation 115A Negative Indefinite Pronouns and Predisimple clauses cate Negation 116A Polar Questions 117A Predicative Possession simple clauses simple clauses 5 1 1 1 1 3 1 1 1 1 1 2 1 1 5 2 1 1 1 1 2 2 2 5 4 3 1 2 1 3 4 8 5 2 2 1 1 2 Continued on next page 40 Working in Progress ID Name Area Camlang 118A Predicative Adjectives 119A Nominal and Locational Predication 120A Zero Copula for Predicate Nominals 121A Comparative Constructions 122A Relativization on Subjects 123A Relativization on Obliques 124A Want Complement Subjects 125A Purpose Clauses 126A When Clauses 127A Reason Clauses 128A Utterance Complement Clauses 143A Order of Negative Morpheme and Verb Preverbal Negative Morphemes 143E 143F Postverbal Negative Morphemes 143G Minor morphological means of signaling negation simple clauses simple clauses simple clauses simple clauses complex sentences complex sentences complex sentences complex sentences complex sentences complex sentences complex sentences word order word order word order word order 144A Position of Negative Word With Respect word order 144B to Subject, Object, and Verb Position of negative words relative to beginning and end of clause and with respect to adjacency to verb The Position of Negative Morphemes in SOV Languages 144R SONegV Order 144L word order word order word order 2 2 1 1 4 4 1 3 2 2 2 1 1 4 4 7 3"
        },
        {
            "title": "B Root Generator",
            "content": "To construct the lexical roots of Camlang, we designed random root generator based on weighted phoneme selection. Each phonotactic slot (e.g., initial, medial, coda) is associated with probability distribution over possible phonemes, specified in frequency table derived from the designed phoneme inventory. During generation, phonemes are sampled proportionally to these frequencies, and concatenated to form monosyllabic (CVC-type) or bisyllabic (CVCVCV-type) roots. To ensure naturalistic distribution, duplicates are discarded and sound iconicity is considered (e.g., front vowels for sharp objects, round vowels for round objects). This procedure yields pool of candidate roots that respects the intended phonotactic constraints while maintaining variety and plausibility."
        },
        {
            "title": "C Prompt Details",
            "content": "In addition to the grammar book and dictionary as the input, we add prompt before the question. For tool-based systems, the prompts are: Developer message: The uploaded files are the grammar book (Grammar.md) and English--Camlang vocabulary (Vocab.xlsx) for the Camlang language. You are asked to use these two resources to understand and answer the question. Prompt message: Below is multiple-choice question written in Camlang. You can use tools to help you understand the language. You are allowed to generate reasoning steps and an explanation to demonstrate your choice. However, the final line of your response must be exactly in this format, where {your answer} is the option letter (A, B, C, D, E, or F): The final answer is {your answer}. For context-only systems, the prompts are: 41 Working in Progress Algorithm 1 Random Root Generator for Camlang 1: Input: Phoneme inventories {Pi} and frequency tables {Fi} for each position 2: Output: Set of generated monosyllabic and bisyllabic roots Sample phoneme with probability proportional to its frequency in return c1 WEIGHTEDRANDOMCHOICE(P1, F1) c2 WEIGHTEDRANDOMCHOICE(P2, F2) c3 WEIGHTEDRANDOMCHOICE(P3, F3) return concatenate(c1, c2, c3) 3: function WEIGHTEDRANDOMCHOICE(P, F) 4: 5: 6: end function 7: function GENERATEMONOSYLLABICROOT 8: 9: 10: 11: 12: end function 13: function GENERATEBISYLLABICROOT 14: 15: 16: 17: 18: 19: 20: 21: end function c1 WEIGHTEDRANDOMCHOICE(P1, F1) c2 WEIGHTEDRANDOMCHOICE(P2, F2) c3 WEIGHTEDRANDOMCHOICE(P3a, F3a) c4 WEIGHTEDRANDOMCHOICE(P4, F4) c5 WEIGHTEDRANDOMCHOICE(P5, F5) c6 WEIGHTEDRANDOMCHOICE(P6, F6) return concatenate(c1, c2, c3, c4, c5, c6) 22: for = 1 to Nmono do 23: 24: end for 25: for = 1 to Nbi do 26: 27: end for Generate and store unique GENERATEMONOSYLLABICROOT Generate and store unique GENERATEBISYLLABICROOT Prompt message: \"You are given the Camlang grammar book (Camlang.md) and English-Camlang vocabulary (Vocab.xlsx) for the Camlang language. You are asked to use these two resources to understand and answer the question in Camlang. === Camlang Grammar === {grammar text} === English-Camlang Vocabulary === {vocab tsv} Below is multiple-choice question written in Camlang. You are allowed to generate reasoning steps and an explanation to demonstrate your choice. However, the final line of your response must be exactly in this format, where {your answer} is the option letter (A, B, C, D, E, or F): The final answer is {your answer}. where {grammar text} and the {vocab tsv} are the textual grammar book and dictionary, respectively."
        }
    ],
    "affiliations": [
        "UIUC",
        "University of Cambridge",
        "University of Oxford"
    ]
}