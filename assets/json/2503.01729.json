{
    "paper_title": "FLAME: A Federated Learning Benchmark for Robotic Manipulation",
    "authors": [
        "Santiago Bou Betran",
        "Alberta Longhini",
        "Miguel Vasco",
        "Yuchong Zhang",
        "Danica Kragic"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent progress in robotic manipulation has been fueled by large-scale datasets collected across diverse environments. Training robotic manipulation policies on these datasets is traditionally performed in a centralized manner, raising concerns regarding scalability, adaptability, and data privacy. While federated learning enables decentralized, privacy-preserving training, its application to robotic manipulation remains largely unexplored. We introduce FLAME (Federated Learning Across Manipulation Environments), the first benchmark designed for federated learning in robotic manipulation. FLAME consists of: (i) a set of large-scale datasets of over 160,000 expert demonstrations of multiple manipulation tasks, collected across a wide range of simulated environments; (ii) a training and evaluation framework for robotic policy learning in a federated setting. We evaluate standard federated learning algorithms in FLAME, showing their potential for distributed policy learning and highlighting key challenges. Our benchmark establishes a foundation for scalable, adaptive, and privacy-aware robotic learning."
        },
        {
            "title": "Start",
            "content": "FLAME: Federated Learning Benchmark for Robotic Manipulation Santiago Bou Betran,1, Alberta Longhini,1, Miguel Vasco1, Yuchong Zhang1 and Danica Kragic1 5 2 0 2 3 ] . [ 1 9 2 7 1 0 . 3 0 5 2 : r Abstract Recent progress in robotic manipulation has been fueled by large-scale datasets collected across diverse environments. Training robotic manipulation policies on these datasets is traditionally performed in centralized manner, raising concerns regarding scalability, adaptability, and data privacy. While federated learning enables decentralized, privacypreserving training, its application to robotic manipulation remains largely unexplored. We introduce FLAME (Federated Learning Across Manipulation Environments), the first benchmark designed for federated learning in robotic manipulation. FLAME consists of: (i) set of large-scale datasets of over 160,000 expert demonstrations of multiple manipulation tasks, collected across wide range of simulated environments; (ii) training and evaluation framework for robotic policy learning in federated setting. We evaluate standard federated learning algorithms in FLAME, showing their potential for distributed policy learning and highlighting key challenges. Our benchmark establishes foundation for scalable, adaptive, and privacyaware robotic learning. I. INTRODUCTION Recent advances in robot learning have significantly enhanced the autonomy and capability of robotic manipulation systems [1], [2], [3]. Large-scale datasets of interaction data collected across different institutions have played crucial role in enabling robots to learn from extensive demonstrations and refine their skills through imitation and reinforcement learning [4], [5], [6], [7]. However, as these datasets grow with data coming from real-world applications such as domestic environments, data privacy and decentralized learning become critical concerns [8], [9]. In this context, training manipulation policies in distributed, privacy-preserving manner remains largely unexplored. Traditional methods for learning manipulation policies from large-scale datasets rely on centralized training [1], [3], [10], [11], where behavioral model is trained iteratively over an entire dataset stored in centralized manner (illustrated in Fig.1, top). However, we envision paradigm shift where robots continuously acquire knowledge from their own experiences in situated, diverse, real-world environments and collaboratively update global policy model, while keeping their experience data local and private (Fig.1, bottom). Such an approach, termed federated learning (FL) [12], allows distributed robots to contribute to shared model without centralizing sensitive data. Instead of learning from static datasets, robots could dynamically improve their manipulation policies by leveraging experiences across multiple settings, leading to more adaptive and resilient behaviors. While federated learning has gained traction in robotics, *Equal Contribution, 1All authors are with KTH Royal Institute of Technology, Stockholm, Sweden sbb, albertal, miguelsv, yuchongz, dani@kth.se Fig. 1: Learning manipulation policies through federated learning. In centralized training (top), global model is trained iteratively over large dataset stored in central server. In contrast, federated learning (bottom) enables distributed robots to locally train models on their own data and periodically share updates with central server, preserving data privacy. In this work, we contribute FLAME, the first benchmark of federated learning for robotic manipulation. particularly in mobile robot navigation [13], [14] and object grasping [15], there remains notable gap: no standardized benchmarks exist to evaluate FL frameworks specifically for robotic systems, and robotic manipulation in particular has yet to be explored through the lens of federated learning. To address this gap, we introduce FLAME (Federated Learning Across Manipulation Environments), benchmark designed to evaluate federated learning strategies for robotic manipulation tasks. Our benchmark provides set of largescale datasets of diverse manipulation tasks collected across multiple settings, incorporating variations in lighting conditions, textures, object appearances, and camera viewpoints, encompassing over 15M data samples. Furthermore, FLAME integrates these distributed datasets into FL framework, enabling rigorous evaluation of FL algorithms and serving as foundation for developing more robust federated learning manipulation strategies. We employ our proposed benchmark to evaluate different federated learning baselines across diverse set of environments and four different manipulation tasks. Our results highlight the potential of federated learning as scalable and privacy-preserving strategy for robotic manipulation, paving the way for real-world deployment and the continual learning of adaptive robotic systems. In summary, our contributions are as follows: FLAME, federated learning benchmark for robotic manipulation, consisting of large-scale dataset collected across multiple simulated environments and tasks, and federated learning and evaluation framework designed for robotic manipulation. rigorous evaluation of different federated learning baselines, demonstrating the need for more research for federated approaches for robotic manipulation training in distributed setting. To the best of our knowledge, this work presents the first application of federated learning to robotic manipulation strategies. We believe our benchmark will serve as valuable resource for the robotics and machine learning communities, fostering advancements in robotic manipulation. The code and datasets of FLAME will be made publicly available upon acceptance of the paper. II. RELATED WORK A. Federated Learning Benchmarks Federated Learning is machine learning paradigm that advocates for the distributed training of local models to learn global model by aggregating locally-computed updates [12]. The best aggregation strategy is an active area of research [16], [17], [18], [19]. The emergence of federated learning has spurred the creation of diverse benchmarks such as FedScale [20], FLBench [21], FedLLM-Bench [22], and LEAF [23] to evaluate FL methods on text, image, speech, or preference data. Despite covering different learning tasks, such as text and image classification [23], [21], medical analysis [24], and instruction tuning [22], these benchmarks focus exclusively on domains outside robotics. Consequently, there is still no established federated dataset or experimental protocol tailored specifically to robotic manipulation, highlighting the need for domain-specific solutions. B. Federated Learning for Robotics In robotics, FL-based learning offers significant advantages by enabling the continuous, distributed training of models while preserving data privacy and leveraging edge computing to mitigate bandwidth limitations [25], [14]. However, the application of federated learning in robotics remains relatively unexplored. Recent works on distributed reinforcement learning [26] have demonstrated its potential for achieving high-quality policy transfer while ensuring both data and model privacy, yet without explicitly addressing robotics tasks [27]. In contrast, FL for robot navigation and obstacle avoidance has been investigated in [26], [28], highlighting the benefits of multi-robot federated learning with continuous data collection. Additionally, [29] applies FL to task scheduling for heterogeneous agents in warehouse setting. In the context of robotic manipulation, [15] introduces an FL-based algorithm for multi-robot grasping, demonstrating effective training even under heterogeneous and non-transferable data conditions. Despite these advances, FL for learning complete manipulation policies remains largely unexplored. Our work bridges this gap by introducing FL benchmarks that integrate local demonstrations while providing global model for imitation-based manipulation tasks. Furthermore, we evaluate federated learning strategies for aggregating local models into unified global policy, laying the foundation for federated learning in robotic manipulation. C. Benchmarks and Datasets for Robotic Manipulation Datasets and benchmarks in robotic manipulation increasingly emphasize standardized tasks, diverse object sets, and domain shifts, such as RoboNet [30], BridgeData [7], or The Colosseum [31], particularly with the evolution of imitation learning and, more specifically, behavior cloning (BC). These efforts test how well policies adapt to task variations [32], [33] and environment variations, such as lighting conditions, texture, or camera poses [34]. However, existing benchmarks generally rely on centralized data aggregation and do not incorporate the distributed data constraints inherent to FL scenarios. Our work builds upon Colosseum by introducing federation-compatible dataset and codebase specifically designed for FL-based imitation learning in robotic manipulation. By supporting local training across diverse environments and aggregating model updates in privacypreserving manner, we establish the first benchmark to evaluate federated learning in robotic manipulation tasks. III. FLAME FLAME is federated learning benchmark designed to train and evaluate robotic manipulation tasks under diverse environmental conditions in distributed setting. Built upon RLBench [35], it extends the Colosseum [31] benchmark, consisting of 20 diverse robotic manipulation tasks, each enabled with 14 different perturbation factors to increase environment diversity. These perturbations, which include variations in object color, lighting conditions, and other scene properties, increase the complexity of the benchmark, leading to the instantiation of 20, 371 unique environments. key methodological difference between FLAME and [31] lies in how these variations are treated during data collection. While [31] considers each perturbed instance as distinct task and collects only one demonstration per randomized environment, FLAME treats them as unique environments within federated setting. This allows for the collection of more extensive set of demonstrations per environment, with randomized initial conditions, ensuring that federated learning algorithms are exposed to broad variability of environments. Additionally, FLAME introduces structured indexing method that records the specific perturbation factors associated with each environment. This ensures that environments can be re-instantiated with identical conditions when needed for distributed learning, providing greater control over the evaluation process. Another major advancement of FLAME is its integration within federated learning framework, which enables sysFig. 2: Tasks, demonstrations and variations in FLAME. The figure showcases four robotic manipulation tasks: Slide Block to Target, Close Box, Insert Onto Square Peg, and Scoop With Spatula. Each row represents different environment instance (Env 03), introducing variations in background, object textures, lighting, and camera perspectives. Within each environment, three demonstrations (Demo 02) illustrate different executions of the same task, capturing the diversity in data collection used for training and evaluation in our federated learning framework. tematic benchmarking of FL algorithms for robotic manipulation tasks. Unlike [31], which does not natively support federated learning, FLAME is designed to facilitate largescale distributed training and evaluation. The combination of extensive environment diversity, structured data collection, and federated learning integration makes FLAME powerful benchmark for investigating generalization and robustness in distributed robotic learning systems. In the remainder of this section, we provide further details into the environment definition and the perturbation factors, the methodology of data collection and environment indexing, and the FL integration for algorithm implementation and benchmarking. A. Environments and Variations an define Formally, in FLAME we environment = {Q, } as the combination of one of the RLBench tasks with predefined set of factors of variations . We highlight in Figure 2 examples of different tasks and factors of variation, such as predefined lightning conditions, background color, and camera position. These perturbations can be categorized into five main types [31]: (i) color variations are applied to manipulated objects, scene illuminators, and tables, with RGB values sampled uniformly within predefined range; (ii) texture modifications involve randomly selecting from set of 213 textures for objects, tables, and backgrounds, introducing additional visual diversity; (iii) object variations include the placement of distractor objects, chosen from fixed set of 78 unique 3D models, ensuring that learned policies remain robust to scene clutter; and (iv) physical properties, such as friction and mass, are adjusted to modify the dynamics of object interactions, impacting grasping and manipulation strategies; (v) view variations introduce small perturbations in angle and position of the camera to encourage generalization across different viewpoints. These factors collectively create diverse and challenging dataset, facilitating the evaluation of federated learning algorithms in robotic manipulation under wide range of domain shifts. B. Dataset Structure The large-scale nature of our federated training setup requires an adapted data-saving scheme that maximizes performance and ensures the safety and independence of each clients dataset. To this end, we design our training such that each client will be trained in single unique environment, with specified and replicable set of variation parameters. To do so, we sample database of environments, encoded as JSON configuration file, each collected environment is stored in this database with unique client ID."
        },
        {
            "title": "We define the structure of the dataset based on the",
            "content": "following hierarchy definition: Environment: At top level, we define set of environments, each consisting of the manipulation task and the factors of variation , randomly sampled within feasible limits, and stored in the JSON file. Each environment corresponds to unique local agent for our federated learning setup. Episodes: For each environment, we collect predefined number of episodes K, using pretrained, scripted, expert policy. At the beginning of each episode, we randomly sample the pose of the elements of interest in the scene, such as the effected object and the target. This ensures that the training process does not overfit to specific range of manipulator movements. C. Federated Learning Framework To enable federated learning within our benchmark, we exploit FLOWER [36] as the backbone for distributed training across simulated environments. FLOWER is Python library providing scalable and flexible implementation of federated learning, supporting both homogeneous and heterogeneous client scenarios while providing distributed node Fig. 3: The FLAME learning and evaluation framework. Our federated learning framework starts by sampling set of clients for local training (1). After training for user-defined number of local epochs, we evaluate each local policy on offline validation data (2) and in online interactions within the simulator (3). After the evaluation, we aggregate the weights of the local policies using predetermined federated learning method and send back the aggregated weights to initialize the local clients in the new round of training (4). We repeat steps (1-4) for user-defined number of aggregation rounds. Following this, we select the best-performing global policy in the validation dataset and evaluate the final policy using the test dataset (5) and in the test simulator environments (6). computation capabilities. We built customized wrapper around FLOWER to facilitate seamless interaction with the RLBench-based simulation, ensuring efficient data distribution, environment indexing, and federated model training. Our wrapper extends FLOWER by introducing an environment management system that systematically indexes and assigns unique task variations to each of the federated clients. Each client environment configuration is determined by the sampled perturbation factors applied during data collection. This allows for distributed training across diverse set of environments while maintaining consistency when reinstantiating given environment. Additionally, we implement structured data pipeline that handles the allocation of demonstrations, ensuring that each client receives dataset that aligns with its assigned task variation. Furthermore, we adapt FLOWERs client-server architecture to accommodate scripted demonstrations as training data, as shown in Figure 3. Each client trains on unique subset of the training dataset, evaluates its performance and transmits its parameter updates to the central aggregation server. The server, in turn, consolidates updates from multiple clients using predefined aggregation algorithm (e.g., Federated Averaging [12]), allowing the global model to progressively generalize across varying task conditions. By leveraging FLOWERs flexibility, we enable systematic benchmarking of federated learning algorithms within robotic manipulation tasks, assessing their performance under diverse environmental shifts and task variations. For complete description of the training and evaluation procedure in FLAME please refer to Figure 3. IV. EVALUATION A. Experimental Setup Tasks: For our evaluation, we select four distinct tasks: = {Slide block to target (Slide Block), Close Box (Close box), Insert onto Square Peg (Peg in Square), Scoop with Spatula (Scoop)}. In each of these environments, the robots action space is composed of joint velocities as well as binary command to open or close the gripper. Meanwhile, the observation space includes the robots joint positions and single-view camera feed that supplies image observations. This setup allows us to capture both low-dimensional kinematic information and high-dimensional visual context. For each of these tasks, we follow the data collection procedure described in the previous section, containing = 420 different environments and = 100 demonstrations per environment, of which 400 environments are used for training, 10 for validation, and 10 for testing. We highlight the selected factors of variation in Table I. Local Imitation Learning Agent: For each environment, we instantiate the local agent as multi-modal neural network that integrates visual and low-dimensional state inputs to predict continuous control actions. The architecture employs CNN encoder for processing RGB images of size (64, 64, 3), consisting of three convolutional layers with 32, 64, and 128 filters, respectively, each with 33 kernel, stride of 2, and ReLU activation, followed by fully connected layer of 256 units. In parallel, an MLP encoder processes the low-dimensional state input through two fully connected layers with 256 and 128 units, both using ReLU activations. The extracted visual and state features are concatenated into 384-dimensional latent representation and passed through policy network comprising two fully connected layers of 512 and 4 units, where the final layer applies Tanh activation to constrain the action outputs to the range [-1, 1]. The model is trained using supervised learning with Mean Squared Error (MSE) loss, optimizing the action predictions against expert demonstrations using the Adam optimizer with learning rate of 1e-4. To enable decentralized training, the agent is deployed within federated learning framework. To incorporate updates from multiple distributed environments, we benchmark different aggregation strategies, as described TABLE I: Factors of variation in the FLAME benchmark datasets. The table presents the value ranges for each variation across the four manipulation tasks."
        },
        {
            "title": "Scoop With Spatula",
            "content": "Background Texture Camera Pose (x/y/z) Light Color (RGB) Object Color (RGB) Object Size Object Texture Table Color (RGB) Table Texture (-0.05, 0.05) (0, 0.5) (0, 1) (-0.05, 0.05) (0, 0.5) (0, 1) 0.75 1.15 (-0.05, 0.05) (0, 0.5) (0, 1) 1.0 1.5 (-0.05, 0.05) (0, 0.5) (0, 1) 0.75 1.25 (0.25, 1) (0.25, 1) (0.25, 1) (0.25, 1) TABLE II: Performance of different federated learning methods in FLAME. We show the RMSE and the normalized success rate of the different methods across the four manipulation tasks. The values are averaged across 10 test environments and 50 episodes for each task. The arrows indicate the direction of improvement. Best viewed with zoom. (a) Offline Evaluation: RMSE 102() (b) Online Evaluation: Normalized Success Rate () Method Slide Block Close Box Peg in Square Scoop Method Slide Block Close Box Peg in Square Scoop FedAvg FedAvgM FedOpt Krum 2.64 0.13 6.24 0.79 30.99 0.52 3.85 0. FedAvg 0.24 0.43 0.84 0.37 13.45 0.26 11.9 1.03 38.58 0. 40.3 0.32 FedAvgM 0 0 0.54 0.49 2.76 0.13 6.86 0. 30.75 0.50 3.89 0.22 FedOpt 0.28 0.45 0.70 0.46 7.24 2. 9.68 1.98 28.13 7.06 10.19 0.76 Krum 0.10 0.30 0.86 0. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 in the following section. B. Results Federated Learning Approaches: We evaluate multiple federated learning baselines to assess their performance in decentralized robotic learning. In Federated Averaging [12] (FedAvg) local models are trained independently on client devices before being aggregated into global model via weighted averaging. Federated average with Momentum [18] (FedAvgM) extends this by incorporating momentumbased update rule on the server side, which helps stabilize training and mitigate oscillations due to non-IID client data distributions. Krum [19] (Krum) is an aggregation method designed for Byzantine-robust federated learning, selecting single client update that minimizes the influence of potential adversarial models. Adaptive Federated Optimization [17] (FedOpt) generalizes FedAvg by enabling adaptive optimizer strategies, such as Adam, at the server, improving convergence in heterogeneous environments. Training Setup: We trained all federated learning models for total of 30 aggregation rounds, with each client performing 50 local training epochs per round. The number of available clients was set to 400, corresponding to the number of distinct training environments. Due to computational constraints, 20 random clients were selected per training round. Model validation and testing were conducted on 20 previously unseen environments, with the best-performing model on the evaluation set subsequently assessed on the test set. All models were trained on system equipped with single NVIDIA A100 GPU, 64 CPU cores, and 250 GB of allocated memory. We evaluate all federated learning approaches across the different tasks of the FLAME benchmark. We consider two different evaluation scenarios: an offline evaluation scenario, in which we compute the RMSE between the predicted actions of the agent and the test actions; and an online evaluation, where we employ the RLBench simulator and the variation configuration corresponding to the test environments to evaluate the success rate of the agent. We present our main results in Table II. Variability across manipulation tasks: The results highlight significant performance differences across the different tasks in FLAME. While most federated learning approaches are able to learn an effective policy in Close Box, they struggle to generalize in the Slide Block task and are unable to do so in both Peg in Square and Scoop. These differences are expected given the increased difficulty of these tasks: both Peg in Square and Scoop require precise manipulation of small objects, while Close Box and Slide Block only require coarser manipulation strategy. This challenge is intentional: FLAME is designed to evaluate the generalization capabilities of current and future manipulation methods within federated learning setup. Variability across FL methods: The results also highlight significant performance differences across the different federated learning methods. The performance of each method is also highly dependent on the environment: for example, Krum achieves the highest average success rate in the Close Box task, yet struggles to perform in the Slide Block task in comparison with FedAvg and FedAvgM. This disparity raises two important observations. First, the need to evaluate (a) Local Clients (b) Demonstrations per Client (c) Local Training Epochs (d) Aggregation Rounds Fig. 4: Ablation study of federated learning for robotic manipulation. In this study, we consider the Slide Block task and the FedAvg method. We evaluate the performance of the final policy as function of: (a) the number of local clients during training; (b) the number of demonstrations per client during training; (c) the number of local training epochs; (d) the number of aggregation rounds. All results are averaged over 50 episodes across 10 different test environments. novel federated learning methods across wide variety of manipulation tasks to reliably estimate their performance, such as the ones available in FLAME. Secondly, the need to develop federated learning methods that are designed specifically for robotic manipulation tasks. We hope our results and benchmark inspire the community to advance federated learning methods tailored for robotic manipulation. Importance of complementary evaluations: Finally, our the need to complement offline evaluaresults highlight tions (traditionally employed in federated learning literature) with online evaluations to access the performance of these methods for robotic manipulation. While offline evaluation can provide insights into how these models predict actions compared to an expert policy, they do not always correlate with successful executions in the online setting: for example, Krum has high RMSE in the Close Box task, yet achieves the highest success rate in the online evaluation. This underscores the importance of integrating simulation capabilities into federated learning frameworks, as done in FLAME, to better align offline evaluations with actual robot policy performance. C. Ablation Study We present an ablation study to understand how different hyperparameters of the federated learning setup influence the final performance of the robot policy. To do so, we consider the Slide Block task and the FedAvg method. We explore how: (i) the number of local clients during training; (ii) the number of training demonstrations per client; (iii) the number of local training epochs per client; and (iv) the number of central aggregation rounds influence the performance of the final agent. The remaining hyperparameters are set to the values described in Section IV-A. The results of our ablation study are presented in Figure 4. Number of local clients: The results in Figure 4a shows trend of increasing performance as we increase the number of local clients. This behavior aligns with expectations and underscores the potential of large-scale federated learning to develop highly performant and generalizable manipulation policies while adhering to strict privacy constraints, such as preventing raw experience sharing between agents. Number of demonstrations per client: The results in Figure 4b demonstrate strong increase in performance as we increase the number of demonstrations available for training. This result suggests that the performance of the centralized policy is heavily influenced by the quality of local imitation learning policies, which improve with larger training datasets [37]. Number of local training epochs: The results in Figure 4c reveal an interesting phenomenon: agent performance does not increase monotonically with the number of local training epochs per aggregation round, instead peaking at 25 epochs. We hypothesize that this occurs because local policies overfit to their specific environments after large number of training epochs, thereby hindering the aggregation process at the central level. Aggregation rounds: The results in Figure 4d highlight the need for continuous evaluation of the performance of the global model: we observe that the success rate of the agent changes significantly across different aggregation rounds. This observation further motivates the need to develop federated learning algorithms specialized for robotic manipulation. V. CONCLUSIONS This work introduced FLAME, the first federated learning benchmark for robotic manipulation. By leveraging largescale dataset collected across diverse simulation environments, FLAME enables the evaluation of federated learning strategies for training manipulation policies in distributed and privacy-preserving manner. The experimental results demonstrated the feasibility of federated learning for robotic manipulation and highlighted key challenges associated with learning policies in decentralized framework. By establishing standardized benchmark, FLAME lays the groundwork for future research on federated learning in robotic systems. It provides scalable framework for continual learning and adaptive policy refinement without requiring centralized data aggregation. This benchmark aims to to drive advancements in federated robotics, fostering more robust, generalizable, and privacy-conscious learning methodologies for robotic manipulation tasks."
        },
        {
            "title": "ACKNOWLEDGMENT",
            "content": "This work was supported by the European Research Council (ERC-884807). The computations were enabled by the Berzelius resource provided by the Knut and Alice Wallenberg Foundation at the Swedish National Supercomputer Centre. Additionally, this work was partially supported by the HORIZON-CL4-2021-HUMAN-01 ELSA project."
        },
        {
            "title": "REFERENCES",
            "content": "[1] T. Z. Zhao, J. Tompson, D. Driess, P. Florence, K. Ghasemipour, C. Finn, and A. Wahid, Aloha unleashed: simple recipe for robot dexterity, arXiv preprint arXiv:2410.13126, 2024. [2] K. Black, N. Brown, D. Driess, A. Esmail, M. Equi, C. Finn, N. Fusai, L. Groom, K. Hausman, B. Ichter, et al., π 0: visionlanguage-action flow model for general robot control, arXiv preprint arXiv:2410.24164, 2024. [3] A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, X. Chen, K. Choromanski, T. Ding, D. Driess, A. Dubey, C. Finn, et al., Rt-2: Visionlanguage-action models transfer web knowledge to robotic control, arXiv preprint arXiv:2307.15818, 2023. [4] A. Khazatsky, K. Pertsch, S. Nair, A. Balakrishna, S. Dasari, S. Karamcheti, S. Nasiriany, M. K. Srirama, L. Y. Chen, K. Ellis, et al., Droid: large-scale in-the-wild robot manipulation dataset, arXiv preprint arXiv:2403.12945, 2024. [5] H.-S. Fang, H. Fang, Z. Tang, J. Liu, C. Wang, J. Wang, H. Zhu, and C. Lu, Rh20t: comprehensive robotic dataset for learning diverse skills in one-shot, arXiv preprint arXiv:2307.00595, 2023. [6] A. ONeill, A. Rehman, A. Maddukuri, A. Gupta, A. Padalkar, A. Lee, A. Pooley, A. Gupta, A. Mandlekar, A. Jain, et al., Open x-embodiment: Robotic learning datasets and rt-x models: Open xembodiment collaboration 0, in 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024, pp. 68926903. [7] H. R. Walke, K. Black, T. Z. Zhao, Q. Vuong, C. Zheng, P. HansenEstruch, A. W. He, V. Myers, M. J. Kim, M. Du, et al., Bridgedata v2: dataset for robot learning at scale, in Conference on Robot Learning. PMLR, 2023, pp. 17231736. [8] M. Qiu, H.-N. Dai, A. K. Sangaiah, K. Liang, and X. Zheng, Guest editorial: Special section on emerging privacy and security issues brought by artificial intelligence in industrial informatics, IEEE Transactions on Industrial Informatics, vol. 16, no. 3, pp. 20292030, 2019. [9] B. Yankson, An empirical study: Privacy and security analysis of companion robot system development, in ICCWS 2021 16th International Conference on Cyber Warfare and Security. Academic Conferences Limited, 2021, p. 409. [10] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, et al., Palm-e: An embodied multimodal language model, 2023. [11] M. J. Kim, K. Pertsch, S. Karamcheti, T. Xiao, A. Balakrishna, S. Nair, R. Rafailov, E. Foster, G. Lam, P. Sanketi, et al., Openvla: An open-source vision-language-action model, arXiv preprint arXiv:2406.09246, 2024. [12] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Arcas, Communication-efficient learning of deep networks from decentralized data, in Artificial intelligence and statistics. PMLR, 2017, pp. 12731282. [13] F. E. Casado and Y. Demiris, Federated learning from demonstration for active assistance to smart wheelchair users, in 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2022, pp. 93269331. [14] X. Yu, J. P. Queralta, and T. Westerlund, Towards lifelong federated learning in autonomous mobile robots with continuous sim-to-real transfer, Procedia Computer Science, vol. 210, pp. 8693, 2022. [15] S.-K. Kang and C. Choi, Fogl: Federated object grasping learning, in 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023, pp. 58515857. [16] C. Louizos, M. Reisser, J. Soriaga, and M. Welling, Federated averaging as expectation maximization, 2021. [17] S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Koneˇcn`y, S. Kumar, and H. B. McMahan, Adaptive federated optimization, arXiv preprint arXiv:2003.00295, 2020. [18] T.-M. H. Hsu, H. Qi, and M. Brown, Measuring the effects of nonidentical data distribution for federated visual classification, arXiv preprint arXiv:1909.06335, 2019. [19] P. Blanchard, and J. Stainer, Byzantine-tolerant machine learning, arXiv preprint arXiv:1703.02757, 2017. E. Mhamdi, R. Guerraoui, E. M. [20] F. Lai, Y. Dai, S. Singapuram, J. Liu, X. Zhu, H. Madhyastha, and M. Chowdhury, Fedscale: Benchmarking model and system performance of federated learning at scale, in International conference on machine learning. PMLR, 2022, pp. 11 81411 827. [21] Y. Liang, Y. Guo, Y. Gong, C. Luo, J. Zhan, and Y. Huang, Flbench: benchmark suite for federated learning, in Intelligent Computing and Block Chain: First BenchCouncil International Federated Conferences, FICC 2020, Qingdao, China, October 30November 3, 2020, Revised Selected Papers 1. Springer, 2021, pp. 166176. [22] R. Ye, R. Ge, X. Zhu, J. Chai, D. Yaxin, Y. Liu, Y. Wang, and S. Chen, Fedllm-bench: Realistic benchmarks for federated learning of large language models, Advances in Neural Information Processing Systems, vol. 37, pp. 111 106111 130, 2025. [23] S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Koneˇcn`y, H. B. McMahan, V. Smith, and A. Talwalkar, Leaf: benchmark for federated settings, arXiv preprint arXiv:1812.01097, 2018. [24] C. Song, F. Granqvist, and K. Talwar, Flair: Federated learning annotated image repository, Advances in Neural Information Processing Systems, vol. 35, pp. 37 79237 805, 2022. [25] Y. Xianjia, J. P. Queralta, J. Heikkonen, and T. Westerlund, Federated learning in robotic and autonomous systems, Procedia Computer Science, vol. 191, pp. 135142, 2021. [26] S. Na, T. Rouˇcek, J. Ulrich, J. Pikman, T. Krajnık, B. Lennox, and F. Arvin, Federated reinforcement learning for collective navigation of robotic swarms, IEEE Transactions on cognitive and developmental systems, vol. 15, no. 4, pp. 21222131, 2023. [27] J. Qi, Q. Zhou, L. Lei, and K. Zheng, Federated reinforcement learning: Techniques, applications, and open challenges, arXiv preprint arXiv:2108.11887, 2021. [28] N. Majcherczyk, N. Srishankar, and C. Pinciroli, Flow-fl: Datadriven federated learning for spatio-temporal predictions in multirobot systems, in 2021 IEEE international conference on robotics and automation (ICRA). IEEE, 2021, pp. 88368842. [29] T. M. Ho, K.-K. Nguyen, and M. Cheriet, Federated deep reinforcement learning for task scheduling in heterogeneous autonomous robotic system, IEEE Transactions on Automation Science and Engineering, vol. 21, no. 1, pp. 528540, 2022. [30] S. Dasari, F. Ebert, S. Tian, S. Nair, B. Bucher, K. Schmeckpeper, S. Singh, S. Levine, and C. Finn, Robonet: Large-scale multi-robot learning, arXiv preprint arXiv:1910.11215, 2019. [31] W. Pumacay, I. Singh, J. Duan, R. Krishna, J. Thomason, and D. Fox, The colosseum: benchmark for evaluating generalization for robotic manipulation, arXiv preprint arXiv:2402.08191, 2024. [32] Y. Zhu, J. Wong, A. Mandlekar, R. Martın-Martın, A. Joshi, S. Nasiriany, and Y. Zhu, robosuite: modular simulation framework and learning, arXiv preprint arXiv:2009.12293, benchmark for robot 2020. [33] J. Luo, C. Xu, F. Liu, L. Tan, Z. Lin, J. Wu, P. Abbeel, and S. Levine, Fmb: functional manipulation benchmark for generalizable robotic learning, The International Journal of Robotics Research, p. 02783649241276017, 2023. [34] Z. Yuan, S. Yang, P. Hua, C. Chang, K. Hu, and H. Xu, Rl-vigen: reinforcement learning benchmark for visual generalization, Advances in Neural Information Processing Systems, vol. 36, pp. 67206747, 2023. [35] S. James, Z. Ma, D. R. Arrojo, and A. J. Davison, Rlbench: The robot learning benchmark & learning environment, IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 30193026, 2020. [36] D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmao, et al., Flower: friendly federated learning research framework, arXiv preprint arXiv:2007.14390, 2020. [37] J. Tuyls, D. Madeka, K. Torkkola, D. Foster, K. Narasimhan, and S. Kakade, Scaling laws for imitation learning in single-agent games, arXiv preprint arXiv:2307.09423, 2023."
        }
    ],
    "affiliations": [
        "KTH Royal Institute of Technology, Stockholm, Sweden"
    ]
}