{
    "paper_title": "Parallel Latent Reasoning for Sequential Recommendation",
    "authors": [
        "Jiakai Tang",
        "Xu Chen",
        "Wen Chen",
        "Jian Wu",
        "Yuning Jiang",
        "Bo Zheng"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \\textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling."
        },
        {
            "title": "Start",
            "content": "Jiakai Tang tangjiakai5704@ruc.edu.cn GSAI, Renmin University of China Beijing, China Xu Chen xu.chen@ruc.edu.cn GSAI, Renmin University of China Beijing, China Jian Wu joshuawu.wujian@alibaba-inc.com Alibaba Group Beijing, China Yuning Jiang mengzhu.jyn@alibaba-inc.com Alibaba Group Beijing, China Wen Chen chenyu.cw@alibaba-inc.com Alibaba Group Beijing, China Bo Zheng bozheng@alibaba-inc.com Alibaba Group Beijing, China 6 2 0 2 6 ] . [ 1 3 5 1 3 0 . 1 0 6 2 : r Abstract Capturing complex user preferences from sparse behavioral sequences remains fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose Parallel Latent Reasoning (PLR), novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixtureof-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling. CCS Concepts Information systems Recommender systems; Collaborative filtering. Keywords Sequential Recommendation, Latent Reasoning, Personalized Recommendation ACM Reference Format: Jiakai Tang, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang, and Bo Zheng. 2018. Parallel Latent Reasoning for Sequential Recommendation. In Proceedings Work done during an internship at Alibaba Group. Both authors are corresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference acronym XX, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX of Make sure to enter the correct conference title from your rights confirmation email (Conference acronym XX). ACM, New York, NY, USA, 12 pages. https: //doi.org/XXXXXXX.XXXXXXX"
        },
        {
            "title": "1 Introduction\nRecommender systems have become indispensable infrastructure\nin modern digital ecosystems, facilitating personalized content\ndiscovery and user engagement across diverse domains such as\ne-commerce [37, 42], streaming platforms [12, 44], and social net-\nworks [21, 56]. However, a persistent challenge in recommendation\nlies in the sparsity of user behavioral data, which fundamentally\nlimits traditional models‚Äô capability to perform complex logical\ninference for uncovering users‚Äô potential interest patterns and pref-\nerence dynamics [36, 38, 60]. Inspired by recent breakthroughs in\nlarge language models (LLMs) [5, 16, 30], where incorporating rea-\nsoning mechanisms has demonstrated remarkable improvements\nin challenging tasks such as mathematical problem-solving [2, 43]\nand code generation [9, 22], an emerging paradigm in sequential\nrecommendation has begun to embrace test-time computation strate-\ngies [63]. This paradigm shift introduces reasoning capabilities‚Äî\nboth explicit and latent‚Äîthat transform the conventional shal-\nlow pattern-matching approach (input-output) into a sophisticated\nreasoning-driven framework (input-think-output), substantially\nenhancing models‚Äôs computational power.",
            "content": "Despite their promise, existing reasoning-enhanced recommendation methods encounter several critical limitations. For explicit reasoning approaches, two fundamental challenges persist: (1) Inference latency overhead: The generation of verbose reasoning chains incurs substantial computational costs, creating prohibitive delays for real-time online serving scenarios. (2) Reasoning chain definition ambiguity: Unlike mathematical reasoning or code synthesis tasks, where LLMs (such as DeepSeek-R1 [11], Qwen3 [55], and Kimi1.5 [40]) leverage extensive Chain-of-Thought (CoT) data during post-training that can be rigorously verified against objective ground truth. However, recommendation scenarios lack welldefined reasoning trajectories. The absence of expert-annotated, high-quality correct reasoning chains makes it inherently challenging to guide explicit reasoning in recommendation contexts. In contrast, latent reasoning-enhanced recommendation methods adopt data-driven, annotation-free approach to unlock models reasoning potential. However, these methods face distinct bottleneck: current techniques mainly rely on depth computational scalingdeepening the reasoning process through recurrent autogressive steps. Empirical evidence suggests that further increases Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. in reasoning depth yield diminishing or even negative performance gains [24, 35, 65]. We argue this limitation likely stems from two intertwined factors: (i) the models initial reasoning direction may be suboptimal, and (ii) error accumulation along extended reasoning chains progressively degrades the thinking quality, ultimately constraining the models reasoning capability ceiling. In this work, to meet the demands of real-time online inference, we adopt the latent reasoning paradigm while rethinking its computational approach. Rather than pursuing deeper reasoning along singular trajectory, we draw inspiration from cognitive science [6, 17], which reveals that humans typically explore multiple plausible solution paths concurrently before converging to comprehensive conclusion. Building upon this insight, we propose novel computational scaling dimension: width-level reasoning enhancement. Multi-stream latent reasoning enables the model to capture users dynamic and multifaceted interest preferences through diverse reasoning trajectories, preventing premature lockin to single, potentially suboptimal thought process. However, applying this idea is non-trivial due to the following challenges: Challenge 1: How to construct multi-stream reasoning? Unlike discrete decoding in LLMs, where techniques such as beam search [49, 51], self-consistency [1, 46], and majority voting [4, 45] operate on language token sequences, it remains unclear how to effectively construct multiple reasoning streams in the continuous latent representation space. Challenge 2: How to avoid reasoning homogeneity? While width scaling increases computational capacity, it is critical to prevent multiple streams from converging to similar reasoning patterns, leading to redundant resource consumption without bringing positive benefits. Challenge 3: How to aggregate different reasoning streams? After parallel exploration, the model needs to synthesize insights from multiple reasoning pathways into unified solution. Naive aggregation strategies (e.g., mean pooling) risk diluting the contributions of superior reasoning streams while amplifying the interference from inferior ones. To address these challenges, we propose simple yet effective framework for parallel latent reasoning in sequential recommendation, named Parallel Latent Reasoning (PLR). Specifically, to expand the latent representation from sequential encoder to multiple streams, we introduce learnable trigger tokens that actively guide the model to conduct parallel multi-stream reasoning. This simple design effectively resolves the challenge of stream construction in continuous latent space. Furthermore, to enhance the distinctiveness among different streams and across reasoning steps within each stream, we introduce global reasoning regularization mechanism that mitigates the homogeneity issue. For aggregating results from multiple parallel reasoning streams, we design an mixtureof-reasoning-streams aggregation module that adaptively weights and combines outputs from different streams to synthesize the final sequence representation. Additionally, to improve the models reasoning robustness, we propose reasoning contrastive learning objective that enhances the models ability to handle sparse user behaviors. We also provide in-depth theoretical analysis to explain the effectiveness of our approach, offering insights that advance the understanding of reasoning-enhanced recommendation. Our main contributions are summarized as follows: We pioneer the exploration of width-level computational scaling for latent reasoning in sequential recommendation, enabling novel architecture that synergizes breadth and depth reasoning while maintaining real-time inference efficiency. We propose PLR, model-agnostic framework for parallel latent reasoning that employs learnable trigger tokens to construct diverse reasoning streams in continuous latent space, regularizes global reasoning patterns to preserve diversity, and aggregates multi-stream outputs through mixture-of-reasoning-streams. Extensive experiments on three real-world datasets demonstrate that PLR achieves substantial improvements and establishes new ceilings for sequential recommendation, opening new avenues for latent reasoning-enhanced recommendation research."
        },
        {
            "title": "2 Preliminary\n2.1 Problem Formulation\nLet U = {ùë¢1, ùë¢2, . . . , ùë¢ | U | } denote the user set and V = {ùë£1, ùë£2, . . . , ùë£ | V | }\ndenote the set of items. For each user ùë¢ ‚àà U, we denote their chrono-\nlogically ordered interaction sequence as Sùë¢ = [ùë£ùë¢\n2 , . . . , ùë£ùë¢\nùëõ ],\nwhere ùë£ùë¢\nùëñ ‚àà V represents the ùëñ-th item interacted by user ùë¢, and ùëõ\nis the sequence length. The task of sequential recommendation is\nto predict the next item ùë£ùë¢\nùëõ+1 that user ùë¢ is most likely to interact\nwith, given their historical sequence Sùë¢ . Formally, this problem can\nbe formulated as learning a function ùëìùúÉ : Sùë¢ ‚Üí V that maximizes\nthe conditional probability of the ground-truth target item:",
            "content": "1 , ùë£ùë¢ ùúÉ = arg max ùúÉ ùë¢ log ùëù (ùë£ùë¢ ùëõ+1Sùë¢ ; ùúÉ ), (1) where ùúÉ denotes the model parameters. During inference, the model ranks all candidate items based on their predicted probabilities and recommends the top-ùêæ items with the highest scores."
        },
        {
            "title": "Recommendation",
            "content": "Traditional recommendation methods rely on single forward pass to encode the sequence representation, where the fixed computational budget limits their modeling capability, particularly in sparse interaction scenarios. To enable more fine-grained reasoning and deeper representation learning, recent works have explored latent reasoning-enhanced recommender systems [8, 24, 35, 64], which shift from the conventional shallow input-output paradigm to multi-step input-think-output reasoning framework. Formally, given an input sequence Sùë¢ , latent reasoning-enhanced model first encodes the sequence into latent representation h0 through an encoder ùëìenc: h0 = ùëìenc (Sùë¢ ; ùúÉenc), where ùúÉenc denotes the encoder parameters. Subsequently, the model performs ùëá iterative reasoning steps to progressively refine the representation: hùë° = ùëìrea (hùë° 1; ùúÉrea), ùë° = 1, 2, . . . ,ùëá , where ùëìrea is the reasoning module with parameters ùúÉrea (which can be shared with or distinct from ùúÉenc depending on the specific method). Finally, the model generates the prediction based on the refined representation hùëá . The core principle of this paradigm is to enhance the models computational expressiveness through iterative reasoning, thereby improving accuracy on complex tasks. Parallel Latent Reasoning for Sequential Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY The initial sequence representation is obtained by: X0 = [e1, e2, . . . , eùëõ] + P, ùëñ ] Rùëë is the embedding of item ùë£ùë¢ where eùëñ = E[ùë£ùë¢ ùëñ , and Rùëõùëë represents the positional encoding that injects sequential order information into the model. Subsequently, X0 is fed into multi-layer multi-head self-attention module to capture complex dependencies among items in the sequence. Specifically, for the ùëô-th layer, the computation is formulated as: Xùëô = MultiHead(Xùëô 1) + Xùëô 1, where the multi-head self-attention operation is defined as: MultiHead(X) = Concat(head1, . . . , headùêª )W ùëÇ, with each attention head computed as: Figure 1: Overall architecture of the Parallel Latent Reasoning framework. RPE denotes reasoning position embedding. However, empirical studies on existing latent reasoning-enhanced methods reveal critical limitation: after stacking multiple reasoning steps (e.g., 2 steps in ReaRec [35], 3-4 steps in LARES [24], and 1 step in LatentR3 [65]), models often exhibit marginal or even negative performance gains, phenomenon known as overthinking [29, 53]. This issue suggests that depth-only computational scaling may be insufficient to unlock the models full potential. More advanced reasoning mechanisms are needed to further unleash the latent reasoning capabilities of recommendation models."
        },
        {
            "title": "3.1 Parallel Latent Reasoning Backbone\nIn this section, we introduce the core architecture of our Parallel\nLatent Reasoning (PLR) framework. We begin by describing the\nfoundational components: the attention-based sequence encoder,\ndepth-level latent reasoning, and our proposed width-level parallel\nreasoning approach.",
            "content": "3.1.1 Attention-based Sequence Encoding. Following mainstream sequential recommendation methods [50, 62, 69], we adopt the Transformer architecture [41] as our backbone. Given user in2 , . . . , ùë£ùë¢ teraction sequence Sùë¢ = [ùë£ùë¢ ùëõ ], we first embed each item into dense vector representation. Formally, let ùëë denote the item embedding matrix, where ùëë is the embedding dimension. 1 , ùë£ùë¢ , Wùêæ ‚Ñé ùëÑ head‚Ñé = Attention(XW ‚Ñé ùëâ ùêæ , XW ‚Ñé ), ‚Ñé , XW ùëÑ ‚Ñé Rùëë ùëë‚Ñé are learnable projection matrices for where ‚Ñé the ‚Ñé-th head, WùëÇ Rùêªùëë‚Ñé ùëë is the output projection matrix, and ùêª is the number of attention heads. After ùêø encoder layers, we obtain the final encoded representation Henc = Xùêø Rùëõùëë . , Wùëâ 3.1.2 Depth-Level Latent Reasoning. Following recent latent reasoning methods (e.g., ReaRec [35]), we extend the conventional one-pass encoding paradigm to incorporate depth-level multi-step reasoning computation. Rather than directly using the encoder output Henc as the final sequence representation, which is constrained by limited computational capacity for capturing fine-grained user interests, we introduce additional autoregressive reasoning steps to progressively refine the latent representation. Specifically, we extract the representation of the last item in the sequence as the initial reasoning state: h0 = Henc [1] Rùëë . Then, the model performs ùëá iterative reasoning steps: hùë° = ùëì (hùë° 1, rùë° ; ùúÉ ), ùë° = 1, 2, . . . ,ùëá , (2) where ùëì denotes the reasoning module implemented as Transformer layers with shared parameters ùúÉ from the encoder, and rùë° Rùëë is the Reasoning Position Embedding (RPE) for step ùë° that helps distinguish the reasoning phase from the encoding phase. 3.1.3 Width-Level Parallel Reasoning. However, depth-only computational scaling remains susceptible to several critical limitations: suboptimal initial reasoning directions and error accumulation across continuous reasoning chains. To mitigate these challenges, we explore novel dimension of computational scaling: width-level parallel latent reasoning. The key challenge lies in extending the continuous latent state vector into multiple parallel streams in the latent space. To enable this extension, we introduce learnable trigger tokens {ùùâ1, ùùâ2, . . . , ùùâùëÄ } Rùëë to explicitly guide different reasoning streams, where ùëÄ denotes the number of parallel reasoning streams. Specifically, we adopt simplistic approach: we add each trigger token to the initial reasoning state h0 to obtain ùëÄ distinct beginning reasoning states, which is formulated as: h0,ùëö = h0 + ùùâùëö, ùëö = 1, 2, . . . , ùëÄ. This design allows each stream to start from perturbed initial state, encouraging the exploration of diverse reasoning trajectories. (3) Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. For the attention mechanism across multiple reasoning streams, we adopt stream-isolated causal reasoning approach with shared input attention. Formally, for each stream ùëö at reasoning step ùë°, the computation is formulated as: hùë°,ùëö = Attention(Qùë°,ùëö, Kùë°,ùëö, Vùë°,ùëö) + hùë° 1,ùëö, (4) where: ùëÑ, ùêæ, (5) Qùë°,ùëö = (hùë° 1,ùëö + rùë° )W Kùë°,ùëö = [X0; h1,ùëö; . . . ; hùë° 1,ùëö]W Vùë°,ùëö = [X0; h1,ùëö; . . . ; hùë° 1,ùëö]W here, [; ] denotes concatenation along the sequence dimension. This design ensures that: (i) each stream attends to the shared interaction context, preserving access to the original input information; (ii) reasoning within each stream follows causal pattern, where the state at step ùë° only attends to previous steps within the same stream; (iii) different streams remain isolated during reasoning, enabling independent exploration of diverse reasoning paths. ùëâ , 1 , Hrea 2 , . . . , Hrea After ùëá reasoning steps, we obtain ùëÄ refined representation groups {Hrea ùëÄ }, where Hrea ùëö = {h1,ùëö, h2,ùëö, . . . , hùëá ,ùëö } corresponds to the reasoning trajectory of the ùëö-th stream. Following the Ensemble Reasoning Learning (ERL) strategy from ReaRec, we apply average pooling over the multi-step outputs within each reasoning stream to obtain the stream-specific representation: zùëö = 1 ùëá ùëá ùë° =1 hùë°,ùëö, ùëö = 1, 2, . . . , ùëÄ. (6) The final sequence representation is then derived by aggregating the outputs {z1, z2, . . . , zùëÄ } from all reasoning streams. In Section 3.2.3, we will introduce our adaptive mixture-of-reasoning-streams approach for combining multi-stream reasoning results."
        },
        {
            "title": "3.2 Multi-Stream Reasoning Optimization\nIn this section, we introduce three key mechanisms to optimize the\nparallel reasoning process: global reasoning regularization to pre-\nserve diversity, reasoning contrastive learning to enhance robust-\nness, and mixture-of-reasoning-streams for adaptive aggregation.",
            "content": "3.2.1 Global Reasoning Regularization. To prevent multiple reasoning streams from collapsing into homogeneous patterns, where different streams exhibit highly similar reasoning states, we introduce global reasoning regularization mechanism. Specifically, we enforce diversity constraints across all reasoning states (both within and across streams) through bidirectional Kullback-Leibler (KL) divergence regularization. Formally, let hùë°,ùëö denote the hidden state at step ùë° of stream ùëö. We compute the distribution over the item vocabulary for each reasoning state as: ùëùùë°,ùëö (ùë£) = softmax(h ùë°,ùëöE[ùë£]), where E[ùë£] is the embedding of item ùë£. The global reasoning regularization loss is formulated as: KL(ùëùùë°,ùëö ùëùùë° ,ùëö ), (7) LKL = 1 ùëá ùëÄ (ùëá ùëÄ 1) (ùë°,ùëö) (ùë° ,ùëö )(ùë°,ùëö) where the summation iterates over all pairs of distinct reasoning states across all ùëá ùëÄ positions. This constraint encourages: (i) within each stream, different reasoning steps progressively explore distinct reasoning directions to capture high-order feature interactions; (ii) across different streams, parallel reasoning paths diverge to discover diverse sequence patterns. By penalizing similarity among all reasoning states globally, this mechanism mitigates both intra-stream and inter-stream homogeneity simultaneously. 3.2.2 Reasoning Contrastive Learning. To enhance the models reasoning robustness for better capturing user preferences from sparse interactions, we design Reasoning Contrastive Learning (RCL) objective. Specifically, we introduce dropout strategy along two orthogonal dimensions, representation and interaction, to construct diverse contrastive views. During the forward pass of the Transformer, we simultaneously apply random dropout to both the hidden representations (with dropout rate ùëùrep) and the attention score matrices (with dropout rate ùëùattn). By performing two independent forward passes with different dropout realizations, we obtain two augmented versions of reasoning outputs: {h(1) ùëá ,ùëÄ } and {h(2) ùëá ,ùëÄ }, where the superscripts denote different dropout masks. 1,1 , . . . , h(2) 1,1 , . . . , h(1) To enforce consistency between the two augmented views, we adopt an in-batch contrastive learning objective [13, 23, 32]. Specifically, for stream ùëö at reasoning step ùë°, we treat the corresponding reasoning states from the two dropout views of the same user as positive pairs, while treating states from other users in the same batch as negative samples. Given batch of ùêµ users, the contrastive loss for stream ùëö at step ùë° is defined as: Lùë°,ùëö RCL = 1 ùêµ ùêµ (cid:18) ùëñ=1 log exp(ùë† (1,2) /ùúè) ùëñùëñ ùëó=1 exp(ùë† (1,2) ùëñ ùëó (cid:205)ùêµ /ùúè) + log exp(ùë† (2,1) /ùúè) ùëñùëñ ùëó=1 exp(ùë† (2,1) ùëñ ùëó (cid:205)ùêµ /ùúè) (cid:19) , ùëñ ùëó = where ùë† (1,2) (2) ùë°,ùëö,ùëó (2) ùë°,ùëö,ùëó denotes the cosine similarity between (1) ùë°,ùëö,ùëñ (1) ùë°,ùëö,ùëñ different views (similarly for ùë† (2,1) ), and ùúè is the temperature hyperparameter. The overall reasoning contrastive loss aggregates over all reasoning steps and streams: ùëñ ùëó LRCL = 1 ùëá ùëÄ ùëá ùëÄ ùë° =1 ùëö=1 Lùë°,ùëö RCL. (8) This objective encourages the model to learn task-relevant representations that remain invariant across different augmented views, thereby enhancing generalization and robustness capabilities. 3.2.3 Mixture-of-Reasoning-Streams Aggregation. To synthesize outputs from multiple reasoning streams, naive uniform averaging risks contaminating superior reasoning outputs with inferior ones, leading to suboptimal final representations. To address this, we propose Mixture-of-Reasoning-Streams (MoRS) aggregation method that adaptively weights different streams. Inspired by gated mechanisms [26, 31, 52], we introduce lightweight gating network to compute stream-specific importance weights. Specifically, we feed the encoded representation h0 (extracted from Henc) into gating network: = softmax(Wùëîh0 + bùëî), where Wùëî RùëÄ ùëë and bùëî RùëÄ are learnable parameters, and = [ùëî1, . . . , ùëîùëÄ ] RùëÄ represents the normalized gating weights Parallel Latent Reasoning for Sequential Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY for ùëÄ streams. The final output is then computed as: ùëÄ ùëîùëözùëö, zrea = (9) ùëö=1 where zùëö is the pooled representation from stream ùëö (see Eq.(6)). Dual-Process Inference. Motivated by the dual-process theory in human cognitive science [18, 33], which posits that human cognition involves both fast intuitive thinking (System 1) and slow deliberative reasoning (System 2), we combine the encoder output (fast-thinking) with the reasoning output (slow-thinking) during inference. Specifically, the final sequence representation is: zfinal = h0 + zrea, (10) where h0 represents the fast-thinking component directly from the encoder, and zrea encapsulates the refined insights from deliberate multi-stream reasoning. This design leverages both rapid pattern recognition and deep logical inference for next-item prediction."
        },
        {
            "title": "3.3 Training Objective\nThe overall training objective combines the Next-Item Prediction\n(NIP) loss (Eq. (1)) with the aforementioned global regularization\nterm (Eq. (7)) and contrastive learning objective (Eq. (8)):",
            "content": "L = LNIP + LRCL + ùúÜLKL, (11) where ùúÜ is hyperparameter balancing the regularization strength. Notably, we adopt different strategies for training and inference to fully leverage the dual-process reasoning framework: Learning with Reasoning Output. During training, we exclusively use the slow-thinking output zrea (Eq. (9)) for the next-item prediction task. This design forces the model to develop genuine reasoning capabilities rather than taking shortcuts by relying solely on the fast-thinking encoder output h0. By preventing direct access to the encoder representation during training, we ensure that the model learns to perform deliberate multi-step reasoning. Inference with Dual-Process Integration. During inference, we combine both the fast-thinking and slow-thinking outputs using zfinal (Eq. (10)) to rank candidate items. This dual-process integration leverages the complementary strengths of both reasoning modes: the fast-thinking component h0 provides rapid pattern recognition based on direct encoding, while the slow-thinking component zrea contributes refined insights from deliberate multistream reasoning. The synergy between these two modes yields more robust and accurate recommendations."
        },
        {
            "title": "4.1 Why Diversity Reduces Error\nWe first establish the theoretical basis for combining multiple rea-\nsoning streams. Let ÀÜùëùùëö (ùë£ |Sùë¢ ) denote the predicted distribution\nfrom stream ùëö, and ¬Øùëù (ùë£ |Sùë¢ ) = 1\nùëö=1 ÀÜùëùùëö (ùë£ |Sùë¢ ) the uniformly\nùëÄ\nweighted ensemble prediction.",
            "content": "(cid:205)ùëÄ (cid:205)ùëÄ Theorem 4.1 (Ensemble Error Decomposition). Define the ensemble loss Lens = E( Sùë¢,ùë£)D [ log ùëù (ùë£ Sùë¢ )] and average individual loss Lind = 1 ùëö=1 E[ log ÀÜùëùùëö (ùë£ Sùë¢ )]. Then: Lens Lind ESùë¢ [I (Sùë¢ )], where the specialization benefit (Sùë¢ ) 0 quantifies the gain from diversity, with equality if and only if all ÀÜùëùùëö are identical. ùëÄ The proof (Appendix A.1) leverages Jensens inequality for the concave logarithm function. Intuitively, when streams produce diverse predictions, the ensemble averages out individual errors, yielding lower loss than the average individual loss. To connect diversity in representation space to diversity in prediction space, we establish the following result: Proposition 4.2 (Diversity-Specialization Connection). De- (cid:205)ùëöùëö zùëö fine representational diversity as ùê∑ (Sùë¢ ) = zùëö 2. Under linear scoring with bounded item embeddings, the specialization benefit satisfies: 1 ùëÄ (ùëÄ 1) (Sùë¢ ) ùëê ùê∑ (Sùë¢ ), where ùëê > 0 depends on embedding geometry. This establishes that representational diversity (which our trigger tokens and regularization directly control) translates to prediction diversity, which in turn reduces ensemble error."
        },
        {
            "title": "4.2 The Refinement-Diversity Trade-off\nWhile Theorem 4.1 shows the value of diversity, iterative reasoning\nintroduces a fundamental tension: refinement quality improves with\nmore steps, but diversity may decay. We formalize this trade-off\nusing contraction mapping theory.",
            "content": "Assumption 4.3 (Lipschitz Continuity). The reasoning function ùëì is ùêø-Lipschitz continuous: ùëì (h, r; ùúÉ ) ùëì (h, r; ùúÉ )2 ùêøh 2. Layer normalization in Transformers naturally constrains output norms and induces contraction behavior. For shallow architectures (e.g., 2-layer Transformers in our implementation), the Lipschitz constant ùêø is typically bounded by small constant. Theorem 4.4 (Diversity Decay Under Iteration). Under As- (cid:205)ùëöùëö hùë°,ùëö hùë°,ùëö 2 denote di1 sumption 4.3, let ùê∑ (ùë° ) = ùëÄ (ùëÄ 1) versity at reasoning step ùë°. Then: ùê∑ (ùëá ) = ùêø2ùëá ùê∑ (0) + ùëú (ùêø2ùëá ). When ùêø is bounded by constant smaller than 1, diversity decays exponentially: ùê∑ (ùëá ) = exp(2ùõæùëá )ùê∑ (0) where ùõæ := log ùêø > 0. The proof (Appendix A.3) follows from iteratively applying the Lipschitz property. This result reveals why depth-only scaling eventually fails: excessive reasoning steps collapse all streams toward common fixed point, eliminating the diversity benefit. Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. Corollary 4.5 (Refinement-Diversity Trade-off). Combining Theorems 4.1 and 4.4, the ensemble loss at step ùëá satisfies: ens (ùëá ) (ùëá ) ind ùëê ùëí 2ùõæùëá ùê∑ (0), where (ùëá ) ization benefit decays exponentially (diversity loss). ind decreases with ùëá (quality improvement), but the specialThis formalization explains the empirical over-thinking phenomenon: initially, increasing ùëá reduces (ùëá ) faster than diversity ind decays; eventually, diminishing returns from refinement are outweighed by diversity loss."
        },
        {
            "title": "4.3 Gating Benefits\nThe preceding analysis assumed uniform weighting. We now char-\nacterize the benefit of learned gating and its effect on generalization.",
            "content": "Theorem 4.6 (Gating Benefit via Mutual Information). Let ùëö=1 ùë§ùëö (Sùë¢ ) ÀÜùëùùëö (ùë£ Sùë¢ ) denote the gated ensemble. Then: ùëù (ùë£ Sùë¢ ) = (cid:205)ùëÄ Lgated Luniform ESùë¢ [ùêº (ùëç ; ùëâ Sùë¢ )], where ùëç w(Sùë¢ ) is stream selection, ùëâ ùëù (ùë£ Sùë¢ ) is the target, and ùêº (ùëç ; ùëâ Sùë¢ ) is conditional mutual information. This shows that gating provides benefit when streams specialize: if different streams excel on different sequence perspectives, the mutual information ùêº (ùëç ; ùëâ Sùë¢ ) > 0, and adaptive weighting outperforms uniform averaging."
        },
        {
            "title": "5.2 Reasoning-Enhanced Recommendation\nThe remarkable success of large language models (LLMs) [27, 28, 66],\nparticularly through Chain-of-Thought (CoT) prompting [47], has\ntransformed the landscape of AI by shifting from shallow pattern",
            "content": "matching to deep reasoning-driven generation. This breakthrough, which extends computation during test time rather than relying solely on encoding capacity, has inspired new era of reasoningenhanced recommendation research. Explicit Reasoning Approaches. The first line of work leverages LLMs logical capabilities to generate explicit reasoning chains for recommendation tasks. RecGPT-series [57, 58] and OneRecseries [25, 68] employ LLMs to verbalize insights about user interests, thereby improving prediction accuracy through interpretable reasoning paths. DeepRec [67] introduces multi-turn interactions for iterative refinement of recommendations, while R2ec [59] unifies reasoning and recommendation within an autoregressive LLM framework. However, explicit reasoning faces two critical challenges: (i) the absence of well-defined, verifiable reasoning chains in recommendation contexts (unlike mathematical or coding tasks with objective ground truth), and (ii) prohibitive inference latency from verbose token generation, rendering these methods impractical for real-time industrial deployment. Latent Reasoning Approaches. To overcome these limitations, an emerging paradigm adopts data-driven latent reasoning in continuous representation space, eliminating the need for explicit CoT annotations while maintaining low latency. ReaRec [35] pioneers this direction by introducing multi-step autoregressive reasoning with ensemble (ERL) and progressive (PRL) learning strategies. LARES [24] proposes architectural decoupling between encoding (pre-blocks) and reasoning (core-blocks) modules, employing selfsupervised pre-training and reinforcement learning for enhanced reasoning quality. OnePiece [8] upgrades to block-wise latent reasoning and introduces multi-task progressive supervision to enhance reasoning quality. LatentR3 [65] extends this paradigm to LLM backbones with RL-based optimization. Despite their promise, existing latent reasoning methods exclusively focus on depth-level computational scaling through sequential reasoning steps, exhibiting diminishing returns and over-thinking issues. In contrast, our work pioneers width-level parallel reasoning, exploring multiple diverse reasoning trajectories simultaneously to unlock further performance gains while maintaining real-time efficiency."
        },
        {
            "title": "6.1 Experimental Setup\n6.1.1 Datasets. We conduct experiments on three domains from\nthe Amazon Review 2023 dataset [14]: CDs & Vinyl, Movies &\nTV, and Video & Games. Following common practice in recom-\nmender systems [35, 67], we treat ratings greater than 3 as positive\nuser interactions. We chronologically split each user‚Äôs interaction\nsequence based on the official timestamps, which better reflects\nreal-world industrial scenarios and facilitates fair performance com-\nparison across baselines. For the CDs & Vinyl and Video & Games",
            "content": "Parallel Latent Reasoning for Sequential Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY Table 1: The dataset statistics. Dataset CDs & Vinyl Movies & TV Video & Games #User 35,238 51,566 90,678 #Item #Inter. 943,399 87,969 1,314,578 101,114 728,661 22, Sparsity 99.97% 99.97% 99.96% datasets, we filter out users with fewer than 10 interactions. Detailed dataset statistics are presented in Table 1. Feature Construction: For ID-based sequential models (e.g., SASRec, BERT4Rec), we construct item representations using the multilevel category hierarchy, store ID, and item ID provided by the dataset. For text-based models (e.g., UniSRec), we concatenate the item title, hierarchical categories, and store name to synthesize textual descriptions. These text sequences are then encoded using the BGE embedding model [3] to obtain dense sentence embeddings. 6.1.2 Evaluation Metrics. We adopt two widely-used ranking metrics in the field of recommender systems to evaluate models personalized modeling capability: Normalized Discounted Cumulative Gain at (NDCG@K, abbreviated as N@K) and Recall at (R@K). We report results for ùêæ {10, 20}. NDCG@K accounts for the position of relevant items in the ranking list with logarithmic discount, while Recall@K measures the proportion of ground-truth items successfully retrieved within the top-K recommendations. 6.1.3 Baselines. To comprehensively evaluate PLRs effectiveness, we select three representative backbone architectures and three state-of-the-art latent reasoning-enhanced methods. Base Models. We choose three widely-adopted sequential recommendation models as our backbone architectures: SASRec [19]: pioneering Transformer-based sequential recommendation model that employs unidirectional multi-head selfattention to capture sequential dependencies in user behavior. BERT4Rec [34]: An extension of SASRec that leverages bidirectional self-attention with Cloze task (masked item prediction) for sequence modeling, enabling richer contextual representations. UniSRec [15]: text-based sequential recommender that learns universal item representations through textual features and Mixtureof-Experts (MoE) adapters for cross-domain transfer. Latent Reasoning-Enhanced Methods. We focus exclusively on latent reasoning baselines to ensure fair comparison under comparable inference latency and model capacity. Explicit reasoning approaches and LLM-based methods are excluded due to their prohibitive computational overhead for real-time online serving and vastly different parameter scales. ReaRec-ERL [35]: The first latent reasoning framework for sequential recommendation, which firstly introduces multi-step autoregressive computation in latent space to explore test-time reasoning. ERL (Ensemble Reasoning Learning) aggregates outputs from all reasoning steps via average pooling. ReaRec-PRL [35]: variant of ReaRec that employs PRL (Progressive Reasoning Learning), which incrementally refines representations and uses only the final steps output for prediction. LARES [24]: two-stage reasoning architecture consisting of pre-blocks for encoding and core-blocks for reasoning. LARES incorporates self-supervised pre-training and reinforcement learningbased post-training to enhance reasoning capabilities. We implement different latent reasoning methods on top of the three backbone architectures for comprehensive evaluation. Implementation Details. All experiments are conducted 6.1.4 using the PyTorch framework on NVIDIA A100 GPUs. To ensure fair comparison across all models, we standardize the embedding dimension to ùëë = 256 and batch size to ùêµ = 2048. We employ the Adam optimizer [20] with learning rate of 1ùëí 3 and apply the GeLU activation function. User interaction sequences are truncated to maximum length of 50 items. For text-based models, we apply Principal Component Analysis (PCA) to reduce the BGE-encoded representations from their original dimensionality to 768 dimensions, preserving the most informative features. For PLR, we perform grid search to determine optimal hyperparameters: the number of reasoning streams ùëÄ and reasoning steps ùëá are searched in {1, 2, 3, 4, 5}; the KL regularization weight ùúÜ is tuned in {1ùëí 3, 1ùëí 2, 1ùëí 1, 1}; dropout rates ùëùrep and ùëùattn are set equal and searched in {0.1, 0.2, 0.3, 0.4, 0.5, 0.6}; and the temperature ùúè is fixed at 1. We use early stopping based on validation NDCG@10 with patience of 10 epochs. To optimize inference efficiency, we employ KV Caching technique that stores and reuses the computed key-value pairs from the input sequence encoding across all reasoning streams and steps, significantly reducing redundant computation overhead during multi-stream parallel reasoning."
        },
        {
            "title": "6.2 Overall Performance (RQ1)\nTable 2 presents the overall performance comparison across three\ndatasets. We highlight several key observations as follows:",
            "content": "(1) Reasoning-enhanced methods outperform base models across most settings, validating the effectiveness of test-time computational scaling. On CDs & Vinyl with SASRec, ReaRec-ERL improves Recall@10 by 5.15% and Recall@20 by 2.23%. On Movies & TV with BERT4Rec, ReaRec-ERL demonstrates strong improvements of 16.67% in Recall@10 and 13.49% in NDCG@10. These gains validate that allocating additional computation during inference enables deeper reasoning, particularly beneficial for sparse datasets. (2) Among depth-only reasoning methods, ReaRec-ERL generally demonstrates the strongest performance across most scenarios. For instance, on CDs & Vinyl with SASRec, ReaRec-ERL achieves Recall@10 of 0.0572 and NDCG@10 of 0.0269, outperforming both ReaRec-PRL and LARES. However, the performance differences among these methods remain relatively modest, indicating inherent limitations in depth-only reasoning where simply increasing reasoning depth yields diminishing returns. (3) PLR achieves substantial improvements over all baselines across the majority of metrics. On CDs & Vinyl with SASRec, PLR attains 12.07% improvement in Recall@20 over the best baseline ReaRec-ERL, with even more remarkable gains of 14.91% in Recall@10 on UniSRec. While improvements vary across different datasets and metrics, PLR demonstrates superior performance in most scenarios, particularly excelling on sparser datasets like CDs & Vinyl where it achieves over 10% improvements. These results demonstrate that width-level parallel reasoning effectively captures diverse user interests beyond single-trajectory depth reasoning. Crucially, these gains come with minimal inference overhead  (Table 4)  , making PLR practical for real-time systems. Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. Table 2: Performance comparison of different methods on three datasets. The best results are highlighted in bold, and the second-best results are underlined. Improv. denotes the relative improvement of PLR over the best baseline. * indicates statistical significance with ùëù < 0.05 using paired t-test. Method Base ReaRec-ERL ReaRec-PRL LARES PLR (Ours) Improv. Base ReaRec-ERL ReaRec-PRL LARES PLR (Ours) Improv. R@10 0.0544 0.0572 0.0553 0.0555 0.0604 +5.59%* 0.0555 0.0589 0.0541 0.0513 0.0626 +6.28%* Base ReaRec-ERL ReaRec-PRL LARES PLR (Ours) Improv. 0.0419 0.0456 0.0422 0.0434 0.0524 +14.91%* CDs & Vinyl R@20 N@10 0.0762 0.0779 0.0748 0.0757 0.0873 +12.07%* 0.0250 0.0269 0.0273 0.0260 0.0272 -0.37% 0.0745 0.0793 0.0782 0.0759 0.0827 +4.29%* 0.0638 0.0689 0.0680 0.0680 0.0748 +8.56%* 0.0260 0.0285 0.0272 0.0256 0.0293 +2.81%* 0.0195 0.0208 0.0195 0.0194 0.0223 +7.21%* N@20 R@ R@20 N@10 N@20 R@10 Movies & TV Video & Games N@10 R@ N@20 0.0305 0.0321 0.0323 0.0310 0.0339 +4.95%* 0.0308 0.0337 0.0333 0.0318 0.0344 +2.08%* 0.0250 0.0266 0.0260 0.0255 0.0279 +4.89%* SASRec 0.0502 0.0502 0.0504 0.0504 0.0532 +5.56%* 0.0664 0.0680 0.0650 0.0645 0.0701 +3.09%* 0.0230 0.0237 0.0244 0.0232 0.0250 +2.46%* BERT4Rec 0.0592 0.0664 0.0648 0.0652 0.0685 +3.16%* 0.0444 0.0518 0.0502 0.0502 0.0523 +0.97% UniSRec 0.0215 0.0244 0.0235 0.0232 0.0247 +1.23% 0.0557 0.0567 0.0557 0.0548 0.0620 +9.35%* 0.0724 0.0782 0.0754 0.0765 0.0816 +4.35%* 0.0249 0.0252 0.0252 0.0254 0.0271 +6.69%* 0.0270 0.0282 0.0280 0.0267 0.0293 +3.90%* 0.0253 0.0281 0.0271 0.0270 0.0288 +2.49%* 0.0291 0.0307 0.0303 0.0309 0.0321 +3.88%* 0.0624 0.0660 0.0630 0.0648 0.0676 +2.42%* 0.0937 0.0953 0.1003 0.0968 0.1033 +2.99%* 0.0622 0.0680 0.0629 0.0595 0.0656 -3.53% 0.0656 0.0673 0.0688 0.0687 0.0695 +1.02% 0.0912 0.1017 0.0989 0.0960 0.1018 +0.10% 0.1024 0.1006 0.1032 0.1029 0.1054 +2.13%* 0.0280 0.0315 0.0311 0.0314 0.0326 +3.49%* 0.0302 0.0334 0.0301 0.0319 0.0343 +2.69%* 0.0339 0.0351 0.0340 0.0353 0.0341 -3.40% 0.0359 0.0388 0.0405 0.0395 0.0416 +2.72%* 0.0376 0.0418 0.0392 0.0411 0.0435 +4.07%* 0.0432 0.0435 0.0427 0.0439 0.0431 -1.82% Figure 2: Parameter sensitivity analysis on the CDs & Vinyl dataset with SASRec backbone. Table 3: Ablation study. The experiments are conducted based on SASRec on the CDs & Vinyl and Video & Games datasets. Methods w/o MoRS w/o RCL w/o KL CDs & Vinyl N@20 R@20 0.0785 0.0782 0. 0.0321 0.0322 0.0334 Video & Games N@20 R@20 0.0997 0.0970 0.0979 0.0415 0.0387 0.0380 PLR (Full) 0. 0.0339 0.1033 0."
        },
        {
            "title": "6.3 Ablation Study (RQ2)\nTo validate the effectiveness of each component in PLR, we conduct\nablation experiments on two representative datasets (CDs & Vinyl\nand Video & Games) with SASRec backbone. Table 3 presents the",
            "content": "results of four ablated variants: (i) w/o MoRS replaces the adaptive mixture-of-reasoning-streams aggregation with uniform average pooling; (ii) w/o RCL removes the reasoning contrastive learning objective; and (iii) w/o KL eliminates the global regularization. The results demonstrate that each component contributes meaningfully to PLRs performance. Removing MoRS leads to notable performance degradation (Recall@20 drops from 0.0873 to 0.0785 on CDs & Vinyl), validating that adaptive gating effectively identifies superior reasoning streams, consistent with Theorem 4.6. Removing RCL causes decline particularly on Video & Games (Recall@20 drops from 0.1033 to 0.0970), confirming its role in enhancing robustness. Removing KL also leads to performance drops on both datasets, though the degradation is relatively modest, suggesting that diversity regularization provides consistent but moderate benefits. Overall, all components show positive contributions, with MoRS and RCL demonstrating more substantial effects. Parallel Latent Reasoning for Sequential Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY Table 4: Efficiency Comparison of Different Methods Metric FLOPs (108) Improv. Latency (s) Cost Inc. SASRec ReaRec 1.3810 1.3448 +2.69% - 0.8279 0.7844 +5.55% - PLR 1.4150 +5.22% 0.8299 +5.80% enable the model to explore diverse pathways and compensate for lost behavioral signals when certain interaction patterns become unavailable. These results demonstrate PLRs practical value for real-world recommendation scenarios where user behavioral data is inherently sparse and incomplete. Figure 4: Performance ceiling analysis on the CDs & Vinyl dataset with different backbones. 6.5.2 Performance Ceiling Analysis. To understand the theoretical potential of different reasoning approaches, we analyze performance ceilings by evaluating each reasoning steps output independently and selecting the best-performing step for each user sample (oracle selection). Figure 4 compares current performance (using fixed aggregation strategies) against oracle ceiling performance across three backbones on the CDs & Vinyl dataset. The results reveal that PLR and ReaRec-series achieve comparable oracle ceilings (e.g., NDCG@20 [0.0402, 0.0416]), indicating similar theoretical upper bounds. However, PLR exhibits notably smaller gaps between current and oracle performance, suggesting that its parallel multi-stream design enables more effective utilization of reasoning capacity. In contrast, depth-only methods show larger performance gaps, indicating that appropriate step selection is more critical but challenging without width-level exploration. This demonstrates that PLRs co-design of depth and width provides more accessible path to near-optimal performance, reducing reliance on oracle-level step selection while maintaining competitive ceiling potential. 6.5.3 Efficiency Analysis. To evaluate the computational overhead, we compare the FLOPs and inference latency per sample on the CDs & Vinyl dataset with SASRec backbone. As shown in Table 4, PLR introduces 5.22% additional FLOPs and 5.80% latency increase compared to the base SASRec, which represents remarkably efficient trade-off considering the substantial performance gains. Notably, PLRs computational overhead remains comparable Figure 3: Robustness analysis on the CDs & Vinyl dataset."
        },
        {
            "title": "6.4 Sensitivity Analysis (RQ3)\nWe conduct sensitivity analysis on key hyperparameters to under-\nstand their impact on PLR‚Äôs performance. Figure 2 presents the\nresults on the CDs & Vinyl dataset with SASRec backbone, mea-\nsured by NDCG@20 and Recall@20.",
            "content": "Number of Reasoning Streams (ùëÄ). As shown in Figure 2(a), performance peaks at ùëÄ = 2, achieving optimal NDCG@20 and Recall@20. Increasing ùëÄ beyond 2 leads to performance degradation, likely because excessive streams introduce redundant reasoning paths that dilute superior streams contributions, and limited training data becomes insufficient for effectively optimizing numerous specialized streams. We set ùëÄ = 2 as the default configuration. Number of Reasoning Steps (ùëá ). Figure 2(b) shows performance peaks at ùëá = 2, then declines with deeper reasoning. This aligns with our theoretical analysis (Theorem 4.4): while moderate reasoning steps enable sufficient refinement, excessive depth causes diversity decay due to Lipschitz contraction. The optimal ùëá = 2 balances refinement quality and diversity preservation, confirming the over-thinking phenomenon in depth-only methods. Regularization Weight (ùúÜ). Figure 2(c) shows optimal performance at ùúÜ = 0.1. Insufficient regularization (ùúÜ < 0.1) fails to enforce diversity, allowing streams to collapse into homogeneous patterns. Overly aggressive regularization (ùúÜ > 0.1) negatively impacts learning by pushing different reasoning streams too far apart, hindering convergence toward high-quality solutions. Dropout Rate (ùëù). Figure 2(d) indicates that moderate dropout rates ùëù [0.2, 0.5] yield the best performance. Low dropout (ùëù < 0.2) provides insufficient augmentation for contrastive learning, while excessive dropout (ùëù > 0.5) corrupts reasoning by removing too much information. The optimal range effectively balances augmentation diversity and information preservation."
        },
        {
            "title": "6.5 In-Depth Analysis (RQ4)\n6.5.1 Robustness Analysis. To evaluate model robustness un-\nder extreme data sparsity, we randomly remove 10%, 20%, and 30%\nof interactions from user sequences in the CDs & Vinyl test set.\nFigure 3 shows that while all models exhibit performance decline\nas sparsity increases, reasoning-enhanced methods demonstrate\nsuperior robustness compared to base models. At 20% missing rate,\nthe base SASRec‚Äôs performance drops significantly, whereas rea-\nsoning methods maintain relatively stable performance. Among all\napproaches, PLR exhibits the strongest robustness: at 30% missing\nrate, PLR maintains NDCG@20 around 0.028, substantially outper-\nforming other methods. This superior robustness stems from PLR‚Äôs\nparallel reasoning mechanism, where multiple reasoning streams",
            "content": "Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. reasoning scaling, potentially enabling more sophisticated multidimensional reasoning architectures. References [1] Pranjal Aggarwal, Aman Madaan, Yiming Yang, et al. 2023. Lets Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs. arXiv preprint arXiv:2305.11860 (2023). [2] Janice Ahn, Rishu Verma, Renze Lou, Di Liu, Rui Zhang, and Wenpeng Yin. 2024. Large language models for mathematical reasoning: Progresses and challenges. arXiv preprint arXiv:2402.00157 (2024). [3] Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. arXiv preprint arXiv:2402.03216 (2024). Figure 5: Attention visualization illustration. to ReaRec (2.69% FLOPs and 5.55% latency increase), despite exploring multiple reasoning streams simultaneously. This efficiency stems from two key design choices: (i) KV Caching mechanism that reuses the shared encoded key-value pairs from the input and prior reasoning states across all streams and steps, avoiding redundant computation; (ii) vectorized parallel multi-stream reasoning, which leverages modern GPU parallelism to process ùëÄ streams simultaneously without proportional latency scaling. Consequently, PLR achieves width-level computational scaling while maintaining real-time inference feasibility, making it practical for industrial deployment where both accuracy and response time are critical. 6.5.4 Attention Visualization Analysis. To provide deeper insights into the multi-stream reasoning mechanism, we visualize the attention distributions across different streams and reasoning steps in Figure 5. The visualization reveals that different streams exhibit distinct attention patterns, focusing on complementary aspects of the input sequence: while one stream concentrates on recent interactions, another explores long-term dependencies. This diversity in attention allocation substantiates that our multi-stream architecture encourages exploration of heterogeneous reasoning paths, enabling more comprehensive coverage of user interests and contributing to PLRs superior performance."
        },
        {
            "title": "7 Conclusion\nIn this work, we propose Parallel Latent Reasoning (PLR), a novel\nframework that pioneers width-level computational scaling for se-\nquential recommendation. Unlike existing depth-only reasoning\nmethods that suffer from diminishing returns, PLR explores mul-\ntiple diverse reasoning trajectories simultaneously through learn-\nable trigger tokens, global reasoning regularization, and adaptive\nmixture-of-reasoning-streams aggregation. Extensive experiments\non three real-world datasets demonstrate that PLR substantially\noutperforms state-of-the-art baselines while maintaining real-time\ninference efficiency. Theoretical analysis further validates the effec-\ntiveness of parallel reasoning in reducing prediction error through\nensemble diversity and mitigating over-thinking issues. Our work\nopens new avenues for reasoning-enhanced recommendation by\ndemonstrating that width-level scaling offers a complementary di-\nmension to depth scaling for unlocking models‚Äô reasoning potential.\nLooking forward, we plan to further explore synergistic inte-\ngration strategies that jointly optimize both parallel and depth",
            "content": "[4] Lingjiao Chen, Jared Davis, Boris Hanin, Peter Bailis, Ion Stoica, Matei Zaharia, and James Zou. 2024. Are more llm calls all you need? towards the scaling properties of compound ai systems. Advances in Neural Information Processing Systems 37 (2024), 4576745790. [5] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wanxiang Che. 2025. Towards reasoning era: survey of long chain-of-thought for reasoning large language models. arXiv preprint arXiv:2503.09567 (2025). [6] Andy Clark. 1989. Microcognition: Philosophy, cognitive science, and parallel distributed processing. Vol. 6. MIT Press. [7] Qiang Cui, Shu Wu, Qiang Liu, Wen Zhong, and Liang Wang. 2018. MV-RNN: multi-view recurrent neural network for sequential recommendation. IEEE Transactions on Knowledge and Data Engineering 32, 2 (2018), 317331. [8] Sunhao Dai, Jiakai Tang, Jiahua Wu, Kun Wang, Yuxuan Zhu, Bingjun Chen, Bangyang Hong, Yu Zhao, Cong Fu, Kangle Wu, et al. 2025. Onepiece: Bringing context engineering and reasoning to industrial cascade ranking system. arXiv preprint arXiv:2509.18091 (2025). [9] Yangruibo Ding, Jinjun Peng, Marcus Min, Gail Kaiser, Junfeng Yang, and Baishakhi Ray. 2024. Semcoder: Training code language models with comprehensive semantics reasoning. Advances in Neural Information Processing Systems 37 (2024), 6027560308. [10] Tim Donkers, Benedikt Loepp, and J√ºrgen Ziegler. 2017. Sequential user-based recurrent neural network recommendations. In Proceedings of the eleventh ACM conference on recommender systems. 152160. [11] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948 (2025). [12] Lei Guo, Hongzhi Yin, Qinyong Wang, Tong Chen, Alexander Zhou, and Nguyen Quoc Viet Hung. 2019. Streaming session-based recommendation. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. 15691577. [13] Yupeng Hou, Zhankui He, Julian McAuley, and Wayne Xin Zhao. 2023. Learning vector-quantized item representation for transferable sequential recommenders. In Proceedings of the ACM Web Conference 2023. 11621171. [14] Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian McAuley. 2024. Bridging Language and Items for Retrieval and Recommendation. arXiv preprint arXiv:2403.03952 (2024). [15] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining. 585593. [16] Jie Huang and Kevin Chen-Chuan Chang. 2023. Towards reasoning in large language models: survey. In Findings of the association for computational linguistics: ACL 2023. 10491065. [17] Ray Jackendoff. 2011. The parallel architecture and its place in cognitive science. Syntax and Morphology Multidimensional. Eds. A. Nolda, O. Teuber. Berlin, New York: Mouton De Gruyter (2011), 1744. [18] Daniel Kahneman. 2011. Thinking, fast and slow. macmillan. [19] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 197206. [20] Diederik Kingma. 2014. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014). [21] Ioannis Konstas, Vassilios Stathopoulos, and Joemon Jose. 2009. On social networks and collaborative recommendation. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. 195202. [22] Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, and Brian Ichter. 2023. Chain of code: Reasoning with language model-augmented code emulator. arXiv preprint arXiv:2312.04474 (2023). Parallel Latent Reasoning for Sequential Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY [23] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving graph collaborative filtering with neighborhood-enriched contrastive learning. In Proceedings of the ACM web conference 2022. 23202329. [24] Enze Liu, Bowen Zheng, Xiaolei Wang, Wayne Xin Zhao, Jinpeng Wang, Sheng Chen, and Ji-Rong Wen. 2025. LARES: Latent Reasoning for Sequential Recommendation. arXiv preprint arXiv:2505.16865 (2025). [25] Zhanyu Liu, Shiyao Wang, Xingmei Wang, Rongzhou Zhang, Jiaxin Deng, Honghui Bao, Jinghao Zhang, Wuchao Li, Pengfei Zheng, Xiangyu Wu, et al. 2025. Onerec-think: In-text reasoning for generative recommendation. arXiv preprint arXiv:2510.11639 (2025). [26] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining. 19301939. [27] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. 2024. Large language models: survey. arXiv preprint arXiv:2402.06196 (2024). [28] Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick Barnes, and Ajmal Mian. 2025. comprehensive overview of large language models. ACM Transactions on Intelligent Systems and Technology 16, 5 (2025), 172. [29] Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, and Dacheng Tao. 2025. Revisiting Overthinking in Long Chain-of-Thought from the Perspective of SelfDoubt. arXiv preprint arXiv:2505.23480 (2025). [30] Aske Plaat, Annie Wong, Suzan Verberne, Joost Broekens, Niki van Stein, and Thomas Back. 2024. Reasoning with large language models, survey. arXiv preprint arXiv:2407.11511 (2024). [31] Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, et al. 2025. Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free. arXiv preprint arXiv:2505.06708 (2025). [32] Evgenia Rusak, Patrik Reizinger, Attila Juhos, Oliver Bringmann, Roland Zimmermann, and Wieland Brendel. 2024. InfoNCE: Identifying the gap between theory and practice. arXiv preprint arXiv:2407.00143 (2024). [33] Steven Sloman. 1996. The empirical case for two systems of reasoning. Psychological bulletin 119, 1 (1996), 3. [34] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 14411450. [35] Jiakai Tang, Sunhao Dai, Teng Shi, Jun Xu, Xu Chen, Wen Chen, Jian Wu, and Yuning Jiang. 2025. Think before recommend: Unleashing the latent reasoning power for sequential recommendation. arXiv preprint arXiv:2503.22675 (2025). [36] Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, and Han Li. 2024. Towards robust recommendation via decision boundary-aware graph contrastive learning. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 28542865. [37] Jiakai Tang, Yujie Luo, Xunke Xi, Fei Sun, Xueyang Feng, Sunhao Dai, Chao Yi, Dian Chen, Zhujin Gao, Yang Li, et al. 2025. Interactive Recommendation Agent with Active User Commands. arXiv preprint arXiv:2509.21317 (2025). [38] Jiakai Tang, Zuxu Sun, Wei Yao, and Xu Chen. 2024. Robust Graph Recommendation via Noise-Aware Adversarial Perturbation. In International Conference on Database Systems for Advanced Applications. Springer, 134150. [39] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the eleventh ACM international conference on web search and data mining. 565573. [40] Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. 2025. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599 (2025). [41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [42] Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, et al. 2025. ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling. arXiv preprint arXiv:2512.21257 (2025). [43] Peng-Yuan Wang, Tian-Shuo Liu, Chenyang Wang, Ziniu Li, Yidi Wang, Shu Yan, Chengxing Jia, Xu-Hui Liu, Xinwei Chen, Jiacheng Xu, et al. 2025. survey on large language models for mathematical reasoning. Comput. Surveys (2025). [44] Weiqing Wang, Hongzhi Yin, Zi Huang, Qinyong Wang, Xingzhong Du, and Quoc Viet Hung Nguyen. 2018. Streaming ranking based recommender systems. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 525534. [45] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 (2022). [46] Ziqi Wang, Boye Niu, Zhongli Li, Linghui Meng, Jing Liu, Zhi Zheng, Tong Xu, Hua Wu, Haifeng Wang, and Enhong Chen. 2025. A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning. arXiv preprint arXiv:2509.22044 (2025). [47] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems 35 (2022), 2482424837. [48] Wei Wei, Chao Huang, Lianghao Xia, and Chuxu Zhang. 2023. Multi-modal self-supervised learning for recommendation. In Proceedings of the ACM web conference 2023. 790800. [49] Sam Wiseman and Alexander Rush. 2016. Sequence-to-sequence learning as beam-search optimization. arXiv preprint arXiv:1606.02960 (2016). [50] Liwei Wu, Shuqing Li, Cho-Jui Hsieh, and James Sharpnack. 2020. SSE-PT: Sequential recommendation via personalized transformer. In Proceedings of the 14th ACM conference on recommender systems. 328337. [51] Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, James Xu Zhao, Min-Yen Kan, Junxian He, and Michael Xie. 2023. Self-evaluation guided beam search for reasoning. Advances in Neural Information Processing Systems 36 (2023), 4161841650. [52] Lanqing Xue, Xiaopeng Li, and Nevin Zhang. 2020. Not all attention is needed: Gated attention network for sequence data. In Proceedings of the AAAI conference on artificial intelligence, Vol. 34. 65506557. [53] Anushka Yadav, Isha Nalawade, Srujana Pillarichety, Yashwanth Babu, Reshmi Ghosh, Samyadeep Basu, Wenlong Zhao, Ali Nasaeh, Sriram Balasubramanian, and Soundararajan Srinivasan. 2025. Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis. arXiv preprint arXiv:2508.04699 (2025). [54] An Yan, Shuo Cheng, Wang-Cheng Kang, Mengting Wan, and Julian McAuley. 2019. CosRec: 2D convolutional neural networks for sequential recommendation. In Proceedings of the 28th ACM international conference on information and knowledge management. 21732176. [55] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. 2025. Qwen3 technical report. arXiv preprint arXiv:2505.09388 (2025). [56] Xiwang Yang, Harald Steck, and Yong Liu. 2012. Circle-based recommendation in online social networks. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 12671275. [57] Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Wen Chen, Wenjun Yang, Yujie Luo, et al. 2025. RecGPT-V2 Technical Report. arXiv preprint arXiv:2512.14503 (2025). [58] Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Sunhao Dai, Wen Chen, Wenjun Yang, et al. 2025. Recgpt technical report. arXiv preprint arXiv:2507.22879 (2025). [59] Runyang You, Yongqi Li, Xinyu Lin, Xin Zhang, Wenjie Wang, Wenjie Li, and Liqiang Nie. 2025. R2ec: Towards Large Recommender Models with Reasoning. In The Thirty-ninth Annual Conference on Neural Information Processing Systems. [60] Fuqiang Yu, Lizhen Cui, Wei Guo, Xudong Lu, Qingzhong Li, and Hua Lu. 2020. category-aware deep model for successive POI recommendation on sparse check-in data. In Proceedings of the web conference 2020. 12641274. [61] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? idvs. modality-based recommender models revisited. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 26392649. [62] Gaowei Zhang, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, and JiRong Wen. 2024. Scaling law of large sequential recommendation models. In Proceedings of the 18th ACM Conference on Recommender Systems. 444453. [63] Jiaqi Zhang, Junliang Yu, Zongwei Wang, Wei Yuan, Tong Chen, Quoc Viet Hung Nguyen, Bin Cui, and Hongzhi Yin. 2025. Towards Reasoning-Aware Recommender Systems: Survey in the LLM Era. Authorea Preprints (2025). [64] Junjie Zhang, Beichen Zhang, Wenqi Sun, Hongyu Lu, Wayne Xin Zhao, Yu Chen, and Ji-Rong Wen. 2025. Slow Thinking for Sequential Recommendation. arXiv preprint arXiv:2504.09627 (2025). [65] Yang Zhang, Wenxin Xu, Xiaoyan Zhao, Wenjie Wang, Fuli Feng, Xiangnan He, and Tat-Seng Chua. 2025. Reinforced Latent Reasoning for LLM-based Recommendation. arXiv preprint arXiv:2505.19092 (2025). [66] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. survey of large language models. arXiv preprint arXiv:2303.18223 1, 2 (2023). [67] Bowen Zheng, Xiaolei Wang, Enze Liu, Xi Wang, Lu Hongyu, Yu Chen, Wayne Xin Zhao, and Ji-Rong Wen. 2025. DeepRec: Towards Deep Dive Into the Item Space with Large Language Model Based Recommendation. arXiv preprint arXiv:2505.16810 (2025). [68] Guorui Zhou, Honghui Bao, Jiaming Huang, Jiaxin Deng, Jinghao Zhang, Junda She, Kuo Cai, Lejian Ren, Lu Ren, Qiang Luo, et al. 2025. OpenOneRec Technical Report. arXiv preprint arXiv:2512.24762 (2025). [69] Pablo Zivic, Hernan Vazquez, and Jorge S√°nchez. 2024. Scaling sequential recommendation models with transformers. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 15671577. Conference acronym XX, June 0305, 2018, Woodstock, NY Trovato et al. Complete Theoretical Proofs A.1 Proof of Theorem 4.1 (Ensemble Error Decomposition) Proof. For any sequence Sùë¢ , the expected negative log-likelihood under ùëù (ùë£ Sùë¢ ) is: Eùë£ùëù [ log ùëù (ùë£ Sùë¢ )] = ùëù (ùë£ Sùë¢ ) log ùë£ (cid:33) ÀÜùëùùëö (ùë£ Sùë¢ ) . (cid:32) 1 ùëÄ ùëÄ ùëö=1 By Jensens inequality (concavity of log): log (cid:32) 1 ùëÄ ùëÄ ùëö=1 (cid:33) ÀÜùëùùëö (ùë£ Sùë¢ ) 1 ùëÄ ùëÄ ùëö=1 log ÀÜùëùùëö (ùë£ Sùë¢ ), with strict inequality when predictions differ. Therefore: Eùë£ùëù [ log ùëù (ùë£ Sùë¢ )] = 1 ùëÄ 1 ùëÄ ùëÄ ùëö=1 ùëÄ ùëö=1 Eùë£ùëù [ log ÀÜùëùùëö (ùë£ Sùë¢ )] Lùëö (Sùë¢ ), where Lùëö (Sùë¢ ) is the loss of stream ùëö on sequence Sùë¢ . Taking expectation over Sùë¢ yields: Lens Lind. The gap (Sùë¢ ) = Lind Lens (Sùë¢ ) quantifies the benefit of diverse predictions. By the AM-GM inequality, (Sùë¢ ) 0 with equality if and only if all ÀÜùëùùëö (ùë£ Sùë¢ ) are identical. A.2 Proof of Proposition 4.2 Averaging over all pairs (ùëö, ùëö): ùê∑ (ùëá ) = 1 ùëÄ (ùëÄ 1) ùëöùëö hùëá ,ùëö hùëá ,ùëö 2 ùêø2ùëá ùê∑ (0) . For ùêø < 1, writing ùêø = ùëí ùõæ with ùõæ = log ùêø > 0 yields the exponential form: ùê∑ (ùëá ) ùëí 2ùõæùëá ùê∑ (0) . (cid:33) A.4 Proof of Theorem 4.6 (Gating Benefit) Proof. For any Sùë¢ , by Jensens inequality: (cid:32) ùëÄ Eùë£ùëù [ log ùëù (ùë£ Sùë¢ )] = ùëù (ùë£ Sùë¢ ) log ùë§ùëö (Sùë¢ ) ÀÜùëùùëö (ùë£ Sùë¢ ) ùë£ ùë£ ùëù (ùë£ Sùë¢ ) ùëÄ ùëö=1 ùëö=1 ùë§ùëö (Sùë¢ ) log ÀÜùëùùëö (ùë£ Sùë¢ ) ùëÄ = ùë§ùëö (Sùë¢ )Eùë£ùëù [ log ÀÜùëùùëö (ùë£ Sùë¢ )]. ùëö=1 The gap between gated and uniform ensemble is: Luniform (Sùë¢ ) Lgated (Sùë¢ ) = Eùë£ùëù [log ùëù (ùë£ Sùë¢ ) log ùëù (ùë£ Sùë¢ )] . When streams specialize (per-stream losses vary across ùëö and Sùë¢ ), optimal weighting assigns higher ùë§ùëö (Sùë¢ ) to streams with lower losses. This gain is quantified by the conditional mutual information: ùêº (ùëç ; ùëâ Sùë¢ ) = ùëÄ ùëö= ùë§ùëö (Sùë¢ )Eùë£ùëù (cid:20) log ÀÜùëùùëö (ùë£ Sùë¢ ) ùëù (ùë£ Sùë¢ ) (cid:21) , (Diversity-Specialization Connection) Proof. Under linear scoring, ÀÜùëùùëö (ùë£ Sùë¢ ) = softmax(zùëö, eùë£). For two distinct streams ùëö, ùëö: which measures how much knowledge of the selected stream ùëç reveals about the target ùëâ . Under specialization, ùêº (ùëç ; ùëâ Sùë¢ ) > 0. ÀÜùëùùëö (Sùë¢ ) ÀÜùëùùëö (Sùë¢ )TV ùõøùëí 2ùëÖ zùëö zùëö , where TV is total variation distance, ùëÖ bounds item embeddings, and ùõøùëí is minimum embedding separation. By Pinskers inequality, total variation bounds KL divergence: KL( ÀÜùëùùëö ÀÜùëùùëö ) 1 2 ÀÜùëùùëö ÀÜùëùùëö 2 TV ùõø 2 ùëí 8ùëÖ2 zùëö zùëö 2. The specialization benefit (from Jensens inequality gap) is lower bounded by the average pairwise KL divergence: (Sùë¢ ) 1 ùëÄ (ùëÄ 1) KL( ÀÜùëùùëö ÀÜùëùùëö ) Setting ùëê = ùõø ùëöùëö ùëí /(8ùëÖ2) > 0 completes the proof. ùõø 2 ùëí 8ùëÖ2 ùê∑ (Sùë¢ ). A.3 Proof of Theorem 4.4 (Diversity Decay) Proof. By the Lipschitz property (Assumption 4.3): hùë°,ùëöhùë°,ùëö = ùëì (hùë° 1,ùëö, rùë° )ùëì (hùë° 1,ùëö, rùë° ) ùêøhùë° 1,ùëöhùë° 1,ùëö . Iterating from ùë° = 0 to ùë° = ùëá : hùëá ,ùëö hùëá ,ùëö ùêøùëá h0,ùëö h0,ùëö = ùêøùëá ùùâùëö ùùâùëö . Squaring both sides: hùëá ,ùëö hùëá ,ùëö 2 ùêø2ùëá ùùâùëö ùùâùëö 2."
        }
    ],
    "affiliations": [
        "Alibaba Group",
        "GSAI, Renmin University of China"
    ]
}