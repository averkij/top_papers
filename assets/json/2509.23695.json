{
    "paper_title": "Estimating Time Series Foundation Model Transferability via In-Context Learning",
    "authors": [
        "Qingren Yao",
        "Ming Jin",
        "Chengqi Zhang",
        "Chao-Han Huck Yang",
        "Jun Qi",
        "Shirui Pan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Time series foundation models (TSFMs) offer strong zero-shot forecasting via large-scale pre-training, yet fine-tuning remains critical for boosting performance in domains with limited public data. With the growing number of TSFMs, efficiently identifying the best model for downstream fine-tuning becomes increasingly challenging. In this work, we introduce TimeTic, a transferability estimation framework that recasts model selection as an in-context-learning problem: given observations on known (source) datasets, it predicts how a TSFM will perform after fine-tuning on a downstream (target) dataset. TimeTic flexibly organizes the observed model-data relationships as contextual information, allowing it to adapt seamlessly to various test-time scenarios. Leveraging the natural tabular structure formed by dataset meta-features, model characteristics, and fine-tuned performance, we employ tabular foundation models to serve as in-context learners. We further introduce a novel model characterization based on entropy evolution across model layers, capturing embedding-space distinctions and enabling TimeTic to generalize across arbitrary model sets. We establish a comprehensive benchmark for transferability estimation including 10 datasets, 10 foundation models, and 3 forecasting tasks. On this benchmark, TimeTic's estimation demonstrates strong alignment with actual fine-tuned performance for previously unseen datasets, achieving a mean rank correlation of approximately 0.6 and a 30% improvement compared to using zero-shot performance as the transferability score."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 2 ] . [ 1 5 9 6 3 2 . 9 0 5 2 : r a"
        },
        {
            "title": "Preprint",
            "content": "ESTIMATING TIME SERIES FOUNDATION MODEL TRANSFERABILITY VIA IN-CONTEXT LEARNING Qingren Yao1,2, Ming Jin1, Chengqi Zhang3, Chao-Han Huck Yang4, Jun Qi2, Shirui Pan1 1Griffith University 2Hong Kong Baptist University 3The Hong Kong Polytechnic University 4NVIDIA Research"
        },
        {
            "title": "ABSTRACT",
            "content": "Time series foundation models (TSFMs) offer strong zero-shot forecasting via large-scale pre-training, yet fine-tuning remains critical for boosting performance in domains with limited public data. With the growing number of TSFMs, efficiently identifying the best model for downstream fine-tuning becomes increasingly challenging. In this work, we introduce TIMETIC, transferability estimation framework that recasts model selection as an in-context-learning problem: given observations on known (source) datasets, it predicts how TSFM will perform after fine-tuning on downstream (target) dataset. TIMETIC flexibly organizes the observed model-data relationships as contextual information, allowing it to adapt seamlessly to various test-time scenarios. Leveraging the natural tabular structure formed by dataset meta-features, model characteristics, and fine-tuned performance, we employ tabular foundation models to serve as in-context learners. We further introduce novel model characterization based on entropy evolution across model layers, capturing embedding-space distinctions and enabling TIMETIC to generalize across arbitrary model sets. We establish comprehensive benchmark for transferability estimation including 10 datasets, 10 foundation models, and 3 forecasting tasks. On this benchmark, TIMETICs estimation demonstrates strong alignment with actual fine-tuned performance for previously unseen datasets, achieving mean rank correlation of approximately 0.6 and 30% improvement compared to using zero-shot performance as the transferability score."
        },
        {
            "title": "INTRODUCTION",
            "content": "The emergence of time series foundation models (TSFMs) is reshaping the paradigm of time series forecasting (Liang et al., 2025) through their strong zero-shot capabilities. Although efficient and cost-effective, zero-shot inference often underperforms in out-of-distribution scenarios, particularly in domains with limited public data, such as healthcare (Gupta et al., 2024) and finance (Fu et al., 2024). Fine-tuning helps bridge the gap by transferring generalized knowledge from large-scale pre-training to specific, resource-limited downstream tasks (Li & Zhu, 2025). However, due to the inherent diversity of time series data, no single model consistently outperforms others in all scenarios (Brigato et al., 2025). Selecting the most appropriate model from all available models becomes critical consideration that directly impacts the performance of downstream tasks (Ding et al., 2024). straightforward approach would be to enumerate all available TSFMs and evaluate their fine-tuned performance, but this is impractical due to the significant computational cost and extensive training time required, as shown in Figure 1 (a). Therefore, crucial question arises: how can we efficiently identify the best candidate time series model to fine-tune for given test-time scenario with limited data? Existing efficient model selection techniques generally fall into two categories: (1) statistical metrics (You et al., 2021; Nguyen et al., 2023) and (2) meta-learning strategies ( Ozturk et al., 2022; Abdallah et al., 2022b). Most statistical metrics are designed for image classification and depend on strong assumptions about the class structure (Li et al., 2021; Gholami et al., 2023). Although computationally efficient, they are predefined and uniformly applied across scenarios, limiting their Correspondence to: M. Jin <mingjinedu@gmail.com> and J. Qi <jun-qi@comp.hkbu.edu.hk>"
        },
        {
            "title": "Preprint",
            "content": "Figure 1: Model selection paradigms. (a) Enumeration paradigm: Each TSFM is fine-tuned on the target data, and their performances Pm are evaluated to select the best model. (b) In-context learning paradigm: Observed model transfers are organized into context table (Xcontext, ycontext) composed of characteristicperformance pairs. This table provides exemplars for tabular foundation model, which then predicts the transferred performance Sm of target model on new data, given its target table Xtarget. (c) Performance overview: The transferability scores estimated by TIMETIC show strong alignment with actual fine-tuned performance, achieving more than 30% higher Spearman rank correlation compared to ranking models based on their zero-shot performance. adaptability to diverse time series forecasting tasks and models. Meta-learning methods instead train meta-estimator on task-performance pairs to predict fine-tuned performance. However, the estimator is tied to its (fixed) training corpus and predefined model set, restricting its ability to generalize to new tasks or models. In general, existing approaches lack the adaptability needed for transferability estimation in practical settings with TSFMs, where test-time scenarios are open-ended and constantly evolving. In this study, we present TIMETIC, framework for estimating the transferability of TSFMs by casting performance prediction as an in-context learning task: given models transferred performance on known datasets, predict its finetuned performance on new target dataset. As illustrated in Figure 1(b), this paradigm allows flexible organization of historical data to make informed predictions. To this end, we integrate past observations into tabular representation, consolidating models, datasets, and transferred performance within structured table. This format not only facilitates scalability with growing observational data but also clearly captures interrelationships among entities. Recent advances in tabular foundation models have demonstrated strong in-context learning capabilities for structured data (Robertson et al., 2025; Hollmann et al., 2025). Building on this, we employ tabular foundation model as the in-context learner, enabling efficient prediction of target model performance from past transfer observations. To scale across growing variety of TSFMs, we further introduce novel model characterization strategy based on entropy evolution across layers. This architecture-agnostic approach allows TIMETIC to generalize effectively to various types of models. Extensive experiments on 10 datasets, 10 TSFMs, and 3 forecast settings demonstrate that TIMETIC consistently outperforms existing methods, achieving an average Spearman rank correlation of approximately 0.6 and delivering 30% improvement over rankings based on zero-shot performance, as shown in Figure 1(c). The main contributions of this paper are summarized as follows: We propose TIMETIC, the first in-context transferability estimation framework for TSFMs, leveraging tabular foundation models to predict fine-tuned performance from past transfer observations. This offers more practical and efficient alternative to existing methods. We introduce model-agnostic characterization of TSFMs based on the entropy profile, the trajectory of token sequence entropy across model layers. This enables TIMETIC to estimate transferability across arbitrary model classes, without being restricted to fixed candidate set. We construct comprehensive transferability benchmark that spans 10 widely used datasets, 10 time series foundation models, and 3 forecasting tasks, and demonstrate that TIMETIC outperforms existing approaches by more than 30% in model transferability estimation."
        },
        {
            "title": "2 RELATED WORK",
            "content": "Time series foundation model Time series forecasting is critical to decision making, driving advances in both statistical and domain-specific deep learning approaches (Liang et al., 2024). Recently, the focus has shifted to TSFMs because of their strong generalization. Transformer has become the dominant architecture in TSFMs, which fall into three categories: (1) Encoder-only models, such as Moirai (Woo et al., 2024) and Moment (Goswami et al., 2024), using mask prediction for forecasting. (2) Encoder-decoder models, exemplified by the Chronos family (Ansari et al., 2024), which adapts T5 (Raffel et al., 2019) with quantization-based tokenization for time series forecasting. (3) Decoder-only models, including TimesFM (Das et al., 2023), Lag-Llama (Rasul et al., 2023), Timer (Liu et al., 2024) and Time-MoE (Shi et al., 2025), employing autoregressive generation for future prediction. Transferability metric Assessing the transferability of pretrained models is essential for model selection (Okanovic et al., 2024; Lin et al., 2024). Transferability metrics generally aim to quantify the statistical relationship between feature embeddings and sample labels. Most metrics such as H-Score (Bao et al., 2019), NCE (Tran et al., 2019) and LEEP (Nguyen et al., 2020) are primarily designed for classification tasks, relying on the assumption that model outputs follow categorical distribution. In contrast, only few metrics such as LFC (Deshpande et al., 2021), LogME (You et al., 2021), and RegScore (Nguyen et al., 2023) are applicable in broader tasks by estimating transferability through similarity of the characteristic of the label, marginal likelihood and linear regression error, respectively. Learning to select Early work (Lemke & Gabrys, 2010) explored meta-learning strategies that leverage time series characteristics to predict the performance of forecasting models, demonstrating that model accuracy often correlates with data properties. Along this line, FFORMPP (Talagala et al., 2019) and AutoForecast (Abdallah et al., 2022a) train meta-estimators - Bayesian and mixed architecture, respectively - on feature-performance pairs to identify the best model from predefined pool. Instead of feature-based regression, SeqFusion (Huang et al., 2025) embeds both time series and candidate models into shared representation space, allowing selection via similarity search. However, its effectiveness heavily depends on encoder quality (Zhang et al., 2023; Meng et al., 2023), which is difficult to guarantee for unseen models or data. More recently, Wei et al. (2025) have probed LLMs for model selection by encoding the model and data information in prompts and relying on LLM reasoning. Although promising, such approaches remain unreliable due to their opacity. In general, despite progress, generalizable model selection, scalable to unseen models and datasets, remains an open challenge. In particular, with the rapid proliferation of TSFMs, model selection method for TSFMs is still unexplored."
        },
        {
            "title": "3 METHODOLOGY",
            "content": "Problem setup In model selection, we consider set of candidate models {ϕi}M i=1, and target dataset D. Each model has ground truth transferred performance Pi, obtained by fine-tuning ϕi on the dataset D, and evaluating it using predefined metric, e.g., mean absolute scaled error (MASE), scale-independent measure (Talagala et al., 2019). transferability estimation method aims to produce score Si for each model ϕi without fine-tuning on dataset D. The scores {Si}M i=1 should correlate well with true performance {Pi}M i=1, enabling the selection of the best-performing models based on these scores. As shown in Figure 2, TIMETIC casts transferability estimation as an in-context characteristicsto-performance prediction task. At its core, TIMETIC builds unified tabular representation that integrates both the data characteristics and the model characteristics. Specifically, time series characterization encodes datasets into data characteristic table through feature engineering, while model characterization represents TSFMs as model characteristic table using entropy profiles (detailed in Sections 3.1 and 3.2). Based on these representations, in-context transferability estimation (Section 3.3) proceeds in two stages. In the offline stage, pairs of ground-truth characteristics performance are collected by fine-tuning to construct an in-context table. In the online stage, this table serves as context for prompting tabular foundation model (TabPFN Hollmann et al. (2025) in our case) to learn the mapping between characteristics and performance, allowing accurate estimation of the fine-tuned performance of target model on new dataset."
        },
        {
            "title": "Preprint",
            "content": "Figure 2: TIMETIC formulates transferability estimation as an in-context characteristics-toperformance prediction task. Dataset characteristics are encoded as data characteristic table through feature extraction and selection, while models are represented as model characteristic table using entropy profiles. TIMETIC then operates in two stages: in the offline stage, an in-context table (Xcontext, ycontext) is constructed from characteristicperformance pairs obtained via fine-tuning; in the online stage, this table prompts tabular foundation model to learn the mapping between characteristics and performance, enabling estimation of target models fine-tuned performance ytarget given model-data-characteristics table Xtarget in target dataset. The final transferability score is obtained by averaging the estimated performance across samples."
        },
        {
            "title": "3.1 TIME SERIES CHARACTERIZATION",
            "content": "Feature extraction Time series exhibit diverse statistical characteristics that capture their temporal dynamics. For given dataset D, we begin by sampling time windows {ωi}n i=1 according to the historical and prediction lengths specified by the forecasting task. For each time window, we extract statistical features as Fulcher (2017); Talagala et al. (2019), using two standard libraries: tsfresh (Christ et al., 2018) and tsfeatures (Henderson & Fulcher, 2022). The tools can efficiently generate over 700 features that capture diverse properties of time series, including seasonality, stationarity, dependency, complexity, etc. However, these features are highly redundant, which can lead to the curse of dimensionality (Altman & Krzywinski, 2018) and adversely affect characteristic-to-performance regression. Feature selection We perform feature selection guided by the principles of information richness and non-redundancy. To ensure information richness, we select features that minimize the epistemic uncertainty, that is, the uncertainty arising from the insufficient observation of the full state of the system. Given some characteristics-performance pairs = (xi, yi)i>0, where denotes the time series features and the corresponding transferred model performance, we estimate epistemic uncertainty using TotalVariance (T ) as proxy: TotalVarianceϕ(T ) ="
        },
        {
            "title": "1\nK",
            "content": "K (cid:88) k=1 Var(yx Xk) (1) where X1, . . . , XK denote the equivalence classes partitioning, i.e., x, Xk if and only if = (Akhauri et al., 2025). The variance is then empirically computed over the set of all y-values corresponding to inputs within Xk. Intuitively, TotalVariance reflects the distinguishability of features: smaller value indicates that the feature provides greater discriminative power to predict y. Thus,"
        },
        {
            "title": "Preprint",
            "content": "Figure 3: Left: TotalVariance significantly declines as the number of features increases, whereas the information content, quantified as the ratio between the joint entropy of feature subset and that of the full 30-feature set, approaches sufficiency; Right: The upper and lower panels show entropy profiles of various TSFMs on the Kdd cup and Solar datasets. Differences in profile patterns can distinguish model architecture and size: encoderdecoder models (ChronosT5, ChronosBolt) display two-peak pattern; decoder-only models (TimeMoE, TimesFM) exhibit higher magnitudes than encoder-only models (Moirai); larger hidden dimensionality is associated with higher entropy. features with lower TotalVariance are more informative for regression. (See Appendix for detailed analysis and derivation). In practice, we begin with an empty feature set and iteratively apply greedy search strategy, adding the feature that minimizes TotalVariance to the set at each step, until the reduction in TotalVariance falls below 0.001. To avoid redundancy, we evaluate the feature set and retain compact subset that maintains the richness of the information. As shown in Figure 3 (left), the information content of 20 features is comparable to that of the entire 30-feature set. Consequently, we adopt these 20 features with minimal TotalVariance as the final representation for each time series. For given dataset D, this yields data characteristic table Xdata Rn20, where denotes the number of windows sampled and each row corresponds to the 20-dimensional feature representation of time window."
        },
        {
            "title": "3.2 MODEL CHARACTERIZATION",
            "content": "Existing approaches to characterize model, such as assigning classification labels (Talagala et al., 2019) or learning model-specific embeddings (Zhang et al., 2023), often struggle to generalize to unseen models, thereby limiting their utility for practical transferability estimation. Inspired by interpretability studies showing that forecast performance correlates with internal representational dimensionality (Kaufman & Azencot, 2024) and that the entropy dynamics across layers reflects key architectural choices (Gabrie et al., 2018; Voita et al., 2019; Ali et al., 2025), we introduce characterization method based on the trajectory of evolution of the entropy, termed the entropy profile. The central premise is that activation functions, operators, parameterization, and hidden dimensions jointly shape value distributions, which in turn determine the magnitude of information entropy. Moreover, entropy can be computed across models without architectural constraints and relies solely on inference statistics, thus entropy profile offers simple and effective foundation for distinguishing diverse models, without exhaustively accounting for all potential influencing factors. Entropy profile More formally, given time series represented by tokens, let ti = {ti denote the token embeddings after model layer i. The entropy profile is defined as follows: 1, ..., ti } = (cid:77) i= H(ti), (2) where is the total number of model layers, is the continuous entropy estimator (Kraskov et al.), and (cid:76) denotes concatenation, resulting in RN . For given dataset with sampled time windows {ωi}n i=1, entropy profiles are computed across windows using at most 10, 000 tokens per layer to compute the information entropy while mitigating computational overhead. To ensure consistent and comparable tabular representation across models with varying depths, we subsample each entropy profile to fixed length of six, corresponding to the minimum layer count among"
        },
        {
            "title": "Preprint",
            "content": "the models considered. Consequently, each model is represented by model characteristic table Xmodel Rn6 for the given dataset. Entropy profile of TSFMs Figure 3 (right) presents entropy profiles of various TSFMs on the Kdd cup and Solar datasets. Each model family exhibits unique profile, with similarities and differences that effectively distinguish models. Within family, profiles remain consistent across datasets and model sizes, while larger hidden dimensionality is generally associated with higher entropy. Across different families, encoderdecoder architectures (ChronosT5 and ChronosBolt Ansari et al. (2024)) display distinct entropy drop at the encoderdecoder interface, yielding two-peak patIn contrast, encoder-only models (Moirai Woo et al. (2024)) exhibit lower entropy levels tern. and slower growth across layers compared to decoder-only models (TimeMoE Shi et al. (2025) and TimesFM Das et al. (2023)), phenomenon attributable to bidirectional attention producing smoother representations. 3.3 IN-CONTEXT TRANSFERABILITY ESTIMATION We reformulate transferability estimation as an in-context characteristics-to-performance prediction task. Specifically, given the observed fine-tuning processes of TSFM ϕi on collection of source datasets Dsrc, the goal is to predict the finetuned performance of the model on downstream target dataset Dtgt. To this end, TIMETIC performs in-context transferability estimation in two stages: Offline Context Table Construction and Online Target Table Inference, which are detailed as follows: Offline context table construction For each observed finetuning process involving TSFM ϕi and source datasets Dsrc, we construct representation encoding both data and model characteristics, following the procedures described in Section 3.1 and Section 3.2. This yields datamodel characteristic table Xcontext Rn26, where denotes the number of time windows sampled from the source datasets, and 26 corresponds to the concatenation of the data characteristics 20 and the characteristics of the model 6. In addition, both the zero-shot and the fine-tuned performance in each time window are appended to the table. The resulting context table is given by (Xcontext, ycontext) Rn28, where ycontext Rn1 denotes fine-tuned performance. For the cold-start scenario, that is, when no fine-tuned models are available, we can perform fine-tuning on small number of datasets and encode the results into the context table. This table then serves as persistent reference to support performance prediction on previously unseen datasets. Importantly, context construction requires only limited offline finetuning on few datasets, thereby decoupling the one-time finetuning cost from the potentially unbounded number of future target scenarios. Online target table inference Given target dataset Dtgt and TSFM ϕi whose transferability is to be estimated, we sample time windows and construct the target datamodel characteristic table Xtarget Rm26. In the offline stage, context table (Xcontext, ycontext) is constructed to serve as structured memory, encoding the mapping between data-model characteristics, zeroshot performance, and fine-tuned performance. By providing both the context table and the target table to tabular foundation model Φ, predictions of transferred performance on the target dataset can be conditioned on the patterns learned from the context, without requiring gradient updates or retraining. Formally, the estimated transferred performance ytarget Rm1 is obtained as ytarget = Φ(cid:0)Xtarget (cid:12) (cid:12) (Xcontext, ycontext)(cid:1). (3) The final transferability score Si of model ϕi in dataset Dtgt is given by the mean of ytarget in the sampled time windows. Tabular foundation model In TIMETIC, we employ TabPFN (Hollmann et al., 2025) as the tabular foundation model owing to its strong in-context learning capabilities. TabPFN is Transformer encoder pre-trained on large collection of diverse tabular datasets, which enables it to generalize to unseen regression tasks without finetuning. Similar to how large language models leverage incontext examples to perform new tasks, TabPFN can infer task-specific patterns by conditioning on small number of examples from the target regression problem, and subsequently provide accurate predictions on unseen samples of the same task. This property makes TabPFN particularly wellsuited for in-context transferability estimation, as it obviates the need for model retraining and allows flexible organization of context to adapt to diverse transferability estimation scenarios."
        },
        {
            "title": "4 EXPERIMENTS",
            "content": "In Section 4.1, we introduce benchmark for transferability estimation in TSFMs. Section 4.2 demonstrates the superiority of TIMETIC over existing methods, while Section 4.3 evaluates its generalization in two challenging scenarios: estimating unknown models in seen data, and unknown models on unseen data. Finally, Section 4.4 presents an ablation study on time series characterization, model characterization, and context table size to assess their impact."
        },
        {
            "title": "4.1 TRANSFERABILITY ESTIMATION BENCHMARK",
            "content": "To evaluate transferability estimation methods, we construct benchmark based on the following five aspects (see Appendix for details on its construction). Target datasets We use 10 datasets from 4 domains (Nature, Energy, Web and Transport), spanning 5 sampling frequencies (seconds to hours) and 5 key characteristics (trend, seasonality, transition, stationarity and shifting), to ensure the datasets cover diverse temporal patterns. Model zoo 10 models from 5 representative TSFM families (Chronos, Chronos-Bolt, TimesFM, Moirai, Time-MoE), spanning 10M to 500M parameters, are included to cover various architectures and parameter scales. Ground truth All TSFMs are fine-tuned on each dataset using unified hyperparameters to establish ground-truth rankings. For each dataset, the last 10% is reserved for testing; the remaining 90% is used for fine-tuning and validation. The rankings are derived through MASE on the test set. Transferability estimation baselines We compare three categories: (i) Metric-based: LogME (You et al., 2021), LFC (Tran et al., 2019), and RegScore (Nguyen et al., 2023); (ii) Meta-learningbased: linear meta-estimator adapted from AutoForecast (Abdallah et al., 2022b); (iii) Zero-shot performance: using the models zero-shot performance as the most straightforward proxy. Evaluation protocol Methods are evaluated across short-, medium-, and long-term forecasting tasks under standard and few-shot sampling regimes. The effectiveness is primarily quantified using weighted Kendalls τw between estimated scores {Si}M i=1 and actual finetuned performance {Pi}M i=1, with higher τw indicating more reliable estimate (You et al., 2021; Kazemi et al., 2025)."
        },
        {
            "title": "4.2 PERFORMANCE EVALUATION",
            "content": "Table 1: Effectiveness of transferability estimation methods across short-, medium-, and longhorizon forecasting tasks under both standard and few-shot sampling regimes. Reported values are Weighted Kendalls τw , averaged across 10 datasets."
        },
        {
            "title": "Method",
            "content": "LFC LogME RegScore Meta learner Zero-shot TIMETIC"
        },
        {
            "title": "Standard",
            "content": "Few-shot short medium long short medium long 0.136 0.101 0.114 0.106 0.102 0.053 0.138 0.138 0.160 0.119 0.176 0.204 0.187 0.272 0.034 0.040 0.045 0.320 0.262 0.323 0.383 0.018 0.042 0.089 0.279 0.329 0.319 0.429 0.024 0.064 0.131 0. 0.053 0.157 0.305 0.060 Standard evaluation We evaluate transferability estimation methods on three forecasting tasks using all time windows from the training set of target datasets. For each models transferability estimation on target dataset, TIMETIC leverages context table that encodes the models transfer processes on other datasets. As shown in Table 1 (left), TIMETIC consistently outperforms all baselines with higher rank correlations. Although zero-shot performance occasionally aligns with fine-tuned results, it is generally unreliable due to shifts between pretraining and fine-tuning. We also observe that the gap between zero-shot and TIMETIC narrows in long-horizon forecasting, indicating greater challenges in transferability estimation for long-horizon forecasting. Metrics such as RegScore, LogME, and LFC underperform because their assumptions neglect autoregressive error accumulation, while meta-learnerbased methods suffer from overfitting and poor generalization."
        },
        {
            "title": "Preprint",
            "content": "Figure 4: Transferability scores versus actual transferred performance. Each point is target models transferability score against its actual transferred performance. More accurate transferability estimation methods show stronger linear and Spearman rank correlations with fine-tuned performance. Figure 4 illustrates the transferability scores versus the fine-tuned performance under the mediumhorizon task and provides the Spearman rank correlation. Compared to Kendalls τw, Spearmans rank correlation emphasizes monotonic consistency; here, TIMETIC achieves the strongest linear alignment with fine-tuned performance and the highest Spearman coefficient of 0.6. In Appendix C, we provide per dataset results and Spearman correlation analyzes. Few-shot evaluation. Few-shot evaluation poses greater challenge, as only 100 time windows from the training set of the target datasets are used to estimate transferability. With such limited windows, it becomes difficult to fully capture the underlying distribution of dataset. As shown in Table 1 (right), TIMETIC maintains strong performance with only minor fluctuations in Kendalls τw, consistently outperforming all baselines and demonstrating robustness under few-shot settings."
        },
        {
            "title": "4.3 GENERALIZATION EVALUATION",
            "content": "TIMETIC is applicable to wide range of practical model selection scenarios. It can estimate not only the performance of known model on new dataset, but also that of new model on datasets where other models have already been evaluated. In addition, it can handle the more challenging case of predicting the performance of new model on entirely unseen datasets. To simulate these three scenarios, we adopt different constructions of the context table: (i) known target models on unseen datasets - the transfer processes of the target model on the known datasets are encoded in the context table; (ii) unknown target models on seen datasets - other models in the model zoo for the dataset are encoded in the context table; (iii) unknown target models on unseen datasets - other model transfer processes in other datasets are encoded in the context table. As shown in Figure 5, TIMETIC achieves consistently higher rank correlations than relying solely on zero-shot performance in all scenarios. These results highlight the practicality and generalizability of TIMETIC, as it requires only limited number of observed examples as context to estimate the performance of the unknown model on unseen datasets. 8 Figure 5: Weighted Kendalls τw of TIMETIC across 10 datasets for different transferability estimation scenarios: (i) known target models on unseen datasets, (ii) unknown target models on seen datasets, and (iii) unknown target models on unseen datasets."
        },
        {
            "title": "Preprint",
            "content": "Figure 6: Left: Effect of the number of time series features on transferability estimation performance; Middle: Effect of entropy profile on transferability estimation across three scenarios: (i) known target models on unseen datasets, (ii) unknown target models on seen datasets, and (iii) unknown target models on unseen datasets. Right: Effect of context table size on transferability estimation performance."
        },
        {
            "title": "4.4 ABLATION STUDY",
            "content": "Time series feature number We examine how the number of statistical features impacts TIMETIC. As shown in Figure 6 (left), we incrementally select the first features that minimize TotalVariance. The results show consistent improvement as more features are added, since richer representations enhance the discriminative power of the feature space and reduce epistemic uncertainty. However, beyond 20 features, the performance drops slightly, suggesting that additional features introduce redundancy and noise. This observation is consistent with Figure 3 (left), which shows that the information captured by 20 features is nearly equivalent to that of 30 features. Model characterization method Figure 6 (middle) evaluates the contribution of the entropy profile to transferability estimation by comparing TIMETIC with and without it in three scenarios. When the target model is known but the dataset is unseen, the entropy profile yields about 0.1 improvement, indicating that entropy patterns provide useful signals for predicting fine-tuned performance. In more challenging cases, where models are not seen, or both models and datasets are not seen, the entropy profile plays more critical role, increasing the generalization of TIMETIC by approximately 0.2 and 0.15, respectively. This improvement comes from its ability to capture similarities between models of different architectures or scales, enabling TIMETIC to infer the transferability of unseen models from the transfer processes of known ones. Context table size Another key factor influencing TIMETICs performance is the size of the context table. Since TIMETIC frames transferability estimation as an in-context characteristic-toperformance prediction task, the size of the context table determines how much prior knowledge can be used for the target prediction. To examine this, we vary the number of time windows most related to the target dataset when constructing the context table and evaluate the impact. As shown in Figure 6 (right), increasing the size of the context from 1,000 to 6,000 substantially improves performance, indicating that richer context information improves TIMETIC. And TIMETIC remains robust even with only 100 time windows. This exhibits TIMETICs scalability with more known transfer processes and its reliable performance under limited context."
        },
        {
            "title": "5 CONCLUSION",
            "content": "In this paper, we propose TIMETIC, novel framework for estimating the transferability of time series foundation models via in-context learning. By encoding model characteristics and data properties into structured context table, TIMETIC effectively leverages the in-context learning capability of tabular foundation models to provide flexible and accurate performance estimation on unseen datasets. Furthermore, the proposed entropy-profile-based model characterization enhances scalability and generalization, allowing the framework to adapt across diverse transferability estimation scenarios. Comprehensive empirical evaluations demonstrate that TIMETIC consistently surpasses existing methods in model ranking, yielding substantial improvements in correlation with fine-tuned performance. These results establish TIMETIC as robust and versatile tool for navigating the rapidly expanding landscape of time series foundation models."
        },
        {
            "title": "REFERENCES",
            "content": "Mustafa Abdallah, Ryan A. Rossi, Kanak Mahadik, Sungchul Kim, Handong Zhao, and Saurabh Bagchi. Autoforecast: Automatic time-series forecasting model selection. Proceedings of the 31st ACM International Conference on Information & Knowledge Management, 2022a. URL https://api.semanticscholar.org/CorpusID:252587492. Mustafa Abdallah, Ryan A. Rossi, Kanak Mahadik, Sungchul Kim, Handong Zhao, and Saurabh Bagchi. Autoforecast: Automatic time-series forecasting model selection. In Mohammad Al Hasan and Li Xiong (eds.), Proceedings of the 31st ACM International Conference on Information & Knowledge Management, Atlanta, GA, USA, October 17-21, 2022, pp. 514. ACM, 2022b. doi: 10.1145/3511808.3557241. URL https://doi.org/10.1145/3511808.3557241. Yash Akhauri, Bryan Lewandowski, Cheng-Hsi Lin, Adrian N. Reyes, Grant C. Forbes, Arissa Wongpanich, Bangding Yang, Mohamed S. Abdelfattah, Sagi Perel, and Xingyou Song. Performance prediction for large systems via text-to-text regression. ArXiv, abs/2506.21718, 2025. URL https://api.semanticscholar.org/CorpusID:280012288. Taha Aksu, Gerald Woo, Juncheng Liu, Xu Liu, Chenghao Liu, Silvio Savarese, Caiming Xiong, and Doyen Sahoo. Gift-eval: benchmark for general time series forecasting model evaluation. CoRR, abs/2410.10393, 2024. doi: 10.48550/ARXIV.2410.10393. URL https://doi.org/ 10.48550/arXiv.2410.10393. Riccardo Ali, Francesco Caso, Christopher Irwin, and Pietro Lio. Entropy-lens: The information signature of transformer computations. ArXiv, abs/2502.16570, 2025. URL https://api. semanticscholar.org/CorpusID:276575108. Naomi Altman and Martin Krzywinski. The curse(s) of dimensionality. Nature Methods, 15:399 400, 2018. URL https://api.semanticscholar.org/CorpusID:44115671. Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin Shen, Oleksandr Shchur, Syama Sundar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, Jasper Zschiegner, Danielle C. Maddix, Michael W. Mahoney, Kari Torkkola, Andrew Gordon Wilson, Michael Bohlke-Schneider, and Yuyang Wang. Chronos: Learning the language of time series. ArXiv, abs/2403.07815, 2024. URL https://api.semanticscholar.org/ CorpusID:268363551. Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir, and Leonidas J. Guibas. An information-theoretic approach to transferability in task transfer learning. In 2019 IEEE International Conference on Image Processing, ICIP 2019, Taipei, Taiwan, September 2225, 2019, pp. 23092313. IEEE, 2019. doi: 10.1109/ICIP.2019.8803726. URL https://doi. org/10.1109/ICIP.2019.8803726. Lorenzo Brigato, Rafael Morand, Knut Strømmen, Maria Panagiotou, Markus Schmidt, and Stavroula Mougiakakou. Position: There are no champions in long-term time series forecasting, 2025. URL https://arxiv.org/abs/2502.14045. Maximilian Christ, Nils Braun, Julius Neuffer, and A. Kempa-Liehr. Time series feature extraction on basis of scalable hypothesis tests (tsfresh - python package). Neurocomputing, 307:7277, 2018. URL https://api.semanticscholar.org/CorpusID:49343335. Abhimanyu Das, Weihao Kong, Rajat Sen, and Yichen Zhou. decoder-only foundation model for time-series forecasting. ArXiv, abs/2310.10688, 2023. URL https://api. semanticscholar.org/CorpusID:264172792. Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li, Luca Zancato, Charless C. Fowlkes, Rahul Bhotika, Stefano Soatto, and Pietro Perona. linearized framework and new benchmark for model selection for fine-tuning. ArXiv, abs/2102.00084, 2021. URL https: //api.semanticscholar.org/CorpusID:231740997. Yuhe Ding, Bo Jiang, Aijing Yu, Aihua Zheng, and Jian Liang. Which model to transfer? survey on transferability estimation. ArXiv, abs/2402.15231, 2024. URL https://api. semanticscholar.org/CorpusID:267897613."
        },
        {
            "title": "Preprint",
            "content": "Xinghong Fu, Masanori Hirano, and Kentaro Imajo. Financial fine-tuning large time series model, 2024. URL https://arxiv.org/abs/2412.09880. Ben D. Fulcher. Feature-based time-series analysis. ArXiv, abs/1709.08055, 2017. URL https: //api.semanticscholar.org/CorpusID:13178131. Marylou Gabrie, Andre Manoel, Clement Luneau, Jean Barbier, Nicolas Macris, Florent Krzakala, and Lenka Zdeborova. Entropy and mutual information in models of deep neural networks. Journal of Statistical Mechanics: Theory and Experiment, 2019, 2018. URL https: //api.semanticscholar.org/CorpusID:43925762. Mohsen Gholami, Mohammad Akbari, Xinglu Wang, Behnam Kamranian, and Yong Zhang. Etran: In IEEE/CVF International Conference on Computer Energy-based transferability estimation. Vision, ICCV 2023, Paris, France, October 1-6, 2023, pp. 1856718576. IEEE, 2023. doi: 10. 1109/ICCV51070.2023.01706. URL https://doi.org/10.1109/ICCV51070.2023. 01706. Mononito Goswami, Konrad Szafer, Arjun Choudhry, Yifu Cai, Shuo Li, and Artur Dubrawski. Moment: family of open time-series foundation models. ArXiv, abs/2402.03885, 2024. URL https://api.semanticscholar.org/CorpusID:267500205. Divij Gupta, Anubhav Bhatti, and Surajsinh Parmar. Beyond lora: Exploring efficient fine-tuning techniques for time series foundational models, 2024. URL https://arxiv.org/abs/ 2409.11302. Trent Henderson and Ben D. Fulcher. Feature-based time-series analysis in using the theft package. ArXiv, abs/2208.06146, 2022. URL https://api.semanticscholar.org/ CorpusID:251554656. Noah Hollmann, Samuel G. Muller, Lennart Purucker, Arjun Krishnakumar, Max Korfer, Shi Bin Hoo, Robin Tibor Schirrmeister, and Frank Hutter. Accurate predictions on small data with tabular foundation model. Nature, 637:319 326, 2025. URL https://api. semanticscholar.org/CorpusID:275420209. Ting-Ji Huang, Xu-Yang Chen, and Han-Jia Ye. Seqfusion: Sequential fusion of pre-trained models for zero-shot time-series forecasting. ArXiv, abs/2503.02836, 2025. URL https://api. semanticscholar.org/CorpusID:276775468. Ilya Kaufman and Omri Azencot. Analyzing deep transformer models for time series forecasting via manifold learning. Trans. Mach. Learn. Res., 2024, 2024. URL https://api. semanticscholar.org/CorpusID:273403876. Alireza Kazemi, Helia Rezvani, and Mahsa Baktash. Benchmarking transferability: framework for fair and robust evaluation. ArXiv, abs/2504.20121, 2025. URL https://api. semanticscholar.org/CorpusID:278171171. Alexander Kraskov, Harald Stogbauer, and Peter Grassberger. information. doi: 10.1103/PhysRevE.69.066138. URL https://link.aps.org/doi/10.1103/ PhysRevE.69.066138."
        },
        {
            "title": "Estimating mutual",
            "content": "Christiane Lemke and Bogdan Gabrys. Meta-learning for time series forecasting and forecast combination. Neurocomputing, 73:20062016, 2010. URL https://api.semanticscholar. org/CorpusID:43923341. Yandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang Wang, and In IEEE Conference on Computer ViBoqing Gong. Ranking neural checkpoints. June 19-25, 2021, pp. 2663 sion and Pattern Recognition, CVPR 2021, 2673. Computer Vision Foundation / 10.1109/CVPR46437.2021. doi: 00269. URL https://openaccess.thecvf.com/content/CVPR2021/html/Li_ Ranking_Neural_Checkpoints_CVPR_2021_paper.html. IEEE, 2021. virtual, Yuze Li and Wei Zhu. Trace: Time series parameter efficient fine-tuning, 2025. URL https: //arxiv.org/abs/2503.16991."
        },
        {
            "title": "Preprint",
            "content": "Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, and Qingsong Wen. Foundation models for time series analysis: tutorial and survey. Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2024. URL https://api.semanticscholar.org/CorpusID:268667522. Yuxuan Liang, Haomin Wen, Yutong Xia, Ming Jin, Bin Yang, Flora Salim, Qingsong Wen, Shirui Pan, and Gao Cong. Foundation models for spatio-temporal data science: tutorial and survey, 2025. URL https://arxiv.org/abs/2503.13502. Haowei Lin, Baizhou Huang, Haotian Ye, Qinyu Chen, Zihao Wang, Sujian Li, Jianzhu Ma, Xiaojun Wan, James Zou, and Yitao Liang. Selecting large language model to fine-tune via rectified scaling law. ArXiv, abs/2402.02314, 2024. URL https://api.semanticscholar.org/ CorpusID:267411718. Yong Liu, Haoran Zhang, Chenyu Li, Xiangdong Huang, Jianmin Wang, and Mingsheng Long. In International Timer: Generative pre-trained transformers are large time series models. Conference on Machine Learning, 2024. URL https://api.semanticscholar.org/ CorpusID:267412273. Fanqing Meng, Wenqi Shao, Zhanglin Peng, Chong Jiang, Kaipeng Zhang, Y. Qiao, and Ping Luo. Foundation model is efficient multimodal multitask model selector. ArXiv, abs/2308.06262, 2023. URL https://api.semanticscholar.org/CorpusID:260866006. Cuong N. Nguyen, Phong Tran, Lam Si Tung Ho, Vu C. Dinh, Anh T. Tran, Tal Hassner, and Cuong V. Nguyen. Simple transferability estimation for regression tasks. In Robin J. Evans and Ilya Shpitser (eds.), Uncertainty in Artificial Intelligence, UAI 2023, July 31 - 4 August 2023, Pittsburgh, PA, USA, volume 216 of Proceedings of Machine Learning Research, pp. 15101521. PMLR, 2023. URL https://proceedings.mlr.press/v216/nguyen23a.html. Cuong V. Nguyen, Tal Hassner, Matthias W. Seeger, and Cedric Archambeau. LEEP: new In Proceedings of the 37th Inmeasure to evaluate transferability of learned representations. ternational Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pp. 72947305. PMLR, 2020. URL http://proceedings.mlr.press/v119/nguyen20b.html. Patrik Okanovic, Andreas Kirsch, Jannes Kasper, Torsten Hoefler, Andreas Krause, and Nezihe Merve Gurel. All models are wrong, some are useful: Model selection with limited labels. ArXiv, abs/2410.13609, 2024. URL https://api.semanticscholar.org/ CorpusID:273403569. Ekrem Ozturk, Fabio Ferreira, Hadi S. Jomaa, Lars Schmidt-Thieme, Josif Grabocka, and Frank Hutter. Zero-shot automl with pretrained models. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pp. 1713817155. PMLR, 2022. URL https: //proceedings.mlr.press/v162/ozturk22a.html. Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with unified text-to-text transformer. J. Mach. Learn. Res., 21:140:1140:67, 2019. URL https://api. semanticscholar.org/CorpusID:204838007. Kashif Rasul, Arjun Ashok, Andrew Robert Williams, Arian Khorasani, George Adamopoulos, Rishika Bhagwatkar, Marin Bilos, Hena Ghonia, Nadhir Vincent Hassen, Anderson Schneider, Sahil Garg, Alexandre Drouin, Nicolas Chapados, Yuriy Nevmyvaka, and Irina Rish. Lag-llama: Towards foundation models for time series forecasting. ArXiv, abs/2310.08278, 2023. URL https://api.semanticscholar.org/CorpusID:269766909. Jake Robertson, Arik Reuter, Siyuan Guo, Noah Hollmann, Frank Hutter, and Bernhard Scholkopf. Do-pfn: In-context learning for causal effect estimation. ArXiv, abs/2506.06039, 2025. URL https://api.semanticscholar.org/CorpusID:279243613."
        },
        {
            "title": "Preprint",
            "content": "Xiaoming Shi, Shiyu Wang, Yuqi Nie, Dianqi Li, Zhou Ye, Qingsong Wen, and Ming Jin. Time-moe: Billion-scale time series foundation models with mixture of experts. In International Conference on Learning Representations, 2025. Thiyanga S. Talagala, Feng Li, and Yanfei Kang. Fformpp: Feature-based forecast model perInternational Journal of Forecasting, 2019. URL https://api. formance prediction. semanticscholar.org/CorpusID:201698109. Anh Tuan Tran, Cuong V. Nguyen, and Tal Hassner. Transferability and hardness of supervised In 2019 IEEE/CVF International Conference on Computer Vision, ICCV classification tasks. 2019, Seoul, Korea (South), October 27 - November 2, 2019, pp. 13951405. IEEE, 2019. doi: 10.1109/ICCV.2019.00148. URL https://doi.org/10.1109/ICCV.2019.00148. Elena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations in the transformer: study with machine translation and language modeling objectives. ArXiv, URL https://api.semanticscholar.org/CorpusID: abs/1909.01380, 2019. 202541078. Wang Wei, Tiankai Yang, Hongjie Chen, Ryan A. Rossi, Yue Zhao, Franck Dernoncourt, and Hoda Eldardiry. Efficient model selection for time series forecasting via llms. ArXiv, abs/2504.02119, 2025. URL https://api.semanticscholar.org/CorpusID:277510486. Gerald Woo, Chenghao Liu, Akshat Kumar, Caiming Xiong, Silvio Savarese, and Doyen Sahoo. Unified training of universal time series forecasting transformers. ArXiv, abs/2402.02592, 2024. URL https://api.semanticscholar.org/CorpusID:267411817. Kaichao You, Yong Liu, Jianmin Wang, and Mingsheng Long. Logme: Practical assessment of pre-trained models for transfer learning. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pp. 1213312143. PMLR, 2021. URL http://proceedings.mlr.press/v139/you21b.html. Yi-Kai Zhang, Ting Huang, Yao-Xiang Ding, De chuan Zhan, and Han-Jia Ye. Model spider: Learning to rank pre-trained models efficiently. ArXiv, abs/2306.03900, 2023. URL https: //api.semanticscholar.org/CorpusID:259088702."
        },
        {
            "title": "TABLE OF CONTENTS",
            "content": "A Implementations Details A.1 Feature Selection . . A.2 TabPFN . . . . . . . Benchmark Construction . . B.1 Target Datasets . . . B.2 Model Zoo . . . B.3 Ground Turth . . B.4 Baselines . . . B.5 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "C Additional Experimental Results",
            "content": "C.1 Performance Evaluation using Weighted Kendall Tau . . . . . . . . . . . . . . . . C.2 Performance Evaluation using Spearman Correlation . . . . . . . . . . . . . . . ."
        },
        {
            "title": "A IMPLEMENTATIONS DETAILS",
            "content": "A.1 FEATURE SELECTION 14 14 14 15 15 16 18 18 19 22 22 22 22 In this section, we introduce two specific implementations for partitioning equivalence classes in equation 1, along with greedy search strategy for feature selection, as supplement to Section 3.1. Partitioning of equivalence classes Given characteristicperformance pairs = (xi, yi)i>0, directly partitioning equivalence classes Xk based on high-dimensional features is intractable, as fine-grained clustering becomes unstable in such spaces. To address this, we adopt an approximation procedure combining dimensionality reduction and clustering. Specifically, we first standardize to zero mean and unit variance, then apply Principal Component Analysis (PCA) and retain the first two components to obtain reduced feature space. In this space, we cluster the samples into groups (K = 100 in our experiments), with each cluster index serving as proxy for the equivalence class Xk. Finally, TotalVariance is computed as the average variance across all non-empty clusters, following Equation 1. Greedy search strategy We describe the greedy feature selection algorithm in more detail in Algorithm 1. The algorithm incrementally constructs the feature set by minimizing TotalVariance at each step. This procedure guarantees that each iteration adds the feature that most reduces epistemic uncertainty, until the marginal improvement becomes negligible. A.2 TABPFN In TIMETIC, we adopt TabPFN (Hollmann et al., 2025), tabular foundation model pretrained on large collection of regression tasks, as the in-context learner. Both its checkpoint and source code are publicly available. In this section, we provide additional details on TabPFN to help us understand its role within our framework. Model architecture TabPFN treats each cell in table as separate position within sequence. Given context table and target table for prediction, all cell values are first normalized using the column-wise mean and standard deviation computed from the context table. These normalized values are then transformed into embeddings through linear projection layers. As illustrated in Figure A, the backbone of TabPFN employs two types of attention mechanisms within each Transformer block: attention across features (columns) and attention across samples (rows), each operating independently along its respective dimension. Finally, TabPFN addresses tabular regression by predicting probability distribution over possible target values rather than single point estimate."
        },
        {
            "title": "Preprint",
            "content": "Figure A: The TabPFN-based instance of TIMETIC. We encode observed model behaviors into context table (shown in blue) and represents new data and models in target table (shown in red). Then we leverage the in-context learning capabilities of TabPFN to predict the fine-tuned performance on target tasks (denoted as blank cell). TabPFN is an adaptation of the standard Transformer encoder, designed for tabular data using two types of attention mechanisms: one across features and another across samples. Algorithm 1: Greedy Feature Selection Input: Feature matrix Rnd, target vector Rn, threshold ϵ Output: Selected feature set Fsel Fsel ; TVcurr inf; repeat best TV TVcurr, None; foreach / Fsel do Xsel = Fsel(X) (X); TVf TotalVariance(Xsel, y); if TVf < best TV then best TV TVf , ; if = None and TVcurr best TV ϵ then Fsel Fsel {f }; TVcurr best TV; until no improvement ϵ; Inference cost TabPFN is computationally efficient and can be executed on consumer-grade hardware in most scenarios. As reported by Hollmann et al. (2025), for table with 10,000 rows and 10 columns, TabPFN completes the inference in approximately 0.2 seconds. The computational complexity of the architecture scales quadratically with both the number of samples (n) and the number of features (m), i.e. O(n2 + m2), while the memory footprint scales linearly with the size of the table, O(n + m)."
        },
        {
            "title": "B BENCHMARK CONSTRUCTION",
            "content": "In this section, we describe the construction of our benchmark, which provides critical foundation for our experimental analysis. As illustrated in Figure B, the construction pipeline encompasses five key aspects: collection of target datasets and models, unified fine-tuning, selection of baselines, and evaluation protocol. Each of these aspects is elaborated in the following subsections. B.1 TARGET DATASETS As shown in Table A, our benchmark comprises 10 datasets from four distinct domains, spanning 5 sampling frequencies. These datasets exhibit 5 typical time series characteristicstrend, seasonality, transition, stationarity, and shiftingwith example cases illustrated in Figure C. Their diversity simulates real-world TSFM transfer scenarios, providing solid foundation for evaluating transferability estimation methods."
        },
        {
            "title": "Preprint",
            "content": "Figure B: Overview of the benchmark construction. To comprehensively evaluate transferability estimation methods for TSFMs, we construct pipeline ((cid:57)(cid:57)(cid:75)) to derive ground-truth transferred performance across 10 datasets, 10 models, and 3 forecasting horizons, under unified fine-tuning framework. In the evaluation stage (), we compare TIMETIC against three categories of estimation methods under both standard and few-shot sample regimes, measuring performance by the rank correlation between estimated transferability scores and ground truth. Table A: Benchmark dataset statistics and forecasting horizons. Dataset Domain Freq. #Series Avg Len Min Len Max Len #Obs Variates Short-term Med-term Long-term Len Win Len Win Len Win KDD Cup 2018 Nature Nature Jena Weather Energy ETT2 Energy Electricity Solar Energy BizITObs - L2C Web/CloudOps Bitbrains - rnd Web/CloudOps BizITObs - App Web/CloudOps SZ-Taxi Loop Seattle Transport Transport 10T 5T 5T 10S 15T 5T 270 1 1 370 137 1 500 1 156 323 10,898 52,704 17,420 35,064 8760 31,968 8,640 8,834 2,976 105,120 9,504 52,704 17,420 35,064 8760 31,968 8,640 8,834 2,976 105,120 10,920 52,704 17,420 35,064 8760 31,968 8,640 8,834 2,976 105, 2.94M 52,704 17,420 12.97M 1,200,120 31,968 4.32M 8,834 464,256 33.9M 1 21 7 1 1 7 2 2 1 1 64 64 64 64 64 64 64 64 64 64 20 20 20 20 19 20 18 15 7 20 256 256 256 256 256 256 256 256 256 256 2 11 4 8 2 7 2 2 1 512 512 512 512 512 512 512 512 512 512 2 8 3 5 8 5 2 1 1 15 Following the gift benchmark (Aksu et al., 2024), we define short-, mediumand long-term forecasting tasks to evaluate the transfer performance of TSFM, reflecting the varied forecasting requirements in transfer scenarios. The forecast horizons are set to 64, 256, and 512 time steps, with corresponding context lengths of 256, 1024, and 2048. For each dataset, 90% of the data is used for training and the remaining 10% for testing. During testing, time series are segmented into nonoverlapping windows of length equal to the sum of the context length and forecasting horizon. These settings, along with the number of test windows, are also summarized in Table A. B.2 MODEL ZOO Our benchmark includes model zoo comprising 10 TSFMs drawn from 5 representative model families, covering wide spectrum of architectural designs and parameter scalesfrom 8 million to 500 million parameters. Although all models are based on the Transformer architecture, their performance varies significantly due to differences in encoder-decoder configurations, tokenization schemes, dense versus sparse architectures, and the composition of their pretraining datasets. The characteristics of the models in our zoo are summarized in Table B, and brief introduction to each model family is provided below: Moirai (Woo et al., 2024) is an encoder-only Transformer that uses adaptive patch tokenization to accommodate time series with varying frequencies, along with flexible attention mechanism to support multivariate inputs. It also features patch-wise parameterized prediction head for distributional forecasting. In our experiments, we include Moirai-small (14M) and Moirai-base (91M) as candidate models. TimesFM (Das et al., 2023) is decoder-only Transformer tailored for time series forecasting. It extends the standard decoder-only architecture by adopting patch-based tokenization and detokenization strategies, allowing it to effectively handle time series inputs and generate forecasts. We include TimesFM-200M and TimesFM-500M in our candidate models."
        },
        {
            "title": "Preprint",
            "content": "Figure C: 10 datasets illustrating five typical time series characteristics. Table B: Time series foundation model zoo."
        },
        {
            "title": "Input Token Output Token",
            "content": "Moirai TimesFM Chronos Chronos-bolt Time-MoE Encoder-only Decoder-only Enc-Dec Enc-Dec Decoder-only 14M 91M 200M 500M 8M 20M 48M 205M 50M 200M 231B 100B 84B 84B 309B"
        },
        {
            "title": "Patch\nPatch\nPoint\nPatch\nPatch",
            "content": "Chronos (Ansari et al., 2024) is an LLM-based TSFM that repurposes the T5 encoder-decoder architecture for time series forecasting. Instead of using T5s original text-based tokenizer, Chronos applies value quantization and dequantization to convert the regression task into classification problem. It is pretrained on large-scale time series corpus comprising 84 billion time points. Chronos-tiny (8M) and Chronos-min (20M) are included in our candidate models."
        },
        {
            "title": "Preprint",
            "content": "Table C: Ground truth finetuned performance of various time series foundation models in short-term, medium-term, and long-term forecasting tasks. Dataset Chronostiny Chronosbase Chronos-boltbase Chronos-boltsmall Moirailarge Moiraismall Time-MoE50M Time-MoE200M TimesFM200M TimesFM500M Short-term forecasting tasks kdd cup 2018 with missing:H jena weather:10T ett2:H electricity:H solar:H bizitobs l2c:5T bitbrains rnd:5T bizitobs application SZ TAXI:15T LOOP SEATTLE:5T Medium-term forecasting tasks kdd cup 2018 with missing:H jena weather:10T ett2:H electricity:H solar:H bizitobs l2c:5T bitbrains rnd:5T bizitobs application SZ TAXI:15T LOOP SEATTLE:5T Long-term forecasting tasks kdd cup 2018 with missing:H jena weather:10T ett2:H electricity:H solar:H bizitobs l2c:5T bitbrains rnd:5T bizitobs application SZ TAXI:15T LOOP SEATTLE:5T 1.085 2.314 1.161 1.135 1.412 22.862 2.276 27.718 0.884 1.999 1.483 1.610 1.474 1.303 1.270 1.147 1.895 12.494 0.901 1.152 1.778 2.172 2.145 1.552 1.355 1.140 1.861 59.969 0.874 1. 0.997 1.752 1.194 0.945 1.322 24.728 2.155 32.653 0.877 1.862 1.240 1.258 1.219 1.130 0.968 1.125 1.742 9.412 0.914 0.857 1.291 1.387 2.043 1.314 0.916 1.127 1.545 10.745 0.932 0.919 0.763 1.557 1.036 0.941 1.367 26.104 2.053 28.002 0.828 1.798 0.706 0.977 1.021 1.040 1.153 1.222 1.419 1.765 0.816 0.890 0.850 1.202 1.010 1.132 1.031 0.783 1.161 2.274 0.810 0. 0.850 1.515 1.007 0.872 1.456 23.926 2.163 27.819 0.819 1.650 0.812 0.944 1.046 1.020 1.262 1.128 1.702 1.867 0.804 0.850 0.942 1.152 1.181 1.132 1.161 0.804 1.181 2.712 0.816 0.851 1.025 1.905 1.064 1.062 1.447 23.906 2.392 22.586 0.808 1.662 1.158 1.208 1.043 1.096 1.169 0.991 2.076 2.314 0.797 0.798 1.193 1.451 1.112 1.272 1.015 0.562 1.740 3.680 0.776 0. 1.004 1.523 1.090 1.203 1.493 22.882 2.884 36.356 0.843 1.669 1.103 0.998 1.059 1.222 1.118 1.003 2.818 8.932 0.817 0.753 1.137 1.163 1.171 1.347 1.109 0.966 2.181 9.136 0.787 0.785 0.916 1.422 1.085 0.938 1.332 26.300 2.059 22.889 0.807 1.568 1.164 1.180 1.186 1.297 0.767 1.688 3.501 2.750 0.827 1.175 1.395 1.749 2.436 3.696 0.843 0.992 1.590 5.120 0.817 1. 0.993 1.285 1.093 0.947 1.419 26.651 2.008 21.443 0.813 1.552 1.145 1.123 1.096 1.262 0.871 1.661 2.743 2.046 0.821 0.970 1.249 1.710 2.062 3.162 0.946 0.982 1.742 3.313 0.809 1.012 1.092 1.229 1.134 1.355 2.359 28.019 2.635 28.340 0.812 17.183 1.099 1.123 1.169 1.364 1.694 1.331 2.306 6.429 0.843 8.250 1.229 1.271 1.179 1.683 1.848 1.246 2.104 8.389 0.834 10. 0.972 1.158 1.084 1.206 90.266 23.775 14.073 28.237 0.818 36.487 1.034 0.831 1.164 1.285 243.011 1.184 19.307 7.151 0.815 49.073 1.134 1.080 1.171 1.540 645.042 1.138 22.836 9.672 0.792 158.589 Chronos-bolt (Ansari et al., 2024) also builds on the T5 architecture but introduces significant differences in tokenization and prediction strategies. It employs patch-based tokenization and replaces autoregressive decoding with single-pass inference, predicting fixed-length patch in each pass. For longer forecasting horizons, it iteratively encodes the historical context and predicts future patch. We include Chronos-bolt-small (48M) and Chronos-bolt-base (205M) in our model zoo. Time-MoE (Shi et al., 2025) is sparse decoder-only Transformer incorporating mixture-ofexperts (MoE) architecture to enable scalable time series forecasting. By leveraging sparse routing instead of fully dense structure, Time-MoE scales effectively with minimal computational overhead. It also uses point-wise embeddings and multi-scale patch-based predictions. We select Time-MoE with two different sizes (50M and 200M) for inclusion in our model zoo. B.3 GROUND TURTH To evaluate transferability estimation approaches, we fine-tune all models to obtain their actual fine-tuned performance and ranking. unified fine-tuning strategy is applied across all models to eliminate variability introduced by the fine-tuning process itself, ensuring fair comparison of their transferability. We choose to fine-tune all parameters of each model, which is simple but general approach. Each model is fine-tuned for 1 epoch using batch size of 32 and maximum sequence length of 2560. Optimization is performed with the AdamW optimizer and constant learning rate of 1e-5. The final checkpoint after 1 epoch is reserved for final evaluation on the test set to determine the actual fine-tuned performance. All fine-tuning experiments are conducted on single H100 GPU. The actual fine-tuned results under the three forecasting tasks are reported in Table C. B.4 BASELINES LFC (Tran et al., 2019) adopts linearized framework to approximate fine-tuning and measures the Label-Feature Correlation to estimate transferability. We compute the mean LFC across all token embeddings produced by the model backbone within the forecasting horizon, and use it as the transferability score for each sample. LogME (You et al., 2021) models transferability through estimating the maximum value of the target label evidence given the target features extracted from the pre-trained model. We also compute the"
        },
        {
            "title": "Preprint",
            "content": "mean LogME across all token embeddings produced by the model backbone within the forecasting horizon, and use this as the transferability score for given sample. RegScore (Nguyen et al., 2023) assesses transferability by measuring the error of linear regression model trained to predict labels from features. We compute the RegScore between all token embeddings produced by the model backbone within the forecasting horizon and their corresponding labels, and use the mean value as the transferability score for each sample. Meta-learner. The general meta-learner in AutoForecast Abdallah et al. (2022a) is linear model designed to project dataset meta-features to model performance. In our experiments, we adapt this meta-learner to predict fine-tuned performance based on data characteristics, model entropy profile, and zero-shot performance. The training data is identical to the corpus collected for TIMETIC. Zero-shot performance is the simplest proxy for estimating TSFMs transferability. We use the MASE to measure the zero-shot performance on sample and use it as the transferability score. B.5 EVALUATION METRICS Weighted Kendalls tau (τw) is statistic that measures the ordinal association between two ranked lists while assigning different importance to item pairs. It is defined as: τw = 1 2 (cid:80) (i,j):i<j wij I(cid:2)(xi xj)(yi yj) < 0(cid:3) (i,j):i<j wij (cid:80) where wij is nonnegative weight assigned to the pair (i, j), and I[] is the indicator function that equals 1 if the pair is discordant and 0 otherwise. By weighting different item pairs, τw allows emphasizing errors at the top of the ranking or other positions of interest. The value of τw ranges from 1 (inverse ranking) to 1 (perfect agreement), with 0 indicating no ordinal correlation. Compared with the standard Kendalls tau, the weighted version provides greater flexibility in applications where certain ranking positions are more critical than others. Spearmans rank correlation (ρ) is nonparametric statistic that measures the monotonic association between two ranked lists. It is defined as: ρ = 1 6 (cid:80)n i=1 d2 n(n2 1) where di is the difference between the ranks of the i-th item in the two lists, and is the total number of items being ranked. The value of ρ ranges from 1 (perfect inverse monotonic relationship) to 1 (perfect monotonic agreement), with 0 indicating no monotonic correlation. Compared with Kendalls tau, Spearmans ρ is based on rank differences rather than concordant and discordant pairs, making it computationally simpler for large n. Mean Absolute Scaled Error (MASE) evaluates forecast accuracy by comparing it to naive baseline. It is defined as: MASE = 1 t=1 yt ˆyt (cid:80)T 1 (cid:80)T t=m+1 yt ytm where yt is the true value, ˆyt is the predicted value, is the length of the forecast period, and is the seasonality of the series (with = 1 for non-seasonal data). The denominator represents the in-sample mean absolute error of naive forecasting method (e.g., seasonal naive). MASE is scale-free and interpretable: value less than 1 indicates the model outperforms the naive baseline."
        },
        {
            "title": "Preprint",
            "content": "Table D: Performance comparison of transferability estimation methods for short-term, mediumterm, and long-term forecasting under standard evaluation. Method kdd cup bizitobs l2c electricity solar sz taxi jena weather ett2 bitbrains rnd bizitobs app loop seattle"
        },
        {
            "title": "Mean",
            "content": "Downstream Target Datasets Short-term forecasting LFC LogME RegScore Meta learner Zero-shot 0.036 0.432 -0.354 -0.281 0.406 -0.038 -0.245 -0.178 0.339 -0.044 -0.437 0.040 -0.301 0.221 -0. 0.618 -0.448 0.519 -0.556 -0.677 0.069 0.266 0.304 0.444 0.038 -0.605 -0.093 -0.274 -0.120 0.411 -0.471 -0.528 -0.510 0.260 -0.157 -0.441 0.016 0.041 -0.473 0.144 TIMETIC 0. 0.320 0.218 0.159 0.152 0.372 0.190 0. Medium-term forecasting -0.130 LFC -0.205 LogME RegScore 0.200 Meta learner 0.680 0.386 Zero-shot 0.016 0.411 -0.131 -0.320 -0.053 -0.301 0.119 -0.296 -0.015 0.075 0.510 -0.289 -0.147 -0.328 -0.226 0.491 0.105 -0.436 0.187 0.632 -0.435 -0.169 0.135 0.205 0. -0.394 -0.631 0.317 0.260 0.678 -0.296 -0.474 -0.105 0.266 0.002 TIMETIC 0.137 0.522 0. 0.574 0.061 0.561 0.536 0.530 Long-term forecasting -0.079 LFC -0.283 LogME RegScore 0.307 Meta learner 0.411 0.393 Zero-shot 0.385 -0.511 -0.146 -0.119 0.518 0.005 -0.052 -0.606 0.105 -0.079 0.597 -0.499 -0.256 -0.411 -0.340 0.717 -0.221 -0.437 0.099 0.489 -0.317 0.354 0.264 -0.467 0.346 0.234 -0.254 0.334 0.008 0.251 -0.102 -0.321 -0.295 0.105 -0. TIMETIC 0.215 0.632 0.197 0.334 0.052 0. 0.327 0.632 0.007 0.162 -0.294 -0.149 0.110 0.112 0.016 0.411 0.274 -0.504 0.417 0. 0.330 0.346 0.241 0.084 0.547 0.445 0.638 -0.272 -0.246 0.159 0.471 -0.114 -0.053 -0.272 0.053 0.157 0.456 0. 0.402 0.001 -0.320 0.177 0.115 -0.106 -0.138 0.034 0.042 0.329 0.459 0.429 0.451 0.013 -0.300 -0.361 0.242 0.101 -0.138 0.018 -0.089 0. 0.038 0.319 Table E: Performance comparison of transferability estimation methods for short-term, mediumterm, and long-term forecasting under few-shot evaluation. Method kdd cup bizitobs l2c electricity solar sz taxi jena weather ett2 bitbrains rnd bizitobs app loop seattle"
        },
        {
            "title": "Mean",
            "content": "Downstream Target Datasets Short-term forecasting (few-shot) LFC LogME RegScore Meta learner Zero-shot 0.316 0.080 -0.215 -0.366 0.019 0.266 0.114 -0.254 0.277 -0.144 0.282 -0.033 0.001 0.221 -0. 0.628 -0.182 0.257 -0.559 -0.166 0.175 0.266 0.263 0.445 0.145 -0.631 0.067 0.245 -0.120 0.350 0.187 -0.626 0.357 0.374 0.157 -0.180 -0.199 0.383 -0.367 -0.051 TIMETIC 0. 0.286 0.285 0.316 0.134 0.293 0.107 0. Medium-term forecasting (few-shot) 0.110 LFC -0.143 LogME RegScore 0.530 Meta learner 0.680 0.508 Zero-shot 0.140 0.487 0.436 -0.184 0.067 -0.186 -0.255 -0.132 -0.015 0.075 0.686 -0.133 -0.256 -0.328 -0.277 0.481 0.105 -0.436 0.186 0.405 -0.288 -0.198 0.326 0.455 0. -0.044 -0.605 0.505 0.207 -0.081 -0.039 -0.314 0.095 -0.081 0.047 TIMETIC 0.137 0.451 0. 0.593 0.061 0.527 0.436 0.340 Long-term forecasting (few-shot) 0.052 LFC -0.283 LogME 0.361 RegScore Meta learner 0.411 0.425 Zero-shot 0.324 -0.415 -0.174 -0.119 0.536 0.310 0.019 -0.546 0.105 0.001 0.594 -0.528 -0.374 -0.411 -0.453 0.612 -0.221 -0.437 0.152 0.508 -0.280 0.015 0.175 0.095 0.408 0.265 -0.144 0.442 -0.040 0.376 -0.433 -0.429 -0.518 0.089 0. TIMETIC 0.305 0.672 0.197 0.334 0.088 0. 0.469 0.458 0.124 -0.432 -0.104 -0.184 0.119 0.442 0.016 0.411 0.274 -0.505 0.417 0. 0.330 0.346 0.241 0.084 0.547 0.445 0.551 -0.268 -0.179 0.272 0.346 0.136 -0.160 0.024 0.064 0.131 0.241 0. 0.339 0.007 -0.203 0.177 0.213 0.060 -0.119 0.204 0.040 0.262 0.459 0.383 0.384 -0.083 0.046 -0.414 0.173 0.102 -0.176 0.019 -0.045 0. 0.046 0."
        },
        {
            "title": "Preprint",
            "content": "Table F: Spearman ranking correlation of transferability estimation methods for short-term, mediumterm, and long-term forecasting under standard evaluation. Method kdd cup bizitobs l2c electricity solar sz taxi jena weather ett2 bitbrains rnd bizitobs app loop seattle"
        },
        {
            "title": "Mean",
            "content": "Downstream Target Datasets Short-term forecasting LFC LogME RegScore Meta learner Zero-shot 0.261 0.358 -0.491 -0.273 0.588 -0.079 -0.042 0.055 0.624 -0.067 -0.539 0.152 -0.479 0.309 -0. 0.467 -0.624 0.770 -0.673 -0.745 0.285 0.079 0.273 0.564 -0.006 -0.576 -0.273 -0.018 -0.188 0.527 -0.624 -0.612 -0.648 0.358 0.200 -0.479 0.394 0.006 -0.685 0.188 TIMETIC 0. 0.291 0.394 0.067 0.176 0.261 0.103 0. Medium-term forecasting -0.212 LFC -0.358 LogME RegScore 0.188 Meta learner 0.624 0.648 Zero-shot 0.103 0.115 -0.224 -0.164 0.078 -0.333 0.018 -0.419 0.030 0.212 0.442 -0.224 -0.127 -0.394 -0.176 0.261 -0.176 -0.467 0.030 0.794 -0.479 -0.297 0.236 0.176 0. -0.503 -0.794 0.164 0.382 0.697 -0.261 -0.491 0.006 0.345 0.358 TIMETIC 0.521 0.697 0. 0.539 0.394 0.582 0.733 0.555 Long-term forecasting -0.103 LFC -0.345 LogME RegScore 0.236 Meta learner 0.564 0.684 Zero-shot 0.685 -0.733 -0.236 -0.152 0.455 -0.030 -0.067 -0.657 0.345 0.176 0.394 -0.467 -0.224 -0.370 -0.333 0.612 -0.261 -0.358 -0.055 0.539 -0.297 0.491 0.273 -0.382 0.552 0.042 -0.358 0.612 0.321 0.527 -0.273 -0.333 -0.273 0.006 0. TIMETIC 0.527 0.830 0.552 0.078 0.285 0. 0.539 0.673 0.152 0.115 -0.236 -0.139 0.139 0.345 0.273 0.236 0.370 -0.721 0.515 0. 0.697 0.176 0.176 -0.139 0.321 0.539 0.612 -0.527 -0.345 -0.164 0.648 -0.143 -0.034 -0.262 0.019 0.257 0.733 0. 0.515 0.236 -0.285 -0.091 0.430 -0.068 -0.185 0.012 -0.006 0.467 0.600 0.600 0.358 -0.018 -0.455 -0.552 0.297 0.101 -0.178 -0.004 -0.061 0. 0.079 0.418 Table G: Spearman ranking correlation of transferability estimation methods for short-term, medium-term, and long-term forecasting under few-shot evaluation. Method kdd cup bizitobs l2c electricity solar sz taxi jena weather ett2 bitbrains rnd bizitobs app loop seattle"
        },
        {
            "title": "Mean",
            "content": "Downstream Target Datasets Short-term forecasting (few-shot) LFC LogME RegScore Meta learner Zero-shot 0.467 -0.103 -0.006 -0.321 0.248 0.382 0.333 -0.115 0.515 -0.139 0.333 -0.261 0.103 0.309 0. 0.479 -0.176 0.430 -0.624 -0.236 0.091 0.079 0.236 0.612 0.188 -0.770 -0.115 0.394 -0.188 0.430 0.236 -0.721 0.297 0.394 0.297 -0.164 -0.321 0.543 -0.636 -0.042 TIMETIC 0. 0.394 0.394 0.479 0.152 0.370 0.139 0. Medium-term forecasting (few-shot) 0.224 LFC -0.248 LogME RegScore 0.600 Meta learner 0.624 0.660 Zero-shot TIMETIC 0.321 0.418 0.515 0.612 0.006 0.042 0. -0.212 -0.333 0.025 0.030 0.212 0.539 -0.103 -0.297 -0.394 -0.115 0.273 -0.176 -0.467 0.030 0.648 -0.418 -0.321 0.321 0.285 0.855 -0.321 -0.758 0.442 0.236 0.006 -0.055 -0.261 0.030 0.018 0.248 0. 0.588 0.394 0.345 0.515 0.321 Long-term forecasting (few-shot) -0.042 LFC -0.345 LogME 0.552 RegScore Meta learner 0.564 0.697 Zero-shot 0.661 -0.636 -0.188 -0.152 0.455 0.127 -0.079 -0.644 0.345 0.273 0.382 -0.394 -0.394 -0.370 -0.467 0.430 -0.261 -0.358 0.006 0.564 -0.224 0.127 0.370 0.067 0.685 0.091 -0.273 0.685 0.224 0.648 -0.588 -0.539 -0.673 0.006 0. TIMETIC 0.539 0.842 0.552 0.079 0.273 0. 0.576 0.539 -0.224 -0.600 -0.079 -0.164 0.297 0.552 0.273 0.236 0.370 -0.721 0.515 0. 0.697 0.176 0.176 -0.139 0.321 0.539 0.539 -0.588 -0.309 -0.018 0.370 0.110 -0.257 0.068 0.021 0.236 0.291 0. 0.479 0.212 -0.139 -0.091 0.576 0.082 -0.165 0.242 -0.025 0.379 0.600 0.469 0.345 -0.091 0.200 -0.588 0.236 0.105 -0.242 0.044 -0.029 0. 0.418 0."
        },
        {
            "title": "C ADDITIONAL EXPERIMENTAL RESULTS",
            "content": "C.1 PERFORMANCE EVALUATION USING WEIGHTED KENDALL TAU Tables and report the performance of transferability estimation methods in short-, medium-, and long-term forecasting tasks in the standard and few-shot regimes. TIMETIC achieves the highest correlations on most datasets, consistently outperforming all baselines. We also observed fluctuations in transferability estimation performance across different forecast horizons within the same data set, suggesting that the forecast horizon is an important factor influencing TSFM performance and ranking. Moreover, dataset characteristics introduce varying challenges: for example, TIMETIC performs poorly on the sz taxi dataset but consistently achieves strong results on the bitbrains rnd dataset. C.2 PERFORMANCE EVALUATION USING SPEARMAN CORRELATION Tables and report the Spearman rank correlations of transferability estimation methods across short-, medium-, and long-term forecasting tasks under both standard and few-shot regimes. Unlike weighted Kendalls τw, which emphasizes pairwise concordance with importance weights, Spearman correlation evaluates the global monotonic relationship between two rankings, making it more sensitive to overall rank consistency. From the results, we observe that zero-shot performance provides relatively strong baseline with higher correlation than other metrics. By incorporating richer time series features and model characterization, TIMETIC achieves about 30% improvement over zero-shot performance on average."
        },
        {
            "title": "D UNCERTAINTY ANALYSIS",
            "content": "We define the performance estimation task as modeling the conditional distribution p(yx), where denotes models actual fine-tuned performance on the raw time series x. The optimal performance of regressor fθ is fundamentally limited by the aleatoric uncertainty, Var(yx), inherent in the true distribution p(yx). Formally, the expected squared error of pointwise regressor fθ for each input is lower-bounded by this variance: Eyp(yx) (cid:2)(y fθ(x))2(cid:3) Var(y x). In practice, however, observations are restricted to feature-based representations ϕ(x), which only partially capture x. As result, the regressor cannot distinguish between states where ϕ(x) = ϕ(x) but = x. This induces additional epistemic uncertainty, raising the lower bound of the expected error from Var(yx) to the larger Var(yϕ(x)): Eyp(yx) (cid:2)(y fθ(x))2(cid:3) Var(y ϕ(x)). Similar bounds also hold for regression-derived metrics such as rank correlations: if multiple yvalues share identical feature representations ϕ(x), their relative rankings cannot be determined. Hence, to minimize epistemic uncertainty, it is crucial for the regressor to incorporate as many informative features as possible. This insight motivates our use of TotalVariance as practical proxy for epistemic uncertainty and explains why TIMETIC emphasizes rich feature and model characterizations to improve transferability estimation. Moreover, TotalVariance can also serve as an uncertainty metric to guide context table construction, where minimizing it helps reduce the lower bound of estimation error."
        },
        {
            "title": "E USE OF LARGE LANGUAGE MODELS",
            "content": "In preparing this paper, we used large language models solely to improve the clarity and readability of the writing. All substantive research contributions, including conceptualization, model design, experimentation, and analysis, were conducted entirely by the authors."
        }
    ],
    "affiliations": [
        "Griffith University",
        "Hong Kong Baptist University",
        "NVIDIA Research",
        "The Hong Kong Polytechnic University"
    ]
}