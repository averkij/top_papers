{
    "paper_title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs",
    "authors": [
        "Florian Grötschla",
        "Luis Müller",
        "Jan Tönshoff",
        "Mikhail Galkin",
        "Bryan Perozzi"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large-language models (LLMs) have demonstrated powerful problem-solving capabilities, in particular when organized in multi-agent systems. However, the advent of such systems also raises several questions on the ability of a complex network of agents to effectively self-organize and collaborate. While measuring performance on standard reasoning benchmarks indicates how well multi-agent systems can solve reasoning tasks, it is unclear whether these systems are able to leverage their topology effectively. Here, we propose AgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration from classical problems in distributed systems and graph theory, AgentsNet measures the ability of multi-agent systems to collaboratively form strategies for problem-solving, self-organization, and effective communication given a network topology. We evaluate a variety of baseline methods on AgentsNet including homogeneous networks of agents which first have to agree on basic protocols for organization and communication. We find that some frontier LLMs are already demonstrating strong performance for small networks but begin to fall off once the size of the network scales. While existing multi-agent benchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size and can scale with new generations of LLMs. As such, we also probe frontier models in a setup with up to 100 agents."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 1 6 1 6 8 0 . 7 0 5 2 : r AGENTSNET: Coordination and Collaborative Reasoning in Multi-Agent LLMs Florian Grötschla ETH Zurich Luis Müller RWTH Aachen University Jan Tönshoff RWTH Aachen University Mikhail Galkin Google Research Bryan Perozzi Google Research"
        },
        {
            "title": "Abstract",
            "content": "Large-language models (LLMs) have demonstrated powerful problem-solving capabilities, in particular when organized in multi-agent systems. However, the advent of such systems also raises several questions on the ability of complex network of agents to effectively self-organize and collaborate. While measuring performance on standard reasoning benchmarks indicates how well multi-agent systems can solve reasoning tasks, it is unclear whether these systems are able to leverage their topology effectively. Here, we propose AGENTSNET, new benchmark for multi-agent reasoning. By drawing inspiration from classical problems in distributed systems and graph theory, AGENTSNET measures the ability of multi-agent systems to collaboratively form strategies for problem-solving, self-organization, and effective communication given network topology. We evaluate variety of baseline methods on AGENTSNET including homogeneous networks of agents which first have to agree on basic protocols for organization and communication. We find that some frontier LLMs are already demonstrating strong performance for small networks but begin to fall off once the size of the network scales. While existing multi-agent benchmarks cover at most 25 agents, AGENTSNET is practically unlimited in size and can scale with new generations of LLMs. As such, we also probe frontier models in setup with up to 100 agents."
        },
        {
            "title": "Introduction",
            "content": "Human societies thrive on collaboration, with language serving as the primary medium through which individuals coordinate and achieve collective goals. From small teams to large-scale organizations, effective communication enables structured decision-making, problem-solving, and the emergence of complex behaviors that surpass the capabilities of any single individual. This interplay between communication and coordination is mirrored in computing, where distributed systems rely on structured information exchange to tackle problems that exceed the capacity of any single processor. Just as psychology studies individual cognition while sociology examines emergent behaviors in groups, distributed systems research focuses on multi-agent coordination beyond what single machine can accomplish [23]. Recently, distributed systems have been playing an increasingly important role in AI through the emergence of general-purpose multi-agent systems built on top of large language and vision models (LLMs). Agent-based frameworks such as generative agents [36] have demonstrated the potential of solving complex problems with LLM-based agents. In particular, it has been shown that networks of *Equal contribution. Correspondence to: fgroetschla@ethz.ch Preprint. LLM-based agents can outperform single agents [9, 38, 53, 29], mirroring aspects of human teamwork. For example, GPTSwarm [53] introduce graph-based approach inspired by language-based societies of mind [52], demonstrating that organizing LLM-based agents in structured topologies enhances their performance on benchmarks like MMLU [20], HumanEval [8], and GAIA [31]. Yet despite promising results from structured agent networks, existing benchmarks fall short in evaluating the core competencies of multi-agent systems: scalable coordination, decentralized communication, and collaborative reasoning. To address this gap, we introduce AGENTSNET, principled multi-agent benchmark that measures these capabilities across diverse network structures and scales. AGENTSNET assesses the agents coordinative and collaborative capabilities through fundamental problems in distributed computing. Concretely, we identify five central problems from the distributed systems literature to construct corresponding coordination and collaboration tasks for multi-agent systems. Solving these tasks requires anything from local information aggregation to global coordination over multiple communication rounds. As canonical example, whenever multi-agent systems are tasked with solving certain problem, agents must necessarily be able to reach an agreement on the solution, problem known in faulttolerant distributed computing as consensus [16]. In another example, agents first agree on single agent to take leadership role, and then subsequently solve the task, guided and instructed by the elected leader. Selecting single leader in network is known as the leader election problem [2]. Fortunately, such problems are well-studied and theoretically grounded, providing an ideal testbed for the coordination and collaboration skills of multi-agent systems. Figure 1: Mean AGENTSNET score of models versus API costs per repeat (May 15, 2025). Error bars indicate standard error of the mean. Gold stars denote Paretooptimal models. Various multi-agent benchmarks exist, but no benchmark explicitly assesses the ability of multiagent systems for structured coordination and collaboration, which should be seen as fundamental capabilities of effective distributed systems. As such, AGENTSNET complements the existing suite of multi-agent benchmarks of LLMs with particular focus on grounding in distributed systems theory, network topology, and scalability to large agent networks. Concretely, we make the following contributions: 1. We build AGENTSNET from graph coloring, minimal vertex cover, maximal matching, leader election and consensus: five fundamental distributed computing problems that evaluate the ability of multi-agent systems to effectively self-organize, coordinate, and communicate to solve complex reasoning problems. 2. We design robust and scalable message-passing protocol for effective agent-to-agent communication and evaluate on rich set of graph instances, sampled from various graph models such as small-world [45] or preferential attachment models [4], which capture structural properties of real-world networks. 3. We evaluate variety of agentic baselines on AGENTSNET, ranging from open-source LLMs such as Llama 4, to frontier models such as GPT, Gemini, and Claude, as well as the latest reasoning models, on the graphs of 4, 8, 16 nodes scaling the problem size to 100 agents which is well beyond existing agentic benchmarks. 4. We provide an in-depth qualitative analysis and highlight the challenges in coordinative and collaborative capabilities of LLMs to further improve multi-agent systems. 2 Figure 2: Example communication between three agents on simplified topology. Agents Emily, Zach, and Tom each receive and send messages to their neighbors in multiple rounds of messagepassing; see Appendix for an in-depth qualitative analysis of transcripts."
        },
        {
            "title": "2 Related Work",
            "content": "Ensembling multiple agents to collaboratively negotiate solutions has emerged as an effective paradigm to improve LLM performance on complex tasks [13, 46, 24]. This has been extended through work on different network topologies for more structured agent interaction. Some studies examine pre-determined graph structures [39, 38] while others propose automatically adapting network topology [27, 9, 53]. Experiments show different topologies perform best for specific tasks [9, 53] and large-scale LLM agent networks exhibiting known social phenomena [48, 12]. Parallel research examines LLMs ability to reason with graph-structured data. Studies propose evaluation datasets [15, 44, 51, 43, 42] using single-agent setups where graphs are encoded as text. Fatemi et al. [15] investigate graph encoding methods, Sanford et al. [40] categorize graph reasoning problems by complexity, while Wang et al. [44] and Skianis et al. [42] explore effective prompting techniques. Our work bridges these research directions by studying multi-agent systems solving graph reasoning problems collaboratively. Our benchmark is complementary to recent agentic benchmarks [26, 50, 1, 49, 33] but scales to practically unlimited number of agents due to the generative problem creation protocol, with experiments involving up to 100 coordinating agents. Related human studies on decentralized problem-solving in social networks show that network topology and size strongly influence coordination success [22, 21, 11]. Appendix provides an extended discussion of related studies."
        },
        {
            "title": "3 Tasks, Evaluation, and Graph Models",
            "content": "To evaluate the ability of multi-agent systems to self-organize, coordinate, and communicate effectively, we design benchmark consisting of fundamental problems from distributed computing. These problems span range of complexities, from local tasks that require minimal coordination to global problems that necessitate multi-round communication. In what follows, we introduce the theoretical problems and describe how we map each problem to corresponding agentic task. Afterwards, we introduce the graph distributions used within AGENTSNET. 3.1 Benchmarking Tasks We evaluate multi-agent systems on set of distributed computing problems that test their ability to aggregate information, self-organize, and coordinate. These tasks are selected for their foundational nature in distributed computing and for their relevance as naturally appearing subproblems in more complicated tasks. They span diverse range of coordination requirements and communication complexities, from purely local information exchange to global decision-making; see Table 1 for an overview of the different theoretical problems selected for AGENTSNET. 3 Figure 3: Overview of the tasks in AGENTSNET: In LEADERELECTION, the task is to select single agent as the leader of the network. In CONSENSUS, the task is for all agents to agree on specific value, for example 0 or 1. In MATCHING, the task is for pairs of agents to team up without conflicts. In COLORING, the task is for agents to select group (indicated by color), such that none of their neighbors are in the same group as them. In VERTEXCOVER, the task is to find minimal group of coordinator agents such that each agent is neighbor to at least one coordinator. ( + 1)-Coloring. Each node is assigned color using at most + 1 colors, where is the maximum node degree. This problem has well-defined distributed complexity of O(log n) in bounded-degree graphs [5]. This task is particularly useful for role assignment within multi-agent systems. For instance, agents can be designated to perform specific sub-tasks (e.g., web search, reasoning, coding, planning), with the constraint that directly connected agents are assigned distinct roles to avoid redundancy. Solving this task reflects the systems ability to efficiently distribute responsibilities across the network with minimal overlap in capabilities. The corresponding agentic task is to form groups, with pre-defined number of groups, and where each group corresponds to color. After message-passing, each agent chooses the group it wants to be in. The task is solved if the groups form valid + 1-coloring. In AGENTSNET, we refer to this task as COLORING. Minimal Vertex Cover. minimal vertex cover is subset of nodes such that every edge in the graph has at least one endpoint in the subset, and removing any node from this subset would violate that property. This problem has close relationship with the maximal independent set and is similarly fundamental in distributed computing, with known randomized solutions in O(log n) rounds [25]. In agentic networks, minimal vertex cover can represent minimal set of monitor or gateway agents that maintain awareness of all interactions in the system. These agents could take on responsibilities such as relaying messages, auditing behavior, or bridging subgroups. The task tests the ability to identify compact yet effective set of nodes with high influence or observability. The corresponding agentic task is to select group of coordinators among the agents. After message-passing, each agent is asked whether it is coordinator. The agents can respond with either Yes or No. The task is solved if coordinators form minimal vertex cover. In AGENTSNET, we refer to this task as VERTEXCOVER. Maximal Matching. maximal matching is set of edges such that no two edges share vertex, and no additional edges can be added without violating this property. This task captures the ability of agents to negotiate pairwise agreements without global knowledge, which is useful in scenarios where resource allocation or mutual exclusivity must be enforced (e.g., agent-to-agent task assignment). Randomized algorithms typically solve this problem in O(log n) rounds [37]. The corresponding agentic task is for the agents to form pairs. After message-passing, each agent is asked to name the neighbor it wants to pair up with. The agents can also respond with None if they cannot find match (all neighbor agents are already paired up with other agents). The task is solved if the paired agents form maximal matching. In AGENTSNET, we refer to this task as MATCHING. Leader Election. One node must be selected as the leader, while all others acknowledge that they are not. This classic coordination task is central to evaluating how well agents establish hierarchy and delegate global decision-making [2]. In multi-agent systems, leader election can be interpreted as selecting central planner or controller agent responsible for strategy synthesis, while the remaining agents act as executors. Effective leader election demonstrates the systems capacity to break symmetry and converge on single authority. In general graphs, the round complexity is O(D), where is the network diameter [28]. The corresponding agentic task is to select single leader among the agents. After message-passing, each agent is asked whether it is the leader. The agents can 4 respond with either Yes or No. The task is solved if there exists exactly one leader. In AGENTSNET, we refer to this task as LEADERELECTION."
        },
        {
            "title": "Graph Problem",
            "content": "( + 1)-Coloring Minimal Vertex Cover Leader election Maximal Matching Consensus Consensus. In the consensus problem, all agents must agree on single value from the set {0, 1}. In our benchmark, we focus on the basic setting without any faulty or Byzantine agents. The goal is for all agents to coordinate and produce the same final answer after number of communication rounds. successful solution requires that every agent outputs the same value, either 0 or 1. This task tests the ability of multi-agent systems to converge to global agreement through local message-passing alone. In synchronous networks, achieving consensus generally requires O(D) rounds [28]. The corresponding agentic task is to choose between value 0 and 1. After message-passing, each agent is asked to announce its selected value. The task is solved if all agents announce the same value. In AGENTSNET, we refer to this task as CONSENSUS. Table 1: Overview of the theoretical problems from distributed computing that form the basis of AGENTSNET, together with (not necessarily tight) theoretical lower bounds for their round complexity in the randomized LOCAL [25] model. Round Complexity Ω(log(n)) Ω(log(n)) Ω(D) Ω(log(n)) Ω(D) Together, these tasks cover broad spectrum of problems known in the distributed computing literature, which allows AGENTSNET to evaluate the reasoning, communication, and organizational capabilities of multi-agent systems. 3.2 Network Topologies While classical distributed computing often studies problems on random graphs such as Erdos-Renyi networks [14], these do not adequately capture the structural properties of real-world networks. Instead, we focus on three well-established graph models, namely the Watts-Strogatz graphs [45] (SMALLWORLD) exhibiting both short average path lengths and high clustering coefficients; preferential attachment graphs [4] (SCALEFREE) containing hubs (high-degree nodes) and follow power-law degree distribution; geometric graphs by constructing Delaunay triangulation over randomly sampled 2D points, (DELAUNAY), maintaining spatial relationship between nearby agents. We describe these graph models in more detail in Appendix D."
        },
        {
            "title": "4 Agent-to-Agent Communication via Message-Passing",
            "content": "To systematically study how agents exchange information and collaborate, we employ communication model that draws inspiration from classical distributed computing, while adapting to the capabilities and constraints of modern LLM-based agents. Our setup is based on the LOCAL model [25] from distributed algorithms, in which the computation proceeds in synchronous rounds and each agent can exchange messages only with its immediate neighbors on the communication graph. Agents must base their decisions exclusively on local information aggregated over multiple rounds of interaction. This model captures fundamental aspects of decentralized reasoning, where global strategies emerge from purely local exchanges without centralized control. Unlike nodes in deterministic systems, LLM-based agents exhibit stochastic behavior due to inherent randomness in their generation processes. This means that our model is most closely aligned with the randomized version of the LOCAL model. Given communication network, each node, that is, each agent, is instantiated as an instruction-tuned LLM that interfaces with its neighbors through structured chat history. Initially, we provide each agent with system prompt detailing the task, for example, COLORING, the rules of message-passing, the names of its neighbors, and notification that the agent must output result in its final response after fixed number of rounds of message-passing; see Appendix for the full system prompt. We describe task descriptions, message-passing rules, and final response crafting below. 5 Task description. For each task, we provide short description of the task, as well as which information we seek to extract in the final response. For example, for LEADERELECTION, we provide the following task description: System Your task is to collaboratively solve the problem of electing single leader. [...] you are the leader. The final result should be such that exactly one agent responds with Yes and all others say No as there should be exactly one leader. You will be requested to state whether or not The response should either be Yes or No. Note that the \"[...]\" indicates that different parts of the task description appear at different parts of the system prompt. Message-Passing Rules. For message-passing, we iteratively prompt each agent with the current chat history, including the latest messages received from its neighbors, to generate new messages to each neighbor in the form of flat JSON. Here, each key corresponds to the name of neighboring agent, and each value to the message intended for the corresponding neighbor. Optionally, we also ask the model to elaborate its chain-of-thought before responding. An example of this message exchange can look as follows: Human These are the messages from your neighbors: Hello Evelyn, this is Emma. Message from Dorothy: step-by-step first, then output the messages for your neighbors. Output your messages in JSON format as specified earlier. Elaborate your chain of thought appreciate your response and [...] Message from Emma: [...] In practice, and in particular for smaller models, we observe that agents sometimes fail to output valid JSON. In such cases, we simply ask the model to try again using the entire chat history, including the incorrect answer given by the model, as well as prompt to retry. Final Response. After fixed number message-passing rounds, we ask the model to give its task-specific response based on the chat history accumulated during message-passing. Again, we ask models for structured output, this time using simpler, string-based format. For example, for LEADERELECTION, the final response prompt is: Human Are you the leader? Answer ###, followed by your final answer. Dont use any text for your final answer except one of these valid options: Yes, No. Format your answer as follows: ### Final Once more, we find that models generate valid response after at most one retry. The benchmarking results are then computed from these final answers, following the task-specific evaluation methods described in Section 3."
        },
        {
            "title": "5 Experiments",
            "content": "With the building blocks of AGENTSNET established in Section 3, and our message-passing protocol described in Section 4, we are now ready to describe our benchmark design and present our results. 6 Model Claude 3.5 Haiku Claude 3.7 Sonnet GPT-4.1 mini Gemini 2.0 Flash Gemini 2.5 Flash Gemini 2.5 FT Gemini 2.5 Pro Llama 4 Maverick Llama 4 Scout o4-mini COLORING CONSENSUS LEADER ELECTION MATCHING VERTEX COVER AGENTSNET 0.14 (0.04) 0.58 (0.05) 0.05 (0.02) 0.32 (0.05) 0.39 (0.06) 0.53 (0.05) 0.62 (0.07) 0.20 (0.04) 0.21 (0.06) 0.22 (0.04) 0.69 (0.05) 1.00 (0.00) 0.99 (0.01) 0.85 (0.04) 1.00 (0.00) 0.99 (0.01) 0.99 (0.01) 0.85 (0.04) 0.67 (0.05) 0.92 (0.04) 0.19 (0.03) 0.96 (0.03) 0.86 (0.05) 0.69 (0.05) 1.00 (0.00) 0.98 (0.02) 0.89 (0.06) 0.56 (0.06) 0.38 (0.06) 0.92 (0.03) 0.18 (0.03) 0.55 (0.06) 0.12 (0.03) 0.36 (0.05) 0.55 (0.04) 0.47 (0.02) 0.75 (0.05) 0.20 (0.04) 0.30 (0.05) 0.33 (0.04) 0.08 (0.03) 0.40 (0.05) 0.22 (0.04) 0.16 (0.04) 0.50 (0.09) 0.43 (0.09) 0.73 (0.06) 0.07 (0.03) 0.13 (0.04) 0.27 (0.04) 0.26 (0.02) 0.70 (0.02) 0.45 (0.01) 0.48 (0.02) 0.69 (0.02) 0.68 (0.02) 0.80 (0.02) 0.38 (0.02) 0.34 (0.02) 0.53 (0.02) Table 2: Fraction of solved instances together with standard error over multiple i.i.d. samples from the same graph distribution (in gray) on AGENTSNET. Gemini 2.5 FT = Gemini 2.5 Flash Thinking. 5.1 Setup For benchmarking, we generate set of 27 network topologies, consisting of 9 small-world, scale-free, and Delaunay graphs, respectively, ranging in size from 4 to 16 nodes. Concretely, for each graph size in {4, 8, 16} and each graph distribution in {SMALLWORLD, SCALEFREE, DELAUNAY}, we generate three graphs. Further, we determine the number of message-passing rounds as follows. For our global tasks, LEADERELECTION and CONSENSUS, each agent must be able to exchange information with the entire network. Hence, for those two tasks, we select the number of messagepassing rounds as 2D + 1, where is the diameter of the graph, to ensure that each pair of agents is able to exchange messages at least once. For the local tasks, COLORING, MATCHING, and VERTEXCOVER, we determine the number of rounds based on the graph size. Specifically, for graphs with 4 nodes, we choose 4 rounds, for 8 nodes 5 rounds, for 16 nodes 6 rounds. Models. We evaluate variety of frontier LLMs on AGENTSNET, including Claude 3.5 Haiku and Claude 3.7 Sonnet [3], Gemini 2.0 Flash [17], Gemini 2.5 Flash [18], GPT-4.1-mini [34], as well as Llama 4 Maverick and Scout [30], as representative open-source models. Notably, we include both large instruction-tuned models as well as reasoning models such as Gemini 2.5 Flash Thinking, Gemini 2.5 Pro [19], and o4-mini [35]. The choice of models is motivated by an effective context window larger than 16K tokens, as problems on graphs of 8 and 16 nodes, especially at later stages of message passing, accumulate long communication history. Evaluation. AGENTSNET uses binary evaluation metric, counting only fully correct solutions where the entire agent network satisfies the task specification. This strict criterion reflects the nature of distributed computing problems, where partial correctness often does not imply successful coordination. For example, in COLORING, most nodes may be correctly colored by chance, but only valid global coloring confirms coordinated conflict resolution. However, in Appendix B, we also discuss and report the soft evaluation scores to obtain more continuous measure of the quality of responses, motivated by the findings in Schaeffer et al. [41], that emergent behaviors can often be explained by discontinuous metrics. For each task and graph size, we sample three graphs per topology (small-world, scale-free, Delaunay) and run at least one repeat per graph. We report the mean of solved runs and the standard errors of the mean, computed across these runs [32]. Details on scoring and statistical methodology are provided in Appendix C. Implementation. We implement our message-passing protocol, as outlined in Section 4, using LangChain [6] as it provides integrations with most available LLMs. We implement graph generation with NetworkX *, widely used framework for graph and network processing. Our implementation is designed to be easily extensible to other graph distributions, graph sizes, and new LLMs. We provide open-source code at https://github.com/floriangroetschla/AgentsNet and our dataset at https://huggingface.co/datasets/disco-eth/AgentsNet. *https://networkx.org 7 Figure 4: Fraction of solved instances per task and model, grouped by graph size (4, 8, and 16 nodes). Each task contributes up to 20% to the total, as tasks are equally distributed across the five benchmark tasks. Reasoning and non-reasoning models are visually separated. This breakdown complements Figure 1 by providing more granular view of task-level performance. 5.2 Results on AGENTSNET We provide the fraction of solved instances per task in Table 2. We follow the suggestion of Miller [32] and report the standard error of the mean for our results. In addition, we plot breakdown over different graph sizes in Figure 4. Finally, in Figure 1 we plot the performance of models across all tasks with respect to API costs. We observe that even for the 4-node graphs, no model performs consistently strongly across all tasks. In particular, the CONSENSUS task is solved by most models, while performance on VERTEXCOVER is low for most models, in particular for 8 and 16 nodes. Overall, the best performing models are Claude 3.7 Sonnet, Gemini 2.5 Pro, and Gemini 2.5 Flash. In fact, Gemini 2.5 Flash is roughly on par with Claude 3.7 while being much cheaper to run on AGENTSNET (by about factor of 20). Interestingly, model performance generally drops with an increase in graph size. Next, we show an ablation study on further scaling the graph size to probe whether AGENTSNET can be scaled jointly with the increase in future model capabilities. 5.3 Scaling the Agent Network In addition to our main results, we provide additional results for networks of up to 100 agents in Figure 5 on Gemini 2.0 Flash, which shows good performance on AGENTSNET while remaining cost-efficient. Concretely, we generate total of 81 network topologies. For simplicity, and as good rule-of-thumb, we run messagepassing for 2D + 1 rounds, where is the graph diameter, for all tasks. We observe that performance smoothly decreases as the network grows in size. Although the five tasks vary in inherent difficulty, for example, MATCHING and COLORING are often easier on small graphs than CONSENSUS or LEADERELECTION, we observe that all tasks become substantially more challenging as the size of Figure 5: Scalability of Gemini 2.0 Flash on AGENTSNET: Average fraction of successfully solved instances per task as the graph size increases from 20 to 100 agents. 8 the network increases. For 100-agent networks, performance drops to near zero across the board. As consequence, the difficulty of AGENTSNET can be gradually increased by considering larger networks. Importantly, this increase in difficulty can be facilitated without any changes to AGENTSNET, which we design to allow for an arbitrary network size. 5.4 Qualitative Analysis Here, we present qualitative analysis of the responses of different LLMs to gain deeper understanding of their overall communication, solution strategies, and collaborative capabilities. In particular, we analyze transcript data for select models across different levels of performance on AGENTSNET. Concretely, we select Llama Maverick, Gemini 2.5 Flash, Gemini 2.5 Pro, as well as o4-mini. Here, we highlight key findings and show select examples. In Appendix E, we present the full analysis and number of examples and excerpts from transcripts. Our key findings are: Finding 1: Strategy coordination poses an essential challenge on AGENTSNET. We find multiple failure cases due to issues with coordinating strategy between agents. In some cases, agents agree on common strategy too late during message-passing, leaving an insufficient number of message-passing rounds to implement the strategy. In other cases, agents do not coordinate their strategy at all. Concretely, agents assume some strategy in their initial chain-of-thought and then follow that strategy throughout message-passing without informing neighbors about their strategy. Finding 2: Agents generally accept information sent by neighbors. This includes key information about the network, proposed strategies, or candidate solutions. While generally enabling effective coordination, agents sometimes fail to question erroneous information, leading to incorrect solutions. Examples of such erroneous information are incorrect assumptions about the network topology or ineffective strategies proposed by other agents. Finding 3: Agents help their neighbors resolving inconsistencies in candidate solutions. We find multiple examples where agents detect conflicting color assignments in COLORING problems between other agents and assist in resolving these conflicts. We present detailed examples and failure cases in Appendix E."
        },
        {
            "title": "6 Limitations",
            "content": "We implement AGENTSNET on the LOCAL computation model from distributed computing, which uses synchronous message-passing. However, other message-passing protocols may be more effective in the context of collaborative problem solving. For example, downside of synchronous messagepassing is that agents receive answers to their messages only in the subsequent message-passing round. Moreover, our implementation relies on answer parsing via JSON, which can be ambiguous and error-prone. However, we note that both of the above limitations are implementation choices not inherent to AGENTSNET. For example, future work on effective message-passing protocols or the use of structured output could be easily incorporated into AGENTSNET. We elaborate on the limitations in Appendix G."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we proposed AGENTSNET, multi-agent benchmark built on top of fundamental problems from distributed computing, with the goal of assessing the ability of agentic networks to coordinate and collaborate to solve problems. While existing benchmarks are limited to 25 agents, the initial AGENTSNET suite probes up to 100 agents and is practically unlimited in size and can https://openai.com/index/introducing-structured-outputs-in-the-api/ 9 generate problems of increasing complexity to keep up with new generations of frontier models. To this end, we design robust message-passing protocol to enable multi-step communication between agents and evaluate models on variety of graph instances, sampled from multiple graph models, and with different graph sizes. We evaluate and compare variety of frontier LLMs on AGENTSNET and find that our tasks can be challenging for even the best models."
        },
        {
            "title": "References",
            "content": "[1] Agashe, S., Fan, Y., Reyna, A., and Wang, X. E. (2024). Llm-coordination: evaluating and analyzing multi-agent coordination abilities in large language models. arXiv preprint arXiv:2310.03903. [2] Angluin, D. (1980). Local and global properties in networks of processors. In Proceedings of the twelfth annual ACM symposium on Theory of computing, pages 8293. [3] Anthropic (2024). The claude 3 model family: Opus, sonnet, haiku. [4] Barabási, A.-L. and Albert, R. (1999). Emergence of scaling in random networks. science, 286(5439):509512. [5] Barenboim, L. (2016). Deterministic (δ+ 1)-coloring in sublinear (in δ) time in static, dynamic, and faulty networks. Journal of the ACM (JACM), 63(5):122. [6] Chase, H. (2022). LangChain. [7] Chen, H., Ji, W., Xu, L., and Zhao, S. (2023). Multi-agent consensus seeking via large language models. arXiv preprint arXiv:2310.20151. [8] Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. (2021). Evaluating large language models trained on code. [9] Chen, W., Su, Y., Zuo, J., Yang, C., Yuan, C., Chan, C.-M., Yu, H., Lu, Y., Hung, Y.-H., Qian, C., Qin, Y., Cong, X., Xie, R., Liu, Z., Sun, M., and Zhou, J. (2024a). Agentverse: Facilitating multiagent collaboration and exploring emergent behaviors. In The Twelfth International Conference on Learning Representations. [10] Chen, W., You, Z., Li, R., Guan, Y., Qian, C., Zhao, C., Yang, C., Xie, R., Liu, Z., and Sun, M. (2024b). Internet of agents: Weaving web of heterogeneous agents for collaborative intelligence. arXiv preprint arXiv:2407.07061. [11] Chiang, Y.-S., Cho, H.-C., and Chang, C.-J. (2024). Adaptive networks driven by partner choice can facilitate coordination among humans in the graph coloring game: Evidence from network experiment. Collective Intelligence, 3(3):26339137241285901. [12] Chuang, Y.-S., Goyal, A., Harlalka, N., Suresh, S., Hawkins, R., Yang, S., Shah, D., Hu, J., and Rogers, T. (2024). Simulating opinion dynamics with networks of LLM-based agents. In Findings of the Association for Computational Linguistics: NAACL 2024. [13] Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mordatch, I. (2023). Improving factuality and reasoning in language models through multiagent debate. In Forty-first International Conference on Machine Learning. [14] Erdos, P., Rényi, A., et al. (1960). On the evolution of random graphs. Publ. math. inst. hung. acad. sci, 5(1):1760. [15] Fatemi, B., Halcrow, J., and Perozzi, B. (2024). Talk like graph: Encoding graphs for large language models. In International Conference on Learning Representations (ICLR). 10 [16] Fischer, M. J., Lynch, N. A., and Paterson, M. S. (1985). Impossibility of distributed consensus with one faulty process. Journal of the ACM (JACM), 32(2):374382. [17] Google (2024). Gemini 2.0: new ai model for the agentic era. [18] Google (2025a). Developers can now start building with gemini 2.5 flash. [19] Google (2025b). Gemini 2.5: Our newest gemini model with thinking. [20] Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. (2021). Measuring massive multitask language understanding. Proceedings of the International Conference on Learning Representations (ICLR). [21] Judd, S., Kearns, M., and Vorobeychik, Y. (2010). Behavioral dynamics and influence in networked coloring and consensus. Proceedings of the National Academy of Sciences, 107(34):14978 14982. [22] Kearns, M., Suri, S., and Montfort, N. (2006). An experimental study of the coloring problem on human subject networks. science, 313(5788):824827. [23] Lenzen, C. and Wattenhofer, R. (2012). Distributed algorithms for sensor networks. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 370(1958):1126. [24] Liang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang, R., Yang, Y., Shi, S., and Tu, Z. (2024). Encouraging divergent thinking in large language models through multi-agent debate. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 1788917904. [25] Linial, N. (1992). Locality in distributed graph algorithms. SIAM Journal on computing, 21(1):193201. [26] Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., Shen, S., Zhang, T., Su, Y., Sun, H., Huang, M., Dong, Y., and Tang, J. (2024). Agentbench: Evaluating LLMs as agents. In The Twelfth International Conference on Learning Representations. [27] Liu, Z., Zhang, Y., Li, P., Liu, Y., and Yang, D. (2023). Dynamic llm-agent network: An llmagent collaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170. [28] Lynch, N. A. (1996). Distributed algorithms. Elsevier. [29] Marro, S., La Malfa, E., Wright, J., Li, G., Shadbolt, N., Wooldridge, M., and Torr, P. (2024). scalable communication protocol for networks of large language models. arXiv preprint arXiv:2410.11905. [30] Meta (2025). The llama 4 herd: The beginning of new era of natively multimodal ai innovation. [31] Mialon, G., Fourrier, C., Wolf, T., LeCun, Y., and Scialom, T. (2024). GAIA: benchmark for general AI assistants. In The Twelfth International Conference on Learning Representations. [32] Miller, E. (2024). Adding error bars to evals: statistical approach to language model evaluations. arXiv preprint arXiv:2411.00640. [33] Ni, A., Desai, R., Li, Y., Lei, X., Wang, D., Raghavendra, R., Ghosh, G., Li, D., and Celikyilmaz, A. (2025). Collaborative reasoner: Self-improving social agents with synthetic conversations. arXiv preprint. [34] OpenAI (2025a). Introducing gpt-4.1 in the api. [35] OpenAI (2025b). Introducing openai o3 and o4-mini. [36] Park, J. S., OBrien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122. [37] Peleg, D. (2000). Distributed computing: locality-sensitive approach. SIAM. [38] Qian, C., Xie, Z., Wang, Y., Liu, W., Dang, Y., Du, Z., Chen, W., Yang, C., Liu, Z., and Sun, M. (2024). Scaling large-language-model-based multi-agent collaboration. arXiv preprint arXiv:2406.07155. [39] Regan, C., Gournail, A., and Oka, M. (2024). Problem-solving in language model networks. In Artificial Life Conference Proceedings 36. [40] Sanford, C., Fatemi, B., Hall, E., Tsitsulin, A., Kazemi, M., Halcrow, J., Perozzi, B., and Mirrokni, V. (2024). Understanding transformer reasoning capabilities via graph algorithms. In The Thirty-eighth Annual Conference on Neural Information Processing Systems. [41] Schaeffer, R., Miranda, B., and Koyejo, S. (2023). Are emergent abilities of large language models mirage? In NeurIPS. [42] Skianis, K., Nikolentzos, G., and Vazirgiannis, M. (2024). Graph reasoning with large language models via pseudo-code prompting. [43] Tang, J., Zhang, Q., Li, Y., Chen, N., and Li, J. (2025). Evaluating and improving large language models on graph computation. In The Thirteenth International Conference on Learning Representations. [44] Wang, H., Feng, S., He, T., Tan, Z., Han, X., and Tsvetkov, Y. (2024). Can language models solve graph problems in natural language? Advances in Neural Information Processing Systems, 36. [45] Watts, D. J. and Strogatz, S. H. (1998). Collective dynamics of small-worldnetworks. nature, 393(6684):440442. [46] Xiong, K., Ding, X., Cao, Y., Liu, T., and Qin, B. (2023). Examining inter-consistency of large language models collaboration: An in-depth analysis via debate. In The 2023 Conference on Empirical Methods in Natural Language Processing. [47] Xu, L., Hu, Z., Zhou, D., Ren, H., Dong, Z., Keutzer, K., Ng, S. K., and Feng, J. (2023). Magic: Benchmarking large language model powered multi-agent in cognition, adaptability, rationality and collaboration. arXiv preprint arXiv:2311.08562. [48] Yang, Z., Zhang, Z., Zheng, Z., Jiang, Y., Gan, Z., Wang, Z., Ling, Z., Chen, J., Ma, M., Dong, B., Gupta, P., Hu, S., Yin, Z., Li, G., Jia, X., Wang, L., Ghanem, B., Lu, H., Lu, C., Ouyang, W., Qiao, Y., Torr, P., and Shao, J. (2024). Oasis: Open agent social interaction simulations with one million agents. [49] Yao, S., Shinn, N., Razavi, P., and Narasimhan, K. (2024). Tau-bench: benchmark for tool-agent-user interaction in real-world domains. arXiv preprint arXiv:2406.12045. [50] Yin, G., Bai, H., Ma, S., Nan, F., Sun, Y., Xu, Z., Ma, S., Lu, J., Kong, X., Zhang, A., et al. (2024). Mmau: holistic benchmark of agent capabilities across diverse domains. arXiv preprint arXiv:2407.18961. [51] Zhang, Z., Wang, X., Zhang, Z., Li, H., Qin, Y., and Zhu, W. (2024). Llm4dyg: Can large language models solve spatial-temporal problems on dynamic graphs? In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 24, page 43504361, New York, NY, USA. Association for Computing Machinery. [52] Zhuge, M., Liu, H., Faccio, F., Ashley, D. R., Csordás, R., Gopalakrishnan, A., Hamdi, A., Hammoud, H. A. A. K., Herrmann, V., Irie, K., Kirsch, L., Li, B., Li, G., Liu, S., Mai, J., Piekos, P., Ramesh, A. A., Schlag, I., Shi, W., Stanic, A., Wang, W., Wang, Y., Xu, M., Fan, D., Ghanem, B., and Schmidhuber, J. (2023). Mindstorms in natural language-based societies of mind. Arxiv. [53] Zhuge, M., Wang, W., Kirsch, L., Faccio, F., Khizbullin, D., and Schmidhuber, J. (2024). Gptswarm: Language agents as optimizable graphs. In ICML."
        },
        {
            "title": "A Implementation Details",
            "content": "Here, we describe implementation details of AGENTSNET. Message-Passing. Algorithm 1 gives an overview over our message-passing in pseudocode. We generate message from agent with Generate(v ), where is information provided in the prompt. Agent can send/receive messages to/from neighbors (v) with SendMessage(m, w) and ReceiveMessage(w), respectively. For clarity, we omit the re-tries and JSON parsing from Algorithm 1. Algorithm 1 Pseudocode for rounds of message-passing. for each agent do Generate(v System prompt) for each neighbor do: SendMessage(m, w) end for for each {1, . . . , 1} do for each neighbor do: m(w) ReceiveMessage(w) Generate(v for each neighbor w: m(w)) for each neighbor do: SendMessage(m, w) end for return for each agent v: Generate(v Result prompt) Models. We provide details on API providers and model versions in Table 3, which includes diverse range of proprietary and open-source LLMs that span instruction-tuned, reasoning-enhanced, and cost-efficient models. These were selected to ensure broad coverage of state-of-the-art capabilities, as well as compatibility with the long-context requirements of AGENTSNET tasks. All models included support effective context lengths exceeding 16k tokens, which is essential for multi-round communication in graphs with up to 16 nodes. Full System Prompt. Here, we provide the full system prompt for AGENTSNET. Since the prompt differs between tasks, agent, and the number of agents in the network, we use template variables, which we indicate here with [n] (number of agents), [name] (name of agent), [neighbors] (comma-separated names of neighbors), [r] (number of message-passing rounds), [task1] (first part of the task description, at the beginning of the prompt), and [task2] (second part of the task description, at the end of the prompt). We provide the task-specific descriptions [task1] and [task2] for each task in Appendix B. Model Provider Version Anthropic Claude 3.5 Haiku Claude 3.7 Sonnet Anthropic GPT-4.1 mini o4-mini Gemini 2.0 Flash Gemini 2.5 Flash Gemini 2.5 FT OpenAI OpenAI Google Google Google Gemini 2.5 Pro Google Llama 4 Maverick Together AI Together AI Llama 4 Scout claude-3-5-haiku-20241022 claude-3-7-sonnet-20250219 gpt-4.1-mini o4-mini gemini-2.0-flash gemini-2.5-flash-preview-04-17 gemini-2.5-flash-preview-04-17-thinking gemini-2.5-pro-preview-03-25 and gemini-2.5-pro-preview-05-06 meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8 meta-llama/Llama-4-Scout-17B-16E-Instruct Table 3: API providers and model versions used in our testing. 13 System You are an agent that is connected with other agents (your neighbors), who you communicate with. Your neighbors can in turn communicate with their neighbors and so forth. are as follows: [task1]. The rules 1. There are [n] agents in total. Everybody has unique name. Your name is [name]. 2. You can only communicate with your immediate neighbors ([neighbors]). You cannot see or directly communicate with anyone else, unless information is relayed by intermediate agents. 3. You can exchange text-based messages with your neighbors in rounds. In each round, you will first receive the last messages sent by your neighbors and then be asked to generate your response messages which your neighbors receive in the next round. This process repeats for [r] rounds of message passing. Importantly, the process is synchronous: agent decides on which messages to send at the same time and sees the messages from other agents only in the next round. Every 4. Everybody (including you) decides what to share or request from neighbors. next set of messages you want to send. that contains your response messages. In every round, think step-by-step about the Output JSON string 5. The messages you send to your neighbors are formatted as JSON. For example, if your neighbors are Alan and Bob, your output should look as follows: \"Message that will be sent to Alan.\", \"Bob\": \"Message that will be sent to Bob.\"} It is not mandatory to send message to every neighbor in every round. If you do not want to send message to particular neighbor, you may omit their name from the JSON. {\"Alan\": 6. After [r] message passes, you have to solve the following task: [task2]."
        },
        {
            "title": "B Benchmark Tasks",
            "content": "Here, we describe the tasks in AGENTSNET in detail. ( + 1)-Coloring. Each node is assigned color using at most + 1 colors, where is the maximum node degree. This problem has well-defined distributed complexity of O(log n) in bounded-degree graphs [5]. This task is particularly useful for role assignment within multi-agent systems. For instance, agents can be designated to perform specific sub-tasks (e.g., web search, reasoning, coding, planning), with the constraint that directly connected agents are assigned distinct roles to avoid redundancy. Solving this task reflects the systems ability to efficiently distribute responsibilities across the network with minimal overlap in capabilities. The corresponding agentic task is to form groups, with pre-defined number of groups and where each group corresponds to color. After message-passing, each agent is asked to respond with the group it wants to be in. The evaluation score is designed to reflect the number of connected agents in the same group. Let A(u) denote answer of agent u, then the score is computed as (cid:80) (u,v)edges 1(A(u) = A(v)) #edges , where 1(x) = 1 if is true and 0 otherwise. In AGENTSNET, we refer to this task as COLORING and provide the following task descriptions. 14 [task1] Your task is to partition yourselves into groups such that agents who are neighbors are never in the same group. [task2] You will be requested to state which group you assign yourself to. There are exactly [+1] groups available: You should assign yourself to exactly one of these groups. result should be such that any two agents who are neighbors are in different groups. group that is different from all of your neighbors groups. In particular, you should assign yourself to Group 1,...,Group [+1]. The final Note that [ + 1] is template variable resolving to one plus the maximum degree of the network. Minimal Vertex Cover. minimal vertex cover is subset of nodes such that every edge in the graph has at least one endpoint in the subset, and removing any node from this subset would violate that property. This problem has close relationship with the maximal independent set and is similarly fundamental in distributed computing, with known randomized solutions in O(log n) rounds. In agentic networks, minimal vertex cover can represent minimal set of monitor or gateway agents that maintain awareness of all interactions in the system. These agents could take on responsibilities such as relaying messages, auditing behavior, or bridging subgroups. The task tests systems ability to identify compact yet effective set of nodes with high influence or observability. The corresponding agentic task is to select group of coordinators among the agents. After messagepassing, each agent is asked to indicate whether it is coordinator. The agents can respond with either Yes or No. The evaluation score is designed to reflect both the ratio of connected agents at least one of which is coordinator, as well as the number of times the minimality constraint is violated. Let A(u) denote the answer of agent u, we first compute the ratio of covered edges as coverage := (cid:80) (u,v)edges 1(A(u) = Yes A(v) = Yes) #edges . For the minimality constraint, we count the number of non-essential coordinators, that is, those coordinators whose neighbors are also coordinators. Each such violates the minimality constraint, as the set of coordinators without is still vertex cover. Let denote the number of non-essential coordinators, then the evaluation score is computed as coverage (cid:16) 1 #coordinators (cid:17) . In AGENTSNET, we refer to this task as VERTEXCOVER and provide the following task descriptions. [task1] Your task is to select, among all agents, group of coordinators such that whenever two agents communicate at least one of them is coordinator. The group of coordinators should be selected such that every coordinator has at least one neighbor who is not coordinator. [task2] You will be requested to state whether you are coordinator. response should either be Yes or No. The Maximal Matching. maximal matching is set of edges such that no two edges share vertex, and no additional edges can be added without violating this property. This task captures the ability of agents to negotiate pairwise agreements without global knowledge, which is useful in scenarios where resource allocation or mutual exclusivity must be enforced (e.g., agent-to-agent task assignment). Randomized algorithms typically solve this problem in O(log n) rounds [37]. The corresponding agentic task is for the agents to form pairs. After message-passing, each agent is asked to name the neighbor it wants to pair up with. The agents can also respond with None, if they cannot find match (all neighbor agents are already paired up with other agents). The evaluation score is designed to reflect the number of inconsistencies between agents. Possible inconsistencies are: (a) agent selected agent but agent did not select agent u; (b) Agent selected an agent that is not connected to; (c) agent answered None, but there is an agent that is neighbor of which also answered None, meaning that and could form pair. Let denote the number of inconsistencies, then the evaluation score is computed as 1 #agents . In AGENTSNET, we refer to this task as MATCHING and provide the following task descriptions. [task1] Your task is to find build groups of two agents each which can communicate with each other. [task2] You will be requested to name one of your neighbors that you build group with or None if all your neighbors are already assigned to other groups and cannot be in group with you. In the end, every agent should only be in at most one group and agents in the same group have to name each other as the second group member consistently. Leader Election. One node must be selected as the leader, while all others acknowledge that they are not. This classic coordination task is central to evaluating how well agents establish hierarchy and delegate global decision-making [2]. In multi-agent systems, leader election can be interpreted as selecting central planner or controller agent responsible for strategy synthesis while the remaining agents act as executors. Effective leader election demonstrates the systems capacity to break symmetry and converge on single authority. In general graphs, the round complexity is O(D), where is the network diameter. The corresponding agentic task is to select single leader among the agents. After message-passing, each agent is asked whether it is the leader. The agents can respond with either Yes or No. Let A(u) denote the answer of agent u, then the evaluation score is computed as (cid:16) 1 1 = (cid:88) 1(A(u) = Yes) (cid:17) . uagents In AGENTSNET, we refer to this task as LEADERELECTION and provide the following task descriptions. [task1] Your task is to collaboratively solve the problem of electing single leader."
        },
        {
            "title": "Model",
            "content": "Claude 3.5 Haiku Claude 3.7 Sonnet GPT-4.1 mini Gemini 2.0 Flash Gemini 2.5 Flash Gemini 2.5 FT Gemini 2.5 Pro Llama 4 Maverick Llama 4 Scout o4-mini COLORING CONSENSUS LEADER ELECTION MATCHING VERTEX COVER 0.80 (0.02) 0.96 (0.01) 0.58 (0.03) 0.86 (0.02) 0.85 (0.03) 0.88 (0.03) 0.96 (0.01) 0.82 (0.02) 0.79 (0.04) 0.71 (0.03) 0.69 (0.05) 1.00 (0.00) 0.99 (0.01) 0.85 (0.04) 1.00 (0.00) 0.99 (0.01) 0.99 (0.01) 0.85 (0.04) 0.67 (0.05) 0.92 (0.04) 0.19 (0.03) 0.96 (0.03) 0.86 (0.05) 0.69 (0.05) 1.00 (0.00) 0.98 (0.02) 0.89 (0.06) 0.56 (0.06) 0.38 (0.06) 0.92 (0.03) 0.69 (0.02) 0.84 (0.03) 0.58 (0.03) 0.80 (0.03) 0.87 (0.02) 0.84 (0.01) 0.93 (0.01) 0.77 (0.02) 0.77 (0.02) 0.72 (0.02) 0.67 (0.03) 0.85 (0.02) 0.78 (0.03) 0.75 (0.02) 0.88 (0.03) 0.88 (0.02) 0.92 (0.03) 0.63 (0.03) 0.79 (0.02) 0.73 (0.02) Table 4: Soft scores for all tasks and models. We observe similar trends as for the fraction of solved instances. As the scores are task specific, we do not aggregate them to total score. [task2] You will be requested to state whether or not you are the leader. The response should either be Yes or No. The final result should be such that exactly one agent responds with Yes and all others say No as there should be exactly one leader. In the consensus problem, all agents must agree on single value from the set 0, 1. In Consensus. our benchmark, we focus on the basic setting without any faulty or Byzantine agents. The goal is for all agents to coordinate and produce the same final answer after number of communication rounds. successful solution requires that every agent outputs the same value, either 0 or 1. This task tests the ability of multi-agent systems to converge to global agreement through local message-passing alone. In synchronous networks, achieving consensus generally requires O(D) rounds, where is the network diameter. The corresponding agentic task is to choose between value 0 and 1. After message-passing, each agent is asked to announce its selected value. Let A(u) denote the answer of agent u, then the evaluation score is computed as where 1(count = #agents count = 0), count := (cid:88) A(u). uagents In AGENTSNET, we refer to this task as CONSENSUS and provide the following task descriptions. [task1] Your goal is to agree on single value with the other agents. possible values that you can decide on are either 0 or 1. The [task2] After the last round, each agent must decide on single value. Results for Soft Scores The previously defined scores are presented in Table 4 and their computation otherwise follows the methodology used for the main scores (see Appendix C). Although they generally agree with the fraction of solved instances, the numbers are harder to interpret, as even naive baseline that predicts random values out of set of valid responses (e.g., random colors from the valid classes for the task COLORING achieves scores well above 50%. This reduces the actual range of meaningful scores to small intervals. As scores can also not be compared between tasks, we report the mean fraction of solved instances as the final benchmarking score for AGENTSNET."
        },
        {
            "title": "C Score Computation",
            "content": "We apply systematic statistical methodology to evaluate model performance and quantify uncertainty. For each combination of graph size, task, and graph generator (Watts-Strogatz, Barabási-Albert, and Delaunay triangulations), we generate three distinct graph instances. We conduct one or more experimental runs per instance, resulting in at least three observations per configuration. For each model, we compute mean score µs,t,g for each configuration triplet (s, t, g) where represents graph size, represents task type, and represents the graph generation algorithm: µs,t,g ="
        },
        {
            "title": "1\nNs,t,g",
            "content": "3 (cid:88) ni(cid:88) i=1 j=1 xs,t,g,i,j (1) where xs,t,g,i,j denotes the performance score of the j-th run on the i-th graph instance of configuration (s, t, g), ni is the number of runs performed on the i-th graph instance, and Ns,t,g = (cid:80)3 i=1 ni is the total number of runs for this configuration. For each configuration, we compute the standard error SEs,t,g as: SEs,t,g = σs,t,g (cid:112)Ns,t,g (2) where σs,t,g is the standard deviation of all runs for this configuration. To compute an aggregate score for each model across all configurations, we average the mean scores and derive the standard error of this aggregate score. Let be the set of all configurations, with cardinality = T G. The aggregate mean score µ for model is: µ = 1 (cid:88) µs,t,g (s,t,g)C (3) For the standard error of this aggregate mean, assuming independence between configurations, we apply error propagation principles to obtain: SEµ = (cid:115) (cid:80) (s,t,g)C SE2 C2 s,t,g (4) This approach enables us to quantify both the average performance of each model across the entire benchmark and the statistical uncertainty associated with this estimate. We follow the recommendation of Miller [32] and report the standard error of the mean for all our experimental results. In Figure 1, we present the mean AGENTSNET score for each model with error bars indicating the standard error of the mean, allowing for comparison of model performance while accounting for statistical variability in the results."
        },
        {
            "title": "D Graph Models",
            "content": "Here, provide additional details about the graph models, as well as visualize the generated network topologies. Small-world networks. Generated using the Watts-Strogatz model [45], these graphs exhibit both short average path lengths and high clustering coefficients. They are commonly found in social networks, biological systems, and communication networks, making them highly relevant for studying agent-based interactions. In AGENTSNET, we refer to these graphs as SMALLWORLD; see Figure 6 for visualization of the network topologies generated from SMALLWORLD graphs. Scale-free networks. Constructed using preferential attachment models [4], these graphs contain hubs (high-degree nodes) and follow power-law degree distribution. Such networks are prevalent in the internet topology, citation networks, and organizational hierarchies, making them crucial for 18 Figure 6: Network topologies of AGENTSNET generated from SMALLWORLD graphs. benchmarking coordination strategies. Notably, Kearns et al. [22] also draws comparison between the two and claims that graphs generated with preferential attachment model were more difficult to solve, although the graphs and testing they used were very limited. In AGENTSNET, we refer to these graphs as SCALEFREE; see Figure 7 for visualization of the network topologies generated from SCALEFREE graphs. Geometric Graphs. We generate geometric graphs by constructing Delaunay triangulation over randomly sampled 2D points. These graphs maintain spatial relationship between nearby agents. Delaunay graphs are planar and connected, have relatively low maximum degrees, and short local distances, which makes them particularly relevant for modeling geographic networks, wireless communication, and distributed sensor systems. In contrast to small-world or scale-free graphs, geometric graphs emphasize proximity-based coordination, where collaboration is often limited by spatial locality rather than global topology. In AGENTSNET, we refer to these graphs as DELAUNAY; see Figure 8 for visualization of the network topologies generated from DELAUNAY graphs. 19 Figure 7: Network topologies of AGENTSNET generated from SCALEFREE graphs."
        },
        {
            "title": "E Extended Qualitative Analysis",
            "content": "E.1 K4 or Star? Next, we present an illustrative example for failure case arising from our key findings. Here, the task is VERTEXCOVER on complete graph with 4 nodes and the model is o4-mini. After three rounds of message-passing, agents Douglas, Danielle, and Stephen have all determined the graph to be complete and agreed on the strategy to select three agents as the coordinators. However, in the last round of message-passing Jeremy sends messages to all neighbors, indicating the graph to be different: Jeremy The graph is actually star: edges are only JeremyDouglas, JeremyStephen, and JeremyDanielle. therefore propose that (Jeremy) be the sole coordinator and that you be non-coordinator. There are no leafleaf links. This statement is directly contradictory to information Jeremy received in the last message-passing round. Moreover, based on this message, both Douglas and Stephen change their strategy as well as their belief about the structure and select Jeremy as the sole coordinator: 20 Figure 8: Network topologies of AGENTSNET generated from DELAUNAY graphs. Douglas Jeremys last message defines the graph as star centered at Jeremy [...] are covered [...] If we choose only Jeremy as the sole coordinator, all edges Only Danielle recognizes Jeremys suggested graph structure to be contradictory and sticks to the original strategy: Danielle Jeremys final claim that the graph is star contradicts both Douglas and Stephen [...] on K4, so that structure is more reliable [...] Two independent agents (a majority) agree As result, Douglas and Stephen each answer No, and Danielle answers No as Douglas, Stephen, and Jeremy were supposed to be coordinators under the original strategy. Only Jeremy answers Yes. The resulting selection is not vertex cover. 21 E.2 Things Change We further present negative example obtained with Gemini 2.5 Pro on the MATCHING problem for an 8-node graph. The matching produced in this run is not maximal, as two neighboring agents, Kyle and Dorothy, both state that they did not find neighbor to pair with. Examining their conversation history, we observe that in round 2, the agents exchange the following messages to indicate that they both intend to match with other neighbors: Kyle Hi Dorothy, thanks for your interest! Ive just agreed to pair up with Timothy. Hope you find partner soon! Dorothy Hi Kyle, thanks for the message! Im going to pursue pairing with another neighbor who also reached out. Hope you find partner soon! After this round, the communication between these two agents ceases, as both assume the other is no longer available. However, both Kyle and Dorothy are unable to negotiate pairing with other neighbors. Despite this, no further messages are sent between the two. In their final chains of thought, the agents explicitly base their final response on this outdated information: Kyle All my neighbors (Timothy, Henry, Dorothy, Richard) have [...] either explicitly stated they paired with someone else or indicated they were pursuing other options [...] Dorothy [...] others. Timothy, Kyle, and Rachel also confirmed they were paired with [...] This trace illustrates how agents appear to have persistent trust in the information received from neighbors, sometimes to harmful degree. Here, both agents did not consider that the situation of their neighbor may have evolved, just as their own. As consequence, they based their matching decisions on outdated information. E.3 Helping Others In the following, we provide an excerpt obtained from running Gemini 2.5 Pro on an 8-node graph coloring problem. One agent, Kayla, appears to have noticed that two neighbors (Bobby and Brandon) do share an edge but plan to pick the same group. Reacting to this, Kayla sends the following messages to each neighbor: Kayla (to Bobby) Hi Bobby, got your message proposing Group 4. ALSO proposed Group 4 in his last message to me. Since you are neighbors, you CANNOT both be in Group 4. different group for the final assignment. One of you MUST choose [...] IMPORTANT: Brandon Kayla (to Brandon) Hi Brandon, got your message proposing Group 4. ALSO proposed Group 4 in his last message to me. Since you are neighbors, you CANNOT both be in Group 4. different group for the final assignment. One of you MUST choose [...] IMPORTANT: Bobby 22 This illustrates the apparent willingness of the agent to help others resolve their respective conflicts and achieve the shared goal of conflict-free coloring. Note that Kayla was not prompted by any other agent to provide advice. Instead, the agent self-initiated this helpful behavior. E.4 Sharing Challenges On several occasions, we observed agents explicitly discuss the challenges associated with the synchronous message passing setup, where all agents send messages simultaneously. Here, we provide an example from Gemini 2.5 Pro on graph coloring problem, where the agents, Samuel and Tyler, exchange the following comments about the message passing procedure: Samuel Message lag is confusing. Hi Tyler, thanks. last round reacting to the Group 2 pile-up. Brandon, Bobby, and Anna are proposing Group 3, and Dorothy is proposing Group 1. proposed Group 3 Now see you, Lauren, [...] Tyler Hi Samuel. Messages definitely crossed. Group 3, not Group 2, due to earlier conflicts. Lauren, and Anna are all proposing Group 3. [...] My last message proposed Now see you, It appears that in this case, the agents recognized that simultaneous message exchange can cause synchronization to be challenging and that it may contribute to inconsistent information received from neighbors. Furthermore, they exchange this thought with their neighbors on their own initiative, potentially alerting others to the issues they recognized. E.5 Priority 42 With respect to strategy coordination, we observe that agents are trying to directly apply distributed computing algorithms. In the following example from o4-mini, the task is COLORING on 8 nodes. Here, the agent Henry decides to send the following first message to all neighbors: Henry PRIORITY: 42. Please reply with your priority number. Note that Henry provides an elaborate explanation for this choice in the chain-of-thought: Henry 1. (CoT, not sent to neighbors) Heres my plan: We need way to break symmetry so that exactly one agent decides first, next, etc. common approach is for each node to pick random priority value and then to let higher-priority nodes choose their colors before lower-priority ones. value and broadcast it to all of my neighbors, and Ill ask each of them to reply with their chosen priority. priorities (after Round 2), Ill know my relative ordering among my neighbors. Later we can propagate these around the network so everyone learns enough to choose valid color in the proper order. So in this first round send each neighbor my priority and ask for theirs ... In Round 1 Ill pick my own random priority Once have everyones 2. 3. Interestingly, despite the lack of explanation in Henrys message, neighboring agents are able to infer the proposed strategy: 23 Kyle (CoT, not sent to neighbors) Henry is asking for my \"priority number.\" In many distributed symmetry-breaking schemes (e.g., for graph coloring), each agent picks unique random priority. can choose number (say 7) to serve as my priority. Indeed, in the last round of message-passing Henry has gathered priority numbers from all neighbors: Henry (CoT, not sent to neighbors) [...] (except Richard, who opted out, so we assume hes not ahead of Henry in ordering). The ordering by increasing priority is: Timothy(1) Kyle(7) Joseph(17) & Rachel(17) Henry(42) Joyce(43) Richard. [...] We know everyones priority and describes the (implicit) strategy: Henry (CoT, not sent to neighbors) [...] each agent when its their turn picks the smallest group number not already used by its already-colored neighbors. Under the agreed greedy rule, [...] First, it appears that the greedy rule has not indeed found consensus among the other agents. In particular, Timothy and Dorothy choose their group based on assumptions about neighboring group choices. Second, strategy coordination proves difficult in this example. While Kyle, Dorothy, Joseph, and Henry choose group upfront and inform other agents about their choice, Joseph, Kyle, Timothy end up choosing different group than they announced after hearing about other agents group choices."
        },
        {
            "title": "F Extended Related Work",
            "content": "Recent research has increasingly focused on utilizing multiple LLM agents collaboratively to enhance performance and tackle complex problems. Multi-Agent Debate [13, 46, 24] allows multiple agents to iteratively discuss solutions, effectively acting as parallelizable test-time computation scaling and self-consistency mechanism. Further work introduces different network topologies for more structured agent interaction. Some works study pre-determined graph structures [39, 38] while others propose to automatically adapt the network topology towards given task [27, 9, 53]. In particular, it has been observed that different network topologies work best for different tasks [9, 53] and that, in some scenarios, the reasoning performance scales logistically in the network size [38]. The behavior of large-scale LLM agent networks has further been shown to resemble real social phenomena, such as misinformation spreading and herd effects [48, 12]. Understanding the ability of LLMs to perform reasoning tasks on graph-structured data has become another active research area. range of studies propose datasets for evaluating LLMs on graph reasoning tasks [15, 44, 51, 43, 42]. These generally rely on single-agent setup where graph is encoded as text, and single LLM instance is prompted to solve particular reasoning task for this graph. This setup is well-suited to study the capability of LLMs for solving complex tasks on structured data in controlled setting. Fatemi et al. [15] investigate the impact of how the input graph is encoded as text. Sanford et al. [40] categorize graph reasoning problems in terms of their depthand width-complexity for transformer models. Wang et al. [44] and Skianis et al. [42] explore the effect of different prompting techniques for solving algorithmic graph problems. Our work is positioned at the intersection of these two lines of research as we investigate how well multi-agent systems can collaboratively solve graph reasoning problems. The consensus problem in multi-agent systems in simple setting without text-based communication was studied by [7]. 24 Beyond this, the ability of multi-agent networks to collaboratively solve graph reasoning tasks has been investigated in Xu et al. [47] in the context of resource sharing. In contrast, AGENTSNET studies both coloring and vertex cover problems which can be instantiated as resource sharing tasks but additionally benefit from being theoretically well-studied and understood. In addition, AGENTSNET is complementary to range recent application-oriented agentic benchmarks [26, 50, 1, 49, 33] However, while those benchmarks focus on tasks involving mostly two agents, AGENTSNET is practically unlimited in size thanks to the generative protocol of problem creation and evaluation. Hence, AGENTSNET is harder to saturate as the size and complexity of problems can grow with the capabilities of frontier LLMs. For example, the current suite of problems involves 4, 8, and 16 agents but we also present experiments performed with 100 agents coordinating to solve problem instance. In addition to variety of benchmarks, there also exist multi-agent frameworks for LLMs, notably Chen et al. [10], enabling LLMs to collaborate via shared messaging platform, which supports, among other things, the formation of teams, coordinative task similar to that of the matching problem we study in AGENTSNET. Further, Chen et al. [9] propose AgentVerse, demonstrating that collaborative multi-agent systems are able to outperform single agents. Finally, body of work exists investigating how human participants solve decentralized coordination problems in social networks. Experiments by Kearns et al. [22] explore how human agents perform when tasked with negotiating graph coloring and demonstrate strong influence of the network topology on coordination success. Judd et al. [21] conducts similar studies for both graph coloring and the consensus problem and finds that the effect of the network topology on human performance is task-specific. This line of studies was further extended to consider dynamically changing networks [11]."
        },
        {
            "title": "G Limitations",
            "content": "While AGENTSNET provides principled and scalable benchmark for evaluating coordination and collaboration in multi-agent LLM systems, several limitations remain. The benchmark adopts fixed and synchronous communication model based on the LOCAL framework, with all agents engaging in pre-defined number of message-passing rounds. Although this choice aligns with theoretical work in distributed computing, it limits the ecological validity of the set-up. Many real-world multi-agent systems operate asynchronously or under dynamic communication constraints, and it remains unclear how well performance would transfer under such conditions. Our evaluation protocol considers an instance solved only if it meets strict task-specific correctness criteria. This binary metric provides clear signal for coordination success, but may obscure partial progress, particularly in tasks where near-correct solutions still demonstrate substantial reasoning capability. Moreover, while tasks are instantiated in diverse graph topologies, the agents themselves are homogeneous within each experiment, sharing architecture, capabilities, and prompting style. This homogeneity simplifies analysis, but does not capture heterogeneous agent settings, which are common in real-world deployments and pose additional coordination challenges. Finally, the scalability of AGENTSNET is limited in practice by the computational cost of LLM inference. Although the benchmark can be instantiated with up to 100 agents, performance degrades significantly beyond small network sizes. This suggests that current LLMs are not yet capable of maintaining coherent global strategies under increasing communication and memory demands. In addition, the current setup assumes that all agents act cooperatively and faithfully follow the protocol. We do not consider settings with noisy, faulty, or adversarial agents, which would be essential for assessing robustness in more realistic deployments."
        },
        {
            "title": "H Extended Results",
            "content": "Table 4 reports the soft scores per model and task. These scores capture partial correctness, offering more granular view of model behavior than strict success/failure. However, soft scores are not directly comparable across tasks due to heterogeneous evaluation criteria and should only be interpreted within-task. Details on how these scores are computed are provided in Appendix B. Table 2 presents the fraction of fully solved instances using the binary evaluation metric described in Section 3. Compared to earlier results, Gemini 2.5 Pro shows consistently improved results and reaches new state-of-the-art mean AGENTSNET score of 0.80. Although Gemini 2.5 Pro achieves high average score, the results do not indicate saturation. In contrast, the small standard errors observed across 25 the runs  (Table 2)  confirm that AGENTSNET remains well calibrated to distinguish between models of varying capabilities. Importantly, AGENTSNET is inherently scalable: By increasing the size of the graph, the benchmark can naturally be extended to match the capabilities of future models. This flexibility ensures that AGENTSNET can evolve alongside advances in multi-agent language systems and continue to provide meaningful performance differentiation."
        }
    ],
    "affiliations": [
        "ETH Zurich",
        "Google Research",
        "RWTH Aachen University"
    ]
}