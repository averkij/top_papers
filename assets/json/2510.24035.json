{
    "paper_title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research",
    "authors": [
        "Xinqi Li",
        "Yiqun Liu",
        "Shan Jiang",
        "Enrong Zheng",
        "Huaijin Zheng",
        "Wenhao Dai",
        "Haodong Deng",
        "Dianhai Yu",
        "Yanjun Ma"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We introduce GraphNet, a dataset of 2.7K real-world deep learning computational graphs with rich metadata, spanning six major task categories across multiple deep learning frameworks. To evaluate tensor compiler performance on these samples, we propose the benchmark metric Speedup Score S(t), which jointly considers runtime speedup and execution correctness under tunable tolerance levels, offering a reliable measure of general optimization capability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t), which incorporates error information and helps compiler developers identify key performance bottlenecks. In this report, we benchmark the default tensor compilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer vision (CV) and natural language processing (NLP) samples to demonstrate the practicality of GraphNet. The full construction pipeline with graph extraction and compiler evaluation tools is available at https://github.com/PaddlePaddle/GraphNet ."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 2 ] . [ 1 5 3 0 4 2 . 0 1 5 2 : r GraphNet: Large-Scale Computational Graph Dataset for Tensor Compiler Research Xinqi Li* Yiqun Liu Shan Jiang Enrong Zheng Huaijin Zheng Wenhao Dai Haodong Deng Dianhai Yu Yanjun Ma PaddlePaddle Team, Baidu Inc."
        },
        {
            "title": "Abstract",
            "content": "We introduce GraphNet, dataset of 2.7K real-world deep learning computational graphs with rich metadata, spanning six major task categories across multiple deep learning frameworks. To evaluate tensor compiler performance on these samples, we propose the benchmark metric Speedup Score St, which jointly considers runtime speedup and execution correctness under tunable tolerance levels, offering reliable measure of general optimization capability. Furthermore, we extend St to the Error-aware Speedup Score ESt, which incorporates error information and helps compiler developers identify key performance bottlenecks. In this report, we benchmark the default tensor compilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer vision (CV) and natural language processing (NLP) samples to demonstrate the practicality of GraphNet. The full construction pipeline with graph extraction and compiler evaluation tools is available at https://github.com/PaddlePaddle/GraphNet."
        },
        {
            "title": "1 Introduction",
            "content": "The development of high-performance GPU kernels has become critical for computational efficiency in modern deep learning workloads. widely adopted approach integrates deep learning frameworks, such as PaddlePaddle[8] and PyTorch[14], with vendor-specific operator libraries (e.g., cuDNN [2], oneDNN [12]). However, emerging hardware featuring low-precision formats (e.g., BF16[19], FP8[10]) and advanced memory access patterns is creating growing demand for custom operators-a demand that vendor-specific libraries often struggle to accommodate. To meet these demands, modern deep learning systems increasingly rely on tensor compilers (e.g., TVM [1], XLA [6], BladeDISC [21]) to lower high-level computational graphs into efficient backend implementations for heterogeneous hardware platforms. Despite these advances, deep learning engineers still rely heavily on manual tuning, as existing tensor compilation frameworks often lack fine-grained hardware control and offer limited support for crossplatform complex algorithms. Meanwhile, researchers are increasingly exploring the use of large language models (LLMs) [13] and AI coding agents [18] to automatically generate efficient operators and kernels. In this challenging context, systematic evaluation of existing tensor compilers is essential to identify performance bottlenecks and guide the evolution of next-generation compilers. Existing benchmarks are often ad hoc, relying on small set of hand-picked samples, with limited coverage of up-to-date, real-world models from the community and lacking sufficient support for cross-framework evaluation. To address these limitations, we introduce GraphNet, large-scale dataset of deep learning computational graphs designed to enable systematic evaluation of tensor compilers across tasks and frameworks. We further propose unified metric to benchmark compiler performance by jointly accounting for runtime speedup, numerical correctness, and compilation failures. Our main contributions are as follows: *Corresponding author: lixinqi04@baidu.com 1 We collected over 2.7k computational graphs from real-world models, covering diverse task categories and mainstream frameworks (e.g., PaddlePaddle, PyTorch). All samples are stored in unified format and are compatible with multiple tensor compiler backends. We evaluate the performance of CINN[17] and TorchInductor on CV and NLP samples from GraphNet, and propose the Speedup Score (St) to measure the general optimization capability of tensor compilers, as well as the Error-aware Speedup Score (ESt), which accounts for all types of execution failures. We present detailed study of the dataset construction pipeline and sample constraints, and release the GraphNet dataset along with open-source extraction and evaluation tools. The rest of this paper is organized as follows. Section 2 introduces dataset properties and its distribution. Section 3 presents the design of our evaluation metric and discusses experimental results. Section 4 describes the dataset construction methodology. Sections 5 and 6 review related works and outline future directions."
        },
        {
            "title": "2 Dataset Properties",
            "content": "Authenticity: All samples are extracted from models in mainstream deep learning frameworks, focusing on PaddlePaddle libraries (e.g., PaddleNLP, PaddleX, PaddleScience) and PyTorch libraries (e.g., TorchVision, timm, mmseg). These libraries are actively maintained and widely adopted by the community, ensuring that GraphNet reflects real-world workloads rather than synthetic benchmarks. Compatibility: GraphNet samples adopt standardized format that integrates computational graphs with inputs, weights, and custom operators. This format preserves complete computation semantics without information loss, ensuring compatibility with diverse compiler backends, including CINN (PaddlePaddle), TorchInductor (PyTorch), XLA (TensorFlow), TVM, BladeDISC, and TensorRT. This enables fair and reproducible evaluation, as well as seamless extensions to new compilers. Diversity: The dataset spans six major task categories: computer vision, natural language processing, audio, multimodal learning, scientific computing, and others. Models vary in scale from few thousand to 10B parameters, with the most complex sample containing up to 3,686 operators. GraphNet also supports multiple data types, such as BF16, FP16, and FP32, which are essential for evaluating compiler optimizations across different numerical precisions and hardware backends."
        },
        {
            "title": "3.1 Compiler Evaluation",
            "content": "We introduce an automated compiler evaluation workflow that enables unified and repeatable testing of multiple tensor compilers. The evaluation takes GraphNet samples as input and consists of the following key steps: 1. Baseline Execution: Execute the original model in Eager mode on given framework and record its output and execution time Teager as the baseline for subsequent comparisons. 2. Compiler Configuration: Compile the original model into an optimized executable by specifying the target compiler. Currently supported compilers include CINN, TorchInductor, XLA, TVM, BladeDISC, and TensorRT. 3. Compiled Execution: Execute the compiled model after warmup phase to eliminate cold-start overhead and obtain the pure execution time Tcompiled. Record its output to verify accuracy. 2 (b) Operator Numbers of CV Models (a) Categories of Computational Graph Figure 1: Statistical properties of the GraphNet dataset. (a) The distribution of computational graphs across six major task categories, showing that Computer Vision (47.8%) and Natural Language Processing (39.5%) are the dominant domains. (b) and (c) Histograms showing the distribution of operator counts (on log2 scale) for CV and NLP models, respectively. Both categories show high concentration of graphs with operator counts around 29 (512). (c) Operator Numbers of NLP Models 4. Performance Analysis: Compare the outputs collected from baseline and compiled execution to validate correctness. Quantify compiler performance by considering speedup ratio Teager/Tcompiled, execution correctness, and performance degradation. The details of the evaluation metrics are discussed in Section 3.2."
        },
        {
            "title": "3.2 Evaluation Metrics",
            "content": "We design two distinct metrics: one for benchmarking tensor compilers and one for compiler development. The benchmarking metric, detailed in Section 3.2.1, focuses primarily on acceleration and treats the error penalty as fixed constant. The development metric (Section 3.2.2), exposes detailed error penalty information, allowing developers to configure it on demand. 3.2.1 Metrics for Compiler Benchmark The performance evaluation metric is parameterized by tunable tolerance t, which enables the metric to capture compiler performance under varying correctness criteria, from strict numerical precision to more relaxed settings. Tolerance determines whether sample is considered correctly executed, based on the check assert_close(x, y, rtol(t), atol(t)). The values of relative tolerance (rtol) and absolute tolerance (atol) corresponding to different settings and data types are summarized in Appendix A. Based on tolerance and its associated correctness criteria, we define the Speedup Score St as unified metric that combines speedup, accuracy, and penalty factors, providing comprehensive measure of compiler performance: St = αλ βλη b1λ (1) For readability, we omit the explicit (t) notation in this expression, while noting that α, β, λ, and η are all dependent on the tolerance t. Eq. (1) can be viewed as the product of three components: 3 Correct executions: αλ where α is the geometric mean speedup of all correctly executed samples, and λ is the fraction of correctly executed samples, weighting the contribution of this component. Performance degradation: βλη where η is the fraction of correctly executed samples that have speedup < 1 (i.e., slowdowns among correct executions), β is the geometric mean speedup of these slowdown cases, and (0, 1) is the penalty (default 0.1) applied to emphasize their impact. Failures: b1λ where 1 λ denotes the fraction of samples that execute incorrectly (tolerance violations, compilation failures, or runtime crashes), and (0, 1) is the penalty factor (default 0.1). The equivalence between the macro formulation and its sample-level interpretation is formally proven in Proposition B.1 (Appendix B). Experiment Result: We conducted experiments on the NVIDIA H20 GPU using CV and NLP samples from GraphNet, evaluating CINN (the default compiler backend of PaddlePaddle) and TorchInductor (the default compiler backend of PyTorch) on their respective frameworks. As the workloads originate from their native ecosystems, we refer to the two settings as PaddlePaddle and PyTorch in the following discussion. Detailed experimental settings, including framework versions, are summarized in Appendix D. Figure 2: Speedup Score St on NVIDIA H20 for CV and NLP workloads. The vertical axis shows St, which integrates speedup, pass rate, and failure penalties into unified score. Higher St indicates better compiler performance under the correctness-aware speedup metric defined in Equation 1. The horizontal axis represents different numerical tolerance levels used for correctness checks, where larger implies more relaxed thresholds. As shown in Figure 2, the St trajectories exhibit distinct trends across workloads and compiler configurations. For both PaddlePaddle-NLP (blue) and PyTorch-NLP (green), St remains low under strict tolerances (t 7) but rises sharply within [6, 5], indicating that most samples pass the correctness check once the tolerance is slightly relaxed. Both compilers converge to similar peak values around St 1.2 at = 0, with PaddlePaddle achieving marginally higher score. In contrast, PaddlePaddle-CV (orange) exhibits smoother performance increase from = 7 to = 0, whereas PyTorch-CV (red) reaches peak St 0.8 at = 5. and then plateaus. This flat trajectory suggests that increasing the tolerance further (beyond = 5) no longer improves the score by resolving accuracy issues, which implies that its accuracy-related failures are effectively resolved at this point. However, its performance score remains constrained by an upper bound well below 1.0, indicating heavy penalties from either widespread execution failures or performance degradation (slowdowns). While the St score reflects this combined impact, it does not separate these root causes. This breakdown is provided by the development metrics in the following section. 4 3.2.2 Metrics for Compiler Development For compiler developers, error information from incorrectly executed samples is crucial. To encode this information into the evaluation metric, we reinterpret the positive tolerance domain (0, +) to represent discrete levels of error tolerance. We assign error codes {1, 2, 3} to accuracy errors, runtime crashes, and compilation failures, respectively. The metric then tolerates errors based on the level t: 1 tolerates accuracy errors (c = 1), 2 additionally tolerates runtime crashes (c = 2), and 3 tolerates all failures (c = 3). Based on these discrete tolerance levels and error codes, we extend the fixed penalty factor in St (Eq. 1) to tolerance-dependent form γt: γt = 1(t<c))πc = bc πc 1(t<c) (b (2) where {1, 2, 3} is the error code, πc denotes the proportion of error code among all erroneous samples, and 1() is an indicator function. As increases, more error types are tolerated and γt monotonically increases from to 1. With γt defined, we obtain the Error-aware Speedup Score: ESt = αλ βλη γ1λ (3) For 0, ESt reduces to the original St. As grows over the positive domain, more categories of errors are tolerated and ESt increases monotonically. When all errors are tolerated (t 3), ESt reaches its maximum, representing the theoretical upper bound of achievable compiler performance. Appendix analyzes the sample-level meaning of ESt. Experiment Result: We obtain ESt under the same conditions as in Section 3.2.1, as shown in Figure 3. Figure 3: Error-aware Speedup Score ESt for CV and NLP workloads. The vertical axis shows ESt values, capturing compiler performance with increasing fault tolerance. Higher ESt indicates better compiler performance under the error-tolerant speedup metric defined in Equation 3. The horizontal axis represents different tolerance levels: for 0, it reflects numerical correctness thresholds (as in St); for > 0, it encodes the categories of tolerated errors: 1 tolerates accuracy mismatches, 2 tolerates runtime crashes, and 3 tolerates compilation failures. In Figure 3, PaddlePaddle-CV (orange) exhibits discrete jump from = 0 to = 1, indicating that portion of its failures are due to substantial accuracy violations that are tolerated once 1. Jumps also occur at = 3 for both PyTorch-NLP (green) and PaddlePaddle-NLP (blue), revealing that fraction of samples fail due to compilation errors. Notably, PyTorch-CV (red) shows sharp rise at = 3, suggesting that large number of its samples do not pass the compilation stage. 5 Finally, when 3, ESt no longer incorporates any penalties for accuracy violations, runtime crashes, or compilation errors, and thus reflects the raw speedup score the theoretical upper bound of compiler performance. PyTorch-CV ultimately plateaus around ESt 1.0, indicating that even with all failures ignored, its average performance is neutral. This suggests many of its samples are negatively optimized (i.e., compilation leads to slower execution). As shown in Figure 6 (Appendix D), the distribution of per-sample speedups confirms that PyTorch-CV contains substantial number of negatively optimized samples. While St and ESt provide an aggregated view of compiler performance, Tables 36 in the appendix provide detailed values of each component (α, β, λ, η, γ), offering fine-grained view of how St and ESt are constructed."
        },
        {
            "title": "4 Construction of GraphNet",
            "content": "GraphNet provides unified workflow for automated graph extraction, validation, and cross-backend performance evaluation. This section details the dataset requirements and construction methodology."
        },
        {
            "title": "4.1 Dataset Constraints",
            "content": "We define five constraints applied to every computational graph in GraphNet to ensure overall dataset quality and cross-platform compatibility. These constraints act as validation requirements during dataset construction, ensuring consistency and usability at the source. Specifically, all computational graphs must satisfy the following constraints: Runnable: Each computational graph must successfully execute forward propagation under the designated framework without syntax errors, type mismatches, or runtime crashes. Serializable: Each sample and its associated metadata (e.g., input shapes, weight parameters) must be serializable into standard formats (e.g., JSON) and correctly de-serializable upon reloading. Decomposable: The entire computational graph must be decomposable into multiple non-overlapping subgraphs, where each subgraph represents an independent optimization unit. This supports compiler backends in performing fusion, scheduling, and other optimization tasks. Statically Analyzable: The name, type, attributes, and dependency relations of all operators must be statically extractable (e.g., via torch.fx) without model execution. This allows automated analysis tools to fully interpret operator semantics for structural traversal and pattern matching. Custom Operator Accessible: If sample includes user-defined custom operators, the corresponding source code for these operators must be traceable and accessible in modular form, ensuring reusability and integration across compiler environments. Remark: At the time of writing, the first three constraints (Runnable, Serializable, and Statically Analyzable) are strictly enforced by our current validation pipeline. The remaining two (Decomposable and Custom Operator Accessible) are actively under development and represent our roadmap for expanding the datasets capabilities."
        },
        {
            "title": "4.2 Construction Methodology",
            "content": "GraphNet provides an automated workflow for collecting computational graphs across multiple platforms while enforcing the constraints introduced in Section 4.1. The dataset construction pipeline, illustrated in Figure 4, consists of two primary components: graph extraction and graph validation. 6 Figure 4: GraphNet Workflow Overview. The workflow consists of three stages: (1) Graph Extraction: Traces and captures computational graphs from DL models (e.g., PaddlePaddle, PyTorch); (2) Graph Validation: Performs consistency check via re-extraction and re-execution to ensure usability; and (3) Compiler Evaluation: Uses the validated graphs from the dataset to benchmark the runtime speedup and correctness of various compiler backends. 4.2.1 Graph Extraction We design lightweight extraction mechanism that captures dynamic computational graphs from real models and saves them as standardized GraphNet samples. As illustrated in the \"Graph Extraction\" component of Figure 4, we first create Python decorator-based interfaces, including graph_net.paddle.extract and graph_net.torch.extract. Users can wrap the target model with the extractor, which automatically triggers the graph extraction process at runtime. During execution, the extractor employs symbolic tracing and dynamic graph tracking mechanisms built into the framework to capture all operator invocations and tensor dependencies, thereby generating complete dynamic computational graph. The captured graph is stored as standardized set of files (as shown in Figure 5), which encompasses the high-level IR of the computational graph in model.py, weights and input metadata, and optional custom operator implementations. Together, these components form complete GraphNet sample. 4.2.2 Graph Validation To ensure that the extracted data meets the dataset constraints, we adopt re-extraction and re-execution mechanism during the validation stage. This workflow, illustrated in the center of Figure 4, consists of four steps: First, the validator takes an extracted sample (the original computational graph) and deserializes it into an executable Python function, reconstructing the model structure with its input and weight metadata. Second, the reconstructed model is executed to verify that the computational graph is runnable. Third, the validator performs the extraction process again on the reconstructed model, producing second computational graph B. Finally, the validator repeats the reconstruction and execution on graph B, comparing its outputs with those from the second stage and checking for structural and node-level consistency between graphs and B. This validation procedure inherently enforces all dataset constraints. Failures in serialization or deserialization terminate the reconstruction process; non-runnable models are detected during execution; and inaccessible custom operator code interrupts re-extraction. In addition, the consistency check guarantees that static analysis of all operators is performed completely and correctly. GraphNet also incorporates graph deduplication mechanism during data collection to eliminate redundancy. For each extracted computational graph, unique graph hash value is generated from the models 7 source code and graph topology. The validator then identifies and removes duplicate samples by comparing their hash values, ensuring that only distinct computational graphs are retained in the final dataset. Figure 5: GraphNet Sample Composition. users model (left), wrapped by the @graph_net extractor, is symbolically traced to generate standardized set of files. This set forms complete sample, including the high-level IR of the computation graph (model.py), metadata for inputs and weights (input_meta.py, weight_meta.py), and other components such as optional custom operator code."
        },
        {
            "title": "5 Background and Related Works",
            "content": "Tensor Compiler: Tensor compilers[7] transform high-level computation graphs into optimized devicespecific kernels through IR lowering and scheduling. Systems such as TVM [1] and Ansor [20] represent search-based compilers that rely on auto-tuning with cost models, while XLA [6] and Glow [15] follow heuristic-based approach with graph-level optimizations. Recent works include MetaSchedule [16], Hidet [4], and BladeDISC [21], which improve scheduling abstraction, tuning efficiency, and dynamic-shape support. Industry systems include framework-specific compilers such as CINN (PaddlePaddle) and TorchInductor (PyTorch), which are tightly integrated into their respective DL frameworks, as well as vendor-specific tools like TensorRT, which are specialized for the NVIDIA ecosystem. Performance Benchmarks: DL model performance evaluation can be traced back to DeepBench [11], which measured the performance of fundamental operations such as matrix multiplication across different hardware platforms. This direction was later extended by the industry-wide MLPerf [9] suite, standardizing end-to-end evaluation of training and inference workloads. More recently, CompilerGym [3] introduced benchmark datasets and reinforcement learning environments aimed at leveraging ML to improve compiler optimization, while KernelBench [13] proposed benchmark for evaluating correctness and speedup of LLMgenerated GPU kernels. In parallel, Furutanpey et al.[5] evaluated graph compilers across heterogeneous settings and introduced NGraphBench to address the gap between theoretical performance and actual deployment, emphasizing the importance of incorporating compiler effects into ML research."
        },
        {
            "title": "6 Conclusion and Future Work",
            "content": "In this paper, we introduced GraphNet along with St and ESt metrics to enable reproducible evaluation of tensor compilers across tasks and frameworks. GraphNet provides an open and well-structured resource for kernel research at the computational graph level, ensuring broad coverage of real-world workloads. Through experiments, we showed that these tools allow researchers to gain an objective and comprehensive perspective on compiler optimization capability and to better identify potential performance bottlenecks. Our future roadmap focuses on expanding GraphNet to better serve compiler researchers and developers:"
        },
        {
            "title": "6.1 Completing GraphNet",
            "content": "Framework Expansion GraphNet currently supports only two deep learning frameworks, and its evaluation is limited to NVIDIA GPUs (e.g., H20, A100). We plan to expand the dataset by adding more samples from additional frameworks such as TensorFlow, JAX, and MindSpore, and extend evaluation to wider range of hardware platforms, including TPUs and NPUs. Task Category Refinement We will introduce more fine-grained categories within the existing six major domains (CV, NLP, Audio, Multimodal, Scientific Computing, and Other). This will enable more targeted evaluation of compilers on specific application scenarios. Sample Feature Enhancement We aim to enrich sample features by enhancing our graph decomposition tools, allowing full graphs to be more easily split into disjoint subgraphs. We also seek to broaden support for more complex custom operators to preserve model-specific functionality. Distributed Scenario Support Finally, we will extend GraphNet to incorporate distributed computing scenarios, so that GraphNet can capture computation graphs with communication operators and support the evaluation of compiler optimizations in large-scale distributed systems."
        },
        {
            "title": "6.2 Applying GraphNet",
            "content": "Systematic Compiler Evaluation Beyond the limited experiment on CINN and TorchInductor, GraphNet can be extended to benchmark broader range of tensor compilers under unified metric. From the users perspective, this enables users to select compilers based on task categories and framework requirements. From the compiler developers perspective, it helps developers quickly identify worst-case scenarios and uncover optimization bottlenecks. High-level IR Translation GraphNet includes computation graphs from multiple deep learning frameworks, providing foundation for high-level IR translation. Such translation unifies graphs across ecosystems, ensuring that compiler evaluations are based on fully aligned datasets. AI for Compiler Research GraphNet can serve as training and evaluation data for AI-generated compiler passes and kernels. These AI-generated optimizations can be directly applied to GraphNet samples and systematically compared with existing compiler backends under the ESt metric. This enables fair measurement of their speedup and correctness, and positions GraphNet as benchmark platform for advancing AI-driven compiler research."
        },
        {
            "title": "7 Acknowledgment",
            "content": "We thank the developers from the PaddlePaddle community for their invaluable support in constructing GraphNet. In particular, we especially acknowledge Zichao Xia, Ruqi Yang for their key contributions, and we also gratefully recognize the efforts of Guoyong Fang, Mengyuan Liu, Min Li, Shun Liu, Xin Wang, Xujun Chen, Yimeng Xu, Yiqiao Zhang, and Zeping Wu."
        },
        {
            "title": "References",
            "content": "[1] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy. Tvm: an automated end-to-end optimizing compiler for deep learning. In USENIX Conference on Operating Systems Design and Implementation (OSDI), page 579594, 2018. [2] Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John Tran, Bryan Catanzaro, 9 and Evan Shelhamer. cudnn: Efficient primitives for deep learning, 2014. URL https://arxiv.org/ abs/1410.0759. [3] Chris Cummins, Bram Wasti, Jiadong Guo, Brandon Cui, Jason Ansel, Sahir Gomez, Somya Jain, Jia Liu, Olivier Teytaud, Benoit Steiner, et al. Compilergym: Robust, performant compiler optimization environments for ai research. In IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pages 92105. IEEE, 2022. [4] Yaoyao Ding, Cody Hao Yu, Bojian Zheng, Yizhi Liu, Yida Wang, and Gennady Pekhimenko. Hidet: In ACM International Task-mapping programming paradigm for deep learning tensor programs. Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 370384, 2023. [5] Alireza Furutanpey, Carmen Walser, Philipp Raith, Pantelis A. Frangoudis, and Schahram Dustdar. Leveraging neural graph compilers in machine learning research for edge-cloud systems, 2025. URL https://arxiv.org/abs/2504.20198. [6] Samuel J. Kaufman, Phitchaya Mangpo Phothilimthana, Yanqi Zhou, Charith Mendis, Sudip Roy, Amit Sabne, and Mike Burrows. learned performance model for tensor processing units. In Conference on Machine Learning and Systems (MLSys), 2021. [7] Mingzhen Li, Yi Liu, Xiaoyan Liu, Qingxiao Sun, Xin You, Hailong Yang, Zhongzhi Luan, Lin Gan, IEEE ISSN 2161-9883. doi: Guangwen Yang, and Depei Qian. The deep learning compiler: comprehensive survey. Transactions on Parallel and Distributed Systems, 32(3):708727, March 2021. 10.1109/tpds.2020.3030548. URL http://dx.doi.org/10.1109/TPDS.2020.3030548. [8] Yanjun Ma, Dianhai Yu, Tian Wu, and Haifeng Wang. Paddlepaddle: An open-source deep learning platform from industrial practice. Frontiers of Data and Computing, pages 105115, 2019. URL http: //www.jfdc.cnic.cn/CN/abstract/article_2.shtml. [9] Peter Mattson, Vijay Janapa Reddi, Christine Cheng, Cody Coleman, Greg Diamos, David Kanter, Paulius Micikevicius, David Patterson, Guenther Schmuelling, Hanlin Tang, et al. Mlperf: An industry standard benchmark suite for machine learning performance. IEEE Micro, 40(2):816, 2020. [10] Paulius Micikevicius, Dusan Stosic, Neil Burgess, Marius Cornea, Pradeep Dubey, Richard Grisenthwaite, Sangwon Ha, Alexander Heinecke, Patrick Judd, John Kamalu, Naveen Mellempudi, Stuart Oberman, Mohammad Shoeybi, Michael Siu, and Hao Wu. Fp8 formats for deep learning, 2022. URL https://arxiv.org/abs/2209.05433. [11] Sharan Narang and Baidu Research. Deepbench: Benchmarking deep learning operations on different hardware, 2016. URL https://github.com/baidu-research/DeepBench. [12] oneDNN Contributors. oneAPI Deep Neural Network Library (oneDNN). URL https://github.com/ uxlfoundation/oneDNN. [13] Anne Ouyang, Simon Guo, Simran Arora, Alex Zhang, William Hu, Christopher Re, and Azalia Mirhoseini. Kernelbench: Can LLMs write efficient GPU kernels? In Forty-second International Conference on Machine Learning, 2025. URL https://openreview.net/forum?id=yeoN1iQT1x. [14] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, highperformance deep learning library. In Conference on Neural Information Processing Systems (NeurIPS), pages 80248035. Curran Associates, Inc., 2019. [15] Nadav Rotem, Jordan Fix, Saleem Abdulrasool, Garret Catron, Summer Deng, Roman Dzhabarov, Nick Gibson, James Hegeman, Meghan Lele, Roman Levenstein, Jack Montgomery, Bert Maher, Satish Nadathur, Jakob Olesen, Jongsoo Park, Artem Rakhov, Misha Smelyanskiy, and Man Wang. Glow: Graph lowering compiler techniques for neural networks, 2019. URL https://arxiv.org/abs/1805. 00907. 10 [16] Junru Shao, Xiyou Zhou, Siyuan Feng, Bohan Hou, Ruihang Lai, Hongyi Jin, Wuwei Lin, Masahiro Masuda, Cody Hao Yu, and Tianqi Chen. Tensor program optimization with probabilistic programs. Advances in Neural Information Processing Systems, 35:3578335796, 2022. [17] Baidu PaddlePaddle Team. Cinn: Compiling intermediate representation to neural networks, 2021. URL https://github.com/PaddlePaddle/CINN. PaddlePaddle Compiler Infrastructure. [18] Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, and Emad Barsoum. Geak: Introducing triton kernel ai agent & evaluation benchmarks, 2025. URL https://arxiv.org/abs/2507.23194. [19] Norman P. Jouppi Wang, Cliff Young, Nishant Patil, and David Patterson. Bfloat16: The secret to high performance on cloud tpus. https://cloud.google.com/blog/products/ai-machine-learning/ bfloat16-the-secret-to-high-performance-on-cloud-tpus, 2019. Accessed: 2025-10-23. [20] Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu, Ameer Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph E. Gonzalez, and Ion Stoica. Ansor: Generating High-Performance tensor programs for deep learning. In USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2020. [21] Zhen Zheng, Zaifeng Pan, Dalin Wang, Kai Zhu, Wenyi Zhao, Tianyou Guo, Xiafei Qiu, Minmin Sun, Junjie Bai, Feng Zhang, Xiaoyong Du, Jidong Zhai, and Wei Lin. Bladedisc: Optimizing dynamic shape machine learning workloads via compiler approach. Proc. ACM Manag. Data, pages 206:1206:29, 2023. URL https://doi.org/10.1145/3617327."
        },
        {
            "title": "Appendix",
            "content": "A Configuration of atol(t) and rtol(t) Data Type atol(t) atol(-5) atol(0) Data Type rtol(t) rtol(-5) rtol(0) float16 bfloat16 float float64 complex32 complex64 10t 10t 10t 10t7/5 10t 10t complex128 10t7/5 quint quint2x4 quint4x2 qint8 qint32 others 10t 10t 10t 10t 10t 0.0 1e1e-5 1e-5 1e-7 1e-5 1e-5 1e1e-5 1e-5 1e-5 1e-5 1e-5 0. 1 1 1 1 1 1 1 1 1 1 0.0 float16 bfloat16 float32 float64 complex 10t3/5 10t1.796/5 10t5.886/5 10t7/5 10t3/5 1e1.6e-2 1.3e-6 1e-7 1e-3 complex64 10t5.886/ 1.3e-6 complex128 10t7/5 quint8 quint2x4 quint4x qint8 qint32 others 10t5.886/5 10t5.886/5 10t5.886/ 10t5.886/5 10t5.886/5 1e-7 1.3e-6 1.3e-6 1.3e1.3e-6 1.3e-6 0.0 0.0 0.0 1 1 1 1 1 1 1 1 1 1 Table 1: atol configuration Table 2: rtol configuration Building on PyTorchs default testing settings, we develop log-linear interpolation scheme to construct (atol, rtol) configuration table. Specifically, we perform log-linear interpolation between two reference points, for instance, atolfp32(5) = 105 and atolfp32(0) = 1. In essence, this means that lg(atol(t)) and lg(rtol(t)) vary linearly with t, leading to the unified representation atol(t), rtol(t) = 10kt. This formulation provides coherent framework that encompasses floating-point (float16, bfloat16, float32, float64), complex, and quantized integer types. As result, the tolerance (, 0] is mapped smoothly onto tolerance bounds across diverse precisions. 12 Sample-level Interpretation of St In this section, we show that the macro-level Speedup Score St (Eq. 1) can be equivalently expressed as the geometric mean of per-sample rectified speedups. Definition B.1 (Rectified Speedup). For each test sample i, the rectified speedup under tolerance is defined as: st,i = si, p+1 , b, if correctt,i si 1, if correctt,i si < 1, if correctt,i, (4) where si denotes the raw speedup ratio, correctt,i indicates whether the execution satisfies the tolerance criterion t, (0, 1) is the degradation penalty coefficient, and (0, 1) is the failure penalty. This formulation ensures that: (i) correct executions with speedup retain their measured gain; (ii) correct executions with slowdown are exponentially penalized; and (iii) failed executions incur fixed penalty. We further define the Geometric Mean Rectified Speedup (GMRS) as: GMRSt = (cid:33)1/N (cid:32) i=1 st,i (5) where is the total number of evaluated test samples. Proposition B.1. The macro-level Speedup Score St defined in Eq. 1 is equivalent to the geometric mean of per-sample rectified speedups: St = αλ βλη b1λ = GMRSt Proof. Consider benchmark containing test samples in total. Among them, let be the number of correctly executed samples, and be the subset of those whose raw speedup is less than one (i.e., slowdowns). Formally, we define: = #{i correctt,i}, = #{i correctt,i, si < 1}, λ = , η = . Thus, the sample space can be partitioned as: (M K) correctly executed and accelerated samples (si 1); correct executions with slowdown (si < 1); (N M) failed or incorrect samples. Expanding Eq. (5) under this partition gives: GMRSN = si i:correct, si i:correct, si<1 sp+1 i:correct (6) Define the geometric means: Hence, (cid:32) α = i:correct si (cid:33)1/M (cid:32) , β = i:correct, si<1 si (cid:33)1/K i:correct si = αM, i:correct, si<1 si = βK, 13 and consequently: Substituting into Eq. (6): Taking the N-th root gives: i:correct, si1 si = αM βK"
        },
        {
            "title": "GMRSN",
            "content": "t = αM βK (βK)p+1 bNM = αM βKp bNM GMRSt = αM/N βKp/N b(NM)/N Substituting λ = M/N and η = K/M yields: This matches exactly the macro-level formulation in Eq. 1, completing the proof. GMRSt = αλ βλη b1λ (7) 14 Sample-level Interpretation of ESt This section provides the sample-level interpretation of the Error-aware Speedup Score ESt. We show that the aggregated error penalty γt in Eq. (3) is equivalent to the geometric mean of per-sample penalty factors, and that ESt can be viewed as the geometric mean of per-sample error-aware rectified speedup. Definition C.1. For each erroneous sample i, let ci {1, 2, 3} denote its error code (1 for accuracy errors, 2 for execution crashes, 3 for compilation failures). Given tolerance level t, we define the sample-level penalty factor as (cid:40) rt,i = b, < ci, 1, otherwise, (8) where (0, 1) is the base penalty introduced in Section 3.2.1. This factor equals if the current tolerance level does not forgive the error type ci, and 1 otherwise. Proposition C.1. The aggregated penalty γt can be written as the geometric mean of {rt,i} over all erroneous samples: (cid:33)1/E γt = (cid:32) i= rt,i (9) where is the total number of erroneous samples. Proof. From the definition of rt,i, each term in the product rt,i contributes iff < ci: i=1 rt,i = i=1 1(t<ci) = bE i=1 1(t<ci) Grouping by error code and letting Ec denote the number of samples with code c, we have thus Taking the E-th root gives i=1 1(t < ci) = 3 c=1 Ec 1(t < c) i=1 rt,i = b3 c=1 Ec 1(t<c) (cid:33)1/E (cid:32) i=1 rt,i = 1 c=1 Ec 1(t<c) = b3 3 c=1 πc 1(t<c) where πc = Ec/E is the fraction of error code among all erroneous samples. The right-hand side is exactly the definition of γt in Eq. (2). Definition C.2. (Error-aware rectified speedup). Extending the rectified speedup defined in Appendix B, we introduce the per-sample error-aware rectified speedup: error_aware_rectified_speedupt,i = speedupi, speedup p+1 , rt,i, correctt,i speedupi 1, correctt,i speedupi < 1, otherwise. (10) Proposition C.2. Since γt acts as the geometric mean of {rt,i} for given t, the macro-level metric ESt in Eq. (3) can be trivially proved as the geometric mean of these error-aware rectified speedup values: ESt = (cid:32) i=1 error_aware_rectified_speedupt,i (11) (cid:33)1/N"
        },
        {
            "title": "D Details of Benchmark Experiments",
            "content": "Figure 6: Violin Plots of Per-sample Speedups (log2(speedup)). It shows distribution of per-sample speedups under correctness checks = 0. Each violin shows the speedup spread for compiler-task pair. Wider regions denote more frequent speedup values. Samples with log2(speedup) <0 indicate performance degradation. Experiments were conducted on server with dual Intel Xeon Platinum 8563C CPUs, 2 TB DRAM, and eight NVIDIA H20-3e GPUs (144 GB each). Only one GPU was used to ensure single-device setting. The software environment included Python 3.11, PyTorch 2.8, and PaddlePaddle 3.2. PaddlePaddle and PyTorch show broadly consistent dataset distributions. For graphs with fewer than 256 operators, the proportions are 6% vs. 8.5% in NLP (PaddlePaddle vs. PyTorch) and 13% vs. 5.6% in CV. For graphs with more than 256 operators, the proportions are 94% vs. 91.5% in NLP and 87% vs. 94.4% in CV. These residual differences will be resolved through high-level IR transformation tool. The four tables below (Tables 3-6) report detailed scores for the NLP / CV models tested on PaddlePaddle and PyTorch, corresponding to the statistical results behind each point of the St plots in Section 3.2.1 and the ESt plots in Section 3.2.2. Since St does not consider the region > 0, the corresponding entries are marked - to indicate empty. γ is used only when computing ESt. For points that contain no correct samples, η is initialized to 0. α and β are initialized to 1 if no correct samples exist. -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 α β λ η 1.000 1.000 1.000 1.441 1.321 1.284 1.282 1.278 1.278 1.278 1.278 1.278 1.278 1.278 1.278 1.000 1.000 1.000 1.000 0.858 0.878 0.878 0.878 0.878 0.878 0.878 0.878 0.878 0.878 0. 0.000 0.000 0.000 0.009 0.575 0.953 0.962 0.991 0.991 0.991 0.991 0.991 0.991 0.991 0.991 0.000 0.000 0.000 0.000 0.049 0.050 0.049 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 S(t) 0.100 0.100 0.100 0.103 0.442 1.139 1.165 1.248 1.248 1.248 1.248 - - - - γ 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 1.000 1. ES(t) 0.100 0.100 0.100 0.103 0.442 1.139 1.165 1.248 1.248 1.248 1.248 1.248 1.248 1.276 1.276 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 α β λ η 0.981 1.038 1.170 1.175 1.344 1.342 1.345 1.348 1.354 1.360 1.363 1.363 1.363 1.363 1.363 0.927 0.927 0.840 0.840 0.822 0.817 0.817 0.817 0.818 0.818 0.818 0.818 0.818 0.818 0.818 0.010 0.013 0.029 0.030 0.423 0.930 0.933 0.941 0.963 0.975 0.977 0.977 0.977 0.977 0.977 0.800 0.615 0.321 0.310 0.064 0.046 0.046 0.045 0.045 0.045 0.044 0.044 0.044 0.044 0. S(t) 0.102 0.103 0.107 0.108 0.300 1.118 1.129 1.156 1.229 1.275 1.284 - - - - γ 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 1.000 1.000 ES(t) 0.102 0.103 0.107 0.108 0.300 1.118 1.129 1.156 1.229 1.275 1.284 1.284 1.284 1.353 1. Table 3: Values for PaddlePaddle-NLP Table 4: Values for PyTorch-NLP 16 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 α β λ η 1.056 1.056 1.056 1.056 1.117 1.137 1.131 1.125 1.123 1.122 1.121 1.122 1.122 1.122 1.122 0.917 0.917 0.917 0.920 0.906 0.906 0.915 0.912 0.911 0.911 0.910 0.910 0.910 0.910 0.910 0.054 0.054 0.054 0.080 0.228 0.526 0.732 0.892 0.939 0.965 0.981 0.993 0.993 0.993 0. 0.739 0.739 0.739 0.529 0.216 0.129 0.109 0.105 0.105 0.105 0.105 0.104 0.104 0.104 0.104 S(t) 0.114 0.114 0.114 0.121 0.173 0.359 0.591 0.866 0.969 1.031 1.072 - - - - γ 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 1.000 1.000 1.000 1.000 ES(t) 0.114 0.114 0.114 0.121 0.173 0.359 0.591 0.866 0.969 1.031 1.072 1.121 1.123 1.123 1.123 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 α β λ η 0.949 0.954 0.957 0.984 1.006 1.030 1.028 1.028 1.028 1.028 1.028 1.028 1.028 1.028 1.028 0.825 0.829 0.821 0.819 0.814 0.815 0.815 0.815 0.815 0.815 0.815 0.815 0.815 0.815 0.815 0.345 0.404 0.447 0.605 0.766 0.882 0.886 0.886 0.887 0.887 0.887 0.887 0.887 0.887 0.887 0.618 0.623 0.609 0.552 0.505 0.472 0.474 0.474 0.473 0.473 0.473 0.473 0.473 0.473 0.473 S(t) 0.217 0.249 0.274 0.399 0.586 0.783 0.788 0.788 0.790 0.790 0.790 - - - - γ 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 1.000 1.000 ES(t) 0.217 0.249 0.274 0.399 0.586 0.783 0.788 0.788 0.790 0.790 0.790 0.790 0.790 1.025 1.025 Table 5: Values for PaddlePaddle-CV Table 6: Values for PyTorch-CV"
        }
    ],
    "affiliations": [
        "PaddlePaddle Team, Baidu Inc."
    ]
}