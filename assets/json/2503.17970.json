{
    "paper_title": "PathoHR: Breast Cancer Survival Prediction on High-Resolution Pathological Images",
    "authors": [
        "Yang Luo",
        "Shiru Wang",
        "Jun Liu",
        "Jiaxuan Xiao",
        "Rundong Xue",
        "Zeyu Zhang",
        "Hao Zhang",
        "Yu Lu",
        "Yang Zhao",
        "Yutong Xie"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Breast cancer survival prediction in computational pathology presents a remarkable challenge due to tumor heterogeneity. For instance, different regions of the same tumor in the pathology image can show distinct morphological and molecular characteristics. This makes it difficult to extract representative features from whole slide images (WSIs) that truly reflect the tumor's aggressive potential and likely survival outcomes. In this paper, we present PathoHR, a novel pipeline for accurate breast cancer survival prediction that enhances any size of pathological images to enable more effective feature learning. Our approach entails (1) the incorporation of a plug-and-play high-resolution Vision Transformer (ViT) to enhance patch-wise WSI representation, enabling more detailed and comprehensive feature extraction, (2) the systematic evaluation of multiple advanced similarity metrics for comparing WSI-extracted features, optimizing the representation learning process to better capture tumor characteristics, (3) the demonstration that smaller image patches enhanced follow the proposed pipeline can achieve equivalent or superior prediction accuracy compared to raw larger patches, while significantly reducing computational overhead. Experimental findings valid that PathoHR provides the potential way of integrating enhanced image resolution with optimized feature learning to advance computational pathology, offering a promising direction for more accurate and efficient breast cancer survival prediction. Code will be available at https://github.com/AIGeeksGroup/PathoHR."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 3 2 ] . e [ 1 0 7 9 7 1 . 3 0 5 2 : r PathoHR: Breast Cancer Survival Prediction on High-Resolution Pathological Images Yang Luo1, Shiru Wang2, Jun Liu3, Jiaxuan Xiao4, Rundong Xue5, Zeyu Zhang6, Hao Zhang7, Yu Lu8, Yang Zhao9, Yutong Xie10 1XJLTU, 2Dartmouth, 3NUP, 4DLMU, 5XJTU, 6ANU, 7UCAS, 8SZTU, 9La Trobe, 10MBZUAI Abstract. Breast cancer survival prediction in computational pathology presents remarkable challenge due to tumor heterogeneity. For instance, different regions of the same tumor in the pathology image can show distinct morphological and molecular characteristics. This makes it difficult to extract representative features from whole slide images (WSIs) that truly reflect the tumors aggressive potential and likely survival outcomes. In this paper, we present PathoHR, novel pipeline for accurate breast cancer survival prediction that enhances any size of pathological images to enable more effective feature learning. Our approach entails (1) the incorporation of plug-and-play high-resolution Vision Transformer (ViT) to enhance patch-wise WSI representation, enabling more detailed and comprehensive feature extraction, (2) the systematic evaluation of multiple advanced similarity metrics for comparing WSI-extracted features, optimizing the representation learning process to better capture tumor characteristics, (3) the demonstration that smaller image patches enhanced follow the proposed pipeline can achieve equivalent or superior prediction accuracy compared to raw larger patches, while significantly reducing computational overhead. Experimental findings valid that PathoHR provides the potential way of integrating enhanced image resolution with optimized feature learning to advance computational pathology, offering promising direction for more accurate and efficient breast cancer survival prediction. Code will be available at https://github.com/AIGeeksGroup/PathoHR. Keywords: High-resolution representations Pathological imaging Survival prediction."
        },
        {
            "title": "Introduction",
            "content": "In breast cancer pathology, accurate survival prediction fundamentally relies on the detailed analysis of Whole Slide Images (WSIs), which capture representation morphological characteristics that indicate tumor aggressiveness and potential treatment outcomes [9,47]. The high-resolution nature of these pathological images provides essential visual information about cellular patterns, tissue organization, and tumor heterogeneity that directly correlate with patient Equal contribution. Project lead. Corresponding author: y.zhao2@latrobe.edu.au. 2 PathoHR prognosis [23,24]. Recently, computational pathology has gained significant attention, with extensive research focusing on extracting and analyzing quantitative features from WSIs for survival prediction [29,8]. Despite notable advancements [21,19], cancer survival prediction remains challenging. The primary one lies in the significant tumor heterogeneity in pathology, where different regions of the same tumor exhibit distinct morphological characteristics, making it difficult to capture representative predictive patterns [22,26]. Besides, while high-resolution images contain detailed morphological information crucial for accurate prediction, processing such high-dimensional data demands substantial computational resources. Current approaches typically address this by cropping WSIs into smaller patches, but this creates another challenge: how to effectively learn and leverage the similarity features across different patches to capture the tumors overall characteristics [10,44]. This fundamental tension between maintaining high-resolution information and learning representative features across patches has limited the achievement of optimal predictive performance in clinical settings [20,37]. To address these challenges, we propose PathoHR, novel pipeline for breast cancer survival prediction that improves pathological image analysis through efficient multi-resolution processing and advanced feature representation learning. The contribution of this paper is threefold: (1) plug-and-play high-resolution Vision Transformer (ViT) framework is introduced for flexible patch-wise WSI enhancement, designed to process patchbased pathology image regardless of input size. The framework integrates seamlessly with existing architectures to enhance patch-based WSIs, enabling the extraction of fine-grained morphological details that are critical for survival prediction while maintaining computational efficiency. (2) systematic evaluation of advanced similarity metrics is adapted for contrastive learning, designed to effectively discriminate between common and distinct features across multiple tumor regions. This comprehensive evaluation framework aims to address the challenge of tumor heterogeneity by effectively capturing and leveraging common characters across different patches. (3) streamlined approach for processing enhanced smaller image patches is established, aimed at achieving superior prediction accuracy while reducing computational demands. The framework demonstrates how high-resolution feature learning using raw large patches can be effectively accomplished with smaller patches, providing practical solution for clinical implementation."
        },
        {
            "title": "2 Related Works",
            "content": "Representation Learning in Pathology. Representation learning has emerged as crucial approach in computational pathology, particularly in enhancing the accuracy and efficiency of diagnostic models through advanced feature extraction techniques. Jaume et al. proposed the TANGLE framework, which leverages contrastive learning to align gene expression profiles with histology slide representations, significantly improving few-shot classification tasks [15]. PathoHR 3 Dynamic Resolution Adaptation in Vision Transformers. Dynamic resolution adaptation is critical capability for Vision Transformers (ViTs) [36,40,16] in medical imaging [27,46], where image resolutions can vary significantly. Fan et al. introduced ViTAR, Vision Transformer capable of processing images at any resolution through adaptive token merging and fuzzy position encoding [11]. This innovation significantly reduces computational costs while maintaining high accuracy, making it suitable for large-scale histology image analysis. Similarly, Sun et al. proposed HRNet (High-Resolution Network) [33], framework that maintains high-resolution representations throughout the network, which is crucial for position-sensitive vision problems such as human pose estimation, semantic segmentation [38,30,12,31,41,35,43], and object detection [45,42,5,6]. Wang et al. proposed HRFormer, high-resolution Transformer designed for dense prediction tasks, which maintains high-resolution representations throughout the network [34]. Feature Similarity in Whole Slide Images. The analysis of feature similarity in whole slide images (WSIs) is critical aspect of digital pathology, enabling accurate classification and diagnosis [14,39]. Recent advancements in this domain have leveraged various techniques to enhance the representation and similarity assessment of features within WSIs. For instance, Bui et al. proposed FALFormer, Transformer-based model that employs Nyström self-attention and feature-aware landmarks to capture the global relationships among patches in WSIs [4]. In addition, the HMIL framework, proposed by Jin et al., incorporates hierarchical multi-instance learning and supervised contrastive learning to address fine-grained classification tasks in WSIs [2]."
        },
        {
            "title": "3 Method",
            "content": "As presented in Fig.1, the proposed PathoHR pipeline comprises three integral components: (1) patch-wise feature extraction, (2) token merging via similarity computation for enhanced representation learning, and (3) plug-and-play ViT module to process multi-resolution patch-wise pathology images for better survival prediction."
        },
        {
            "title": "3.1 Patch-wise Feature Extraction",
            "content": "The first step of the proposed pipeline involves processing whole slide images (WSIs) to extract low-dimensional representation features, details are shown in Fig. 1(1). Initially, each WSI is cropped into small patches of defined size. An Otsus method is applied to identify tissue boundaries and eliminate holes, ensuring only relevant tissue regions are retained for analysis. Following the prior work [25], weakly supervised attention-based model with pre-trained UNI encoder [7] is adopted for feature extraction. In total 1024-dim features for each patch are generated for further representation learning. 4 PathoHR Fig. 1. The proposed PathoHR pipeline for breast cancer os prediction. The pipeline consists of three main components: (1) patch-wise feature extraction, (2) token merge similarity calculation for representation learning, and (3) plug-and-play ViTAR encoder, that connects to the Transformer Encoder Block and incorporates Attention operations to generate predictive outputs."
        },
        {
            "title": "3.2 Similarity Calculation for Token Merging",
            "content": "Following the concept of contrastive learning, where the model learns to identify and group similar features, several similarity computation methods are proposed and systematically tested. The details are presented in Fig. 1(2) and Fig. 2. Pooled Attention Method. Same as the ViTAR work [11], obtained through average pooling operations that reduce the sequence length by half. The similarity is computed through standard projection operations, where q, k, and are derived from the input features through shared linear projection layer. Euclidean Distance Method. This method [17] quantifies token relationships based on their spatial distances in the feature space. Details are shown in Fig. 2(1). After obtaining pooled queries, the similarity is computed as sim(q, k) = exp (cid:118) (cid:117) (cid:117) (cid:116) (cid:88) (qi ki)2 τ i=1 (1) where τ is learnable temperature parameter that controls the sharpness of the similarity distribution. This distance-based approach captures local feature relationships in the embedding space. Cosine Distance Method. In Fig. 2(2), cosine distance method [18] is introduced. This method measures the angular correlation between token representations, focusing on directional relationships rather than absolute distances. PathoHR 5 Fig. 2. This figure illustrates five different methods of calculating similarity: (1) Euclidean Similarity [17]; (2) Cosine Similarity [18]; (3) Attention Score [13]; (4) Semantic Similarity [32]; and (5) ToMe Similarity [3]."
        },
        {
            "title": "The similarity is calculated as",
            "content": "sim(q, k) = τ k (2) where vectors are first normalized to unit length. The normalization ensures that the similarity measure is invariant to the scale of the token representations. Attention Score Method. Attention score method [13] is introduced in Fig. 2(3) This method is built upon transformer architecture which benefits from the attention mechanism. The scaled dot-product attention with separate projections for queries, keys, and values are implemented in this work. The similarity is computed as sim(q, k) = softmax (cid:18) τ (cid:19) qkT (3) where represents the feature dimension. Semantic Similarity Method. The semantic similarity [32] introduces an additional layer of abstraction by projecting tokens through lower-dimensional semantic space. The aim is to capture higher-level semantic relationships between tokens through learned transformations. This method is shown in Fig. 2(4). The similarity is calculated as sim(q, k) = softmax (cid:18) fq(q) fk(k)T (cid:19) (4) where fq and fk are non-linear projection functions implemented as multi-layer perceptrons. ToMe Similarity Method. This method [3] reduces the use of computational resource usage and maintains model performance by applying token merging strategy based on bipartite soft matching. The architectural design is shown in Fig. 2(5) and aims to reduce computational overhead in similarity measurement by eliminating redundant token participation, thereby achieving optimized PathoHR computational density during large-scale token processing. The similarity is calculated as sim(q, k) = softmax (cid:16) GA(t) GB(t)T (cid:17) (5) where GA(t) and GB(t) are two tokens formed by grouping input tokens according to certain rules."
        },
        {
            "title": "3.3 Plug-in-play ViTAR Encoder",
            "content": "The plug-in-play ViTAR Encoder contains mainly two parts as shown in Fig. 1(3): Adaptive Token Merge (ATM) and Fuzzy Positional Encodings (FPE) [11]. ATM starts by calculating the similarities among patches. Then these similarities are served as query in cross-attention operation to merge all features. This similarity-based token merging adaptively reduces spatial dimensions while preserving essential features. The FPE mechanism further reinforces resolution robustness by introducing controlled positional uncertainty. Specifically, for token at position (i, j), its fuzzy positional encoding Pf is computed as: Pf (i, j) = (i + s1, + s2), s1, s2 (0.5, 0.5) (5) where represents the learnable positional embeddings, and denotes uniform distribution. Through this dual-mechanism architecture, ViTAR could efficiently process multi-resolution inputs by adaptively managing token density while maintaining spatial coherence, ensuring consistent performance across varying image scales. After ViTAR Encoder processes the input images and generates token representations, these tokens are further refined through the attention mechanisms of the Tangle architecture [15] to extract diagnostically relevant features. The pre-attention module applies multiple linear transformations with normalization and GELU activation to prepare patch features for attention computation. The gated-attention mechanism then employs dual-path architecture where features are processed through parallel tanh and sigmoid activations before being multiplied together. This multiplication generates attention weights that highlight important features such as diagnostic regions in the slide. The slide embedding is generated by weighting patch features with these attention scores and then applying mean aggregation. This allows the model to emphasize diagnostically relevant regions while suppressing less informative areas. The detailed implementation steps of the proposed PathoHR pipeline are formally defined in Algorithm 1, which outlines the end-to-end procedure. The inputs are WSI, patch size, similarity threshold for token merging (τ ), transformer encoder block count (N), and transformer encoder iteration count (J). The output is overall survival (OS) prediction. PathoHR 7 tissue_mask OtsuThreshold(WSI) patches ExtractPatches(WSI, tissue_mask, patch_size) patch_embeddings UNIEncoder(patches) CLS_token InitializeCLSToken() tokens Concatenate(CLS_token, patch_embeddings) for = 1 to do Algorithm 1 PathoHR: Multi-resolution Patch-based Pathology Image process 1: procedure PathoHR(WSI, patch_size, τ, N, J, method) 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: norm_tokens Normalize(tokens) tokens tokens + MultiQueryAttention(norm_tokens) tokens tokens + Linear(norm_tokens) tokens TransformerEncoderBlocks(tokens, ) end for Q, ProjectionHead(tokens) similarity_matrix ComputeSimilarity(Q, K, method) method {Pooled Attention, Euclidean, Cosine, Attention Score, Semantic} merged_tokens TokenMerge(tokens, similarity_matrix, τ ) slide_embedding ExtractCLSToken(merged_tokens) output_logits PredictionHead(slide_embedding) prediction Classify(output_logits) return prediction 15: 16: 17: 18: 19: 20: end procedure"
        },
        {
            "title": "4.1 Dataset and Evaluation Metrics",
            "content": "Dataset. We utilized comprehensive dataset comprising 1,036 Whole Slide Images (WSIs) with corresponding OS labels from the TCGA-BRCA (Invasive breast cancer) dataset [1]. To facilitate comparative analysis, each WSI was segmented into 1616 pixel patches. The dataset was randomly partitioned into training, validation, and testing sets with ratio of 8:1:1, respectively. Evaluation Metrics. Model performance was evaluated by comparing the prediction metrics which include AUC and ACC and F1 Recall and Precision between our proposed 1616 patches and the baseline 2424 patches, maintaining consistent model architecture across experiments. We employed supervised learning strategy focused on minimizing mean square error loss. All experiments were performed on standardized platform using workstation equipped with an NVIDIA RTX A6000 GPU."
        },
        {
            "title": "4.2 Comparetive Study",
            "content": "We conducted comparative analysis of our proposed PathoHR pipeline performance against benchmark Tangle methods without VITAR encoder enhancement. The validation results for intra-modality slide self-supervised learning (Intra) across different patch sizes and similarity metrics are presented in Table 1. Intra (24) and Intra (16) utilize the basic Tangle model, while the remaining results follow the proposed PathoHR pipeline with patch size of 1616. The 8 PathoHR Fig. 3. Performance on breast cancer classification task. Different models using WSIs as input for breast cancer classification tasks are evaluated. AUC values are reported. results demonstrate that while smaller input patches intuitively lead to lower os prediction accuracy, our proposed PathoHR pipeline effectively counters this limitation. By enhancing representation feature extraction, the pipeline enables 1616 patches to surpass the baseline architecture using 2424 patches in both AUC and F1 scores. Performance comparisons between our proposed PathoHR pipeline and architectures with different backbones performing similar classification tasks are also conducted [28]. Fig. 3. demonstrates that the PathoHR pipeline enables superior classification performance despite using relatively smaller patches, highlighting the efficiency of this approach."
        },
        {
            "title": "4.3 Ablation Study",
            "content": "Table 1. Validation performance on os prediction for breast cancer pathology.(24) and (16) denote input patch sizes of 2424 and 1616, respectively. F1 ACC AUC 0.8 Models Intra(24) Intra(16) Intra with pool Intra with cos Intra with euclidean Intra with semantic Recall Precision 0.95313 0.83025 0.95313 0.90845 0.76786 0.97436 0.91077 0.87179 0.89451 0.71622 0.94872 0.92375 0.94872 0.90007 0.90741 0.97436 0.96170 0.97436 0.94938 0.82413 0.97436 0.92375 0.94872 0.92915 0.90541 0.89286 0.92375 0.89286 0.94938 Intra with attention score 0.62353 0.94872 0.92375 0.94872 0.90007 0.78947 0.97436 0.96170 0.97436 0. Intra with ToMe PathoHR 9 Table 2 showcases the enhancements brought about by our proposed PathoHR strategies. The results indicate that integrating residual connections or similarity comparisons independently could improve os prediction accuracy. However, the experiments reveal potential counteractive relationship between these components. Optimal results are achieved either using cosine similarity without residual connections or using only pooling with residual links. Future work should explore this interaction effect to potentially combine residual connections with selective similarity metrics for improved pathology-based survival prediction. Table 2. Ablation study of different designs. Similarity matrix values are reported. Test performance on breast cancer os prediction is statistically evaluated. ACC AUC Models Intra with 16 Recall Precision F1 0.68235 0.74359 0.76476 0.74359 0.78757 Pool(only with res) 0.83118 0.76003 0.81796 0.76003 0.87533 0.64815 0.87179 0.88615 0.87179 0.85207 0.62037 0.89744 0.88615 0.89744 0.85207 0.73030 0.88462 0.83090 0.88462 0.78403 0.70142 0.89745 0.84616 0.89745 0.84221 Semantic without res 0.72294 0.88462 0.83090 0.88462 0.78403 0.81429 0.87179 0.96154 0.84615 0.88552 0.58571 0.92308 0.88615 0.92308 0.85207 Cosine Semantic Pool without res Cos without res ToMe ToMe without res"
        },
        {
            "title": "5 Conclusion",
            "content": "In this paper, we present PathoHR, novel pipeline for efficient multi-resolution processing of patch-based pathology images to improve representation learning. By leveraging diverse similarity metrics for adaptive token merging, our approach effectively clusters features based on their semantic relationships. Integrating the proposed plug-in-play ViTAR encoder alongside the Tangle model enables the use of smaller patches while achieving superior performance compared to prior large-patch approaches. The contributions of this study pave the way for fast and accurate os prediction using high-resolution pathology images. Future work might include the incorporation of multi-modal data to further enhance OS prediction accuracy."
        },
        {
            "title": "References",
            "content": "1. 13, B..W.H..H.M.S.C.L...P.P.J..K.R., data analysis: Baylor College of Medicine Creighton Chad J. 22 23 Donehower Lawrence A. 22 23 24 25, G., for Systems Biology Reynolds Sheila 31 Kreisberg Richard B. 31 Bernard Brady 31 Bressler Ryan 31 Erkkila Timo 32 Lin Jake 31 Thorsson Vesteinn 31 Zhang Wei 33 Shmulevich Ilya 31, I., et al.: Comprehensive molecular portraits of human breast tumours. Nature 490(7418), 6170 (2012) 10 PathoHR 2. et al., C.J.: Hmil: Hierarchical multi-instance learning for fine-grained whole slide image classification. IEEE Transactions on Medical Imaging (2024). https://doi. org/10.1109/TMI.2024.3520602 3. Bolya, D., et al.: Token merging for memory-efficient vision transformers. arXiv preprint arXiv:2210.09461 (2022) 4. Bui, D.C., Vuong, T.T.L., Kwak, J.T.: Falformer: Feature-aware landmarks selfattention for whole-slide image classification. In: Proceedings of Medical Image Computing and Computer Assisted Intervention MICCAI 2024. vol. LNCS 15004, pp. 123 132. Springer Nature Switzerland (October 2024) 5. Cai, G., Cai, Y., Zhang, Z., Cao, Y., Wu, L., Ergu, D., Liao, Z., Zhao, Y.: Medical ai for early detection of lung cancer: survey. arXiv preprint arXiv:2410.14769 (2024) 6. Cai, G., Zhang, R., He, H., Zhang, Z., Ergu, D., Cao, Y., Zhao, J., Hu, B., Liao, Z., Zhao, Y., et al.: Msdet: Receptive field enhanced multiscale detection for tiny pulmonary nodule. arXiv preprint arXiv:2409.14028 (2024) 7. Chen, R.J., Ding, T., Lu, M.Y., Williamson, D.F., Jaume, G., Chen, B., Zhang, A., Shao, D., Song, A.H., Shaban, M., et al.: Towards general-purpose foundation model for computational pathology. Nature Medicine (2024) 8. Cui, M., Zhang, D.Y.: Artificial intelligence and computational pathology. Laboratory Investigation 101(4), 412422 (2021) 9. El Nahhas, O.S., van Treeck, M., Wölflein, G., Unger, M., Ligero, M., Lenz, T., Wagner, S.J., Hewitt, K.J., Khader, F., Foersch, S., et al.: From whole-slide image to biomarker prediction: end-to-end weakly supervised deep learning in computational pathology. Nature Protocols 20(1), 293316 (2025) 10. Fan, L., Sowmya, A., Meijering, E., Song, Y.: Cancer survival prediction from whole slide images with self-supervised learning and slide consistency. IEEE Transactions on Medical Imaging 42(5), 14011412 (2022) 11. Fan, Q., You, Q., Han, X., Liu, Y., Tao, Y., Huang, H., He, R., Yang, H.: Vitar: Vision transformer with any resolution. arXiv preprint arXiv:2403.18361 (2024) 12. Ge, J., Zhang, Z., Phan, M.H., Zhang, B., Liu, A., Zhao, Y.: Esa: Annotation-efficient active learning for semantic segmentation. arXiv preprint arXiv:2408.13491 (2024) 13. He, K., et al.: Transformers in medical image analysis. Intelligent Medicine 2(3), 135144 (2022) 14. Hiwase, A.D., Ovenden, C.D., Kaukas, L.M., Finnis, M., Zhang, Z., OConnor, S., Foo, N., Reddi, B., Wells, A.J., Ellis, D.Y.: Can rotational thromboelastometry rapidly identify theragnostic targets in isolated traumatic brain injury? Emergency Medicine Australasia 37(1), e14480 (2025) 15. Jaume, G., Oldenburg, L., Vaidya, A., Chen, R.J., Williamson, D.F., Peeters, T., Song, A.H., Mahmood, F.: Transcriptomics-guided slide representation learning in computational pathology. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 96329644 (2024) 16. Ji, Y., Saratchandran, H., Gordon, C., Zhang, Z., Lucey, S.: Sine activated low-rank matrices for parameter efficient learning. arXiv e-prints pp. arXiv2403 (2024) 17. Jones, A.R., et al.: Spatial analysis of histology in 3d: quantification and visualization of organ and tumor level tissue environment. Heliyon 8(1), e08762 (2022) 18. Khan, M.H., et al.: similarity measure of histopathology images by deep embeddings. arXiv preprint arXiv:2107.13703 (2021) 19. Levy, J., Haudenschild, C., Barwick, C., Christensen, B., Vaickus, L.: Topological feature extraction and visualization of whole slide images using graph neural PathoHR networks. In: BIOCOMPUTING 2021: Proceedings of the Pacific Symposium. pp. 285296. World Scientific (2020) 20. Li, B., Liu, F., Lv, B., Zhang, Y., Gou, F., Wu, J.: Cytopathology image analysis method based on high-resolution medical representation learning in medical decision-making system. Complex & Intelligent Systems 10(3), 42534274 (2024) 21. Li, X., Li, C., Rahaman, M.M., Sun, H., Li, X., Wu, J., Yao, Y., Grzegorzek, M.: comprehensive review of computer-aided whole-slide image analysis: from datasets to feature extraction, segmentation, classification and detection approaches. Artificial Intelligence Review 55(6), 48094878 (2022) 22. Lim, B., Hortobagyi, G.N.: Current challenges of metastatic breast cancer. Cancer and Metastasis Reviews 35, 495514 (2016) 23. Liu, T., Su, R., Sun, C., Li, X., Wei, L.: Eocsa: Predicting prognosis of epithelial ovarian cancer with whole slide histopathological images. Expert Systems with Applications 206, 117643 (2022) 24. Liu, X., Liu, Z., Yan, Y., Wang, K., Wang, A., Ye, X., Wang, L., Wei, W., Li, B., Sun, C., et al.: Development of prognostic biomarkers by tmb-guided wsi analysis: two-step approach. IEEE Journal of Biomedical and Health Informatics 27(4), 17801789 (2023) 25. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood, F.: Data-efficient and weakly supervised computational pathology on whole-slide images. Nature Biomedical Engineering 5(6), 555570 (2021) 26. Margolin, A.A., Bilal, E., Huang, E., Norman, T.C., Ottestad, L., Mecham, B.H., Sauerwine, B., Kellen, M.R., Mangravite, L.M., Furia, M.D., et al.: Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer. Science translational medicine 5(181), 181re1181re1 (2013) 27. Qi, X., Zhang, Z., Handoko, A.B., Zheng, H., Chen, M., Huy, T.D., Phan, V.M.H., Zhang, L., Cheng, L., Jiang, S., et al.: Projectedex: Enhancing generation in explainable ai for prostate cancer. arXiv preprint arXiv:2501.01392 (2025) 28. Qi, X., Zhang, Z., Zheng, H., Chen, M., Kutaiba, N., Lim, R., Chiang, C., Tham, Z.E., Ren, X., Zhang, W., et al.: Medconv: Convolutions beat transformers on long-tailed bone density prediction. arXiv preprint arXiv:2502.00631 (2025) 29. Song, A.H., Jaume, G., Williamson, D.F., Lu, M.Y., Vaidya, A., Miller, T.R., Mahmood, F.: Artificial intelligence for digital and computational pathology. Nature Reviews Bioengineering 1(12), 930949 (2023) 30. Tan, S., Xue, R., Luo, S., Zhang, Z., Wang, X., Zhang, L., Ergu, D., Yi, Z., Zhao, Y., Cai, Y.: Segkan: High-resolution medical image segmentation with long-distance dependencies. arXiv preprint arXiv:2412.19990 (2024) 31. Tan, S., Zhang, Z., Cai, Y., Ergu, D., Wu, L., Hu, B., Yu, P., Zhao, Y.: Segstitch: Multidimensional transformer for robust and efficient medical imaging segmentation. arXiv preprint arXiv:2408.00496 (2024) 32. Tizhoosh, H., et al.: On image search in histopathology. Medical Image Analysis 87, 102372 (2024) 33. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y., Liu, D., Mu, Y., Tan, M., Wang, X., et al.: Deep high-resolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence 43(10), 33493364 (2020) 34. Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., Han, X.: Transformer-based unsupervised contrastive learning for histopathological image classification. Med. Image Anal. 81, 102559 (2022) 12 PathoHR 35. Wu, B., Xie, Y., Zhang, Z., Ge, J., Yaxley, K., Bahadir, S., Wu, Q., Liu, Y., To, M.S.: Bhsd: 3d multi-class brain hemorrhage segmentation dataset. In: International Workshop on Machine Learning in Medical Imaging. pp. 147156. Springer (2023) 36. Wu, B., Xie, Y., Zhang, Z., Phan, M.H., Chen, Q., Chen, L., Wu, Q.: Xlip: Crossmodal attention masked modelling for medical language-image pre-training. arXiv preprint arXiv:2407.19546 (2024) 37. Yu, X., Yang, Q., Zhou, Y., Cai, L.Y., Gao, R., Lee, H.H., Li, T., Bao, S., Xu, Z., Lasko, T.A., et al.: Unest: local spatial representation learning with hierarchical transformer for efficient medical segmentation. Medical Image Analysis 90, 102939 (2023) 38. Zhang, R., Guo, H., Zhang, Z., Yan, P., Zhao, S.: Gamed-snake: Gradient-aware adaptive momentum evolution deep snake model for multi-organ segmentation. arXiv preprint arXiv:2501.12844 (2025) 39. Zhang, Z., Ahmed, K.A., Hasan, M.R., Gedeon, T., Hossain, M.Z.: deep learning approach to diabetes diagnosis. In: Asian Conference on Intelligent Information and Database Systems. pp. 8799. Springer (2024) 40. Zhang, Z., Qi, X., Chen, M., Li, G., Pham, R., Qassim, A., Berry, E., Liao, Z., Siggs, O., Mclaughlin, R., et al.: Jointvit: Modeling oxygen saturation levels with joint supervision on long-tailed octa. In: Annual Conference on Medical Image Understanding and Analysis. pp. 158172. Springer (2024) 41. Zhang, Z., Qi, X., Zhang, B., Wu, B., Le, H., Jeong, B., Liao, Z., Liu, Y., Verjans, J., To, M.S., et al.: Segreg: Segmenting oars by registering mr images and ct annotations. In: 2024 IEEE International Symposium on Biomedical Imaging (ISBI). pp. 15. IEEE (2024) 42. Zhang, Z., Yi, N., Tan, S., Cai, Y., Yang, Y., Xu, L., Li, Q., Yi, Z., Ergu, D., Zhao, Y.: Meddet: Generative adversarial distillation for efficient cervical disc herniation detection. In: 2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). pp. 40244027. IEEE (2024) 43. Zhang, Z., Zhang, B., Hiwase, A., Barras, C., Chen, F., Wu, B., Wells, A.J., Ellis, D.Y., Reddi, B., Burgan, A.W., To, M.S., Reid, I., Hartley, R.: Thin-thick adapter: Segmenting thin scans using thick annotations. OpenReview (2023) 44. Zhao, L., Hou, R., Teng, H., Fu, X., Han, Y., Zhao, J.: Coads: Cross attention based dual-space graph network for survival prediction of lung cancer using whole slide images. Computer Methods and Programs in Biomedicine 236, 107559 (2023) 45. Zhao, R., Zhang, Z., Xu, Y., Yao, Y., Huang, Y., Zhang, W., Song, Z., Chen, X., Zhao, Y.: Peddet: Adaptive spectral optimization for multimodal pedestrian detection. arXiv preprint arXiv:2502.14063 (2025) 46. Zhao, Y., Liao, Z., Liu, Y., Nijhuis, K.O., Barvelink, B., Prijs, J., Colaris, J., Wijffels, M., Reijman, M., Zhang, Z., et al.: landmark-based approach for instability prediction in distal radius fractures. In: 2024 IEEE International Symposium on Biomedical Imaging (ISBI). pp. 15. IEEE (2024) 47. Zheng, Q., Yang, R., Ni, X., Yang, S., Xiong, L., Yan, D., Xia, L., Yuan, J., Wang, J., Jiao, P., et al.: Accurate diagnosis and survival prediction of bladder cancer using deep learning on histological slides. Cancers 14(23), 5807 (2022)"
        }
    ],
    "affiliations": [
        "ANU",
        "DLMU",
        "Dartmouth",
        "La Trobe",
        "MBZUAI",
        "NUP",
        "SZTU",
        "UCAS",
        "XJLTU",
        "XJTU"
    ]
}