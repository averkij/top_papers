{
    "paper_title": "Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders",
    "authors": [
        "Yue Meng",
        "Nathalie Majcherczyk",
        "Wenliang Liu",
        "Scott Kiesel",
        "Chuchu Fan",
        "Federico Pecora"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Multi-agent coordination is crucial for reliable multi-robot navigation in shared spaces such as automated warehouses. In regions of dense robot traffic, local coordination methods may fail to find a deadlock-free solution. In these scenarios, it is appropriate to let a central unit generate a global schedule that decides the passing order of robots. However, the runtime of such centralized coordination methods increases significantly with the problem scale. In this paper, we propose to leverage Graph Neural Network Variational Autoencoders (GNN-VAE) to solve the multi-agent coordination problem at scale faster than through centralized optimization. We formulate the coordination problem as a graph problem and collect ground truth data using a Mixed-Integer Linear Program (MILP) solver. During training, our learning framework encodes good quality solutions of the graph problem into a latent space. At inference time, solution samples are decoded from the sampled latent variables, and the lowest-cost sample is selected for coordination. Finally, the feasible proposal with the highest performance index is selected for the deployment. By construction, our GNN-VAE framework returns solutions that always respect the constraints of the considered coordination problem. Numerical results show that our approach trained on small-scale problems can achieve high-quality solutions even for large-scale problems with 250 robots, being much faster than other baselines. Project page: https://mengyuest.github.io/gnn-vae-coord"
        },
        {
            "title": "Start",
            "content": "Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders Yue Meng1, Nathalie Majcherczyk2, Wenliang Liu2, Scott Kiesel2, Chuchu Fan1 and Federico Pecora2 5 2 0 2 4 ] . [ 1 4 5 9 2 0 . 3 0 5 2 : r Abstract Multi-agent coordination is crucial for reliable multi-robot navigation in shared spaces such as automated warehouses. In regions of dense robot traffic, local coordination methods may fail to find deadlock-free solution. In these scenarios, it is appropriate to let central unit generate global schedule that decides the passing order of robots. However, the runtime of such centralized coordination methods increases significantly with the problem scale. In this paper, we propose to leverage Graph Neural Network Variational Autoencoders (GNN-VAE) to solve the multi-agent coordination problem at scale faster than through centralized optimization. We formulate the coordination problem as graph problem and collect ground truth data using Mixed-Integer Linear Program (MILP) solver. During training, our learning framework encodes good quality solutions of the graph problem into latent space. At inference time, solution samples are decoded from the sampled latent variables, and the lowest-cost sample is selected for coordination. By construction, our GNN-VAE framework returns solutions that always respect the constraints of the considered coordination problem. Numerical results show that our approach trained on small-scale problems can achieve high-quality solutions even for large-scale problems with 250 robots, being much faster than other baselines. I. INTRODUCTION Multi-agent coordination is essential to ensure that fleet of robots can navigate shared spaces, such as warehouse floors [33] and public roads [1]. Effective coordination avoids collisions, reduces delays, and optimizes resource usage. Coordination between robots can either be achieved implicitly by each robot acting to avoid conflicts based on its local information, or explicitly via distributed or centralized decision-making. The former category of methods implies pre-determined mutual understanding between robots (e.g. set of rules or reciprocal policies). Their myopic nature is ill-suited for solving complex scenarios with many agents. The latter methods can plan ahead to optimize fleet operation, allowing robots to achieve common goals safely and efficiently in challenging settings. However, existing explicit coordination methods face fundamental trade-off between optimality and computational tractability, particularly as the number of robots increases or the task objectives become more complex. While heuristicbased methods [9] and sampling-based methods [27] are fast in computation, they often struggle to provide high-quality *This research was done during Yues internship at Amazon. Project page: https://mengyuest.github.io/gnn-vae-coord/ 1Yue Meng and Chuchu the Massachusetts of Technology, Cambridge, MA 02139 USA. Email: are with Fan Institute {mengyue,chuchu}@mit.edu 2Authors are with Amazon Robotics, North Reading, MA USA. Email: {majcherc,liuwll,skkiesel,fpecora}@amazon.com solutions for large graphs and require carefully crafted designs tailored to specific objectives. On the other hand, exact methods such as optimization-based approaches [22] and search-based methods [23] can deliver better quality results, but their exponential complexity makes them impractical for large-scale problems. In light of the recent advances in deep generative models [21], we leverage Graph Neural Networks (GNN) and Variational Autoencoders (VAE) to learn the distribution of the high-quality solutions for multi-agent coordination problems. This approach offers several key advantages: (i) GNN are well-suited for embedding the inherent graphical structure of multi-agent coordination problems, enabling them to capture complex interactions among robots. (ii) VAE incorporate uncertainties in the problem, opening the possibility to generate multiple candidate solutions. (iii) Neural Networks are efficient in evaluation, leveraging GPU parallel computation for faster performance, and (iv) deep generative models based on graphs can generalize effectively to larger-scale problems. In this paper, we propose GNN-VAE based framework to achieve reliable and efficient multi-agent coordination. Framing the multi-agent coordination problem as an optimization problem on graph, we collect optimal solutions using Mixed-Integer Linear Program (MILP) solver. During training, the GNN-VAE encodes these solutions into latent space. At the inference stage, latent embeddings are sampled from the latent space and are further decoded to the solution samples, with the solution sample having the lowest cost selected for the coordination problem. Rather than predicting pure solution labels, GNN-VAE learns node ranks and edge modes in semi-supervised manner to construct the solution, ensuring the prediction satisfies formal constraints of the coordination problem. Our contributions can be summarized as follows: 1) We propose novel learning framework that utilizes GNN-VAEs to tackle the particular application of multi-agent navigation in shared space, leveraging the generative nature of the model to sample from the set of feasible problem solutions. 2) We propose two-branch learning framework that guarantees, by construction, the satisfaction of two types of constraints of the coordination problem when inferring solutions. 3) We perform an extensive evaluation of our approach, benchmarking it against strong baselines for problems involving up to 250 robots. II. RELATED WORK This paper considers centralized, explicit coordination problems, which belong to resource-constrained project scheduling problems (RCPSP) [29] known to be NPhard [2]. Related work can be divided into heuristic-based methods [6], optimization-based methods [22], search-based methods [23] and sampling-based methods [34]. An extensive comparison in [30] shows that meta-heuristic methods such as Tabu search outperforms other algorithms, and optimization-based methods work well on small-scale problems. Our approach does not require handcrafted heuristics designs, nor does it require time-consuming search or optimization processes. Instead, our method is akin to the sampling-based methods as it learns the underlying solution distribution from the demonstrated data, enabling it to scale and generalize to large-scale unseen scenarios. [35], to new scenarios [24], Recent advances in neural networks have introduced datadriven approaches for multi-agent systems [8]. Graph Neural Networks (GNN) [20], [37], [3] show significant advantage in representing complex interactions between robots and generalize well [36]. Deep generative models such as Variational Autoencoders (VAE) [18], Generative Adversarial Networks (GAN) [11] and Diffusion models [15] have shown great success in learning from demonstrated data [31], [16], [17]. Inspired by these contributions, we propose to utilize Graph Variational Autoencoders [21] to learn solution distribution for explicit coordination problems. The closest paper to ours is [32], which uses GNN to solve multi-robot coordination tasks with two to five robots. We consider tasks with diverse dependencies among robots with density constraints, and with the novel structural design, our method is guaranteed to generate feasible solutions and can scale up to 250 robots. : Ri(qi) = ϕ} with Ri III. PRELIMINARIES Robot configurations and paths.1 Consider robots navigating in shared 2D environment R2 with static obstacles W. The i-th robots configuration space is Qi SE(2) = R2 S1 where configuration consists of the 2D position and heading angle. We define obstaclefree configurations for the i-th robot as Qfree = {qi : Qi 2R2 Qi indicating the robots occupancy in the environment. Given start, goal configurations qs : [0, 1] Qf ree , and other kinematic constraints. Interfering intervals. Given an interference relation ξ : Qf ree [0, 1], with 1 indicating the collision with two robots and 0 being collision-free, pair of k-interfering intervals ([li, ui], [lj, uj]) ([0, 1] [0, 1]) for paths pi, pj is defined as (here 0 < < 1): , qg that satisfies pi(0) = qs , path is function pi , pi(1) = qg Qf ree Qf ree {σi [li, ui], σj [lj, uj], s.t. ξ(pi(σi), pj(σj)) k} {σj [lj, uj], σi [li, ui], s.t. ξ(pi(σi), pj(σj)) k} (1) 1We mainly follow the coordination graph formulation in [26] and [30]. i=1 and we will refer to this pair of intervals as an interfering section between two robots. These interfering intervals are maximal k-interfering intervals if they cannot be further expanded while satisfying the conditions above. For brevity, we will refer to them as interfering intervals for the rest of the paper. For pair of paths pi, pj, denote the set of all interfering intervals as Ξ(pi, pj, k). Coordination graphs. Given all the interfering intervals for the robots 1 j=i+1Ξ(pi, pj, k), we construct mixed graph = (V, P, A) with the vertices set , the directed edge set and the undirected edge set A. The node vp is associated with the pth merged interfering interval 2 for the , vp+1 ith robot. denotes all the precedence edges: (vp ) , vq and denotes all the unordered joint action edges {vp } for each pair of interfering intervals ([lp ]) with = j. The graph is called coordination skeleton graph. (full) coordination graph is coordination skeleton graph with each joint action edge assigned to value that decides the passing order and the passing pattern for the robots at the interfering section. For each pair {vp , vq } A, the joint action values are = {, , , }, where: ], [lq , up , uq , vq }) {vp Exclusive: vp Following: vp vq navigate beyond lq vq navigate beyond lq imposes the j-th robot must wait to until the i-th robot has reached up . imposes the j-th robot must wait to until the i-th robot has reached lp . Problem constraints. Denote : the function to assign joint action edges with values, and the assignment for graph wG = {w({vp , vq } A}. We have the constraints: (1) The directed graph GwG induced by the skeleton graph and the assignment wG is acyclic (no cycles in the graph), and (2) the number of followingtype edges is restricted. The former (acyclic constraint) is to avoid deadlocks caused by circular waiting among the robots, and the latter (density constraint) limits the maximum number of robots allowed to pass the interfering section simultaneously. The density constraint is enforced on maximal cliques 3 on the subgraph = (V, A): for each maximal clique K(G) with density constraint ρK, the number of following-type edges should be no more than hK = (ρK +1)ρK Travel time under assignment. We consider the updated robots travel time as main objective to measure the assigni , up ment quality. Each interfering interval [lp ] is associated with an expected travel time interval [Lp , ] indicating the scheduled time for the ith robot to enter lp and to exit up if there is no interference. Given an assignment wG, the updated travel time intervals [ Lp ] for robots 1.4 An illustration is shown in Fig. 1. ], [ Lq , j , q 2 2If interfering intervals from different pairs overlap on robot path, we merge them but keep the intervals entering/exit time per interfering pair. 3A clique is subset of vertices where every pair is connected by an edge, while maximal clique is clique that cannot be extended by including any additional adjacent vertex. 4The minimum number of following edges needed for robots to pass . Hence, the maximum through an interfering region at once is k(k1) allowed for density ρK is (ρK +1)ρK 1. 2 Fig. 1: Illustration for the coordination graph. , vq , vq , vq , vq j Lp , if w({vp , if w({vp , if w({vp , if w({vp }) =; Lq }) =; Lq i, at the interfering section should satisfy: Lp i Lq Lp }) = }) = . (2) Globally, the updated travel time should satisfy monotoneincreasing delay constraint along the path. Denote all the distinct expected time for the robot to enter and exit its interfering intervals sorted as 0 (1) (2) ... (Ci) , (2) . The updated travel time (1) should satisfy: 0 (1) , ..., (Ci) ... (Ci) T (2) (2) (1) (Ci) . (3) i denotes the delay at the lth stage. The minimum values to satisfy the constraints in (2) and (3) for all the robots form the updated travel time. Here (Ci) denotes the updated task finishing time of robot, = (l) and D(l) (l) IV. PROBLEM FORMULATION Given coordination skeleton graph = (V, P, A), set of density constraints K(G) on its subgraph = (V, A), and an expected travel time {{T (p) i=1 for multiagent coordination problem defined in Sec. III, we aim to find the optimal assignment that minimizes the cost function fG,T : while satisfying the acyclic and density constraints: }Ci p=1}N Min wGW fG,T (wG) s.t. GwG is directed acyclic graph (DAG). (cid:88) 1(w({v,v}){,}) hK, K(G) v,vK,v=v (4) where 1(w({v,v}){,}) is 1 if the assignment for the edge {v, v} is following-type, otherwise 0. Different cost functions will be explained in the following section. ij = 1). Using the big-M method [14] with big (zpq positive number, the MILP formulation is: , Lp min ({ypq s.t. ypq ij , zpq ij }{vp ij + zpq , }A, {Lp i , ij + Lp , , i ,vq ij + Lq ij ) + zpq Lp , ij ) + Lp Lq , zpq ij hK, (1 ypq ij + Lq ypq (1 ypq (cid:88) ) , vq , vq , vq , vq }vp (vp ) {vp } {vp } {vp } K(G) ,vq {vp }K (1) 0 (1) }Ci (2) (2) (Ci) (Ci) {1, 2, ..., } (5) where {T (l) l=1 are the sorted distinct expected enter/exit time in the ascending order for the ith robot. The first four constraints are exclusive and following constraints. The next one is for density constraints. The last one indicates the monotone increasing delay for the robots. For the objective function, we consider the average completion time, the maximum completion time, the synchronized completion time and the average interference delay, defined as follows: tavg = 1 (cid:88) i=1 (Ci) , tmax = max i=1,...,N (Ci) tsync = tavg + 1 (cid:88) i=1 (Ci) tavg, (6) tdelay = 1 N (cid:88) i=1 1 Ci Ci(cid:88) ( (p) (p) ). p=1 For each objective function and graph, we collect top Loptimal assignments using MILP solver, which will be used to train our GNN-VAE model. V. TECHNICAL APPROACH B. Assignment prediction using GNN-VAE A. MILP formulation for assignment optimization Given the problem defined in Eq. (4), we can find the optimal solution considering the following MILP. For every joint action edge {vp } A, we denote the binary decision variables ypq ij to indicate whether an edge is pointing to vp to vq from vp ij = 1), and denote the binary decision variables zpq ij to indicate whether an edge is an exclusive type (zpq ij = 0) or following type ij = 0) or from vq (ypq (ypq , vq Graph data encoding. The GNN-VAEs input has the same number of nodes as in the coordination graph, where we assign directed edge for precedence edges and bidirected edges for joint action edges. The node feature for vp is (Lp ) which are the left and right expected travel time at the pth merged interfere section and the density constraint. The edge feature for (vp ) on the completed graph ij , wpq is (Lpq ij ) with the expected enter/exit time for the ij , pq , , ρp , vq Fig. 2: Learning framework: The GNN-VAE first encodes the assignment via graph convolution and graph max pooling to latent embedding. The sampled latent code is sent to the decoder and the two-branch MLP to get the predicted assignment. when considering the interference , and wij indicating the joint action type. The edge interfering interval of vp with vq feature for the skeleton graph is (Lij, Uij, 0). GNN-VAE learning framework. In training, the assignment graph is sent to the graph encoder with global max-pooling to derive the latent embedding, which is used to reconstruct graph assignments. In testing, the embedding is directly sampled from standard normal distribution. In the decoding process, we concatenate the embedding node-wise on the skeleton graph and conduct message propagation. Here we use graph attention layer (GATv2) proposed in [3] for the encoder and the decoder. The resulting fused features are then utilized to generate the assignments. Violation-free assignment generation. Our GNN-VAE predicts the node ranks and edge types to generate assignments that are guaranteed by design to satisfy the acyclic and density constraints. The fused feature vector for each node vi is sent into multi-layer perceptron (MLP) to predict the node bid bi > 0. The nodes ranks are computed from the bids under the following graph operation: ri = bi + (cid:88) bj jA(i) (7) where A(i) denotes all the ancestors for the node vi on the coordination graph with only precedence edges = (V, ). The joint action edges direction then are determined by pointing from the lower-ranked nodes to the higher-ranked nodes. variation of hinge loss is used to ensure the learned ranks consistent with the ground truth assignments: Lbar = (cid:88) {vi,vj }A [σ+(ri rj)1ij + σ+(rj ri)1ji] (8) where 1ij = 1 if the edge is from vi to vj in the assignment and 0 otherwise, and σ+(x) = max(x+γ, 0) with bloating factor γ > 0 for numerical stability. To determine if an undirected edge {vi, vj} is exclusive or following, we use an MLP with input the fused node features from vi, vj to predict the edge type with the binary cross-entropy loss: Lbce = (cid:88) {vi,vj }A [yij log(ˆpij) + (1 yij) log(1 ˆpij)] (9) here ˆpij is the estimated probability for the edge {vi, vj} being following-type, and yij is the binary ground truth label (with 1 being the following-type). Upon assignment generation, for each maximal clique on the graph, we sort edges based on pij and select the top-hk edges to be following-type. This formulation guarantees that the assignment always adheres to the density limit. Finally, we use KL-divergence loss to regularize the latent space distribution to be similar to standard normal distribution and the final loss becomes: = α1Lbar + α2Lbce + α3Lkl (10) where α1, α2, α3 weighs the balance between loss terms. Remarks. Our method is reliable and expressive: The generated assignments can always satisfy the acyclic and density constraints. Moreover, it can produce corresponding assignment for any directed acyclic graph (DAG) with any distribution of the following-type edges. The density constraints are met since the top-k selection mechanism allows at most hk robots into an interfering interval at once. Therefore, we just complete our proof of this statement for the acyclic constraints below. Proposition 1 Given mixed graph = (V, E, S) with disjointed directed edges and undirected edges and = (V, E) Gd directed acyclic graph (DAG), denote the transformation from the mixed graph and node bids to new directed graph as : BV Gd. The following properties hold: (1) bV BV , Gnew = (G, rV ) is DAG containing E. (2) Enew, if Gnew = (V, Enew) is DAG, then bV BV such that (G, bV ) = Gnew. Proof: (1) By [4] (Section 22.4), the partial order on the set of nodes induces DAG. Since the node ranks rV derived from the node bids bV is valid partial order, we know the Gnew is DAG, and it remains to show the newly induced graph contains edges in E, that i.e., (u, v) E, ru < rv. Since and all its ancestors are also the ancestors of v, and the node ranks are all positive, rv = bv + (cid:80) bj bv + ru > ru. bi bv + bu + (cid:80) iA(v) jA(u) Thus, Gnew = (G, bV ) is DAG that contains E. (2) We prove it by construction. Any DAG has at least one topological ordering, where, for any edge (u, v) on the DAG, appears before v. We assign the node bids following (a) Average completion time (b) Maximum completion time (c) Synchronized completion time (d) Average interfere delay Fig. 3: Main comparisons for solution quality and computation runtime under different cost functions. the topological order for Gnew so that the ancestors bids and ranks are available when determining the current nodes bid. Denote the current node as and then (u, v) E, any positive bv will ensure rv > ru (proved above). To ensure (w, v) Enew, rv > rw, we can assign bv = bk} + ϵ with ϵ > 0 and Av denotes max{0, max jAv rj (cid:80) kAv the set of all the ancestors for the current node. Thus, we can get rv = bv + (cid:80) rj + ϵ > rw. We continue this kAv process to get all the node bids bV , which, by construction, generates Gnew = (V, Enew). bk > max jAv VI. EXPERIMENTS Implementation details. We randomly generate 10000 coordination problems with 2 to 8 robots and up to 14 interfering sections in each case. For each cost function, we use the Gurobi MILP solver [12] to generate the top-10 optimal assignments and form the training and validation datasets. In our GNN-VAE learning framework, the encoder and decoder are GATv2 layers [3], and the node/edge prediction heads are MLPs. Both GATv2 and MLP are implemented with 4 hidden layers, 256 units in each layer, and ReLU activation is used for the intermediate layers. The learning pipeline is implemented in Pytorch Geometric [7], [28]. The training is conducted with an ADAM [19] optimizer, learning rate 3 104 and batch size 128. The coefficients are α1 = 1.0, α2 = 1.0, α3 = 0.01, γ = 0.1. The training takes 1 2 hours on an NVidia A100 GPU. During evaluation, for each graph, we sample 100 assignments from the GNN-VAE decoder and select the one with the lowest cost. Baselines. We consider: (1) Random: randomly generate node ranks and joint action edge types to form valid assignment (2) FCFS: first-come-first-serve to assign the joint action direction (if has an earlier entering time than B, an edge points from to B) and randomly generate edge types (3) Tabu: local search algorithm based on Tabu Search [10], initialized with the solution from FCFS (4) CMA-ES: Covariance Matrix Adaptation Evolution Strategy [13], (5) B-BTS: budgeted backtrack search that finds the first 1000 feasible candidates and select the one with the lowest cost, and (6) MILP: mixed-integer linear program (treated as the oracle since it generates optimal solutions). Metrics. (1) Optimality ratio: the ratio of the oracle assignment cost to the predicted assignment cost, number between (0,1] to measure the assignment quality (the closer to 1, the better quality of the assignment) (2) Computation runtime: the average runtime to solve problem. A. Main results on small-scale problems We train our GNN-VAE on four datasets with varied cost functions and evaluate on the validation set. As shown in Fig. 3, regarding the optimality ratio, Ours outperforms Random, FCFS and B-BTS, achieving comparable performance to strong baselines such as Tabu and CMA-ES while being one magnitude faster than both approaches in the computation runtime. With few CMA-ES refinement steps conducted based on our predicted assignment solution (denoted as Ours*), we achieve the closest-to-oracle (MILP) solution quality with slight increase in the computation time. Our method demonstrates consistent advantage across varied objective functions, with the most significant improvement over baselines observed on the Average interfere is intuitive, as the delay metric delay cost. This result captures the absolute difference in robot progress at each interference section, and is therefore not affected by the total length of the progress. This shows our GNN-VAE can effectively learn to capture the optimal solution distribution and achieves better trade-off between the solution quality and the inference runtime compared to other approaches. Fig. 4: Performance over larger graphs. B. Generalizability and scalability to large-scale problems The main advantages of our GNN-VAE are that it can generalize well to larger graphs without retraining and that (a) Absolute runtime (seconds) (b) Normalized runtime Fig. 5: Runtime breakdown for GNN-VAE at inference stage. it can scale better than other search-based or optimizationbased methods. We generate large-scale problems by (1) creating the coordination subgraphs following the procedure as creating small-scale problems and (2) randomly stitching subgraphs together by adding more interfering relations over vertices from different subgraphs. The original problem involves on average 5 robots, whereas the average numbers of robots on the new generated graphs range from 10 to 250. We select the GNN-VAE model pre-trained on the Average completion time dataset and directly compare it with strong baselines B-BTS, MILP and CMA-ES5 on the newly generated varied-size large-scale problems. In this stage, we do not conduct further CMA-ES refinement due to the time limit. As shown in Fig. 4, our approach can generate close-to-oracle assignments with the optimality ratio consistently over 0.9 while the optimality ratio curves for BBTS and CMA-ES drop quickly as the number of robots is more than 20. This shows the great generalizability of our approach. Regarding the algorithm runtime, our approach can be 10 to 20 times faster than the baselines, and we can solve the coordination problem with 250 robots in less than 5 seconds on average. Fig. 5 shows runtime breakdown analysis where it reveals that the bottleneck is not from data processing or the neural network operations, but from measuring the assignment quality, which can be computed in parallel fashion as they do not depend on each other. We believe this could further improve our runtime performance. C. Test on out-of-distribution data in simulation We randomly generate disk-shaped and rectangular obstacles in 2d environment and use search-based path planner [25] to generate reference paths for the robots. Next, we create the coordination graph based on these reference paths and use our GNN-VAE to generate an assignment. Then we compute the updated travel time for robots at interfering sections. At every simulation step, if the time is before the updated travel time, the robot will wait on the reference path; otherwise, the robot will track the reference path. We conduct the simulation in PyBullet environment [5]. The screenshot for the simulation and the cost ratio are shown in Fig. 6. We can see that our model pretrained on the small-scale synthetic graph dataset can generalize to out-of-distribution scenarios, providing close-to-oracle quality schedules for up-to-eight robots, and still better than Random for <10 robots. 5We did not compare with TABU because it is too time-consuming on the larger graphs, and we did not compare with FCFS or Random because they cannot produce quality solutions. (a) Simulation screenshot. (b) Cost ratio curve under varied number of robots in simulation. Fig. 6: Out-of-distribution test in simulation environments. Fig. 7: Ablation study on the number of GNN-VAE samples. D. Ablation studies At the testing phase for the Average completion time dataset, we sample various numbers of samples per graph and evaluate the performance. As shown in Fig. 7, with one sample used, the optimality ratio is 0.96, and as the number of samples increases, the optimality ratio improves and finally converges to 0.98 at the cost of increasing runtime. This shows the advantage of using VAE for assignment prediction, as we can pick the one with the highest performance from multiple candidates. To balance the quality and the runtime, we generate 100 samples per graph in our experiments. VII. CONCLUSIONS We propose Graph Neural Network Variational Autoencoder (GNN-VAE) framework to generate high-quality solutions for multi-agent coordination problem. Treating coordination as graph optimization problem, we design GNN-VAE to learn assignments in semi-supervised manner from the optimal solutions. Our GNN-VAE has been proven to generate feasible solutions that satisfy the acyclic and density constraints inherent in coordination problems. Trained in small-scale problems, our method shows great generalizability and scalability in large-scale problems, generating near-optimal solutions 20 times faster than the oracle and achieving better quality-efficiency trade-offs than other baselines. However, some limitations remain: our approach relies on ground truth data and thus cannot adapt to flexible cost functions after training. Besides, we assume fully observable environment without uncontrollable agents (e.g., pedestrians). We aim to address these in future work."
        },
        {
            "title": "REFERENCES",
            "content": "[1] Jeffrey Adler and Victor Blue. cooperative multi-agent transportation management and route guidance system. Transportation Research Part C: Emerging Technologies, 10(5-6):433454, 2002. [2] Jacek Blazewicz, Jan Karel Lenstra, and AHG Rinnooy Kan. Schedulto resource constraints: classification and complexity. ing subject Discrete applied mathematics, 5(1):1124, 1983. [3] Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph attention networks? arXiv preprint arXiv:2105.14491, 2021. [4] Thomas Cormen, Charles Leiserson, Ronald Rivest, and Clifford Stein. Introduction to algorithms. MIT press, 2022. [5] Erwin Coumans and Yunfei Bai. Pybullet, python module for physics simulation for games, robotics and machine learning, 2016. [6] Eline De Frene, Damien Schatteman, Willy Herroelen, and Stijn Van de Vonder. heuristic methodology for solving spatial resourceconstrained project scheduling problems. Available at SSRN 1089355, 2007. [7] Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. arXiv preprint arXiv:1903.02428, 2019. [8] Kunal Garg, Songyuan Zhang, Oswin So, Charles Dawson, and Chuchu Fan. Learning safe control for multi-robot systems: Methods, verification, and open challenges. Annual Reviews in Control, 57:100948, 2024. [9] William Gere Jr. Heuristics in job shop scheduling. Management Science, 13(3):167190, 1966. [10] Fred Glover and Manuel Laguna. Tabu search. Springer, 1998. [11] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. the ACM, Generative adversarial networks. 63(11):139144, 2020. Communications of [12] Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2024. [13] Nikolaus Hansen, Sibylle Muller, and Petros Koumoutsakos. Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (cma-es). Evolutionary computation, 11(1):118, 2003. [14] Frederick Hillier and Gerald Lieberman. Introduction to operations research. McGraw-Hill, 2015. [15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion information processing probabilistic models. Advances in neural systems, 33:68406851, 2020. [16] Boris Ivanovic and Marco Pavone. The trajectron: Probabilistic multiagent trajectory modeling with dynamic spatiotemporal graphs. In Proceedings of the IEEE/CVF international conference on computer vision, pages 23752384, 2019. [17] Chiyu Jiang, Andre Cornman, Cheolho Park, Benjamin Sapp, Yin Zhou, Dragomir Anguelov, et al. Motiondiffuser: Controllable multithe agent motion prediction using diffusion. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 96449653, 2023. In Proceedings of [18] Diederik Kingma. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013. [19] DP Kingma. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [20] Thomas Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016. [21] Thomas Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308, 2016. [22] Thomas Kyriakidis, Georgios Kopanos, and Michael Georgiadis. Milp formulations for single-and multi-mode resourceconstrained project scheduling problems. Computers & chemical engineering, 36:369385, 2012. [23] Jiaoyang Li, Wheeler Ruml, and Sven Koenig. Eecbs: boundedsuboptimal search for multi-agent path finding. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 12353 12362, 2021. [24] Maosen Li, Siheng Chen, Yanning Shen, Genjia Liu, Ivor Tsang, and Ya Zhang. Online multi-agent forecasting with interpretable IEEE Transactions on Neural collaborative graph neural networks. Networks and Learning Systems, 35(4):47684782, 2022. [25] Maxim Likhachev. Search-based planning with motion primitives, 2010. [26] Anna Mannucci, Lucia Pallottino, and Federico Pecora. On provably safe and live multirobot coordination with online goal posting. IEEE Transactions on Robotics, 37(6):19731991, 2021. [27] Mohammad Nabi Omidvar and Xiaodong Li. comparative study In Australasian Joint of cma-es on large scale global optimisation. Conference on Artificial Intelligence, pages 303312. Springer, 2010. [28] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, highperformance deep learning library. Advances in neural information processing systems, 32, 2019. [29] Alan Pritsker, Lawrence Waiters, and Philip Wolfe. Multiproject scheduling with limited resources: zero-one programming approach. Management science, 16(1):93108, 1969. [30] Jarosław Rudy, Radosław Idzikowski, Elzbieta Roszkowska, and Konrad Kluwak. Multiple mobile robots coordination in shared workspace for task makespan minimization. Processes, 10(10):2087, 2022. [31] Jiaming Song, Hongyu Ren, Dorsa Sadigh, and Stefano Ermon. Multiagent generative adversarial imitation learning. Advances in neural information processing systems, 31, 2018. [32] Zheyuan Wang and Matthew Gombolay. Learning scheduling policies IEEE for multi-robot coordination with graph attention networks. Robotics and Automation Letters, 5(3):45094516, 2020. [33] Peter Wurman, Raffaello DAndrea, and Mick Mountz. Coordinating hundreds of cooperative, autonomous vehicles in warehouses. AI magazine, 29(1):99, 2008. [34] Ke Xue, Jiacheng Xu, Lei Yuan, Miqing Li, Chao Qian, Zongzhang Zhang, and Yang Yu. Multi-agent dynamic algorithm configuration. Advances in Neural Information Processing Systems, 35:2014720161, 2022. [35] Chenning Yu, Hongzhan Yu, and Sicun Gao. Learning control admissibility models with graph neural networks for multi-agent navigation. In Conference on robot learning, pages 934945. PMLR, 2023. [36] Songyuan Zhang, Oswin So, Kunal Garg, and Chuchu Fan. Gcbf+: neural graph control barrier function framework for distributed safe multi-agent control. arXiv preprint arXiv:2401.14554, 2024. [37] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. Graph neural networks: review of methods and applications. AI open, 1:57 81, 2020."
        }
    ],
    "affiliations": [
        "Amazon Robotics, North Reading, MA USA",
        "Massachusetts Institute of Technology, Cambridge, MA 02139 USA"
    ]
}