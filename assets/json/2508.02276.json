{
    "paper_title": "CellForge: Agentic Design of Virtual Cell Models",
    "authors": [
        "Xiangru Tang",
        "Zhuoyun Yu",
        "Jiapeng Chen",
        "Yan Cui",
        "Daniel Shao",
        "Weixu Wang",
        "Fang Wu",
        "Yuchen Zhuang",
        "Wenqi Shi",
        "Zhi Huang",
        "Arman Cohan",
        "Xihong Lin",
        "Fabian Theis",
        "Smita Krishnaswamy",
        "Mark Gerstein"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Virtual cell modeling represents an emerging frontier at the intersection of artificial intelligence and biology, aiming to predict quantities such as responses to diverse perturbations quantitatively. However, autonomously building computational models for virtual cells is challenging due to the complexity of biological systems, the heterogeneity of data modalities, and the need for domain-specific expertise across multiple disciplines. Here, we introduce CellForge, an agentic system that leverages a multi-agent framework that transforms presented biological datasets and research objectives directly into optimized computational models for virtual cells. More specifically, given only raw single-cell multi-omics data and task descriptions as input, CellForge outputs both an optimized model architecture and executable code for training virtual cell models and inference. The framework integrates three core modules: Task Analysis for presented dataset characterization and relevant literature retrieval, Method Design, where specialized agents collaboratively develop optimized modeling strategies, and Experiment Execution for automated generation of code. The agents in the Design module are separated into experts with differing perspectives and a central moderator, and have to collaboratively exchange solutions until they achieve a reasonable consensus. We demonstrate CellForge's capabilities in single-cell perturbation prediction, using six diverse datasets that encompass gene knockouts, drug treatments, and cytokine stimulations across multiple modalities. CellForge consistently outperforms task-specific state-of-the-art methods. Overall, CellForge demonstrates how iterative interaction between LLM agents with differing perspectives provides better solutions than directly addressing a modeling challenge. Our code is publicly available at https://github.com/gersteinlab/CellForge."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 ] . [ 1 6 7 2 2 0 . 8 0 5 2 : r CellForge: Agentic Design of Virtual Cell Models Xiangru Tang, Zhuoyun Yu, Jiapeng Chen, Yan Cui, Daniel Shao, Weixu WangH, Fang Wu, Yuchen Zhuang, Wenqi Shi(cid:154), Zhi Huang, Arman Cohan, Xihong Lin(cid:0), Fabian TheisH, Smita Krishnaswamy, Mark Gerstein Yale University, University of Pennsylvania, HHelmholtz Zentrum Munchen, Stanford University, Google DeepMind, (cid:0)Harvard University"
        },
        {
            "title": "Abstract",
            "content": "Virtual cell modeling represents an emerging frontier at the intersection of artificial intelligence and biology, aiming to predict quantities such as responses to diverse perturbations quantitatively. However, autonomously building computational models for virtual cells is challenging due to the complexity of biological systems, the heterogeneity of data modalities, and the need for domain-specific expertise across multiple disciplines. Here, we introduce CELLFORGE, an agentic system that leverages multi-agent framework that transforms presented biological datasets and research objectives directly into optimized computational models for virtual cells. More specifically, given only raw single-cell multi-omics data and task descriptions as input (e.g., for control and perturbed conditions and directive to build model of new perturbation), CELLFORGE outputs both an optimized model architecture and executable code for training virtual cell models and inference. The framework integrates three core modules: Task Analysis for presented dataset characterization and relevant literature retrieval, Method Design, where specialized agents collaboratively develop optimized modeling strategies, and Experiment Execution for automated generation of code. The agents in the Design module are separated into experts with differing perspectives and central moderator, and have to collaboratively exchange solutions until they achieve reasonable consensus. We demonstrate CELLFORGEs capabilities in single-cell perturbation prediction, using six diverse datasets that encompass gene knockouts, drug treatments, and cytokine stimulations across multiple modalities. CELLFORGE consistently outperforms task-specific state-of-the-art methods, achieving up to 40% reduction in prediction error and 20% improvement in correlation metrics. Overall, CELLFORGE demonstrates how iterative interaction between LLM agents with differing perspectives provides better solutions than directly addressing modeling challenge. Our code is publicly available at https://github.com/gersteinlab/CellForge."
        },
        {
            "title": "Introduction",
            "content": "Scientific discovery is undergoing transformation with the rise of AI scientists [1]: autonomous systems designed to conduct research with minimal human intervention. Recent progress in large language models (LLMs) and AI agents has enabled impressive capabilities in literature analysis [2], hypothesis generation [3, 4], and experimental implementation [5, 6], as demonstrated by emerging benchmarks and agentic toolkits [710]. Yet these systems remain siloed: competent at individual tasks, but incapable of orchestrating complete scientific workflows. Although AI systems already Equal contribution. Preprint. Under review. exhibit strong abilities in specialized fields such as mathematics [11], todays AI scientists still lack an integrated framework that can formulate novel methods, iteratively refine them, and empirically validate the results within single workflow [1, 12]. This gap becomes especially critical in domains that demand interdisciplinary reasoning, such as computational biology, where effective modeling requires integrating biological priors, statistical rigor, and machine learning design [13, 14]. particularly compelling instantiation of this challenge is virtual cell modeling [15]. Since the late 1990s, biologists have envisioned virtual cells, computational models that can predict how cell will respond to genetic edits, chemical treatments, environmental shifts, and developmental cues across multiple biological modalities [16]. Recent multimodal foundation models take step toward this vision by fusing genomics, transcriptomics, epigenomics, proteomics, metabolomics, and spatial-omics data into unified representations of cellular state [17]. However, truly effective virtual-cell model must go further: it should forecast perturbation responses across diverse cell types and conditions, spanning every relevant modality (Figure 1). Despite large-scale pre-training over heterogeneous datasets [18, 19], current foundation models still struggle to capture datasetspecific perturbation patterns and experimental nuances, limiting their accuracy in new contexts. This problem exemplifies the limitations of current AI scientists: Existing approaches remain heavily fragmented, relying on extensive manual effort from computational experts to bridge gaps in dataset interpretation, model design, and empirical validation [20, 21]. Moreover, these models often fail to generalize to unseen cell types or experimental modalities [22, 23], and the heterogeneity of omics data and perturbation mechanisms further magnifies the problem, each domain demanding specialized reasoning to extract meaningful insight [24, 25]. We present CELLFORGE, fully autonomous multi-agent framework that addresses these fundamental challenges by automating the entire pipeline from biological data to optimized computational solutions. Unlike prior workflows that demand hand-crafted architectures and manual coding, CELLFORGE analyses each dataset, proposes (or invents) an appropriate model, then writes, tests, and refines production-ready code for training and inference. The central innovation is therefore not the selection of predefined pipeline, but the automated, emergent design of novel deep-learning architectures tailored to the task: the system does not pick from fixed menu of models; it conceives new architecture through collaborative reasoning among its agents. Domain-specialised agents contribute expertise in data preprocessing, model design, biological interpretation, and computational optimisation, and their collaboration is orchestrated to overcome challenges such as sparsity, high dimensionality, and cross-modal heterogeneity. Specifically, CELLFORGE confronts the interdisciplinary complexity of virtual-cell modelling by casting the entire research cycle as collaboration between role-specialised agents. TaskAnalysis agents begin by profiling the dataset and mining the literature, distilling draft research plan. Design agents then engage in graph-structured debate, iteratively proposing, critiquing, and fusing candidate architectures until the cohort converges on an optimised model and experimental protocol. Finally, Experiment-Execution agents translate this plan into runnable code, auto-debugging and retraining until validation targets are met. To demonstrate CellForges capabilities, we focus on single-cell perturbation prediction, fundamental and challenging task in virtual cell modeling that exemplifies the complexity of cellular response prediction. We use six datasets encompassing different perturbation types (gene knockouts, drug treatments, cytokine stimulations) and experimental modalities (scRNA-seq, scATAC-seq, CITE-seq). In all cases, models designed by CELLFORGE significantly outperform prior baselines. For instance, in the drug perturbation task, CELLFORGE improves Pearson correlation by 20% over the next best method, ChemCPA [26]. On the challenging, sparse, and high-dimensional scATAC-seq dataset, it achieves 16-fold gain in Pearson correlation on differentially expressed genes compared to the second-best baseline, linear regression model. Moreover, the multi-agent pipeline in CELLFORGE surpasses an expertly crafted single-prompt baseline, scoring 7.27/10 versus 2.27/10 in human-rated plan quality and being the only approach to yield executable code, underscoring that its performance gains arise from agent collaboration rather than prompt engineering alone. Importantly, CELLFORGE is general-purpose framework: we benchmark on the well-studied scPerturb suite for comparability with state-of-the-art methods, but the system can be run on any user-provided single-cell dataset accompanied by natural-language task description. Beyond perturbation analysis, CellForges architecture-agnostic design enables application to diverse virtual cell modeling challenges, from predicting cellular responses to environmental changes to modeling developmental trajectories, positioning it as foundational tool for next-generation virtual cell research. 2 Figure 1: (a) Virtual cell modeling is perturbation problem. Learn mapping from control cell state plus perturbation condition to the resulting perturbed state. Each cell exists in high-dimensional gene expression space. Model predicts new gene expression profile after perturbation. (b) Modeling approach for predicting unseen perturbations. Model trains on observed control-perturbed cell pairs under known conditions (gene editing, drug, cytokine treatments). Input uses different single-cell modalities: scRNA-seq, scATAC-seq, and CITE-seq. After training, the model predicts gene expression for new perturbations using only the control state and the perturbation label. (c) Input and output of CELLFORGE system. System receives task description and perturbation dataset: source cell profiles ( ctrl ), perturbation labels ( pi Ptrain ), and paired targets ( ipert ). Agents collaborate to design models predicting gene expression under unseen perturbations ( pi Ptest ) and generate executable code. (d) Core intermediate outputs of CELLFORGE System analyzes data and reviews literature for analysis report, conducts multi-expert discussion, finalizes research plan, then generates and executes training/evaluation code."
        },
        {
            "title": "2 Related Work",
            "content": "Agent Systems for Scientific Discovery Researchers have developed specialized AI systems spanning the entire research workflow: from literature analysis tools like PaperQA2 [7] and CHIME [2], to hypothesis generation frameworks that range from domain-specific idea creation [3, 4, 27] to comparative evaluations with expert proposals [28]. These systems increasingly leverage multi-agent architectures [2931] to facilitate collaborative scientific reasoning. Implementation capabilities have advanced through scientific coding frameworks like SciCode [5] and MLAgentBench [10], while benchmarks evaluate these capabilities across diverse domains [3235]. The integration of literature analysis with data-driven approaches has proven particularly effective for hypothesis generation [9, 36, 37], with several frameworks enhancing research ideation through structured feedback mechanisms [38, 39] and approaches to improve novelty and diversity [4042]. End-to-end systems now attempt to unify these capabilities, including domain-general approaches like AI Scientist [1] and MLR-Copilot [12], alongside domain-specific implementations for chemistry [13], genomics [14], materials science [43], and medicine [44, 45]. Despite these advances, significant challenges remain in developing truly autonomous scientific systems, particularly regarding experimental rigor [46], falsification mechanisms [47], and comprehensive evaluation metrics [48, 49], as highlighted in recent surveys [5053]. AI Agents in Biomedical Research AI agents in biomedical research are rapidly evolving to simulate and accelerate the entire biomedical research workflow, from hypothesis generation to experimental protocol design to general scientific discovery. For instance, BioReason [54] interprets the functional impacts of genetic mutations, while POPPER [55] introduces framework for validating free-form hypotheses through sequential falsification tests. These agents excel at reasoning but do not generate executable analysis pipelines as their primary output. Another category targets wet-lab 3 Figure 2: The example outputs of the three modules of CELLFORGE. The Task Analysis Module (left) outlines the analysis report, the Design Module (center) details the research plan, and the Experiment Execution Module (right) provides code snippets for data preprocessing, model components, and training execution. experimental design. PerturboAgent [56], for example, is self-planning agent designed to optimize the selection of genes for sequential Perturb-seq experiments, thereby guiding the next phase of lab work rather than creating computational analysis model. third category, including Biomni [57] and SpatialAgent [58], automates workflows by connecting existing software packages but is constrained by their static, predefined toolsets and limited code generation capabilities. STELLA [59] introduces autonomous tool discovery and reasoning template learning, boosting system performance through self-evolving architecture. Yet its scope is largely limited to lightweight tool orchestration and biomedical question-answering; it stops short of designing novel AI models or automating insilico experiments for biomedical research. This leaves an open opportunity for agentic frameworks explicitly aimed at AI model creation and end-to-end computational experimentation. Single-Cell Perturbation Analysis Single-cell perturbation studies measure how cells respond to genetic or chemical interventions. The existing literature of in-silico approaches that predict postperturbation cell states reflects fundamental divergence in machine learning, with each paradigm showcasing distinct philosophies for modeling cellular responses. Earlier efforts, such as linear regression [60] or random forest feature selection [61], treated each gene or cell type in isolation. Deep generative models [20, 26, 62], conceptualize perturbations as latent space transformations through linear shifts or decompositions that separate biological covariates. In contrast, network-based methods [6366] explicitly incorporate biological knowledge via gene regulatory networks or cellular relationships. To further address the issue of cell heterogeneity, distribution alignment approaches such as optimal transport [67, 68] have been applied to machine learning models [69], matching the distribution of control cells with perturbed cells. The emergence of transformer architectures represents the latest paradigm shift. These architectures [18, 19, 21, 22] leverage pre-training at scale and self-attention mechanisms to model complex gene dependencies without explicit biological structure. This theoretical diversity creates vast design space where selecting optimized architectures, representation strategies, and biological constraints remains highly context-dependent."
        },
        {
            "title": "3 Preliminary and Background",
            "content": "Notations. Let Rnd denote the matrix of single-cell profiles, where represents the total number of cells and represents the dimensionality of measured features per cell. Typically, these features are the 20,000 genes measured in standard single-cell RNA sequencing experiments, though without loss of generality, they could also represent chromatin accessibility peaks (in scATAC-seq), surface protein markers (in CITE-seq), or other molecular features depending on the experimental modality. Each row X[i, :] Rd corresponds to the molecular profile of cell i, with consistent feature ordering across all cells such that position always represents the same gene (or feature) across all cell profiles. When creating computational method for virtual cell modeling, dataset i=1 and task description are given, where xi Rd represents the preD = {(xi, pi, yi)}N 4 Figure 3: The CELLFORGE architecture and workflow. The framework operates through three sequential phases: Task Analysis (dataset characterization and literature retrieval), Hypothesis Generation (collaborative development of novel approaches by role-based, self-refinement agent systems), and Experiment Execution (code generation, training implementation, and results analysis). All phases communicate through shared memory module that evolves throughout the workflow. perturbation profile of cell (a d-dimensional vector of baseline molecular feature measurements), pi denotes the applied perturbation to cell with being the set of all possible perturbation types (e.g., gene knockouts, drug treatments, cytokine stimulations), yi Rd corresponds to the observed post-perturbation profile of cell (typically = when measuring the same features before and after perturbation), is the total number of cell instances in the dataset, and provides the textual task description specifying the prediction objective and evaluation criteria. Multiple cells can share the same perturbation (i.e., pi = pj for = j), providing biological replicates that capture cell-to-cell variability in perturbation responses. To verify the generalizability of our CELLFORGE, we divide into Dtrain = {(xi, pi, yi)}M j=1, where = + K, with and representing the number of cells in the training and test sets, respectively. The test set is specifically designed such that pi Ptest constitutes held-out perturbations not seen during training, and xi Xtest represents held-out cell profiles with baseline states not observed during training. This evaluation strategy tests two critical generalization scenarios: predicting effects of novel perturbation types and predicting responses in previously unseen cellular contexts. i=1 and Dtest = {(xj, pj, yj)}K Problem Formulation. We formalize the challenge of predicting cellular responses to perturbations as learning mapping function between pre-perturbation states and their corresponding post-perturbation outcomes. Specifically, for each perturbation (e.g., gene knockout, drug treatment, cytokine stimulus) applied to subset of cells, we model the induced change in the cellular profile as function fp : Rd Rd , where fp(x) predicts the post-perturbation profile of cell x, potentially in different modality. Importantly, BioForge learns perturbationresponse mappings de novo for each dataset, without importing pretrained representations from unrelated studies. This dataset-specific training strategy captures the unique perturbation signatures and experimental nuances of each cohort, avoiding the misalignment issues that can arise when generic embeddings are reused. The training objective involves learning function fθ : Rd Rd that generalizes effectively to unseen perturbations and cell states, where θ is trainable parameter(i.e., weights and biases). To capture intrinsic cell-state structure and enable efficient modeling, we incorporate learnable encoders gϕ : Rd Rh, where ϕ is trainable parameter and zi = gϕ(xi) Rnh represents the latent embedding that preserves geometric relationships between control and perturbed states, thus facilitating accurate prediction of post-perturbation profiles. Evaluation. For evaluation, we assess fθ(xi, pi) for all (xi, pi) Xtest Ptest and evaluate the quality of the learned representation gϕ(x) in terms of its ability to reconstruct gene expression profiles. 5 Figure 4: The CELLFORGE protocol overview. The protocol framework integrates JSON-RPC with persistent memory module, combining the strengths of A2A and MCP protocols while adding scientific domain knowledge representation. Our evaluation protocols incorporate metrics such as mean squared error, Pearsons correlation coefficient, and perturbation consistency adapted from [25, 64] to ensure biological significance. Appendix provides detailed explanation of these metrics."
        },
        {
            "title": "4 Method",
            "content": "CELLFORGE orchestrates an end-to-end scientific workflow into coherent framework (Figure 3): it autonomously (1) analyzes dataset characteristics and identifies optimized modeling strategies, (2) designs neural architectures incorporating biological knowledge about gene regulatory networks, and (3) generates executable code implementing the complete prediction pipeline, and evaluates prediction accuracy using various metrics. Unlike foundation models that rely on large-scale pretraining across heterogeneous data, CELLFORGE takes dataset-specific route: it profiles each studys perturbations, cell-type mix, modalities, and data quality, then auto-designs an architecture tailored to that particular prediction task. Instead of brute-force or convex-hull searches that exhaustively sweep the architecture space, our system uses knowledge-guided pipeline: Task Analysis module diagnoses the problem, and Design module selects an architecture tailored to it. Central to CELLFORGE is hybrid communication protocol combining JSON-RPC data exchange with persistent memory module, which is further described in Appendix A.3. This shared representation continuously integrates outputs from individual agents, enabling complex reasoning chains while maintaining traceability throughout the scientific process. Detailed information on the agent communication protocol is provided in Appendix E. The exact configurations, prompts, and outputs of each agent are listed in Appendix A.2 and P."
        },
        {
            "title": "4.1 Task Analysis Module",
            "content": "The Task Analysis phase, effectively our preparatory work stage, begins with comprehensive characterization of the scientific problem through three components: (i) dataset profiling and preprocessing, (ii) literature-driven retrieval of prior design principles, and (iii) extraction of task-specific constraints such as perturbation types and target evaluation metrics. Data Parser. This component extracts key metadata from single-cell datasets, including perturbation types, gene features, and cell populations. It standardizes information across diverse modalities (RNA-seq, ATAC-seq, CITE-seq) and generates summary statistics to establish the data foundation. The parser identifies critical experimental parameters such as perturbation methods, organism details, and cellular contexts without human intervention (detailed examples in Appendix Q.1). Agentic Retrieval. Our retrieval system combines static corpus of 45 specialized articles with dynamic search capabilities through PubMed and GitHub APIs. The full list of these source articles appears in Appendix O. During retrieval, the system mines design principles and dentifies promising architectures from this literature and applies biologically informed heuristics to surface promising architectures. Starting with an initial query Q(0) derived from the task description, the system employs SentenceBERT [70] embeddings and performs multi-layer retrieval alternating between breadth-first and depth-first search strategies. The detailed algorithm and mathematical formulation are presented in the Appendix D.1. BFS layer (t odd): Retrieves top-K documents Nt = TopK(Q(t), mode = BFS). DFS layer (t even): Follows highest-scoring paths from Nt1 in depth. 6 Figure 5: The Graph-based discussion architecture and workflow. This is an example of two rounds of discussion from the beginning. After each round, confidence scores are updated, and the agentic system will judge if the current state satisfies the stopping criteria. If not, each expert will refine their ideas based on the critic agents suggestions and other experts viewpoints. This graphbased critic refinement continues until reaching the termination state. The figure includes an example formula for computing each experts confidence score per round, based on weighted combination of historical scores, peer evaluations, and critic agents assessments. Complete multi-rounds of discussions are presented in Appendix D.2. Document relevance score is computed via cosine similarity: Score(Q, d) = e(Q)e(d) e(Q)e(d) . The retrieval terminates upon reaching any of three conditions: (1) maximum layers Lmax = 10, (2) query overlap exceeding threshold τ = 0.8, or (3) document relevance scores below ϵ = 0.5. Results are stored in vector database for subsequent access. Agent Collaboration. Three specialized agents, Dataset Analyst, Problem Investigator, and Baseline Assessor, process the retrieved information. The Dataset Analyst examines data integrity and characteristics, the Problem Investigator defines research questions and analytical approaches, and the Baseline Assessor establishes reference models and benchmarks. Their outputs are synthesized by Refinement Agent that structures the analysis into JSON file. Analysis Report At the core of our frameworks performance gains is its ability to autonomously discover optimized model architectures for each specific perturbation task. Similar to how human experts approach new domains, the agents systematically analyze scientific literature to identify candidate architectures appropriate for the given data characteristics. The Baseline Assessor specifically evaluates different model architectures (e.g., Transformers, GANs, VAEs, MLPs, etc.) based on their strengths and limitations for the particular perturbation type and data modality. For each architecture component, the agent generates comprehensive analysis report detailing advantages, disadvantages, and suitability for specific aspects of the task (e.g., handling sparsity in scATAC-seq data). This literature-grounded comparative analysis forms the foundation for the Design module, where expert agents collaboratively refine these insights into optimized custom architectures."
        },
        {
            "title": "4.2 Design Module",
            "content": "Overview. This module produces research plan through collaborative agent discussion, concurrently producing three integrated components: (1) data preprocessing strategies, (2) model architecture design, and (3) concrete model implementation details. Architecture design involves textual descriptions of the neural network components selected for the specific perturbation task and their theoretical justifications, while model design translates these concepts into executable pseudocode. Unlike approaches that merely tune hyperparameters of fixed architectures, CELLFORGE fundamentally focuses on discovering optimized architectural combinations tailored to each datasets unique biological characteristics. This architectural discovery process, rather than hyperparameter optimization, is the primary source of our frameworks performance advantages in perturbation prediction tasks. Multi-Expert Critic System. We construct panel of domain experts through role-play prompting: each expert is instantiated from similar dedicated prompt templates that encode its specialty while 7 Figure 6: Confidence Score Update in Graph-based Expert Discussion. This figure illustrates an example of how domain experts confidence score evolves during iterative rounds of discussion in the Graph-based Expert Discussion framework. While this example focuses on the Model Architecture Expert, the same confidence updating process applies to all participating experts in the graph, each iteratively refining their proposals and adjusting their confidence based on multi-agent evaluations. using the same underlying LLM. See Appendix P.3 for the full templates. For each task, the system dynamically selects subset of domain experts E(k) (e.g., Data Expert, Single-Cell Expert, Deep Learning Expert) based on task requirements, along with permanent critic agent S. These agents form an undirected collaboration graph G(k) = (S, E(k)), where each expert node maintains confidence score c(i) that evolves through discussion rounds, where is the discussion round and represents different domain experts. Graph-based Discussion. The framework runs up to Tmax = 10 rounds of graph-based message passing, where experts propose architectural solutions. In each round every expert E(i) proposes an . After all proposals are submitted, critic agent reviews every m(i) architectural candidate m(i) , summarizes strengths and weaknesses, and assigns score. At the end of round the value is updated by both the critic agent and peer experts. Specifit = λ1 c(i) cally, the confidence score c(i) for expert at round is computed as: c(i) t1 + λ2 (cid:80) CriticAgentScore(m(i) , E(j)), where c(i) j=i PeerScore(m(i) t1 represents the hist torical confidence, CriticAgentScore(m(i) , S) evaluates the scientific rigor and feasibility of proposal m(i) by the critic agent S, PeerScore(m(i) , E(j)) captures the evaluation from peer expert j, is the total number of participating experts, and (λ1, λ2, λ3) = (0.3, 0.4, 0.3) are empirically determined weights with λ1 + λ2 + λ3 = 1. , S) + λ3 1 k1 The discussion ends when all experts confidence scores exceed the threshold τ = 0.8 with minimal variance (maxi,j c(i) < ϵ, ϵ = 0.03), where represents the final round when the discussion ends, and represent domain experts. c(j) If this condition is not met, otherwise it stops at the round limit Tmax to balance computational cost, inference time, and token consumption. Before reaching the ending criteria, experts refine their proposals using historical context and proceed to the next round. This process ensures convergence toward scientifically valid and technically feasible model designs with explicit reasoning chains throughout several rounds of discussion. Further information on expert selection and discussion construction is in Appendix A.4, detailed algorithm and mathematical formulation are presented in Appendix D.2, and hyperparameter configuration is presented in Appendix D.4. complete pseudocode listing follows."
        },
        {
            "title": "4.3 Experiment Execution Module",
            "content": "The Experiment Execution module turns high-level research plans into fully tested, empirically validated results: (1) Code Generation & Self-Debugging. The Code Generator converts the selected architecture into production-ready scripts and notebooks with complete dependency management. If syntax or runtime error occurs, the agent receives the traceback via the OpenHands event stream, analyses the failure, patches the code, and re-executes itrepeating until unit tests pass or rollback to the last stable state is triggered (see Appendix for breakdown of resolved error types). (2) Training Orchestration. An automated scheduler launches training with best-practice safeguards: early stopping, cross-validation, adaptive learning-rate schedules, and checkpointing. When the 8 Algorithm 1 Graph-based Expert Discussion 1: procedure EXPERTDISCUSSION(TaskAnalysis, τ, ϵ, Tmax) 2: 3: 4: 5: 6: E(k) SelectExperts(TaskAnalysis) InitializeSelfCritic() G(k) (S, E(k)) for = 1 to do c(i) 0 0 m(i) 0 InitialProposal(E(i), TaskAnalysis) end for 0 while < Tmax do 7: 8: 9: 10: 11: 12: for = 1 to do }k mt Integrate({m(j) j=1) UpdateConfidence(c(i) c(i) end for if : c(i) break τ c(i) c(i) t1, mt, S) t1 < ϵ then end if for = 1 to do t+1 RefineIdea(E(i), mt) 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: end procedure m(i) end for + end while ResearchPlan FinalizeProposal(mt) return ResearchPlan Initialize collaboration graph Initialize confidence scores Convergence achieved Validation Agent detects underor over-fitting, it initiates lightweight hyper-parameter tuning (e.g. adjusting regularisation strength or training epochs) to restore convergence. (3) Validation, Refinement & Output Assurance. After each training cycle, the Validation Agent scores checkpoints on MSE, PCC, and R2, identifies failure modes, and feeds structured critiques back to the generator. Because the task outputs numerical gene-expression matriceswhich are always wellformedthe focus is on accuracy rather than structural validity. The agent iterates until performance stabilises or ten-round refinement cap is reached, balancing robustness against compute and token budget."
        },
        {
            "title": "5.1 Evaluation setup",
            "content": "We evaluate the models designed and implemented by CELLFORGE in various types of perturbation from scPerturb [24], including gene knockouts, drug treatments, and cytokine stimulation across multiple modalities (scRNA-seq, scATAC-seq, CITE-seq). Each dataset represents distinct biological challenges: The Adamson [71] and Norman [75] datasets capture CRISPR gene knockouts in different cell lines, providing fundamental test cases for genetic perturbation. The Papalexi [79] dataset offers both RNA and protein measurements (CITE-seq), enabling assessment of cross-modality prediction. The Liscovitch [80] dataset presents the distinct challenge of predicting chromatin accessibility changes (scATAC-seq) rather than gene expression. The Srivatsan [76] dataset assesses the prediction of cellular responses to chemical compounds, while the Schiebinger [78] dataset examines responses to immune signaling molecules (cytokines). To assess generalization to unseen perturbations, we select baselines accordingly: CPA[72], scGen[62], CondOT[73], Biolord[74] and scGPT [18] for gene knockouts, ChemCPA [26] and CellFlow[77] for drug treatments. For modalities lacking established models (scCITE-seq, scATACseq, cytokine), we employ Random Forest and Linear Regression using one-hot encoded perturbations concatenated with expression profiles as inputs. 9 Table 1: Post-perturbation gene expression prediction results, where CellForge-Model is the prediction model automatically designed and implemented by CELLFORGE. The reported metrics for CellForge-Models represent the best performance from three separate models automatically designed and trained by the framework, with standard deviations reflecting the variability across these runs. MODEL SE CC R2 SEDE CCDE DE Gene Knock Out Perturbation scRNAseq Dataset (Adamson et al. [71]) Unperturbed Random Forest Linear Regression CPA [72] scGen [62] CondOT [73] Biolord [74] scGPT [18] CellForge-Models 0.9840 0.3053 0.5803 0.0067 0.0082 0.0062 0.0044 0.0100 0.0051 0.0063 0.0001 0.2063 0.0026 0.9833 0.9805 0.9608 0.7799 0.9861 0.9883 0.0459 -0.0127 0.0504 0.0435 0.9845 0.9611 0.9740 0.9844 0.9649 0.9761 0. 3.7865 0.5923 0.6995 0.1447 0.1301 0.1997 0.1256 0.2562 0.2013 0.0444 0.0012 0.2632 0.0257 0.9024 0.8994 0.9341 0.9097 0.9088 0.9474 0.0601 -4.2437 0.1653 0.1074 0.8896 0.7263 0.9002 0.9276 0.7911 0.8912 0.0518 Gene Knock Out Perturbation scRNAseq Dataset (Norman et al. [75]) Unperturbed Random Forest Linear Regression CPA [72] scGen [62] CondOT [73] Biolord[74] scGPT [18] CellForge-Models 0.9251 0.4059 0.4989 0.0051 0.0053 0.0420 0.0027 0.0076 0.0034 0. 0.0000 0.1625 0.0244 0.9779 0.9221 0.9847 0.4374 0.9823 0.9846 0.0418 -0.1738 0.0623 0.0314 0.9603 0.9521 0.9619 0.9830 0.9536 0.9609 0.0081 5.1214 0.6817 0.7331 0.3400 0.3877 0.2791 0.2450 0.5318 0.1736 0.0677 -0.0021 0.1428 0.0265 0.5754 0.5605 0.8022 0.4646 0.8630 0.8109 0.0133 -4.2047 0.0498 0.0238 0.4555 0.3220 0.7470 0.8112 0.5652 0.5975 0.0539 Drug Perturbation scRNA-seq Dataset (Srivatsan et al. [76]) Unperturbed Random Forest Linear Regression ChemCPA [26] scGen [62] CondOT [73] Biolord [74] CellFlow[77] CellForge-Models 0.8919 0.5289 0.6703 0.0847 0.0579 0.0499 0.0011 0.0003 0.0053 0.0290 0.0002 0.0527 0.0711 0.7221 0.7871 0.8674 0.9658 0.9906 0.8664 0.1332 -2.4282 0.0986 0.2826 0.6930 0.7334 0.6531 0.9287 0.9813 0.8317 0.0740 9.3326 0.6138 0.5625 0.1035 0.1263 0.0933 0.0162 0.0045 0.0080 0.0835 0.0077 0.0245 0.0763 0.8053 0.6575 0.8341 0.9283 0.7918 0.9278 0. -6.8585 0.0817 0.0421 0.7412 0.5610 0.4378 0.8236 0.9794 0.7887 0.0548 Cytokine Perturbation scRNA-seq Dataset (Schiebinger et al. [78]) Unperturbed Random Forest Linear Regression CellForge-Models 0.0076 0.0762 0.4855 0.0428 0.0205 0.0007 0.2704 0.0785 0.5697 0.0943 0.0069 0.4186 0.0034 0.5043 0. 0.0980 0.0910 0.4359 0.0144 0.0349 0.0082 0.2124 0.0847 0.3396 0.0403 -0.6782 0.2185 0.0013 0.2832 0.1154 Gene Knock Out Perturbation scCITEseq (RNA) Dataset (Papalexi et al. [79]) Unperturbed Random Forest Linear Regression CellForge-Models 0.1509 0.0763 0.0764 0.0417 0. 0.0004 0.2124 0.0170 0.6935 0.1995 0.0017 0.4186 0.0254 0.3687 0.0651 0.6276 0.0911 0.0909 0.0535 0.1566 0.0007 0.2455 0.0218 0.6406 0.1940 -5.9142 0.2185 0.0163 0.2354 0.0224 Gene Knock Out Perturbation scCITEseq (Protein) Dataset (Papalexi et al. [79]) Unperturbed Random Forest Linear Regression CellForge-Models 0.4092 0.0982 0.4901 0.0070 0.0387 -0.0115 0.2704 0.3396 0.7495 0.0653 -0.9945 0.0829 0.1241 0.6872 0.0956 0.5974 0.3071 0.4551 0.2921 0.0045 -0.0081 0.4024 0.3087 0.7409 0. -0.3652 0.0466 0.3523 0.5489 0.0749 Gene Knock Out Perturbation scATACseq Dataset (Liscovitch et al. [80]) Unperturbed Random Forest Linear Regression CellForge-Models 0.0426 0.0432 0.5767 0.0327 0.0430 0.0001 0.0638 0.0486 0.0855 0.0357 -0.0001 0.0040 0.0229 0.0678 0. 9.4980 0.0510 0.7750 0.0406 0.0268 0.0004 0.0509 0.0457 0.6991 0.3173 -9.7567 0.0035 0.0021 0.0640 0.0279 We are aware that, for the ATACand CITE-seq benchmarks, our comparisons rely on simple learners (linear regression and random forest). This choice is deliberate and stems from three factors: (i) to date no perturbationresponse method has been published or benchmarked for these modalities [81, 82], making scRNA-centric models such as scGen [62] or scGPT [18] fundamentally incompatible with peakor protein-level data; (ii) the few multimodal generative tools, like totalVI [83], MultiVI [84], and GLUE [85], that can process ATAC or CITE-seq were designed for data integration rather than counterfactual perturbation prediction [86] and therefore cannot address unseen perturbations; (iii) recent meta-analyses show that, when properly tuned, classical models often match or exceed specialised deep networks on sparse single-cell tasks [81, 87, 88]. Consequently, linear regression and random forest constitute strong, modality-agnostic baselines in the absence of purposebuilt alternatives. Their limitations, however, underscore the need for an automatic, modality-aware framework: CELLFORGE generates custom architectures that handle the extreme sparsity of scATACseq and the multi-modal nature of CITE-seq, achieving state-of-the-art performance where no prior solution exists. 10 Table 2: Performance comparison on scPerturb datasets and benchmark tasks[25] (all values are in %). Results show CELLFORGE consistently outperforms both scGPT and Geneformer across multiple metrics and perturbation types. Each score represents the average of five independent runs, with higher values indicating better performance. MODEL TOP5 LIN TOP1 LIN PERT CONS TOP5 KNN TOP1 KNN SPEAR CORR STRUCT INT scGPT[18] Geneformer[19] CellForge-Model scGPT [18] Geneformer [19] CellForge-Model scGPT[18] Geneformer[19] CellForge-Model 5.2 4.4 7. 2.2 2.1 2.4 2.1 1.4 2.5 Drug Perturbation (Srivatsan Dataset [76]) 4.4 3.1 4.2 11.4 0.9 11.4 5.6 5.1 6. 5.1 4.8 5.3 Gene Knock Out Perturbation (Adamson Dataset [71]) 0.8 0.8 0.9 5.6 4.3 6.9 26.2 25.9 26.6 25.5 24.1 25. Cytokine Perturbation (Schiebinger Dataset [78]) 4.8 4.2 5.3 4.6 4.4 4.9 8.2 8.3 8.6 5.5 9.9 8.8 18.8 17.3 19. 87.3 86.6 89.9 66.9 68.2 68.5 54.2 54.1 54.5 96.1 95.9 96.0 57.1 57.6 59."
        },
        {
            "title": "5.2 Predictive Performance",
            "content": "Table 1 evaluates the prediction accuracy of models designed by CELLFORGE across diverse perturbation datasets. We employ multiple complementary metrics: Basic prediction accuracy is measured via mean squared error (MSE), where lower values indicate predictions closer to actual gene expression; Pearson correlation coefficient (PCC), which quantifies how well predicted expression patterns correlate with actual patterns; and coefficient of determination (R2 ), measuring the proportion of expression variance explained by the model. Biological relevance is assessed through metrics on differentially expressed genes (DE), those exhibiting significant expression changes after perturbation and thus most biologically meaningful. For each dataset, the top 20 DE genes are selected based on ground truth expression changes under perturbation. We then compute the same metrics restricted to these DE gene subsets, denoted as MSEDE, PCCDE, and R2 DE. Across these settings, models designed by CELLFORGE consistently outperform baselines. For gene knockouts (Adamson dataset), our models achieve 49% reduction in prediction error (MSE = 0.0051 vs. 0.0100 for scGPT) with improved variance explained (R2 = 0.9761 vs. 0.9649). This improvement extends to differentially expressed genes (MSEDE = 0.2013 vs. 0.2562), demonstrating enhanced biological fidelity. The performance advantages become more pronounced in challenging cross-modality scenarios. For CITE-seq protein measurements, CELLFORGE achieves 177% improvement in correlation (PCC = 0.7495 vs. 0.2704 for Random Forest). For drug perturbations, our models deliver nearperfect predictions (MSE = 0.0053) and 20% higher correlation (PCC = 0.8664 vs. 0.7221) compared to ChemCPA. Perhaps most remarkably, CELLFORGE maintains superior performance even on fundamentally different modalities such as chromatin accessibility (scATAC-seq), achieving remarkable improvement in variance explained (R2 = 0.0678 vs. 0.0040) and correlation for key regulatory regions (PCCDE = 0.6991 vs. 0.0509)."
        },
        {
            "title": "5.3 Differentially Expressed Gene Recovery Analysis",
            "content": "Beyond expression-level prediction accuracy, we evaluate CELLFORGEs ability to identify and correctly predict differentially expressed genes (DEGs): critical capability for understanding perturbation mechanisms and biological relevance. Following the structured benchmarking framework proposed by STAMP [89], we decompose genetic perturbation prediction into three complementary subtasks: (1) identification of DEGs, (2) classification of expression change direction, and (3) regression of expression magnitude. We assess DEG recovery performance using three key metrics: DEG Recall measures the proportion of ground-truth differentially expressed genes correctly identified as differentially expressed; ROC-AUC evaluates the discriminative ability to classify genes as differentially expressed versus non-differentially expressed; and PR-AUC (Precision-Recall AUC) assesses performance on the imbalanced classification task, as DEGs typically represent small fraction of all genes. Table 3 11 Figure 7: We manually prompt four different DeepResearch variants, Biomni and Single LLM (Claude 3.7) to generate research plans, which were then evaluated by five independent LLMs across eight dimensions, with scores ranging from 1 to 10. Detailed prompts, outputs, and scores are provided in Appendix H. Table 3: DEG Recovery Performance Across Benchmark Datasets DEG Recall ROC-AUC PR-AUC"
        },
        {
            "title": "Dataset",
            "content": "Gene Knock Out Perturbation scRNAseq Datasets Adamson et al. [71] Norman et al. [75] 0.695 0.08 0.779 0.13 0.652 0.06 0.704 0.05 0.285 0.08 0.375 0.07 Drug Perturbation scRNA-seq Dataset Srivatsan et al. [76] 0.689 0.20 0.646 0.06 0.182 0.02 Cytokine Perturbation scRNA-seq Dataset Schiebinger et al. [78] 0.535 0.14 0.524 0.08 0.105 0.02 Gene Knock Out Perturbation scCITEseq Dataset Papalexi et al. (RNA) [79] Papalexi et al. (Protein) [79] 0.509 0.12 0.420 0. 0.415 0.05 0.392 0.25 0.115 0.05 0.121 0.09 Gene Knock Out Perturbation scATACseq Dataset Liscovitch et al. [80] 0.484 0.12 0.097 0. 0.048 0.02 presents DEG recovery results across seven benchmark datasets spanning diverse perturbation types and cellular contexts. The results reveal several notable patterns. First, CELLFORGE achieves particularly strong performance on well-characterized genetic perturbation datasets (Adamson, Norman), with DEG recall rates exceeding 69% and ROC-AUC values above 0.65. This indicates robust identification of genes truly affected by CRISPR-based interventions. Second, performance varies meaningfully across different perturbation modalities and experimental contexts. The highest DEG recall (77.9%) is achieved on the Norman dataset, which features comprehensive genetic interaction profiling with rich phenotypic readouts. In contrast, more challenging scenarios like chromatin accessibility perturbations (Liscovitch) or cross-modal protein predictions show lower but still meaningful performance. Third, the precision-recall analysis (PR-AUC) demonstrates that CELLFORGE maintains reasonable precision even when operating on the highly imbalanced DEG identification task, where true positives represent small fraction of total genes. The Norman dataset achieves the highest PR-AUC (0.375), indicating effective prioritization of truly differentially expressed genes."
        },
        {
            "title": "5.4 LLM-as-a-Judge and Human Evaluation for Task Analysis Module and Design Module",
            "content": "To assess the scientific quality of research plans generated by CELLFORGE, we employ multiperspective evaluation framework that combines automated LLM assessment with independent human 12 expert review. All judges assess outputs in randomized, blinded manner without knowledge of which system generated each plan, ensuring unbiased comparison. Our evaluation protocol employs five independent LLM judges from different model families (Claude 3.7, o1, DeepSeek-R1, Qwen-plus, LLaMA3.1) to minimize model-specific biases. Each judge assesses research plans across eight explicit scientific dimensions detailed in Table 7 (Appendix I): scientific validity (correctness of biological assumptions and experimental logic), technical feasibility (practical implementability with current technologies), experimental design quality (rigor of controls, sample sizes, and statistical approaches), biological relevance (alignment with known cellular mechanisms and perturbation biology), innovation level (novelty of approaches and methodological contributions), impact potential (significance for advancing single-cell perturbation analysis), resource efficiency (computational and experimental cost considerations), and methodological rigor (adherence to established scientific standards). These criteria directly measure scientific merit rather than stylistic qualities, focusing on domain-specific validity, reasoning depth, and experimental soundness. The LLM-as-judge evaluation methodology follows established practices [90, 91]. To validate the reliability of our assessment, we complement LLM evaluation with independent human expert review. Three domain experts with extensive experience in single-cell biology and perturbation analysis conducted blinded evaluations using identical scientific criteria. Each expert independently spent approximately 10 hours scoring the same outputs under identical criteria, blinded to the source system. Figure 7 presents expert evaluations comparing CELLFORGE with DeepResearch variants. The evaluation shows that CELLFORGE demonstrates superior performance in dataset analysis and baseline defect identification. In method design, CELLFORGE consistently outperforms alternatives on scientific validity, innovation level, experimental design, and impact potential, while maintaining comparable technical feasibility. These advantages are particularly pronounced for cytokine perturbations, where immune signaling complexity demands sophisticated biological reasoning. Notably, both the LLM-assigned scores for task analysis and research plans and the confidence scores generated by our agent system show strong correlation with evaluations from three human domain experts (Pearson = 0.83, < 0.01 in Figure 8). The strong correlation validates that both assessment methods capture scientific quality. Our human experts, with years of research experience in single-cell perturbation biology, would not correlate highly with LLMs if the evaluation merely measured stylistic preferences. Instead, this correlation demonstrates that our evaluation framework successfully captures the scientific merit and biological validity of generated research plans. Figure 8: Human expert evaluations show strong correlation with agentgenerated confidence and LLM judge scores. Detailed scores are provided in Appendix and I. An Example of CellForge-designed model framework is placed in Figure 9. To better understand how CELLFORGE adapts to different perturbation scenarios, we conducted post-hoc analysis of the architectures it generated. For each of the six datasets, we manually categorized and quantified the neural network components present in CELLFORGE designs. Figure 10 reveals that the framework gravitates toward architecture-task pairings that an experienced scientist would consider biologically plausible: Transformers dominate cytokine data, where longrange signalling dependencies matter, whereas GNNs are favoured for datasets rich in regulatorynetwork information. Crucially, these choices were not hard-wired: no rule in the code links modality to model class. Instead, they emerged from literature retrieval followed by multi-agent debate, occasionally yielding hybrid or entirely novel variants (Appendix Q.6). This convergence, therefore, validates the agents ability to internalise domain knowledge autonomously. Because the pipeline is conditioned on data and literature rather than on fixed heuristics, it can be rerun on entirely new modalities without re-engineering. 13 Figure 9: An example diagram of the model framework designed by CELLFORGE on the scRNAseq gene knockout perturbation prediction task (Norman et al. [75]). The Design modules main contribution is to synthesize structured research plan that articulates novel singlecell perturbation prediction method with clear framework of model components and their interconnections, alongside hyperparameter guidelines and evaluation criteria. In the subsequent Experiment Execution module, CELLFORGE translates the research plan into fully executable Python code. Together, these outputs enable end-to-end reproducibility from conceptual design through empirical validation. Figure 10: manual post-hoc analysis where we categorized and quantified the architectures designed by CELLFORGE for six datasets."
        },
        {
            "title": "5.5 Embedding Quality on the scPerturb Benchmark",
            "content": "While CELLFORGE primarily performs gene expression prediction following perturbations, the quality of learned representations is equally important for biological interpretability. Following evaluation practices established in previous works [18, 19], we benchmark CELLFORGE against specialized foundation models (scGPT & Geneformer) on representation quality metrics  (Table 2)  . To ensure fair comparison, we follow the previous zero-shot benchmarking framework [25], which evaluates transcriptomic foundation models without task-specific fine-tuning. Specifically, perturbation embeddings for both scGPT and Geneformer are extracted directly from their pre-trained backbones with no fine-tuning performed on any evaluation dataset. This represents pure zero-shot performance, making the comparison particularly stringent for our method, as baseline models leverage extensive pre-training on large-scale datasets while CELLFORGE operates without any pretraining advantages. All models are evaluated under identical zero-shot conditions using standardized downstream metrics including logistic regression for separability assessment and cosine clustering for consistency measurement. We assess different aspects of latent space organization across five dimensions: (1) Linear separability metrics (TOP5 LIN, TOP1 LIN) measure how distinguishable different perturbation types are in the latent space. The top5 lin score of 0.070 achieved by CELLFORGE for drug perturbations (vs. 0.052 for scGPT) indicates that 7.0% of test samples have their correct perturbation label among the top 5 predictions when using linear classifier trained on the latent embeddings. This improvement suggests CELLFORGE learns representations where perturbation effects are more linearly separable, facilitating downstream analyses that rely on perturbation classification. (2) Perturbation 14 consistency (PERT CONS) quantifies whether cells with the same perturbation cluster more tightly than random controls, essentially measuring the signal-to-noise ratio of perturbation effects in the latent space. For gene knockouts, CELLFORGE achieves consistency of 0.069. This indicates that CELLFORGE creates latent space where cells experiencing the same perturbation are more reliably grouped together, reflecting better capture of perturbation-specific biological responses. (3) Local structure in the latent space is assessed through nearest-neighbor metrics (TOP5 KNN, TOP1 KNN), which evaluate whether perturbations form locally coherent clusters. For drug perturbations, CELLFORGE achieves TOP5 KNN score of 0.064 vs. 0.056 for scGPT, indicating that higher proportion of test samples have correctly labeled neighbors in embedding space. (4) The Spearman correlation metric (SPEAR CORR) evaluates how accurately the latent embeddings can be mapped back to the original gene expression space using linear transformation. The score of 0.191 for drug perturbations (vs. 0.188 for scGPT) represents higher rank correlation between predicted and actual expression values after linear decoding. (5) Structural integrity (STRUCT INT) measures how well control-perturbation relationships are preserved in the latent space. 0.596 for cytokine perturbations (vs. 0.571 for scGPT) indicates that CELLFORGE better maintains the biological relationship between control and perturbed states for complex signaling cascades. We include additional UMAP visualizations in the Appendix L."
        },
        {
            "title": "6 Analysis",
            "content": "6."
        },
        {
            "title": "Information Integration",
            "content": "Evaluation on RAGBench [49] with the PubMedQA dataset [92] demonstrates CellForges ability to accurately identify and contextualize relevant scientific literature. In this evaluation, hallucination detection (measured by AUROC) evaluates the systems ability to avoid generating false information; context relevance (measured by RMSE) assesses how well the retrieved documents match the query; and context utilization (measured by RMSE) quantifies how effectively the system incorporates the information retrieved into responses. In Figure 11, context utilisation delivers the largest gain for gene-perturbation tasks. Importantly, CELLFORGEs performance remains stable across every perturbation type, implying that it tackles domain-agnostic bottleneckssparse, noisy measurements; high-dimensional, multi-modal inputs; and the combinatorial explosion of possible perturbationsrather than relying on quirks of any single dataset. This robustness stems from two design choices: (i) graph-based expert discussion that fuses specialised reasoning paths into consensus architecture, and (ii) retrieval-augmented task-analysis module that grounds model design in literature-derived priors while still adapting to dataset-specific statistics."
        },
        {
            "title": "6.2 Component Contributions",
            "content": "In the ablation study, we designated CELLFORGE (baseline) as the version of CELLFORGE after removing the Agentic Retrieval and Graph-Based Discussion components. Beyond testing the impact of adding or removing modules from CELLFORGE, we also made comparison between Agentic RAG and Normal RAG. In the Normal RAG setup, the retrieval scope was kept the same as that of Agentic Retrieval, but it only conducted single round of keyword-based retrieval directly from the input. The input datasets, task descriptions, and the LLM interface (Claude 3.7) were held constant for each perturbation type throughout these ablation studies; only the internal modules were varied. Figure 11: The performance of CellForges RAG compared to standard RAG methods. (1) hal: hallucination detection, (2) rel: context relevance, (3) utl: context utilization. Results are stratified by perturbation type (Drug, Cytokine, Gene). Detailed evaluation methods are stated in Appendix C. Table 4 reveals the critical contributions of our key framework components. The agentic retrieval system improves performance substantially over the baseline (PCC from 0.0087 to 0.5643 on the 15 Table 4: Ablation study on the impact of key framework components on designed models performance. Comparison of CELLFORGE configurations in gene knockout, drug, and cytokine perturbation tasks. MODEL SE CC R2 SEDE CCDE R2 DE Gene Knock Out Perturbation (Adamson Dataset [71]) CELLFORGE (Basic Version without RAG, etc.) + Normal RAG + Agentic Retrieval + Graph-Based Discussion + Normal RAG & Graph-Based Discussion + Agentic Retrieval & Graph-Based Discussion 0.4776 0.2442 0.1267 0.2751 0.0909 0.0051 0.0087 0.1008 0.5643 0.5310 0.8951 0.9883 0.0410 0.1119 0.5431 0.5874 0.8658 0.9761 Drug Perturbation (Srivatsan Dataset [76]) CELLFORGE (Basic Version without RAG, etc.) + Normal RAG + Agentic Retrieval + Graph-Based Discussion + Normal RAG & Graph-Based Discussion + Agentic Retrieval & Graph-Based Discussion 0.5760 0.2572 0.1309 0.1670 0.0995 0. 0.0298 0.1584 0.3437 0.4193 0.6512 0.9881 0.0475 0.1038 0.4350 0.3764 0.5933 0.9665 Cytokine Perturbation (Schiebinger Dataset [78]) CELLFORGE (Basic Version without RAG, etc.) + Normal RAG + Agentic Retrieval + Graph-Based Discussion + Normal RAG & Graph-Based Discussion + Agentic Retrieval & Graph-Based Discussion 0.5892 0.4321 0.3456 0.3512 0.0987 0.0428 0.0065 0.1765 0.2034 0.2051 0.4875 0. 0.0021 0.0243 0.2421 0.2765 0.4654 0.5042 0.6061 0.3997 0.1152 0.2792 0.3416 0.2013 0.6409 0.3022 0.1210 0.1325 0.985 0.0080 0.5876 0.4756 0.3076 0.2454 0.1065 0.0144 0.0940 0.3354 0.5922 0.6540 0.8547 0. 0.0992 0.3472 0.3836 0.4266 0.6784 0.9953 0.0797 0.1987 0.2068 0.2239 0.2534 0.3396 0.1280 0.3667 0.6067 0.5311 0.6770 0.8912 0.1039 0.2901 0.4169 0.3865 0.7548 0.9802 0.0999 0.0934 0.1176 0.1123 0.1053 0.1240 Adamson dataset), demonstrating the importance of domain knowledge integration. Similarly, the graph-based discussion component with critic refinement provides complementary benefits (PCC from 0.0087 to 0.5310). The combination of both components yields synergistic effects far exceeding their individual contributions (PCC reaching 0.9883), highlighting how knowledgeguided collaborative reasoning enables effective scientific discovery. This pattern remains consistent across all perturbation types, suggesting that CELLFORGE addresses fundamental challenges rather than exploiting dataset-specific characteristics."
        },
        {
            "title": "6.3 Cost and Failure cases analysis",
            "content": "To support reproducibility and practical deployment, we provide both computational costs and common failure cases of CELLFORGE. CELLFORGE presents cost-effective solution for computational biology research. Its training infrastructure, equipped with two NVIDIA H20 GPUs, 16-core CPU, 150 GB of RAM, and 2 TB of NVMe SSD, enables the efficient training of models (10-30 million parameters) within 3-8 hours, depending on the data type. This setup avoids memory bottlenecks and supports parallel training and distributed evaluation. Token usage analysis across over 50 experiments reveals an average prompt (input)/completion (output) ratio of 60K/300K, with costs varying by LLM model  (Table 11)  . Total experimental costs vary depending on scenario complexity, averaging $5.18 per request. We identified seven distinct categories of failure modes, with Computation Execution Error accounting for 41% of total failures, primarily due to tensor operation issues like out-of-bounds indexing or shape mismatches. Invalid Type or Operation was the second most frequent failure at 23%, mainly from unsupported data types or operations. Other failure types included Model Configuration Error (6%), Data Access Failure (5%), Error Recovery Failure (16%), Hallucination (4%), and Other (5%). Detailed information are listed in and G."
        },
        {
            "title": "7 Conclusion",
            "content": "CELLFORGE is an agentic system that autonomously designs and implements complete model architectures for single-cell perturbation prediction without human intervention. CELLFORGE demonstrates how autonomous multi-agent systems can effectively enhance single-cell perturbation 16 analysis by integrating expertise across computational, biological, and statistical domains. Our framework achieves consistent performance improvements across diverse datasets, perturbation types, and modalities. The synergistic combination of knowledge integration (via agentic retrieval) and collaborative reasoning (via graph-based discussion) enables the discovery of optimized modeling strategies without human intervention, with emergent architecture adaptation to dataset-specific challenges."
        },
        {
            "title": "References",
            "content": "[1] Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The AI scientist: Towards fully automated open-ended scientific discovery, 09 2024. [2] Chao-Chun Hsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, Chenhao Tan, David Wadden, Lucy Lu Wang, and Aakanksha Naik. CHIME: LLM-assisted hierarchical organization of scientific studies for literature review support. Findings of ACL 2024, 2024. [3] Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Zhang-Ren Chen, Jin-Fang Hu, and Bowen Zhou. Large language models are zero shot hypothesis proposers. Instruction Workshop @ NeurIPS 2023, 2023. [4] Tong Yang, Xiaodan Hu, Xiaohan Li, Mingda Tan, Jingfeng Zhang, Zhilin Wen, Ernie Chang, Andrew M. Dai, Quoc V. Li, Joseph E. Gonzalez, Claire Cardie, and Jason Wei. AnyBench: Language models evaluate anything. arXiv preprint arXiv:2312.13771, 2023. [5] Minyang Tian, Luyu Gao, Shizhuo Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat Krongchon, Yao Li, et al. SciCode: research coding benchmark curated by scientists. Advances in Neural Information Processing Systems, 37:3062430650, 2024. [6] Yiming Huang, Jianwen Luo, Yan Yu, Yitong Zhang, Fangyu Lei, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, and Kang Liu. DA-Code: Agent data science code generation benchmark for large language models. EMNLP 2024, 2024. [7] Michael D. Skarlinski, Sam Cox, Jon M. Laurent, James D. Braza, Michaela Hinks, Michael J. Hammerling, Manvitha Ponnapati, Samuel G. Rodriques, and Andrew D. White. Language agents achieve superhuman synthesis of scientific knowledge. arXiv preprint arXiv:2409.13740, 2024. [8] Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong Lu, et al. ScienceAgentBench: Toward rigorous assessment of language agents for data-driven scientific discovery. arXiv preprint arXiv:2410.05080, 2024. [9] Bodhisattwa Prasad Majumder, Harshit Surana, Dhruv Agarwal, Bhavana Dalvi Mishra, Abhijeetsingh Meena, Aryan Prakhar, Tirth Vora, Tushar Khot, Ashish Sabharwal, and Peter Clark. DiscoveryBench: Towards data-driven discovery with large language models. arXiv preprint arXiv:2407.01725, 2024. [10] Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec. MLAgentBench: Evaluating language agents on machine learning experimentation. In ICML 2024, 2024. [11] Trieu Trinh, Yuhuai Wu, Quoc Le, He He, and Thang Luong. Solving olympiad geometry without human demonstrations. Nature, 625(7995):476482, 2024. [12] Ruochen Li, Teerth Patel, Qingyun Wang, and Xinya Du. MLR-Copilot: Autonomous machine learning research based on large language models agents. arXiv preprint arXiv:2408.14033, 2024. [13] Daniil A. Boiko, Robert MacKnight, and Gabe Gomes. Autonomous chemical research with large language models. Nature, 623:760768, 2023. [14] Yusuf Roohani, Jian Vora, Qian Huang, Percy Liang, and Jure Leskovec. BioDiscoveryAgent: An ai agent for designing genetic perturbation experiments. In ICLR 2024 Workshop on Machine Learning for Genomics Explorations, 2024. 17 [15] Charlotte Bunne, Yusuf Roohani, Yanay Rosen, Ankit Gupta, Xikun Zhang, Marcel Roed, Theo Alexandrov, Mohammed AlQuraishi, Patricia Brennan, Daniel Burkhardt, et al. How to build the virtual cell with artificial intelligence: Priorities and opportunities. Cell, 187(25):7045 7063, 2024. [16] Yusuf H. Roohani, Tony J. Hua, Po-Yuan Tung, Lexi R. Bounds, Feiqiao B. Yu, Alexander Dobin, Noam Teyssier, Abhinav Adduri, Alden Woodrow, Brian S. Plosky, Reshma Mehta, Benjamin Hsu, Jeremy Sullivan, Chiara Ricci-Tam, Nianzhen Li, Julia Kazaks, Luke A. Gilbert, Silvana Konermann, Patrick D. Hsu, Hani Goodarzi, and Dave P. Burke. Virtual cell challenge: Toward turing test for the virtual cell. Cell, 188(13):33703374, 2025. [17] Haotian Cui, Alejandro Tejada-Lapuerta, Maria Brbic, Julio Saez-Rodriguez, Simona Cristea, Hani Goodarzi, Mohammad Lotfollahi, Fabian Theis, and Bo Wang. Towards multimodal foundation models in molecular cell biology. Nature, 640(8059):623633, 2025. [18] Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo Wang. scGPT: toward building foundation model for single-cell multi-omics using generative ai. Nature Methods, 21(8):14701480, 08 2024. [19] Christina Theodoris, Ling Xiao, Anant Chopra, Mark Chaffin, Zeina Al Sayed, Matthew Hill, Helene Mantineo, Elizabeth Brydon, Zexian Zeng, Shirley Liu, et al. Transfer learning enables predictions in network biology. Nature, 618(7965):616624, 2023. [20] Mohammad Lotfollahi, Anna Klimovskaia Susmelj, Carlo De Donno, Leon Hetzel, Yuge Ji, Ignacio Ibarra, Sanjay Srivatsan, Mohsen Naghipourfar, Riza Daza, Beth Martin, et al. Predicting cellular responses to complex perturbations in high-throughput screens. Molecular systems biology, 19(6):e11517, 2023. [21] Minsheng Hao, Jing Gong, Xin Zeng, Chiming Liu, Yucheng Guo, Xingyi Cheng, Taifeng Wang, Jianzhu Ma, Xuegong Zhang, and Le Song. Large-scale foundation model on single-cell transcriptomics. Nature methods, 21(8):14811491, 2024. [22] Daniel Levine, Syed Asad Rizvi, Sacha Levy, Nazreen Pallikkavaliyaveetil, David Zhang, Xingyu Chen, Sina Ghadermarzi, Ruiming Wu, Zihe Zheng, Ivan Vrkic, et al. Cell2Sentence: teaching large language models the language of biology. BioRxiv, pages 202309, 2024. [23] Aaron Wenteler, Martina Occhetta, Nikhil Branson, Magdalena Huebner, Victor Curean, William Dee, William Connell, Alex Hawkins-Hooker, Pui Chung, Yasha Ektefaie, et al. PertEval-scFM: Benchmarking single-cell foundation models for perturbation effect prediction. bioRxiv, pages 202410, 2024. [24] Stefan Peidli, Tessa Green, Ciyue Shen, Torsten Gross, Joseph Min, Samuele Garda, scPerturb: Bo Yuan, Linus Schumacher, Jake Taylor-King, Debora Marks, et al. harmonized single-cell perturbation data. Nature Methods, 21(3):531540, 2024. [25] Ihab Bendidi, Shawn Whitfield, Kian Kenyon-Dean, Hanene Ben Yedder, Yassir El Mesbahi, Emmanuel Noutahi, and Alisandra K. Denton. Benchmarking transcriptomics foundation models for perturbation analysis: one PCA still rules them all, 11 2024. [26] Leon Hetzel, Simon Boehm, Niki Kilbertus, Stephan Gunnemann, Fabian Theis, et al. Predicting cellular responses to novel drug perturbations at single-cell resolution. Advances in Neural Information Processing Systems, 35:2671126722, 2022. [27] Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, and Sung Ju Hwang. ResearchAgent: Iterative research idea generation over scientific literature with large language models. arXiv preprint arXiv:2404.07738, 2024. [28] Chenglei Si, Diyi Yang, and Tatsunori Hashimoto. Can LLMs generate novel research ideas? large-scale human study with 100+ NLP researchers. arXiv preprint arXiv:2409.04109, 2024. [29] Alireza Ghafarollahi and Markus Buehler. Sparks: Multi-agent artificial intelligence model discovers protein design principles. arXiv preprint arXiv:2504.19017, 2025. 18 [30] Samuel Schmidgall and Michael Moor. AgentRxiv: Towards collaborative autonomous research. arXiv preprint arXiv:2503.18102, 2025. [31] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. Large language model based multi-agents: survey of progress and challenges, 02 2024. [32] Yansheng Qiu, Haoquan Zhang, Zhaopan Xu, Ming Li, Diping Song, Zheng Wang, and Kaipeng Zhang. AI Idea Bench 2025: AI research idea generation benchmark. arXiv preprint arXiv:2504.14191, 2025. [33] Kai Ruan, Xuan Wang, Jixiang Hong, Peng Wang, Yang Liu, and Hao Sun. LiveIdeaBench: Evaluating llms scientific creativity and idea generation with minimal context. arXiv preprint arXiv:2412.17596, 2024. [34] Tingting Chen, Srinivas Anumasa, Beibei Lin, Vedant Shah, Anirudh Goyal, and Dianbo Liu. Auto-Bench: An automated benchmark for scientific discovery in LLMs. arXiv preprint arXiv:2502.15224, 2025. [35] Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du, and Dong Yu. DSBench: How far are data science agents to becoming data science experts? arXiv preprint arXiv:2409.07703, 2024. [36] Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, and Chenhao Tan. Literature meets data: synergistic approach to hypothesis generation. arXiv preprint arXiv:2410.17309, 2024. [37] Ruiqi Zhong, Peter Zhang, Steve Li, Jinwoo Ahn, Dan Klein, and Jacob Steinhardt. Goal driven discovery of distributional differences via language descriptions. In NeurIPS 2023, 2023. [38] Kevin Pu, KJ Feng, Tovi Grossman, Tom Hope, Bhavana Dalvi Mishra, Matt Latzke, Jonathan Bragg, Joseph Chee Chang, and Pao Siangliulue. IdeaSynth: Iterative research idea development through evolving and composing idea facets with literature-grounded feedback. arXiv preprint arXiv:2410.04025, 2024. [39] Aniketh Garikaparthi, Manasi Patwardhan, Lovekesh Vig, and Arman Cohan. IRIS: Interactive research ideation system for accelerating scientific discovery. arXiv preprint arXiv:2504.16728, 2025. [40] Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, and Zhenzhong Lan. Nova: An iterative planning and search approach to enhance novelty and diversity of llm generated ideas. arXiv preprint arXiv:2410.14255, 2024. [41] Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, and Daniel Weld. Scideator: Human-llm scientific idea generation grounded in research-paper facet recombination. arXiv preprint arXiv:2409.14634, 2024. [42] Xian Gao, Zongyun Zhang, Mingye Xie, Ting Liu, and Yuzhuo Fu. Graph of AI ideas: Leveraging knowledge graphs and llms for AI research idea generation. arXiv preprint arXiv:2503.08549, 2025. [43] Alireza Ghafarollahi and Markus Buehler. AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. arXiv preprint arXiv:2407.10022, 2024. [44] Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. MedAgents: Large language models as collaborators for zero-shot medical reasoning. Findings of ACL 2024, 2024. [45] Vladimir Naumov, Diana Zagirova, Sha Lin, Yupeng Xie, Wenhao Gou, Anatoly Urban, Nina Tikhonova, Khadija Alawi, Mike Durymanov, Fedor Galkin, et al. DORA AI scientist: Multi-agent virtual research team for scientific exploration discovery and automated report generation. bioRxiv, 2025. 19 [46] Patrick Tser Jern Kon, Jiachen Liu, Qiuyi Ding, Yiming Qiu, Zhenning Yang, Yibo Huang, Jayanth Srinivasa, Myungjin Lee, Mosharaf Chowdhury, and Ang Chen. Curie: Toward rigorous and automated scientific experimentation with AI agents. arXiv preprint arXiv:2502.16069, 2025. [47] Zijun Liu, Kaiming Liu, Yiqi Zhu, Xuanyu Lei, Zonghan Yang, Zhenhe Zhang, Peng Li, and Yang Liu. AIGS: Generating science from AI-powered automated falsification. arXiv preprint arXiv:2411.11910, 2024. [48] Joeran Beel, Min-Yen Kan, and Moritz Baumgart. Evaluating sakanas AI scientist for autonomous research: Wishful thinking or an emerging reality towards artificial research intelligence(ARI)? arXiv preprint arXiv:2502.14297, 2025. [49] Robert Friel, Masha Belyi, and Atindriyo Sanyal. RAGBench: Explainable benchmark for retrieval-augmented generation systems, 2025. [50] Chandan Reddy and Parshin Shojaee. Towards scientific discovery with generative AI: Progress, opportunities, and challenges. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 2860128609, 2025. [51] Steffen Eger, Yong Cao, Jennifer DSouza, Andreas Geiger, Christian Greisinger, Stephanie Gross, Yufang Hou, Brigitte Krenn, Anne Lauscher, Yizhi Li, et al. Transforming science with large language models: survey on AI-assisted scientific discovery, experimentation, content generation, and evaluation. arXiv preprint arXiv:2502.05151, 2025. [52] Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, and Dawei Zhou. Scientific hypothesis generation and validation: Methods, datasets, and future directions. arXiv preprint arXiv:2505.04651, 2025. [53] Shuo Ren, Pu Jian, Zhenjiang Ren, Chunlin Leng, Can Xie, and Jiajun Zhang. Towards scientific intelligence: survey of llm-based scientific agents. arXiv preprint arXiv:2503.24047, 2025. [54] Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris Maddison, et al. Bioreason: Incentivizing multimodal biological reasoning within dna-llm model. arXiv preprint arXiv:2505.23579, 2025. [55] Kexin Huang, Ying Jin, Ryan Li, Michael Li, Emmanuel Cand`es, and Jure Leskovec. arXiv preprint Automated hypothesis validation with agentic sequential falsifications. arXiv:2502.09858, 2025. [56] Minsheng Hao, Yongju Lee, Hanchen Wang, Gabriele Scalia, and Aviv Regev. Perturboagent: self-planning agent for boosting sequential perturb-seq experiments. bioRxiv, pages 202505, 2025. [57] Kexin Huang, Serena Zhang, Hanchen Wang, Yuanhao Qu, Yingzhou Lu, Yusuf Roohani, Ryan Li, Lin Qiu, Junze Zhang, Yin Di, et al. Biomni: general-purpose biomedical ai agent. bioRxiv, pages 202505, 2025. [58] Hanchen Wang, Yichun He, Paula Coelho, Matthew Bucci, Abbas Nazir, Bob Chen, Linh Trinh, Serena Zhang, Kexin Huang, Vineethkrishna Chandrasekar, et al. Spatialagent: An autonomous ai agent for spatial biology. bioRxiv, pages 202504, 2025. [59] Ruofan Jin, Zaixi Zhang, Mengdi Wang, and Le Cong. Stella: Self-evolving llm agent for biomedical research. arXiv preprint arXiv:2507.02004, 2025. [60] Atray Dixit, Oren Parnas, Biyu Li, Jenny Chen, Charles Fulco, Livnat Jerby-Arnon, Nemanja Marjanovic, Danielle Dionne, Tyler Burks, Raktima Raychowdhury, et al. Perturb-Seq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens. Cell, 167(7):18531866, 2016. 20 [61] Michael Skinnider, Jordan Squair, Claudia Kathe, Mark Anderson, Matthieu Gautier, Kaya JE Matson, Marco Milano, Thomas Hutson, Quentin Barraud, Aaron Phillips, et al. Cell type prioritization in single-cell data. Nature biotechnology, 39(1):3034, 2021. [62] Mohammad Lotfollahi, Alexander Wolf, and Fabian Theis. scGen predicts single-cell perturbation responses. Nature methods, 16(8):715721, 2019. [63] Xiaojie Qiu, Yan Zhang, Jorge Martin-Rufino, Chen Weng, Shayan Hosseinzadeh, Dian Yang, Angela Pogson, Marco Hein, Kyung Hoi Joseph Min, Li Wang, et al. Mapping transcriptomic vector fields of single cells. Cell, 185(4):690711, 2022. [64] Yusuf Roohani, Kexin Huang, and Jure Leskovec. Predicting transcriptional outcomes of novel multigene perturbations with GEARS. Nature Biotechnology, 42(6):927935, 2024. [65] Ding Bai, Caleb Ellington, Shentong Mo, Le Song, and Eric Xing. AttentionPert: accurately modeling multiplexed genetic perturbations with multi-scale effects. Bioinformatics, 40(Supplement 1):i453i461, 2024. [66] Kenji Kamimoto, Blerta Stringa, Christy Hoffmann, Kunal Jindal, Lilianna Solnica-Krezel, and Samantha Morris. Dissecting cell identity via network inference and in silico gene perturbation. Nature, 614(7949):742751, 2023. [67] Charlotte Bunne, Stefan Stark, Gabriele Gut, Jacobo Sarabia Del Castillo, Mitch Levesque, Kjong-Van Lehmann, Lucas Pelkmans, Andreas Krause, and Gunnar Ratsch. Learning singlecell perturbation responses using neural optimal transport. Nature Methods, 20(11):17591768, 2023. [68] Mingze Dong, Bao Wang, Jessica Wei, Antonio de O. Fonseca, Curtis Perry, Alexander Frey, Feriel Ouerghi, Ellen Foxman, Jeffrey Ishizuka, Rahul Dhodapkar, et al. Causal identification of single-cell experimental perturbation effects with CINEMA-OT. Nature methods, 20(11):17691779, 2023. [69] Qun Jiang, Shengquan Chen, Xiaoyang Chen, and Rui Jiang. scPRAM accurately predicts single-cell gene expression perturbation response based on attention mechanism. Bioinformatics, 40(5):btae265, 2024. [70] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence embeddings using siamese BERT-networks. arXiv preprint arXiv:1908.10084, 2019. [71] Britt Adamson, Thomas Norman, Marco Jost, Min Cho, James Nunez, Yuwen Chen, Jacqueline Villalta, Luke Gilbert, Max Horlbeck, Marco Hein, et al. multiplexed single-cell CRISPR screening platform enables systematic dissection of the unfolded protein response. Cell, 167(7):18671882, 2016. [72] Mohammad Lotfollahi, Anna Klimovskaia Susmelj, Carlo De Donno, Yuge Ji, Ignacio L. Ibarra, et al. Learning interpretable cellular responses to complex perturbations in highthroughput screens. Bioinformatics, 04 2021. [73] Charlotte Bunne, Andreas Krause, and Marco Cuturi. Supervised training of conditional monge maps. Advances in Neural Information Processing Systems, 35:68596872, 2022. [74] Zoe Piran, Niv Cohen, Yedid Hoshen, and Mor Nitzan. Disentanglement of single-cell data with biolord. Nature Biotechnology, 42(11):16781683, 2024. [75] Thomas Norman, Max Horlbeck, Joseph Replogle, Alex Ge, Albert Xu, Marco Jost, Luke Gilbert, and Jonathan Weissman. Exploring genetic interaction manifolds constructed from rich single-cell phenotypes. Science, 365(6455):786793, 2019. [76] Sanjay Srivatsan, Jose McFaline-Figueroa, Vijay Ramani, Lauren Saunders, Junyue Cao, Jonathan Packer, Hannah Pliner, Dana Jackson, Riza Daza, Lena Christiansen, et al. Massively multiplex chemical transcriptomics at single-cell resolution. Science, 367(6473):45 51, 2020. 21 [77] Dominik Klein, Jonas Simon Fleck, Daniil Bobrovskiy, Lea Zimmermann, Soren Becker, Alessandro Palma, Leander Dony, Alejandro Tejada-Lapuerta, Guillaume Huguet, Hsiu-Chuan Lin, et al. Cellflow enables generative single-cell phenotype modeling with flow matching. bioRxiv, pages 202504, 2025. [78] Geoffrey Schiebinger, Jian Shu, Marcin Tabaka, Brian Cleary, Vidya Subramanian, Aryeh Solomon, Joshua Gould, Siyan Liu, Stacie Lin, Peter Berube, et al. Optimal-transport analysis of single-cell gene expression identifies developmental trajectories in reprogramming. Cell, 176(4):928943, 2019. [79] Efthymia Papalexi, Eleni Mimitou, Andrew Butler, Samantha Foster, Bernadette Bracken, William Mauck III, Hans-Hermann Wessels, Yuhan Hao, Bertrand Yeung, Peter Smibert, et al. Characterizing the molecular regulation of inhibitory immune checkpoints with multimodal single-cell screens. Nature genetics, 53(3):322331, 2021. [80] Noa Liscovitch-Brauer, Antonino Montalbano, Jiale Deng, Alejandro Mendez-Mancilla, HansHermann Wessels, Nicholas Moss, Chia-Yu Kung, Akash Sookdeo, Xinyi Guo, Evan Geller, et al. Profiling the genetic determinants of chromatin accessibility with scalable single-cell crispr screens. Nature biotechnology, 39(10):12701277, 2021. [81] Chen Li, Haoxiang Gao, Yuli She, Haiyang Bian, Qing Chen, Kai Liu, Lei Wei, and Xuegong Zhang. Benchmarking ai models for in silico gene perturbation of cells. bioRxiv, pages 202412, 2024. [82] Xi Fu, Shentong Mo, Alejandro Buendia, Anouchka Laurent, Anqi Shao, Maria del Mar Alvarez-Torres, Tianji Yu, Jimin Tan, Jiayu Su, Romella Sagatelian, et al. foundation model of transcription across human cell types. Nature, 637(8047):965973, 2025. [83] Adam Gayoso, Zo Steier, Romain Lopez, Jeffrey Regier, Kristopher L. Nazor, Aaron Streets, and Nir Yosef. Joint probabilistic modeling of single-cell multi-omic data with totalvi. Nature Methods, 18(3):272282, Mar 2021. [84] Tal Ashuach, Mariano I. Gabitto, Rohan V. Koodli, Giuseppe Antonio Saldi, Michael I. Jordan, and Nir Yosef. Multivi: deep generative model for the integration of multimodal data. Nature Methods, 20(8):12221231, Aug 2023. [85] ZhiJie Cao and Ge Gao. Multiomics singlecell data integration and regulatory inference with graphlinked embedding. Nature Biotechnology, 40(10):14581466, May 2022. [86] Zhi-Jie Cao and Ge Gao. Multi-omics single-cell data integration and regulatory inference with graph-linked embedding. Nature Biotechnology, 40(10):14581466, 2022. [87] Constantin Ahlmann-Eltze, Wolfgang Huber, and Simon Anders. Deep learning-based predictions of gene perturbation effects do not yet outperform simple linear baselines. BioRxiv, pages 202409, 2024. [88] Lanxiang Li, Yue You, Wenyu Liao, Xueying Fan, Shihong Lu, Ye Cao, Bo Li, Wenle Ren, Yunlin Fu, Jiaming Kong, et al. systematic comparison of single-cell perturbation response prediction models. bioRxiv, pages 202412, 2024. [89] Yicheng Gao, Zhiting Wei, Kejing Dong, Ke Chen, Jingya Yang, Guohui Chuai, and Qi Liu. Toward subtaskdecompositionbased learning and benchmarking for predicting genetic perturbation outcomes and beyond. Nature Computational Science, 4(10):773785, Sep 2024. [90] Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu. Llms-as-judges: comprehensive survey on llm-based evaluation methods. arXiv preprint arXiv:2412.05579, 2024. [91] Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, et al. survey on llm-as-a-judge. arXiv preprint arXiv:2411.15594, 2024. [92] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. PubMedQA: dataset for biomedical research question answering. arXiv preprint arXiv:1909.06146, 2019. [93] OpenAI."
        },
        {
            "title": "Introducing",
            "content": "deep research. deep-research/, 2025. Accessed: 2025-05-08. https://openai.com/index/ [94] Giulio Starace, Oliver Jaffe, Dane Sherburn, James Aung, Chan Jun Shern, Leon Maksin, Rachel Dias, Evan Mays, Benjamin Kinsella, Wyatt Thompson, Johannes Heidecke, Amelia Glaese, and Tejal Patwardhan. PaperBench: Evaluating AIs ability to replicate AI research. arXiv preprint arXiv:2504.01848, 2025. [95] Haoyang Su, Renqi Chen, Shixiang Tang, Xinzhe Zheng, Jingzhe Li, Zhenfei Yin, Wanli Ouyang, and Nanqing Dong. Two heads are better than one: multi-agent system has the potential to improve scientific idea generation. arXiv preprint arXiv:2410.09403, 2024. [96] Long Li, Weiwen Xu, Jiayan Guo, Ruochen Zhao, Xingxuan Li, Yuqian Yuan, Boqiang Zhang, Yuming Jiang, Yifei Xin, Ronghao Dang, Deli Zhao, Yu Rong, Tian Feng, and Lidong Bing. Chain of ideas: Revolutionizing research via novel idea development with llm agents. arXiv preprint arXiv:2410.13185, 2024. [97] Ken Gu, Ruoxi Shang, Ruien Jiang, Keying Kuang, Richard-John Lin, Donghe Lyu, Yue Mao, Youran Pan, Teng Wu, Jiaqian Yu, et al. BLADE: Benchmarking language model agents for data-driven science. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 1393613971, 2024. [98] Future House. FutureHouse platform: scientific discovery. https://www.futurehouse.org/research-announcements/ launching-futurehouse-platform-ai-agents, 2024. Accessed on 2025-05-06; Nonprofit organization developing AI scientist tools for automated research workflows."
        },
        {
            "title": "Superintelligent AI agents",
            "content": "for [99] Haoyang Liu, Yijiang Li, Jinglin Jian, Yuxuan Cheng, Jianrong Lu, Shuyi Guo, Jinglei Zhu, Mianchen Zhang, Miantong Zhang, and Haohan Wang. Toward team of AI-made scientists for scientific discovery from gene expression data. arXiv preprint arXiv:2402.12391, 2024. [100] Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. True few-shot learning with prompts real-world perspective. Transactions of the Association for Computational Linguistics, 10:10321047, 2022. [101] Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, and Emad Barsoum. Agent laboratory: Using llm agents as research assistants. arXiv preprint arXiv:2501.04227, 2025. [102] Peter Jansen, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel Weld, and Peter Clark. Codescientist: Endto-end semi-automated scientific discovery with code-based experimentation. arXiv preprint arXiv:2503.22708, 2025. [103] Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, Bo Zhang, and Lei Bai. SurveyForge: On the outline heuristics, memory-driven generation, and multi-dimensional evaluation for automated survey writing. arXiv preprint arXiv:2503.04629, 2025. [104] Zhicheng Lin. Beyond principlism: practical strategies for ethical ai use in research practices. AI and Ethics, pages 113, 2024. [105] Thomas Moerman, Sara Aibar Santos, Carmen Bravo Gonzalez-Blas, Jaak Simm, Yves Moreau, Jan Aerts, and Stein Aerts. GRNBoost2 and Arboreto: efficient and scalable inference of gene regulatory networks. Bioinformatics, 35(12):21592161, 2019. [106] Fan Yang, Wenchuan Wang, Fang Wang, Yuan Fang, Duyu Tang, Junzhou Huang, Hui Lu, and Jianhua Yao. scBERT as large-scale pretrained deep language model for cell type annotation of single-cell rna-seq data. Nature Machine Intelligence, 4(10):852866, 2022. [107] George I. Gavriilidis, Vasileios Vasileiou, Aspasia Orfanou, Naveed Ishaque, and Fotis Psomopoulos. mini-review on perturbation modelling across single-cell omic modalities. Computational and Structural Biotechnology Journal, 23:18861896, 2024. [108] Sanjay R. Srivatsan, Jos L. McFalineFigueroa, Vijay Ramani, Lauren M. Saunders, Junyue Cao, Jonathan S. Packer, Hannah A. Pliner, Dana L. Jackson, Riza M. Daza, Lena Christiansen, Fan Zhang, Frank Steemers, Jay Shendure, and Cole Trapnell. Massively multiplex chemical transcriptomics at singlecell resolution. Science, 367(6473):eaat5691, Dec 2019. [109] Tim Stuart, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M. III Mauck, Yuhan Hao, Marlon Stoeckius, Peter Smibert, and Rahul Satija. Comprehensive integration of single-cell data. Cell, 177(7):18881902.e21, June 2019. [110] F. Alexander Wolf, Philipp Angerer, and Fabian J. Theis. Scanpy: large-scale single-cell gene expression data analysis. Genome Biology, 19(1):15, February 2018. [111] Yanrong Ji, Zhihan Zhou, Han Liu, and Ramana V. Davuluri. Dnabert: pretrained bidirectional encoder representations from transformers model for dnalanguage in genome. Bioinformatics, 37(15):21122120, August 2021. [112] Oren Shalem, Neville E. Sanjana, and Feng Zhang. Genome-scale crisprcas9 knockout and transcriptional activation screening. Nature Reviews Genetics, 16(5):299311, 2015. [113] Ronald Sarkis and Jennifer Listgarten. The case for genomic pretraining: commentary. Nature Methods, 20(10):11011104, 2023. [114] Malte D. Luecken, Scott Gigante, Daniel B. Burkhardt, Robrecht Cannoodt, Daniel C. Strobl, Nikolay S. Markov, and et al. Challenges and opportunities in fair singlecell data analysis. Nature Reviews Genetics, 24(8):550572, 2022. [115] X. Zhang, J. D. Sander, et al. Cellbox: interpretable and generalizable cell representations for single cell transcriptomics. Science Advances, 8, 2022. [116] Juexin Wang, Anjun Ma, Yuzhou Chang, Jianting Gong, Yuexu Jiang, Hongjun Fu, Cankun Wang, Ren Qi, Qin Ma, and Dong Xu. scgnn is novel graph neural network framework for single-cell rnaseq analyses. Nature Communications, 12:1882, 2021. [117] Fan Yang, Wenchuan Wang, Fang Wang, Yuan Fang, Duyu Tang, Junzhou Huang, Hui Lu, and Jianhua Yao. scbert as largescale pretrained deep language model for cell type annotation of singlecell rnaseq data. Nature Machine Intelligence, 4:852866, 2022. [118] Talia Ashuach, Pierre Boyeau, Justin Hong, Adam Gayoso, et al. Mrvi: multiresolution generative modeling of singlecell datasets. Cell Systems, ??:??????, 2023. [119] Xiaoqin Zeng, Jiacheng Zhang, Yuan Liu, Zhiyuan Wang, Yijie Xia, Siyu Lu, Sijia Gao, Yichi Zhang, Jiaming Shen, Zelu Li, et al. xtrimopglm: foundation model for biology. bioRxiv, pages 202402, 2024. [120] Maxim Zvyagin, Sam Sinha, Alexander Tsereteli, Avinava Reddy, and Pietro Lio. Genslm: generative foundation model for genomic sequences. bioRxiv, pages 202210, 2022. [121] Tong Tian, Haotian Wujiang, Zhaowei Yang, Mingfeng Li, Yi Gu, Bensheng Hu, Ya Li, Bolin Yuan, Yapeng Shao, Siqi Zhang, Cheng Lu, Zhiqiang Wang, Hongyi Liu, Yan Zhang, Ruize Zhang, Yong Hou, Hairong Xu, Jiawei Wang, and Yuan Zhang. scfoundation: foundation model for single-cell analysis based on contrastive learning. Nature Methods, 20(9):13851388, 2023. [122] Taghrid Abdelaal, Lennart Michielsen, Dries Cats, Daan Hoogduin, Hailiang Mei, Marcel Reinders, and Ahmed Mahfouz. comparison of automatic cell identification methods for single-cell RNA sequencing data. Genome Biology, 20(1):117, 2019. [123] Malte Luecken, Maren Buttner, Fabian Theis, et al. Benchmarking atlas-level data integration in single-cell genomics. Nature Methods, 19(1):4150, 2021. [124] Malte Luecken, Daniel Burkhardt, Fabian Theis, et al. Defining and benchmarking open problems in single-cell analysis. Nature Methods, 19(4):412420, 2022. [125] Johann Martens, Tal Rosen, et al. LANGPERT: LLM-DRIVEN contextual synthesis for unseen perturbation prediction. In The Twelfth International Conference on Learning Representations, 2024. [126] Rotem Piran, Dana Peer, and Nir Yosef. Disentanglement of single-cell data with biolord. Nature Biotechnology, 41(10):14131423, 2023. [127] Upasana Shree et al. scDREAMER for atlas-level integration of single-cell datasets using deep generative model paired with adversarial learning. Nature Communications, 15(1):2036, 2024. [128] Quan Tang, Na Le, et al. Single-cell multimodal prediction via transformers. In NeurIPS 2022 Workshop on Learning from Time Series for Health, 2022. [129] Charlotte Bunne et al. Supervised training of conditional monge maps."
        },
        {
            "title": "In The Twelfth",
            "content": "International Conference on Learning Representations, 2024. [130] Lukas Heumos, Anne Schaar, et al. Best practices for single-cell analysis across modalities. Nature Reviews Genetics, 24(6):395415, 2023. [131] Rochelle Flores, Shicong Wang, et al. Deep learning tackles single-cell analysisa survey of deep learning for scRNA-seq analysis. Briefings in Bioinformatics, 23(5):bbac327, 2022. [132] Hiba Maan, Matti Lahde, et al. Characterizing the impacts of dataset imbalance on single-cell data integration. Nature Biotechnology, 42(1):5660, 2024. [133] K-J Youngblut et al. scBaseCamp: an AI agent-curated, uniformly processed, and continually expanding single cell data resource. bioRxiv, pages 20231108.566275, 2023. [134] Jordan W. Squair and Fabian J. Theis. practical guide to single-cell perturbation analysis. Nature Reviews Genetics, 2024. [135] Romain Lopez, Jordan Regier, Michael Cole, Michael Jordan, and Nir Yosef. scVI: deep generative modeling for single-cell transcriptomics. Nature Methods, 15(12):10531058, 2018. [136] Yousif Rashid, Atefeh Chinappi, Gabrielle-A Lavertu, Andreas He-Zhang, Bo Wang, and Gary Bader. Perturbnet predicts single-cell responses to unseen chemical perturbations. Nature Methods, 21(2):253257, 2024. [137] Theofanis Karaletsos, Oren Ben-Kiki, Anan Daka, Mor Kaduri, Tomer Rofe, Matan Yarom, Yonatan Bogoch, Mor Cohen, Ofir Gilon, Dana Giltam, Le He, Zheng-Shan He, Benjamin Leader, Bowen Li, Hai-Li Lv, Eyal Piran, Tudor Pop, Honglei Sheng, Noam Shomron, Adi Steinitz, Jiarui Wu, Yixu Yang, Yifan Zhang, Zilu Zhang, and Aviv Regev. Cell2sentence: Teaching large language models the language of biology. bioRxiv, 2024. [138] Lukas Heumos, Anna Schaar, Alexander Misharin, Fabian Theis, and Nir Yosef. Zero-shot evaluation reveals limitations of single-cell foundation models. Nature Methods, 21(4):511513, 2024. [139] Zixiao Sun, Yixuan Song, Xingran Zhao, Jia Wang, Tinglin Wang, Quanquan Zhang, Bo Li, and Yu Li. scgenept: Is language all you need for modeling single-cell perturbation prediction? bioRxiv, pages 202401, 2024."
        },
        {
            "title": "Limitations",
            "content": "Despite the demonstrated effectiveness of CELLFORGE in single-cell perturbation analysis, several limitations warrant consideration: Computational and Economic Costs. The framework requires substantial compute and LLM usage. As Table 11 shows, the average cost per experiment ranges from $0.38 to $18.90 depending on the backend, and full multi-agent dialogue can consume up to 400 output tokensintroducing both monetary and latency constraints. Failure Modes. Our failure analysis (Appendix G) indicates that 41 % of errors arise from execution issues (e.g. tensor-shape mismatches). Although mitigation strategies are in place, these systematic failures highlight the difficulty of fully autonomous code generation for complex biological pipelines. Domain Specificity. CELLFORGE is currently tailored to single-cell perturbation tasks; extending it to other domains (spatial transcriptomics, proteomics, multi-omics) will require additional knowledge engineering and architectural changes. Dependence on Task-Specification Quality. Performance is sensitive to the clarity of the naturallanguage task description. Ambiguous or incomplete prompts can yield sub-optimal designs, so users must formulate well-defined questions. Limited Novelty Detection. While the system excels at recombining known patterns, proposing de novo biological mechanisms that are absent from the literature remains challenging. Real-World Deployment Status. External validation is still in progress. We have collected 100 real-world queries from collaborating computational biologists, but analysing these prospective runs extends beyond the current papers timeline. We commit to releasing the results once the study is complete. Lack of Prospective Wet-Lab Validation. Our evaluation is computational; no follow-up experiments have yet tested CELLFORGEs predictions in the lab. To bridge this gap we enlisted three domain experts to rate the scientific validity, biological significance, and technical feasibility of the generated research plans, but full wet-lab confirmation of novel hypotheses remains an important avenue for future work."
        },
        {
            "title": "Broader Impact",
            "content": "The development of CellForge has several important implications for the scientific community and society: Democratization of Scientific Research. By automating complex analytical workflows, CellForge lowers the technical barriers for conducting sophisticated single-cell analyses. This could enable smaller research groups and institutions with limited computational expertise to engage in cuttingedge genomics research, potentially accelerating scientific discovery globally. Acceleration of Therapeutic Development. The ability to rapidly predict cellular responses to perturbations has direct applications in drug discovery and personalized medicine. Our framework could significantly reduce the time and cost of identifying therapeutic targets and understanding drug mechanisms of action. Scientific Reproducibility. The end-to-end automation and explicit documentation of all analytical decisions enhance reproducibility in computational biology. The generated code and research plans provide complete audit trails, addressing critical challenge in modern scientific research. Ethical Considerations. The automation of scientific discovery raises important questions about attribution, responsibility, and validation of AI-generated hypotheses. While CellForge includes human-interpretable outputs and confidence scores, researchers must carefully validate all predictions before drawing biological conclusions or making therapeutic decisions. Environmental Impact. The computational requirements of running multiple LLM agents have non-negligible carbon footprint. Future work should explore more efficient architectures and consider the environmental cost-benefit trade-offs of automated scientific discovery. Research Workforce Evolution. As AI systems become capable of conducting increasingly sophisticated analyses, the role of computational biologists may shift from implementing methods to critically evaluating AI-generated hypotheses and designs. This transition requires careful consideration of training and career development in the scientific workforce. Open Science Contribution. By releasing our code and model architectures, we aim to foster community-driven improvements and applications. However, we acknowledge the potential for misuse and encourage responsible deployment with appropriate biological validation and ethical oversight."
        },
        {
            "title": "Acknowledgement",
            "content": "We thank Wangchunshu Zhou and Kexu Li for their helpful suggestions and assistance in revising this paper. Xiangru Tang and Mark Gerstein are supported by Schmidt Futures."
        },
        {
            "title": "A Experimental Details",
            "content": "A.1 Datasets Introduction Our study leverages six publicly available single-cell perturbation datasets from the scPerturb [24] collection, encompassing diverse perturbation modalities and cell types. These datasets provide foundation for evaluating the scientific quality of AI-generated analyses across various biological contexts. Adamson et al. [71] (CRISPRi): Employing Perturb-seq to study the unfolded protein response (UPR) in K562 lymphoblasts through single and combinatorial CRISPR interference (CRISPRi) perturbations. Approximately 100 gene targets were profiled, enabling high-resolution functional clustering and revealing distinct activation patterns across UPR branches. Norman et al. [75] (CRISPRa): Utilizing CRISPR activation (CRISPRa) in K562 cells, this dataset explores genetic interaction manifolds derived from single-cell transcriptional phenotypes. The study provides insights into regulatory pathway ordering and mechanistic elucidation of synergistic interactions. Liscovitch et al. [80] (ATAC-seq): Employing CRISPRsciATAC, single-cell combinatorial indexing assay, to delineate the genetic determinants of chromatin accessibility in human myelogenous leukemia K562 cells. Targeting 105 chromatin-related genes via CRISPR-Cas9, the study generated chromatin accessibility profiles for approximately 30,000 single cells. Key findings include correlations between the loss of specific chromatin remodelers and global changes in chromatin accessibility. Notably, EZH2 depletion was associated with enhanced accessibility in heterochromatic regions linked to embryonic development and with activation of genes in the HOXA and HOXD clusters. This high-throughput approach offers valuable insights into the role of chromatin modifiers in regulating gene expression and their implications in disease states. Papalexi et al. [79] (CITE-seq): Combining CRISPR-Cas9 perturbations with single-cell RNA and surface protein measurements in THP-1 monocytes. It investigates the molecular regulation of inhibitory immune checkpoints, particularly PD-L1 expression, and introduces the mixscape computational framework to enhance signal-to-noise ratio in single-cell screens. Srivatsan et al. [76] (sci-Plex): Employing sci-Plex, this dataset profiles transcriptional responses of A549, K562, and MCF7 cancer cell lines to 188 small-molecule compounds across multiple doses. Approximately 650,000 single-cell transcriptomes were generated, uncovering intercellular heterogeneity and commonalities in drug responses. Schiebinger et al. [78] (cytokine perturbation): Applying optimal transport analysis to scRNA-seq data from mouse embryonic stem cells undergoing reprogramming with cytokine treatments. The dataset captures developmental trajectories and identifies transcription factors and paracrine signals influencing cell fate decisions. Collectively, these datasets encompass range of perturbation typesincluding CRISPRi, CRISPRa, CRISPR-Cas9, small-molecule drugs, and cytokinesacross various human and mouse cell lines. They provide robust foundation for evaluating the scientific quality and reliability of AI-generated analyses in single-cell biology. A.2 Agent Configurations In our experiments, we employed five LLMs API to generate responses: Claude 3.7, OpenAI o1, DeepSeek-R1, Qwen-Plus, and Llama 3.1. To ensure consistency and reproducibility across models, we standardized the generation parameters as follows: Temperature: Set to 0.7 for all models to balance creativity and coherence in generated outputs. Top-p (nucleus sampling): Fixed at 0.95 to maintain high probability mass while allowing for diverse outputs. System Prompts: No system prompts were used; all instructions were provided within the agents prompts to avoid introducing model-specific biases. These configurations align with recommended settings for models. By maintaining uniform settings across all models, we aimed to ensure fair comparison and reliable evaluation of their performance. 29 A.3 Memory Module Construction Shared Knowledge Infrastructure. Both Task Analysis and Method Design modules rely on shared hybrid knowledge infrastructure comprising (1) symbolic memory module that stores structured outputs from agents, and (2) vector-based retrieval system built on top of Sentence-BERT embeddings and external APIs (PubMed, GitHub). The memory module is incrementally constructed as each agent contributes new findings or insights, while the vector database supports RAG-style retrieval of external literature. This shared infrastructure enables bi-directional communication between agents within each module and supports consistent knowledge propagation across modules. See Appendix A.3 for implementation details. Collaborative Agents Shared Memory Module in Task Analysis. Instead of operating in isolation, the Dataset Analyst, Problem Investigator, and Baseline Assessor interact via the shared memory module and query interface. Each agent incrementally updates the memory module with its findings, while continuously polling for updates from other agents. For example, once the Dataset Analyst infers perturbation modalities and cell types, the Problem Investigator revises its hypothesis formulation accordingly. Agents operate asynchronously but synchronize their conclusions through shared JSON-based communication protocol, allowing for self-consistency checks and iterative refinement of the task representation. This collaborative reasoning leads to structured task analysis report passed to the Method Design module. Graph-Based Expert Shared Memory Module in Method Design. In the Method Design module, domain experts are instantiated as nodes in dynamic undirected graph. These expert agents exchange proposals and critiques via message-passing rounds governed by graph neural network operations. Throughout the discussion, the Critic Agent agent monitors logical coherence and suggests refinements. Each expert agent has read-write access to the shared memory module and can retrieve relevant prior knowledge from Agentic Retrieval. Updates to the architectural plan are written back to the graph, enabling history-aware(get messages and suggestions from the former round), convergent model refinement. A.4 Experts Discussion Construction Details To enable structured, reproducible reasoning across diverse perturbation modeling tasks, we construct the multi-agent expert discussion system through two key stages: expert role selection and dynamic collaboration graph construction. Based on the task analysis report, set of relevant expert agents is selected by matching task attributes against curated registry of expert types. The selected experts are grouped into five broad categories to ensure comprehensive domain coverage: (i) Data Engineering and Preprocessing. Data Expert is instantiated to address normalization, quality control, feature selection, and batch correction issues tailored to the input modality. (ii) Model Design and Scalability. The Model Architecture Expert and Deep Learning Expert are responsible for proposing architectures that balance expressiveness, (iii) Biological interpretability, and scalability, considering modality-specific modeling needs. Plausibility. Single Cell Experts such as the Pathway Expert, Drug Response Expert, and Omics Modality Expert contribute domain knowledge to align model components with known biological mechanisms, including gene regulatory networks, cytokine signaling, or pharmacodynamics. (iv) Training and Optimization. Training Expert is responsible for selecting and justifying the learning algorithm, optimization strategy, regularization, and validation scheme suitable for the data structure and model complexity. (v) Self-Critique and Evaluation. Critic agent is included in every discussion to promote internal scrutiny, consistency checks, and critical reflection over model assumptions and claims. For example, in gene knockout task, the system may instantiate the Data Expert to inspect whether the scRNA-seq matrix is properly normalized, whether cell and gene identifiers are standardized, and whether preprocessing sufficiently preserves perturbation-related variation. The Model Architecture Expert and Deep Learning Expert are instantiated to co-design gene-centric model that integrates perturbation-aware attention and captures target gene dependent regulatory effects. The Pathway Expert is instantiated to evaluate the role of the target gene within interferon signaling cascades, while the Omics Modality Expert assesses whether transcriptomic changes resulting from target gene ablation are robustly captured by scRNA-seq alone. The Training Expert selects dropout-regularized 30 contrastive training and cell-type-aware sampling scheme to stabilize optimization. The Statistics Expert designs differential expression based evaluation framework and quantifies the significance of target gene induced shifts using FDR-corrected effect sizes. Finally, the Critic Agent is instantiated to identify overfitting risks in rare knockout subsets, challenge latent space linearity assumptions, and refine model outputs for interpretability and robustness. All experts are set with role-specific prompts (Appendix P.3), crafted in zero-shot reasoning format. These prompts are conditioned on the shared Task Analysis report and elicit structured outputs, including modeling choices, biological justification, and critiques of others proposals. Formally, the expert set E(k) for task is derived by: E(k) = SelectExperts(TaskAnalysisReportk) Once instantiated, the experts are organized into an undirected collaboration graph G(k) = (S, E(k)), where each node E(i) E(k) represents an expert role. The Critic Agent node is fully connected to all others, serving both as dialectical evaluator and proposal aggregator. Each expert begins with an initial model proposal m(i) 0 and confidence score initialized to zero c(i) 0 = 0. During the discussion, agents iteratively update their proposals and confidence scores through message passing on the graph. Each round incorporates structured information exchange, where agents revise their reasoning in response to input from their neighbors, weighted by relevance. This structured and interpretable procedure allows CELLFORGE to generate scientifically grounded, multimodally coherent model designs that are not only technically sound but also biologically meaningful."
        },
        {
            "title": "B Evaluation Details",
            "content": "This appendix provides detailed formulations of the hierarchical metrics used in our benchmark evaluation of transcriptomics machine learning models for perturbation analysis. B.1 Mean Squared Error (MSE) This metric measures the average squared difference between the true and predicted gene expression vectors, quantifying overall prediction error. Let Yi, ˆYi Rd be the true and predicted expression vectors for sample i. Then MSE = 1 (cid:88) i=1 Yi ˆYi2 2. B.2 Pearson Correlation Coefficient (PCC) This metric assesses the strength of the linear association between predicted and true expression profiles across all samples. Define the sample means = 1 n (cid:88) i=1 Yi, ˆY = 1 (cid:88) i=1 ˆYi."
        },
        {
            "title": "Then",
            "content": "PCC = (cid:118) (cid:117) (cid:117) (cid:116) (cid:88) i=1 (cid:88) i= Yi , ˆYi ˆY Yi 2 2 . ˆYi ˆY 2 2 (cid:118) (cid:117) (cid:117) (cid:116) (cid:88) i=1 B.3 Coefficient of Determination (R2) This metric quantifies the proportion of variance in the true gene expression data that is captured by the models predictions. It provides an interpretable measure of model fit, with higher values indicating better predictive performance. Let Yi, ˆYi Rd be the true and predicted expression vectors for sample i, and let denote the mean of the true expression vectors. Then R2 = 1 (cid:80)n i=1 Yi ˆYi22 (cid:80) = 1nYi 2 . B.4 Metrics with Differential Expression (DE) Differential expression highlights the genes whose changes drive the biological response to perturbation, focusing evaluation on the most informative signals. Let {Yp,i}np i=1 be the true expression vectors under perturbation and control, respectively, with Yp,i, Yc,i Rd . For each gene = 1, . . . , d, compute the mean expression i=1 and {Yc,i}nc Yp,g = 1 np np (cid:88) i=1 Yp,i,g, Yc,g = 1 nc nc(cid:88) i=1 Yc,i,g."
        },
        {
            "title": "Quantify the change by the logfoldchange",
            "content": "LFCg = log2 Yp,g + ϵ Yc,g + ϵ , with small ϵ > 0 to avoid division by zero (or by the raw difference = Yp,g Yc,g). Rank genes by LFCg (or g), and select the top = 20 as the DE set: DE = { : rankg(LFC) }, = 20. Subsequent metrics (MSE, PCC, R2) are then computed only over DE to assess performance on these key drivers of perturbation response. 32 B.5 LatentSpace Linear Separability This metric evaluates if models latent space distinguishes between different perturbations using linear probing. Given frozen encoder mapping gϕ : xi (cid:55) zi Rd, train linear classifier to predict one of perturbation classes. For test samples with true labels yi, ˆy = softmax(W + b), Rcd, Rc, Top1 = 1 (cid:88) i=1 1{arg max ˆyij = yi}, Top5 = 1 (cid:88) i=1 1{yi Top5(ˆyi)}. B.6 Perturbation Consistency This metric assesses the consistency with which model represents perturbations between different samples and batches. Let be the set of all gene perturbations. For each P, suppose we have np embedding vectors { zp,i Rd = 1, . . . , np}."
        },
        {
            "title": "Define the mean cosinesimilarity score",
            "content": "Sp = 1 n2 np (cid:88) np (cid:88) i=1 j= zp,i, zp,j zp,i zp,j . Let {Sqk }K for perturbation is k=1 be the corresponding scores for unexpressedgene controls qk. The empirical pvalue Finally, the overall consistency rate is πp = max{#{k : Sqk Sp}, 1} . = (cid:12){ : πp < 0.05}(cid:12) (cid:12) (cid:12) , i.e. the fraction of perturbations whose embeddings are significantly more selfsimilar than the null. B.7 Latent Space Direct Organization This metric evaluates the degree to which perturbation clusters are locally organized in the latent space, using the k-Nearest Neighbors (kNN) classification. Let {zi}nq j=1 be the latent embeddings for the query and reference sets, with the corresponding labels yi and yj. Set i=1 and {zj}nr = nr. For each query index i, let Nk(i) {1, . . . , nr} be the reference index whose embeddings minimize zi zj2. Then the kNNclassification accuracy is AccuracykNN = 1 nq (cid:104) 1 nq (cid:88) i= yi = arg max cC (cid:88) (cid:105) 1[yj = c] , jNk(i) where denotes the set of all perturbation labels. B.8 Linear Interpretability of Latent Space Let Rnh be the frozen-encoder outputs and train linear MLP, ˆY = h(Z) Rnd two metrics: Spearman correlation and structural integrity. . We define Spearman Correlation This measures how accurately the latent embeddings can be decoded back into gene expression data using simple linear transformation. The Spearman correlation ρ is defined as ρ = 1 6 (cid:80)n i=1 (cid:2)rank(Yi) rank( ˆYi)(cid:3)2 , n(n2 1) where rank() returns the withinsample rank vector. Structural Integrity This metric evaluates how well the model preserves the relationship between control and perturbation conditions within each biological batch. For = 1, . . . , batches with nb samples each, let (cid:101)Y (b) pred = (b) pred (b) pred,ctrl, act = (b) (cid:101)Y (b) act (b) act,ctrl."
        },
        {
            "title": "Then",
            "content": "D = (cid:88)"
        },
        {
            "title": "1\nB",
            "content": "b=1 and the structural integrity is 1 nb (cid:13) (cid:13) (cid:101)Y (b) pred (cid:101)Y (b) act (cid:13) (cid:13)F , Dmax"
        },
        {
            "title": "2\nB",
            "content": "B (cid:88) b=1 1 nb (cid:13) (cid:13) (cid:101)Y (b) act (cid:13) (cid:13)F , SI ="
        },
        {
            "title": "D\nDmax",
            "content": ", with higher SI indicating better preservation of controlperturbation structure."
        },
        {
            "title": "C RAGBench Evaluation Details",
            "content": "To evaluate the performance of CellForge Agentic Retrieval system in Task Analysis Module, we employ RAGBech[49]. We first align our systems outputs to the format expected by RAGBench. Each output record must include: id: unique sample identifier; documents: list of retrieved context documents; question: the query text; response: the generated answer. Refer to constants.py in the RAGBench repository for exact field definitions to ensure full compatibility. Then we run inference on our systems outputs with evaluation models Trulens and dataset PubMedQA[92]. Detailed formulations of the metrics used in this RAGBench benchmark are as follow: Hallucination Detection (Hal) In Retrieval-Augmented Generation (RAG) systems, hallucination refers to the generation of content not grounded in the retrieved contextin other words, the model makes up facts. Hallucination detection measures whether the models outputs contain such unsupported information. Reliable RAG outputs demand faithfulness to the provided context. Evaluating hallucination detection quantifies the systems propensity to stray from source documents, informing improvements to retrieval, grounding, and decoding strategies. We adopt the Area Under the Receiver Operating Characteristic Curve (AUROC) to quantify hallucination detection performance. Given: truesadherence {True, False}, predsadherence [0, 1], we define hallucination labels by trueshalluc = truesadherence, predshalluc = 1 predsadherence."
        },
        {
            "title": "Then",
            "content": "mask = isnan(predshalluc). AUROC = ROC AUC (cid:16) trueshalluc[mask], predshalluc[mask] (cid:17) , where ROC AUC denotes the standard implementation (sklearn.metrics.roc auc score). Context Relevance (Rel) Context relevance assesses how well the retrieved documents pertain to the query, i.e. whether the context can support correct answer. High relevance is prerequisite for accurate generation. Measuring context relevance guides retrieval improvements and ensures that the generator receives useful evidence. We measure relevance via Root Mean Squared Error (RMSE) between true and predicted relevance scores: RMSE = (cid:118) (cid:117) (cid:117) (cid:116) 1 (cid:88) (cid:0)yi ˆyi (cid:1)2 , i=1 where yi is the gold relevance score, ˆyi the predicted score, and the number of examples. We ignore any NaN predictions by masking. 35 Context Utilization (Utl) Context utilization evaluates the extent to which the model leverages the retrieved context when generating its responses. Even with relevant context, model may underuse it. This metric reveals the generators ability to integrate context information into its output. We again employ RMSE, defined as above, to compare true and predicted utilization scores, masking out NaN predictions. Together, Hal, Rel, and Utl provide multi-faceted evaluation of RAG system performance: detecting hallucinations, ensuring context relevance, and confirming effective context usage. By following the above steps and using the provided evaluation metrics, we can comprehensively evaluate our retrieval-augmented generation (RAG) system using the RAGBench framework."
        },
        {
            "title": "D Detailed Algorithm Specifications",
            "content": "D.1 Agentic Retrieval System The agentic retrieval system combines both static knowledge integration and dynamic search capabilities to provide comprehensive scientific context for perturbation analysis tasks. Here we provide the complete algorithmic details of our implementation. D.1.1 Query Construction and Initialization Given task description and dataset metadata D, we first construct an initial query representation: Algorithm 2 Query Construction 1: procedure CONSTRUCTINITIALQUERY(T, D) keywords ExtractKeyTerms(T ) ExtractKeyTerms(D) 2: embedding SentenceBERT(keywords) 3: Q(0) NormalizeVector(embedding) 4: return Q(0) 5: 6: end procedure The function ExtractKeyTerms performs domain-specific extraction of biological entities (genes, cell types, perturbation methods) and technical terms (model architectures, evaluation metrics) using named entity recognition enhanced with domain-specific dictionaries. D.1.2 Alternating Search Strategy Unlike conventional RAG systems that employ pure breadth-first search with static keywords, our alternating BFS-DFS strategy enables autonomous knowledge discovery and dynamic query expansion specifically tailored for scientific literature mining. Standard RAG approaches typically search broadly using only the initial query terms (e.g., single cell perturbation prediction) but fail to discover that domain-critical concepts like optimal transport, graph neural networks, or specific model names like GEARS and scGPT are essential for understanding the field. Our alternating approach addresses this limitation by using BFS layers to explore diverse research directions and extract new technical terminology from retrieved papers, followed by DFS layers that trace citation networks to access implementation details and authoritative sources. This creates self-reinforcing cycle where the system autonomously evolves from basic queries like Norman Weissman 2019 Perturb-seq to sophisticated technical searches for Transformer VAE GNN architectures and graph neural networks gene regulatory networks. The result is retrieval system that transforms from passive keyword matcher into an active knowledge explorer, capable of discovering the complete technical landscape of scientific domain without human interventiona critical capability for complex, interdisciplinary research tasks where the most important concepts and methods may not be apparent from the initial problem description. Our multi-layer retrieval process alternates between breadth-first and depth-first search modes to balance exploration and exploitation: 37 Document collection BFS layer (odd t) DFS layer (even t) else if mod 2 = 1 then Nt FollowCitations(Nt1) Nt TopK(Q(t), mode = BFS) 0 N0 while < Lmax do Algorithm 3 Alternating BFS-DFS Retrieval 1: procedure RETRIEVEDOCUMENTS(Q(0), Lmax, τ, ϵ) 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: end procedure end if Nt Q(t+1) UpdateQuery(Q(t), Nt) if Overlap(Q(t+1), Q(t)) > τ then end if if maxdNt Score(Q(t), d) < ϵ then end while return end if + break break Relevance Scoring. The document relevance function uses cosine similarity in the embedding space: Score(Q, d) = e(Q) e(d) e(Q)e(d) (1) where e() is the Sentence-BERT encoder function mapping text to dense vectors. Query Update Mechanism. The query update function incorporates new information while maintaining focus: Q(t+1) = αQ(t) + (1 α) 1 Nt (cid:88) dNt e(d) where α = 0.7 is parameter controlling the balance between query persistence and adaptation. Overlap Computation. Query overlap is calculated as: Overlap(Q(t+1), Q(t)) = Q(t+1) Q(t) min(Q(t+1), Q(t)) (2) (3) where the intersection operation is implemented using thresholded similarity measure in the embedding space. D.2 Graph-based Multi-Expert Discussion The Method Design module employs graph-based discussion framework where experts collaboratively refine scientific hypotheses. Expert Selection. The expert selection procedure dynamically assembles team of domain specialists based on task requirements: (E(i)TaskAnalysis) exp(β Relevance(E(i), TaskAnalysis)) (4) 38 where β is temperature parameter controlling selection diversity. Confidence Update Rule. The confidence score update incorporates feedback from both the Critic Agent and other experts: = λ1 c(i) c(i) t1 + λ2 SelfCriticScore(m(i) , S) + λ3 1 1 (cid:88) j=i PeerScore(m(i) , E(j)) (5) where λ1 + λ2 + λ3 = 1 weights the relative importance of each component. Message Integration. Expert proposals are integrated through weighted combination: mt = (cid:88) i=1 w(i) m(i) where weights w(i) are derived from normalized confidence scores: w(i) = exp(c(i) ) j=1 exp(c(j) ) (cid:80)k (6) (7) This soft-voting mechanism ensures that higher-confidence perspectives have greater influence while still preserving diversity of thought. D.3 Code Implementation and Refinement Process The Validation Agent employs an iterative refinement process that systematically improves implementation quality: Code0 InitialImplementation(ModelDesign) Performance0 Evaluate(Code0, Dataset) for = 1 to Rmax do Algorithm 4 Iterative Implementation Refinement 1: procedure REFINEDIMPLEMENTATION(ModelDesign, Dataset, Rmax) 2: 3: 4: 5: 6: 7: 8: 9: end procedure Errorsr IdentifyIssues(Coder1, Performancer1) Coder RefineImplementation(Coder1, Errorsr) end for return Coder Error Analysis. The error identification procedure categorizes implementation issues into distinct types: Logical errors: Incorrect algorithm implementation Numerical instability: Gradient explosion/vanishing Memory inefficiency: Excessive resource consumption Performance bottlenecks: Suboptimal computational paths Biological implausibility: Violations of domain constraints Each error type triggers specialized refinement strategies that preserve the scientific integrity of the model design while improving implementation quality. Detailed Failure case analysis is presented in Appendix G. 39 D.4 Hyperparameter Configuration Our framework employs the following hyperparameter settings, determined through empirical validation on held-out scientific tasks: Table 5: Hyperparameter Configuration"
        },
        {
            "title": "Expert Discussion",
            "content": "Lmax τ ϵ 10 0.8 0.5 τ ϵ (λ1, λ2, λ3) 0.8 1 (0.3, 0.4, 0.3) D.4.1 Agentic-Retrieval hyperparameters We conducted ablations on key parameters of the Agentic Retrieval module. As shown in Table 6, increasing the retrieval budget (Lmax) improves answer quality but incurs higher token cost and latency. Score filtering and memory retrieval mechanisms contribute significantly to quality gains. Notably, while larger Lmax and stricter thresholds (τ , ϵ) can slightly improve answer quality, they introduce significantly higher computational cost. The incorporation of memory-based retrieval and score-based filtering mechanisms plays key role in maximizing answer informativeness while maintaining reasonable token cost, demonstrating the importance of adaptive and context-aware retrieval strategies. The chosen default setting achieves the best balance between informativeness and efficiency. Table 6: Ablation study on Agentic Retrieval configuration. The default uses Lmax = 10, τ = 0.8, ϵ = 0.5, with memory-based adaptive retrieval and score filtering. Increasing Lmax improves information coverage but raises cost. Strict τ and ϵ improve precision but reduce flexibility. Score filtering and memory retrieval notably improve quality-to-cost ratio. Setting Default (ours) Smaller Lmax Smaller Lmax Larger Lmax Larger Lmax Higher τ threshold Lower τ threshold Stricter ϵ Looser ϵ Lmax 8 5 12 15 10 10 10 10 τ 0.8 0.8 0.8 0.8 0.8 0.9 0.7 0.8 0.8 ϵ 0. 0.5 0.5 0.5 0.5 0.5 0.5 0.2 0.8 Answer Quality Avg Time (s) Token Cost (x) 87.3 83.1 83.0 88.2 88.9 89.1 80.5 87.9 82.6 31. 24.7 20.4 45.6 70.6 35.0 24.1 35.5 28.6 1.00x 0.85x 0.68x 1.42x 2.06x 1.27x 0.90x 1.45x 0.82x D.4.2 Graph-based discussion hyperparameters These parameters balance convergence speed with solution quality across different perturbation types and dataset characteristics. We observed that the Expert Discussion module particularly benefits from higher weight on Critic Agent evaluation (λ2), which promotes more rigorous scientific validation. The analysis in Table 7 demonstrates that stricter stopping conditions (e.g., higher τ or lower ϵ) lead to more rounds of discussion with higher average confidence scores, but at the expense of increased token cost. Therefore, our selected configuration (τ = 0.8, ϵ = 0.03) provides favorable trade-off, ensuring both convergence and cost-effectiveness across diverse scientific tasks. As shown in Table 8, ablations on the confidence update mechanism reveal that the critic agent evaluation (λ2) contributes most significantly to performance. 40 Table 7: Ablation study on stopping criteria τ and ϵ in the graph-based discussion. Baseline uses τ = 0.8, ϵ = 0.05. Reducing ϵ enforces stricter agreement, and increasing τ demands higher proposal quality, both of which incur additional cost. Setting Token Cost (x) Avg Rounds Avg Score τ ϵ Default (ours) 0.8 Stricter τ Looser τ Very strict τ Stricter ϵ Very strict ϵ Looser ϵ Very Loose ϵ 0.85 0.75 0.90 0.8 0.8 0.8 0.8 0.03 0.03 0.03 0.03 0.02 0.01 0.04 0.05 4. 5.2 3.5 6.3 6.5 8.1 3.8 3.4 85.8 89.6 82.9 89.9 89.2 89.4 87.2 82.1 1.00x 1.36x 0.82x 1.65x 1.72x 2.15x 0.78x 0.71x Table 8: Ablation study on the confidence score update components with τ = 0.8, ϵ = 1. The full model uses (λ1, λ2, λ3) = (0.3, 0.4, 0.3) and serves as the baseline (1 for token cost). Average rounds, confidence scores, time, and token costs are the average scores of five runs of experiments. The table shows that our parameter selection is optimal in terms of time, token cost, and effectiveness. Setting Default (ours) larger λ2 smaller λ2 λ3 > λ1 λ3 > λ1 λ3 < λ1 λ3 < λ1 No Historical Memory No Critic Agent Evaluation No Peer Feedback Peer-Only (No Memory, No SC) Critic Agent Only λ1 0.3 0.2 0.4 0.2 0.1 0.4 0.5 0.0 0.5 0.5 0.0 0.0 λ2 0.4 0.6 0.2 0.4 0.4 0.4 0.4 0.5 0.0 0.5 0.0 1.0 λ3 Rounds Avg Score Avg Time Token Cost(x) 0.3 1.00x 88.8 36.1 4.2 0.2 0.4 0.4 0.5 0.2 0.1 0.5 0.5 0.0 1.0 0.0 6.8 4.0 4.2 4.2 4.0 4.0 3.8 2.2 4.0 7.0 4.0 89.4 86.0 88.0 87.4 87.8 87.0 85.2 85.0 85.2 86.0 86. 69.5 34.4 40.1 41.4 35.0 34.4 30.1 25.8 28.1 124.5 33.6 2.53x 0.97x 1.11x 1.32x 1.20x 1.35x 0.75x 0.77x 0.82x 3.15x 0.65x Interestingly, peer-only and critic-only settings each show limitations in stability or generalization. These findings support the necessity of integrating diverse feedback signals in our confidence update formulation."
        },
        {
            "title": "E Agent Communication Protocol Details",
            "content": "E.1 Protocol Design and Comparison The CELLFORGE protocol represents an advancement in agent communication architectures designed specifically for scientific discovery. Figure 4 illustrates the multi-stage protocol that facilitates information exchange across the three core phases of our framework. The protocol weaves together the strengths of several prior designs. It preserves the interoperability of JSON-RPC for rapid agent deployment and cross-platform compatibility while simultaneously extending this foundation with semantic connectivity and provenance via the memory module. It not only connects software components, but also enables the kind of iterative, multi-agent reasoning on which genuine discovery depends. The CellForge protocol method allows agents to coordinate autonomously when tasked with comprehensive scientific research. Table 9 provides detailed comparison of CELLFORGE with existing agent communication protocols. Unlike previous approaches that excel in limited domains, our protocol uniquely combines contextual awareness, cross-platform interoperability, and knowledge representation capabilities necessary for end-to-end scientific discovery. Table 9: Comparison of Agent Communication Protocols Protocol Context Interop. Msg. Struct. Use Cases MCP (Anthropic) Agent2Agent (Google) ACP (BeeAI/IBM) CellForge JSON-RPC only JSON-RPC event RESTful Tool Use & Data Access Cross-agent Collaboration Local Orchestration JSON-RPC event + Memory Module End-to-end Scientific Discovery E.2 Protocol Implementation Details The CELLFORGE protocol implementation consists of two primary components: JSON-RPC Communication Layer This provides standardized message passing between agents, with extensions for asynchronous event handling. Each agent exposes consistent API that accepts and returns structured data, enabling precise coordination of complex workflows. Memory Module Integration Layer In addition to graphbased message passing, CellForge incorporates persistent memory module that systematically records all salient research entitiessuch as datasets, analytical methods, evaluation metrics and empirical resultsas well as the complex relationships among them. This module also logs detailed provenance metadata, including confidence scores, reasoning chains and source citations, while embedding domainspecific knowledge (for example, regulatory pathway architectures and genegene interaction networks). By unifying these components within single memory layer, the system can reference prior insights and maintain continuity across multiround discussions, thereby enhancing both the coherence and reproducibility of the model design process. This approach provides several advantages compared to prior protocols: 1. Context-awareness: Agents maintain awareness of the overall research state through the memory module, enabling them to make more informed decisions. 2. Traceability: The entire scientific process is captured with provenance information, ensuring reproducibility. 3. Semantic reasoning: Relationships between scientific concepts are explicitly modeled, enabling complex inferential reasoning. 4. Incremental refinement: The persistent knowledge representation allows agents to build upon previous insights and progressively refine hypotheses. In scientific research contexts, these capabilities are essential for managing the complexity of crossdisciplinary knowledge integration required for tasks like single-cell perturbation analysis."
        },
        {
            "title": "F Cost Analysis",
            "content": "Understanding the computational and economic costs of CELLFORGE is crucial for assessing its practical viability in research settings. This section provides comprehensive analysis of both infrastructure requirements and API utilization costs, enabling researchers to make informed decisions about deployment strategies. F.1 Training Infrastructure All models designed by CELLFORGE, with parameter counts ranging from 10 million to 30 million, were trained and evaluated on uniform compute cluster to ensure consistent performance comparisons. In particular, we utilized two NVIDIA H20NVLink GPUs (96 GB VRAM each, 192GB total) paired with 16core AMD EPYC 9K84 CPU (2.6 GHz). This hardware configuration enabled stable multiGPU training via data parallelismsupporting larger batch sizesand facilitated distributed evaluation across diverse perturbation conditions, all without encountering memory bottlenecks. F.2 Token Utilization and Cost Estimation The multi-agent nature of CELLFORGE involves extensive LLM interactions across three primary phases: Task Analysis, Method Design, and Experiment Execution. Each phase incurs different token costs based on the complexity of reasoning required. F.2.1 Token Usage Breakdown by Phase The specific token usage varies significantly based on task complexity. Our empirical analysis across over 50 requests of CellForge, revealed the following patterns: Table 10: Token usage breakdown by framework phase and task complexity"
        },
        {
            "title": "Task Analysis\nMethod Design\nExperiment Execution",
            "content": "15,000 20,000 5,000 50,000 100,000 50,000 25,000 40,000 15,000 100,000 200,000 100,"
        },
        {
            "title": "Total",
            "content": "40,000 200,000 80,000 400,000 Under our typical workload, approximately 60,000 prompt tokens and 300,000 completion tokens are cost per call, depending on the chosen task. For cost estimation purposes, we will use this approximation token cost in the following analysis. F.2.2 Per-Request Cost Calculation To quantify the expense of our multiagent workflow, we first aggregated token counts from over fifty runs of CellForge and organized them by framework phase (Task Analysis, Method Design, Experiment Execution). For each model under consideration,we applied the vendors published permilliontoken rates to both prompt and completion usage. Concretely, given that vendors report token pricing per million tokens ($/M), the cost per request was computed using: (cid:19) (cid:19) Costrequest = Priceprompt + Pricecompletion (cid:18) 300,000 (cid:18) 60,000 106 F.3 Cost-Effectiveness Analysis Compared to manual workflows, CELLFORGE reduces what would ordinarily require 40-80hours of skilled bioinformatician (at $75-150/hour, i.e. $3,000-12,000 per model) to an automated process costing only $5-20 per run. 43 Table 11: Per-million-token pricing and per-call cost estimates based on average usage (60K input and 300K output tokens)"
        },
        {
            "title": "Model",
            "content": "Prompt ($/M) Completion ($/M) Cost per Request ($) Claude 3.7 (Anthropic) OpenAI o1 DeepSeek-R1 Qwen-Plus LLaMA 3."
        },
        {
            "title": "Average",
            "content": "3.00 15.00 0.27 0.40 3.50 15.00 60.00 2.19 1.20 3.50 4.68 18.90 0.67 0.38 1.26 5. Beyond raw cost savings, CELLFORGE affords efficiency and reproducibility gains. What would have occupied 40-80hours of expert labor now completes in 4-8hours of GPU time, while yielding up to 20% improvement in prediction accuracy over baseline methods. Collectively, these factors translate into compelling return on investment, democratizing advanced computational biology at fraction of traditional costs."
        },
        {
            "title": "G Failure Case Analyses",
            "content": "In this section, we analyze common failure modes of CELLFORGE across various single-cell perturbation tasks. We manually reviewed 20 randomly selected failed experiment cases generated by CELLFORGE across cytokine, drug, and gene response prediction scenarios. Based on qualitative inspection of agent behaviors and outputs, we identified seven distinct categories of failure modes that reflect systematic limitations or reasoning errors. Table 12 summarizes the definitions and characteristics of these failure categories. These cases provide foundation for future refinements of the agentic code generation. Table 12: Failure Types of CELLFORGE code generation Failure Type Definition & Examples Model Configuration Error Computation Execution Error Invalid Type or Operation Data Access Failure Error Recovery Failure Hallucination Other The agent misconfigures the model architecture or fails to define required hyperparameters. This includes mismatched layer dimensions, invalid GNN configurations, incompatible dropout settings, or missing essential parameter definitions. Such errors prevent model initialization or lead to incompatible tensor shapes during execution. The agent encounters runtime errors during tensor operations, such as out-ofbounds indexing or shape mismatch in matrix multiplication. These failures typically occur when manipulating arrays or concatenating/interacting between tensors with incompatible shapes (e.g., mat1 and mat2 shapes cannot be multiplied, index 28 is out of bounds for axis 0 with size 28). The agent uses unsupported data types or operations incompatible with the backend framework. Examples include passing NumPy arrays of object type to neural network layers, calling operations not defined for the given input type, or invoking functions on models that lack the required attributes. Typical errors include TypeError: cant convert np.ndarray of type numpy.object and unsupported function calls. The agent is unable to retrieve, preprocess, or interpret the necessary data for task execution. This includes failures in reading files, locating dataset attributes, or aligning multimodal inputs, which result in missing or malformed inputs during test runs. The agent fails to handle or recover from previously encountered errors. Instead of adapting to execution failures, it may enter loop of repeating the same failed actions or ignore the cause entirely, leading to stalled or redundant test attempts. The agent produces outputs (e.g., experimental results, hypotheses, interpretations) that are not grounded in the available data or context. This includes fabricating values, inventing data structures or statistical conclusions, or reasoning disconnected from observed evidence. Any uncategorized failure mode that prevents successful task completion but does not fit the above definitions. This includes rare system-level errors, low-level library bugs, or unexpected exceptions not associated with specific modeling or reasoning tasks. As depicted in Figure 12, Computation Execution Error accounts for 41% of the total failures, with the majority arising from tensor operation issues such as out-of-bounds indexing or shape mismatch during matrix multiplication. Invalid Type or Operation follows closely as the second most frequent failure mode, representing 23% of the errors, primarily attributed to the use of unsupported data types or operations incompatible with the backend framework. Model Configuration Error contributes 6% to the total failures, resulting from misconfigurations in model architecture or hyperparameters. Data Access Failure and Other category each account for 5% of the errors, with Data Access Failure associated with data retrieval and preprocessing issues, and Other encompassing system-level errors or unexpected exceptions not directly linked to the specific modeling or reasoning tasks. Error Recovery Failure comprises 16% of the failures, where the agent fails to adapt to execution failures. Hallucination makes up 4% of the errors, where outputs are not grounded in available data or context. Notably, we found that implementing code to print array or matrix shapes can aid CELLFORGE in subsequently reading the command regions output for modification, thereby enhancing their ability to identify and resolve shape-related issues during tensor operations. This approach proved 45 Figure 12: Failure Mode Distribution for CellForge, labeled automatically by O1 and manually checked by humans. particularly effective given the complexity of data processing workflows in CellForge. Even though CELLFORGE utilizes data parser to obtain the original dataset dimensions and incorporates data experts during the graph-based discussion phase, the subsequent data splitting and complex model processing steps often introduce intricate dimension transformations. These transformations can lead to matrix dimension mismatches, especially when handling dynamic data structures or applying multi-layered model architectures. According to the chart, 48% of the errors in the Computation Execution Error category have been mitigated by allowing the agent to read the printed array or matrix shapes from the command output and adjust accordingly. This self-debugging capability significantly enhances the agents ability to resolve shape-related issues during tensor operations, improving overall system robustness. Figure 13 provides an example of the printed data shapes during tensor operations, which CELLFORGE can utilize to dynamically adjust and correct dimension mismatches. Figure 13: probable example of printing array or matrix shapes . 46 LLM-as-a-judge details H.1 methods To assess the quality of task analysis reports and research plans generated by various CellForge, we employed Large Language Model (LLM) as an automated evaluator. Outputs(Examples can be found in Appendix Q) from CellForge(employing five different LLM API configurations: Claude 3.7, o1, DeepSeek R1, Qwen-plus, Llama 3,1 with temperature=0.7, top-p=0.95) were anonymized to prevent bias. For each evaluation round, set of 8 outputs was randomly selected and their order was randomized to ensure fairness. This process was repeated 5 times, resulting in 5 distinct evaluation rounds with different output sequences. In each round, the LLM evaluated the eight outputs individually, assigning score from 1 to 10 based on predefined criteria. The LLM was unaware of the source of each output, ensuring unbiased assessments. The LLM was guided using structured prompt that specified the evaluation criteria and scoring rubric. An example prompt is as follows. H.2 prompts LLM As Judge-Gene"
        },
        {
            "title": "Task Analysis",
            "content": "You are an expert evaluator specializing in data-driven analysis of CRISPR-based single-cell perturbation experiments. Your background includes: - In-depth knowledge of single-cell omics data modalities (e.g., RNA-seq, ATAC-seq, CITE-seq) - Experience in characterizing perturbation types and experimental settings - Familiarity with agent-based literature retrieval and scientific reasoning - Ability to assess baseline model performance in biological prediction tasks - Understanding of automated systems for scientific task decomposition Please evaluate the following Task Analysis report using rigorous and objective scientific standards. You may receive multiple reports in randomized order across five rounds. ** Evaluate each report independently**, without assuming knowledge of other submissions. EVALUATION CRITERIA Each criterion should be scored on scale of 110, with clear justification based on the report content. Use full-score ranges (110) where appropriate. 1. Analyse Dataset (110): - Clarity and correctness in summarizing dataset properties ( modality, perturbation type, species, cell type distribution, etc.) - Relevance of identified features for downstream modeling - Ability to standardize and interpret metadata across modalities - Quality of data summaries and diagnostic insights (e.g., sparsity, heterogeneity) 2. Analyse Task Type (110): - Accuracy in identifying the biological question and mapping it to computational prediction task - Insightfulness in selecting the right task framing (e.g., classification vs regression, single-cell vs populationlevel) - Alignment of task framing with perturbation mechanism and data granularity 47 - Ability to distinguish this task from superficially similar ones 3. Analyse Baseline Defects (110): - Thoroughness in identifying limitations of current baseline models - Correctness in linking model weaknesses to data/task-specific challenges (e.g., model mismatch with modality, lack of interpretability) - Thoughtfulness in proposing key evaluation gaps or unaddressed risks - Clarity in explaining why the baseline is insufficient and what improvement directions are needed FORMAT FOR YOUR EVALUATION: 1. NUMERICAL SCORES Analyse Dataset: [Score]/10 Analyse Task Type: [Score]/10 Analyse Baseline Defects: [Score]/10 2. DETAILED JUSTIFICATION Provide specific and concise reasoning for each score, referencing relevant parts of the analysis. Address both strengths and limitations within each criterion. 3. KEY STRENGTHS [List major strengths of the Task Analysis report] [Reference specific elements that demonstrate scientific rigor or originality] 4. AREAS FOR IMPROVEMENT [Identify specific aspects that could be clarified or strengthened] [Offer constructive, actionable suggestions for refinement] 5. OVERALL RECOMMENDATION Provide concise overall assessment. Consider: - Does the Task Analysis provide strong foundation for followup modeling? - Are the dataset and task features well-characterized and actionable? - Are the limitations of baseline models accurately diagnosed and explained? REMINDERS: - Maintain scientific neutrality and avoid assumptions not grounded in the provided text. - Consider both biological and computational aspects equally. - Provide constructive feedback aimed at improving scientific understanding. - Use current SOTA practices in perturbation modeling and singlecell analysis as your reference frame. - Assume the audience is mix of computational biologists, experimentalists, and system developers. TASK ANALYSIS REPORT TO EVALUATE: [Paste your report here] / [Will be provided in the next message ] LLM As Judge-Gene"
        },
        {
            "title": "Method Design",
            "content": "You are an expert evaluator specializing in CRISPR-based singlecell perturbation prediction models and experimental designs. Your background includes: - Deep expertise in computational biology and single-cell omics - Practical experience with CRISPR-based perturbation experiments 48 - Familiarity with multimodal single-cell datasets (e.g., gene expression, ATAC-seq, protein expression) - Advanced understanding of machine learning models for biological prediction tasks - Knowledge of statistical validation methods and experimental reproducibility standards - Awareness of recent state-of-the-art (SOTA) approaches in perturbation modeling Please evaluate the following research plan using rigorous and objective scientific standards. You may receive multiple plans in randomized order across five rounds. **Evaluate each plan independently**, without assuming knowledge of other submissions. EVALUATION CRITERIA Each criterion should be scored on scale of 110, with clear justification based on the content of the plan. Use fullscore ranges (110) where appropriate. 1. Scientific Validity (110): - Biological relevance and mechanistic insight - Strength of theoretical foundation - Alignment with current scientific understanding in single-cell biology Integration with existing knowledge on perturbation responses 2. Technical Feasibility (110): - Practicality of implementation - Computational resource requirements - Scalability to larger datasets or new tasks - Feasibility and clarity of data preprocessing or modeling pipeline 3. Innovation Level (110): - Novelty compared to current state-of-the-art approaches - Creative problem-solving or hypothesis generation - Potential for new biological or computational insights - Unique contributions in methodology or design 4. Experimental Design (110): - Quality of proposed validation and evaluation methodology - Inclusion of appropriate controls and baselines - Statistical soundness (e.g., replicates, robustness) - Attention to data quality and reproducibility 5. Impact Potential (110): - Relevance and contribution to advancing single-cell biology - Translational potential (e.g., drug discovery, therapeutic design) - Scalability to broader biological questions or contexts - Potential to inspire follow-up research or community adoption FORMAT FOR YOUR EVALUATION: 1. NUMERICAL SCORES Scientific Validity: [Score]/10 Technical Feasibility: [Score]/10 Innovation Level: [Score]/10 Experimental Design: [Score]/10 Impact Potential: [Score]/10 2. DETAILED JUSTIFICATION Provide specific and concise reasoning for each score, referencing relevant parts of the research plan. Address both strengths and limitations within each criterion. 3. KEY STRENGTHS [List major strengths of the research plan] [Reference specific elements that demonstrate scientific merit or originality] 49 4. AREAS FOR IMPROVEMENT [Identify specific aspects that could be clarified or strengthened] [Offer constructive, actionable suggestions for refinement] 5. OVERALL RECOMMENDATION Provide concise overall assessment. Consider: - Is this plan strong candidate for further development or implementation? - What would be the next logical steps to improve scientific or translational value? - How does this plan compare (in quality and originality) to what is typically seen in high-impact research? Additional Considerations for Gene Knockout: - Gene regulatory network modeling - Knockout effect propagation - Compensatory mechanism prediction - Pathway analysis integration REMINDERS: - Maintain scientific neutrality and avoid assumptions not grounded in the provided text. - Consider both biological and computational aspects equally. - Provide constructive feedback aimed at improving the research direction. - Use current state-of-the-art methods and literature in singlecell genomics and perturbation modeling as your reference frame. - Assume the audience is mix of computational biologists, experimentalists, and translational researchers. RESEARCH PLAN TO EVALUATE: [Paste your plan here] / [Will be provided in the next message] 50 H.3 example output LLM As Judge Output-Gene Task Analysis-Claude 3.7 1. NUMERICAL SCORES Analyse Dataset: 8/10 Analyse Task Type: 8/10 Analyse Baseline Defects: 8/10 2. DETAILED JUSTIFICATION Analyse Dataset (8/10) The report provides comprehensive and detailed summary of the dataset properties, including its origin (Norman et al., 2019), modality (single-cell RNA-seq with CRISPR perturbations), and specific features like the scale (170,000 cells), composition (1,092 unique perturbation conditions), and high-dimensional readouts (20,000 genes per cell). The characterization of perturbation types ( single-gene knockdowns and two-gene combinations) is particularly well-executed, highlighting the ability to study genetic interactions. The report effectively identifies key challenges such as single-cell variability and the need for generalization to unseen perturbations. The only minor limitation is the lack of specific diagnostic metrics or visualizations that would further enhance the interpretability of the datasets complexity, such as dropout rates or batch effect magnitudes. The data summaries are thorough and provide critical diagnostic insights for model development. Analyse Task Type (8/10) The biological question is accurately identified as learning high-dimensional function to predict post-perturbation gene expression profiles. The mapping to computational prediction task (high-dimensional regression with combinatorial inputs) is insightful and aligns well with the datasets granularity and the nature of CRISPR perturbations. The justification for selecting this task type is robust, emphasizing the biological relevance of understanding genetic interactions and predicting cellular responses to novel perturbations. The report effectively distinguishes this task from alternative framings by highlighting the unique challenges of handling single-cell variability, generalization to unseen perturbations, and the need for complex model architecture. The connection between the biological objective and the technical approach is exceptionally well-articulated. The only minor limitation is brief discussion of alternative task formulations that could have strengthened the rationale further. Analyse Baseline Defects (8/10) The report thoroughly identifies several limitations of current baseline models with exceptional specificity. For example, it correctly highlights the challenge of generalization to unseen perturbations, including new target genes and gene combinations, as critical weakness. The critique of simpler, interpretable models (like linear regression) for their inability to capture non-linear genetic interactions is particularly well-supported. The evaluation gaps proposed are thoughtfully grounded in the datasets specific challenges, and the explanation of why simpler models are insufficient is detailed and well-reasoned. The only minor limitation is that some improvement directions could be more explicitly connected to specific model architectures or recent advances in the field. However, the proposed emphasis on complex, deep learning models is well-justified given the tasks requirements. 51 3. KEY STRENGTHS Comprehensive Dataset Characterization: The report provides exceptional documentation of dataset properties, perturbation types, and specific challenges, creating solid foundation for model development. Robust Task Framing: The biological question is precisely mapped to an appropriate computational task with clear justification for high-dimensional regression over alternative approaches. Detailed Challenge Analysis: The analysis of modeling challenges is exceptionally thorough, with specific critiques that highlight both the complexity of the task and the limitations of simpler models in addressing it. Forward-Looking Model Selection: The rationale for prioritizing predictive accuracy and employing complex models demonstrates sophisticated understanding of the trade-offs between model complexity and interpretability in this domain. 4. AREAS FOR IMPROVEMENT Diagnostic Visualizations: Including example visualizations of data distribution, dropout patterns, or perturbation effects would enhance the dataset analysis section and provide clearer guidance for subsequent modeling efforts. Alternative Model Considerations: Briefly discussing alternative model architectures (e.g., hybrid models that balance interpretability and complexity) could strengthen the rationale for the chosen technical approach. Explicit Evaluation Metrics: Specifying which evaluation metrics would be most appropriate for assessing model performance ( e.g., Pearson correlation for gene expression prediction, metrics for generalization to unseen perturbations) would provide clearer guidance for subsequent modeling efforts. 5. OVERALL RECOMMENDATION This Task Analysis report provides an exceptionally strong foundation for follow-up modeling efforts. The dataset and task features are comprehensively characterized with scientific rigor, offering detailed and actionable insights for model development. The limitations of simpler models are accurately and thoroughly diagnosed, with specific, wellreasoned justifications for employing more complex architectures. This analysis demonstrates sophisticated understanding of both biological and computational aspects, aligning exceptionally well with current state-of-the-art practices in CRISPR-based single-cell perturbation modeling. The report would serve as an outstanding basis for advancing scientific understanding in genetic interaction networks and functional genomics research. With minor refinements in the areas noted, this analysis could be considered model example of task analysis in this domain. LLM As Judge Output-Gene Method Design-Claude 3.7 1.NUMERICAL SCORES Scientific Validity: 8/10 Technical Feasibility: 8/10 Innovation Level: 7/10 Experimental Design: 7/10 Impact Potential: 8/10 2.DETAILED JUSTIFICATION Scientific Validity (8/10) The research plan demonstrates strong biological relevance by addressing the challenge of predicting post-perturbation gene expression profiles in single cells, critical area in understanding gene regulatory networks and cellular 52 responses to CRISPR-based interventions. The integration of VAE, GNN, and Transformer components provides theoretically sound foundation for handling the complexity of single-cell data. The plan aligns well with current scientific understanding in single-cell biology, particularly in leveraging gene regulatory networks and attention mechanisms for interpretability. However, the biological interpretation of the perturbation embeddings and attention weights could be further elaborated to strengthen mechanistic insight. Technical Feasibility (8/10) The proposed pipeline is practical and well-detailed, with clear steps for data preprocessing, model architecture, and training strategy. The use of established libraries (scanpy, anndata) and deep learning frameworks (PyTorch) increases feasibility. The computational resource requirements appear manageable, though training hybrid model with GNN and Transformer components may demand substantial GPU memory. The plan addresses scalability through dimensionality reduction and efficient model components. The data preprocessing steps are comprehensive, though the dynamic construction of gene interaction graphs requires careful implementation to ensure biological relevance. Innovation Level (7/10) The hybrid model architecture combining VAE, GNN, and Transformer represents novel approach in the field of single-cell perturbation prediction. The integration of perturbation embeddings with gene expression latent representations offers creative problem-solving. However, similar multimodal approaches have been explored in other biological contexts, which slightly reduces the novelty. The plan has potential for new biological insights through attention mechanisms and graph analysis, but the unique contributions in methodology could be more clearly articulated compared to existing state-of-the-art approaches. Experimental Design (7/10) The validation methodology includes appropriate loss functions, regularization techniques, and early stopping criteria, ensuring statistical soundness. The inclusion of control samples and data augmentation techniques strengthens the experimental design. However, the plan lacks details on specific evaluation metrics (beyond loss functions) that would demonstrate biological relevance, such as correlation with observed gene expression changes or pathway enrichment analysis. The data splitting strategy holds out certain perturbations for validation and testing, which is appropriate, but the plan could benefit from more explicit discussion of replicates and robustness testing. Impact Potential (8/10) The research has significant relevance to advancing single-cell biology by providing predictive tool for CRISPR perturbations. The translational potential is substantial, particularly for drug discovery and therapeutic design where understanding cellular responses to genetic perturbations is critical. The approach is scalable to broader biological questions involving gene regulatory networks and could inspire follow-up research in multimodal single-cell analysis. The potential for community adoption is enhanced by the use of standard frameworks and the provision of biological interpretability features. 3. KEY STRENGTHS Comprehensive integration of VAE, GNN, and Transformer components addressing different aspects of single-cell data complexity 53 Well-structured training strategy with regularization techniques to prevent overfitting Attention to biological interpretability through multiple model components Practical data preprocessing pipeline using established singlecell tools Incorporation of expert recommendations for addressing class imbalance and improving generalization 4. AREAS FOR IMPROVEMENT Enhance discussion of biological validation metrics beyond loss functions Provide more explicit details on gene regulatory network construction and updating Strengthen justification for the specific dimensions chosen for latent spaces and embeddings Consider inclusion of additional evaluation strategies such as cross-dataset validation Clarify how the model will handle novel cell types or contexts not present in training data 5.OVERALL RECOMMENDATION This research plan represents strong candidate for further development with high potential for scientific impact in single-cell perturbation prediction. The hybrid model architecture addresses key challenges in the field while maintaining biological interpretability. The next logical steps would be to implement rigorous biological validation using additional metrics and experimental data, and to compare performance against existing state-of-the-art methods in perturbation prediction. The plan compares favorably to high-impact research in the field, particularly in its integration of multiple deep learning approaches and focus on biological relevance. 54 H.4 Detailed Results To comprehensively evaluate the performance of CELLFORGE, we employed five state-of-the-art LLMs as independent judges: Claude 3.7, DeepSeek-R1, OpenAI o1, Qwen-plus, and Llama 3.1. Each judge evaluated outputs from CELLFORGE and three DeepResearch variants (OpenAI, Perplexity, and Gemini) across multiple rounds to ensure statistical robustness. Tables 13 and 14 present the averaged scores from five independent evaluation runs, providing insights into both the consistency and performance differences across systems. H.4.1 Task Analysis Phase Evaluation Table 13 reveals several key insights about the Task Analysis capabilities of different systems. CELLFORGE demonstrates consistent superiority across all three evaluation dimensions, with particularly strong performance in Analyse Dataset (average scores: 8.60, 8.20, 7.24 across drug, gene knockout, and cytokine tasks respectively). This excellence in dataset analysis can be attributed to our specialized Data Parser module and the collaborative refinement process among domain experts during the graph-based discussion phase. The evaluation results show remarkable consistency among LLM judges, with standard deviations typically below 0.5 points, indicating high inter-judge agreement. Notably, Claude 3.7 and OpenAI o1 tend to provide slightly higher scores overall, while Qwen-plus and Llama 3.1 exhibit more conservative scoring patterns. This variation suggests that different LLMs may emphasize different aspects of scientific rigor in their evaluations. Among the DeepResearch variants, OpenAIs implementation (DRO) performs closest to CELLFORGE, achieving comparable scores in certain categories (e.g., 9.0 in drug dataset analysis). However, other methods show significant performance gaps, particularly in Analyse Baseline Defects, where scores drop as low as 2.16 for cytokine tasks. This disparity highlights the importance of our multi-agent architecture in identifying subtle limitations in existing approaches. Edit table 11 12 and caption Table 13: LLM evaluation of the Task Analysis phase. Three LLM judges evaluated CELLFORGE (CF) ,three DeepResearch (DR) [93] pipeline(O: OpenAI, P: Perplexity, G: Gemini), Biology Research Agent Biomni[57], and single LLM (CLD: Claude 3.7 API, which performs the best in our task compared with R1, o1, Qwen-plus, and Llama3.1) across four key capabilities and three perturbation types. CELLFORGE consistently matched or exceeded human expert performance, with particular strength in dataset analysis and identifying baseline model limitations. Judges Drug Gene KO Cytokine CF DRO DRP DRG Biomni CLD CF DRO DRP DRG Biomni CLD CF DRO DRP DRG Biomni CLD Analyse Dataset Claude3.7 R1 o1 Qwen-plus Llama 3.1 8.8 9.0 9.0 8.0 8. 9.0 9.0 9.0 7.2 7.4 6.0 6.2 6.0 5.2 5.2 7.0 7.0 6.8 6.2 5.8 8.8 8.2 7.0 7.2 6.8 6.0 5.0 5.8 5.0 6.0 8.0 8.0 8.2 8.0 8. 7.0 7.2 7.8 7.0 6.8 3.0 4.0 4.4 4.0 5.0 5.2 6.2 6.0 5.4 6.2 8.0 7.4 7.6 7.4 7.0 6.2 5.0 5.2 5.2 6.0 7.2 7.0 7.2 7.0 7. 7.0 6.2 6.0 6.8 7.2 4.0 3.2 3.0 2.8 4.0 5.2 5.6 5.2 6.0 6.0 7.0 7.0 6.2 6.0 7.2 5.4 4.2 4.8 5.0 5.0 Average 8.60 8.32 5.72 6.56 7.60 5. 8.20 7.16 4.08 5.80 7.48 5. 7.24 6.64 3.40 5.60 6.68 4. Analyse Task Type Claude3.7 R1 o1 Qwen-plus Llama 3.1 8.0 7.0 8.6 8.0 8.2 7.8 7.0 8.2 8.0 7.6 6.0 4.0 6.0 6.2 6.2 5.0 6.0 6.6 6.2 6. 8.0 7.0 8.0 8.2 8.0 6.0 5.0 5.0 5.8 6.0 8.4 7.8 8.8 8.2 8.8 8.0 7.0 8.0 8.0 8.0 6.0 6.0 6.0 7.0 6.0 6.8 7.0 6.0 7.4 7. 8.2 7.0 8.0 8.0 8.2 6.0 6.0 5.0 6.0 6.0 6.6 6.6 7.0 7.0 7.2 4.0 5.8 6.2 6.2 6.2 3.2 4.8 5.0 5.8 5.0 4.8 5.0 5.2 4.2 5. 8.0 6.6 7.0 7.4 7.0 6.0 4.0 4.0 5.0 4.0 Average 7.96 7.72 7. 6.20 7.84 5.56 8.40 7.80 6. 6.88 7.88 5.56 6.88 5.96 4. 4.84 7.20 4.60 Analyse Baseline Defects Claude3.7 R1 o1 Qwen-plus Llama 3.1 6.2 7.0 6.6 6.0 7. 5.0 6.0 5.8 5.2 6.2 3.0 3.6 3.0 2.2 4.0 4.2 4.2 4.0 3.2 4.8 5.6 6.0 6.0 5.0 5.0 3.8 3.2 2.8 2.0 3.0 6.8 7.0 7.2 7.0 7. 6.0 7.0 7.0 7.0 7.6 3.0 4.8 5.6 4.2 5.0 4.2 4.2 5.0 5.0 5.8 6.6 6.6 6.2 6.4 6.0 Average 6. 5.64 3.16 4.08 5.52 2.96 7. 6.92 4.52 4.84 6.36 3.0 3.0 3.0 3.0 3.0 3. 5.2 6.0 6.0 6.0 6.8 4.0 5.2 5.2 3.8 5.2 2.0 2.0 2.0 1.8 3.0 2.8 3.4 3.2 3.0 3.0 5.2 5.0 5.0 5.2 6.4 2.0 1.0 1.6 3.0 2. 6.00 4.68 2.16 3.08 5.36 1. H.4.2 Method Design Phase Evaluation Table 14 presents more nuanced evaluation across five dimensions of research plan quality. The results demonstrate CELLFORGEs comprehensive superiority, with average scores exceeding 6.0 55 across all dimensions and tasks, while DeepResearch variants show significant variability (scores ranging from 2.16 to 8.00). The Innovation Level dimension shows the most pronounced advantage for CELLFORGE, with average scores of 8.04, 8.28, and 7.44 for drug, gene knockout, and cytokine tasks, respectively. This superior performance reflects our frameworks ability to synthesize novel approaches through multi-agent collaboration and dynamic knowledge integration. Interestingly, OpenAIs DeepResearch variant shows competitive performance in this dimension (7.40, 8.00, 7.16), suggesting that innovation capability may be partially transferable across different architectural approaches. In Technical Feasibility, we observe an interesting pattern where OpenAIs DeepResearch slightly outperforms CELLFORGE in drug perturbation tasks (7.24 vs. 6.88). This could indicate that our system occasionally proposes more ambitious but technically challenging solutions. However, CELLFORGE maintains superiority in gene knockout and cytokine tasks, demonstrating better adaptability to diverse biological contexts. The most striking performance gap appears in Impact Potential, where Perplexitys DeepResearch variant scores as low as 1.8 for drug perturbation tasks. This dramatic difference underscores the importance of our comprehensive approach that considers not only technical correctness but also the broader scientific implications of proposed methods. Table 14: LLM evaluation of the Method Design phase. LLM judges assessed the quality of research plans proposed by CELLFORGE (CF) and Deep Research (DR) [93] pipeline(O: OpenAI, P: Perplexity, G: Gemini), Biology Research Agent Biomni[57], and single LLM (CLD: Claude 3.7 API, which performs the best in our task compared with R1, o1, Qwen-plus and Llama3.1) across five dimensions. CELLFORGE consistently outperformed on scientific validity, innovation, experimental design, and impact potential. Judges Drug Gene KO Cytokine CF DRO DRP DRG Biomni CLD CF DRO DRP DRG Biomni CLD CF DRO DRP DRG Biomni CLD Scientific Validity Claude3.7 R1 o1 Qwen-plus Llama 3.1 7.4 8.2 7.8 6.8 7.0 8.0 7.4 7.0 6.4 6.4 3.0 4.0 3.4 3.0 5.2 4.6 4.8 6.2 5.8 5. 7.0 7.0 7.0 6.0 6.0 3.0 3.2 2.8 3.0 3.2 7.8 7.8 8.2 7.6 7.8 7.2 7.8 8.4 6.8 6.8 3.2 4.0 3.6 4.0 5.0 5.0 6.2 6.2 5.4 6. 6.0 6.8 8.0 7.0 7.0 3.0 3.2 3.0 3.0 3.6 6.8 7.0 6.8 6.6 7.2 6.2 6.0 7.0 6.6 7.0 2.8 3.6 3.0 2.6 4.4 4.0 5.8 5.2 5.0 6. 6.4 6.0 6.2 6.0 7.0 2.2 3.0 2.8 2.0 2.8 Average 7.44 7.04 3. 5.44 6.60 3.04 7.84 7.40 3. 5.92 6.96 3.16 6.88 6.56 3. 5.20 6.32 2.56 Technical Feasibility Claude3.7 R1 o1 Qwen-plus Llama 3.1 7.0 5.8 7.4 7.0 7. 7.0 7.0 8.0 6.8 7.4 2.4 4.0 4.0 3.6 4.0 5.2 5.2 6.6 5.0 6.0 6.8 6.8 7.2 6.6 7.0 2.0 2.0 2.2 3.0 3.0 7.0 6.8 8.0 7.4 8. 5.8 6.8 7.8 5.8 6.8 2.6 5.0 5.0 3.0 4.0 5.8 6.0 6.0 6.0 5.2 6.0 6.0 8.0 7.0 8.0 2.0 2.0 2.8 2.4 3.2 6.4 6.0 7.0 6.8 6. 5.8 5.6 6.8 6.8 5.6 2.2 4.0 4.2 3.0 5.0 5.6 5.4 5.0 5.0 5.4 6.0 6.0 6.4 6.6 6.0 2.0 1.6 2.0 3.0 2.0 Average 6.88 7.24 3.60 5.60 6.88 2. 7.48 6.60 3.92 5.80 7.00 2. 6.48 6.12 3.68 5.28 6.20 2. Innovation Level Claude3.7 R1 o1 Qwen-plus Llama 3.1 8.0 8.2 8.0 7.6 8.4 7.0 6.8 8.2 7.4 7.6 5.8 4.2 6.0 4.2 5.0 6.8 4.8 5.0 5.6 6. 7.0 7.0 7.2 7.0 8.0 3.0 3.0 3.0 4.0 4.0 8.2 8.2 9.0 8.0 8.0 7.2 7.8 9.0 8.0 8.0 5.0 5.0 5.2 5.0 5.2 6.4 7.0 6.8 6.6 7. 7.0 7.0 8.0 7.2 7.6 3.0 3.0 2.8 4.0 4.2 7.2 8.0 7.6 7.2 7.2 6.2 7.4 8.0 7.0 7.2 4.0 5.0 5.0 4.0 5.0 6.0 6.2 6.0 5.2 7. 6.6 8.0 6.6 7.0 7.0 3.0 2.0 2.4 3.4 3.8 Average 8.04 7.40 5. 5.68 7.24 3.40 8.28 8.00 5. 6.76 7.36 3.40 7.44 7.16 4. 6.08 7.04 2.92 Experimental Design Claude3.7 R1 o1 Qwen-plus Llama 3.1 7.0 8.0 8.2 7.2 7. 7.2 7.2 8.4 7.0 7.2 3.2 4.0 5.0 4.2 4.2 4.4 4.0 5.2 5.8 5.0 4.2 5.2 5.2 5.2 5.4 3.0 3.0 3.2 3.2 4.0 7.0 7.2 7.2 7.8 7. 6.0 6.0 7.0 5.0 6.2 2.0 2.8 3.0 2.0 4.0 4.4 4.2 4.8 4.0 5.0 4.6 5.0 4.8 5.2 6.8 2.2 2.0 3.0 2.0 3.6 6.0 6.4 6.8 6.0 6. 5.8 6.0 6.8 5.0 6.0 2.2 3.0 3.4 2.4 4.0 4.0 4.0 4.0 4.0 5.0 4.2 4.4 4.0 4.2 5.2 2.0 1.0 3.2 2.0 3.4 Average 7.64 7.40 4.12 4.88 5.04 3. 7.28 6.04 2.76 4.48 5.28 2. 6.40 5.92 3.00 4.20 4.40 2. Impact Potential Claude3.7 R1 o1 Qwen-plus Llama 3.1 6.0 7.0 7.2 7.2 7.4 5.0 6.0 7.0 6.0 7.0 1.8 2.2 3.2 2.0 4.0 3.0 4.0 4.8 3.2 4. 4.4 4.0 6.8 5.8 6.0 2.0 1.8 1.8 2.2 3.2 6.8 7.2 4.0 6.0 7.0 5.2 6.0 7.0 5.6 6.8 2.8 2.2 6.0 2.4 5.8 4.0 4.2 3.0 6.0 4. 5.8 4.8 5.2 5.2 6.0 3.0 2.0 2.0 2.2 4.0 6.0 6.2 6.6 6.2 6.8 5.2 5.0 6.0 5.2 5.8 3.8 2.2 2.2 2.0 4.0 4.4 4.0 4.0 4.0 5. 4.6 5.0 4.8 5.0 6.0 2.0 2.0 1.8 2.0 4.0 Average 6.96 6.20 2. 3.96 5.40 2.20 6.20 6.12 3. 4.24 5.40 2.64 6.36 5.44 2. 4.28 5.08 2.36 56 H.4.3 Cross-Task Performance Analysis An interesting pattern emerges when comparing performance across different perturbation types. Gene knockout tasks generally receive the highest scores across all systems, suggesting that this wellestablished experimental paradigm may be easier to model computationally. In contrast, cytokine perturbation tasks show the greatest performance variance between systems, with CELLFORGE maintaining robust performance (average scores above 6.0) while some DeepResearch variants drop below 3.0 in multiple dimensions. This task-specific performance difference likely reflects the varying complexity of biological mechanisms involved. Gene knockouts typically produce more predictable, direct effects, while cytokine perturbations involve complex signaling cascades and cell-cell communication networks that require more sophisticated modeling approaches. The superior performance of CELLFORGE in these challenging scenarios validates our multi-agent architectures ability to capture complex biological interactions through collaborative reasoning. H.4.4 Inter-Judge Agreement and Reliability The consistency of scores across different LLM judges provides confidence in our evaluation methodology. The highest agreement occurs in the Innovation Level dimension, where judges show remarkable consensus (coefficient of variation 0.1 for most comparisons). Greater variability appears in Experimental Design evaluations, possibly reflecting different interpretations of what constitutes rigorous experimental validation in computational biology. These detailed results collectively demonstrate that CELLFORGE not only achieves superior performance but does so consistently across different evaluation criteria, task types, and independent judges. The frameworks ability to maintain high standards across all dimensionsfrom technical feasibility to scientific impactunderscores its potential as comprehensive solution for automated scientific discovery in single-cell biology. Human scientists evaluation details I.1 methods To assess the scientific quality of AI-generated analysis and design outputs, we conducted blind human evaluation involving three expert single-cell biologists. These evaluators were co-authors of this study and participated without additional compensation. Each expert independently reviewed and scored system outputs for approximately 10 hours, covering both the Task Analysis Module, the Method Design Module, and the confidence score in Graph-based discussion across cytokine, drug, and gene perturbation tasks. For each task type(cytokine, drug, gene), experts evaluated eight outputs: 5 generated by different LLM backends of CELLFORGE (Claude 3.7, o1, DeepSeek R1, Qwen-plus, and Llama 3.1) and three from independent DeepResearch agents (OpenAI, Perplexity, Gemini). To ensure fairness and minimize bias, all outputs were anonymized and randomly shuffled across models. Experts were unaware of the model identity behind each output. Evaluations were performed along multiple dimensions, including biological significance, gap analysis insight, task clarity, data accuracy, literature integration, technical novelty, feasibility, and mechanistic explanation, using standardized rubric with scores ranging from 0 (poor) to 10 (excellent). Additionally, we compared human ratings with the confidence scores produced by CELLFORGE during graph-based multi-turn reasoning. Strong alignment between expert judgments and model confidence was observed, supporting the reliability of model self-evaluation. I.2 Detailed Results Table 15 presents the scores given by human scientists across different tasks (cytokine, drug, and gene perturbation) for outputs from various CELLFORGE (with different LLM backends) and DeepResearch agents. The results indicate that CELLFORGE generally outperforms DeepResearch agents, with versions like CellForge-Claude3.7 showing superior performance in several dimensions, even achieving full marks in some cases. Each model demonstrates varying capabilities across different task types and evaluation criteria. CELLFORGE versions show more balanced performance compared to the DeepResearch agents, which sometimes score low in certain dimensions. Table 16 compares the expert ratings with CellForges confidence scores during graph-based multiturn reasoning. The alignment between the confidence scores and expert ratings suggests that CellForges self-evaluation mechanism is reliable. This correlation confirms that the confidence scores can serve as valid indicator of the quality of CellForges outputs. Overall, these results highlight CellForges effectiveness in handling scientific analysis and design tasks and validate the utility of their confidence assessment. 58 Table 15: CELLFORGE Performance Scores Evaluated by three human scientists for 10 hours. (CFcld: CellForge-Claude3.7, CFo1 : CellForge-o1, CFds: CellForge-DeepSeek R1, CFqw: CellForge-Qwenplus, CFlm: CellForge-llama 3.1, DRO: OpenAI DeepResearch, DRP : Perplexity DeepResearch, DRG: Gemini DeepResearch), Biomni:Biomni[57], CLD:Single LLM Claude 3.7. Dimension CFcld CFo1 CFds CFqw CFlm DRO DRP DRG Biomni CLD A. Analysis Reports by Task Analysis Module 4 2 4 3 5 5 3 3 6 5 5 6 5 5 5 5 3 5 1 3 5 4 3 4 4 4 4 4 5 5 6 4 4 2 2 0 6 0 2 2 3 3 3 4 4 5 0 2 5 5 2 5 5 1 0 0 0 3 2 3 2 0 0 1 2 2 3 1 1 0 10 4 2 2 3 2 5 5 3 3 3 5 3 3 3 3 2 5 6 3 2 3 5 4 1 4 3 2 2 4 5 5 4 4 2 2 8 3 3 3 5 5 3 3 3 4 4 4 3 4 4 6 4 4 4 4 4 4 3 2 2 2 2 4 4 3 4 4 4 4 4 4 7 4 1 1 2 2 4 2 2 4 1 4 1 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 3 2 2 4 9 Cytokines Task Analysis Biological Significance Gap Analysis Insight Task Formulation Clarity Data Characterization Accuracy Literature Integration Quality Drug Perturbation Task Biological Significance Gap Analysis Insight Task Formulation Clarity Data Characterization Accuracy Literature Integration Quality Gene Perturbation Task Biological Significance Gap Analysis Insight Task Formulation Clarity Data Characterization Accuracy Literature Integration Quality 7 6 7 7 7 7 7 8 7 8 7 7 8 8 8 6 2 5 4 4 6 5 7 8 7 7 7 8 8 7 6 7 7 5 7 6 7 8 8 6 5 6 6 5 5 4 6 6 6 6 7 6 6 5 4 7 7 6 6 5 5 4 4 5 6 5 4 5 4 5 7 3 3 B. Hypothesis Plan by Method Design Module Cytokines Perturbation Task Technical Novelty Feasibility Clarity and Consistency Biological Plausibility Mechanism Explanation Quality Pathway Relevance Cross-Perturbation Generalizability Drug Perturbation Task Technical Novelty Feasibility Clarity and Consistency Biological Plausibility Mechanism Explanation Quality Pathway Relevance Cross-Perturbation Generalizability Gene Perturbation Task Technical Novelty Feasibility Clarity and Consistency Biological Plausibility Mechanism Explanation Quality Pathway Relevance Cross-Perturbation Generalizability Overall Ranking 6 5 6 5 6 5 6 8 7 8 8 9 9 9 7 7 9 7 7 7 1 6 6 5 6 5 6 7 7 7 8 8 8 8 8 7 7 8 7 7 7 7 3 4 5 5 5 4 4 5 4 5 4 4 3 4 4 3 4 3 2 2 3 5 4 5 5 4 5 3 5 5 4 6 5 4 4 5 5 4 5 4 3 3 4 5 7 6 7 6 6 4 7 6 7 6 5 5 6 6 5 6 5 4 4 5 2 Table 16: Expert Human Scores compare with CellForges Confidence Scores on graph-based discussions Across Tasks and Rounds Experts Cytokine Task Drug Task Gene Task Model Architecture Expert Confidence Score Data Expert Confidence Score Training Expert Confidence Score Deep Learning Expert Confidence Score Pathway Expert Confidence Score Critic Agent Confidence Score R1 8 0.78 8 0.75 7 0.69 9 0.74 9 0.77 8 0.78 R2 9 0.81 9 0.77 8 0.80 8 0.77 8 0.79 8 0.80 R3 9 0.82 10 0.81 9 0.81 9 0.85 9 0.83 9 0. R4 9 0.84 10 0.82 9 0.82 9 0.88 9 0.85 9 0.85 R1 9 0.72 8 0.65 8 0.77 8 0.79 8 0.77 8 0.78 R2 9 0.77 10 0.78 9 0.80 10 0.82 10 0.81 9 0. R3 10 0.84 10 0.81 10 0.82 10 0.86 10 0.81 10 0.83 R4 10 0.85 10 0.82 10 0.82 10 0.87 10 0.81 10 0.83 R1 9 0.74 9 0.65 9 0.78 10 0.79 10 0.77 9 0. R2 9 0.76 9 0.78 9 0.80 10 0.85 10 0.85 9 0.80 R3 9 0.82 10 0.81 9 0.81 10 0.87 10 0.86 9 0.84 R4 9 0.84 10 0.83 9 0.82 10 0.88 10 0.88 9 0."
        },
        {
            "title": "J Performance Varies Across Different LLMs and AI Coders",
            "content": "To comprehensively evaluate the robustness of our framework, we conducted extensive experiments comparing CELLFORGE with various baseline approaches across six challenging single-cell perturbation datasets. Table 17 presents the success rates (out of 5 independent runs) for each method, where successful run is defined as generating executable code that produces biologically meaningful predictions without runtime errors. J.1 Experimental Setup We evaluated four distinct categories of code generation approaches: (1) CELLFORGE with Different LLM Backends: Our full framework integrated with five state-ofthe-art LLMs (Claude 3.7, OpenAI o1, DeepSeek R1, Qwen-plus, and Llama 3.1), leveraging the complete multi-agent architecture with collaborative reasoning and iterative refinement. (2) Single-LLM Direct Generation: Each LLM operates independently without the multi-agent framework, tasked with generating the complete solution in single pass, given the exact input specifications. (3) DeepResearch Variants: Three commercial implementations of automated research systems, representing the current state-of-the-art in end-to-end scientific code generation. (4) AI Coding Assistants: Two popular open-source coding frameworks (OpenHands and Aider) are integrated with the same five LLMs, representing specialized code generation tools designed for software development tasks. J.2 Key Findings Table 17: Expert Human Scores compare with CellForges Confidence Scores on graph-based discussions Across Tasks and Rounds Tool Adamson Norman Liscovitch Papalexi Srivatsan Schiebinge CELLFORGE with different LLMs integrated CellForge-Claude3.7 CellForge-o1 CellForge-DeepSeek R1 CellForge-Qwen-plus CellForge-llama 3.1 Claude3.7 only o1 only DeepSeek R1 only Qwen-plus only Llama 3.1 only OpenAI DeepResearch Perplexity DeepResearch Gemini DeepResearch OpenHands-Claude3.7 OpenHands-o1 OpenHands-DeepSeek R1 OpenHands-Qwen-plus OpenHands-Llama 3.1 aider-Claude3.7 aider-o1 aider-DeepSeek R1 aider-Qwen-plus aider-Llama 3.1 4 4 4 4 2 2 1 1 1 1 1 0 0 3 3 2 2 2 2 2 3 1 1 5 4 4 3 4 3 3 4 1 Single-LLM generated code 2 1 1 1 1 1 0 0 0 0 DeepResearch generated codes AI Coders 2 0 0 4 2 3 2 1 3 2 2 1 1 1 0 0 3 2 2 1 0 2 2 2 0 0 61 The results reveal several critical insights: 4 3 3 2 1 0 1 1 0 0 1 0 0 3 2 2 2 1 2 2 2 1 0 4 2 3 3 1 1 1 1 1 1 0 0 2 1 1 2 1 2 1 1 0 0 4 2 3 3 1 1 0 0 0 0 1 0 0 2 1 2 2 1 2 1 1 0 Multi-Agent Architecture Superiority: CELLFORGE consistently outperforms all baseline approaches, with success rates ranging from 40-100% depending on the LLM backend and dataset complexity. The multi-agent framework provides an average improvement of 2.3x over single-LLM approaches and 3.5x over AI coding assistants. LLM Backend Dependency: Within CELLFORGE, Claude 3.7 demonstrates the most robust performance (average success rate: 4.2/5), followed by DeepSeek R1 and OpenAI o1. This performance hierarchy remains consistent across different dataset complexities, suggesting that certain LLMs are inherently better suited for scientific code generation tasks. Dataset Complexity Impact: The Liscovitch (scATAC-seq) and Papalexi (CITE-seq) datasets prove most challenging across all methods, with single-LLM approaches achieving near-zero success rates. These datasets require handling sparse chromatin accessibility data and multi-modal protein measurements, respectively, highlighting the importance of domain-specific knowledge integration. Catastrophic Failure of DeepResearch Variants: Both Perplexity and Gemini DeepResearch variants fail across all tasks (0/5 success rate), while OpenAIs variant achieves only marginal success. This suggests that general-purpose research systems lack the specialized capabilities required for complex biological data analysis. J.3 Analysis of Failure Modes The dramatic performance gap between CELLFORGE and other approaches can be attributed to several factors: (1) Domain Knowledge Integration: Single-LLM approaches often generate syntactically correct but biologically meaningless code, failing to account for data-specific characteristics such as sparsity patterns in scATAC-seq or batch effects in Perturb-seq experiments. (2) Error Recovery Capability: AI coding assistants (OpenHands, Aider) struggle with the iterative debugging required for scientific computing, often getting trapped in error loops when encountering tensor dimension mismatches or memory overflow issues. (3) Architectural Complexity: The multi-modal nature of datasets like CITE-seq requires sophisticated model architectures that combine different data streams. Single-pass generation approaches typically produce overly simplistic models that fail to capture these complexities. J.4 Implications for Scientific AI Systems These results underscore the critical importance of specialized, multi-agent architectures for scientific discovery tasks. The success of CELLFORGE demonstrates that effective scientific code generation requires not just powerful language models, but also: Collaborative reasoning among domain experts Iterative refinement with biological validation Task-specific knowledge retrieval and integration Robust error handling and recovery mechanisms The consistent superiority of Claude 3.7 within our framework also suggests that certain LLMs may possess inherent advantages for scientific reasoning, possibly due to their training data composition or architectural design. Future work should investigate these model-specific characteristics to optimize scientific AI systems further."
        },
        {
            "title": "K Designed Models",
            "content": "To understand how CELLFORGE adapts its architectural choices to different biological contexts, we conducted post-hoc analysis of the model components selected across various perturbation tasks. Table 18 presents the frequency of different neural network components appearing in models automatically designed by CELLFORGE across multiple independent runs for each dataset. K.1 Methodology For each of the six benchmark datasets, we executed CELLFORGE five times with different random seeds and analyzed the resulting model architectures. Each value in Table 18 represents the number of times specific component appeared in the generated models. This analysis reveals how our framework naturally adapts its design choices to the unique characteristics of each perturbation type and data modality. Table 18: Type of model components automatically selected by CELLFORGE across different perturbation tasks. Each value represents the frequency of component usage across five independent runs. The adaptive selection of architectures demonstrates the frameworks ability to tailor solutions to specific biological contexts. Model Type Transformer Attention GNN VAE MLP RNN CNN GAN XGBoost Gene Knock Out-RNAseq (Adamson Dataset) Gene Knock Out-RNAseq (Norman Dataset) Gene Knock Out-ATACseq (Liscovitch Dataset) Gene Knock Out-CITEseq (Papalexi Dataset) Drug Perturbation (Srivatsan Dataset) Cytokine Perturbation (Schiebinger Dataset) 5 4 3 6 3 4 4 6 2 3 1 1 4 4 2 4 1 1 3 2 1 2 1 1 4 5 2 1 2 - 1 - - - - 1 1 - - - - 2 2 2 1 2 1 - - 1 2 - 1 K.2 Architecture Selection Patterns Several notable patterns emerge from this analysis: Transformer Dominance in Gene Expression Tasks: Transformer architectures appear most frequently in traditional scRNA-seq datasets (Adamson: 5/5, Norman: 4/5), reflecting their effectiveness in capturing long-range gene-gene dependencies. The self-attention mechanism enables modeling of complex regulatory relationships without explicit prior knowledge of gene interaction networks. Attention Mechanism Prevalence: Beyond full transformer architectures, standalone attention mechanisms are particularly favored for the Norman dataset (6 occurrences), suggesting that the multi-gene perturbation patterns in this dataset benefit from selective information aggregation. This aligns with the biological reality that combinatorial perturbations often involve non-linear interactions requiring dynamic weighting of different genes contributions. Graph Neural Networks for Regulatory Modeling: GNNs appear consistently across gene knockout experiments (4/5 for both Adamson and Norman datasets), indicating that CELLFORGE recognizes the value of explicitly modeling gene regulatory networks. The slightly lower frequency in drug and cytokine perturbations (1/5) suggests that molecular interaction networks may be less directly applicable to these perturbation types. Modality-Specific Adaptations: The scATAC-seq dataset (Liscovitch) shows unique patterns with the inclusion of XGBoost (1/5), the only dataset to utilize this traditional machine learning approach. This likely reflects the extreme sparsity of chromatin accessibility data, where gradient boosting can effectively handle the binary nature of peak calling. K.3 Biological Interpretation of Architectural Choices The architectural diversity reflects CELLFORGEs understanding of different biological mechanisms: Multi-Modal Integration: The CITE-seq dataset (Papalexi) shows the highest transformer usage (6/5 possible due to hybrid architectures), consistent with the need to integrate RNA and protein measurements. The lower MLP frequency (1/5) suggests that simple concatenation approaches are insufficient for this multi-modal challenge. 63 Temporal Dynamics: The appearance of RNNs exclusively in the Norman dataset (1/5) indicates recognition of potential temporal aspects in perturbation responses, even though the data itself is not explicitly time-series. This may reflect the frameworks attempt to model the cascade effects of genetic perturbations. Generative Modeling: GANs appear sporadically across datasets (ranging from 1-2 occurrences), primarily in scenarios where data augmentation might benefit model training. Their higher frequency in scATAC-seq tasks suggests utility in handling the severe class imbalance inherent in chromatin accessibility data. K.4 Task Complexity and Model Sophistication clear correlation exists between task complexity and architectural sophistication: Simple Perturbations, Simple Models: Drug and cytokine perturbations, which typically involve more direct molecular mechanisms, show lower architectural diversity. The predominant use of transformers (3-4/5) with minimal additional components suggests that these tasks can be adequately modeled with standard sequence-to-sequence approaches. Complex Biology, Complex Architecture: Gene knockout experiments, particularly those involving combinatorial perturbations, consistently employ multiple architectural components in tandem. The co-occurrence of transformers, attention mechanisms, and GNNs in these models reflects the need to capture both local (gene-specific) and global (network-wide) effects. Sparse Data, Specialized Solutions: The unique challenges of scATAC-seq dataextreme sparsity (95% zeros) and binary naturelead to distinctive architectural choices. The reduced reliance on VAEs (1/5) and increased use of discriminative models reflect the difficulty of learning meaningful latent representations from such sparse data. K."
        },
        {
            "title": "Implications for Automated Model Design",
            "content": "This analysis demonstrates that CELLFORGE has developed an implicit understanding of the relationship between biological data characteristics and appropriate model architectures. The frameworks ability to consistently select transformers for sequence modeling, GNNs for network effects, and specialized components for unique challenges validates our multi-agent approach to scientific discovery. Moreover, the architectural diversity observed across different perturbation types underscores the limitations of one-size-fits-all approaches in computational biology. The success of CELLFORGE lies not just in its ability to generate working code, but in its capacity to reason about the fundamental nature of each biological problem and select appropriate computational tools accordingly. These findings suggest that effective automation of scientific model design requires not just technical expertise but also deep integration of domain knowledge. This capability emerges naturally from our multi-agent collaborative framework."
        },
        {
            "title": "L UMAP of Perturbation Results",
            "content": "To visualize the quality of CELLFORGEs predictions in the high-dimensional gene expression space, we employed Uniform Manifold Approximation and Projection (UMAP), state-of-the-art dimensionality reduction technique that preserves both local and global structure of the data. This analysis provides an intuitive visual assessment of how well our models capture the complex cellular state changes induced by different perturbation types. L.1 Visualization Methodology For each perturbation type, we processed the data as follows: 1. Combined predicted and ground truth expression profiles into single matrix 2. Applied standard preprocessing (log-normalization, selection of top 3,000 highly variable genes) 3. Computed UMAP embeddings using 50 principal components with parameters: neighbors=30, min dist=0.3 4. Overlaid predictions and ground truth with distinct coloring (blue for ground truth, orange for predicted) L.2 Results and Interpretation Figure 14 presents UMAP visualizations comparing the predicted and ground truth single-cell gene expression profiles under three different types of perturbations: gene perturbation (Norman et al. Dataset [75]), drug perturbation (Srivatsan et al. Dataset [76]), and cytokine perturbation (Schiebinger et al. Dataset [78]). Figure 14: UMAP visualizations of predicted and ground truth single-cell gene expression profiles under three types of perturbations. In each panel, blue points represent ground truth cells and orange points represent model predictions. The degree of overlap and similarity in the distribution of cell states between predicted and real data reflects the models performance in capturing the effects of different perturbations. Left: Gene knockout perturbations show excellent overlap with distinct clustering. Middle: Drug perturbations exhibit more diffuse patterns but maintain overall structure. Right: Cytokine perturbations demonstrate tight correspondence despite complex signaling effects. L.2.1 Gene Perturbation Analysis The gene perturbation visualization (left panel) demonstrates exceptional model performance with near-complete overlap between predicted and ground truth distributions. Several key observations emerge: Cluster Preservation: The model accurately reconstructs distinct cellular subpopulations, visible as separate clusters in the UMAP space Density Matching: The orange (predicted) points show similar density distributions within each cluster as the blue (ground truth) points Rare State Capture: Even outlier cells and rare states at the periphery are well-represented in the predictions 65 This high fidelity likely reflects the relatively direct and predictable nature of genetic perturbations, where CELLFORGE successfully learned the gene regulatory logic. L.2.2 Drug Perturbation Analysis The drug perturbation results (middle panel) reveal more complex landscape: Global Structure: The overall comet-like shape is well-preserved, indicating successful capture of major drug response trajectories Increased Dispersion: Predicted cells show slightly more spread than ground truth, particularly in transition regions Gradient Effects: The model captures the continuous nature of dose-response relationships, visible as smooth transitions rather than discrete clusters The increased variability in drug responsesdue to factors like off-target effects and cell-specific metabolismpresents greater challenge that our model handles reasonably well. L.2.3 Cytokine Perturbation Analysis The cytokine perturbation visualization (right panel) shows remarkably tight correspondence despite the inherent complexity of immune signaling: Circular Organization: Both predicted and ground truth cells form characteristic circular pattern, likely representing cell cycle or differentiation trajectories Uniform Coverage: The model achieves uniform coverage across the entire manifold without gaps or over-densification Fine Structure: Subtle substructures within the main circular pattern are preserved, indicating capture of nuanced biological states L.3 Quantitative Assessment To complement the visual analysis, we computed several quantitative metrics on the UMAP embeddings: Table 19: Quantitative metrics for UMAP embedding similarity"
        },
        {
            "title": "Gene Drug Cytokine",
            "content": "Procrustes Distance Centroid Distance KL Divergence Silhouette Score (Overlap) 0.12 0.08 0.09 0.92 0.18 0.15 0.16 0.84 0.14 0.10 0.11 0.89 These metrics confirm the visual observations: gene perturbations show the highest fidelity (lowest distances), while drug perturbations exhibit more variability. All values indicate strong overall correspondence between predicted and ground truth distributions. L.4 Biological Significance The UMAP visualizations reveal that CELLFORGE captures not just individual gene expression values but also: 1. Cell State Relationships: The preservation of relative distances between cells indicates accurate modeling of transcriptional similarities 2. Perturbation Gradients: Smooth transitions in the embedding space reflect biological continuities in cellular responses 3. Heterogeneity Patterns: The maintenance of population-level variance demonstrates that models avoid mode collapse to average responses 66 L.5 Limitations and Considerations While these visualizations provide compelling evidence of model quality, several caveats should be noted: UMAP Parameters: Different parameter choices can affect the visual appearance while preserving the same underlying relationships Projection Artifacts: Some apparent differences may be artifacts of the 2D projection rather than true prediction errors Sampling Effects: For visualization clarity, we show random subset of 5,000 cells per condition L.6 Implications for Model Development The UMAP analysis provides several insights for future model improvements: 1. Perturbation-Specific Architectures: The varying degrees of overlap suggest that different perturbation types may benefit from specialized model components 2. Uncertainty Quantification: Regions with lower overlap could guide uncertainty estimation mechanisms 3. Biological Constraints: Incorporating known constraints (e.g., cell cycle boundaries) could improve predictions in ambiguous regions These visualizations ultimately demonstrate that CELLFORGE successfully generates models that capture both fine-grained expression patterns and global transcriptional landscapes across diverse perturbation types, validating our approach for automated scientific discovery in single-cell biology."
        },
        {
            "title": "M Additional Visualizations",
            "content": "M.1 Comparative Performance Analysis To provide comprehensive visual assessment of CELLFORGEs performance advantages, Figure 15 presents comparative bar charts across three evaluation dimensions for different perturbation types. These visualizations offer complementary insights to the numerical results in Tables 13 and 14. Figure 15: Comparative evaluation of CELLFORGE and DeepResearch variants across perturbation types. Bar charts show performance scores from LLM judges for three key dimensions: (a) Analyse Dataset, (b) Analyse Task Type, and (c) Analyse Baseline Defects. CELLFORGE (purple) consistently outperforms OpenAI (blue), Perplexity (orange), and Gemini (pink) DeepResearch implementations across drug, gene knockout, and cytokine perturbation tasks. Error bars represent standard deviation across five independent evaluation runs. Notable improvements include up to 17% gain in perturbation consistency and 15% improvement in expression correlation metrics. Key Performance Insights: Dataset Analysis Excellence. CELLFORGE achieves consistently high scores (7.2-8.6) across all perturbation types, demonstrating robust capability in extracting and interpreting complex biological data characteristics. The most significant advantage appears in drug perturbation analysis (8.6), where our multi-agent approach effectively handles the complexity of chemical-biological interactions. Task Type Understanding. While baseline methods show variable performance (3.2-8.0), CELLFORGE maintains stable high performance (6.9-8.0) across tasks. This consistency reflects our frameworks ability to correctly identify and formulate computational problems regardless of the biological context, critical advantage for automated scientific discovery. Baseline Defect Identification. The most pronounced performance gap emerges in identifying limitations of existing approaches. CELLFORGE excels particularly in gene knockout scenarios (7.04), where it successfully identifies subtle methodological issues that other systems miss. Perplexity and Gemini variants show particularly poor performance (2.16-4.52), highlighting the importance of domain-specific reasoning in our multi-agent architecture. Cross-Task Robustness. Unlike competing approaches that show task-dependent performance fluctuations, CELLFORGE demonstrates remarkable stability across diverse biological contexts. This robustness stems from our collaborative agent design, where specialized experts contribute complementary perspectives to handle varying data modalities and perturbation mechanisms. These visualizations underscore that CELLFORGEs superiority extends beyond marginal improvementsit represents fundamental advancement in how AI systems approach complex biological analysis tasks. The consistent outperformance across all dimensions validates our hypothesis that multi-agent collaboration with domain knowledge integration is essential for effective automated scientific discovery in single-cell biology."
        },
        {
            "title": "N Related Works",
            "content": "This section provides comprehensive overview of existing approaches in automated scientific discovery and single-cell perturbation analysis, positioning CELLFORGE within the broader landscape of AI-driven research systems. N.1 Agent Systems for Scientific Discovery The landscape of agent systems for scientific discovery has evolved rapidly with the advancement of LLMs, creating continuum of capabilities that span different aspects of the scientific workflow. As summarized in Table 20, existing systems can be categorized into several distinct classes based on their primary functionalities. Literature Analysis Systems. Task analysis systems form the foundation of this ecosystem, with tools like PaperQA2 [7] and CHIME [2] demonstrating sophisticated literature retrieval and organization capabilities. These systems excel at extracting insights from diverse sources while maintaining accuracy and contextualizing information within broader scientific frameworks. Evaluation frameworks such as ScienceAgentBench [8] and DSBench [35] have emerged to systematically assess these capabilities, providing standardized benchmarks for scientific task decomposition and comprehension abilities. However, these systems remain limited to analysis without the ability to generate novel hypotheses or implement solutions. Hypothesis Generation Systems. Building on these foundational capabilities, hypothesis generation systems represent more creative dimension of scientific discovery. ResearchAgent [27] implements an iterative approach to research ideation by progressively refining hypotheses through literature analysis. Complementary research has investigated whether LLMs possess inherent scientific reasoning abilities, with Qi et al. [3] demonstrating that models can generate plausible hypotheses in zero-shot contexts. The quality of these AI-generated research proposals has been critically assessed Table 20: Comparison of Agent Systems for Scientific Discovery. The table highlights the comprehensive capabilities of CELLFORGE across all evaluated dimensions versus existing methods. Method PaperQA2 [7] CHIME [2] PaperBench[94] ResearchAgent [27] VirSci [95] CoI Agent [96] OpenD5 [37] DeepResearch [93] SciCode [5] DA-Code [6] MLAgentBench [10] DiscoveryBench [9] BLADE [97] AI Scientist [1] MLR-Copilot [12] Future House[98] BioDiscoveryAgent [14] Coscientist [13] AtomAgents [43] TAIS [99] MedAgents [44] CellForge Task Analysis Hypothesis Gen. Code Gen. End-to-End Automation Multi-Agent System Domain Knowledge Evaluation Capability Literature Analysis Systems Hypothesis Generation Systems Code Generation Systems End-to-End Scientific Systems Domain-Specific Systems 69 through human evaluation studies [28], revealing that while LLM-generated ideas often meet basic quality thresholds, they frequently lack the creative insights characteristic of high-impact human research. Commercial platforms like DeepResearch [93] have operationalized these capabilities, offering integrated solutions for literature analysis and hypothesis development across disciplines. Code Generation and Validation Systems. The implementation gap between conceptual models and executable experiments has been addressed through specialized code generation frameworks. SciCode [5] and DA-Code [6] establish benchmarks for evaluating code quality across scientific domains, while MLAgentBench [10] focuses specifically on machine learning experimentation workflows. More advanced systems like DiscoveryBench [9] and BLADE [97] integrate hypothesis generation with code implementation, providing more comprehensive evaluation of scientific reasoning. These tools ensure that implementation aligns with scientific best practices, bridging the gap between theoretical models and practical applications. The refinement and validation of hypotheses represent crucial step where several innovative approaches have emerged. Chain of Ideas [96] implements sequential framework that builds upon previous insights while exploring novel directions through structured reasoning. Goal-Driven Discovery [37] demonstrates how language-guided exploration can enhance hypothesis development by highlighting statistically significant relationships in complex datasets. These developments address critical gap identified by Honovich et al. [100], who highlighted the limitations of current prompting methods for complex scientific tasks. N.2 End-to-End Scientific Discovery Systems Recent developments have focused on integrating these capabilities into comprehensive systems that manage the entire scientific workflow. The AI Scientist [1] represents one of the most ambitious attempts at fully automated scientific discovery, integrating literature analysis, hypothesis generation, experimentation, and result interpretation into cohesive framework. Similar end-to-end approaches include MLR-Copilot [12] for machine learning research and Agent Laboratory [101], which employs LLM agents as research assistants throughout the scientific process. particularly innovative development is Agentrxiv [30], which creates collaborative framework for autonomous research through shared preprint server, demonstrating that knowledge sharing among agents significantly improves performance on benchmark tasks. These systems represent significant progress toward full automation but often lack domain-specific knowledge integration, limiting their effectiveness in specialized fields like single-cell biology. Domain-Specific Implementations. Domain-specific implementations have addressed the unique challenges of particular scientific fields. Autonomous Chemical Research [13] integrates chemical knowledge with laboratory automation to accelerate compound discovery, while BioDiscoveryAgent [14] focuses on designing genetic perturbation experiments. Systems like AtomAgents [43] for materials science, MedAgents [44] for medical reasoning, and DORA AI Scientist [45] for general scientific exploration demonstrate how domain knowledge can be effectively incorporated into agent-based systems. Perhaps most impressively, Sparks [29] has discovered previously unknown phenomena in protein mechanics without human intervention, highlighting the potential for truly autonomous scientific discovery. Specialized Methodologies and Enhancements. Specialized methodologies have emerged to enhance specific aspects of the scientific discovery process. NOVA [40] employs iterative planning and search to improve the novelty and diversity of generated ideas, while Scideator [41] grounds idea generation in research paper facet recombination. Literature Meets Data [36] demonstrates the advantages of combining literature-based insights with empirical data, outperforming approaches that rely exclusively on either source. CODESCIENTIST [102] utilizes genetic search over combinations of research text and executable code for scientific ideation and experiment, enabling large-scale automated discovery with rigorous evaluation across code, review, and replication. The quality and organization of literature synthesis have been enhanced through systems like SurveyForge [103], which employs outline heuristics and memory-driven generation for automated survey writing. Novel evaluation frameworks such as AI Idea Bench [32] and LiveIdeaBench [33] provide standardized metrics for assessing LLMs scientific creativity and idea generation capabilities, while RAGBench [49] offers an explainable benchmark for retrieval-augmented generation systems specifically designed for scientific literature. 70 Maintaining methodological rigor in automated experimentation has been addressed by Curie [46], which embeds rigor through modules enhancing reliability, methodical control, and interpretability. The ethical dimensions of AI in scientific research have been explored by Lin et al. [104], who propose practical strategies for ethical AI use that move beyond abstract principles to address concrete implementation challenges. N.3 Comparison of CELLFORGE with Existing Approaches Table 21: Comparison of computational approaches for single-cell analysis. The table highlights the comprehensive capabilities of CELLFORGE across all evaluated dimensions versus existing methods grouped by categories. Method Linear Regression [60] Random Forest [61] scGen [62] Perturb-CGAN [26] Dynamo [63] AttentionPert [65] GRNBoost2 [105] scGPT [18] Geneformer [19] scBERT [106] BioDiscoveryAgent [14] DiscoveryBench [9] ScienceAgentBench [8] CellForge Automation Agentic Domain Knowl. Cross Modal. Interpret. Code Gen. Dimension Traditional ML Deep Generative Models Network-Based Methods Transformer Architectures Existing Agent Systems While general scientific discovery systems have made significant progress, single-cell perturbation analysis presents unique challenges that require specialized approaches. Table 21 compares CELLFORGE with existing methods specifically designed for single-cell analysis across six critical dimensions. Traditional and Deep Learning Approaches. Traditional machine learning methods like Linear Regression [60] and Random Forest [61] offer interpretability but lack the sophistication to capture complex gene regulatory relationships. Deep generative models such as scGen [62] and PerturbCGAN [26] improve prediction accuracy but operate as black boxes without domain knowledge integration or automation capabilities. Network-Based and Transformer Methods. Network-based approaches including Dynamo [63], AttentionPert [65], and GRNBoost2 [105] incorporate biological knowledge through gene regulatory networks, enhancing interpretability. However, they require manual implementation and lack crossmodal capabilities. Recent transformer architectures like scGPT [18], Geneformer [19], and scBERT [106] demonstrate impressive cross-modal learning but still require expert knowledge for deployment and lack automated discovery capabilities. The CELLFORGE Advantage. As shown in both tables, CELLFORGE is the only system that achieves comprehensive coverage across all evaluated dimensions. This unique position stems from our integration of: End-to-end automation that eliminates the need for manual intervention Multi-agent collaboration that leverages specialized expertise Domain knowledge integration through agentic retrieval and expert reasoning Cross-modal capabilities for handling diverse single-cell data types 71 Built-in interpretability through transparent decision-making processes Automatic code generation that produces executable, optimized implementations This comprehensive approach enables CELLFORGE to address the full complexity of single-cell perturbation analysis while maintaining the flexibility to adapt to new biological contexts and data modalities. The frameworks success in outperforming specialized models like scGPT while providing complete automation demonstrates the power of combining domain-specific knowledge with general-purpose reasoning capabilities in unified system."
        },
        {
            "title": "O Knowledge Base for Agentic Retrieval",
            "content": "The vector database used in the Agentic Retrieval module integrates 45 peer-reviewed or high-quality preprint publications, serving as the core knowledge base that supports architectural reasoning and evidence retrieval. The articles were selected based on relevance to perturbation modeling, single-cell analysis, foundation model design, and biological data integration. 1. mini-review on perturbation modelling across single-cell omic modalities. (Gavriilidis, G., et al., 2024) Computational and Structural Biotechnology Journal. [107] 2. scPerturb: harmonized single-cell perturbation data. (Peidli, S., et al., 2024) Nature Methods. [24] 3. Massively parallel single-cell chemical screening with sci-Plex (Srivatsan et al., 2020). Science. [108] 4. Integrated analysis of single-cell RNA-seq data across different conditions, technologies, and species (Stuart et al., 2019). Cell. [109] 5. Scanpy: large-scale single-cell gene expression data analysis (Wolf et al., 2018). Genome Biology. [110] 6. scGen predicts single-cell perturbation responses (Lotfollahi et al., 2019). Nature Methods. [62] 7. Learning interpretable cellular responses to complex perturbations in high-throughput screens. (Lotfollahi et al., 2021) Bioinformatics. [72] 8. Predicting transcriptional outcomes of novel multigene perturbations with GEARS (Roohani et al., 2023). Nature Biotechnology. [64] 9. scGPT: foundation model for single-cell biology (Cui et al., 2024). Nature Methods. [18] 10. DNABERT: pre-trained Bidirectional Encoder Representations from Transformers for DNAlanguage (Ji et al., 2021). Bioinformatics. [111] 11. Genome-scale CRISPR-Cas9 knockout and transcriptional activation screening (Shalem et al., 2015). Nature Reviews Genetics. [112] 12. The case for genomic pretraining: commentary (Sarkis and Listgarten, 2023). Nature Methods. [113] 13. Challenges and opportunities in FAIR single-cell data analysis (Luecken et al., 2022). Nature Reviews Genetics. [114] 14. CellBox: interpretable and generalizable cell representations for single cell transcriptomics (Zhang et al., 2022). Science Advances. [115] 15. scGNN is novel graph neural network for single-cell RNA-Seq analysis (Wang et al., 2021). Nature Communications. [116] 16. Predicting single-cell perturbation responses to chemical compounds with generalization to novel drugs (Hetzel et al., 2024). Nature Communications. [26] 17. scBERT as large-scale pretrained deep language model for cell type annotation (Yang et al., 2022). Nature Machine Intelligence. (Note: This is the extended journal version of the PNAS paper, focusing on cell type annotation). [117] 18. Joint modeling of single-cell multimodal data with totalVI (Gayoso et al., 2021). Nature Methods. [83] 20. Optimal-transport analysis of single-cell gene expression deconvolutes lineage branching (Schiebinger et al., 2019). Cell. [78] 21. MrVI: multi-resolution generative modeling of single-cell datasets (Ashuach et al., 2023). Cell Systems. [118] 22. xTrimoPGLM: foundation model for biology (Zeng et al., 2024). bioRxiv. [119] 23. GenSLM: generative foundation model for genomic sequences (Zvyagin et al., 2022). bioRxiv. [120] 24. scFoundation: Foundation Model for Single-Cell Analysis Based on Contrastive Learning (Tian et al., 2023). Nature Methods. [121] 25. comparison of automatic cell identification methods for single-cell RNA sequencing data (Abdelaal et al., 2019). Genome Biology. [122] 26. Benchmarking atlas-level data integration in single-cell genomics (Luecken et al., 2021). Nature Methods. [123] 27. Benchmarking Transcriptomics Foundation Models for Perturbation Analysis: one PCA still rules them all (Bendidi et al., 2024). bioRxiv. [25] 28. Defining and benchmarking open problems in single-cell analysis (Luecken et al., 2022). Nature Methods. (Note: This is different, broader benchmarking paper by the same lead author). [124] 29. Langpert: LLM-Driven contextual synthesis for unseen perturbation prediction (Martens et al., 2024). ICLR 2024. [125] 30. Learning single-cell perturbation responses using neural optimal transport (Bunne et al., 2023). NeurIPS 2022. [67] 31. Disentanglement of single-cell data with biolord (Piran et al., 2023). Nature Biotechnology. [126] 32. scDREAMER for atlas-level integration of single-cell datasets using deep generative model paired with adversarial learning (Shree et al., 2024). Nature Communications. [127] 33. Single-Cell Multimodal Prediction via Transformers (Tang et al., 2022). NeurIPS 2022 Workshop. [128] 34. Supervised Training of Conditional Monge Maps (Bunne et al., 2024). ICLR 2024. [129] 35. Best practices for single-cell analysis across modalities (Heumos et al., 2023). Nature Reviews Genetics. [130] 36. Deep learning tackles single-cell analysisa survey of deep learning for scRNA-seq analysis (Flores et al., 2022). Briefings in Bioinformatics. [131] 37. Characterizing the impacts of dataset imbalance on single-cell data integration (Maan et al., 2024). Nature Biotechnology. [132] 38. scBaseCamp: an AI agent-curated, uniformly processed, and continually expanding single cell data resource (Youngblut et al., 2023). bioRxiv. [133] 39. Transfer learning enables predictions in network biology (Theodoris, C. V. et al., 2024). Nature. [19] 40. practical guide to single-cell perturbation analysis (Squair, J. W. et al., 2024). Nature Reviews Genetics. [134] 41. Deep generative modeling for single-cell transcriptomics (Lopez, R. et al., 2018). Nature Methods. [135] 42. PerturbNet predicts single-cell responses to unseen chemical perturbations (Rashid, Y. S. et al., 2024). Nature Methods. [136] 43. Cell2Sentence: Teaching Large Language Models the Language of Biology (Karaletsos, T. et al., 2024). bioRxiv. [137] 44. Zero-shot evaluation reveals limitations of single-cell foundation models (Heumos, L. et al., 2024). Nature Methods. [138] 45. scGenePT: Is language all you need for modeling single-cell perturbation prediction (Sun, Z. et al., 2024). bioRxiv. [139]"
        },
        {
            "title": "P Prompt Templates",
            "content": "P.1 Task Description input"
        },
        {
            "title": "Task Desciption Input",
            "content": "Your task is to develop predictive model that accurately estimates gene expression profiles of individual K562 cells following CRISPR interference (CRISPRi), using the dataset from Norman et al. (2019, Science). Task Definition: - Input: Baseline gene expression profile of an unperturbed K562 cell and the identity of the target gene(s) for perturbation - Output: Predicted gene expression profile after perturbation Evaluation Scenarios: 1. Unseen Perturbations: Predict effects of gene perturbations not present during training 2. Unseen Cell Contexts: Predict responses in cells with gene expression profiles not observed during training Evaluation Metrics: - Mean Squared Error (MSE): Measures the average squared difference between predicted and observed gene expression. - Pearson Correlation Coefficient (PCC): Quantifies linear correlation between predicted and observed profiles. - R$ˆ2$ (Coefficient of Determination): Represents the proportion of variance in the observed gene expression that can be explained by the predicted values. - MSE for Differentially Expressed (DE) Genes (MSE_DE): Same as MSE but computed specifically for genes identified as differentially expressed. - PCC for Differentially Expressed (DE) Genes (PCC_DE): Same as PCC but computed specifically for genes identified as differentially expressed. - R$ˆ2$ for Differentially Expressed (DE) Genes (R$ˆ2$_DE): Same as R$ˆ2$ but computed specifically for genes identified as differentially expressed. 75 P.2 Task Analysis Collaboration Agents Settings Agent 1: Dataset Analyst Dataset Analyst is specialized agent responsible for performing systematic analysis of single-cell perturbation datasets during the Task Analysis stage. Its core function is to extract and summarize the key characteristics of given datasetincluding experimental design, data modalities, perturbation types, and quality metrics to facilitate downstream hypothesis generation and modeling. The agent is equipped with contextualized agent retrieval (RAG in the former module) results to incorporate relevant metadata, associated publications, and protocol references. Its output follows structured JSON format to enable direct inter-agent communication and automatic pipeline integration. The Dataset Analyst prioritizes clarity, scientific precision, and critical evaluation, identifying potential risks or biases while offering preprocessing recommendations tailored to the datasets complexity and intended use cases."
        },
        {
            "title": "Data Analyst",
            "content": "You are Dataset Analyst agent in multi-agent scientific research system. Your goal is to analyze single-cell perturbation dataset and provide comprehensive, structured, and insightful report to support downstream hypothesis generation and modeling. # Role Description: The Dataset Analyst is responsible for extracting structured knowledge from single-cell perturbation datasets. This includes characterizing the experimental design, identifying quality and completeness issues, and proposing datasetspecific modeling considerations. The agent draws upon both metadata and relevant scientific context retrieved via agentic tools. It supports hypothesis generation by clarifying what is measurable, what may be confounded, and what preprocessing steps are necessary. # Skills: - Interpreting single-cell multi-omics data structures (e.g., RNA, ATAC, protein) - Identifying perturbation types and their downstream modeling implications - Detecting quality control issues (e.g., batch effects, sparsity, missing modalities) - Integrating metadata from publications, protocols, and retrieved scientific sources - Structuring heterogeneous information into JSON-compatible schemas - Making biologically grounded recommendations for preprocessing and modeling # Objectives: - Extract and summarize the key characteristics of the dataset - Identify risks, limitations, and preprocessing needs - Suggest modeling strategies aligned with dataset structure - Provide additional scientific insights not limited to fixed template # Input: You will receive: 1. Dataset metadata (e.g., species, cell types, perturbation types) 2. relevant knowledge from agentic retrieval # Instructions: Produce two-part output: ## Part 1: Structured Summary (JSON format) Include the following fields, but you may expand or adapt them based on dataset complexity: { \"introduction\": { \"modalities\": [...], \"perturbation_type\": [...], \"conditions\": [...], \"timepoints\": [...], \"replicates\": true/false, \"batches\": true/false, \"cell_types\": [...], \"organism\": \"...\", \"description\": \"...\" }, \"data_properties\": { \"num_cells\": [...], \"num_genes\": [...], \"num_features\": { \"RNA\": ..., \"ATAC\": ..., \"protein\": ... }, \"perturbation_targets\": { \"num_unique\": [...], \"target_type\": [...], \"coverage\": \"dense/sparse/mixed\" }, \"modality_completeness\": [...], \"metadata_completeness\": [...], \"preprocessing_required\": [...] }, \"quality_assessment\": { \"data_sparsity\": [...], \"batch_effect\": [...], \"replicate_consistency\": [...], \"known_issues\": [...], \"strengths\": [...], \"limitations\": [...] }, \"recommendations\": { \"preprocessing_steps\": [...], \"modeling_considerations\": [...], \"open_questions\": [...] }, \"refinement_suggestions\": [...] } Write concise, scientifically sound narrative (150300 words) to accompany the JSON summary. This should include: - holistic interpretation of dataset readiness for modeling - Potential scientific pitfalls or confounders - Unique strengths or opportunities (e.g., rare perturbation types, rich time series) - Reflections on whether the dataset aligns with typical assumptions in modeling pipelines - Any useful observations that do not fit cleanly into the structured fields You may reference information from retrieved publications or external protocols. If information is unknown or ambiguous, state it clearly using cautious language (e.g., \"not reported\", \"likely sparse\", \"appears to have\"). # Constraints: - Be concise, accurate, and avoid redundancy - Use clear scientific language; bullet points are acceptable in the JSON - Allow flexibility in output structure if additional insights emerge # Style Guide: - Output should be compatible with integration into downstream agent pipelines - Aim for the clarity and precision expected in peer-reviewed supplementary method section 77 - Prioritize information relevant to perturbation modeling, multi-omic integration, and biological interpretation Agent 2: Problem Investigator The Problem Investigator is domain-specialized agent responsible for transforming the input dataset and task context into clearly defined scientific problem formulation. This agent operates at the interface between biological insight and computational design, aiming to decompose complex single-cell perturbation tasks into actionable research questions, computational objectives, and biologically meaningful evaluation strategies. Leveraging both LLM reasoning and agentic retrieval results, the agent integrates biological mechanisms and relevant literature to propose testable hypotheses, identify key challenges, and design analysis methods with biological and computational validity."
        },
        {
            "title": "Probelm Investigator",
            "content": "You are Problem Investigator agent in multi-agent scientific research system. Your goal is to transform the dataset analysis into scientifically meaningful and computationally tractable hypothesis or modeling plan. # Role Description: The Problem Investigator interprets dataset summaries and transforms them into well-scoped scientific problems. This includes identifying biologically significant questions, selecting meaningful targets or outcomes, and proposing hypotheses that can be tested using computational modeling. The agent must balance biological relevance, data availability, and methodological feasibility. It serves as bridge between raw data and actionable research direction. # Skills: - Formulating biologically meaningful and testable hypotheses from complex data - Mapping experimental designs to machine learning problem types (e.g., classification, regression) - Evaluating feasibility of predictive tasks based on data modality and perturbation scope - Identifying pitfalls such as confounding, data leakage, or unobservable targets - Specifying input-output pairs and validation schemes for modeling tasks - Justifying scientific value and downstream utility of proposed tasks # Objectives: - Translate dataset structure into concrete scientific questions - Identify feasible targets, tasks, and outputs for modeling - Justify the biological and computational value of the proposed formulation - Propose structured hypothesis or modeling objective for downstream agents # Input: You will receive: 1. Dataset summary from the Dataset Analyst (structured + narrative) 2. Relevant biological context via retrieval or user input # Instructions: Produce structured problem specification with the following components: { \"biological_question\": \"string\", \"hypothesis_statement\": \"string\", \"task_formulation\": { \"input\": [\"modality1\", \"metadata1\", \"...\"], 78 \"output\": \"target variable or prediction goal\", \"task_type\": \"regression/classification/generation/other\" }, \"justification\": { \"biological_relevance\": [...], \"data_suitability\": [...], \"expected_challenges\": [...] }, \"evaluation_plan\": { \"metrics\": [...], \"baselines_to_consider\": [...], \"validation_strategy\": \"cross-validation/held-out cells/timesplit/...\" }, \"open_questions\": [...] } In addition to the structured JSON, write short explanation (100250 words) that: - Restates the goal in accessible scientific language - Explains why the proposed formulation is worth pursuing - Anticipates possible modeling limitations or edge cases - Optionally suggests alternatives or extensions # Constraints: - Prioritize alignment with the datasets structure and perturbation resolution - Avoid overly generic formulations; focus on specificity and tractability - Maintain scientific rigor and make testable claims when possible # Style Guide: - Write in the tone of proposal for computational biology modeling section - Use precise language grounded in both biology and data science - Be mindful of what is *not* observable or predictable from the dataset Agent 3: Baseline Assessor The Baseline Assessor is methodological analyst agent tasked with selecting, evaluating, and recommending baseline models for single-cell perturbation studies. Operating at the intersection of computational rigor and biological relevance, this agent critically assesses modeling paradigms across task types (e.g., regression, classification, generative modeling) and data modalities (e.g., gene expression, ATAC-seq, protein levels). It integrates literature evidence, benchmark practices, and dataset-specific constraints to recommend flexible yet strong baseline approaches. The agent also incorporates multi-objective considerations such as performance, interpretability, scalability, and biological plausibility."
        },
        {
            "title": "Baseline Assessor",
            "content": "You are Baseline Assessor agent specialized in recommending suitable baseline models for single cell perturbation prediction tasks. Your goal is to provide comprehensive assessments of baseline models and evaluation strategies based on relevant literature and dataset characteristics. # Role Description: The Baseline Assessor is comparative modeling expert focused on identifying and analyzing baseline architectures for perturbation prediction. This includes reviewing existing literature, extracting methodological details, and evaluating model suitability based on dataset constraints and task objectives. The agent serves as bridge between literature insights and practical modeling recommendations. # Skills: 79 - Assessing baseline models for biological interpretability and computational requirements - Identifying candidate architectures relevant to perturbation types and modalities - Extracting methodological details and limitations from scientific literature - Comparing model performances across different biological contexts - Designing evaluation frameworks with biologically significant metrics - Providing actionable improvement suggestions based on technical and biological considerations # Objectives: - Review relevant literature for the given perturbation type and modality - Identify 35 candidate architectures and discuss their pros/ cons in this context - Recommend at least two baseline models with rationale aligned to the dataset constraints and task objectives - Design evaluation frameworks considering biological variability and technical limitations - Provide improvement suggestions for model enhancements and biological validation # Input: You will receive: Task description and dataset information from upstream agents Retrieved papers and code implementations from literature databases RAG system results including relevant papers and code snippets # Instructions: Produce structured analysis report with the following components: { \"literature_overview\": { \"perturbation_types\": [...], \"existing_methods\": [...], \"technical_trends\": [...] }, \"candidate_models\": [ { \"model_name\": \"string\", \"architecture\": \"string\", \"strengths\": [...], \"weaknesses\": [...], \"biological_applicability\": [...] } ], \"recommended_baselines\": [ { \"model_name\": \"string\", \"rationale\": \"string\", \"implementation_details\": \"string\", \"evaluation_metrics\": [...], \"biological_relevance\": [...] } ], \"evaluation_framework\": { \"primary_metrics\": [...], \"secondary_metrics\": [...], \"validation_strategy\": \"string\", \"test_scenarios\": [...] }, \"improvement_suggestions\": { \"technical\": [...], \"biological\": [...], \"computational\": [...] } } 80 In addition to the structured JSON, write short explanation (100250 words) that: Summarizes the assessment of baseline models Explains the rationale behind the recommended baselines Discusses the biological relevance of the evaluation framework Anticipates potential limitations in model interpretability Suggests practical improvements for future modeling work # Constraints: - Prioritize models with established track records in similar biological contexts - Computational requirements relative to dataset scale - Ensure recommended models balance biological interpretability and predictive performance - Align evaluation metrics with both technical accuracy and biological significance - Provide concrete implementation details for recommended baselines # Style Guide: - Write in the tone of modeling methodology section for computational biology paper - Use precise language describing both technical and biological considerations - focus on practical applicability while acknowledging theoretical limitations - Clearly distinguish between established knowledge and speculative improvements - Format model recommendations to facilitate direct implementation Agent 4: Critic Refinement The Critic Refinement Agent orchestrates the integration of outputs from domain-specialized agents into coherent and machine-actionable analysis plan. It ensures consistency across the Dataset Analysts data characterization, the Problem Investigators hypothesis formulation, and the Baseline Assessors methodological recommendations. By resolving redundancies, aligning formats, and verifying logical flow, the Refinement Agent synthesizes the findings into structured JSON schema. This agent balances standardization with flexibility, enabling downstream automation while preserving the scientific rationale of each module."
        },
        {
            "title": "Critic Refinement",
            "content": "You are the Refinement Agent in multi-agent scientific research system. Your goal is to consolidate and refine outputs from the Dataset Analyst, Problem Investigator, and Baseline Assessor agents into unified, actionable analysis. # Role Description: The Refinement Agent is meta-agent focused on cross-validating consistency across different analytical components. This includes resolving contradictions, aligning terminology, and ensuring biological relevance and technical feasibility of proposed models and evaluation frameworks. The agent serves as the integration point for all upstream analyses. # Skills: Cross-validating consistency across different analytical components Resolving contradictions and aligning terminology Evaluating biological relevance and technical feasibility Structuring outputs into unified JSON schemas Generating comprehensive refinement comments Providing actionable improvement suggestions # Objectives: Ensure consistency in terminologies and constraints across all outputs Align problem definitions with model assumptions 81 Reorganize content into clean JSON schemas suitable for automated use Validate biological and technical coherence of the integrated analysis Provide final recommendations balancing biological relevance and technical feasibility # Input: You will receive: Analysis results from Dataset Analyst, Problem Investigator, and Baseline Assessor Refinement comments from previous iterations RAG system results including relevant papers and code snippets Instructions: Produce refined analysis report with the following components: { \"summary\": { \"biological_context\": \"string\", \"technical_requirements\": \"string\", \"refinement_overview\": \"string\" }, \"task_definition\": { \"input_modalities\": [...], \"output_targets\": \"string\", \"task_type\": \"regression/classification/generation/other\", \"biological_significance\": \"string\" }, \"baseline_models\": { \"recommended_models\": [...], \"model_comparisons\": [...], \"implementation_details\": \"string\" }, \"constraints\": { \"dataset_limitations\": [...], \"technical_constraints\": [...], \"biological_constraints\": [...] }, \"evaluation\": { \"primary_metrics\": [...], \"secondary_metrics\": [...], \"validation_strategy\": \"string\", \"test_scenarios\": [...] } } In addition to the structured JSON, write short explanation (100250 words) that: Summarizes the refinement process and key adjustments made Explains how the integrated analysis addresses biological and technical requirements Discusses remaining challenges or limitations Suggests potential extensions or future work # Constraints: Maintain consistency in terminology across all components Ensure alignment between problem formulation and model capabilities Validate that evaluation metrics reflect both technical accuracy and biological significance Provide concrete implementation details for recommended approaches Format outputs to facilitate direct use in downstream architecture design # Style Guide: Write in the tone of methods integration section for computational biology paper Use precise language describing both technical and biological considerations Clearly distinguish between established knowledge and speculative improvements Format recommendations to facilitate direct implementation Include both biological validation strategies and technical validation methods 82 P.3 Multi-experts Settings"
        },
        {
            "title": "Data Expert",
            "content": "You are acting as **Data Engineer** in multi-agent research critique system. Your task is to evaluate the provided dataset and experimental setup from data engineering and infrastructure perspective. You will receive task analysis report that includes: - summary of single-cell perturbation dataset (in structured or free-text form). - The task formulation and its corresponding prediction targets. - Metadata schemas and any available preprocessing or encoding steps. - Optional: access to inferred feature matrices, cell/gene count distributions, or batch annotations. Your objectives: 1. Assess Data Integrity and Format - Are the cell and gene identifiers standardized and consistently used? - Is the perturbation metadata properly aligned and encoded? - Are there signs of data leakage, missing values, or corrupted entries? 2. Evaluate Preprocessing Pipelines - Comment on normalization, batch correction, filtering, and feature selection steps. - Are the preprocessing steps appropriate for downstream modeling? 3. Assess Data Scalability and Efficiency - Is the dataset efficiently stored and structured (e.g., sparse matrix, HDF5)? - Can it be easily integrated with common ML frameworks (e.g., PyTorch, TensorFlow, scikit-learn)? - Are large-scale operations (sampling, merging, batching) feasible? 4. Suggest Improvements or Optimizations - Recommend preprocessing adjustments, format conversions, or data storage alternatives. - Point out any engineering bottlenecks that might affect reproducibility or scalability."
        },
        {
            "title": "Model Architecture Expert",
            "content": "You are acting as Model Architecture Expert in multi-agent research critique system. Your task is to analyze and optimize the structural design of the proposed model. You will receive task analysis report that includes: - Task specification (input type, target prediction, expected invariances). - baseline model description or proposed architecture diagram. - echnical constraints (e.g., compute, latency, interpretability ). Your objectives: 1. Deconstruct Architectural Choices - Analyze core design (e.g., encoder-decoder, attention, residuals). 83 - Is the architecture aligned with inductive priors from the data/task? 2. Evaluate Module Interactions - Are modality fusions or skip connections implemented properly? - Are graph structures or latent bottlenecks justified? 3. Spot Redundancies or Inefficiencies - Are there unnecessary layers, repeated computations, or excessive parameters? 4. Propose Optimized Designs - Recommend improved architecture patterns. - Suggest changes that enhance expressivity, stability, or efficiency."
        },
        {
            "title": "Deep Learning Expert",
            "content": "You are acting as Deep Learning Expert in multi-agent research critique system. Your task is to evaluate the model design, scalability, and suitability for learning from high-dimensional single-cell data. You will receive task analysis report that includes: - Input-output schema of the learning task (e.g., input modalities, targets, sample size). - Model class (e.g., MLP, Transformer, VAE, GNN) and architecture sketch. - Training setup including loss functions and evaluation metrics. Your objectives: 1. Evaluate Model Suitability - Is the model architecture appropriate for the data type and task complexity? - Does it support integration across modalities or time points? 2. Assess Scalability and Inductive Bias - Can the model scale with data size and sparse inputs? - Does it exploit structure in the data (e.g., gene graphs, batch embeddings)? 3. Identify Training Bottlenecks or Risks - Is overfitting likely due to low data:parameter ratio? - Are optimization challenges (e.g., vanishing gradients, instability) addressed? 4. Recommend Enhancements - Suggest architecture variants (e.g., regularization, pretraining, latent modeling). - Propose alternative loss designs or data augmentations"
        },
        {
            "title": "Training Expert",
            "content": "You are acting as Training Expert in multi-agent research critique system. Your role is to critically evaluate the training strategy and optimization pipeline. You will receive task analysis report that includes: - Model structure and parameter count. - Training procedure (e.g., optimizer, learning rate, batch size, scheduler). - Regularization strategies and data augmentation steps. Your objectives: 1. Analyze Optimization Pipeline 84 - Are optimizers and learning rates well-tuned for the model/ task? - Is gradient clipping or scheduler use justified? 2. Evaluate Regularization and Overfitting Risks - Are dropout, weight decay, or early stopping applied effectively? - Is data augmentation sufficient and biologically reasonable ? 3. Diagnose Training Stability - Any signs of mode collapse, oscillation, or vanishing gradients? 4. Recommend Training Enhancements - Suggest better optimizers, learning rate schedules, or initialization schemes. - Propose curriculum learning or contrastive pretraining if beneficial."
        },
        {
            "title": "Drug Response Expert",
            "content": "You are acting as Drug Response Expert in multi-agent scientific design system. Your role is to assess the biological and pharmacological feasibility of drug perturbation modeling based on the provided single-cell dataset and task formulation. You will receivea task analysis report that includes: - summary of the perturbation dataset, including drug names, target pathways, dosage, and timing. - The biological context (e.g., cell types, disease states, assay modality). - Task objective and prediction targets. Your objectives: 1. Evaluate Drug Perturbation Validity - Are the drugs applied at biologically relevant concentrations and durations? - Are the perturbations expected to have measurable effect at the single-cell level? - Are there known resistance mechanisms or compensatory pathways? 2. Assess Target Coverage and Specificity - Do the drug targets align with the measured omics modality (e.g., RNA for transcriptional drugs)? - Are off-target effects likely to interfere with interpretation? 3. Recommend Improvements or Adjustments - Suggest better dosage choices or controls. - Recommend alternative compounds or combinations that better elicit the intended perturbation."
        },
        {
            "title": "Pathway Expert",
            "content": "You are acting as Pathway Expert in multi-agent biological reasoning system. Your role is to evaluate the alignment between experimental perturbations (e.g., gene knockout or cytokine induction) and known biological signaling pathways. You will receive task analysis report that includes: - summary of perturbation targets (genes or cytokines). - Downstream measurements (e.g., RNA, ATAC, surface proteins). - Known pathway annotations or inferred gene modules (optional). 85 Your objectives: 1. Assess Biological Plausibility - Does the perturbation target belong to well-characterized signaling pathway? - Are expected downstream genes or modules represented in the dataset? 2. Predict Downstream Effects - Based on pathway topology, what cell states or features are expected to change? - Are these detectable in the available omics modality? 3. Suggest Enhancements - Recommend additional perturbations to validate pathway effects. - Propose experimental readouts to strengthen pathway conclusions."
        },
        {
            "title": "Cell Communication Expert",
            "content": "You are acting as Cell Communication Expert in multi-agent single-cell modeling system. Your role is to evaluate whether intercellular signaling contributes to the cytokine response captured in the dataset. You will receive task analysis report that includes: - single-cell dataset containing cytokine expression or response. - Cell-type annotations and spatial or pseudo-spatial information if available. - Metadata on cytokine stimulation protocols or inferred ligandreceptor pairs. Your objectives: 1. Identify Communication Patterns - Are there likely paracrine or autocrine effects influencing cytokine expression? - Do ligand-expressing cells co-occur with receptor-positive target cells? 2. Evaluate Impact on Task - Could intercellular signaling confound or explain observed cytokine responses? - Are current assays sufficient to separate intrinsic vs. extrinsic effects? 3. Recommend Additions - Suggest experiments (e.g., co-culture, transwell) to isolate signaling effects. - Recommend including spatial transcriptomics if necessary."
        },
        {
            "title": "Omics Modality Expert",
            "content": "You are acting as an Omics Modality Expert in multi-agent model evaluation system. Your role is to assess whether the chosen data modality (e.g., RNA-seq, ATAC-seq, protein) is suitable for capturing the effects of the specified perturbation. You will receive task analysis report that includes: - single-cell perturbation dataset with modality metadata. - Task objective and prediction targets. - Optional: known regulatory links (e.g., enhancer-promoter pairs, TF motifs, signaling cascades). 86 Your objectives: 1. Evaluate Signal Availability - Is the measured modality expected to show downstream effects of the perturbation? - Are known markers or targets captured by the modality? 2. Assess Measurement Resolution - Does the modality offer sufficient resolution (gene-level, peak-level, surface protein) to model the task? 3. Suggest Modality Enhancements - Recommend complementary modalities (e.g., ATAC + RNA) if needed. - Propose targeted panels or multi-omics techniques to improve interpretability."
        },
        {
            "title": "Q Detailed outputs from CellForge",
            "content": "Q.1 Data Parser The input is Norman et al. [75] Dataset in h5ad format."
        },
        {
            "title": "Data Parser Output",
            "content": "Modality:RNA Perturbation type:CRISPRa dataset_index: filtered Title: Exploring genetic interaction manifolds constructed from rich single-cell phenotypes Organisms: Homo sapiens Modality = Data type: RNA Method: Perturb-seq Tissues: K562 Perturbation: CRISPRa disease: chronic myelogenous leukemia celltype: lymphoblasts tissue type: cell_line Mini-Abstract (loosely summarized original Abstract): Here, the authors present an analytical framework for interpreting high-dimensional landscapes of cell states (manifolds) constructed from transcriptional phenotypes. They applied this approach to Perturb-seq profiling of strong genetic interactions (GIs) mined from growth-based, gain-offunction GI map. Exploration of this manifold enabled ordering of regulatory pathways, principled classification of GIs (e.g., identifying suppressors), and mechanistic elucidation of synergistic interactions. Finally, they applied recommender system machine learning to predict interactions, facilitating exploration of vastly larger GI manifolds. contains guide_id read_count UMI_count coverage gemgroup ... nperts ngenes ncounts percent_mito percent_ribo TTGAACGAGACTCGGA ARID1A_NegCtrl0;ARID1A_NegCtrl0 28684 1809 15.856274 2 ... 1 3079 15097.0 5.815725 33.569583 CGTTGGGGTGTTTGTG BCORL1_NegCtrl0;BCORL1_NegCtrl0 18367 896 20.498884 7 ... 1 2100 8551.0 4.104783 45.842592 GAACCTAAGTGTTAGA FOSB_NegCtrl0;FOSB_NegCtrl0 16296 664 24.542169 6 ... 1 2772 10999.0 5.655060 17.801618 CCTTCCCTCCGTCATC SET_KLF1;SET_KLF1 16262 850 19.131765 4 ... 5385 38454.0 4.335050 38.165080 TCAATCTGTCTTTCAT OSR2_NegCtrl0;OSR2_NegCtrl0 16057 1067 15.048735 2 ... 1 4869 27926.0 5.084867 32.317554 ... ... ... ... ... ... ... ... ... ... ... ... TTTGCGCAGTCATGCT RHOXF2_NegCtrl0;RHOXF2_NegCtrl0 1 1 1.000000 2 ... 1 1853 5192.0 5.508475 31.798921 TTTGCGCCAGGACCCT BCL2L11_BAK1;BCL2L11_BAK1 1 1 1.000000 3 ... 2 3508 15704.0 6.718034 38. TTTGCGCGTACTTGAC-1 CNN1_NegCtrl0;CNN1_NegCtrl0 1 1 1.000000 3 ... 1 3609 15054.0 5.633054 29.440680 TTTGCGCTCTCGCATC-1 CEBPB_OSR2;CEBPB_OSR2 1 1 1.000000 6 ... 2 2576 6825.0 2.695971 16.879121 TTTGGTTGTTCCGTCT MAP2K3_MAP2K6;MAP2K3_MAP2K6 1 1 1.000000 2 ... 2 2499 8331.0 5.617573 34. [111445 rows 20 columns] --- obs Index([guide_id, read_count, UMI_count, coverage, gemgroup, good_coverage, number_of_cells, tissue_type, cell_line, cancer, disease, perturbation_type, celltype, organism, 88 perturbation, nperts, ngenes, ncounts, percent_mito, percent_ribo], dtype=object) good_coverage number_of_cells tissue_type cell_line ... perturbation_type celltype organism perturbation TTGAACGAGACTCGGA True 1 cell_line K562 ... CRISPR lymphoblasts human ARID1A CGTTGGGGTGTTTGTG True 1 cell_line K562 ... CRISPR lymphoblasts human BCORL1 GAACCTAAGTGTTAGA True 1 cell_line K562 ... CRISPR lymphoblasts human FOSB CCTTCCCTCCGTCATC True 1 cell_line K562 ... CRISPR lymphoblasts human SET_KLF1 TCAATCTGTCTTTCAT True 2 cell_line K562 ... CRISPR lymphoblasts ... ... ... ... ... ... ... ... ... ... TTTGCGCAGTCATGCT False 0 cell_line K562 ... CRISPR lymphoblasts human OSR human RHOXF2 TTTGCGCCAGGACCCT False 0 cell_line K562 ... CRISPR lymphoblasts human BCL2L11_BAK1 TTTGCGCGTACTTGAC-1 False 0 cell_line K562 ... CRISPR lymphoblasts human CNN1 TTTGCGCTCTCGCATC-1 False 0 cell_line K562 ... CRISPR lymphoblasts human CEBPB_OSR2 TTTGGTTGTTCCGTCT False 0 cell_line K562 ... CRISPR lymphoblasts human MAP2K3_MAP2K6 [111445 rows 10 columns] --- var ensemble_id ncounts ncells RP11-34P13.3 ENSG00000243485 29.0 29 FAM138A ENSG00000237613 0.0 0 OR4F5 ENSG00000186092 0.0 0 RP11-34P13.7 ENSG00000238009 266.0 265 RP11-34P13.8 ENSG00000239945 10.0 10 ... ... ... ... AC233755.2 ENSG00000277856 0.0 0 AC233755.1 ENSG00000275063 0.0 0 AC240274.1 ENSG00000271254 11735.0 10835 AC213203.1 ENSG00000277475 0.0 0 FAM231B ENSG00000268674 0.0 [33694 rows 3 columns] --- shape (111445, 33694) Q.2 Agentic Retrieval"
        },
        {
            "title": "Example Agentic Retrieval Output",
            "content": "Keywords: Norman Weissman 2019 Perturb-seq CRISPRa K562 single cell perturbation prediction Round 1: Initial DFS Search (one example branch) Keywords: single cell perturbation prediction (what is -> how to solve) Learning single-cell perturbation responses using neural optimal transport...{Nature Link} Modeling and predicting single-cell multi-gene perturbation responses...{PMC Link} 89 Explainable modeling of single-cell perturbation data using Bayesian hierarchical modeling...{Cell Press Link} Multiplexed Single-Cell CRISPR Screening...{Cell Press Link} Predicting transcriptional outcomes of novel perturbations...{ PMC Link} Modeling and predicting single-cell multi-gene perturbation responses...{PMC Link} Exploring genetic interaction manifolds...{PMC Link} Predicting transcriptional outcomes of novel perturbations...{ PMC Link} In-silico biological discovery with large-scale perturbation data{arXiv Link} DeepChrome 2.0: Investigating and modeling chromatin accessibility...{arXiv Link} Predicting the genetic component of gene... {arXiv Link} genome-scale deep learning model to pre...{arXiv Link} Attention-based Interpretable Regression...{arXiv Link} GATES: Graph Network...{arXiv Link} GRNFormer: Biologically...{arXiv Link} Round 2: BFS Search (one example branch) Key words:state-of-the-art models for single-cell perturbation prediction GEARS: Predicting transcriptional outcomes of novel multi-gene perturbations{nature Link} scGPT: Is language all you need for modeling single-cell perturbation responses{nature Link} Geneformer - BioNeMo Framework for Genomic Language Modeling{ nature link} Efficient Fine-Tuning of Single-Cell Foundation Models for Perturbation Prediction...{arXiv Link} Multicell-Fold: geometric learning in folding...{PMC Link} Variational Mixtures of ODEs for Inferring Cellular...{ICML} DeepChrome 2.0: Investigating and modeling chromatin accessibility...{arXiv Link} Predicting the genetic component of gene...{Bioinformatics} genome-scale deep learning model to pre...{PMC Link} Round 3: DFS Search (one example branch) Keywords: GEARSscGPTGeneformerMulticell-FoldDeepChrome 2.0... GEARS: Predicting transcriptional outcomes of novel multi-gene perturbations{nature Link} Predicting transcriptional outcomes of novel multigene perturbations with GEARS...{nature Link} snap-stanford/GEARS {Github Link} scGPT: Is language all you need for modeling single-cell perturbation responses{nature Link} bowang-lab/scGPT{Github Link} Geneformer - BioNeMo Framework for Genomic Language Modeling{ nature link} jkobject/geneformer {Github Link} Multicell-Fold: geometric learning in folding...{PMC Link} bm2-lab/scPerturBench{Github Link} DeepChrome 2.0: Investigating and modeling chromatin accessibility...{arXiv Link} DeepChrome/DeepChrome2.0{Github Link} ....... Round 4: BFS Search (one example branch) Keywords: TransformerVAE... (used by models for single-cell perturbation prediction) TransVAE: Giving Attention to Generative VAE Models for De Novo Molecular Design{https://github.com/oriondollar/TransVAE}{ GitHub Link} Transformer Graph Variational Autoencoder for Generative Molecular Design{https://www.biorxiv.org/content /10.1101/2024.07.22.604603v1.full.pdf}{Paper Link} novel molecule generative model of VAE combined with Transformer{https://arxiv.org/pdf/2402.11950}{arxiv Link} 90 Graph VAE and Graph Transformer Approach to Generating{https ://arxiv.org/abs/2104.04345}{arxiv Link} Large Scale GNN and Transformer Models and for Genomics{https:// qdata.github.io/deep2Read//talks-mb2019/Jack_20190530LargeScaleGNNTransformer.pdf} Round 5: DFS Search ...... 91 Q.3 Task Analysis Report"
        },
        {
            "title": "Data Analyst Output\nTask Analysis",
            "content": "### Introduciton - **Modalities**: RNA (single-cell RNA-seq) - **Perturbation Type**: CRISPRa (activation) - **Conditions**: 1,092 unique perturbation conditions including: - 105 single-gene perturbations - 131 paired-gene perturbations - **Timepoints**: Not explicitly reported (likely single timepoint) - **Replicates**: Present (multiple cells per perturbation condition) - **Batches**: Likely present due to sequencing logistics - **Cell Types**: K562 cells (chronic myelogenous leukemia cell line) - **Organism**: Homo sapiens - **Description**: This Perturb-seq experiment profiles transcriptional responses in K562 cells following CRISPRa perturbations. The dataset captures both single and paired genetic perturbations, providing insight into genetic interaction networks. ### Data Properties - **Number of Cells**: 111,445 - **Number of Genes**: 33,694 - **Features**: - **RNA**: 33,694 genes - **ATAC**: Not available - **Protein**: Not available - **Perturbation Targets**: - **Unique Perturbations**: 105 single genes and 131 gene pairs - **Target Type**: Genes and gene pairs - **Coverage**: Sparse (many genes show no expression change) - **Modality Completeness**: RNA data available for all cells with appropriate quality control metrics - **Metadata Completeness**: Comprehensive perturbation annotations, technical covariates (UMI_count, percent_mito, percent_ribo), and cell barcodes - **Preprocessing Required**: - Normalization of UMI counts - Log-transformation of expression values - Filtering of lowly expressed genes - Batch effect correction ### Quality Assessment - **Data Sparsity**: 78% of gene expression values are zero due to dropout events and biological sparsity - **Batch Effect**: Potential technical variability from different sequencing runs - **Replicate Consistency**: Not explicitly reported but suggested by reproducibility of common perturbations - **Known Issues**: - Extreme class imbalance (some perturbations appear only once) - High dimensionality with 33,694 genes per output - Technical noise inherent to single-cell sequencing - **Strengths**: - Rich perturbation annotations with precise gene targeting - Large number of profiled cells providing statistical power - Comprehensive technical covariates enabling noise correction - **Limitations**: - High dimensionality challenges - Sparse perturbation distribution 92 - Potential confounding from clonal expansion ### Recommendations - **Preprocessing Steps**: - Filter genes with fewer than 10 counts across all cells - Normalize UMI counts using library size factors - Apply log-transformation (log1p) to expression values - Combat batch effects using Harmony or Scanorama - **Modeling Considerations**: - Focus modeling efforts on the top 5,000-10,000 variable genes - Use sparse-aware models (e.g., sparse neural networks) - Incorporate technical covariates as model inputs - Implement data augmentation for rare perturbations - **Open Questions**: - Optimal representation of paired perturbations in model architecture - Strategies for handling extreme class imbalance in training - Best practices for integrating technical covariates ### Refinement Suggestions - Investigate the impact of clonal expansion on expression profiles - Assess the quality of rare perturbation data for potential filtering - Explore data augmentation techniques for underrepresented perturbations - Develop quality control metrics specific to Perturb-seq data"
        },
        {
            "title": "Task Analysis",
            "content": "### Biological Question How do genetic perturbations propagate through gene regulatory networks to alter the transcriptional landscape of K562 cells, and can we predict these changes for novel perturbations and cellular contexts? ### Hypothesis Statement predictive model can accurately estimate post-perturbation gene expression profiles by learning the complex relationships between baseline cell states, genetic perturbations, and transcriptional responses, including nonlinear genetic interaction effects. ### Task Formulation - **Input**: - **Output**: - **Task Type**: - Baseline gene expression profile (33,694 genes) - Perturbation identities (single or paired genes) - Technical covariates (UMI_count, percent_mito, percent_ribo) - Post-perturbation gene expression profile (33,694 genes) - High-dimensional regression with combinatorial inputs ### Justification - **Biological Relevance**: - Understanding genetic interactions is fundamental to deciphering cellular response networks - Mapping genotype-phenotype relationships at single-cell resolution - Predicting cellular responses to novel perturbations accelerates functional genomics research - **Data Suitability**: 93 - Rich perturbation annotations enable supervised learning approaches - Single-cell resolution captures heterogeneity in cellular responses - Coverage of both single and paired perturbations allows study of genetic interactions - **Expected Challenges**: - High-dimensional output space with 33,694 genes per prediction - Non-linear genetic interactions requiring complex model architectures - Generalization to unseen perturbations and cellular contexts - Technical noise and dropout events in single-cell data ### Evaluation Plan - **Metrics**: - Pearson Correlation Coefficient (PCC) across all genes and on top 1,000 differentially expressed genes(DE) - Mean Squared Error (MSE) across all genes and for differentially expressed genes - score across all genes and for differentially expressed genes - **Baselines to Consider**: - Linear regression models with gene-level outputs - Gene-wise neural networks - Graph neural networks using known regulatory interactions - **Validation Strategy**: - Stratified group k-fold cross-validation holding out entire perturbation conditions - Separate validation sets for unseen single-gene and paired perturbations - Baseline profile holdout sets to test generalization to new cellular contexts ### Open Questions - Optimal representation of paired perturbations in model architecture - Strategies for handling extreme class imbalance during training - Incorporation of technical covariates into model architecture - Best practices for defining differentially expressed genes in this context"
        },
        {
            "title": "Task Analysis",
            "content": "### Literature Overview - **Perturbation Types**: - CRISPRi (interference) - CRISPRa (activation) - **Existing Methods**: - GEARS: Graph neural network with gene interaction modeling - scGPT: Transformer architecture for single-cell data - Geneformer: Pretrained transformer for genomics - scLAMBDA: Variational autoencoder for perturbation prediction - **VAE (Variational Autoencoder)**: Probabilistic model for learning latent representations of cellular states - **Technical Trends**: - Transformer architectures for capturing long-range dependencies - Graph neural networks for explicit gene interaction modeling - Variational autoencoders for probabilistic modeling of cellular states - Hybrid models combining multiple data modalities 94 - Deep generative models for data augmentation and uncertainty quantification ### Candidate Models #### GEARS (Gene Network Embedding for Perturbation Response Prediction) - **Architecture**: Graph Neural Network (GNN) combined with Multi-Layer Perceptron (MLP) - Explicitly models gene dependencies using known regulatory - Handles combinatorial perturbations through graph propagation - Demonstrated success in previous Perturb-seq challenges - **Strengths**: interactions - **Weaknesses**: - Relies on external gene interaction databases - May overfit to common perturbations with limited generalization - Computationally intensive for full transcriptome modeling - **Biological Applicability**: - Captures genetic interactions and regulatory relationships - Models enhancer-promoter relationships in K562 cells - Provides interpretable gene importance scores #### scGPT (Single-Cell Generative Perturbation Transformer) - **Architecture**: Transformer with multi-head self-attention - **Strengths**: - Captures long-range gene interactions without relying on external databases - Robust to technical noise through attention mechanisms - Handles variable numbers of perturbations naturally - **Weaknesses**: - Requires extensive pretraining on large datasets - Computationally demanding for full transcriptome modeling - May struggle with extreme class imbalance - **Biological Applicability**: - Models context-dependent transcriptional responses - Handles sparse data efficiently through attention mechanisms - Provides gene importance scores through attention weights #### Enformer (Enhancer former) - **Architecture**: Dilated Convolutional Neural Network (CNN) - **Strengths**: - Effective at modeling sequence-to-expression relationships - Provides interpretable feature importance scores - Computationally efficient compared to transformer architectures - **Weaknesses**: - Requires DNA sequence input not directly applicable to posttranscriptional perturbations - Limited ability to model combinatorial genetic effects - Not designed for single-cell data with technical covariates - **Biological Applicability**: - Predicts expression changes from DNA sequence modifications - Limited utility for CRISPRa perturbations affecting posttranscriptional regulation ### Recommended Baselines #### Graph Neural Network (GNN) with Gene Interaction Modeling - **Rationale**: Explicitly models gene dependencies and can incorporate known regulatory interactions while remaining flexible to learn from data - **Implementation Details**: - Use PyTorch Geometric for efficient graph operations - Construct gene interaction graphs from public databases (e.g ., STRING, BioGRID) 95 - Implement separate graph branches for regulatory and coexpression relationships - Include attention mechanisms to weight different interaction types - Embed perturbation identities using learned gene embeddings - Concatenate baseline expression features with perturbation embeddings - Apply multiple GNN layers followed by dense layers for prediction - **Evaluation Metrics**: PCC, MSE, - **Biological Relevance**: Captures genetic interactions and regulatory mechanisms, providing insight into how perturbations propagate through networks #### Transformer Architecture with Gene Positional Encoding - **Rationale**: Capable of discovering complex gene interactions without relying on external databases, with architectural flexibility for different input modalities - **Implementation Details**: - Use PyTorch with Hugging Face transformer libraries - Encode genes as positional tokens with expression values - Implement specialized embeddings for perturbed genes - Apply layer normalization and residual connections - Use mixed precision training to handle large output dimensions - Implement masking for rare perturbations during training - Apply attention pooling to focus on biologically relevant genes - **Evaluation Metrics**: PCC, MSE, - **Biological Relevance**: Models context-dependent responses and technical noise robustly, providing flexibility to adapt to different biological questions #### VAE (Variational Autoencoder) - **Architecture**: Encoder-decoder architecture with probabilistic latent space - **Strengths**: responses - Models uncertainty in cellular states and perturbation - Effective for data augmentation through generation of new cellular states - Provides compressed latent representations for downstream analysis - Handles sparse and noisy single-cell data well - **Weaknesses**: space - May oversimplify complex biological relationships in latent - Requires careful tuning of KL divergence weighting - Potential blurring of distinct cellular states in latent space - **Biological Applicability**: - Captures multimodal distributions of cellular responses - Enables exploration of cellular state transitions following perturbations - Provides robust representations for classifying cellular phenotypes VAE with Perturbation Conditioning: - **Rationale**: Models uncertainty in cellular responses and provides robust latent representations for downstream analysis while enabling data augmentation - **Implementation Details**: - Use PyTorch for flexible probabilistic modeling - Implement encoder-decoder architecture with probabilistic latent space - Include perturbation identities as conditional inputs to the decoder - Apply beta-VAE regularization to balance reconstruction and latent space regularization 96 - Implement sparse VAE modifications to handle zero-valued genes - Use importance weighting for rare perturbations during training - Apply latent space interpolation to explore cellular state transitions - **Evaluation Metrics**: PCC, MSE, R, ELBO (Evidence Lower Bound) - **Biological Relevance**: Captures multimodal distributions of cellular responses, enables exploration of cellular state transitions, and provides robust representations for classifying cellular phenotypes ### Evaluation Framework - **Primary Metrics**: - PCC for differentially expressed genes - MSE for differentially expressed genes - for differentially expressed genes - **Secondary Metrics**: - Global PCC across all genes - Global MSE across all genes - Classification accuracy for key gene up/down regulation - ELBO for VAE models - **Validation Strategy**: Stratified group k-fold crossvalidation holding out entire perturbation conditions - **Test Scenarios**: - Unseen single-gene perturbations - Unseen paired perturbations with one known gene - Completely novel gene pairs - Baseline profiles from held-out cell subsets ### Improvement Suggestions - **Technical**: relevant genes - Incorporate attention mechanisms to focus on biologically - Apply data augmentation for rare perturbations (e.g., mixup, elastic deformation) - Use mixed precision training to reduce memory requirements - Implement gradient checkpointing for deeper architectures - Experiment with different VAE architectures (e.g., VAE-GCN, VAE-Transformer) - **Biological**: - Integrate known regulatory interactions as model priors - Focus modeling efforts on biologically relevant gene subsets - Model cell cycle effects using phase markers - Incorporate chromatin accessibility information when available - Use VAE latent space for phenotypic classification and clustering - **Computational**: - Optimize for sparse operations to handle zero-valued genes efficiently - Implement efficient parallel processing strategies - Use model pruning to reduce parameters while maintaining performance - Apply distributed training for VAE models with large latent spaces"
        },
        {
            "title": "Task Analysis",
            "content": "### Summary - **Biological Context**: Predicting transcriptional responses to CRISPR perturbations in K562 cells requires modeling 97 complex genetic interactions and cellular context dependencies while generalizing to novel perturbations - **Technical Requirements**: Handling high-dimensional sparse data, extreme class imbalance, and the need for inductive generalization - **Refinement Overview**: Integration of dataset analysis, problem formulation, and baseline recommendations into cohesive analysis plan with aligned terminology and evaluation metrics ### Task Definition - **Input Modalities**: - Baseline gene expression profile (33,694 genes) - Perturbation identities (single or paired genes) - Technical covariates (UMI_count, percent_mito, percent_ribo) - **Output Targets**: Post-perturbation gene expression profile (33,694 genes) - **Task Type**: High-dimensional regression with combinatorial inputs - **Biological Significance**: Enables understanding of genetic interaction networks and prediction of cellular responses to novel perturbations ### Baseline Models - **Recommended Models**: - Graph Neural Network (GNN) - Transformer Architecture - VAE with Perturbation Conditioning - **Model Comparisons**: regulatory networks - GNNs excel at explicit gene interaction modeling using known - Transformers offer flexible interaction discovery without relying on external databases - VAEs provide probabilistic modeling of cellular states and enable data augmentation - **Implementation Details**: - Implement GNNs with PyTorch Geometric using gene interaction graphs derived from prior knowledge - Implement Transformers with PyTorch/Hugging Face using gene positional encoding - Implement VAEs with PyTorch using conditional latent spaces for perturbation modeling - Include specialized embeddings for perturbations and normalize technical covariates - Apply mixed precision training and gradient checkpointing for efficiency ### Constraints - **Dataset Limitations**: - Class imbalance with rare perturbations appearing only once - Data sparsity with 78% zero-valued genes - Potential batch effects from different sequencing runs - **Technical Constraints**: - Computational resources for training large models on full transcriptome data - Model interpretability requirements for biological validation - **Biological Constraints**: - Need for generalization to unseen perturbations and cellular contexts - Model must align with known regulatory mechanisms where possible - Focus on biologically relevant gene subsets to avoid overfitting ### Evaluation - **Primary Metrics**: 98 - PCC across all genes and for differentially expressed genes ( top 1,000) - MSE across all genes and for differentially expressed genes - across all genes andfor differentially expressed genes - **Validation Strategy**: Stratified group k-fold crossvalidation holding out entire perturbation conditions - **Test Scenarios**: - Unseen single-gene perturbations - Unseen paired perturbations with one known gene - Completely novel gene pairs - Baseline profiles from held-out cell subsets"
        },
        {
            "title": "Task Analysis",
            "content": "Task Analysis # Biological Objective Predict post-perturbation gene expression profiles in K562 cells to understand genetic interaction networks and enable discovery of novel regulatory mechanisms. This work aims to develop computational tool for exploring genetic interaction manifolds, accelerating functional genomics research and therapeutic target discovery. # Technical Approach Develop high-dimensional regression models incorporating baseline expression, perturbation identities, and technical covariates. The models must explicitly handle sparse data, extreme class imbalance, and demonstrate inductive generalization to novel perturbations and cellular contexts. The plan includes exploration of deterministic models (GNNs, Transformers) and probabilistic models (VAEs) to capture different aspects of cellular response variability. # Dataset Characterization ## Origin Norman et al. (2019) Perturb-seq dataset (GEO: GSE133344). Key Features Number of Cells: 111,445 Number of Genes: 33,694 Perturbation Conditions: 1,092 unique conditions (105 single genes, 131 gene pairs) Technical Covariates: UMI_count, percent_mito, percent_ribo ## Challenges Class Imbalance: Rare perturbations appear only once. Data Sparsity: 78% zero-valued genes due to dropout events. Technical Noise: Inherent to single-cell sequencing. Batch Effects: Potential variability from different sequencing runs. # Problem Formulation ## Biological Question How do genetic perturbations propagate through gene regulatory networks to alter the transcriptional landscape of K562 cells, and can we predict these changes for novel perturbations and cellular contexts? ## Hypothesis Statement predictive model can accurately estimate post-perturbation gene expression profiles by learning the complex relationships between baseline cell states, genetic perturbations, and transcriptional responses, including nonlinear genetic interaction effects. ## Task Definition ### Input: Baseline gene expression profile (33,694 genes) Perturbation identities (single or paired genes) Technical covariates (UMI_count, percent_mito, percent_ribo) ### Output: Post-perturbation gene expression profile (33,694 genes) ###Task Type: High-dimensional regression with combinatorial inputs ## Justification Biological Relevance: Understanding genetic interactions is fundamental to deciphering cellular response networks Mapping genotype-phenotype relationships at single-cell resolution Predicting cellular responses to novel perturbations accelerates functional genomics research Data Suitability: Rich perturbation annotations enable supervised learning approaches Single-cell resolution captures heterogeneity in cellular responses Coverage of both single and paired perturbations allows study of genetic interactions Expected Challenges: High-dimensional output space with 33,694 genes per prediction Non-linear genetic interactions requiring complex model architectures Generalization to unseen perturbations and cellular contexts Technical noise and dropout events in single-cell data The models performance will be evaluated under two key scenarios to assess its generalizability: - Unseen Perturbations: The model should be able to accurately predict the effects of CRISPRi targeting genes or gene pairs that were not included in the training data. This scenario tests the models ability to extrapolate its learned knowledge to novel genetic manipulations. - Unseen Cell Contexts: The model should be capable of predicting the response to perturbation in cells with baseline gene expression profiles that were not observed during the training phase. This evaluates the models robustness to the inherent heterogeneity within the K562 cell population. # Baseline Model Analysis **SOTA**: GEARS achieves best Pearson correlation in combinatorial prediction tasks but violates the \"no external database\" constraint . Below are detailed critiques of each baselines shortcomings in the context of the AdamsonWeissman UPR CRISPRi dataset, followed by concrete recommendationsgrounded in recent literaturefor how to overcome them. Each point is supported by highquality citations. 1. SC-GPT **Shortcomings:** 1). **Discrete Perturbation Tokens:** SC-GPT treats each perturbation (e.g. specific dualguide combination) as unique token. It cannot form embeddings for guide sets unseen in pretraining, so it fails on novel combinations 2). **No Zero-Inflated Modeling:** SC-GPTs Gaussian or crossentropy losses dont account for dropoutdriven zeros common in scRNA-seq, causing biased predictions for low-UMI cells 3). **Parameter Bloat for Dense Output:** Extending SC-GPTs languagemodel head to 35 kdimensional gene outputs inflates parameters, hindering training efficiency and generalization 2. GeneFormer **Shortcomings:** 1). **Single-Gene Focus:** GeneFormer has been validated primarily on singlegene knockouts, lacking mechanisms to ** compose** multiple guide embeddings for combinatorial CRISPRi 2). **Static Graph Priors:** It uses fixed genegene network that doesnt adapt to perturbationinduced regulatory rewiring in the UPR pathway, limiting dynamic response modeling 3. **Scalability Issues:** Fullgraph attention over 35 genes is intractable, so practical implementations subsample to 25 genesdiscarding potentially important UPR regulators 3. DEEP (Plain MLP) **Shortcomings:** 1). **Ignores Gene Covariance:** Treats each gene independently, missing co-regulation patterns (e.g., ATF6XBP1 axis in UPR) 2). **Overfitting Risk:** Millions of parameters on 35 inputs with limited replicates per combination leads to memorization, not generalization to unseen guide sets 3). **No Interpretability:** Provides no insight into which genes or interactions drive predictions, unlike graph-based or attention-based models. 4. GEARS **Shortcomings:** 1). **External Knowledge Dependency:** GEARS integrates genegene memory module (e.g., from STRING or GO) to regularize embeddings, which violates our no external database constraint 2). **Fixed Graph Structure:** The perturbation relationship graph in GEARS is static, not conditioned on cell-state or UPR context, limiting dynamic response capture. 3). **Heavy GNN Overhead:** Graph neural network message passing on 35 nodes multiple perturbations incurs high memory and compute costs, impractical for largescale CRISPRi screens. --- Recommendations for Improvement 1. **Factorized Perturbation Embeddings** - **Approach:** Learn separate embedding $e_{g}$ for each guide $g$. Represent perturbation set $P$ by **learned nonlinear composition**. - **Benefit:** Zeroshot support for unseen guide combinations via embedding arithmetic, as demonstrated by CPA and scGen 2. **Zero-Inflated Negative Binomial (ZINB) Loss** - **Approach:** Replace MSE with **ZINB loss** that models both dropout probability and overdispersion per gene. - **Benefit:** Accounts for scRNA-seq technical noise, improving prediction in low-UMI cells (e.g., 162 median UMI) 3. **Learned Dynamic Graph Priors** - **Approach:** Instead of fixed PPI graph, **learn genegene affinity weights** from data using **Gaussian 101 kernel** on baseline coexpression, then refine during training. - **Benefit:** Captures UPR pathway rewiring under CRISPRi; avoids external databases (matches constraints) 4. **Contrastive Pretraining** - **Approach:** Pretrain an encoder on (x,0) vs. (x,p) pairs with an ** InfoNCE contrastive loss**, pulling matched baselineperturbed embeddings together and pushing apart random mismatches. - **Benefit:** Disentangles baseline state from perturbation effect; enhances generalization to unseen contexts like new guide sets or cellcycle states 5. **Neural ODE or OT Trajectory Module** - **Approach:** For multiguide dynamics, model latent drift via **neural ODE** $dz/dt=f(z,hP)dz/dt = f(z,h_P)$ or ** optimaltransport regularization** linking $(x,p)to(x,p) $. - **Benefit:** Enforces smooth interpolation/extrapolation between perturbation levels (01 guide,,4 guides), capturing graded UPR responses 6. **Perturbation-Guided Attention Decoder** - **Approach:** Use **crossattention** layer where query = latent state, key/value = perturbation embedding $h_P$, then an attentionaugmented decoder to weight genes most impacted by UPR factors (e.g., ATF6 targets). - **Benefit:** Focuses model capacity on biologically salient genes; improves interpretability and reduces parameter count **Implementing these enhancements**factorized, compositional embeddings; ZINB loss; datadriven graph priors; contrastive pretraining; latent ODE/OT modules; and perturbationguided attentionwill address the key limitations of SC-GPT, GeneFormer, DEEP, GEARS. This integrated architecture can robustly predict singlecell transcriptomic responses to both seen and unseen CRISPRi perturbations in the UPR pathway, while respecting the no external database constraint and modeling lowsignal, highsparsity regimes. 102 Q.4 Graph based discussion"
        },
        {
            "title": "Graph Based Discussion Output",
            "content": "Round 1 subsection{Graph based discussion} label{app:graphbased_discussion_output} begin{green_template} textbf{Round 1} begin{lstlisting} **Data Preprocessing Expert**: The dataset contains over 1000,000 cells and 33,000 genes. Its quite large and very sparse. propose starting with log-normalization to handle the skewness in the data. We could also use PCA for dimensionality reduction to capture the main sources of variation. Maybe around 100-200 principal components would be good starting point. What do you all think? Confidence Score: 0. **Model Architecture Expert**: agree with the preprocessing steps. Given the complexity of gene regulatory networks, graph neural network (GNN) might be suitable to capture gene interactions. However, constructing the gene interaction graph is challenging. We could start with simple graph based on prior knowledge like protein-protein interaction networks. But our task is to predict the effects of unseen perturbations, so the model needs to be flexible enough to handle new genes not in the training set. Maybe combining GNN with gene embeddings could work. The embeddings can capture functional similarities between genes. Confidence Score: 0.74 **Training and Optimization Expert**: Training GNN on this scale will be computationally intensive. We need an efficient training strategy. suggest using learning rate scheduler to adjust the learning rate during training. Also, to prevent overfitting, especially with the high dimensionality, dropout layers should be incorporated. Given the potential class imbalance in the perturbation types, we might need to use weighted loss functions or some form of resampling. Confidence Score: 0.78 **Pathway Expert**: From biological standpoint, its crucial to model not just direct effects of perturbations but also downstream effects. Genes dont operate in isolation. perturbation to one gene can have cascading effects on many others. The model should ideally capture these dynamic changes. Also, cell-to-cell variability is significant in single-cell data. The model needs to account for this inherent noise. Confidence Score: 0.77 **Deep Learning Expert**: think incorporating attention mechanisms could help the model focus on the most relevant genes for each perturbation. Transformers have been successful in other areas of bioinformatics, particularly in capturing long-range dependencies. Maybe hybrid model that combines transformer architecture with GNNs would be powerful. The transformer can handle the gene expression data and the GNN can model the interactions. Also, using multi-task learning approach where the model predicts both the gene expression changes and the perturbation type could improve performance. Confidence Score: 0.77 **Critic**: The initial plan covers several important aspects, but the models generalization to unseen perturbations remains critical issue. The proposed GNN with gene 103 embeddings is solid foundation, but the reliance on prior knowledge for the gene interaction graph could be limitation. The data-driven approach suggested by the Critic Agent could mitigate this. Also, the training strategy needs to address the high dimensionality and sparsity effectively. The inclusion of contrastive learning component, as suggested by the Deep Learning Specialist, could enhance the models ability to distinguish different perturbation effects. However, the evaluation metrics should be clearly defined to assess both the predictive accuracy and biological relevance. Confidence Score: 0."
        },
        {
            "title": "Graph Based Discussion Output",
            "content": "Round 2 **Data Preprocessing Expert**: Ive thought more about the preprocessing. Besides PCA, we could use variational autoencoder (VAE) for dimensionality reduction. VAEs are generative models and might better capture the complex distributions in the data. Also, for handling the sparsity, adding step to impute missing values could be beneficial. Maybe using simple k-nearest neighbors imputation method. Confidence Score: 0.78 **Model Architecture Expert**: like the idea of combining transformers and GNNs. For the gene interaction graph in the GNN, perhaps we can construct it dynamically based on the data. Using the correlations between genes in the training data to build an adjacency matrix. This way, the graph is data-driven and doesnt rely solely on prior knowledge. Also, for the gene embeddings, we can initialize them with pretrained embeddings from resources like Gene2Vec and then fine-tune them during training. Confidence Score: 0.76 **Training and Optimization Expert**: Regarding training, suggest using the AdamW optimizer with OneCycle learning rate schedule. This schedule helps in finding good balance between the learning rate and the number of epochs. For handling class imbalance, focal loss could be an option. It focuses the training more on the hard-to-classify examples. Also, implementing gradient clipping will help prevent exploding gradients, which is important given the models complexity. Confidence Score: 0.80 **Pathway Expert**: agree with the need for dynamic modeling. The effects of perturbations arent instantaneous. Maybe incorporating recurrent component or using time-series approach could help model the progression of changes. Also, including cell cycle phase as covariate might improve predictions, as gene expression varies significantly across different phases. Confidence Score: 0.85 **Deep Learning Expert**: Ive considered the multi-task learning approach more. The model can have one branch predicting the gene expression changes and another branch classifying the perturbation type. This forces the model to learn features that are useful for both tasks. Also, using contrastive loss component could help the model distinguish between different perturbation effects more effectively. The transformers self-attention mechanism is particularly useful for capturing long-range dependencies in gene expression data, which could be crucial for understanding the downstream effects of perturbations. 104 Confidence Score: 0. **Critic**: Great to find our method more detailed. However, pretrained vectors are not wise choice. We need to fit in our task, meanwhile, balance cost and performance. The use of VAE for preprocessing and data-driven gene interaction graph are positive steps. For Gene embeddings, pre-trained vectors should be excluded, we should focus on design novel method and balance performance and cost. The multi-task learning and contrastive loss components add robustness. However, the evaluation strategy still needs clarification. We should define specific metrics for both predictive performance (MSE, PCC, R2) and biological relevance (MSE_DE, PCC_DE, R2_DE). Also, the models ability to handle combinatorial perturbations should be explicitly tested. Confidence Score: 0."
        },
        {
            "title": "Graph Based Discussion Output",
            "content": "Round 3 **Data Preprocessing Expert**: Ive further refined the preprocessing steps. After careful consideration, believe using combination of log-normalization, imputation for missing values, and PCA for dimensionality reduction will provide solid foundation for the model. Ive also added data augmentation techniques like adding Gaussian noise and random masking to improve model robustness. The lognormalization step is crucial for handling the skewness in the gene expression data, while the PCA helps in reducing noise and computational complexity. Confidence Score: 0.81 **Model Architecture Expert**: Ive updated the model architecture to better align with the training phases. The model now includes VAE for the gene expression data, separate embedding layer for perturbations, and transformer for capturing long-range dependencies. The dynamic graph construction based on data correlations addresses the concern about prior knowledge reliance. With the gene embeddings initialized from Gene2Vec, the model should have good starting point for capturing gene functionalities. The VAE is particularly useful for denoising and capturing the complex distributions in the data. Confidence Score: 0.82 **Training and Optimization Expert**: Ive adjusted the training strategy to include three phases: 1) VAE pretraining for 20 epochs, 2) Transformer integration for 30 epochs, and 3) Full fine-tuning with adversarial samples for 50 epochs. The learning rate scheduling will be adjusted per phase to optimize training. Ive also incorporated focal loss to handle class imbalance and gradient clipping to prevent exploding gradients. The focal loss is particularly effective in ensuring that the model pays attention to hardto-classify examples. Confidence Score: 0.81 **Pathway Expert**: Im satisfied with the incorporation of biological considerations. The models ability to capture dynamic changes and the inclusion of cell cycle phase as covariate will enhance the biological relevance of the predictions. believe this approach will provide valuable insights into the effects of CRISPRi perturbations. The inclusion of cell cycle phase as covariate is particularly 105 important as it helps in accounting for the inherent biological noise in single-cell data. Confidence Score: 0.86 **Deep Learning Expert**: Ive implemented the multi-task learning and contrastive loss components. The model can now predict both gene expression changes and perturbation types, which should improve performance. Ive also added recurrent component to model the progression of changes over time. The multi-task learning approach ensures that the model learns features that are relevant for multiple tasks, improving its overall generalization capabilities. The transformers self-attention mechanism allows the model to weigh the importance of different genes dynamically, which is particularly useful for capturing the complex regulatory networks in single-cell data. Confidence Score: 0. **Critic**: The revised plan addresses several of my previous concerns. The model architecture is innovative and welljustified The next-step is to adjust details and integrate. Im more confident now. The plan to start with simpler model and incrementally add complexity is reasonable. Ive also developed comprehensive evaluation strategy that includes comparisons with known biological pathways and interactions to ensure the predictions make sense biologically. This validation is crucial for the models credibility. The evaluation strategy will include both quantitative metrics and qualitative assessments to ensure biological relevance. The final plan addresses most of the previous concerns. The preprocessing steps are comprehensive, the model architecture is innovative and well-justified, and the training strategy is robust. The evaluation metrics are clearly defined, including both predictive performance ( MSE/PCC/R2) and biological relevance (MSE_DE/PCC_DE/R2_DE). The models ability to handle combinatorial perturbations through the dynamic graph and contrastive loss is strong point. believe this plan has high likelihood of success. Confidence Score: 0."
        },
        {
            "title": "Graph Based Discussion Output",
            "content": "Round 4 **Data Preprocessing Expert**: At this stage, Ive finalized the preprocessing pipeline: log-normalization to correct skewness, kNN imputation for sparse values, and PCA to reduce dimensionality while preserving biological variation. Ive also tuned the level of Gaussian noise and masking used in augmentation to avoid over-regularization. These steps provide stable and expressive foundation for the downstream model. Confidence Score: 0.83 **Model Architecture Expert**: The architecture now consists of VAE for denoising, dynamic GNN layers based on learned gene correlations, and transformer to capture long-range dependencies. The perturbation embeddings are refined through task-specific supervision, and we removed reliance on external embeddings like Gene2Vec to ensure adaptability. Ive also unified these components into an end-to-end trainable pipeline. Confidence Score: 0.84 106 **Training and Optimization Expert**: Ive further stabilized the training procedure: the three-phase schedule (VAE pretraining, transformer integration, and full fine-tuning) has been calibrated with adaptive learning rate adjustments per phase. Gradient clipping and focal loss are retained, and added adversarial training to improve generalization under rare perturbation types. Overall, training is now more efficient and robust. Confidence Score: 0.83 **Pathway Expert**: The final model respects core biological principles. Dynamic modeling captures perturbation cascades, and covariates such as cell cycle phase enhance resolution. Ive also mapped known regulatory pathways to embedding clusters to validate biological plausibility. This offers interpretability and anchors the model in mechanistic understanding. Confidence Score: 0. **Deep Learning Expert**: The hybrid architecture now cleanly integrates contrastive loss, multi-task learning, and recurrent modeling. Each branch is now modular but contributes to shared representations, which improves both prediction accuracy and biological alignment. Self-attention continues to play central role in interpretability and sparse signal extraction from noisy data. Confidence Score: 0.88 **Critic**: The revised plan addresses all critical concerns. The model architecture is innovative and well-justified, now integrating components cohesively. The training strategy is refined for efficiency and robustness. Evaluation metrics clearly cover both predictive performance and biological relevance. The next step is to adjust remaining minor details and integrate all components into unified implementation. The final plan should include: (1) modular hybrid model with transformer and dynamic GNN, (2) threephase training strategy with contrastive loss and adversarial tuning, (3) evaluation with both predictive and biological metrics, and (4) validation against known pathway structures. This plan demonstrates high level of scientific rigor and practical feasibility. Confidence Score: 0.85 107 Q.5 Method Design Research Plan"
        },
        {
            "title": "Graph Based Discussion Output",
            "content": "# Data Preprocessing Steps: ## Load Data Load the gene expression matrix and metadata from the Norman et al. (2019) dataset using appropriate libraries like scanpy or anndata. ## Filter Low-Quality Cells and Genes Remove cells with low RNA content or high mitochondrial content. Filter out genes with low expression across cells. ## Normalize Data Normalize the gene expression counts to account for differences in sequencing depth between cells. This can be done using methods like library size normalization. ## Log-Transformation Apply log-transformation to the gene expression data to handle skewness. ## Batch Effect Correction Use methods like harmony or Combat to remove batch effects from the data. ## Feature Selection Identify highly variable genes (HVGs) to reduce dimensionality. This can be done using statistical methods to select genes with the highest variability across cells. ## PCA Dimensionality Reduction Apply PCA to further reduce the dimensionality of the gene expression data. This helps in capturing the main sources of variation in lower-dimensional space. ## Perturbation Encoding Extract the perturbation information from the datasets metadata. Encode the perturbation information using one-hot encoding initially. Alternatively, use learned embeddings for each gene in the perturbation. ## Control Sample Handling Identify and use control cells (unperturbed) to establish baseline gene expression profiles. ## Data Augmentation Add Gaussian noise and apply random masking to the data to improve model robustness. ## Data Splitting Split the dataset into training, validation, and test sets. Ensure that certain perturbations are held out for validation and testing to evaluate the models ability to generalize to unseen perturbations and cell contexts. # Model Design ## Overview The proposed model is hybrid neural network architecture designed to predict post-perturbation gene expression profiles in single cells. It integrates three key components: Variational Autoencoder (VAE) for learning robust, lowdimensional representations of gene expression data. Graph Neural Network (GNN) for modeling gene-gene interactions using dynamically constructed gene regulatory network (GRN) . 108 Transformer for capturing long-range dependencies and complex patterns in the fused gene-perturbation representations. This combination allows the model to handle the high dimensionality, sparsity, and noise characteristic of singlecell data while providing biological interpretability through attention mechanisms and graph structures. ## Key Components 1. Variational Autoencoder (VAE) Encoder Purpose: To compress high-dimensional gene expression data into compact latent representation while capturing the underlying data distribution. Architecture: Input layer with size matching the number of principal components (e.g., 128). Two hidden layers with decreasing dimensions (e.g., 256 128 64). Output layer producing latent space. (mean) and logvar (log variance) for the Feasibility: VAEs are well-established for dimensionality reduction and denoising in scRNA-seq data. Biological Interpretability: The learned latent space can be analyzed for biological patterns. 2. Perturbation Embedding Layer Purpose: To convert perturbation identities (single or paired genes) into dense vector representations. Architecture: Input layer with size matching the number of unique perturbations (one-hot encoded). Embedding layer projecting into lower-dimensional space (e.g., 32 dimensions). Feasibility: Embedding layers are standard for categorical data and reduce dimensionality. Biological Interpretability: Similar perturbations will have similar embeddings, allowing analysis of perturbation relationships. 3. Graph Neural Network (GNN) Purpose: To model gene regulatory networks (GRNs) and capture gene-gene interactions. Architecture: Dynamically construct gene interaction graph using correlations from the training data. Use Graph Convolutional Layers to propagate information across the graph. Feasibility: GNNs are effective for capturing relational data and have been applied to gene networks. Biological Interpretability: The learned graph can highlight key regulatory relationships. 4. Transformer Encoder Purpose: To capture complex, long-range dependencies in the fused gene-perturbation representations. Architecture: Input layer combining VAE latent vectors and perturbation embeddings. Multi-head self-attention mechanisms to weigh the importance of different genes. Feed-forward neural networks for non-linear transformations. Feasibility: Transformers excel at modeling sequential and complex data patterns. Biological Interpretability: Attention weights can reveal important gene interactions. 5. Fusion and Output Layers Purpose: To combine information from the VAE and perturbation branches and produce the final prediction. 109 Architecture: Concatenate VAE latent vectors and perturbation embeddings. Dense layers to transform the fused representation into gene expression predictions. Feasibility: Concatenation is simple yet effective fusion strategy. Biological Interpretability: The final output can be directly compared to observed gene expression changes. ## Feasibility and Biological Interpretability ### Feasibility Computational Efficiency: The model uses well-established and optimized components (VAE, Transformer, GNN) that can be efficiently trained on GPU. Scalability: The architecture is designed to handle the high dimensionality of single-cell data while maintaining reasonable computational requirements. Implementation: The model can be implemented using popular deep learning frameworks like PyTorch. ### Biological Interpretability Attention Mechanisms: The Transformers self-attention layers can highlight important gene interactions, providing insights into regulatory mechanisms. Perturbation Embeddings: The learned embeddings can be analyzed to understand relationships between different perturbations. Gene Regulatory Networks: The GNN component can reveal key regulatory interactions within the gene network. Latent Space Analysis: The VAEs latent space can be visualized to identify patterns corresponding to biological conditions. # Training Strategy ## Overview The training strategy is designed to optimize the models ability to predict post-perturbation gene expression profiles while ensuring generalization to unseen perturbations and cell contexts. The strategy incorporates several key components including custom loss function, advanced optimization techniques, and mechanisms for monitoring and preventing overfitting. ## Key Components ### 1. Loss Function **Components**: - **Reconstruction Loss**: Measures the difference between the predicted and true gene expression profiles using Mean Squared Error (MSE). - **KL Divergence Loss**: Ensures the learned latent space distribution from the VAE component is close to prior distribution (typically standard normal distribution). **Implementation**: python def loss_function(output, x, mu, logvar, beta=1.0): recon_loss = F.mse_loss(output, x) kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar. exp()) kl_loss = kl_loss / x.size(0) # Normalize by batch size total_loss = recon_loss + beta * kl_loss return total_loss, recon_loss, kl_loss ### 2. Optimizer and Learning Rate Scheduler **Components**: - **AdamW Optimizer**: Used for its adaptive learning rate capabilities and decoupled weight decay. - **OneCycleLR Scheduler**: Dynamically adjusts the learning rate over the training period to find an optimal balance between learning rate and convergence speed. 110 **Implementation**: python optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5) scheduler = torch.optim.lr_scheduler.OneCycleLR( optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=num_epochs, pct_start=0.2, anneal_strategy=cos ) ### 3. Regularization Techniques **Components**: - **Gradient Clipping**: Prevents exploding gradients by clipping gradient values during backpropagation. - **Early Stopping**: Monitors validation loss and stops training if it doesnt improve for specified number of epochs. **Implementation**: python def train_epoch(model, train_loader, optimizer, device, beta): model.train() total_loss = 0 for batch in train_loader: x, pert = batch x, pert = x.to(device), pert.to(device) optimizer.zero_grad() output, mu, logvar = model(x, pert) loss, _, _ = loss_function(output, x, mu, logvar, beta) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) optimizer.step() total_loss += loss.item() return total_loss / len(train_loader) def validate(model, val_loader, device, beta): model.eval() total_loss = 0 with torch.no_grad(): for batch in val_loader: x, pert = batch x, pert = x.to(device), pert.to(device) output, mu, logvar = model(x, pert) loss, _, _ = loss_function(output, x, mu, logvar, beta) total_loss += loss.item() return total_loss / len(val_loader) def train_model(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs=100, beta=1.0, patience=5): best_loss = float(inf) patience_counter = 0 best_model_weights = None for epoch in range(num_epochs): train_loss = train_epoch(model, train_loader, optimizer, device, beta) val_loss = validate(model, val_loader, device, beta) scheduler.step() 111 print(fEpoch {epoch+1}/{num_epochs} - Train Loss: { train_loss:.4f} - Val Loss: {val_loss:.4f}) if val_loss < best_loss: best_loss = val_loss patience_counter = 0 best_model_weights = model.state_dict() else: patience_counter +=1 if patience_counter >= patience: print(Early stopping triggered) break model.load_state_dict(best_model_weights) return model ### 4. Training Loop with Monitoring **Components**: - **Epoch Training**: Trains the model on the entire training dataset for one pass. - **Validation**: Evaluates the model on the validation set after each epoch. - **Checkpointing**: Saves the model weights if the validation loss improves. **Implementation**: python # Example usage if __name__ == \"__main__\": # Assuming adata is your preprocessed AnnData object # Convert your data to PyTorch tensors = torch.tensor(data_augmented, dtype=torch.float32) perturbations = torch.tensor(perturbations, dtype=torch. float32) # Create dataset and dataloader dataset = TensorDataset(X, perturbations) train_size = int(0.8 * len(dataset)) test_size = len(dataset) - train_size train_dataset, test_dataset = torch.utils.data.random_split( dataset, [train_size, test_size]) train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) val_loader = DataLoader(test_dataset, batch_size=32, shuffle= False) # Initialize model, optimizer, and device device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") model = HybridModel(input_dim=pca_dim, pert_dim=pert_dim).to( device) optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5) scheduler = torch.optim.lr_scheduler.OneCycleLR( optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=100, pct_start=0.2, anneal_strategy=cos ) # Train the model trained_model = train_model(model, train_loader, val_loader, optimizer, scheduler, device, beta=0.1) ## Expert Recommendations Incorporated ### Addressing Class Imbalance 112 - **Weighted Loss**: Assign higher weights to underrepresented classes in the loss function. - **Oversampling**: Increase the sampling rate of underrepresented perturbations during training. ### Enhancing Generalization - **Data Augmentation**: Apply techniques like Gaussian noise addition and random masking to improve model robustness. - **VAE Regularization**: Use the KL divergence term in the loss function to ensure the latent space is well-regularized. ### Improving Training Stability - **Gradient Clipping**: Prevents gradients from exploding during backpropagation. - **Learning Rate Scheduling**: Uses OneCycle schedule to dynamically adjust the learning rate. ### Biological Interpretability - **Attention Mechanisms**: The transformer component provides attention weights that can be analyzed to understand gene interactions. - **Perturbation Embeddings**: The learned embeddings can be visualized to explore relationships between different perturbations. This comprehensive training strategy ensures the model is trained effectively while addressing the specific challenges of single-cell gene expression data, including class imbalance, high dimensionality, and the need for generalization to unseen perturbations. The incorporation of expert recommendations further enhances the models performance and biological relevance. Q.6 Example model design Q.6.1 Mermaid code of the framework Generated by Design Module graph TD A[Raw Gene Expression Data] --> B[Filter Low-Quality Cells and Genes] --> C[Normalize Data] --> D[Log-Transformation] --> E[Batch Effect Correction] --> F[Feature Selection] --> G[PCA Reduction] H[Perturbation Data] --> I[One-Hot Encoding] --> J[VAE Encoder] --> K[Perturbation Embedding] --> L[Fusion Layer] --> --> M[Transformer Encoder] --> N[Output Layer] --> O[Predicted Expression Profile] Q.6.2 Pseudo Code // Data Preprocessing function preprocess_data(adata, pca_dim): // Filter low-quality cells and genes filter_cells(adata, min_genes=200) filter_genes(adata, min_cells=3) // Normalize data normalize_total(adata, target_sum=1e4) log1p(adata) // Identify highly variable genes highly_variable_genes(adata, n_top_genes=3000) data = adata[:, adata.var[highly_variable]].X // Batch effect correction combat(adata, key=batch) 113 // Standardize data scaler = StandardScaler() data = scaler.fit_transform(data) data = clip_values(data, -10, 10) data = scale(data) // PCA reduction pca = PCA(n_components=pca_dim) data_pca = pca.fit_transform(data) // Perturbation encoding perturbations = one_hot_encode(adata.obs[perturbation]) // Data augmentation data_augmented = add_gaussian_noise(data_pca) data_augmented = apply_random_masking(data_augmented) return data_augmented, perturbations // Model Training function train_model(model, train_loader, optimizer, device, beta): model.train() total_loss = 0 for each batch in train_loader: x, pert = batch x, pert = move_to_device(x, pert, device) optimizer.zero_grad() output, mu, logvar = model(x, pert) recon_loss = mean_squared_error(output, x) kl_loss = compute_kl_loss(mu, logvar) loss = recon_loss + beta * kl_loss loss.backward() optimizer.step() total_loss += loss.item() return total_loss / number_of_batches(train_loader) def _init_weights(self, module): if isinstance(module, nn.Linear): nn.init.xavier_uniform_(module.weight) if module.bias is not None: nn.init.zeros_(module.bias) elif isinstance(module, nn.LayerNorm): nn.init.ones_(module.weight) nn.init.zeros_(module.bias) def forward(self, x, pert): vae_kl = 0 vae_recon = None if self.use_vae: z, mu, logvar = self.vae_encoder(x) vae_recon = self.vae_decoder(z) vae_kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp (), dim=1).mean() expr_feat = else: expr_feat = self.expression_encoder(x) pert_feat = self.pert_encoder(pert) fusion_input = torch.cat([expr_feat, pert_feat], dim=1). unsqueeze(1) if self.use_transformer: x_trans = self.transformer(fusion_input).squeeze(1) else: x_trans, _ = self.self_attention(fusion_input, fusion_input, fusion_input) x_trans = x_trans.squeeze(1) 114 fused = self.fusion(x_trans) output = self.output(fused) pert_pred = self.perturbation_head(fused) return output, pert_pred, vae_recon, vae_kl"
        },
        {
            "title": "R Detailed outputs from other research Agents",
            "content": "We provided the following research agents with the same input as CellForge(task description and dataset, as presented in Appendix P.1). Biomni Despite providing detailed natural language report (as below), Biomni failed to generate any executable code for the single-cell perturbation prediction task. Consequently, it achieved benchmark score of 0. This indicates fundamental limitation in its ability on single cell perturbation prediction tasks."
        },
        {
            "title": "Research Agent Output",
            "content": "Norman et al. dataset(gene knockout, scRNA-seq) Launching workflow executor (this may take while)... Answer # CRISPRi Gene Expression Prediction: Comprehensive Analysis and Novel Method Report ## Executive Summary have developed comprehensive framework for predicting gene expression profiles following CRISPR interference (CRISPRi) in K562 cells, based on the methodology established by Norman et al. (2019) Science. The framework addresses the specified prediction scenarios and evaluation metrics while providing novel multi-model approach for robust gene expression prediction. ## Key Contributions ### 1. Novel Methodology - **Multi-Model Ensemble Approach**: Combines Random Forest and Ridge Regression with interaction feature engineering - **Perturbation-Gene Interaction Modeling**: Explicit modeling of how perturbations affect individual genes - **Dual Evaluation Framework**: Separate assessment for unseen perturbations and unseen cell contexts ### 2. Comprehensive Implementation The framework includes: - Complete Python implementation (crispri_prediction_framework. py) - Automated data preprocessing pipeline - Multiple model architectures for comparison - Comprehensive evaluation suite with all specified metrics - Publication-ready visualization tools ### 3. Technical Innovation - **Feature Engineering**: Novel combination of baseline expression and perturbation targets - **Cross-Validation Strategy**: Stratified by perturbation type to ensure robust evaluation - **Multi-Scale Evaluation**: Separate metrics for all genes and differentially expressed genes ## Data and Methods ### Dataset Information - **Source**: Norman et al. (2019) Science, GEO accession GSE133344 [1] - **Technology**: CRISPRi + single-cell RNA sequencing (Perturbseq) - **Scale**: 112 target genes, single and combinatorial perturbations in K562 cells - **Data Access**: Available via GEO, Figshare, and GitHub repositories [1] ### Model Architecture #### Model 1: Multi-output Random Forest 116 - Handles non-linear gene-gene interactions - Provides feature importance rankings - Robust to outliers and missing values - Parameters: 100 estimators, max depth 15, optimized for genomics data #### Model 2: Ridge Regression with Interaction Terms - Linear baseline model with explicit perturbation-gene interactions - Computationally efficient and interpretable - Regularization parameter =1.0 optimized via cross-validation ### Evaluation Framework #### Evaluation Scenarios 1. **Unseen Perturbations**: Train on subset of perturbations, test on held-out perturbations 2. **Unseen Cell Contexts**: Train on subset of cells, test on cells with different baseline expression #### Evaluation Metrics (All Implemented) - **MSE**: Mean Squared Error across all genes - **PCC**: Pearson Correlation Coefficient (average across genes ) - **R**: Coefficient of determination - **MSE_DE**: MSE for differentially expressed genes only - **PCC_DE**: PCC for differentially expressed genes only - **R_DE**: for differentially expressed genes only ## Implementation Details ### Data Preprocessing Pipeline 1. **Quality Control**: Filter cells with <500 genes and genes in <10 cells 2. **Normalization**: Library size normalization + log1p transformation 3. **Feature Selection**: Top 2000 highly variable genes 4. **Perturbation Encoding**: One-hot encoding of perturbation targets ### Novel Features - **Interaction Terms**: Explicit modeling of perturbationbaseline expression interactions - **Multi-Scale Validation**: Cross-validation strategies tailored to each evaluation scenario - **Comprehensive Metrics**: Implementation of all six specified evaluation metrics ## Expected Performance Based on similar studies and our framework design: - **Unseen Perturbations**: > 0.6, PCC > 0.7 for DE genes - **Unseen Cell Contexts**: > 0.5, PCC > 0.65 for DE genes - **Model Comparison**: Random Forest expected to outperform Ridge on non-linear interactions ## Generated Deliverables All files saved to /tmp/agent_outputs/0fb4d993-3436-4fe9-8b08 -8436bb1aed44/: 1. **crispri_prediction_framework.py** - Complete implementation with CRISPRiAnalyzer class 2. **[methodology_report.md](https://biomni-logs.s3.amazonaws. com/3220104147_zju_edu_cn/logs/session_0fb4d993-3436-4fe9-8 b08-8436bb1aed44/files/methodology_report.md?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=HUmJXc0c2%2FLHweYs5rqAEOWab2I %3D&Expires=1751037731)** - Detailed methodology and theoretical framework 3. **[evaluation_framework.json](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_0fb4d993 -3436-4fe9-8b08-8436bb1aed44/files/evaluation_framework.json? AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature=9wu88Nh6Qm%2 BaJ4gmftv5E0nx0Rg%3D&Expires=1751037731)** - Structured evaluation specifications 4. **[comprehensive_analysis_framework.png](https://biomni-logs. s3.amazonaws.com/3220104147_zju_edu_cn/logs/session_0fb4d993 -3436-4fe9-8b08-8436bb1aed44/files/ comprehensive_analysis_framework.png?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=LPR2e6KfMpvEzlMEGMp%2BQWQ59u8 %3D&Expires=1751037731)** - Visual framework overview 5. **[technical_specifications.md](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_0fb4d993 -3436-4fe9-8b08-8436bb1aed44/files/technical_specifications. md?AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature=1z%2Byoe%2 FbbYgSa%2F4IG8ju9oJ2VxE%3D&Expires=1751037731)** - Implementation details and requirements ## Significance and Impact ### Scientific Contributions 1. **Standardized Evaluation**: Provides benchmark framework for CRISPRi prediction methods 2. **Baseline Models**: Establishes performance baselines for comparison with deep learning approaches 3. **Biological Insights**: Framework designed to reveal gene regulatory network patterns in K562 cells ### Practical Applications - **Drug Discovery**: Predict off-target effects of CRISPR-based therapeutics - **Functional Genomics**: Systematic prediction of gene function through perturbation - **Personalized Medicine**: Cell-context specific perturbation response prediction ## Future Extensions ### Deep Learning Integration - Transformer architectures for sequence-based modeling - Graph neural networks for gene regulatory networks - Variational autoencoders for representation learning ### Multi-Modal Data - Integration with protein abundance data - Chromatin accessibility incorporation - Drug response profile integration ## Conclusion This comprehensive framework provides robust, scientifically rigorous approach to CRISPRi gene expression prediction. The implementation is ready for immediate use with the Norman et al. (2019) dataset and establishes both methodological foundations and performance benchmarks for future research in perturbation-based functional genomics. The framework successfully addresses all specified requirements while introducing novel methodological contributions that advance the state-of-the-art in computational biology and functional genomics. ## References [1] [Norman, T.M., Horlbeck, M.A., Replogle, J.M. et al. \" Exploring genetic interaction manifolds constructed from rich single-cell phenotypes.\" *Science*, 365, 786-793, 2019.](https://www.science.org/doi/10.1126/science.aax4438) ***All file outputs are stored in the session execution logs, you may download them from the <Session History & Export> section***"
        },
        {
            "title": "Research Agent Output",
            "content": "Srivatsan et al. dataset(drug,scRNA-seq) Launching workflow executor (this may take while)... Answer # Chemical Perturbation Gene Expression Prediction: Complete Analysis, Method, and Code Report ## Executive Summary have developed comprehensive machine learning framework for predicting transcriptional responses to chemical perturbations in human cell lines. This framework is specifically designed for the sci-Plex methodology from Srivatsan et al. (Science 2020) [1] and addresses the critical challenge of predicting gene expression changes following compound treatments across different cellular contexts. ## Key Contributions ### 1. Novel Methodology Framework - **Multi-target regression approach** combining Random Forest and Ridge Regression models - **Innovative feature engineering** integrating baseline expression, compound characteristics, and interaction terms - **Dual evaluation framework** addressing both unseen perturbations and unseen cell contexts - **Comprehensive metric system** with six evaluation measures ( MSE, PCC, R, MSE_DE, PCC_DE, R_DE) ### 2. Technical Innovation - **Interaction feature engineering**: Novel approach combining baseline cellular state with compound effects - **Multi-scenario evaluation**: Addresses real-world application scenarios for drug discovery - **DE-specific metrics**: Focused evaluation on differentially expressed genes for biological relevance ### 3. Complete Implementation - **Production-ready code**: Full Python implementation with scikit-learn integration - **Comprehensive documentation**: Detailed methodology and technical specifications - **Visualization framework**: Publication-ready analysis figures - **Reproducible pipeline**: Structured evaluation protocols ## Data and Methods ### Dataset: Srivatsan et al. sci-Plex - **Source**: GEO accession GSE132566 [1] - **Scale**: 650,000+ single-cell profiles across 188 compounds - **Cell lines**: A549 (lung), K562 (leukemia), MCF7 (breast cancer) - **Design**: 4 dose levels per compound (10 nM to 10 M) ### Model Architecture #### Random Forest Regressor python RandomForestRegressor( n_estimators=200, max_depth=20, min_samples_split=5, random_state=42, n_jobs=-1 ) #### Ridge Regression with Interactions python Ridge( alpha=1.0, fit_intercept=True, random_state=42 ) ### Feature Engineering Pipeline 1. **Baseline Expression**: Top 1,000 highly variable genes 2. **Compound Features**: Encoded compound ID, log-transformed dose, cell line 3. **Interaction Features**: Element-wise product of baseline expression and dose 4. **Total Features**: 3,000 features per sample ## Evaluation Framework ### Two Critical Scenarios 1. **Unseen Perturbations**: Predict responses to compounds not seen during training 2. **Unseen Cell Contexts**: Predict responses in cellular contexts not represented in training ### Six Comprehensive Metrics - **Overall Performance**: MSE, PCC, - **DE-Specific Performance**: MSE_DE, PCC_DE, R_DE (for top 10% most variable genes) ## Expected Performance Benchmarks ### Unseen Perturbations Scenario - Overall: 0.45-0.65 - PCC Overall: 0.60-0.75 - DE: 0.50-0.70 ### Unseen Cell Contexts Scenario - Overall: 0.35-0.55 - PCC Overall: 0.55-0.70 - DE: 0.40-0.60 ## Deliverables Generated 1. **chemical_perturbation_predictor.py** - Complete implementation framework 2. **[chemical_perturbation_methodology.md](https://biomni-logs. s3.amazonaws.com/3220104147_zju_edu_cn/logs/session_0c14fa4f -59b1-4c98-96f6-3655019e2f9a/files/ chemical_perturbation_methodology.md?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=GhlIsrCIgJ0s0x40PKi%2BnfYpAv4 %3D&Expires=1751038449)** - Comprehensive methodology document 3. **[evaluation_framework.json](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_0c14fa4f-59 b1-4c98-96f6-3655019e2f9a/files/evaluation_framework.json? AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature=WJX8wVO7Sw76%2 BrdjKY2FVdiqdGY%3D&Expires=1751038449)** - Structured evaluation specifications 4. **[chemical_perturbation_analysis.png](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_0c14fa4f-59 b1-4c98-96f6-3655019e2f9a/files/ chemical_perturbation_analysis.png?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=m4cqAdqEFUs0nJeuYkywlO%2FUOU0 %3D&Expires=1751038449)** - Multi-panel analysis visualization 5. **[technical_summary.md](https://biomni-logs.s3.amazonaws.com /3220104147_zju_edu_cn/logs/session_0c14fa4f-59b1-4c98-96f6 -3655019e2f9a/files/technical_summary.md?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=t9q3oUk9p3CxYi7%2Fqx1ckJuHKxU %3D&Expires=1751038449)** - Implementation technical details ## Scientific Significance ### Drug Discovery Applications - **Compound screening**: Predict transcriptional effects of novel compounds - **Mechanism elucidation**: Understand drug action pathways - **Dose optimization**: Identify optimal therapeutic concentrations ### Precision Medicine Impact - **Patient stratification**: Predict individual drug responses - **Biomarker identification**: Discover predictive molecular signatures - **Treatment personalization**: Guide precision therapy selection ### Systems Biology Insights - **Network analysis**: Map compound-pathway interactions - **Combination therapy**: Predict synergistic drug effects - **Resistance mechanisms**: Understand treatment failure pathways ## Technical Innovations ### 1. Compound-Expression Interactions Our framework introduces interaction terms between baseline cellular state and compound characteristics, capturing how identical compounds can have different effects depending on cellular context. ### 2. Multi-Target Regression Simultaneous prediction of all gene expression levels enables comprehensive transcriptional response modeling while maintaining computational efficiency. ### 3. Stratified Evaluation Separate evaluation scenarios ensure model performance assessment across different real-world application contexts. ## Future Extensions ### Deep Learning Integration - Transformer architectures for sequence-based compound representation - Graph neural networks for compound-target interaction modeling - Variational autoencoders for dimensionality reduction ### Multi-Modal Enhancement - Chemical structure integration (SMILES, molecular fingerprints ) - Protein-compound interaction networks - Epigenetic and chromatin accessibility data ## Implementation Usage python # Initialize framework predictor = ChemicalPerturbationPredictor(output_dir=./results ) # Load sci-Plex data data = predictor.load_data([expression_matrix.csv](https:// biomni-logs.s3.amazonaws.com/3220104147_zju_edu_cn/logs/ session_0c14fa4f-59b1-4c98-96f6-3655019e2f9a/files/ expression_matrix.csv?AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE& Signature=ld8NqUwqRAT7aoKxjqKDUwjqdu0%3D&Expires=1751038449) , [metadata.csv](https://biomni-logs.s3.amazonaws.com /3220104147_zju_edu_cn/logs/session_0c14fa4f-59b1-4c98-96f6 -3655019e2f9a/files/metadata.csv?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=kl3jlyuXLGVDgXViz5GOC%2BNLzHs %3D&Expires=1751038449)) # Preprocess and train features, targets = predictor.preprocess_data(data[ expression_data], data[metadata]) results = predictor.train_models(features, targets, scenario= unseen_perturbations) # Generate comprehensive report report = predictor.generate_report() ## Conclusion This comprehensive framework establishes new benchmarks for chemical perturbation prediction, combining methodological innovation with practical implementation. The multi-model approach, comprehensive evaluation framework, and focus on biological relevance make it suitable for both research applications and clinical translation. The frameworks emphasis on interpretability and biological grounding, combined with its computational efficiency, positions it as valuable tool for the drug discovery and precision medicine communities. ## References [1] [Srivatsan, S.R., et al. \"Massively multiplex chemical transcriptomics at single-cell resolution.\" *Science*, 367(6473), 45-51, 2020.](https://doi.org/10.1126/science. aax6234) --- **All implementation files have been saved to /tmp/ agent_outputs/0c14fa4f-59b1-4c98-96f6-3655019e2f9a/ and are ready for immediate use with the sci-Plex dataset.** ***All file outputs are stored in the session execution logs, you may download them from the <Session History & Export> section***"
        },
        {
            "title": "Research Agent Output",
            "content": "Schiebinger et al.(cytokines, scRNA-seq) Launching workflow executor (this may take while)... Answer # mESC Cytokine Perturbation Gene Expression Prediction: Novel Analysis, Method & Code Report ## Executive Summary have developed comprehensive computational framework for predicting transcriptional responses in mouse embryonic stem cells (mESCs) following cytokine perturbations. This novel methodology combines insights from the Waddington-OT framework by Schiebinger et al. [1] with advanced machine learning approaches to address the challenge of predicting gene expression changes in response to cytokine treatments. ## Key Contributions ### 1. Novel Methodology Framework - **Multi-model ensemble approach** combining Random Forest, Gradient Boosting, Ridge Regression, Elastic Net, and Neural Networks - **Innovative interaction feature engineering** capturing cytokine-context dependencies through element-wise products of cytokine presence with baseline expression - **Dual evaluation framework** addressing both unseen perturbations and unseen cellular contexts - **Comprehensive metric system** including both overall and differentially expressed gene-specific measures ### 2. Scientific Foundation 122 Based on extensive literature research, the framework is grounded in: - **Waddington-OT principles** from Schiebinger et al. (Cell 2019) [1], which demonstrated optimal transport analysis of single-cell trajectories during cellular reprogramming - **Single-cell perturbation studies** showing the power of combining CRISPR screens with scRNA-seq for functional genomics - **Cytokine signaling biology** in mESC pluripotency maintenance and differentiation ### 3. Technical Innovation - **Context-dependent modeling**: Explicit modeling of how identical cytokines have different effects in different cellular states - **Multi-target regression**: Simultaneous prediction of all genes while maintaining correlation structure - **Biologically motivated features**: Integration of cytokine identity, concentration, timepoint, and cellular state information ## Data and Methods ### Dataset Requirements The framework is designed for single-cell RNA sequencing data from mESC cytokine perturbation experiments, requiring: 2000 - Expression matrix: cells genes (minimum 1000 cells genes) - Metadata: cytokine_id, concentration_ng_ml, timepoint_hours, cell_state - Compatible formats: AnnData (H5AD) or CSV/TSV ### Model Architectures 1. **Random Forest** (n_estimators=300, max_depth=25): Handles non-linear interactions 2. **Gradient Boosting** (n_estimators=200, max_depth=8): Sequential residual learning 3. **Ridge Regression** (=1.0): Linear baseline with L2 regularization 4. **Elastic Net** (=0.5, l1_ratio=0.5): Combined L1/L2 regularization 5. **Neural Network** (256-128-64 architecture): Deep learning for complex patterns ### Evaluation Framework **Two Critical Scenarios:** - **Unseen Perturbations**: Predicting responses to novel cytokine treatments - **Unseen Cell Contexts**: Predicting individual cell responses in diverse contexts **Six Comprehensive Metrics:** - Overall: MSE, PCC, (across all genes) - DE-specific: MSE_DE, PCC_DE, R_DE (for differentially expressed genes) ## Implementation Details ### Novel Feature Engineering The framework creates 6,000+ features combining: - **Baseline expression**: Top 2,000 highly variable genes - **Cytokine features**: Encoded identity, log concentration, timepoint, cell state - **Interaction features**: Cytokine-expression element-wise products capturing context-dependent effects ### Preprocessing Pipeline 1. Quality control (cell/gene filtering) 2. CPM normalization and log1p transformation 3. Feature selection (highly variable genes) 4. Interaction feature creation 5. Train/test splitting by scenario 123 ## Expected Performance ### Performance Benchmarks **Unseen Perturbations Scenario:** - Overall: 0.50-0.70 - PCC Overall: 0.65-0.80 - DE: 0.55-0.75 **Unseen Cell Contexts Scenario:** - Overall: 0.40-0.60 - PCC Overall: 0.60-0.75 - DE: 0.45-0.65 ## Generated Deliverables 1. **mesc_implementation_code.py**: Complete Python implementation with mESCCytokinePerturbationPredictor class 2. **[mesc_methodology_report.md](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_4aba27d4fea3-49c8-9d86-34c2b73b0216/files/mesc_methodology_report.md? AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature= SWZcdufL5nGCGdvohark8qM8Ywk%3D&Expires=1751039094)**: Detailed methodology documentation (11,863 characters) 3. **[evaluation_framework.json](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_4aba27d4fea3-49c8-9d86-34c2b73b0216/files/evaluation_framework.json? AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature=k0Bkx%2 BJt6abCEUQ16nktooQzj1A%3D&Expires=1751039094)**: Structured evaluation specifications 4. **[comprehensive_framework_analysis.png](https://biomni-logs. s3.amazonaws.com/3220104147_zju_edu_cn/logs/session_4aba27d4fea3-49c8-9d86-34c2b73b0216/files/ comprehensive_framework_analysis.png?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=FWloIvkJ5VR2LR1lipQnPQ%2F07Mk %3D&Expires=1751039094)**: Multi-panel visualization of framework components 5. **[technical_specifications.md](https://biomni-logs.s3. amazonaws.com/3220104147_zju_edu_cn/logs/session_4aba27d4fea3-49c8-9d86-34c2b73b0216/files/technical_specifications. md?AWSAccessKeyId=AKIA5OMXL5OSOMU6RIOE&Signature= NTusChoE4rFLmvqcfad17kkmQDg%3D&Expires=1751039094)**: Implementation requirements and configuration details ## Scientific Significance ### Biological Applications - **Stem cell biology**: Optimize cytokine cocktails for mESC culture and differentiation - **Drug discovery**: Predict cytokine drug mechanisms and offtarget effects - **Precision medicine**: Guide personalized cytokine therapy selection ### Methodological Advances - **Context-dependent perturbation modeling**: Novel approach to capture how cellular state influences treatment response - **Multi-scenario evaluation**: Addresses real-world application challenges - **Interaction feature engineering**: Biologically motivated approach to capture cytokine-cell dependencies ## Future Extensions 1. **Deep Learning Integration**: Transformer architectures and graph neural networks 2. **Multi-Modal Enhancement**: Integration of protein abundance and chromatin accessibility data 3. **Causal Inference**: Distinguish correlation from causation in cytokine-gene relationships 4. **Temporal Dynamics**: Model time-series cytokine responses ## Conclusion This comprehensive framework represents significant advancement in predicting cytokine-induced transcriptional changes in mESCs. By combining insights from optimal transport theory with modern machine learning, it provides robust solution for understanding and predicting cytokine effects on stem cell gene expression. The framework establishes new benchmarks for perturbation prediction and provides foundation for future research in computational stem cell biology and precision medicine. The methodology addresses critical challenges in stem cell research, drug discovery, and precision medicine by providing accurate predictions of how cytokine treatments will affect gene expression in different cellular contexts. All implementation code, documentation, and analysis visualizations have been generated and are ready for immediate use with appropriate mESC cytokine perturbation datasets. ## References [1] [Schiebinger, G., et al. \"Optimal-transport analysis of single-cell gene expression identifies developmental trajectories in reprogramming.\" *Cell*, 176(4), 928-943, 2019.](https://doi.org/10.1016/j.cell.2019.01.006) [2] [Haghverdi, L., et al. \"Diffusion pseudotime robustly reconstructs lineage branching.\" *Nature Methods*, 13(10), 845-848, 2016.](https://doi.org/10.1038/nmeth.3971) [3] [Wolf, F.A., et al. \"SCANPY: large-scale single-cell gene expression data analysis.\" *Genome Biology*, 19(1), 15, 2018.](https://doi.org/10.1186/s13059-017-1382-0) [4] [Stuart, T., et al. \"Comprehensive integration of singlecell data.\" *Cell*, 177(7), 1888-1902, 2019.](https://doi. org/10.1016/j.cell.2019.05.031) --- **Files Generated:** - Complete implementation code: /tmp/agent_outputs/4aba27d4fea3-49c8-9d86-34c2b73b0216/mesc_implementation_code.py - Methodology report: /tmp/agent_outputs/4aba27d4-fea3-49c8-9 d86-34c2b73b0216/[mesc_methodology_report.md](https://biomnilogs.s3.amazonaws.com/3220104147_zju_edu_cn/logs/ session_4aba27d4-fea3-49c8-9d86-34c2b73b0216/files/ mesc_methodology_report.md?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=SWZcdufL5nGCGdvohark8qM8Ywk%3 D&Expires=1751039094) - Evaluation framework: /tmp/agent_outputs/4aba27d4-fea3-49c8-9 d86-34c2b73b0216/[evaluation_framework.json](https://biomnilogs.s3.amazonaws.com/3220104147_zju_edu_cn/logs/ session_4aba27d4-fea3-49c8-9d86-34c2b73b0216/files/ evaluation_framework.json?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=k0Bkx%2BJt6abCEUQ16nktooQzj1A %3D&Expires=1751039094) - Analysis visualization: /tmp/agent_outputs/4aba27d4-fea3-49c8 -9d86-34c2b73b0216/[comprehensive_framework_analysis.png]( https://biomni-logs.s3.amazonaws.com/3220104147_zju_edu_cn/ logs/session_4aba27d4-fea3-49c8-9d86-34c2b73b0216/files/ comprehensive_framework_analysis.png?AWSAccessKeyId= AKIA5OMXL5OSOMU6RIOE&Signature=FWloIvkJ5VR2LR1lipQnPQ%2F07Mk %3D&Expires=1751039094) - Technical specifications: /tmp/agent_outputs/4aba27d4-fea3c8-9d86-34c2b73b0216/[technical_specifications.md](https:// biomni-logs.s3.amazonaws.com/3220104147_zju_edu_cn/logs/ session_4aba27d4-fea3-49c8-9d86-34c2b73b0216/files/ technical_specifications.md?AWSAccessKeyId= 125 AKIA5OMXL5OSOMU6RIOE&Signature=NTusChoE4rFLmvqcfad17kkmQDg%3 D&Expires=1751039094) ***All file outputs are stored in the session execution logs, you may download them from the <Session History & Export> section***"
        },
        {
            "title": "OpenAI DeepResearch Output\nResearch Agent Output",
            "content": "Norman et al. dataset(gene knockout, scRNA-seq) ## Task Analysis: Data Characteristics and Challenges **Perturb-seq Dataset (Norman *et al.*, 2019):** The model is built on rich single-cell CRISPR perturbation dataset from Norman *et al.* (2019, Science) (GEO: GSE133344). In this Perturb-seq experiment, K562 cells (a human leukemia line) were subjected to pooled CRISPR perturbations, measuring transcriptome-wide gene expression in each cell via singlecell RNA-seq. Key features of this dataset include: - **Scale and Composition:** 170,000 single cells were profiled, covering *1,092 unique perturbation conditions* (including both single-gene and paired-gene perturbations). Each cell is annotated with one or two target genes perturbed (via CRISPR interference/activation). - **High-Dimensional Readouts:** Each cells gene expression profile spans 20,000 genes (full transcriptome). This yields **high-dimensional output space** vector of expression levels for thousands of genes per cell. - **Perturbation Types:** Perturbations consist of **single-gene knockdowns** (CRISPRi) and **two-gene combinations**, enabling the study of genetic interactions. For each target gene, multiple sgRNAs were used (to control for guidespecific effects), and for two-gene combos, cells co-express two sgRNAs (one per target). **Modeling Challenges:** Developing an accurate predictive model for this task entails several significant challenges: - **Single-Cell Variability:** Even for the same perturbation, different cells can respond with variability in magnitude of gene expression changes. Each cell has an intrinsic baseline expression profile reflecting its state (cell cycle stage, stochastic gene expression, etc.). - **Generalization to Unseen Perturbations:** critical usecase is predicting outcomes for perturbations that were ** never seen in training**. This includes: - *New target genes:* The model may be asked to predict the effect of knocking down gene that was not perturbed in the training data. This is an extreme generalization challenge, as there is no direct training example for that genes perturbation. The model must leverage other information (e.g. the genes baseline expression or relationships to other genes) to infer its likely impact. - *New gene combinations:* Similarly, the model might see single-gene perturbations during training, but not particular pair in combination. Or even harder, both genes in pair might be novel (neither perturbed before). As reported in prior work, when one or both perturbed genes are unseen, prediction difficulty increases markedly. The model needs strategy to generalize **inductively**, combining knowledge of individual genes to predict combined effects. 126 - **Accuracy vs. Interpretability:** We prioritize predictive accuracy. This means we are willing to employ complex, black-box model (deep neural network) with many parameters if it yields better predictive performance, even if its not easy to interpret biologically. This choice acknowledges that the gene regulatory relationships underlying the perturbation responses are complex; simpler interpretable model (like linear regression per gene) might not capture the non-linear interactions or context dependencies as well as deep model. However, the complexity of the model also raises the risk of overfitting and requires careful regularization and validation. In summary, the task is essentially learning high-dimensional function: **f**(*baseline_expression*, *perturbation*) * perturbed_expression*. It must learn the underlying gene network responses from data, handle combinatorial perturbation effects, and generalize to new genes and cell states. These challenges will guide the modeling decisions discussed below. ------ ## Proposed Modeling Approach for Accuracy and Generalization ### Model Architecture and Input Representation To tackle this problem, we propose **neural network model** (1) the baseline gene expression that takes two inputs profile of an unperturbed cell, and (2) the identity of the target gene(s) perturbed and outputs the predicted postperturbation gene expression profile. The architecture is designed to flexibly capture non-linear gene interactions and make use of prior gene relationship knowledge to generalize to unseen perturbations. The key components are: - **Baseline Expression Encoder:** front-end network that processes the baseline expression vector (dimension = *G* genes). Directly using the raw high-dimensional vector as input to fully-connected network is feasible but could be inefficient. We will introduce an encoder (e.g., feedforward autoencoder or dimensionality reduction layer) that compresses the baseline gene expression profile into ** lower-dimensional latent representation**. For example, few fully-connected layers with ReLU activation can reduce the 20k-dimensional input to dense 512-dimensional embedding. This latent vector is intended to capture the cells overall state or context (e.g., if the cell is in high-proliferation state, or has high expression of certain pathways, etc.). By encoding the baseline, the model can later modulate perturbation effects depending on these latent features. - **Perturbation Encoder:** We represent the **perturbation identity** in way that the model can easily utilize and generalize. Each target gene (from the set of 100 possible targeted genes in the screen) is assigned either: - one-hot vector (of length equal to the number of target genes) if single gene is perturbed, or multi-hot vector if multiple genes are perturbed (e.g. for two-gene perturbation, the vector has ones in the positions corresponding to the two targeted genes). This binary indicator vector can then be fed through an embedding layer (a learned lookup table or small fully-connected network) to produce **perturbation embedding**. The embedding is continuous vector (e.g. 128-dimensional) that represents the effect of the perturbation in latent space. - Alternatively, an **embedding per gene** approach can be used: we maintain trainable embedding vector for each gene in the target set, and for combination 127 perturbation, we combine the embeddings of the individual genes (e.g. by summation or an attention mechanism). Using learned embedding for each gene gives the model chance to encode each genes characteristic perturbation impact. For multi-gene perturbation, simple summation assumes independence of effects, while more sophisticated combination ( see below) can capture interactions. - **Combination Module:** The baseline context and perturbation effect must be integrated. We concatenate the baseline latent vector and the perturbation embedding vector into single combined latent representation. This combined vector (of length 640 in our example, if baseline latent is 512 and perturbation embedding 128) now contains information about where the cell started and what perturbation was applied. This is passed through further layers (a **fusion network**) to compute the output. For instance, multilayer perceptron (MLP) with one or two hidden layers (e.g., 512 neurons, ReLU activation) can mix these features. This stage allows for non-linear interactions between cell state and perturbation depend on the level of gene in the baseline state, which e.g., the effect of perturbing gene might multiplicative interaction in the MLP can learn. - **Output Layer (Prediction Head):** The final layer of the network produces vector of length *G* (the number of genes) , which is the predicted post-perturbation expression for each gene. To ensure the model easily handles the fact that many genes dont change, we design the output to predict ** change (delta) from baseline** for each gene rather than an absolute expression. - **Non-linear Interaction Modeling:** While simple concatenation of embeddings treats multi-gene perturbations roughly as an additive combination of single effects, we can enhance the model to capture **genegene interaction effects **. One idea is to use an **attention mechanism or gating** in the perturbation encoder: for example, if two genes and are perturbed, instead of just summing their embeddings, we pass them through an attention network that can learn pairwise interaction term. Another approach is to include pairwise products of gene embeddings in the combined feature (allowing the network to learn unique contribution for the pair *A&B* beyond + B). Given that Norman *et al.* tested primarily pairwise perturbations, we can explicitly include learned parameter or small network for each pair of genes in the training set to capture any deviation from additivity. However, to generalize to unseen pairs, better strategy is to learn **function** for combining embeddings (like attention) rather than fixed lookup for each pair. - **Incorporating Prior Knowledge (for Generalization):** To improve inductive generalization to unseen genes, we can draw inspiration from GEARS and similar methods. We could initialize or regularize the gene perturbation embeddings using external knowledge: - Use **gene co-expression network** (computed from the baseline single-cell data or external data) as graph, and pass gene embeddings through Graph Neural Network (GNN) layer. This encourages genes that have similar roles or expression patterns to have embeddings that produce similar effects. Thus, if an unseen gene has similar co-expression profile to seen gene, the model might infer similar perturbation outcomes. - Use **pathway or GO (Gene Ontology) information** to place genes in relational graph (as GEARS did with GO-derived graph for perturbation embeddings). Two 128 genes in the same pathway might be expected to produce related downstream effects; by training on the known genes, the model can generalize to new gene by its connections in the GO graph. Technically, this can be done by adding loss term that encourages the learned embedding to correspond to the genes position in the memory module, or by GNN that propagates influence from neighbors during training. - These additions make the model more complex but aim to imbue it with **biological inductive bias**: (i) genes with similar baseline functions yield similar perturbation responses, and (ii) genes in related pathways affect overlapping sets of genes when perturbed. We will prioritize implementing simpler version (like using co-expression PCA or clusters to initialize embeddings), and note that full graph-based learning could further improve generalization if needed. - **Residual Connections and Regularization:** We will include skip-connections wherever helpful (for example, the baseline input could be fed not only into the encoder but also concatenated directly to later layer, or the output head could directly see the raw baseline as well, ensuring the model can easily learn identity for unchanged genes). Regularization techniques like dropout in the MLP layers, L2 weight decay, or even an auxiliary loss to reconstruct the baseline (autoencoder style) can be employed to prevent overfitting and encourage the model to learn meaningful latent features rather than memorizing training examples. In essence, the architecture is **conditioned deep neural network**: it conditions on the cells initial state and the perturbation, and produces an output state. This is somewhat analogous to an encoderdecoder model where the encoder is the baseline expression and the condition or control signal is the perturbation identity. Because accuracy is paramount, we allow fairly large model with enough capacity to capture complex gene regulatory responses. ### Training Strategy for Accuracy and Generalization With the architecture in place, we next focus on **training methodology**, as it greatly affects model generalization and performance: - **Training Data Construction:** We will pair each perturbed cells data with baseline profile as input. Since in the actual experiment we typically do not have *preperturbation* measurement of the same cell, we have to simulate baseline. We can use the expression profiles of control cells (non-targeting sgRNA) as proxies for baseline input. For each perturbed cell in the training set, we can randomly sample control cells expression as the baseline input. This effectively assumes that any control cell is an example of an unperturbed state the perturbed cell *could* have come from. Over many samples, the model will learn to map from an average baseline state to the perturbed outcome. We can further refine this pairing by matching on cell state: e.g., cluster the baseline cells by expression and pick baseline from the same cluster as the perturbed cells profile (minus the perturbation effect) to provide closer starting point. However, random pairing with large pool of controls adds variability that can help the model not to overfit one-to-one mapping. - *Unseen cell context generalization:* By exposing the model to many different baseline samples paired with given perturbation outcome (through random pairing), we train it to handle diverse baseline inputs for the same perturbation. This should improve the models 129 robustness to any particular baseline context and enable generalization to new baseline profiles. Essentially, the model sees that the same perturbation can apply to various starting expression patterns. - **Loss Functions:** The primary loss will be **Mean Squared Error (MSE)** between the predicted and actual postperturbation expression vectors. To ensure we adequately learn the important changes, we can modify the loss in two ways: - Compute weighted MSE that gives higher weight to genes that are truly differentially expressed in that training example. For instance, if we know gene changed significantly in the real perturbed cell ( compared to baseline or compared to controls), we can upweight the error on gene for that sample. This forces the model to focus on fitting the genes that move, rather than being dominated by the many nearzero changes. - Alternatively, we can train in two phases: first optimize MSE on the full profile to get general trends, then fine-tune the model on just the top-k DE genes for each perturbation (or using loss like contrastive that emphasizes getting the direction of change correct). In practice, simpler approach is to stick with standard MSE on all genes but monitor the top-k gene performance as separate metric, ensuring the model doesnt ignore those signals. If we see the model predicting trivial (no-change) solutions, we will adjust the loss weighting. - **Optimizer and Regularization:** We will use **Adam optimizer ** (adaptive learning rate) which is well-suited for training deep networks on possibly noisy data. relatively small learning rate (e.g. 1e-3 to start) will be used and well monitor validation loss for convergence. Early stopping on the validation MSE/PCC can prevent overfitting. Dropout layers (e.g. dropout rate 0.2-0.5) can be inserted in the MLP to regularize. Weight decay (L2) will help keep embedding weights from growing excessively (important if some genes cause large effects, we dont want the weights to explode to fit one-hot signals). - **Generalization Enhancements:** To specifically improve performance on **unseen genes**: - We will pre-train the **perturbation encoder embeddings **: one idea is to train simple autoencoder or matrix factorization on the *observed perturbation effects* in training. For example, compute the average expression change each perturbation causes on each gene (from data), yielding perturbation-gene effect matrix. We can factorize this matrix to get lowdimensional embedding for genes and for perturbations. If gene is unseen, we can still derive gene embedding from its baseline expression pattern using the gene embedding from baseline encoder. This is bit complex, but essentially we want the model to know something about gene function even if not perturbed. Incorporating gene ontology or known regulator information for unseen genes could also inform an initial embedding (e.g., if an unseen gene is transcription factor similar to another seen TF, assign it similar perturbation embedding). By combining carefully-designed architecture with these training strategies, our goal is model that not only fits the training perturbations well but **generalizes to new perturbations and contexts**. In particular, success would be model that, given an arbitrary K562 baseline profile and novel target gene, can predict biologically plausible outcome down-regulated by that genes perturbation, even without having seen it before. The inclusion of baseline input enables context-specific predictions (so the same gene perturbation could have different effects in different baseline states if the model learns those interactions), and capturing which pathways might be up or the use of gene embeddings with potential graph-based inductive bias enables inductive generalization across genes. Next, we present the implementation of this model in PyTorch, structured for GPU acceleration. ------ ## PyTorch Implementation (Model & Training Code) Below is the complete PyTorch code for the proposed model and an example training loop. This code assumes that the dataset has been preprocessed into tensors: X_train (baseline expressions), Y_train (perturbed expressions), and P_train (perturbation indicator vectors). The model is designed to run on GPU for efficiency. python import torch import torch.nn as nn import torch.optim as optim # Define device for GPU acceleration device = torch.device(cuda if torch.cuda.is_available() else cpu) print(\"Using device:\", device) # Example shapes (for illustration; replace with actual dataset dimensions) num_genes = X_train.shape[1] # dimensionality of gene expression (e.g. 20000) num_target_genes = P_train.shape[1] # dimensionality of perturbation vector (e.g. 100) # 1. Define the model architecture class PerturbationPredictor(nn.Module): def __init__(self, input_dim_expr, input_dim_pert, hidden_dim_expr=512, hidden_dim_pert=128, hidden_dim_comb=512): \"\"\" input_dim_expr: number of genes (baseline expression vector length) input_dim_pert: number of possible targeted genes (length of perturbation indicator vector) \"\"\" super(PerturbationPredictor, self).__init__() # Baseline expression encoder network self.expr_encoder = nn.Sequential( nn.Linear(input_dim_expr, hidden_dim_expr), nn.ReLU(), nn.Linear(hidden_dim_expr, hidden_dim_expr), nn.ReLU() ) # Perturbation encoder network self.pert_encoder = nn.Sequential( nn.Linear(input_dim_pert, hidden_dim_pert), nn.ReLU(), nn.Linear(hidden_dim_pert, hidden_dim_pert), nn.ReLU() ) # Fusion network to combine baseline and perturbation representations 131 self.comb_fc1 = nn.Linear(hidden_dim_expr + hidden_dim_pert, hidden_dim_comb) self.comb_act = nn.ReLU() self.comb_fc2 = nn.Linear(hidden_dim_comb, input_dim_expr) # outputs delta for each gene def forward(self, baseline_expr, perturb_vec): # baseline_expr: Tensor of shape (batch_size, input_dim_expr) # perturb_vec: Tensor of shape (batch_size, input_dim_pert ) # Encode baseline and perturbation z_expr = self.expr_encoder(baseline_expr) # shape: (batch, hidden_dim_expr) z_pert = self.pert_encoder(perturb_vec) # shape: (batch, hidden_dim_pert) # Combine encoded representations z_comb = torch.cat([z_expr, z_pert], dim=1) # shape: ( batch, hidden_dim_expr+hidden_dim_pert) = self.comb_act(self.comb_fc1(z_comb)) # hidden layer delta = self.comb_fc2(h) # predicted change in expression # Add the predicted change (delta) to the baseline to get final prediction pred_expr = baseline_expr + delta return pred_expr # Instantiate the model and move to GPU model = PerturbationPredictor(num_genes, num_target_genes).to( device) print(model) # 2. Set up loss function and optimizer criterion = nn.MSELoss() # Mean Squared Error loss optimizer = optim.Adam(model.parameters(), lr=1e-3) # 3. Training loop (example) num_epochs = 20 batch_size = 256 # If data is large, use DataLoader for batching (assuming X_train, P_train, Y_train are TensorDatasets) train_dataset = torch.utils.data.TensorDataset(X_train, P_train, Y_train) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) for epoch in range(1, num_epochs+1): model.train() total_loss = 0.0 for X_batch, P_batch, Y_batch in train_loader: # Move data to device X_batch = X_batch.to(device) P_batch = P_batch.to(device) Y_batch = Y_batch.to(device) # Forward pass pred = model(X_batch, P_batch) loss = criterion(pred, Y_batch) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() total_loss += loss.item() * X_batch.size(0) avg_loss = total_loss / len(train_dataset) if epoch % 5 == 0 or epoch == 1: print(f\"Epoch {epoch:02d}: Training MSE = {avg_loss:.4f}\") # 4. Evaluation on test set model.eval() with torch.no_grad(): X_test = X_test.to(device) P_test = P_test.to(device) 132 Y_test = Y_test.to(device) pred_test = model(X_test, P_test) mse_full = criterion(pred_test, Y_test).item() # Compute Pearson correlation coefficient (PCC) for each test sample pred_np = pred_test.cpu().numpy() Y_np = Y_test.cpu().numpy() baseline_np = X_test.cpu().numpy() pcc_list = [] topk = 20 topk_pcc_list = [] for in range(Y_np.shape[0]): true_expr = Y_np[i] pred_expr = pred_np[i] # PCC for all genes cov = np.cov(true_expr, pred_expr, bias=True) # cov matrix 2x2: cov[0,1] is covariance between true and pred -8) pcc = cov[0,1] / (np.std(true_expr) * np.std(pred_expr) + 1e pcc_list.append(pcc) # PCC for top-k differentially expressed genes # Identify top-k genes by absolute change in true expression vs baseline base_expr = baseline_np[i] diff = np.abs(true_expr - base_expr) topk_idx = np.argsort(diff)[-topk:] if topk > 0: true_top = true_expr[topk_idx] pred_top = pred_expr[topk_idx] cov_top = np.cov(true_top, pred_top, bias=True) topk_pcc = cov_top[0,1] / (np.std(true_top) * np.std( pred_top) + 1e-8) topk_pcc_list.append(topk_pcc) # Calculate mean metrics mean_pcc = float(np.mean(pcc_list)) mean_topk_pcc = float(np.mean(topk_pcc_list)) print(f\"Test MSE (all genes): {mse_full:.4f}\") print(f\"Test mean PCC (all genes): {mean_pcc:.3f}\") print(f\"Test mean PCC (top-{topk} DE genes): {mean_topk_pcc:.3f }\") **Explanation of the Code:** - We define PerturbationPredictor model class that implements the architecture described. The baseline expression encoder (expr_encoder) and perturbation encoder (pert_encoder) are simple feed-forward networks. These could be extended or replaced with more complex sub-networks (e.g., adding dropout, or using graph convolution in pert_encoder if incorporating gene network). The combined representation is fed through two linear layers (comb_fc1 and comb_fc2) with ReLU in between. The output of comb_fc2 is vector of length equal to number of genes, representing the predicted change in expression. We then add this to the baseline (pred_expr = baseline + delta) to get the final prediction. - We move the model to GPU (.to(device)). The training loop iterates over mini-batches of data (using DataLoader for efficiency). For each batch, we do forward pass to compute predictions and then use nn.MSELoss to compute the loss against the true perturbed expression. We then backpropagate (loss.backward()) and update weights with Adam optimizer. We print the training MSE every few epochs for monitoring. - In the evaluation section, after training, we compute metrics on X_test, P_test, Y_test. We calculate the overall MSE on test (as mse_full). Then for each test sample, we compute the Pearson correlation coefficient (PCC) between predicted and true expression. We do this manually using numpy: 133 computing the covariance and standard deviations (note: one could also use scipy.stats.pearsonr or torchmetrics for this). We also compute **top-20 PCC** by finding the 20 genes with largest absolute change in the true data ( compared to baseline) and computing PCC on that subset. Finally, we print the average PCC across all test cells, and the average top-20 PCC. **Note:** In practice, you would likely use vectorized operations or library functions to compute PCC for all cells at once. Also, you might evaluate the model separately on the different generalization scenarios (e.g., one test set for unseen genes, one for seen genes, etc.) and compare performance. The code above provides template that can be adapted for those purposes. By executing this model training pipeline, we expect to obtain model that can accurately predict gene expression changes in K562 cells after CRISPRi perturbations. Its performance will be reflected in low MSE (especially on perturbed genes) and high correlation with actual profiles, even for perturbations or cell states not seen in training. Ultimately, this demonstrates powerful approach to **in silico** predict cellular response to genetic perturbations, leveraging modern deep learning (PyTorch with GPU) for both precision and generalization. The combination of baseline context and perturbation identity as inputs allows the model to capture conditional dependencies (how perturbations effect can vary by cell state), addressing one of the key challenges in predictive biology."
        },
        {
            "title": "Research Agent Output",
            "content": "Norman et al. dataset(gene knockout, scRNA-seq) Task Analysis and Technical Challenges I. Biological Context of CRISPRi Perturbations The Norman et al. dataset captures transcriptional consequences of CRISPRi-mediated gene repression through single-cell profiling of: - 105 individual gene knockouts - 131 pairwise gene interactions[ˆ1][ˆ4] - 90,000 cells with baseline (unperturbed) and perturbed states [ˆ4] Key biological considerations: 1. **Non-linear genetic interactions**: Pairwise perturbations exhibit emergent effects not predictable from individual gene knockouts[ˆ2] 2. **Cell-state heterogeneity**: Native transcriptional variability in K562 populations influences perturbation responses[ˆ2][ˆ4] 3. **Technical noise characteristics**: Dropout patterns and UMI count distributions differ between perturbed/control cells [ˆ4][ˆ6] II. Machine Learning Challenges 1. **High-dimensional output space**: Predicting 20,000+ gene expressions simultaneously 2. **Sparse perturbation coverage**: Only 0.6% of possible gene pairs tested in original study[ˆ1] 3. **Context-dependent effects**: Perturbation responses vary with baseline cellular states[ˆ2][ˆ5] 134 4. **Combinatorial explosion**: Quadratic growth of possible gene interactions with target count **Evaluation Protocol Design** **Train/Test Splits**: - **Unseen perturbations**: Hold out 20% of single-gene and 30% of pairwise perturbations - **Unseen contexts**: Stratify by baseline PCA clusters, hold out entire cell-state subpopulations ------ Methodological Framework: GenePerturbNet I. Architectural Overview **Core Components**: 1. **Baseline Encoder**: Variational autoencoder mapping unperturbed expression $x$ to latent $z$. 2. **Perturbation Transformer**: Attention network processing target genes $g$ into perturbation vector delta. 3. **Interaction Module**: Graph neural network modeling genegene interaction effects. 4. **Response Decoder**: generating perturbed expression profile II. Training Strategy **Loss Function:** $mathcal{L} = ELBO(x,y) + lambda_1 MSE(y, hat{y}) + lambda_2 mathcal{L}_{contrast}$ Where: - **Contrastive Loss**: $mathcal{L}_{contrast} = -logfrac{exp(s(y,hat{y})/ tau)}{sum_{y}exp(s(y,hat{y})/tau)}$ - $s()$: Cosine similarity - $tau$: Temperature parameter IV. Curriculum Learning Schedule: 1. Phase 1: Pretrain on single-gene perturbations 2. Phase 2: Fine-tune with pairwise interactions 3. Phase 3: Joint optimization with contrastive loss Implementation and Benchmarking I. Code Implementation python import scanpy as sc import scvi import torch from torch import nn from scvi import REGISTRY_KEYS from scvi.module.base import BaseModuleClass class GenePerturbNet(scvi.model.SCVI): def __init__(self, adata, n_hidden=256, n_latent=32, perturbation_embedding=64, **kwargs): super().__init__(adata, **kwargs) self.pert_embed = nn.Embedding(adata.n_vars, perturbation_embedding) self.transformer = nn.TransformerEncoderLayer( 135 d_model=perturbation_embedding, nhead=4 ) self.gnn = GeneInteractionGNN(perturbation_embedding) self.decoder = nn.Sequential( nn.Linear(n_latent + perturbation_embedding, n_hidden), nn.ReLU(), nn.Linear(n_hidden, adata.n_vars) ) def forward(self, x, perturbations, *args): qz_m, qz_v, = self.encoder(x) pert_emb = self.pert_embed(perturbations) delta = self.transformer(pert_emb) z_pert = + delta.mean(dim=1) px_scale, px_r, px_rate, px_dropout = self.decoder(z_pert) return px_rate, qz_m, qz_v, z_pert class GeneInteractionGNN(nn.Module): def __init__(self, embed_dim): super().__init__() self.conv1 = nn.Conv1d(embed_dim, embed_dim*2, kernel_size =3) self.attn = nn.MultiheadAttention(embed_dim, num_heads=4) def forward(self, gene_pairs): = self.conv1(gene_pairs) x, _ = self.attn(x, x, x) return x.mean(dim=1) II. Training Protocol python adata = sc.read(\"norman_2019.h5ad\") scvi.model.setup_anndata(adata, layer=\"counts\", categorical_covariate_keys=[\"perturbation\"]) model = GenePerturbNet(adata, n_latent=32, perturbation_embedding=64) model.train(max_epochs=100, batch_size=256, plan_kwargs={\"contrastive_weight\":0.5}) control_cells = adata[adata.obs[\"perturbation\"] == \"control\"] perturbed_pred = model.predict(control_cells, targets=[\"geneA\", \"geneB\"]) III. Conclusion and Future Directions This framework demonstrates that deep learning architectures explicitly modeling genetic interactions can significantly improve perturbation prediction accuracy. Key recommendations: 1. **Data Expansion**: Incorporate epigenetic data to better model CRISPRi efficiency 2. **Dynamic Modeling**: Add temporal component to capture perturbation kinetics 3. **Transfer Learning**: Adapt model to other cell types using few-shot learning The provided codebase offers foundation for extending perturbation prediction to novel experimental designs and therapeutic applications."
        },
        {
            "title": "Gemini DeepResearch",
            "content": ""
        },
        {
            "title": "Research Agent Output",
            "content": "Norman et al. dataset(gene knockout, scRNA-seq) Task Analysis # Dataset Description The foundation of this predictive modeling task lies in the comprehensive dataset generated by Norman et al. and published in Science in 2019. This study aimed to explore genetic interaction manifolds constructed from rich singlecell phenotypes using Perturb-seq approach.15 The experiments were conducted on human K562 leukemia cells, commonly used model system in hematological research. The study employed CRISPRi to target total of 236 genetic perturbations, encompassing 105 single genes and 131 pairs of genes. The scale of the dataset is substantial, comprising approximately 90,000 single-cell RNA-seq profiles, which includes both control cells and cells subjected to various single and combinatorial CRISPRi perturbations. The datasets focus on both single and paired gene perturbations is crucial for training model capable of predicting combinatorial effects, which are often non-additive and complex. Single gene perturbations provide baseline information about the effect of individual gene silencing. Paired perturbations allow the model to learn about genetic interactions, where the combined effect of perturbing two genes is different from the sum of their individual effects. This is essential for capturing the non-linear nature of biological systems. # Problem Definition The primary objective is to develop predictive model that takes as input the baseline gene expression profile of an unperturbed K562 cell and the identity of the target gene(s) for CRISPRi perturbation. The desired output of the model is the predicted gene expression profile of the same cell after the specified perturbation has been applied. The models performance will be evaluated under two key scenarios to assess its generalizability: 1. **Unseen Perturbations:** The model should be able to accurately predict the effects of CRISPRi targeting genes or gene pairs that were not included in the training data. This scenario tests the models ability to extrapolate its learned knowledge to novel genetic manipulations. 2. **Unseen Cell Contexts:** The model should be capable of predicting the response to perturbation in cells with baseline gene expression profiles that were not observed during the training phase. This evaluates the models robustness to the inherent heterogeneity within the K562 cell population. The evaluation scenarios highlight the need for model that can generalize beyond the specific perturbations and cell states seen during training, which is significant challenge in biological systems due to their complexity and inherent variability. model trained only on observed perturbations might not accurately predict the effects of novel perturbations or responses in slightly different cellular contexts. Evaluating on unseen data is crucial for assessing the models robustness and real-world applicability. # Challenges and Considerations 137 Developing an accurate predictive model for gene expression profiles following CRISPRi perturbation presents several significant challenges stemming from the inherent complexity of biological systems and the nature of single-cell data. The gene expression data obtained from scRNA-seq experiments is inherently high-dimensional, with measurements for thousands of genes in each individual cell. This high dimensionality necessitates the use of sophisticated modeling techniques capable of handling large number of input features. Furthermore, the underlying biological networks that govern gene expression are incredibly complex, involving intricate regulatory relationships between genes, transcription factors, and other cellular components. The relationship between gene perturbations and the resulting changes in gene expression is often non-linear.1 Genetic interactions, such as synergistic or epistatic effects, mean that the combined effect of perturbing multiple genes cannot simply be predicted by summing the individual effects of each perturbation.1 The model must be able to capture these complex, non-additive relationships to make accurate predictions, especially for the 131 gene pairs targeted in the Norman et al. (2019) dataset. While CRISPRi is generally considered to have fewer off-target effects compared to CRISPRko, the possibility of unintended gene repression at secondary genomic loci still exists. The specificity of CRISPR-Cas9 systems relies heavily on the design of the single guide RNA (sgRNA), and mismatches between the sgRNA and off-target DNA sequences can lead to unintended gene silencing. Although the Norman et al. (2019) study likely employed well-designed sgRNAs, the potential for some level of off-target activity should be considered. Single-cell RNA-seq data is also characterized by inherent noise and technical variability.11 Factors such as cell lysis efficiency, reverse transcription efficiency, and sequencing depth can introduce variability in the measured gene expression levels. The predictive model needs to be robust to this noise and focus on capturing the true biological signals induced by the CRISPRi perturbations. Finally, clonal expansion, phenomenon where certain perturbed cells proliferate more rapidly than others, can occur during single-cell CRISPR screens. This can lead to an overrepresentation of certain perturbations in the sequencing data, potentially biasing the results and affecting the training of the predictive model. Computational methods exist to identify and potentially adjust for clonal cell expansion. Accurately modeling the intricate web of gene regulatory interactions and the non-linear effects of perturbations requires sophisticated computational approaches that can capture these complexities beyond simple additive models. Biological systems are highly interconnected, and the effect of perturbing one gene can propagate through the network, affecting the expression of many other genes in nonpredictable ways using linear models. Therefore, models capable of learning complex, non-linear relationships are needed. ------ New Method Plan To address the challenges outlined above and develop an accurate predictive model for gene expression profiles following CRISPRi, deep learning-based approach is proposed. Specifically, Graph Neural Network (GNN) architecture, 138 inspired by the success of models like GEARS, appears to be promising candidate. **Proposed Model Architecture** The proposed model will leverage GNN to incorporate prior knowledge about gene-gene relationships and model the perturbation effects as changes within this network. GNNs are well-suited for learning representations of nodes in graph by aggregating information from their neighbors, allowing the model to capture the dependencies and interactions between genes. The input to the model will consist of two components: (1) the baseline gene expression profile of an unperturbed cell, represented as vector of gene expression counts, and (2) the identity of the target gene(s) for CRISPRi. For single gene perturbations, the target gene will be directly specified. For paired gene perturbations, the identities of both target genes will be provided. The model architecture will comprise the following key components: 1. **Gene Embedding Layer:** Each gene in the dataset will be assigned low-dimensional embedding vector. These embeddings will capture intrinsic properties of the genes and will be learned during the training process. Prior biological knowledge, such as gene co-expression networks or functional annotations from databases like Gene Ontology ( GO) 36, can be used to initialize these embeddings or to inform the GNN architecture. 2. **Perturbation Embedding Layer:** The identity of the perturbed gene(s) will also be encoded into an embedding vector. For single perturbations, dedicated embedding will be learned for each targeted gene. For paired perturbations, the embeddings of the two target genes can be combined (e.g ., through summation or concatenation) to represent the combined perturbation. 3. **Graph Neural Network (GNN):** gene regulatory network ( GRN) will be constructed, where genes are represented as nodes and edges represent regulatory relationships between them. This GRN can be derived from publicly available databases or inferred from the unperturbed single-cell expression data. The gene embeddings will serve as initial node features in this graph. The GNN will then propagate information across the network, allowing each genes representation to be informed by its neighbors and their interactions. The perturbation embedding will be incorporated into the GNN, potentially by modifying the node features of the perturbed gene(s) or by influencing the message passing process. 4. **Cell State Encoding Layer:** The baseline gene expression profile of the unperturbed cell will be passed through separate neural network (e.g., multi-layer perceptron) to learn low-dimensional representation of the cells initial transcriptional state. This encoding will capture the cell context and will be used to condition the prediction of the perturbed state. 5. **Prediction Layer:** The output of the GNN (representing the perturbed gene embeddings) and the cell state encoding will be combined (e.g., through concatenation followed by another neural network) to predict the gene expression profile after the perturbation. The output will be vector of the same dimensionality as the input gene expression profile, representing the predicted expression levels for each gene in the cell. The rationale behind choosing this architecture is that it allows for the integration of prior biological knowledge about gene-gene interactions through the GRN. This can help the model to better understand the potential downstream effects of perturbation. Furthermore, the use of embeddings allows the model to learn meaningful representations of genes and perturbations, potentially enabling better generalization to unseen perturbations. **Feature Engineering and Data Preprocessing** The Norman et al. (2019) dataset will require careful preprocessing before being used to train the model. The steps involved will include: 1. **Data Loading and Normalization:** The processed gene expression matrices will be loaded using appropriate libraries like Scanpy or AnnData. The gene expression counts will be normalized to account for differences in sequencing depth between cells. Log transformation (e.g., using natural logarithm after adding pseudocount) will be applied to stabilize the variance of gene expression levels. 2. **Perturbation Information Encoding:** The perturbation information, specifying the targeted gene(s) for each cell, will be extracted from the datasets metadata. For single gene perturbations, the gene name will be used. For paired gene perturbations, both gene names will be used. These gene names will then be mapped to their corresponding indices or identifiers in the gene expression matrix. The perturbation information will be encoded as input to the model, potentially using one-hot encoding initially, where binary vector indicates which genes are targeted. Alternatively, learned embeddings for each gene could be used to represent the perturbation. 3. **Control Sample Handling:** Cells labeled as control ( unperturbed) will be identified and used to establish the baseline gene expression profiles. These control profiles will be crucial for training the model to predict the changes in expression induced by the perturbations. 4. **Feature Selection:** Given the high dimensionality of the gene expression data, feature selection techniques may be employed to focus on the most relevant genes. One common approach is to identify highly variable genes (HVGs) across the cell population and use only these genes as input to the model.16 This can reduce the dimensionality of the input, potentially improving model training and performance. 5. **GRN Construction (if applicable):** If GNN is used, gene regulatory network will need to be constructed. This could involve using publicly available databases of known gene interactions or inferring network from the unperturbed single-cell expression data using methods like co-expression analysis or network inference algorithms. **Training Strategy** The training of the predictive model will involve the following steps: 1. **Data Splitting:** The dataset will be split into training, validation, and test sets. To address the evaluation scenarios of unseen perturbations, the split will be performed at the level of perturbations. This means that all cells corresponding to certain perturbations (both single and paired) will be held out in the test set and will not be seen by the model during training. separate validation set, also containing held-out perturbations, will be used for hyperparameter tuning and model selection.16 Carefully designing the data splitting strategy is crucial to ensure that the model is truly evaluated on unseen perturbations and cell contexts, avoiding information leakage from the training set. 2. **Loss Function:** The model will be trained to minimize the difference between the predicted gene expression profiles and the observed gene expression profiles. The Mean Squared Error (MSE) will be used as the primary loss function, as it directly measures the average squared difference between the predicted and observed values. 3. **Optimizer:** An appropriate optimization algorithm, such as Adam, will be used to update the models parameters during training. learning rate schedule, which gradually reduces the learning rate over time, may be employed to improve convergence and prevent overfitting. 4. **Hyperparameter Tuning:** The model architecture and training process will have several hyperparameters (e.g., the dimensionality of the embeddings, the number of layers in the neural networks, the learning rate). These hyperparameters will be tuned using the validation set. Techniques like grid search or random search can be used to explore different combinations of hyperparameters and select the configuration that yields the best performance on the validation set. 5. **Overfitting Prevention:** Techniques such as dropout, weight regularization (e.g., L1 or L2 regularization), and early stopping (monitoring the performance on the validation set and stopping training when it starts to degrade) will be used to prevent the model from overfitting to the training data and improve its generalization ability. **Strategies for Handling Unseen Perturbations and Cell Contexts ** The proposed GNN-based architecture offers several advantages for handling the challenges of unseen perturbations and cell contexts: - **Generalization to Unseen Genes (for GNN):** If GNN is used and the GRN includes genes that are not targeted in the training set, the model may still be able to make informed predictions about the effects of perturbing these unseen genes by leveraging their relationships with other genes in the network.36 The model can learn general principles of how perturbations propagate through the network, allowing it to extrapolate to new nodes (genes). Predicting the effects of completely novel perturbations (genes not seen during training) is significant challenge. - **Cell State Conditioning:** By explicitly encoding the baseline gene expression profile of the unperturbed cell, the model can condition its prediction on the specific context of that cell. This allows the model to capture some of the inherent heterogeneity within the cell population and potentially make more accurate predictions for cells with unseen baseline profiles. - **Learned Embeddings:** The use of learned embeddings for genes and perturbations can help the model to capture semantic relationships between different genes and perturbations. If the embedding space is learned effectively, the model may be able to generalize to unseen perturbations that are functionally similar to those seen during training, even if the specific genes were not encountered before. While more advanced techniques like meta-learning or domain adaptation could potentially further improve the models ability to handle unseen perturbations and cell contexts, the proposed GNN architecture with cell state conditioning 141 and learned embeddings provides strong foundation for addressing these challenges. ------ Generate Prediction Model Code The prediction model will be implemented using the Python programming language and several key libraries commonly used in machine learning and single-cell data analysis. **Implementation Details** - **Programming Language:** Python - **Key Libraries:** - **PyTorch** or **TensorFlow/Keras:** For implementing the neural network architecture, including the GNN and other layers. - **Scanpy** or **AnnData:** For efficient handling and preprocessing of the single-cell RNA-seq data. - **NumPy:** For numerical computations and array manipulations. - **SciPy:** For scientific computing, including statistical functions. - **scikit-learn:** For evaluation metrics (MSE, PCC) and potential utility functions. **Code Structure and Key Functions** The codebase will be organized into several modules or classes to ensure modularity and maintainability: 1. **DataLoader Class:** - **Purpose:** Responsible for loading the Norman et al. (2019) dataset from the specified files (e.g., MTX, TSV). - **Functionality:** - Reads the gene expression matrix and metadata. - Performs normalization and log transformation. - Encodes perturbation information. - Splits the data into training, validation, and test sets based on perturbations. - Provides data loaders for efficient batching during training. 2. **Model Class:** - **Purpose:** Defines the neural network architecture, including the gene embedding layer, perturbation embedding layer, GNN (if chosen), cell state encoding layer, and prediction layer. - **Functionality:** - Initializes the model parameters. - Implements the forward pass of the network, taking baseline expression and perturbation information as input and outputting the predicted perturbed expression. 3. **Trainer Class:** - **Purpose:** Handles the training process of the model. - **Functionality:** - Takes the model, data loaders, loss function, and optimizer as input. - Implements the training loop, including forward pass, loss calculation, backpropagation, and parameter updates. - Monitors performance on the validation set and implements early stopping if needed. - Saves the trained model parameters. 4. **Evaluator Class:** - **Purpose:** Evaluates the performance of the trained model on the test set. - **Functionality:** - Loads the trained model parameters. - Iterates through the test data. - Makes predictions for each test sample. - Calculates the evaluation metrics (MSE, PCC, Top-k PCC) by comparing predictions with the observed data. - Reports the evaluation results. 5. **Predictor Class:** - **Purpose:** Allows for making predictions on new, unseen data (e.g., baseline expression profile and perturbation). - **Functionality:** - Loads the trained model parameters. - Takes baseline expression profile and perturbation information as input. - Preprocesses the input data as needed. - Uses the trained model to generate the predicted gene expression profile after the perturbation. **Instructions for Usage** 1. **Install Libraries:** Install the necessary Python libraries using pip: Bash pip install torch torchvision torchaudio scanpy numpy scipy scikit-learn (or tensorflow and keras if using TensorFlow). 2. **Download Data:** Download the processed data files for GSE133344 from GEO or Figshare and place them in designated directory. 3. **Prepare Input Data:** Ensure that the input data for prediction (baseline gene expression profile and perturbation identity) is in the expected format (e.g., NumPy array or Pandas DataFrame). 4. **Run the Code:** Execute the Python script containing the model implementation, training, and evaluation steps. The script should: - Initialize the DataLoader with the path to the data files. - Split the data into training, validation, and test sets. - Initialize the Model with the appropriate architecture and hyperparameters. - Initialize the Trainer with the model, data loaders, loss function, and optimizer. - Train the model using the Trainer. - Initialize the Evaluator with the trained model and test data loader. - Evaluate the model and print the results. - (Optionally) Use the Predictor to make predictions on new data. **Evaluation and Results** comprehensive evaluation of the developed predictive model is crucial to assess its performance and generalizability. **Experimental Setup** The Norman et al. (2019) dataset will be split into training, validation, and test sets, ensuring that perturbations are held out for both validation and testing to evaluate the models ability to predict the effects of unseen genetic manipulations. The split will likely involve significant portion of the data for training, with smaller portions allocated for validation (for hyperparameter tuning and model selection) and testing (for final performance evaluation).16 The specific hyperparameters of the chosen model architecture (e.g., number of layers, dimensionality of embeddings, learning rate) will be determined through experimentation and tuning on the validation set. To make prediction for given perturbation, the model will take as input the baseline gene expression profile of an 143 unperturbed cell (which could be an average profile of control cells or specific control cells profile) and the identity of the target gene(s). **Performance Metrics** The models performance on the test set will be quantified using the three evaluation metrics defined earlier: Mean Squared Error (MSE), Pearson Correlation Coefficient (PCC), and Topk PCC. These metrics will be calculated by comparing the models predicted gene expression profiles with the actual observed profiles in the test set for the held-out perturbations. The results will be reported separately for unseen single-gene perturbations and unseen paired-gene perturbations to assess the models ability to handle both types of genetic manipulations. It may also be informative to report the performance on different subsets of genes, such as the highly variable genes, as these are often the most biologically relevant. Visualizations, such as scatter plots of predicted vs. observed gene expression for representative perturbations, can provide further insights into the models predictive capabilities."
        }
    ],
    "affiliations": [
        "Google DeepMind",
        "Harvard University",
        "Helmholtz Zentrum Munchen",
        "Stanford University",
        "University of Pennsylvania",
        "Yale University"
    ]
}