{
    "paper_title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
    "authors": [
        "Samuel Ferino",
        "Rashina Hoda",
        "John Grundy",
        "Christoph Treude"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context."
        },
        {
            "title": "Start",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1 Walking the Tightrope of LLMs for Software Development: Practitioners Perspective Samuel Ferino, Rashina Hoda, John Grundy, Christoph Treude AbstractBackground: Large Language Models emerged with the potential of provoking revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from software developers perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers personality and damage to developers reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context. Index TermsSoftware Engineering, Artificial Intelligence, Large Language Models, Socio-Technical Grounded Theory, Interviews"
        },
        {
            "title": "1 INTRODUCTION",
            "content": "There is nothing permanent except change. Heraclitus This quote by the Greek philosopher Heraclitus highlights how the world is continuously changing. Large Language Models (LLMs) are the contemporary catalyst for revolution in the Information Technology sector [1], starting from the release of LLM tools like ChatGPT and GitHub Copilot for the general public between 2022 and 2023 [2], [3]. LLM-powered code generators and assistants like GitHub Copilot, for instance, fostered the emergence of new potential pillar for software development: AI pair programming [4], [5]. LLMs can support variety of software development tasks, such as code generation and information retrieval [6][8]. Enterprise LLM adoption reports from McKinsey [9] and DORA [10], [11] call attention to growing interest from companies in examining the potential of LLMs for software development. There is also growing shift from traditional Q&A online communities like Stack Overflow towards LLM tools as the first source of support [1], [12]. For instance, the decline in networking traffic of Stack Overflow may be attributed to developers adopting LLMs [13]. Many investigations (e.g., [14][17]) highlight the potential benefits associated with software practitioners adopting LLMs. For instance, Cui et al. [15] found software developers using GitHub Copilot achieving an increase of 26.08% in the number of weekly completed tasks when conducting an experiment with almost five thousand software developers from companies including Microsoft and Accenture. On the other hand, many studies (e.g., [18][21]) present the downsides of using LLMs. For instance, Lee et al. [20] S. Ferino, R. Hoda, and J. Grundy are with the Faculty of Information Technology, Monash University, Melbourne, Australia. E-mail: {samuel.demouraferino, rashina.hoda, john.grundy}@monash.edu C. Treude is with the School of Computing and Information Systems, Singapore Management University, Singapore. E-mail: ctreude@smu.sg observed from surveying 319 knowledge workers that LLMs can potentially affect software developers critical thinking skills. Although there is an emerging amount of studies related to LLMs in Software Engineering (SE) [6], [22], there is still need for investigations focusing on managing the impact of LLMs. Mohamed et al. [23] conducted systematic literature review on how LLMs affect software developer productivity. From their thirty-seven selected studies, they summarised most benefits and risks concerning how LLMs affect software developer productivity, such as supporting knowledge acquisition and promoting overreliance, disruptions to developer flow. They highlight that few studies explore aspects involving communication and humanhuman collaboration. Ferino et al. [24] conducted systematic review exploring novice software developers adoption and use of LLMs in SE activities. From their 80 selected studies, they identified many research gaps, such as exploring the impact of LLMs on mentorship interactions. To gain more understanding about the impact of LLMs in SE tasks and especially how to manage it, our investigation focused on answering this main question: How does the use of LLMs for software development impact software practitioners? This question was decomposed into the following research questions (RQs): RQ1. How do LLMs take software developers forward? Taking developers forward involves benefits gained from using LLMs. RQ2. How do LLMs hold software developers back? Holding developers back involves disadvantages arising from using LLMs. RQ3. How do software developers achieve balanced use of LLMs? To answer these RQs, we conducted twenty-two semi-structured interviews with software practitioners across three rounds - between October (2024) and September (2025). Our study aims to comprehend the current industrial perspective on software developers adopting Large Language Model-based tools on SE5 2 0 2 ] . [ 1 8 2 4 6 0 . 1 1 5 2 : r JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 2 Fig. 1: Study methodology. related activities, which involves exploring the benefits, challenges, limitations, and recommendations shared by software practitioners involved in SE-related activities. Our analysis reveals the following main benefits: (B1) reduced effort due to LLMs as foundation to boost code development and perceived saving time; (B2) flow experience when LLMs mitigate interruptions and automate simple and tedious tasks; (B3) interaction with LLMs influencing developers personality and creating safe space; and (B4) LLMs promoting LLM entrepreneurship as consultant for every (not complex) question; and these disadvantages: (D1) disruption of the development flow due to an increase in developers effort influenced by LLMs; (D2) reduced effort due to LLMs negatively impacting developers personality (e.g., laziness) and hindering developers skills; (D3) interaction with LLMs reducing mentorship opportunities. The main contributions of this research include: Identification and categorisation of benefits and disadvantages of adopting LLMs for software development tasks in terms of individual, team, organisation, and society level. set of recommendations on how to best use LLMs for software development tasks."
        },
        {
            "title": "2.1 Why Socio-Technical Grounded Theory (STGT)?",
            "content": "In the face of many other qualitative research methods (e.g., thematic analysis, content analysis), we choose STGT, variation of Grounded Theory (GT) [25], [27]. While STGT also includes human and social aspects similar to GT, it also acknowledges the importance of technical knowledge - very relevant aspect of software engineering research - enabling more profound insights. In fact, STGT stands out as research method suitable for topics where practice-based or industry perspectives are relevant. To better explain the importance of using STGT in our context, we will explain our research topics using the four dimensions of its underlying socio-technical research framework: Socio-technical Phenomenon: Our research investigates software practitioners perspectives on the role of LLM tools in software development. This phenomenon is characterised as socio-technical because the potential influence of individual aspects (e.g., motivations, emotions), team aspects (e.g., collaboration), and technology aspects (e.g., usability, features) can interplay on the experiences of software practitioners using LLM-powered tools. Socio-technical Domain and Actors: The domain of LLMs for SE (LLM4SE), an intersection between Software Engineering and Artificial Intelligence, is socio-technical domain since there is tight coupling between its social and technical aspects [25], [27], [28]. The actors of this domain encompass software practitioners using LLM tools in software development, such as software developers, software engineers, data engineers, data scientists, and DevOps engineers. Socio-technical researchers: This research was conducted by combining different experiences and skills among the research team. The interviews were conducted by an earlycareer researcher under the supervision of three experienced researchers. Socio-technical data, tools, and techniques: During the study, the first author utilised Qualtrics survey to collect participant demographics, Zoom for recording and transcription, DeepL2 for translation of the interview transcriptions in Portuguese (P1, P4, P6) to English, and Nvivo and spreadsheets to support the analysis of the interview transcriptions. Before starting the STGT study, it is fundamental to define how the STGT study will be conducted in terms of ontology, epistemology, and research paradigm. STGT offers flexibility in comparison with the traditional GT methods (i.e., StraussCorbinian GT, Glaserian GT, and Constructivist GT) with specific paradigms. Ontology is described as What we believe exists or what we perceive as reality, in research context [27, Chapter 5]. 1. Approved by Monash Human Research Ethics Committee (No. 44875) 2. www.deepl.com JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 3 TABLE 1: Participant Demographics. ID P1 P2 P3 P4 P6 P7 P8 P9 P10 P12 P13 P14 P15 P16 P18 P19 P20 P21 P22 Role Domain Country of Residence Total Experience Self-Reported Level of Experience Round Software Developer Software Engineer Software Engineer IT IT IT Software Developer Finance Software Developer IT Data Engineer DS/BD BI Analyst TELCOM Software Engineer IT AI Engineer Government Software Engineer Web Developer IT IT Brazil Australia Australia Brazil Australia Brazil Australia Australia Brazil Canada Australia Software Engineer Healthcare United States Software Developer IT Data Engineer TELCOM Researcher Engineering R&D Researcher Gaming Data Analyst IT Software Developer Finance ML Scientist Software Engineer Research Engineer Software Developer IT IT IT IT Australia Australia Australia Canada Australia Finland Canada Malaysia Singapore United States 3-5 Years 1-2 Years 3-5 Years 3-5 Years 0-0.9 Years 3-5 Years 0-0.9 Years 1-2 Years +10 Years 6-10 Years 3-5 Years 6-10 Years 1-2 Years 1-2 Years 0-0.9 Years 1-2 Years 1-2 Years 3-5 Years 3-5 Years 1-2 Years 1-2 Years +10 Years Experienced Experienced Intermediate Intermediate Intermediate Highly Experienced Intermediate Experienced Intermediate Highly Experienced Highly Experienced Experienced Advanced Beginner Intermediate Novice Intermediate Intermediate Intermediate Experienced Intermediate Experienced Highly Experienced 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 IT: Information Technology; DS/BD: Data Science/Big Data; TELCOM: Telecommunications. Our study involves participants combining physical contexts and interactions (e.g., developers collaborating in team physically) and virtual contexts and interactions (e.g., developers working remotely). Epistemology is described as What can be treated as knowledge and how that knowledge is gained, in research context [27, Chapter 5]. Since we understand that the perceptions about benefits, challenges, and recommendations involving LLM adoption are subject to interpretation, we decided to adopt subjective epistemology approach. Research paradigm is described as Researcher worldview about what they believe is reality (ontology) and how knowledge about that reality can be gained (epistemology), in research context [27, Chapter 5]. Since we are adopting subjective epistemology approach, believing in socially constructed reality, we decided to follow constructivist research paradigm."
        },
        {
            "title": "2.2 Study Design and Piloting",
            "content": "Based on the findings (i.e., benefits, challenges, recommendations) from our systematic literature review [24], we developed preliminary interview guide, which also included potential followup questions. This interview guide [26] was improved based on discussions with the PhD supervisors, as well as feedback from an industrial collaborator, who has experience managing software team in an Australian company. The Attitude Towards Artificial Intelligence (ATAI) scale, developed by [29], was included to collect participants attitudes towards LLMs (AI). ATAI scale includes the following five nine-point scale questions, which we adapted to five-point scale ranging from strongly disagree to strongly agree to facilitate the participants to answer them: fear artificial intelligence trust artificial intelligence Artificial intelligence will destroy humankind Artificial intelligence will benefit humankind Artificial intelligence will cause many job losses From our industry collaborators feedback, we included questions, for example, seeking to understand participants perceptions of the impact of LLMs on their career trajectory or job market competitiveness in the near future. We collected participants information regarding basic demographics, work experience, and experience with LLM tools. We also conducted two pilot interview sessions with experienced software practitioners to evaluate the interview structure - whether to adopt pre-interview questionnaire to collect participants information - and the clarity of the interview questions. During our pilot study, we observed that it takes only about 5-10 minutes to collect participants information during the interview; however, we also observed that the pilot study participant who filled out pre-interview questionnaire was more comfortable (relaxed) during the interview. We believe that while using the preinterview questionnaire, with the interview moment focused only on the interview guide, we provided more simplified structure for the participant. The pilot interview using pre-interview questionnaire was not included in the analysis because this participant had no experience using LLMs for software development."
        },
        {
            "title": "2.3 Sampling",
            "content": "STGT supports different sampling methods: purposive, random and convenience. Using our findings from [24] as foundation, we began with purposive sampling in the first round, focusing on less JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 4 TABLE 2: Participants use of LLMs. Exp. (LLMs in General) # of Practitioners Exp. (LLM4SE) # of Practitioners # of Prompts per Day # of Practitioners Less than 2 years Less than 1 year Less than 18 months More than 2 years 5 5 5 Less than 1 year Less than 2 years Less than 6 months Less than 18 months More than 2 years 8 5 4 3 2 3 - 5 11 - 20; 21 - 30 6 - 10 Less than or equal to 2 50 - 100; +100 5 4 3"
        },
        {
            "title": "ATAI Scale",
            "content": "Frequency*"
        },
        {
            "title": "SE Tasks supported by LLMs",
            "content": "# of Practitioners"
        },
        {
            "title": "I fear artificial intelligence\nI trust artificial intelligence\nArtificial intelligence will destroy humankind\nArtificial intelligence will benefit humankind\nArtificial intelligence will cause many job losses",
            "content": "[7, 7, 4, 2, 2] [4, 10, 4, 4, 0] [11, 3, 3, 4, 1] [1, 0, 3, 12, 6] [0, 2, 7, 10, 3] Code-related tasks Test-related tasks Documentation-related tasks Requirement-related tasks 20 11"
        },
        {
            "title": "LLM tools",
            "content": "# of Practitioners"
        },
        {
            "title": "LLM tools",
            "content": "# of Practitioners Companys AI Policy # of Practitioners"
        },
        {
            "title": "ChatGPT\nGitHub Copilot\nClaude\nLlama\nGemini\nPerplexity\nMicrosoft Copilot",
            "content": "18 Cursor Phind Mistral Jan.AI H2O Danube Continue 2 2 2 1 1 1 7 7 4 2"
        },
        {
            "title": "Allowed to use\nNo policy\nProhibited to use\nI do not know\nPrefer not to say",
            "content": "16 3 1 1 1 *Order of the bars in Frequency column of ATAI Scale graph: Strongly disagree Somewhat disagree Neither agree nor disagree Somewhat agree Strongly agree, followed by respective values. experienced developers with less than five years of professional experience (See Fig. 1). In the following rounds, we moved to convenience sampling, interviewing software practitioners from all levels of experience. This would support further comparison between novice and experienced developers perceptions and experiences. We advertised this study on our professional social media, LinkedIn and (formerly Twitter). We also recruited participants from our personal connections. Initially, we advertised our study, including $50 (AUD) voucher gift card. However, due to potential fake participants identified based on discrepancies between their IP addresses and the countries they submitted in the pre-interview questionnaire, we got approval from the Faculty Ethical Review Committee to omit the gift card in the advertisement, and only offered it to genuine participants at the end of the interview. We adopted snowballing approach by encouraging the participants to share our study with others. The first round of interviews with six novice software practitioners took place between October and November (2024). Then, after changes in the interview guide, the second round of interviews with thirteen software practitioners took place between April and June (2025). The third round of interviews occurred in September (2025). The interviews were conducted and recorded via Zoom meetings, which also provided the transcriptions. Interviews were scheduled to go 40-45 minutes, but ranged from 34 to 58 minutes. We manually reviewed the transcriptions, filtered any sensitive information, and de-identified the participants. Participants demographics. Our participant pool covers diverse range of roles, countries of residence, years of experience, and experience using LLMs. We conducted twenty-two interviews with software practitioners from Latin America, Oceania, North America, Asia, and Europe - mostly from Australia (n=10). Table 1 provides an overview of participants demographics. Our study participants worked in different domains, such as healthcare, government, and finance. Most of the participants are males (n=14), have equal to or less than five years of professional experience (n=13), and describe their skill level as intermediate or advanced beginner (n=17). Regarding their experience using LLM tools, which can influence the faced challenges and suggested solution strategies, participants reported using variety of LLM tools. Not surprisingly, ChatGPT (n=18) was the most recurrent tool used by the interview participants. Figure 2 summarises participants demographics information related to the adoption of LLM tools. Most of the participants (n=14) have used LLMs in general, not specifically for SE tasks, for more than one year. According to their self-report amount of daily prompts, 59% (n=13) of participants engage daily with LLMs through at least 6 prompts. Their attitudes towards LLMs captured via Attitude Towards Artificial Intelligence (ATAI) scale highlight different inclinations towards AI technologies. While mostly (n=14) strongly disagreeing or somewhat disagreeing about fearing AI, they also mostly (n=14) disagree or somewhat disagree about trusting AI. Most (n=18) somewhat agree or strongly agree that AI will benefit humanity, and somewhat disagree or strongly disagree that AI will destroy humanity (n=14). However, most participants (n=13) somewhat agree or strongly agree that AI will affect the job market, leading to job losses. With respect to their experience using LLMs for SE tasks, mostly (n=16) reported having more than six months of experience, and they use LLMs mostly for code-related tasks (n=17), such as coding and debugging. Most of the study participants (n=14) reported that their companies allow them to employ LLM tools for job responsibilities. The fast-paced evolution of LLM tools compels us to examine the features available in the tools mentioned by interview participants. During our three rounds of data collection and analysis, we observed an emergence and evolution of different LLM tools (e.g., ChatGPT, Cursor) and integration with traditional tools (e.g., ChatGPT for Databricks [30], Copilot for Power BI [31]). This was also highlighted by the participants, e.g.: 9 Ive been able to see bit of how those tools evolve during this time. [For example, GitHub] Copilot evolved from being better autocomplete to having more tools [and features]. P10 [Software Engineer]. Ferino et al. [24] suggest researchers investigating LLMs for SE to JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 Fig. 2: Emergence of the category Impact on using LLMs from raw data codes concepts subcategories category through constant comparison. provide snapshot of the LLM features with the intent of improving clarity of the context related to the data collection. We summarise the main features in the supplementary online package [26]."
        },
        {
            "title": "2.4 Data Analysis",
            "content": "One of the ways in which STGT distinguishes itself from traditional grounded theory methods is by being organised into two stages: basic stage of data collection and analysis, and advanced stage for theory development. The basic stage of data collection analysis involves conducting lean literature review to identify research gaps, followed by data collection (e.g., survey), and open coding, constant comparison, and basic memoing for data analysis. When managed carefully, systematic literature reviews (SLRs) [24] can also be conducted. The advanced stage of theory development involves conducting targeted data collection and analysis, aiming to reach theoretical saturation, theory structuring, and targeted literature review. Through this clear separation, STGT gives flexibility to the researcher to decide whether to proceed to the advanced stage or share and communicate the findings from the basic stage [28]. Driven by the rich and fascinating results from the basic stage, we decided to communicate the findings. Open Coding. The process of open coding was iteratively improved by the first researcher following the guidance of an STGT expert, the second author. Initially, the first author printed out one of the interviews and coded it, followed by review and discussions with an experienced researcher. After this, the researcher coded two more interviews using Google Docs. The researcher decided to move to NVivo, instigated by its features, and spreadsheets. Before doing the open coding, and between rounds of data collection and analysis, the first author was advised to create and update an assumption list [26]. This helped to make transparent the researchers bias. Constant Comparison. By doing this, similar codes were grouped into concepts, and similar concepts under sub-categories, and similar sub-categories under categories. During this process, we drew diagrams to facilitate visualisation and insights regarding the relationship between concepts and sub-categories, and also conducted discussions between the authors. Figure 2 illustrates the emergence of the category Impact of using LLMs via constant comparison. Memoing. While performing constant comparison, we also wrote down memos reflecting our ideas, thoughts, and key elements emerging throughout the analysis. Those memos, which encompass both interview and inter-interview levels, supported the update of the interview guide between rounds. At the interview level, we compared the participants pre-interview questionnaire responses with their interview responses, especially concerning the ATAI scale. That information provided more context for our analysis. At the inter-interview level, we compared codes from different interview participants, which also helped to refine our concepts and sub-categories. An example of memo How LLMs affect developers intuition? is shown below. The discussion on the main insights from memoing is presented in Section 4.2. Memo on How LLMs affect developers intuition? LLMs seem to emerge as learning tool for software developers based on P12, P14, and P15, e.g., relying on LLMs to cover gaps in knowledge. At the same time, P14 argues that while using LLMs for learning, novice developers should do the majority of the work. This practice seems to be necessary to improve novice developers skills, but also to cultivate the intuition inherent in experienced developers. Intuition is something that comes naturally after fully understanding something. That intuition (internalised knowledge) helps to avoid scenarios where LLMs are misleading, which P11 described as ChatGPT being very good liar."
        },
        {
            "title": "3 FINDINGS\nWe found variations in the impact of software developers adopting\nLLMs across four levels:",
            "content": "Impact on the Individual Level: it refers to LLMs impacting software practitioners directly; Impact on the Team Level: it involves how LLMs influence software development teams and their collaboration; Impact on the Organisation Level: it encompasses how LLMs affect entire software organisations; JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 Impact on the Society Level: it refers to how LLMs affect daily life in society, not just developer communities. Tables 3 and 4 illustrate the benefits and disadvantages at the individual level of using LLM tools to support software development tasks, along with the reason influencing these impacts. For instance, when using LLMs for brainstorming, it has negative impact on developers personalities because of overreliance on LLMs, reduction of effort, mitigation of interruptions in software development and also because of the loss of control over LLMs. Additionally, we have summarised the main benefits and disadvantages in Figure 3 and 4, respectively. For instance, using LLMs for debugging can boost code development, saving development time, reduce software developers effort, and provide learning opportunities to software developers. We organised the remainder of this section by describing benefits in using LLMs (section 3.1), disadvantages in using LLMs (section 3.2), and recommendations on how to use LLMs (section 3.3). Throughout this section, we provide representative quotes to illustrate participants experiences and viewpoints. In order to protect the privacy of our participants, we refer to the interview participants as P1-P22. Similar to Masood et al. [32], we will use some expressions to indicate the extent of the predominance. In this sense, few refers to less than 25%, many or majority to over 50%. Although this is not quantitative study, it indicates how much evidence supports each theme."
        },
        {
            "title": "3.1.1 Individual Level\nBoosting code Development. A majority of participants (i.e.,\nP1-P16, P18-P19, P22) mention LLMs speeding up software\ndevelopment by automating simple, repetitive, and tedious tasks,\ne.g.: 9 “You spend less time thinking about simple problems,\nand you spend more time thinking about complex problems” –\nP13 [Software Developer]. For instance, LLMs can provide the\nboilerplate files quickly, e.g.: 9 “I just started a new project. So\nokay, I’ll get the initial boilerplate done quickly. So I don’t need\nto go create multiple folders and the files and everything” – P10\n[Software Engineer]. LLMs can also provide an extra boost to finish\ntasks quickly when stuck, e.g.: 9 “I try to show a code snippet\nand say [to ChatGPT]: ‘ I’ve developed it up to here, and I’d like to\nelaborate on it up to there. What would you do? Why?’” – P6 [Data\nEngineer]. Participants point out that, while developers could come\nup with those solutions, they would take more time, especially\nfor novice developers, e.g.: 9 “As a software engineer, you can\ncome up with all these solutions by yourself, but it would just take\na longer period of time.” – P3 [Software Engineer]. In summary,\nthis boost in developer productivity occurs when developers rely\non LLMs’ capabilities, which save development time by reducing\ntheir effort and interruptions.",
            "content": "LLMs Reducing Developers Effort. majority of participants (i.e., P1-P18, P20-P22) described scenarios where LLMs work to lighten their efforts for simple, repetitive, or tedious tasks. This happens because software practitioners hand over the control to LLMs automation capabilities, e.g.: 9 As have this extension in Databricks, it makes it much easier. For example, [if] miss line, miss path, miss way of calling class method, etc, it corrects it on the spot and automatically shows the button: Do you want me to correct it and run the cell again?. P6 [Data Engineer]. This mitigates interruptions in their development flow that would happen by doing it themselves, such as by filtering 6 relevant content on Google, e.g.: 9 If you go on to Google [...] theres bunch of official documentation from different resources. It takes some cognitive load to pick one, and then it goes through. P11 [Web Developer]. LLMs Saving Time. Most of the participants (i.e., P1-P18, P20, P22) also describe how LLMs contribute to time-saving for simple, repetitive, or tedious tasks. The perceived saving in developers time happens due to the reduced effort provided by LLMs when the developer hands over control to LLMs, e.g.: 9 In the past, there were several sites, Stack Overflow [...] From the moment you go looking for your question until you find it, youve already spent lot of time. P6 [Data Engineer]. Thus, this time-saving is correlated to the reduced effort, requiring the developer to weaken the grip over development. Otherwise, developers might not notice significant time-saving, e.g., 9 only use it for syntax lookup. And dont do that very often [...] and the time it really saves me is [...] pretty much the exact same thing that need to click into website, load it and then scroll little bit. P11 [Web Developer]. At the same time, participants do not feel confident about reducing the time required for task execution during planning, e.g., 9 Something that will normally take me 3 days [to do without LLMs help], Im still going to say 3 days. Its not just because have [Microsoft] Copilot doesnt mean Im going to say: This will take me one day or 2 days. P14 [Data Engineer]. Gaining Learning Opportunities. Fourteen participants (i.e., P1-P4, P6-P7, P12, P14, P15, P17, P18, P20, P22) mentioned the potential of LLMs as an educational tool for software developers, as well as the learning opportunities from adopting LLMs. For instance, developers can search for the reason behind AI wrong suggestion, e.g.: 9 try to see if the wrong answer was because didnt give enough information [...] Ill see if the prompt didnt make sense P1 [Software Developer]. LLMs can provide alternative solutions that can reinforce developers solution arsenal, e.g.: 9 LLMs will give me an essentially different perspective. Maybe this is an alternative approach, more concise way of doing things [...] so then can learn from them in this way. P17 [Data Analyst], and assist developers in programming language familiarisation, e.g.: 9 always used to search for Python functions in ChatGPT, [...] Phind [...] and also Perplexity.AI [...] it was super helpful, especially to know the proper Python way of doing things, because each language has its own sort of style of writing code P2 [Software Engineer], and in getting domain knowledge, e.g.: 9 GPT is definitely more helpful in [...] adopting the background knowledge of new area P11 [Web Developer]. Maintaining Software Development Flow. Fifteen participants (i.e., P1, P4-P8, P12-P13, P15-P20, P22) presented different aspects that LLMs contribute to the software development flow. For instance, LLMs help developers to stay focused on the logic instead of typing when it autocompletes, e.g.: 9 So it helps me with [...] reducing the time Im actually writing and giving me more space to think about the flow in general. P4 [Software Developer], fix syntax errors, e.g.: 9 really like to give ChatGPT the context [...] As have this extension in Databricks, it makes it much easier. For example, miss line, miss path, miss way of calling class method, etc, it corrects it on the spot P6 [Data Engineer], or return relevant information, e.g.: 9 You can just make query like: Hey, can you give me query for this?, [then] can just copy [it and] paste it. [This basically] gives me more concentration for 2, 3 hours to solve that problem P12 [Software Engineer]. Participants also mention how browsing on Google may break the development flow, e.g.: 9 When didnt have ChatGPT [...] JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 7 TABLE 3: Summary of the Benefits of using LLMs at the Individual (Software Practitioner) Level. SE Activity Software Development Tasks / How LLMs Impact? Task: Brainstorming Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time, [#4] Gaining Learning Opportunities Requirement Engineering & Software Design Task: Requirement Documentation Generation Benefit: [#1] Boosting code development, [#2] Reducing Effort,[#3] LLMs Saving Time Tasks: Diagram Generation Benefit: [#1] Boosting code development, [#2] Reducing Effort,[#3] LLMs Saving Time, [#4] Improving Developers Mental Model, [#5] Maintaining Developers Flow Why the Impact Happens? Reason: LLMs Saving Time#1; LLMs Reducing Effort#1,#3; Mitigating Interruptions#1,#2,#3; Handing over the Control to LLMs#1,#2,#3; Automation#1,#2,#3; Reliance on LLMs#1,#2,#3,#4; Balanced Control over LLMs#4; LLMs Capabilities#4 Reason: LLMs Saving Time #1; LLMs Reducing Effort#1,#3; Mitigating Interruptions#1,#2,#3; Handing Over The Control To LLMs#1,#2,#3; Automation#1,#2,#3; Reliance On LLMs#1,#2,#3 Reason: LLMs Saving Time#1; LLMs Reducing Effort#1,#3,#5; Mitigating Interruptions#1,#2,#3,#5; Handing over the Control to on LLMs#1,#2,#3,#4,#5 Automation#1,#2,#3,#4,#5; LLMs#1,#2,#3,#4,#5; Reliance Tasks: Concept Understanding Benefit: [#1] Reducing Effort, [#2] LLMs Saving Time, [#3] Gaining Learning Opportunities Reason: Balanced Control#3; Reliance on LLMs#1,#2,#3; LLMs Capabilities#3; Mitigating Interruptions#1,#2; Automation#1,#2; LLMs Reducing Effort#2 Tasks: Information Retrieval Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time, [#4] Gaining Learning Opportunities, [#5] Maintaining Developers Flow Reason: LLMs Saving Time#2; LLMs Reducing Effort#1,#3,#5; Mitigating Interruptions#1,#2,#3,#5; Handing over to LLMs#1,#2,#3,#5; Automation#1,#2,#3,#5; Reliance on LLMs#1,#2,#3,#4,#5; Balanced Control#4; LLMs Capabilities#4 the Control Software Development & Software Quality Assurance Tasks: Code Understanding Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time, [#4] Improving Developers Mental Model, [#5] Maintaining Developers Flow Tasks: Code Generation; Code Translation; Code Documentation Generation; Code Comment Generation; Unit Test Generation Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time, [#4] Maintaining Developers Flow LLMs Reason: Mitigating Interruptions#1,#2,#3,#5; LLMs Saving Time#1; Handing Over the Control to LLMs#1,#2,#3,#4,#5; Automation#1,#2,#3,#4,#5; Reliance on LLMs#1,#2,#3,#4,#5 Reducing Effort#1,#3,#5; Reason: LLMs Saving Time#1; Reducing Effort#1,#3,#4; Mitigating Interruptions#1,#2,#3,#4; Handing over the Control to LLMs#1,#2,#3,#4; Automation#1,#2,#3,#4; Reliance on LLMs#1,#2,#3,#4 Tasks: Test Case Identification, Test Data Generation Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time Reason: LLMs Saving Time#1; Reducing Effort#1,#2; Mitigating Interruptions#1,#2,#3; Handing over to LLMs#1,#2,#3; Automation#1,#2,#3; Reliance on LLMs#1,#2,#3 the Control Tasks: Pull Request Generation Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time Reason: Mitigating Interruptions#1,#2,#3; Cautious Reliance On LLMs#1,#2,#3; Reducing Effort#1,#3; LLMs Saving Time#1,#2,#3; Balanced Control#1,#2,#3; Handing over the Control to LLMs#1,#2,#3; Automation#1,#2,#3; Reliance on LLMs#1,#2,#3; Tasks: Debugging Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time,[#4] Gaining Learning Opportunities, [#5] Maintaining Developers Flow Reason: LLMs Saving Time#1; LLMs Reducing Efforts#1,#3,#5; Mitigating Interruptions#1,#2,#3,#5; Handing over the Control to LLMs#1,#2,#3,#5; Balanced Control#4; LLMs capabilities#4; Automation#1,#2,#3,#5; Reliance on LLMs#1,#2,#3,#4,#5 Tasks: Code Review Benefit: [#1] Boosting code development, [#2] Reducing Effort, [#3] LLMs Saving Time, [#4] Gaining Learning Opportunities, [#5] Improving Developers Skills Reason: LLMs Saving Time#1,#2,#3; LLMs Reducing Effort#1,#2,#3; Balanced Control#1,#2,#3; Automation#1,#2,#3; Cautious Reliance On LLMs#1,#2,#3 Software Maintenance It was much more difficult to clear up my doubts by wandering around the internet. Theres lot on the Internet [...] several sites, Stack Overflow, for example. [But] for you to find your question and be able to find your specific answer took while. P6 [Data Engineer]. When comparing AI pair programming and traditional pair programming, participants mentioned how traditional pair programming may come with interruption moments to searching for solution, e.g.: 9 Sometimes, when have this question, and my colleague also does not know [how to get to] the answer, we have to look it up together in Stack Overflow [or something] like that. P8 [Software Engineer]. Improving Developers Mental Model. few participants (i.e., P6, P10, P13-P14) mention how LLMs can aid developers in improving their code understanding, e.g.: 9 Why is it going on? Why is that method function [implemented in that way]? P19 [Machine Learning Scientist]. When the developer responsible for certain piece of code is busy, developers can ask questions to LLMs, e.g.: 9 have friend who [...] was the one who built the functions and all systems. Sometimes hes unavailable [but] [still] need someone to tell me what this [code] is about. When read the code, [I cannot], its quite unclear [what the code is about]. [Then, my] 1st thought: need to check on documentation, and also some discussions on Stack Overflow. [But then] was thinking: maybe can use LLMs [to help understand the code]. So, copied and pasted the code [into Perplexity.AI] and asked this LLM to explain that to me. P8 [Software Engineer]. Developers can also use LLMs to generate diagrams to improve their code understanding, e.g.: 9 So if have described an architecture. [I can say to the LLMs:] Create the diagram for this architecture. [Then] it creates the mermaid diagram, so it can easily be visualised how this architecture works. P10 [Software Engineer]. Safe Space. few participants (i.e., P4, P7, P12, P15) mention how LLMs provide safe space for sharing ideas and questions. For instance, software developers can ask as many questions as they need, e.g.: 9 feel like senior people dont have lot of JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 8 Fig. 3: Main Benefits of using LLMs at the Individual (Software Practitioner) Level. time on hand for trivial issues [...] [but for LLMs] there is no judgment [while asking questions], because you can ask dumb questions to ChatGPT or any [other] LLMs. And you can ask it as many times as you want, and you can get examples [...] You can get customised responses. P15 [Researcher]. This seems to be motivated by the desire to avoid disturbing colleagues work, while becoming self-reliant, e.g.: 9 Everyones very busy at work - the senior developers as well - you kind of - Its not set rule - but feel have limited number of questions can ask per day. P7 [BI Analyst]. In parallel, LLMs can offer certain levels of companionship experience, e.g.: 9 We can interact with LLMs like person. And its good to have that kind of companionship as well, like you can talk to it and say: Hey, what do you think about this? P12 [Software Engineer], and empathy, e.g.: 9 There was one time when [...] imported some of the things Copilot sent me and tried them. When went to Unity, it wouldnt even run the project. [...] [Copilot would reply]: Im sorry for your dissatisfaction, for your frustration, but lets try to do it another way. P4 [Software Developer]."
        },
        {
            "title": "3.1.2 Team Level\nMitigating Interruptions. Fifteen participants (i.e., P1, P4-P6,\nP10, P12-P21) described how LLMs lead to fewer interruptions.\nParticipants showed a preference to LLMs over disturbing col-\nleagues, e.g.: 9 “I’m always more comfortable using ChatGPT,\nCopilot. I do as little as possible to ask for help, so as not to\ndisturb other people.” – P4 [Software Developer]. Participants also\nhighlight the potential of LLMs supporting companies’ onboarding,\nwhich normally requires a lot of guidance from colleagues, e.g.:\n9 “If you’re kind of new to the team, you would feel more inclined\nto kind of just break it down through Copilot or ChatGPT first. And\nthen afterwards, if you still don’t understand it, then kind of go ask\nan experienced coworker” – P14 [Data Engineer].",
            "content": "Additional Assistance for Technical Questions. Many participants (i.e., P1-P4, P6, P8, P11-P13, P15, P17, P18, P22) mention about relying on LLMs for technical questions. LLMs are convenient in providing direction to software developers on how to approach tasks, e.g.: 9 If need some help [...] can get some idea about what need to do regarding those things, if we need some best code practices, or something like that P18 [Software Developer]. LLMs can also suggest an alternative approach, acting as second opinion, e.g.: 9 Sometimes even the whole team is narrowed down into one specific way of doing stuff. So its good thing there [to have second opinion] P12 [Software Developer]."
        },
        {
            "title": "3.1.3 Organisation Level",
            "content": "Cost Saving due to LLMs. few participants (i.e., P7, P9, P15P16, P20-P22) highlight how LLMs can contribute to reducing costs. For instance, using LLMs for debugging can decrease the time to find the problem, e.g.: 9 We are small company, but we move at least one to 2 million dollars per week [...] If theres production issue, then its like: Oh, we need to solve this immediately. And it [LLMs] saves lot of time to find the bugs and to mitigate the problem. That [time spent searching for the problem] it costs, [and] you have put the money in somewhere else, where it should not be P12 [Software Engineer]."
        },
        {
            "title": "3.1.4 Society Level",
            "content": "Foster Entrepreneurship. few participants (i.e., P10 and P21) mention the potential of LLMs encourage entrepreneurship. This occurs due to the great LLM prototyping capabilities, e.g.: 9 Prototyping becomes much faster for these [startup] companies [...] Even non-coder [...] can create just the rundown prototype, not full, scalable solution. But just to showcase sort of working front-end P21 [Researcher Developer], and boost in individual productivity, reducing demand for big teams, e.g.: 9 It also makes it easier to create new companies [...] because you can do more with fewer people. P10 [Software Engineer]. At the same time, LLMs can provide basic information necessary to start business, e.g.: 9 It can help you with the basics of marketing, accounting, and law, so it can help you tap into the basics of all these things, so you dont need to recruit team first. P21 [Researcher Developer]. Consultant for Everyday Questions. few participants (i.e., P6, P18, P21) highlight how LLMs emerge as valuable assistant for everyday demands. This extends from simple questions, e.g.: 9 In my day-to-day life, LLMs are more of consultant for questions. For example, when was arranging an interview with you, thought: My God, whats the time zone difference between Brazil and Australia? LLM is day-to-day consultant for basic JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 9 TABLE 4: Summary of the Disadvantages of using LLMs at the Individual (Software Practitioner) Level. SE Activity Software Development Tasks / How LLMs Impact? Why the Impact Happens? Requirement Engineering & Software Design Task: Brainstorming Disadvantage: [#1] Losing Learning Opportunities, [#2] Hindering Developers Skills, [#3] Poising Developers Personality Reason: Unpracticed skills#1,#2; Handing Over the control to LLMs#1; Influence of Personality#1,#2; Overreliance on LLMs#1,#2,#3; Losing Control Over LLMs#2,#3; LLMs Reducing Effort#1,#2,#3; Mitigating Interruptions#3 Tasks: Diagram Generation Disadvantage: [#1] Hindering Developers Skills Reason: Overreliance on LLMs#1; Losing Control over LLMs#1; LLMs Reducing Effort#1; Mitigating Interruptions#1; Unpracticed skills#1 Tasks: Information Retrieval Disadvantage: [#1] Losing Learning Opportunities, [#2] Poising Developers Personality Reason: Unpracticed skills#1; Handing Over the control to LLMs#1; LLMs Reducing Effort#1,#2; Overreliance on LLMs#1,#2; Influence of Personality#1; Losing Control Over LLMs#2 Tasks: Code Understanding Disadvantage: [#1] Poising Developers Personality Reason: Overreliance on LLMs#1; Losing Control Over LLMs#1; LLMs Reducing Effort#1 Software Development & Software Quality Assurance Task: Code Generation Disadvantage: [#1] Reducing Developers Mental Model, [#2] Hindering Developers Skills, [#3] Damaging Developers Reputation, [#4] Disrupt Developers flow, [#5] Degrade Code Quality Reason: Losing Control over LLMs#1,#2,#3,#4,#5; Automation#1,#4; Overreliance on LLMs#1,#3,#4; LLMs Reducing Effort#2,#3; Mitigating Interruptions#2; Unstable Accuracy#3,#5 Tasks: Test Generation; Test Data Generation; Code Translation; Pull Request Generation Disadvantage: [#1] Degrade Code Quality, [#2] Hindering Developers Skills Reason: Reliance On LLMs#1; Unstable Accuracy#1; Unpracticed skills#2; Handing Over the control to LLMs#2; LLMs Reducing Effort#2; Overreliance on LLMs#2; Mitigating Interruptions#2; Influence of Expertise#2; Influence of Personality#2; Losing Control over LLMs#1 Tasks: Debugging Disadvantage: crease Developers Effort due to LLMs [#1] Hindering Developers Skills, [#2] InReason: Unpracticed skills#1; Handing Over the Control to LLMs#1; LLMs Reducing Effort#1; Overreliance on LLMs#1; Influence of Personality#1; Mitigating Interruptions#1; Lack of Background Knowledge#2; Unstable Accuracy#2 Tasks: Code Review Disadvantage: [#1] Degrade Code Quality, [#2] Losing Learning Opportunity Reason: Unstable Accuracy#1; Losing Control over LLMs#1; Handing Over the control to LLMs#2; LLMs Reducing Effort#2; Reliance on LLMs#2; Influence of Personality#2; Mitigating Interruptions#2 Software Maintenance questions. P6 [Data Engineer], and advanced tasks, e.g.: 9 For general tasks, have to plan trip or something like that. Im always like, sometimes like, go for ChatGPT and ask for [potential] schedules and everything. So, its easier for me [to use ChatGPT for searching relevant information]. P18 [Software Developer]. RQ1. How do LLMs take software developers forward? We found benefits at the individual, team, organisation, and society levels. At the individual level, LLMs benefit developers by boosting software development, reducing effort, saving time, providing learning opportunities, maintaining software development flow, improving developers mental model, and providing safe space. Most of the participants mentioned that LLMs boost software development, save time, and reduce effort."
        },
        {
            "title": "3.2.1 Individual Level",
            "content": "Slowing software development. Most of the participants (i.e., P1-P3, P5-P19, P21, P22) mention how using LLMs may slow software developers. For instance, they may need to start new conversation when LLMs get stuck in the same wrong suggestion, e.g.: 9 usually started from scratch and gave him as much background and information as possible. Because when continued the same conversation, it tended to continue the same mistake P6 [Data Engineer]. Due to the possibility of hallucinations happening, developers need to review suggestions, e.g., 9 We dont have that trust [that] everything [every output] is correct, because its not always correct, so we still have that gap like everything is not [always] correct. P18 [Software Developer]. Increasing the Developers Effort. The majority of the participants (i.e., P1, P3-P12, P14-P17, P19, P21, P22) presented scenarios where adopting LLMs increase their effort, for example, due to LLMs response size limitation, e.g.: 9 The biggest [limitation] would be the question of answer size, where it cant answer very large answer, and Im going to have to ask several small questions in order to get my objective. P1 [Software Developer]. In order to avoid LLMs from getting full picture, software developers may also need to break down prompts into subprompts, e.g.: 9 dont typically give the whole idea that want to achieve to the GPT. Rather, kind of break down into different segments and then let them to generate the code for me for each segment. In the end, would do my own construction [, integration,] of these segments. P17 [Data Analyst]. The unstable accuracy of LLMs also makes the developers spend energy in vain implementing wrong suggestions, e.g.: 9 would follow the debugging steps that they laid out for me. And then sometimes that works. Sometimes it doesnt, as usual P3 [Software Engineer]. LLMs Dragging out Tasks. Many participants (i.e., P1, P3, P5-P8, P10-P11, P13-P17) mention how LLMs dragging out tasks. For instance, participants argue that there are situations where it is faster to do by themselves, e.g.: 9 Sometimes you have [moments when you get doubtful about LLMs]: Okay, Im just struggling to get this done because [LLMs] it doesnt get what Im saying. So Ill just do myself P10 [Software Engineer]. Degrade Code Quality. Most of the participants (i.e., P1-P3, P5, P7-P11, P13-P22) discussed how LLMs negatively affect code quality. This can be caused by weakening in their software development skills, e.g.: 9 If you fully rely on it, the quality of your code base would drop by lot P3 [Software Engineer]. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 They also highlight that LLMs may suggest solutions without taking into consideration the organisations approach, e.g.: 9 Usually make lot of changes to the code as well, because theres always something [that] the LLM will miss. The LLM wont have the entire context of the task, or [understand] whats the future plan [adopted by] the company P10 [Software Engineer]. LLMs can also provide wrong suggestions, e.g.: 9 Sometimes ChatGPT - dont know if its [related to ChatGPT] design or something [else] - [recommend] libraries or packages [which] are not compatible. What ChatGPT proposed is not compatible with the environment work in. Ive encountered numerous times that have to deal with this issue, and [I] ended up wasting lot of time. P17 [Data Analyst]. Losing Learning Opportunities. Fourteen participants (i.e., P2-P8, P14-P15, P17, P19-P22) mentioned the negative impact on learning due to adopting LLMs. For instance, software developers might lose interesting discussions from online forums due to adopting LLMs, e.g.: 9 from Stack Overflow, [there are] more comprehensive discussions there P8 [Software Engineer]. Relying on LLMs to reduce effort via automation may take away valuable learning opportunities. Reducing Developers Code Mental Model. few participants (i.e., P6, P10, P13-P14, P20-P21) mentioned the negative impact on the developers mental model. They argue that when developers overrely on LLMs by handing over the control to them, they lose in code understanding. This also affects software developers debugging capabilities, e.g.: 9 For example, Copilot developed five class methods for me, didnt do it myself. If you debug it or show it to someone, you wont know how the code was implemented. P6 [Data Engineer]. Consequently, they are pressured to continue relying on LLMs for debugging, e.g.: 9 If you have zero knowledge of the code, you just wrote because ChatGPT wrote it, and you didnt actually go through and read it, [doing code review], you then have to [rely on ChatGPT and to] ask ChatGPT to read the code that it wrote and then [get ChatGPT] tell it what problem happened P13 [Software Developer]. On the other hand, their code understanding improves naturally when coding by themselves, e.g.: 9 When you code yourself, you already have that [mental model] by default, because you had to code. P10 [Software Engineer]. Negative Impact on Developers Personality. We found in the responses of thirteen participants (i.e., P1, P3-P5, P9, P11, P13, P15, P17, P19-P22) examples of how using LLMs impacts their personality. For instance, LLMs automation capabilities influence software developers in becoming lazier, e.g.: 9 have become lazy [to write] even if [it is just a] small one line can also rely on the LLMs [...] if have to read documentation, will just ask LLMs to summarise so that dont have to read it completely P19 [Machine Learning Scientist], apathetic, e.g.: 9 Even my capacity for analysis, its lost over time. Ill spend more and more time just accepting, just like you review PR (pull request). And you dont really care P4 [Software Developer], and less confident in their own development skills, e.g.: 9 It would take much longer to do something [that while not using AI, compared to] you [that] can do it with ChatGPT or Claude nowadays. P15 [Researcher]. Hindering Developers skills. Eleven participants (i.e., P2P5, P7, P11-P15, P19-P20) mention how adopting LLMs affects software developers skills. This occurs because, when novice software developers overrely on LLMs to reduce effort by delegating tasks, they miss essential opportunities for the development of their technical and soft skills, e.g.: 9 Youre so reliant on 10 ChatGPT to think for you [...] your skills dont really increase much. Youre still that beginner P5 [Software Developer]. For more experienced developers, the process of atrophying their software development skills happens due to reliance on LLMs, e.g.: 9 One of my colleagues said he deliberately turned off the [AI-based] completion because now he says sometimes just forget how it works. Sometimes forget about the basics of my programming, because Im used to this now. P12 [Software Engineer], 9 But since youre missing that sort of mental exercise, you dont really develop the coding muscles. And think it kind of deteriorates your skills and your ability as software developer. P5 [Software Developer]. Doing code review is not defended as not being enough to stop the skill deterioration, e.g.: 9 Ah but [when using LLMs] you analyse the code, do. But think that even my capacity for analysis, its lost over time. Ill spend more and more time just accepting, just like [when] you review PR (pull request) and you dont really care. think Id do the same thing over time, gradually [...] my review would get worse. P4. Damaging Developers Reputation. few participants (i.e., P6-P7, P9-P10, P19, P21-P22) mention how errors from code generated via LLMs can affect developers credibility - due to LLMs non-deterministic nature. For this reason, participants demonstrate cautious approach towards completely delegating tasks to LLMs, e.g.: 9 It [code with errors] impacts your credibility as professional P9 [AI Engineer], 9 When you push the code to the Git [repository], it is not the LLMs name that will be in that log, it will be your name. P19 [Machine Learning Scientist]. Disrupting Software Development Flow. We found eleven participants (i.e., P4-P5, P7-P8, P12-P13, P15-P19) mentioned how interaction with LLMs can disturb their flow. For instance, interacting with LLMs via their online platform may cost context switch to the code editor, e.g.: 9 If need to find solution with it, Im still [do] context switch because [ChatGPT] its not inside [the IDE] where Im coding P16 [R&D Researcher]. The many suggestions offered by LLMs can also distract software developers, e.g.: 9 Sometimes ChatGPT will give you an answer thats completely different to what you were thinking. Unless you actually implement those [potential solutions] in real life, you dont know what the result is going to be [...] [basically] ChatGPT puts another option on top of your solution that you have in your mind. P7 [BI Analyst]. Communication Problems. We identified six participants (i.e., P1-P4, P6, P17) mentioning problems related to miscommunication with LLMs. This appears to happen due to AI hallucination or misunderstanding of user prompts, e.g.: 9 Sometimes it will do extra things that didnt ask for. P5 [Software Developer]. But this can also occur due to the user facing difficulty in creating clear prompts, e.g.: 9 Theres the communication problem. cant explain the whole robust part so that the LLM has the basis to be able to answer me P6 [Data Engineer]."
        },
        {
            "title": "3.2.2 Team Level\nLosing Mentorship Opportunities. Some participants (i.e., P2-P3,\nP6-P7, P15-P14, P18-P19, P21-P22) describe how LLMs negatively\ninfluencing mentorship opportunities, taking the mentorship role\nfrom senior developers. This happens because novice developers\nwould seek assistance first from LLMs, 9 “If I’m researching\nsomething that I don’t know a lot about, I usually will turn to\ntechnical documentation and Google [...] first. While mentoring a\njunior in my field, they were very quick to go to LLMs first, and",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 11 Fig. 4: Main Disadvantages of using LLMs at the Individual (Software Practitioner) Level. even criticise me, not for going to Google first P22 [Software Developer]."
        },
        {
            "title": "3.2.3 Organisation Level",
            "content": "Issues with Code License. few participants (i.e., P2, P11, P16) mention license concerns at the organisation level, and how they shape their organisations approach towards LLMs, e.g.: 9 Our company doesnt allow the use of ChatGPT because of [...] ownership [issues]. Its not possible to get the ownership P18. Seeking to avoid potential code license issues, companies can decide to prohibit using LLMs in the workplace, e.g.: 9 At my previous work [...] their policy was just to avoid using ChatGPT or any other LLMs. Their concern was more to do with the ownership of the code that was being generated, and how it might violate the trademarks. P2 [Software Engineer]. Settling licenses may also cause delay in the adoption of LLMs at the workplace, e.g.: 9 We had to wait for the licenses [regarding ChatGPT] to come for that P16 [R&D Researcher]. Issues with Security & Privacy. We found security and privacy concerns in the responses of twelve participants (i.e., P2-P3, P5, P7, P9-P11, P13-P16, P18). There is sceptical attitude on how LLMs approach these topics, e.g.: 9 For security reasons, my current company isnt allowing AI [to be] integrated into the program. P7 [Data Analyst]. The potential of LLMs to suggest code with potential security flaws also makes software developers approach LLMs with caution, e.g.: 9 When started using it... kind of realised that it [ChatGPT] tends to hallucinate bit more. It made me worried about using the code directly in my code base. Because if Im not careful and read every single line of code, might introduce [...] security flaw in the code. P5 [Software Developer]. Cost of using LLMs. Seven participants (i.e., P2, P9-P10, P12, P16-P17, P19) mentioned the organisation cost of adopting LLMs. In this sense, the cost of tokens may limit high-volume interactions (i.e., vibe coding), e.g.: 9 When we try to scale [that AI-generated code], we know that it becomes much faster and much more expensive quickly because we rely on OpenAI to do the calls, and we pay by token. You cant actually do it because its going to cost this amount. P16 [R&D Researcher]. This forces more planning before initiating this level of interaction, e.g.: 9 We have to measure that in advance to make sure that you can spend that money [for] that type of stuff. P16 [R&D Researcher]."
        },
        {
            "title": "3.2.4 Society Level\nErosion of Social Trust. We found negative effects of LLMs on\nsocial trust in six participants (i.e., P2, P11, P14, P16, P19, P22).\nThere is a concern of LLMs being misused, such as cheating during\ninterview processes, e.g.: 9 “There’s also a lot of LLMs that can\nhelp you pass an interview, right? [Of course] it really depends\non how [the interview] it’s monitored.” – P14 [Data Engineer],\n9 “People would still need to consider the situation where it would\nadd to misinformation and generate maybe a lot of fake news and\nfake videos [...] [because of] that people would find it difficult to\ntrust anything” – P2 [Software Engineer].",
            "content": "Job Market Crisis. Eight participants (P3, P7, P12, P16, P18, P20-P22) describe the impact of LLMs on the job market. Automation, not just LLMs, appears as the motivation for human replacement in simple tasks, e.g.: 9 With the rise of AI and automation, lot of things that humans can do can be replaced by using robot. P3 [Software Engineer]. While there is still demand for experts, non-specialised professionals might be replaced, e.g.: 9 Were still gonna need to rely on those experts for lot of things. But then the issue is the ones that are not the experts, the in-between ones. P16 [R&D Researcher]. RQ2. How do LLMs hold software developers back? We found disadvantages at the individual, team, organisation, and society levels. At the individual level, LLMs may slow software development, increase developers effort, degrade code quality, reduce learning opportunities and developers code mental model, negatively impacts developers personality, hinder developers skills, damage developers reputation, and disrupt software development flow. Most of the participants mentioned LLMs slowing down software development and increasing developers effort."
        },
        {
            "title": "3.3 RQ3. How do software developers achieve a bal-\nanced use of LLMs?",
            "content": "Exploring LLM Capabilities. This involves investigating, learning by experimentation, how LLMs can support software developers. In this process, developers can navigate through different LLMs until they find one that suits their needs, e.g.: 9 actually started JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 with ChatGPT like everyone else. And then found that ChatGPT [basically] give me too [much] general information [...] then tested [Microsoft] Copilot, and it gave me better results [...] think that, in some cases, its giving me not wanted it and then moved to Perplexity.AI, because Perplexity.AI has more current [information]. P8 [Software Engineer]. Their perception towards LLMs also advanced during this process, e.g.: 9 In the beginning, it seemed like they managed to make this semi-sentient chatbot thing. But as started to understand the technology behind it, it became clear that its not very sentient. And its not really aware of what its doing. Its more like statistical or machine learning model P5 [Software Developer]. Pragmatic Attitude towards LLMs. Participants describe slow adoption of LLMs. Some participants mention why the late adoption, e.g.: 9 just didnt feel like really needed [to use LLMs] [...] already have good workflow established. P11 [Web Developer]. At the same time, software developers should drop LLMs in case they are not being helpful, e.g.: 9 If youre finding that it wastes your time, just stop using it and just write it yourself because [LLMs] its useful to save time. But if its not saving time, just stop using it. P13 [Software Developer]. Balancing Time-Saving & Learning Opportunities. While LLMs can provide time-saving for software development by reducing effort, that effort may be necessary to practice their skills. Software developers, especially novice developers, should seek balance between time-saving and skill growth, e.g.: 9 Im going to continue seeing it [GenAI] as tool that can save me lot of time. But at the same time, can use it to help me learn as well. P14 [Data Engineer]. In that sense, it requires certain levels of self-control to avoid the temptation of overreliance on LLMs, e.g.: 9 use [Copilot] good amount, but taking into account that know could use more, just want to preserve the processing in my head [...] If dont exercise my [brain for] programming logic, Ill lose it [the skills]. P4 [Software Developer]. Understand Suitable Use Cases for LLMs. Every participant presented suitable and unsuitable use cases for LLMs. LLMs are skilled in simple tasks and popular topics, e.g.: 9 ChatGPT is very good at doing things that have already been done [...] lot of times. P5 [Software Developer]. Regarding unsuitable tasks, participants mention how LLMs are unhelpful for complex tasks, e.g.: 9 If the tasks are fully related to code, design patterns, modularisation, or unit tests, yeah, [LLMs are] pretty helpful. But if its more related to the business aspect of the solution, LLMs are not that helpful. P9, or tasks that differ between companies, e.g.: 9 When you are dealing with non-functional aspects of the solution, sometimes LLMs ask lot about [...] [for instance,] how to deploy this - because the deployment process [is] different among different companies. P9 [AI Engineer]. Combining Different LLMs for Different Tasks. Many participants (i.e., P2-P5, P8-P10, P12, P14, P16) defend that LLMs should be treated as tool, which involves understanding their capabilities. Participants highlight how different LLMs (e.g., ChatGPT, Claude) are more efficient for different tasks, e.g.: 9 Ive been using ChatGPT for user-related tasks and requirement-related tasks but for code-related tasks, Ive been using the Copilot. P12 [Software Engineer]. In this context, the traditional software engineering seems to transition into agentic software engineering, e.g.: 9 Most applications will become agentic applications, using LLMs to take actions [...] these new protocols which are emerging like the model context protocol (MCP) from Anthropic and A2A from Google will be able to improve this kind of communication 12 between software and agent software P9 [AI Engineer]. This aligns with Hassan et al. [33] when they proposed the Agentic Software Engineering (SE 3.0). LLMs for Code Improvement instead of Code Generation. Participants mention how LLMs aid them to improve their code, e.g.: 9 usually what do when want to create the logic, dont just say [to LLMs]: Generate this [without showing any example] [but] actually start typing and creating the code. And use more of the auto-complete [feature] of the LLMs, [than] the actual generation stuff. P10 [Software Engineer]. In this sense, the software developer maintains balanced level of control over LLMs. In addition, participants mention avoiding using LLMs for code generation from scratch due to concerns involving the potential impact on their skills, e.g.: 9 for code generation, would be bit more sceptical and maybe not use it very often. Because it will also affect your skills as well P2 [Software Developer]. Running LLMs Locally. Participants P9 and P22 both decided to run LLMs (i.e., Jan.AI, Llama, H2O Danube, and Mistral) locally via Ollama, Llama.cpp, and LM Studio as an approach to deal with privacy concerns in hosted LLM services. They believe maintaining privacy is worth the cost incurred, e.g.: 9 Im avoiding hosted services [and using LLMs locally] is largely around my concerns around privacy, and do think there is cost to privacy [...] these companies that are hosting the services will train on your input [...] It is not private conversation. P22 [Software Developer]. RQ3. How do software developers achieve balanced use of LLMs? We found recommendations focused on achieving middle ground between benefits and disadvantages. They are based on exploration of LLM capabilities, understanding suitable use cases for LLMs, combining different LLMs for different tasks, pragmatic attitude towards LLMs, and balancing time-saving with learning opportunities."
        },
        {
            "title": "4 DISCUSSION\n4.1 Implications for Practice\nGains do not come without cost. We presented in section 3.1 the\nbenefits and 3.2 the disadvantages of using LLMs. Our findings\nalign with the literature (e.g., [34]–[37]) by showing the multiple\nfacets regarding the impact of using LLMs. While LLMs can boost\nsoftware development, software developers can be affected in the\nlong term in case of overreliance. Those developers could find\nthemselves in a scenario where they stop improving their skills. On\nthe other hand, developers who decided to have self-control against\noverreliance will obtain more long-term career benefits due to their\nmature skills. When it comes to environmental cost, surprisingly,\nonly two participants (P16, P22) demonstrated concerns about the\nenergy consumption, overlooking water consumption [38]. Shi et al.\n[22] suggested that developers employ program-centric techniques,\nsuch as program pruning and grammar augmentation, to reduce the\nnumber of tokens.",
            "content": "Balanced control is the solution. We identified participants exercising various levels of control over Large Language Models (LLMs), ranging from high levels of control, such as self-restraint (e.g., turn off GitHub Copilot autocomplete), to low levels, exemplified by vibe coding [39]. While it may seem appealing to relinquish JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 control over LLMs by generating extensive pieces of code, doing so can increase the risk of hidden bugs and errors. Although LLMs can assist with software development tasks, software developers must retain oversight. Examples of balanced control include using Test-Driven Development (TDD) in conjunction with LLMs and employing prompts across multiple LLMs. Mathews et al. [40] found that employing TDD with models like GPT-4 and Llama 3 leads to higher success rate in solving programming challenges. LLMs as Approach to Mitigate Interruptions. Several studies have delved into understanding how to improve developer experience (DevEx) [41], [42] by mitigating interruptions. Zuger et al. [43] argue that frequent interruptions for knowledge workers can lead to organizational costs due to incomplete tasks. To address this issue, they developed physical traffic-light-like LED with an automatic interruptibility measure based on computer interaction data. From their large-scale and long-term field study, they found that their solution reduced the interruptions of participants by 46%. In this sense, we identified that teams adopting LLMs may result in fewer interruptions. LLMs Facilitating Developers Reaching the Flow. While analysing how LLMs influence software development flow in Section 3.1 and 3.2, we observe the great potential of LLMs for facilitating developers reach flow, aligned with the literature [23], [44]. Ritonumi et al. [45] describe flow state as: The characteristics of being in flow include deep involvement in the activity (often described as intense and focused concentration), merging of action and awareness, loss of reflective self-consciousness, sense of control, an altered sense of time, and autotelic experience. They also mention optimal challenge, challenge-skill balance, and immediate feedback as flow antecedents; and no distractions or interruptions and positive developer experience as facilitator factors to reach flow. LLMs can support provide better developer experience (i.e., DevEx [46]), by reducing frictions for simple and repetitive tasks. Different Effects on Novice and Experienced Developers. When adopting LLMs for code generation, developers move from actively coding to conducting code review [47]. While experienced developers face loss of coding muscles, they can rely on muscle memory to go back to their best performance. On the other hand, novice developers did not build those muscles, and overreliance will make them stuck in their current level. On the other hand, software developers can improve their code review skills by reviewing LLMs suggestions, essential for senior roles. LLMs as Champion for Prototyping. Participants described the high potential of LLMs for prototyping, which aligns with the literature (e.g., [48], [49]). Vibe coding paradigm appears to suit this context, focused on the development of minimum viable product (MVP) to validate hypotheses about customer needs. They can quickly communicate the product proposals to the public [50]. With Great Power comes Great Responsibility. Participants demonstrated different perspectives involving code ownership when using LLMs. We observed less experienced participants showing insecurity in recognising their code ownership. However, code ownership emerges when developers act responsibly [51], ensuring the quality of the code. This aligns with the emerging regulations worldwide that emphasise the importance of human authorship. For instance, the U.S. copyright law3 requires sufficient human contribution or control over AI-generated code. 3. www.copyright.gov/ai"
        },
        {
            "title": "4.2 Directions for Future Work",
            "content": "Based on the findings from our analysis, we have identified research gaps involved to software practitioners adopting LLMs for Software Development, not explored in our current work. How do LLMs affect social intelligence? Our findings show that using LLMs may mitigate interruptions at the team level. Although it may benefit in terms of productivity, the software development life cycle is entwined with collaboration, human judgment, emotional interactions, and decision-making [52], [53]. This is particularly important for manager positions, where social intelligence plays crucial role in capitalising on interactions with customers and employers. How do LLMs empower developers time? Participants mentioned different ways LLMs empower their time. While some participants would just proceed to the next task after finish current tasks using LLMs, one of the participants would use LLMs to give an extra time before close tasks, e.g.: 9 The big advantage is time. You can even bargain for bit of time too. For example, suppose have task that know will take day to do, if the AI can do it for me, wont deliver it quickly. Ill take my time and at the end of the day Ill hand it in. P4 [Software Developer]. How does laziness drive developers interaction with LLMs? We identified some examples that point to laziness in software developers interaction with LLMs. Software developers might feel lazy to write prompts, and interaction with LLMs can also make software developers lazy. How do LLMs affect developers intuition? According to Naur [54], Software development in all its phases, and irrespective of the techniques employed in its pursuits must and will always depend on intuition. Intuition built from previous experiences acts as safeguard mechanism, enabling software developers to navigate LLMs wrong suggestions. While Chen et al. [55] investigated the role of human intuition when using LLMs, the study regarding the effects of LLMs on human intuition remains unexplored. How do LLMs contribute to burnout in software projects? Investigations into burnout in SE have been the focus of numerous studies [56]. In their systematic mapping study, Tulili et al. [56] identified the following causes for burnout: personality traits (e.g., neuroticism), work-related factors (e.g., job demand, job overload), communication practices, agile practices, and physiological factors. In our study, one of our participants expressed concern about organisations pressuring developers to expand their responsibilities by using LLMs as justification, which may contribute to developer burnout. Controversial use cases. Participants demonstrate different opinions regarding using LLMs for test generation, code generation, and debugging. LLMs are discouraged for test-related tasks due to providing the illusion of false assurance. Wang et al. [7] argue that using LLMs for integration tests may result in errors or unreliable results because those tests may exceed the capacity of the LLM to process and analyse. LLMs are also discouraged for code generation due to the harmful long-term effects towards software developers skills. Some participants also highlight LLMs may provide general debugging guidance, since they cannot run the code."
        },
        {
            "title": "5 RELATED WORK\nBarke et al. [57] conducted an observational and interview study\nwith twenty software developers using GitHub Copilot on how\nthey interact with GitHub Copilot. They employed traditional\nGrounded Theory analysis [61], identifying two interaction modes:",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 14 Fig. 5: Comparison with related work focused on benefits and disadvantages. The colored bars represent the overlap with existing literature [57][60], and empty bars indicate new findings. acceleration mode and exploration mode. In acceleration mode, the developer has clear understanding of the next required task; whereas developers explore GitHub Copilot autocomplete suggestions in exploration mode due to lack of direction. According to Barke et al., the interactions in the acceleration mode are fast and do not disrupt the programmers flow. Our study findings corroborate their findings regarding LLMs maintaining development flow. Also aligned with our findings, they identified that LLMs can also disrupt the development flow when providing long suggestions. Banh et al. [58] conducted eighteen interviews with IT-related professionals (i.e., software developers, product owner, and scrum master) between August 2023 and January 2024. They aimed to understand how to integrate Generative AI in Software Engineering, exploring the opportunities and challenges related to adopting Generative AI tools. They applied the traditional Grounded Theory, resulting in the conceptual framework of generative AI integration in Software Engineering practices. Their findings, similar to ours, are: reduced development time, issues with intellectual property, underestimated overhead, developer empowerment, and code quality improvement via LLMs. However, our findings also include the contractions involving the benefits and disadvantages, such as code degradation via LLMs, LLMs dragging tasks (see 3.2.1). Our results point out the necessity for balanced approach to the adoption of LLMs, advocating for their use as net positive in the software development process. Our recommendations in Section 3.3 contain practical suggestions contributing to achieve this. Liang et al. [59] employed traditional Grounded Theory [62] through twenty interviews and observation of fifteen software developers. We could not identify when interviews and observation were conducted. Their contribution includes an understanding of prompt programming practices. Similar to our study, they identified the potential of LLMs to assist developers in improving their mental model. Although their research focused on prompt programming aspects, they present their impact across different software development tasks similar to us (See Table 3 and 4). Our findings distinguish by showing not only the impact of software practitioners interaction with LLMs, but also how it reflects in others levels, such as team level (e.g., mitigating interruptions). Li et al., [60] conducted twenty-six interviews in three rounds with industry practitioners and 395 survey respondents. They employed Socio-Technical Grounded Theory [25], [27], which resulted in the theory of AI Tool Use and Adoption in Software Engineering. Similar to our study, they also classified the impact at the individual and organisational level, such as fear of decreased skills and potential judgment of using LLMs, which are related to the sections hindering developers skills and damaging developers reputation from our study (See 3.2). On the other hand, our findings also comprehend the impact at the team and society level, such as losing mentorship opportunities due to LLMs, and LLMs fostering entrepreneurship. Although the literature presents studies exploring the impact of LLMs for software development, as illustrated in Figure 5, our investigation goes further by identifying best practices to balance the forward and backward impact of adopting LLMs."
        },
        {
            "title": "6 EVALUATION\n6.1 Evaluating STGT Application",
            "content": "The evaluation of the STGT method application consists of credibility and rigour as key criteria [25], [27]. In terms of credibility, our section 2 provides details involving the recruitment process (social media, and emailing), sampling method (purposive sampling followed by convenient sampling), how iterative and interleaved data occurred (three rounds of data collection and analysis), and how memos was written and applied (to guide structure of emerging concepts and sub-categories, and as directions for future work). Concerning rigour, our section 2 also provides examples of basic coding and constant comparison (See Fig. 2) and embedded sanitised evidence (i.e., several interview quotes throughout Section 3)."
        },
        {
            "title": "6.2 Evaluating STGT Outcomes",
            "content": "Findings from the application of STGT for data analysis should exhibit originality, relevance, and density [25], [27]. In terms of JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 originality, we position our findings within comparison to related work in Section 5. The relevance of understanding the impact of LLMs on software practitioners is highlighted in Section 1. Regarding density, Section 3 condenses the sub-categories and concepts that compose the category Impact on using LLMs. We illustrate the different aspects by using several interview quotes."
        },
        {
            "title": "7 THREATS TO VALIDITY",
            "content": "We will discuss the study limitations using the Total Quality Framework (TQF) developed by [63], suitable for qualitative studies in software engineering [64], [65]. This framework is structured in the following aspects: credibility regarding data collection, analyzability on the data, transparency of reporting, and usefulness of the findings. Credibility. It refers to how comprehensively and accurately the data collection was performed [66]. Our study participants cover individuals from different demographics, such as gender, country of residence, years of professional experience, and role. At the same time, we acknowledge that future research could expand the participants pool by interviewing, for example, IT managers and project managers or collecting data from professional social media (e.g., LinkedIn and Reddit posts). Besides our challenges in recruiting participants - an arduous task described by [67] - we reached suitable sampling size. We also acknowledge that changing the ATAI scale questions from 9 scale to 5 scale may impose threats to validity. However, we also defend that it may facilitate respondents to answer the questions. Analyzability. It refers to how comprehensively and accurately the data analysis was designed and executed. Although our qualitative analysis carries an intrinsic subjectivity, we mitigate this by conducting pilot for the open coding, as well as conducting discussions over the emerging codes, concepts, sub-categories and categories between the authors. Transparency. It refers to how clear and complete this paper reports the aspects referring to credibility and analysability, supporting replication or transference to other contexts. We intend to present enough information. Additionally, we provide further information in the appendices and in the online supplementary material package [26]. Usefulness. It refers to how useful the study contributions and findings are. Our findings can support software team leaders and IT managers in evaluating whether LLMs align with their context and needs, as well as guiding SE researchers for future research needs."
        },
        {
            "title": "8 CONCLUSION",
            "content": "In this paper, we present the software practitioners perspective on the impact of LLMs at the individual, team, organisation, and society levels. We also present suggestions on how to balance the benefits and disadvantages of using LLMs. Throughout the paper, we present LLMs as double-edged sword. At the individual level, most of the participants mention LLMs boosting software development, saving time, and reducing effort as benefits; and LLMs slowing software development, increasing effort as downside. At the team level, most of the participants refer to LLMs as mitigating interruptions, but also reducing mentorship opportunities. At the organisation level, participants highlight the cost savings due to LLMs, but also security and privacy concerns. At the society level, participants mention LLMs promoting entrepreneurship, but also the erosion of social trust. We conclude that balanced control is the ideal approach towards LLMs. Our findings also indicate LLMs are improving developer experience, enabling them to reach flow state."
        },
        {
            "title": "REFERENCES",
            "content": "[1] I. Ozkaya, Application of large language models to software engineering tasks: Opportunities, risks, and implications, IEEE Software, vol. 40, no. 3, pp. 48, 2023. [2] T. Teubner et al., Welcome to the era of chatgpt et al. the prospects of large language models, Business & Information Systems Engineering, vol. 65, no. 2, pp. 95101, 2023. [3] Y. K. Dwivedi et al., Opinion paper:so what if chatgpt wrote it? multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy, International Journal of Information Management, vol. 71, p. 102642, 2023. [4] A. M. Dakhel et al., Github copilot ai pair programmer: Asset or liability? Journal of Systems and Software, vol. 203, p. 111734, 2023. [5] X. Zhou et al., Exploring the problems, their causes and solutions of ai pair programming: study on github and stack overflow, Journal of Systems and Software, p. 112204, 2024. [7] [6] X. Hou et al., Large language models for software engineering: systematic literature review, ACM Trans. Softw. Eng. Methodol., Sep. 2024. [Online]. Available: https://doi.org/10.1145/3695988 J. Wang et al., Software testing with large language models: Survey, landscape, and vision, IEEE Transactions on Software Engineering, vol. 50, no. 4, pp. 911936, 2024. J. Di Rocco et al., On the use of large language models in model-driven engineering, Software and Systems Modeling, pp. 126, 2025. [8] [9] H. Mayer et al., Superagency in the workplace: Empowering people to unlock ais full potential, McKinsey Digital, vol. 28, 2025. [10] D. Debellis et al. (2024) Superagency in the workplace: Empowering [Online]. Available: https: people to unlock ais full potential. //dora.dev/research/ai/gen-ai-report/ et al. [11] D. DeBellis ai-assisted software development. [Online]. Available: https://dora.dev/research/ai/ #state-of-ai-assisted-software-development (2025) 2025 state dora of [12] G. Burtch et al., The consequences of generative ai for online knowledge communities, Scientific Reports, vol. 14, no. 1, p. 10413, 2024. [13] S. Kabir, D. N. Udo-Imeh, B. Kou, and T. Zhang, Is stack overflow obsolete? an empirical study of the characteristics of chatgpt answers to stack overflow questions, in Proceedings of the CHI Conference on Human Factors in Computing Systems, 2024, pp. 117. [14] A. Ziegler et al., Measuring github copilots impact on productivity, Communications of the ACM, vol. 67, no. 3, pp. 5463, 2024. [15] Z. K. Cui, M. Demirer, S. Jaffe, L. Musolff, S. Peng, and T. Salz, The effects of generative ai on high skilled work: Evidence from three field experiments with software developers, Available at SSRN 4945566, 2024. [16] C. Ebert and P. Louridas, Generative ai for software practitioners, IEEE Software, vol. 40, no. 4, pp. 3038, 2023. [17] D. Nam, A. Macvean, V. Hellendoorn, B. Vasilescu, and B. Myers, Using an llm to help with code understanding, in Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, 2024, pp. 113. [18] M. A. Kuhail et al., will be replaced? assessing chatgpts effect on software development and programmer perceptions of ai tools, Science of Computer Programming, vol. 235, p. 103111, 2024. [19] V. Krauß et al., create fear of missing out-chatgpt implements unsolicited deceptive designs in generated websites without warning, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, 2025, pp. 120. [20] H.-P. H. Lee et al., The impact of generative ai on critical thinking: Self-reported reductions in cognitive effort and confidence effects from survey of knowledge workers, in Proceedings of the CHI Conference on Human Factors in Computing Systems, 2025. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 [21] X. Chen et al., An empirical study on challenges for llm application developers, ACM Transactions on Software Engineering and Methodology, 2025. [22] J. Shi, Z. Yang, and D. Lo, Efficient and green large language models for software engineering: Literature review, vision, and the road ahead, ACM Transactions on Software Engineering and Methodology, vol. 34, no. 5, pp. 122, 2025. [23] A. Mohamed, M. Assi, and M. Guizani, The impact of llm-assistants on software developer productivity: systematic literature review, arXiv preprint arXiv:2507.03156, 2025. [24] S. Ferino, R. Hoda, J. Grundy, and C. Treude, Novice developers perspectives on adopting llms for software development: systematic literature review, arXiv preprint arXiv:2503.07556, 2025. [25] R. Hoda, Socio-technical grounded theory for software engineering, IEEE Transactions on Software Engineering, vol. 48, no. 10, pp. 3808 3832, 2022. [26] S. Ferino, R. Hoda, J. Grundy, and C. Treude, Supplementary [Online]. Available: https: Information Package - STGT, 2025. //doi.org/10.5281/zenodo.17556044 [27] R. Hoda, Qualitative Research with Socio-Technical Grounded Theory. Springer, 2024. [Online]. Available: https://link.springer.com/book/10. 1007/978-3-031-60533-8 [28] U. M. Graetsch et al., Dealing with data challenges when delivering dataintensive software solutions, IEEE Transactions on software engineering, vol. 49, no. 9, pp. 43494370, 2023. [29] C. Sindermann et al., Assessing the attitude towards artificial intelligence: Introduction of short measure in german, chinese, and english language, KI-Kunstliche intelligenz, vol. 35, no. 1, pp. 109118, 2021. [30] A. Dogra and A. Nieto. (2025) Build with gpt-5 on databricks with ai gateway. Accessed: 2025-10-07. [Online]. Available: https: //www.databricks.com/blog/build-gpt-5-databricks-ai-gateway [31] M. team. (2025) Overview of copilot for power bi. Accessed: 202510-07. [Online]. Available: https://learn.microsoft.com/en-us/power-bi/ create-reports/copilot-introduction [32] Z. Masood, R. Hoda, and K. Blincoe, Real world scrum grounded theory of variations in practice, IEEE Transactions on Software Engineering, vol. 48, no. 5, pp. 15791591, 2020. [33] A. E. Hassan et al., Agentic software engineering: Foundational pillars and research roadmap, arXiv preprint arXiv:2509.06216, 2025. [34] D. Russo, Navigating the complexity of generative ai adoption in software engineering, ACM Transactions on Software Engineering and Methodology, vol. 33, no. 5, pp. 150, 2024. [35] J. T. Liang, C. Yang, and B. A. Myers, large-scale survey on the usability of ai programming assistants: Successes and challenges, in Proceedings of the 46th IEEE/ACM international conference on software engineering, 2024, pp. 113. [36] T. Weber et al., Significant productivity gains through programming with large language models, Proceedings of the ACM on Human-Computer Interaction, vol. 8, no. EICS, pp. 129, 2024. [37] S. Abrahao, J. Grundy, M. Pezz`e, M.-A. Storey, and D. A. Tamburri, Software engineering by and for humans in an ai era, ACM Transactions on Software Engineering and Methodology, vol. 34, no. 5, pp. 146, 2025. [38] N. Jegham, M. Abdelatti, L. Elmoubarki, and A. Hendawi, How hungry is ai? benchmarking energy, water, and carbon footprint of llm inference, arXiv preprint arXiv:2505.09598, 2025. [39] A. Fawz, A. Tahir, and K. Blincoe, Vibe coding in practice: Motivations, challenges, and future outlook-a grey literature review, arXiv preprint arXiv:2510.00328, 2025. [40] N. S. Mathews and M. Nagappan, Test-driven development and llm-based code generation, in Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, ser. ASE 24. New York, NY, USA: Association for Computing Machinery, 2024, p. 15831594. [Online]. Available: https://doi.org/10.1145/3691620.3695527 [41] A. N. Meyer, E. T. Barr, C. Bird, and T. Zimmermann, Today was good day: The daily life of software developers, IEEE Transactions on Software Engineering, vol. 47, no. 5, pp. 863880, 2019. [42] A. Razzaq, J. Buckley, Q. Lai, T. Yu, and G. Botterweck, systematic literature review on the influence of enhanced developer experience on developers productivity: Factors, practices, and recommendations, ACM Computing Surveys, vol. 57, no. 1, pp. 146, 2024. [43] M. Zuger et al., Reducing interruptions at work: large-scale field study of flowlight, in Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 2017, pp. 6172. [44] H. Mozannar et al., Reading between the lines: Modeling user behavior and costs in ai-assisted programming, in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 2024, pp. 116. 16 [45] S. Ritonummi, V. Siitonen, M. Salo, H. Pirkkalainen, and A. Sivunen, Flow experience in software engineering, in Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2023, pp. 618630. [46] A. Noda et al., Devex: What actually drives productivity? Communications of the ACM, vol. 66, no. 11, pp. 4449, 2023. [47] A. Simkute et al., Ironies of generative ai: understanding and mitigating productivity loss in human-ai interaction, International Journal of HumanComputer Interaction, vol. 41, no. 5, pp. 28982919, 2025. [48] E. Jiang et al., Promptmaker: Prompt-based prototyping with large language models, in CHI Conference on Human Factors in Computing Systems Extended Abstracts, 2022, pp. 18. [49] H. Subramonyam et al., Prototyping with prompts: Emerging approaches and challenges in generative ai design for collaborative software teams, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, 2025, pp. 122. [50] A. N. Duc and P. Abrahamsson, Minimum viable product or multiple facet product? the role of mvp in software startups, in International conference on agile software development. Springer, 2016, pp. 118130. [51] A. Alami, V. V. Jensen, and N. A. Ernst, Accountability in code review: The role of intrinsic drivers and the impact of llms, ACM Transactions on Software Engineering and Methodology, 2025. [52] A. Alami and N. Ernst, Human and machine: How software engineers perceive and engage with ai-assisted code reviews compared to their peers, in 2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE). IEEE, 2025, pp. 6374. [53] E. Kalliamvakou et al., What makes great manager of software engineers? IEEE Transactions on Software Engineering, vol. 45, no. 1, pp. 87106, 2017. [54] P. Naur, Intuition in software development, in International Joint Conference on Theory and Practice of Software Development. Springer, 1985, pp. 6079. [55] V. Chen et al., Understanding the role of human intuition on reliance in human-ai decision-making with explanations, Proceedings of the ACM on Human-computer Interaction, vol. 7, no. CSCW2, pp. 132, 2023. [56] T. R. Tulili, A. Capiluppi, and A. Rastogi, Burnout in software engineering: systematic mapping study, Information and Software Technology, vol. 155, p. 107116, 2023. [57] S. Barke et al., Grounded copilot: How programmers interact with codegenerating models, Proceedings of the ACM on Programming Languages, vol. 7, no. OOPSLA1, pp. 85111, 2023. [58] L. Banh, F. Holldack, and G. Strobel, Copiloting the future: How generative ai transforms software engineering, Information and Software Technology, vol. 183, p. 107751, 2025. [59] J. T. Liang et al., Prompts are programs too! understanding how developers build software containing prompts, Proceedings of the ACM on Software Engineering, vol. 2, no. FSE, pp. 15911614, 2025. [60] Z. S. Li et al., Ai tool use and adoption in software development by individuals and organizations: grounded theory study, arXiv preprint arXiv:2406.17325, 2024. [61] B. Glaser and A. Strauss, Discovery of grounded theory: Strategies for qualitative research. Routledge, 2017. [62] M. Juliet and S. Corbin, Basics of qualitative research: Techniques and procedures for developing grounded theory. SAGE Publications, Incorporated, 2015. [63] M. R. Roller and P. J. Lavrakas, Applied qualitative research design: total quality framework approach. Guilford Publications, 2015. [64] P. Lenberg et al., Qualitative software engineering research: Reflections and guidelines, Journal of Software: Evolution and Process, vol. 36, no. 6, p. e2607, 2024. [65] H. Gunatilake et al., The role of empathy in software engineering - socio-technical grounded theory, ACM Trans. Softw. Eng. Methodol., Sep. 2025, just Accepted. [Online]. Available: https://doi.org/10.1145/3768315 [66] I. Korstjens and A. Moser, Series: Practical guidance to qualitative research. part 4: Trustworthiness and publishing, European Journal of General Practice, vol. 24, no. 1, pp. 120124, 2018. [67] K. Madampe et al., The struggle is real! the agony of recruiting participants for empirical software engineering studies, in 2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, 2024, pp. 417422."
        }
    ],
    "affiliations": [
        "Faculty of Information Technology, Monash University",
        "School of Computing and Information Systems, Singapore Management University"
    ]
}