{
    "paper_title": "oMeBench: Towards Robust Benchmarking of LLMs in Organic Mechanism Elucidation and Reasoning",
    "authors": [
        "Ruiling Xu",
        "Yifan Zhang",
        "Qingyun Wang",
        "Carl Edwards",
        "Heng Ji"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Organic reaction mechanisms are the stepwise elementary reactions by which reactants form intermediates and products, and are fundamental to understanding chemical reactivity and designing new molecules and reactions. Although large language models (LLMs) have shown promise in understanding chemical tasks such as synthesis design, it is unclear to what extent this reflects genuine chemical reasoning capabilities, i.e., the ability to generate valid intermediates, maintain chemical consistency, and follow logically coherent multi-step pathways. We address this by introducing oMeBench, the first large-scale, expert-curated benchmark for organic mechanism reasoning in organic chemistry. It comprises over 10,000 annotated mechanistic steps with intermediates, type labels, and difficulty ratings. Furthermore, to evaluate LLM capability more precisely and enable fine-grained scoring, we propose oMeS, a dynamic evaluation framework that combines step-level logic and chemical similarity. We analyze the performance of state-of-the-art LLMs, and our results show that although current models display promising chemical intuition, they struggle with correct and consistent multi-step reasoning. Notably, we find that using prompting strategy and fine-tuning a specialist model on our proposed dataset increases performance by 50% over the leading closed-source model. We hope that oMeBench will serve as a rigorous foundation for advancing AI systems toward genuine chemical reasoning."
        },
        {
            "title": "Start",
            "content": "oMeBench: Towards Robust Benchmarking of LLMs in Organic"
        },
        {
            "title": "Mechanism Elucidation and Reasoning",
            "content": "Ruiling Xu1* Yifan Zhang1* Qingyun Wang2 Carl Edwards1,3 Heng Ji1 1University of Illinois Urbana-Champaign 2Wlliam & Mary 3Genentech 5 2 0 2 2 ] . [ 2 1 3 7 7 0 . 0 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Organic reaction mechanisms are the stepwise elementary reactions by which reactants form intermediates and products, and are fundamental to understanding chemical reactivity and designing new molecules and reactions. Although large language models (LLMs) have shown promise in understanding chemical tasks such as synthesis design, it is unclear to what extent this reflects genuine chemical reasoning capabilities, i.e., the ability to generate valid intermediates, maintain chemical consistency, and follow logically coherent multi-step pathways. We address this by introducing oMeBench, the first large-scale, expert-curated benchmark for organic mechanism reasoning in organic chemistry. It comprises over 10,000 annotated mechanistic steps with intermediates, type labels, and difficulty ratings. Furthermore, to evaluate LLM capability more precisely and enable finegrained scoring, we propose oMeS, dynamic evaluation framework that combines step-level logic and chemical similarity. We analyze the performance of state-of-the-art LLMs, and our results show that although current models display promising chemical intuition, they struggle with correct and consistent multi-step reasoning. Notably, we find that using prompting strategy and fine-tuning specialist model on our proposed dataset increases performance by 50% over the leading closed-source model. We hope that oMeBench will serve as rigorous foundation for advancing AI systems toward genuine chemical reasoning."
        },
        {
            "title": "Introduction",
            "content": "Organic reaction mechanisms, the stepwise elementary reactions where reactants form intermediates and products, provide detailed, step-bystep description of how chemical bonds are broken and formed during an organic chemical reaction (Muller, 1994). In other words, mecha- * These authors contributed equally to this work. 1https://github.com/skylarkie/oMeBench 1 Figure 1: Given reaction from oMeBench, we generate reaction mechanism and score it with oMeS. nism serves as the natural algorithm of reaction. Mechanisms form the foundation for understanding chemical reactions (Grossman, 2003), and play key role in accelerating molecular discovery (Carey and Sundberg, 2007; Smith, 2025). For instance, in drug discovery, mechanistic models serve as the basis for predicting metabolic pathways and toxicities (Silverman and Holladay, 2014; Patrick, 2023). Thus, organic reaction mechanisms are not merely theories of fundamental chemistry but tools that drive innovations in applied chemistry. Large language models (LLMs) have recently demonstrated remarkable performance in diverse chemical applications, such as property prediction (Stark et al., 2022), retrosynthetic analysis (Chen et al., 2023), product prediction (Schwaller et al., 2021), reaction mining (Zhong et al., 2023), action extraction (Zhong et al., 2024), and reaction-condition optimization (Broni-Bediako et al., 2022). Despite this progress, chemical reasoning, especially mechanisFigure 2: Overview of dataset construction and examples. named reaction refers to class of reactions that share common mechanistic pattern and can be abstracted into generalized template. Templates are denoted using placeholders such as R-groups, which represent variable substituents (e.g., Me, Et, H) tic reasoning, remains largely unexplored. Existing benchmarks primarily focus on mapping reactants to products without explicit annotation of the underlying elementary steps (Lowe, 2012; Kearnes et al., 2021), leaving models unable to explain why or how reaction occurs. Moreover, prior attempts to construct reaction mechanism datasets largely rely on rule-based systems (Chen et al., 2024), which encode limited set of hard-coded transformation rules (e.g., deprotection). This results in relatively simple datasets with low reaction diversity, and therefore models which dont generalize well. To address this gap, we introduce oMeBench  (Fig. 1)  , which contains over 10,000 annotated mechanistic steps with intermediates, step-type labels, and rationales, as well as wide range of reaction classes and difficulty levels. To enable fine-grained evaluation, we further propose oMeS, dynamic scoring framework that aligns predicted and gold-standard mechanisms using weighted similarity metrics. Together, these resources allow us to dissect model behavior beyond product prediction and quantify mechanistic fidelity (mechanismlevel accuracy). Our extensive evaluation reveals that while LLMs demonstrate non-trivial chemical intuition, they struggle to sustain multi-step causal logic, especially in complex or lengthy mechanisms. Importantly, exemplar-based in-context learning and supervised fine-tuning both yield substantial improvements (Dong et al., 2023; Zhang et al., 2023), highlighting not only the potential but also the current limitations of LLMs in mechanistic chemistry. We hope that oMeBench will serve as rigorous foundation for advancing AI systems toward mechanistic chemical reasoning. Our contributions are threefold: We construct the first expert-annotated largescale suite of organic reaction mechanism datasets, with step-by-step mechanisms and natural language rationales, all released in standardized format that is both human-interpretable and machine-readable. We introduce novel dynamic and chemically interpretable evaluation metrics that automatically measure LLMs mechanism elucidation and reasoning. We conduct systematic study of mechanistic reasoning across multiple LLMs. We reveal and partially bridge critical gaps, achieving 50% final gain over the proprietary baseline."
        },
        {
            "title": "2 Related Work",
            "content": "Organic Reaction Datasets. Large-scale reaction datasets, such as USPTO (Lowe, 2012), Pistachio (Mayfield et al., 2017), and PubChem (Kim et al., 2025), collect reactions from the literature without providing explicit mechanistic details. Recent mechanism-aware datasets generally rely on atommapped encodings that are difficult to interpret (App. B.2), and remain limited in scope: some focus narrowly on radical (Tavakoli et al., 2023) or polar reactions (Tavakoli et al., 2024), while others are oversimplified with low diversity (Chen et al., 2024; Joung et al., 2024). Broader scientific benchmarks (Li et al., 2025a; Wang et al., 2023) include mechanisms only in simple QA formats. Chemistry-Specific Models. Domain-specific models, such as ChemDFM (Zhao et al., 2024) exploit chemical corpora via pretraining and finetuning, while Ether0 (Narayanan et al., 2025) enhances multi-step reasoning through supervised and reinforcement learning. mCLM (Edwards et al., 2025) has advanced this direction by modularization at the representation level, modeling molecules as functional building blocks. Despite these advances, most chemistry-specific LLMs focused on tasks such as molecular property prediction, retrosynthesis, or text-based QA, with explicit mechanistic reasoning still largely unexplored. Chemistry-related tasks in LLMs. Research on LLMs in chemistry has evolved from early tasks such as molecular name translation and property prediction (Chithrananda et al., 2020; Zheng et al., 2024b) to more complex reasoning applications, including retrosynthesis and automated synthesis protocols (Wang et al., 2025; Vaškeviˇcius and Kapoˇciute-Dzikiene, 2024). Recent work has explored prompting strategies and autonomous agents to extend model capabilities (Bran et al., 2024; Darvish et al., 2024). However, LLM performance on these tasks remains limited. In particular, understanding organic mechanisms, the foundation of all organic transformations, has received little attention, with prior papers addressing only few simple cases (Bran et al., 2025). To address this gap, we present the first comprehensive study of LLMs on mechanism reasoning and release largescale dataset to support fine-tuning and evaluation."
        },
        {
            "title": "3 Dataset",
            "content": "Tab. 1 highlights three key limitations of early datasets: (i) unreadable formats. Each mechanistic step is represented through atom-mapping, which is non-intuitive and difficult to interpret (App. B.2); (ii) missing metadata, limiting deeper analysis; and (iii) lack of difficulty and diversity, as most reactions are either high-school level, domain-specific, or repetitive despite large scale. To address these limitations, we introduce three complementary organic reaction mechanism datasets. oMe-Gold comprises literature-verified organic reactions with detailed mechanisms, serving as the gold-standard benchmark for evaluation. oMe-Template consists of mechanistic templates that generalize families of reactions sharing common mechanistic pathway. Each template contains substitutable placeholder R-groups, enabling instantiation into diverse reaction instances. oMe-Silver is large-scale dataset systematically expanded from oMe-Template, containing chemically plausible but not necessarily literature-verified reactions, and primarily used for large-scale model training. All three datasets include rich expert annotations covering difficulty. Tab. 2 summarizes the dataset statistics, and Fig. 2 illustrates the complete construction process."
        },
        {
            "title": "3.1 Gold Dataset",
            "content": "All reactions were curated from authoritative organic chemistry textbooks and reaction databases (Kim et al., 2025; Kearnes et al., 2021; Grossman, 2003; Kurti and Czakó, 2005). For each named reaction,2 we included either the classical instance or challenging variant. In addition, several outof-domain reactions from textbooks were included to enhance diversity. Reactions were initially extracted using Gemini-Pro-2.5 (Team et al., 2023) and subsequently verified by experts for SMILES validity and chemical consistency.3 Difficulty Level. Difficulty is defined by mechanistic complexity and the depth of reasoning required. Reactions are classified as Easy (20%), involving single-step logic; Medium (70%), requiring conditional reasoning; and Hard (10%), involving complex mechanisms that demand advanced understanding. All reactions were independently annotated by two expert chemists, with disagreements resolved by third expert (App. A). Step Type and Subtype. We propose two-level 2A named reaction refers to class of reactions following shared mechanistic template. 3Among the 196 entries, 189 required manual correction. Manual verification was essential, as SOTA LLMs and other tools often fail to produce chemically valid results. 3 Dataset #Temps Size(Scaled) Scaling Method Level Mech? Int? NL? Lowe (2012) Chen et al. (2024) (Joung et al., 2024) Tavakoli et al. (2023) Li et al. (2025a) Wang et al. (2023) Ours 86 86 86 100 30 196 50k 31k 19.2k 5k+ 100 30 10k Expert System Expert System Expert System Manual Curation Manual Curation Manual Curation Easy Easy Easy Medium Easy Easy Mixed Table 1: Comparison of representative organic reaction datasets by scale, construction method, and annotation type. \"#Temps\" denotes unique templates; \"Mech?\", \"Int?\", and \"NL?\" indicate the presence of mechanistic details, intermediates, and natural language descriptions, respectively. Dataset #Reactions #Steps #Types #Subtypes Annotation Source oMe-Gold oMe-Template oMe-Silver 196 167 2,508 858 722 10,619 8 8 30 30 30 Expert-verified, curated from textbooks and literature Expert-curated templates abstracted from oMe-Gold Automatically expanded from oMe-Template with filtering Table 2: Statistics of the three curated datasets in oMeBench. Figure 3: Overview of the dataset metadata and format. taxonomy for elementary steps, comprising 8 types and 30 subtypes, detailed in Tab. 5. The annotation procedure follows Difficulty Level. Descriptions and Rationales. Each entry includes high-level natural language description of the reaction and rationale for every mechanistic step explaining the underlying mechanistic principles. These texts were generated using Gemini-Pro-2.5 through prompts in App. H.2. Step Weighting. Each step is weighted by its mechanistic importance and reasoning complexity. We 1) assign initial weights to each step type, 2) adjust for unusually simple or difficult subtypes, and then 3) fine-tune by positional or structural factors. The complete details are in App. C.1."
        },
        {
            "title": "3.2 Template Abstraction and Expansion",
            "content": "oMe-Template comprises template-level reactions from named reaction databases, which provide generic R-group structures and representative instances. As these sources lack explicit mechanistic details, expert chemists reconstructed each mechanism by generalizing from the instance-level reaction while preserving its reaction conditions. This abstraction is chemically justified, since named reactions inherently represent families of reactions sharing common mechanistic pathways. Metadata annotation followed the same protocol as oMeGold. Representative examples are in App. B.2. oMe-Silver is constructed by expanding oMeTemplate. For each template, Gemini-Pro-2.5 proposes chemically plausible R-group substitutions (App. H.1), and invalid SMILES are filtered automatically. Metadata are inherited from the source template, and the scaling algorithm is in App. D. On average, each template yields 15 valid silverstandard reactions. This LLM-guided expansion enables greater chemical diversity and plausibility than rule-based substitution. 4 Figure 4: The overview of the evaluation system. LLM-generated mechanisms are dynamically aligned with gold references. Subtype correctness, molecular similarity σ, and weight are used to compute oMeS S, , and L."
        },
        {
            "title": "4 Evaluation",
            "content": "We introduce oMeS, dynamic evaluation framework offering four complementary metrics for finegrained assessment of LLMs mechanistic reasoning. It addresses three main challenges: (i) unreliable LLM-as-judge results due to weak domain knowledge, (ii) the inadequacy of static string matching for complex mechanistic outputs, and (iii) the need to score partial reasoning. oMeS resolves this through dynamic alignment ( 4.2) and weighted partial scoring ( 4.1). The evaluation pipeline  (Fig. 4)  consists of three stages: (i) Generate: Prompt the LLM to produce stepwise mechanisms, each with an intermediate (SMILES) and selected reaction subtype (Tab. 5). The full prompt is in App. H.3. (ii) Align: Match the predicted and gold mechanisms using weighted NeedlemanWunsch dynamic algorithm (Likic, 2008). (iii) Calculate: Derive four complementary metrics from the alignment to enable detailed, fine-grained evaluation of mechanistic reasoning."
        },
        {
            "title": "4.1 Definitions\nLet the gold mechanism be G = {(tk, Ik, wk)}N\nk=1\nwith N steps, where tk is the gold subtype label, Ik\nis the gold intermediate SMILES, and wk ≥ 0 is the\nstep weight with (cid:80)N\nk=1 wk = 1. Let the model’s\nraw prediction be P = {(ˆtj, ˆIj)}M\nj=1 with M pre-\ndicted intermediates. After alignment (§ 4.2), each\ngold step k is matched to at most one predicted step;\nwe denote such an aligned prediction at position k\nas (ˆtk, ˆIk) or marked missing if unmatched.\nSMILES Validity Score (V ) measures a model’s",
            "content": "ability to produce chemically valid intermediates, defined as the fraction of predicted SMILES that can be parsed by RDKit. Logical Fidelity Score (L) measures stepwise mechanistic labeling accuracy irrespective of structural correctness, computed over aligned positions. Formal definitions of and are in App. E. Organic Mechanism Scores (Stot, Spart) measures LLMs reasoning ability in organic reaction mechanisms. For each step, subtype correctness is prerequisite, since the model can demonstrate understanding of the underlying chemical rationale only with the correct subtype. oMeS-total (Stot) will assign credit only for exact matches: stot = wk 1{tk=ˆtk} 1{Ik= ˆIk}, Stot = (cid:88) k=1 stot oMeS-partial (Spart) grants partial credit when the generated intermediate has meaningful chemical similarity to the gold intermediate, as measured by molecular fingerprints, while oMeS-total is stricter. Let denotes the Tanimoto similarity (Bajusz et al., 2015) of Morgan fingerprints (Rogers and Hahn, 2010) and τ is similarity threshold: σ(Ik, ˆIk) = T(Ik, ˆIk) 1{T(Ik, ˆIk)τ } Spart = (cid:88) k=1 spar ; spar = wk σ(Ik, ˆIk) 1{tk=ˆtk}"
        },
        {
            "title": "4.2 Alignment Strategy\nWe align G = {(tk, Ik, wk)}N\n{(ˆtj, ˆIj)}M",
            "content": "k=1 and = j=1 with NeedlemanWunsch algorithm: 5 Model Size Overall Easy Medium Hard Stot Spart Stot Spart Stot Spart Stot Spart GPT-5 GPT-4o o3 Claude-Sonnet-4 Gemini-Pro-2.5 DeepSeek-R1* GPT-OSS LLaMA-3 Qwen-3 Mistral Phi-4 OLMo-2 OpenBioLLM ChemDFM BioT5+ - - - - - 685B 20B 8B 4B 7B 7B 13B 8B 8B 770M 90.4 83.7 90.8 91.0 90.5 87.6 78.2 73.5 58.4 52.8 0.3 17.4 4.4 0.0 0.0 51.9 20.3 47.4 37.3 57.8 45.4 31.5 12.6 14.9 12.7 0.0 6.1 1.7 0.7 0. 23.6 3.9 24.0 14.9 34.9 22.5 12.9 2.7 3.2 2.0 0.0 0.6 0.3 0.0 0.0 Proprietary and Frontier Models 29.1 5.0 28.1 17.9 37.9 25.0 14.2 3.3 4.2 2.2 0. 92.4 82.6 94.6 93.0 94.5 88.4 88.4 69.9 63.1 56.6 0.0 69.9 26.0 64.5 54.3 70.5 62.3 42.5 8.3 36.8 28.9 56.5 39.0 51.8 10.1 47.3 33.9 61.3 41.9 Open Source Models 47.6 13.0 12.1 14.6 0.0 25.1 1.5 2.6 1.7 0.0 28.0 1.5 2.6 2.2 0.0 Domain-Specific Models 0.6 0.3 0.0 0.0 22.0 9.4 0.0 0. 10.2 1.7 0.0 0.0 3.1 0.3 0.0 0.0 3.1 0.3 0.0 0.0 90.0 83.8 90.6 90.9 90.3 87.9 77.0 74.2 60.4 52.5 0.3 16.5 3.8 0.7 0. 50.7 20.6 45.6 35.8 56.6 45.1 30.3 13.2 17.5 12.8 0.0 5.2 1.9 0.0 0.0 21.6 3.2 23.3 12.7 32.4 20.6 11.7 3.2 3.8 2.3 0.0 0.0 0.3 0.0 0. 26.5 4.2 26.3 15.6 35.2 23.3 12.6 4.0 5.3 2.5 0.0 0.0 0.3 0.0 0.0 90.2 85.1 86.4 88.7 85.4 82.9 70.2 74.9 40.3 48.6 0.0 16.2 0.0 0.0 0. 31.5 9.7 32.5 20.7 46.3 21.3 14.8 7.9 4.3 9.0 0.0 4.9 0.0 0.0 0.0 7.2 1.6 8.6 7.5 16.6 8.3 1.8 1.5 0.2 1.0 0.0 0.0 0.0 0.0 0. 10.0 1.6 9.7 7.9 18.5 9.7 2.4 1.8 0.3 1.0 0.0 0.0 0.0 0.0 0.0 Table 3: Model Performance on oMeBench Across Difficulty Levels Match: if tk = ˆtj, we evaluate both exactmatch (stot) and similarity-based credit (spar); Type mismatch: if tk = ˆtj, we assign zero credit and mild penalty; Gaps (skip): skipping gold step or predicted step incurs fixed penalty. To break ties, we prioritize alignment paths sequentially by (1) higher Stot, (2) higher Spart, (3) fewer mismatches, and (4) fewer gaps. The final traceback assigns one of four step-level tags: match, type_mismatch, skip_gold (missing prediction), or extra (spurious prediction). The alignment procedure is robust to common edge cases, including minor SMILES typos or benign variants, skipped or extra steps, and cases where the intermediate is plausible but the subtype is mislabeled. Case studies and ablations are in App. F."
        },
        {
            "title": "5.1 Can LLMs solve mechanism problems?",
            "content": "To establish the baseline performance on our benchmark, we evaluate multiple different LLMs under common one-shot prompting setup. We adopt four metrics: Validity (V), Logicality (L), oMeS-total (Stot) and oMeS-partial (Spart).4 The results are presented in Tab. 3 and Fig. 5. Evaluated Models. We categorize the 14 LLMs into three groups: (i) Proprietary LLMs: GPTseries (Achiam et al., 2023), o3 (OpenAI, 2025), Claude-sonnet-4 (Anthropic, 2025), and Gemini Pro 2.5 (Team et al., 2023); (ii) Open-source LLMs: DeepSeek-R1 (Guo et al., 2025) and instruct version of LLaMa-3 (Dubey et al., 2024), 4Detailed prompts are in App. H.3. Qwen-3 (Yang et al., 2025), Mistral, and Phi-4mini (Abdin et al., 2024); (iii) Domain-specific LLMs: OLMo-2 (OLMo et al., 2025), OpenBioLLM (Ankit Pal, 2024), ChemDFM (Zhao et al., 2024), and BioT5+ (Pei et al., 2024)."
        },
        {
            "title": "5.2 LLMs show limited understanding of",
            "content": "mechanisms The evaluation indicates that while current LLMs can often produce syntactically valid SMILES and maintain certain degree of procedural coherence, their understanding of reaction mechanisms remains highly limited. Even the strongest frontier models achieve only moderate scores that decline sharply with task difficulty. For example, Gemini-Pro-2.5, the best-performing model, reach only 37.9 on Spart, while many other models yield scores close to zero, reflecting profound lack of mechanistic knowledge. In other words, LLMs can imitate the surface form of mechanistic explanations but fail to capture the precise, multi-step causal logic underlying organic reactions. Domain-specific models underperform. Although chemistry-trained models (e.g., ChemDFM, OLMo-2) are optimized on large chemical corpora, their performance lags behind that of generalpurpose LLMs. Even OLMo-2, the strongest, underperforms open-source baselines across all metrics, including even validity. This disparity suggests that while domain pretraining exposes models to vast chemical literature, it fails to provide explicit mechanistic reasoning. The frequent generation of irrelevant or inconsistent structure indicates that these models capture surface-level chemical patterns rather than causal mechanistic logic. 6 Figure 5: Performance of LLMs on oMeBench across difficulty levels. Frontier models outperform others but all degrade on harder reactions, while chemistry-specific models lag despite domain pretraining Chain-of-Thought fails to enhance reasoning. One-shot Chain-of-Thought (CoT) prompting (Wei et al., 2022) did not yield measurable improvements (Tab. 14). The generated reasoning traces tend to be verbose yet shallow, merely paraphrasing reaction conditions without offering causal insights. Unlike symbolic or mathematical reasoning, mechanism elucidation requires structural understanding, which CoT, without chemistry-aware supervision, fails to provide."
        },
        {
            "title": "5.3 Why do LLMs fail?",
            "content": "To systematically analyze the failure modes, we categorize three broad categories of errors: Chemical Knowledge Errors, Mechanistic and Procedural Errors, and Structural and Formalization Errors. Each of them is further divided into representative subtypes (Tab. 8). These categories are not independent. For instance, misinterpreting reaction conditions can lead to misidentified reactive centers or invalid intermediates. In Fig. 6, we analyze Gemini-2.5-pro as representative. Figure 6: Distribution of mechanistic reasoning errors for Gemini-Pro-2.5. The chart groups errors into three primary categories, with each bar indicating the percentage of specific subtype. Chemical structural inconsistency. Despite high product-level SMILES validity in Tab. 3, 35.4% of all errors arise from invalid or inconsistent SMILES within multi-step mechanisms. Models can often produce valid final products but fail to maintain 7 coherent symbolic representations across steps. In addition, valence and charge violations account for 7.3% of total errors, revealing instability in representing intermediate states. The case in Tab. 4 shows how LLMs invent inconsistent chemical structures to provide logical mechanism, which is considered as perceptual gap of LLMs. Figure 7: Performance vs Reaction Complexity. Performance degradation as length increases. Longer pathways amplify illogical jumps, showing models limited ability to sustain causal reasoning across extended steps. Length effect of the mechanism. Fig. 7 shows that performance consistently drops with increasing mechanism length. While short twoor three-step mechanisms can often be reproduced, mechanisms longer than five steps frequently omit intermediates or rearrangements, leading to incomplete or illogical pathways. This highlights their inability to sustain multi-step causal reasoning over longer contexts. Skipping critical steps, accounting for 20.8% of total errors, reflects the models difficulty in sustaining multi-step causal reasoning. An example of this behavior is in Tab. 4. Inherently more challenging types. Mechanism step types differ markedly in difficulty. Fig. 8 shows models perform better on frequent, patternbased transformations such as substitution and addition, but struggle with rearrangements, pericyclic reactions, and radical processes. These categories demand deeper causal reasoning about electron Step Model Output Comments 1 2 3 ... acid_base_proton_transfer: CC(C1CC1)=N[N-]... acid_base_proton_transfer: [CH2-]C(C1CC1)=N[N-]... leaving_group_elimination: C=C(C1CC1)N=N Correct initial deprotonation. Redundant step: removes α-H instead of cleaving. Fabricate flow and distribution. electron charge Table 4: Example where the model achieves the correct result via implausible steps. Full results in App. J.4 flow, intermediate stability, and molecular structure, which are capabilities that current LLMs fail to develop. The observed disparity suggests that model predictions rely primarily on surface pattern association rather than mechanistic understanding. These results reveal two key deficiencies: reasoning gap, where models fail to sustain coherent multi-step causal logic, and knowledge gap, where limited mechanistic understanding leads to systematic errors in complex reaction types. Figure 8: Model accuracy by type. While addition and substitution are handled moderately well, pericyclic, rearrangement, and radical steps remain challenging. 5."
        },
        {
            "title": "Improving LLM Performance",
            "content": "In-context learning (ICL). To narrow the perceptual gap, we apply three-shot in-context learning strategy, selecting three reactions from the training corpus oMe-Silver with the highest Tanimoto similarity of Differential Reaction Fingerprint (DRFP) (Probst et al., 2022) to the query reaction. These exemplars provide structural priors that guide the model toward multi-step, causally coherent reasoning. As shown in Tab. 15 and App. J.5, exemplar-based prompting consistently improves scores across nearly all models. The gains are most pronounced for larger proprietary models, such as GPT-5 and Gemini-Pro-2.5. Even models that underperform in the one-shot setting, like GPT-4o, 8 show notable improvements under ICL. Improvements are especially strong for common step types, such as proton transfer and nucleophilic addition, where models can retrieve and adapt familiar mechanistic patterns. This suggests that ICL enhances reasoning not by introducing new knowledge, but by scaffolding the models retrieval and analogy capabilities. Further, the improvements also demonstrate the high quality of silver standard data. Fine-tuning. To move beyond exemplar imitation and further narrow the reasoning and knowledge gaps, we finetune open-source foundation models on our oMe-Silver dataset using supervised instruction tuning. All experiments are implemented in the LLaMA-Factory framework (Zheng et al., 2024a) and Transformers (Wolf et al., 2020) with BF16 precision on NVIDIA GH200 GPUs. Qwen-3-4B is trained with both standard SFT (data without rationale) and Chain-of-Thought SFT (CoT-SFT, data augmented with natural-language rationales), while LLaMA-3-8B, Mistral-7B, and OLMo-213B are optimized using parameter-efficient LoRA. Fine-tuning yields substantial improvements in all dimensions, particularly for in-domain reactions, with Qwen-3-SFT outperforming some proprietary models such as Claude-Sonnet-4 (Tab. 16). Notably, incorporating CoT reasoning during SFT provides additional gains in mechanistic accuracy under ICL prompting. While ICL enhances reasoning by imitation, fine-tuning internalizes such reasoning patterns as stable model priors. Together, these results demonstrate that explicit mechanistic supervision is the most effective way to transfer mechanism knowledge and reasoning capabilities into open-source LLMs."
        },
        {
            "title": "6 Conclusion",
            "content": "In conclusion, we present oMeBench, benchmark for evaluating large language models on organic mechanism reasoning. Evaluating 14 proprietary and open-source models, we identify persistent gaps in mechanistic understanding, particularly in multi-step causal reasoning and symbolic consistency. To address these challenges, we introduce oMeS, dynamic evaluation framework, and show that both in-context learning and supervised finetuning enhance mechanistic reasoning, with our fine-tuned 4B model achieving 50% higher performance than Claude-Sonnet-4. Overall, oMeBench establishes foundation for advancing chemically grounded reasoning in large language models."
        },
        {
            "title": "Limitations",
            "content": "We identify key limitations in our models, dataset, and evaluation framework. While several are discussed throughout the paper, we summarize the most critical aspects below for completeness Models. Both our improved models and existing LLMs still struggle with mechanistic grounding. They sometimes misinterpret reaction conditions or generate chemically invalid intermediates, revealing limited integration between symbolic reasoning and molecular structure constraints. This indicates that current token-level generation lacks explicit enforcement of chemical conservation and contextual awareness. Dataset. While oMeBench includes graduatelevel mechanisms across diverse reaction classes, its current scale remains smaller than large outcome-prediction corpora, limiting opportunities for large-scale pretraining. Expanding the dataset to modern reaction classes, such as photoredox, enzymatic, and transition-metal catalysis, would enable broader and more realistic benchmarking. Moreover, while LLM-driven expansion introduces substantial structural diversity, it yields skewed distribution of substituents; for example, CH3 is disproportionately overrepresented  (Fig. 9)  , which may bias model learning toward common functional groups. Evaluation. We recruit annotators with strong chemistry expertise (see Appendix A), whose judgments may differ from those of general or non-expert annotators. Although oMeS offers fine-grained and chemically grounded evaluation in both molecular and mechanistic level, it still abstracts molecules into symbolic SMILES representations, which cannot fully capture threedimensional environments. Incorporating graphor geometry-based similarity measures could yield more complete assessment of reasoning accuracy."
        },
        {
            "title": "Ethical Considerations",
            "content": "Data. All data were obtained from publicly available textbooks, peer-reviewed publications, and open-access reaction databases, in full compliance with relevant legal and ethical standards. No proprietary or confidential sources were used. Annotation. Human annotations were carried out by qualified chemistry researchers, compensated at the standard institutional rate; anonymized 9 summaries of their expertise and experience are provided in Appendix A. Model and Environmental Ethics. All models used are open-source or publicly available under research-friendly licenses. Because our methods build upon pretrained language models, they may inherit biases from their underlying training data. Moreover, since most chemical sources are written in English, certain linguistic or regional chemistries may be underrepresented. We also recognize the environmental costs associated with large-scale model computation and therefore restrict our work to evaluation and lightweight fine-tuning. Responsible Research. We aim to promote fairness, transparency, and reproducibility in AI-forscience research. The tools and benchmarks introduced in this work are designed to assist, not replace, human chemists. All results should be interpreted with expert judgment."
        },
        {
            "title": "Use Of Generative AI",
            "content": "We employed large language models (e.g., ChatGPT) to assist with grammar refinement, LaTeX code formatting, and, in few cases, improving the conciseness of lengthy sentences in the authors original handwritten content. All outputs were subsequently reviewed and critically revised by the human authors to ensure scientific accuracy and originality."
        },
        {
            "title": "References",
            "content": "Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell Hewett, Mojan Javaheripi, Piero Kauffmann, and 1 others. 2024. Phi-4 technical report. ArXiv preprint, abs/2412.08905. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. Gpt-4 technical report. ArXiv preprint, abs/2303.08774. Malaikannan Sankarasubbu Ankit Pal. Advancing open-source 2024. large Openbiollms: language models for healthcare and life scihttps://huggingface.co/aaditya/ ences. OpenBioLLM-Llama3-70B. Anthropic. 2025. About claude models. https://docs.anthropic.com/en/docs/ about-claude/models. 24. Accessed: 2025-09Dávid Bajusz, Anita Rácz, and Károly Héberger. 2015. Why is tanimoto index an appropriate choice for fingerprint-based similarity calculations? Journal of cheminformatics, 7(1):20. Andres Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew White, and Philippe Schwaller. 2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence, 6(5):525535. Andres Bran, Theo Neukomm, Daniel Armstrong, Zlatko Jonˇcev, and Philippe Schwaller. 2025. Chemical reasoning in llms unlocks strategy-aware synthesis planning and reaction mechanism elucidation. ArXiv preprint, abs/2503.08537. Ekow Broni-Bediako, Zhaoyu Li, Lannie Estergreen, José Vásquez-Cervantes, Gabriel Lee, Mohamad Ali Mashhadi, Alán Aspuru-Guzik, and Klavs Jensen. 2022. Autonomous reaction optimization with language model. Nature Communications, 13(1):6813. Francis A. Carey and Richard J. Sundberg. 2007. Advanced Organic Chemistry: Part A: Structure and Mechanisms, 5th edition. Springer Science & Business Media, New York, NY. Shuan Chen, Ramil Babazade, Taewan Kim, Sunkyu Han, and Yousung Jung. 2024. large-scale reaction dataset of mechanistic pathways of organic reactions. Scientific Data, 11(1):863. Ziqi Chen, Zixun Liu, Zhong-Yu Wei, and Dongxiao Zhao. 2023. G-retro: graph-based generative model for retrosynthesis prediction. In Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI), pages 36373645. Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. 2020. Chemberta: Large-scale selfsupervised pretraining for molecular property prediction. ArXiv preprint, abs/2010.09885. Kourosh Darvish, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, Jason Hein, and Alán Aspuru-Guzik. 2024. ORGANA: robotic assistant for automated chemistry experimentation and characterization. ArXiv preprint, abs/2401.06949. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Tianyu Liu, and 1 others. 2023. survey on incontext learning. ArXiv preprint, abs/2301.00234. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, and 1 others. 2024. The llama 3 herd of models. arXiv e-prints, pages arXiv2407. Carl Edwards, Chi Han, Gawon Lee, Thao Nguyen, Bowen Jin, Chetan Kumar Prasad, Sara Szymkuc, Bartosz A. Grzybowski, Ying Diao, Jiawei Han, Ge Liu, Hao Peng, Martin D. Burke, and Heng Ji. 2025. mclm: function-infused and synthesisfriendly modular chemical language model. ArXiv preprint, abs/2505.12565. Robert B. Grossman. 2003. The Art of Writing Reasonable Organic Reaction Mechanisms, 2nd edition. Springer Science & Business Media, New York, NY. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, and 1 others. 2025. Deepseekr1: Incentivizing reasoning capability in llms via reinforcement learning. ArXiv preprint, abs/2501.12948. Wengong Jin, Connor W. Coley, Regina Barzilay, and Tommi S. Jaakkola. 2017. Predicting organic reaction outcomes with weisfeiler-lehman network. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 26072616. Joonyoung Joung, Mun Hong Fong, Jihye Roh, Zhengkai Tu, John Bradshaw, and Connor Coley. 2024. Reproducing reaction mechanisms with machine-learning models trained on large-scale mechanistic dataset. Angewandte Chemie International Edition, 63(43):e202411296. Steven Kearnes, Michael Maser, Michael Wleklinski, Anton Kast, Abigail Doyle, Spencer Dreher, Joel Hawkins, Klavs Jensen, and Connor Coley. 2021. The open reaction database. Journal of the American Chemical Society, 143(45):1882018826. Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin Shoemaker, Paul Thiessen, Bo Yu, and 1 others. 2025. Pubchem 2025 update. Nucleic acids research, 53(D1):D1516D1525. Laszlo Kurti and Barbara Czakó. 2005. Strategic applications of named reactions in organic synthesis. Elsevier. Greg Landrum, Paolo Tosco, Brian Kelley, Ricardo Rodriguez, David Cosgrove, Riccardo Vianello, sriniker, Peter Gedeck, Gareth Jones, Eisuke Kawashima, NadineSchneider, Dan Nealschneider, Andrew Dalke, tadhurst cdd, Matt Swain, Brian Cole, Samo Turk, Aleksandr Savelev, Alain Vaucher, and 11 others. 2025. rdkit/rdkit: 2025_03_5 (q1 2025) release. Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, and Yu Li. 2025a. Beyond chemical qa: Evaluating llms chemical reasoning with modular chemical operations. ArXiv preprint, abs/2505.21318. Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, and Yu Li. 2025b. Beyond chemical qa: Evaluating llms chemical reasoning with modular chemical operations. ArXiv preprint, abs/2505.21318. 10 Vladimir Likic. 2008. The needleman-wunsch algorithm for sequence alignment. Lecture given at the 7th Melbourne Bioinformatics Course, Bi021 Molecular Science and Biotechnology Institute, University of Melbourne, pages 146. Daniel Mark Lowe. 2012. Extraction of chemical structures and reactions from the literature. Ph.D. thesis. John Mayfield, Daniel Lowe, and Roger Sayle. 2017. Pistachio: Search and faceting of large reaction databases. In ABSTRACTS OF PAPERS OF THE AMERICAN CHEMICAL SOCIETY, volume 254. AMER CHEMICAL SOC 1155 16TH ST, NW, WASHINGTON, DC 20036 USA. Paul Muller. 1994. Glossary of terms used in physical organic chemistry (iupac recommendations 1994). Pure and applied chemistry, 66(5):10771184. Siddharth M. Narayanan, James D. Braza, Ryan-Rhys Griffiths, Albert Bou, Geemi Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G. Rodriques, and Andrew D. White. 2025. Training scientific reasoning model for chemistry. ArXiv preprint, abs/2506.17238. Team OLMo, Pete Walsh, Luca Soldaini, Dirk Groeneveld, Kyle Lo, Shane Arora, Akshita Bhagia, Yuling Gu, Shengyi Huang, Matt Jordan, and 1 others. 2025. 2 olmo 2 furious. ArXiv preprint, abs/2501.00656. OpenAI. 2025. o4-mini. introducing-o3-and-o4-mini/. Introducing openai o3 and https://openai.com/index/ Graham Patrick. 2023. An introduction to medicinal chemistry. Oxford university press. Qizhi Pei, Lijun Wu, Kaiyuan Gao, Xiaozhuan Liang, Yin Fang, Jinhua Zhu, Shufang Xie, Tao Qin, and Rui Yan. 2024. Biot5+: Towards generalized biological understanding with iupac integration and multi-task tuning. ArXiv preprint, abs/2402.17810. Daniel Probst, Philippe Schwaller, and Jean-Louis Reymond. 2022. Reaction classification and yield prediction using the differential reaction fingerprint drfp. Digital discovery, 1(2):9197. Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. 2020. Zero: Memory optimizations toward training trillion parameter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, pages 1 16. IEEE. David Rogers and Mathew Hahn. 2010. Extendedconnectivity fingerprints. Journal of chemical information and modeling, 50(5):742754. Philippe Schwaller, Daniel Probst, Alain Vaucher, Vishnu Nair, David Kreutter, Teodoro Laino, and Jean-Louis Reymond. 2021. Predicting the outcomes of organic reactions with language model. ACS Central Science, 7(7):11651171. Richard Silverman and Mark Holladay. 2014. The organic chemistry of drug design and drug action. Academic press. Michael Smith. 2025. Marchs advanced organic chemistry: reactions, mechanisms, and structure. John Wiley & Sons. Hannes Stark, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, and Tommi Jaakkola. 2022. Chemberta-2: Towards better molecular foundation model. ArXiv preprint, abs/2209.01712. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto. 2023. Alpaca: strong, replicable instruction-following model. Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html, 3(6):7. Mohammadamin Tavakoli, Yin Ting Chiu, Pierre Baldi, Ann Marie Carlton, and David Van Vranken. 2023. Rmechdb: public database of elementary radical reaction steps. Journal of chemical information and modeling, 63(4):11141123. Mohammadamin Tavakoli, Ryan Miller, Mirana Claire Angel, Michael Pfeiffer, Eugene Gutman, Aaron Mood, David Van Vranken, and Pierre Baldi. 2024. Pmechdb: public database of elementary polar reaction steps. Journal of Chemical Information and Modeling, 64(6):19751983. Gemini Team, Rohan Anil, Sebastian Borgeaud, JeanBaptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew Dai, Anja Hauth, Katie Millican, and 1 others. 2023. Gemini: family of highly capable multimodal models. ArXiv preprint, abs/2312.11805. Mantas Vaškeviˇcius and Jurgita Kapoˇciute-Dzikiene. 2024. Language models for predicting organic synthesis procedures. Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, and Chao Zhang. 2025. LLM-augmented chemical synthesis and design decision programs. ArXiv preprint, abs/2505.07027. Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, and Wei Wang. 2023. Scibench: Evaluating college-level scientific problem-solving abilities of large language models. ArXiv preprint, abs/2307.10635. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, and 1 others. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824 24837. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, and 3 others. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 3845, Online. Association for Computational Linguistics. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, and 1 others. 2025. Qwen3 technical report. ArXiv preprint, abs/2505.09388. Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang. 2023. Instruction tuning for large language models: survey. ArXiv preprint, abs/2308.10792. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, Hongshen Xu, Zichen Zhu, Su Zhu, and 1 others. 2024. Chemdfm: large language foundation model for chemistry. ArXiv preprint, abs/2401.14818. Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma. 2024a. Llamafactory: Unified efficient finetuning of 100+ language models. ArXiv preprint, abs/2403.13372. Yizhen Zheng, Jiaxin Ju, Yaw-Ling Koh, Xinyue Wang, Chen Gong Lu, Shenda Poon, Tong Liu, Geoffrey Kishun Chan, and Shirui Pan. 2024b. Large language models for scientific synthesis, inference and explanation. Nature Machine Intelligence. Ming Zhong, Siru Ouyang, Yizhu Jiao, Priyanka Kargupta, Leo Luo, Yanzhen Shen, Bobby Zhou, Xianrui Zhong, Xuan Liu, Hongxiang Li, Jinfeng Xiao, Minhao Jiang, Vivian Hu, Xuan Wang, Heng Ji, Martin Burke, Huimin Zhao, and Jiawei Han. 2023. Reaction miner: An integrated system for chemical reIn Proc. The action extraction from textual data. 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP2023) Demo Track. Xianrui Zhong, Yufeng Du, Siru Ouyang, Ming Zhong, Tingfeng Luo, Qirong Ho, Hao Peng, Heng Ji, and Jiawei Han. 2024. Actionie: Action extraction from scientific literature with programming languages. In Proc. The 62nd Annual Meeting of the Association for Computational Linguistics (ACL2024)."
        },
        {
            "title": "A Annotation Detail",
            "content": "Annotator Background. We recruited four expert annotators with strong backgrounds in chemistry competitions. Two are gold medalists of the Chemistry Olympiad, while the other two are regional firstprize winners. All annotators have received more than four years of rigorous training in organic chemistry, including functional group transformations, reaction mechanisms, stereochemistry, and common strategies in synthetic design, and are currently pursuing degrees in chemistry. To ensure both competence and reliability, the selection criteria required (i) at least first prize in chemistry competitions and enrollment in relevant major, (ii) demonstration of responsibility and enthusiasm during interviews, and (iii) successful completion of pilot annotations that reflected correct understanding of the task. Annotation Procedure. The annotation process began with the authors curating candidate reactions and defining preliminary criteria for reaction type, subtype, and difficulty level. Annotators were first introduced to the project background and refreshed their knowledge of key organic chemistry concepts before receiving detailed task instructions. They were encouraged to refine and clarify the labeling criteria through iterative discussions with the authors. The core tasks involved (i) extracting reactions and validating intermediate SMILES strings, and (ii) annotating metadata such as difficulty level, type, and subtype. In later stages, annotators also contributed to labeling error categories and drafting representative case studies. Inter-Annotator Agreement. Each reaction was independently annotated by two domain experts, and disagreements were resolved through consultation with third annotator followed by consensus discussion. To quantify annotation consistency, we measured inter-annotator agreement across major labeling dimensions. Fleiss κ for reaction types reached 0.95, indicating almost perfect agreement, while the quadratic-weighted κ for difficulty levels was 0.86, reflecting strong consistency across annotators. These results demonstrate that the annotation protocol yields highly reliable and reproducible human labels, providing stable foundation for subsequent similarity-based evaluation. A."
        },
        {
            "title": "Instructions to Expert Annotators",
            "content": "Task Definition. Given reaction entry with its reactants_smiles, products_smiles, and conditions, your task is to construct or verify complete and correct mechanism. Each entry must include all required metadata fields, ensuring machine readability and chemical validity. The target JSON schema is as follows: { } \"reaction_id\": \"XX-xxx\", \"level\": \"easy/medium/hard\", \"name\": \"...\", \"reactants_smiles\": [...], \"products_smiles\": [...], \"conditions\": \"...\", \"mechanism_step_nums\": 4, \"description\": \"...\", \"mechanism\": [...] Required Metadata Fields. Annotators must carefully fill out or verify the following components: 1. reaction_id: unique alphanumeric identifier (e.g., NR-201). 2. level: Difficulty level: easy, medium, or hard, based on mechanistic complexity and reasoning depth. 3. name: The formal or commonly accepted name of the reaction (e.g., Nazarov Cyclization Reaction). 13 4. reactants_smiles / products_smiles: Chemically valid SMILES strings representing all reactants and products. 5. conditions: Concise expression of reaction conditions, including catalysts, reagents, or solvents (e.g., H+ OSO2Me). 6. description: short natural-language summary of the overall mechanism and rationale. 7. mechanism: list of ordered elementary steps. Each step must contain: step: Step number (integer, starting from 1). type: The high-level mechanistic category (e.g., addition, elimination, proton_transfer). subtype: The specific mechanistic subtype (e.g., acid_base_proton_transfer, nucleophilic_addition). intermediate_smiles: chemically valid SMILES representing the intermediate after this step. rationale: brief expert-level explanation of the mechanistic principle underlying this transformation (e.g., Protonation of the carbonyl oxygen increases electrophilicity and stabilizes the developing positive charge via resonance.) Annotation Principles. 1. Each mechanism must align with those recordings in literature, textbooks or databases. 2. All SMILES strings, including reactants, products and intermediates, must satisfy chemical validity and are compilable by RDKit. 3. Assign step types and subtypes according to the standardized taxonomy provided in Tab. 5. 4. Annotators should provide rationales and descriptions in concise academic language, emphasizing reactivity, resonance, or stability reasoning rather than descriptive repetition. Example Annotation. Mechanism JSON 1 { 3 4 5 6 7 9 10 11 12 13 15 16 17 18 19 } \"reaction_id\": \"NR-201\", \"level\": \"medium\", \"name\": \"Nazarov Cyclization Reaction\", \"reactants_smiles\": [\"C(C)=CC(=O)C=C(C)\", \"CS(=O)(=O)O\"], \"products_smiles\": [\"CC1=CC(=O)CC1(C)\"], \"conditions\": \"H+ OSO2Me\", \"mechanism_step_nums\": 4, \"description\": \"Under strong acid conditions, the divinyl ketone is protonated to activate the (cid:44) carbonyl toward cation formation. This enables oxyallyl cation generation, which undergoes (cid:44) Nazarov 4$pi$-electrocyclization to form cyclopentenyl cation. Subsequent (cid:44) deprotonation and tautomerization yield the thermodynamically stable cyclopentenone (cid:44) product.\", \"mechanism\": [ { \"step\": 1, \"type\": \"proton_transfer\", \"subtype\": \"acid_base_proton_transfer\", \"intermediate_smiles\": \"C(C)=CC(=[OH+])C=CC\", \"rationale\": \"Protonation of the carbonyl oxygen increases electrophilicity and stabilizes (cid:44) the developing positive charge via resonance, facilitating oxyallyl cation formation under (cid:44) strong acid.\" }, ..."
        },
        {
            "title": "B Dataset",
            "content": "B.1 Related Work wide range of datasets have been developed to support machine learning in chemistry. General-purpose chemical databases such as Pistachio (Mayfield et al., 2017) and PubChem (Kim et al., 2025) provide millions of reactions and molecular entries compiled from ELNs, patents, and scientific publications. While valuable for large-scale data mining, these resources mainly emphasize reaction outcomes or compound properties, without explicit mechanistic details. Among reaction-focused datasets, the USPTO collections are the most widely used. USPTO-50k (Lowe, 2012) and USPTO-MIT (Jin et al., 2017) provide thousands of reactions extracted from patents, but they primarily encode transformations from reactants to products without mechanistic rationales. Later variants such as mech-USPTO-31k (Chen et al., 2024) and USPTO-Mechanistic (Joung et al., 2024) introduced template-based mechanism generation. However, these datasets are generated by automated matching procedures with atom-mapped SMILES, resulting in limited mechanistic diversity and repetitive patterns. They fail to reflect the stepwise reasoning chemists employ when analyzing electron flow and intermediates. Other efforts have attempted to collect mechanistic steps more explicitly. RMechDB (Tavakoli et al., 2023) focuses on radical reactions, aggregating over 5,000 manually curated steps linked to specific transition states. Its counterpart, PMechDB, specializes in polar reactions (Tavakoli et al., 2024), providing complementary collection of elementary steps. While valuable, both databases focus narrowly on single mechanistic families, and do not integrate radical and ionic logic in unified pathways. Along with USPTO family, their step collections remain fragmented, making them less suitable for benchmarking end-to-end reasoning. Moreover, this mapping representation is suitable for training neural networks, e.g. GNN, but far from good dataset for LLM fine-tuning and evaluation. Recently, datasets like ChemCoTBench (Li et al., 2025b) and SciBench (Wang et al., 2023) introduced natural language chemistry tasks, including multiple-choice questions or descriptive reasoning. These benchmarks emphasize natural language interaction but lack explicit molecule-level mechanistic detail, limiting their ability to test fine-grained chemical reasoning. In summary, existing datasets fall into two extremes: large-scale outcome-oriented corpora without mechanisms, or narrowly focused collections that lack breadth and natural language interpretability. Our benchmark complements these efforts by combining stepwise mechanistic detail, validated intermediates, and natural language rationales in unified, diverse, and challenging dataset. B.2 Data format and comparison B.2.1 mech-USPTO-31k Sample Below we show the data format in mech-USPTO-31k (Chen et al., 2024), corresponding to single line in the CSV file. We can see that early datasets primarily rely on atom-mapping to represent individual mechanistic steps, which is non-intuitive and difficult to interpret. Moreover, in the raw CSV format, it is difficult to determine which mechanistic steps together constitute complete reaction. 15 mechanistic step in mech-USPTO-31k Original Reaction: O=C(OCc1ccccc1)[NH:1][CH2:2][CH2:3][CH2:4][CH2:5][C@@H:6]([C:7]([O:8][CH3:9])=[O:10])[NH:11][C:12](=[O:13])[NH:14][c :15]1[cH:16][c:17]([O:18][CH3:19])[cH:20][c:21]([C:22]([CH3:23])([CH3:24])[CH3:25])[c:26]1[OH:27]>>[NH2:1][CH2:2][ CH2:3][CH2:4][CH2:5][C@@H:6]([C:7]([O:8][CH3:9])=[O:10])[NH:11][C:12](=[O:13])[NH:14][c:15]1[cH:16][c:17]([O:18][ CH3:19])[cH:20][c:21]([C:22]([CH3:23])([CH3:24])[CH3:25])[c:26]1[OH:27] Updated Reaction: [O:201]=[C:101]([O:202][CH2:203][c:204]1[cH:205][cH:206][cH:207][cH:208][cH:209]1)[NH:1][CH2:2][CH2:3][CH2:4][CH2:5][C@@H :6]([C:7]([O:8][CH3:9])=[O:10])[NH:11][C:12](=[O:13])[NH:14][c:15]1[cH:16][c:17]([O:18][CH3:19])[cH:20][c:21]([C :22]([CH3:23])([CH3:24])[CH3:25])[c:26]1[OH:27].[BrH:301]>>[NH2:1][CH2:2][CH2:3][CH2:4][CH2:5][C@@H:6]([C:7]([O:8][ CH3:9])=[O:10])[NH:11][C:12](=[O:13])[NH:14][c:15]1[cH:16][c:17]([O:18][CH3:19])[cH:20][c:21]([C:22]([CH3:23])([CH3 :24])[CH3:25])[c:26]1[OH:27] Mechanistic Class: Cbz_deprotection Mechanistic Label: [(201, 301.1), ([301.1, 301], 301), (301, 203), ([203, 202], [202, 101]), ([101, 201], 201), (1, 201.1), ([201.1, 201], 201), (201, [201, 101]), ([101, 1], 1)] oMe-Gold Sample B.2.2 Below, we present the data format used in our datasets. It provides clear reaction information, including SMILES of reactants, products, and conditions, as well as step-by-step mechanism with annotations of type, subtype, and intermediate SMILES. In addition, each step is accompanied by fine-grained rationales, and each reaction is accompanied by natural language description explaining the underlying reasons for the transformations. The dataset is stored in JSON/JSONL format, enabling both large-scale evaluation and fine-tuning, while remaining interpretable for humans and domain experts."
        },
        {
            "title": "Mechanism JSON",
            "content": "1 { 2 3 4 5 6 8 9 10 11 12 14 15 16 17 18 20 21 22 23 24 26 27 \"reaction_id\": \"NR-201\", \"level\": \"medium\", \"name\": \"Nazarov Cyclization Reaction\", \"reactants_smiles\": [\"C(C)=CC(=O)C=C(C)\", \"CS(=O)(=O)O\"], \"products_smiles\": [\"CC1=CC(=O)CC1(C)\"], \"conditions\": \"H+ OSO2Me\", \"mechanism_step_nums\": 4, \"description\": \"Under strong acid conditions, the divinyl ketone is protonated to activate the (cid:44) carbonyl toward cation formation. This enables oxyallyl cation generation, which undergoes (cid:44) Nazarov 4$pi$-electrocyclization to form cyclopentenyl cation. Subsequent (cid:44) deprotonation and tautomerization yield the thermodynamically stable cyclopentenone (cid:44) product.\", \"mechanism\": [ { \"step\": 1, \"type\": \"proton_transfer\", \"subtype\": \"acid_base_proton_transfer\", \"intermediate_smiles\": \"C(C)=CC(=[OH+])C=CC\", \"step_weight\": 0.1020, \"rationale\": \"Protonation of the carbonyl oxygen increases electrophilicity and stabilizes (cid:44) the developing positive charge via resonance, facilitating oxyallyl cation formation under (cid:44) strong acid.\" }, { \"step\": 2, \"type\": \"pericyclic\", \"subtype\": \"electrocyclization\", \"intermediate_smiles\": \"C1(=CC(C([CH+]1)C)C)O\", \"step_weight\": 0.5714, \"rationale\": \"The oxyallyl cation undergoes conrotatory 4$pi$-electrocyclization, favored (cid:44) by orbital symmetry and leading to cyclopentenyl cation stabilized by adjacent (cid:44) substituents.\" }, { 16 \"step\": 3, \"type\": \"elimination\", \"subtype\": \"proton_elimination\", \"intermediate_smiles\": \"C1(=CC(C(=C1)C)C)O\", \"step_weight\": 0.2449, \"rationale\": \"Deprotonation relieves positive charge on the cyclopentenyl cation, driven by (cid:44) formation of more conjugated alkene system.\" }, { \"step\": 4, \"type\": \"proton_transfer\", \"subtype\": \"acid_base_proton_transfer\", \"intermediate_smiles\": \"CC1=CC(=O)CC1(C)\", \"step_weight\": 0.0816, \"rationale\": \"Acid-catalyzed tautomerization converts the enol to the more stable conjugated (cid:44) ketone, favored by carbonyl bond strength and extended $pi$-conjugation.\" } 28 29 30 32 33 34 35 36 38 39 40 41 42 ] 43 44 } oMe-Template Sample B.2.3 Substitutable R-groups are denoted as [*:i] for RDKit compatibility. Mechanism JSON 1 { 2 4 5 6 7 8 10 11 12 13 14 16 17 18 19 20 22 23 24 25 26 28 29 30 31 32 34 35 36 \"reaction_id\": \"NR-201\", \"level\": \"medium\", \"name\": \"Nazarov Cyclization Reaction\", \"reactants_smiles\": [\"C(C([*:1]))=CC(=O)C=C(C([*:2]))\", \"CS(=O)(=O)O\"], \"products_smiles\": [\"C([*:2])C1=CC(=O)CC1([*:1])\"], \"conditions\": \"H+ OSO2Me\", \"mechanism_step_nums\": 4, \"description\": \"The reaction begins with protonation of the carbonyl oxygen in the divinyl (cid:44) ketone, forming resonance-stabilized oxyallyl cation. This cation undergoes 4$pi$- (cid:44) electrocyclic ring closure to yield cyclopentenyl cation intermediate, followed by (cid:44) deprotonation and keto-enol tautomerization to produce the cyclopentenone product.\", \"mechanism\": [ { \"step\": 1, \"type\": \"proton_transfer\", \"subtype\": \"acid_base_proton_transfer\", \"intermediate_smiles\": \"C(C([*:1]))=CC(=[OH+])C=CC([*:2])\", \"step_weight\": 0.1020, \"rationale\": \"Protonation of the carbonyl oxygen activates the divinyl ketone toward cation (cid:44) formation by stabilizing the developing positive charge.\" }, { \"step\": 2, \"type\": \"pericyclic\", \"subtype\": \"electrocyclization\", \"intermediate_smiles\": \"C1(=CC(C([CH+]1)C([*:1]))C([*:2]))O\", \"step_weight\": 0.5714, \"rationale\": \"The oxyallyl cation undergoes conrotatory 4$pi$-electrocyclization, (cid:44) generating cyclopentenyl cation stabilized by conjugation and substituent effects.\" }, { \"step\": 3, \"type\": \"elimination\", \"subtype\": \"proton_elimination\", \"intermediate_smiles\": \"C1(=CC(C(=C1)C([*:2]))C([*:1]))O\", \"step_weight\": 0.2449, \"rationale\": \"Deprotonation of the cation intermediate restores aromatic conjugation and (cid:44) reduces charge localization.\" }, { \"step\": 4, 17 \"type\": \"proton_transfer\", \"subtype\": \"acid_base_proton_transfer\", \"intermediate_smiles\": \"C([*:2])C1=CC(=O)CC1(C([*:1]))\", \"step_weight\": 0.0816, \"rationale\": \"Final tautomerization converts the enol to the stable conjugated ketone, (cid:44) completing the Nazarov cyclization.\" } 37 39 40 41 42 ] 43 44 } B.3 Types and Subtypes Type cleavage addition elimination substitution Subtype Description heterolytic_cleavage homolytic_cleavage nucleophilic_addition electrophilic_addition radical_addition Bond breaks with both electrons going to one fragment (ions formed), including decarboxylation in some condition Bond breaks evenly with one electron to each fragment (radicals formed) Nucleophile attacks an electrophilic center Electrophile adds to an electron-rich system (e.g., alkene) Radical adds to π-bond system proton_elimination leaving_group_elimination radical_elimination β-H proton of carbocation is abstracted to form double bond Leaving group departs simultaneously with double bond formation Radical eliminates small fragment to form π-bond nucleophilic_substitution electrophilic_substitution radical_substitution Nucleophile replaces leaving group Electrophile replaces hydrogen atom on an aromatic ring Radical replaces group within σ-bond rearrangement 1,2-shift radical_rearrangement 1,2-alkyl or hydride shift Radical migrates to different position proton_transfer acid_base_proton_transfer Proton migrates between donor and an acceptor electron_transfer single_electron_transfer Single electron moves from donor to acceptor coordination lewis_acid_base_coordination Lone pair coordinates with an empty orbital radical pericyclic radical_initiation radical_propagation radical_termination radical_coupling Generation of radicals (e.g., by light, heat) Radical continuously generates new radicals Two radicals combine to terminate chain reactions Two radicals form new bond directly (e.g., CC or CN) cycloaddition electrocyclization sigmatropic_rearrangement group_transfer ene_reaction cheletropic_reaction Two π-systems combine to form ring (e.g., DielsAlder) Ring closure or opening via conjugated π-system rotation Migration of σ-bond across π-system (e.g., [3,3]-Claisen) Group is transferred via concerted cyclic pathway Transfer of an allylic hydrogen and formation of new σ-bond Two new bonds formed to the same atom (subset of cycloaddition) Table 5: Reaction Types, Subtypes, and Descriptions"
        },
        {
            "title": "C Weighting",
            "content": "C.1 Weighting Strategy Concretely, each steps raw weight combines: (i) base weight by step type (e.g., pericyclic > rearrangement > elementary proton transfer), (ii) subtype modifier (e.g., sigmatropic or cheletropic steps are up-weighted relative to baseline nucleophilic additions), and (iii) contextual adjustments: Positional adjustment Pposition: terminal steps that mainly \"copy\" product structure are slightly down-weighted; Structural bonus Bspecial: ring closures, key bond-forming events, etc., receive small positive bonuses. 18 The raw weight for step is wraw = clip (cid:16) Wtype Msubtype Pposition + Bspecial, 0.5, 6. (cid:17) , and the final weights are normalized: wi = wraw . This scheme (curated by three domain experts) mirrors how chemists prioritize steps and ensures stability while preserving contrast between trivial and non-trivial reasoning. k=1 wraw (cid:14) (cid:80)N C.2 Weighting Implementation For reproducibility, we summarize in Table 6 the weighting configuration used in our benchmark. The final step weight is computed by combining these factors as described in Section 4.2 (Metrics). Factor Category Values Notes Base type weights Subtype modifiers Pericyclic Rearrangement Radical Electron transfer Substitution Cleavage Addition Elimination Coordination Proton transfer / Dissociation Sigmatropic rearrangement Cheletropic reaction Cycloaddition / Ene Homolytic cleavage Electrophilic substitution Nucleophilic substitution Leaving-group elimination Proton transfer (acid-base) Positional modifier Last step 4.0 3.5 3.0 3.0 2.5 2.5 2.0 2.0 1.5 1. 1.3 1.3 1.2 1.2 1.2 1.1 1.1 0.9 0.9 Highest complexity (cycloadditions, sigmatropic shifts) Includes 1,2and 1,3-shifts Radical initiation, propagation, coupling Singleor multi-electron processes Nucleophilic/electrophilic substitutions Heterolytic/homolytic bond cleavage Nucleophilic/electrophilic additions Deprotonation, leaving-group elimination Metal-ligand binding, weak interactions Elementary steps, down-weighted Extra difficulty Extra difficulty Ring closure / pericyclic steps More complex than heterolytic Context-dependent selectivity Simplest step, discounted Often bookkeeping proton transfers Special bonuses Bspecial Ring closure (cycl\" in subtype) +0.3 Key bond-forming step (addition/substitution) +0.2 Central to overall mechanism Table 6: Weighting configuration for mechanistic steps."
        },
        {
            "title": "D Scaling Algorithm",
            "content": "We scale oMe-Template into oMe-Silver using generative augmentation procedure as the pseudocode outlined below. Algorithm 1 Mechanism Template Up-Scaling Require: Template set oMe-Template = {T1, . . . , Tn} , LLM , Validator (e.g., RDKit) Ensure: Valid mechanism dataset oMe-Silver Daug 1: Initialize Daug 2: for each template do 3: EXTRACTRGROUPS(T ) QUERYLLM(G, T, R) ENUMERATECOMBINATIONS(R, S) for each combination do Tc SUBSTITUTERGROUPS(T, c) if ISVALID(V, Tc) then Daug Daug {Tc} end if 4: 5: 6: 7: 8: 9: 10: Identify reactive sites / substitutable groups Use LLM to propose candidate R-groups Generate all feasible substitution combinations Construct new mechanism instance Add valid mechanism to dataset end for 11: 12: end for 13: return Daug Figure 9: Top 19 R-groups most frequently suggested by Gemini-Pro-2."
        },
        {
            "title": "The formula for",
            "content": ": ="
        },
        {
            "title": "1\nM",
            "content": "M (cid:88) j=1 1(cid:2)RDKit parses ˆIj (cid:3). ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) k=1 1(cid:2)tk = ˆtk (cid:3), where missing alignment at position counts as incorrect."
        },
        {
            "title": "F Alignment Strategy",
            "content": "The alignment strategy is specialized dynamic programming (DP) algorithm designed to align predicted reaction mechanism steps (P) against set of gold-standard steps (G). It significantly improves upon Minimum Edit Distance (MED) and simple match-prioritized scoring by incorporating chemical structural similarity and hierarchical preference for alignment into its scoring function. F.1 Alignment Process and Multi-Criteria Scoring The alignment strategy is shown as the below, Pseudocode for Alignment Strategy Input: - Gold steps = [(type, smiles, weight)]1..N - Predicted steps = [(type, smiles)]1..M - Similarity function sim(, ), threshold τ Output: oMeSResult (Stot, Spart, Alignment, V, L) 1: Initialize DP tables: DP _tot, DP _par, DP _pen, DP _rank, race 2: Fill first row/col with skip penalties (skip_gold / skip_pred) 3: for = 1 do 4: for = 1 do 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: Extract = (g_type, g_smi, w), = (p_type, p_smi) if g_type = p_type then m_tot if canonical(g_smi) = canonical(p_smi) m_par σ(sim(g, p), τ ) action match\" else m_tot, m_par 0 action type_mismatch\" end if Candidates Skip_gold: from (i 1, j) Skip_pred: from (i, 1) Diagonal: from (i 1, 1) with (m_tot, m_par) 15: Choose best candidate by priority: max( DP _tot, DP _par, Rank, DP _pen ) 16: Update DP and Trace at (i, j) end for 17: 18: end for Backtrace: 19: Start from (N, ), follow Trace until (0, 0) 20: Build Alignment sequence (match / mismatch / skip) Metrics: 21: Stot DP _tot[N ][M ] 22: Spart DP _par[N ][M ] 23: fraction of valid predicted SMILES 24: fraction of matches in alignment 25: return (Stot, Spart, Alignment, V, L) Unlike traditional sequence alignment, which maximizes single score or minimizes single cost, oM eS uses four-dimensional, lexicographically ordered score vector at each DP cell DP[i][j] to determine the optimal path: Key = (Stotal, Spartial, Rank, Spenalty) The optimal action (Match, Type Mismatch, Skip Gold, or Skip Pred) is chosen by maximizing this vector in the order presented (i.e., Stotal is the primary objective, followed by Spartial, etc.). The four fundamental actions used in the DP transitions are described in Table 7. Action Description skip_gold skip_pred match type_mismatch The steps align but choose the wrong step types. step present in the Gold sequence was skipped by the Pred sequence. step present in the Pred sequence is extraneous and does not match any Gold step. The steps align and correctly choose the step types Table 7: Description of Alignment Actions Stotal: Strict Match Score (1st Priority): Rewards perfect alignment where the step type is identical and the canonical SMILES are identical. This is the highest reward. Spart: Partial Chemical Match Score (2nd Priority): When Stotal = 0, this metric rewards alignment based on chemical structural similarity. It is calculated using the Tanimoto similarity of Morgan fingerprints, but only if the similarity is greater than threshold τ = 0.60 (Eq. 1). σ(sg, sp) = (cid:40) Tanimoto(sg, sp) 0.0 if Tanimoto(sg, sp) τ otherwise (1) Rank: Explicit Operation Priority (3rd Priority): This ensures the DP prioritizes alignment over skipping when Stotal and Spartial are equal. The ranks are defined as:"
        },
        {
            "title": "Rank",
            "content": "match type_mismatch skip_gold / skip_pred 3 2 1 Spenalty: Non-Match Penalty (4th Priority): minor penalty (1e6) applied to skip and type_mismatch actions. This minimizes the total number of non-perfect alignments when all higher-priority scores are identical. F.2 Edge Cases Demonstrating Robustness of the Alignment Strategy We denote each gold mechanistic step as (Ti, Ii), where Ti represents the reaction type and Ii the intermediate. Predicted steps are (T j). Each alignment result is displayed in two rows: the upper row shows the predicted types , and the lower row shows the alignment label (Match, Type Mismatch, Skip_gold, Skip_pred). Columns labeled / indicate redundant predictions that do not correspond to any gold step. j, Edge Case 1: Long but redundant predictions. In this situation, the model outputs long sequence containing extra but chemically valid substeps, such as protonationdeprotonation or intermediate resonance rearrangements. While these steps are redundant, they remain chemically reasonable. Traditional MED or match-first DP tends to greedily match these extra predictions, misplacing true gold correspondences and therefore underestimating the models performance. Our alignment strategy correctly preserves structural consistency, skipping only redundant steps (Skip_pred) without penalizing chemically correct reasoning. 22 Gold Our Alignment MED / match-first DP / (T1=A, I1=S1) / Skip_pred - - Match Match Skip_pred / - - (T2=B, I2=S2) (T3=C, I3=S3) (T4=D, I4=S4) Match Match Match Match Match Match Skip_pred Skip_pred In this case, our strategy recognizes that the additional (T 3) are redundant but not erroneous, yielding an accurate evaluation of mechanistic reasoning. By contrast, conventional DP misaligns these intermediate steps, lowering both Stotal and Spartial despite chemically valid logic. 1) and (T 3, 1, Edge Case 2: Incomplete but near-correct predictions. Here, the model predicts shorter sequence that captures most intermediates correctly but misclassifies the final step type. For instance, it correctly generates (C, S3) and (C, S5) but predicts (E, S6) instead of the correct (D, S6). This single type misclassification leads to cascade in traditional DP: the alignment path fetches the wrong step, propagating mismatches backward and producing multiple Skip_gold actions. Our hierarchical scoring isolates this terminal type error without disturbing earlier matches, thus preserving earned partial credit."
        },
        {
            "title": "Gold",
            "content": "(A, S1) (B, S2) (C, S3) (E, S4) (C, S5) (D, S6)"
        },
        {
            "title": "Our Alignment",
            "content": "A C"
        },
        {
            "title": "Match Match",
            "content": "A C"
        },
        {
            "title": "Match Match",
            "content": "Match-first DP C"
        },
        {
            "title": "Match Match",
            "content": "- Skip_gold Match Match - Skip_gold Match - Type Mismatch Skip_gold - Type Mismatch Skip_gold Type Mismatch - Skip_gold - Skip_gold This example highlights that even minor terminal error (incorrect type (E, S6)) can distort traditional DP scoring, leading to overcounted skips and underestimation of reasoning quality. Our approach, however, penalizes only the actual type mismatch while retaining the credit for structurally and sequentially correct steps. Takeaways. Across both cases, our alignment method: Accurately distinguishes between chemically redundant and truly erroneous steps, preventing underestimation of valid reasoning. Localizes late-step classification errors, avoiding backward propagation and preserving consistent credit distribution. ensuring more faithful measurement of multi-step mechanistic reasoning accuracy. 23 Extracting High-Similarity Reactions via DRFP To provide contextually relevant examples for in-context learning or to augment reaction datasets, we develop retrieval mechanism that identifies structurally similar reactions from an external chemical reaction database. Our approach leverages DRFP to measure similarity between chemical transformations, enabling efficient retrieval of the most analogous reactions. G.1 Reaction Representation Given chemical reaction with reactants {R1, R2, . . . , Rm} and products {P1, P2, . . . , Pn} represented as SMILES strings, we first construct unified reaction SMILES representation: RXNSMILES = R1.R2. .Rm (cid:125) (cid:124) (cid:123)(cid:122) reactants P1.P2. .Pn (cid:125) (cid:124) (cid:123)(cid:122) products (2) where . concatenates multiple molecules and separates reactants from products. G.2 DRFP Traditional molecular fingerprints encode individual molecules as binary or count vectors based on structural features. For reactions, we employ the DRFP approach (Landrum et al., 2025), which captures the structural changes occurring during chemical transformation. For each structural feature (e.g., circular substructures of varying radii derived from Morgan fingerprints (Rogers and Hahn, 2010)), we compute the feature count in reactants and products: c(R) = c(P ) = (cid:88) i=1 (cid:88) j= fk(Ri), fk(Pj), (3) (4) where fk(M ) denotes the count of feature in molecule . The difference fingerprint is then defined as: = (dk)kK, where dk = c(P ) c(R) . (5) positive value dk > 0 indicates that feature is generated during the reaction, while dk < 0 indicates consumption. This signed integer vector encodes the net structural changes, making it particularly suitable for comparing reaction mechanisms. In practice, we use RDKits CreateDifferenceFingerprintForReaction function, which internally hashes the feature space into fixed-dimensional sparse vector via: = h(k) mod N, (6) where h() is hash function and is the fingerprint dimension. Feature counts are accumulated into corresponding hash buckets, yielding compact representation. G.3 Similarity Computation and Retrieval Given query reaction with fingerprint dq and candidate reaction with fingerprint dc from an external database, we compute their Tanimoto similarity: Sim(dq, dc) = (cid:80) (cid:80) min(dq,k, dc,k) max(dq,k, dc,k) , (7) where the absolute values ensure that similarity focuses on the magnitude of structural changes regardless of sign. RDKits TanimotoSimilarity function handles this computation efficiently for sparse count vectors. Our retrieval algorithm proceeds as follows: 24 1. Database preprocessing: We pre-compute difference fingerprints for all reactions in the external database and cache them as {(di, reactioni)}D i=1. 2. Query fingerprint generation: For query reaction, we compute its difference fingerprint dq using the procedure described above. 3. Similarity scoring: We compute Tanimoto similarity between dq and each cached fingerprint di, filtering out identical reactions (by reaction ID or exact SMILES match). 4. Top-k selection: We rank candidates by decreasing similarity and retrieve the top (typically = 3) most similar reactions. G.4 Implementation Details We implement this retrieval system using RDKit version 2023.09 with Python 3.9. The external database consists of Next standardized reactions from diverse sources, stored in JSONL format with fields for reactant SMILES, product SMILES, and reaction metadata (conditions, mechanisms, etc.). The difference fingerprints are computed using Morgan-based circular environments with default RDKit parameters. To avoid computational redundancy, we cache all database fingerprints in memory upon first access. This fingerprint-based retrieval enables efficient identification of mechanistically similar reactions without requiring explicit reaction classification or rule-based matching, making it well-suited for augmenting language model inputs with relevant chemical knowledge."
        },
        {
            "title": "H Prompts",
            "content": "H.1 Prompt for suggested group Prompt Used for R-group Suggestions You are an expert organic chemist. need {num_suggestions} chemically reasonable substituents for each R-group placeholder. Reaction Template: {template} R-groups to substitute: {, .join(rgroups)} Requirements: 1. Provide valid SMILES strings (no placeholder notation) 2. Include diverse functional groups: alkyl, aryl, heteroatoms, etc. 3. Do not include any (H, CH3, CH2CH3, etc.) in the suggestions, only include instead (C, CC) 4. Ensure chemical stability and synthetic accessibility 5. Include both electron-donating and electron-withdrawing groups 6. If there are already ring systems in the template, do not include any ring systems in the suggestions Format your response as JSON, below is an example { } \"[*:1]\": [\"C\", \"CC\", \"C(C)(C)C\", \"c2ccccc2\", \"CCCC(C)C\", \"CC(C)(C)OC1=CC=C(C=C1)C2=CC=C(OC(C)(C)C)C=C2\", \"C(F)(F)F\"], \"[*:2]\": [\"C\", \"c2ccccc2\", \"CCCCCCCCCC4=CC2=CC=CC=C2C3=CC=CC=C34\", \"COC1=CC(=CC=C1)C2=CC(=CC=C2O[Si](C)(C)C)C3=CC=CC=C3\", \"OC\", \"CC(C)(C)C1=CC(OCCC(C)C)=CC=C1\"] Constraint: Only return the JSON, no other text. 26 H.2 Prompt used for rationale annoation Prompt used for rationale annoation You are an organic chemist. Given reaction JSON (reactants, products, conditions) and step-by-step mechanism list without explanations, your task is to: Add top-level \"description\" (overall reasoning, maximum 90 words), Add \"rationale\" (maximum 40 words) to each mechanism step. You should think like chemist, and for each step, explain why it happens under the given conditions, not just what happens. Output Format: { \"description\": \"overall reasoning\", \"mechanism\": [ {\"step\": 1, \"rationale\": \"rationale1\"}, {\"step\": 2, \"rationale\": \"rationale2\"}, ... ] } Hints: In each steps rationale, include at least one specific chemical reasoning element, such as: Electronic effects: resonance stabilization, inductive effects, conjugation, electronwithdrawing/donating groups. Steric effects: bulky substituents blocking attack. Reaction conditions: acid/base catalysis, solvent polarity, temperature effects. Kinetics vs. thermodynamics: faster pathway vs. more stable product. Leaving group ability and stability of intermediates. Structure analysis: how the intermediate structure approaches the product. Key Constraints: Refer to placeholders as R1 ([*:1]), R2 ([*:2]), R3 ([*:3]); discuss sterics/electronics qualitatively only. Do not add, remove, or reorder steps; the number should exactly match the original mechanism list. Output valid JSON only, and do not include any extra text. Note that the provided hints are designed to follow the logic that human chemists typically adopt when analyzing mechanisms, essentially serving as chemically grounded \"mind map\". This design has proven effective in guiding models to produce results with more meaningful underlying chemical analysis. 27 H.3 Prompt used for mechanism generation Prompt Used for Mechanism Generation You are an expert in organic reaction mechanisms. Task: Given the following information:Reactants (SMILES),Products (SMILES), Reaction Conditions, your task is to write step-by-step organic chemistry reaction mechanism as JSON list. For each step, include: 1. step\" - the step number (starting from 1) 2. type\" - the reaction type, selected exactly from the predefined list below 3. subtype\" - the reaction subtype, selected exactly from the predefined list below 4. intermediate_smiles\" - valid SMILES string representing the intermediate at this step (must be parsable by RDKit) Predefined list of types and subtypes: [ ] {\"type\": \"...\", \"subtype\": \"...\", \"description\":\"...\"}, ... (full content provided in Table 9) Output format: Return only the valid JSON in the format below. Do not include any explanatory text, code blocks, markdown formatting, or any other content before or after the JSON. [ ] {{ \"step\": 1, \"type\": \"\", \"subtype\": \"\", \"intermediate_smiles\": \"\" }}, ... Example: Input: # EXAMPLE INPUT OMITTED FOR BREVITY Expected Output: # EXAMPLE OUTPUT OMITTED FOR BREVITY Input for you: [ ] { } \"reactants_smiles\": \"{ reactants_smiles }\", \"products_smiles\": \"{ products_smiles }\", \"conditions\": \"{ conditions }\" Now, generate your output!"
        },
        {
            "title": "I Error Discussions",
            "content": "Category Subtype Manifestation Cause Analysis Chemical Knowledge Errors Reaction condition misinterpretation Under acidic conditions, the model performs nucleophilic attack or basic deprotonation; under transitionmetal catalysis, fails to include coordination or oxidative addition steps. Electrophilic/nucleophilic center misidentification Valence/charge rule violation Structural/steric constraint neglect Nucleophiles attack incorrect atoms or positions; conjugated systems attacked at non-electron-rich sites (e.g., β-position rather than carbonyl carbon). Generated intermediates contain pentavalent carbon, tetravalent nitrogen (non-ammonium), or trivalent oxygen (non-oxonium); misplaced or imbalanced charges. Failure to enforce anti-periplanar geometry in E2/SN2 reactions; impossible pathways in cyclic systems due to steric hindrance. Models may treat reaction conditions (acid\", base\") as plain text tokens rather than mechanistically decisive entities. Training data often states that reaction occurs under acidic conditions\" but lacks stepwise mechanistic detail linking conditions to reaction pathways. Deficiency in reasoning about electronic effects (inductive, conjugative, steric). Models may rely only on functional group canonical\" reactivity rather than context-specific micro-environment. Represents fundamental violation of chemical rules. As sequence predictors, LLMs lack an internal chemical engine to enforce valence/electron conservation, often producing illogical SMILES patterns. Stems from difficulty in inferring 3D spatial constraints from 1D/2D textual representations (e.g., SMILES). Intermediate stability misjudgment SN1/E1 mechanisms without carbocation rearrangement; generation of unstable intermediates without subsequent rapid conversion. Model fails to assess relative energies of intermediates; rearrangements require non-trivial reasoning beyond pattern matching. Mechanistic and Procedural Errors figureError Step omission or illogical jumps Structural and Formalization Errors Invalid SMILES representation JSON/field mismatches Misclassifies nucleophilic substitution as electrophilic substitution; describes radical reactions using ionic steps; decomposes concerted pericyclic reactions into stepwise ionic events. Missing key rearrangements; skipping intermediates (e.g., jumping from nucleophilic attack directly to product without deprotonation). Failure to recognize fundamental reaction type (e.g., light-initiated radical vs. ionic pathways). Models may have been exposed to simplified mechanistic descriptions or aim to optimize\" step count, reflecting insufficient grasp of mechanistic rigor. Generated SMILES cannot be parsed (e.g., by RDKit) or parse into chemically nonsensical structures (e.g., open-chain rings). LLMs struggle with precise symbolic sequences; minor character errors (brackets, ring indices) break validity. valid contain Outputs not JSON; type/subtype out-ofvocabulary strings; missing required fields. Reflects instruction-following limitations. Models may lose adherence to schema constraints over long generations. Table 8: Taxonomy of error types observed in model-generated mechanisms. Errors are grouped into three broad categories, each with representative subtypes, manifestations, and cause analysis."
        },
        {
            "title": "J Case Studies",
            "content": "J.1 Case Study 1 Reactants: C(N)C(=O)c1ccccc1, CCOC(=O)CC(=O)C Products: CCOC(=O)c1c(C)Ncc1c2ccccc2 Conditions: Acidic medium Step Model-Generated Mechanism Expert Comment 2 3 4 5 6 Type: addition / Subtype: nucleophilic_addition Intermediate: CCOC(=O)C(C(=O)C)C(O)(c1ccccc1)CN Type: elimination / Subtype: leaving_group_elimination Intermediate: CCOC(=O)C(=C(c1ccccc1)CN)C(=O)C Type: addition / Subtype: nucleophilic_addition Intermediate: CCOC(=O)C1=C(c2ccccc2)CNC1(C)O Type: elimination / Subtype: leaving_group_elimination Intermediate: CCOC(=O)C1=C(c2ccccc2)C=NC(C)=C1 Type: proton_transfer / Subtype: acid_base_proton_transfer Intermediate: CCOC(=O)C1=C(C)NC(c2ccccc2)=CC1 Type: elimination / Subtype: leaving_group_elimination Intermediate: CCOC(=O)c1c(C)N=C(c2ccccc2)C=C1 Completely illogical. Both the nucleophilic and electrophilic sites are incorrect, leading to random adduct that bears no mechanistic connection to the product. Structural errors persist. While the reaction type (elimination) is plausible, the intermediate structure diverges significantly from the correct mechanistic pathway. Mechanistic reasoning error. The model incorrectly assumes nitrogen participates as nucleophile again, whereas the reaction should involve the enamine carbon center. Ring system error. The model inexplicably transforms the five-membered ring into six-membered one, which is chemically impossible under the given conditions. The same ring-size error continues. The overall sequence fails to restore the correct conjugation pattern. Although the final structure matches the product, the mechanistic path remains indicating weak chemically unsound, self-correction ability of the model. Table 9: Model-generated mechanism for Case Study 1. Error Analysis. While large language models exhibit clear advantages in handling simple ionic reactions with relatively accurate stepwise reasoning, they remain limited in representing Lewis acid catalysis and complex ring-forming systems. In radical or catalytic cycle reactions, the model struggles to construct coherent, chemically valid pathway and tends to generate only substrateproduct mappings. Moreover, persistent issues include misplaced protonation timing, loss of hydrogen atoms, and poor control of stereochemical details-all of which highlight the current gap between linguistic coherence and genuine chemical reasoning. 30 J.2 Case Study 2 Reactants: COc1cc(Br)c(OC)cc1, COC(Cl)Cl, Cl[Ti](Cl)(Cl)Cl, Cl[Ti](Cl)(Cl)Cl Products: COc1cc(Br)c(OC)cc1(C=O) Conditions: 1. Lewis acid; 2. Aqueous Hydrolysis Step Model-Generated Mechanism Expert Comment 1 2 3 5 6 7 8 9 Type: heterolytic_cleavage Intermediate: CO[C+]Cl Type: electrophilic_substitution Intermediate: COc1c(OC)c(Br)c(C(Cl)OC)c[cH+]1 Type: acid_base_proton_transfer Intermediate: COc1c(OC)c(Br)c(C(Cl)OC)cc1 Type: heterolytic_cleavage Intermediate: COc1c(OC)c(Br)c(C=[O+]C)cc1 Type: nucleophilic_addition Intermediate: COc1c(OC)c(Br)c(C(OC)[OH2+])cc1 Type: acid_base_proton_transfer Intermediate: COc1c(OC)c(Br)c(C(O)OC)cc1 Type: acid_base_proton_transfer Intermediate: COc1c(OC)c(Br)c(C(O)[O+](C)H)cc1 Type: leaving_group_elimination Intermediate: COc1c(OC)c(Br)c(C=[OH+])cc1 Type: acid_base_proton_transfer Intermediate: COc1c(OC)c(Br)c(C=O)cc1 Generated Chemically Invalid SMILES. The model doesnt realize that the hydrogen atom should be put into the middle brackets to form correct SMILES structure. This is mistake that the model frequently make here and there. Incorrect Structure. The model doesnt realize the fact that the electrophilic substitution broke the aromaticity of the ring, thus resulting in the lowercase spelling of benzene ring to be incorrect. Partly Incorrect Step Logic. The proton transfer after an electrophilic addition in an aromatic ring is more often regarded as proton elimination. Correct Correct Correct Generated Chemically Invalid SMILES. The order of carbon and hydrogen atoms are incorrect. Correct Correct Table 10: Model-generated mechanism for Case Study 2. 31 J.3 Case Study Reactants: Oc1ccccc1, CC#N Products: CC(=O)c1ccccc1O Conditions: i. ZnCl2, HCl; ii. H2O Step Model-Generated Mechanism Expert Comment 1 3 4 5 6 7 Type: acid_base_proton_transfer Intermediate: CC##[NH+] Type: electrophilic_substitution Intermediate: Oc1c(C(=[NH+])C)C[cH+]cc1 Type: acid_base_proton_transfer Intermediate: CC(=[NH+])c1ccccc1O Type: nucleophilic_addition Intermediate: CC(O[H2+])c1ccccc1O Type: acid_base_proton_transfer Intermediate: CC(O)c1ccccc1O Type: acid_base_proton_transfer Intermediate: C(O)c1ccccc1O Type: acid_base_proton_transfer Intermediate: CC(=[OH+])c1ccccc1O Type: acid_base_proton_transfer Intermediate: CC(C=O)c1ccccc1O Incorrect Catalysis. The reaction should be initiated by Lewis acid activation, but the model incorrectly uses proton as the catalyst. This is recurring error where the model often ignores the role of Lewis acids. Incorrect Structure. The position of the double bond is wrong. The model fails to capture that the hydroxyl group donates electron density through conjugation, which makes the aromatic ring nucleophilic. Incorrect SMILES. In addition to misrepresenting the Lewis acid as proton, the SMILES structure is invalid as it places an unpaired electron on nitrogen, which is chemically unreasonable. Incorrect SMILES. The nitrogen atom is again assigned an unpaired electron, reflecting repeated formatting error. Incorrect SMILES. The same issue persists with the misrepresentation of charged nitrogen species. Incorrect SMILES. Once again, the model incorrectly places an unpaired electron on nitrogen. Correct. Correct. Table 11: Model-generated mechanism for Case Study 3. 32 J.4 Case Study Reaction Overview. Reactants: CC(C1CC1)=NNS(=O)(=O)c2ccc(C)cc2 Products: C=CC1CC1 Conditions: Base Step Model-Generated Mechanism Expert Comment 1 2 4 5 Type: acid_base_proton_transfer Intermediate: CC(C1CC1)=N[N-]S(=O)(=O) c1ccc(C)cc1 Type: acid_base_proton_transfer Intermediate: [CH2-]C(C1CC1)=N[N-]S(=O)(=O) c1ccc(C)cc1 Type: leaving_group_elimination Intermediate: C=C(C1CC1)N=N Type: leaving_group_elimination Intermediate: C=[C-]C1CC1 Type: acid_base_proton_transfer Intermediate: C=CC1CC1 Correct deprotonation of the hydrazone nitrogen. This step aligns with the gold mechanism. Incorrect second deprotonation: removes an α-hydrogen instead of initiating NN bond cleavage. Mechanistically implausible. Partial match. Correctly identifies diazo formation but misses the ionic character ([N+]=[N-]). Electron flow and charge distribution are wrong. Incorrect elimination: the carbocation intermediate is replaced by carbanion. This reverses the reaction polarity. Produces the correct product but through nonphysical sequence of steps. The mechanism lacks heterolytic cleavage and proper diazonium formation. Table 12: Model-generated mechanism for Case Study 4. Expert Analysis In the gold-standard mechanism, the key step is the heterolytic cleavage of the diazonium intermediate to form carbocation, followed by base-promoted proton elimination. The model, however, omits the cleavage and instead chains multiple proton-transfer and elimination operations. This yields the correct alkene but through chemically implausible pathway, illustrating that the model captures surface-level reactivity patterns without understanding charge redistribution or intermediate stability. 33 J.5 ICL Case Study Reactants: Nc1ccc(C(=O)C(=O)c2ccccc2)cc1 Products: Nc1ccc(C(O)(C(=O)O)c2ccccc2)cc1 Conditions: NaOH, H2O Step Without ICL With ICL (Aligned with Gold) 1 2 3 Type: nucleophilic_addition Intermediate: Nc1ccc(C(=O)C([O-])(O)c2ccccc2)cc1 Type: 1,2-shift Intermediate: Nc1ccc(C(O)(C(=O)[O-])c2ccccc2)cc1 Type: acid_base_proton_transfer Intermediate: Nc1ccc(C(O)(C(=O)O)c2ccccc2)cc1 (missing) Type: nucleophilic_addition Intermediate: Nc1ccc(C(=O)C([O-])(O)c2ccccc2)cc1 Type: 1,2-shift Intermediate: O=C(O)C([O-])(c1ccccc1)c1ccc(N)cc1 Type: acid_base_proton_transfer Intermediate: Nc1ccc(C(O)(C(=O)[O-])c2ccccc2)cc1 Type: acid_base_proton_transfer Intermediate: Nc1ccc(C(O)(C(=O)O)c2ccccc2)cc1 Table 13: case exemplifies how ICL improves (PT denotes proton transfer). Without ICL, the model omits the critical rearrangement step and terminates early after three steps. Expert Analysis. Without ICL, the model halts prematurely and fails to include the second protontransfer step, leaving the mechanism incomplete. With ICL, the model recovers the correct rearrangement pathway and produces all four steps, mirroring the gold-standard mechanism. This example demonstrates that exemplar-guided prompting enhances causal continuity and encourages models to reconstruct multistep reasoning chains consistent with chemical logic."
        },
        {
            "title": "K Results",
            "content": "This section presents the performance outcomes of various large language models on oMeBench under different reasoning and training configurations. We evaluate models across multiple experimental settings, including chain-of-thought prompting (CoT), in-context learning (ICL), and fine-tuning, to examine how these paradigms influence mechanistic reasoning ability. Each subsection reports quantitative metrics covering validity, linguistic correctness, and both total and partial structural alignment, organized by difficulty level or data domain. K.1 CoT results This subsection summarizes model performance under the one-shot chain-of-thought setting, where models are prompted to explicitly reason through each mechanistic step before predicting the next intermediate or transformation. Model Size Overall Easy Medium Hard Stot Spart Stot Spart L Stot Spart Stot Spart Open Source Models (One-shot CoT Setting) Mistral Qwen-3 OLMo-2 7B 4B 13B 55.2 49.9 18.7 10.1 12.6 6. 3.0 2.6 1.1 3.5 3.2 1.1 53.8 54.3 13.5 20.8 14.7 9.2 5.1 1.5 2.9 5.5 2.6 2. 56.0 49.0 21.1 7.3 13.2 6.6 2.7 3.1 0.8 3.3 3.8 0.9 53.0 48.9 12.1 10.4 6.0 5. 1.3 0.9 0.0 1.9 1.1 0.0 Table 14: Performance of Open-Source Models that work under One-shot Chain-of-Thought (CoT) Setting across Difficulty Levels. K.2 In-context learning (ICL) results This subsection reports results from the in-context learning setting, where models are provided with several exemplars of annotated reaction mechanisms before generating predictions for new queries. Model Size Overall Easy Medium Hard Stot Spart Stot Spart Stot Spart Stot Spart GPT-5 GPT-4o o3 Claude-Sonnet-4 Gemini-Pro-2.5 - - - - - DeepSeek-R1 685B GPT-OSS 20B LLaMA-3 Qwen-3 Mistral 8B 4B 7B 94.6 +4.2 78.3 -5.4 92.9 +2.1 92.6 +1.6 95.2 +4.7 90.6 +3.0 79.3 +1.1 77.2 +3.7 75.6 +17.2 63.7 +10.9 66.3 +14.4 44.0 +23.7 66.6 +19.2 60.2 +22.9 73.8 +16.0 68.7 +23.3 43.1 +11.6 44.5 +31.9 50.1 +35.2 38.9 +26.2 46.9 +23.3 23.2 +19.3 45.8 +21.8 40.2 +25.3 54.4 +19.5 45.6 +23.1 23.1 +10.2 19.0 +16.3 24.6 +21.4 16.2 +14. 50.6 +21.5 26.0 +21.0 48.8 +20.7 42.2 +24.3 56.9 +19.0 48.2 +23.2 24.0 +9.8 20.8 +17.5 27.0 +22.8 17.9 +15.7 Hypothetical and SOTA Frontier Models 93.1 +0.7 81.7 -0.9 95.6 +1.0 95.4 +2.4 97.5 +3.0 95.7 +7.3 79.0 -9.4 77.2 +7.3 78.8 +15.7 68.5 +11.9 75.0 +5.1 45.4 +19.4 72.9 +8.4 72.5 +18.2 79.9 +9.4 83.4 +21. 56.4 +13.9 26.9 +18.6 58.1 +21.3 46.9 +18.0 65.7 +9.2 56.0 +17.0 61.9 +10.1 32.7 +22.6 62.0 +14.7 52.9 +19.0 69.4 +8.1 61.5 +19.6 Open Source Models 55.6 +8.0 40.1 +27.1 53.1 +41.0 42.4 +27.8 34.7 +9.6 16.4 +14.9 30.5 +27.9 20.1 +18.4 34.9 +6.9 20.0 +18.5 34.3 +31.7 23.4 +21. Chemistry-specified Models 94.9 +4.9 77.6 -6.2 93.1 +2.5 92.3 +1.4 94.9 +4.6 90.0 +2.1 80.0 +3.0 76.4 +2.2 75.7 +15.3 63.0 +10.5 66.4 +15.7 43.9 +23.3 65.7 +20.1 57.9 +22.1 74.8 +18.2 67.5 +22.4 42.9 +12.6 46.0 +32.8 49.8 +32.3 39.6 +26.8 45.9 +24.3 23.2 +20.0 43.7 +20.4 40.7 +28.0 54.6 +22.2 45.8 +25. 22.6 +10.9 20.3 +17.1 24.9 +21.1 16.3 +14.0 49.3 +22.8 25.5 +21.3 47.0 +20.7 41.8 +26.2 56.8 +21.6 48.0 +24.7 23.6 +11.0 21.8 +17.8 27.0 +21.7 17.6 +15.1 95.3 +5.1 77.4 -7.7 87.7 +1.3 90.7 +2.0 93.1 +7.7 86.9 +4.0 75.6 +5.4 73.7 -1.2 67.0 +26.7 64.0 +15.4 52.3 +20.8 41.9 +32.2 62.6 +30.1 55.2 +34.5 58.4 +12.1 53.6 +32. 25.0 +10.2 41.7 +33.8 47.2 +42.9 29.6 +20.6 38.7 +31.5 17.9 +16.3 39.6 +31.0 26.3 +18.8 35.5 +18.9 29.0 +20.7 8.6 +6.8 15.0 +13.5 14.0 +13.8 10.0 +9.0 41.5 +31.5 18.8 +17.2 39.8 +30.1 28.7 +20.8 38.4 +19.9 29.2 +19.5 9.6 +7.2 15.9 +14.1 15.7 +15.4 11.2 +10.2 OLMo13B 53.5 +36.1 31.1 +25.0 10.9 +10.3 12.3 +11.7 54.9 +32. 33.8 +23.6 12.5 +9.4 14.6 +11.5 53.9 +37.4 32.1 +26.9 10.9 +10. 12.1 +12.1 48.6 +32.4 21.0 +16.1 8.6 +8.6 9.7 +9.7 Score Metrics: (Validity), (Linguistic Correctness), Stot (Total Structural Match), Spart (Partial Structural Match). (Assumed definitions) The second line in each cell shows the change (+/-) from the baseline performance. Table 15: Model Performance (ICL) with Change from Baseline 35 K.3 Fine-tuning results This subsection presents results from fine-tuned variants of selected models, comparing their preand post-tuning performance under both simple and in-context prompting conditions. Model Size Overall In-Domain Out-of-Domain Stot Spart Stot Spart L Stot Spart Before Fine-tuning (Simple Prompt) Qwen-3 LLaMA-3 Mistral OLMo-2 58.5 4B 73.5 8B 7B 52.8 13B 17.4 15.0 12.6 12.7 6. 3.2 2.7 2.0 0.6 4.3 3.3 2.2 0.6 59.8 76.9 54.0 17.4 16.2 12.7 13.0 6.1 3.0 2.6 2.1 0.6 Qwen-3-SFT 4B Qwen-3-CoT-SFT 4B LLaMA-3-LoRA 8B Mistral-LoRA 7B OLMo-2-LoRA 13B After Fine-tuning (Simple Prompt) 85.2 +26.7 82.6 +24.1 65. -8.5 77.8 +25.0 75.7 38.7 +23.7 37.5 +22.5 19.6 +7.0 19. +6.7 17.8 +58.3 +11.7 18.2 +15.0 15.5 +12.3 3. +1.2 6.5 +4.5 6.3 +5.7 20.6 +16.3 17.4 +13.1 4. +1.5 7.6 +5.4 7.4 +6.8 86.8 +27.0 83.3 +23.5 64. -12.2 79.3 +25.3 76.9 43.2 +27.0 42.0 +25.8 21.7 +9.0 21. +8.4 18.7 +59.5 +12.6 20.9 +17.9 18.9 +15.9 4. +1.8 7.9 +5.8 7.4 +6.8 Before Fine-tuning (ICL Baseline) 4.3 2.9 2.3 0.6 23. +19.2 20.6 +16.3 5.3 +2.4 9.2 +6.9 8.3 +7.7 54.7 63.6 49.0 17. 11.4 12.0 11.9 6.1 80.1 +25.4 80.6 +25.9 66.0 +2.4 73.5 +24.5 72. +54.6 24.7 +13.3 24.1 +12.7 13.5 +1.5 13.3 +1.4 15. +8.9 3.8 2.9 1.8 0.6 9.7 +5.9 5.3 +1.5 2.3 -0.6 2. +0.4 2.7 +2.1 4.1 4.3 2.1 0.6 11.5 +7.4 7.8 +3.7 3. -0.9 2.7 +0.6 4.7 +4.1 Qwen-3 LLaMA-3 Mistral OLMo-2 75.2 4B 76.2 8B 7B 64.1 13B 53.5 50.1 44.5 38.9 31. 24.6 19.0 16.2 10.9 27.0 20.8 17.9 12.3 78.4 78.1 67.6 53.5 60.3 52.6 48.1 31.1 30.8 23.7 20.7 10.9 32.9 25.6 22.9 12. 65.8 70.5 53.7 53.5 19.4 20.2 11.3 31.1 6.0 4.8 2.9 10.9 9.2 6.3 2.9 12.3 After Fine-tuning (with ICL) Qwen-3-SFT 4B Qwen-3-CoT-SFT 4B LLaMA-3-LoRA 8B Mistral-LoRA 7B OLMo-2-LoRA 13B 84.4 +9.2 85.6 +10.4 83.2 +7.0 82. +18.4 79.7 +26.2 53.6 +3.5 55.1 +5.0 51.5 +7.0 45. +6.1 39.3 27.4 +2.8 29.2 +4.6 26.8 +7.8 22.2 +6.0 21. 30.6 +3.6 31.0 +4.0 28.6 +7.8 24.8 +6.9 22.8 84. +6.3 86.5 +8.1 86.7 +8.6 84.5 +16.9 82.4 63.3 +3.0 65. +5.2 61.7 +9.1 55.1 +7.0 46.8 33.8 +3.0 36.3 +5.5 33. +9.5 28.5 +7.8 25.6 36.5 +3.6 38.0 +5.1 35.5 +9.9 31. +9.0 27.4 83.7 +17.9 83.0 +17.2 73.0 +2.5 76.4 +22.7 71. +8.2 +10.4 +10.5 +28.9 +15.7 +14. +15.1 +18.1 24.4 +5.0 23.8 +4.4 21.2 +1.0 15. +3.7 16.8 -14.3 8.1 +2.1 7.8 +1.8 7.7 +2.9 3. +0.3 8.2 -2.7 12.9 +3.7 9.9 +0.7 7.9 +1.6 3. +0.5 8.9 -3.4 Score Metrics: (Validity), (Linguistic Correctness), Stot (Total Structural Match), Spart (Partial Structural Match). Table 16: Performance of fine-tuned models under one-shot simple prompt and three-shot ICL prompt 36 Fine-Tuning Configuration and Hyperparameters We fine-tune large language models (LLMs) for chemical reaction mechanism prediction using two complementary parameter-efficient strategies: full supervised fine-tuning (SFT) and Low-Rank Adaptation (LoRA). L.1 Dataset and Preprocessing Both configurations utilize the alpaca_chemical_mechanism_dataset, formatted in the Alpaca instruction-following template (Taori et al., 2023) with three fields: instruction (task description), input (reactants and products in SMILES format), and output (predicted reaction mechanism). To accommodate the structured nature of chemical reactions and their detailed mechanistic descriptions, we set maximum sequence length of Lmax = 6000 tokens, substantially longer than typical instructionfollowing tasks. We employ 16 parallel workers for data preprocessing to efficiently handle the large-scale chemical dataset. L.2 Optimization Hyperparameters Table 17 summarizes the key hyperparameters for both fine-tuning strategies. Table 17: Fine-tuning hyperparameters for full SFT (Qwen3-4B) and LoRA (> 4B)."
        },
        {
            "title": "LoRA",
            "content": "Optimization Learning rate (η) LR scheduler Warmup ratio Number of epochs Batch Configuration Per-device batch size Gradient accumulation steps Effective batch size LoRA-specific LoRA rank (r) LoRA target modules"
        },
        {
            "title": "System\nPrecision\nDeepSpeed stage\nMax sequence length",
            "content": "1.0 105 Cosine 0.1 6 1.0 104 Cosine 0.1 8 1 16 16 1 8 8 8 all BF16 ZeRO-3 6000 BF16 ZeRO-3 6000 Learning Rate and Schedule: We adopt substantially different learning rates for the two strategies. For full SFT, we use conservative learning rate of η = 1 105 to prevent catastrophic forgetting of the models pre-trained chemical and general knowledge. In contrast, LoRA fine-tuning employs η = 1 104, an order of magnitude larger, as only the low-rank adaptation matrices are updated and thus require stronger gradient signals. Both configurations use cosine learning rate schedule with warmup ratio of 0.1, where the learning rate linearly increases from 0 to η during the first 10% of training steps, then follows cosine decay to 0. This schedule stabilizes early training and prevents aggressive weight updates near convergence. Distributed Training and Mixed Precision Both configurations leverage DeepSpeed ZeRO-3 (Rajbhandari et al., 2020) for memory-efficient distributed training."
        }
    ],
    "affiliations": [
        "Genentech",
        "University of Illinois Urbana-Champaign",
        "Wlliam & Mary"
    ]
}