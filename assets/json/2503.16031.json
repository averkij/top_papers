{
    "paper_title": "Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content",
    "authors": [
        "Sai Kartheek Reddy Kasu",
        "Shankar Biradar",
        "Sunil Saumya"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This paper presents the Deceptive Humor Dataset (DHD), a novel resource for studying humor derived from fabricated claims and misinformation. In an era of rampant misinformation, understanding how humor intertwines with deception is essential. DHD consists of humor-infused comments generated from false narratives, incorporating fabricated claims and manipulated information using the ChatGPT-4o model. Each instance is labeled with a Satire Level, ranging from 1 for subtle satire to 3 for high-level satire and classified into five distinct Humor Categories: Dark Humor, Irony, Social Commentary, Wordplay, and Absurdity. The dataset spans multiple languages including English, Telugu, Hindi, Kannada, Tamil, and their code-mixed variants (Te-En, Hi-En, Ka-En, Ta-En), making it a valuable multilingual benchmark. By introducing DHD, we establish a structured foundation for analyzing humor in deceptive contexts, paving the way for a new research direction that explores how humor not only interacts with misinformation but also influences its perception and spread. We establish strong baselines for the proposed dataset, providing a foundation for future research to benchmark and advance deceptive humor detection models."
        },
        {
            "title": "Start",
            "content": "Deceptive Humor: Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content Disclaimer: This paper includes LLM-generated data on fabricated humor that may unintentionally offend readers. Kasu Sai Kartheek Reddy1, Shankar Biradar2, Sunil Saumya1 1IIIT Dharwad, 2MIT Manipal saikartheekreddykasu@gmail.com, shankar.biradar@manipal.edu sunil.saumya@iiitdwd.ac.in"
        },
        {
            "title": "Abstract",
            "content": "This paper presents the Deceptive Humor Dataset (DHD)1, novel resource for studying humor derived from fabricated claims and misinformation. In an era of rampant misinformation, understanding how humor intertwines with deception is essential. DHD consists of humor-infused comments generated from false narratives, incorporating fabricated claims and manipulated information using the ChatGPT-4o model. Each instance is labeled with Satire Level, ranging from 1 for subtle satire to 3 for high-level satire and classified into five distinct Humor Categories: Dark Humor, Irony, Social Commentary, Wordplay, and Absurdity. The dataset spans multiple languages including English, Telugu, Hindi, Kannada, Tamil, and their code-mixed variants (Te-En, Hi-En, KaEn, Ta-En), making it valuable multilingual benchmark. By introducing DHD, we establish structured foundation for analyzing humor in deceptive contexts, paving the way for new research direction that explores how humor not only interacts with misinformation but also influences its perception and spread. We establish strong baselines for the proposed dataset, providing foundation for future research to benchmark and advance deceptive humor detection models."
        },
        {
            "title": "Introduction",
            "content": "Deceptive humor arises from fabricated or misleading claims, often crafted to provoke laughter or satirical commentary on social, political, or cultural issues. Unlike traditional humor, which primarily relies on exaggeration, absurdity, or irony, deceptive humor distorts false narratives to create comedic effect. This form of humor thrives in online spaces, where social media facilitates the rapid spread of jokes and satirical content, making it increasingly difficult to distinguish between harmless comedy and harmful misinformation. The challenge in identifying deceptive humor lies in its subjective nature, what appears humorous to one individual might be offensive or misleading to another, especially if the reader is aware of the falsity of the underlying claim. This duality underscores the urgency and complexity of addressing deceptive humor, as its impact varies based on the audiences awareness and interpretation. In the era of social media, deceptive humor has become an ongoing issue, with significant portion of online content being generated in response to various claims, both real and fabricated. Given the vast accessibility of social platforms, individuals of all demographics, including children, are exposed to such content. The uncritical consumption and unintentional sharing of deceptive humor can have severe societal repercussions. For instance, fabricated claim stating, \"Recently, scientists discovered that steady intake of poison grants superior strength\" may seem humorous at first glance. However, impressionable audiences, such as children or uninformed users, may misinterpret such content, potentially leading to dangerous real-world consequences. This highlights the critical need for robust detection mechanisms to differentiate between deceptive humor and misinformation, ensuring that humor does not inadvertently contribute to spreading harmful narratives. Given the difficulty in manually collecting real-world samples for deceptive humor, we opted for structured data generation approach using the ChatGPT-4o model(Hurst et al., 2024) 3. Identifying deceptive humor in natural discourse is inherently complex, requiring knowledge of both 1DHD: Deceptive Humor Dataset 2*Under Review 3Dataset and other required documents will be publicly available upon acceptance of the paper. 5 2 0 2 0 2 ] . [ 1 1 3 0 6 1 . 3 0 5 2 : r the claim and the commenters intent. Even if user knows the claims validity, they may still misinterpret the humor embedded in the comment. This ambiguity makes curating high-quality dataset from existing social media content challenging. To address this, we systematically generated deceptive humor comments, ensuring control over claim validity and the humorous framing of responses. Moreover, most existing computational models are trained on high-resource languages like English, leaving significant gap in handling regional languages. With its 1.4 billion people and 22 officially recognized languages4, India presents unique opportunity to study multilingual and code-mixed communication. Due to the historical influence of English on Indias education system, people often mix their native languages with English, resulting in code-mixed scripts. Our work focuses on building corpus for deceptive humor detection in English along with four major Indian languages: Telugu, Tamil, Hindi, and Kannada as well as their code-mixed variations. We aim to create more generalizable and inclusive dataset by including multiple languages. Further details on our data generation methodology are elaborated in later sections of this paper. Recognizing the need for dedicated resource to study this phenomenon and to promote the research in this direction, we introduce the Deceptive Humor Dataset (DHD), novel dataset designed to bridge the research gap in understanding how humor contributes to the propagation of misinformation and the challenges in detecting humorous comments generated from fabricated narratives. While prior research has explored related areas, such as Faux Hate, which refers to hateful comments derived from fake narratives(Biradar et al., 2024), deceptive humor presents distinct challenge. Unlike explicit hate speech, which users may hesitate to share, deceptive humor often appears harmless and is readily disseminated, making it more insidious carrier of misinformation. By providing structured dataset and establishing new research problem statement, we aim to facilitate further exploration of this critical issue and encourage the development of novel detection methodologies. 4https://en.wikipedia.org/wiki/Languages_of_India Key Contributions of this work: Deceptive Humor: Novel Intersection of Humor and Misinformation: This work introduces novel research problem that fuses humor detection with misinformation, focusing on humor generated from fabricated narratives. First Multilingual and Code-Mixed Synthetic Benchmark for Fact-Aware Humor: This study presents the first synthetic benchmark corpus designed to analyze fact-aware humor across multiple languages and codemixed contexts, broadening computational humor research. Evaluating DHD with Diverse PLMs: We establish benchmark by evaluating the proposed dataset with widely used opensource models, providing an initial reference point for future research. The remainder of the article is organized as follows: section 2 reviews existing work on humor and misinformation. section 3 details the dataset construction process and baseline methods for deceptive humor detection. section 5 presents and analyzes the experimental findings. Finally, section 7 summarizes key takeaways and outlines future research directions."
        },
        {
            "title": "2 Literature Review",
            "content": "standpoint, Existing research treats humor and misinformation as separate domains, yet their intersection remains largely unexplored. From psychological and social the Interpersonal Humor Deception Model (IHDM) suggests that humor can either reduce self-centered deception and build trust or, if poorly executed, raise suspicions and undermine credibility(Gaspar and Methasani, 2023). Similarly, humor is widely used in advertising to mask deceptive practices, with 73.5% of humorous advertisements containing misleading elements that obscure unethical messaging(Shabbir and Thwaites, 2007). These findings highlight humors dual nature, It can both expose and conceal deception, making it an effective yet ethically complex tool. From computational perspective, humor detection in NLP has largely focused on sarcasm(Joshi et al., 2015), irony(Van Hee et al., 2018), and satire(Rubin et al., 2016), but these studies do not address humor generated from fabricated claims. While humors role in misinformation detection has been acknowledged(Zhou and Zafarani, 2020), prior work treats humor and misinformation as distinct problems, lacking framework to analyze how humor itself can be carrier of deceptive content. Additionally, research on fact-checking and misinformation detection(Thorne et al., 2018; Bhardwaj et al., 2020) has primarily focused on textual veracity, without considering how humor can distort factual claims, making detection even more complex. Current humor datasets(Hossain et al., 2019) focus on linguistic features rather than fact-aware humor, limiting their applicability to deceptive humor detection. To address this, we opt to generate data using state-of-the-art (SOTA) generative models. We experimented with several models, including Gemini, Llama, Claude, and ChatGPT. While Gemini and Llama perform reasonably well in generating English comments, they struggle with Indic languages, often failing to maintain grammatical structure and contextual coherence. Additionally, Claude does not effectively support the generation of humorous content. Even ChatGPT-4o-mini does not meet our expectations in this regard. Based on thorough evaluation of the outputs, we identify ChatGPT-4o as the most effective model due to its superior performance, making it the optimal choice for dataset generation."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we describe the process of selecting fabricated claims and generating the Deceptive Humor Dataset (DHD). Using ChatGPT-4o, we create humor-infused comments across multiple languages, ensuring diversity in satire and linguistic variations. We also highlight the role of synthetic data in advancing AI, emphasizing its importance in training robust models and addressing data scarcity in multilingual settings."
        },
        {
            "title": "3.1 Selection of Fake Claims",
            "content": "The first step in data acquisition involves identifying various topics for data collection. To ensure diversity in the collected data, the authors have selected range of topics, including entertainment, politics, finance, sports, religion, and health. Following the selection of topics, the next step is to identify fake narratives associated with these topics. These fake narratives are systematically scraped from well-known fact-checking websites such as AltNews5, Boom FactCheck6, FactChecker7, and FACTLY8. This approach ensures the reliability and relevance of the data collected for analysis. The selected fake claims are listed in Appendix F."
        },
        {
            "title": "3.2 Generation of Deceptive Humor corpus",
            "content": "Generating humorous comments based on claims presents significant challenges. Humor often blends seamlessly into conversations, making it difficult to discern without deep understanding of both the claim and its surrounding context. 5https://www.altnews.in/ 6https://www.boomlive.in/fact-check 7https://www.factchecker.in/fact-check 8https://factly.in/ System Prompt: You are tasked with generating humorous comments based on fake claims. The comments should be in one of the following languages or code-mixed combinations: Te (Telugu), Hi (Hindi), Ka (Kannada), Ta (Tamil), En (English), Te-En (Telugu-English), Hi-En (Hindi-English), Ka-En (Kannada-English), Ta-En (Tamil-English). Each generated comment must be labeled with the following: Satire Level: value between 1 and 3, where 1 is subtle satire and 3 is high satire. Humor Attribute: Select one from the following categories: Irony Dark Humor Absurdity Wordplay Social Commentary Ensure the comments are complex and human-like, reflecting various humor types and incorporating witty or sharp expressions where appropriate. Prompt: Generate humorous comment based on the following fake claim: <FAKE_CLAIM> The Deceptive Humor Dataset (DHD) is generated using ChatGPT-4o, with carefully structured prompts designed to create humor that feels natural and human-like. To ensure quality and appropriateness, language experts aged above 18, closely monitored the content, making sure it remained engaging without negatively impacting younger audiences. No individuals under 18 are involved in the process, as the dataset is curated with responsible approach to humor. This careful curation is reflected in the prompt design. Figure 1: Flowchart for the DHD Data Generation We enhance data complexity by combining multiple claims and tasking the model to generate comments, producing more nuanced samples. If quality is lacking, we refine it through feedback via instructions or examples to improve human-like text, as shown in the Figure 1. Role of Synthetic Data in Advancing the AI systems: The proposed DHD is synthetically generated using the ChatGPT-4o model. common critique of synthetic data is that pre-trained language models (PLMs) struggle to capture patterns representative of human-generated text. While this argument holds some merit, it is also important to acknowledge that human annotations are influenced by inherent biases shaped by individual mental models(Gautam and Srinath, 2024). The role of synthetic data in AI research has become increasingly significant in recent years. Numerous top institutions, including Hugging Face9, and various companies are actively researching the use of synthetic data and have recently released synthetic data generators10 to support this effort. Notably, the Phi-4 model11 state-of-the-art(SOTA) open model has effectively utilized synthetic data as core component of its training regimen. In light of these advancements, it is evident that 9https://huggingface.co/ 10https://huggingface.co/blog/synthetic-data-generator 11https://huggingface.co/microsoft/phi-4 synthetic data, once point of contention, has emerged as an invaluable tool in the evolution of modern AI systems. Its integration plays pivotal role in improving model generalization, enhancing capabilities, and addressing data limitations. Furthermore, synthetic data offers the added advantage of mitigating biases that may be introduced by human annotators, thereby fostering the development of more robust, unbiased, and versatile AI models. This transformative approach not only expands the scope of AI applications but also ensures greater fairness and reliability in model outcomes. 3.3 Dataset Description The proposed DHD consists of 9,000 synthetically generated humorous comments, carefully curated to ensure linguistic diversity and humor variation. The dataset is split into 7,200 comments for training, 900 for validation, and 900 for testing as shown in Table 1. Each comment is labelled with satire level ranging from 1 to 3, where 1 represents subtle satire and 3 denotes highly exaggerated satire. Additionally, every comment is assigned humor attribute from one of the five predefined categories: Irony, Absurdity, Social Commentary, Dark Humor, and Wordplay. Train Validation Test 900 900 7,200 2,092 3,125 1,983 Statistic Total Samples Satire Level Distribution Low Satire Moderate Satire High Satire Humor Attribute Distribution Irony Absurdity Social Commentary Dark Humor Wordplay 2,180 1,639 1,217 1,101 1,063 251 378 270 196 149 154 131 253 388 259 284 208 142 129 137 Table 1: DHD Distribution key aspect of the DHD is its linguistic diversity. Along with English, it includes comments in four major Indic languages: Telugu, Hindi, Kannada, and Tamil, along with their code-mixed versions (Te-En, Hi-En, Ka-En, Ta-En). This ensures rich and varied dataset that captures the nuances of humor across multiple languages and cultural contexts. The structured labeling enables comprehensive analysis of humor in NLP systems, fostering advancements in computational humor understanding, particularly in multilingual and code-mixed settings. detailed description of the dataset is presented in Table 2. Description of the Labels: Satire Level: This label quantifies the degree of satire in the generated comment. Low Satire (1): The humor is subtle and lightly satirical, often resembling real-world statements with mild twist. Moderate Satire (2): The humor is more evident, incorporating exaggeration and sarcasm while maintaining balance between reality and absurdity. High Satire (3): The humor is strongly exaggerated and overtly satirical, often making use of extreme irony or absurd distortions of reality. Humor Attribute: This label categorizes the type of humor used in the comment. Irony: form of humor where the intended meaning contrasts sharply with the literal meaning, often exposing contradictions or unexpected outcomes. Absurdity: Humor that thrives on exaggeration, illogical scenarios, or unrealistic premises to create an amusing effect. Social Commentary: Humor that critiques, mocks, or highlights societal or cultural issues, often with satirical or thought-provoking angle. Dark Humor: Humor that deals with morbid, taboo, or controversial topics in way that might be unsettling but still amusing. Wordplay: Humor that relies on clever linguistic constructs, including puns, double meanings, and phonetic playfulness."
        },
        {
            "title": "4 Experimental Setup",
            "content": "In this section, we discuss the experimental setup used to evaluate the proposed DHD. The dataset is tested across different model architectures, including Encoder-Only Models, Encoder-Decoder Models, and Large Language Models(Brown et al., 2020) with Zero-Shot, Few-Shot, and QLoRA(Dettmers et al., 2024) fine-tuning. Encoder-Only models: To establish strong baseline results, we evaluate on several transformer-based Models(Vaswani, 2017). BERT(Kenton and Toutanova, 2019) is bidirectional transformer trained using masked language modeling and next sentence prediction. DistilBERT(Sanh, 2019) is distilled version of BERT that is smaller, faster, and lighter, achieving similar performance while being more efficient. mBERT extends BERT to multilingual settings, enabling cross-lingual tasks. XLM-RoBERTa(Conneau, 2019) is large multilingual language model trained on 100 languages, enhancing cross-lingual DeBERTa(He et al., 2020) understanding. improves upon BERT and RoBERTa by using disentangled attention and enhanced mask decoder mechanisms. ALBERT(Lan, 2019) is lightweight model that reduces parameters through cross-layer parameter sharing and factorized embedding parameterization. Lastly, XLNet(Yang, 2019) leverages permutation-based training to address the limitations of BERT, capturing bidirectional context while maintaining autoregressive properties. Encoder-Decoder models: Following the evaluation of encoder-only models, we also assess several transformer-based encoder-decoder models. BART(Lewis, 2019) is denoising autoencoder that combines bidirectional encoder with an autoregressive decoder, excelling in text generation and comprehension tasks. mBART(Liu, 2020) extends BART to multilingual context, pre-trained as sequenceto-sequence denoising autoencoder on large-scale monolingual corpora across multiple languages, making it effective for neural machine translation. T5(Raffel et al., 2020) frames all NLP tasks as text-to-text transformations, enabling unified approach to various tasks such as translation, summarization, and question answering. Large Language Models: After computing the results with Encoder-Only and Encoder-Decoder Models, we evaluated several open-source large language models on the proposed DHD. Google Gemini(Team et al., 2024) is known for its enhanced reasoning abilities, offering high efficiency in processing complex tasks. Meta Llama(Touvron et al., 2023), provides open-source LLMs optimized for diverse NLP applications, with focus on scalability and efficient inference across different hardware platforms. Microsoft Phi-4(Abdin et al., 2024) incorporates synthetic data in its training set, which Language Total Records Train Data English Telugu Hindi Kannada Tamil Telugu-English Hindi-English Kannada-English Tamil-English Validation Data English Telugu Hindi Kannada Tamil Telugu-English Hindi-English Kannada-English Tamil-English Test Data English Telugu Hindi Kannada Tamil Telugu-English Hindi-English Kannada-English Tamil-English 877 819 822 771 725 815 831 768 772 112 110 100 84 88 104 99 108 95 110 117 80 81 100 114 95 115 88 Satire Level 3 2 190 300 264 268 231 194 219 199 227 323 345 386 348 343 345 349 329 357 364 174 172 155 151 276 263 240 188 21 33 38 30 29 23 23 27 27 21 38 23 29 32 26 25 32 27 31 49 40 30 43 49 53 45 37 51 47 32 49 44 41 55 32 60 28 22 24 16 32 23 36 30 52 28 10 20 19 44 29 28 29 Absurdity Dark Humor Irony Social Commentary Wordplay Humor Attribute 243 178 166 203 183 195 122 189 160 38 19 20 18 17 20 11 32 21 32 33 22 22 28 23 14 21 13 147 111 90 95 99 153 137 162 107 23 19 9 10 11 23 12 25 22 20 15 6 15 9 20 13 19 297 321 285 218 238 206 233 175 207 31 48 30 27 34 32 24 17 27 39 43 27 19 44 25 23 36 28 101 162 169 185 143 114 130 110 103 12 23 24 21 16 10 21 14 8 11 18 16 17 13 15 17 16 89 47 112 70 62 147 209 132 195 8 1 17 8 10 19 31 20 17 8 8 9 8 6 31 28 23 16 Table 2: Distribution of Satire Levels and Humor Attributes Across Languages (Appendix provides visualization of these distributions). aids in improving its performance, particularly in mathematical reasoning tasks, by providing more diverse and challenging training scenarios. We evaluated LLMs on the DHD using Zero-Shot and Few-Shot approaches. Zero-Shot required models to make predictions without task-specific examples, relying on pre-trained knowledge, while FewShot provided limited labeled examples for better contextual adaptation. To enhance performance, we fine-tuned the LLMs using QLoRA (Dettmers et al., 2024), which applies low-rank adaptations efficiently. This fine-tuning helped models incorporate domain-specific knowledge and improve taskspecific performance. Details on prompt generation, inputs, and the experimental setup for ZeroShot, Few-Shot, and QLoRA fine-tuning are in Appendix and Appendix D."
        },
        {
            "title": "5 Results and Discussion",
            "content": "In the results for Satire Level Classification, the mBART(Liu, 2020) outperformed other models, while for the Humor attribute, the BERT(Kenton In and Toutanova, 2019) performed better. Zero-Shot and Few-Shot settings, LLMs exhibited bias by disproportionately favoring certain labels while underutilizing others, with some labels receiving little to no representation in predictions, leading to significantly lower scores, as shown in Table 5. To enhance domain knowledge and improve performance, we employed the QLoRA approach(Dettmers et al., 2024), which led to better results than the Zero-Shot and Few-Shot versions. However, even with QLoRAs enhancements, language models still struggle with deceptive humor highly nuanced category requiring contextual and cultural understanding. The subtle and ambiguous nature of deceptive humor makes it difficult to distinguish from other humor types or even non-humorous text, limiting generalization. This highlights the need for further research to develop more robust techniques, given its broader implications in misinformation detection, social media content moderation, and computational humor studies. The detailed error analysis of some challenging samples is discussed in Appendix H, providing further insights into the limitations and failure cases of existing models. and misinformation Our findings reveal fundamental challenge: existing models, which perform well on humor detection classification individually, struggle significantly when dealing with deceptive humor. This is because deceptive humor is not merely about understanding humor; it also requires fact verification and intent recognition, which traditional humor detection models lack. While humor classification has been explored using datasets such as SemEval-2017 Task 6 on Humor Detection (Potash et al., 2017), Humicroedit (Hossain et al., 2019), these datasets primarily focus on linguistic humor rather than humor derived from fabricated claims. Similarly, misinformation detection datasets such as FEVER (Thorne et al., 2018), LIAR (Wang, 2017), and Hostile Dataset(Bhardwaj et al., 2020) focus on textual veracity but do not account for the nuances of humor distorting false narratives. Although synthetic humor datasets have been introduced, such as the Unfun dataset (Horvitz et al., 2024), which edits humorous texts to make them non-humorous for improved humor detection, their primary focus is on humor manipulation rather than humor intertwined with deception. This highlights the increased complexity of deceptive humor, which combines linguistic ambiguity, misinformation, and humor-specific reasoning, making it more challenging task than standard humor detection or fact-checking alone.12 Unlike prior work that treats humor and misinformation as separate problems, our findings highlight how humor itself can actively propagate misinformation, further complicating detection. This introduces fundamentally new challenge that requires both linguistic and factual reasoning, where existing models struggle. Our results in Table 5 confirm this gap even fine-tuned transformer models and LLMs fail to generalize effectively across different humor attributes and satire levels in the proposed DHD.These limitations emphasize the urgent need for novel approaches that integrate both humor understanding and misinformation detection to effectively handle deceptive humor. 12ColBERT Humor Detection Dataset: https: //huggingface.co/datasets/CreativeLang/ColBERT_ Humor_Detection Results Reproducibility: The hyperparameters used in our experiments are presented in Tables Table 3 and Table 4, specifying the configurations for different settings. These details ensure the reproducibility of our results by providing clear reference for the training and evaluation setups. Hyperparameter Value 128 Max Len 16 Batch Size 5 Epochs 3e-5 Learning Rate 0.3 Drop Out Table 3: Hyperparameter settings for Encoder-Only and Encoder-Decoder Models. Hyperparameter LoRA Rank (r) LoRA Alpha LoRA Dropout Target Modules Learning Rate Batch Size Epochs Weight Decay Value 16 64 0.2 {k_proj, q_proj, v_proj} 2e-5 8 3 0.01 Table 4: Hyperparameter settings for the LLM Models."
        },
        {
            "title": "6 Human Evaluation",
            "content": "To evaluate the quality of the synthetically generated dataset, we conducted human evaluation with native speakers and language experts familiar with the fake claims to validate the generated records. Given the nature of our work, we selected evaluators over the age of 18 from diverse regions, as shown in Table 6. Evaluators received clear guidelines and all necessary materials before the evaluation began. To ensure their understanding of the task, we first conducted mock evaluation with small sample set. Based on their performance, we selected the most suitable evaluators. They rated the labels assigned by the ChatGPT-4o model on scale from 0 to 5, where 0 indicated the poorest match and 5 the best. To ensure diverse label representation, we randomly selected 50 records per language, totaling 450 manually validated samples across all languages. As token of appreciation, evaluators Model Satire Level Humor Attribute Parameters Accuracy F1-Score Precision Recall Accuracy F1-Score Precision Recall Encoder-Only BERT(Kenton and Toutanova, 2019) DistilBERT(Sanh, 2019) mBERT XLM-RoBERTa(Conneau, 2019) DeBERTa(He et al., 2020) ALBERT(Lan, 2019) XLNet(Yang, 2019) Encoder-Decoder BART(Lewis, 2019) mBART(Liu, 2020) T5(Raffel et al., 2020) Decoder-Only (Zero-Shot) Gemma(Team et al., 2024) Llama(Touvron et al., 2023) Phi-4(Abdin et al., 2024) Decoder-Only (Few-Shot) Gemma Llama Phi-4 Decoder-Only (QLoRA Fine-Tuned) Gemma Llama Phi-4 49.44 49.44 50.44 49.33 47.89 46.33 50.44 49.11 51.00 46.78 35.78 27.78 42.40 43.11 28.78 28. 34.00 30.00 35.00 46.47 45.60 50.00 48.87 42.52 43.52 46.72 46.44 50.24 43.64 28.76 19.23 20.35 20.08 14.90 14.90 27.00 24.00 29. 49.22 49.42 49.98 48.86 49.07 46.24 50.84 49.34 51.04 46.37 30.03 27.10 20.93 14.37 9.59 9.59 40.00 34.00 34.00 46.19 45.60 50.06 48.93 43.29 43.25 46. 46.09 49.82 43.53 31.46 32.73 32.90 33.33 33.33 33.33 33.00 35.00 34.00 40.44 37.89 36.00 34.44 37.33 38.89 36.78 37.89 36.11 37. 23.44 21.11 15.00 31.56 29.67 14.33 24.00 22.00 26.00 34.73 34.58 35.77 33.70 28.76 33.33 25.49 33.84 35.60 28.48 14.66 16.65 11. 9.59 12.08 5.01 21.00 18.00 12.00 44.37 38.95 37.19 33.95 30.00 39.91 31.41 37.93 36.32 36.02 13.44 20.55 10.33 6.31 10.04 2. 26.00 21.00 35.00 34.42 34.09 35.00 33.60 31.51 33.56 28.52 33.93 35.22 30.50 19.47 20.60 20.22 20.00 19.93 20.00 24.00 21.00 18. 110M 66M 110M 125M 184M 11M 117M 407M 680M 738M 7000M 8000M 14000M 7000M 8000M 14000M 7000M 8000M 14000M Table 5: Baseline Metrics of Models Across Satire Levels and Humor Attributes. The top results are represented in bold, and the second-best results are underlined. were granted free access to GPU resources. This evaluation highlights the alignment between model-generated labels and human judgment, providing valuable insights into dataset quality. The results are summarized in Table 7. Language English Telugu* Hindi* Kannada* Tamil* Education B.Tech B.Tech Gender Male Male PhD Candidate Male PhD Candidate Male Male Country: India B.Tech State Andhra Pradesh Andhra Pradesh Delhi Karnataka Tamil Nadu Table 6: Profile of Human Evaluators Across Languages (* indicates Indic languages along with their code-mixed variants). Language English Telugu Hindi Kannada Tamil Telugu-Eng Hindi-Eng Kannada-Eng Tamil-Eng Avg Satire Score Avg Humor Score Overall Avg. Score 4.14 4.00 3.60 2.80 3.87 4.00 4.00 3.00 4.34 4.17 3.83 3.55 2.95 3.43 4.10 4.00 3.00 4.04 4.21 3.67 3.50 3.00 3.00 4.20 4.00 3.00 3.74 Table 7: Human Evaluation results for Satire, Humor, and Average scores across various language variants. The human evaluation results reveal that English comments receive higher ratings, likely due to the ChatGPT-4o models extensive training on English compared to languages such as Telugu, Hindi, Tamil, and Kannada, particularly in their native scripts. Notably, the code-mixed versions of these languages achieve relatively higher scores than their native-script counterparts. This observation suggests that the model demonstrates greater proficiency in generating Indic languages in codemixed format, reflecting an imbalance in training data coverage and script-specific linguistic capabilities."
        },
        {
            "title": "7 Conclusion and Future work",
            "content": "In this study, we proposed novel research direction at the intersection of misinformation and humorous content, emphasizing how humor can act as major vehicle for spreading misinformation. This approach highlighted the need to better understand the interplay between humor and misinformation, which is often overlooked in existing research. The study underscored the importance of addressing this issue as it plays significant role in shaping public perception and influencing societal narratives. In future work, there is pressing need to focus on detecting and mitigating deceptive humor, which has become increasingly prevalent. Leveraging advanced methods in nlp will be essential for tackling this challenge, given its growing impact on misinformation in contemporary times."
        },
        {
            "title": "References",
            "content": "The proposed work relies on synthetically generated data, which may not fully replicate the complexity and nuance of human-generated text. While synthetic data allows for controlled and scalable dataset creation, it often lacks the inherent unpredictability and cultural context in naturally occurring humor. Additionally, generative models may introduce biases or produce humor that does not always align with human expectations. However, we mitigate these concerns by carefully designing prompts and examples to approximate human-like complexity, ensuring that the dataset remains linguistically diverse and contextually relevant. Despite these limitations, the use of synthetic data has gained significant traction in NLP research, demonstrating its ability to mimic humangenerated text effectively while addressing data scarcity issues. Studies have shown that synthetic data can be comparable to human-labeled data in various NLP tasks, particularly in low-resource language settings(He et al., 2022). Large-scale models have successfully leveraged synthetic datasets to improve generalization and task-specific performance(Veselovsky et al., 2023). Furthermore, recent work has demonstrated that synthetic data can enhance model robustness by introducing controlled variations that mirror real-world complexities(Liu et al., 2024). Given the increasing reliance on LLM-generated datasets across NLP domains, our approach aligns with ongoing efforts to leverage synthetic data."
        },
        {
            "title": "9 Ethical Considerations",
            "content": "The Deceptive Humor Dataset (DHD) is released for academic and research purposes only. It intends to facilitate studies at the intersection of misinformation and humor. Any commercial use, application in real-world misinformation campaigns, or use in generating deceptive content for malicious purposes is strictly prohibited. Researchers utilizing this dataset should ensure ethical compliance and consider potential biases inherent in AI-generated content. Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell Hewett, Mojan Javaheripi, Piero Kauffmann, et al. 2024. Phi-4 technical report. arXiv preprint arXiv:2412.08905. Mohit Bhardwaj, Md Shad Akhtar, Asif Ekbal, Amitava Das, and Tanmoy Chakraborty. 2020. HosarXiv preprint tility detection dataset in hindi. arXiv:2011.03588. Shankar Biradar, Sunil Saumya, and Arun Chauhan. 2024. Faux hate: unravelling the web of fake narratives in spreading hateful stories: multi-label and multi-class dataset in cross-lingual hindi-english code-mixed text. Language Resources and Evaluation, pages 132. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. Conneau. 2019. Unsupervised cross-lingual reparXiv preprint resentation learning at scale. arXiv:1911.02116. Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2024. Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems, 36. Joseph Gaspar and Redona Methasani. 2023. Laughter and lies: Unraveling the intricacies of humor and deception. Current Opinion in Psychology, page 101707. Sanjana Gautam and Mukund Srinath. 2024. Blind spots and biases: Exploring the role of annoarXiv preprint tator cognitive biases in nlp. arXiv:2404.19071. Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. Deberta: Decoding-enhanced arXiv preprint bert with disentangled attention. arXiv:2006.03654. Xuanli He, Islam Nassar, Jamie Kiros, Gholamreza Haffari, and Mohammad Norouzi. 2022. Generate, annotate, and learn: Nlp with synthetic text. Transactions of the Association for Computational Linguistics, 10:826842. Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, and Kathleen McKeown. 2024. Getting serious about humor: Crafting humor datasets with unfunny large language models. arXiv preprint arXiv:2403.00794. Nabil Hossain, John Krumm, and Michael Gamon. 2019. \" president vows to cut< taxes> hair\": Dataset and analysis of creative text editing for humorous headlines. arXiv preprint arXiv:1906.00274. Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. 2024. Gemma: Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295. James Andreas Vlachos, Christos Thorne, Christodoulopoulos, and Arpit Mittal. 2018. Fever: large-scale dataset for fact extraction and verification. arXiv preprint arXiv:1803.05355. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971. Cynthia Van Hee, Els Lefever, and Véronique Hoste. 2018. Semeval-2018 task 3: Irony detection in english tweets. In Proceedings of the 12th international workshop on semantic evaluation, pages 3950. Vaswani. 2017. Attention is all you need. Advances in Neural Information Processing Systems. Veniamin Veselovsky, Manoel Horta Ribeiro, Akhil Arora, Martin Josifoski, Ashton Anderson, and Robert West. 2023. Generating faithful synthetic data with large language models: case study arXiv preprint in computational social science. arXiv:2305.15041. William Yang Wang. 2017. \" liar, liar pants on fire\": new benchmark dataset for fake news detection. arXiv preprint arXiv:1705.00648. Zhilin Yang. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprint arXiv:1906.08237. Xinyi Zhou and Reza Zafarani. 2020. survey of fake news: Fundamental theories, detection methods, and opportunities. ACM Computing Surveys (CSUR), 53(5):140. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Aditya Joshi, Vinita Sharma, and Pushpak Bhattacharyya. 2015. Harnessing context incongruity for sarcasm detection. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 757762. Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of naacL-HLT. Minneapolis, Minnesota. Zhenzhong Lan. 2019. Albert: lite bert for selfsupervised learning of language representations. arXiv preprint arXiv:1909.11942. Mike Lewis. 2019. Bart: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461. Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, Yanzhe Zhang, Jinmeng Rao, Steven Zheng, Daiyi Peng, Diyi Yang, Denny Zhou, et al. 2024. Best practices and lessons learned on synthetic data for language models. arXiv preprint arXiv:2404.07503. Liu. 2020. Multilingual denoising pre-training arXiv preprint for neural machine translation. arXiv:2001.08210. Peter Potash, Alexey Romanov, and Anna Rumshisky. 2017. Semeval-2017 task 6:# hashtagwars: Learning sense of humor. In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval2017), pages 4957. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with unified text-to-text transformer. Journal of Machine Learning Research, 21(140):167. Victoria Rubin, Niall Conroy, Yimin Chen, and Sarah Cornwell. 2016. Fake news or truth? using satirical cues to detect potentially misleading news. In Proceedings of the second workshop on computational approaches to deception detection, pages 717. Sanh. 2019. Distilbert, distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108. Haseeb Shabbir and Des Thwaites. 2007. The use of humor to mask deceptive advertising: Its no laughing matter. Journal of Advertising, 36(2):7585."
        },
        {
            "title": "B Zero Shot Prompts",
            "content": "Zero Shot prompting is used to classify comment based on its humor or satire level, without requiring any labeled examples in the prompt. This approach allows the model to generalize based on the provided categories. B.1 Zero Shot Prompt for Satire Level The following prompt is used to classify the level of satire in comment. The categories are defined as follows: PROMPT = \"Classify the following comment based on the Satire Level. The categories are as follows: 1 refers to Low Satire, 2 refers to Medium Satire, 3 refers to High Satire.\" B.2 Zero Shot Prompt for Humor Attribute The following prompt is used to classify the humor type of comment. The categories are defined as: PROMPT = \"Classify the following comment based on the humor attributes. categories are as follows: 0 refers to Irony, 1 refers to Absurdity, 2 refers to Social Commentary, 3 refers to Dark Humor and 4 refers to Wordplay\" The"
        },
        {
            "title": "C Few Shot Prompts",
            "content": "Few Shot prompting is used when we provide few labeled examples along with the query to help the model understand the context better. It typically results in more accurate predictions, as the model has specific examples to learn from. C.1 Few Shot Prompt for Satire Level The following prompt is for classifying the satire level in comments with the inclusion of example data to provide better insights: PROMPT = \"Classify the following comment based on humor attributes: 1 refers to Low Satire, 2 refers to Medium Satire, 3 refers to High Satire. to get better insights about the data, look at the given examples : Comment: If spitting on food spreads COVID, chefs should get hazard pay upgrade! Given Satire Level: 3\" C.2 Few Shot Prompt for Humor Attribute The following prompt is for classifying the humor attribute in comments, including few examples to improve the models understanding: PROMPT = \"Classify the following comment based on humor attributes: 0 refers to Irony, 1 refers to Absurdity, 2 refers to Social Commentary, 3 refers to Dark Humor and 4 refers to Wordplay to get better insights about the data, look at the given examples : Comment: If spitting on food spreads COVID, chefs should get hazard pay upgrade! Given Humor Attribute: Dark Humor\" QLoRA Approach: Prompt Generation Functions QLoRA is fine-tuning approach for large language models that uses low bit precision, maintaining performance while reducing computational costs. The use of structured prompts in QLoRA helps the model better understand and classify text, improving its ability to handle tasks like humor and satire classification. Below are the key functions and label mappings. D.1 Prompt Generation Functions Training Data Prompt generate_train_prompt(text, label): def generate_train_prompt(text, label): return (f\"Comment: {text} The (Satire Level)/(Humor Attribute) assigned to this comment is {label}, which corresponds to the humor type: {label_mapping[label]}.\") Validation/Test Data Prompt generate_eval_prompt(text): def generate_eval_prompt(text): return f\"Analyze the following comment: {text}\"; D.2 Label Mappings"
        },
        {
            "title": "Label Mapping for Satire Level",
            "content": "label_mapping = { 1: \"Low Satire\", 2: \"Medium Satire\", 3: \"High Satire\", }"
        },
        {
            "title": "Label Mapping for Humor Attribute",
            "content": "label_mapping = { 0: \"Irony\", 1: \"Absurdity\", 2: \"Social Commentary\", 3: \"Dark Humor\", 4: \"Wordplay\" }"
        },
        {
            "title": "E Heatmap Analysis of Satire and Humor Across Languages",
            "content": "Figure 2: Satire Level vs Humor Attribute. The color intensity represents the frequency distribution across datasets. Figure 3: Language Variants vs Humor Attribute. The heatmap highlights humor variations across languages. Figure 4: Language Variants vs Satire Level. The color intensity represents frequency distribution, showing how different languages align with satire levels."
        },
        {
            "title": "F Claims Supporting this Research Work",
            "content": "Claims Supporting this Research Work: World Health Organization (WHO) declares eating meat causes cancer. India has replaced the Indian Rupee with Digital Currency Completely. Muslims are spitting on food to spread COVID-19. Hindu temples in India are being destroyed and replaced with mosques. African immigrants are responsible for rising crime in Europe. The LGBTQ+ community is pushing for legalizing pedophilia. Specific vaccines cause sterility in minority communities. The COVID-19 vaccine turns you into zombie after two years. China is actively exporting fake rice made from plastic to African countries. Salaar had crossover with KGF, both are part of the cinematic universe. Bollywood is spreading anti-hindu sentiments through its movies like Pk, Adipurush and pathan. The Earth Is Flat. Sharks Are Immune to Cancer. Pyramids Were Built by Aliens. NASA confirms 15 days of darkness due to planetary alignment. The Taj Mahal was originally Hindu temple named Tejo Mahalaya. Vaccines contain microchips for surveillance. Muslims in Kerala are forcing non-Muslims to convert to Islam with the help of the government. Chinese companies are secretly building surveillance networks in Indian cities. The Indian government is introducing one-child policy to control the population. Muslim community in India is receiving special treatment in government welfare schemes. Bill Gates created the COVID-19 virus to implant tracking devices via vaccines. Indias government is secretly constructing detention camps for Muslims in Assam. Justice Muralidhar was transferred overnight by the central government due to his critical remarks against the Delhi Police during the Delhi riots. Muslim youth beaten up, detained for urinating on Kumbh banner. 300-year-old St. Josephs Church in Sugnu, Imphal. BJP-supporting extremists had set it on fire. Kukis bombing Meitei areas in Manipur. China spreading coronavirus as biological weapon. Tablighis spreading coronavirus as jihadi propaganda. Migrant workers beaten during the coronavirus lockdown. Farmer protest is sponsored by Khalistan. GPS chip installed in 2000 rupee notes. Wrestler Sakshi Malik being pinned down by cops. AAP offers monetary relief only to Muslim victims of Delhi riots. Shaheen Bagh women getting paid. Posters of Hindu deities burnt during CAA protests. COVID-19 booster shots lead to AIDS. All vaccinated people will die within 2 years. Tablighi Jamaat members roaming naked in an isolation ward. Muslim man threw an Indane gas cylinder on the tracks in Haldwani. Station master at Bahanaga Bazar station is Muslim and fled the accident site. Hindu temple near Bahanaga Bazar station portrayed as mosque, falsely claiming the Muslim community is behind the train accident. RSS training Hindus to entrap Muslim girls. Claims of Dhoni and Kohli donating to the Odisha train accident circulate on social media. Pathan is spreading anti-Hindu sentiment. Adani Group is accused of fraud and stock manipulation by Hindenburg Research. Prabhas dating Anushka Banner was seen in front of the gate of Tihar Jail reading Kejriwal will come again. Adani publicly admitted to paying bribes, suggesting the practice extended to India. Stalins photo displayed at Times Square in New York."
        },
        {
            "title": "G Sample Records of Deceptive Humor",
            "content": "Language Comment Satire Level Humor Attribute En En En En En Te-En Te-En Te-En Te-En Te-En Hi-En Hi-En Hi-En Hi-En Hi-En Ka-En Ka-En Ka-En Ka-En Ka-En Ta-En Ta-En Ta-En Ta-En Ta-En Next up: redefining gravity because someone feels its oppressive. Mosques near stations now double as train wreck centers? Innovative blaming! The Earth is so flat that NASA has been fooling us with Photoshop for decades. Even the beggars now ask, Do you have Paytm, sir? No cash, please! They say sticks and stones break bones, but in lockdown, it was just discipline! So now Khalistan is getting into the protest business. Can book protest for my birthday? Temples ni mosques chesthunnaru anta, next Ramayan ni alochinchi Game of Thrones laga chesthara? Corona ni jihadi tool ga use chesthunaru anta, inkem cheptaru? Wi-Fi lo use chesi live cheyyadam? Arey mamsam tintaru ani cheppi kotha rule pettara WHO? Tablighi Jamaat spreading COVID-19 like its secret mission, script lo plot twist thappa! Bhai, anthem ke jagah Azan bajegi kya ab? Bhai, China ke rice ke saath ek Recycle or Die sticker bhi milega! China ka corona bio weapon? Aur hum lockdown comedy mein atak gaye! Arre bhai, ab roadside vendors bhi bolenge QR lagao ya aage badho! Plastic rice mein agar fiber hai, toh diet ke liye perfect hoga! Dhoni Instagram alli photo haakidre issue complete solve agathe anta! Bill Gates created COVID-19 to implant tracking devices, well, wheres the tracking device for common sense? Digital rupee anta, but bank queue sullu badlu illa yenadre? Gas cylinder throw madi Haldwani summit-anna join agidru anta! Flat earth andre nimma GPS ge flat map kodutha? Bro unga ooru marriage la gift QR code la thaane kudupaanga? World-a kaapatharadhukku virus-a anupa China, evvalavo innovation! Church-ai set pannina history save aaguma? Temple oru creative hub nu solra trend WhatsApp-la! Vaccines-ku microchip install panna? Mari app store-la update varuma? 3 3 2 1 2 2 3 2 1 3 2 3 3 2 3 2 3 1 1 1 2 3 1 1 1 Absurdity Dark Humor Irony Social Commentary Wordplay Absurdity Dark Humor Irony Social Commentary Wordplay Absurdity Dark Humor Irony Social Commentary Wordplay Absurdity Dark Humor Irony Social Commentary Wordplay Absurdity Dark Humor Irony Social Commentary Wordplay Table 8: Deceptive humorous comments across different languages with their corresponding satire levels and humor attributes."
        },
        {
            "title": "H Error Analysis of Model Misclassifications",
            "content": "We analyzed model misclassifications in satire level and humor attributes. The key patterns observed are: Irony misclassified as Social Commentary Example: \"China is exporting plastic ricesave the environment, eat plastic!\" The model interpreted the contradiction as critique rather than irony. Exaggeration mistaken for Dark Humor Example: \"WHO bans meat eating forever to reduce climate change.\" Misclassified due to the serious undertone, despite being wordplay. Absurdity confused with Irony Example: \"Flat Earth believers demand GPS satellites stop lying to them!\" The model failed to distinguish absurdity from sarcasm. Subtle satire labeled as High Satire Example: \"Even beggars now ask, Do you have Paytm, sir?\" Mild satire misinterpreted as extreme. Social Commentary misclassified as Irony Example: \"Farmers protests are birthday package dealpay extra for celebrity endorsement!\" The model overlooked the political critique and labeled it as sarcasm. These errors highlight the difficulty in differentiating between satire intensities and humor attributes, indicating the need for improved contextual understanding and fact-aware to understand and detect the deceptive humor comments."
        }
    ],
    "affiliations": [
        "IIIT Dharwad",
        "MIT Manipal"
    ]
}