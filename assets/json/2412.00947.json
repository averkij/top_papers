{
    "paper_title": "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information",
    "authors": [
        "Ryo Kamoi",
        "Yusen Zhang",
        "Sarkar Snigdha Sarathi Das",
        "Ranran Haoran Zhang",
        "Rui Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Errors in understanding visual information in images (i.e., visual perception errors) remain a major source of mistakes in Large Vision Language Models (LVLMs). While further analysis is essential, there is a deficiency in datasets for evaluating the visual perception of LVLMs. In this work, we introduce VisOnlyQA, a new dataset designed to directly evaluate the visual perception capabilities of LVLMs on questions about geometric and numerical information in scientific figures. Our dataset enables us to analyze the visual perception of LVLMs for fine-grained visual information, independent of other capabilities such as reasoning. The evaluation set of VisOnlyQA includes 1,200 multiple-choice questions in 12 tasks on four categories of figures. We also provide synthetic training data consisting of 70k instances. Our experiments on VisOnlyQA highlight the following findings: (i) 20 LVLMs we evaluate, including GPT-4o and Gemini 1.5 Pro, work poorly on the visual perception tasks in VisOnlyQA, while human performance is nearly perfect. (ii) Fine-tuning on synthetic training data demonstrates the potential for enhancing the visual perception of LVLMs, but observed improvements are limited to certain tasks and specific models. (iii) Stronger language models improve the visual perception of LVLMs. In summary, our experiments suggest that both training data and model architectures should be improved to enhance the visual perception capabilities of LVLMs. The datasets, code, and model responses are provided at https://github.com/psunlpgroup/VisOnlyQA."
        },
        {
            "title": "Start",
            "content": "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information"
        },
        {
            "title": "Sarkar Snigdha Sarathi Das Ranran Haoran Zhang Rui Zhang",
            "content": "Penn State University {ryokamoi, rmz5227}@psu.edu 4 2 0 2 1 ] . [ 1 7 4 9 0 0 . 2 1 4 2 : r a"
        },
        {
            "title": "Errors in understanding visual",
            "content": "information in images (i.e., visual perception errors) remain major source of mistakes in Large Vision Language Models (LVLMs). While further analysis is essential, there is deficiency in datasets for evaluating the visual perception of LVLMs. In this work, we introduce VisOnlyQA, new dataset designed to directly evaluate the visual perception capabilities of LVLMs on questions about geometric and numerical information in scientific figures. Our dataset enables us to analyze the visual perception of LVLMs for fine-grained visual information, independent of other capabilities such as reasoning. The evaluation set of VisOnlyQA includes 1,200 multiple-choice questions in 12 tasks on four categories of figures. We also provide synthetic training data consisting of 70k instances. Our experiments on VisOnlyQA highlight the following findings: (i) 20 LVLMs we evaluate, including GPT-4o and Gemini 1.5 Pro, work poorly on the visual perception tasks in VisOnlyQA, while human performance is nearly perfect. (ii) Fine-tuning on synthetic training data demonstrates the potential for enhancing the visual perception of LVLMs, but observed improvements are limited to certain tasks and specific models. (iii) Stronger language models improve the visual perception of LVLMs. In summary, our experiments suggest that both training data and model architectures should be improved to enhance the visual perception capabilities of LVLMs. The datasets, code, and model responses are provided at https://github. com/psunlpgroup/VisOnlyQA. 1. Introduction Large Vision Language Models (LVLMs) have demonstrated significant advancement across range of challenging multi-modal tasks over the past few years [2, 12, 20, 38, 42, 57]. Understanding visual information in provided figures (i.e., visual perception) is primary capability of LVLMs, enabled by visual encoders and multi-modal trainFigure 1. VisOnlyQA includes questions about geometric or numerical information in images, which directly evaluates the visual perception capabilities of LVLMs. ing [2, 38, 41, 72]. However, despite these advancements, it has been reported that visual perception errors are still major source of mistakes in LVLMs [74, 77]. The visual perception of LVLMs should be further analyzed, as it directly impacts performance in all multi-modal tasks; withDataset SEED-Bench [35] MM-Vet [73] CharXiv [67] MathVista [50] MMMU [74] VisOnlyQA (ours) Required Capabilities Visual Perception Reasoning Knowledge Image Categories Question Categories General Figures General Figures Scene understanding Scene understanding, Math, Commonsense Charts Math, Synthetic Math, Academic, Charts Math, Information extraction Math Academic exams Math, Academic, Charts, 3D Shapes Geometric properties, Information extraction Table 1. Comparison between VisOnlyQA and existing datasets for evaluating LVLMs. VisOnlyQA focuses on evaluating the visual perception capabilities of LVLMs about the detailed geometric and numerical information in scientific figures. Existing datasets for evaluating visual perception often target less detailed understanding of general figures, and existing datasets of scientific figures often evaluate multiple capabilities, including reasoning and knowledge, and cannot directly evaluate visual perception. tures, such as symmetry, which do not require knowledge of chemistry, as in Figure 3. VisOnlyQA addresses the limitations in existing datasets in analyzing the visual perception of LVLMs: (1) The questions in our dataset are designed to directly evaluate visual perception without involving reasoning or knowledge, as in Figure 1. (2) We target scientific figures, not general images, to create objective questions about fine-grained visual information. We evaluate 20 LVLMs and observe that state-of-theart LVLMs, including GPT-4o and Gemini 1.5 Pro, work poorly on VisOnlyQA (51.4% and 54.2% in accuracy on the Real split, 4.1), while human performance is nearly perfect (93.5%), as in Figure 2. We also manually analyze the outputs from the LVLMs and observe that most of their mistakes on VisOnlyQA are visual perception errors, which is consistent with our claim that this dataset is for evaluating visual perception, independent from other capabilities like reasoning (4.2). Our observations indicate that existing LVLMs still have weak visual perception capabilities. Under the hypothesis that the current training datasets for LVLMs do not include sufficient cases that require detailed visual perception, we evaluate LVLMs fine-tuned on our training data specifically designed to improve visual perception (4.3). We observe that fine-tuning largely improves performance on few tasks, indicating that the lack of training data is part of the reason for the poor visual perception of the current LVLMs. However, fine-tuning does not always improve performance, and both task properties and model architectures largely influence the visual perception capabilities of LVLMs, even when fine-tuning data is available. Specifically, we observe that larger language models improve the performance of LVLMs on VisOnlyQA when using the same visual encoders, although our dataset evaluates visual perception (4.4). This result suggests that language models play an important role in processing visual information encoded by visual encoders and influence the visual perception capabilities of LVLMs. In summary, our experiments on VisOnlyQA reveal that LVLMs still do not have strong visual perception capabiliFigure 2. Performance of LVLMs on VisOnlyQA in accuracy. LVLMs perform poorly on VisOnlyQA, while human performance is nearly perfect. Table 4 provides detailed results. out correct understanding of visual information in images, they cannot perform downstream tasks effectively. However, as in Table 1, there is lack of datasets for directly evaluating the visual perception capabilities of LVLMs on fine-grained visual information. (1a) Recent popular datasets for evaluating LVLMs, such as MMMU [74] and MathVista [50], focus less on visual perception and target tasks that require expert-level reasoning and knowledge. In addition, (1b) the performance metrics on these datasets are affected by multiple capabilities and do not allow for direct evaluation of visual perception. (2) While there also exist datasets designed for evaluating the visual perception of LVLMs [4, 21, 24, 35], they often target relatively less fine-grained visual information, such as scene understanding. In this work, we propose the VisOnlyQA dataset, which is designed for directly evaluating and analyzing the visual perception capabilities of LVLMs on questions about detailed visual information in scientific images. VisOnlyQA consists of questions about geometric and numerical information in diverse scientific figures, including geometric shapes, chemical structures, charts, and 3D shapes. For example, questions for geometric shapes ask about shapes, relative lengths, or angles, and questions for chemical figures are about the geometric properties of chemical struc2 Figure 3. Examples from VisOnlyQA and responses from LVLMs. Even state-of-the-art LVLMs often cannot correctly answer visual questions in VisOnlyQA. Questions are abbreviated from the original data. Refer to Appendix for full examples. ties, and we need to improve both training data and model architectures to enhance their visual perception. and do not require perceiving details in visual contexts. 2. Related Work Large Vision Language Models. Recent LVLMs often consist of vision transformers (ViT) [14] and large language models [56, 60], which are jointly trained on vision language tasks such as image captioning and visual question answering [2, 38, 41, 72]. Powered by the multi-modal pre-training on transformers, various open source [5, 11 13, 41, 42, 55, 71, 80] and proprietary [3, 20, 57] LVLMs have been developed in recent years. Several studies also propose models for specific applications, such as mathematical reasoning [78], chart understanding [40, 52], medical images [36], and text-rich image understanding [79]. Benchmarks for Multi-modal Reasoning on Scientific Figures. Various datasets that include questions about scientific figures have been proposed in the domains of mathematical reasoning [7, 8, 23, 46, 50], chart understanding [28, 51, 54], and academic exams [48, 49, 74]. Although they are popular benchmarks for recent LVLMs [3, 57, 59], questions in those datasets often require expert-level reasoning and knowledge, less focusing on visual perception. Moreover, recent studies [75, 77] point out that many questions in recent datasets provide too much information in text Benchmarks for Visual Perception Capabilities. Various datasets have been proposed to evaluate the visual perception capabilities of LVLMs on general figures. Several datasets target evaluating LVLMs on specific visual perception tasks, such as OCR [9, 43, 64], depth estimation [18], and counting [26, 65]. However, popular datasets for evaluating visual perception on general images [4, 16, 21, 24, 35, 44, 70] often evaluate relatively less fine-grained understanding of visual information in images, such as overall scene understanding. This is potentially due to the difficulty of creating questions about detailed information on general images. In this work, we target scientific and synthetic figures because they allow us to annotate objective questions about detailed visual information. Several studies have also evaluated the visual perception of LVLMs on scientific figures. CharXiv [67] includes questions for evaluating the perception capabilities on charts. However, it often targets relatively easy tasks, such as What is its title. HallusionBench [22] shows that LVLMs exhibit poor visual perception of misleading figures such as illusive geometric shapes. Our work, in contrast, focuses on images and questions from more natural distribution. Fu et al. [17] evaluate visual perception by assessing the performance gaps when providing figures and text that include identical information. Our dataset provides more direct way to evaluate Triangle Quadrilateral Length Angle Area Diameter Shape (s) Shape (m) Extraction Intersection Size Angle Geometry Chemistry Charts 3D Eval-Real Eval-Synthetic Train (Synthetic) 50 100 10k 50 100 10k 50 100 10k 50 100 10k 50 100 10k 50 50 Answer Format True/False True/False True/False 5 options 5 options 5 options True/False 50 Select Multiple 50 50 10k 100 10k 5 options True/False 3 options 5 options Total 500 700 70k Table 2. Dataset Statistics of VisOnlyQA. VisOnlyQA-Eval-Real includes figures in existing datasets and human-annotated questions. VisOnlyQA-Eval-Synthetic and VisOnlyQA-Train comprise synthetic figures and automatically generated questions. # Points # Lines # Circles"
        },
        {
            "title": "Real",
            "content": "5.8 ( 2.2) 0.2 ( 0.4) Synthetic 9.3 ( 3.2) 10.6 ( 4.5) 0.4 ( 0.5) 5.0 ( 1.3) Table 3. Average number ( standard deviation) of points, lines, circles in geometric shapes in VisOnlyQA. visual perception. There also exist datasets that use synthetic figures to evaluate the visual perception of LVLMs on tasks including visual question answering [4, 33, 47, 76], chart understanding [29, 30], visual reasoning [62], mathematical reasoning [46], diagram understanding [19], 3D object understanding [27, 31, 39], and color distinction [25]. 3. VisOnlyQA Dataset We introduce VisOnlyQA, new dataset designed to directly evaluate the visual perception capabilities of LVLMs on questions about the geometric and numerical information of scientific figures. Each instance of VisOnlyQA consists of figure, multiple-choice question, and answer label. As in Table 2 and Figure 3, VisOnlyQA includes 12 subtasks on figures in four categories: geometric shapes, chemical structures, charts, and 3D shapes. 3.1. Motivation Visual perception errors are still major source of mistakes in LVLMs [74, 77]. However, there is lack of datasets for analyzing the visual perception capabilities of LVLMs, as in Figure 1 and Table 1. Popular datasets for evaluating recent LVLMs often include tasks that require multiple capabilities, such as reasoning and knowledge [50, 74]. (1a) They put less focus on visual perception and (1b) cannot directly evaluate visual perception independent from other capabilities. (2) While there exist datasets designed for evaluating visual perception [4, 21, 24, 35], they often target an understanding of less fine-grained visual information on general images, such as scene understanding. We introduce VisOnlyQA to directly evaluate the visual perception capabilities of LVLMs in detail. For this purpose, we target questions about geometric and numerical information in scientific and synthetic figures. This approach 4 enables us to (1) avoid questions that demand other capabilities, such as reasoning and knowledge, allowing for direct assessment of visual perception, and (2) design objective questions about fine-grained visual information. 3.2. Sources of Figures VisOnlyQA includes two types of figures: Real and Synthetic. The Real figures are from existing datasets. We use figures in existing popular datasets to evaluate whether LVLMs truly understand images in those datasets. It also ensures that images are from natural distributions and not adversarially designed. The Synthetic figures are automatically generated. The primary purpose of synthetic figures is to provide large-scale training data to analyze finetuned models. In addition, they ensure that there is no bias caused by human annotations because both images and questions are automatically generated. Real Figures. We use figures from popular datasets in three domains: geometric shapes in MathVista [50], which includes Geometry3K [46], GeoQA+ [6], GEOS [61], and UniGeo [8], chemistry figures in MMMU [74], and charts in ChartQA [51] and CharXiv [67]. Synthetic Figures. For geometric shapes, we create new dataset, SyntheticGeometry, by generating geometric shapes by writing Python scripts based on an open source project [34] reproducing AlphaGeometry [63]. For 3D shapes, we use CLEVR [27] and SuperCLEVR [39]. 3.3. Questions For Real Figures Human Annotation. We manually annotate questions and answers for ten sub-tasks about the Real figures. We provide question templates and instructions to annotators, and each question-answer pair is annotated by one annotator. The annotators are PhD students specializing in natural language processing. For Synthetic Figures Synthetic Questions. We generate synthetic questions using the metadata of the synthetic figures and question templates, as in Figure 4. For geometric shapes, we use the metadata in SyntheticGeometry, including the positions of points and lines. We write Python scripts to calculate geometric information Figure 4. Construction process of synthetic images and questions in VisOnlyQA-Eval-Synthetic and VisOnlyQA-Train. This process does not involve language models and uses precise metadata, guaranteeing the correctness of generated question-answer pairs. length, angle, area) from of geometric shapes (shapes, the metadata and generate question-answer pairs for five tasks. For 3D shapes, we write Python scripts to generate question-answer pairs about the relative sizes of objects in CLEVR (3D-Size) and angles between objects in SuperCLEVR (3D-Angle) using the metadata in CLEVR (positions and sizes) and SuperCLEVR (positions and angles). 3.4. Data Split VisOnlyQA includes three splits: Eval-Real, EvalSynthetic, and Train. Eval-Real includes 500 instances for ten sub-tasks in three categories of figures from existing datasets (geometry, chemistry, and charts). Eval-Synthetic and Train include 700 and 70k instances for seven sub-tasks in two categories of synthetic figures (geometry and 3D). 3.5. Data Analysis Geometric Shapes. Table 3 shows statistics of geometric shapes in VisOnlyQA. For Real figures, we manually annotate 24 figures to get the statistics. For Synthetic figures, we calculate the statistics of all images using the metadata. Geometric shapes in the Synthetic data include more points, lines, and circles, with larger standard deviations, suggesting that they are more complex and diverse. Label Distribution. To ensure that the labels in our dataset are balanced, we instructed the annotators to make an equal number of questions for each option and add negative version of the questions for all true or false questions (e.g., There is triangle ABC in this figure and There is no triangle ABC in this figure). Finally, we shuffled the options to remove biases caused by the order of the options. Human Performance. To verify the annotation quality and evaluate human performance, we provide randomly sampled questions to three new annotators (300 instances in total) for the Real split and two new annotators (140 instances in total) for the Synthetic split. The average human performance is 93.5% and 95.0% in accuracy, as in Table 4a, showing that the dataset quality is high and the tasks in VisOnlyQA are easy and unambiguous for humans. 4. Experiments We evaluate 20 open-source and proprietary LVLMs and five fine-tuned LVLMs on VisOnlyQA. Our experiments aim to answer the following research questions: RQ1: Do existing LVLMs have strong visual perception capabilities? (4.1) RQ2: Does VisOnlyQA directly evaluate visual perception, independent of other capabilities? (4.2) RQ3: Which factors should we improve to enhance the visual perception of LVLMs? (4.3) RQ4: Do language models of LVLMs influence their visual perception capabilities? (4.4) Models: We evaluate 20 LVLMs in 9 model families, including 15 open-source models: Phi-3.5-Vision [1, 55], LLaVA-Next (8B, 34B) [37], Llama 3.2-Vision (11B, 90B) [45, 53], Molmo (7B-D, 72B) [13], Qwen2-VL (2B, 7B, 72B) [66], InternVL2 (4B, 8B, 26B, 40B, 76B) [11, 12, 59]; and 5 proprietary models: Claude 3.5 Sonnet [3], GPT-4o-mini, GPT-4o [5658], and Gemini-1.5 Flash and Pro [20]. Details are in Appendix A. Prompts: We evaluate two types of zero-shot prompts: with and without chain-of-thought reasoning [32, 68]. Full prompts are in Appendix B. 4.1. LVLMs Perform Poorly on VisOnlyQA Table 4 shows the accuracies of LVLMs on Eval-Real and Eval-Synthetic without chain-of-thought reasoning. The performance of LVLMs is far from perfect on all tasks, with Average 33.6 36.0 34.2 35.8 34.6 39.0 33.8 41.2 32.8 38.8 46.0 37.2 41.6 43.4 43.4 49.0 44.4 43.0 51.4 49.2 54.2 93.5 Triangle Quadrilateral Diameter Length Angle Area Shape (s) Shape (m) Extraction Intersection Geometry Chemistry Charts Random Phi-3.5-vision LLaVA-Next 8B LLaVA-Next 34B Llama 3.2 11B Llama 3.2 90B MolMo 7B-D MolMo 72B Qwen2-VL-2B Qwen2-VL-7B Qwen2-VL-72B InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-40B InternVL2-76B Claude 3.5 Sonnet GPT-4o-mini GPT-4o Gemini 1.5 Flash Gemini 1.5 Pro Human 50.0 48.0 50.0 54.0 50.0 46.0 56.0 48.0 46.0 52.0 46.0 50.0 50.0 48.0 50.0 48.0 54.0 46.0 60.0 54.0 48. 96.7 50.0 54.0 50.0 50.0 52.0 44.0 46.0 52.0 52.0 56.0 60.0 46.0 38.0 44.0 46.0 48.0 46.0 60.0 48.0 50.0 58.0 90.0 20. 22.0 20.0 24.0 18.0 22.0 22.0 26.0 6.0 16.0 24.0 24.0 30.0 30.0 36.0 34.0 22.0 26.0 30.0 24.0 32.0 93.3 20.0 16.0 18.0 20.0 18.0 28.0 6.0 34.0 20.0 22.0 30.0 18.0 34.0 32.0 32.0 38.0 20.0 22.0 40.0 32.0 46. 93.3 20.0 24.0 32.0 28.0 38.0 30.0 20.0 26.0 32.0 34.0 32.0 18.0 28.0 30.0 34.0 46.0 32.0 32.0 40.0 46.0 52.0 86.7 50. 50.0 50.0 50.0 46.0 52.0 60.0 50.0 48.0 50.0 66.0 48.0 58.0 58.0 58.0 60.0 62.0 58.0 72.0 60.0 64.0 100.0 50.0 54.0 42.0 34.0 34.0 60.0 40.0 48.0 38.0 46.0 56.0 54.0 50.0 58.0 28.0 60.0 52.0 58.0 72.0 68.0 62. 93.3 (a) Accuracy on VisOnlyQA-Eval-Real. Triangle Quadrilateral Length Angle Area Geometry Random Phi-3.5-vision LLaVA-Next 8B LLaVA-Next 34B Llama 3.2 11B Llama 3.2 90B MolMo 7B-D MolMo 72B Qwen2-VL-2B Qwen2-VL-7B Qwen2-VL-72B InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-40B InternVL2-76B Claude 3.5 Sonnet GPT-4o-mini GPT-4o Gemini 1.5 Flash Gemini 1.5 Pro Human 50.0 54.0 50.0 51.0 54.0 61.0 49.0 51.0 50.0 58.0 51.0 50.0 51.0 51.0 51.0 52.0 61.0 60.0 66.0 54.0 54.0 95.0 50.0 55.0 50.0 50.0 52.0 56.0 56.0 55.0 50.0 59.0 56.0 51.0 57.0 53.0 54.0 51. 63.0 51.0 56.0 51.0 57.0 95.0 20.0 15.0 17.0 25.0 31.0 12.0 22.0 23.0 31.0 24.0 33.0 21.0 21.0 30.0 30.0 29.0 33.0 21.0 25.0 29.0 34.0 95. 20.0 22.0 21.0 24.0 21.0 16.0 20.0 22.0 23.0 18.0 21.0 24.0 17.0 23.0 23.0 18.0 20.0 20.0 17.0 21.0 21.0 90.0 20.0 21.0 19.0 20.0 21.0 20.0 14.0 18.0 20.0 22.0 26.0 18.0 23.0 21.0 21.0 22. 34.0 18.0 26.0 19.0 40.0 95.0 (b) Accuracy on VisOnlyQA-Eval-Synthetic. 6.2 10.0 4.0 10.0 8.0 20.0 12.0 30.0 12.0 16.0 36.0 16.0 22.0 28.0 30.0 36.0 40.0 32.0 50.0 42.0 52. 93.0 Size 33.3 39.0 26.0 48.0 32.0 45.0 29.0 50.0 38.0 58.0 76.0 57.0 46.0 72.0 69.0 84.0 62.0 27.0 60.0 60.0 69.0 100. 20.0 32.0 26.0 38.0 32.0 44.0 30.0 48.0 32.0 42.0 60.0 44.0 50.0 54.0 58.0 66.0 64.0 40.0 48.0 58.0 70.0 93.3 50.0 50.0 50.0 50.0 50.0 44.0 46.0 50.0 42.0 54.0 50.0 54.0 56.0 52.0 62.0 54. 52.0 56.0 54.0 58.0 58.0 95.0 3D Average Angle 20. 20.0 19.0 32.0 21.0 26.0 27.0 27.0 23.0 21.0 27.0 18.0 30.0 25.0 25.0 27.0 22.0 23.0 23.0 21.0 22.0 95.0 30.5 32.3 28.9 35.7 33.1 33.7 31.0 35.1 33.6 37.1 41.4 34.1 35.0 39.3 39.0 40.4 42.1 31.4 39.0 36.4 42. 95.0 Table 4. Accuracy of LVLMs on VisOnlyQA-Eval with no chain-of-thought reasoning. All LVLMs perform much worse than humans and are comparable to or worse than random performance on many visual perception tasks. the best average accuracies of 54.2% and 42.4% by Gemini 1.5 Pro on the Real and Synthetic splits, while human performance is nearly perfect (93.5% and 95.0%). This result indicates that existing LVLMs still do not have strong visual perception capabilities to understand geometric and numerical information in scientific images. Specifically, even large models perform near-randomly as Geometry-Triangle, Chartson tasks, Geometry-Quadrilateral, some such and Intersection in the Real split, as well as GeometryAngle and 3D-Angle in the Synthetic split. Appendix includes examples of model responses. 4.2. VisOnlyQA Evaluates Visual Perception. To verify our claim that VisOnlyQA directly evaluates visual perception independent of other capabilities, we analyze chain-of-thought reasoning generated by LVLMs. Figure 5. improve performance. Table 9 provides further results. Improvement by chain-of-thought reasoning on VisOnlyQA-Eval-Real in accuracy. Chain-of-thought does not constantly Error Analysis in Chain-of-Thought Reasoning. Chainof-thought reasoning does not consistently improve performance on our dataset but can provide clues to analyzing why LVLMs make mistakes. We manually annotate errors in chain-of-thought reasoning by six models on VisOnlyQA-Eval-Real and provide the results in Figure 6. We manually annotate error categories for 250 responses in total (50 responses for each model). We classify their errors in chain-of-thought into the following categories. Refer to Appendix for details and examples. Question Understanding Error: LVLMs understand questions incorrectly or do not follow instructions. Visual Perception Error: LVLMs do not correctly perceive visual information in figures. Reasoning Error: Reasoning includes mistakes. Minor Problems in Reasoning: Reasoning does not necessarily include mistakes but is insufficient or redundant. We observe that almost all errors in our dataset are caused by visual perception errors, verifying that our dataset directly evaluates visual perception. Specifically, it shows that errors made by Gemini 1.5 Pro almost do not involve anything other than visual perception errors, indicating that VisOnlyQA will be able to completely independently evaluate the visual perception capabilities of future models stronger than Gemini 1.5 Pro. However, at the same time, we need to be careful about comparing the performances of weaker LVLMs on our dataset, as our results indicate that up to 10% of their mistakes may not involve visual perception errors. 4.3. Fine-tuning Does Not Always Improve Visual"
        },
        {
            "title": "Perception of LVLMs",
            "content": "Motivation and Hypothesis. We hypothesize that the current LVLMs have weak visual perception capabilities because the training data of current LVLMs do not include sufficient amount of data that requires detailed visual perception. To verify this hypothesis, we evaluate LVLMs finetuned on VisOnlyQA-Train. Settings. We fine-tune InternVL2 (4B, 8B) [12, 59], Qwen2-VL (2B, 7B) [66], and Phi-3.5-Vision [1, 55] on Figure 6. Errors in chain-of-thought reasoning by LVLMs on VisOnlyQA-Eval-Real. Almost all errors are visual perception errors, verifying that our dataset directly evaluates visual perception. We manually annotate the error categories. Each response can include multiple categories of errors. Chain-of-Thought Does Not Consistently Improve Performance. Figure 5 shows performance improvement by using chain-of-thought reasoning, indicating that chain-ofthought does not consistently improve the performance of LVLMs on VisOnlyQA-Eval-Real and harms the performance in some cases. This result differs from observations on existing datasets for vision-language reasoning tasks, where chain-of-thought largely improves the performance of LVLMs [10, 69, 77]. This result is consistent with our claim that our dataset directly evaluates the visual perception capabilities and does not require reasoning. 7 Figure 7. Accuracy after fine-tuning on VisOnlyQA-Train. We evaluate the fine-tuned models on VisOnlyQA-Eval-Synthetic, which is generated from the same distribution as the train data, and VisOnlyQA-Eval-Real, which includes images from different distributions. The numbers above the bars represent the improvements from the original models. More details are in Table 10. each task in VisOnlyQA-Train (7 tasks in total) and evaluate on Eval-Synthetic (in-distribution; figures from the same distribution as the Train data) and Eval-Real (outof-distribution). To evaluate the maximum possible performance, we fine-tune each model in single-task setting on 10k training data. In total, we fine-tune seven different models independently for each LVLM. We use prompts without chain-of-thought. Refer to Appendix for detailed settings. Improvement by Fine-tuning Depends on Tasks. Figure 7 shows that fine-tuning often improves performance on VisOnlyQA, especially on in-distribution (Synthetic) data. Specifically, all models achieve near-perfect performance in 3D-Size after fine-tuning, and InternVL2-8B and Qwen2-VL-7B show large improvement even on the out-of-distribution (Real) figures in Geometry-Length. This result partially verifies our hypothesis that training data for existing LVLMs are insufficient and indicates that our approach of using synthetic training data has the potential to improve the visual perception of LVLMs. However, fine-tuning almost does not improve performance even on the in-distribution (Synthetic) data in 3DAngle on all models we evaluate. In addition, the improvement on the in-distribution (Synthetic) figures do not generalize well to the out-of-distribution (Real) figures on Geometry-Angle and Geometry-Area. This result indicates that fine-tuning does not always improve visual perception, depending on the properties of target tasks. Performance of Fine-tuned Models Depends on Model Sizes. We also observe that larger models often work better even after fine-tuning; InternVL2-8B and Qwen2-VL7B perform better than smaller models in GeometryLength and Geometry-Area. This result suggests that model architectures largely influence visual perception, even when fine-tuning datasets for target tasks are available."
        },
        {
            "title": "Original",
            "content": "Fine-tuned"
        },
        {
            "title": "Real Synthetic Real Synthetic",
            "content": "InternVL2-4B 304M 3.8B 36.8 InternVL2-8B 304M 7.7B 41.0 Qwen2-VL-2B 675M 1.5B 32.1 Qwen2-VL-7B 675M 7.6B 36.0 34.1 35.0 33.6 37.1 43.6 53.2 42.0 46. 57.7 64.6 54.6 65.0 Table 5. Vision and language models of InternVL2 (4B, 8B) and performance on VisOnlyQA-Eval. Larger language models improve performance on the LLVMs using the same visual encoders. of the reasons for the weak visual perception of the current LVLMs. However, additional training data does not always solve the issue, and we also need to improve model architectures to enhance the visual perception of LVLMs. 4.4. Language Models Influence Visual Perception InternVL2 4B and 8B and Qwen2-VL 2B and 7B use the same ViT while using different language models, respectively. We expected the models with the same ViT to work similarly after fine-tuning since our in-distribution fine-tuning should make LVLMs understand tasks correctly, removing the influence of the reasoning capabilities of LVLMs. However, as shown in Table 5, the gaps between LVLMs with the same ViT and different language models become larger after fine-tuning, especially on indistribution (Synthetic) data. It indicates that language models of LVLMs directly influence visual perception, not only capabilities in question understanding or reasoning. This result suggests that language models play crucial role in processing visual information encoded by ViT, and strong language models are needed even for visual perception tasks that do not require reasoning or knowledge. 5. Conclusion Was Our Hypothesis Supported? Partially. Our results indicate that the insufficiency of training data is one We propose VisOnlyQA, new dataset for directly evaluating the visual perception capabilities of LVLMs on ques8 tions about geometric and numerical information in scientific figures. Our experiments show that existing LVLMs work poorly on VisOnlyQA, indicating that they still do not have strong visual perception capabilities. We also evaluate models fine-tuned on our synthetic training data designed to improve visual perception. We observe that fine-tuning does not always improve visual perception, and the performance is largely affected by task properties and model architectures, even after fine-tuning. In addition, our experiments suggest that language models of LVLMs influence visual perception, and strong language models are needed to properly process visual information encoded by ViT. This work reveals that LVLMs still do not have strong visual perception capabilities, and we need to improve both training data and model architectures for better visual perception."
        },
        {
            "title": "Acknowledgment",
            "content": "This work was supported by NSF CAREER Award IIS2338418. We thank Kai Katsumata for the valuable discussions."
        },
        {
            "title": "References",
            "content": "[1] Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sebastien Bubeck, Martin Cai, Qin Cai, Vishrav Chaudhary, Dong Chen, Dongdong Chen, Weizhu Chen, Yen-Chun Chen, Yi-Ling Chen, Hao Cheng, Parul Chopra, Xiyang Dai, Matthew Dixon, Ronen Eldan, Victor Fragoso, Jianfeng Gao, Mei Gao, Min Gao, Amit Garg, Allie Del Giorno, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J. Hewett, Wenxiang Hu, Jamie Huynh, Dan Iter, Sam Ade Jacobs, Mojan Javaheripi, Xin Jin, Nikos Karampatziakis, Piero Kauffmann, Mahoud Khademi, Dongwoo Kim, Young Jin Kim, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen Liang, Lars Liden, Xihui Lin, Zeqi Lin, Ce Liu, Liyuan Liu, Mengchen Liu, Weishung Liu, Xiaodong Liu, Chong Luo, Piyush Madan, Ali Mahmoudzadeh, David Majercak, Matt Mazzola, Caio Cesar Teodoro Mendes, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Liliang Ren, Gustavo de Rosa, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Yelong Shen, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Praneetha Vaddamanu, Chunyu Wang, Guanhua Wang, Lijuan Wang, Shuohang Wang, Xin Wang, Yu Wang, Rachel Ward, Wen Wen, Philipp Witte, Haiping Wu, Xiaoxia Wu, Michael Wyatt, Bin Xiao, Can Xu, Jiahang Xu, Weijian Xu, Jilong Xue, Sonali Yadav, Fan Yang, Jianwei Yang, Yifan Yang, Ziyi Yang, Donghan Yu, Lu Yuan, Chenruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou. Phi-3 technical report: highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219, 2024. 5, 7 [2] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikoł aj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan. Flamingo: visual language model for few-shot learning. In Advances in Neural Information Processing Systems, pages 2371623736. Curran Associates, Inc., 2022. 1, 3 [3] Anthropic. Claude 3.5 sonnet model card addendum, 2024. 3, 5, 1 [4] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi In Proceedings Parikh. Vqa: Visual question answering. of the IEEE International Conference on Computer Vision (ICCV), 2015. 2, 3, [5] Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. Qwen-vl: versatile vision-language model for understanding, localization, text reading, and beyond. arXiv preprint arXiv:2308.12966, 2023. 3 [6] Jie Cao and Jing Xiao. An augmented benchmark dataset for geometric question answering through dual parallel text encoding. In Proceedings of the 29th International Conference on Computational Linguistics, pages 15111520, Gyeongju, Republic of Korea, 2022. International Committee on Computational Linguistics. 4 [7] Jiaqi Chen, Jianheng Tang, Jinghui Qin, Xiaodan Liang, Lingbo Liu, Eric Xing, and Liang Lin. GeoQA: geometric question answering benchmark towards multimodal numerical reasoning. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 513523, Online, 2021. Association for Computational Linguistics. 3 [8] Jiaqi Chen, Tong Li, Jinghui Qin, Pan Lu, Liang Lin, Chongyu Chen, and Xiaodan Liang. UniGeo: Unifying geometry logical reasoning via reformulating mathematical expression. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 3313 3323, Abu Dhabi, United Arab Emirates, 2022. Association for Computational Linguistics. 3, 4 [9] Jian Chen, Ruiyi Zhang, Yufan Zhou, Ryan Rossi, Jiuxiang Gu, and Changyou Chen. Mmr: Evaluating reading ability of large multimodal models. arXiv preprint arXiv:2408.14594, 2024. 3 [10] Yangyi Chen, Karan Sikka, Michael Cogswell, Heng Ji, and Ajay Divakaran. Measuring and improving chain-ofIn Proceedthought reasoning in vision-language models. ings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 192210, Mexico City, Mexico, 2024. Association for Computational Linguistics. 7 [11] Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, and Jifeng Dai. Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks. arXiv preprint arXiv:2312.14238, 2023. 3, 5 [12] Zhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye, Zhangwei Gao, Erfei Cui, Wenwen Tong, Kongzhi Hu, Jiapeng Luo, Zheng Ma, et al. How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites. arXiv preprint arXiv:2404.16821, 2024. 1, 5, 7 [13] Matt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, Jiasen Lu, Taira Anderson, Erin Bransom, Kiana Ehsani, Huong Ngo, YenSung Chen, Ajay Patel, Mark Yatskar, Chris CallisonBurch, Andrew Head, Rose Hendrix, Favyen Bastani, Eli VanderBilt, Nathan Lambert, Yvonne Chou, Arnavi Chheda, Jenna Sparks, Sam Skjonsberg, Michael Schmitz, Aaron Sarnat, Byron Bischoff, Pete Walsh, Chris Newell, Piper Wolters, Tanmay Gupta, Kuo-Hao Zeng, Jon Borchardt, Dirk Groeneveld, Jen Dumas, Crystal Nam, Sophie Lebrecht, Caitlin Wittlif, Carissa Schoenick, Oscar Michel, Ranjay Krishna, Luca Weihs, Noah A. Smith, Hannaneh Hajishirzi, Ross Girshick, Ali Farhadi, and Aniruddha Kembhavi. Molmo and pixmo: Open weights and open data arXiv preprint for state-of-the-art multimodal models. arXiv:2409.17146, 2024. 3, 5 [14] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021. 3 [15] Haodong Duan, Junming Yang, Yuxuan Qiao, Xinyu Fang, Lin Chen, Yuan Liu, Xiaoyi Dong, Yuhang Zang, Pan Zhang, Jiaqi Wang, Dahua Lin, and Kai Chen. Vlmevalkit: An opensource toolkit for evaluating large multi-modality models. In Proceedings of the 32nd ACM International Conference on Multimedia, page 1119811201, New York, NY, USA, 2024. Association for Computing Machinery. 1 [16] Chaoyou Fu, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin, Jinrui Yang, Xiawu Zheng, Ke Li, Xing Sun, et al. Mme: comprehensive evaluation benchmark for multimodal large language models. arXiv preprint arXiv:2306.13394, 2023. 3 [17] Deqing Fu, Ruohao Guo, Ghazal Khalighinejad, Ollie Liu, Bhuwan Dhingra, Dani Yogatama, Robin Jia, and Willie Neiswanger. Isobench: Benchmarking multimodal foundation models on isomorphic representations. In First Conference on Language Modeling, 2024. [18] Xingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth, Noah Smith, Wei-Chiu Ma, and Ranjay Krishna. Blink: Multimodal large language models In Proceedings of the European can see but not perceive. Conference on Computer Vision (ECCV), 2024. 3 [19] Buse Giledereli, Yifan Hou, Yilei Tu, and Mrinmaya Sachan. Do vision-language models really understand visual language? arXiv preprint arXiv:2410.00193, 2024. 4 [20] Google. Our next-generation model: Gemini 1.5, 2024. 1, 3, 5 [21] Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the in vqa matter: Elevating the role of image understanding in visual question answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. 2, 3, 4 [22] Tianrui Guan, Fuxiao Liu, Xiyang Wu, Ruiqi Xian, Zongxia Li, Xiaoyu Liu, Xijun Wang, Lichang Chen, Furong Huang, Yaser Yacoob, Dinesh Manocha, and Tianyi Zhou. Hallusionbench: An advanced diagnostic suite for entangled language hallucination and visual illusion in large visionlanguage models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1437514385, 2024. 3 [23] Himanshu Gupta, Shreyas Verma, Ujjwala Anantheswaran, Kevin Scaria, Mihir Parmar, Swaroop Mishra, and Chitta Baral. Polymath: challenging multi-modal mathematical reasoning benchmark. arXiv preprint arXiv:2410.14702, 2024. [24] Danna Gurari, Qing Li, Abigale J. Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, and Jeffrey P. Bigham. Vizwiz grand challenge: Answering visual questions from In Proceedings of the IEEE Conference on blind people. Computer Vision and Pattern Recognition (CVPR), 2018. 2, 3, 4 [25] Nam Hyeon-Woo, Moon Ye-Bin, Wonseok Choi, Lee Hyun, and Tae-Hyun Oh. Vlms eye examination: Instruct and inspect visual competency of vision language models. arXiv preprint arXiv:2409.14759, 2024. 4 [26] Jitesh Jain, Jianwei Yang, and Humphrey Shi. Vcoder: Versatile vision encoders for multimodal large language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 27992 28002, 2024. 3 [27] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, and Ross Girshick. Clevr: diagnostic dataset for compositional language and elementary visual reasoning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. 4 [28] Kushal Kafle, Brian Price, Scott Cohen, and Christopher Kanan. Dvqa: Understanding data visualizations via question answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. 3 [29] Kushal Kafle, Brian Price, Scott Cohen, and Christopher Kanan. Dvqa: Understanding data visualizations via question answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. 4 [30] Samira Ebrahimi Kahou, Adam Atkinson, Vincent Michalski, Akos Kadar, Adam Trischler, and Yoshua Bengio. FigureQA: An annotated figure dataset for visual reasoning, 2018. 4 [31] Sebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, 10 Denis Zorin, and Daniele Panozzo. Abc: big cad model dataset for geometric deep learning. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. 4 [32] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In ICML 2022 Workshop on Knowledge Retrieval and Language Models, 2022. 5 [33] Alexander Kuhnle and Ann Copestake. Shapeworld - new test methodology for multimodal language understanding. arXiv preprint arXiv:1704.04517, 2017. 4 [34] Felix Leeb. 2024. 4 https://github.com/felixludos/alphageometry, [35] Bohao Li, Yuying Ge, Yixiao Ge, Guangzhi Wang, Rui Wang, Ruimao Zhang, and Ying Shan. Seed-bench: Benchmarking multimodal large language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1329913308, 2024. 2, 3, 4 [36] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng Gao. Llava-med: Training large languageand-vision assistant for biomedicine in one day. In Advances in Neural Information Processing Systems, pages 28541 28564. Curran Associates, Inc., 2023. 3 [37] Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, and Chunyuan Li. Llava-next-interleave: Tackling multi-image, video, and 3d in large multimodal models. arXiv preprint arXiv:2407.07895, 2024. 5 [38] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. In Proceedings of the 40th International Conference on Machine Learning, pages 1973019742. PMLR, 2023. 1, 3 [39] Zhuowan Li, Xingrui Wang, Elias Stengel-Eskin, Adam Kortylewski, Wufei Ma, Benjamin Van Durme, and Alan L. Yuille. Super-clevr: virtual benchmark to diagnose doIn Proceedings of main robustness in visual reasoning. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1496314973, 2023. 4 [40] Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, and Julian Eisenschlos. MatCha: Enhancing visual language pretraining with math reasoning and chart derendering. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1275612770, Toronto, Canada, 2023. Association for Computational Linguistics. [41] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. 1, 3 [42] Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. Improved baselines with visual instruction tuning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 2629626306, 2024. 1, 3 [43] Yuliang Liu, Zhang Li, Mingxin Huang, Biao Yang, Wenwen Yu, Chunyuan Li, Xucheng Yin, Cheng lin Liu, Lianwen Jin, and Xiang Bai. Ocrbench: On the hidden mystery of ocr in large multimodal models. arXiv preprint arXiv:2305.07895, 2024. 3 [44] Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, and Dahua Lin. Mmbench: Is your multi-modal model an all-around player? In Computer Vision ECCV 2024, pages 216233, Cham, 2025. Springer Nature Switzerland. 3 [45] Llama Team, AI @ Meta. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. 5 [46] Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-Chun Zhu. Inter-GPS: Interpretable geometry problem solving with formal language In Proceedings of the 59th Anand symbolic reasoning. nual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6774 6786, Online, 2021. Association for Computational Linguistics. 3, 4 [47] Pan Lu, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan Liang, and Song-Chun Zhu. Iconqa: new benchmark for abstract diagram understanding and visual language reasoning. In The 35th Conference on Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks, 2021. 4 [48] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought chains for science question answering. In Advances in Neural Information Processing Systems, 2022. 3 [49] Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, KaiWei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought chains for science question answering. In Advances in Neural Information Processing Systems, pages 25072521. Curran Associates, Inc., 2022. 3 [50] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts. In The Twelfth International Conference on Learning Representations, 2024. 2, 3, [51] Ahmed Masry, Xuan Long Do, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. ChartQA: benchmark for question answering about charts with visual and logical reasoning. In Findings of the Association for Computational Linguistics: ACL 2022, pages 22632279, Dublin, Ireland, 2022. Association for Computational Linguistics. 3, 4 [52] Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, and Shafiq Joty. UniChart: universal visionlanguage pretrained model for chart comprehension and reasoning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 14662 14684, Singapore, 2023. Association for Computational Linguistics. 3 [53] Meta. Llama 3.2: Revolutionizing edge ai and vision with open, customizable models, 2024. 5 11 [54] Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, and Pratyush Kumar. Plotqa: Reasoning over scientific plots. In The IEEE Winter Conference on Applications of Computer Vision (WACV), 2020. [55] Microsoft. Discover the new multi-lingual, high-quality phi3.5 slms, 2024. 3, 5, 7, 1, 2 [56] OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. 3, 5, 1 [57] OpenAI. Hello gpt-4o, 2024. 1, 3 [58] OpenAI. Gpt-4o mini: advancing cost-efficient intelligence, 2024. 5, 1 [59] OpenGVLab Team. than the bestexpanding performance boundaries of open-source multimodal models with the progressive scaling strategy, 2024. 3, 5, 7, 1, 2 Internvl2:"
        },
        {
            "title": "Better",
            "content": "[60] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022. 3 [61] Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren EtSolving geometry problems: zioni, and Clint Malcolm. Combining text and diagram interpretation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 14661476, Lisbon, Portugal, 2015. Association for Computational Linguistics. 4 [62] Alane Suhr, Mike Lewis, James Yeh, and Yoav Artzi. corpus of natural language for visual reasoning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 217 223, Vancouver, Canada, 2017. Association for Computational Linguistics. 4 [63] Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. Solving olympiad geometry without human demonstrations. Nature, 625(7995):476482, 2024. 4 [64] Andreas Veit, Tomas Matera, Lukas Neumann, Jiri Matas, and Serge Belongie. Coco-text: Dataset and benchmark for text detection and recognition in natural images. arXiv preprint arXiv:1601.07140, 2016. 3 [65] Guangzhi Wang, Yixiao Ge, Xiaohan Ding, Mohan Kankanhalli, and Ying Shan. What makes for good visual toarXiv preprint kenizers for large language models? arXiv:2305.12223, 2023. 3 [66] Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin. Qwen2-vl: Enhancing vision-language models perception of the world at any resolution. arXiv preprint 2409.12191, 2024. 5, 7, 1, [67] Zirui Wang, Mengzhou Xia, Luxi He, Howard Chen, Yitao Liu, Richard Zhu, Kaiqu Liang, Xindi Wu, Haotian Liu, Sadhika Malladi, Alexis Chevalier, Sanjeev Arora, and Danqi Chen. Charxiv: Charting gaps in realistic chart understanding in multimodal llms. arXiv preprint arXiv:2406.18521, 2024. 2, 3, 4 12 [68] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, 2022. 5 [69] Yifan Wu, Pengchuan Zhang, Wenhan Xiong, Barlas Oguz, James C. Gee, and Yixin Nie. The role of chain-of-thought in complex vision-language reasoning task. arXiv preprint arXiv:2311.09193, 2023. 7 [70] Peng Xu, Wenqi Shao, Kaipeng Zhang, Peng Gao, Shuo Liu, Meng Lei, Fanqing Meng, Siyuan Huang, Yu Qiao, and Ping Luo. Lvlm-ehub: comprehensive evaluation benchmark for large vision-language models. arXiv preprint arXiv:2306.09265, 2023. 3 [71] Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael Ryoo, Shrikant Kendre, Jieyu Zhang, Can Qin, Shu Zhang, Chia-Chih Chen, Ning Yu, Juntao Tan, Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan Wang, Yejin Choi, Ludwig Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos Niebles, Caiming Xiong, and Ran Xu. xgen-mm (blip-3): family of open large multimodal models. arXiv preprint arXiv:2408.08872, 2024. [72] Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou. mplug-owl: Modularization empowers large language models with multimodality. arXiv preprint arXiv:2304.14178, 2024. 1, 3 [73] Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Zicheng Liu, Xinchao Wang, and Lijuan Wang. MM-vet: Evaluating large multimodal models for integrated capabilities. In Forty-first International Conference on Machine Learning, 2024. 2 [74] Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. Mmmu: massive multi-discipline multimodal understanding and reasoning benchmark for expert agi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 95569567, 2024. 1, 2, 3, 4 [75] Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, and Graham Neubig. Mmmu-pro: more robust multi-discipline multimodal understanding benchmark. arXiv preprint arXiv:2409.02813, 2024. 3 [76] Peng Zhang, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Yin and yang: Balancing and answering binary visual questions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. 4 [77] Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, Pengshuo Qiu, Aojun Zhou, Pan Lu, Kai-Wei Chang, Peng Gao, and Hongsheng Li. Mathverse: Does your multi-modal llm truly see the diagrams in visual math problems? arXiv preprint arXiv:2403.14624, 2024. 1, 3, 4, 7 [78] Renrui Zhang, Xinyu Wei, Dongzhi Jiang, Yichi Zhang, Ziyu Guo, Chengzhuo Tong, Jiaming Liu, Aojun Zhou, Bin Wei, Shanghang Zhang, Peng Gao, and Hongsheng Li. Mavis: Mathematical visual instruction tuning. arXiv preprint arXiv:2407.08739, 2024. 3 [79] Yanzhe Zhang, Ruiyi Zhang, Jiuxiang Gu, Yufan Zhou, Nedim Lipka, Diyi Yang, and Tong Sun. Llavar: Enhanced visual instruction tuning for text-rich image understanding. arXiv preprint arXiv:2306.17107, 2024. 3 [80] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. MiniGPT-4: Enhancing vision-language understanding with advanced large language models. In The Twelfth International Conference on Learning Representations, 2024. 3 13 VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information"
        },
        {
            "title": "Supplementary Material",
            "content": "A. Model Access This section provides details of the model access and model parameters we use in Section 4.1. For all models, we use temperature of zero or do sample=False. The model responses in this paper were collected between October 1 and November 10, 2024. A.1. Proprietary Models OpenAI GPT. We access GPT-4o [5658] models via OpenAI API.1 We evaluate gpt-4o-mini-2024-07-18 and gpt-4o-2024-08-06 with the parameter of detail: high, which make the model to receive high resolution images.2 Anthropic Claude. We access Claude 3.5 [3] via Anthropic API.3 We evaluate claude-3-5-sonnet-20240620. Google Gemini. We access Gemini 1.5 Pro [20] via Google Cloud.4 We evaluate gemini-1.5-flash-002 and gemini-1.5-pro-002. A.2. Open Models We evaluate models published on Hugging Face Model Hub.5 For InternVL2 [59], Qwen2-VL [66], and Phi-3.5vision [55], we evaluate the models using code released by the authors.6 For other models, we evaluate using VLMEvalKit [15].7 Refer to Table 6 for the models we evaluate. For Qwen2-VL, we set max pixels=1280*28*28.8 1https://platform.openai.com/ 2https : / / platform . openai . com / docs / guides / vision/low-or-high-fidelity-image-understanding 3https://console.anthropic.com/ 4https://cloud.google.com/ 5https://huggingface.co/models 6InternVL2: https://github.com/OpenGVLab/InternVL, Qwen2-VL: https://github.com/QwenLM/Qwen2-VL, Phi-3.5vision: https://github.com/microsoft/Phi-3CookBook 7https://github.com/open-compass/VLMEvalKit 8https : / / huggingface . co / Qwen / Qwen2 - VL - 72B - Instruct#image-resolution-for-performance-boost 1 Phi-3.5-vision LLaVA-Next 8B LLaVA-Next 34B MolMo 7B-D MolMo 72B Llama 3.2 11B Llama 3.2 90B Qwen2-VL-2B Qwen2-VL-7B Qwen2-VL-72B InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-40B InternVL2-76B Claude 3.5 Sonnet GPT-4o-mini GPT-4o Gemini 1.5 Flash Gemini 1.5 Pro microsoft/Phi-3.5-vision-instruct llava next llama llava next yi 34b molmo-7B-D-0924 molmo-72B-0924 Llama-3.2-11B-Vision-Instruct Llama-3.2-90B-Vision-Instruct Qwen/Qwen2-VL-2B-Instruct Qwen/Qwen2-VL-7B-Instruct Qwen/Qwen2-VL-72B-Instruct OpenGVLab/InternVL2-4B OpenGVLab/InternVL2-8B OpenGVLab/InternVL2-26B OpenGVLab/InternVL2-40B OpenGVLab/InternVL2-Llama3-76B claude-3-5-sonnet-20240620 gpt-4o-mini-2024-07-18 gpt-4o-2024-08-06 gemini-1.5-flash-002 gemini-1.5-proTable 6. LVLMs we evaluate in this paper. For open-source models, this table shows model names in Hugging Face or VLMEvalKit."
        },
        {
            "title": "Prompt",
            "content": "C. Details of Fine-tuning {question} w/o chain-ofthought Your response should only include the final answer ({response type}). Do not include any reasoning or explanation in your response. {question} w/ chain-ofthought In your response, provide short explanation or reasoning for your answer. Then, provide the final answer ({response type}). Table 7. Prompts we use when evaluating LVLMs on VisOnlyQA. {response type} specifies the format of final answers, such as (a, b, c, d) or (True, False) B. Details of LVLM Evaluation This section provides details of experiments in Section 4.1 and 4.2. Prompts. Table 7 shows two types of prompts with and without chain-of-thought we use to evaluate LVLMs on VisOnlyQA in Section 4. Postprocessing. We extract the selected options from responses from LVLMs using GPT-4o. We instruct GPT-4o with the following prompt, where {response type} is final answers for each task, such as a, b, c, d, or True, False. Your task is to extract the final answer (selected option) from the response. Your response should only include {response type}. Question: {question} Response: {response} We use Chemistry-Shape(m). the following prompt for Your task is to extract the final answer from the response. Your response should only include the final answer(s) in format of a, a,b, a,c,d, a,b,c,d. For example, (a), (b), (c), (d) should be converted to a,b,c,d. Question: {question} Response: {response} 2 We fine-tune InternVL2 (4B and 8B) [59], Qwen2-VL (2B and 7B) [66], and Phi-3.5-vision [55]. We use the following parameters for our fine-tuning. For other parameters, we use fine-tuning code and hyperparameters provided by the authors, and we fine-tune each model for three epochs.9 InternVL2 We use learning rate of 4e-6, as we find the original learning rate of 4e-5 is too large for our dataset. Qwen2-VL We use the total batch size of 128. We warmup steps: use 100 warmup ratio: size is relatively small. 0. because our instead of dataset D. Error Analysis of Chain-of-Thought Table 8 shows an example for each error label in the analysis of chain-of-thought reasoning in Section 4.2. E. Additional Results This section provides additional results of experiments in Section 4. E.1. Improvement by Chain-of-Thought Table 9 shows improvement by chain-of-thought reasoning on VisOnlyQA-Eval-Real, which corresponds to Figure 5. E.2. Improvement by Fine-tuning Table 10 shows the performance of LVLMs fine-tuned on VisOnlyQA-Train, which corresponds to Figure 7. F. Computational Resources To evaluate and fine-tune open-source models, we use server with eight NVIDIA A100 SXM4 80GB GPUs. G. Example Data and Model Outputs Table 11 to 61 show examples from VisOnlyQA and model responses. The examples in these tables are uniformly randomly selected from Eval-Real and Eval-Synthetic."
        },
        {
            "title": "All instances in our dataset and all responses from",
            "content": "LVLMs are provided in our GitHub repository. 9InternVL2: https://github.com/OpenGVLab/InternVL/ tree / main / internvl _ chat / shell / internvl2 . 0 / 2nd _ finetune/, Qwen2-VL: https : / / github . com / hiyouga / LLaMA - Factory / blob / main / examples / train _ full / qwen2vl_full_sft.yaml, Phi-3.5-vision: https://github. com / microsoft / Phi - 3CookBook / blob / main / code / 04 . Finetuning/vision_finetuning/ Error Label Image Model Response Question Understanding Error GPT-4o In the figure, CAEB is not quadrilateral. quadrilateral must have four distinct sides and four vertices. However, CAEB shares the side AE with triangle AEC and triangle AEB, making it not closed four-sided figure. Final answer: False."
        },
        {
            "title": "Visual Perception Error",
            "content": "Gemini 1.5 Pro"
        },
        {
            "title": "Reasoning Error",
            "content": "InternVL2-76B The statement is True. While points A, D, and exist in the figure, they are not connected by line segments to form closed shape. Therefore, triangle ADP does not exist in the figure. Final Answer: The final answer is $boxed{True}$ To estimate the ratio of the areas of triangles QNM and QML, we can visually compare their bases and heights. From the diagram, it appears that the base of triangle QNM (which is NM) is roughly twice the length of the base of triangle QML (which is ML). Assuming the heights of the triangles are approximately the same, the ratio of their areas would be the square of the ratio of their corresponding sides. Since the ratio of the bases is approximately 2:1, the ratio of the areas would be (2:1)ˆ2, which is 4:1. Therefore, triangle QNM is approximately 4 times larger in area than triangle QML. Final answer: (c) 4 Insufficient Reasoning Gemini 1.5 Pro Redundant Reasoning InternVL2-26B The figure shows triangle with three edges and three vertices, which are explicitly connected. True The double line between the two hexagonal structures in the left chemical structure represents double bond. This is common way to depict double bond in chemical structures, where two lines represent single bond and one line represents double bond. Final answer: True. Table 8. Examples for each error label in chain-of-thought error analysis. 3 Geometry Chemistry Charts Triangle Quadrilateral Diameter Length Angle Area Shape (s) Shape (m) Extraction Intersection Phi-3.5-vision LLaVA-Next 8B LLaVA-Next 34B Llama 3.2 11B Llama 3.2 90B MolMo 7B-D MolMo 72B Qwen2-VL-2B Qwen2-VL-7B Qwen2-VL-72B InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-40B InternVL2-76B Claude 3.5 Sonnet GPT-4o-mini GPT-4o Gemini 1.5 Flash Gemini 1.5 Pro -2.0 2.0 0.0 0.0 2.0 -2.0 -2.0 0.0 -4.0 6.0 2.0 0.0 -4.0 2.0 6.0 2.0 0.0 0.0 -4.0 4.0 4.0 4.0 0.0 -4.0 12.0 6.0 -4.0 0.0 -2.0 -6.0 4.0 6.0 4.0 -6.0 4.0 4.0 10.0 0.0 2.0 18. 2.0 4.0 -4.0 2.0 2.0 0.0 -14.0 14.0 10.0 8.0 0.0 2.0 0.0 -4.0 -8.0 0.0 2.0 0.0 0.0 4.0 4.0 -4.0 0.0 2.0 -4.0 12.0 -8.0 0.0 -4.0 -6.0 6.0 -20.0 -12.0 -8.0 -16.0 8.0 -4.0 -12.0 -2.0 -6.0 2.0 -10.0 -8.0 -26.0 -4.0 10.0 14.0 -4.0 2.0 8.0 10.0 0.0 2.0 4.0 -2.0 -10.0 -4.0 0.0 -6.0 -2. 20.0 -2.0 -4.0 0.0 2.0 -8.0 4.0 -2.0 2.0 -2.0 2.0 6.0 0.0 10.0 -2.0 -6.0 10.0 4.0 14.0 8.0 -2.0 -2.0 4.0 8.0 2.0 -6.0 -10.0 -6.0 -4.0 20.0 6.0 2.0 2.0 18.0 -6.0 32.0 14.0 10.0 4.0 10.0 2.0 14.0 2.0 8.0 8.0 10.0 4.0 -4.0 -4.0 2.0 -2.0 -2.0 2.0 8.0 -2.0 2.0 6.0 4.0 0.0 4. 6.0 8.0 -10.0 12.0 8.0 -6.0 -8.0 -4.0 4.0 -6.0 -4.0 10.0 8.0 -8.0 -6.0 16.0 -8.0 10.0 10.0 2.0 2.0 0.0 0.0 -10.0 -2.0 4.0 -4.0 10.0 -2.0 8.0 8.0 0.0 -2.0 -8.0 -4.0 10.0 -6.0 -12.0 6.0 2.0 Average 3.8 1.4 -2.0 -0.8 2.6 2.0 -2.8 0.4 -0.2 3.2 3.2 0.4 0.0 0.8 -3. 5.8 2.0 0.4 2.4 4.4 Table 9. Improvement by Chain-of-Thought Reasoning. This table corresponds to the results in Figure 5. Triangle Quadrilateral Length Angle Area Geometry VisOnlyQAEval-Synthetic (In-Distribution) VisOnlyQAEval-Real (Outof-Distribution) Random Phi-3.5-vision InternVL2-4B InternVL2-8B Qwen2-VL-2B Qwen2-VL-7B Phi-3.5-vision InternVL2-4B InternVL2-8B Qwen2-VL-2B Qwen2-VL-7B Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned Original Fine-tuned 50.0 54.0 62.0 50.0 74.0 51.0 76.0 50.0 69. 58.0 77.0 48.0 46.0 50.0 68.0 50.0 72.0 46.0 58.0 52.0 58. 50.0 55.0 50.0 51.0 75.0 57.0 76.0 50.0 68.0 59.0 73. 54.0 50.0 46.0 56.0 38.0 44.0 52.0 56.0 56.0 52.0 20. 15.0 27.0 21.0 64.0 21.0 78.0 31.0 41.0 24.0 71.0 22.0 20. 24.0 34.0 30.0 72.0 6.0 40.0 16.0 50.0 20.0 22.0 25. 24.0 29.0 17.0 36.0 23.0 28.0 18.0 42.0 16.0 14.0 18.0 32. 34.0 26.0 20.0 26.0 22.0 36.0 20.0 21.0 29.0 18.0 39. 23.0 66.0 20.0 56.0 22.0 68.0 24.0 16.0 18.0 30.0 28.0 40. 32.0 30.0 34.0 36.0 3D Angle Average 20. 20.0 28.0 18.0 23.0 30.0 20.0 23.0 20.0 21.0 24.0 32.3 44.0 34.1 57. 35.0 64.6 33.6 54.6 37.1 65.0 32.8 29.2 31.2 44.0 36.0 50. 31.2 42.0 36.0 46.4 Size 33.3 39.0 87.0 57.0 100. 46.0 100.0 38.0 100.0 58.0 100.0 Table 10. Accuracy of LVLMs fine-tuned on VisOnlyQA-Train. We evaluate the fine-tuned models on VisOnlyQA-Eval-Synthetic, which is generated from the same distribution as the fine-tuning data, and VisOnlyQA-Eval-Real, which includes images from different distributions. This table corresponds to Figure 7. 4 Image Question Gold Answer There is no triangle BAC in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. Model Answer w/ CoT InternVL2-4B The figure shows triangle with vertices labeled A, B, and C. The triangle BAC is not present in the figure. False InternVL2-8B False. In the given figure, there is triangle BAC formed by the points B, A, and C. The vertices B, A, and are explicitly connected by edges, forming closed figure. Therefore, triangle BAC does exist in the figure. InternVL2-26B To determine if there is triangle BAC in the figure, we need to check if there are three vertices connected by edges. In the given figure, we can see that there are three vertices: B, A, and C. These vertices are connected by edges, forming triangle. Therefore, the statement There is no triangle BAC in the figure is false. Final answer: False. InternVL2-76B The figure shows triangle labeled as BAC. This triangle has three edges (BA, BC, and AC) and three vertices (B, A, and C), which are all connected. Therefore, the statement There is no triangle BAC in the figure is False. False Answer w/o CoT False False False False Claude 3.5 Sonnet Lets analyze the figure: 1. The image shows triangle with vertices labeled A, B, and C. 2. Theres line segment from to point on AC, labeled B. 3. This creates two triangles within the original triangle: ABB and BBC. 4. However, there is no triangle explicitly labeled as BAC in this figure. While we can see triangle formed by points B, A, and C, its not specifically labeled or highlighted as distinct triangle in the given diagram. Reasoning: The question asks about the existence of triangle BAC in the figure. Although the points B, A, and do form triangle, its not explicitly drawn or labeled as separate entity in the diagram. Final answer: True (There is no triangle explicitly labeled or identified as BAC in the figure) GPT-4o In the figure, triangle ( BAC ) is formed by the vertices ( ), ( ), and ( ). These points are explicitly connected by edges, forming closed shape with three sides. Therefore, triangle ( BAC ) does exist in the figure. Final answer: False. Gemini 1.5 Pro The statement is **True**. There is triangle BAC with vertices B, A, and C. While points B, are marked on the segments BA and BC respectively, there are no line segments drawn connecting to either or C. Therefore, no triangle BAC exists. Final Answer: The final answer is $boxed{True}$ False"
        },
        {
            "title": "False",
            "content": "Table 11. Examples of dataset and model responses for Geometry-Triangle (1) 5 Image Question Gold Answer There is triangle DBC in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. Model Answer w/ CoT InternVL2-4B The figure shows triangle with three edges and three vertices, which are explicitly connected. True InternVL2-8B InternVL2-26B False. The figure provided does not show triangle DBC. Instead, it shows triangle ABC with line segment DE intersecting it. The vertices of the triangle are A, B, and C, and the line segment DE is drawn inside the triangle, creating two smaller triangles, ADE and DEC. There is no triangle DBC present in the figure. triangle is polygon with three edges and three vertices. In the given figure, triangle DBC has three edges (DB, BC, and CD) and three vertices (D, B, and C), which are explicitly connected. Therefore, the statement There is triangle DBC in the figure is true. True. InternVL2-76B The figure shows triangle labeled as DBC, with vertices D, B, and connected by edges. Therefore, it is valid triangle. True Claude 3.5 Sonnet Lets analyze the figure: 1. The image shows shape with three distinct vertices labeled D, B, and C. 2. These three points are connected by straight line segments. 3. The shape formed by connecting these three points creates closed figure with three sides. This configuration meets the definition of triangle: polygon with three edges and three vertices. Reasoning: The figure clearly depicts three-sided closed shape with vertices labeled D, B, and C, which constitutes triangle. Final answer: True GPT-4o In the figure, there is triangle labeled ( triangle ABC ). The line segment ( DE ) is parallel to ( BC ) and divides ( triangle ABC ) into two smaller triangles, ( triangle ADE ) and ( triangle BDE ). However, there is no triangle labeled ( triangle DBC ) in the figure. Final answer: False. Gemini 1.5 Pro The figure shows points D, B, and connected by line segments DB, BC, and CD. These three segments and the points D, B, and form triangle. Final Answer: The final answer is $boxed{True}$ Table 12. Examples of dataset and model responses for Geometry-Triangle (2) False Answer w/o CoT True False True True True False."
        },
        {
            "title": "True",
            "content": "6 Image Question Gold Answer There is no triangle ACD in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. Model Answer w/ CoT InternVL2-4B The figure shows quadrilateral ABCD with vertices A, B, C, and D. The lines connecting these vertices form closed shape with four sides, which is characteristic of quadrilateral. However, the figure does not explicitly show triangle ACD. triangle is polygon with three edges and three vertices. In the given figure, there is no triangle ACD explicitly drawn. Therefore, the answer is True. InternVL2-8B False In the given figure, quadrilateral ABCD is shown with vertices A, B, C, and D. The lines AD, BC, and AC are drawn, forming triangles ACD, ABC, and ABD. Therefore, triangle ACD does exist in the figure. InternVL2-26B To determine if triangle ACD exists in the figure, we need to check if the three vertices A, C, and are connected by edges. 1. Vertex is connected to vertex by the edge AC. 2. Vertex is connected to vertex by the edge CD. 3. Vertex is connected to vertex by the edge DA. Since all three vertices are connected by edges, triangle ACD does exist in the figure. Therefore, the statement There is no triangle ACD in the figure is false. Final answer: False. InternVL2-76B The figure shows quadrilateral ABCD with diagonals AC and BD intersecting at point O. The vertices A, C, and are connected by edges, forming triangle ACD. Therefore, the statement There is no triangle ACD in the figure is False. False Answer w/o CoT True False False False Claude 3.5 Sonnet Lets analyze the figure carefully: 1. We can see four distinct points: A, B, C, and D. 2. Theres point in the center, which appears to be the intersection of the diagonals. 3. We can clearly see lines connecting to D, to C, and to D. Given these observations: - The line AD forms one side of the potential triangle ACD. - The line AC forms another side of the potential triangle ACD. - The line CD forms the third side of the potential triangle ACD. These three lines connect the three points A, C, and D, forming closed shape with three sides and three vertices. This meets the definition of triangle. Therefore, there is indeed triangle ACD in the figure. Final answer: False False GPT-4o In the figure, points A, C, and are connected by line segments, forming closed shape with three edges and three vertices. This satisfies the definition of triangle. Therefore, the statement There is no triangle ACD in the figure is False. Gemini 1.5 Pro The vertices A, C, and are connected by line segments AC and AD, forming the triangle ACD. Final Answer: False"
        },
        {
            "title": "False",
            "content": "Table 13. Examples of dataset and model responses for Geometry-Triangle (3) 7 Image Question Gold Answer There is quadrilateral ABCO in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). Model InternVL2-4B InternVL2-8B Answer w/ CoT The figure shows circle with points A, B, C, and on the circumference. The line segments AB, BC, CA, and AO form quadrilateral. True False. Reasoning: The figure shows quadrilateral ABCO, but it is not standard quadrilateral. standard quadrilateral has four sides and four vertices. However, in this figure, point is the center of the circle, and the lines AB, BC, and CA are chords of the circle. The line segment AC is diameter of the circle, and point is the midpoint of AC. Therefore, the figure does not form standard quadrilateral but rather cyclic quadrilateral (a quadrilateral inscribed in circle) with additional properties due to the circles center. InternVL2-26B quadrilateral is defined as four-sided polygon. In the given figure, quadrilateral ABCO is formed by the four vertices A, B, C, and O, and the four edges connecting these vertices. Therefore, the statement quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices) is true. True. InternVL2-76B The figure shows circle with four points labeled A, B, C, and O. These points are connected by lines forming four-sided polygon. Therefore, the figure represents quadrilateral. Final answer: True Claude 3.5 Sonnet Lets analyze the figure carefully: 1. The image shows circle with three distinct points labeled A, B, and on its circumference. 2. Theres also point O, which appears to be the center of the circle. 3. Lines are drawn connecting points A, B, and to each other and to point O. 4. While there are multiple triangles formed (such as ABC, ABO, BCO, and ACO), there isnt four-sided shape visible. 5. quadrilateral would require four distinct vertices connected by four sides, which we dont see in this figure. Explanation: The figure shows circle with inscribed triangles, but it does not contain four-sided polygon. The shape ABCO is not quadrilateral because is connected to all other points, forming triangles instead of four-sided shape. Final answer: False GPT-4o In the figure, (A), (B), (C), and (O) are points. However, the lines form triangle (ABC) and three additional line segments (AO), (BO), and (CO) that meet at point (O). This does not form closed four-sided polygon, as there are not four distinct sides forming quadrilateral. Final answer: False. Gemini 1.5 Pro The figure shows points A, B, C, and connected by line segments to form closed, four-sided shape. These four points represent the vertices, and the lines connecting them represent the edges. Thus, the figure represents quadrilateral. Final Answer: The final answer is $boxed{True}$ True Answer w/o CoT False False False False False"
        },
        {
            "title": "True",
            "content": "Table 14. Examples of dataset and model responses for Geometry-Quadrilateral (1) 8 Image Question Gold Answer There is quadrilateral COEF in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). Model Answer w/ CoT InternVL2-4B The figure shows circle with points E, C, O, and on its circumference. The line segment CO is chord of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line segment OG is radius of the circle. The line segment OE is radius of the circle, and the line segment OF is radius of the circle. The line segment OD is radius of the circle, and the line. . True Answer w/o CoT False InternVL2-8B False The figure provided does not form quadrilateral COEF. quadrilateral is defined as four-sided polygon, but in this figure, COEF does not form closed four-sided shape. The points C, O, E, and are not connected in way that forms quadrilateral. Instead, the points are arranged in way that forms circle with line segment intersecting it. Therefore, the figure does not meet the criteria for quadrilateral. InternVL2-26B quadrilateral is defined as four-sided polygon. The figure shows quadrilateral COEF with four sides and four vertices. Therefore, the statement There is quadrilateral COEF in this figure is true. True. InternVL2-76B The figure shows quadrilateral COEF, which is four-sided polygon. The vertices are C, O, E, and F, and the sides are CO, OE, EF, and FC. Therefore, the statement is true. True False"
        },
        {
            "title": "True",
            "content": "Claude 3.5 Sonnet Lets analyze the figure carefully: 1. The image shows circle with several points and line segments marked. 2. We can see points labeled C, O, E, F, D, and G. 3. However, these points do not form quadrilateral COEF: - and are connected by radius - is the center of the circle - and are points on the circumference - There are no visible line segments connecting these points to form closed four-sided shape 4. The figure appears to show circle with various elements like diameter (EF), radii, and possibly chord (CD), but not quadrilateral COEF. 5. For quadrilateral COEF to exist, we would need to see four line segments connecting these points in closed shape, which is not present in this diagram. Explanation: While the points C, O, E, and are present in the figure, they do not form quadrilateral as they are not connected to create four-sided closed shape. Final answer: False"
        },
        {
            "title": "False",
            "content": "GPT-4o In the figure, the points C, O, E, and are connected, but they do not form quadrilateral. quadrilateral requires four distinct sides, and in this case, the lines CO and OF are not connected directly to form closed shape with four sides. Instead, COEF forms triangle with an additional point inside the circle. Therefore, the statement is False. 9 Gemini 1.5 Pro The given figure has points C, O, E, and F. These four points can be connected to form four-sided polygon. Therefore, COEF is quadrilateral. Final Answer: The final answer is $boxed{True}$"
        },
        {
            "title": "True",
            "content": "Table 15. Examples of dataset and model responses for Geometry-Quadrilateral (2) Image Question Gold Answer There is no quadrilateral CBPQ in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). Model Answer w/ CoT InternVL2-4B To determine if there is quadrilateral CBPQ in the figure, we need to identify if there are four vertices (corners) and four edges (sides) that form closed shape. In the given figure, we can see the following points: - Point - Point - Point - Point However, there is no point in the figure. Therefore, there is no quadrilateral CBPQ in this figure. Final answer: True InternVL2-8B False The figure does not contain quadrilateral CBPQ. quadrilateral is defined as four-sided polygon, but in this figure, the points C, B, P, and do not form closed four-sided shape. Instead, the points form triangle (ABC) and segment (PQ) that intersects the circle at point P. Therefore, there is no quadrilateral CBPQ in this figure. InternVL2-26B quadrilateral is four-sided polygon, and in the given figure, the shape CBPQ has only three sides and three vertices. Therefore, it cannot be classified as quadrilateral. True. InternVL2-76B The figure shows circle with points C, B, P, and Q. However, the quadrilateral CBPQ is not formed because the line segment BP does not exist in the figure. Therefore, the statement There is no quadrilateral CBPQ in this figure is true. True Claude 3.5 Sonnet Lets analyze the figure carefully: 1. We can see circle with center C. 2. Theres triangle with vertices A, B, and what appears to be P. 3. Point is not explicitly labeled, but there is point where the line from intersects the circle. Now, lets consider if we can form quadrilateral CBPQ: - is the center of the circle - is clearly marked - appears to be marked at the top of the triangle - Q, while not labeled, could be considered as the point where line AP intersects the circle If we connect these four points (C, B, P, and the unlabeled intersection point as Q), we can indeed form four-sided figure with four vertices. Therefore, it is possible to identify quadrilateral CBPQ in this figure, even though is not explicitly labeled. Final answer: False True Answer w/o CoT True False True False"
        },
        {
            "title": "False",
            "content": "GPT-4o In the figure, points C, B, P, and are not all connected to form closed shape with four sides. quadrilateral requires four connected edges forming closed loop. Here, the points do not form such shape. Therefore, the statement is **True**. Gemini 1.5 Pro The statement is **False**. The points C, B, P, and are connected by line segments CB, BP, PQ, and QC, forming closed four-sided figure. This meets the definition of quadrilateral. It doesnt matter that some of the lines forming it happen to also be part of other shapes (triangle and circle). Final Answer: The final answer is $boxed{False}$"
        },
        {
            "title": "False",
            "content": "Table 16. Examples of dataset and model responses for Geometry-Quadrilateral (3) 10 Image Question Gold Answer Line AP is times longer than CB. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.25 (b) 2 (c) 4 (d) 0.5 (e) 1 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To estimate the value of X, we need to visually compare the lengths of line AP and CB. 1. **Observation**: - Line AP is the hypotenuse of the right triangle AOB. - Line CB is the radius of the circle and is perpendicular to line AB at point B. 2. **Comparison**: - Since AB is radius of the circle, it is equal to the radius of the circle, which is fixed length. - AP is the hypotenuse of the right triangle AOB, which is longer than the radius AB. 3. **Estimation**: - Given that AB is fixed length and AP is significantly longer, we can estimate that AP is approximately 2 times longer than AB. 4. **Conclusion**: - Based on the visual information, reasonable estimate for the value of (the ratio of AP to CB) is 2. Therefore, the final answer is (b) 2. To estimate the value of ( ), we can visually compare the lengths of line segments ( AP ) and ( CB ) in the given diagram. 1. **Visual Comparison**: - ( AP ) appears to be about 4 times the length of ( CB ). This is because ( AP ) extends beyond ( CB ) by significant proportion, making it appear much longer. 2. **Reasoning**: - Given the visual estimation, ( AP ) is approximately 4 times the length of ( CB ). This is rough estimate based on the relative lengths observed in the diagram. Therefore, the most reasonable estimate of ( ) is: **Final Answer: (c) 4** To estimate the value of ( ), we need to compare the lengths of ( AP ) and ( CB ) visually. 1. Observe the lengths of ( AP ) and ( CB ) in the diagram. 2. Estimate the ratio of ( AP ) to ( CB ) by visually comparing their lengths. From the visual information, it appears that ( AP ) is approximately four times the length of ( CB ). Therefore, reasonable estimate for ( ) is 4. The correct answer is (c) 4. To estimate the length of AP relative to CB, we can visually compare the segments. - CB is chord of the circle. - AP extends from the circles edge at to point P, which is significantly farther away than B. From the visual information, it appears that AP is roughly four times the length of CB. Therefore, the reasonable estimate of is 4. Final answer: (c) 4 Looking at the image, can see circle with its center O, and triangle APB where is point on the circle. Line CB is chord of the circle, passing through its diameter. Visually comparing the lengths of AP and CB: 1. AP extends from point on the circle to point well outside it. 2. CB is chord within the circle, noticeably shorter than the diameter. 3. AP appears to be significantly longer than CB - roughly 3 to 4 times longer. Among the given options, the one that best matches this visual estimate is (c) 4. Option (a) 0.25 and (d) 0.5 would imply AP is shorter than CB, which is clearly not the case. Option (e) 1 would mean theyre equal, which is also not true. Option (b) 2 is closer but still seems to underestimate the difference. Therefore, based on visual estimation alone, the most reasonable answer is: (c) 4 GPT-4o From the visual information, line segment ( AP ) appears to be approximately twice the length of segment ( CB ). Therefore, reasonable estimate for ( ) is 2. Final answer: (b) Gemini 1.5 Pro Visually, AP appears roughly twice as long as the diameter of the circle. CB is chord that is close in length to the diameter (although clearly shorter). Therefore, AP appears to be roughly twice the length of CB. Final Answer: (b) Table 17. Examples of dataset and model responses for Geometry-Length (1) (b) 2 (b) 11 Image Question Gold Answer Line CE is times longer than AD. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.5 (b) 1 (c) 2 (d) 4 (e) 0.25 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B To estimate the value of X, we need to visually compare the lengths of CE and AD. 1. **Observation**: - CE is the chord of the circle. - AD is the radius of the circle. 2. **Comparison**: - From the diagram, it is clear that CE is much longer than AD. - The radius (AD) appears to be about half the length of the diameter, which is twice the length of the radius. - CE appears to be about twice the length of the radius. 3. **Estimation**: - Since CE is approximately twice the length of AD, we can estimate that is around 2. Therefore, the reasonable estimate of is 2. **Final Answer**: (c) 2 To estimate the value of ( ) based on the visual information, we need to compare the lengths of ( CE ) and ( AD ). 1. **Visual Comparison**: - ( CE ) appears to be about twice the length of ( AD ). This is rough estimate based on the visual proportions in the image. 2. **Reasoning**: - If ( CE ) is twice as long as ( AD ), then ( ) would be 2. Thus, the most reasonable estimate of ( ) is 2. **Final Answer**: (c) 2 To estimate the value of ( ), we can visually compare the lengths of ( CE ) and ( AD ) in the given circle diagram. From the diagram, it appears that ( CE ) is approximately twice the length of ( AD ). This suggests that ( ) is around 2. Therefore, the reasonable estimate for ( ) is (c) 2. So, the final answer is (c) 2. InternVL2-76B To estimate the length of CE relative to AD, observe the visual proportions in the circle. Line CE appears to be roughly twice the length of AD. Given the options: (a) 0.5 (b) 1 (c) 2 (d) 4 (e) 0.25 The most reasonable estimate is (c) 2. Final answer: (c) 2 Claude 3.5 Sonnet Based on the visual information provided in the image, can estimate the relative lengths of lines CE and AD. Line CE appears to be diameter or very close to diameter of the circle, as it passes through or very near the center. Line AD, on the other hand, is chord that does not pass through the center and is visibly shorter than CE. Comparing these two lines visually, CE looks to be about twice the length of AD. Its clearly longer, but not dramatically so - certainly not four times as long. At the same time, CE is definitely more than just little bit longer than AD, ruling out the options where CE would be equal to or shorter than AD. Given these observations, the most reasonable estimate for (where CE is times longer than AD) would be 2. Therefore, my answer is: (c) 2 GPT-4o From the image, line ( CE ) appears to be about twice as long as line ( AD ). Visually estimating, ( CE ) is significantly longer than ( AD ), but not excessively so. Therefore, the reasonable estimate for ( ) is 2. The final answer is (c) 2. Gemini 1.5 Pro CE looks to be roughly the same length as AD. Therefore, is approximately 1. Final Answer: (b) Table 18. Examples of dataset and model responses for Geometry-Length (2) (c) 2 c (a) 12 Image Question Gold Answer Line BC is times longer than AD. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 1 (b) 0.25 (c) 2 (d) 4 (e) 0.5 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To estimate the value of X, we need to visually compare the lengths of BC and AD. 1. **Observation**: - AD appears to be about half the length of BC. - This is rough visual estimate based on the proportions of the triangle. 2. **Reasoning**: - If AD is approximately half the length of BC, then BC is approximately twice the length of AD. - Therefore, X, which represents the ratio of BC to AD, is approximately 2. 3. **Conclusion**: - The reasonable estimate of from the visual information is 2. **Final Answer**: (c) To estimate the value of ( ) based on the visual information, we need to compare the lengths of ( BC ) and ( AD ). 1. **Visual Comparison**: - ( BC ) appears to be about twice the length of ( AD ). This is rough estimate based on the visual proportions in the image. 2. **Reasoning**: - If ( BC ) is twice as long as ( AD ), then ( ) would be 2. Therefore, the most reasonable estimate of ( ) is 2. **Final Answer**: (c) 2 To estimate the value of ( ), we need to compare the lengths of ( BC ) and ( AD ) visually. From the diagram, it appears that ( BC ) is significantly longer than ( AD ). reasonable estimate for ( ) would be value that reflects this visual disparity. Option (a) 1 suggests that ( BC ) is equal in length to ( AD ), which is not visually accurate. Option (b) 0.25 suggests that ( BC ) is one-fourth the length of ( AD ), which also does not match the visual information. Option (c) 2 suggests that ( BC ) is twice the length of ( AD ), which is closer to the visual estimate but still not quite accurate. Option (d) 4 suggests that ( BC ) is four times the length of ( AD ), which visually seems to be reasonable estimate. Option (e) 0.5 suggests that ( BC ) is half the length of ( AD ), which is not visually accurate. Given the visual information, the most reasonable estimate for ( ) is 4. Final answer: (d) 4 To estimate the length of BC relative to AD, observe the visual proportions in the triangle. The line segment AD appears to be approximately half the length of BC. Given the options: (a) 1 - This would mean AD and BC are equal, which is not visually accurate. (b) 0.25 - This would mean BC is four times longer than AD, which seems too long. (c) 2 - This would mean BC is twice as long as AD, which looks about right. (d) 4 - This would mean BC is four times longer than AD, which seems too long. (e) 0.5 - This would mean BC is half the length of AD, which is incorrect. The most reasonable estimate from the visual information is (c) 2. Final answer: (c) Looking at the image, we can see triangle ABC with smaller triangle ADE inside it. The line BC forms the base of the larger triangle, while AD is one of the sides of the smaller triangle. Visually comparing the lengths of BC and AD: 1. BC appears to be significantly longer than AD. 2. BC seems to span almost the entire width of the image, while AD is much shorter line segment. 3. AD looks to be roughly 1/4 to 1/3 of the length of BC. Given these observations, we can estimate that BC is approximately 3 to 4 times longer than AD. This means X, which represents how many times longer BC is compared to AD, should be around 3 or 4. Among the given options, the closest value to this visual estimate is 4. Therefore, the final answer is: (d) 4 GPT-4o From the visual information, line BC appears to be significantly longer than line AD. It looks like BC is about four times the length of AD. Therefore, reasonable estimate for is 4. The final answer is (d) 4. Gemini 1.5 Pro BC appears to be roughly twice the length of AD. Final Answer: (c) c (d) d Table 19. Examples of dataset and model responses for Geometry-Length (3) 13 Image Question Gold Answer Which of the following options is reasonable estimate of the angle CAB in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 90 degrees (b) 45 degrees (c) 135 degrees (d) 10 degrees (e) 180 degrees Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B To estimate the angle CAB, we can visually assess the triangle and the right angle at point D. The angle at point is formed by the line segments AC and AB. Since the triangle is right triangle with right angle at D, the sum of the angles in triangle is 180 degrees. The right angle at is 90 degrees, so the remaining two angles (CAB and BDC) must add up to 90 degrees. Given that angle BDC is right angle, angle CAB must be less than 90 degrees. Among the given options, the only reasonable estimate for angle CAB is 45 degrees. Final answer: (b) 45 degrees The figure shows right triangle with right angle at point D. The angle CAB is the angle at the top of the triangle, which is opposite the side BC. Given that the right angle is at D, and the triangle is right triangle, the angle CAB must be one of the other two angles in the triangle. In right triangle, the sum of the two non-right angles is 90 degrees. Therefore, the angle CAB must be less than 90 degrees. Among the given options: - (a) 90 degrees is incorrect because it would make the triangle straight line. - (b) 45 degrees is reasonable estimate for an angle in right triangle. - (c) 135 degrees is incorrect because it is greater than 90 degrees. - (d) 10 degrees is too small and not reasonable estimate for an angle in right triangle. - (e) 180 degrees is incorrect because it would make the triangle straight line. Therefore, the most reasonable estimate for the angle CAB is 45 degrees. Final answer: (b) 45 degrees To estimate the angle CAB, we can use the concept of similar triangles. Since AD is the altitude of the triangle ABC, it divides the triangle into two smaller right triangles, $ensuremath{triangle}$ABD and $ensuremath{triangle}$ACD. In right triangle, the angle opposite the altitude is right angle (90 degrees). Therefore, $ensuremath{angle}$BAD and $ensuremath{angle}$CAD are both 90 degrees. Since $ensuremath{angle}$BAC is the angle between the two legs of the right triangle, it must be the remaining angle in the triangle, which is 90 degrees. Therefore, the angle CAB is 90 degrees. The final answer is (a) 90 degrees. Answer w/o CoT b (b) 45 degrees InternVL2-76B To estimate the angle CAB, observe the triangle ABC and the line AD. The line AD appears to bisect the angle BAC into two equal parts. Given that triangle ABC is isosceles (AB = AC), the angle at (BAC) is typically around 70-80 degrees. Since AD bisects this angle, each of the two resulting angles (BAD and CAD) would be approximately half of the original angle. Therefore, the angle CAB (which is one of these bisected angles) would be around 45 degrees. Final answer: (b) 45 degrees Claude 3.5 Sonnet Based on the visual information provided in the image, can estimate the angle CAB as follows: The triangle shown appears to be roughly isosceles, with the two sides CA and BA looking approximately equal in length. The angle at the top vertex (angle CAB) seems to be less than right angle (90 degrees), but not by large amount. Given this visual assessment, the angle CAB looks to be close to 45 degrees. Its clearly much larger than 10 degrees and significantly smaller than 90 degrees or anything above that. Among the given options, 45 degrees (option b) is the most reasonable estimate that matches what we can see in the figure. Final answer: (b) GPT-4o The angle ( angle CAB ) appears to be an acute angle, as it is less than right angle (90 degrees). It is also significantly smaller than 45 degrees. Therefore, the most reasonable estimate from the given options is 10 degrees. Final answer: (d) 10 degrees. Gemini 1.5 Pro Angle CAB looks less than 90 degrees, and closer to half of 90 degrees. 45 degrees is reasonable estimate. Final Answer: (b) (b) 45 degrees b Table 20. Examples of dataset and model responses for Geometry-Angle (1) 14 Image Question Gold Answer Which of the following options is reasonable estimate of the angle AOD in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 180 degrees (b) 10 degrees (c) 135 degrees (d) 90 degrees (e) 45 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B To estimate the angle AOD, we need to consider the shape of the quadrilateral ABCD. The figure shows that ABCD is square, as all sides are equal and all angles are right angles (90 degrees). In square, the diagonals are equal in length and bisect each other at right angles. Therefore, each diagonal divides the square into two congruent right-angled triangles. Since the diagonals of square bisect the angles of the square, each angle at the vertices of the square is divided into two equal parts. Thus, the angle AOD is half of the right angle at vertex A, which is 90 degrees. Therefore, the reasonable estimate for the angle AOD is 45 degrees. Final answer: (e) 45 degrees To estimate the angle AOD in the figure, we can observe the following: 1. The figure shows square ABCD with diagonals AC and BD intersecting at point O. 2. In square, the diagonals are equal in length and bisect each other at right angles (90 degrees). Since the diagonals of square intersect at right angles, the angle AOD is 90 degrees. Therefore, the reasonable estimate of the angle AOD is: (d) 90 degrees InternVL2-26B To estimate the angle AOD, we can observe that the figure is rhombus, which means all sides are equal and opposite angles are equal. Since the diagonals of rhombus bisect each other at right angles (90 degrees), the angle AOD is half of the angle formed by the diagonals at point O. Given that the diagonals bisect each other at right angles, the angle AOD is half of 90 degrees, which is 45 degrees. Therefore, the answer is (e) 45 degrees. InternVL2-76B Claude 3.5 Sonnet To estimate the angle AOD, observe the figure and note the position of points A, O, and D. The diagonals of the parallelogram intersect at point O, and in parallelogram, the diagonals bisect each other. Therefore, angle AOD is one of the angles formed by the intersection of the diagonals. From the visual information, angle AOD appears to be right angle because the diagonals intersect at 90 degrees in parallelogram. Thus, the reasonable estimate of angle AOD is 90 degrees. Final answer: (d) 90 degrees Looking at the figure, we can see that AOD is one of the angles formed by the diagonals of what appears to be quadrilateral (possibly square or rectangle). The diagonals intersect at point O, creating four angles. From visual inspection, the angle AOD looks to be approximately half of right angle. right angle is 90 degrees, and half of that would be 45 degrees. The angle certainly doesnt look like 180 degrees (which would be straight line), 10 degrees (which would be very narrow angle), or 135 degrees (which would be larger than right angle). It also doesnt appear to be full 90 degrees, as its visibly smaller than the right angles at the corners of the quadrilateral. Therefore, based on visual estimation alone, the most reasonable estimate for angle AOD is 45 degrees. Final answer: (e) 45 degrees GPT-4o From the visual information in the figure, angle ( angle AOD ) appears to be an acute angle, significantly less than 90 degrees. It looks closer to small angle, possibly around 45 degrees. Therefore, the reasonable estimate for angle ( angle AOD ) is: (e) 45 degrees Gemini 1.5 Pro The angle AOD appears to be close to right angle. right angle measures 90 degrees. Final Answer: (d) Table 21. Examples of dataset and model responses for Geometry-Angle (2) (d) 90 degrees (d) 90 degrees 15 Image Question Gold Answer Which of the following options is reasonable estimate of the angle BMN in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 90 degrees (b) 135 degrees (c) 180 degrees (d) 45 degrees (e) 10 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To estimate the angle BMN in the figure, we need to consider the shape and the given angles. The figure shows quadrilateral with diagonal, and the angles at vertices and are right angles (90 degrees). Given that the angles at and are right angles, the sum of the angles in quadrilateral is 360 degrees. Since the other two angles (at vertices and D) are not directly given, we can infer that the angle BMN is likely to be part of the remaining angles that sum up to 360 degrees. Considering the options provided: (a) 90 degrees - This is the angle at vertex A, not BMN. (b) 135 degrees - This is reasonable estimate for the angle BMN, as it is large angle but not as large as 180 degrees. (c) 180 degrees - This would imply straight line, which is not the case here. (d) 45 degrees - This is too small for the angle BMN. (e) 10 degrees - This is too small for the angle BMN. Therefore, the most reasonable estimate for the angle BMN is 135 degrees. Final answer: (b) 135 degrees. The angle BMN appears to be right angle, as indicated by the small square at the intersection of lines BM and MN. This typically represents 90-degree angle in geometric diagrams. Therefore, the most reasonable estimate of the angle BMN is 90 degrees. Final answer: (a) 90 degrees To estimate the angle BMN, we can observe the given geometric figure. The figure shows right-angled triangle (ABD) and rectangle (ABCD). In rectangle, all interior angles are 90 degrees. Since BMN is part of the rectangle, it is reasonable to estimate that angle BMN is also 90 degrees. Final answer: (a) 90 degrees To estimate the angle BMN, observe the figure and the relative positions of points B, M, and N. The angle BMN appears to be right angle because line BM is perpendicular to line MN. Therefore, the reasonable estimate of the angle BMN is 90 degrees. Final answer: (a) 90 degrees Looking at the figure, can see that angle BMN is formed by two lines that meet at point M. This angle appears to be significantly larger than right angle (90 degrees), but its not straight line (180 degrees). The angle looks to be roughly halfway between right angle and straight line. This would put it close to 135 degrees, which is one of the options provided. Its clearly much larger than 45 degrees or 10 degrees, and noticeably larger than 90 degrees. However, it doesnt extend all the way to form straight line, so 180 degrees would be too large. Based on this visual estimation, the most reasonable estimate among the given options would be 135 degrees. Final answer: (b) GPT-4o The angle ( angle BMN ) appears to be an acute angle, as it is smaller than right angle. Visually, it seems closer to small angle rather than large one. Among the options, 10 degrees is the most reasonable estimate for an acute angle. Final answer: (e) 10 degrees Gemini 1.5 Pro Angle BMN appears to be slightly larger than right angle (90 degrees). 135 degrees seems like reasonable estimate. Final Answer: (b) Table 22. Examples of dataset and model responses for Geometry-Angle (3) (b) 135 degrees (b) 135 degrees d 16 Image Question Gold Answer ADB is times larger in area than ABC. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.5 (b) 0.25 (c) 1 (d) 4 (e) 2 Model Answer w/ CoT Answer w/o CoT InternVL2-4B To estimate the area ratio of triangle ADB to triangle ABC, we can visually compare their sizes. Triangle ADB appears to be roughly twice as large as triangle ABC in terms of height and base length. Given the options: (a) 0.5 (b) 0.25 (c) 1 (d) 4 (e) 2 The most reasonable estimate from the visual information is (e) 2. Final answer: (e) 2. InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet The diagram shows triangle ( triangle ABC ) with smaller triangle ( triangle ADE ) inside it. The base ( DE ) is part of the base ( DC ) of ( triangle ABC ). The height from ( ) to ( DC ) is the same for both triangles, as they share the same vertex ( ). From the visual information, it appears that ( DE ) is approximately half the length of ( DC ). Since the height is the same for both triangles, the area of ( triangle ADE ) is roughly half the area of ( triangle ABC ). Therefore, the area of ( triangle ADB ) is approximately half the area of ( triangle ABC ). The final answer is (a) 0.5. To estimate the area ratio of triangle (ADB) to triangle (ABC), we can visually compare the base lengths and the heights of the triangles. 1. **Base Comparison**: The base (DB) appears to be roughly twice the length of the base (BC). This suggests that the area of (ADB) will be larger due to the larger base. 2. **Height Comparison**: The height from (A) to (D) appears to be roughly the same as the height from (A) to (B). This means the height ratio is approximately 1. Given that the base ratio is 2 and the height ratio is 1, the area ratio of (ADB) to (ABC) can be estimated using the formula for the area of triangle (( text{Area} = frac{1}{2} times text{base} times text{height} )): [ text{Area ratio} = left( frac{text{Base of } ADB}{text{Base of } ABC} right)ˆ2 = left( frac{2}{1} right)ˆ2 = 4 ] Thus, the area of (ADB) is 4 times larger than the area of (ABC). The correct answer is (d) 4. To estimate the ratio of the areas of triangle ADB to triangle ABC, we can visually compare their bases and heights. 1. **Base Comparison**: The base of triangle ADB (from to B) appears to be roughly twice as long as the base of triangle ABC (from to C). 2. **Height Comparison**: The height of triangle ADB (from to the line containing and B) appears to be roughly the same as the height of triangle ABC (from to the line containing and C). The area of triangle is given by the formula ( text{Area} = frac{1}{2} times text{base} times text{height} ). Since the height is the same for both triangles, the ratio of the areas will be the same as the ratio of their bases. Given that the base of ADB is approximately twice the base of ABC, the area of ADB will be approximately twice the area of ABC. Therefore, the reasonable estimate is: (e) 2 Looking at the image, we can see triangle ABC with point on the side AC. This creates two triangles: the larger original triangle ABC, and smaller triangle ADB within it. Visually estimating the areas, triangle ADB appears to take up roughly half or slightly less than half of the total area of triangle ABC. The question states that ADB is times larger in area than ABC, which means were looking for the inverse of this visual estimate. Given that ADB looks to be about half the size of ABC, would be the reciprocal of this, which is approximately 2. Among the given options, 2 (option e) seems to be the most reasonable estimate based on the visual information provided. Final answer: (e) 2 GPT-4o From the visual information, triangle ( triangle ADB ) appears to be larger than triangle ( triangle ABC ). The base ( DB ) is longer than ( EC ), and the height from ( ) to ( DB ) is the same as the height to ( EC ). This suggests that ( triangle ADB ) is significantly larger than ( triangle ABC ). reasonable estimate is that ( triangle ADB ) is about twice the size of ( triangle ABC ). Final answer: (e) Gemini 1.5 Pro ADB appears roughly twice as large as ABC. This is because ADB encompasses most of the area within triangle ADC, which itself is roughly the same area as triangle ABC. Therefore, ADB is approximately 2 times larger than ABC. Final Answer: (e) Table 23. Examples of dataset and model responses for Geometry-Area (1) e (d) e 17 Image Question Gold Answer DAO is times larger in area than DBC. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.25 (b) 4 (c) 1 (d) 2 (e) 0.5 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B To estimate the value of ( ), we need to visually compare the areas of triangles ( DAO ) and ( DBC ). 1. **Observation**: Triangle ( DAO ) appears to be roughly twice as large as triangle ( DBC ) in terms of height and base. 2. **Estimation**: If we assume that the height and base of ( DAO ) are approximately twice those of ( DBC ), then the area of ( DAO ) would be roughly four times that of ( DBC ). Given the options: (a) 0.25 (b) 4 (c) 1 (d) 2 (e) 0.5 The most reasonable estimate for ( ) is 4, as it aligns with the visual observation that ( DAO ) is about twice as large as ( DBC ). **Final Answer**: (b) To estimate the ratio of the areas of triangles DAO and DBC, we can visually compare their sizes. 1. **Visual Comparison**: - Triangle DAO appears to be significantly larger than triangle DBC. - The height of triangle DAO from point to line AB is much greater than the height of triangle DBC from point to line AB. 2. **Reasoning**: - The area of triangle is given by the formula ( text{Area} = frac{1}{2} times text{base} times text{height} ). - Since the base (line AB) is the same for both triangles, the ratio of their areas is directly proportional to the ratio of their heights. 3. **Estimation**: - From the visual information, triangle DAOs height is approximately 4 times the height of triangle DBC. - Therefore, the area of triangle DAO is approximately 4 times the area of triangle DBC. Thus, the most reasonable estimate is (b) 4. InternVL2-26B To estimate the area ratio of triangle DAO to triangle DBC, we can visually compare the areas of the two triangles. 1. Observe the triangles DAO and DBC. 2. Notice that triangle DAO is larger than triangle DBC. 3. Estimate the ratio of the areas by comparing the visual sizes of the triangles. From the visual information, it appears that triangle DAO is approximately 4 times larger than triangle DBC. Therefore, the answer is (b) 4. b InternVL2-76B Claude 3.5 Sonnet GPT-4o To estimate the area ratio of triangle DAO to triangle DBC, we can visually compare their bases and heights. 1. **Base Comparison**: The base of triangle DAO (DO) appears to be roughly half the length of the base of triangle DBC (DB). 2. **Height Comparison**: The height of triangle DAO (AO) appears to be roughly the same as the height of triangle DBC (BO). Given that the area of triangle is calculated as ( frac{1}{2} times text{base} times text{height} ), if the base of DAO is half that of DBC, and the heights are the same, the area of DAO would be half the area of DBC. Thus, the area of DAO is approximately 0.5 times the area of DBC. Final answer: (e) 0.5 Looking at the image, we can see quadrilateral ABCD with diagonal AC that divides it into two triangles: DAO and DBC. Visually estimating the areas: Triangle DAO appears to be significantly larger than triangle DBC. It covers more than half of the entire quadrilateral, while DBC covers less than half. The question states that DAO is times larger in area than DBC. Given this information and the visual estimate, we can reasonably conclude that DAO is about twice the size of DBC. Among the given options, the value that best represents this relationship is 2. Therefore, my reasoning leads to the answer: (d) 2 From the image, triangle ( triangle DAO ) and triangle ( triangle DBC ) share the same height from point ( ) to line ( AC ). The base ( AO ) of ( triangle DAO ) appears to be shorter than the base ( BC ) of ( triangle DBC ). Visually, ( triangle DAO ) seems to be about half the size of ( triangle DBC ). Therefore, reasonable estimate for the ratio of their areas is 0.5. The final answer is (e) 0.5. Gemini 1.5 Pro The triangle DAO appears to be roughly half the size of triangle DBC. Therefore, DBC is roughly twice as large as DAO, meaning that DAO is roughly 0.5 times larger than DBC. Final Answer: (e) (d) (e) 0. Table 24. Examples of dataset and model responses for Geometry-Area (2) 18 Image Question Gold Answer BAM is times larger in area than BMN. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.25 (b) 4 (c) 2 (d) 0.5 (e) 1 Model Answer w/ CoT InternVL2-4B To estimate the value of ( ), we need to visually compare the areas of triangles ( BAM ) and ( BMN ). 1. **Observation**: Triangle ( BAM ) is visually larger than triangle ( BMN ). 2. **Estimation**: By visually comparing the two triangles, it appears that ( BAM ) is roughly 4 times larger in area than ( BMN ). Therefore, the reasonable estimate for ( ) is 4. **Final Answer**: (b) 4 To estimate the ratio of the areas of triangles BAM and BMN, we can visually compare their sizes. 1. **Visual Comparison**: Triangle BAM appears to be significantly larger than triangle BMN. The base of triangle BAM (AB) is much longer than the base of triangle BMN (BN), and the height from point to BC is also greater than the height from point to BC. 2. **Area Relationship**: The area of triangle is given by the formula ( text{Area} = frac{1}{2} times text{base} times text{height} ). Since both triangles share the same height (the perpendicular distance from to BC), the ratio of their areas will be directly proportional to the ratio of their bases. 3. **Base Comparison**: The base of triangle BAM (AB) is approximately 4 times the length of the base of triangle BMN (BN). 4. **Area Ratio**: Given that the height is the same for both triangles, the area of triangle BAM will be approximately 4 times the area of triangle BMN. Therefore, the most reasonable estimate for the ratio of the areas of triangles BAM to BMN is 4. **Final Answer**: (b) 4 To estimate the ratio of the areas of triangles BAM and BMN, we can visually compare the bases and the heights of the triangles. 1. **Base Comparison**: The base of triangle BAM (AB) appears to be roughly twice the length of the base of triangle BMN (BN). This suggests that the area of triangle BAM will be approximately four times the area of triangle BMN, assuming the height remains constant. 2. **Height Comparison**: The height of triangle BAM (AM) appears to be roughly the same as the height of triangle BMN (MN). This means that the height does not significantly affect the area ratio, as the height is common factor in both triangles. Given these observations, the area of triangle BAM (ABM) is likely to be around four times the area of triangle BMN (BMN). Therefore, the correct answer is (b) 4. To estimate the area ratio between triangle BAM and triangle BMN, observe the following: 1. The height of triangle BAM from point to side BM is significantly larger than the height of triangle BMN from point to side BN. 2. The base lengths of both triangles are proportional to the segments BM and MN of line BC. Given that the height of BAM is roughly twice the height of BMN, and the base lengths are in similar proportion, the area of triangle BAM would be approximately four times the area of triangle BMN. Therefore, the reasonable estimate for the area ratio is 4. Final answer: (b) 4 Looking at the image, we can see triangle ABC with point on side AC and point on side BC. These points create two triangles: the larger triangle BAM and the smaller triangle BMN. Visually estimating the areas, it appears that triangle BAM is noticeably larger than triangle BMN, but not dramatically so. It looks to be about twice the size, give or take. Among the given options, the one that best matches this visual estimate is: (c) 2 This suggests that BAM is approximately 2 times larger in area than BMN, which seems reasonable based on the visual information provided in the diagram. Final answer: InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o From the image, triangle ( triangle BAM ) appears to be larger than triangle ( triangle BMN ). The area of ( triangle BAM ) seems to be approximately twice the area of ( triangle BMN ), as ( ) is roughly halfway along ( overline{AN} ) and ( overline{BM} ) is common side. Therefore, reasonable estimate for the ratio of the areas is 2. Final answer: (c) 2 Gemini 1.5 Pro Triangle BAM looks roughly twice the size of triangle BMN. Therefore, is approximately 2. Final Answer: (c) Table 25. Examples of dataset and model responses for Geometry-Area (3) Answer w/o CoT b (b) b (c) 19 Image Question Gold Answer In the figure, the line AB is diameter of circle. True or False? True Answer w/ CoT Answer w/o CoT Model InternVL2-4B InternVL2-8B InternVL2-26B True. The line AB is diameter of circle because it passes through the center of the circle, O, and connects two points on the circumference, and B. By definition, diameter is straight line passing from side to side through the center of circle or sphere. False. In the given figure, the line segment AB is not diameter of the circle. diameter is line segment that passes through the center of the circle and has its endpoints on the circle. However, in this figure, the line segment AB does not pass through the center of the circle (point O). Instead, it is chord that connects two points on the circumference of the circle. Therefore, AB is not diameter. To determine if the statement is true or false, we need to analyze the given figure. The line AB is shown as straight line passing through the center of the circle, which is characteristic of diameter. diameter is defined as straight line passing from side to side through the center of circle, thus dividing it into two equal parts. Given that AB passes through the center and extends from one side of the circle to the other, it meets the criteria of being diameter. Therefore, the statement is true. True. InternVL2-76B To determine if the line AB is diameter of the circle, we need to check if it passes through the center of the circle, denoted as O. From the figure, it is clear that the line AB does indeed pass through the center O. Therefore, AB is diameter of the circle. Final answer: True Claude 3.5 Sonnet GPT-4o Lets analyze this step-by-step: 1) In circle, diameter is defined as line segment that passes through the center of the circle and has its endpoints on the circle. Its the longest chord of the circle. 2) In this figure, we can see that line AB passes through point O, which appears to be the center of the circle. 3) Both points and are on the circumference of the circle. 4) The line AB divides the circle into two equal halves. 5) These characteristics are consistent with the definition of diameter. Therefore, based on the information provided in the image, the statement appears to be correct. Final answer: True In the figure, ( AB ) is chord of the circle, and ( ) is point on the circle such that ( triangle AEB ) is inscribed. For ( AB ) to be diameter, the angle ( angle AEB ) must be right angle (90 degrees) according to the inscribed angle theorem. However, the figure does not provide enough information to confirm that ( angle AEB ) is right angle. Therefore, based on the given information, we cannot conclude that ( AB ) is diameter. Final answer: False. Gemini 1.5 Pro diameter of circle is line segment that passes through the center of the circle and whose endpoints lie on the circle. In this figure, AB passes through point (the circles center) and points and lie on the circle. Final Answer: True True False True True True True."
        },
        {
            "title": "True",
            "content": "Table 26. Examples of dataset and model responses for Geometry-Diameter-Radius (1) 20 Image Question Gold Answer Model InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet In the figure, the line DC is diameter of circle. True or False? True Answer w/ CoT Answer w/o CoT True. The line DC passes through the center of the circle, O, and extends to both ends of the circle, touching the circumference at points and F. This means that DC is diameter of the circle. Final answer: True. False In the figure, the line segment CD is not diameter of the circle. diameter is line segment that passes through the center of the circle and has its endpoints on the circle. In the given figure, the line segment CD does not pass through the center of the circle, and therefore it is not diameter. To determine if the statement is true or false, we need to analyze the given figure. The figure shows circle with line segment DC passing through the center O. Since DC passes through the center of the circle and extends to both ends of the circle, it is diameter. Therefore, the statement the line DC is diameter of circle is true. True. To determine if the line DC is diameter of the circle, we need to check if it passes through the center of the circle and if its endpoints lie on the circle. From the figure, it is clear that: 1. The line DC passes through the center of the circle. 2. The endpoints and lie on the circumference of the circle. Since the line DC satisfies both conditions, it is indeed diameter of the circle. Final answer: True Lets analyze this step-by-step: 1. In circle, diameter is defined as line segment that passes through the center of the circle and has its endpoints on the circle. Its the longest chord of the circle. 2. In this figure, we can see that line DC passes through point O, which appears to be the center of the circle (as its typically denoted). 3. Both points and are on the circumference of the circle. 4. The line DC appears to divide the circle into two equal halves, which is property of diameter. 5. While we dont have explicit measurements, the visual representation strongly suggests that DC is indeed diameter. Reasoning: Given that DC passes through the center and has its endpoints on the circle, it meets the definition of diameter. Final answer: True True False True True"
        },
        {
            "title": "True",
            "content": "GPT-4o In the figure, ( DC ) is line that passes through the center ( ) of the circle, making it diameter. diameter is line segment that passes through the center of the circle and has its endpoints on the circle. Since ( DC ) meets these criteria, it is indeed diameter. Final answer: True. Gemini 1.5 Pro diameter is line segment that passes through the center of circle and whose endpoints lie on the circle. The line segment DC passes through the center and its endpoints and lie on the circle. Therefore, DC is diameter. Final Answer: The final answer is $boxed{True}$"
        },
        {
            "title": "True",
            "content": "Table 27. Examples of dataset and model responses for Geometry-Diameter-Radius (2) 21 Image Question Gold Answer In the figure, the line AO is radius of circle. True or False? True Answer w/ CoT Answer w/o CoT Model InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet True. Explanation: In the given figure, AO is line segment that starts from point and ends at point O, which is the center of the circle. Since is the center of the circle, AO is radius of the circle. Final answer: True True In the figure, the line segment AO is drawn from the center of the circle (point O) to point on the circumference (point A). By definition, any line segment that connects the center of circle to point on the circles circumference is radius. Therefore, AO is radius of the circle. In the given figure, the line segment AO is drawn from the center of the circle (O) to point on the circle (A). Since AO is line segment connecting the center of the circle to point on the circle, it is radius of the circle. Therefore, the statement In the figure, the line AO is radius of circle is true. True. The line AO is radius of the circle because it extends from the center of the circle (O) to point on the circle (A). By definition, radius is straight line from the center of circle to any point on its circumference. Therefore, AO meets this criterion and is indeed radius. Final answer: True Lets analyze this figure: 1. We see circle with three points labeled A, B, and on its circumference. 2. Theres line segment drawn from point to the center of the circle, labeled O. 3. By definition, radius of circle is line segment from the center of the circle to any point on its circumference. 4. The line AO meets this definition exactly - it goes from the center to point on the circumference. 5. While there are other line segments in the figure (BO and CO), were specifically asked about AO. Reasoning: Since AO is line segment that connects the center of the circle to point on its circumference, it fits the definition of radius perfectly. Final answer: True GPT-4o In the figure, ( ) is the center of the circle, and ( ) is point on the circle. The line ( AO ) connects the center of the circle to point on the circle, which is the definition of radius. Therefore, the statement is **True**. Gemini 1.5 Pro The center of the circle is labeled as O. radius of circle is any line segment that connects the center to point on the circumference (edge) of the circle. Point is on the circumference of the circle. The line segment AO connects the center to point on the circumference. Final Answer: True True True True True True True."
        },
        {
            "title": "True",
            "content": "Table 28. Examples of dataset and model responses for Geometry-Diameter-Radius (3) 22 Image Question Gold Answer CH 3 is attached to single line, not double line. True or False? You must answer this question using visual information and do not use knowledge of chemistry unless explicitly instructed to do so. False Answer w/ CoT Answer w/o CoT The image shows chemical structure where CH 3 is attached to single line, indicating single bond between the carbon and the hydrogen atoms. False True The image shows chemical structure where CH$ 3$ group is attached to nitrogen atom (N) via single line. This indicates single covalent bond between the CH$ 3$ group and the nitrogen atom. Therefore, the statement CH$ 3$ is attached to single line, not double line is true. Final answer: True InternVL2-26B The structure shows single line representing single bond between the carbon (C) and the nitrogen (N) atoms. The double line represents double bond between the carbon and the oxygen (O) atoms. Therefore, the statement CH 3 is attached to single line, not double line is true. True. InternVL2-76B The image shows chemical structure with CH$ 3$ group attached to nitrogen atom (N) via single line. This single line represents single covalent bond between the carbon of the CH$ 3$ group and the nitrogen atom. Final answer: True Claude 3.5 Sonnet Based on the visual information provided in the image: can see that the CH3 group is indeed attached to single line in the molecular structure diagram, not double line. The single line connects the CH3 group to what appears to be nitrogen atom (N) within the larger molecular structure. Final answer: True GPT-4o The CH$ 3$ group is attached to single line, which represents single bond. True. Gemini 1.5 Pro The CH$ 3$ is attached to what appears to be vertex where three lines meet. This is single bond, not double bond (which would be represented by two lines). Final Answer: True True True True False"
        },
        {
            "title": "True",
            "content": "Model InternVL2-4B InternVL2-8B Table 29. Examples of dataset and model responses for Chemistry-Shape-Single (1) Image Question Gold Answer and are attached to opposite vertices of hexagonal structure. True or False? You must answer this question using visual information and do not use knowledge of chemistry unless explicitly instructed to do so. False Model Answer w/ CoT InternVL2-4B The structure depicted in the image is hexagonal ring with alternating oxygen and nitrogen atoms. The hydrogen atoms (H a, b, c, d, e) are attached to the carbon atoms of the hexagonal ring. To determine if and are attached to opposite vertices of the hexagonal structure, we need to examine the positions of these hydrogen atoms in relation to the ring. - is attached to one of the carbon atoms of the hexagonal ring. - is also attached to one of the carbon atoms of the hexagonal ring. Since both and are attached to the same type of carbon atoms (carbon atoms of the hexagonal ring), they are not attached to opposite vertices of the hexagonal structure. Therefore, the statement is False. Final answer: False Answer w/o CoT True InternVL2-8B False. In the given structure, and are not attached to opposite vertices of hexagonal structure. Instead, they are both attached to the same carbon atom in the middle of the hexagonal ring. The hexagonal structure is formed by the six carbon atoms, and b, c, and are attached to the other carbon atoms in the ring. and are part of the same carbon atom, not opposite vertices of the hexagonal structure. False InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To determine if and are attached to opposite vertices of hexagonal structure, we need to examine the given chemical structure. 1. Identify the hexagonal structure: The hexagonal structure in the given chemical diagram is the benzene ring, which is six-membered ring with alternating double bonds. 2. Locate and d: is attached to one vertex of the benzene ring, and is attached to the opposite vertex of the same ring. 3. Verify the attachment: Since and are attached to opposite vertices of the benzene ring, the statement is true. Therefore, the final answer is True. To determine if and are attached to opposite vertices of hexagonal structure, we need to analyze the positions of these hydrogen atoms in the given molecular structure. 1. Identify the hexagonal structure: The hexagonal structure in the molecule is the six-membered ring containing alternating double bonds (the benzene ring). 2. Locate and d: - is attached to the carbon atom that is part of the hexagonal structure and is adjacent to the nitrogen atom in the five-membered ring. - is attached to the nitrogen atom in the five-membered ring that is directly connected to the hexagonal structure. 3. Determine their relative positions: - is attached to carbon atom on the hexagonal structure. - is attached to nitrogen atom that is part of the five-membered ring connected to the hexagonal structure. Since is not directly attached to the hexagonal structure but rather to an atom in the connected five-membered ring, and are not attached to opposite vertices of the hexagonal structure. Final answer: False To answer this question based solely on the visual information provided in the image: Ill examine the structure and the positions of Ha and Hd. The structure is not simple hexagon, but rather fused bicyclic system. Ha is attached to carbon at the junction of the two rings, which forms one of the vertices of the overall structure. Hd is attached to nitrogen atom that is part of one of the rings, but not at vertex opposite to Ha. The positions of Ha and Hd are not at opposite corners or vertices of the overall structure. They are on the same side of the molecule as depicted. Based on this visual analysis: False. Ha and Hd are not attached to opposite vertices of the structure shown in the image. GPT-4o and are attached to adjacent vertices of the hexagonal structure, not opposite ones. They are on the same side of the hexagon. False. Gemini 1.5 Pro and are attached to the same carbon atom, which forms vertex of the hexagonal structure. They are not attached to opposite vertices. False. True False"
        },
        {
            "title": "False",
            "content": "Table 30. Examples of dataset and model responses for Chemistry-Shape-Single (2) 24 Image Question Gold Answer and are attached to opposite vertices of the hexagonal structure. True or False? You must answer this question using visual information and do not use knowledge of chemistry unless explicitly instructed to do so. False Answer w/ CoT Answer w/o CoT Model InternVL2-4B InternVL2-8B InternVL2-26B The image shows hexagonal ring structure with double bond (indicated by the double line) between two of the vertices. The hydrogen (H) and oxygen (O) atoms are attached to the vertices of the hexagon, not necessarily opposite each other. Final answer: False. False. The hexagonal structure in the image is benzene ring, which is common aromatic ring in organic chemistry. In the given structure, the oxygen atom (O) is attached to one of the carbon atoms in the ring, and the hydrogen atom (H) is attached to another carbon atom. These two atoms are not located at opposite vertices of the hexagonal structure. Instead, they are adjacent to each other within the ring. Therefore, the statement that and are attached to opposite vertices of the hexagonal structure is false. To determine if and are attached to opposite vertices of the hexagonal structure, we need to examine the positions of and in the given diagram. In the diagram, the hexagonal structure is benzene ring. The oxygen (O) is attached to one vertex of the hexagon, and the hydrogen (H) is attached to another vertex, which is directly opposite the oxygen. This means that and are indeed attached to opposite vertices of the hexagonal structure. Therefore, the statement is true. True. InternVL2-76B The hexagonal structure in the image represents benzene ring. The hydrogen (H) and oxygen (O) atoms are attached to adjacent carbon atoms in the ring, not to opposite vertices. Therefore, the statement is false. Final answer: False Claude 3.5 Sonnet To answer this question based solely on the visual information provided in the image: can see that the (oxygen) atom is attached to one of the vertices of the hexagonal structure at the top. The (hydrogen) atom is attached to different vertex, which is not directly opposite to the O. The appears to be attached to vertex that is one position clockwise from the bottom vertex of the hexagon. For the and to be on opposite vertices, they would need to be at the top and bottom of the hexagon, or on opposite corners of the sides. This is not the case in the image. Therefore, based purely on the visual information: False. and are not attached to opposite vertices of the hexagonal structure. GPT-4o In the image, the hexagonal structure represents cyclohexane ring. The oxygen (O) is attached to one vertex of the hexagon, and the hydrogen (H) is attached to different vertex. However, they are not on opposite vertices of the hexagon. Final answer: False. Gemini 1.5 Pro The Oxygen (O) is attached to vertex of the hexagon. The Hydrogen (H) is attached to point along the edge of the hexagon below the Oxygen and adjacent to the isopropyl group (the two CH3s attached to central carbon). Therefore, they are not at opposite vertices. False. False False True False False"
        },
        {
            "title": "False",
            "content": "Table 31. Examples of dataset and model responses for Chemistry-Shape-Single (3) 25 Image Question Gold Answer List all figures that satisfy the following conditions from a, b, c, and d. You must answer this question using visual information and do not need to use your knowledge of chemistry unless explicitly instructed to do so. Conditions: Including hexagonal structure. a,b,c,d Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To determine which figures satisfy the condition of including hexagonal structure, we need to identify the figures that have hexagon within their structure. - Figure (a) shows hexagonal ring structure. - Figure (b) does not have hexagonal structure. - Figure (c) does not have hexagonal structure. - Figure (d) does not have hexagonal structure. Therefore, the only figure that satisfies the condition of including hexagonal structure is figure (a). Final answer: The figures that satisfy the condition of including hexagonal structure are: - (a) and (b) Explanation: - Figure (a) clearly shows hexagonal structure. - Figure (b) also shows hexagonal structure. - Figures (c) and (d) do not have hexagonal structure. Therefore, the figures that satisfy the condition are (a) and (b). To determine which figures satisfy the condition of including hexagonal structure, we need to identify the structures that have hexagonal ring within them. - Figure (a) has benzene ring, which is hexagon. - Figure (b) has benzene ring, which is hexagon. - Figure (c) has benzene ring, which is hexagon. - Figure (d) has benzene ring, which is hexagon. All four figures (a, b, c, and d) have hexagonal structure, specifically benzene ring. Final answer: a, b, c, To determine which figures satisfy the condition of including hexagonal structure, we need to visually inspect each figure for the presence of hexagon. - Figure (a): This figure shows hexagonal structure with double bond attached to one of the carbons. - Figure (b): This figure also shows hexagonal structure with double bond attached to one of the carbons. - Figure (c): This figure shows hexagonal structure with two double bonds attached to two different carbons. - Figure (d): This figure shows hexagonal structure with double bond attached to one of the carbons. All figures (a, b, c, and d) include hexagonal structure. Final answer: a, b, c, Lets examine each figure: (a) This structure has hexagonal ring with an external double bond attached. (b) This structure has hexagonal ring with an external double bond attached to the ring itself. (c) This structure has hexagonal ring with an external methyl group attached. (d) This structure has hexagonal ring with an internal double bond and an external methyl group. All of these structures (a, b, c, and d) satisfy the condition of including hexagonal structure. Each figure shows six-membered ring, which is the defining characteristic of hexagonal structure in organic chemistry notation. Explanation: hexagonal structure in this context refers to the six-sided ring that forms the base of each molecule depicted. This hexagonal ring is present in all four figures, regardless of the additional features like double bonds or methyl groups. Final answer: a, b, c, Answer w/o CoT a, b, c, a, b, c, a, b, c, a, b, c, a, b, c, GPT-4o All the figures (a, b, c, and d) include hexagonal structure. Each structure has six-membered ring, which is the hexagonal part. Final answer: a, b, c, d. Gemini 1.5 Pro All of the figures (a, b, c, and d) include hexagonal structure as the base of their molecule. Each one has six-sided ring. Final Answer: a, b, c, a, b, c, a, b, c, Table 32. Examples of dataset and model responses for Chemistry-Shape-Multi (1) Image Question Gold Answer List all figures that satisfy the following conditions from a, b, c, and d. You must answer this question using visual information and do not need to use your knowledge of chemistry unless explicitly instructed to do so. Conditions: Including pentagonal structure. Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet To determine which figures satisfy the condition of including pentagonal structure, we need to identify the figures that have five-sided polygon (pentagon). - Figure (a) is bicyclic compound with five-membered ring, which is pentagon. - Figure (b) is benzene ring, which is hexagon. - Figure (c) is bicyclic compound with five-membered ring, which is pentagon. - Figure (d) is square, which is four-sided polygon. Based on this analysis, figures (a) and (c) satisfy the condition of including pentagonal structure. Final answer: a, To identify the figures that include pentagonal structure, we need to examine each figure for the presence of five-sided polygon. - **Figure (a)**: This structure contains pentagonal ring. - **Figure (b)**: This structure contains hexagonal ring. - **Figure (c)**: This structure contains pentagonal ring. - **Figure (d)**: This structure contains linear structure with chlorine atom at each end. Based on the conditions provided, the figures that include pentagonal structure are (a) and (c). **Final answer: (a, c)** To determine which figures satisfy the condition of including pentagonal structure, we need to identify the structures that have five-sided shape. - Figure (a) shows pentagonal structure with two chlorine atoms attached to it. - Figure (b) is hexagonal structure with three chlorine atoms attached to it. - Figure (c) is triangular structure with three chlorine atoms attached to it. - Figure (d) is square structure with one chlorine atom attached to it. The only figure that includes pentagonal structure is (a). Final answer: (a) To determine which figures include pentagonal structure, we need to visually inspect each figure for five-sided polygon. - Figure (a) contains five-sided ring, which is pentagon. - Figure (b) contains six-sided ring, which is hexagon. - Figure (c) contains three-sided ring, which is triangle. - Figure (d) contains four-sided ring, which is square. Based on this analysis, the only figure that includes pentagonal structure is (a). Final answer: (a) Lets examine each figure: (a) This structure shows pentagonal (five-sided) ring with two chlorine atoms attached. (b) This structure shows hexagonal (six-sided) ring with two chlorine atoms attached. (c) This structure shows triangular shape with four chlorine atoms attached. (d) This structure shows square (four-sided) ring with two chlorine atoms attached. Reasoning: The question asks for figures that include pentagonal structure. Looking at the shapes, only one of these figures contains five-sided ring, which is the definition of pentagonal structure. Final answer: GPT-4o The figure that includes pentagonal structure is (a). It has five-sided ring, which is characteristic of pentagon. Final answer: Gemini 1.5 Pro The condition is including pentagonal structure. Figure (a) contains pentagon. Final Answer: The final answer is $boxed{a}$ Answer w/o CoT (b), (c), (d) a, b, a Table 33. Examples of dataset and model responses for Chemistry-Shape-Multi (2) 27 Image Question Gold Answer List all figures that satisfy the following conditions from a, b, c, and d. You must answer this question using visual information and do not need to use your knowledge of chemistry unless explicitly instructed to do so. Conditions: Including pentagonal structure. Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B To determine which figures satisfy the condition of including pentagonal structure, we need to identify the structures that have five-membered ring. - Figure (a) shows benzene ring, which is hexagonal structure. - Figure (b) shows benzene ring, which is hexagonal structure. - Figure (c) shows benzene ring, which is hexagonal structure. - Figure (d) shows benzene ring, which is hexagonal structure. None of the figures (a, b, c, or d) include pentagonal structure. Final answer: None of the figures (a, b, c, or d) satisfy the condition of including pentagonal structure. To identify the figures that include pentagonal structure, we need to examine each figure for the presence of five-sided polygon. - **Figure (a)**: This structure is hexagon, not pentagon. - **Figure (b)**: This structure is hexagon, not pentagon. - **Figure (c)**: This structure is hexagon, not pentagon. - **Figure (d)**: This structure is pentagon. Therefore, the only figure that includes pentagonal structure is **Figure (d)**. Final answer: (d) To determine which figures satisfy the condition of including pentagonal structure, we need to identify the structures that have five-sided ring. - Figure (a) shows pentagonal structure with methyl group attached to one of the vertices. - Figure (b) shows pentagonal structure with methyl group attached to one of the vertices. - Figure (c) shows pentagonal structure with hydroxyl group attached to one of the vertices. - Figure (d) shows pentagonal structure with chlorine atom attached to one of the vertices. All four figures (a, b, c, and d) satisfy the condition of including pentagonal structure. Final answer: a, b, c, To determine which figures satisfy the condition of including pentagonal structure, we need to visually inspect each figure for the presence of five-sided ring. - Figure (a) contains five-membered ring with one oxygen atom, which is pentagonal structure. - Figure (b) also contains five-membered ring with one oxygen atom, which is pentagonal structure. - Figure (c) contains five-membered ring with one oxygen atom and hydroxyl group, which is pentagonal structure. - Figure (d) contains five-membered ring with one chlorine atom, which is pentagonal structure. All figures (a, b, c, and d) include pentagonal structure. Final answer: a, b, c, a,d Answer w/o CoT (a), (b), (c), (d) a, a, b, c, a, b, c, Claude 3.5 Sonnet Lets examine each figure for pentagonal structure: (a) This molecule has pentagonal (5-sided) ring structure. (b) This molecule has 7-membered ring, not pentagonal. (c) This molecule also has 7-membered ring, not pentagonal. (d) This molecule has pentagonal (5-sided) ring structure. Reasoning: pentagonal structure is defined by having 5 sides or vertices. Only figures (a) and (d) contain 5-membered ring, which satisfies the condition of including pentagonal structure. Final answer: a, GPT-4o All the figures (a, b, c, and d) include pentagonal structure. Each structure has five-membered ring, which is pentagon. Final answer: a, b, c, d. Gemini 1.5 Pro The figures (a), (b), (c), and (d) all depict pentagonal structures as part of their molecular diagrams. Final Answer: a, b, c, a, a, b, c, a, b, c, Table 34. Examples of dataset and model responses for Chemistry-Shape-Multi (3) Image Question Gold Answer Answer the following question about the chart in the figure. Select the most reasonable answer from the provided options. Stock Index of Dow Jones on 28 Jan is (a) 200 (b) 350 (c) 250 (d) 0.08 (e) 3000 Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B To determine the Stock Index of Dow Jones on 28 Jan, we need to look at the chart labeled Dow Jones in the figure. The chart shows the Dow Jones index with time series from 14 Jan to 29 Oct. On 28 Jan, the Dow Jones index is clearly marked on the chart. The value is approximately 250. Therefore, the most reasonable answer is: (c) 250 Final answer: (c) 250 To determine the stock index of Dow Jones on 28 Jan, we need to look at the graph corresponding to the Dow Jones index. The graph shows the index value over time. Upon examining the graph, we can see that on 28 Jan, the Dow Jones index is around the 350 mark. This is visually confirmed by locating the date 28 Jan on the x-axis and finding the corresponding value on the y-axis. Therefore, the correct answer is: (b) To determine the stock index of Dow Jones on 28 Jan, we need to look at the graph corresponding to the Dow Jones index. The graph shows the index values over time. On 28 Jan, the graph shows the index value at point that is just above 250. The closest value to this point on the graph is 250. Therefore, the most reasonable answer is (c) 250. Final answer: (c) 250 InternVL2-76B The chart for the Dow Jones shows the stock index value over time. On 28 Jan, the value is just above 3000, which is closest to option (e) 3000. Final answer: (e) 3000 Claude 3.5 Sonnet To answer this question, Ill look at the Dow Jones chart in the image, which is the third chart from the top on the left side. Looking at the Dow Jones chart, we can see that on 28 Jan (the start date of the chart), the stock index value is approximately 200. The options given are: (a) 200 (b) 350 (c) 250 (d) 0.08 (e) 3000 Among these, 200 is the closest to the actual value shown on the chart for 28 Jan. Explanation: The Dow Jones chart clearly shows the stock index starting at around 200 on 28 Jan. The other values are either too high (350, 250, 3000) or represent completely different scale (0.08) that doesnt match the y-axis of the chart. Final answer: (a) GPT-4o The chart for the Dow Jones is located in the middle row on the left side. On January 28, the stock index value is approximately 350. The most reasonable answer is (b) 350. Gemini 1.5 Pro The question asks for the Stock Index of Dow Jones on 28 Jan. The Dow Jones plot is the third row, left side. We look for 28 Jan on the x-axis of this plot. The corresponding value on the y-axis is approximately 200. Final Answer: The final answer is $boxed{a}$ Table 35. Examples of dataset and model responses for Charts-Extraction (1) Answer w/o CoT (e) 3000 b) 350 (b) 350 (c) 29 Image Question Gold Answer Answer the following question about the chart in the figure. Select the most reasonable answer from the provided options. The value of SC of N=500 in graph (ii) is: (a) 0.195% (b) 0.045% (c) 0.170% (d) 0.095% (e) 0.145% Answer w/o CoT (e) 0.145% (b) 0.045% (b) 0.045% Model InternVL2-4B InternVL2-8B InternVL2-26B Answer w/ CoT To determine the value of SC for N=500 in graph (ii), we need to look at the bar corresponding to N=500 in the SC category. The bar reaches up to the 0.15 mark on the RMAE axis. Reasoning: - The bar for N=500 in the SC category is clearly visible and reaches the 0.15 mark on the RMAE axis. Final Answer: (c) 0.170% To determine the value of SC (Standardized Coefficient) for N=500 in graph (ii), we need to look at the height of the SC bar for N=500. The SC bar for N=500 is the third bar from the left in the graph (ii). The height of the SC bar for N=500 is approximately 0.045% on the y-axis. Therefore, the correct answer is: (b) 0.045% To determine the value of SC for N=500 in graph (ii), we need to look at the bar corresponding to SC in the N=500 column. The bar for SC is the one with the blue dashed pattern. From the graph, the height of the SC bar for N=500 is just above 0.1 on the y-axis, which represents the RMAE (Root Mean Absolute Error) percentage. The closest value to this height from the given options is 0.145%. Therefore, the most reasonable answer is (e) 0.145%. Final answer: (e) 0.145% InternVL2-76B In graph (ii), the SC (Shortest Chain) for N=500 is represented by the blue bar. The height of the bar corresponds to the value on the y-axis, which is approximately 0.045%. Therefore, the correct answer is (b) 0.045%. (d) 0.095% Claude 3.5 Sonnet GPT-4o To answer this question, Ill examine graph (ii) in the image and look at the SC (striped) bar for N=500. Looking at graph (ii), the SC bar for N=500 is very small, barely visible above the x-axis. The y-axis for this graph goes from 0.00 to 0.20, with tick marks at 0.05, 0.10, and 0.15. The SC bar for N=500 appears to be just slightly above 0.00, but definitely below the 0.05 mark. Among the given options, 0.045% (which is equivalent to 0.00045 on the scale of the graph) is the closest match to what we can see. Therefore, the most reasonable answer is (b) 0.045%. Final answer: To determine the value of SC for ( N=500 ) in graph (ii), we need to look at the height of the SC bar in the middle graph. The SC bar is represented by the striped pattern with red outline. By examining the graph, the SC bar for ( N=500 ) in graph (ii) appears to be slightly below the 0.05 mark on the RMAE axis. Therefore, the most reasonable answer is: (b) 0.045% Gemini 1.5 Pro The y-axis of the graph (ii) represents RMAE values. We look for the bar that corresponds to SC and N=500. The height of this bar is slightly below 0.05. Among the choices provided, the closest value is 0.045 (b). Final Answer: The final answer is $boxed{b}$ (b) 0.045% Table 36. Examples of dataset and model responses for Charts-Extraction (2) Image Question Gold Answer Answer the following question about the chart in the figure. Select the most reasonable answer from the provided options. PPL of NEXUS at Perturbation = 0.08 is (a) 5x10ˆ2 (b) 1x10ˆ2 (c) 4x10ˆ2 (d) 3x10ˆ2 (e) 2x10ˆ2 Model Answer w/ CoT InternVL2-4B InternVL2-8B InternVL2-26B To determine the PPL (Perplexity) of NEXUS at perturbation of 0.08, we need to locate the point on the graph where the perturbation value is 0.08 and then find the corresponding PPL value on the y-axis. 1. Locate the perturbation value of 0.08 on the x-axis. 2. Draw vertical line from the perturbation value of 0.08 up to the NEXUS line. 3. Draw horizontal line from the point where the vertical line intersects the NEXUS line to the y-axis. From the graph, the PPL value at perturbation of 0.08 for NEXUS is approximately 2x10ˆ2. Final answer: (e) 2x10ˆ2 To determine the PPL (Posterior Predictive Likelihood) of NEXUS at Perturbation = 0.08, we need to locate the point on the graph where the perturbation value is 0.08 and identify the corresponding PPL value on the y-axis. 1. Locate the perturbation value of 0.08 on the x-axis. 2. Observe the line corresponding to NEXUS (blue line with diamond markers). 3. Find the y-value (PPL) at the point where the perturbation is 0.08. From the graph, at Perturbation = 0.08, the PPL for NEXUS is approximately 3x10ˆ2. Therefore, the correct answer is (d) 3x10ˆ2. To determine the PPL of NEXUS at Perturbation = 0.08, we need to locate the point on the graph where the perturbation is 0.08 and find the corresponding PPL value for NEXUS. 1. Locate the point on the x-axis where Perturbation = 0.08. 2. Follow the vertical line up from this point to the graph lines. 3. Identify the line corresponding to NEXUS (cyan diamond markers). 4. The PPL value at this point is approximately 3x10ˆ2. Therefore, the PPL of NEXUS at Perturbation = 0.08 is 3x10ˆ2. Final answer: (d) 3x10ˆ Answer w/o CoT e) 2x10ˆ2 (d) 3x10ˆ2 InternVL2-76B At Perturbation = 0.08, the PPL of NEXUS is indicated by the cyan line with diamond markers. The value on the graph at this perturbation level is approximately 3x10ˆ2. Final answer: (d) 3x10ˆ2 (d) 3x10ˆ2 Claude 3.5 Sonnet To answer this question, Ill look at the line for NEXUS on the graph at the perturbation value of 0.08 on the x-axis. Following the NEXUS line (light blue with diamond markers) to the 0.08 mark on the x-axis, can see that the corresponding y-axis value is just above the 3x10ˆ2 mark. The PPL value for NEXUS at 0.08 perturbation appears to be slightly higher than 3x10ˆ2, but definitely lower than 4x10ˆ2. The closest option provided is 3x10ˆ2. Therefore, the most reasonable answer is (d) 3x10ˆ2. Final answer: GPT-4o To determine the PPL of NEXUS at Perturbation = 0.08, we need to look at the cyan diamond line on the graph. At Perturbation = 0.08, the PPL value for NEXUS is approximately 3x10ˆ2. Therefore, the most reasonable answer is: (d) 3x10ˆ2 Gemini 1.5 Pro The NEXUS line has diamond marker. At Perturbation = 0.08, the NEXUS line corresponds to PPL value of just above 3x10ˆ2. Final Answer: (d) Table 37. Examples of dataset and model responses for Charts-Extraction (3) 31 Image Question Gold Answer In the left chart in the figure, the lines for 10 eV and 100 eV do not intersect between x-value=60 and 80. True or False? False Model Answer w/ CoT InternVL2-4B The lines for 10 eV and 100 eV intersect between x-value=60 and 80. **Explanation:** Upon examining the left chart in the figure, it is evident that the lines representing 10 eV and 100 eV intersect at some point between x-value=60 and 80. This can be observed by the crossing of the two lines within this range of x-values. **Final Answer:** False InternVL2-8B The lines for 10 eV and 100 eV in the left chart do not intersect between x-value=60 and 80. The 10 eV line is consistently above the 100 eV line throughout this range. Final answer: True. InternVL2-26B The lines for 10 eV (green) and 100 eV (purple) do not cross each other between x-values 60 and 80. The green line is always above the purple line within this range. True. InternVL2-76B The left chart shows the lines for 10 eV and 100 eV as separate and distinct without any intersection points between the x-values of 60 and 80. Therefore, the correct answer is True. Claude 3.5 Sonnet GPT-4o Lets examine the left chart (a) carefully: 1. The 10 eV line (green with circles) is decreasing steadily throughout the graph. 2. The 100 eV line (purple with circles) is relatively flat with some small fluctuations. 3. Between x-values of 60 and 80, we can see that: - The 10 eV line continues its downward trend - The 100 eV line remains relatively stable Importantly, these two lines do not cross each other in the interval between x=60 and x=80. The 100 eV line remains above the 10 eV line throughout this range. Therefore, the statement is correct. Final answer: True To determine if the lines for 10 eV and 100 eV intersect between x-values 60 and 80 in the left chart, we need to examine the lines closely. The 10 eV line is represented by green circles, and the 100 eV line is represented by purple diamonds. Upon inspection, the green circles (10 eV) and purple diamonds (100 eV) do not cross each other between x-values 60 and 80. The green line remains above the purple line throughout this range. Therefore, the statement is **True**. Gemini 1.5 Pro The 10 eV (light green, dotted line with circles) and 100 eV (purple, dotted line with pentagons) lines do appear to intersect between x-value=60 and 80 on the left chart in the figure. Final Answer: False Answer w/o CoT True True True True False True"
        },
        {
            "title": "True",
            "content": "Table 38. Examples of dataset and model responses for Charts-Intersection (1) 32 Image Question Gold Answer In the figure, the lines for India and the Taliban intersect between 2012 and 2014. True or False? False Model InternVL2-4B Answer w/ CoT The lines for India and the Taliban do not intersect between 2012 and 2014. The line for India shows decrease in concern from 59% in 2012 to 38% in 2014, while the line for the Taliban shows an increase from 23% in 2012 to 33% in 2013. False Answer w/o CoT False InternVL2-8B True. The lines for India and the Taliban intersect between 2012 and 2014 at the point where both are at 38% in 2013. InternVL2-26B The lines for India and the Taliban intersect at point between 2012 and 2014. In 2012, the percentage for India is higher than the Taliban, but by 2014, the percentage for the Taliban has increased to the point where it intersects with Indias line, indicating that the concern about the Taliban as threat to Pakistan is equal to the concern about India during that period. Therefore, the final answer is True. InternVL2-76B True. The lines for India and the Taliban intersect between 2012 and 2014, as indicated by the graph where the orange line (India) and the green line (Taliban) cross each other. True Claude 3.5 Sonnet Lets examine the graph carefully: 1. The line for India (orange) shows sharp decline from 2012 to 2013, dropping from 59% to 38%. 2. The line for the Taliban (green) shows an increase from 2012 to 2013, rising from 23% to 35%. 3. Between 2013 and 2014, the India line rises again to 51%, while the Taliban line drops to 25%. Crucially, we can see that the lines for India and the Taliban do cross each other between 2012 and 2014. This intersection occurs sometime in 2013, when Indias perceived threat level dropped below the Talibans before rising again. Therefore, the statement is correct. Final answer: True GPT-4o The lines for India and the Taliban intersect between 2012 and 2014. In 2013, the percentage for India is 38, and for the Taliban, it is 33. In 2014, the percentage for India is 51, and for the Taliban, it is 25. This indicates that the lines intersected between these years. True. Gemini 1.5 Pro The lines for India and the Taliban intersect between the years 2012 and 2013, which is within the range of 2012 and 2014. Final Answer: True Table 39. Examples of dataset and model responses for Charts-Intersection (2) True True True False"
        },
        {
            "title": "True",
            "content": "33 Image Question Gold Answer In the figure, the lines for China and U.S. intersect between 2009 and 2011. True or False? True Answer w/ CoT Answer w/o CoT Model InternVL2-4B InternVL2-8B The lines for China and the U.S. do not intersect between 2009 and 2011. The line representing China shows steady increase in the percentage of respondents who see China as the leading economic power during this period, while the line for the U.S. shows decrease. Final answer: False. False. The lines for China and the U.S. do not intersect between 2009 and 2011. The line for China starts at 29 in 2008, increases to 40 in 2010, and then rises to 57 in 2012. The line for the U.S. starts at 44 in 2008, decreases to 37 in 2011, and then increases to 33 in 2012. The two lines do not cross each other during this period. InternVL2-26B The lines for China and U.S. intersect at point between 2009 and 2011, as can be seen where the green line (U.S.) crosses the orange line (China) on the graph. True InternVL2-76B True. The lines for China and U.S. intersect between the years 2009 and 2011, indicating crossover point where the perception of leading economic power shifted from the U.S. to China according to the median across the 5 European nations surveyed. The graph shows that in 2009, the U.S. was seen as the leading economic power by larger percentage than China. However, by 2011, China surpassed the U.S. in this perception, as indicated by the point where the two lines cross. Claude 3.5 Sonnet Lets examine the graph closely: 1. In 2009, the U.S. line is at 28% while Chinas line is at 33%. 2. In 2010, the U.S. line rises to 37% while Chinas line rises to 40%. 3. In 2011, the U.S. line continues to rise to 47% while Chinas line rises to 44%. We can see that between 2009 and 2011, the lines for China and the U.S. do indeed cross each other. The intersection occurs somewhere between 2010 and 2011, as Chinas percentage starts higher but is overtaken by the U.S. during this period. Therefore, the statement is True. GPT-4o The lines for China and the U.S. intersect between 2009 and 2011. In 2009, both are at 44%, and after that, Chinas line rises above the U.S. line. Therefore, the statement is true. True. Gemini 1.5 Pro The lines intersect between 2009 and 2010, not between 2009 and 2011. Final Answer: False False False False True"
        },
        {
            "title": "True",
            "content": "Table 40. Examples of dataset and model responses for Charts-Intersection (3) 34 Image Question Gold Answer There is triangle CBG in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. False Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro True True True True True True True Table 41. Examples of dataset and model responses for Syntheticgeometry-Triangle (1) Image Question Gold Answer There is triangle AKI in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. True Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro True False True True False True True Table 42. Examples of dataset and model responses for Syntheticgeometry-Triangle (2) 36 Image Question Gold Answer There is triangle GEF in the figure. True or False? triangle is polygon with three edges and three vertices, which are explicitly connected in the figure. False Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro True True True True True False True Table 43. Examples of dataset and model responses for Syntheticgeometry-Triangle (3) Image Question Gold Answer There is no quadrilateral CBAD in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). False Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro True False True False False True False Table 44. Examples of dataset and model responses for Syntheticgeometry-Quadrilateral (1) 38 Image Question Gold Answer There is quadrilateral HFDE in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). True Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro False True True True True True False Table 45. Examples of dataset and model responses for Syntheticgeometry-Quadrilateral (2) Image Question Gold Answer There is no quadrilateral EMPQ in this figure. True or False? quadrilateral is four-sided polygon having four edges (sides) and four corners (vertices). True Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro True False True False False True False Table 46. Examples of dataset and model responses for Syntheticgeometry-Quadrilateral (3) 40 Image Question Gold Answer Line BG is times longer than DF. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 1 (b) 2 (c) 4 (d) 0.5 (e) 0.25 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b) 2 (c) (b) Table 47. Examples of dataset and model responses for Syntheticgeometry-Length (1) Image Question Gold Answer Line CE is times longer than AC. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.5 (b) 4 (c) 0.25 (d) 1 (e) 2 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b (b) 4 (e) 2 (e) 2 Table 48. Examples of dataset and model responses for Syntheticgeometry-Length (2) 42 Image Question Gold Answer Line CF is times longer than JM. Which of the following options is reasonable estimate of X? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 4 (b) 1 (c) 2 (d) 0.5 (e) 0.25 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro a) 4 (a) 4 (c) (c) 2 Table 49. Examples of dataset and model responses for Syntheticgeometry-Length (3) Image Question Gold Answer Which of the following options is reasonable estimate of the angle CFB in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 90 degrees (b) 10 degrees (c) 180 degrees (d) 135 degrees (e) 45 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro a) 90 degrees (a) 90 degrees (e) 45 degrees e Table 50. Examples of dataset and model responses for Syntheticgeometry-Angle (1) 44 Image Question Gold Answer Which of the following options is reasonable estimate of the angle LIA in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 45 degrees (b) 90 degrees (c) 180 degrees (d) 135 degrees (e) 10 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro d) 135 degrees a) 45 degrees (b) 90 degrees (a) 45 degrees (a) 45 degrees Table 51. Examples of dataset and model responses for Syntheticgeometry-Angle (2) Image Question Gold Answer Which of the following options is reasonable estimate of the angle FDE in the figure? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 90 degrees (b) 10 degrees (c) 135 degrees (d) 45 degrees (e) 180 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro d) 45 degrees a) 90 degrees (a) 90 degrees (d) 45 degrees (d) 45 degrees Table 52. Examples of dataset and model responses for Syntheticgeometry-Angle (3) 46 Image Question Gold Answer AEB is times larger in area than ECBA. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 2 (b) 0.25 (c) 1 (d) 0.5 (e) 4 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro (a) 2 (d) 0. (a) 2 Table 53. Examples of dataset and model responses for Syntheticgeometry-Area (1) Image Question Gold Answer EADJ is times larger in area than ABD. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.25 (b) 4 (c) 0.5 (d) 2 (e) 1 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b (b) 4 (b) 4 c Table 54. Examples of dataset and model responses for Syntheticgeometry-Area (2) 48 Image Question Gold Answer AEB is times larger in area than BAC. Which of the following options is reasonable estimate? You only need to estimate from the visual information and do not need to do any mathematical reasoning. (a) 0.25 (b) 4 (c) 2 (d) 0.5 (e) 1 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro (b) 4 (b) (c) 2 Table 55. Examples of dataset and model responses for Syntheticgeometry-Area (3) Image Question Gold Answer The blue cylinder is times taller than the red sphere. Which of the following options is reasonable estimate? (a) 2 (b) 0.5 (c) 1 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b) 0.5 (c) 1 (a) 1 a Table 56. Examples of dataset and model responses for 3D-Size (1) 50 Image Question Gold Answer The cyan cylinder is times taller than the brown cylinder. Which of the following options is reasonable estimate? (a) 0.5 (b) 1 (c) 2 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro (b) 1 (c) 2 (c) c Table 57. Examples of dataset and model responses for 3D-Size (2) Image Question Gold Answer The yellow rubber sphere is times wider than the yellow cube. Which of the following options is reasonable estimate? (a) 1 (b) 0.5 (c) 2 Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b) 0.5 (a) 1 (a) 1 a Table 58. Examples of dataset and model responses for 3D-Size (3) 52 Image Question Gold Answer Which of the following options is reasonable estimate of the angle between the directions of the gray motorcycle and the brown airplane in the figure? We define 0 degrees if the direction is the same and 180 degrees if the direction is opposite. (a) 180 degrees (b) 45 degrees (c) 0 degrees (d) 135 degrees (e) 90 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro (a) 180 degrees (e) 90 degrees d Table 59. Examples of dataset and model responses for 3D-Angle (1) Image Question Gold Answer Which of the following options is reasonable estimate of the angle between the directions of the left blue car and the fighter jet in the figure? We define 0 degrees if the direction is the same and 180 degrees if the direction is opposite. (a) 90 degrees (b) 135 degrees (c) 180 degrees (d) 0 degrees (e) 45 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro b) 135 degrees (a) 90 degrees (a) 90 degrees b Table 60. Examples of dataset and model responses for 3D-Angle (2) 54 Image Question Gold Answer Which of the following options is reasonable estimate of the angle between the directions of the airplane and the purple motorcycle in the figure? We define 0 degrees if the direction is the same and 180 degrees if the direction is opposite. (a) 90 degrees (b) 180 degrees (c) 135 degrees (d) 45 degrees (e) 0 degrees Model Answer w/ CoT Answer w/o CoT InternVL2-4B InternVL2-8B InternVL2-26B InternVL2-76B Claude 3.5 Sonnet GPT-4o Gemini 1.5 Pro (a) 90 degrees (a) 90 degrees a Table 61. Examples of dataset and model responses for 3D-Angle (3)"
        }
    ],
    "affiliations": [
        "Penn State University"
    ]
}