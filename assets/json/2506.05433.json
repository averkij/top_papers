{
    "paper_title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward",
    "authors": [
        "Zikang Liu",
        "Tongtian Yue",
        "Yepeng Tang",
        "Longteng Guo",
        "Junxian Cai",
        "Qingbin Liu",
        "Xi Chen",
        "Jing Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Group Relative Policy Optimization (GRPO) enhances policy learning by computing gradients from relative comparisons among candidate outputs that share a common input prefix. Despite its effectiveness, GRPO introduces substantial computational overhead when processing long shared prefixes, which must be redundantly encoded for each group member. This inefficiency becomes a major scalability bottleneck in long-context learning scenarios. We propose Prefix Grouper, an efficient GRPO training algorithm that eliminates redundant prefix computation via a Shared-Prefix Forward strategy. In particular, by restructuring self-attention into two parts, our method enables the shared prefix to be encoded only once, while preserving full differentiability and compatibility with end-to-end training. We provide both theoretical and empirical evidence that Prefix Grouper is training-equivalent to standard GRPO: it yields identical forward outputs and backward gradients, ensuring that the optimization dynamics and final policy performance remain unchanged. Empirically, our experiments confirm that Prefix Grouper achieves consistent results while significantly reducing the computational cost of training, particularly in long-prefix scenarios. The proposed method is fully plug-and-play: it is compatible with existing GRPO-based architectures and can be seamlessly integrated into current training pipelines as a drop-in replacement, requiring no structural modifications and only minimal changes to input construction and attention computation. Prefix Grouper enables the use of larger group sizes under the same computational budget, thereby improving the scalability of GRPO to more complex tasks and larger models. Code is now available at https://github.com/johncaged/PrefixGrouper"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 ] . [ 1 3 3 4 5 0 . 6 0 5 2 : r Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward Zikang Liu1,2, Tongtian Yue1,2, Yepeng Tang3, Longteng Guo1, Junxian Cai4, Qingbin Liu4, Xi Chen4, Jing Liu1,2 1Institute of Automation, Chinese Academy of Sciences 2School of Artificial Intelligence, University of Chinese Academy of Sciences 3School of Computer Science and Technology, Beijing Jiaotong University 4Basic Algorithm Center, Tencent {liuzikang2023,yuetongtian2022}@ia.ac.cn, yepengtang@bjtu.edu.cn {jasoncjxcai,qingbinliu,jasonxchen}@tencent.com {longteng.guo,jliu}@nlpr.ia.ac.cn"
        },
        {
            "title": "Abstract",
            "content": "Group Relative Policy Optimization (GRPO) enhances policy learning by computing gradients from relative comparisons among candidate outputs that share common input prefix. Despite its effectiveness, GRPO introduces substantial computational overhead when processing long shared prefixes, which must be redundantly encoded for each group member. This inefficiency becomes major scalability bottleneck in long-context learning scenarios. We propose Prefix Grouper, an efficient GRPO training algorithm that eliminates redundant prefix computation via Shared-Prefix Forward strategy. In particular, by restructuring self-attention into two parts, our method enables the shared prefix to be encoded only once, while preserving full differentiability and compatibility with end-to-end training. We provide both theoretical and empirical evidence that Prefix Grouper is training-equivalent to standard GRPO: it yields identical forward outputs and backward gradients, ensuring that the optimization dynamics and final policy performance remain unchanged. Empirically, our experiments confirm that Prefix Grouper achieves consistent results while significantly reducing the computational cost of training, particularly in long-prefix scenarios. The proposed method is fully plug-and-play: it is compatible with existing GRPO-based architectures and can be seamlessly integrated into current training pipelines as drop-in replacement, requiring no structural modifications and only minimal changes to input construction and attention computation. Prefix Grouper enables the use of larger group sizes under the same computational budget, thereby improving the scalability of GRPO to more complex tasks and larger models. Code is now available at https://github.com/johncaged/PrefixGrouper."
        },
        {
            "title": "Introduction",
            "content": "Group Relative Policy Optimization (GRPO) [1] has emerged as an effective framework for optimizing large language models in reinforcement learning. It avoids explicit value function estimation by comparing multiple candidate outputs generated from the same input and updating the policy based on their relative rankings. This group-based formulation reduces gradient variance and improves Equal contribution. Corresponding Author. Technical Report. training stability. GRPO has been widely applied to large-scale reasoning tasks, such as instruction following and chain-of-thought learning [2, 3, 4, 5, 6, 7, 8]. Although GRPO improves training efficiency, it also introduces critical inefficiency. Each training instance forms group of candidates that share common input prefix (e.g., prompts or instructions). However, during the forward pass, this shared input prefix must be re-encoded independently for each group member, resulting in redundant computation that scales with the group size. In long-context reinforcement learning tasks, the prefix often constitutes substantial portion of the total input sequence. This overhead significantly increases training cost and memory usage, thereby creating major bottleneck to scalability. To address this issue, we propose Prefix Grouper, an efficient GRPO training algorithm that eliminates redundant prefix computation via Shared-Prefix Forward strategy. This design enables the shared input prefix to be encoded only once, regardless of the group size, by restructuring attention computation without modifying the model architecture. Our core idea is to split the self-attention computation into two parts. One part performs self-attention over only the shared prefix tokens to update their contextual representations. The other computes query embeddings from the suffix tokens, while using the full sequence (prefix + suffix) to compute keys and values. The suffix tokens then attend to both prefix and suffix via concat-attention mechanism to obtain updated representations. Notably, unlike standard key-value caching mechanisms that are typically designed for inference and do not support gradient backpropagation, our method preserves full differentiability and remains compatible with end-to-end training. We provide both theoretical and empirical evidence that Prefix Grouper is training-equivalent to standard GRPO. Theoretically, we prove that Prefix Grouper yields identical forward outputs and backward gradients to those of the standard GRPO formulation, ensuring that the optimization dynamics and final policy performance remain unchanged. Empirically, we validate this equivalence through extensive experiments, showing that Prefix Grouper achieves consistent performance while significantly reducing the computational cost of training. It can be seamlessly integrated into current training pipelines without requiring any structural modifications and only involves modifying few lines of code related to input construction and attention computation. The computational savings are especially pronounced in scenarios with long shared prefixes. By reducing redundant computation, Prefix Grouper allows for larger group sizes within the same computational budget, thereby enhancing the scalability of GRPO methods to more complex tasks and larger models. Our main contributions are as follows: We identify key inefficiency in standard GRPO training: shared input prefixes are repeatedly encoded for each group member, resulting in significant computational overhead that limits scalability in long-context reinforcement learning. We introduce Prefix Grouper, general and implementation-friendly GRPO training algorithm that eliminates redundant prefix computation via Shared-Prefix Forward strategy. Prefix Grouper is fully plug-and-play and compatible with existing GRPO-based architectures. We provide theoretical guarantees of gradient equivalence and computational efficiency. Extensive experiments further demonstrate that Prefix Grouper significantly accelerates training in long-prefix scenarios without compromising policy performance."
        },
        {
            "title": "2 Prefix Grouper for GRPO",
            "content": "As is mentioned above, traditional GRPO implementations suffer from redundant computations when processing long query prefixes (e.g., multi-modal inputs like video tokens), as the same prefix is repeatedly encoded for each group member. This inefficiency becomes pronounced with larger group sizes, which are essential for reducing advantage variance. To address this, we introduce Prefix Grouper, novel algorithm that eliminates redundant prefix computations by leveraging shared-prefix forward. In this section, we will first introduce the algorithm, and then analyze the gradient equivalence and computational savings of Prefix Grouper. 2 Figure 1: Method illustration of Grouped Attention in Prefix Grouper. 2.1 Algorithm implementation For clarity, we assume forward batch size of 1, where the input consists of single query prefix R1LD (typically containing system prompts, multi-modal inputs, and questions). Given group size G, the model samples response candidates {R1, R2, . . . , RG} from , where each Ri R1LiD. Traditional approaches, which we refer to as Repeated-Prefix Forward, process the inputs as follows: xi = [P ; Ri], Xbase = pad(x1, x2, . . . , xG), (1) where pad denotes length-padding operation, resulting in Xbase R1(L+max(L1,L2,...,LG))D. In Prefix Grouper, we instead concatenate the shared prefix with all response suffixes along the sequence dimension: Xours = [P ; R1; R2; . . . ; RG], (2) where Xours R1(L+L1++LG)D. It is obvious that the concatenated samples maintain equivalence with Repeated-Prefix Forward in word embedding and FFN layers. While Repeated-Prefix Forward directly applies self-attention: = Attn(Q, K, V, mask), (3) where the rollouts per prefix lead to redundant computation on the repeated prefix in Xbase, particularly significant for long prefixes. In contrast, our method decomposes the attention computation into two kernel calls (which we refer to as Grouped Attention): Oprefix = Attn(Qprefix, Kprefix, Vprefix, maskprefix), Osuffix = Attn(Qsuffix, Kprefix+suffix, Vprefix+suffix, maskprefix+suffix), = group(Oprefix, Osuffix), (4) where group(, ) represents concatenating using index select. For positional encoding (using RoPE or its variants), we set the position id of each token the same as the corresponding position in the Repeated-Prefix Forward. The complete process of Grouped Attention in Prefix Grouper is summarized in Algorithm 1 and Figure 1. 2.2 Gradient equivalence of Prefix Grouper critical property of Prefix Grouper is its theoretical equivalence to Repeated-Prefix Forward in both forward outputs and backward gradients. Forward equivalence is self-evident: every token undergoes 3 Algorithm 1 Pseudocode of Grouped Attention in PyTorch-like style def grouped_attention(self, q, k, v, prefix_grouper, **kwargs): \"\"\" q, k, v: Shape [b, num_heads, seq_len, head_dim]. q, should be pre-processed with RoPE in advance. prefix_grouper: plug-and-play module implemented by us. kwargs: Any arguments needed by the attention operation. \"\"\" # Split the concatenated samples into prefix and suffix q_prefix, k_prefix, v_prefix, q_suffix, k_suffix, v_suffix = prefix_grouper.ungroup(q, k, v) # Attention call prefix_attn_output, _ = attention_interface( self, q_prefix, k_prefix, v_prefix, # NOTE: Attention mask is pre-computed by prefix_grouper prefix_grouper.prefix_attn_mask.to(q_prefix.device), **kwargs, ) suffix_attn_output, _ = attention_interface( self, q_suffix, prefix_grouper.batch_repeat_cat(k_prefix, k_suffix, cat_dim=2), prefix_grouper.batch_repeat_cat(v_prefix, v_suffix, cat_dim=2), # NOTE: Attention mask is pre-computed by prefix_grouper prefix_grouper.suffix_attn_mask.to(q_prefix.device), **kwargs, ) # Concatenate the prefix and suffix output # The input shape should be [b, seq_len, num_heads, head_dim] attn_output = prefix_grouper.group(prefix_attn_output, suffix_attn_output) return attn_output, None attention_interface: the attention operation; prefix_grouper: implemented using torch.autograd.Function. fundamentally identical computations in both algorithms. Gradient equivalence is demonstrated below: Lemma 2.1 (Gradient Equivalence) Under the Grouped Attention in our Prefix Grouper, the gradients of the policy loss function with respect to model parameters θ are identical to those computed by the original GRPO algorithm, i.e., θJours(Xours, A) θJbase(Xbase, A), (5) where denotes the advantage of the rollout responses. Proof. See Appendix A. This property ensures that Prefix Groupers computational efficiency gains come without trade-offs, which means it accelerates training and reduces GPU memory while preserving model performance identically. 2.3 Computational cost analysis of Prefix Grouper Prefix Grouper employs the Shared-Prefix Forward approach, which demonstrates increasingly significant advantages over Repeated-Prefix Forward as group size grows: Lemma 2.2 (Computation Reduction) Given group size and sequence lengths Lp (prefix), Lr (response), when Lp Lr, Prefix Grouper reduces FLOPs to 1 Proof. See Appendix A.2 of the Repeated-Prefix Forward approach. Under long-prefix scenarios (e.g., multi-modal inputs or extended text contexts), Prefix Grouper effectively reduces computational load and memory consumption, requiring only marginal computational increase as group size scales, demonstrating its superior efficiency. 4 2.4 Futher discussion Similar to the GRPO training process, our Prefix Grouper can be extended to other shared-prefix inference scenarios requiring computational efficiency. representative application is multi-QA judge modeling: given long response R, the model processes multiple short questions {Q1, Q2, . . . , Qk} sharing as context. The acceleration is achieved by computing perplexity-based predictions exclusively from hidden states at final tokens of each question, enabling single-token prediction for evaluation metrics or rewards."
        },
        {
            "title": "3 Experiment",
            "content": "3.1 Computational overhead Figure 2: Comparison of FLOPs under different group sizes. The figure displays results at fixed prefix lengths (4096, 8192, and 16384) across different Ratios (prefix length / suffix length). Comparison of computational overhead is shown in Figure 2. Within any given group size investigated (2, 4, 8, or 16), Prefix Grouper (\"Ours\") consistently demonstrates significant computational advantage over the \"Baseline\" approach. This superiority is evidenced by the markedly lower Floating Point Operations (FLOPs) required by our method across all tested configurations (@4096, @8192, @16384) and ratios. The consistent reduction in computational load for the same group size underscores the enhanced efficiency and practical benefits of our proposed technique. 3.2 Memory usage Figure 3 illustrates comparative analysis of GPU memory usage between Prefix Grouper (\"Ours\") and the \"Baseline\" approach, evaluated under identical group size conditions of 2, 4, 8, and 16. Across all tested group sizes, clear and consistent pattern indicates that our method achieves substantial reduction in GPU memory consumption when compared directly to the baseline for all configurations Figure 3: Comparison of memeory usage under different group sizes. The figure displays results at fixed prefix lengths (4096, 8192, and 16384) across different Ratios (prefix length / suffix length). (@4096, @8192, @16384) and over the entire range of ratios. Our method consistently maintains significantly lower memory footprint."
        },
        {
            "title": "4 Conclusion",
            "content": "We present Prefix Grouper, an efficient algorithm for Group Relative Policy Optimization (GRPO) that eliminates redundant computation of shared input prefixes through novel Shared-Prefix Forward strategy. By restructuring attention into two kernel callsencoding prefixes once while enabling suffixes to attend to full contextsour method achieves identical forward outputs and backward gradients to standard GRPO, preserving optimization dynamics. This implementation-agnostic approach substantially reduces training costs, particularly for long-context tasks, and serves as drop-in replacement to enhance GRPOs scalability without compromising policy performance."
        },
        {
            "title": "References",
            "content": "[1] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. [2] An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, et al. Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122, 2024. [3] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Zamani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025. 6 [4] Haozhan Shen, Peng Liu, Jingcheng Li, Chunxin Fang, Yibo Ma, Jiajia Liao, Qiaoli Shen, Zilun Zhang, Kangjia Zhao, Qianqian Zhang, et al. Vlm-r1: stable and generalizable r1-style large vision-language model. arXiv preprint arXiv:2504.07615, 2025. [5] Wenxuan Huang, Bohan Jia, Zijie Zhai, Shaosheng Cao, Zheyu Ye, Fei Zhao, Zhe Xu, Yao Hu, and Shaohui Lin. Vision-r1: Incentivizing reasoning capability in multimodal large language models. arXiv preprint arXiv:2503.06749, 2025. [6] Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Benyou Wang, and Xiangyu Yue. Video-r1: Reinforcing video reasoning in mllms. arXiv preprint arXiv:2503.21776, 2025. [7] Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, and Limin Wang. Videochat-r1: Enhancing spatio-temporal perception via reinforcement fine-tuning. arXiv preprint arXiv:2504.06958, 2025. [8] Ye Wang, Boshen Xu, Zihao Yue, Zihan Xiao, Ziheng Wang, Liang Zhang, Dingyi Yang, Wenxuan Wang, and Qin Jin. Timezero: Temporal video grounding with reasoning-guided lvlm. arXiv preprint arXiv:2503.13377, 2025."
        },
        {
            "title": "A Proof",
            "content": "A.1 Proof of Gradient Equivalence Proof (1 of 2) For clarity, we assume batch size = 1. For transformer with parameters θ, the total gradient θJ is the sum of per-token contributions: θJ = (cid:88) t= ht (cid:124) (cid:123)(cid:122) token ts gradient contribution (cid:125) θht , (6) Jt(ht) (e.g., next-token prediction) where ht is the hidden state at position t. This holds under additive loss decomposition: = (cid:80) We decompose the transformer architecture into two computational categories: 1. Attention operations: = Attn(Q, K, ). 2. Pointwise operations: MLP, QKV projections, and normalization layers. All learnable parameters reside in pointwise operations. Gradient equivalence is established by analyzing each category separately. Part 1: Attention Gradient Consider the attention output and its gradients Q,K,V O. For suffix tokens (Ri), both implementations compute identical gradients due to equivalent computational paths: Qsuffix,Ksuffix,Vsuffix Oours Qsuffix,Ksuffix,Vsuffix Obase. For prefix tokens (P ), the gradient is calculated as follows: Pi(Q,K,V )Obase = Pi(Q,K,V )Oprefix (cid:125) (cid:124) (cid:123)(cid:122) prefix-only + Pi(Q,K,V )Osuffix , (cid:125) (cid:123)(cid:122) response interaction (cid:124) (Q,K,V )Oours = (Q,K,V )Oprefix + 1 (cid:88) i=1 (cid:0)P (Q,K,V )Osuffix (cid:1) . Part 2: Pointwise Operation Gradient For any pointwise operation parameter θ, gradients are computed as: θJbase = 1 (cid:32) (cid:88) (cid:88) i=1 tPi Jbase ht θht + (cid:88) tRi Jbase ht (cid:33) θht , θJours = (cid:88) tP Jours ht θht + 1 (cid:88) (cid:88) i=1 tRi Jours ht θht. In the final output, the GRPO loss depends only on response tokens Ri: P, ht = 0 (both algorithms), (7) (8) (9) (10) (11) (12) so based on Eq. 10 and Eq. 11, the gradients of the final FFN and output embedding layers are equivalent in both algorithms. For the attention part, we have: 1 (cid:88) i= Pi(Q,K,V )Obase = (Q,K,V )Oours, (13) 8 Proof (2 of 2) so substitute Eq. 13 into Eq. 10 and Eq. 11, we have: θJbase = ="
        },
        {
            "title": "1\nG",
            "content": "(cid:32) (cid:88) (cid:88) tPi i=1 (cid:88) (cid:88) i=1 tPi Jbase ht θht + (cid:88) tRi Jbase ht (cid:33) θht Jbase ht θht +"
        },
        {
            "title": "1\nG",
            "content": "G (cid:88) (cid:88) i=1 tRi Jbase ht θht (cid:88) = Jours ht tP = θJours. θht +"
        },
        {
            "title": "1\nG",
            "content": "G (cid:88) (cid:88) i=1 tRi Jours ht θht (14) Therefore, through layer-by-layer backpropagation, gradient equivalence propagates upstream from output layers. Thus, θJours(Xours, A) θJbase(Xbase, A) for all parameters θ. 9 A.2 Proof of Computation Reduction Proof For clarity, we assume batch size = 1 and uniform response length Lr across all responses. Let Lp denote prefix length, head dimension, and number of attention heads. The computational complexity is analyzed separately for causal attention and pointwise operations (MLP & QKV projections). Causal Attention Operation: The baseline Repeated-Prefix Forward method computes: Our Prefix Grouper decomposes attention into prefix and suffix components: attn = G(Lp + Lr)2dn Cbase attn = L2 Cours pdn (cid:124) (cid:123)(cid:122) (cid:125) prefix self-attn + GLr(2Lp + Lr)dn (cid:123)(cid:122) (cid:125) suffix attn (cid:124) The complexity ratio simplifies to:"
        },
        {
            "title": "Cours\nattn\nCbase\nattn",
            "content": "= = L2 L2 pdn + GLr(2Lp + Lr)dn G(Lp + Lr)2dn + GLr(2Lp + Lr) G(Lp + Lr)2 As Lp Lr, the asymptotic limit is: lim Lp/Lr Cours attn Cbase attn = L2 GL2 = 1 (15) (16) (17) (18) Pointwise Operation: Let Cffn denote FLOPs per token for MLP and projections. The baseline requires: while Prefix Grouper computes: Cbase pointwise = G(Lp + Lr)Cffn Cours pointwise = LpCffn + GLrCffn The asymptotic ratio is: lim Lp/Lr Cours pointwise Cbase pointwise = lim Lp/Lr Lp + GLr G(Lp + Lr) = 1 (19) (20) (21) Conclusion: Both attention and pointwise operations exhibit O(1/G) complexity reduction under Lp Lr conditions."
        }
    ],
    "affiliations": [
        "Basic Algorithm Center, Tencent",
        "Institute of Automation, Chinese Academy of Sciences",
        "School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "School of Computer Science and Technology, Beijing Jiaotong University"
    ]
}