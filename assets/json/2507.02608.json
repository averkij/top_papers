{
    "paper_title": "Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation",
    "authors": [
        "François Rozet",
        "Ruben Ohana",
        "Michael McCabe",
        "Gilles Louppe",
        "François Lanusse",
        "Shirley Ho"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The steep computational cost of diffusion models at inference hinders their use as fast physics emulators. In the context of image and video generation, this computational drawback has been addressed by generating in the latent space of an autoencoder instead of the pixel space. In this work, we investigate whether a similar strategy can be effectively applied to the emulation of dynamical systems and at what cost. We find that the accuracy of latent-space emulation is surprisingly robust to a wide range of compression rates (up to 1000x). We also show that diffusion-based emulators are consistently more accurate than non-generative counterparts and compensate for uncertainty in their predictions with greater diversity. Finally, we cover practical design choices, spanning from architectures to optimizers, that we found critical to train latent-space emulators."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 3 ] . [ 1 8 0 6 2 0 . 7 0 5 2 : r Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation François Rozet1,2,3 Ruben Ohana1,2 Michael McCabe1,4 Shirley Ho1,2,4,5 François Lanusse1,2,6 Gilles Louppe3 1Polymathic AI 2Flatiron Institute 3University of Liège 4New York University 5Princeton University 6Université Paris-Saclay, Université Paris Cité, CEA, CNRS, AIM"
        },
        {
            "title": "Abstract",
            "content": "The steep computational cost of diffusion models at inference hinders their use as fast physics emulators. In the context of image and video generation, this computational drawback has been addressed by generating in the latent space of an autoencoder instead of the pixel space. In this work, we investigate whether similar strategy can be effectively applied to the emulation of dynamical systems and at what cost. We find that the accuracy of latent-space emulation is surprisingly robust to wide range of compression rates (up to 1000). We also show that diffusionbased emulators are consistently more accurate than non-generative counterparts and compensate for uncertainty in their predictions with greater diversity. Finally, we cover practical design choices, spanning from architectures to optimizers, that we found critical to train latent-space emulators."
        },
        {
            "title": "Introduction",
            "content": "Numerical simulations of dynamical systems are at the core of many scientific and engineering disciplines. Solving partial differential equations (PDEs) that describe the dynamics of physical phenomena enables, among others, weather forecasts [1, 2], predictions of solar wind and flares [35], or control of plasma in fusion reactors [6, 7]. These simulations typically operate on fine-grained spatial and temporal grids and require significant computational resources for high-fidelity results. To address this limitation, promising strategy is to develop neural network-based emulators to make predictions orders of magnitude faster than traditional numerical solvers. The typical approach [817] is to consider the dynamics as function (xi) = xi+1 that evolves the state xi of the system and to train neural network fϕ(x) to approximate that function. In the context of PDEs, this network is sometimes called neural solver [11, 18, 19]. After training, the autoregressive application of the solver, or rollout, emulates the dynamics. However, recent studies [11, 1821] reveal that, while neural solvers demonstrate impressive accuracy for short-term prediction, errors accumulate over the course of the rollout, leading to distribution shifts between training and inference. This phenomenon is even more severe for stochastic or undetermined systems, where it is not possible to predict the next state given the previous one(s) with certainty. Instead of modeling the uncertainty, neural solvers produce single point estimate, usually the mean, instead of distribution. The natural choice to alleviate these issues are generative models, in particular diffusion models, which have shown remarkable results in recent years. Following their success, diffusion models have been applied to emulation tasks [18, 19, 2225] for which they were found to mitigate the rollout instability of non-generative emulators. However, diffusion models are much more expensive than deterministic alternatives at inference, due to their iterative sampling process, which defeats the purpose of using an emulator. To address this computational drawback, many works in the image and Preprint. Under review. video generation literature [2632] consider generating in the latent space of an autoencoder. This approach has been adapted with success to the problem of emulating dynamical systems [3337], sometimes even outperforming pixel-space emulation. In this work, we seek to answer simple question: What is the impact of latent-space compression on emulation accuracy? To this end, we train and systematically evaluate latent-space emulators across wide range of compression rates for challenging dynamical systems from TheWell [38]. Our results indicate that i. Latent-space emulation is surprisingly robust to the compression rate, even when autoencoder reconstruction quality greatly degrades. ii. Latent-space emulators match or exceed the accuracy of pixel-space emulators, while using fewer parameters and less training compute. iii. Diffusion-based emulators consistently outperform their non-generative counterparts in both accuracy and plausibility of the emulated dynamics. Finally, we dedicate part of this manuscript to design choices. We discuss architectural and modeling decisions for autoencoders and diffusion models that enable stable training of latent-space emulators under high compression. To encourage further research in this direction, we provide the code for all experiments at https://github.com/polymathicai/lola along with pre-trained model weights."
        },
        {
            "title": "2 Diffusion models",
            "content": "The primary purpose of diffusion models (DMs) [39, 40], also known as score-based generative models [41, 42], is to generate plausible data from distribution p(x) of interest. Formally, continuoustime diffusion models define series of increasingly noisy distributions ˆ ˆ p(xt) = p(xt x) p(x) dx = (xt αt x, σ I) p(x) dx (1) such that the ratio αt/σt R+ is monotonically decreasing with the time [0, 1]. For such series, there exists family of reverse-time stochastic differential equations (SDEs) [4244] 1 + η2 2 g2 xt log p(xt) (cid:20) ft xt dt + η gt dwt dxt = (2) (cid:21) where η 0 is parameter controlling stochasticity, the coefficients ft and gt are derived from αt and σt [4244], and for which the variable xt follows p(xt). In other words, we can draw noise samples x1 p(x1) (0, σ2 1I) and obtain data samples x0 p(x0) p(x) by solving Eq. (2) from = 1 to 0. For high-dimensional samples, the terminal signal-to-noise ratio α1/σ1 should be at or very close to zero [45]. In this work, we adopt the rectified flow [28, 46, 47] noise schedule, for which αt = 1 and σt = t. In practice, the score function xt log p(xt) in Eq. (2) is unknown, but Denoising score matching can be approximated by neural network trained via denoising score matching [48, 49]. Several equivalent parameterizations and objectives have been proposed for this task [4042, 47, 50, 51]. In this work, we adopt the denoiser parameterization dϕ(xt, t) and its objective [51] arg min ϕ Ep(x)p(t)p(xtx) (cid:104) λt dϕ(xt, t) x2 2 (cid:105) , (3) for which the optimal denoiser is the mean E[x xt] of p(x xt). Importantly, E[x xt] is linked to the score function through Tweedies formula [5255] E[x xt] = xt + σ2 xt log p(xt) αt , (4) which allows to use sϕ(xt) = σ2 (dϕ(xt, t) αt xt) as score estimate in Eq. (2)."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we detail and motivate our experimental methodology for investigating the impact of compression on the accuracy of latent-space emulators. To summarize, we consider three challenging 2 Figure 1. Illustration of the latent-space emulation process. At each step of the autoregressive rollout, the diffusion model generates the next = 4 latent states zi+1:i+n given the current state zi and the simulation parameters θ. After rollout, the generated latent states are decoded to pixel space. datasets from TheWell [38]. For each dataset, we first train series of autoencoders with varying compression rates. These autoencoders learn to map high-dimensional physical states xi RHW Cpixel to low-dimensional latent representations zi Clatent . Subsequently, for each autoencoder, we train two emulators operating in the latent space: diffusion model (generative) and neural solver (non-generative). Both are trained to predict the next latent states zi+1:i+n given the current latent state zi and simulation parameters θ. This technique, known as temporal bundling [11], mitigates the accumulation of errors during rollout by decreasing the number of required autoregressive steps. After training, latent-space emulators are used to produce autoregressive rollouts z1:L starting from known initial state z0 = Eψ(x0) and simulation parameters θ, which are then decoded to the pixel space as ˆxi = Dψ(zi). W"
        },
        {
            "title": "3.1 Datasets",
            "content": "To study the effects of extreme compression rates, the datasets we consider should be high-dimensional and contain large amounts of data. Intuitively, the effective size of the dataset decreases in latent space, making overfitting more likely at fixed model capacity. According to these criteria, we select three datasets from TheWell [38]. Additional details are provided in Appendix B. Euler Multi-Quadrants The Euler equations model the behavior of compressible non-viscous fluids. In this dataset, the initial state presents multiple discontinuities which result in interacting shock waves as the system evolves for 100 steps. The 2d state of the system is represented with three scalar fields (energy, density, pressure) and one vector field (momentum) discretized on 512 512 grid, for total of Cpixel = 5 channels. Each simulation has either periodic or open boundary conditions and different heat capacity γ, which constitutes their parameters θ. In order to have noticeable movement between two consecutive states xi and xi+1, we set time stride = 4 such that the simulation time τ = . Rayleigh-Bénard (RB) The Rayleigh-Bénard convection phenomenon occurs when an horizontal layer of fluid is heated from below and cooled from above. Over the 200 simulation steps, the temperature difference leads to the formation of convection currents where cooler fluid sinks and warmer fluid rises. The 2d state of the system is represented with two scalar fields (buoyancy, pressure) and one vector field (velocity) discretized on 512 128 grid, for total of Cpixel = 4 channels. Each simulation has different Rayleigh and Prandtl numbers as parameters θ. In order to have noticeable movement between two consecutive states xi and xi+1, we set time stride = 4. Turbulence Gravity Cooling (TGC) The interstellar medium can be modeled as turbulent fluid subject to gravity and radiative cooling. Starting from an homogeneous state, dense filaments form in the fluid, leading to the birth of stars. The 3d state of the system is represented with three scalar fields (density, pressure, temperature) and one vector field (velocity) discretized on 64 64 64 grid, for total of Cpixel = 6 channels. Each simulation has different initial conditions function of their density, temperature, and metallicity. We set time stride = 1."
        },
        {
            "title": "3.2 Autoencoders",
            "content": "To isolate the effect of compression, we use consistent autoencoder architecture and training setup across datasets and compression rates. We focus on compressing individual states xi into latent states zi = Eψ(xi), which are reconstructed as ˆxi = Dψ(zi). 3 Architecture We adopt convolution-based autoencoder architecture similar to the one used by Rombach et al. [26], which we adapt to perform well under high compression rates. Specifically, inspired by Chen et al. [31], we initialize the downsampling and upsampling layers near identity, which enables training deeper architectures with complex latent representations, while preserving reconstruction quality. For 2d datasets (Euler and RB), we set the spatial downsampling factor = 32 for all autoencoders, meaning that 32 32 patch in pixel space corresponds to one token in latent space. For 3d datasets (TGC), we set = 8. The compression rate is then controlled solely by varying the number of channels per token in the latent representation. For instance, with the Euler dataset, an autoencoder with Clatent = 64 latent channels f32c64 in the notations of Chen et al. [31] transforms the input state with shape 512 512 5 to latent state with shape 16 16 64, yielding compression rate of 80. This setup ensures that the architectural capacity remains similar for all autoencoders and allows for fair comparison across compression rates. Further details as well as short ablation study are provided in Appendix B. Training Latent diffusion models [26] often rely on Kullback-Leibler (KL) divergence penalty to encourage latents to follow standard Gaussian distribution. However, this term is typically down-weighted by several orders of magnitude to prevent severe reconstruction degradation. As such, the KL penalty acts more as weak regularization than proper variational objective [56] and post-hoc standardization of latents is often necessary. We replace this KL penalty with deterministic saturating function (cid:55) (cid:112)1 + z2/B (5) applied to the encoders output. In our experiments, we choose the bound = 5 to mimic the range of standard Gaussian distribution. We find this approach simpler and more effective at structuring the latent space, without introducing tradeoff between regularization and reconstruction quality. We additionally omit perceptual [57] and adversarial [58, 59] loss terms, as they are designed for natural images where human perception is the primary target, unlike physics. The training objective thus simplifies to an L1 reconstruction loss arg min ψ Ep(x) (cid:13)x Dψ(Eψ(x))(cid:13) (cid:2)(cid:13) (cid:13) (cid:3) . (6) Finally, we find that preconditioned optimizers [6062] greatly accelerate the training convergence of autoencoders compared to the widespread Adam [63] optimizer (see Table 4). We adopt the PSGD [60] implementation in the heavyball [64] library for its fewer number of tunable hyperparameters and lower memory footprint than SOAP [62]."
        },
        {
            "title": "3.3 Diffusion models",
            "content": "t p(zi We train diffusion models to predict the next latent states zi+1:i+n given the current state zi and simulation parameters θ, that is to generate from p(zi+1:i+n zi, θ). We parameterize our diffusion models with denoiser dϕ(zi:i+n , θ, t) whose task is to denoise sequences of noisy states zi zi) = (zi I) given the parameters θ of the simulation. Conditioning with respect to known elements in the sequence zi:i+n is tackled with binary mask {0, 1}n+1 concatenated to the input. For instance, = (1, 0, . . . , 0) indicates that the first element zi is known, while = (1, . . . , 1, 0) indicates that the first 1 elements zi:i+n1 are known. Known elements are provided to the denoiser without noise. αt zi, σ2 Figure 2. Illustration of the denoisers inputs and outputs, while generating from p(zi+1:i+n zi, θ). Architecture Drawing inspiration from recent successes in latent image generation [2731], we use transformer-based architecture for the denoiser. We incorporate several architectural refinements shown to improve performance and stability, including query-key normalization [65], rotary positional embedding (RoPE) [66, 67], and value residual learning [68]. The transformer operates on the spatial and temporal axes of the input zi:i+n , while the parameters θ and diffusion time modulate the transformer blocks. Thanks to the considerable (r = 32) spatial downsampling performed by the autoencoder, we are able to apply full spatio-temporal attention, avoiding the need for sparse attention 4 patterns [6971]. Finally, we fix the token embedding size (1024) and the number of transformer blocks (16) for all diffusion models. The only architectural variation stems from the number of input and output channels dictated by the corresponding autoencoder. Training As in Section 2, diffusion models are trained via denoising score matching [48, 49] arg min ϕ p(θ,zi:i+n,zi:i+n (cid:104)(cid:13) (cid:13)dϕ(zi:i+n + zi:i+n )p(b) (1 b), b, θ, t) zi:i+n(cid:13) 2 (cid:13) (cid:105) (7) with the exception that the data does not come from the pixel-space distribution p(θ, x1:L) but from the latent-space distribution p(θ, z1:L) determined by the encoder Eψ. Following Voleti et al. [72], we randomly sample the binary mask p(b) during training to cover several conditioning tasks, including prediction with context p(zi+c:i+n zi:i+c1) and backward temporal prediction p(zi:i+n1 zi+n). We find this random masking strategy to slightly improve convergence and generalization [72, 73]. Sampling After training, we sample from the learned distribution by solving Eq. (2) with η = 0, which corresponds to the probability flow ODE [42]. To this end, we implement 3rd order AdamsBashforth multi-step method [74, 75]. Intuitively, this method leverages information from previous integration steps to improve accuracy. We find this approach highly effective, producing highquality samples with significantly fewer neural function evaluations (NFEs) than other widespread samplers [50, 51]."
        },
        {
            "title": "3.4 Neural solvers",
            "content": "We train neural solvers to perform the same task as diffusion models. Unlike the latter, however, solvers do not generate from p(zi+1:i+n zi, θ), but produce point estimate fϕ(zi, θ) E(cid:2)zi+1:i+n zi, θ(cid:3) instead. We also train pixel-space neural solver, for which zi = xi, as baseline. Architecture For latent-space neural solvers, we use the same transformer-based architecture as for diffusion models. The only notable difference is that transformer blocks are only modulated with respect to the simulation parameters θ. For the pixel-space neural solver, we keep the same architecture, but group the pixels into 16 16 patches, as in vision transformers [76]. We also double the token embedding size (2048) such that the pixel-space neural solver has roughly two times more trainable parameters than an autoencoder and latent-space emulator combined."
        },
        {
            "title": "Training Neural solvers are trained via mean regression",
            "content": "arg min ϕ Ep(θ,zi:i+n)p(b) (cid:104)(cid:13) (cid:13)fϕ(zi:i+n b, b, θ) zi:i+n(cid:13) 2 (cid:13) 2 (cid:105) . (8) Apart from the training objective, the training configuration (optimizer, learning rate schedule, batch size, masking, ...) for neural solvers is strictly the same as for diffusion models."
        },
        {
            "title": "3.5 Evaluation metrics",
            "content": "We consider several metrics for evaluation, each serving different purpose. We report these metrics either at lead time τ = or averaged over lead time horizon : b. If the states xi present several fields, the metric is first computed on each field separately, then averaged. Variance-normalized RMSE The root mean squared error (RMSE) and its normalized variants are widespread metrics to quantify the point-wise accuracy of an emulation [21, 38, 77]. Following Ohana et al. [38], we pick the variance-normalized RMSE (VRMSE) over the more common normalized RMSE (NRMSE), as the latter down-weights errors in non-negative fields such as pressure and density. Formally, for two spatial fields and v, the VRMSE is defined as VRMSE(u, v) = (cid:115) (u v)2 (u u)2 + ϵ (9) where denotes the spatial mean operator and ϵ = 106 is numerical stability term. 5 Power spectrum RMSE For chaotic systems such as turbulent fluids, it is typically intractable to achieve accurate long-term emulation as very small errors can lead to entirely different trajectories later on. In this case, instead of reproducing the exact trajectory, emulators should generate diverse trajectories that remain statistically plausible. Intuitively, even though structures are wrongly located, the types of patterns and their distribution should stay similar. Following Ohana et al. [38], we assess statistical plausibility by comparing the power spectra of the ground-truth and emulated trajectories. For two spatial fields and v, we compute the isotropic power spectra pu and pv and split them into three frequency bands (low, mid and high) evenly distributed in log-space. We report the RMSE of the relative power spectra pv/pu over each band. Spread-skill ratio In earth sciences [25, 77], the skill of an ensemble of particles is defined as the RMSE of the ensemble mean. The spread is defined as the ensemble standard deviation. Under these definitions and the assumption of perfect forecast where ensemble particles are exchangeable, Fortin et al. [77] show that Skill (cid:112)K+1/K Spread . (10) This motivates the use of the (corrected) spread-skill ratio as metric. Intuitively, if the ratio is smaller than one, the ensemble is biased or under-dispersed. If the ratio is larger than one, the ensemble is over-dispersed. It should be noted however, that spread-skill ratio of 1 is necessary but insufficient condition for perfect forecast."
        },
        {
            "title": "4 Results",
            "content": "We start with the evaluation of the autoencoders. For all datasets, we train three autoencoders with respectively 64, 16, and 4 latent channels. These correspond to compression rates of 80, 320 and 1280 for the Euler dataset, 64, 256, and 1024 for the RB dataset, and 48, 192, 768 for the TGC dataset, respectively. In the following, we refer to models by their compression rate. Additional experimental details are provided in Section 3 and Appendix B. For each autoencoder, we evaluate the reconstruction ˆxi = Dψ(Eψ(xi)) of all states xi in 64 test trajectories x0:L. As expected, when the compression rate increases, the reconstruction quality degrades, as reported in Figure 3. For the Euler dataset, the reconstruction error grows with the lead time due to wavefront interactions and rising high-frequency content. For the RB dataset, the reconstruction error peaks mid-simulation during the transition from low to high-turbulence regime. Similar trends can be observed for the power spectrum RMSE in Tables 8, 9 and 10, where the highfrequency band is most affected by compression. These results so far align with what practitioners intuitively expect from lossy compression. We now turn to the evaluation of the emulators. For each autoencoder, we train two latent-space emulators: diffusion model and neural solver. Starting from the initial state z0 = Eψ(x0) and simulation parameters θ of 64 test trajectories x0:L, each emulator produces 16 distinct autoregressive rollouts z1:L, which are then decoded to the pixel space as ˆxi = Dψ(zi). Note that for neural solvers, all 16 rollouts are identical. We compute the metrics of each prediction ˆxi against the ground-truth state xi. Figure 3. Average VRMSE of the autoencoder reconstruction at different compression rates and lead time horizons for the Euler (left), RB (center) and TGC (right) datasets. The compression rate has clear impact on reconstruction quality. 6 Figure 4. Examples of latent-space emulation for the Euler (left) and Rayleigh-Bénard (right) datasets. Even for large compression rates (), latent-space emulators are able to reproduce the dynamics surprisingly faithfully, despite significant reconstruction artifacts. For Euler, wavefronts are accurately propagated until the end of the simulation, while vortices are well located, but distorted. For RayleighBénard, plumes grow correctly until the fluid reaches high-turbulence regime. Even though they diverge from the ground-truth, diffusion-based emulators produce statistically plausible trajectories. Similar observations can be made in Figures 10 to 21. As expected from imperfect emulators, the emulation error grows with the lead time, as shown in Figures 5 and 8. However, the point-wise error of diffusion models and neural solvers, as measured by the VRMSE, remains largely unaffected until extreme (> 1000) compression rates are reached. Even then, latent-space emulators outperform the baseline pixel-space neural solver, despite the latter benefiting from more parameters and training compute. Similar observations can be made with the power spectrum RMSE over low and mid-frequency bands. High-frequency content, however, appears limited by the autoencoders reconstruction capabilities. We confirm this hypothesis by recomputing the metrics relative to the auto-encoded state Dψ(Eψ(xi)), which we report in Figure 9. This time, the power spectrum RMSE of the diffusion models is low for all frequency bands. These findings support puzzling narrative: emulation accuracy exhibits strong resilience to latent-space compression, starkly contrasting with the clear degradation in reconstruction quality. Table 1. Inference time per state for the Euler dataset, including generation and decoding. Our experiments also provide direct comparison between generative (diffusion) and deterministic (neural solver) approaches to emulation within latent space. Figures 8 and 9 indicate that diffusion-based emulators are consistently more accurate than their deterministic counterparts and generate trajectories that are statistically more plausible in terms of power spectrum. This can be observed qualitatively in Figure 4 or Figures 10 to 21 in Appendix C. In addition, the spread-skill ratio of diffusion models is close to 1, suggesting that the ensemble of trajectories they produce are reasonably well calibrated in terms of diversity/uncertainty. However, the ratio slightly decreases with the compression rate. This phenomenon is partially explained by the smoothing effect of L1-driven compression, and is therefore less severe in Figure 9. Nonetheless, it remains present and could be sign of overfitting due to the reduced amount of training data in latent space. pixel O(10 s) 56 ms pixel 13 ms latent O(1 s) pixel 84 ms latent simulator neural solver neural solver diffusion diffusion"
        },
        {
            "title": "Time",
            "content": "7 Figure 5. Average evaluation metrics of latent-space emulation for the Euler dataset. As expected from imperfect emulators, the emulation error grows with the lead time. However, the compression rate has little to no impact on emulation accuracy, beside high-frequency content. The spread-skill ratio [25, 77] drops slightly with the compression rate, which could be sign of overfitting. The diffusion-based emulators are consistently more accurate than neural solvers. In terms of computational cost, although they remain slower than latent-space neural solvers, latentspace diffusion models are much faster than their pixel-space counterparts and competitive with pixel-space neural solvers (see Table 1). With our latent diffusion models, generating and decoding full (100 simulation steps, 7 autoregressive steps) Euler trajectory takes 3 seconds on single A100 GPU, compared to roughly 1 CPU-hour with the original numerical simulation [38, 78]. final advantage of diffusion models lies in their capacity to incorporate additional information during sampling via guidance methods [42, 7982]. For example, if partial or noisy state observations are available, we can guide the emulation such that it remains consistent with these observations. We provide an illustrative example in Figure 6 where guidance is performed with the MMPS [79] method. Thanks to the additional information in the observations, the emulation diverges less from the ground-truth."
        },
        {
            "title": "5 Related work",
            "content": "Data-driven emulation of dynamical systems has become prominent research area [817] with diverse applications, including accelerating fluid simulations on uniform meshes using convolutional networks [8, 12], emulating various physics on non-uniform meshes with graph neural networks [9 11, 14], and solving partial differential equations with neural operators [13, 21, 8385]. However, McCabe et al. [15] and Herde et al. [16] highlight the large data requirements of these methods and propose pre-training on multiple data-abundant physics before fine-tuning on data-scarce ones to improve data efficiency and generalization. Our experiments similarly suggest that large datasets are needed to train latent-space emulators. parallel line of work, related to reduced-order modeling [86], focuses on learning low-dimensional representations of high-dimensional system states. Within this latent space, dynamics can be emulated more efficiently [8795]. Various embedding approaches have been explored: convolutional autoencoders for uniform meshes [89, 90], graph-based autoencoders for non-uniform meshes [91], and implicit neural representations for discretization-free states [34, 93]. Koopman operator theory [96] has also been integrated into autoencoder training to promote linear latent dynamics [92, 97]. Other approaches to enhance latent predictability include regularizing higher temporal derivatives [98], jointly optimizing the decoder and latent emulator [99], and self-supervised prediction [100]. While our work adopts this latent emulation paradigm, we do not impose structural biases on the latent space beside reconstruction quality. 8 Figure 6. Example of guided latent-space emulation for the RB (left) and TGC (right) datasets. The observations are the states downsampled by factor 16 for RB and stripe along the domain boundaries for TGC. Guidance is performed using the MMPS [79] method. Thanks to the additional information in the observations, the emulation diverges less from the ground-truth. persistent challenge in neural emulation is ensuring temporal stability. Many models, while accurate for short-term prediction, exhibit long-term instabilities as errors accumulate, pushing the predictions out of the training data distribution [21]. Several strategies have been proposed to mitigate this issue: autoregressive unrolling during training [11, 87, 101], architectural modifications [21, 84], noise injection [12], and post-processing [18, 102]. Generative models, particularly diffusion models, have recently emerged as promising approach to address this problem [18, 19, 2225] as they produce statistically plausible states, even when they diverge from the ground-truth solution. While more accurate and stable, diffusion models are computationally expensive at inference. Drawing inspiration from latent space generation in computer vision [2632], recent studies have applied latent diffusion models to emulate dynamical systems: Gao et al. [33] address short-term precipitation forecasting, Zhou et al. [35] generate trajectories conditioned on text descriptions, Du et al. [34] generate trajectories within an implicit neural representation, and Li et al. [36] combine state-wise autoencoder with spatiotemporal diffusion transformer [27] for autoregressive emulation, similar to our approach. These studies report favorable or competitive results against pixel-space and deterministic baselines, consistent with our observations."
        },
        {
            "title": "6 Discussion",
            "content": "Our results reveal key insights about latent physics emulation. First, emulation accuracy is surprisingly robust to latent-space compression, with performance remaining nearly constant even when autoencoder reconstruction quality significantly deteriorates. This observation is consistent with the latent generative modeling literature [26, 56], where compression serves dual purpose: reducing dimensionality and filtering out perceptually irrelevant patterns that might distract from semantically meaningful information. Our experiments support this hypothesis as latent-space emulators outperform their pixel-space counterparts despite using fewer parameters and requiring less training compute. Yao et al. [103] similarly demonstrate that higher compression can sometimes improve generation quality despite degrading reconstruction. Second, diffusion-based generative emulators consistently achieve higher accuracy than deterministic neural solvers while producing diverse, statistically plausible trajectories. 9 Despite the limited number of datasets, we believe that our findings are likely to generalize well across the broader spectrum of fluid dynamics. The Euler, RB and TGC datasets represent distinct fluid regimes that cover many key challenges in dynamical systems emulation: nonlinearities, multi-scale interactions, and complex spatio-temporal patterns. In addition, previous studies [3336] come to similar conclusions for other fluid dynamics problems. However, we exercise caution about extending these conclusions beyond fluids. Systems governed by fundamentally different physics, such as chemical or quantum phenomena, may respond unpredictably to latent compression. Probing these boundaries represents an important direction for future research. Apart from datasets, if compute resources were not limiting factor, our study could be extended along several dimensions, although we anticipate that additional experiments would not fundamentally alter our conclusions. First, we could investigate techniques for improving the structure of the latent space, such as incorporating Koopman-inspired losses [92, 97], regularizing temporal derivatives [98], or training shallow auxiliary decoders [103, 104]. Second, we could probe the behavior of different embedding strategies under high compression, including spatio-temporal embeddings [34, 35, 105] and implicit neural representations [34, 93]. Third, we could study the effects of autoencoder and emulator capacity by scaling either up or down their number of trainable parameters. Each of these directions represents substantial computational investment, particularly given the scale of our datasets and models, but would help establish best practices for latent-space emulation. Nevertheless, our findings lead to clear recommendations for practitioners wishing to implement physics emulators. First, try latent-space approaches before pixel-space emulation. The former offer reduced computational requirements, lower memory footprint, and comparable or better accuracy across wide range of compression rates. Second, prefer diffusion-based emulators over deterministic neural solvers. Latent diffusion models provide more accurate, diverse and stable long-term trajectories, while narrowing the inference speed gap significantly. Our experiments, however, reveal important considerations about dataset scale when training latentspace emulators. The decreasing spread-skill ratio observed at higher compression rates suggests potential overfitting. This makes intuitive sense: as compression increases, the effective size of the dataset in latent space decreases, making overfitting more likely at fixed model capacity. Benchmarking latent emulators on smaller (10-100 GB) datasets like those used by Kohl et al. [19] could therefore yield misleading results. In addition, because the latent space is designed to preserve pixel space content, observing overfitting in this compressed representation suggests that pixel-space models encounter similar issues that remain undetected. This points towards the need for large training datasets or mixtures of datasets used to pre-train emulators before fine-tuning on targeted physics, as advocated by McCabe et al. [15] and Herde et al. [16]."
        },
        {
            "title": "Acknowledgments and Disclosure of Funding",
            "content": "The authors would like to thank Géraud Krawezik and the Scientific Computing Core at the Flatiron Institute, division of the Simons Foundation, for the compute facilities and support. We gratefully acknowledge use of the research computing resources of the Empire AI Consortium, Inc., with support from the State of New York, the Simons Foundation, and the Secunda Family Foundation. Polymathic AI acknowledges funding from the Simons Foundation and Schmidt Sciences, LLC."
        },
        {
            "title": "References",
            "content": "[1] ECMWF. IFS documentation CY49R1 - part III: Dynamics and numerical procedures. In [2] IFS Documentation CY49R1. IFS Documentation. ECMWF, 2024. Jongil Han and Hua-Lu Pan. Revision of Convection and Vertical Diffusion Schemes in the NCEP Global Forecast System. In Weather and Forecasting 26.4 (2011). [3] A. J. Hundhausen and R. A. Gentry. Numerical simulation of flare-generated disturbances [4] in the solar wind. In Journal of Geophysical Research (1896-1977) 74.11 (1969). John T. Mariska et al. Numerical Simulations of Impulsively Heated Solar Flares. In The Astrophysical Journal 341 (1989). [5] Chi Wang et al. Magnetohydrodynamics (MHD) numerical simulations on the interaction of the solar wind with the magnetosphere: review. In Science China Earth Sciences 56.7 (2013). [6] Yuri N. Dnestrovskii and Dimitri P. Kostomarov. Numerical Simulation of Plasmas. Berlin, Heidelberg: Springer, 1986. [7] Yildirim Suzen et al. Numerical Simulations of Plasma Based Flow Control Applications. In 35th AIAA Fluid Dynamics Conference and Exhibit. Fluid Dynamics and Co-located Conferences. American Institute of Aeronautics and Astronautics, 2005. Jonathan Tompson et al. Accelerating Eulerian Fluid Simulation With Convolutional Networks. In Proceedings of the 34th International Conference on Machine Learning. PMLR, 2017. [8] [9] Alvaro Sanchez-Gonzalez et al. Learning to Simulate Complex Physics with Graph Networks. In Proceedings of the 37th International Conference on Machine Learning. PMLR, 2020. [10] Tobias Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. In International [11] Conference on Learning Representations. 2020. Johannes Brandstetter et al. Message Passing Neural PDE Solvers. In International Conference on Learning Representations. 2021. [12] Kim Stachenfeld et al. Learned Simulators for Turbulence. In International Conference on Learning Representations. 2021. [13] Nikola Kovachki et al. Neural Operator: Learning Maps Between Function Spaces With Applications to PDEs. In Journal of Machine Learning Research 24.89 (2023). [14] Remi Lam et al. Learning skillful medium-range global weather forecasting. In Science 382.6677 (2023). [15] Michael McCabe et al. Multiple Physics Pretraining for Spatiotemporal Surrogate Models. In Advances in Neural Information Processing Systems. Vol. 37. 2024. [16] Maximilian Herde et al. Poseidon: Efficient Foundation Models for PDEs. In Advances in Neural Information Processing Systems. Vol. 37. 2024. [17] Rudy Morel et al. DISCO: learning to DISCover an evolution Operator for multi-physicsagnostic prediction. 2025. [18] Phillip Lippe et al. PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers. In Advances in Neural Information Processing Systems. Vol. 36. 2023. [19] Georg Kohl et al. Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation. In ICML 2024 AI for Science Workshop. 2024. [20] Björn List et al. Learned turbulence modelling with differentiable fluid solvers: physicsbased loss functions and optimisation horizons. In Journal of Fluid Mechanics 949 (2022). [21] Michael McCabe et al. Towards Stability of Autoregressive Neural Operators. In Transactions on Machine Learning Research (2023). [22] Salva Cachay et al. DYffusion: Dynamics-informed Diffusion Model for Spatiotemporal Forecasting. In Advances in Neural Information Processing Systems. Vol. 36. 2023. [23] Aliaksandra Shysheya et al. On conditional diffusion models for PDE simulations. In [24] Advances in Neural Information Processing Systems. Vol. 37. 2024. Jiahe Huang et al. DiffusionPDE: Generative PDE-Solving under Partial Observation. In Advances in Neural Information Processing Systems. Vol. 37. 2024. 11 [25] Ilan Price et al. Probabilistic weather forecasting with machine learning. In Nature 637.8044 (2025). [26] Robin Rombach et al. High-Resolution Image Synthesis With Latent Diffusion Models. In Conference on Computer Vision and Pattern Recognition. 2022. [27] William Peebles and Saining Xie. Scalable Diffusion Models with Transformers. In International Conference on Computer Vision. 2023. [28] Patrick Esser et al. Scaling Rectified Flow Transformers for High-Resolution Image Synthesis. 2024. [29] Tero Karras et al. Analyzing and Improving the Training Dynamics of Diffusion Models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024. [30] Enze Xie et al. SANA: Efficient High-Resolution Text-to-Image Synthesis with Linear Diffusion Transformers. In International Conference on Learning Representations. 2024. Junyu Chen et al. Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models. In International Conference on Learning Representations. 2024. [31] [32] Adam Polyak et al. Movie Gen: Cast of Media Foundation Models. 2025. [33] Zhihan Gao et al. PreDiff: Precipitation Nowcasting with Latent Diffusion Models. In Thirty-seventh Conference on Neural Information Processing Systems. 2023. [34] Pan Du et al. Conditional neural field latent diffusion model for generating spatiotemporal turbulence. In Nature Communications 15.1 (2024). [35] Anthony Zhou et al. Text2PDE: Latent Diffusion Models for Accessible Physics Simulation. In The Thirteenth International Conference on Learning Representations. 2024. [36] Zijie Li et al. Generative Latent Neural PDE Solver using Flow Matching. 2025. [37] Gérôme Andry et al. Appa: Bending Weather Dynamics with Latent Diffusion Models for Global Data Assimilation. 2025. [39] [38] Ruben Ohana et al. The Well: Large-Scale Collection of Diverse Physics Simulations for Machine Learning. In Advances in Neural Information Processing Systems. Vol. 37. 2024. Jascha Sohl-Dickstein et al. Deep Unsupervised Learning using Nonequilibrium Thermodynamics. In Proceedings of the 32nd International Conference on Machine Learning. 2015. Jonathan Ho et al. Denoising Diffusion Probabilistic Models. In Advances in Neural Information Processing Systems. 2020. [40] [41] Yang Song and Stefano Ermon. Generative Modeling by Estimating Gradients of the Data Distribution. In Advances in Neural Information Processing Systems. 2019. [42] Yang Song et al. Score-Based Generative Modeling through Stochastic Differential Equations. In International Conference on Learning Representations. 2021. [43] Brian D. O. Anderson. Reverse-time diffusion equation models. In Stochastic Processes and their Applications (1982). [44] Simo Särkkä and Arno Solin. Applied Stochastic Differential Equations. Institute of Mathematical Statistics Textbooks. Cambridge University Press, 2019. [45] Shanchuan Lin et al. Common Diffusion Noise Schedules and Sample Steps are Flawed. In"
        },
        {
            "title": "2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). 2024.",
            "content": "[46] Xingchao Liu et al. Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow. In The Eleventh International Conference on Learning Representations. 2022. [47] Yaron Lipman et al. Flow Matching for Generative Modeling. In International Conference on Learning Representations. 2023. [48] Aapo Hyvärinen. Estimation of Non-Normalized Statistical Models by Score Matching. In Journal of Machine Learning Research (2005). [49] Pascal Vincent. Connection Between Score Matching and Denoising Autoencoders. In [50] Neural Computation (2011). Jiaming Song et al. Denoising Diffusion Implicit Models. In International Conference on Learning Representations. 2021. 12 [51] Tero Karras et al. Elucidating the Design Space of Diffusion-Based Generative Models. In Advances in Neural Information Processing Systems. 2022. [52] M. C. K. Tweedie. Functions of statistical variate with given means, with special reference to Laplacian distributions. In Mathematical Proceedings of the Cambridge Philosophical Society (1947). [53] Bradley Efron. Tweedies Formula and Selection Bias. In Journal of the American Statistical Association (2011). [54] Kwanyoung Kim and Jong Chul Ye. Noise2Score: Tweedies Approach to Self-Supervised Image Denoising without Clean Images. In Advances in Neural Information Processing Systems. 2021. [55] Chenlin Meng et al. Estimating High Order Gradients of the Data Distribution by Denoising. In Advances in Neural Information Processing Systems. 2021. [56] Sander Dieleman. Generative modelling in latent space. 2025. [57] Richard Zhang et al. The Unreasonable Effectiveness of Deep Features as Perceptual Metric. In Conference on Computer Vision and Pattern Recognition. 2018. Ian J. Goodfellow et al. Generative Adversarial Networks. 2014. [58] [59] Patrick Esser et al. Taming Transformers for High-Resolution Image Synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021. [60] Xi-Lin Li. Preconditioned Stochastic Gradient Descent. In IEEE Transactions on Neural Networks and Learning Systems 29.5 (2018). [61] Vineet Gupta et al. Shampoo: Preconditioned Stochastic Tensor Optimization. In Proceedings of the 35th International Conference on Machine Learning. PMLR, 2018. [62] Nikhil Vyas et al. SOAP: Improving and Stabilizing Shampoo using Adam for Language Modeling. In The Thirteenth International Conference on Learning Representations. 2024. [63] Diederik P. Kingma and Jimmy Ba. Adam: Method for Stochastic Optimization. In International Conference on Learning Representations. 2015. [64] Lucas Nestler and François Rozet. HeavyBall: Efficient optimizers. 2022. [65] Alex Henry et al. Query-Key Normalization for Transformers. In Findings of the Association for Computational Linguistics. Ed. by Trevor Cohn et al. Online: Association for Computational Linguistics, 2020. Jianlin Su et al. RoFormer: Enhanced transformer with Rotary Position Embedding. In Neurocomputing 568 (2024). [66] [67] Byeongho Heo et al. Rotary Position Embedding for Vision Transformer. In European Conference on Computer Vision. Ed. by Aleš Leonardis et al. Cham: Springer Nature Switzerland, 2025. [68] Zhanchao Zhou et al. Value Residual Learning. 2025. [69] Zilong Huang et al. CCNet: Criss-Cross Attention for Semantic Segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019. Jonathan Ho et al. Axial Attention in Multidimensional Transformers. 2019. [70] [71] Ali Hassani et al. Neighborhood Attention Transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [72] Vikram Voleti et al. MCVD - Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. In Advances in Neural Information Processing Systems 35 (2022). [73] Hongkai Zheng et al. Fast Training of Diffusion Models with Masked Transformers. In Transactions on Machine Learning Research (2023). [74] Ernst Hairer et al. Solving Ordinary Differential Equations I. Vol. 8. Springer Series in Computational Mathematics. Berlin, Heidelberg: Springer, 1993. [75] Qinsheng Zhang and Yongxin Chen. Fast Sampling of Diffusion Models with Exponential Integrator. In International Conference on Learning Representations. 2022. [76] Alexey Dosovitskiy et al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In International Conference on Learning Representations. 2020. [77] V. Fortin et al. Why Should Ensemble Spread Match the RMSE of the Ensemble Mean? In Journal of Hydrometeorology 15.4 (2014). 13 [78] Kyle T. Mandli et al. Clawpack: building an open source ecosystem for solving hyperbolic PDEs. In PeerJ Computer Science 2 (2016). [79] François Rozet et al. Learning Diffusion Priors from Observations by Expectation Maxi- [80] mization. In Advances in Neural Information Processing Systems. Vol. 37. 2024. Jonathan Ho et al. Video Diffusion Models. In ICLR Workshop on Deep Generative Models for Highly Structured Data. 2022. [81] Hyungjin Chung et al. Diffusion Posterior Sampling for General Noisy Inverse Problems. In International Conference on Learning Representations. 2023. [82] François Rozet and Gilles Louppe. Score-based Data Assimilation. In Advances in Neural Information Processing Systems. Vol. 36. 2023. [83] Zongyi Li et al. Fourier Neural Operator for Parametric Partial Differential Equations. In International Conference on Learning Representations. 2020. [84] Bogdan Raonic et al. Convolutional Neural Operators for robust and accurate learning of PDEs. In Advances in Neural Information Processing Systems. Vol. 36. 2023. [85] Zhongkai Hao et al. GNOT: General Neural Operator Transformer for Operator Learning. In Proceedings of the 40th International Conference on Machine Learning. PMLR, 2023. [86] Peter Benner et al. Survey of Projection-Based Model Reduction Methods for Parametric Dynamical Systems. In SIAM Review 57.4 (2015). [87] Bethany Lusch et al. Deep learning for universal linear embeddings of nonlinear dynamics. In Nature Communications 9.1 (2018). [88] Hugo F. S. Lui and William R. Wolf. Construction of reduced-order models for fluid flows using deep feedforward neural networks. In Journal of Fluid Mechanics 872 (2019). [89] S. Wiewel et al. Latent Space Physics: Towards Learning the Temporal Evolution of Fluid Flow. In Computer Graphics Forum 38.2 (2019). [90] Romit Maulik et al. Reduced-order modeling of advection-dominated systems with recurrent neural networks and convolutional autoencoders. In Physics of Fluids 33.3 (2021). [91] Xu Han et al. Predicting Physics in Mesh-reduced Space with Temporal Attention. In International Conference on Learning Representations. 2021. [92] Nicholas Geneva and Nicholas Zabaras. Transformers for modeling physical systems. In Neural Networks 146 (2022). [93] Peter Yichen Chen et al. CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations. In The Eleventh International Conference on Learning Representations. 2022. [94] AmirPouya Hemmasian and Amir Barati Farimani. Reduced-order modeling of fluid flows with transformers. In Physics of Fluids 35.5 (2023). [95] Zijie Li et al. Latent neural PDE solver: reduced-order modeling framework for partial differential equations. In Journal of Computational Physics 524 (2025). [96] B. O. Koopman. Hamiltonian Systems and Transformation in Hilbert Space. In Proceedings of the National Academy of Sciences 17.5 (1931). [97] Enoch Yeung et al. Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems. In 2019 American Control Conference (ACC). 2019. [98] Xiaoyu Xie et al. Smooth and Sparse Latent Dynamics in Operator Learning with Jerk Regularization. 2024. [99] Francesco Regazzoni et al. Learning the intrinsic dynamics of spatio-temporal processes through Latent Dynamics Networks. In Nature Communications 15.1 (2024). [100] Adrien Bardes et al. Revisiting Feature Prediction for Learning Visual Representations from Video. In Transactions on Machine Learning Research (2024). [101] Nicholas Geneva and Nicholas Zabaras. Modeling the dynamics of PDE systems with physics-constrained deep auto-regressive networks. In Journal of Computational Physics 403 (2020). [102] Daniel E. Worrall et al. Spectral Shaping for Neural PDE Surrogates. 2024. [103] Jingfeng Yao et al. Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models. 2025. 14 [104] Hao Chen et al. Masked Autoencoders Are Effective Tokenizers for Diffusion Models. 2025. [105] Lijun Yu et al. MAGVIT: Masked Generative Video Transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [106] Keaton J. Burns et al. Dedalus: flexible framework for numerical simulations with spectral methods. In Physical Review Research 2.2 (2020). [107] Masaki Iwasawa et al. Implementation and performance of FDPS: framework for developing parallel particle simulation codes. In Publications of the Astronomical Society of Japan 68.4 (2016). [108] Kaiming He et al. Deep Residual Learning for Image Recognition. In Conference on Computer Vision and Pattern Recognition. 2016. [109] Stefan Elfwing et al. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. In Neural Networks (2018). Jimmy Lei Ba et al. Layer Normalization. 2016. [110] [111] Ashish Vaswani et al. Attention is All you Need. In Advances in Neural Information Processing Systems. 2017. 15 Spread / Skill The skill [25, 77] of an ensemble of particles vk is defined as the RMSE of the ensemble mean (cid:42)(cid:32) (cid:118) (cid:117) (cid:117) (cid:116) Skill = (cid:33)2(cid:43)"
        },
        {
            "title": "1\nK",
            "content": "K (cid:88) k=1 vk (11) where denotes the spatial mean operator. The spread is defined as the ensemble standard deviation (cid:42) (cid:118) (cid:117) (cid:117) (cid:117) (cid:116) Spread ="
        },
        {
            "title": "1\nK − 1",
            "content": "(cid:32) (cid:88) j=1 vj (cid:33)2(cid:43) ."
        },
        {
            "title": "1\nK",
            "content": "K (cid:88) k=1 vk (12) Under these definitions and the assumption of perfect forecast where ensemble particles are exchangeable, Fortin et al. [77] show that Skill (cid:114) + 1 Spread . (13) This motivates the use of the (corrected) spread-skill ratio as metric. Intuitively, if the ratio is smaller than one, the ensemble is biased or under-dispersed. If the ratio is larger than one, the ensemble is over-dispersed. It should be noted however, that spread-skill ratio of 1 is necessary but not sufficient condition for perfect forecast."
        },
        {
            "title": "B Experiment details",
            "content": "Datasets For all datasets, each field is standardized with respect to its mean and variance over the training set. For Euler, the non-negative scalar fields (energy, density, pressure) are transformed with (cid:55) log(x + 1) before standardization. For TGC, the non-negative scalar fields (density, pressure, temperature) are transformed with (cid:55) log(x + 106) before standardization. When the states are illustrated graphically, as in Figure 1, we represent the density field for Euler, the buoyancy field for RB, and slice of the temperature field for TGC. Table 2. Details of the selected datasets. We refer the reader to Ohana et al. [38] for more information."
        },
        {
            "title": "Fields",
            "content": "Channels Cpixel Resolution Discretization Trajectories Time steps Stride θ Euler Multi-Quadrants Rayleigh-Bénard"
        },
        {
            "title": "Turbulence Gravity Cooling",
            "content": "Clawpack [78] 5243 GB energy, density, pressure, velocity 5 512 512 Uniform 10000 100 4 heat capacity γ, boundary conditions Dedalus [106] 367 GB buoyancy, pressure, momentum 4 512 128 Chebyshev 1750 200 4 Rayleigh number, Prandtl number FDPS [107] 849 GB density, pressure, temperature, velocity 6 64 64 64 Uniform 2700 50 1 hydrogen density ρ0, temperature T0, metallicity Autoencoders The encoder Eψ and decoder Dψ are convolutional networks with residual blocks [108], SiLU [109] activation functions and layer normalization [110]. multi-head self-attention layer [111] is inserted in some residual blocks. The output of the encoder is transformed with saturating function (see Section 3). We provide schematic illustration of the autoencoder architecture in Figure 7. We train the encoder and decoder jointly for 1024256 steps of the PSGD [60] optimizer. To mitigate overfitting we use random spatial axes permutations, flips and rolls as data augmentation. Each autoencoder takes 1 (RB), 2 (Euler) or 4 (TGC) days to train on 8 H100 GPUs. Other hyperparameters are provided in Table 3. Table 3. Hyperparameters for the autoencoders. Euler & RB TGC Architecture Parameters Pixel shape Latent shape Residual blocks per level Channels per level Attention heads per level Kernel size Activation Normalization Dropout Optimizer Learning rate Weight decay Scheduler Gradient norm clipping Batch size Steps per epoch Epochs GPUs Conv 2.4 108 Cpixel Clatent 32 32 (3, 3, 3, 3, 3, 3) (64, 128, 256, 512, 768, 1024) (, , , , , 8) 3 3 SiLU LayerNorm 0.05 8 Conv 7.2 108 Cpixel 8 Clatent 8 (3, 3, 3, 3) (64, 256, 512, 1024) (, , , ) 3 3 3 SiLU LayerNorm 0.05 PSGD 105 0.0 cosine 1.0 64 256 1024 8 PSGD 105 0.0 cosine 1.0 64 256 1024 8 17 Figure 7. Schematic representation of the autoencoder architecture. Downsampling (resp. upsampling) is performed with space-to-depth (resp. depth-to-space) operation followed (resp. preceded) with convolution initialized near identity. Table 4. Short ablation study on the autoencoder architecture and training configurations. We pick the Rayleigh-Bénard dataset and an architecture with 64 latent channels to perform this study. The two major modifications that we propose are (1) the initialization of the downsampling and upsampling layers near identity, inspired by Chen et al. [31], and (2) the use of preconditioned optimizer, PSGD [60], instead of Adam [63]. We report the mean absolute error (MAE) on the validation set during training. The combination of both proposed modifications leads to order(s) of magnitude faster convergence. Optimizer Id. init Adam Adam PSGD w/o w/ w/ Epoch 0.029 0.023 0.015 1000 0.017 0.014 0.011 Time 19 19 25 0.065 0.039 0.023 Caching The entire dataset is encoded with each trained autoencoder and the resulting latent trajectories are cached permanently on disk. The latter can then be used to train latent-space emulators, without needing to load and encode high-dimensional samples on the fly. Depending on hardware and data dimensionality, this approach can make huge difference in I/O efficiency. Emulators The denoiser dϕ and neural solver fϕ are transformers with query-key normalization [65], rotary positional embedding (RoPE) [66, 67], and value residual learning [68]. The 16 blocks are modulated by the simulation parameters θ and the diffusion time t, as in diffusion transformers 18 [27]. We train the emulator for 4096 64 steps of the Adam [63] optimizer. Each latent-space emulator takes 2 (RB) or 5 (Euler, TGC) days to train on 8 H100 GPUs. Each pixel-space emulator takes 5 (RB) or 10 (Euler) days to train on 16 H100 GPUs. We do not train pixel-space emulator for TGC. Other hyperparameters are provided in Table 5. Table 5. Hyperparameters for the emulators."
        },
        {
            "title": "Architecture\nParameters\nInput shape\nPatch size\nTokens\nEmbedding size\nBlocks\nPositional embedding\nActivation\nNormalization\nDropout",
            "content": "Optimizer Learning rate Weight decay Scheduler Gradient norm clipping Batch size Steps per epoch Epochs GPUs Latent-space Transformer 2.2 108 Pixel-space Transformer 8.6 108 Clatent + 1 32 32 Cpixel + 1 1 1 1 1 16 16 32 32 n + 1 1024 16 Absolute + RoPE SiLU LayerNorm 0.05 16 16 + 1 2048 16 Absolute + RoPE SiLU LayerNorm 0.05 Adam 104 0.0 cosine 1.0 256 64 4096 8 Adam 104 0.0 cosine 1.0 256 64 4096 During training we randomly sample the binary mask b. The number of context elements follows Poisson distribution Pois(λ = 2) truncated between 1 and n. In addition, we randomly flip with probability 0.33 to cover backward temporal prediction. Hence, the masks take the form = (1, . . . , 1 (cid:124) (cid:123)(cid:122) (cid:125) , 0, . . . , 0) or = (0, . . . , 0, 1, . . . , 1 (cid:124) (cid:123)(cid:122) (cid:125) ) (14) implicitely defining distribution p(b). Evaluation For each dataset, we randomly select 64 trajectories x0:L with various parameters θ in the test set. For each latent-space emulator, we encode the initial state z0 = Eψ(x0) and produce 16 distinct autoregressive rollouts z1:L. For the diffusion models, sampling is performed with 16 steps of the 3rd order Adams-Bashforth multi-step method [74, 75]. The metrics (VRMSE, power spectrum RMSE, spread-skill ratio) are then measured between the predicted states ˆxi = Dψ(zi) and the ground-truth states xi or the auto-encoded states Dψ(Eψ(xi))."
        },
        {
            "title": "C Additional results",
            "content": "Table 6. Average VRMSE of autoencoder reconstruction and latent-space emulation at different compression rates () and lead time horizons for the Euler, RB and TGC datasets. The compression rate has clear impact on reconstruction quality, but its effect on emulation accuracy goes unnoticed until extreme compression rates are reached."
        },
        {
            "title": "Method",
            "content": "autoencoder diffusion neural solver"
        },
        {
            "title": "Method",
            "content": "RB 1:20 21:60 61:100 1:20 21: 61:160 80 320 1280 80 320 1280 1 80 320 1280 0.011 0.025 0.067 0.075 0.070 0. 0.138 0.077 0.080 0.137 0.015 0.042 0.109 0.199 0.192 0.217 0.397 0.232 0.232 0.314 0.020 0.061 0.145 0.395 0.371 0. 1.102 0.500 0.476 0.592 autoencoder diffusion neural solver 64 256 1024 64 256 1 64 256 1024 0.027 0.054 0.108 0.157 0.177 0.219 0.245 0.219 0.235 0.256 0.036 0.072 0.140 0.469 0.474 0. 0.629 0.645 0.651 0.644 0.018 0.039 0.087 0.625 0.621 0.657 0.870 0.828 0.834 0.827 Method autoencoder diffusion neural solver TGC 1:10 11:20 21: 48 192 768 48 192 768 48 192 768 0.151 0.229 0.338 0.297 0.342 0.425 0.302 0.361 0. 0.116 0.175 0.272 0.523 0.527 0.575 0.599 0.632 0.710 0.129 0.189 0.276 0.675 0.665 0.694 0.826 0.835 0. Table 7. Average VRMSE of latent-space emulation at different context lengths (c) and lead time horizons for the Euler, RB and TGC datasets. We can test different context lengths without retraining as our models were trained for different conditioning tasks (see Section 3). Perhaps surprisingly, context lengths does not have significant impact on emulation accuracy. Method diffusion neural solver Euler 1 2 3 1 2 3 1:20 21:60 61:100 0.085 0.074 0. 0.108 0.092 0.094 0.204 0.201 0.203 0.266 0.253 0.260 0.393 0.383 0.389 0.526 0.513 0.529 Method diffusion neural solver RB 1 2 3 1 2 1:20 21:60 61:160 0.186 0.184 0.182 0.231 0.235 0.244 0.486 0.481 0. 0.625 0.640 0.675 0.635 0.637 0.630 0.818 0.826 0.848 Method diffusion neural solver TGC 1 2 3 1 2 3 1:10 11: 21:50 0.362 0.351 0.250 0.376 0.371 0.378 0.550 0.536 0.539 0.632 0.641 0.669 0.681 0.670 0. 0.837 0.855 0.888 20 Table 8. Average power spectrum RMSE of autoencoder reconstruction and latent-space emulation at different compression rates () and lead time horizons for the Euler dataset. The mid and high-frequency content of diffusion-based emulators is limited by the autoencoders reconstruction capabilities."
        },
        {
            "title": "Method",
            "content": ""
        },
        {
            "title": "High",
            "content": "1:20 21:60 61:100 1:20 21:60 61: 1:20 21:60 61:100 autoencoder diffusion neural solver 80 320 1280 80 320 1280 1 80 320 1280 0.001 0.002 0.010 0.017 0.014 0.019 0.046 0.021 0.020 0. 0.001 0.003 0.017 0.063 0.058 0.065 0.128 0.074 0.075 0.116 0.001 0.004 0.025 0.168 0.157 0.163 0.339 0.212 0.204 0. 0.006 0.024 0.087 0.054 0.052 0.096 0.227 0.085 0.074 0.131 0.008 0.049 0.171 0.100 0.102 0.187 0.297 0.151 0.144 0. 0.014 0.087 0.267 0.178 0.171 0.300 0.754 0.245 0.234 0.349 0.070 0.111 0.237 0.112 0.128 0.246 0.821 0.164 0.151 0. 0.070 0.142 0.363 0.116 0.155 0.349 0.984 0.173 0.169 0.345 0.98 0.246 0.593 0.184 0.275 0.569 2.666 0.249 0.271 0. Table 9. Average power spectrum RMSE of autoencoder reconstruction and latent-space emulation at different compression rates () and lead time horizons for the Rayleigh-Benard dataset. The mid and high-frequency content of diffusion-based emulators is limited by the autoencoders reconstruction capabilities. Method Low Mid High 1:20 21:60 61:100 1:20 21:60 61: 1:20 21:60 61:100 autoencoder diffusion neural solver 64 256 1024 64 256 1024 1 64 256 1024 0.011 0.030 0.092 0.283 0.256 0.158 4.143 1.873 1.233 0. 0.002 0.006 0.028 0.225 0.218 0.232 0.661 0.404 0.338 0.305 0.001 0.004 0.018 0.339 0.330 0.308 0.491 0.441 0.429 0. 0.010 0.049 0.121 0.078 0.079 0.137 1.147 0.286 0.170 0.174 0.015 0.111 0.254 0.113 0.163 0.276 0.565 0.315 0.297 0. 0.010 0.069 0.196 0.144 0.164 0.236 0.387 0.286 0.281 0.310 0.99 0.150 0.197 0.126 0.159 0.199 0.523 0.198 0.184 0. 0.194 0.268 0.340 0.234 0.279 0.340 1.029 0.335 0.315 0.358 0.139 0.207 0.274 0.190 0.224 0.277 0.824 0.281 0.264 0. Table 10. Average power spectrum RMSE of autoencoder reconstruction and latent-space emulation at different compression rates () and lead time horizons for the TGC dataset. The mid and high-frequency content of diffusion-based emulators is limited by the autoencoders reconstruction capabilities. Method autoencoder diffusion neural solver 48 192 768 48 192 768 48 192 768 Low Mid High 1:10 11:30 31:50 1:10 11:30 31: 1:10 11:30 31:50 0.011 0.028 0.072 0.064 0.069 0.107 0.070 0.086 0. 0.016 0.033 0.068 0.189 0.191 0.294 0.221 0.228 0.277 0.025 0.045 0.080 0.329 0.309 0.425 0.424 0.402 0. 0.022 0.108 0.285 0.059 0.128 0.289 0.110 0.172 0.322 0.025 0.091 0.235 0.133 0.165 0.305 0.197 0.201 0. 0.044 0.113 0.254 0.227 0.249 0.360 0.324 0.295 0.407 0.275 0.359 0.454 0.297 0.369 0.456 0.357 0.390 0. 0.188 0.273 0.476 0.253 0.317 0.419 0.320 0.317 0.418 0.195 0.282 0.367 0.338 0.380 0.443 0.427 0.395 0. 21 Figure 8. Average evaluation metrics of latent-space emulation for the Euler (top), RB (center) and TGC (bottom) datasets. As expected from imperfect emulators, the emulation error grows with the lead time. However, the compression rate has little to no impact on emulation accuracy. Mid and high-frequency content is limited by the the autoencoders reconstruction capabilities. The spreadskill ratio [25, 77] drops slightly with the compression rate, which could be sign of overfitting. The diffusion-based emulators are consistently more accurate than neural solvers. 22 Figure 9. Average evaluation metrics of latent-space emulation relative to the auto-encoded states Dψ(Eψ(xi)) for the Euler (top), RB (center) and TGC (bottom) datasets. As expected from imperfect emulators, the emulation error grows with the lead time. However, the compression rate has little to no impact on emulation accuracy. The spread-skill ratio [25, 77] drops slightly with the compression rate, which could be sign of overfitting. The diffusion-based emulators are consistently more accurate than neural solvers. 23 Figure 10. Examples of emulation at different compression rates () for the Euler dataset. In this simulation, the system has open boundary conditions. 24 Figure 11. Examples of emulation at different compression rates () for the Euler dataset. In this simulation, the system has periodic boundary conditions. 25 Figure 12. Examples of emulation at different compression rates () for the Euler dataset. In this simulation, the system has periodic boundary conditions. 26 Figure 13. Examples of emulation at different compression rates () for the Euler dataset. In this simulation, the system has periodic boundary conditions. 27 Figure 14. Examples of emulation at different compression rates () for the Rayleigh-Bénard dataset. In this simulation, the fluid is in low-turbulence regime (Ra = 106). 28 Figure 15. Examples of emulation at different compression rates () for the Rayleigh-Bénard dataset. In this simulation, the fluid is in high-turbulence regime (Ra = 108). 29 Figure 16. Examples of emulation at different compression rates () for the Rayleigh-Bénard dataset. In this simulation, the fluid is in low-turbulence regime (Ra = 106). 30 Figure 17. Examples of emulation at different compression rates () for the Rayleigh-Bénard dataset. In this simulation, the fluid is in high-turbulence regime (Ra = 108). 31 Figure 18. Examples of emulation at different compression rates () for the TGC dataset. In this simulation, the initial density is low and the initial temperature is low (ρ0 = 0.445, T0 = 10.0). 32 Figure 19. Examples of emulation at different compression rates () for the TGC dataset. In this simulation, the initial density is medium and the initial temperature is high (ρ0 = 4.45, T0 = 1000.0). 33 Figure 20. Examples of emulation at different compression rates () for the TGC dataset. In this simulation, the initial density is high and the initial temperature is low (ρ0 = 44.5, T0 = 10.0). 34 Figure 21. Examples of emulation at different compression rates () for the TGC dataset. In this simulation, the initial density is high and the initial temperature is medium (ρ0 = 44.5, T0 = 100.0)."
        }
    ],
    "affiliations": [
        "Flatiron Institute",
        "New York University",
        "Polymathic AI",
        "Princeton University",
        "University of Liège",
        "Université Paris-Saclay, Université Paris Cité, CEA, CNRS, AIM"
    ]
}