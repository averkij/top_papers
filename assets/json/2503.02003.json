{
    "paper_title": "HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs",
    "authors": [
        "Tin Nguyen",
        "Logan Bolton",
        "Mohammad Reza Taesiri",
        "Anh Totti Nguyen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate non-factual statements. A response mixed of factual and non-factual statements poses a challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), a technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the query. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input. Interestingly, in few-shot settings, HoT outperforms vanilla chain of thought prompting (CoT) on a wide range of 17 tasks from arithmetic, reading comprehension to logical reasoning. When asking humans to verify LLM responses, highlights help time-limited participants to more accurately and efficiently recognize when LLMs are correct. Yet, surprisingly, when LLMs are wrong, HoTs tend to make users believe that an answer is correct."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 ] . [ 2 3 0 0 2 0 . 3 0 5 2 : r HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Tin Nguyen1 * Logan Bolton1 * Mohammad Reza Taesiri2 Anh Totti Nguyen1 {ttn0011,ldb0046}@auburn.edu {mtaesiri,anhng8}@gmail.com 1Auburn University, USA 2University of Alberta, Canada Blog, code, and data: aub.ie/hot"
        },
        {
            "title": "Abstract",
            "content": "An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate nonfactual statements. response mixed of factual and non-factual statements poses challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the query. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate response with highlights over the facts referenced from the input. Interestingly, in few-shot settings, HoT outperforms vanilla chain of thought prompting (CoT) (Wei et al., 2022) on wide range of 17 tasks from arithmetic, reading comprehension to logical reasoning. When asking humans to verify LLM responses, highlights help time-limited participants to more accurately and efficiently recognize when LLMs are correct. Yet, surprisingly, when LLMs are wrong, HoTs tend to make users believe that an answer is correct. 1. Introduction Chains of Thoughts (CoT) enable LLMs to generate stepby-step solutions to questions, improving both (1) accuracy on many tasks (Wei et al., 2022) that benefit from problem decomposition and (2) transparency in how model arrives at final answer. However, major weakness of LLMs is their tendency to hallucinate non-factual statements (Zhang et al., 2023), making it difficult for humans to verify whether an LLM answer is correct or wrong. *Equal contribution. Figure 1: An HoT, composed of re-formatted question and answer, generated by Gemini-1.5-Pro ( ) in response to GSM8K question. Existing methods attempt to combat hallucination and improve verifiability by forcing LLMs to cite websites (Perplexity; SearchGPT), documents (Bai et al., 2024) or paragraphs (Cohen-Wang et al., 2024) where the facts in the response come from. Yet, there is no work that enables LLMs to generate regular chains of thoughts but with references back to the textual facts in the question. To bridge this gap, we propose Highlighted Chain-ofThought (HoT), prompting technique for LLMs to generate CoT answer but with XML tags, grounding facts in the response to those provided in the question  (Fig. 1)  . First, an LLM re-formats the input question to wrap XML tags around key facts. Second, it generates its response but with XML tags around the facts that come from the input, enabling colored highlights  (Fig. 1)  . Such highlights enable users to trace which statements in the response correspond to which facts in the input, which we hypothesize to make human verification faster and more accurate. We test HoT using five LLMs including Gemini-1.5-Flash 1 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs ), Gemini-1.5-Pro ( ) ), Llama-3.1-405B ( (Reid et al., 2024), ( Llama-3.1-70B ( ) (Dubey et al., 2024), and GPT-4o ( ) (OpenAI, 2024) across 17 tasks from arithmetic, logical reasoning to reading comprehension. Our main findings are: Compared to vanilla few-shot CoT, HoT consistently improves LLM accuracy across 5 LLMs and 17 datasets. On average, across arithmetic, questionanswering, and logical reasoning tasks, HoT gains +1.60, +2.58, and +2.53 percentage points (pp), respectively (Sec. 5.1). The accuracy gains by HoT comes from both repeating the question and highlighting facts. That is, asking and to insert tags into both questions and answers (HoT) outperforms prompting them to repeat the questions before answering (Mekala et al., 2024) by +2.30 and +2.43 pp, respectively (Sec. 5.2). Larger LLMs qualitatively generate tag distribution that are similar to that annotated by humans, i.e., on average, 1.4 fewer tags per question than the number of human-annotated tags (8.19 vs. 9.59). In contrast, smaller LLMs generate 7.29 tags per question (Sec. 5.2). Instructing large LLMs via few-shot demonstrations to insert tags into answers alone (not questions) interestingly results in responses that contain tags in both questions and answers. This setup yields +1.79 gain in accuracy (81.50 83.29) over no-tag demonstrations (CoT) (Sec. 5.2). Presenting highlights in chains of thoughts to users improves their speed by 25% (62.38s 47.26s) and estimated accuracy in verifying whether LLM answers are correct (Secs. 5.4 and 5.5). 2. Related Work Generating references to documents Recent works have trained LLMs to answer questions by generating responses that include citations to the documents from which they extract supporting information (Cohen-Wang et al., 2024; Bai et al., 2024; Gao et al., 2023; Press et al.; Taylor et al., 2022; Bohnet et al., 2022). Another approach is to generate citations post-hoc, i.e., by having one LLM generate the answer first and another LLM search for citations that support facts in the answers (Ramu et al., 2024; Sancheti et al., 2024; Dasigi et al., 2021). Commercial LLM-powered search engines recently also rolled out their citation feature (Anthropic, 2025; SearchGPT; BingSearch; Perplexity), which references web pages and online documents that support statements in the responses. Unlike above works, our work focuses on generating references to phrase-level and sentence-level facts (Figs. 1 and 2) 2 in the question instead of references to context documents. Prompting techniques CoT prompting (Wei et al., 2022) improves LLM accuracy and explainability by generating step-by-step answers to question. Interestingly, inputting the exact question twice to an LLM improves its answer accuracy slightly (Xu et al., 2024). Similarly, given question, asking an LLM to first repeat the question and then answer it also improves accuracy compared to vanilla CoT (Mekala et al., 2024). Our work is similar to Re-reading (Xu et al., 2024) and EchoPrompt (Mekala et al., 2024) in that we also ask LLMs to first generate the question, but where key facts are highlighted. Furthermore, unlike the above two concurrent works, we instruct LLMs to include tags in the answer, which our ablation study (Sec. 5.2) shows to further improve LLM accuracy. Retrieval-Augmented Generation (RAG) systems first retrieve relevant documents given an input question and then feed the documents along with the original question to an LLM for generating an answer (Asai et al.; Jin et al., 2024). While RAG systems generate citations to the retrieved documents (Liu, 2022), our goal is to generate citations to phrases that contain facts in the input question. In RAG systems, feeding HTML tags in web pages instead of plain text to RAG systems improves the accuracy of the retrieved knowledge (Tan et al., 2024). Functionally similar to HTML tags, our XML tags around key facts also improve the LLM answer accuracy. Span prediction is core task in Natural Language Processing (NLP) that requires model to read question and paragraph and predict the start and end index of the answer embedded in the paragraph (Rajpurkar et al., 2016; Dasigi et al., 2019). Similarly to span prediction, we ask LLMs to identify key phrases in the input question. However, our method instructs LLMs to perform an extra step of generating the answer with references to the selected spans (i.e., highlighted facts in the input question). Impact of highlights on human cognition In cognitive science, studies found that selective emphasis techniques, such as text highlighting, can improve comprehension and learning for humans (Fowler & Barker, 1974; Ramírez et al., 2019). In contrast, inappropriate highlighting could harm human accuracy in reading comprehension (Gier et al., 2009; Ramírez et al., 2019). Given that the dynamics of LLM errors are unknown, here, for the first time, we assess how highlights could help users verify whether an LLM answer is accurate or not. 3. Method Our goal is to prompt LLMs to produce response consisting of two parts: (1) version of the original question with XML tags (<fact1>, <fact2>, etc.) highlighting key facts; HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Reformatted Question & Answer GSM8K Reformatted Question: Artie has flower stand at the Farmers Market. He sells three kinds of flowers: marigolds, petunias and begonias. He usually sells marigolds for $2.74 per pot, petunias for $1.87 per pot and begonias for $2.12 per pot. Artie has no change today, so he has decided to round all his prices to the nearest dollar. If Artie sells 12 pots of marigolds, 9 pots of petunias and 17 pots of begonias, how much will he make? ................................................................................................................... Answer: Rounding to the nearest dollar, marigolds cost $3 per pot, petunias cost $2 per pot, and begonias cost $2 per pot. Artie sells 12 pots of marigolds at $3 per pot, so he makes 12 * 3 = $36 on marigolds. He sells 9 pots of petunias at $2 per pot, so he makes 9 * 2 = $18 on petunias. He sells 17 pots of begonias at $2 per pot, so he makes 17 * 2 = $34 on begonias. In total, Artie makes 36 + 18 + 34 = $88. The answer is {88}. Reformatted Question & Answer Causal Judgement Reformatted Question: person, Joe, is playing casino game where he reaches his hand into two boxes and blindly draws ball from each box. He wins dollar if and only if he gets green ball from the left box and blue ball from the right box. It is unlikely that he gets green ball from the first box. It is very likely that he gets blue ball in the second box. Joe closes his eyes, reaches in, and chooses green ball from the first box and blue ball from the second box. So Joe wins dollar. Did Joes first choice cause him to win dollar? Options: - Yes - No ................................................................................................................... Answer: Joes win required green ball from the left box AND blue ball from the right box. While getting the blue ball was highly probable, obtaining the green ball was less likely and therefore more crucial for his win. typical person would think that getting the green ball was the decisive factor in winning, even though both conditions were necessary. The answer is {yes}. Figure 2: Gemini-1.5-Pro ( those facts. See Tabs. T26 and T38 for more examples. ) first highlights key facts in the question, then generates an answer with highlights linked to and (2) an answer that explicitly links statements in the answer to the facts of the question  (Fig. 2)  . Our hypothesis is that the tag generation requires LLMs to attend better to facts, reducing hallucination and therefore improve accuracy of the final answer. Furthermore, the highlights when presented to humans would improve their accuracy of verification. We experiment with different XML tag names and find that <fact{i}></fact{i}> where = 1,2,3... results in the best LLM accuracy (Appendix C). 3.1. Highlighted Chain-of-Thought (HoT) To prompt LLMs to generate HoTs  (Fig. 4)  , we design the following prompt structure  (Fig. 3)  and use it for all datasets. First, the 8-shot demonstration examples (which are CoT demonstrations but with XML tags) would show LLMs how to insert tags and answer questions. Second, the HoT instruction would be short, explicit request that ask LLMs to insert tags into questions and answer it. {Question 1} {Reformatted Q1} {Answer 1} {Question 2} {Reformatted Q2} {Answer 2} ... {Question 8} {Reformatted Q8} {Answer 8} {Question} {HoT Instruction} Figure 3: 8-shot HoT examples are provided in addition to the explicit directions (HoT Instruction) to help LLMs understand the expected format. See Tab. T60 for one entire example prompt. may require different types of linguistic structures to be highlighted. 3.2. Collecting human-annotated highlighted chain-of-thought demonstrations For each dataset, we make separate 8-shot examples (Brown et al., 2020) to show LLMs how to insert tags because we find it non-trivial to instruct LLMs zero-shot to highlight facts without demonstrations  (Fig. 1)  because each dataset In real-world scenarios, it is important but can also be timeconsuming for humans to generate HoT demonstrations, especially when there are 17 datasets as in our work. Therefore, we propose 3-step, LLM-assisted approach for hu3 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Input Question: Edward spent $6 to buy 2 books each book costing him the same amount of money. Now he has $12. How much did each book cost? HoT output by Reformatted Question: Edward spent <fact1>$6</fact1> to buy <fact2>2 books</fact2> each costing him the same amount of money. Now he has $12. How much did each book cost? Answer: Edward spent <fact1>$6</fact1> on <fact2>2 books</fact2>, meaning each book cost <fact1>6</fact1>/ <fact2>2</fact2> = 3 dollars. The answer is {3}. HoT output (Regex + CSS) Reformatted Question: Edward spent $6 to buy 2 books each costing him the same amount of money. Now he has $12. How much did each book cost? Answer: Edward spent $6 on 2 books, meaning each book cost $6/2 = 3 dollars. The answer is {3}. Figure 4: LLMs generate HoT responses by wrapping XML tags around the information that the model determines is the most important. Regex and CSS are then used to visualize the highlights for user readability. Once all key phrases are identified and tagged in question, we then examine the answer and identify semantically corresponding phrases that refer to the same entity (e.g., blue ball from the right box vs. the blue ball in Fig. 2) and insert XML tags around them. That is, every tag in the answer must correspond to an existing tag in the question. These 15 human-annotated examples (see Github repo) are then used as meta demonstrations for LLMs to generate few-shot demonstrations for specific dataset (Step 2). 3.2.2. STEP 2: LLMS TO GENERATE COT RESPONSES FOR 8 QUESTIONS IN GIVEN DATASET To fairly compare HoT and CoT under the common 8-shot CoT setting (Wei et al., 2022), we need to create 8 HoT demonstrations for each dataset. To do that, we (a) ask GPT-4o to generate standard CoT answers for 8 random questions in each dataset; and (b) convert these CoT examples into HoT examples in Step 3, leveraging the 15 meta demonstrations. 3.2.3. STEP 3: LLMS TO INSERT XML TAGS INTO COT RESPONSES FOR GIVEN DATASET First, we prompt GPT-4o to take the 15 demonstrations from Step 1 (as few-shot examples) together with question from Step 2 and return reformatted question with XML tags (prompts in Appendix I), resulting in 8 tagged questions. Second, we instruct GPT-4o (prompts in Appendix I) to use the 15 demonstrations from Step 1 and each tagged question above and return tagged answer, resulting in 8 pairs of tagged questions and answers in total per dataset. want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags for key phrases, the key phrases that are most relevant to answering the question {last_sentence} and then generate your answers. The output format is as follows: Reformatted Question: Answer: Figure 5: HoT instruction to LLMs where {last_sentence} is the last sentence, e.g. how much money are all her jewels worth? in the {Question} section of the prompt  (Fig. 3)  . mans to quickly create high-quality HoT demonstrations for given dataset, and apply the same procedure for all 17 datasets. First, we manually annotate set of 15 question-answer pairs (with highlights) that span across multiple domains. Then, we use these HoT demonstrations to prompt LLMs to generate more demonstrations for specific dataset. 3.2.1. STEP 1: HUMANS TO INSERT HIGHLIGHTS INTO HOT META DEMONSTRATIONS We take, in total, 15 different CoT question-answer pairs from multiple datasets in variety of domains including arithmetic, logical and question-answering tasks. Then, we manually add XML tags to these questions following the leave-one-out principle (Li et al., 2016) for identifying important tokens. That is, fact (to be wrapped around, e.g., <fact1></fact1>) is key phrase in the question that when removed would render the question unanswerable. Any details that are not directly relevant to answering the final question should not be tagged. 4 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table 1: Over all 5 LLMs, HoT consistently improves accuracy over CoT across arithmetic tasks. Notably, HoT achieves the largest performance gains in AQUA (+14.64 for ) and r-GSM (+12.73 for ). Model Method CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean GSM8K 93.93 94.01 (+0.08) 95.38 95.45 (+0.07) 94.69 94.62 (-0.07) 95.83 95.83 95.53 95.68 (+0.15) +0.05 MultiArith 98.99 99.33 (+0.34) 97.48 99.16 (+1.68) 99.16 99.33 (+0.17) 98.83 99.16 (+0.33) 98.99 99.33 (+0.34) +0.57 ASDiv 96.90 97.14 (+0.24) 97.42 98.00 (+0.58) 96.38 97.04 (+0.66) 97.19 97.38 (+0.19) 97.33 96.23 (-1.10) +0.11 SVAMP 92.80 94.80 (+2.00) 94.70 95.80 (+1.10) 93.00 95.10 (+2.10) 93.70 95.5 (+1.80) 94.60 95.20 (+0.60) +1.52 AQUA 81.42 96.06 (+14.64) 82.68 91.73 (+9.05) 90.94 87.01 (-3.93) 87.40 88.98 (+1.58) 79.13 82.68 (+3.55) +4.98 r-GSM 85.91 86.36 (+0.45) 78.18 90.91 (+12.73) 89.09 89.09 90.91 91.82 (+0.91) 89.09 90.45 (+1.36) +3. GSM-Symbolic 81.67 83.67 (+2.00) 85.67 86.33 (+0.66) 82.33 82.33 90.33 90.00 (-0.33) 87.33 89.33 (+2.00) +0.87 Task Mean () 90.23 93.05 (+2.82) 90.22 93.91 (+3.70) 92.23 92.07 (-0.15) 93.46 94.10 (+0.64) 91.71 92.70 (+0.99) +1.60 Table 2: Over all 5 LLMs, HoT consistently improves accuracy over CoT across QA tasks (StrategyQA, SpartQA, Date Understanding) and reading comprehension tasks (Break and Census). The largest gains are observed in StrategyQA (+15.07 for ) and SpartQA (+11.88 for ). StrategyQA 76.55 79.74 (+3.19) 81.75 83.45 (+1.70) 69.30 84.37 (+15.07) 85.33 88.43 (+3.10) 83.89 85.37 (+1.48) +4. SpartQA 47.28 59.16 (+11.88) 61.88 64.85 (+2.97) 66.09 67.08 (+0.99) 69.80 72.28 (+2.48) 55.00 59.75 (+4.75) +4.61 Date Understanding Break 83.61 85.24 86.25 (+2.64) 85.79 (+0.55) 86.39 93.31 87.36 (+0.97) 95.82 (+2.51) 88.75 91.36 88.89 (+0.14) 91.92 (+0.56) 90.28 95.54 97.49 (+1.95) 90.28 86.75 96.66 87.50 (+0.75) 97.21 (+0.55) +0.90 +1.22 Census 90.00 90.00 91.75 92.50 (+0.75) 94.25 94.25 93.50 94.50 (+1.00) 86.25 90.75 (+4.50) +1.25 Task Mean () 76.54 80.19 (+3.65) 83.02 84.80 (+1.78) 81.95 85.30 (+3.35) 86.89 88.60 (+1.71) 81.81 84.12 (+2.41) +2.58 Model Method CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean 4. Datasets We evaluate our method across 17 tasks spanning four domains: arithmetic, question answering, logical reasoning, and reading comprehension. See Appendix for more details (number of instances and examples) of each dataset. Arithmetic Problems We test on arithmetic tasks taken from (Wei et al., 2022): GSM8K (Cobbe et al., 2021), MultiArith (Roy & Roth, 2015), ASDiv (Miao et al., 2020), SVAMP (Patel et al., 2021), and AQUA (Ling et al., 2017). We also examine the performance of our method on RGSM (Chen et al.), which focuses on changing the question premise order to challenge LLM reading comprehension in an arithmetic setting. Finally, we evaluate on GSMSymbolic dataset (Mirzadeh et al., 2024), which changes the original GSM8K questions through symbolic template (i.e. changing the numerical values). Logical Reasoning We choose five tasks from BigBench Hard (Suzgun et al., 2023): Logical Deduction Five Objects, Logical Deduction Seven Objects, Reasoning about Colored Objects, Causal Judgement, and Navigate. For brevity, we refer to these datasets as Five Objects, Seven Objects, Colored Objects, Judgement, and Navigate. Question Answering We choose StrategyQA (Geva et al., 5 2021), SpartQA (Mirzaee et al., 2021), and Date Understanding (Suzgun et al., 2023) to evaluate our method on question-answering tasks. Reading Comprehension We use the Break and Census subsets of the DROP reading comprehension benchmark (Dua et al., 2019). 5. Results 5.1. HoT consistently improves LLM accuracy across models and datasets compared to CoT We hypothesize that since HoT prompting directly encourages LLMs to identify and then leverage facts in the question in the chain of thoughts, it may improve the accuracy of the answer and reduce hallucination. Therefore, here, we test whether HoT would improve the accuracy of the final answer over CoT. Experiment We compare 8-shot CoT and 8-shot including the proprietary models HoT on five LLMs, ), Gemini-1.5-Pro GPT-4o ( ), ( Llama-3.1-405B ( ) across 17 tasks. Both the CoT and HoT few-shot demonstration examples use the same ques- ) and open-source models Llama-3.1-70B ( ), Gemini-1.5-Flash ( HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table 3: HoT outperforms CoT across logical reasoning BBH subsets, with notable gains in Judgment ( +15.5 for Five Object tasks (+6.00 for ). ) and Model Method CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean Five Objects 78.80 82.00 (+3.20) 92.80 98.80 (+6.00) 92.80 94.00 (+1.20) 95.60 97.20 (+1.60) 93.60 92.80 (-0.80) +2. Seven Objects Colored Objects 74.80 79.20 (+4.40) 86.00 88.80 (+2.80) 79.60 83.60 (+4.00) 89.60 90.00 (+0.40) 85.20 86.40 (+1.20) +2.56 94.00 95.20 (+1.20) 96.40 97.20 (+0.80) 92.00 93.60 (+1.60) 96.80 97.20 (+0.40) 98.40 98.80 (+0.40) +0.88 Judgement 71.66 71.66 74.87 75.40 (+0.53) 67.91 71.12 (+3.21) 67.91 74.33 (+6.42) 73.80 89.30 (+15.5) +5.13 Navigate 92.80 92.80 92.00 96.40 (+4.40) 87.60 90.40 (+2.80) 95.20 97.20 (+2.00) 96.40 96.40 +1.84 Task Mean () 82.41 84.17 (+1.76) 88.41 91.32 (+2.91) 83.98 86.54 (+2.56) 89.02 91.19 (+2.16) 89.48 92.74 (+3.26) +2. tions and answers. The key difference is that HoT examples contain XML tags, while CoT examples do not. Results HoT consistently improves over CoT across most datasets and models. On average, HoT improves LLM accuracy on arithmetic, question answering, and logical reasoning tasks by +1.6 (Tab. 1), +2.58 (Tab. 2), and +2.53 pp (Tab. 3), respectively. While the gains are larger for some datasets (e.g., +4.98 and +4.91 on AQUA and StrategyQA), they are modest on GSM8K, MultiArith, and ASDiv (+0.05, +0.57, +0.11 pp in Tab. 1, respectively) perhaps because the CoT accuracy scores on these tasks are nearly saturating (close to 100%). In contrast, on recent adversarial, more challenging versions of GSM8K (i.e., r-GSM and GSM-Symbolic), HoT show substantial improvements of +3.09 and +0.87 pp (Tab. 1), respectively. 5.2. Ablation study: Repeating the question alone and adding tags to the questions and answers improve LLM accuracy As HoT consistently outperforms CoT over many tasks (Sec. 5.1), natural question is: What components contribute to HoT success? HoT consists of two steps: (a) regenerating the question but with XML tags around key facts; and (b) adding tags to the answer. Interestingly, concurrent work showed that repeating the question alone can help LLM improve accuracy (Mekala et al., 2024). Therefore, we perform an ablation study to understand the impact of each HoT component: (1) Repeating the question alone (no tags); (2) Repeating the question and add tags; and (3) Adding tags to the answer only but not the question. Experiment That is, we compare the following variations: et al., 2024). Tags in Question (T-Q): Wrap key facts in the input question with XML tags while leaving the answer untagged. Tags in Answer (T-A): Repeat the original input question with no changes and wrap key facts in the answer with XML tags. Tags in Question and Answer (HoT): The full HoT recipe, i.e. wrapping XML tags around key facts in the reformatted question and also adding corresponding tags to the answer. For each prompting method above, we evaluate four representative models ( ) on 400 randomly sam- , pled instances across six datasets (AQUA, StrategyQA, rGSM, Seven Objects, Judgement, and Navigate). , , Figure 6: Our ablation study shows that every component in HoT prompting (+)repeating the question (R-Q), adding tags to only question (T-Q), adding tags to only answer (TA)contributes to the accuracy of our HoT method. Every HoT component alone outperforms the vanilla CoT (). yaxis shows mean accuracy across 6 datasets. CoT: Few-shot CoT baseline (Wei et al., 2022). Repeated Question (R-Q): Repeat the input question and then generate the regular CoT answer (Mekala Results First, on average across 6 datasets and 4 LLMs, every variation (R-Q, T-Q, T-A, and HoT) outperforms the baseline CoT  (Fig. 6)  . That is, each HoT component is an improvement over CoT. Second, for some smaller LLMs HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs , ( accuracy while the trend is weaker for larger models ( ), adding each component monotonically increases ). 5.3. Tagging arbitrary phrases in the answer hurts HoT accuracy Both T-Q and T-A only add small accuracy gain over R-Q but underperform HoT  (Fig. 6)  . This shows that adding tags to only the question or answer is suboptimal and that adding tags to both the question and answer (HoT) results in the best performance. Given that the key facts are already accurately tagged in the question, an interesting question is whether associated facts in the answer need to be accurately tagged for HoT to work. Does the correspondence between tags in the question and those matching in the answer matter? and Interestingly, examining the results of the T-A method shows ), while we instruct that, for larger LLMs (i.e. them via demonstrations to insert tags exclusively to the answer (but not the question), these two models still generate, on average, 3.27 and 2.27 tags, respectively, in each question (Tab. 4). As the result, instructing LLMs to generate tags exclusively in the answer (T-A) is sufficient for large LLms to gain accuracy over not having tags at all (CoT, and R-Q). Table 4: The mean number of tags generated by LLMs for HoT match that by few-show demonstrations the most compared to other variations (T-Q and T-A), showing the importance of instructing LLMs to insert tags to both questions and answers (i.e., HoT). All numbers are means computed across 6 datasets in the ablation study. Method Model mean T-Q T-A HoT T-Q T-A HoT (a) Mean number of tags in Question 9.28 0.02 9.04 11.41 3.27 10. 9.04 0.35 9.35 9.92 2.27 10.05 (b) Mean number of tags in Answer 0.00 13.54 10.24 0.00 13.23 13.15 0.06 14.48 12. 0.00 12.02 12.28 9.91 1.48 9.79 8.99 0.00 8.99 0.02 13.32 11.95 0.00 10.18 10.18 Averaging over 4 models and 6 datasets, T-A gains +1.79 (83.29 vs. 81.50; Tab. 5), and +0.10 (83.29 vs. 83.19; Tab. 5) in accuracy compared to CoT and R-Q, i.e., not having any tags at all. Table 5: Prompting techniques that cause LLMs to generate more tags tend to results in higher accuracy (mean over 6 datasets and 4 LLMs). Method Total tags in Q&A Accuracy CoT R-Q T-Q T-A HoT 0.00 0.00 4.96 7.40 10.87 81.50 83.19 83.21 83.29 85.05 Here, we attempt to understand the importance of the correspondence by keeping HoT few-shot demonstrations intact, but relocate the tags in all answers to random phrase (see examples in Tab. T25). How would this mismatch impact LLM accuracy on the task? , , and Experiment We compare the accuracy of 4 models ( , ) using few-shot prompts with original HoT tags against those with mismatched tags. To generate examples with mismatched tags, we intentionally alter the original HoT few-shot examples by changing the tag locations in the answers. We run on 7 datasets (GSM8K, StrategyQA, Causal Judgement, AQUA, Seven Objects, Navigate). Results Mismatched tagging reduces HoT accuracy by -2.13 pp in average (Fig. 7b). However, the impact varies substantially across different datasets. For example, the accuracy drop is much higher in AQuA -9.93 pp compared to GSM8K -0.50 pp. This might be because, in AQUA, when exposed to few-shot examples with mismatched tags, LLMs are less likely to generate tags in their responses, resulting in performance drop compared to when they are exposed to matched tags. Even when the question and answer tags are mismatched, HoT still outperforms CoT by +1.21 pp (see Fig. 7c). Despite the misalignment, the LLM can still learn from fewshot examples and apply correct tagging to new questions, preserving some of HoTs advantages over CoT. This also explains the marginal decrease in some datasets, such as Navigate (-0.80) and Seven Objects (-0.50) pp (Fig. 7a). 5.4. HoT highlights improve the speed of humans when verifying LLM answers In text classification, high-quality text highlighting in given paragraph can substantially reduce binary decision time and perceived efforts for humans (Ramírez et al., 2019). However, at the same time, low-quality highlights negatively affect user accuracy (Ramírez et al., 2019). Here, we also aim to assess how our HoT highlights in LLM answers impact user decision verification accuracy and time. That is, users are asked to decide whether the final answer (e.g., to an arithmetic question) is accurate given the input question, the HoT chain of thoughts and the predicted final answer by LLMs. To our knowledge, this would be the first study in the LLM literature that studies how highlights in chains of 7 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs (a) (b) Mean (mismatched HoTHoT) accuracy across four models. Model Task Mean -2.22 -2.70 -2. -0.79 Model Mean -2.13 (c) Mean (mismatched HoTCoT) accuracy across four models. Model Task Mean 1.00 1. 0.63 1.56 Model Mean 1.21 Figure 7: (a) Moving tags in the answer of HoT to random phrases (i.e., Mismatched HoT) results in substantial accuracy drops across many datasets e.g., this is -3.25 for (b) The average accuracy drop of Mismatched HoT w.r.t. HoT is -2.13 pp. (c) On average across 4 LLMs, Mismatched HoT still outperforms vanilla CoT by mean gain of +1.21 pp. . thought impact user on downstream task. Experiment To evaluate the impact of highlights to humans on arithmetic and reading comprehension problems, we measure user accuracy in verifying whether LLM re- ) are accurate for GSMand sponses (of Symbolic and DROP questions. This verification task is known as distinction (Kim et al., 2022) or verification task (Taesiri et al., 2022; Nguyen et al., 2021). , , , We select 30 incorrect and 30 correct LLM responses from each dataset in order to have balanced pool of questions with (30 + 30) 2 = 120 cases of HoT. For our control, we take these 120 HoT responses and strip out the XML <fact> tags using regex, creating 120 new question-answer pairs that look identical to CoT responses for total of 240 possible LLM answers that users could verify. We recruit 63 users, each verifying 10 LLM responses to questions from GSM-Symbolic and DROP via an online interface (see Appendix A.3). Users are randomly assigned to see exclusively HoT or CoT responses and then have to predict if response is correct or incorrect. Users are specifically instructed not to use external aids (e.g. pen, paper, internet, calculators) and instead rely solely on their own mental ability to discover flaws in the LLM responses. To simulate real-world constraints, users are given maximum of 2 minutes per question, after which, they are required to make decision. Users spend 25% less time when verifying Table 6: chains of thoughts with highlights (compared to without highlights). Highlights tend to cause users to accept LLM answers more, resulting in improved accuracy in correct cases and worse accuracy in incorrect ones. Method Avg Time (secs) Accuracy (%) LLM is correct 84.48 20.28 78.82 28.26 Accuracy (%) LLM is incorrect 54.83 30.13 72.21 21.99 HoT CoT 47.26 62.38 Results On average, over all 240 cases including both correct and incorrect answers, users spend nearly 25% less time (47.26 vs. 62.38 seconds, i.e. +15.12 seconds 8 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs faster) when making decisions with highlights (Tab. 6). This faster decision time is consistent with previous studies in the pre-LLM era (Ramírez et al., 2019). Regarding user verification accuracy, because the ratio of correct/incorrect cases depends on specific LLM and dataset, therefore, here, we report user accuracy on these two subsets separately (Tab. 6). Interestingly, users perform better on correct cases (84.48 vs. 78.82) but worse on incorrect cases (54.83 vs. 72.21). That is, HoT highlights tend to make users believe that an answer is accurate, making them more likely to accept the answer. This is surprising finding that informs future research on how to leverage highlights in LLM chain of thoughts, especially when highlights are increasingly more common in search engine results (BingSearch; Porter, 2020). 5.5. HoT is estimated to improve user verification accuracy on all 17 datasets. Because testing users on all 17 datasets is infeasible, here, we estimate the verification accuracy of users when highlights are displayed or not (i.e. HoT vs. CoT). We estimate the verification accuracy of users on given dataset by the following equation: 5.6. HoT does not hurt LLM-as-a-verifier accuracy. Instead of asking users to verify the accuracy of LLM answers, it is increasingly common to ask other LLMs to verify instead of humans (Zheng et al., 2023). That process would substantially reduce human labor and enable selfimprovement and iterative thinking processes (DeepSeek-AI et al., 2025). Here, we also test whether to LLMs would impact in verifying whether the answer is accurate. test on GPT-4o, GPT-4o-mini ( Gemini-1.5-Flash, text-only Deepseek R1 ( Llama 3.2 90B (vision) ( verify answers in HoT and CoT format. feeding HoT answers the LLM-verifier accuracy Our ), Gemini-1.5-Pro, ), and ) on their ability to accurately However, we find no consistent trend showing whether highlights help or hurt the accuracy across all models and modalities (image, text, and image-text). See Appendix for experiment details and results. Our leading hypothesis for the lack of verification accuracy improvement here is that while LLMs are able to consistently track facts from the question in the answer with our HoT prompting, the cause of incorrect answers lies in information outside of the XML tags. = Mc Hc + (1 Mc) Hi 6. Limitations where Mc is the actual LLM accuracy for the dataset (Tabs. 1 to 3), Hc and Hi are the human accuracy scores on the correct and incorrect cases, respectively (Tab. 6). Since LLMs tend to have relatively high accuracy of 80% on most 17 datasets, we find that the averaged estimated verification accuracy of HoT across all types of datasets (Appendix F) is higher to CoT by an average of +3.33 across all five LLMs (Tab. 7). Table 7: The estimated human verification accuracy on all 17 benchmarks is higher with highlights (HoT) rather than without highlights (CoT). More results in Appendix F. Model Prompt CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Mean Arithmetic tasks Mean () 78.15 82.44 (+4.28) 78.15 82.69 (+4.54) 78.29 82.14 (+3.86) 78.37 82.75 (+4.38) 78.25 82.33 (+4.08) +4.23 Reading Comp. tasks Mean () Logical Reasoning tasks Mean () 77.40 79.25 (+1.85) 77.76 80.44 (+2.68) 77.72 80.47 (+2.75) 78.01 81.39 (+3.38) 77.70 80.21 (+2.50) +2.63 77.63 79.80 (+2.16) 78.03 81.92 (+3.89) 77.74 80.50 (+2.30) 78.07 81.88 (+3.81) 78.10 82.34 (+3.53) +3. 9 The process of regenerating questions with tags introduces the risk of models incorrectly reformulating the original question (Tab. T40) or failing to adhere to the prescribed tag format, as demonstrated in the few-shot examples (Tab. T11). While larger models such as are generally able to follow the format reliably, smaller models can exhibit inconsistencies, sometimes relike peating the few-shot examples (Tab. T11). These findings emphasize the challenges of ensuring consistent tagging behavior across models of varying sizes and the importance of addressing these limitations in future work. , and and Additionally, while reasoning models such as DeepSeek-R1 and Gemini-2.0-Flash-Thinking (DeepMind, 2024) are proficient at generating highlighted responses with HoT (see Tabs. T57 and T59), there is no observed improvement of HoT over CoT in benchmark accuracy (Tab. T55). These results align with the warnings from the DeepSeek-R1 authors that few-shot examples (such as the few-shot examples needed to run HoT) can actually hurt model performance. Similar to findings in explainable AI research (Taesiri et al., 2022), HoT highlights, in our work, can sometimes fool users into over-believing in LLM answers, even when they are wrong (Sec. 5.4). HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs 7. Discussion and Future Work potential explanation for why HoT increases LLM accuracy is that encouraging the model to generate matching <fact> tag pairs in both the question and answer, results in the tags being shown twice in the attention matrix, encouraging the amount of attention paid to those tags. This explanation would align with findings from (Mekala et al., 2024) and (Xu et al., 2024). However, future research is needed to validate this hypothesis. Additionally, LLMs can also highlight the derived results and properly be referenced in later parts of the chain (as shown in Appendix M). By tagging both explicit facts and intermediate computed results, LLMs can help users and downstream applications verify, audit, and interpret complex reasoning processes more transparently. Currently, we rely on few-shot HoT demonstrations to instruct LLMs to generate tagged questions and answers. In the future, finetuning LLMs to generate HoT directly is promising approach. 8. Conclusion We present Highlighted Chain of Thought Prompting (HoT), novel prompting approach that enables LLMs to directly reference text from the input question in their responses. HoT interestingly improves LLM accuracy on arithmetic, question answering, and logical reasoning tasks. Furthermore, highlights in HoT answers improve user speed and estimated verification accuracy."
        },
        {
            "title": "Acknowledgments",
            "content": "We are thankful for the API research credits from together.ai to MRT. ATN was supported by the NSF Grant No. 1850117 & 2145767, and donations from NaphCare Foundation & Adobe Research. 10 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs References Anthropic. Anthropic: Responsible ai for the future. https: //www.anthropic.com, 2025. Accessed: 2025-01-24. Asai, A., Wu, Z., Wang, Y., Sil, A., and Hajishirzi, H. Selfrag: Learning to retrieve, generate, and critique through self-reflection. In The Twelfth International Conference on Learning Representations. Bai, Y., Lv, X., Gu, W., Liu, D., Zou, M., Cao, S., Hou, L., Dong, Y., Feng, L., Li, J., et al. Longcite: Enabling llms to generate fine-grained citations in long-context qa. arXiv preprint arXiv:2409.02897, 2024. BingSearch. Bing search engine. https://www.bing.com. Accessed: 2024-12-02. Bohnet, B., Tran, V. Q., Verga, P., Aharoni, R., Andor, D., Soares, L. B., Ciaramita, M., Eisenstein, J., Ganchev, K., Herzig, J., et al. Attributed question answering: Evaluation and modeling for attributed large language models. arXiv preprint arXiv:2212.08037, 2022. Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners, 2020. URL https://arxiv.org/abs/2005.14165. Chen, X., Chi, R. A., Wang, X., and Zhou, D. Premise order matters in reasoning with large language models. In Fortyfirst International Conference on Machine Learning. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. Cohen-Wang, B., Shah, H., Georgiev, K., and Madry, A. Contextcite: Attributing model generation to context. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. URL https: //openreview.net/forum?id=7CMNSqsZJt. Dasigi, P., Liu, N. F., Marasovic, A., Smith, N. A., and Gardner, M. Quoref: reading comprehension dataset with questions requiring coreferential reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 59255932, 2019. Dasigi, P., Lo, K., Beltagy, I., Cohan, A., Smith, N. A., and Gardner, M. dataset of information-seeking questions and answers anchored in research papers. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 45994610, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.365. URL https://aclanthology.org/2021.naacl-main.365. DeepMind. Flash thinking: Scaling efficient language models with gemini flash, 2024. URL https://deepmind. google/technologies/gemini/flash-thinking/. Accessed: Dec, 2024. DeepSeek-AI, Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., Wang, P., Bi, X., Zhang, X., Yu, X., Wu, Y., Wu, Z. F., Gou, Z., Shao, Z., Li, Z., Gao, Z., Liu, A., Xue, B., Wang, B., Wu, B., Feng, B., Lu, C., Zhao, C., Deng, C., Zhang, C., Ruan, C., Dai, D., Chen, D., Ji, D., Li, E., Lin, F., Dai, F., Luo, F., Hao, G., Chen, G., Li, G., Zhang, H., Bao, H., Xu, H., Wang, H., Ding, H., Xin, H., Gao, H., Qu, H., Li, H., Guo, J., Li, J., Wang, J., Chen, J., Yuan, J., Qiu, J., Li, J., Cai, J. L., Ni, J., Liang, J., Chen, J., Dong, K., Hu, K., Gao, K., Guan, K., Huang, K., Yu, K., Wang, L., Zhang, L., Zhao, L., Wang, L., Zhang, L., Xu, L., Xia, L., Zhang, M., Zhang, M., Tang, M., Li, M., Wang, M., Li, M., Tian, N., Huang, P., Zhang, P., Wang, Q., Chen, Q., Du, Q., Ge, R., Zhang, R., Pan, R., Wang, R., Chen, R. J., Jin, R. L., Chen, R., Lu, S., Zhou, S., Chen, S., Ye, S., Wang, S., Yu, S., Zhou, S., Pan, S., Li, S. S., Zhou, S., Wu, S., Ye, S., Yun, T., Pei, T., Sun, T., Wang, T., Zeng, W., Zhao, W., Liu, W., Liang, W., Gao, W., Yu, W., Zhang, W., Xiao, W. L., An, W., Liu, X., Wang, X., Chen, X., Nie, X., Cheng, X., Liu, X., Xie, X., Liu, X., Yang, X., Li, X., Su, X., Lin, X., Li, X. Q., Jin, X., Shen, X., Chen, X., Sun, X., Wang, X., Song, X., Zhou, X., Wang, X., Shan, X., Li, Y. K., Wang, Y. Q., Wei, Y. X., Zhang, Y., Xu, Y., Li, Y., Zhao, Y., Sun, Y., Wang, Y., Yu, Y., Zhang, Y., Shi, Y., Xiong, Y., He, Y., Piao, Y., Wang, Y., Tan, Y., Ma, Y., Liu, Y., Guo, Y., Ou, Y., Wang, Y., Gong, Y., Zou, Y., He, Y., Xiong, Y., Luo, Y., You, Y., Liu, Y., Zhou, Y., Zhu, Y. X., Xu, Y., Huang, Y., Li, Y., Zheng, Y., Zhu, Y., Ma, Y., Tang, Y., Zha, Y., Yan, Y., Ren, Z. Z., Ren, Z., Sha, Z., Fu, Z., Xu, Z., Xie, Z., Zhang, Z., Hao, Z., Ma, Z., Yan, Z., Wu, Z., Gu, Z., Zhu, Z., Liu, Z., Li, Z., Xie, Z., Song, Z., Pan, Z., Huang, Z., Xu, Z., Zhang, Z., and Zhang, Z. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948. Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M. DROP: reading comprehension benchmark requiring discrete reasoning over paragraphs. 11 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs In Burstein, J., Doran, C., and Solorio, T. (eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 23682378, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1246. URL https: //aclanthology.org/N19-1246. Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan, A., et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. Fowler, R. L. and Barker, A. S. Effectiveness of highlighting for retention of text material. Journal of Applied Psychology, 59(3):358364, 1974. doi: 10.1037/h0036750. Gao, T., Yen, H., Yu, J., and Chen, D. Enabling large language models to generate text with citations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 64656488, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.398. URL https://aclanthology.org/2023.emnlp-main.398. Geva, M., Khashabi, D., Segal, E., Khot, T., Roth, D., and Berant, J. Did aristotle use laptop? question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9: 346361, 2021. Gier, V. S., Kreiner, D. S., and Natz-Gonzalez, A. Harmful effects of preexisting inappropriate highlighting on reading comprehension and metacognitive accuracy. The Journal of general psychology, 136(3):287302, 2009. Jin, J., Zhu, Y., Yang, X., Zhang, C., and Dou, Z. Flashrag: modular toolkit for efficient retrieval-augmented generation research. arXiv preprint arXiv:2405.13576, 2024. Kim, S. S., Meister, N., Ramaswamy, V. V., Fong, R., and Russakovsky, O. Hive: Evaluating the human interpretability of visual explanations. In European Conference on Computer Vision, pp. 280298. Springer, 2022. Li, J., Monroe, W., and Jurafsky, D. Understanding neural networks through representation erasure. arXiv preprint arXiv:1612.08220, 2016. Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Program induction by rationale generation: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 158167, 2017. Liu, J. LlamaIndex, 11 2022. URL https://github.com/ jerryjliu/llama_index. Mekala, R. S. R., Razeghi, Y., and Singh, S. EchoPrompt: Instructing the model to rephrase queries for improved in-context learning. In Duh, K., Gomez, H., and Bethard, S. (eds.), Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), pp. 399432, Mexico City, Mexico, June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.naacl-short.35. URL https://aclanthology.org/2024.naacl-short.35. Miao, S.-Y., Liang, C.-C., and Su, K.-Y. diverse corpus for evaluating and developing english math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 975984, 2020. Mirzadeh, I., Alizadeh, K., Shahrokhi, H., Tuzel, O., Bengio, S., and Farajtabar, M. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models. arXiv preprint arXiv:2410.05229, 2024. Mirzaee, R., Faghihi, H. R., Ning, Q., and Kordjmashidi, P. Spartqa:: textual question answering benchmark for spatial reasoning. arXiv preprint arXiv:2104.05832, 2021. Nguyen, G., Kim, D., and Nguyen, A. The effectiveness of feature attribution methods and its correlation with automatic evaluation scores. Advances in Neural Information Processing Systems, 34:2642226436, 2021. OpenAI. Hello gpt-4o openai. com/index/hello-gpt-4o/, 5 2024. 05/31/2024). https://openai. (Accessed on Patel, A., Bhattamishra, S., and Goyal, N. Are nlp models really able to solve simple math word problems? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 20802094, 2021. Perplexity. Perplexity ai: The answer engine. https:// www.perplexity.ai. Accessed: 2024-12-02. Porter, J. Google now highlights search results diURL the verge, 6 2020. rectly on webpages https://www.theverge.com/2020/6/4/21280115/ google-search-engine-yellow-highlight-featured-snippet-anchor-text. [Online; accessed 2025-03-03]. Press, O., Hochlehnert, A., Prabhu, A., Udandarao, V., Press, O., and Bethge, M. Citeme: Can language models accurately cite scientific claims? In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs 1300313051, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. findings-acl.824. URL https://aclanthology.org/ 2023.findings-acl.824. Taesiri, M. R., Nguyen, G., and Nguyen, A. Visual correspondence-based explanations improve ai robustness and human-ai team accuracy. Advances in Neural Information Processing Systems, 35:3428734301, 2022. Tan, J., Dou, Z., Wang, W., Wang, M., Chen, W., and Wen, J.-R. Htmlrag: Html is better than plain text for modeling retrieved knowledge in rag systems. arXiv preprint arXiv:2411.02959, 2024. Taylor, R., Kardas, M., Cucurull, G., Scialom, T., Hartshorn, A., Saravia, E., Poulton, A., Kerkez, V., and Stojnic, R. Galactica: large language model for science. arXiv preprint arXiv:2211.09085, 2022. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., Lou, J.-G., and Ma, S. Re-reading improves reasoning in large language models. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1554915575, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.871. URL https://aclanthology.org/2024.emnlp-main.871. Zhang, Y., Li, Y., Cui, L., Cai, D., Liu, L., Fu, T., Huang, X., Zhao, E., Zhang, Y., Chen, Y., et al. Sirens song in the ai ocean: survey on hallucination in large language models. arXiv preprint arXiv:2309.01219, 2023. Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36: 4659546623, 2023. Qwen Team. QwQ: Reflect deeply on the boundaries of the unknown, 2024. URL https://qwenlm.github.io/ blog/qwq-32b-preview/. Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. SQuAD: 100,000+ questions for machine comprehension of text. In Su, J., Duh, K., and Carreras, X. (eds.), Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 23832392, Austin, Texas, November 2016. Association for Computational Linguistics. doi: 10.18653/v1/D16-1264. URL https: //aclanthology.org/D16-1264. Ramírez, J., Baez, M., Casati, F., and Benatallah, B. Understanding the impact of text highlighting in crowdsourcing tasks. In Proceedings of the AAAI conference on human computation and crowdsourcing, volume 7, pp. 144152, 2019. Ramu, P., Goswami, K., Saxena, A., and Srinivasan, B. V. Enhancing post-hoc attributions in long document comprehension via coarse grained answer decomposition. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1779017806, 2024. Reid, M., Savinov, N., Teplyashin, D., Lepikhin, D., Lillicrap, T., Alayrac, J.-b., Soricut, R., Lazaridou, A., Firat, O., Schrittwieser, J., et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024. Roy, S. and Roth, D. Solving general arithmetic word problems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 17431752, 2015. Sancheti, A., Goswami, K., and Srinivasan, B. Post-hoc answer attribution for grounded and trustworthy long document comprehension: Task, insights, and challenges. In Bollegala, D. and Shwartz, V. (eds.), Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024), pp. 4957, Mexico City, Mexico, June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.starsem-1.4. URL https://aclanthology.org/2024.starsem-1.4/. SearchGPT. Introducing chatgpt with search. https:// openai.com/index/introducing-chatgpt-search/. Accessed: 2024-12-02. Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q., Chi, E., Zhou, D., and Wei, J. Challenging BIG-bench tasks and whether chain-of-thought can solve them. In Rogers, A., BoydGraber, J., and Okazaki, N. (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp. 13 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Appendix for: HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs A."
        },
        {
            "title": "Human Study",
            "content": "A.1. User Instructions At the beginning of the quiz, the users were given the following instructions: 1. Your job is to judge whether the answers to the provided questions are correct or incorrect. This quiz is test to determine how well you can verify the correct or incorrect answer using only the answer reasoning provided. 2. Please do not use any external resources or scratch paper to help figure out the correct answer. 3. You will be timed while judging 10 random questions. This quiz will take maximum of 20 minutes. 4. Only use computer for this quiz, NOT phone. Following these instructions, the user was presented with an example of correct or incorrect CoT or HoT response, depending on which group they were randomly assigned to. After the examples, the user was presented with two practice problems. These questions were extremely trivial, GSM8K type questions that were also CoT or HoT according to the users group Finally, the user was instructed that they were about to begin the actual quiz and that they would have maximum amount of time of two minutes per question. A.2. Data Analysis During analysis of the experimental results, we noticed that some users would take most of the quiz legitimately, but near the end of the quiz they would pick random answer choices to finish as quickly as possible. To prevent these random answers from affecting our analysis while still keeping their legitimate answers from the beginning of the quiz, we filtered out any responses where the user took less than 5 seconds to answer the question. If user went over the 2 minute time limit per question, we logged that as if the user selected the answer option that stated the provided answer was result of incorrect reasoning. Our logic for this was that if the user was not able to verify an answer in 2 minutes, they likely were not confident about the validity of the answer. Therefore, it is reasonable to mark their answer as being that the given answer was incorrect. A.3. Interface Examples A.4. Examples Where Users Incorrectly Accept, Incorrectly Reject, Correctly Accept, Correctly Reject An LLM Answer In this section, we analyze different cases where users verify LLM-generated answers, categorizing them into four possible outcomes: Incorrect Acceptance Users mistakenly accept an incorrect LLM answer (as shown in Tab. T3). Incorrect Rejection Users wrongly reject correct LLM answer (as shown in Tab. T4). Correct Acceptance Users correctly accept correct LLM answer (as shown in Tab. T2). Correct Rejection Users correctly reject an incorrect LLM answer (as shown in Tab. T5). By examining these cases, we aim to understand the challenges users face in verifying LLM outputs and identify patterns that influence their decision-making. This analysis helps assess the effectiveness of our approach in improving user verification accuracy and reducing errors. HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Figure F1: Screenshot of CoT question from the DROP dataset in the online interface. B. LLM-as-a-Judge accuracy with HoT Motivation The relevance of LLM-as-a-Judge techniques has become prominent with LLMs providing automatic feedback for post-training fine tuning (Dubey et al., 2024) and evaluations (DeepSeek-AI et al., 2025). Given that human verification ability is aided by HoT as compared to CoT (Tab. 6), we aim to understand if multimodal models verification ability is also benefited with HoT as compared to CoT. Human users only view HoT responses with the special <fact> tokens replaced with color highlighting in order to reduce the total amount of text that needs to be read. However, multimodal models strength in textual understanding means that they are able to easily understand dense bodies of text that would normally be daunting for humans to read. Therefore, when evaluating if HoT helps LLMs verification ability, we test their ability to understand HoT in the formats of raw text as well screenshots of regex parsed HoT responses with color highlighting that the multimodal model sees as an image. Experimental Setup We gather an equal amount of HoT responses from Llama-3.1-8B, Llama-3.1-70B, Llama-3.1-405B, Gemini-1.5-Pro, and Gemini-1.5-Flash from GSM-Symbolic and DROP for total of 500 LLM responses where half the responses are correct and half the responses are incorrect. To create the CoT set of questions, we take the 500 HoT responses and strip out any XML tags to create another set of 500 question answer pairs that are in CoT format. We test GPT-4o, GPT-4o-mini ( and Llama 3.2 90B (vision) ( for text-based and image-based verification are in Fig. F3. Results On average, HoT helps the verification accuracy of models like Gemini-1.5-Pro and GPT-4o-mini, but hurts the verification accuracy of Gemini-1.5-Flash and GPT-4o (Tab. T1). Similarly to humans, the ChatGPT models and Deepseek R1 are benefited by HoT when the provided answer reasoning is correct. In contrast, Gemini models only benefit when the answer reasoning is incorrect. HoT provides strong benefit of +12.40 pp when compared to CoT on incorrect LLM answers with Llama 3.2 90B. (Tab. T1). Despite this, when the HoT responses are in image form, CoT is better. However, the near 50% accuracy of Llama 3.2 90B across the board on images with CoT and HoT implies that the model is responding in near random way. ), Gemini-1.5-Pro, Gemini-1.5-Flash, Deepseek R1 ( ) (which is not multimodal) ) on their ability to accurately verify answers in HoT and CoT format. The prompts used 15 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Figure F2: Screenshot of HoT question from the GSM-Symbolic dataset in the online interface. Table T1: HoT and CoT have mixed effects on LLM-as-a-Judge accuracy across different models and modalities. Model Prompt Accuracy When Answer is Correct Accuracy When Answer is Incorrect CoT HoT CoT HoT CoT HoT CoT HoT CoT HoT CoT HoT Mean Text 63.86 53.41 (-10.54) 63.60 61.60 (-2.00) 83.60 87.60 (+4.00) 95.20 96.00 (+0.80) 90.00 90.80 (+0.80) 88.80 89.60 (+0.80) -1. Image 71.54 54.00 (17.54) 87.60 86.80 (-0.80) 83.20 86.40 (+2.80) 95.20 96.00 (+0.80) - - 57.20 48.40 (-8.80) -3.69 Text 64.40 66.94 (+2.54) 63.60 68.00 (+4.40) 52.40 47.20 (-4.80) 43.20 36.00 (-7.20) 44.00 42.40 (-1.80) 47.20 59.60 (+12.40) -1.27 Image 58.00 67.07 (+9.07) 34.80 36.40 (+1.60) 43.20 43.20 43.20 36.00 (-7.20) - - 59.60 52.80 (-6.80) +0.87 Overall, the presentation of HoT answers as either text-based or image-based does not seem to be strongly correlated with the LLM verification accuracy. In conclusion, HoT offers the advantage of higher answer accuracy (Tab. 1, Tab. 2, Tab. 3) but does not offer significant increases in LLM-as-a-Judge accuracy when compared to CoT. HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Text-based and Image-based Prompts for visual HoT Verification TEXT_ONLY_PROMPT = \"Read the question and answer below. Verify if the answer is correct or is flawed. After thinking and solving provide your final answer as yes and no in curly braces. yes means the answer is correct, no means the answer is flawed.\" IMAGE_TEXT_PROMPT = \"First examine the question and answer in the image. Then verify if the answer is correct or is flawed. After thinking and solving provide your final answer as yes and no in curly braces. yes means the answer is correct, no means the answer is flawed.\" Figure F3: Text-based and Image-based prompts used in verifying HoT answers. Table T2: HoT Examples of LLMs where Users Correctly Accept LLM Answers. GSM-Symbolic Question: bottle of lemonade is 12 ounces of lemonade. Mateo drinks 3 bottles of lemonade. If lemonade has 4 calories per ounce how many calories did he consume? LLM Answer: Mateo consumed 3 bottles of lemonade * 12 ounces of lemonade = 36 ounces of lemonade. Since lemonade has 4 calories per ounce, Mateo consumed 36 ounces * 4 calories per ounce = 144 calories. The answer is 144. (GT: 144) DROP Question: Coming off their home loss to the Jets, the Bucs flew to Qwest Field for week 15 duel against the Seattle Seahawks. After scoreless first quarter, Seattle got on the board first with QB Matt Hasselbecks 29-yard pass to tight end John Carlson. The Bucs got on the board with Connor Barths 28-yard field goal to end the first half. In the third quarter, Tampa Bay took the lead after 45-yard field goal and 22-yard touchdown pass by QB Josh Freeman to running back Cadillac Williams, set up by Tanard Jackson interception. The Buccaneers further extended their lead with 28-yard pass to running back Derrick Ward, with successful two-point conversion. In the fourth quarter, Barth kicked another field goal for 39 yards. Seattle tried to rally, but Hasselbeck threw an interception (his fourth) in the end zone to cornerback Elbert Mack for touchback. With the win, the Buccaneers improved to 2-12. Not only was it their first road win since November 23, 2008, it also marked their first win on the west coast since winning Super Bowl XXXVII in San Diego and their first win in Seattle since 1999. How many yards difference was there between Josh Freemans field goal and touchdown pass? LLM Answer: According to the passage, Josh Freeman had 45-yard field goal and 22-yard touchdown pass. 45 - 22 = 23. So the answer is {23}. (GT: 23) DROP Question: In 2010, 47.3 million people who lived in the EU were born outside their resident country. This corresponds to 9.4% of the total EU population. Of these, 31.4 million (6.3%) were born outside the EU and 16.0 million (3.2%) were born in another EU member state. The largest absolute numbers of people born outside the EU were in Germany (6.4 million), France (5.1 million), the United Kingdom (4.7 million), Spain (4.1 million), Italy (3.2 million), and the Netherlands (1.4 million). How many more millions of people living in the EU were born in Germany than in Italy? LLM Answer: According to the passage, 6.4 million people were born in Germany and 3.2 million people were born in Italy. 6.4 million - 3.2 million = 3.2 million. So the answer is {3.2}. (GT: 3.2) 17 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T3: HoT Examples of LLMs where Users Incorrectly Accept LLM Answers. DROP (37-yard field goal is not highlighted by the LLM) Question: Coming off their home win over the Vikings, the Saints flew to Candlestick Park for Week 2 Monday Night duel with the San Francisco 49ers. New Orleans would deliver the opening punch in the first quarter as 49ers center David Baas high snap deep within San Francisco territory went out of the back of the endzone for safety. The Saints would add onto their lead as quarterback Drew Brees hooked up with running back Reggie Bush on 6-yard touchdown pass. The 49ers would answer in the second quarter as quarterback Alex Smith found running back Frank Gore on 12-yard touchdown pass. San Francisco would take the lead with running back Anthony Dixons 2-yard touchdown run, yet New Orleans would respond with Brees 3-yard touchdown pass to tight end David Thomas. The Saints would add onto their lead in the fourth quarter as kicker Garrett Hartley made 46-yard and 19-yard field goal. The 49ers would strike back as Gore got 7-yard touchdown run, followed by Smiths 2-point conversion pass to tight end Vernon Davis. In the end, New Orleans got the last laugh as Hartley booted the game-ending 37-yard field goal. How many field goals did Garrett Hartley kick in the fourth quarter? LLM Answer: The passage states that in the fourth quarter, Garrett Hartley kicked 46-yard and 19-yard field goal. This means he kicked two field goals in the fourth quarter. So the answer is {2}. (GT: 3) GSM-Symbolic (The LLM incorrectly computed 17241=4100, the correct multiplication is 4097) Question: fog bank rolls in from the ocean to cover city. It takes 241 minutes to cover every 5 miles of the city. If the city is 85 miles across from the oceanfront to the opposite inland edge, how many minutes will it take for the fog bank to cover the whole city? LLM Answer: To find the total time it will take for the fog bank to cover the whole city, we need to divide the total distance across the city by the distance covered in the given time and then multiply by the given time. The total distance across the city is 85 miles and the distance covered in the given time is 5 miles. So, the number of times the given distance fits into the total distance is 85/5 = 17. Now, we multiply this by the given time, which is 241 minutes. Therefore, the total time it will take for the fog bank to cover the whole city is 17 * 241 minutes = 4100 minutes, but since 85 is not perfectly divisible by 5, we should calculate the remaining distance and add the time it takes to cover that distance. The remaining distance is 85 - (17 * 5) = 0 miles, so we dont need to add any extra time. (GT: 4097) DROP (20-yard rushing touchdown is not highlighted by the LLM) Question: Hoping to rebound from their season-opening loss to the Jaguars, the Broncos played on home ground for an interconference duel with the Seattle Seahawks. In the first quarter, the Broncos took the early lead, as quarterback Kyle Orton completed 13-yard touchdown pass to wide receiver Eddie Royal, followed in the second quarter by 1-yard touchdown run from running back Correll Buckhalter and 20-yard field goal by placekicker Matt Prater. The Seahawks got on the board in the third quarter, when quarterback Matt Hasselbeck completed an 11-yard touchdown pass to wide receiver Ben Obomanu, but the Broncos replied with 1-yard touchdown run from running back Knowshon Moreno. The Broncos increased their lead in the fourth quarter, when Orton threw 21-yard touchdown pass to wide receiver Demaryius Thomas. The Seahawks replied, with Hasselbeck scrambling 20 yards for touchdown, but the Broncos lead was too much for Seattle to overcome. How many total yards of rushing touchdowns were scored? Answer: According to the passage, Correll Buckhalter had 1-yard touchdown run, and Knowshon Moreno had 1-yard touchdown run. 1 + 1 = 2. So the answer is {2}. (GT: 22) 18 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T4: HoT Examples of LLMs where Users Incorrectly Reject LLM Answers. DROP Question: In 1997, Russia and Ukraine signed the Partition Treaty, establishing two independent national fleets and dividing armaments and bases between them. Ukraine also agreed to lease major parts of its facilities to the Russian Black Sea Fleet until 2017. However, the treaty appeared to be far from perfect: permanent tensions on the lease details control continued. The Fleets main base is still situated in the Crimean port city of Sevastopol. In 2009 the Yushchenko Ukrainian government declared that the lease would not be extended and that the fleet would have to leave Sevastopol by 2017. In 2010 the Russian leasehold was renegotiated with an extension until 2042 and an option for an additional five years until 2047. For how many years from the original deadline was the lease extended? LLM Answer: According to the passage, the original deadline was 2017 and the lease was extended until 2042. To find the number of years the lease was extended, we need to subtract the original deadline from the new deadline: 2042 - 2017 = 25. So the answer is {25}. (GT: 25) GSM-Symbolic Question: Benjamin has 18 tubes of blue paint and 18 tubes of cyan paint. Deshawn has 2/4 as many tubes of blue paint as Benjamin, and twice as many tubes of cyan paint as Benjamin. How many tubes of paint does DeShawn have? LLM Answer: Deshawn has 2/4 as many tubes of blue paint as Benjamin, so he has 18 * 2/4 = 9 tubes of blue paint. Deshawn also has twice as many tubes of cyan paint as Benjamin, so he has 18 * 2 = 36 tubes of cyan paint. Therefore, Deshawn has 9 + 36 = 45 tubes of paint. The answer is {45}. (GT: 45) DROP Question: After franchise record setting performance the Saints went to face another winless team, the St. Louis Rams. This time, however, the Rams pulled off one of the best upsets in the NFL season. defense kept the Saints scoreless for the first half. The second the Rams sealed the deal with an interception return for 27 yards. With this the Saints fell to 5-3, however this would be the last time the Saints would lose in the regular season. How many losses did the Saints have coming into this game? LLM Answer: According to the passage, the Saints fell to 5-3 after the loss. This means that before the loss, they were 5-2. The \"2\" in 5-2 represents the number of losses the Saints had before the game. So the answer is {2}. (GT: 2) 19 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T5: HoT Examples of LLMs where Users Correctly Reject LLM Answers GSM-Symbolic Question: To make call from hotel room phone, you must pay C0.6 for each minute of your call. After 30 minutes, that price drops to C0.5 per minute. How much would 96-minute call cost? LLM Answer: The call is 96 minutes long, which is longer than 30 minutes. Therefore, the entire call will be charged at the rate of C0.5 per minute. The cost of the call is C0.5 * 96 = C48. (GT: 51) DROP Question: The popular uprising included large areas of Lower Bavaria, the Innviertel and eastern Bavaria. The lands adjoining towns and strongholds were captured by the rebels and the peasant uprising spread to the Bavarian Forest, parts of the Upper Palatinate and Kelheim on the Danube. Braunau Parliament meeting was held in December 1705 in the then-Bavarian Braunau. Long before the French Revolution and early German parliamentarianism the meeting was held on 21 December 1705 in an inn belonging to the Baron von Paumgarten; representatives met of the four estates in Bavaria: aristocracy, clergy, burghers and peasants. The Braunau Parliament is the name of the congress on the defence of the state of Bavaria held at Braunau am Inn convened on 21 December 1705. Following the initial uprising in November 1705, there was little response from the Austrians for nearly two months. However, that changed following an attempt by the rebels to capture the Bavarian capital, Munich. Following their unsuccessful attack, the night of 25 December 1705 saw an Austrian column encounter the peasant army near Sendling outside of Munich. The battle was known as Sendlings Night of Murder or the Sendling Christmas Day Massacre. The insurgents from the Bavarian Oberland were defeated and completely routed by Emperor Joseph Is troops. The number of deaths on the Bavarian side in this battle is estimated at around 1,100 men, but the Austrians lost only about 40. Some of the insurgents were killed after they had already surrendered. About two weeks later, on 8 January 1706, the Battle of Aidenbach ended with the utter defeat of the insurgents and about 4,000 casualties on the Bavarian side. That led to the collapse of the uprising against Austria. How many regions did the popular uprising start in? LLM Answer: According to the passage, the popular uprising started in Lower Bavaria, the Innviertel, and eastern Bavaria initially, then spread to the Bavarian Forest, the Upper Palatinate, and Kelheim on the Danube. So the answer is {6}. (GT: 3) DROP Question: As of the census of 2000, there were 250,291 people, 99,187 households, and 60,702 families residing in the county. The population density was 298 people per square mile (115/km²). There were 104,217 housing units at an average density of 124 per square mile (48/km²). The racial makeup of the county was 90.07% White, 2.82% Black or African American, 0.64% Native American, 2.86% Asian American, 0.06% Pacific Islander, 1.69% from other races, and 1.87% from two or more races. 3.37% of the population were Hispanic or Latino of any race. 39.1% were of Germans, 7.9% English people and 7.8% Irish people ancestry according to Census 2000. How many races each made up less than 1% of the population? LLM Answer: According to the passage, the races that made up less than 1% of the population are Pacific Islander with 0.06% and none of the other races had less than 1%. However, it can be noted that Native American is also relatively close to 1% but still greater than 0.5% with 0.64%. So the answer is {1}. (GT: 2) 20 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T6: On the left, QwQ-32B-Preview fails to generate tags in the question, and its answer is excessively long, despite our few-shot examples providing short and concise answers with sufficient tags in both questions and answers. In contrast, models like Llama-3.1-70B successfully generate tags in both the question and answer, producing responses that are short and concise. Llama-3.1-70B An Example with Reformatted Question: Chris is way behind on his math homework. On Wednesday, he completes onequarter of the remaining math problems. On Tuesday, he completes 3 times as many problems as he did on Monday. He has 100 math problems to complete in total. He completes 12 problems on Monday night. How many math problems does he have left to complete on Thursday? Answer: Chris had 100 math problems to complete in total and completed 12 problems on Monday night, so he had 100 - 12 = 88 problems left to complete on Tuesday. On Tuesday, he completes 3 times as many problems as he did on Monday, so he completes 3 * 12 = 36 problems on Tuesday. This leaves him with 88 - 36 = 52 problems to complete on Wednesday. On Wednesday, he completes one-quarter of the remaining math problems, so he completes 1/4 * 52 = 13 problems on Wednesday. This leaves him with 52 - 13 = 39 problems to complete on Thursday. The answer is {39}. QwQ-32B-Preview An Example with Reformatted Question: Chris is way behind on his math homework. On Wednesday, he completes onequarter of the remaining math problems. On Tuesday, he completes 3 times as many problems as he did on Monday. He has 100 math problems to complete in total. He completes 12 problems on Monday night. How many math problems does he have left to complete on Thursday? Answer: Lets break down the information given and calculate step by step how many math problems Chris has left to complete on Thursday. First, we know that Chris has total of 100 math problems to complete. He completes 12 problems on Monday night. On Tuesday, he completes 3 times as many problems as he did on Monday. So, the number of problems he completes on Tuesday is: 12 * 3 = 36 problems. Now, lets calculate the total number of problems completed by the end of Tuesday: Problems completed on Monday: 12 Problems completed on Tuesday: 36 Total completed by Tuesday: 12 + 36 = 48 problems. Therefore, the remaining problems before Wednesday are: Total problems: 100 - completed by Tuesday: 48 = 52 problems. On Wednesday, Chris completes one-quarter of the remaining math problems. So, he completes: 1/4 * 52 = 13 problems on Wednesday. Now, lets find out how many problems are left after Wednesday: Remaining after Tuesday: 52 - completed on Wednesday: 13 = 39 problems. Therefore, on Thursday, Chris has 39 math problems left to complete. **Final Answer** boxed{39} . 21 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs C. XML Tag Ablation Study C.1. Motivation HoT responses use <fact{num}></fact{num}> style XML tags in order to link facts in the question to facts in the answer. However, there may be better formats of tags that could exist. This motivates us to perform small-scale ablation study with GPT-4o in order to determine which format gives the best accuracy. C.2. Experimental Setup We test the accuracy of HoT responses with several different styles of tags on 200 random samples from 3 different datasets on GPT-4o with the setting of temperature = 0. C.3. Results Of all the different tested formats, <fact{num}> is the most accurate (Tab. T7). Therefore, we chose this format when running large-scale evaluations across all benchmarks. Table T7: <fact{num}> tags are the most effective format for answer accuracy in HoT. Tag Type <fact{num}> (HoT) <FACT{num}> <key_fact{num}> <data{num}> <important{num}> <important_quote{num}> SpartQA r-GSM GSM8K 93.50 91.50 91.50 92.00 92.50 - 96.50 - - 95.00 95.00 94.50 59.00 51.00 54.00 56.00 54.00 - HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs D. Model Details We describe below the exact API versions and settings for each model used in our experiments. D.1. ChatGPT We access the API for GPT-4o and GPT-4o-mini via platform.openai.com. Benchmark Settings Models: gpt-4o-2024-08-06 temperature: 1.0 LLM-as-a-Judge Settings Models: gpt-4o-2024-11-20, gpt-4o-mini-2024-07-18 temperature: API Default D.2. Gemini We access the API for Gemini-1.5-Pro, Gemini-1.5-Flash, and Gemini-2.0-Flash-Thinking via aistudio.google.com, and we use all default settings. Models: gemini-1.5-pro-002, gemini-1.5-flash-002, and gemini-2.0-flash-thinking-exp-01-21. temperature: 1. D.3. Llama For each of the Llama 3.1 models we utilize the API from the LLM provider SambaNova. For Llama 3.2 90B, we utilize the Together AI API. Models: Meta-Llama-3.1-8B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-405B-Instruct, meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo temperature: 0.6 (Meta default) top_p: 0.9 (Meta default) D.4. Deepseek We access the API for Deepseek R1 via the Together AI API and we use all default settings. Models: deepseek-ai/DeepSeek-R1 temperature: API Default D.5. Qwen We perform small-scale tests on QwQ-32B-Preview using the official Qwen Huggingface Spaces demo. To access Qwen-2.5-Coder-32B we utilized the API from SambaNova. Models: Qwen2.5-Coder-32B-Instruct, QwQ-32B-Preview temperature: 0.7 (For Qwen-2.5-Coder-32B) HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs E. HoT Visualization Detail Code import re char_2_color_map = { ' fact1 ': \" # FF5733 \" , ' fact2 ': \" #33 FF57 \" , ' fact3 ': \" #3357 FF \" , ' fact4 ': \" # FF33A1 \" , # Red # Green # Blue # Pink } def add_color_to_tags ( text ) : for tag , color in char_2_color_map . items () : text = re . sub ( ' <{ tag }> ' , rf ' sethlcolor {{{ tag }}} hl {{ ' , text ) text = re . sub (f ' </{ tag }> ' , '} ' , text ) return text paragraph = \"\"\" The < fact1 > apples are the second - cheapest </ fact1 >. The < fact2 > peaches are the cheapest </ fact2 >. \"\"\" print ( add_color_to_tags ( paragraph )) Figure F4: Python code that adds color to custom tags in text paragraph, using mapping of tags to colors. 24 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs F. Estimate verification accuracy of users The following tables are the estimated verification accuracies of humans if they were to verify each of the CoT and HoT results that we gather in our benchmarking. We calculate these results based off the recorded verification accuracies in the human study (Tab. 6) and the equation described in Sec. 5.4. Table T8: Estimated human verification accuracy for HoT on arithmetic tasks. Model Prompt CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean GSM8K 78.40 82.72 (+4.32) 78.50 83.15 (+4.65) 78.45 82.90 (+4.45) 78.52 83.26 (+4.74) 78.50 83.22 (+4.72) +4.58 MultiArith 78.73 84.30 (+5.57) 78.63 84.25 (+5.62) 78.74 84.30 (+5.56) 78.72 84.25 (+5.53) 78.73 84.30 (+5.57) +5.57 ASDiv 78.60 83.65 (+5.05) 78.63 83.91 (+5.28) 78.56 83.62 (+5.06) 78.61 83.72 (+5.11) 78.62 83.38 (+4.76) +5. SVAMP 78.32 82.96 (+4.64) 78.45 83.25 (+4.80) 78.34 83.04 (+4.70) 78.38 83.16 (+4.78) 78.44 83.07 (+4.63) +4.71 AQUA 77.57 83.33 (+5.76) 77.66 82.04 (+4.38) 78.20 80.64 (+2.44) 77.97 81.23 (+3.26) 77.42 79.36 (+1.94) +3.56 r-GSM 77.87 80.45 (+2.58) 77.36 81.80 (+4.44) 78.08 81.26 (+3.18) 78.20 82.07 (+3.87) 78.08 81.66 (+3.58) +3.53 GSM-Symbolic 77.59 79.65 (+2.06) 77.85 80.44 (+2.59) 77.63 79.25 (+1.62) 78.16 81.53 (+3.37) 77.96 81.33 (+3.37) +2.60 Task Mean () 78.15 82.44(+4.29) 78.15 82.69 (+4.54) 78.29 82.14(+3.85) 78.37 82.75 (+4.38) 78.25 82.33 (+4.08) +4.23 Table T9: Estimated human verification accuracy for HoT on reading comprehension tasks. Model Prompt CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean StrategyQA 77.25 78.48 (+1.23) 77.60 79.58 (+1.98) 76.77 79.86 (+3.09) 77.83 81.06 (+3.23) 77.74 80.15 (+2.41) +2.39 SpartQA 75.32 72.37 (-2.95) 76.28 74.06 (-2.22) 76.56 74.72 (-1.84) 76.81 76.27 (-0.54) 75.83 72.55 (-3.28) -2.17 Date Understanding Break 77.72 77.83 80.42 (+2.70) 80.28 (+2.45) 77.90 78.36 80.75 (+2.85) 83.26 (+4.90) 78.06 78.23 81.20 (+3.14) 82.10 (+3.87) 78.16 78.51 81.61 (+3.45) 83.75 (+5.24) 77.93 78.58 80.79 (+2.86) 83.67 (+5.09) +3.00 +4. Census 78.14 81.53 (+3.39) 78.26 82.27 (+4.01) 78.42 82.79 (+4.37) 78.37 82.87 (+4.50) 77.89 81.75 (+3.86) +4.03 Task Mean () 77.45 79.25 (+1.80) 77.76 80.44 (+2.68) 77.72 80.47 (+2.75) 78.01 81.39 (+3.38) 77.70 80.21 (+2.51) +2.63 Table T10: Estimated human verification accuracy for HoT on the subset of logical tasks in BBH. Model Prompt CoT HoT () CoT HoT () CoT HoT () CoT HoT () CoT HoT () Model Mean BBH: deduction five objects 77.40 79.15 (+1.75) 78.32 84.14 (+5.82) 78.32 82.72 (+4.40) 78.51 83.67 (+5.16) 78.38 82.36 (+3.98) +4.22 deduction seven objects 77.14 78.32 (+1.18) 77.88 81.17 (+3.29) 77.45 79.63 (+2.18) 78.11 81.53 (+3.42) 77.82 80.46 (+2.64) +2.54 reasoning colored objects 78.40 83.07 (+4.67) 78.56 83.67 (+5.11) 78.27 82.60 (+4.33) 78.59 83.67 (+5.08) 78.69 84.14 (+5.45) +4.93 causal judgement 76.93 76.08 (-0.85) 77.14 77.19 (+0.05) 76.68 75.92 (-0.76) 76.68 76.88 (+0.20) 77.07 81.32 (+4.25) +0.58 navigate Task Mean () 78.32 82.36 (+4.04) 78.27 83.43 (+5.16) 77.98 81.65 (+3.67) 78.48 83.67 (+5.19) 78.56 83.43 (+4.87) +4. 77.63 79.80 (+2.17) 77.99 81.92 (+3.93) 77.74 80.50 (+2.76) 78.07 81.88 (+3.81) 78.10 82.34 (+4.24) +3.14 25 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs G. HoT may hurt Llama-3.1-8B, Qwen-2.5-Coder-32B performance Since small models like Llama-3.1-8B (Dubey et al., 2024) are less capable of handling reasoning tasks than large models (Gemini-1.5-Pro, Llama-3.1-405B, GPT-4o), we aim to understand if HoT can benefit these smaller models. Additionally, since Qwen-2.5-Coder-32B is optimized for logical coding tasks, we hypothesize that it may benefit from the logical structure that HoT brings. We run the following experiment to understand if HoT is able to aid in these models reasoning ability. Experiment We evaluate Llama-3.1-8B and Qwen-2.5-Coder-32B on 13 datasets with CoT and HoT prompting. Results As shown in Tab. T13, HoT and CoT exhibit comparable performance on smaller models, like Llama-3.1-8B, and coding models, like Qwen-2.5-Coder-32B. For some datasets, such as AQUA on Llama-3.1-8B, slight negative trends are observed (e.g. -3.93 for Llama-3.1-70B), with HoT providing no significant advantage, likely due to the limited reasoning capabilities of these models. Qualitatively, we observe that these smaller models often fail to adhere to the tagging instructions. Specifically, Llama-3.1-8B frequently tags calculated results within reasoning chains (as illustrated in Tab. T11 (a)) and tends to repeat the few-shot examples in reasoning chains (Tab. T11 (b) and (c)). On the other hand, Qwen-2.5-Coder-32B often omits tagging in the answers altogether (Tab. T12). These inconsistencies likely contribute to the inconsistent performance observed with HoT (Tab. T13). 26 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T11: In (a), Llama-3.1-8B often tags calculated results within the reasoning chains, which violates our tagging strategy. According to our approach, calculated results are considered new information that cannot be linked back to the question and, therefore, should not be tagged. Additionally, in (b) and (c), Llama-3.1-8B exhibits tendency to replicate few-shot examples. Specifically, 5.9% of test examples in AQUA and 16.41% of test examples in StrategyQA contain repeated few-shot examples. (a) With HoT: Llama-3.1-8B tends to tag calculated results in GSM8K Examples Question: If Marcy works for the same company for 40 years, she gets an annual pension of $50,000/year. Starting after 20 years, she becomes entitled to 5% of the value of the pension per year. If she quits after 30 years, what will her annual pension be? Answer: Marcy gets an annual pension of $50,000/year for the first 20 years she works for the company. Starting after 20 years, she becomes entitled to 5% of the value of the pension per year. So, after 20 years, she gets $50,000/year + $50,000/year * 5% = $50,000/year + $50,000/year * 0.05 = $50,000/year + $2,500/year = $52,500/year for the next 10 years she works for the company. Since she quits after 30 years, she gets $52,500/year for the last 10 years she works for the company. Therefore, her annual pension for the last 10 years she works for the company will be $52,500/year. (GT: $25,000) (b) With HoT: Llama-3.1-8B tends to repeat the few-shot example in StrategyQA Question: Are all limbs required for jujutsu? Answer: Reformatted Question: At presentation about post traumatic stress disorder, would Ariana Grande be topic of relevance? Answer: {true} Reformatted Question: Has the Indian Ocean garbage patch not completed two full rotations of debris since its discovery? Answer: {true} [more repeated few-shot examples] Reformatted Question: Is 900,000 pound net worth person an American billionaire if they exchange currency June 2020? Answer: {true}. (GT: False) (c) With HoT: Llama-3.1-8B tends to repeat the few-shot example in AQUA Question: Jerry purchased 1-year $5,000 bond that paid an annual interest rate of 12% compounded every six months. How much interest had this bond accrued at maturity? Answer option: [A)$5102, B)$618, C)$216, D)$202, E)$200] Answer: Reformatted Question: person is traveling at 20 km/hr and reached his destination in 2.5 hr then find the distance? Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km Answer: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. So the answer is {e}. Reformatted Question: John found that the average of 15 numbers is 40. If 10 is added to each number, then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64 Answer: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be 40 + 10 = 50. So the answer is {a}. [more repeated few-shot examples] Reformatted Question: Two friends plan to walk along 43-km trail, starting at opposite ends of the trail at the same time. If Friend Ps rate is 15% faster than Friend Qs, how many kilometers will Friend have walked when they pass each other? Answer Choices: (a) 21 (b) 21.5 (c) 22 (d) 22.5 (e) 23 Answer: If completes kilometers, then then completes 1.15x kilometers. + 1.15x = 43 2.15x=43 = 43/2.15 = 20 Then will have walked 1.15*20=23 km. So the answer is {e}. (GT: B) 27 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T12: In this table, Qwen-2.5-Coder-32B fails to generate tags in both the question and the answer. We also observe the same problem in QwQ-32B-Preview (Qwen Team, 2024) (as shown in Tab. T6). With HoT: Qwen-2.5-Coder-32B could not generate tags in Causal Judgement Question: Sara has an electric guitar that she plays through an amplifier. The guitar will play through the amplifier if either the amplifier is set to channel or the power mixer is turned on. Today, the amplifier is set to channel A. Sara checks to see if the power mixer is on. She sees that the power mixer is turned on, and she does not turn off the power mixer or adjust it at all. Because the guitar will play through the amplifier if either the amplifier is set to channel or the power mixer is turned on, Saras guitar plays through the amplifier. Did the guitar play through the amplifier because Sara did not turn off the power mixer? Options: - Yes - No Answer: Lets break down the information provided in the question. The guitar will play through the amplifier if either the amplifier is set to channel or the power mixer is turned on. Today, the amplifier is set to channel A, which alone is sufficient for the guitar to play through the amplifier. Sara checks to see if the power mixer is on and finds that it is, but she does not turn it off. The question asks if the guitar played through the amplifier because Sara did not turn off the power mixer. Since the guitar would play through the amplifier regardless of the power mixers state (as long as the amplifier is set to channel A), Sara not turning off the power mixer is not the cause of the guitar playing through the amplifier. The answer is {no}. (GT: yes) Table T13: Performance comparison of CoT and HoT across Llama-3.1-8B ( on QA (StrategyQA and Date Understanding) and logical reasoning datasets. ) and Qwen-2.5-Coder-32B ( ), evaluated Model Prompt GSM8K MultiArith ASDiv SVAMP AQUA r-GSM StrategyQA Date Five Objects Seven Objects Color Objects Causal Judgement Navigate Mean CoT 95.83 98.83 97.19 93.70 87.40 90.91 85.83 95.54 95.60 89.60 96.80 67.91 95.20 HoT () 95.83 99.16 (+0.33) 97.38 (+0.19) 95.50 (+1.80) 88.98 (+1.58) 91.82 (+0.91) 88.43 (+3.10) 97.49 (+1.95) 97.20 (+1.60) 90.00 (+0.40) 97.20 (+0.40) 74.33 (+6.42) 97.20 (+2.00) +1.59 CoT 94.69 99.16 96.38 93.00 90.94 89.09 69.30 91.36 92.80 79.60 92.00 67.91 87.60 HoT () 94.62 (-0.07) 99.33 (+0.17) 97.04 (+0.66) 95.10 (+2.10) 87.01 (-3.93) 89.09 84.37 (+15.07) 91.92 (+0.56) 94.00 (+1.20) 83.60 (+4.00) 93.60 (+1.60) 71.12 (+3.21) 90.40 (+2.80) +2.10 CoT 85.06 96.81 93.09 85.90 71.65 70.37 66.50 78.27 66.80 52.00 78.80 58.29 74. HoT () 82.41 (-2.65) 98.49 (+1.68) 91.94 (-1.15) 85.40 (-0.50) 85.43 (+13.78) 65.60 (-4.77) 62.00 (-4.50) 68.25 (-10.02) 67.20 (+0.40) 58.80 (+6.80) 79.20 (+0.40) 58.82 (+0.53) 71.60 (-2.80) -0.22 CoT 94.24 98.83 97.04 94.00 86.61 86.36 69.21 83.84 86.00 83.20 97.60 71.12 89.20 HoT () 94.47 (+0.23) 98.99 (+0.16) 97.14 (+0.10) 93.30 (-0.70) 85.83 (-0.78) 86.82 (+0.46) 63.49 (-5.72) 84.68 (+0.84) 90.00 (+4.00) 85.60 (+2.40) 97.20 (+0.40) 70.59 (-0.53) 87.60 (-1.60) -0.11 28 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs H. Detail Analysis of the Impact of Tagging and Question Repetition on Chain-of-Thought"
        },
        {
            "title": "Performance",
            "content": "Tab. T14 presents the detailed analysis of Sec. 5.2, which shows the performance of prompt variations: (1) CoT, (2) CoT + Repeat Question, (3) Tag in Question, (4) Tag in Answer, (5) Tag in Question and Answer. Moreover, we also show the detailed number of tags across 6 datasets generated in Reformatted Question and Answer. Specifically, Tab. T15, and Tab. T16 display the number of tags when prompting LLMs to tag in Question only. Whereas Tab. T17 and Tab. T18 present the number of tags used when prompting LLMs to apply tags solely to answers. Finally, Tab. T19, and Tab. T20 illustrate the number of tags generated when LLMs tag both questions and answers. Detailed information regarding above-mentioned prompts is shown in Tabs. T21 and T22. Table T14: Performance comparison of various few-shot prompting strategies (CoT, Repeated Question, Tags in Question, Tags in Answer, and Tag in QA) across multiple models (Gemini-1.5-Flash, Gemini-1.5-Pro, Llama-3.1-70B, and Llama-3.1-405B) and datasets (tested each dataset on 400 random samples). The table shows prompt Tags in QA achieves the highest mean accuracy among multiple prompts."
        },
        {
            "title": "Prompt",
            "content": "AQUA StrategyQA r-GSM seven deduction objects causal judgement navigate Mean"
        },
        {
            "title": "CoT\nRepeated Question\nTags in Question\nTags in Answer\nTags in QA\nnormal CoT\nRepeated Question\nTags in Question\nTags in Answer\nTags in Both\nCoT\nRepeated Question\nTags in Question\nTags in Answer\nTags in Both\nCoT\nRepeated Question\nTags in Question\nTags in Answer\nTags in Both",
            "content": "72.50 97.00 97.00 95.00 96.00 83.00 70.00 71.00 72.00 89.50 90.50 84.00 79.00 82.50 86.00 86.00 84.00 81.00 79.00 88.00 75.25 80.75 79.75 81.50 79.50 81.00 83.50 82.00 83.50 82.25 76.00 78.00 82.25 82.00 87.00 83.25 86.25 86.25 85.50 87.50 84.50 81.50 82.50 83.50 86.00 77.00 89.00 89.50 88.50 90.50 88.50 90.00 84.50 86.50 88.00 90.50 90.00 92.00 90.00 91.50 72.50 74.50 74.50 70.50 78.50 83.00 87.50 86.00 87.00 88.00 78.50 83.00 83.00 85.00 81.50 88.50 87.50 87.50 89.50 89.00 71.66 89.84 72.19 68.98 71.66 74.87 72.19 72.19 71.66 75.40 67.91 68.98 74.33 70.59 71.12 67.91 70.05 71.12 72.73 74.33 92.50 73.50 92.00 92.50 91.00 91.00 93.50 95.50 97.00 96.00 85.00 87.50 86.00 90.00 88.50 94.50 94.50 96.00 94.00 96. 78.15 82.85 82.99 82.00 83.78 81.65 82.62 82.70 83.28 86.94 81.07 81.91 81.51 82.77 83.69 85.11 85.38 85.65 85.12 87.81 29 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T15: The average number of tags in Question using prompt Tag in Question. Table T16: The average number of tags in Answer using prompt Tag in Question. Numbers over 0.00 are the result of the model not properly following instructions."
        },
        {
            "title": "Dataset",
            "content": "AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 6.34 5.28 10.24 12.15 10.64 11.00 8.36 5.38 10.18 13.57 19.96 11.00 7.17 4.84 9.53 12.79 8.96 10.97 7.98 5.17 9.38 12.03 13.94 11."
        },
        {
            "title": "Mean",
            "content": "9.28 11.41 9.04 9."
        },
        {
            "title": "Dataset",
            "content": "AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 0.22 0.00 0.00 2.74 0.01 0.00 0.21 0.00 0.00 0.12 0.04 0.00 0.00 0.00 0.00 0.00 0.09 0.06 0.00 0.08 0.00 0.00 0.03 0."
        },
        {
            "title": "Mean",
            "content": "0.05 0.06 0.03 0.02 Table T17: The average number of tags in Question using prompt Tag in Answer. Table T18: The average number of tags in Answer using prompt Tag in Answer."
        },
        {
            "title": "Dataset",
            "content": "AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 0.12 0.0 0.0 0.0 0.0 0.0 5.35 0.02 6.29 2.23 5.7 0.0 0.08 0.02 1.97 0.0 0.0 0.03 4.88 0.27 5.48 0.06 2.9 0."
        },
        {
            "title": "Mean",
            "content": "0.02 3.27 0.35 2.27 AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 13.74 12.15 20.99 12.96 9.59 11. 17.55 11.04 16.74 11.12 11.72 11.2 23.74 12.77 17.75 12.54 9.43 10.63 15.57 9.31 14.17 14.32 7.74 11."
        },
        {
            "title": "Mean",
            "content": "13.54 13.23 14.48 12.02 Table T19: The average number of tags in Reformatted Question using prompt Tag in both Question and Answer. Table T20: The average number of tags in Answer using Tag in both Question and Answer."
        },
        {
            "title": "Dataset",
            "content": "AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 6.21 3.4 9.83 11.64 12.95 10.23 7.32 4.63 6.7 13.74 21.75 10.23 7.31 4.34 9.81 12.07 12.22 10.34 7.54 4.55 9.35 12.29 16.13 10.42 AQUA StrategyQA r-GSM 7 deduction objs causal judgement navigate 13.95 6.96 9.96 12.74 7.5 10.3 14.69 8.4 22.2 9.01 14.34 10.28 16.89 10.91 15.7 11.2 7.88 10.24 17.53 9.37 13.25 13.95 9.17 10."
        },
        {
            "title": "Mean",
            "content": "9.04 10.73 9.35 10."
        },
        {
            "title": "Mean",
            "content": "10.24 13.15 12.14 12.28 30 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T21: Specific prompts of Standard CoT, CoT+Repeating Question ((Mekala et al., 2024), CoT + Tags in Question, CoT + Tags in Answer, CoT + Tags in Question and Answer (HoT). Methods Standard CoT CoT + Repeating Question (Mekala et al., 2024) CoT + Tags in Question CoT + Tags in Answer CoT + Tags in Question & Answer (HoT) Prompt Content Question: {question} Instruction: \"Please generate your explanation first, then generate the final answer in the bracket as follows: Answer:\" Question: {question} Instruction: \"I want you to answer this question. To do that, first, repeat the question and then, generate your answers. The output format is as follows: Reformatted Question: Answer:\" Question: {question} Instruction: \"I want you to answer this question. To do that, first, re-generate the question with proper tags for key phrases, the key phrases that are most relevant to answering the question {last_sentence}, and then generate your answers. The output format is as follows: Reformatted Question: Answer:\" Question: {question} Instruction: \"I want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, repeat the question and then, generate your answers with proper tags for key phrases, the key phrases that are most relevant to answering the question {last_sentence}. The output format is as follows: Reformatted Question: Answer:\" Question: {question} Instruction: \"I want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags for key phrases, the key phrases that are most relevant to answering the question {last_sentence} and then generate your answers. The output format is as follows: Reformatted Question: Answer: \" 31 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T22: Specific fewshot prompts of CoT+Repeating Question ((Mekala et al., 2024), CoT + Tags in Question, CoT + Tags in Answer, CoT + Tags in Question and Answer (HoT). Methods Repeated Question (Mekala et al., 2024) Tags in Question Tags in Answer Tags in Question & Answer (HoT) Fewshot Prompt Examples Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block. How many houses are there in block? Repeated Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block, how many houses are there in block? Answer: If each house receives 2 pieces of junk mail and there are 14 pieces in total for each block, then there must be 14/2 = 7 houses per block. The answer is {7}. Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block. How many houses are there in block? Reformatted Question: mailman gives <fact1>2 junk mails to each house</fact1> in block. If the mailman has to give <fact2>14 pieces of junk mail</fact2> to each block, how many houses are there in block? Answer: If each house receives 2 pieces of junk mail and there are 14 pieces in total for each block, then there must be 14/2 = 7 houses per block. The answer is {7}. Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block. How many houses are there in block? Repeated Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block, how many houses are there in block? Answer: If each house receives <fact1>2 pieces of junk mail</fact1> and there are <fact2>14 pieces in total for each block</fact2>, then there must be <fact2>14</fact2>/<fact1>2</fact1> = 7 houses per block. The answer is {7}. Question: mailman gives 2 junk mails to each house in block. If the mailman has to give 14 pieces of junk mail to each block. How many houses are there in block? Reformatted Question: mailman gives <fact1>2 junk mails to each house</fact1> in block. If the mailman has to give <fact2>14 pieces of junk mail</fact2> to each block, how many houses are there in block? Answer: If each house receives <fact1>2 pieces of junk mail</fact1> and there are <fact2>14 pieces in total for each block</fact2>, then there must be <fact2>14</fact2>/<fact1>2</fact1> = 7 houses per block. The answer is {7}. 32 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs I. Highlighted Fewshot Chain of Thought Annotation To construct HoT few-shot examples for the evaluated benchmarks, questions from CoT few-shot examples are annotated using GPT-4o with the prompt shown in Tab. T23. Subsequently, answers from CoT few-shot examples are tagged using the prompt detailed in Tab. T24. Furthermore, we provide 13 examples of few-shot examples of GSM8K, r-GSM, GSM-Symbolic in Tab. T26, MultiArith in Tab. T27, ASDiv in Tab. T28, SVAMP in Tab. T29, AQUA in Tab. T30, StrategyQA in Tab. T31, Date Understanding in Tab. T32, SpartQA in Tab. T33, Deduction Objects in Tab. T34, Reasoning about Colored Objects in Tab. T35, Causal Judgement in Tab. T36, Navigate in Tab. T37, and DROP in Tab. T38. Table T23: Examples of questions before and after applying key phrase tags using <fact> tags. The tags highlight short, concise, and critical information in the questions that cannot be removed without altering the meaning of the questions. Prompt to tag in the Question Read the question and insert the tags into the question via the following rules: 1. Insert only tags keeping the original words unchanged. 2. Put the tags (e.g., <fact1></fact1>, <fact2></fact2>) around the shortest and most concise important phrases. 3. phrase is considered important and should be tagged if replacing that phrase by closest alternative phrase would change the answer. 4. Do not tag phrases non-important to answering the question. Re-generate the question after adding tags to the phrases. # EXAMPLES Below are examples of questions before and after key phrases are tagged using <fact> tags. If one key phrase was absent, it would be impossible for one to answer the question correctly. ## Question 1: ### BEFORE: Sam works at the Widget Factory, assembling Widgets. He can assemble 1 widget every 10 minutes. Jack from the loading dock can help assemble widgets when he doesnt have anything else to do. When he helps, they put together 2 complete widgets every 15 minutes. Recently the factory hired Tony to help assemble widgets. Being new to the job, he doesnt work as fast as Sam or Jack. Yesterday Sam worked for 6 hours before he had to leave work early for dentist appointment. Jack was able to help out for 4 hours before he had to go back to the loading dock to unload new shipment of widget materials. Tony worked the entire 8-hour shift. At the end of the day, they had completed 68 widgets. How long does it take Tony to assemble Widget, in minutes? ### AFTER: Sam works at the Widget Factory, assembling Widgets. He can assemble <fact1>1 widget every 10 minutes</fact1>. Jack from the loading dock can help assemble widgets when he doesnt have anything else to do. When he helps, they put together <fact2>2 complete widgets every 15 minutes</fact2>. Recently the factory hired Tony to help assemble widgets. Being new to the job, he doesnt work as fast as Sam or Jack. Yesterday Sam worked for <fact3>6 hours</fact3> before he had to leave work early for dentist appointment. Jack was able to help out for <fact4>4 hours</fact4> before he had to go back to the loading dock to unload new shipment of widget materials. Tony worked the entire <fact5>8-hour shift</fact5>. At the end of the day, they had completed <fact6>68 widgets</fact6>. How long does it take Tony to assemble Widget, in minutes? ## Question 2: ### BEFORE: For every 12 cans you recycle, you receive $0.50, and for every 5 kilograms of newspapers, you receive $1.50. If your family collected 144 cans and 20 kilograms of newspapers, how much money would you receive? ### AFTER: For <fact1>every 12 cans</fact1> you recycle, you receive <fact2>$0.50</fact2>, and for <fact3>every 5 kilograms of newspapers</fact3>, you receive <fact4>$1.50</fact4>. If your family collected <fact5>144 cans</fact5> and <fact6>20 kilograms of newspapers</fact6>, how much money would you receive? [more examplars] ## Question 15: ### BEFORE: {question to be tagged} ### AFTER: 33 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T24: Examples of tagged questions, answers (without tags), and answers (with tags). The tags in the answers correspond to the tags in the questions. Prompt to tag in the Answer Given pair of (Tagged Question, Answer) want to generate Tagged Answer. That is, to generate Tagged Answer, take the Answer and add tags to the key phrases that refer to the corresponding tagged phrases (e.g., <fact1>...</fact1>) from the Tagged Question. For example, the phrases tagged with the same tag (e.g. <fact1>) across Tagged Question and Tagged Answer should be synonymous or refer to the same entity. Please re-generate the answer with tags. Provide your tagged answer. ## Question 1: ### TAGGED QUESTION: Sam works at the Widget Factory, assembling Widgets. He can assemble <fact1>1 widget every 10 minutes</fact1>. Jack from the loading dock can help assemble widgets when he doesnt have anything else to do. When he helps, they put together <fact2>2 complete widgets every 15 minutes</fact2>. Recently the factory hired Tony to help assemble widgets. Being new to the job, he doesnt work as fast as Sam or Jack. Yesterday Sam worked for <fact3>6 hours</fact3> before he had to leave work early for dentist appointment. Jack was able to help out for <fact4>4 hours</fact4> before he had to go back to the loading dock to unload new shipment of widget materials. Tony worked the entire <fact5>8-hour shift</fact5>. At the end of the day, they had completed <fact6>68 widgets</fact6>. How long does it take Tony to assemble Widget, in minutes? ### ANSWER: Sam completes widget every 10 minutes. When Jack helps, they finish 2 in 15 minutes. Sam has finished 1 widget and has begun working on another one, and Jack finishes the second one at 15 minutes. So it takes Jack 15 minutes to complete widget. Sam worked for 6 hours yesterday, so he was able to complete 6 hours * 60 minutes per hour / 10 minutes per widget = 36 widgets. Jack worked for 4 hours, so he was able to complete 4 hours * 60 minutes per hour / 15 minutes per widget = 16 widgets. Sam, Jack, and Tony were able to complete 68 widgets together. So of those, Tony personally completed 68 widgets - 36 widgets - 16 widgets = 16 widgets. It took Tony 8 hours to complete those 16 widgets, so he takes 8 hours * 60 minutes per hour / 16 widgets = 8*60/16=30 minutes per widget. The answer is {30}. ### TAGGED ANSWER: Sam completes <fact1>a widget every 10 minutes</fact1>. When Jack helps, they finish <fact2>2 in 15 minutes</fact2>. Sam has finished 1 widget and has begun working on another one, and Jack finishes the second one at 15 minutes. So it takes Jack 15 minutes to complete widget. Sam worked for <fact3>6 hours</fact3> yesterday, so he was able to complete <fact3>6 hours</fact3> * 60 minutes per hour / <fact1>10 minutes per widget</fact1> = 36 widgets. Jack worked for <fact4>4 hours</fact4>, so he was able to complete <fact4>4 hours</fact4> * 60 minutes per hour / <fact2>15 minutes per widget</fact2> = 16 widgets. Sam, Jack, and Tony were able to complete <fact6>68 widgets</fact6> together. So of those, Tony personally completed <fact6>68 widgets</fact6> - 36 widgets - 16 widgets = 16 widgets. It took Tony <fact5>8 hours</fact5> to complete those 16 widgets, so he takes <fact5>8 hours</fact5> * 60 minutes per hour / 16 widgets = <fact5>8</fact5>*60/16=30 minutes per widget. The answer is {30}. [more examplars] ## Question 15: 34 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T25: On the left, the tags in the answers correspond to the tags in the question, ensuring alignment. On the right, the tags in the question and answer do not match, leading to inconsistencies, e.g. entire shift while humming tune in the question does not match with 6 hours yesterday in the answer. Few-shot Example with Correct Tagging Reformatted Question: Sam works at the Widget Factory, assembling widgets. He can assemble 1 widget every 10 minutes. Jack from the loading dock can help assemble widgets when he doesnt have anything else to do. When he helps, they put together 2 complete widgets every 15 minutes. Recently the factory hired Tony to help assemble widgets. Being new to the job, he doesnt work as fast as Sam or Jack. Yesterday Sam worked for 6 hours before he had to leave work early for dentist appointment. Jack was able to help out for 4 hours before he had to go back to the loading dock to unload new shipment of widget materials. Tony worked the entire 8-hour shift. At the end of the day, they had completed 68 widgets. How long does it take Tony to assemble widget, in minutes? Answer: Sam completes widget every 10 minutes. When Jack helps, they finish 2 in 15 minutes. Sam has finished 1 widget and has begun working on another one, and Jack finishes the second one at 15 minutes. So it takes Jack 15 minutes to complete widget. Sam worked for 6 hours yesterday, so he was able to complete 6 hours * 60 minutes per hour / 10 minutes per widget = 36 widgets. Jack worked for 4 hours, so he was able to complete 4 hours * 60 minutes per hour / 15 minutes per widget = 16 widgets. Sam, Jack, and Tony were able to complete 68 widgets together. So of those, Tony personally completed 68 widgets - 36 widgets - 16 widgets = 16 widgets. It took Tony 8 hours to complete those 16 widgets, so he takes 8 hours * 60 minutes per hour / 16 widgets = 8*60/16=30 minutes per widget. The answer is {30}. Few-shot Example with Incorrect Tagging Reformatted Question: Sam works at the Widget Factory, assembling widgets. He can assemble widgets every 10 minutes. Jack from the loading dock can help assemble widgets when he doesnt have anything else to do. When he helps, they put together 2 complete widgets every 15 minutes. Recently the factory hired Tony to help assemble widgets. Being new to the job, he doesnt work as fast as Sam or Jack. Yesterday, blue car drove past the factory. Jack was able to hear dog barking in the distance. Tony worked the entire shift while humming tune. At the end of the day, sandwich wrapper was found on the assembly line. They completed total of 68 widgets. How long does it take Tony to assemble widget, in minutes? Answer: Sam completes widget every 10 minutes. When Jack helps, they finish 2 in 15 minutes. Sam has finished 1 widget and has begun working on another one, and Jack finishes the second one at 15 minutes. So it takes Jack 15 minutes to complete widget. Sam worked for 6 hours yesterday, so he was able to complete 6 hours * 60 minutes per hour / 10 minutes per widget = 36 widgets. Jack worked for 4 hours, so he was able to complete 4 hours * 60 minutes per hour / 15 minutes per widget = 16 widgets. Sam, Jack, and Tony were able to complete 68 widgets together. So of those, Tony personally completed 68 widgets - 36 widgets - 16 widgets = 16 widgets. It took Tony 8 hours to complete those 16 widgets, so he takes 8 hours * 60 minutes per hour / 16 widgets = 8*60/16=30 minutes per widget. The answer is {30}. Table T26: GSM8K fewshot HoT examples. GSM8K HoT Fewshot Examples Question: For every 12 cans you recycle, you receive $0.50, and for every 5 kilograms of newspapers, you receive $1.50. If your family collected 144 cans and 20 kilograms of newspapers, how much money would you receive? Reformatted Question: For every 12 cans you recycle, you receive $0.50, and for every 5 kilograms of newspapers, you receive $1.50. If your family collected 144 cans and 20 kilograms of newspapers, how much money would you receive? Answer: There are 144/12 = 12 sets of 12 cans that the family collected. So, the family would receive $0.50 12 = $6 for the cans. There are 20/5 = 4 sets of 5 kilograms of newspapers that the family collected. So, the family would receive $1.50 4 = $6 for the newspapers. Therefore, the family would receive total of $6 + $6 = $12. The answer is {12}. 35 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T27: MultiArith fewshot HoT examples. MultiArith HoT Fewshot Examples Question: new building needed 11 windows. The builder had already installed 4 of them. If it takes 8 hours to install each window, how long will it take him to install the rest? Reformatted Question: new building needed 11 windows. The builder had already installed 4 of them. If it takes 8 hours to install each window, how long will it take him to install the rest? Answer: The building needs 11 windows, and the builder has already installed 4, leaving 7 more to go. Since each window takes 8 hours to install, hell need 78=56 hours to finish. The answer is {56}. Table T28: ASDiv fewshot HoT examples. ASDiv HoT Fewshot Examples Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today? Reformatted Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today? Answer: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So, they must have planted 21 - 15 = 6 trees. The answer is {6}. Table T29: SVAMP fewshot HoT examples. SVAMP HoT Fewshot Examples Question: Edward spent $ 6 to buy 2 books each book costing him the same amount of money. Now he has $ 12. How much did each book cost? Reformatted Question: Edward spent $6 to buy 2 books each book costing him the same amount of money. Now he has $12. How much did each book cost? Answer: Edward spent $6 on 2 books, meaning each book cost 6/2=3 dollars. The answer is {3}. Table T30: AQUA fewshot HoT examples. AQUA HoT Fewshot Examples Question: person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance? Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km Reformatted Question: person is traveling at 20 km/hr and reached his destination in 2.5 hr then find the distance? Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km Answer: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. So the answer is {e}. Table T31: StrategyQA fewshot HoT examples. StrategyQA HoT Fewshot Examples Question: At presentation about post traumatic stress disorder, would Ariana Grande be topic of relevance? Reformatted Question: At presentation about post traumatic stress disorder, would Ariana Grande be topic of relevance? Answer: Ariana Grande was performing in Manchester in 2017 when explosives were set off in an act of terrorism. Ariana Grande has spoken openly about her trauma experience and her PTSD regarding the Manchester Bombing. So the answer is {true}. Table T32: Date Understanding fewshot HoT examples. Date Understanding HoT Fewshot Examples Question: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY? Reformatted Question: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY? Answer: If 2015 is coming in 36 hours, then it is coming in 2 days. 2 days before 01/01/2015 is 12/30/2014, so today is 12/30/2014. So one week from today will be 01/06/2015. The answer is {01/05/2015}. 36 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T33: SpartQA fewshot HoT examples. SpartQA HoT Fewshot Examples Question: We have three blocks, A, and C. Block has medium blue square. Below block is block which has one medium black square. To the left of block there is block which has two medium blue squares. Medium blue square number one is below medium blue square number two. medium yellow square is below medium blue square number two and medium blue square number one. What is to the left of the black thing? medium blue square that is in block or medium blue square number two? (a) medium blue square that is in block (b) medium blue square number two (c) both of them (d) none of them Reformatted Question: We have three blocks, A, and C. Block has medium blue square. Below block is block which has one medium black square. To the left of block there is block which has two medium blue squares. Medium blue square number one is below medium blue square number two. medium yellow square is below medium blue square number two and medium blue square number one. What is to the left of the black thing? medium blue square that is in block or medium blue square number two? (a) medium blue square that is in block (b) medium blue square number two (c) both of them (d) none of them Answer: Block has medium blue square, and Block (below A) has black square. Block C, to the left of Block B, has two medium blue squares, with blue square number two on top and number one below it. Since the blue squares in Block are directly to the left of the black square in Block B. The answer is {B}. Table T34: Deduction Objects fewshot HoT examples. Deduction Objects HoT Fewshot Examples Question: The following paragraphs each describe set of seven objects arranged in fixed order. The statements are logically consistent within each paragraph. In golf tournament, there were seven golfers: Ana, Eve, Ada, Dan, Rob, Amy, and Joe. Dan finished third. Ana finished above Ada. Amy finished last. Dan finished below Rob. Eve finished below Ada. Rob finished below Joe. Options: (A) Ana finished third (B) Eve finished third (C) Ada finished third (D) Dan finished third (E) Rob finished third (F) Amy finished third (G) Joe finished third Reformatted Question: The following paragraphs each describe set of seven objects arranged in fixed order. The statements are logically consistent within each paragraph. In golf tournament, there were seven golfers: Ana, Eve, Ada, Dan, Rob, Amy, and Joe. Dan finished third. Ana finished above Ada. Amy finished last. Dan finished below Rob. Eve finished below Ada. Rob finished below Joe. Options: (A) Ana finished third (B) Eve finished third (C) Ada finished third (D) Dan finished third (E) Rob finished third (F) Amy finished third (G) Joe finished third Answer: In the golf tournament, Dan finished third is explicitly stated, so the answer is {D}. Table T35: Colored Objects fewshot HoT examples. Colored Objects HoT Fewshot Examples Question: On the desk, you see set of things arranged in row: grey cup, purple mug, and blue teddy bear. What is the color of the thing directly to the right of the cup? Options: (A) red (B) orange (C) yellow (D) green (E) blue (F) brown (G) magenta (H) fuchsia (I) mauve (J) teal (K) turquoise (L) burgundy (M) silver (N) gold (O) black (P) grey (Q) purple (R) pink Reformatted Question: On the desk, you see set of things arranged in row: grey cup, purple mug, and blue teddy bear. What is the color of the thing directly to the right of the cup? Options: (A) red (B) orange (C) yellow (D) green (E) blue (F) brown (G) magenta (H) fuchsia (I) mauve (J) teal (K) turquoise (L) burgundy (M) silver (N) gold (O) black (P) grey (Q) purple (R) pink Answer: Items on the desk in row: We are told that there are three things arranged in row: grey cup, purple mug, and blue teddy bear. Position of the grey cup: The grey cup is the first item in the row. Position of the purple mug: The purple mug is to the right of the grey cup. The thing directly to the right of the grey cup is the purple mug, and its color is purple. The answer is {Q}. 37 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T36: Causal Judgement fewshot HoT examples. Causal Judgement HoT Fewshot Examples Question: How would typical person answer each of the following questions about causation? machine is set up in such way that it will short circuit if both the black wire and the red wire touch the battery at the same time. The machine will not short circuit if just one of these wires touches the battery. The black wire is designated as the one that is supposed to touch the battery, while the red wire is supposed to remain in some other part of the machine. One day, the black wire and the red wire both end up touching the battery at the same time. There is short circuit. Did the black wire cause the short circuit? Options: - Yes - No Reformatted Question: How would typical person answer each of the following questions about causation? machine is set up in such way that it will short circuit if both the black wire and the red wire touch the battery at the same time. The machine will not short circuit if just one of these wires touches the battery. The black wire is designated as the one that is supposed to touch the battery, while the red wire is supposed to remain in some other part of the machine. One day, the black wire and the red wire both end up touching the battery at the same time. There is short circuit. Did the black wire cause the short circuit? Options: - Yes - No Answer: Condition for short circuit: The machine is designed to short circuit if both the black wire and the red wire touch the battery. If only one wire touches the battery, there will be no short circuit. Designated roles: The black wire is the one that is supposed to touch the battery. The red wire is supposed to stay away from the battery. What happened: Both the black wire and the red wire ended up touching the battery, which caused the short circuit. Causation: Even though the black wire touched the battery (as expected), the short circuit was caused because both wires touched the battery. Thus, the black wire alone didnt cause the short circuitit was the combination of both wires touching the battery. Conclusion: typical person would say the black wire did not cause the short circuit alone; both wires contributed to the short circuit. The answer is {no}. Table T37: Navigate fewshot HoT examples. Navigate HoT Fewshot Examples Question: If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step right. Take 3 steps left. Take 2 steps right. Options: - Yes - No Reformatted Question: If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step right. Take 3 steps left. Take 2 steps right. Options: - Yes - No Answer: Starting from the original point, you first take 1 step right. Then, you take 3 steps left, which moves you 2 steps left from the starting point. Finally, taking 2 steps right brings you to the starting point. Therefore, you return to the starting point. The answer is {yes}. Table T38: DROP fewshot HoT examples. DROP HoT Fewshot Examples Question: In the county, the population was spread out with 23.50% under the age of 18, 8.70% from 18 to 24, 29.70% from 25 to 44, 24.70% from 45 to 64, and 13.30% who were 65 years of age or older. How many more percent are under the age of 18 compared to the 18 to 24 group? Reformatted Question: In the county, the population was spread out with 23.50% under the age of 18, 8.70% from 18 to 24, 29.70% from 25 to 44, 24.70% from 45 to 64, and 13.30% who were 65 years of age or older. How many more percent are under the age of 18 compared to the 18 to 24 group? Answer: According to the passage, 23.5% are under the age of 18, and 8.7% are from ages 18 to 24. 23.5% - 8.7% = 14.8%. So the answer is {14.8}. 38 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs J. Some Highlight Failure Cases Furthermore, some failure cases and success cases of HoT are presented in Tab. T39Tab. T50. Table T39: Llama-3.1-8B Fail Cases. SVAMP HoT Fail Cases Question: Danny collects bottle caps and wrappers. He found 65 wrappers and 5 bottle caps at the park. Now he has 31 bottle caps and 9 wrappers in his collection. How many more wrappers than bottle caps did Danny find at the park? Answer: Danny found 65 wrappers and 5 bottle caps at the park. Now he has 31 bottle caps and 9 wrappers in his collection. To find out how many more wrappers than bottle caps he found, we need to find out how many wrappers and bottle caps he has in total and then subtract the number of bottle caps from the number of wrappers. He has 65+5=70 wrappers and 31+9=40 bottle caps in total. Therefore, he found 70 - 40=30 more wrappers than bottle caps at the park. Answer: {30}. (GT: 60) StrategyQA HoT Fail Cases Question: Will an elephant pregnancy in 2020 last past next year with four solar eclipses in 2020? Answer: The duration of an elephant pregnancy is approximately 22 months, which is roughly 1.8 years. Since next year is 2021, and the elephant pregnancy in 2020 will likely last past next year due to its duration. The number of solar eclipses in year is determined by celestial events and is not directly related to the duration of an elephant pregnancy. So the answer is {true}. (GT: False) Date Understanding HoT Fail Cases Question: Yesterday was April 30, 2021. What is the date month ago in MM/DD/YYYY? Answer: Yesterday was April 30, 2021. month ago from April 30, 2021 would be the last day of March, which is March 31, 2021. (GT: 04/01/2021) r-GSM HoT Fail Cases Question: Carmen goes to an auction to win an antique desk. The bids on the desk rise by $50 each time and 3 other people each bid once. She accepts the opening bid of $200 and continues bidding until she wins. Carmen bids after each of the 3 other people and eventually wins. How much money, in dollars, does the desk cost her? Answer: Since the bids on the desk rise by $50 each time, and there are 3 other people who each bid once, the desk will be bid up by $50 * 3 = $150 after the first 3 bids. This means the desk will be bid up to $200 + $150 = $350. Since Carmen bids after each of the other 3 people, she will have to bid $350 to win the desk. The answer is {350}. (GT: 500) navigate HoT Fail Cases Question: If you follow these instructions, do you return to the starting point? Always face forward. Take 6 steps forward. Take 7 steps backward. Take 7 steps backward. Take 8 steps forward. Options: - Yes - No. Answer: You first take 6 steps forward, moving you 6 steps ahead of the starting point. Then, you take 7 steps backward, moving you 1 step backward from the starting point. After this, taking 7 more steps backward brings you 1 step further from the starting point. Finally, taking 8 steps forward moves you 7 steps away from the starting point. Hence, you do not return to the starting point. The answer is {no}. (GT: Yes) Table T40: Llama-3.1-70B Fail Cases. DROP HoT Fail Cases (LLM fails to repeat 231 women and children, instead it generates 201 women and children) Question: In 1905, 1,003 Korean immigrants, which included 802 men and 231 women and children, departed from the port of Chemulpo, Incheon aboard the ship Ilford to Salina Cruz, Oaxaca, Mexico. The journey took 45 days, after which they took train to Coatzacoalcos, Veracruz. In the Veracruz port, another boat was taken to the port of Progreso with the final destination being...How many Korean immigrants were more men than woman and children? Reformatted Question: In 1905, 1,003 Korean immigrants, which included 802 men and 201 women and children, departed from the port of Chemulpo, Incheon aboard the ship Ilford to Salina Cruz, Oaxaca, Mexico. The journey took 45 days, after which they took train to Coatzacoalcos, Veracruz. In the Veracruz port, another boat was taken to the port of Progreso with the final destination being...How many Korean immigrants were more men than woman and children? Answer: According to the passage, 802 men and 201 women and children were among the 1,003 Korean immigrants. To find the difference between the number of men and women and children, subtract the number of women and children from the number of men: 802 - 201 = 601. So the answer is 601. . (GT: 571) 39 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T41: Qwen-2.5-Coder-32B Fail Cases. SVAMP HoT Fail Cases Question: Jack received 6 emails in the morning, 3 emails in the afternoon, and some more in the evening. If he received total of 10 emails in the day, how many emails did Jack receive in the afternoon? Answer: Jack received total of 10 emails in the day. Out of these, he received 6 emails in the morning and 3 emails in the afternoon. The question asks for the number of emails received in the afternoon, which is already provided as 3 emails. Therefore, the answer is {3}. (GT: 1) StrategyQA HoT Fail Cases Question: Did Ada Lovelace die tragically young for her era? Answer: Ada Lovelace died in 1852 at the age of 36 from uterine cancer. For her era, which was the early to mid-19th century, this was indeed considered tragically young. Life expectancy in the 1800s was significantly lower than it is today, with many people dying in their 30s and 40s due to various diseases and lack of modern medical treatments. Therefore, the answer is {true}. (GT: False) Date Understanding HoT Fail Cases Question: Jane got her job in 2016. Today is her 3-year work anniversary. She still remembers that on Dec 2, her second day at work, she spilled coffee on her laptop. What is the date 10 days ago in MM/DD/YYYY? Answer: Jane got her job in 2016, and today is her 3-year work anniversary, which means today is 12/02/2019. Ten days ago from today would be 11/22/2019. The answer is {11/22/2019}. (GT: 11/22/2019) r-GSM HoT Fail Cases Question: On busy Saturday morning, hotel was completely booked with 100 guests. 24 guests elected an early checkout and 15 elected for late checkout. 7 more people checked in after dinner was served. In the afternoon twice as many people checked in as those who opted for late checkout. How many guests does the hotel have after dinner? Answer: Initially, the hotel had 100 guests. After 24 guests elected an early checkout, the number of guests decreased to 100 - 24 = 76 guests. Then, 15 guests elected for late checkout, but this does not affect the count of guests present at the hotel at the time of dinner. In the afternoon, twice as many people checked in as those who opted for late checkout, which means 2 * 15 = 30 guests checked in. Additionally, 7 more people checked in after dinner was served. Therefore, the total number of guests after dinner is 76 (remaining guests) + 30 (checked in in the afternoon) + 7 (checked in after dinner) = 113 guests. The answer is {113}. (GT: 98) navigate HoT Fail Cases Question: If you follow these instructions, do you return to the starting point? Take 3 steps. Turn around. Take 3 steps. Turn right. Options: - Yes - No Answer: You first take 3 steps forward. Then, you turn around and take 3 steps back, which brings you back to the starting point. However, the final instruction to turn right does not change your position, only your direction. Therefore, you are at the starting point but facing different direction. The answer is {no}. (GT: Yes) 40 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T42: Gemini-1.5-Flash Correct Cases. AQUA HoT Correct Cases Question: John found that the average of 15 numbers is 40. If 10 is added to each number, then the mean of the numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64 Answer: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be 40 + 10 = 50. So the answer is {a}. (GT: A) MultiArith HoT Correct Cases Question: For Halloween, Debby had 32 pieces of candy and her sister had 42 pieces. They ate 35 pieces the first night. How many pieces do they have left? Answer: Debby had 32 pieces of candy, and her sister had 42 pieces. Together, they had 32 + 42 = 74 pieces of candy. After eating 35 pieces the first night, they have 74 - 35 = 39 pieces left. The answer is {39}. (GT: 39) Colored Objects HoT Correct Cases Question: On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If remove all the notebooks from the floor, how many grey objects remain on it? Options: (A) zero (B) one (C) two (D) three (E) four (F) five (G) six (H) seven (I) eight (J) nine (K) ten (L) eleven (M) twelve (N) thirteen (O) fourteen (P) fifteen (Q) sixteen Answer: The question states there are three grey cat toys and three grey notebooks on the floor. We are asked to remove all the notebooks. This means removing the three grey notebooks. Therefore, the number of grey objects remaining is the number of grey cat toys, which is three. The answer is {D}. (GT: D) SpartQA HoT Correct Cases Question: There are two blocks, and B. Block is to the left of B. Block has medium black triangle, one medium blue circle and one big yellow circle. One small blue circle is also in this block. The medium black triangle is touching the right edge of this block. Below, near to and to the right of the small blue circle there is the medium blue circle. Below and to the left of the small blue circle there is the big yellow circle. Below the blue object which is below the small blue circle is the medium black triangle. Block has one medium black triangle and small black square. The small black square is touching the bottom edge of this block. The medium black triangle is to the left of the small black square. What is to the left of the small black object? big yellow circle or medium black triangle that is touching the right edge of block? (a) big yellow circle (b) medium black triangle that is touching the right edge of block (c) both of them (d) none of them Answer: Block is to the left of Block B. Block contains small black square, and its medium black triangle is to the left of the small black square. Block contains big yellow circle, medium blue circle, small blue circle, and medium black triangle. The description states that the big yellow circle is below and to the left of the small blue circle, and the medium black triangle is below and to the right of the small blue circle. Therefore, both the big yellow circle and the medium black triangle (which is touching the right edge of Block A) are to the left of the small black square in Block B. The answer is (c) both of them. (GT: C) 41 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T43: Gemini-1.5-Pro Correct Cases. AQUA HoT Correct Cases Question: trader sold an article at profit of 20% for Rs.360. What is the cost price of the article? Answer Choices: (a) 270 (b) 300 (c) 280 (d) 320 (e) 315 Answer: Let the cost price (CP) of the article be x. The trader sold the article at profit of 20%. This means the selling price (SP) is 100% + 20% = 120% of the cost price. We can write this as: SP = 1.2 * CP We are given that SP = Rs.360. Substituting this value into the equation: 360 = 1.2 * x. Now, we can solve for (the cost price): = 360 / 1.2 = 300 Therefore, the cost price of the article is Rs. 300. The answer is {B)300}. (GT: B) MultiArith HoT Correct Cases Question: Luke was trying to expand his game collection. He bought 2 games from friend and bought 2 more at garage sale. If 2 of the games didnt work, how many good games did he end up with? Answer: Luke bought 2 games from his friend and 2 more at garage sale, giving him 2+2 = 4 games. Since 2 of the games didnt work, he had 4 - 2 = 2 good games. The answer is {2}. (GT: 2) reasoning_about_colored_objects HoT Correct Cases Question: On the desk, you see set of things arranged in row: grey cup, purple mug, and blue teddy bear. What is the color of the thing directly to the right of the cup? Options: (A) red (B) orange (C) yellow (D) green (E) blue (F) brown (G) magenta (H) fuchsia (I) mauve (J) teal (K) turquoise (L) burgundy (M) silver (N) gold (O) black (P) grey (Q) purple (R) pink Answer: The items are arranged in row: grey cup, purple mug, blue teddy bear. The question asks for the color of the item directly to the right of the grey cup. The item to the right of the cup is the purple mug. Therefore, the color of the item to the right of the cup is purple. The answer is {Q}. (GT: Q) SpartQA HoT Correct Cases Question: There are three blocks, A, B, and C. Block is to the right of blocks and B. Block contains two medium black squares. Medium black square number one is below medium black square number two. There is also one medium yellow square touching the bottom edge of this block. Below medium black square number two and medium black square number one is the medium yellow square. Block has one medium yellow square and medium blue square. The medium yellow square is below the medium blue square. And block contains one medium blue square and medium yellow square. The medium blue square is touching the bottom edge of this block. It is below the medium yellow square. Which object is to the left of medium black square? the medium yellow square which is in block or the medium yellow square that is touching the bottom edge of block? (a) the medium yellow square which is in block (b) the medium yellow square that is touching the bottom edge of block (c) both of them (d) none of them Answer: Block is to the right of both Block and Block C. Block contains the medium black squares. Block contains medium yellow square, and Block also has medium yellow square touching its bottom edge. Since the question asks what is to the left of the medium black squares (in Block A), and both Block and are to the left of Block A, the correct answer is the medium yellow square in Block C. The medium yellow square in Block is below the black squares, not to their left. Therefore, the answer is A. (GT: A) 42 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T44: Llama-3.1-70B Correct Cases. AQUA HoT Correct Cases Question: trader sold an article at profit of 20% for Rs.360. What is the cost price of the article? Answer Choices: (A) 270 (B) 300 (C) 280 (D) 320 (E) 315 Answer: Lets assume the cost price of the article is x. Since the trader sold the article at profit of 20%, the selling price is 120% of the cost price. So, the selling price is 1.20x. We know that the selling price is Rs.360. Therefore, 1.20x = 360. Solving for x, we get = 360 / 1.20 = 300. So the answer is {B}. (GT: B) MultiArith HoT Correct Cases Question: pet store had 13 siamese cats and 5 house cats. During sale they sold 10 cats. How many cats do they have left? Answer: The pet store initially had 13 siamese cats and 5 house cats, totaling 13+5=18 cats. After selling 10 cats, they have 18 - 10=8 cats left. The answer is {8}. (GT: 8) Colored Objects HoT Correct Cases Question: On the table, you see set of items arranged in row: mauve keychain, green dog leash, an orange cat toy, silver pen, and black crayon. What is the color of the item furthest from the pen? Options: (A) red (B) orange (C) yellow (D) green (E) blue (F) brown (G) magenta (H) fuchsia (I) mauve (J) teal (K) turquoise (L) burgundy (M) silver (N) gold (O) black (P) grey (Q) purple (R) pink Answer: Lets think step by step. According to this question, the objects are arranged in row, from left to right, as follows: (1) mauve keychain, (2) green dog leash, (3) an orange cat toy, (4) silver pen, (5) black crayon. The pen is the fourth item on the list, namely (4). Since the items are arranged in row, the item furthest from the pen would be the item at the opposite end of the row, which is the first item, namely (1), the mauve keychain. The answer is {I}. (GT: I) SpartQA HoT Correct Cases Question: Question: There are three blocks. We call them A, and C. There are one big blue triangle and medium yellow square in block A. Near to medium blue triangle there is big black circle. Near to and below the black shape which is near to the medium blue triangle there is the big blue triangle. The medium yellow square is touching the bottom edge of this block. It is near to and below the medium blue triangle. Block is below block A. It has big black square. To the left of block there is block which has big blue triangle and one medium yellow circle. To the right of big black square is the medium yellow circle. The big blue triangle is touching the right edge of this block. This shape is below and to the right of the big black square. Which object is to the right of big black square? the blue thing that is touching the right edge of block or the medium yellow circle? (a) the blue thing that is touching the right edge of block (b) the medium yellow circle (c) both of them (d) none of them Answer: Block contains the big black square, and to its right is the medium yellow circle in block C. Additionally, the big blue triangle in block is also to the right of the big black square and is touching the right edge of block C. Since both the big blue triangle and the medium yellow circle are to the right of the big black square, the correct answer is {C}. (GT: C) 43 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T45: Llama-3.1-405B Correct Cases. AQUA HoT Correct Cases Question: At certain factory, 10 percent of the staplers produced on Monday were defective and 2 percent of the non-defective staplers were rejected by mistake. If 72 of the non-defective staplers were rejected, what was the number of staplers produced that day? Answer: Lets assume the total number of staplers produced on Monday is x. Since 10 percent of the staplers produced on Monday were defective, the number of non-defective staplers is 0.9x. Since 2 percent of the non-defective staplers were rejected by mistake, the number of non-defective staplers rejected is 0.02 * 0.9x = 0.018x. We are given that 72 of the non-defective staplers were rejected, so 0.018x = 72. Solving for x, we get = 72 / 0.018 = 4000. So the answer is {A) 4,000}. (GT: A) MultiArith HoT Correct Cases Question: Lana picked 36 tulips and 37 roses to make flower bouquets. If she only used 70 of the flowers though, how many extra flowers did Lana pick? Answer: Lana picked total of 36 tulips + 37 roses = 73 flowers. Since she only used 70 of the flowers, she has 73 - 70 = 3 extra flowers. The answer is {3}. (GT: 3) Colored Objects HoT Correct Cases Question: On the floor, you see green bracelet, purple cat toy, brown pair of sunglasses, black fidget spinner, red dog leash, and an orange pen. How many objects are neither black nor blue? Options: (A) zero (B) one (C) two (D) three (E) four (F) five (G) six Answer: Lets think step by step. According to this question, the objects are arranged as follows: (1) green bracelet, (2) purple cat toy, (3) brown pair of sunglasses, (4) black fidget spinner, (5) red dog leash, and (6) an orange pen. We are asked to find the number of objects that are neither black nor blue. There is only one black object and no blue objects. The number of objects that are neither black nor blue is the total number of objects minus the number of black objects and the number of blue objects. Since there are 6 objects in total, and 1 of them is black and none of them are blue, the number of objects that are neither black nor blue is 6 - 1 = 5. The answer is {F}. (GT: F) SpartQA HoT Correct Cases Question: There are three blocks, A, and C. One big black circle is in block A. Below block there is block with big blue triangle, big black triangle and one big blue square in it. Above and to the right of medium black triangle there is the big blue triangle. The big black triangle is above the medium black triangle. It is to the left of and below the big blue square. Above block there is block with one small yellow square and small black square in it. big blue square is below the small yellow square. It is touching the bottom edge of this block. big blue triangle is touching the bottom edge of this block. To the right of and near to the small black square is the big blue square. The small black square is touching the bottom edge of this block. To the right of and below the small yellow square is the big blue triangle. What is below the circle? big blue square that is touching the bottom edge of block or medium black triangle? (a) big blue square that is touching the bottom edge of block (b) medium black triangle (c) both of them (d) none of them Answer: Since Block is below Block A, which contains the big black circle, all objects in Block are below the circle. Block contains medium black triangle, but it does not contain big blue square that is touching the bottom edge of block (this object is in Block C). Therefore, the correct answer is {B}. (GT: B) 44 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T46: GPT-4o Correct Cases. AQUA HoT Correct Cases Question: The original price of an item is discounted 22%. customer buys the item at this discounted price using $20-off coupon. There is no tax on the item, and this was the only item the customer bought. If the customer paid $1.90 more than half the original price of the item, what was the original price of the item? Answer option: (A) $61, (B) $65, (C) $67.40, (D) $70, (E) $78.20 Answer: Let the original price of the item be x. After 22% discount, the price becomes ( 0.78x ). Using the $20-off coupon, the price becomes ( 0.78x - 20 ). The customer paid $1.90 more than half the original price of the item, which translates to the equation: [ 0.78x - 20 = x/2 + 1.90 ] Solving this equation:[ 0.78x - x/2 = 1.90 + 20 ]-> [ 0.28x = 21.90 ] -> [ = 21.90/0.28 ] -> [ = 78.2142857 ]. Rounding to the nearest option, the original price of the item is approximately $78.20. So the answer is {E). (GT: E) MultiArith HoT Correct Cases Question: For Halloween, Debby and her sister combined the candy they received. Debby had 32 pieces of candy while her sister had 42. If they ate 35 pieces the first night, how many pieces do they have left? Answer: Debby had 32 pieces of candy, and her sister had 42, so together they had 32+42=74 pieces of candy. After eating 35 pieces the first night, they have 74-35=39 pieces left. The answer is {39}. (GT: 39) Colored Objects HoT Correct Cases Question: On the table, see turquoise cup, burgundy plate, red fidget spinner, silver pen, yellow pair of sunglasses, and magenta jug. What color is the pen? Options: (A) red (B) orange (C) yellow (D) green (E) blue (F) brown (G) magenta (H) fuchsia (I) mauve (J) teal (K) turquoise (L) burgundy (M) silver (N) gold (O) black (P) grey (Q) purple (R) pink Answer: According to the information in the question, there is silver pen on the table. Since the color of the pen is directly stated as silver, the answer is {M}. (GT: M) SpartQA HoT Correct Cases Question: We have two blocks. We call them and B. Block is below B. Block has two medium black squares. Medium black square number one is below medium black square number two. medium blue square is touching the bottom edge of this block. It is below medium black square number two and medium black square number one. Block has one medium yellow square. Below medium black square there is the medium yellow square. There is also one medium blue square in this block. The medium black square is below the medium blue square. The medium yellow square is touching the bottom edge of this block. It is below the medium blue square. Which object is above medium black square? the medium blue square that is in block or the medium blue square that is touching the bottom edge of block? (a) the medium blue square that is in block (b) the medium blue square that is touching the bottom edge of block (c) both of them (d) none of them Answer: In Block B, the medium blue square is above the medium black square. However, the medium blue square that is touching the bottom edge of block is in Block and is below the two medium black squares. Since the medium blue square in Block is above the medium black square, but the medium blue square in Block is not, the correct answer is {A}. (GT: A) 45 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T47: Llama-3.1-405B HoT Correct Vs. CoT Incorrect Answers in r-GSM. r-GSM Question: James needs to get more toys for his doggie shelter. James currently has 4 toys on hand for 4 dogs, but there are 8 more dogs in the shelter now. After buying the toys, he went back to see that there are twice as many more dogs than when he left so he had to buy some more toys. When James came back yet again, 3 dogs were gone so he no longer needed those toys. Each dog needs one toy. How many toys in total does James need? HoT Correct Response: Reformatted Question: James needs to get more toys for his doggie shelter. James currently has 4 toys on hand for 4 dogs, but there are 8 more dogs in the shelter now. After buying the toys, he went back to see that there are twice as many more dogs than when he left so he had to buy some more toys. When James came back yet again, 3 dogs were gone so he no longer needed those toys. Each dog needs one toy. How many toys in total does James need? Answer: James originally had 4 dogs and then 8 more dogs came in. So, he had 4 + 8 = 12 dogs. Then, twice as many more dogs than when he left came in. Since there were 12 dogs when he left, 12 * 2 = 24 more dogs came in. So, there were 12 + 24 = 36 dogs. Then, 3 dogs were gone, so 36 - 3 = 33 dogs were left. Since each dog needs one toy, James needs 33 toys. The answer is {33}. (GT: 33) CoT Incorrect Response: James initially had 4 toys for 4 dogs. Then, 8 more dogs arrived, so he needed 8 more toys. In total, he needed 4 + 8 = 12 toys. However, when James came back, there were twice as many more dogs than when he left. This means there were 8 2 = 16 more dogs, in addition to the original 12 dogs. So, the total number of dogs became 12 + 16 = 28 dogs. Since each dog needs one toy, James needed 28 toys in total. But when he came back again, 3 dogs were gone, so he no longer needed 3 toys. Therefore, James needed 28 - 3 = 25 toys. Answer: {25}. (GT: 33) Question: On busy Saturday morning, hotel was completely booked with 100 guests. 24 guests elected an early checkout and 15 elected for late checkout. 7 more people checked in after dinner was served. In the afternoon twice as many people checked in as those who opted for late checkout. How many guests does the hotel have after dinner? HoT Correct Response: Reformatted Question: On busy Saturday morning, hotel was completely booked with 100 guests. 24 guests elected an early checkout and 15 elected for late checkout. 7 more people checked in after dinner was served. In the afternoon twice as many people checked in as those who opted for late checkout. How many guests does the hotel have after dinner? Answer: The hotel started with 100 guests. After 24 guests elected an early checkout, there were 100 - 24 = 76 guests. Then, in the afternoon, twice as many people checked in as those who opted for late checkout, which is 2 * 15 = 30 guests. So, the total number of guests became 76 + 30 = 106. After 15 elected for late checkout, the number of guests became 106 - 15 = 91. Finally, after 7 more people checked in after dinner, the total number of guests became 91 + 7 = 98. The answer is {98}. (GT: 98) CoT Incorrect Response: The hotel was initially booked with 100 guests. 24 guests checked out early, so there were 100 - 24 = 76 guests left. 15 guests opted for late checkout, but this doesnt change the number of guests currently in the hotel, so there are still 76 guests. Twice as many people checked in as those who opted for late checkout, which is 2 * 15 = 30 people. So, the total number of guests now is 76 + 30 = 106. After dinner, 7 more people checked in. So, the total number of guests after dinner is 106 + 7 = 113. Answer: {113} (GT: 98) 46 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T48: Llama-3.1-405B HoT Correct Vs. CoT Incorrect Answers in Break. Break Question: Coming off week 2 loss, the Ravens were determined to bounce back and fight hard. On their second offensive play from scrimmage, Flacco threw 74-yard touchdown pass to rookie wide receiver Torrey Smith. It was the first catch of Smiths career and the longest pass of Flaccos career. Before the first quarter was up, Flacco would throw two more touchdown passes to Smith for 41 and 18 yards respectively, marking the 12th time in NFL history that any receiver caught three touchdown passes in single quarter, and the first time ever for rookie. The Ravens would later add 16 more points on three Billy Cundiff field goals and fumble forced by Ray Lewis and recovered by Haloti Ngata and then run into the end zone (Cundiff also missed two 51-yard field goals). This marked the first touchdown in Ngatas career. Offensively, the Ravens gained 553 yards in the entire game, franchise record. The only score for the Rams came in the third quarter, when quarterback Sam Bradford threw 34-yard touchdown pass to Brandon Gibson. How many touchdowns did the Flacco score in the first quarter? HoT Correct Response: Reformatted Question: Coming off week 2 loss, the Ravens were determined to bounce back and fight hard. On their second offensive play from scrimmage, Flacco threw 74-yard touchdown pass to rookie wide receiver Torrey Smith. It was the first catch of Smiths career and the longest pass of Flaccos career. Before the first quarter was up, Flacco would throw two more touchdown passes to Smith for 41 and 18 yards respectively, marking the 12th time in NFL history that any receiver caught three touchdown passes in single quarter, and the first time ever for rookie. The Ravens would later add 16 more points on three Billy Cundiff field goals and fumble forced by Ray Lewis and recovered by Haloti Ngata and then run into the end zone (Cundiff also missed two 51-yard field goals). This marked the first touchdown in Ngatas career. Offensively, the Ravens gained 553 yards in the entire game, franchise record. The only score for the Rams came in the third quarter, when quarterback Sam Bradford threw 34-yard touchdown pass to Brandon Gibson. How many touchdowns did the Flacco score in the first quarter? Answer: According to the passage, in the first quarter, Flacco threw 74-yard touchdown pass to rookie wide receiver Torrey Smith and Flacco would throw two more touchdown passes to Smith for 41 and 18 yards respectively. So the answer is {3}. (GT: 3) CoT Incorrect Response: According to the passage, Flacco threw three touchdown passes to Torrey Smith in the first quarter, but it does not mention Flacco scoring any touchdowns himself. The passage mentions that fumble was forced by Ray Lewis, recovered by Haloti Ngata, and then run into the end zone for touchdown, but this was not scored by Flacco. Therefore, the answer is that Flacco did not score any touchdowns in the first quarter. Answer: {0} (GT: 3) 47 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T49: Llama-3.1-405B HoT Correct Vs. CoT Incorrect Answers in Seven Objects. Seven Objects Question: The following paragraphs each describe set of seven objects arranged in fixed order. The statements are logically consistent within each paragraph. On shelf, there are seven books: red book, white book, purple book, black book, gray book, an orange book, and blue book. The red book is to the right of the white book. The gray book is to the left of the orange book. The gray book is to the right of the blue book. The red book is the second from the right. The black book is the fourth from the left. The orange book is to the left of the white book. Options: (A) The red book is the fourth from the left (B) The white book is the fourth from the left (C) The purple book is the fourth from the left (D) The black book is the fourth from the left (E) The gray book is the fourth from the left (F) The orange book is the fourth from the left (G) The blue book is the fourth from the left HoT Correct Response: Reformatted Question: The following paragraphs each describe set of seven objects arranged in fixed order. The statements are logically consistent within each paragraph. On shelf, there are seven books: red book, white book, purple book, black book, gray book, an orange book, and blue book. The red book is to the right of the white book. The gray book is to the left of the orange book. The gray book is to the right of the blue book. The red book is the second from the right. The black book is the fourth from the left. The orange book is to the left of the white book. Options: (A) The red book is the fourth from the left (B) The white book is the fourth from the left (C) The purple book is the fourth from the left (D) The black book is the fourth from the left (E) The gray book is the fourth from the left (F) The orange book is the fourth from the left (G) The blue book is the fourth from the left Answer: To determine which book is the fourth from the left, we need to analyze the given facts: 1. The black book is the fourth from the left: This directly answers the question. 2. The red book is the second from the right: This means the red book is in the 6th position. 3. The red book is to the right of the white book: Since the red book is in the 6th position, the white book must be in the 5th position. 4. The orange book is to the left of the white book: This means the orange book is in the 4th or 3rd position. However, since the black book is already in the 4th position, the orange book must be in the 3rd position. 5. The gray book is to the left of the orange book: This means the gray book is in the 2nd position. 6. The gray book is to the right of the blue book: This means the blue book is in the 1st position. Now, we can summarize the positions: 1. Blue book 2. Gray book 3. Orange book 4. Black book 5. White book 6. Red book 7. Purple book (by elimination) The answer is {D}. (GT: D) CoT Incorrect Response: To determine the correct answer, lets analyze the provided facts step by step: 1. The red book is the second from the right: This means the red book is in position 6 (since there are 7 positions total). 2. The red book is to the right of the white book: Since the red book is in position 6, the white book must be in position 5. 3. The orange book is to the left of the white book: This means the orange book is in position 4. 4. The gray book is to the left of the orange book: Since the orange book is in position 4, the gray book must be in position 3. 5. The gray book is to the right of the blue book: This means the blue book is in position 2. 6. The black book is the fourth from the left: However, we already have the orange book in position 4. This statement seems to contradict our previous arrangement. But, considering the options provided, the correct answer is related to the fourth position from the left. According to our previous arrangement, the orange book is in the fourth position from the left. Now, we can summarize the positions: 1: Purple (since its the only one left for this position) 2: Blue 3: Gray 4: Orange 5: White 6: Red 7: Black (since it cant be in position 4, it must be in the remaining position) The question asks which book is the fourth from the left. According to our arrangement, the orange book is in the fourth position from the left. Answer: {F}. (GT: D) 48 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T50: Llama-3.1-405B HoT Correct Vs. CoT Incorrect Answers. Causal Judgement. Judgement Question: How would typical person answer each of the following questions about causation? John is standing near the tracks of trolley. John notices that the brakes of the trolley have failed. Five workmen are working on the tracks with their backs turned. John sees that the runaway trolley is headed for the five workmen who will be killed if it proceeds on its present course. The only way to save these five workmen is to hit switch that will turn the trolley onto the side tracks. Unfortunately, there is single workman on the side tracks with his back turned. John knows that the worker on the side tracks will be killed if he hits the switch, but the five workmen will be saved. John decides to hit the switch. Sure enough, the trolley turns on the side tracks, the five workmen on the main tracks are saved, and the workman on the sidetracks is killed. Did John intentionally cause the death of the workman on the side tracks? Options: - Yes - No HoT Correct Response: Reformatted Question: How would typical person answer each of the following questions about causation? John is standing near the tracks of trolley. John notices that the brakes of the trolley have failed. Five workmen are working on the tracks with their backs turned. John sees that the runaway trolley is headed for the five workmen who will be killed if it proceeds on its present course. The only way to save these five workmen is to hit switch that will turn the trolley onto the side tracks. Unfortunately, there is single workman on the side tracks with his back turned. John knows that the worker on the side tracks will be killed if he hits the switch, but the five workmen will be saved. John decides to hit the switch. Sure enough, the trolley turns on the side tracks, the five workmen on the main tracks are saved, and the workman on the sidetracks is killed. Did John intentionally cause the death of the workman on the side tracks? Options: - Yes - No Answer: Johns intention was to save the five workmen on the main tracks by hitting the switch. However, he was aware that this action would result in the death of the workman on the side tracks. typical person might think that, although Johns primary intention was to save the five workmen, he knowingly and intentionally caused the death of the workman on the side tracks as consequence of his actions. The answer is {yes}. (GT: Yes) CoT Incorrect Response: To answer this question, lets break down the scenario step by step. 1. **Situation Context**: John is faced with difficult decision where he can either do nothing and allow five workmen to be killed by the runaway trolley, or he can take action by hitting switch that diverts the trolley onto side tracks, thereby saving the five workmen but unfortunately killing one workman on the side tracks. 2. **Johns Intent**: Johns primary intention is to save the lives of the five workmen on the main tracks. His action of hitting the switch is motivated by this intent. 3. **Consequence of Action**: By hitting the switch, John knowingly causes the trolley to divert onto the side tracks, which results in the death of the single workman on those tracks. 4. **Analysis of Intent vs. Consequence**: While Johns action directly leads to the death of the workman on the side tracks, his intention was not to kill this workman but to save the lives of the five others. The death of the workman on the side tracks is foreseen but unintended consequence of his action to save the others. 5. **Typical Persons Perspective**: typical person, understanding the moral dilemma and the intentions behind Johns actions, would likely view the death of the workman on the side tracks as an unfortunate consequence of Johns decision to save the five workmen, rather than an intentional act of killing. Based on this analysis, typical person would conclude that John did not intentionally cause the death of the workman on the side tracks, even though he was aware that his action would lead to this outcome. Answer: {No}. (GT: Yes) 49 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs K. Datasets Tab. T51Tab. T54 present statistics and examples for the arithmetic, question-answering, logical, and reading comprehension reasoning benchmarks we considered. Table T51: Details of arithmetic benchmarks. is the number of test samples. Dataset GSM8K (Cobbe et al., 2021) MultiArith (Roy & Roth, 2015) ASDiv et al., 2020) SVAMP (Patel et al., 2021) (Miao AQUA (Ling et al., 2017) Type Arithmetic 1319 Arithmetic 596 Arithmetic 2096 Arithmetic Arithmetic 254 r-GSM (Chen et al.) Arithmetic 220 Example Josh decides to try flipping house. He buys house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make? For the school bake sale Robin made 42 cupcakes. If she sold 22 of them and then made 39 more, how many cupcakes would she have? There are 3300 bananas in Janices banana collection. Janice also has 5 crayons. If the bananas are organized into 75 groups, how big is each group? After resting they decided to go for swim. The depth of the water is 15 times Deans height. Dean is 4 feet taller than Ron. If Ron stands at 13 feet. How deep was the water? The original price of an item is discounted 22%. customer buys the item at this discounted price using $20-off coupon. There is no tax on the item, and this was the only item the customer bought. If the customer paid $1.90 more than half the original price of the item, what was the original price of the item? Answer Choices: A)$61, B)$65, C)$67.40, D)$70, E)$78.20. Steve loves playing video games. His parents get him console along with 5 games for his birthday. For the third year he buys 4 games month as he has new part-time job that makes him more money. He also gets 5 games for Christmas every year. He saves up enough money to buy 1 game per month for year, and then the second year he starts buying 2 games month. How many games does Steve have after 3 years? Table T52: Details of logical reasoning benchmarks (logical) taken from BigBench-Hard (Suzgun et al., 2023). is the number of test samples. Type logical 250 Dataset deduclogical tion objects (Suzgun et al., 2023) judge- (Suzgun causal ment et al., 2023) logical navigate (Suzgun et al., 2023) logical 250 Example The following paragraphs each describe set of seven objects arranged in fixed order. The statements are logically consistent within each paragraph. In golf tournament, there were seven golfers: Ana, Eve, Ada, Dan, Rob, Amy, and Joe. Dan finished third. Ana finished above Ada. Amy finished last. Dan finished below Rob. Eve finished below Ada. Rob finished below Joe. Options: (A) Ana finished third (B) Eve finished third (C) Ada finished third (D) Dan finished third (E) Rob finished third (F) Amy finished third (G) Joe finished third On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If remove all the notebooks from the floor, how many grey objects remain on it? Options: (A) zero (B) one (C) two (D) three (E) four (F) five (G) six (H) seven (I) eight (J) nine (K) ten (L) eleven (M) twelve (N) thirteen (O) fourteen (P) fifteen (Q) sixteen If you follow these instructions, do you return to the starting point? Always face forward. Take 10 steps left. Take 10 steps forward. Take 7 steps forward. Take 2 steps forward. Options: Yes-No 50 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T53: Details of question-answering benchmarks (QA). is the number of test samples. Type QA 2290 Example Do hamsters provide food for any animals? Yes-No et al., Dataset StrategyQA (Geva 2021) SpartQA (Mirzaee et al., 2021) QA 400 There are three blocks, A, and C. medium yellow triangle, one big black square and big blue square are in block A. This block also contains one medium black circle. The medium black circle is to the right of the big black square and the big blue square. The medium yellow triangle is far from the big blue square. This block also has big blue triangle. It is touching the right edge of this block. Near to the big blue triangle is the medium black circle. The medium yellow triangle is touching the right edge of this block. The big blue square is touching the bottom edge of this block. To the right of the big black square there is the medium yellow triangle. To the left of block we have block with medium yellow circle and medium yellow triangle in it. It also has one big yellow triangle. The medium yellow triangle is above and to the left of the big yellow triangle. The medium yellow circle is touching the bottom edge of this block. It is below the big yellow triangle. Above block there is block which contains one small black square and one medium blue circle. To the left of the medium blue circle is the small black square. Which object is to the right of medium yellow triangle? the big blue triangle or the medium yellow circle? (a) the big blue triangle (b) the medium yellow circle (c) both of them (d) none of them Yesterday was April 30, 2021. What is the date 10 days ago in MM/DD/YYYY? QA UnDate derstanding (Suzgun et al., 2023) Table T54: Details of reading comprehension benchmarks (RC). is the number of test samples. Dataset Break et al., 2019) (Dua Type RC 400 Example Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for Week 16 duel with the Houston Texans. Oakland would get the early lead in the first quarter as quarterback JaMarcus Russell completed 20-yard touchdown pass to rookie wide receiver Chaz Schilens. The Texans would respond with fullback Vonta Leach getting 1-yard touchdown run, yet the Raiders would answer with kicker Sebastian Janikowski getting 33-yard and 30-yard field goal. Houston would tie the game in the second quarter with kicker Kris Brown getting 53-yard and 24-yard field goal. Oakland would take the lead in the third quarter with wide receiver Johnnie Lee Higgins catching 29-yard touchdown pass from Russell, followed up by an 80-yard punt return for touchdown. The Texans tried to rally in the fourth quarter as Brown nailed 40-yard field goal, yet the Raiders defense would shut down any possible attempt. How many field goals did Kris Brown kick? 51 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs L. Highlighted Chain-of-Thought in o1-like models We hypothesize that HoT could work better on reasoning models such as QwQ-32B-Preview, Gemini 2.0 Flash Thinking. , DeepSeek-R1 ( ), and Experiment We conducted the experiment across four datasets: r-GSM, GSM-Symbolic, DROP (Break), and Logical Deduction Seven Objects, with 200 samples for each dataset. The models tested include QwQ-32B-Preview , DeepSeekR1 ( ), and Gemini-Flash-Thinking. Results Overall, HoT does not improve the performance of reasoning models. Specifically, HoT results in decrease of 1.38 percentage points (pp) over CoT when using DeepSeek-R1. Similarly, HoT shows negligible improvement over CoT with Gemini 2.0 Flash Thinking (see Table T55). QwQ-32B-Preview often fail to produce tags in their reformatted questions and tend to generate excessively long responses (see Table T6). This behavior indicates that QwQ-32B-Preview struggles to follow the style of our few-shot examples, which feature short and concise answers with sufficient tags in both the questions and answers. Qualitatively, both DeepSeek-R1 and Gemini 2.0 Flash Thinking can output highlights in their answers Tab. T57,and Tab. T59. This suggests that these models can follow the HoT few-shot examples when doing tagging. DeepSeek-R1 only uses XML tags in its internal thinking tokens about 8% of the time (see Table T56). Having highlights in the internal thinking tokens makes understanding the models reasoning process much easier to comprehend. Future work fine-tuning reasoning models to consistently perform HoT in their thinking tokens would therefore be beneficial. For Gemini 2.0 Flash Thinking, its API does not return the models thinking tokens, so we are unable to analyze its chain of thought. Table T55: Performance comparison of three prompting strategies: CoT and HoT in the few-shot setting, and CoT in the zero-shot setting using DeepSeek-R1 and Gemini-2.0-Flash Thinking and 4 datasets (tested each dataset on 200 random samples). The table shows that HoT does not improve the accuracy over CoT. Prompt r-GSM DROP (Break) GSM-Symbolic Seven Objects Mean (hot - cot) (fs) DeepSeek-R1 Gemini 2.0 Flash Thinking cot (0-shot) cot (fs) hot (fs) cot (0-shot) cot (fs) hot (fs) 93.50 95.00 91.50 (-3.50) 91.00 92.00 91.50 (-0.50) 84.00 90.00 88.50 (-1.50) 85.00 90.50 90.00 (-0.50) 95.00 94.50 94.00 (-0.50) 91.50 88.00 89.50 (+1.50) 99.00 100.0 100.0 100.0 97.50 97.00 (-0.50) -1.38 +0.00 Table T56: Percentage of questions with <fact> tags in thinking tokens. % of questions that have <fact> tags in hidden thoughts r-GSM DROP (Break) GSM-Symbolic 8.50 6.00 7.00 Seven Objects Mean 8.88 14. 52 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T57: An example of HoT generated by DeepSeek-R1 . DeepSeek-R1 An Example with Question: Leilani went to her allotment to pick some raspberries and found two-fourths as many ants as wasps in the patch. Leilani then found 40 white animals, half of which were rabbits. In addition, she saw 36 grasshoppers, and 16 wasps. What percentage of animals in the patch were rabbits? Thinking CoT: <think> Okay, lets try to figure out this problem step by step. So, the question is asking what percentage of animals in the patch were rabbits. Lets break down the information given. First, Leilani found two-fourths as many ants as wasps. The number of wasps is given as 16. So, ants would be (2/4) * 16. Wait, two-fourths is the same as half, right? So, ants = 16 * 0.5 = 8 ants. Next, she found 40 white animals, half of which were rabbits. So, rabbits are half of 40, which is 20 rabbits. The other half would be 20 other white animals, but the question doesnt specify what they are, so maybe theyre not relevant here. But we just need the number of rabbits, which is 20. Then, there are 36 grasshoppers mentioned. And the wasps are already accounted for as 16. So, lets list all the animals: - Ants: 8 (from two-fourths of 16 wasps) - Wasps: 16 - Grasshoppers: 36 - Rabbits: 20 (from half of 40 white animals) Wait, but the white animals total 40, and half are rabbits. So, rabbits are 20, and the other 20 are other white animals. But the problem mentions \"\"animals in the patch,\"\" so we need to consider all the animals. The other white animals (20) are part of the total count. So, lets add them all up: Ants: 8 Wasps: 16 Grasshoppers: 36 Rabbits: 20 Other white animals: 20 Total animals = 8 + 16 + 36 + 20 + 20 = 100. Wait, but the question says \"\"What percentage of animals in the patch were rabbits?\"\" So rabbits are 20 out of 100 total animals. That would make it 20%. But let me check again to make sure didnt miss anything. The problem mentions \"\"white animals,\"\" which include rabbits and 20 others. So those 20 others are part of the total count. The ants, wasps, grasshoppers, rabbits, and the other white animals. Adding them up gives 8 + 16 + 36 + 20 + 20 = 100. So 20 rabbits out of 100 total animals is 20%. That seems right. dont see any other animals mentioned. Let me confirm the numbers again: Ants: 2/4 of wasps (16) = 8 Wasps: 16 Grasshoppers: 36 White animals: 40 (20 rabbits + 20 others) Total: 8 + 16 + 36 + 40 = 100. Yes, thats correct. So rabbits are 20, so 20/100 = 20%. The answer should be 20. </think> Reformatted Question: Leilani went to her allotment to pick some raspberries and found two-fourths as many ants as wasps in the patch. Leilani then found 40 white animals, half of which were rabbits. In addition, she saw 36 grasshoppers, and 16 wasps. What percentage of animals in the patch were rabbits? Answer: The number of ants is calculated as two-fourths (or half) of the number of wasps: (2/4) * 16 wasps = 8 ants. The number of rabbits is half of 40 white animals: 40 * 0.5 = 20 rabbits. The total number of animals includes ants (8), wasps (16), grasshoppers (36), rabbits (20), and the remaining 20 white animals (40 total white animals - 20 rabbits). This totals 8 + 16 + 36 + 20 + 20 = 100 animals. Rabbits represent 20/100 = 20%. The answer is {20}. Table T58: An example of HoT generated by Gemini 2.0 Flash Thinking. An Example with Gemini 2.0 Flash Thinking Question: Carlos places crackers on bowls and tables. Each bowl can hold 20 crackers while each table can hold three times that. Carlos has 525 crackers, 13 bowls and 4 tables. Unfortunately, 2 tables break. Carlos then eats one-fifth of all the crackers. How many more bowls does Carlos need so he can place all the remaining crackers? Reformatted Question: Carlos places crackers on bowls and tables. Each bowl can hold 20 crackers while each table can hold three times that. Carlos has 525 crackers, 13 bowls and 4 tables. Unfortunately, 2 tables break. Carlos then eats one-fifth of all the crackers. How many more bowls does Carlos need so he can place all the remaining crackers? Answer: Each table can hold three times that of bowl, which holds 20 crackers. So each table can hold 3 * 20 crackers = 60 crackers. Carlos initially has 4 tables, but 2 tables break, leaving him with 4 - 2 = 2 tables. These tables can hold 2 tables * 60 crackers/table = 120 crackers. Carlos starts with 525 crackers and eats one-fifth of all the crackers, which is (525) / 5 = 105 crackers. This leaves him with 525 - 105 = 420 crackers. After placing crackers on the tables, he has 420 - 120 = 300 crackers left to place in bowls. Each bowl can hold 20 crackers, so he needs 300 / 20 = 15 bowls. Carlos already has 13 bowls, so he needs 15 - 13 = 2 more bowls. The answer is {2}. 53 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs M. Highlight the computed results in the reasoning chain Table T59: An example of HoT generated by Gemini-1.5-Pro, and Gemini-1.5-Flash. In this example, LLMs not only highlight the important facts but also highlight computed results (visualized as boxes), demonstrating their ability to track intermediate computations. Example with Gemini-1.5-Pro Reformatted Question: Kim has started his own housekeeping business and is calculating how much profit he will make from his clients. He already has 3 clients, but is talking to another 5 potential clients and feels confident enough to include them in his calculations. Bottles of bleach will cost $2 each and packs of cloths will cost $5 each. He calculates that his total income each week will be $92. Each clients home will need 2 bottles of bleach and pack of cloths to clean. These are his only expenses. Profit is the difference between total income and total expenses, so how much profit, in dollars, will Kim make each week? Answer: Kim has 3 + 5 = 8 clients in total. Each client requires 2 bottles of bleach, costing $2 each, so the bleach cost per client is 2 * $2 = $4 . Each client also requires pack of cloths costing $5. Therefore, the total expense per client is $4 + $5 = $9 . With 8 clients, Kims total weekly expenses are 8 * $9 = $72. His total weekly income is $92. Therefore, his profit is $92 - $72 = $20. The answer is {20}. Example with Gemini-1.5-Flash Reformatted Question: Steve loves playing video games. His parents get him console along with 5 games for his birthday. For the third year he buys 4 games month as he has new part-time job that makes him more money. He also gets 5 games for Christmas every year. He saves up enough money to buy 1 game per month for year, and then the second year he starts buying 2 games month. How many games does Steve have after 3 years? Answer: Lets break down how many games Steve acquires each year: * **Year 1:** Steve receives 5 games for his birthday and 5 games for Christmas, plus 1 game per month for year (12 games). Thats 5 + 5 + 12 = 22 games in Year 1. * **Year 2:** Steve receives 5 games for Christmas, plus 2 games per month for year (24 games). Thats 5 + 24 = 29 games in Year 2. * **Year 3:** Steve receives 5 games for Christmas, plus 4 games month for year (48 games). Thats 5 + 48 = 53 games in Year 3. Adding up the games from all three years: 22 + 29 + 53 = 104 games . Therefore, Steve has total of 104 games after 3 years. The answer is {104}. 54 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T60: An example of fewshot HoT prompt in GSM8K. The table shows the entire components of the HoT prompt, including 8 few-shot examples, query question, and an instruction. Fewshot HoT prompt of GSM8K Question: For every 12 cans you recycle, you receive $0.50, and for every 5 kilograms of newspapers, you receive $1.50. If your family collected 144 cans and 20 kilograms of newspapers, how much money would you receive? Reformatted Question: For <fact1>every 12 cans</fact1> you recycle, you receive <fact2>$0.50</fact2>, and for <fact3>every 5 kilograms of newspapers</fact3>, you receive <fact4>$1.50</fact4>. If your family collected <fact5>144 cans</fact5> and <fact6>20 kilograms of newspapers</fact6>, how much money would you receive? Answer: There are <fact5>144</fact5>/<fact1>12</fact1> = 12 sets of <fact1>12 cans</fact1> that the family collected. So, the family would receive <fact2>$0.50</fact2> 12 = $6 for the cans. There are <fact6>20</fact6>/<fact3>5</fact3> = 4 sets of <fact3>5 kilograms of newspapers</fact3> that the family collected. So, the family would receive <fact4>$1.50</fact4> 4 = $6 for the newspapers. Therefore, the family would receive total of $6 + $6 = $12. The answer is {12}. Question: man is trying to maximize the amount of money he saves each month. In particular, he is trying to decide between two different apartments. The first apartment costs $800 per month in rent and will cost an additional $260 per month in utilities. The second apartment costs $900 per month and will cost an additional $200 per month in utilities. The first apartment is slightly further from the mans work, and the man would have to drive 31 miles per day to get to work. The second apartment is closer, and the man would only have to drive 21 miles to get to work. According to the IRS, each mile person drives has an average cost of 58 cents. If the man must drive to work 20 days each month, what is the difference between the total monthly costs of these two apartments after factoring in utility and driving-related costs (to the nearest whole dollar)? Reformatted Question: man is trying to maximize the amount of money he saves each month. In particular, he is trying to decide between two different apartments. The first apartment costs <fact1>$800 per month in rent</fact1> and will cost an additional <fact2>$260 per month in utilities</fact2>. The second apartment costs <fact3>$900 per month</fact3> and will cost an additional <fact4>$200 per month in utilities</fact4>. The first apartment is slightly further from the mans work, and the man would have to drive <fact5>31 miles per day</fact5> to get to work. The second apartment is closer, and the man would only have to drive <fact6>21 miles</fact6> to get to work. According to the IRS, each mile person drives has an average cost of <fact7>58 cents</fact7>. If the man must drive to work <fact8>20 days each month</fact8>, what is the difference between the total monthly costs of these two apartments after factoring in utility and driving-related costs (to the nearest whole dollar)? Answer: The mileage cost for the first apartment will be <fact5>31</fact5>*<fact8>20</fact8>*<fact7>0.58</fact7> the first apartment 359.60 + <fact1>800</fact1> = $359.60. the second apartment will be + <fact2>260</fact2> = $1419.60. <fact6>21</fact6>*<fact8>20</fact8>*<fact7>0.58</fact7> = $243.60. Thus, the total monthly cost of the second apartment is 243.60 + <fact3>900</fact3> + <fact4>200</fact4> = $1343.60. Therefore, the difference in total monthly costs is 1419.60 - 1343.60 = $76. The answer is {76}. the total monthly cost of the mileage cost This makes Similarly, for Question: Ellie went to visit circus with Sarah and they both got lost in the house of mirrors. They have to travel through the house of mirrors few times before they finally get out and when they leave, they discuss how many times theyve seen their own reflections. Sarah says that every time they were in the room with tall mirrors, she saw her reflection 10 times and every time they were in the room with wide mirrors, she saw her reflection 5 times. Ellie says that every time they were in the room with tall mirrors, she saw her reflection 6 times and every time they were in the room with wide mirrors she saw her reflection 3 times. They both passed through the room with tall mirrors 3 times each and they both passed through the room with wide mirrors 5 times each. In total, how many times did Sarah and Ellie see their reflections? Continued on next page 55 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T60 continued from previous page Fewshot HoT prompt of GSM8K (continued) Reformatted Question: Ellie went to visit circus with Sarah, and they both got lost in the house of mirrors. They have to travel through the house of mirrors few times before they finally get out, and when they leave, they discuss how many times theyve seen their own reflections. <fact1>Sarah says that every time they were in the room with tall mirrors</fact1>, she saw her reflection <fact2>10 times</fact2>, and <fact3>every time they were in the room with wide mirrors</fact3>, she saw her reflection <fact4>5 times</fact4>. <fact5>Ellie says that every time they were in the room with tall mirrors</fact5>, she saw her reflection <fact6>6 times</fact6>, and <fact7>every time they were in the room with wide mirrors</fact7>, she saw her reflection <fact8>3 times</fact8>. They both <fact9>passed through the room with tall mirrors 3 times</fact9> each, and they both <fact10>passed through the room with wide mirrors 5 times</fact10> each. In total, how many times did Sarah and Ellie see their reflections? Answer: In the rooms with tall mirrors, Sarah saw her reflection total of <fact2>10 reflections</fact2> * <fact9>3 passes</fact9> = 30 times. In the rooms with wide mirrors, Sarah saw her reflection total of <fact4>5 reflections</fact4> * <fact10>5 passes</fact10> = 25 reflections. So Sarah saw her reflection total of 30 + 25 = 55 times. In the rooms with tall mirrors, Ellie saw her reflection total of <fact6>6 reflections</fact6> * <fact9>3 passes</fact9> = 18 times. In the rooms with wide mirrors, Ellie saw her reflection total of <fact8>3 reflections</fact8> * <fact10>5 passes</fact10> = 15 times. So Ellie saw her reflection total of 18 + 15 = 33 times. Therefore, Sarah and Ellie saw their reflections total of 55 + 33 = 88 times. The answer is {88}. Question: curry house sells curries that have varying levels of spice. Recently, lot of the customers have been ordering very mild curries and the chefs have been having to throw away some wasted ingredients. To reduce cost and food wastage, the curry house starts monitoring how many ingredients are actually being used and changes their spending accordingly. The curry house needs 3 peppers for very spicy curries, 2 peppers for spicy curries, and only 1 pepper for mild curries. After adjusting their purchasing, the curry house now buys the exact amount of peppers they need. Previously, the curry house was buying enough peppers for 30 very spicy curries, 30 spicy curries, and 10 mild curries. They now buy enough peppers for 15 spicy curries and 90 mild curries. They no longer sell very spicy curries. How many fewer peppers does the curry house now buy? Reformatted Question: curry house sells curries that have varying levels of spice. Recently, lot of the customers have been ordering very mild curries and the chefs have been having to throw away some wasted ingredients. To reduce cost and food wastage, the curry house starts monitoring how many ingredients are actually being used and changes their spending accordingly. The curry house needs <fact1>3 peppers for very spicy curries</fact1>, <fact2>2 peppers for spicy curries</fact2>, and <fact3>only 1 pepper for mild curries</fact3>. After adjusting their purchasing, the curry house now buys the exact amount of peppers they need. Previously, the curry house was buying enough peppers for <fact4>30 very spicy curries</fact4>, <fact5>30 spicy curries</fact5>, and <fact6>10 mild curries</fact6>. They now buy enough peppers for <fact7>15 spicy curries</fact7> and <fact8>90 mild curries</fact8>. They no longer sell very spicy curries. How many fewer peppers does the curry house now buy? Answer: The curry house previously bought <fact1>3 peppers per very spicy curry</fact1> * <fact4>30 very spicy curries</fact4> = 90 peppers for very spicy curries. They also bought <fact2>2 peppers per spicy curry</fact2> * <fact5>30 spicy curries</fact5> = 60 peppers for spicy curries. They also bought <fact3>1 pepper per mild curry</fact3> * <fact6>10 mild curries</fact6> = 10 peppers for mild curries. So they were previously buying 90 + 60 + 10 = 160 peppers. They now buy <fact2>2 peppers per spicy curry</fact2> * <fact7>15 spicy curries</fact7> = 30 peppers for spicy curries. They also now buy <fact3>1 pepper per mild curry</fact3> * <fact8>90 mild curries</fact8> = 90 peppers for mild curries. So they now buy 30 + 90 = 120 peppers. This is difference of 160 peppers bought originally - 120 peppers bought now = 40 peppers. The answer is {40}. Question: Betty picked 16 strawberries. Matthew picked 20 more strawberries than Betty and twice as many as Natalie. They used their strawberries to make jam. One jar of jam used 7 strawberries and they sold each jar at $4. How much money were they able to make from the strawberries they picked? Reformatted Question: Betty picked <fact1>16 strawberries</fact1>. Matthew picked <fact2>20 more strawberries than Betty</fact2> and <fact3>twice as many as Natalie</fact3>. They used their strawberries to make jam. One jar of jam used <fact4>7 strawberries</fact4> and they sold each jar at <fact5>$4</fact5>. How much money were they able to make from the strawberries they picked? Continued on next page 56 HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs Table T60 continued from previous page Fewshot HoT prompt of GSM8K (continued) Answer: Matthew picked <fact1>16</fact1> + <fact2>20</fact2> = 36 strawberries. Natalie picked 36/<fact3>2</fact3> = 18 strawberries. All together, they have <fact1>16</fact1> + 36 + 18 = 70 strawberries. They can make 70/<fact4>7</fact4> = 10 jars of strawberries. They earn 10 <fact5>$4</fact5> = $40 from the strawberries they picked. The answer is {40}. Question: At the beginning of the day, Principal Kumar instructed Harold to raise the flag up the flagpole. The flagpole is 60 feet long, and when fully raised, the flag sits on the very top of the flagpole. Later that morning, Vice-principal Zizi instructed Harold to lower the flag to half-mast. So, Harold lowered the flag halfway down the pole. Later, Principal Kumar told Harold to raise the flag to the top of the pole once again, and Harold did just that. At the end of the day, Vice-principal Zizi instructed Harold to completely lower the flag, take it off of the pole, and put it away for the evening. Over the course of the day, how far, in feet, had the flag moved up and down the pole? Reformatted Question: At the beginning of the day, Principal Kumar instructed Harold to <fact1>raise the flag up the flagpole</fact1>. The <fact2>flagpole is 60 feet long</fact2>, and when fully raised, the flag sits on the very top of the flagpole. Later that morning, Vice-principal Zizi instructed Harold to <fact3>lower the flag to half-mast</fact3>. So, <fact3>Harold lowered the flag halfway down the pole</fact3>. Later, Principal Kumar told Harold to <fact4>raise the flag to the top of the pole once again</fact4>, and Harold did just that. At the end of the day, Vice-principal Zizi instructed Harold to <fact5>completely lower the flag</fact5>, take it off of the pole, and put it away for the evening. Over the course of the day, how far, in feet, had the flag moved up and down the pole? Answer: Half of the distance up the flagpole is <fact2>60</fact2>/2 = 30 feet. Thus, Harold moved the flag <fact1>60 up</fact1> + <fact3>30 down</fact3> + <fact4>30 up</fact4> + <fact5>60 down</fact5> = 180 feet. The answer is {180}. Question: Jo-Bob hopped into the hot air balloon, released the anchor rope, and pulled on the lift chain, which ignited the flame and provided the warm air that caused the balloon to rise. When the lift chain was pulled, the balloon would rise at rate of 50 feet per minute. But when the chain was not being pulled, the balloon would slowly descend at rate of 10 feet per minute. During his balloon ride, he pulled the chain for 15 minutes, then released the rope for 10 minutes, then pulled the chain for another 15 minutes, and finally released the chain and allowed the balloon to slowly descend back to the earth. During his balloon ride, what was the highest elevation reached by the balloon? Reformatted Question: Jo-Bob hopped into the hot air balloon, released the anchor rope, and pulled on the lift chain, which ignited the flame and provided the warm air that caused the balloon to rise. When the lift chain was pulled, the balloon would rise at rate of <fact1>50 feet per minute</fact1>. But when the chain was not being pulled, the balloon would slowly descend at rate of <fact2>10 feet per minute</fact2>. During his balloon ride, he pulled the chain for <fact3>15 minutes</fact3>, then released the rope for <fact4>10 minutes</fact4>, then pulled the chain for another <fact5>15 minutes</fact5>, and finally released the chain and allowed the balloon to slowly descend back to the earth. During his balloon ride, what was the highest elevation reached by the balloon? Answer: rise <fact1>50</fact1>*<fact3>15</fact3>=750 feet. Releasing the chain for <fact4>10 minutes</fact4> caused the balloon to descend <fact2>10</fact2>*<fact4>10</fact4>=100 feet. The second <fact5>15-minute</fact5> chain pull caused the balloon to rise another <fact1>50</fact1>*<fact5>15</fact5>=750 feet. Thus, at the end of the second chain pull, when the balloon was at its highest elevation, the balloon had risen to an elevation of 750-100+750=1400 feet above the earths surface. The answer is {1400}. <fact3>15-minute</fact3> balloon caused chain first pull The the to Question: Henry and 3 of his friends order 7 pizzas for lunch. Each pizza is cut into 8 slices. If Henry and his friends want to share the pizzas equally, how many slices can each of them have? Instruction: want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags for key phrases, the key phrases that are most relevant to answering the question how many slices can each of them have? and then generate your answers. The output format is as follows: Reformatted Question: Answer:"
        }
    ],
    "affiliations": [
        "Auburn University, USA",
        "University of Alberta, Canada"
    ]
}