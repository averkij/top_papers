{
    "paper_title": "Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models",
    "authors": [
        "Mahta Fetrat Qharabagh",
        "Zahra Dehghanian",
        "Hamid R. Rabiee"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Homograph disambiguation remains a significant challenge in grapheme-to-phoneme (G2P) conversion, especially for low-resource languages. This challenge is twofold: (1) creating balanced and comprehensive homograph datasets is labor-intensive and costly, and (2) specific disambiguation strategies introduce additional latency, making them unsuitable for real-time applications such as screen readers and other accessibility tools. In this paper, we address both issues. First, we propose a semi-automated pipeline for constructing homograph-focused datasets, introduce the HomoRich dataset generated through this pipeline, and demonstrate its effectiveness by applying it to enhance a state-of-the-art deep learning-based G2P system for Persian. Second, we advocate for a paradigm shift - utilizing rich offline datasets to inform the development of fast, rule-based methods suitable for latency-sensitive accessibility applications like screen readers. To this end, we improve one of the most well-known rule-based G2P systems, eSpeak, into a fast homograph-aware version, HomoFast eSpeak. Our results show an approximate 30% improvement in homograph disambiguation accuracy for the deep learning-based and eSpeak systems."
        },
        {
            "title": "Start",
            "content": "Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models Mahta Fetrat Qharabagh, Zahra Dehghanian, Hamid R. Rabiee Dep. of Computer Engineering, Sharif University of Technology m.fetrat@sharif.edu, zahra.dehghanian97@sharif.edu, rabiee@sharif.edu 5 2 0 2 9 1 ] . [ 1 3 7 9 2 1 . 5 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Homograph disambiguation remains significant challenge in grapheme-to-phoneme (G2P) conversion, especially for low-resource languages. This challenge is twofold: (1) creating balanced and comprehensive homograph datasets is labor-intensive and costly, and (2) specific disambiguation strategies introduce additional latency, making them unsuitable for real-time applications such as screen readers and other accessibility tools. In this paper, we address both issues. First, we propose semi-automated pipeline for constructing homograph-focused datasets, introduce the HomoRich dataset generated through this pipeline, and demonstrate its effectiveness by applying it to enhance state-of-the-art deep learningbased G2P system for Persian. Second, we advocate for paradigm shiftutilizing rich offline datasets to inform the development of fast, rule-based methods suitable for latencysensitive accessibility applications like screen readers. To this end, we improve one of the most well-known rule-based G2P systems, eSpeak, into fast homograph-aware version, HomoFast eSpeak. Our results show an approximate 30% improvement in homograph disambiguation accuracy for the deep learning-based and eSpeak systems."
        },
        {
            "title": "Introduction",
            "content": "Grapheme-to-phoneme (G2P) conversion is crucial step in many fast text-to-speech (TTS) models (2020). It refers to the task of converting given written text into its corresponding sequence of phonemeshow it is pronounced. There are several formats for representing phoneme sequences, one of the most widely used being the International Phonetic Alphabet (IPA) (1999). As an example, the phoneme sequence for the sentence \"I will read it\" is /aI wIl ri:d It/ in IPA format. The complexity of G2P conversion varies by language. Some languages like Turkish and Spanish 1 are highly phonetic, meaning near one-to-one correspondence between spelling and pronunciation (2013; 1945). In contrast, in many other languages, such as Persian, G2P is more complex due to exceptions and rules that depend on context (2025a). is handling homographswords spelled the same but pronounced differently depending on context. For example, the word \"read\" is pronounced /rEd/ in the past tense (\"I read this book yesterday\") and /ri:d/ in the present tense (\"I read the book every night\"). such challenge One Unfortunately, sentence-level G2P datasets are extremely scarce in low-resource languages. This scarcity stems from the fact that phonemization is time-consuming and costly process that requires expert annotators. Homograph-specific datasets are even rarer, as they depend on source corpora that must meet strict conditions: they should contain wide range of homographs and provide balanced number of examples for each pronunciation. Without this balance, the resulting models will fail to learn some homographs and tend to default to the more frequent pronunciation in ambiguous cases. Beyond data scarcity, there is also methodological challenge in G2P conversion. The two primary approaches are rule-based methods (2012; 2019; 2012) and neural models (2024; 2024b; 2024). While neural methods have gained popularity due to their flexibility and learning capacity, they often suffer from high inference latency, making them unsuitable for real-time applications such as screen readers that serve accessibility needs. This motivates renewed focus on rule-based approaches, aiming to improve their accuracy while preserving their inherent speed. This work proposes practical approach for generating rich and balanced homograph dataset. We demonstrate that such dataset not only boosts the homograph disambiguation accuracy of neural G2P models but also significantly enhances the performance of rule-based systems. Specifically, we show that by incorporating simple, fast statistical method that leverages the proposed dataset, rule-based models can be equipped with context understanding, leading to improved handling of homographs without sacrificing speed. Our key contributions are as follows: We propose practical and cost-efficient recipe for constructing rich and balanced homograph datasets in low-resource languages by leveraging LLMs for G2P annotation and homograph sample generation. We release HomoRich, the first and largest Persian homograph dataset, and demonstrate its effectiveness by improving the homograph disambiguation accuracy of state-of-the-art neural G2P model by 29.72%. We introduce lightweight statistical method that enhances G2P systems for homograph disambiguation, using datasets generated by our proposed approach. We integrate this method into the open-source eSpeak engine, resulting in HomoFast eSpeak, variant that achieves 30.66% improvement in homograph disambiguation without compromising real-time performance."
        },
        {
            "title": "2 Related Works",
            "content": "In this section, we review homograph disambiguation from two perspectives: the common methods and the datasets developed to address challenges in low-resource settings like Persian. 2.1 Approaches There are multiple approaches to addressing the homograph challenge, including neural and rulebased methods, various machine learning algorithms, hybrid techniques, and the use of large language models (LLMs). We briefly highlight only the works most relevant to our approach. more comprehensive review is provided in Appendix A. Rule-based approaches have been widely explored for homograph disambiguation across various languages. These methods often rely on morphosyntactic patterns, lexical cues, and contextual heuristics rather than deep semantic inference. For instance, Silva et al. (2012) and Alayiaboozar et al. (2019) utilized hand-crafted linguistic rules derived from syntactic and morphological features in Brazilian Portuguese and Persian, respectively. Hearst (1991) introduced system based on shallow syntactic patterns and lexical co-occurrences in local contexts, while Yarowsky (1997) developed data-driven decision lists using log-likelihood-ranked contextual patterns. Riahi and Sedghi (2012) further extended these ideas by integrating rule-based decision lists into tritraining framework. Neural approaches have been widely adopted for homograph disambiguation and G2P conversion across languages, leveraging contextual embeddings, sequence modeling, and attention mechanisms. Nicolis and Klimkov (2021) and Seale (2021) utilized pretrained language models like BERT, ALBERT, and XLNet to extract contextual word embeddings and fine-tune token classifiers or logistic regressors for English homographs. SoundChoice, proposed by Ploujnikov (2024), employed hybrid RNN-attention model with BERT embeddings and curriculum learning to predict phonemes in context. Similarly, Nanni (2023) adapted SoundChoice for Italian, integrating ChatGPT-generated data. ˇRezáˇcková et al. (2024a,b) adopted the T5 transformer for multilingual G2P, bypassing rulebased post-processing by modeling cross-word effects. Comini et al. (2025) combined GRUs, transformers, and knowledge distillation for efficient G2P in low-resource settings. Gao (2024) enhanced multilingual phonetic recognition using self-supervised learning models (e.g., wav2vec2, HuBERT) and synthetic data. are approaches LLM-based increasingly demonstrating the potential of LLMs in G2P conversion. Suvarna et al. (2024) were the first to benchmark models like GPT-4 and Claude-3 on phonological tasks, including G2P, and found that while promising, they still lag behind traditional models in accuracy. Han et al. (2024) leveraged GPT-4s in-context retrieval to map homographs to dictionary pronunciations, combining automated generation with manual refinement for accuracy. Similarly, in our previous work (Qharabagh et al., 2025a), we applied LLMs to Persian G2P conversion through advanced prompting, achieving state-of-the-art results on custom datasets without model fine-tuning. 2.2 Datasets Several studies have proposed various methods to address data scarcity in G2P for low-resource languages such as Persian. comprehensive review Title Sample Type Sample Count Hom. Hom. Curated Count Availablity License (2012) Semi-sup H.D. (2024) AvashoG2P (2022) Multi-Module G2P (2024) GE2PE HomoRich (Ours) Sent. Sent. Word Sent. Sent. Sent. 12,000 42,540 5,376,670 528,891 Yes Yes No No No Yes 2 54 285 Not avail. Not avail. Available Not avail. Available Available CC0-1.0 N.A. N.A. N.A. N.A. MIT Table 1: Persian Homograph Datasets. Hom. Count shows the number of homographs covered in the dataset and Hom. Curated indicates if homograph samples were deliberately inserted or naturally occurring in regular corpus. of these studies is provided in Appendix A.2; however, here we summarize only the most relevant features of the datasets in Table 1. As shown, all of the referenced datasets are either not homographspecific, not sentence-level, or not publicly available. This highlights critical gap in homograph data for Persianand likely for many other lowresource languageswhich has resulted in the lack of G2P systems that outperform random chance in homograph disambiguation."
        },
        {
            "title": "3 Methodology",
            "content": "Developing an effective G2P model requires both high-quality data and the tools to make use of it. This section outlines our data generation process and how we leveraged it to improve G2P models. 3.1 Data Preparation The scarcity of homograph data arises from two main challenges. First, assembling high-quality text corpus that provides broad and balanced coverage of homographs across diverse contexts is difficult. Second, phonemizing text corpus is both time-consuming and costly, as it requires trained experts with linguistic knowledge. In this paper, we present practical approach for collecting such data in low-resource language like Persian and demonstrate its effectiveness in the next section. To tackle the first challenge, we started with KaamelDict (Fetrat, 2024a), the most extensive Persian G2P dictionary introduced in Qharabagh et al., 2025a. We filtered for words with multiple valid pronunciations to identify potential homographs. Then, through manual review, we excluded words that either (1) had multiple commonly accepted pronunciations needing no disambiguation, or (2) included archaic, poetic, or rarely used forms. From this, we selected list of 285 homograph words that were both comprehensive and practically relevant. 3 The next task was to generate diverse and balanced set of sentences for each homograph, covering different usage contexts and ensuring equal representation of all pronunciations. To automate this, we experimented with prompting LLMs to generate sentences for each pronunciation or meaning. However, the results were often skewed toward the dominant pronunciation, even with explicit instructions. We found that embedding the homograph in full sentence that implied its intended meaning significantly improved accuracy. As result, we adopted hybrid approach, combining manual and LLM-generated sentences. We first shared list of selected homographs with about 200 native speakers, asking each to write five contextually varied sentences for every pronunciation. We then used some of these human-written examples as few-shot prompts to guide LLM-based sentence generation (see Figure 1). To further enhance the dataset and support downstream TTS and G2P tasks, we integrated sentences from three widely used Persian corpora: ManaTTS (2025b), GPTInformal (2025), and CommonVoice (2019). These additions were meant to improve overall G2P accuracyparticularly phoneme error rate (PER)and enrich the corpus with phonemeannotated examples from diverse registers. To the second leveraged address chalour lengephonemizationwe prior work on LLM-powered G2P conversion (2025a). In that study, we demonstrated that LLMs can assist in labeling graphemes with their phonemes, thanks to their phonetic knowledge and contextual understanding, which is particularly helpful in disambiguating homographs. We introduced several techniques to enhance LLM performance in G2P tasks without requiring any training, benchmarking state-of-the-art models to guide future dataset generation. Figure 1: Prompt for generating homograph sentences. We use the most effective method from that It prompts study to phonemize our corpus. the model with Finglisha more accessible but slightly ambiguous phonemic representation of Persianinstead of the less common IPA format. The method combines in-context learning, few-shot examples, hints from G2P dictionary, and final mapping step to produce the target phoneme format (see Figure 2). To balance cost, availability, and quality, we use GPT-4o (2024) as the LLM, which achieved Phoneme Error Rate (PER) of 6.43% and homograph disambiguation accuracy of 64%, outperforming many existing Persian G2P systems (see Section 4 for details). Figure 3 summarizes the structure of the generated dataset. For compatibility with previous work, we mapped the phonemes of all sentences to an alternative phoneme format (see Appendix B). We release our dataset, named HomoRich, under permissive CC0-1 license, making it freely available for both academic and commercial use.1 3.1.1 Data Statistics The HomoRich dataset, generated using our proposed recipe, contains 528,891 annotated Persian sentences. As mentioned, it consists of both homograph-focused and general-purpose G2P data collected from multiple sources. Figure 4 and Table 2 illustrate the composition of the dataset. To ensure diversity, both human annotators and language models were instructed to generate data across wide range of contexts. The dataset comprises 75,715 unique words, and the distribution of sentence lengths is shown in Appendix Figure 11. The HomoRich dataset includes 285 homograph 1The HomoRich available https://huggingface.co/datasets/MahtaFetrat/ HomoRich-G2P-Persian. dataset is at 4 Source GPT-4o CommonVoice ManaTTS human GPTInformal Homograph Samples (Human + GPT-4o) Total Count 257,915 118,983 76,561 69,560 5,872 327,475 528,891 Table 2: The source for different parts of the HomoRich dataset. words, each associated with multiple pronunciations: 257 have two variants, 21 have three, and 7 have four. On average, each homograph appears in over 1,000 distinct sentence contexts. To avoid bias toward more frequent pronunciations, we maintained balanced number of samples for each variant. Figure 5 shows the pronunciation distribution, confirming the datasets high balance. 3.1.2 Data Augmentation To further address data scarcityparticularly in homograph disambiguationwe proposed three augmentation methods (Figure 6) aimed at enhancing the models understanding of context and increasing data diversity. 1. Synonym Replacement (Figure 6a): We identified the most frequently occurring words in the dataset and mapped each to set of synonyms with equivalent meaning. For each sentence, we replaced these words with their alternatives to generate new samples. 2. Sentence Reordering (Figure 6b): In most Figure 2: LLM-powered G2P workflow (2025a) Figure 3: Dataset structure with example entry. Figure 4: Data source distribution in HomoRich dataset. cases, the order of context words does not affect the pronunciation of the homograph. Thus, we split sentences at random words and swapped the resulting segments, updating their corresponding phoneme sequences. However, in Persian and similar languages like Arabic, Ezafe (a phoneme that connects grammatically related words) must be preserved. We employed POS tagger (2023) to detect Ezafe constructions and ensured no splits occurred within them. 3. Homograph-focused Concatenation (Figure 6c): we further augmented homograph samples by appending randomly selected short sentences (without homographs) to the homograph samples. 5 Figure 5: Sample counts per pronunciation. Using combinations of these methods, we were able to scale the dataset by up to 10x, depending on the augmentation configuration. 3.2 Proposed G2P Tools Having generated large, rich, and balanced homograph dataset using the proposed method, we introduce both neural and rule-based G2P tools that build upon this data and demonstrate how this dataset can be used to enhance homograph disambiguation in each approach. 3.2.1 Homo-GE2PE (Neural) As reviewed in Section 2, T5 has been successfully fine-tuned for G2P tasks in multiple studies (2024b; 2024a; 2024). In recent study (2024), this approach resulted in GE2PE, model achieving state-of-the-art performance in Persian G2P. We further fine-tuned GE2PE on our dataset using three-phase process: 1. Initial fine-tuning on the regular G2P subset 2. Second-phase fine-tuning on LLM-generated homograph sentences 3. Final fine-tuning on high-quality, humanauthored homograph sentences We used learning rate of 5e-4 and batch size of 32 across all phases, with 5, 20, and 50 training epochs respectively, trained on an NVIDIA GTX (a) Synonym Replacement (b) Reordering (c) Concatenation Figure 6: Illustration of our three data augmentation methods for homograph disambiguation. TITAN (12GB VRAM, CUDA 12.2) with Intel i7-5820K CPU. The full training process took approximately 24 hours in total. The learning curves for all phases, including training and validation metrics, are shown in Figure 7. The resulting enhanced model, named Homo-GE2PE, is publicly available under an open license. 3.2.2 HomoFast eSpeak (Rule-based) As discussed earlier, one of the main motivations for favoring rule-based methods in certain applications is their low latency. Neural models, while powerful, often incur high inference times, making them less suitable for real-time systems such as screen readers. In contrast, rule-based systems are extremely fast and lightweight, enabling them to operate effectively in low-latency environments. Therefore, despite the advances in neural G2P systems, it remains important to continue exploring and enhancing rule-based approaches, particularly when speed and responsiveness are critical. However, key limitation of rule-based systems is their difficulty in disambiguating homographs, due to their limited or nonexistent semantic or contextual understanding. In this work, we introduce strategy to enhance the homograph disambiguation ability of G2P systems using datasets generated by our proposed approach. This strategy is purely statistical and does not rely on neural models or even embeddings, making it perfect solution for improving the homograph accuracy of rule-based methods without compromising their key advantagespeed and low latency. While straightforward in design, this approach has not been explored in prior homograph disambiguation research. 2Complete training scripts, model files and usage instructions are available at https://github.com/MahtaFetrat/ Homo-GE2PE-Persian. The approach begins by tokenizing the sentences in our dataset, removing stopwords, and constructing database that maps different pronunciations of homographs to lists of context words that frequently co-occur with each pronunciation. For new sentence, we compute weighted overlap between its context words and each pronunciations context list to derive similarity score. To mitigate bias toward longer lists, we normalize each score by the length of the corresponding context list. The pronunciation with the highest normalized score is then selected as the most contextually appropriate. For schematic overview of this method, see Figure 8. We applied this approach to the widely used eSpeak NG project (2024), selected for its relevance to real-world applications. eSpeak NG is compact, open-source text-to-speech synthesizer available on Linux, Windows, Android, and other platforms. It supports over 100 languages and accents, benefiting from contributions by various linguistic communities. Notably, it has an add-on in the opensource NVDA screen reader (2007), and its Persian G2P module is extensively used in screen readers by large portion of the blind community in Iran (2023; 2022). We name the enhanced version HomoFast eSpeak, which, as shown in the following sections, demonstrated outstanding results, indicating viable path for enhancing rule-based TTS systems in Persian."
        },
        {
            "title": "4 Results",
            "content": "Although several word-to-phoneme datasets exist for Persian (2023; 2019; 2022; 2002; 2004; 2017; 2022; 2020; 2019; 2022), there was no public sentence-level dataset suitable for benchmark3The HomoFast eSpeak is available at https://github. com/MahtaFetrat/HomoFast-eSpeak-Persian. 6 (a) Phase 1 (5 epochs) (b) Phase 2 (20 epochs) (c) Phase 3 (50 epochs) Figure 7: Learning curves across fine-tuning phases. Figure 8: Overview of the proposed statistical homograph disambiguation approach. ing homograph accuracy of G2P systems prior to our LLM-Powered G2P work (2025a), which introduced SentenceBench (Fetrat, 2024b). We also adopted this dataset as the primary benchmark in our experiments. Evaluation of Baseline G2P Tools: Table 3 presents the performance of previously available G2P tools on the SentenceBench benchmark. As shown, the only two models that perform well in terms of PER are the neural GE2PE model (2024) and the rule-based eSpeak tool (2024). However, even these models perform worse than random when it comes to homograph disambiguation. Evaluation of the Proposed Improved G2P Tools: To address the challenge of homograph disambiguation in Persian G2P systems, we utilized curated homograph dataset to enhance both neural and rule-based models. Specifically, we fine-tuned the GE2PE (2024) model and proposed statistical disambiguation module integrated into eSpeak (2024), resulting in two improved variants: Homo-GE2PE and HomoFast eSpeak. As depicted in Table 3, our improved GE2PE model achieves 29.72% increase in homograph accuracy with concurrent reduction in PER. Notably, our statistical disambiguation moduledevoid of any neural components or learned embeddingsdelivers the same level of homograph accuracy improvement when integrated into rule-based models, all while maintaining their in7 ference speed. This underscores the value of highquality data and shows that even simple statistical techniques can be highly effective when supported by strong datasets. Fine-tuning T5 on Our Dataset: To evaluate the effectiveness of our dataset in improving both the general phoneme error rate (PER) and homograph disambiguation, we fine-tuned the base GE2PE model (T5) using only our data with the same hardware setup and training configuration as for Homo-GE2PE, referring to this variant as HomoT5. The learning curves can be seen in Figure 12. Despite our dataset being an order of magnitude smaller than the 5-million-sample synthetic dataset used in the original GE2PE study (2024), HomoT5 achieves competitive PER and high homograph accuracy  (Table 3)  , demonstrating the quality and utility of our approach. Evaluation of Inference Speed: Another critical factor is inference speed. While the Homo-GE2PE model outperforms HomoFast eSpeak in accuracy, it is orders of magnitude slower, making it impractical for real-time applications such as screen readers. Figure 9 presents the speed and accuracy of all available and proposed G2P tools. All inference tests were conducted on Google Colab (CPU runtime).4 The color heatmap highlights lower4Inference scripts available Persian-G2P-Tools-Benchmark. at and are https://github.com/MahtaFetrat/ benchmarking code Model PER (%) Homograph Acc. (%) Avg. Inf. Time (s) persian-phonemizer (2022) PersianG2P (2020) Persian_G2P (2019) G2P (2022) G2P with Transformer (2023) Epitran (2018) eSpeak (2024) GE2PE (2024) Homo-T5 HomoFast eSpeak Homo-GE2PE 25.27 0.09 15.04 0.00 35.23 0.00 19.63 1.83 12.85 0.09 45.12 0.00 6.92 0.00 4.81 0. 4.12 0.13 6.33 0.00 3.98 0.00 29.25 0.47 37.74 0.00 21.23 0.00 29.91 0.72 40.00 0.21 0.00 0.00 43.87 0.00 47.17 0.00 76.32 0.52 74.53 0.00 76.89 0.00 0.1803 0.04 2.1686 0.10 11.1374 0.56 28.0039 0.42 0.9685 0.03 0.0003 0.00 0.0169 0.00 0.4464 0.03 0.4141 0.09 0.0084 0.00 0.4473 0.02 Table 3: Comparison of Persian G2P tools in terms of Phoneme Error Rate (PER), Homograph Accuracy, and Average Inference Time. Results are reported as mean standard deviation across 5 independent runs. Best results are in bold, and second-best are underlined. Figure 9: Inference speed and phoneme error rate (PER) of available and proposed G2P tools. performing models in red and higher-performing models in green. As shown, eSpeak and HomoFast eSpeak are the fastest models, with the latter benefiting from newly added feature that enables processing of larger text segments in single run."
        },
        {
            "title": "5 Conclusion",
            "content": "In this work, we tackled two persistent challenges in homograph disambiguation for low-resource languages: the high cost of dataset creation and the latency constraints of real-time G2P applications. We proposed semi-automated pipeline for building homograph-rich datasets and introduced HomoRich, the first large-scale, openly licensed Persian homograph dataset. Using this resource, we achieved 29.72% improvement in homograph accuracy for state-of-the-art neural G2P model. To bridge the gap between accuracy and real-time performance, we further developed lightweight, context-aware statistical method that enhances homograph handling with minimal computational overhead. Integrated into the widely used eSpeak engine, this method led to HomoFast eSpeak, fast, homograph-aware G2P system that improves disambiguation accuracy by 30.66% while retaining the responsiveness crucial for screen readers and other accessibility tools. Our results highlight the potential of using highquality offline datasets not only to train neural models, but also to enrich and modernize traditional rule-based systems. By releasing all resources under CC0-1.0 license, we aim to foster further research and practical adoption in accessibility technologies for low-resource languages."
        },
        {
            "title": "6 Limitations",
            "content": "Homograph disambiguation is not the only contextdependent challenge in Persian. Another notable challenge is the correct phonemization of the Ezafe, linking phoneme that grammatically and semantically connects words. This is major weakness in current rule-based systems. Addressing such context-sensitive phenomena requires further research, particularly in designing fast yet linguistically aware rule-based methods. Tackling challenges like Ezafe handling could bring rule-based G2P models significantly closer to the naturalness of neural modelswhile maintaining the speed advantage crucial for real-world deployment."
        },
        {
            "title": "References",
            "content": "2002. Wiktionary free dataset. https://www. wiktionary.org/. Accessed: 2024-09-05. 2004. Persian zaya dictionary. //peykaregan.ir/dataset/%D9%88%D8%A7% DA%98%DA%AF%D8%A7%D9%86-%D8%B2%D8%A7%DB% 8C%D8%A7%DB%8C-%D8%B2%D8%A8%D8%A7%D9%86-% D9%81%D8%A7%D8%B1%D8%B3%DB%8C. Accessed: 2024-09-05. https: 2007. NV Access - home of the nvda screen reader. https://www.nvaccess.org/. Accessed: 2025-0429. 2017. Persian jame glossary. http://farhang.apll. ir/. Accessed: 2024-09-05. 2019. Tihu persia dictionary. https://github.com/ tihu-nlp/tihudict. 2022. Ipa-translator. https://github.com/ lotusfa/IPA-Translator. 2023. Ipa-dict: Monolingual wordlists with pronunciation information in ipa. https://github.com/ open-dict-data/ipa-dict. Mohammad Hasan Sohan Ajini. 2022. Attention based https://github.com/ Accessed: grapheme to phoneme. mohamad-hasan-sohan-ajini/G2P. 2025-04-22. Elham Alayiaboozar, Amirsaeid Moloodi, and Manouchehr Kouhestani. 2019. Word sense disambiguation focusing on pos tag disambiguation International in persian: rule-based approach. Journal of Information, 17(2):119134. Sajad Alipour. 2023. Persian transformer. phoneme with to //github.com/sajadalipour7/ Persian-Grapheme-To-Phoneme-With-Transformer. Accessed: 2025-04-22. grapheme https: 9 Sawsan Alqahtani, Hanan Aldarmaki, and Mona Diab. 2019. Homograph disambiguation through selecIn Proceedings of the tive diacritic restoration. Fourth Arabic Natural Language Processing Workshop, pages 4959. Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber. 2019. Common voice: massivelyarXiv preprint multilingual arXiv:1912.06670. speech corpus. International Phonetic Association. 1999. Handbook of the International Phonetic Association: guide to the use of the International Phonetic Alphabet. Cambridge University Press. Seyed Moein Ayyoubzadeh and Kourosh Shahnazari. 2024. Persian homograph disambiguation: Leveraging parsbert for enhanced sentence understanding with novel word disambiguation dataset. arXiv preprint arXiv:2406.00028. Giulia Comini, Heereen Shim, and Sam Ribeiro. 2025. Lightweight neural front-ends for low-resource ondevice text-to-speech. Hafez Dehghani. 2022. persian_phonemizer: https: tool for translating persian text to ipa. //github.com/de-mh/persian_phonemizer. Accessed: 2025-04-22. Pierre Delattre. 1945. Spanish is phonetic language. Hispania, 28(4):511516. Jonathan Duddington. 2024. espeak: Compact open source speech synthesizer. https://espeak. sourceforge.net/. Accessed: 2025-04-22. Mahta Fetrat. 2024a. Kaameldict: dictionary dataset. Hugging Face Dataset. Accessed: 2025-04-22. 2024b. Mahta Fetrat. perbenchmark https://huggingface.co/datasets/ sian. MahtaFetrat/SentenceBench. Accessed: 2025-0430. Sentencebench: in sentence-level g2p for Mahta Fetrat. 2025. Gptinformal-persian: Informal persian text dataset. Hugging Face Dataset. Accessed: 2025-04-22. Heting Gao. 2024. Unsupervised speech technology for low-resource languages. Ph.D. thesis, University of Illinois at Urbana-Champaign. Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets for datasets. Communications of the ACM, 64(12):86 92. Masood Ghayoomi. 2019. Identifying persian words senses automatically by utilizing the word embedding method. Iranian Journal of Information Processing & Management, 35(1):2550. Gooshkon. 2022. New version of espeak for android and windows notice. https://gooshkon.ir/1401/03/ %D9%86%D8%B3%D8%AE%D9%87-%D8%AC%D8%AF%DB% 8C%D8%AF-%D8%A7%DB%8C%D8%B3%D9%BE%DB%8C% DA%A9-%D8%A8%D8%B1%D8%A7%DB%8C-%D8%A7%D9% 86%D8%AF%D8%B1%D9%88%DB%8C%D8%AF-%D9%88-% D9%88%DB%8C%D9%86%D8%AF%D9%88%D8%B2-e/. Accessed: 2025-04-29. Kyle Gorman, Gleb Mazovetskiy, and Vitaly Nikolaev. 2018. Improving homograph disambiguation with supervised machine learning. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). Roshan Research Group. 2023. Hazm: python library for digging into persian text. GitHub repository. Version 0.7.0. Accessed: 2025-04-22. Maria-Loulou Hajj, Martin Lenglet, Olivier Perrotin, and Gérard Bailly. 2022. Comparing nlp solutions for the disambiguation of french heterophonic homographs for end-to-end tts systems. In International Conference on Speech and Computer, pages 265278. Springer. Dongrui Han, Mingyu Cui, Jiawen Kang, Xixin Wu, Xunying Liu, and Helen Meng. 2024. Improving grapheme-to-phoneme conversion through in-context knowledge retrieval with large language models. In 2024 IEEE 14th International Symposium on Chinese Spoken Language Processing (ISCSLP), pages 631 635. IEEE. Marti Hearst. 1991. Noun homograph disambiguation using local context in large text corpora. Using Corpora, pages 185188. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, and 1 others. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Maria Karamihaylova. 2023. Neural network vs. rulebased g2p: hybrid approach to stress prediction and related vowel reduction in bulgarian. Özgün Kosaner, Çagdas Can Birant, and Özlem Aktas. 2013. Improving turkish language training materials: Grapheme-to-phoneme conversion for adding phonemic transcription into dictionary entries and course books. Procedia-Social and Behavioral Sciences, 103:473484. Mohamadreza Mahmoodvand and Maryam Hourali. 2015. Persian word sense disambiguation corpus extraction based on web crawler method. Advances in Computer Science: an International Journal, 4(5):101106. Mohamadreza Mahmoodvand and Maryam Hourali. 2017. Semi-supervised approach for persian word sense disambiguation. In 2017 7th International Conference on Computer and Knowledge Engineering (ICCKE), pages 104110. IEEE. Ali Moghadaszadeh, Fatemeh Pasban, Mohsen Mahmoudzadeh, Maryam Vatanparast, and Amirmohammad Salehoof. 2024. Avashog2p: multi-module g2p converter for persian. In 2024 14th International Conference on Computer and Knowledge Engineering (ICCKE), pages 343348. IEEE. David R. Mortensen, Siddharth Dalmia, and Patrick Littell. 2018. Epitran: Precision G2P for many languages. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). Matilde Nanni. 2023. Disambiguating italian homographic heterophones with soundchoice and testing chatgpt as data-generating tool. Marco Nicolis and Viacheslav Klimkov. 2021. Homograph disambiguation with contextual word embeddings for tts systems. NV Access Limited and 2023. in eSpeak add-on for nvda. contributors. Speech Player https://addons.nvda-project.org/addons/ speechPlayerInEspeak.en.html. 2025-04-29. Accessed: Demetry Pascal. 2020. Simple persian (farsi) graphemehttps://github.com/ to-phoneme converter. PasaOpasen/PersianG2P. Accessed: 2025-04-22. Artem Ploujnikov. 2024. Towards unified model for speech and language processing. Mahta Fetrat Qharabagh, Zahra Dehghanian, and Hamid Rabiee. 2025a. Llm-powered graphemeto-phoneme conversion: Benchmark and case study. In ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 15. IEEE. Mahta Fetrat Qharabagh, Zahra Dehghanian, and Hamid Rabiee. 2025b. Manatts persian: recipe for creating tts datasets for lower-resource languages. In Proceedings of the 2025 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Mexico City, Mexico. Azam Rabiee. 2019. Persian g2p. https://github. com/AzamRabiee/Persian_G2P. Accessed: 202409-05. Elnaz Rahmati and Hossein Sameti. 2024. Ge2pe: Persian end-to-end grapheme-to-phoneme conversion. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 34263436. Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. 2020. Fastspeech 2: Fast and high-quality end-to-end text to speech. In International Conference on Learning Representations. Markéta ˇRezáˇcková, Daniel Tihelka, and Jindˇrich Matoušek. 2024a. Homograph disambiguation with textIn Proc. Interspeech to-text transfer transformer. 2024, pages 27852789. 10 Markéta ˇRezáˇcková, Daniel Tihelka, and Jindˇrich Matoušek. 2024b. T5g2p: Text-to-text transfer transformer based grapheme-to-phoneme conversion. IEEE/ACM Transactions on Audio, Speech, and Language Processing. methods into five categories: rule-based, neural, hybrid, LLM-based, and other approaches. This organization reflects both the chronological evolution and methodological diversity of the field. Mahdi Rezaei, Negar Nayeri, Saeed Farzi, and Hossein Sameti. 2022. Multi-module g2p converter for persian focusing on relations between words. arXiv preprint arXiv:2208.01371. Noushin Riahi and Fatemeh Sedghi. 2012. semisupervised method for persian homograph disambiguation. In 20th Iranian Conference on Electrical Engineering (ICEE2012), pages 748751. IEEE. Jennifer Seale. 2021. Label imputation for homograph disambiguation: theoretical and practical approaches. Ph.D. thesis, City University of New York. Denilson Silva, Daniela Braga, and Fernando Gil Resende Jr. 2012. rule-based method for homograph disambiguation in brazilian portuguese textto-speech systems. Journal of Communication and Information Systems, 27(1). Ashima Suvarna, Harshita Khandelwal, and Nanyun Peng. 2024. Phonologybench: Evaluating phonological skills of large language models. In Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024), pages 114. Virongrong Tesprasit, Paisarn Charoenpornsawat, and Virach Sornlertlamvanich. 2003. context-sensitive homograph disambiguation in thai text-to-speech synthesis. In Companion Volume of the Proceedings of HLT-NAACL 2003-Short Papers, pages 103105. David Yarowsky. 1997. Homograph disambiguation in text-to-speech synthesis. In Progress in speech synthesis, pages 157172. Springer. Zhu, Zhang, and Jurgens. 2022. Byt5 model for massively multilingual grapheme-to-phoneme conversion. Interspeech 2022."
        },
        {
            "title": "A Extended Related Work Review",
            "content": "This appendix provides more detailed review of prior work on homograph disambiguation. We organize the discussion into two parts: first, we survey general approaches used across languages, including rule-based, statistical, neural, and hybrid methods. Then, we turn our focus to Persianspecific efforts, particularly those that involve the creation or use of datasets aimed at addressing the scarcity of resources for homograph disambiguation in low-resource settings. A.1 Homograph Disambiguation Approaches This subsection reviews the main approaches proposed for homograph disambiguation across languages. To provide clear structure, we divide the A.1.1 Rule-based Approaches Silva et al. (2012) proposed rule-based algorithm set as their core method for homograph disambiguation in Brazilian Portuguese text-to-speech systems. Their approach utilizes linguistic rules based on morphosyntactic and semantic analysis, employing information from the surrounding context, including part-of-speech, morphology, lemmas, and semantic relations from Wordnets, along with restrict lexical combinations. The authors tested their algorithms on existing text databases, namely newspaper corpus (CETENFolha), the Holy Bible in BP, and Brazilian literature. Yarowsky (1997) developed corpus-driven approach for English homograph disambiguation, utilizing 400-million-word multi-domain dataset that included news articles, scientific texts, and literary works. Their method employed statistical decision lists that ranked contextual patterns (including adjacent words and part-of-speech tags) by their log-likelihood ratios to determine correct pronunciations, effectively addressing seven major categories of homographs through data-driven rules rather than neural networks. The work demonstrated how large-scale, diverse training data could be leveraged to resolve lexical ambiguities with high accuracy. Hearst (1991) proposed method for noun homograph disambiguation in English using large unrestricted text corpus, the Academic American Encyclopedia, which contains approximately 8.6 million words. To address the lack of sense-annotated data, the author manually labeled small set of training instances for each homographtesting the method on five English nouns (e.g., bank, tank, bass)and further improved performance through an unsupervised learning phase that incorporated highconfidence predictions without additional manual effort. The core method, called CatchWord, is rulebased and relies on shallow contextual cues such as syntactic patterns, orthographic features (e.g., capitalization), and lexical co-occurrence information extracted from local context windows. This approach avoids deep semantic resources or inference and demonstrates that coarse-grained disambiguation can be effectively achieved using lightweight, corpus-driven statistical techniques. 11 A.1.2 Neural Approaches Nicolis and Klimkov (2021) proposed homograph disambiguation system for American English text-to-speech (TTS) applications, focusing primarily on neural methods rather than rule-based ones. They used publicly available dataset comprising 138 homograph words, each with around 90 training and 10 test sentences, and addressed data imbalance by manually augmenting the training set for underrepresented homograph variants using an internal fiction-based corpus. This augmentation, which added about 10 examples per weak variant, led to relative accuracy improvement of over 11%, demonstrating the effectiveness of targeted data enrichment. Their method relies on contextual word embeddings (CWEs) extracted from pretrained BERT and ALBERT models, which are then fed into lightweight logistic regression classifiers trained separately for each homograph. This fully ML-based approach achieves state-of-the-art performance without the need for hand-crafted rules. Seale (2021) addressed the challenge of lowresource data in homograph disambiguation by exploring label imputation techniques. To mitigate this, the author generated four homograph disambiguation datasets and made them available for the research community. The author also used the Wikipedia Homograph Data (WHD) released by Gorman et al. (2018) to conduct the research. Their core method involved employing regularized, multinomial logistic regression and fine-tuning pretrained ALBERT, BERT, and XLNet language models as token classifiers to improve model performance, particularly in classes with low prevalence samples. Ploujnikov (2024) proposed SoundChoice, sentence-level Grapheme-to-Phoneme (G2P) model aimed at improving homograph disambiguation in English. To address the challenge of contextaware phoneme prediction, they constructed the LibriG2P dataset, which integrates lexicon-based word pronunciations from CMUDict, phoneme alignments from LibriSpeech, and Wikipedia homograph data. This dataset includes approximately 10259 homograph-labeled samples, addressing inconsistencies between lexicon-based and audio-derived phoneme annotations. Their model employs hybrid neural architecture, leveraging LSTMs, GRUs, and content-based attention, alongside CTC loss and curriculum learningprogressing from individual word training to sentence-level fine-tuning for enhanced contextual phoneme prediction. Additionally, BERT word embeddings are incorporated to inject semantic knowledge for better homograph resolution, achieving phoneme error rate (PER) of 2.65% and 94% homograph classification accuracy. This work contributes to dataset development and model innovations in grapheme-to-phoneme conversion. ˇRezáˇcková et al. (2024b), ˇRezáˇcková et al. (2024a) introduced grapheme-to-phoneme (G2P) conversion approach using Text-to-Text Transfer Transformer (T5) model. To capture crossword context and assimilation effects, their models for English and Czech were trained on proprietary datasets of several hundred thousand sentences provided by language experts, mitigating the need for explicit rule-based post-processing. The T5-based model achieved high conversion accuracy across the tested languages. Comini et al. (2025) present neural-based lightweight front-end for on-device TTS in English, Polish, and Russian, using internal pronunciation dictionaries and the Kaggle text normalization dataset to address data limitations. Their dataset includes 53.1k, 42.4k, and 31.9k words for G2P and 6.4k, 6.5k, and 11.2k tokens for TN. They employ transformer-based and GRU-based models, leveraging knowledge distillation from pre-trained teacher models to train compact student models, optimizing for low latency and scalability in low-resource scenarios. Gao (2024) tackle speech processing for lowresource languages using neural methods, particularly self-supervised learning (SSL) with models like wav2vec2 and HuBERT. They use existing speech datasets (e.g., LibriSpeech, VoxPopuli, CommonVoice) and enhance SSL pretraining with synthetic speech generated by diffusion models to address data scarcity. Their approach improves multilingual and zero-shot phonetic recognition without requiring labeled data. Nanni (2023) investigated homographic heterophone disambiguation in Italian Text-To-Speech (TTS) systems using the SoundChoice model, which includes an RNN (LSTM + GRU) and transformer version. Given the scarcity of Italian homograph datasets, the study generated 9,916 sentences with ChatGPT, supplementing 1,700sentence corpus dataset. The ChatGPT-generated data was created through iterative prompting, where sentences were crafted to include homo12 graphs in varying syntactic contexts. These sentences were manually validated for linguistic accuracy and context relevance before phonetic transcription using ReadSpeaker transcription tool, which had 59.56% accuracy in homograph resolution. The model integrates semantic disambiguation via BERT embeddings and weighted homograph loss, enabling sentence-level pronunciation prediction. Evaluation showed the transformer model outperformed the RNN, highlighting the feasibility of neural methods for Italian homograph disambiguation. A.1.3 Hybrid Approaches Gorman et al. (2018) addressed homograph disambiguation for English TTS by creating labeled dataset of 163 homographs (including morphosyntactic, lexical, and mixed types), with 100 sentences per homograph sampled from Wikipedia and annotated via crowdsourcing. To mitigate data scarcity, they employed rigorous adjudication for label disagreements and released the dataset publicly. Their hybrid system combined rulebased heuristics (e.g., context-triggered pronunciation rules, POS tags) with supervised ML (perhomograph maxent classifiers using word-context, POS, and capitalization features), showing that hybridization outperformed either approach alone. Karamihaylova (2023) developed hybrid grapheme-to-phoneme (G2P) system for Bulgarian, combining rule-based finite-state transducers (FSTs) for consonant mapping and vowel reduction rules with an LSTM-based seq2seq model for stress prediction. To address inconsistencies in publicly available data, they scraped and filtered 38,000 word-pronunciation pairs from Bulgarian Wiktionary using WikiPron, then standardized consonant transcriptions while preserving vowel variations to study stress-induced reduction. The dataset included homographs, where stress position disambiguates meaning. Their hybrid approach achieved performance comparable to pure neural methods, demonstrating the viability of curated rule-neural integration for medium-resource languages. A.1.4 LLM-based Approaches Suvarna et al. (2024) introduced PhonologyBench, evaluating Large Language Models (LLMs) on English phonological tasks, including homographs. Their dataset includes 3,000 words for graphemeto-phoneme conversion, sourced from SIGMORPHON 2021, ensuring phonemic transcriptions. They tested GPT-4, Claude-3-Sonnet, and LLaMA2-13B, using zero-shot neural approach, showing that LLMs struggle with homograph pronunciation. Their findings highlight the need for phonologyaware datasets to improve text-based pronunciation models. Han et al. (2024) explored the use of Large Language Models (LLMs) for grapheme-to-phoneme conversion, focusing on leveraging the in-context knowledge retrieval capabilities of GPT-4 to disambiguate homographs. To facilitate this, the authors constructed dictionary by combining the Librig2p training dataset and the CMU dictionary. For homograph words, they used GPT-4 to generate cases automatically. Each homograph contains multiple cases and was later manually refined. The core of their method involves prompting GPT-4 to analyze the input sentence, identify the most relevant meaning and part-of-speech for the target word, and then retrieve the corresponding phoneme pronunciation from the constructed dictionary. Qharabagh et al. (2025a) In previous study, we proposed an LLM-powered approach to Graphemeto-Phoneme (G2P) conversion in Persian, addressing challenges posed by polyphone words and context-sensitive phonemes. To improve phonetic accuracy and benchmark sentence-level G2P performance, we introduced two datasets: KaamelDict, unified phonetic dictionary with 120,000+ entries, and Sentence-Bench, sentence-level dataset containing 400 annotated sentences, including 100 polyphone words used in various contexts. Our method leverages large language models (LLMs) without additional training, applying advanced prompting and post-processing techniques to enhance phonetic predictions. Our benchmarking results demonstrate that LLMs can outperform traditional models, highlighting the potential of LLMs in low-resource G2P tasks. A.1.5 Other Approaches Tesprasit et al. (2003) addressed the challenges posed by word boundary and homograph ambiguity in Thai Text-to-Speech, noting the absence of word delimiters in the language. To conduct their research, they created their own 25K-word corpus where sentences were manually segmented, and part-of-speech tags and pronunciations were manually annotated by linguists. Their core method is unified machine learning framework based on the Winnow algorithm, statistical technique that learns to combine local and long-distance contex13 tual features like context words and collocations to disambiguate word pronunciations without relying on predefined rules or standard neural network architectures. Alqahtani et al. (2019) addressed homograph disambiguation in Arabic by proposing unsupervised, data-driven methods to selectively restore diacritics, balancing lexical disambiguation and sparsity. They leveraged existing corpora ( 50M tokens, including Gigaword and Arabic Treebank) without new data collection, using the MADAMIRA tool for automated diacritization and morphological analysis. Their approach identified 33.8% of words as homographs (e.g., 168K ambiguous types) by clustering diacritized variants (Brown, K-means) and analyzing translation divergences in parallel text. Unlike rule-based or neural methods, their work focused on distributional similarity and morphological variants to guide selective diacritization, demonstrating improved performance in downstream tasks like machine translation and POS tagging. Hajj et al. (2022) addressed the challenge of disambiguating French heterophonic homographs for TTS systems by creating custom dataset. They collected 8137 sentences from the web, ensuring balanced representation of 34 pairs of prototypical homographs, with roughly one hundred instances per pair. To enhance disambiguation, they employed Linear Discriminant Analysis (LDA) classifiers, utilizing contextual word embeddings as input features, and experimented with the FlauBERT transformer for POS tagging. A.2 Persian Homograph Disambiguation and Dataset Development Several recent works have introduced or curated datasets specifically for Persian homograph disambiguation and word sense disambiguation (WSD). Notably, Moghadaszadeh et al. (2024) presented dataset collected through cluster-based sampling strategy to mitigate phoneme imbalance. Another valuable dataset is by Ghayoomi (2019), who developed manually annotated gold standard for 20 Persian ambiguous words, each with 100 sentences, totaling 2000 sentences. These sentences were extracted from the Persian Language Database and annotated according to SemEval2010 guidelines. Similarly, Rahmati and Sameti (2024) generated over 5 million sentence-phoneme pairs, including manually and automatically labeled data which was valuable source for general G2P task not homo14 graph challenge. Other works focused on smaller, curated datasets. Ayyoubzadeh and Shahnazari (2024) created dataset containing 63 homograph words, with sentence-level phonetic annotations developed through careful selection. Mahmoodvand and Hourali (2017) extracted 5368 documents/sentences using web crawler for three Persian homographs (\"Shir\", \"Rast\", \"Tar\") from Iranian news agency websites, partially labeled (2133 documents). Riahi and Sedghi (2012) used the Hamshahri corpus and manually tagged instances of two homographs, with training sizes ranging from 10 to 1500 words for their tri-training framework. Additionally, Nanni (2023) created an Italian homograph dataset, including 9,916 ChatGPTgenerated sentences supplemented with 1,700 corpus examples. The following paragraphs provide more detailed examination of each study. Riahi and Sedghi (2012) addressed the challenge of limited manually tagged data for Persian Word Sense Disambiguation (WSD) by proposing semisupervised method. To conduct their experiments, they utilized the raw Hamshahri corpus and created their own tagged data by manually annotating instances of two Persian homographs. Their core method employs statistical approach based on tri-training with decision lists. The decision lists classify homographs by analyzing the distribution of collocations (surrounding words), and the tritraining framework iteratively leverages small tagged corpus and larger untagged corpus to improve disambiguation accuracy. Moghadaszadeh et al. introduced AvashoG2P, multi-module system for Persian grapheme-to-phoneme (G2P) conversion that primarily employs neural network-based approaches. For out-of-vocabulary word prediction, their core method utilizes sequence-to-sequence model with GRU-based recurrent unit and an attention mechanism. Addressing the lack of labeled data for homograph disambiguation in Persian, the authors collected and labeled their own homograph data. To mitigate the challenge of data imbalance in their collected homograph data, they first clustered the data for each homograph before labeling selection of samples from each cluster. Their homograph disambiguation module leverages classification approach that uses single model for all 54 supported Persian homographs, with experiments highlighting the superior performance of transformer-based (2024) models like XLMRoberta. Ghayoomi (2019) proposed an unsupervised neural method for Persian word sense induction using word embeddings and hierarchical clustering. They trained embeddings on combined corpus ( 529M words) and evaluated on manually annotated dataset of 20 ambiguous words (100 sentences each). Their approach leveraged context windows (8 surrounding words) and sentence-level embeddings, clustering them without predefined rules. Ayyoubzadeh and Shahnazari (2024) introduced novel dataset for Persian homograph disambiguation, addressing the challenges posed by words with identical spellings but different meanings in Persian[1]. Their dataset includes diverse sentences containing homographs, which are carefully annotated to facilitate detailed analysis and model training. The authors trained both lightweight machine learning and deep learning models, leveraging embeddings and cosine similarity to disambiguate homographs and evaluated model performance using accuracy, recall, and F1 score. Mahmoodvand and Hourali (2017) addressed the challenge of limited labeled data for Persian word sense disambiguation by implementing semisupervised machine learning approach. They created their own corpus by developing crawler to extract sentences containing target ambiguous words from news agency websites, building dataset specifically designed for WSD tasks. Their method leverages small set of labeled seed data combined with larger volume of unlabeled data in collaborative learning framework, focusing on defined features of target words to disambiguate their meanings. The researchers evaluated their approach on three Persian homograph words (\"Shir,\" \"Rast,\" and \"Tar\"), achieving impressive results with 88% recall, 95% precision, and 93% accuracy across 5,368 documents, demonstrating the effectiveness of their semi-supervised approach for Persian language processing despite the inherent challenges of Persians rich metaphorical nature and complex writing style. Mahmoodvand and Hourali (2015) presented method for building Persian word sense disambiguation (WSD) dataset by employing web crawler to gather documents containing specific ambiguous words. Addressing the lack of suitable WSD corpora for Persian, their approach focuses on extracting relevant phrases for ambiguous words from web data to create dataset that can be used in WSD tasks. The authors used three prevalent Persian ambiguous words to extract appropriate phrases. This research provides foundation for supervised WSD methods in Persian by offering means to generate training data where it was previously scarce. Rahmati and Sameti (2024) proposed GE2PE, Persian end-to-end grapheme-to-phoneme conversion model that addresses the challenges of Persian homographs and missing short vowels by leveraging sentence-level context. To support this, they created two large datasets comprising over five million sentences with corresponding phoneme sequences, including both manually labeled and machine-generated data, and designed evaluation sets specifically for tasks like Kasre-Ezafe detection and homograph disambiguation. Their core approach is T5 model trained in two-step process, building on advances in transformer architectures shown to be effective for G2P tasks. This work stands out for its extensive data creation tailored to Persian linguistic challenges and its end-to-end neural modeling strategy. Rezaei et al. (2022) proposed multi-module G2P system for Persian that addresses the challenges of homographs, OOV words, and ezafe constructions. To handle homographs, they extracted homograph dictionary from the Ariana lexicon. Their core method involves combination of GRU and Transformer architectures within separate modules to handle different aspects of G2P conversion. The system operates at the sequence level, capturing cross-word relations crucial for homograph disambiguation and ezafe recognition. Alayiaboozar et al. (2019) proposed rule-based approach for disambiguating Persian noun and adjective homographs ending in (/i/), leveraging context-sensitive syntactic rules (e.g., preposition + quantifier patterns) derived from three existing corpora: the Peykare corpus, Farsi Linguistic Database, and Persian Dependency Treebank. They extracted 36 rules based on 10-word contextual windows, achieving high accuracy (e.g., 94% for some rules), but did not create new labeled data. Their method focused on morphological and syntactic patterns (e.g., adjacent POS tags) to resolve ambiguity in language with prevalent homography due to orthographic constraints."
        },
        {
            "title": "B Phoneme Representaion Mapping",
            "content": "There are two common representations for Persian phonemics. The first representation is the one used 15 in many of the G2P glossaries, including KaamelDict (Fetrat, 2024a; tih, 2019; IPA, 2022; wik, 2002; zay, 2004; jam, 2017; Ajini, 2022; Pascal, 2020; Rabiee, 2019; Zhu et al., 2022) and benchmarks like SentenceBench (Fetrat, 2024b). The second representation is used in one of the stateof-the-art G2P models for Persian, namely GE2PE, which is fine-tuned and enhanced in this work. Our HomoRich dataset includes the sentence phoneme sequences in both of these formats for compatibility. Figure 10 shows these two representations. key challenge in mapping the Ezafe phoneme between these representations was its inconsistent annotation. The Ezafe is short vowel /e/ used to indicate possession, relation, or description in Persian noun phrases. For instance, in the sentences \"This is Zibas flower\" (/in gol-e zibA ast/) and \"This flower is beautiful\" (/in gol zibA ast/), the Ezafe appears as linking /e/ sound, but its presence or absence can alter the meaning of the sentence. In the GE2PE representation, the Ezafe is denoted by an additional 1 symbol after the /e/ phoneme, while in our dataset, the /e/ phoneme alone may indicate either regular vowel or an Ezafe. To resolve this ambiguity, we employed POS tagger (Group, 2023) with 99.249% accuracy to identify Ezafe constructions based on the grapheme sequence. For each Ezafe occurrence, we retrieved its phonemic form from the KaamelDict (Fetrat, 2024a) glossary and searched for the corresponding /e/ phoneme in the phoneme sequence. 1 symbol was then appended to the /e/ to maintain consistency with the GE2PE representation."
        },
        {
            "title": "C Additional Figures",
            "content": "Dataset Sentence Length Distribution welldesigned dataset for G2P model should include sentences of varying lengths to ensure the model can accurately transcribe both short and long utterances. Sentence length is also an indicator of linguistic diversity and complexity. Figure 11 illustrates the distribution of sentence lengths in the Homorich dataset. Learning Curves for T5 Training Figure 12 shows the training dynamics across all phases when fine-tuning T5, with identical hyperparameters as described in Section 3.2.1."
        },
        {
            "title": "Results",
            "content": "To provide comprehensive view of the variability in the reported metrics, we present error bar plots for the Phoneme Error Rate (PER), Homograph Accuracy, and Inference Time across the evaluated G2P tools and proposed models. Figures 13, 14, and 15 illustrate these metrics, with error bars representing standard deviations across five runs. The inference time plot is rendered on logarithmic scale to highlight differences across models with varying computational requirements."
        },
        {
            "title": "E Details of Human Subject Participation",
            "content": "in Data Collection As part of this study, we engaged approximately 200 human participants to contribute to the humangenerated portion of our homograph sentence corpus. Specifically, we curated list of 285 Persian homograph words, each with multiple valid pronunciations. These were organized into several Google Sheets, where each sheet listed subset of homograph words along with their pronunciations, followed by five empty rows designated for sentence creation for each alternative. Each homograph word appeared in multiple sheets to ensure that it was annotated by different individuals, and each participant received subset of wordsthus distributing the workload and encouraging diversity in linguistic expression. The instructions, originally provided in Persian, asked participants to compose Persian sentences that naturally incorporate the target homograph with the specified pronunciation. translated excerpt of the instruction reads: \"Please write five different Persian sentences using the given word with the pronunciation indicated below it. Try to make the sentences as natural and diverse as possible. Avoid repeating sentence structures or vocabulary.\" Participants were explicitly encouraged to avoid sentence repetition, maintain lexical diversity, and write fluent, meaningful examples. Each participant completed multiple such entries, and collectively, this process yielded total of 69,560 high-quality, human-written sentences. The sentences form valuable component of our dataset for disambiguating homograph pronunciation in context. 16 (a) Repr. 1 (used in this work and related studies) (b) Repr 2 (used in other prior literature) Figure 10: Comparison of two commonly used phoneme representations for Persian sounds."
        },
        {
            "title": "F Broader Impact",
            "content": "The ultimate goal of our work is to improve the quality of fast, rule-based G2P modelsand neural G2P systems in generalso they can be effectively integrated into low-latency text-to-speech (TTS) pipelines, particularly for screen readers and other real-time accessibility tools. By enhancing homograph disambiguation and overall phonetic accuracy, we enable more natural and reliable speech synthesis, which is critical for users who rely on assistive technologies. key practical outcome of our research is the development of HomoFast eSpeak, an enhanced version of the widely used open-source eSpeak NG speech synthesizer. Our experiments show that HomoFast eSpeak achieves 30.66% improvement in homograph disambiguation accuracy while maintaining the low-latency performance critical for real-time applications. This advancement has the potential to elevate the intelligibility and naturalness of synthesized speech in screen readers used by the blind community in Iran. Beyond immediate applications, we hope this work encourages further development of open, high-quality, and performant TTS systems for lowresource languages. By releasing our dataset (HomoRich), models (Homo-GE2PE), and enhancements to eSpeak under permissive licenses, we lower barriers for researchers and developers working on accessibility-focused speech technologies. Our contributions demonstrate that even simple, data-informed statistical methods can significantly improve rule-based systemsmaking high-quality G2P more scalable and sustainable for languages with limited resources."
        },
        {
            "title": "G Disclosure of LLM usage",
            "content": "We used large language models (LLMs) for language refinement, including grammar correction, paragraph rephrasing, and other minor edits, based on drafts written by the authors. In the related work section, LLMs assisted in summarizing prior works after the authors had identified, read summaries of, and grouped the relevant literature; this use was 17 Figure 11: Distribution of sentence word counts. (a) Phase 1 (5 epochs) (b) Phase 2 (20 epochs) (c) Phase 3 (50 epochs) Figure 12: Learning curves across fine-tuning phases of T5. limited to generating low-novelty text describing pre-existing methods and data. The generated text was subsequently reviewed for accuracy. Additionally, LLMs were used for fine-grained coding tasks such as generating individual functions or single-purpose scripts, which were then validated and integrated by the authors."
        },
        {
            "title": "H Data Sheet",
            "content": "In the rest of this document, we present the datasheet for the HomoRich dataset, adhering to the guidelines outlined by Gebru et al. (2021). H.1 Motivation The questions in this section are primarily intended to encourage dataset creators to clearly articulate their reasons for creating the dataset and to promote transparency about funding interests. The latter may be particularly relevant for datasets created for research purposes. focus on homograph disambiguation in Persian. These resources aim to support the development of open text-to-speech (TTS) and screen reader tools, enhancing accessibility for Persian-speaking communities, including individuals with visual impairments. Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)? ANS: The dataset was created by the speech processing team of the Data Science and Machine Learning (DML) Laboratory at Sharif University of Technology. Who funded the creation of the dataset? If there is an associated grant, please provide the name of the grantor and the grant name and number. ANS: The dataset creation received no external funding and is provided free of charge. For what purpose was the dataset created? Was there specific task in mind? Was there specific gap that needed to be filled? Please provide description. Any other comments? ANS: No. H.2 Composition ANS: The dataset was created to address the scarcity of open-source datasets and models for grapheme-to-phoneme (G2P) conversion, with Most of the questions in this section are intended to provide dataset consumers with the information they need to make informed decisions about using 18 Figure 13: Phoneme Error Rate (PER) of previous and proposed G2P tools/models with error bars indicating standard deviations across five runs. the dataset for their chosen tasks. Some of the questions are designed to elicit information about compliance with the EUs General Data Protection Regulation (GDPR) or comparable regulations in other jurisdictions. What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)? Are there multiple types of instances (e.g., movies, users, and ratings; people and interactions between them; nodes and edges)? Please provide description. ANS: The dataset consists of Persian sentences (text) paired with their corresponding phoneme sequences in two formats (text). subset of the dataset includes carefully curated Persian sentences containing homograph words, where each homograph and its pronunciation are explicitly annotated (text). All samples include metadata indicating their source (human, GPT-4o, CommonVoice, ManaTTS, or GPTInformal) and unique identifier within each source category. How many instances are there in total (of each type, if appropriate)? ANS: The dataset contains 528,891 Persian sentences in total, with 327,475 specifically curated for homograph disambiguation. Does the dataset contain all possible instances or is it sample (not necessarily random) of instances from larger set? If the dataset is sample, then what is the larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If so, please describe how this representativeness was validated/verified. If it is not representative of the larger set, please describe why not (e.g., to cover more diverse range of instances, because instances were withheld or unavailable). ANS: The dataset incorporates: (1) complete samples from ManaTTS and GPTInformal (covering all available data at study time), and (2) non-random subset of CommonVoice selected by availability (prioritizing validated samples while respecting original data ordering). GPT-4o generations and human annotations were collected specifically for this study. What data does each instance consist of? Raw data (e.g., unprocessed text or images) or features? In either case, please provide description. ANS: Each instance contains processed Persian text along with its corresponding phoneme sequence represented in two formats: primary phonemic transcription and an alternative standardized representation mapped for compatibility. For instances containing homographs, the data addi19 Figure 14: Homograph Accuracy of previous and proposed G2P tools/models with error bars indicating standard deviations across five runs. tionally includes the identified homograph word and its correct pronunciation in both representation formats. Is there label or target associated with each instance? If so, please provide description. ANS: Yes, each instance serves multiple labeling purposes. The complete phoneme sequence of the sentence acts as the primary label. For homographcontaining instances, additional labels include the specific homograph word and its contextually correct pronunciation, enabling the dataset to support both general grapheme-to-phoneme conversion and specialized homograph disambiguation tasks. Is any information missing from individual instances? If so, please provide description, explaining why this information is missing (e.g., because it was unavailable). This does not include intentionally removed information, but might include, e.g., redacted text. ANS: Due to our semi-automated data creation pipeline, sentences containing multiple homograph words only have the target homograph (the focus of that particular instance) annotated. Are relationships between individual instances made explicit (e.g., users movie ratings, social network links)? relationships are made explicit. If so, please describe how these ANS: No. Are there recommended data splits (e.g., training, development/validation, testing)? If so, please provide description of these splits, explaining the rationale behind them. ANS: The dataset does not come with predefined splits. We recommend using the entire dataset for training while evaluating performance on the dedicated SentenceBench test set, following the methodology established in our work. This approach ensures consistent benchmarking across studies. Are there any errors, sources of noise, or redundancies in the dataset? If so, please provide description. ANS: As detailed in the data creation process, some sentences were generated by GPT-4o with prompts targeting specific homograph pronunciations. While we implemented techniques to prevent these issues, the approach carries inherent limitations including potential hallucinated sentences and occasional incorrect homograph usage. Additionally, phonemization was performed using the LLMbased method from prior work, which achieves 20 Figure 15: Inference Time (s) of previous and proposed G2P tools/models plotted on logarithmic scale with error bars indicating standard deviations across five runs. phoneme error rate of 6.43% and homograph accuracy of 64%, representing another source of potential noise in the phonetic transcriptions. Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)? If it links to or relies on external resources, a) are there guarantees that they will exist, and remain constant, over time; b) are there official archival versions of the complete dataset (i.e., including the external resources as they existed at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees) associated with any of the external resources that might apply to dataset consumer? Please provide descriptions of all external resources and any restrictions associated with them, as well as links or other access points, as appropriate. ANS: The dataset is self-contained and doesnt rely on external resources. Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctorpatient confidentiality, data that includes the content of individuals non-public communications)? If so, please provide description. three sources: (1) established public datasets (CommonVoice, ManaTTS, and GPTInformal), (2) GPT4o generated content, and (3) contributions from voluntary human participants who provided nonsensitive example sentences. Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? If so, please describe why. ANS: The dataset is derived from well-known public datasets, the safeguarded GPT-4o model, and voluntary human subjects in an academic environment who were specifically asked to generate example sentences. Given these controlled sources and collection methods, we believe it is unlikely to contain offensive or harmful content. However, as with any language dataset, we recommend users review the content for their specific application needs. Does the dataset identify any subpopulations (e.g., by age, gender)? If so, please describe how these subpopulations are identified and provide description of their respective distributions within the dataset. ANS: The dataset contains no confidential or personal information. All data originates from ANS: The dataset does not identify any subpopulations. 21 Is it possible to identify individuals (i.e., one or more natural persons), either directly or indirectly (i.e., in combination with other data) from the dataset? If so, please describe how. ANS: We believe identification is not possible, as the data consists of voluntarily provided sample sentences generated for specific words. Does the dataset contain data that might be considered sensitive in any way (e.g., data that reveals race or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)? If so, please provide description. ANS: The dataset consists of linguistic examples derived from established public datasets, the safeguarded GPT-4o model, and voluntary contributions from participants in an academic setting. Given these controlled sources and collection methods focused solely on language patterns, we believe it is unlikely to contain sensitive information. However, as with any textual dataset, we recommend users assess the content for their specific requirements. Any other comments? ANS: No. H.3 Collection Process In addition to the goals outlined in the previous section, the questions in this section are designed to elicit information that may help researchers and practitioners to create alternative datasets with similar characteristics. How was the data associated with each instance acquired? Was the data directly observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or indirectly inferred/derived from other data (e.g., part-of-speech tags, modelbased guesses for age or language)? If the data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified? If so, please describe how. datasets (CommonVoice, ManaTTS, GPTInformal), (2) GPT-4o-generated sentences with targeted homograph usage (indirectly derived through prompting), and (3) human-authored sentences voluntarily contributed in an academic setting. No specific validation was performed on the LLMgenerated or human-provided data beyond the collection methods described in the paper. What mechanisms or procedures were used to collect the data (e.g., hardware apparatuses or sensors, manual human curation, software programs, software APIs)? How were these mechanisms or procedures validated? ANS: For the GPT-4o generated portion, data was collected through API calls using Python scripts. The human-authored content was gathered via online Google Sheets containing the target homograph words and detailed instructions, as documented in our methodology. No additional validation procedures were applied to these collection mechanisms. If the dataset is sample from larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)? ANS: The dataset incorporates: (1) complete samples from ManaTTS and GPTInformal (covering all available data at study time), and (2) non-random subset of CommonVoice selected by availability (prioritizing validated samples while respecting original data ordering). GPT-4o generations and human annotations were collected specifically for this study. Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)? ANS: The human-annotated portion of the dataset was collected through voluntary participation of native Persian speakers from diverse backgrounds. While we did not collect detailed demographic information about participants, their native language proficiency was the primary qualification for contribution. Participants were not financially compensated, as the data collection was conducted as part of an academic research initiative. ANS: The data combines three acquisition meth- (1) directly observable text from public ods: Over what timeframe was the data collected? Does this timeframe match the creation timeframe of the data associated with the instances (e.g., recent crawl of old news articles)? If not, please describe the timeframe in which the data associated with the instances was created. ANS: The dataset was compiled in 2024-2025, combining newly generated GPT-4o outputs and human annotations with existing public corpora. The ManaTTS, GPTInformal, and CommonVoice components originate from their 2024 releases. Were any ethical review processes conducted (e.g., by an institutional review board)? If so, please provide description of these review processes, including the outcomes, as well as link or other access point to any supporting documentation. ANS: No ethical review processes were conducted. Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (e.g., websites)? ANS: The data was obtained from the individuals directly. Were the individuals in question notified about the data collection? If so, please describe (or show with screenshots or other information) how notice was provided, and provide link or other access point to, or otherwise reproduce, the exact language of the notification itself. ANS: The data was not collected from preexisting source; instead, individuals were explicitly instructed to generate the data, eliminating the need for notification. Did the individuals in question consent to the collection and use of their data? If so, please describe (or show with screenshots or other information) how consent was requested and provided, and provide link or other access point to, or otherwise reproduce, the exact language to which the individuals consented. If consent was obtained, were the consenting individuals provided with mechanism to revoke their consent in the future or for certain uses? If so, please provide description, as well as link or other access point to the mechanism (if appropriate). ANS: As the data generation was based on direct instructions and not from pre-existing sources or personal information, the issue of consent revocation does not apply in this context. Has an analysis of the potential impact of the dataset and its use on data subjects (e.g., data protection impact analysis) been conducted? If so, please provide description of this analysis, including the outcomes, as well as link or other access point to any supporting documentation. ANS: No such analysis has been conducted. Any other comments? ANS: No. H.4 Preprocessing/cleaning/labeling The questions in this section are intended to provide dataset consumers with the information they need to determine whether the raw data has been processed in ways that are compatible with their chosen tasks. For example, text that has been converted into bag-of-words is not suitable for tasks involving word order. Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)? If so, please provide description. If not, you may skip the remaining questions in this section. ANS: Yes, the underlying text corpora sourced from previous datasets and generated through GPT4o or human annotators were phonemized as labels using the LLM prompting method outlined in prior study, as referenced in the paper. ANS: Similar to the previous response, since the data was generated based on explicit instructions provided to the individuals, consent was inherently obtained through participation, and no additional consent process was necessary. Was the raw data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)? If so, please provide link or other access point to the raw data. 23 ANS: Yes, the raw data includes the underlying text corpora from previous datasets (ManaTTS, GPTInformal, CommonVoice), as well as data generated using GPT-4o and contributions from human subjects. These data remain accessible and were only augmented with the phoneme labels as described earlier. Is the software that was used to preprocess/clean/label the data available? If so, please provide link or other access point. ANS: Yes, the complete code for data generation and labeling is publicly accessible at https://github.com/MahtaFetrat/HomoRich-G2PPersian. Any other comments? ANS: No. H.5 Uses The questions in this section are intended to encourage dataset creators to reflect on the tasks for which the dataset should and should not be used. By explicitly highlighting these tasks, dataset creators can help dataset consumers to make informed decisions, thereby avoiding potential risks or harms. Has the dataset been used for any tasks already? If so, please provide description. ANS: Yes, it has been employed to finetune two neural G2P models and enhance rule-based G2P tool in our research, which is used to evaluate data efficiency. Is there repository that links to any or all papers or systems that use the dataset? If so, please provide link or other access point. ANS: The dataset was not publicly available before this work, and as far as we know, it hasnt been utilized in any other projects. What (other) tasks could the dataset be used for? convey distinct meanings that require contextual clarification. Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? For example, is there anything that dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other risks or harms (e.g., legal risks, financial harms)? If so, please provide description. Is there anything dataset consumer could do to mitigate these risks or harms? ANS: We do not believe that the dataset carries such risks. Are there tasks for which the dataset should not be used? If so, please provide description. ANS: We do not foresee any specific limitations regarding potential uses of the dataset. Any other comments? ANS: No. H.6 Distribution Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created? If so, please provide description. ANS: Yes, the dataset is available to the public under CC-0 license. How will the dataset be distributed (e.g., tarball on website, API, GitHub)? Does the dataset have digital object identifier (DOI)? ANS: The dataset is distributed through the Hugging Face platform and will be assigned DOI upon finalization. When will the dataset be distributed? ANS: The dataset is publicly available at https://github.com/MahtaFetrat/HomoRich-G2PPersian. ANS: The dataset can be utilized for both general G2P conversion and specific homograph pronunciation disambiguation. Additionally, it could be valuable for tasks involving context understanding, such as word sense disambiguation. While not all sense disambiguations involve pronunciation differences, words with multiple pronunciations often Will the dataset be distributed under copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)? If so, please describe this license and/or ToU, and provide link or other access point to, or otherwise reproduce, any relevant licensing terms or ToU, as well as any fees associated with these restrictions. 24 ANS: The dataset is shared under the CC-0 license, allowing free use. Have any third parties imposed IP-based or other restrictions on the data associated with the instances? If so, please describe these restrictions, and provide link or other access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with these restrictions. ANS: No, there are no IP-based or other restrictions imposed on the data associated with the instances. Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? If so, please describe these restrictions, and provide link or other access point to, or otherwise reproduce, any supporting documentation. ANS: No, there are no export controls or other regulatory restrictions applicable to the dataset or individual instances. Any other comments? ANS: No. H.7 Maintenance The questions in this section are intended to encourage dataset creators to plan for dataset maintenance and communicate this plan to dataset consumers. Who will be supporting/hosting/maintaining the dataset? ANS: The dataset is stored in public data repositories and maintained by the authors for updates. How can the owner/curator/manager of the dataset be contacted (e.g., email address)? ANS: You can contact the authors via the following email addresses: Mahta Fetrat: m.fetrat@sharif.edu Zahra Dehghanian: zahra.dehghanian97@sharif.edu Hamid R. Rabiee: rabiee@sharif.edu Is there an erratum? or other access point. If so, please provide link ANS: There is currently no erratum. Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances)? If so, please describe how often, by whom, and how updates will be communicated to dataset consumers (e.g., mailing list, GitHub)? ANS: We intend to update the dataset if significant errors are identified or if valuable community contributions can be incorporated. However, we do not plan to establish formal mechanism for communicating changes. Updates can be tracked through the version history available on the hosting platforms (e.g., GitHub). If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (e.g., were the individuals in question told that their data would be retained for fixed period of time and then deleted)? If so, please describe these limits and explain how they will be enforced. ANS: There are no retention limits specified for the dataset. Will older versions of the dataset continue to be supported/hosted/maintained? If so, please describe how. If not, please describe how its obsolescence will be communicated to dataset consumers. ANS: No, older versions will not be maintained. We do not plan to implement specific mechanism to notify consumers of updates. Instead, changes can be observed through the version history available on the hosting platforms (e.g., GitHub). If others want to extend/augment/build on/contribute to the dataset, is there mechanism for them to do so? If so, please provide description. Will these contributions be validated/verified? If so, please describe how. If not, why not? Is there process for communicating/distributing these contributions to dataset consumers? If so, please provide description. ANS: Contributions are very welcome. Contributors can open issues or submit pull requests on GitHub, or contact the authors directly for error reports or improvements. Any other comments? ANS: No."
        }
    ],
    "affiliations": [
        "Dep. of Computer Engineering, Sharif University of Technology"
    ]
}