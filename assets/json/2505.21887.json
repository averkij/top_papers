{
    "paper_title": "SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem",
    "authors": [
        "Ahmed Heakl",
        "Yahia Salaheldin Shaaban",
        "Martin Takac",
        "Salem Lahlou",
        "Zangir Iklassov"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Robust routing under uncertainty is central to real-world logistics, yet most benchmarks assume static, idealized settings. We present SVRPBench, the first open benchmark to capture high-fidelity stochastic dynamics in vehicle routing at urban scale. Spanning more than 500 instances with up to 1000 customers, it simulates realistic delivery conditions: time-dependent congestion, log-normal delays, probabilistic accidents, and empirically grounded time windows for residential and commercial clients. Our pipeline generates diverse, constraint-rich scenarios, including multi-depot and multi-vehicle setups. Benchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade by over 20% under distributional shift, while classical and metaheuristic methods remain robust. To enable reproducible research, we release the dataset and evaluation suite. SVRPBench challenges the community to design solvers that generalize beyond synthetic assumptions and adapt to real-world uncertainty."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 2 ] . [ 1 7 8 8 1 2 . 5 0 5 2 : r SVRPBench: Realistic Benchmark for Stochastic"
        },
        {
            "title": "Vehicle Routing Problem",
            "content": "Ahmed Heakl1 Yahia Salaheldin Shaaban1 Martin Takáˇc1 Salem Lahlou1 Zangir Iklassov1 1MBZUAI, Abu Dhabi, UAE https://github.com/yehias21/vrp-benchmarks (cid:18) https://huggingface.co/datasets/MBZUAI/svrp-bench"
        },
        {
            "title": "Abstract",
            "content": "Robust routing under uncertainty is central to real-world logistics, yet most benchmarks assume static, idealized settings. We present SVRPBench, the first open benchmark to capture high-fidelity stochastic dynamics in vehicle routing at urban scale. Spanning more than 500 instances with up to 1000 customers, it simulates realistic delivery conditions: time-dependent congestion, log-normal delays, probabilistic accidents, and empirically grounded time windows for residential and commercial clients. Our pipeline generates diverse, constraint-rich scenarios, including multi-depot and multi-vehicle setups. Benchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade by over 20% under distributional shift, while classical and metaheuristic methods remain robust. To enable reproducible research, we release the dataset (Hugging Face) and evaluation suite (GitHub). SVRPBench challenges the community to design solvers that generalize beyond synthetic assumptions and adapt to real-world uncertainty."
        },
        {
            "title": "Introduction",
            "content": "Efficient vehicle routing is fundamental to modern logistics and last-mile delivery. The classical Vehicle Routing Problem (VRP) [8, 11] seeks cost-effective routes for servicing customers under constraints such as vehicle capacities and time windows. Although well studied, real-world deployments face uncertain and dynamic conditions that most existing benchmarks do not adequately capture. One key extension addressing real-world complexity is the Stochastic Vehicle Routing Problem (SVRP). Unlike deterministic VRP, SVRP explicitly incorporates uncertainty into routing decisions, with problem elements such as travel times, customer demands, service times, and even customer presence considered random variables [11, 22]. Consequently, routes are planned priori, and corrective actions, known as recourse strategies, are applied when realized conditions deviate from planned values [9, 2]. Prominent examples include random travel times modeled by probabilistic distributions or random customer presence known as probabilistic VRP (PVRP) [18, 5]. Despite this extensive body of research, many existing public benchmarks for SVRP still rely on static assumptions, such as deterministic travel times, fixed customer availability, and unchanged route constraints, thus limiting their practical applicability and robustness evaluations, as shown in Table 1. The Case for Realistic SVRP Benchmark. Urban logistics operates under dynamic and uncertain conditions, yet most existing benchmarks fail to reflect this complexity. Practical routing systems must Preprint. Table 1: Comparison of SVRPBench with existing VRP benchmarks. indicates full support, indicates partial or limited support, and indicates no support. Feature SVRPBench CVRPLIB SINTEF VRP-REP TSPLIB RL4CO Stochastic Elements Time-dependent travel delays Peak-hour traffic patterns Random travel time noise Probabilistic accidents Heterogeneous time windows Problem Configurations Multi-depot support Multi-vehicle fleets Capacity constraints Time window constraints Clustered customer distributions Scale & Diversity Small instances ( 100 customers) Medium instances (100-300) Large instances (>300) Varying stochasticity levels account for peak-hour congestion, random incidents like accidents, and diverse delivery preferences across customer types [14, 3, 24]. Ignoring these factors leads to overly optimistic performance assessments and misdirects algorithmic development toward unrealistic assumptions [1]. Our Contributions. To address these gaps, we introduce SVRPBench, novel, open-source benchmark suite for the Stochastic Vehicle Routing Problem (SVRP), designed to simulate realistic logistics scenarios with embedded uncertainty. Our key contributions include: Stochastic Realism. We model time-dependent congestion using Gaussian mixtures, inject lognormal delays and probabilistic accidents [18], and generate customer time windows from empirical residential and commercial distributions. Constraint-Rich Instance Generation. Our framework supports multi-depot and multi-vehicle setups, strict capacity constraints, and diverse time window widths, all grounded in spatially realistic demand distributions. Diverse Baseline Evaluation. We benchmark classical heuristics (e.g., Nearest Neighbor, 2-opt), metaheuristics (e.g., ACO, Tabu Search [12, 7]), industrial solvers (OR-Tools [26], LKH3 [31]), and learning-based methods (AM [15], POMO [17]), highlighting how stochastic conditions affect solution quality, feasibility, and robustness. Open Community Platform. We release datasets, solvers, and evaluation scripts through public repository to support reproducibility and foster future contributions. By advancing realism and accessibility in SVRP benchmarking, SVRPBench aims to accelerate the development of robust, deployable routing algorithms suited for real-world logistics."
        },
        {
            "title": "2 Realistic Stochastic Modeling",
            "content": "A core contribution of SVRPBench is its simulation of real-world uncertainty in urban-scale logistics. Classical VRP benchmarks often assume static travel times and rigid customer schedules [13], overlooking time-varying conditions and operational stochasticity. Informed by empirical and theoretical literature [3, 14, 1, 23, 25, 27, 19, 6, 10, 20], our benchmark introduces: (1) timedependent congestion, (2) stochastic travel time delays, (3) accident-induced disruptions, and (4) customer-specific time window distributions. 2.1 Time-Dependent Travel Time Modeling We model the travel time from node to at time as: (a, b, t) = D(a,b) + B(a, b, t) R(t) + Iaccidents(t) Daccident, (1) where D(a, b) is Euclidean distance and is average road speed. The congestion factor B(a, b, t) is defined as: with: B(a, b, t) = α Ftime(t) Fdistance(D(a, b)), Ftime(t) = β + γ [f (t; µmorning, σpeak) + (t; µevening, σpeak)] , (t; µ, σ) = 1 2π σ 2 ( tµ σ )2 1 , (2) (3) (4) Fdistance(D) = 1 eD/λdist, (5) where the Gaussian peaks around µmorning = 8 and µevening = 17 (σpeak = 1.5) align with observed urban traffic congestion patterns [27]. The distance decay λdist = 50 modulates slowdown severity, reflecting empirical findings that longer trips are more likely to encounter congestion [6]. The multiplicative stochastic delay R(t) is drawn from log-normal distribution: µ(t) = µbase + δ [f (t; µmorning, σpeak) + (t; µevening, σpeak)] , σ(t) = σbase + ϵ [f (t; µmorning, σpeak) + (t; µevening, σpeak)] , R(t) LogNormal(µ(t), σ(t)), (6) (7) (8) reflecting both the skewed and bursty nature of traffic delays [19, 6]. Baseline values µbase = 0 and σbase = 0.3 reflect free-flow conditions, while δ = 0.1 and ϵ = 0.2 capture peak-hour amplification. Accident delays are modeled using time-inhomogeneous Poisson process: λ(t) = λscale (t; µnight, σacc), (9) (10) (11) where accidents peak around µnight = 21 (σacc = 2) due to elevated nighttime risks from fatigue and impaired driving [28]. The delay duration is drawn from (0.5, 2.0) hours, consistent with industry reports on incident clearance times [28]. Iaccidents(t) Poisson(λ(t)), Daccident (dmin, dmax), 2.2 Customer Time Window Sampling Residential and commercial customers exhibit different temporal availability patterns [23, 20]. For residential profiles, delivery windows are sampled from bimodal Gaussian mixture: (cid:40) Tstart (µres,morning, σ2 (µres,evening, σ2 res,morning), w.p. 0.5, res,evening), w.p. 0.5, (12) where µres,morning = 480 (8:00 AM) and µres,evening = 1140 (7:00 PM), with variances σ = 90 and 120 mins, respectively, aligning with common parcel service offerings such as FedEx and Bring [10, 20]. The window duration is drawn from: Wlength (wmin, wmax), Tstart = max(0, min(Tstart, 1440 Wlength)). (13) Commercial customers follow single-mode Gaussian: with µcom = 780 (1:00 PM), σcom = 60, and wcom business hours and delivery norms [29]. Tstart (µcom, σ2 com), Wlength (wmin, wcom max), (14) max = 120 minutes, reflecting standard daytime This probabilistic windowing model encourages algorithms to balance varied service constraints, simulating realistic scheduling trade-offs in last-mile delivery systems."
        },
        {
            "title": "3 Dataset Construction Pipeline",
            "content": "To enable scalable and reproducible experimentation, we develop unified pipeline that generates diverse, constraint-rich SVRP instances grounded in stochastic realism. It integrates models of customer behavior, traffic patterns, spatial layouts, and routing constraints to produce problem scenarios suited for evaluating both classical and learning-based solvers under realistic uncertainty [22, 11]. The complete pipeline is illustrated in Figure 1. 3 Figure 1: SVRPBench pipeline. The framework generates realistic SVRP instances through four stages: input generation, stochastic modeling, instance assembly, and evaluation with standardized metrics and solvers. Location Sampling. We begin by selecting the from {10, 20, 100, 500, 1000}, then compute the number of cities as max(1, #customers//50). To simulate spatial separation between urban clusters, we apply K-Means clustering to generate city centers that are as distant from each other as possible. Customer locations are then sampled around each city center using 2D Gaussian distributions [14]. total number of customers Demand Assignment. Each customer is assigned discrete demand selected uniformly at random from set {1, 2, . . . , max_demand}. The number of vehicles and their capacity are computed based on the total customer demand, with vehicle capacity set as total demand number of vehicles. This ensures balanced feasibility across instance scales [9]. Time Window Assignment. Customer time windows are generated stochastically, following the models described in Section 2. Residential and commercial customer patterns are differentiated using realistic temporal distributions [3]. Travel Time Matrix Construction. full travel time matrix (a, b, t) is computed for all location pairs, incorporating deterministic base time, time-dependent congestion patterns, log-normal stochastic variation, and random accident delays, as detailed in Section 2. This captures the nonlinear, time-varying nature of urban transportation systems [18]. Constraint Integration. We support both single-depot and multi-depot configurations. In multidepot settings, depots can be placed either randomly or aligned with city centers (one per city). homogeneous fleet of vehicles is used, and vehicle count is configured to balance demand and capacity. All customer time windows are sampled to ensure feasibility under the assigned travel time model [1]. Validation. Each generated instance undergoes automated validation to ensure feasibility under both capacity and temporal constraints. For CVRP, we verify that the total vehicle capacity (number of vehicles per-vehicle capacity) exceeds the sum of all customer demands, ensuring that feasible route covering all customers exists. For TWVRP, we construct time-windowed demand histogram by binning the time axis and accumulating customer demands per bin. We then identify the peakdemand bin and ensure that the fleet capacity is sufficient to serve this worst-case demand, i.e., capacity num_vehicles maxt demand(t). This provides conservative guarantee that even under concentrated temporal demand, feasible schedule remains possible. Infeasible instances (e.g., unreachable nodes or incompatible time windows) are filtered or regenerated. Parameters are selected to reflect urban-scale routing challenges but can be modified for rural or industrial scenarios. Accident frequency and delay magnitudes are parameterized using Poissonbased arrival model and uniform delay range, respectively. Customer types are split roughly 60% residential to 40% commercial, matching empirical logistics patterns [3]. Various Scales. Our benchmark includes three instance tiers. Small instances (50100 customers, 12 depots) with low noise allow quick testing. Medium instances (100300 customers, 23 depots) 4 (a) Michigan (Real) (b) Abu Dhabi (Real) (c) Milan (Real) (d) Michigan (Synthetic) (e) Abu Dhabi (Synthetic) (f) Milan (Synthetic) Figure 2: Comparison of real (top) and synthetic (bottom) routing instances across three cities. feature moderate stochasticity. Large instances (300+ customers) integrate high travel-time variability and tighter delivery windows to stress-test scalability. All levels are generated with multiple random seeds to support statistical averaging and ensure robustness of comparisons. To validate the realism of our spatial sampling strategy, we visually compare synthetic routing instances against satellite imagery of real-world cities. As shown in Figure 2, our generated layouts closely mimic key structural patterns, grid-like in Michigan, radial in Milan, and dispersed in Abu Dhabi, demonstrating the pipelines ability to emulate diverse urban morphologies critical for evaluating routing algorithms in geographically grounded scenarios."
        },
        {
            "title": "4 Evaluation Protocol",
            "content": "To ensure fair, rigorous, and reproducible comparisons across routing algorithms, we propose standardized evaluation protocol tailored for our stochastic vehicle routing benchmark. This protocol assesses not only solution quality but also robustness, feasibility, and scalability under conditions of realistic uncertainty, addressing limitations of earlier benchmark designs that overlooked stochastic effects [22, 11]. 4.1 Performance Metrics We report comprehensive suite of metrics to evaluate different facets of algorithmic behavior. The Total Cost (TC) measures the cumulative travel time across all vehicles, including congestion-induced delays and accident-based disruptions. Formally, it is computed as: (cid:88) (cid:88) TC = (i, j, ti), kV (i,j)routek (15) where (i, j, ti) is the sampled travel time from node to at time ti. Figure 3: Solver Comparison: Overall Performance Metrics. Constraint Violation Rate (CVR) quantifies the proportion of customers whose service violates time windows or exceeds vehicle capacity, capturing solution feasibility: CVR = #violations #customers 100%. (16) Feasibility Rate (FR) reflects the robustness of solutions across instances and solvers. It is defined as the fraction of problem instances for which solution satisfies all routing constraints: FR = #feasible instances #total instances . (17) Runtime (RT) captures wall-clock computation time, serving as proxy for scalability and practical deployability. Robustness (ROB) measures the variability in cost due to stochastic elements by computing the variance across independent samples of the same instance: ROB = 1 (cid:80)N i=1 (cid:0)TCi TC(cid:1)2 , (18) where TC denotes the mean total cost. This metric is especially important in stochastic VRP settings [2, 18]."
        },
        {
            "title": "5 Experimental Results",
            "content": "We conduct comprehensive evaluation of baseline methods on our stochastic VRP benchmark, which systematically varies four key dimensions: instance size, problem type, depot configuration, and vehicle configuration. We generate 10 instances for each combination across instance sizes {10, 20, 50, 100, 200, 500, 1000}, problem types {CVRP, TWVRP}, depot configurations {single, multi}, and vehicle settings {single, multi}, yielding large-scale, structured test suite. Additionally, we provide scalable data generator for training. Reinforcement learning models were trained on 100k synthetic instances under the single-depot, single-vehicle CVRP and TWVRP regimes. 5.1 Evaluation Scope All methods were evaluated under the stochastic setting defined in Section 2. Metrics reported include total cost (incorporating all stochastic factors), constraint violation rate (CVR), feasibility rate, runtime, and robustness (measured as variance across stochastic samples). 6 Figure 4: Solver Performance by Problem Size. Table 2: Performance of baseline methods (mean over all instances, 5 stochastic runs). Method Total Cost CVR (%) Feasibility Runtime (s) Robustness NN+2opt Tabu Search ACO OR-Tools Attention Model (AM) POMO 40707.5 40787.8 40566.5 40259.3 41358.3 40650.4 1.6 1.6 1.6 1.6 1.9 1. 0.984 0.690 0.690 0.984 0.910 0.933 0.697 5.157 11.382 1.940 1.852 1.421 0.1 0.1 0.1 0.1 0.2 0.1 Classical algorithms, Nearest Neighbor + 2-opt, Tabu Search, and ACO (refer to Appendix for more details), were evaluated across all settings without modification. Their flexibility allows them to handle diverse configurations out of the box. 5.2 Experimental Setup All baselines were evaluated on consumer-grade CPU (Intel i7, 16GB RAM), except learningbased models, which used single NVIDIA RTX 4080. Classical and metaheuristic solvers were implemented in Python; learning models used the RL4CO framework [4]. Training for RL models was done on 100k synthetic instances (refer to Appendix for more details). Evaluation followed the stochastic protocol detailed in Section 2, averaging results over five realizations per test case. 5.3 Results & Analysis Overall Performance. Table 2 and Figure 3 summarize the aggregate performance across all test cases. OR-Tools achieved the best overall cost (40,259), followed closely by ACO (40,566; +0.8%) and POMO (40,650; +1.0%), with OR-Tools and NN+2opt maintaining the highest feasibility rates (98.4%) while NN+2opt delivered the fastest runtime (0.697s). Learning-based approaches demonstrated feasibility-speed tradeoff, with POMO offering better solution quality than NN+2opt at competitive runtimes (1.421s) while the Attention Model showed higher constraint violations (CVR: 1.9%) but reasonable performance across other metrics. 7 Table 3: Performance Comparison: CVRP vs TWCVRP. CVRP TWCVRP Impact Method Cost CVR Feas RT Cost CVR Feas RT % NN+2opt Tabu Search ACO OR-Tools Attention Model (AM) POMO 10399.2 10494.1 10384.9 9499.7 11235.6 10358.7 0.0 0.0 0.0 0.0 0.2 0. 1.000 1.000 1.000 1.000 0.965 0.987 646.3 945.1 11159.8 2328.0 1775.4 1316.9 71015.8 71081.5 70748.1 71018.8 71481.0 70942.1 3.2 3.2 3.2 3.2 3.6 3.3 0.968 0.381 0.381 0.968 0.854 0.879 747.8 9368.6 11603.6 1552.1 1929.2 1525. +582.9 +577.3 +581.3 +647.6 +536.2 +584.8 Table 4: Detailed Performance Analysis by Instance Size. Small (50) Medium (100-200) Large (500) Method Cost CVR Feas RT Cost CVR Feas RT Cost CVR Feas RT NN+2opt Tabu Search ACO OR-Tools Attention Model (AM) POMO 6295.0 6232.5 6080.7 6008.1 6523.2 6176.4 0.6 0.6 0.6 0.6 0.8 0.7 0.994 0.917 0.917 0.994 0.975 0.985 5.9 251.6 69.6 513.7 42.3 29. 31486.1 31692.2 31371.9 30640.2 32165.5 31024.8 2.3 2.3 2.3 2.3 2.6 2.4 0.977 0.542 0.542 0.977 0.910 0.945 90.9 1339.5 1530.6 665.8 857.4 642.3 101547.5 101716.5 101490.0 101255.0 102756.2 101408.7 2.4 2.4 2.4 2.4 2.9 2. 0.976 0.500 0.500 0.976 0.835 0.860 2340.0 16332.1 38201.0 5353.7 4758.9 3586.2 Impact of Time Windows. Table 3 reveals that introducing time windows (TWCVRP) increases total cost by 536648% across all solvers, with OR-Tools incurring the highest relative penalty (+647.6%) while the Attention Model showed the lowest relative increase (+536.2%). Learningbased methods demonstrated moderate resilience to time constraints with POMO maintaining 87.9% feasibility and Attention Model 85.4%, positioning them between the top performers (NN+2opt and OR-Tools at >96%) and the struggling metaheuristics (ACO and Tabu Search at 38.1%). Scalability by Instance Size. As shown in Table 4 and Figure 4, cost scaled approximately 16 from small ( 50 nodes) to large ( 500 nodes) instances across all methods, with NN+2opt and OR-Tools maintaining feasibility >97% at all scales, while learning-based methods showed moderate degradation (POMO: 86%, AM: 83.5%). Learning-based approaches demonstrated competitive performance-runtime tradeoffs, with POMO offering the fastest runtime on small instances (29.7s) and maintaining feasibility significantly better than ACO and Tabu Search (50%) on large instances, though traditional heuristics still held the advantage for the largest problems. Effect of Depot Configuration. Table 5 shows that multi-depot setups consistently reduced costs and improved feasibility across all methods, with OR-Tools achieving 72% cost reduction (from 34,611 to 9,561) and POMO showing similarly impressive gains (71% reduction to 10,178). Learningbased methods particularly benefited from multi-depot configurations, with both POMO and Attention Model reaching perfect feasibility (100%) despite their variable performance in single-depot scenarios (92-96.5%), supporting the counterintuitive finding that more flexible depot placements improve both computational and solution efficiency regardless of algorithm class. Key Takeaways. Our evaluation underscores several important insights: OR-Tools is the most reliable choice for large-scale offline optimization, balancing quality and feasibility despite higher runtimes. Table 5: Performance Analysis by Depot Configuration. Single Depot Multi Depot Method Cost CVR Feas RT Cost CVR Feas RT NN+2opt Tabu Search ACO OR-Tools Attention Model (AM) POMO 34978.5 35072.0 34852.1 34611.0 35825.6 34786.3 0.8 0.8 0.8 0.8 1.1 0.9 0.992 0.690 0.690 0.992 0.920 0.965 686.3 4818.2 10712.0 1911.2 1785.3 1438.2 10625.2 10713.8 10614.9 9561.4 10974.7 10178. 0.0 0.0 0.0 0.0 0.0 0.0 1.000 1.000 1.000 1.000 1.000 1.000 643.7 946.1 11298.7 2396.5 1852.6 1324.8 8 NN+2opt offers robust, low-latency alternative for real-time deployment with minimal compromise on cost or feasibility. Metaheuristics underperform at scale, while learning-based methods like POMO offer feasible solutions with better scalability, though still lag behind top heuristics. The Attention Model demonstrates potential but requires further refinement to match the performance of top-performing methods, particularly for large instances. Time windows impose the most significant complexity, sharply degrading performance for nonadaptive solvers, though learning-based methods show moderate resilience. Multi-depot settings improve both feasibility and runtime across all solver types, offering practical design consideration for logistics planning. Together, Figures 3 and 4 illustrate these trends across key metrics. SVRPBench successfully reveals scalability bottlenecks, constraint sensitivity, and performance trade-offs, establishing realistic and informative testbed for stochastic routing research. Please refer to appendix for additional results."
        },
        {
            "title": "6 Limitations and Future Directions",
            "content": "While SVRPBench advances realism in stochastic vehicle routing, several limitations remain. Our delay models rely on Gaussian and log-normal distributions to simulate traffic peaks and randomnessefficient and interpretable, yet unable to capture network-level dynamics such as bottlenecks, cascading congestion, or real-time rerouting [14]. These assumptions, however, are user-modifiable, allowing injection of domain-specific uncertainty. Reinforcement learning methods like AM and POMO show limited scalability to larger instances, reflecting overfitting and weak generalization. Additionally, our current evaluation protocol lacks standardized procedures to assess robustness across instance scales and distribution shifts, motivating future work on curriculum learning and hierarchical solver design. To further bridge the gap to real-world logistics, future extensions will incorporate road-constrained instances derived from OpenStreetMap or GIS data, enabling geographically grounded routing behavior. Dynamic and multi-day settingswith online updates and rolling horizonswill support evaluation of adaptive strategies [2]. We also plan to introduce diagnostic tasks for probing model robustness, generalization under distributional shift, and few-shot performance [21, 17], enabling more fine-grained analysis of algorithmic reliability in complex environments."
        },
        {
            "title": "7 Conclusion",
            "content": "We presented SVRPBench, modular and open-source benchmark for evaluating vehicle routing under realistic stochastic dynamics. By incorporating time-dependent congestion, probabilistic delays, and heterogeneous customer time windows, our benchmark departs from static assumptions and reflects the operational uncertainty of real logistics. Empirical results across over 500 instances revealed that classical and metaheuristic methods remain competitive on feasibility and runtime, while reinforcement learning models like POMO and AM, despite strong performance in training regimes, struggled with multi-depot generalization and exhibited > 20% cost degradation under distributional shift. Surprisingly, multi-depot configurations consistently improved both cost and robustness, even for learning-based solvers, highlighting the importance of flexible depot placement in practical settings. By supporting large-scale, reproducible evaluations via Hugging Face and GitHub, SVRPBench offers community platform to benchmark solvers across realism axes. We urge the research community to develop adaptive, noise-aware routing algorithms that bridge the gap between synthetic optimization and deployable, resilient logistics solutions."
        },
        {
            "title": "References",
            "content": "[1] Yossiri Adulyasak and Patrick Jaillet. Models and algorithms for stochastic and robust vehicle routing with deadlines. Transportation Science, 50(2):608626, 2016. [2] Cock Bastian and Alexander H. G. Rinnooy Kan. The stochastic vehicle routing problem revisited. European Journal of Operational Research, 56(3):407412, 1992. [3] Russell Bent and Pascal Van Hentenryck. Scenario-based planning for partially dynamic vehicle routing with stochastic customers. Operations Research, 52(6):977987, 2004. [4] F. Berto, C. Hua, J. Park, M. Kim, H. Kim, J. Son, H. Kim, J. Kim, and J. Park. Rl4co: unified reinforcement learning for combinatorial optimization library. In Proceedings of Advances of Neural Information Processing Systems (workshop), 2023. [5] Dimitris J. Bertsimas, Patrick Jaillet, and Amedeo R. Odoni. priori optimization. Operations Research, 38(6):10191033, 1990. [6] Werner Brilon, Jürgen Geistefeldt, and Markus Regler. Reliability of travel times: stochastic modeling approach. Transportation Research Record, 2061(1):18, 2008. [7] K. Chepuri and T. Homem-de Mello. Solving the vehicle routing problem with stochastic demands using the cross-entropy method. Annals of Operations Research, 134(1):153181, 2005. [8] George Dantzig and John Ramser. The truck dispatching problem. Management science, 6(1):8091, 1959. [9] Moshe Dror, Gilbert Laporte, and Pierre Trudeau. Vehicle routing with stochastic demands: Properties and solution frameworks. Transportation Science, 23(3):166176, 1989. [10] FedEx Corporation. Fedex residential delivery options whitepaper. Whitepaper, 2020. Flexible delivery time window practices. [11] Michel Gendreau, Gilbert Laporte, and Renaud Séguin. Stochastic vehicle routing. European Journal of Operational Research, 88(1):312, 1996. [12] Michel Gendreau, Gilbert Laporte, and Renaud Séguin. tabu search heuristic for the vehicle routing problem with stochastic demands and customers. Operations Research, 44(3):469477, 1996. [13] Michel Gendreau, Gilbert Laporte, and Rene Seguin. Stochastic vehicle routing. European Journal of Operational Research, 88(1):312, 1996. [14] Lars Magnus Hvattum, Arne Lø kketangen, and Gilbert Laporte. Solving dynamic and stochastic vehicle routing problem with sample scenario hedging heuristic. Transportation Science, 40(4):421438, 2006. [15] Wouter Kool, Herke Van Hoof, and Max Welling. Attention, learn to solve routing problems! arXiv preprint arXiv:1803.08475, 2018. [16] Wouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems! International Conference on Learning Representations (ICLR), 2019. [17] Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, and Seungjai Min. Pomo: Policy optimization with multiple optima for reinforcement learning. Advances in Neural Information Processing Systems, 33:2118821198, 2020. [18] Gilbert Laporte, François V. Louveaux, and Hélène Mercure. The vehicle routing problem with stochastic travel times. Transportation Science, 26(3):161170, 1992. [19] Qing Li, Ming Xu, and Yinhai Wang. Modeling travel time variability with lognormal distribution. Transportation Research Record, 2490(1):4754, 2015. [20] Bring Logistics. Customer preferences in last-mile deliveries: Flexible windows and urban density effects. Industry Report, 2021. Available via company white papers. [21] Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Takáˇc. Reinforcement In Proceedings of Advances in Neural learning for solving the vehicle routing problem. Information Processing Systems, pages 98619871, 2018. [22] Jorge Oyola, Halvard Arntzen, and David L. Woodruff. The stochastic vehicle routing problem, literature review, part i: Models. EURO Journal on Transportation and Logistics, 7(3):193221, 2018. [23] Jorge Luis Oyola, Halvard Arntzen, and David Woodruff. The stochastic vehicle routing problem: literature review, part i: Models. EURO Journal on Transportation and Logistics, 7(3):193221, 2018. [24] Nikica Peric, Slaven Begovic, and Vinko Lesic. Adaptive memory procedure for solving real-world vehicle routing problem. arXiv preprint arXiv:2403.04420, 2024. [25] Nikica Peric, Slaven Begovic, and Vinko Lesic. Adaptive memory procedure for solving real-world vehicle routing problem. arXiv preprint arXiv:2403.04420, 2024. [26] Laurent Perron and Frédéric Didier. Cp-sat. [27] David Schrank, Bill Eisele, Tim Lomax, et al. 2021 urban mobility report. Texas A&M Transportation Institute, 2021. [28] Federal Highway Administration U.S. Department of Transportation. Manual on uniform traffic control devices (mutcd), 2009 edition, 2009. Accident and incident classification and duration guidelines. [29] Ron van Duin, Tolga Bektas, Murat Bektas, and Tavares Tan. Attended home deliveries: Preferences and behavioral patterns. Transportation Research Procedia, 16:3039, 2016. [30] Ronald Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3):229256, 1992. [31] Jiongzhi Zheng, Kun He, Jianrong Zhou, Yan Jin, and Chu-Min Li. Reinforced lin kernighanhelsgaun algorithms for the traveling salesman problems. Knowledge-Based Systems, 260:110144, 2023."
        },
        {
            "title": "A Open Infrastructure",
            "content": "To ensure reproducibility, extensibility, and accessibility, we release all components of the benchmark openly on GitHub and Hugging Face. This includes the dataset, instance generator, evaluation engine, and baseline implementations. Evaluation instances can be used out of the box, while the modular codebase allows users to integrate new solvers and adapt evaluation scripts. public leaderboard on huggingface1 serves as the central hub for documentation, instance downloads, and leaderboard submissions. Submissions are validated automatically and ranked by total cost, feasibility, and runtime. All data and code are versioned, containerized (Docker-supported), and designed to support future extensions such as new routing scenarios or solver classes. We welcome community contributions, including new solvers, datasets, and improvements to documentation or evaluation tools. By sharing the infrastructure broadly, we aim to foster collaboration and accelerate progress in realistic stochastic routing research. A.1 Reproducibility Requirements To maintain transparency and enable fair comparison, submissions intended for leaderboard inclusion or academic publication must satisfy several criteria. Solvers must be evaluated on the official benchmark test set, with all hyperparameters, configuration details, and seed values fully documented. Additionally, we encourage open-source releases or detailed methodological descriptions to ensure 1https://huggingface.co/spaces/ahmedheakl/SVRP-leaderboard algorithm reproducibility. Runtime should be measured using the official script or clearly defined procedure, consistent across all experiments. These guidelines help uphold reproducibility standards advocated in combinatorial optimization literature [7, 1] and promote meaningful scientific comparisons under controlled, yet realistic, conditions."
        },
        {
            "title": "B Baseline Models",
            "content": "Ant Colony Optimization (ACO). Routes are constructed by sampling next locations based on pheromone intensity and heuristic proximity. The pheromone matrix is updated as: τij (1 ρ)τij + (cid:88) k=1 τ (k) ij , τ (k) ij = (cid:26) L(k) , 0, if (i, j) tour(k) otherwise, where ρ = 0.5, = 50 ants, α = 1, and β = 2. Tabu Search. Candidate solutions are evaluated using penalized cost function: where λ is adaptively tuned based on violation severity. (S) = Cost(S) + λ Penalty(S), Learning-Based Methods. The Attention Model is trained to minimize the expected cost: L(θ) = EXD (cid:2)Eπθ(aX)[L(aX)](cid:3) . (19) (20) (21) POMO uses multiple rollout agents initialized with distinct permutations. Its gradient signal is computed as: θJ(θ) = 1 (cid:88) (cid:88) m=1 θ log πθ(am sm ) (Rm b), (22) where is the number of rollouts and is learned baseline for variance reduction."
        },
        {
            "title": "C Detailed Solver Performance Breakdowns",
            "content": "Tables 6,7,8,9,10,11 present comprehensive performance breakdown of various solvers across multiple configurations for Capacitated VRP (CVRP) and Time Window VRP (TWVRP). Each solver, NN+2opt, Tabu Search, ACO, OR-Tools, and RL-based methods (Attention, POMO), is evaluated under different settings including depot configurations (single depot, multi depot, depots equal to cities), problem sizes (ranging from 10 to 1000 customers), and feasibility constraints. Metrics include total cost, CVR (constraint violation rate), feasibility, runtime, and time window violations. Traditional heuristic solvers (NN+2opt, Tabu, ACO) generally yield competitive costs with increasing runtimes as problem size grows, while OR-Tools offers consistent feasibility but with significantly higher runtimes. Reinforcement learning solvers (Attention, POMO) demonstrate exceptionally fast runtimes (in milliseconds), achieving full feasibility across all tested instances, although their cost can vary notably, especially for large-scale problems where some cost inflation is observed (e.g. POMO on 1000-node CVRP). These results highlight trade-offs between solution quality, computational efficiency, and scalability across solver paradigms. 12 Table 6: NN+2opt - Detailed Performance Breakdown. Configuration single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot Size 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 Cost CVR Feas Runtime TW Violations 2290.7 2371.8 3736.5 3662.9 4840.4 5626.1 6841.4 7868.2 11268.2 11479.2 16390.0 17551.0 25844.3 25817.4 4564.6 4359.0 8192.2 8347.0 13666.8 13882.4 38704.2 30389.4 89937.2 55400.9 175711.7 118279.0 244956.8 187829.7 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.3 3.3 0.0 0.0 0.0 0.7 6.0 1.0 10.1 1.0 7.7 2.2 6.1 2.7 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.967 0.967 1.000 1.000 1.000 0.993 0.940 0.990 0.899 0.990 0.923 0.978 0.939 0.973 0.0 2.0 0.3 3.2 10.5 14.1 31.8 31.3 125.2 135.5 829.5 826.3 3545.9 3493.3 2.0 2.0 5.7 5.0 14.9 11.7 52.2 37.8 145.2 167.8 1318.5 929.7 3865.2 3911.5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 Table 7: Tabu Search - Detailed Performance Breakdown. Configuration single depot single vehicle sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot Size 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 Cost CVR Feas Runtime TW Violations 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.3 3.3 0.0 0.0 0.0 0.7 6.0 1.0 10.1 1.0 8.1 2.2 6.2 2.7 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.667 0.667 1.000 1.000 1.000 0.667 0.000 0.333 0.000 0.000 0.000 0.000 0.000 0.000 19.4 13.3 47.6 33.8 79.8 102.9 170.0 169.2 373.9 314.2 1270.4 1445.1 4647.9 4544.5 185.9 193.6 479.8 489.9 719.3 654.4 2013.6 1998.3 2662.6 3014.1 13851.1 11822.7 50402.1 42673. 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 2297.2 2373.8 3776.7 3656.4 4897.0 5749.3 6981.9 8058.6 11417.8 11602.8 16554.8 17676.2 25995.4 25879.7 3966.1 4067.6 8156.1 7661.3 13918.7 14269.3 39031.2 30820.4 90028.5 55596.2 176001.3 118726.0 244953.3 187945.6 13 Table 8: ACO - Detailed Performance Breakdown. Configuration single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot Size 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 Cost CVR Feas Runtime TW Violations 2183.6 2325.4 3725.9 3644.2 4840.5 5626.2 6840.4 7868.4 11264.3 11473.0 16389.2 17551.6 25840.7 25815.8 3931.6 3819.2 7714.2 7749.4 13535.4 13872.4 37800.2 30389.5 89937.2 55401.8 175711.1 118280.2 244999.0 187332.2 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.3 3.3 0.0 0.0 0.0 0.7 6.0 1.0 10.1 1.0 7.7 2.2 6.1 2.8 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.667 0.667 1.000 1.000 1.000 0.667 0.000 0.333 0.000 0.000 0.000 0.000 0.000 0.000 14.3 11.9 34.6 31.4 165.2 179.5 698.1 678.2 2295.7 2380.3 15573.5 16468.6 58364.4 59341.2 9.4 9.6 34.2 34.1 166.9 143.6 629.4 679.0 2556.8 2327.0 15299.3 14781.5 70932.6 54846.8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0. Table 9: OR-Tools - Detailed Performance Breakdown. Configuration single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot single depot single vehicule sumDemands multi depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot depots equal city single depot Size 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 Cost CVR Feas Runtime TW Violations 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.3 3.3 0.0 0.0 0.0 0.7 6.0 1.0 10.1 1.0 7.7 2.2 6.1 2.7 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.967 0.967 1.000 1.000 1.000 0.993 0.940 0.990 0.899 0.990 0.923 0.978 0.939 0. 1037.9 1003.3 999.5 1002.6 1015.9 1015.9 1046.5 1048.8 1174.7 1185.4 2129.5 2085.2 8412.4 9434.5 12.6 3.6 8.2 7.2 30.3 27.7 108.6 87.8 345.3 329.8 2010.0 2020.5 8273.1 8464.4 2049.2 2167.6 3238.9 3142.2 3773.4 4714.2 6283.5 6250.4 9198.8 8956.2 15677.5 15883.2 25844.3 25816.3 4564.7 4359.0 8192.3 8346.9 13666.7 13882.3 38704.1 30389.3 89937.5 55401.8 175711.4 118279.4 244998.0 187830.1 14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 Table 10: RL Algorithms Detailed Performance on CVRP (runtimes in ms). Solver Configuration Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands single depot single vehicule sumDemands Size 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 Cost CVR Feas Runtime (ms) TW Violations 2364.12 2312.68 3222.68 3341.56 5803.63 5920.19 8553.26 16983.50 13228.84 12726.96 22496.94 88789.44 37430.47 184656.10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0. 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.365 0.282 0.269 0.279 0.304 0.287 0.319 0.319 0.353 0.360 0.463 0.506 0.649 0.689 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 Table 11: RL Algorithms Detailed Performance on TWVRP (runtimes in ms). Solver Configuration Size Cost CVR Feas Runtime (ms) TW Violations Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO Attention POMO single depot single depot single depot single depot single depot single depot single depot single depot single depot single depot single depot single depot single depot single depot 10 10 20 20 50 50 100 100 200 200 500 500 1000 1000 3 940.38 3 854.6 6 504.73 6 744.7 29 132.94 29 718.0 57 778.84 114 726.7 113 742.27 109 427.1 271 201.60 438 502.6 531 470.88 611 307.8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1. 0.916 0.707 1.780 1.841 0.731 0.689 0.864 0.864 0.868 0.886 1.412 1.412 1.638 1.672 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15 C.1 Qualitative Results As shown in figures 5, 6, 7, 8, 9, 10, 11, 12, 13, and 14, we qualitatively observe that for CVRP instances with small number of customers, both Attention and POMO models, as well as classical methods (ACO, NN2OPT, and OR-Tools), generate highly structured and near-optimal routes. As the number of customers increases, route complexity grows, making it harder for models to preserve efficiency and structure. For TWVRP, the models priority shifts toward satisfying delivery time windows, often at the expense of distance optimization. This results in routes that appear less spatially coherent but better aligned with temporal constraints. Figure 5: CVRP 20 customers Attention Model Figure 6: CVRP 10 customers POMO Figure 7: CVRP 200 customers Attention Model Figure 8: TWVRP 20 customers Attention Model 16 Figure 9: CVRP 10 customers ACO Figure 10: TWVRP 10 customers ACO Figure 11: CVRP 10 customers NN2OPT Figure 12: TWVRP 10 customers NN2OPT Figure 13: CVRP 10 customers OR-Tools Figure 14: TWVRP 10 customers OR-Tools"
        },
        {
            "title": "D Reinforcement Learning",
            "content": "D.1 Problem Formulation We model both the Capacitated Vehicle Routing Problem (CVRP) and Vehicle Routing Problem with Time Windows (VRPTW) as Markov Decision Process (MDP) = (S, A, P, r, γ), where each state st encodes the vehicles current position, remaining capacity, visited set (and only for VRPTW the current time and per-customer time windows [ei, ℓi]). Actions at A(st) select the next customer, and transitions (st+1 st, at) deterministically update the tour while, in VRPTW, adding stochastic delays. The reward is r(st, at) = di,j τ [tarrive > ℓi] when visiting customer j, with di,j the Euclidean distance and τ large penalty for time-window violations, and zero upon return to the depot. We follow constructive, autoregressive decoding: at each step we append one customer until all are visited. D.2 Policy /Vt We adopt the encoderdecoder with multi-head attention of Kool [16]. Given embedded node features xi Rd, each of the encoder layers applies multi-head self-attention. At step t, with context embedding ht, we score each remaining node by ut,j = tanh(cid:0)W1ht + W2xj (cid:1) and define πθ(at = st) = exp(ut,j)/ (cid:80) exp(ut,k) . We optimize the policy by maximizing the expected return J(θ) = Eτ πθ [R(τ )] using two constructive, autoregressive policy-gradient methods. constructive policy builds complete solution by sequentially selecting one customer at time until the tour is finished, while an autoregressive policy conditions each action on the history of previous choices, enabling the network to capture dependencies across steps. We first apply REINFORCE [30], which updates parameters via θJ(θ) = E(cid:2)(cid:80) θ log πθ(at st) (R(τ ) b(st))(cid:3), where b(st) is rollout baseline obtained by greedy decoding; then POMO [17] samples different start nodes per instance, computes returns Rk and shared baseline = k=1 θ log πθ(τk) (Rk R). REINFORCE offers simplicity 1 and unbiased gradients, while POMOs shared baseline exploits VRP permutation symmetry for variance reduction; together they provide strong comparison between classical Monte Carlo approach and state-of-the-art, variance-reduced VRP-specific algorithm. Rk, and applies θJ(θ) = 1 (cid:80)K (cid:80) D.3 Training Details All models were implemented in the RL4CO framework and trained end-to-end with Adam at learning rate of 104. For CVRP with REINFORCE we used batch size of 512 and generated 100 000 synthetic instances on the fly; for VRPTW with POMO we used batch size 64 and 1 000 000 instances. Validation employed greedy decoding under nominal travel-time conditions. VRPTW environments included log-normal delays calibrated to traffic data, Gaussian time-of-day kernels, and Poisson accident events, with infeasible actions heavily penalized to enforce time windows. D.4 Evaluation on SVRPBench After training, we converted each of the 500+ SVRPBench instances into the RL4CO environment format and ran the trained policies in greedy mode, selecting at each step at = arg maxj πθ(at = st). To assess robustness, we then simulated each resulting tour under multiple sampled delay realizations and reported average tour length and feasibility rates. Despite domain shift, attentionbased RL policies maintained high feasibility and near-optimal costs across all problem sizes."
        }
    ],
    "affiliations": [
        "MBZUAI, Abu Dhabi, UAE"
    ]
}