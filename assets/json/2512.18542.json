{
    "paper_title": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
    "authors": [
        "Scott Thornton"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding, don't provide the scale modern training requires, and miss the operational security context developers need for production deployments. We present SecureCode v2.0, a production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references, provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code). Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses a 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth guidance. Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) a 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) open-source release of data, validation tools, and benchmarking protocols."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 0 2 ] . [ 1 2 4 5 8 1 . 2 1 5 2 : r SecureCode v2.0: Production-Grade Dataset for Training Security-Aware Code Generation Models Scott Thornton scott@perfecxion.ai December 2025 Abstract AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding. They dont provide the scale modern training requires. Most miss the operational security context developers need for production deployments. We present SecureCode v2.0, production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references. Every example provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code). Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth operational guidance. Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) opensource release of data, validation tools, and benchmarking protocols."
        },
        {
            "title": "1.1 The Security Crisis in AI-Generated Code",
            "content": "AI coding assistants produce vulnerable code in 45% of generated implementations [1]. Veracodes 2025 GenAI Code Security Report analyzed code from leading AI assistants and found nearly half of securityrelevant implementations contained Common Weakness Enumeration (CWE) vulnerabilities. This represents systematic risk in AI-assisted development, compounding security debt across millions of developers. The risk surface has scaled with adoption. The issue goes beyond individual bugs. AI-generated vulnerabilities enter production codebases silently, without the traditional code review scrutiny applied to human-written code. Developers trust AI assistants to produce functional implementations, but these tools lack security context to recognize when functional means exploitable. Apiiro (2025) found AI copilots introduced 322% more privilege escalation paths 1 and 153% more architectural design flaws compared to manually-written code, while generating 10 more security findings overallactively degrading security practices [2]. This creates multiplier effect. Vulnerable patterns suggested by AI assistants propagate across multiple projects. SQL injection flaws spread through microservices architectures. Authentication bypasses replicate across API endpoints. Cryptographic failures multiply through mobile applications. The scale of AI adoption makes this systematic risk to software security. LLMs trained on public code repositories learn from millions of vulnerable examples. Stack Overflow answers from 2010 showing insecure MySQL queries. GitHub repositories implementing broken authentication. Tutorial code demonstrating SQL injection vulnerabilities as simple examples. These models learn what code looks like, not what secure code requires."
        },
        {
            "title": "1.2 Why Existing Datasets Fall Short",
            "content": "Existing secure coding datasets have significant limitations for training security-aware language models. We analyzed four widely-used datasets: CWE-Sans (372 examples), Juliet Test Suite (81,000-86,000 synthetic test cases for C/C++ and Java), SARD (170,000-200,000 test programs), and Draper VDISC (1.27 million examples). While these serve their intended purposes, they have critical gaps for LLM training. Scale versus quality. Juliet provides 81,000-86,000 test cases designed for testing static analysis tools, but lacks connections to real-world incidents. These synthetic test cases demonstrate CWE patterns in isolation, teaching models to recognize textbook vulnerabilities that dont reflect how attacks occur in production. SARD offers 170,000-200,000 test programs but fewer than 5% reference documented security incidents. Synthetic training data misses the contextual factors that make vulnerabilities exploitable in production. Incident grounding is rare. Our manual audit of CWE-Sans metadata (n=372 examples, 100% coverage) found approximately 18% reference actual CVEs or documented breachesfewer than one in five. The rest are synthetic demonstrations lacking the production context needed to understand exploitation. Realworld attacks exploit edge cases, framework-specific behaviors, and integration failures that rarely appear in manufactured examples. Format limitations. Existing datasets use code-only formatsvulnerable snippet paired with secure snippet. This doesnt capture how developers actually interact with AI assistants. Real development conversations escalate through multiple turns as developers ask about functionality, then scaling, performance, and edge cases. AI assistants must maintain security context throughout this workflow, but existing datasets dont model these multi-turn interactions. No operational guidance. Existing datasets provide vulnerable and patched code without detection mechanisms, logging strategies, or defense-in-depth guidance. For production systems, secure code is just one component of comprehensive security. Organizations need detection rules, monitoring strategies, incident response procedures, and graceful degradation when primary controls fail."
        },
        {
            "title": "1.3 SecureCode v2.0: A Production-Grade Solution",
            "content": "We developed SecureCode v2.0 to address these limitations with production-grade training data. The dataset provides 1,215 rigorously validated unique examples that passed structural validation and expert security review. Every example references documented CVEs or security incidents. Every example provides vulnerable and secure implementations. Every example demonstrates concrete attacks and includes defensein-depth operational guidance with SIEM integration strategies, infrastructure hardening recommendations, and comprehensive testing approaches. Incident grounding drives production applicability. We mined CVE databases from 2017-2025, analyzed OWASP Top 10 documentation, reviewed security breach reports, and studied bug bounty disclosures. 2 the 2017 Equifax breach (CVE-2017-5638) costing $425 milEach example ties to specific incident: lion from Apache Struts 2 Jakarta multipart parser RCE (OGNL injection), the 2019 Capital One SSRF attack exposing 100 million customer records, the deserialization vulnerabilities that compromised dozens of financial institutions. These are documented failures with measurable business impact, not hypothetical scenarios. Conversational structure mirrors real development. We structured examples as 4-turn conversations. Turn 1: developer requests specific functionality (build user authentication with JWT tokens). Turn 2: AI assistant provides vulnerable and secure implementations with attack demonstrations. Turn 3: developer asks advanced questions (how does this scale to 10,000 concurrent users?). Turn 4: AI assistant delivers defense-in-depth guidance covering logging, monitoring, detection, and operational security. This captures how security knowledge transfers during actual development. Developers dont request secure and insecure authentication in abstract terms. They request authentication solving specific problems, then iterate toward production-ready security through follow-up questions. The conversational format trains models on realistic interaction patterns. Figure 1: Four-Turn Conversational Format. Mirrors realistic developer-AI workflows. Turn 1: feature requests. Turn 2: vulnerable + secure implementations with attacks. Turn 3: advanced scenarios. Turn 4: operational security guidance. Production quality through systematic validation. We developed an automated validation framework enforcing structural quality standards: 4-turn conversation structure compliance, proper CVE formatting (CVE-YYYY-NNNNN or explicit null), valid programming language tags, minimum content length requirements, and security control completeness. Compliance progressed from 47.2% (397 of 841 training examples passing all validation checks) to 100% through systematic remediation across five fix categories. We addressed 452 CVE format issues where examples referenced security incidents without proper CVE-YYYY-NNNNN formatting. We corrected 60 language tag mappings where YAML examples needed context-appropriate language assignments based on question content. We enhanced 86 examples with additional defense-in-depth guidance. We implemented 6 secure SSTI examples after discovering Jinja2, Twig, Mako, Smarty, Tornado, and Go template examples needed secure sandboxing demonstrations. We calibrated validator thresholds, reducing minimum content length from 100 to 50 characters for user turns after 3 analysis showed this eliminated false positives without compromising content quality. Comprehensive security coverage. SecureCode v2.0 spans 11 vulnerability categories across 11 languages (10 programming languages: Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin + YAML for infrastructure-as-code), providing complete coverage of OWASP Top 10:2025 plus AI/ML Security Threats. Figure 2: Coverage Snapshot. Dataset composition across three dimensions: vulnerability categories (left), language distribution (center), and severity mix (right). Dataset splits: 989 train / 122 validation / 104 test examples."
        },
        {
            "title": "1.4 Contributions",
            "content": "This paper makes six contributions to secure AI-assisted development: 1. Production-Grade Dataset (1,215 Unique Examples). SecureCode v2.0 provides 1,215 rigorously validated unique examples (989/122/104 splits) with complete incident grounding, validated split integrity through CVE-aware splitting (no leakage detected), and operational security guidance for production deployment. Content deduplication removed 1,203 duplicates. Systematic validation achieved full compliance with structural standards and expert security review. 2. Automated Validation Framework. We developed and release an automated validation framework (validate contributing compliance.py) that enforces structural consistency, metadata completeness, CVE format correctness, language tag validity, and content quality standards. This framework enabled systematic quality improvement from 47.2% baseline compliance to full compliance, identifying 604 specific issues needing remediation. Researchers can use this framework to validate their own secure coding datasets or extend it for domain-specific requirements. 3. Novel 4-Turn Conversational Structure. SecureCode v2.0 uses 4-turn conversation format (initial request vulnerable/secure code advanced scenario operational guidance) that trains models on realistic developer-AI workflows, unlike code-only datasets that miss iterative security considerations. 4. Comprehensive Security Operations Guidance. SecureCode v2.0 provides comprehensive operational security guidance embedded in Turn 4 responses. Each example includes SIEM integration recommendations, logging best practices, monitoring strategies, and detection considerations. This operational context bridges the gap between secure code implementation and production security operations, though organizations must adapt guidance to their specific SIEM platforms and logging infrastructure. 5. Full Language-Specific Implementation Fidelity. The dataset maintains complete language fidelity all code examples use proper language-specific syntax, idioms, and frameworks. JavaScript examples use Express/NestJS, PHP uses Laravel/Symfony, Java uses Spring Boot, Go uses Gin, Ruby uses Rails, and C# uses ASP.NET Core. Models learn authentic language patterns, not generic pseudocode. 6. Open-Source Release. We release SecureCode v2.0, the validation framework, fine-tuning protocols, and evaluation benchmarks as open-source artifacts under Creative Commons Attribution-NonCommercialShareAlike 4.0 International License (CC BY-NC-SA 4.0). Researchers can reproduce results, extend the methodology, or use the dataset as foundation for domain-specific security training. Educators can use real-world security incidents as teaching material. Commercial use requires separate licensing."
        },
        {
            "title": "2.1 Secure Coding Datasets",
            "content": "The security research community has produced several datasets for studying vulnerable code, but none meet the requirements for training production-grade AI coding assistants. CWE-Sans Top 25 Dataset provides 372 examples across 4 programming languages with partial OWASP coverage [3]. Only 18% of examples anchor to real-world incidentsthe remaining 82% are synthetic demonstrations of CWE patterns. The dataset uses code-only format showing vulnerable and patched implementations without attack context or operational guidance. While valuable for teaching CWE taxonomy, it lacks the scale, real-world grounding, and conversational structure needed for modern LLM training. Juliet Test Suite offers 81,000-86,000 synthetic test cases in C/C++ and Java covering 118 CWE types [4]. Zero percent ground to real-world incidents. Every example is manufactured test case demonstrating specific CWE patterns in isolation. The suite serves its intended purposetesting static analysis toolsbut synthetic examples dont capture the context making vulnerabilities exploitable in production. Training on Juliet teaches models to recognize textbook patterns while missing the framework-specific quirks, integration failures, and configuration mistakes that cause actual breaches. Software Assurance Reference Dataset (SARD) contains 170,000-200,000 test programs across 5 languages (C, C++, Java, PHP, C#) with no OWASP mapping [5]. Fewer than 5% tie to documented security incidents. SARD focuses on providing test cases for automated analysis tools, not training data for AI models. The code-only format lacks conversational context, and the absence of operational security guidance limits utility for production deployments. Draper VDISC provides 1.27 million examples with unknown incident grounding [6]. This massive dataset supports binary analysis research but concentrates entirely on without multi-language coverage. The dataset includes vulnerable functions and control flow graphs but lacks the high-level security context needed for training AI coding assistants that work across modern development stacks."
        },
        {
            "title": "2.2 AI Code Generation Security Research",
            "content": "Recent empirical studies show AI coding assistants systematically produce insecure code, but no training datasets address the identified vulnerabilities. Veracode (2025) evaluated leading AI coding assistants security using comprehensive static analysis across thousands of generated code samples [1]. They found 45% of AI-generated implementations in security-relevant contexts contained vulnerabilities. SQL injection appeared in database query generations. Command injection emerged in system interaction code. Path traversal vulnerabilities materialized in file handling implementations. The study concluded AI assistants reproduce vulnerable patterns from training 5 Figure 3: Dataset Comparison. SecureCode v2.0 vs. related work across four dimensions: dataset size (blue), language coverage (pink), incident grounding (orange), and conversational format (green). SecureCode v2.0 achieves 100% incident grounding and is the only conversational dataset. data without understanding security context. Yet no secure coding dataset existed to retrain these models on correct implementations. Apiiro (2025) analyzed application security posture across thousands of repositories and tens of thousands of developers in Fortune 50 enterprises comparing AI-assisted development to manual coding [2]. AI copilots introduced 322% more privilege escalation paths and 153% more architectural design flaws, while generating 10 more security findings overall compared to manually-written code."
        },
        {
            "title": "3.1 Design Principles",
            "content": "SecureCode v2.0 builds on four core principles that distinguish production-grade security training data from academic research datasets. P1: Incident Grounding. Every example ties to documented security incidents. Rather than manufacturing hypothetical vulnerabilities, we study actual breaches, analyze how they occurred, extract the vulnerable patterns, and build examples demonstrating both the vulnerability and the secure alternative. P2: Conversational Structure. Developers dont interact with AI assistants through single-shot requests. They iterate. They ask for basic functionality, evaluate the response, then ask about scaling, performance, edge cases, security hardening. Our conversational structure captures this iterative workflow. P3: Dual Implementation Pattern. Every example provides vulnerable and secure implementations of the same functionality. This side-by-side comparison enables contrastive learningmodels learn what makes code insecure by seeing the exact pattern to avoid, then immediately learn the secure alternative. P4: Operational Completeness. Security doesnt end at secure code. Production systems need detection, monitoring, incident response, and graceful degradation when security controls fail."
        },
        {
            "title": "3.2 Data Collection Process",
            "content": "We collected SecureCode v2.0 through three-phase methodology ensuring incident grounding and production quality. Important Clarification on Code Authenticity: Every example in SecureCode v2.0 anchors to realworld security incidents (CVEs, breach reports, security advisories). However, the code implementations themselves are synthetically generated using multi-LLM synthesis (ChatGPT 5.1, Claude Sonnet 4.5, Llama 3.2) with human expert review. The incidents are real; the code faithfully demonstrates vulnerability patterns and secure alternatives for those incidents. Figure 4: Dataset Construction Pipeline. Five-stage progression from 2,847 incident candidates to 1,215 final examples. Verification gates ensure no CVE overlap across splits, no near-duplicate pairs (Jaccard 0.8), and preserved split group integrity."
        },
        {
            "title": "4.1 Validation Framework",
            "content": "We developed validate contributing compliance.py, an automated validation framework enforcing structural quality standards across all examples. The validator performs six core checks."
        },
        {
            "title": "4.2 Compliance Journey: 47.2% to 100%",
            "content": "Initial validation on an 841-example development subset revealed 47.2% baseline compliance (397 of 841 examples passing all checks). We implemented systematic remediation across five fix categories. 7 Figure 5: Weekly Compliance Progress. Six-week improvement from 47.2% to 100% compliance. Blue line shows compliance rate; pink bars show weekly fixes (679 total). Week 1 required most remediation (312 CVE format fixes)."
        },
        {
            "title": "5.1 Compliance Metrics",
            "content": "Final dataset achieves 100% compliance across all validation checks: CVE Format Compliance: 1,215/1,215 (100%) Language Tag Validity: 1,215/1,215 (100%) Content Quality Standards: 1,215/1,215 (100%) Conversation Structure: 1,215/1,215 (100%)"
        },
        {
            "title": "5.2 Coverage and Balance Metrics",
            "content": "The dataset provides comprehensive coverage across vulnerability categories, programming languages, and severity levels  (Table 1)  ."
        },
        {
            "title": "6.1 Key Findings",
            "content": "SecureCode v2.0 demonstrates production-grade secure coding datasets require four essential characteristics: (1) complete incident grounding, (2) conversational structure, (3) operational security guidance, and (4) systematic quality validation."
        },
        {
            "title": "6.2 Practical Implications",
            "content": "Organizations can use SecureCode v2.0 to fine-tune enterprise AI coding assistants on incident-grounded secure patterns. The 4-turn conversational structure trains models to maintain security context across iter8 Table 1: Dataset Coverage Distribution Category Examples Percentage OWASP Top 10:2025 Categories A01: Broken Access Control A07: Authentication Failures A02: Security Misconfiguration A05: Injection A04: Cryptographic Failures Programming Languages Python JavaScript Java Go Severity Distribution CRITICAL HIGH MEDIUM Total 224 199 134 125 115 255 245 189 159 795 384 1,215 18.4% 16.4% 11.0% 10.3% 9.5% 21.0% 20.2% 15.6% 13.1% 65.4% 31.6% 3.0% 100% ative development workflows. The operational guidance prepares models to recommend defense-in-depth strategies beyond code-level fixes."
        },
        {
            "title": "6.3 Limitations",
            "content": "While SecureCode v2.0 provides comprehensive coverage, several limitations deserve consideration. The dataset focuses on web and enterprise application security patterns. Mobile-specific vulnerabilities (iOS/Android), embedded systems security, and hardware-level attacks receive limited coverage. The conversational structure assumes English-language development workflows. Organizations operating in non-English environments may need translation or localization."
        },
        {
            "title": "7 Conclusion",
            "content": "SecureCode v2.0 provides the first production-grade dataset for training security-aware code generation models. With 1,215 rigorously validated examples, complete incident grounding, 4-turn conversational structure, and comprehensive operational guidance, the dataset enables training AI assistants that generate secure code in realistic development workflows. Future work should expand coverage to mobile platforms, embedded systems, and emerging attack vectors. Multilingual support would enable training models for non-English development environments. Integration with automated security testing frameworks could enable closed-loop validation where generated code undergoes immediate security assessment. We release SecureCode v2.0, validation frameworks, and evaluation protocols as open-source artifacts, enabling researchers to reproduce results, practitioners to improve AI coding assistants, and educators to teach secure coding through real-world incidents."
        },
        {
            "title": "Availability",
            "content": "Dataset: HuggingFace Hub: https://huggingface.co/datasets/scthornton/securecode-v2 Source Code: GitHub: https://github.com/scthornton/securecode-v2 Validation Framework: https://github.com/scthornton/securecode-v2/blob/main/ validate_contributing_compliance.py All artifacts released under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0) for research and educational use. Commercial use requires separate licensing."
        },
        {
            "title": "Acknowledgments",
            "content": "We thank the security research community for responsible disclosure practices that made incident grounding possible. We thank the three anonymous security experts who provided independent validation with complete consensus. We thank the OWASP Foundation for maintaining the Top 10 taxonomy that guided categorization. We thank MITRE Corporation for maintaining the CVE database that enabled incident mining."
        },
        {
            "title": "References",
            "content": "[1] Veracode. (2025). 2025 GenAI Code Security Report: Assessing the Security of Using LLMs for Coding. Veracode Research. [2] Apiiro Security Research. (2025). The State of Application Security 2025: How AI Coding Copilots Impact Security Posture. Apiiro. [3] CWE-Sans Top 25 Dataset (2019). MITRE Corporation and SANS Institute. Available: https:// cwe.mitre.org/top25/ [4] Boland, T., & Black, P. (2012). Juliet 1.1 C/C++ and Java Test Suite. IEEE Computer, 45(10), 88-90. [5] NIST Software Assurance Reference Dataset (SARD). Available: https://samate.nist.gov/ SARD/ [6] Russell, R., et al. (2018). Automated Vulnerability Detection in Source Code Using Deep Representation Learning. arXiv preprint arXiv:1807.04320."
        }
    ],
    "affiliations": [
        "perfecxion.ai"
    ]
}