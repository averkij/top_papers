{
    "paper_title": "Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction",
    "authors": [
        "Yong Lin",
        "Shange Tang",
        "Bohan Lyu",
        "Ziran Yang",
        "Jui-Hui Chung",
        "Haoyu Zhao",
        "Lai Jiang",
        "Yihan Geng",
        "Jiawei Ge",
        "Jingruo Sun",
        "Jiayun Wu",
        "Jiri Gesi",
        "Ximing Lu",
        "David Acuna",
        "Kaiyu Yang",
        "Hongzhou Lin",
        "Yejin Choi",
        "Danqi Chen",
        "Sanjeev Arora",
        "Chi Jin"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We introduce Goedel-Prover-V2, a series of open-source language models that set a new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate synthetic tasks of increasing difficulty to train the model to master increasingly complex theorems; (2) Verifier-guided self-correction: We enable the model to iteratively revise its proofs by leveraging feedback from the Lean compiler; (3) Model averaging: We merge model checkpoints to mitigate the decrease in model output diversity in later stages of training. Our small model, Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in standard mode and 90.4% in self-correction mode, outperforming prior SOTA by a large margin. Additionally, our flagship model solves 86 problems on PutnamBench at pass@184, securing the first place among open-source models on the leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47 problems by pass@1024 with a significantly smaller model size and compute budget. At the time of its release (July-August 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing models--including closed-source systems with publicly reported performance--under a constrained test-time compute budget. Our models, code, and data are released at https://github.com/Goedel-LM/Goedel-Prover-V2."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 ] . [ 1 3 1 6 3 0 . 8 0 5 2 : r a"
        },
        {
            "title": "Technical Report",
            "content": "GOEDEL-PROVER-V2: SCALING FORMAL THEOREM PROVING WITH SCAFFOLDED DATA SYNTHESIS AND SELF-CORRECTION Yong Lin1, Shange Tang1 2 , Bohan Lyu3 , Ziran Yang1 , Jui-Hui Chung1 , Haoyu Zhao1 , Lai Jiang7 , Yihan Geng8 , Jiawei Ge1, Jingruo Sun4, Jiayun Wu3, Jiri Gesi6 , Ximing Lu2, David Acuna2, Kaiyu Yang5 , Hongzhou Lin6 , Yejin Choi2 4, Danqi Chen1, Sanjeev Arora1, Chi Jin1 1Princeton Language and Intelligence, Princeton University 3Tsinghua University 7Shanghai Jiao Tong University 2NVIDIA 5Meta FAIR 6Amazon 4Stanford University 8Peking University"
        },
        {
            "title": "ABSTRACT",
            "content": "We introduce Goedel-Prover-V2, series of open-source language models that set new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate synthetic tasks of increasing difficulty to train the model to master increasingly complex theorems; (2) Verifier-guided self-correction: We enable the model to iteratively revise its proofs by leveraging feedback from the Lean compiler; (3) Model averaging: We merge model checkpoints to mitigate the decrease in model output diversity in later stages of training. Our small model, Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in standard mode and 90.4% in selfcorrection mode, outperforming prior SOTA by large margin. Additionally, our flagship model solves 86 problems on PutnamBench at pass@184, securing the first place among open-source models on the leaderboard, surpassing DeepSeekProver-V2-671Bs record of solving 47 problems by pass@1024 with significantly smaller model size and compute budget. At the time of its release (JulyAugust 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing models including closed-source systems with publicly reported performanceunder constrained test-time compute budget. Our models, code, and data are released at https://github.com/Goedel-LM/Goedel-Prover-V2."
        },
        {
            "title": "INTRODUCTION",
            "content": "Automated theorem proving (ATP) is grand challenge for AI, requiring the construction of stepby-step, machine-verifiable proofs in formal languages like Lean (De Moura et al., 2015; Moura & Ullrich, 2021). Unlike reasoning in natural language, ATP demands completely rigorous logical flow, which poses an exceptional challenge for AI systems. The field has advanced rapidly in recent years; for example, DeepMinds AlphaProof (Google DeepMind, 2024) and AlphaGeometry (Trinh et al., 2024; Chervonyi et al., 2025) demonstrated that AI systems are capable of achieving IMO (International Math Olympiad) medal-level performance. Furthermore, open-source efforts such as DeepSeek-Prover-V2 (Ren et al., 2025) and Kimina-Prover (Wang et al., 2025) have achieved impressive results on benchmarks like MiniF2F (Zheng et al., 2021) and PutnamBench (Tsoukalas et al., 2024), demonstrating the effectiveness of leveraging the reasoning ability of LLMs through Core Contributor. This work is independent of and outside of the work at Amazon. All experiments and data processing were conducted outside Meta."
        },
        {
            "title": "Technical Report",
            "content": "Figure 1: Performance of Goedel-Prover-V2 on different benchmarks under pass@32. chain-of-thoughts. These successes, however, typically depend on massive models (e.g., DeepSeekProver-V2 has 671B parameters) or computationally intensive inference (e.g., the concurrent work Seed-Prover (Chen et al., 2025)), which involves complex search algorithms and enormous search budgets. In this work we introduce Goedel-Prover-V2, new series of open-source models for automated theorem proving in Lean that establish new state-of-the-art in both performance and computational efficiency. The models are capable of generating whole proof and leveraging verifier feedback for iterative self-correction. Our flagship 32B model achieves 88.1% pass@32 on the MiniF2F benchmark, improving to 90.4% with self-correction. This performance surpasses both the concurrent 72B Kimina-Prover and the previous SOTA 671B DeepSeek-Prover-V2, while using significantly fewer parameters (Figure 1). On the more challenging PutnamBench, our model solves 44 problems (57 with self-correction), more than doubling the number solved by DeepSeek-Prover-V2 under the same metric. The efficiency of our approach is further underscored by our 8B model, which alone outperforms the 671B DeepSeek-Prover-V2 on MiniF2F despite being nearly 80 times smaller. At the time of its release (JulyAugust 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing modelsincluding closed-source systems with publicly reported performanceunder small test-time compute budgets. The key to these gains lies in novel design across the framework, data, and training pipelines. We highlight the main components below: Verifier-guided self-correction: Framework-wise, we incorporate feedback from the Lean compiler (verifier) into the model input to enable the error-correction ability of our theorem prover (verifier-guided self-correction). While correcting errors based on verifier feedback has been studied in theorem proving (First et al., 2023) and coding (Olausson et al., 2024; Chen et al., 2024; Bouzenia et al., 2024), we further incorporate this into models that generate long chain-of-thought (CoT) reasoning, which is effective for complex reasoning tasks such as ATP (Jaech et al., 2024; Guo et al., 2025; Wang et al., 2025; Ren et al., 2025). Scaffolded data synthesis: Successfully combining long CoT with verifier-guided error correction requires special efforts on curating data. In addition to formalizing existing math problems and curating data for error correction, we augment our training statement set through scaffolded data synthesis. This technique creates math problems at an appropriate difficulty level to provide the model with better learning signals. Model averaging: Our training recipe extends beyond standard expert iteration and reinforcement learning. We also apply model averaging (Wortsman et al., 2022b) to mitigate the decrease in model output diversity that can occur in the later stages of training. Overall, our results demonstrate that the frontier of formal theorem proving can be advanced without access to extremely large models, vast computational resources, or proprietary technology. We hope"
        },
        {
            "title": "Technical Report",
            "content": "that our open-source theorem prover series, Goedel-Prover-V2, will enable the community to build upon them and accelerate progress toward AI systems that can reliably solve and verify complex mathematical problems, and ultimately bridge the long-standing divide between intuitive human reasoning and formal proof verification. The following paper is organized as follows: in Section 2, we introduce our main methods to train Goedel-Prover-V2, including the verifier-guided self-correction framework (Section 2.1), scaffolded data synthesis (Section 2.2), and the training pipeline (Section 2.3). In Section 3, we present the evaluation results on Goedel-Prover-V2, including evaluation on both standard and our curated benchmarks (Section 3.3), scaling behavior under different test-time budgets (Section 3.4), and study of reinforcement learning and model averaging (Section 3.6). Finally, we review the previous works (Section 4) and discuss the connection with Goedel-Prover-V2."
        },
        {
            "title": "2 METHOD",
            "content": "In this section, we present our method in detail. We start with the key framework innovation compared to the previous vanilla whole-proof generation methods (e.g. DeepSeek-Prover-V2) by utilizing the feedback from the Lean compiler to guide the proof-correction procedure (Section 2.1). Then, in Section 2.2, we demonstrate how to curate the training data (statements), with an emphasis on augmenting the data through scaffolded data synthesis. Based on the curated data, we present the details of training our theorem prover in Section 2.3, which includes supervised fine-tuning (SFT), reinforcement learning (RL), and model averaging. Section 2.4 provides summary of the overall framework."
        },
        {
            "title": "2.1 CHAIN-OF-THOUGHT AND SELF-CORRECTION",
            "content": "Prevailing paradigms for whole-proof generation in automated theorem proving have largely been end-to-end, where model generates complete formal proof from theorem statement in single pass (Xin et al., 2024b; Lin et al., 2025; Dong & Ma, 2025). Recent work has significantly advanced this approach by leveraging the long-chain-of-thought reasoning capabilities of large models (Wang et al., 2025; Ren et al., 2025). key distinction between informal and formal proof generation lies in the availability and utilization of compilation (verification) feedback from proof assistants like Lean or Coq. Humans naturally leverage such feedback to iteratively revise their proofs. Recent works have shown that integrating the verifiers error messages or tactic verification outcomes into proof generation significantly improves synthesis accuracy (First et al., 2023). Our framework formalizes this intuition by explicitly incorporating verifier feedback within the wholeproof generation loop. We structure the pipeline so that, after an initial proof attempt, verification failures are parsed and communicated back into the model as corrective guidance. The model then generates proof repairs, leading to an iterative self-correction process."
        },
        {
            "title": "2.2 CURATING FORMAL STATEMENTS",
            "content": "In this part, we detail our methods for curating large, high-quality dataset of Lean 4 statements, which is essential for expert iteration and RL in formal theorem proving. We start with the formalizer training, which is the core of translating existing math problems written in natural language into Lean statements. We then present our scaffolded data synthesis pipeline that creates math problems at an appropriate difficulty level, which includes lightweight formal-based method that utilizes the Lean system, and an informal-based system for large-scale data augmentation. Formalizer Training. Existing Lean datasets (e.g., Goedel-Pset-v1) contain many low-quality problemshuman evaluation on sampled subset shows that over 80% of unsolved problems are incorrectly formalized. This highlights the need for stronger formalizers. We train our formalizer using the standard expert iteration pipeline, which combines Lean syn-"
        },
        {
            "title": "Pass Failed",
            "content": "Kimina-autoformalizer Goedel-Formalizer-V2 161 228 139 72 Table 1: Comparison of different formalizers on 300 Omni-math problems."
        },
        {
            "title": "Technical Report",
            "content": "Figure 2: Our informal-based scaffolded data synthesis pipeline with three parts: (1) informal statement generation; (2) formalization and quality checking; and (3) negation and difficulty filtering. tax checks and semantic evaluation via LLMs to assess translation quality. Only statements that pass both checks are included in the next iteration of SFT. Details of the LLM semantic evaluation prompt are provided in Appendix C. To initialize expert iteration, we prompt Claude Sonnet 4 to generate 50K formalized statements, along with corresponding reasoning traces. Incorporating reasoning capability enables our formalizer to outperform previous models such as Goedel-Formalizer-V1 and Kimina-Autoformalizer, which lack this feature. We evaluate our model Goedel-Formalizer-V2 and Kimina-Autoformalizer on benchmark of 300 OmniMath problems. Results are shown in Table 1. Formal-based scaffolded data synthesis. When the prover fails to find proof for challenging problem, we can still leverage the proof attempt to generate simpler, related problems. The intuition is that even an incorrect proof attempt may introduce valid subgoals that represent easier subproblems. We utilize powerful tactic in Lean, extract goal, to capture the unsolved states of proof. These extracted goals (together with the preconditions), which are well-formed mathematical statements, are then used to augment our training data for the next phase. Since an extracted statement is not guaranteed to be provable, we also include its negation, thereby training the model to recognize both true and false propositions. Informal-based scaffolded data synthesis. Another way of scaffolded data synthesis is to leverage the current LLMs mathematical reasoning ability in natural language, to create math statements at the right level for the model to learn. For given problem, we prompt an LLM (Qwen3-32B) to generate simpler/sub-problems if it is unsolved, or harder variants if it is already solved. To improve generation quality, we first have the LLM attempt natural language solution to the original problem, using its output as context. The generated informal statements are then formalized into Lean by the formalization pipeline we described in Formalizer Training. To avoid the inference overhead of incorrect or trivial statements, we use an LLM-based filter that assesses each statement for correctness and difficulty, where trivial or mathematically incorrect statements are discarded (the negation of incorrect statements are also added to the dataset). This filtering process significantly accelerates data synthesis, with minor trade-off in potentially discarding some valid statements due to LLM judgment errors. The prompts and further details are in Appendix D."
        },
        {
            "title": "2.3 TRAINING ALGORITHMS",
            "content": "Supervised fine-tuning and expert iteration. We follow the standard pipeline of Expert Iteration by iterating between using the model to conduct large-scale inference on the statement sets, collecting"
        },
        {
            "title": "Technical Report",
            "content": "Figure 3: The overall workflow of model training. +AVG denotes that the trained model is averaged with the base model after training. RL-AVG is the final output model. Detailed descriptions are provided in Section 2.4. correct proofs with reasoning traces, and fine-tuning the model further by Supervised Fine-tuning (SFT) on the collected samples. Reinforcement learning. We aim to train model capable of generating complete proofs and correcting its own errors via verifier-guided self-correction. To this end, we adopt an efficient hybrid strategy. We first sample multiple complete proofs in parallel. For each sampled proof, we perform serial self-correction, generating one correction per round. This serial correction process aligns well with RL, which optimizes expected reward and has been shown to improve single-shot (pass@1) accuracy (Shao et al., 2024; Yue et al., 2025). Our RL implementation adopts multi-task setup (illustrated in Appendix Figure 9): 50% of the inputs are used for whole proof generation, and the remaining 50% for first-round self-correction. We train for single epoch, using approximately 46K and 67K unique inputs for the 8B and 32B models, respectively. On the algorithmic side, we use hybrid GRPO-based approach (Shao et al., 2024). Compared to vanilla GRPO, our method removes group normalization as suggested by Dr.GRPO (Liu et al., 2025) to avoid inherent bias on length, incorporates clip-higher, overlong penalties, and dynamic sampling from DAPO (Yu et al., 2025), and excludes the KL regularization term from the objective to encourage exploration. key observation is that question difficulty significantly impacts RL training. To address this, we modify the dynamic sampling strategy to only include problems with pass rates in the range (0, 0.75] during optimization. For further implementation details, see Appendix E.1. Model averaging for enhanced diversity. We observed that in the later stages of SFT and RL, the models diversity decreases. This is reflected by an increase in pass@1 but decline in pass@N for larger values of N, such as N=32. We adopts model averaging to enhance model diversity (Wortsman et al., 2022b;a; Lin et al., 2023a;b; Dang et al., 2025) . Specifically, let the parameters of the base model be denoted as θ0, and those of the fine-tuned model as θ. We use the combined model parameters defined as (1 α)θ0 + αθ, where α (0, 1). Existing literature has demonstrated that this simple approach can significantly improve the feature diversity of the final model. Our observations also confirm that this method effectively enhances pass@N. We perform model averaging at each stage of the process. Specifically, we apply model averaging after completing SFT and use the averaged model as the starting point for RL. Once RL is completed, we perform model averaging again and use this averaged model as the final model."
        },
        {
            "title": "2.4 WHOLE PIPELINE: PUTTING EVERYTHING TOGETHER",
            "content": "The pipeline consists of the following steps: We utilize Deepseek-Prover-V2-7B and Deepseek-Prover-V2-671B to perform large-scale inference, producing an initial supervised fine-tuning (SFT) dataset S1 for complete proof generation."
        },
        {
            "title": "Technical Report",
            "content": "We employ S1 to conduct SFT on both Qwen3-8B and Qwen3-32B, resulting in fine-tuned models SFT-S1 for both the 8B and 32B variants1. Using SFT-S1 and Deepseek-Prover-V2-671B, we annotate self-correction data. The selfcorrection data from Deepseek-Prover-V2-671B is inferenced using NeMo-Skills2 with 144 H100s. This data is then incorporated back into S1 to create an enhanced dataset S2. We subsequently perform SFT on both model sizes using S2, yielding improved models SFT-S2. We perform model averaging between SFT-S2 and the base model for both the 8B and 32B models, resulting in SFT-S2-AVG. We perform scaffolded data synthesis with SFT-S2-AVG to generate the dataset S3. Continuing the SFT process, we further improve the models by training SFT-S2-AVG on S3, yielding SFT-S3, and subsequently obtain the averaged model SFT-S3-AVG. We apply reinforcement learning to the SFT-S3-AVG and conduct model averaging and obtain the final model RL-AVG. The overall workflow is illustrated in Fig. 3."
        },
        {
            "title": "3 EVALUATION",
            "content": "This section presents our experiment results on Goedel-Prover-V2. We first discuss our evaluation benchmarks (Section 3.1). Then, we discuss our main evaluation results on the selected benchmarks (Section 3.3), and correspondingly the scaling behavior (Section 3.4). Finally, we investigate the performance of reinforcement learning and model averaging (Section 3.6)."
        },
        {
            "title": "3.1 BENCHMARKS",
            "content": "MiniF2F. MiniF2F (Zheng et al., 2021) consists of 488 problem statements (244 validation and 244 test problems) in Lean. The problems are drawn from high-school level competitions including the AMC, AIME, and the International Mathematical Olympiad (IMO). We use the version of MiniF2F provided by Kimina (Wang et al., 2025)3, which has some incorrect statements fixed. PutnamBench. PutnamBench (Tsoukalas et al., 2024) focuses on college-level mathematics competition problems that are sourced from the William Lowell Putnam Mathematical Competition years 1962 - 2023. PutnamBench comprises 644 problems, covering algebra, analysis, number theory, geometry, combinatorics, probability, and set theory. MathOlympiadBench. We constructed MathOlympiadBench, which comprises 360 humanverified formalizations of Olympiad-level mathematical problems, sourced from Compfiles 4 and IMOSLLean4 repository 5. It contains 158 IMO problems from 1959 to 2024, 131 IMO shortlist problems covering 2006 to 2023, 68 national mathematical Olympiad problems, and 3 additional mathematical puzzles. The statistic of problem categories in MathOlympiadBench is presented in Figure 4, and Figure 5 visualizes humans formalizing and solving status of IMO problems in MathOlympiadBench. See Appendix for more details of MathOlympiadBench and its comparison with MiniF2F."
        },
        {
            "title": "3.2 EVALUATED METHODS",
            "content": "Following previous works (Xin et al., 2024b; Lin et al., 2025; Dong & Ma, 2025; Ren et al., 2025) the evaluations are done under Lean 4.9.0-rc1. For the first round of whole-proof generation, the max token length of the model is set to be 30,000. For the verifier-guided error-correction, we sequentially conduct 2 additional rounds of self-correction, given the verifiers feedback on the previous attempt. The total number of tokens in the self-correction mode is set to be 40,000. We report the pass@N metric. 1We use https://github.com/hiyouga/LLaMA-Factory for SFT. 2https://github.com/NVIDIA/NeMo-Skills 3https://huggingface.co/datasets/AI-MO/minif2f_test 4https://dwrensha.github.io/compfiles/imo.html 5https://github.com/mortarsanjaya/IMOSLLean"
        },
        {
            "title": "Technical Report",
            "content": "Figure 4: Distribution of problems in MathOlympiadBench by category."
        },
        {
            "title": "3.3 MAIN RESULTS",
            "content": "Figure 5: Communitys achievement on IMO problems by year and problem index. Each cell represents problem: statement not formalized, not solved, and solved. Table 2: Performance of different whole-proof generation methods on MiniF2F test split. denotes concurrent work Method Budget Performance Goedel-Prover-SFT (Lin et al., 2025) STP (Dong & Ma, 2025) Kimina-Prover-Preview-72B (Wang et al., 2025) DeepSeek-Prover-V2-7B (Ren et al., 2025) DeepSeek-Prover-V2-671B Kimina-Prover-8B (Wang et al., 2025) Kimina-Prover-70B w/ TTRL Goedel-Prover-V2-8B w/ self-correction Goedel-Prover-V2-32B w/ self-correction 32 3200 128 3200 25600 32 8192 32 8192 32 8192 57.6% 0.7% 62.7% 61.2% 0.6% 65.0% 0.5% 67.6% 68.85% 80.74% 75.6% 0.5% 82.0% 82.4% 0.6% 88.9% 32 32 1024 unknown 78.3% 84.0% 87.7% 92.2% 32 1024 8192 32 1024 32 1024 8192 32 1024 84.6% 0.6% 87.9% 90.2% 86.7% 0.2% 89.3% 88.1% 0.8% 91.8% 92.2% 90.4% 0.6% 92.6% The evaluation results of Goedel-Prover-V2 on MiniF2F are summarized in Table 2, and results on PutnamBench are shown in Table 3. The results for MathOlympiadBench are presented in the rightmost figure of Figure 1. Below, we summarize and discuss the results. High performance at modest scale. Our 32B model achieves pass@32 accuracy of 88.1% on MiniF2F, with 90.4% after 2 rounds of error-correction, exceeding the previous state-of-the-art DeepSeek-Prover-V2-671Bs 82.4% while using far fewer parameters. Even the 8B variant achieves"
        },
        {
            "title": "Technical Report",
            "content": "84.6%, nearly matching or outperforming Kimina-Prover-70Bs results under the same inference budget, and outperforming the previous SOTA DeepSeek-Prover-V2-671B on MiniF2F, with an significant smaller model size. On PutnamBench, our 32B model solves 43 problems under pass@32, nearly doubling the DeepSeek-Prover-V2-671B models performance under the same budget. With errorcorrection, Goedel-Prover-V2-32B solves 57 problems under pass@32, outperforming DeepSeekProver-V2-671B under pass@1024. Under pass@184 and error correction, Goedel-Prover-V2-32B solves 86 on PutnamBench, securing the best open-source theorem prover on the leaderboard. Table 3: Comparison of different models on PutnamBench. Our Goedel-Prover-V2 with compiler-guided self-correction solves 86 problems from PutnamBench, improving the previous SOTA (DeepSeek-Prover-V2) by 39 more problems, and securing the best opensource model on the leaderboard.* compute # Model num-solved 1 Goedel-Prover-V2 (self-correction mode) 1 Goedel-Prover-V2 (self-correction mode) 1 Goedel-Prover-V2 2 DeepSeek-Prover-V2 2 DeepSeek-Prover-V2 3 DSP+ 4 Bourbaki 5 Kimina-Prover-7B-Distill Self-play Theorem Prover 6 7 Goedel-Prover-SFT 8 ABEL * concurrent work, Seed Prover (Chen et al., 2025), successfully solved 331 problems on PutnamBench. However, the prover is not open-source, and it is not clear what the computational budget is at test time (which is expected to be much larger than ours). pass@184 pass@32 pass@32 pass@1024 pass@32 pass@128 pass@512 pass@192 pass@3200 pass@512 pass@596 86 57 43 47 22 23 14 10 8 7 7 open-source Efficacy of verifier-guided self-correction. Adding self-correction provides consistent gain of approximately 2 percentage points in pass@32 for both models on MiniF2F. On PutnamBench, error correction leads to 14 more solves under pass@32. This demonstrates that integrating Lean compiler feedback into long-chain-of-thought revision pipeline enables the model to identify errors and repair them effectively. Sample-efficient inference. Unlike prior models such as Kimina-Prover and DeepSeek-Prover-V2, which rely heavily on large sampling budgets or test-time reinforcement learning to reach peak accuracy, Goedel-Prover-V2 attains very high pass@N with minimal inference overhead (N=32 or 64), indicating that the model internalizes powerful reasoning strategies during training. The sample efficiency, together with the relatively small size, makes Goedel-Prover-V2 series very good candidate for the community to develop new algorithms and test on different benchmarks."
        },
        {
            "title": "3.4 SCALING ANALYSIS",
            "content": "Figure 6 and Table 4 illustrate the scaling behavior of Goedel-Prover-V2 (8B and 32B variants) across different inference budgets, compared against DeepSeek-Prover-V2 (7B and 671B) and Kimina-Prover-72B. At the lower sampling regime (pass@32), Goedel-Prover-V2-32B already achieves 88.1%, notably surpassing DeepSeek-Prover-V2671B (82.4%) and Kimina-Prover-72B (84.0%). This advantage persists across inference budgets, with our self-correction mode providing approximately 2-point performance improvement under pass@32 and pass@64, peaking at 92.6% at pass@8192. The smaller 8B model also demonstrates strong scalability, surpassing the 671B DeepSeek model at all budgets. 8 Figure 6: Scaling behavior on MiniF2F test split."
        },
        {
            "title": "Technical Report",
            "content": "Model 32B (self-correction mode) 32B 8B (self-correction mode) 8B 32 90.4 88.1 86.7 84.6 64 91.4 89.8 86.9 86. 128 91.9 90.5 87.4 86.5 256 92.3 91.0 88.0 87.0 512 92.4 91.6 88.5 87. 1024 2048 4096 8192 92.6 91.8 89.3 87.9 92.0 88. 92.2 89.3 92.2 90.2 Table 4: The performance (%) of Goedel-Prover-V2 on MiniF2F across different compute budget. These results indicate that Goedel-Prover-V2 efficiently internalizes reasoning during training, requiring fewer inference samples to achieve comparable or superior accuracy. Furthermore, the consistent gains from verifier-guided self-correction across all inference budgets further underscore the value of combining error correction with long-chain-of-thought reasoning in formal theorem proving."
        },
        {
            "title": "3.5 ANALYSIS OF SELF-CORRECTION",
            "content": "In our main experiments, self-correction was conducted for maximum of 2 rounds with 40k token context length. To further explore its capabilities, we used YaRN (Peng et al., 2024) to extend the context length to 128k tokens and allowed up to 5 revision iterations. We conducted series of experiments on the MiniF2F benchmark at pass@32, the results of which are presented in Figure 7. Alongside our standard prompting setup (Self Correction), we performed two ablation studies: (1) removing the specific compiler error messages (w/o Error Messages), and (2) removing the chain-ofthought from previous attempts, retaining only the formal proof (w/o Previous CoTs). Figure 7: Ablation study on self-correction with extended context length and revision iterations on the MiniF2F test split at pass@32. The results show that removing compiler feedback significantly lowers performance, confirming that specific error messages are crucial for effective revision. Similarly, removing the reasoning from previous attempts also slightly degrades performance, indicating that retaining the chain-of-thought from prior rounds is beneficial. Furthermore, with an extended context and more revision iterations, the full self-correction models pass@32 accuracy on MiniF2F reaches an average of 92.7%, which surpasses the 92.2% performance of the model without self-correction at pass@8192, highlighting the sample efficiency of our iterative revision process."
        },
        {
            "title": "3.6 RL AND MODEL AVERAGING",
            "content": "We systematically evaluate the impact of RL steps and model averaging strategies on the performance of Goedel-Prover-V2. Specifically, for RL checkpoints at steps 60, 80, and 90, we apply model averaging with coefficients α = 0.6, 0.7, 0.8, 0.9 (where α is the weight of the base model). We assess each averaged model in both vanilla (whole-proof generation) and correction (with self-correction) settings, evaluating both pass@1 and pass@N, as visualized in Figure 8. For both vanilla and correction settings, pass@1 consistently increases as the number of RL steps grows. For vanilla pass@N, performance stabilizes at higher RL steps, whereas in the correction setting, pass@N continues to improve. This indicates that correction benefits more from RL, likely due to the shortage of high-quality self-correction data in the SFT stages. Examining different values of α, we observe that higher proportion of the base model (i.e., lower α) leads to lower pass@1, but pass@N first rises and then falls as α increases. There exists an optimal model averaging ratio that maximizes pass@N. This trend holds for both vanilla and correction settings, with the improvement being more pronounced for correction. This suggests that model averaging not only improves sample diversity but also amplifies the benefits of RL-driven self-correction."
        },
        {
            "title": "Technical Report",
            "content": "Figure 8: The effects of varying RL steps and model averaging ratios on the pass@1 and pass@32 performance of models, both with and without correction."
        },
        {
            "title": "4 RELATED WORKS",
            "content": "Formal Theorem Proving as Whole Proof Generation. Inspired by the success of end-to-end reasoning in informal LLMs, recent foundational work in formal theorem proving has adopted similar strategy: generating entire Lean proofs in single pass. While informal reasoning models often struggle with step verificationproducing fluent yet logically flawed arguments (Petrov et al., 2025)formal settings like Lean (De Moura et al., 2015) offer precise and executable verifier that enforces correctness. Leveraging this, models such as DeepSeek-Prover (Xin et al., 2024a), Goedel Prover (Lin et al., 2025), and Kimina Prover (Wang et al., 2025) demonstrate that end-to-end generation can produce formally verified proofs that are immediately checkable by the Lean proof assistant. This paradigm retains the global coherence and simplicity of sequence generation while grounding outputs in verifiable formal logic. Formal Theorem Proving using Proof Search. In contrast to end-to-end generation, proof searchbased methods guide the model to incrementally construct proofs by exploring derivation paths with verifier feedback at each step. Recent systems such as InternLM2.5-StepProver (Wu et al., 2024), Hunyuan Prover (Li et al., 2024), DeepSeek-Prover v1.5 (Xin et al., 2024b), and BFS Prover (Xin et al., 2025) employ tree search algorithmssuch as Monte Carlo Tree Search or breadth-first searchto explore multiple proof trajectories and iteratively assemble valid proofs. While this strategy improves correctness, it comes at the cost of significantly higher computational overhead, as the model must evaluate and verify large number of partial branches. Recently, hybrid methods, which use general-purpose (strong) LLM to write the proof sketch and query theorem provers to fill in the proof for small steps, also emerged (DSP+ (Cao et al., 2025) and the concurrent work Delta-Prover (Zhou et al., 2025)). However, these works usually require the LLM to be very large and powerful, where DSP+ uses 671B DeepSeek-R1 (Guo et al., 2025) or DeepSeek-V3 (Liu et al., 2024), and Delta-Prover uses Gemini (Comanici et al., 2025). Notably, Seed-Prover (Chen et al., 2025) employs wide range of techniques, including extensive test-time search and refinement, and achieves IMO medal-level performance. However, it requires substantial computational resources. Self-Repair and Verifier-Guided Refinement. While tree-based proof search improves correctness, its high computational cost has motivated the development of more efficient mechanisms for guiding search and enabling self-refinement. One direction explores how auxiliary signals or intermediate structures can streamline the reasoning process. Jiang et al. (2023); Gloeckle et al. (2024); Cao et al. (2025) bridge informal and formal reasoning by using informal sketches as skeleton for formal proof generation, while Yang et al. (2024) employs retrieval-augmented generation (RAG) to retrieve relevant theorems from formal libraries during proof construction. Other approaches, such as Ji et al. (2025), implement self-verification and iterative refinement loops, allowing models to autonomously revise candidate proofs using verifier feedback. Verifier-in-the-loop strategies in recent works (Baba et al., 2025; Zhou et al., 2025; Ren et al., 2025; Wang et al., 2025; Chen et al., 2025), also highlight the benefits of interactive feedback, improving success rates through iterative correction rather than brute-force search. These methods collectively"
        },
        {
            "title": "Technical Report",
            "content": "point to more flexible and scalable paradigm: enabling the model to diagnose and repair its own outputs with minimal external supervision. Goedel-Prover-V2 builds on this trajectory by adopting self-revision framework, where the model iteratively proposes and refines candidate proofs until they satisfy the Lean checker. This architecture draws inspiration from general-purpose self-repair frameworks in coding and reasoning (Yao et al., 2023; Shinn et al., 2023; First et al., 2023; Olausson et al., 2024; Chen et al., 2024; Bouzenia et al., 2024), bringing their iterative refinement loop into the domain of formal mathematics with long chain-of-thought reasoning."
        },
        {
            "title": "5 CONCLUSION AND DISCUSSION",
            "content": "In this work, we introduced Goedel-Prover-V2, series of state-of-the-art open-source theorem provers that significantly advance automated formal proof generation. Our key innovation is the integration of long-chain-of-thought reasoning with compiler-guided self-correction, addressing crucial gap overlooked by prior methods. Through scaffolded data synthesis, SFT and RL training, and model averaging, our models achieve state-of-the-art performance among open-source provers. In particular, our 32B model achieves 88.1% on MiniF2F at pass@32 and benefits further from self-correction and reaching 90.4% on MiniF2F at pass@32, outperforming larger models with lower inference cost. Moreover, our 8B model also outperforms the previous SOTA DeepSeek-Prover-V2671B under pass@32 on MiniF2F with significant smaller model size. We also investigate proof repair strategy as test-time alternative to standard pass@k sampling. Instead of regenerating an entire failed proof, our method corrects only the faulty segment. We use Lean 4s compiler feedback and the extract goal tactic to isolate the unsolved subgoal, prompt the prover to solve it independently, and then reinsert the correct solution into the original proof. On the MiniF2F benchmark, this approach improves the amortized budget scaling curve by 12 percentage points, highlighting inference-time scaling strategies as key direction for future work. By open-sourcing all trained models, we aim to catalyze further advancements in formal reasoning research. We envision that the release of Goedel-Prover-V2 will not only establish new benchmark for automated theorem proving but also provide practical, efficient platform upon which future innovations can be built."
        },
        {
            "title": "ACKNOWLEDGEMENT",
            "content": "This project was the result of close collaborative effort by all authors, and every major component benefited from joint discussion and iteration. The author would like to thank Igor Gitman for support with the curation of self-correction data. HZ and SA acknowledge the support from Schmidt, Darpa, ONR, and NSF. CJ acknowledges the support from NSF-OAC-2411299, NSF-IIS-2239297, and Princeton AI Lab Seed Fund."
        },
        {
            "title": "REFERENCES",
            "content": "Kaito Baba, Chaoran Liu, Shuhei Kurita, and Akiyoshi Sannai. Prover agent: An agent-based framework for formal mathematical proofs. arXiv preprint arXiv:2506.19923, 2025. Islem Bouzenia, Premkumar Devanbu, and Michael Pradel. Repairagent: An autonomous, llm-based agent for program repair. arXiv preprint arXiv:2403.17134, 2024. Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, and Fan Yang. Reviving dsp for advanced theorem proving in the era of reasoning models. arXiv preprint arXiv:2506.11487, 2025. Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, and Thomas Hanwen"
        },
        {
            "title": "Technical Report",
            "content": "Zhu. Seed-prover: Deep and broad reasoning for automated theorem proving, 2025. URL https://arxiv.org/abs/2507.23726. Xinyun Chen, Maxwell Lin, Nathanael Scharli, and Denny Zhou. Teaching large language models to self-debug. In The Twelfth International Conference on Learning Representations, 2024. Yuri Chervonyi, Trieu Trinh, Miroslav Olˇsak, Xiaomeng Yang, Hoang Nguyen, Marcelo Menegali, Junehyuk Jung, Vikas Verma, Quoc Le, and Thang Luong. Gold-medalist performance in solving olympiad geometry with AlphaGeometry2. arXiv preprint arXiv:2502.03544, 2025. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Xingyu Dang, Christina Baek, Zico Kolter, and Aditi Raghunathan. Assessing diversity collapse in reasoning. In Scaling Self-Improving Foundation Models without Human Supervision, 2025. Leonardo De Moura, Soonho Kong, Jeremy Avigad, Floris Van Doorn, and Jakob von Raumer. The lean theorem prover (system description). In Automated Deduction-CADE-25: 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings 25, pp. 378388. Springer, 2015. Kefan Dong and Tengyu Ma. STP: Self-play LLM theorem provers with iterative conjecturing and proving. In International Conference on Machine Learning (ICML), 2025. Emily First, Markus Rabe, Talia Ringer, and Yuriy Brun. Baldur: Whole-proof generation and repair with large language models. In ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), 2023. Fabian Gloeckle, Jannis Limperg, Gabriel Synnaeve, and Amaury Hayat. Abel: Sample efficient online reinforcement learning for neural theorem proving. In The 4th Workshop on Mathematical Reasoning and AI at NeurIPS24, 2024. Google DeepMind. olympiad matical ai-solves-imo-problems-at-silver-medal-level/, 2024. problems."
        },
        {
            "title": "AI achieves",
            "content": "silver-medal standard solving international mathehttps://deepmind.google/discover/blog/ Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024. Xingguang Ji, Yahui Liu, Qi Wang, Jingyuan Zhang, Yang Yue, Rui Shi, Chenxi Sun, Fuzheng Zhang, Guorui Zhou, and Kun Gai. Leanabell-prover-v2: Verifier-integrated reasoning for formal theorem proving via reinforcement learning. arXiv preprint arXiv:2507.08649, 2025. Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothee Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, and Yuhuai Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, 2023. Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, and Haitao Mi. Hunyuanprover: scalable data synthesis framework and guided tree search for automated theorem proving. arXiv preprint arXiv:2412.20735, 2024. Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, et al. Mitigating the alignment tax of rlhf. arXiv preprint arXiv:2309.06256, 2023a."
        },
        {
            "title": "Technical Report",
            "content": "Yong Lin, Lu Tan, Yifan Hao, Honam Wong, Hanze Dong, Weizhong Zhang, Yujiu Yang, and Tong Zhang. Spurious feature diversification improves out-of-distribution generalization. arXiv preprint arXiv:2309.17230, 2023b. Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, et al. Goedel-Prover: frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025. Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024. Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee Sun Lee, and Min Lin. Understanding r1-zero-like training: critical perspective. arXiv preprint arXiv:2503.20783, 2025. Leonardo de Moura and Sebastian Ullrich. The Lean 4 theorem prover and programming language. In International Conference on Automated Deduction (CADE), 2021. Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama. Is self-repair silver bullet for code generation? In The Twelfth International Conference on Learning Representations, 2024. Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. YaRN: Efficient context window extension of large language models. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=wHBfxhZu1u. Ivo Petrov, Jasper Dekoninck, Lyuben Baltadzhiev, Maria Drencheva, Kristian Minchev, Mislav Balunovic, Nikola Jovanovic, and Martin Vechev. Proof or bluff? evaluating llms on 2025 usa math olympiad. arXiv preprint arXiv:2503.21934, 2025. ZZ Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, et al. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition. arXiv preprint arXiv:2504.21801, 2025. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. Hybridflow: flexible and efficient rlhf framework. arXiv preprint arXiv: 2409.19256, 2024. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: language agents with verbal reinforcement learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. Trieu Trinh, Yuhuai Wu, Quoc Le, He He, and Thang Luong. Solving olympiad geometry without human demonstrations. Nature, 625(7995):476482, 2024. George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, and Swarat Chaudhuri. Putnambench: Evaluating neural theorem-provers on the putnam mathematical competition. arXiv preprint arXiv:2407.11214, 2024. Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, et al. Kimina-prover preview: Towards large formal reasoning models with reinforcement learning. arXiv preprint arXiv:2504.11354, 2025. Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et al. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In International conference on machine learning, pp. 2396523998. PMLR, 2022a."
        },
        {
            "title": "Technical Report",
            "content": "Mitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 79597971, 2022b. Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Jiayu Wang, Dahua Lin, and Kai Chen. InternLM2.5-StepProver: Advancing automated theorem proving via expert iteration on large-scale lean problems. arXiv preprint arXiv:2410.15700, 2024. Huajian Xin, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, and Xiaodan Liang. Deepseek-prover: Advancing theorem proving in llms through large-scale synthetic data. arXiv preprint arXiv:2405.14333, 2024a. Huajian Xin, ZZ Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, et al. Deepseek-prover-v1. 5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024b. Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, and Ming Ding. BFS-prover: Scalable best-first tree search for LLM-based automatic theorem proving. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, 2025. Kaiyu Yang, Aidan Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, and Animashree Anandkumar. Leandojo: Theorem proving with retrieval-augmented language models. Advances in Neural Information Processing Systems, 36, 2024. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, et al. Dapo: An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476, 2025. Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Shiji Song, and Gao Huang. Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model? arXiv preprint arXiv:2504.13837, 2025. Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. Minif2f: cross-system benchmark for formal olympiad-level mathematics. arXiv preprint arXiv:2109.00110, 2021. Yichi Zhou, Jianqiu Zhao, Yongxin Zhang, Bohan Wang, Siran Wang, Luoxin Chen, Jiahui Wang, Haowei Chen, Allan Jie, Xinbo Zhang, et al. Solving formal math problems by decomposition and iterative reflection. arXiv preprint arXiv:2507.15225, 2025."
        },
        {
            "title": "A DETAILS OF MATHOLYMPIADBENCH",
            "content": "MathOlympiadBench is human-processed to eliminate several issues presented in the source problems: 1. incomplete problem statements, 2. distribution across multiple files, 3. multiple theorems per problem, and 4. incompatibility with the commonly used Mathlib. The verification process ensures that each problem contains exactly one formal theorem with its corresponding informal statement, and confirms that all formal statements can pass the compilation with the sorry tactic. We compared the IMO problems shared between MathOlympiadBench and MiniF2F, and identified at least 3 cases in MiniF2F exhibiting issues such as: 1. the formal statement to be proved is strictly weaker than the informal statement, and 2. the formal statement does not match the informal statement. Notably, similar issues are not observed for these problems in MathOlympiadBench. In the following, we present three case studies comparing the problem formalizations in MiniF2F and MathOlympiadBench. A.1 IMO 1981, PROBLEM 6: SPECIFIC VALUE VS. GENERAL FORMULA"
        },
        {
            "title": "MathOlympiadBench",
            "content": "1 /-! 2 # International Mathematical Olympiad 1981, Problem 6 3 4 Suppose that : satisfies MiniF2F 1 /-- 2 The function (x, y) satisfies 3 4 (1) (0, y) = + 1, 5 6 (2) (x + 1, 0) = (x, 1), 7 8 (3) (x + 1, + 1) = (x, (x + 1, y)), 9 10 for all non-negative integers x, . Determine (4, 1981). 11 -/ 12 13 theorem imo_1981_p6 (f : N) 5 6 1) (0, y) = + 1 7 2) (x + 1, 0) = (x, 1), 8 3) (x + 1, + 1) = (x, (x + 1, y)) 9 10 for all N. 11 12 Determine (4, 1981). 13 -/ 14 15 def no_eval (x : N) : := 16 abbrev solution_value : := 17 no_eval ((2ˆ)ˆ[1984] 1 - 3) 18 19 theorem imo1981_p6 (f : N) 14 15 16 18 (h0 : y, 0 = + 1) (h1 : x, (x + 1) 0 = 1) (h2 : y, (x + 1) (y + 1) = (f (x + 1) y)) : y, 4 (y + 1) = 2 ˆ (f 4 + 20 21 22 24 (h1 : y, 0 = + 1) (h2 : x, (x + 1) 0 = 1) (h3 : y, (x + 1) (y + 1) = (f (x + 1) y)) : 4 1981 = solution_value := 3) - 3 := by sorry The informal statement requires computing the exact value of (4, 1981), specific number. However, the MiniF2F formalization only asks to prove general recurrence relation, which is an intermediate step in the solution process. This discrepancy can make the formal proof substantially easier than solving the original problem. In contrast, MathOlympiadBench faithfully translates the original problem into formal language, requiring the proof of the final numerical value as demanded by the IMO statement."
        },
        {
            "title": "Technical Report",
            "content": "A.2 IMO 1983, PROBLEM 6: INCOMPLETE VS. FULL CONDITION"
        },
        {
            "title": "MathOlympiadBench",
            "content": "1 /-! 2 # International Mathematical Olympiad 1983, Problem 6 3 4 Suppose that a,b,c are the side lengths of triangle. Prove that 5 6 a2b(a b) + b2c(b c) + c2a(c a) 0. MiniF2F 1 /-- Let a, and be the lengths of the sides of triangle. Prove that 2 3 a2b(a b) + b2c(b c) + c2a(c a) 0. 4 5 Determine when equality occurs. 6 -/ 7 8 theorem imo_1983_p6 (a : R) 9 (h0 : 0 < 0 < 0 < c) (h1 : < + b) (h2 : < + c) (h3 : < + c) : 0 aˆ2*b*(a-b) + bˆ2*c*(b-c) + cˆ2*a*(c-a) := by 10 11 12 12 17 18 19 20 21 7 8 Determine when equality occurs. 9 -/ 10 11 abbrev EqualityCondition (a : R) : Prop := = = 13 14 theorem imo1983_p6 15 (T : Affine.Triangle (EuclideanSpace (Fin 2))) : let := dist (T.points 1) (T.points 2) let := dist (T.points 0) (T.points 2) let := dist (T.points 0) (T.points 1) 0 aˆ2*b*(a-b) + bˆ2*c*(b-c) + cˆ2*a*(c-a) (0 = aˆ2*b*(a-b) + bˆ2*c*(b-c) + cˆ2*a*(c-a) EqualityCondition c) := sorry The informal statement has two parts: proving an inequality and determining the condition for equality. The MiniF2F version only formalizes the inequality, completely omitting the second part of the problem. In contrast, MathOlympiadBench provides complete formalization."
        },
        {
            "title": "Technical Report",
            "content": "A.3 IMO 1962, PROBLEM 2: INFORMAL & FORMAL STATEMENT MISMATCH MiniF2F 1 /-- Determine all real numbers which satisfy the inequality: 2 4 (cid:112) 3 + 1 > 1 5 Show that it is (cid:104) 1, 1 127 (cid:17) . 6 -/ 7 8 theorem imo_1962_p2 (x : R) (h0 : 9 0 3 - x) (h1 : 0 + 1) (h2 : 1 / 2 < Real.sqrt (3 - x) - Real.sqrt (x + 1)) : -1 < 1 - Real.sqrt 31 / 8 := sorry"
        },
        {
            "title": "MathOlympiadBench",
            "content": "1 /-! 2 # International Mathematical Olympiad 1962, Problem 2 3 4 Determine all real numbers which satisfy 5 3 + 1 > 1 2 . 6 7 -/ 8 9 abbrev SolutionSet : Set := 31 / 8) Set.Ico (-1) (1 - 10 11 theorem imo1962_p2 (x : R) : 12 SolutionSet 3 -1 1/2 < (cid:112)(3 x) 13 - (cid:112)(x + 1) := sorry (cid:112) + 1 > 2 and another as For this problem, the original inequality appears in two different versions6: one as 3 + 1 > 1 2 . In MiniF2F, the informal statement uses the latter (the nested square root version), but the formal statement is based on the former (the simpler difference of square roots), resulting in mismatch between the informal and formal statements. In contrast, MathOlympiadBench ensures that both the informal and formal statements consistently correspond to the same version of the problem."
        },
        {
            "title": "B FORMAL NEGATION",
            "content": "We attempt to disprove unsolved statements by proving their logical negation. This is achieved by parsing the Lean 4 statements as follows. 1 theorem fourIsPrime (a : N) (ha : = 4) : a.Prime := by sorry 2 theorem fourIsPrimeNeg : (a : N) (ha : = 4), a.Prime := by sorry"
        },
        {
            "title": "C DETAILS FOR JUDGING FORMALIZATION",
            "content": "Here is the exact prompt for LLM judging the faithfulness of formalization. You will receive math problem consisting of its natural language statement along with its formal statement in LEAN 4. Please evaluate whether the formal LEAN statement appropriately translates the natural language statement based on the following criteria: 1. Key Elements: The problems essential components are correctly represented in LEAN code. 2. Mathematical Accuracy: The translation preserves the accuracy of the mathematical content. 3. Structural Fidelity: The translation aligns closely with the original problem, maintaining its structure and purpose. 6Please refer to: https://artofproblemsolving.com/wiki/index.php/1962_IMO_ Problems/Problem_2."
        },
        {
            "title": "Technical Report",
            "content": "4. Comprehensiveness: All assumptions, conditions, and goals present in the natural language statement are included in the LEAN translation. Your answer should be in the following format: Thought: [Your Answer] Judgement: [Your Answer, one of {Appropriate, Inappropriate}] --- Following are the example problems label for the reasonability of their translation. # Example 1: ## Original natural language statement of the problem: For the graph of certain quadratic = ax2 + bx + c, the vertex of the parabola is (2, 10), and one of the x-intercepts is (1, 0). x-coordinate of the other x-intercept? What is the ## Translated formal statement: lean theorem quadratic_other_intercept (f : R) (a : R) (h_quad : x, = * xˆ2 + * + c) (h_vertex : 2 = 10 x, 2) -- vertex at (2,10) (h_intercept1 : 1 = 0) : 3 = 0 := by (3,0) -- x-intercept at (1,0) -- other x-intercept at Thought: The Lean translation of the problem is appropriate because it accurately captures the intent and reasoning of the original problem. The problems key elements, such as the vertex, axis of symmetry, and x-intercepts of the quadratic function, are correctly translated into Lean code. The logical flow of the proof mirrors the original reasoning, starting with the symmetry property of the quadratic function and using it to determine the second x-intercept. The mathematical accuracy is preserved, as the proof correctly applies the vertex property and symmetry to arrive at the solution. Furthermore, the translation aligns well with the original problem in natural language, maintaining fidelity to its structure and purpose. Overall, the translation is both faithful and complete, making it an appropriate representation of the original problem. Judgement: Appropriate # Example 2: ## Original natural language statement of the problem: Draw tangent line from the point (4, 3) to the circle (x 2)2 + (y 1)2 = 1 . What is the equation of the line that passes through the two tangent points? ## Translated formal statement: lean theorem tangent_line_equation (x : R) : let : := (4, 3) -- Point let : := (2, 1) -- Center of first circle"
        },
        {
            "title": "Technical Report",
            "content": "-- Radius of first circle let : := 1 -- Points (x,y) satisfying both circle equations let on_first_circle := (x - 2)ˆ2 + (y - 1)ˆ2 = 1 let on_second_circle := (x - 3)ˆ2 + (y - 2)ˆ2 = 2 -- If point is on both circles on_first_circle on_second_circle -- Then it lies on the line 2x + 2y - 7 = 0 2*x + 2*y - 7 = 0 := by Thought: The Lean translation of the problem is inappropriate because it fundamentally changes the intent of the original problem. The original problem asks to derive the equation of the tangent line passing through the intersection points of two circles, but the translation assumes the equation (2x + 2y - 7 = 0) is already given and instead asks to prove that the intersection points lie on this line. This shifts the problem from construction task to verification task, losing the original problems focus on deriving the result through geometric and algebraic reasoning. Additionally, the translation omits the key reasoning step of subtracting the circle equations to derive the line equation, which is central to the original problem. As result, the translation fails to accurately represent the problems intent and educational value, making it an incomplete and inappropriate representation. Judgement: Inappropriate Example3: ## Original natural language statement of the problem: If a, b, c, > 0 and abcd = 1 , prove that nn 1 a+b+c+1 + 1 b+c+d+1 + 1 c+d+a+1 + 1 d+a+b+1 1 a+3 + 1 b+3 + 1 c+3 + 1 d+3 nn -/ ## Translated formal statement: lean4 theorem lean_workbook_49553 (a : R) (habc : * * * = 1) : (1 / (a + + + 1) + 1 / (b + + + 1) + 1 / (c + + + 1) + 1 / (d + + + 1)) (1 / (a + 3) + 1 / (b + 3) + 1 / (c + 3) + 1 / (d + 3)) by sorry := Thought: The Lean translation of the problem is inappropriate because the condition a, b, c, > 0 is ignored in the formal statement. Judgement: Inappropriate Example4: ## Original natural language statement of the problem: If = = = 2 so (cid:80) cyc (a1)2 a2+2 = 2 . Well prove that 1 2 is the answer. ## Translated formal statement: lean4 theorem lean_workbook_plus_1478 (a : R) (ha : = 2) (hb : = 2) (hc : = 2) : (a - 1) ˆ 2 / (a ˆ 2 + 2) + (b - 1) ˆ 2 / (b ˆ 2 + 2) + (c - 1) ˆ 2 / (c ˆ 2 + 2) = 1 / 2 by sorry :="
        },
        {
            "title": "Technical Report",
            "content": "Thought: The Lean translation of the problem is appropriate because it accurately captures the assumptions and the goal in the natural language statement. Judgement: Appropriate ## Original natural language statement of the problem: {informal_statement} ## Translated formal statement: lean4 {formal_statement} DETAILS FOR INFORMAL-BASED SCAFFOLDED DATA SYNTHESIS In this section, we provide all the details for informal-based scaffolded data synthesis. We start with the prompt template for different LLM queries, including the prompt template to generate harder variant, simpler/sub-problem, as well as the prompt template to judge the simplicity and correctness. Then, we provide more details for the synthesis pipeline. Prompt template for solving the original problem Note that for both input with natural language problem and statement written in Lean, we use the same prompt because we find that general-purpose models can understand the Lean although they cannot generate the whole proof correctly. Solve the following math problem probably written in Lean 4: {problem} Provide detailed solution. Note that you dont need to prove the problem in Lean 4, just provide detailed solution in natural language or math notation. Prompt template for generating sub/simpler problems will give you math problem along with its full solution. Your task is to generate simpler problems which may enable student to build up the skills to solve the given problem. Each simpler problem should reflect the idea of core step in the solution. Each generated problem must: (1) Be completely self-contained and standalone: it should be clearly stated as an independent question that someone could read and work on without seeing the original problem and the other generated problems. (2) Be purely proof-based: stated explicitly as question of the form \"Prove that. . .\". (3) Be related to the core steps in the solution of the original problem or reflect the core idea, and should not be just trivial and straightforward derivation, plug-in calculation, or solving simple equations. After generating the problems, carefully evaluate your own output and perform the following checks: (1) Ensure each problem is fully self-contained: check that it does not rely on undefined variables, terms, or concepts from the original problem or other problems. (2) Ensure the set of problems is diverse, covering different steps or aspects of the original reasoning. (3) Ensure that the problems are not too simple or trivial, and that they require meaningful proof. Avoid trivial and straightforward derivation, plug-in calculation, or solving simple equations."
        },
        {
            "title": "Technical Report",
            "content": "Wrap each final selected problem between the tags <newproblem> and </newproblem> to make it easy to extract. Do not include anything else. Problem: {problem} Solution: {solution}"
        },
        {
            "title": "Prompt template for generating harder variant of problems",
            "content": "I now have math problem and its solution at hand, and would like you to modify the problem to generate diverse set of new problems based on it. Below is the problem (probably written in Lean 4): --- {problem} --- Below is the solution: --- {solution} --- Now would like you to generate at least 10 new math problems, each clearly different from the original. For example, you can make the following modifications to make the problem different: Change the number in the original problem to generate new problem. Transform the algebraric formula such that it needs more simplification. For example, change cos(x) in the original problem into 1 - 2 sin(x/2)ˆ2. Add more terms in the inquality. For example, the original problem need to show that f(x) is non-negative, you transform the problem into f(x) + (1/x - a)ˆ2 is non-negative, or f(x) cdot (x - b)ˆ2 is non-negative. Lift real variable into complex number, vector or even matrix. For example previously when solving quadratic equation in real space, you now change it to complex field, which might lead to slightly different solutions. Or the original problem considers planer geometry, you modify the problem into 3 dimensional geometry. Substitute variable into more complex algebraic form, which includes but not limited to changeing variable into polynomial, exponential, logarithm, or even trigonometry. For example, you change variable in the original problem into yˆ2 or even yˆn in the new problem. Another example is that you are given some condition like + + = 1 where a, b, are all positive, and you need to show f(a, b, c) is non-negative. You can change the condition into + + = with x, y, positive, which is equivalent to 1/x + 1/y + 1/z = 1, and modify the statement to show that f(1/x, 1/y, 1/z) is non-negative. Use the conclusion in the problem as step to solve another problem. For example, the original problem need to solve equation f(x) = 0, where is the variable. Now you change it to solve f( exp(x) ) = 0, f( ln(x) ) = 0, or f( cos(x) ) = 0, or even f( xˆ2 ) = 0. These are just some example transformations you can try, and you are not limited to these transformations. Do not overcomplicate the problem, and it is acceptable to make simple transformations. The new math problem should not be simpler than the example problems provided, i.e., you should not simplify the original problem and make it the new problem. Each generated problem must: (1) Be purely proof-based: stated explicitly as question of the form \"Prove ...that\". Do not generate problems that ask to \"determine\", \"compute\", \"evaluate\", \"find\", or similar. (2) Be completely self-contained and standalone. (3) Be mathematically valid and solvable. (4) Be meaningfully different to ensure diversity."
        },
        {
            "title": "Technical Report",
            "content": "Wrap each generated problem between the tags <newproblem> and </newproblem> to make it easy to extract. Do not include anything else."
        },
        {
            "title": "Prompt template to judge the correctness and simplicity of the synthesized statement",
            "content": "I will give you math problem written in Lean 4, and will ask you to determine (1) whether the problem is correct or not; and (2) whether the problem is too simple to prove or disprove in Lean 4. Here is list of too simple problems in Lean 4: simple calculations, simple algebraic manipulations, solving single variable linear equations (by just 1-step calculation), and inequalities proved by an easy sum-of-squares technique. However, do not include inequality proving with the square root since that might be more complex. Please do not label other problems, such as other more complex inequalities, limits, and integrals, as simple problems. Also, please do not label problems that deals with integers (more related to number theory), higher order roots, complex numbers, matrices, polynomials, group, finite-sum, or functional equations (e.g. Let be function such that xf(x) f(-x) = -f(x) shed lights on other hard problems. Prove that is an odd function, i.e., in .), since these problems might in R. f(xˆ2) = for all for all Please carefully analyze the problem and provide an explanation of your reasoning. For judging the correctness, if the problem is correct, respond with \"yes\"; if the problem is incorrect, respond with \"no\"; if you are not sure, respond with \"unsure\". For judging the simplicity, if the problem is too simple to prove or disprove in Lean 4, respond with \"yes\"; if the problem is not too simple, respond with \"no\"; if you are not sure, respond with \"unsure\". Please refer to the list of too-simple problems provided. Wrap your judgment between <judge> and </judge> to make it easy to extract. You should first answer yes or no to the correctness and then answer yes or no to the simplicity, separated by comma. For example, if you think the problem is correct and not too simple, you should respond with <judge>yes, no</judge>. If you are not sure about the correctness, you can respond with <judge>unsure, no</judge> because at least this problem is not simple. If you think the problem is incorrect but it is not too easy to disprove, you can respond with <judge>no, no</judge>. If you think the problem is correct but too simple to prove or disprove, you can respond with <judge>yes, yes</judge>. Again, when judging the simplicity, please do not label inequality proving with the square root as simple, since that might be more complex than expected. Please do not include problems such as more complex inequalities, or problems that include limits, and integrals. Also, please do not label problems that deals with integers (more related to number theory), higher order roots, complex numbers, matrices, polynomials, group, finite-sum, or functional equations, as simple problems, since these notions are more likely to related to hard problems and proving problems related to these concepts in Lean 4 might not be easy even if the problem is straight-forward in natural language. Do not include anything else. Problem: {formal_statement} More details for informal-based scaffolded data synthesis of the design choices and details for the scaffolded data synthesis pipeline. In the following part, we discuss some 1. (Informal statements generation.) For the informal statements generation, one design choice is whether to generate multiple questions during the same inference, or to generate"
        },
        {
            "title": "Technical Report",
            "content": "multiple times while only generating 1 (or very few) questions during one inference. From our experiment, we observe that for the Qwen3-32B model, generating multiple questions during the same inference is better, since the generated questions are likely to be different. Otherwise, there might be very similar questions among different generations. Besides, we also find that repeatedly generating single problem multiple times doesnt significantly increase the number of different problems. Thus, for efficiency considerations, we only query the LLM (Qwen3-32B) once for generating multiple hard variants/simple problems of given math problem. 2. (Formalization and quality checking.) For each generated informal statement, we call the trained formalizer to formalize the problem twice. Then, we then query Qwen3-8B for 3 times for each formalization, and decide if the formalization is aligned with the informal statement using majority voting (among three queries). We decide to formalize each informal statement twice in order to balance the efficiency and the number of generated problems. We only keep at most one formalization for each generated informal statement. 3. (Negation and difficulty filtering.) For each formalization, we query Qwen3-32B for 4 times, where each inference judges the correctness and the simplicity simultaneously. The final correctness is judged by strict majority voting among the 4 judges, while the final simplicity is determined if all 4 judges think the problem is easy. We use such strict criteria to minimize the probability of discarding hard and valuable problems. The efficiency for the judging is high, even if we call Qwen3-32B 4 times for each formalization, since lot of the time Qwen3-32B enters the fast thinking mode (no long chain-of-thought for reasoning). 4. (Final deduplication.) At the end of the pipeline, we filter out duplicated statements under exact match."
        },
        {
            "title": "E RL TRAINING DETAILS",
            "content": "We further explain our RL training in detail. E.1 RL IMPLEMENTATION Figure 9: Illustrative figure for our multi-task RL. This pipeline improves models performance on both the whole proof and the self-correction at the same time without additional design on the framework or algorithm. We begin by collecting 50K challenging statements and 50K self-correction samples. Each self-correction sample contains statement, output generated by the SFT model, and an associated error message. During RL training, we consumed approximately 46K and 64K unique inputs for the 8B and 32B models on 1 epoch, respectively. We use the VeRL framework (Sheng et al., 2024) with several key setups: We adopt batch size of 128 and of 8 for parallel rollouts and reward function calls (via the Lean compiler), while using mini-batch size of 32, accepting certain degree of off-policy training in exchange for higher frequency of policy optimization. For the dynamic sampling, we set the over-sample batch size equal to three times of train batch size and filter out inputs with pass rate equal to 0 or higher than 0.75. We use maximum prompt length of 16K for those long inputs in the self-correction task. We set the maximum response length to 24K to support reasonably sized reasoning trajectory while staying within the Qwen3 models native 40K context"
        },
        {
            "title": "Technical Report",
            "content": "window, ensuring generation quality. We enable the overlong penalty with 4K overlong buffer and set the overlong penalty factor to 1. We use token-averaged policy loss and do not use KL divergence or entropy terms in our training objective. Figure 10: Training curves comparing 32B and 8B models: training rewards (top row) and generation lengths (bottom row) for whole proof completion and self-correction tasks. Note that the rewards are averaged over all generated rollouts, including those then filtered by the dynamic sampling strategy, thus reflecting the policy improvement. E.2 FURTHER DISCUSSION ON RL For the design of training with self-correction, we explored both tool-use and multi-turn reinforcement learning. However, the former not only requires dedicated tool-calling design, but also demands strong model capability to follow the tool-calling protocol, especially in complex and lengthy formal language scenarios like Lean, which is particularly challenging for our relatively small model. Meanwhile, multi-turn approaches introduce various engineering challenges, especially on the rollout engine side, such as asynchronous generation. Moreover, on the algorithm side, the effectiveness and efficiency of multi-turn RL still require further validation. We have explored some preliminary approaches, but they remain immature. Therefore, we adopt more straightforward implementation that is natively integrated into the current RL framework, as illustrated in Figure 9. In this setup, we have two different type of inputs for RL and detailed training curves are shown in Figure 10. Furthermore, for the algorithmic design, like the advantage estimator, we explored different popular GRPO variants but did not observe significant differences."
        }
    ],
    "affiliations": [
        "Amazon",
        "Meta FAIR",
        "NVIDIA",
        "Peking University",
        "Princeton Language and Intelligence, Princeton University",
        "Shanghai Jiao Tong University",
        "Stanford University",
        "Tsinghua University"
    ]
}