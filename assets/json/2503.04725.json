{
    "paper_title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
    "authors": [
        "Zhuo Chen",
        "Oriol Mayné i Comas",
        "Zhuotao Jin",
        "Di Luo",
        "Marin Soljačić"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We rigorously establish a bipartite mutual information scaling law in natural language that governs long-range dependencies. This scaling law, which we show is distinct from and scales independently of the conventional two-point mutual information, is the key to understanding long-context language modeling. Using this scaling law, we formulate the Long-context Language Modeling (L$^2$M) condition, which relates a model's capacity for effective long context length modeling to the scaling of its latent state size for storing past information. Our results are validated through experiments on both transformers and state space models. This work establishes a theoretical foundation that guides the development of large language models toward longer context lengths."
        },
        {
            "title": "Start",
            "content": "L2M: Mutual Information Scaling Law for Long-Context Language Modeling Zhuo Chen 1 2 3 Oriol Mayne Comas 1 3 4 Zhuotao Jin 1 3 5 Di Luo 1 2 3 5 6 Marin Soljaˇcic 1 2 3 5 2 0 2 6 ] . [ 1 5 2 7 4 0 . 3 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "We rigorously establish bipartite mutual information scaling law in natural language that governs long-range dependencies. This scaling law, which we show is distinct from and scales independently of the conventional twopoint mutual information, is the key to understanding long-context language modeling. Using this scaling law, we formulate the Long-context Language Modeling (L2M) condition, which relates models capacity for effective long context length modeling to the scaling of its latent state size for storing past information. Our results are validated through experiments on both transformers and state space models. This work establishes theoretical foundation that guides the development of large language models toward longer context lengths. 1. Introduction Large language models (LLMs) have revolutionized natural language processing, achieving remarkable capabilities across wide range of tasks (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023a;b). Recent advances, particularly with models like GPT-4 (OpenAI et al., 2024), Claude-3.5, LLaMA-3 (Grattafiori et al., 2024), and DeepSeek-V3 (DeepSeek-AI et al., 2024), have demonstrated breakthroughs in tasks from code generation to mathematical problem solving, from text summarization to creative writing (Stiennon et al., 2020; Yuan et al., 2022; Gou et al., 2023; Wang et al., 2023). These models have become increasingly powerful and versatile, pushing the boundaries of whats possible in natural language processing and marking significant steps toward artificial general intelligence (Bubeck et al., 2023; Ge et al., 2023; Kosinski, 2023). 1{chenzhuo, omayne, jinzhta, diluo, soljacic}@mit.edu 2NSF AI Institute for Artificial Intelligence and Fundamental Interactions 3Massachusetts Institute of Technology 4Polytechnic University of Catalonia 5Harvard University 6University of California, Los Angeles. Correspondence to: Zhuo Chen <chenzhuo@mit.edu>. Preprint. Copyright 2025 by the author(s). Figure 1. Illustration of the central idea of our paper. (a) random block of text of length is divided into two parts and . (b) The (bipartite) mutual information between the random variables and has power-law scaling with respect to the length. (c) Autoregressive neural networks parameterize conditional distributions q(yx) = (yxℓ, z) via hidden state that caches past information. (d) We formulate the Long-context Language Modeling (L2M) condition, which states that models state size for storing past information must grow at least as the power-law scaling of the bipartite mutual information for effective long context length modeling. In pushing these advances further, the ability to handle long contexts has become increasingly crucial. This ability is the key to document-level understanding, multi-turn dialogue, and complex reasoning. Models like GPT-o1 and DeepSeekR1 often generate extensive chains of thought, sometimes spanning thousands of tokens to solve complex problems (Wei et al., 2022; Wang et al., 2024). However, processing long contexts remains significant challenge. While transformer architectures have achieved remarkable success and recent advances like DeepSeek have dramatically improved the efficiency (DeepSeek-AI et al., 2024), they still suffer from the intrinsic computational cost quadratic in sequence length, resulting in challenges in long sequence length generation. Although various architectures have been proposed to address the quadratic scaling (Katharopoulos et al., 2020; Gu et al., 2022a; Zhu et al., 2021; Beltagy et al., 2020; Ding et al., 2023; Gu & Dao, 2024; Dao & Gu, 2024; Peng et al., 2023; Sun et al., 2024), fundamental gap persists in our theoretical understanding of how their effectiveness for capL2M: Mutual Information Scaling Law for Long-Context Language Modeling turing long-range dependencies scales. In spite of existing efforts to characterize these dependencies through various statistical measures (Ebeling & Poschel, 1994a; Debowski, 2011; Bentz et al., 2017; Futrell et al., 2019) theories guiding practical efficient architecture design have not yet been formulated. In this work, we address the challenges of understanding long-context language modeling through the following contributions  (Fig. 1)  . 1. We establish bipartite mutual information scaling law, based on the relaxed Hilberg conjecture (Hilberg, 1990; Łukasz Debowski, 2015), which governs the true long-range dependencies of natural language and is the key to understanding long-context language modeling, fundamentally distinct from conventional two-point mutual information scaling. 2. We validate this new scaling law across various natural language datasets using state-of-the-art LLMs, including both LLaMA (Grattafiori et al., 2024) and DeepSeek (DeepSeek-AI et al., 2024) models, revealing strongly consistent power-law growth behavior. 3. We formulate the Long-context Language Modeling (L2M) condition and prove that models state size for storing past information must scale faster than the bipartite mutual information scaling for effective long context length modeling, which is further empirically verified with transformer and state space models trained on varying sequence lengths. Our theoretical foundation for understanding LLMs capability for long sequence length modeling provides crucial insights and quantitative analysis for improving LLM architectures, enabling more effective long-context applications, and guiding the development of more capable and scalable AI systems. 2. Related Works 2.1. Mutual Information Estimation and Application in Machine Learning Mutual information estimation and optimization have been extensively studied in machine learning, with approaches including variational bounds (Poole et al., 2019), neural estimators (Belghazi et al., 2021), nearest-neighbor methods (Kraskov et al., 2004; Gao et al., 2015), and various upper bounds (Cheng et al., 2020). It has wide applications in feature selection (Brown et al., 2012), representation learning (Tschannen et al., 2020), disentanglement (Chen et al., 2016), and generative modeling (Hjelm et al., 2019). 2.2. Statistical Properties of Natural Language Natural language exhibits characteristic statistical scaling behaviors across different levels of analysis. Zipfs law (Gelbukh & Sidorov, 2001) describes how word frequencies decay with their rank following power-law distribution. Heaps law (Gelbukh & Sidorov, 2001) characterizes vocabulary growth, showing that the number of unique words scales sublinearly with text length. Hilbergs conjecture and its relaxed version posit specific scaling laws for entropy and bipartite mutual information in natural language, respectively (Hilberg, 1990). 2.3. Neural Scaling Laws Power-law relationships between model performance, architecture, and computational requirements have been established (Kaplan et al., 2020; Biderman et al., 2023), though theoretical understanding remains limited (Bahri et al., 2024; Bordelon et al., 2024). These empirical observations have guided the development of larger models, complementing our theoretical framework for context length scaling. 2.4. Architectures for Efficient Long-Context Modeling Various approaches have been proposed for processing long sequences. Architectural innovations targeting the quadratic complexity include sparse attention (Child et al., 2019; Ding et al., 2023; Beltagy et al., 2020; Zaheer et al., 2020), recurrent mechanisms (Dai et al., 2019; Rae et al., 2019; Sukhbaatar et al., 2019), and alternative formulations (Katharopoulos et al., 2020; He et al., 2024; Gu et al., 2022a; Gu & Dao, 2024; Dao & Gu, 2024; Peng et al., 2023; Sun et al., 2024; Gu et al., 2022b; Beck et al., 2024; De et al., 2024). Memory-efficient implementations like Flash Attention (Dao et al., 2022; Dao, 2023; Shah et al., 2024), Lightning Attention (Qin et al., 2024), and Paged Attention (Kwon et al., 2023) have improved computational efficiency while maintaining the underlying complexity scaling. 2.5. Long-Form Reasoning and Context Utilization Chain-of-thought prompting (Wei et al., 2022) and scratchpad methods (Nye et al., 2021) demonstrate the importance of extended context for complex reasoning tasks, emphasizing the need for effective long-range dependency modeling. 2.6. Information Theory and Physics-Inspired Approaches Recent work has demonstrated how information-theoretic principles and physics-inspired approaches can guide machine learning (Tishby & Zaslavsky, 2015; Goldfeld & Polyanskiy, 2020; Chen & Luo, 2024), leading to novel architectures (Luo & Clark, 2019; Luo et al., 2023; Wang et al., 2021; Chen et al., 2022; Lami et al., 2022; Wu et al., 2 L2M: Mutual Information Scaling Law for Long-Context Language Modeling 2023; Chen et al., 2023; Dugan et al., 2024), training methods (Stokes et al., 2020; Chen et al., 2024b;a), and broad applications (Carleo et al., 2019; Lee et al., 2020; Luo et al., 2022; Moro et al., 2024; Chen et al., 2024b; Choi et al., 2024). Our work continues this direction by establishing concrete connections between information-theoretic principles and practical model architectures. 3. Preliminaries 3.1. Mutual Information Mutual information I(X; ) quantifies the statistical dependence between random variables and , defined as: I(X; ) = DKL(pXY pX pY ), (1) where DKL() denotes the KullbackLeibler (KL) divergence and pXY is the joint distribution of and . For discrete random variables, mutual information can be equivalently expressed as: I(X; ) = H(X) + H(Y ) H(XY ) = H(X) H(XY ) = H(Y ) H(Y X), (2) where H() denotes the (Shannon) entropy and H() denotes the conditional entropy. For continuous distributions, these relations hold when entropy is replaced by differential entropy h(). While differential entropy lacks some properties of Shannon entropy, the mutual information remains well-defined and maintains its key properties. This definition naturally extends to collections of random variables, which we denote as I(X1:m; Y1:n), where the notation Xi:j represents the sequence (Xi, . . . , Xj). For notational convenience, we use boldface notation := Xi:j when the indices are clear from context. Similarly, we often drop the index of single variable := Xi when appropriate. 3.2. Autoregressive Neural Networks Modern large language models (LLMs) predominantly employ autoregressive neural architectures. An autoregressive neural network models sequence of conditional probability distributions over tokens {q(wiw1:i1, wBOS)}L i=1, where wBOS denotes the beginning-of-sentence token1. Throughout this paper, we use to denote model-generated probability distributions and to denote the true underlying distributions; upper case letters denote random variables and lower case letters denote specific values or realizations of random variables. These conditional distributions jointly model the 1Some early LLMs, such as the original GPT, did not include this token. probability for sequence of tokens given prefix: q(wℓ:Lw1:ℓ1, wBOS) = (cid:89) i=ℓ q(wiw1:i1, wBOS). (3) When ℓ = 1, this reduces to the unconditional generation distribution q(w1:LwBOS). During inference, tokens are sampled sequentially from these conditional distributions to generate text or respond to prompts. Our theoretical analysis is independent of the specific sampling procedure employed. 4. Mutual Information Scaling Laws In this section, we establish and empirically verify two distinct types of scaling laws for mutual information in natural language: bipartite mutual information scaling between adjacent text segments [Fig. 2 (a)] and two-point mutual information scaling between pairs of tokens [Fig. 2 (d)]. We then demonstrate that bipartite mutual information provides crucial insights into long-range dependencies in natural language in Section 5, and connect an LLMs long context length modeling capacity to its ability to capture correct bipartite mutual information scaling, leading to the L2M condition. 4.1. Bipartite Mutual Information and Relaxed Hilberg Conjecture While classical scaling laws in natural language (e.g., Zipfs law and Heaps law) focus on token-level statistics, understanding language modeling requires analyzing dependencies between text segments. The bipartite mutual information between adjacent text blocks emerges as particularly illuminating measure. Definition 4.1 (Bipartite Mutual Information [Fig. 2(a)]). For consecutive sequence of tokens (random variables) W1:L of length L, consider biparition of the tokens: X1:ℓ := W1:ℓ and Y1:Lℓ := Wℓ+1:L. The bipartite mutual information is the mutual information between the two parts BP ℓ;L := I(X1:ℓ; Y1:Lℓ) When = 2ℓ, the bipartite mutual information in natural language is conjectured to follow power-law growth (Hilberg, 1990; Łukasz Debowski, 2015), Conjecture 4.2 (Relaxed Hilberg Conjecture2). For equal lengths3 of and , the bipartie mutual information scales as BP L/2;L Lβ for some β [0, 1]. We note this power-law growth is sometimes also referred 2The original conjecture does not concern tokens specifically, but the scaling should be similar when measured on symbols, tokens or words. 3Having equal lengths may not be necessary, but it presents in the original statement of the conjecture. 3 L2M: Mutual Information Scaling Law for Long-Context Language Modeling Figure 2. Illustration and estimations of bipartite and two-point mutual information in natural language. (a) The bipartite mutual information measures statistical dependence between two adjacent segments within text block of length L. (b, c) Estimations using LLaMA 3.1 405B model (Meta) on PG19 dataset (Rae et al., 2020) of pre-1919 books and WIKIPEDIA (Foundation). Both direct estimation and vCLUB approximation (Cheng et al., 2020) show consistent results across datasets. See Appx. A.IV for results using DeepSeek and other LLaMA models. (d) The two-point mutual information measures statistical dependence between tokens separated by distance d. (e, f) Two-point mutual information estimations on PG19 dataset and WIKIPEDIA. to as the sub-volume law. We will use the two terms interchangeably depending on context. While empirical verification of this power-law growth is intuitively appealing, rigorous validation has proven challenging due to difficulties in estimating high-dimensional entropy and mutual information from samples. Early work by Hilberg (Hilberg, 1990) considered stricter version of the conjecture (also see Appx. A.I) and found β 0.5, with limited data and only for sequences up to 100 characters. Later studies using universal compression codes estimated β 0.95 for millions of tokens (Łukasz Debowski, 2015), though these results may be sensitive to compression algorithm choice and likely overestimate the exponent (see Appx. A.II). Recent work using kNN and MINE estimators ℓ;L ℓ0.82 for ℓ/L 0.2 and found related scaling BP 200 (Lu et al., 2024), but suffered from dimensional bias issues4. Despite these estimation challenges, all studies support the existence of power-law growth. In Sec. 4.3, we verify this conjecture using LLM approximations to the underlying distribution of natural language and demonstrate clear powerlaw scaling. 4The dimensional bias is severe enough that their measured 50;200, violating basic mutual information inI BP 50;100 exceeds BP equalities. 4.2. Two-point Mutual Information Before presenting our empirical results on bipartite mutual information scaling, we first address two-point mutual information, which was previously thought to indicate longrange language dependencies. In Sec. 4.4, we show why two-point mutual information is inadequate for capturing true multi-token dependencies, while bipartite mutual information provides more complete understanding. Definition 4.3 (Two-point Mutual Information [Fig. 2(d)]). The two-point mutual information measures the mutual information between two tokens (random variables) and separated by distance d: TP = I(X; ). We note that the two-point mutual information has been observed to follow power-law decay TP dα (Ebeling & Poschel, 1994b; Ebeling & Neiman, 1995; MONTEMURRO & PURY, 2002; Shen, 2019). Based on this scaling, it is often argued that natural language exhibits similar structures and long-range dependencies to critical physical systems (Lin & Tegmark, 2017), whose two-point correlation function follows similar decay (Stanley, 1995). We stress that this argument is misleading. The two-point mutual information does not capture the multivariate longrange dependencies in natural language. While the twopoint mutual information for both natural language and critical physical systems follows power-law decay, the bipartite mutual information scalings are drastically differentonedimensional critical physical system only exhibits logarithmically growing bipartite mutual information (Alcaraz & 4 L2M: Mutual Information Scaling Law for Long-Context Language Modeling Rajabpour, 2013; Dai et al., 2020), much slower than the sub-volume law growth expected in natural language. We explain this in more detail in Sec. 4.4. 4.3. Empirical Verification of Mutual Information Scaling Laws 4.3.1. BIPARTITE MUTUAL INFORMATION Measuring bipartite mutual information presents significant challenges without access to the underlying probability distribution p. Recent advances in LLMs provide solution by offering high-quality approximations to these distributions. As autoregressive neural networks, LLMs enable efficient computation of conditional probabilities (Sec 3.2) and their associated cross entropies (negative log likelihoods): H(pY , qY ) := EpXY log q(Y X), (4) where the expectation is taken over samples from the true underlying distribution pXY . The cross entropy provides an upper bound to the true entropy: H(pY , qY ) = DKL(pY qY ) + p(Y X), (5) where the conditional cross entropy and KL-divergence always implicitly average over pX , and (or q) denotes the entropy computed with respect to distribution (or q). Using these properties, we can construct direct estimator for bipartite mutual information: BP,direct ℓ;L =EpXY [log q(Y X) log q(Y )] =H(pY , qY ) H(pY , qY ) =I p(X; ) + ε(p, q), (6) where p(X; ) denotes mutual information with respect to and ε(p, q) = DKL(pY qY ) DKL(pY qY ). While this estimator no longer provides bound, it preserves the key property that ε(p, q) 0 as p. We note this estimation method faces specific challenge with modern LLMs: they model q(wiw1:i1, wBOS) rather than q(wiw1:i1), where wBOS denotes the BOS token. When sampling from the dataset, we can ensure starts at sentence beginnings, making q(Y X, wBOS) q(Y X). However, may start mid-sentence, creating mismatch where q(Y ) = q(Y wBOS). This introduces errors in estimating H(pY , qY ). We address this using n-gram corrections for the first two tokens, from where most of biases come (see Appx. A.III). To circumvent issues with estimating q(Y ), we also employ the vCLUB estimator (Cheng et al., 2020): BP,vCLUB ℓ;L = EpXY log q(Y X) EpX pY log q(Y X), (7) where the second term can be calculated by shuffling the second halves of samples in the dataset. Analysis in (Cheng et al., 2020) shows that vCLUB provides an upper bound on the true bipartite mutual information when closely approximates p. Even when deviates moderately from p, though the upper bound property may not hold, vCLUB continues to provide reliable estimates of the true bipartite mutual information. Our empirical analysis in Fig.2(b, c) examines equal-length partitions of and (ℓ = L/2), which maximizes bipartite mutual information for fixed L. Using both the bias-corrected direct estimator [Eq.(6)] and vCLUB estimator [Eq. (7)], we measure scaling on the PG19 dataset5 (Rae et al., 2020) (a collection of books before 1919) and WIKIPEDIA (Foundation), employing the LLaMA 3.1 405B model (Meta) as q. All measurements reveal clear powerlaw scaling across thousands of tokens. Additional measurements using LLaMA 3.1 70B (Meta) and DeepSeek V3 Base models (DeepSeek-AI et al., 2024), along with varying ℓ/L ratios, can be found in Appx. A.V). We note that both estimators likely underestimate the true exponent β (see Appx. A.VI for discussion). 4.3.2. TWO-POINT MUTUAL INFORMATION Two-point mutual information estimation is more straightforward, requiring only 1and 2-gram statistics without LLM approximations. We estimate this quantity using entropy calculations for individual tokens and token pairs separated by distance d. Following (Grassberger, 2008), we employ their bias-reduced entropy estimator: ˆH(X) = ˆH(Y ) = log 1 M (cid:88) m=1 nmG(nm), (8) where is the total number of tokens, is the vocabulary size, nm is the number of tokens whose token ID equals nm, and G() is defined as G(n) = ψ(n) + (1)n 2 (cid:18) ψ (cid:18) + 1 2 (cid:19) ψ (cid:17)(cid:19) (cid:16) 2 (9) with ψ() the digamma function. The entropy of pairs of tokens is estimated analogously, with the summation running over all ordered pairs of tokens (mi, mj), resulting in the total number of terms quadratic in the vocabulary size. The mutual information is then estimated as (X; ) = ˆH(X) + ˆH(Y ) ˆH(XY ). ˆI TP 5We couldnt use the BOOKS3 dataset because it was removed (10) due to copyright infringement concerns. 5 L2M: Mutual Information Scaling Law for Long-Context Language Modeling the simple dependency structure as BP ℓ;L = log remains constant for any choice of ℓ and Ltwo segments share exactly the same amount of information (log ) regardless of their lengths, which is no more than the information shared between just two adjacent tokens. For more realistic setting, in Fig. 3, we consider two families of multivariate Gaussian distributions of different lengths (see Appx. for details in constructing these distributions). In particular, both families show identical powerlaw decay in their two-point mutual information between variables at maximum separation. However, they exhibit dramatically different bipartite mutual information scalingone scales as Lβ, similar to natural language, while the other scales as log L, similar to critical physical systems. These examples illustrate that two-point mutual information alone is insufficient, and can be misleading: it may suggest strong long-range dependencies where none exist, or fail to distinguish between systems with fundamentally different dependency structures. 5. Long-Context Language Modeling (L2M)"
        },
        {
            "title": "Condition",
            "content": "Having established bipartite mutual information as more reliable measure of dependencies, we analyze how models capacity to handle long contexts fundamentally depends on its ability to store past information, using bipartite mutual information scaling as our theoretical framework. Intuitively, to model natural language effectively, model must be able to capture all dependencies between past and future tokens. Since these dependencies (measured by bipartite mutual information) grow with sequence length, the models state capacity for storing past information must necessarily grow as well. We formalize this intuition through the Longcontext Language Modeling (L2M) condition and explore its implications in detail throughout this section. 5.1. Theoretical Derivations To analyze how models handle long-range dependencies, we first formalize the notion of model state for storing past information, which we call the history state. Definition 5.1. Consider sequence of tokens w1:L. Denote x1:ℓ := w1:ℓ and y1:Lℓ := wℓ+1:L. For autoregressive neural networks that parameterize conditional probabilities q(y1:Lℓx1:ℓ), we define the history state at ℓ as the intermediate variables zℓ = (x1:ℓ1) of smallest size that, together with xℓ, fully characterizes the models behavior through q(yxℓ, zℓ)6 [Fig. 1(c)]. 6We separate xℓ from zℓ to accurately reflect its distinct role as current input token in autoregressive models, though including it in zℓ would not affect the main results of this paper. Figure 3. Bipartite and two-point mutual information scalings for two families of multivariate Gaussian distributions with varying sequence lengths (see Appx. B). The two families of distributions (a) have significantly different scaling for bipartite mutual information (Lβ vs log L), but (b) identical two-point mutual information scaling (dα). We note that this mutual information estimator exhibits systematic bias. The entropy estimator has negative bias that increases (in absolute value) with dimension of the sample space Ω. Since ΩX = ΩY = where as ΩXY = 2, the bias in ˆH(XY ) exceeds that in ˆH(X) = ˆH(Y ), leading to positive bias in ˆId. This bias becomes particularly problematic at large distances d, where H(XY ) H(X) + H(Y ) and Id approaches zero. To mitigate this issue, we perform additional bias correction by fitting the systematic bias from the data (see Appx. A.VII for detail). We apply this methodology to measure two-point mutual information on both the PG19 dataset and WIKIPEDIA, confirming power-law decay in both cases [Fig. 2 (e, f)]. 4.4. Distinction between Bipartite and Two-point Mutual Information Bipartite and two-point mutual information differ fundamentally in their characterization of dependencies in multivariate systems. We demonstrate through two examples that two-point mutual information can fail to capture the true nature of long-range dependencies, leading to potentially misleading conclusions. Consider simple distribution where all tokens must be identical: p(x1, x2, . . . , xL) = 1(x1 = x2 = = xL)/M , with 1() being the indicator function that evaluates to 1 when the condition is satisfied and 0 otherwise, and the vocabulary size. Notice that this distribution permits Markov chain construction as p(x1) = 1/M and p(xix1:i1) = 1(xi = xi1), and therefore has simple token-to-token dependency structure. Despite this simplicity, the two-point mutual information of the distribution suggests misleading strong long-range dependencyit maintains large value of TP = log without any decay as increases, far exceeding that of natural languages. In contrast, the bipartite mutual information correctly identifies 6 L2M: Mutual Information Scaling Law for Long-Context Language Modeling As illuminating examples, the history state corresponds to the latent state in RNNs and state space models (SSMs) after processing token wℓ1, and to the key-value pairs up to token wℓ1 for transformers (see Appx. C). Generally, the history state zℓ should be chosen as the smallest hidden state responsible for caching historical information. We now establish that the size of this history state upper bounds models capacity to capture bipartite mutual information: Theorem 5.2. The maximum bipartite mutual information that model can capture is bounded by the size of its history state: BP,q L/2;L dim(zL/2) + log(M ) (11) where is some constant and denotes the vocabulary size. Here, we focus on ℓ = L/2 where the bipartite mutual information reaches the maximum for given L. We present an intuitive proof below assuming discrete history states zL/2. This assumption naturally aligns with float point or quantized numerical representations in neural networks, and does not affect our theoretical conclusions. complete proof with relaxed assumptions is provided in Appx. D. the processing Proof. By inequality: data q(X1:L/2; Y1:L/2) q(ZL/2, XL/2; Y1:L/2). This is upper bounded by the entropy: q(ZL/2, XL/2), which is further upper bounded by q(ZL/2) + q(XL/2) dim(zL/2) + log(M ), where the last inequality follows from the bound on entropies of discrete variables. Having established that models history state dimension bounds its ability to capture bipartite mutual information, we now formalize how models must scale to maintain performance as sequence length increases. To systematically analyze this scaling behavior, we consider both increasing sequence lengths and model sizes, examining whether models can continue to capture the mutual information present in the data as both scales grow. We formalize this notion through the following definition of MI-capable model scaling. Definition 5.3. Let {W1:L} L=1 be series of natural language datasets of different lengths, which we obtain by truncating an ideal infinite-length dataset. Define scaling of model architecture (or simply scaling of models) as series of models {qL} L=1 of the same architecture, with possibly increasing model sizes as grows. We say scaling of models is MI-capable if and only if each model qL can achieve the desired bipartite mutual information for its corresponding sequence length L: BP,qL L/2;L = BP L/2;L. Since each models mutual information is bounded by its history state dimension, we can now characterize the necessary scaling of history states for MI-capability. Theorem 5.4 (L2M Condition). For scaling of models {qL} their history states zqL L/2 just before token wL/2 must satisfy the scaling dim(zqL L=1 to be MI-capable, L/2;L Lβ . L/2) BP In other words, to capture the full bipartite mutual information at each sequence length, the history state dimension must grow at least as fast as the power-law scaling of mutual information in the data. Proof. We prove by contrapositive. By Thm. 5.2, each models mutual information is bounded by its history state dimension: BP,qL L/2;L, L/2;L then BP,qL L/2;L BP 7, implying there exists some where BP,qL L/2;L < BP L/2;L, violating MI-capability. dim(zL/2). If dim(zqL L/2) BP L/2;L This is the central result of the paper and establishes the minimal scaling required for models history state dimension to capture the power-law growth of bipartite mutual information in natural language. 5.2. Implications to Common LLM Architectures Our theoretical framework allows us to analyze how different architectures history states scale with sequence length, and what this implies for their ability to capture long-range dependencies. In transformer-based models (excluding sparse attention and linear attention variants), the history state consists of stored key-value pairs for all previous tokens. With fixed model size, the size of key-value pairs already grows linearly with sequence length: dim(zqL L/2) Lβ. This means transformer models naturally satisfy the L2M condition without model size scaling, as the history state dimension automatically grows with sequence length, despite the quadratic computational cost. On the other hand, although often celebrated for their infinite context length and linear complexity, SSMs, RNNs, and linear attention models do not satisfy the L2M condition without scaling up model sizes as sequence length increases. When the model size is fixed, the history state dimension remains constant regardless of the sequence length. Our theory shows this constant-size state cannot capture the growing mutual information. To actually satisfy the L2M condition, these architectures require increasingly larger models as sequence length grows, so that their history state 7We use to denote scaling at the same or lower rate, and to denote scaling at strictly lower rate. 7 L2M: Mutual Information Scaling Law for Long-Context Language Modeling Figure 5. Position-wise conditional negative log likelihood (NLL) evaluation for models trained on 4096-token sequences on the PG19 dataset (Rae et al., 2020). Lower values indicate better performance, with performance differences at later positions highlighting varying capabilities in modeling long-range dependencies. Figure 4. Evaluation of KL-divergence across model architectures trained on sub-volume Gaussian distributions. (a, b) Average KL-divergence per token for models trained on different sequence lengths. (c, d) Position-wise conditional KL-divergence for models trained on sequence length 4096. Lower values indicate better performance. dimensions can increase accordingly. This requirement effectively offsets their computational efficiency advantage for long sequence length modeling. For other architectures like sparse attention models, we can similarly analyze their history state scaling to understand when they can or cannot satisfy the L2M condition. We note that the L2M condition only addresses models ability to capture long-range dependencies, not its overall language modeling capability. Therefore, the L2M condition remains necessary but not sufficient conditionfailing to satisfy it implies inherent limitations at longer sequences, while satisfying it does not guarantee effective language modeling. It is also distinct from neural scaling laws, which typically study how model performance scales with model size, dataset size, and compute budget at given sequence length. 6. Empirical Verification Having established the L2M condition and its implications for various LLM architectures, we now empirically validate our theoretical predictions. 6.1. Experimental Setup We first validate our theory using the sub-volume Gaussian distributions introduced in Fig. 3. This distribution family closely resembles both the bipartite and two-point mutual information scaling observed in natural language, while allowing for efficient calculation of conditional probabilities and KL-divergences (see Appx. B), which would be intractable with real natural language datasets. To thoroughly stress the models, we stack 64 sub-volume Gaussian distributions together and group the random variables at the same position into single token (see Appx. for details). We then extend our analysis to the PG19 dataset (Rae et al., 2020), high-quality collection of pre-1919 books with long contextual dependencies. We evaluate GPT2 (Brown et al., 2020), Mamba (Gu & Dao, 2024), and Mamba2 (Dao & Gu, 2024) models of varying sizes as representative transformer and state space model architectures. Additional experimental details can be found in Appx. E. 6.2. Results In Fig. 4, we present the average per-token KL-divergence (a, b) and position-wise conditional KL-divergence (c, d) for both architectures (see Appx. for definition). We specifically use KL-divergence rather than negative log likelihood (NLL) for more interpretable results. NLL conflates model performance (KL-divergence) with the inherent entropy of the data, which can obscure differences in model capabilities, particularly at longer sequence lengths where both the sub-volume Gaussian distribution and natural language tend to have lower conditional and average entropies. Our results reveal that GPT2 maintains consistent KLdivergence across varying sequence lengths and positions. In contrast, smaller Mamba and Mamba2 models demonstrate increasing difficulty with longer contexts, requiring substantially larger model sizes to achieve comparable performance at sequence length 4096. These findings directly align with our L2M condition and remain consistent across both Mamba variants, providing strong empirical validation of our theoretical framework. 8 L2M: Mutual Information Scaling Law for Long-Context Language Modeling In Fig. 5, we show the position-wise conditional NLL of models trained on the PG19 dataset (Rae et al., 2020) with 4096-token sequences, where calculating KL-divergence is not feasible. In this experiment, we observe two important patterns. In (a), GPT2-125M and Mamba-130M achieve comparable performance early in sequences, but GPT2s advantage becomes evident at later positions. In (b), we see similar behavior with GPT2-Medium (355M) and Mamba370M. Furthermore, GPT2-Medium (355M) initially underperforms Mamba-790M at early token positions, yet their performance converges at later positions despite the Mamba model being more than twice the size. These observations confirm transformers stronger capacity for modeling longrange dependencies, consistent with predictions by our L2M condition. We emphasize that Mambas linear computational complexity can make larger Mamba models practically more efficient than smaller transformers. Our results should not be interpreted as suggesting Mambas architectural inferiority. They simply demonstrate that models capacity for capturing long-range dependencies aligns with our theoretical L2M framework, regardless of the architecture. Additional experimental results can be found in Appx. F. 7. Conclusion In this work, we establish bipartite mutual information scaling law, based on the relaxed Hilberg conjecture, to characterize long-range dependencies in natural language, fundamentally distinct from conventional two-point mutual information scaling. Through evaluations on diverse datasets with state-of-the-art LLMs, we validate this law and observe consistent power-law growth pattern. We introduce the L2M condition, proving that models state size must scale faster than bipartite mutual information for effective long-context modeling, which we verify empirically using transformers and state space models. These findings suggest promising directions, such as designing synthetic language datasets with proper mutual information scaling and developing memoryand computation-efficient LLM architectures. Two intriguing questions emerge: is it possible to design architectures that just meet this theoretical minimum requirement, and can there exist architectures with linear computational complexity that satisfy the L2M condition? By bridging theoretical scaling laws with empirical verification, our work provides solid foundation for advancing long-context language modeling."
        },
        {
            "title": "Limitations",
            "content": "Our theoretical framework specifically examines models capacity to capture long-range dependencies, without addressing other aspects of language modeling, such as reasoning or world knowledge. While our empirical validation on the Gaussian distribution dataset captures the essential mutual information scaling effects, it may not fully reflect the complexities of natural language. Our analysis is currently limited to English text, primarily because the LLMs used for approximation were predominantly trained on English data, and verification of the scaling law in other languages would provide valuable insights into potential universal properties across different linguistic structures. Additionally, our theory focuses on autoregressive language models, and extending it to other architectures such as discrete diffusion models or even vision models could reveal similar information scaling behaviors in different domains. Our evaluations rely on open-source models like LLaMA and DeepSeek, and further verification using closed-source state-of-the-art models would provide additional validation of our findings."
        },
        {
            "title": "Impact Statement",
            "content": "This work advances our theoretical understanding of how language models process long-range dependencies, with implications for the design and deployment of more efficient LLM architectures. By establishing the L2M condition, we provide principled framework for evaluating architectures fundamental capacity for long-context modeling. This could lead to more efficient models that maintain effectiveness while reducing computational resources, potentially decreasing the environmental footprint of training and inference. Our findings may influence the development of specialized architectures for tasks requiring long-context understanding, such as legal document analysis, scientific research, and complex reasoning. However, improved longcontext modeling could also amplify existing challenges in LLMs, including the propagation of biases over longer contexts and enhanced capabilities for generating persuasive misinformation. Research applying the L2M framework should consider these ethical dimensions, particularly how improvements in long-range dependency modeling might affect model safety, fairness, and the verifiability of model outputs."
        },
        {
            "title": "Acknowledgements",
            "content": "The authors acknowledge support from the National Science Foundation under Cooperative Agreement PHY-2019786 (The NSF AI Institute for Artificial Intelligence and Fundamental Interactions). Z.C. acknowledges support from the Mathworks Fellowship. Z.C. thanks Rumen Dangovski for helpful discussions. The research was sponsored by the United States Air Force Research Laboratory and the Department of the Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-2-1000. The computations in this paper were partly run on the FASRC cluster supported by the FAS 9 L2M: Mutual Information Scaling Law for Long-Context Language Modeling Division of Science Research Computing Group at Harvard University. 66, 2012. URL http://jmlr.org/papers/v13/ brown12a.html."
        },
        {
            "title": "References",
            "content": "Alcaraz, F. C. and Rajabpour, M. Universal behavior of the shannon mutual information of critical quantum chains., 2013. J., Lee, Bahri, Y., Dyer, E., Kaplan, and Sharma, U. Explaining neural scaling laws. Prothe National Academy of Sciences, ceedings of 121(27):e2311878121, 2024. 10.1073/pnas. 2311878121. URL https://www.pnas.org/doi/ abs/10.1073/pnas.2311878121. doi: J., Beck, M., Poppel, K., Spanring, M., Auer, A., Prudnikova, O., Kopp, M., Klambauer, G., Brandstetter, J., and Hochreiter, S. xlstm: Extended long short-term memory, 2024. URL https://arxiv.org/abs/2405. 04517. Belghazi, M. I., Baratin, A., Rajeswar, S., Ozair, S., Bengio, Y., Courville, A., and Hjelm, R. D. Mine: Mutual information neural estimation, 2021. URL https: //arxiv.org/abs/1801.04062. Beltagy, I., Peters, M. E., and Cohan, A. Longformer: The long-document transformer, 2020. URL https: //arxiv.org/abs/2004.05150. Bentz, C., Alikaniotis, D., Cysouw, M., and Cancho, R. F. The entropy of words - learnability and expressivity across more than 1000 languages, 2017. Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., OBrien, K., Hallahan, E., Khan, M. A., Purohit, S., Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and van der Wal, O. Pythia: suite for analyzing large language models across training and scaling, 2023. URL https://arxiv.org/abs/2304.01373. Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., Pieler, M., Prashanth, U. S., Purohit, S., Reynolds, L., Tow, J., Wang, B., and Weinbach, S. Gpt-neox-20b: An open-source autoregressive language model, 2022. URL https://arxiv.org/abs/2204.06745. Bordelon, B., Atanasov, A., and Pehlevan, C. dynamical model of neural scaling laws, 2024. URL https:// arxiv.org/abs/2402.01092. Brown, G., Pocock, A., Zhao, M.-J., and Lujan, M. Conditional likelihood maximisation: unifying framework for information theoretic feature selection. Journal of Machine Learning Research, 13(2):27 10 Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot In Larochelle, H., learners. Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 18771901. Curran Associates, Inc., 2020. URL https://proceedings.neurips. cc/paper_files/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper. pdf. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y., Li, Y.-F., Lundberg, S. M., Nori, H., Palangi, H., Ribeiro, M. T., and Zhang, Y. Sparks of artificial general intelligence: Early experiments with gpt-4, 2023. Carleo, G., Cirac, I., Cranmer, K., Daudet, L., Schuld, M., Tishby, N., Vogt-Maranto, L., and Zdeborova, L. Machine learning and the physical sciences. Rev. Mod. Phys., 91:045002, Dec 2019. doi: 10.1103/RevModPhys.91. 045002. URL https://link.aps.org/doi/10. 1103/RevModPhys.91.045002. Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R. (eds.), Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips. cc/paper_files/paper/2016/file/ 7c9d0b1f96aebd7b5eca8c3edaa19ebb-Paper. pdf. Chen, Z. and Luo, D. Entangling intelligence: Ai-quantum In 2024 IEEE 6th Intercrossovers and perspectives. national Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA), pp. 516 519, 2024. doi: 10.1109/TPS-ISA62245.2024.00069. Chen, Z., Luo, D., Hu, K., and Clark, B. K. Simulating 2+1d lattice quantum electrodynamics at finite density with neural flow wavefunctions, 2022. URL https: //arxiv.org/abs/2212.06835. Chen, Z., Newhouse, L., Chen, E., Luo, D., and Soljacic, M. Antn: Bridging autoregressive neural networks L2M: Mutual Information Scaling Law for Long-Context Language Modeling and tensor networks for quantum many-body simIn Oh, A., Naumann, T., Globerson, A., ulation. Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems, volume 36, pp. 450476. Curran Associates, Inc., 2023. URL https://proceedings.neurips. cc/paper_files/paper/2023/file/ 01772a8b0420baec00c4d59fe2fbace6-Paper-Conference. pdf. Cohn, H. and Zhao, Y. Sphere packing bounds via spherical codes. Duke Mathematical Journal, 163 (10), July 2014. doi: 10.1215/ ISSN 0012-7094. 00127094-2738857. URL http://dx.doi.org/ 10.1215/00127094-2738857. Dai, Y.-W., Chen, X.-H., Cho, S. Y., and Zhou, H.-Q. Critical exponents of block-block mutual information in onedimensional infinite lattice systems., 2020. Chen, Z., Dangovski, R., Loh, C., Dugan, O., Luo, D., and Soljaˇcic, M. Quanta: Efficient high-rank fine-tuning of llms with quantum-informed tensor adaptation, 2024a. URL https://arxiv.org/abs/2406.00132. Chen, Z., McCarran, J., Vizcaino, E., Soljacic, M., and Luo, D. TENG: Time-evolving natural gradient for solving PDEs with deep neural nets toward machine precision. In Forty-first International Conference on Machine Learning, 2024b. URL https://openreview. net/forum?id=v1I4zRAjMb. Cheng, P., Hao, W., Dai, S., Liu, J., Gan, Z., and Carin, L. Club: contrastive log-ratio upper bound of mutual information, 2020. URL https://arxiv.org/abs/ 2006.12013. Child, R., Gray, S., Radford, A., and Sutskever, I. Generating long sequences with sparse transformers, 2019. URL https://arxiv.org/abs/1904.10509. Choi, S., Salamin, Y., Roques-Carmes, C., Dangovski, R., Luo, D., Chen, Z., Horodynski, M., Sloan, J., Uddin, S. Z., and Soljaˇcic, M. Photonic probabilistic machine learning using quantum vacuum noise. Nature Communications, 15(1):7760, Sep 2024. ISSN 2041-1723. doi: 10.1038/ s41467-024-51509-0. URL https://doi.org/10. 1038/s41467-024-51509-0. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling language modeling with pathways, 2022. URL https://arxiv.org/abs/2204.02311. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and Salakhutdinov, R. Transformer-xl: Attentive language models beyond fixed-length context, 2019. URL https://arxiv.org/abs/1901.02860. Dao, T. Flashattention-2: Faster attention with better parallelism and work partitioning, 2023. URL https: //arxiv.org/abs/2307.08691. Dao, T. and Gu, A. Transformers are ssms: Generalized models and efficient algorithms through structured state space duality, 2024. URL https://arxiv.org/ abs/2405.21060. Dao, T., Fu, D. Y., Ermon, S., Rudra, A., and Re, C. Flashattention: Fast and memory-efficient exact attention with ioawareness, 2022. URL https://arxiv.org/abs/ 2205.14135. De, S., Smith, S. L., Fernando, A., Botev, A., CristianMuraru, G., Gu, A., Haroun, R., Berrada, L., Chen, Y., Srinivasan, S., Desjardins, G., Doucet, A., Budden, D., Teh, Y. W., Pascanu, R., Freitas, N. D., and Gulcehre, C. Griffin: Mixing gated linear recurrences with local attention for efficient language models, 2024. URL https://arxiv.org/abs/2402.19427. Debowski, L. Excess entropy in natural language: present state and perspectives, 2011. DeepSeek-AI, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C., Zhang, C., Ruan, C., Dai, D., Guo, D., Yang, D., Chen, D., Ji, D., Li, E., Lin, F., Dai, F., Luo, F., Hao, G., Chen, G., Li, G., Zhang, H., Bao, H., Xu, H., Wang, H., Zhang, H., Ding, H., Xin, H., Gao, H., Li, H., Qu, H., Cai, J. L., Liang, J., Guo, J., Ni, J., Li, J., Wang, J., Chen, J., Chen, J., Yuan, J., Qiu, J., Li, J., Song, J., Dong, K., Hu, K., Gao, K., Guan, K., Huang, K., Yu, K., Wang, L., Zhang, L., Xu, L., Xia, L., Zhao, L., Wang, L., Zhang, L., Li, M., Wang, M., Zhang, M., Zhang, M., Tang, M., Li, M., Tian, N., Huang, P., Wang, P., Zhang, P., Wang, Q., Zhu, Q., Chen, Q., Du, Q., Chen, R. J., Jin, R. L., Ge, R., Zhang, R., Pan, R., Wang, R., Xu, R., Zhang, R., Chen, R., Li, S. S., Lu, S., Zhou, S., Chen, S., Wu, S., Ye, S., Ye, S., Ma, S., Wang, S., Zhou, S., Yu, S., Zhou, S., Pan, S., Wang, T., Yun, T., Pei, T., Sun, T., Xiao, W. L., Zeng, W., Zhao, W., An, W., Liu, L2M: Mutual Information Scaling Law for Long-Context Language Modeling W., Liang, W., Gao, W., Yu, W., Zhang, W., Li, X. Q., Jin, X., Wang, X., Bi, X., Liu, X., Wang, X., Shen, X., Chen, X., Zhang, X., Chen, X., Nie, X., Sun, X., Wang, X., Cheng, X., Liu, X., Xie, X., Liu, X., Yu, X., Song, X., Shan, X., Zhou, X., Yang, X., Li, X., Su, X., Lin, X., Li, Y. K., Wang, Y. Q., Wei, Y. X., Zhu, Y. X., Zhang, Y., Xu, Y., Xu, Y., Huang, Y., Li, Y., Zhao, Y., Sun, Y., Li, Y., Wang, Y., Yu, Y., Zheng, Y., Zhang, Y., Shi, Y., Xiong, Y., He, Y., Tang, Y., Piao, Y., Wang, Y., Tan, Y., Ma, Y., Liu, Y., Guo, Y., Wu, Y., Ou, Y., Zhu, Y., Wang, Y., Gong, Y., Zou, Y., He, Y., Zha, Y., Xiong, Y., Ma, Y., Yan, Y., Luo, Y., You, Y., Liu, Y., Zhou, Y., Wu, Z. F., Ren, Z. Z., Ren, Z., Sha, Z., Fu, Z., Xu, Z., Huang, Z., Zhang, Z., Xie, Z., Zhang, Z., Hao, Z., Gou, Z., Ma, Z., Yan, Z., Shao, Z., Xu, Z., Wu, Z., Zhang, Z., Li, Z., Gu, Z., Zhu, Z., Liu, Z., Li, Z., Xie, Z., Song, Z., Gao, Z., and Pan, Z. Deepseek-v3 technical report, 2024. URL https://arxiv.org/abs/2412.19437. Ding, J., Ma, S., Dong, L., Zhang, X., Huang, S., Wang, W., Zheng, N., and Wei, F. Longnet: Scaling transformers to 1,000,000,000 tokens, 2023. URL https://arxiv. org/abs/2307.02486. Dugan, O., Beneto, D. M. J., Loh, C., Chen, Z., Dangovski, R., and Soljaˇcic, M. Occamllm: Fast and exact language model arithmetic in single step, 2024. URL https: //arxiv.org/abs/2406.06576. Ebeling, W. and Neiman, A. Long-range correlations between letters and sentences in texts. Physica A: Statistical Mechanics and its Applications, 215(3):233241, 1995. doi: ISSN 0378-4371. https://doi.org/10.1016/0378-4371(95)00025-3. URL science/article/pii/0378437195000253. https://www.sciencedirect.com/ Ebeling, W. and Poschel, T. Entropy and long-range correlations in literary english, 1994a. Ebeling, W. and Poschel, T. Entropy and long-range correlations in literary english. Europhysics Letters, 26(4):241, may 1994b. doi: 10.1209/0295-5075/26/ 4/001. URL https://dx.doi.org/10.1209/ 0295-5075/26/4/001. Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain, D., Chen, C., Grosse, R., McCandlish, S., Kaplan, J., Amodei, D., Wattenberg, M., and Olah, C. Toy models of superposition, 2022. URL https://arxiv.org/ abs/2209.10652. Foundation, W. Wikimedia downloads. URL https:// dumps.wikimedia.org. 12 Futrell, R., Qian, P., Gibson, E., Fedorenko, E., and Blank, I. Syntactic dependencies correspond to word pairs with high mutual information. In Gerdes, K. and Kahane, S. (eds.), Proceedings of the Fifth International Conference on Dependency Linguistics (Depling, SyntaxFest 2019), pp. 313, Paris, France, August 2019. Association for Computational Linguistics. doi: 10.18653/v1/ W19-7703. URL https://aclanthology.org/ W19-7703/. Gao, S., Steeg, G. V., and Galstyan, A. Efficient estimation of mutual information for strongly dependent variables, 2015. URL https://arxiv.org/abs/ 1411.2003. Ge, Y., Hua, W., Ji, J., Tan, J., Xu, S., and Zhang, Y. Openagi: When llm meets domain experts, 2023. Gelbukh, A. and Sidorov, G. Zipf and heaps laws coefIn Conference on Intelficients depend on language. ligent Text Processing and Computational Linguistics, 2001. URL https://api.semanticscholar. org/CorpusID:20344161. Goldfeld, Z. and Polyanskiy, Y. The information bottleneck problem and its applications in machine learning. IEEE Journal on Selected Areas in Information Theory, 1(1): 1938, 2020. doi: 10.1109/JSAIT.2020.2991561. Gou, Z., Shao, Z., Gong, Y., Shen, Y., Yang, Y., Huang, M., Duan, N., and Chen, W. Tora: tool-integrated reasoning agent for mathematical problem solving, 2023. Grassberger, P. Entropy estimates from insufficient samplings, 2008. URL https://arxiv.org/abs/ physics/0307138. Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E. M., Radenovic, F., Guzman, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L., Thattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, L2M: Mutual Information Scaling Law for Long-Context Language Modeling J., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia, J., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield, K., Stone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary, L., van der Maaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher, L., Landzaat, L., de Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M., Tsimpoukelli, M., Oldham, M., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh, M. K., Hassan, M., Goyal, N., Torabi, N., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N., Duchenne, O., elebi, O., Alrassy, P., Zhang, P., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal, P., Krishnan, P., Koura, P. S., Xu, P., He, Q., Dong, Q., Srinivasan, R., Ganapathy, R., Calderer, R., Cabral, R. S., Stojnic, R., Raileanu, R., Maheswari, R., Girdhar, R., Patel, R., Sauvestre, R., Polidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang, R., Hosseini, S., Chennabasappa, S., Singh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang, S., Raparthy, S., Shen, S., Wan, S., Bhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S., Collot, S., Gururangan, S., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speckbacher, T., Mihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez, V., Gonguet, V., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W., Martinet, X., Wang, X., Wang, X., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur, Y., Babaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z., Papakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria, A., Goldstand, A., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A., Sangani, A., Teo, A., Yunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A., Ryan, A., Ramchandani, A., Dong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel, A., Bharambe, A., Eisenman, A., Yazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B., Loyd, B., Paola, B. D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B., Stojkovic, B., Gamido, B., Montalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C., Wang, C., Kim, C., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty, D., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine, D., David, D., Parikh, D., Liskovich, D., Foss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil, E., Montgomery, E., Presani, E., Hahn, E., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun, F., Kreuk, F., Tian, F., Kokkinos, F., Ozgenel, F., Caggioni, F., Kanayet, F., Seide, F., Florez, G. M., Schwarz, G., Badeer, G., Swee, G., Halpern, G., Herman, G., Sizov, G., Guangyi, Zhang, Lakshminarayanan, G., Inan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H., Suk, H., Aspegren, H., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche, I.-E., Gat, I., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan, J., Zhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard, J., McPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K. H., Saxena, K., Khandelwal, K., Zand, K., Matosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K., Chawla, K., Huang, K., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L., Moshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M., Lennie, M., Reso, M., Groshev, M., Naumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M. L., Valko, M., Restrepo, M., Patel, M., Vyatskov, M., Samvelyan, M., Clark, M., Macey, M., Wang, M., Hermoso, M. J., Metanat, M., Rastegari, M., Bansal, M., Santhanam, N., Parks, N., White, N., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev, N. P., Dong, N., Cheng, N., Chernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P., Balaji, P., Rittner, P., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang, Q., Alao, R., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan, R., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S. J., Datta, S., Chugh, S., Hunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy, S., Lindsay, S., Lindsay, S., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S., Zhang, S., Zhang, S., Wang, S., Agarwal, S., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield, S., Govindaprasad, S., Gupta, S., Deng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S., Goldman, S., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson, T., Li, T., Zhang, T., Matthews, T., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V., Kumar, V. S., Mangla, V., Ionescu, V., Poenaru, V., Mihailescu, V. T., Ivanov, V., Li, W., Wang, W., Jiang, W., Bouaziz, W., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y., Jia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu, Wang, Zhao, Y., Hao, Y., Qian, Y., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z., and Ma, Z. The llama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783. Gu, A. and Dao, T. Mamba: Linear-time sequence modeling with selective state spaces, 2024. URL https: //openreview.net/forum?id=AL1fq05o7H. Gu, A., Goel, K., and Re, C. Efficiently modeling In Inlong sequences with structured state spaces. ternational Conference on Learning Representations, L2M: Mutual Information Scaling Law for Long-Context Language Modeling 2022a. URL https://openreview.net/forum? id=uYLFoz1vlAC. Gu, A., Goel, K., and Re, C. Efficiently modeling long sequences with structured state spaces, 2022b. URL https://arxiv.org/abs/2111.00396. He, Z., Qin, Z., Prakriya, N., Sun, Y., and Cong, J. Hmt: Hierarchical memory transformer for long context language processing, 2024. URL https://arxiv.org/abs/ 2405.06067. Kraskov, A., Stogbauer, H., and Grassberger, P. EsPhys. Rev. E, 69: timating mutual 066138, 10.1103/PhysRevE.69. doi: 066138. URL https://link.aps.org/doi/10. 1103/PhysRevE.69.066138. information. Jun 2004. Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient memory management for large language model serving with pagedattention, 2023. URL https:// arxiv.org/abs/2309.06180. Hilberg, W. Der bekannte grenzwert der redundanzfreien information in texten - eine fehlinterpretation der shanFrequenz, 44:243 248, nonschen experimente? 1990. URL https://api.semanticscholar. org/CorpusID:124878549. Lami, G., Carleo, G., and Collura, M. Matrix product states with backflow correlations. Phys. Rev. B, 106:L081111, Aug 2022. doi: 10.1103/PhysRevB.106. L081111. URL https://link.aps.org/doi/ 10.1103/PhysRevB.106.L081111. Hjelm, R. D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P., Trischler, A., and Bengio, Y. Learning deep representations by mutual information estimation and maximization, 2019. URL https://arxiv. org/abs/1808.06670. Inc., W. R. Mathematica, Version 14.2. URL https: //www.wolfram.com/mathematica. Champaign, IL, 2024. Jiang, Y., Rajendran, G., Ravikumar, P., Aragam, B., and Veitch, V. On the origins of linear representations in large language models, 2024. Kabatiansky, G. A. and Levenshtein, V. I. On bounds for packings on sphere and in space. Problemy Peredachi Informatsii, 14(1):325, 1978. URL http: //mi.mathnet.ru/ppi1518. English translation: Problems Inform. Transmission, vol. 14, no. 1, pp. 117, 1978. Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. Scaling laws for neural language models, 2020. URL https://arxiv.org/abs/2001. 08361. Katharopoulos, A., Vyas, A., Pappas, N., and Fleuret, F. Transformers are rnns: Fast autoregressive transformers with linear attention, 2020. URL https://arxiv. org/abs/2006.16236. Kawabata, T. and Dembo, A. The rate-distortion diIEEE Transactions mension of sets and measures. on Information Theory, 40(5):15641572, 1994. doi: 10.1109/18.333868. Kosinski, M. Theory of mind may have spontaneously emerged in large language models, 2023. 14 Lee, C.-H., Khan, A., Luo, D., Santos, T. P., Shi, C., Janicek, B. E., Kang, S., Zhu, W., Sobh, N. A., Schleife, A., Clark, B. K., and Huang, P. Y. Deep learning enabled strain mapping of single-atom defects in twodimensional transition metal dichalcogenides with subpicometer precision. Nano Letters, 20(5):33693377, May 2020. ISSN 1530-6984. doi: 10.1021/acs.nanolett. 0c00269. URL https://doi.org/10.1021/acs. nanolett.0c00269. Li, J., Chen, D., Cai, T., Chen, P., Hong, Y., Chen, Z., Shen, Y., and Gan, C. Flexattention for efficient highresolution vision-language models, 2024. URL https: //arxiv.org/abs/2407.20228. Lin, H. W. and Tegmark, M. Critical behavior in physics and probabilistic formal languages. Entropy, 19(7), 2017. doi: 10.3390/e19070299. URL https://www.mdpi.com/1099-4300/19/ 7/299. ISSN 1099-4300. Lu, S., Kanasz-Nagy, M., Kukuljan, I., and Cirac, J. I. Tensor networks and efficient descriptions of classical data, 2024. URL https://arxiv.org/abs/2103. 06872. Luo, D. and Clark, B. K. Backflow transformations via neural networks for quantum many-body Phys. Rev. Lett., 122:226401, wave functions. Jun 2019. 10.1103/PhysRevLett.122.226401. URL https://link.aps.org/doi/10.1103/ PhysRevLett.122.226401. doi: Luo, D., Chen, Z., Carrasquilla, J., and Clark, B. K. Autoregressive neural network for simulating open quantum systems via probabilistic formulation. Phys. Rev. Lett., 128:090501, Feb 2022. doi: 10.1103/PhysRevLett.128. 090501. URL https://link.aps.org/doi/10. 1103/PhysRevLett.128.090501. L2M: Mutual Information Scaling Law for Long-Context Language Modeling Luo, D., Chen, Z., Hu, K., Zhao, Z., Hur, V. M., Gauge-invariant and anyonicand Clark, B. K. symmetric autoregressive neural network for quanPhys. Rev. Res., 5:013216, tum lattice models. Mar 2023. doi: 10.1103/PhysRevResearch.5.013216. URL https://link.aps.org/doi/10.1103/ PhysRevResearch.5.013216. Meta. URL https://ai.meta.com/blog/ meta-llama-3-1/. fractal MONTEMURRO, M. A. and correlations Fractals, 10(04):451461, 2002. Long-range pora. 10.1142/S0218348X02001257. //doi.org/10.1142/S0218348X02001257. P. A. cordoi: URL https: PURY, in literary Moro, V., Loh, C., Dangovski, R., Ghorashi, A., Ma, A., Chen, Z., Kim, S., Lu, P. Y., Christensen, T., and Soljaˇcic, M. Multimodal learning for materials, 2024. URL https://arxiv.org/abs/2312.00111. Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A. Show your work: Scratchpads for intermediate computation with language models, 2021. URL https://arxiv.org/ abs/2112.00114. OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Balaji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M., Belgum, J., Bello, I., Berdine, J., Bernadett-Shapiro, G., Berner, C., Bogdonoff, L., Boiko, O., Boyd, M., Brakman, A.-L., Brockman, G., Brooks, T., Brundage, M., Button, K., Cai, T., Campbell, R., Cann, A., Carey, B., Carlson, C., Carmichael, R., Chan, B., Chang, C., Chantzis, F., Chen, D., Chen, S., Chen, R., Chen, J., Chen, M., Chess, B., Cho, C., Chu, C., Chung, H. W., Cummings, D., Currier, J., Dai, Y., Decareaux, C., Degry, T., Deutsch, N., Deville, D., Dhar, A., Dohan, D., Dowling, S., Dunning, S., Ecoffet, A., Eleti, A., Eloundou, T., Farhi, D., Fedus, L., Felix, N., Fishman, S. P., Forte, J., Fulford, I., Gao, L., Georges, E., Gibson, C., Goel, V., Gogineni, T., Goh, G., Gontijo-Lopes, R., Gordon, J., Grafstein, M., Gray, S., Greene, R., Gross, J., Gu, S. S., Guo, Y., Hallacy, C., Han, J., Harris, J., He, Y., Heaton, M., Heidecke, J., Hesse, C., Hickey, A., Hickey, W., Hoeschele, P., Houghton, B., Hsu, K., Hu, S., Hu, X., Huizinga, J., Jain, S., Jain, S., Jang, J., Jiang, A., Jiang, R., Jin, H., Jin, D., Jomoto, S., Jonn, B., Jun, H., Kaftan, T., Łukasz Kaiser, Kamali, A., Kanitscheider, I., Keskar, N. S., Khan, T., Kilpatrick, L., Kim, J. W., Kim, C., Kim, Y., Kirchner, J. H., Kiros, J., Knight, M., Kokotajlo, D., Łukasz Kondraciuk, Kondrich, A., Konstantinidis, A., Kosic, K., Krueger, G., Kuo, V., 15 Lampe, M., Lan, I., Lee, T., Leike, J., Leung, J., Levy, D., Li, C. M., Lim, R., Lin, M., Lin, S., Litwin, M., Lopez, T., Lowe, R., Lue, P., Makanju, A., Malfacini, K., Manning, S., Markov, T., Markovski, Y., Martin, B., Mayer, K., Mayne, A., McGrew, B., McKinney, S. M., McLeavey, C., McMillan, P., McNeil, J., Medina, D., Mehta, A., Menick, J., Metz, L., Mishchenko, A., Mishkin, P., Monaco, V., Morikawa, E., Mossing, D., Mu, T., Murati, M., Murk, O., Mely, D., Nair, A., Nakano, R., Nayak, R., Neelakantan, A., Ngo, R., Noh, H., Ouyang, L., OKeefe, C., Pachocki, J., Paino, A., Palermo, J., Pantuliano, A., Parascandolo, G., Parish, J., Parparita, E., Passos, A., Pavlov, M., Peng, A., Perelman, A., de Avila Belbute Peres, F., Petrov, M., de Oliveira Pinto, H. P., Michael, Pokorny, Pokrass, M., Pong, V. H., Powell, T., Power, A., Power, B., Proehl, E., Puri, R., Radford, A., Rae, J., Ramesh, A., Raymond, C., Real, F., Rimbach, K., Ross, C., Rotsted, B., Roussez, H., Ryder, N., Saltarelli, M., Sanders, T., Santurkar, S., Sastry, G., Schmidt, H., Schnurr, D., Schulman, J., Selsam, D., Sheppard, K., Sherbakov, T., Shieh, J., Shoker, S., Shyam, P., Sidor, S., Sigler, E., Simens, M., Sitkin, J., Slama, K., Sohl, I., Sokolowsky, B., Song, Y., Staudacher, N., Such, F. P., Summers, N., Sutskever, I., Tang, J., Tezak, N., Thompson, M. B., Tillet, P., Tootoonchian, A., Tseng, E., Tuggle, P., Turley, N., Tworek, J., Uribe, J. F. C., Vallone, A., Vijayvergiya, A., Voss, C., Wainwright, C., Wang, J. J., Wang, A., Wang, B., Ward, J., Wei, J., Weinmann, C., Welihinda, A., Welinder, P., Weng, J., Weng, L., Wiethoff, M., Willner, D., Winter, C., Wolrich, S., Wong, H., Workman, L., Wu, S., Wu, J., Wu, M., Xiao, K., Xu, T., Yoo, S., Yu, K., Yuan, Q., Zaremba, W., Zellers, R., Zhang, C., Zhang, M., Zhao, S., Zheng, T., Zhuang, J., Zhuk, W., and Zoph, B. Gpt-4 technical report, 2024. URL https://arxiv.org/abs/2303.08774. Park, K., Choe, Y. J., and Veitch, V. The linear representation hypothesis and the geometry of large language models, 2023. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. Pytorch: An imperative style, high-performance deep learning library, 2019. URL https://arxiv.org/abs/1912.01703. Peng, B., Alcaide, E., Anthony, Q. G., Albalak, A., Arcadinho, S., Biderman, S., Cao, H., Cheng, X., Chung, M. N., Derczynski, L., Du, X., Grella, M., GV, K. K., He, X., Hou, H., Kazienko, P., Kocon, J., Kong, J., Koptyra, B., Lau, H., Lin, J., Mantri, K. S. I., Mom, F., Saito, A., Song, G., Tang, X., Wind, J. S., Wozniak, S., Zhang, Z., Zhou, Q., Zhu, J., and Zhu, R.-J. RWKV: Reinventing RNNs for the transformer era. In The 2023 Conference L2M: Mutual Information Scaling Law for Long-Context Language Modeling on Empirical Methods in Natural Language Processing, 2023. URL https://openreview.net/forum? id=7SaXczaBpG. Poole, B., Ozair, S., van den Oord, A., Alemi, A. A., and Tucker, G. On variational bounds of mutual information, 2019. URL https://arxiv.org/abs/1905. 06922. Qin, Z., Sun, W., Li, D., Shen, X., Sun, W., and Zhong, Y. Lightning attention-2: free lunch for handling unlimited sequence lengths in large language models, 2024. URL https://arxiv.org/abs/2401.04658. Rae, J. W., Potapenko, A., Jayakumar, S. M., and Lillicrap, T. P. Compressive transformers for long-range sequence modelling, 2019. URL https://arxiv.org/abs/ 1911.05507. Rae, J. W., Potapenko, A., Jayakumar, S. M., Hillier, C., and Lillicrap, T. P. Compressive transformers for longrange sequence modelling. In International Conference on Learning Representations, 2020. URL https:// openreview.net/forum?id=SylKikSYDH. Shah, J., Bikshandi, G., Zhang, Y., Thakkar, V., Ramani, P., and Dao, T. Flashattention-3: Fast and accurate attention with asynchrony and low-precision, 2024. URL https: //arxiv.org/abs/2407.08608. Shen, H. Mutual information scaling and expressive power of sequence models, 2019. URL https://arxiv. org/abs/1905.04271. Stanley, H. E. Power laws and universality. Nature, 378: 554555, 1995. doi: 10.1038/378554a0. Stiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, R. J., Voss, C., Radford, A., Amodei, D., and Christiano, P. Learning to summarize from human feedback, 2020. Stokes, J., Izaac, J., Killoran, N., and Carleo, G. Quantum Natural Gradient. Quantum, 4:269, May 2020. 10.22331/ q-2020-05-25-269. URL https://doi.org/10. 22331/q-2020-05-25-269. ISSN 2521-327X. doi: Sukhbaatar, S., Grave, E., Bojanowski, P., and Joulin, A. Adaptive attention span in transformers, 2019. URL https://arxiv.org/abs/1905.07799. Sun, Y., Li, X., Dalal, K., Xu, J., Vikram, A., Zhang, G., Dubois, Y., Chen, X., Wang, X., Koyejo, S., Hashimoto, T., and Guestrin, C. Learning to (learn at test time): Rnns with expressive hidden states, 2024. URL https: //arxiv.org/abs/2407.04620. 16 Tishby, N. and Zaslavsky, N. Deep learning and the inIn 2015 IEEE Inforformation bottleneck principle. mation Theory Workshop (ITW), pp. 15, 2015. doi: 10.1109/ITW.2015.7133169. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. Llama: Open and efficient foundation language models, 2023a. URL https://arxiv.org/abs/ 2302.13971. Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. Llama 2: Open foundation and fine-tuned chat models, 2023b. URL https://arxiv.org/ abs/2307.09288. Tschannen, M., Djolonga, J., Rubenstein, P. K., Gelly, S., and Lucic, M. On mutual information maximization for representation learning. In International Conference on Learning Representations, 2020. URL https:// openreview.net/forum?id=rkxoh24FPH. Wang, J., Chen, Z., Luo, D., Zhao, Z., Hur, V. M., and Clark, B. K. Spacetime neural network for high dimensional quantum dynamics, 2021. URL https: //arxiv.org/abs/2108.02200. Wang, J., Meng, F., Liang, Y., and Zhou, J. Drt-o1: Optimized deep reasoning translation via long chain-ofthought, 2024. URL https://arxiv.org/abs/ 2412.17498. Wang, Y., Le, H., Gotmare, A. D., Bui, N. D. Q., Li, J., and Hoi, S. C. H. Codet5+: Open code large language models for code understanding and generation, 2023. Wei, J., Wang, X., Schuurmans, D., Bosma, M., brian ichter, Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain of thought prompting elicits reasoning in large language models. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/ forum?id=_VjQlMeSB_J. L2M: Mutual Information Scaling Law for Long-Context Language Modeling Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T. L., Gugger, S., Drame, M., Lhoest, Q., and Rush, A. M. Huggingfaces transformers: State-of-the-art natural language processing, 2020. URL https://arxiv.org/abs/1910.03771. Wu, D., Rossi, R., Vicentini, F., and Carleo, G. From tensor-network quantum states to tensorial recurrent neural networks. Physical Review Research, 5(3), July 2023. ISSN 2643-1564. doi: 10.1103/physrevresearch. 5.l032001. URL http://dx.doi.org/10.1103/ PhysRevResearch.5.L032001. Yuan, A., Coenen, A., Reif, E., and Ippolito, D. Wordcraft: Story writing with large language models, 2022. Zaheer, M., Guruganesh, G., Dubey, K. A., Ainslie, J., Alberti, C., Ontanon, S., Pham, P., Ravula, A., Wang, Q., Yang, L., and Ahmed, A. Big bird: Transformers for longer sequences. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1728317297. Curran Associates, Inc., 2020. URL https://proceedings.neurips. cc/paper_files/paper/2020/file/ c8512d142a2d849725f31a9a7a361ab9-Paper. pdf. Zhu, C., Ping, W., Xiao, C., Shoeybi, M., Goldstein, T., Anandkumar, A., and Catanzaro, B. Long-short transformer: Efficient transformers for language and vision, 2021. URL https://arxiv.org/abs/2107. 02192. Łukasz Debowski. The relaxed hilberg conjecture: review and new experimental support. Journal of Quantitative Linguistics, 22(4):311337, 2015. doi: 10.1080/ 09296174.2015.1106268. URL https://doi.org/ 10.1080/09296174.2015.1106268. 17 L2M: Mutual Information Scaling Law for Long-Context Language Modeling A. Additional Details on Mutual Information Scalings A.I. Hilberg Conjecture In the main text, we mainly discussed the bipartite mutual information with equal splitting of tokens with X1:L/2 := W1:L/2 and Y1:L/2 := WL/2+1:L where W1:L is the sequence of tokens. The relaxed Hilberg conjecture states that this bipartite mutual information follows power-law growth BP L/2;L := I(X1:L/2, Y1:L/2) (A.1) L/2;L Lβ. BP (A.2) In Hilbergs original work (Hilberg, 1990), however, he considered more strict conjecture that says the entropy of natural language should also follow power law H(W1:L) Lβ. (A.3) It is easy to see that the Hilberg conjecture leads to the relaxed Hilberg conjecture. BP L/2;L = H(W1:L/2) + H(WL/2+1:L) H(W1:L) = (cid:19)β (cid:18) 2 + (cid:19)β (cid:18) 2 ALβ = A(21β 1)Lβ Lβ. (A.4) However, the converse is not trueallowing the entropy of natural language to have an additional linear term does not alter the biparitite mutual information scaling. A.II. Universal Compression Code Approximation of Mutual Information One important result in information theory is the relation between the entropy of random variable, to its average compression rate. In particular, The average number of bits needed to store the random variable, often referred to as the Kolmogorov complexity, is upper bounded by its entropy K(X) = E[C(X)] H2(X), (A.5) where C() denotes compression algorithm, is the length of the bitstring, and H2() = log 2H() is the entropy measured in bits, to distinguish from entropy measured in nats used in the main text. Because this difference in unit only results in difference in multiplicative constant and does not alter the scaling, we will drop this log 2 constant and make no distinction between the units in later discussions. The Kolmogorov complexity allows the bipartite mutual information to be estimated as L/2;L BP,Kol BP L/2;L := K(W1:L/2) + K(WL/2+1:L) K(W1:L). (A.6) Since no compression code perfectly compresses natural language, it is reasonable to believe that the Kolmogorov complexity grows faster than the entropy of natural language. Assuming the original Hilberg conjecture [Eq. (A.3)] is true, it is reasonable to believe that the Kolmogorov complexity scales as K(W1:L) Lβ+ε, (A.7) with ε due to the inefficiency of compression code. Therefore, the Kolmogorov estimation of the mutual information would also grow as BP,Kol L/2;L Lβ+ε, (A.8) resulting in an overestimation of the scaling exponent. A.III. Direct Estimation of Biparitite Mutual Information Using LLMs In the main text, our direct estimator for the bipartite mutual information is BP,direct ℓ;L = EpXY [log q(Y X) log q(Y )] = H(pY , qY ) H(pY , qY ) = p(X; ) + ε(p, q). (A.9) 18 L2M: Mutual Information Scaling Law for Long-Context Language Modeling where as usual, := X1:ℓ := W1:ℓ and := Y1:Lℓ := Wℓ+1:L with W1:L being sequence of tokens. However, as discussed in the main text, the H(pY , qY ) term suffers from an additional biaswe cannot guarantee that starts at the beginning of sentence, but LLMs model distributions conditioned on BOS token. To mitigate this issue, we use n-gram calculations to correct the entropy of the first two tokens as explained below. We first rewrite the (marginal) cross entropy as H(pY , qY ) = Ep[log q(Y )] = Lℓ (cid:88) i=1 Ep[log q(YiY1:i1)], (A.10) where as usual, the omitted expectation over the conditional variable is implied in the cross entropy calculation. In modern LLMs, we can only compute q(yiyi:i1, wBOS) = q(yiyi:i1), resulting in an additional error in the bipartite mutual information estimation. In practice, this difference becomes less pronounced for larger i, because it matters less if the sequence starts at the beginning of sequence or not if there are many yi:i1 prior tokens to conditional on. Therefore, we focusing on reducing the bias for small i. In addition, if is small, we can iterate over the dataset and construct histogram for the i-gram distribution p(y1:i). We denote the count for each i-tuple of tokens with ny1:i and the total number of samples with . Then, the entropy of the distribution can be estimated naively as ˆH naıve(Y1:i) = ny1:i (cid:88) y1:i log ny1:i = log 1 (cid:88) y1:i ny1:i log ny1:i, (A.11) where the summation runs over all possible combination of tokens y1:i := (y1, y2, . . . yi). However, this estimation is severely biased and underestimates the true entropy, due to the concavity of logarithm function. In (Grassberger, 2008), bias-corrected estimator is proposed by replacing the logarithm function with new function where ˆH G(Y1:i) = log 1 (cid:88) y1:i ny1:iG(ny1:i), G(n) = ψ(n) + (1)n 2 (cid:18) ψ (cid:18) + 1 2 (cid:19) ψ (cid:17)(cid:19) , (cid:16) 2 (A.12) (A.13) with ψ() the digamma function. We note that Ref. (Grassberger, 2008) was not able to obtain the closed form expression for G(), which we derived with the help of Wolfram Mathematica (Inc.). Figure A.1. Effect of bias correction method in the direct estimator. The bias only affects the estimation at small sequence lengths, and all methods converge at large sequence lengths. This bias-corrected estimator still underestimates the true entropy, but much less compared to the original naıve estimator. In the main text, we estimate the (marginal) cross entropy with 2-gram correction in the following way. Breaking up the cross entropy as H(pY , qY ) = Lℓ (cid:88) i= Ep[log q(YiY1:i1)] + H(pY1Y2, qY1Y2). (A.14) 19 L2M: Mutual Information Scaling Law for Long-Context Language Modeling For the first term, we use LLM generated q(yiyi:i1, wBOS) as approximation. For the second term, we mitigate the bias from LLM estimation by combining it with Eq. (A.12) as H(pY1Y2, qY1Y2wBOS )/5 + 4 ˆH (Y1, Y2)/5. In Fig. A.1, we also present the result without this correction and show that this bias correction mostly affects the estimation at small lengths L, and does not alter the generalizing scaling behavior. In addition, since the result from this bias-corrected direct estimator agrees with the vCLUB (Cheng et al., 2020) estimator, we believe this correction is reasonable. A.IV. Bipartite Mutual Information Scaling Using Various LLMs In the main text, we use the LLaMA 3.1 405B model to approximate the underlying distribution of natural language. In this section, we provide additional estimations of the bipartite mutual information scaling using the DeepSeek V3 Base model and LLaMA 3.1 70B model. We note that because we are merely measuring the conditional probabilities of the input tokens without interactions with the agent, we believe the non-instruction-finetuned model better suits our tasks. Figure A.2. Bipartite mutual information estimation using Deepseek V3 Base model and LLaMA 3.1 70B model compared to LLaMA 3.1 405B model on the PG19 dataset. All direct measurements include the bias correction described in Appx. A.III. Both models appear to produce worse estimations of bipartite mutual information at long sequence lengths, but still suggest power-law scaling. In Fig. A.2, we report the results on PG19 dataset and compare them to LLaMA 3.1 405B models results. We find that the DeepSeek V3 Base model estimates consistently lower bipartite mutual information compared to the LLaMA 3.1 405B model, especially at long sequence lengths. Based on our argument in Appx. A.VI, this suggests that the DeepSeek V3 Base model does not approximate the probability distribution at long sequence lengths as well as the LLaMA 3.1 405B model. We believe this could be attributed to the following reasons. (1) The DeepSeek V3 Base model is mixture-of-expert (MOE) model. When we draw samples randomly from the dataset, the topic may not be immediately clear, whereas an MOE model usually needs to know the topic to correctly predict the conditional probabilities. (2) The DeepSeek model is trained without using the cross-sample attention masking (DeepSeek-AI et al., 2024) whereas the LLaMA model is (Grattafiori et al., 2024). Without the mask, concatenated training samples affect the models learned long-range dependencies. In spite of this, the DeepSeek model still largely suggests the existence of power-law growth of bipartite mutual information. LLaMA 3.1 70B model, on the other hand, being smaller mode, estimates lower biparitite mutual information at large sequence lengths. It is unsurprising because smaller model is expected to be worse approximation to the true underlying distribution of natural language In addition, since its predecessor, the LLaMA 3 70B model, only has context window of 8192, this model, despite having larger claimed context window, is likely not trained on as much high-quality long context length data as LLaMA 3.1 405B. Nevertheless, even the small LLaMA 3.1 70B model estimates the bipartite mutual information growth closer to power law than logarithmic. A.V. Bipartite Mutual Information Scaling Under Various Ratios of ℓ/L In the main text, we focused on the bipartite mutual information with equal splits. However, the bipartite mutual information scaling is not limited to equal biparitition. In this section, we provide additional results for various ratios of ℓ/L. In Fig. A.3, we provide estimation of the bipartite mutual information scaling for ℓ/L = 3 and ℓ/L = 4. All results show clear power-law relations, and are consistent with Fig. 2 in the main text. A.VI. Why The Estimated Exponent β Is Likely An Underestimation? In the main text, we mentioned that our measured exponent β using LLMs likely underestimates the true β. Here, we discuss the reasons. 20 L2M: Mutual Information Scaling Law for Long-Context Language Modeling Figure A.3. Bipartite mutual information estimation using different ratios of ℓ/L. All results suggest the existence of power-law scaling, with various fitted exponents. For the direct estimator, BP,direct ℓ;L = H(pY , qY ) H(pY , qY ), (A.15) both terms (without the minus sign) overestimates the true (conditional) entropy, but for different extent and at different scales. At small L, the first term suffers from the bias from the BOS token as discussed in Appx. A.III. The second term, despite also an overestimation, does not suffer from the BOS token issue. Therefore, at small L, the direct estimator tends to overestimate the true entropy. At large L, the bias from the BOS token is less severe. However, modeling p(Y X) requires the model to correctly capture all the dependencies between and , making it significantly harder than modeling p(Y ) along. Therefore, q(Y X) is likely worse estimation of the true distribution than q(Y ), resulting in more overestimation in the second term, and an underestimation of the bipartite mutual information. This means that the direct estimator tends to overestimate the true bipartite mutual information at small and underestimate it at large L, resulting in an underestimation of the fitted exponent. The vCLUB estimator, as pointed out in (Cheng et al., 2020), is an upper bound to the true mutual information if is close to p, but fails to maintain the property when the KL-divergence between them increases. Therefore, it is likely that this estimator also overestimates the true bipartite mutual information at small and underestimates it at large L, resulting in similar underestimation of the fitted exponent as our direct estimator. As our fitted exponent for the vCLUB estimator is smaller than that of the direct estimator, we conclude that the vCLUB estimator has larger bias in this case, and it is reasonable to believe that the true exponent is even larger. A.VII. Estimation of Two-Point Mutual Information As discussed in the main text, the estimation of two-point mutual information can be calculated directly using the n-gram approximation [Eq. (A.12)], and compute the two-point mutual information as (X; ) = ˆH G(X) + ˆH G(Y ) ˆH G(XY ). ˆI TP (A.16) As discussed in Appx. A.III, this entropy estimator has negative bias, whose magnitude depends on the ratio Ω/N , with Ω the size of the corresponding sample space. Since the sample space for the joint distribution is larger, it has larger negative bias, resulting in positive bias in ˆI. When is small, this bias is relatively small compared to the mutual information itself. However, as becomes larger, and become less correlated, and H(XY ) H(X) + H(Y ). In this case, the estimator can be dominated by this bias, and fitting for the power-law exponent becomes impossible. To mitigate this issue, we propose bias-corrected estimator. ˆI TP,corrected (X; ) = ˆH G(X) + ˆH G(Y ) ˆH G(XY ) C, (A.17) where is an unknown positive constant that does not depend on the distance d, which accounts for the bias of the original estimator. 21 L2M: Mutual Information Scaling Law for Long-Context Language Modeling To obtain this bias correction term and fit the power-law exponent, we minimize the following loss function (log ( ˆI TP C) (log α log d))2, (cid:88) (A.18) which is just ˆI TP power-law exponent. = Adα + fitted in log-log space. Then, we take the fitted as the systematic bias and α as the fitted Figure A.4. Effect of bias correction for two-point mutual information. The bias causes plateau at large distances. In Fig. A.4, we compare the corrected and uncorrected two-point mutual information as function of (only the corrected version is shown in the main text). Without the bias correction, the data appear to have larger long-range dependencies, but after the bias correction, all points lie on straight line in log-log plot. The bias correction constant is much smaller than the entropies involved in the calculation, even the smallest two-token entropy measured is 12.5, at least two orders of magnitude larger than the fitted bias correction. In addition, single variable added to the fitting function can fit the data so well, These suggest the bias correction is reasonable and highly effective. We note that on WIKIPEDIA, we were only able to measure the two-point mutual information up to = 256, due to limited long-context length data in WIKIPEDIA. B. Multivariate Gaussian Distributions In the main text, we considered two families of multivariate Gaussian distributions of different sequence lengths to demonstrate the distinction between bipartite and two-point mutual information scalings. In particular, one is designed to mimic natural language, both in terms of the sub-volume law growth of the bipartite mutual information and the power-law decay of two-point mutual information. This family of distributions is also used to empirically verify our theory on L2M condition for different LLM architectures. The other is designed to have the same two-point mutual information scaling, but very different bipartite mutual information scaling, showcasing that one can have distributions with the same two-point mutual information scaling, but drastically different bipartite mutual information scalings. B.I. Construction Lets start by considering the family of distributions with sub-volume law growth. The distributions are constructed in hierarchical manner. We start at the first layer, with four independent standard Gaussian random variables (X1, X2, X3, X4). Then, define the change-of-coordinate matrix = γ γ γ γ γ γ γ γ γ γ γ γ , ρ ρ ρ ρ where we choose γ = 5/4 and ρ = 1/4. The output of the first layer is defined as = MX, 22 (B.19) (B.20) L2M: Mutual Information Scaling Law for Long-Context Language Modeling where the independent random variables are correlated. It is easy to verify that this operation only changes the off-diagonal elements in the covariance matrix, and leaves the diagonal elements unaffected. For the second layer and up, we first stack three independently sampled copies from the previous layer and attach additional independent standard Gaussian random variables as the fourth elements as = Y1,1 Y1,2 Y1,3 W1 Y2,1 Y2,2 Y2,3 W2 Y3,1 Y3,2 Y3,3 W3 ... ... ... ... , (B.21) where refers to the input to the new layer, Yi,j refers to the ith output from previous layer of the jth copy, and Wi refers to the ith newly sampled standard Gaussian random variable. Note that at this point, all rows are independent from each other; therefore we apply the change of coordinate matrix at each row to correlate them. The matrix is then flattened to obtain = (Z1,1, Z1,2, Z1,3, Z1,4, Z2,1, Z2,2, Z2,3, Z2,4, Z3,1, Z3,2, Z3,3, Z3,4, ), (B.22) where the subscripts denote the variables original position in the matrix. Before outputting from this layer, we perform an addition operation to each pair of random variables (Zi,4, Zi+1,1), by applying coordinate transformation that modifies their correlations as corr(Zi,4, Zi+1,1) (corr(Zi,3, Zi,4) + corr(Zi+1,1, Zi+1,2)) + . (B.23) 1 5 2 5 This operation may seem arbitrary, but it is crucial to introduce correlations that give linear ordering of the random variables. Without this operation, the distribution simply forms tree structure. Now, we can truncate the construction at different layers and form family of distributions with different sequence lengths = 4l. In Fig. 3 of the main text, we consider up to 8 layers, and in Fig. 4 and 5, we consider = 4, 5 and, 6. The second family of distributions is constructed analogously. The only difference is that we replace Eq. (B.24) with single copy of and three independent copies of as = Y1 W1,1 W1,2 W1,3 Y2 W2,1 W2,2 W2,3 Y3 W3,1 W3,2 W3,3 ... ... ... ... , (B.24) B.II. Properties These two series of distributions have many nice properties, in addition to their bipartite and two-point mutual information scalings. Due to the analytic construction, their biparite and two-point mutual information can be calculated exactly, without relying on LLM approximations. Moreover, they permit efficient sampling and evaluation of conditional probabilities. In addition, infinitely many samples can be drawn from the distribution, giving us an infinite dataset size. C. Model State for Storing Past Information In Definition 5.1 in the main text, we give concrete definition of model state for storing past information as history state, and claim that it is the past key-value pairs for transformers and latent state for SSMs and RNNs. Here, we explain them in more detail. C.I. Transformers In transformers, only the attention block mixes information among different tokens, therefore we only need to analyze the behavior of the attention block. We will be assuming the existence of the causal mask, as our theory only applies to generative LLMs. Denoting the input and output of the attention layer as and (notice they are no longer two parts of the 23 L2M: Mutual Information Scaling Law for Long-Context Language Modeling same sequence), the self-attention mechanism is defined as = softmax((Wqx)(Wkx)T )Wvx, where Wq, Wk and Wv are the weight matrices. For simplicity, we drop the usual weight matrix, as they are irrelevant to our discussion. Separating the calculation for each token, the mechanism can be rewritten as hdim normalization and the output (C.25) yi = (cid:80)i j=1 e(Wqxi)(Wkxj )Wvxj (cid:80)i j=1 e(Wqxi)(Wkxj ) = e(Wqxi)(Wkxi)Wvxi + (cid:80)i1 e(Wqxi)(Wkxi) + (cid:80)i1 j=1 e(Wqxi)kj j=1 e(Wqxi)kj vj , (C.26) where kj = Wkxj and vj = Wvxj are keys and values which we sum over past tokens. Clearly, the attention output only depends on the current token xi and the past key-value pairs k1:i1 and v1:i1. This arguments extends to all yk with i, where all yks dependency on x1:i1 is via k1:i1 and v1:i1. Therefore, key-value pairs are the model state for storing past information, and their sizes grow linearly with input sequence length. We note that Eq. (C.26) also describes how key-value caching works. C.II. State Space Models and RNNs State space models (SSMs) and RNNs, on the other hand, are easier to analyze. These models in general all have some latent state, or hidden state, with fixed size, and some mechanism to update the state when new token is observed. The output depends only on the past latent state, and the current token. They can in general be written in the following way. hi = (hi1, xi), yi = g(hi1, xi), (C.27) for some update function and output function g. It is obvious that the model state for storing past information is exactly this latent state, which does not grow with the input sequence. We note that this discussion also applies to linear attention models, whose key-value pairs can be merged into latent state with fixed size, due to the replacement of softmax function. Test time training (TTT) models can also be included in this discussion. They can be viewed as SSMs with inner model parameters as latent state, and test time training process as update function. C.III. Other Architectures For other models, such as sparse transformers or some compression-based models, the analysis has to be performed separately. Nevertheless, in general, one wants to identify the smallest hidden state used to cache past information, as it is the bottleneck for modeling long sequences with large bipartite mutual information. D. Additional Proofs for Theorem 5.2 In the main text, we only provided an intuitive proof based on the discreteness of model states. Here, we relax this assumption in different ways and provide additional proofs to the theorem. We start by restating the theorem. Theorem D.1 (Restatement of Theorem 5.2). models capacity to capture bipartite mutual information is bounded by the size of its history state as BP,q ℓ;L dim(zℓ) + log(M ) (D.28) where is some constant and denotes the vocabulary size. We start with proof assuming the following observed fact of neural networksneural networks store distinct information in almost orthogonal directions (AODs) of the hidden state (Elhage et al., 2022; Park et al., 2023; Jiang et al., 2024). Proof. An autoregressive neural networks dependency on past tokens is through the intermediate variable zℓ = (x1:ℓ1 such that q(yx) := q(yxℓ, zℓ). This can be viewed as the process (Zℓ, Xℓ) . According to the data processing inequality, q(X1:ℓ; Y1:Lℓ) q(ZℓXℓ; Y1:Lℓ) Hq(ZℓXℓ) Hq(Zℓ) + q(Xℓ), (D.29) 24 L2M: Mutual Information Scaling Law for Long-Context Language Modeling where we use to denote generalized notion of entropy which measures the amount of information that can be stored in Zℓ, because the standard definition of entropy fails for continuous random variables. Notice that because we only care about the general scaling of H, its exact definition does not matter in this proof. Since neural networks store distinct information in AODs of the hidden state, should scale at most logarithmically with respect to the number of AODs as the state size increases. According to the KabatjanskiiLevenstein bound (Kabatiansky & Levenshtein, 1978; Cohn & Zhao, 2014), given an error tolerance ε, the number of AODs is upper bounded by exp(f (ϵ) dim(zℓ)) for some function that purely depends on the error threshold. Therefore, the generalized entropy at most scales as Hq(Zℓ) log exp(f (ϵ) dim(zℓ)) dim(zℓ). It is easy to see that q(Xℓ) log(M ) with being the vocabulary size, so we conclude BP,q ℓ;L dim(zℓ) + log(M ). (D.30) Alternatively, it is possible to prove the theorem only assuming certain Lipschitz continuous conditions. Proof. This time, we again start with the data processing inequality, but we rewrite the bound as q(X1:ℓ; Y1:Lℓ) q(ZℓXℓ; Y1:Lℓ) q(Zℓ; Y1:Lℓ) + q(Xℓ; Y1:Lℓ) q(Zℓ; Y1:Lℓ) + log(M ), (D.31) where the last inequality used the fact that q(Xℓ; Y1:Lℓ) q(Xℓ) log(M ), with again being the vocabulary size. Notice that the history state is function of the input tokens zℓ = (x1:ℓ1), with x1:ℓ1 {1, 2, . . . , }ℓ1. Assuming satisfies (cid:13) 1:ℓ1), then zℓ = (x1:ℓ1) lives in d-dimensional ball of radius Kf , where is the size of zℓ. Now, consider quantization of zℓ as Q(zℓ), which maps each zℓ to nearest ε-ball that covers the full space of zℓ. Then, we rewrite Kf 1(x1:ℓ1 = (cid:13)f (x1:ℓ1) (x 1:ℓ1)(cid:13) (cid:13)2 q(Zℓ, ) = q(Q(Zℓ), ) + q(Y Q(Zℓ)) q(Y Zℓ). (D.32) We assume the neural network is entropy-Lipschitz, satisfying q(Y zℓ) q(Y ℓ2. Therefore q(Y Q(Zℓ)) q(Y Zℓ) KH ε. For the first term, notice that Q(Zℓ) is discrete, which takes maximum of (2Kf /ε)d possible values due to covering number argument. Therefore, q(Q(Zℓ), ) q(Q) log(2Kf /ε), which leads to q(Zℓ, ) log(2Kf /ε) + KH ε for some constant C. This concludes our proof ℓ) KH zℓ BP,q ℓ;L + log(M ) = dim(zℓ) + log(M ) (D.33) We believe this theorem is more universal and can be proved in additional ways, such as by connecting it to the channel capacity and potentially showing BP,q ℓ;L log(1 + SNR) + log(M ). We also believe the theorem can be established with more relaxed assumptions, similar to how the information dimension is proved to be the upper bound of lossless compression of continuous random variables (Kawabata & Dembo, 1994). However, additional proofs are beyond the scope of this work, and current proofs should be already applicable in any practical settings. E. Additional Details on Experimental Setup In this section, we provide additional details on the experimental setup. For experiments on the multivariate Gaussian distribution, as mentioned in the main text, we stack 64 copies of the distribution and group the 64 Gaussian variables at each position to form single token. More specifically, an example sample looks like = (W1, W2, . . . , WL) := ((Z1,1, Z1,2, . . . , Z1,64), (Z2,1, Z2,2, . . . , Z2,64), . . . , (ZL,1, ZL,2, . . . , ZL,64), (E.34) where again, the two subscripts (i, j) refers to the ith random variable from jth copy. In this way, the bipartite mutual information matches better with natural language, not only in scaling, but also in the coefficient (multiplicative constant). We in addition prepend an all zero token W0 in each sample to mimic the effect of BOS token. L2M: Mutual Information Scaling Law for Long-Context Language Modeling In order to process continuous random variables, we replace the embedding layers of GPT2 and Mamba(2) models with two layer MLPs. For output, since all the conditional distributions are also Gaussian, we use different two layer MLP to outputs the 64 conditional means µqZi,j Z0:i1,j As discussed in Appx. B.II, due to the analytical construction, the Gaussian distribution permits efficient calculation of conditional probabilities. Therefore, instead of simply training the neural networks with negative log likelihood on the samples alone, we use the average conditional KL-divergence estimated as and standard deviations σqZi,j Z0:i1,j . DKL(pqθ) = EpZ"
        },
        {
            "title": "1\nL",
            "content": "L (cid:88) i=1 1 64 64 (cid:88) j=1 log σqZi,j Z0:i1,j σpZi,j Z0:i1,j + σ2 pZi,j Z0:i1,j + (µqZi,j Z0:i1,j µpZi,j Z0:i1,j 2σ2 qZi,j Z0:i1,j )2 1 (E.35) instead to reduce the sampling variance. For the Gaussian distribution training, during each iteration, we choose batch size of 4 (4 times sequence length number of tokens) with freshly generated samples, meaning we never reuse any sample, and therefore only has single epoch, thanks to the infinite dataset size. We train all neural networks using AdamW optimizer and cosine decay scheduler with warmup. We choose peak learning rate of 0.00005, weight decay of 0.01, 2000 warmup steps, and 500000 training steps in total. The results reported are at the end of the training. For the PG19 dataset, we train on standard average negative log likelihood. We first split the dataset into samples of around 5000 tokens, where we ensure each sample starts at the beginning of some sentence. Then we train the models for 5 epochs (around 235000 iterations) with batch size of 8 (32768 tokens for sequence length of 4096). Similar to the other experiments, we train all neural networks using AdamW optimizer and cosine decay scheduler with warmup. We choose peak learning rate of 0.00005, weight decay of 0.01 2000 warmup steps, and 500000 steps in total. The results reported are at the end of the training using separate evaluation dataset containing 10000 samples. To keep consistency across different models, we always use the same tokenizer from GPT-Neo-X (Black et al., 2022). In the main text, we report results on the position-wise conditional KL-divergence D(i) KL(pqθ) = EpW [log p(WiW1:i1) log qθ(WiW1:i1)] , average KL-divergence and position-wise conditional NLL DAvg KL (pqθ) = 1 L (cid:88) i=1 D(i) KL(pqθ), NLL(i)(pqθ) = EpW [log qθ(WiW1:i1)] . One can also define average NLL as NLLAvg(pqθ) = 1 (cid:88) i=1 NLL(i)(pqθ), (E.36) (E.37) (E.38) (E.39) which we will use in Appx. F. Our experiments are performed mostly on H100 GPUs, with varying VRAM size between 80GB and 94GB. Some experiments are performed on A100 GPUs with 80GB VRAM instead. We use the the vLLM library when running inference to estimate the mutual information scaling. For DeepSeek V3 and LLaMA 3.1 405B models, we run the FP8 version of the models using 8 H100 GPUs (with 94GB VRAM); and for LLaMA 3.1 70B model, we run the FP16 version of the model using 4 H100 GPU (with 94GB VRAM). The model weights and configurations are downloaded from HuggingFace (Wolf et al., 2020). When training GPT and Mamba(2) models on the Gaussian distribution, we use our custom library developed in PyTorch, (Paszke et al., 2019); when training GPT and Mamba models on the PG19 dataset, we use the trainer from HuggingFace transformers library. All models are initialized from scratch, with model configurations taken from HuggingFace. All training experiments are performed on individual H100 and A100 GPUs, with FP32 precision to avoid possible training 26 L2M: Mutual Information Scaling Law for Long-Context Language Modeling failures. Although training with FP16 would make the experiments run faster, it should not affect the actual results. We note that for Mamba2, we use the official implementation instead of the HuggingFace version, and for the GPT2 experiments on PG19, we re-implement the attention mechanism with FlexAttention (Li et al., 2024) to save memory, as the official FlashAttention (Dao et al., 2022; Dao, 2023; Shah et al., 2024) does not support FP32 precision. The code for reproducing our mutual information estimation and the PG19 results is available at https://github. com/LSquaredM/mutual_info_scaling_law. F. Additional Experimental Results Figure F.5. Evaluation of KL-divergence across model architectures trained on sub-volume Gaussian distributions. (a, b) Average KL-divergence per token for models trained on different sequence lengths [same as Fig. 4 (a, b)]. (c, d) Position-wise conditional KL-divergence for models trained on sequence length 256. (e, f) Position-wise conditional KL-divergence for models trained on sequence length 1024. (g, h) Position-wise conditional KL-divergence for models trained on sequence length 4096 [same as Fig. 4 (c, d)]. Lower values indicate better performance. 27 L2M: Mutual Information Scaling Law for Long-Context Language Modeling In this section, we show additional experimental results. In Fig. F.5, we include additional positional-wise conditional KL-divergences of models trained on sub-volume Gaussian distributions with sequence length 256 (c, d) and sequence length 1024 (e, f). As clearly demonstrated in the figure, for short sequence lengths, Mamba maintains similar performances to GPT2; Mamba models of different sizes also appear to have smaller performance gap. However, as we go to longer sequence lengths, smaller Mamba models starts to fail, while GPT2 always maintain relatively stable performances, consistent with our theory. Figure F.6. Negative log likelihood (NLL) across model architectures trained on sub-volume Gaussian distributions (a, b) Average NLL per token for models trained on different sequence lengths. (c, d) Position-wise conditional NLL for models trained on sequence length 4096. Lower values indicate better performance. In Fig. F.6, we show the negative log likelihood (NLL) of models trained on sub-volume Gaussian distributions. As mentioned in the main text, because NLL combines the KL-divergence with the intrinsic entropy of the underlying distribution (the average and position-wise conditional of which decays as sequence lengths), the differences between model performances are less visible. Its worth noting that, since Gaussian random variables are continuous, NLL values can differ by an arbitrary additive constant by rescaling the distribution. Therefore, the exact values of conditional NLL do not carry intrinsic meaning, though relative comparisons (which is exactly the same as the KL-divergence) between models remain valid. Figure F.7. Position-wise conditional negative log likelihood (NLL) evaluation for models trained on 4096-token sequences of the PG19 dataset. In Fig. F.7, we show additional comparisons of the conditional NLL of models trained on PG19 dataset. Ignoring the decay of conditional NLL with token position, which is likely due to the decay in inherent conditional entropy of natural language, the relative differences between models exhibits similar trend as the sub-volume Gaussian results. Since the models have to 28 L2M: Mutual Information Scaling Law for Long-Context Language Modeling learn additional sematic meanings of natural language in addition to the long-range dependencies, we find it reasonable for smaller models to perform even worse on PG19 dataset than on the sub-volume Gaussian distribution. The results here are consistent with our theory. Model Average Negative Log Likelihood GPT2 (125M) GPT2-medium (255M) Mamba-130M Mamba-370M Mamba-790M 2.977 2.771 3.111 2.875 2.766 Table F.1. Average conditional negative log likelihood evaluation for models trained on 4096-token sequences of the PG19 dataset. For completeness, we further show the average NLL of the models trained on PG19 dataset with sequence length of 4096 in Table F.1, where results similar to Fig. F.7 is observed. Notice that, in Fig. F.7, the token position is plotted in log-scale; therefore, the average NLL is very close to the conditional NLLs at later token positions."
        }
    ],
    "affiliations": [
        "Harvard University",
        "Massachusetts Institute of Technology",
        "NSF AI Institute for Artificial Intelligence and Fundamental Interactions",
        "Polytechnic University of Catalonia",
        "University of California, Los Angeles"
    ]
}