{
    "paper_title": "CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models",
    "authors": [
        "Tong Zhang",
        "Carlos Hinojosa",
        "Bernard Ghanem"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt."
        },
        {
            "title": "Start",
            "content": "CAPTAIN: SEMANTIC FEATURE INJECTION FOR MEMORIZATION MITIGATION IN TEXT-TO-IMAGE DIFFUSION MODELS 5 2 0 2 1 1 ] . [ 1 5 5 6 0 1 . 2 1 5 2 : r Tong Zhang, Carlos Hinojosa, Bernard Ghanem {tong.zhang.1; carlos.hinojosa; bernard.ghanem}@kaust.edu.sa King Abdullah University of Science and Technology"
        },
        {
            "title": "ABSTRACT",
            "content": "Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt."
        },
        {
            "title": "Introduction",
            "content": "Diffusion models have made significant progress in text-to-image synthesis, generating high-quality, diverse, and stylistically rich images. However, recent studies have revealed concerning trend: some of these novel creations are, in fact, near-exact reproductions of images from their training datasets, behavior known as memorization Somepalli et al. [2023a], Carlini et al. [2023], Somepalli et al. [2023b], Gu et al. [2025]. This unintended memorization raises serious concerns for both model owners and end users, particularly when training data contain sensitive or copyrighted material, and as large-scale diffusion systems are increasingly deployed in public and commercial settings. recent example is the UK High Court case involving Getty Images and Stability AI, in which generated samples from Stable Diffusion were found to reproduce Gettys watermark, highlighting the real-world risks of memorization and copyright infringement The Guardian [2025]. Understanding and mitigating memorization has therefore become crucial for ensuring the safe and responsible use of generative models. Existing mitigation strategies can be broadly categorized into training-time and inference-time approaches. Training-time methods typically require access to the original dataset and large computational resources, limiting their practicality Wen et al. [2024]. In contrast, inference-time methods aim to detect or suppress memorization without modifying model parameters Chen et al. [2024], Jain et al. [2025], Hintersdorf et al. [2024], Chen et al. [2025a], Ren et al. [2024], offering an efficient alternative. Overall, most inference-time strategies steer the diffusion process away from memorized outputs by manipulating the strength of classifier-free guidance (CFG), prompt embeddings, or cross-attention behavior. For instance, Wen et al. [2024] detect memorization by monitoring the magnitude of the conditional noise prediction and mitigate it by adjusting prompt embeddings. Jain et al. [2025] propose applying opposite guidance during early denoising steps to counteract memorization induced by CFG. Similarly, Chen et al. [2025b] mitigate memorization by re-anchoring prompts within CFG through prompt perturbation and semantic prompt search for non-memorized variants. On the other hand, Chen et al. [2025a] identify novel bright ending (BE) anomaly in text-to-image diffusion models, where memorized image Figure 1: CAPTAIN achieves strong semantic alignment and effective memorization mitigation across diverse categories, including Objects, People in Scenes, Close-up Portraits (the most challenging category), and Textures & Patterns, where structural repetition is more likely. In each pair, the left image shows the memorized training example, while the right image shows the corresponding mitigated result generated by our approach. patches exhibit significantly greater attention to the final text token during the last inference step than non-memorized patches. This distinct cross-attention pattern highlights regions where the generated image replicates training data, enabling efficient localization of memorized regions. However, these methods often struggle to reduce memorization without compromising alignment with the conditioning prompt. In this paper, we introduce CAPTAIN (see fig. 1), training-free framework that mitigates memorization at inference time. Instead of manipulating CFG or perturbing prompt embeddings to control generation, we guide the denoising trajectory away from memorized outputs by directly modifying latent features. The contributions are as follows: (i) Frequency decomposed initialization. Our initialization strategy blends the low-frequency components of given reference image with the high-frequency components of random noise. This constrains the initial latent and encourages the early denoising trajectory to steer away from reproducing memorized patterns. (ii) Timestep and spatial memorization localization. Our method operates directly in the latent space and introduces timestep window localization strategy that determines when feature injection is most effective during denoising and identifies the spatial regions that contain memorized content. This enables targeted suppression of memorized content while preserving the semantic structure of the generated image. (iii) Semantic feature injection for memorization mitigation. We propose localized feature injection mechanism that replaces memorized latent regions with semantically aligned features extracted from non-memorized reference images, steering generation away from memorized outputs while maintaining prompt fidelity and visual quality."
        },
        {
            "title": "2 Related Works",
            "content": "Memorization in Diffusion Models. Diffusion models can unintentionally reproduce images that closely resemble samples seen during training, behavior referred to as memorization. This phenomenon raises privacy and copyright concerns, as it can lead to the leakage of sensitive or proprietary data. Recent studies have analyzed this issue Somepalli et al. [2023a], Carlini et al. [2023], showing that large pretrained text-to-image models such as Stable Diffusion can directly replicate training images under specific prompts. Although newer versions (e.g., SDv2.1) apply dataset de-duplication, subsequent research demonstrates that memorization persists and cannot be fully explained by data duplication alone Somepalli et al. [2023b], Gu et al. [2025]. Several contributing factors have been identified, including model capacity, dataset scale and diversity, and prompt conditioning mechanisms. Together, these findings suggest that memorization arises not only from data redundancy but also from how diffusion models encode and retrieve semantic and structural priors during denoising, motivating the development of inference-time mitigation strategies beyond dataset curation or retraining. Detection and Mitigation Strategies. Early efforts to address memorization in diffusion models operated either during training or at inference. Training-time methods typically require access to the original dataset and large computational resources, limiting their practicality. As result, recent studies have focused on inference-time detection and mitigation Chen et al. [2024], Jain et al. [2025], Hintersdorf et al. [2024], Chen et al. [2025a], Ren et al. [2024]. Wen et al. [2024] detect memorization by monitoring the magnitude of conditional noise prediction and mitigate it by adjusting prompt embeddings. Chen et al. [2025a] further refine this process through the Bright Ending (BE) attention mechanism, which identifies memorized regions where the last cross-attention layer assigns abnormally high attention to the final prompt token. Somepalli et al. [2023b] alleviate memorization by perturbing input prompts via token addition or replacement, while Ren et al. [2024] link memorization to highly concentrated cross-attention patterns, where specific tokens act as triggers. Jain et al. [2025] propose applying opposite guidance during early denoising steps to counteract memorization induced by classifier-free guidance (CFG). Similarly, Han et al. [2025] adjust the initial noise samples to reduce memorization. More recently, Chen et al. [2025b] introduced PRSS, which mitigates memorization by re-anchoring prompts within CFG through prompt perturbation and semantic prompt search for non-memorized variants. Overall, most inference-time strategies steer the diffusion process away from memorized outputs by manipulating CFG strength, prompt embeddings, or cross-attention behavior. In contrast, our proposed method, CAPTAIN, mitigates memorization by directly operating in the latent feature space, combining frequency-aware initialization and semantic feature injection to steer denoising away from memorized content without modifying CFG or prompt embeddings. Feature Injection in Diffusion Models Feature-space interventions in diffusion models have been mainly explored for image editing and controllability rather than memorization mitigation. Methods such as Plug-and-Play Diffusion Tumanyan et al. [2023] and Prompt-to-Prompt Hertz et al. [2023] manipulate cross-attention features to control spatial layouts or preserve structure during prompt editing, while Null-Text Inversion Mokady et al. [2023] and SDEdit Meng et al. [2022] guide generation by modifying latent representations. As shown in the video domain, FreeInit Wu et al. [2024] performs frequency-domain filtering to inject low-frequency structural information from an anchor frame, thereby enabling long-term temporal stability in videos. More recently, MoCA-Video Zhang et al. [2025] extends concept-level alignment to the video domain by leveraging motion-aware semantic feature fusion, ensuring temporal consistency across edited sequences. In contrast to these approaches, which inject or modify features to improve editability and temporal coherence, our method initializes with non-memorized content and explicitly injects localized features to further suppress memorized content, integrating semantic cues to preserve concept fidelity while preventing overfitting to the training data."
        },
        {
            "title": "3 Method",
            "content": "To address memorization in text-to-image diffusion models, we propose CAPTAIN, training-free framework that steers the denoising trajectory toward non-memorized outputs by injecting features directly into the latent denoising process with frequency decomposed noise initialization. The framework integrates detection and mitigation within unified pipeline that adaptively determines the semantic content, spatial regions, and intermediate timesteps for feature injection, effectively mitigating memorization while maintaining prompt consistency. Framework Overview. Our framework is illustrated in fig. 2. Given text prompt and reference non-memorized image Xr (see section 3.1), the goal is to generate an image that remains semantically aligned with the prompt while avoiding the reproduction of memorized content from the training data. CAPTAIN operates through four stages. First, we initialize the latent variable by combining the low-frequency components of Xr with the high-frequency (0, I) (section 3.1), discouraging structural copying from training samples. components of Gaussian noise ϵT 3 Figure 2: Given an input prompt, CAPTAIN retrieves semantically related but unseen reference image from the web and encodes it into latent features xr. (Left) We initialize the diffusion process using frequency-based strategy: the low-frequency components of Gaussian noise are combined with the high-frequency components of the reference image to discourage early-stage memorization. (Bottom) During denoising, we monitor imagetext alignment to identify the [thigh, tlow]. (Right) By intersecting the BE mask with concept-specific attention maps, optimal injection window [thigh, tlow], CAPTAIN we produce binary mask that highlights the target memorized regions. At every step injects semantically aligned features from xr into the masked regions of ˆx0, yielding the updated latent ˆx 0. During denoising, we hypothesize that memorization tends to appear after coarse structure formation but before finedetail refinement; therefore, we identify timestep window where feature injection can effectively steer the generation toward non-memorized output (section 3.2). Once this window is determined, we localize potential memorized regions by combining Bright Ending (BE) attention with concept-specific attention maps, isolating areas where memorization overlaps with the target semantic concept (section 3.3). Finally, within those localized regions, we inject semantically consistent but visually distinct features from conditioned image, guiding the denoising trajectory toward outputs that maintain prompt fidelity while reducing the influence of memorized content (section 3.4). Preliminaries on Diffusion Models. Diffusion probabilistic models Ho et al. [2020] define forwardreverse process that transforms clean data samples x0 into Gaussian noise through Markov chain and learns to invert this noising process. In latent diffusion models Rombach et al. [2022], this process operates in compressed latent space rather than in pixel space; an encoder first maps images to the latent domain where diffusion occurs, and decoder later reconstructs them. In this work, xt denotes latent variable that evolves entirely in this latent space, with x0 representing the final latent after denoising. The forward diffusion gradually perturbs x0 according to variance schedule βt t=1: } { q(xt xt1) = βt xt1, βtI (cid:16)(cid:112)1 (cid:17) , (1) (0, I). The reverse process learns to denoise xt step by step using neural network I(cid:1) , (cid:0)µθ(xt, t, c), σ pθ(xt1 xt) = (2) so that after steps, xT parameterized by θ: where denotes conditioning input. Following Ho et al. [2020], Song et al. [2021], Rombach et al. [2022], the mean term can be expressed in closed form through the predicted noise ϵθ(xt, t, c): µθ(xt, t, c) = (cid:18) 1 αt xt (cid:19) ϵθ(xt, t, c) , (3) 1 αt αt s=1 αs. The denoising network ϵθ, typically U-Net Rombach et al. [2022], is trained where αt = 1 by minimizing the simplified objective βt and αt = (cid:81)t where ϵ latent simple = Et,x0,ϵ ϵ (cid:2) ϵθ(xt, t, c) (cid:3) , 2 2 (4) (0, I) is standard Gaussian noise. At inference, samples are generated by iteratively predicting the clean ˆx0 = 1 xt αtϵθ(xt, t, c) αt , 4 (5) and reconstructing the previous step: xt1 = αt1 ˆx0 + (cid:112) αt1ϵθ(xt, t, c) + σtϵt, (6) where ϵt = D(x0) from the latent space, enabling efficient high-resolution synthesis while preserving semantic structure. (0, I) and σt follows the chosen noise schedule. Finally, decoder reconstructs the generated image 3.1 Initialization and Reference Image Selection Initialization via Frequency Decomposition. Drawing inspiration from recent works demonstrating that initialization influences memorization behavior Han et al. [2025], Wu et al. [2024], we adopt frequency decomposed initialization strategy that blends the low-frequency components of reference image with high-frequency Gaussian noise. Specifically, given reference image Xr, we construct the initial latent noise xT as: xT = 1( high (ϵ) + low (xr)), (7) and low, 1 denote the Fourier and inverse-Fourier transforms, respectively, ϵ (0, I) is where xr = E(Xr) and high are complementary frequency masks (i.e., low-pass and high-pass filter, respectively) Gaussian noise, and that partition the frequency spectrum. In this initialization, the high-frequency components of xT are drawn from the noise ϵ, encouraging stochasticity. The low-frequency components from the reference image latent xr introduce novel structural patterns. By decoupling broad spatial structure, which tends to be memorized, from semantics at the noise level, we reduce the models reliance on memorized spatial priors during early denoising steps. F Reference Image Selection. To obtain the reference image Xr used in initialization (eq. (7)) and feature injection, CAPTAIN employs an online retrieval strategy to collect semantically related yet previously unseen images from the web. Given prompt p, we identify the top-k visually attended words i=1 by aggregating the U-Net cross-attention } maps over spatial queries, heads, layers, and timesteps, and pooling attention scores from tokens to words. In practice, we set = 3, and one word is randomly sampled from i=1 to serve as the retrieval query. Using as } from public APIs such as Pexels or Unsplash Pexels keyword, we fetch candidate set of web images { [2025], Unsplash [2025]. Each candidate and the query word are encoded using the CLIP vision (V ) and text (T ) encoders to obtain normalized embeddings fj = (Xj) and = (w). Their cosine similarity defines the semantic alignment h1(Xj) = cos(fj, g). To estimate dataset novelty, we precompute FAISS index Johnson et al. [2019] of one million LAION-5B CLIP embeddings and define: web = { Xj wi wi { } h2(Xj) = 1 max ℓFAISS cos(fj, fℓ). (8) Additionally, we compute perceptual uniqueness term h3 from 64-bit perceptual hashes (pHash) as the normalized minimum Hamming distance between each candidate image and hashes from the LAION subset, rewarding images that are visually distinct from training samples. Each image receives final composite score combining semantic relevance, dataset novelty, and perceptual uniqueness, and the final reference image is selected as: Xr = arg max Xj Xweb (λ1h1 + λ2h2 + λ3h3), (9) where λ = [0.3, 0.4, 0.3]. Alternatively, Xr can be directly provided by the user in our pipeline. For more details on our online image retrieval approach, refer to the Supplementary Material. Once Xr is obtained, we compute its latent representation xr = E(Xr) using the diffusion encoder, and use this semantic feature for injection during frequency decomposed noise initialization and the denoising process. 3.2 Timestep Window Injection Localization Given the latent features xr, the next step is to determine the optimal timesteps for feature injection during denoising. The diffusion process follows hierarchical generation pattern: early timesteps establish coarse global structure and composition, while later ones progressively refine local details and textures Ho et al. [2020]. Memorization is most likely to occur during the last refinement phase, where the model may inadvertently reproduce specific visual cues from training samples once the overall structure has been formed. To identify the optimal injection window, we analyze how imagetext alignment changes over the denoising trajectory. At each timestep t, the partially denoised latent xt is decoded to image space and compared with the conditioning prompt using CLIP similarity: st = (p) (p) 2 (D(xt)) (D(xt)) 5 . 2 (10) Figure 3: Identifying the optimal injection region for semantic editing. (Left) Average CLIP score evolution across diffusion timesteps for all the sdv1-500 memorized dataset. The injection region is bounded by the upper limit, where the CLIP score exceeds the average (indicating strong semantic content), and the lower limit before the sharp drop in the rate of change. (Right) First derivative of CLIP scores showing the rate of change. The sharp drop threshold (orange dashed line) identifies the transition point where fine details begin to stabilize, marking the end of the optimal injection window. The similarity st measures how well the semantic content of the prompt is expressed at timestep t. Figure 3 (left) shows the average st computed over the SDv1-500 memorized dataset. The injection window is bounded by the point at which the CLIP similarity first exceeds its mean (upper limit, thigh) and the point preceding the sharp decline in its rate of change (lower limit, tlow). The derivative of st across timesteps (fig. 3 right) highlights this transition region, where noticeable drop in dst/dt indicates that fine-grained details start to converge. Then, the lower bound tlow is determined as the first timestep where the derivative falls below threshold defined as (cid:8) dst (cid:9) , tlow = min dt < µdst/dt where µdst/dt and σdst/dt denote the mean and standard deviation of the derivative, respectively. Based on this observation, we define the timestep injection window as the range [tlow, thigh] = [141, 341], corresponding to the phase in which semantic alignment stabilizes while visual details are still being formed. Therefore, we inject features within this window to mitigate memorization. Note that this CLIP-based measure serves as proxy for semantic consolidation rather than direct indicator of memorization, and the exact timestep range may vary across diffusion architectures and datasets. 1.5 σdst/dt (11) 3.3 Spatial Memorization Localization [tlow, thigh] is determined, we aim to inject the reference features xr into spatial Once the timestep injection window regions that exhibit memorized content while remaining semantically consistent with xr. To this end, we employ two complementary mechanisms: the Bright Ending (BE) mask Chen et al. [2025a] and concept-specific attention maps Helbling et al. [2025]. The BE mask mBE [0, 1] is obtained by extracting the cross-attention map of the final text token during pseudo run at the last inference step of the diffusion model, where memorized image patches exhibit significantly greater attention to the final text token than non-memorized ones. To refine this localization with semantic awareness, we introduce concept-specific attention extraction scheme adapted to the U-Net backbone. Given the target concept (obtained in section 3.1), we encode it with the diffusion models text encoder and append its tokens to the standard prompt embeddings during cross-attention computation. We record cross-attention tensors from 16 layers across the U-Nets downsampling, middle, and upsampling blocks. We then average across attention heads, layers, and concept tokens, and normalize the aggregated map. After applying Gaussian smoothing with standard deviation of 1.5, we obtain concept mask mconcept [0, 1]. Finally, we compute the memorized concept region as the intersection between both masks: where outputs 1 when its argument exceeds τ and 0 otherwise. denotes element-wise multiplication, τ is predefined threshold, and 1>τ ( ) is the indicator function that = 1>τ (mBE mconcept) , 0, 1 , (12) { } 6 3.4 Feature Injection for Memorization Mitigation [tlow, thigh], we reconstruct the predicted clean latent ˆx0 from the current noisy latent At each injection timestep xt using eq. (5). The reference latent xr is then injected into the spatially localized region defined by the mask m, producing the modified latent: 0 = (1 [0, 1] controls the injection strength. The updated clean prediction ˆx ˆx0 + δ δ m) xr, ˆx where δ 0 is then substituted into eq. (6) to compute the next latent state xt1. This localized feature blending allows CAPTAIN to suppress memorized content while preserving semantic and structural coherence throughout the diffusion trajectory. (13)"
        },
        {
            "title": "4 Experiments",
            "content": "Experimental Setup. In line with prior work on memorization in diffusion models Somepalli et al. [2023b], Wen et al. [2024], Ren et al. [2024], Hintersdorf et al. [2024], Chen et al. [2025a], we evaluate our method on Stable Diffusion (SD) v1.4 Rombach et al. [2022]. We use 500 prompts extracted from the LAION dataset Schuhmann et al. [2022] that are known to trigger memorization in SD v1.4 to evaluate the effectiveness of memorization mitigation. These prompts, provided by Webster [2023], are associated with cases where the model reproduces near-identical training images. Evaluation metrics. We evaluate memorization mitigation using the Self-Supervised Copy Detection (SSCD) score Pizzi et al. [2022], which measures object-level similarity between generated image and its nearest neighbor in the training set (lower is better ). Image-text alignment is assessed with the CLIP score Radford et al. [2021], which quantifies the semantic consistency between each generated image and its corresponding text prompt (higher is better ). Baselines. We compare CAPTAIN against three state-of-the-art inference-time memorization mitigation methods. BE Chen et al. [2025a] and PRSS Chen et al. [2025b], which use attention-based masking to achieve spatially-aware memorization suppression under both local and global memorization scenarios. We also include Wen et al. [2024], which mitigates memorization by adjusting prompt embeddings based on conditional noise prediction, and Han et al. [2025], which modifies the initial noise before denoising, providing complementary initialization-based mitigation strategy. All baseline methods are applied at inference time and do not require access to the training data, making them suitable for fair comparison with our proposed approaches. Implementation details. For each diffusion model, we generate one image per memorized prompt using seed 0 with identical inference configurations across all baselines and our proposed method. Specifically, for Stable Diffusion v1.4, we employ the DDIM Song et al. [2021] sampler with 50 sampling steps and CFG scale of 7.5. Additional implementation details are provided in the supplementary material. Compute Overhead Our approach adds minimal overhead beyond standard Stable Diffusion inference. Running 500 prompts on single A100 GPU took under 30 minutes, including noise initialization and mask computation. The full pipeline requires roughly 3 seconds per image, preserving practical inference speed. runtime comparison with baseline methods is provided in the supplementary material. 4.1 Comparison with baselines Quantitative Results. Figure 4a compares the performance of CAPTAIN against BE Chen et al. [2025a], PRSS Chen et al. [2025b], and Han et al. [2025] using SSCD and CLIP scores. The diagonal dashed line (SSCD = CLIP score) serves as reference boundary, with points below this line indicating favorable tradeoff between imagetext alignment and memorization mitigation. As shown in fig. 4a, PRSS-Global and Hanet al.achieve low SSCD scores (0.210.23), indicating strong memorization mitigation, but this comes at the cost of reduced semantic alignment, with CLIP scores 0.275) but exhibits high of only 0.250.27. BE-Global attains the highest semantic alignment among baselines (CLIP 0.40), demonstrating limited ability to suppress memorization. Finally, PRSS-Local and BE-Local SSCD values ( occupy an intermediate region, with moderate CLIP (0.250.26) and higher SSCD (0.350.45), but neither metric shows favorable performance. In contrast, CAPTAIN achieves the strongest tradeoff, with the highest CLIP score (0.29) and the lowest SSCD among all non-overly-degrading methods (0.25). CAPTAIN improves semantic alignment by 28% over PRSS-Global (0.29 vs. 0.21 CLIP) while maintaining comparable SSCD, and reduces SSCD by 38% relative to BE-Global (0.25 vs. 0.40) without sacrificing prompt fidelity. Its position well below the SSCD = CLIP reference line reflects effective decoupling of semantic alignment from structural memorization. These gains stem from combining noise initialization and localized feature injection. Unlike CFG-based methods (PRSS, BE) or initialization7 (a) (b) (c) Figure 4: Quantitative comparison of memorization mitigation methods under Stable Diffusion v1.4. (a) SSCD and CLIP scores across different methods. Lower SSCD indicates stronger memorization mitigation, while higher CLIP scores indicate better imagetext alignment. (b) SSCD vs. FID, measuring image fidelity. (c) SSCD vs. LPIPS, measuring perceptual similarity. Lower values are preferred for all metrics except CLIP. Our method achieves the lowest SSCD while maintaining competitive fidelity and alignment, outperforming BE Chen et al. [2025a], PRSS Chen et al. [2025b], , and Han et al. Han et al. [2025]. Figure 5: Qualitative comparison with different memorization mitigation methods: BE(Chen et al. [2025a]), PRSS(Chen et al. [2025b]), and Han et al. Han et al. [2025]. The last three columns show results from our approach using different random seeds. The prompts used for generation and more qualitative results are provided in the supplementary material. only approaches (Han et al.), CAPTAIN directly guides the denoising trajectory away from memorized outputs by intervening at multiple stages of the generation process, enabling more effective, targeted suppression of memorization. To further evaluate the image quality of our generated results and the baselines, we report FID and LPIPS scores. As shown in fig. 4b and fig. 4c, our method achieves the lowest values across both metrics, indicating higher visual quality while still mitigating memorization. For PRSS and BE, we take their globaland local-variant SSCD scores from Fig. 4a, average them, and use the averages as their SSCD points in this comparison. Figure 6: CAPTAIN also shows strong semantic alignment while reducing memorization on Stable Diffusion 2.0 (SD 2.0). In each pair, the left image shows the memorized output produced by SD 2.0, and the right image is the mitigated result produced by our approach. The prompt used for generation is shown above each pair. Qualitative Results. Figure 5 compares our approach with baseline methods, including BE(Chen et al. [2025a]), PRSS(Chen et al. [2025b] and Han et al. [2025]. Each row illustrates representative memorization case from the SDv1-500 benchmark Webster [2023]. Across diverse scenariosincluding portraits, animals, artistic compositions, and product imagerybaseline methods reduce some degree of duplication but often preserve key memorized structures or introduce noticeable degradations. As observed, our approach effectively suppresses memorized content while producing visually coherent and prompt-faithful results across different random seeds (rightmost columns). Examples include removing the distinctive facial attributes of training portraits, altering animal poses and appearances, and generating novel object shapes while preserving category-level semantics. Additional qualitative examples and prompt lists are provided in the supplementary material. Evaluation on Stable Diffusion 2.0. We further evaluate our approach on Stable Diffusion 2.01. Since SD 2.0 is trained on de-duplicated dataset, our method achieves even better SSCD performance (0.202) on the 219 non-memorized samples of Ren et al. [2024], while maintaining strong semantic alignment (CLIP score 0.258). Compared to the results reported in Han et al. [2025] (0.248 CLIP, 0.226 SSCD), this corresponds to 4.03% increase in CLIP and 10.84% decrease in SSCD. Visual comparisons between CAPTAIN and the memorized outputs are shown in Fig. 6. 1https://huggingface.co/lzyvegetable/stable-diffusion-2-1 9 (a) Init. and feat. inj. ablation. δ = 0.1 δ = 0.2 Init. Feat. Inj. CLIP SSCD CLIP SSCD 0.279 0.270 0.292 0.291 0.332 0.250 0.279 0.232 0.262 0.291 0.247 0. (b) Mask ratio ablation. τ 0.1 0.2 0.3 0.4 0.5 CLIP SSCD 0.292 0.275 0.253 0.250 0. 0.250 0.256 0.251 0.243 0.236 Table 1: Ablation studies on our method. (a) Impact of initialization and feature injection across different δ values. Our full approach (highlighted) is shown in the last row. (b) Effect of different mask ratios τ on performance. 4.2 Ablation Studies Table 1a evaluates the contribution of CAPTAINs two core components, noise initialization and feature injection, using SSCD and CLIP scores under different injection strengths δ. Figure 4a also shows the ablation results when using our method without Noise initialization (Without Init) and without feature injection (Without Injection). Noise Initialization. When feature injection is disabled, the perturbation strength δ has no effect on the generation process, since δ only scales the injected features. As result, the initialization-only row in table 1a yields identical CLIP and SSCD scores across all δ values. This shows that initialization provides fixed level of memorization mitigation 0.29) but cannot be strengthened or adapted during denoising. In practice, initialization establishes static (SSCD mitigation effect at the start of the diffusion trajectory, yet lacks the flexibility required to further reduce memorization in later steps. Feature Injection. Feature injection acts as the dynamic, adaptive component of CAPTAIN, intervening at intermediate stages of the diffusion process to modify latent features. Without initialization, however, injection becomes highly sensitive to the perturbation strength δ. At low δ, it preserves semantic alignment (high CLIP) but fails to suppress memorization (SSCD = 0.332). At high δ, the opposite occurs, memorization decreases (SSCD = 0.179) but semantic alignment degrades sharply (CLIP = 0.201). This instability indicates that feature injection alone cannot reliably balance alignment and memorization mitigation across different perturbation levels. Combined Effect. The full CAPTAIN configuration (initialization + injection) achieves the best trade-off across all δ values, consistently improving privacy while preserving semantic alignment (e.g., CLIP = 0.292, SSCD = 0.250 at δ = 0.1). Initialization stabilizes the injection mechanism, while injection provides the adaptability that initialization alone lacks. Together, they yield predictable, well-balanced behavior that neither component achieves independently. Mask Threshold. We also conduct an ablation study on the τ threshold defined in eq. (12). In practice, we set τ = 0.1, meaning that only values greater than 0.1 after the element-wise multiplication are retained in the binary mask. To ensure valid mask during injection, we handle the rare case where thresholding produces an all-zero mask, which occurs when every element of the product falls below τ . In such cases, we fall back to the BE mask and apply threshold of 0.5 to obtain valid binary mask. We additionally evaluate τ = 0.2, 0.3, 0.4, 0.5. Table 1b shows that increasing τ results in lower SSCD, but also leads to noticeable drop in the CLIP score compared to the default τ = 0.1 setting. This reflects weaker semantic alignment between the generated image and the prompt. Considering this trade-off, we adopt τ = 0.1 as the most stable and balanced value."
        },
        {
            "title": "5 Conclusions",
            "content": "We introduced CAPTAIN, training-free framework for mitigating memorization in text-to-image diffusion models. Unlike prior inference-time methods that rely on manipulating CFG strength or perturbing prompt embeddings, CAPTAIN operates directly in the latent space. Our frequency-based noise initialization reduces the tendency to reproduce memorized patterns in early denoising steps, while our temporalspatial localization strategy identifies effective timesteps and regions for intervention. By injecting semantically aligned features from non-memorized reference images, CAPTAIN suppresses memorized content without sacrificing visual quality or alignment with the conditioning prompt. Extensive experiments demonstrate that CAPTAIN achieves stronger memorization mitigation than existing inference-time baselines while maintaining competitive semantic fidelity. 10 Limitations. We acknowledge our approach presents some limitations. First, it relies on retrieving an external reference image, and variations in retrieval quality may influence injection effectiveness. Second, our spatial localization strategy, based on BE attention and concept-specific attention, can be less reliable for abstract or ambiguous prompts, occasionally producing overly small or diffuse masks. Third, CAPTAIN requires FAISS index to estimate the novelty of retrieved image; while we will provide one for Stable Diffusion, new index must be built when applying the method to other models trained on different datasets. Finally, although computationally lightweight, CAPTAIN introduces extra operations such as frequency decomposition and CLIP-based timestep selection. Ethical and Legal Considerations. CAPTAIN retrieves reference images from public, royalty-free APIs (Pexels and Unsplash), which provide openly licensed content for research and creative use. No personal, private, or copyrighted datasets are accessed or stored. Retrieved images are used exclusively at inference time to guide feature injection and are not included in training or redistributed. This design aligns with CAPTAINs goal of reducing copyright and privacy risks associated with memorization in diffusion models. Acknowledgments. The research reported in this publication was supported by funding from King Abdullah University of Science and Technology (KAUST) - Center of Excellence for Generative AI, under award number 5940."
        },
        {
            "title": "References",
            "content": "Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Diffusion art or digital forgery? investigating data replication in diffusion models. In CVPR, pages 60486058, 2023a. Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models. In USENIX security symposium, pages 52535270, 2023. Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Understanding and mitigating copying in diffusion models. NeurIPS, 36:4778347803, 2023b. Xiangming Gu, Chao Du, Tianyu Pang, Chongxuan Li, Min Lin, and Ye Wang. On memorization in diffusion models. Transactions on Machine Learning Research, 2025. ISSN 2835-8856. URL https://openreview.net/forum?id=D3DBqvSDbj. The Guardian. Ai firm wins high court ruling after photo agencys copyright claim. https://www.theguardian.com/media/ 2025/nov/04/stabilty-ai-high-court-getty-images-copyright, 2025. Accessed: 2025-11-11. Yuxin Wen, Yuchen Liu, Chen Chen, and Lingjuan Lyu. Detecting, explaining, and mitigating memorization in diffusion models. In ICLR, 2024. Chen Chen, Daochang Liu, and Chang Xu. Towards memorization-free diffusion models. In CVPR, pages 84258434, 2024. Anubhav Jain, Yuya Kobayashi, Takashi Shibuya, Yuhta Takida, Nasir Memon, Julian Togelius, and Yuki Mitsufuji. Classifier-free guidance inside the attraction basin may cause memorization. In CVPR, pages 1287112879, 2025. Dominik Hintersdorf, Lukas Struppek, Kristian Kersting, Adam Dziedzic, and Franziska Boenisch. Finding nemo: Localizing neurons responsible for memorization in diffusion models. NeurIPS, 37:8823688278, 2024. Chen Chen, Daochang Liu, Mubarak Shah, and Chang Xu. Exploring local memorization in diffusion models via bright ending attention. In ICLR, 2025a. Jie Ren, Yaxin Li, Shenglai Zeng, Han Xu, Lingjuan Lyu, Yue Xing, and Jiliang Tang. Unveiling and mitigating memorization in text-to-image diffusion models through cross attention. In ECCV, pages 340356. Springer, 2024. Chen Chen, Daochang Liu, Mubarak Shah, and Chang Xu. Enhancing privacy-utility trade-offs to mitigate memorization in diffusion models. In CVPR, pages 81828191, 2025b. Hyeonggeun Han, Sehwan Kim, Hyungjun Joo, Sangwoo Hong, and Jungwoo Lee. Adjusting initial noise to mitigate memorization in text-to-image diffusion models. In NeurIPS, 2025. Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. Plug-and-play diffusion features for text-driven image-to-image translation. In CVPR, pages 19211930, 2023. Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-or. Prompt-to-prompt image editing with cross-attention control. In ICLR, 2023. Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. Null-text inversion for editing real images using guided diffusion models. In CVPR, pages 60386047, 2023. Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. SDEdit: Guided image synthesis and editing with stochastic differential equations. In ICLR, 2022. Tianxing Wu, Chenyang Si, Yuming Jiang, Ziqi Huang, and Ziwei Liu. Freeinit: Bridging initialization gap in video diffusion models. In ECCV, pages 378394. Springer, 2024. Tong Zhang, Juan Leon Alcazar, and Bernard Ghanem. Motion-aware concept alignment for consistent video editing. arXiv preprint arXiv:2506.01004, 2025. 11 Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 33:68406851, 2020. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, pages 1068410695, 2022. Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In ICLR, 2021. Pexels. Pexels api. https://www.pexels.com/api, 2025. Accessed: 2025-12-11. Unsplash. Unsplash api. https://unsplash.com/developers, 2025. Accessed: 2025-12-11. Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3): 535547, 2019. Alec Helbling, Tuna Han Salih Meral, Ben Hoover, Pinar Yanardag, and Duen Horng Chau. Conceptattention: Diffusion transformers learn highly interpretable features. arXiv preprint arXiv:2502.04320, 2025. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. Laion-5b: An open large-scale dataset for training next generation image-text models. NeurIPS, 35:2527825294, 2022. Ryan Webster. reproducible extraction of training images from diffusion models. arXiv preprint arXiv:2305.08694, 2023. Ed Pizzi, Sreya Dutta Roy, Sugosh Nagavara Ravindra, Priya Goyal, and Matthijs Douze. self-supervised descriptor for image copy detection. In CVPR, pages 1453214542, 2022. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, pages 87488763. PmLR, 2021."
        },
        {
            "title": "A Reference Image Selection Details",
            "content": "This section details our reference-image retrieval procedure, which identifies concept word from cross-attention, retrieves semantically related web images, and selects novel, perceptually distinct reference. The full procedure is summarized in Algorithm 1. A.1 Attention-Based Query Word Extraction. Given prompt p, CAPTAIN identifies visually relevant words by aggregating U-Net cross-attention across layers, timesteps, attention heads, and spatial queries. For each layer l, timestep t, and head index u, the cross-attention matrix RQNtok captures attention from the Ntok text tokens to the spatial query positions. We compute: A(l,t,u) (cid:88) (cid:88) (cid:88) (14) stok ="
        },
        {
            "title": "1\nH Q",
            "content": "l,t u=1 q=1 A(l,t,u) q,: , yielding token-level importance scores. To obtain word-level scores, token scores are mapped to their corresponding words in the prompt (preserving order), producing the unfiltered word-score vector sword. filtering operator Φ( ) removes stopwords and punctuation: sword = Φ(sword). (15) Finally, the top-k highest-scoring words are selected. In practice, one word (with = 3) is randomly sampled to form the retrieval query. A.2 Online Image Retrieval and Scoring. Using as keyword, we retrieve candidate set from public APIs (e.g., Pexels, Unsplash). To further { reduce the likelihood that retrieved samples overlap with the Stable Diffusion training data (drawn mainly from images up to 2022), we preferentially select images uploaded after 2024. Each candidate and the query word are encoded using CLIP vision (V ) and text (T ) encoders: web = Xj } and the semantic alignment score is defined as h1(Xj) = cos(fj, g). fj = (Xj), = (w), (16) (17) Dataset Novelty. To estimate novelty with respect to the data distribution seen by Stable Diffusion, we build FAISSJohnson et al. [2019] index using 1M CLIP ViT-L/14 embeddings randomly sampled from the HuggingFace LAION laion2B-en-aesthetic subset2. This subset is derived from the larger LAION-5B corpus but represents only filtered portion of the original dataset. We use flat L2 index over unit-normalized embeddings and compute the novelty score as: h2(Xj) = 1 max ℓFAISS cos(fj, fℓ). (18) Perceptual Uniqueness. We compute 64-bit perceptual hash (pHash) for each candidate image Xj, producing binary hash πj. To measure perceptual dissimilarity with respect to the models training distribution, we precompute large set of 64-bit pHashes from the laion2B-en-aesthetic subset and denote them by . The perceptual uniqueness } score is defined as the minimum normalized Hamming distance between πj and these LAION hashes: πℓ { h3(Xj) = min ℓ clip (cid:18) Hamming(πj, πℓ) 32 (cid:19) , 0, 1 , (19) , 0, 1) = min(max( where clip( , 0), 1) limits the normalized Hamming distance to [0, 1], and dividing by 32 corresponds to half the maximum 64-bit distance, leading larger distances to saturate at one after clipping. Larger values correspond to candidates that are more perceptually distinct from LAION samples, reducing the likelihood of overlap with training-set images. Final Selection. Each candidate image receives composite score formed by weighted combination of semantic relevance, dataset novelty, and perceptual uniqueness: Xr = arg max Xj Xweb (λ1h1(Xj) + λ2h2(Xj) + λ3h3(Xj)) , (20) where λ = [0.3, 0.4, 0.3]. Users may alternatively provide Xr directly. The latent reference representation xr = E(Xr) is then used for both noise initialization and feature injection in CAPTAIN. 2https://huggingface.co/datasets/laion/laion2B-en-aesthetic 1 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 23 24 25 26 Algorithm 1: Reference Image Selection. 1 def select_reference_image(prompt, lambda1, lambda2, lambda3): # 1) Extract query word eq. (14) attn = collect_cross_attention(prompt) s_tok = sum(A.mean(dim=0) for in attn.values()) s_word = tokens_to_words(s_tok, prompt) top3 = s_word.topk(3).indices w_star = random.choice(top3) # 2) Retrieve post-2024 web images sources = [\"Unsplash\", \"Pexels\", \"Wikimedia Commons\"] X_web = query_image_apis(w_star, sources, min_year=2024) g_star = encode_text(w_star) # eq. (16) # 3) Score candidates using (h1, h2, h3) best_score, X_r = , None for X_j in X_web: f_j = encode_image(X_j) # eq. (16) h1 = cos_sim(f_j, g_star) # eq. (17) h2 = 1 - faiss_max_sim(f_j) # eq. (18) pi_j = phash64(X_j) d_min = min_hamming(pi_j, laion_phash) h3 = clip(d_min / 32)# eq. (19) score = lambda1*h1 + lambda2*h2 + lambda3*h3 if score > best_score: best_score, X_r = score, X_j return X_r"
        },
        {
            "title": "B Computation Overhead Comparison",
            "content": "We evaluate the computational overhead of our method against baseline models in Table 2, including BE Chen et al. [2025a], PRSS Chen et al. [2025b], and Han et al. [2025]. All methods are compared against the vanilla Stable Diffusion v1.4, whose average inference time 2.06 is used to compute the per-method overhead. As reported in Section 4, our approach maintains computational efficiency in terms of both wall-clock time and FLOPs. BE and PRSS exhibit similar efficiency with minimal overhead. However, the per-sample mitigation variant of Han et al. [2025] exhibits significantly higher overhead than other methods due to its optimization-based noise initialization procedure, which incurs additional computational costs that vary across cases. Notably, their batch-wise variant achieves the fastest inference time among all methods, although it does not perform better than the per-sample variant as shown in Han et al. [2025]. Furthermore, as noted in Han et al. [2025], per-sample initialization can be retrieved from cached previous initializations when sample has been processed before, thereby reducing computational overhead in practice. Unless otherwise noted, in our experiments we mainly compare against the per-sample variant of Han et al. [2025], as it outperforms the batch-wise variant. Table 2: Computational overhead comparison over 10 runs with 50 inference steps on SD v1.4. GFLOPS Overhead Time (s) Method Chen et al. [2025a](BE) Chen et al. [2025b](PRSS) Han et al. [2025] [batch-wise] Han et al. [2025] [per-sample] CAPTAIN (Ours) 303.45 136.64 317.25 62.28 235.83 2.23 0.32 4.96 0.48 2.14 0.32 10.88 10.24 2.87 0.87 1.08 2.41 1.04 5.28 1."
        },
        {
            "title": "C Additional Quantitative Result",
            "content": "C.1 Per-Sample Optimal Hyperparameter Results To evaluate the strongest performance our method can achieve, we run full hyperparameter search for each prompt. For every example, we select the conditioning concept extracted from the prompt, choose the corresponding conditioning image, and optimize the injection strength δ. Across 500 prompts, the best configuration per sample reaches CLIP score of 0.294 and an SSCD score of 0.213. In comparison, our default setting (using δ = 0.1) achieves CLIP 0.292 and SSCD 0.250, as reported in the main paper. This corresponds to small CLIP improvement of about 0.7% and larger 14.8% reduction in SSCD, indicating lower similarity to training images while still preserving strong semantic alignment."
        },
        {
            "title": "D Additional Qualitative Results",
            "content": "We provide additional qualitative results in fig. 7 and fig. 8, along with the corresponding prompts listed in table 3. Table 3 also includes the prompts used in fig. 5 of the main paper. As shown in the figures, our approach achieves structural changes while maintaining strong semantic alignment, property that methods like BE Chen et al. [2025a] often struggle with. PRSS Chen et al. [2025b] performs better in this regard but can deviate from the intended prompt due to the semantic prompt replacement. Han et al. [2025] can also induce structural changes through its initialization strategy, which aligns with our frequency-decomposed noise initialization, allowing early latent steps to incorporate external structural bias before memorization occurs. However, Han et al. [2025] sometimes leads to over-saturated visual effects, likely due to its proposed noise-initialization optimization approach. Regarding fine-grained details, we observe that direct feature injection can shift the denoising trajectory, leading some visual details to drift away from the memorized image. At the same time, this shift also strengthens the correctness of textual representation in the final output compared to other methods."
        },
        {
            "title": "E Notation",
            "content": "For clarity and completeness, we provide in table 4 summary of the notation used throughout the main paper. The table groups variables by their functional role in the method, including diffusion-process variables, reference-image retrieval and scoring, frequency-decomposition initialization, timestep-window localization, spatial-memorization localization, and feature injection. This overview is intended to help readers follow the mathematical definitions and implementation details presented in the accompanying sections. 3 Figure 7: Additional Qualitative comparisons between CAPTAIN and the baseline methods, BE Chen et al. [2025a], PRSSChen et al. [2025b], and Han et al.Han et al. [2025]. 4 Figure 8: Additional Qualitative comparisons between CAPTAIN and the baseline methods, BE Chen et al. [2025a], PRSSChen et al. [2025b], and Han et al.Han et al. [2025]. Table 3: Prompts associated with the visual examples in fig. 5, fig. 7, and fig. 8. Training Image Prompt Training Image Prompt The No Limits Business Woman Podcast Ethan Hawke to Star as Jazz Great Chet Baker in New Biopic Mothers influence on her young hippo Daft Punk, Jay Collaborate on Computerized If Barbie Were The Face of The Worlds Most Famous Paintings Renegade RSS Laptop Backpack - View 4 Aero 52-984720BLU 52 Series 158 Wheel, 5 on 43/4 BP, 2 Inch BS IMCA Design Art Beautiful View of Paris Eiffel Towerunder Red Sky Ultra Glossy Cityscape Circle Wall Art Annabel Green Area Rug by Bungalow Rose Freddy Adu Signs For Yet Another Club You Probably Dont Know Lilah Teal Blue Area Rug by Andover Mills Its Always Sunny Gang Will Turn Your Life Around with Self-Help Book Breaking Down the $12 in Your SixPack of Craft Beer Designart Circled Blue Psychedelic Texture Abstract Art On Canvas - 7 Panels Talks on the Precepts and Buddhist Ethics Netflix Strikes Deal with AT&T for Faster Streaming Full body U-Zip main opening on front of bag for easy unloading when you get to camp Shaw Floors Sandy Hollow III 15 Adobe 00108_Q4278 Simple Floral Pave Utpala Garnet Ring with Amethyst and Pink Tourmaline in 18k Yellow Gold 3D Black & White Skull King Design Luggage Covers 007 6 Diffusion Process Variables Table 4: Main notation used in our paper. xt x0 ˆx0 ˆx 0 ϵ, ϵt, ϵT βt αt = 1 ϵθ( ) E, βt, αt latent variable at timestep clean latent (final) predicted clean latent injected clean latent Gaussian noises (0, I) Represents the noisy latent during denoising; evolves from xT to final latent x0. Predicted clean latent after denoising, later decoded to an image. Computed using the denoising network ϵθ (Eq. 5). Clean latent after feature injection inside the mask region. ϵ is forward-diffusion noise; ϵt is reverse-step noise; ϵT is initial noise for sampling. Defines forward diffusion variance. Used to compute the reverse mean and predicted clean latents. U-Net noise estimator conditioned on text. Used to map images to latents and back. variance schedule noise schedule terms noise prediction network VAE encoder/decoder text-conditioning embedding Encoding of the prompt used by the diffusion model. Reference Image Retrieval and Scoring wi, input prompt top-k attended words ) web ), ( Xj Xr ( fj h1, h2, h3 λ retrieved image set jth candidate image selected reference image CLIP vision/text encoders CLIP embedding of Xj CLIP embedding of scoring terms scoring weights Frequency Decomposition Initialization xT initialization latent xr , 1 latent of reference image Fourier transform / inverse frequency masks low, Timestep Window Localization high Text description used for generation. Words extracted by cross-attention aggregation; is randomly sampled for retrieval. Candidate images from Pexels/Unsplash. retrieved non-memorized image. Final reference image chosen after scoring. Used to compute semantic similarity. Vision features used in retrieval scoring. Query word embedding. Semantic alignment, dataset novelty, and perceptual uniqueness scores. Fixed weights [0.3, 0.4, 0.3] for retrieval scoring. Constructed from high-frequency noise and low-frequency reference features. Computed as E(Xr). Used to blend high/low frequencies. Complementary low/high frequency masks in Fourier domain. st tlow, thigh dst dt µdst/dt, σdst/dt mean and std of derivative CLIP similarity at timestep Measures semantic alignment of xt to prompt p. injection window bounds similarity derivative Denoising steps where memorization tends to emerge. Used to detect phase transition of semantic refinement. Used to threshold the lower bound of injection window. Spatial Memorization Localization mBE mconcept τ Bright Ending mask concept-attention mask final binary mask threshold Feature Injection Localizes regions correlated with memorized content. Refined spatial mask aligned with the target concept. Intersection mask: = 1>τ (mBE Used to binarize mask intersection. mconcept). δ injection strength elementwise multiplication Controls the intensity of reference feature injection. Used for mask operations and blending."
        }
    ],
    "affiliations": [
        "King Abdullah University of Science and Technology"
    ]
}