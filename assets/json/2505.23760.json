{
    "paper_title": "Model Immunization from a Condition Number Perspective",
    "authors": [
        "Amber Yijia Zheng",
        "Cedar Site Bai",
        "Brian Bullins",
        "Raymond A. Yeh"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Model immunization aims to pre-train models that are difficult to fine-tune on harmful tasks while retaining their utility on other non-harmful tasks. Though prior work has shown empirical evidence for immunizing text-to-image models, the key understanding of when immunization is possible and a precise definition of an immunized model remain unclear. In this work, we propose a framework, based on the condition number of a Hessian matrix, to analyze model immunization for linear models. Building on this framework, we design an algorithm with regularization terms to control the resulting condition numbers after pre-training. Empirical results on linear models and non-linear deep-nets demonstrate the effectiveness of the proposed algorithm on model immunization. The code is available at https://github.com/amberyzheng/model-immunization-cond-num."
        },
        {
            "title": "Start",
            "content": "Amber Yijia Zheng * 1 Cedar Site Bai * 1 Brian Bullins 1 Raymond A. Yeh 1 5 2 0 2 9 2 ] . [ 1 0 6 7 3 2 . 5 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Model immunization aims to pre-train models that are difficult to fine-tune on harmful tasks while retaining their utility on other non-harmful tasks. Though prior work has shown empirical evidence for immunizing text-to-image models, the key understanding of when immunization is possible and precise definition of an immunized In this work, we promodel remain unclear. pose framework, based on the condition number of Hessian matrix, to analyze model immunization for linear models. Building on this framework, we design an algorithm with regularization terms to control the resulting condition numbers after pre-training. Empirical results on linear models and non-linear deep-nets demonstrate the effectiveness of the proposed algorithm on model immunization. The code is available at https://github.com/amberyzheng/ model-immunization-cond-num. 1. Introduction Model immunization, recently proposed by Zheng & Yeh (2024), studies how to pre-train model that is more difficult to fine-tune on harmful content, but not others. The aim is to mitigate the risk of misuse (Brundage et al., 2018; Marchal et al., 2024) associated with open-sourced models by immunizing them before they are released to the public. Zheng & Yeh (2024) focus on immunizing text-to-image models, where they formulate immunization as bi-level optimization. Empirically, they show that pre-trained diffusion models that undergo immunization are more difficult to finetune on given harmful concept dataset. To quantify this difficulty, they compare the generation quality of models with and without immunization after fixed number of finetuning iterations. While the empirical results are promising, *Equal contribution 1Department of Computer Science, Purdue University. Correspondence to: Raymond A. Yeh <rayyeh@purdue.edu>. Proceedings of the 42 nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s). 1 definition of an immunized model and the circumstances that make immunization possible remain unclear. To tackle this issue, we propose framework to study model immunization using the condition number (Gloub & Van Loan, 1996). The effectiveness of immunization can be characterized by the condition number of the Hessian matrix. When using gradient-based methods during finetuning, condition number closer to one indicates faster convergence (Boyd & Vandenberghe, 2004), i.e., easier to fine-tune. With this perspective, we observe that the existence of an effective immunization for linear models is related to the angle between the singular vectors of the harmful fine-tuning datasets covariance matrix and the pretraining datasets covariance matrix. From this condition number perspective, we propose an immunization algorithm to find such model. In detail, we propose two additional terms to regularize the condition number during pre-training. Each of the introduced regularization terms can be shown to ensure monotonic increase/decrease of the condition number under gradient updates. Beyond the theoretical results, we empirically validate the proposed algorithm on linear models for regression and image classification tasks. Lastly, we conduct experiments using the proposed algorithm on non-linear models, i.e., deep-nets. Despite the gap in theory, we observe that the proposed approach remains effective at model immunization across ResNet (He et al., 2016) and ViT (Dosovitskiy, 2021). Our contributions are summarized as follows: We introduce framework based on the condition number to study the task of model immunization. This framework leads to concrete definition of an immunized model along with novel experiment setup and evaluation metric to compare the quality of different immunization techniques. We propose regularizers to maximize/minimize the condition number, with guaranteed monotonic increase/decrease when updated with the gradient-based method. Together with the task objective and regularizers, we demonstrate that the proposed algorithm effectively immunizes linear models and deep-nets on regression/image classification tasks. Model Immunization from Condition Number Perspective 2. Preliminaries This section provides the background of the condition number and its connection to gradient descent. Additionally, we briefly review transfer learning (Zhuang et al., 2020), as it can be technique for misusing open-source models. Condition number and convergence of gradient descent. Given general matrix S, the condition number (Gloub & Van Loan, 1996) is defined as (cid:13)S(cid:13) (cid:13) κ(S) S2 /σmin , (cid:13)2 = σmax (1) where is the pseudoinverse and σS corresponds to the max/min singular value of S. The condition number is related to the convergence rate of gradient-based algorithms. Consider an optimization problem minw L(w) where is strongly convex and has Hessian 2L with max/min singular values denoted as σmax/min. In this case, the constant step-size steepest descent algorithm has convergence rate (Bubeck, 2015) of the following wt w2 (cid:18) 1 (cid:19)t σmin σmax w0 w2, (2) where denotes the optimal solution, and wt denotes the steepest descent iterate at step t. We can observe that larger condition number corresponds to slower convergence. Condition number regularization. Nenov et al. (2024) proposed regularizer for minimizing the condition number of some general matrix Rwell(S) = 1 S2 2 1 2p S2 , (3) in which is the minimum dimension of S, and the norms correspond to the spectral norm and Frobenius norm. They showed that Rwell(S) is valid regularizer by proving its nonnegativity, and is an upper bound on log (κ (S)). In addition, they showed that Rwell(S) is differentiable under some mild conditions, and if updated with gradient descent, it is guaranteed to decrease the condition number monotonically. See Appendix for the exact statements. Different from Nenov et al. (2024), we propose differentiable regularizer that is guaranteed to increase the condition number as an upper bound on 1/log (κ (S)). For model immunization, instead of general matrix S, we need to consider the regularization of the Hessian of linear models composed of feature extractor and classifier, while preserving their differentiability and monotonicity guarantees during gradient updates to the feature extractor. Transfer learning via linear probing. In this work, we focus on the transfer learning method of linear probing. Given pre-trained feature extractor fθ : RDin RDhid, linear probing learns an linear classifier hw : RDhid RDout over the target dataset = {(x, y)} using the frozen feature extractor fθ. This model learning is formulated as the following optimization problem min L(D, w, θ) min (cid:88) (x,y)D ℓ(hw fθ(x), y) (4) where ℓ denotes suitable loss function, e.g., cross-entropy. By keeping θ fixed, the model leverages features learned from pre-training task and transfers them to the target task. This approach is effective when the target dataset is too small to train model from scratch. 3. Immunization with Condition Number The goal of model immunization is to learn pre-trained model gω fθI , consisting of classifier gω and an immunized feature extractor fθI , such that fine-tuning fθI on harmful task is difficult, but not for other tasks. The model should also maintain good pre-training task performance. Specifically, we study the setting when bad actor uses linear probing on pre-trained linear feature extractor with gradient descent. Immunization setting. We denote pre-training dataset as DP = {(x, y)} and harmful dataset as DH = {(x, y)} where RDin. The bad actor performs linear probing using DH following Eq. (4) with an ℓ2 loss. We will focus our analysis on linear pre-trained feature extractor without dimensionality reduction, i.e., fθ xθ with θ RDinDin. Definition 3.1. Under this setting, model is said to be immunized if it satisfies the following: (a) It is more difficult to apply linear probing on the harmful task DH using the immunized feature extractor fθI than directly on the input data, i.e., κ(2 wL(DH, w, θI)) κ(2 wL(DH, w, I)), (5) where denotes the identity matrix. (b) It is not more difficult to apply linear probing on other tasks. As there is only one other task DP, an immunized feature extractor should have κ(2 ωL(DP, ω, θI)) κ(2 ωL(DP, ω, I)). (6) Note: we use ω to denote the classifier parameters of the pre-training task and for the harmful task. (c) The immunized model should maintain competitive task performance on the pre-training dataset DP, i.e., min ω,θ L(DP, ω, θ) min ω L(DP, ω, θI). (7) For linear models, as long as θI is invertible, exact equality can be achieved. 2 Model Immunization from Condition Number Perspective 3.1. Analysis on Immunized Linear Models To provide some intuition on how the feature extractor θ affects the convergence of linear probing, we study the analytical form of the singular values of the Hessian. For readability, we will rewrite linear probing in Eq. (4) by considering fθ xθ and ℓ2-loss. Let XH RN Din and YH RN Dout denote data from DH stacked into matrices with DH. When using ℓ2-loss, Eq. (4) can be written as min L(DH, w, θ) = min (XHθ)w 2 2 . In this case, the Hessian matrix HH(θ) wL(DH, w, θ) = θKHθ, (8) (9) XH is the data covariance matrix. where KH Proposition 3.2. The singular values of the Hessian matrix in Eq. (9) are given by σi = Din(cid:88) j=1 (cid:0)σθ,i(u θ,iqj) (cid:1) , γj {1, . . . , Din}. (10) Here, σθ,i and uθ,i correspond to the i-th singular value and vector of θ. Next, γj and qj correspond to the j-th singular value and vector of the covariance K. Proof sketch. This result can be shown by using the fact that KH is symmetric positive semi-definite matrix and decomposing via SVD. The complete proof is provided in Appendix B.1. From Eq. (10), we can see that the singular value of the Hessian depends on the relative angle between the singular vectors between feature extractor θ and the covariance matrix of the data KH. As the feature extractor is shared between the pretrained DP and harmful DH datasets, the strength of the immunization depends on the relative angle between the singular vectors of KP and KH. For example, if the singular vectors (sorted by the singular values) are all perfectly aligned between the two, then no θ can simultaneously maximize κ(2 wL(DH, w, θ)) and minimize κ(2 ωL(DP, ω, θ)). With better understanding of the effect of the feature extractor θ on the condition number, we will next present an algorithm to immunize model. 4. Algorithm for Immunizing Model Algorithm 1 Condition number regularized gradient descent for model immunization input Primary task DP = (XP, YP), harmful task input XH, supervised loss L, learning rate η, regularizing constants λP, λH R+, model initialization θ0, ω0 1: KP = XP 2: KH = XH 3: for = 0, 1, . . . , 1 do 4: 5: HP (θt) = θ 6: ωt+1 = ωt ηωL(ωt, θt; DP) KPθt, HH (θt) = θ KHθt θt+1 = θt ηθL(ωt, θt; X1) ηλPK1 ηλHK1 θRwell (HP (θt)) θRill (HH (θt)) 7: end for output Immunized feature extractor θI θT . in Eq. (3) denotes the regularizer to minimize the condition number, HP(θ) 2 ωL(DP, ω, θ) = θKPθ is the Hessian matrix of the pre-training task, and denotes the supervised loss. Each of the terms encourages the model to satisfy the three immunization requirements in Definition 3.1. For readability, we have dropped the scalar hyperparameters balancing the terms. We propose to solve Eq. (11) using gradientbased method as outlined in Alg. 1. In the remainder of this section, we will first introduce the novel regularizer to maximize general matrices condition number and their relevant properties (Sec. 4.1). We then show how to incorporate the regularizers Rill and Rwell into the immunization setup (Sec. 4.2). Finally, we discuss the provable guarantees with respect to each of the regularizers (Sec. 4.3). 4.1. Regularizer for Maximizing the Condition Number We analyze the condition number of general matrix Rprpc, = min{pr, pc}, and rank (S) = p. The compact SVD of is given by = Diag(σ)V , in which σ = [σ1, , σk] such that σmax = σ1 σ2 > 0 and ui, vi denotes the ith column σk = σmin vector of , for [k]. Inspired by the regularizer for minimizing the condition number, we propose its counterpart for maximizing the condition number We formulate model immunization as an optimization problem with the following objective: Rill(S) = 1 1 )2 , 2 (σmin 1 2k S2 (12) min ω,θ Rill(HH(θ)) + Rwell(HP(θ)) + L(DP, ω, θ), (11) which satisfies the properties in the following theorem. where Rill, to be defined in Sec. 4.1, denotes our proposed regularizer to maximize the condition number, Rwell Theorem 4.1 (Properties of κ-maximizing regularizer Rill(S)). 3 Model Immunization from Condition Number Perspective (1) [Nonnegativity] For any Rprpc , Rill (S) 0, and Rill (S) = 0 if and only if κ (S) = . 1 (2) [Upper Bound] log(κ(S)) (σmax )2 Rill (S), i.e., is reasonlog(κ(S)) when σmax Rill(S) upper bounds ably away from . (3) [Differentiability] If σmin = σk < σi for any < k, is unique, then Rill(S) is differentiable and i.e., σmin SRill(S) = σkukv 1 )2(cid:17)2 . 2 (σmin (cid:16) 1 2k F 1 (13) (4) [Monotonic Increase] If σmin is unique, update with SRill(S) such that = η2SRill(S) (cid:16) 1 2k S2 for 0 < η2 < , then k1 κ (S) > κ (S). )2(cid:17)2 2 (σmin 1 Proof sketch. We provide some intuitive illustrations of the proof and defer the complete version to Appendix B.2. For (1), as the squared Frobenius norm of matrix equals the sum of the squares of its singular values, the denominator of Rill (S) is the average of the squared singular values minus their minimum, ensuring it is nonnegative. It can be shown that Rill (S) is inversely related to κ (S), which indicates that Rill (S) = 0 if and only if κ (S) = . For (2) the upper bound holds by the design of Rill (S) and applying the mean value inequality on log (cid:0)κ(S)2(cid:1) = log (cid:16) )2(cid:17) (σmax log (cid:16)(cid:0)σmin (cid:1)2(cid:17) . (14) For (3), even though σmin is not differentiable since it involves taking the minimum of the singular values, its subdifferential is well-defined (Lewis, 1995). When σmin is unique, its subdifferential reduces to singleton, i.e., its gradient, making Rill (S) also differentiable. For (4), one key observation is that the closed-form SRill(S) shares the same set of singular vectors as S, so that the linear relation in gradient update can be passed on to singular values. By choosing suitable step size, the increase in condition number can be guaranteed. Theorem 4.1 demonstrates that the regularizer Rill (S) introduced is reasonable upper bound for maximizing condition numbers and indicates that under some mild condition, i.e., the minimum singular value is unique, simple first-order algorithms like gradient descent can be used to minimize the regularizer with guaranteed increase in condition number. 4.2. Incorporating Regularizers into Immunization Given the immunization setup, we now analyze the regularizer Rill and Rwell for matrices with the specific structure of feature covariance matrices, and propose the corresponding algorithm for model immunization. As illustrated in the immunization setup, the feature extractor θ is the trainable parameter. For data RN Din of the feature extractor, we analyze the condition number of H(θ) θKθ RDinDin with rank (H) = k, and compact SVD = Diag(σ)V . Recall, we define = to be the covariance matrix of the data. In the following theorem, we show that under the same conditions, the introduced regularizers Rill () and Rwell () are also differentiable w.r.t. θ when applied to θKθ. Theorem 4.2. For (θ) = θKθ, if its maximum and minimum singular values σ1 and σk are unique, then (1) θRwell (H (θ)) = 2Kθ (cid:16) σ1v1v θKθ (cid:17) , (2) θRill (H (θ)) = 1 1 Din θKθ) k)2 . 2 σ 2Kθ(σkvkv ( 1 2k θKθ2 1 1 Proof sketch. The differentiability follows from the same argument of Theorem 4.1 (3) under the condition that the maximum and minimum singular values are unique. The closed-form gradients are computed with the chain rule in matrix calculus defined by the Frobenius inner product. The complete proof can be found in Appendix B.3. With the closed-form gradient of the regularizers w.r.t. θ, we propose our algorithm for model immunization in Alg. 1. Specifically, Alg. 1 employs the general gradient descent framework. Line 4 conducts standard updates for the classifier ω, minimizing the supervised loss L. In lines 5 to 6, the regularizers Rill and Rwell are applied on the feature covariance HH(θ) of the harmful task and HP(θ) of the pretraining task. This is done by updating the feature extractor θ with the gradients θRill(HH) and θRwell(HP) normalized by their input covariances and the gradient from the supervised loss θL. 4.3. Condition Number Guarantees We show in the following theorem that the condition number decrease/increase guarantees introduced in Theorem A.1 (4) and Theorem 4.1 (4) are preserved for θKθ even when the gradient updates are taken in θ as in Alg. 1, instead of θKθ. Theorem 4.3. For the trainable feature extractor θ, feature covariance HP (θ) = θKPθ of the primary task and HH (θ) = θKHθ of the immunization task with rank (HP) = kP, rank (HH) = kH and compact SVD HP (θ) = UPDiag(σP)V , HH (θ) = UHDiag(σH)V , for σP = [σP,1, , σP,kP], σH = [σH,1, , σH,kH ], (1) if σmax HP i.e., σmax HP is unique, θ such that θ = θ ηPK1 = σP,1 > σP,2, update θRwell(HP (θ)) for , then σP,1σP,2σP,2 σ (cid:27) , 2 Din P,2 (cid:26) 1 Din )σP,1 (1 1 0 < ηP < min 4 Model Immunization from Condition Number Perspective (cid:16) θKPθ(cid:17) κ < κ (cid:0)θKPθ(cid:1), (2) if σmin HH is unique, i.e., σmin HH = σH,kH < σH,kH1, update θ such that θ = θ ηHK1 θRill(HH (θ)) for 0 < (cid:1)2(cid:17)2 (cid:13)θKHθ(cid:13) (cid:13) 2 1 1 , ηH < (cid:13) > κ (cid:0)θKHθ(cid:1). θKHθ(cid:17) (cid:16) 1 2kH (cid:0)σmin HH 12σmin HH then κ /kH (cid:16) 2 Table 1. Quantitative results of immunization in House Price dataset (Montoya & DataCanary, 2016), computed over 5 random seeds. Eq. (15) (i) Eq. (15) (ii) Method Rill Only 90.02 3.773 72.415 3.545 7.053 1.662 3.545 0.880 1.518 0.027 0.016 0.001 18.92 2.056 IMMA Opt κ Ours RIR 1.244 0.021 2.001 0.187 92.58 4.492 0.053 0.002 356.20 5. Proof sketch. There is mismatch between the gradient update on θ and the condition number update, which is observed for (θ). To address this, we carefully leverage the structure of the problem, noting that (θ), unlike general matrix, is symmetric and positive semidefinite, with identical left and right singular vectors. Exploiting this property, along with our algorithm design, ensures that the linearity in singular value updates is preserved when expanding (θ) using the closed-form gradient in Theorem 4.2. Consequently, monotonic increase or decrease in the condition number can be guaranteed by appropriately selecting the step size. The full proof is provided in Appendix B.4. 4.4. Additional Discussion Implementation considerations. At glance, it may seem that to implement Alg. 1 using automatic differentiation packages, e.g., Pytorch (Paszke et al., 2019), one would have to implement custom optimizer and involve multiple update steps. Instead, we observe that by directly modifying the computation graph, it would only involve single backward pass. This is done by introducing dummy layer with an identified function as its forward pass and its backward pass multiplies the gradient by the inverse feature covariance matrix. The dummy layer implementation is inspired by prior works in gradient estimator (Bengio et al., 2013; Roeder et al., 2017). Pseudo-code is provided in Appendix C.3. Limitations. The monotonicity guarantees in Theorem 4.3 serve as theoretical justification for our proposed algorithm, albeit partial reflection of the application setup. Note that the feature extractor is updated with the gradients of the two regularizers jointly together with that of the supervised loss and the guarantees may not linearly combine as such. In practice, maintaining the balance between κ (HP (θ)) and κ (HH (θ)) requires proper choice of hyperparameters. Next, the current framework we analyzed focuses on linear feature extractors and using linear probing for transfer learning. We are aware of the practical limitations of this setting. To address this, in the experiments, we empirically study the effect of the proposed method on non-linear models, i.e., deep-nets, and demonstrate our methods potential despite the theoretical gap. 5. Experiments We evaluate the proposed Alg. 1 on regression and image classification tasks using linear models, and also explored immunizing non-linear models, i.e., deep-nets. Experiment and implementation details are provided in Appendix C. Evaluation metrics. We introduce the relative immunization ratio (RIR) to quantify the effectiveness of the immunization based on the ratio of the condition number of Hessian, defined as follows: RIR (cid:18) κ(HH(θI)) κ(HH(I)) (cid:123)(cid:122) (i) (cid:124) (cid:19) (cid:125) (cid:30) (cid:18) κ(HP(θI)) κ(HP(I)) (cid:123)(cid:122) (ii) (cid:124) (cid:19) (cid:125) (15) where denotes the identity matrix. Each term here measures the ratio between condition numbers with and without the pre-trained feature extractor on the (i) harmful task or (ii) on the pre-training task. successful immunization is characterized by: (i) large ratio κ(HH(θI)) κ(HH(I)) , i.e., using the immunized feature extractor makes the optimization of linear probing more difficult on the harmful task. (ii) small ratio κ(HP(θI)) κ(HP(I)) ), i.e., using the pre-trained extractor do not make optimization more difficult on the pre-training task. To obtain single metric, we compare (i) and (ii) relative to each other. In other words, an effective immunized model should have relative immunization ratio RIR 1. Baselines. We consider three baselines for comparisons: Rill Only immunizes the model by minimizing only the regularizer Rill(HH) as defined in Eq. (12) using gradient descent. IMMA (Zheng & Yeh, 2024) is formulated as bi-level optimization program where both lower and upper tasks are solved via gradient descent. In the lower-level, it minimizes L(DH, w, θ) w.r.t. θ to obtain θ, and in the upper-level, it maximizes L(DH, w, θ) L(DP, ω, θ) w.r.t. θ by backpropagating through θ. Opt κ directly minimizes κ(HP(θ)) κ(HH(θ)) w.r.t. θ Model Immunization from Condition Number Perspective Norm ratio curve on DP Norm ratio curve on DH Figure 1. Norm ratio Eq. (16) vs. Epochs. We visualize the convergence of linear probing of different immunized models using gradient descent with an exact line search. Here, Identity corresponds to not using feature extractor, i.e., θI = I. Observe that Ours made the convergence faster on DP while slower in DH when compared to the other baselines; consistent with the results in Tab. 1. via gradient descent instead of using our proposed regularizers. 5.1. Experiments on Immunizing Linear Models Linear regression task. We use the regression task from the House prices dataset (Montoya & DataCanary, 2016). We split the data into DP and DH based on the feature MSZoning. For the pre-training task, we use the target of LotArea and for the harmful task we use the target of SalePrice. Both DP and DH contain input vectors of dimension 79. We immunized the model by running Alg. 1 for 100 epochs with η = 0.005. We choose λP and λH by balancing the gradient norm of Rwell and Rill. The implementation details can be found in Appendix C.2. In Tab. 1, we present the empirical results of immunizing linear feature extractor θ. We observe that only Opt κ and our method successfully immunize the model achieving an RIR thats much greater than 1. For Rill Only and IMMA, while they successfully made the harmful task more ill-conditioned, i.e., Eq. (15) (i) went up, however, this is at the cost of making the other task ill-conditioned as well, i.e., Eq. (15) (ii) went up. Next, we demonstrate how large condition number slows down the convergence of linear probing on the harmful task by analyzing the norm ratio defined as wt w2 2/w0 w2 2, (16) which measures how the classifier weights wt at step approach the optimal weights during fine-tuning. Note, naively choosing step size will not reflect the difference in condition number. Hence, we use the exact line search (Boyd & Vandenberghe, 2004) which chooses the step size that minimizes the loss at each iteration. Table 2. Quantitative results of immunization in MNIST (LeCun, 1998), computed over 3 random seeds and averaged over all digit pairs. Note that Opt κ has large STD in RIR, resulting in the deviation between RIR and the ratio of the averaged values. Eq. (15) (i) RIR Eq. (15) (ii) Method Rill Only 14.832 1.039 8.654 0.606 1.933 0.046 1.774 0.041 2.774 0.094 4.522 0.139 3.196 1.225 69.73 54.00 0.756 1.171 6.345 0.188 0.149 0.009 70.04 3.280 IMMA Opt κ Ours achieves stronger immunization effect than Opt κ. In contrast, Rill Only and IMMA slowed the convergence on both the harmful task DH and the pre-training task DP. Image classification task. For image classification, we conduct experiments using MNIST (LeCun, 1998). The MNIST dataset consists of images over 10-digit classes, which can be formulated into 10 independent binary classification tasks. Across all pairs of tasks, we choose one to be the harmful task DH and the other the pre-training DP resulting in total of 90 experiments. We ran Alg. 1 for 30 epochs with η = 0.005 for these experiments. The implementation details can be found in Appendix C.2. In Tab. 2, we present the quantitative results on these binary task pairs. For each entry, the values are averaged over all 90 pairs. Based on the averaged results, we observe that our method effectively immunizes the linear feature extractor θ on DH without compromising performance on DP. Although Opt κ achieves comparable RIR with our method, the variances of the metric values are relatively large. This indicates that Opt κ is sensitive to random initialization while our method is robust. As illustrated in Fig. 1, both our method and Opt κ slow down convergence in DH compared to Identity while accelerating convergence in DP. Furthermore, our method In Fig. 2 we further analyze the results by visualizing the log(RIR) for each digit pair. blue block indicates successful immunization, while red block indicates failure. It can 6 Model Immunization from Condition Number Perspective"
        },
        {
            "title": "IMMA",
            "content": "Opt κ Ours Figure 2. Visualization of log(RIR) of binary classification tasks created from MNIST. Each element in the figure corresponds to the log(RIR) of model immunized against DH from the pre-training task of DP. We color the block blue if RIR 1, and red otherwise. Our method succeeds in immunizing the model across all digit pairs, while the baselines failed in most pairs. be observed that Rill Only fails for all digit pairs, IMMA only succeeds in one pair, and Opt κ fails for 32 out of 90 pairs. In contrast, our method achieves success across all digit pairs demonstrating its effectiveness for immunization. Thus far, we have conducted experiments strictly following the immunization setting that we have proposed in Sec. 3. However, one limitation of the setting is that the feature extractor is assumed to be linear, which limits its real-world potential. To further study the practicality of our method, despite the theoretical gap, we conduct experiments with non-linear models, i.e., deep-nets, on larger-scale image classification dataset of ImageNet. 5.2. Experiments on Immunizing Deep-Nets Immunization task. In this experiment, we consider common setup of linear probing on models pre-trained on ImageNet (Deng et al., 2009), i.e., ImageNet serves as DP. For DH we experiment with the Stanford Cars Dataset (Krause et al., 2013) and Country211 Dataset (Radford et al., 2021). These datasets have been previously used for studying transfer learning (Radford et al., 2021) for image classification. More dataset details are deferred to Appendix C.1. Experiment setup. For non-linear models, we experiment with the architecture of ResNet18 (He et al., 2016) and ViT (Dosovitskiy, 2021). Here we study practical setting where given model with parameters θ0 has already been trained on DP and would undergo immunization to obtain θI to be released to the public. Note that as we are now using an initialization of θ0 and non-linear feature extractor fθ, we extend the RIR metric to consider those changes. Specifically, we propose RIRθ0 (cid:32) (cid:124) κ( HH(θI)) κ( HH(θ0)) (cid:123)(cid:122) (i) (cid:33) (cid:30) (cid:32) (cid:125) (cid:124) κ( HP(θI)) κ( HP(θ0)) (cid:123)(cid:122) (ii) (cid:33) (cid:125) (17) where we compare the immunized model θI relative to the initialization model θ0. Here, H(θ) denotes the Hessian for linear probing on DH with non-linear fθ, i.e., HH(θ) = 2 wL(DH, w, θ) = XH(θ) XH(θ). (18) Here, XH(θ) [fθ(x); DH] RN Dhid denotes the concatenation of the features, with dimensions Dhid, extracted from the input data. Due to memory constraints, we approximate Eq. (17) by randomly sampling 20 groups of training data, each containing 100 samples, and reporting the average values. Finally, we also report the task performance after immunization. This is because, as the feature extractor is non-linear we are no longer guaranteed to retain the task performance. For ResNet18, we immunize only the last two convolutional blocks of the trained feature extractor and keep the rest of the parameters frozen as in θ0. For ViT, we only immunize the final transformer block. We optimize Eq. (11) using SGD with momentum, the default optimizer on ImageNet. Further details are provided in Appendix C.2. Results. We present the quantitative results of immunizing deep-nets in Tab. 3. On both Cars and Country211 datasets, our method demonstrates strong performance when applied to ResNetg18 and ViT, as indicated by RIRθ0 1. In comparison, Rill Only and IMMA did not effectively immunize the models in all evaluated settings. Next, Opt κ also succeeds in immunizing the models but our proposed method outperforms it in RIRθ0. Next, we report the test accuracy of the immunized models on DP, i.e., ImageNet1K. On the ResNet18 architecture, we observe reduction in test-accuracy from the initialization model θ0 of 68.24% to 62.36% when DH is Cars and 65.01% when DH is Country211. Interestingly, on the ViT architecture the test-accuracy increased from 81.78% to 82.79% for Cars, and 83.17% for Country211. These results suggested that it is possible to immunize non-linear model against the harmful task without losing the effectiveness of the other task. 7 Model Immunization from Condition Number Perspective Table 3. Quantitative results of immunization of model pre-trained on ImageNet (Deng et al., 2009), computed over 3 random seeds. The DP test accuracy for the off-the-shelf model initialization of θ0 on ResNet18 is 68.24% and that of ViT is 81.78%. We report RIRθ0 to measure the quality of immunization. Test accuracy of DP is reported to ensure the performance on the pre-training task is maintained. DH Method Init. θ0 Rill Only IMMA Opt κ Ours C 1 Rill Only 1 2 n IMMA Opt κ Ours ResNet Eq. (17) (i) 1.0 1.878 0.034 0.866 0.002 1.217 0.021 2.386 0.442 20.727 0.791 0.791 0.005 1.538 0.155 3.287 0.33 Eq. (17) (ii) 1.0 1.786 0.025 0.889 0.001 0.798 0.005 0.699 0.062 20.675 1.685 0.814 0.006 1.053 0.091 0.399 0.034 RIRθ0 1.0 1.057 0.026 0.974 0.002 1.527 0.019 3.467 0.358 1.038 0.05 0.972 0.007 1.472 0.043 8.714 0.672 DP Test Acc. (%) 68.24 63.84 0.292 63.57 0.234 63.65 0.148 62.36 0.173 62.17 1.599 67.03 0.146 66.81 0.115 65.01 0.143 Eq. (17) (i) 1.0 13.121 0.038 1.422 0.006 3.598 0.510 7.945 0.247 69.291 1.198 6.242 0.203 4.589 0.079 20.894 1.425 Eq. (17) (ii) 1.0 4.097 0.098 2.090 0.043 0.171 0.033 0.323 0.086 63.519 6.62 7.599 0.717 0.300 0.106 0.700 0. ViT RIRθ0 1.0 3.342 0.048 0.702 0.007 26.369 2.814 34.517 0.886 1.122 0.097 0.845 0.048 16.498 5.183 41.341 0.967 DP Test Acc. (%) 81.78 82.21 0.035 81.89 0.010 82.51 0.085 82.79 0.200 80.73 0.129 82.47 0.036 82.79 0.023 83.17 0.075 To further show larger Eq. (17) (i) indicating that model is better immunized, we report the linear probed (fine-tuned) results on different feature extractors and provide the test accuracy on DH, where DH is the Stanford Cars dataset. As shown in Fig. 3, our method exhibits the slowest convergence rate on both ResNet18 and ViT, indicated by the lowest test accuracy compared with baselines. In summary, our method remains effective on deep-nets, producing models that satisfy the requirements of an immunized model as in Definition 3.1. 6. Related Work We briefly discuss related research on AI safety and the condition number. AI safety, model un/re-learning, and immunization. AI safety has received attention lately, specifically in generative AI, due to the impressive progress. We refer the reader to Brundage et al. (2018); Marchal et al. (2024); Bengio et al. (2025) for more in-depth discussion on this topic. In the following, we will discuss model unlearning, one of the ways to mitigate the potential of misuse, followed by model immunization, which protects model against relearning. Machine unlearning was first introduced by Cao & Yang (2015) to remove users private information from model. Approximate unlearning aims to achieve this by modifying the pre-trained model directly using the specific data samples to erase, without requiring full retraining (Nguyen et al., 2020; Wu et al., 2022; Guo et al., 2019; Sekhari et al., 2021; Neel et al., 2021). In the context of text-to-image models, several methods for concept erasure have been proposed. These include inference-time approaches (Brack et al., 2023; Schramowski et al., 2023), fine-tuning of diffusion models (Gandikota et al., 2023; Kim et al., 2023; Kumari et al., 2023), and direct model editing (Zhang et al., 2024; Gandikota et al., 2024). While promising, these works still face potential risks of the re-emergence/re-learning of harmful data (Zheng & Yeh, 2024; Zheng et al., 2024; Zhan et al., 2024; Bertran et al., 2024; Xu et al., 2025). To avoid relearning or further finetuning on harmful data, Zheng & Yeh (2024) propose to immunize the text-to-image models against malicious finetuning and Zheng & Yeh (2025) extend model immunization to multi-concept settings. Recent work highlights the importance of preventing re-finetuning or distillation on harmful tasks in language models (Huang et al., 2024; Savani et al., 2025) and encoder probing (Ding et al., 2025), which is closely related to our goal. While we also study the task of model immunization, different from Zheng & Yeh (2024) that primarily focuses on empirical applications on generative tasks, our work aims to provide more principled understanding of model immunization by analyzing it through the lens of the condition number. Minimizing Condition Number. Condition number has been key factor in the convergence rates and accuracies of iterative methods, e.g., Jacobi method (Arioli & Romani, 1985), steepest descent (Luenberger et al., 1984), conjugate gradient (Hestenes et al., 1952), for solving optimization problems from classic linear systems (Saad, 2003) to those with general nonlinear objectives (Nesterov, 2018) concernIt is widely ing modern machine learning applications. observed that small condition number tends to speed up convergence and improve accuracy whereas large condition number could lead to an unstable optimization procedure (Saarinen et al., 1993; Kress, 2012; Bengio et al., 2017; Guille-Escuret et al., 2021). As result, methods to minimize the condition number in various contexts have been proposed. Preconditioning (Evans, 1968), technique that involves finding matrix, i.e., the preconditioner, to multiply with the original matrix, resulting in new matrix with significantly smaller condition number, is widely used for solving linear systems. The preconditioner can be constructed using methods such as semidefinite programming (Jambulapati et al., 2020; 2023; Qu et al., 2024) or matrix equilibration (Van der Sluis, 8 Model Immunization from Condition Number Perspective Fine-tuning accuracy with ResNet-18 Fine-tuning accuracy with ViT Figure 3. Test accuracy vs. Fine-tuning Epochs on DH. We visualize the test accuracy of linear probing on ImageNet of different immunized models using gradient descent. Here DH is the Stanford Cars dataset. 1969), and has recently found applications in deep learning (Saratchandran et al., 2024). Most related to this work, Balazs et al. (2024) propose to regularize the condition number of weight matrices by directly adding the condition number term into the optimization objective and applying (sub)gradient descent. Observing that the condition number is discontinuous and nonconvex, Nenov et al. (2024) proposed differentiable regularizer that minimizes the matrix condition number with monotonic decrease guarantee if optimized with gradient descent. To the best of our knowledge, no notable effort has been made to increase or maximize the condition number. 7. Conclusion We propose framework for studying model immunization through the condition number of the Hessian matrix. We show that immunization can be achieved by increasing the condition number of harmful datasets while keeping it stable for the pre-training task. To achieve this, we introduce two differentiable regularizers and propose an algorithm that incorporates these regularizers into gradient-based optimization algorithm. Empirical results on both linear and deep models demonstrate the effectiveness of our approach to model immunization. We believe that our proposed framework is first step towards more principled understanding of model immunization and will ultimately make open-sourced models safer."
        },
        {
            "title": "Acknowledgements",
            "content": "This project is supported in part by an NSF Award #2420724 and the Ross-Lynn Research Scholar Grant."
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents work whose goal is to advance the field of Machine Learning and Optimization. While there are many potential societal consequences of our work, we believe that the benefits outweigh the harms. Specifically, the topic of model immunization is towards making AI safer."
        },
        {
            "title": "References",
            "content": "Arioli, M. and Romani, F. Relations between condition numbers and the convergence of the jacobi method for real positive definite matrices. Numerische Mathematik, 1985. Balazs, P., Haider, D., Lostanlen, V., and Perfler, F. Trainable signal encoders that are robust against noise. In INTER-NOISE and NOISE-CON Congress and Conference Proceedings, 2024. Bengio, Y., Leonard, N., and Courville, A. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013. Bengio, Y., Goodfellow, I., and Courville, A. Deep learning. MIT press Cambridge, MA, USA, 2017. Bengio, Y., Mindermann, S., Privitera, D., Besiroglu, T., Bommasani, R., Casper, S., Choi, Y., Fox, P., Garfinkel, B., Goldfarb, D., Heidari, H., Ho, A., Kapoor, S., Khalatbari, L., Longpre, S., Manning, S., Mavroudis, V., Mazeika, M., Michael, J., Newman, J., Ng, K. Y., Okolo, C. T., Raji, D., Sastry, G., Seger, E., Skeadas, T., South, T., Strubell, E., Tram`er, F., Velasco, L., Wheeler, N., Acemoglu, D., Adekanmbi, O., Dalrymple, D., Dietterich, T. G., Felten, E. W., Fung, P., Gourinchas, P.-O., Heintz, F., Hinton, G., Jennings, N., Krause, A., Leavy, S., Liang, P., Ludermir, T., Marda, V., Margetts, H., McDermid, J., Munga, J., Narayanan, A., Nelson, A., Neppel, C., Oh, A., Ramchurn, G., Russell, S., Schaake, M., Scholkopf, B., Song, D., Soto, A., Tiedrich, L., Varoquaux, G., Yao, A., Zhang, Y.-Q., Ajala, O., Albalawi, F., Alserkal, M., Avrin, G., Busch, C., de Carvalho, A. C. P. d. L. F., Fox, B., Gill, A. S., Hatip, A. H., Heikkila, J., Johnson, C., 9 Model Immunization from Condition Number Perspective Jolly, G., Katzir, Z., Khan, S. M., Kitano, H., Kruger, A., Lee, K. M., Ligot, D. V., Lopez Portillo, J. R., Molchanovskyi, O., Monti, A., Mwamanzi, N., Nemer, M., Oliver, N., Pezoa Rivera, R., Ravindran, B., Riza, H., Rugege, C., Seoighe, C., Sheehan, J., Sheikh, H., Wong, D., and Zeng, Y. International AI safety report. Technical Report DSIT 2025/001, 2025. URL https: //www.gov.uk/government/publications/ international-ai-safety-report-2025. Bertran, M. A., Tang, S., Kearns, M., Morgenstern, J. H., Roth, A., and Wu, S. Reconstruction attacks on machine unlearning: Simple models are vulnerable. In Proc. NeurIPS, 2024. Boyd, S. and Vandenberghe, L. Convex optimization. Cambridge university press, 2004. Brack, M., Friedrich, F., Hintersdorf, D., Struppek, L., Schramowski, P., and Kersting, K. SEGA: Instructing text-to-image models using semantic guidance. In Proc. NeurIPS, 2023. Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., Dafoe, A., Scharre, P., Zeitzoff, T., Filar, B., et al. The malicious use of artificial intelligence: Forecasting, prevention, and mitigation. arXiv preprint arXiv:1802.07228, 2018. Bubeck, S. Convex optimization: Algorithms and complexity. Foundations and Trends in Machine Learning, 2015. Cao, Y. and Yang, J. Towards making systems forget with machine unlearning. In IEEE symposium on security and privacy, 2015. Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: large-scale hierarchical image database. In Proc. CVPR, 2009. Ding, R., Zhou, T., Su, L., Ding, A. A., Xu, X., and Fei, Y. Probe-me-not: Protecting pre-trained encoders from malicious probing. In Proc. NDSS, 2025. Dosovitskiy, A. An image is worth 16x16 words: Transformers for image recognition at scale. In Proc. ICLR, 2021. Evans, D. J. The use of pre-conditioning in iterative methods for solving linear equations with symmetric positive definite matrices. IMA Journal of Applied Mathematics, 1968. Gandikota, R., Materzynska, J., Fiotto-Kaufman, J., and Bau, D. Erasing concepts from diffusion models. In Proc. ICCV, 2023. Gandikota, R., Orgad, H., Belinkov, Y., Materzynska, J., and Bau, D. Unified concept editing in diffusion models. In Proc. WACV, 2024. Gloub, G. H. and Van Loan, C. F. Matrix computations. Johns Hopkins Universtiy Press, 3rd edtion, 1996. Guille-Escuret, C., Girotti, M., Goujaud, B., and Mitliagkas, I. study of condition numbers for first-order optimization. In Proc. AISTATS, 2021. Guo, C., Goldstein, T., Hannun, A., and Van Der Maaten, L. Certified data removal from machine learning models. arXiv preprint arXiv:1911.03030, 2019. He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Proc. CVPR, 2016. Hestenes, M. R., Stiefel, E., et al. Methods of conjugate gradients for solving linear systems. NBS Washington, DC, 1952. Huang, T., Hu, S., Ilhan, F., Tekin, S. F., and Liu, L. Harmful fine-tuning attacks and defenses for large language models: survey. arXiv preprint arXiv:2409.18169, 2024. Jambulapati, A., Li, J., Musco, C., Sidford, A., and Tian, K. Fast and near-optimal diagonal preconditioning. arXiv preprint arXiv:2008.01722, 2020. Jambulapati, A., Li, J., Musco, C., Shiragur, K., Sidford, A., and Tian, K. Structured semidefinite programming for recovering structured preconditioners. In Proc. NeurIPS, 2023. Kim, S., Jung, S., Kim, B., Choi, M., Shin, J., and Lee, J. Towards safe self-distillation of internet-scale text-to-image arXiv preprint arXiv:2307.05977, diffusion models. 2023. Kingma, D. P. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. Krause, J., Stark, M., Deng, J., and Fei-Fei, L. 3d object representations for fine-grained categorization. In Proc. ICCV Workshops, 2013. Kress, R. Numerical analysis. Springer Science & Business Media, 2012. Kumari, N., Zhang, B., Wang, S.-Y., Shechtman, E., Zhang, R., and Zhu, J.-Y. Ablating concepts in text-to-image diffusion models. In Proc. ICCV, 2023. LeCun, Y. The MNIST database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998. Lewis, A. S. The convex analysis of unitarily invariant matrix functions. Journal of Convex Analysis, 1995. Model Immunization from Condition Number Perspective Luenberger, D. G., Ye, Y., et al. Linear and nonlinear programming, volume 2. Springer, 1984. Marchal, N., Xu, R., Elasmar, R., Gabriel, I., Goldberg, B., and Isaac, W. Generative AI misuse: taxonomy of tactics and insights from real-world data. arXiv preprint arXiv:2406.13843, 2024. Montoya, A. and DataCanary. House prices - advanced regression techniques, 2016. Kaggle. Mordukhovich, B. S. Variational analysis and applications. Springer, 2018. Neel, S., Roth, A., and Sharifi-Malvajerdi, S. Descent-todelete: Gradient-based methods for machine unlearning. In Proc. ALT, 2021. Nenov, R., Haider, D., and Balazs, P. (Almost) Smooth Sailing: Towards numerical stability of neural networks through differentiable regularization of the condition number. In ICML Differentiable Almost Everything Workshop, 2024. Nesterov, Y. Lectures on convex optimization, volume 137. Springer, 2018. Nguyen, Q. P., Low, B. K. H., and Jaillet, P. Variational bayesian unlearning. Proc. NeurIPS, 2020. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, high-performance deep learning library. In Proc. NeurIPS, 2019. Petersen, K. B., Pedersen, M. S., et al. The matrix cookbook. Technical University of Denmark, 7(15):510, 2008. Qu, Z., Gao, W., Hinder, O., Ye, Y., and Zhou, Z. Optimal diagonal preconditioning. Operations Research, 2024. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al. Learning transferable visual models from natural language supervision. In Proc. ICML, 2021. Rockafellar, R. Convex analysis. Princeton Mathematical Series, 28, 1970. Roeder, G., Wu, Y., and Duvenaud, D. K. Sticking the landing: Simple, lower-variance gradient estimators for variational inference. In Proc. NeurIPS, 2017. Saad, Y. Iterative methods for sparse linear systems. SIAM, 2003. Saratchandran, H., Wang, T. X., and Lucey, S. Weight conditioning for smooth optimization of neural networks. In Proc. ECCV, 2024. Savani, Y., Trockman, A., Feng, Z., Schwarzschild, A., Robey, A., Finzi, M., and Kolter, J. Z. Antidistillation sampling. arXiv preprint arXiv:2504.13146, 2025. Schramowski, P., Brack, M., Deiseroth, B., and Kersting, K. Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models. In Proc. CVPR, 2023. Sekhari, A., Acharya, J., Kamath, G., and Suresh, A. T. Remember what you want to forget: Algorithms for machine unlearning. In Proc. NeurIPS, 2021. Thomee, B., Shamma, D. A., Friedland, G., Elizalde, B., Ni, K., Poland, D., Borth, D., and Li, L.-J. YFCC100M: The new data in multimedia research. Communications of the ACM, 2016. Van der Sluis, A. Condition numbers and equilibration of matrices. Numerische Mathematik, 1969. Wightman, R. Pytorch image models. https://github. com/rwightman/pytorch-image-models, 2019. Wu, G., Hashemi, M., and Srinivasa, C. Puma: Performance unchanged model augmentation for training data removal. In Proc. AAAI, 2022. Xu, X., Yue, X., Liu, Y., Ye, Q., Hu, H., and Du, M. Unlearning isnt deletion: Investigating reversibility of machine unlearning in llms. arXiv preprint arXiv:2505.16831, 2025. Zhan, Q., Fang, R., Bindu, R., Gupta, A., Hashimoto, T., and Kang, D. Removing rlhf protections in gpt-4 via fine-tuning. In Proc. NAACL, 2024. Zhang, G., Wang, K., Xu, X., Wang, Z., and Shi, H. Forgetme-not: Learning to forget in text-to-image diffusion models. In Proc. CVPR, 2024. Zheng, A. Y. and Yeh, R. A. Imma: Immunizing textto-image models against malicious adaptation. In Proc. ECCV, 2024. Zheng, A. Y. and Yeh, R. A. Multi-concept model immunization through differentiable model merging. In Proc. AAAI, 2025. Zheng, A. Y., Yang, C.-A., and Yeh, R. A. Learning to obstruct few-shot image classification over restricted classes. In Proc. ECCV, 2024. Saarinen, S., Bramley, R., and Cybenko, G. Ill-conditioning in neural network training problems. SIAM Journal on Scientific Computing, 1993. Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., and He, Q. comprehensive survey on transfer learning. Proceedings of the IEEE, 2020. 11 Model Immunization from Condition Number Perspective Appendix The appendix is organized as follows: In Sec. A, we provide the complete statements of the properties of Rwell(S) for minimizing the condition number. In Sec. B, we provide the complete proof for the Theorems stated in the main paper. In Sec. C, we provide additional experiment details. The code will be open-sourced upon the acceptance of this paper. A. Properties of the Condition Number Minimizing Regularizer Theorem A.1 (Properties of κ-minimizing regularizer Rwell(S), Theorem 2.1, 2.2, 3.1, 3.2 in Nenov et al. (2024)). (1) [Nonnegativity] Rprpc, Rwell(S) 0. If = 0, Rwell(S) = 0 if and only if has full rank and κ(S) = 1. (2) [Upper Bound] κ(S) ep(σmin )2 from 0. Rwell(S), i.e., r(S) is an upper bound of log(κ(S)) as long as σmin is bounded away (3) [Differentiability] If σmax is given by SRwell(S) = σ1u1v = σ1 > σi for any > 1, i.e., σmax S. 1 1 is unique, then Rwell(S) is differentiable and its gradient (4) [Monotonic Decrease] If σmax is unique, update with SRwell(S) such that = η1SRwell(S) for 0 < η1 < κ(S)1 )κ(S)+ 1 (1 , then κ(S) < κ(S). B. Proof of Propositions and Theorems B.1. Proof of Proposition 3.2. Proposition 3.2. The singular values of the Hessian matrix in Eq. (9) are given by σi = Din(cid:88) j=1 (cid:0)σθ,i(u θ,iqj) (cid:1)2 , γj {1, . . . , Din}. (10) Here, σθ,i and uθ,i correspond to the i-th singular value and vector of θ. Next, γj and qj correspond to the j-th singular value and vector of the covariance K. Proof. Substitute the SVD of θ and the eigendecomposition of into θKθ: θKθ = (UθΣθV θ )(QΓ2Q)(UθΣθV θ ). Simplify the expression: Define = ΣθU θ QΓ, so that: The elements of are: θKθ = Vθ(ΣθU θ QΓ2QUθΣθ)V θ . θKθ = Vθ(MM )V θ . [i, j] = σθ,i(u θ,iqj)γj, where σθ,is for [d] are the singular values of θ, γjs for [d] are the diagonal entries of Γ, and (u alignment between the i-th column of Uθ and the j-th column of Q. θ,iqj) measures the 12 Model Immunization from Condition Number Perspective We observe the following decomposition of in to two matrices and D: . . . . . . . . . = = ... . . . . . . σθ,i(u θ,iqj)γj ... . . . . . . . . . ... σθ,i(u (σθ,i(u ... (cid:113)(cid:80) . . . = OD θ,iqj )γj θ,iqj )γj )2 . . . . . . . . . . . . 0 0 (cid:113)(cid:80) 0 j(σθ,i(u θ,iqjγj) 0 0 0 . . . where is an orthonormal matrix, i.e., OO = I, and = diag(d1, . . . , dd) with di = diagonal matrix. As result, diagonal entries of D2 are: d2 = (cid:88) j=1 (cid:0)σθ,i(u θ,iqj)γj (cid:1) . (cid:113)(cid:80) j(σθ,i(u θ,iqj)γj)2 is Thus, MM = (OD)(OD) = OD2O, and the eigenvalues of θKθ are the diagonal entries of D2, given by: σi = i = (cid:88) j=1 (cid:0)σθ,i(u θ,iqj)γj (cid:1) , = 1, . . . , d. B.2. Proof of Theorem 4.1 B.2.1. PROOF OF THEOREM 4.1 (1) Theorem 4.1. (1) For any Rprpc, Rill (S) 0, and Rill (S) = 0 if and only if κ (S) = . Proof. By definition, Rill(S) = 1 ill(S) , and 1 1 )2 . Denote 2 (σmin ill(S) = 1 1 2k S2 (cid:16) (σmin )2 1 F (cid:17) , then we have Rill (S) = ill(S) = (cid:32) σ2 1 2 (cid:33) 1 (cid:88) i= σ2 (cid:0)σ2 σ2 (cid:1) = 1 2k (cid:88) i=1 0, since [k], σmin = σk σi. As result, ill(S) 0 and Rill (S) = 1 ill(S) 0, i.e., Rill (S) is non-negative. 13 Model Immunization from Condition Number Perspective Also, by definition, σ1 = κ (S) σk. Therefore, Rill (S) = = = 1 (cid:80)k 1 σ )2 2 i=1 σ2 (σmin 2 )2 (σmin 1 + k1 (σmin 2 σ2 1 (σmin 2k (κ(S)2 1) (σmin )2(cid:17) )2 . 1 (cid:16) )2 If κ(S) = , Rill(S) Similarly, we have 2k (κ(S)21)(σmin )2 = 0 for σmin > 0, which yields Rill(S) = 0 given that Rill(S) 0. Rill (S) = 1 (cid:80)k )2 2 i=1 σ2 (σmin 2 )2 (σmin 1 + 1 (σmin 2 ) k1 σ2 (cid:16) σ2 1 (σmin )2(cid:17) k1 2k k1 (κ(S)2 1) (σmin )2 . = = If Rill(S) = 0, we have κ (S) (cid:114) 2k k1 Rill(S)(σmin )2 + 1 = which yields κ (S) = . B.2.2. PROOF OF THEOREM 4.1 (2) To prove Theorem 4.1 (2), we start by analyzing ill(S) = 1 2 (cid:16) Lemma B.1. For ill(S) = 1 2 (cid:16) (σmin )2 1 F (cid:17) , (σmin )2 1 F 1 κ(S) k1 σ2 1 ill(S) That is, ill(S) is an upper bound of log (cid:16) 1 (cid:17) κ(S) , i.e., log(κ(S)). Proof. Similar to the proof of Theorem 3.2 in (Nenov et al., 2024), (cid:17) with the following lemma. (19) 2R ill(S) = (cid:0)σmin (cid:1)2 = (cid:0)σmin (cid:1)2 1 1 S2 (cid:88) σ2 i=1 (cid:16) (cid:1)2 1 (cid:0)σmin (cid:18) = 1 (k 1)σ2 (cid:1)2(cid:17) 1 + (cid:0)σmin (cid:17) (cid:19) (cid:16)(cid:0)σmin (cid:1)2 σ2 1 1 14 Model Immunization from Condition Number Perspective In the meantime, 2 log (cid:18) 1 (cid:19) κ(S) (cid:1)2(cid:17) = log = log (cid:0)κ(S)2(cid:1) (cid:16)(cid:0)σmin (cid:16) 1 σ2 1 (cid:16)(cid:0)σmin 1 σ2 1 (cid:1)2 = 1 (cid:0)σmin σ2 (cid:17) σ2 1 (cid:1) log (cid:0)σ2 (cid:1)2(cid:17) 1 in which the inequality follows from the Mean Value Theorem. As result, 1 κ(S) 1 2σ2 1 (cid:16)(σmin )2 σ2 1 (cid:17) ( k1 2R ill(S)) 1 2σ2 1 k1 σ2 1 ill(S) = Theorem 4.1. (2) . 1 log(κ(S)) (σmax )2 Rill (S), i.e., Rill(S) upper bounds 1 log(κ(S)) when σmax is reasonably away from Proof. Taking the logarithm of Lemma B.1, we have Negating both sides, Finally, taking the reciprocal, log (κ (S)) 1 σ2 1 ill (S) . log (κ (S)) 1 σ2 1 ill (S) . 1 log (κ (S)) = 1 1 σ2 1 ill (κ (S)) σ2 1 )2 1 1 2 (σmin 2k S2 σ2 1Rill (S) B.2.3. PROOF OF THEOREM 4.1 (3) To analyze the differentiability of Rill(S) = (cid:17) 2k S2 , which needs the following lemma as prerequisite. 2 (σmin (cid:16) )2 1 S2 (σmin 1 2 Lemma B.2 (Theorem 3.1 in (Lewis, 1995) without Convexity). If function : Rp is absolutely symmetric, that is, Rp and any as permutation of x, (x) = (y), then σ is differentiable at matrix Rp1p2 if and only if is differentiable at σ = σ(S). In this case, for the singular value decomposition = Diag(σ)V , )2 , we start by analyzing the differentiability of ill(S) = 1 1 1 (f σ) (S) = Diag(f (σ))V . Model Immunization from Condition Number Perspective Proof. For the forward direction, by Corollary 2.5 in (Lewis, 1995), for = Diag(σ)V , (f σ) (S) = Diag(µ)V (cid:12) (cid:111) (cid:110) (cid:12) (cid:12)µ (σ) . By Theorem 25.1 in (Rockafellar, 1970), since σ is differentiable at matrix Rp1p2, we know that its subgradient (f σ) (S) is singleton, meaning that Diag(µ)V is unique, and consequently, µ (σ) is unique. As result, (σ) is also singleton, which, again by Corollary 2.5 in (Lewis, 1995), indicates that is differentiable at σ. The reverse direction holds true following similar argument. Lemma B.3. For = Diag(σ)V , in which σ = [σ1, , σk] such that σmax σk < σi for any < k, (σmin , ill(S) = 1 2 )2 1 S2 , i.e., is differentiable and for uk, vk as the kth column vector of , = σ1 σ2 > σk = σmin (cid:17) (cid:16) ill(S) = σmin ukv 1 S. (20) Proof. For Rk, denote ill,1(x) = min i[k] 1 2 , x2 ill,2(x) = 1 2k (cid:88) i=1 x2 . With 2 (σmin Proposition 4.9 in (Mordukhovich, 2018), we have for Rk, , we first analyze 1 ill(S) = 1 2 (σmin 2k S2 )2 1 )2. By the subdifferential of piecewise minimum given by (cid:40) xR ill,1(x) (cid:18) 1 2 x2 (cid:19) (cid:12) (cid:12) (cid:12)i arg min (cid:41) j[k] (cid:41) 1 2 x2 (cid:40) = xiei (cid:40) = xiei (cid:12) (cid:12) (cid:12)i arg min j[k] 1 2 (cid:12) (cid:12) (cid:12)i arg min j[k] xj x2 (cid:41) in which ei is the ith vector from the k-dimensional standard basis. Therefore, (cid:40) σR ill,1(σ) σiei (cid:41) (cid:12) (cid:12) (cid:12)i arg min j[k] σj σiei (cid:12) (cid:12) (cid:12)i arg minj[k] σj Since for any < k, σk < σi, i.e., the minimum non-zero singular value σmin (cid:110) (cid:111) is unique, we know that the subdifferential = {σmin } is singleton. Therefore, by Theorem 25.1 in (Rockafellar, 1970), we know ill,1 ek. Regarding σ = σ (S) as function of in which σ () is differentiable with respect to σ and σR represents taking the singular values of matrix, we have by Corollary 2.5 in (Lewis, 1995) (cid:1)2(cid:19) ill,1(σ) = σmin (cid:18) 1 2 (cid:0)σmin = S(R ill,1 σ)(S) Diag(µ)V (cid:12) (cid:110) (cid:12)µ σR (cid:12) = (cid:111) ill,1(σ) Given that 1 2 (σmin )2 is also differentiable and ill,1 is differentiable and apparently also absolutely symmetric with respect to σ, by Lemma B.2, we know (cid:18) 1 2 (cid:1)2(cid:19) (cid:0)σmin = Diag(σR ill,1(σ))V ep)V = Diag(σmin ukv = σmin . 16 Model Immunization from Condition Number Perspective In addition, we have (cid:18) 1 2k (cid:19) S2 = (cid:32) 1 2k (cid:33) (cid:88) σ (S)2 i=1 = Diag(µ)V (cid:12) (cid:110) (cid:12)µ σR (cid:12) ill,2(σ) (cid:111) by Corollary 2.5 in (Lewis, 1995). B.2, ill,2 is apparently differentiable with ill,2(x) = 1 x. Therefore, again by Lemma (cid:18) 1 2k (cid:19) S2 = Diag(R ill,2(σS))V = = 1 1 Diag (σS) S. ill(S) = (cid:18) 1 2 (cid:1)2(cid:19) (cid:0)σmin (cid:18) 1 2k (cid:19) S2 By the linearity of gradients, = σmin ukv 1 S, which completes the proof. Theorem 4.1. (3) If σmin = σk < σi for any < k, then Rill(S) is differentiable and SRill(S) = σkukv 1 2 (σmin )2(cid:17)2 . 2k S2 (cid:16) 1 Proof. Since Rill(S) = 1 )2 , we have 2 (σmin 1 2k S2 Rill (S) = = = (cid:16) 1 2k S2 1 (cid:16) 1 2k S2 (cid:16) 1 2 (σmin (cid:16) 1 2k S2 (cid:16) 1 2k S2 1 )2 )2(cid:17) 2 (σmin )2(cid:17)2 (cid:17) 2 (σmin 2k S2 )2(cid:17)2 1 2 (σmin ill (S) 1 )2(cid:17)2 2 (σmin By Lemma B.3, we know that if σmin Consequently, Rill(S) is differentiable and = σk < σi for any < k, ill (S) is differentiable and ill(S) = σmin ukv 1 S. Rill (S) = ukv σmin (cid:16) 1 2k S2 1 )2(cid:17)2 . 2 (σmin B.2.4. PROOF OF THEOREM 4.1 (4) Theorem 4.1. (4) (cid:16) 1 2k S2 1 k1 is unique, update with SRill(S) such that = η2SRill(S) for 0 < η2 < If σmin )2(cid:17)2 , then κ (S) > κ (S). 2 (σmin 17 Model Immunization from Condition Number Perspective Proof. Given that = η2Rill(S) and that Rill(S) = ill(S) = 1 (cid:16) 1 σ2 S2 (cid:17) , ukv σmin 2k S2 1 1 2 (σmin )2(cid:17)2 = (cid:16) 1 1 ill(S)2 (cid:0)σkukv 1 S(cid:1) for = η2Rill(S) (cid:18) = (cid:18) = 1 + (cid:18) = 1 + η2 ill(S)2 η2 ill(S)2 η2 ill(S)2 kR kR (cid:18) = 1 + η2 ill(S)2 = Diag(σS)V . kR σkukv (cid:19) (cid:19) 1 η2 ill(S)2 σkukv (cid:19) (cid:88) i=1 (cid:19) k1 (cid:88) i=1 σiuiv σiuiv + η2 ill(S)2 σkukv η2 ill(S)2 kR 1 + (cid:18) (cid:19) η2 ill(S)2 σkukv (cid:104)(cid:16) (cid:17) (cid:16) where σS = the singular values of but not necessarily in the decreasing order. σ1, , σk1, 1 + 1 + kR kR 1 + η2 ill(S)2 η2 ill(S)2 (cid:17) (cid:16) η2 ill(S)2 η2 ill(S)2 kR (cid:105) (cid:17) σk is the vector formed by (cid:16) (cid:17) η2 ill(S) 1 + Now we argue that kR the minimum. Since σk < σi for any < k, i.e., σmin (cid:16) 1 = kR 2k S2 Also, given that η2 < 1 k1 (cid:18) 2 σ2 (cid:17)2 σ1 remains to be the maximum singular value while σk = σk is unique, we must have 0 < β < 1 such that σk = βσk1. ill(S)2 η2 ill(S)2 1 + kR η2 (cid:16) (cid:17) ill(S)2 k1 , we have 1 + η ill(S)2 η2 ill(S)2 > 0. Therefore, kR (cid:19) σk η2 ill(S) (cid:19) 1 + ill(S)2 σk η2 ill(S)2 η2 kR η2 1 + kR ill(S)2 η2 ill(S)2 η2 ill(S) 1 + kR (cid:33) σk (cid:19) (cid:32) 1 (cid:19) σk kR 1 + (cid:18) = 1 + (cid:18) = 1 + (cid:18) < 1 + (cid:18) < 1 + (cid:18) = 1 + η2 ill(S)2 η2 ill(S)2 kR η2 ill(S)2 η2 ill(S)2 η2 ill(S)2 η2 ill(S)2 kR kR kR kR σk (cid:19) 1 β (cid:19) σk1. η2 ill(S)2 > 0, we know that σmax = kR (cid:16) 1 + η2 ill(S)2 kR (cid:17) σ1 and Since σ1 σ2(S) σk1 > σk and 1 + σmin = (cid:16) 1 + η2 ill(S)2 η2 ill(S)2 kR (cid:17) σk. Finally, κ (S) = = = σmax σmin (cid:16) 1 + (cid:16) (cid:17) 1 + kR η2 σ1 ill(S)2 ill(S)2 η2 ill(S)2 η kR (cid:17) σk kR η2 1 + ill(S)2 ill(S)2 η2 η2 kR ill(S)2 1 + κ (S) > κ (S) . Model Immunization from Condition Number Perspective B.3. Proof of Theorem 4.2 Theorem 4.2. For (θ) = θKθ, if its maximum and minimum singular values σ1 and σk are unique, then (cid:17) (cid:16) (1) θRwell (H (θ)) = 2Kθ σ1v1v θKθ , (2) θRill (H (θ)) = 1 1 Din θKθ) k)2 . 2 σ2 2Kθ(σkvkv ( 1 2k θKθ2 1 Proof. Given that (θ) = θKθ for = X, we know (θ) is symmetric and positive semidefinite. Therefore, for compact SVD (θ) = Diag (σ) , we have = . (1) When the maximum singular value σ1 of is unique, we know from Theorem A.1 (3) that Rwell (H (θ)) is = σ1v1v differentiable with respect to H, and Rwell (H (θ)) = σ1u1v Given the form (θ) = θKθ, we have dH = (dθ) Kθ + θK (dθ). Furthermore, 1 1 Din 1 1 Din H. (dRwell) (H (θ)) = Rwell (H (θ)) , dHF (cid:32)(cid:18) = Tr σ1v1v 1 1 Din (cid:19) (cid:16) (cid:17) (dθ) Kθ + θK (dθ) (cid:33) (cid:32)(cid:18) = Tr σ1v1v 1 (cid:19) 1 Din (cid:33) (dθ) Kθ + Tr (cid:32)(cid:18) σ1v1v 1 (cid:19) 1 Din (cid:33) θK (dθ) (cid:32) (cid:18) = Tr Kθ σ1v1v 1 (cid:19) 1 Din (cid:33) (cid:32) (dθ) + Tr (dθ) (cid:18) σ1v1v 1 (cid:19) (cid:33) θK , 1 Din in which , denotes the Frobenius inner product, and that last equality follows from the cyclic property of trace. As result, following the derivatives of traces as in Eq. (100) and Eq. (104) in Petersen et al. (2008), θRwell(H (θ)) = Rwell(H (θ)) θ = Kθ (cid:18) σ1v1v 1 (cid:19) (cid:32)(cid:18) + 1 Din σ1v1v 1 (cid:33) (cid:19) 1 Din θK (cid:18) = Kθ σ (cid:0)v1v 1 (cid:1) (cid:19) + Kθ (cid:18) σ1v1v 1 (cid:19) 1 Din (cid:18) = 2Kθ σ1v1v 1 1 Din (cid:19) . 1 Din (2) When the minimum singular value σk of is unique, we know from Theorem 4.1 (3) that Rill (H (θ)) is differentiable k)2 . Following similar arguments as in (1), we have 2 σ2 1 with respect to H, and Rill (H (θ)) = σkukv ( 1 2k H2 2Kθ(σkukv ( 1 2k H2 1 θRill (H (θ)) = H) k)2 . 1 2 σ2 B.4. Proof of Theorem 4.3 Theorem 4.3. For the trainable feature extractor θ, feature covariance HP (θ) = θKPθ of the primary task and HH (θ) = θKHθ of the immunization task with rank (HP) = kP, rank (HH) = kH and compact SVD HP (θ) = UPDiag(σP)V , HH (θ) = UHDiag(σH)V (1) if σmax HP (cid:26) , for σP = [σP,1, , σP,kP], σH = [σH,1, , σH,kH], i.e., σmax HP σP,1σP,2σP,2 σ2 = σP,1 > σP,2, update θ such that θ = θ ηPK1 θRwell(HP (θ)) for 0 < ηP < < κ (cid:0)θKPθ(cid:1), θKPθ(cid:17) (cid:16) is unique, , then κ min (cid:27) , 1 Din )σP,1 (1 1 2 Din P,2 19 Model Immunization from Condition Number Perspective (2) if σmin HH 1 12σmin HH Proof. = σH,kH < σH,kH1, update θ such that θ = θ ηHK1 is unique, i.e., σmin HH θKHθ(cid:17) (cid:13)θKHθ(cid:13) (cid:13) 2 1 (cid:13) (cid:0)σmin HH (cid:16) 1 2kH , then κ (cid:1)2(cid:17)2 (cid:16) /kH 2 > κ (cid:0)θKHθ(cid:1). (cid:16) (1) By Theorem 4.2 (1), we know θRwell (HP (θ)) = 2KPθ θRwell(HP (θ)), we have ηPK1 θKPθ = (cid:0)θ ηPK1 (cid:18) θRwell(HP (θ))(cid:1) (cid:18) KP = θ 2ηPK1 KPθ σP,1vP,1v P,1 (cid:0)θ ηPK1 (cid:19)(cid:19) 1 Din (cid:19)(cid:19) HP (cid:18) θRill(HH (θ)) for 0 < ηH < σP,1vP,1v P,1 1 Din (cid:17) HP . Since θ = θ θRwell(HP (θ))(cid:1) KP (cid:18) θ 2ηPK1 KPθ (cid:18) σP,1vP,1v P,1 (cid:19)(cid:19)"
        },
        {
            "title": "1\nDin",
            "content": "HP (cid:18) (cid:18) = θ 2ηPθ σP,1vP,1v P,"
        },
        {
            "title": "1\nDin",
            "content": "HP = θKPθ 2ηP (cid:18) σP,1vP,1v P,1 KP θ 2ηPθ (cid:18) σP,1vP,1v P,1 (cid:19)(cid:19)"
        },
        {
            "title": "1\nDin",
            "content": "HP (cid:19) HP θKPθ 2ηPθKPθ (cid:18) σP,1vP,1vP,1 (cid:19)"
        },
        {
            "title": "1\nDin",
            "content": "HP (cid:18) + 4η2 σP,1vP,1v P,"
        },
        {
            "title": "1\nDin",
            "content": "= HP 2ηP (cid:18) σP,1vP,1v P,1 HP 1 Din θKPθ (cid:18) σP,1vP,1vP,1 (cid:19)"
        },
        {
            "title": "1\nDin",
            "content": "HP (cid:19) (cid:18) HP HP 2ηPHP σP,1vP,1vP,1 (cid:19) 1 Din HP"
        },
        {
            "title": "1\nDin\n(cid:19)⊤",
            "content": "(cid:18) + 4η2 σP,1vP,1v P,1 1 Din (cid:19) (cid:18) HP HP σP,1vP,1vP,1 (cid:19) HP . 1 Din Since HP (θ) = θKPθ for KP = UPDiag (σP) , it holds that UP = VP. Furthermore, XP is symmetric and positive semidefinite, we know for HP (θ) = σP,1vP,1v P,1 1 Din HP = σP,1vP,1v P,1 1 Din kP(cid:88) i=1 σP,iuP,iv P,i σP,1uP,1v P,1 (cid:18) (cid:19) = 1 1 Din = UPDiag ( σP) = VPDiag ( σP) 1 Din kP(cid:88) i= σP,iuP,iv P,i for Diag ( σP) = (cid:104)(cid:16) (cid:17) 1 1 Din σP,1, 1 Din σP,2, , 1 Din σP,kP (cid:105) . Therefore, plugging this and the SVD of HP back in, θKPθ = VPDiag (σP) 2ηP (cid:0)VPDiag (σP) (cid:0)VPDiag ( σP) 2ηP + 4η2 (cid:0)VPDiag ( σP) (cid:1) (cid:1) VPDiag (σP) VPDiag ( σP) VPDiag ( σP) VPDiag (σP) (cid:1) = VPDiag (σP) 2ηPVPDiag ( σP) Diag (σP) 2ηPVPDiag (σP) Diag ( σP) + 4η2 VPDiag ( σP) Diag (σP) Diag ( σP) = VPDiag (σP) 2ηPVPDiag ( σP σP) 2ηPVPDiag (σP σP) + 4η2 VPDiag ( σP σP σP) = VPDiag (cid:0)σP 4ηP σP σP + 4η2 σP σP σP P) = VPDiag (σ , (cid:1) in which σ = (cid:104) P,1, , σ σ P,kP (cid:105) for σ P,i = notes element-wise product and the second equality holds by the fact that VP is orthonormal, i.e., (cid:16) σP,1 4ηP σP,i + 4ηP Din 1 1 Din P,i + 4η2 σ D2 in σ3 P,i (cid:17) P,1 + 4η2 σ2 (cid:16) 1 1 Din (cid:17)2 σ3 P,1 if = 1 , deif > 1 VP = I. 20 Model Immunization from Condition Number Perspective Since σmax HP is unique, we know that α > 1 such that σP,1 = ασP,2. Therefore, σ P,2 = σP,2 + σ2 P,2 + 4ηP Din 4ηP Din σP,2 + 4η2 D2 in α σP,2 + 4η2 D2 in 4η2 D2 in σ2 P,2 (cid:18) = 1 + 1 + 4ηP Din = σ3 P,2 (cid:19) σP, σ2 P,2 σP,1. With ηP < result, that is, σP,1σP,2σP,2 σ 2 Din P,2 , we have 1 + 4ηP Din σP,2 + 4η2 D2 in σ2 P,2 < 1 4ηP (cid:16) 1 1 Din (cid:17) σP,1 + 4η2 (cid:16) 1 1 Din (cid:17) σ2 P,1. As σP,2 + 4η2 D2 in 1 + 4ηP Din (cid:17) 1 1 Din σP,1 + 4η2 P, σ2 (cid:16) 1 1 Din < 1 < α, (cid:17)2 σ2 P, (cid:16) 1 4ηP 1 + 4ηP Din σP,2 + 4η2 D2 in α σ2 P, (cid:18) < 1 4ηP 1 (cid:19) 1 Din σP,1 + 4η2 (cid:18) 1 (cid:19)2 1 Din σ2 P,1. Plugging this result back in, 1 + 4ηP Din σ P,2 = (cid:32) σP,2 + 4η2 D2 in α (cid:18) σ2 P, σP,1 (cid:19) σP,1 + 4η2 (cid:18) 1 (cid:19) 1 Din (cid:33) σ2 P,1 σP,1 1 Din < 1 4ηP 1 = σ P,1. P,2 σP,i + 4ηP P,2 = σP,2 + 4ηP σ3 In addition, σ Din Din P,1 remains to be the maximum singular value of θKPθ, and σ for = 3, , kP by definition. Therefore, σ minimum. Finally, P,i for = 3, , kP since σP,2 σP,i the P,i = σ σ3 D2 in D2 in P,kP P,2 + 4η2 σ2 P,i + 4η2 σ (cid:16) θKPθ(cid:17) κ = P,1 σ σ P,kP (cid:16) 1 1 Din (cid:17) σP,kP + 4ηP Din (cid:17) (cid:16) 1 1 Din = < < σP,1 4ηP σP,1 4ηP σP,1 σP,kP = κ (cid:0)θKPθ(cid:1) (cid:16) 1 1 Din (cid:17)2 σ3 P, 1 1 Din (cid:17)2 σ3 P,1 σ3 P,kP P,1 + 4η2 σ2 + 4η2 D2 in (cid:16) σ2 P,kP P,1 + 4η2 σ2 σP,kP where the second inequality holds when ηP < (cid:16) 4η2 1 1 Din (cid:17)2 σ3 P,1 < 0. 1 Din )σP,1 (1 1 which indicates that 4ηP (cid:16) 1 1 Din (cid:17) σ2 P,1 + 21 then by Theorem 4.2 (2), we know θRill (HH (θ)) = Model Immunization from Condition Number Perspective (2) Denote ill (HH) = 1 HH) 1 kH H,kH HH2 1 2 σ2 , 2kH . Since θ = θ ηHK1 2KHθ(σH,kH uH,kH H,kH ill(HH)2 θKHθ = (cid:0)θ ηHK = θKHθ (cid:18) 2ηH ill (HH)2 σH,kH uH,kH H,kH θRill(HH (θ)), we have θRill(HH (θ))(cid:1) KH θRill(HH (θ))(cid:1) (cid:0)θ ηHK1 (cid:19) HH θKHθ 1 kH (cid:19) + = HH + (cid:18) 4η2 ill (HH)4 2ηH ill (HH)2 (cid:18) 4η2 ill (HH)4 σH,kHuH,kH H,kH 1 kH HH θKHθ (cid:18) σH,kHuH,kH H,kH (cid:19) HH 1 kH (cid:18) (cid:18) σH,kHuH,kH H,kH (cid:19) HH HH 1 kH 2ηH ill (HH)2 HH σH,kHuH,kH H,kH (cid:19) 1 kH HH σH,kHuH,kH H,kH (cid:19) (cid:18) HH HH 1 kH σH,kH uH,kHv H,kH (cid:19) HH . 1 kH 2ηH ill (HH)2 θKHθ (cid:18) σH,kH uH,kHv H,kH (cid:19) 1 kH HH Since HP (θ) = θKHθ for KH = UHDiag (σH) , it holds that UH = VH. Following similar arguments as in (1), XH is also symmetric and positive semidefinite, we know for HH (θ) = σH,kHuH,kH H,kH 1 kH HH = 1 kH kH1 (cid:88) σH,iuH,iv H,i + (cid:18) 1 (cid:19) σH,kH uH,kH H,kH 1 kH i=1 = VHDiag ( σH) (cid:105) (cid:17) (cid:16) . Since VH is orthonormal, i.e., σH,kH 1 1 kH VH = I, for Diag ( σH) = (cid:104) 1 kH σH,1, , 1 kH σH,kH1, θKHθ = VHDiag (σH) (cid:0)VHDiag ( σH) (cid:1) VHDiag (σH) 2ηH ill (HH)2 (cid:0)VHDiag (σH) (cid:1) VHDiag ( σP) (cid:0)VHDiag ( σH) (cid:1) VHDiag (σH) VHDiag ( σH) 4ηH ill (HH)2 σH σH + 4η2 ill (HH)4 σH σH σH (cid:33) + 2ηH ill (HH)2 4η2 ill (HH)4 (cid:32) R = VHDiag σH = VHDiag (σ H) , σH,i + σH,kH kHR 4ηH ill(HH)2 σ2 (cid:16) 4ηH ill(HH)2 H,i + 1 1 kH 4η2 ill(HH)4 σ3 k2 (cid:17) σ2 H,i + 4η2 H,kH ill(HH)4 (cid:16) 1 1 kH (cid:17)2 σ H,kH if < kH if = kH , for σ = (cid:104) H,1, , σ σ H,kH (cid:105) , σ H,i = and denotes element-wise product. Since σmin HH σ H,kH = σH,kH 1 σ2 H,kH + is unique, we know that β (0, 1) such that σH,kH = βσH,kH1. Then we have (cid:19) 1 kH (cid:19) 1 kH 1 σH,kH + 1 (cid:19) 1 kH σH,kH + 4η2 ill (HH)4 (cid:18) 4η2 ill (HH)4 4η2 ill (HH)4 (cid:18) R (cid:19)2 1 kH (cid:19)2 (cid:18) 1 1 1 kH 1 (cid:19)2 1 kH σ3 H,kH σ2 H,kH (cid:33) (cid:33) σH,kH σ2 H,kH βσH,kH (cid:18) 4ηH ill (HH)2 (cid:18) 4ηH ill (HH)2 4ηH ill (HH)2 4ηHσH,kH ill (HH)2 + (cid:18) R kHR (cid:32) = 1 (cid:32) = 1 (cid:32) = 1 + 4η2 σ2 ill (HH)4 k2 H,kH 4ηHσH,kH ill (HH)2 + H,kH 4η2 σ2 ill (HH)4 8η2 σ2 H,kH ill (HH)4 kHR (cid:33) βσH,kH1. 22 Model Immunization from Condition Number Perspective Letting 0 < ηH < ill(HH)2 12σH,kH /kH = 12σmin HH /kH (cid:16) 1 2kH (cid:13)θKHθ(cid:13) (cid:13) 2 1 (cid:13) 2 (cid:0)σmin HH (cid:1)2(cid:17)2 , we have 4ηHσH,kH ill (HH)2 + H,kH 4η2 σ2 ill (HH)4 8η2 σ2 ill (HH)4 < 0. kHR H,kH (21) 4η2 1 1 Also, 1 ill(HH)4 kH ηH > 0. Given that σH,kH1 > σH,kH and Eq. (21), 4ηH ill(HH)2 σH,kH + R (cid:16) (cid:17) (cid:16) 1 1 kH (cid:17)2 σ2 H,kH = (cid:16) 1 2ηH ill(HH)2 (cid:16) 1 1 kH (cid:17) σH,kH (cid:17)2 > 0 for any β < 1 1 + < < (cid:16) kHR 1 + 4ηH ill(HH)2 σH,kH1 + 4ηH ill(HH)2 σH,kH + 1 + kHR k R k2 4η2 H,kH1 4η2 ill(HH)4 σ2 ill(HH)4 σ2 4ηH ill(HH)2 σH,kH1 + H,kH 4ηH H,kH kHR ill(HH)4 σ2 4η2 1 + 4ηH ill(HH)2 σH,kH + H k2 indicating 1 + kHR kHR 4ηH ill(HH)2 σH,kH1 + (cid:32) 4ηH ill(HH)2 σH,kH + 4η2 ill(HH)4 σ2 H k2 4η2 ill(HH)4 σ2 H,kH k2 H,kH1. Therefore, σ H,kH = 1 + (cid:32) < 1 + H,kH 4ηHσH,kH ill (HH)2 + 4ηH ill (HH)2 σH,kH1 + σ2 4η2 ill (HH)4 k2 4η2 ill (HH)4 σ2 R k2 kHR kHR 4ηHσH,kH ill (HH)2 + H,kH (cid:33) σH,kH1 4η2 ill(HH)4 σ2 R k2 ill(HH)2 σH,kH + 4η2 ill(HH)2 σH,kH + 4η2 4ηH R H,kH1 ill(HH)4 σ2 H,kH ill(HH)4 σ H,kH 8η2 ill(HH)4 σ2 H,kH kHR 8η2 ill(HH)4 σ2 H,kH kHR , (cid:17) β < 1 + H,kH σ2 4η2 ill (HH)4 σ2 8η2 H,kH ill (HH)4 kHR (cid:33) βσH,kH = σ H,kH1. H,kH1 = σH,kH1+ In addition, σ H,i+ k2 σ H,i for = 1, , kH 2 since σH,kH1 σH,i for = 2, , kH 1 by definition. That is to say, σ H,kH the minimum singular value of θKHθ, and σ H,1 the maximum. Finally, H,kH1 σH,i+ ill(HH)2 σ2 ill(HH)2 σ2 H,kH1+ k2 kHR kHR 4ηH 4ηH 4η2 ill(HH)4 σ3 4η2 ill(HH)4 σ3 H,i = remains to be (cid:16) κ = = > > θKHθ(cid:17) σ σ H, H,kH (cid:16) kHR 4ηH ill(HH)2 σH,kH + 4ηH ill(HH)2 σH,1 + 4ηH ill(HH)2 σH,kH + kHR kHR (cid:16) 1 + (cid:16) 1 + (cid:16) 1 + σH,1 σH,kH 1 + 4η2 kHR ill(HH)4 σ2 4η2 ill(HH)4 σ2 ill(HH)4 σ2 4η2 R k2 k2 k (cid:17) H,1 σH,1 (cid:17) σH,kH H,kH 4ηH ill(HH)2 σH,1 + 4ηH 4η2 ill(HH)4 σ2 R k2 ill(HH)2 σH,kH + 4η2 H,kH H,1 R (cid:17) σH,1 ill(HH)4 σ2 H,kH 8η2 ill(HH)4 σ2 H,kH kHR (cid:17) σH,kH = κ (cid:0)θKHθ(cid:1) where the first inequality holds by Eq. (21) and the second by σH,1 > σH,kH. 23 Model Immunization from Condition Number Perspective C. Detailed Experiment Setup C.1. Datasets Stanford Cars (Krause et al., 2013) contains 16,185 images of 196 car models and focuses on fine-grained image classification. Country211 (Radford et al., 2021) is dataset used for country classification based on satellite images, comprising 211 country-level labels, each with 150 training images. This is subset of the YFCC100M dataset (Thomee et al., 2016) providing user-generated photos and videos, used for domain adaptation evaluation. C.2. Immunization training details We summarize the hyper-parameters of training for model immunization in Tab. 4. We choose λP and λH by balancing the gradient norm of Rwell and Rill. Specifically, we obtain the scale of λP and λH first and search over multiples of {1, 2, 3, 5}. For linear models, we search over the set of {0.0005, 0.001, 0.005, 0.01} and report the best result. For ImageNet we followed the default learning rate η = 1 105. The number of epochs is based on early stopping using RIR and the test accuracy. All experiments are conducted using float64 precision to ensure numerical stability and reduce potential inaccuracies in computations. Table 4. Hyperparameters for immunization training."
        },
        {
            "title": "Model\nLinear\nLinear",
            "content": "Dataset HousePrice MNIST ImageNet vs. Stanford Cars ResNet18 ImageNet vs. Country211 ResNet18 ImageNet vs. Stanford Cars ViT ViT ImageNet vs. Country211 η 0.005 0.001 1 105 1 105 1 105 1 105 λP 100 1 5 105 1 104 3 106 1 106 λH 1 107 5 107 2 106 2 106 3 108 1 108 Epochs 1000 30 3 3 2 2 Mean squared error Binary Cross-entropy (CE) Label-smoothing CE Label-smoothing CE Label-smoothing CE Label-smoothing CE Details of immunizing linear models. For the regression task, the linear feature extractor θ R7979 is randomly initialized dummy linear layer, as discussed in Sec. 4.4. We handle missing values in the tabular data by filling NaNs with 0. Categorical features are converted into numerical values using LabelEncoder. Finally, the features and labels are normalized using their respective mean and standard deviation. To create DP and DH, we split the House prices dataset (Montoya & DataCanary, 2016) by the feature MSZoning. Specifically, all entries where MSZoning = RL are assigned to DH, while the remaining entries form DP. For the binary classification task on MNIST, the linear feature extractor θ R784784 is also randomly initialized dummy linear layer, and we construct training dataset by selecting two specific target digits. The dataset is created using custom BinaryDataset class, which filters the original MNIST dataset to include only the chosen digits and assigns new labels: one digit is mapped to label 0 and the other to label 1. To ensure balance in the dataset, we limit the number of samples for each digit to the smaller count between the two. For optimization, we use Adam (Kingma, 2014) with β = (.9, 0.999) and ϵ = 1 108 instead of the basic gradient descent in Alg. 1. For the linear model, we computed the Hessian inverse by solving regularized least-squares system, where the Hessian is in the shape of RDinDin. Here Din = 79 for the regression task and Din = 784 for the image classification task. Details of immunizing non-linear models. The pre-trained ResNet18 and ViT are loaded from Pytorch Image Models (Wightman, 2019) with the model name resnet18 and vit base patch16 clip 224. We also create the dataset with the built-in function create dataset from Wightman (2019). The feature embedding sizes for ResNet18 and ViT are 512 and 768, respectively. To facilitate balanced training when dataset sizes differ, we implement CombinedLoader, which pairs batches from two data loaders. The longer dataset dictates training duration, while the shorter dataset cycles continuously using itertools. The number of epochs reported in Tab. 4 corresponds to the epochs of DH, i.e., the shorter loader. For optimization, we use SGD with Nesterov momentum to optimize Eq. (11), setting an initial learning rate of 1 105 with momentum 0.9. The trainable feature extractor parameters are optimized with zero weight decay, while the classifier parameters use weight decay of 2 105. 24 Model Immunization from Condition Number Perspective C.3. Pseudo-code of the dummy layer We provide the Pseudo-code for implementing the dummy layer in Fig. 4 below. The DummyLinear layer extends torch.nn.Linear and incorporates an optional preconditioning mechanism in the backward pass using the inverse feature covariance matrix. The LinearFunction class defines the forward and backward computations, where the forward pass applies standard linear transformation XW + and stores the input, weight, and bias for gradient computation. In the backward pass, the input gradient is computed normally, while the weight gradient is modified based on whether preconditioning is enabled (use precond=True). If enabled, the weight gradient is adjusted by solving regularized least-squares system using the inverse of the feature covariance matrix + ϵI, improving numerical stability. class LinearFunction: @staticmethod def forward(ctx, input, weight, bias, lambda_reg, use_precond): ctx.save_for_backward(input, weight, bias) ctx.lambda_reg = lambda_reg ctx.use_precond = use_precond output = input.mm(weight.t()) if bias is not None: output += bias.unsqueeze(0).expand_as(output) return output @staticmethod def backward(ctx, grad_output): input, weight, bias = ctx.saved_tensors lambda_reg = ctx.lambda_reg use_precond = ctx.use_precond grad_input = grad_weight = grad_bias = None if ctx.needs_input_grad[0]: grad_input = grad_output.mm(weight) if ctx.needs_input_grad[1]: base_grad_weight = grad_output.t().mm(input) if use_precond: XtX = input.t().mm(input) lambda_eye = lambda_reg * torch.eye(XtX.size(0), device=XtX.device) XtX_reg = XtX + lambda_eye grad_weight = torch.linalg.solve(XtX_reg, base_grad_weight) else: grad_weight = base_grad_weight if bias is not None and ctx.needs_input_grad[2]: grad_bias = grad_output.sum(0) return grad_input, grad_weight, grad_bias, None, None class DummyLinear(nn.Linear): def forward(self, input, lambda_reg, use_precond): return LinearFunction.apply(input, self.weight, self.bias, lambda_reg, use_precond) Figure 4. Dummy layer with selective inverse feature covariance matrix in backward function."
        }
    ],
    "affiliations": [
        "Department of Computer Science, Purdue University"
    ]
}