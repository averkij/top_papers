{
    "paper_title": "MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents",
    "authors": [
        "Dongming Jiang",
        "Yi Li",
        "Guanpeng Li",
        "Bingzhe Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, a multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems in long-horizon reasoning tasks."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 6 ] . [ 1 6 3 2 3 0 . 1 0 6 2 : r MAGMA: Multi-Graph based Agentic Memory Architecture for AI Agents Dongming Jiangα, Yi Liα, Guanpeng Liβ and Bingzhe Liα αUniversity of Texas at Dallas βUniversity of Florida {dongming.jiang, yi.li3, bingzhe.li}@utdallas.edu; liguanpeng@ufl.edu"
        },
        {
            "title": "Abstract",
            "content": "Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-theart agentic memory systems in long-horizon reasoning tasks."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) have demonstrated remarkable capabilities across wide range of tasks (Brown et al., 2020; Achiam et al., 2023; Wei et al., 2022), yet they remain limited in their ability to maintain and reason over long-term context. These models process information within finite attention window, and their internal representations do not persist across interactions, causing earlier details to be forgotten once they fall outside the active context (Brown et al., 2020; Beltagy et al., 2020a). Even within single long sequence, attention effectiveness degrades with distance due to attention dilution, positional encoding limitations, and token interference, leading to the well-known lost-in-the-middle and context-decay phenomena (Liu et al., 2024; Press et al., 2021a). Moreover, LLMs lack native mechanisms for stable and structured memory, resulting in inconsistent recall, degraded long-horizon reasoning, and limited support for tasks requiring persistent and organized memory (Khandelwal et al., 2018; Maharana et al., 2024). To address these inherent limitations, MemoryAugmented Generation (MAG) systems have emerged as promising direction for enabling LLMs to operate beyond the boundaries of their fixed context windows. MAG equips an agent with an external memory continuously recording interaction histories and allowing the agents to retrieve and reintegrate past experiences when generating new responses. By offloading long-term context to an explicit memory module, MAG systems provide means for agents to accumulate knowledge over time, support multi-session coherence, and adapt to evolving conversational or task contexts. In this paradigm, memory is no longer implicit in internal activations but becomes persistent, queryable resource that substantially enhances long-horizon reasoning, personalized behavior, and stable agent identity. Despite their promise, current MAG systems exhibit structural and operational limitations that constrain their effectiveness in long-term reasoning (Li et al., 2025; Chhikara et al., 2025; Xu et al., 2025; Packer et al., 2023; Rasmussen et al., 2025; Wang and Chen, 2025; Kang et al., 2025a). Most existing approaches store past interactions in monolithic repositories or minimally structured memory buffers, relying primarily on semantic similarity, recency, or heuristic scoring to retrieve relevant content. For example, A-Mem (Xu et al., 2025) organizes past interactions into Zettelkasten-like memory units that are incrementally linked and refined, yet their retrieval pipelines rely primarily on semantic embedding similarity, missing the relations such as temporal or causal relationships. Cognitiveinspired frameworks like Nemori (Nan et al., 2025) introduce principled episodic segmentation and representation alignment, enabling agents to detect event boundaries and construct higher-level semantic summaries. However, their memory structures are still narrative and undifferentiated, with no explicit modeling of distinct relational dimensions. To address the structural limitations of existing MAG systems, we propose MAGMA, multigraph agentic memory architecture that explicitly models heterogeneous relational structure in an agents experience. MAGMA represents each memory item across four orthogonal relational graphs (i.e., semantic, temporal, causal, and entity), yielding disentangled representation of how events, concepts, and participants are related. Built on this unified multi-graph substrate, MAGMA introduces hierarchical, intent-aware query mechanism that selects relevant relational views, traverses them independently, and fuses the resulting subgraphs into compact, type-aligned context for generation. By decoupling memory representation from retrieval logic, MAGMA enables transparent reasoning paths, fine-grained control over memory selection, and improved alignment between query intent and retrieved evidence. This relational formulation provides principled and extensible foundation for agentic memory, improving both long-term coherence and interpretability. Our contributions are summarized as follows: 1. We propose MAGMA, multi-graph agentic memory architecture that explicitly models semantic, temporal, causal, and entity relations essential for long-horizon reasoning. 2. We introduce an Adaptive Traversal Policy that routes retrieval based on query intent, enabling efficient pruning of irrelevant graph regions and achieving lower latency and reduced token usage. 3. We design dual-stream memory evolution mechanism that decouples latency-sensitive event ingestion from asynchronous structural consolidation, preserving responsiveness while refining relational structure. 4. We demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems on long-context benchmarks including LoCoMo and LongMemEval, while reducing retrieval latency and token consumption relative to prior systems. The code is open-sourced1. 1https://github.com/FredJiang0324/MAMGA Figure 1: High-Level Architecture of MemoryAugmented Generation (MAG)."
        },
        {
            "title": "2 Background",
            "content": "Existing Large Language Models (LLMs) face fundamental challenges in handling long-term agentic interactions. These challenges stem from the inherent limitations of fixed-length contexts, which result in fragmented memory and an inability to maintain narrative coherence over time. The evolution of long-term consistency in LLMs is shifted from Context-Window Extension (Beltagy et al., 2020a; Press et al., 2021a; Kang et al., 2025c; Qian et al., 2025), Retrieval-Augmented Generation (RAG) (Lewis et al., 2020; Jiang et al., 2025; Wang et al., 2024; Jiang et al., 2024; Gutiérrez et al., 2025; Lin et al., 2025) to Memory-Augmented Generation (MAG). Retrieval-oriented approaches enrich the model with an external, dynamic memory library, giving rise to the paradigm of Memory-Augmented Generation (MAG) (Zhong et al., 2024; Park et al., 2023; Huang et al., 2024). Formally, unlike static RAG, MAG maintains time-variant memory Mt that evolves via feedback loop: ot = LLM(qt, Retrieve(qt, Mt)) Mt+1 = Update(Mt, qt, ot) (1) (2) As shown in Figure 1, this feedback loop enables the memory module to evolve over time: the user query is combined with retrieved information to form an augmented prompt, and the models output is subsequently written back to refine Mt. Some prior schemes focused on structuring the intermediate states or relationships of memory to enable better reasoning. Think-in-Memory (TiM) (Liu et al., 2023) stores evolving chains-of-thought to maintain consistency. A-MEM (Xu et al., 2025) draws inspiration from the Zettelkasten method, organizing knowledge into an interconnected note Figure 2: Architectural Overview of MAGMA. The system is composed of three layers: (1) Query Process that routes and synthesizes context; (2) Data Structure Layer organizing memory into Relation Graphs and Vector Database; and (3) Write/Update Process utilizing dual-stream mechanism for fast ingestion and asynchronous consolidation. network. More recently, graph-based approaches like GraphRAG (Edge et al., 2024a) and Zep (Rasmussen et al., 2025) structure memory into knowledge graphs to capture cross-document dependencies. We provide detailed discussion of related work in Appendix A. However, prior work typically organizes memory around associative proximity (e.g., semantic similarity) rather than mechanistic dependency (Kiciman et al., 2023). As result, such methods can retrieve what occurred but struggle to reason about why, since they lack explicit representations of causal structure, leading to reduced accuracy in complex reasoning tasks (Jin et al., 2023; Zhang et al., 2025)."
        },
        {
            "title": "3 MAGMA Design",
            "content": "In this section, we introduce the proposed MultiGraph based Agentic Memory (MAGMA) design and its components in detail."
        },
        {
            "title": "3.1 Architectural Overview",
            "content": "MAGMA architecture is organized into the following three logical layers, orchestrating the interaction between control logic and the memory substrate as illustrated in Figure 2. Query Process: The inference engine responsible for retrieving and synthesizing information. It comprises the Intent-Aware Router for dispatching tasks, the Adaptive Topological Retrieval module for executing graph traversals, and the Context Synthesizer for generating the final narrative response. Data Structure (G): The unified storage substrate that fuses disparate modalities. As shown in the center of Figure 2, it maintains Vector Database for semantic search alongside four distinct Relation Graphs (i.e., Semantic, Temporal, Causal and Entity). This layer provides the topological foundation for cross-view reasoning. Write/Update Process: dual-stream pipeline manages memory evolution. It decouples latencysensitive operations via Synaptic Ingestion (Fast Path) from compute-intensive reasoning via Asynchronous Consolidation (Slow Path), ensuring the system remains responsive while continuously deepening its memory structure. Functionally, the Query Layer interacts with the Data Structure Layer to execute the synchronous Query Process (Section 3.3), while the Write/Update Layer manages the continuous Memory Evolution (Section 3.4)."
        },
        {
            "title": "3.2 Data Structure Layer",
            "content": "As the core component of Memory-Augmented Generation (MAG), the data structure layer is responsible for storing, organizing, and evolving past information to support future retrieval and updates. In MAGMA, we formalize this layer as timevariant directed multigraph Gt = (Nt, Et), where nodes represent events and edges encode heterogeneous relational structures. This unified manifold enables structured reasoning across multiple logical dimensions(i.e., semantic, temporal, causal, and entity) while preserving their orthogonality. Unified node representation: The node set is hierarchically organized to represent experience at multiple granularities, ranging from fine-grained atomic events to higher-level episodic groupings. Each Event-Node ni Nevent is defined as: ni = ci, τi, vi, Ai (3) where ci denotes the event content (e.g., observations, actions, or state changes), τi is discrete timestamp anchoring the event in time, and vi Rd is dense representation indexed in the vector database (Johnson et al., 2019). The attribute set Ai captures structured metadata such as entity references, temporal cues, or contextual descriptors, enabling hybrid retrieval that integrates semantic similarity with symbolic and structural constraints. Relation graphs (edge space): The edge set is partitioned into four semantic subspaces, corresponding to the relation graphs: Temporal Graph (Etemp): Defined as strictly ordered pairs (ni, nj) where τi < τj. This immutable chain provides the ground truth for chronological reasoning. Causal Graph (Ecausal): Directed edges representing logical entailment. An edge eij Ecausal exists if S(njni, q) > δ, explicitly inferred by the consolidation module to support \"Why\" queries. Semantic Graph (Esem): Undirected edges connecting conceptually similar events, formally defined by cos(vi, vj) > θsim. Entity Graph (Eent): Edges connecting events to abstract entity nodes, solving the object permanence problem across disjoint timeline segments."
        },
        {
            "title": "Retrieval",
            "content": "As illustrated in Figure 3, retrieval in MAGMA is formulated as policy-guided graph traversal rather than static lookup operation. The query process is orchestrated by Router R, which decomposes the user query into structured control signals and executes multi-stage retrieval pipeline (Algorithm 1) that dynamically selects, traverses, and fuses relevant relational views. Four main stages in the query process is introduced below: Stage 1 - Query Analysis & Decomposition: The process begins by decomposing the raw user query into structured control signals, including semantic, lexical, and temporal cues. MAGMA then extracts three complementary representations to guide the retrieval process: Intent Classification (Tq): lightweight classifier maps to specific intent type Tq {WHY, WHEN, ENTITY}. This acts as the \"steering wheel,\" determining which graph edges will later be prioritized (e.g., \"Why\" queries trigger bias for Causal edges). Temporal Parsing ([τs, τe]): temporal tagger resolves relative expressions (e.g., \"last Friday\") into absolute timestamps, defining hard time window for filtering. Representation Extraction: The system simultaneously generates dense embedding for semantic search and extracts sparse keywords qkey for exact lexical matching. Stage 2 - Multi-Signal Anchor Identification: Before initiating graph traversal, the system first identifies set of anchor nodes that serve as entry points into the memory graph. To ensure robustness across query modalities, we fuse signals from dense semantic retrieval, lexical keyword matching, and temporal filtering using Reciprocal Rank Fusion (RRF) (Cormack et al., 2009): Sanchor = TopK (cid:88) m{vec,key,time} 1 + rm(n) (4) This ensures robust starting points regardless of query modality. Stage 3 - Adaptive Traversal Policy: Starting from the anchor set Sanchor, the system expands the context using Heuristic Beam Search. Unlike rigid rule-based traversals, MAGMA calculates dynamic transition score S(njni, q) for moving from node ni to neighbor nj via edge eij. This score fuses structural alignment with semantic relevance: (cid:18) S(njni, q) = exp λ1 ϕ(type(eij), Tq) (cid:125) (cid:124) (cid:123)(cid:122) Structural Alignment (cid:19) (5) + λ2 sim(nj, q) (cid:125) (cid:124) (cid:123)(cid:122) Semantic Affinity Here, sim() denotes the cosine similarity between the neighbors embedding and the query emFigure 3: Query process with adaptive hybrid retrieval pipeline. (1) Query Analysis detects intent and fuses signals to find Anchors. (2) Adaptive Traversal navigates specific graph views (Causal, Temporal) based on the policy weights. bedding. The structural alignment function ϕ dynamically rewards edge types based on the detected query intent Tq: ϕ(r, Tq) = Tq 1r (6) where wTq is an adaptive weight vector specific to intent Tq (e.g., assigning high weights to CAUSAL edges for \"Why\" queries), and 1r is the one-hot encoding of the edge relation. At each step, the algorithm retains the top-k nodes with the highest cumulative scores. This ensures the traversal is guided by dual signal: strictly following the logical structure (via ϕ) while maintaining contextual focus (via sim). Stage 4: Narrative Synthesis via Graph Linearization: The final phase transforms the retrieved subgraph Gsub into coherent narrative context. MAGMA employs structure-aware linearization protocol that preserves the relational dependencies encoded in the graph with the following three phases. 1. Topological Ordering: Raw nodes are reorganized to reflect the logic of the query. For temporal queries (Tq = WHEN), nodes are sorted by timestamp τi. For causal queries (Tq = WHY), we apply topological sort on the causal edges Ecausal to ensure causes precede effects in the prompt context. 2. Context Scaffolding with Provenance: To mitigate hallucination, each node is serialized into structured block containing its timestamp, content, and explicit reference ID. We define the linearized context Cprompt as: Cprompt = (cid:76) niSort(Gsub) [<t:τi> ni.content <ref:ni.id>] (7) Algorithm 1 Adaptive Hybrid Retrieval (Heuristic Beam Search) Input: Query q, Graph G, VectorDB , Intent Tq Output: Narrative Context Cout // Phase 1: Initialization 1: 2: Sanchor RRF(V.SEARCH(q), K.SEARCH(qkey)) // Hybrid Retrieval 3: CurrentF rontier, isited Sanchor 4: wTq GETATTENTIONWEIGHTS(Tq) 5: for 1 to axDepth do 6: 7: 8: 9: 10: 11: Candidates PRIORITYQUEUE() for CurrentF rontier do for G.NEIGHBORS(u) do if / isited then // Calculate transition score via Eq. 5 suv exp(λ1(w Tq 1euv ) + λ2sim(v, q)) Decay γ scorev scoreu γ + suv // Apply Candidates.PUSH(v, scorev) end if end for end for CurrentF rontier 12: 13: 14: 15: 16: 17: Candidates.TOPK(BeamW idth) isited.ADDALL(CurrentF rontier) if isited.SIZE() Budget then break end if 18: 19: 20: 21: end for 22: Csorted TOPOLOGICALSORT(V isited, Tq) 23: return SERIALIZE(Csorted) where (cid:76) denotes string concatenation. 3. Salience-Based Token Budgeting: Given fixed LLM context window, we cannot include all retrieved nodes. We utilize the relevance scores S(njni, q) computed in Eq. (5) to enforce dynamic budget. Low-probability nodes are summarized into brevity codes (e.g., \"...3 intermediate events...\"), while high-salience nodes retain full semantic detail."
        },
        {
            "title": "This structured scaffold forces the LLM to act\nas an interpreter of evidence rather than a creative",
            "content": "Algorithm 2 Fast Path: Synaptic Ingestion Algorithm 3 Slow Path: Structural Consolidation Input: User Interaction I, Current Graph Gt Output: Updated Graph Gt+1 1: nt SEGMENTEVENT(I) 2: nprev GETLASTNODE(Gt) 3: 4: G.ADDEDGE(nprev, nt, type = TEMP) 5: 6: vt ENCODER(nt.c) 7: DB.ADD(vt, nt.id) 8: Queue.ENQUEUE(nt.id) 9: return nt // Update Temporal Backbone // Indexing // Trigger Slow Path loop 1: Worker Process: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: end loop id Queue.DEQUEUE() if id is null then continue end if nt G.GETNODE(id) Nlocal G.GETNEIGHBORHOOD(nt, hops = 2) // Infer latent Causal and Entity structures rompt FORMAT(Nlocal) Enew ΦLLM (P rompt) G.ADDEDGES(Enew) writer, significantly reducing grounding errors."
        },
        {
            "title": "3.4 Memory Evolution (Write and Update)",
            "content": "Long-term reasoning requires not only effective retrieval, but also memory substrate that can adapt and reorganize as experience accumulates. MAGMA addresses this requirement through structured memory evolution scheme that incrementally refines its multi-relational graph over time. Specifically, the transition from Gt to Gt+1 is governed by dual-stream process that decouples latency-sensitive ingestion from compute-intensive consolidation (Kumaran et al., 2016), balancing short-term responsiveness with long-term reasoning fidelity. Fast path ( synaptic ingestion): The Fast Path operates on the critical path of interaction, constrained by strict latency requirements. It performs non-blocking operations: event segmentation, vector indexing, and updating the immutable temporal backbone (nt1 nt). As detailed in Algorithm 2, no blocking LLM reasoning occurs here, ensuring the agent remains responsive regardless of memory size. Slow path (structural consolidation): Asynchronously, the slow path performs Memory Consolidation (Algorithm 3). It functions as background worker that dequeues events and densifies the graph structure. By analyzing the local neighborhood (nt) of recent events, the system employs an LLM Φ to infer latent connections: Enew = Φreason(N (nt), Hhistory) (8) This process constructs high-value Ecausal and Eent links, effectively trading off compute time for relational depth. 3."
        },
        {
            "title": "Implementation",
            "content": "We implement MAGMA as modular three-layer architecture designed for extensibility, scalability, and deployment flexibility. The storage layer abstracts over heterogeneous physical backends, providing unified interfaces for managing the typed memory graph, dense vector indices, and sparse keyword indices. This abstraction cleanly separates the logical memory model from its physical realization, enabling seamless substitution of storage backends (e.g., in-memory data structures versus production-grade graph or vector databases) with minimal engineering effort. The retrieval layer coordinates the core algorithmic components, including memory construction, multi-stage ranking, and policy-guided graph traversal. It is supported by specialized utility modules for episodic segmentation and temporal normalization, which provide structured signals to downstream retrieval and traversal policies. The application layer manages the interaction loop, evaluation harnesses, and prompt construction, serving as the interface between the agent and the underlying memory system."
        },
        {
            "title": "4 Experiments",
            "content": "We conduct comprehensive experiments to evaluate both the reasoning effectiveness and systems properties of the proposed MAGMA architecture over state-of-the-art baselines."
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "Datasets. We evaluate long-term conversational capability using two widely adopted benchmarks: (1) LoCoMo (Maharana et al., 2024): which contains ultra-long conversations (average length of 9K tokens) designed to assess long-range temporal and causal retrieval. (2) LongMemEval (Wu et al., 2024): large-scale stress-test benchmark with an average context length exceeding 100K tokens, used to evaluate scalability and memory retention stability over extended interaction horizons.. Table 1: Performance on the LoCoMo benchmark evaluated using the LLM-as-a-Judge metric. Higher scores indicate better performance. LLM model is based on gpt-4o-mini. Method Multi-Hop Temporal Open-Domain Single-Hop Adversarial Overall Full Context A-MEM MemoryOS Nemori MAGMA (ours) 0.468 0.495 0.552 0.569 0.528 0.562 0.474 0.422 0.649 0.650 0.486 0.385 0.504 0.485 0.517 0.630 0.653 0.674 0.764 0.776 0.205 0.616 0.428 0.325 0. 0.481 0.580 0.553 0.590 0.700 Baselines. We compare MAGMA against four state-of-the-art memory architectures. For fair comparison, all methods employ the same backbone LLMs. Full Context: Feeds the entire conversation history into the LLM. A-MEM (Xu et al., 2025): biological-inspired, self-evolving memory system that dynamically organizes agent experiences. Nemori (Nan et al., 2025): graph-based memory utilizing \"predict-calibrate\" mechanism for episodic segmentation. MemoryOS(Kang et al., 2025a) : semanticfocused memory operating system employing hierarchical storage strategy. Metrics. Following standard evaluation protocols, we primarily use the LLM-as-a-Judge score (Zheng et al., 2023) to assess the accuracy of different methods. The detailed evaluation prompt used for the judge model is provided in the appendix. For completeness, we also report token-level F1 and BLEU-1 (Papineni et al., 2002)."
        },
        {
            "title": "4.2 Overall Comparison",
            "content": "This section introduces the accuracy performance comparison between all methods on the LoCoMo benchmark based on LLM-as-a-judge. As shown in Table 1, MAGMA achieves the highest overall judge score of 0.7, substantially outperforming the other baselines: Full Context (0.481), A-MEM (0.58), MemoryOS (0.553) and Nemori (0.59) by relative margins of 18.6% to 45.5%. This result demonstrates that explicitly modeling multirelational structure enables more accurate longhorizon reasoning than flat or purely semantic memory architectures. closer analysis reveals that MAGMAs advantage is particularly pronounced in reasoningintensive settings. In the Temporal category, MAGMA slightly but consistently outperforms others (Judge: 0.650 for MAGMA vs. 0.422 - 0.649 for others), validating the effectiveness of our Temporal Inference Engine in resolving relative temporal expressions into grounded chronological representations. The performance gap further widens under adversarial conditions, where MAGMA attains judge score of 0.742. This robustness stems from the Adaptive Traversal Policy, which prioritizes causal and entity-consistent paths and avoids semantically similar yet structurally irrelevant distractors that often mislead vector-based retrieval systems. Additional results and analyzes, including case studies and evaluations under alternative metrics, are provided in the appendix."
        },
        {
            "title": "4.3 Generalization Study",
            "content": "To evaluate generalization under extreme context lengths, we compare MAGMA against prior methods on the LongMemEval benchmark. LongMemEval poses substantial scalability challenge, with an average context length exceeding 100k tokens, and therefore serves as rigorous stress test for long-term memory retention and retrieval under strict computational constraints. As summarized in Table 2, MAGMA achieves the highest average accuracy (61.2%), outperforming both the Full-context baseline (55.0%) and the Nemori system (56.2%). These results indicate that MAGMA generalizes effectively to ultra-long interaction histories while maintaining strong retrieval precision. At the same time, the results highlight favorable efficiencygranularity trade-off. Although the Full-context baseline performs strongly on singlesession-assistant tasks (89.3%), this performance comes at prohibitive computational cost, requiring over 100k tokens per query. MAGMA achieves competitive accuracy (83.9%) while using only 0.7k4.2k tokens per query, representing reduction of more than 95%. This demonstrates that MAGMA effectively compresses long interaction histories into compact, reasoning-dense subgraphs, preserving essential information while substantially Table 2: Performance comparison on LongMemEval dataset across different question types. We compare our MAGMA method against the Full-context baseline and the Nemori system."
        },
        {
            "title": "Question Type",
            "content": "Full-context (101K tokens) Nemori (3.74.8K tokens) MAGMA (0.74.2K tokens) m - 4 - single-session-preference single-session-assistant temporal-reasoning multi-session knowledge-update single-session-user Average 6.7% 89.3% 42.1% 38.3% 78.2% 78.6% 55.0% 62.7% 73.2% 43.0% 51.4% 52.6% 77.7% 56.2% 73.3% 83.9% 45.1% 50.4% 66.7% 72.9% 61.2% Table 3: System efficiency comparison with total memory build time (in hours), average token consumption per query (in tokens), and average query latency (in seconds). Method Build Time (h) Tokens/Query (k) Latency (s) Full Context A-MEM MemoryOS Nemori MAGMA N/A 1.01 0.91 0.29 0.39 8.53 2.62 4.76 3.46 3.37 1.74 2.26 32.68 2.59 1.47 Table 4: Breakdown analysis on the performance impact of different schemes in MAGMA. MAGMA schemes Judge F1 BLEU-1 w/o Adaptive Policy w/o Causal Links w/o Temporal Backbone w/o Entity Links 0.637 0.644 0.647 0.666 0.413 0.439 0.438 0.451 MAGMA (Full) 0.700 0.467 0.357 0.354 0.349 0.363 0.378 reducing inference-time overhead."
        },
        {
            "title": "4.4 System Efficiency Analysis",
            "content": "To evaluate the system efficiency of MAGMA, two metrics are focused: (1) memory build time (the time required to construct the memory graph) and (2) token cost (the average tokens processed per query). Table 3 reports the comparative results. While A-MEM achieves the lowest token consumption (2.62k) due to its aggressive summarization, it sacrifices reasoning depth (see Table 1). In contrast, MAGMA achieves the lowest query latency (1.47s) about 40% faster than the next best retrieval baseline (A-MEM) while maintaining competitive token cost (3.37k). This efficiency stems from our Adaptive Traversal Policy, which prunes irrelevant subgraphs early, and the dual-stream architecture that offloads complex indexing to the background."
        },
        {
            "title": "4.5 Ablation Study",
            "content": "In this subsection, we conduct systematic ablation study to assess the contribution of individual components in MAGMA. By selectively disabling edge types and traversal mechanisms, we isolate the sources of its reasoning capability. The results in Table 4 reveal three main findings. First, removing Traversal Policy results in the largest performance drop, with the Judge score decreasing from 0.700 to 0.637. This confirms that intent-aware routing is critical: without it, retrieval degenerates into static graph walk that introduces structurally irrelevant information and degrades reasoning quality. Second, removing either Causal Links or the Temporal Backbone leads to comparable and substantial performance losses (0.644 and 0.647, respectively), indicating that causal structure and temporal ordering provide complementary, non-substitutable axes of reasoning. Finally, removing Entity Links causes smaller but consistent decline (0.700 to 0.666), highlighting their role in maintaining entity permanence and reducing hallucinations in entity-centric queries."
        },
        {
            "title": "5 Conclusion",
            "content": "We introduced MAGMA, multi-graph agentic memory architecture that models semantic, temporal, causal, and entity relations within unified yet disentangled memory substrate. By formulating retrieval as policy-guided graph traversal and decoupling memory ingestion from asynchronous structural consolidation, MAGMA enables effective long-horizon reasoning while maintaining low inference-time latency. Empirical results on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-ofthe-art memory systems while achieving substantial efficiency gains under ultra-long contexts."
        },
        {
            "title": "6 Limitations",
            "content": "While MAGMA demonstrates strong empirical performance, it has several limitations. First, the quality of the constructed memory graph depends on the reasoning fidelity of the underlying Large Language Models used during asynchronous consolidation. This dependency is shared limitation of agentic memory systems that rely on LLM-based structural inference, as they are susceptible to extraction errors and hallucinations (Pan et al., 2024; Xi et al., 2025; Wadhwa et al., 2023). Although MAGMA employs structured prompts and conservative inference thresholds to reduce spurious links, erroneous or missing relations may still arise and propagate to downstream retrieval. Nevertheless, our experimental results indicate that, even under these constraints, agentic memory systems such as MAGMA substantially outperform traditional baselines, including full-context approaches, in longhorizon reasoning tasks. Second, multi-graph substrate may introduce additional storage and engineering complexity compared to flat, vector-only memory systems. Maintaining multiple relational views and dual-stream processing incurs little higher implementation and memory overhead, which may limit applicability in highly resource-constrained environments. Finally, most existing agentic memory systems, including MAGMA, are primarily evaluated on long-context conversational and agentic benchmarks such as LoCoMo and LongMemEval. While these benchmarks effectively stress temporal and causal reasoning, they do not cover the full range of settings in which agentic memory may be required(Hu et al., 2025). Extending MAGMA to other scenarios, such as multimodal agents or environments with heterogeneous observation streams, may require additional adaptation and calibration. Addressing these broader evaluation settings remains an important research direction for future work."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Iz Beltagy, Matthew Peters, and Arman Cohan. 2020a. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150. Iz Beltagy, Matthew Peters, and Arman Cohan. 2020b. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, and 1 others. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. 2025. Mem0: Building production-ready ai agents with scalable long-term memory. arXiv preprint arXiv:2504.19413. Gordon V. Cormack, Charles Clarke, and Stefan Buettcher. 2009. Reciprocal rank fusion outperforms condorcet and individual rank learning methods. In Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 09, page 758759, New York, NY, USA. Association for Computing Machinery. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, and Jonathan Larson. 2024a. From local to global: graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, and Jonathan Larson. 2024b. From local to global: graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130. Bernal Jiménez Gutiérrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, and Yu Su. 2025. From rag to memory: Non-parametric continual learning for large language models. arXiv preprint arXiv:2502.14802. Yuyang Hu, Shichun Liu, Yanwei Yue, Guibin Zhang, Boyang Liu, Fangyi Zhu, Jiahang Lin, Honglin Guo, Shihan Dou, Zhiheng Xi, and 1 others. 2025. Memory in the age of ai agents. arXiv preprint arXiv:2512.13564. Le Huang, Hengzhi Lan, Zijun Sun, Chuan Shi, and Ting Bai. 2024. Emotional rag: Enhancing roleplaying agents through emotional retrieval. In 2024 IEEE International Conference on Knowledge Graph (ICKG), pages 120127. IEEE. Wenqi Jiang, Suvinay Subramanian, Cat Graves, Gustavo Alonso, Amir Yazdanbakhsh, and Vidushi Dadu. 2025. Rago: Systematic performance optimization for retrieval-augmented generation serving. In Proceedings of the 52nd Annual International Symposium on Computer Architecture, pages 974989. Ziyan Jiang, Xueguang Ma, and Wenhu Chen. 2024. Longrag: Enhancing retrieval-augmented generarXiv preprint ation with long-context arXiv:2406.15319. llms. Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng Lyu, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, and 1 others. 2023. Cladder: Assessing causal reasoning in language models. Advances in Neural Information Processing Systems, 36:31038 31065. Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. IEEE Billion-scale similarity search with gpus. Transactions on Big Data, 7(3):535547. Jiazheng Kang, Mingming Ji, Zhe Zhao, and Ting Bai. 2025a. Memory os of ai agent. arXiv preprint arXiv:2506.06326. Jiazheng Kang, Mingming Ji, Zhe Zhao, and Ting Bai. 2025b. Memory os of ai agent. arXiv preprint arXiv:2506.06326. Jikun Kang, Wenqi Wu, Filippos Christianos, Alex Chan, Fraser Greenlee, George Thomas, Marvin Purtorab, and Andy Toulis. 2025c. Lm2: Large memory models. arXiv preprint arXiv:2502.06049. Urvashi Khandelwal, He He, Peng Qi, and Dan Jurafsky. 2018. Sharp nearby, fuzzy far away: How neural language models use context. arXiv preprint arXiv:1805.04623. Emre Kiciman, Robert Ness, Amit Sharma, and Chenhao Tan. 2023. Causal reasoning and large language models: Opening new frontier for causality. Transactions on Machine Learning Research. Dharshan Kumaran, Demis Hassabis, and James McClelland. 2016. What learning systems do intelligent agents need? complementary learning systems theory updated. Trends in cognitive sciences, 20(7):512 534. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems, 33:9459 9474. Zhiyu Li, Shichao Song, Chenyang Xi, Hanyu Wang, Chen Tang, and 1 others. 2025. Memos: memory os for ai system. arXiv preprint arXiv:2507.03724. Shuhang Lin, Zhencan Peng, Lingyao Li, Xiao Lin, Xi Zhu, and Yongfeng Zhang. 2025. Cache mecharXiv preprint anism for agent rag systems. arXiv:2511.02919. Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang. 2023. Thinkin-memory: Recalling and post-thinking enable arXiv preprint llms with long-term memory. arXiv:2311.08719. Nelson Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157173. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024. Evaluating very long-term converarXiv preprint sational memory of llm agents. arXiv:2402.17753. Jiayan Nan, Wenquan Ma, Wenlong Wu, and Yize Chen. 2025. Nemori: Self-organizing agent memory inspired by cognitive science. arXiv preprint arXiv:2508.03341. Charles Packer, Vivian Fang, Shishir_G Patil, Kevin Lin, Sarah Wooders, and Joseph_E Gonzalez. 2023. Memgpt: Towards llms as operating systems. Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. 2024. Unifying large language models and knowledge graphs: roadmap. IEEE Transactions on Knowledge and Data Engineering, 36(7):35803599. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics. Joon Sung Park, Joseph OBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122. Ofir Press, Noah Smith, and Mike Lewis. 2021a. Train short, test long: Attention with linear biases enables input length extrapolation. arXiv preprint arXiv:2108.12409. Ofir Press, Noah Smith, and Mike Lewis. 2021b. Train short, test long: Attention with linear biases enables input length extrapolation. arXiv preprint arXiv:2108.12409. Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Defu Lian, Zhicheng Dou, and Tiejun Huang. 2025. Memorag: Boosting long context processing with global memory-enhanced retrieval augmentation. In Proceedings of the ACM on Web Conference 2025, pages 23662377. Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, and Daniel Chalef. 2025. Zep: temporal knowledge graph architecture for agent memory. arXiv preprint arXiv:2501.13956. Somin Wadhwa, Silvio Amir, and Byron Wallace. 2023. Revisiting relation extraction in the era of large language models. In Proceedings of the conference. association for computational linguistics. meeting, volume 2023, page 15566. Yu Wang and Xi Chen. 2025. Mirix: Multi-agent memory system for llm-based agents. arXiv preprint arXiv:2507.07957. Zheng Wang, Shu Teo, Jieer Ouyang, Yongjun Xu, and Wei Shi. 2024. M-rag: Reinforcing large language model performance through retrieval-augmented genIn Proceedings eration with multiple partitions. of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 19661978. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, and 1 others. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824 24837. Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, and Dong Yu. 2024. Longmemeval: Benchmarking chat assistants on long-term interactive memory. arXiv preprint arXiv:2410.10813. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, and 1 others. 2025. The rise and potential of large language model based agents: survey. Science China Information Sciences, 68(2):121101. Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, and Yongfeng Zhang. 2025. A-mem: Agentic memory for llm agents. arXiv preprint arXiv:2502.12110. Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, and 1 others. 2025. Igniting language intelligence: The hitchhikers guide from chain-of-thought reasoning to language agents. ACM Computing Surveys, 57(8):139. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, and 1 others. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in neural information processing systems, 36:4659546623. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2024. Memorybank: Enhancing large language models with long-term memory. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1972419731."
        },
        {
            "title": "A Related Work",
            "content": "Following the framing in main text, we organize related work along the same progression: from context window extension to retrieval augmented generation (RAG) and finally to memory augmented generation (MAG), and then discuss structured/graph memories and causal reasoning, which are central to long-horizon agentic interactions. Context-window Extension. direct line of work extends the effective context length of Transformers by modifying attention or positional extrapolation. Longformer (Beltagy et al., 2020b) introduces sparse attention patterns to scale to long documents, reducing quadratic cost while retaining locality and selected global connectivity. ALiBi (Press et al., 2021b) (Attention with Linear Biases) enables length extrapolation by injecting distance-aware linear biases into attention scores, improving robustness when testing on longer sequences than those seen in training. Recent efforts also add explicit memory modules or hybrid mechanisms to push beyond pure attention-window scaling. For example, LM2 (Kang et al., 2025c) proposes decoder-only architecture augmented with an auxiliary memory to mitigate long-context limitations. MemoRAG (Qian et al., 2025) similarly emphasizes global-memory-enhanced retrieval to boost long-context processing when raw context is insufficient or inefficient. While these approaches improve long-range coverage, they do not, by themselves, address the continual, evolving, and writeback nature of agent memory required for multisession interactions. Retrieval Augmented Generation. RAG (Lewis et al., 2020) augments an LLM with external retrieval over fixed corpus, classically retrieving supporting passages and conditioning generation on them. Subsequent work explores better integration with long-context models and more scalable retrieval pipelines. LongRAG (Jiang et al., 2024) studies how to exploit long-context LLMs together with retrieval, improving the ability to incorporate larger retrieved evidence sets. Other systems focus on structuring the retrieved memory space or optimizing the RAG serving stack: MRAG (Wang et al., 2024) uses multiple partitions to encourage fine-grained retrieval focus, while RAGO (Jiang et al., 2025) provides systematic framework for performance optimization in RAG serving. However, standard RAG typically assumes static knowledge base. In contrast, agentic settings require memory that is continuously updated (the feedback loop described in the main text). This motivates the shift to MAG systems, where memory is dynamic and evolves with interaction histories. Memory Augmented Generation and Agent Memory Systems. MAG systems maintain and update an external memory over time, enabling agents to accumulate knowledge, preserve identity, and remain coherent across sessions. Early and representative directions include memory construction and write-back strategies for long-term agent behavior, such as MemoryBank (Zhong et al., 2024) and generative agents style architectures that emphasize persistent profiles and evolving state grounded in past interactions (Nan et al., 2025; Maharana et al., 2024). growing body of work adopts systems metaphors and designs: MemGPT (Packer et al., 2023) frames LLM agents with an operatingsystem-like memory hierarchy, emphasizing paging and controlled context management. More recent memory OS systems propose explicit storage hierarchies and controllers (e.g., MemoryOS (Kang et al., 2025b), MemOS (Li et al., 2025)) to manage persistence and retrieval policies at scale. In addition, practical agent-memory stacks (e.g., Zep (Rasmussen et al., 2025)) offer temporal knowledgegraph-based memory services aimed at real-world deployment constraints. Structured memory: chains-of-thought and graph-based representations. Beyond flat text buffers or vector stores, several methods explicitly structure memory to support reasoning. Think-inMemory (TiM) stores evolving chains-of-thought to improve consistency across long-horizon reasoning, while A-MEM (Xu et al., 2025) is inspired by Zettelkasten-style linking of notes/experiences. These methods highlight the value of representing intermediate reasoning traces or explicit links, but many retrieval pipelines still predominantly rely on semantic similarity as the primary access mechanism. Graph-based approaches have recently gained traction as way to capture cross-document and cross-episode dependencies. GraphRAG (Edge et al., 2024b) builds entity-centric graphs and community summaries to answer more global questions over large corpora. Zep proposes temporallyaware knowledge-graph engine (Graphiti) that synthesizes conversational and structured business data while preserving historical relations. The main text notes these graph-based lines explicitly and motivates key gap: many systems organize memory around associative proximity (semantic relatedness) rather than mechanistic dependency. Causal reasoning and long-horizon evaluation. Causal reasoning has been highlighted as both important and challenging for LLMs. The work (Kiciman et al., 2023) study LLMs ability to generate causal arguments across multiple causal tasks and emphasize robustness/failure modes, reinforcing that what happened retrieval is not sufficient for why reasoning in many settings. Benchmarking efforts such as LoCoMo (Maharana et al., 2024) stress long-range temporal and causal dynamics in multi-session conversations and provide evaluation tasks that expose long-horizon memory deficits. The papers experimental setup also uses LongMemEval (Wu et al., 2024) as an ultra-long context stress test, and evaluates via LLM-as-a-Judge protocols standard in modern instruction-following evaluation. Overall, prior work demonstrates steady progress in (i) scaling context length, (ii) improving retrieval pipelines, and (iii) building structured, evolving memories for agents. The main text positions MAGMA within this trajectory by explicitly targeting multi-relational structure (semantic/temporal/causal/entity) and intent-aware retrieval control."
        },
        {
            "title": "B System Implementation Details",
            "content": "B.1 Hyperparameter Configuration Table 5 presents the comprehensive configuration used in our experiments. These parameters were empirically optimized on the LoCoMo benchmark. Notably, MAGMA employs an Adaptive Scoring mechanism where weights (λ) shift dynamically based on the detected query intent."
        },
        {
            "title": "C Prompt Library",
            "content": "MAGMA employs sophisticated prompt strategy with three distinct types, each optimized for specific cognitive tasks within the memory pipeline. C.1 Event Extraction Prompt (JSON-Structured) To ensure robustness against hallucination and parsing errors, this module employs strict JSON schema enforcement strategy. The prompt explicitly defines the extraction targets to ensure downstream graph integrity, capturing not just entities but also semantic relationships and temporal markers. Table 5: Hyperparameter settings for MAGMA. \"Traversal Weights\" correspond to the intent-specific vector wTq , while λ1 and λ2 control the global balance between structural alignment and semantic affinity (Eq. 5). Module Parameter Value/Range Embedding Inference Retrieval (Phase 1) Traversal (Phase 2) Adaptive Weights (Eq. ??) Model (Default) Model (Optional) Dimension LLM Backbone Temperature RRF Constant (k) Vector Top-K wkeyword (Fusion) Sim. Threshold Max Depth Max Nodes Drop Threshold all-MiniLM-L6-v2 text-embedding-3-small 384 / 1536 gpt-4o-mini 0. 60 20 2.0 5.0 0.100.30 5 hops 200 0.15 λ1 (Structure Coef.) λ2 (Semantic Coef.) 1.0 (Base) 0.3 0.7 wentity (in wTq ) wtemporal (in wTq ) wcausal (in wTq ) wphrase (in wTq ) 2.5 6.0 0.5 4.0 3.0 5.0 2.5 5. System Prompt: Event Extractor System Role: You are an automated Graph Memory Parser. Your task is to extract structured metadata from raw conversational logs to build knowledge graph. Input Data: Speaker: {speaker} Text: {text} Context: {prev_summary} Instructions: Analyze the input and return ONLY valid JSON object matching the specific schema below. Do not include markdown formatting. Target Schema: \"entities\": List of proper nouns (People, Locations, Organizations). \"topic\": String (13 words representing the main theme). \"relationships\": List of strings describing interactions (e.g., \"X researches Y\"). \"semantic_facts\": List of atomic facts preserving key information. \"dates_mentioned\": List of temporal strings (e.g., \"next Friday\", \"2024-01-01\"). \"summary\": One-sentence summary preserving speaker attribution. C.2 Query-Adaptive QA Prompt The generation prompt begins with strict persona definition and appends specific reasoning instructions dynamically based on the Routers classification (e.g., Multi-hop, Temporal, Open-domain). System Prompt: Adaptive QA System Role: You are precision QA assistant operating on retrieved memory contexts. Your goal is to answer the users question accurately using only the provided information. Context: {context} Current Query: Question: {question} Constraints: {category_specific_constraints} Instructions: 1. Use ONLY information explicitly stated in the context. 0.6 (Partial Match): Contains valid information but misses key constraints (e.g., wrong date but correct event). 0.4 (Tangential): Touches on the topic but misses the core information requirement. 0.2 (Incoherent): Factually incorrect with only 2. If the answer is not present, respond exactly with minimal topical overlap. \"Information not found\". 3. Be concise (typically 110 words) unless detailed reasoning is required. 4. {dynamic_instruction} // Automatically generated by our engines query classifier/router (no oracle labels) Answer: *Dynamic Instruction Injection Candidates: [Multi-hop]: \"Connect related facts across different nodes. For comparison queries (e.g., both/all), identify commonalities between entities rather than listing individual details.\" [Temporal]: \"Resolve relative dates (e.g., yesterday) using the event timestamps. Output dates strictly in Month YYYY format. Calculate durations if asked.\" [Open-Domain/Inference]: \"Make reasonable inferences based on the users personality traits, interests, and Support hypothetipast behaviors. cal reasoning with evidence.\" (would/could) [Single-hop/Factual]: \"Extract the specific entity, name, or method requested. Do not add explanations. Return the exact fact matching the query intent.\" C.3 Evaluation Prompt (LLM-as-a-Judge) To ensure rigorous evaluation beyond simple ngram overlapping, we employ semantic scoring mechanism. The Judge LLM evaluates the alignment between the generated response and the ground truth using the following schema. System Prompt: Semantic Grader You are an expert evaluator assessing the semantic fidelity of memory retrieval system. Score the Candidate Answer against the Gold Reference on continuous scale [0.0, 1.0]. Scoring Rubric: 1.0 (Exact Alignment): Captures all key entities, temporal markers, and causal relationships. Semantically equivalent. 0.8 (Substantially Correct): Main point is accurate but lacks minor nuances or secondary details. 0.0 (Contradiction/Hallucination): Completely unrelated or contradicts the ground truth. Evaluation Constraints: 1. Temporal Flexibility: Accept relative time references (e.g., \"next Tuesday\") if they resolve to the same period as the Gold Reference. 2. Semantic Equivalence: Prioritize informational content over lexical matching. 3. Adversarial Handling: If the Gold Reference states \"Unanswerable\", the Candidate MUST explicitly state lack of information. Any hallucinated fact results in 0.0. Input: Question: {question} Gold: {gold} Candidate: {generated} Output: JSON {\"score\": float, \"reasoning\": \"concise explanation\"}"
        },
        {
            "title": "D Baseline Configurations",
            "content": "To ensure fair and rigorous comparison, we standardized the experimental environment across all systems. Specifically, we adhered to the following protocols: Full Context Baseline: We implemented \"Full Context\" baseline where the entire available conversation history is fed directly into the LLMs context window (up to the 128k token limit of gpt-4o-mini). This serves as \"brute-force\" reference to evaluate the models native long-context capabilities without external retrieval mechanisms. Retrieval-Based Baselines: For all baseline systems (e.g., AMem, Nemori, MemoryOS), we applied their official default hyperparameters and storage settings to reflect their standard out-of-the-box performance. Unified Backbone Model: To eliminate performance variance caused by different foundation models, all systems utilized OpenAIs gpt-4o-mini for both retrieval reasoning and response generation. Unified Evaluation: All system outputs were evaluated using the identical LLM-as-a-Judge framework (also powered by gpt-4o-mini with temperature=0.0), as detailed in Appendix C. Dataset Statistics. We conducted comprehensive evaluation on the full LoCoMo benchmark, testing across all five cognitive categories to assess varying levels of retrieval complexity. The detailed distribution of query types is presented in Table 6. Table 6: Distribution of query categories in the LoCoMo benchmark used for evaluation. Query Category Count Single-Hop Retrieval Adversarial Temporal Reasoning Multi-Hop Reasoning Open Domain 841 446 321 282 96 Total Samples 1,"
        },
        {
            "title": "E Case Study",
            "content": "To demonstrate MAGMAs reasoning capabilities across different cognitive modalities, we analyze three real-world scenarios from the LoCoMo benchmark. Table 7 provides side-by-side comparison of MAGMA against key baselines (AMEM, Nemori, MemoryOS). E.1 Detailed Analysis Case 1: Overcoming Information Loss (Recall). For the query regarding instruments, AMEM failed completely due to its summarization process abstracting away specific details (\"violin\") from early sessions. Other RAG baselines only retrieved the \"clarinet\" due to surface-level semantic matching. MAGMA, however, maintains an entitycentric graph structure. Instead of relying on rigid schemas, MAGMA queries the local neighborhood of the [Entity: Melanie] node. This allows it to capture diverse natural language predicates (e.g., \"playing my violin\", \"started clarinet\") and aggregate disjoint facts into comprehensive answer, demonstrating robustness against information loss. Case 2: Multi-Hop Reasoning vs. Surface Extraction. The query \"How many children?\" exposes critical weakness in standard RAG: the inability to perform arithmetic across contexts. Baselines simply extracted the explicit mention of \"two children\" from photo caption. In contrast, MAGMA treated this as graph traversal problem focused on entity resolution. It queried the neighborhood of [Entity: Melanie] for connected nodes of type Person. By analyzing the semantic edges, specifically distinguishing the \"two kids\" entity in the canyon photo from the \"son\" entity involved in the car accident, MAGMA synthesized these distinct nodes. It correctly deduced that the \"son\" (referenced later as \"brother\") was an additional individual, summing up to count of \"at least three,\" logical leap impossible for systems relying solely on vector similarity. Case 3: Temporal Grounding. When asked \"When did she hike?\", baselines either hallucinated or defaulted to the conversation timestamp (Oct 20). This ignores the semantic meaning of the users statement: \"we just did it yesterday.\" MAGMAs structured ingestion pipeline normalizes relative dates during graph construction. The event was stored with the resolved attribute date=\"2023-10-19\", making the retrieval trivial and exact, completely bypassing the ambiguity that confused the LLM-based baselines."
        },
        {
            "title": "F Metric Validation Analysis",
            "content": "To validate our choice of using an LLM-based Judge over traditional lexical metrics, we conducted granular failure analysis on seven representative test cases. Table 9 details the quantitative breakdown. F.1 Rationale for Semantic Scoring Our empirical results reveal two critical failure modes where standard metrics (F1, BLEU-1) directly contradict human judgment: 1. False Rewards (The Hallucination Problem): Lexical metrics heavily reward incorrect answers that share surface-level tokens. In Case 3, direct negation (compatible vs. not compatible) yields remarkably high F1 of 0.857, treating fatal contradiction as near-perfect match. In Case 6, substituting the wrong entity (John vs. Sarah) still achieves F1 0.750, rewarding the hallucinatory output. 2. False Penalties (The Phrasing Problem): Valid answers with different formatting or synonyms are unfairly penalized. In Case 4 (Time Notation) and Case 5 (Synonyms), F1 and BLEU scores drop to 0.000 despite the answers being semantically identical. Table 7: Case study for failure analysis comparing MAGMA against baselines across three reasoning types. Red text indicates hallucinations or partial failures; Teal text indicates correct reasoning derived from graph traversal. F o T Query & Type Baseline Failure Mode MAGMA Graph Reasoning (Success) Q1: Fact Retrieval \"What does Melanie play?\" instruments A-MEM: \"Memories do not explicitly state...\" MemoryOS: \"Clarinet\" Failure: Baselines relying on top-k vector search missed the distant memory of the \"violin\" (D2:5) because it appeared in context about \"me-time\" rather than explicitly about music. \"Clarinet and Violin.\" Mechanism: MAGMA utilized the entitycentric subgraph around \"Melanie\". By traversing dynamic semantic edges (e.g., \"playing\", \"enjoy\") to connected event nodes, it aggregated all mentions of musical activities regardless of the specific relation label or distance. Q2: Logical Inference \"How many children does Melanie have?\" Nemori: \"At least two...\" MemoryOS: \"Two\" Failure: Baselines performed surface-level extraction from photo description showing \"two children\" (D18:5), failing to account for the \"son\" mentioned in separate accident event. Q3: Temporal Res. \"When did she hike after the roadtrip?\" A-MEM: \"20 October 2023\" MemoryOS: \"29 December 2025\" Failure: A-MEM simply copied the session timestamp. MemoryOS hallucinated future date. Both failed to resolve the relative time expression. \"At least three.\" Mechanism: MAGMA executed multi-hop inference focused on Entity Resolution: 1. Node (Photo): Identified \"two kids\" entity. 2. Node (Accident): Linked \"son\" (D18:1) via dynamic relationship edge. 3. Node (Dialogue): Confirmed \"brother\" (D18:7) is distinct from the two in the photo. Logic: 2 (Photo) + 1 (Son/Brother) = 3. \"19 October 2023\" Mechanism: MAGMAs Temporal Parser identified the relative marker \"yesterday\" in D18:17. Calculation: Tsession(Oct20) 1 day = Oct19. This exact date was anchored to the Event Node, allowing precise retrieval. Table 8: LoCoMo evaluation with F1 and BLEU-1 metrics Multi-Hop"
        },
        {
            "title": "Temporal",
            "content": "Open-Domain Single-Hop"
        },
        {
            "title": "Method",
            "content": "F1 BLEU-1 F1 BLEU-1 F1 BLEUF1 BLEU-1 F1 BLEU-1 Full Context A-MEM MemoryOS Nemori MAGMA (ours) 0.182 0.128 0.365 0.363 0. 0.128 0.088 0.276 0.249 0.172 0.079 0.128 0.434 0.569 0.509 0.055 0.079 0.369 0.479 0.370 0.042 0.076 0.246 0.247 0.180 0.030 0.051 0.191 0.189 0.136 0.229 0.174 0.493 0.548 0. 0.156 0.110 0.437 0.439 0.477 0.140 0.116 0.413 0.502 0.467 0.096 0.074 0.355 0.403 0.378 As shown in Table 9, the LLM-Judge correctly assigns score of 0.0 to factual errors and 1.0 to semantic matches, aligning perfectly with reasoning requirements. Table 9: Quantitative Failure Analysis of Lexical Metrics. We present seven controlled cases with their calculated F1 and BLEU-1 scores. The data demonstrates that lexical metrics frequently assign high scores to fatal errors (False Rewards) and zero scores to correct variations (False Penalties), whereas the LLM-Judge correctly assesses semantic validity. Failure Mode Case Detail (Gold / Predicted) Case 1: False Reward (Wrong Fact, High Overlap) Case 2: False Penalty (Verbose Phrasing) Case 3: False Reward (Negation/Contradiction) Case 4: False Penalty (Time Notation) Case 5: False Penalty (Synonyms) Case 6: False Reward (Entity Hallucination) Case 7: False Penalty (Format Noise) Gold: three items Pred: five items Analysis: Factually wrong count, but rewarded for sharing the noun items. Gold: 18 days Pred: The total duration was 18 days Analysis: Correct answer penalized for low precision due to extra words. Gold: compatible with Mac Pred: not compatible with Mac Analysis: Fatal contradiction receives nearperfect scores due to high token overlap. Gold: 14:00 Pred: 2 PM Analysis: Different formats result in zero overlap despite identical meaning. Gold: cheap Pred: inexpensive Analysis: Standard metrics cannot handle synonym matching without external resources. Gold: John completed the project Pred: Sarah completed the project Analysis: Wrong entity (Sarah vs John), yet high metrics due to shared sentence structure. Gold: 5 Pred: 5 (extracted from JSON...) Analysis: Correct value embedded in noise results in poor precision metrics. Lexical Metrics (F1 / BLEU-1) LLM Judge (Semantic) High 0.500 / 0. 0.0 (Reject) Low 0.500 / 0.333 1.0 (Accept) Very High 0.857 / 0.750 0.0 (Reject) Zero 0.000 / 0. 1.0 (Accept) Zero 0.000 / 0.000 1.0 (Accept) High 0.750 / 0.750 0.0 (Reject) Low 0.286 / 0. 1.0 (Accept)"
        }
    ],
    "affiliations": [
        "University of Florida",
        "University of Texas at Dallas"
    ]
}