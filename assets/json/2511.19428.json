{
    "paper_title": "Flow Map Distillation Without Data",
    "authors": [
        "Shangyuan Tong",
        "Nanye Ma",
        "Saining Xie",
        "Tommi Jaakkola"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 2 ] . [ 1 8 2 4 9 1 . 1 1 5 2 : r a"
        },
        {
            "title": "Flow Map Distillation Without Data",
            "content": "Shangyuan Tong* MIT sytong@csail.mit.edu Nanye Ma* NYU nm3607@nyu.edu Saining Xie NYU saining.xie@nyu.edu Tommi Jaakkola MIT tommi@csail.mit.edu"
        },
        {
            "title": "Abstract",
            "content": "State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces fundamental risk of Teacher-Data Mismatch, as static dataset may provide an incomplete or even misaligned representation of the teachers full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore data-free alternative that samples only from the prior distributiona distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce principled framework that learns to predict the teachers sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes new state-of-the-art by significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256 512, both with only 1 sampling step. We hope our work establishes more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data. (cid:128) Project page: data-free-flow-distill.github.io 256, and 1.49 on ImageNet 512 Figure 1. Teacher-Data Mismatch and the data-free alternative. (Top) Conventional data-based distillation relies on intermediate distributions (pt) derived from static dataset, which could be misaligned with the teachers true generative distributions (ˆpt). (Bottom) The data-free paradigm, in contrast, samples only from the prior (π), the single distribution with guaranteed alignment, thereby circumventing the mismatch risk by construction. 1. Introduction Diffusion models [22, 28, 73, 78] and flow models [1, 18, 40, 43, 56, 91, 92] have revolutionized high-fidelity synthesis [23, 60, 62, 86], yet their reliance on numerically integrating an Ordinary Differential Equation (ODE) creates significant computational bottleneck. To resolve this latency, flow maps [5], which learn the solution operator of the ODE directly, offer principled path to acceleration, bypassing iterative solving by taking large jumps *Equal contribution, Equal advising along the generative trajectory. While flow maps can be trained from scratch [4, 12, 14, 79], more flexible alternative is to distill them from powerful, pre-trained teacher models [3, 32, 64, 65, 79]. This modular strategy allows for the compression of state-of-the-art models, which are often the product of advanced training [38, 100, 102] and post-training [39, 41, 84, 90, 101] techniques. We observe that the dominant and most successful flow map distillation approaches are data-based, relying on samples from an external dataset to train the student. We argue 1 that this tacitly accepted dependency introduces fundamental risk of Teacher-Data Mismatch. As illustrated in Fig. 1, static dataset may provide an incomplete or misaligned representation of the teachers true generative capabilities. This discrepancy arises frequently in practice: when teacher generalizes beyond its original training set [26, 27, 54, 58, 70, 75, 96, 99]; when post-hoc finetuning [39, 41, 84, 90, 101] shifts the teachers distribution away from the original data; or when the teachers proprietary training data is simply unavailable [6, 35, 62, 71, 87]. In these scenarios, forcing student to match the teacher on misaligned dataset fundamentally constrains its potential. Fortunately, this mismatch is not inevitable. We observe that while the teachers generative paths may diverge from the dataset, they are, by definition, anchored to the prior distribution. As shown in Fig. 1, the prior serves as the single point of guaranteed alignment: it is the shared origin for the teachers generation and the termination point for any noising process. This insight leads us to question whether the common reliance on data is truly necessary. We posit that we can instead build robust, data-free alternative by sampling only from the prior, thereby circumventing the mismatch risk entirely by construction. To operationalize this philosophy, we introduce principled framework designed to track the teachers dynamics purely from the prior. Our method takes sample from the prior and scalar integration interval, predicting where the flow should jump. We show that optimality is achieved when the models generating velocity, the rate at which it traverses its own path, aligns with the teachers instantaneous velocity. Nevertheless, like any autonomous numerical solver, this prediction process is susceptible to compounding errors. To mitigate this, we propose correction mechanism that further aligns the models noising velocity, the marginal velocity of the noising flow implied by the students predicted distribution, back to the teacher. We name our proposal FreeFlow, emphasizing its defining characteristic as completely datafree distillation framework for flow maps. 256 and 1.49 on 512 We validate our approach through extensive experiments on ImageNet [63]. Distilling from SiT-XL/2+REPA [100] teacher, FreeFlow establishes new state-of-the-art, reaching an impressive FID of 1.45 on 256 512 with 1 function evaluation (1-NFE), significantly surpassing all data-based baselines. Furthermore, by leveraging its nature as fast, consistent proxy, FreeFlow enables efficient inference-time scaling [51, 72], allowing for the search of optimal noise samples in single step. Ultimately, our findings confirm that an external dataset is not an essential requirement for high-fidelity flow map distillation, and the risk of Teacher-Data Mismatch can be avoided entirely without compromising performance. We believe this work provides more robust foundation for generative model acceleration and motivates shift toward the data-free paradigm. 2. Preliminaries p0 to easy-to-sample prior distribution π Diffusion and flow. Diffusion models [22, 28, 73, 78] and flow models [1, 18, 40, 43, 56, 91, 92] are trained to reverse reference noising process that transports the data distribution p1 (0, I). We denote the interpolating distributions in belike tween as pt and their samples xt, indexed by time [0, 1]. For the linear interpolation scheme [40, 43, 50] that we utilize throughout the paper, given pair of terminal samples π, we construct the noising process from its interpolants, xt = It(x, z) := (1 t)x + tz, which in turn defines conditional velocity, pointing in the direction from z. Takprior to data, u(xt, ing the expectation over and π, we arrive at the marginal instantaneous velocity, : Rd Rd, vector field that dictates how the samples evolve, which governs the noising process with the following ODE: tIt(x, z) = x, z) := and [0, 1] dx(t) = u(x(t), t)dt, (1) Rd denotes the state of the system. In practice, where x(t) the typically unknown can be well approximated by model gψ with parameters ψ, trained with denoising score matching [77, 83] or conditional flow matching [40, 56]: Ex,z,t gψ(It(x, z), t) u(It(x, z), x, z) 2 . (2) For sampling, we need to solve Eq. (1) by integrating the flow backward in time: ϕu(xt, t, s) = xt + (cid:90) u(x(τ ), τ )dτ, (3) } { [0, ζ] Rd, ζ (y, ζ, ξ) Rd, Dflow = where ϕu : Dflow , denotes the generating flow equipped with [0, 1], ξ underlying velocity field u, and is the integration time interval. The standard sampling procedure of flow π. In models corresponds to calculating ϕu(z, 1, 0), practice, we resort to some numerical solver, like Euler [74, 78] and Heun methods [28]. Since the underlying trajectories typically exhibit complicated structure and curvature [88, 93], such numerical integration procedures often require dozens or even hundreds of NFEs for single generation. Flow maps. Instead of approximating the instantaneous velocity u, flow map model [3, 5, 12, 14, 32, 64, 65, 79], fθ parameterized by θ, is trained to directly approximate ϕu. Existing works dissect and utilize key properties of ϕu to construct their training objective, typically via the local dynamics described by u. For example, in MeanRd represents the Flow [14], the network Fθ : Dflow average velocity travels over its path: fθ(xt, t, s) = s)Fθ(xt, t, s). At optimality, we know from Eq. (3) xt +(t 2 3.1. The Risk of Teacher-Data Mismatch The distribution of xt is conventionally formed by sampling from data-noising distribution, which we denote as pt. This is the set of all interpolants It( x, z) generated by taking p1 and prior sample π. Although data point tacitly accepted, this practice implicitly assumes that pt is suitable representation of the states the teacher model follows over its sampling trajectory. We note that the teacher defines distinct set of intermediate states via Eq. (3). The set of all xt along these solution paths constitutes the true teacher-generating distribution, which we denote as ˆpt. For the student to perfectly reproduce the teacher, it should be trained to match the teachers dynamics over ˆpt. The central problem that we identify in this paper, which we term the Teacher-Data Mismatch, is that these two distributions are not equivalent: pt By training on pt, the student is compelled to learn the teachers dynamics only on trajectories that are anchored to the static dataset p. Any generative behavior of the teacher that starts from π and evolves through states not well-represented by pt will be systematically ignored during training. Consequently, even perfectly converged student is not guaranteed to reproduce the teachers outputs, as it has fundamentally been trained to distill the wrong process. = ˆpt. To examine and validate the impact of the discussed mismatch, we design controlled experiment on ImageNet, where we introduce deliberately misaligned pt distributions by applying data augmentations during the training of conventional flow map distillation. As shown in Fig. 2, the quality of the learned flow map is highly sensitive to the fidelity and representativeness of the distillation dataset: stronger augmentation leads to larger discrepancy between ˆpt and pt, and, in turn, results in more significant degradation in student performance. This mismatch is not merely theoretical curiosity; it manifests in several common and critical scenarios. First, when powerful teacher model has generalized beyond its training set [26, 27, 54, 58, 70, 75, 96, 99], or even when it simply employs the widely adopted Classifier-Free Guidance (CFG) [21], its generative distribution ˆp0 will contain novel, extrapolated samples not present in p, causing its trajectories ˆpt to necessarily diverge from the data-noising paths pt. Second, if the teacher has been altered by posthoc fine-tuning [39, 41, 84, 90, 101], its generating flow is deliberately modified, again forcing ˆpt to diverge from the original data-noising distribution. Third, teacher model may be released publicly while its massive, proprietary training data is not [6, 35, 62, 71, 87]. In this case, is simply unavailable, and any proxy dataset used will almost certainly create severe mismatch. 1We use to denote the dataset available at distillation time. As we will discuss, it may differ from p. (cid:82) dt Figure 2. Impact of Teacher-Data Mismatch. With fixed teacher model, increasing augmentation induces more severe mismatch between teacher and data, degrading student performance. that (t ating both sides w.r.t. leads to s)Fθ (xt, t, s) = (x(τ ), τ ) dτ . DifferentiFθ (xt, t, s) + (t s) Fθ (xt, t, s) = u(xt, t), (4) where into following practical training objective: dt is the total derivative that can be further expanded xtF dxt dt + tF . This identity then motivates the 2 , (5) sg (uMF) Fθ(xt, t, s) s) Et,s,xt ) denotes the stop-gradient operation, and uMF = where sg( dt Fθ(xt, t, s). The decision to drop the (t u(xt, t) remaining gradients is mostly empirical and common in prior literature [12, 14, 45, 76], as it results in faster, less resource-demanding, and often more stable training. Here, is either co-trained from scratch [14] together with Eq. (2), or pre-trained flow model [57, 64, 79] in procedure known as flow map distillation. In this paper, we focus on the second case, since this modular approach allows for easier incorporation of advanced training [38, 100, 102] and posttraining [39, 41, 84, 90, 101] techniques. 3. With or Without Data? The goal of flow map distillation is to create student fθ that faithfully reproduces the full generative process of the given ϕu, just with fewer NFEs. Intuitively, existing methods learn the teacher sampling dynamics at series of intermediate states xt (note the expectation over xt in Eq. (5)). Our discussion begins from this very point, with closer inspection of foundational, yet largely unexamined, element: the underlying distribution from which these states xt are drawn. Figure 3. Selected samples from FreeFlow-XL/2 model at 512512 resolution with 1-NFE. More uncurated results are in App. D. 3.2. Towards Data-Free Alternative straightforward remedy to the Teacher-Data Mismatch is to directly sample from ˆpt during training. This would involve sampling π, integrating the teacher model from = 1 to random time to get xt = ϕu(z, 1, t), and then using this xt in the distillation loss. Just like the case of knowledge distillation [20, 43, 47, 104], where the model is trained to learn the fully integrated outcomes at = 0, obtaining reference trajectories on-the-fly is prohibitively costly, whereas pre-computing them offline scales poorly. In short, for high-dimensional or complex conditional tasks, generating enough samples to adequately represent the underlying distribution simply becomes intractable. This apparent impasse leads us to re-examine the properties of these two distributions. While ˆpt and pt diverge for [0, 1), they are, by construction, identical at = 1. The data-noising process terminates at the prior distribution (i.e., p1 π), and the teachers generative process begins at the same prior (i.e., ˆp1 π). This observation provides crucial foothold. The prior π is the one distribution we can sample from that is guaranteed to be on-distribution for the teachers generative process, completely circumventing the risk of Teacher-Data Mismatch. This insight motivates our central question: Is the commonly followed data-dependency truly necessary for flow map distillation? We argue that it is not. In the following, we explore data-free alternative, building new flow map distillation objective governed only by the prior distribution. 4. Flow Map Distillation Without Data Our exploration now moves from motivation to mechanism. flow map model can be generally understood as directly modeling segment of full generative trajectory, and the core principle for training such model is to enforce consistency with at some point along this segment, ensuring the learned dynamics are locally correct. The segments two key points provide natural candidates: sampled start-point, xt, and predicted end-point, xs = fθ(xt, t, s). This perspective provides clear lens through which to view the distillation process. In the conventional, data-based setting, the start-point xt is drawn from series of data4 noising distributions pt. It is thus natural to constrain the model by perturbing this start-point, which corresponds to differentiating the optimal condition, (t s)Fθ (xt, t, s) = (x(τ ), τ ) dτ , with respect to t. This operation leads to the MeanFlow identity [14] in Eq. (4), which effectively (cid:82) enforces consistency at the start of the segment. In our data-free investigation, however, we only sample our start-point from the prior π, which fixes xt = at = 1. Consequently, perturbing the start-time t, and in turn the start-point, is no longer meaningful operation. Thus, we consider the symmetrical alternative: if we cannot enforce consistency by perturbing the sampled start-point, we can instead do so by perturbing the predicted end-point. This provides different path to ensuring the students local dynamics are correct, and it corresponds to differentiating the optimal condition with respect to the end time s. To formalize this, we first simplify our notation to reflect this prior-anchored (t = 1) view. That is: (1) We define the [0, 1]; integration duration as δ = (2) The flow map fθ(z, δ) : Rd Rd approxiδ); (3) The average velocity mates the true flow ϕu(z, 1, 1 Fθ(z, δ) : Rd Rd is linked by the parameterization fθ(z, δ) = + δFθ(z, δ). The optimal condition, anchored at = 1, thus reduced to: s, where δ [0, 1] = 1 [0, 1] δFθ (z, δ) = 1 δ 1 (cid:90) (x(τ ), τ ) dτ. (6) Following our exposition, we differentiate both sides of Eq. (6) w.r.t. δ (equivalent to differentiating w.r.t. s): δ) . Fθ (z, δ) + δδFθ (z, δ) = (fθ (z, δ), (7) Eq. (7) differs from Eq. (4) in subtle ways: (1) The time derivative of Fθ is just partial derivative, as does not depend on δ; (2) is evaluated at state predicted by fθ. The identity defined in Eq. (7) provides sufficient condition for optimality, which motivates the following loss: Ez,δ Fθ(z, δ) sg(utarget) 2 , (8) where utarget = (fθ(z, δ), 1 δδFθ(z, δ). Remarkably, we verify that Eq. (8) is formulated by only sampling δ) from the prior π, without any reliance on an external dataset and thus free from the risks of Teacher-Data Mismatch. Hence, it achieves the goal of our exploration. 4.1. Predict With Generating Flows δ) δfθ(z, δ) u(fθ(z, δ), 1 We now analyze our proposed objective in Eq. (8). Note that δfθ(z, δ), the model predictions rate of change with respect to the integration time, is the velocity with which the model travels along its generating flow. Thus, the optimality of the student is equivalent to the alignment between the models generating velocity and the underlying velocity. Indeed, it is easy to see that the loss value of Eq. (8) is 2, which the same as Ez,δ evaluates to 0 if and only if δf = u. Intuitively, the student is analogous to an autonomous ODE solver, which uses its current estimated state to query the derivative function and compute the next state. The student learns to ride the teachers vector field, starting from π and extending outward, step by step, based entirely on its own evolving predictions. In practice, δFθ can be calculated easily and efficiently via Jacobian-vector product (JVP) with forward-mode automatic differentiation, barring some advanced computation kernels, which currently require customized solutions [45]. Still, it is desirable to work with more flexible loss function with no such limitations, which is why we derive discrete-time alternative (detail in App. A.1) that numerically approximates δFθ with finite differences. Consequently, we abstract away the computation detail, and use the general notation vG(fθ(z, δ), 1 δ) to denote the students generating velocity δfθ(z, δ). The understanding that Eq. (8) aligns vG and can also be observed from its optimization gradients: (9) δ) , (cid:17)(cid:21) θ Ez,δ vG,u(fθ(z, δ), 1 (cid:16) δ) and u(fθ(z, δ), Fθ(z, δ)sg (cid:20) δ) is the difference between where vG,u(fθ(z, δ), 1 δ). Explicitly writvG(fθ(z, δ), 1 ing out the gradients makes it easier to adopt techniques like gradient weighting/normalization explored in Sec. 5.1. Note that, if Fθ is further parameterized, we should replace the first term in Eq. (9) with the actual network output to ensure effective gradient control by only modifying vG,u. Lastly, we note that advanced sampling techniques can be easily incorporated in u, e.g., for classifier-free guidance c)2 with (CFG) [21], we could simply replace u(xt, ), c) + (1 uγ(xt, = u(xt, c) = γ referring to null input, and where is condition with γ is the guidance strength. Furthermore, the model can be trained on range of γ values, which enables the ability to effortlessly change the guidance strength at inference time. u(xt, γ) The Challenge of Error Accumulation. In practice, the student model fθ is only learned approximation, not 2We omit everywhere else in the paper for simplicity. 5 Figure 4. Approximation errors accumulate as the prediction proceeds from noise to data. Figure 5. Correction objective in Eq. (11) aligns the students noising velocity vN with u. mathematically perfect one. At any δ, its prediction fθ(z, δ) may contain small approximation error, placing it slightly δ). Because the off the true teacher trajectory ϕu(z, 1, 1 objective is self-referential, this small deviation influences the target used for subsequent steps. The student queries the teacher at its current and potentially slightly erroneous state, and the resulting velocity target, while correct for that state3, may not guide the student back toward the true path. Such errors can compound as the integration proceeds from δ = 0 to δ = 1. In Fig. 4, we measure the relative differences between the students predicted trajectory and the teachers true sampling path, which empirically quantifies and confirms such phenomenon as the student progressively diverges from the teacher when δ increases. 4.2. Correct With Noising Flows The problem identified above is that the student is trained to predict the next state based on its current one, but it has no means to correct its own deviations and pull the trajectory back towards the teachers true path. Drawing inspiration from Song et al. [78], we seek to correct the marginal distributions of the student solutions, analogous to predictorcorrector method for solving ODEs [2]. Additionally, the correction objective cannot reintroduce the data-dependency we have worked to remove, meaning that we do not consider objectives like GANs [15] that rely on an external dataset. Variational Score Distillation [85] was originally proposed as training procedure to distill distributions from pre-trained diffusion models by minimizing the Integral KL divergence [48]. We slightly adapt it to our setting, where q0 to denote the marginal distribution of clean we use fθ(z, 1)dπ. Specifically, samples generated by the model, it has been shown that = if and only if their IKL divergence is 0, which is defined as (cid:82) DIKL(q p) := 1 0 (cid:90) Exr qr log (cid:20) qr(xr) pr(xr) (cid:21) dr, (10) where qr and pr are the marginal interpolating distributions, following the same noising process constructed by I. Er,xr The optimization gradient of Eq. (10) w.r.t. θ is . As xr log pr(xr)) (cid:105) 3This assumes the teacher is perfect, which is not true in practice. xr log qr(xr) θxr) ( (cid:104) ( the score functions are interchangeable with the marginal velocities [50], we can optimize with the following gradient instead for correcting the students prediction: θ Ez,n,r Fθ(z, 1)sg (cid:20) (cid:16) vN,u(Ir(fθ(z, 1), n), r) , (cid:17)(cid:21) (11) where is sampled from the prior π like z. We verify that Eq. (11) is also formulated by only sampling from π, free from the risks of Teacher-Data Mismatch. Here, vN denotes the marginal velocity of the noising flow constructed from the generated distribution with the interpolating function I, and vN,u is the difference between vN and u. We illustrate the high-level understanding of this mechanism in Fig. 5. Since vN is unknown, we approximate it with another on4, full-parameter [48, 95, 97, 98, 107, 108] line network gψ or LoRA [24, 53, 85], with loss in Eq. (2). More specifically, for pair of samples fθ(z, 1) and n, the conditional noising velocity is rIr(fθ(z, 1), n), and we arrive at vN by taking the expectation over π and π: gψ(Ir(fθ(z, 1), n), r) + rIr(fθ(z, 1), n) Ez,n,r 2 . (12) We highlight the similarity of the gradient forms between Eq. (9) and Eq. (11). Consequently, we identify that the optimality of the student is also equivalent to the alignment between the models noising velocity and the underlying velocity. That is, Eq. (10) evaluates to 0 if and only if vN,u = 0. Such velocity alignment perspective offers series of new understandings, which provide the essential reasoning behind the practical design choices discussed later in Sec. 5.1. We further note that comprehensive correction procedure should correct the full predicted trajectory of the student, rather than only the end sample considered in Eq. (10). However, we do not find such design helpful in the experiment settings we considered in Sec. 5. 5. Experiments We empirically validate our proposed method on ImageNet [63] at 256 512 resolutions using FID50K [19], with implementation details provided in App. B. 256 and 512 5.1. Design Decisions We analyze each design choice through targeted qualitative and quantitative studies, presenting key findings in the main text and deferring full analyses to the App. A. Unless specified otherwise, we adopt the DiT-B/2 architecture [55], use the pre-trained SiT-B/2 [50] as and student initialization, train the model for 400K iterations (roughly equivalent to 80 epochs with batch size of 256) with uniformly sampling 4Further parameterizations on gψ are permissible. 6 sampling; Eq. (11) LogitNormal(-0.4, 1.6) LogitNormal(0.0, 1.6) LogitNormal(0.4, 1.6) LogitNormal(0.8, 1.6) LogitNormal(1.2, 1.6) FID 6.24 5.95 5.78 5.63 5.78 range; Eq. (11) [0, 0.6] [0, 0.7] [0, 0.8] [0, 0.9] [0, 1.0] FID 91.82 24.62 9.00 6.64 6.02 (a) sampling. More emphasis on higher noise levels leads to better results when aligning vN and u. (b) range. With uniform distribution over r, dropping higher noise levels leads to worse results. interval; Eq. (11) [0, 0.5] [0, 0.6] [0, 0.7] [0, 0.8] [0, 0.9] [0, 1.0] FID 7.09 5.72 5.63 6.44 7.41 8.65 objective Eq. (9) Eqs. (9) and (11) 0.0 0.5 1.0 0.0 0.5 1. FID 11.91 11.71 12.40 43.53 10.58 5.58 (c) Guidance interval. Compared to teacher sampling, more aggressive guidance interval is better. (d) Gradient weighting. With both objectives, stronger decay on vG,u leads to better training. Table 1. Empirical investigations of various design decisions. [1, 2], and evaluate with the best γ = 2. We begin with γ designs specific to training with one of Eqs. (9) and (11), followed by studies on how to properly combine the two. Sampling of in Eq. (11). Traditionally, within the diffusion framework and from the divergence minimization perspective, the sampling of in Eq. (11) often follows uniform distribution over the discretized steps designed for generation [59, 85, 98]. Here, we provide new perspective on the Eq. (11), which drives our proposal on the sampling distribution of r. Recall that the optimality of our correction objective is vN,u = 0, the alignment between the noising velocity of the models generated distribution and the underlying velocity. The velocity fields induce pair of continuity equations tpt(x) = (pt(x)u(x, t)) and (qt(x)vN(x, t)), which dictate the evolutqt(x) = tion of and q. We note that p1 = q1 = π by construction, and the gap between p0 and q0 can be understood as the time-integrated accumulation of the differences in their corresponding probability fluxes. This understanding suggests we place greater emphasis on higher noise levels, and we empirically validate this intuition in Tabs. 1a and 1b. Handling guidance in Eq. (11). The usual treatment for including guidance in Eq. (11) is the same as in Eq. (9): replacing it with the guided velocity uγ. However, we highlight that there is subtle but major difference between vG and vN. In traditional flow model training with Eq. (2), we essentially train the model to learn datasets noising velocity, and use it as the generating velocity during sampling, i.e., the two velocities are identical as they describe the same process. However, this equivalence no longer holds in the presence of techniques like CFG [29, 103], and the distinction is especially prominent at high noise levels. We resort to dropping the guidance application at high noise levels, in similar fashion to the guidance interval [34] used Figure 6. Performance is robust across α. Figure 7. Synergy between Eqs. (9) and (11). Figure 8. Inference-time scaling. for flow sampling. Furthermore, as demonstrated in Tab. 1c, we stress that their empirical behaviors are different, and one typically needs to limit the interval significantly more aggressively (the pre-trained SiT-B/2 does not benefit from guidance interval with γ = 2) in our correction objective. Adaptive gradient balancing between Eqs. (9) and (11). We now discuss how to fuse the training signals from Eqs. (9) and (11). First, in similar manner to prior works [12, 14], we decide to split the training batch between the prediction and correction objectives (75% and 25%, respectively), since correction is slightly more expensive compute-wise. Then, we adopt an adaptive gradient balancing strategy [10], where the correction gradients are scaled by some dynamic weight λ before concatenating with the prediction gradients. With the form similarity between Eq. (9) and Eq. (11), and the observation that both optimizations lack aleatoric uncertainty [31]5, we design λ = α +ϵ , where the 6 is expectation is taken over the mini-batch and ϵ = 10 used for numerical stability. We show that the model performance is robust across wide range of α in Fig. 6. vN ,u vG ,u vG,u Gradient norm manipulations in Eq. (9). We note that we can change the magnitude of vG,u freely without changing the optimal solution, which can also be understood as changing the loss metrics [13]. Concretely, we can scale vG,u with per-sample positive weights. Prior works [13, 14, 76] 2 + ε)k, where mostly explored scaling with 1/( 4 is used for numerical stability and we vary the ε = 10 power term k. Since the actual weighting applied depends on the original norm of vG,u, which changes with the dimension of data d, we first divide it by so that it is dimension invariant before calculating the weight. We note that such weighting design corresponds to applying power-law decay on vG,u, and larger indicates stronger decay, effectively dampening the gradient contributions. In Tab. 1d, we find that the model prefers weightings with stronger decay when training with both Eqs. (9) and (11). We hypothesize that this is because their signals may not always agree with each other in practice, and by applying dampener on vG,u, we mitigate the conflict between the two objectives and promote more harmonious joint optimization. 5vG,u and vN,u represent the quality of alignments, unlike Eq. (2). 5.2. Main Results 256 and 512 256 and 1.49 on Comparisons with prior work. In Tab. 2, we benchmark our approach against existing proposals for learning fast flows on class-conditional ImageNet [63] generation at both 256 512 resolutions. We highlight three key findings from our main results. (1) Our method achieves state-of-the-art performance by significant margin. Distilling from SiT-XL/2+REPA [100], our method reaches an impressive FID of 1.45 on 256 512, greatly outperforming prior proposals. (2) Competitive performance is realized very early in training. Our model surpasses the final performance of many strong baselines after only 100K iterations ( 20 epochs), demonstrating exceptional training efficiency. (3) Our student faithfully reproduces the teachers full capabilities with 1-NFE. Our distilled model consistently stays within 10% of the teachers original performance with only single step, even when the teacher employs advanced training techniques like REPA [100], and sampling techniques like guidance intervals [34]. This is critical advantage over training fast flows from scratch: it allows us to seamlessly inherit the benefits of complex teacher training recipes, which can be complicated to adopt [36], simply by distilling the final product. Crucially, we emphasize that our results are achieved using only the pre-trained teacher model, without requiring access to single sample from an external dataset, real or synthetic, thus validating the effectiveness of the data-free paradigm. Synergy between prediction and correction. While theory suggests that either learning the flow trajectories (Eq. (9)) or matching the marginal distributions (Eq. (11)) could suffice for generation, we find that neither is robust in isolation. The prediction objective, when used alone, falls victim to the error accumulation identified in Sec. 4.1, plateauing at suboptimal fidelity (blue line in Fig. 7). Conversely, training only with the correction objective (Eq. (11)) leads to gradual mode collapse and performance degradation (green line in Fig. 7; also gray baseline in Fig. 6). Fig. 7 illustrates the powerful synergy realized by our framework on SiTXL/2 teacher. By combining both signals at their optimal settings, we achieve performance strictly superior to either independent component. The prediction signals construct 7 Table 2. Class-conditional generation on ImageNet 256256 and 512512. * indicates the use of AutoGuidance [29]. Methods marked with are initialized from pretrained models. Crucially, unlike other listed distillation baselines, ours is constructed to be entirely data-free. Class-Conditional ImageNet 256 Class-Conditional ImageNet 512512 Method Epochs #Params NFE FID Method Epochs #Params NFE FID Teacher Diffusion / Flow Models Teacher Diffusion / Flow Models SiT-XL/2 [50] SiT-XL/2+REPA [100] 1400 800 675M 675M 2 250 434 2.06 1. SiT-XL/2 [50] SiT-XL/2+REPA [100] Fast Flow from scratch Shortcut-XL/2 [12] 250 675M IMM-XL/2 [106] 3840 675M STEI [42] 1420 675M MeanFlow-XL/2 [14] DMF-XL/2 [36] 240 1000 880 Fast Flow by distillation Teacher: SiT-XL/2 (FID = 2.06) SDEI [42] FACM [57] FreeFlow-XL/2 20 20 300 Teacher: SiT-XL/2+REPA (FID = 1.37) FACM [57] π-Flow [7] FreeFlow-XL/2 448 20 676M 675M 675M 675M 678M 675M 675M 678M 1 128 2 2 1 8 1 1 2 1 4 8 2 1 1 1 2 1 1 10.60 3.80 7.77 1.99 7.12 1.96 3.43 2. 2.16 1.51 2.46 2.07 2.24 1.69 1.52 2.85 1. 1.84 1.45 EDM2-S* [29] EDM2-XXL [30] EDM2-XXL* [29] Fast Flow from scratch sCT-XXL [45] DMF-XL/2 [36] 600 400 1678 734 761 540 675M 675M 280M 1.5B 1.5B 675M Fast Flow by distillation Teacher: EDM2-S* (FID = 1.34) AYF-S [64] 80 280M Teacher: EDM2-XXL (FID = 1.40) sCD-XXL [45] sCD-XXL+VSD [45] 320 32 Teacher: SiT-XL/2 (FID = 2.62) FreeFlow-XL/2 20 200 Teacher: SiT-XL/2+REPA (FID = 1.37) FreeFlow-XL/2 20 200 1.5B 678M 678M 250 460 2 63 82 2 1 2 1 4 1 4 1 1 2 1 1 2.62 1.37 1.34 1.40 1. 4.29 3.76 2.12 1.68 3.32 1.70 2.28 1.88 2.16 1.89 3.01 2. 2.11 1.49 the generative path, while the correction signals act as stabilizer to rectify compounding errors, ensuring consistent improvement throughout training. Inference-time scaling. The recently proposed inferencetime scaling framework [51, 72] offers promising avenue to trade additional compute for generation quality. However, existing search strategies typically require the full integration of ϕu for every candidate, making the search process prohibitively expensive. We propose more efficient alternative: by distilling the teacher into flow map, we create fast proxy that retains the teachers mapping from noise to data. This allows us to conduct the expensive search using the cheap, one-step student, transferring only the optimal noise to the teacher for final generation. We investigate Best-of-N search with an oracle verifier [51], employing our student (trained for only 20 epochs) to guide the fixed SiT-XL/2 teacher. As shown in Fig. 8, this approach drastically improves the teachers sampling quality. Crucially, the results highlight the benefit of our prediction objective (Eq. (9)): while the correction-only model (Eq. (11)) yields improvements, it is notably less efficient at identifying transferable noise candidates due to lack of guaranteed trajectory alignment. Our combined objective, by enforcing strict consistency with ϕu, enables much more effective search. With total budget of only 80 NFEs, our method outperforms the teachers standard classifier-free guidance sampling at 128 NFEs. This result demonstrates powerful practical trade-off: by shifting fraction of the inference burden to short distillation phase, we enable the compute-efficient deployment of large-scale diffusion models. 6. Conclusion In this work, we challenge the conventional reliance on external datasets for flow map distillation. We identify fundamental vulnerability in this practice, the Teacher-Data Mismatch, and argue that static dataset is an inherently unreliable proxy for teachers full generative capabilities. This data-dependency is not only risky but also unnecessary. Our principled, data-free alternative, formulated as predictor-corrector framework, resolves this mismatch by construction as it samples only from the prior. Our strong empirical results, which establish new state-of-the-art, confirm the practical viability and strength of this data-free paradigm. We believe this work provides more robust foundation for accelerating generative models and hope it motivates broader exploration of flow map distillation without data."
        },
        {
            "title": "Acknowledgments",
            "content": "We are grateful to Kaiming He for valuable discussions and feedback on the manuscript. This work was partly supported by the Google TPU Research Cloud (TRC) program and the Google Cloud Research Credits program (GCP19980904). ST and TJ acknowledge support from the Machine Learning for Pharmaceutical Discovery and Synthesis (MLPDS) consortium, the DTRA Discovery of Medical Countermeasures Against New and Emerging (DOMANE) threats program, the NSF Expeditions grant (award 1918839) Understanding the World Through Code. SX acknowledges support from the MSIT IITP grant (RS-2024-00457882) and the NSF award IIS-2443404."
        },
        {
            "title": "References",
            "content": "[1] Michael Samuel Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants. In The Eleventh International Conference on Learning Representations, 2023. 1, 2 [2] Eugene Allgower and Kurt Georg. Numerical continuation methods: an introduction. Springer Science & Business Media, 2012. 5 [3] David Berthelot, Arnaud Autef, Jierui Lin, Dian Ang Yap, Shuangfei Zhai, Siyuan Hu, Daniel Zheng, Walter Talbott, and Eric Gu. Tract: Denoising diffusion models with transitive closure time-distillation. arXiv preprint arXiv:2303.04248, 2023. 1, 2, 18 [4] Nicholas Boffi, Michael Albergo, and Eric VandenEijnden. How to build consistency model: Learning flow maps via self-distillation. arXiv preprint arXiv:2505.18825, 2025. 1 [5] Nicholas Matthew Boffi, Michael Samuel Albergo, and Eric Vanden-Eijnden. Flow map matching with stochastic interpolants: mathematical framework for consistency models. Transactions on Machine Learning Research, 2025. 1, 2, 14, 18 [6] Siyu Cao, Hangting Chen, Peng Chen, Yiji Cheng, Yutao Cui, Xinchi Deng, Ying Dong, Kipper Gong, Tianpeng Gu, Xiusen Gu, et al. Hunyuanimage 3.0 technical report. arXiv preprint arXiv:2509.23951, 2025. 2, [7] Hansheng Chen, Kai Zhang, Hao Tan, Leonidas Guibas, Gordon Wetzstein, and Sai Bi. pi-flow: Policy-based fewstep generation via imitation distillation. arXiv preprint arXiv:2510.14974, 2025. 8, 18 [8] Earl Coddington, Norman Levinson, and Teichmann. Theory of ordinary differential equations, 1956. 13 [9] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:87808794, 2021. 16, 17 [10] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1287312883, 2021. 7 [11] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik 9 Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In Forty-first international conference on machine learning, 2024. [12] Kevin Frans, Danijar Hafner, Sergey Levine, and Pieter Abbeel. One step diffusion via shortcut models. arXiv preprint arXiv:2410.12557, 2024. 1, 2, 3, 7, 8 [13] Zhengyang Geng, Ashwini Pokle, William Luo, Justin Lin, and Zico Kolter. Consistency models made easy. arXiv preprint arXiv:2406.14548, 2024. 7, 18 [14] Zhengyang Geng, Mingyang Deng, Xingjian Bai, Zico Kolter, and Kaiming He. Mean flows for one-step generative modeling. arXiv preprint arXiv:2505.13447, 2025. 1, 2, 3, 4, 7, 8, 18 [15] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. 5 [16] Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Lingjie Liu, and Joshua Susskind. Boot: Data-free distillation of denoising diffusion models with bootstrapping. In ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling, 2023. 18 [17] Jonathan Heek, Emiel Hoogeboom, and Tim Salimans. Multistep consistency models. arXiv preprint arXiv:2403.06807, 2024. 18 [18] Eric Heitz, Laurent Belcour, and Thomas Chambon. Iterative α-(de) blending: minimalist deterministic diffusion model. In ACM SIGGRAPH 2023 Conference Proceedings, pages 18, 2023. 1, [19] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium. Advances in neural information processing systems, 30, 2017. 6, 15, 16 [20] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in neural network. arXiv preprint arXiv:1503.02531, 2015. 4 [21] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022. 3, 5 [22] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:68406851, 2020. 1, 2, 13 [23] Emiel Hoogeboom, Vıctor Garcia Satorras, Clément Vignac, and Max Welling. Equivariant diffusion for molecule generation in 3d. In International conference on machine learning, pages 88678887. PMLR, 2022. 1 [24] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. ICLR, 1(2):3, 2022. 6 [25] Aapo Hyvärinen and Peter Dayan. Estimation of nonnormalized statistical models by score matching. Journal of Machine Learning Research, 6(4), 2005. [26] Zahra Kadkhodaie, Florentin Guth, Eero Simoncelli, and Stéphane Mallat. Generalization in diffusion models arises from geometry-adaptive harmonic representations. arXiv preprint arXiv:2310.02557, 2023. 2, 3 [27] Mason Kamb and Surya Ganguli. An analytic theory of creativity in convolutional diffusion models. arXiv preprint arXiv:2412.20292, 2024. 2, 3 [28] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in neural information processing systems, 35:2656526577, 2022. 1, 2, 14, 16, 17 [29] Tero Karras, Miika Aittala, Tuomas Kynkäänniemi, Jaakko Lehtinen, Timo Aila, and Samuli Laine. Guiding diffusion model with bad version of itself. Advances in Neural Information Processing Systems, 37:5299653021, 2024. 6, 8 [30] Tero Karras, Miika Aittala, Jaakko Lehtinen, Janne Hellsten, Timo Aila, and Samuli Laine. Analyzing and improving the training dynamics of diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2417424184, 2024. 8, 16 [31] Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? Advances in neural information processing systems, 30, 2017. 7 [32] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon. Consistency trajectory models: Learning probability flow ODE trajectory of diffusion. In The Twelfth International Conference on Learning Representations, 2024. 1, 2, [33] Ba Jimmy Kingma, Diederik P. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 16, 17 [34] Tuomas Kynkäänniemi, Miika Aittala, Tero Karras, Samuli Laine, Timo Aila, and Jaakko Lehtinen. Applying guidance in limited interval improves sample and distribution quality in diffusion models. Advances in Neural Information Processing Systems, 37:122458122483, 2024. 6, 7 [35] Black Forest Labs, Stephen Batifol, Andreas Blattmann, Frederic Boesel, Saksham Consul, Cyril Diagne, Tim Dockhorn, Jack English, Zion English, Patrick Esser, et al. Flux. 1 kontext: Flow matching for in-context image generation and editing in latent space. arXiv preprint arXiv:2506.15742, 2025. 2, 3 [36] Kyungmin Lee, Sihyun Yu, and Jinwoo Shin. Decoupled meanflow: Turning flow models into flow maps for accelerated sampling. arXiv preprint arXiv:2510.24474, 2025. 7, 8, 18 [37] Sangyun Lee, Yilun Xu, Tomas Geffner, Giulia Fanti, Karsten Kreis, Arash Vahdat, and Weili Nie. Truncated consistency models. arXiv preprint arXiv:2410.14895, 2024. 18 [38] Xingjian Leng, Jaskirat Singh, Yunzhong Hou, Zhenchang Xing, Saining Xie, and Liang Zheng. Repa-e: Unlocking vae for end-to-end tuning with latent diffusion transformers. arXiv preprint arXiv:2504.10483, 2025. 1, 3 [39] Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, and Zhao Zhong. Mixgrpo: Unlocking flowbased grpo efficiency with mixed ode-sde. arXiv preprint arXiv:2507.21802, 2025. 1, 2, [40] Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. Learning Representations, 2023. 1, 2, 15 In The Eleventh International Conference on [41] Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang, and Wanli Ouyang. Flow-grpo: Training flow matching models via online rl. arXiv preprint arXiv:2505.05470, 2025. 1, 2, 3 [42] Wenze Liu and Xiangyu Yue. Learning to integrate diffusion odes by averaging the derivatives. arXiv preprint arXiv:2505.14502, 2025. 8, 18 [43] Xingchao Liu, Chengyue Gong, and qiang liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. In The Eleventh International Conference on Learning Representations, 2023. 1, 2, 4, [44] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, et al. Instaflow: One step is enough for high-quality diffusionbased text-to-image generation. In The Twelfth International Conference on Learning Representations, 2023. 18 [45] Cheng Lu and Yang Song. Simplifying, stabilizing and scaling continuous-time consistency models. arXiv preprint arXiv:2410.11081, 2024. 3, 5, 8, 18 [46] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: fast ode solver for diffusion probabilistic model sampling in around 10 steps. Advances in Neural Information Processing Systems, 35:57755787, 2022. 14 [47] Eric Luhman and Troy Luhman. Knowledge distillation in iterative generative models for improved sampling speed. arXiv preprint arXiv:2101.02388, 2021. 4, 18 [48] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun, Zhenguo Li, and Zhihua Zhang. Diff-instruct: universal approach for transferring knowledge from pre-trained diffusion models. Advances in Neural Information Processing Systems, 36:7652576546, 2023. 5, 6, 15, 18 [49] Weijian Luo, Zemin Huang, Zhengyang Geng, Zico Kolter, and Guo-jun Qi. One-step diffusion distillation through score implicit matching. Advances in Neural Information Processing Systems, 37:115377115408, 2024. 18 [50] Nanye Ma, Mark Goldstein, Michael Albergo, Nicholas Boffi, Eric Vanden-Eijnden, and Saining Xie. Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers. arXiv preprint arXiv:2401.08740, 2024. 2, 6, 8, 15, 16, [51] Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, YuChuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, et al. Inference-time scaling for diffusion models beyond scaling denoising steps. arXiv preprint arXiv:2501.09732, 2025. 2, 8 [52] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans. On distillation of guided diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1429714306, 2023. 18 [53] Thuan Hoang Nguyen and Anh Tran. Swiftbrush: Onestep text-to-image diffusion model with variational score distillation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 78077816, 2024. 6 10 [54] Matthew Niedoba, Berend Zwartsenberg, Kevin Murphy, and Frank Wood. Towards mechanistic explanaarXiv preprint tion of diffusion model generalization. arXiv:2411.19339, 2024. 2, 3 [55] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF international conference on computer vision, pages 41954205, 2023. 6, [56] Stefano Peluchetti. Non-denoising forward-time diffusions. arXiv preprint arXiv:2312.14589, 2023. 1, 2 [57] Yansong Peng, Kai Zhu, Yu Liu, Pingyu Wu, Hebei Li, Xiaoyan Sun, and Feng Wu. Flow-anchored consistency models. arXiv preprint arXiv:2507.03738, 2025. 3, 8, 18 [58] Jakiw Pidstrigach. Score-based generative models detect manifolds. Advances in Neural Information Processing Systems, 35:3585235865, 2022. 2, 3 [59] Ben Poole, Ajay Jain, Jonathan Barron, and Ben Mildenhall. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988, 2022. 6 [60] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on machine learning, pages 88218831. Pmlr, 2021. [61] Yuxi Ren, Xin Xia, Yanzuo Lu, Jiacheng Zhang, Jie Wu, Pan Xie, Xing Wang, and Xuefeng Xiao. Hyper-sd: Trajectory segmented consistency model for efficient image synthesis. Advances in Neural Information Processing Systems, 37: 117340117362, 2024. 18 [62] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1068410695, 2022. 1, 2, 3, 16 [63] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115:211252, 2015. 2, 6, 7 [64] Amirmojtaba Sabour, Sanja Fidler, and Karsten Kreis. Align your flow: Scaling continuous-time flow map distillation. arXiv preprint arXiv:2506.14603, 2025. 1, 2, 3, 8, 18 [65] Tim Salimans and Jonathan Ho. Progressive distillation for fast sampling of diffusion models. In International Conference on Learning Representations, 2022. 1, 2, 18 [66] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in neural information processing systems, 29, 2016. 16 [67] Tim Salimans, Thomas Mensink, Jonathan Heek, and Emiel Hoogeboom. Multistep distillation of diffusion models via moment matching. Advances in Neural Information Processing Systems, 37:3604636070, 2024. [68] Axel Sauer, Frederic Boesel, Tim Dockhorn, Andreas Blattmann, Patrick Esser, and Robin Rombach. Fast highresolution image synthesis with latent adversarial diffusion distillation. In SIGGRAPH Asia 2024 Conference Papers, pages 111, 2024. [69] Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach. Adversarial diffusion distillation. In European Conference on Computer Vision, pages 87103. Springer, 2024. 18 [70] Christopher Scarvelis, Haitz Sáez de Ocáriz Borde, and Justin Solomon. Closed-form diffusion models. arXiv preprint arXiv:2310.12395, 2023. 2, 3 [71] Team Seedream, Yunpeng Chen, Yu Gao, Lixue Gong, Meng Guo, Qiushan Guo, Zhiyao Guo, Xiaoxia Hou, Weilin Huang, Yixuan Huang, et al. Seedream 4.0: Toward nextgeneration multimodal image generation. arXiv preprint arXiv:2509.20427, 2025. 2, 3 [72] Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, and Rajesh Ranganath. general framework for inference-time scaling and steering of diffusion models. arXiv preprint arXiv:2501.06848, 2025. 2, 8 [73] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning, pages 22562265. PMLR, 2015. 1, [74] Jiaming Song, Chenlin Meng, and Stefano Ermon. arXiv preprint Denoising diffusion implicit models. arXiv:2010.02502, 2020. 2, 14 [75] Kiwhan Song, Jaeyeon Kim, Sitan Chen, Yilun Du, Sham Kakade, and Vincent Sitzmann. Selective underfitting in diffusion models. arXiv preprint arXiv:2510.01378, 2025. 2, 3 [76] Yang Song and Prafulla Dhariwal. Improved techniques for training consistency models. In The Twelfth International Conference on Learning Representations, 2024. 3, 7, 18 [77] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32, 2019. 2, 15 [78] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021. 1, 2, 5, 14 [79] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya In Proceedings of the Sutskever. Consistency models. 40th International Conference on Machine Learning, pages 3221132252, 2023. 1, 2, 3, 18 [80] Endre Süli and David Mayers. An introduction to numerical analysis. Cambridge university press, 2003. 14 [81] Joshua Tian Jin Tee, Kang Zhang, Hee Suk Yoon, Dhananjaya Nagaraja Gowda, Chanwoo Kim, and Chang Yoo. Physics informed distillation for diffusion models. arXiv preprint arXiv:2411.08378, 2024. 18 [82] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. 16 [83] Pascal Vincent. connection between score matching and denoising autoencoders. Neural computation, 23(7):1661 1674, 2011. 2 11 [84] Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou, Senthil Purushwalkam, Stefano Ermon, Caiming Xiong, Shafiq Joty, and Nikhil Naik. Diffusion model alignment using direct preference optimization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 82288238, 2024. 1, 2, 3 [85] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation. Advances in Neural Information Processing Systems, 36:84068441, 2023. 5, [86] Joseph Watson, David Juergens, Nathaniel Bennett, Brian Trippe, Jason Yim, Helen Eisenach, Woody Ahern, Andrew Borst, Robert Ragotte, Lukas Milles, et al. De novo design of protein structure and function with rfdiffusion. Nature, 620(7976):10891100, 2023. 1 [87] Chenfei Wu, Jiahao Li, Jingren Zhou, Junyang Lin, Kaiyuan Gao, Kun Yan, Sheng-ming Yin, Shuai Bai, Xiao Xu, Yilei Chen, et al. Qwen-image technical report. arXiv preprint arXiv:2508.02324, 2025. 2, 3 [88] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling the generative learning trilemma with denoising diffusion GANs. In International Conference on Learning Representations, 2022. 2 [89] Sirui Xie, Zhisheng Xiao, Diederik Kingma, Tingbo Hou, Ying Nian Wu, Kevin Murphy, Tim Salimans, Ben Poole, and Ruiqi Gao. Em distillation for one-step diffusion models. Advances in Neural Information Processing Systems, 37: 4507345104, 2024. 18 [90] Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai Li, Ming Ding, Jie Tang, and Yuxiao Dong. Imagereward: Learning and evaluating human preferences for textto-image generation. Advances in Neural Information Processing Systems, 36:1590315935, 2023. 1, 2, 3 [91] Yilun Xu, Ziming Liu, Max Tegmark, and Tommi Jaakkola. Poisson flow generative models. Advances in Neural Information Processing Systems, 35:1678216795, 2022. 1, 2 [92] Yilun Xu, Ziming Liu, Yonglong Tian, Shangyuan Tong, Max Tegmark, and Tommi Jaakkola. Pfgm++: Unlocking the potential of physics-inspired generative models. In International Conference on Machine Learning, pages 38566 38591. PMLR, 2023. 1, [93] Yilun Xu, Shangyuan Tong, and Tommi S. Jaakkola. Stable target field for reduced variance score estimation in diffusion models. In The Eleventh International Conference on Learning Representations, 2023. 2 [94] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufogen: You forward once large scale text-to-image generation via diffusion gans. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 81968206, 2024. 18 [95] Yilun Xu, Weili Nie, and Arash Vahdat. One-step diffusion models with -divergence distribution matching. arXiv preprint arXiv:2502.15681, 2025. 6, 18 [97] Tianwei Yin, Michaël Gharbi, Taesung Park, Richard Zhang, Eli Shechtman, Fredo Durand, and Bill Freeman. Improved distribution matching distillation for fast image synthesis. Advances in neural information processing systems, 37: 4745547487, 2024. 6, 15, 18 [98] Tianwei Yin, Michaël Gharbi, Richard Zhang, Eli Shechtman, Fredo Durand, William Freeman, and Taesung Park. One-step diffusion with distribution matching distillation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 66136623, 2024. 6, 15, 16, 18 [99] TaeHo Yoon, Joo Young Choi, Sehyun Kwon, and Ernest Ryu. Diffusion probabilistic models generalize when they fail to memorize. In ICML 2023 workshop on structured probabilistic inference & generative modeling, 2023. 2, [100] Sihyun Yu, Sangkyung Kwak, Huiwon Jang, Jongheon Jeong, Jonathan Huang, Jinwoo Shin, and Saining Xie. Representation alignment for generation: Training diffusion transformers is easier than you think. arXiv preprint arXiv:2410.06940, 2024. 1, 2, 3, 7, 8, 17, 18 [101] Yinan Zhang, Eric Tzeng, Yilun Du, and Dmitry Kislyuk. Large-scale reinforcement learning for diffusion models. In European Conference on Computer Vision, pages 117. Springer, 2024. 1, 2, 3 [102] Boyang Zheng, Nanye Ma, Shengbang Tong, and Saining Xie. Diffusion transformers with representation autoencoders. arXiv preprint arXiv:2510.11690, 2025. 1, 3 [103] Candi Zheng and Yuan Lan. Characteristic guidance: Nonlinear correction for diffusion model at large guidance scale. In International Conference on Machine Learning, pages 6138661412. PMLR, 2024. 6 [104] Hongkai Zheng, Weili Nie, Arash Vahdat, Kamyar Azizzadenesheli, and Anima Anandkumar. Fast sampling of diffusion models via operator learning. In International conference on machine learning, pages 4239042402. PMLR, 2023. 4, 18 [105] Kaiwen Zheng, Yuji Wang, Qianli Ma, Huayu Chen, Jintao Zhang, Yogesh Balaji, Jianfei Chen, Ming-Yu Liu, Jun Zhu, and Qinsheng Zhang. Large scale diffusion distillation via score-regularized continuous-time consistency. arXiv preprint arXiv:2510.08431, 2025. 18 [106] Linqi Zhou, Stefano Ermon, and Jiaming Song. Inductive moment matching. arXiv preprint arXiv:2503.07565, 2025. [107] Mingyuan Zhou, Huangjie Zheng, Yi Gu, Zhendong Wang, and Hai Huang. Adversarial score identity distillation: Rapidly surpassing the teacher in one step. arXiv preprint arXiv:2410.14919, 2024. 6, 18 [108] Mingyuan Zhou, Huangjie Zheng, Zhendong Wang, Mingzhang Yin, and Hai Huang. Score identity distillation: Exponentially fast distillation of pretrained diffusion models for one-step generation. In Forty-first International Conference on Machine Learning, 2024. 6, 18 [96] Mingyang Yi, Jiacheng Sun, and Zhenguo Li. the generalization of diffusion model. arXiv:2305.14712, 2023. 2, 3 On arXiv preprint A. Extended Technical Discussion We continue our technical discussion in Secs. 4 and 5, dividing this section into three parts. A.1. More on the Prediction Objective δfθ(z, δ) u(fθ(z, δ), 1 Optimality of training with Eq. (8). Recall that we have already established that the loss value of Eq. (8) equals π Ez,δ [0, 1]. Furthermore, we note that the parametric relationship fθ(z, δ) = + δFθ(z, δ), which satisfies fθ(z, 0) = and δ π by design. We show that, assuming standard regularity conditions on u, we ensure ϕu is uniquely defined via an for all initial value problem by the Picard-Lindelöf theorem [8], thus providing well-defined criterion for fθ. This is direct result of the fundamental theory of ODE. 2. Thus, at optimality, we have δfθ(z, δ) = u(fθ(z, δ), 1 δ) for all δ) [0, 1], Proposition A.1. Let ϕu(xt, t, s) be defined as in Eq. (3), and we assume that there exists some > 0 for all y, r Then, we have fθ(z, δ) = ϕu(z, 1, 1 δfθ(z, δ) = u(fθ(z, δ), 1 . We further assume that fθ(z, δ) is continuously differentiable for δ δ) for all π, δ [0, 1], if and only if, (i) fθ(z, 0) = for all δ) for all u(y, r) [0, 1]. u(y, r) π, δ y Rd and [0, 1]. π, and (ii) Proof. By assuming u(y, r) continuous in and Lipschitz continuous in y, we could apply the Picard-Lindelöf theorem [8] to guarantee the existence and uniqueness of its solution ϕu, which is δ) holds for all δ [0, 1], it must hold for δ = 0. We know that ϕu(xt, t, s) = xt + (cid:90) u(x(τ ), τ )dτ. : = (i). Since the equality fθ(z, δ) = ϕu(z, 1, 1 ϕu(z, 1, 1) = z. Thus, for any π, (ii). Given that fθ(z, δ) = ϕu(z, 1, 1 fθ(z, 0) = ϕu(z, 1, 1) = z. differentiable with respect to δ on [0, 1], their derivatives with respect to δ must be equal. That is, for all δ) for all δ [0, 1], and both fθ(z, δ) and ϕu(z, 1, 1 δ) are continuously π, δ [0, 1], δfθ(z, δ) = dδ ϕu(z, 1, 1 δ) = u(ϕu(z, 1, 1 =: Since fθ(z, 0) = for all solution to the initial value problem on the interval δ π, and δfθ(z, δ) = u(fθ(z, δ), 1 [0, 1]: δ), 1 δ) = u(fθ(z, δ), 1 δ). δ) for all π, δ [0, 1], we know that fθ(z, δ) is dδ fθ(z, δ) = u(fθ(z, δ), δ), fθ(z, 0) = z. δ) is also solution to the same IVP on [0, 1]. Thus, we arrive at the equality between fθ(z, δ) By definition, ϕu(z, 1, 1 and ϕu(z, 1, δ). Discrete-time objective. In Sec. 4.1, we skipped over the development of more flexible discrete-time training objective for Eq. (8), which does not require efficient JVP implementations. First, recall that our default continuous-time objective is Ez,δ Fθ(z, δ) + sg δδFθ(z, δ) (fθ(z, δ), 1 δ) 2 . (13) (cid:13) (cid:13) (cid:13) (cid:16) Specifically, we can discretize the time horizon and approximate the partial derivative δFθ using finite differences. Following the common practice in the sampling procedure of flow models [22], we divide the time horizon into intervals with + 1 ti), or equivalently boundary points: 1 = t1 > t2 > ti) where 1 tb fθ(z, t1 to δa,b, we have the following discrete-time objective: > tN +1 = 0. We note that the generating velocity at point fθ(z, 1 (fθ(z, t1 ti)). Short-handing ta , can be approximated by fθ(z, t1 1 ti+1 ti ti+1) (cid:17) (cid:13) (cid:13) (cid:13) Ez,i Fθ(z, δ1,i+1) + sg (cid:13) (cid:13) (cid:13) (cid:13) Fθ(z, δ1,i+1) δi,i+1 Fθ(z, δ1,i) δ1,i (cid:18) 13 (fθ(z, δ1,i), ti) 2 , (14) (cid:19) (cid:13) (cid:13) (cid:13) (cid:13) which approximates Eq. (8) as δi,i+1 note that the loss value of Eq. (14) is the same as Ez,i (fθ(z, δ1,i+1) simplify the notations, we arrive at the following optimization gradients in Eq. (9): 2, we δ) 2, where fθ(z, δ1,i)) /δi,i+1 is the models generating velocity, approximating δfθ(z, δ). If we use vG to further 0. Just like Eq. (13) equals to Ez,δ (fθ(z, δ1,i+1) δfθ(z, δ) fθ(z, δ1,i)) /δi,i+1 u(fθ(z, δ), 1 (fθ(z, δ1,i), ti) θ Ez,δ Fθ(z, δ)sg (cid:20) vG fθ(z, δ), 1 δ fθ(z, δ), 1 (cid:1) (cid:0) vG ,u(fθ(z,δ),1 δ) δ , (cid:17)(cid:21) (cid:1) (15) (cid:16) (cid:0) (cid:124) (cid:123)(cid:122) (cid:125) Error analysis. With discrete-time objective, we essentially train the student to trace numerically integrated trajectory by an ODE solver. More concretely, the loss function inherently mimics specific solver, whose error rate depends on the technique deployed. As written, Eq. (14) can be understood as using an Euler method [74, 78] for solving the flow, specified at time steps t1, t2, . . . , tN . Similar to existing fast-solver literature, we could readily adapt the objective using higher-order finite differences to mimic more precise, higher-order solvers [28, 46]. The classical theory from numerical analysis [80] ((δmax)p), where indicates that local truncation error at ti bounded by δmax := maxi δi,i+1 = maxi(ti ti+1) is the maximum step size. This component is the discretization error, which is entirely independent of the networks approximation error (the inevitable training inaccuracy discussed in Sec. 4.1). Together, these two errors represent the total deviation of the students trajectory from the true teacher flow defined by u. The total error can also be shown [5] to directly control the Wasserstein distance between the generative distribution of the student and the teacher. ((δi,i+1)p+1) leads to the global error rate is ti+1) Number of discretization steps. The above discussion suggests that one 0, and as precise should take as small step as possible, (ti solver as possible, for the discretization error to be minimal. This means that we should use the continuous-time setup if allowed, and for the discrete-time setting, we should choose to use large number of discretization steps . However, this is not the trend we observe in practice. Surprisingly, larger after certain point actually degrades the performance. We attribute this behavior to the accumulated approximation error (discussed in Sec. 4.1) made by the model. Since is evaluated at the models prediction, the goodness of the trajectory implicitly depends on the quality of fθ itself, and such problem exacerbates as becomes larger. We further note that incorporating higher-order solvers in like the Heun method [28] is helpful, as it significantly reduces the discretization error. Fortunately, in Fig. 9, we observe that while the model is sensitive to the number of discretization steps and solver choices when training with Eq. (9) alone, the corrective signal in Eq. (11) effectively renders such decision unimportant, making our final proposal robust against and the precision of solvers. Sampling of δ. Another important aspect of the training algorithm is the time sampling of δ. On one hand, the correctness of the model propagates from small jumps δ = 0 to large jumps δ = 1. On the other hand, the highfrequency features of the images only emerge at lower noise level (large δ). To balance these two notions, we investigate mixture of logit-normal distribution [11, 28] and fixed value of δ = 0 (effectively dropout on δ). Results are presented in Tab. 3. Note that for the discrete-time setting, we apply an additional step of the floor operation with respect to our predefined set of discrete time steps. Confident region warmup. We observe that naively optimizing with Eq. (9) brings about instability early on in training, mainly with the JVP approach. We hypothesize that it is because is evaluated at state predicted by fθ, which can be out-of-distribution for at initialization. We propose to add noise to the δ), predicted state before feeding it to u. Specifically, we replace u(fθ(z, δ), 1 with u(Itc is the generalized interpolating function, transition kernel that takes samples from the noise level of to tc. δ(fθ(z, δ), n), tc), where Itc 1 14 Figure 9. Effects of discretization steps and solver type. Our correction objective in Eq. (11) makes the model robust against both. % of δ = 0 δ sampling 10% 0% 30% 50% 10% 10% 10% 0% 0% 0% LogitNormal(0, 1) LogitNormal(0, 1) LogitNormal(0, 1) LogitNormal(0, 1) LogitNormal(-0.8, 1) LogitNormal(-0.4, 1) LogitNormal(0, 1.2) LogitNormal(-0.8, 1.6) LogitNormal(-0.4, 1.6) LogitNormal(0, 1.6) FID 12.40 47.09 13.19 14.30 13.78 12.98 12. 13.43 12.98 12.59 Table 3. Ablation of δ sampling. mixture of logit-normal and fixed δ=0 works well. tc)2 t)2 t2n, assuming tc > t; if For the linear interpolation scheme [40, 43, 50], we have Itc t, it simply does nothing and returns xt. At the start of training, we linearly decrease tc from 1 to 0 over short warmup tc of 10K steps. Intuitively, this procedure ensures that always operates in region where it is confident. After the inclusion of this warmup period, we do not find any instability of training fθ with reasonable sampling distribution of δ. t(xt, n) = 1 1 tc xt + t2 (1 (1 (cid:113) A.2. More on the Correction Objective From minimizing IKL to aligning the noising velocities. We know from prior works [48, 98] that minimizing Eq. (10) w.r.t. θ gives us the following gradient: Er,xr ( θxr) ( xr log qr(xr) (cid:104) xr log pr(xr)) (cid:105) , (16) xr log qr(xr) and where xr log pr(xr) are the score functions [25, 77] of qr and pr respectively. It has also been shown that there exists direct bijective translation between the score functions and the marginal velocities [50]. Specifically, for the linear interpolation scheme [40, 43, 50] and our definition of the conditional velocity, we have: u(xr, r) = xr log pr(xr) = 1 r xr log pr(xr) + xr. u(xr, r) 1 1 xr Additionally, recall that the student predicts the data sample as fθ(z, 1). With average velocity parameterization, the intermediate state is thus xr = Ir(fθ(z, 1), n) = (1 r)(z + Fθ(z, 1)) + rn. Thus, we could rewrite Eq. (16) as Er,xr r)2 (1 (cid:20) ( θFθ(z, 1)) vN Ir(fθ(z, 1), n), Ir(fθ(z, 1), n), (cid:0) (cid:0) (cid:1) (cid:0) , (cid:21) (cid:1)(cid:1) where vN is the marginal noising velocity induced by the students generated distribution q, similar to with p. Dropping the weighting (1 , as it does not change the optimal solution and provides us with easier-to-control gradients, we arrive at Eq. (11). Note that different interpolation scheme does not change our investigation. r)2 θ Ez,n,r Fθ(z, 1)sg (cid:20) vN (cid:16) (cid:0) Ir(fθ(z, 1), n), Ir(fθ(z, 1), n), vN ,u(Ir(fθ(z,1),n),r) (cid:1) (cid:0) (17) . (cid:17)(cid:21) (cid:1) (cid:125) (cid:124) (cid:123)(cid:122) Learning rate. Our correction objective defined in Eq. (11) assumes access to vN, which is the velocity of the noising flow starting from the generated distribution, and we approximate it by training an auxiliary model gψ concurrently with Eq. (2). The quality of the optimization signal vN,u depends on the quality of this approximation. Empirically in Tab. 4, we confirm this intuition and observe that the algorithm benefits from having larger learning rate on gψ compared to fθ. We note that it is also possible to adopt two time-scale update rule [19, 97], where we train multiple iterations on gψ before updating fθ, but we do not explore this option given the overhead. In related vein, we find that while training with only the prediction objective in Eq. (9) permits wide range of learning rates, incorporating the correction objective in Eq. (11) 4 in SiT). prefers smaller one on fθ (adopted 3 5 compared to 1 10 10 learning rate for gψ FID 3 105 6 105 8 105 1 104 8.28 5.77 5.72 5.63 Table 4. Ablation of gψs lr. higher lr compared to fθs one (3 105) is better. Additional note on sampling of in Eq. (11). Recall that our understanding of Eq. (11) with PDE perspective through the continuity equation in Sec. 5.1 leads to our design of sampling more in the higher noise levels. We would like to make brief note that, similar to Eq. (9), if Fθ is further parameterized, we should replace the first term in Eq. (11) with the actual network output. Additionally, one needs to ensure vN,u across different values are roughly on the same scale first, so that their actual contributions can be precisely controlled via the sampling of r. Concretely, for our case of the linear interpolation and velocity parameterization [40, 43, 50], vN,u is really just the difference between the direct outputs of two neural networks, which does not require further manipulations, assuming the network outputs are of consistent scale. In comparison, another 15 Figure 10. Performances across different guidance strength parameter γ in terms of FID () and Inception Score (). 1 xr + cout(r) commonly used setup is the EDM parameterization [28], whose velocity at (xr = fθ(z, 1) + rn, r), cskip(r) π is of the form G, where is the actual network (the auxiliary or teacher model). Notice that the outputs of are by design of constant norm across r, so the magnitude of vN,u is proportional to cout(r) . In Yin et al. [98], an additional weighting of is applied, which makes the overall gradient contributions from Eq. (11) proportional to cout(r). Substituting in the actual terms used, we have 0.52+r2 , which heavily downplays the effect of small (lower noise levels). 0.5r A.3. More on How to Combine Both Additional schedule on α. We set α = 0 for the first 10K steps (recall that the prediction objective has warmup of 10K steps), and follow it with linear warmup of another 10K steps before α settles at reference value αref. While the model performance is shown to be robust across wide range of α in Fig. 6, we further notice general trend that larger α learns faster in the beginning of training, and smaller α converges better as the training continues. Hence, for our REPA distillation tasks, we try out simple inverse square root decay [30, 33], and arrive at the following schedule on α: α = αref clip Tdelay Twarmup , 0, 1 (cid:16) (cid:17) max(n/Tdecay, 1) , where is the current training iteration, Tdelay = Twarmup = 10K, and Tdecay is the hyperparameter that controls the decay rate with indicating no decay applied (α stays at the constant value αref after warmup). We also would like to clarify that, considering the adopted 75-25 split, an α value of 0.3 really means that the gradient contribution of the correction objective is around 10% of that of the prediction objective. (cid:112) Additional empirical results on prediction and correction synergy. In addition to presenting the model progress in Fig. 7, we list the final performances of training with only prediction Eq. (9), only correction Eq. (11), and both in Tab. 5. Specifically, all models are distilled from SiT-XL/2 [50], and we compare them in terms of FID [19] and Inception Score [66] at 1.5M iterations (300 epochs). For each method, we select the optimal γ based on the FID performances. Recall from Fig. 7, at this point in training, although Eq. (9) makes progress, its absolute performance still lags far behind the other two configurations because of the significant error accumulation. In contrast, Eq. (11) has already suffered from mode collapse, and its diversity continues to deteriorate. B. Implementation Details objective FID IS Eq. (9) Eq. (11) Eqs. (9) and (11) 5.78 3.19 1.69 257.02 258.15 273.49 Table 5. Synergy between Eqs. (9) and (11). Together, they achieve performance that neither could attain in isolation. Training. We follow the standard practice and train our models in the latent space of the VAE used in Rombach et al. [62]. The 2 patches. Recall that the standard input to flow model model architecture we use is based on standard DiT [55] with 2 for ImageNet is fθ(xt, t, c) (c is the class label), and we need to include two additional scalar inputs: jump duration δ and guidance strength γ. That is, during both training and inference, the model follows fθ(z, 1, c, δ, γ). Thus, we add few layers to handle these additional conditions. For both, we follow the standard design for including scalar input. Specifically, we use 256-dimensional frequency embedding [9, 82] followed by two-layer SiLU-activated MLP with the same dimensionality as the models hidden size. We then add all four embeddings from t, c, δ, and γ together (the newly added ones, δ and γ, are initialized at 0) and feed the sum to each block. The same goes for gψ, where it is modified to take input gψ(xt, t, c, γ) as it needs to track different noising flows from different γ of fθ. No further architecture changes are necessary for stable and 16 Table 6. Detailed experimental configurations of our main results. SiT-XL/2 [50] SiT-XL/2+REPA [100] 256256 512 256256 512512 1.5M (300) 1M (200) 1.5M (300) 1M (200) 256 Adam [33] (0.9, 0.99) 1 108 0.0 0.0 constant 3 105 constant 1 104 0.9999 678 119 525 119 28 1152 16 22 additional input for δ and γ in fθ; additional input for γ in gψ Task teacher model resolution General iterations (epochs) batch size optimizer optimizer betas optimizer eps weight decay dropout fθ learning rate gψ learning rate EMA decay Network params (M) FLOPs (G) depth hidden dim heads patch size change from teacher Training Specific to Eq. (9) confident region warmup duration δ type δ sampling % of δ = 0 type Specific to Eq. (11) sampling guidance interval Relevant to both Eqs. (9) and (11) split between Eqs. (9) and (11) γ range αref αref schedule (Tdelay, Twarmup, Tdecay) 10K discrete; uniform; N=8 LogitNormal(0, 1) LogitNormal(-0.4, 1.2) 10% Heun solver [28] [0, 0.4] [0, 0.5] [0, 0.3] [0, 0.3] LogitNormal(0.8, 1.6) 75% : 25% [1, 2] 0.3 (10K, 10K, ) 0.6 (10K, 10K, 25K) effective training. For each of our reported entries listed in Tab. 2, we present their implementation details in Tab. 6. All model trainings are done with an internal JAX codebase on TPU. Evaluation. We observe small performance variations between TPU-based FID evaluation and GPU-based FID evaluation (ADMs TensorFlow evaluation suite [9]6). To ensure fair comparison with the baseline methods, we convert all of our models into PyTorch, sample all of our models on GPU, and obtain FID scores using the ADM evaluation suite for reporting the final results of our XL-size models in Tabs. 2 and 5 and Fig. 10. Additionally, since our model is trained on range of (1, 2), we can efficiently sweep for an optimal value during inference. We report the best FID in guidance strengths γ Tab. 2, and provide the complete performance curves in Fig. 10. 6https://github.com/openai/guided-diffusion/tree/main/evaluations 17 C. Related Work Among the existing distillation approaches, BOOT [16] stands as the most closely related precursor, sharing the distinct operational characteristic of being data-free. However, our works diverge fundamentally in their conceptual positioning and the identified imperative for removing data. BOOT frames the data-free property primarily as practical/logistical advantage, emphasizing the benefits of bypassing the storage and privacy burdens associated with massive, proprietary training sets. In contrast, we argue that the exclusion of data is not merely convenience but theoretical necessity for ensuring distributional fidelity. We elevate the data-free paradigm from strategy of efficiency to one of correctness, presenting it as the rigorous solution to the identified Teacher-Data Mismatch. Our proposed method also differs significantly from BOOT and its subsequent improvements, which are not necessarily data-free in nature. In particular, Gu et al. [16] focuses on the specific signal-ODE parameterization, which requires separate loss just to enforce the boundary condition fθ(z, 0) = z. In comparison, our prediction objective stems from the properties of average velocity [14], which satisfy the boundary condition by design. Tee et al. [81] and the Lagrangian objective in Boffi et al. [5] consider more general ODE formulations. Their optimization involves costly computations of the gradients over the partial derivatives δfθ, whereas ours does not (the partial derivatives in Eq. (8) are placed inside the stop-gradient operation). This improved training efficiency also originates from the average velocity perspective and our deduced identity in Eq. (7). Furthermore, we introduce an auxiliary correction objective for the accumulated prediction errors, pushing the model performance beyond the current state-of-the-art. In doing so, we believe our work finally completes the picture, validating the data-free paradigm as robust and promising foundation for the future of generative model acceleration. Our contribution sits within much broader body of literature dedicated to accelerating diffusion and flow models. These techniques generally fall into two categories based on their distillation targets. The first category operates at the trajectory level, attempting to compress the complex ODE integration into fewer steps by directly mimicking the sampling path or its solution operator [47, 104]. The foundational work of Progressive Distillation [52, 65] further established the viability of this direction through an iterative strategy that progressively halves the required sampling steps. This paradigm was significantly expanded by Consistency Models [3, 45, 76, 79], which enforce property of self-consistency along the trajectory, allowing the model to map arbitrary intermediate states directly to the data origin. More recent approaches [5, 7, 13, 14, 17, 32, 36, 37, 4244, 57, 61, 64] have further refined this objective by formulating direct matching conditions between the students transport map and the teachers vector field. The second category operates at the distribution level [48, 49, 6769, 89, 94, 95, 97, 98, 107, 108], where the student is trained to match the teachers marginal distribution directly, often utilizing adversarial or score-based objectives without strictly adhering to the teachers specific trajectory. We make contributions in both directions by proposing an efficient algorithm for distilling trajectories without data and elucidating additional design spaces for better distribution matching objectives. Together, our proposed predictor-corrector framework can be seen as combining the strengths of the two categories [45, 105], achieving superior quality while maintaining desired diversity, all without reliance on external data. D. Additional Visual Results In Figs. 11 to 18, we present additional uncurated samples generated by FreeFlow-XL/2 at 512 512 resolution with only 1-NFE. Again, we emphasize that, during training, we only make use of the teacher model (SiT-XL/2+REPA [100]), without querying any samples from ImageNet. 18 Figure 11. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = robin (15) Figure 12. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = Siberian husky (250) 19 Figure 13. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = barn (425) Figure 14. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = desktop computer (527) 20 Figure 15. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = dogsled (537) Figure 16. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = fire truck (555) 21 Figure 17. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = lakeside (975) Figure 18. Uncurated 512512 samples by FreeFlow, 1-NFE. Class label = volcano (980)"
        }
    ],
    "affiliations": [
        "MIT",
        "NYU"
    ]
}