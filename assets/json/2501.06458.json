{
    "paper_title": "O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning",
    "authors": [
        "Zhongzhen Huang",
        "Gui Geng",
        "Shengyi Hua",
        "Zhen Huang",
        "Haoyang Zou",
        "Shaoting Zhang",
        "Pengfei Liu",
        "Xiaofan Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Building upon our previous investigations of O1 replication (Part 1: Journey Learning [Qin et al., 2024] and Part 2: Distillation [Huang et al., 2024]), this work explores the potential of inference-time scaling in large language models (LLMs) for medical reasoning tasks, ranging from diagnostic decision-making to treatment planning. Through extensive experiments on medical benchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical Challenges), our investigation reveals several key insights: (1) Increasing inference time does lead to improved performance. With a modest training set of 500 samples, our model yields substantial performance improvements of 6%-11%. (2) Task complexity directly correlates with the required length of reasoning chains, confirming the necessity of extended thought processes for challenging problems. (3) The differential diagnoses generated by our model adhere to the principles of the hypothetico-deductive method, producing a list of potential conditions that may explain a patient's symptoms and systematically narrowing these possibilities by evaluating the evidence. These findings demonstrate the promising synergy between inference-time scaling and journey learning in advancing LLMs' real-world clinical reasoning capabilities."
        },
        {
            "title": "Start",
            "content": "O1 Replication Journey Part 3: Inference-time Scaling for Medical Reasoning Zhongzhen Huang1,3* Gui Geng3* Shengyi Hua1,3* Zhen Huang4* Haoyang Zou4* Shaoting Zhang1 Pengfei Liu1,2,4 Xiaofan Zhang1,3 1Shanghai Jiao Tong University , 2SII, 3SPIRAL Lab, 4Generative AI Research Lab (GAIR),"
        },
        {
            "title": "Abstract",
            "content": "Building upon our previous investigations of O1 replication (Part 1: Journey Learning (Qin et al., 2024) and Part 2: Distillation (Huang et al., 2024)), this work explores the potential of inference-time scaling in large language models (LLMs) for medical reasoning tasks, ranging from diagnostic decision-making to treatment planning. Through extensive experiments on medical benchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical Challenges), our investigation reveals several key insights: (1) Increasing inference time does lead to improved performance. With modest training set of 500 samples, our model yields substantial performance improvements of 6%-11%. (2) Task complexity directly correlates with the required length of reasoning chains, confirming the necessity of extended thought processes for challenging problems; (3) The differential diagnoses generated by our model adhere to the principles of the hypothetico-deductive method, producing list of potential conditions that may explain patients symptoms and systematically narrowing these possibilities by evaluating the evidence. These findings demonstrate the promising synergy between inference-time scaling and journey learning in advancing LLMs real-world clinical reasoning capabilities. Resources are available at https://github.com/SPIRAL-MED/Ophiuchus, which is part of O1 Journey Project. 5 2 0 2 1 1 ] . [ 1 8 5 4 6 0 . 1 0 5 2 : r Figure 1: Illustration of our O1 replication journey in the medical field. of deep scientific thinking, ultimately enabling AI-driven breakthroughs in medical domains. which aims to develop systems capable * Co-first authors Corresponding author"
        },
        {
            "title": "Introduction",
            "content": "Medicine is an endeavor that fundamentally involves complex reasoning, spanning tasks from diagnostic decisionmaking to treatment planning. Intricate reasoning is particularly crucial in medical scenarios where patient outcomes depend on understanding multifactorial conditions (Singhal et al., 2023; Qiu et al., 2024). The process of differential diagnosis (Seller and Symons, 2011) exemplifies this complexity, requiring physicians to generate list of potential diagnoses and methodically narrow it down by evaluating clinical findings and excluding options that do not align with the evidence. This process demands not only deep clinical knowledge but also the ability to draw logical inferences and evaluate multiple hypotheses based on available evidence. In recent years, the emergence of large language models (LLMs) holds significant promise for advancing clinical applications. However, the complexity of medical reasoning poses unique challenges that traditional scaling methodssuch as increasing model parameters or training data volume (Kaplan et al., 2020; Brown et al., 2020; Chowdhery et al., 2023)struggle to address effectively. Recent studies (Snell et al., 2024; OpenAI, 2024) have demonstrated that scaling inference time can lead to more efficient improvements in LLM performance. This approach, known as inference-time scaling, allows more processing time for complex tasks, enabling step-by-step problem-solving and iterative refinement of the reasoning process. OpenAIs O1 (OpenAI, 2024) particularly emphasizes this strategy by scaling inference time to generate long thoughts for complex reasoning. While previous studies (Huang et al., 2024; Jiang et al., 2024; Zhang et al., 2024a,b; Kimi, 2024; o1 Team, 2024; Team, 2024b) have validated inference-time scaling in various domains such as mathematical reasoning, its application to medical scenarios presents unique opportunities and challenges. Building on our previous work on journey learning (Qin et al., 2024), we posit that complex clinical scenariosrequiring integration of established knowledge with nuanced patient histories and comorbiditiesnecessitate even longer reasoning processes. Our initial explorations demonstrated significant improvements (Figure 1) when scaling inference time to account for multiple clinical factors and iteratively refine diagnostic strategies. This work examines how LLMs with inference-time scaling adapt to varying task complexities in medicine, focusing on two key aspects: (1) identifying optimal scenarios for assessing performance variations with inference-time computing, and (2) developing effective methods to synthesize supervised fine-tuning data for generating extended reasoning chains. To validate our approach, we utilize public medical benchmarks proposed by (Chen et al., 2024), encompassing challenging clinical cases and medical licensing examinations. key challenge lies in enabling effective journey learning during inference. Building on previous work (Huang et al., 2024), we employ straightforward yet effective knowledge distillation approach (Hinton, 2015) from GPT-series models. Key findings from our experiments include the following: (1) majority voting provides straightforward approach to augment inference-time computation, though its effectiveness is constrained in complex scenarios; (2) effective scaling of inference time, however, depends on the sufficient capacity of LLMs, otherwise, such efforts are likely to be in vain; (3) tasks with greater complexity necessitate longer reasoning processes, reinforcing the need for extended thought chains as task difficulty increases; and (4) removing multiple-choice options and encouraging free-form responses unlocks the potential for medical journey learning, fostering nuanced clinical reasoning. Looking ahead, the integration of inference-time scaling into clinical applications presents both opportunities and challenges. Our work underscores the potential of this approach to address complex medical tasks, but it also highlights the need for continued exploration and innovation. By releasing key findings, distilled datasets, and experimental methodologies, we aim to contribute to the broader AI research community and foster collaborative advancements. Furthermore, we advocate for research ethos rooted in transparency, originality, and rigorous evaluation, particularly as AI systems become more deeply embedded in critical domains like healthcare. While the distillation strategy and its implications warrant further scrutiny, we hope this study catalyzes future investigations into inference-time scaling and its capacity to enhance the reasoning capabilities of LLMs. Ultimately, our goal is to inspire new methodologies and applications that bridge the gap between computational innovation and practical medical impact, ensuring better outcomes for patients and practitioners alike."
        },
        {
            "title": "2 Exploration Process",
            "content": "The conclusion derived from analyzing examples provided by OpenAI 1 demonstrates that as the difficulty increases, the inference time tends to grow proportionally (Qin et al., 2024). This suggests that higher-difficulty problems require more reasoning steps, which in turn necessitate longer inference time. Although the exact mechanisms through which inference-time scaling enhances problem-solving remain underexplored, it is evident that inference-time scaling contributes significantly to identifying and analyzing key information. This phenomenon is particularly critical in medical domains, where clinicians require much time to process data from multiple sources and modalities when diagnosing conditions, making prognostic evaluations, and determining treatment plans. In 1https://openai.com/index/learning-to-reason-with-llms 2 the following parts, we document our exploration of evaluating the utility of inference-time scaling in addressing complex, domain-specific challenges in medicine. 2.1 Benchmark Overview To demonstrate the effectiveness of inference-time scaling in addressing medical problems, we selected three benchmarks in (Chen et al., 2024) for our experiments: the JAMA Clinical Challenge (JAMA), Medbullets, and MedQA. These benchmarks encompass challenging real-world clinical cases from various medical domains as well as medical licensing exams of different difficulty levels. The JAMA dataset includes 1,524 examples collected from the JAMA Network Clinical Challenge 2 archive, spanning the past decade (July 2013October 2023) and covering 13 medical domains. The examples are based on complicated clinical scenarios involving patient history, family history, laboratory results, physical/radiology/cardiology analysis, etc., and hence require more sophisticated understanding and reasoning to arrive at correct diagnosis. At this stage, our primary goal is to examine the effectiveness of inference-time scaling on complex tasks. Therefore, we focused on cases that o1-mini struggles with. Specifically, we utilized streamlined subset of JAMA containing 646 cases, half of which are challenging for o1-mini, for evaluation. The Medbullets and MedQA datasets in use are based on the National Medical Board Examination in the United States or the United States Medical Licensing Examination (USMLE). Medbullets is an online platform that provides medical study resources. The dataset focuses on Medbullets Step 2/3 3 which serves USMLE Step 2&3 4 type questions. The resolution of the questions in Step 2/3 demands the application of medical knowledge and clinical reasoning rather than relying solely on textbook knowledge (Step 1 questions). The dataset consists of 308 examples posted on the (formerly Twitter) 5 platform between April 2022 and December 2023. Each comprises case description, question, five answer choices, and an explanation that explains each option. MedQA also includes questions from the Medbullets website but without the aforementioned explanations. The test set includes 679 Step 1 6 questions and 594 Step 2/3 questions, obtained in March 2021, ensuring that there is no overlap with the Medbullets dataset. The involvement of these two datasets provides insights into whether inference-time scaling helps or hinders tackling medical tasks of various difficulty levels, and how it takes effect. 2.2 Journey Learning Data Synthesis To enable LLMs to perform journey learning during the problem-solving process, we need to construct collection of high-quality demonstration data that exhibits this behavior. Building on prior efforts, we adopted distillationbased approach for producing high-quality data. In the era of LLMs, instructing weaker models using stronger ones is common practice for advancing models. Recent research (Taori et al., 2023; Xu et al., 2023; Gunasekar et al., 2023) highlights that fine-tuning with high-quality data synthesized from proprietary models can achieve remarkable outcomes. In our exploration, we utilized o1 to collect journey learning data, synthesizing two types of long-form data: LongStep and LongMonolog. LongStep: Upon analyzing responses from o1 and GPT-4o, we observed that o1 generates longer solution steps that include more detailed processes for analyzing key information. Given o1s exceptional performance and sophisticated reasoning capabilities, we extracted its solution steps to train LLMs to emulate this behavior, producing more thorough and detailed solutions. LongMonolog: In practice, the examples provided by OpenAI often exhibit relatively flexible, sometimes colloquial, inner monolog style. However, the internal thought processes of o1 cannot be directly accessed because it summarizes these processes before presenting them to the user. Despite this, its summarized internal thoughts are still valuable, as they outline the key stages of problem-solving. That said, the summarized thoughts are not directly suitable for training. Inspired by (Huang et al., 2024), we designed prompts to instruct o1-preview to expand its summarized thoughts into long-form reasoning. Careful prompt design is essential, as o1 imposes restrictions on accessing its internal reasoning processes. The resulting output adheres to specific guidelines, ensuring that the solutions resemble an inner monologue, are highly detailed and reflective, including self-corrections, and exhibit extended reasoning. After collecting labeled data, we performed further preprocessing to ensure data quality and standardization of output formats. At the current stage, our primary goal is to evaluate the role of inference-time scaling in addressing medical problems. Our objective is not to directly perform differential diagnosis, which we acknowledge as extremely difficult given the limited information and resources available. In real-world scenarios, differential diagnosis aligns with the principles of the hypothetico-deductive method, where potential diseases or conditions are treated as 2https://jamanetwork.com/collections/44038/clinical-challenge 3https://step2.medbullets.com/ 4https://www.usmle.org/step-exams/step-2-ck 5https://x.com/medbullets 6https://step1.medbullets.com/ 3 hypotheses that clinicians evaluate to determine their validity. To simplify the task, we adopt multiple-choice datasets in this section, allowing potential diagnoses (the differential) can be predefined to guide the model in generating hypotheses. We opt not to use in-house data, as real-world clinical scenarios often contain substantial amount of irrelevant information that can interfere with reasoning. This poses great challenge for current models. In contrast, public benchmarks simplify the problem and eliminate some of this interference. Moreover, the choices from MedQA and JAMA are carefully designed to be similar and plausible options. In analyzing these options to determine the final answer, the process closely mirrors the thought process involved in clinical diagnosis. Moreover, the key factor in data selection was the length of the problem-solving process. We excluded cases with short thought process. Collectively, we assembled training dataset consisting of 500 examples, with 350 drawn from the training set of MedQA (Jin et al., 2020) and 150 from the remaining set of the JAMA Clinical Challenge. The average length is 729 for the curate LongStep dataset and 1,223 for the LongMonolog dataset, respectively. Examples of our distilled data are presented in Figures 9, 11 and 12. Model Name Param. Size Mean Acc. JAMA (646) Medbullets (308) MedQA (1273) Acc. #Avg. Token Acc. #Avg. Token Acc. #Avg. Token GPT-4o GPT-4o-Vanilla CoT o1-mini o1-preview Qwen2.5 Qwen2.5-Vanilla CoT InternLM2.5 InternLM2.5-Vanilla CoT LLama3.1 InternLM2.5 InternLM2.5-Vanilla CoT Qwen2.5 Qwen2.5-Vanilla CoT LLama3.1 LLama3.1-Vanilla CoT Qwen2.5 Qwen2.5-Vanilla CoT Qwen2.5-CoT SFT LLama3.1-CoT SFT Qwen2.5-CoT SFT Qwen2.5-LongStep Qwen2.5-LongMonolog LLama3.1-LongStep LLama3.1-LongMonolog Qwen2.5-LongStep Qwen2.5-LongMonolog - - - - 7B 7B 7B 7B 8B 20B 20B 32B 32B 70B 70B 72B 72B 32B 70B 72B 32B 32B 70B 70B 72B 72B Proprietary 63.77 63.77 50.00 73. - 335 - - Open Source Models 42.41 40.40 39.78 34.05 46.67 43.34 42.41 49.84 50.92 59.59 57.27 50.15 50.15 - 371 - 303 - - 312 - 351 - 529 - 435 80.01 81.83 77.45 87.95 51.23 49.61 45.84 42.47 55.71 51.90 51.18 64.20 65.86 71.39 73.59 65.82 69. 77.92 81.68 80.51 89.28 46.75 46.42 43.18 38.63 49.43 49.02 46.01 59.74 61.68 67.85 66.55 63.63 65.58 Supervised Fine-tuning with Vanilla CoT 67.13 74.48 70.94 70.08 70.23 76.59 77.36 75.51 77.18 52.16 56.03 53. 383 386 402 Ours (Journey Learning) 56.34 53.71 60.21 59.44 58.66 59.28 759 1098 819 1153 762 1076 61.03 72.07 67.20 66.23 68.50 74.67 77.27 72.07 76. - 323 - - - 353 - 273 - - 330 - 332 - 496 - 387 340 342 355 645 1023 721 1029 692 917 88.76 91.04 90.65 95.12 56.79 55.06 49.56 48.15 61.82 56.95 56.87 72.58 74.46 78.24 83.11 74.31 79. 76.19 84.44 80.91 78.00 79.02 85.38 86.48 84.91 86.48 - 300 - - - 344 - 291 - - 323 - 329 - 477 - 375 323 333 346 615 997 669 953 631 Table 1: Performance comparison of proprietary, open-source, and supervised fine-tuned models across three medical benchmarks. The metrics include accuracy (Acc.) and average output token length (Avg. Token). Mean Acc. represents the weighted average across the three datasets. The best score excluding closed-source APIs was bolded, and the second-best score was underlined. 4 Figure 2: Weighted mean accuracy of Qwen2.5-72B-Instruct, LLama3.1-70B, and Qwen2.5-32B across three datasets using distinct strategies."
        },
        {
            "title": "3 Experiments",
            "content": "3.1 Implementation Details In our pilot studies, we found that current open-source LLMs still lag significantly behind commercial closedsource APIs. Considering resource constraints and the need to share our results with the community promptly, we selected Qwen2.5-32B-Instruct (Team, 2024a), Qwen2.5-72B-Instruct (Team, 2024a) and LLama3.1-70BInstruct (AI@Meta, 2024) as our base models due to their foundational capabilities in medicine. This foundational knowledge ensures solid starting point for subsequent long reasoning processes and improvements. We utilized Llama-Factory (Zheng et al., 2024) to perform instruction tuning on the LLMs with LoRA (Hu et al., 2021). Additionally, we employed DeepSpeed optimization (Rasley et al., 2020) with ZeRO-3 configuration. Following the methodology outlined in (Qin et al., 2024; Huang et al., 2024), we set the number of training epochs to three. All LLMs were fine-tuned on 8 NVIDIA A800 GPUs using learning rate of 1 104 and batch size of 8. 3.2 Main Results In this study, we present comprehensive performance comparison of various methods on the evaluation benchmarks listed in Table 1. The results include performance metrics for proprietary APIs, open-source baselines, and several models fine-tuned on our synthesized data. In Table 1, the rows with the -Vanilla CoT suffix indicate models or APIs that solve problems step by step using Chain-of-Thought prompts according to (Wei et al., 2022). We selected models that benefit from introducing reasoning process (highlighted in red) for further experiments. The rows marked in orange (-CoT SFT suffix) show the result of models trained with vanilla CoT from GPT-4o. The rows marked in blue correspond to models, with the -LongStep suffix and -LongMonolog suffix, fine-tuned on our two journey learning datasets. Additionally, we measure the average token count of each models outputs via tiktoken. 7 This is crucial for evaluating the effectiveness of inference time scaling schemes. The results demonstrate that these methods significantly improve model performance even with minimal training data. These findings highlight the effectiveness of inference-time computing in enhancing the complex reasoning capabilities of LLMs for addressing medical challenges. more detailed analysis can be seen in the next sections. 3.3 Does Inference-time Scaling Help? To intuitively illustrate the contribution of inference-time computing, we present the accuracy of Qwen2.5-72B, LLama3.1-70B, and Qwen2.5-32B across three datasets using distinct strategies: vanilla usage, vanilla CoT prompting, CoT SFT, long step SFT, and long monolog SFT. As shown in Figure 2, each strategy significantly improves overall accuracy. Notably, Qwen2.5-72B achieves gains of +3.28%, +5.12%, +9.69%, and +11.36% for the respective strategies, strongly supporting the hypothesis that incorporating structured thought processes in inference time enhances the ability of powerful models to address complex medical problems. key observation is that more inference time leads to enhanced performance. For instance, when Qwen2.572B employs step-by-step reasoning, whether via vanilla CoT or CoT fine-tuning, the output token length ranges from 300 to 500 tokens, resulting in about 5% increase in mean accuracy. In contrast, under the journey learning settings, which include long step and long monolog fine-tuning, the token count extends to approximately 1,000, yielding improvements of about 10%. similar trend is evident for Qwen2.5-32B and LLama3.1-70B, as depicted in the remaining figures of Figure 2. Specifically, LLama3.1-70B achieves improvements of +2.20%, +3.09%, +5.20%, and +5.97%, while Qwen2.5-32B shows gains of +1.66%, +2.93%, +5.88%, and +6.03% across the three reasoning strategies. 7https://github.com/openai/tiktoken 5 Figure 3: The Accuracy of Qwen2.5-72B-Series on MedQA with inference-time scaling. When comparing LongStep and LongMonolog, it remains challenging to determine which consistently delivers superior performance. Based on current experimental data, long monolog demonstrates higher accuracy on Medbullets and MedQA but does not maintain its advantage in JAMA. For instance, Qwen2.5-32B achieves 56.34% accuracy in JAMA with LongStep but only 53.71% with LongMonolog. The limitation in Qwen2.5-32Bs self-reflective reasoning may stem from its inability to construct complete thought leading to correctness. As shown in Figures 10, 13 and 14, extended steps result in correct answers, whereas redundant reflections sometimes lead to errors (red texts in Figure 14). This finding suggests an assumption that long thought processes during inference time can aid in answering complex medical questions but require sufficient domain knowledge. How about scaling the inference time by majority voting? Majority voting is an intuitive plug-and-play approach commonly used for scaling inference time by leveraging the collective reasoning process across different computational runs. To investigate the superimposed effect of majority voting and the aforementioned schemes, we conducted experiments with the Qwen2.5-72B model on the MedQA dataset. The results, illustrated in Figure 3, compare the performance of four paradigms under majority voting (4, 8, 16, and 32 rounds). Inference time was measured by the average number of output tokens per problem. Although Qwen2.5-72B-Vanilla shows steady increase in performance with majority voting, the improvement is minimal, with accuracy rising only from 74.31% to 74.63%. Interestingly, when majority voting is combined with CoT reasoning (Qwen2.5-72B-Vanilla CoT), more improvements are observed. However, the accuracy reaches peak of 80.44% at higher token counts before slightly declining to 79.81%. Marginal gains of applying majority voting are also observed in the proposed journey learning schemes (i.e., LongStep and LongMonolog), but more obvious than that in previous methods. Qwen2.5-72B-LongStep benefits 1.26% increment from majority voting while LongMonolog benefits 1.50%. These results indicate that while majority voting can help refine predictions by aggregating outputs from multiple runs, it does not significantly enhance performance in tasks when intermediate steps are unthoughtful to achieve consistency in voting. Journey learning, which includes nuanced thoughts for reasoning, is more hopeful way to enhance performance via majority voting. As we stated at the beginning of this section, we only select models benefiting from vanilla CoT for further exploration. There is question: Does inference-time scaling always help? From this starting point, we first lay out the benefits of models using CoT prompting to solve medical problems of various difficulties. As vividly depicted in Figure 4, the models possessing huge number of parameters are those achieving positive gains from CoT prompting. For models with smaller parameter sizes, such as 7B or 20B, increased inference time can unfortunately lead to performance degradation and, at times, failure to adhere to the instructed output format. On datasets of higher difficulty like JAMA, which contain challenging real-world clinical cases and require extensive domain knowledge for analysis, the performance deficits are particularly pronounced. Another noteworthy observation is that models with fewer parameters, such as Qwen2.5-32B, gain less from inference-time scaling than models with larger capacities. Specifically, Qwen2.5-32B and Qwen-72B respectively achieve increments of +1.66% / +3.28% (vanilla CoT), +2.93% / +5.12% (CoT), +5.88% / +9.69% (LongStep) and +6.03% / +11.36% (LongMonolog). Based on these findings, the underlying philosophy we hypothesize is: The functioning of long thought during 6 Figure 4: The benefits of prompting open-source models to solve problems step by step are illustrated. The positive axis indicates that breaking down the problem into smaller steps can enhance model performance, while the negative axis suggests that doing so may lead to diminished returns. Each bubble represents different model, with bubble size corresponding to the models parameter size. Figure 5: Comparison of accuracy and average length of output tokens of Qwen2.5-72B across three datasets using distinct strategies(from left to right: Vanilla CoT, LongStep and LongMonolog) inference time requires sufficient capability, otherwise futile effort is expected. This is particularly significant in medicine, where solving clinical problems depends on the capacity to understand and generate complex and nuanced text and extensive knowledge, including aspects of diseases, pharmacology, and treatment protocols. 3.4 Harder Tasks, Longer Thoughts, More Inference Time The right part of Figure 5 reveals an intriguing observation: harder tasks appear to require longer output tokens to benefit from inference-time computing. To contextualize the level of difficulty, we hypothesized that answering questions in JAMA is more challenging than in Medbullets and MedQA, as JAMA presents more comprehensive real-world scenarios, and even proprietary models do not work well on JAMA. Additionally, we posited that Medbullets is more difficult than MedQA, as MedQA partially includes Step 1 questions from the USMLE. This hypothesis is partially validated by the overall performance of various settings presented on the left of Figure 5, where MedQA achieves the highest accuracy, followed by Medbullets and JAMA. Examining the length of output tokens, Qwen2.5-72B utilizes an average of 1,076 tokens to answer questions in JAMA through detailed monolog, compared to 917 tokens in Medbullets and 873 tokens in MedQA. similar increase in output length with task difficulty is evident across other reasoning paradigms and base models, as depicted in Table 1. This philosophy is consistent with our initial observations outlined in Section 2, higher-difficulty questions necessitate more reasoning steps, thereby requiring more complex thinking and longer output during inference. Another interesting observation is that models with fewer parameters, such as Qwen2.5-32B, tend to generate longer outputs when thinking aloud, particularly for easier questions. However, the opposite trend is observed in the other two reasoning paradigms, vanilla CoT prompting and long monolog SFT. Weaker models produce shorter responses in the former and outputs of similar length in the latter. After reviewing some examples, this discrepancy may stem from unnecessary verbosity when generating long monolog, as illustrated in Figures 10, 13 and 14. 8 weaker model may overlook or misinterpret key points during long monolog, becoming stuck in confusion 8https://jamanetwork.com/journals/jamadermatology/fullarticle/2797659 or arriving at incorrect conclusions. This finding, from the other side, supports the previous hypothesis that the functioning of inference-time scaling should be based on adequate knowledge. 3.5 Generalizability and Future Directions When we take closer look at the curated data in LongStep (in Figure 11) and LongMonolog dataset (in Figure 12), surprising finding is that the data are not bounded by the options provided. The priori options as input are internalized as heuristics for developing the output thought during inference time, which more resembles complete diagnosis with differential candidates (and exclusion of them), rather than discussing the options sequentially. To verify whether models trained on journey learning data can be effective in the differential diagnosis context, we conducted preliminary study. We removed the multiple-choice options and allowed the model to respond freely. To ensure fairness, we selected cases published in the 2024 JAMA Clinical Challenges while the training data were collected before October 2023. It is important to note that our model was exclusively trained on journey learning data, where the synthesis process included the provision of multiple-choice options. Figures 6 to 8 9 presents representative case demonstrating the application of long-form reasoning for diagnosis. With long-form reasoning, the model tends to analyze broader range of potential diseases while integrating various contextual information and its knowledge to approach more and more concise conclusions. These results offer promising insights for future research directions."
        },
        {
            "title": "4 Conclusion",
            "content": "Building upon our initial exploration of inference-time scaling in the medical domain, our findings indicate that this approach offers promising enhancements for tackling complex reasoning tasks. This study demonstrated that inference-time scaling significantly improves model performance across benchmarks like MedQA, Medbullets, and JAMA Clinical Challenges, with accuracy gains of 611% achieved using only 500 training samples. Key insights at this stage primarily concern the effectiveness of scaling inference time. While majority voting offers straightforward method to enhance inference-time computation, its impact remains limited compared to long reasoning paradigms. The necessity of extended reasoning for harder tasks underscores the scalability of inferencetime scaling with task complexity. Furthermore, the shift from multiple-choice formats to free-form responses revealed the potential for nuanced medical journey learning, fostering deeper clinical reasoning capabilities. Through continued exploration and iterative improvements, we aim to enhance the interpretability and effectiveness of inference-time scaling for addressing real-world medical challenges. By focusing on collaborative research and open resource sharing, we aim to strengthen the connection between computational advancements and real-world medical applications, ultimately improving diagnostic accuracy, patient outcomes, and healthcare efficiency. Our long-term goal is to develop intelligent systems that complement clinical expertise and address the growing complexity of modern medicine. Case: Problem of Differential Diagnosis 72-year-old man with history of polycythemia vera (positive for JAK2 V617F) presented with several months of functional decline and weight loss. Previous imaging obtained year prior showed hepatomegaly (18 cm) and mild perinephric stranding bilaterally. On admission, physical examination findings revealed tense ascites without telangiectasia, jaundice, or other skin changes. Initial workup showed macrocytic anemia (hemoglobin, 11.8 g/dL [to convert to g/L, multiply by 10]; mean corpuscular volume, 106 µm3), thrombocytopenia (88 103 µL), normal white blood cell count (5.19 103 µL [to convert to 109 L1, multiply by 0.001]) with lymphopenia (0.72 103 µL [to convert to 109 L1, multiply by 0.001]), hypoalbuminemia (2.2 g/dL [to convert to g/L, multiply by 10]), elevated alkaline phosphatase (655 U/L; reference, 41133 U/L [to convert to µkat/L, multiply by 0.0167]), and hyperbilirubinemia (total, 2.1 mg/dL; reference, 0.31.2; direct, 1.3 mg/dL [to convert to µmol/L, multiply by 17.104]) with otherwise normal levels of creatinine, alanine aminotransferase, and aspartate aminotransferase. Findings of activated partial thromboplastin time and international normalized ratio were also normal, and there was no significant proteinuria. An 18F-fluorodeoxyglucose (FDG) positron emission tomography/computed tomography showed soft tissue infiltrates and sclerosis of the perirenal spaces with FDG uptake, hepatosplenomegaly, ascites, and FDG avid sclerotic lesions throughout the pelvis, lumbosacral spine, and bilateral femurs. Several abdominopelvic FDG avid lymph nodes were also seen. Perinephric fibrosis and hepatomegaly were significantly worse compared with previous imaging obtained 12 months prior. A, 18F-fluorodeoxyglucose (FDG) positron emission tomography (PET)/computed tomography (CT) showing FDG uptake in the perirenal space (white arrowheads) and sclerotic bone lesions with FDG uptake (yellow arrowheads). B, Abdomen CT showing perirenal fibrosis (arrowheads) and sclerotic bone lesions in the sacrum. What is your diagnosis? Figure 6: Problem of Differential Diagnosis from JAMA Clinical Challenges 9https://jamanetwork.com/journals/jamaoncology/fullarticle/ 8 Case: Output of Qwen2.5-72B to Differential Diagnosis ((cid:37)) The patients clinical presentation and imaging findings suggest complex and evolving condition that is likely related to his underlying polycythemia vera (PV). Heres step-by-step analysis of the key points: 1. Clinical History and Symptoms: Age and Gender: 72-year-old male. Underlying Condition: Polycythemia vera (JAK2 V617F positive). Symptoms: Functional decline and weight loss over several months. Physical Examination: Tense ascites, no telangiectasia, jaundice, or other skin changes. 2. Laboratory Findings: Hematologic Parameters: Macrocytic anemia (Hemoglobin 11.8 g/dL, MCV 106 µm3). Thrombocytopenia (88 103/µL). Normal white blood cell count (5.19 103/µL) with lymphopenia (0.72 103/µL). Biochemical Parameters: Hypoalbuminemia (2.2 g/dL). Elevated alkaline phosphatase (655 U/L). Hyperbilirubinemia (Total 2.1 mg/dL, Direct 1.3 mg/dL). Normal creatinine, ALT, and AST. Normal coagulation parameters (aPTT and INR). 3. Imaging Findings: Previous Imaging (1 year ago): Hepatomegaly (18 cm). Mild perinephric stranding bilaterally. Current Imaging (18F-FDG PET/CT): Soft tissue infiltrates and sclerosis of the perirenal spaces with FDG uptake. Hepatosplenomegaly. Ascites. FDG-avid sclerotic lesions throughout the pelvis, lumbosacral spine, and bilateral femurs. FDG-avid lymph nodes in the abdominopelvic region. Significant worsening of perinephric fibrosis and hepatomegaly compared to previous imaging. 4. Differential Diagnosis: Transformation of PV to Myelofibrosis: Given the patients history of PV and the presence of splenomegaly, hepatomegaly, and bone marrow fibrosis (sclerotic lesions), this is strong possibility. The FDG uptake in these areas suggests active disease. Secondary Amyloidosis: This can occur in chronic myeloproliferative disorders and can present with organomegaly, hypoalbuminemia, and ascites. Malignancy: The presence of FDG-avid lymph nodes and bone lesions raises the possibility of secondary malignancy, such as lymphoma or metastatic disease. 5. Conclusion: The most likely diagnosis is transformation of polycythemia vera to myelofibrosis. This is supported by the clinical symptoms, laboratory findings (anemia, thrombocytopenia, hypoalbuminemia, and elevated alkaline phosphatase), and imaging findings (hepatosplenomegaly, perinephric fibrosis, and FDG-avid sclerotic bone lesions). Therefore, the diagnosis is: Transformation of Polycythemia Vera to Myelofibrosis. Figure 7: Free-form Response: Incorrect Output of Qwen2.5-72B to Differential Diagnosis Case: Output of Qwen2.5-72B-LongMonolog to Differential Diagnosis ((cid:33)) ##Process Alright, lets dive into this case. 72-year-old man with history of polycythemia vera (PV), positive for JAK2 V617F mutation, presents with several months of functional decline and weight loss. Hmm, functional decline and weight loss in an elderly patientimmediately raises concerns about systemic illness or malignancy. Looking back, previous imaging from year ago showed hepatomegaly (18 cm) and mild perinephric stranding bilaterally. Now, on admission, he has tense ascites without telangiectasia, jaundice, or other skin changes. So, his liver and spleen might be enlarged, and hes retaining fluid. His labs show macrocytic anemia (hemoglobin 11.8 g/dL, MCV 106 µm3), thrombocytopenia (platelets 88 103/µL), normal white blood cell count but with lymphopenia (0.72 103/µL). He also has hypoalbuminemia (2.2 g/dL), elevated alkaline phosphatase (655 U/L), and hyperbilirubinemia (total bilirubin 2.1 mg/dL, direct 1.3 mg/dL). Creatinine, AST, and ALT are normal, and no significant proteinuria. The FDG-PET/CT shows soft tissue infiltrates and sclerosis of the perirenal spaces with FDG uptake, hepatosplenomegaly, ascites, and FDG-avid sclerotic lesions throughout the pelvis, lumbosacral spine, and bilateral femurs. There are also FDG-avid lymph nodes in the abdomen and pelvis. Perinephric fibrosis and hepatomegaly are worse than year ago. So, what could be going on here? Firstly, his PV is known, which is myeloproliferative neoplasm (MPN). Over time, MPNs can transform into more aggressive diseases. Possible complications include myelofibrosis, acute leukemia, or even extramedullary hematopoiesis. Wait, the FDG-avid sclerotic bone lesions and lymphadenopathy suggest active cell turnover or malignancy. The perirenal fibrosis and soft tissue infiltrates with FDG uptake point toward infiltration by malignant cells. Could this be acute myeloid leukemia (AML)? AML can arise from MPNs, but typically wed see high peripheral blast count, which doesnt seem to be the case herethe WBC count is normal. What about myelofibrosis? Myelofibrosis is known complication of PV where fibrosis replaces normal bone marrow, leading to extramedullary hematopoiesis in organs like the liver and spleen. Symptoms include splenomegaly, constitutional symptoms, and cytopenias due to ineffective hematopoiesis. But would myelofibrosis explain the sclerotic bone lesions and FDG-avid lymph nodes? Usually, myelofibrosis leads to bone pain and osteosclerosis, but Im not sure if it causes FDG-avid lesions. Alternatively, could this be secondary amyloidosis? Amyloidosis can result from chronic inflammation or malignancy and leads to organ deposition of amyloid proteins. It can cause organomegaly, macroglossia, skin changes, and involvement of the kidneys and heart. However, our patient doesnt have these features. Hmm, maybe Castleman disease? Its lymphoproliferative disorder that can cause systemic symptoms and lymphadenopathy. But Castleman disease doesnt typically cause sclerotic bone lesions or perirenal fibrosis. Wait, could this be light-chain deposition disease or multiple myeloma? Multiple myeloma is plasma cell malignancy causing bone lesions, often sclerotic or lytic, and can lead to renal issues. But patients usually present with anemia, hypercalcemia, and elevated immunoglobulins, which dont seem prominent here. Perhaps its POEMS syndrome? Polyneuropathy, Organomegaly, Endocrinopathy, Monoclonal gammopathy, and Skin changes. Our patient has hepatomegaly and sclerotic bone lesions, but theres no mention of neuropathy, endocrine issues, or skin changes. Hold on, the perirenal fibrosis and sclerotic lesions make me think of Erdheim-Chester disease (ECD). ECD is rare non-Langerhans histiocytosis characterized by the proliferation of histiocytes leading to fibrosis and infiltration of various organs. ECD commonly affects middle-aged adults and involves the bones, especially the long bones and axial skeleton, causing sclerotic lesions. It also frequently affects the central nervous system, lungs, and skin. Perirenal fibrosis is hallmark of ECD and can lead to hypertension and renal dysfunction. Additionally, ECD can involve the skin, CNS, orbits, and other organs. Patients often present with diabetes insipidus, pulmonary symptoms, and neurological signs. Our patient doesnt have these symptoms, but perhaps they havent developed yet. Also, ECD is often associated with BRAF V600E mutations or MAPK pathway alterations. However, it can coexist with MPNs like PV, which have JAK2 mutations. Wait, could the JAK2 V617F mutation in PV somehow be related to ECD? While they involve different signaling pathways, both conditions involve dysregulated cell proliferation. Alternatively, could this be extramedullary hematopoiesis? In advanced myelofibrosis, the body compensates for bone marrow failure by producing blood cells in the spleen, liver, and other organs. This can cause organomegaly and fibrosis. But extramedullary hematopoiesis wouldnt explain the sclerotic bone lesions or FDG-avid lymph nodes. Maybe Im missing something. Lets revisit myelofibrosis. Secondary myelofibrosis from PV can cause bone pain, splenomegaly, and extramedullary hematopoiesis. The fibrosis could lead to sclerotic bone lesions. But would it cause perirenal fibrosis? Well, fibrosis is common theme. Also, the elevated alkaline phosphatase suggests active bone turnover, supporting bone involvement. Given all this, think myelofibrosis is strong possibility. However, considering the perirenal fibrosis and sclerotic lesions, ECD remains compelling diagnosis. Wait, perhaps combination of both? Could the PV have transformed into myelofibrosis, and concurrently, ECD has developed? Alternatively, perhaps the histiocyte proliferation in ECD is mimicking myelofibrosis. Given the rarity of ECD and the presence of hallmark features like perirenal fibrosis and sclerotic bone lesions, think ECD is the most likely diagnosis. Therefore, after considering all possibilities, believe the diagnosis is Erdheim-Chester disease. Figure 8: Free-form Respons: Correct Output of Qwen2.5-72B-LongMonolog to Differential Diagnosis"
        },
        {
            "title": "References",
            "content": "[1] AI@Meta. 2024. Llama 3 model card. [2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. [3] Hanjie Chen, Zhouxiang Fang, Yash Singla, and Mark Dredze. 2024. Benchmarking large language models on answering and explaining challenging medical questions. arXiv preprint arXiv:2402.18060. [4] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2023. Palm: Scaling language modeling with pathways. Journal of Machine Learning Research, 24(240):1113. [5] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio Cesar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. 2023. Textbooks are all you need. arXiv preprint arXiv:2306.11644. [6] Geoffrey Hinton. 2015. Distilling the knowledge in neural network. arXiv preprint arXiv:1503.02531. [7] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685. [8] Zhen Huang, Haoyang Zou, Xuefeng Li, Yixiu Liu, Yuxiang Zheng, Ethan Chern, Shijie Xia, Yiwei Qin, Weizhe Yuan, and Pengfei Liu. 2024. O1 replication journeypart 2: Surpassing o1-preview through simple distillation, big progress or bitter lesson? arXiv preprint arXiv:2411.16489. [9] Jinhao Jiang, Zhipeng Chen, Yingqian Min, Jie Chen, Xiaoxue Cheng, Jiapeng Wang, Yiru Tang, Haoxiang Sun, Jia Deng, Wayne Xin Zhao, et al. 2024. Technical report: Enhancing llm reasoning with reward-guided tree search. CoRR, abs/2411.11694. [10] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. 2020. What disease does this patient have? large-scale open domain question answering dataset from medical exams. arXiv preprint arXiv:2009.13081. [11] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361. [12] Kimi. 2024. k0math. [13] OpenAI. 2024. Learning to reason with llms. [14] Yiwei Qin, Xuefeng Li, Haoyang Zou, Yixiu Liu, Shijie Xia, Zhen Huang, Yixin Ye, Weizhe Yuan, Hector Liu, Yuanzhi Li, and Pengfei Liu. 2024. O1 replication journey: strategic progress report part 1. CoRR. [15] Pengcheng Qiu, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, and Weidi Xie. 2024. Towards building multilingual language model for medicine. Nature Communications, 15(1):8384. [16] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. 2020. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 35053506. [17] Robert Seller and Andrew Symons. 2011. Differential Diagnosis of Common Complaints E-Book. Elsevier Health Sciences. [18] Karan Singhal, Shekoofeh Azizi, Tao Tu, Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. 2023. Large language models encode clinical knowledge. Nature, 620(7972):172180. [19] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314. [20] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto. 2023. Alpaca: strong, replicable instruction-following model. Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html, 3(6):7. [21] Qwen Team. 2024a. Qwen2.5: party of foundation models. 11 [22] Qwen Team. 2024b. Qwq: Reflect deeply on the boundaries of the unknown. [23] Skywork o1 Team. 2024. Skywork-o1 open series. https://huggingface.co/Skywork. [24] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837. [25] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244. [26] Di Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong Li, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco Pavone, Yuqiang Li, Wanli Ouyang, and Dongzhan Zhou. 2024a. Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning. CoRR, abs/2410.02884. [27] Yuxiang Zhang, Shangxi Wu, Yuqi Yang, Jiangming Shu, Jinlin Xiao, Chao Kong, and Jitao Sang. 2024b. o1-coder: an o1 replication for coding. CoRR, abs/2412.00154. [28] Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma. 2024. Llamafactory: Unified efficient fine-tuning of 100+ language models. arXiv preprint arXiv:2403.13372."
        },
        {
            "title": "A Appendix",
            "content": "Figure 9: Case of problems for synthesizing data. Figure 10: One case of JAMA problems. 13 Figure 11: Case of our distilled long step data for the problem. 14 Figure 12: One case of our distilled long Monolog data for the problem. 15 Figure 13: Generated Thought by the Qwen2.5-32B-LongStep Model. 16 Figure 14: Failure case generated by the Qwen2.5-32B-LongStep Model."
        }
    ],
    "affiliations": [
        "Generative AI Research Lab (GAIR)",
        "SII",
        "SPIRAL Lab",
        "Shanghai Jiao Tong University"
    ]
}