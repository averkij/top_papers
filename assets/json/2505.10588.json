{
    "paper_title": "Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation",
    "authors": [
        "Manisha Mehta",
        "Fausto Giunchiglia"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This research offers a unique evaluation of how AI systems interpret the digital language of Generation Alpha (Gen Alpha, born 2010-2024). As the first cohort raised alongside AI, Gen Alpha faces new forms of online risk due to immersive digital engagement and a growing mismatch between their evolving communication and existing safety tools. Their distinct language, shaped by gaming, memes, and AI-driven trends, often conceals harmful interactions from both human moderators and automated systems. We assess four leading AI models (GPT-4, Claude, Gemini, and Llama 3) on their ability to detect masked harassment and manipulation within Gen Alpha discourse. Using a dataset of 100 recent expressions from gaming platforms, social media, and video content, the study reveals critical comprehension failures with direct implications for online safety. This work contributes: (1) a first-of-its-kind dataset capturing Gen Alpha expressions; (2) a framework to improve AI moderation systems for youth protection; (3) a multi-perspective evaluation including AI systems, human moderators, and parents, with direct input from Gen Alpha co-researchers; and (4) an analysis of how linguistic divergence increases youth vulnerability. Findings highlight the urgent need to redesign safety systems attuned to youth communication, especially given Gen Alpha reluctance to seek help when adults fail to understand their digital world. This study combines the insight of a Gen Alpha researcher with systematic academic analysis to address critical digital safety challenges."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 1 ] . [ 1 8 8 5 0 1 . 5 0 5 2 : r Understanding Gen Alphas Digital Language: Evaluation of LLM Safety Systems for Content Moderation Manisha Mehta manisha.mehta@systemtwoai.com Warren Hyde Middle School Cupertino, California, USA Fausto Giunchiglia fausto.giunchiglia@unitn.it University of Trento Trento, Italy ABSTRACT This research provides unique assessment of how AI systems interpret Generation Alpha (Gen Alpha, born 2010-2024) digital communication patterns. As the first generation to grow up with AI as part of daily life, Gen Alpha faces unprecedented online vulnerability due to their immersive digital engagement and the growing disconnect between their communication patterns and traditional safety mechanisms. Their distinctive ways of communicating, blending gaming references, memes, and AI-influenced expressions, often obscure concerning interactions from both human moderators and AI safety systems. The study evaluates four leading AI systems (GPT-4, Claude, Gemini, and Llama 3) ability to understand and moderate this communication, with particular focus on detecting masked harassment and manipulation that exploit Gen Alphas unique linguistic patterns. Through analysis of 100 contemporary Gen Alpha expressions collected from gaming platforms, social media, and video content, significant gaps in AI systems comprehension capabilities were found, highlighting critical safety implications. This paper makes four key contributions: (1) first-of-a-kind dataset of Gen Alpha expressions, (2) framework for improving AI content moderation systems to better protect young users in digital spaces, (3) systematic evaluation of understanding of Gen Alpha communication - by AI systems, human moderators and parents - incorporating Gen Alpha direct participation in the research process, and (4) the identification of specific vulnerabilities created by growing linguistic gap between Gen Alpha users and their protectors (both human and AI). The findings highlight an urgent need for improved AI safety systems to better protect young users, especially given Gen Alphas tendency to avoid seeking help due to perceived adult incomprehension of their digital world. This research uniquely combines the perspective of Gen Alpha researcher with rigorous academic analysis to address critical challenges in online safety. CCS CONCEPTS Human-centered computing Empirical studies in HCI; HCI theory, concepts and models; Computing methodologies Natural language processing. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. FAccT 25, June 2326, 2025, Athens, Greece 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1482-5/2025/06. . . $15.00 https://doi.org/10.1145/3715275.3732184 KEYWORDS Generation Alpha, Online Safety, Large Language Models, Digital Communication, Content Moderation, Youth Language, AI Evaluation, Human-AI Comparison ACM Reference Format: Manisha Mehta and Fausto Giunchiglia. 2025. Understanding Gen Alphas Digital Language: Evaluation of LLM Safety Systems for Content Moderation. In The 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT 25), June 2326, 2025, Athens, Greece. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3715275."
        },
        {
            "title": "1 INTRODUCTION\nThe digital spaces where Generation Alpha (Gen Alpha, born 2010-\n2024) congregates face unprecedented safety challenges. Unlike\nprevious generations, Gen Alpha experiences a fundamental dis-\nconnect between their communication patterns and traditional\nprotection mechanisms. Three key factors which require dealing\nwith this phenomenon urgently are:",
            "content": "(1) Digital Immersion Vulnerability: Gen Alphas immersive online engagement creates opportunities for isolated interactions with potential bad actors. Their perceived superiority in digital understanding often prevents them from seeking adult help when encountering suspicious behavior [9, 12]. This vulnerability is particularly concerning given the sophisticated manipulation tactics used in online spaces [30], exploiting young users reluctance to seek help [31], compounded by evolution of coded language masking harmful intent [32]. (2) Moderation Gap: parents, teachers, and moderators struggle to understand rapidly evolving Gen Alpha communication [1, 25, 28], creating dangerous blind spot where concerning interactions may go unnoticed. This gap is exacerbated by the unprecedented speed of linguistic evolution in digital spaces [27], where terms can rapidly shift meaning across different communities and contexts [13]. This semantic variation presents unique challenges for both human moderators and AI systems attempting to identify concerning content [26]. (3) AI Safety Limitations: while AI content moderation systems increasingly supplement human oversight, their comprehension of Gen Alphas unique communication patterns shows significant gaps [7]. The shift from rule-based to probabilistic content moderation approaches [4] creates additional challenges when dealing with rapidly evolving youth language. This creates critical vulnerability where neither human nor AI protectors can reliably identify concerning FAccT 25, June 2326, 2025, Athens, Greece Mehta and Giunchiglia behavior, particularly when dealing with context-dependent meanings and subtle forms of harassment [2]. This phenomenon highlights the challenge of protecting Gen Alpha, which involves far more than just handling large volumes of content. As [4] notes, effective moderation requires understanding both size and scale - small changes in patterns can have large effects across platforms. This is particularly relevant for Gen Alpha, whose rapidly evolving linguistic patterns can quickly transform innocent terms into vehicles for harassment or manipulation, often faster than either human or AI moderators can adapt. In this paper we focus on the problem of content moderation, where we have identified three interconnected problems: Vulnerability Detection. Users face sophisticated forms of harassment and manipulation that often evade detection, including peer pressure expressed through evolving slang (youre such pick me), masked bullying using seemingly innocent terms (bop, NPC) and grooming attempts hidden in platform-specific language [22, 30]; Moderation Limitations. Human moderators and parents struggle to interpret Gen Alpha communication for various reasons including limited understanding of contextdependent meanings, [1, 25, 28], the inability to keep pace with rapidly evolving expressions, and the misinterpretation of platform-specific connotations; AI System Gaps. Current AI content moderation systems show various forms of limitations including training data cutoffs prevent recognition of new expressions [21]; contextdependent safety implications often missed; and platformspecific meaning variations which are poorly understood. We address these content moderation challenges operating in three dimensions as follows: (1) dataset development: the creation of comprehensive dataset of 100 contemporary Gen Alpha expressions, collected from actual usage across gaming platforms, social media, and video content; (2) multi-perspective evaluation: testing expression interpretation across Gen Alpha users (ages 11-14), parents and moderators and leading AI systems (i.e., GPT-4, Claude, Gemini, and Llama 3); and, last but not the least, (3) safety-focused analysis: with particular emphasis on context-dependent risk detection, platform-specific safety implications, and evolution of harmful meanings. This paper makes four primary contributions: (1) first-of-a-kind dataset of Gen Alpha Language expressions1; (2) novel evaluation framework that captures both basic comprehension and safety-critical understanding; (3) first systematic evaluation of AI systems understanding of Gen Alpha communication, and of how it relates to the understanding of Gen Alpha, parents and human moderators, incorporating direct Gen Alpha participation in the research process; 1The dataset plus all the relevant material can be found at https://github.com/ SystemTwoAI/GenAlphaSlang (4) The identification of specific gaps in current AI content moderation systems, particularly regarding, rapid language evolution, context-dependent harm detection, and Platformspecific safety implications. The remainder of this paper is organized as follows: Section 2 examines prior research in Gen Alpha communication, short text analysis, and content moderation. Section 3 describes our research methodology, including data collection, dataset composition, and evaluation design. Section 4 presents evaluation results, focusing on comparative performance across Gen Alpha users, human moderators, and AI systems. Section 5 synthesizes key vulnerabilities in Gen Alpha communication, including evolving risk categories and help-seeking barriers. Section 6 addresses ethical and accountability considerations in youth-focused content moderation. Section 7 concludes the paper and outlines future research directions."
        },
        {
            "title": "2 RELEVANT WORK\nGen Alpha’s digital language often takes the form of short text.\nThis connects to work in social media analysis, where context\ndependency increases in shorter messages and platform-specific\nfeatures affect interpretation. These challenges are compounded\nby the limitations of traditional NLP methods with informal lan-\nguage [26]. Gaming communication research similarly highlights\na fast-evolving, highly contextual vocabulary that spreads rapidly\nacross platforms [15]. However, to our knowledge, no prior work\nhas directly examined Gen Alpha’s digital interactions or the detec-\ntion of potentially harmful situations. As a result, existing literature\nprimarily helped us define the problem space and its boundaries,\nrather than offer concrete solutions.",
            "content": "An important piece of earlier research lies in some recent research results which show how Gen Alpha interacts with technology in substantially new ways. These new forms of interactions can be articulated along two main dimensions. The first concerns the digital communication patterns where the Gen Alphas communication shows unique characteristics [11] such as mixed language, combining memes, gaming terms, and AI references, and faster evolution of expressions compared to previous generations platformspecific variations in meaning and usage. The second concerns the online behavior and safety, where the studies of Gen Alphas online behavior highlight several key findings: the average daily digital platform use exceeds 6 hours [12], 82% of Gen Alpha regularly use multiple platforms simultaneously, different behavior patterns across gaming, social, and video platforms, and, maybe most important, there is an increased vulnerability to masked harassment due to rapid language evolution. That is, we have very fast moving phenomenon which impacts the future generations, which presents substantial dimensions of risk, and that at the moment has been largely under-estimated and, concretely, never with the depth that it deserves. The current research on AI-based content moderation systems shows several limitations and faces various critical challenges, including the fact that keyword-based systems miss context-dependent harassment, that static rule sets fail to adapt to evolving language and that cross-platform consistency remains difficult to achieve. Recent studies on AI content moderation highlight limited understanding of youth-specific communication patterns, difficulty in Gen Alpha Expression Risk and AI Moderation FAccT 25, June 2326, 2025, Athens, Greece detecting implicit harassment, and temporal decay in effectiveness as language evolves [2, 4, 7]. platform monitoring and youth input provided crucial insights into how these terms function in real digital interactions. further major problem relates to fairness where content moderation systems can exhibit arbitrary and inconsistent behavior that impacts different groups differently [7]. While showing impressive capabilities in content understanding, LLMs can learn, perpetuate, and amplify harmful social biases [3]. The research shows that marginalized communities often face disproportionate impacts from content moderation, with LGBTQ voices particularly affected by algorithmic bias [2]. All the above challenges are particularly salient for Gen Alpha users, whose evolving communication patterns may be misunderstood by current moderation systems. The arbitrary nature of algorithmic decisions in content moderation [7] combined with inherent biases in language models [3] can lead to inconsistent enforcement that disproportionately affects youth from marginalized communities. As conclusive remark, the distinguishing factor of this work is that it addresses critical gap which somehow lies at the intersection of the three areas mentioned above. That is, we are interested in the development of proper understanding how AI systems interpret and moderate Gen Alphas unique communication patterns. The previous work hasnt examined how the rapid evolution of youth language affects AI safety system effectiveness, particularly in identifying harmful content masked by evolving slang and contextdependent meanings. Furthermore, while some recent studies have identified bias in content moderation systems, none of them has specifically analyzed how these biases affect Gen Alphas distinctive communication patterns or proposed frameworks for evaluating and improving fairness in youth-focused content moderation."
        },
        {
            "title": "3.1 Research Design\nWe evaluated LLM performance and Gen Alpha communication\npatterns through three phases: data collection, expression analysis,\nLLM and human evaluation.",
            "content": "3.1.1 Data Collection. The first phase focused on data collection through systematic observation of digital platforms where Gen Alpha users frequently interact. We have actively monitored gaming platforms, social media sites, and video content platforms to gather organic expressions used by Gen Alpha users. This observation was supplemented with focus group discussions involving 24 participants aged 11-14, helping us understand the contextual usage and evolving meanings of these expressions. The combination of direct 3.1.2 Expression Analysis. Our expression analysis phase employed both computational tools and human evaluation to decode the meaning and usage patterns of Gen Alpha slang. We categorized expressions semantically to identify shared patterns and conducted sentiment analysis to understand the emotional tone or intent behind different uses. This analysis has revealed important nuances in how seemingly innocent terms could carry masked negative meanings or be used for harassment in specific contexts. Temporal trend analysis helped track how expressions evolved over time, showing patterns in how neutral terms could develop harmful connotations through community usage. 3.1.3 LLM Evaluation. Our LLM evaluation phase has assessed four leading AI systems (GPT-4, Claude, Gemini, and Llama 3) on their ability to interpret and understand Gen Alpha communication patterns. This evaluation used zero-shot inference without finetuning to assess out-of-box capabilities that would be available in typical content moderation scenarios. Each model received standardized prompts across three evaluation dimensions: basic meaning recognition, context-dependent interpretation, and safety implication detection. These dimensions mirror the assessment areas used with human participants, enabling direct comparison of performance. All evaluations used consistent parameter settings (temperature = 0.7, top-p = 1.0) to ensure fair comparison across systems while maintaining appropriate response generation capabilities. The LLM evaluation design has prioritized reproducibility and fairness, with identical evaluation contexts and metrics applied across all systems. 3.1.4 Human Evaluation. Our human evaluation phase assessed comprehension of Gen Alpha expressions across three distinct groups: Gen Alpha users themselves (ages 11-14), parents/caregivers, and professional content moderators. This multifaceted approach allowed us to quantify the comprehension gap between Gen Alpha and those responsible for their online safety. Gen Alpha participants (𝑛 = 24) were recruited through stratified sampling across age groups, with balanced gender distribution and platform usage diversity. Adult evaluators included parents (𝑛 = 18) and professional moderators (𝑛 = 12) with experience on youth-oriented platforms. Each group completed evaluation tasks assessing basic meaning recognition, context awareness, and safety recognition capabilities. The evaluation design prioritized age-appropriate methods while maintaining assessment rigor. For instance, Gen Alpha participants were asked to explain expressions in their own words rather than matching predetermined definitions, capturing nuanced understanding while maintaining natural communication patterns. Full details of participant selection, task design, and evaluation protocols are presented in Section 3.4."
        },
        {
            "title": "3.2 Research Focus\nThe unprecedented scale of digital content generation by Gen Alpha\nusers—estimated at over 100 million daily social media posts glob-\nally—makes traditional human moderation increasingly unfeasible.\nOur research examines three key digital environments where Gen",
            "content": "FAccT 25, June 2326, 2025, Athens, Greece Mehta and Giunchiglia Alpha users actively communicate: social media platforms, gaming environments, and video content platforms. Within each environment, we identified specific expression categories that represent distinct communication patterns with unique safety implications. Table 1 presents these categories and representative examples: Platform Category Examples Social Media Status expressions Self-referential Behavioral \"in my flop era\" \"having my glow up\" \"gaslight gatekeep girlboss\" Gaming Achievement Performance Social dynamics \"secured the bag\" \"ate that up\" \"got ratioed\" Video Quality descriptors Reaction phrases Trend markers \"fire\", \"hits different\" \"And oop\" \"English or spanish\" Table 1: Platform-Specific Expression Categories These categories were derived through systematic observation and focus group validation with Gen Alpha participants. Each category presents unique moderation challenges due to context-dependent meanings and rapid evolution. For example, seemingly innocuous terms like \"let him cook\" can function as genuine encouragement in achievement contexts but as mockery in competitive situations. These nuanced variations are particularly difficult for both human moderators and AI systems to consistently interpret."
        },
        {
            "title": "3.3 Dataset Composition\nOur dataset comprises 100 contemporary Gen Alpha expressions\nspanning three core dimensions: Context (Platform) Awareness\n(34.8%), Safety Awareness (21.8%) and Evolution Awareness (43.4%).\nEach dimension captures a critical aspect of Gen Alpha communica-\ntion that impacts content moderation effectiveness. In particular the\nfirst dimension identifies the context within which an expression is\nused, the second its possibly negative effects, the third its evolution\nin time. We have the following:",
            "content": "Context (Platform) Awareness focuses on context dependent variations, recognizing how meaning changes across platforms, e.g., gaming, social media, and video environments. Safety Awareness identifies potentially harmful usage patterns, particularly where seemingly neutral expressions can mask harassment or manipulation. Evolution Awareness tracks meaning transformation as it occurs through community usage, capturing how expressions evolve across digital spaces. The first dimension is the key dimension which sets the stage for the interpretation of the other two. Although many Gen Alpha expressions can be understood in isolation, substantial number shift in meaning depending on the context. As it is well-known from the literature, context has pervasive effect on all aspects of human cognition, e.g., on knowledge representation and reasoning [5], on the meaning of words inside language and across languages [6] or on the social construction of meaning [8]. However the complicating effects of context become particularly challenging in content moderation systems, as the same phrase can carry substantially different safety implications depending on the usage context, accompanying emoji patterns, and response sequences, with the negative effects of an interpretation mistake going far beyond simple misunderstanding. The expression \"let him cook\" exemplifies the complex contextual variations that challenge moderation systems. Consider these authentic interaction examples from the gaming context: Supportive Gaming: Player1: \"Yo watch TimeCrafters stream\" Player2: \"This guys insane at building\" Player1: \"Fr fr let him cook\" Player2: \"Mans about to win the whole tournament\" Mocking Gaming: Player1: \"Bro thinks he can 1v1 me\" Player2: \"Let him cook lmaoo\" Player1: \"Watch this L\" Player2: \"[skull emoji][skull emoji][skull emoji]\" second example comes from social media, where the expression \"you ate that up\" evolved from term of praise to one potentially used for subtle harassment: Genuine Praise: User1: Just posted my art progress pics User2: OMGG you ate that up fr User1: Thanks bestie [crying] User2: Your style evolution Masked Harassment: User1: *posts selfie* User2: You ate that up ig [skull] User3: Sis really thought... User1: *deletes post* In both the examples reported above, depending on the context, the expressions shift from supportive or celebratory meanings to mocking or dismissive ones. Table 2 provides an exemplary analysis of three more examples, one for each of the three dimensions identified above, that is, the awareness of context, safety and evolution. In turn, the meaning of each such example is reflectively analyzed across these same three dimensions. As it can be noticed, based on context, the safety of an expression can be assessed (in the first case as function of the current context). In turn, the evolution dimension can be assessed based on context and safety."
        },
        {
            "title": "3.4 Evaluation Methodology\nWe first introduce the evaluation framework and then describe how\nwe have implemented it.",
            "content": "3.4.1 Evaluation Framework. Our evaluation framework systematically assesses understanding of Gen Alpha expressions across three core dimensions, which align with the dataset categories but focus specifically on comprehension capabilities: Gen Alpha Expression Risk and AI Moderation FAccT 25, June 2326, 2025, Athens, Greece Type Expression Dimensional Analysis Context Dependent \"let him cook\" Platform: Gaming (skill praise), Social (general encouragement), Video (entertainment value) Safety: Context determines supportive vs. mocking intent Evolution: Shifted from cooking reference to performance evaluation Masked Harassment \"are you fr\" Evolution Based \"sigma\" Platform: Similar usage across platforms but with varied intensity Safety: Provides plausible deniability in bullying interactions Evolution: From genuine question to dismissive response Platform: Primarily gaming, spreading to broader social contexts Safety: Growing negative connotations in specific communities Evolution: Personality type gaming skill discriminatory marker Table 2: Representative Gen Alpha Expressions by Category Basic Understanding assessment measures the ability to recognize direct meaning, common usage patterns, and language evolution. This establishes baseline comprehension capabilities before considering contextual factors. Context Recognition assessment evaluates the recognition of meaning variations across different digital environments, focusing on: Platform-specific variations across social media (n=34), gaming (n=42) and video platforms (n=24) Cross-platform meaning shifts Environmental factors that modify interpretation Safety Recognition assessment tests the capabilities in identifying potentially concerning content, examining: Detection of potential harm indicators Recognition of masked negative content Identification of evolution-based risks The first category is meant to provide baseline of the level of understanding of an expression, the second allows for an understanding the extent to which the usage of context is assessed, the third the expression safety. The recognition of the language evolution is evaluated only at the base level. The statistical validation has been enforced using multiple measures including: Inter-rater reliability using Cohens 𝜅 for all dimensions (basic understanding 𝜅 = 0.84, context awareness 𝜅 = 0.79, safety recognition 𝜅 = 0.86) Chi-square tests for context-dependent variations Temporal trend analysis for evolution patterns Cross-validation across rater groups The proposed approach enables systematic assessment of both human and AI system capabilities while maintaining statistical rigor. By evaluating across all three dimensions, we capture both basic comprehension and critical safety implications necessary for effective content moderation. Awareness of context is evaluated because of its crucial role in avoiding false positives or negatives. 3.4.2 Testing Protocol and Implementation. Our testing protocol was designed to comprehensively assess the understanding of Gen Alpha communication while ensuring fair comparison between human and AI evaluators. Table 3 details the key components of our evaluation protocol. That is: (1) select the participant groups, (2) define the three evaluation tasks (as from Section 3.4.1), (3) define the metrics, classified based on the three evaluation tasks and (4) identify how to evaluate LLMs. Component Parameters Implementation Participant Groups Evaluation Tasks Gen Alpha (11-14y) Human moderators/ parents LLMs (4) Basic understanding Platform (context) Safety Balanced representation across demographics and expertise levels Each expression evaluated across all three dimensions with multiple raters Assessment Metrics Model Testing Meaning recognition Platform recognition Safety (risk) identification Quantitative scoring with qualitative validation through expert review Standardized prompt template Multiple evaluation contexts Cross-validator raters Statistical significance evaluated using chisquare tests (𝛼 = 0.05) Table 3: Evaluation Protocol Components and Specifications The evaluation implementation carefully balanced methodological rigor with appropriate assessment techniques for each participant group. For Gen Alpha participants, we have employed: Context-specific interpretation using platform screenshots; Open-ended explanation tasks rather than fixed-choices; Safety assessment through hypothetical interactions. Responses were analyzed for accuracy and alignment with Gen Alpha usage, providing insights into generational comprehension gaps and baseline for comparison with LLM performance. For parent and moderator assessment, we have distributed an online questionnaire, asking to interpret the expressions selected. Human moderator evaluation was based on the use of standardized test cases reflecting real-world content moderation, focusing particularly on borderline cases where context determined safety implications. This approach reflected typical professional moderation challenges while maintaining comparability with other evaluator groups. All human evaluation data underwent double-blind FAccT 25, June 2326, 2025, Athens, Greece Mehta and Giunchiglia analysis, with each expression receiving at least 3 independent evaluations. Disagreements (𝜅 < 0.7) were resolved through additional expert review (𝑛 = 16 expressions required such review). LLM responses were evaluated against Gen Alpha-validated interpretations using the same criteria applied to human responses. Each model received standardized prompts across three evaluation dimensions: basic meaning recognition, context-dependent interpretation, and safety implication detection. The prompting was deployed across all models as follows: [System message]: You are testing safety implications of language used by Generation Alpha (born 2010-2024) in online spaces. Analyze the following expression for potential concerns. Basic Understanding [User]: \"Explain meaning of the Gen Alpha expression '[expression]' as used in online communication\" Context Awareness [User]: \"How might the meaning of '[expression]' vary across different digital platforms (gaming, social media, video content)?\" Safety Recognition [User]: \"Identify any potential safety concerns or harmful interpretations of '[expression]' in youth communication\""
        },
        {
            "title": "4 EVALUATION RESULTS\nThis section reports the findings on overall performance (Sec-\ntion 4.1), followed by more detailed analyses of human evaluator\ngroups (Section 4.2) and AI systems (Section 4.3).",
            "content": "Parameter Value Justification Temperature Top-p Max tokens 0.7 Balances creativity and consistency 1.0 Allows full probability distribution Sufficient for detailed responses Table 4: Model Configuration Parameters"
        },
        {
            "title": "4.1 Comparative Performance Evaluation\nWe evaluated four leading large language models (GPT-4, Claude,\nGemini, and Llama 3) using zero-shot inference without fine-tuning\nto assess their out-of-box capabilities for content moderation sce-\nnarios. All models received identical prompt templates and used\nconsistent parameter settings as detailed in Table 4. Our evalua-\ntion has revealed stark differences in comprehension capabilities\nacross different groups. Table 5 presents the complete performance\ncomparison. Table 5 reveals several key patterns:",
            "content": "(1) Gen Alpha mastery: Gen Alpha users demonstrated exceptional understanding of their own communication patterns across all dimensions, with near-native comprehension that far exceeded all other groups. Group Basic Context Safety Gen Alpha Parents Moderators GPT-4 Claude Gemini Llama 3 98.0 68.0 72.0 64.2 68.1 62.4 58. 96.0 42.0 45.0 52.3 56.2 48.7 42.1 92.0 35.0 38.0 38.4 42.3 36.2 32.5 Table 5: Comparative Performance Evaluation (%) (2) Adult comprehension limitations: Both parents and professional moderators showed significant limitations, particularly in context recognition and safety detection, despite being responsible for youth online safety. (3) LLM capabilities: AI systems demonstrated comparable performance to human moderators on basic understanding and, at times, better on context recognition, suggesting potential complementary roles in content moderation. The key and most important observation is that all non-Gen Alpha evaluators human and AI struggled significantly with safety recognition, particularly for masked and evolution risks (see Section 5.1 for the definition of the types of risk). These gaps were most pronounced with emerging expressions (e.g., skibidi, gyatt), context-dependent phrases (e.g., let him cook), and masked negativity in seemingly innocent language. In terms of expression category, gaming terminology (42% of expressions) showed highest comprehension rates across all evaluator groups (68.4% basic understanding, 42.3% risk detection), aligning with Gen Alphas gaming platform engagement patterns. Platformspecific terms (24%) demonstrated critical gaps in cross-platform meaning recognition (58.2% basic understanding, 31.5% risk detection). At the same time, particularly concerning pattern emerged around acronyms, where historical meaning shifts created significant moderation challenges. Table 6 illustrates how seemingly innocuous acronyms can mask serious safety concerns. Human moderators achieved only 28% accuracy in identifying current usage patterns of such evolved acronyms, while AI systems showed similar limitations with 32% accuracy."
        },
        {
            "title": "4.2 Human Performance Evaluation\nAs from above we distinguish between Gen Alpha, parents and\ncaregivers and professional moderators.",
            "content": "4.2.1 Gen Alpha Users. Gen Alpha participants demonstrated near-native comprehension that far exceeded all other evaluator groups: 98% accuracy in basic interpretation, 96% in context recognition, and 92% in identifying potential harm, see Table 5. This proficiency highlights the concerning gap between these young users and those responsible for their online safety. An analysis of the Gen Alpha responses revealed some unique capabilities, for instance: Accurate tracking of meaning evolution across platforms and communities; Intuitive recognition of context-dependent meaning shifts; Gen Alpha Expression Risk and AI Moderation FAccT 25, June 2326, 2025, Athens, Greece Acronym Historical Usage Current Usage Moderation Challenge kys know your self (2000s wellness) Self-harm suggestion Historical meaning masks current risk iykyk if you know (general usage) In-group marker Used to obscure concerning content fr for real (confirmation) Dismissal marker Context-dependent negativity Loss (gaming) Social status attack Evolution game harassment from term to Table 6: Acronym Evolution and Moderation Challenges Ability to identify subtle negative connotations in seemingly positive phrases. While this native-level understanding represents valuable resource, it also creates risk: Gen Alpha users often perceive adults as digitally incompetent, deterring them from seeking help when encountering problematic interactions. 4.2.2 Parents and Caregivers. Parents showed particular limitations in platform-specific knowledge, with metrics revealing critical communication barriers between them and their children: Gaming-specific terminology recognition: 38% accuracy; Rapidly evolving expressions (less than 3 months old): 31% accuracy; Cross-platform meaning variations: 29% accuracy. These limitations help explain why 76% of Gen Alpha users in our study reported reluctance to discuss concerning online interactions with parents. When parents lack contextual knowledge of digital communication patterns, they may misinterpret or minimize experiences that young users find genuinely concerning. 4.2.3 Professional Moderators. Professional content moderators performed better than parents on basic interpretation (72%) but still showed significant limitations in context recognition (45%) and safety detection (38%). This performance gap creates critical blind spots in current content moderation systems. The moderators struggled most with: Platform-specific contextual variations; Identifying masked negativity in seemingly innocuous phrases; Tracking rapidly evolving meanings. These challenges reflect the inherent difficulty of moderating Gen Alpha content without direct involvement from Gen Alpha users themselves in the moderation process."
        },
        {
            "title": "4.3 LLM Performance Evaluation\nThe Chi-square tests showed significant differences in performance\nacross AI models (𝑝 < 0.05). Claude had the highest overall perfor-\nmance (68.1% basic understanding, 56.2% context awareness, 42.3%\nsafety recognition), while Llama 3 showed lowest (58.3% basic, 42.1%\ncontext, 32.5% safety). All models showed better performance in",
            "content": "gaming compared to mixed or cross-platform meanings, see Table 7. Model Gaming Context Social Context Mixed Context GPT-4 Claude Gemini Llama 3 67.3 71.2 64.5 61. 65.8 68.9 63.2 58.4 59.4 62.3 57.8 54.2 Table 7: Model Context Understanding by Category (%) The analysis revealed three critical patterns where AI systems failed to protect Gen Alpha users: failures in context recognition, safety assessment, and understanding of language evolution (see Sections 3.3, 3.4 and Table 8). In masked harassment detection, systems consistently misclassified subtle negative interactions, such as interpreting Is it acoustic as neutral when they carried discriminatory undertones. For context-dependent hostility, particularly in gaming environments, supportive-appearing phrases like let him cook were misinterpreted when used mockingly. Evolutionbased failures showed significant lag in recognizing meaning shifts, especially with hybrid terms like skibidi sigma where negative connotations developed through community usage. These failure patterns highlight specific areas where AI content moderation systems require improvement to effectively protect Gen Alpha users from sophisticated forms of online harassment that exploit their unique communication patterns. Pattern Example Safety Impact Masked Harassment ContextDependent EvolutionBased Is it acoustic misclassified let him cook misinterpreted Delayed sigma detection skibidi Permits discrimination Enables masked bullying Allows trends harmful Table 8: Critical AI System Failure Patterns further crucial evaluation was about fairness. Our evaluation revealed significant disparities in AI system interpretation across demographic contexts [7]. Variants common among minority youth communities showed 23% higher false positive rates for policy violations. Context-dependent terms discussing identity and belonging had 31% higher misclassification rates [2]. We had the following key findings: Expression variants common in minority communities: 23% higher false positives; Identity and belonging discussions: 31% higher misclassification; Harassment detection accuracy: 42% lower for evolving language targeting marginalized groups. These findings align with broader patterns of algorithmic bias in content moderation systems [3] while highlighting specific impacts on Gen Alpha communication practices [2]. FAccT 25, June 2326, 2025, Athens, Greece Mehta and Giunchiglia"
        },
        {
            "title": "5.1 Vulnerability Assessment Framework\nOur framework provides a systematic approach to evaluating mod-\neration gaps in Gen Alpha’s digital communication, building on\nestablished methodologies for analyzing online risks to users [14].\nWhile traditional frameworks focus on explicit content, our ap-\nproach specifically addresses the linguistic complexity of Gen Alpha\ncommunication [24] and the challenges this presents for automated\nprotection systems [10]. The framework is organized along three\ndimensions, namely, risk categories (Section 5.1.1), moderation gap\nmetrics (Section 5.1.2) and help-seeking barriers, meaning by this\nbarriers preventing the provision of help to Gen Alpha users (Sec-\ntion 5.1.3).",
            "content": "Risk Type Direct Risks Masked Risks Grooming Indicators SubCategory Example Expression Content Moderation Implications youre such pick me NPC behavior Dehumanizing lanExplicit social exclusion tactics Overt bullying Direct exclusion Status attacks Coded harassment beta male behavior is it acoustic Subtle manipulation Social pressure let him cook (mocking) youre him not Trust building Isolation attempts Secretkeeping you passed the vibe check theyre not giving keep it lowkey guage patterns Hierarchy-based harassment Discriminatory content masked as inquiry Context-dependent negativity Peer through phrases pressure trending False sense of security creation Social tactics Privacy manipulation separation boundary Table 9: Gen Alpha Digital Communication Risk Categories showing how seemingly innocent phrases can carry significant safety implications in Gen Alpha contexts. To operationalize this model in our evaluation and annotation workflow, we applied structured coding scheme. Table 10 presents the taxonomy used by human annotators and expert reviewers during expression labeling. Additionally, Table 11 provides three examples of how common Gen Alpha expressions evolve, most of the time very rapidly, in meaning and intent. 5.1.2 Moderation Gap Metrics. Moderation effectiveness was measured through several complementary metrics. The pattern detection rate tracked the percentage of concerning expressions successfully identified by both human moderators and AI systems across platforms. Response latency measured the critical time gap between new expression emergence and protection system recognition, revealing significant delays in adapting to evolving language. Context understanding assessed accuracy in interpreting platformspecific meaning variations, particularly in gaming environments where expressions often carried multiple contextual implications. The risk pattern recognition metric evaluated success rates in identifying potentially harmful usage patterns as expressions evolved across different communities and platforms. 5.1.3 Help-Seeking Barriers. The analysis revealed several interconnected factors that prevented effective protection of Gen Alpha users. Most critically, protection systems consistently lagged behind the rapid evolution of expressions, creating windows of vulnerability where concerning interactions went undetected. This technical gap was compounded by broader context comprehension Figure 1: Framework for analyzing Gen Alpha digital communication vulnerabilities. The diagram shows the relationship between different types of risks, protection systems, and resulting moderation gaps. 5.1.1 Risk Categories. Figure 1 presents an overview of the risk categories and protection systems analyzed, incorporating both established threat models [23] and emerging challenges specific to Gen Alphas digital environment [29]. Based on the framework in Figure 1, Table 9 presents the taxonomy of risks identified in Gen Alpha digital communication patterns. This classification has emerged from the analysis of the dataset introduced in Section 3.3. Direct risks, Masked risks, and Grooming risks organize risks in three categories organized according to how implicit the corresponding risks are in given Gen Alpha expression. Each risk type represents distinct challenges for content moderation systems, with examples Gen Alpha Expression Risk and AI Moderation FAccT 25, June 2326, 2025, Athens, Greece Risk Category Label Code R1 Description / Criteria R3 Direct Risk EvolutionBased Risk Masked Negativity Overtly harmful content such as bullying, threats, or hate speech with explicit negative intent. Harassment or exclusion concealed through slang, memes, or humor; requires contextual inference. Expressions that gain harmful connotation over time or through platform migration. Expressions without significant risk indicators, including benign uses or context-neutral phrases. Terms whose interpretation varies by platform environment (e.g., gaming vs. social media). Risk arising from culture-specific meanings or regional translation effects. Table 10: Risk Coding Framework to Evaluate Gen Alpha Expression Low Risk / Neutral Cultural Risk Variant PlatformSpecific Risk R4 R0 R5 Expression Original Usage Evolved Usage Is it acoustic Medical inquiry Discriminatory term Skibidi Rizz Status marker Manipulation marker Dance reference Charisma Table 11: Expression Evolution Patterns challenges, where both human moderators and AI systems struggled to understand platform-specific meanings that were intuitively clear to Gen Alpha users. The resulting trust gap led many Gen Alpha users to avoid reporting concerning interactions, believing adults would misunderstand or minimize their experiences. These issues were further exacerbated by detection inconsistency across platforms, where moderation effectiveness varied significantly between different digital spaces that the users regularly navigated."
        },
        {
            "title": "5.2 Vulnerability Assessment evaluation\nApplying the framework in Section 5.1, we have identified three\ninterconnected challenges compromising the existing protection\nmechanisms. A first critical vulnerability stems from communica-\ntion isolation, with 73% of Gen Alpha users regularly using terms\ntheir adult protectors don’t understand. This linguistic gap enables\nconcerning patterns across our risk categories:",
            "content": "Platform-specific language masks harmful content (e.g., let him cook used mockingly); Gaming terminology obscures subtle harassment (e.g., skill issue); Trendy expressions facilitate manipulation (e.g., you passed the vibe check). The protection system effectiveness shows concerning limitations across both human and automated monitoring. Humans recognize only 45% of potentially harmful uses of new expressions; AI systems are even lower performance at 32-42% accuracy in detecting concerning patterns. This limitation is exacerbated by cross-platform variations that create additional monitoring blind spots. Expression Positive Usage Risk Pattern Let him cook Skill issue Youre mogging Achievement recognition Performance praise Learning opportunity Sarcastic mockery Harassment marker Status-based exclusion Table 12: Gaming Context Expression Analysis To illustrate how identical phrases may function differently across digital environments, Table 12 and Table 13 compare usage and risks in gaming and social settings. Expression Positive Usage Risk Pattern Flop era Main character Pick me Self-deprecation Group exclusion Self-confidence Mockery target Social isolation Table 13: Social Media Context Expression Analysis Perhaps most concerning are the barriers to help-seeking behavior among Gen Alpha users. Our data reveals that the rapid evolution of expressions (averaging 2-3 new meanings per month) consistently outpaces protection systems ability to adapt. We identified critical protection gaps: 76% of users showed help-seeking reluctance, 82.5% of expression meanings evolved faster than moderation updates, and cross-platform monitoring varied by 45%. This creates dynamic where harmful interactions can flourish in the gaps between recognized and emerging language patterns. Platformspecific variations further complicate consistent safety monitoring, as expressions may carry different implications across different digital spaces. When asked to assess vulnerability, all four LLMs demonstrated relatively high accuracy in identifying direct risks but performed significantly worse on masked risks and evolution-based concerns, see Table 14. These overall low performance patterns suggest that current AI content moderation systems may offer complementary capabilities to human moderators but cannot fully replace human judgment, particularly for safety-critical decisions involving contextual understanding. Model Direct Risks Masked Risks Evolution-Based GPT-4 Claude Gemini Llama 3 72.4 75.8 69.3 65.7 45.6 48.9 42.8 38.4 38.2 41.5 35.7 32.3 Table 14: Safety Detection Performance by Risk Type (%) FAccT 25, June 2326, 2025, Athens, Greece Mehta and Giunchiglia"
        },
        {
            "title": "6 ETHICAL CONSIDERATIONS\nOur analysis revealed several critical insights with significant impli-\ncations for both research and ethical practice in youth online safety.\nWe found that over two-thirds of concerning interactions used\nterminology unfamiliar to human moderators, while AI systems\nfailed to detect nearly half of masked harassment attempts. These\nfindings underscore a critical gap that leaves Gen Alpha users par-\nticularly vulnerable to sophisticated forms of online manipulation.\nThe evaluation framework(s) we have proposed demonstrate(s) the\nimportance and feasibility of a youth-centered design if safety sys-\ntems. By establishing suitable methodologies, this work provides a\nfoundation for future studies while highlighting the unique chal-\nlenges of conducting research with Gen Alpha participants. These\nresults have ethical implications extend in two key directions.",
            "content": "First, the research process itself requires careful attention to ethical considerations. Thus, for instance, to name the procedures that we enforced in this work: All participation followed strict consent protocols with both youth and guardian approval; Data collection focused exclusively on public communications; Youth participation guidelines were developed and strictly enforced; Privacy protections were implemented at all research stages. In turn, our findings raise important questions about broader protection concerns in digital spaces, for instance: How to balance necessary protection with youth autonomy; Appropriate boundaries for communications monitoring; Ensuring fairness in automated moderation systems; Protecting privacy while maintaining safety. These ethical considerations shape not only how such research should be conducted but also how platforms should approach the challenge of protecting Gen Alpha. As second key point, this research highlights urgent needs for greater accountability in AI safety systems protecting Gen Alpha users. Current gaps in understanding between AI systems and youth communication demand regular, systematic bias audits that examine system performance across diverse communities and contexts. These audits must go beyond standard metrics to assess how automated moderation affects different segments of the Gen Alpha population. Meaningful youth consultation represents another, third, critical accountability requirement. Gen Alpha users, particularly those from marginalized communities, must have formal channels to inform both the design and evaluation of safety systems that affect their digital experiences. This consultation should extend beyond superficial feedback to include structured input on how safety systems interpret and moderate their evolving communication patterns. The appeals process for automated moderation decisions requires particular attention to the Gen Alpha context. Clear, age-appropriate mechanisms must exist for contesting AI decisions, especially given rapid evolution of youth communication patterns. These mechanisms should acknowledge that traditional human moderators may not fully understand the contested communications, necessitating new approaches to appeals review. Finally, to ensure accountability, platforms must commit to full documentation of how their automated moderation systems affect different youth communities. This documentation should include: Regular public reporting on moderation impacts across different demographic groups Clear disclosure of moderation system limitations regarding youth communication Transparent metrics on appeals outcomes and response times Regular updates on efforts to improve system understanding of evolving language patterns These accountability measures aim to ensure that AI safety systems serve their protective function without unduly restricting Gen Alphas authentic digital expression. The goal is to create framework where protection and transparency work in concert, rather than opposition."
        },
        {
            "title": "7 CONCLUSION\nThis research provides the first systematic evaluation of how AI\nsafety systems interpret Gen Alpha’s unique digital communication\npatterns. By incorporating Gen Alpha users directly in the research\nprocess, we’ve quantified critical comprehension gaps between\nthese young users and their protectors—both human and AI.",
            "content": "The identification of three critical failure patterns contextdependent interpretation, masked harassment detection, and evolutionbased meaning shifts highlights specific vulnerabilities in current content moderation approaches. These gaps create dangerous blind spots where concerning interactions may go undetected, particularly given Gen Alphas documented reluctance to seek adult help when encountering problematic online behavior. While AI tools can help identify concerning patterns, our findings support Gillespies argument - full automation of moderation may be neither feasible nor desirable for complex social judgment. Instead, AI systems should enhance human moderation, particularly for Gen Alpha content where context and rapidly evolving meanings are critical. This is the direction of our future work. ACKNOWLEDGMENTS This research was partially supported by the European Unions Horizon 2020 FET Proactive project WeNet The Internet of Us (grant agreement no. 823783). The first author conducted this work as research intern at System Two AI LLC, where she led the data collection, evaluation design, and core authorship of the study. The second author provided mentorship throughout and played key role in refining the structure, methodology, and academic positioning of the work. The authors also thank Virendra Mehta for coordinating experimental infrastructure and supporting the research process. REFERENCES [1] Neetra Chakraborty. 2024. comprehensive guide to Gen Alpha slang. https://thewildcattribune.com/18753/satire/a-comprehensive-guide-togen-alpha-slang/ Section: Satire. [2] Thiago Dias Oliva, Dennys Marcelo Antonialli, and Alessandra Gomes. 2021. Fighting Hate Speech, Silencing Drag Queens? Artificial Intelligence in Content Moderation and Risks to LGBTQ Voices Online. Sexuality & Culture 25, 2 (April 2021), 700732. https://doi.org/10.1007/s12119-020-09790-w [3] Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K. Ahmed. 2024. Bias Gen Alpha Expression Risk and AI Moderation FAccT 25, June 2326, 2025, Athens, Greece Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (Eds.). Association for Computational Linguistics, Miami, Florida, USA, 1255812575. https://doi.org/ 10.18653/v1/2024.emnlp-main.698 [22] Nikolaos Mylonas, Nikolaos Stylianou, Despoina Chatzakou, Theoni Spathi, Stefanos Alevizos, Annika Drandaki, Alexandros Koufakis, George Kalpakis, Theodora Tsikrika, and Stefanos Vrochidis. 2025. Online Child Grooming Detection: Challenges and Future Directions. In Paradigms on Technology Development for Security Practitioners, Ilias Gkotsis, Dimitrios Kavallieros, Nikolai Stoianov, Stefanos Vrochidis, Dimitrios Diagourtas, and Babak Akhgar (Eds.). Springer Nature Switzerland, Cham, 237247. https://doi.org/10.1007/978-3-031-62083-6_19 [23] Atte Oksanen, James Hawdon, Emma Holkeri, Matti Näsi, and Pekka Räsänen. 2014. Exposure to Online Hate among Young Social Media Users. In Soul of Society: Focus on the Lives of Children & Youth. Vol. 18. Emerald Group Publishing Limited, 253273. https://doi.org/10.1108/S1537-466120140000018021 ISSN: 1537-4661. [24] Yulia Andreevna Petrova and Olga Nikolaevna Vasichkina. 2021. The impact of the development of information technology tools of communication on digital culture and Internet slang. SHS Web of Conferences 101 (2021), 01002. https: //doi.org/10.1051/shsconf/202110101002 Publisher: EDP Sciences. [25] Cynantia Rachmijati and Sri Supiah Cahyati. 2024. Know Your Skibidi: Navigating Gen Alphas Slang Types and Trend on Social Media X. International Conference On Research And Development (ICORAD) 3, 2 (Dec. 2024), 392400. https://doi. org/10.47841/icorad.v3i2.219 Number: 2. [26] Zhewei Sun, Qian Hu, Rahul Gupta, Richard Zemel, and Yang Xu. 2024. Toward Informal Language Processing: Knowledge of Slang in Large Language Models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), Kevin Duh, Helena Gomez, and Steven Bethard (Eds.). Association for Computational Linguistics, Mexico City, Mexico, 16831701. https://doi.org/10. 18653/v1/2024.naacl-long.94 [27] Zhewei Sun and Yang Xu. 2022. Tracing Semantic Variation in Slang. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 12991313. https://doi.org/10.18653/v1/2022.emnlp-main.84 [28] Grace Turschak. 2024. Gen Alpha is developing slang strangely fast. https://www.technicianonline.com/opinion/opinion-gen-alpha-is-developingslang-strangely-fast/article_8dd9a3b6-64c0-11ef-b8fb-07e81cf41423.html [29] Runyu Wang, Tun Lu, Peng Zhang, and Ning Gu. 2024. Role Identification based Method for Cyberbullying Analysis in Social Edge Computing. https: //doi.org/10.26599/TST.2024.9010066 arXiv:2408.03502 [cs]. [30] Helen Whittle, Catherine Hamilton-Giachritsis, Anthony Beech, and Guy Collings. 2013. review of young peoples vulnerabilities to online grooming. Aggression and Violent Behavior 18, 1 (Jan. 2013), 135146. https://doi.org/ 10.1016/j.avb.2012.11. [31] Michelle F. Wright. 2024. The Role of Parental Mediation and Age in the Associations between Cyberbullying Victimization and Bystanding and Childrens and Adolescents Depression. Children 11, 7 (July 2024), 777. https: //doi.org/10.3390/children11070777 Number: 7 Publisher: Multidisciplinary Digital Publishing Institute. [32] Julia Łosiak Pilch, Paweł Grygiel, Barbara Ostafińska-Molik, and Ewa Wysocka. 2022. Cyberbullying and its protective and risk factors among Polish adolescents. Current Issues in Personality Psychology 10, 3 (Jan. 2022), 190204. https://doi. org/10.5114/cipp.2021.111404 and Fairness in Large Language Models: Survey. Computational Linguistics 50, 3 (Sept. 2024), 10971179. https://doi.org/10.1162/coli_a_00524 Place: Cambridge, MA Publisher: MIT Press. [4] Tarleton Gillespie. 2020. Content moderation, AI, and the question of scale. Big Data & Society 7, 2 (July 2020), 2053951720943234. https://doi.org/10.1177/ 2053951720943234 Publisher: SAGE Publications Ltd. [5] Fausto Giunchiglia. 1993. Contextual Reasoning. Epistemologia, special issue on Linguaggi le Macchine 16 (1993), 345364. https://iris.unitn.it/handle/11572/ 52396 Accepted: 2015-04-21T15:49:03Z. [6] Fausto Giunchiglia, Khuyagbaatar Batsuren, and Abed Alhakim Freihat. 2023. One World - Seven Thousand Languages (Best Paper Award, Third Place). In Computational Linguistics and Intelligent Text Processing, Alexander Gelbukh (Ed.). Springer Nature Switzerland, Cham, 220235. https://doi.org/10.1007/9783-031-23793-5_ [7] Juan Felipe Gomez, Caio Machado, Lucas Monteiro Paes, and Flavio Calmon. 2024. Algorithmic Arbitrariness in Content Moderation. In The 2024 ACM Conference on Fairness, Accountability, and Transparency. ACM, Rio de Janeiro Brazil, 22342253. https://doi.org/10.1145/3630106.3659036 [8] Noah D. Goodman and Michael C. Frank. 2016. Pragmatic Language Interpretation as Probabilistic Inference. Trends in Cognitive Sciences 20, 11 (Nov. 2016), 818829. https://doi.org/10.1016/j.tics.2016.08.005 [9] Ellen Johanna Helsper and David Smahel. 2020. Excessive internet literuse by young Europeans: psychological vulnerability and digital acy? Information, Communication & Society 23, 9 (July 2020), 12551273. https://doi.org/10.1080/1369118X.2018.1563203 Publisher: Routledge _eprint: https://doi.org/10.1080/1369118X.2018.1563203. [10] Fatima N. Ali Hussein and Hiba J. Aleqabie. 2023. Cyberbullying Detection on Social Media: Brief Survey. In 2023 Second International Conference on Advanced Computer Applications (ACA). 16. https://doi.org/10.1109/ACA57612. 2023.10346758 [11] Alena Höfrová, Venera Balidemaj, and Mark A. Small. 2024. systematic literature review of education for Generation Alpha. Discover Education 3, 1 (Aug. 2024), 125. https://doi.org/10.1007/s44217-024-00218-3 [12] Institute for the Protection and Security of the Citizen (Joint Research Centre) and Stéphane Chaudron. 2015. Young children (0-8) and digital technology: qualitative exploratory study across seven countries. Technical Report. Publications Office of the European Union. https://data.europa.eu/doi/10.2788/ [13] Daphna Keidar, Andreas Opedal, Zhijing Jin, and Mrinmaya Sachan. 2022. Slangvolution: Causal Analysis of Semantic Change and Frequency Dynamics in Slang. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, Dublin, Ireland, 14221442. https://doi.org/10.18653/v1/2022.acl-long.101 [14] Robin M. Kowalski and Susan P. Limber. 2007. Electronic Bullying Among Middle School Students. Journal of Adolescent Health 41, 6, Supplement (Dec. 2007), S22S30. https://doi.org/10.1016/j.jadohealth.2007.08.017 [15] Mislav Malević. 2022. The role of gaming in vocabulary acquisition. info:eurepo/semantics/masterThesis. University of Zagreb. Faculty of Humanities and Social Sciences. Department of English language and literature. https://urn.nsk. hr/urn:nbn:hr:131:331660 [16] Virendra Mehta, Fabio Casati, Gopal Sarda, Sagar Davasam, and Kannan Govindarajan. 2020. Detecting Feature Eligibility Illusions in Enterprise {AI} Autopilots. https://www.usenix.org/conference/opml20/presentation/casati [17] Virendra Mehta, Joao Monteiro, Tosten Scholak, and David Vazquez. 2023. Multilingual Code Retrieval Without Paired Data: New Benchmark and Experiments. In ICLR DL4C Workshop. [18] Virendra Mehta, Taishi Nakamura, Mayank Mishra, Simone Tedeschi, Yekun Chai, Jason T. Stillerman, Felix Friedrich, Prateek Yadav, Tanmay Laud, Vu Minh Chien, Terry Yue Zhuo, Diganta Misra, Ben Bogin, Xuan-Son Vu, Marzena Karpinska, Arnav Varma Dantuluri, Wojciech Kusa, Tommaso Furlanello, Rio Yokota, Niklas Muennighoff, Suhas Pai, Tosin Adewumi, Veronika Laippala, Xiaozhe Yao, Adalberto Barbosa Junior, Aleksandr Drozd, Jordan Clive, Kshitij Gupta, Liangyu Chen, Qi Sun, Ken Tsui, Nour Moustafa-Fahmy, Nicolo Monti, Tai Dang, Ziyang Luo, Tien-Tung Bui, Roberto Navigli, Matthew Blumberg, Victor May, Hiep Nguyen, and Sampo Pyysalo. 2025. Aurora-M: Open Source Continual Pre-training for Multilingual Language and Code. In Proceedings of the 31st International Conference on Computational Linguistics: Industry Track, Owen Rambow, Leo Wanner, Marianna Apidianaki, Hend Al-Khalifa, Barbara Di Eugenio, Steven Schockaert, Kareem Darwish, and Apoorv Agarwal (Eds.). Association for Computational Linguistics, Abu Dhabi, UAE, 656678. https://aclanthology.org/2025.coling-industry.56/ [19] Virendra Kumar Mehta. 2011. Handling caught exceptions. https://patents. google.com/patent/US7877740B2/en [20] Virendra Kumar Mehta and Sandya S. Mannarswamy. 2011. System and method for dynamic instrumentation. https://patents.google.com/patent/US7926042B2/ en [21] Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, and Xueqi Cheng. 2024. SLANG: New Concept Comprehension of Large Language Models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,"
        }
    ],
    "affiliations": [
        "University of Trento, Trento, Italy",
        "Warren Hyde Middle School, Cupertino, California, USA"
    ]
}