{
    "paper_title": "Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification",
    "authors": [
        "Yahya Masri",
        "Emily Ma",
        "Zifu Wang",
        "Joseph Rogers",
        "Chaowei Yang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having a model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as a benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 2 1 ] . [ 1 0 9 7 7 0 . 1 0 6 2 : r a"
        },
        {
            "title": "Joseph Rogers\nGeorge Mason University",
            "content": "Chaowei Yang George Mason University Abstract System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrievalaugmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration."
        },
        {
            "title": "Introduction",
            "content": "System logs are vital components of modern computing infrastructure, capturing operational events, warnings, and performance information across distributed systems [14]. They play critical role in diagnosing faults, monitoring system health, and supporting automated responses in large-scale environments such as data centers and digital twins (DTs) [57]. However, as computing systems generate massive volumes of logs with complex, context-dependent language, manual interpretation has become infeasible [812]. The continuous flow of log entries produced by servers far exceeds Email: cyang3@gmu.edu 1 human review capacity, leading to delayed fault detection and increased mean time to resolve [13, 14]. Recent advances in combining large language models (LLMs) and retrieval-augmented generation (RAG) have demonstrated that external context can significantly improve model reliability on tasks that require domain awareness and factual grounding. Rather than relying solely on parameters learned during training, RAG allows models to incorporate relevant evidence at inference time by querying knowledge database. This approach has shown strong benefits in knowledge-intensive applications such as question answering, structured information extraction, and technical reasoning, where precision and traceability are essential [1517]. In system operation settings, retrieval enables models to surface historical signals, recurring patterns, and contextual system metadata, creating the foundation for downstream diagnostic reasoning. As DT architectures increasingly integrate intelligence and autonomy, retrieval becomes key mechanism for linking runtime observations to prior system states, enabling more interpretable and context-aware decision pipelines. Events and messages originating from the kernel, applications, and users of system are recorded in system logs. Thus, these logs form an extensive record of processes executed within network [18]. This provides system administrators with crucial resource for monitoring performance, detecting security threats, and conducting root cause analysis (RCA) [1820]. The Syslog protocol was created as framework to allow machines to transmit these event notifications [21]. Each Syslog message contains PRI component that consists of <, number, and >. The number is known as the severity value, which is combination of the logs Facility and Severity values. The Facility value is an integer ranging from 0 to 23, which describes the context of the log. The Severity value is an integer from 0 to 7 that quantifies the risk level of each log. Multiplying the Facility value by 8 and adding the Severity yields the Priority, which administrators use to identify and resolve system errors [22]. This lack of strict standardization limits the use of severity labels as canonical ground truth. However, it also makes them realistic and challenging probe for evaluating whether language models (LMs) can align log content with operational intent under ambiguity [23]. Within DT-oriented monitoring pipelines, such log interpretation must be both accurate and latency-efficient, motivating the evaluation of compact, deployable LMs under strict output and runtime constraints. The study focuses on evaluating small language models (SLMs) and small reasoning language models (SRLMs) using log severity classification as controlled probe of their ability to ground real-world system log semantics under constrained outputs, based on logs collected from journalctl within the computing infrastructure."
        },
        {
            "title": "2.1 Log Classification with Manual Methods",
            "content": "In the past, developers created sets of rules for processes such as anomaly detection, leading to manually implemented systems. However, with the rapid development of computing infrastructure in both complexity and scale, these methods have become time-consuming and error-prone [24]. Modern computing systems generate logs rapidly; for example, Le and Zhang [25] estimate rate of 30-50 gigabytes (about 120200 million lines) per hour for Alibabas email production cloud computing system. The massive volume of system logs produced is impossible to manually traverse, 2 complicating efforts to uncover patterns and nuanced faults that contribute to system failures [26]. He et al. [27] observe another notable limitation: developers may suffer from insufficient technical expertise, such as an understanding of runtime behaviors, the functions of different log levels, or best logging practices. Often, large-scale systems will have hundreds of contributors, with each individual having deep knowledge of one sub-component of the overall system. Due to this specialization, developers may have gaps in their understanding of overall system behaviors and relationships [28]. Both conditions lead to struggles with assigning the proper log level. As result, developers often must retrace their work and revise the levels assigned to previous system logs, further decreasing the efficiency [29]."
        },
        {
            "title": "2.2 Log Classification with Traditional ML Methods",
            "content": "Due to the challenges of manual log classification, autonomous analysis methods have been explored through the creation of traditional machine learning (ML) methods [3032]. Commonly used ML algorithms include random forest (RF) and support vector machine (SVM) [33]. Recently, Qi et al. [34] utilized RF as baseline, observing strong performance on Hadoop Distributed File System (HDFS), OpenStack, and BlueGene/L (BGL) datasets. The RF model often outperforms other classical ML methods, such as principal component analysis (PCA) and invariant mining (IM). Similarly, Li et al. [35] evaluate SVM as baseline and observe strong performance across the BGL and HDFS datasets, with the model achieving an F1-score of 0.96 and 0.92, respectively. Chen et al. [36] observe that while ML methods represented significant development for log analysis, key limitations prevent their widespread adaptation for practical use. Particularly, these methods often require the set of log events to be known beforehand, leading to difficulty in accounting for previously unseen events or sequences. As systems are upgraded and altered over time, many methods struggle to address new log events or changes in log semantics [37]. Another notable limitation of traditional ML models is their limited ability to model meaningful temporal dependencies between log events, including cause-related event sequences and abnormal timing patterns [38]. As result, critical information such as abnormally long delays or unusual event sequences is often not taken into consideration."
        },
        {
            "title": "2.3 Log Classification with DL Methods",
            "content": "More recently, deep learning has been explored to improve autonomous system log classification and analysis [3941]. Guo et al. [42] propose Logformer, Transformer-based framework that is pre-trained on source domain log data and applied to the target domain via shared parameters, enhancing cross-domain performance. Logformer achieved higher F1 scores than baselines on the HDFS, BGL, and Thunderbird datasets. Li et al. [43] propose Log2Graphs, graph neural network model that detects graph-level anomalies for log anomaly detection. Compared to traditional baseline methods for ML and DL, Logs2Graphs performed better or similar across five datasets (HDFS, BGL, High-Performance Computing (HPC), Zookeeper, and Proxifier) as indicated by the area under the receiver operating characteristic curve (ROC AUC) and the area under the precision-recall curve (PRC AUC) measurements. Li et al. [29] propose DeepLV, an automated DL approach for log level suggestion, outperforming ordinal regression (OR) and one-hot encoding recurrent neural network (RNN) baselines with 3 respect to accuracy and AUC. Notably, this approach applies ordinal encoding to log levels in order to accurately represent sequential relationships between logs. The approach demonstrates best performance when combining both log message features and syntactic context, revealing the logs location. Wang et al. [44] present OC4Seq, multi-scale one-class RNN for anomaly detection. OC4Seq was tested on the HDFS, BGL, and RUBiS system log datasets. It was compared against five anomaly detection baselines: PCA, IM, One-Class SVM (OC-SVM), DeepLog, and DeepSVDD. OC4Seq demonstrates strong performance, achieving the highest F1 score across all three datasets with an F1 score of 0.976, 0.747, and 0.985 for HDFS, BGL, and RUBiS, respectively. However, Yu et al. [45] caution that complex DL methods may not always be more accurate or time-efficient than traditional ML methods, especially when considering the greater computational costs of DL models. DL methods still suffer from some of the same issues that ML methods contend with, such as poor generalization across different datasets due to differences in log syntax and limitations on the quantity of labeled logs available for training. As such, creating model that can be applied across different software systems poses significant challenge [46]. Currently, both ML and DL models often require manual intervention to optimize performance, especially for preprocessing and parameter tuning [47]."
        },
        {
            "title": "2.4 Log Classification using LLMs",
            "content": "Several recent works have focused on leveraging LMs specifically for log classification, demonstrating significant improvements over traditional methods. Yang and Harris [48] propose LogLLaMA, LLaMA2-based framework that first learns normal log patterns by predicting next log key sequences, then refines anomaly detection with reinforcement learning objective using Top-k rewards. Across BGL, HDFS, and Thunderbird, LogLLaMA consistently surpasses traditional and prior deep learning baselines, showing stronger robustness to unstable or unstructured logs and better generalization to unseen patterns. Zhang et al. [49] present GPT-based log anomaly detection framework that fine-tunes GPT 2 on structured log sequences derived from Drain parsed event IDs, then optimizes training with Focal Loss to handle extreme class imbalance. This optimization improves precision, recall, and F1 over vanilla GPT-2 while matching GPT-3.5 performance with efficient local deployment. Additionally, Huang et al. [50] introduce LogRules, lightweight log analysis framework designed to reduce hallucinations in LLMs by teaching them explicit reasoning rules from logs. The system operates in three stages: induction, where large model like GPT-4o-mini generates and validates log-related rules; alignment, where smaller models ( 8B parameters) are fine-tuned via contrastive preference optimization to better apply those rules; and deduction, where rule-enhanced prompts guide inference on unseen logs. Across Loghub datasets, LogRules outperforms case-based LLM prompting and traditional methods in both log parsing and log-based anomaly detection, improving F1 by over 30% on benchmarks like BGL and Spirit. This demonstrates that explicit rule induction and alignment substantially enhance reasoning accuracy and generalization for smaller LLMs in system log analysis. Furthermore, recent studies have systematically evaluated the effectiveness of LMs in automating log-level classification tasks within software systems. Heng et al. [51] benchmarked twelve opensource LLMs for log-level classification of Java source-code logging statements, comparing Fill-Mask and text-generation models across zero-shot, few-shot, and fine-tuned settings. Their results showed modest effectiveness, with baseline zero-shot and few-shot prompting often yielding accuracies below 4 30%. Even with fine-tuning the best models (e.g., GraphCodeBERT, CodeLlama) plateaued around 6070% accuracy, highlighting ongoing challenges in deploying LLMs for static code-embedded log statement classification. Building on the limitations identified in prior work, Ouatiti et al. [52] introduce OmniLLP, retrieval-augmented framework that replaces random in-context examples with examples drawn from clusters that reflect real project structure. Source files are grouped by semantic similarity using code embeddings and by developer ownership using version control history, and in-context examples are retrieved from these coherent neighborhoods. Evaluated on four large open-source Java systems, this cluster-informed retrieval improves AUC by up to 8% over random and documentation-based baselines, and the combined semantic-plus-ownership setting achieves AUC scores between 0.88 and 0.96, showing the effectiveness of incorporating software engineering context into LLM-based log level prediction. Current research on LMs for log analysis remains fragmented and does not yet provide comprehensive benchmark for real-world operational system logs. Many studies rely on Java logging statements or code-contextual logs rather than production system logs [51], while others focus on cybersecurity or intrusion-detection logs that differ substantially from general Linux operational logs [53]. Additional work centers on telecom, network-device, or vendor-specific logs [54], limiting generalizability to common system environments. Several influential benchmarks use structured datasets such as BGL, HDFS, or Thunderbird [55, 56], which do not capture the temporal structure, irregularity, and noise of real-world journalctl logs. Other studies examine log-generation tasks tied to source code instead of operational log interpretation [57]. Prior work comparing prompting strategies and RAG in log and text analysis remains limited in scope and misaligned with the requirements of system-log severity classification. Existing studies in intrusion detection and security contexts compare zero-shot, few-shot, RAG, and fine-tuning approaches, but they rely on proprietary intrusion datasets rather than operational Linux logs [58, 59]. Additional work on microservices and industrial pipelines investigates prompt engineering techniques such as minimal instruction, Chain-of-Thought (CoT), and few-shot prompting, but focuses on log summarization, not classification [60]. Even within log-specific literature, prompting-strategy studies emphasize anomaly detection, log parsing, and summarization rather than classification tasks, and use heavily preprocessed and template-parsed HPC or distributed-system logs as BGL, HDFS, and Thunderbird instead of journalctl logs [61, 62]. While recent work has explored RAG in log analysis, these studies primarily examine RAGs vulnerability to noisy, outdated, or heterogeneous log data such as noise-sensitive knowledge sources [63], retrieval errors and hallucination failure modes [64], and instability arising from multi-source or semi-structured logs [65], but they do not analyze how retrieval affects model performance in the context of system log severity classification using SLMs and SRLMs. Although prior work reports inference latency and throughput for LLM-based log analysis, including per-log inference times for classification models [53], parsing time comparisons between small and large LLMs [66], and efficiency evaluations within broader benchmark suites [62], these studies focus on anomaly detection, log parsing, summarization, or specialized domains such as telecom logs, and none evaluate inference latency or real-time performance for severity classification on Linux system logs, nor do they measure latency specifically for SLMs or SRLMs. Moreover, none of these efficiency-oriented studies incorporate RAG or analyze the additional inference latency overhead introduced by retrieval when combined with reasoning models, independent of predictive accuracy."
        },
        {
            "title": "2.5 Research Objectives",
            "content": "Despite rapid progress in applying LMs to log analysis, existing research remains fragmented across log types, tasks, and modeling paradigms. Prior work has emphasized Java logging statements, security-oriented logs, telecom logs, or heavily preprocessed anomaly-detection datasets, leaving real-world Linux system logs (e.g., journalctl) comparatively understudied. Likewise, promptingstrategy research has largely centered on anomaly detection, summarization, or intrusion detection, and has not evaluated retrieval-induced degradation or the behavior of small or reasoning models on operational logs. Efficiency-oriented studies measure inference latency for parsing or anomaly detection, but no prior work assesses deployable SLM/SRLM performance or end-to-end latency for severity classification on journalctl data. To address these gaps, this work makes the following contributions: 1. We introduce the first benchmark evaluating SLMs and SRLMs on real-world Linux system logs (journalctl) for severity classification, in contrast to prior work focusing on code logging statements, anomaly datasets (e.g., HDFS, BGL), or security-specific logs. 2. We compare zero-shot, few-shot, and retrieval-augmented prompting specifically for system log severity classification on journalctl data, and document retrieval-induced degradation effects for several SRLMs. 3. We analyze both accuracy and inference latency for SLMs and SRLMs, providing deployabilityoriented evaluation for real-time DT and monitoring pipelines. By systematically evaluating SLMs and SRLMs for severity classification on temporal-based operational Linux system logs under zero-shot, few-shot, and RAG approaches, this study establishes foundation for future work on lightweight, real-time, and retrieval-aware log analysis, all important aspects that support the development of intelligent, automated infrastructure monitoring systems such as DTs."
        },
        {
            "title": "3 Data",
            "content": "To develop reliable benchmark for log severity classification, we collected over 7.3 million system log entries from six servers across the computing infrastructurefour internal nodes and two external public-facing machines. The logs were extracted from each systems journal and converted into structured JSON format, with each entry tagged by its originating IP address to maintain source traceability. To ensure consistent interpretation by LMs, every record was standardized into keyvalue dictionary representation. Table 1 illustrates an example of single log entry and its corresponding JSON structure. This structured design aligns with recent findings showing that explicit text formatting improves LLM comprehension and reliability [67, 68]. 6 Table 1: Example JSON-style representation of system log entry. Attribute id hostname ip comm cmdline exe message selinux context systemd unit systemd slice realtime datetime priority Example 57010 ray-worker4 10.192.20.11 cat /bin/cat /usr/bin/cat -rw-r--r-- 2 root root 0 Oct 26 2021 usr/lib/kbd/keymaps/legacy/mac/all/mac-de CH.map.gz unconfined u:unconfined r:rpm script t:s0-s0:c0.c1023 session-1.scope user-0.slice 2025-02-14 11:38:10.852717 7. The dataset spans from June 2024 to July 2025, capturing broad range of operational conditions, from low-level kernel and hardware diagnostics to service activity and security notifications. Each entry retains critical metadata, including timestamp, process ID, command, message content, and priority level, which are essential features for accurate severity classification. For manageable experimentation, we sampled 50,000 log entries at random from the full corpus of 7.3 million system logs, maintaining statistical representativeness while ensuring computational feasibility. The original corpus exhibited pronounced class imbalance: informational messages (priority 6) dominated, while high-severity categories such as alert (1), critical (2), and error (3) occurred infrequently. To preserve the fidelity of rare but operationally significant events, all logs from priority levels 14 (alertwarning) were fully retained, yielding 16,635 entries. The remaining 33,365 samples were evenly drawn from lower-severity levels 57 (notice, informational, debug) to reduce bias toward frequent categories. After deduplication, the dataset contained 46,774 unique logs, reflecting the removal of 3,226 duplicates. Following preprocessing, the dataset was divided into training and evaluation subsets using an 80/20 split with fixed random seed to ensure reproducibility. The training subset contained 37,419 logs while the evaluation subset contained 9,355 logs. Stratified sampling preserved proportional representation of all severity levels across both subsets. To prevent data leakage, the target label corresponding to log priority was removed from the evaluation set prior to inference, producing label-free version used for model testing. Table 2 summarizes the final distribution of priority levels according to the standardized syslog scale, where level 0 denotes emergency (system unusable), levels 13 correspond to alert, critical, and error conditions, levels 45 indicate warning and notice messages, level 6 represents informational events, and level 7 corresponds to debug output. No emergency-level entries were observed in the collected logsa reflection of the infrastructures stable operational state but also limitation for evaluating model sensitivity to extreme conditions. 7 Table 2: Final distribution of 46,774 log entries across standardized syslog severity levels. Each level (07) represents increasing system stability from emergency to debug, illustrating semi-balanced dataset that preserves coverage across both rare high-severity and common low-severity events observable in production systems. Severity Level Description Count Percentage 0% 0 4.6% 1 10.8% 2 14.1% 3 19.3% 4 17.5% 5 20.6% 6 12.1% 7 Emergency Alert Critical Error Warning Notice Info Debug 0 2,315 5,412 7,025 9,678 8,744 10,286 6,314 This semi-balanced, empirically representative benchmark provides realistic foundation for evaluating SLMs and SRLMs under operational conditions, positioning log severity classification as practical means to gauge model comprehension and its relevance to downstream tasks such as DT system integration."
        },
        {
            "title": "4 Methodologies",
            "content": "Figure 1: Workflow for evaluating log-severity classification using SLMs and SRLMs. System logs are collected from real-world servers, processed through prompting strategies (zero-shot, few-shot, and RAG with FAISS), evaluated across various open-source models, and assessed by accuracy and inference speed. Figure 1 outlines the workflow for evaluating the performance of using different prompting methods and open-source small language models (SLMs) and small reasoning language models (SRLMs) to classify system log severity. After collecting over 7.3 million log entries from six servers within the computing infrastructure, each log was standardized into structured JSON format and sampled to produce semi-balanced benchmark for evaluation. Each entry was processed using three prompting 8 methods: zero-shot prompting [69, 70], few-shot prompting [71], and retrieval-augmented generation (RAG) [72]. Zero-shot and few-shot prompts were applied to infer the correct severity level from the underlying log content. For RAG implementation, Facebook AI Similarity Search (FAISS), an open-source library developed by Meta for efficient similarity search and clustering of dense vectors, was utilized to construct vector database from the training set [73]. During evaluation, each test log queried this database using the same prompt to retrieve contextually similar entries for severity inference. Each method was tested across multiple open-source models with consistent hyperparameter settings to ensure comparability. Final evaluation considered overall accuracy and average inference time per log entry to assess both model comprehension and runtime efficiency. More details are provided in the sub-sections."
        },
        {
            "title": "4.1 Method Configuration",
            "content": "4.1.1 Zero-shot The zero-shot configuration evaluated each models ability to classify logs without any examples or prior context exposure. The prompt framed the model as Linux System Log Specialist with expertise in system administration, log analysis, and troubleshooting critical system-level issues through comprehensive log examination as well as familiarity with journalctl syntax and Syslog standards. Following Kong et al. [74], this role-based framing was used to enhance zero-shot reasoning by providing the model with an explicit professional context that encourages domain-consistent interpretation and decision-making. To enforce output consistency, strict rule was applied: models were to produce only single digit from 0 to 7 with no explanation, punctuation, or whitespace. This design choice standardized responses for efficient evaluation and eliminated ambiguity from model verbosity."
        },
        {
            "title": "4.1.2 Few-shot",
            "content": "The few-shot configuration expanded upon the baseline setup by including example logs with their corresponding Syslog severity level directly in the prompt to guide the models reasoning process. The prompt retained the same professional framing as in the zero-shot configuration, positioning the model as Linux System Log Specialist with expertise in system administration, log analysis, and familiarity with journalctl syntax and Syslog standards. However, rather than relying solely on domain instructions, the model was provided five example log entries paired with their severity levels. The five examples were sampled directly from the training subset to prevent data leakage and ensure that the evaluation set remained unseen. These examples were intentionally chosen to capture range of operational conditions from routine informational messages to critical disk errors, allowing the models to observe the underlying linguistic and structural cues that distinguish highand low-severity logs. Following Dong et al. [75], the inclusion of in-context exemplars was designed to activate the models internal task priors, improving alignment between log semantics and severity classification through analogical reasoning. As mentioned prior, models were instructed to produce only single integer from 0 to 7, without any accompanying explanation or punctuation. This consistency maintained direct comparability with the zero-shot configuration while isolating the performance gains derived from contextual exemplars. 9 4.1.3 RAG The retrieval-augmented configuration extended the zero-shot prompt by pairing it with vectorbased memory of the training subset, which contained 37,419 logs containing their Syslog severity level. This design aimed to enhance interpretability and classification precision through dynamic grounding in prior data rather than the static exemplars used in the few-shot configuration. To construct the retrieval corpus, FAISS index was built over the training set Dtrain = {(xi, yi)}N where xi denotes structured log entry and yi {0, 1, . . . , 7} denotes its Syslog severity i=1 label. Each indexed document was generated by converting row from the training subset into key-value text representation, where each log field (e.g., hostname, message, pid) was arranged into Python dictionary-like string concatenated with its corresponding Syslog severity level, producing semantic embedding ei = fθ(xi) R768, where fθ denotes the Nomic Embed text encoder (nomic-embed-text-v1.5), which produces 768-dimensional embeddings and is held fixed across all experiments to ensure comparability [76]. At inference time, each unseen xq was embedded into the same vector space and queries against the index using an L2 similarity metric. The retriever then selected the top-k neighbors: Nk(xq) = arg min xiDtraineq ei2 For all experiments, k=5 was used as the default retrieval depth. The retrieved examples were automatically formatted as in-context snippets appended below the zero-shot instruction prompt. This configuration thus combined the interpretability of structured retrieval with the generalized capacity of zero-shot prompting. By conditioning on Nk(xq), the model effectively approximated similarity-weighted local decision function: ˆyq = gϕ(xq, Nk(xq)) where gϕ denotes the LMs classification mapping under RAG conditioning. This approach enabled more informed classification by using prior knowledge from semantically aligned logs. Figure 2: Retrieval-Augmented Generation (RAG) Pipeline for Syslog severity classification where incoming logs are embedded using local LM Studio encoder (768-dimensional embeddings) and indexed with FAISS. At inference, each query log is embedded, and the top-k nearest training vectors (k=5) are retrieved using L2 similarity and appended to zero-shot prompt. The LLM then predicts the Syslog severity label conditioned on the retrieved examples."
        },
        {
            "title": "4.1.4 Hardware and Environment",
            "content": "All experiments were executed on high-performance local workstation configured for large-scale inference. The system was equipped with an Intel Xeon W3-2423 processor, 128 GB RAM, and 10 dual NVIDIA RTX A6000 GPUs (each providing 48 GB of VRAM). This setup offered sufficient inference speed, acceleration, and capacity for dense vector retrieval. Model evaluation was hosted through LM Studio, which provided an offline OpenAI-compatible API endpoint for serving the S(R)LMs used in this study [77]. This hardware-software arrangement ensured reproducibility across experiments involving different prompting configurations."
        },
        {
            "title": "4.2 Models",
            "content": "SLMs are compact neural models designed for efficient inference, lower computational demand, and reduced energy use, making them suitable for constrained deployment environments [78]. Recent benchmarking shows that SLMs can achieve strong task performance while providing measurable gains in runtime efficiency and power consumption across range of settings, including multi-domain evaluation suites and diverse hardware platforms [79]. NVIDIA study defines SLMs functionally as models that can be served on common personal devices with latency sufficiently low for practical use, noting that models below roughly ten billion parameters are currently capable of this in practice [80]. Following this definition, this study focuses on the 0.6B4B parameter range to ensure deterministic execution, stable latency, and full local control over inference conditions, aligning with current research emphasis on reproducibility and resource-bounded evaluation [80]. This scale also enables integration within DT environments, remaining practical for real-time pipelines that demand fast, continuous, and locally-reliable inference. In parallel, SRLMs extend the SLM paradigm by inheriting reasoning through distillation from larger models, enabling multi-step reasoning while maintaining smaller computational footprints [81]. These models leverage CoT supervision, reward-guided refinement, and test-time scaling strategies to improve reasoning without increasing parameter count, reflecting broader trend toward efficiency-oriented cognitive modeling [81]. Architectural developments such as groupedquery attention (GQA), linear-time sequence models like Mamba, and lightweight normalization layers further enhance SLM efficiency by reducing memory requirements and inference latency while preserving expressivity [81]. By evaluating both SLMs and SRLMs, we assess whether distilled reasoning signals provide additive performance benefits in resource-constrained classification settings and whether compact architectures can deliver consistent, domain-relevant accuracy under tight latency and compute budgets. To evaluate the generalization and reasoning capacity of LMs under different prompting strategies, diverse set of small-scale models spanning two distinct categories was selected: SLMs and SRLMs. The SLM group comprises variants of the Llama3.2 and Gemma3 families, optimized primarily for efficient natural-language understanding and instruction following with minimal context. In contrast, the SRLM group includes variants of the Qwen3 family and other models like DeepSeek-R1-DistillQwen-1.5B and Phi-4-Mini-Reasoning, each incorporating CoT aimed at improving step-by-step inference and logical consistency. The models evaluated in this study are summarized in Table 3, grouped by their classification as either SLMs or SRLMs. Table 3: Models evaluated in this study, categorized as either small language models (SLMs) or small reasoning language models (SRLMs). Model Llama3.2-3B Llama3.2-1B Gemma3-4B Gemma3-1B Qwen3-4B Qwen3-1.7B Qwen3-0.6B DeepSeek-R1-Distill-Qwen-1.5B Phi-4-Mini-Reasoning (3.8B) Category SLM SLM SLM SLM SRLM SRLM SRLM SRLM SRLM Beyond their architectural goals, these models also differ in attention-head configuration and context capacity, critical factors for latency, retrieval performance, and real-time operation. Table 4: Technical specifications of the evaluated models, including the number of query (Q) and keyvalue (KV) attention heads and maximum context length supported. Model Llama3.2-3B Llama3.2-1B Gemma3-4B Gemma3-1B Qwen3-4B Qwen3-1.7B Qwen3-0.6B DeepSeek-R1-Distill-Qwen-1.5B Phi-4-Mini-Reasoning (3.8B)"
        },
        {
            "title": "Q Heads KV Heads Max Context Length",
            "content": "24 32 8 4 32 16 16 12 24 8 8 4 1 8 8 8 2 8 131,072 131,072 131,072 32,768 32,768 32,768 32,768 131,072 131,072 Together, these models offer balanced scope suitable for efficiency and potential real-time DT integration."
        },
        {
            "title": "4.3 Evaluation",
            "content": "To assess and evaluate the ability of SLMs and SRLMs on interpreting system logs, we evaluate each model across the three prompting configurations mentioned in Section 4.1: zero-shot, few-shot, and RAG. Evaluation is conducted on the test subset of the data, comprising unique log entries that were not shown during instruction or retrieval phases to prevent information leakage. For each configuration, models receive raw log text and are required to output single Syslog severity level, enabling direct comparison of predictive accuracy across architectures and scales. Accuracy served as the primary evaluation metric, capturing the proportion of predictions that matched the reference Syslog severity labels assigned in the collected system logs. To quantify classification performance, we compute accuracy as the fraction of correctly predicted severity levels over all log entries in the test set. Formally, 12 Accuracy = I(ˆyi = yi), N i=1 where denotes the total number of log messages, yi is the ground-truth Syslog severity level for the i-th entry, ˆyi is the models predicted label, and I() is the indicator function that returns 1 when the classification matches the reference label and 0 otherwise. In addition, per-log inference latency was measured and averaged across the test subset to capture realistic performance implications for continuous monitoring environments and DT pipelines. Together, these evaluation procedures quantify model performance across accuracy, latency, and retrieval-driven reasoning efficiency, providing insight into both linguistic competence and operational viability in real-time log analysis systems."
        },
        {
            "title": "5.1 Zero-shot",
            "content": "Table 5 summarizes zero-shot log severity classification results for all evaluated models, reporting both accuracy and average inference time per log entry. Notably, the Qwen3 family of models achieved the highest accuracy, with Qwen3-1.7B leading at 33.61%, outperforming all other models and size variants in this setup. In contrast, smaller variants of Llama3 and Gemma demonstrated substantially lower accuracy (below 10%), highlighting the challenge of zero-shot severity inference for smaller SLMs. Per-log inference times varied widely, with lightweight models such as Llama3.2-1B achieving 0.08 seconds per log, while reasoning models such as DeepSeek-R1-Distill-Qwen-1.5B and Qwen3-0.6B took several seconds per log. One observation from the zero-shot runs is that the Phi-4-Mini-Reasoning model, while achieving 9.20% accuracy, frequently appended unnecessary explanations to its classifications (e.g., outputting reasoning or justifications after the answer), which decreased its overall accuracy as the zero-shot prompt explicitly mentioned to produce single digit output corresponding to the Syslog severity level. Overall, these results establish baseline performance and reveal practical trade-offs between speed and accuracy in the zero-shot setup. Table 5: Zero-shot performance of evaluated models. Model Llama3.2-3B Llama3.2-1B Gemma3-4B Gemma3-1B Qwen3-4B Qwen3-1.7B Qwen3-0.6B DeepSeek-R1-Distill-Qwen-1.5B Phi-4-Mini-Reasoning (3.8B) Accuracy Average (seconds/log) 0.13 0.08 0.18 0.12 3.53 1.71 4.19 4.07 13.18 8.11% 1.04% 4.79% 0.14% 27.12% 33.61% 27.45% 11.54% 9.20%"
        },
        {
            "title": "5.2 Few-shot",
            "content": "Table 6 presents few-shot prompt results for all models, showing considerable improvements in accuracy over the zero-shot baseline for most architectures. The Qwen3-4B model achieved the best performance, reaching an accuracy of 56.01%, substantially higher than its zero-shot result and indicating strong benefit from exposure to labeled examples. Gemma3-4B and Qwen3-1.7B also showed marked gains, achieving 41.06% and 43.30% accuracy respectively. In contrast, some smaller models, such as Llama3.2-1B and Phi-4-Mini-Reasoning, failed to improve and in fact produced 0% accuracy under few-shot prompts, while also suffering significant increases in inference time per logup to 39.33 and 23.43 seconds, respectively. This was due to these models not following directions and producing lengthy outputs with verbose reasoning, resulting in unclear answers. Compared to the zero-shot setting, these results demonstrate not only higher accuracy for larger and mid-scale models but also increased inference latency, especially for models less optimized for prompt-following or with limited capacity. This highlights that few-shot prompting can produce stronger classification ability, but model choice and operational constraints remain key considerations. Table 6: Few-shot performance of evaluated models. Model Llama3.2-3B Llama3.2-1B Gemma3-4B Gemma3-1B Qwen3-4B Qwen3-1.7B Qwen3-0.6B DeepSeek-R1-Distill-Qwen-1.5B Phi-4-Mini-Reasoning (3.8B) Accuracy Average (seconds/log) 33.21% 0.00% 41.06% 20.25% 56.01% 43.30% 28.92% 17.63% 0.00% 0.19 39.33 0.26 0.22 8.35 3.03 18.74 5.53 23."
        },
        {
            "title": "5.3 RAG",
            "content": "Table 7 details the model performance using RAG, revealing dramatic improvements in accuracy for most architectures compared to zeroand few-shot prompting. In particular, Gemma3-1B and Gemma3-4B achieved accuracy rates of 85.28% and 81.84%, respectively, while Qwen3-4B reached near-perfect 95.64%, sharply outperforming its previous results. Smaller models benefited substantially from RAG as well, such as Llama3.2-1B, which improved to 37.37% accuracy, and Qwen3-0.6B rose to 88.12%. However, inference latency generally increased, especially for larger and reasoning models: Qwen3-4B required 7.14 seconds per log, and Phi-4-Mini-Reasoning again struggled with both accuracy (0%) and extremely high latency (over 3 minutes per log). Interestingly, the RAG results reveal that not all models benefited from retrieval augmentation. In fact, Qwen3-1.7B, DeepSeek-R1-Distill-Qwen-1.5B, and Phi-4-Mini-Reasoning (3.8B) saw their performance decline sharply. Qwen3-1.7B dropped from 43.30% (few-shot) down to 28.96% (RAG), while DeepSeek-R1-Distill-Qwen-1.5B fell from 17.63% to just 3.17%, performing even worse than its zero-shot accuracy. Most strikingly, Phi-4-Mini-Reasoning failed to produce any correct classification with RAG (0% accuracy), despite long inference times. These findings highlight that RAG can introduce additional challenges, especially for models that struggle to meaningfully incorporate 14 retrieved context or are sensitive to more complex prompts. Such declines in accuracy highlight the importance of model-specific tuning and careful evaluation. These findings illustrate that while RAG can provide critical context and substantially improve classification performance for many models, its benefits are not universal. Careful evaluation of both specific model architectures and size variants is essential to determine the most suitable approach for given domain-specific task. Table 7: Retrieval-Augmented Generation (RAG) performance of evaluated models. Model Llama3.2-3B Llama3.2-1B Gemma3-4B Gemma3-1B Qwen3-4B Qwen3-1.7B Qwen3-0.6B DeepSeek-R1-Distill-Qwen-1.5B Phi-4-Mini-Reasoning (3.8B) Accuracy Average (seconds/log) 53.31% 37.37% 81.84% 85.28% 95.64% 28.96% 88.12% 3.17% 0.00% 0.90 0.63 1.16 0.70 7.14 0.89 2.75 4.88 228."
        },
        {
            "title": "6.1 Impact of Top-k Retrieval on Model Stability",
            "content": "Although Qwen3-4B demonstrated strong performance gains from retrieval, the 1.7B variant exhibited the opposite behavior. To investigate whether this degradation stemmed from excessive retrieval context, an experiment was conducted in which the top-k neighbors returned by FAISS were reduced from k=5 to k=3 to k=1. Figure 3 summarizes the effect of reducing retrieval depth on accuracy and latency. 15 Figure 3: Performance of Qwen3-1.7B across retrieval depths. Reducing from 5 to 1 decreases latency but does not improve accuracy, indicating limited retrieval integration at this model scale. Results reveal that performance did not recover with smaller context windows when reducing the neighbors. Instead, accuracy declined steadily from 28.96% at k=5 to 26.47% at k=1, despite inference speed decreasing proportionally. This behavior suggests that the models challenge with retrieval is not driven by excessive context volume, but instead reflects limitation in effectively incorporating retrieved information into its decision process. While retrieval substantially benefits certain compact models in our evaluation framework, these results indicate that gains do not scale uniformly across model sizes. Instead, successful retrieval integration appears to depend on models capacity to absorb and utilize external evidence alongside internal representations. This effect is observed here within domain-specific system log classification setting, and highlights retrieval-conditioning behavior as an important consideration when working with models near the lower-capacity regime."
        },
        {
            "title": "6.2 Overall Observations",
            "content": "Across all models and prompting strategies, we observe clear stratification in both accuracy and efficiency. RAG yields the greatest improvements, though the extent of these gains varies considerably by model family and scale. Figure 4 reports the model accuracy across the three different prompting configurations, while Figure 5 summarizes the per-log inference speed. 16 Figure 4: Performance of evaluated models under zero-shot, few-shot, and RAG prompting. Retrieval yields the strongest overall gains, with notable variation across architectures. Figure 5: Average per-sample inference time. Several models approach real-time latency, though performance varies significantly by scale and prompting mode. According to the results, Qwen3-4B is the top performer, reaching 95.64% accuracy with RAG compared to 56.01% in few-shot and 27.12% in zero-shot. The Gemma family also shows substantial gains, with Gemma3-1B improving from 20.25% (few-shot) to 85.28% (RAG) and Gemma3-4B from 41.06% to 81.84%. Llama3.2 models benefit more modestly: Llama3.2-3B increases from 8.11% (zero-shot) to 53.31% (RAG), while Llama3.2-1B remains limited, peaking at 37.37% under RAG and collapsing to 0.00% in few-shot. Interestingly, Qwen3-0.6B emerges as an outlier, performing weakly in zero-shot (27.45%) and few-shot (28.92%) but jumping to 88.12% with RAG, indicating that retrieval can elevate tiny models. In contrast, Qwen3-1.7B performs worse with RAG (28.96%) than few-shot (43.30%), and DeepSeek-R1-Distill-Qwen-1.5B degrades sharply from 17.63% (few-shot) to 3.17% (RAG). Phi-4-Mini-Reasoning fails across all settings, reaching peak of 9.20% in zero-shot and reaching 0.00% in both few-shot and RAG. These anomalies suggest the possibility of structural incompatibilities between retrieval integration and some smaller or distilled architectures. Processing time reveals different dynamics. Most models complete zero-shot and RAG inference in under second per log, with Gemma variants particularly consistent below 1.2 seconds. Llama models are also efficient, though Llama3.2-1B produces an extreme outlier at 39.33 seconds in few-shot, caused by difficulty adhering to prompt instructions when example inputs and outputs were provided, which led to unnecessarily long generations. Qwen models incur greater latency: Qwen3-4B ranges from 3.53 to 8.35 seconds, Qwen3-1.7B from 0.89 to 3.03 seconds, and Qwen3-0.6B from 2.75 to 18.74 seconds. DeepSeek-R1-Distill-Qwen-1.5B falls in the middle range at 45.5 seconds. Phi-4-Mini-Reasoning is highly inefficient, requiring more than 228 seconds per log under RAG due to excessive <think> token usage and verbose outputs, making it impractical despite its already poor accuracy. Although several of the evaluated models achieved nearreal-time performance, with 11 out of the 27 total evaluations completing inference in under one second, newer-generation GPUs with greater throughput and memory bandwidth would further reduce latency and bring the system closer to true real-time operation. These results are consistent with prior findings indicating that GPU acceleration plays critical role, where rapid inference directly supports continuous synchronization with live system data. As prior studies show, inference time decreases significantly with higher GPU throughput and memory bandwidth [82, 83]."
        },
        {
            "title": "6.3 Architectural Factors Behind Performance Differences",
            "content": "The strong performance of the Qwen3 family, especially Qwen3-4B and the tiny Qwen3-0.6B, appears consistent with aspects of their underlying architecture and post-training pipeline. Qwen3 models are dense decoder-only Transformers with GQA and QK-Norm, trained on very large, STEM and code-heavy corpus and then refined via four-stage post-training process that jointly optimizes thinking (CoT) and non-thinking modes [84]. In our setting, Qwen3-4B combines relatively large number of query heads (32 / 8 KV) with 32K context and strong reasoning/post-training, giving it both the capacity to project the mixed structure of logs (paths, numeric fields, timestamps, errors) into many attention subspaces and the stability to keep retrieved neighbors salient over long prompts. Qwen3-0.6B shares the same 16 / 8 KV configuration as Qwen3-1.7B but is more heavily shaped by strong-to-weak distillation from larger teachers, which is explicitly designed to transfer both reasoning skills and mode-switching into lightweight models [84]. This combination of fine-grained attention, long-context training, and distillation from stronger thinking/non-thinking flagship models offers plausible explanation for why Qwen3-4B reaches 95.64% accuracy with RAG and why the 0.6B variant jumps to 88.12% despite weak zero-shot and few-shot scores. By contrast, the Gemma3 models seem to benefit from different architectural bias. Gemma3-4B and Gemma3-1B also use modern Transformer stack with GQA and QK-Norm, but their attention is organized into interleaved local and global blocks tailored for long-context throughput (e.g., 5 local layers followed by 1 global layer) [85]. In our RAG pipeline, each query log is followed by small neighborhood of retrieved logs; Gemmas local blocks can focus on within-log structure (e.g., message, unit, path), while its global blocks integrate across the query-plus-neighbors window. This architecture may be well aligned with clustered context layouts where relevant evidence is packed into short spans, which helps explain why Gemma3-1B and Gemma3-4B exhibit large gains under RAG (85.28% and 81.84%) despite relatively poor zero-shot baselines. Their lower Q-head counts (8/4 and 4/1) compared to Qwen3 limit expressivity somewhat, but the localglobal pattern still lets them exploit retrieved examples effectively once those examples are explicitly surfaced by FAISS. 18 The Llama3.2 models, in turn, exemplify more general-purpose small-model design. Public reports describe Llama 3style models as decoder-only Transformers with GQA, long-context RoPE, and RMSNorm, trained on large but more general mixture of web, code, and text than Qwen3s STEMand reasoning-heavy mix [86, 87]. In our benchmarks, Llama3.2-3B and Llama3.2-1B have relatively high numbers of query heads (24 and 32, respectively) and 128K context, which supports efficient scanning of long inputs but without the same depth of reasoning-oriented posttraining or strong-to-weak distillation. This pattern is consistent with their observed behavior: they benefit modestly from RAG (e.g., Llama3.2-3B rises to 53.31% accuracy) but never reach the Qwen3/Gemma3 tier. Their architecture appears more suited to broad instruction following than to aggressively leveraging structured retrieved evidence in narrow technical domain like syslog classification. Finally, the degradation observed for several SRLMs under RAG, such as Qwen3-1.7B, DeepSeekR1-Distill-Qwen-1.5B, and Phi-4-Mini-Reasoning may be interpreted through differences in architectural and post-training choices. Qwen3-1.7B shares the same 16 / 8 KV head configuration as Qwen3-0.6B, but receives heavier reasoning reinforcement learning (RL) and long-CoT training, which may bias it toward relying on its internally generated reasoning traces rather than on short, label-bearing retrieved snippets [84]. Similarly, DeepSeek-R1-Distill-Qwen-1.5B and Phi4-Mini-Reasoning are distilled from larger reasoning models and explicitly optimized to produce long chain-of-thought outputs [88, 89]. Because our setup restricts the models to single-digit output and supplies dense retrieval context, one plausible explanation is that CoT-centric models may over-weight internal reasoning, under-use retrieved examples, and sometimes emit verbose or malformed outputs, leading to degradation. This behavior is consistent with what we observe: high latency, frequent violation of the output format, and in some cases, sharp drops in accuracy when RAG is employed. Together, these patterns suggest that architectures and post-training pipelines geared toward controlled, retrieval-aware non-thinking modes may be better aligned with RAG approach than the other configurations evaluated here."
        },
        {
            "title": "7 Conclusion and Future Work",
            "content": "This research treats severity classification as controlled setting for probing retrieval behavior. The broader goal is to support diagnostic reasoning tasks such as RCA within DT environments, where compact models must integrate external evidence in real time. Our results show that SRLMs hold an advantage over SLMs in zero-shot and few-shot settings, while retrieval consistently strengthens SLM performance. However, retrieval benefits are not uniform: several SRLMs exhibit performance degradation under RAG, indicating that retrieval effectiveness depends not only on model size but also on architecture, training objectives, and the interaction between external context and internal reasoning dynamics. To clarify the scope of these findings, this study does not claim that system log severity classification, as defined by Syslog labels, constitutes comprehensive measure of log understanding or diagnostic competence. Severity levels are inherently noisy, administrator-defined, and weakly standardized across systems, which limits their suitability as ground-truth representations of underlying system state. Instead, severity classification is intentionally employed here as constrained probing task that isolates models ability to ground unstructured operational log content to semantically meaningful categories under strict output constraints. Accordingly, the reported accuracy and latency results should be interpreted as indicators of retrieval integration behavior and 19 context utilization efficiency, rather than as direct proxies for correctness in downstream operational tasks such as RCA or anomaly diagnosis. Within this landscape, Qwen3 provides notable contrast to Llama3.2 and Gemma3. Qwen3 models are distilled from larger teacher models with an explicit thinking mode and trained on broad, multi-domain corpora, whereas Llama3.2 and Gemma3 prioritize instruction tuning and efficiency. Qwen3-4B, in particular, strikes balance between capacity and stability: it has sufficient representational depth to parse noisy system logs and exploit retrieved top-k neighbors without the instability observed in smaller variants. This is reflected in its substantial RAG improvement (56.01% 95.64%), while Qwen3-1.7B degrades and Qwen3-0.6B relies heavily on near-label exemplars. These observations do not imply that SRLMs bias internal reasoning tokens, but they suggest that reasoning-oriented design and long-context training may shape how models integrate external evidence. Interpreting these behaviors requires caution. Prior work on long-context limitations [90], unfaithful or inconsistent chain-of-thought processes [91, 92], and retrieval-aware training frameworks such as RA-DIT [93], Self-RAG [94], and IRCoT [95] offer plausible explanations and mechanisms for the mixed SRLM outcomes observed here. Our results should therefore be read as evidence of potential tension between generative reasoning and retrieval, not definitive claim about SRLM behavior. Future work will investigate whether these effects stem primarily from capacity constraints, training objectives, or deeper architectural dynamics. We further plan to extend this benchmark beyond system logs to other domain-specific tasks to test whether these retrieval patterns generalize across domains. Finally, integrating this framework into live DT system will enable evaluation under streaming telemetry, shifting baselines, and evolving system state, where dynamic memory policies, time-aware retrieval, and continual context updates are essential for real-time diagnostic reasoning. Author Contributions. Conceptualization, C.Y. and Y.M.; methodology, Y.M., E.M., Z.W.; software, Y.M.; validation, Y.M. and Z.W.; resources, C.Y. and Z.W.; data curation, J.R., E.M., Y.M.; writingoriginal draft preparation, Y.M. and E.M.; writingreview and editing, Y.M., E.M., Z.W., C.Y.; supervision, C.Y.; project administration, C.Y.; funding acquisition, C.Y. All authors have read and agreed to the published version of the manuscript. Funding. This research was funded by NSF I/UCRC program (1841520); NASA Goddard CISTO; and the ASSIP program, supported by George Mason Universitys College of Science. Data Availability Statement. The original data and source code presented in this study are openly available at https://github.com/stccenter/Benchmarking-SLMs-and-SRLMs-on-System-LogSeverity-Classification Acknowledgments. We are grateful to Anusha Srirenganathan Malarvizhi and Yaya Lan for helpful discussions and advice. Conflicts of Interest. The authors declare no conflict of interest."
        },
        {
            "title": "References",
            "content": "[1] Sina Gholamian and Paul AS Ward. comprehensive survey of logging in software: From logging statements automation to log mining and analysis. arXiv preprint arXiv:2110.12489, 2021. [2] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. Deeplog: Anomaly detection and diagnosis from system logs through deep learning. In Proceedings of the 2017 ACM SIGSAC conference on computer and communications security, pages 12851298, 2017. [3] Sekar, Hanke Kimm, and Rohit Aich. eaudit: fast, scalable and deployable audit data collection system. In 2024 IEEE Symposium on Security and Privacy (SP), pages 35713589. IEEE, 2024. [4] Ramona-Georgiana Albert. System logs anomaly detection. are we on the right path? Applied Artificial Intelligence, 39(1):2440692, 2025. [5] Laura Viola, Elisabetta Ronchieri, and Claudia Cavallaro. Combining log files and monitoring data to detect anomaly patterns in data center. Computers, 11(8):117, 2022. [6] Marietheres Dietz, Manfred Vielberth, and Gunther Pernul. Integrating digital twin security simulations in the security operations center. In Proceedings of the 15th International Conference on Availability, Reliability and Security, pages 19, 2020. [7] Shenglin Zhang, Weibin Meng, Jiahao Bu, Sen Yang, Ying Liu, Dan Pei, Jun Xu, Yu Chen, Hui Dong, Xianping Qu, et al. Syslog processing for switch failure diagnosis and prediction in datacenter networks. In 2017 IEEE/ACM 25th International Symposium on Quality of Service (IWQoS), pages 110. IEEE, 2017. [8] Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael Jordan. Detecting large-scale system problems by mining console logs. In Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, pages 117132, 2009. [9] Weihang Jiang, Chongfeng Hu, Shankar Pasupathy, Arkady Kanevsky, Zhenmin Li, and Yuanyuan Zhou. Understanding customer problem troubleshooting from storage system logs. In FAST, volume 9, pages 4356, 2009. [10] Max Landauer, Sebastian Onder, Florian Skopik, and Markus Wurzenberger. Deep learning for anomaly detection in log data: survey. Machine Learning with Applications, 12:100470, 2023. [11] Pranjal Gupta, Harshit Kumar, Debanjana Kar, Karan Bhukar, Pooja Aggarwal, and Prateeti Mohapatra. Learning representations on logs for aiops. In 2023 IEEE 16th International Conference on Cloud Computing (CLOUD), pages 155166. IEEE, 2023. [12] Ruchi Mahindru, Harshit Kumar, and Sahil Bansal. Log anomaly to resolution: Ai based proactive incident remediation. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pages 13531357. IEEE, 2021. [13] Chetan Bansal, Sundararajan Renganathan, Ashima Asudani, Olivier Midy, and Mathru Janakiraman. Decaf: Diagnosing and triaging performance issues in large-scale cloud services. 21 In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice, pages 201210, 2020. [14] Yongqian Sun, Shiyu Ma, Tong Xiao, Yongxin Zhao, Xuhui Cai, Wei Dong, Yue Shen, Yao Zhao, Shenglin Zhang, Jing Han, et al. Accurate and interpretable log-based fault diagnosis using large language models. IEEE Transactions on Services Computing, 2025. [15] Zifu Wang, Yahya Masri, Anusha Srirenganathan Malarvizhi, Tayven Stover, Samir Ahmed, David Wong, Yongyao Jiang, Yun Li, Mathieu Bere, Daniel Rothbart, et al. Optimizing context-based location extraction by tuning open-source llms with rag. International Journal of Digital Earth, 18(1):2521786, 2025. [16] Yahya Masri, Zifu Wang, Anusha Srirenganathan Malarvizhi, Samir Ahmed, Tayven Stover, David WS Wong, Yongyao Jiang, Yun Li, Qian Liu, Mathieu Bere, et al. Comparative analysis of bert and gpt for classifying crisis news with sudan conflict as an example. Algorithms, 18(7): 420, 2025. [17] Spurthi Setty, Harsh Thakkar, Alyssa Lee, Eden Chung, and Natan Vidra. Improving retrieval for rag based question answering models on financial documents. arXiv preprint arXiv:2404.07221, 2024. [18] Lin Yang, Junjie Chen, Zan Wang, Weijing Wang, Jiajun Jiang, Xuyuan Dong, and Wenbin Zhang. Semi-supervised log-based anomaly detection via probabilistic label estimation. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pages 14481460. IEEE, 2021. [19] Song Chen and Hai Liao. Bert-log: Anomaly detection for system logs based on pre-trained language model. Applied Artificial Intelligence, 36(1):2145642, 2022. [20] Max Landauer, Florian Skopik, Markus Wurzenberger, and Andreas Rauber. System log clustering approaches for cyber security applications: survey. Computers & Security, 92: 101739, 2020. [21] Rainer Gerhards. Rfc 5424: The syslog protocol, 2009. [22] Chris Lonvick. Rfc3164: The bsd syslog protocol, 2001. [23] Diana El-Masri, Fabio Petrillo, Yann-Gael Gueheneuc, Abdelwahab Hamou-Lhadj, and Anas Bouziane. systematic literature review on automated log abstraction techniques. Information and Software Technology, 122:106276, 2020. [24] Weibin Meng, Ying Liu, Shenglin Zhang, Federico Zaiter, Yuzhe Zhang, Yuheng Huang, Zhaoyang Yu, Yuzhi Zhang, Lei Song, Ming Zhang, et al. Logclass: Anomalous log identification and classification with partial labels. IEEE Transactions on Network and Service Management, 18(2):18701884, 2021. [25] Van-Hoang Le and Hongyu Zhang. Log-based anomaly detection with deep learning: How far are we? In Proceedings of the 44th international conference on software engineering, pages 13561367, 2022. 22 [26] Jieming Zhu, Shilin He, Jinyang Liu, Pinjia He, Qi Xie, Zibin Zheng, and Michael Lyu. Tools and benchmarks for automated log parsing. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), pages 121130. Ieee, 2019. [27] Shilin He, Pinjia He, Zhuangbin Chen, Tianyi Yang, Yuxin Su, and Michael Lyu. survey on automated log analysis for reliability engineering. ACM computing surveys (CSUR), 54(6): 137, 2021. [28] Shilin He, Jieming Zhu, Pinjia He, and Michael Lyu. Experience report: System log analysis for anomaly detection. In 2016 IEEE 27th international symposium on software reliability engineering (ISSRE), pages 207218. IEEE, 2016. [29] Zhenhao Li, Heng Li, Tse-Hsun Chen, and Weiyi Shang. Deeplv: Suggesting log levels using ordinal based neural networks. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pages 14611472. IEEE, 2021. [30] Utkarsh Dixit, Suman Bhatia, and Pramod Bhatia. Utilizing ml and dl algorithms for alert classification in intrusion detection and prevention systems: detailed review. In 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), pages 11991205. IEEE, 2022. [31] Joao Henriques, Filipe Caldeira, Tiago Cruz, and Paulo Simoes. Combining k-means and xgboost models for anomaly detection using log datasets. Electronics, 9(7):1164, 2020. [32] Shenglin Zhang, Yuhe Ji, Jiaqi Luan, Xiaohui Nie, Ziang Chen, Minghua Ma, Yongqian Sun, and Dan Pei. End-to-end automl for unsupervised log anomaly detection. In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, pages 16801692, 2024. [33] Shan Ali, Chaima Boufaied, Domenico Bianculli, Paula Branco, and Lionel Briand. comprehensive study of machine learning techniques for log-based anomaly detection. Empirical Software Engineering, 30(5):129, 2025. [34] Jiaxing Qi, Zhongzhi Luan, Shaohan Huang, Yukun Wang, Carol Fung, Hailong Yang, and Depei Qian. Adanomaly: adaptive anomaly detection for system logs with adversarial learning. In NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium, pages 15. IEEE, 2022. [35] Xiaoyun Li, Pengfei Chen, Linxiao Jing, Zilong He, and Guangba Yu. Swisslog: Robust anomaly detection and localization for interleaved unstructured logs. IEEE Transactions on Dependable and Secure Computing, 20(4):27622780, 2022. [36] Zhuangbin Chen, Jinyang Liu, Wenwei Gu, Yuxin Su, and Michael Lyu. Experience report: Deep learning-based system log analysis for anomaly detection. arXiv preprint arXiv:2107.05908, 2021. [37] Shuxian Liu, Le Deng, Huan Xu, and Wei Wang. Logbd: log anomaly detection method based on pretrained models and domain adaptation. Applied Sciences, 13(13):7739, 2023. 23 [38] Yunfeng Duan, Kaiwen Xue, Hao Sun, Haotong Bao, Yadong Wei, Zhangzheng You, Yuantian Zhang, Xiwei Jiang, Sangning Yang, Jiaxing Chen, et al. Logedl: Log anomaly detection via evidential deep learning. Applied Sciences, 14(16):7055, 2024. [39] Ahmad Alzubi, Omar Darwish, Amjad Albashayreh, and Yahya Tashtoush. Cyberattack event logs classification using deep learning with semantic feature analysis. Computers & Security, 150:104222, 2025. [40] Shekar Ramachandran, Rupali Agrahari, Priyanka Mudgal, Harshita Bhilwaria, Garth Long, and Arisha Kumar. Automated log classification using deep learning. Procedia Computer Science, 218:17221732, 2023. [41] Yali Yuan, Sripriya Srikant Adhatarao, Mingkai Lin, Yachao Yuan, Zheli Liu, and Xiaoming Fu. Ada: Adaptive deep log anomaly detector. In Ieee Infocom 2020-ieee Conference on Computer Communications, pages 24492458. IEEE, 2020. [42] Hongcheng Guo, Jian Yang, Jiaheng Liu, Jiaqi Bai, Boyang Wang, Zhoujun Li, Tieqiao Zheng, Bo Zhang, Junran Peng, and Qi Tian. Logformer: pre-train and tuning pipeline for log anomaly detection. In Proceedings of the AAAI conference on artificial intelligence, volume 38, pages 135143, 2024. [43] Zhong Li, Jiayang Shi, and Matthijs Van Leeuwen. Graph neural networks based log anomaly detection and explanation. In Proceedings of the 2024 IEEE/ACM 46th international conference on software engineering: companion proceedings, pages 306307, 2024. [44] Zhiwei Wang, Zhengzhang Chen, Jingchao Ni, Hui Liu, Haifeng Chen, and Jiliang Tang. Multi-scale one-class recurrent neural networks for discrete event sequence anomaly detection. In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pages 37263734, 2021. [45] Boxi Yu, Jiayi Yao, Qiuai Fu, Zhiqing Zhong, Haotian Xie, Yaoliang Wu, Yuchi Ma, and Pinjia He. Deep learning or classical machine learning? an empirical study on log-based anomaly detection. In Proceedings of the 46th IEEE/ACM international conference on software engineering, pages 113, 2024. [46] Deepali Arun Bhanage, Ambika Vishal Pawar, and Ketan Kotecha. It infrastructure anomaly detection and failure handling: systematic literature review focusing on datasets, log preprocessing, machine & deep learning approaches and automated tool. IEEE Access, 9: 156392156421, 2021. [47] Tianzhu Zhang, Han Qiu, Gabriele Castellano, Myriana Rifai, Chung Shue Chen, and Fabio Pianese. System log parsing: survey. IEEE Transactions on Knowledge and Data Engineering, 35(8):85968614, 2023. [48] Zhuoyi Yang and Ian Harris. Logllama: Transformer-based log anomaly detection with llama. arXiv preprint arXiv:2503.14849, 2025. [49] Zeng Zhang, Wenjie Yin, and Xiaoqi Li. novel gpt-based framework for anomaly detection in system logs. arXiv preprint arXiv:2510.16044, 2025. 24 [50] Xin Huang, Ting Zhang, and Wen Zhao. Logrules: Enhancing log analysis capability of large language models through rules. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 452470, 2025. [51] Yi Wen Heng, Zeyang Ma, Zhenhao Li, Dong Jae Kim, and Tse-Hsun Chen. Benchmarking In 2025 IEEE Conference on open-source large language models for log level suggestion. Software Testing, Verification and Validation (ICST), pages 314325. IEEE, 2025. [52] Youssef Esseddiq Ouatiti, Mohammed Sayagh, Bram Adams, and Ahmed Hassan. Omnillp: Enhancing llm-based log level prediction with context-aware retrieval. arXiv preprint arXiv:2508.08545, 2025. [53] Egil Karlsen, Xiao Luo, Nur Zincir-Heywood, and Malcolm Heywood. Benchmarking large language models for log analysis, security, and interpretation. Journal of Network and Systems Management, 32(3):59, 2024. [54] Achintha Ihalage, Sayed Taheri, Faris Muhammad, and Hamed Al-Raweshidy. Convolutional vs large language models for software log classification in edge-deployable cellular network testing. IEEE Access, 2025. [55] Yilun Liu, Shimin Tao, Weibin Meng, Jingyu Wang, Wenbing Ma, Yuhang Chen, Yanqing Zhao, Hao Yang, and Yanfei Jiang. Interpretable online log analysis using large language models with prompt strategies. In Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension, pages 3546, 2024. [56] Isaiah Thompson Ocansey, Ritwik Bhattacharya, and Tanmay Sen. Logtinyllm: Tiny large language models based contextual log anomaly detection. arXiv preprint arXiv:2507.11071, 2025. [57] Se-Jin Kim and Chan-Gun Lee. Automated log statement using source-code metrics. IEEE Access, 2025. [58] Minh-Thanh Bui, Matteo Boffa, Rodolfo Vieira Valentim, Jose Manuel Navarro, Fuxing Chen, Xiaosheng Bao, Zied Ben Houidi, and Dario Rossi. systematic comparison of large language models performance for intrusion detection. Proceedings of the ACM on Networking, 2(CoNEXT4):123, 2024. [59] Shuo Yang, Xinran Zheng, Xinchen Zhang, Jinfeng Xu, Jinze Li, Donglin Xie, Weicai Long, and Edith CH Ngai. Large language models for network intrusion detection systems: Foundations, implementations, and future directions. arXiv preprint arXiv:2507.04752, 2025. [60] Sahar Ahmed. Optimizing llms for microservices logs analysis through prompt engineering, 2025. [61] Yilun Liu, Shimin Tao, Weibin Meng, Feiyu Yao, Xiaofeng Zhao, and Hao Yang. Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. In Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings, pages 364365, 2024. 25 [62] Tianyu Cui, Shiyu Ma, Ziang Chen, Tong Xiao, Shimin Tao, Yilun Liu, Shenglin Zhang, Duoming Lin, Changchang Liu, Yuzhe Cai, et al. Logeval: comprehensive benchmark suite for large language models in log analysis. arXiv preprint arXiv:2407.01896, 2024. [63] Chiming Duan, Tong Jia, Yong Yang, Guiyang Liu, Jinbu Liu, Huxing Zhang, Qi Zhou, Ying Li, and Gang Huang. Eagerlog: Active learning enhanced retrieval augmented generation for log-based anomaly detection. In ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 15. IEEE, 2025. [64] Chaitanya Sharma. Retrieval-augmented generation: comprehensive survey of architectures, enhancements, and robustness frontiers. arXiv preprint arXiv:2506.00054, 2025. [65] Wenlong Wu, Haofen Wang, Bohan Li, Peixuan Huang, Xinzhe Zhao, and Lei Liang. Multirag: knowledge-guided framework for mitigating hallucination in multi-source retrieval augmented generation. In 2025 IEEE 41st International Conference on Data Engineering (ICDE), pages 30703083. IEEE, 2025. [66] Lipeng Ma, Weidong Yang, Yixuan Li, Ben Fei, Mingjie Zhou, Shuhao Li, Sihang Jiang, Bo Xu, and Yanghua Xiao. Adaptivelog: An adaptive log analysis framework with the collaboration of large and small language model. ACM Transactions on Software Engineering and Methodology, 2025. [67] Christian Braun, Alexander Lilienbeck, and Daniel Mentjukov. The hidden structure improving legal document understanding through explicit text formatting. arXiv preprint arXiv:2505.12837, 2025. [68] Jia He, Mukund Rungta, David Koleczek, Arshdeep Sekhon, Franklin Wang, and Sadid Hasan. Does prompt formatting have any impact on llm performance? arXiv preprint arXiv:2411.10541, 2024. [69] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. [70] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:2219922213, 2022. [71] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. [72] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen-tau Yih, Tim Rocktaschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems, 33:94599474, 2020. [73] Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, PierreEmmanuel Mazare, Maria Lomeli, Lucas Hosseini, and Herve Jegou. The faiss library. IEEE Transactions on Big Data, 2025. [74] Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xin Zhou, Enzhi Wang, and Xiaohang Dong. Better zero-shot reasoning with role-play prompting. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 40994113, 2024. [75] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Baobao Chang, et al. survey on in-context learning. In Proceedings of the 2024 conference on empirical methods in natural language processing, pages 11071128, 2024. [76] Zach Nussbaum, John Morris, Brandon Duderstadt, and Andriy Mulyar. Nomic embed: Training reproducible long context text embedder. arXiv preprint arXiv:2402.01613, 2024. [77] LM Studio Inc. Lm studio [computer software]. https://lmstudio.ai, 2025. Accessed: 29 October 2025. [78] Fali Wang, Minhua Lin, Yao Ma, Hui Liu, Qi He, Xianfeng Tang, Jiliang Tang, Jian Pei, and Suhang Wang. survey on small language models in the era of large language models: Architecture, capabilities, and trustworthiness. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2, pages 61736183, 2025. [79] Nghiem Thanh Pham, Tung Kieu, Duc-Manh Nguyen, Son Ha Xuan, Nghia Duong-Trung, and Danh Le-Phuoc. Slm-bench: comprehensive benchmark of small language models on environmental impactsextended version. arXiv preprint arXiv:2508.15478, 2025. [80] Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan Fu, Xin Dong, Saurav Muralidharan, Yingyan Celine Lin, and Pavlo Molchanov. Small language models are the future of agentic ai. arXiv preprint arXiv:2506.02153, 2025. [81] Chengyu Wang, Taolin Zhang, Richang Hong, and Jun Huang. short survey on small reasoning models: Training, inference, applications and research directions. arXiv preprint arXiv:2504.09100, 2025. [82] Krishna Teja Chitty-Venkata, Siddhisanket Raskar, Bharat Kale, Farah Ferdaus, Aditya Tanikanti, Ken Raffenetti, Valerie Taylor, Murali Emani, and Venkatram Vishwanath. Llminference-bench: Inference benchmarking of large language models on ai accelerators. In SC24W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis, pages 13621379. IEEE, 2024. [83] Zifu Wang, Yun Li, Kevin Wang, Jacob Cain, Mary Salami, Daniel Duffy, Michael Little, and Chaowei Yang. Adopting gpu computing to support dl-based earth science applications. International Journal of Digital Earth, 16(1):26602680, 2023. [84] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. [85] Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Rame, Morgane Rivi`ere, et al. Gemma 3 technical report. arXiv preprint arXiv:2503.19786, 2025. 27 [86] Meta AI. Llama 3.2: Model cards and prompt formats. https://www.llama.com/docs/ model-cards-and-prompt-formats/llama3_2/, 2024. Accessed: 2025-12-04. [87] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. [88] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [89] Haoran Xu, Baolin Peng, Hany Awadalla, Dongdong Chen, Yen-Chun Chen, Mei Gao, Young Jin Kim, Yunsheng Li, Liliang Ren, Yelong Shen, et al. Phi-4-mini-reasoning: Exploring the limits of small reasoning language models in math. arXiv preprint arXiv:2504.21233, 2025. [90] Nelson Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157173, 2024. [91] Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et al. Measuring faithfulness in chain-of-thought reasoning. arXiv preprint arXiv:2307.13702, 2023. [92] Miles Turpin, Julian Michael, Ethan Perez, and Samuel Bowman. Language models dont always say what they think: Unfaithful explanations in chain-of-thought prompting. Advances in Neural Information Processing Systems, 36:7495274965, 2023. [93] Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Richard James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, et al. Ra-dit: Retrieval-augmented dual instruction tuning. In The Twelfth International Conference on Learning Representations, 2023. [94] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learning to retrieve, generate, and critique through self-reflection. In Proceedings of the International Conference on Learning Representations (ICLR), 2024. URL https://selfrag.github.io/. [95] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. In Proceedings of the 61st annual meeting of the association for computational linguistics (volume 1: long papers), pages 1001410037, 2023."
        }
    ],
    "affiliations": [
        "George Mason University"
    ]
}