{
    "paper_title": "Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding",
    "authors": [
        "Yunkai Zhang",
        "Qiang Zhang",
        "Feng Lin",
        "Ruizhong Qiu",
        "Hanchao Yu",
        "Jiayi Liu",
        "Yinglong Xia",
        "Zhuoran Yu",
        "Zeyu Zheng",
        "Diji Yang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyond-accuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in a fully unsupervised manner. Instead of discarding the human priors accumulated over years of practice, we introduce a backbone-agnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along human-understandable axes (e.g., interaction types, long- vs. short-term interests). We also introduce a hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . [ 2 2 9 4 0 1 . 1 1 5 2 : r Dont Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding Yunkai Zhang1,2,, Qiang Zhang1, Feng (Ryan) Lin1, Ruizhong Qiu1, Hanchao Yu1, Jiayi (Jason) Liu1, Yinglong Xia1, Zhuoran Yu1, Zeyu Zheng2, Diji Yang3, 1Meta AI, 2BAIR (UC Berkeley), 3UC Santa Cruz Work done at Meta, Last author Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyondaccuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in fully unsupervised manner. Instead of discarding the human priors accumulated over years of practice, we introduce backboneagnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along humanunderstandable axes (e.g., interaction types, longvs. short-term interests). We also introduce hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes. Date: November 18, 2025 Correspondence: Yunkai Zhang at yunkai_zhang@berkeley.edu and Qiang Zhang at qiangzhang@meta.com Code: https://github.com/zhykoties/Multi-Head-Recommendation-with-Human-Priors"
        },
        {
            "title": "1 Introduction",
            "content": "The goal of recommender systems extends beyond mere predictive accuracy. The importance of objectives such as novelty and diversity has long been recognized within the academic community Adomavicius and Tuzhilin (2005), acknowledging that successful system must balance relevance with discovery. Nevertheless, the metrics predominantly used to evaluate and optimize these systems have centered on accuracy and engagement Ricci et al. (2021). This focus catalyzed significant algorithmic advancements, from collaborative filtering Sarwar et al. (2001); He et al. (2017) to deep sequential models Kang and McAuley (2018); Zhai et al. (2024). However, the prioritization of easily measurable signals has exposed critical limitation, often termed the alignment problem: model may predict the next interaction accurately, yet fail to align with the users broader goals or well-being. This optimization imbalance has been shown to yield detrimental side effects, including polarization, addiction, and popularity bias, while discouraging the discovery of new user interests. This realization has accelerated paradigm shift toward human-centered approach. The critical question is evolving from Is this recommendation accurate? to Is this recommendation worth your time?, which requires considering richer set of objectives that extend beyond accuracy, such as diversity, novelty, and personalization Said et al. (2025). 1 To navigate these multifaceted objectives, industrial recommendation systems have accumulated wide array of post-hoc adjustments applied during the ranking or post-ranking stage Wang et al. (2020); McDonald et al. (2023); Wu et al. (2025). We refer to this accumulated domain expertise as human priors. For example, diversity is often enforced by greedily selecting candidates that maximize combined function of relevance and entropy (defined over manually tuned categories). To favor high-value interactions (e.g., purchases over clicks), practitioners typically build separate value models for each interaction type and apply heuristic weighting schemes. Similarly, balancing short-term engagement with long-term interests often involves temporal discounting heuristics or separate value models trained on different time horizons. Furthermore, ensuring adequate personalization for minority users frequently relies on first identifying these minority users and then optimizing separate value model, or boosting content based on demographic features. Recently, the field is trending towards the development of end-to-end (E2E) generative recommendation foundation models Zhai et al. (2024); Chen et al. (2024); Zhou et al. (2025). While powerful, these models often attempt to learn user intent in an entirely unsupervised manner. Consequently, we still rely on the aforementioned post-hoc adjustments. However, these adjustments remain disconnected from the core representation learning process. As result, the core model itself remains black box, unaware of the crucial objectives. Additionally, to accommodate such adjustments, it is usually required to make specific changes to the model recommendations, which incurs additional cost. Alternative approaches attempt to explicitly address specific aspects, such as multi-interest networks for diversityLi et al. (2019); Cen et al. (2020); Xie et al. (2023) or disentanglement methods for interpretability Ma et al. (2019); Guo et al.. However, these methods typically require specialized architectures and their applicability in industry scenarios is still limited. This dichotomy between complex post-hoc adjustments and unsupervised E2E models motivates question: Instead of discarding the human priors accumulated over years of practice, can we integrate them directly into the learning process of generative recommender systems in simple, effective, and interpretable manner? To this end, we propose backbone-agnostic framework that seamlessly injects various human priors into the generative model training with lightweight adapters, by drawing inspiration from efficient decoding strategies in Large Language Models (LLMs) Cai et al. (2024). Unlike post-hoc filtering or architecture-specific modifications, these adapter heads guide the sequential model to learn user representations that are naturally disentangled. This renders the model inherently controllable, explainable, and better aligned with complex, real-world objectives. Our main contributions are summarized as follows: We generalize the concept of multi-interest to multi-faceted intent by demonstrating the frameworks effectiveness across diverse human priors, including semantic, behavioral, temporal, and graph priors. We propose lightweight and backbone-agnostic framework that uses prior-conditioned adapter heads to disentangle multifaceted user intent in an end-to-end manner. We introduce hierarchical composition strategy to model complex interactions across different prior types, providing flexible inductive bias for learning compositional representations. Extensive experiments on three large-scale datasets demonstrate that our method not only improves standard accuracy metrics, but also yields significant improvements on other objectives, such as diversity, personalization, and user interest discovery."
        },
        {
            "title": "2 Related Work",
            "content": "We position our work at the intersection of generative recommendation, muti-interest and disentangled representation learning, and the integration of structured knowledge, motivated by the broader shift toward human-centered recommendation."
        },
        {
            "title": "2.1 Generative Recommenders",
            "content": "Modeling the temporal dynamics of user behavior is fundamental challenge in recommender systems. Early approaches used Recurrent Neural Networks (e.g., GRU4Rec Hidasi (2015)). The field shifted significantly by adopting the Transformer architecture, which offers superior scalability and capacity for modeling long-range 2 dependencies. SASRec Kang and McAuley (2018) established strong baseline using self-attention for next-item prediction, leading to variants such as BERT4Rec Sun et al. (2019) (bidirectional modeling) and S3Rec Zhou et al. (2020) (self-supervised learning). Recently, the focus has shifted to large-scale foundational models. Generative Recommenders, such as HSTU Zhai et al. (2024), frame recommendation as sequential transduction task, demonstrating significant performance gains at scale. HLLM Chen et al. (2024) introduces hierarchical approach by stacking two large language models (LLMs): an item LLM to capture item content and user LLM to model user behavior. Despite these advances, the prevailing paradigm relies on encoding the users history into single, monolithic state vector. This representation bottleneck struggles to capture the heterogeneity and multi-faceted nature of user intent, often leading to suboptimal recommendations when interests conflict or evolve."
        },
        {
            "title": "2.2 Modeling Multi-Faceted User Intent",
            "content": "To address the limitations of monolithic representations, works on multi-interest frameworks and disentangled representation learning emerged. They generally attempt to discover latent factors of user intent in an unsupervised manner and learn the preference distribution conditioned on these factors. Multi-interest frameworks aim to extract multiple vectors representing distinct user preferences from single sequence. Many prominent models adopt cluster-then-encode paradigm, relying on algorithms to partition the user history before encoding. For instance, MIND Li et al. (2019) employed dynamic routing via capsule networks to group interactions. ComiRec Cen et al. (2020) extended this with controllable aggregation framework, and REMI Xie et al. (2023) aimed to improve the stability of this process using regularization to prevent routing collapse. Disentangled representation learning focuses on separating the underlying factors of variation in user behavior, often using Variational Autoencoders (VAEs). For example, MacridVAE Ma et al. (2019) sought to separate high-level intentions from low-level preferences, while DualVAE Guo et al. learns disentangled multi-aspect representations for both users and items, and ensures correspondence between each aspect of the user representation and the item representation. While valuable, these unsupervised approaches share critical limitations. First, they primarily focus on apparel), often conflating other critical dimensions disentangling topic interests (e.g., electronics vs. such as temporality or co-engagement structures. Second, the cluster-then-encode paradigm often relies on computationally intensive or potentially unstable discovery processes (e.g., dynamic routing, clustering). Third, the learned interest vectors often lack explicit semantic meaning. This lack of interpretability severely limits controllability, making it difficult to steer recommendations to align with business objectives, such as promoting more educational videos in order to comply with regulations."
        },
        {
            "title": "2.3 Integration of Human Priors and Structure\nThere is growing recognition that integrating structured, human-understandable knowledge, or human priors,\ncan enhance model performance and interpretability.",
            "content": "In recommender systems, human priors have traditionally been incorporated through rigid structures or post-hoc adjustments. Hierarchical models, such as HieRec Qi et al. (2021), use fixed, predefined item taxonomies to create static interest hierarchy. While effective for taxonomy-based disentanglement, such methods cannot easily accommodate diverse, orthogonal priors (e.g., temporal dynamics) that do not fit neatly into item categories. Alternatively, industrial systems often rely on brittle post-hoc heuristic rules, which are decoupled from the core learning process. In language models, there is significant work on enhancing models Knowledge and Adaptation in LLMs. with external knowledge and structural biases. Methods like KnowBert Peters et al. (2019) inject entity embeddings from knowledge bases to improve factual recall. Furthermore, introducing structural inductive biases, such as the Tree of Thoughts (ToT) framework Yao et al. (2023), has been shown to improve reasoning abilities. 3 Table 1 Examples of human priors supported by our framework. Prior Type Description and Examples Item Semantic item attributes, such as product categories, content genres, or learned topic clusters. Temporal Evolution of user interests (e.g., short-term vs. long-term). Event Graph User The modality of the user-item interaction (e.g., click, like, purchase, subscribe). Community-based item clusters derived from co-engagement or knowledge graphs. User attributes such as demographics, subscription status, or clusters from user co-interaction graph. Drawing inspiration from these trends and efficient LLM adaptation techniques like Medusa Cai et al. (2024), our work diverges from previous approaches by proposing an encode-then-project paradigm. We integrate diverse human priors directly into the end-to-end learning process using lightweight, prior-conditioned adapter heads. This bypasses the need for expensive unsupervised discovery or explicit history clustering, avoids rigid taxonomies, and yields representations that are inherently disentangled along interpretable and controllable axes."
        },
        {
            "title": "3.1 Problem Formulation\nLet a user’s interaction history be a sequence of items x1:T = (x1, . . . , xT ), where T is the context length,\nrepresenting the number of item interactions in the history. The objective is to predict the user’s future\nengagement over the next τ items, denoted as Y = {yT +1, . . . , yT +τ }.\nFirst, a sequential encoder fθ (e.g., a decoder-only transformer) is used to map the interaction history x1:T\ninto a latent user state representation hT ∈ Rd. Let V be the set of all candidate items, and each item i ∈ V\nis represented by an embedding ei ∈ Rd. These item embeddings can either be ID-based (e.g., HSTU) or\nsemantic-based (e.g., HLLM). The conventional approach computes a relevance score for each candidate item\ni using the dot product between the user state and the item embedding:",
            "content": "The top-K items with the highest scores are then recommended to the user. This approach relies on single representation hT to capture all facets of user intent, which may be suboptimal when interests are diverse, context-dependent, or evolving over time. s(i hT ) = ei. (1)"
        },
        {
            "title": "3.2 Incorporating Human Priors via Conditioned Query Heads",
            "content": "Real-world user behavior is often characterized by specific factors that can be formalized as human priors. These priors provide structured and interpretable way to partition the interaction space along meaningful dimensions, such as item semantics, temporal dynamics, or interaction modalities (see Table 1). To effectively incorporate these priors without modifying the backbone model fθ, we introduce multi-head framework that employs multiple lightweight, prior-conditioned adapter heads to generate set of specialized query embeddings, instead of relying on single representation hT . Let be the index set of the prior heads. With each head corresponding to specific prior group (e.g., the Sports category), we can project the backbones output hT into different specialized query vectors q1, qK. Inspired by the multi-head decoding structure of Medusa Cai et al. (2024), we implement the projection through residual adapter : qk = hT + SiLU(cid:0)W(k)hT (cid:1), (2) where W(k) Rdd is learnable transformation matrix and SiLU is the activation function Elfwing et al. (2018). We initialize each W(k) with zeros, ensuring that all heads output the same representation as the original user state hT at the beginning of training. As training progresses, each individual head specializes only when supported by the training signal, whereas the backbone model is shared among all prior heads. This design allows the backbone to process users entire interaction history, while each prior head is dedicated to modeling specific subset of interactions. In our design, each head is restricted to retrieve only items compatible with its Compatibility masking. associated prior group, with the set of such items denoted by Ωk V, where the definition of Ωk depends on the prior type. For example, for item-based priors (e.g., categories), an item belongs to Ωk if it is labeled with category k, and for event-based priors, Ωk includes items accessible through event type k. To enforce this specialization in inference, we define score through the following compatibility masking: sk(ihT ) = (cid:40) ei, , Ωk, / Ωk. (3) This masking approach filters out all the incompatible items for the prior heads and ensures each head can focus exclusively on the subset of items aligned with its prior group. As result, in contrast to the score in Eq. (1), the resulting score in Eq. (3) is tailored to different items with their prior information, which results in an explicit decomposition of user intent. Unlike conventional unsupervised approaches built on implicit latent factors Ma et al. (2019); Guo et al.; Li et al. (2019), our method allows for more model interpretability as it guarantees that the learned representation qk is identifiable. In addition, while conventional approaches suffer from the inherent uncertainty arising from the entanglement of user preferences and their underlying latent factors, our method mitigates this issue by disentangling this complexity into set of more tractable sub-tasks, thereby enhancing the computational efficiency. With compatibility masking, different query heads are specialized with distinct functional roles determined by the specified priors. Thus, when predicting for one prior group, our method can largely reduce the reliance on irrelevant features, which minimizes the mutual interference among these different objectives. As result, the model can show stronger predictive capability for each prior group, and thus result in performance improvement with the cooperation of the heads."
        },
        {
            "title": "3.3 Hierarchical Composition of Priors",
            "content": "Practical recommendation settings often involve multiple, potentially interacting priors (e.g., combining item categories with temporal interests). Given distinct sets of priors {P (1), . . . , (D)} with cardinalities (1), . . . , (D) respectively, key challenge when generalizing the adapter mechanism (proposed previously in Eq. (2)) is how to effectively capture the interactions between different prior sets while mitigating data sparsity for rare combinations. We introduce hierarchical composition strategy that organizes the adapters sequentially into tree structure. This architecture enforces coarse-to-fine specialization process, encouraging the model to first learn robust, shared intermediate representations at the upper levels before refining for specific prior combinations. This design is motivated by Bayesian hierarchical modeling Allenby et al. (2005), which has the shrinkage effect, where group-level estimates are pulled towards common mean as an effective form of regularization, preventing overfitting in rare prior combinations. Furthermore, this structural inductive bias mirrors recent advances in Large Language Models (LLMs), where hierarchical structures are employed to enhance reasoning, such as in Tree of Thoughts Yao et al. (2023). Starting with the base representation z(0) = hT , we recursively apply prior-specific residual adapters. At depth d, the representation corresponding to the path (g1, . . . , gd) is: z(d) g1,...,gd = z(d1) g1,...,gd1 + A(d) g1,...,gd (cid:0)z(d1) g1,...,gd1 (cid:1). (4) The final queries are the leaf nodes qg1,...,gD = z(D) g1,...,gD where the parameters at depth are conditioned on the entire upstream path (g1, . . . , gd). It is defined as: denotes path-dependent adapters, . Here, A(d) g1,...,gd A(d) g1,...,gd (z) = SiLU(cid:0)W(d) g1,...,gd z(cid:1) + egd1, (5) where W(d) g1,...,gd Rdd are path-dependent weights. We also incorporate learned group embedding egd1 Rd. This embedding is shared across all branches that include gd1 (e.g., across all sub-trees rooted at short-term interest), encouraging information sharing among related heads. Hierarchical Compatibility. The eligible item set for hierarchical head is defined by the intersection of the compatibilities across all involved priors: Ωg1,...,gD = (cid:92) d=1 Ω(d) gd . An item is eligible for the head (g1, . . . , gD) if and only if it is compatible with all involved priors along the path."
        },
        {
            "title": "3.4 Training Objective\nFor a specific head k, the set of positive examples is defined as the subset of future ground-truth items Y\ncompatible with that head:",
            "content": "Yk = { : Ωk }. (6) Heads for which Yk = in batch are excluded from the loss computation for that batch. We optimize the parameters of each head using unified loss framework, which can be instantiated as either next-token prediction loss (for ID-based embeddings) or contrastive learning loss (for semantic-based embeddings): Lk,t = 1yT +tYk log exp(sk(yT +t)) (cid:80) Ωk exp(sk(j)) . (7) Here, Lk,t is the loss for head with yT +t as the positive item. Ωk Ωk is the set of items over which the softmax is computed. For next-token prediction, Ωk can be all the compatible items Ωk. For contrastive learning, it is typically subset containing the positives and some sampled negatives. We restrict Ωk to be only from Ωk. This in-group negative sampling forces the head to discriminate among items within the same prior group. This naturally exposes the model to harder negatives (semantically or contextually similar items), leading to improved representations Robinson et al. (2021). To properly balance the contributions from different heads and prioritize near-future predictions, we introduce reweighting scheme. The final loss is sum over the forecast horizon, with each step weighted by temporal discount factor: τ (cid:88) = γt1 (cid:88) wk Lk,t, (8) where Lk,t is defined in Eq. (7). This formulation incorporates two mechanisms: t=1 kK 1. Frequency Balancing: To mitigate the impact of data imbalance across heads and prevent common priors from dominating the loss, we normalize by the relative frequency of each combination of priors: = Yk wfreq (cid:80) . jK Yj 2. Temporal Discounting: We apply discount factor γ (0, 1] to prioritize near-future predictions, since predicting the very next item is often more critical than the more distant items, and the labels are also less noisy."
        },
        {
            "title": "3.5 Inference and Score Fusion\nDuring inference, given a user state hT , we compute all prior-conditioned queries {qk}k∈K. For a candidate\nitem i, we identify the set of eligible heads H(i) = {k : i ∈ Ωk}. We then fuse the scores {sk(i)}k∈H(i) to\nobtain a final relevance score S(i), which is then used to rank the candidates.",
            "content": "6 We adopt maximum fusion strategy: Smax(i) = maxkH(i) sk(i), which allows the most relevant specialist to dominate1. Not only is it computationally simple, but it also enhances interpretability by providing clear explanation for the recommendation (e.g., this item was recommended because it strongly matches your short-term interest in electronics)."
        },
        {
            "title": "3.6 Implementation Details",
            "content": "The proposed framework is model-agnostic and can be integrated with any generative recommender system that produces dense user representation hT . The efficiency of the approach stems from the lightweight nature of the adapters2 and the parallelizability of the query computations at the same depth level in the hierarchy, thus minimizing the latency overhead. Per-group indices {Ωk} are pre-computed and cached, enabling efficient computation of the masked scores (Eq. (3)) via batched matrix multiplication. To allow scalable distributed training on massive datasets, we implemented several critical optimizations. significant bottleneck is the CPU memory overhead caused by replicating the dataset for each local process. We address this with shared memory data structure, which ensures that the dataset is loaded and serialized into contiguous byte array only once by the local master process (rank 0), which then places the data into POSIX shared memory block. Peer processes on the same node subsequently attach to this shared memory block and access individual data objects using pre-computed byte offsets. This approach enables near zero-copy access to the data, eliminating intra-node redundancy and significantly reducing the per-node memory footprint. Furthermore, we optimize the data loading pipeline for sequential recommendation. Existing approaches often pre-generate rolling windows, leading to substantial data redundancy. Instead, we pre-compute and store only the starting indices of the valid sample locations. It allows for more nuanced sampling strategies, such as using overlapping windows to maximize training data usage or prioritizing more recent interactions. For massive datasets exceeding available memory, we first preprocess user interaction histories and store them as individual NumPy files. During training, workers first sample user based on predefined weights, and then access the corresponding file via NumPy memmap, which allows efficient access to file segments on disk without loading the entire file into RAM. The specific sequence window is determined according to some custom sampling strategies and only the selected window is loaded on-demand."
        },
        {
            "title": "4.1 Datasets and Prior Instantiation",
            "content": "To instantiate and evaluate different types of human priors  (Table 1)  , we select three real-world datasets from various domains: video (Pixel8M), e-Commerce (MerRec), and news (EB-NeRD). Detailed statistics are provided in Appendix A.1  (Table 8)  . 4.1.1 Pixel8M (Video) Pixel8M Cheng et al. (2024) is large-scale dataset from an online video sharing platform, featuring rich multimodal item content with text and images. As the industry trend is to incorporate more modalities, this allows us to test whether our framework provides additional benefits even when the backbone model can leverage these modalities to recommend diverse contents. Semantic Item Prior: To create structured semantic prior, we consolidated the datasets 111 highly unbalanced and sometimes redundant tags into eight high-level categories: Real life, Informational & Educational, Fictional character, Music, Science & technology, Entertainment, Gaming, Performance & Arts. To perform this task easily, consistently, and at scale, we follow the practical approach Ding et al. (2023) and prompted ChatGPT to assign each original tag to one or more categories. 1We explore alternative fusion strategies in Section 4.7.2. 2We show each head only incurs an extra 0.14% of overall parameters in Section 4.3. 4.1.2 MerRec (E-commerce) MerRec Li et al. (2025) is derived from the Mercari C2C marketplace. It is characterized by exceptionally long interaction sequences (there are 119756 users that have at least 2000 interactions) and diverse user behaviors. Event Prior: Users interact with items with one of six event types: item view, item like, add to cart, offer make, Buy start, and Buy complete. These events represent different levels of user intent. key challenge here is that offer make, Buy start, and Buy complete only occur less than 1% of the time, but they are also most directly related to monetization. We use event types as priors to investigate the frameworks ability to specialize on sparse, high-value signals. 4.1.3 EB-NeRD (News) EB-NeRD Kruse et al. (2024) is news recommendation dataset with high-quality textual content. This dataset is less sparse than the previous two datasets, and the interaction patterns in news consumption often reflect the underlying community structures. Graph Prior: We construct an item co-engagement graph, where an edge exists if two items are interacted with by the same user. To discover underlying structural priors, for simplicity, we apply the off-the-shelf Leiden algorithm Traag et al. (2018) from the igraph package, an established method for community detection that optimizes modularity and guarantees that the resulting communities are well connected. We control the influence of highly active users and merge very small clusters (details in Appendix A.1). The resulting item clusters are used as graph-based priors, testing the frameworks ability to leverage community structures3. 4.1.4 General Temporal Prior. In addition to domain-specific priors, we instantiate temporal priors, applicable across all datasets, to capture the evolution of user interests. Given forecast horizon τ , we divide it into contiguous long-term), trained only on segments. Each segment corresponds to prior head (e.g., short-term vs. ground-truth items falling within that specific temporal segment."
        },
        {
            "title": "4.2 Experiment Setup",
            "content": "We integrate our framework with two recent generative recommender architectures to demonstrate its generalizability: HSTU Zhai et al. (2024): scalable, Transformer-based architecture representing the state-of-the-art in ID-based modeling. It uses learned item ID embeddings, and is trained with next-item prediction objective. We experiment with five sizes, from 12.42M to 1B parameters. We report based on size 3 by default. HLLM Chen et al. (2024): hierarchical LLM-based architecture representing the state-of-the-art in semantic-based modeling. It uses an Item LLM to derive item embeddings from text and visual content, and is trained with contrastive learning objective for next item prediction. We compare the performance of these backbone models against their counterparts enhanced with our priorconditioned adapter framework. We also compare against the following baselines: ComiRec Cen et al. (2020) is representative multi-interest network that outputs multiple embeddings as the different interests for each user, and uses controllable aggregation framework to balance diversity and accuracy. REMI Xie et al. (2023) improves multi-interest networks like ComiRec by introducing Interest-aware Hard Negative Mining and Routing Regularization term to mitigate routing collapse. DualVAE Guo et al. learns disentangled multi-aspect representations for both users and items, and uses neighborhood-enhanced contrastive learning to ensure direct correspondence between each aspect of item representations and user representations. 3While this algorithmic clustering is practical choice for our implementation, its success also underscores the frameworks tolerance for noisy or approximated priors, suggesting it can derive benefits even from imperfect structural information. 8 Architectural details and hyperparameters are provided in Appendix A.2.4 We evaluate the recommendation accuracy using standard retrieval metrics: Recall@K and NDCG@K (Normalized Discounted Cumulative Gain)."
        },
        {
            "title": "4.3 Main Results",
            "content": "Table 2 summarizes the overall performance across the three datasets and two backbone architectures. The integration of human priors consistently improves both Recall and NDCG over different settings. Furthermore, combining multiple priors (e.g., Item + Temporal, Graph + Temporal) can lead to additional performance gains, demonstrating that our framework can effectively capture multi-faceted user intents. On EB-NeRD, with 8 temporal segments and 11 clusters, our method is able to scale to total of 88 heads. Notably, our adapter heads are very lightweight. In the HSTU case, single head only takes up 0.14% of the overall model parameters. Table 2 Overall performance comparison. Human priors consistently lead to improvements over the backbone models (HSTU and HLLM). The backbones and baselines are highlighted in gray. Note that HLLM and HSTU results are not directly comparable due to different context lengths used (See Appendix A.1), and all the baselines are run under the HSTU settings and should only be compared to HSTU. Dataset Model Recall@5 Recall@10 NDCG@5 NDCG@10 Pixel8M MerRec EB-NeRD HLLM +Item +LT/ST +Both ComiRec REMI DualVAE HSTU +Item +LT/ST +Both HLLM +Event ComiRec REMI DualVAE HSTU +Event HLLM +Graph +LT/ST +Both ComiRec REMI DualVAE HSTU +Graph +LT/ST +Both 0.84 0.91 0.88 0.92 1.04 1.13 0.95 0.90 1.08 1.15 1.23 33.83 35.85 40.74 41.46 38.36 40. 42.61 18.14 21.09 19.76 21.54 21.47 21.61 18.54 19.77 20.78 21.50 22.36 1.37 1.48 1.44 1.50 1.70 1.81 1.49 1.45 1.75 1.90 2.00 42. 43.48 49.49 49.27 48.20 49.30 50.33 31.23 36.05 34.05 36.24 35.71 34.79 31.24 32.54 34.48 36.28 37.05 1.46 1.57 1.52 1.59 1.80 1.99 1.67 1.56 1.88 1. 2.12 24.38 26.87 30.07 31.55 27.29 29.71 33.49 26.40 32.19 28.17 32.38 32.18 33.11 28.28 30.36 31.59 32.20 33.87 1.42 1.54 1. 1.56 1.77 1.92 1.60 1.53 1.83 1.96 2.09 27.05 29.36 33.01 33.15 31.03 32.61 35.99 29.47 35.05 31.57 35.16 34.75 34.88 30.61 32.30 33.84 34.99 36. 4For fair comparison, we implement ComiRec and REMI on top of the HSTU backbone, and we validated that they achieve better performances compared to the original dense layers. However, DualVAE becomes very unstable once we switch to deep encoders, instead of the shallow encoders in its codebase, so we stick with its original implementation. 9 Both ComiRec and REMI underperform the counterparts when we inject human prior into HSTU. The reason is that instead of relying on purely unsupervised methods to discover latent interests as in multi-interest networks, our approach uses these explicit priors as form of weak supervision to guide the model in learning different user intents as well as disentangled representations. As for DualVAE, we observe it to be very unstable when implemented based on the deep HSTU backbone. With its original shallow encoders, it only marginally outperforms HSTU on Pixel8M and even slightly lags behind HSTU on MerRec and EB-NeRD."
        },
        {
            "title": "4.4 Benefits Beyond Standard Metrics",
            "content": "4.4.1 Better Accuracy-Diversity Trade-off We demonstrate that our method not only improves traditional ranking metrics such as Recall and NDCG, but also promotes recommendation diversity. To quantify this, we define an entropy-based metric in terms (cid:1), where nj is the of the eight binary item categories on the Pixel8M dataset, H@K = (cid:80)8 number of top-K items for which the j-th binary feature is active. Intuitively, higher entropy means that the top-K recommended items are semantically more diverse. log2 (cid:0) nj nj j= Figure 1 Evolution of entropy as training progresses on the validation set. Here HSTU is the backbone model. As shown in Figure 1, all model variants begin training with high entropy, which gradually declines as the training progresses. Interestingly, higher entropy typically corresponds to lower NDCG due to the accuracy-diversity trade-off. However, we observe that injecting item priors can partially break this constraint: the variants using Item Prior and both priors simultaneously achieve higher NDCG while maintaining higher entropy. This balance between relevance and diversity is also observed in HLLM (Appendix Table 6). We also include strong multi-interest network baseline, REMI. Without explicit supervision from item priors, it only marginally improves diversity over the HSTU backbone. 4.4.2 User Interest Exploration Exploration in recommender systems aims to uncover content user may like but has not yet engaged with. Although it improves long-term user engagement, it is often believed to negatively affect near-term experience Chen et al. (2021), similar to the exploration versus exploitation dilemma in reinforcement learning. We argue that adding multiple heads for human priors can somehow strike good balance between the two. To evaluate this, we analyze the performance of our method on targeted subset of users in the Pixel8M dataset using HLLM. Specifically, we identify users who interacted with item features during the forecast horizon of the test split, but who had never engaged with those features in their prior history. In these cases, the models success hinges on its ability to recommend items from entirely new categories. Applying this criterion, we identified total of 283,497 such users. Table 3 compares the relative improvement over the HLLM without priors baseline achieved by different prior configurations on the standard evaluation set (All Users) versus this subset (New Interest). We also quantify the relative boost, which measures how much more the method improves performance on the New Interest subset compared to All Users. Table 3 The relative improvement over the HLLM baseline for All Users vs. New Interest. Both priors help with user interest exploration, and Item Prior brings even larger gain compared to LT/ST interest due to more direct supervision. Variant Split N@10 R@10 N@ R@200 LT/ST1 LT/ST2 LT/ST1 + Item LT/ST2 + Item LT/ST4 + Item 8.50% All New 9.70% Rel. Boost +3.58% +9.00% +10.30% +14.40% 7.16% 7.41% 7.80% 8.50% 8.10% 8.90% 6.20% All 6.30% New Rel. Boost +2.68% +1.70% 5.23% 5.37% All New Rel. Boost 8.53% 9.87% 9.00% 10.40% +15.76% +16.50% 8.00% 8.40% +5.50% 7.90% 9.20% +17.50% 9.20% 9.80% +6.80% 7.50% 9.00% +19.50% 10.40% All New 11.20% Rel. Boost +6.10% +7.50% 9.63% 10.22% 11.20% 10.70% 11.80% 12.50% +9.60% +11.80% 8.90% All New 9.50% Rel. Boost +5.94% +7.30% 8.02% 8.49% 9.80% 10.50% +6.90% 10.60% 11.50% +8.30% We observe that the relative improvements are consistently higher for this New Interest subset across all configurations. Moreover, incorporating Item Prior yields substantially more benefits compared to using only Temporal Prior (LT/ST). For example, HLLM with both LT/ST1 and Item Prior achieves remarkable relative boost of +15.76% for NDCG@10, compared to only +3.58% for LT/ST1 alone. This supports the intuition that when learning the different categories together, the user embedding will be biased against the minority items, while dedicating specific heads to the minority items allows us to retain the capacity and encouraging exploration toward novel categories. Case studies in Section B.1 further illustrate this insight. 4.4.3 Personalization Another common issue in recommender systems is popularity bias. In some cases, it means that the behaviors of some users, whose interests are different from the majority, might receive inferior recommendations. To address this issue, we instantiated User Prior on EB-NeRD, constructed similar to Graph Prior. But here, the nodes are the users in the co-engagement graph, and an edge exists between the two users if they interacted with the same item in the train set. To avoid popular items from making the graph too dense, for each item, we random sample maximum of 2000 users that have interacted with it before generating the edges. We then employ the Leiden algorithm Traag et al. (2018) with the modularity objective to cluster the graph into total of 9 user groups. We define User Prior by assigning an adapter to each group. Figure 2 User Prior leads to more personalized recommendations, especially on the minority user groups. 11 As shown in Figure 2, before introducing any prior, the minority groups with fewer users generally suffer from lower recommendation quality. However, by dedicating separate head to each user group, we effectively lower the impact of the majority users from dominating the query representation, which allows us to better personalize the recommendations for the minority users. This results in bigger improvements for groups with fewer users, and recommendation quality looks more balanced after User Prior is introduced."
        },
        {
            "title": "4.5 Scalability",
            "content": "Figure 3 Scaling by context lengths and sizes for HSTU. key trend in recommender systems is the use of longer context lengths to enhance personalization. While scaling laws typically require more training data to improve larger models, our experimental setup with fixed dataset introduces trade-off: increasing the context length reduces the number of available training windows. To investigate this, we test HSTU with longer context lengths and larger model sizes on Pixel8M. In Figure 3, the left subplot shows that for size 4 and 1b, the base model (LT/ST1, equivalent to the discounted loss) struggles to benefit from increasing context as we increase the context length beyond 20 items. However, in the right subplot, when guided by human priors, the same model architecture continues to extract performance gains from longer contexts and larger model sizes, although the magnitude of increase slowly plateaus. This finding suggests that the structural information imposed by human priors facilitates more efficient learning, allowing the model to better benefit from increasing context and larger model sizes when the amount of training data is fixed."
        },
        {
            "title": "4.6 Representation Space Visualization",
            "content": "Figure 4 Visualization of the representation space for particular user on Pixel8M. We plot item history, target items, and the top recommended items. The items recommended by different heads or interests are represented using different colors. Figure 4 presents UMAP visualization comparing the learned representation spaces for representative user across three models: the baseline HSTU (No Prior), our proposed method (w/ Item Prior), and REMI. 12 For each model, we project the embeddings of the users 50 past views, the 10 target items, and the top 50 recommended items. The UMAP is fit on the history and target embeddings. Since item embeddings are learned end-to-end with the models, the topology of the space differs for each model. For Item Prior and REMI, the recommended items are colored according to the head or interest that generates them. We observe that the recommendations of No Prior form single, concentrated cluster, failing to span the users diverse targets. In contrast, w/ Item Prior leverages its different heads to generate recommendations that cover the full spectrum of the target items. For REMI, we set the number of interest to two since it achieves the best performance. However, one interest (orange squares) dominates the recommendations in the bottom-left corner with fewer target items, while the second interest (light blue squares) only partially covers the primary target cluster in the upper-right corner. This suggests that leveraging existing human priors achieves more effective alignment between its diverse heads and the users multifaceted interests compared to learning the multiple interests as in REMI."
        },
        {
            "title": "4.7 Ablations",
            "content": "4.7.1 How to Structure the Priors? When multiple priors are available, the strategy used to compose them significantly impacts performance. We compare the three composition strategies: Additive, Multiplicative, and Hierarchical. Additive Composition learns the heads for each prior dimension independently. head specializes in single prior while remaining agnostic to others (e.g., category-specific head optimizes for that category regardless of the time horizon). Multiplicative Composition defines distinct head for every element in the Cartesian product of the priors. Each head is derived independently from hT using Eq. (2). We evaluate these strategies on Pixel8M, using both Item Prior and Temporal Prior. We apply these compositions on top of the HSTU backbone across five different model sizes to assess scalability and consistency. Figure 5 Comparison of composition strategies on Pixel8M across different HSTU model sizes. Figure 5 demonstrates that all three composition strategies outperform the baseline (no priors). Hierarchical Composition consistently achieves the best results across all model sizes. Although both Hierarchical and Multiplicative have similar parameter complexity, the Hierarchical structure provides superior performance. Specifically, Multiplicative treats the (A, B) head and the (A, C) head as completely independent entities, failing to leverage their shared context. This can lead to data fragmentation and poor generalization, especially for rare prior combinations. This highlights the effectiveness of structural regularization and the inductive bias imposed by sequential adapters (Eq. (5)). We observe similar trends with the HLLM backbone (Appendix Table 6). 4.7.2 Why it works: priors or just more heads? We answer two questions using Pixel8M while keeping the backbone and the number of heads fixed. First, do the gains come from human prior, or just because we benefit from more heads? We compare human priors to two variants: (i) Random - items are assigned to heads uniformly at random, and (ii) All - each item is assigned to all heads. 13 Second, how to fuse the scores from different heads for each item candidate at inference time? Let sh(i) be the score of item from head H(i) (the heads that are responsible for item i). We consider two fusion methods, average and maximum: Savg(i) = 1 H(i) (cid:88) sh(i), hH(i) Smax(i) = max hH(i) sh(i). We compare the results in Table 4. For Random, simply adding more heads without meaningful partitions only decreases the amount of data to train each head, causing it to underperform the baseline. On the other hand, All improves modestly over LT/ST1, showing that simply having more heads can indeed be beneficial, but it underperforms the human priors, LT/ST8 or Item. As for fusion, taking the average across heads might seem more natural, as commonly done in an ensemble. On the other hand, taking the maximum across heads might lead to overly optimistic estimates, similar to the issue of value overestimation in off-policy reinforcement learning Kumar et al. (2020). In fact, when we take the average on the random/all prior variant, or just using Temporal Prior, it does perform better than taking the max. However, we found that taking the max yields better results for Item Prior, in terms of both NDCG/recall and diversity. The reason might be each head evaluates whether the item candidate is good fit under different criteria (e.g., item category or action type), as are done in multi-interest networks Li et al. (2019); Cen et al. (2020), while heads in random/all or Temporal Prior evaluate on more similar criteria. As future work, we may consider aggregating the scores hierarchically according to the nature of the prior type, and using inverse variance weighting to upweight more certain heads. Table 4 Head assignment vs. fusion on Pixel8M. Baseline here is LT/ST1. Recall (%) NDCG (%) Entropy (H) Prior Fusion @10 @50 @ @50 @10 @50 Baseline 1.655 4. 1.726 2.977 2.303 2.461 Random All LT/ST8 Item Max Avg Max Avg Max Avg Max Avg 1.586 1.602 1.671 1. 1.878 1.950 1.749 1.738 4.377 4.417 4.559 4.560 5.251 5.338 4.695 4.663 1.648 1.670 1.741 1. 1.937 2.028 1.834 1.825 2.861 2.893 2.996 2.998 3.403 3.501 3.115 3.097 2.308 2.307 2.296 2. 2.296 2.303 2.371 2.335 2.462 2.463 2.457 2.460 2.455 2.457 2.515 2.489 4.7.3 Long-Term vs. Short-Term Interests We study the generalization ability of LT/ST interests by training with τ = 4, and evaluating on τ {1, 4, 8}  (Table 5)  . For brevity, we only report the average gain over the baseline (next target prediction) across the eight metrics, and leave the complete results to Table 6. All variants clearly surpass the baseline at τ = 4, and the benefit grows when we evaluate at τ = 8. On the other hand, when τ = 1, we only evaluate on the next one item as the target item, which is the same training objective as the baseline and only focuses on the short-term interest. Even under such setting, also modeling the long-term interest leads to only small drop in performance, which diminishes with more segments and disappears once we add the item prior. Finally, adding the item prior brings consistent benefit over the LT/ST prior alone, suggesting different human priors can be complementary. 14 Variant τ = 1 τ = 4 τ = LT/ST1 -3.07% 6.95% 7.72% LT/ST1 + Item -1.23% 7.95% 8.34% LT/ST2 -2.68% 5.74% 6.71% LT/ST2 + Item 0.25% 9.72% 10.36% LT/ST4 + Item 0.04% 8.58% 9.07% Table 5 Average gain over the baseline HLLM (w/o prior) across eight metrics. We train the model on τ = 4, and show its robustness when evaluated on τ = 1, 4, 8. Next, we show that the benefit of LT/ST interests is consistent across different model sizes of HSTU (Figure 6). Here, we train on τ = 8 using only the LT/ST prior. The baseline is only trained to predict the next one item, while LT/ST1 means that we only model one interest, and the objective reduces to the simple discounted loss over the next τ items. We see that explicitly assigning more different heads to model the long-term vs. short-term interests brings more improvements as we go from the baseline to seg = 2, and then the benefit from further increasing the number of segments slowly diminishes. We observe slight dip from size4 to 1b, and our hypothesis is that the number of target items used to train each head decreases when the number of interests increases. Nevertheless, the benefit of separately modeling the long-term and short-term interests is still significant at the scale of 1b, where the performance gain of the baseline model from increasing the model size has already flattens out at this scale. Table 6 HLLM results on Pixel8M with evaluation horizon τ = 8. With multiple human priors, enforcing hierarchical composition (Hier ) yields the best Recall (R@K) and NDCG (N@K) while maintaining diversity (H @K). multiplicative composition (Mult) maximizes but underperforms on Recall/NDCG as it lacks explicit structure. HLLM Variants No Prior LT/ST1 LT/ST1 + Item LT/ST2 LT/ST2 + Item (Mult) LT/ST2 + Item (Add) R@10 N@10 H@10 2.124 1.422 1.358 2.126 1.523 1.464 2.193 1.543 1.479 2.121 1.496 1.442 1.496 1.441 1.524 1.467 2.223 2.193 LT/ST2 + Item (Hier) 1.499 1.559 2. Figure 6 Sensitivity to the number of segments in Temporal Prior across different HSTU sizes. 4.7.4 Training Objective We conduct ablation studies on three key components of our training objective highlighted in Section 3.4: 1) in-group negative sampling, 2) frequency balancing, and 3) the temporal discount factor γ. The results are 15 summarized in Table 7. Table 7 Ablation studies on the training objective. We report Recall (R@10), NDCG (N@10), and Entropy (H@10). The best results within each section are highlighted in bold. Ablation Full Model (γ = 0.99) w/o in-group negative sampling w/o frequency balancing R@10 N@10 H@10 2.3728 2.6395 2.4234 2.000 2.099 1.700 1.642 2.005 1.928 Discount Factor γ γ = 1.0 γ = 0.95 γ = 0.9 γ = 0.8 γ = 0.7 γ = 0.6 γ = 0.5 2.000 2.033 2.045 2. 2.065 2.025 2.017 2.084 2.113 2.130 2.143 2.155 2.110 2.098 2.3773 2.3768 2.3727 2.3768 2.3773 2.3810 2.3818 First, removing in-group negative sampling (i.e., sampling negatives from all prior groups instead of the same group) and removing frequency balancing both lead to sharp decline in Recall and NDCG. Specifically, removing in-group sampling causes R@10 to drop significantly from 2.000 to 1.642. This validates the importance of these mechanisms for learning effective representations and handling data imbalance. The impact of the temporal discount factor γ is more nuanced. Both Recall and NDCG peak at γ = 0.7. Interestingly, the entropy initially decreases as γ decreases from 1.0 to 0.9, while Recall/NDCG increases. However, beyond γ = 0.9, the entropy instead increases alongside Recall/NDCG until they reach their peak at γ = 0.7. This observation is intriguing because it suggests that, even for the same architecture, higher accuracy (Recall/NDCG) does not necessarily imply lower diversity (Entropy). Furthermore, the optimal γ = 0.7 is notably different from the values typically used in reinforcement learning, which range from 0.9 to 0.995."
        },
        {
            "title": "5 Conclusion",
            "content": "By integrating human priors accumulated over post-hoc business rules directly into generative recommenders learning process, our proposed framework offers principled approach to aligning recommendations with multifaceted human objectives. Our experiments demonstrate that prior-conditioned adapter heads not only enhance accuracy, but also improve diversity, novelty, and personalization, which are key dimensions of user experience that are often overlooked. The frameworks backbone-agnostic design and hierarchical composition strategy further enable flexible modeling of complex user intent, making it broadly applicable across scenarios. While this work showcases the efficacy of using pre-defined priors, we view this as fundamental but not the final step. promising future direction is to establish formal methodology for what constitutes good prior, guiding the prior curation whether through human-in-the-loop or automated discovery of salient priors directly from data. Advancing the architectural fusion of these priors with more dynamic, context-aware mechanisms will also be critical. As the first attempt towards this goal, this work aims to strengthen the bridge between abstract human knowledge and the end-to-end optimization of large-scale generative recommenders."
        },
        {
            "title": "6 Acknowledgment",
            "content": "We would like to thank Zhuokai Zhao, Benyu Zhang, Lizhu Zhang, Xiangjun Fan, and Abhishek Kumar for their support."
        },
        {
            "title": "References",
            "content": "Gediminas Adomavicius and Alexander Tuzhilin. Toward the next generation of recommender systems: survey of the state-of-the-art and possible extensions. IEEE transactions on knowledge and data engineering, 17(6):734749, 2005. Greg M. Allenby, Peter E. Rossi, and Robert E. McCulloch. Hierarchical bayes models: practitioners guide. Econometrics eJournal, 2005. https://api.semanticscholar.org/CorpusID:13681821. Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, and Tri Dao. Medusa: Simple llm inference acceleration framework with multiple decoding heads, 2024. https://arxiv.org/abs/2401.10774. Yukuo Cen, Jianwei Zhang, Xu Zou, Chang Zhou, Hongxia Yang, and Jie Tang. Controllable multi-interest framework for recommendation. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, page 29422951. ACM, 2020. Junyi Chen, Lu Chi, Bingyue Peng, and Zehuan Yuan. Hllm: Enhancing sequential recommendations via hierarchical large language models for item and user modeling, 2024. https://arxiv.org/abs/2409.12740. Minmin Chen, Yuyan Wang, Can Xu, Ya Le, Mohit Sharma, Lee Richardson, Su-Lin Wu, and Ed Chi. Values of user exploration in recommender systems. In Proceedings of the 15th ACM Conference on Recommender Systems, RecSys 21, page 8595, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450384582. doi: 10.1145/3460231.3474236. https://doi.org/10.1145/3460231.3474236. Yu Cheng, Yunzhu Pan, Jiaqi Zhang, Yongxin Ni, Aixin Sun, and Fajie Yuan. An image dataset for benchmarking recommender systems with raw pixels. In SDM, pages 418426. SIAM, 2024. https://doi.org/10.1137/1.9781611978032.49. Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, and Lidong Bing. Is gpt-3 good data annotator? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1117311195, 2023. Stefan Elfwing, Eiji Uchibe, and Kenji Doya. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. Neural networks, 107:311, 2018. Zhiqiang Guo, Guohui Li, Jianjun Li, Chaoyang Wang, and Si Shi. DualVAE: Dual Disentangled Variational AutoEncoder for Recommendation, pages 571579. doi: 10.1137/1.9781611978032.66. https://epubs.siam.org/doi/ abs/10.1137/1.9781611978032.66. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web, pages 173182, 2017. Hidasi. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939, 2015. Wang-Cheng Kang and Julian McAuley. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM), pages 197206. IEEE, 2018. Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, and Jes Frellsen. Eb-nerd large-scale dataset for news recommendation. In Proceedings of the Recommender Systems Challenge 2024, RecSysChallenge 24, page 111, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400711275. doi: 10.1145/3687151.3687152. https: //doi.org/10.1145/3687151.3687152. Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine. Conservative q-learning for offline reinforcement learning. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS 20, Red Hook, NY, USA, 2020. Curran Associates Inc. ISBN 9781713829546. Chao Li, Zhiyuan Liu, Mengmeng Wu, Yuchi Xu, Huan Zhao, Pipei Huang, Guoliang Kang, Qiwei Chen, Wei Li, and Dik Lun Lee. Multi-interest network with dynamic routing for recommendation at tmall. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 19, page 26152623, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450369763. doi: 10.1145/3357384.3357814. https://doi.org/10.1145/3357384.3357814. Lichi Li, Zainul Abi Din, Zhen Tan, Sam London, Tianlong Chen, and Ajay Daptardar. Merrec: large-scale multipurpose mercari dataset for consumer-to-consumer recommendation systems. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1, KDD 25, page 23712382, New York, NY, USA, 2025. Association for Computing Machinery. ISBN 9798400712456. doi: 10.1145/3690624.3709394. https://doi.org/10.1145/3690624.3709394. Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. Learning disentangled representations for recommendation. Curran Associates Inc., Red Hook, NY, USA, 2019. Thomas M. McDonald, Lucas Maystre, Mounia Lalmas, Daniel Russo, and Kamil Ciosek. Impatient bandits: Optimizing recommendations for the long-term without delay. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 23, page 16871697, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701030. doi: 10.1145/3580305.3599386. https://doi.org/10.1145/3580305.3599386. Matthew E. Peters, Mark Neumann, Robert Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, and Noah A. Smith. Knowledge enhanced contextual word representations. In EMNLP, 2019. Tao Qi, Fangzhao Wu, Chuhan Wu, Peiru Yang, Yang Yu, Xing Xie, and Yongfeng Huang. HieRec: Hierarchical user interest modeling for personalized news recommendation. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 54465456, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.423. https://aclanthology.org/2021.acl-long.423/. Francesco Ricci, Lior Rokach, and Bracha Shapira. Recommender systems: Techniques, applications, and challenges. Recommender systems handbook, pages 135, 2021. Joshua David Robinson, Ching-Yao Chuang, Suvrit Sra, and Stefanie Jegelka. Contrastive learning with hard negative In International Conference on Learning Representations, 2021. https://openreview.net/forum?id= samples. CR1XOQ0UTh-. Alan Said, Maria Soledad Pera, and Michael D. Ekstrand. Were still doing it (all) wrong: Recommender systems, fifteen years later, 2025. https://arxiv.org/abs/2509.09414. Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web, pages 285295, 2001. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management, pages 14411450, 2019. Vincent Antonio Traag, Ludo Waltman, and Nees Jan van Eck. From louvain to leiden: guaranteeing well-connected communities. Scientific Reports, 9, 2018. https://api.semanticscholar.org/CorpusID:53041707. Yichao Wang, X. Zhang, Zhirong Liu, Zhenhua Dong, Xinhua Feng, Ruiming Tang, and Xiuqiang He. Personalized re-ranking for improving diversity in live recommender systems. ArXiv, abs/2004.06390, 2020. https://api. semanticscholar.org/CorpusID:215754155. Yihan Wu, Mingze Gao, Haoran Liu, Weiwei Li, Kevin Han, Junfeng Pan, Xinyi Zhang, Jiawei Wen, and Gedi Zhou. Gas: Large-scale heterogeneous personalization in social network applications at meta. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2, KDD 25, page 50495058, New York, NY, USA, 2025. Association for Computing Machinery. ISBN 9798400714542. doi: 10.1145/3711896.3737225. https://doi.org/10.1145/3711896.3737225. Yueqi Xie, Jingqi Gao, Peilin Zhou, Qichen Ye, Yining Hua, Jae Boum Kim, Fangzhao Wu, and Sunghun Kim. Rethinking multi-interest learning for candidate matching in recommender systems. In Proceedings of the 17th ACM Conference on Recommender Systems, RecSys 23, page 283293, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400702419. doi: 10.1145/3604915.3608766. https://doi.org/10.1145/3604915. 3608766. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. https://openreview.net/forum?id=5Xc1ecxO1h. Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li, Xuan Cao, Leon Gao, Zhaojie Gong, Fangda Gu, Michael He, Yinghai Lu, and Yu Shi. Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations, May 2024. http://arxiv.org/abs/2402.17152. arXiv:2402.17152 [cs]. Guorui Zhou, Jiaxin Deng, Jinghao Zhang, Kuo Cai, Lejian Ren, Qiang Luo, Qianqian Wang, Qigen Hu, Rui Huang, Shiyao Wang, Weifeng Ding, Wuchao Li, Xinchen Luo, Xingmei Wang, Zexuan Cheng, Zixing Zhang, Bin Zhang, Boxuan Wang, Chaoyi Ma, Chengru Song, Chenhui Wang, Di Wang, Dongxue Meng, Fan Yang, Fangyu Zhang, Feng Jiang, Fuxing Zhang, Gang Wang, Guowang Zhang, Han Li, Hengrui Hu, Hezheng Lin, Hongtao Cheng, Hongyang Cao, Huanjie Wang, Jiaming Huang, Jiapeng Chen, Jiaqiang Liu, Jinghui Jia, Kun Gai, Lantao Hu, Liang Zeng, Liao Yu, Qiang Wang, Qidong Zhou, Shengzhe Wang, Shihui He, Shuang Yang, Shujie Yang, Sui Huang, Tao Wu, Tiantian He, Tingting Gao, Wei Yuan, Xiao Liang, Xiaoxiao Xu, Xugang Liu, Yan Wang, Yi Wang, Yiwu Liu, Yue Song, Yufei Zhang, Yunfan Wu, Yunfeng Zhao, and Zhanyu Liu. Onerec technical report, 2025. https://arxiv.org/abs/2506.13695. Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization. In Proceedings of the 29th ACM international conference on information & knowledge management, pages 18931902, 2020."
        },
        {
            "title": "A Experiment Details",
            "content": "A.1 Dataset Details and Preprocessing Table 8 Statistics of the datasets after preprocessing. Filtering criteria vary slightly depending on the backbone model. Dataset Backbone # Users # Items # Interactions Pixel8M HSTU HLLM 561,737 2,220,506 398,261 404,182 MerRec Both 119,754 1,255,665 EB-NeRD Both 44,968 25, 57M 102M 521M 30M Pixel8M. For HSTU, we filter out users with fewer than 50 interactions. For HLLM, we filter out users with fewer than 20 interactions. Settings: For HSTU, we use context length (T ) of 50 and forecast horizon (τ ) of 8. For HLLM, we use = 10 and τ = 4 due to its higher computation cost. Modalities: Text inputs are title, tag, and description. Images are rescaled to 224 224 pixels. Item Prior Details: Over 5% of all items are labeled with the Miscellaneous tag, which appear to be unlabeled data that can randomly come from any of the other tags. We have to simply set all 8 binary features to be True for this tag. However, this also demonstrates the robustness of our method to noise in the human prior. The resulting normalized frequency distribution of the eight features is: Entertainment: 24.95%, Real life: 21.10%, Performance & Arts: 15.30%, Informational & Educational : 12.69%, Fictional character : 9.00%, Music: 6.29%, Gaming: 6.89%, and Science & technology: 3.77%. For example, the original tag Food Production is labeled with Real life, Informational & Educational, and Entertainment, while the original tag Celebrities Mix is labeled with Real life, Entertainment, Performance & Arts. MerRec. We select the user subset with over 2,000 interactions. Settings: For HSTU, we use context length of = 400, and for HLLM, we use = 50, both to predict one item ahead. Modalities: Text inputs are c2_name and brand_name. EB-NeRD. We select the 44,968 users with over 512 interactions. Settings: For HSTU, we use = 50, τ = 8. For HLLM, we use = 24, τ = 4. Modalities: Text inputs are title, subtitle, and topics. Graph Construction Details: For the co-engagement graph, we cap the contribution of highly active users by considering only their last 1000 interactions to prevent them from dominating the graph structure. When running the Leiden algorithm Traag et al. (2018) (implemented via the igraph package), we use modularity as the optimization objective and tune the resolution parameter based on the desired number of clusters. Small clusters falling below size threshold are merged into single larger cluster. A.2 Model Architectures and Hyperparameters For both HSTU and HLLM backbones, we use discount factor γ = 0.99. However, we observed that smaller γ might lead to higher accuracy at the cost of lower diversity  (Table 7)  . HLLM Configurations. The choice of LLMs for HLLM depends on the available modalities in the dataset. For Pixel8M, which contains both text and images, we use Qwen2-VL-2B-Instruct as the Item LLM and Qwen2.51.5B as the User LLM. For MerRec and EB-NeRD, which only contain text, we use TinyLlama-1.1B-Chat-v1.0 as the Item LLM and TinyLlama_v1.1 as the User LLM. HSTU Configurations. We experiment with various sizes5 of the HSTU model, detailed in Table 9. For all datasets, we remap product IDs based on the ones that still have been interacted with after filtering. We report the results based on size 3 unless noted. Figure 7 An instantiation of the hierarchical composition strategy with Temporal (LT/ST2) and Graph Priors. Specific Instantiation. We illustrate concrete instantiation of our hierarchical framework (Section 3.3) using both Temporal and Graph Priors, corresponding to the configuration used on the EB-NeRD dataset (Figure 7). For visualization, we assume two graph clusters, C1 (green) and C2 (purple). In this example, the forecast horizon (τ = 6) is divided into two equal segments (LT/ST2), where ST (short-term) is responsible for the first three targets and LT (long-term) is responsible for the last three targets. In the first layer (depth 1), the adapters specialize based on the temporal segments. The adapter A(1) ST trained using only ground-truth items falling within the ST segment, while A(1) LT LT segment. They output the intermediate representations z(1) ST In the second layer (depth 2), the specialization is further refined based on Graph Prior. For example, the adapter A(2) is optimized specifically for predicting items that belong to cluster C1 (green) and the ST ST,C1 segment. Similarly, A(2) targets C2 (purple) items in the LT segment. In other words, each leaf head is responsible only for the intersection of its associated priors. is is trained using items in the , respectively. and z(1) LT ST,C2 Crucially, the backbone encoder processes the entire context sequence, regardless of the items cluster. The specialization occurs only in the adapter heads. During training, we use in-group negative sampling (Section 3.4). For the graph prior heads, negatives are sampled from the respective clusters compatible set (e.g., ΩC1 ). The heads for Temporal Prior are compatible with all items, as any item can occur in any temporal segment. Instead, Temporal Prior restricts the training signal based on the items position in the forecast horizon. for A(2) ,C1 5For the 1B model, we use the same hyperparameters as TinyLlama as in the original HLLM paper. However, the total number of parameters is less than 1B due to the simplification of the feed-forward block in HSTU. 21 num_layers num_heads d_model dropout Size 1 Size 2 Size Size 4 4 4 128 0.1 8 8 256 0.1 12 8 512 0.2 16 16 1024 0.2 1B 22 32 2048 0.4 Total Params 12.4 26.8 64.3 181.6 658.9 Table 9 The list of hyperparameters in the five model sizes of HSTU, along with the total parameter counts. Baseline Configurations. For ComiRec and REMI, we use the self-attention version, which demonstrates performance comparable to the dynamic routing version, but with stabler and faster training. We use learning rate of 0.001, search the number of interest from {1, 2, 4, 8, 16, 32}, and report the best performance. For REMI, we tune the additional β parameter for interest-aware hard negative mining from {0.1, 1, 4, 10} and set routing regularization weight λ to 100 following the original paper. For DualVAE, we reimplement it under the window-wise sequential recommendation setting. We search the aspect number from {4, 5, 10} and set the VAE latent dimension to 32. We search dropout from {0.1, 0.15, 0.2}, γ (for contrastive loss) and β (for KL-divergence) from {1e 3, 1e 2, 1e 1, 1}."
        },
        {
            "title": "B Additional Results",
            "content": "B.1 Case Studies To illustrate the qualitative benefits of human priors, we present case study in Figure 8 using the Pixel8M dataset. We analyze the predictions of the HLLM backbone, which leverages both text and image modalities6, configured with LT/ST2 and Item Prior, and we compare it against the baseline HLLM. The user history (top two rows) does not contain videos related to Informational & Educational, but they indicate latent user interest in military and geopolitics, since they include clips from the WWII movie Downfall, game on evolution under nuclear waste, and meme on atomic egg explosion. The baseline HLLM (fourth row) struggles to synthesize this nuanced intent. Even after filtered to the Informational & Educational category, it produces relatively generic recommendations. In contrast, our proposed model demonstrates effective specialization (last row). The adapter head dedicated to the LongTerm interest within the Informational & Educational prior successfully captures the users latent interest, resulting in recommendations such as the revival of the Soviet Union and Russian territorial waters. The better recommendation quality is validated by the target items (third row). Starting from the second target item, the user engaged with content related to the Soviet Union, which was successfully predicted by our model, and the Second Sino-Japanese War. This shows that dedicating specialized head to model underrepresented categories is effective at discovering the users hidden interests, which the baseline overlooked. 6Video descriptions are omitted in Figure 8 due to space constraints. 22 Figure 8 case study on Pixel8M. Top two rows: browsing history. Third row: ground truth target items. Fourth row: HLLM baseline predictions (filtered to Informational & Educational). Last row: predictions from our models long-term Informational & Educational head."
        }
    ],
    "affiliations": [
        "BAIR (UC Berkeley)",
        "Meta AI",
        "UC Santa Cruz"
    ]
}