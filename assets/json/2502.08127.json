{
    "paper_title": "Fino1: On the Transferability of Reasoning Enhanced LLMs to Finance",
    "authors": [
        "Lingfei Qian",
        "Weipeng Zhou",
        "Yan Wang",
        "Xueqing Peng",
        "Jimin Huang",
        "Qianqian Xie"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent advancements in large language models (LLMs) have shown strong general reasoning abilities, yet their effectiveness in financial reasoning remains underexplored. In this study, we comprehensively evaluate 16 powerful reasoning and general LLMs on three complex financial tasks involving financial text, tabular data, and equations, assessing numerical reasoning, tabular interpretation, financial terminology comprehension, long-context processing, and equation-based problem solving. Our results show that while better datasets and pretraining improve financial reasoning, general enhancements like CoT fine-tuning do not always yield consistent gains. Moreover, all reasoning strategies face challenges in improving performance on long-context and multi-table tasks. To address these limitations, we develop a financial reasoning-enhanced model based on Llama-3.1-8B-Instruct, by CoT fine-tuning and reinforcement learning with domain-specific reasoning paths. Even with simple fine-tuning with one financial dataset, our model achieves a consistent 10% performance improvement across tasks, surpassing all 8B models and even Llama3-70B-Instruct and Llama3.1-70B-Instruct on average. Our results highlight the need for domain-specific adaptations in financial tasks, emphasizing future directions such as multi-table reasoning, long-context processing, and financial terminology comprehension. All our datasets, models, and codes are publicly available. Furthermore, we introduce a leaderboard for benchmarking future datasets and models."
        },
        {
            "title": "Start",
            "content": "Fino1: On the Transferability of Reasoning-Enhanced LLMs to Finance Lingfei Qian TheFinAI lfqian94@gmail.com Weipeng Zhou TheFinAI tracyzhoeipng@gmail.com Yan Wang TheFinAI wy2266336@gmail.com Xueqing Peng TheFinAI xueqing.peng2024@gmail.com Jimin Huang TheFinAI jimin.huang@thefin.ai Qianqian Xie TheFinAI xqq.sincere@gmail.com"
        },
        {
            "title": "Abstract",
            "content": "Recent advancements in large language models (LLMs) have shown strong general reasoning abilities, yet their effectiveness in financial reasoning remains underexplored. In this study, we comprehensively evaluate 16 powerful reasoning and general LLMs on three complex financial tasks involving financial text, tabular data, and equations, assessing numerical reasoning, tabular interpretation, financial terminology comprehension, long-context processing, and equation-based problem solving. Our results show that while better datasets and pretraining improve financial reasoning, general enhancements like CoT fine-tuning do not always yield consistent gains. Moreover, all reasoning strategies face challenges in improving performance on long-context and multi-table tasks. To address these limitations, we develop financial reasoning-enhanced model based on Llama-3.1-8B-Instruct, by CoT fine-tuning and reinforcement learning with domain-specific reasoning paths. Even with simple fine-tuning with one financial dataset, our model achieves consistent 10% performance improvement across tasks, surpassing all 8B models and even Llama3-70B-Instruct and Llama3.1-70BInstruct on average. Our results highlight the need for domain-specific adaptations in financial tasks, emphasizing future directions such as multi-table reasoning, long-context processing, and financial terminology comprehension. All our datasets, models1, and codes2 are publicly available. Furthermore, we introduce leaderboard for benchmarking future datasets and models3."
        },
        {
            "title": "Introduction",
            "content": "Advancements in large language models (LLMs) have demonstrated remarkable performance across Corresponding author 1https://huggingface.co/TheFinAI 2https://github.com/The-FinAI/Fino1 3https://huggingface.co/spaces/TheFinAI/ open-finllm-reasoning-leaderboard various natural language pocessing tasks, including content generation(Van Veen et al., 2024; Zhang et al., 2024), language translation (Xu et al., 2024), and sentiment analysis (Xing, 2024; Miah et al., 2024). More recently, reasoning-enhanced models such as OpenAIs o1 and DeepSeeks R1 have been developed to extend LLM capabilities in complex reasoning (Guo et al., 2025; Jaech et al., 2024). These models exhibit significant improvements, particularly in mathematical and logical tasks that require complex reasoning (Temsah et al., 2024; Zhong et al., 2024). However, despite their success in general reasoning, their performance in the financial domain remains largely unexplored. Financial tasks inherently demand rigorous reasoning, requiring not only numerical computations but also deep contextual understanding of financial terminology, regulations, and economic principles (Xie et al., 2023, 2024a). Unlike general reasoning tasks, financial reasoning necessitates (1) comprehension of domain-specific terminology, (2) the ability to establish and manipulate relationships between financial concepts and numbers to derive accurate conclusions, and (3) an understanding of the structure and content of financial tables (Xie et al., 2024b). Given the specialized nature of financial decision-making, assessing the reasoning capabilities of LLMs in this domain is crucial for bridging the gap between general AI reasoning and financial applications. Effective financial reasoning requires models to integrate textual, numerical, and structured data, highlighting the need for domainspecific adaptations to enhance AI-driven financial analysis. In this study, we aim to comprehensively evaluate the performance of existing powerful reasoning models and conduct an in-depth analysis of their capabilities in financial tasks. Through this evaluation, we aim to provide insights into the strengths and limitations of existing reasoning models in financial applications, informing future ad5 2 0 2 2 1 ] . [ 1 7 2 1 8 0 . 2 0 5 2 : r vancements in financial AI research. We focus on the following key aspects: (1) Transferability of general-domain reasoning enhancements Assessing whether reasoning-enhanced LLMs, originally optimized for general-domain reasoning, also demonstrate improved performance in financial reasoning tasks. (2) Impact across financial tasks Analyzing how the reasoning enhancement process influences LLM performance across different types of financial tasks. (3) Scaling and performance gap Investigating the differences between smaller reasoning models and large-scale LLMs in financial reasoning. (4) Limits of LLMs in complex financial tasks Evaluating the extent to which LLMs can handle extremely complex financial reasoning challenges. We evaluated the performances of 16 large language models from the GPT (Achiam et al., 2023), LLaMA (Dubey et al., 2024), DeepSeek (Liu et al., 2024), and Qwen (Yang et al., 2024) families on three financial datasets, FinQA (Chen et al., 2021), DM-Simplong (Zhao et al., 2024), and XBRLMath (Wang et al., 2025), which incorporate financial text, tabular data, and equations as inputs. Our selection includes both general purpose and reasoning-enhanced models, such as DeepSeek-V3 (Liu et al., 2024) and DeepSeek-R1 (Guo et al., 2025), spanning from smaller models like LLaMA 3-8B-Instruct (Dubey et al., 2024) to high-capacity models like GPT-o1 (Jaech et al., 2024), ensuring comprehensive assessment across different computational scales. These three financial reasoning datasets are designed to evaluate distinct aspects of financial understanding. Collectively, they assess models abilities in numerical reasoning, tabular data interpretation, financial terminology comprehension, long-context processing, and equation-based problem solving. Through this evaluation, our objective is to examine the capacity of LLMs to process financial concepts, reason over structured and unstructured financial data, and perform complex mathematical operations, offering deeper insight into their strengths and limitations in financial analysis tasks. From experimental results and analysis, we have the following findings: (1) General reasoning enhancement strategies, such as those employed in DeepSeek-R1 and GPTo1, do not consistently improve performance in financial domain tasks. In fact, these models exhibit performance decline compared to generalpurpose models like DeepSeek-V3 and GPT-4o, suggesting challenges in understanding financial terminology and reasoning over long contexts and multi-table data. (2) While improvements in pretraining methods and increased training data in general domains, as well as increasing model size all contributes to performance gains.For financial tasks, model performance tends to plateau at an upper boundary. Specifically, after reaching 70B or even 32B parameters, financial reasoning tasks show no significant improvement. (3) The performance of different reasoning enhancement strategies in financial tasks can vary significantly. For instance, general-domain techniques like Chain-of-Thought and reflection-tuning in GPT-o1, designed for math and code, show no improvements in financial reasoning. In contrast, results show that DeepSeek and Qwen-Math incorporate enhance formula computations and structured data parsing using tool-integrated reasoning (TIR) and the process reward model (PRM), and knowledge distilled from general-purpose models. While these methods improve numerical accuracy in financial reports and market data, their impact on financial terminology comprehension, long-context modeling, and multi-table inference remains limited. Based on the evaluation results, we developed reasoning-enhanced language model specifically designed for financial tasks. We selected Llama3.1-8B-Instruct (Dubey et al., 2024) as the backbone model due to its superior performance among small-scale LLMs. To enhance its reasoning capabilities, we employed Chain-of-Thought (CoT) fine-tuning and reinforcement learning (RL), inspired by the four backtracking strategies from HuatuoGPT-o1 (Chen et al., 2024) and the FinQA training dataset. To construct effective reasoning paths for fine-tuning, we leveraged GPT-4o, the best-performing closed-source model, as it achieved comparable results across all datasets. Experimental results indicate that even simple finetuning approach using the reasoning paths from single financial dataset, FinQA, led to significant performance improvements across multiple datasets. In some cases, our models performance approached that of advanced closed-source reasoning models, such as GPT-o3-mini and GPT-o1. These results demonstrate that reasoning enhancement tailored to financial domain tasks and datasets can significantly boost model performance in financial applications. In contrast, reasoning enhancement in general-domain tasks does not yield effective or consistent improvements for financial tasks, highlighting the necessity of domain-specific fine-tuning for optimal results. To the best of our knowledge, we are the first to systematically explore the reasoning capabilities of enhanced LLMs in factual reasoning tasks across various financial inputs, including financial reports, tables, equations, and structured XBRL texts. Additionally, we investigate the effectiveness of reasoning enhancement strategies using financial data in adapting general-domain models for financial tasks. Overall, our results show that reasoning enhancement strategies designed for general domains do not consistently yield stable and effective improvements in financial reasoning tasks, whereas reasoning enhancement with financial data leads to significant performance gains. Furthermore, we highlight several key directions for advancing reasoning-enhanced LLMs in the financial domain, including enhancing models understanding of financial knowledge and terminology, improving their ability to handle multi-table reasoning and long financial contexts, and developing well-designed and diverse reasoning enhancement strategies to improve LLM performance in financial reasoning tasks. soning capabilities of LLMs, with primary focus on long contexts consisit of specialized documents and tables. In particular, the simpllong subset is specifically designed to evaluate LLMs numerical reasoning abilities over long financial or specialized documents that contain multiple and multi-tiered tables. It challenges models to extract relevant information from extended contexts and perform reasoning across complex tabular structures. (3) XBRL-Math (Wang et al., 2025): This dataset is designed to evaluate the numerical reasoning capabilities of LLMs in the context of XBRL (eXtensible Business Reporting Language) filings. Different from regular financial reports, XBRL files are well structured that encode financial data using standardized taxonomies, ensuring consistency and interoperability across regulatory filings. It contains structured financial documents with US GAAP XBRL tags, equations, and multi-tiered numerical relationships. This dataset challenges models to extract, interpret, and reason across interconnected financial terms and formulas, such as APR = ((Fees + Interest) / Principal) (365 / Days in Loan Term). Understanding XBRL taxonomy, hierarchical disclosures, and numerical dependencies is essential for accurate financial data analysis, making this dataset benchmark for evaluating LLMs ability to handle complex financial reasoning tasks."
        },
        {
            "title": "2 Methods",
            "content": "2.1 Datasets Dataset FinQA Size 1100 Tables and Texts DM-Simplong 100 Tables and Texts XBRL-Math 90 Texts and Equations Data Types Average Token 1,128 4,330 To evaluate the overall capabilities of existing reasoning-oriented and general LLMs in handling financial reasoning tasks, we select three tasks with different attributes: (1) FINQA (Chen et al., 2021): FinQA is largescale dataset designed to facilitate research in numerical reasoning within the financial domain. It consists of expert-annotated question-answer pairs and is distinctive in its focus on complex numerical reasoning, requiring the integration of both structured data (such as tables) and unstructured data (such as textual descriptions) found within financial reports. The dataset contains vast number of financial terms, posing challenge for models to understand domain-specific terminology and extract relevant information accurately. (2) DocMath (simplong) (Zhao et al., 2024): The DocMath-Eval dataset is comprehensive benchmark designed to evaluate the numerical reaTable 1: Overview of the datasets used in the study. More details of the datasets are listed in Table 1. By conducting experiments on these three datasets, we aim to evaluate the models ability in various aspects, including understanding financial terms, extracting relevant numbers and entities from financial reports from different sources, and reasoning over long contexts and multiple tables. 2.2 Evaluated Models To conduct comprehensive evaluation of existing LLMs, we select models from the GPT, LLaMA, DeepSeek, and Qwen families, which have demonstrated effectiveness in various natural language processing tasks. Our selection includes models of different scales, ranging from small-sized models (8B) to large models (70B), as well as even larger ones like DeepSeek-R1 (approximately 700B). Additionally, we incorporate the most advanced closed-source models, such as GPT-4o and GPT-o1. Finally, all the models we use are listed following: (1) GPT-4o (Hurst et al., 2024): OpenAIs latest flagship model, featuring multimodal capabilities, improved efficiency, and real-time reasoning across text, image, and audio modalities. (2) GPT-o1 (Jaech et al., 2024): highly optimized variant within OpenAIs GPT series, designed for enhanced reasoning and problem-solving with strong step-by-step thought processes. (3) GPTo3-mini: compact version of the o3 model, optimized for efficiency while maintaining robust language processing abilities. (4) DeepSeek-V3 (Liu et al., 2024): DeepSeeks Mixture-of-Experts (MoE) model with 671 billion parameters, activating 37 billion per token for efficient reasoning tasks. (5) DeepSeek-R1 (Guo et al., 2025): DeepSeeks first-generation reasoning model, achieving performance comparable to OpenAIs o1 across math, code, and reasoning tasks. (6) Qwen2.5-72BInstruct (Yang et al., 2024): Alibabas open-source model demonstrating superior performance in Chinese and English tasks with advanced instruction tuning. (7) Qwen2.5-72B-Instruct-Math (Yang et al., 2024): specialized variant fine-tuned for mathematical reasoning, achieving strong results in complex problem-solving tasks. (8) Llama-series Models (Dubey et al., 2024): This is the most widely adopted open-source large language model family, setting industry benchmarks for accessibility, efficiency, and performance. These models are trained on extensive datasets incorporating diverse multilingual and domain-specific data, leveraging high-quality pretraining and instruction tuning methodologies. In our experiments, we mainly focus on instruction finetune versions of these models ranging from 8B to 70B. (8) DeepSeek-R1Distill Models (Guo et al., 2025): This series of models is supervised fine-tuned on data distilled from DeepSeek-R1, leveraging its reasoning capabilities, with backbone models selected from Llama3.3-70B-Instruct, Qwen 2.5-32B, Qwen 2.514B, and Llama3.1-8B to balance efficiency and performance in instruction-following tasks. 2.3 Evaluation Settings In each dataset, the LLMs are presented with context consisting of financial reports, financial tables, equations, and mathematical symbols, along with question. Insired by previous work (Zhao et al., 2024), generic prompt is used to instruct the model to answer the question based on the provided context. The models are required to extract relevant information and perform mathematical computations using numbers and concepts derived from the context. This necessitates strong logical reasoning abilities within financial contexts. The results are typically presented in mathematical format, but due to variations in numerical representationsuch as percentages and different rounding strategiesthe final outputs can differ. Furthermore, reasoning-focused models, such as DeepSeek-R1 and GPT-o1, tend to provide stepby-step reasoning process before arriving at the final answer. Inspired by DocMath, we employ an LLM-as-judge approach to evaluate model performance. First, an LLM (GPT-3.5-Turbo) is used to extract the final answer from the models output. Then, mathematical comparison method is applied to determine whether the result is correct. large models like DeepSeek-V3 and DeepSeek-R1, or closed-source models like the GPT series, we conduct our experiments using APIs provided by togetherAI4 and OpenAI5. Specifically, we utilize GPT-o1-2024-12-17, GPTo3-mini-2025-01-31, and GPT-4o-2024-08-06 for our evaluations. For other models with 72B parameters or fewer, we generate results using the VLLM framework on 4 A100 GPUs (80GB memory per GPU), with maximum generation length of 512 tokens. For 2.4 Fino1: LLMs for Financial Reasoning To gain deeper insight into how domain-specific reasoning enhancement benefits financial tasks compared to general reasoning enhancement, we developed Fino1, reasoning-enhanced LLM specifically designed for financial tasks. WTo enhance the domain-specific reasoning abilities of LLMs, we first construct high-quality training data with domain-specific reasoning paths based on the FinQA dataset. FinQA consists of over 5,000 open-ended question-answer pairs derived from financial reports and tables. This comprehensive dataset integrates both textual and tabular financial data, presenting moderate level of difficulty, making it well-suited for training reasoningbased models. For reasoning path generation, we utilize GPT4https://www.together.ai 5https://platform.openai.com Model Name GPT-4o GPT-o1 GPT-o3-mini DeepSeek-V3 DeepSeek-R1 Qwen2.5-72B-Instruct Qwen2.5-72B-Instruct-Math DeepSeek-R1-Distill-Llama-70B Llama3-70B-Instruct Llama3.1-70B-Instruct Llama3.3-70B-Instruct DeepSeek-R1-Distill-Qwen-32B DeepSeek-R1-Distill-Qwen-14B DeepSeek-R1-Distill-Llama-8B Llama3-8B-Instruct Llama3.1-8B-Instruct Parameters Reasoning Enhanced Unknown Unknown Unknown 671B 671B 72B 72B 70B 70B 70B 70B 32B 14B 8B 8B 8B No Yes Yes No Yes No Yes Yes No No No Yes Yes Yes No No Context Window Size 128k 128k 128k 128k 128k 128k 128k 128k 8k 128k 128k 128k 128k 128k 8k 128k Close/Open Source Reasoning Enhanced Training Data Closed Closed Closed Open Open Open Open Open Open Open Open Open Open Open Open Open - Public and properity data (Human-annotated CoT, MCTS-assisted Synthetic data) Public and properity data - Cold-start data generation, post-processing data - Synthetic data from Qwen, high-quality mathematical data, CoT, TIR Distilled from R1 - - - Distilled from R1 Distilled from R1 Distilled from R1 - - Table 2: Summary of evaluated large language models, including their parameter sizes, reasoning capabilities, input limits, source availability, and reasoning enhancement strategies. MCTS refers to Monte Carlo Tree Search. CoT refers to chain-of-thought reasoning. TIR means tool-integrated reasoning. 4o, as it demonstrates consistently strong performance across multiple datasets (as reported in Table 3), achieving results comparable to the highest-performing models on FinQA. Followed by HuatuoGPT-o1 (Chen et al., 2024), we adopt similar strategy to refine the CoT reasoning paths generated by GPT-4o. The refinement process involves the use of verifier to assess the correctness of the generated CoT. If the verifier rejects the reasoning path, the model iteratively refines it by applying strategy sampled from one of the following: (1) Backtracking Revisiting previous steps to correct logical inconsistencies. (2) Exploring New Paths Generating alternative reasoning routes when the current path fails. (3) Verification Cross-checking intermediate steps to ensure logical soundness. (4) Correction Making targeted adjustments to rectify errors. The CoT refinement process begins with an initial prompt to generate reasoning path and an answer. The verifier then evaluates the response. If the answer is incorrect, one of the above strategies is applied iteratively to refine the CoT process until correct and logically sound answer is generated. 2.4.1 Mode Training After curating the reasoning data, we fine-tune Llama3.1-8B-Instruct, selected as the optimal backbone model based on the performance of 8B models. First, the curated dataset is used for supervised fine-tuning (SFT), where the question serves as input, and the reasoning path along with the final answer serves as output, enabling the model to learn structured financial reasoning. Next, we apply reinforcement learning with reward model trained to assess the quality of generated reasoning paths. Inspired by prior work, we employ verifier-based sparse reward mechanism and optimize the model using Proximal Policy Optimization (PPO). The verifier evaluates the correctness and coherence of the reasoning path; if an error is detected, the model iteratively refines the reasoning steps through backtracking, exploring alternative paths, verification, and correction. This two-stage approach enhances logical consistency, financial reasoning depth, and equation-solving accuracy, ultimately improving model performance across financial benchmarks. During the SFT phase, the model was trained with learning rate of 5e-6 for three epochs, using maximum sequence length of 8192 tokens. LoRA (Low-Rank Adaptation) was applied to update parameters efficiently, reducing computational costs while maintaining performance. In the subsequent RL stage, the learning rate was lowered to 5e-7, and the model was trained for an additional three epochs. The reward model, previously trained in (Chen et al., 2024), was employed to evaluate the quality of the models reasoning paths. This reward signal guided optimization through Proximal Policy Optimization (PPO), refining the models ability to generate accurate and coherent financial reasoning."
        },
        {
            "title": "3 Results",
            "content": "3.1 Overall Results Analysis The resutls of all these models on three dataset are listed in Table 3. Among all models, DeepSeek-R1 achieves the highest overall performance (68.93), driven by its strong XBRL-Math results, with its distilled variants, DeepSeek-R1-Distill-Llama-70B and DeepSeek-R1-Distill-Qwen-32B, closely following. Among large-scale models, GPT-4o performs well across datasets but is outperformed by DeepSeek-R1 due to its lower XBRL-Math score. General-purpose 70B models, such as Qwen2.572B-Instruct and Llama3.3-70B-Instruct, achieve strong results, with Llama3.3-70B showing significant improvement over its predecessors. Surprisingly, these models also surpass the reasoningfocused GPT-o1 and approach GPT-o3-mini, suggesting that general-purpose reasoning strategies do not always translate effectively to financial tasks. In the 8B category, Fino1-8B (61.03) outperforms other models, demonstrating robust task optimization. Notably, reasoning-enhanced models exhibit mixed results: while they improve XBRL-Math scores, they tend to perform worse on FinQA and DM-Simplong. This suggests that different reasoning strategies yield varying benefits across financial reasoning tasks, emphasizing the importance of task-specific optimization. From our results, we identify several key insights regarding the performance of large language models (LLMs) in financial reasoning tasks: (1) General reasoning enhancements do not necessarily translate to improvements in financial tasks. While models fine-tuned for general reasoning, such as GPT-o1 and DeepSeek-R1, demonstrate strong performance in mathematical and logical reasoning tasks, they do not consistently outperform other models in financial benchmarks. For example, GPT-o1 scores 49.07 in FinQA and 56.0 in DM-Simplong, trailing behind models like GPT4o that are not explicitly optimized for general reasoning. Also, DeepSeek-R1 also under performan V3 in these tasks. This suggests that financial reasoning requires more than just enhanced logical and mathematical capabilities; it demands deep understanding of domain-specific terminology, structured financial statements, and numerical patterns. One possible explanation for this phenomenon is that reasoning-focused fine-tuning, which emphasizes general problem-solving strategies, may inadvertently weaken models retention of financial knowledge. This is particularly relevant for tasks requiring precise comprehension of financial terms, balance sheet structures, and industry-specific metrics, where models without targeted financial fine-tuning may struggle. Additionally, reasoning-enhanced models might prioritize general logical inference over domain-specific factual recall, which could lead to decrease in performance when interpreting specialized financial contexts. These findings indicate that while general reasoning improvements enhance broad problemsolving skills, they do not necessarily translate into domain-specific advantages, highlighting the need for specialized financial training in LLMs. (2) Different reasoning enhancement strategies yield varying improvements depending on the financial reasoning task format. By comparing the performance of GPT-4o vs. GPT-o1, Qwen2.5-72B-Instruct vs. Qwen2.5-72B-InstructMath, and Llama models vs. the DeepSeek-R1 distilled Llama models, we observe that reasoningenhanced models do not always improve financial task performance. GPT-o1 underperforms GPT-4o in FinQA (49.07 vs. 72.49) and DM-Simplong (56.00 vs. 60.00), suggesting that its reasoning strategies, such as chain of thought and reflectiontuning, are optimized for general problem-solving rather than financial-specific logic. Similarly, Qwen2.5-72B-Instruct-Math, despite achieving substantial XBRL-Math boost (67.78 83.33), experiences sharp declines in FinQA (69.74 42.00) and DM-Simplong (59.00 42.00), indicating that mathematical reasoning enhancements help structured financial data but do not generalize well to broader financial tasks. In the 8B category, DeepSeek-R1-Distill-Llama-8B (53.36) outperforms Llama3.1-8B-Instruct (50.12) and Llama3-8B-Instruct (39.95), excelling in XBRLMath (81.11) but showing limited improvements in other financial tasks. These results suggest that different reasoning strategies target distinct aspects of financial reasoning. DeepSeek-R1 and Qwen2.5-72B-InstructMath demonstrate strong performance in symbolic and mathematical reasoning, excelling in structured equation-based tasks. However, they do not generalize well to financial question-answering tasks like FinQA and DM-Simplong. Similarly, reasoning augmentations in GPT-o1 fail to provide consistent improvements, likely due to the absence of relevant financial reasoning data, highlighting the challenge Models FinQA DM-Simplong XBRL-Math Average GPT-4o GPT-o1 GPT-o3-mini DeepSeek-V3 DeepSeek-R1 Qwen2.5-72B-Instruct Qwen2.5-72B-Instruct-Math DeepSeek-R1-Distill-Llama-70B Llama3-70B-Instruct Llama3.1-70B-Instruct Llama3.3-70B-Instruct DeepSeek-R1-Distill-Qwen-32B DeepSeek-R1-Distill-Qwen-14B DeepSeek-R1-Distill-Llama-8B Llama3-8B-Instruct Llama3.1-8B-Instruct Fino1-8B 72.49 49.07 60.87 73.20 65.13 73.38 69.74 66.73 58.92 63.18 68.15 65.48 63.27 45.96 41.97 54.13 60.87 60.00 56.00 59.00 53.00 53.00 59.00 42.00 53.00 41.00 48.00 54.00 55.00 44.00 33.00 29.00 34.00 40. 72.22 74.44 76.67 76.67 86.67 67.78 83.33 86.67 56.67 63.33 70.00 84.44 84.44 81.11 48.89 62.22 82.22 68.24 59.84 65.51 67.62 68.93 66.72 65.69 68.80 52.20 58.17 64.05 68.97 63.90 53.36 39.95 50.12 61.03 Table 3: Performance of different LLMs on three tested financial datasets. of adapting broad reasoning techniques to financial logic. (3) Scaling model size does not always lead to performance gains in financial tasks. While larger models typically achieve better results in standard NLP tasks, their performance in financial tasks does not always scale proportionally with size. For instance, DeepSeek-70B (66.73 in FinQA, 53 in DM-Simplong, and 86.67 in XBRL-Math) performs similarly to its smaller distilled variant DeepSeek-R1-Distill-Qwen-32B (65.48, 55, 84.44), despite the latter having less than half the parameters. broader comparison, including Qwen2.5-72B-Instruct, DeepSeek-R1Distill-Llama-70B, GPT-4o, DeepSeek-V3, and DeepSeek-R1, reveals that performance stabilizes once model size reaches approximately 70B parameters. One possible explanation for this trend is the nature of XBRL-Math, which consists of structured financial tables and numerical equations that prioritize precise mathematical computations over complex language-based reasoning. In such structured, numerically driven tasks, smaller models can achieve competitive performance by leveraging arithmetic operations and pattern recognition rather than advanced language modeling. This suggests that the advantage of larger models diminishes in financial decision-making tasks where structured data comprehension and numerical reasoning play more crucial role than language-based inference. (4) Improving Pre-training Data and Strategies in General Domains Also Benefits Financial Tasks. Compared with Llama 3-8B-Instruct, Llama 3.1-8B-Instruct demonstrates significant performance boost, increasing its average score from 39.95 to 50.12, with substantial improvements in XBRL-Math (62.22 vs. 48.89) and FinQA (54.13 vs. 41.97). Similarly, among the 70B-Instruct models, Llama 3.1-70B-Instruct outperforms Llama 370B-Instruct (58.17 vs. 52.20), with the largest improvement in DM-Simplong (48.00 vs. 41.00), while Llama 3.3-70B-Instruct achieves the highest overall performance (64.05 vs. 58.17), excelling in FinQA (68.15 vs. 63.18) and XBRL-Math (70.00 vs. 63.33), highlighting the benefits of dataset expansion and refined training strategies. More specifically, Llama 3.1 incorporates more extensive dataset, covering over 15 trillion tokens across multiple languages and domains, leading to notable performance gains. Llama 3.3 further benefits from advancements in post-training techniques, such as online preference optimization, which enhances core performance while significantly reducing training and inference costs. These refined optimization strategies in pre-training not only improve general capabilities but also enhance performance in domain-specific tasks. (5) Existing reasoning models struggle with long financial contexts and cross-table correlations. Many financial reasoning tasks require models to extract and synthesize information from lengthy reports, structured tables, and numerical equations. However, performance discrepancies across datasets suggest that current LLMs struggle with this challenge. For example, models that perform well in FinQA, which primarily involves textual financial reasoning, do not necessarily excel in DM-Simplong, which integrates numerical and symbolic information. GPT-4o achieves 72.49 in FinQA but drops to 60.0 in DM-Simplong, indicating difficulties in integrating mathematical symbols with textual reasoning. Furthermore, models that score highly in XBRL-Math, such as DeepSeekR1-Distill-Qwen-32B (84.44) and DeepSeek-R1 (86.67), highlight growing but incomplete capability to process structured financial tables. Notably, all reasoning-enhanced models fail to show improvements in handling long financial contexts and multi-table correlations. This is particularly concerning given that financial reports are inherently long and include complex interlinked tables. Though smaller models perform well in structured inputs like XBRL-Math, their performance drops significantlyby nearly 30%when handling long contexts. For example, DeepSeek-R1Distill-Llama-8B achieves 81.11 in XBRL-Math but drops to 33.0 in DM-Simplong. This suggests that while smaller models can recognize structured patterns, they struggle with long-range dependencies and multi-step reasoning. Addressing these limitations requires improvements in longcontext retention, structured data comprehension, and multi-modal document understanding to enhance financial reasoning capabilities. (6) Reasoning enhancement basd on financial data improve performance of all datasets. Compared with Llama 3.1-8B-Instruct, DeepSeekR1-Distill-Llama-8B, which incorporates reasoning enhancement data distilled from DeepSeek-R1, shows only modest improvement (50.12 to 53.36). However, our model, Fino1-8B, trained with reasoning paths distilled from GPT-4o using backtracking strategy to iteratively refine the reasoning process, achieves substantial performance boost across all datasets, with an average score of 61.03a 10.91-point increase over Llama 3.1-8BInstruct. Notably, Fino1-8B outperforms its counterparts in FinQA (60.87 vs. 54.13), DM-Simplong (40.00 vs. 34.00), and particularly in XBRL-Math (82.22 vs. 62.22), demonstrating the effectiveness of reasoning-driven training. It is important to note that our training utilized reasoning paths generated exclusively from FinQA, yet the model exhibited improvements across all datasets. This suggests that financial domainspecific reasoning enhancement data can significantly improve models comprehensive understanding of financial terminology, long-context comprehension, table-based reasoning, and equation interpretation. Furthermore, these results highlight the effectiveness of combination of reasoning pathbuilding strategies, including backtracking, exploring new paths, verification, and correction, in financial tasks. By refining reasoning paths through iterative corrections, these strategies enhance logical consistency, computational accuracy, and overall robustness, demonstrating promising approach for advancing financial reasoning capabilities in language models. Overall, these insights demonstrate that financial reasoning presents unique challenges distinct from general NLP and mathematical reasoning. The variability in performance across different tasks underscores the necessity for more financially specialized training methodologies and architectural improvements to enhance financial comprehension, structured data processing, and multi-step numerical reasoning. 3.2 Error Analysis To further investigate why reasoning-enhanced models like DeepSeek-R1 and GPT-o1 underperform in financial tasks compared to generalpurpose models such as GPT-4o and DeepSeekV3, we conduct an error analysis using the FinQA dataset since these reasoning-enhanced models exhibit significant performance drop on FinQA. We focus on cases where DeepSeek-R1 produces incorrect answers while DeepSeek-V3 generates correct ones. Two common error patterns emerge. First, DeepSeek-R1 tends to over-reason and does not strictly adhere to instructions, as illustrated in Figure 1. In this case, the question requires sum, but the model provides excessive details by breaking down the calculation instead of directly summing the values as instructed. Second, compared to DeepSeek-V3, DeepSeekR1 appears to lack financial sensitivity. For instance, in Figure 2, it fails to recognize critical financial nuances, leading to an incorrect response. Specifically, DeepSeek-R1 misinterprets the concept of \"average share price\" in the UK Employee Share Purchase Plan by incorrectly identifying it as the employee purchase price ($4,078 per share) rather than the actual compensation expense per share ($719 per share). This mistake stems from an inability to correctly differentiate between compensation expense per share and the full fair market value (FMV) calculation, resulting in an overestimated figure. In contrast, DeepSeek-V3 correctly understands that the compensation expense per share represents the direct financial impact per issued share, allowing it to provide the accurate answer. This highlights fundamental gap in DeepSeek-R1s financial reasoning capabilities, particularly in recognizing the accounting conventions used to report share-based compensation. Figure 1: Error case 1. 3.3 Future Direction Based on the above findings, we observe that developing powerful reasoning model for financial tasks presents unique challenges distinct from general-domain reasoning. Our analysis suggests three key areas for improvement in financial reasoning models: (1) Enhancing models understanding of financial knowledge and terminology. While reasoning-enhanced models demonstrate strong performance in general domains, they often struggle with financial tasks due to lack of domainspecific knowledge. Future work should explore strategies that incorporate financial corpora, structured financial reports, and regulatory documents to improve models comprehension of domainspecific terminology and contextual nuances. (2) Improving models ability to handle multitable reasoning and long financial contexts. Our results highlight that even large models exhibit significant performance drops when processing long financial reports and cross-referencing multiple tables. To address this, future reasoning stratigies should be focused on inferring logics among tables or menorization mechanisms to enhance longcontext understanding. (3) Deeper analysis of reasoning-enhanced strategies in models like GPT-o1 and DeepSeekR1. Although GPT-o1 and DeepSeek-R1 are designed with advanced reasoning enhancements, they fail to show consistent improvements across financial tasks. GPT-o1 utilizes \"chain-of-thought\" prompting, generating intermediate reasoning steps to enhance structured problem-solving. However, this reasoning strategy does not lead to improvements in any of the financial benchmarks, as GPTo1 underperforms compared to GPT-4o across all tasks, scoring 49.07 in FinQA and 56.0 in DMSimplong. In contrast, DeepSeek-R1 introduces self-reflection capabilities through reinforcement learning, enabling the model to iteratively evaluate and refine its reasoning processes without supervised data. While this approach helps DeepSeekR1 achieve strong performance in XBRL-Math (86.67), indicating improved structured numerical reasoning, it also leads to drop in FinQA (65.13), suggesting challenges in financial textbased reasoning. These results highlight fundamental difference between the two models GPTo1s structured reasoning approach does not translate to domain-specific improvements, whereas DeepSeek-R1s reinforcement learning strategy enhances structured data processing but remains limited in free form textual financial reasoning. Understanding these trade-offs is essential for designing reasoning strategies tailored to financial tasks. Developing robust financial reasoning models requires both domain adaptation and architectural advancements to bridge the gap between general reasoning capabilities and financial-specific challenges. Future work should focus on integrating financially specialized pretraining, multi-table comprehension techniques, and long-context optimization to build models capable of handling complex financial documents and reasoning tasks effectively."
        },
        {
            "title": "4 Related Work",
            "content": "Our work builds upon three main research directions: the development of general-purpose and reasoning-enhanced language models, applications of LLMs in finance, and studies on reasoning capabilities in financial tasks. 4.1 General-Purpose and Reasoning-Enhanced LLMs Recent years have witnessed significant advancements in large language models which demonstrated remarkable capabilities across various tasks, including natural language understanding, generation, and complex reasoning. Building upon these Figure 2: Error case 2. foundations, researchers have developed specialized reasoning-enhanced models such as DeepSeekR1 and GPT-o1, which incorporate techniques like chain-of-thought prompting (Wei et al., 2022), selfreflection (Zhang et al., 2023), and reinforcement learning from human feedback (Ouyang et al., 2022). These models have shown superior performance in mathematical reasoning (Lewkowycz et al., 2022), symbolic manipulation (Drori et al., 2023), and logical inference tasks (Chen et al., 2023). 4.2 LLMs in Financial Applications The application of LLMs in finance has gained significant attention, with models being adapted for tasks such as financial text analysis (Yang et al., 2020), market sentiment prediction (Yang et al., 2023), and automated trading strategies (Kou et al., 2024). Recent work has focused on developing finance-specific models like BloombergGPT (Wu et al., 2023), FinGPT (Yang et al., 2023) and PIXIU (Xie et al., 2023), OpenFinLLMs (Xie et al., 2024b), which are pretrained on financial corpora to better understand domain-specific terminology and concepts. These models have demonstrated effectiveness in tasks such as financial sentiment analysis, earnings call analysis, and regulatory compliance checking. 4.3 Reasoning Capabilities in Financial Tasks Financial reasoning presents unique challenges that combine numerical computation, domain knowledge, and logical inference. Recent studies have explored LLMs capabilities in financial reasoning tasks, including numerical reasoning over financial documents (Chen et al., 2021), mathematical problem-solving in financial contexts (Srivastava et al., 2024), and structured data interpretation (Liu et al., 2025). These works highlight the importance of both domain expertise and reasoning abilities in financial applications. Our work extends these research directions by systematically evaluating how reasoning enhancements in state-of-the-art LLMs translate to financial domain tasks, providing insights into the effectiveness of different reasoning strategies and identifying areas for improvement in financial reasoning capabilities."
        },
        {
            "title": "5 Conclusion",
            "content": "In this study, we evaluated the performance of 16 recent reasoning-augmented LLMs and generalpurpose LLMs on financial tasks, analyzing their capabilities in text understanding, numerical reasoning, and structured data processing. Our results indicate that while reasoning-enhanced models demonstrate strong performance in general tasks, they often fail to generalize effectively to financial reasoning due to insufficient domain adaptation. Additionally, models optimized for structured mathematical reasoning perform well in numerical tasks like XBRL-Math but struggle with financial text comprehension and long-context processing, highlighting the need for financial domain-specific adaptations. To address these limitations, we presented Fino1, reasoning-enhanced LLMs based on Llama-3.1-8B-Instruct, leveraging reasoning paths curated from GPT-4o using only FinQA, dataset with 5,000 financial reasoning samples. Our results demonstrate that, despite being trained on single dataset, Fino1 achieved an overall performance improvement of approximately 10% across three financial benchmarks. This significant improvement underscores the potential of financial domain-specific data in enhancing LLMs financial reasoning capabilities. Future work can focus on enhancing financial knowledge adaptation, improving multi-table reasoning, and handling longcontext financial documents. Additionally, refining domain-specific reasoning strategies through structured data reasoning, retrieval-augmented approaches, and domain-aware pretraining will be critical for bridging the gap between general reasoning capabilities and financial-specific challenges."
        },
        {
            "title": "Limitations",
            "content": "Our study has several limitations that highlight areas for future improvement. First, our model scale is limited, as we only fine-tuned an 8B model (Fino1), while larger models (e.g., 70B) could potentially benefit more from reasoning enhancements. Second, our evaluation scope is restricted, covering only three financial reasoning tasks (FinQA, DM-Simplong, and XBRL-Math), which do not fully capture the breadth of financial NLP applications such as forecasting, financial sentiment analysis, and fraud detection. Third, our fine-tuning relies on single dataset, FinQA, for reasoning path construction, limiting the models exposure to different financial reasoning patterns; incorporating additional datasets could improve generalization. Fourth, our reasoning path construction approach is simplified, as we generate paths using single method (GPT-4o), whereas exploring multiple reasoning path generation strategiessuch as ensemble approaches or humanannotated pathscould lead to more robust financial reasoning capabilities."
        },
        {
            "title": "Ethics Statement",
            "content": "While our study demonstrates significant advancements in financial reasoning with LLMs, Fino1 remains research prototype and is not yet suitable for real-world financial applications. Our model inherits the well-documented limitations of large language models, including hallucinations, sensitivity to input phrasing, and potential biases in financial data sources, which could affect reliability in critical financial contexts. Furthermore, Fino1 has not undergone rigorous testing for high-stakes financial decision-making, such as investment strategies, regulatory compliance, or risk assessment, where incorrect outputs could lead to severe consequences. Additionally, the models reliance on single dataset (FinQA) and single reasoning path construction method (GPT-4o) limits its robustness and adaptability to the complex and evolving nature of financial environments. As with all AI-driven financial models, careful human oversight remains essential, and future work must focus on enhancing factual consistency, mitigating biases, improving domain adaptation, and ensuring alignment with regulatory frameworks before such models can be considered for real-world financial deployment."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, and Benyou Wang. 2024. Huatuogpt-o1, towards medical complex reasoning with llms. arXiv preprint arXiv:2412.18925. Mark Chen et al. 2023. Automatic formal reasoning about large language models. arXiv preprint arXiv:2307.09829. Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, et al. 2021. Finqa: dataset of numerical reasoning over financial data. arXiv preprint arXiv:2109.00122. Iddo Drori et al. 2023. Neural-symbolic mathematical reasoning. arXiv preprint arXiv:2301.07076. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. arXiv preprint 2024. Openai o1 system card. arXiv:2412.16720. Zhizhuo Kou, Holam Yu, Jingshu Peng, and Lei Chen. 2024. Automate strategy finding with llm in quant investment. arXiv preprint arXiv:2409.06289. Aitor Lewkowycz et al. 2022. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858. Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. 2024. arXiv preprint Deepseek-v3 technical report. arXiv:2412.19437. Shu Liu, Shangqing Zhao, Chenghao Jia, Xinlin Zhuang, Zhaoguang Long, Jie Zhou, Aimin Zhou, Man Lan, and Yang Chong. 2025. Findabench: Benchmarking financial data analysis ability of large language models. In Proceedings of the 31st International Conference on Computational Linguistics, pages 710725. Md Saef Ullah Miah, Md Mohsin Kabir, Talha Bin Sarwar, Mejdl Safran, Sultan Alfarhood, and MF Mridha. 2024. multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and llm. Scientific Reports, 14(1):9603. Long Ouyang et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155. Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, and Dan Roth. 2024. Evaluating llms mathematical reasoning in financial document question answering. In Findings of the Association for Computational Linguistics ACL 2024, pages 38533878. Mohamad-Hani Temsah, Amr Jamal, Khalid Alhasan, Abdulkarim Temsah, and Khalid Malki. 2024. Openai o1-preview vs. chatgpt in healthcare: new frontier in medical ai reasoning. Cureus, 16(10). Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerov, et al. 2024. Adapted large language models can outperform medical experts in clinical text summarization. Nature medicine, 30(4):11341142. Keyi Wang, Jaisal Patel, Charlie Shen, Daniel Kim, Andy Zhu, Alex Lin, Luca Borella, Cailean Osborne, Matt White, Steve Yang, et al. 2025. Finnlp-fnpllmfinlegal-2025 shared task: Regulations challenge. In Proceedings of the Joint Workshop of the 9th Financial Technology and Natural Language Processing (FinNLP), the 6th Financial Narrative Processing (FNP), and the 1st Workshop on Large Language Models for Finance and Legal (LLMFinLegal), pages 363370. Jason Wei et al. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903. Shijie Wu et al. 2023. Bloomberggpt: large language model for finance. arXiv preprint arXiv:2303.17564. Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, et al. 2024a. The finben: An holistic financial benchmark for large language models. arXiv preprint arXiv:2402.12659. Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro Lopez-Lira, and Jimin Huang. 2023. Pixiu: large language model, instruction data and evaluation benchmark for finance. In Proceedings of the 37th International Conference on Neural Information Processing Systems, pages 3346933484. Qianqian Xie, Dong Li, Mengxi Xiao, Zihao Jiang, Ruoyu Xiang, Xiao Zhang, Zhengyu Chen, Yueru He, Weiguang Han, Yuzhe Yang, et al. 2024b. Open-finllms: Open multimodal large language models for financial applications. arXiv preprint arXiv:2408.11878. Frank Xing. 2024. Designing heterogeneous llm agents for financial sentiment analysis. ACM Transactions on Management Information Systems. Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin Van Durme, Kenton Murray, and Young Jin Kim. 2024. Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation. arXiv preprint arXiv:2401.08417. An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, et al. 2024. Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122. Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023. Fingpt: Open-source financial large language models. arXiv preprint arXiv:2306.06031. Yi Yang et al. 2020. Finbert: pre-trained financial language representation model for financial text mining. International Joint Conference on Artificial Intelligence. Haopeng Zhang, Philip Yu, and Jiawei Zhang. 2024. systematic survey of text summarization: From statistical methods to large language models. arXiv preprint arXiv:2406.11289. Zhuosheng Zhang et al. 2023. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2302.12822. Yilun Zhao, Yitao Long, Hongjun Liu, Ryo Kamoi, Linyong Nan, Lyuhao Chen, Yixin Liu, Xiangru Tang, Rui Zhang, and Arman Cohan. 2024. Docmatheval: Evaluating math reasoning capabilities of llms in understanding long and specialized documents. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1610316120. Tianyang Zhong, Zhengliang Liu, Yi Pan, Yutong Zhang, Yifan Zhou, Shizhe Liang, Zihao Wu, Yanjun Lyu, Peng Shu, Xiaowei Yu, et al. 2024. Evaluation of openai o1: Opportunities and challenges of agi. arXiv preprint arXiv:2409.18486."
        }
    ],
    "affiliations": [
        "TheFinAI"
    ]
}