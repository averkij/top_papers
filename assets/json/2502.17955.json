{
    "paper_title": "Language Models' Factuality Depends on the Language of Inquiry",
    "authors": [
        "Tushar Aggarwal",
        "Kumar Tanmay",
        "Ayush Agrawal",
        "Kumar Ayush",
        "Hamid Palangi",
        "Paul Pu Liang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Multilingual language models (LMs) are expected to recall factual knowledge consistently across languages, yet they often fail to transfer knowledge between languages even when they possess the correct information in one of the languages. For example, we find that an LM may correctly identify Rashed Al Shashai as being from Saudi Arabia when asked in Arabic, but consistently fails to do so when asked in English or Swahili. To systematically investigate this limitation, we introduce a benchmark of 10,000 country-related facts across 13 languages and propose three novel metrics: Factual Recall Score, Knowledge Transferability Score, and Cross-Lingual Factual Knowledge Transferability Score-to quantify factual recall and knowledge transferability in LMs across different languages. Our results reveal fundamental weaknesses in today's state-of-the-art LMs, particularly in cross-lingual generalization where models fail to transfer knowledge effectively across different languages, leading to inconsistent performance sensitive to the language used. Our findings emphasize the need for LMs to recognize language-specific factual reliability and leverage the most trustworthy information across languages. We release our benchmark and evaluation framework to drive future research in multilingual knowledge transfer."
        },
        {
            "title": "Start",
            "content": "Language Models Factuality Depends on the Language of Inquiry Tushar Aggarwal*,, Kumar Tanmay*,,, Ayush Agrawal*,,,, Kumar Ayush(cid:50),, Hamid Palangi, Paul Pu Liang Harvard University, Université de Montréal, Mila, MIT (cid:50)Stanford University, Google, Microsoft Research"
        },
        {
            "title": "Abstract",
            "content": "Multilingual language models (LMs) are expected to recall factual knowledge consistently across languages, yet they often fail to transfer knowledge between languages even when they possess the correct information in one of the languages. For example, we find that an LM may correctly identify Rashed Al Shashai as being from Saudi Arabia when asked in Arabic, but consistently fails to do so when asked in English or Swahili. To systematically investigate this limitation, we introduce benchmark of 10,000 country-related facts across 13 languages and propose three novel metricsFactual Recall Score, Knowledge Transferability Score, and Cross-Lingual Factual Knowledge Transferability Scoreto quantify factual recall and knowledge transferability in LMs across different languages. Our results reveal fundamental weaknesses in todays state-of-the-art LMs, particularly in crosslingual generalization where models fail to transfer knowledge effectively across different languages, leading to inconsistent performance sensitive to the language used. Our findings emphasize the need for LMs to recognize language-specific factual reliability and leverage the most trustworthy information across languages. We release our benchmark and evaluation framework to drive future research in multilingual knowledge transfer. The data and codes are available at this link. 5 2 0 2 5 2 ] . [ 1 5 5 9 7 1 . 2 0 5 2 : r"
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) are often perceived as vast knowledge reservoirs, capable of recalling factual information across multiple languages (Wang et al., 2024). However, what if *equal contribution. Corresponding authors: tushar.aggarwal53@gmail.com, kumartanmay@fas.harvard.edu, ayush.agrawal@mila.quebec 1 Illustratation of the cross-lingual factual Figure 1: knowledge transferability issue across linguistic knowledge clouds in LMs. The model correctly recalls that Rashed Al Shashai is from Saudi Arabia when queried in Arabic, but fails to retrieve this fact in English and Swahili, highlighting that factual knowledge is often stored in language-specific silos. their knowledge is locked within linguistic boundaries and unable to be transferred across languages? Despite advancements in multilingual LMs such as Llama (Touvron et al., 2023a; Dubey et al., 2024), Gemma (Team et al., 2024a), DeepSeek (DeepSeek-AI et al., 2024), and Phi (Abdin et al., 2024; Li et al., 2023), our study reveals striking asymmetry in their factual recall across languages: consider the example in Figure 1, where an LM is tasked with simple factual query: Rashed Al Shashai is from which country? When asked in Arabic, several state-of-the-art LMs correctly generate the response: Saudi Arabia. However, when posed in English, Hindi, or Swahili, the same models fail to recall the fact. This example suggests that models can correctly retrieve country-specific facts in the language associated with that country but struggle to do so in others. This raises critical questiondo these models truly internalize and transfer factual knowledge across languages, or do they merely encode isolated linguistic silos? This limitation has significant implications for multilingual AI development and real-world applications. Many LM-based systemssuch as retrieval-augmented generation (RAG) pipelines, multilingual search engines, and cross-lingual reasoning modelsassume that factual knowledge is consistently available and transferable across languages. Our findings reveal that LMs often rely on language-specific memorization rather than true cross-lingual knowledge generalization. This over-reliance can introduce biases, inconsistencies, and reliability issues in multilingual AI applications (Chua et al., 2024). To systematically analyze the factual inconsistencies, we introduce carefully curated dataset comprising country-related facts translated into 13 languages. This benchmark evaluates LMs on multiple dimensionsfactual recall, in-context recall, and counter-factual context adherenceacross high-, medium-, and low-resource languages. This benchmark comprises of 802 instances for factual recall, 156 instances for In-context recall, and 1404 instances for counter-factual context adherence as shown in Table 1. Factual recall assesses the LMs ability to recall country-specific facts consistently across multiple languages. We evaluate factual recall using three metrics: (a) Factual Recall Score (FRS): Measures how accurately model recalls fact in given language, (b) Knowledge Transferability Score (KTS): Quantifies how well factual knowledge is transferred across languages, and (c) Cross-Lingual Factual Knowledge Transferability (X-FaKT) Score: Combines the assessment of factual recall and cross-lingual transfer ability. FRS and KTS measure the effectiveness of cross-lingual knowledge transfer, and X-FaKT Score integrates factual recall with transferability to provide robust measure of multilingual generalization. These metrics offer more nuanced evaluation than simple error rate, allowing for deeper understanding of crosslingual generalization. In-Context Recall (Machlab and Battle, 2024) measures the general performance of the models in multilingual contexts. Inspired by (Du et al., 2024), we also study how factual knowledge of models affects their performance in handling in-context tasks in the multilingual setting (Counterfactual Context Adherence). For this, we design dataset where factual knowledge conflicts with in-context instructions. Our experiments reveal that while LMs often retrieve factual information correctly in the language associated with the fact, they struggle to transfer this knowledge to other languages. We also found that the size of the LLM plays an important role in factuality and knowledge transferability. For example, the combined performance of LLama-3-70B in factuality and knowledge transfer across languages is markedly ( 152% in X-FaKT Score) better than Llama-3.2-1B. In addition, there is marked difference in these tasks when queries are asked in high-resource languages ( 46% in X-FaKT Score) as compared to the case with low resources. This finding exposes critical limitation in current language models and their approach to multilingual knowledge integration. Our findings also reveal an interesting trade-off: LMs with stronger factual recall often struggle with counterfactual adherence, highlighting key limitation in balancing factual memory and contextual reasoning. In our experiments, we observed that the factual knowledge of LMs could skew their judgments, leading to inaccurate evaluations. One has to be very careful when designing the prompt and using LM as an evaluator. We highlight the importance of controlling the evaluators factual knowledge to ensure consistent and effective evaluation."
        },
        {
            "title": "2 Related Work",
            "content": "Multilingual Transformers. Early work by (Petroni et al., 2019) explored whether LMs can store factual knowledge about entities, setting the stage for later investigations into multilingual LMs. Notable multilingual models such as mBERT (Devlin et al., 2019), XLM-R (Conneau et al., 2020), mT5 (Xue et al., 2021), and BLOOM (Workshop et al., 2023) have demonstrated varying levels of performance across different languages. These models, trained on diverse multilingual corpora, show that LMs exhibit language-dependent capabilities in factual recall. Research has highlighted systematic biases in factual retrieval across languages (Artetxe et al., 2020; Liu et al., 2020; Kassner et al., 2021), which is key challenge in multilingual LMs. While multilingual QA benchmarks like XQuAD (Artetxe et al., 2020), MLQA (Lewis et al., 2020), and TyDiQA (Clark et al., 2020) assess factual consistency, they do not directly measure the transfer of knowledge between languages. Recent work by (Wang et al., 2024) raised questions about LMs ability to recall factual knowledge in reason2 ing tasks, while (Fierro et al., 2025) emphasized the need for more robust methodologies for evaluating knowledge in multilingual LMs. Our study builds on these insights by introducing benchmark specifically designed to assess cross-lingual factual knowledge transferability. Cross-Lingual Knowledge Transfer in LMs. Recent works have sought to understand the factors that influence cross-lingual knowledge transfer in multilingual models. Studies suggest that multilingual LMs exhibit zero-shot and few-shot generalization across languages (Nooralahzadeh et al., 2020; Pfeiffer et al., 2020), but empirical evidence indicates that this transfer is often asymmetric, with high-resource languages benefiting more than lower-resource ones (Hu et al., 2020). (Muller et al., 2021) investigated the connection between cross-lingual similarity in hidden representations and downstream task performance, revealing that LMs with stronger representation alignment across languages perform better. (Chai et al., 2022) explored cross-linguality from language structure perspective, emphasizing the importance of compositional properties in facilitating knowledge transfer. More recent work has focused on crosslingual transfer from high-resource to low-resource languages (Zhao et al., 2024a,b), further underscoring the asymmetries in cross-lingual knowledge integration. Our work contributes to this area by evaluating the effectiveness of factual knowledge transfer across languages using comprehensive set of metrics designed to measure both factual recall and transferability. Context Sensitivity and Counterfactual Reasoning. LMs are known to be highly sensitive to contextual cues, which can sometimes override factual knowledge when the context is misleading (Brown et al., 2020; Tirumala et al., 2022; Du et al., 2024). (Ghosh et al., 2025) provides an in-depth review of multilingual reasoning in LMs. Counterfactual reasoning, in which models must consider hypothetical situations, has been studied in various contexts (Wu et al., 2023). These studies show that LMs optimized for factual recall often struggle with counterfactual tasks, especially when faced with conflicting contextual instructions. While most prior evaluations have focused on monolingual settings (Shwartz et al., 2020; Wang et al., 2020), our work extends these investigations into the multilingual domain. By introducing tasks like in-context recall and counterfactual adherence, we analyze how multilingual models handle both factual acTask Type # Examples Factual Recall In-context Recall Counter-Factual Context Adherence 802 156 1404 Table 1: Number of examples per languages in our benchmark (3). Figure 2: Examples from our multilingual dataset illustrating three tasks. Factual Recall: LMs recall countryspecific facts better in native languages, as seen with Dharans correct identification in Nepali but incorrect in English. Incontext Recall: Models struggle with contextual reasoning, showing regional bias when associating names with countries. Counter-Factual Context Adherence: When given counterfactual prompts about well-known figures, models rely on prior knowledge, affecting their ability to adhere to provided context. curacy and contextual reasoning across languages, revealing important challenges in balancing factual knowledge and context sensitivity."
        },
        {
            "title": "3 Dataset",
            "content": "We introduce new multilingual dataset designed to evaluate three key capabilities of LMs: (a) Factual Recall, (b) In-context Recall, and (c) CounterFactual Context Adherence. The number of instances in our dataset is given in the Table 1. Given the multilingual nature of our study, we categorize languages based on their resource availability in existing LM training corpora: High-resource: English, Chinese, French, Japanese. Medium-resource: Hindi, Russian, Arabic, Greek. Low-resource: Nepali, Ukrainian, Turkish, Swahili, Thai. These languages correspond to countries strongly associated with their usage: the United States, China, France, Japan, India, Russia, Saudi Arabia, Greece, Nepal, Ukraine, Turkey, Kenya, and Thailand. Now, we describe our datasets in 3 detail. 3.1 Factual Recall This task evaluates an LMs ability to recall country-specific facts across multiple languages. For example, given the query, In which country is Mumbai located?, the model should correctly respond with India when asked in different languages. To construct the dataset, we curated diverse set of entitiesincluding cities, artists, sports figures, landmarks, festivals, and politiciansfor 13 selected countries. We then created standardized templates for factual queries and translated them into each language using the Google Translate API (Google, n.d.). All translations were manually verified and refined as needed with the assistance of ChatGPT. In total, our dataset consists of 805 unique factual questions, each available in 13 language versions. 3.2 In-Context Recall The in-context recall task evaluates how effectively an LM utilizes contextual information to answer question, ensuring that internal knowledge does not influence the models output. Building on the work of (Feng and Steinhardt, 2024), we constructed our dataset by focusing on common person names associated with each country. For each example, we sampled two names and paired them with two different countries, creating context-based prompts as shown in violet color in Figure 2. To enhance dataset efficiency, we intentionally avoided associating name with its most commonly linked country within the example. 3.3 Counter-Factual Context Adherence This task evaluates an LMs susceptibility to counterfactual information by assessing whether it adheres to the provided context when answering question. Ideally, the model should rely solely on the given context, but in some cases, its internal knowledge may interfere or override it, leading to unintended responses (Du et al., 2024). To investigate this, we curated list of well-known personalities strongly associated with specific countries and deliberately introduced counterfactual information into the context. For the example given in Figure 2, if the model defaults to its internal knowledge and answers United States, it demonstrates resistance to the contextual information. Conversely, if it follows the counterfactual context and answers India, it suggests higher reliance on the provided context rather than pre-existing knowledge. One might expect these models to perform nearperfectly on these tasks, as they are very simple. However, despite the simplicity of these tasks, the performance varies across languages and models."
        },
        {
            "title": "4 Experiments",
            "content": "In this section, we discuss our experimental setup, metric formulation, and both quantitative and qualitative analyses. We present the results of our experiments evaluating LMs on our dataset across diverse multilingual tasks. These experiments assess how language and country-specific factual knowledge influence LMs responses in multilingual setting. All experiments were conducted using the latest models, with Qwen-2.5-72B-Inst (Qwen et al., 2025) serving as the evaluator (Li et al., 2024). 4.1 Experimental Setup Models We evaluated 14 models of varying sizes, trained on different compositions of multilingual data, and fine-tuned using various preference optimization strategies (Ouyang et al., 2022; Rafailov et al., 2024), for our multilingual study. These include Deepseek (DeepSeek-AI et al., 2024), Qwen (Yang et al., 2024), Gemma (Team et al., 2024b), and Llama (Touvron et al., 2023b) families. Further details of the models evaluated are given in Table A.1. Compute Details All our experiments were conducted on set of 4 NVIDIA A100 GPUs, each with 80GB of VRAM. Evaluation To evaluate all models on the curated datasets (Section 3), we used temperature setting of 0 and maximum token limit of 128. Specifically, we tested the models performance on Factual Recall and In-Context Recall across different settings. For evaluation, we designed our metrics and utilized Qwen-2.5-72B-Inst as the evaluator (Li et al., 2024), with maximum token limit of 256 to support reasoning. Evaluation prompts are shown in Figures 11 and 12. 4.2 Metric Definition and Formulation This section introduces our carefully designed metrics to evaluate factual recall and knowledge transferability across languages in LMs. We propose two key metrics: the Factual Recall Score (FRS) 4 and the Knowledge Transferability Score (KTS). To establish common metric for evaluating the models performance in our benchmark, we compute their harmonic mean, which is defined as the Cross-Lingual Factual Knowledge Transferability Score (X-FaKT), to ensure balanced assessment while penalizing large disparities between them. Our metrics incorporate an inverse formulation with correction factor to maintain bounded range of [0, 1]. higher error rate results in lower metric value due to the inverse transformation, ensuring that better model performance corresponds to higher scores. 4.2.1 Associative vs. Non-Associative Knowledge We categorize our dataset into two groups: associative and non-associative knowledge. The categorization is defined as follows: we consider 13 languages, each associated with corresponding country (i.e., the ith language belongs to the ith country). Associative = {Q Questions : Languagei output(Q) = Countryj = j} Non-associative = {Q Questions : Languagei output(Q) = Countryj = j} We denote the mean error rate for countryspecific fact asked in the language strongly associated with that country as µassoc., and the mean error rate for country-specific fact asked in language not associated with that country as µnon-assoc.. 4.2.2 Factual Recall Score (FRS) Factual recall evaluates the models ability to correctly retrieve both associative and non-associative knowledge. We define the Factual Recall Score (FRS) as: RS = (cid:18) 3 2 1 µassoc. + µnon-assoc. + 1 (cid:19) 1 3 (1) When both errors are zero (µassoc. = 0, µnon-assoc. = 0), the model has perfect factual recall, yielding an FRS score of 1. When both errors are high, the denominator increases, resulting in lower FRS score closer to 0, indicating poor factual recall. across languages. We define the Knowledge Transferability Score (KTS) as: (cid:18) 1 µassoc. µnon-assoc. + 1 (cid:19) 1 2 (2) KT = where: µassoc. µnon-assoc. captures the absolute difference between associative and nonassociative recall errors. When both errors are zero (µassoc. = 0, µnon-assoc. = 0), there is perfect factual knowledge transfer, resulting in KTS score of 1. When both errors are high but equal (e.g., µassoc. = 20, µnon-assoc. = 20), KTS remains 1, indicating that while factual recall is poor, the model exhibits consistent errors across languages. When errors differ significantly (e.g., µassoc. = 20, µnon-assoc. = 2 or vice versa), the absolute difference increases, leading to lower KTS, highlighting lack of knowledge transfer across languages. 4.2.4 Cross-Lingual Factual Knowledge Transferability Score (X-FAKT) To ensure balanced evaluation of factual recall and cross-lingual transferability, we compute their harmonic mean: X-FAKT = 2 RS KT RS + KT (3) where: The harmonic mean penalizes large disparities between factual recall (FRS) and knowledge transferability (KTS), ensuring that both contribute meaningfully to the final score. If either FRS or KTS is significantly lower, the overall score remains low, discouraging models from excelling in one metric while performing poorly in the other. high X-FAKT score indicates that the model is both factually accurate and consistent across multiple languages. 4.2.3 Knowledge Transferability Score (KTS) Knowledge transferability quantifies how well model maintains consistent factual knowledge This formulation provides holistic evaluation of factual knowledge retention and cross-lingual consistency, making it robust metric for assessing multilingual model performance. Model µassoc.(%) µnonassoc.(%) t-stat p-value FRS KTS X-FAKT Llama-3-70B Gemma-2-27B Phi-4-14B Phi-3-14B Gemma-2-9B Llama-3-8B Orca-2-7B DeepSeek-7b Mistral-7B-v0.2 Phi-3.5-4B Phi-3-4B Llama-3.2-3B Gemma-2-2B Llama-3.2-1B 2.36 5.12 4.23 8.49 12.87 16.51 25.09 29.84 4.98 6.09 4.60 7.54 31.95 31.65 31.49 30.68 16.96 15.65 41.85 31.62 42.45 30.99 24.10 17.80 9.97 14.78 34.74 22.32 9.85 10.54 16.46 17.07 30.15 25.92 55.57 36.24 22.32 21.37 25.77 19.61 56.77 32.99 63.73 36.29 45.25 29.34 69.87 31.23 77.95 33.72 47.48 26.80 45.77 31.30 65.96 26.98 2.52 2.54 2.35 2.93 2.90 3.85 2.60 3.09 3.42 3.09 3.65 3.07 4.06 4. 0.01 0.01 0.02 <0.01 <0.01 <0.01 0.01 <0.01 <0.01 <0.01 <0.01 <0.01 <0.01 <0.01 0.835 0.742 0.548 0.330 0.677 0.649 0.295 0.268 0.424 0.208 0.181 0.375 0.463 0.247 0.862 0.783 0.706 0.535 0.705 0.651 0.603 0.514 0.559 0.563 0.477 0.620 0.473 0.524 0.848 0.762 0.617 0.408 0.691 0.650 0.396 0.353 0.483 0.304 0.262 0.467 0.468 0.336 Table 2: Results of the t-test comparing associative and non-associative knowledge across models, alongside FRS, KTS, and X-FAKT scores. (A) Llama-3-70B achieves the best performance in both factual recall and knowledge transferability. (B) There is statistically significant difference between the performance on associative queries (asked in countrys native language) and non-associative queries (asked in other languages). Figure 4: This figure illustrates the model-wise comparison of X-FAKT scores grouped by language families. clear trend emerges, showing that as the model size increases within family, the X-FAKT score tends to increase. the highest X-FAKT score of 0.848, demonstrating superior balanced performance in both factual recall (FRS = 0.835) and knowledge transferability (KTS = 0.862). This exceptional performance is supported by the lowest error rates (µassoc. = 2.36%, µnonassoc. = 9.85%), suggesting that larger model sizes generally correlate with better cross-lingual factual knowledge handling. Despite similar model sizes, significant performance variations exist between different architectures. For example, Gemma-2-9B (X-FAKT: 0.691) substantially outperforms Mistral-7B-v0.2 (X-FAKT: 0.483), suggesting that architecture design and training methodology play crucial roles beyond mere parameter count. As illustrated in Figure 4, the XFAKT scores exhibit clear upward trend with increasing model size within each language family. This suggests that larger models generally achieve better factual consistency, highlighting the impact 6 Figure 3: Error rates for each model on the Factual Recall task. clear pattern emerges, showing decline in performance as we move from larger to smaller models (top to bottom) and from high-resource to low-resource languages (left to right). 4.3 Quantitative Analysis 4.3.1 Performance on Factual Recall task The error rate across different LMs (Figure 3) reveals clear pattern in performance across languages and model sizes. Notably, all models demonstrate superior performance on highresource languages like English and French, with error rates consistently below 15% for most model variants. This performance gradually deteriorates as the model size decreases, with smaller models showing significantly higher error rates across all languages. However, an interesting observation emerges with languages like Swahili and Turkish, which despite being low-resource languages, exhibit relatively better performance with error rates comparable to mid-resource languages. This can be attributed to their use of Latin script, facilitating better knowledge transfer from English. compelling pattern emerges when examining languages that share similar scripts, and strong correlations in model performance among languages that share similar scripts. For example, the error patterns for Hindi-Nepali and Russian-Ukrainian pairs show remarkable similarities, suggesting that the models effectively leverage shared scriptural characteristics during learning. These patterns indicate that script similarity plays crucial role in the models ability to generalize across languages, potentially offering insights into how these models transfer knowledge between different language pairs and scripts. Knowledge Transferability Analysis: From Table 2, Llama-3-70B emerges as the clear leader with Language High Medium Low µassoc.(%) 3.83 3.79 26.73 17.60 29.53 16.19 µnonassoc.(%) 29.84 27.47 50.54 21.20 53.91 23.68 Table 3: Average mean and standard deviation for error rate across all models for each language group. Highresource languages exhibit lower error rates compared to low-resource languages. of scale on model performance. These findings provide valuable insights into the current state of cross-lingual factual knowledge in LMs and highlight areas for future improvement, particularly in reducing the performance gap between associative and non-associative knowledge retrieval. Associative vs. Non-associative performance: We analyze the performance of various models on these two subsets of data and report the results in the Table 2. For all models, the t-statistic and pvalue indicate that the differences between associative and non-associative categories are statistically significant (p-value less than 0.05). language Performance comparison across groups: In this study, we categorize languages into three groups based on their availability and coverage in the dataset: High, Medium, and Low, as defined in Section 3. From the results shown in Table 3, we observe clear trend across language groups. Specifically, high resouce languages exhibit the lowest average error rates, particularly in the associative category, where models make fewer mistakes (µassoc. = 3.83%). However, for non-associative questions, the error rate rises significantly (µnonassoc. = 29.84%), indicating that models struggle more when dealing with non-associative samples in these languages. The error rate increases while moving from high to lowresource languages. 4.3.2 Performance on In-Context Recall task Figure 13 demonstrates the incorrectness rate for the in-context recall capabilities of different LMs. Despite being simple task, certain models such as DeepSeek-7B, Orca-2-7B, Phi-3-4B, Llama-3.2-1B, and Mistral-7B-v0.2 perform poorly across multiple languages. This suggests that these models struggle to effectively utilize contextual information when generating outputs. Interestingly, even for languages like Swahili and Turkish, which showed better scores in the Factual Recall task, models demonFigure 5: Error rate for each model on Counter-Factual Context Adherence task. Models show high error rates in high resource languages such as English and French where they have high factual recall. strate poor performance on this context-dependent task. This stark contrast suggests that the benefits of Latin script-based knowledge transfer observed in the Factual Recall task do not extend to in-context learning scenarios, where performance depends primarily on the models ability to process and utilize contextual information. As mentioned in the dataset section, we intentionally paired cross-entities as context. This setup appears to induce regional bias, which negatively impacts model performance. The structured entitycontext pairing in the dataset may have led to spurious correlations (Yang et al., 2023; Ye et al., 2024), reducing model accuracy in in-context recall tasks. Some models struggle to effectively leverage contextual information, revealing potential weaknesses in their retrieval and in-context learning mechanisms. 4.3.3 Performance on Counter-Factual Context Adherence task Figure 5 illustrates the error rates of LMs in the Counterfactual Context Adherence task. Notably, Latin-script languages (English, French, Swahili, and Turkish), which performed well in factual recall tasks, exhibited significantly higher error rates in counterfactual adherence. This suggests fundamental trade-off in the models capabilities: their strength in accurately retrieving factual information appears to come at the expense of their ability to maintain adherence to counterfactual contexts. This inverse relationship raises important questions about the inherent limitations and tradeoffs in LMs learning mechanisms, particularly in how they balance factual knowledge with hypothet7 Figure 6: Mistral-7B-v0.2 output when prompted with the given context in English. This model generation shows how spurious correlation leads to in-context recall failures Figure 8: Llama-3-70B output when prompted with factual recall query in English Figure 7: Llama-3-70B output when prompted with counter-factual context adherence query in English. This shows LMs favour internal knowledge over contextual understanding. Figure 9: Llama-3-70B output when prompted with factual recall query in Hindi. In Hindi, it misinterprets understanding of French word. ical reasoning. 4.4 Qualitative Analysis Spurious correlation leads to in-context recall failures. We observe that some models tend to associate names with cultural origins, even when contextual evidence contradicts this assumption. Figures 6 demonstrate the model response when prompted Mistral-7B-v0.2 with the contextual understanding-based question in English. Despite the explicit context stating that Li Wei resides in Russia, the model disregards this information and defaults to cultural associations. This behavior reveals limitation in integrating contextual evidence when making country-specific inferences. Models favor factual knowledge over context. We also observed that some models prioritize their internal factual knowledge over contextual information when responding to questions about wellknown personalities. Figures 7 demonstrate the model response when prompted Llama-3-70B with the factual retrieval query in English. In this case, despite being explicitly told that George Washington lived in India, the model relied on its factual knowledge, correcting the given fact and asserting that George Washington lived in the United States. This response demonstrates the models strong reliance on factual accuracy, rather than adapting to the context provided. It suggests that when it comes to well-known historical figures, models may prioritize prior knowledge over the specific context they are given. Linguistic variability in word interpretation. LMs can interpret words differently depending on the language. Figures 8 and 9 demonstrate the model responses when prompted Llama-3-70B with the same queries but in different languages. This highlights challenges in multilingual consistency, where the model misinterprets Dijon as De Janeiro in Hindi, revealing inconsistencies in cross-lingual factual retrieval. Challenges with using LMs as evaluators. We used zero-shot prompt with Llama-3-70B as an evaluator and found that its inherent factual knowledge can skew assessments. For example, when evaluating Gemma-2-27B response to the counterfactual context taskCatherine the Great lives in Indiathe evaluator corrected it, asserting that she lived in Russia, despite the provided ground truth. This bias highlights the need to control evaluators factual knowledge to ensure consistent evaluation."
        },
        {
            "title": "5 Conclusions",
            "content": "Our study reveals critical limitation in multilingual LMs: their inability to consistently transfer factual knowledge across languages. Our bench8 transparency, and social responsibility."
        },
        {
            "title": "8 Acknowledgment",
            "content": "We thank Alessandro Sordoni, Prachi Jain, Rishav Hada, Chanakya Ekbote, Anirudh Buvanesh, and Ankur Sikarwar for their valuable feedback. We acknowledge the support of Ayush Agrawals PhD advisors, Aaron Courville and Navin Goyal. mark provides standardized framework to evaluate both current and future LMs on their factual consistency and cross-lingual generalization, enabling more systematic comparison of their capabilities. Moreover, it can serve as valuable resource to promote research in interpretability by helping analyze how and where factual knowledge is stored and retrieved across languages, fostering deeper understanding of LM internals. We emphasize the need for AI systems with internal awareness of their language-specific strengths and weaknessesa concept we term calibrated multilingualism. Under this paradigm, model would autonomously leverage the most reliable internal representations for any given multilingual query. We also find that LMs, when used as evaluators, are biased by their internal factual knowledge, which may not align with the intended input-outputground-truth context. This underscores the need to control the evaluators factual knowledge for more reliable assessments. Ultimately, enabling AI to cross-generalize across languages is crucial for inclusive and equitable technology, ensuring language is no barrier to reliable knowledge access."
        },
        {
            "title": "6 Limitations",
            "content": "Our study provides valuable insights into crosslingual knowledge transfer in LMs but has some limitations. First, our benchmark, though comprehensive in country-related facts, covers only 13 languages, limiting its representation of diverse linguistic families. Second, we evaluated only opensource LMs, excluding proprietary models that may exhibit different transfer patterns. Third, our fact collection used standardized template for consistency, which may not reflect the diversity of real-world queries. Lastly, our focus on countryrelated facts means our findings may not generalize to other domains like science, history, or culture."
        },
        {
            "title": "7 Ethics Statement",
            "content": "This research is conducted with strong commitment to ethical principles, ensuring data privacy and consent by using publicly available information and adhering to data protection regulations. We acknowledge potential biases in multilingual language models and aim to highlight and address these through our benchmark. Transparency and reproducibility are promoted by making our dataset and evaluation framework publicly available. Our research aligns with the broader goals of fairness,"
        },
        {
            "title": "References",
            "content": "Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, et al. 2024. Phi-3 technical report: highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219. Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. 2020. On the cross-lingual transferability of monolingual representations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 46234637, Online. Association for Computational Linguistics. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. Yuan Chai, Yaobo Liang, and Nan Duan. 2022. Crosslingual ability of multilingual masked language models: study of language structure. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 47024712, Dublin, Ireland. Association for Computational Linguistics. Lynn Chua, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chulin Xie, and Chiyuan Zhang. 2024. Crosslingual capabilities and knowledge barriers in mularXiv preprint tilingual large language models. arXiv:2406.16135. Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki. 2020. TyDi QA: benchmark for information-seeking question answering in typologically diverse languages. Transactions of the Association for Computational Linguistics, 8:454470. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440 8451, Online. Association for Computational Linguistics. DeepSeek-AI, :, Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge, Kang Guan, Daya Guo, Jianzhong Guo, Guangbo Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li, Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu, Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan Liu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma, Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu, Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli Sha, Zhihong Shao, Junxiao Song, Xuecheng Su, Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingxuan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang, Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie, Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu, Yanhong Xu, Dejian Yang, Yuxiang You, Shuiping Yu, Xingkai Yu, B. Zhang, Haowei Zhang, Lecong Zhang, Liyue Zhang, Mingchuan Zhang, Minghua Zhang, Wentao Zhang, Yichao Zhang, Chenggang Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou, Qihao Zhu, and Yuheng Zou. 2024. Deepseek llm: Scaling open-source language models with longtermism. Preprint, arXiv:2401.02954. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41714186, Minneapolis, Minnesota. Association for Computational Linguistics. Kevin Du, Vésteinn Snæbjarnarson, Niklas Stoehr, Jennifer White, Aaron Schein, and Ryan Cotterell. 2024. Context versus prior knowledge in language models. arXiv preprint arXiv:2404.04633. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Jiahai Feng and Jacob Steinhardt. 2024. How do language models bind entities in context? Preprint, arXiv:2310.17191. Constanza Fierro, Negar Foroutan, Desmond Elliott, and Anders Søgaard. 2025. How do multilingual language models remember facts? Preprint, arXiv:2410.14387. Akash Ghosh, Debayan Datta, Sriparna Saha, and Chirag Agarwal. 2025. The multilingual mind : survey of multilingual reasoning in language models. Preprint, arXiv:2502.09457. Google. n.d. Google translate. Accessed: 2025-02-16. Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and Melvin Johnson. 2020. Xtreme: massively multilingual multi-task benchmark for evaluating cross-lingual generalization. Preprint, arXiv:2003.11080. Nora Kassner, Philipp Dufter, and Hinrich Schütze. 2021. Multilingual LAMA: Investigating knowledge in multilingual pretrained language models. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 32503258, Online. Association for Computational Linguistics. 10 Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, and Holger Schwenk. 2020. MLQA: Evaluating cross-lingual extractive question answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7315 7330, Online. Association for Computational Linguistics. Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu. Llms-as-judges: comprehensive sur2024. vey on llm-based evaluation methods. Preprint, arXiv:2412.05579. Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. 2023. Textbooks are all you need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463. Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020. Multilingual denoising pretraining for neural machine translation. Transactions of the Association for Computational Linguistics, 8:726742. Daniel Machlab and Rick Battle. 2024. context recall arXiv:2404.08865. is prompt dependent. Llm inPreprint, Benjamin Muller, Yanai Elazar, Benoît Sagot, and Djamé Seddah. 2021. First align, then predict: Understanding the cross-lingual ability of multilingual BERT. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 22142231, Online. Association for Computational Linguistics. Farhad Nooralahzadeh, Giannis Bekoulis, Johannes Bjerva, and Isabelle Augenstein. 2020. Zero-shot cross-lingual transfer with meta learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 45474562, Online. Association for Computational Linguistics. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:2773027744. Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowlIn Proceedings of the 2019 Conferedge bases? ence on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 24632473, Hong Kong, China. Association for Computational Linguistics. Jonas Pfeiffer, Ivan Vulic, Iryna Gurevych, and Sebastian Ruder. 2020. MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 76547673, Online. Association for Computational Linguistics. Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2025. Qwen2.5 technical report. Preprint, arXiv:2412.15115. Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2024. Direct preference optimization: Your language model is secretly reward model. Preprint, arXiv:2305.18290. Vered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020. Unsupervised commonsense question answering with self-talk. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 46154629, Online. Association for Computational Linguistics. Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. 2024a. Gemma: Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295. Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, Léonard Hussenot, Pier Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex CastroRos, Ambrose Slone, Amélie Héliou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. Choquette-Choo, Clément Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Mikuła, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, 11 Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Clément Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy. 2024b. Gemma: Open models based on gemini research and technology. Preprint, arXiv:2403.08295. Kushal Tirumala, Aram Markosyan, Luke Zettlemoyer, and Armen Aghajanyan. 2022. Memorization without overfitting: Analyzing the training dynamics of large language models. Advances in Neural Information Processing Systems, 35:3827438290. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023b. Llama: Open and efficient foundation language models. Preprint, arXiv:2302.13971. Chenguang Wang, Xiao Liu, and Dawn Song. 2020. Language models are open knowledge graphs. arXiv preprint arXiv:2010.11967. Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, and Ningyu Zhang. 2024. Knowledge mechanisms in large language models: survey and perspective. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 70977135, Miami, Florida, USA. Association for Computational Linguistics. BigScience Workshop, :, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanamanchi, Thomas Wang, Benoît Sagot, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurençon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeoluwa Adelani, Dragomir Radev, Eduardo González Ponferrada, Efrat Levkovizh, Ethan Kim, Eyal Bar Natan, Francesco De Toni, Gérard Dupont, Germán Kruszewski, Giada Pistilli, Hady Elsahar, Hamza Benyamina, Hieu Tran, Ian Yu, Idris Abdulmumin, Isaac Johnson, Itziar Gonzalez-Dios, Javier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu, Jonathan Chang, Jörg Frohberg, Joseph Tobing, Joydeep Bhattacharjee, Khalid Almubarak, Kimbo Chen, Kyle Lo, Leandro Von Werra, Leon Weber, Long Phan, Loubna Ben allal, Ludovic Tanguy, Manan Dey, Manuel Romero Muñoz, Maraim Masoud, María Grandury, Mario Šaško, Max Huang, Maximin Coavoux, Mayank Singh, Mike Tian-Jian Jiang, Minh Chien Vu, Mohammad A. Jauhar, Mustafa Ghaleb, Nishant Subramani, Nora Kassner, Nurulaqilla Khamis, Olivier Nguyen, Omar Espejel, Ona de Gibert, Paulo Villegas, Peter Henderson, Pierre Colombo, Priscilla Amuok, Quentin Lhoest, Rheza Harliman, Rishi Bommasani, Roberto Luis López, Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Sebastian Nagel, Shamik Bose, Shamsuddeen Hassan Muhammad, Shanya Sharma, Shayne Longpre, Somaieh Nikpoor, Stanislav Silberberg, Suhas Pai, Sydney Zink, Tiago Timponi Torrent, Timo Schick, Tristan Thrush, Valentin Danchev, Vassilina Nikoulina, Veronika Laippala, Violette Lepercq, Vrinda Prabhu, Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin Heinzerling, Chenglei Si, Davut Emre Tasar, Elizabeth Salesky, Sabrina J. Mielke, Wilson Y. Lee, Abheesht Sharma, Andrea Santilli, Antoine Chaffin, Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla, Gunjan Chhablani, Han Wang, Harshit Pandey, Hendrik Strobelt, Jason Alan Fries, Jos Rozen, Leo Gao, Lintang Sutawika, Saiful Bari, Maged S. Al-shaibani, Matteo Manica, Nihal Nayak, Ryan Teehan, Samuel Albanie, Sheng Shen, Srulik Ben-David, Stephen H. Bach, Taewoon Kim, Tali Bers, Thibault Fevry, Trishala Neeraj, Urmish Thakker, Vikas Raunak, Xiangru Tang, ZhengXin Yong, Zhiqing Sun, Shaked Brody, Yallow Uri, Hadar Tojarieh, Adam Roberts, Hyung Won Chung, Jaesung Tae, Jason Phang, Ofir Press, Conglong Li, Deepak Narayanan, Hatim Bourfoune, Jared Casper, Jeff Rasley, Max Ryabinin, Mayank Mishra, Minjia Zhang, Mohammad Shoeybi, Myriam Peyrounette, Nicolas Patry, Nouamane Tazi, Omar Sanseviero, Patrick von Platen, Pierre Cornette, Pierre François Lavallée, Rémi Lacroix, Samyam Rajbhandari, Sanchit Gandhi, Shaden Smith, Stéphane Requena, Suraj Patil, Tim Dettmers, Ahmed Baruwa, Amanpreet Singh, Anastasia Cheveleva, Anne-Laure Ligozat, Arjun Subramonian, Aurélie Névéol, Charles Lovering, Dan Garrette, Deepak Tunuguntla, Ehud Reiter, Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bogdanov, Genta Indra Winata, Hailey Schoelkopf, JanChristoph Kalo, Jekaterina Novikova, Jessica Zosa Forde, Jordan Clive, Jungo Kasai, Ken Kawamura, Liam Hazan, Marine Carpuat, Miruna Clinciu, Najoung Kim, Newton Cheng, Oleg Serikov, Omer Antverg, Oskar van der Wal, Rui Zhang, Ruochen Zhang, Sebastian Gehrmann, Shachar Mirkin, Shani Pais, Tatiana Shavrina, Thomas Scialom, Tian Yun, Tomasz Limisiewicz, Verena Rieser, Vitaly Protasov, pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 483498, Online. Association for Computational Linguistics. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024. Qwen2 technical report. arXiv preprint arXiv:2407.10671. Yu Yang, Besmira Nushi, Hamid Palangi, and Baharan Mirzasoleiman. 2023. Mitigating spurious correlations in multi-modal models during fine-tuning. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 3936539379. PMLR. Wenqian Ye, Guangtao Zheng, Xu Cao, Yunsheng Ma, and Aidong Zhang. 2024. Spurious correlations in machine learning: survey. Preprint, arXiv:2402.12715. Jun Zhao, Zhihao Zhang, Luhui Gao, Qi Zhang, Tao Gui, and Xuanjing Huang. 2024a. Llama beyond english: An empirical study on language capability transfer. arXiv preprint arXiv:2401.01055. Xin Zhao, Naoki Yoshinaga, and Daisuke Oba. 2024b. Tracing the roots of facts in multilingual language models: Independent, shared, and transferred knowledge. arXiv preprint arXiv:2403.05189. Vladislav Mikhailov, Yada Pruksachatkun, Yonatan Belinkov, Zachary Bamberger, Zdenˇek Kasner, Alice Rueda, Amanda Pestana, Amir Feizpour, Ammar Khan, Amy Faranak, Ana Santos, Anthony Hevia, Antigona Unldreaj, Arash Aghagol, Arezoo Abdollahi, Aycha Tammour, Azadeh HajiHosseini, Bahareh Behroozi, Benjamin Ajibade, Bharat Saxena, Carlos Muñoz Ferrandis, Daniel McDuff, Danish Contractor, David Lansky, Davis David, Douwe Kiela, Duong A. Nguyen, Edward Tan, Emi Baylor, Ezinwanne Ozoani, Fatima Mirza, Frankline Ononiwu, Habib Rezanejad, Hessie Jones, Indrani Bhattacharya, Irene Solaiman, Irina Sedenko, Isar Nejadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis Sanz, Livia Dutra, Mairon Samagaio, Maraim Elbadri, Margot Mieskes, Marissa Gerchick, Martha Akinlolu, Michael McKenna, Mike Qiu, Muhammed Ghauri, Mykola Burynok, Nafis Abrar, Nazneen Rajani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel, Ran An, Rasmus Kromann, Ryan Hao, Samira Alizadeh, Sarmad Shubber, Silas Wang, Sourav Roy, Sylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le, Yoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap, Alfredo Palasciano, Alison Callahan, Anima Shukla, Antonio Miranda-Escalada, Ayush Singh, Benjamin Beilharz, Bo Wang, Caio Brito, Chenxi Zhou, Chirag Jain, Chuxin Xu, Clémentine Fourrier, Daniel León Periñán, Daniel Molano, Dian Yu, Enrique Manjavacas, Fabio Barth, Florian Fuhrimann, Gabriel Altay, Giyaseddin Bayrak, Gully Burns, Helena U. Vrabec, Imane Bello, Ishani Dash, Jihyun Kang, John Giorgi, Jonas Golde, Jose David Posada, Karthik Rangasai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa Shinzato, Madeleine Hahn de Bykhovetz, Maiko Takeuchi, Marc Pàmies, Maria Castillo, Marianna Nezhurina, Mario Sänger, Matthias Samwald, Michael Cullan, Michael Weinberg, Michiel De Wolf, Mina Mihaljcic, Minna Liu, Moritz Freidank, Myungsun Kang, Natasha Seelam, Nathan Dahlberg, Nicholas Michio Broad, Nikolaus Muellner, Pascale Fung, Patrick Haller, Ramya Chandrasekhar, Renata Eisenberg, Robert Martin, Rodrigo Canalli, Rosaline Su, Ruisi Su, Samuel Cahyawijaya, Samuele Garda, Shlok Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Simon Ott, Sinee Sang-aroonsiri, Srishti Kumar, Stefan Schweter, Sushil Bharati, Tanmay Laud, Théo Gigant, Tomoya Kainuma, Wojciech Kusa, Yanis Labrak, Yash Shailesh Bajaj, Yash Venkatraman, Yifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli Xie, Zifan Ye, Mathilde Bras, Younes Belkada, and Thomas Wolf. 2023. Bloom: 176b-parameter open-access multilingual language model. Preprint, arXiv:2211.05100. Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim. 2023. Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. arXiv preprint arXiv:2307.02477. Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mT5: massively multilingual"
        },
        {
            "title": "A APPENDIX",
            "content": "Figure 10: Comparision of models (in the increasing order of size with respect to the parameters) using Factual Recall Score, Knowledge Transferability Score, and Cross-Lingual Factual Knowledge Transferability Score. 14 Model Llama-3-70B Gemma-2-27B Model Size & Architecture 70B L=80, H=64 27B Phi-4-14B Phi-3-14B Gemma-2-9B Llama-3-8B Orca-2-7B DeepSeek-7B Mistral-7B-v0.2 Phi-3.5-4B Phi-3-4B Llama-3.2-3B Gemma-2-2B Llama-3.2-1B 14B 14B 9B 8B L=32, H=32 7B L=32, H=32 7B L=30, H=32 7B L=32, H=32 3.8B L=32, H=32 3.8B 3B 2B 1B Training Data 15T tokens Multi-lingual 13T tokens Web, Code, Math 400B synthetic + 10T web 4.8T tokens 8T tokens 15T tokens Multi-lingual Based on Llama 2 2T tokens Open Web 3.4T tokens Multi-lingual 4.9T tokens 9T tokens Multi-lingual 2T tokens 9T tokens Multi-lingual Languages Supported EN, DE, FR, IT, PT, HI, ES, TH Primarily English DE, ES, FR, PT, IT, HI, JA 10% multilingual data Primarily English EN, DE, FR, IT, PT, HI, ES, TH Based on Llama 2 English & Chinese Open Web languages 23 languages incl. AR, ZH, CS, NL, Similar to Phi-3.5-mini EN, DE, FR, IT, PT, HI, ES, TH Primarily English EN, DE, FR, IT, PT, HI, ES, TH Context Vocab Post-Training Length 8K Size 128K SFT, RS, DPO Strategies 8K 256K SFT, RLHF 16K 100K 128K 32K SFT, RS, DPO SFT, DPO 8K 8K 4K 4K 256K SFT, RLHF 128K 32K 102K SFT, RS, DPO Single-turn SFT SFT, DPO 32K 32K SFT 128K 32K SFT, DPO 128K 32K SFT, DPO 128K 128K 8K 256K 128K 128K SFT, RS, DPO SFT, RLHF SFT, RS, DPO Key Features GQA, 8 heads, RoPE embeddings Local-global attention, Knowledge distillation Full attention over 4K context Reasoning focus, Multi-lingual support GQA, RoPE, Knowledge distillation GQA, RoPE, 32 heads Enhanced reasoning abilities English & Chinese focus GQA, Sliding window attention Multi-lingual support Diverse domain coverage GQA, Knowledge distillation GQA, RoPE, Knowledge distillation GQA, Multi-lingual dialogue focus Table A.1: Model Specifications: Comparison of LMs across key architectural and training characteristics. Languages abbreviated as: EN=English, DE=German, FR=French, IT=Italian, PT=Portuguese, HI=Hindi, ES=Spanish, TH=Thai, AR=Arabic, ZH=Chinese, CS=Czech, NL=Dutch, JA=Japanese. L=Layers, H=Heads, SFT=Supervised Fine-Tuning, RS=Rejection Sampling, DPO=Direct Preference Optimization, GQA=Grouped-Query Attention, RoPE=Rotary Position Embedding. 15 Figure 11: Prompt used for evaluation of Factual Recall and In-Context Recall tasks. Figure 12: Prompt used for evaluation of Counter-Factual Context Adherence task. 16 Question New York iko katika nchi gani? New Model Prediction York iko nchini **Marekani**. George Birlesik **Amerika vletleri**nde yasıyor. Washington, DeGround Truth LLM Evaluation Output Response: The assistants Marekani response is in the same language as the reference and aligns with the reference provided. Rating: [[1]] The assistants response is in the same language as the reference and aligns with the reference. Rating: [[1]] Amerika Birlesik Devletleri David lives in China. David Talimat: Verilen gerçege göre soruyu cevaplayın. Gerçek: George Washington, Amerika Birlesik Devletleri ülkesinde yasıyor. Soru: George Washington hangi ülkede yasıyor? David lives in China and Li Wei lives in United States. Who lives in China? Dans quel pays Sourate ? se trouve Sourate nest pas un pays, mais le nom dune **ville** située en **Algérie**. Inde Response: The assistants response is in the same language and aligns with the reference provided. Rating: [[1]] The assistants response is in French, which aligns with the reference language, but the information provided does not align with the reference. The assistant incorrectly states that Sourate is city in Algeria, while the reference is about India. Rating: [[4]] Table A.2: Some outputs from evaluator Qwen-2.5-72B-Inst. Rating[1-3]: Correct and Rating[4]: Incorrect. 17 Figure 13: Error rate for each model on In-context Recall task. Clearly, few models such as DeepSeek-7B, Phi-3-4B, etc. performs poorly on this simple task. 18 Figure 14: English Fall Back Rate across models (The English Fall Back Rate measures the frequency with which model defaults to English in its output). 19 Figure 15: Country-Specific Factual Error Rates in each language for Llama-3-70B 20 Figure 16: Country-Specific Factual Error Rates in each language for Gemma-2-27B 21 Figure 17: Country-Specific Factual Error Rates in each language for Phi-4-14B 22 Figure 18: Country-Specific Factual Error Rates in each language for Phi-3-14B 23 Figure 19: Country-Specific Factual Error Rates in each language for Gemma-2-9B 24 Figure 20: Country-Specific Factual Error Rates in each language for Llama-3-8B 25 Figure 21: Country-Specific Factual Error Rates in each language for Orca-2-7B 26 Figure 22: Country-Specific Factual Error Rates in each language for DeepSeek-7B 27 Figure 23: Country-Specific Factual Error Rates in each language for Mistral-7B-v0.2 28 Figure 24: Country-Specific Factual Error Rates in each language for Phi-3.5-4B 29 Figure 25: Country-Specific Factual Error Rates in each language for Phi-3-4B 30 Figure 26: Country-Specific Factual Error Rates in each language for Llama-3.2-3B 31 Figure 27: Country-Specific Factual Error Rates in each language for Gemma-2-2B 32 Figure 28: Country-Specific Factual Error Rates in each language for Llama-3.2-1B"
        }
    ],
    "affiliations": [
        "Google",
        "Harvard University",
        "MIT",
        "Microsoft Research",
        "Mila",
        "Stanford University",
        "Université de Montréal"
    ]
}