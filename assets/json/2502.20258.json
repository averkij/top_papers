{
    "paper_title": "LLM as a Broken Telephone: Iterative Generation Distorts Information",
    "authors": [
        "Amr Mohamed",
        "Mingmeng Geng",
        "Michalis Vazirgiannis",
        "Guokan Shang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs. Inspired by the \"broken telephone\" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation. Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 2 ] . [ 1 8 5 2 0 2 . 2 0 5 2 : r LLM as Broken Telephone: Iterative Generation Distorts Information Amr Mohamed1, Mingmeng Geng2, Michalis Vazirgiannis1,3, Guokan Shang 1MBZUAI, 2SISSA, 3Ecole Polytechnique {amr.mohamed, guokan.shang}@mbzuai.ac.ae"
        },
        {
            "title": "Abstract",
            "content": "As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their Inspired by the broken teleown outputs. phone effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation. Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AImediated information propagation, raising important questions about the reliability of LLMgenerated content in iterative workflows."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) are becoming an integral part of our daily lives, helping us process, comprehend, and convey information via text, while also expanding their support to additional areas (Yin et al., 2023). Consequently, an increasing amount of online content is now model-generated or assisted (Geng and Trotta, 2024), and such content is almost indistinguishable from humanproduced data (Uchendu et al., 2023). This prompts us to consider the question: what effects arise when the same piece of information is repeatedly processed by LLMs through multiple iterations? This procedure is analogous to the telephone game in human communication, widely known childrens game in which message is passed sequentially from one player to the next, with the final version often differing significantly from the original, usually with amusing or humorous effect. This happens because players often act as broken telephones, where information is gradually distorted as it is passed along the chain of individuals, highlighting how repeated transmission 1 0th lorry driver has been fined after his load of slabs fell off his vehicle on bend, writing off passing car worth 50,000. 2nd lorry driver was fined after stone slab he was transporting fell off his vehicle at bend, causing damage to passing car worth up to 50,000. 10th bus received $50,000 fine after large rock dislodged from it at bend and forced passing cars to swerve off the road. 50th bus received compensation of $50,000 after large rock struck the bus when the bus changed lanes on the city road, causing damage and an explosion on the road. 100th small car received compensation of $50,000 after large rock collided with the car, causing an accident and an explosion on the road. Table 1: Example of iterative translations of an English news article using Llama-3.1-8B-Instruct, with Thai as the intermediate language, highlighting the distortions introduced over the different iterations. can lead to the accumulation of errors, omissions, or unintended alterations (Hitchcock et al., 2011). Investigating these effects for LLMs is becoming increasingly crucial in the present era, because LLMs are not only consuming human-supplied information at one time, but also processing their own outputs in an iterative way. Therefore, our study focuses on exploring whether LLM also acts as broken telephone, when the same content is continuously refined, paraphrased, or reprocessed, and particularly when the generated output becomes the input for subsequent model iterations. We expect to observe an effect similar to that of human information distortion through iterative generation. In our study, we simulate the LLMs telephone game in conjunction with the translation task mainly, under three experimental setups. As illustrated in Figure 1, within each iteration, document in English is subsequently translated into one or more different languages, then back to English, by leveraging LLMs. We compare the back-translated Figure 1: Overview of examples from our three experimental setups. Left: Bilingual Self-LoopA single model iteratively translates document from English (EN) to French (FR) or Thai (TH) and back to English. Middle: Bilingual Two-PlayerTwo different models collaborate within the same chain on translating between English and French or English and Thai. Right: Multilingual MultiplayerA more complex translation chain involving multiple languages and models, designed to examine how increasing the variety of languages and models accelerates information distortion over iterative generations. English version with the initial English version at every iteration with textual relevance and factuality measures, to investigate whether and how information distortion accumulates. Our results show that over time, small alterations in phrasing, meaning, or factual details can accumulate, leading to progressive drift from the original source, as illustrated by the example in Table 1. Code and data are publicly available1. Our main findings include: The degree of information distortion in translation chains depends on the choice of intermediate languages, influenced by their linguistic similarity to the source language and their prevalence in the models pre-training and post-training corpora. Greater chain complexity, whether by adding languages or models, often amplifies distortion, with longer chains introducing more degradation regardless of the type of iterative chain. Although distortion is unavoidable, it can be mitigated through temperature control and restricted prompting, which restrict the LLM from deviating significantly from the original text. Our research echoes the ongoing conversation about the long-term impact of the widespread use of LLM-generated content on models themselves, humans, and society at largeoften termed model and knowledge collapse (Guo et al., 2024b; Peterson, 2024). Our findings raise concerns about the reliability of AI-mediated information dissemination over the long term and in an iterative way. 1https://github.com/amr-mohamedd/ LLM-as-a-Broken-Telephone"
        },
        {
            "title": "2 Related Work",
            "content": "Model Collapse. Iterative training on synthetically generated data induces model collapse, phenomenon characterized by systematic erosion of the long-tail components of the original data distribution (Shumailov et al., 2023). Theoretical analyses further elucidated how self-consuming training loops alter intrinsic scaling laws, thereby intensifying this collapse (Fu et al., 2024; Dohmatob et al., 2024), complementing earlier findings on distributional distortions (LeBrun et al., 2022). Furthermore, Guo et al. (2024b) demonstrated that iterative training on synthetic text does not preserve the nuanced richness of human language, particularly in creative tasks, underscoring the broader challenges of maintaining linguistic diversity in iteratively generated content. Iterative Generation and Information Evolution. Iterative generation can trigger model collapse, whereby the diversity of real-world information degrades over timea process that Peterson (2024) defines as knowledge collapse. Research on language evolution offers framework for analyzing these degradations (Markov et al., 2023), aligning with broader perspectives on cultural evolution (Mesoudi and Whiten, 2008; Caldwell and In the context of LLMs, Perez Millen, 2008). et al. (2024) analyzed text properties evolution in rephrasing, continuation, and inspiration-taking tasks. Their work, however, overlooked translationa key LLM applicationand focused solely on chains involving single model. Our work overcomes these shortcomings by investigating how iterative information translation accelerates distor2 tions, explores heterogeneous model chains, and extends the analysis to higher complexity rephrasing chains, providing broader view of iterative generations impact on information evolution. LLM Agents. We consider the implications for multi-agent settings, where communication frameworks leverage collaborative interactions between multiple LLMs (Park et al., 2023; Wu et al., 2023; Li et al., 2024b). These frameworks enable agents to iteratively refine outputs through debate-style interactions (Helm et al., 2024) or cooperative task decomposition (Pham et al., 2023), often improving accuracy in mathematical and logical tasks (Zhang et al., 2024). As introduced by Park et al. (2023), generative agents showcase the potential for creating interactive simulacra of human behavior through memory, reflection, and planning. However, such architectures implicitly assume that iterative exchanges preserve or enhance information fidelitya premise challenged by our findings in translation chains. While prior work focuses on emergent problem-solving capabilities (Chan et al., 2024), our study reveals how these same iterative mechanisms accelerate information distortion, particularly in scenarios where translation ambiguities compound through successive agent handoffs. Evaluation of LLM Outputs. In addition to the multi-agent perspective, it is essential to scrutinize how LLM outputs are evaluated. Existing research predominantly relies on metrics such as token similarity (Hu and Zhou, 2024), output diversity (Guo et al., 2024a; Shaib et al., 2024), and factuality (Wang et al., 2023; Iqbal et al., 2024; Min et al., 2023; Chern et al., 2023). However, these evaluations are generally confined to single iterations and fail to capture the cumulative degradation introduced by iterative generationa critical aspect of the translation chains under investigation. Although previous studies have explored variations in toxicity, positivity, difficulty, and length in iterative LLM transmission chains (Perez et al., 2024), they have overlooked the systematic assessment of textual similarity and factuality. Our work addresses this gap by providing rigorous analysis of the deterioration of these properties over successive iterations in both translation and rephrasing tasks. 3 Methodology In this section, we formalize the telephone game procedure with machine translation, noting that the broken telephone effect may occur with any generative task when carried out iteratively. 3.1 Notations and Definitions Let = {di}I = {lj}J = {mk}K i=1 denote set of documents, j=1 as set of natural languages, and k=1 for set of models. We define translation chain as sequence of translation iterations that progressively transform document. For iteration 1, let d(t1) be the i,lsource i-th document in the source language at iteration 1. At iteration t, an ordered language chain is constructed by selecting permutation π(t) of 1 languages from and forming the sequence L(t) = (l(t) 1 , l(t) 2 , . . . , l(t) J1, l(t) ) (1) with the requirement that l(t) = lsource (ensuring that the final translation returns to the source language). Simultaneously, model sequence M(t) = (cid:0)m(t) 1 , m(t) 2 , . . . , m(t) (cid:1) (2) is defined, where each m(t) is sampled uniformly from (allowing repeats; if = = 1, the same model is used throughout). Let ab() denote the translation operator that converts an input from language to language using model m. The composed operator for iteration is then (t) = m(t) l(t) l(t) J1 m(t) 2 l(t) 2 l(t) 1 m(t) 1 l(t) 1 lsource (3) so that the updated document is given by d(t) i,lsource = (t)(cid:16) d(t1) i,lsource (cid:17) . (4) Starting with d(0) sequence (d(0) is the total number of iterations. , d(1) i,lsource i,lsource i,lsource = di, the process yields the ), where , . . . , d(N ) i,lsource 3.2 Experimental Settings Languages. We selected English (EN) as lsource for all experiments and French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) as the bridge (intermediate) languages in the translation chains. Within each iteration, document in English is subsequently translated into one or more bridge languages, then back to English. This set creates varying degrees of semantic, lexical, and syntactic similarities between the source language and the bridge languages, which may differentially influence the extent of distortion introduced within the translation chains (Marchisio et al., 2020; Guerin et al., 2024). 3 Datasets. We utilized three datasets that span distinct domains: BookSum (Kryscinski et al., 2021), ScriptBase-alpha (Gorinski and Lapata, 2015), and (BBC)News2024 (Li et al., 2024a), from which we select articles published in 2024 to minimize the chances of data exposure that may result in biases amplification over the iterations (Luo et al., 2024; Li et al., 2024a). For our experiments, we randomly select 150 documents from each dataset, with each document containing between 100 and 200 words long. Models. We primarily used two models, LLAMA-3.1-8B-INSTRUCT (Llama) (Dubey et al., 2024) and MISTRAL-7B-INSTRUCT-V0.2 (Mistral) (Jiang et al., 2023), for our main experiments. Additionaly, GEMMA-2-9B-IT (Gemma) (Team et al., 2024) is incorporated into Experiment 3 (Section 4.3) to evaluate higher complexity chains. Decoding Parameters and Translation Prompt. Each model was used for inference with its default decoding parameters. We capped the maximum number of newly generated tokens at 8000 to encourage open-ended generation. This high limit allows translations, which can vary in length across different languages, to conclude naturally rather than being prematurely truncated. Models within the main experiments were prompted to translate documents from source to target language with moderately constrained prompt. The full translation prompt can be found in Appendix C. 3.3 Evaluation Metrics To comprehensively assess the impact of iterative generation on text quality, we employ two complementary sets of evaluation metrics: textual relevance and factuality preservation. The former quantifies the lexical, syntactic, and semantic deviations introduced at each generation step, while the latter evaluates the degree to which the generated text remains faithful to the original information. Textual Relevance. We used BLEU (Papineni et al., 2002) to detect incremental errors, ROUGE1 (Lin, 2004) to quantify word-level omissions and subtle deviations, CHR-F (Popovic, 2015) for capturing character-level deviations and errors accumulation, METEOR (Banerjee and Lavie, 2005) for being adept at capturing paraphrastic variations and subtle semantic shifts, and finally BERTScore (Zhang et al., 2019) for its focus on nuanced contextual and semantic relationships beyond traditional n-gram overlap-based methods. Factuality Preservation. FActScore (Min et al., 2023) decomposes long-form text into atomic units and verifies each against trusted reference using dedicated judge model. In this study, we assume that the original text is factually correct and use FActScore to assess the rate of factuality degradation over the different iterations by comparing each model generation with its original text, then employ Claude 3.5 Sonnet as the judge model."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Experiment 1: Bilingual Self-loop Setup. We fix the language set to = {EN, lbridge} (5) where lbridge {FR, DE, NL, VN, ZH, TH}. We consider the case when M1 = M2 = 1, with M1 and M2 containing Llama and Mistral respectively. We also consider the three datasets: BookSum, ScriptBase-alpha , and News2024. For each dataset D, every document d(0) undergoes = 100 translation iterations with an iteration of the form: EN lbridge EN. (6) All translations within single chain are performed by single model. Concretely, at iteration t, the translation operator (t) = m1 ENlbridge m1 lbridgeEN is applied to produce = (t)(cid:0)d(t1) d(t) (cid:1). (7) (8) ) , d(1) , . . . , d(100) This yields the sequence (d(0) for each document d(0) D. Hypothesis 1 (H1) We hypothesize that iterative translation chains better preserve relevance and factuality when the bridge language shares lexical overlap, script, and syntax with the source language. In contrast, languages markedly dissimilar from the source language are expected to introduce greater distortion over iterations. Results. Figure 2 presents Llamas iterative translation outcomes on the News2024 dataset. Across all language pairs, there is gradual decline in both factuality and relevance. Notably, language pairs exclusively using Latin scriptwith bridge languages such as French, German, and Dutchdemonstrated superior preservation of 4 Figure 2: Results of Llama in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the News2024 dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH). EN DE EN FR EN NL EN TH EN VN EN ZH Dataset Model Avg Grad. Std Err. Avg Grad. Std Err. Avg Grad. Std Err. Avg Grad. Std Err. Avg Grad. Std Err. Avg Grad. Std Err. BookSum News2024 ScriptBase-alpha Llama Mistral Llama Mistral Llama Mistral -0.006 -0. -0.005 -0.011 -0.005 -0.010 0.003 0.009 0.003 0.006 0.003 0.006 -0.005 -0. -0.004 -0.007 -0.006 -0.008 0.003 0.007 0.003 0.004 0.004 0.005 -0.006 -0. -0.005 -0.011 -0.005 -0.009 0.003 0.008 0.003 0.006 0.004 0.006 -0.026 -0. -0.018 -0.038 -0.015 -0.039 0.014 0.025 0.009 0.022 0.009 0.023 -0.009 -0. -0.008 -0.027 -0.011 -0.027 0.005 0.018 0.005 0.015 0.007 0.015 -0.021 -0. -0.011 -0.024 -0.013 -0.021 0.011 0.015 0.006 0.012 0.008 0.011 Table 2: Comparison of average gradient and standard error values of FActScore for the different models and language pairs across datasets. these qualities compared to those employing nonLatin script bridge languages, which exhibited more pronounced distortions over successive iterations. similar trend was observed for Llama in the other datasets, while Mistral showed an even more severe decline across all three datasets. Comprehensive results for the remaining datasets and models are provided in Appendix B.1. The average gradient values of FActScore in Table 2 quantify the rate of factuality loss across translation iterations. For language pairs composed solely of Latin script languages, gradients remain close to zero across all datasets and LLMs, indicating minimal degradations. For instance, in the News2024 dataset, the average gradients for EN FR are -0.004 (0.003) with Llama and -0.007 (0.004) with Mistral, while for EN DE they are -0.005 (0.003) and -0.011 (0.006), respectively. In contrast, chains involving non-Latin scriptsparticularly Thaiexhibit significantly faster factuality loss. In the BookSum dataset, the EN TH gradient is -0.026 (0.014) with Llama and -0.040 (0.025) with Mistral. This pattern is consistently observed across all evaluated language pairs, datasets, and models, with Thai demonstrating the highest rates of factual degradation. 4.2 Experiment 2: Bilingual Two-player Setup. We fix the language set to = {EN, lbridge} (9) where lbridge {FR, TH}. Following the results presented in Section 4.1, we selected EN FR and EN TH for Experiment 2, as they demonstrated the lowest and highest levels of information distortion, respectively. We consider model set that includes both Llama and Mistral. For this experiment, we used the News2024 dataset because, as shown in Section 4.1, the choice of dataset did not significantly influence the observed trends, and to further mitigate data exposure (Luo et al., 2024; Li et al., 2024a). Unlike Experiment 1, where single model was used for both translation directions, we allow each translation step to potentially use different model. At iteration t, we define two-component model sequence: M(t) = (cid:0)m(t) 1 , m(t) (cid:1), (10) where m(t) is the model used for the translation 1 from English to lbridge, and m(t) is the model used 2 for the translation from lbridge to English. Each component is sampled uniformly from M. 5 Figure 3: Comparison of metrics for the Bilingual Two-Player Experiment on the News2024 dataset, illustrating the interaction effects between Llama and Mistral on translation chains for EN FR and EN TH, contrasted with their individual performances in the Bilingual Self-loop Experiment. The translation operator at iteration is then 4.3 Experiment 3: Multilingual Multiplayer defined as: (t) = m(t) 2 ENlbridge m(t) 1 lbridgeEN. (11) The output document at iteration is then determined as shown in Equation 8. This yields the sequence (d(0) , . . . , d(100) ) for each document in the News2024 dataset. , d(1) i Hypothesis 2 (H2) We hypothesize that the coexistence of two different models in the same translation chain will add more distortions to the original information, thereby causing the original information to degrade over the successive iterations. Results. Figure 3 shows distinct patterns in the collaborative performance of Llama and Mistral In French, the joint across different languages. translation chain did not enhance the preservation of factuality or textual relevance relative to the models operating independently; instead, the collaboration introduced additional distortions that further degraded all evaluation metrics. Conversely, in Thai, the collaboration of Llama and Mistral resulted in reduced distortion compared to Mistral alone, though it still exhibited greater degradation than Llama in isolation. We further quantified the average gradient of FActScore. For French, the collaborative chain exhibited an average gradient of -0.007 (0.004), confirming minimal factuality degradation, though slightly worse than the standalone performances of Llama and Mistral. In contrast, for Thai, the collaborative chain showed lower average gradient of -0.035 (0.019) when compared to the standalone chain of Mistral. However, despite this lower decline, it was still outperformed by the standalone performance of Llama, where factual degradation was less pronounced. 6 Setup. In this experiment, we design three settings of increasing complexity, each incorporating at least two bridge languages and at least two models within the same translation chain. The objective is to examine whether introducing greater number of languages or models accelerates distortion. Setting 1. We fix = {EN, FR, TH} (12) and define to contain both Llama and Mistral. At each iteration t, we sample permutation L(t) = π(t)(L) that enforces cyclic translation path: EN l(t) 1 l(t) 2 EN, 1 and l(t) = l(t) 2 drawn from {FR, TH} and satisfy2 . The corresponding model sequence with l(t) ing l(t) 1 is M(t) = (cid:0)m(t) 1 , m(t) 2 , m(t) 3 (cid:1), (13) with each m(t) sampled uniformly from M. The translation operator at iteration is composed as: m(t) 2 2 l(t) l(t) m(t) 1 l(t) 1 EN (t) = m(t) 3 ENl(t) 2 (14) , 1 which is applied iteratively to generate: = (t)(cid:16) d(t) d(t1) (cid:17) . (15) i , d(1) , . . . , d(N ) ), where d(0) This produces (d(0) is the original document and = 100. Setting 2. We here retain and the translation chain structure from Setting 1, utilizing the same translation operator as defined in Equation 14, while expanding with an additional model, Gemma, to assess the impact of adding more models of similar size into the chain. Figure 4: Results of rephrasing experiments on 30 randomly sampled documents from the News2024 dataset. The figure compares the performance of individual models (Llama, Mistral, and Gemma) and their collaborative combinations over 100 rephrasing iterations. Setting 3. We extend the language set to: = {EN, FR, TH, ZH, DE}, (16) and hold fixed from Setting 1. The translation operator is then defined as: (t) = m(t) (17) , m(t) 1 l(t) 1 EN 5 ENl(t) 4 . applied to generate d(t) Hypothesis 3 (H3) We hypothesize that higher complexity translation chains cause higher factual degradation of the source document. Results. As shown in Appendix B.2, all three experimental settings indicated comparable degree of factual, lexical, and semantic degradation by the 100th iteration across all evaluation metrics. However, differences emerged in the rate at which this degradation occurred. Specifically, Setting 3 exhibited the steepest decline in factual accuracy, with an average FActScore gradient of 0.038 0.02. By the 10th generation, Setting 3s factuality had dropped to 0.054, and by the 100th generation, it further declined to 0.04. Setting 1 followed closely, with an average gradient of 0.036 0.02, showing factuality score of 0.063 at the 10th generation and 0.04 at the 100th. Setting 2 exhibited the slowest rate of factual degradation, with an average gradient of 0.034 0.02, reaching 0.075 at the 10th generation and 0.04 at the 100th."
        },
        {
            "title": "5 Ablation Studies",
            "content": "5.1 Other Tasks: Rephrasing Building on our findings in section 4, we extend our experiments to explore whether information distortion manifests in other types of iterative generation chains. Inspired by the work of Perez et al. (2024), who examined the evolution of toxicity, positivity, difficulty, and length in rephrasing as well as in 7 continuation and inspiration-taking chains, we further probe the effects of information distortion in more complex rephrasing chains. In this task, the model is instructed to rephrase given document while preserving its full meaning (the full rephrasing prompt can be found in Appendix C). We randomly sampled 30 documents from News2024 and conducted four experiments based on the setups from Sections 4.1, 4.2, and 4.3 (Setting 2). These experiments tested standalone rephrasing chains, the collaborative effects of Llama and Mistral, and an extended setup incorporating Gemma into the chain. Rephrasing results are presented in Figure 4. Textual relevance metrics reveal rapid degradation of lexical and semantic properties over iterations. Among individual models, Llama shows the slowest divergence in textual relevance, with Mistral following. When these models collaborate, the degradation in textual relevance increases, and combining Llama, Mistral, and Gemma leads to the steepest decline, particularly after 100 iterations. The same order was observed when evaluating factuality, although the loss was steadier, without clear convergence at the 100th iteration. 5.2 Temperature Variation Affects Outputs To further investigate the impact of decoding parameters on the models outputs, we conducted several experiments using Llama across spectrum of temperature parameter values, including 1 106, 0.25, 0.5, 0.75, and 1.0 on 30 randomly sampled documents from News2024. From Figure 5, higher temperature settings lead to greater factual and semantic degradation. At extremely low temperatures (1 106), factuality drops slightly in the first two iterations but stabilizes thereafter. As temperature increases, stability diminishes, and factuality gradually diverges. Figure 5: Impact of temperature variation on Llama outputs for 30 randomly sampled documents from the News2024 dataset, evaluated on the EN FR translation chain. Figure 6: Impact of the prompts level of constraint on noise accumulation measure on each of the metrics for Llama on 30 randomly sampled documents from the News2024 dataset in iterative translation Higher temperatures exacerbate this trend, with maximum temperature (1.0) causing the steepest decline, showing continuous divergence. Additional examples can be found in Appendix D. 5.3 Sensitivity of Iterative Translation Outputs to the Chosen Prompt We subsequently investigated the influence of the translation prompt on the outputs produced by the iterative process. To this end, 30 documents were randomly sampled from the News2024 dataset, and Llama was tasked with translating them using three distinct prompts characterized by varying levels of constraint: simple, base (used in all our experiments), and constrained. The complete prompts are provided in Appendix C. Figure 6 illustrates that the level of constraint imposed by the prompt markedly affects the models generation. Specifically, more constrained prompts were found to result in higher levels of relevance and factuality preservation."
        },
        {
            "title": "6 Discussion and Conclusion",
            "content": "As LLMs increasingly shape online content, the likelihood that they re-process their own outputs continues to rise. This study confirms that such iterative generation leads to progressive information distortion, akin to the broken telephone effect in human communication. Our findings from translation-based experiments are multifaceted. Effect of intermediate language(s) on information distortion. As found in Experiment 1, different language chains have varying levels of sensitivity to information distortion. As presented in Figure 2, we found that transmitting information between English and highly similar language significantly reduces the distortion effect, while transmitting through dissimilar language results in more pronounced distortion. We suggest that this variation in information retention and distortion stems from the proportion of each language encountered during the models training, with underrepresented languages experiencing greater distortion. Chains of higher complexity may result in higher levels of distortion. Experiments 2 and 3 showed that increasing the levels of complexity of chains can result in higher levels of distortion. Figure 3 illustrates how the combination of Llama and Mistral amplified the distortion in the chain when French served as the bridge language. However, when Thai was used as the bridge language, their collaboration helped reduce distortionlikely due to the stronger model (Llama) and the weaker model (Mistral) interacting with an intermediate language that may have been underrepresented in Mistrals training compared to Llama. Moreover, we observed that increasing the number of lan8 guages in the translation chain amplifies information distortion, likely due to the cumulative effects of longer generation sequences. In contrast, incorporating Gemma into the chain improved information retention, which we hypothesize stems from its larger parameter countone to two billion more than Llama and Mistral. We leave the broader impact of model scaling for future work. Information distortion can be reduced through temperature control and constrained prompting. Our findings suggest that while information distortion is unavoidable, it can be significantly mitigated through careful control of the models generation temperature. Figure 5 shows that higher temperature values lead to greater distortion in the outputs, which we attribute to increased model creativity. higher temperature encourages the generation of atypical tokens that may not fully preserve the meaning of the source document. Additionally, our analysis of prompt effects revealed that less constrained prompts contribute to greater noise accumulation over multiple iterations, resulting in higher divergence from the original meaning. These findings underscore the need for strategies to mitigate such degradation and ensure the reliability of AI-generated content."
        },
        {
            "title": "Limitations",
            "content": "While our study uses datasets from three different domainsbook summaries, movie scripts, and newsthey share similar characteristics and may not capture the rare or long-tailed information typical of specialized domains. Additionally, due to computational resource constraints, our experiments focus on models with seven to nine billion parameters. Future work should explore whether datasets from specialized domains and larger models influence the levels of information distortion in iterative generation chains."
        },
        {
            "title": "References",
            "content": "Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 6572, Ann Arbor, Michigan. Association for Computational Linguistics. Christine A. Caldwell and Alan E. Millen. 2008. Studying cumulative cultural evolution in the laboratory. In Proceedings of the 30th Annual Conference of the Cognitive Science Society, pages 16651670. Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. 2024. Scaling synthetic data creation with 1,000,000,000 personas. arXiv preprint arXiv:2406.20094. I-Chun (Steffi) Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, and Pengfei Liu. 2023. FacTool: Factuality detection in generative AIa tool augmented framework for multi-task and multi-domain scenarios. arXiv preprint arXiv:2307.13528. Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton, and Julia Kempe. 2024. tale of tails: Model collapse as change of scaling laws. arXiv preprint arXiv:2402.07043. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Shi Fu, Sen Zhang, Yingjie Wang, Xinmei Tian, and Dacheng Tao. 2024. Towards theoretical understandings of self-consuming generative models. arXiv preprint arXiv:2402.11778. Mingmeng Geng and Roberto Trotta. 2024. Is chatgpt transforming academics writing style? arXiv preprint arXiv:2404.08627. Philip John Gorinski and Mirella Lapata. 2015. Movie script summarization as graph-based scene extraction. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 10661076, Denver, Colorado. Association for Computational Linguistics. Nicolas Guerin, Shane Steinert-Threlkeld, and Emmanuel Chemla. 2024. The impact of syntactic and semantic proximity on machine translation with backtranslation. arXiv preprint arXiv:2403.18031. Yanzhu Guo, Guokan Shang, and Chloé Clavel. 2024a. Benchmarking linguistic diversity of large language models. arXiv preprint arXiv:2412.10271. Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, and Chloé Clavel. 2024b. The curious decline of linguistic diversity: Training language models on synthetic text. In Findings of the Association for Computational Linguistics: NAACL 2024, pages 35893604, Mexico City, Mexico. Association for Computational Linguistics. Hayden Helm, Brandon Duderstadt, Youngser Park, and Carey E. Priebe. 2024. Tracking the perspectives of interacting language models. arXiv preprint arXiv:2406.11938. 9 Robert Hitchcock, Robert Whallon, and William Information and Its Role in HunterLovis. 2011. Gatherer Bands. Cotsen Institute of Archaeology Press at UCLA. Taojun Hu and Xiao-Hua Zhou. 2024. Unveiling llm evaluation focused on metrics: Challenges and solutions. ArXiv, abs/2404.09135. Hasan Iqbal, Yuxia Wang, Minghan Wang, Georgi Georgiev, Jiahui Geng, Iryna Gurevych, and Preslav Nakov. 2024. Openfactcheck: unified framework for factuality evaluation of LLMs. arXiv preprint arXiv:2408.11832. Albert Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. arXiv preprint arXiv:2310.06825. Wojciech Kryscinski, Nazneen Rajani, Divyansh Agarwal, Caiming Xiong, and Dragomir Radev. 2021. longBooksum: collection of datasets for arXiv preprint form narrative summarization. arXiv:2105.08209. Benjamin LeBrun, Alessandro Sordoni, and Timothy ODonnell. 2022. Evaluating distributional distortion in neural language modeling. arXiv preprint arXiv:2203.12788. Yucheng Li, Frank Guerin, and Chenghua Lin. 2024a. Latesteval: Addressing data contamination in language model evaluation through dynamic and timeIn Proceedings of the sensitive test construction. AAAI Conference on Artificial Intelligence, volume 38, pages 1860018607. Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, and Eugene Ie. 2024b. Improving multi-agent debate with sparse communication topology. arXiv preprint arXiv:2406.11776; arXiv:2407.02030. Chin-Yew Lin. 2004. ROUGE: package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 7481, Barcelona, Spain. Association for Computational Linguistics. Jiaming Luo, Colin Cherry, and George Foster. 2024. To diverge or not to diverge: morphosyntactic perspective on machine translation vs human translation. Transactions of the Association for Computational Linguistics, 12:355371. Kelly Marchisio, Kevin Duh, and Philipp Koehn. 2020. When does unsupervised machine translation work? In Proceedings of the Fifth Conference on Machine Translation, pages 571583, Online. Association for Computational Linguistics. Ilia Markov, Kseniia Kharitonova, and Elena Grigorenko. 2023. Language: Its origin and ongoing evolution. Journal of Intelligence, 11(4):61. Alex Mesoudi and Andrew Whiten. 2008. The multiple roles of cultural transmission experiments in understanding human cultural evolution. Philosophical Transactions of the Royal Society B, 363(1509):3489 3501. Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. FActScore: Fine-grained atomic evaluation of factual precision in long form text generation. arXiv preprint arXiv:2305.14251. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics. Joon Sung Park, Joseph OBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122. Jérémy Perez, Corentin Léger, Grgur Kovaˇc, Cédric Colas, Gaia Molinaro, Maxime Derex, PierreYves Oudeyer, and Clément Moulin-Frier. 2024. When llms play the telephone game: Cumulative changes and attractors in iterated cultural transmissions. arXiv preprint arXiv:2407.04503. Andrew Peterson. 2024. Ai and the problem of knowledge collapse. arXiv preprint arXiv:2404.03502. Chau Pham, Boyi Liu, Yingxiang Yang, Zhengyu Chen, Tianyi Liu, Jianbo Yuan, Bryan A. Plummer, Zhaoran Wang, and Hongxia Yang. 2023. Let models speak ciphers: Multiagent debate through embeddings. arXiv preprint arXiv:2310.06272. Maja Popovic. 2015. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392395, Lisbon, Portugal. Association for Computational Linguistics. Chantal Shaib, Joe Barrow, Jiuding Sun, Alexa Siu, Byron Wallace, and Ani Nenkova. 2024. Standardizing the measurement of text diversity: tool and comparative analysis of scores. arXiv preprint arXiv:2403.00553. Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023. The curse of recursion: Training on generated data makes models forget. arXiv preprint arXiv:2305.17493. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024. Gemma 2: 10 Improving open language models at practical size. arXiv preprint arXiv:2408.00118. Adaku Uchendu, Jooyoung Lee, Hua Shen, Thai Le, Dongwon Lee, et al. 2023. Does human collaboration enhance the accuracy of identifying llm-generated deepfake texts? In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, volume 11, pages 163174. Yuxia Wang, Revanth Gangi Reddy, Zain Muhammad Mujahid, Arnav Arora, Aleksandr Rubashevskii, Jiahui Geng, Osama Mohammed Afzal, Liangming Pan, Nadav Borenstein, Aditya Pillai, Isabelle Augenstein, Iryna Gurevych, and Preslav Nakov. 2023. Factcheck-GPT: End-to-end fine-grained documentlevel fact-checking and correction of LLM output. arXiv preprint arXiv:2311.09000. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W. White, Doug Burger, and Chi Wang. 2023. Autogen: Enabling next-gen llm applications via multi-agent conversation. arXiv preprint arXiv:2308.08155. Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. 2023. survey on multimodal large language models. arXiv preprint arXiv:2306.13549. Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, and Shumin Deng. 2024. Exploring collaboration mechanisms for LLM agents: social psychology view. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14544 14607, Bangkok, Thailand. Association for Computational Linguistics. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2019. Bertscore: ArXiv, Evaluating text generation with bert. abs/1904.09675."
        },
        {
            "title": "A Additional Details",
            "content": "All experiments were conducted using NVIDIA A100 (40GB VRAM) and A10 (24GB VRAM) GPU clusters. The compute allocation totaled 54 GPU-days, comprising 36 GPU-days on 8A100 nodes and 18 GPU-days on 4A10 nodes."
        },
        {
            "title": "B Experiments Results Visualizations",
            "content": "We hereby present the complement of the visualizations of results from sections 4.1 and 4.3 B.1 Experiment 1: Bilingual Self-loop B.1.1 Llama Figure 7: Results of Llama in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the BookSum dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) Figure 8: Results of Llama in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the ScriptBase-alpha dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) B.1.2 Mistral Figure 9: Results of Mistral in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the News2024 dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) Figure 10: Results of Mistral in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the BookSum dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) 13 Figure 11: Results of Mistral in the Bilingual Self-loop Experiment showing metrics evolution across translation iterations over the ScriptBase-alpha dataset for French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) B.2 Experiment 3: Multilingual Multiplayer Figure 12: Results of Experiment 3 showing metrics evolution across translation iterations over the News2024 dataset. Setting 1 presents the translation chain of English with the bridge languages French and Thai. Setting 2 maintains the same chain as Setting 1, while adding Gemma to the set of models. Setting 3 further add the bridge languages Chinese and German to the chain from Setting 1."
        },
        {
            "title": "C Generation Prompts",
            "content": "You are translation expert. Given passage, source language, and target language, translate the passage from the source language to the target language while preserving all the original meaning and without losing any context. Do not write an introduction or summary. Return only the translated passage. Translate the following text from {source_language} to {target_language}: {document} Figure 13: Base (main) translation Prompt for the translation chains experiments Translate the following text from {source_language} to {target_language}: {document} Figure 14: Simple translation Prompt for the prompt ablation You are translation expert. Please follow these instructions carefully: - Task: You will receive paragraph in {source_language}. - Objective: Translate the paragraph into {target_language}. - Guidelines: - Do not write an introduction or summary. - Preserve the original meaning entirely; ensure no information is lost or altered. - Do not add, omit, or modify any details from the original paragraph. - Maintain the tone and style as closely as possible. - Paragraph: {document} Figure 15: Constrained translation Prompt for the prompt ablation Given passage, rephrase it while preserving all the original meaning and without losing any context. Do not write an introduction or summary. Return only the rephrased passage. Rephrase the following text: {document} Figure 16: Rephrasing prompt used for the rephrasing task"
        },
        {
            "title": "D Examples Analysis",
            "content": "Temperature 1e-16: UEFA has imposed fines on the English Football Association and the Football Association of Ireland after their national anthems were booed before Ireland played England in the Nations League in September. Temperature 0.25: The Union of European Football Associations (UEFA) has imposed fines on the England Football Association and the Football Association of Ireland after their national anthems were booed before Ireland played England in the Nations League in September. Temperature 0.5: The UEFA Football Federation has sanctioned the England Football Association and the Football Association of Ireland after their national anthems were insulted before Ireland played England in the Nations League in September. Temperature 0.75: The UEFA Football Federation has sanctioned the Football Association (FA) of England and the Football Association of Ireland (FAI) after their national anthems were deemed offensive before the UEFA Nations League match between England and Ireland in September. Temperature 1: The Football Association (FA) of England and the Football Association of Ireland (FAI) have been sanctioned by the Union of European Football Associations (UEFA) due to incidents that occurred prior to the UEFA Nations League match between England and Ireland in September. Table 3: An example of news article highlighting the effect of temperature variation on the iterative translation process with English as the source language and French as the bridge language using Llama after 100 iterations. Color key: Entities, Financial Actions, Cultural Elements, Controversial Outcomes, Events/Locations, Emergent Details."
        }
    ],
    "affiliations": [
        "Ecole Polytechnique",
        "MBZUAI",
        "SISSA"
    ]
}