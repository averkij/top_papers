{
    "paper_title": "CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving",
    "authors": [
        "Changxing Liu",
        "Genjia Liu",
        "Zijun Wang",
        "Jinchang Yang",
        "Siheng Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Vehicle-to-vehicle (V2V) cooperative autonomous driving holds great promise for improving safety by addressing the perception and prediction uncertainties inherent in single-agent systems. However, traditional cooperative methods are constrained by rigid collaboration protocols and limited generalization to unseen interactive scenarios. While LLM-based approaches offer generalized reasoning capabilities, their challenges in spatial planning and unstable inference latency hinder their direct application in cooperative driving. To address these limitations, we propose CoLMDriver, the first full-pipeline LLM-based cooperative driving system, enabling effective language-based negotiation and real-time driving control. CoLMDriver features a parallel driving pipeline with two key components: (i) an LLM-based negotiation module under an actor-critic paradigm, which continuously refines cooperation policies through feedback from previous decisions of all vehicles; and (ii) an intention-guided waypoint generator, which translates negotiation outcomes into executable waypoints. Additionally, we introduce InterDrive, a CARLA-based simulation benchmark comprising 10 challenging interactive driving scenarios for evaluating V2V cooperation. Experimental results demonstrate that CoLMDriver significantly outperforms existing approaches, achieving an 11% higher success rate across diverse highly interactive V2V driving scenarios. Code will be released on https://github.com/cxliu0314/CoLMDriver."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ] . [ 1 3 8 6 8 0 . 3 0 5 2 : r CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving Changxing Liu1,3* Genjia Liu1,3* Zijun Wang1,3 Jinchang Yang1,3 Siheng Chen1,2,3 1Shanghai Jiao Tong University 3Multi-Agent Governance & Intelligence Crew (MAGIC) {cx-liu,LGJ1zed,wzjinsjtu,andreo y,sihengc}@sjtu.edu.cn 2Shanghai AI Laboratory"
        },
        {
            "title": "Abstract",
            "content": "Vehicle-to-vehicle (V2V) cooperative autonomous driving holds great promise for improving safety by addressing the perception and prediction uncertainties inherent in single-agent systems. However, traditional cooperative methods are constrained by rigid collaboration protocols and limited generalization to unseen interactive scenarios. While LLM-based approaches offer generalized reasoning capabilities, their challenges in spatial planning and unstable inference latency hinder their direct application in cooperative driving. To address these limitations, we propose CoLMDriver, the first full-pipeline LLM-based cooperative driving system, enabling effective languagebased negotiation and real-time driving control. CoLMDriver features parallel driving pipeline with two key components: (i) an LLM-based negotiation module under an actor-critic paradigm, which continuously refines cooperation policies through feedback from previous decisions of all vehicles; and (ii) an intention-guided waypoint generator, which translates negotiation outcomes into executable waypoints. Additionally, we introduce InterDrive, CARLA-based simulation benchmark comprising 10 challenging interactive driving scenarios for evaluating V2V cooperation. Experimental results demonstrate that CoLMDriver significantly outperforms existing approaches, achieving an 11% higher success rate across diverse highly interactive V2V driving scenarios. Code will be released on https://github.com/cxliu0314/CoLMDriver. 1. Introduction Vehicle-to-vehicle (V2V) cooperative autonomous driving (AD) aims to improve driving performance by allowing autonomous vehicles to communicate with surrounding ve- *Equal contribution Corresponding author Figure 1. Negotiation with critic feedback. CoLMDriver refines cooperation policy by evaluating the latest negotiation outcomes. hicles. Unlike single-vehicle autonomous driving [15], where each vehicle makes driving decisions based solely on the observations from its own sensors, cooperative driving enables vehicles to exchange driving-related data [6, 7]. This collaborative information-sharing mechanism helps autonomous vehicles surmount the inherent limitations in single-vehicle driving, such as incomplete environmental perception [811] and uncertainty in forecasting the future states of surrounding traffic participants [12, 13]. Traditional cooperative driving approaches can be generally categorized into optimization-based and learning-based methods. Optimization-based cooperative driving methods [12, 14, 15] formulate multi-vehicle planning as constrained optimization problems to determine optimal actions. However, these methods depend on precise environmental modeling and require task-specific optimization objectives and constraints, making them inherently limited in handling unknown scenarios. Learning-based methods [16 1 18] employ reinforcement learning and imitation learning to develop cooperative driving policies. While these approaches have been applied to several driving tasks [1921], they struggle with declined performance when encountering unseen multi-vehicle interaction patterns [22, 23]. These limitations underscore the exploration towards more flexible and generalizable cooperative driving framework. Recently, large language models (LLMs) have gained significant attention in cooperative systems [24, 25] due to their remarkable reasoning abilities and vast knowledge. This advancement underscores the potential of LLMbased cooperative driving, where vehicles negotiate through natural language. Compared to optimization-based and learning-based approaches, LLM-based cooperation offers two key advantages. First, language-based cooperation offers greater flexibility compared to fixed-protocol communication [12], as it can incorporate both local motion details and global scene semantics. Second, with extensive pre-trained commonsense knowledge, LLMs have demonstrated strong capabilities in understanding traffic scenarios and making driving decisions [2628]. This indicates their potential to handle diverse multi-vehicle driving scenarios, including complex cases such as navigating non-traffic-light intersections. However, integrating LLMs into cooperative driving faces three challenges. First, LLMs limited ability to understand and plan in continuous road spaces makes direct application infeasible [29], requiring additional spatial information for effective cooperation. Second, redundant environmental information and unconstrained negotiation reduce efficiency, necessitating selective communication with relevant collaborators. Third, LLMs long and unstable inference delays hinder high-frequency planning, demanding efficient negotiation and inference mechanisms to adapt to real-time control. To address these challenges, we propose CoLMDriver (Cooperative Language-Model-based Driver), the first full pipeline (from sensor data to control signal) LLM-based cooperative driving system that accommodates real-time control with efficient planning negotiation. CoLMDriver coni) An end-to-end sists of two parallel planning pipelines: driving pipeline for real-time vehicle control, inherently capable of full driving functionality. To integrate languagebased negotiation, we incorporate it with an intentionguided waypoint planner that translates high-level negotiation outcomes into executable waypoints. ii) cooperative planning pipeline, implemented via an LLM-based negotiation module. To enhance the effectiveness and efficiency of negotiation, we propose three key techniques. First, we introduce an Actor-Critic feedback mechanism that evaluates negotiation outcomes and feeds the results back to the LLM-based negotiator, enabling continuous policy refinement as shown in Fig 1. This evaluation considers both high-level intentions and low-level waypoints, providing feedback from safety, efficiency, and multi-vehicle consensus perspectives. Second, we propose dynamic grouping mechanism to select relevant collaborators for negotiation, improving efficiency by focusing on critical agents. Third, we integrate an auxiliary VLM-based intention planner to handle non-cooperation periods. This system offers two key advantages. First, it effectively integrates LLM-based cooperative planning with finegrained waypoint generation. LLM-derived driving intentions guide waypoints generation, and the waypoints provide feedback to refine cooperation strategies, forming an online optimization loop. Second, its parallel framework accommodates asynchronous planning, mitigating the inherent inference latency gap between the LLM and the endto-end pipeline. To evaluate performance in V2V scenarios, we introduce InterDrive (Interactive Driving) benchmark, which constructs 10 challenging traffic scenarios in the CARLA simulator [30]. These scenarios involve multiple autonomous vehicles with severely conflicting routes, testing an AD systems ability to handle highly interactive V2V situations. We evaluate CoLMDriver on both InterDrive benchmark and the public Town05 benchmark [2]. Results indicate that CoLMDriver surpasses existing single-vehicle and cooperative driving methods, achieving an 11% higher success rate across diverse scenarios. To sum up, our contributions are: We propose CoLMDriver, the first full pipeline LLMbased cooperative driving system, featuring two main components: an LLM-based negotiator with Actor-Critic feedback, and an intention-guided waypoints planner to translate negotiation outcomes. We introduce InterDrive Benchmark, which includes 10 types of challenging scenarios to enable the evaluation of autonomous driving in handling V2V interactions. We conduct comprehensive experiments and validate that CoLMDriver achieves superior success rate in various V2V driving scenarios. 2. Related works 2.1. End-to-end Autonomous Driving key research direction in end-to-end autonomous driving is imitation learning, which aims to replicate expert driving behaviors by fitting model to recorded driving data. Recent advancements focus on several core areas to improve driving performance and robustness. Some methods, such as NEAT [31], TransFuser [2], UniAD [3], InterFuser [1], and ReasonNet [5], leverage transformer architectures to capture more nuanced representations of driving scenarios, enhancing the models ability to process complex environments. Other approaches, like MP3 [32], UniAD, LAV [33], TCP [34], incorporate auxiliary tasks that provide additional learning signals to support the primary driving task, 2 leading to better generalization. However, the IL approach struggles with low generalization to unseen scenarios and lacks causal reasoning. To overcome these issues, we propose an LLM-based method to achieve generalized reasoning ability in diverse interactive scenarios. 2.2. MLLMs-based Driving recent In the field of autonomous driving (AD), research [26, 3537] has integrated LLMs into AD systems to improve interpretability and facilitate human-like interactions. Some studies [28, 3840] leverage VLMs to process multi-modal input data, providing both descriptive text and control signals suited to driving scenarios. LMDrive [27] integrates multi-modal sensor data with textual instructions, leveraging LLMs for closed-loop end-to-end AD. Most current research focuses on using LLMs to enhance individual driving capabilities, while few works explore driving cooperation. AgentsCoDriver [36] promotes lifelong learning through interaction with the environment, enabling simple negotiations between agents. CoDrivingLLM [41] centered around roadside units for vehicle-tovehicle negotiations to resolve conflicts. However, these approaches are limited to discrete decisions and cannot generate executable control signals. They also overlook the inference latency of LLM, making real-world deployment challenging. To bridge these gaps, we propose CoLMDriver, an LLM-based cooperative system that generates real-time driving signals through parallel framework. 3. Problem Formulation Consider agents participate in the cooperation. Let Xi and Di be the observation and the destination of the ith agent. The objective of collaborative driving is to achieve the maximized driving performance of all agents; that is, arg max θ,M (cid:88) i=1 d(Φθ(Xi, Di, Mk )) (1) where d() is the driving performance metric, Φ is the driving framework with trainable parameter θ. Mi is the message exchange between agent and other agents, which can iterate rounds. Here we focus on leveraging the flexibility of language to achieve planning consensus and improve overall performance, where Mk j=1]k represents multi-round language-based negotiation process. = [{Mij}N 4. Methodology This section introduces CoLMDriver, cooperative driving system that leverages language-based negotiation and planning to enhance the collective driving capabilities of multiple autonomous vehicles. We start by outline the overall system architecture in Sec. 4.1, followed by detailed composition of two parallel pipelines in Sec. 4.2, 4.3. 4.1. Overall Architecture As illustrated in Fig. 2, CoLMDriver operates through parallel driving pipeline designed to tackle the latency challenges of negotiation without disrupting the normal execution of the downstream planner. The high-level guidance generation pipeline conducts deep reasoning at relatively low frequency to formulate comprehensive and consensusdriven driving intentions, while the low-level perceptionplanning-control pipeline runs at high frequency to ensure real-time vehicle control."
        },
        {
            "title": "The",
            "content": "high-level orchestrates cooperative pipeline i) decision-making through two core components: LLM-based negotiation module under the Actor-Critic paradigm, where LLMs enable multi-round negotiation between vehicles to reach consensus on driving policy, guided by feedback from the evaluator; ii) VLM-based intention planner, which generate high-level driving intentions by synthesizing multi-modal environmental context. The VLM intention planner continuously refines driving intentions based on textual descriptions of the current state, detected objects from the low-level perception module and the front camera input. If conflicts are predicted, the LLM negotiation module first conduct dynamic graph grouping with surrounding vehicles to form negotiation groups, and then takes current driving intention and engages in multi-round negotiation process with guidance from evaluator. The negotiation results and intention guidance are then fed back into the low-level waypoint planner to guide precise planning. The low-level pipeline follows the perception-planningcontrol structure. When receiving the sensor data, the perception module generates object-level 3D information and BEV perception features, conducting spatial understanding as auxiliary inputs for planning tasks. To translate language-based information into actionable waypoints, the key component is the intention-guided waypoint planner, which leverages both perception features and high-level planning intentions to generate waypoints. These waypoints are converted into control signals by the control module, resulting in improved cooperative driving outcomes. 4.2. High-level Guidance Layer The high-level guidance pipeline is responsible for strategic decision-making and cooperative negotiation, enhancing driving adaptability through semantic reasoning and multi-agent consensus. It consists of two core components: the VLM-based intention planner and the LLM-based negotiation module. The negotiation results guide the low-level planner during the negotiation process, while the VLM output takes precedence when no negotiation is activated. 3 Figure 2. Overall architecture of CoLMDriver. CoLMDriver operates through parallel driving pipeline, where language negotiation assists in the planning process through asynchronous connection of three component: i) an LLM-based negotiation module under the Actor-Critic paradigm; ii) VLM-based intention planner and iii) an intention-guided waypoint planner. 4.2.1. LLM-based Negotiation Module The LLM-based negotiation module engages in multiple rounds of dialogue with surrounding intelligent vehicles, resolving predicted conflicts by reaching consensus on driving policies. Given the negligible latency in LLM inference, the negotiation system focuses on how to efficiently achieve consensus on optimized driving policy. To ensure the generalizability of negotiations, we avoid imposing strict output formats or rigid communication rules. However, overly unrestricted negotiations may struggle to converge on consensus. The key innovation lies in incorporating an ActorCritic paradigm within the negotiation system. The ActorCritic paradigm is reinforcement learning approach where the actor selects actions based on current policies, while the critic evaluates the chosen actions by providing feedback on their quality, enabling faster convergence towards In our method, the LLM-based negooptimal outcomes. tiators act as the actors and the evaluator as the critic. By providing feedback based on dialogue quality, safety, and efficiency expectations, we leverage the in-context learning capabilities of LLMs to facilitate rapid convergence in the negotiation process. The LLM-based negotiation module consists of three main components: i) The dynamic graph grouping mechanism, which identifies agents with negotiation needs and establishes communication in dynamic traffic scenarios, ii) The LLM-based negotiator, which conducts negotiations with grouped agents using natural language and iii) The negotiation quality evaluator, which acts as critic, providing feedback to the negotiator to accelerate consensus achievement. Overall Process. Once the negotiation process begins, vehicles first form negotiation groups using dynamic graph In each round, vehicles take turns grouping mechanism. speaking in designated order. The negotiation quality evaluator then assesses the situation, providing feedback on consensus, safety, and efficiency. The LLM-based negotiators incorporate this feedback into their input, adjust their driving intentions accordingly, and call the evaluator again. After several rounds, when the evaluator determines that consensus has been reached, the negotiation concludes, and the final driving intentions are passed on to the downstream planners of each vehicle. Dynamic Graph Grouping Mechanism. It is crucial for vehicles to determine who and when to communicate with. To address this challenge, we prioritize vehicle groups that are most likely to conflict and build communication graph to promote effective negotiation. We assume that vehicles can automatically establish communication within the range of their hardware and are capable of broadcasting essential information, such as their planned future waypoints. To better clarify the mutual influence between vehicles, we conduct dynamic grouping by constructing spatiotemporal vehicle graph. Each vehicle is treated as node, and vehicles that could potentially conflict in the future are connected by edges, which are calculated based on their safety scores derived from their waypoints. At any given moment, we build the spatial vehicle graph and apply Depth-First Search (DFS) to gather all connected vehicles into groups. To avoid inconsistent driving policies due to the constantly changing nature of dynamic groups, we preserve historical groups and merge intersecting groups across temporal dimension, obtaining comprehensive grouping result. The communication graph at time is constructed iterative: = HT , Ht = Φ(Ht1 Ct) (2) 4 Ct = (cid:91) DFS(V t, {(vi, vj) Ss(vi, vj) θ}) (3) points, calculated by the carefully designed formula: where safety score Ss determines edges and Φ() merges all groups that intersect between history group Ht1 and current group Ct. Negotiations are then carried out within each group, allowing for local optimization of driving policies, which contributes to improved overall performance. LLM-based negotiator. The LLM-based negotiator conducts human-like language negotiation with other vehicles in the group. Inputs include ego vehicles current speed, intention, other cars broadcast information, history conversation and critics suggestion if exist. Since the inference time of an LLM is proportional to the output length, we have carefully designed the prompts to ensure concise information transmission and employed prompt caching techniques to maintain timeliness. The LLM-based negotiator integrates the shared information from group members, consider past conversations, and combine feedback from evaluators to output information that may include self actions, requests or responses to others. In group that has vehicles, the negotiator output of the ith vehicle at round is:"
        },
        {
            "title": "OLLMK",
            "content": "i = LLMi(fP( (cid:91) Ij, (cid:91) (cid:91) j=0 k=0 j="
        },
        {
            "title": "OLLMk",
            "content": "j , SK1) (4) where denotes the current information shared by vehicles in the group, including speed, intention, and position, and the evaluators suggestion, fP the prompt generation process. Since the used LLM is not trained on specific domain, this paradigm differs from previous multi-vehicle cooperative driving approaches by not requiring each vehicle to be equipped with specific model, demonstrating the versatility and broad applicability of LLM. Negotiation Quality Evaluator. The negotiation quality evaluator acts as critic, assessing the negotiation performance based on future planning and generating feedback related to consensus, safety, and efficiency concerns. The evaluation process follows three key steps: sum, score, and criticize. To initiate the evaluation, the evaluator can be activated on random vehicle within the group. Based on the current round conversation, the evaluator first sums each vehicles actions using LLM, transforming them into driving intention formats, and then distributes the results to all vehicles. Each vehicles waypoint planner uses the summed intentions as input, generates planned waypoints, and broadcasts these plans to assist in the evaluation. The evaluator conducts the scoring process by assessing three key aspects consensus, safety, and efficiency. Consensus score Sc is judged by LLM, indicating whether every vehicle in the group is willing to execute the reached policy. Both safety score Ss and efficiency score Se are derived from the waySk = LLMc( (cid:91) j="
        },
        {
            "title": "OLLMk",
            "content": "j ), [Sk , Sk ] = F( (cid:91) Wj) (5) j=0 where is the predicted waypoints and the score calculation formula. Finally, the evaluator provides feedback through classifier Ψ, criticizing scores that fail to meet the required standards. = Ψ(Sk , Sk , Sk ) (6) This criticism is used as input for the next round of negotiation, guiding the system towards an optimal driving policy by encouraging faster convergence. 4.2.2. VLM-based Intention Planner The VLM-based intention planner utilizes the generalized knowledge embedded in language models to recognize unusual objects and deal with complex scenes, providing more holistic decision support. The focus is to provide optimal high-level driving intention to accurately guide the downstream planner. To comprehensively and efficiently activate the understanding and decision-making capabilities of the VLM-based intention planner, we have carefully designed hierarchical prompt generation process and limited output format. The prompt contains perception results written in an intelligible format, providing accurate environment information. To collect reasonable driving intention in different environments, we use V2Xverse [8] platform and employ an expert agent [1] to record driving data, capturing wide range of urban scenarios. Driving intentions are defined as navigation intentions and speed intentions. Navigation intentions are derived from the ground truth navigation instructions, while speed intentions are extracted from the experts driving speed. To adapt the VLM to the specific task of driving intention assessment, we utilize the processed driving data for transfer learning based on LoRA. 4.3. Low-level Planning Layer The low-level planning layer focuses on real-time execution, translating high-level intentions into geometrically feasible trajectories and control commands. The key component is the intention-guided waypoint planner, operating at high frequency to conduct precise planning guided by driving intentions. 4.3.1. Intention-guided Waypoint Planner The Intention-guided waypoint planner acts bridge connecting high-level driving intentions and low-level implementation paths. The challenge lies in how to precisely map high-level intentions to specific scenarios as usable waypoints. Our design consists of two main parts: intentionto-waypoint data generation and the model structure. 5 5. InterDrive Test Benchmark To evaluate the capabilities of autonomous driving systems in handling multi-vehicle interaction, we present the InterDrive benchmark on top of V2Xverse simulation platform. This benchmark encompasses 10 types of typical multivehicle scenarios, each involving multiple under-test vehicles. We assign these vehicles with largely overlapped target paths to encourage conflicts, and randomly deploy additional traffic participants (vehicles, pedestrians, cyclists) as obstacles. These scenarios are constructed to simulate realistic traffic scenarios where several on-road vehicles are autonomous-driven. 5.1. Scenarios Fig 4 visualizes the 10 scenarios in InterDrive Benchmark, where we construct traffic scenarios with reference to the pre-crash typology of the US National Highway Traffic Safety Administration (NHTSA). Through these scenarios, we assess three typical scenarios in handling multi-vehicle interaction, including crossing intersections, lane merging, and lane changing. *Intersection Crossing (IC). Several vehicles enter, meet, and then exit an intersection from different directions. Four distinct types of scenarios are incorporated, with visual representations shown in Fig 4(a)-(d). To ensure comprehensive evaluation diversity, we carefully design different combinations of entry and exit directions for the vehicles at the intersection. *Lane Merging (LM). Vehicles merge into the same lane from different directions, see visualizations in Fig 4(e)-(h). We construct scenarios in different road topologies, including parallel straight-ahead lanes, T-junctions, and highway ramps. *Lane Changing (LC). This study defined two distinct lane-changing scenarios. In these scenarios, multiple vehicles initially maintain parallel trajectories while traveling in the same direction. Subsequently, they are required to execute lane-changing maneuvers, intersecting the trajectories of adjacent vehicles to reach their respective destinations. See visualizations in Fig 4(i),(j). InterDrive benchmark extends each scenario through diverse configurations, varying in route waypoints, the number of vehicles under test, and additional obstacles, ultimately generating 92 distinct test tasks. The number of interactive test vehicles is configured to range from 2 to 8, simulating the typical number of vehicles with which single vehicle may have direct conflicts simultaneously. 5.2. Metrics InterDrive incorporates five metrics: Route Completion, Infraction Score, and Driving Score, which are adopted from CARLA Leaderboard [43], along with additional metrics: Success Rate Figure 3. Model architecture of the low-level Transformer-based intention-guided waypoint planner. Intention-to-waypoint Data Generation. To achieve precise intention-guided waypoints generation, we use waypoints of expert agent as reference and generate waypoints that align with the intended action while satisfying practical scenario constraints. Based on the observation that acceleration is influenced by surrounding objects density, we extract the actual waypoints of the referenced vehicle and interpolate them using an environment-adaptive acceleration model, which generates elaborate waypoints corresponding to different driving intentions. Given ground-truth waypoints , the data generation process can be expressed as Wg = Φ(W, a). Here, the acceleration = (I, x, σ) is guided by the intention and generated by the environmentadaptive acceleration model , considering the distance to the nearest vehicle and the vehicle density σ. The generated waypoints Wg is interpolated by function Φ, which conforms to driving norms and adapts to environmental conditions. Model Structure. To ensure waypoints align with different driving intentions within the same scenario, we developed Transformer-based, intention-guided waypoint planner, as shown in Fig. 3. The model effectively takes input from the BEV occupancy map and BEV features from previous frames, which are processed by the MotionNet [42] encoder to capture the environmental context. Additionally, goal-oriented inputs, including target points, navigation intentions, and speed intentions, are fused through MLP Fuser to form the guidance context. multi-layer Transformer decoder performs cross-attention between waypoint query and the environmental/guidance contexts, followed by Waypoints Decoder to generate sequence of waypoints. These waypoints are then passed to the control module to produce the necessary control signals. 6 (a) Cross:Straight-Straight (b) Cross:Straight-Left (c) Cross:Opposite Lane (d) Cross:Chaos (e) Merge:Straight-Right (f) Merge:Neighbor Lane (g) Merge:Left-Right (h) Merge:Highway (i) Change:Right-Straight (j) Change:Highway Figure 4. The 10 types of scenarios in the proposed InterDrive benchmark. These scenarios evaluate the three key skills in handling interaction among nearby vehicles, including going cross intersections (a-d), lane merging (e-h), and lane changing (i-j). Route Completion (RC) is the percentage of the total planned route distance completed by the under-test vehicles. Infraction Score (IS) starts at 1.0 for each task and reduced with collisions by predefined discount factor, evaluating all test vehicles safety perfeomance. Driving Score (DS) serves as the primary ranking metric, and is calculated as the product of Route Completion and Infraction Score, capturing both task progress and safety. Success Rate (SR) is the percentage of tasks completed with full-mark Driving Score, reflecting the consistency of the system to achieve reliable driving performance. These metrics collectively provide comprehensive view of navigation performance in multi-vehicle driving scenarios. 6. Experiments 6.1. Experimental Settings We implement and evaluate our method on the CARLA simulator of version 0.9.10.1 [30]. The simulation frequency is set to 5 Hz for all experiments except real-time ablation. For the low-level pipeline in the CoLMDriver framework, we deploy PointPillars [44] to encode point clouds. We use Lora finetuning [45] for InternVL2-4B [46] as the VLM intention planner and Qwen2.5-3B [47] as the LLM negotiator, for both accuracy and efficiency consideration. For the intention-waypoints translator, we use an embedding size of 256 and medium feature size of 256 as well, with 20 output waypoints at 5 Hz. 6.2. Quantitative Results of Closed-loop driving Performance in Highly Interaction Traffic Scenarios. Tab. 1 presents CoLMDrivers driving performance in our proposed InterDrive Benchmark, compared to other advanced closed-loop driving baselines, including TCP [34], VAD [4], UniAD [3], CoDriving [8], and another VLMbased method, LMDrive [27]. To prove the necessity of negotiation, we build the Rule-based method on traffic norms as comparison. Optimization-based cooperative planning methods are not compared due to being closed-source or on other platform. The table shows the overall score under InterDrive and separate performance for InterDrive-IC, InterDrive-LM and InterDrive-LC. CoLMDriver achieves SOTA performance on driving score(DS) across all interactive scenarios due to its language negotiation capability, outperforming other baselines by at least 10.15% in DS. The three cooperative driving methods all outperform single-agent driving approaches, demonstrating the effectiveness of cooperation in conflict resolution. Other baselines face challenges such as target recognition issues, leading to lower route completion(RC), or collision incidents due to the lack of negotiation, resulting in low infraction scores(IS). TCP achieves relatively high driving score but struggles with low success rate (SR), indicating frequent collisions among scenes. LMDrive benefits from its multiview, multimodal input and LLM capability, achieving high infraction score, but encounters challenges in driving interruption where two cars come to stop due to close proximity, each yielding to the other without progressing. Both intention-conflict collisions and dual-yielding issues can be resolved through language negotiation. Consensus Convergence. Fig. 5 presents the negotiation quality score distribution of the evaluator for system with or without critic feedback. When the LLM updates its negotiation messages based on conversation alone, the negotia7 Table 1. Driving performance in InterDrive Benchmark. CoLMDriver achieves the highest success rate in all scenarios."
        },
        {
            "title": "Method",
            "content": "VAD[4] UniAD[3] TCP [34] LMDrive [27] CoDriving [8] Rule-based CoLMDriver(Ours) DS 25.37 35.17 73.68 48.83 74.13 78.38 88.53 InterDrive-total RC IS 75.00 88.30 90.54 58.02 96.31 91.85 94.05 0.33 0.38 0.82 0.85 0.76 0.80 0. SR 0.02 0.11 0.50 0.20 0.57 0.72 0.80 InterDrive-IC IS RC 54.72 91.63 82.83 57. 90.57 95.93 88.78 0.29 0.41 0.94 0.79 0.71 0.81 0.86 DS 15.49 37.24 77.64 44.72 66.32 80.06 82. SR 0.00 0.11 0.50 0.17 0.61 0.72 0.72 InterDrive-LM IS RC 92.85 84.41 95.18 69. 100.00 100.00 99.93 0.40 0.47 0.86 0.86 0.96 0.94 0.98 DS 37.24 42.50 82.18 60.88 96.18 94.44 98. SR 0.05 0.15 0.70 0.30 0.75 0.90 0.92 DS 17.93 12.19 43.52 27.96 36.57 34.43 59. InterDrive-LC IS RC 76.00 90.57 96.30 29.70 100.00 62.29 82.50 0.26 0.12 0.45 0.95 0.37 0.42 0. SR 0.00 0.00 0.00 0.00 0.00 0.25 0.50 Table 2. Ablation study of system components. Nego : negotiation, S/E :safety/efficiency score, Cons: consensus score. ID Nego Grouping Critic S/E Cons DS RC IS SR 1 2 3 4 5 47.64 9.33 77.29 83.46 88.53 96.43 10.37 95.22 91.93 94.05 0.485 0.935 0.784 0.860 0. 0.130 0.000 0.652 0.739 0.804 Figure 5. Experiment of negotiation convergence guided by ActorCritic paradigm. tion quality score fluctuates randomly across rounds. However, when guided by evaluator feedback, the score exhibits steady increase as negotiation iterates. System Component Ablation. Tab. 2 evaluates the impact of different system components on performance. system without negotiation (ID 1) performs closely to LMDrive on DS, demonstrating solid baseline performance. However, negotiation without the dynamic grouping mechanism leads to continuous stopping, resulting in lower route completion. Incorporating the Actor-Critic paradigm into the negotiation module further enhances the driving score. Real-time Performance. We compare the performance in ideal computing situation(no inference latency) and situation with inference latency in Fig. 6 on the InterDriveLM. Our CoLMDriver experiences only 6.62% drop in driving score and still keeps driving score over 90, demonstrating the inference efficiency of the proposed system. In our framework, the low-level planning pipeline can continuously generate precise execution based on intention guidance within varying environment. TCP, operating faster than our ideal simulation, slightly increase its performance. Performance on public benchmark. We further investi8 Figure 6. aware/Ideal) accounting for inference latency. The driving performance with/without (Latencygate the general navigation capability of CoLMDriver on the public Town05 benchmark [2]. To enable V2V communication in this single-vehicle driving benchmark, we enable the surrounding vehicles to transmit their driving intention to the ego vehicle but do not change their own behaviors. Tab. 3 compares the driving CoLMDriver with two SOTA single-vehicle driving methods baseline methods. We can see that CoLMDriver achieves superior Driving Score in both long and short routes, and surpasses ReasonNet by 11% in Town05 Long. This is because CoLMDriver receives driving intention from neighbors, thereby reducing the uncertainty in planning. Table 3. Driving performance on Town05 benchmark [2]"
        },
        {
            "title": "Method",
            "content": "Town05 Short RC DS Town05 Long RC DS InterFuser [1] ReasonNet [5] CoLMDriver(Ours) 94.95 95.71 96.14 95.19 96.23 96.45 68.31 73.22 81. 94.97 95.88 96.72 7. Conclusion and limitation In this paper, we present CoLMDriver, an innovative autonomous driving system that leverages multimodal LLMs for effective language-based cooperative planning in endto-end driving. CoLMDriver employs high-level driving intention to guide low-level waypoints generation, and utilizes multi-round negotiation to achieve consensus in highly interactive scenarios. Meanwhile, we construct the InterDrive Benchmark to evaluate autonomous driving systems in such interactive environments. Extensive closed-loop experiments demonstrate the effectiveness of CoLMDriver, highlighting the significant potential of language-based negotiation for advancing cooperative driving. One current limit is the diversity of language interaction demonstrations, which we aim to expand in future work by constructing more complex and interactive scenarios, further enhancing the systems capability and adaptability."
        },
        {
            "title": "References",
            "content": "[1] Hao-Chiang Shao, Letian Wang, Ruobing Chen, Hongsheng Li, and Yu Tang Liu. Safety-enhanced autonomous driving using interpretable sensor fusion transformer. In Conference on Robot Learning, 2022. 1, 2, 5, 8 [2] Aditya Prakash, Kashyap Chitta, and Andreas Geiger. Multimodal fusion transformer for end-to-end autonomous driving. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 70737083, 2021. 2, 8 [3] Yi Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wen Wang, Lewei Lu, Xiaosong Jia, Qiang Liu, Jifeng Dai, Yu Qiao, and Hongyang Li. Planning-oriented autonomous driving. 2022. 2, 7, 8 [4] Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang, and Xinggang Wang. Vad: Vectorized scene representation for efficient autonomous driving. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 83408350, 2023. 7, 8 [5] Hao Shao, Letian Wang, Ruobing Chen, Steven L. Waslander, Hongsheng Li, and Yu Liu. Reasonnet: End-to-end driving with temporal and global reasoning, 2023. 1, 2, 8 [6] Ruiqi Zhang, Jing Hou, Florian Walter, Shangding Gu, Jiayi Guan, Florian Rohrbein, Yali Du, Panpan Cai, Guang Chen, and Alois Knoll. Multi-agent reinforcement learnarXiv preprint ing for autonomous driving: survey. arXiv:2408.09675, 2024. [7] Yushan Han, Hui Zhang, Huifang Li, Yi Jin, Congyan Lang, and Yidong Li. Collaborative perception in autonomous drivIEEE Intelligent ing: Methods, datasets, and challenges. Transportation Systems Magazine, 15(6):131151, 2023. 1 [8] Genjia Liu, Yue Hu, Chenxin Xu, Weibo Mao, Junhao Ge, Zhengxiang Huang, Yifan Lu, Yinda Xu, Junkai Xia, Yafei Wang, et al. Towards collaborative autonomous driving: Simulation platform and end-to-end system. arXiv preprint arXiv:2404.09496, 2024. 1, 5, 7, 8 [9] Yue Hu, Shaoheng Fang, Zixing Lei, Yiqi Zhong, and Siheng Chen. Where2comm: Communication-efficient collaborative perception via spatial confidence maps. Advances in Neural Information Processing Systems, 2022. [10] Yifan Lu, Yue Hu, Yiqi Zhong, Dequan Wang, Siheng Chen, and Yanfeng Wang. An extensible framework for open heterogeneous collaborative perception. arXiv preprint arXiv:2401.13964, 2024. [11] Sizhe Wei, Yuxi Wei, Yue Hu, Yifan Lu, Yiqi Zhong, Siheng Chen, and Ya Zhang. Asynchrony-robust collaborative perception via birds eye view flow. Advances in Neural Information Processing Systems, 36, 2024. 1 [12] Haichao Liu, Zhenmin Huang, Zicheng Zhu, Yulin Li, Shaojie Shen, and Jun Ma. Improved consensus admm for cooperative motion planning of large-scale connected autonomous vehicles with limited communication. IEEE Transactions on Intelligent Vehicles, 2024. 1, 2 [13] Chaoyi Chen, Qing Xu, Mengchi Cai, Jiawei Wang, Jianqiang Wang, and Keqiang Li. Conflict-free cooperation method for connected and automated vehicles at unsignalized intersections: Graph-based modeling and optimality IEEE Transactions on Intelligent Transportation analysis. Systems, 23(11):2189721914, 2022. [14] Zhenmin Huang, Shaojie Shen, and Jun Ma. Decentralized ilqr for cooperative trajectory planning of connected autonomous vehicles via dual consensus admm. IEEE Transactions on Intelligent Transportation Systems, 24(11):12754 12766, 2023. 1 [15] Zhenmin Huang, Haichao Liu, Shaojie Shen, and Jun Ma. Parallel optimization for cooperative autonomous driving at unsignalized roundabouts with hard safety guarantees. arXiv e-prints, pages arXiv2303, 2023. 1 [16] Rui Zhao, Yun Li, Fei Gao, Zhenhai Gao, and Tianyao Zhang. Multi-agent constrained policy optimization for conflict-free management of connected autonomous vehicles at unsignalized intersections. IEEE Transactions on Intelligent Transportation Systems, 25(6):53745388, 2023. 1 [17] Zhi Zheng and Shangding Gu. Safe multi-agent reinforcement learning with bilevel optimization in autonomous driving. IEEE Transactions on Artificial Intelligence, 2024. [18] Wei Zhan, Liting Sun, Di Wang, Haojie Shi, Aubrey Clausse, Maximilian Naumann, Julius Kummerle, Hendrik Konigshof, Christoph Stiller, Arnaud de La Fortelle, et al. Interaction dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps. arXiv preprint arXiv:1910.03088, 2019. 2 [19] Shanxing Zhou, Weichao Zhuang, Guodong Yin, Haoji Liu, and Chunlong Qiu. Cooperative on-ramp merging control of connected and automated vehicles: Distributed multi-agent deep reinforcement learning approach. In 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC), pages 402408. IEEE, 2022. 2 [20] Jiaqi Liu, Peng Hang, Xiaoxiang Na, Chao Huang, and Jian Sun. Cooperative decision-making for cavs at unsignalized intersections: marl approach with attention and hierarchiIEEE Transactions on Intelligent Transcal game priors. portation Systems, 2024. [21] Dong Chen, Kaixiang Zhang, Yongqiang Wang, Xunyuan Yin, Zhaojian Li, and Dimitar Filev. Communicationefficient decentralized multi-agent reinforcement learning for cooperative adaptive cruise control. IEEE Transactions on Intelligent Vehicles, 2024. [22] Robert Kirk, Amy Zhang, Edward Grefenstette, and Tim Rocktaschel. survey of zero-shot generalisation in deep reinforcement learning. Journal of Artificial Intelligence Research, 76:201264, 2023. 2 9 [23] Dibya Ghosh, Jad Rahme, Aviral Kumar, Amy Zhang, Ryan Adams, and Sergey Levine. Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability. Advances in neural information processing systems, 34:2550225515, 2021. 2 [24] Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, and Yi Yang. survey on llm-based multi-agent systems: workflow, infrastructure, and challenges. Vicinagearth, 1(1):9, 2024. 2 [25] Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu, and Chaoyang He. Llm multi-agent sysarXiv preprint tems: Challenges and open problems. arXiv:2402.03578, 2024. 2 [26] Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou, Botian Shi, Liang He, and Yu Qiao. Dilu: knowledge-driven approach to auarXiv tonomous driving with large language models. preprint arXiv:2309.16292, 2023. 2, 3 [27] Hao Shao, Yuxuan Hu, Letian Wang, Guanglu Song, Steven Waslander, Yu Liu, and Hongsheng Li. Lmdrive: Closed-loop end-to-end driving with large language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1512015130, 2024. 3, 7, [28] Chonghao Sima, Katrin Renz, Kashyap Chitta, Li Chen, Hanxue Zhang, Chengen Xie, Jens Beißwenger, Ping Luo, Andreas Geiger, and Hongyang Li. Drivelm: Driving arXiv preprint with graph visual question answering. arXiv:2312.14150, 2023. 2, 3 [29] Jiageng Mao, Yuxi Qian, Junjie Ye, Hang Zhao, and Yue Wang. Gpt-driver: Learning to drive with gpt. arXiv preprint arXiv:2310.01415, 2023. 2 [30] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio M. Lopez, and Vladlen Koltun. Carla: An open urban driving simulator. In Conference on Robot Learning, 2017. 2, 7 [31] Kashyap Chitta, Aditya Prakash, and Andreas Geiger. Neat: Neural attention fields for end-to-end autonomous driving. 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pages 1577315783, 2021. 2 [32] Sergio Casas, Abbas Sadat, and Raquel Urtasun. Mp3: 2021 unified model to map, perceive, predict and plan. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1439814407, 2021. 2 [33] Dian Chen and Philipp Krahenbuhl. Learning from all vehicles. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1720117210, 2022. [34] Peng Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, and Yu Qiao. Trajectory-guided control prediction for endto-end autonomous driving: simple yet strong baseline. Advances in Neural Information Processing Systems, 2022. 2, 7, 8 [35] Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, and Yue Wang. language agent for autonomous driving. arXiv preprint arXiv:2311.10813, 2023. 3 [36] Senkang Hu, Zhengru Fang, Zihan Fang, Yiqin Deng, Xianhao Chen, and Yuguang Fang. Agentscodriver: Large language model empowered collaborative driving with lifelong learning. arXiv preprint arXiv:2404.06345, 2024. 3 10 [37] Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu, Ping Luo, Shengbo Eben Li, Masayoshi Tomizuka, Wei Zhan, and Mingyu Ding. Languagempc: Large language models as decision makers for autonomous driving. arXiv preprint arXiv:2310.03026, 2023. 3 [38] Katrin Renz, Long Chen, Ana-Maria Marcu, Jan Hunermann, Benoit Hanotte, Alice Karnsund, Jamie Shotton, Elahe Arani, and Oleg Sinavski. Carllava: Vision language models for camera-only closed-loop driving. arXiv preprint arXiv:2406.10165, 2024. 3 [39] Wenhai Wang, Jiangwei Xie, ChuanYang Hu, Haoming Zou, Jianan Fan, Wenwen Tong, Yang Wen, Silei Wu, Hanming Deng, Zhiqi Li, et al. Drivemlm: Aligning multi-modal large language models with behavioral planning states for autonomous driving. arXiv preprint arXiv:2312.09245, 2023. [40] Xiaoyu Tian, Junru Gu, Bailin Li, Yicheng Liu, Yang Wang, Zhiyong Zhao, Kun Zhan, Peng Jia, Xianpeng Lang, and Hang Zhao. Drivevlm: The convergence of autonomous driving and large vision-language models. arXiv preprint arXiv:2402.12289, 2024. 3 [41] Shiyu Fang, Jiaqi Liu, Mingyu Ding, Yiming Cui, and Chen Lv. Towards interactive and learnable cooperative driving automation: large language model-driven decision-making framework. arXiv preprint arXiv:2409.12812, 2024. 3 [42] Pengxiang Wu, Siheng Chen, and Dimitris Metaxas. MoJoint perception and motion prediction for autionnet: In Protonomous driving based on birds eye view maps. ceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1138511395, 2020. 6 [43] CARLA leaderboard. https://leaderboard.carla.org/leaderboard/. 6 [44] Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1268912697, 2018. [45] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021. 7 [46] Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, et al. Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2418524198, 2024. 7 [47] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115, 2024. 7 CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving"
        },
        {
            "title": "Supplementary Material",
            "content": "8. Model Details 8.1. VLM-based Intention Planner Dataset and Training. As described in Sec. 4.2.2, we adopted three-stage training approach for the VLM planner. In the first stage, Driving Knowledge Enhancement Training, we utilized sampled DriveLM-CARLA dataset containing 64k image-QA pairs focused on driving-related knowledge for perception, prediction, and planning. This stage was completed in single epoch. In the second stage, Intention Tuning, the VLM was fine-tuned on 50k samples of our collected intention dataset. For each frame, the input query was structured by incorporating the transformed GT perception information, GT navigation instructions and speed into the VLM prompt. The response combined navigation and speed intentions. Finally, in the third stage, Consensus Tuning, we enriched the second-stage dataset by adding negotiation information. The VLM was finetuned for five epochs in the second stage and one epoch in the third stage. Key training parameters included LoRA tuning, DeepSpeed ZeRO-3 optimization, batch size of 1, and learning rates of 1 104 for stages one and two, and 1 105 for stage three. For reference, we trained the InternVL2-4B model on 8 NVIDIA 3090 GPUs, with each epoch taking approximately 5 hours. 8.2. Intention-guided Waypoint Planner Model Structure. The Occupancy Encoder and the Feature Encoder each comprise two convolutional layers with 32 output channels. The MotionNet Encoder includes two Spatial-Temporal Convolution blocks followed by standard convolutional block. Each Spatial-Temporal block consists of two 2D convolutional layers and one 3D convolutional layer. The MotionNet Encoder generates an output with 256 channels. Both the speed intention and direction intention are embedded into 256-dimensional vectors, matching the output channels of the MotionNet Encoder. Similarly, the target point is transformed into 256dimensional vector using three-layer MLP. Then the MLP Fuser combines the concatenated vector into 256 dimensions. The Transformer Decoder, which includes three layers, applies cross-attention and self-attention mechanisms to BEV Tokens and Command Tokens. Finally, two-layer MLP decoder predicts 10 waypoints, which are used as control signals. Dataset. The dataset used for training and testing the generator is derived from CARLA. The training set is constructed from data in CARLA towns 1, 2, 3, 4, and 6, while data from towns 7, 8, and 10 are used for validation, and town 5 is reserved for testing. The original training dataset consists of approximately 25k records. We extend the dataset into four categoriesSTOP, SLOWER, KEEP, and FASTER. This is done by first polynomial fitting the original trajectory and then sample waypoints according to the intention and environmental information. Then the actual training dataset grows to approximately 93k records. This number is slightly less than four times the original dataset size, as in certain cases, the original trajectory is too short for polynomial fitting. The perception module processes the last five frames of data, and outputs BEV features and BEV occupancy. The BEV occupancy contains six channels with resolution of 19296, while the BEV feature comprises 128 channels at the same resolution. Intentions are represented as indexing tensors corresponding to the category of the given extended record. Training the generator on 8 NVIDIA 3090 GPUs takes approximately 9 hours per epoch, with convergence typically achieved after 10 epochs. 9. InterDrive Benchmark Details In the current iteration of the InterDrive Benchmark, we have meticulously selected 46 routes from the Town05, Town06, and Town07 scenarios within the CARLA simulator. Route distribution. In the InterDrive Benchmark, which consists of 46 routes, 10 scenario types and 3 categories. We integrate the characteristics of the scenarios with the specific conditions of each Carla Town to ensure that each route is both challenging to complete and practically valuable. Town05, characterized by an urban environment, is the most representative of the models target application environment, hence its higher number of routes. Town06 is distinguished by its multi-lane highways, whereas Town07 primarily features rural scenarios with narrow roads. We have designed variety of scenarios by varying the number of vehicles and the surrounding environments, which include different towns and diverse intersections, as shown in Tab. 4. Their inclusion in the benchmark is crucial for enhancing its diversity and significantly raises the complexity of driving tasks, particularly in terms of vehicle-vehicle interactions. Scenario Settings. In order to enhance the fidelity of the simulation environment to real-world scenarios, we have introduced certain number of additional traffic participants. Specifically, we set the number of vehicles, pedestrians, and 1 the output being JSON-formatted behavior request. The consensus scoring is then conducted using the prompts designed for evaluation, as shown in Lst. 4, to complete one round of negotiation. Herein, the placeholder -convwill be dynamically replaced with the current message record. 11. Autonomous Vehicle Details The autonomous vehicle in CoLMDriver processes sensor data and produces control signals as its final output. This section offers detailed introduction to the sensor setup and controller configuration. Sensor configurations. In CoLMDriver, we use the frontfacing image with resolution of 30001500 and horizontal field of view (FoV) of 100 as an input for the VLM-based intention planner. For 3D detection, we rely on point clouds generated by 64-channel LiDAR mounted at height of 1.9 meters, with an upper FoV of 10 and lower FoV of 30. Controller configurations. The controller generates executable driving actions, including steering, throttle, and braking, based on the predicted waypoints. To achieve this, we employ two PID controllers: lateral controller and longitudinal controller, which produce the corresponding control signals. The lateral signal (turn signal) is calculated using the angle between the last two predicted waypoints, while the longitudinal signal (speed signal) is calculated using the average displacement in the predicted waypoints. Subsequently, we use the PID controller to generate relatively smooth output. Mathematically, let RN be the historical signal with time length of , each PID controller takes the current signal as input and outputs = KP + KI MEAN(E) + KD (E[1] E[2]) , where [KP , KI , KD, N] forms set of hyper-parameters for PID controller. Specifically, the lateral controller is configured with [1, 0.2, 0.1, 5], while the longitudinal controller uses [5, 1, 0.1, 20]. Table 4. Detailed information of the 10 scenario types in InterDrive Benchmark. Scenario Type Scenario Category Vehicle Count Carla Town No. Route Count Straight-Straight Straight-Left Opposite Lane Chaos Straight-Right Neighbor Lane Left-Right Highway-Merge Right-Straight Highway-Change IC IC IC IC LM LM LM LM LC LC 2 2 3, 4 6, 8 2 2 3, 4 3, 4 3, 4 6, 7, 8 05, 06, 07 05, 06, 07 05 05 05, 06, 07 05, 06, 07 05 06 05 06 4 6 4 4 6 6 4 4 4 4 cyclists in the environment to 50 each. This allows them to create certain level of disturbance without completely blocking the routes and interfering with the predefined vehicle interactions. Moreover, this numerical value is also objectively close to the actual traffic conditions in real-world scenarios. The result of the simulation with these participants are shown in Tab. 5. By comparing with Tab. 1, it can be observed that the inclusion of traffic participants has certain impact on the methods primarily based on cooperation. In contrast, the scores of non-cooperative methods remain essentially unchanged or even slightly improve. This is because these participants still prevent the originally designed vehicle conflicts in specific scenarios. 10. Prompt Details and Example 10.1. Prompt for VLM To better harness the knowledge and reasoning capabilities of the VLM, as well as to standardize its output format, we designed the VLM prompt based on the following structure: role definition, task description, logical guidance, additional rules, real-time input, and output format. The specific prompt design is detailed in Lst. 1. The content in {} will be replaced by real-time input. 10.2. Prompt for LLM According to the design of our negotiation module, the prompts designed for the LLM consist of three types: vehicle-to-vehicle communication, sum actions, and consensus scoring. In each round of negotiation, each vehicle broadcasts messages based on the prompts required for communication, and subsequently, one vehicle acts as critic to sum actions and score. The prompts required for vehicle-to-vehicle communication are shown at Lst. 2, where the environmental information and message records are denoted by {} and will change in real-time based on the scenario. The prompts for action-summing are presented in Lst. 3, with 2 Table 5. Driving performance in InterDrive Benchmark with traffic participants."
        },
        {
            "title": "Method",
            "content": "VAD UniAD TCP LMDrive CoDriving Rule-based CoLMDriver DS 25.18 37.13 74.18 49.95 64.50 69.71 77.09 InterDrive-total RC 75.66 88.71 91.21 61.61 93.58 87.35 92.02 IS 0.31 0.41 0.82 0.84 0.67 0.75 0.80 SR 0.02 0.11 0.48 0.13 0.47 0.57 0. InterDrive-IC IS 0.32 0.44 0.91 0.81 0.59 0.72 0.70 RC 61.31 83.52 84.62 59.34 88.08 88.48 82.55 DS 22.13 37.45 76.26 47.65 54.64 66.05 63.06 SR 0.00 0.06 0.44 0.00 0.33 0.50 0.44 InterDrive-LM IS 0.39 0.52 0.91 0.85 0.91 0.93 0.94 RC 88.23 91.33 95.00 67.10 96.55 97.92 100. DS 35.10 48.29 86.59 54.12 88.07 90.72 94.00 SR 0.05 0.20 0.65 0.20 0.73 0.80 0.85 InterDrive-LC IS 0.09 0.09 0.40 0.87 0.28 0.38 0.68 RC 76.56 93.82 96.56 53.02 98.51 58.38 93.41 DS 7.24 8.48 38.50 44.69 27.78 25.44 66.38 SR 0.00 0.00 0.13 0.25 0.13 0.13 0. Suppose you are an autopilot assistant driving car on the road. You will receive images from the car front camera and are expected to provide driving intentions. There are other traffic participants in the scenario, and you may have communication with them. Your analysis logic chain should be as follows: 1. Understand the direction of the road and your own position. 2. Perceive surrounding objects. 3. Pay attention to key objects and dangerous situations. 4. Follow the rules listed below. 5. Check communication decision. 6. Finally, conclude the situation and provide driving intentions. ### Rules 1. If the environment is safe and clear, drive fast 2. Maintain safe distance from the car in front. 3. Stop to avoid pedestrians preparing to cross the road. 4. Slow down or stop when other vehicles change lanes, merge or turn. 5. Slow down or stop when there is obstacle on the road ahead. 6. When establishing communication with other vehicles, take the communication decision as important reference. ### Perception Results {perception} ### Real-time Inputs Negotiation suggestion: {negotiation message} Target direction: {navigation instruction} Current Speed: {speed} m/s ### Output Requirements Provide the navigation and speed intention. Navigation intention include turn left at intersection, turn right at intersection, go straight at intersection, follow the lane, left lane change, right lane change. Speed intention include STOP, FASTER, SLOWER, KEEP. Listing 1. VLM intention generation prompt ## Role You are driving assistant of car (Vehicle ID: {i}). Given scenario where multiple vehicles are in conflict, you need to negotiate with other vehicles to reach consensus and ensure the safety and efficiency of all vehicles involved. ## Scenario - Ego Vehicle (ID: {info[ego_id]}): Intention = {info[ego_intention]}, Speed = {round(info[ ego_speed], 1)}m/s - Surrounding Vehicles: {veh_string} ## Traffic Rules 0. In emergency situations, allow vehicles with special circumstances to pass through first. 1. Merging cars slow down to yield to straight car. 2. Left-turn cars slow down to yield to straight/right-turn car. 3. The car being yielded to go faster. 4. Cars behind decrease speed during emergency braking. 5. Following cars maintain safe distance. ## Task Based on the scenario info and conversation history, analyze the situation considering the **speed, direction, distance and intention of each vehicle**. Make sure you understand the situation before making any decisions. Pay attention to the traffic rules and critic suggestion. Identify any potential conflicts and propose actions that ensure the safety and efficiency of all vehicles involved. Remember to consider others actions and requests from previous conversations. When conflicts occur, either request others to yield or yield to others. Your message may contain the action you will take and requests for other vehicles. **The actions and requests are speed intentions** ## Negotiation Tips - Your actions should be logically consistent with your requests. No need for both sides to yield. - Clearly specify which vehicle is responsible for each request or action. - Focus your message on speed rather than navigation. ## Conversation History {previous_conv}{sug_str} ## Output You are vehicle {info[ego_id]}, you need to send message to other cars. Please output the message only, within 18 words. Please do not provide specific speed values; instead, describe the trend of speed changes. Sample output: will [speed intention]; [requested speed intention]. Listing 2. LLM negotiation prompt - ego vehicle communication 4 ## Task Given conversation of multiple cars negotiating to reach consensus, classify each vehicles speed change into [STOP, SLOWER, KEEP, FASTER] and output the result as string in format: {id: car_id, speed: category}. ## Classification rules - STOP: Come to complete stop. - SLOWER: Decrease speed. - KEEP: Maintain current speed. - FASTER: Increase speed. ## Additional rules: - If car request others to yield, it should go faster - If car yield to others, it should stop ## Input conversation: {conv} Your task is to analyze the given conversations for each vehicle and output the classification as string in the specified format. DO NOT output other content other than the required actions. Ensure the output matches the required structure exactly. ## Output example: {\"0\": {\"speed\": \"STOP\"}, \"1\":{\"speed\": \"SLOWER\"}, \"2\":{\"speed\": \"SLOWER\"}...} Listing 3. LLM negotiation prompt - sum actions Task Description: Please analyze the following conversation and determine whether the characters have reached consensus in the given scenario. Your response should include two parts: the first part is brief explanation of whether consensus was reached; the second part is score indicating the degree of consensus, ranging from 0 to 100, where 0 means no consensus at all, and 100 means complete consensus. Scoring Criteria: 0-20: There are significant disagreements with almost no common ground. 21-40: While there are some disagreements, there are one or two points where both parties can accept each others views. 41-60: There is moderate level of compromise and understanding on most discussed topics, but important disagreements remain unresolved. 61-80: Consensus has been reached on most issues, with only minor differences of opinion on few details. 81-100: Almost all issues have been agreed upon by all parties, with only negligible objections remaining. Scenario: On the road, multiple cars may have driving conflicts now. They negotiate with each other to avoid conflict. Conversation: {conv} Your output format: Short analysis: very short sentence to sum the consensus situation of the conversation. Consensus score: int Listing 4. LLM negotiation prompt - consensus score evaluation"
        }
    ],
    "affiliations": [
        "Multi-Agent Governance & Intelligence Crew (MAGIC)",
        "Shanghai AI Laboratory",
        "Shanghai Jiao Tong University"
    ]
}