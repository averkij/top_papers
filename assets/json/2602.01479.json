{
    "paper_title": "Ebisu: Benchmarking Large Language Models in Japanese Finance",
    "authors": [
        "Xueqing Peng",
        "Ruoyu Xiang",
        "Fan Zhang",
        "Mingzi Song",
        "Mingyang Jiang",
        "Yan Wang",
        "Lingfei Qian",
        "Taiki Hara",
        "Yuqing Guo",
        "Jimin Huang",
        "Junichi Tsujii",
        "Sophia Ananiadou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 1 ] . [ 1 9 7 4 1 0 . 2 0 6 2 : r EBISU: Benchmarking Large Language Models in Japanese Finance Xueqing Peng2, Ruoyu Xiang3, Fan Zhang4, Mingzi Song5, Mingyang Jiang2, Yan Wang2, Lingfei Qian2, Taiki Hara1, Yuqing Guo2, Jimin Huang1,2, Junichi Tsujii6, Sophia Ananiadou1, 1University of Manchester, 2The Fin AI, 3New York University, 4The University of Tokyo, 5Meiji Gakuin University, 6National Institute of Advanced Industrial Science and Technology (AIST), 7The National Centre for Text Mining Correspondence: jimin.huang@postgrad.manchester.ac.uk"
        },
        {
            "title": "Abstract",
            "content": "Japanese finance combines agglutinative, headfinal linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing substantial challenge for LLMs. We introduce EBISU, benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, languageand domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. EBISU provides focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released."
        },
        {
            "title": "Introduction",
            "content": "large language models Even state-of-the-art (LLMs) can get lost in Japanese finance. This is linguistically grounded because Japanese is agglutinative and head final (McCawley, 1975), so modality and negation are often realized sentence 1 Data: https://huggingface.co/datasets/TheFinAI/JF-ICR https://huggingface.co/datasets/TheFinAI/JF-TE Code: https://github.com/The-FinAI/Ebisu 1 Figure 1: Representation examples of JF-ICR and JFTE. Benchmark JA Fin Ling Prag FC JGLUE (Kurihara et al., 2022) JBLiMP (Someya and Oseki, 2023) FinBen (Xie et al., 2024) FinQA (Chen et al., 2022) MultiFinBen (Peng et al., 2025b) Japanese-LM-Fin-Harness (Hirano, 2024b) EDINET-Bench (Sugiura et al., 2025) EBISU (ours) Table 1: Comparison with existing benchmarks. JA: Japanese language coverage; Fin: financial domain coverage; Ling: linguistic phenomena; Prag: pragmatic understanding; FC: financialcultural knowledge. finally (Hasegawa, 2018; Narrog, 2007) and refusals are frequently conveyed indirectly through pragmatic cues (Ide, 1989). Interpretation is further complicated by Japanese financial term formation, where nested nominal compounds and mixed script variants (kanji, hiragana, and katakana (Bond and Baldwin, 2016; Joyce et al., 2017; Tamaoka, 2014)) make semantic scope depend on term boundaries and reference. Since Japanese corporate disclosures and investor communications are already consumed and processed at global scale, evaluating this capability matters for cross border finance rather than only domestic use, especially given that foreign investors held 32.4% of listed share market value in Japan in FY2024 (Tsutsumi, 2025). However, existing multilingual and financial LLM evaluations are optimized for cross-language comparability and scalable supervision (Peng et al., 2025b; Xie et al., 2024), which biases them toward short contexts, explicit targets, and label schemes that remain stable across languages and annotators. Multilingual benchmarks therefore concentrate on QA, NLI, and multiple-choice style formats (Qian et al., 2025a; Zhang et al., 2024; Peng et al., 2025a), while finance benchmarks are typically instantiated as canonical task templates with clear inputoutput supervision (Wang et al., 2025a,b; Qian et al., 2025b), making both less suited to phenomena that are hard to operationalize at scale, such as discourse-level intent conveyed indirectly and stance resolved by sentence-final morphology (Nasukawa et al., 2025). Japanese finance resources (Hirano, 2024a) often inherit the same constraints because high-quality native financial text is difficult to curate and license and pragmatic intent labels are costly to annotate reliably, so available datasets tend to emphasize sentiment (Nakatsuka and Suimon, 2025) or exam-style QA (Sugiura et al., 2025). In this work, we introduce EBISU, benchmark for native Japanese financial language understanding that targets two coupled requirements in real corporate communication, stance inference about commitment and refusal and boundary-sensitive grounding of finance terminology in mixed-script text  (Table 2)  . JF-ICR (Japanese Financial Implicit Commitment Recognition) consists of 94 investorfacing Q&A pairs from 4 companies spanning 3 years, annotated into 5 implicit stance categories that distinguish agreement, hedging, and refusal under high-context discourse. JF-TE (Japanese Financial Term Extraction) consists of 202 notelevel instances extracted from 10 professional disclosures with 2,412 expert-curated term mentions covering 777 unique finance terms after normalization, where nested compounds and script-variant loanwords make term boundaries and semantic scope ambiguous. Both datasets are labeled by finance-trained native-level Japanese annotators following detailed guideline and each item is independently double-annotated, disagreements are adjudicated by senior expert, and we report interannotator agreement  (Table 3)  together with auditbased quality checks on stance consistency and term-boundary validity. We evaluate JF-ICR using Accuracy as the primary metric and JF-TE as ranked retrieval task using F1 and HitRate@K (K=[1/5/10]) under exact matching, enabling diagnostic evaluation of whether models recover what is being discussed and what is being committed to in Japanese financial discourse. We evaluate 22 LLMs on EBISU, including both open-weight and proprietary systems, and find that overall performance remains low across models, highlighting the challenging nature of the benchmark. We conduct within-family, size-matched comparisons to analyze the effects of model scale, Japanese language adaptation, and financial doIncreasing model scale conmain adaptation. sistently improves performance on both JF-ICR (+0.33 Acc) and JF-TE (+0.38 F1), but these gains remain limited. In contrast, languageand domainspecific adaptation does not reliably yield improvements: Japanese-adapted models do not consistently outperform their English counterparts at matched scale, and continued financial pretraining can even degrade performance, particularly for financial term extraction (-0.12 F1). Across both tasks, errors concentrate on linguistically and pragmatically defined phenomena rather than missing domain knowledge. On JF-ICR, models struggle with cases where stance is resolved through clausefinal auxiliaries or indirect refusal strategies, frequently confusing refusal with neutral or hedged responses. On JF-TE, ranking quality deteriorates with increasing compound depth and mixed-script variability, and the gap between HitRate@1 and HitRate@10 indicates difficulties in term boundary resolution and variant handling rather than lack of financial vocabulary. Together, these findings suggest that current scaling and adaptation strategies improve average accuracy without reliably capturing the morphosyntactic and pragmatic mechanisms central to Japanese financial communication. 2 Our contributions are fourfold: EBISU benchmark. We introduce EBISU, benchmark for native Japanese financial language understanding that targets pragmatic stance inference and finance-term grounding under Japanese-specific linguistic and discourse conditions. New tasks and datasets grounded in Japanese finance. We define two new expertannotated tasks and datasets that deeply reflect Japanese financial practices: JF-ICR for implicit commitment recognition in investorfacing Q&A and JF-TE for extraction and ranking of finance-relevant terminology in professional disclosures. Comprehensive evaluation and diagnostic analysis. We conduct broad evaluation over 22 LLMs and provide diagnostic analyses that isolate the effects of scaling and adaptation, showing that improvements are limited and that strong performance is not guaranteed by proprietary training alone. Public resources. We release EBISU and accompanying annotation guidelines and evaluation code to facilitate languageand cultureaware financial NLP research."
        },
        {
            "title": "2 Related Work",
            "content": "2."
        },
        {
            "title": "Japanese Financial LLMs",
            "content": "The development of Japanese LLMs has transitioned from general-purpose adaptation to deep financial specialization. Early efforts like the Swallow series (Fujii et al., 2024) established successful pipeline for enhancing Japanese syntax and reasoning through continual pre-training and vocabulary expansion. Financial domain alignment was subsequently advanced by works like (Tanabe et al., 2024; Hirano and Imajo, 2024), which provides high-quality instructions sourced from authoritative entities like the Bank of Japan and the Financial Services Agency to ensure model responses adhere to professional regulatory standards. Industry innovations include SoftBanks Sarashina2, which targets \"sovereign AI\" with 460 billion parameters for legal language understanding, and StockmarkLLM3, which suppresses hallucinations in business 2https://huggingface.co/sbintuitions/sarashina2.1-1b 3https://huggingface.co/stockmark/stockmark-100b contexts through training on extensive news and patent corpora. 2.2 Japanese Financial Benchmarks Evaluation frameworks for Japanese financial LLMs have evolved from knowledge-based tests to expert-level reasoning tasks. The Japanese-LMFin-Harness (Hirano, 2024b) first provided an initial substrate for benchmarking by incorporating securities analyst exams, CPA audit theory, and binary sentiment analysis. Recently, to capture expert-level reasoning, EDINET-Bench (Sugiura et al., 2025) introduced expert tasks such as accounting fraud detection and earnings forecasting grounded in decade of official filings. Specialized assessments like SIG-FIN UFO-2024 (Kimura et al., 2024) focus on table retrieval and QA within securities reports, while pfgen-bench (Imajo et al., 2025) measures the quality of financial text generation. Other studies on small-cap stocks (Suzuki et al., 2025) and earnings briefing dialogues (Nakatsuka and Suimon, 2025) further highlight that specialized LLMs can identify predictive signals and nuanced investor stances that traditional methods overlook. Existing evaluations span general Japanese linguistic benchmarks (Kurihara et al., 2022; Someya and Oseki, 2023) and global financial benchmarks (Xie et al., 2024; Chen et al., 2022), but the former lacks finance coverage and the latter is largely English-centric. Cross-lingual efforts (Peng et al., 2025b) partly bridge Japanese finance, yet often remain too coarse for fine-grained linguistic analysis."
        },
        {
            "title": "3 EBISU Benchmark",
            "content": "In this section, we introduce EBISU, benchmark designed to evaluate LLMs on native Japanese financial language understanding. EBISU consists of two complementary tasks targeting (1) Japanese Financial Implicit Commitment Recognition (JFICR) in high-context Japanese financial communication and (2) Japanese Financial Term Extraction (JF-TE) from professional financial documents  (Table 2)  . 3.1 JF-ICR: Japanese Financial Implicit Commitment Recognition Japanese communication is characterized by indirectness, politeness, and implicit expression of intent, making agreement or refusal difficult to infer. This difficulty is compounded by the agglutinative nature of Japanese, where critical semantic 3 Task / Dataset Source Test Size Metrics License Tested Capabilities JF-ICR JF-TE Accuracy F1 and HitRate@K3 1 https://www.mufg.jp/ir/presentation/2024/index.html; https://www.smfg.co.jp/investor/financial/presentation.html; https://www.itochu.co.jp/ja/ir/ Implicit intent understanding in Japanese finance Financial terminology extraction and ranking Company Q&A1 Annual Securities Reports2 Public Public 94 202 financial_statements/2025/index.html; https://www.mufg.jp/ir/stock/meeting/2023/; https://www.mitsubishicorp.com/jp/ja/ir/ 2 https://disclosure2.edinet-fsa.go.jp/ 3 We report HitRate@1, HitRate@5, and HitRate@10 to evaluate the accuracy of financial terms at different ranking depths. Table 2: Overview of the EBISU benchmark. For each task, we report the data source, data size, evaluation metrics, license information, and the targeted capabilities. and pragmatic information is often encoded at the sentence-final position, in sharp contrast to English or Chinese, leading to frequent errors in polarity, commitment, and risk interpretation. In Japanese financial discourse, intent inference becomes even more challenging due to the prevalent use of vague and abstract expressions, limited explicit negative assertions, hedged and hypothetical writing styles, layered negation, and katakana-based loanwords whose meanings may diverge from their source languages, often framing potential risks in neutral or favorable light. As most large language models are predominantly trained on English-centric corpora and U.S.- style financial disclosures, they may struggle to accurately infer the true intent behind Japanese financial communication. The JF-ICR task is designed to evaluate this capability by assessing whether models can correctly identify implicit agreement and refusal in such high-context settings. Task Definition. The JF-ICR task is formulated as an intent classification problem over Japanese financial communication. Given single-turn financial questionanswer pair (q, a), where denotes financial query and denotes the corresponding company response in Japanese, the model is required to infer the underlying intent expressed in the response a. The output is five-level intent label {2, 1, 0, +1, +2}, corresponding to Strong Commitment (+2), Weak or Qualified Commitment (+1), Neutral or Hedged Intent (0), Weak Refusal (1), and Strong Refusal (2). This formulation focuses on intent inference from the response a, rather than sentiment classification or surfacelevel polarity detection. Data Source. We construct JF-ICR from realworld, publicly available Japanese corporate disclosures in which companies respond to financial inquiries in high-context settings. Specifically, we collect questionanswer transcripts from (i) earnings call / investor briefing Q&A4, (ii) shareholder meeting Q&A5, and (iii) financial results briefings (kessan setsumeikai) Q&A6.In total, our corpus comprises 8 source documents from 4 companies spanning 20232026, with an average of 10 Q&A exchanges per document. To ensure unambiguous intent annotation, we perform careful manual curation. We retain only single-turn questionanswer pairs that focus on single topic, and exclude multi-part questions, intertwined follow-ups, or exchanges that require broader conversational context. This filtering process reduces annotation ambiguity and improves data quality. After curation, we obtain 94 singleturn Japanese financial Q&A instances for expert annotation. Expert Annotation. We developed rigorous annotation guideline (Appendix A) in collaboration with Japanese financial experts. Each instance was annotated using the five-point agreement/refusal scale {+2, +1, 0, 1, 2}, with detailed criteria specified for each label to ensure consistency. The guidelines were iteratively refined through pre-annotation rounds, with particular attention to incorporating rules for ambiguous cases. Only responses expressing strong, clear, explicit, and definitive agreement or refusal were assigned the 2 labels. All annotations were performed by 2 native-level Japanese financial experts with extensive industry experience (Appendix C). The annotation process was conducted using the Label Studio platform (Figure 3, Appendix D), ensuring streamlined and reproducible workflow. Quality Validation. To assess the reliability of the JF-ICR annotations, we measure interannotator agreement using standard metrics for multi-class classification tasks, including MacroF1 (Sokolova and Lapalme, 2009), Cohens κ (Cohttps://www.mufg.jp/ir/presentation/2024/index.html https://www.smfg.co.jp/investor/financial/presentation.html https://www.itochu.co.jp/ja/ir/financial_statements/2025/index.html https://www.mufg.jp/ir/stock/meeting/2023/ https://www.mitsubishicorp.com/jp/ja/ir 4 5 6 4 Dataset Macro-F1 Cohens κ Krippendorffs α JF-ICR JF-TE 0.9215 0.8230 0.8769 0. 0.8768 0.7832 3.2 JF-TE: Japanese Financial Term Extraction Table 3: Inter-annotator agreement results for JF-ICR and JF-TE, evaluated using Macro-F1, Cohens κ, and Krippendorffs α. hen, 1960), and Krippendorffs α (Krippendorff, 2011) (Appendix E). Macro-F1 captures balanced agreement across the five intent categories, while Cohens Kappa and Krippendorffs Alpha adjust for chance agreement and label distribution skew. The agreement results indicate high level of consistency between annotators  (Table 3)  , demonstrating that the annotation guidelines are clearly defined and consistently applied. Instruction Data Conversion. To support instruction-based evaluation, we convert each annotated instance into structured instruction-style format using expert-crafted task-specific prompt as outlined below. Evaluation Metric. We formulate intent recognition as multi-class classification problem and evaluate model performance using Accuracy (Makridakis, 1993) (Appendix F). Accuracy measures the proportion of instances for which the predicted intent label exactly matches the annotated groundtruth label, providing direct assessment of overall classification correctness. Task Instruction for JF-ICR You are Japanese financial expert fluent in Japanese business communication. Given financial question and the corresponding company response (both in Japanese), your task is to determine the companys underlying intent level and output exactly one label from the following set: {\"+2\", \"+1\", \"0\", \"-1\", \"-2\"}. The label meanings are provided for explanation only (DO NOT output these texts): \"+2\" : \"Strong Commitment\" \"+1\" : \"Weak or Qualified Commitment\" \"0\" : \"Neutral or Hedged Intent\" \"-1\" : \"Weak Refusal\" \"-2\" : \"Strong Refusal\" Financial Question: {Japanese question} Company Response: {Japanese answer} Directly output the chosen label, and do not provide any explanation. Answer: {Intent label} Japanese financial terminology is shaped by the interaction of three writing systems, nested nominal compounds, and extensive borrowing from both Chinese and English. Financial terms are predominantly realized in kanji and katakana, where loanwords frequently undergo semantic drift from their source languages, and visually identical forms may convey entirely different meanings across languages (e.g., kento consideration, bimyo ambiguous, taio response), limiting the effectiveness of cross-lingual dictionary-based approaches (Goworek et al., 2025; Li et al., 2020). Beyond linguistic factors, Japanese financial disclosure follows conventions that diverge substantially from U.S.-style reporting: although disclosures are nominally investor-facing, they are primarily oriented toward shareholders, resulting in distinctive writing styles and information structuring. Annual filings are highly standardized, with meaningful updates often embedded in seemingly peripheral note sections rather than headline figures, making them easy for language models to overlook. The JFTE task therefore targets financial term extraction from Japanese disclosure notes, assessing how well LLMs predominantly trained on U.S. financial documents can identify domain-specific terminology in Japanese financial contexts. Task Definition The JF-TE task is formulated as financial terminology extraction and ranking problem over Japanese financial text, with explicit modeling of nested term structures. Inspired by termhood-oriented principles such as C-value (Frantzi et al., 2000), the task evaluates whether models can identify and prioritize domainspecific financial terminology in Japanese disclosures. Each input is single note section drawn from professional Japanese financial documents. The model is required to identify set of maximal financial terms = {m1, m2, . . . , mp}, where each mi denotes the longest contiguous expression representing financial concept in n. For each maximal term mi, the model further identifies set of candidate nested terms Ti = {ti1, ti2, . . . , tik}, where each tij mi is potential financial term (including tij = mi); in the absence of nested terms, Ti = {mi}. The model outputs an ordered list , ranking these candidates from the most to the least likely to represent domain-specific financial terminology. Non-financial expressions are 5 excluded from the output. The final output is structured JSON object aggregating all across maximal terms. and financial termhood are operational and reproducible, supporting the reliability of the resulting high-quality JF-TE dataset. Data Source. To construct the JF-TE dataset, we collect Japanese Annual Securities Reports (Yuka shoken hokokusho) disclosed through EDINET7, the official electronic disclosure system operated by Japans Financial Services Agency. Our corpus consists of 10 professional disclosures released in 2025 by 10 publicly listed companies, with each report spanning up to 261 pages in the original EDINET filings. Consistent with Japanese financial disclosure practices, substantive updates and domain-specific information are often embedded in fine-grained appendix notes rather than the main narrative sections. To capture these information-dense units, we manually identify and extract individual note entries from each financial disclosure, treating each note as standalone instance for expert annotation and financial terminology extraction. In total, this process yields 202 curated note-level data instances. Expert Annotation. We follow similar expert annotation protocol as in JF-ICR, with task-specific guidelines tailored to hierarchical financial terminology (Appendix B). Each note-level instance was annotated by identifying the longest financial term spans and, where applicable, the nested financial terms contained within them. Annotation was conducted at the span level, allowing multiword expressions, compound nouns, and nested structures to be marked explicitly. The annotation guidelines were iteratively refined through preannotation rounds, with explicit rules governing term boundary decisions and the distinction between financial terminology and general expressions. All annotations were carried out by the same native-level Japanese financial experts (Appendix C) using the Label Studio platform (Figure 4, Appendix D), ensuring consistency and reproducibility. Quality Validation. We evaluate annotation quality using inter-annotator agreement metrics MacroF1 (Sokolova and Lapalme, 2009), Cohens κ (Cohen, 1960), and Krippendorffs α (Krippendorff, 2011) (Appendix E). The results demonstrate strong agreement in identifying financial term spans  (Table 3)  . This consistency indicates that the annotation rules governing term boundaries 7 https://disclosure2.edinet-fsa.go.jp/ Instruction Data Conversion. To support instruction-based evaluation, we reformulate each annotated instance into an instruction-style format, with task-specific prompts tailored to financial terminology extraction as shown below. Evaluation Metrics. The JF-TE task is evaluated using two-level metric design to reflect the hierarchical structure of financial terminology in Japanese disclosures. We first evaluate maximal financial term extraction by comparing predicted ones with the ground truth using exact matching and report the F1 score (Tjong Kim Sang and De Meulder, 2003) (Appendix F). We then assess the ranking of nested financial terms within each maximal financial term using HitRate@K (Bordes et al., 2013) (Appendix F), which measures whether gold nested terms appear among the top-K predictions. To account for variation in the number of nested terms across instances, we report HitRate@1, HitRate@5, and HitRate@10. Together, these metrics capture both accurate identification of complete financial term boundaries and effective prioritization of nested financial terminology. English Translated Task Instruction for JF-TE You are Japanese financial expert specializing in financial disclosure analysis. Read the following Japanese financial note carefully. Identify all maximal (longest) financial terms in the text. For each maximal term, identify any nested financial terms it contains, including the maximal term itself if applicable. For each maximal financial term, output ranked list of its associated financial terms (including itself and any nested terms), ordered from most to least likely to represent domainspecific financial terminology. Do not include non-financial expressions. Return the output in JSON format, where each element corresponds to one maximal financial term and contains ranked list of financial terms. Text: {Japanese financial disclosure note} Answer: {JSON with ranked financial terms}"
        },
        {
            "title": "4.1 Evaluation Models",
            "content": "We evaluate comprehensive set of 22 LLMs on the EBISU benchmark, spanning wide range 6 Model JF-ICR JF-TE Mean Acc F1 HR@1 HR@5 HR@10 Avg Llama-4-Scout-17B Llama-3.3-70B-Instruct Qwen3-235B-A22B-Instruct Qwen3-32B Qwen3-14B Qwen3-8B Qwen2.5-32B-Instruct Qwen-14B Ministral-3-14B-Instruct DeepSeek-V3.1 Kimi-K2-Instruct gpt-5 gpt-4o gemini-3-flash claude-sonnet-4-5 FinMA-7B Llama-3.3-Swallow-70B-Instruct TinySwallow-1.5B-Instruct japanese-stablelm-instruct-beta-7b japanese-stablelm-instruct-beta-70b nekomata-14b nekomata-14b-pfn-qfin Open-source General Models 0.6064 0.5638 0.4574 0.1915 0.1809 0.1277 0.3830 0.0638 0.3723 0.5106 0.4574 0.4133 0.4370 0.4355 0.2860 0.2038 0.0548 0.4137 0.1613 0.3756 0.3653 0.4396 Proprietary Models 0.5532 0.0319 0.3936 0.5213 0.0000 0.3997 0.0000 0.4362 0.1085 0.1277 0.0971 0.0285 0.0165 0.0050 0.0982 0.0308 0.0875 0.0794 0. 0.0000 0.0890 0.0000 0.0743 English Financial Models 0.1596 0.0000 0.0000 Japanese General Models 0.5957 0.0638 0.0426 0.0319 0.0213 0.4070 0.1937 0.0143 0.1826 0. 0.1258 0.0264 0.0069 0.0388 0.0173 Japanese Financial Model 0.0213 0.0468 0.0012 0.3094 0.3657 0.3053 0.1052 0.0787 0.0142 0.3462 0.0650 0.2377 0.2663 0.3251 0.0000 0.2845 0.0000 0. 0.4513 0.5111 0.4301 0.1763 0.1097 0.0233 0.4786 0.1076 0.3704 0.4121 0.4680 0.0000 0.4255 0.0000 0.4752 0.3778 0.4011 0.3451 0.1575 0.1179 0.0450 0.3439 0.0857 0.2887 0.3267 0.3590 0.1106 0.2461 0.0787 0.3618 0.0000 0. 0.0319 0.3270 0.0712 0.0079 0.1090 0.0330 0.4701 0.1012 0.0079 0.1461 0.0479 0.3851 0.0913 0.0159 0.1017 0.0251 0.0118 0. 0.0198 Table 4: LLM performance on the EBISU benchmark. JF-ICR is evaluated using Accuracy (Acc). JF-TE is evaluated using F1 and HitRate@K (HR@1/5/10). Bold values denote the best scores and underlined values denote the second-best scores in each column. scales (Mistral of model types and training paradigms. The evaluated models comprise: (1) 11 open-source general-purpose models at both large and small (Llama-4-Scout-17B (Meta AI, 2025), Llama-3.3-70B-Instruct (Dubey et al., 2024), Qwen3-235B-A22B-Instruct-2507-FP8, Qwen3-32B, Qwen3-14B, Qwen3-8B (Qwen (Qwen Team, 2025), Qwen2.5-32B-Instruct Team, 2024), Qwen-14B (Qwen Team, 2023), Ministral-3-14B-Instruct-2512 AI, 2025), DeepSeek-V3.1 (DeepSeek-AI, 2024), (2) 4 Kimi-K2-Instruct (Kimi Team, 2025)); proprietary closed-source models accessed via official APIs (gpt-5 (OpenAI, 2025), gpt4o (OpenAI, 2024), gemini-3-flash (Google DeepMind, 2025), claude-sonnet-4-5 (Anthropic, 2025)); (3) English financial domain-specific (4) 5 model (FinMA-7B (Xie et al., 2023); Japanese general-purpose models (Llama3.3-Swallow-70B-Instruct-v0.4 (Swallow Team, 2025), TinySwallow-1.5B-Instruct (Shing et al., 2025), japanese-stablelm-instruct-beta-70b, japanese-stablelm-instruct-beta-7b (Stability AI, 2023), nekomata-14b (Sawada et al., 2024)); and (5) Japanese financial domain-specific model (nekomata-14b-pfn-qfin (Hirano and Imajo, 2024)). 4."
        },
        {
            "title": "Implementation Details",
            "content": "To ensure evaluation integrity and consistency, we develop unified evaluation pipeline based on the LM Evaluation Harness (Gao et al., 2024). Proprietary models are evaluated using their official APIs, with temperature fixed to 0 to ensure deterministic outputs.. Open-source models available through TogetherAI are served and evaluated via the TogetherAI platform, and all other open-source models are deployed and evaluated locally using vLLM (Kwon et al., 2023) on GPUs. In-house evaluation is conducted on cluster of four H100 GPUs, each equipped with 80GB of memory, for total of over 200 GPU-hours. We standardize the maximum generation length to 1,024."
        },
        {
            "title": "4.3 Key Results",
            "content": "Table 4 and Figure 2 summarize model performance on the EBISU benchmark. We structure our analysis around the following research questions. RQ1: Is EBISU challenging for state-of-theart LLMs under Japanese financial settings? Overall, the results show that current LLMs face Figure 2: Ranked models performance on the EBISU benchmark.. substantial challenges on the EBISU benchmark, including state-of-the-art systems. Leading proprietary models such as GPT-4o (0.2461) and ClaudeSonnet-4.5 (0.3618) exhibit limited performance, while the best overall result is achieved by the open-source Llama-3.3-70B-Instruct (0.4011), suggesting persistent difficulties in robustly modeling the linguistic and pragmatic characteristics of Japanese financial texts. Performance generally improves with increasing model scale. For example, within the Qwen family, larger models such as Qwen3-235B-A22B-Instruct (0.3451) and Qwen332B (0.1575) outperform the smaller Qwen3-14B (0.1179) and Qwen3-8B (0.0450). However, these gains remain limited, indicating that the challenges reflected in EBISU cannot be resolved through model capacity alone. Instead, the persistent performance gap points to linguistic and cultural properties of Japanese financial communication that are not sufficiently captured by prevailing train7 ing paradigms. Collectively, these results highlight the difficulty of Japanese financial language understanding and position EBISU as demanding benchmark for evaluating such capabilities in modern LLMs. RQ2: How effectively do models transfer knowledge across language and domain boundaries in Japanese finance? Clear limitations emerge in cross-language and cross-domain knowledge transfer across model families. English financial domain-specific model (FinMA-7B: 0.0319) performs worse than general-purpose models of comparable scale like Qwen3-8B (0.0450). This pattern indicates that financial knowledge learned primarily from English corpora does not readily transfer to Japanese financial tasks without sufficient Japanese generalJapanese language training. purpose models still underperform relative to their English counterparts. For instance, Llama-3.3Swallow-70B-Instruct (0.3851) lags behind Llama3.3-70B-Instruct (0.4011), indicating that performance gains from language adaptation do not necessarily generalizable. In contrast to expectations, continued languageand domain-specific pretraining does not consistently improve performance. The Japanese financial model nekomata-14b-pfnqfin (0.0198) performs worse than both its Japanese general counterpart nekomata-14b (0.0251) and the original backbone Qwen-14B (0.0857). This suggests that continued next-token pretraining on Japanese financial text alone is insufficient, and may even hinder performance on tasks requiring implicit intent understanding in Japanese finance. Collectively, these findings show that EBISU exposes critical shortcomings in existing English financial, Japanese general, and Japanese financial models, and provides meaningful benchmark for driving progress toward models that better capture the linguistic and cultural context of Japanese finance. RQ3: Do LLMs exhibit systematic biases when recognizing implicit commitment in Japanese financial responses? Performance on JF-ICR falls short across all evaluated models, revealing persistent difficulties in intent understanding within Japanese financial contexts. Even the strongest model, Llama-4-Scout-17B (Acc: 0.6064), struggles to accurately recognize implicit agreement and refusal in Japanese finance, indicating that this capability remains an open challenge. Beyond overall accuracy, we further examine the average predicted commitment scores across models. At similar model sizes, English-centric models consistently assign higher commitment scores than their Japanese counterparts, such as Llama-3.3-70BInstruct (0.9787) compared to Llama-3.3-Swallow70B-Instruct (0.8404), and Qwen-14B (0.3830) compared to nekomata-14b (-0.8511). This pattern indicates systematic bias in models primarily trained on English data, where indirect refusals and strategic non-commitment in Japanese financial responses are frequently misinterpreted as acceptance or weak agreement. These findings reflect the intrinsic difficulty of JF-ICR, which arises from the combined influence of Japanese linguistic features that encode intent implicitly, such as sentencefinal constructions and layered negation, and financial communication norms that discourage explicit refusal. As result, JF-ICR requires models to distinguish genuine commitment from strategic non-commitment beyond surface-level semantics in high-context Japanese financial discourse. RQ4: Are Japanese financial terms particularly difficult for LLMs to extract due to languagespecific lexical properties? Performance on JFTE remains weak across all evaluated models, revealing substantial limitations in current LLMs ability to extract and prioritize Japanese financial terminology. Even the strongest-performing model, Llama-3.3-70B-Instruct, achieves only modest HitRate at different cutoffs (HitRate@1: 0.1277, HitRate@5: 0.3657, HitRate@10: 0.5111), indicating that accurate identification and ranking of financial terms in Japanese disclosures is far from solved. JF-TE emphasizes that Japanese financial term extraction is not merely problem of surface matching, but one of identifying and ranking domain-relevant terminology in setting dominated by loanwords with shifted meanings and densely populated financial expressions shaped by Japanese disclosure conventions."
        },
        {
            "title": "5 Conclusion",
            "content": "We present EBISU, benchmark for evaluating LLMs on Japanese financial language understanding, explicitly designed to reflect the linguistic structure and communication norms of Japanese finance. Comprising JF-ICR and JF-TE, EBISU targets two core challenges that arise from the interaction between Japanese language use and Japanese financial practices: implicit commitment recognition and financial term extraction. Experiments 8 across diverse model families show that current LLMs, including state-of-the-art proprietary and open-source systems, struggle on both tasks. While increased model scale yields some improvements, languageand domain-specific training provides limited gains and can even degrade performance. These results reveal persistent gaps rooted in the linguistic and cultural characteristics of Japanese financial communication not solved by current model trainings. By exposing systematic difficulties in commitment recognition and terminology ranking, EBISU offers focused benchmark for advancing LLMs toward deeper and more reliable understanding of Japanese finance."
        },
        {
            "title": "Limitations",
            "content": "Several limitations of EBISU warrant acknowledgment. First,the dataset scope is constrained by practical considerations: JF-ICR comprises Q&A transcripts from 4 companies over limited temporal window (20232026), while JF-TE focuses exclusively on Annual Securities Reports from EDINET. This coverage may not fully represent the diversity of Japanese financial communication across company sizes, industries, or disclosure formats. Second, due to the current dataset size, we do not provide train/test splits in this release. Once the dataset is expanded, standard train/validation/test splits will be introduced to support model training and evaluation. Third, EBISU evaluates two complementary tasks that target core challenges in Japanese financial language understanding but do not encompass the full spectrum of financial NLP capabilities. Both tasks operate on relatively short text segments, limiting evaluation of long-context understanding and multi-turn discourse reasoning. Finally, the evaluation metrics have inherent limitations: Accuracy for JF-ICR treats all misclassifications equally, while exact matching for JF-TE may penalize semantically correct but slightly misaligned spans. equally critical. The focused scope of EBISU introduces potential dataset bias and representativeness limitations. Because the datasets are drawn from limited set of large, publicly listed companies, they may not reflect communication styles, terminology, or disclosure practices across the broader Japanese financial landscape. The temporal scope (20232026) may also not capture evolving financial terminology or regulatory changes. Moreover, as with many benchmarks, there is risk that models may be optimized to perform well on EBISU without corresponding improvements in generalization, potentially encouraging benchmark-specific overfitting. EBISU is released for research and evaluation purposes to advance the understanding of Japanese financial language processing capabilities in large language models. All datasets are constructed from publicly available corporate disclosures and financial documents, and we respect the original data sources terms of use and licensing requirements.The benchmark is intended for academic research, model evaluation, and methodological development. Models that achieve high performance on EBISU should not be assumed suitable for production deployment in financial systems, automated investment analysis, regulatory compliance, or other high-stakes applications without extensive additional validation, human oversight, and domain expert review. The tasks evaluated in EBISU focus on implicit commitment recognition and financial term extraction, which represent specific aspects of Japanese financial language understanding but do not guarantee accurate financial reasoning, risk assessment, or regulatory interpretation. We encourage responsible use of the benchmark and welcome feedback from the research community to improve its coverage, fairness, and utility."
        },
        {
            "title": "Ethical Concerns",
            "content": "The release of EBISU raises several ethical considerations that warrant careful attention. primary concern is risk of over-reliance on benchmark scores for evaluating Japanese financial LLM capabilities. Benchmark performance may not fully predict real-world utility in production systems, where factors such as latency, robustness to distribution shift, and integration with existing workflows are Anthropic. 2025. Claude sonnet 4.5 system card. Technical report, Anthropic. Accessed 2026-01-03. Francis Bond and Timothy Baldwin. 2016. Introduction to japanese computational linguistics. Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems 26, pages 27872795. 9 Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, and William Yang Wang. 2022. Finqa: dataset of numerical reasoning over financial data. Preprint, arXiv:2109.00122. Jacob Cohen. 1960. coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):3746. DeepSeek-AI. 2024. Deepseek-v3 technical report. Preprint, arXiv:2412.19437. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, and 1 others. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Katerina T. Frantzi, Sophia Ananiadou, and Hideki Mima. 2000. Automatic recognition of multi-word terms: the C-value/NC-value method. International Journal on Digital Libraries, 3(2):115130. Kazuki Fujii, Taishi Nakamura, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Shota Hirai, Sakae Mizuki, Rio Yokota, and Naoaki Okazaki. 2024. Continual pre-training for cross-lingual llm adaptation: Enhancing japanese language capabilities. arXiv preprint arXiv:2404.17790. Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noach, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, and 5 others. 2024. framework for few-shot language model evaluation. Google DeepMind. 2025. Gemini 3 flash: Model card. Technical report, Google DeepMind. Accessed 202601-03. Roksana Goworek, Olivia Macmillan-Scott, and Eda Özyigit. 2025. Bridging language gaps: Advances in cross-lingual information retrieval with multilingual llms. arXiv preprint arXiv:2510.00908. Yoko Hasegawa. 2018. The Cambridge handbook of Japanese linguistics. Cambridge University Press. Masanori Hirano. 2024a. Construction of japanese financial benchmark for large language models. arXiv preprint arXiv:2403.15062. Masanori Hirano. 2024b. Japanese-lm-fin-harness: financial evaluation harness for japanese large language models. arXiv preprint arXiv:2403.15062. Masanori Hirano and Kentaro Imajo. 2024. Construction of domain-specified japanese large language model for finance through continual pre-training. arXiv preprint arXiv:2404.10555. Sachiko Ide. 1989. Formal forms and discernment: Two neglected aspects of universals of linguistic politeness. Kentaro Imajo, Masanori Hirano, Shuji Suzuki, and Hiroaki Mikami. 2025. pfgen-bench: Benchmark for evaluating text generation performance of japanese pre-trained models. Terry Joyce, Bor Hodošˇcek, and Hisashi Masuda. 2017. Constructing an ontology and database of japanese lexical properties: Handling the orthographic complexity of the japanese writing system. Written Language & Literacy, 20(1):2751. Kimi Team. 2025. Kimi k2: Open agentic intelligence. arXiv preprint arXiv:2507.20534. Yasutomo Kimura, Eisaku Sato, Kazuma Kadowaki, and Hokuto Ototake. 2024. Understanding tables in financial documents. Klaus Krippendorff. 2011. Computing krippendorffs alpha-reliability. Technical report, Annenberg School for Communication, University of Pennsylvania. Literature updated 2013-09-13. Accessed 202601-04. Kentaro Kurihara, Daisuke Kawahara, and Tomohide Shibata. 2022. JGLUE: Japanese general language understanding evaluation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 29572966, Marseille, France. European Language Resources Association. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles. Yanyang Li, Yingfeng Luo, Ye Lin, Quan Du, Huizhen Wang, Shujian Huang, Tong Xiao, and Jingbo Zhu. 2020. simple and effective approach to robust unsupervised bilingual dictionary induction. arXiv preprint arXiv:2011.14874. Spyros Makridakis. 1993. Accuracy measures: theoretical and practical concerns. International Journal of Forecasting, 9(4):527529. Noriko McCawley. 1975. The structure of the Journal of japanese language by susumu kuno. Japanese Linguistics, 4(1-2):209232. Meta AI. 2025. The llama 4 herd: The beginning of new era of natively multimodal https://ai.meta.com/blog/ ai llama-4-multimodal-intelligence/. Accessed 2025-05-09. innovation. Mistral AI. 2025. Introducing mistral 3. https:// mistral.ai/news/mistral-3. Accessed 2026-0103. 10 Hiromasa Nakatsuka and Yoshiyuki Suimon. 2025. Extracting information and sentiment analysis on dialogue in financial results briefing. Digital Finance, 7(4):605621. Marina Sokolova and Guy Lapalme. 2009. systematic analysis of performance measures for classification tasks. Information Processing & Management, 45(4):427437. Heiko Narrog. 2007. Modality and grammaticalization in japanese. Journal of Historical Pragmatics, 8(2):269294. Kuniya Nasukawa, Ge Song, and Sachiko Kiyama. 2025. The empathetic utterance-final particle-ne in japanese: study on its phonological representation. Journal of Japanese Linguistics, 41(1):95113. OpenAI. 2024. Gpt-4o system card. Technical report, OpenAI. Accessed 2026-01-03. OpenAI. 2025. Gpt-5 system card. Technical report, OpenAI. Accessed 2026-01-03. Xueqing Peng, Triantafillos Papadopoulos, Efstathia Soufleri, Polydoros Giannouris, Ruoyu Xiang, Yan Wang, Lingfei Qian, Jimin Huang, Qianqian Xie, and Sophia Ananiadou. 2025a. Plutus: Benchmarking large language models in low-resource greek finance. arXiv preprint arXiv:2502.18772. Xueqing Peng, Lingfei Qian, Yan Wang, Ruoyu Xiang, Yueru He, Yang Ren, Mingyang Jiang, Vincent Jim Zhang, Yuqing Guo, Jeff Zhao, Huan He, Yi Han, Yun Feng, Yuechen Jiang, Yupeng Cao, Haohang Li, Yangyang Yu, Xiaoyu Wang, Penglei Gao, and 28 others. 2025b. Multifinben: Benchmarking large language models for multilingual and multimodal financial application. Preprint, arXiv:2506.14028. Lingfei Qian, Xueqing Peng, Yan Wang, Vincent Jim Zhang, Huan He, Hanley Smith, Yi Han, Yueru He, Haohang Li, Yupeng Cao, and 1 others. 2025a. When agents trade: Live multi-market trading benchmark for llm agents. arXiv preprint arXiv:2510.11695. Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Jimin Huang, and Qianqian Xie. 2025b. Fino1: On the transferability of reasoning enhanced llms to finance. arXiv e-prints, pages arXiv2502. Qwen Team. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609. Qwen Team. 2024. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115. Qwen Team. 2025. Qwen3 technical report. arXiv preprint arXiv:2505.09388. Kei Sawada, Tianyu Zhao, Makoto Shing, Kentaro Mitsui, Akio Kaga, Yukiya Hono, Toshiaki Wakatsuki, and Koh Mitsuda. 2024. Release of pre-trained models for the japanese language. Makoto Shing, Kou Misaki, Han Bao, Sho Yokoi, and Takuya Akiba. 2025. Taid: Temporally adaptive interpolated distillation for efficient knowledge transfer in language models. Preprint, arXiv:2501.16937. Taiga Someya and Yohei Oseki. 2023. JBLiMP: Japanese benchmark of linguistic minimal pairs. In Findings of the Association for Computational Linguistics: EACL 2023, pages 15811594, Dubrovnik, Croatia. Association for Computational Linguistics. Stability AI. 2023. ble lm beta. japanese-stable-lm-beta-language-models. Accessed 2026-01-04. Introducing japanese stahttps://stability.ai/news/ Hirohisa Sugiura, Yusuke Kawamura, and Hiroshi Hamaguchi. 2025. Edinet-bench: Benchmarking large language models in japanese financial domain. arXiv preprint arXiv:2506.08762. Masahiro Suzuki, Yasushi Ishikawa, Masayuki Teraguchi, and Hiroki Sakaji. 2025. Sentiment works in small-cap stocks: Japanese stocks sentiment with language models. International Journal of Information Management Data Insights, 5(1):100318. Swallow Team. 2025. Llama-3.3-swallow-70b-instructv0.4. Model card. Accessed: 2026-01-04. Katsuo Tamaoka. 2014. The japanese writing system and lexical understanding. Japanese Language and Literature, pages 431471. Kota Tanabe, Masahiro Suzuki, Hiroki Sakaji, and Itsuki Noda. 2024. Jafin: Japanese financial instruction dataset. arXiv preprint arXiv:2404.09260. Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages 142 147. Kentaro Tsutsumi. 2025. Japan sees biggest jump on record in individual shareholdings. Bloomberg News. Foreign shareholders held record high of 32.4% of the total value of Japanese shares in FY2024. Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji Feng, Xiao-Yang Liu, Jimin Huang, and Qianqian Xie. 2025a. Fintagging: An llm-ready benchmark for extracting and structuring financial information. arXiv preprint arXiv:2505.20650. Yan Wang, Keyi Wang, Shanshan Yang, Jaisal Patel, Jeff Zhao, Fengran Mo, Xueqing Peng, Lingfei Qian, Jimin Huang, Guojun Xiong, and 1 others. 2025b. Finauditing: financial taxonomy-structured multidocument benchmark for evaluating llms. arXiv preprint arXiv:2510.08886. 11 Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, Yijing Xu, Haoqiang Kang, Ziyan Kuang, Chenhan Yuan, Kailai Yang, Zheheng Luo, Tianlin Zhang, Zhiwei Liu, Guojun Xiong, and 15 others. 2024. Finben: holistic financial benchmark for large language models. In Advances in Neural Information Processing Systems, volume 37, pages 9571695743. Curran Associates, Inc. Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro Lopez-Lira, and Jimin Huang. 2023. Pixiu: large language model, instruction data and evaluation benchmark for finance. Preprint, arXiv:2306.05443. Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Alejandro Lopez-Lira, XiaoYang Liu, Meikang Qiu, Sophia Ananiadou, Min Peng, and 1 others. 2024. Dólares or dollars? unraveling the bilingual prowess of financial llms between spanish and english. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 62366246. JF-ICR Annotation Guideline JF-ICR focuses on the Annotation Philosophy. degree of commitment expressed in management responses, rather than the surface intent of the question or the factual correctness of the content. Annotations are determined solely by whether and how the answer conveys forward-looking action, decision, or policy stance, reflecting common communication practices in financial disclosures. Due to the cautious and convention-driven nature of Japanese financial disclosures, explicit strong commitments are relatively rare. As result, substantial portion of responses naturally fall into weakly committed or neutral categories, reflecting realistic managerial communication practices rather than annotation ambiguity or inconsistency. A.1 Classification Categories Each answer is annotated based on the speakers degree of commitment toward future action, decision, or policy stance expressed in the response. +2: Strong Commitmentclear, explicit, and unambiguous commitment to concrete action or outcome. +1: Weak or Qualified Commitmentintention or directional stance expressed with conditions, hedging, or limited scope. 0: Neutral or Hedged Intentclarification, explanation, assessment, or perception without commitment or refusal. -1: Weak Refusalimplicit or qualified rejection of proposed action. -2: Strong Refusalexplicit and definitive rejection with no flexibility. A.2 General Annotation Rules Annotation focuses on intent and commitment strength, not factual correctness. Only statements expressing future actions, decisions, policies, targets, or strategic directions are considered for non-zero labels. Annotation is based on the content of the answer, not the surface form or intent of the question. Even if the question is retrospective or explanatory, the answer may introduce forward-looking commitment or refusal. If an answer does not express any futureoriented action, decision, or policy stance, it should be annotated as 0, regardless of the question. Hedging expressions (e.g., uncertainty, dependency on conditions, ongoing review) reduce commitment strength. When multiple signals appear, the label reflects the strongest applicable commitment or refusal expressed in the answer. Annotation is based on the overall stance of the full response, rather than isolated sentences or individual expressions; labels reflect the speakers dominant commitment or refusal as conveyed by the answer as whole. Annotations focus on the strength of commitment, rather than the tone, length, or politeness of the response. Conventional polite expressions in Japanese financial discourse (e.g., 努めてまいります) do not by themselves imply commitment. A.3 Specific Annotation Rules +2 (Strong Commitment): Applied when the answer contains clear, decisive statement indicating firm commitment. Typical linguistic signals include: しますを実施しますを達 成します を決定していますは確定してい ます 方 針 を 変 更 す る 考 え は あ り ま せ ん (when directly answering decision or policy question) Representative examples include: 来期は増配を実施します 中長期でROE12%を達成します この施策により利益成長は実現できると 確信しています +1 (Weak or Qualified Commitment): Applied when the answer expresses positive or leaning commitment toward future action or outcome, but with qualifications, caution, or limited specificity. Such responses indicate directional intent or possibility rather than finalized decision. Typical linguistic signals include: していきたいを目指していま す 13 と考えていますを見込んでいま す Conditional or hypothetical expressions (e.g., であれば次第で) Representative examples include: 成長投資を進めていきたいと考えていま す 今後も収益は拡大していくと見ていま す 環 境 が 整 え ば 検 討 を 進 め る 考 え で す 0 (Neutral or Hedged Intent): Applied when the answer exhibits genuine ambiguity or provides clarification, explanation, or background without expressing commitment or refusal toward any future action, decision, or policy stance. Such responses may describe facts, context, perceptions, or reasoning, but do not convey directional or evaluative position regarding future behavior. Typical linguistic signals include: 断定できません明確な見通しは示 せない 検討中状況を見極める必要がある Purely descriptive or explanatory statements providing facts or background Representative examples include: 現 時 点 で は 明 確 な 見 通 し は 示 せ ま せ ん 様々な見方がありコメントは差し控え ます 過去にはこのような取り組みを行ってき ました (background explanation only) -1 (Weak Refusal): Applied when the answer expresses negative stance toward proposed future action or change, but does so in qualified, conditional, or time-bound manner that leaves room for future reconsideration. Such responses reject the action in the current context without ruling it out permanently. Typical linguistic signals include: 現時点ではしない直ちには考えて いない 今後検討の余地はあるが Refusals framed as temporary, conditional, or dependent on future circumstances Representative examples include: 現時点では配当方針を変更する考えはあ りません 今中計期間中に見直すことは想定してい ません 足元では難しいと考えていますが今後 は検討します -2 (Strong Refusal): Applied when the answer clearly and definitively rejects proposed future action, decision, or policy stance, leaving no visible room for reconsideration. Such responses convey firm and final negative position. Typical linguistic signals include: Avoid including surrounding explanatory text, verbs, or modifiers If span does not represent financial or accounting concept, it should not be annotated. B.3 Definition of Financial Terms する予定はありません は行いませんを否定します financial term is defined as word or phrase that denotes: Representative examples include: An accounting item or financial statement 株式分割を行う予定はありません 当該事業への投資は実施しません そ の 想 定 は 当 社 の 方 針 で は あ り ま せ ん JF-TE Annotation Guideline JF-TE focuses on idenAnnotation Philosophy. tifying financial and accounting terminology explicitly defined or referenced in notes and annotations (注記) of Japanese Annual Securities Reports. These sections are primarily functional and explanatory, serving to define accounting concepts, clarify disclosure scope, or specify calculation and regulatory conditions, rather than to provide narrative or managerial discussion. Annotations aim to capture domain-relevant financial terms as they appear in disclosure notes, reflecting realistic accounting and reporting practices. B.1 Scope of the Text All input texts are extracted exclusively from nonnarrative explanatory sections, including: Footnotes and annotation blocks (注記) Explanatory remarks below tables Definitions of accounting items, metrics, or disclosure conditions Clarifications of calculation methods, scope, or regulatory treatment"
        },
        {
            "title": "These texts should be interpreted within their",
            "content": "definitional and regulatory context. component financial metric, ratio, or valuation concept disclosure category, reporting unit, or consolidation scope legally or regulatorily defined financial or accounting concept General language or procedural expressions should not be annotated unless they constitute recognized financial terminology. B.4 Nested and Overlapping Terms Financial terms may appear in nested or overlapping forms. Annotators should follow these rules: Both nested and non-nested financial terms should be annotated if they independently represent meaningful financial or accounting concepts. When longer term contains shorter term, each should be annotated separately, provided that each span has standalone financial meaning. Annotators should always select the minimal span for each term, even when multiple annotated spans overlap. Nested terms should not be merged unless the shorter term lacks independent financial meaning outside the longer expression. B.5 Exclusions The following should not be annotated: General verbs, adjectives, or explanatory B.2 Annotation Unit phrases Each annotation unit corresponds to single text span (NER-style span). Annotators should: Purely numerical values or units (unless part of named financial term) Select only the minimal span that represents Time expressions without financial meaning financial or accounting term Cross-references, footnote symbols, or formatPrefer noun or noun-phrase spans ting markers 14 B.6 Representative Examples Example 1: Single Financial Term. 注当社は金融危機等の状況下でも安 定した資金確保を目的として取引銀行と コミットメントラインを設定しましたこ の契約に基づく借入未実行残高は次のとお りであります Annotated spans: 取引銀行 コミットメントライン 借入未実行残高 No nested annotation is applied in this example, as the identified financial terms represent parallel disclosure units rather than compositional or hierarchical expressions. Example 2: Nested Financial Terms. () 潜在株式調整後1株当たり当期純利益に ついては潜在株式がないため記載してお りません Annotated spans: 潜在株式調整後1株当たり当期純利益 financial reasoning tasks. Prior to their doctoral studies, they accumulated professional experience as quantitative researcher in the financial industry, providing practical exposure to real-world financial data and analytical workflows. Another annotator is researcher at Japanese fintech company with nearly two decades of experience in the Japanese financial market. They hold Ph.D. in Economics and possess deep expertise in Japanese corporate finance, financial reporting, and investor communications. As native-level Japanese speaker, they are familiar with the linguistic, cultural, and institutional conventions of Japanese financial disclosures, including earnings reports, management commentary, and shareholder meeting materials. Together, the annotators combined academic training, industry experience, and linguistic competence enable the construction of high-quality Japanese financial benchmark. Their expertise ensures that the annotations are both technically accurate and contextually grounded, providing reliable foundation for evaluating Japanese financial language understanding. 潜在株式 1株当たり当期純利益 当期純利益 純利益 Example 3: Non-Annotated Content. (注) 主 に 通 信 販 売 し て い る 機 能 性 表 示 食 品 ご ま 豆 乳 仕 立 て の み ん な の み か たDHA特定保健用食品イマークＳ などの健康食品 No annotation is applied, as the sentence does not introduce specific financial or accounting term."
        },
        {
            "title": "C Annotator Demography",
            "content": "All annotations in EBISU were conducted by annotators with strong financial expertise, substantial professional experience, and high proficiency in Japanese, ensuring both domain fidelity and annotation reliability. One annotator is doctoral student in Japan with solid academic background in financial mathematics and several years of study and residence in Japan. Their research focuses on AI applications in finance, and they have previously contributed to the annotation of financial benchmarks targeting"
        },
        {
            "title": "D Annotation Process",
            "content": "Figure 3: The Label Studio interface of the JF-ICR annotation process. Figure 4: The Label Studio interface of the JF-TE annotation process."
        },
        {
            "title": "E Quality Validation",
            "content": "To assess the reliability of the JF-ICR and JFTE annotations, we compute 3 standard interannotator agreement metrics: Macro-F1, Cohens κ, and Krippendorffs α. Below we summarize their formal definitions. Macro-F1. Let denote the set of categories, and for each category C, we compute Precisionc = Pc Pc + Pc , Recallc = Pc Pc + Nc . The category-level F1 score is F1c = 2 Precisionc Recallc Precisionc + Recallc . (1) (2) (3) Macro-F1 averages the per-class F1 scores uniformly: Macro-F1 = 1 (cid:88) cC F1c. (4) Compared to accuracy, Macro-F1 weights all classes equally and is therefore more sensitive to skewed label distributions. Cohens κ. For two annotators r1 and r2, let Krippendorffs α (Nominal Scale). Krippendorffs α accommodates multiple annotators and missing labels. It is defined as α = 1 Do De . (8) For nominal categories, the distance function is δ(a, b) = (cid:40) 0, = b, 1, = b. (9) Let be the number of items, ni the number of annotations for item i, nia the number of times item receives label a, and na the total number of times label appears. Then Do = 1 (cid:88) i=1 1 ni 1 (cid:88) a=b nia nib, (10) De = 1 (N 1) (cid:88) a=b na nb. (11) When annotators completely agree, α = 1, and larger values indicate higher annotation reliability."
        },
        {
            "title": "F Evaluation Metrics",
            "content": "The JF-ICR task is an intent recognition problem, which is treated as multi-class classification task over the label set {+2, +1, 0, 1, 2}. Given predicted label ˆyi and the annotated gold label yi for the i-th instance, Accuracy is defined as: Acc ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) i=1 1(ˆyi = yi) , (12) Po = (cid:88) cC pcc, Pe = (cid:88) cC pc pc, where pcc is the empirical probability that both annotators assign category c, and pc and pc are the corresponding marginal probabilities. Cohens κ corrects observed agreement by subtracting chance agreement: κ = Po Pe 1 Pe . (7) value of κ = 1 indicates perfect agreement, while κ = 0 corresponds to chance-level agreement. where 1() is the indicator function and is the total number of instances. The JF-TE task is evaluated using two-level metric design to reflect the hierarchical structure of financial terminology in Japanese disclosures. (5) (6) Maximal Financial Term F1. For each instance, we derive the set of maximal financial terms from both gold annotations (Mgold) and predictions (Mpred). We compute: = (cid:12) (cid:12)Mgold Mpred (13) (cid:12) (cid:12) . Precision = Recall = (cid:12) (cid:12) (cid:12) (cid:12)Mpred (cid:12) (cid:12)Mgold (cid:12) (cid:12) F1 = 2 Precision Recall Precision + Recall . 17 (14) (15) (16) HitRate@K for Nested Financial Terms. For the i-th instance, let Gi denote the set of gold nested terms and (K) the top-K predicted terms: HR@K(i) = (cid:12) (cid:12)Gi (K) (cid:12) Gi (cid:12) (cid:12) (cid:12) . (17) The final score averages over all valid instances: HR@K = 1 (cid:88) i=1 HR@K(i). (18) We report HR@1, HR@5, and HR@10 to account for different levels of ranking tolerance."
        }
    ],
    "affiliations": [
        "Meiji Gakuin University",
        "National Institute of Advanced Industrial Science and Technology (AIST)",
        "New York University",
        "The Fin AI",
        "The National Centre for Text Mining",
        "The University of Tokyo",
        "University of Manchester"
    ]
}