{
    "paper_title": "Locality in Image Diffusion Models Emerges from Data Statistics",
    "authors": [
        "Artem Lukoianov",
        "Chenyang Yuan",
        "Justin Solomon",
        "Vincent Sitzmann"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Among generative models, diffusion models are uniquely intriguing due to the existence of a closed-form optimal minimizer of their training objective, often referred to as the optimal denoiser. However, diffusion using this optimal denoiser merely reproduces images in the training set and hence fails to capture the behavior of deep diffusion models. Recent work has attempted to characterize this gap between the optimal denoiser and deep diffusion models, proposing analytical, training-free models that can generate images that resemble those generated by a trained UNet. The best-performing method hypothesizes that shift equivariance and locality inductive biases of convolutional neural networks are the cause of the performance gap, hence incorporating these assumptions into its analytical model. In this work, we present evidence that the locality in deep diffusion models emerges as a statistical property of the image dataset, not due to the inductive bias of convolutional neural networks. Specifically, we demonstrate that an optimal parametric linear denoiser exhibits similar locality properties to the deep neural denoisers. We further show, both theoretically and experimentally, that this locality arises directly from the pixel correlations present in natural image datasets. Finally, we use these insights to craft an analytical denoiser that better matches scores predicted by a deep diffusion model than the prior expert-crafted alternative."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ] . [ 1 2 7 6 9 0 . 9 0 5 2 : r a"
        },
        {
            "title": "Locality in Image Diffusion Models\nEmerges from Data Statistics",
            "content": "Artem Lukoianov Massachusetts Institute of Technology arteml@mit.edu Chenyang Yuan Toyota Research Institute chenyang.yuan@tri.global Justin Solomon Massachusetts Institute of Technology jsolomon@mit.edu Vincent Sitzmann Massachusetts Institute of Technology sitzmann@mit.edu https://locality.lukoianov.com"
        },
        {
            "title": "Abstract",
            "content": "Among generative models, diffusion models are uniquely intriguing due to the existence of closed-form optimal minimizer of their training objective, often referred to as the optimal denoiser. However, diffusion using this optimal denoiser merely reproduces images in the training set and hence fails to capture the behavior of deep diffusion models. Recent work has attempted to characterize this gap between the optimal denoiser and deep diffusion models, proposing analytical, training-free models that can generate images that resemble those generated by trained UNet. The best-performing method hypothesizes that shift equivariance and locality inductive biases of convolutional neural networks are the cause of the performance gap, hence incorporating these assumptions into its analytical model. In this work, we present evidence that the locality in deep diffusion models emerges as statistical property of the image dataset, not due to the inductive bias of convolutional neural networks. Specifically, we demonstrate that an optimal parametric linear denoiser exhibits similar locality properties to the deep neural denoisers. We further show, both theoretically and experimentally, that this locality arises directly from the pixel correlations present in natural image datasets. Finally, we use these insights to craft an analytical denoiser that better matches scores predicted by deep diffusion model than the prior expert-crafted alternative."
        },
        {
            "title": "Introduction",
            "content": "Denoising diffusion models [8, 27] have achieved state-of-the-art results for generative modeling, especially for domains involving continuous data distributions such as images, videos, and audio. They are trained to predict clean image from one corrupted by varying levels of Gaussian noise. Analysis of the diffusion model training objective leads to an apparent paradox: The objective admits an analytical, non-parametric, and closed-form solution that is only function of the training dataset. However, this so-called optimal denoiser does not empirically match the outputs of deep diffusion models and in fact can only produce images in the training set, exhibiting perfect memorization and failing to generate novel images. Recent work investigates this paradox and proposes changes to the optimal denoiser to close the gap between theory and practice [12, 19, 25, 26]. Kamb and Ganguli [12] hypothesize that the inductive bias of the neural network architectureparticularly shift equivariance and locality biases of convolutional neural networksprevent the model from converging to the global optimum of the Preprint. Under review. loss function and thus allows for generalization. Locality here means that during denoising, any pixel in the denoised output will only be sensitive to local neighborhood around that pixel in the noisy input. They demonstrate that adding locality and equivariance constraints to the closed-form optimal denoiser yields model that generates images that closely resemble those generated by simple UNet diffusion model. However, their theory has key limitation: it cannot predict the degree of locality from first principles. Instead, their method relies on measuring the receptive field of trained UNet diffusion model and estimating patch size for each diffusion timestep that is then fed as parameter to their analytical model. Further, other neural network architectures, such as transformers, can similarly generate novel images, but they lack either explicit locality or shift-equivariance inductive biases; even U-Nets generally have receptive field that covers the complete image. In this work, we demonstrate that locality in image diffusion models is not property of the neural network architecture and instead can be derived directly from the training dataset via simple statistical analysis. Specifically, we analyze the principal components of the datain particular, their signalto-noise (SNR) ratioand show that learned sensitivity fields for different architectures closely approximate projection operators onto principal components with high SNR. On CIFAR10 [16], dataset with high self-similarity across pixel locations, simple locality pattern emerges. However, on CelebA-HQ [13], dataset of centered human faces, sensitivities are nonlocal, aligned with correlations of pixels across, for instance, the eyes. We relate this behavior to the optimal linear denoiser known as the Wiener filter, establishing connection to prior work that observed linear behavior of diffusion models [17, 29]. We provide further evidence that sensitivity fields are learned to match statistical properties of the training set by showing that we can achieve arbitrary, nonlocal patterns in models sensitivity field by imperceptibly editing the pixel statistics of the training set. We rigorously benchmark recent analytical models by how well they match generations by trained deep diffusion model. Surprisingly, we find that simple Wiener filter outperforms all recent analytical methods based on modifications of the optimal denoiser. Integrating our analytically-derived sensitivity fields into the model of Kamb and Ganguli [12], however, yields the best-performing analytical diffusion model to-date across multiple datasets, including CIFAR10 [16], AFHQv2 [4], and CelebA-HQ [13]. This observation provides evidence that capturing pixel correlations across dataset plays major role in the performance of denoising diffusion models. In summary, our contributions are as follows: We demonstrate that local sensitivities in trained image diffusion models are learned property of deep diffusion models and not just an inductive bias of the model architecture. We analytically derive the spatial sensitivity of an optimal linear filter as function of the training data and show empirically that it closely matches that learned by denoising neural network, yielding both local and nonlocal sensitivities depending on the training data statistics. We establish quantitative benchmark to measure how well an analytical diffusion model explains predictions made by UNet and demonstrate that, surprisingly, prior optimal denoiser-based methods are outperformed by simple optimal linear filter. We incorporate our analytically-computed locality into the optimal denoiser-based model proposed by Kamb and Ganguli [12] and show that it outperforms alternative analytical models while eliminating previously heuristically-determined hyperparameter."
        },
        {
            "title": "2 Preliminaries and Related Work",
            "content": "We discuss preliminaries and related work for our primary line of inquiry, building analytical models of deep diffusion networks. Denoising diffusion models. Score-based image generative models [8, 27, 28] learn to reverse the process of adding Gaussian noise to clean data. During training, we sample data point x0 from the training data distribution X, noise level from the interval [0, 1], and Gaussian noise direction ϵ (0, I); noise schedule αt is chosen such that α0 = 1 and α1 = 0. We then add noise to x0 to 1 αtϵ. The training objective for an image diffusion model (x, t), also obtain xt = αtx0 + known as score-matching, aims to predict x0 given xt:1 (cid:13)f (cid:0) (cid:13) αt x0 + 1 αt ϵ, t(cid:1) x0 (cid:13) 2 (cid:13) 2 (1) min x0X ϵN (0,I) t[0,1] Recent studies explored the generalization capabilities of diffusion models, highlighting the contradiction between their theoretical propensity for memorization and their empirical ability to generate novel samples. Yoon et al. [34] introduce the memorization-generalization dichotomy, positing that diffusion models generalize when they avoid memorizing training data. Yi et al. [33] formalize generalization through mutual information metrics, demonstrating that trained diffusion models can generalize beyond the empirical optimal solutions. Gu et al. [7] further investigate this phenomenon, revealing that factors such as dataset size and conditioning can influence the extent of memorization in diffusion models. Analytical diffusion via the optimal denoiser. Multiple works [5, 14, 23, 25] identify the optimal denoiser as promising analytical model for the behavior of deep diffusion models. This optimal denoiser ˆf (x, t) minimizing (1) can be written as conditional expectation: ˆf (x, t) = E[x0 xt = x] (2) When the data distribution is approximated with finite empirical distribution = {x(i) due to the fact that we have an analytic form for density p(xt) = ( denoiser is available in closed-form [5, 14, 23, 25]: 0 }i[N ], and αtx0, (1 αt)I), the optimal ˆf (x, t) = (cid:88) i= wi(x, t)xi 0, wi(x, t) = softmax (cid:26) 1 2σ2 (cid:13) (cid:13) (cid:13)x αtxj 0 2(cid:27) (cid:13) (cid:13) (cid:13) j[N ] , (3) = 1 αt and softmaxi {aj}j[N ] = where σ2 j=1 exp(aj ) . This expresses the optimal denoiser (cid:80)N as kernel-weighted average over the training set, and clarifies the key limitation of the optimal denoiser as an appropriate model for deep neural networks: As the noise level approaches zero, the softmax term in effect picks the nearest neighbor in the training set. As result, the optimal denoiser will always generate an image in the training set and never generate novel image. exp(ai) Improving the optimal denoiser via smoothing. To promote generalization, Scarvelis et al. [25] propose smoothing the score function to generate novel samples different from the training data. Niedoba et al. [18] derive an efficient nearest neighbor search to support the implementation of the analytical score models. Separately, Shah et al.[26] proposes smoothing the empirical training data distribution by adding Gaussian noise to encourage neural network models to generalize in the small-data regime. Aithal et al. [1] argue that hallucinations in diffusion models happen due to smooth interpolation between modes of the data distribution. Adding inductive biases to the optimal denoiser. Kadkhodaie and Simoncelli [11] observe that the inductive biases of neural networks align well with the data density, effectively projecting data onto low-dimensional basis adapted to the image structure. Based on this insight, Kamb and Ganguli [12] and Niedoba et al. [19] suggest that the gap between the optimal denoiser and deep diffusion models stems from the inductive bias of the deep neural network used to approximate the denoiser. Specifically, they assume that the structure of the convolutional U-Net [24] imposes constraints of locality and/or shift equivariance on the function in the score-matching objective eq. (1): min x0X,ϵN (0,I),t[0,1] ( αtx0 + 1 αtϵ, t) x02 2 s.t. q(x, t) = q(M x, t) (g x, t) = (x, t) (2), (4) (locality) (equivariance) 1In practice, often linear combination of ϵ and x0 is predicted, but these are all equivalent to (1) for the purposes of deriving an optimal denoiser and for our theoretical analysis. Without loss of generality, through the rest of the paper, we will assume that all models are trained to predict x0. We provide additional details on the effects of parametrization in sections A.1 and B.3 3 where is pixel of the output, is masking operator for each time-step selecting patch around pixel q, and (2) is the 2D translation group acting on Rn through . They show that for general , the solution for the constrained score-matching objective eq. (4) has similar form compared to eq. (3), but with weights specific to each pixel such that ˆf q(x, t) = (cid:88) wq i,g(x, t)(g xi 0)q, wq i,g(x, t) = softmax i,g i[N ] gT (2) (cid:26) 1 2σ2 (cid:13) (cid:13)M (cid:13) (x αth xj 0) (cid:27) (cid:13) 2 (cid:13) (cid:13) 2 , j[N ] hT (2) (5) where is binary mask, and we end up again with an isotropic multivariate Gaussian projected to subspace defined by the mask. Effectively, this model splits each training image into patches of size Mt, forgets about their location (equivariance), and denoises each input pixel by taking the average of the center pixels in the ground truth patches weighted with the distances to them from the patch centered at q. Kamb and Ganguli [12] obtain patches for each noise level by iterating over all possible square binary patches and choosing the one that yields the best correlation with trained diffusion model. Niedoba et al. [19] relax the constraint on the shape of the patches and allow them to be of arbitrary shape but compact and averaged across all pixels. Then they measure the average sensitivity of trained U-Net and binarize it to get the masks. Both works fit masks to the empirically-observed locality fields of the trained models and average all the masks for each pixel q, i.e. are identical up to translation. and Linear denoisers. Recent studies have uncovered that diffusion models exhibit strong linear behavior. Wang and Vastola [29, 30] provide theoretical and empirical evidence that, at high noise levels, the learned score functions of well-trained diffusion models closely align with those of linear models. Linear denoisers are well-studied [2, 20, 31], and one can show that the optimal denoiser constrained to be linear has the same form as the optimal denoiser on Gaussian dataset [15]. Li et al. [17] demonstrate that, particularly in the generalization regime and for high levels of noise diffusion, denoisers approximate the optimal denoiser for multivariate Gaussian distribution characterized by the empirical mean and covariance of the dataset."
        },
        {
            "title": "3 Deriving Denoising Sensitivity from Dataset Statistics",
            "content": "In this section, we explore the relationship between generalization and locality in patch-based optimal denoisers [12, 19] and link it to the observed linearity of diffusion models [17, 29, 30]. Unlike the optimal denoiser in eq. (3), trained diffusion models exhibit pass-through behavior, retaining input information along high signal-to-noise (SNR) ratio data directions. We hypothesize that by constraining the locality in patch-based optimal denoisers, previous works effectively adopt the pass-through behavior from linear denoisers and thus are capable of producing novel images. Sampling voids. The optimal denoiser ˆf (x, t) is well-defined for all values of Rn and (0, 1), but the distribution of (xt, t) that neural network denoiser is trained on has low-density regions that will be sparsely sampled throughout the training process. For example, when 0 (low noise regime), regions in Rn far away from training data will be undersampled in training the diffusion model with score-matching objective in eq. (1). This is illustrated in Figure 1 (left), where the regions of small noise near the test images are not covered with any training samples. We will refer to the part of Rn [0, 1] that is not covered by the empirical samples in eq. (1) as sampling void regions. On one hand, the behavior of the denoiser in those regions is critical for generalization. On the other hand, the optimal denoiser is not good model of trained diffusion model in these regions, as there were no empirical samples in this part of the space during training. In the next sections, we will build up intuition on how to reason about the behavior of the trained diffusion models in the sampling void regions. Pass-through denoisers. When the optimal denoiser in eq. (3) is presented with test image outside of the training dataset and the amount of noise is small, the softmax becomes more selective, and the optimal denoiser will predict x0 to be the closest image in the dataset (see Figure 1, middle). This behavior prevents generalization, as any novel image will be teleported to its closest neighbor in the training dataset as σt 0. 4 Figure 1: Left: We visualize the distribution of xt for two training data points x(1) as high-probability0 density cones, as function of spatial dimension and noise level t. Note how for new testing point x(test) there exists noise level such that noised versions of x(test) are outside of any of the training cones and thus the behavior of the denoiser there is undefined. Middle: We take CIFAR10 test images (top) and add noise ϵt (2nd row). With single denoising step, trained diffusion model fθ passes through most of the coarse structure of the input image, and thus the output image is visually similar to the input (3rd row). Optimal denoiser instead teleports the image to the closest data point in the training dataset (4th row). Right: We compare MSE error of single-step denoising of fθ (Unet) and (Optimal). At low noise levels, fθ removes noise from x(test) but predicts different image from x(test) . At high noise levels, the outputs of fθ and are similar. and x(2) 0 0 0 Inspired by the observations in Figure 1, we develop an intuition about pass-through properties of denoisers. For small noise levels, lot of information in the image is not destroyed by the added noise. It is natural to assume that good denoiser, unlike the optimal denoiser, will retain this information in its estimation of x0. Which part of xt is not affected by small amount of noise? Informally, for natural images, low frequencies survive after adding small amounts of noise. We formalize this intuition by observing that 1) adding noise preserves the higher principal components of data, and 2) these principal components correspond to low-frequency features in natural images. 1, λ2 2, . . . λ2 )U , where is matrix of the eigenvectors and λ2 The principal components of the data come from the eigendecomposition of the covariance matrix Cov(X) = diag(λ2 are eigenvalues. The noises covariance matrix σ2I is also isotropic in this basis, so that the signal-to-noise ratio (SNR) along the i-th principal component is λ2 /σ2 . It is well-known in classical image processing literature [10] that for natural images, this eigenbasis approximates the Fourier basis, and thus the highest variance components (equiv. high SNR) correspond to low-frequency features. Thus, intuitively, the pass-through projection resembles low-pass filter. Generally, however, it is not the case, and for more specific datasets, the pass-through projection is not just low-pass filter. For instance, as we will show in section 4, for datasets such as centered and normalized human faces (i.e., Celeba-HQ/FFHQ), the eigen-basis is very different from Furrier basis, and thus the locality patterns observed in trained denoisers are not translation equivariant, nor isotropic. Connection to Gaussian data and linear denoiser. The intuition in the previous paragraphs was built on an assumption that the dataset is well-described with single covariance matrix (assuming Gaussian data distribution). In this case, one can craft simple denoiser by just projecting the input noise images to their high-SNR principal components: Wt = 1 αi diag (cid:19) (cid:18) λ2 λ2 + σ2 . (6) This denoiser, optimal under Gaussian dataset assumption x0 (0, Σ) [15], is known as the Wiener filter [31]. At the same time, the Wiener filter is also the optimal linear denoiser minimizing eq. (1) under linear constraint (xt) = Atxt [31]. As we can see from eq. (6), it projects its input to the datas principal components, shrinks these projections according to their SNR, and projects them back to the data space. As reported in multiple previous works [17, 29], trained diffusion models exhibit linear behavior and can be surprisingly well-approximated with Wiener filter. Later in this work, we extend these observations and demonstrate that the Wiener filter performs on par with or better than existing patch-based analytical denoisers [12, 18]. Locality and sensitivity. So far, we built up the intuition that good denoiser should passthrough high-SNR components of the input in the sampling void regionsparts of space where optimal denoiser analysis is no longer effective, critical for generalization. According to [12, 19], 5 locality of the denoisers sensitivity fields plays crucial role for its generalization. But how does it relate to the pass-through intuition above? To show the relationship, we return to the notion of locality. By locality, we mean limited, typically compact sensitivity field of neural network. Formally, the sensitivity field of denoiser (x, t) is its inputoutput Jacobian Sf (x, t) = (x, t)/x. Kamb and Ganguli [12] approximate learned locality patterns in diffusion models with square patches, assuming them to be compact, roughly isotropic, and constant with respect to both the output pixel position and the input image. As we will demonstrate in section 4, none of these assumptions is universal, and while they are reasonable for diverse datasets of natural images, the sensitivities of neural diffusers on more specialized datasets can violate any of the assumptions above. For our analysis, we retain the assumption of independence with respect to the input image and lift all other assumptions, allowing locality patterns to take arbitrary shapes and depend on the output pixel. Under the assumption that the sensitivity Sf (x, t) is constant w.r.t. x, the denoiser is linear in and takes the form (x, t) = At + Bt, where At is the sensitivity and Bt is bias term. Recall that solution to eq. (1) under linear constraint is the Wiener filter and thus At = Wt and Bt = 0 assuming the dataset is centered. For each individual output pixel q, the sensitivity takes the form: (x, t) = Sq = (cid:20) diag (cid:18) SNRi (cid:19) SNRi + 1 (cid:21)q where SNRi = λ2 σ2 . (7) In other words, with the assumption that locality patterns are shared for all input images, the sensitivity of the denoiser is identical to the high-SNR projection operator to the principal components of the covariance matrix. key observation about the form of eq. (7) is that as σt 0 the signal-to-noise ratio for each component SNRi inf and thus Sq (x, t) 1q, i.e., the sensitivity field of the locally linear denoiser shrinks with smaller noise levels. As we showed above, under the local linearity assumption, the exact shape of those sensitivity fields is function of the data and not of the models architecture. In the subsequent sections, we empirically show that different architectures of denoising diffusion models learn sensitivity fields similar to those of linear denoisers, effectively approximating the projection operator to the high-SNR datas principal components. Recall that previous work [12, 19] adopts the learned sensitivity fields from the trained diffusion networks, which play crucial role in their generalization. As we reveal the connection of the sensitivity field to the local data statistics, we obtain valuable insights into the performance of the analytical models, especially for specialized datasets, where the datas principal components are far from being local and equivariant."
        },
        {
            "title": "4 Validation",
            "content": "In this section, we perform extensive validation to support our claims. As the main backbone for diffusion model, we use the DDPM UNet [8] with removed self-attention to follow the protocol of [12]. As we show in section B.2, removing the self attention does not drastically affect performance, and our insights are valid for both architectures. We begin by showing that different neural network architectures learn similar sensitivity fields, which in turn match projection operators to high-SNR principal components, or equivalently, the Wiener filter. We continue by demonstrating that the learned sensitivity fields are property of the dataset and thus by manipulating the statistics of the data, we can force the diffusion models sensitivity to take any shape, including being nonlocal for low noise levels. Finally, to support our claim that the locality properties of trained diffusion models come from data statistics, we suggest simple modification to previous patch-based analytical models [12, 19]. Instead of measuring locality from trained diffusion models, we limit the analytical model to only use high-SNR principal components. We benchmark this modification on five datasets and show that while being more interpretable, this algorithm also explains trained diffusion models better than other baselines. Additionally, we ablate our model and present comparisons in section B.1. Locality pattern is shared across architectures. We compare the locality patterns throughout the denoising process across architectures (U-Net [8] and diffusion transformer (DiT) [21]) trained on 6 Figure 2: Comparison of sensitivity fields of deep denoisers and the projection operators to high-SNR datas components (eq. Wiener filter) on CIFAR10 dataset. Sensitivity is measured at the center pixel w.r.t. x0 prediction and throughout 1000-step DDIM denoising process. Each image is averaged across 32 samples and normalized to [0,1]. the CIFAR10 dataset. Although there is architectural bias for locality in U-Nets due to convolutional layers, the self-attention layers in DiTs are global in scope, where every patch can attend to any other patch. Nevertheless, Figure 2 shows that U-Nets and DiTs share similar sensitivity fields. Surprisingly, these fields are similar to the shapes of high-SNR projector operators, i.e., the sensitivity of Wiener filter. This provides evidence that the main reason for the diffusion models to exhibit locality properties is the correlation of the pixels between the images in the dataset. Our observation is that the architecture of the neural network matters, but is secondary to the data and serves as container accommodating the locality properties dictated by the covariance in the data. Learned sensitivity fields are not always equivariant. As we saw in the previous experiment, the sensitivity fields learned by diffusion models are similar across architectures and align with the datas principal components. In Figure 2, these fields appear roughly isotropic and equivariantmeaning the sensitivity sq(x) has the same shape for each pixel q, up to translation. This form of sensitivity is well-captured by the square-shaped patches in [12]. This behavior arises due to the high correlation among neighboring pixels and the translation equivariance inherent in the CIFAR10 dataset, which consists of diverse natural images. However, for more specialized datasets, the principal componentsand consequently the learned sensitivity fieldstake on drastically different shapes. In particular, CelebA-HQ is dataset of uniformly-scaled and centered human faces. The lack of translation equivariance and the unique pixel correlation patterns result in structured, location-dependent sensitivity fields. In Figure 3, we observe the complex structure that arises in the sensitivity fields of diffusion model trained on CelebA-HQ. Notably, the pattern of sensitivity is now highly dependent on the pixels location. This experiment highlights the need for more flexible representations of sensitivity fields, especially for specialized datasets, than those in prior work. Manipulating the sensitivity field. We show that by editing the datasets statistics, we can manipulate the sensitivity fields of neural denoisers and make them take on any shape. With this manipulation, U-Net-based denoisers can learn sensitivity fields that are not local, thus suggesting that the locality properties of learned denoisers emerge from dataset statistics. 7 Figure 3: Average sensitivity fields of trained DDPM on the CelebA-HQ dataset. The top row corresponds to an output pixel located near the left eye; the bottom row corresponds to an output pixel near the image center. Left to right: different noise levels corresponding to of 600, 400, 200. In our experiment on CIFAR-10, we generate modified dataset: ˆx0 = x0 + γcs, Uniform([1, 1]3), where x0 Rd is training image, {0, 1}d is fixed binary mask in the shape of the letter W, and R3 is random RGB vector (single color per image) with γ > 0 controlling signal strength. Note that this transformation does not change the first-order moments of the data as E[γcs] = 0. With this, we train new DDPM UNet from scratch on the modified CIFAR10 dataset and then study its sensitivity fields. Let λw be the variance of the perturbation. We choose γ so that λw σt for some intermediate t, i.e., the variance of the added signal matches the variance of the noise. As we can see2 from Figure 4, the W-shaped sensitivity field emerges for all where σt λw. Crucially, this demonstrates that any desired pattern can be induced in the sensitivity of trained neural network by embedding the pattern into the data covariance. Figure 4: We slightly manipulate pixels correlation across the CIFAR10 dataset such that desired pattern emerges in the sensitivity of trained diffusion model. In particular, DDPM diffusion model trained on the CIFAR10 dataset (sample on the top left) has coarse-to-fine sensitivity field (top row, noise level decreases from left to right). For each image in the dataset, we edit pixel correlations by adding the desired pattern with random color and weights γ = 0.1 (middle row) and γ = 0.5 (bottom row). DDPM models trained on those manipulated datasets exhibit the pattern in their sensitivity fields. We underscore the time-steps for which σt < 10λW . This supports our claim that the locality in diffusion models arises not from the inductive bias (i.e., usage of convolutional layers) but from the data statistics. Our model. Previous work uses rectangular binary masks fitted to the sensitivity fields of trained denoisers. In this paper, we demonstrated that the sensitivity fields of the trained denoisers emerge from the data covariance. We consider constant sensitivity fields, i.e., Aq is not function of x. If the sensitivity field is constant, the denoiser is linear, and we know that the optimal linear denoiser is the Wiener filter. Using this intuition we consider generalized notion of locality, and show that the locality property is equivalent to subspace projection, which can be written as an orthogonal change of basis followed by masking operator. We provide detailed derivation in section A.3. Replacing the measured sensitivity field as in [12, 19] with the projection operator to high-SNR components (sensitivity of the optimal linear denoiser) performs on par with or better than the patch-based optimal denoisers. More formally, we suggest using the following analytical model: ˆf (x, t) = (cid:88) i=1 wi(x, t)xi 0, wq (x) = softmax (cid:26) 1 2σ2 (cid:13) ˆW (cid:13) (cid:13) (x (cid:13) 2 αtxj (cid:13) 0) (cid:13) (cid:27) j[N ] , (8) where ˆW is q-th row of the Wiener matrix binarized with threshold τ = 0.02 (we are using τ = 0.02 relative to the max value in the row unless stated otherwise). We provide detailed derivation of this formula and the ablation of τ in sections A.2 and B.1. Key differences of our model compared to [12] and [19] are: 2To aid visualization, we apply the square root to the sensitivity field and plot it with turbo color map. In the rest of the paper, the color map is applied to the raw signal. 8 Figure 5: Qualitative comparison. In this figure, we compare our analytical model (3rd row) with multiple baselines: Wiener filter (4th row), Kamb and Ganguli [12] analytical model (5th row), Niebola et al. [19] (6th row). All images are generated with the same initial noise sample with 10 steps of DDIM [27]. In the top row, we provide the results of generation with two trained neural networks, NN1 and NN2 both are instances of the same DDPM UNet [8], but trained with different seeds. The distance in Table 1 is measured with respect to NN1. We also provide the nearest image from the dataset for our final generation w.r.t. L2 distance in the last row. 1. Enhanced interpretability. Instead of fitting patch sizes and/or shapes to trained models, we obtain them analytically from dataset statistics. 2. No equivariance. While prior work claims equivariance as an important property of diffusion models [12, 18], we instead find that introducing the translation group integral to Equation (8) does not improve performance but increases inference time. 3. Locality specific to each pixel in the image. Unlike prior work, we do not enforce the shape of the patches to be shared across all pixels of the image, instead relying on the datasets statistics. This is particularly important for datasets with nonlocal covariances, such as datasets of faces. Our model is nonlinear and does not assume that the dataset is Gaussian. Rather, it approximates only the locality fields with the second-order statistics of the dataset. We benchmark our analytical model by measuring the r2-coefficient of determination and mean-squared error (MSE) between the predictions of the analytical model and trained DDPM [8] given the same starting noise. For comparison, we chose five datasets with diverse sets of statistics: CIFAR10 [16], datset of diverse 32 32 natural images; CelebA-HQ [13] and AFHQv2 [3], datasets of centered faces and animals in 64 64; and MNIST [6] and FashionMNIST [32], datasets of binary centered images in 28 28 resolution. We compare against the vanilla optimal denoiser in eq. (3), the Wiener filter [31], and two recent patch-based optimal denoising algorithms: Kamb and Ganguli [12] and Niedoba et al. [19]. Additionally, to capture the variance in signal-to-noise mapping of diffusion models, we compare with another trained diffusion model with the same architecture and dataset, but with different initialization. Table 1 and Figure 5 show that our analytical model outperforms all of the baselines, with the Wiener filter being almost always in second place. Kamb and Gangulis model qualitatively performs worse on CelebA-HQ due to patch-based locality erasing eyes and blurring out facial features, while other models using dataset-dependent locality retain these features. This experiment confirms our hypothesis that the modeling of correct locality in the analytical models is key to explaining trained diffusion models and that those localities come from the dataset statistics. We provide additional quantitative results for AFHQv2 and Fashion-MNIST in section B.6. 9 Table 1: We provide qualitative comparison that measures how well each analytical model explains the trained image diffusion models. All metrics are averaged over 128 samples. Best results are highlighted in green and second best in maroon. Method Optimal CIFAR10 CelebA-HQ MNIST r2 MSE r2 MSE r2 MSE -0.5490.774 0.1910.044 0.4000.298 0.1010.023 0.1870.204 0.2310. Wiener (linear) Kamb [12] Niedoba [19] Ours 0.4080.092 0.3030.126 0.5230.137 0.5890.078 0.0320.004 0.8180.039 0.0310.004 0.4690.066 0.1610.014 0.0650.017 0.7950.081 0.0330.006 0.2830.110 0.2270.045 0.0490.004 0.7330.092 0.0430.005 0.3010.077 0.2140.022 0.0280.008 0.9020.032 0.0160.006 0.4910.051 0.1530.015 Another DDPM 0.8520.113 0.0230.002 0.9810.007 0.0040.001 0.9690.082 0.0070."
        },
        {
            "title": "5 Conclusion, Limitations, and Future Work",
            "content": "In this work, we demonstrated that locality in diffusion models emerges from dataset statistics rather than architectural inductive biases. Through theoretical analysis and empirical validation, we showed that both U-Nets and Transformers learn sensitivity fields that closely align with projections onto high-SNR principal components of the training data. This intuition links the behavior of the diffusion models to linear denoisers, or equivalently, the Wiener filter. Using our theoretical insights, we show that by editing the datasets statistics, we are able to manipulate the sensitivity fields of trained diffusion models and can make them take arbitrary shapes, including highly nonlocal ones. Finally, our analytically model, based on dataset statistics, outperforms previous approaches in approximating trained diffusion models across multiple datasets. This work addresses critical gap in understanding how diffusion models generalize rather than memorize, highlighting the pass-through behavior where high-SNR components are preserved. Limitations of our approach include focus on simpler architectures and reliance on second-order statistics, while deep diffusion networks can capture higher-order statistics of the data. In particular, we are making strong assumption that the locality fields are constant with respect to the input images. Studying non-linear regimes of the neural diffusers can deepen our understandings of the mechanisms of image generation. Future work on complex architectures, higher-order statistics, and conditional generation has substantial potential to further explain the theory-practice gap in diffusion models."
        },
        {
            "title": "Acknowledgments",
            "content": "The authors thank Christopher Scarvelis, Ishaan Chandratreya and Vitor Guizilini for their thoughtful insights and feedback. Vincent Sitzmann was supported by the National Science Foundation under Grant No. 2211259, by the Singapore DSTA under DST00OECI20300823 (New Representations for Vision, 3D Self-Supervised Learning for Label-Efficient Vision), by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) under 140D0423C0075, by the Amazon Science Hub, and by the MIT-Google Program for Computing Innovation. The MIT Geometric Data Processing Group acknowledges the generous support of Army Research Office grant W911NF2110293, of National Science Foundation grants IIS2335492 and OAC2403239, from the CSAIL Future of Data and FinTechAI programs, from the MITIBM Watson AI Laboratory, from the Wistron Corporation, from the MIT Generative AI Impact Consortium, from the Toyota CSAIL Joint Research Center, and from Schmidt Sciences."
        },
        {
            "title": "References",
            "content": "[1] Sumukh Aithal, Pratyush Maini, Zachary Lipton, and Zico Kolter. Understanding hallucinations in diffusion models through mode interpolation. Advances in Neural Information Processing Systems, 37:134614134644, 2024. [2] Robert Grover Brown Brown and Patrick YC Hwang. Introduction to random signals and applied Kalman filtering: with MATLAB exercises fourth ed. Wiley & Sons 2012. [3] Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. Stargan v2: Diverse image synthesis for multiple domains. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 81888197, 2020. [4] Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. Stargan v2: Diverse image synthesis for multiple domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2020. [5] Valentin De Bortoli. Convergence of denoising diffusion models under the manifold hypothesis. arXiv preprint arXiv:2208.05314, 2022. [6] Li Deng. The mnist database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6):141142, 2012. [7] Xiangming Gu, Chao Du, Tianyu Pang, Chongxuan Li, Min Lin, and Ye Wang. On memorization in diffusion models. arXiv preprint arXiv:2310.02664, 2023. [8] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:68406851, 2020. [9] Hugging Face. Diffusers library documentation. diffusers/en/index, 2024. Accessed: 2025-05-23. https://huggingface.co/docs/ [10] Aapo Hyvärinen, Jarmo Hurri, and Patrick Hoyer. Natural image statistics: probabilistic approach to early computational vision., volume 39. Springer Science & Business Media, 2009. [11] Zahra Kadkhodaie, Florentin Guth, Eero Simoncelli, and Stéphane Mallat. Generalization in diffusion models arises from geometry-adaptive harmonic representations. arXiv preprint arXiv:2310.02557, 2023. [12] Mason Kamb and Surya Ganguli. An analytic theory of creativity in convolutional diffusion models. arXiv preprint arXiv:2412.20292, 2024. [13] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. [14] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in neural information processing systems, 35: 2656526577, 2022. [15] Steven Kay. Fundamentals of statistical signal processing: estimation theory. Prentice-Hall, Inc., 1993. [16] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. [17] Xiang Li, Yixiang Dai, and Qing Qu. Understanding generalizability of diffusion models requires rethinking the hidden gaussian structure. Advances in neural information processing systems, 37:5749957538, 2024. [18] Matthew Niedoba, Dylan Green, Saeid Naderiparizi, Vasileios Lioutas, Jonathan Wilder Lavington, Xiaoxuan Liang, Yunpeng Liu, Ke Zhang, Setareh Dabiri, Adam Scibior, et al. Nearest neighbour score estimators for diffusion generative models. arXiv preprint arXiv:2402.08018, 2024. 11 [19] Matthew Niedoba, Berend Zwartsenberg, Kevin Murphy, and Frank Wood. Towards mechanistic explanation of diffusion model generalization. arXiv preprint arXiv:2411.19339, 2024. [20] Alan Oppenheim and George Verghese. Signals, systems & inference. Pearson London, 2017. [21] William Peebles and Saining Xie. Scalable diffusion models with transformers. 2023 ieee. In CVF International Conference on Computer Vision (ICCV), volume 4172, 2022. [22] Frank Permenter and Chenyang Yuan. Interpreting and improving diffusion models from an optimization perspective. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 4046140483. PMLR, 2127 Jul 2024. URL https: //proceedings.mlr.press/v235/permenter24a.html. [23] Martin Raphan and Eero Simoncelli. Least squares estimation without priors or supervision. Neural computation, 23(2):374420, 2011. image segmentation. [24] O. Ronneberger, P.Fischer, and T. Brox. U-net: Convolutional networks for biomedIn Medical Image Computing and Computer-Assisted Inical tervention (MICCAI), volume 9351 of LNCS, pages 234241. Springer, 2015. URL http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a. (available on arXiv:1505.04597 [cs.CV]). [25] Christopher Scarvelis, Haitz Sáez de Ocáriz Borde, and Justin Solomon. Closed-form diffusion models. arXiv preprint arXiv:2310.12395, 2023. [26] Kulin Shah, Alkis Kalavasis, Adam Klivans, and Giannis Daras. Does generation require memorization? creative diffusion models using ambient diffusion. arXiv preprint arXiv:2502.21278, 2025. [27] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020. [28] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021. [29] Binxu Wang and John Vastola. The hidden linear structure in score-based models and its application. arXiv preprint arXiv:2311.10892, 2023. [30] Binxu Wang and John Vastola. The unreasonable effectiveness of gaussian score approximation for diffusion models and its applications. arXiv preprint arXiv:2412.09726, 2024. [31] Norbert Wiener. Extrapolation, interpolation, and smoothing of stationary time series. The MIT press, 1964. [32] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017. [33] Mingyang Yi, Jiacheng Sun, and Zhenguo Li. On the generalization of diffusion model. arXiv preprint arXiv:2305.14712, 2023. [34] TaeHo Yoon, Joo Young Choi, Sehyun Kwon, and Ernest Ryu. Diffusion probabilistic models generalize when they fail to memorize. In ICML 2023 workshop on structured probabilistic inference & generative modeling, 2023. [35] Bohao Zou. Denoising diffusion probabilistic model (ddpm) implementation. https: //github.com/zoubohao/DenoisingDiffusionProbabilityModel-ddpm, 2022. Accessed: 2025-05-23. 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 14 15 17 19 20 20 20 21 21 22 23 24 24 25 25 25 25 26 26"
        },
        {
            "title": "Table of Contents",
            "content": "A Derivations and proofs A.1 Optimal denoiser: derivation, equivalence of ϵ and x0 parametrization . . . . A.2 Patch-based optimal denoiser: formal derivation . . . A.3 Ours: why do we binarize the sensitivity field . . . . A.4 Pass-through denoisers: detailed analysis of SNR . . . A.5 Manipulating the sensitivity field: variance of the perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Additional Experiments and Ablation . . . . . . . . . . . . . . . . B.1 Ablation of our model . . B.2 Self-attention layers in denoising U-Nets . . . B.3 How to reproduce the reported sensitivity fields . . . B.4 Sensitivity field of the optimal denoiser . B.5 Generation dynamics . . . . B.6 Quantitative results for AFHQv2 and Fashion-MNIST . . B.7 Quantitative measure of novelty of samples . . . B.8 Additional generation results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Implementation details . . . . . . . . C.1 Sampling. . . . C.2 Training DDPM Model . C.3 Our analytical model . . C.4 Baseline implementation details . C.5 Algorithmic Complexity . . . C.6 Computational resources and runtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "A Derivations and proofs",
            "content": "In this section, we provide detailed derivations and proofs for the background and the claims made in the paper. A.1 Optimal denoiser: derivation, equivalence of ϵ and x0 parametrization We begin by defining the optimal denoiser for the x0 parameterization we use in the paper. Definition A.1. The optimal denoiser ˆf (x, t) for data distribution at particular noise level is the minimizer of the loss function min x0X ϵN (0,I) (cid:13) (cid:13)f ( αtx0 + 1 αtϵ, t) x0 (cid:13) 2 (cid:13) 2 (9) Recall that σ2 = 1 αt. Proposition A.2. When = (cid:8)xi ˆf (x, t) has the following analytical expression: 0 (cid:9) i[N ] is finite empirical distribution, the optimal denoiser ˆf (x, t) = (cid:88) xi 0 softmax (cid:26) (cid:13) (cid:13) (cid:13)x αtxj (cid:13) 2 (cid:13) (cid:13) (cid:27) . /2σ2 Proof. We first write down the objective (9) in terms of the random variable = (cid:104)(cid:13) (cid:13)f ( αtx0 + 1 αtϵ, t) x0 (cid:105) (cid:13) 2 (cid:13) x0X ϵN (0,I) (10) αtx0 + 1 αtϵ: (x, t) x02 2 = = x0X xN ( (cid:90) x0X αtx0,σtI) (cid:20)(cid:16) σt (cid:17)n (cid:16) exp 2π αtx0 x2 /2σ2 (cid:17) (x, t) x02 2 (cid:21) dx We then minimize the integral coordinate-wise for each to get the optimal (x, t): 0 = (cid:104) (cid:16) exp x0X (cid:80) xi (cid:80) αtx0 x2 /2σ2 0 exp( (cid:13) (cid:13)x (cid:13) (cid:13) exp( (cid:13)x (cid:13) 2 αtxi (cid:13) 0 (cid:13) 2 αtxj (cid:13) (cid:13) /2σ2 ) . /2σ2 ) ˆf (x, t) = (cid:17) (cid:105) ( ˆf (x, t) x0) Using the definition of softmaxi {aj}j[N ] = exp(ai) (cid:80)N j=1 exp(aj ) , we get (10). Definition A.3. The optimal denoiser ˆϵ(z, t) for data distribution at particular noise level is the minimizer of the loss function min x0X ϵN (0,I) (cid:13) (cid:13)f ( αtx0 + 1 αtϵ, t) ϵ(cid:13) 2 (cid:13) 2 (11) Proposition A.4. When = (cid:8)xi the ϵ-parameterization ˆϵ(x, t) can be written in terms of that of the x-parameterization ˆf (x, t): i[N ] is finite empirical distribution, the optimal denoiser for (cid:9) 0 ˆϵ(x, t) = (x αt ˆf (x, t))/σt (12) 14 Proof. We follow the same proof as Theorem A.2, with the main difference being the following step: (cid:104)(cid:13) (cid:13)f ( αtx0 + 1 αtϵ, t) ϵ(cid:13) 2 (cid:13) 2 (cid:105) x0X ϵN (0,I) = x0X xN ( αtx0,σtI) (x, t) (x αtx0)/σt2 2 . Remark A.5. Another way to prove Theorem A.2 and Theorem A.4 is to show that the optimal solutions are of the form E[x0 x] and E[ϵ x], where ( αtx0, σtI). Then it becomes clear that the two expressions are linearly related to each other. A.2 Patch-based optimal denoiser: formal derivation We now turn to the patch-based denoiser, incorporating both locality and equivariance constraints into the optimal denoising problem as suggested in [12], repeating the derivations in the notations of this manuscript. Let = {xi i=1 be finite empirical distribution of images, and let 0}N : Rdd Rdd denote the operator that masks out patch centered at pixel q, setting the rest of the pixels to 0. As suggested in [12], we impose two constraints on each patch-wise function q: 1. Locality: q(x, t) = q(cid:0)M t x, t(cid:1). 2. Equivariance: For every 2D translation (2), (cid:0)g x, t(cid:1) = (x, t), = q(cid:0)g x, t(cid:1) = g1q(x, t), i.e. denoising commutes with the action of (2) and relocates patches accordingly. Definition A.6. The patch-based optimal denoiser ˆf (x, t) for data distribution at particular noise level is the minimizer of the loss function (cid:13)f (cid:0) (cid:13) 1 αt ϵ, t(cid:1) x0 αt x0 + min x0X, ϵN (0,I), t[0,1] (cid:13) 2 (cid:13) 2 s.t. q(x, t) = q(cid:0)M x, t(cid:1), (cid:0)g x, t(cid:1) = (x, t), = 1, . . . , Q, (locality) (2). (equivariance) (13) Proposition A.7 (Patch-based optimal denoiser). Under the empirical distribution = {xi the minimizer { ˆf q} of eq. (13) is given, for each patch location q, by 0}N i=1, ˆf q(x, t) = (cid:88) (cid:88) gT (2) (cid:0)g xi 0 (cid:1)q softmax (cid:16) 1 2σ2 (cid:13) (cid:13) (cid:0)x αt xi 0 2(cid:17) (cid:1)(cid:13) (cid:13) , (14) and the full-image denoiser is obtained by reconstructing the final image from the pixels above. Proof of Patch-based optimal denoiser. We prove this result in three steps: (1) decomposition into per-pixel optimization, (2) equivalence of equivariance constraint and data augmentation, and (3) derivation of the local form. Step 1: Decomposition into per-pixel optimization. Let Pq : Rdd denote the operator that extracts pixel from an image, and define = (cid:80)Q places scalar value at pixel and zeros elsewhere. Since pixels are disjoint, PiP } orthogonal projections with (cid:80)Q = 0 for = j, making {PqP q where q=1 PqP q=1 PqP = I. 15 By orthogonality of pixel projections: (x) x02 2 = (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:88) q="
        },
        {
            "title": "PqP T",
            "content": "2 (cid:13) (cid:13) (cid:13) (f (x) x0) (cid:13) (cid:13) 2 = = (cid:88) q=1 (cid:88) q=1 Pqf (x) Pqx02 2 q(x) xq 02 Therefore, the original minimization problem decomposes as: Ex0X,ϵN (0,I)f ( αtx0 + 1 αtϵ) x02 2 min = (cid:88) q=1 min Ex0X,ϵN (0,I) (cid:2)f q( αtx0 + 1 αtϵ) xq 0 (cid:3)2 Each pixel can be optimized independently. Step 2: Equivariance constraint equals data augmentation. For the q-th pixel problem with equivariance constraint: minf s.t. Ex0X,ϵN (0,I) q(g x) = (g (x))q (2) αtx0 + (cid:2)f q( 1 αtϵ) xq 0 (cid:3)2 (15) The equivariance constraint implies that for any translation g: q(g x) = g1q(x) Now consider the data-augmented problem: min Ex0X,ϵN (0,I)EgT (2) (cid:2)f q(g ( αtx0 + 1 αtϵ)) (g x0)q(cid:3)2 (16) We want to prove that (15) is equivalent to (16). To do so, we first show that the optimal solution of (15) does not change with data-augmentation, then show that the optimal solution of (16) satisfies the equivariance constraint. Constrained optima invariant under data-augmentation Let = translation commutes with noise addition and (g x0)q = xg1q becomes: 0 αtx0 + 1 αtϵ. Since , (15) under data-augmentation Ex0X,ϵN (0,I)EgT (2) min s.t. q(g x) = (g (x))q (2) q(g x) xg1q 0 (cid:104) (cid:105)2 If satisfies the equivariance constraint, then q(g x) = g1q(x), so: Ex0X,ϵN (0,I),gT (2) (cid:16) q(g x) xg1q 0 (cid:17)2 arg min = arg min = arg min = arg min (cid:16) Ex0,ϵ,g g1q(x) xg1q 0 (cid:17)2 (cid:88) Ex0,ϵ (f r(x) xr 0)2 r=1 Ex0,ϵ (f q(x) xq 0)2 Data-augmented optima is equivariant We can solve the data-augmented problem (16) and check that its optimal solution ˆf is equivariant under the transformation x, for any (2): ˆf q(h x) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i=1 gT (2) (cid:88) (cid:88) (g xi 0)q softmaxi,g (cid:26) (cid:26) 1 2σ2 1 2σ2 h αt(g xi 0)2 (cid:27) αt(h1 xi 0)2 (h xi 0)q softmaxi,g (cid:26) 1 2σ2 αt(g xi 0) = = i=1 gT (2) (cid:88) (cid:88) i=1 gT (2) = (h (x))q, where = h1 g. (cid:27) (cid:27) Step 3: Local form derivation. From the data augmentation equivalence, the optimal denoiser for pixel minimizes: Ex0X,ϵN (0,I)EgT (2) (cid:2)f q( αt(g x0) + 1 αtϵ) (g x0)q(cid:3) Let = αtg x0 + 1 αtϵ. Writing the objective as an integral over x, we get: (cid:90) Ex0X,gT (2) (cid:16) σt 2π (cid:17)d (cid:16) exp αtg x0 x2 /2σ2 (cid:17) (f q(x) (g x0)q)2 dx With the locality constraint q(x) = q(M masked out by (cid:90) (as does not depend on them), to get: (cid:16) (cid:17)p2 (cid:16) Ex0X,gT (2) σt 2π exp t ( αtg x0 x)2 /2σ2 x), we can integrate out the coordinates of that are (cid:17) (f q(M x) (g x0)q)2 d(M x) Solving for the optimal ˆf q, we get: (cid:18) 0 = exp x0X gT (2) ϵN (0,I) (g x0)2 αtM 2σ2 (cid:19) (f q(M t x) (g x0)q) Rearranging: ˆf q(M x) = (cid:80)N i= (cid:80) gT (2)(g xi (cid:80) hT (2) exp 0)q exp (cid:0)M t (cid:16) αtM (g xi αtM (h xj 0)2/2σ2 0)2/2σ2 (cid:17) (cid:1) (cid:80)N j=1 Using the softmax notation: ˆf q(x, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i=1 gT (2) (cid:26) 1 2σ2 t This completes the proof. A.3 Ours: why do we binarize the sensitivity field αtM (g xi 0)2 (cid:27) In this section, we provide justification for our algorithm provided in the main paper. In particular, we formally justify why it makes sense to binarize the sensitivity fields into mask of zeros and ones. At first, we generalize the patch-based optimal denoiser by relaxing the locality constraint. Instead of restricting to patch extraction operators : Rdd Rdd that can capture more complex spatial relationships. , we consider linear operators Aq 17 Definition A.8 (Generalized masked optimal denoiser). The generalized masked optimal denoiser ˆf (x, t) for data distribution at noise level is the minimizer of: min x0X, ϵN (0,I) s.t. q(x, t) = q(cid:0)Aq (cid:13)f (cid:0) (cid:13) x, t(cid:1), αt x0 + 1 αt ϵ, t(cid:1) x0 (cid:13) 2 (cid:13) 2 (17) = 1, . . . , Q, (generalized locality) (cid:0)g x, t(cid:1) = (x, t), (2) (equivariance) where Aq : Rdd Rdd is linear operator. is invertible, is effectively unconstrained (i.e. there is no locality). On the = 0, does not depend on x. The following result interpolates between these Note that when Aq other hand, when Aq two extreme cases, showing that the optimal denoiser depends only on the row-space Aq . Proposition A.9 (Generalized masked optimal denoiser). Following the decomposition and data augmentation equivalence from the previous section, the optimal denoiser for pixel under the generalized locality constraint is: ˆf q(x, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i=1 gT (2) (cid:26) 1 2σ2 (cid:13) (cid:13)P (cid:0)x αt(g xi 2(cid:27) 0)(cid:1)(cid:13) (cid:13) (18) where = (Aq )T (cid:0)Aq (Aq )T (cid:1) Aq is the orthogonal projection matrix onto the row space of Aq . Proof. The objective (17) can be written as (cid:90) (cid:17)d2 (cid:16) (cid:16) σt 2π exp αtg x0 x2 /2σ2 x0,g We use SVD to write Aq = ΛV , where Λ is diagonal matrix with 0 or 1 diagonal entries depending if the corresponding diagonal entry of Λ is nonzero. Then we impose the constraint q(x) = q(Aq x) and perform change of variables = x. (cid:17) = ΛV , and notice that (f q(x) (g x0)q)2 dx. (cid:17)d2 (cid:16) (cid:16) (cid:90) σt 2π exp αtg x0 x2 /2σ2 (f q(Aq x) (g x0)q)2 dx (cid:17) (cid:16) σt 2π (cid:17)d2 (cid:16) exp αtV (g x0) y2 /2σ2 (cid:17) (f q(Λy) (g x0)q)2 dy, x0,g (cid:90) = x0,g (cid:90) where we have absorbed into as it is an invertible matrix. Next, we integrate out the coordinates of corresponding to the zero-values in Λ, and absorb non-zero entries of Λ into q, to get (cid:13) (cid:17) (cid:0)f q(Λy) (g x0)q(cid:1)2 (cid:13) (cid:13) (cid:13) (cid:13)Λ ( (cid:13) We then solve for the optimal ˆf q(y) and change variables to get ˆf q(x): αtV (g x0) y)2 /2σ2 E x0,g (cid:17)d2 exp dy. 2π σt (cid:16) (cid:16) ˆf q(y, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i=1 gT (2) ˆf q(x, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i= gT (2) (cid:88) (cid:88) = (g xi 0)q softmaxi,g i=1 gT (2) (cid:26) (cid:26) (cid:26) 1 2σ2 1 2σ2 1 2σ2 (cid:13) (cid:13)Λ (cid:0)y αtV (g xi 2(cid:27) 0)(cid:1)(cid:13) (cid:13) (cid:13) (cid:13)ΛV (cid:0)x αt(g xi 2(cid:27) 0)(cid:1)(cid:13) (cid:13) (cid:13) (cid:13)P (cid:0)x αt(g xi 2(cid:27) 0)(cid:1)(cid:13) (cid:13) . Corollary A.9.1 (Diagonal operators and mask binarization). When Aq constrained to be diagonal matrix with entries aq , the optimal denoiser simplifies to: = diag(aq ) is further ˆf q(x, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i=1 gT (2) (cid:26) 1 2σ2 Bq (x αt(g xi 0))2 (cid:27) (19) 18 where Bq is the binary mask with Bq element-wise multiplication. = 1 if aq = 0 and Bq = 0 otherwise, and denotes = diag(aq Proof. We begin with the generalized optimal denoiser from equation (18) and substitute the diagonal = (Aq 1, aq operator Aq = Bq. We get binary = 0. The actual values of non-zero aq mask because oefficients aq do not affect the optimal denoiseronly whether aq = 0 matters. Then we can apply Theorem A.9 to get 2, . . . , aq cancel out completely when aq Q). Then = 0 or aq )T (cid:0)Aq )T (cid:1) (Aq Aq ˆf q(x, t) = (cid:88) (cid:88) (g xi 0)q softmaxi,g i= gT (2) (cid:26) 1 2σ2 Bq (x αt(g xi 0))2 (cid:27) This completes the proof, showing that the optimal denoiser depends only on the binary support of the diagonal operator, not on the specific non-zero values. Connection to patch-based denoiser: When aq = 0, the corresponding pixel is effectively removed from the optimization, as it contributes zero to the distance metric. This is precisely the locality constraint from the patch-based denoiser: pixels outside the patch (where aq = 0) do not influence the denoising of pixel q. Remark A.10 (Justification for binary masks). In summary, we showed in Theorem A.9 that the only interesting generalized locality matrices are binary masks. In particular, when the masking operator Aq has diagonal structure, the specific values of the non-zero entries cancel out in the softmax computation. This means that: 1. The optimal denoiser depends only on the pixels that are included in the mask (the support), not their relative weights. 2. Binary masks {0, 1} are as expressive as any diagonal weighting scheme for this optimization problem. 3. This theoretical result justifies our practical choice of binary masks in the main paper, as more complex weighting provides no additional benefit for the optimal denoiser. A. Pass-through denoisers: detailed analysis of SNR In this section, we provide detailed analysis of the signal-to-noise ratio in the principal components of the data, extending section Pass-through denoisers in the main paper. Lets consider the data 0 ] RdN . Doing singular value decomposition, and assuming matrix = [x1 we get = diag(λ1, λ2, . . . λd)V , where λi are sorted in the descending order of their absolute values. Covariance of the dataset, assuming that the mean of the dataset is zero: 0 . . . xN 0x2 Σ = 1 XX = 1 diag(λ2 1, λ2 2, . . . λ2 d)U , where are the principal components of the data and λ2 /N is the variance of the data along those components. We can now compute the signal-to-noise ratio along each of the principal components of the data: SNRi = = = Ex0X (cid:104)(cid:0)U (cid:104)(cid:0)U (cid:1)2(cid:105) αtx0 1 αtϵ(cid:1)2(cid:105) EϵN (0,I) αt ΣUi (1 αt) αt λ2 /N Ui 1 αt 19 When λ2 /N (1 αt)/αt, the intrinsic data variance is much larger than the relative noise level, and the signal was not destroyed by noise. Note, the analysis above does not have to be performed on the entire dataset, but rather on the most relevant set of neighbors to the image that is currently being denoised. In that case, the high SNR projections will be more precise and specific to each particular image as long as SVD is well defined. Due to computation constraints and to keep the analysis simple from now on we will assume that the covariance matrix is computed on the entire dataset. A.5 Manipulating the sensitivity field: variance of the perturbation In this section, we provide the derivation for the variance of the added perturbation λW in the section Manipulating the sensitivity field of the main paper. Denote by = γcs the signal vector; then the empirical covariance of the modified data is Σmod = E[ˆx0 ˆxT 0 ] 0 ] + γ E[x0sT cT ] + γ E[csT xT 0 ] + γ2 E[cssT cT ] = E[(x0 + γcs)(x0 + γcs)T ] = E[x0xT = Σorig + γ2 E[ccT ]ssT = Σorig + γ2 1 3 I3 ssT , where we used E[x0] = 0, E[c] = 0, and for Uniform([1, 1]3), we have E[ccT ] = 1 noisy observations ˆxt = 1 αtϵ, the covariance becomes: αt ˆx0 + 3 I. For the Σt mod = E[ˆxt ˆxT ] 0 ] + (1 αt)I = αt E[ˆx0 ˆxT = αtΣmod + (1 αt)I = αtΣorig + αtγ2 1 3 I3 ssT + (1 αt)I. Assuming the RGB perturbation affects each color channel independently and focusing on single channel, the second term contributes rank-1 perturbation with eigenvalue λ2 = αtγ2s2/3. By the Wiener filter analysis of section 3, the learned sensitivity along the new \"W\" principal component is sw(t) = λ2 λ2 + (1 αt) = = αtγ2s2/3 αtγ2s2/3 + (1 αt) αtγ2s2 αtγ2s2 + 3(1 αt) , where (1 αt) is the noise variance at timestep t."
        },
        {
            "title": "B Additional Experiments and Ablation",
            "content": "B.1 Ablation of our model The analytical model proposed in this paper has single hyperparameter: τ the threshold of the sensitivity field binarization. In section A.3 we formally justify binarization of the sensitivity fields for our analytical model. Here, we demonstrate the effect of choosing different binarization thresholds. In particular, from fig. 6 we can see that higher threshold values (i.e., smaller patch sizes) correspond to sharper, but patchier. On the other side, small threshold values (i.e., bigger patch sizes) cause the generated image to be over-smoothed. We report the r2 and MSE metrics of correlation with the trained diffusion model for different threshold values in table 2. 20 Table 2: Comparison of r2 and MSE metrics across datasets for different binarization threshold values. Best values are highlighted in bold. Threshold CIFAR10 r2 MSE CelebA-HQ r2 MSE MNIST r2 MSE Fashion MNIST r2 MSE 0.005 0.010 0.020 0.050 0.070 0.100 0.150 0.396 0.520 0.672 0.773 0.771 0.737 0.641 0.059 0.046 0.031 0.021 0.022 0.026 0. 0.786 0.865 0.897 0.894 0.879 0.852 0.799 0.038 0.023 0.017 0.017 0.020 0.024 0.033 0.492 0.441 0.418 0.214 0.214 0.214 0.214 0.151 0.165 0.176 0.255 0.255 0.255 0.255 0.563 0.517 0.406 0.072 -0.192 -0.407 -0.209 0.115 0.122 0.144 0.211 0.264 0.311 0. Figure 6: Ablation of the binarization threshold τ . B.2 Self-attention layers in denoising U-Nets Across our experiments, we are using trained DDPM model with removed self-attention (SA) layers following [12]. In this section, we demonstrate that removing the self-attention layer brings the FID score to 6.04 from 4.12 with SA. Qualitatively, the generated images look similar with and without SA, and thus our analysis in the main paper can be extended to U-Nets with SA layers. In particular, we train U-Net without self-attention and compare it with baseline U-Net trained with self-attention. Using the gradient-estimation sampler from [22], we report the FID scores for both models, and in Figure 7, we compare sample results. B.3 How to reproduce the reported sensitivity fields In this section, we provide the technical details and intuition needed to measure the sensitivity fields of diffusion models. All the results are reported for CIFAR10 dataset. Recall that the optimization problem is invariant under the change of variables from the initial image x0 to the noise sample ϵ; see section A.1 for details. Consequently, one can measure the sensitivity field in either the noise parameterization, ϵ(x, t)/x, or the image parameterization, x0(x, t)/x. Although the choice is merely theoretical convenience, in practice the models behavior is highly sensitive to it. The top row of fig. 8 shows the sensitivity fields of DDPM model trained to predict x0 and then reparameterized with linear transform to predict ϵ; here we plot ϵ(x, t)/x. The middle row depicts the same model, but the sensitivity is evaluated in the image parameterization, i.e. x0(x, t)/x. As we can see, simple linear reparameterization applied to the model output drastically alters the result. These observations are intuitive. From the optimal-denoiser analysis, we know that, in the high-noise regime, the model predicts an image close to the dataset mean. Thus, predicting the 21 Figure 7: Samples from trained DDPM U-Nets without (left) and with (right) self-attention layers. The initial random noise is the same for both sets of images. added noise sample ϵ for each pixel is almost equivalent to outputting minus that mean, so the noise-parameterized sensitivity field appears highly local. Because this visualization is not very informative, we chose to plot x0(x, t)/x throughout the paper, as it captures the actual structure of the sensitivity field. αt x0 + Figure 9 illustrates the effect of training U-Net and DiT models in the two parameterizations. Recall that xt = 1 αt ϵ. For large where αt 0, image x0 is ill-defined given ϵ and xt; conversely, for small where αt 1, ϵ is ill-defined given x0 and xt. Hence, while theory predicts identical results (up to re-parameterization), numerical errors lead to different behavior at low and high noise levels. The top two rows of fig. 9 show x0(x, t)/x for models trained in the noise parameterization, revealing pronounced shrinkage of the sensitivity fields in the high-noise regime. We hypothesize that this is numerical artifact and therefore plot, in the bottom two rows, the fields obtained from models trained directly in the image parameterization. For clarity, all DDPM examples in the main paper are trained in that setting. Finally, the middle and bottom rows of fig. 8 compare two normalization strategies. In the middle row, each sensitivity field is normalized independently to [1, 1]; in the bottom row, the images are normalized jointly, preserving relative scale. Joint normalization makes the field appear less local while preserving its overall mass. Throughout the paper, we adopt per-image normalization, as it more faithfully reflects the binarization assumed in our analytical model. Summary of visualization choices Train the model to predict the image x0 (not the noise ϵ). Visualize the sensitivity of the image prediction, i.e. x0(x, t)/x. Apply per-image normalization. B.4 Sensitivity field of the optimal denoiser In this section, we provide visualization of the sensitivity fields of the optimal denoiser on the CIFAR10 dataset. As shown in fig. 10, the sensitivity of the optimal denoiser closely resembles that of the trained models only in the high-noise regime. At intermediate noise levels, the sensitivity field begins to diverge, and in the low-noise regime, it ultimately explodes. 22 Figure 8: Top: sensitivity field of the noise prediction ϵ(x, t)/x. Middle: sensitivity field of the image prediction x0(x, t)/x with per-image normalization. Bottom: the same field with joint normalization across images. Figure 9: Sensitivity fields x0(x, t)/x for U-Net (left) and DiT (right). Top two rows: models trained to predict noise ϵ. Bottom two rows: models trained to predict the image x0. The shrinkage observed at high noise in the noise-parameterized models is likely due to numerical instability. B.5 Generation dynamics Here we provide additional results demonstrating the dynamics of image generation. In fig. 12 we numerically compare x0 predictions through the generation process. In fig. 11 we demonstrate how the dynamics of image generation of our analytical model compares with that one of trained DDPM model. Note that the trained model produces noisy single-step predictions for high noise levels (t 850). We explain this behavior by the fact that the model was trained to predict ϵ and later re-parametrized to output x0 for the visualization. Since αt 0 for high noise level, x0 becomes ill-defined and thus noises the outputs. 23 Figure 10: Sensitivity field of the optimal denoiser. Figure 11: Intermediate generation results of trained DDPM model (rows 1 and 3) and ours (rows 2 and 4). The figure displays single-step estimations of x0 from each xt along sampling trajectory of 10 steps. B.6 Quantitative results for AFHQv2 and Fashion-MNIST In addition to table 1 in the main paper we report quantitative results for AFHQv2 and Fashion-MNIST in table 3. All the values are calculated across 128 samples. B.7 Quantitative measure of novelty of samples In this work, we focus on the ability of the trained diffusion models to generate novel samples that contrast with the behavior of the optimal denoiser. Therefore, the ability of the analytical model to generate novel samples is paramount. In figure 5 of the main paper (as well as in section B.8) we report the nearest neighbors from the training dataset for each sample generated with our analytical model. To quantify these results, we report the average L2 distances between samples generated with each of the baseline models and the closest image in the dataset in table 4. Additionally, we report the dynamics of the novelty measure in the generation process in fig. 13. Figure 12: Mean Squared Error (MSE) between the baselines predictions and trained DDPM model. The MSE is calculated on x0 prediction from each xt point along 10-step generation trajectory. The results are presented on the CIFAR10 and CelebA-HQ datasets. Mean and standard deviation values were calculated across 128 samples. 24 Table 3: Comparison of methods across AFHQv2 and Fashion-MNIST. All metrics are averaged over 128 samples. Best results are highlighted in green and second best in maroon. AFHQv Fashion-MNIST Method r2 MSE r2 MSE Optimal Denoiser -1.239 0.371 0.180 0.023 -0.137 0.344 0.254 0.077 Wiener (linear) Kamb & Ganguli [12] Niedoba et al.[19] Ours 0.601 0.072 0.429 0.081 0.382 0.092 0.759 0.026 0.025 0.003 0.041 0.006 0.045 0.006 0.019 0.004 0.449 0.068 0.112 0.114 0.311 0.088 0.523 0. 0.137 0.018 0.217 0.032 0.180 0.022 0.125 0.011 Another DDPM 0.928 0.019 0.050 0.001 0.950 0.020 0.015 0. Table 4: We numerically quantify the ability of analytical models to produce images outside of the training dataset. In this table, we provide the average L2 distance between images generated with the baselines and the corresponding closest image in the training dataset. Results are averaged over 128 samples. Method Fashion MNIST CelebA-HQ CIFAR10 AFHQv2 MNIST Optimal Denoiser 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.091 0.006 0.104 0.006 0.112 0.005 0.177 0.015 Wiener (linear) Kamb & Ganguli [12] 0.094 0.005 0.089 0.006 0.136 0.007 0.355 0.061 0.113 0.007 0.134 0.009 0.145 0.007 0.221 0.019 Niedoba et al.[19] 0.040 0.005 0.063 0.004 0.063 0.004 0.204 0.023 Ours 0.133 0.013 0.218 0.032 0.215 0.019 0.131 0.027 Another DDPM 0.079 0.014 0.087 0.010 0.095 0.013 0.103 0.023 0.067 0.015 B.8 Additional generation results We present additional generation results similar to fig. 5 of the main paper in figs. 14 to 18."
        },
        {
            "title": "C Implementation details",
            "content": "C.1 Sampling. In all of the generations in this paper, we are using diffusers [9] implementation of the DDIM [27] sampler with 10 sampling steps. We discretize the noise time scale for [1, 1000] where = 0 is no noise and = 1000 is full noise. The scheduler is linear with α0 = 104 and α1000 = 0.02. C.2 Training DDPM Model We train Denoising Diffusion Probabilistic Model (DDPM) U-Net using third-party pytorch implementation [35]. We adopt the U-Net model architecture based on the input image resolution: MNIST/FashionMNIST (img_size = 28): 3 downsampling levels with channel_mult = [1, 2, 2], base channel width 64. CIFAR10 (img_size = 32) and CelebA-HQ/AFHQ (img_size = 64): 4 downsampling levels with channel_mult = [1, 2, 3, 4], base channel width 128. The number of residual blocks per level is fixed to 2, with no self-attention modules included. Dropout is set to 0.15 throughout the network. The model is trained for 200 epochs with batch size of 32. We use the Adam optimizer with learning rate of 104 over 1000 diffusion steps. Training and evaluation use fixed random seeds for reproducibility. 25 Figure 13: L2 distance between x0 prediction and the closest image in the training dataset reported along 10-step generation trajectory for 5 datasets. C.3 Our analytical model Below, we provide detailed description of the implementation of our analytical model. key component of this implementation is the weighted streaming softmax (wssm) that accumulates the product x0 softmax (. . .) over batches of training images. Algorithm 1 Single denoising step of the proposed analytical model. Require: Noisy image xt Timestep Precomputed covariance of the data Masking threshold τ Dataset Schedule of αt (cid:17) (cid:16) αtλi Ensure: Estimated clean image ˆx0 1: ΛU = 2: Wt = diag βt+αtλi 3: Mt = Binarize(Wt, τ ) 4: wssm.init() 5: for each batch x(k) 0 (cid:20)(cid:16) from do Dk = stack xt 6: αtx(k) (cid:17)2(cid:21) 7: Dmt = DkMt (cid:16) wssm.update 8: 9: end for 10: ˆx0 = wssm.value() 11: return ˆx0 Dmt/2 [1 αt] , x(k) 0 SVD of the covariance matrix Current Wiener matrix Construct the projection matrix Initialize weighted streaming softmax Distance to xt for each image in the batch (cid:17) Each row of Mt serves as mask Add the distances and the value C.4 Baseline implementation details Wiener filter. To implement the Wiener matrix, we first center each dataset to zero mean. Then we pre-compute the covariance matrix of the dataset. Note that this is part of training and these computations were not included in the runtime report. On sampling, use the PyTorch implementation of SVD to compute the principal components and the corresponding singular values. Finally, we are using eq. (7) from the main paper to implement Wt. Note that we are using the Wiener filter as denoiser, and when generating the images, we are still using 10-step DDIM sampling, effectively applying the Wiener filter 10 times to the initial noise. Kamb & Ganguli model. We implemented the analytical model suggested by Kamb & Ganguli in our code base. Then we fit the patch sizes Mt of the analytical model to our trained DDPM U-Nets, maximizing the r2 between the scores on each step of generation. Below are the patch sizes that we obtained: CIFAR10 32 32: [32, 32, 32, 29, 25, 17, 13, 9, 7, 3] CelebA-HQ 64 64: [ 64, 64, 57, 49, 45, 25, 17, 17, 9, 3] AFHQ 64 64: [64, 64, 45, 33, 25, 17, 17, 9, 9, 3] 26 MNIST 28 28: [28, 28, 23, 23, 17, 17, 17, 13, 9, 9] Fashion MNIST 28 28 : [28, 28, 25, 23, 17, 17, 13, 13, 9, 9] Niedoba et al. model. We similarly re-implement the Niedoba et al. model in our code base. We then measure and average the sensitivity field of our instance of the DDPM model. The sensitivity field is averaged across all output pixels and 64 different noise samples. After the averaging, we binarize the sensitivity field with τ = 0.05 relative to the max value in the receptive field for each timestep t. We empirically observed that the performance is worse with equivariance, so our implementation does not contain equivariance to translations. Finally, we implemented the algorithm similar to our model, but with the measured sensitivity fields. C.5 Algorithmic Complexity In this section, we provide an analysis of the algorithmic complexity of our method and the baselines. For small-resolution images, the Wiener filter remains the most efficient at O(m2), where is the flattened image resolution. Both our model and Kamb&Gangulis require dataset pass per inference step, leading to scaling linear in n, where is the dataset size. Kamb&Ganguli assume translation equivariance, so for each pixel, its surrounding patch (size pt at denoising step t) is compared to every patch in the dataset, resulting in O(nptm2) complexity. With approximate vector search (e.g., using clusters), this reduces to O(nptm2/k). Our model forgoes translation equivariance as we did not observe any difference in quality. Additionally, we are using distinct per-pixel mask pattern. This leads to the algorithmic complexity of our algorithm being O(nptm). For larger datasets, we can match the O(nptm/k) complexity by indexing masks per timestep and pixel. We provide the summary in section C.5. Table 5: Algorithmic complexity of the baselines. Here, denotes the flattened image resolution, the dataset size, pt the patch size at denoising step t, and the number of clusters used in approximate nearest-neighbor search. Method Wiener Kamb (exact) Kamb (approx) Ours (exact) Ours (approx) Complexity O(m2) O(nptm2) (cid:16) nptm2 (cid:17) O(nptm) O(cid:0) nptm (cid:1) C.6 Computational resources and runtime All the experiments were performed on server machine with Ubuntu 20.04. The machine has 1008GB RAM, 128 CPU cores and 8 NVIDIA RTX A6000 GPUs with 49140MB VRAM. We note that all the baselines could be run with fewer computational resources. In table 6 we provide the average run times for each baseline. Table 6: We demonstrate the computational efficiency of each method by displaying the total sampling time for each of the baselines over 10 denoising steps. None of the methods are optimized for runtime, and the comparison is provided only as rough reference. Results show times averaged over 64 samples. Method CIFAR10 CelebA-HQ AFHQv2 MNIST Fashion MNIST Optimal Denoiser Wiener (linear) Kamb & Ganguli [12] Niedoba et al.[19] Ours Another DDPM 7.90 0.11 44.44 22.35 21.25 0. 18.90 3.10 349.68 76.09 70.23 0.65 10.01 3.08 181.08 322.65 314.55 0. 0.63 0.07 4.40 22.77 22.39 0.61 0.64 0.07 4.49 23.19 22.97 0. 27 Figure 14: Additional generation results for all baselines and ours on the CelebA-HQ dataset. Figure 15: Additional generation results for all baselines and ours on the AFHQ dataset. 28 Figure 16: Additional generation results for all baselines and ours on the CIFAR10 dataset. Figure 17: Additional generation results for all baselines and ours on the MNIST dataset. 29 Figure 18: Additional generation results for all baselines and ours on the Fashion MNIST dataset."
        }
    ],
    "affiliations": [
        "Massachusetts Institute of Technology",
        "Toyota Research Institute"
    ]
}