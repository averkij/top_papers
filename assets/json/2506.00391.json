{
    "paper_title": "SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL",
    "authors": [
        "Ge Qu",
        "Jinyang Li",
        "Bowen Qin",
        "Xiaolong Li",
        "Nan Huo",
        "Chenhao Ma",
        "Reynold Cheng"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Current self-correction approaches in text-to-SQL face two critical limitations: 1) Conventional self-correction methods rely on recursive self-calls of LLMs, resulting in multiplicative computational overhead, and 2) LLMs struggle to implement effective error detection and correction for declarative SQL queries, as they fail to demonstrate the underlying reasoning path. In this work, we propose SHARE, an SLM-based Hierarchical Action corREction assistant that enables LLMs to perform more precise error localization and efficient correction. SHARE orchestrates three specialized Small Language Models (SLMs) in a sequential pipeline, where it first transforms declarative SQL queries into stepwise action trajectories that reveal underlying reasoning, followed by a two-phase granular refinement. We further propose a novel hierarchical self-evolution strategy for data-efficient training. Experimental results demonstrate that SHARE effectively enhances self-correction capabilities while proving robust across various LLMs. Furthermore, our comprehensive analysis shows that SHARE maintains strong performance even in low-resource training settings, which is particularly valuable for text-to-SQL applications with data privacy constraints."
        },
        {
            "title": "Start",
            "content": "SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL Ge Qu 1, Jinyang Li 1, Bowen Qin 2, Xiaolong Li 1, Nan Huo1, Chenhao Ma 3, Reynold Cheng 1 1The University of Hong Kong, 2 BAAI 3The Chinese University of Hong Kong, Shenzhen quge@connect.hku.hk, bwqin@baai.ac.cn, ckcheng@cs.hku.hk 5 2 0 2 1 3 ] . [ 1 1 9 3 0 0 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Current self-correction approaches in text-toSQL face two critical limitations: 1) Conventional self-correction methods rely on recursive self-calls of LLMs, resulting in multiplicative computational overhead, and 2) LLMs struggle to implement effective error detection and correction for declarative SQL queries, as they fail to demonstrate the underlying reasoning path. In this work, we propose SHARE, an SLM-based Hierarchical Action corREction assistant that enables LLMs to perform more precise error localization and efficient correction. SHARE orchestrates three specialized Small Language Models (SLMs) in sequential pipeline, where it first transforms declarative SQL queries into stepwise action trajectories that reveal underlying reasoning, followed by two-phase granular refinement. We further propose novel hierarchical self-evolution strategy for data-efficient training. Experimental results demonstrate that SHARE effectively enhances self-correction capabilities while proving robust across various LLMs. Furthermore, our comprehensive analysis shows that SHARE maintains strong performance even in low-resource training settings, which is particularly valuable for text-to-SQL applications with data privacy constraints. For reproducibility, we release our code at https: //github.com/quge2023/SHARE."
        },
        {
            "title": "Introduction",
            "content": "Text-to-SQL, aimed at converting natural language (NL) queries to executable SQL queries (Qin et al., 2022), plays crucial role in enabling nontechnical users to analyze and interact with data in relational databases. In recent years, the application of Large Language Models (LLMs) has improved the performance of text-to-SQL to another level of intelligence (Rajkumar et al., 2022; Corresponding authors are Bowen Qin and Reynold Cheng. Figure 1: correction for text-to-SQL. Illustrations of self-debugging and selfTalaei et al., 2024; Pourreza et al., 2024; Zhang et al., 2025). critical component emerging from these architectural developments is the automatic error correction mechanism (Ouyang et al., 2022a; Chen et al., 2023; Pan et al., 2024b), which systematically identifies and rectifies query errors to improve response accuracy. Contemporary automatic error correction approaches can be categorized along two primary dimensions: self-debugging and self-correction. Self-debugging represents an execution-guided approach in which LLMs iteratively refine their SQL queries based on database execution feedback (Zhong et al., 2023; Li and Xie, 2024; Xie et al., 2024), as illustrated in Figure 1 (A). While demonstrating promising results, this approach faces several fundamental challenges. First, execution feedback from mainstream SQL dialects such as SQLite tends to be concise but insufficiently specific, impeding accurate error localization. This ambiguity may subsequently induce hallucinations (Dziri et al., 2021; Ji et al., 2023) in the correction process. Furthermore, the fundamental requirement for direct database execution access presents significant operational constraints, particularly in contexts where data privacy and security considerations preclude such direct interaction with the database system (Awan et al., 2023). These issues have motivated the focus of automatic correction towards self-correcting mechanisms (Liu and Tan, 2024; Askari et al., 2024), where LLMs are prompted to revise their initial outputs through autonomous contextual reanalysis, without relying on external execution feedback. This decoupling from execution environments proves particularly valuable in text-toSQL applications where database access is typically restricted by privacy constraints. However, achieving effective self-correction often requires multiple inference iterations through proprietary LLM APIs like GPT-4 or Claude-3.5-Sonnet, leading to prohibitive computational costs that scale exponentially. Furthermore, LLMs exhibit tendency towards self-enhancement bias (Huang et al., 2024), leading them to overestimate the quality of their initial outputs and struggle to effectively identify errors within their self-generated declarative SQL queries. This inherent limitation undermines the overall effectiveness of the correction process. In this work, we propose an assistant-based framework where generator LLMs create initial outputs and implement self-correction guided by assistants. Our primary contribution, SHARE (SLM-based Hierarchical Action CorREction Assistant), orchestrates three specialized Small Language Models (SLMs), each under 8B parameters, in sequential pipeline. Specifically, the Base Action Model (BAM) transforms raw SQL queries into action trajectories that capture reasoning paths; the Schema Augmentation Model (SAM) and the Logic Optimization Model (LOM) further perform orchestrated inference to rectify schema-related and logical errors, respectively, within action trajectories. SHARE improves error detection precision and correction efficacy while reducing computational overhead compared to conventional LLM approaches. Additionally, we also incorporate novel hierarchical self-evolution strategy that enhances data efficiency during training. efficiency, and generalizability of SHARE. By enabling SLMs to collaboratively guide LLMs in SQL correction, SHARE achieves substantial execution accuracy improvements over the GPT-4o baseline, with relative gains of 14.80% on BIRD and 11.41% on SPIDER within single round of correction, while significantly reducing computational costs (Section 4.4). Beyond precision, our framework exhibits strong robustness in varying query complexities, low-resource settings, and various generator models, including both closedsource and open-source LLMs (Section 4.2). Notably, SHAREs learned debugging logic generalizes effectively to previously unseen SQL dialects without dialect-specific supervision (Section 4.5). These findings position our method as scalable and cost-efficient paradigm for improving the reasoning reliability of LLMs in SQL auto-correction for real-world applications."
        },
        {
            "title": "2.1 Task Definition",
            "content": "Text-to-SQL. Given natural language question qi Q, where = {qi}n i=1 with its corresponding database input 1 di D, where = {di}n i=1, the goal of text-to-SQL is to guide the generator model to generate the SQL query si by: si = fG(di, qi), (1) where fG () refers to the mapping function applied by the generator model G. Assistant-based Self-Correction. Given the di, qi and the corresponding initial SQL queries generated by the generator model G, the goal of assistant-based correction aims to utilize feedback yi generated by the assistant , which could be LLM or an agent mechanism, to guide the generator model to refine its initial output effectively by: si = fG(di, qi, i, yi), (2) where yi = fT (di, qi, i), and fT () is the mapping function applied by the assistant. The generator model and assistant engage in multiple iterative refinement cycles until correct SQL query is produced or the predefined maximum number of turns is reached. Experimental results across 4 diverse text-toSQL benchmarks demonstrate the effectiveness, 1Database input refers to the schema of specific database and its corresponding sampled value. Figure 2: An illustration of SHARE. Figure (A)-(C) illustrate the training architecture of three specialized SLMs in SHARE: the Base Action Model (BAM), Schema Augmentation Model (SAM), and Logic Optimization Model (LOM). Figure presents SHAREs orchestration of these three models in sequential pipeline for inference."
        },
        {
            "title": "2.2 Action Model",
            "content": "An action model (Zhang et al., 2024) is specifically architected to comprehend, plan, and generate stepwise action trajectories ti, given the contextual input xi by: ti = {a1, a2, ..., an} = fA(xi; A), (3) where fA (; A) refers to the mapping function applied by the action model with an action space inherently mastered by A, and ai denotes as the selected action. Unlike natural language, actions manipulated by action models are typically in the format of API or function calls. For instance, declarative SQL query \"SELECT .. FROM .. WHERE ..\" can be decomposed by an action model into sequence of functional operations as [where(column = param_1, value = param_2), select(table = param_1, column = param_2)]."
        },
        {
            "title": "3.1 Training Pipeline",
            "content": "The general training data used to develop SLMs is often generated through knowledge distillation pipelines, thereby reducing the need for costly human expert annotations (Xu et al., 2024b; Peng and Zhang, 2024). In these pipelines, LLMs serve as teacher models, providing annotations and generating new training instances to guide the learning process of SLMs as student models. We employ this approach to train Base Action Model (BAM), which transforms initially produced declarative SQL queries into structured sequences of actions within predefined action space, capturing the underlying reasoning steps. Building on this foundation, two action models specialized for two crucial aspects of text-to-SQL are further presented: the Schema-Augmentation Model (SAM) and the Logic Optimization Model (LOM). SAM concentrates on improving schema linking (Dou et al., 2023), while LOM focuses on logical synthesis (Yin and Neubig, 2017). All our models were trained via Lora fine-tuning (Hu et al., 2022). To train SAM and LOM efficiently, we propose novel continual learning technique: hierarchical self-evolve strategy. Instead of repeatedly querying teacher LLM (e.g., GPT-4o) for each new training instance, this strategy leverages BAM to synthesize and augment task-specific training data, targeting distinct aspects of text-to-SQL translation. This approach reduces annotation costs while maintaining strong performance, as demonstrated in Section 4.4. Formally, we begin with seed dataset = {(di, qi, si, i=1, where each tuple (di, qi, si) consists of database input, user question, and the associated ground-truth SQL from the BIRD and SPIDER training corpora. detailed i)}n Type ADD Definition Example Inserts an additional action into the original action trajectory. [a1, a2, ..., an] [a1, a2, anew, ..., an] DELETE Removes an existing action from the trajectory. [a1, a2, a3, ..., an] [a1, a3, ..., an] Before: df1 = df.orderby(element = movie.likes, desc).limit(1) res = df1.select(element = movie.director) After: df1 = df.groupby(element = movies.id) df2 = df1.orderby(element = movie.likes, desc).limit(1) res = df2.select(element = movie.director) Before: df1 = df.where(element = users.country_code,filter = 20) df2 = df1.where(element = users.gender, filter = male) res = df2.select(users.user_id) After: df1 = df.where(element = users.country_code,filter = 20) res = df1.select(users.user_id) SUBSTITUTE Replaces an existing action with different action type or modifies the parameters of the existing action. [a1, a2, a3, ..., an] [a1, 2, a3, ..., an] Before: df1 = df.where(element = reviews.Date, filter = 2018-09-11) res = df1.select(district.district_id, district.city) After: df1 = df.where(element = reviews.Date, filter = 2018-09-11) res = df1.select(district.city, district.district_id ) Table 1: Three error perturbation types utilized by Base Action Model (BAM) to implement data augmentation. distribution of the training data is provided in Appendix A.1. The initial SQL is generated by GPT-4o using the baseline prompt implemented in BIRD (Li et al., 2024a)."
        },
        {
            "title": "3.2 Base Action Model (BAM)",
            "content": "Training Target. BAM aims to generate the corresponding action trajectory given an initial SQL query s. Following prior study (Qu et al., 2024), we design actions in target trajectories as pandaslike APIs (see Refined Reasoning Trajectory in Figure 2 (D)) to present the reasoning process of text-to-SQL transformations. The complete enumeration of actions used in the construction of action trajectories within the SHARE framework is detailed in the Appendix A.2. Data Construction. Given that BAM is the most important model and such reasoning derivations are complex and highly demanding, we employ GPT-4o as strong teacher LLM to construct the training data for BAM. As shown in Figure 2 (A), GPT-4o is guided to convert each ground-truth (gt) SQL to verified action trajectory by few-shot prompting. The prompt we use is detailed in Appendix D.3. To ensure high-quality training data with fewer hallucinations during conversion, we only contain (s, t) pairs in which can be successfully reverted back to (Berglund et al., 2024). We ultimately collected 13k query-trajectory pairs as the training data for BAM in this phase."
        },
        {
            "title": "3.3 Schema Augmentation Model (SAM)",
            "content": "Training Target. Schema linking is critical step in identifying the relevant database tables and columns needed to answer user queries (Lei et al., 2020). However, the complexity and heterogeneity of database schemas, spanning from pre-trained language models (PLMs) (Qiu et al., 2020; Li et al., 2023) to large language models (LLMs) (Zhao et al., 2024), often compromise accurate schema linking, thereby introducing substantial burdens on downstream SQL generation. To address this issue, we propose the Schema Augmentation Model (SAM), designed to specifically target and correct schema-linking errors within the input action trajectory. By focusing on schema-related components, SAM aims to isolate and rectify errors before they propagate, ultimately leading to more reliable SQL generation. Data Construction. We begin with corpus of 13k action trajectories from BAM, each represented as (d, q, s, t). For each verified trajectory t, we generate schema-masked variant by inserting mask symbols [MASK] to isolate schemaspecific elements. For each initial SQL s, we extract its referenced tables and columns as an initial schema list l. These paired forms, (t, m) and (d, q, l, m, t), form the backbone of SAMs two-phase training paradigm. In the first phase, SAM is trained with (t, m) to identify and mask schema-related elements accurately. In the second phase, SAM leverages (d, q, l, m, t) to refine the previously masked segments, seamlessly reintegrating the corrected schema links into the schemamasked variant. By employing BAM in few-shot setting to prepare and orchestrate these training steps, we ensure that SAM efficiently acquires the specialized capabilities needed for robust schema augmentation."
        },
        {
            "title": "3.4 Logic Optimization Model (LOM)",
            "content": "Training Target. Given more precise set of schema-linked database tables or columns, the reasoning logic expressed as an action trajectory should align with both natural language descriptions and valid SQL semantics. Formally, the model takes and as input and outputs refined action trajectory t. This trajectory captures the correct chain of reasoning necessary to accurately resolve the question q. Data Construction. As shown in Figure 2 (C), the erroneous action trajectories in the training data for LOM come from two resources. First, we collect the corresponding action trajectory of erroneous initial SQLs. However, the scale of this resource is limited. Therefore, we propose an action-based perturbation strategy for data augmentation. We apply three types of perturbation, as illustrated in Table 1, on error-free action trajectories derived from correct initial SQL to reproduce various logic errors in text-to-SQL conversions. Finally, 15k erroneous action trajectories along with their corresponding verified action trajectories are collected for LOM training. The detailed pseudocode of this process is provided in Appendix A.3."
        },
        {
            "title": "3.5 Orchestration Inference",
            "content": "During inference, as shown in Figure 2 (D), SHARE operates in sequential orchestration that integrates three LoRa fine-tuned models, enabling iterative refinement of action trajectories. Upon receiving an initial SQL query s, SHARE first invokes the BAM to generate corresponding action trajectory t. The SAM then refines by applying schema-based adjustments derived from the given database input d, producing the intermediate trajectory , along with the user query and the refined database content, is forwarded to the LOM for logic-based corrections. The refined trajectory generated by LOM serves as SHAREs final output and is employed as feedback to guide . Next, the underlying language model in self-correcting within zero-shot setting. Ultimately, with these refined action trajectories serving as self-correction signals, the language model can regenerate more accurate and contextually appropriate SQL queries."
        },
        {
            "title": "4.1 Experiment Settings",
            "content": "Datasets and Metrics. The experiments are conducted on four challenging benchmarks for crossdomain text-to-SQLs. 1) BIRD (Li et al., 2024a) is the most challenging large-scale cross-domain text-to-SQL benchmark, which introduces external knowledge as an additional resource in complex scenarios. In this paper, we use its development set for evaluation, which contains 1,534 pairs of text-to-SQL data and 11 complex databases. 2) SPIDER(Yu et al., 2018) is more standard crossdomain text-to-SQL benchmark. It contains 1,034 examples, covering 20 databases across multiple domains, in the development set. 3) DK (Gan et al., 2021), extended from the SPIDER benchmark, requires text-to-SQL parsers equipped with the ability of domain-knowledge reasoning. 4) REALISTIC removes and switches the obvious mentions of schema items in questions, making it closer to the real scenarios. In this paper, we use widely adopted Execution Accuracy (EX) to measure the performance of our framework. Compared Methods. We explore two opensource SLMs, namely Llama-3.1-8B and Phi3-Mini-3.8B, as backbone models to construct our SHARE. For all baseline and advanced selfcorrection methods for comparison in Table 2, we employ GPT-4o as the generator model and report the results after single refinement iteration. Details of these methods are shown in Appendix B.1. Implementation Details. We fine-tune all our models using the LLaMa-Factory library (Zheng et al., 2024) with LoRA (Hu et al., 2022). All our experiments are conducted on 4A100 GPU with 80GB memory. We detail the hyperparameters for training and inference in Appendix B.2, and claim the reproducibility of this work in Appendix E."
        },
        {
            "title": "4.2 Overall Performance",
            "content": "Overall Results. Table 2 presents the performance of GPT-4o on the BIRD and SPIDER benchmarks, comparing approaches with baseline and"
        },
        {
            "title": "Simple Moderate Challenging Total Easy Medium Hard Extra Hard Total",
            "content": "GPT-4o 63.35 44.18 Self-Correction Self-Consistency Multiple-Prompt Self-Debugging DIN-Correction MAC-Refiner MAGIC +SHARE-3.8B +SHARE-8B 62.70 65.75 66. 65.41 65.62 66.27 66.75 68.00 70.81 43.75 49.04 48.06 47.84 46.98 47.41 49.46 51.29 56.25 55.87 45.52 55.28 58.75 58. 44.83 45.21 44."
        },
        {
            "title": "89.10\nSelf Correction w/o Feedback\n88.30\n92.30\n91.10\nSelf Correction w/ Feedback\n91.10\n91.90\n93.10\n-\n92.70\n94.00",
            "content": "46.21 44.83 46.90 45.79 46.21 46.90 58.28 58.02 58.74 59.53 60.89 64.14 83.00 68.40 52.40 77. 82.70 87.90 87.20 85.90 85.20 85.00 - 88.30 90.10 66.10 75.10 74.70 74.70 70.10 73.00 - 78.70 78.20 49.40 58.60 59.00 60.80 55.40 56.60 - 65.10 70. 75.90 81.80 81.50 81.20 79.50 80.40 85.66 84.00 85.90 Table 2: Self-correction performance of GPT-4o in Execution Accuracy (EX) (%) on BIRD and SPIDER. means the model uses external execution results as feedback. Bold indicates best results, while underlines denote second-best results. advanced self-correction strategies. Three key observations emerge: 1) When GPT-4o attempts intrinsic Self-Correction, performance actually decreases (55.87% 55.28% on BIRD). This occurs because the model lacks reliable mechanisms to assess the correctness of its prior reasoning steps, sometimes converting originally correct solutions into incorrect ones (Huang et al., 2024). Moreover, improving prompts for self-correction strategies can inadvertently introduce biases, leading to suboptimal revisions. (Gou et al., 2024). Although advanced methods with carefully crafted designs, such as Multiple-Prompt and Magic, mitigate these biases, they rely heavily on extensive human-engineered prompts and entail significant computational overhead. 2) In contrast, SHARE enables GPT-4o to perform effective selfcorrection through single interaction, resulting in relative improvement of 14.80% in EX on BIRD and 11.41% on SPIDER with SHARE-8B. That is because SHARE introduces novel mechanism for inferring and analyzing initial hidden reasoning paths, allowing the LLM to identify and rectify errors more precisely. Notably, this process is conducted automatically by SLMs, thereby reducing both the human effort and the computational costs associated with high-level LLMs. 3) Significant performance improvements using SHARE3.8B and SHARE-8B, which are based on two widely used SLMs (Phi-3-mini and Meta-Llama8B), demonstrate the generalization and robustness of our training pipeline. METHOD EASY MED. HARD EXTRA ALL GPT-4o 75.50 +SHARE-3.8B 84.90 85.50 +SHARE-8B 81.70 GPT-4o +SHARE-3.8B 88.10 87.20 +SHARE-8B DK 73.60 73.80 81.30 REALISTIC 82.30 86.70 88.20 47.30 48.90 56.80 69.70 68.70 74. 41.90 56.20 63.80 49.50 57.70 68.00 64.10 69.20 75.30 73.40 78.00 81.50 Table 3: Execution Accuracy (EX) of GPT-4o + SHARE across queries of varying levels of difficulty on DK and REALISTIC. Results on Robust Testing. Table 3 presents evaluation results in EX on the variant datasets of SPIDER for robustness without any additional training. SHARE-8B effectively enhances the performance of the GPT-4o baseline by 11.20% and 8.10% on DK and REALISTIC, respectively, with improvements across all difficulty levels. SHARE3.8B also facilitates significant performance gains, achieving relative increase of 7.96% on DK and 7.18% on REALISTIC. Results on Various Generator Models. Although the teacher LLMs we employ for data generation during training are primarily based on GPT-4o, the performance gains observed with our trained SHARE-8B assistant extend well beyond this single source, as evidenced in Table 4. Notably, our approach significantly improves performance for both proprietary closed-source models, such as Claude-3.5-Sonnet ( 28.64% relatively), and for open-source alternatives, such as Llama-3.170B ( 14.88% relatively). This indicates that our MODEL Claude-3.5-S +SHARE-8B GPT-4o-mini +SHARE-8B GPT-3.5-turbo +SHARE-8B SIM. MOD. Closed-Source LLM CHALL. TOTAL 57.08 68.86 55.03 67.46 52.51 57.51 39.87 57. 41.59 50.86 35.99 38.36 31.03 50.34 35.17 40.00 29.66 31.03 Open-Source weaker LM Llama-3.1-70B +SHARE-8B 60.54 68.86 Qwen-Coder-32B 65.72 67.78 +SHARE-8B Llama-3.1-8B +SHARE-8B DS-Coder-6.7B +SHARE-8B 41.62 47. 41.30 56.25 44.61 53.88 46.71 54.31 27.59 35.13 26.94 45.04 41.38 43. 45.23 46.90 20.00 28.97 23.45 36.55 49.41 63.56 49.09 59.64 45.35 49. 53.91 61.93 58.03 61.73 35.33 42.11 34.57 51.24 Table 4: Self-correction performance of various generator models assisted by SHARE on BIRD. For brevity, we refer to some models using shorthand names and provide their corresponding official model aliases in Appendix B.3. SIM., MOD., CHALL. represent the levels of query difficulty and are the abbreviations of simple, moderate, and challenging, respectively. Figure 3: The effect of training data scale on SHARE. method is not limited to the model bias of error patterns in text-to-SQL, but also general knowledge of SQL correction. Results on Low-resource Settings. To take closer look at the impact of the amount and quality of training data on self-correction assistance in LLM, we conduct low-resource training analysis. Specifically, we sampled three subsets of the training data10%, 20%, and 50%and repeated each experiment three times to minimize variance. The averaged results are illustrated in Figure 3. Our findings reveal strong positive correlation between the amount of training data and model performance, thereby confirming the overall high quality of the training set. In particular, GPT-4o + SHARE-8B with only 50% training data outperforms the state-of-the-art MAGIC baseline, achievMETHOD SIM. MOD. CHALL. TOTAL SHARE-8B 70.81 56.25 (a) w/o Schema Aug (b) w/o Logic Opt (c) w/o Hierarchy (d) w/o Error Pert 67.14 64. 68.34 68.08 50.22 46.77 49.89 52.79 46.90 46.00 39.31 45.02 46. 64.14 60.02 ( 4.08) 56.98 ( 7.16) 60.55 ( 3.59) 61.38 ( 2.76) Table 5: Ablation study of SHARE. w/o Schema Aug and w/o Logic Opt denote removing the SAM and LOM, respectively. w/o Hierarchy denotes training specialized models sequentially instead of employing the hierarchical evolution strategy. w/o Error Pert denotes the removal of action-based error perturbation. ing 60.71% versus MAGICs 59.53% in EX in the BIRD data set. However, this positive trend does not fully hold for more challenging instances. From 0% to 20% of the training data, improvements remain unclear and at 10% there is even slight decline in performance. Only when the dataset exceeds 20% of the full training set we do observe clear performance increase. This suggests that performance improvements for harder instances often remain erratic or limited until the dataset size exceeds certain point, particularly for tasks involving nuanced or rare examples, as demonstrated by (Kaplan et al., 2020)."
        },
        {
            "title": "4.3 Ablation Study",
            "content": "Table 5 presents the results of our ablation study. The removal of either the schema or logic refinement module (Table 5 (ab)) results in substantial performance drops, underscoring the importance of the two-stage refinement architecture for disentangling schema linking from logical reasoning (Lei et al., 2020). Replacing the hierarchical evolution strategy with conventional sequential training (Table 5 (c)) leads to 3.59% decline, indicating the advantage of the hierarchical approach in preventing error accumulation and bias transfer across stages (Liu et al., 2021). Furthermore, the exclusion of action-based error perturbation (Table 5 (d)) leads to 2.76% reduction, demonstrating the effectiveness of this lightweight augmentation technique. More detailed analysis is provided in Appendix C.1."
        },
        {
            "title": "4.4 Computational Cost Analysis of SHARE",
            "content": "Table 6 presents the computational cost analysis of SHARE. To the best of our knowledge, our work is the first effort in the text-to-SQL domain to implement correction through collaboration between METHOD LLM INTOKS LLM OUTTOKS SLM INTOKS SLM OUTTOKS COST / 1K EX MAC-Refiner Multiple-Prompt MAGIC GPT-4o + SHARE-8B 7126.74 21128.65 8245.16 716.30 MAGIC GPT-4o + SHARE-8B 4838.63 1623.28 Inference Stage 236.58 1004.55 1737.98 68.32 2085.22 66. - - - 1731.23 Training Stage - 2308.75 - - - 132.16 - 83.04 $20.18 $62.86 $37.99 $2. $32.94 $4.85 58.74 58.80 59.53 64.14 59.53 64.14 Table 6: Token usage and computational cost of various self-correction methods on BIRD. In(Out)Toks refers to the average input (output) token length per instance. Cost / 1K refers to the average cost per 1000 instances. Figure 4: The performance of SHARE on BIRD across various SQL dialects, specifically MySQL (left) and PostgreSQL (right). small and large LMs. This paradigm effectively reduces the inference overhead of SHARE and incurs only one-tenth the cost of the most economical baseline. Notably, SHARE remains highly cost-efficient during the training data construction stage. Compared to the In-Context-Learning-based (ICL-based) training method adopted in MAGIC, which is the strongest self-correction method, our self-evolution strategy significantly reduces the reliance on LLMs during the construction of training data, resulting in substantial cost savings in the overall process. Other relevant details of the cost computation are shown in Appendix C.2."
        },
        {
            "title": "4.5 Generalization for Different SQL Dialects",
            "content": "Mainstream text-to-SQL benchmarks predominantly use SQLite as their target SQL dialect, primarily for its accessibility and ease of data collection. However, due to the heightened privacy requirements in data management, MySQL and PostgreSQL, characterized by licensing restrictions and proprietary attributes, are more commonly adopted dialects in real-world implementation scenarios. As demonstrated in Figure 4, SHARE also exhibits effective performance on MySQL and PostgreSQL dialects even without additional training. This can be attributed to SHAREs focus on learning lowlevel reasoning path corrections, enabling it to generalize across various high-level SQL dialects. MODEL GPT-4o +SHARE-gpt +SHARE-llama Claude-3.5-S +SHARE-gpt +SHARE-llama Llama-3.1-70B +SHARE-gpt +SHARE-llama Llama-3.1-8B +SHARE-gpt +SHARE-llama SIM. MOD. 44.18 63.35 56.25 70.81 57.54 71. CHALL. 45.52 46.90 48.97 TOTAL 55.87 64.14 65.19 57.08 68.86 67.68 60.54 68.86 69.08 41.62 47.68 53.08 39.87 57.11 52. 44.61 53.88 56.90 27.59 35.13 35.56 31.03 50.34 44.83 41.38 43.45 46.90 20.00 28.97 30.34 49.41 63.56 60. 53.91 61.93 63.30 35.33 42.11 45.63 Table 7: Performance comparison across different teacher models on BIRD."
        },
        {
            "title": "4.6 Open-source Teacher Models",
            "content": "During the construction of SHARE, as introduced in Section 3.2, GPT-4o acts as the teacher model for automated data synthesis within the Base Action Model (BAM). To strengthen the flexibility and generalization of our workflow, we further investigate the use of open-source teacher models. Specifically, we replace GPT-4o with Llama-3.1-70B to generate training data for the BAM and retrain SHARE-8B accordingly. To clarify the distinction, we refer to the original version of the SHARE-8B model trained with GPT4o as SHARE-gpt, and the SHARE-8B model trained with Llama-3.1-70B as the teacher model as SHARE-llama. Table 7 shows the performance of various generator models assisted by SHAREgpt and SHARE-llama on the BIRD dev set. It demonstrates that SHARE continues to deliver strong performance even when using an opensource model as the teacher model, and it still works well with variety of generator models. This suggests that our approach is not restricted by the error patterns of any one model in text-to-SQL, but rather leverages broader knowledge of SQL correction."
        },
        {
            "title": "5 Related Work",
            "content": "LLMs for Text-to-SQL. In recent years, large language models (LLMs) (Ouyang et al., 2022b; Anthropic, 2024; Team et al., 2024) have attracted considerable attention due to their robust reasoning and domain generalization capabilities. The application of LLMs has improved the performance of text-to-SQL to another level of intelligence. Early research leverages in-context learning capabilities of LLMs to develop text-to-SQL systems through meticulously crafted prompt engineering methodologies (Rajkumar et al., 2022; Pourreza and Rafiei, 2024; Gao et al., 2024; Qu et al., 2024). With the emergence of language agents (Deng et al., 2024; Gu et al., 2024) as promising paradigm, recent works (Wang et al., 2024; Talaei et al., 2024; Pourreza et al., 2024) leverage multi-agent architectures to construct more reliable and comprehensive frameworks for text-to-SQL conversion, yielding substantial improvements in empirical performance. Self-correction in Text-to-SQL. Self-correction (Pan et al., 2024b), where LLMs evaluate and refine their initial output, has emerged as crucial technology to enhance the reliability and accuracy of automated code generation tasks (Gu, 2023; Li et al., 2024b). Self-correction has been widely applied in text-to-SQL tasks. Some studies (Lee et al., 2024; Gao et al., 2024) leverage carefully designed prompts to guide LLMs in utilizing their intrinsic reasoning capabilities for more effective selfcorrection. Additionally, using feedback to effectively guide the self-correction process of LLMs is another promising approach. The sources of feedback are diverse, ranging from human annotations (Pourreza and Rafiei, 2024), external execution environments (Chen et al., 2024a; Wang et al., 2024) to iterative exploration conducted by the LLM itself (Askari et al., 2024; Xia et al., 2024)."
        },
        {
            "title": "6 Conclusion",
            "content": "In this research, we propose SHARE, an SLMbased hierarchical action correction assistant designed to enable more precise error localization and effective self-correction for LLMs. We further propose novel hierarchical evolution strategy for data-efficient training. Experimental results show the effectiveness and robustness of our method, even in low-source settings, unlocking the potential of SLMs in self-correction for text-to-SQL tasks. Figure 5: The correction performance across finegrained error categories on BIRD."
        },
        {
            "title": "Corrections",
            "content": "To quantify the effectiveness of SHARE in error correction, we analyze the SQL queries generated by the GPT-4o baseline. Following TA-SQL (Qu et al., 2024), we categorize the observed errors into two primary types: schema-based errors and logic-based errors. Each category is further subdivided into three specific subtypes. For detailed definitions and examples of these error types, we refer the reader to TA-SQL. Table 5 presents the correction performance across fine-grained error categories on the BIRD dev set. The results indicate that SHARE is effective in mitigating both schema-based and logic-based errors, showing substantial reductions in Attribute Overanalysis ( 18.61%), Schema Contradiction ( 7.24%), and Clause Abuse ( 7.54%). However, SHARE demonstrates limited effectiveness in correcting instances of Mathematical Delusion ( 1.63%), which may be attributed to the restricted mathematical reasoning capability of the underlying generator model (Mirzadeh et al., 2025). To further elucidate SHAREs correction behavior, we conduct qualitative case studies and present representative example in Appendix C.6 output to confirm the absence of politically sensitive or biased material. Finally, it is noteworthy that we utilize parameter-efficient LoRA finetuning to train our models, which demonstrates superior environmental sustainability compared to full-parameter fine-tuning."
        },
        {
            "title": "7 Limitation",
            "content": "In this paper, we demonstrate the effectiveness of SHARE by presenting the performance of SHAREassisted self-correction in the one-turn setting, where the generator model receives feedback generated by SHARE and performs single-revision iteration. We leave investigating the performance of our framework in multi-turn interactive selfcorrection scenarios, where the correction process undergoes multiple refinement cycles, as our future work. Furthermore, our current work exclusively focuses on the text-to-SQL domain. Expanding SHARE to broader code generation tasks represents another key direction for future research."
        },
        {
            "title": "8 Acknowledgement",
            "content": "We thank all constructive comments from anonyReynold Cheng, Ge Qu, mous reviewers. Jinyang Li, and Nan Huo are supported by the Hong Kong Jockey Club Charities Trust (Project 260920140), the University of Hong Kong (Project 2409100399), the HKU Outstanding Research Student Supervisor Award 2022-23, and the HKU Faculty Exchange Award 2024 (Faculty of Engineering). Bowen Qin was supported by National Science and Technology Major Project (Project 2022ZD0116306). Chenhao Ma was partially supported by NSFC under Grant 62302421, Basic and Applied Basic Research Fund in Guangdong Province under Grant 2023A1515011280, 2025A1515010439, Ant Group through CCF-Ant Research Fund, Shenzhen Research Institute of Big Data under grant SIF20240004, and the Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen. Ge Qu and Jinyang Li were supported by HKU Presidential PhD Scholar Programme. Ge Qu was also funded by Hong Kong PhD Fellowship Scheme."
        },
        {
            "title": "9 Ethical Statement",
            "content": "All datasets employed in this work are publicly accessible. We will also release our models and source code after the review process, ensuring the transparency and reproducibility of our findings. Furthermore, the output generated by our investigations is structured as SQL queriesa programming language formatrather than natural language text, which could potentially involve harmful or biased content. Our team meticulously examines each"
        },
        {
            "title": "References",
            "content": "Anthropic. 2024. Claude 3 haiku: our fastest model yet. Arian Askari, Christian Poelitz, and Xinye Tang. 2024. Magic: Generating self-correction guideline for incontext text-to-sql. Kamran Ahmad Awan, Ikram Ud Din, Ahmad Almogren, and Joel J. P. C. Rodrigues. 2023. Privacypreserving big data security for iot with federated learning and cryptography. IEEE Access. Lukas Berglund, Meg Tong, Maximilian Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. 2024. The reversal curse: Llms trained on \"a is b\" fail to learn \"b is a\". In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. 2023. Codet: Code generation with generated tests. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. 2024a. Teaching large language models to self-debug. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. 2024b. Teaching large language models to self-debug. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang, Huan Sun, and Yu Su. 2024. Mind2web: Towards generalist agent for the web. Advances in Neural Information Processing Systems. Longxu Dou, Yan Gao, Mingyang Pan, Dingzirui Wang, Wanxiang Che, Jian-Guang Lou, and Dechen Zhan. 2023. Unisar: unified structure-aware autoregressive language model for text-to-sql semantic parsing. Int. J. Mach. Learn. Cybern. Nouha Dziri, Andrea Madotto, Osmar Zaïane, and Avishek Joey Bose. 2021. Neural path hunter: Reducing hallucination in dialogue systems via path grounding. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021. Yujian Gan, Xinyun Chen, and Matthew Purver. 2021. Exploring underexplored limitations of cross-domain In Proceedings of the text-to-sql generalization. 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021. Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, and Jingren Zhou. 2024. Text-to-sql empowered by large language models: benchmark evaluation. Proc. VLDB Endow. Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2024. CRITIC: large language models can self-correct with In The Twelfth Intertool-interactive critiquing. national Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. Qiuhan Gu. 2023. Llm-based code generation method for golang compiler testing. In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023, San Francisco, CA, USA, December 3-9, 2023. Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, and Yu Su. 2024. Middleware for llms: Tools are instrumental for language agents in complex environments. arXiv preprint arXiv:2402.14672. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. Lora: Low-rank adaptation of large language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. 2024. Large language In The models cannot self-correct reasoning yet. Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Comput. Surv. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. Dongjun Lee, Choongwon Park, Jaehyuk Kim, and Heesoo Park. 2024. Mcs-sql: Leveraging multiple prompts and multiple-choice selection for text-to-sql generation. Wenqiang Lei, Weixin Wang, Zhixin Ma, Tian Gan, Wei Lu, Min-Yen Kan, and Tat-Seng Chua. 2020. Re-examining the role of schema linking in text-toIn Proceedings of the 2020 Conference on SQL. Empirical Methods in Natural Language Processing (EMNLP). Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si, and Yongbin Li. 2023. Graphix-t5: Mixing pretrained transformers with graph-aware layers for textto-sql parsing. In Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023, Washington, DC, USA, February 7-14, 2023. Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo, et al. 2024a. Can llm already serve as database interface? big bench for large-scale database grounded text-to-sqls. Advances in Neural Information Processing Systems. Jinyang Li, Nan Huo, Yan Gao, Jiayi Shi, Yingxiu Zhao, Ge Qu, Yurong Wu, Chenhao Ma, Jian-Guang Lou, and Reynold Cheng. 2024b. Tapilot-crossing: Benchmarking and evolving llms towards interactive data analysis agents. Zhenwen Li and Tao Xie. 2024. Using llm to select the right sql query from candidates. Huihui Liu, Yiding Yang, and Xinchao Wang. 2021. Overcoming catastrophic forgetting in graph neural networks. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021. Xiping Liu and Zhao Tan. 2024. Epi-sql: Enhancing text-to-sql translation with error-prevention instructions. Seyed-Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. 2025. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022a. Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022b. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William Yang Wang. 2024a. Automatically correcting large language models: Surveying the Landscape of Diverse Automated Correction Strategies. Trans. Assoc. Comput. Linguistics. Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William Yang Wang. 2024b. Automatically correcting large language models: Surveying the landscape of diverse automated correction strategies. Transactions of the Association for Computational Linguistics. Tianyu Peng and Jiajun Zhang. 2024. Enhancing knowledge distillation of large language models through efficient multi-modal distribution alignment. Mohammadreza Pourreza, Hailong Li, Ruoxi Sun, Yeounoh Chung, Shayan Talaei, Gaurav Tarlok Kakkar, Yu Gan, Amin Saberi, Fatma Ozcan, and Sercan O. Arik. 2024. Chase-sql: Multi-path reasoning and preference optimized candidate selection in text-to-sql. Mohammadreza Pourreza and Davood Rafiei. 2024. Din-sql: Decomposed in-context learning of textto-sql with self-correction. Advances in Neural Information Processing Systems. Bowen Qin, Lihan Wang, Binyuan Hui, Bowen Li, Xiangpeng Wei, Binhua Li, Fei Huang, Luo Si, Min Yang, and Yongbin Li. 2022. SUN: exploring intrinsic uncertainties in text-to-sql parsers. In Proceedings of the 29th International Conference on Computational Linguistics, COLING 2022, Gyeongju, Republic of Korea, October 12-17, 2022. XiPeng Qiu, TianXiang Sun, YiGe Xu, YunFan Shao, Ning Dai, and XuanJing Huang. 2020. Pre-trained models for natural language processing: survey. Science China Technological Sciences. Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo, Chenhao Ma, and Reynold Cheng. 2024. Before generation, align it! novel and effective strategy for mitigating hallucinations in text-to-sql generation. Association for Computational Linguistics. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly reward model. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Nitarshan Rajkumar, Raymond Li, and Dzmitry Bahdanau. 2022. Evaluating the text-to-sql capabilities of large language models. Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, and Jonathan Fuerst. 2024. Sm3-text-to-query: Synthetic multi-model medical text-to-query benchmark. Shayan Talaei, Mohammadreza Pourreza, Yu-Chen Chang, Azalia Mirhoseini, and Amin Saberi. 2024. Chess: Contextual harnessing for efficient sql synthesis. Gemini Team, Rohan Anil, Sebastian Borgeaud, JeanBaptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, and Andrew M. 2024. Gemini: family of highly capable multimodal models. human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018. Jianguo Zhang, Tian Lan, Ming Zhu, Zuxin Liu, Thai Hoang, Shirley Kokane, Weiran Yao, Juntao Tan, Akshara Prabhakar, Haolin Chen, Zhiwei Liu, Yihao Feng, Tulika Awalgaonkar, Rithesh Murthy, Eric Hu, Zeyuan Chen, Ran Xu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Silvio Savarese, and Caiming Xiong. 2024. xlam: family of large action models to empower ai agent systems. Bing Wang, Changyu Ren, Jian Yang, Xinnian Liang, Jiaqi Bai, Linzheng Chai, Zhao Yan, Qian-Wen Zhang, Di Yin, Xing Sun, and Zhoujun Li. 2024. Mac-sql: multi-agent collaborative framework for text-to-sql. Xuanliang Zhang, Dingzirui Wang, Longxu Dou, Qingfu Zhu, and Wanxiang Che. 2025. survey of table reasoning with large language models. Frontiers Comput. Sci. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2024. survey of large language models. Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Wanxiang Che, Zhiyuan Liu, and Maosong Sun. 2025. Chartcoder: Advancing multimodal large language model for chart-to-code generation. Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, and Zheyan Luo. 2024. LlamaFactory: Unified efficient fine-tuning of 100+ language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations). Association for Computational Linguistics. Ruiqi Zhong, Charlie Snell, Dan Klein, and Jason Eisner. 2023. Non-programmers can label programs indirectly via active examples: case study with text-to-sql. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 51265152. Hanchen Xia, Feng Jiang, Naihao Deng, Cunxiang Wang, Guojiang Zhao, Rada Mihalcea, and Yue Zhang. 2024. r3: \"this is my sql, are you with me?\" consensus-based multi-agent system for text-to-sql tasks. Yuanzhen Xie, Xinzhou Jin, Tao Xie, Matrixmxlin Matrixmxlin, Liang Chen, Chenyun Yu, Cheng Lei, Chengxiang Zhuo, Bo Hu, and Zang Li. 2024. Decomposition for enhancing attention: Improving llmbased text-to-sql through workflow paradigm. In Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024. Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, and Yi Wu. 2024a. Is dpo superior to ppo for llm alignment? In Proceedings of the 41st comprehensive study. International Conference on Machine Learning. Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, and Tianyi Zhou. 2024b. survey on knowledge distillation of large language models. Pengcheng Yin and Graham Neubig. 2017. syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir R. Radev. 2018. Spider: large-scale MODEL #INPUT #OUTPUT A.3 Erroneous Trajectory Collection Base Action Model Schema Augmentation Model Logic Optimation Model 196.23 621.46 683.69 25.71 30.24 29.80 Table 8: The average length of input and output tokens in the training corpus for each model. SHORTHAND NAME OFFICIAL MODEL ALIAS Llama-3.1-70B Qwen-Coder-32B Llama-3.1-8B DS-Coder-6.7B Llama-3.1-70B-Instruct Qwen2.5-Coder-32B-Instruct Llama-3.1-8B-Instruct deepseek-coder-6.7b-instruct Table 9: Shorthand model names used throughout the paper and their corresponding official model aliases."
        },
        {
            "title": "A SHARE Recipe",
            "content": "A.1 Training Data Distribution In this work, we utilize the training set of two mainstream cross-domain text-to-SQL benchmarks as the seed data to construct our own training data. 1) BIRD: The training set of BIRD contains 9,428 pairs of text-to-SQL data and 69 big databases across 37 professional domains. 2) SPIDER: SPIDER is more standard text-to-SQL benchmark that contains 8659 training examples across more than 20 domains. Table 8 displays the detailed average length of the input and output tokens for each model in our own training data. Our approach achieved superior performance with notably few training tokens, validating the data-efficient nature of SHARE. A.2 Action Space of SHARE As discussed in Section 3.2, we design actions in target trajectories as pandas-like APIs and employ GPT-4o to convert each ground truth SQL to verified action trajectory by few-shot prompting for the training data construction. All logically meaningful and validated actions generated by GPT-4o in this process are collected as the action space of SHARE. We further categorize these actions into four types, including clause, dataframe, aggregation, and operator types. Specific actions are presented in Table 11 and 12. APPROACH SIMPLE MODERATE CHALLENGING TOTAL DPO LoRA 65.08 70.81 48.06 56.25 42.76 46.90 57.82 64.14 Table 10: The performance of SHARE trained via different fine-tuning approaches on BIRD dev. As introduced in Section 3.4, the erroneous action trajectories in the training data for LOM come from two resources: 1) initial erroneous SQLs, and 2) verified action trajectories that are perturbed by our action-based perturbation strategy. To better clarify the data augmentation through error perturbations, we present the pseudocode of this process in Pseudocode 1. Algorithm 1 Data Augmentation 1: Inputs: 2: verif ied_corrs collection of verified correct trajectories verif ied_corr_1, verif ied_corr_2, . . . 3: SLM 4: Small Language Model Number of error perturbations per ground truth 5: Output: 6: data_pairs set of (erroneous trajectory, verified correct trajectory) pairs 7: Initialize: 8: Initialize data_pairs as an empty set. 9: for verif ied_corr_i in verif ied_corrs do 10: for = 1 to do 11: 12: er_p ErrorPerturb(verif ied_corr_i, SLM ) Use the smaller model to inject errors into the verified correct trajectory verif ied_corr_i. Add the pair (er_p, verif ied_corr_i) to data_pairs No additional verification is needed, since verif ied_corr_i is correct by definition. end for 13: 14: end for 15: return data_pairs"
        },
        {
            "title": "B Experiment Setup",
            "content": "B.1 Baseline Methods Table 2 presents all the baseline methods we use for comparison. In this work, we consider SelfCorrection (Huang et al., 2024), Self-Consistency (Wang et al., 2023), Multiple-Prompt (Lee et al., 2024) as feedback-independent self-correction baselines. These methods leverage the intrinsic capabilities of the LLM through prompt engineering to enable its self-correction. For feedbackdependent self-correction baselines, we implement Self-Debugging (Chen et al., 2024a), DINCorrection (Pourreza and Rafiei, 2024), MACRefiner (Wang et al., 2024), and MAGIC (Askari et al., 2024), where the Large Language Model (LLM) refines its initial output under the guidance of feedback. Feedback utilized in these approaches is derived from three primary sources: human annotations, external execution environments, and through LLMs iteratively exploring contextual environments. The details of these methods are as follows: 1) Self-Correction is naive method in which the LLM reconsiders and refines its outputs through vanilla Chain-of-Thought (CoT) prompting. 2) Self-Consistency (Wang et al., 2023) is method that refines the initial output by exploring broader search space and selecting the most consistent one. We generate five SQL queries using the baseline SQL generation prompt implemented in BIRD (Li et al., 2024a) and consider an instance to be correctly solved if at least one of the generated SQL queries produces the correct result. 3) MultiplePrompt generates diverse queries by systematically reordering candidate tables within the prompt. Following the implementation of (Lee et al., 2024), we generate up to five combinations of prompts for each instance and employ the same evaluation mechanism as self-consistency to determine the results. 4) Self-Debugging (Chen et al., 2024b) generates the feedback by investing the execution results and explaining the generated SQL in natural language. The feedback further serves as guidance to instruct the LLM to self-correct. 5) DINCorrection utilizes the human-annotated guideline from DIN-SQL (Pourreza and Rafiei, 2024) for self-correction. 6) MAC-Refiner, which is sub-agent of MAC-SQL (Wang et al., 2024), implements the self-correction process based on multidimensional error feedback information by analyzing the execution results, including syntactic correctness, execution feasibility, and retrieval of non-empty results. 7) Magic (Askari et al., 2024) collaborates on the failure experiences and automatically distills correction guidelines, employing crafted LLM-based multi-agent framework for self-correction. B.2 Hyper-Parameters We set the low-rank dimensions as 8, the learning rate as 5e5, and the batch size as 8. We train epochs for the Base Action Model (BAM) and train 3 epochs for the Schema Augmentation Model (SAM) and the Logic Optimization Model (LOM). During inference, we set the temperature as 0.1, the top as 0.95, and the maximum sample length as 1024. We report the experimental results as the average of five repeated trials. B.3 Model Reference Mapping We list in Table 9 the shorthand model names used throughout the paper alongside their corresponding official model aliases."
        },
        {
            "title": "C Further Anaylsis",
            "content": "C.1 Ablation Study Table 5 presents the results of our ablation study, aimed at isolating and evaluating contributions of each component of SHARE. As shown in Table 5(a)-(b), the substantial performance degradation resulting from the removal of either refinement action model underscores the importance of our two-stage refinement design. This two-stage approach, which separately handles schema linking and logical reasoning, proves to be essential for effective text-to-SQL correction (Lei et al., 2020). To further examine the benefits of the hierarchical evolution strategy in SHARE, we compare it against sequential training pipeline reminiscent of classical continual learning. When trained sequentially, performance declines by 3.59% (Table 5(c)), suggesting that later models may be disproportionately influenced by biases or errors carried over from earlier training stages (Liu et al., 2021). In contrast, SHARE employs hierarchical evolution during training and strategically integrates knowledge at inference time, mitigating these limitations and achieving superior results. Finally, Table 5(d) highlights the effectiveness of action-based error perturbation as data augmentation strategy. Although simple, it yields 2.76% improvement in performance, reinforcing its value as straightforward yet potent enhancement to SHAREs overall text-to-SQL reasoning capability. C.2 Computational Cost of SHARE As illustrated in Section 4.4, we compare the average token usage per instance and average computational cost per 1000 instances during the inference and training stages for GPT-4o assisted by SHARE, versus other strong LLM-based text-to-SQL correction approaches on the BIRD development set. We present the usage of input and output tokens separately since they have different prices. We take the same price for the calculation as in the previous work (Sivasubramaniam et al., 2024) 2. Notably, SHARE remains highly cost-efficient during the training data construction stage. As introduced in Section 3.2, SHARE just uses GPT4o to generate and verify the training data for the Base Action Model (BAM). Afterward, BAM itself creates the training data for all other models, enabling self-evolution process without further reliance on GPT-4o. To more clearly demonstrate SHAREs cost-efficiency in training, we compare it against the strongest self-correction method, MAGIC. While MAGIC does not undergo direct fine-tuning step, it adopts an ICL-based training approach, which follows training-like procedure where the LLM explores the training set, produces correction guideline for each instance, and memorizes successful corrections as task knowledge for inference. As shown in Table 6, the sharp reduction in token usage directly translates to significant computational savings, underscoring SHAREs superior cost-efficiency in the training stage. C."
        },
        {
            "title": "Independent Inference of SHARE",
            "content": "While SHARE shows clear improvements among various generator LLMs, key question is how well it performs independently, without any external LLM grounding. This question is especially important for privacy-sensitive scenarios, such as textto-SQL tasks on confidential relational databases. To address this, we evaluate SHAREs standalone capabilities, using the same orchestration prompting strategy as for Llama-3.1-8B Orchestration. As shown in Figure 6, SHARE-8B achieves robust performance on its own, surpassing both Llama-3.1-8B and Llama-3.1-8B Orchestration, and approaching the quality of strong proprietary models like GPT-35-Turbo, Claude-3.5-Sonnet, and GPT4o-mini. This improvement results from our parameterefficient LoRa fine-tuning approach, which augments the models capabilities without altering its original parameters. By optimizing only small set of new parameters, we enhance the underlying 2Pricing of GPT-4o API: https://openai.com/api/pricing/. Price of Llama-3.1 8B usage: https://groq.com/pricing/ Figure 6: SHARE on BIRD."
        },
        {
            "title": "Independent",
            "content": "inference performance of SLMs text-to-SQL performance without compromising its existing strengths. Moreover, this efficient design supports secure on-device deployment that does not require exposing sensitive database content, relying solely on an 8B-scale SLM and modest set of additional parameters. C.4 Analysis of Overcorrections Overcorrection (Pan et al., 2024a), which refers to the modification of initially correct SQL queries into incorrect ones, is notorious challenge in selfcorrection. To mitigate this issue, we tailored the training data for the Logic Optimization Model (LOM). Specifically, we consider pairs of (erroneous trajectory, verified trajectory) as positive samples and, at 4:1 ratio, introduce (verified trajectory, verified trajectory) pairs as negative samples. Analysis of the final correction results shows that, compared to the current leading selfcorrection method, MAGIC, SHARE reduced the overcorrection rate from 15.52% to 11.20%. This demonstrates that our design mitigates overfitting in the correction process in simple but effective way, preventing the SLMs from treating all trajectories as erroneous and unnecessarily fixing them. C.5 Fine-tuning Approach Exploration Apart from LoRA, we also explored training the SLMs in SHARE using Direct Preference Optimization (DPO) (Rafailov et al., 2023) during our initial attempt. In the data construction stage, verified action trajectories are considered as the chosen responses. We employ the action-based perturbation strategy introduced in Section 3.4 and provide 5-shot examples to guide GPT-4o to generate rejected responses based on chosen responses. As shown in Table 10, compared to SHARE8B trained via LoRA, the performance gains of the DPO-trained version showed consistent decline across all difficulty levels. We observe that the DPO model outputs many meaningless trajectories, such as invalid pandas output format. We speculate that the suboptimal performance of DPObased training arises from its limited suitability for low-resource settings. Furthermore, for data science code generation tasks (Zhao et al., 2025) that require complex reasoning, DPO relies on highquality data and requires crafted rejected responses by human annotation (Xu et al., 2024a). In contrast, LoRA can effectively leverage automatically generated data, making it more efficient under these constraints. Consequently, we adopted LoRA as our primary fine-tuning method, given its lightweight design and effectiveness. C.6 Case Study In order to provide deeper insights into SHAREs effectiveness, we conducted case studies on its correction outputs. Table 13 presents an illustrative case randomly selected from the BIRD development set. By decomposing the declarative SQL query into an action trajectory and leveraging the multi-SLM orchestration during inference, SHARE achieves more granular corrections. Consequently, it produces correct query that effectively addresses both schema and logic issues. We additionally offer an output log that contains the output of each model during SHARE inference for reference."
        },
        {
            "title": "D Implement Prompts",
            "content": "D.1 Data Construction for BAM Figure 7 illustrates the prompts employed in our data construction process for BAM. Specifically, we utilize seven examples to guide GPT-4o in generating corresponding action trajectories for SQL queries. The figure presents two representative examples, while the remaining examples can be found in our code. D.2 Error Perturbation Prompt Figure 8 illustrates the prompts we use to implement error perturbations during the data construction process of LOM. Specifically, we utilize four examples to guide BAM to generate perturbed action trajectories. The figure presents representative example, while the remaining examples can be found in our code. D."
        },
        {
            "title": "Inference Prompts",
            "content": "In this section, we present prompts that we use in the inference process of SHARE. During inference, we prompt BAM to convert the initial SQL using the prompt in Figure 9. Subsequently, the generated trajectory is forwarded to SAM. The SAM first masks the schema using the prompt in Figure 10 and then generates the schema-refined trajectory using the prompt in Figure 11. The LOM then takes this trajectory as input and refines it as the final output of SHARE using the prompt in Figure 12. Finally, the SHARE-produced trajectory serves as feedback to facilitate the self-correction of LLM, as shown in Figure 13. All the prompts are in the zero-shot setting."
        },
        {
            "title": "E Reproducebility",
            "content": "via We fine-tune and infer open-source models, Llama-3.1-8b-Instruct including Phi-3-mini-4K-instruct and LlamaFactory3. The (3.8B) Llama-3.1-70B-Instruct model inferred using vllm4. To accelerate its inference process, we also implemented deepspeed5. All open-source models accessed via huggingface6. are is We will open-source the source code along with the training data, model checkpoints, and prompts in each stage after the anonymous review phase. 3https://github.com/hiyouga/LLaMA-Factory 4https://github.com/vllm-project/vllm 5https://github.com/microsoft/DeepSpeed 6https://huggingface.co/models Category Clause Action SELECT Expression Explanation select(elements) WHERE where(element, filter) GROUP BY groupby(elements) HAVEING having(element, filter) ORDER BY orderby(by, order) LIMIT limit(num) DISTINCT distinct(element) Select data from the database. Parameters: elements - the selected elements. Valid elements include qualified column names in the format of table.column, aggregate functions, or any valid SQL-syntax selectable entity. Multiple elements are separated by commas. Filter rows by conditions. Parameters: elements - The qualified column, or expression to be filtered. filter - The condition that determines which values from the element are included. Groups rows that have the same values into summary rows. Parameters: elements - Qualified columns, or expressions used to group the data. Multiple elements are separated by commas. Filter groups of data with aggregate functions. Parameters: elements - Qualified columns, or expressions used to filter data. Multiple elements are separated by commas. filter - The condition that determines which values from the element are included. Sort the result set based on qualified column or expression. Parameters: by - The qualified column or expression used to sort the data. order - The sorted order. It should be DESC or ASC. Restrict the number of rows returned. Parameters: num - The num is flexible input that specifies the type of limitation to apply. For instance, limit(1) denotes limiting the number of rows to 1. limit(2,9) denotes specifying range of columns to return, which is columns 2 through 9. Remove duplicate rows from the result set. Parameters: element - The qualified column to be processed. Dataframe Aggregation UNION df1.union(df2) Union the result set of two dataframes. INTERSECT df1.intersect(df2) Intersect the result set of two dataframes. EXCEPT df1.except(df2) Subtract the result of df2 from the result of df1. SUM sum(element) AVG average(element) COUNT count(element) MIN min(element) MAX max(element) Sum all non-null values of the element or expression. Parameters: element - The target qualified column or expression. Calculate the average of all non-null values for the element or expression. Parameters: element - The target qualified column or expression. Returns the total number of the element or expression. Parameters: element - The target qualified column or expression. Minimum value in the element or expression except for nULL. Parameters: element - The target qualified column or expression. Maximum value in the element or expression except for nULL. Parameters: element - The target qualified column or expression. Table 11: Actions categorized as clause, dataframe, and aggregation types employed in the construction of action trajectories within SHARE. Actions categorized as operator types are shown in Table 12. Category Operator Action CAST CALCULATION SUBSTR Expression Explanation cast(element, type) Convert the element or expression to the target data type. Parameters: element - The qualified column or expression to convert. type - The target data type. +, -, *, / Implement corresponding calculations for two expressions. substr(element, piv, len) Extract substring, starting from specified position and optionally for specified length Parameters: element - The qualified column to extract. piv - The start point. len - The extracted length. Table 12: Actions categorized as operator actions employed in the construction of action trajectories within SHARE. Actions categorized as other types are shown in Table 11. Question Evidence Gold Initial SQL MAGIC SHARE Initial SQL BAM: SAM: LOM: Final Output Detailed Case Which county reported the most number of school closures in the 1980s with school ownership code belonging to Youth Authority Facilities (CEA)? Youth Authority Facilities (CEA) refers to SOC = 11; 1980s = years between 1980 and 1989. SELECT County FROM schools WHERE strftime(%Y, ClosedDate) BETWEEN 1980 AND 1989 AND SOC = 11 GROUP BY County ORDER BY COUNT(ClosedDate) DESC LIMIT 1 SELECT County, COUNT(*) AS YearCount FROM schools WHERE Year BETWEEN 1980-01-01 AND 1989-12-31 AND SOC = 11 GROUP BY County ORDER BY YearCount DESC LIMIT 1; SELECT County, COUNT(*) as ClosureCount FROM schools WHERE ClosedDate BETWEEN 1980-01-01 AND 1989-12-31 AND SOC = 11 GROUP BY County ORDER BY ClosureCount DESC LIMIT 1; SELECT schools.County FROM schools WHERE schools.SOC = 11 AND schools.ClosedDate BETWEEN 1980-01-01 AND 1989-12-31 GROUP BY schools.County ORDER BY COUNT(schools.ClosedDate) DESC LIMIT 1; Output Log SELECT County, COUNT(*) AS YearCount FROM schools WHERE Year BETWEEN 1980-01-01 AND 1989-12-31 AND SOC = 11 GROUP BY County ORDER BY YearCount DESC LIMIT 1; df1 = df.where(element = schools.Year, filter = between 1980-01-01 and 1989-12-31)) df2 = df1.where(element = schools.SOC, filter = 11) df3 = df2.groupby(schools.County).count(schools.Year) df4 = df3.orderby(by = count(schools.Year), desc).limit(1) res = df4.select(schools.County, count(schools.Year)) df1 = df.where(element = schools.ClosedDate, filter = between 1980-01-01 and 1989-12-31)) df2 = df1.where(element = schools.SOC, filter = 11) df3 = df2.groupby(schools.County).count(schools.ClosedDate) df4 = df3.orderby(by = count(schools.ClosedDate), desc).limit(1) res = df4.select(schools.County, count(schools.ClosedDate)) df1 = df.where(element = schools.ClosedDate, filter = between 1980-01-01 and 1989-12-31)) df2 = df1.where(element = schools.SOC, filter = 11) df3 = df2.groupby(schools.County).count(schools.ClosedDate) df4 = df3.orderby(by = count(schools.ClosedDate), desc).limit(1) res = df4.select(schools.County) SELECT schools.County FROM schools WHERE schools.SOC = 11 AND schools.ClosedDate BETWEEN 1980-01-01 AND 1989-12-31 GROUP BY schools.County ORDER BY COUNT(schools.ClosedDate) DESC LIMIT 1; Table 13: Case study: an illustrative case from BIRD dev. Figure 7: The prompt for the data construction process of BAM. Figure 8: The prompt for the error perturbation strategy implemented by BAM. Figure 9: The prompt for BAM to convert SQL to action trajectory. Figure 10: The prompt for SAM to generate the schema-masked variant given the input trajectory. Figure 11: The prompt for SAM to reinsert the correct schema in the schema-based variant. Figure 12: The prompt for LOM to rectify logic-related errors in the input trajectory. Figure 13: The prompt for LLM to generate refined SQL given the trajectory outputted by SHARE."
        }
    ],
    "affiliations": [
        "BAAI",
        "The Chinese University of Hong Kong, Shenzhen",
        "The University of Hong Kong"
    ]
}