{
    "paper_title": "Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key",
    "authors": [
        "Yingda Chen",
        "Xingjun Wang",
        "Jintao Huang",
        "Yunlin Mao",
        "Daoze Zhang",
        "Yuze Zhao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As large language models rapidly evolve to support longer context, there is a notable disparity in their capability to generate output at greater lengths. Recent study suggests that the primary cause for this imbalance may arise from the lack of data with long-output during alignment training. In light of this observation, attempts are made to re-align foundation models with data that fills the gap, which result in models capable of generating lengthy output when instructed. In this paper, we explore the impact of data-quality in tuning a model for long output, and the possibility of doing so from the starting points of human-aligned (instruct or chat) models. With careful data curation, we show that it possible to achieve similar performance improvement in our tuned models, with only a small fraction of training data instances and compute. In addition, we assess the generalizability of such approaches by applying our tuning-recipes to several models. our findings suggest that, while capacities for generating long output vary across different models out-of-the-box, our approach to tune them with high-quality data using lite compute, consistently yields notable improvement across all models we experimented on. We have made public our curated dataset for tuning long-writing capability, the implementations of model tuning and evaluation, as well as the fine-tuned models, all of which can be openly-accessed."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 5 1 ] . [ 2 0 1 2 0 1 . 0 1 4 2 : r a"
        },
        {
            "title": "Minimum Tuning to Unlock Long Output from LLMs with High\nQuality Data as the Key",
            "content": "Yingda Chen, Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang and Yuze Zhao ModelScope Team, Alibaba Group ABSTRACT As large language models rapidly evolve to support longer context, there is notable disparity in their capability to generate output at greater lengths. Recent study[8] suggests that the primary cause for this imbalance may arise from the lack of data with long-output during alignment training. In light of this observation, attempts are made to re-align foundation models with data that fills the gap, which result in models capable of generating lengthy output when instructed. In this paper, we explore the impact of data-quality in tuning model for long output, and the possibility of doing so from the starting points of human-aligned (instruct or chat) models. With careful data curation, we show that it possible to achieve similar performance improvement in our tuned models, with only small fraction (3.74%) of training data instances and compute. In addition, we assess the generalizability of such approaches by applying our tuning-recipes to several models. our findings suggest that, while capacities for generating long output vary across different models out-of-the-box, our approach to tune them with high-quality data using lite compute, consistently yields notable improvement across all models we experimented on. We have made public our curated dataset for tuning long-writing capability, the implementations of model tuning and evaluation, as well as the fine-tuned models, all of which can be openly-accessed."
        },
        {
            "title": "1 INTRODUCTION\nDespite recent strides in large language models (LLMs) for handling\nextensive inputs[4, 15], current long-context LLMs face a notable\nchallenge when it comes to generating equally lengthy outputs.\nThe ability to produce coherent and contextually rich text over\nextended lengths remains a critical bottleneck. This limitation not\nonly restricts the practical utility of these models but also highlights\na gap between input processing and output generation capabilities.\nAs the demand for more sophisticated and versatile AI systems\ngrows, addressing this disparity becomes increasingly important.\nThe capability to handling long context does not readily trans-\nlate into that of outputting long output following the prompted\ninstruction. To tackle the imbalance of these two capabilities nor-\nmally found in general-purposed LLMs, several previous studies\nhave gone into instructing the LLM to follow length constraints[23],\nand to understand multi-constraint instruction for long-form text\ngeneration[14]. In particular, the authors of [8] make the impor-\ntant observations that for many LLMs, there is a significant lack of\nalignment-training data samples with lengthy output. In recogni-\ntion of this gap, an alignment-based approach was taken to align\nbase model with data of lengthy output, resulting in LongWriter\nbilingual model[7] that scales the output window size of LLMs to\n10, 000+ words. Building upon of these earlier observations, we",
            "content": ": equal contributions. : corresponding author. are of further opinion that not only the length of output matters, the proper match between the required length in the prompt instruction, and the actual output length, also matters in tuning data. Therefore, it is important to tune model with high-quality dataset that meet the requirements not only in length, but also in coherence. In this paper, we show how to curate high-quality dataset that meets both of these requirements, and tune model for the task of long-form length-following. In addition, with high-quality data, it is possible to achieve the goal with minimum tuning cost, as measured by the number of training data instances. By doing so, we aim to provide insights into how to tune models that handle both long inputs and generate high-quality, extended outputs, and at much lower cost. Specifically, we have made the following contributions in this paper: Identification of the Importance of Aligning Quality of Data with the Task: We identify that aligning the quality of the data is crucial for tuning model towards longwriting task. Once high-quality data that align well with the task, it is possible to achieve significant model performance improvement with as little as 666 data samples. Human-Aligned Model as Starting Point: Our results confirm that well trained, general human-aligned model can serve as good starting point for unlocking the capability of outputting long text and following prompted instruction. While our work leverages upon, and is motivated by results outlined in [8], we deviate from the alignmentbased approach therein, and choose to tune our model from human-aligned starting point. We believe this is viable solution that should apply to wide range of tasks that do not conflict with the overall goal of human-alignment. Efficient Tuning with Minimal Data: Altogether, we show that by starting tuning from human-aligned models, and by using small quantity of high-quality data, much higher tuning efficiency can be achieved. In particular, we are able to tune long-writing model with similar performance[8] with only less than 4% of training data instances. The rest of this paper is organized as follows. Section 2 outlines the methodologies for evaluating models performance for the task of long-form output following instructions. The process of data curation to produce high-quality data is then described in Section 3. We than present how we tune the models for the target tasks with different experiments, and present the performance results of the models tuned under various setups. The paper is then concluded in Section 5, with additional data presented in Appendix."
        },
        {
            "title": "2 EVALUATION METHODOLOGIES\nWe followed the evaluation methodologies in [8] and adopted\nLongBench-Write as the benchmark for evaluating a model’s ca-\npacities in following instruction to output long text. In particular, we\nhave integrated an open-source implementation of LongBench-Write\nin EvalScope framework[9]. With LongBench-Write , two metrics\nare employed to evaluate the quality of a model, namely",
            "content": "Output Length Score 𝑆𝐿, and Output Quality Score 𝑆𝑄 In particular, to ensure that the models output length is as close as possible to the requirement specified in the instructions, piecewise linear function is used to calculate 𝑆𝐿: 100 max(0, 1 100 max(0, 1 ( 𝐿 𝐿 1 ( 𝐿 𝐿 1 ) ) /3) /2) if 𝐿 > 𝐿, if 𝐿 𝐿. (1) 𝑆𝐿 = 𝐿 denotes the target length as instructed and 𝐿 is the actual output length. With this metric, an output length falling short or excessively over-length with both lead to lower score of 𝑆𝐿. On the other hand, the output quality 𝑆𝑄 is comprehensively evaluated by GPT4o from various perspectives including Relevance, Accuracy, Coherence, Clarity,Breadth and Depth and Reading Experience. Detailed description for these evaluation metric can be found in [8] or in our reference implementation[9]."
        },
        {
            "title": "3.1 Inspection of LongWriter-6K Dataset\nDespite efforts to make LongWriter-6K dataset suitable for training\nmodel to output long-form text, upon careful review, we have found\nthat there is still room for improvement in LongWriter-6K. In\nparticular, we identify that substantial amount of sub-optimal data\nsamples exist in the dataset that may not align well with the task.\nBy inspecting the correlation between data characteristics and the\nevaluation methodologies outlined in Section 2, we conclude that, to\nalign data better with the task of tuning a model to output lengthy",
            "content": "Yingda Chen , Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang and Yuze Zhao text of given length, different categories of sub-optimal data entries shall be cleansed, including: Category 1: Data samples with input prompt that does not specify Required Length for output. 1 { 2 3 4 5 } \" messages \": [ {\" role \": \" user \" , \" content \": \" Can you please write Stakeholder Analysis and Engagement Strategy for Online Loan Tracking System software project ? n\"}, {\" role \": \" assistant \" , \" content \": \" ### Introduction to the Online Loan Tracking System Software Project ... \" }] One of such example is shown above. Such sub-optimal entry would unlikely guide the model to align with the target task, as no length requirement is specified, and there is no way for model-training to learn expected behavior from such data. Upon review of the dataset, we found significant proportion (70.9%) of data in LongWriter-6K fall into this category. Category 2: Data samples that exhibit significant discrepancy between the Required Length in prompt, and the actual Output Length. 1 {\" messages \": [{ \" role \": \" user \" , \" content \": \" Write in 50000 words romanace , fantasy , mystery , adventure , sexy and drama bl love story about vampires and werewolves place and time specified it must have some comedy scenes too and happy ending . \"}, {\" role \": \" assistant \" , \" content \": \" ### The Enigmatic Night nIn the heart of sprawling metropolis , where neon lights reflected off rain - slicked streets and the city pulsed with an electric , nocturnal energy , lived young vampire named Alex ... \" }] , \" length \": 50000 , \" response_length \": 16199} One of such example is shown above, where Required Length of 50, 000 is specified in input instruction while the output measured at only 16, 199. In addition, we found that common discrepancy between Required Length and Output Length arise when data sample contains response of desk-rejection from model. In this case, the output resembles response along the line of cannot answer this question for safety reasons, please try other questions.. One can imagine that, such entries in dataset would likely Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key confuse the model alignment, or even pollute the models capability to follow instruction. Figure 1: Two-Stage Data Refinement on LongWriter-6K"
        },
        {
            "title": "3.2 Data Refinement\nAs has been shown in earlier studies [25], quality of the alignment\ndata can be of extreme importance to model’s performance, more\nso than the quantity of the data. It is therefore imperative to further\nimprove the quality to better align with the target task.",
            "content": "In light of the two categories of data sub-optimalities, we take LongWriter-6K as the starting dataset and perform further twostep data cleansing. First we remove all data entries missing Required Length in input instruction, reducing the total 6000 data entries to 1748. Additionally we strip away data that display noticeable discrepancy between Required Length and Output Length. More specifically, we use 1 as the eliminating metric, and remove all entries with score of 𝑆𝐿 < 80. Doing so further reduce the count of data entries from 1748 to 666: only about 10% of the LongWriter-6K remain after the two-step filtration. The process is illustrated in Fig. 1, which result in new dataset LongWriter-6K-filtered, with 666 high-quality data entries that align well with the task of generating output at required length. (a) Intermediate dataset: after removing Category 1 entries. (b) LongWriter-6K-filtered: after removing Category 2 entries. Figure 2: Comparison of different datasets length-following characteristics. the actual Output Length of the data now demonstrates very good adherence to the Required Length, with an overall nearlinear alignment between the lengths of the data samples. The resulting LongWriter-6K-filtered dataset containing 666 entries, which is made publicly available [13], and the data processing implementation is also made open-sourced[9]."
        },
        {
            "title": "4 TUNING WITH CURATED DATA\nIt is now recognized that given a well-trained foundation model,\nthe quality of SFT data is pivotal in determining the performance\nand capacity of the models after alignment[25]. In this section, we\nexplore the task of tuning a model to generate long output. While\nour work is built upon, and has taken inspirations from [8], our\napproach is fundamentally different in several aspects:",
            "content": "First of all, we believe that for the task of generating long text following instructed length, it may not be necessary to build from un-aligned base model and train with the entire SFT phase. Instead, with proper tuning techniques, starting off from human-aligned instruct or chat version is plausible approach. Therefore, unlike the approach in [8], we have chosen to tune instructed and chat models instead. After all, the capability of writing long output is more complementary to, than being in conflict with, the human-aligned capability of model. Secondly, as detailed in Sec. 3.2, we perform thorough data cleansing, and after the two-stage distillation, the curated LongWriter-6k-filtered dataset represents collection of data that aligns well with the target task, which we believe to be pivotal in shaping the behavior of fine-tuned models. The different approaches we adopt resulted in large amount of saving in tuning cost, which we discuss in this Section."
        },
        {
            "title": "4.2 Datasets for Model Tuning\nThe datasets used in different experiments are listed below:",
            "content": "LongWriter-6k: 6000 data entries LongWriter-6k-filtered: 666 data entries MagPie-Qwen2-Pro-200K-English[20]: 200, 000 data entries MagPie-Qwen2-Pro-200K-Chinese[19]: 200, 000 data entries Fig. 2 depicts data characteristics after applying the filtration of Category 1 and 2 data. As we can see, after two rounds of filtering, Among this list, LongWriter-6k and LongWriter-6k-filtered are the task datasets designed for our task of tuning model for to Yingda Chen , Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang and Yuze Zhao Qwen2-7B-Instruct Setup 1 Setup 2 Setup Setup 4 Training data and epoch setup LongWriter-6k with 1:1 mixing ratio of alignment data(6k), trained for 2 epochs LongWriter-6k with 1:30 mixing ratio of alignment data(180k), trained for 1 epoch LongWriter-6k-filtered only, trained for 4 epochs LongWriter-6k-filtered with 1:20 mixing ratio of alignment data(13k), trained for 2 epochs (avg) 67.4 𝑆𝐿 48.92 𝑆𝑄 85.87 Improvement 66.38 52.76 80.00 -1.02 pt 72.02 64. 79.44 +4.62 pt 76.62 70.44 82.8 +9.22 pt 79.51 75.61 83.4 +12.1 pt Table 1: Tuning Qwen2-7B-Instruct with various setups for long-writing task. output long text, while dataset MagPie-Qwen2-Pro-200K-English and MagPie-Qwen2-Pro-200K-Chinese are alignment data synthesized using MagPie[21]1. The alignment dataset is introduced to avoid potential degradation in models generalization ability and catastrophic forgetting[12] with rehearsal methods. In particular, alignment data is sampled at different rates which result in various mixing ratios with task-data in tuning experiments, which we explain in detail later in Section 4.4. It is important to note that, for all our experiments, the alignment dataset was only meant to serve as guided data to avoid loss of general capabilities during tuning. Since we have started from human-aligned versions of models, only small fraction(3% at the maximum) is sampled from the alignment dataset and used during turning."
        },
        {
            "title": "4.3 Experiment Setup\nAll models are tuned on a single node with 4xA100 80G GPUs.\nWe use ModelScope Swift(MS-Swift)[24] for all model tuning, an\nopen-sourced training framework that adapts to various tuning\ntechniques via standardized interfaces. Some of the example tuning\nscripts are included in Appendix A.1.",
            "content": "To mitigate the reduction in the contribution of target tokens to the overall loss for longer output sequences, which can result in sub-optimal model performance on tasks requiring extended outputs, token-averaged loss weighting strategy is employed. With this approach, the loss is calculated as the mean of individual losses associated with each target token within given batch. We implement this particular loss as loss-ce(cross-entropy) in the open-sourced turning framework MS-Swift[24]. During model evaluation, repetition_penalty of 1.1, and temperature of 0.5 is used for inference. We follow the evaluation mythologies outlined in Section 2. In particular, the evaluation procedures and associated metrics are implemented based on EvalScope[17]. We include exampled evaluation implementation in Appendix A.2."
        },
        {
            "title": "4.4 Experiment Results\nWe begin by tuning Qwen2-7B-Instruct, by adopting various com-\nbinations of the task and alignment datasets. The performance for\ndifferent tuned models are listed in Table 1. From the observation\nabove, it is evident that tuning with high quality data is crucial for",
            "content": "1It should be noted that we rely on these two open dataset synthesized with Qwen2-72B-Instruct using MagPie, which may be sub-optimal for non-Qwen2 models. model to achieve superior performance in long-form writing tasks. Most notably: Tuning with the unfiltered LongWriter-6k dataset from Qwen2-7B-Instruct does not result in significant performance improvement. In particular, while long-output lengthfollowing capability improves, noticeable regression in writing quality is introduced. This may be attributed to data sub-optimality analyzed in Section 3.1. Tuning with 2,664 high-quality data instances (trained with 666-sample LongWriter-6k-filtered dataset for 4 epochs) resulted in in model significantly outperforming the model trained on mixture of LongWriter-6k and 180,000 alignment data samples, in terms of both length-following (𝑆𝐿) and writing quality 𝑆𝑄 . Proper mixing of task data and alignment data helps not only sustaining the writing quality 𝑆𝑄 , by also help improve the length-following capability 𝑆𝐿. For example, extending Setup 4 with alignment data sampled from [19, 20] at 1 : 20 mixing ratio (13320 data samples coming equally from [19] and [20]) achieve the best performance among all Setups, with 2 epochs of tuning. We have made the model checkpoints achieved from Setup 4 public available at name it MS-LongWriter-Qwen2-7B-Instruct [2]. This result also validates the generalizbility of tuning models for longwriting tasks, which is not limited to the GLM series of models studied in [8]. Fig. 3 shows the length-following capability of the tuned model MS-LongWriter-Qwen2-7B-Instruct (from Setup 4 in Table 1) and the original Qwen2-7B-Instruct model. It can be observed that, the tuned model exhibits better adherence to prompt requirements on text output length. In particular, the model aligns much better to the length-instruction when the required text length is longer. For fair comparison between our approach summarized in Setup 4, and the original LongWriter model training[8], Table 2 shows how the performance of the tuned compares. In particular, with Setup 4, we depart from the chat version of GLM4 model, GLM4-9b-Chat, and tuned the model with 666 task data entries from LongWriter-6k-filtered and 13, 320 alignment data entries sampled from [19, 20]. Upon 2 epochs of tuning, the training data instances amount to total of 27, 972. The resulting model achieve similar performance comparing to LongWriter-GLM4-9B, which was trained from GLM-4-9B with 6, 000 data samples from Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key GLM4-9b-Chat LongWriter-GLM4-9B[7, 8] Setup 4 Training data and epoch setup Trained from GLM-4-9B[11] with LongWrite-6k plus 1:30 mixing ratio using entire GLM chat SFT dataset (180k), trained for 4 epochs LongWriter-6k-filtered with 1:20 mixing ratio of alignment data (13k), trained for 2 epochs (avg) 67.8 𝑆𝐿 52.8 𝑆𝑄 82.78 Improvement 80.5 78. 82.3 +12.7 pt 79.88 77.42 82.33 +12.08 pt Table 2: Tuning GLM4-9b-Chat with various setups for long-writing task. Qwen2.5-7B-Instruct Setup 4 Setup 5 Training data and epoch setup LongWriter-6k-filtered with 1:20 mixing ratio of alignment data (13k), trained for 2 epochs Based on Setup 4, introduce additional annealing with learning rate of 2𝑒 6 using LongWriter-6k-filtered for another 2 epochs (avg) 75. 𝑆𝐿 66.4 𝑆𝑄 85.17 Improvement 79.88 77.42 82. +4.75 pt 82.84 81.24 84.44 +7.05 pt Table 3: Tuning Qwen2.5-7B-Instruct with various setups for long-writing task. This coincide with our approach to tune long-writing capability based on human-aligned version of model, which is guided by the intuition that, the capability of writing long output is more complementary to, rather than being in conflict with, the human-aligned capability of model. Still, our tuning recipes demonstrates notable performance improvement (for both Setup 4 and 5) against the stronger baseline of Qwen2.5-7B-Instruct. Specifically, on top of Setup 4 , we introduce an additional annealing phase with continuous-tuning in Setup 5. This results in model that exhibits strongest performance in both 𝑆𝐿 and 𝑆𝑄 , we name this model MS-LongWriter-Qwen2.5-7B-Instruct and made it publicly available at [3]."
        },
        {
            "title": "5 CONCLUSION\nIn this work, we explore efficient tuning of large language models\n(LLMs) to generate extended outputs that align with length-based in-\nstructions. Our findings highlight that high-quality datasets, specifi-\ncally curated to match both length and coherence requirements, are\nessential for effective tuning. Notably, we demonstrate that signifi-\ncant performance gains can be achieved with minimal tuning effort,\nwith high-quality dataset constitute of as few as 666 data samples.\nWe also demonstrate that similar performance improvement can be\nachieved with our approach using much less training data instances,\ncomparing to the alignment-based approach. In this regard, our\nresults suggests that starting from a well-trained, human-aligned\nmodel serves as an efficient foundation for unlocking long-form\noutput capabilities. It is also worth investigating leveraging human-\naligned models in tuning models targeting a broader range of other\ntasks.",
            "content": "REFERENCES [1] MS-LongWriter-GLM4-9B-Chat Model. https://www.modelscope.com/models/ swift/MS-LongWriter-GLM4-9B-Chat, 2024. [2] MS-LongWriter-Qwen2-7B-instruct Model. https://www.modelscope.com/ models/swift/MS-LongWriter-Qwen2-7B-Instruct, 2024. [3] MS-LongWriter-Qwen2.5-7B-instruct Model. https://www.modelscope.com/ models/swift/MS-LongWriter-Qwen2.5-7B-instruct, 2024. [4] Anthropic. Anthropic: Introducing Claude 3.5 Sonnet. https://www.anthropic. com/news/claude-3-5-sonnet, 2024. (a) Qwen2-7B-Instruct Characteristics for (b) MS-LongWriter-Qwen2-7B-Instruct Characteristics for Figure 3: Improvement on length-following characteristics on Qwen2-7B-Instruct. LongWrite-6k, and 180, 000 alignment data, for 4 epochs, which amounts to total of 744, 000 training data instances. In other words, similar performance is achieved here with mere of 3.74% of training instances, or in other words, about 3.74% of compute cost for training. Clearly, the approach to train from base model will necessitate larger amount of alignment dataset. However, with the result shown in Table 2, we would like to argue that, for the specific task of long-form writing, much cost-efficient tuning approach is possible by leveraging higher-quality tuning data, and by starting from human-aligned version of model. The tuned model from Setup 4 of Table 2 is named MS-LongWriter-GLM4-9B-Chat and made publicly available at [1]. Finally, we complete our experiments by applying our approach to the latest addition to the high-performing language model, the Qwen 2.5 family[18]. In particular, Table 3 shows the result of applying our tuning recipes to Qwen2.5-7B-Instruct. Out of the box, Qwen2.5-7B-Instruct emerges as strong competitor in all performance metrics under evaluation. This points to the perspective that, the evolution of general-purposed Instruct (or Chat) models can naturally lead to stronger capability in generating longer text. Yingda Chen , Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang and Yuze Zhao [5] Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. Longwriter-6k dataset. https://www.modelscope.com/ datasets/ZhipuAI/LongWriter-6k, 2024. [6] Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. Longwriter-6k dataset. https://huggingface.co/datasets/ THUDM/LongWriter-6k, 2024. [7] Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. LongWriter-glm4-9b. https://huggingface.co/THUDM/ LongWriter-glm4-9b, 2024. [8] Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. Longwriter: Unleashing 10,000+ word generation from long context llms, 2024. [9] EvalScope. open source implementation for longbench-write benchmark. https://github.com/modelscope/evalscope/tree/main/evalscope/third_ party/longbench_write, 2024. [10] Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, et al. Chatglm: family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793, 2024. [11] GLM Team. GLM-4-9B. https://huggingface.co/THUDM/glm-4-9b, 2024. [12] Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, and Jinsong Su. Mitigating catastrophic forgetting in large language models with self-synthesized rehearsal. arXiv preprint arXiv:2403.01244, 2024. [13] ModelScope. Longwriter-6k-filtered dataset. https://www.modelscope.com/ datasets/swift/longwriter-6k-filtered, 2024. [14] Chau Minh Pham, Simeng Sun, and Mohit Iyyer. Suri: Multi-constraint instruction following for long-form text generation, 2024. [15] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024. [16] ModelScope Team. Ms-swift documentatoin. https://swift.readthedocs.io/. [17] ModelScope Team. EvalScope Evaluation Framework. https://github.com/ modelscope/evalscope/, 2024. [18] Qwen Team. Qwen2.5: party of foundation models! https://qwenlm.github.io/ blog/qwen2.5/, 2024. [19] Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. Magpie 200k synthesis-data generated by qwen/qwen2-72b-instruct - chinese. https://huggingface.co/datasets/MagpieAlign/Magpie-Qwen2-Pro-200K-Chinese, 2024. [20] Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. Magpie 200k synthesis-data generated by qwen/qwen2-72b-instruct - english. https://huggingface.co/datasets/MagpieAlign/Magpie-Qwen2-Pro-200K-English, 2024. [21] Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. Magpie: Alignment data synthesis from scratch by prompting aligned llms with nothing. arXiv preprint arXiv:2406.08464, 2024. [22] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. Qwen2 technical report. arXiv preprint arXiv:2407.10671, 2024. [23] Weizhe Yuan, Ilia Kulikov, Ping Yu, Kyunghyun Cho, Sainbayar Sukhbaatar, Jason Weston, and Jing Xu. Following length constraints in instructions, 2024. [24] Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, and Yingda Chen. Swift:a scalable lightweight infrastructure for fine-tuning, 2024. [25] Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. Advances in Neural Information Processing Systems, 36, 2024. Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key APPENDIX A.1 Training Scripts A.1.1 Tuning with MS-Swift. Example MS-Swift script for model tuning. Qwen2-7B-Instruct model, and 1 : 10 : 10 mixing of the entire LongWriter-6K-filtered dataset (666 data entries), 6660 random data samples from [19] and 6660 random data samples from [20]. Refer to documentation of MS-Swift[16] for detailed explanation of script parameters. 1 swift sft 2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 -- model_type qwen2 -7b - instruct -- dataset longwriter -6k - filtered qwen2 - pro - zh # 6660 qwen2 - pro - en #6660 -- max_length 28672 -- num_train_epochs 2 -- eval_steps 200 -- batch_size 1 -- gradient_accumulation_steps 64 -- gradient_checkpointing true -- warmup_ratio 0.1 -- learning_rate 1e -5 -- sft_type full -- loss_name long - ce -- check_dataset_strategy warning -- save_only_model false -- save_total_limit -1 -- lazy_tokenize true -- dataloader_num_workers 1 -- resume_only_model true -- neftune_noise_alpha 5 -- use_flash_attn true Continue from checkpoint out of Setup 4, with additional annealing using new learning rate 2𝑒 6) for additional 2 epochs of LongWriter-6k-filtered dataset. 1 swift sft 2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 -- model_type qwen2_5 -7b - instruct -- dataset longwriter -6k - filtered -- max_length 28672 -- num_train_epochs 2 -- eval_steps 200 -- batch_size 1 -- gradient_accumulation_steps 64 -- gradient_checkpointing true -- warmup_ratio 0.1 -- learning_rate 2e -6 -- sft_type full -- loss_name long - ce -- check_dataset_strategy warning -- save_only_model false -- save_total_limit -1 -- lazy_tokenize true -- dataloader_num_workers 1 -- resume_only_model true -- neftune_noise_alpha 5 -- use_flash_attn true -- resume_from_checkpoint { previous - checkpoint - path } > { output - checkpoint - path } A.2 Evaluation Script Yingda Chen , Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang and Yuze Zhao 1 2 # Task Configuration 3 # `infer `-- Inference ; `eval_l `-- S_L score evaluation ; `eval_q `: S_Q score evaulation 4 task_cfg = dict ( stage =[ ' infer ', ' eval_l ' , ' eval_q '], 5 6 7 8 9 11 12 13 14 15 17 18 19 20 model = ' ZhipuAI / LongWriter - glm4 -9 ' , input_data_path = None , output_dir = ' ./ outputs ' , openai_api_key = None , openai_gpt_model = 'gpt -4o -2024 -05 -13 ' , infer_generation_kwargs ={ ' max_new_tokens ': 32768 , ' temperature ': 0. }, eval_generation_kwargs ={ ' max_new_tokens ': 1024 , ' temperature ': 0.5 , ' stop ': None }, proc_num =8) 21 # execute evaluation task 22 from evalscope . third_party . longbench_write import run_task 23 run_task ( task_cfg = task_cfg )"
        }
    ],
    "affiliations": [
        "ModelScope Team, Alibaba Group"
    ]
}