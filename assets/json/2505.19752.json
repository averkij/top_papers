{
    "paper_title": "Discrete Markov Bridge",
    "authors": [
        "Hengli Li",
        "Yuxuan Wang",
        "Song-Chun Zhu",
        "Ying Nian Wu",
        "Zilong Zheng"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Discrete diffusion has recently emerged as a promising paradigm in discrete data modeling. However, existing methods typically rely on a fixed rate transition matrix during training, which not only limits the expressiveness of latent representations, a fundamental strength of variational methods, but also constrains the overall design space. To address these limitations, we propose Discrete Markov Bridge, a novel framework specifically designed for discrete representation learning. Our approach is built upon two key components: Matrix Learning and Score Learning. We conduct a rigorous theoretical analysis, establishing formal performance guarantees for Matrix Learning and proving the convergence of the overall framework. Furthermore, we analyze the space complexity of our method, addressing practical constraints identified in prior studies. Extensive empirical evaluations validate the effectiveness of the proposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO) of 1.38 on the Text8 dataset, outperforming established baselines. Moreover, the proposed model demonstrates competitive performance on the CIFAR-10 dataset, achieving results comparable to those obtained by image-specific generation approaches."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 2 ] . [ 1 2 5 7 9 1 . 5 0 5 2 : r a"
        },
        {
            "title": "Discrete Markov Bridge",
            "content": "Hengli Li1,2,3 lihengli@stu.pku.edu.cn Yuxuan Wang2,3 wangyuxuan1@bigai.ai Song-Chun Zhu1,2,3,4 s.c.zhu@pku.edu.cn Ying Nian Wu5(cid:0) ywu@stat.ucla.edu Zilong Zheng2,3(cid:0) zlzheng@bigai.ai 1 Institute of Artificial Intelligence, Peking University 2 NLCo Lab, Beijing Institute for General Artificial Intelligence 3 State Key Laboratory of General Artificial Intelligence 4 Department of Automation, Tsinghua University 5 University of California, Los Angeles"
        },
        {
            "title": "Abstract",
            "content": "Discrete diffusion has recently emerged as promising paradigm in discrete data modeling. However, existing methods typically rely on fixed-rate transition matrix during training, which not only limits the expressiveness of latent representationsa fundamental strength of variational methodsbut also constrains the overall design space. To address these limitations, we propose Discrete Markov Bridge, novel framework specifically designed for discrete representation learning. Our approach is built upon two key components: Matrix-learning and Score-learning. We conduct rigorous theoretical analysis, establishing formal performance guarantees for Matrix-learning and proving the convergence of the overall framework. Furthermore, we analyze the space complexity of our method, addressing practical constraints identified in prior studies. Extensive empirical evaluations validate the effectiveness of the proposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO) of 1.38 on the Text8 dataset, outperforming established baselines. Moreover, the proposed model demonstrates competitive performance on the CIFAR-10 dataset, achieving results comparable to those obtained by image-specific generation approaches."
        },
        {
            "title": "Introduction",
            "content": "A fundamental question in generative modeling is estimating an underlying distribution, µ, from observed data and subsequently generating new samples from this distribution. Among the various generative models proposed, diffusion models have exhibited remarkable performance in both continuous [1, 2] and discrete domains [3, 4], demonstrating their versatility and effectiveness in diverse applications. These models effectively capture complex data distributions, enabling highquality sample generation in various applications. However, despite their strong connection to variational models [5, 6], which are known for their impressive generative capabilities, diffusion models have yet to integrate the latent encoding ability inherent to variational approaches. Specifically, in the discrete domain, the noise rate transition matrices within discrete diffusion models are fixed and constrained, resulting in limited design space and reduced expressive capacity. To the best of our knowledge, only the Absorb and Uniform Matrix [3, 4, 7] have been considered in computations due to their simplicity in handling exponential term calculations. 1Implementation code is available at https://github.com/Henry839/Discrete-Markov-Bridge. Preprint. Under review. Figure 1: Overview of the DMB framework. DMB consists of two component: the Matrix-learning and the Score-learning. The Matrix-learning process is designed to learn an adaptive transition rate matrix, which facilitates the estimation of an adapted latent distribution. Concurrently, the score-learning process focuses on estimating the probability ratio necessary for constructing the inverse transition rate matrix, thereby enabling the reconstruction of the original data distribution. In this study, we challenge the convention of using predefined static matrix in discrete modeling by introducing novel approach, termed the Discrete Markov Bridge (DMB), which aims to integrate the strengths of variational methods with discrete diffusion models, offering more robust and efficient solution for complex discrete-state systems. This methodology seeks to enhance the modeling capabilities by leveraging the theoretical foundations of variational inference within the framework of discrete diffusion processes. Specifically, DMB is structured as bidirectional twostage learning algorithm. It comprises forward variational process, i.e., Matrix-learning, that maps the data distribution to learned distribution, followed by backward decoding process, i.e., Score-learning, that reconstructs the data distribution from the learned representation. In the Matrix-learning process, we propose novel parameterized rate transition matrix that enhances the flexibility of the overall algorithm. This refinement allows for greater adaptability and improved performance in dynamic learning environments. The rate transition matrix is designed to be diagonalizable, ensuring high spatial efficiency while facilitating the rapid computation of matrix exponentials. On the other hand, in the Score-learning process, neural network is employed to model the concrete score [4, 8]. This score serves crucial role in the derivation of the backward rate transition matrix. As for the sampling procedure, the rate transition matrix derived from the Matrix-learning process and the neural network obtained from the Score-learning process are jointly employed to solve the backward differential equation. Within this framework, broad spectrum of tasks can be effectively addressed. For discrete data modalities such as text, the model supports non-autoregressive generation, following the approach outlined in [9]. In this work, we demonstrate that our proposed method surpasses the performance of the previously established SEDD model [4]. For image data, the model can be integrated with VQ-VAE architecture [6], yielding performance on par with that of DDPM when evaluated on the CIFAR-10 dataset. We summarize our contributions as follows: Novel Framework for Discrete Data (Section 3): We introduce the Discrete Markov Bridge, new variational framework for learning discrete representations. By leveraging variational formulation, this approach provides novel method for modeling complex discrete data. Theoretical Guarantee (Section 4): We present theoretical guarantee for the Matrix-learning process, covering both its validity and accessibility. Furthermore, we provide comprehensive analysis of the entire framework, culminating in formal convergence proof. Addressing Practical Issues (Section 5): Building on the theoretical insights established earlier, we propose computationally efficient matrix to tackle the practical challenges discussed in Section 5. We then evaluate the models performance through experiments, demonstrating that it outperforms baseline methods in text modeling and provides competitive image modeling results."
        },
        {
            "title": "2 Preliminaries and Related Works",
            "content": "2.1 Continuous-Time Discrete Markov Chain Let = {1, 2, . . . , n} denote finite state space, where R. continuous time discrete Markov chain (CTDMC) defined on is represented as {X(t) R, X(t) X}. For convenience, we use the notation Xt X(t). The probability of transitioning from state at time to state at time + is denoted as pt+st(yx) (Xt+s = Xt = x). Similarly, the probability that Xt takes state at time is expressed as pt(x) (Xt = x). The probability distribution over the state space at time is then given by the vector pt (pt(1), pt(2), . . . , pt(n)). The core component to describe continuous time discrete Markov chain is the rate transition matrix. We defined the rate transition probability as follows: qt(x, y) dpt+st(yx) ds = lim s0 pt+st(yx) ptt(yx) = lim s0 pt+st(yx) δx(y) , where δx(y) is the Dirac delta function. The Forward Kolmogorov Equation can be written as dt = ptQ(t). The notation Q(t) dpt x,y qt(x, y), for all x, X, denotes the rate transition matrix at time t. The subscripts and indicate the row and column indices, respectively. Each rate transition matrix satisfies the conditions: the sum of each row must be zero, and all off-diagonal entries must be non-negative. Formally, this is expressed as (cid:80) Qx,y = 0 for all and Qx,y 0 for all = x. 2.2 Related Works Prior Learning Leveraging prior is longstanding paradigm in machine learning. In the field of natural language processing, for example, training typically begins with pretrained language models [1016]. Likewise, pretrained models are highly valued in computer vision [17]. In our approach, the concept of prior is equally fundamental: the forward process adaptively refines this prior based on the evolving training dynamics of the backward process. Discrete Diffusion Models Diffusion models [2, 1, 18, 19] add noise to data and use denoiser for reconstruction, achieving success in image tasks and gaining traction in discrete domains like natural language [20, 4, 3, 2124]. Some methods map discrete data to continuous space [20, 21], introducing rounding errors, while others operate directly in discrete space but impose rigid, non-learnable noise structures [3, 4]. In the continuous domain, trainable Gaussian parameters improve flexibility [25], but no such method exists for discrete diffusion, where Gaussian distributions also remain restrictive. Moreover, masked discrete diffusion models struggle to learn temporal dependencies [26]. Flow Models Flow-based models [2732] constitute prominent class of machine learning models characterized by their ability to perform reversible transformations on data representations. In contrast to conventional flow models, which rely on transformation paths predefined by human designers [31, 29], our approach autonomously learns these paths, enhancing adaptability and expressiveness in data modeling."
        },
        {
            "title": "3 Discrete Markov Bridge",
            "content": "The target distribution, denoted as µ Rn, is probability vector, meaning that its elements are non-negative and collectively sum to one. As shown in Figure 1, our objective is to estimate the distribution at one endpoint of the Markov chain, denoted as p0, such that p0 µ. The other endpoint, denoted as pT , serves as the distribution for the latent variables or prior. To achieve the specified objectives, the proposed DMB framework is structured into two distinct components: Matrix Learning and Score Learning. The Matrix-learning serves as forward bridge, facilitating the transition from µ to the latent distribution. Conversely, the Score-learning function delineates reverse pathway from the latent distribution back to µ, leveraging the groundwork established by the Matrix-learning process. This dual-function framework ensures comprehensive bidirectional understanding of the data structure, enhancing the robustness of the analytical model. 3 The structure of the DMB is demonstrated in Algorithm 2. This pseudocode illustrates two nested while loops that operate within the overarching while loop governing the training epochs. Each of these nested loops corresponds to distinct learning stage within the framework, effectively organizing the training process into two phases. We list the following theorem to ensure the reversibility of the forward and backward Markovian processes. Theorem 3.1 (Reversibility [3, 4]). Given the Forward Kolmogorov Equation of CTDMC: dpt dt = ptQ(t) There exists reverse CTDMC with Forward Kolmogorov Equation: dpT dt = pT ˆQ(T t) ,where ˆQ(t) x,y = pt(y) pt(x) Q(t) y,x (1) (2) This theorem elucidates the reverse form of CTDMC, proposing that knowledge of the probability ratio enables the derivation of reversal of the original Markov chain that is almost everywhere equivalent. This assertion underscores the theoretical framework necessary to comprehend the conditions under which the reverse process mirrors the dynamics of the forward stochastic process. We structure the learning process of the framework by employing the continuous-time Evidence Lower Bound (ELBO) as an alternative optimization objective to Maximum Likelihood Estimation (MLE). In the DMB framework, both Matrix-learning and Score-learning collaboratively optimize distinct segments of the full bound through their respective subprocesses. 3.1 Matrix-Learning In the Matrix-learning process, our primary objective is to estimate the rate transition matrix Qα, where α denotes the set of model parameters. For simplicity, we assume that the forward rate transition matrix at time t, denoted Q(t) α , is given by σ(t)Qα. Furthermore, we employ the following Qα: Qα = n1 (cid:80) i= ai 0 . . . 0 0 a1 n1 (cid:80) i=2 . . . 0 . . . an2 an1 ai . . . an an1 . . . . . . . . . . . . an1 an1 0 . . . 0 A1 := AHA (3) , where {a1, a2, . . . , an1} = α are parameters for learning, A, A1 are fixed predefined permutation matrices and is introduced to stand for the upper-triangle matrix. The derivation and underlying rationale for utilizing this matrix are detailed in Section 4 and further explored in Section 5.1. Another essential component of this process is µ, which is approximated using the currently predicted p0 obtained through Score-learning as prior (see Section 3.2). By integrating Equation (1) from time 0 to time t, the following equation can be derived: (cid:90) pt = p0 exp{ 0 σ(s)dsQα} (4) Note that the exponential in the formula is matrix exponential. The training procedure aims to minimize portion of the variational bound, leading to the following objective function JQ: where the conditional probability distribution pT 0;α is given by the rows of exp{(cid:82) 0 σ(s)dsQα}: JQ Eµ[DKL(pT 0;αpT ;α)], (5) pT 0;α(xT x0) = exp{ (cid:90) 0 σ(s)dsQα}x0,xT (6) The final distribution pT ;α is obtained by multiplying the initial distribution p0 with the conditional distribution, as presented in Equation (4), evaluated at time = . 4 Algorithm 2 Training Algorithm of the DMB Input: Target discrete data µ 1: Initialize p0, pT random_init() 2: while not converge do 3: Sample batch of discrete instance X0 µ. /* Data for the two learning processes. */ /* Matrix Learning */ step 0 while step max_step & LQ ϵQ do Update Qα, JQ according to Eqn. (5) and predict pT using Eqn. (4) at = . step step + 1 end while /* Score Learning */ step 0 while step max_step & Jscore ϵscore do Update sθ, Jscore w.r.t. current Qα using Eqn. (8). step step + end while Predict updated p0 that estimates µ using Eqn. (10). /* Used for Matrix Learning */ if JQ + Jscore < ϵ then converge TRUE 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: end while end if 3.2 Score-learning Score-learning constitutes reverse process of Matrix-learning. It is noted that in Theorem 3.1, the reverse rate transition matrix adheres to the following relationship: ˆQ(t) pt(y) pt(x) Consequently, while Matrix-learning handles the forward rate transition matrix Q, Score-learning focuses on managing the remaining part, i.e pt(y) pt(x) . learnable model sθ(xt, t)y is designed to model the ratio, and the main part of the continuous time Evidence Lower Bound (ELBO) [35] is leveraged as the training objective, denoted as Jscore: Qx,yσ(t) x,y = (7) (cid:82) Ex0µ,xtpt0 (cid:2) (cid:80) y=xt Q(t) y,xt (cid:32) sθ(xt, t)y pt0(yx0) pt0(xtx0) + pt0(yx0) pt0(xtx0) (cid:0)log( pt0(yx0) pt0(xtx0) ) log sθ(xt, t)y (cid:1) (cid:33) (cid:3)dt (8) To provide comprehensive understanding, we present the complete ELBO as follows, demonstrating how Matrix-learning and Score-learning collaboratively contribute to minimizing the ELBO bound. Ex0µ[ log p0;θ(x0)] Jscore + JQ. (9) Estimating µ The estimation of µ is expressed as Equation (10). The equation below is derived under the Euler method and can be generalized to other ODE-solving methods. Suppose the inference time process is partitioned as: [0, t1], [t1, t2], . . . , [tn, ]. By Bayesian rules: µ(x0) p0(x0) = EXT ,Xn,...X1 [p01(x0x1)]. (10) Under the guidance of Equation (10), the sampling process begins with drawing xT , followed by obtaining xn through the conditional distribution ptnT (xnXT = xT ). This procedure continues iteratively, generating xn1, and proceeding sequentially until the complete sequence {XT , Xn, . . . , X1} is sampled. Subsequently, the conditional probability p01(x0x1) is determined. By repeating this process multiple times and averaging the sampled probabilities, an estimation can be obtained by approximating the expectation with the empirical mean. 3.3 Sampling The sampling process is done under the cooperation of Matrix-learning and Score-learning in similar way as estimating µ. The reverse rate transition matrix is calculated as Equation (7), and an 5 ode-solving method such as the Euler method can be further applied to solve Equation (2). Noticed that, as shown in line 15 of Algorithm 2, the sampling process is performed every time after the Score-learning process to gain the estimation of µ and samples for evaluation."
        },
        {
            "title": "4 Theoretical Foundations",
            "content": "4.1 Validity and Accessibility of Matrix-learning The validity and accessibility of the backward process are established by Theorem 3.1. In this subsection, we extend our analysis to the same aspects of the Matrix-learning process. Specifically, validity concerns the ultimate state of the forward process and whether it remains confined within well-defined domain, i.e., whether probability distribution transforms into another valid probability distribution. Accessibility, on the other hand, pertains to the ability of the process to transition between any two arbitrary discrete distributions, thereby characterizing the reachability and adaptability of the Matrix-learning process. Validity Proposition 4.1, presented below, establishes that any transformation originating from probability distribution must result in another probability distribution. This theorem guarantees that, despite the presence of errors in the learning process, the outcome remains valid probability distribution. For detailed proof, refer to Section A. Proposition 4.1 (Conservation of the Sum). For two arbitrary vectors ϕ, µ Rn, rate transition matrix Rnn, if ϕ = µ exp{Q}, then (cid:88) i=1 ϕ[i] = (cid:88) i=1 µ[i] Accessibility Theorem 4.2 ensures that any two probability distributions are accessible in the forward process. Consequently, this implies that the optimality of Matrix-learning can be achieved, provided the presence of strong optimizer. Theorem 4.2 (Accessibility). For two arbitrary discrete distributions p, Rn, there exists rate transition matrix Rnn such that: = qeQ (11) The central idea of the proof is to construct specialized matrix that possesses strong representational capacity while remaining computationally manageable within the framework of matrix exponentiation. The designed matrix, which is depicted in Lemma 4.3, is an upper triangle matrix with the vanished sum of rows. remarkable characteristic of this matrix is its elegant eigendecomposition form, which presents well-structured and analytically convenient representation. Its eigenmatrix is an all-one upper triangular matrix, as shown in Lemma 4.3. Lemma 4.3. Let matrix Rnn and hold the following form: = , where is defined in Equation (3), then can be diagonalized in the following form: = ΛU 1 , Λ = diag({ n1 (cid:80) i=1 ai, n1 (cid:80) i=2 ai, . . . , an1, 0}). 1 1 . . . 0 . . . . . . . . . . . . 1 1 . . . 1 1 0 . . . 0 ,where = There are two key observations regarding the matrix. First, it contains only 1 parameters, which constitute the minimal set necessary to solve Equation (11). This sufficiency implies that the solution derived for the matrix is unique. Second, the matrix retains nonzero elements exclusively in its upper triangular portion, implying that each element can transition only to those with larger index. This observation raises an additional consideration: for effective state transitions, the matrix must allocate sufficient mass\" or probability. Consequently, matrix is required to appropriately adjust the indices of elements within the finite set X, as shown in Lemma 4.4. Lemma 4.4 establishes 6 that, after permutation, the cumulative probability at each element of the initial distribution in the transition process is greater than or equal to that of the target distribution. This guarantees that elements with surplus probability can redistribute their excess, while those with deficiency can receive the necessary adjustments, ensuring balanced transformation. Lemma 4.4. For arbitrary distribution p, Rn, there exists an permutation matrix such that: 1 1 1 + 2 1 + q 2 . . . (cid:80) i=1 (cid:80) i=1 q . . . (cid:80) i=1 (cid:80) i=1 is the i-th entry of q. = 1 (12) where = pA, = qA, Lemma 4.5. Let Rnn be rate transition matrix, Rnn be permutation matrix, then AQA1 is rate transition matrix. is the i-th entry of p, and By integrating the lemmas above, we aim to establish the proof of Theorem 4.2. comprehensive derivation of these lemmas and the theorem is provided in Section B."
        },
        {
            "title": "4.2 Convergence",
            "content": "As discussed earlier, the DMB framework operates as two-step learning algorithm, necessitating thorough examination of its convergence properties. In this section, we present formal theorem that establishes the convergence guarantee for the entire algorithm. The convergence problem is nontrivial, as the Score-learning process does not merely constitute direct inversion of the Matrix-learning process. The discrepancy arises because the score model sθ is trained under the supervision of the distribution µ, rather than p(k) Proposition 4.6 (Supervision of Score-learning). Suppose Qts elements are non-zeros, the training objective is depicted as in Equation (8), then the optimality of the score model sθ (xt, t)y satisfies: 0 , where denotes the epoch number. To be specific, we have sθ (xt, t)y = Ex0µ0t(xt)[ pt0(yx0) pt0(xtx0) ] = (cid:80) x0 (cid:80) µ(x0)pt0(yx0) µ(x0)pt0(xtx0) The proposition presented above illustrates the influence of µ on the training process and underscores the challenge of convergence arising from the absence of p(k) 0 . detailed proof of this proposition can be found in Section C. Under the assumption that each process achieves optimality, the following theorem establishes the convergence of DMB from the perspective of KL divergence, thereby demonstrating the validity of the overall DMB framework. Moreover, given our primary focus on the algorithmic aspects, this assumption is justified, consistent with prior work that introduces new frameworks, such as Goodfellow et al. [33]. Notably, although the training objective of the Score-learning process is the continuous ELBO bound, the theorem presented below can be generalized to encompass broader class of objectives. This generalization suggests the potential for designing improved training objectives within our framework. Theorem 4.7 (Convergence of the algorithm). If we assume optimality is achieved in every epoch of the Matrix-learning process and the Score-learning process, and we denote the k-th epoch estimation of µ as p(k) 0 , then limk DKL(µp(k) 0 ) converges. Please refer to Section for the proof."
        },
        {
            "title": "5 Practical Issues and Experiments",
            "content": "5.1 High Dimensional Data In this section, we discuss the practical issues of DMB by assuming our data coming from high dimensional space, i.e.µ Rdn, where is the size of the finite set and is the number of dimensions. For instance, for textual data, is the size of the vocabulary and is the sequence length. 7 Assumptions. When dealing with high-dimensional data, such as textual sequences, the combinatorial explosion in the number of possible sequences imposes prohibitive constraints on both storage and computational efficiency. To address this challenge, certain assumptions are introduced [4, 3, 34]: Independent Evolution: pT 0;α(xT x0) = (cid:81)d i=1 pT 0;α(x(i) Independent Terminal: pT (xT ) = (cid:81)d i=1 p(x(i) ) The first assumption posits that, during the forward process, each dimension evolves independently. The second assumption asserts that the latent space consists of independent dimensions. x(i) 0 ) 5.2 Addressing Practical Issues Both the DMB model and discrete diffusion models [4, 3, 35] face significant challenges related to the matrix. In particular, during the Score-learning process, the computational efficiency of matrix exponential operations becomes critical constraint. Furthermore, the Matrix-learning process often requires storing the entire matrix, posing substantial concerns regarding space efficiency. These limitations have been the primary reasons restricting previous studies to utilizing only the Uniform and Absorb matrices. As Jean le Rond dAlembert once remarked, Algebra is generous; she often gives more than is asked of her. In the context of proving Theorem 4.2, we identify distinct class of matrices, as mentioned in Section 3.1 and further rigorously discussed in Lemma 4.3. This structured approach not only underscores the theoretical underpinnings but also highlights the practical implications of matrix manipulation in these models. Efficient Computation of the permutation matrix. Before proceeding with the analysis of the Qα matrix, we first outline the computation of the predefined permutation matrix A. As illustrated in the assumptions, the evolution of each dimension occurs independently. Consequently, for each dimension, the permutation matrix is computed separately. In accordance with Lemma 4.4, we assume the denominator to be constant. Therefore, the permutation matrix for the i-th dimension satisfies the following inequality: µ(X (i) 0 = j) µ(X (i) 0 + 1), 1, 2, . . . , The marginal distribution µ(X (i) 0 ) can be efficiently estimated in the form of histogram by extracting subbatch from the dataset. Subsequently, the permutation matrix is computed using fast sorting algorithm with time complexity of O(n log n). Efficient Computation of Matrix Exponential. Matrix exponential is difficult to calculate as its defined through Tylor expansion, however, property exists: Proposition 5.1. For matrix Rnn and non-degenerate matrix Rnn, we have: exp{DQD1} = exp{Q}D1 Please refer to Section for the derivation of Proposition 5.1. By Proposition 5.1, exp{Qα} = exp{(AU )Λα(AU )1} = (AU ) exp{Λα}(AU )1 (13) , where is the all-one upper triangle matrix, Λα is diagonal matrix parameterized by α. Therefore, the computation of the matrix exponential is reduced to evaluating the exponential of diagonal matrix, which is significantly more efficient. Space Efficiency. For the permutation matrices A, A1 Rdnn, total of d2n parameters are required. Apart from A, A1, the upper triangle matrix can be decomposed into non-parameterized all-one upper triangle matrix, parameterized diagonal matrix, and constant matrix. Consequently, the storage requirement is of the order O(nd) parameters. 5.3 ELBO Bound Calculation As shown in Equation (9), the computation of the full bound necessitates the evaluation of both the Jscore and the expected KullbackLeibler (KL) divergence between the evolved distribution and the target distribution, expressed as EµDKL(PT 0PT ). Under the assumptions outlined within Section 5.1, we can derive closed-form expression for computing the KL term: 8 Proposition 5.2. The KL term can be calculated as:"
        },
        {
            "title": "DKL",
            "content": "(cid:0)pT 0;α(xT x0)pT (xT )(cid:1)= (cid:88) i="
        },
        {
            "title": "DKL",
            "content": "(cid:0)pT 0;α(x(i) x(i) 0 )pT (x(i) )(cid:1) (14) Table 1: The results were tested 1000 times on the Text8 dataset. We adopt the baseline results reported in [4] for comparison. AR: Autoregressive. NAR: Non-autoregressive."
        },
        {
            "title": "Type Model",
            "content": "AR IAF/SCF [36] AR Argmax Flow [34] Discrete Flow [37] NAR SEDD Uniform [4] SEDD Absorb [4] D3PM Uniform [7] D3PM Absorb [7] Mult. Diffusion [34] MAC [38] BFN [39] DMB (Ours) BPC () 1.88 1.39 1. 1.47 1.39 1.61 1.45 1.72 1.40 1.41 1.38 Table 2: CIFAR-10 Results. We report inception score (IS), and Fréchet Inception Distance (FID) score. Results are adopted from Ho et al. [40]. Model Conditional IS () FID () EBM [41] JEM [42] BigGAN [43] StyleGAN2 + ADA (v1) [44] 8.30 8.76 9.22 10.06 Unconditional Gated PixelCNN [45] PixelIQN [46] EBM [41] NCSN [47] SNGAN [48] SNGAN-DDLS [49] StyleGAN2 + ADA (v1) [44] DDPM (fixed isotropic) [40] DDPM (simple) [40] Ours 4.60 5.29 6.78 8.870.12 8.220.05 9.090.10 9.74 0.05 7.670.13 9.460. 8.64 37.9 38.4 14.73 2.67 65.93 49.46 38.2 25.32 21.7 15.42 3.26 13.51 3.17 11.63 5.4 Experiment In this section, the performances of DMB on Text8 and CIFAR-10 are reported. Best Performance on Text8 We conduct our experiments using the Text8 dataset to evaluate the proposed framework. The experimental results are summarized in Table 1. To ensure statistical reliability, the model was evaluated across 1,000 independent trials. The primary performance metric, the Evidence Lower Bound (ELBO), was computed following the methodology outlined in Section 5.3. Our proposed approach, DMB, achieves Bits Per Character (BPC) bound of 1.38, surpassing baseline models such as SEDD [4], representative discrete diffusion model. Notably, our approach does not modify the vocabulary; in particular, no mask token is introduced. Consequently, when compared to similar methods that also do not incorporate mask tokensuch as SEDD Uniform and D3PM Uniformour approach demonstrates an improvement of approximately 0.1 points. Competitive Performance on CIFAR-10 Although our approach is not specifically tailored for image modeling tasks, we evaluate its performance on the CIFAR-10 dataset using VQ-VAE framework [6]. The quantitative results are presented in Table 2. Our method, DMB, achieves an Inception Score (IS) of 8.64 and Fréchet Inception Distance (FID) of 11.63. Notably, these results surpass those of several models explicitly designed for image generation, including DDPM (fixed isotropic) and SNGAN [48], in both IS and FID metrics. This demonstrates the effectiveness and generalization capability of our model beyond its primary design scope."
        },
        {
            "title": "6 Conclusion",
            "content": "In this study, we propose novel paradigm, the Discrete Markov Bridge (DMB), which combines the strengths of variational methods with the capabilities of discrete diffusion models. We provide theoretical guarantees to substantiate the feasibility and effectiveness of the proposed Matrix-learning process and prove the convergence of the DMB algorithm. In addition to our theoretical contributions, we conduct extensive empirical evaluations on the Text8 and CIFAR-10 datasets. The experimental results indicate that DMB not only surpasses existing baselines such as SEDD [4] in text modeling tasks, but also achieves competitive performance in image modeling on CIFAR-10, thereby demonstrating its potential as unified framework for discrete representation learning."
        },
        {
            "title": "Acknowledgement",
            "content": "We thank Junqi Wang from BIGAI for inspiration of discovering the matrix and Jianwen Xie from Lambda for discussion."
        },
        {
            "title": "References",
            "content": "[1] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=PxTIG12RRHS. [2] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:68406851, 2020. [3] Andrew Campbell, Joe Benton, Valentin De Bortoli, Tom Rainforth, George Deligiannidis, and Arnaud Doucet. continuous time framework for discrete denoising models, 2022. [4] Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion modeling by estimating the ratios of the data distribution. CoRR, 2023. [5] Diederik Kingma and Max Welling. Auto-encoding variational bayes. International Conference on Learning Representations (ICLR), 2014. [6] Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation learning, 2018. URL https://arxiv.org/abs/1711.00937. [7] Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. In Advances in Neural Information Processing Systems (NeurIPS), pages 1798117993, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/ 958c530554f78bcd8e97125b70e6973d-Abstract.html. [8] Chenlin Meng, Kristy Choi, Jiaming Song, and Stefano Ermon. Concrete score matching: Generalized score matching for discrete data, 2023. URL https://arxiv.org/abs/2211.00802. [9] Jiatao Gu and Xu Tan. Non-autoregressive sequence generation. In Luciana Benotti, Naoaki Okazaki, Yves Scherrer, and Marcos Zampieri, editors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, pages 2127, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-tutorials.4. URL https://aclanthology. org/2022.acl-tutorials.4. [10] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: robustly optimized bert pretraining approach. CoRR, 2019. [11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), pages 41714186, 2019. [12] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023. [13] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. [14] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert: lite bert for self-supervised learning of language representations, 2020. [15] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021. [16] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2023. [17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition, 2015. 10 [18] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models, 2022. [19] Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics, 2015. [20] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori Hashimoto. Diffusion-lm improves controllable text generation. Advances in neural information processing systems, 35:43284343, 2022. [21] Ishaan Gulrajani and Tatsunori B. Hashimoto. Likelihood-based diffusion language models, 2023. [22] Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, and Hanjun Dai. Score-based continuous-time discrete diffusion models, 2023. [23] Sander Dieleman, Laurent Sartran, Arman Roshannai, Nikolay Savinov, Yaroslav Ganin, Pierre H. Richemond, Arnaud Doucet, Robin Strudel, Chris Dyer, Conor Durkan, Curtis Hawthorne, Rémi Leblond, Will Grathwohl, and Jonas Adler. Continuous diffusion for categorical data, 2022. [24] Shen Nie, Fengqi Zhu, Zebin You, Xiaolu Zhang, Jingyang Ou, Jun Hu, Jun Zhou, Yankai Lin, Ji-Rong Wen, and Chongxuan Li. Large language diffusion models, 2025. URL https://arxiv.org/abs/2502. 09992. [25] Diederik P. Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models, 2023. URL https://arxiv.org/abs/2107.00630. [26] Kaiwen Zheng, Yongxin Chen, Hanzi Mao, Ming-Yu Liu, Jun Zhu, and Qinsheng Zhang. Masked diffusion models are secretly time-agnostic masked models and exploit inaccurate categorical sampling, 2024. URL https://arxiv.org/abs/2409.02908. [27] Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows, 2016. [28] Diederik P. Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions, 2018. [29] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow, 2022. [30] Victor Garcia Satorras, Emiel Hoogeboom, Fabian B. Fuchs, Ingmar Posner, and Max Welling. E(n) equivariant normalizing flows, 2022. [31] Michael S. Albergo, Nicholas M. Boffi, and Eric Vanden-Eijnden. Stochastic interpolants: unifying framework for flows and diffusions, 2023. [32] Asher Trockman and J. Zico Kolter. Orthogonalizing convolutional layers with the cayley transform, 2021. [33] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks, 2014. URL https://arxiv.org/abs/ 1406.2661. [34] Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions, 2021. URL https://arxiv.org/abs/2102. 05379. [35] Kun Sun, Mingli Jing, Yuliag Hu, and Yao Jiao. Image style transfer based on improved convolutional In 2021 2nd International Conference on Artificial Intelligence and Computer Engineering neural. (ICAICE), pages 575579, 2021. doi: 10.1109/ICAICE54393.2021.00114. [36] Zachary M. Ziegler and Alexander M. Rush. Latent normalizing flows for discrete sequences, 2019. URL https://arxiv.org/abs/1901.10548. [37] Dustin Tran, Keyon Vafa, Kumar Agrawal, Laurent Dinh, and Ben Poole. Discrete flows: Invertible generative models of discrete data. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/ e046ede63264b10130007afca077877f-Paper.pdf. [38] Andy Shih, Dorsa Sadigh, and Stefano Ermon. Training and inference on any-order autoregressive models the right way, 2022. URL https://arxiv.org/abs/2205.13554. [39] Alex Graves, Rupesh Kumar Srivastava, Timothy Atkinson, and Faustino Gomez. Bayesian flow networks, 2024. URL https://arxiv.org/abs/2308.07037. 11 [40] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 68406851. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/ 4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf. [41] Yilun Du and Igor Mordatch. Implicit generation and modeling with energy based models. In Advances in Neural Information Processing Systems, pages 36033613, 2019. [42] Will Grathwohl, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. Your classifier is secretly an energy based model and you should treat it like one. In International Conference on Learning Representations, 2020. [43] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural image synthesis. In International Conference on Learning Representations, 2019. [44] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676v1, 2020. [45] Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. Conditional image generation with PixelCNN decoders. In Advances in Neural Information Processing Systems, pages 47904798, 2016. [46] Georg Ostrovski, Will Dabney, and Remi Munos. Autoregressive quantile networks for generative modeling. In International Conference on Machine Learning, pages 39363945, 2018. [47] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. In Advances in Neural Information Processing Systems, pages 1189511907, 2019. [48] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In International Conference on Learning Representations, 2018. [49] Tong Che, Ruixiang Zhang, Jascha Sohl-Dickstein, Hugo Larochelle, Liam Paull, Yuan Cao, and Yoshua Bengio. Your GAN is secretly an energy-based model and you should use discriminator driven latent sampling. arXiv preprint arXiv:2003.06060, 2020. [50] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019. URL https://arxiv. org/abs/1711.05101."
        },
        {
            "title": "Contents",
            "content": "A Proof of Conservation of the Sum Proof of Accessibility B.1 Proof of Lemmas . . . B.2 Proof of the theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Supervision of Score-learning Proof of Convergence D.1 Proof of Lemmas . . . D.2 Proof of the theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Derivation of Matrix Exponential Calculation Derivation of KL term calculation proposition Additional Experimental details G.1 Model Details . . G.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Limitations and Societal Impact 14 14 14 16 18 18 18 19 19 20 20"
        },
        {
            "title": "A Proof of Conservation of the Sum",
            "content": "Proposition A.1 (Conservation of the Sum). For two arbitrary vectors ϕ, µ Rd, rate transition matrix Rdd, if ϕ = µ expQ, then Proof. As ϕ = µ expQ, Therefore,"
        },
        {
            "title": "As we have",
            "content": "Thus, (cid:88) i=1 ϕ[i] = (cid:88) i= µ[i] ϕ(i) = (cid:88) µ(j)(exp{Q})j,i (cid:88) (cid:88) (cid:88) ϕ(i) = µ(j)(exp{Q})j,i j (cid:88) (exp{Q})i,j = 1 (cid:88) ϕ(i) = (cid:88) µ(j) (cid:88) (exp{Q})j,i = i (cid:88) µ(j)"
        },
        {
            "title": "B Proof of Accessibility",
            "content": "B.1 Proof of Lemmas Lemma B.1. Let matrix Rdd and hold the following form: = n1 (cid:80) i=1 ai 0 0 . . . 0 0 n1 (cid:80) i=2 ai 0 . . . 0 0 a2 n1 (cid:80) i=3 . . . 0 0 . . . an2 an . . . an2 an1 ai . . . an an1 . . . . . . . . . . . . an1 an1 0 0 0 then can be diagonalized in the following form: = ΛU 1 , Λ = diag({ n1 (cid:80) i=1 ai, n1 (cid:80) i=2 ai, . . . , an1, 0}) 1 1 1 . . . 0 1 1 1 . . . 0 . . . . . . . . . . . . . . . 1 1 1 . . . 1 0 0 . . . 0 ,where = Proof. = 1 0 . . . 0 0 1 1 . . . 0 0 1 1 . . . . . . 0 . . . . . . . . . 1 0 1 1 . . . 1 1 diag({ n1 (cid:80) i=1 ai, n1 (cid:80) i= ai, . . . , an1, 0}) 14 1 1 0 . . . 0 0 0 1 1 . . . . . . . . . 0 0 0 . . . 0 . . . 0 . . . . . . 1 1 1 0 Lemma B.2. For arbitrary distribution p, R1d, there exists an permutation matrix such that: 1 1 1 + 2 1 + q 2 . . . (cid:80) i=1 (cid:80) i=1 q . . . (cid:80) i=1 (cid:80) i=1 q = 1 (15) where = pA, = qA, i is the i-th entry of Proof. Its obvious that there exists permutation matrix which can sort pi qi ascendly, i.e.: q i+1 i+ , where := pA, := qA, and the corner mark refer to the i-th entry. Also, we can demonstrate that: a1 b1 a2 b2 a1 b1 a1 + a2 b1 + b2 a2 b2 () The inequality we need to prove is: (cid:80) i=1 (cid:80) i=1 q k+1 (cid:80) i=1 k+1 (cid:80) i= q and its sufficient to proving the following inequality: (cid:80) i=1 (cid:80) i=1 q p k+1 k+1 We then start to prove the inequality by induction. 1, a2 = = 1: Let a1 = + 1: By induction: 1, b2 = 2, b1 = 2, and by using inequality , the statement is proved. By leveraging inequality : As k+1 k+1 k+2 k+2 : Thus the lemma is proved. (cid:80) i=1 (cid:80) i=1 q k+1 (cid:80) i=1 k+1 (cid:80) i=1 i k+1 (cid:80) i=1 k+1 (cid:80) i=1 q k+1 k+ k+1 k+1 k+2 k+2 15 Lemma B.3. Let Rdd be rate transition matrix, Rdd be permutation matrix, then AQA1 is rate transition matrix. Proof. As every permutation matrix can be expressed as the products of elementary matrices, we denote: = 1 (cid:89) k=NA ij = (NA) (k) ij (NA1) ij . . . (1) ij , where Tij is the elementary matrix obtained by swapping row and row of the identity matrix, NA Therefore: AQA1 = ( 1 (cid:89) (k) ij )Q( NA(cid:89) (k) ij ) k=NA k=1 For single pair of transformation, i.e. (k) ij QT (k) ij , the row sums remain unchanged, and the diagonal elements is still the diagonal elements after transformation, thus AQA1 is rate transition matrix. B.2 Proof of the theorem Theorem B.4 (Accessibility). For two arbitrary discrete distributions p, Rd, there exists rate transition matrix Rdd such that: = qeQ Proof. By Lemma 4.4, there exists permutation matrix which satisfies inequality 15, and we denote: := pA := qA := AQA1 a2 . . . an2 an1 . . . 0 0 . . . an2 an1 . . . . . . . . . . . . an1 an1 0 0 n1 (cid:80) i=2 ai, . . . , an1, 0}) 0 Suppose: , where = n1 (cid:80) i=1 ai 0 . . . 0 0 ai a1 n1 (cid:80) i=2 . . . 0 0 triangle matrix, and Λ = diag({ n1 (cid:80) i=1 ai, Denote: = ΛU 1, is all one upper n1 (cid:88) i=1 n1 (cid:88) i=1 i, 1] i, 1] := pU = [p 1, 1 + 2, . . . , := qU = [q 1, 1 + 2, . . . , Thus the solution of = qeQ can be obtained by solving: = qeΛ 16 , where eΛ = diag({e n1 (cid:80) i=1 ai , n1 (cid:80) i=2 ai , . . . , ean1, 1}) Solving the equation: and specifically, ak = ln k+1 (cid:80) i=1 k+1 (cid:80) i=1 q ln (cid:80) i=1 (cid:80) i= q an1 = ln n1 (cid:80) i=1 n1 (cid:80) i=1 q By the inequality 15 which p, satisfies and the monotonicity of the ln() function, ak 0, k, and thus is rate transition matrix Transfering the solution of = qeΛ back, we obtain: and by Lemma 4.5, is rate transition matrix. = AU ΛU 1A1 = AQA1 Proof of Supervision of Score-learning Proposition C.1 (Supervision of Score-learning). Suppose Q(t)s elements are non-zeros, the training objective is depicted as in Equation (8), then the optimality of the score model sθ (xt, t)b satisfies: sθ (xt, t)y = Ex0µ0t(xt)[ pt0(yx0) pt0(xtx0) ] = (cid:80) x0 (cid:80) x0 µ(x0)pt0(yx0) µ(x0)pt0(xtx0) Proof. (cid:90) Jscore = Ex0µ,xtpt0(xtx0) (cid:32) Q(t) y,xt sθ(xt, t)y pt0(yx0) pt0(xtx0) (cid:2) (cid:88) y=xt pt0(yx0) pt0(xtx0) (cid:0)log sθ(xt, t)y log( pt0(yx0) pt0(xtx0) )(cid:1) (cid:33) (cid:3)dt 0 + Therefore, with little abuse of notation, we have arg min θ Jscore = arg min θ = arg min θ (cid:90) 0 (cid:90) 0 (cid:124) Ex0µ,xtpt0(xtx0) (cid:32) Q(t) y,xt sθ pt0(yx0) pt0(xtx0) (cid:33) (cid:3)dt log sθ (cid:2) (cid:88) b=xt Extµt (cid:2) (cid:88) y=xt (cid:32) Q(t) y,xt sθ Ex0µ0t[ pt0(yx0) pt0(xtx0) (cid:33) (cid:3)dt ] log sθ (cid:123)(cid:122) (cid:125) sθ = (cid:90) Extµt (cid:2) (cid:88) y=xt (cid:32) Q(t) y,xt 1 Ex0µ0t[ pt0(yx0) pt0(xtx0) ] 1 sθ (cid:33) ]dt As Q(t)s elements are non zeros, therefore Q(t) y,xt > 0, = xt sθ = 0 1 Ex0µ0t[ pt0(yx0) pt0(xtx0) ] 1 sθ = 0 17 Therefore, the optimality of sθ satisfies: sθ (xt, t)y = Ex0µ0t(xt)[ pt0(yx0) pt0(xtx0) ] Furthermore, as µ0t(x0xt) = µ(x0)pt0(xtx0) µ(x0)pt0(xtx0) , we have (cid:80) x0 (cid:80) x0 (cid:80) x0 µ(x0)pt0(yx0) µ(x0)pt0(xtx0) sθ (xt, t)y ="
        },
        {
            "title": "D Proof of Convergence",
            "content": "D.1 Proof of Lemmas Lemma D.1. For random variable X0 Rn with arbitrary two distributions p0, kernel is pt0(xtx0). We denote 0, the transition pt(xt) := t(xt) := (cid:88) x0 (cid:88) x0 p0(x0)pt0(xtx0) 0(x0)pt0(xtx0) DKL(ptp t) DKL(p0p 0) Then we have: Proof. DKL(p0,t(, )p 0,t(, )) = = (cid:88) x0,xt (cid:88) x0,xt p0,t(x0, xt) log p0,t(x0, xt) 0,t(x0, xt) p0,t(x0, xt) log pt0(xtx0)p0(x0) pt0(xtx0)p 0(x0) = DKL(p0p 0) Using the chain rule for KL divergence: DKL(ptp t) = DKL(p0,t(x0, xt)p 0,t(x0, xt)) Ept[DKL(p0t(x0xt)p 0t(x0xt)] As KL divergence is greater than zero, we have: DKL(ptp t) DKL(p0,t(x0, xt)p 0,t(x0, xt)) = DKL(p0p 0) D.2 Proof of the theorem Theorem D.2 (Convergence of the algorithm). If we assume optimality is achieved in every epoch of the forward process and the reverse process, and we denote the k-th epoch estimation of µ as p0, then limk DKL(µp(k) 0 ) converges. Proof. According to the assumption that each subprocess reaches its optimum, µ = µp(k) 0p(k); 0T p(k+1) 0 = p(k) 0 p(k) 0p(k); 0T 18 Therefore, by using Lemma D.1 twice: 0 ) DKL(µp(k) DKL(µp(k) 0p(k) 0 p(k) 0) DKL(µp(k) 0p(k); 0T p(k) 0 p(k) 0p(k); 0T ) Therefore, DKL(µp(k) 0 ) DKL(µp(k+1) 0 ) As KL divergence is greater than zero, then lim DKL(µp(k) 0 ) converges."
        },
        {
            "title": "E Derivation of Matrix Exponential Calculation",
            "content": "Proposition E.1. For matrix Rnn and non-degenerate matrix Rnn, we have: exp{DQD1} = exp{Q}D1 Proof. According to the definition of matrix exponential, exp{DQD1} = + (cid:88) i= (DQD1)i As (DQD1)i = DQiD1, exp{DQD1} = + (cid:88) i=1 DQiD1 = D(I + (cid:88) i=1 Qi)D1 = exp{Q}D"
        },
        {
            "title": "F Derivation of KL term calculation proposition",
            "content": "The full bound [8, 3] is as follows: Ex0µ[ log p0;θ(x0)] Jscore + Ex0µ[DKL (cid:0)pT 0;α(xT x0)ϕ(cid:1)] , where (cid:90) Jscore Ex0µ,xtpt0(xtx0) (cid:2) (cid:88) b=xt Q(t) b,xt (cid:32) sθ(xt, t)b pt0(bx0) pt0(xtx0) (cid:33) pt0(bx0) pt0(xtx0) (cid:0)log sθ(xt, t)b log( pt0(bx0) pt0(xtx0) )(cid:1) (cid:3)dt 0 + However, unlike previous works, the second term, which is the KL term should be considered, and it seems impossible to compute. Fortunately, certain characteristics of the Matrix-learning process can be used to justify computable form for the second term. Suppose the text sequence holds dimensions, i.e.x Rd, then the characteristics can be described as follows: Independent Evolution: Independent Terminal: pT 0;α(xT x0) = ϕ(xT ) = (cid:89) i=1 (cid:89) i=1 pT 0;α(x(i) x(i) 0 ) pT (x(i) ) As result, we provide computable form for the KL term. 19 Proposition F.1. DKL (cid:0)pT 0;α(xT x0)pT (xT )(cid:1)= (cid:80) i="
        },
        {
            "title": "DKL",
            "content": "(cid:0)pT 0;α(x(i) x(i) 0 )pT (x(i) )(cid:1) Proof. By independent evaluation and independent terminal, we have"
        },
        {
            "title": "DKL",
            "content": "(cid:0)pT 0;α(xT x0)pT (xT )(cid:1) = pT 0;α(xT x0) log pT 0;α(xT x0) ϕ (cid:88) xT = = = = (cid:88) pT 0;α(xT x0) (cid:88) i=1 log x(i) pT 0;α(x(i) 0 ) pT (x(i) ) ,...,x(d) ,x(2) x(1) (cid:88) i=1 ,x(2) x(1) ,...,x(d) (cid:88) pT 0;α(xT x0) log x(i) pT 0;α(x(i) 0 ) pT (x(i) ) (cid:88) (cid:88) i=1 x(i) pT 0;α(x(i) x(i) 0 ) log x(i) pT 0;α(x(i) 0 ) pT (x(i) ) (cid:88) i=1 DKL (cid:0)pT 0;α(x(i) x(i) 0 )pT (x(i) (cid:1)"
        },
        {
            "title": "G Additional Experimental details",
            "content": "G.1 Model Details In terms of text modeling, for Matrix-learning, the Qα matrix is initialized as follows: ai = 0, = 1, 2, 3, . . . , 2 an1 = 1 The model is kept the same as SEDD [4]. As for image modeling, for Matrix-learing, the Qα matrix is initialized as follows: ai = 1e 5, = 1, 2, 3, . . . , 2 The model is kept the same as SEDD [4]. G.2 Training Details The model is trained with batch size of 512 and trained with learning rate of 3 104 (Adam optimizer) on 8 4090 24GB GPUs. Both the Matrix-learning as well as the Score-learning are trained with the AdamW [50]. Training start with weight decay factor 0.01, which then turn to 0 in the 7,900,000 step for text8."
        },
        {
            "title": "H Limitations and Societal Impact",
            "content": "In this work, the DMB framework primarily relies on the evidence lower bound (ELBO) for both training and evaluation. However, given that Theorem 4.7 is not dependent on the specific form of the loss function, it is theoretically possible to derive other bounds for training. This flexibility opens new avenues for optimizing DMB under different theoretical and practical settings. Furthermore, we havent provided theorem focusing on optimality, which may be done for future work. As for societal impact, our work focus on foundation learning algorithms, which doesnt hold direct societal impact."
        }
    ],
    "affiliations": [
        "Department of Automation, Tsinghua University",
        "Institute of Artificial Intelligence, Peking University",
        "NLCo Lab, Beijing Institute for General Artificial Intelligence",
        "State Key Laboratory of General Artificial Intelligence",
        "University of California, Los Angeles"
    ]
}