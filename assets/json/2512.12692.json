{
    "paper_title": "WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment",
    "authors": [
        "Mahir Labib Dihan",
        "Tanzima Hashem",
        "Mohammed Eunus Ali",
        "Md Rizwan Parvez"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 1 ] . [ 1 2 9 6 2 1 . 2 1 5 2 : r WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment WEBOPERATOR: ACTION-AWARE TREE SEARCH FOR AUTONOMOUS AGENTS IN WEB ENVIRONMENT Mahir Labib Dihan1 Tanzima Hashem1 Mohammed Eunus Ali2 Md Rizwan Parvez3 1Department of Computer Science and Engineering Bangladesh University of Engineering and Technology (BUET) 2Faculty of Information Technology, Monash University 3Qatar Computing Research Institute (QCRI) {dihan, tanzimahashem}@cse.buet.ac.bd, eunus.ali@monash.edu, mparvez@hbku.edu.qa Work done when working as remote RA at QCRI."
        },
        {
            "title": "ABSTRACT",
            "content": "LLM-based agents often operate in greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observablelimited to browservisible content (e.g., DOM and UI elements)where single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actionslimitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates best-first search strategy that ranks actions by both reward estimates and safety considerations, along with robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution. All our resources are open-sourced at https://kagnlp.github.io/WebOperator/."
        },
        {
            "title": "INTRODUCTION",
            "content": "LLM-based WebAgents are increasingly applied to automate complex web interactions, ranging from form filling and content retrieval to multi-step workflows over dynamic pages (Deng et al., 2024). However, planning and executing such tasks remains challenging due to unique characteristics of web environments, such as being partially observable: the agent can access the current pages DOM, UI elements, and visible content, but has no direct access to hidden server-side state or the broader global context. Despite these challenges, conventional WebAgents operate in greedy, step-by-step manner, selecting actions based solely on the current observation, without accounting for long-term consequences or alternative strategies (Ning et al., 2025). While off-the-shelf models for estimating action usefulness are available, they are inherently short-sighted and imperfect (Chae et al., 2025) and this myopic approach is particularly fragile in web-like, partially observable environments, where sin1 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Figure 1: Overview of WebOperator, tree-search framework for solving web tasks. The workflow iteratively explores the web environment via structured tree: it (1) initializes at the start page, (2) observes and encodes the current page state as node in the search tree, (3) adapts action space using the current observation, and expands the node by generating candidate actions using varied contextual formulations, and these actions are validated through rule-based analysis and simple URL-existence checks; (4) evaluates actions with reward model, (5) merges duplicate or equivalent actions, (6) updates the search tree, (7) selects the best unexecuted action using action-aware criteria, (8) restores the target state using speculative backtracking, (9) executes the selected action, and (10) repeats until terminating action produces complete solution trajectory. The left panel shows an example thoughtaction sequence produced during task execution, and the right panel details the speculative backtracking mechanism. detailed step-by-step example of the tree search is provided in Appendix (Figure 8). gle incorrect action can lead the agent into state, from which the goal is unreachable. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. While tree search provides principled foundation for decision-making with backtracking, existing methods struggle to generalize across diverse problems and real-world complexities, leaving much of its potential unrealized. In this paper, we introduce WebOperator, performant, action-aware tree-search framework for autonomous agents that systematically addresses these fundamental challenges and operates robustly in dynamic, real-world web settings. Designing tree-search WebAgents presents several core challenges that are specific to search-based decision making in realistic web environments: (i) low-quality action generation - LLMs may produce invalid or contextually irrelevant actions (e.g., go back on the start page), reducing tree search efficiency and wasting computation. (ii) redundant candidate actions - Fixed number of candidate actions are generated at each step, many of which are redundant or semantically equivalent. Multiple actions may lead to the same outcome without contributing new information, reducing meaningful exploration. (iii) fragile state reversibility - Tree search fundamentally depends on reversing or replaying actions to explore alternative paths. However, real web environments are non-deterministic: asynchronous updates, DOM mutations, and navigation effects can make naÄ±ve backtracking unreliable. Replaying previously executed actions may fail or lead to an inconsistent state, limiting the practical effectiveness of tree search. (iv) handling destructive actions - Many real web interactions, such as submitting irreversible forms, deleting items, or logging out, permanently alter the environment. Existing tree search methods (Koh et al., 2024; Zhou et al., 2024; Zhang et al., 2025b) assume reversibility and cannot safely reason about or schedule these destructive actions. Executing them carelessly can invalidate previously visited states, preventing reliable backtracking and limiting exploration of alternative paths. (v) computational overhead exhaustive tree search is prohibitively expensive in realistic web settings. Monte Carlo Tree Search (MCTS), for instance, relies on extensive random rollouts and costly environment resets, making it ill-suited for web-scale (Zhou et al., 2024; Zhang et al., 2025b). To address these challenges, WebOperator pioneers redefinition of web environments by extending the notions of state (temporary and persistent) and actions (safe and destructive). It develops an action-aware tree-search approach that incorporates: (a) Dynamic adaptation of the action space at 2 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Table 1: Comparison of tree-search WebAgents across key capabilities, highlighting WebOperator. Method Dynamic Action Context Action Non-deterministic Action Space Validation Variation Merging LM-TS (Koh et al., 2024) LA-TS (Zhou et al., 2024) WebPilot (Zhang et al., 2025b) Branch-n-Browse (He et al., 2025) WebRollback (Zhang et al., 2025c) WebOperator (Ours) Environment Destructive Action Handling each step based on the current observation, along with validation of generated actions to reject those that are invalid or have no meaningful effect. (b) Variation of the LLM input context to generate diverse candidate actions, combined with consolidation of redundant actions to ensure meaningful exploration. (c) Reliable backtracking using speculative execution and snapshot validation, allowing previously executed actions to be replayed or aborted without corrupting the main environment. (d) Preand post-execution heuristics to identify potentially destructive actions based solely on observable content. (e) Efficient traversal via best-first search strategy that prioritizes safe, reversible actions early and defers destructive actions, replacing costly random-rollout methods like MCTS. Together, these contributions enable WebOperator to systematically explore web environments, safely handle both temporary and persistent state changes, and operate efficiently under uncertainty, advancing the capabilities of tree search for realistic web automation tasks. Table 1 presents feature-based comparison with prior methods, while Figure 1 provides an operational overview. Through comprehensive experiments on two dynamic, real-world web benchmarks, WebArena and WebVoyager, we demonstrate the effectiveness of WebOperator. Our ablation studies and analyses further provide deeper insights into WebOperators capabilities and limitations."
        },
        {
            "title": "2 PRELIMINARIES",
            "content": "2.1 PROBLEM DEFINITION: TREE SEARCH IN WEB ENVIRONMENTS Let web environment be represented as tuple = (S, A, T, O), where: is the state space, partitioned into persistent state (e.g., server-side data, cookies, local storage) and temporary state (e.g., DOM elements, scroll offsets, open tabs). is the set of actions the agent can perform (e.g., click, fill form, navigate, terminate). The complete action set is provided in Table 5 (Appendix). : is the transition function, describing how actions change the environment state. Transitions may be stochastic due to dynamic page content. : is the observation function, mapping states to agent-observable snapshots (DOM, page content, URL, etc.). tree search for web automation constructs search tree , where each node represents reachable state and each edge corresponds to an action that transitions from the parent state to the child state. The agents goal is to find sequence of actions from the root node (initial state) to target node (goal state). 2.2 ACTION CLASSIFICATION WebOperator classifieds actions based on their impact on the web environment and their reversibility. This classification allows the agent to reason about risks and choose actions that maintain safety and efficiency during tree search. Safe Actions. Actions that only modify temporary state, such as scrolling, interacting with dropdowns, or toggling checkboxes. These actions are fully reversible, meaning the agent can return to the previous state without affecting persistent data. Navigational actions, which change the page URL and effectively reset the temporary state while preserving persistent state, are treated as special safe actions. Safe actions (including navigational actions) form the majority of exploratory steps in the tree search. 3 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Destructive Actions. Actions that modify persistent state, including server-side changes, form submissions, or updates to browser storage and cookies. Destructive actions are high-risk and cannot always be undone. WebOperator carefully considers these actions and applies them only when necessary, with mechanisms to verify safety and prevent unintended consequences. Terminating Actions. Actions proposed by the agent to terminate the search at the current node. These actions do not modify the environment but signal that the agent considers the current node as sufficient solution or stopping point for exploration. Invalid Actions. Actions that are syntactically or semantically incorrect and would raise an execution error if performed in the environment. Examples include navigating to an invalid URL, clicking disabled or non-existent element, filling read-only field, or attempting to go back from the initial page."
        },
        {
            "title": "3 METHODOLOGY",
            "content": "In this section, we describe our WebOperator framework for robust and efficient tree search in web environments. Building on the task formalization and action taxonomy introduced in 2.1 and 2.2, WebOperator develops best-first search strategy that integrates several key components: rich action generation process (3.1) that combines adaptive action space, context variation, action validation, and action merging to produce high-quality and diverse candidates; an improved backtracking procedure (3.3) to ensure efficient and reliable traversal; specialized handling of destructive actions (3.2), which are the primary source of environment corruption; and dynamic, context-aware action selection mechanism (3.4) that balances reward, safety, reversibility, and search context while maintaining bounded frontier. The complete search algorithm, integrating all these components, is provided in Appendix C.. 3.1 ACTIONS GENERATION Candidate actions are generated using large language model (LLM) based on rich contextual representation of the current state. WebOperator addresses the two primary challenges: low-quality and redundant actions. To generate high-quality actions, WebOperator combines proactive and reactive measures: Dynamic Action Space. The set of available action types is dynamically adapted to the current observation, ensuring only feasible actions are considered at each step (e.g., go back is allowed only when there are previous pages). This reduces irrelevant exploration and prevents invalid actions. Action Validation via Error Prediction. Each generated action is checked before execution. Static analysis inspects the DOM/accessibility tree (e.g., element visibility, enabled status), while simple dynamic checks ensure that actions such as navigation target valid URLs. Actions that are invalid or ineffective are rejected, and feedback is provided to the LLM to regenerate improved candidates. To generate diverse actions, WebOperator further employs complementary proactive and reactive strategies: Context Variation. Different components of the LLM input are varied for each candidate action, such as the length of task history included or selective retrieval of relevant past trajectories. This encourages the model to propose semantically distinct actions. Action Merging. Semantically equivalent actions are consolidated after generation to avoid redundant expansions, effectively reducing the branching factor and ensuring meaningful exploration. This combination of proactive and reactive mechanisms ensures that the candidate actions entering the search are both high-quality and diverse, directly addressing the core limitations of traditional tree-search WebAgents. Detailed implementation of each component is provided in Appendix A.1. 4 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment"
        },
        {
            "title": "3.2 THE CHALLENGE OF DESTRUCTIVE ACTIONS",
            "content": "A key challenge in web tree search is handling actions that permanently modify the environment, i.e., destructive actions. Executing such actions may alter the database or browser state (cookies, local storage, session storage), potentially invalidating1 previously visited states and corrupting the main environment. Pre-execution Heuristic for detecting Destructive Actions. Before executing an action, WebOperator employs lightweight heuristic to proactively identify potentially destructive operations. This heuristic considers both the action type and the interacted element. Non-click actions (e.g., scroll, tab focus) are generally non-destructive. For clicks, only button elements are considered potentially destructive, while links and other elements are typically safe. Similarly, pressing the Enter key, which often triggers form submissions or default button actions, is treated as potentially destructive. Buttons with labels indicating navigation or transient actions (e.g., back, search, refresh) are classified as non-destructive. The full detection procedure is summarized in Algorithm 2 (Appendix). Figure 2: Illustration of destructive action execution in WebOperator Post-execution Heuristic for detecting Destructive Actions. While the pre-execution heuristic provides an initial estimate based on static cues, it lacks runtime information available only after execution. To address this limitation, we introduce post-execution heuristic that leverages networklevel observations to validate whether an executed action was indeed destructive. During execution, WebOperator monitors the network activity triggered by the action, analyzing the corresponding HTTP requests. Actions resulting in GET requests are typically non-destructive, as they merely retrieve data. In contrast, actions generating POST, PUT, DELETE, or PATCH requests are strong indicators of destructive operations, as they usually modify server-side data or trigger irreversible effects. After execution, WebOperator applies this heuristic to reassess the actions destructiveness. If confirmed, all previous states are invalidated, and the search tree is reset as described below. This twostage detection mechanismcombining preand post-execution heuristicsprovides both proactive avoidance and reactive correction, ensuring robust handling of destructive behaviors throughout the search process. Handling Destructive Actions Execution. When an action is detected as destructive, its execution marks point of no return in the search process. Once the environments persistent state changes, previously visited states may become inconsistent. Continuing to expand or backtrack to these states could lead to invalid or unsafe transitions. 1Invalid state means we cant backtrack to that state with our proposed backtracking algorithm 5 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment WebOperator handles this situation as follows: 1. Invalidate All Previous States: All states in the tree, except the current states resulting from the destructive action, are marked as invalid and excluded from further expansion. 2. Reset Tree Root: The current state becomes the new root of the search tree. 3. Resume Exploration: Tree search continues from this new root using the action-aware BestFirst Search, generating new candidate actions based on the updated environment state. This mechanism ensures that exploration can safely continue even after executing destructive actions, preserving the correctness of the search and preventing invalid backtracking."
        },
        {
            "title": "3.3 BACKTRACKING",
            "content": "Backtracking is crucial operation in tree search for web automation, where the agent may need to execute an action originally generated from previous state rather than the current one. Formally, backtracking navigates the agent from the current state to prior state where promising action was proposed, typically by (1) restoring the environment to an ancestor of the target state, and (2) executing the minimal sequence of actions required to reach the target. Prior works (Koh et al., 2024; He et al., 2025) rely on naive approach that resets the root state and replays all actions to reach the target, which is highly inefficient. More critically, as discussed earlier, executing destructive actions can invalidate previously saved states, including the original root and many intermediate ancestors in such cases resetting to that root for backtracking is impossible or unsafe. To address both issues, WebOperator introduces an improved backtracking mechanism that addresses both efficiency and reliability concerns. Figure 3: Different types of Backtracking visualization. See Appendix for detailed comparison. Efficiency. To reduce replay overhead, WebOperator employs checkpoint-based state jumping (illustrated in Fig. 3). state is marked as checkpoint when its webpage observation remains unchanged under refresh and its URL differs from that of its parent. Such states are safe to revisit directly because they are refresh-stable and represent distinct navigation points, ensuring that jumping to their URL reliably reconstructs the same underlying environment without requiring prior UI interactions. During backtracking, the agent jumps to the closest checkpoint of st via URL navigation, then replays only the minimal UI interactions (e.g., scrolling, form filling) needed to reconstruct st. This strategy avoids unnecessary intermediate steps by leveraging the determinism of URL-based navigation: navigate to the nearest checkpoint, then apply only the incremental UI operations required to recover the exact target state. Reliability. To handle non-deterministic behaviors, WebOperator employs speculative backtracking with snapshot validation. Instead of replaying actions directly in the main environment, the agent 6 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment attempts backtracking in parallel browser tab. Before executing each stored action, the agent compares the current observation in the parallel tab with the corresponding stored snapshot2 of the target state st (see Appendix for the comparison procedure). If any mismatch indicates that the state is no longer reproducibledue to randomness, dynamic content changes, or UI driftthe backtracking attempt is immediately aborted, leaving the main environment unchanged. If all actions replay successfully and all snapshots match, the reconstructed state is committed to the main environment. This speculative execution prevents unintended side effects and ensures reliable state restoration even in non-deterministic web environments."
        },
        {
            "title": "3.4 ACTION SELECTION",
            "content": "After each expansion step, newly generated candidate actions are scored and inserted into frontiera priority queue of unexecuted actions that the tree search may choose from. Unlike prior approaches, which select the next action solely based on these static scores, WebOperator employs dynamic, context-aware selection policy. At every step, the priority of each frontier action is recomputed based on (i) its type (safe, destructive, terminating, or repetitive) and (ii) the evolving search context, such as progress toward the goal, past destructive actions, or accumulated step count. This allows the agent to adaptively steer exploration: safe and reversible actions are favored early, destructive actions are deferred until they are strategically justified, and terminating actions are promoted only when they represent high-confidence opportunities. To keep the search tractable, WebOperator maintains fixed frontier budget. Whenever the frontier exceeds this budget, it is pruned through structured reduction process. First, actions that cannot be reliably backtracked to are removed. Next, among destructive actions, only the highest-rewarded one is retained, since once destructive action is selected, all others become irrelevantthe search tree is reset afterward. similar rule is applied to terminating and repetitive actions. If the frontier still exceeds its budget, semantically duplicate safe actions are merged, and any remaining overflow is resolved by discarding the lowest-rewarded safe actions. Through this dynamic prioritization and controlled frontier management, WebOperator selects actions not merely by reward, but by their safety, reversibility, contextual relevance, and contribution to meaningful long-horizon exploration. The complete procedure is detailed in Algorithm 5."
        },
        {
            "title": "4 EXPERIMENTS",
            "content": "Here, we detail experiments on WebArena (Zhou et al.), web simulator benchmark. Further experiments with WebVoyager (He et al., 2024), web benchmark based on real-world websites, are included in Appendix F. 4.1 EXPERIMENTAL SETUP Environment. We utilize WebArena, an interactive web simulator benchmark comprising fully functional websites across four domains: e-commerce (OneStopShop), social forums (Reddit), collaborative software development (GitLab), and content management (online store management). The environment also provides utility tools (map, calculator, scratchpad, Wikipedia) to support realistic interactions. WebArena contains 812 tasks instantiated from 241 parameterized templates, each paired with programmatic evaluator that verifies task completion against ground-truth targets. Implementation. We implement WebOperator on top of the BrowserGym framework (Drouin et al., 2024). The backend language model is gpt-4o-2025-01-01, serving as the core reasoning and evaluation module throughout action generation, and scoring. Unless otherwise stated, the tree search uses depth factor = 5, frontier budget 4, and branching factor = 3 with search budget of 20 steps per task. Prompts used for action-generation and scoring are provided in Appendix I. Baselines. Our controlled evaluation focuses on prior and concurrent tree-search methodsLMTS, WebPilot, and Branch-and-Browseall using gpt-4o as their backbone. We directly report the results from their respective papers. Additional non-tree-search agents are included later in the main results table for completeness. 2Observation stored in the search tree during the first visit 7 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Table 2: Success rate (SR %) comparison on WebArena. Agent Model Overall Reddit GitLab Shopping CMS Map Multisite (#187) (#812) (#109) (#180) (#182) (#106) (#48) BrowserGym (Drouin et al., 2024) LM-TS (Koh et al., 2024) Go-Browse (Gandhi et al., 2025) AWM (Wang et al., 2024) Branch-n-Browse (He et al., 2025) WebPilot (Zhang et al., 2025b) AgentOccam (Yang et al., 2025) AgentSymbiotic (Zhang et al., 2025a) claude-3.5-sonnet ScribeAgent (Shen et al., 2024) gpt-4 gpt-4o qwen-2.5-7b gpt-4 gpt-4o gpt-4o gpt-4-turbo gpt-4o WebOperator gpt-4o 15.0 19.2 22.6 35.5 35.8 37.2 45.7 52.1 53.0 54. 20.2 11.3 30.7 50.9 50.9 65.1 67.0 66.0 73.7 76.4 19.0 13.9 15.3 31.8 36.7 39.4 43.3 51.0 59.7 52.8 17.2 27.8 22.4 30.8 34.6 36.9 46.2 48.0 45.8 49. 14.8 16.5 25.3 29.1 26.4 24.7 38.9 49.0 37.9 55.0 25.5 26.6 17.9 43.3 46.8 33.9 52.3 60.0 56.3 55.2 - 16.7 - - 18.8 - 16.7 29.0 - 31."
        },
        {
            "title": "4.2 MAIN RESULTS",
            "content": "Overall performance. We first present the main performance comparison on WebArena in Table 2, which summarizes the success rates of WebOperator against broad range of prior web agents, including both tree-search and non-tree-search methods. Using gpt-4o as the backbone, WebOperator achieves an overall success rate of 54.6%, outperforming all existing methods on the benchmark. The gains are consistent across domains, with particularly strong performance on Reddit (76.4%), GitLab (52.8%), and CMS (55.0%), demonstrating the effectiveness of action-aware tree search with safe backtracking in diverse web settings. Table 3: Success rate (SR %) comparison of Tree Search Agents on WebArena with gpt4o (BFS = Best-First Search). Agent Search Algorithm Search Budget SR (%) LM-TS Branch-n-Browse WebPilot BFS BFS MCTS WebOperator BFS 20 / Iteration 10 / Sub-task 10 / Sub-task 5 (Overall) 10 (Overall) 15 (Overall) 20 (Overall) 19.2 35.8 37.2 24.4 42.7 48.4 54.6 Fair comparison with tree-search baselines. While Table 2 reflects end-to-end performance using results reported in prior work, different methods employ varying search strategies, budgets, and backbones. To ensure fair comparison, Table 3 isolates tree-search-based agents evaluated under the same backbone (gpt-4o) and explicitly reports their search algorithms and budgets. Under identical conditions, WebOperator substantially outperforms existing tree-search methods: with search budget of 20 steps, it achieves 54.6% SR, compared to 35.8% for Branch-n-Browse and 37.2% for WebPilot. This confirms that the performance gains stem from our action-aware search design rather than model choice or evaluation protocol. Search budget analysis. Table 3 further analyzes how performance scales with the search budget. WebOperator shows smooth and consistent improvements as the budget increases, from 24.4% (budget 5) to 54.6% (budget 20). Notably, even with budget of only 10 steps, WebOperator (42.7%) already surpasses all prior tree-search methods that use larger per-task budgets. This highlights not only superior peak performance but also strong budget efficiency, indicating that WebOperator explores the search space more effectively at shallow and moderate depths. 4.3 BACKTRACKING ANALYSIS As shown in Figure 4, while majority of tasks are solved without any backtracking, approximately 40% of successful tasks required at least one backtrack, highlighting the importance of WebOperators robust corrective search mechanism. Tasks requiring 5 or more backtracks remain rare (< 3%), indicating that extreme corrective efforts are uncommon in WebArena. These patterns emphasize both the efficiency and reliability of WebOperator: it can handle straightforward tasks quickly while still effectively recovering from mistakes in harder scenarios, contributing to its strong overall and cross-domain performance. 8 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Figure 4: Distribution of successful WebArena tasks grouped by the number of backtracks required across different task domains."
        },
        {
            "title": "4.4 DESTRUCTIVE ACTION HEURISTICS",
            "content": "Figure 5 illustrates the behavior of WebOperators preand post-execution destructive-action heuristics. The pre-execution heuristic takes conservative approach by flagging actions that may alter persistent state, while the post-execution check later confirms which of them actually modify persistent state. We find that only about 37% of preflagged actions are confirmed as truly destructive, indicating that the pre-execution filter is useful but not highly precise. This reflects an inherent tradeoff: the heuristic is intentionally lightweight to keep node expansion efficient, whereas improving its precision would likely require more computationally expensive approaches such as model-based reasoning or the use of learned world models to predict downstream effects. Nevertheless, the current combination of conservative pre-checks and definitive post-checks enables the agent to identify risky actions early, assess their actual impact, and reliably re-root the search tree when irreversible changes occur. Figure 5: Comparison of number of destructive actions detected by preand postexecution heuristic across different task domains.(Map is excluded since destructive action is not applicable for read-only websites). 4.5 ABLATION STUDIES We conduct detailed ablation studies on WebArena-lite (Liu et al.), curated subset of 155 tasks from WebArena, to systematically evaluate the contribution of each component in our WebOperator framework. The progressive integration of components, as shown in Table 4, follows our architectural design. Single-Action Agent Enhancement. We begin with Base ReAct Agent that generates single action at each step (47.74% SR). First, we integrate our core interaction improvements: adding Dynamic Action Space provides modest gain (49.03% SR), while incorporating Action Validation further improves success rate to 53.55% and significantly enhances efficiency, achieving the lowest average action count (8.67). This validates that filtering invalid actions early is crucial for robust single-step decision-making. Transition to Multi-Action Generation. Building upon the validated single-action components (Dynamic Action Space + Action Validation), we transition from single to multiple action generation. The Multi-Action approach forms the foundation for tree search, though it naturally increases action exploration (24.06 avg. actions). We then enhance this with Action Merging to consolidate redundant actions and Context Variation to diversify exploration, progressively improving the success rate to 54.84%. This demonstrates that diverse, consolidated action proposals facilitate more effective state space exploration, with slight increase in the average action count (+1.24). Advanced Search with Backtracking. Introducing naive Tree Search to the multi-action framework reduces performance to 51.61% from 54.84%. This demonstrates that basic backtracking 9 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Table 4: Ablation study on WebArena-lite (gpt-4o) showing the effect of different components on success rate (SR %) and average number of generated actions. Avg Success Rate (SR %) Agent Base ReAct Agent + Dynamic Action Space + Action Validation + Multi-Action + Action Merging + Context Variation + Tree Search + Destruction-Aware + Checkpoints + Selection Heuristic + Speculative-Backtracking Generated Overall Reddit GitLab Shopping CMS Map (#26) Actions (#155) (#30) (#45) (#19) (#35) 9.30 9.17 8. 24.06 25.39 25.30 24.79 27.09 29.67 31.34 47.74 49.03 53.55 52.90 54.19 54.84 51.61 51.61 58.71 60.00 57.89 52.63 68. 68.42 57.89 63.16 42.11 63.16 68.42 78.95 56.67 63.33 70.00 63.33 66.67 66.67 66.67 66.67 70.00 70.00 46.67 46.67 51. 48.89 51.11 53.33 51.11 51.11 57.78 53.33 31.43 53.85 40.00 46.15 42.86 42.31 34.29 61.54 37.14 65.38 37.14 61.54 37.14 61.54 37.14 46.15 45.71 57.69 51.43 57.69 alone is insufficient for complex web tasks. The subsequent integration of our advanced reasoning modules proves essential: incorporating Destructive-Action Handling and Context-Aware Action Selection Policy recovers and substantially improves performance to 58.71%. The complete system with Speculative-Execution achieves the highest success rate of 60.00%, confirming that sophisticated action selection and reliable backtracking are essential for maximizing tree search benefits in long-horizon tasks. Notably, while our full approach (31.34 actions) generates +6.55 more actions than naive tree search (24.79 actions), it delivers substantially higher absolute gain of +8.39% in success rate, confirming that our sophisticated action selection effectively trades moderate computational exploration for significantly improved task completion."
        },
        {
            "title": "5 RELATED WORK",
            "content": "LLM-based web agents increasingly adopt tree-search planning to overcome the brittleness of greedy step-by-step execution. However, existing systems still struggle with key challenges of the web environmentincluding non-determinism, partial observability, destructive actions, and reliable state recovery. Tree-Search Web Agents. growing line of work applies tree-search planning to web automation, aiming to overcome the brittleness of greedy LLM execution. LM-Tree Search (LMTS) (Koh et al., 2024), LATS (Zhou et al., 2024), Branch-and-Browse (He et al., 2025), WebPilot (Zhang et al., 2025b), and WebRollback (Zhang et al., 2025c) all adopt the general strategy of expanding multiple candidate actions, evaluating them with learned value functions or heuristics, and traversing the search space through backtracking-based exploration. These systems demonstrate that branching exploration improves robustness on long-horizon tasks, but they still depend heavily on replay-based restoration, limited action validation, and heuristic handling of dynamic or irreversible transitions. Our work builds on this direction by introducing more principled treatment of destructive actions, higher-quality and more diverse action generation, and backtracking mechanism designed for partially observable, non-deterministic web environments. Safety and Destruction Handling. parallel strand of research focuses on safety-aware planning and recovery for LLM-based web agents. WebGuard (Zheng et al., 2025) introduces classifier trained to predict the risk level of web actions (e.g., SAFE/LOW/HIGH) and uses it to block or flag potentially harmful interactions. InferAct (Fang et al., 2024) simulates the effect of candidate actions using secondary LLM and warns users before executing risky commands. While effective, these systems generally operate outside the core planning loopeither through external classifiers or simulation-based safety checksrather than integrating safety guarantees directly into search. In contrast, our method incorporates both preand post-execution heuristics for destructive action detection and speculative backtracking, providing recovery guarantees as part of the tree-search framework itself. 10 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment"
        },
        {
            "title": "6 CONCLUSION",
            "content": "In conclusion, WebOperator introduces action-aware tree search framework that fundamentally advances autonomous web agents by systematically addressing the challenges of partial observability, non-determinism, and irreversible actions. Through its integrated approachfeaturing highquality action generation, reliable speculative backtracking, and strategic handling of destructive operationsthe method enables robust and efficient exploration. The framework achieves state-ofthe-art performance on WebArena and demonstrates strong, superior generalization on WebVoyager, establishing itself as principled solution for reliable web automation that strategically balances exploration with safety and long-term foresight."
        },
        {
            "title": "REPRODUCIBILITY STATEMENT",
            "content": "To support reproducibility, we release the full implementation of WebOperator at: https: //github.com/kagnlp/WebOperator. The repository includes source code, configuration files, and scripts to reproduce all experiments reported in this paper. Specifically, it provides: (i) an implementation built on the open-source BrowserGym framework, (ii) benchmark configurations for WebArena, WebArena-lite, and WebVoyager following official evaluation protocols, (iii) hyperparameter settings including search budget, frontier budget, and thresholds for destructive/terminating actions, and (iv) logs of experiments for verification of reported results. All experiments can be reproduced using the provided scripts with minimal setup."
        },
        {
            "title": "LIMITATIONS",
            "content": "Despite the effectiveness of our tree search framework, there are several limitations and considerations for future work: Highly Dynamic Environments: In highly dynamic or non-deterministic websites, speculative backtracking may always fail and eventually making the process sequential search. Destructive Action Heuristics: While effective in many cases, these heuristics may fail for complex or unconventional interactions, leading to potential irreversible changes in the environment. However, even when the heuristic detection fails, the speculative backtracking mechanism serves as reliable backup to maintain search safety. Reward Model Dependency: Our approach depends on the process reward model to evaluate candidate actions before execution. The overall performance is influenced by the accuracy and generalization of this model, which may not capture all edge cases. Frontier Budget Constraints: The action queue has limited size, which constrains exploration. Although we incorporate action merging to improve diversity, very large or complex websites may still require more exploration than the current budget allows. Termination Risk: Selecting terminating actions is inherently risky. Incorrect early execution can end the search prematurely, and while we mitigate this by deferring terminating actions, there is no formal guarantee against mistakes. These limitations highlight avenues for future work, including more robust destructive action detection, handling highly dynamic pages, improving process reward models, and extending the framework to multi-user or collaborative environments."
        },
        {
            "title": "REFERENCES",
            "content": "Hyungjoo Chae, Sunghwan Kim, Junhee Cho, Seungone Kim, Seungjun Moon, Gyeom Hwangbo, Dongha Lim, Minjin Kim, Yeonjun Hwang, Minju Gwak, et al. Web-shepherd: Advancing prms for reinforcing web agents. arXiv preprint arXiv:2505.15277, 2025. Yang Deng, An Zhang, Yankai Lin, Xu Chen, Ji-Rong Wen, and Tat-Seng Chua. Large language model powered agents in the web. In Companion Proceedings of the ACM Web Conference 2024, pp. 12421245, 2024. 11 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Alexandre Drouin, Maxime Gasse, Massimo Caccia, Issam Laradji, Manuel Del Verme, Tom Marty, David Vazquez, Nicolas Chapados, and Alexandre Lacoste. Workarena: How capable are web agents at solving common knowledge work tasks? In Forty-first International Conference on Machine Learning, 2024. Haishuo Fang, Xiaodan Zhu, and Iryna Gurevych. Inferact: Inferring safe actions for llm-based agents through preemptive evaluation and human feedback. arXiv e-prints, pp. arXiv2407, 2024. Apurva Gandhi, Graham Neubig, and Mahir Labib Dihan. Go-browse: Training web agents with structured exploration. arXiv preprint arXiv:2506.03533, 2025. Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Yong Dai, Hongming Zhang, Zhenzhong Lan, and Dong Yu. Webvoyager: Building an end-to-end web agent with large multimodal models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 68646890, 2024. Shiqi He, Yue Cui, Xinyu Ma, Yaliang Li, Bolin Ding, and Mosharaf Chowdhury. Branch-andbrowse: Efficient and controllable web exploration with tree-structured reasoning and action memory. arXiv preprint arXiv:2510.19838, 2025. Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 22252240, 2022. Jing Yu Koh, Stephen McAleer, Daniel Fried, and Ruslan Salakhutdinov. Tree search for language model agents. arXiv preprint arXiv:2407.01476, 2024. Xiao Liu, Tianjie Zhang, Yu Gu, Iat Long Iong, Song XiXuan, Yifan Xu, Shudan Zhang, Hanyu Lai, Jiadai Sun, Xinyue Yang, et al. Visualagentbench: Towards large multimodal models as visual foundation agents. In The Thirteenth International Conference on Learning Representations. Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip Yu, et al. survey of webagents: Towards next-generation In Proceedings of the 31st ACM ai agents for web automation with large foundation models. SIGKDD Conference on Knowledge Discovery and Data Mining V. 2, pp. 61406150, 2025. Junhong Shen, Atishay Jain, Zedian Xiao, Ishan Amlekar, Mouad Hadji, Aaron Podolny, and Ameet Talwalkar. Scribeagent: Towards specialized web agents using production-scale workflow data. arXiv preprint arXiv:2411.15004, 2024. Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and Ming Zhou. Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers. Advances in neural information processing systems, 33:57765788, 2020. Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, and Graham Neubig. Agent workflow memory. arXiv preprint arXiv:2409.07429, 2024. Ke Yang, Yao Liu, Sapana Chaudhary, Rasool Fakoor, Pratik Chaudhari, George Karypis, and Huzefa Rangwala. Agentoccam: simple yet strong baseline for llm-based web agents. In The Thirteenth International Conference on Learning Representations, 2025. Ruichen Zhang, Mufan Qiu, Zhen Tan, Mohan Zhang, Vincent Lu, Jie Peng, Kaidi Xu, Leandro Agudelo, Peter Qian, and Tianlong Chen. Symbiotic cooperation for web agents: Harnessing complementary strengths of large and small llms. CoRR, 2025a. Yao Zhang, Zijian Ma, Yunpu Ma, Zhen Han, Yu Wu, and Volker Tresp. Webpilot: versatile and autonomous multi-agent system for web task execution with strategic exploration. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 2337823386, 2025b. Zhisong Zhang, Tianqing Fang, Kaixin Ma, Wenhao Yu, Hongming Zhang, Haitao Mi, and Dong Yu. Enhancing web agents with explicit rollback mechanisms. arXiv preprint arXiv:2504.11788, 2025c. 12 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Boyuan Zheng, Zeyi Liao, Scott Salisbury, Zeyuan Liu, Michael Lin, Qinyuan Zheng, Zifan Wang, Xiang Deng, Dawn Song, Huan Sun, et al. Webguard: Building generalizable guardrail for web agents. arXiv preprint arXiv:2507.14293, 2025. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. Language agent tree search unifies reasoning, acting, and planning in language models. In Proceedings of the 41st International Conference on Machine Learning, pp. 6213862160, 2024. Shuyan Zhou, Frank Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, et al. Webarena: realistic web environment for building autonomous agents. In The Twelfth International Conference on Learning Representations. WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment"
        },
        {
            "title": "A ACTION GENERATION AND SELECTION",
            "content": "A."
        },
        {
            "title": "INPUT PROCESSING",
            "content": "A.1.1 REPHRASED INSTRUCTION To improve LLM understanding and performance, we reformulate the user instruction into more LLM-friendly version. This involves clarifying ambiguities, emphasizing important details, and highlighting potential edge cases the model should consider. The rephrased goal helps guide the agents reasoning and ensures that the input is structured in way the model can interpret reliably. The complete prompt template used for generating rephrased instructions is shown in Listing 2 and an example rephrased instruction shown in 3. A.1.2 ADAPTIVE OBSERVATION SPACE The agent receives flattened representation of the accessibility tree as input. However, this alone can make it difficult to determine whether the page is scrollable or whether scrolling would be beneficial. We adapt the observation space based on the size of the accessibility tree and context window constraints: Small accessibility trees: When the tree is relatively small and fits within the models context window, the entire page is provided as input, and scrolling is disabled. This ensures the agent has complete context without needing to scroll. Large accessibility trees: When the tree is large or would exceed the models context window, only visible elements in the current viewport are provided as input, and scrolling is enabled. This prevents the agent from being overwhelmed while still allowing exploration of off-screen elements. This strategy balances context completeness with tractability, enabling better decision-making for actions such as scrolling while respecting the models input limitations. A.1.3 INCORPORATING ALERTS INTO THE ACCESSIBILITY TREE JavaScript alert dialogs produce pop-ups in the browser that are not part of the standard accessibility tree. However, these alerts can contain important information, such as error messages or confirmation prompts, which may affect task progress or decision-making. To address this, we detect alerts during execution and include them as nodes in the accessibility tree. This allows the agent to reason about their content and handle them appropriately, integrating these previously hidden signals into action generation. A.1.4 CONCISE HISTORY REPRESENTATION major challenge in web navigation is the large context requirement: the agent needs to remember previous steps to make informed decisions, but including the full trajectory (observations, thoughts, actions) quickly exceeds the models context window. To address this, we use concise trajectory representation: At each step, the agent is prompted to generate summary of the current observation. In the context for subsequent steps, we provide only the summaries of the last steps (observation summary, thought, action) rather than the full raw observations. This approach allows the agent to maintain meaningful memory of the trajectory while keeping the context size manageable. By summarizing observations, we provide compact yet informative history, enabling the agent to reason over previous steps without overwhelming the model. A.1. INTEGRATING PAST EXPERIENCE Humans rarely interact with websites purely by exploration; they rely on past experiences, such as remembering how login form was filled or which sequence of clicks led to desired page. Inspired 14 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment by this, we enhance input formation with retrieval-based context, allowing the agent to incorporate relevant prior interactions from static database of past trajectories collected in advance, as in GoBrowse (Gandhi et al., 2025). Purely context-based inputs often fail to capture repetitive interaction patterns, e.g., filling out profile form or navigating to settings, which typically follow similar sequences even if minor details like button labels or DOM structures change. At each step, the agent encodes the current observation, retrieves the most similar (observation, thought, action) tuples from the database, and includes them in the prompt. This enriches the models input with relevant past experience, improving efficiency, robustness to minor UI variations, and producing more human-like reasoning by leveraging prior knowledge instead of relying solely on immediate context. A.1.6 DYNAMIC ACTION SPACE In web environments, not all actions are valid in every state. To improve agent efficiency and reduce irrelevant exploration, we introduce conditional action space, where certain actions are only available under specific conditions: scroll Enabled only when the observation contains visible elements that can be scrolled. select option Enabled only when there is at least one option element present in the observation. tab close, tab focus Enabled only when multiple tabs are open. go back, go forward Enabled only when navigation history allows moving backward or forward. By conditioning the action space in this way, the agent is prevented from generating actions that are impossible or meaningless in the current state. This not only reduces the complexity of decisionmaking but also improves context relevance and reduces uninformative errors in the trajectory. Category Basic Actions Tab Operations Page Operations Workflow Management Table 5: The dynamic action space of WebOperator . Description Action Type click Click at an element fill Fill an element scroll Scroll up and down select option Choose an option from dropdown or select menu Focus on the i-th tab Open new tab Close current tab Visit the last URL Undo go back Go to URL tab focus new tab tab close go back go forward goto When Applicable? Always Always Page is too long Dropdown/select element present is Multiple tabs are open Always Multiple tabs are open Previous page exists in history Previous action was go back Always stop Stop with an answer Always A.2 OUTPUT PROCESSING At each decision step, the agent produces structured output capturing its reasoning and interaction with the environment. Specifically, the output consists of three components: Thought: The agents internal reasoning, capturing why it chooses particular action. Action: The concrete operation to perform in the environment, such as clicking button or entering text. Observation Summary: concise representation of the current state, highlighting relevant elements and changes for subsequent reasoning steps. 15 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment This structured format ensures that the models outputs are interpretable and can be fed back into future steps. By explicitly separating reasoning, action, and environment summary, the agent maintains clear and reusable decision trace throughout the interaction. A.2.1 ACTION VALIDATION LOOP Some generated actions may lead to execution errors, making them uninformative for the trajectory. To address this, we introduce predictive action validation mechanism that filters likely failures before executing them in the main environment. Validation is performed using hybrid approach: Simple checks: For most actions, validation is done using the current accessibility/DOM tree or simple heuristics (e.g., checking if button is disabled or field is read-only). These checks are lightweight and do not modify the environment. Speculative tab checks: For complex cases where success cannot be determined from the DOM alone (e.g., verifying whether URL is valid), the framework opens new tab in the same browser context. This preserves sessions and authentication. The URL is loaded, the page is inspected, and then the tab is closed, leaving the main environment unchanged. Only actions predicted to succeed are executed in the agents working environment. If an action fails validation, feedback is provided to the agent and an internal retry is allowed. Importantly, these feedback-retry steps are not recorded in the trajectory, keeping the history clean and informative. Common error scenarios include: Generated actions that are syntactically invalid or not included in action space. Actions with incorrect parameters. Attempts to fill read-only fields or click disabled buttons. Attempts to interact with elements that do not exist in the current observation. Attempts to access invalid URLs. A.2.2 AUTO CORRECTION While generating actions, agent sometimes make minor mistakes which can easily be corrected without retrying. For example, if agent generates multiple action instead of single action, WebOperator chooses the first one. Additionally, if agent makes mistake in the syntax of an action, for example generates fill(24, Hello World, false) instead of fill(24, Hello World, False), WebOperator automatically capitalize the false to False. A.2.3 RECOVERY ASSISTANCE WebOperator tries to avoid errors by Action validation, but despite that even if an execution error occurs it provides detailed feedback to agent. Also, in some cases uses predefined actions. For example, if an invalid page appears (e.g., 404) WebOperator uses the action go back or tab close based on the context. Also, if agent faces captcha, WebOperator allows human intervention to escape from that. A.2.4 GENERATING MULTIPLE CANDIDATE ACTIONS At each step, relying on single action can limit coverage and increase the risk of failure. Generating multiple candidate actions instead allows the agent to compare alternatives and select the most promising path. Simply sampling multiple times from the same prompt often yields low diversity, since all samples share identical context. To improve variety, we systematically vary the input itselffor example, by adjusting the amount of navigation history included, injecting past experiences via retrieval, or rephrasing the task goal to reduce ambiguity. Such input variations produce richer and more diverse candidate actions, improving robustness across different decision points. 16 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Figure 6: Action merging strategy A.2.5 PROCESS REWARD MODEL FOR CANDIDATE ACTIONS At each step, multiple candidate actions must be evaluated before deciding which one to execute. To guide this selection, we employ process reward model, which assigns reward or score to each action based on its likelihood of being productive, without actually executing it in the environment. Formally, let at be candidate action at time t. The process reward model estimates value vt [0, 1] that predicts the expected utility of executing at. Since the full environment state st may not be accessible to the agent (it can include private information such as database entries or browser cookies), the model computes vt based on observable information: (cid:16) vt = fv I, {(o1, a1), (o2, a2), . . . , (ot, at)} (cid:17) where: is the natural language instruction or task goal. oi and ai are the observation and action at step i. fv is the process reward function that predicts the likelihood of an action being productive. Following WebShepherd (Chae et al., 2025), we adopt checklist-based reward model. From the task instruction and initial observation, checklist of sub-goals or expected steps is generated. Candidate actions are then evaluated based on how well they contribute to completing items on this checklist. This approach allows the agent to assign rewards to actions without executing them, providing structured and interpretable measure of expected productivity, which can be used to efficiently rank and select actions. A.2.6 ACTION MERGING FOR EFFICIENT EXPLORATION Multiple candidate actions may target the same element or have the same effect, leading to redundant exploration if treated independently. We implement action merging to address this: semantically equivalent actions are identified and their predicted rewards are combined (e.g., summed) before selection. For example, if actions (A, rA = 0.4), (B, rB = 0.5), and (C, rC = 0.4) are generated and and are equivalent, merging gives + 0.8 vs 0.5, prioritizing the collectively stronger option. This improves efficiency, reduces redundant exploration, and favors actions with higher overall likelihood of success. WebOperator merge actions based on 4 criteria. 1. If two actions are exactly same. Which means function name and all parameters. 2. For multiple stop actions, we can safely merge them as only the highest rewarded action is considered for termination. 3. For multiple fill actions, if the input text becomes the same after normalizing, we will merge them."
        },
        {
            "title": "B EXPERIMENT DETAILS",
            "content": "B.1 MODEL We have used GPT-4o for our experiments. We have used temperature 0.7 for action generation. 17 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment B.2 RETRIEVAL"
        },
        {
            "title": "For",
            "content": "that we have used the dataset For retrieving past experience we first need database where each row contains goal,current observation,though,action. from Go-Browse (Gandhi et al., 2025), which proposes method for automatically collecting diverse and realistic web agent data at scale through structured exploration of web environments. We first needed to preprocess the dataset as the urls in the observation depends on how we host webarena. For example, base url of Reddit website in Go-Browse is http://ec2-3-148-123-246.us-east-2.compute.amazonaws.com:9999, which we needed to modify to http://localhost:9999, to make it consistent with out setup. To implement semantic retrieval we have used all-MiniLM-L6-v2 (Wang et al., 2020) as the embedding model. The query contains (goal,observation) and we include the (goal,thought,action) as examples in the context of agent. B.3 ACTION GENERATION We have used 3 prompt variations to generate maximum of 3 actions at each step. After generating an action, that is validated by Action Validator. If an action fails validation, feedback is given to agent and need to generate action again. Each agent need to generate valid action within 5 retries. After that it will lead to failure. If all agents become successful, we will get 3 valid actions otherwise we will get less. This is fail-safe architecture, as even if one agent fails other can cover-up that. Also, even if all agent fails at any step we can backtrack and explore other parts of the search tree. B.4 PROCESS REWARD MODEL Checklist Generation. Following WebShepherd, WebOperator first generates checklist that outlines key intermediate milestones for achieving the users goal. Given an instruction I, it produces checklist comprising sequence of natural language subgoals (g1, g2, , gk). This checklist then serves as the foundation for reward prediction, enabling WebOperator to track progress toward the goal. Similar to action generation we use GPT-4o to generate checklists. sample checklist for illustration is provided in Listing 5. Also, the prompt for checklist generation is provided in 4. Reward Generation. The generated checklist is then used by the same model to estimate the agents progress, providing the reward signal R(st) that guides the tree search. In our experiments, we have used the same model for both checklist and reward generation, but it can be different. Since the reward is predicted via token generation, the output resides in discrete space. To obtain continuous reward signal, several mapping strategies can be employed. Following WebShephered, we employ verbalizer (Hu et al., 2022) to estimate soft probabilities over label tokens (e.g., Yes, No, and In Progress) using the logits from the LM head. At inference time, WebShephered generate the feedback (I, C, o, a) and compute the reward for each checklist item using the probabilities of Yes and In Progress tokens follow: rk(o, a) = 1 (cid:88) (YesI, C, o, a, ) + 0.5 (In ProgressI, C, o, a, ), (1) where denotes the number of checklist and rk is the score assigned to the kth response. The final reward is computed as the average: r(o, a) = (cid:80)K k=1 rk(o, a). Prompt used to assign rewards is shown in 6."
        },
        {
            "title": "C SEARCH ALGORITHM",
            "content": "Initialization Start from the initial state s0 with observation o0. Initialize the search tree with root node s0 3, and the frontier as priority queue of unexecuted actions, initially empty. Main Loop At each iteration: 3As we dont have access to the full state, we store only the accessible states (or observation) in each tree node WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment 1. Expansion: If the current state sc has not been expanded, generate candidate actions ai from observation oc using the LLM agent. 2. Scoring: Score each action using the process reward model without execution. Unlike prior works (Koh et al., 2024; Zhang et al., 2025b) that rely on executing actions and scoring the resulting statesan approach often limited to simulated environments or reversible actions. 3. Merging: Merge equivalent actions (e.g., clicking the same element) by aggregating their scores (summing rewards) to reflect combined promise. 4. Tree Update: For each merged action ai, add it as an outgoing edge from sc in (target state pending execution). 5. Frontier Update: Add the merged actions to F. 6. Action-Aware Selection: Select the most-promising action from using multi-criteria approach that considers both reward score and action type (e.g., prioritizing navigation actions over data entry). 7. Termination: If is terminating action, return the solution trajectory from s0 to sorigin in . 8. Backtracking: If sorigin = sc, attempt backtracking using speculative execution. If backtracking is infeasible (due to dynamic content changes or missing UI elements), remove from and repeat Step 6. 9. Execution: Execute in the browser, resulting in new state snew with observation onew. 10. Tree Expansion: Add snew to and link to snew. 11. State Transition: Set sc snew and continue. The main search procedure is detailed in Algorithm 1, which uses the queue management, destructive action detection, action selection policy and backtracking functions defined in Algorithms 4, 2, 5 and 3."
        },
        {
            "title": "D BACKTRACKING",
            "content": "Backtracking is crucial operation in tree search for web automation. In our search algorithm, actions are selected based on priority function that estimates their potential utility. As result, the agent may need to execute an action that was generated from previous state rather than the current one. In WebOperator, we define backtracking as the process of navigating the agent from the current state to previous state where promising action was originally proposed. This process generally involves two steps: (1) restoring the environment to state corresponding to an ancestor of the target state, and (2) executing the sequence of actions required to reach the target state. In an ideal scenario, to backtrack from current state sc to target state st, Ideal Backtracking. the agent would: 1. Identify the lowest common ancestor (LCA)4 of sc and st in the search tree. 2. Undo all actions from sc to the LCA, restoring the environment to the LCA state. 3. Replay the actions from the LCA to st, reaching the target state. Challenges of Action Undo. Undoing actions in web environments is often non-trivial: Safe actions (affecting temporary state) can typically be reversed. Destructive actions (modifying persistent state) may not have defined inverse. Many actions, such as clicks, form submissions, or dynamic content changes, are nondeterministic, making perfect reversal unreliable. As result, executing ideal backtracking directly in the main environment is not feasible. Naive Backtracking. Prior work (Koh et al., 2024) restores the root state by reseting the environment and replays the entire sequence of actions to reach the target state. While straightforward, this approach is inefficient, as it requires executing all actions from the root to the target state. 4The lowest common ancestor is the deepest node that is an ancestor of both sc and st. 19 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Optimized Backtracking. WebOperator introduces an improved backtracking mechanism that addresses both efficiency and reliability concerns. Efficiency. To reduce replay overhead, WebOperator employs checkpoint-based state jumping. state is marked as checkpoint when its webpage observation remains unchanged under refresh and its URL differs from that of its parent. Such states are safe to revisit directly because they are refresh-stable and represent distinct navigation points, ensuring that jumping to their URL reliably reconstructs the same underlying environment without requiring prior UI interactions. During backtracking, the agent jumps to the closest checkpoint of st via URL navigation, then replays only the minimal UI interactions (e.g., scrolling, form filling) needed to reconstruct st. This strategy avoids unnecessary intermediate steps by leveraging the determinism of URL-based navigation: navigate to the nearest checkpoint, then apply only the incremental UI operations required to recover the exact target state. Reliability. To handle non-deterministic behaviors, WebOperator employs speculative backtracking with snapshot validation. Instead of replaying actions directly in the main environment, the agent attempts backtracking in parallel browser tab. Before executing each stored action, the agent compares the current observation in the parallel tab with the corresponding stored snapshot of the target state st. If any mismatch indicates that the state is no longer reproducibledue to randomness, dynamic content changes, or UI driftthe backtracking attempt is immediately aborted, leaving the main environment unchanged. If all actions replay successfully and all snapshots match, the reconstructed state is committed to the main environment. This speculative execution prevents unintended side effects and ensures reliable state restoration even in non-deterministic web environments. key challenge arises with actions such as tab focus(index), whose behavior depends on tab indices that may differ between the actual and speculative environments. To address this, WebOperator dynamically remaps tab indices to maintain consistency. For instance, when simulating backtrack from state with open tabs, an action like tab focus(index) in the original sequence is transformed into tab focus(N + index) (using relative indexing) to align with the temporary tab configuration. Together, these mechanisms make backtracking both efficient and reliable, allowing the agent to reach target states while minimizing unnecessary actions and handling web environment dynamics. ACCESSIBILITY TREE-BASED OBSERVATION COMPARISON. To robustly verify UI state equivalence during backtracking, WebOperator compares accessibility tree (AX tree)5 structures with semantic flexibility instead of requiring exact structural matches, which would fail on real-world dynamic webpages. Pivotal Node. When WebOperator performs an action (e.g., clicking button, typing into text field, choosing menu option), it identifies the corresponding node for that UI element in the AX tree of the current observation. This node is designated as the pivotal node. During normal forward navigation, WebOperator stores each AX tree snapshot and records the pivotal node for the upcoming action. Backtracking Verification. When backtracking to previous observation, the system must ensure that the previously executed action is still valid in the current page state. To do so, it checks Figure 7: Pivotal node and its context in the accessibility tree 5The accessibility tree is structured representation of webpages elements, exposing their roles, states, and properties to assistive technologies and programmatic agents. 20 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment whether the pivotal node still exists and remains semantically equivalent. The comparison proceeds in three steps: 1. Node Identity Check: Using the unique node identifier recorded earlier, WebOperator checks whether node with the same ID is present in the current AX tree. If missing, observations differ, backtracking mismatch. 2. Node Equivalence Check: If the node exists, WebOperator compares the semantic attributes of the node (e.g., role, label, value, enabled/disabled state). If not equivalent, mismatch. 3. Contextual Neighborhood Check: For additional stability, WebOperator compares the pivotal nodes local structural context: its ancestors its own descendants children of its ancestors This localized region (illustrated in Fig. 7) ensures that the UI around the action-critical element has not significantly changed in way that could invalidate the action. If the context matches, observations are considered equivalent. GENERALIZATION TO REAL-WORLD WEBSITES. As shown in Table 6, WebOperator achieves 63.57% accuracy on the WebVoyager subset, surpassing AgentOccam (48.84%). Improvements are most pronounced on knowledgeintensive or structurally complex websites such as ArXiv (+31.25%) and HuggingFace (+17.65%), indicating strong robustness to deep navigation and multi-step decisionmaking. Additionally, WebOperator avoids catastrophic failures seen in AgentOccam (e.g., BBC News: 0.00% 50.00%), demonstrating more reliable behavior under ambiguity. Performance saturates on straightforward transactional sites such as Amazon and Booking, where both methods achieve near-perfect accuracy. Conversely, on direct retrieval sites like Google Search, AgentOccam performs slightly better, highlighting trade-off: WebOperator excels in decision-heavy environments but may incur overhead when the optimal action path is trivial."
        },
        {
            "title": "G QUALITATIVE EXAMPLE",
            "content": "Table 6: Accuracy (%) of AgentOccam and WebOperator on WebVoyager-subset. Website AgentOccam WebOperator Allrecipes (#4) Amazon (#1) Apple (#7) ArXiv (#16) BBC News (#2) Booking (#2) Cambridge Dict (#9) Coursera (#2) ESPN (#10) Google Map (#9) Google Search (#16) Huggingface (#17) Wolfram Alpha (#34) Overall (#129) 50.00 100.00 28.57 31.25 0.00 100.00 66.67 50.00 30.00 22.22 81.25 47.06 52. 48.84 75.00 100.00 28.57 62.50 50.00 100.00 77.78 100.00 30.00 44.44 75.00 64.71 70.59 63.57 Figure 8 shows qualitative walkthrough of our tree-search process for the task webarena.421. 21 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Figure 8: Step-by-step tree search corresponding to the overview in Figure 1 (Task: webarena.421). 22 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment"
        },
        {
            "title": "H ERROR ANALYSIS",
            "content": "We identify key factors limiting WebOperators performance, stemming from both evaluation framework constraints and inherent autonomous web navigation challenges. Action Selection and Termination Challenges. Incorrect Termination: Success hinges on the final action; incorrect reward assignment or lack of productive actions can lead to premature or wrong termination. Destructive Action Side Effects: Destructive actions can invalidate states critical to correct solutions. Safety thresholds help but cannot prevent all such dead ends. Task Ambiguity and Domain Knowledge. Performance is constrained by interpreting ambiguous instructions, especially for niche domains. LLM-based rephrasing improves clarity but is limited by the models general knowledge, leading to possible misinterpretations and failures. Web Interface Complexity and Feedback. Non-intuitive UI elements and delayed or uninformative feedback (e.g., generic error pages, Figure 9) hinder diagnosis and recovery, complicating the agents task execution. Figure 9: Filling up the URL field in reddit submission page, leads to 500 Internal Server Error. Which is really hard to understand because the error is not immediate. Agent first fills up URL field, then title, then body and finally submits the post. And then gets the error. So, it is hard to know which step causes the error. Agent tries this again and again, and eventually fails. 23 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Algorithm 1 WebOperator Tree Search Algorithm Require: Initial state s0, instruction I, max depth Dmax, search budget Ensure: Task completion status 1: 2: current node create node(s0) 3: terminating count 0 4: destruction count 0 5: 6: while is not empty do Max priority queue for candidate actions Initialize tree with root node STEP 1: Generate actions and add to queue if depth(current node) < Dmax then candidates GENERATE ACTIONS(current node, I) candidates MERGE ACTIONS(candidates) if there is any terminating action in candidates then terminating count terminating count + 1 end if Q.push all(candidates) end if while true do STEP 2: Select best action from queue (nselected, aselected) SELECT ACTION(Q) if current node = nselected then if not BACKTRACK(current node, nselected) then Need to backtrack first Backtracking failed, select another action Enforce search budget STEP 3: Execute action and adjust tree Task completed successfully Reset queue on destructive actions Reduce search budget Task failed (queue empty) continue else current node nselected end if end if break end while if > then PRUNE QUEUE(Q, B) end if snew execute in env(aselected) new node create node(snew) add edge(current node, new node, aselected) current node new node if is terminating(aselected) then return true end if if is destructive(aselected) then destruction count destruction count + 1 max(B 1, MIN QUEUE SIZE) 29: 30: 31: 32: 33: 34: 35: 36: 37: 38: 39: 40: end if 41: 42: end while 43: return false 24 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment return False Algorithm 2 Destructive Action Detection Require: Current action action, authentication status Ensure: Boolean flag indicating whether action is destructive 1: if user is not authenticated then 2: 3: end if 4: if action.type is click then 5: 6: 7: 8: if selected element is not button then return False end if if button label indicates navigation or transient action (e.g., back, search, refresh, export) then return False return False end if if button has popup or is disabled then 9: 10: 11: 12: 13: 14: 15: else if action.type is fill and action.args.press enter is True then 16: 17: end if 18: return False end if return True return True Otherwise, treat as potentially destructive path, rollback node FIND PATH(current node, target node) Open new tabs to match the rollback node and focus on the active tab of the rollback node. for each action in path do EXECUTE ACTION(a) oactual GET OBSERVATION() oexpected GET STORED OBS(node after(a)) if not COMPARE OBSERVATION(oactual, oexpected) then Close new tabs and focus back on the original tab. return false Discard Backtracking Commit Backtracking end if Algorithm 3 Speculative Backtracking 1: function BACKTRACK(current node, target node) 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: end function 15: 16: function COMPARE OBSERVATION(oactual, oexpected) pivotal node GET PIVOTAL NODE(oexpected) 17: if not NODE EXISTS(oactual, pivotal node) then 18: 19: 20: 21: 22: 23: 24: 25: end function end for Close old tabs. end if return true return false return false end if if not COMPARE NEIGHBORHOOD(oexpected, oactual, pivotal node) then 25 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Process reward model prediction 3: safe, 2: destructive, 1: terminating end for for = 1 to MAX RETRY do fv(I, trajectory, a) GET PRIORITY CLASS(a) candidates.push((node, a, r, c)) Access global variables terminating count actions GENERATE CANDIDATE ACTIONS(node, I) candidates for each candidate action in actions do get observation(node) get history(node) retreive examples(I, o) IR rephrase(I) candidates for each variation in INPUT VARIATIONS(I, H, E, IR) do Algorithm 4 Core Functions for Action Management 1: function GENERATE ACTIONS(node, instruction I, queue Q) 2: 3: 4: 5: 6: 7: 8: 9: 10: end function 11: 12: function GENERATE CANDIDATE ACTIONS(node, instruction I) 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: end function 30: 31: function PRUNE QUEUE(queue Q, budget B) 32: 33: 34: 35: 36: 37: 38: 39: 40: end while 41: 42: end function generate action(variation) valid VALIDATE ACTION(node, a) if valid then end if Group actions in by priority class for each priority class in (1, 2) do candidates candidates {a} break Keep only the action with the highest reward in class end for while > do end for return candidates if then return end for end if Find and remove the action with the smallest reward from 26 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Let KT be the threshold for discovered terminating actions Let KD be the threshold for executed destructive actions Access global variables terminating count, destruction count deferred queue if > Or COUNT DESTRUCTIVE ACTIONS(Q) > 1 then (n, a, r, c) Q.pop() if = 1 & terminating count < KT then deferred queue.push((n, a, r, c)) while is not empty do Algorithm 5 Action Selection Policy 1: function SELECT ACTION(queue Q) 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: end if return (n, a) end if end while else if = 2 then end if else Q.push all(deferred queue) return (n, a) Q.push all(deferred queue) if (a, r, c) = 1 & destruction count KD then (n, a, r, c) arg max(n,a,r,c)Q,c=1 {(n, a, r, c)} return (n, a) 26: 27: 28: 29: 30: 31: 32: 33: 34: 35: 36: 37: 38: 39: 40: 41: 42: 43: 44: 45: 46: 47: 48: 49: while is not empty do (n, a, r, c) Q.pop() if = 3 then return (n, a) Process safe actions and terminating actions meeting threshold Get highest rewarded action Safe action - execute immediately else if = 1 & terminating count KT then Terminating meeting threshold return (n, a) else deferred queue.push((n, a, r, c)) end if end while if deferred queue is empty then return None end if Defer other actions No action found Special case for terminating actions when destruction count is high deferred queue if (a, r, c) = 1 & destruction count KD then (n, a, r, c) arg max(n,a,r,c)Q,c=1 {(n, a, r, c)} return (n, a) end if Find best terminating action Remove from queue if (a, r, c) = 2 then (n, a, r, c) arg max(n,a,r,c)Q,c=2 {(n, a, r, c)} return (n, a) end if (n, a, r, c) Q.pop() return (n, a) 50: 51: 52: end function Execute any remaining destructive action Find best destructive action Remove from queue Execute any remaining terminating action Get highest rewarded action WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment"
        },
        {
            "title": "I PROMPT",
            "content": "Agent Prompt. Listing 1 shows the general prompt template for action generation. full example with all components is available at Listing 7. Rephraser Prompt. Listing 2 shows the prompt used to rephrase task instruction. Reward Model Prompt. Listing 4 shows the prompt used for checklist generation and Listing 6 shows the prompt used for reward estimation. Listing 1: Action generation prompt template You are an expert web automation agent that performs precise actions on web pages to accomplish user goals. Your task is to analyze the current page state and select the single best next action. >> Instructions Review the current state of the page and all other information to find the best possible next action to accomplish your goal. Your answer will be interpreted and executed by program, make sure to follow the formatting instructions. {input specifications} >> Action Space You are ONLY allowed to use the following action commands. {action space} >> Generate the response in the following format: # Observation Description Describe the current page state and extract key information relevant to the goal. Focus on: 1. CONTENT EXTRACTION: If this page contains information needed for the final answer, extract and record it explicitly. This step is crucial for ensuring the final answer is accurate and complete. Dont miss any critical details. 2. RELEVANT ELEMENTS: Identify interactive elements, data, or content that helps accomplish the objective Format your observation to help future answer extraction by being specific about: - Exact values, numbers, prices, names, dates found on the page - Location of critical information (which sections, forms, tables contain target data) # Reason Explain your rationale clearly. If the current interface appears to fulfill your objective, consider: - Could there be hidden alternatives? - Is there ambiguity in whats being shown (e.g., default sort orders)? - Would it be safer to explore before committing? Be cautious. Its OK to say: \"This appears correct, but want to confirm it by checking X.\" Analyze previous actions. Do not get stuck in loop by repeatedly trying the same action. # Action Select your action here. Strictly adheres to the given format. **Only issue one single action **. Listing 2: Instruction rephraser prompt You are rephraser module that helps task-solving agent better understand web-based task. Given task description, you should: 1. Rephrase the task in clearer language without changing its meaning. 2. Identify logical subgoals needed to accomplish the task. 3. Detect any vague or ambiguous terms. 4. Identify possible implicit assumptions that need verification. 5. List cautions - things the agent should be skeptical about when interpreting the task or interacting with the interface. Do not rely on any specific knowledge of websites, domains, or UI layouts. Stay generalpurpose. >> Task Objective {task_description} >> Generate the response in the following format: # REPHRASED TASK: <Clear, literal paraphrase of the original task. No assumptions.> 28 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment # SUBGOALS: - <Subgoal 1> - <Subgoal 2> - ... # AMBIGUITIES OR ASSUMPTIONS: - <Potentially vague or implied elements in the task> # CAUTIONS: - <Any points where the agent should validate its understanding rather than assume> Listing 3: Example rephraser output for the task Set my gitlab status as Resting due to leg injury. # REPHRASED TASK: Change the users status message in the GitLab application to the text \"Resting due to leg injury\". # SUBGOALS: - Verify that the agent is currently authenticated on GitLab or can log in. - Locate the user profile or status editing interface within GitLab. - Enter the exact status text \"Resting due to leg injury\". - Save or confirm the status change. - Confirm that the status display reflects the new text. # AMBIGUITIES OR ASSUMPTIONS: - Which GitLab instance or URL is being used (e.g., gitlab.com, self-hosted server). - Whether the user is already logged in or needs authentication. - The exact UI element that allows status editing (profile menu, settings page, sidebar, etc.) . - Whether there is character limit, special formatting, or required emoji to display the status. - Whether the task refers to the personal status or project/team status. # CAUTIONS: - Do not assume the status field is always visible; first verify its presence. - Check that the status message \"Resting due to leg injury\" does not exceed any length limits or contain disallowed characters. - Ensure that the change is applied to the correct user account-verify the identity before editing. - After saving, confirm visually that the status update appeared; dont just rely on confirmation dialog. - Be aware of any permissions or two-factor authentication that might block status changes. You are an AI assistant tasked with generating structured checklists that highlight key subgoals necessary to complete task. Listing 4: Checklist generation prompt # Task Description Generate checklist which are key milestones for achieving the given instruction. First, provide concise subgoal analysis in single paragraph summarizing the required interactions. Then, based on this, generate the checklist with brief description. Note: If the target website requires login, assume the user is already logged in and starts from an authenticated session. So, dont include any login steps in the checklist. # Given Information ## User Instruction {intent} ## Current State ### Current URL {start_url} ### AXTREE Note: [bid] is the unique alpha-numeric identifier at the beginning of lines for each element in the AXTree. Always use bid to refer to elements in your actions. {text_observation} Listing 5: Example generated checklist for Set my gitlab status as Resting due to leg injury. Checklist 1: Log into Your GitLab Account - Ensure you are signed into your GitLab account to access account settings. Checklist 2: Navigate to Account Settings - Locate and open the account menu to find the option to manage your GitLab status. Checklist 3: Set GitLab Status - Access the section where you can set your GitLab status and select \"Resting due to leg injury\" to apply your custom status. 29 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Listing 6: Judge prompt You are an expert evaluator of web agent. Your task is to assess how helpful given agents THOUGHT and ACTION is in making progress toward the users goal, based on the current state of the webpage. # Task Description Evaluate how well the agents THOUGHT and ACTION satisfy each item in the checklist using the task instruction, trajectory (including previously completed steps), current webpage state, the agents latest response and checklist completion after (n-1)th step. Start by writing concise paragraph summarizing the agents overall performance. Refer to the reasoning provided in the trajectory, and discuss whether the THOUGHT is appropriate and the ACTION moves the task forward. Then, assess each checklist item individually using the following labels: - Yes: The item is fully and clearly satisfied, either in the current response or previously completed. - In Progress: There is meaningful partial progress toward completing the item. - No: The item is not satisfied due to ambiguity, insufficient evidence, or lack of progress. # Given Information ## User Instruction {intent} ## Trajectory {trajectory} ## AXTREE Note: [bid] is the unique alpha-numeric identifier at the beginning of lines for each element in the AXTree. Always use bid to refer to elements in your actions. {text_observation} ## Checklist {checklist} ## Last Step Checklist Completion {progress} ## Agents Response THOUGHT: {thought} ACTION: {action} Listing 7: Example Prompt with all components >> Instructions Review the current state of the page and all other information to find the best possible next action to accomplish your goal. Your answer will be interpreted and executed by program, make sure to follow the formatting instructions. >> Goal Set my gitlab status as \"Resting due to leg injury\". # REPHRASED TASK: Change the users status message in the GitLab application to the text \"Resting due to leg injury\". # SUBGOALS: - Verify that the agent is currently authenticated on GitLab or can log in. - Locate the user profile or status editing interface within GitLab. - Enter the exact status text \"Resting due to leg injury\". - Save or confirm the status change. - Confirm that the status display reflects the new text. # AMBIGUITIES OR ASSUMPTIONS: - Which GitLab instance or URL is being used (e.g., gitlab.com, self-hosted server). - Whether the user is already logged in or needs authentication. - The exact UI element that allows status editing (profile menu, settings page, sidebar, etc.) . - Whether there is character limit, special formatting, or required emoji to display the status. - Whether the task refers to the personal status or project/team status. # CAUTIONS: - Do not assume the status field is always visible; first verify its presence. - Check that the status message \"Resting due to leg injury\" does not exceed any length limits or contain disallowed characters. - Ensure that the change is applied to the correct user account-verify the identity before editing. - After saving, confirm visually that the status update appeared; dont just rely on confirmation dialog. - Be aware of any permissions or two-factor authentication that might block status changes. >> Previous Actions and Observations Observation #1: (Url: http://127.0.0.1:8023/) The current view is the GitLab dashboard page. In the header navigation there is link with id 201 labeled \"Byte Blaze\" next to the avatar image. No status or profile editing controls are visible on this dashboard view. The GitLab user status can be edited from profile or avatar menu, which is typically accessed by clicking the user avatar link. Reason #1: To set status, we must first navigate to the users profile area where the status widget is available. The only accessible element that leads to the profile is the avatar link 30 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment 201. No other interactive elements on the dashboard provide direct way to edit the status . Action #1: click(201) >> Current step: 2 >> Currently open tabs Tab 0 - Projects Dashboard GitLab (http://127.0.0.1:8023/) -> Active >> Current page Accessibility Tree RootWebArea Projects Dashboard GitLab, focused, url=http://127.0.0.1:8023/ banner [52] link Skip to content, url=http://127.0.0.1:8023/#content-body StaticText GitLab [58] link Dashboard, url=http://127.0.0.1:8023/ntt[xxx] list listitem [64] button , hasPopup=menu, expanded=False list listitem [130] textbox Search GitLab StaticText / list listitem [141] link Create new..., url=http://127.0.0.1:8023/projects/new listitem [153] link Issues, url=http://127.0.0.1:8023/dashboard/issues? assignee_username=byteblaze listitem [157] link Merge requests, url=http://127.0.0.1:8023/dashboard/ merge_requests?assignee_username=byteblaze listitem [171] link To-Do List, url=http://127.0.0.1:8023/dashboard/todos StaticText 2 listitem [175] link Help, url=http://127.0.0.1:8023/help StaticText Help listitem [201] link Byte Blaze, focused, expanded=True, url=http://127.0.0.1:8023/ byteblaze image Byte Blaze, url=https://www.gravatar.com/avatar/99 a4297c867eada2606b9b6973f081f9?s=48&d=identicon list listitem ....... >> Similar Examples from Past Successes Here are 5 similar successful examples from past interactions: Example 1 (relevance: 8009.89): Goal: View the source code of the PyTorch-GAN project Thought: have filled in the search box with PyTorch-GAN, but need to submit this search to see the results. Therefore, will press the Enter key to initiate the search. Action: press(1038, Enter) Example 2 (relevance: 7979.707): Goal: Go to your user profile page to manage account settings. Thought: The users avatar image was clicked, but it seems to be opening the users personal page rather than the profile page. Lets look for more explicit link to the profile page. The menu list in the dropdown contains an option to Edit profile, which is likely to be the link to the users profile page. will click on this option to navigate to the profile. Action: click(213, button=left, modifiers=[]) Example 3 (relevance: 7967.268): Goal: View your user profile Thought: The user has already clicked on their profile icon Byte Blaze, which is the first step to view their user profile. After clicking on the profile icon, the next step would be to click on the Edit profile link to view the profile page. Action: click(213) Example 4 (relevance: 7967.268): Goal: View your user profile Thought: The user has clicked on their name Byte Blaze to navigate to their profile. The next step is to view the users profile. Since the name was clicked, its expected that the users profile page is now loaded. No further action is required to view the users profile. Action: noop() Example 5 (relevance: 7965.269): Goal: View your user profile Thought: The users profile is now visible, as evidenced by the additional profile information such as the profile picture and name. No further action is needed to view the users profile. The next step is to notify the user that their profile is now visible. 31 WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment Action: stop(Your user profile is now visible. You can explore your profile information here.) Use these examples as guidance, but adapt your action to the current context and goal. >> Action Space You are ONLY allowed to use the following action commands. click(bid: str): To click on an element with its numerical ID on the webpage. E.g., click( a51). select_option(bid: str, option: str): To select an option in <select> element. You can specify option value or label to select. E.g., select_option(237, Option 1). In case directly clicking an option returns error, you can try this out. fill(bid: str, value: str, press_enter_after: bool): To type content into field with specific ID. Note that, this function overwrites the existing text in that field. Optionally, it can press Enter after typing. E.g., fill(\"237\", \"example value\", True) or fill(\"237\", \" example value\", False). In case this fill action is related to content writing (e.g., Reddit posts, comments, tweets, blog posts, forum posts, reviews, messages, emails, bios, descriptions), ensure that the \"value\" matches EXACTLY the text specified in the goal. Because your actions will be evaluated by exact string matcher. scroll(direction: str): To navigate the webpage content. E.g., scroll(up) or scroll(down ). In case, page is too long vertically, some elements may be hidden. They can be revealed by scrolling. Such hidden items are usually represented using StaticText [ and StaticText ] goto(url: str): Navigate to url. E.g., goto(http://www.example.com). It is recommended not to try any random url unless you have discovered it in previous interations. new_tab(url: str): Open new tab and navigate to url. It will become the active tab. Example: new_tab(http://www.example.com) tab_focus(index: int): Bring tab to front (activate tab). Example: tab_focus(2) tab_close(): Close the current tab. Example: tab_close() go_back(): To return to the previously viewed page. E.g., go_back(). go_forward(): Navigate to the next page in history. E.g., go_forward(). stop(text: str): To stop interaction. E.g., stop(\"Based on the results of my search, the city was built in 1751.\"). If the task isnt QnA, and you have completed the task, you should call \"stop\" with appropriate message. But if the task is QnA, you should ensure that the \" text\" parameter is consistent with the \"goal\" and observations. Because your answer will be evaluated by exact string matcher. >> Generate the response in the following format: # Observation Description Describe the current page state and extract key information relevant to the goal. Focus on: 1. CONTENT EXTRACTION: If this page contains information needed for the final answer, extract and record it explicitly. This step is crucial for ensuring the final answer is accurate and complete. Dont miss any critical details. 2. RELEVANT ELEMENTS: Identify interactive elements, data, or content that helps accomplish the objective Format your observation to help future answer extraction by being specific about: - Exact values, numbers, prices, names, dates found on the page - Location of critical information (which sections, forms, tables contain target data) # Reason Explain your rationale clearly. If the current interface appears to fulfill your objective, consider: - Could there be hidden alternatives? - Is there ambiguity in whats being shown (e.g., default sort orders)? - Would it be safer to explore before committing? Be cautious. Its OK to say: \"This appears correct, but want to confirm it by checking X.\" Analyze previous actions. Do not get stuck in loop by repeatedly trying the same action. # Action Select your action here. Strictly adheres to the given format. **Only issue one single action **."
        }
    ],
    "affiliations": [
        "Bangladesh University of Engineering and Technology (BUET)",
        "Monash University",
        "Qatar Computing Research Institute (QCRI)"
    ]
}