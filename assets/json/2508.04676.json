{
    "paper_title": "GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay",
    "authors": [
        "Yunan Zhang",
        "Shuoran Jiang",
        "Mengchen Zhao",
        "Yuefeng Li",
        "Yang Fan",
        "Xiangping Wu",
        "Qingcai Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The continual learning capability of large language models (LLMs) is crucial for advancing artificial general intelligence. However, continual fine-tuning LLMs across various domains often suffers from catastrophic forgetting, characterized by: 1) significant forgetting of their general capabilities, and 2) sharp performance declines in previously learned tasks. To simultaneously address both issues in a simple yet stable manner, we propose General Sample Replay (GeRe), a framework that use usual pretraining texts for efficient anti-forgetting. Beyond revisiting the most prevalent replay-based practices under GeRe, we further leverage neural states to introduce a enhanced activation states constrained optimization method using threshold-based margin (TM) loss, which maintains activation state consistency during replay learning. We are the first to validate that a small, fixed set of pre-collected general replay samples is sufficient to resolve both concerns--retaining general capabilities while promoting overall performance across sequential tasks. Indeed, the former can inherently facilitate the latter. Through controlled experiments, we systematically compare TM with different replay strategies under the GeRe framework, including vanilla label fitting, logit imitation via KL divergence and feature imitation via L1/L2 losses. Results demonstrate that TM consistently improves performance and exhibits better robustness. Our work paves the way for efficient replay of LLMs for the future. Our code and data are available at https://github.com/Qznan/GeRe."
        },
        {
            "title": "Start",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1 GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay Yunan Zhang, Shuoran Jiang, Mengchen Zhao, Yuefeng Li, Yang Fan, Xiangping Wu, Qingcai Chen 5 2 0 A 6 ] . [ 1 6 7 6 4 0 . 8 0 5 2 : r AbstractThe continual learning capability of large language models (LLMs) is crucial for advancing artificial general intelligence. However, continual fine-tuning LLMs across various domains often suffers from catastrophic forgetting, characterized by: 1) significant forgetting of their general capabilities, and 2) sharp performance declines in previously learned tasks. To simultaneously address both issues in simple yet stable manner, we propose General Sample Replay (GeRe), framework that use usual pretraining texts for efficient anti-forgetting. Beyond revisiting the most prevalent replay-based practices under GeRe, we further leverage neural states to introduce enhanced activation states constrained optimization method using threshold-based margin (TM) loss, which maintains activation state consistency during replay learning. We are the first to validate that small, fixed set of pre-collected general replay samples is sufficient to resolve both concernsretaining general capabilities while promoting overall performance across sequential tasks. Indeed, the former can inherently facilitate the latter. Through controlled experiments, we systematically compare TM with different replay strategies under the GeRe framework, including vanilla label fitting, logit imitation via KL divergence and feature imitation via L1/L2 losses. Results demonstrate that TM consistently improves performance and exhibits better robustness. Our work paves the way for efficient replay of LLMs for the future. Our code and data are available at https://github.com/Qznan/GeRe. Index TermsLarge Language Models, Continual Learning, Finetune, Replay, Activation State"
        },
        {
            "title": "1 INTRODUCTION",
            "content": "C ONTINUAL learning (CL) of large language models (LLMs) remains challenging for real-world applications. For instance, continual finetuning often degrades general capabilities, particularly over long task sequences. The finetuned model forgets its original world knowledge or basic instruction-following skills [1], [2]. Additionally, the overall performance on sequential downstream tasks often deteriorates due to forgetting of previously learned Yunan Zhang, Shuoran Jiang, Yang Fan, Mengchen Zhao, Xiangping Wu, Qingcai Chen are with the Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China. shuoran.chiang@gmail.com, (E-mail: yfan@stu.hit.edu.cn, wxpleduole@gmail.com, qingcai.chen@hit.edu.cn) zhaomengchen@stu.hit.edu.cn, zhangyunan@stu.hit.edu.cn, Yuefeng Li is with Ysstech Info-Tech Co.,Ltd, Shenzhen. Qingcai Chen and Xiangping Wu are the corresponding authors. (E-mail: wxpleduole@gmail.com, qingcai.chen@hit.edu.cn) Code and Data Website: https://github.com/Qznan/GeRe Fig. 1: Traditional replay vs. GeRe: unlike traditional replay requiring laborious collection of an increasing set of downstream replay samples, GeRe simply employs fixed set of general replay samples to not only retain general capabilities in continual learning, but also enhance the overall performance of learned downstream tasks. The blue oval is the threshold-based margin loss that imposes consistency constraint on neural activation state under GeRe frameworks. tasks, caused by inter-task conflicts. This phenomenon, also known as catastrophic forgetting, often compels practitioners to seek complex CL solutions. However, the contemporary LLM system, marked by architectural bulkiness and computational heaviness, is imperative to call for simple yet stable approach to effectively mitigate forgetting. In this context, our research aims to review and develop an efficient and general anti-forgetting method of CL adapted to the LLM era. Historically, solutions for CL are primarily categorized into three traditional branches: replay-based, regularizationbased, and architecture-based methods [3]. Considering the massive number of parameters in LLMs and their widely accepted fixed structures, it appears prohibitive and impractical to regularize all parameters or frequently expand the architecture for every new task. Thus current practice in LLMs continual learning regularly prioritizes replay-based methods due to its simplicity. For instance, practitioners commonly mix certain proportion of general task samples JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST during finetuning for downstream tasks [4], [5]. However, the underlying mechanisms and optimal strategies of these replay-based methods tailored for LLMs remain insufficiently explored and analyzed. In this work, we (1) systematically revisit the replay mechanisms targeting LLMs under newly introduced general sample replay (GeRe) framework and, (2) present threshold-based margin (TM) loss for activation state constrained optimization. Specifically, we prepares fixed, permanently reusable set of general replay samples (e.g., the commonly used pretraining texts) and leverages the TM loss to maintain consistent neuron activation states, ultimately resisting various forms of forgetting. The approach is motivated by two ideas: (1) From cognitive perspective, learner obtaining superior general capabilities is more likely to achieve better generalization and robustness in downstream tasks. Leveraging its comprehensive knowledge, such learner can reduce conflicts arising from overfitting to specific tasks, thereby mitigating task forgetting. Consequently, it is worth exploring how to utilize general replay samples to retain general capabilities. (2) In the human brain, critical information is sparsely distributed across few activated neurons [6], [7]. Therefore, in replay-based continual learning (replay learning), the activation states of neurons evoked by replay samples may require deeper attention. By designing an activation state constrained optimization, we seek less rigid but more informative target that enables the replay learning to be more robust and generalizable. Through the paper we have explored and answered 2 pressing questions in real-world LLMs continual learning scenario: Q1: Can we simply select fixed set of replay samples once and for all? To retain general capabilities, contemporary strategies for mixing replay samples in LLM training may be as laborious as feature engineering, requiring careful selection of both the proper size and specific replay samples tailored to the particular downstream task. For instance, even with fixed mixing ratio, we still need to frequently resize the replay samples set and select an appropriate subset or superset to adapt to the varying data scale of incoming tasks. For this question, we have empirically validated that constructing fixed set of randomly selected general replay samples (e.g., 1k texts from the widely available general pretraining corpus) can be durably applied to fulfill all replay needs in subsequent tasks, while successfully preserving general capabilities. This becomes more pronounced when integrating replay with feature-based distillation, as it fully exploits information from these limited replay samples rather than merely fitting their explicit labels. To our knowledge, we are the first to propose that fixed set of general replay samples can efficiently adapt to real-world continual learning scenario involving long sequences of tasks under full or LoRA settings, which holds significant practical implications. Q2: Can general replay samples alone facilitate continual learning in sequential downstream tasks, typically without any of task replay samples? Normally, collecting task replay samples from each old task in subsequent learning is necessary to maintain their long-term performance. However, we believe that the learning efficacy of any down2 stream task fundamentally depends on the LLMs general knowledge. For this question, we have encouragingly validated that the aforementioned fixed set of general replay samples, under our optimization approach, can effectively promote the persistent retention of previously learned task knowledge, mitigating the forgetting induces by inter-task conflicts. The results demonstrate the feasibility of conveniently utilizing only predetermined general replay samples to resist task-specific forgetting in future applications. These answers highlight the advantages of the proposed GeRe framework. Furthermore, we enhance feature-based replay learning under GeRe by introducing activation state constrained optimization, which statistically determines activation states and optimizes using threshold-based margin loss. This relatively lightweight constraint on feature values empirically exhibits better robustness and generalizability compared to the conventional yet rigid L1/L2 fitting manner. Our contributions are as follows: 1. GeRe: We first demonstrate that fixed set of predefined general replay samples can be reused throughout the entire continual finetuning process, effectively preserving LLMs original general capabilities. Crucially, replaying any downstream task sample proves unnecessary, as maintaining general capabilities alone enhances overall downstream tasks performance. 2. TM loss: We pioneer comprehensive comparison of commonly used replay-based practices for continual learning in LLMs, exploring their integration with various knowledge distillation strategies. Among these, our proposed threshold-based margin loss, motivated by the previously overlooked activation state constraint, achieves SoTA performance. 3. Our method shows robustness not only to learning ratea critical hyperparameter seriously impacting both knowledge updating and retentionbut also to intrinsic optimization dynamics, as evidenced by optimization landscape visualization, highlighting its practical utility."
        },
        {
            "title": "2 RELATED WORKS\n2.1 Continual Learning",
            "content": "Continual learning, also known as lifelong or incremental learning, refers to the ability of machine learning model to learn from stream of data over time, while retaining knowledge from previous tasks and adapting to new ones without forgetting [8]. Unlike traditional learning paradigms, where models are trained on static datasets, continual learning should addresses the dynamic nature of real-world applications, where data distributions and tasks evolve over time. central challenge in continual learning is the catastrophic forgetting problem, where model tends to forget previously learned knowledge when trained on new tasks [9]. To mitigate this, various strategies have been proincluding replay-based, regularization-based, and posed, architecture-based methods. For replay-based methods like Experience Replay [10] store and replay samples from past tasks to maintain performance, while regularization-based methods like Elastic Weight Consolidation (EWC) [11] introduce regularization term to preserve instance, JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 3 Fig. 2: (a) Flowchart of the GeRe framework using general replay samples, including distillation of hidden states and the derived activation state in offline mode, and continual learning across sequential tasks with mixing general samples for replay. (b) Illustration of threshold-based margin loss, which transforms the hidden values into discrete activation states on both the target and prediction followed by margin loss calculation. important parameters for previous tasks. Similarly, Learning without Forgetting (LwF) [12] uses knowledge distillation to regularize the model by minimizing the divergence between its current and previous outputs. Architecture-based methods allocate distinct subsets of model parameters to different tasks to prevent interference. For example, Progressive Neural Networks (PNNs) [13] expand the network architecture by adding new layer of parameters for each task while freezing existing ones. In addition Mask-Based Methods [14] learns task-specific masks to trigger or suppress parameters dynamically. In the LLM era, continual pretraining or finetuning has become essential for model iteration and advancement. We focus on continual finetuning, where the most common practice involves replay-based methods, which typically incorporate general corpus to preserve the models general capabilities for downstream tasks. In this work, we explore further integration with regularization-based techniques, i.e., the distillation strategy used in LwF. Specifically, we pre-generate and store the feature representations of the replay samples, which are then used as targets within distillation framework to effectively leverage this information. Moreover, we include the LoRA [15] setup since it is widely adopted in finetuning due to its strong generalization and resistance to forgetting. It can be considered as another type of architecture-based method, as it typically trains only small fraction of parameters."
        },
        {
            "title": "2.2 Knowledge Distillation",
            "content": "Knowledge distillation (KD) [16] aim to compress large models into smaller, efficient ones by transferring knowledge from teacher model to student model. This process is achieved by minimizing the difference between their output distributions, where the student learns from the teachers soft labels rather than the original datasets hard labels [17], [18], [19]. KD can be implemented generally with two types: logit-based imitation and feature-based imitation [20]. The former involves matching the predictions and target distributions using the Kullback-Leibler divergence (KL) loss with temperature-based softmax normalization, while the latter focuses on aligning the intermediate representations in the feature space through similarity-based functions. KD has already been applied in continual learning, with the key distinction lying in how the target and prediction are defined. Taking LwF for example, when the new tasks samples arrived, the model preliminarily computed the logits of these samples at the output heads regarding old tasks, served as the distilled pseudo-targets. During subsequent training, the real-time predicted logits at these old tasks output heads are constrained to match the precomputed pseudo-targets. In this case, the teacher and student models are essentially the same model. This self-distillation mechanism [21] enables the model to retain performance on previously learned tasks while adapting to new ones. However, few research emphasizes similarity of feature in KD typically applied for continual learning of LLMs [22]. Our work thereby delves deeper into studying efficient mechanism combining replay and distillation methods, where labels or features of replay samples are pre-distilled to serve as pseudo-targets, enabling persistent fitting of replay samples during continual learning. We empirically compare the effect of using replay samples simply versus leveraging replay samples under both logit-based imitation via KL divergence and feature-based imitation via L1 or L2 function. The study offers comprehensive comparison of diverse replay strategies."
        },
        {
            "title": "3 PROPOSED METHOD",
            "content": "This section provides detailed introduction to the overall process of GeRe framework and the proposed replay-based activation state constrained optimization. As outlined in Fig.2(a), we first collect small-scale set of general samples for permanently available replay. Then these data are proactively distilled using the untuned base LLM to derive JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 the activation threshold, which determines the activation state. Subsequently, continual finetuning is performed on mixed data containing downstream task and general replay samples, jointly optimizing specialized replay-based objective alongside the standard cross-entropy loss. Fig.2(b) illustrates our proposed threshold-based margin (TM) loss, which transforms the given optimization target into activate states through thresholds on both sides and employs margin loss for constraint. (The different optimization targets used by other competitors are shown in Fig. 3.)"
        },
        {
            "title": "3.1 Distilled Activation States",
            "content": "In deep neural networks, neuron activation values refer to the outputs of each layers sub-network. Taking the Transformer-based LLMs as an example, the activation values refer to the output of the feed-forward network within each layer. These activations are progressively passed through residual connections, evolving started from the input and ultimately forming the networks final output. Analogous to the activation states of neurons in the human brain, we propose to categorize the neural network activations into three distinct states: positive activation, negative activation, and non-activation. These states exhibit discrete sparsity patterns while encoding specific semantic information. Building on this, we hypothesize that during continual finetuning, the original activation states represented with general replay samples can effectively reflect the models general capabilities. Therefore, in our replay learning, we employ feature-based imitation to utilize these activations as targets, thereby preserving the essential characteristics of the models learned representations."
        },
        {
            "title": "3.1.1 Feature-Based Distillation\nGiven a general replay sample set D(g) = {s1, s2, . . . , sN }\ncomprising N natural sentences s, we feed these sentence\nsamples into the base LLM, performing forward propaga-\ntion to obtain the activation values (i.e., the hidden states\noutput of each layer) as follows:",
            "content": "h = LLM(s) (1) where RntndL is activation value tensor, nt is the length (number of tokens) of the input, nd is the dimension of the hidden states, is the number of layers in LLM. We distill these feature-base activation values of all samples in D(g) to form H(g) = {h1, h2, . . . , hN }."
        },
        {
            "title": "3.1.2 Activation Threshold\nAfter distilling all the activation values of samples in D(g),\nwe statistically determine the activation threshold and ac-\ncordingly infer the activation state. Specifically, for each\nactivation value ¯hj,k,l corresponding to the k-th dimension\nof hidden state at the l-th layer, we compute its mean\nand variance across the entire H(g) over the size N and\nlength nt, yielding meanl = (m1, m2, mk, . . . , mnd )l and\nstdl = (σ1, σ2, σk, . . . , σnd)l relative to the l-th layer. In\npractice, since the hidden state of the last layer encodes\nthe majority of the semantic information for the model’s\nfinal predictions, we choose to utilize only the last layer\nfor subsequent computations, which serve as the constraint\noptimization objective. Therefore, we assume l = L (the",
            "content": "last layer) and omit the subscript in all the following formulas, (e.g., hj,k := hj,k,l=L). Each component mk and σk is computed as follows: 4 mk ="
        },
        {
            "title": "1\nN × nt",
            "content": "N (cid:88) nt (cid:88) i=1 j=1 hi j,k (cid:118) (cid:117) (cid:117) (cid:116)"
        },
        {
            "title": "1\nN × nt",
            "content": "σk = (cid:88) nt (cid:88) (hi j,k mk)2 i= j=1 (2) (3) where ranges over the D(g) size and ranges over the number of tokens within the current sample, denote the k-th dimension. We further utilize the characteristics of Gaussian distribution to define the activation thresholds, considering one standard deviation above the mean as the positive activation threshold: τ + = m+1σ, and one standard deviation below the mean as the negative activation threshold: τ = 1σ. Each hk relative to the k-th dimension possesses two thresholds as follows: τk = (τ , τ + ) = (mk 1 σk, mk + 1 σk) (4) and we define three types of activation state: 1) values greater than τ + are considered positively activated, 2) values less than τ are considered negatively activated, 3) values between τ and τ + are considered non-activated: statek = positively activated non-activated negatively activated if value > τ + if value < τ if τ value τ + (5) According to Gaussian distribution, about 68.27% of the activation values are considered non-activated, which aligns with the assumption that only subset of neurons plays critical role during forward propagation. Once the thresholds for the D(g) are determined, they can be permanently applied to subsequent downstream task finetuning conveniently. Notably, we can also preemptively transform the float-type activation values into binary-type activation states to reduce the storage overhead."
        },
        {
            "title": "3.2 Threshold-Based Margin Optimization",
            "content": "This section describes the computation process of the proposed TM loss. Optionally we can randomly select subset of samples from D(g) for actually replay. However, if the original size is small, using the complete set is recommended. Specifically, given the previously determined positive and negative activation thresholds, these samples are jointly optimized with the downstream task samples during continual finetuning. Detailed steps are as follows."
        },
        {
            "title": "3.2.1 Batch Insertion",
            "content": "Traditional replay-based methods simply mix replay samples with downstream task training samples randomly. However, it requires considering the scale of both samples set and thereby adjusting the mixing ratio. Additionally, during optimization, it is possible that given batch may contain no replay samples, resulting in gradients that are exclusively influenced by the downstream task samples. To address this issue, we propose the Batch Insertion (BI) strategy, which ensures that specific proportion of replay JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 samples is included in each training batch. This strategy encourages the influence of the gradient update direction by the replay samples in every iteration, helping to retain the general capabilities of the LLM, meanwhile avoids the cumbersome adjustment of mixing ratios for datasets of varying scales. Given the finetuning batch size nbatch, we define the indicating that ρBI nbatch Batch Insertion ratio as ρBI, samples in each batch are replay samples. This can be easily implemented by modifying the Sampler Class within Torch DataLoader."
        },
        {
            "title": "3.2.2 Loss Calculation",
            "content": "During the joint training process, the proposed TM loss for the replay samples within each batch is computed as follows:"
        },
        {
            "title": "LTM",
            "content": "j,k = max(ˆhj,k τ max(ˆhj,k τ + + max(τ max(τ + , 0) , 0) ˆhj,k, 0) ˆhj,k, 0) if hj,k < τ if τ hj,k τ + (6) if hj,k > τ + where LTM j,k denotes the TM loss for the k-th dimension of the hidden state on the j-th token (at the last layer), is the precomputed target activation values while ˆh is the currently predicted activation values. This piecewise loss function guides the optimization direction of the predicted value when the target value resides in the negatively activated, non-activated, and positively activated states, respectively. The overall TM loss for each replay sample sentence is computed as follows: LT = 1 nt nd nt (cid:88) nd (cid:88) j=1 k= LT j,k (7)"
        },
        {
            "title": "3.2.3 Dynamic Weight Balancing\nDuring training, we jointly optimize the TM loss LTM re-\ngarding general replay samples and the standard Cross-\nEntropy (CE) loss LCE regarding downstream task samples.\nTo prevent the model from being overly biased toward\noptimizing either loss, we adopt a dynamic loss weighting\nstrategy to balance their magnitudes as follows:",
            "content": "ωTM = detach(LCE/LTM) = LCE + ωTM LTM (8) (9) where denotes the final total loss for continual finetuning. ωTM is the dynamic weight to dynamically scale the magnitude of the TM loss to match that of the CE loss during joint optimization. The detach() function indicates that the weight value is detached from gradient backpropagation, preventing it from being optimized. Notably, this approach is experimental, employing fixed or dynamic weights depending on practice."
        },
        {
            "title": "4 EXPERIMENTS",
            "content": "In this section, we evaluate the performance of our proposed method using representative base-LLM Llama-3.18B [23] along with 15 downstream tasks under continue learning regime. We first introduce the datasets, metrics and experimental settings, followed by detailed analyses of the experimental results and landscape visualization [24], [25] exploring robustness."
        },
        {
            "title": "4.1 Datasets",
            "content": "For the general replay sample set D(g), we randomly select 1K samples from the open-source SlimPajama-627B corpus [26], which is cleaned and deduplicated version of RedPajama [27] that reproduces the collection of LLaMA training data. We release the complete selected samples used throughout this paper to ensure reproducibility. Notably, the selection process is arbitrary rather than deliberately curated (see Appendix for details), which further substantiating the robustness and universality of our method with respect to the replay data. This replay data potentially reflect the general ability of the base LLM model, which is used to calculate the activation threshold and to compute the threshold-based margin loss. For the downstream finetuning tasks, we adopt long-sequence continual learning benchmark comprising as many as 15 diverse datasets [28], which enables comprehensive evaluation of model performance in practical scenarios under more demanding and challenging conditions. The benchmark integrates 5 datasets (yelp, amazon, dbpedia, agnews, yahoo) from the standard CL benchmark [29], [30], 4 datasets (MNLI, QQP, RTE, SST-2) from the GLUE benchmark [31], 5 datasets (CB, COPA, MultiRC, BoolQA, WiC) from the SuperGLUE benchmark [32], and the IMDB movie reviews dataset [33]. In alignment with [28], we utilize the available validation set for each dataset as the test set since test data is not available. However, unlike their setting, which randomly selects fixed number of training samples per dataset (i.e., potentially up-sampling or downsampling), we employ the original full training set for each dataset to better align with real-world scenarios where the data quantity distribution across tasks is inherently imbalanced. In continual finetuning, we train each task until the training loss converges without validation set. We proceed to train the next task after the previous one is finish, and the training data for each task was no longer available once used. TABLE 1: The statistic of the 15 downstream tasks."
        },
        {
            "title": "Datasets",
            "content": "# of Train # of Test"
        },
        {
            "title": "SC\nSC\nNLI\nNLI\nCOPA\nQQP\nNLI\nSC\nSC\nTC\nTC\nSC",
            "content": "yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo"
        },
        {
            "title": "MultiRC MultiRC\nBoolQA\nBoolQA\nWiC\nWiC",
            "content": "5000 5000 3000 250 400 2000 2000 2000 2000 14000 4000 10000 2000 2000 2000 7600 7600 7600 56 100 7600 277 7600 872 7600 7600 7600 4848 3270 638 JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 6 Fig. 3: comparable baseline series of distinct replay-based optimization targets (left to right): native non-replay Baseline, vanilla replay BaselineR, replay with different distillation strategies regarding logits imitation BaselineR+KL and feature imitation BaselineR+L1/L2. The rightmost BaselineR+TM is our proposed method, which employs the TM loss. Table 1 presents the dataset statistics for the 15 tasks. Examples mainly including instructions, inputs, and golden answers for each dataset are provided in the Appendix."
        },
        {
            "title": "4.2 Metrics",
            "content": "We evaluate the performance of the final model (i.e., after continual finetuning on 15 tasks) from two dimensions comprising general capabilities and the average accuracy over all downstream tasks. For general capabilities, We employ MMLU [34] benchmark, which spans 57 diverse disciplines ranging from STEM, humanities and social sciences, etc., to rigorously measure both factual knowledge and analytical skills across multiple levels of complexity. We use five-shot setting and discriminative evaluation. For ability to effectively learn the sequential downstream tasks, we assess the Average Performance (AP) [35] of the final model via obtaining task-wise accuracies and then computing their mean. AP reflects the models overall performance across multiple tasks and its ability to retain knowledge from previously learned. Notably, we also evaluated the multi-task learning (MTL) regime which finetunes on the combined dataset of all 15 tasks, serving as the theoretical upper bound performance for continual learning. Finally, we compute the F1 average of the MMLU and AP to reflect the holistic performance of model in maintaining its original general capabilities while effectively learning downstream tasks. All experimental results are reported as the average of 3 runs."
        },
        {
            "title": "4.3 Comparable Methods",
            "content": "We meticulously implement all comparable methods from scratch for controlled experiments, including the most basic level and its progressively enhanced counterparts. As shown in Fig.3, we compare our method (denoted as BaselineR+TM hereafter) with: native non-replay Baseline, vanilla replay BaselineR, replay with different distillation strategies regarding logits imitation BaselineR+KL and feature imitation BaselineR+L1/L2. These competitors cover the most prevalent and established practices in real-world application. For fair comparison, all methods are implemented within the same framework using identical replay samples and maintaining consistent configuration throughout the evaluation process. Details are as follows: Baseline: continually finetune the LLM on sequential tasks without adding any general replay samples. BaselineR: continually finetune the LLM on sequential tasks by mixing 1K general replay samples from D(g) with each task. These samples are pre-selected before finetuning and remain unchanged throughout the entire finetuning process. Both the replay and downstream task samples are jointly optimized using the standard crossentropy loss. Notably, all the methods discussed subsequently maintain this cross-entropy loss. BaselineR+KL: extend the BaselineR by integrating an additional KL loss. Specifically, the pre-distilled general replay sample logits serve as the target for KL loss during finetuning. The softmax temperature is set to 2, and the weight of KL loss term is accordingly set to 4 (its square) to compensate for gradient scaling down induced by the temperature [36]. In implementation, to avoid the large overhead of pre-storing the high-dimensional logits vectors, we compute the logits in real-time during finetuning based on the previously acquired final layer hidden state h(g) and the original lm head parameters of LLM. BaselineR+L1: extend the BaselineR by integrating an additional L1 loss computed on the hidden states at the last layer. The previously acquired h(g) serves as the target. BaselineR+L2: resemble BaselineR+L1 but employ L2 loss instead of L1 loss. Our method and other options are explained as follows: Our method (aka. BaselineR+TM): extend the BaselineR by integrating our proposed TM loss computed on the hidden states at the last layer as in Eq.6Eq.9. BI Option: adopt Batch Insertion (Sec. 3.2.1) and evaluate its effectiveness across all the replay-based BaselineR series, i.e., BaselineR and BaselineR+KL/L1/L2/TM that typically using general replay samples. Loss Weight: varied weighting values (denoted as w=[]) loss term regarding L1/L2/TM are of the additional JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 tested. We first empirically set w=1 (omitted as default), w=100 and dynamic weighting w=d.(Sec. 3.2.3) for LT to find the optimal performance, and then deliberately evaluate the same optimal weight on L1 and L2 for fair comparison. Upper Bound: we also include the upper bound performance for comparison, where Orig denotes the original MMLU score of untuned base model as ceiling. MTL denotes multi-tasks learning result across all 15 downstream tasks, which is trained on the combined task samples with the identical settings (epochs, learning rate, etc.). We calculate their F1 average upper bound as well. Notably, BaselineR+L1/L2 can be viewed as stricter version of ours, which pursues precise value fitting (also bringing activation state alignment), but lacks the inherent variation tolerant afforded by our discrete states. Regarding external competitors, since we strive for simply yet effective replay-base approach (e.g., promptsagnostic, task ids-agnostic, non-generative), we do not compare with ineligible methods like ProgPrompt [28], which sequentially integrates previously learned prompts with the current one during both training and testing. Instead, we compare O-LoRA [37] in our LoRA setting due to its simplicity in only constraining the LoRAs update direction by an additional orthogonal loss term. We are interested in comparing the downstream tasks performance enhanced as byproduct by our method with that of the specialized OLoRA, which is solely dedicated to this purpose. We reimplement it carefully using the same LoRA hyperparameters. TABLE 2: Comparison of different methods on continual full-parameter finetuning (15 epochs per task) in 15 downstream tasks. Methods (Full-Parameter) MMLU Score (Final)"
        },
        {
            "title": "15 Tasks AP\n(Final)",
            "content": "F1 Avg"
        },
        {
            "title": "4.4 Implementation Details",
            "content": "In all experimental comparison, we assess both fullparameter and LoRA finetuning settings with consistent batch size of 64. All downstream samples are truncated with maximum source length of 512 and maximum target length of 50. Accordingly general replay samples are truncated with maximum length of summation 562. In full-parameter setting, we maintain uniform learning rate of 3e-6 across all methods, employing warmup strategy coupled with cosine learning rate schedule. In LoRA setting, we maintain uniform learning rate of 1e-4 with warmup strategy across all methods, while seting LoRA hyperparameters to =8, α=32, LoRA dropout=0.1 and only tuning the parameters limited to proj and proj. We aim to finetune each task with sufficient steps to ensure loss convergence. Based on preliminary experiments, we ultimately selected 15 epochs per task for the full-parameter setting (due to the smaller learning rate) and 8 epochs for the LoRA. Notably, the replay samples used in all experiments are identical (the pre-selected set of 1K samples mentioned in BaselineR), which guarantees that the observed effects are attributable to the methodological variations rather than differences in the replay data. All experiments are conducted using Transformers [38] library with DeepSpeed ZeRO2 [39] and AdamW optimizer [40], running on up to 8 H80080GB GPUs. For the BI option experiments, we set ρBI=4/64, which indicates that 4 general replay samples are inserted into each batch of 64 data points. Specifically, these 4 general replay samples are selected randomly and non-repetitively from the aforementioned 1K samples. Once all samples have been selected, the process is reset to ensure continuously sampling."
        },
        {
            "title": "Baseline",
            "content": "BaselineR w/ BI BaselineR+KL w/ BI BaselineR+L1 w/ BI BaselineR+L w/ BI BaselineR+L1 (w=100) w/ BI BaselineR+L2 (w=100) w/ BI BaselineR+L1 (w=d.) w/ BI BaselineR+L2 (w=d.) w/ BI Ours BaselineR+TM w/ BI BaselineR+TM (w=100) w/ BI BaselineR+TM (w=d.) w/ BI"
        },
        {
            "title": "Upper Bound",
            "content": "38.3213 50.5332 55.5556 51.0492 52.7692 54.9364 54.5942 55.0052 56.6219 57.9635 59.0299 60.7499 57.8947 53.1132 53.2852 55.1772 54. 55.3836 57.6539 60.7155 60.9907 60.7843 57.2411 Orig 66.5291 37.4720 37."
        },
        {
            "title": "4.5 Results",
            "content": "39.2741 43.9903 42.0231 35.5259 66.8605 66.7673 67.4899 66.7462 72.4376 71.1125 72.6112 73.2265 67.4546 64.4925 71.0094 68.2590 70.3490 68.7473 74.0817 72.4771 74.4796 70. MTL 81.0079 44.1979 49.1011 46.0985 42.4638 60.3147 60.0691 60.6113 61.2686 64.3973 64.5103 66.1531 64.6643 59.4309 58.3556 62.1001 60. 61.9756 62.7138 66.7359 66.2396 66.9386 63.2068 73."
        },
        {
            "title": "4.5.1 Continual Full-Parameter Finetune",
            "content": "Table 2 shows the performance of each method in continual full finetuning 15 downstream tasks. We find that simply mixing general replay samples (BaselineR) significantly outperforms the Baseline without any replay, achieving notable improvement of 12% on MMLU. It justify the widespread adoption of this vanilla replay way in practice. After additional distillation technique, BaselineR+KL yields further improvements by capturing more information, specifically the distribution of labels. However, under the similar distillation cost, feature-based methods (BaselineR+L1/L2/TM) perform remarkable better, empirically suggesting that feature information is more efficient than label information by encoding richer representations of model knowledge in feature layer. Our rationale is that softmax-normalized labels tend to be dominated by extreme values, whereas features preserve finer-grained details. Among them, BaselineR+TM further alleviate the overly rigid inherence of L1/L2 loss by appropriately constraining optimization from an activation state perspective, achieving the highest performance. Moreover, the results of all BaselineR series validate the hypothesis that using only general replay samples can simultaneously maintain general capabilities and enhance JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 TABLE 3: Comparison of different methods on continual LoRA finetuning (8 epochs per task) in 15 downstream tasks (w=d. denotes weight dynamic). Methods (LoRA) MMLU Score (Final)"
        },
        {
            "title": "15 Tasks AP\n(Final)",
            "content": "F1 Avg"
        },
        {
            "title": "Baseline",
            "content": "BaselineR w/ BI BaselineR+KL w/ BI BaselineR+L1 w/ BI BaselineR+L w/ BI Ours BaselineR+TM w/ BI BaselineR+TM (w=100) w/ BI BaselineR+TM (w=d.) w/ BI O-LoRA [37]"
        },
        {
            "title": "Upper Bound",
            "content": "55.7620 58.6515 56.5187 61.0251 61.5755 61.5411 65.1875 61.6787 64.4651 65.3251 64.6371 65.9443 65.5659 66.2539 65.4627 55. Orig 66.5291 73.3944 63.3746 75.5310 73.3986 74.8367 72.9626 73.4170 73.1178 74.9397 74. 75.0639 72.7650 63.9167 68.7755 64.4417 67.7580 73.6823 MTL 80.3474 66.0296 63.8621 67.2289 66.7872 66.9565 68.9253 67.6656 68. 69.8567 68.4606 64.9147 67.1323 65.3352 66.5906 63.5707 72.7882 overall performance of downstream task. As shown in the table, both MMLU and AP improve. This provides an alternative to the traditional practice of laboriously collecting downstream task replay samples during continual finetuning, sparking promising research direction."
        },
        {
            "title": "4.5.2 Continual LoRA Finetune",
            "content": "Table 3 shows the performance of each method in continual LoRA finetuning 15 downstream tasks. Compared to fullparameter setting, LoRA alone exhibits notable superiority, which tunes only 0.042% of the parameters (i.e., proj and proj), This minimal parameter tuning likely contributes to its strong anti-forgetting ability, but it still enables adequate learning of new tasks. For instance, when equipped with LoRA, both the Baseline and vanilla replay BaselineR nearly match the best F1 Avg observed in full-parameter, and BaselineR also show surprisingly strong AP of downstream tasks. Still, similar trends hold for LoRA, with the BaselineR series showing progressive improvements, where our method ultimately achieves the best F1 Avg. We also find that several methods here have achieved MMLU scores nearly matching the upper bound evaluated from original base model, showing negligible loss of general capabilities. O-LoRA, as simple and comparable approach dedicated to AP of downstream tasks, achieves decent AP performance but exhibits obvious forgetting of general capabilities. Furthermore, the original O-LoRA paper claims its superiority over the method with replaying downstream task samples, but we still attain higher AP. This demonstrates the multifaceted advantages of our GeRe framework over tradition. By the way, the MTL performance under both settings shows that LoRA still slightly underperforms full-parameter when jointly learning multiple new tasks, aligning with full-parameter remains study [41] and suggesting that 8 preferable in normal situation with available computational resources."
        },
        {
            "title": "4.5.3 Ablation Study of BI and Loss Weight",
            "content": "Each method with BI option under full-parameter and LoRA settings is additional list in Table.23. The effectiveness of BI varies across methods and settings, without showing consistent enhancement. For instance, BI improves the Baseline in full-parameters and BaselineR+L1/L2 in LoRA, but its effect appears negligible in most distillation methods that already capture more information. We attribute this to the small scale of our finetuning datasets in the experiments, where mixing 1K general replay samples suffices for many downstream tasks. In extremely small datasets like CB, BIs proportional insertion may even reduce the final replay samples below the standard 1K. However, BI remain necessary in potential scenarios especially finetuning large-scale downstream task datasets that may far exceeds the 1K replay samples. In such cases, data balancing is crucial since simply mixing them at their original scale leads to insufficient replay. As shown in the results, while BI does not significantly improve performance, it also does not degrade it especially with our method, indicating that BaselineR+TM with BI can be directly used in most circumstances. In conclusion, the adoption of BI should be determined by practical considerations and an optimal replay insertion ratio, which warrants further investigation Regarding different loss weight, the results also vary. In full-parameter setting, our method with dynamic weighting LT , i.e., BaselineR+TM (w=d.) performs best, even in fair comparison where L1 and L2 are purposefully evaluated with the same weighting strategy. In contrast, simply setting of fixed weight of 1 yields better performance under LoRA, as larger or dynamic weight tend to degrade AP. So We only list results (w=1) of L1 and L2 as well. This indicates that different settings should better have their individual weight strategies, and we have already explore two best practice. Unified settings remain for future research. In the following comparison, we intentionally use results of w=100 for full-parameter setting and w=1 for LoRA in order to simultaneously consider the maximum achievable performance of the L1/L2 competitors. Furthermore, conventional belief suggests that strengthening the weight of optimization direction toward antiforgetting will enhance stability at the cost of plasticity, thereby impairing learning of new task. However, results with higher weight (from w=1 to w=100) show that not only MMLU dose but also downstream tasks AP continues to improve. This may stem from the adoption of general replay samples rather than task-specific replay samples, which mitigates the Stability-Plasticity Dilemma [42] typically occurs when excessively replaying samples from downstream tasks in tradition."
        },
        {
            "title": "4.5.4 Performance Trend Over Tasks",
            "content": "Fig.4 shows the dynamic changes of the three metrics assessed in Table 23 as the model sequentially learns 15 downstream tasks under full-parameter and LoRA settings. Evidently, our method consistently achieves the highest score on MMLU at nearly every task step under both settings. Moreover, it remains in the top tier performance JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 9 Fig. 4: Performance trend during continual learning 15 tasks of different methods. Y-axis of each figure indicates the specific task that has just been learned. Two rows depict full-parameter and LoRA settings, respectively. Three columns are metrics: current MMLU score, average performance over tasks learned so far, F1 average. of AP across the downstream tasks learned so far, achieving the best final F1 Avg. Notably, during the full-parameter learning, significant decline in AP occurs after the model learned the COPA task. Deeper investigation of the task-wise results (see Appendix) reveals that it is mainly caused by performance drops in the MNLI and CB tasks. We attribute this to the unique instruction format of COPA without providing options (see Appendix), which temporarily disrupts the models instruction-following ability after learning COPA. So, tasks with the most similar instructions like MNLI and CB experience performance degradation. Fortunately, as the model continues to learn subsequent tasks with regular instructions, the performance of these two tasks recovers. We interpret this as case of spurious forgetting [43], where the model does not lose the core knowledge of these tasks but undergoes temporary confusion in instruction following, which can be readily restored in later learning phases."
        },
        {
            "title": "4.5.5 Robustness to Learning Rate",
            "content": "In continual finetuning, it is well-established that while larger learning rates (LR) facilitate more thorough learning of downstream tasks, they also intensify the forgetting of previously acquired knowledge. This effect becomes particularly pronounced when dealing with LLMs featuring Fig. 5: MMLU, AP and F1 Avg performance of three major representative methods across different learning rate is compared under full-parameter and LoRA settings, with the LR axis displayed on logarithmic scale. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 10 Fig. 6: Landscapes of (a) replay samples loss, and (b) MMLU score under full-parameter setting. Origin point (0,0) is base untuned model. Y-axis is weight update direction of Baseline (0,1), representing the learning dedicated to downstream tasks. X-axis is weight update direction of target method for comparison (1,0). The upper-right area of interest simulates the target model guided by the learning direction of downstream tasks (yellow arrow), where the flatness (see zoomed-in view) can imply the optimizing robustness against latent forgetting even under potential overtraining in practice. massive training parameters, which aligns with our observations in preliminary experiments. Thus, practitioners need to carefully adjust the LR from relatively small values to balance new task acquisition with knowledge retention. However, empirical evaluating against both the native Baseline and vanilla replay BaselineR show that our method maintains relatively strong general capabilities (MMLU scores) even with substantially increased LRs. As shown in Fig.5, our method gains more stable performance despite 3 LR increase under full-parameter and 10 increase under LoRA. In contrast, the compared methods approach MMLU score of nearly 25% ,equivalent to random guessing among 4 options, highlighting their vulnerable dependence on tuning LR. Our methods demonstrates superior adaptability in practice scenarios. Beyond MMLU, similar conclusions regarding AP and the resulting F1 Avg can be drawn from the subsequent subfigures."
        },
        {
            "title": "4.5.6 Robustness in Optimization Landscape",
            "content": "To better understand the underlying optimization mechanisms of different methods and their robustness against forgetting, we visualize the landscapes with two contour values under full-parameter  (Fig.6)  and LoRA settings  (Fig.7)  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 11 Fig. 7: Landscapes of (a) replay samples loss, and (b) MMLU score under LoRA setting. Origin point (0,0) is base untuned model. Y-axis is weight update direction of Baseline (0,1), representing the learning dedicated to downstream tasks. X-axis is weight update direction of target method for comparison (1,0). The upper-right area of interest simulates the target model guided by the learning direction of downstream tasks (yellow arrow), where the flatness (see zoomed-in view) can imply the optimizing robustness against latent forgetting even under potential overtraining in practice. Our idea is that in replay-based learning, to ensure thorough learning for downstream tasks, excessive training can easily occur, which will compromise the general capabilities. We consider that better method should reconcile the optimization directions of both downstream tasks and replay samples. Such method would maintain latent robustness even when subjected to excessive downstream task training that typically induces forgetting. According to task vector arithmetic [44], we can directly perform linear combinations of model weight for specific method to simulate and observe their robustness to optimization dynamics under extreme conditions of excessive training. Therefore, the landscape is designed as 2D weight space spanned by two specific model weight update directions, where y-axis is the update direction of the Baseline and x-axis is one of the interested methods for comparison. Specifically, the upward direction (yellow arrow) indicates the optimization toward native continual finetuning without any replay, highlighting exclusive learning of downstream tasks. The rightward direction indicates the optimization toward target model trained from specific method among the replay-based series. Based on this coordinate, the upper-right region (white rectangle) is the area of interest that can reveal the robustness against forgetting undergoing potential overtraining, JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 as it simulates the weight update direction imposed on the target model toward overly optimizing downstream tasks. As for contour values, we select two metrics: a) the CE loss of replay samples, as it is universally adopted and optimized across all methods, and b) the direct MMLU score for straightforward observation. These values measure the retention of general capabilities implicitly and explicitly, respectively. The flatness (i.e., the rate of performance degradation) of the area of interest indicates how robustly each method preserves their general capabilities while learning downstream task. The landscapes are implemented with positioning the untuned base LLM model at coordinate (0,0), the native Baseline finetuned model at coordinate (1,0), and specific replay-based finetuned model for comparison at coordinate (0,1). Weight parameters of each model are flattened into vector, and the two basis vectors of this coordinate system are derived by subtracting the corresponding model weight vectors (e.g., y=w[target]wbase, x=wbaselinewbase). We use these two basis vectors to generate grid of points, where each point represents model derived from linear combination of these basis vectors (e.g., (0.6,0.4) denotes model of weight w=0.6x+0.4y). For every model associated with the points, we compute the loss of replay samples and the MMLU score, creating the contour plot as landscape, respectively. For instance, Fig.6(a) shows the replay sample loss under full-parameter setting. We observe that the BaselineR exhibits notably steepness in the area of interest, implying that this optimization encounters significant conflicts when following the direction of learning downstream tasks while attempting to replay to retain general capabilities. This potentially accounts for its poor performance in Tab.2. The same issue persists in BaselineR+KL, though it is relatively less severe, but still remarkable. In comparison, the featurebased replay methods show significantly flatter behavior in the area of interest, and among them our BaselineR+TM performs the flattest upon closer look at the contour values in the zoomed-in view. This mean our method show better robustness to the intrinsic optimization dynamics when arbitrarily or excessively trained on downstream tasks. For the MMLU score landscape in Fig.6(b), similar trend is observed. The feature-based replay methods exhibit higher scores and slower decline in the area of interest. They also shape distinct ridge along the learning trajectory (i.e., y-axis) of the specific model, where the scores are maximally preserved. Besides, though the learning trajectories of baselineR and baselineR+KL maintain high score early, they undergo sharply decline as more tasks are introduced. In contrast, the feature-based methods effectively preserve the score along the ridge, confirming the necessity of benchmarking typical long-sequence tasks. In the MMLU score landscape, our BaselineR+TM still demonstrate superior performance. Additionally, although the contour patterns of general samples loss and MMLU score differ, their underlying trends exhibit similar characteristics, e.g., both metrics show consistent variations in the area of interest of the same method. This confirms that general samples can implicitly reflect the actual general capabilities. However, relying solely on the CE loss of general samples may be insufficient, 12 e.g., BaselineR and BaselineR+KL achieve lower loss values, but their MMLU scores remain low. Instead, the optimization of feature-based methods align more closely with the trends of MMLU. Finally, Fig.7 shows landscape under LoRA setting, where the observations are generally similar to those of full-parameter, except that LoRAas highly effective anti-forgetting toolsignificantly enhances the foundational performance of all variants. Notably, our method here shows more pronounced flatness and maintains higher performance in the are of interest. Across both settings, our BaselineR+TM consistently demonstrates the optimizing robustness against latent forgetting."
        },
        {
            "title": "5 CONCLUSION",
            "content": "In this research, we introduce GeRe, framework that leverages general replay samples for continual learning in LLMs. Building upon GeRe, we revisit the existing replay baseline and devise novel optimization method that utilizes the informative states of neurons through proposed TM loss. This loss function effectively aligns the activation states of replay samples, offering moderate yet discerning constraint compared to existing replay-based variants. Crucially, GeRes results reveal that only fixed set of general replay samples is sufficient for continual learning across long sequence of downstream tasks, which not only effectively retains the general capabilities but also successfully promotes the overall performance on downstream tasks. Furthermore, detailed analyses and intuitive visualizations rigorously validate the superior performance and robustness of the TM loss within GeRe. Our study offers valuable insights into the efficacy of replay mechanisms, highlighting the practical advantages and contributing to potential applications for the continuous iteration of LLMs."
        },
        {
            "title": "REFERENCES",
            "content": "[1] Y. Luo, Z. Yang, F. Meng, Y. Li, J. Zhou, and Y. Zhang, An empirical study of catastrophic forgetting in large language models during continual fine-tuning, arXiv preprint arXiv:2308.08747, 2023. 1 J. Zheng, S. Qiu, and Q. Ma, Concept-1k: novel benchmark for instance incremental learning, arXiv e-prints, pp. arXiv2402, 2024. 1 [2] [3] H. Shi, Z. Xu, H. Wang, W. Qin, W. Wang, Y. Wang, Z. Wang, S. Ebrahimi, and H. Wang, Continual learning of large language models: comprehensive survey, arXiv preprint arXiv:2404.16789, 2024. 1 [4] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale et al., Llama 2: Open foundation and fine-tuned chat models, arXiv preprint arXiv:2307.09288, 2023. 2 [5] A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu, F. Huang, H. Wei et al., Qwen2. 5 technical report, arXiv preprint arXiv:2412.15115, 2024. 2 [6] B. A. Olshausen and D. J. Field, Emergence of simple-cell receptive field properties by learning sparse code for natural images, Nature, vol. 381, no. 6583, pp. 607609, 1996. 2 J. Wolfe, A. R. Houweling, and M. Brecht, Sparse and powerful cortical spikes, Current opinion in neurobiology, vol. 20, no. 3, pp. 306312, 2010. [7] [8] G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter, Continual lifelong learning with neural networks: review, Neural networks, vol. 113, pp. 5471, 2019. 2 [9] R. M. French, Catastrophic forgetting in connectionist networks, Trends in cognitive sciences, vol. 3, no. 4, pp. 128135, 1999. 2 JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 13 [10] D. Rolnick, A. Ahuja, J. Schwarz, T. Lillicrap, and G. Wayne, Experience replay for continual learning, Advances in neural information processing systems, vol. 32, 2019. [11] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska et al., Overcoming catastrophic forgetting in neural networks, Proceedings of the national academy of sciences, vol. 114, no. 13, pp. 35213526, 2017. 2 [12] Z. Li and D. Hoiem, Learning without forgetting, IEEE transactions on pattern analysis and machine intelligence, vol. 40, no. 12, pp. 29352947, 2017. 3 [13] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick, K. Kavukcuoglu, R. Pascanu, and R. Hadsell, Progressive neural networks, arXiv preprint arXiv:1606.04671, 2016. 3 [14] A. Mallya, D. Davis, and S. Lazebnik, Piggyback: Adapting single network to multiple tasks by learning to mask weights, in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 6782. 3 [15] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen et al., Lora: Low-rank adaptation of large language models. ICLR, vol. 1, no. 2, p. 3, 2022. 3 [16] G. Hinton, O. Vinyals, and J. Dean, Distilling the knowledge in neural network, arXiv preprint arXiv:1503.02531, 2015. 3 [17] V. Sanh, L. Debut, J. Chaumond, and T. Wolf, Distilbert, distilled version of bert: smaller, faster, cheaper and lighter, arXiv preprint arXiv:1910.01108, 2019. 3 [18] X. Jiao, Y. Yin, L. Shang, X. Jiang, H. Chen, L. Li, F. Wang, and Q. Liu, Tinybert: Distilling bert for natural language understanding, arXiv preprint arXiv:1909.10351, 2020. 3 [19] Y. Zhou, Y. Wang, J. Zhang, and X. Li, Distilling taskspecific knowledge from large pre-trained models, arXiv preprint arXiv:2203.12345, 2022. 3 [20] Z. Zhengetal, Localizationdistillationforobjectdetection, IEEE Trans. Pattern Anal. Mach. Intell, vol. 45, no. 8, pp. 10 07010 083, 2023. [21] L. Wang, M. Zhang, and Y. Liu, Self-distillation for large language models, arXiv preprint arXiv:2301.04567, 2023. 3 [22] X. Xu, M. Li, C. Tao, T. Shen, R. Cheng, J. Li, C. Xu, D. Tao, and T. Zhou, survey on knowledge distillation of large language models, arXiv preprint arXiv:2402.13116, 2024. 3 [23] A. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. AlDahle, A. Letman, A. Mathur, A. Schelten, A. Vaughan et al., The llama 3 herd of models, arXiv preprint arXiv:2407.21783, 2024. 5 [24] H. Li, Z. Xu, G. Taylor, C. Studer, and T. Goldstein, Visualizing the loss landscape of neural nets, Advances in neural information processing systems, vol. 31, 2018. 5 [25] L. Wang, X. Zhang, H. Su, and J. Zhu, comprehensive survey of continual learning: Theory, method and application, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024. 5 [26] D. Soboleva, F. Al-Khateeb, R. Myers, J. R. Steeves, J. Hestness, and N. Dey, Slimpajama: 627b token cleaned and deduplicated version of redpajama, 2023. [Online]. Available: https://huggingface.co/datasets/cerebras/SlimPajama-627B [27] M. Weber, D. Y. Fu, Q. Anthony, Y. Oren, S. Adams, A. Alexandrov, X. Lyu, H. Nguyen, X. Yao, V. Adams, B. Athiwaratkun, R. Chalamala, K. Chen, M. Ryabinin, T. Dao, P. Liang, C. Re, I. Rish, and C. Zhang, Redpajama: an open dataset for training large language models, NeurIPS Datasets and Benchmarks Track, 2023. 5 [28] A. Razdaibiedina, Y. Mao, R. Hou, M. Khabsa, M. Lewis, and A. Almahairi, Progressive prompts: Continual learning for language models, in The Eleventh International Conference on Learning Representations, 2023. 5, 7 [29] X. Zhang, J. Zhao, and Y. LeCun, Character-level convolutional networks for text classification, Advances in neural information processing systems, vol. 28, 2015. 5 [30] C. Qin and S. Joty, Lfpt5: unified framework for lifelong fewshot language learning based on prompt tuning of t5, arXiv preprint arXiv:2110.07298, 2021. 5 [31] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, Glue: multi-task benchmark and analysis platform for natural language understanding, arXiv preprint arXiv:1804.07461, 2018. 5 [32] A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. Bowman, Superglue: stickier benchmark for general-purpose language understanding systems, Advances in neural information processing systems, vol. 32, 2019. 5 [33] A. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts, Learning word vectors for sentiment analysis, in Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies, 2011, pp. 142150. 5 [34] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt, Measuring massive multitask language understanding, arXiv preprint arXiv:2009.03300, 2020. 6 [35] A. Chaudhry, P. K. Dokania, T. Ajanthan, and P. H. Torr, Riemannian walk for incremental learning: Understanding forgetting and intransigence, in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 532547. 6 [36] S. Sun, W. Ren, J. Li, R. Wang, and X. Cao, Logit standardization in knowledge distillation, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2024, pp. 15 731 15 740. 6 [37] X. Wang, T. Chen, Q. Ge, H. Xia, R. Bao, R. Zheng, Q. Zhang, T. Gui, and X. Huang, Orthogonal subspace learning for language model continual learning, arXiv preprint arXiv:2310.14152, 2023. 7, 8 [38] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz et al., Transformers: State-of-the-art natural language processing, in Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, 2020, pp. 3845. [39] S. Rajbhandari, J. Rasley, O. Ruwase, and Y. He, Zero: Memory optimizations toward training trillion parameter models, in SC20: International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE, 2020, pp. 116. 7 [40] I. Loshchilov and F. Hutter, Decoupled weight decay regularization, arXiv preprint arXiv:1711.05101, 2017. 7 [41] D. Biderman, J. Portes, J. J. G. Ortiz, M. Paul, P. Greengard, C. Jennings, D. King, S. Havens, V. Chiley, J. Frankle et al., Lora learns less and forgets less, arXiv preprint arXiv:2405.09673, 2024. 8 [42] S. Dohare, J. F. Hernandez-Garcia, Q. Lan, P. Rahman, A. R. Mahmood, and R. S. Sutton, Loss of plasticity in deep continual learning, Nature, vol. 632, no. 8026, pp. 768774, 2024. 8 [43] J. Zheng, X. Cai, S. Qiu, and Q. Ma, Spurious forgetting learning of language models, in The Thirteenth in continual International Conference on Learning Representations, 2025. [Online]. Available: https://openreview.net/forum?id=ScI7IlKGdI 9 [44] G. Ilharco, M. T. Ribeiro, M. Wortsman, L. Schmidt, H. Hajishirzi, and A. Farhadi, Editing models with task arithmetic, in The Eleventh International Conference on Learning Representations, 2023. [Online]. Available: https://openreview.net/forum?id=6t0Kwf8jrj"
        },
        {
            "title": "APPENDIX",
            "content": "A .1 Examples of General Replay Samples Table.4 presents some selected examples from the general replay samples set D(g) used throughout this paper, where each entry is normal pretraining text sentence. The ID is the line number of our released jsonl file of D(g), and the set name is the meta information indicating the source. (We purposely selected examples from diverse sources for display.) The data was obtained through the following process: We downloaded the first chunk of data (train-00000-of-00048ab2b35705f029d94.parquet) from SlimPajama-6B (https:// huggingface.co/datasets/DKYoon/SlimPajama-6B), sampled version of SlimPajama-627B (https://huggingface.co/ datasets/cerebras/SlimPajama-627B). Then, we simply extracted the first 1000 entries using the following code to generate the jsonl file: slim_datasets = load_dataset(parquet, data_files={train-00000-of-00048ab2b35705f029d94.parquet} )[train] slim_datasets.select(range(1000)).to_json( slimpajama_6B_chunk0_head1k.jsonl) JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 14 Id"
        },
        {
            "title": "Text",
            "content": "0 RedPajamaC4 Want Tori to Coach You Too?nToris Health Step by Step coming soon.nWin free copies, prizes, access to exclusive behind-the-scenes, free access to Coach Tori, and more.nand receive copy of Toris Weekly Challenges. Well also notify you of when Toris Program becomes available.nIve been asked, even criticized, about adding focus on nutrition to Desert. Theres reason why. had poor nutritional examples growing up. Being confused on the issue of nutrition cost me lot. remember yo-yoing lot. The only time even came close to being my desired weight was when did high-intensity workouts daily. At one point, was exercised about 6 hours day. was in multiple dance classes and karate class, as well as another karate club that met for two hours three days week. also rode my bike to campus, and even added one hour workout when got home. was still thirty pounds overweight. can attest to the coined phrase You cannot exercise away bad diet.nIt was hard to consider diet for me, because had genetic heritage that leaned on the heavy side. felt trapped, having low metabolism. It seemed if even looked at what others ate, was the one who gained weight.nEvery once in while, someone would mention diet to me, but it did little to sway me. Why? Bad examples.nBrad Pitt in Oceans Eleven. Every scene hes in, hes eating something unhealthy.nIn Hollywood and at school, lots of lean people were eating the things loved: pizza, ice cream, hamburgers, fries, bread, cake, cookies, etc.nI also knew several weighed down people who were eating healthy diet.nIt wasnt until was in college, having just finished my laps in swimming plus jog, that stopped by to visit frienda slim friend who never seemed hungry. It seemed so unfair as watched her prepare herself salad and two small slices of pizza.nI knew in that moment that if ate like her, would look like her. also knew that if prepared small salad and two small slices of pizza, that by the end of the meal would end up not eating just one personal pizza, but two or three.nI started to believe in nutrition, but didnt have faith that someone like me could do it.nI was right, and was wrong . . ."
        },
        {
            "title": "RedPajamaGithub",
            "content": "ACCEPTEDnn#### According tonThe Catalogue of Life, 3rd January 2011nn#### Published innNew Zealand J. Bot. 25:166. 1987nn#### Original namenAtropis pumila Kirknn### Remarksnnull 500 RedPajamaC"
        },
        {
            "title": "RedPajama\nCommonCrawl",
            "content": "839 1000 RedPajamaC4 Located in an impressive old drapers warehouse, Citibase Birmingham Mailbox is in the heart of the vibrant Mailbox shopping, entertainment and dining district. The recently refurbished reception area is reminiscent of New York warehouse and the centre provides wide range of offices many with amazing city views, including new Loft-style suites.nWith New Street Station and the smart new Grand Central Shopping Centre, the Central Business District and the vast array of other shopping and dining options all under 10 minutes walk away, its the ideal location to grow your business. Big Boys 24/7 ChannelnReal 92.3 LAnBigBoyTV VideosnBig Boys BankrollnBig Boy Full EpisodesnBig Boys Fully Loaded InterviewsnBig Boys Uncut PodcastnWhats Trending with Natalia PereznMeet the NeighborhoodnNatalia PereznVick OnenDJ HednAdvertise on Big Boys NeighborhoodnPodcast: Home Grown RadionTupacs Strictly 4 My NIGGAZ Will Be Out Again For Its 25th AnniversarynBy DJ Hed Feb 17, 2018nYesterday (February 16) marked the 25th anniversary of Tupacs sophomore album, Strictly 4 My N.I.G.G.A.Z.nToday, Interscope Records and UMe are gifting Pac and hip-hop fans are around the world, the blessing to cop limited edition, commemorative 2LP vinyl of the project.nTheres two vinyl editions available for purchase. The standard edition is available at all physical retailers and comes with the 180-gram vinyl of the album, and the deluxe edition features gatefold image of 2PACs original notebook, with his handwritten track list visible, and prints.nThe only catch is that theres only 1,000 copies made, which means you have to cop your copy asap. Grab your Strictly 4 My N.I.G.G.A.Z copy on Tupacs website here.nAbout DJ HednDJ Hed is deejay mixer on REAL 92.3 KRRL FM Los Angeles RadioRead MorenBig Boy BlognBig Boys Full EpisodesnBIGBOY Political Filenu00a9 2021 Premiere Networks, Inc. The Pastel Piebald is co-dom recessive morph combination, we produced it in 2005 along with The Snake Keeper. After missing the odds on multiple clutches, our luck changed with the second to last clutch of the season, from 5 egg clutch of Pastel het Pied het Pied, out came one of our prized possessions one of the first Pastel Pieds. You can imagine the excitement and joy that was felt on that Labor Day holiday in 2005, when we discovered this beautiful Pastel Pied had hatched and it was male. This male has grown up and in 2008 had sired the first Super Pastel Pied or Killer Pied, stunning lemon yellow Piebald, creating greater demand for the already sought after Pastel Pied. TABLE 4: The example of the adopted general replay samples .3 Task-wise Results On Continual Fine-tuning 15 Downstream Tasks We show the task-wise results of the continual fine-tuning experiments as in Table.744, corresponding to each entry in Table.2 and Table.3. For instance, Table.7 elaborates the Baseline entry in Table.2 by including performance of the previous 14 tasks, rather than only listing the final result of the last task. The first column indicates the current learning task, while the remaining columns show evaluation metrics for previously learned tasks and the resulted MMLU and F1 Avg at each learning step. This acquisition process demonstrates that the general replay sample set was obtained through random selection rather than deliberate curation, thereby substantiating the robustness and universality of our method regarding the replay data. .2 Examples of Downstream Task Datasets Table.56 show detailed examples of 15 downstream task datasets, including task types, dataset names, instructions, inputs, and golden answers. All data are constructed using the same template: [Instruction]n[Input]nAnswer:[Golden Answer]. The evaluation criterion for all samples is binary classification for being correct or incorrect , determining whether the model-generated answers exactly match the golden answers. The accuracy for each dataset is then calculated as the corresponding task performance. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST"
        },
        {
            "title": "Golden Answer",
            "content": "SC yelp SC amazon"
        },
        {
            "title": "NLI",
            "content": "CB"
        },
        {
            "title": "RTE",
            "content": "SC SC"
        },
        {
            "title": "IMDB",
            "content": "SST-2 TC dbpedia TC agnews TC yahoo What is the sentiment of the following paragraph? Choose one from the option. Option: very negative, negative, neutral, positive, very positive What is the sentiment of the following paragraph? Choose one from the option. Option: very negative, negative, neutral, positive, very positive What is the logical relationship between the sentence 1 and the sentence 2? Choose one from the option. Option: neutral, entailment, contradiction What is the logical relationship between the sentence 1 and the sentence 2? Choose one from the option. Option: entailment, contradiction, neutral Text: This place is printing money and rightfully so. They simply do bang up job. Best BBQ in AZ. very positive Title: Very fragile...arrived broken Text: The set is cute, but refrigerator door was broken on arrival and not repairable. The table top and hutch had come apart and required regluing. This set will not stand up to play. negative sentence 1: She leaned back in her chair. sentence 2: She stood next to chair. neutral sentence 1: A: Your turn. B: Okay. Uh, dont think they should abolish it. sentence 2: they should abolish it contradiction Which sentence is the cause of coughed.? Choose one between and B. A: inhaled smoke. B: lowered my voice. Whether the first sentence and the second sentence have the same meaning? Choose one from the option. Option: False, True first sentence: What are the best franchises in India? second sentence: What are the best franchise in India? What is the logical relationship between the sentence 1 and the sentence 2? Choose one from the option. Option: contradiction, entailment sentence 1: The girl was found in Drummondville. sentence 2: Drummondville contains the girl. What is the sentiment of the following paragraph? Choose one from the option. Option: Good, Bad This is good film. This is very funny. Yet after this film there were no good Ernest films! Text: it not the ultimate depressionera gangster movie . Title: Cori Schumacher Text: Cori Schumacher is world champion surfer from California. Title: British sailors bag bronze Text: Britains Chris Draper and Simon Hiscocks win bronze in tense final 49er race on the Saronic Gulf. What is the sentiment of the following paragraph? Choose one from the option. Option: Good, Bad What is the topic of the following paragraph? Choose one from the option. InstiOption: Company, Educational tution, Artist, Athlete, Office Holder, Mean of Transportation, Building, Natural Place, Village, Animal, Plant, Album, Film, Written Work What is the topic of the following paragraph? Choose one from the option. Option: World, Sports, Business, Science or Technology What is the topic of the following paragraph? Choose one from the option. Option: Society & Culture, Science & Mathematics, Health, Education & Reference, Computers & Internet, Sports, Business & Finance, Entertainment & Music, Family & Relationships, Politics & Government TABLE 5: The example of the 15 downstream tasks for fine-tuning Title: did God create people or did people create god?..? Question: think about it... Answer: Good question dude. Society & Culture A"
        },
        {
            "title": "True",
            "content": "contradiction"
        },
        {
            "title": "Sports",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST"
        },
        {
            "title": "MultiRC MultiRC",
            "content": "According to the following passage and question, is the candidate answer true or false? Choose one from the option. Option: False, True"
        },
        {
            "title": "WiC",
            "content": "According to the following passage, is the question true or false? Choose one from the option. Option: True, False Given word and two sentences, whether the word is used with the same sense in both sentence? Choose one from the option. Option: True, False paragraph: Susan wanted to have birthday party. She called all of her friends. She has five friends. Her mom said that Susan can invite them all to the party. Her first friend could not go to the party because she was sick. Her second friend was going out of town. Her third friend was not so sure if her parents would let her. The fourth friend said maybe. The fifth friend could go to the party for sure. Susan was little sad. On the day of the party, all five friends showed up. Each friend had present for Susan. Susan was happy and sent each friend thank you card the next week. question: Did Susan call her friends before or after asking her mother? candidate answer: Before asking her mother question: can drive in canada with us license passage: American entry into Canada by land Persons driving into Canada must have their vehicles registration document and proof of insurance. word: touch He has touch of rheumatism. He longed for the touch of her hand."
        },
        {
            "title": "False",
            "content": "TABLE 6: The example of the 15 downstream tasks for fine-tuning Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 63.8440 62.0571 yelp 60.9339 58.1699 amazon 58.7423 55.0740 MNLI 57.8043 55.3492 CB 31.0482 52.8724 COPA 57.5412 53.5604 QQP 57.4316 51.8060 RTE 58.2702 51.4964 IMDB 55.5752 49.9484 SST-2 52.2713 48.6068 dbpedia 54.6519 46.4740 agnews yahoo 41.6585 38.4933 MultiRC 53.1073 47.5748 BoolQA 51.7833 47.6436 37.8919 38.3213 WiC 65.7368 63.9737 62.9342 60.4874 21.9768 62.1613 64.4277 67.0960 62.6307 56.5334 66.3224 45.3909 60.0959 56.7108 37.4720 - - - - - - - - - - - - - - - - - - - - - 65.7368 63.4605 64.4868 53.8158 49.8158 85.1711 51.4737 47.4605 82.2500 98.2143 36.4605 28.6711 0.0000 0.0000 95.0000 54.8289 55.7500 52.6447 51.7857 98.0000 85.0263 55.0789 56.0921 61.4211 87.5000 97.0000 83.5921 89.8917 51.7237 54.2237 62.2368 87.5000 96.0000 83.6842 89.8917 82.2500 45.5921 42.8816 63.3026 89.2857 91.0000 74.2368 89.8917 81.9474 94.2661 30.0263 24.3421 62.8684 85.7143 96.0000 80.7763 74.0072 40.6316 57.5688 99.0658 41.2500 30.2237 63.0658 82.1429 42.0000 77.8026 59.9278 71.4474 92.6606 85.5921 92.2895 30.1184 5.4474 39.9342 50.0000 54.0000 27.7368 40.7942 31.0263 55.5046 77.7368 77.0132 72.9737 41.3816 29.5658 24.1711 19.6429 55.0000 82.4605 64.2599 81.5263 93.8073 90.3421 72.5921 46.1447 74.0924 42.3289 29.3684 10.0658 8.9286 29.0000 80.1184 17.3285 80.5789 93.8073 90.8553 69.0658 27.9211 72.0297 83.4557 12.2500 4.9605 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 0.5132 0.0000 12.0000 60.5000 1.0830 39.8684 52.6376 83.8289 55.8816 13.1316 57.5908 68.7462 70. - - - - - - - - - - - - - - TABLE 7: The task-wise performance (%) of Baseline under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.6890 62.9859 yelp 62.8706 61.1971 amazon 59.6392 56.0028 MNLI 57.6580 53.4228 CB 46.5305 57.0003 COPA 57.5918 55.6244 QQP 58.7280 54.3172 RTE 61.4086 55.4868 IMDB 59.5391 54.3172 SST-2 57.9254 52.4596 dbpedia 58.9884 50.3612 agnews yahoo 44.4589 42.1053 MultiRC 52.5617 53.1820 BoolQA 53.9872 55.3492 44.1979 50.5332 WiC 66.4868 64.6382 63.7807 62.6225 39.3100 59.7035 63.9185 68.7456 65.8720 64.6626 71.1825 47.0912 51.9558 52.6907 39.2741 - - - - - - - - - - - - - - - - - - - - - 66.4868 64.6579 64.6184 55.9211 50.0395 85.3816 56.3026 50.5132 80.8158 94.6429 51.5395 45.2763 20.5921 8.9286 96.0000 58.6579 54.3816 39.7763 48.2143 97.0000 85.5921 56.2632 50.3553 62.8158 83.9286 95.0000 84.7368 89.8917 56.0658 55.5526 63.0658 85.7143 95.0000 85.1053 88.8087 82.7368 51.5132 49.1842 63.2632 85.7143 96.0000 78.2105 89.5307 82.3158 96.1009 47.7237 42.7895 63.6842 85.7143 97.0000 85.1711 88.0866 47.9474 66.9725 98.9605 48.3553 44.1711 62.8289 83.9286 38.0000 84.3947 68.2310 76.9737 92.8899 86.6184 92.8947 26.9737 3.8421 48.4079 60.7143 15.0000 29.4211 26.7148 38.9342 47.7064 72.9737 83.2895 73.8816 37.8026 27.0526 42.3684 37.5000 43.0000 84.7237 56.3177 75.5658 92.6606 67.5526 44.7895 15.8158 76.0520 41.6316 27.7632 31.3289 32.1429 40.0000 82.5789 46.5704 78.9342 92.6606 68.5789 42.5526 16.6053 74.1337 84.8318 23.9211 14.6579 19.0395 17.8571 27.0000 61.4342 16.6065 67.3553 75.5734 42.8289 32.7237 12.9474 69.8226 71.5596 73.6677 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 8: The task-wise performance (%) of BaselineR under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 17 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.0879 62.4011 yelp 62.5326 60.6467 amazon 57.3472 58.2387 MNLI 53.2286 58.1355 CB 44.9626 57.7227 COPA 61.5757 57.9291 QQP 60.0372 54.9364 RTE 60.8189 55.2460 IMDB 60.7176 55.9340 SST-2 60.6662 55.2460 dbpedia 62.0695 54.0420 agnews yahoo 52.3671 48.4004 MultiRC 56.9748 57.1723 BoolQA 56.0990 58.3419 49.1011 55.5556 WiC 65.8684 64.5395 56.4825 49.0856 36.8226 65.7121 66.1823 67.6424 66.3961 67.2657 72.8979 57.0421 56.7786 54.0222 43.9903 - - - - - - - - - - - - - - - - - - - - - 65.8684 64.8158 64.2632 46.3421 37.6447 85.4605 39.6974 31.0263 76.2368 89.2857 58.0789 51.6974 0.2105 0.0000 94.0000 63.8158 61.5921 51.4342 80.3571 88.0000 85.6053 61.6579 57.7763 60.7368 80.3571 85.0000 83.2895 91.3357 54.4211 53.9868 61.7895 83.9286 83.0000 84.2237 90.9747 82.6184 49.8816 49.4868 62.3158 83.9286 90.0000 83.7895 90.6137 81.8421 95.5275 46.5921 46.6316 64.0000 87.5000 95.0000 84.3421 89.1697 59.6711 83.6009 99.1711 48.0526 47.7105 63.8026 85.7143 84.0000 84.2500 88.0866 82.2368 95.5275 88.0658 92.7763 35.9605 13.1316 52.4868 73.2143 31.0000 57.2368 62.4549 55.3289 84.7477 78.8158 86.7368 73.4868 44.7237 41.2632 40.6711 37.5000 68.0000 83.8947 63.5379 67.8289 91.7431 76.5921 60.2105 22.8947 75.4125 46.5658 38.4342 12.6447 0.0000 57.0000 80.9079 14.8014 71.6974 86.2385 75.7368 59.6184 18.8553 74.5050 83.6391 30.5263 14.2105 2.5000 1.7857 43.0000 72.5395 3.2491 59.7895 62.2706 66.3816 55.6842 16.6711 69.8845 78.1346 69. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 9: The task-wise performance (%) of BaselineR with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.8132 63.5707 yelp 62.3487 60.4403 amazon 61.7917 56.2092 MNLI 61.9254 56.4499 CB 45.0773 56.1060 COPA 57.0507 54.2484 QQP 58.2697 52.9412 RTE 58.2656 51.7716 IMDB 58.8497 53.4572 SST-2 57.8783 52.7692 dbpedia 59.8917 51.1868 agnews yahoo 52.1987 47.6436 MultiRC 60.1670 53.9044 BoolQA 59.8226 55.2804 46.0985 51.0492 WiC 66.1053 64.3816 68.6053 68.5772 37.6721 60.1584 64.7910 66.6224 65.4522 64.0827 72.1640 57.7168 68.0761 65.1781 42.0231 - - - - - - - - - - - - - - - - - - - - - 1.7857 96. 66.1053 64.8158 63.9474 63.0395 56.9211 85.8553 63.0526 57.6711 84.7763 100.0000 55.6184 53.0789 3.8158 58.3289 57.7500 38.8158 57.1429 86.0000 85.4211 57.5132 55.1184 61.5789 85.7143 87.0000 83.5658 90.6137 51.3289 51.9474 61.8026 83.9286 89.0000 84.1316 89.8917 82.6316 48.6974 46.3421 62.7632 85.7143 88.0000 82.5263 88.4477 82.2632 94.9541 46.7368 43.2763 63.0000 85.7143 94.0000 82.5658 86.2816 48.8158 60.4358 99.1579 48.6053 50.7237 62.2895 83.9286 85.0000 77.7237 85.5596 81.2105 94.3807 88.2632 93.0395 43.4342 26.0789 62.2632 85.7143 35.0000 39.6842 66.4260 56.0658 77.1789 72.6316 85.1316 73.9868 47.3553 45.5789 64.1711 87.5000 79.0000 83.3947 85.1986 80.0132 93.1193 91.7895 74.8289 48.9211 75.5569 48.6842 41.2500 57.7763 64.2857 73.0000 79.6974 63.8989 79.2105 92.6606 89.6579 71.2105 37.5263 72.5248 84.9847 24.6842 13.3158 28.4737 42.8571 37.0000 63.4737 19.4946 56.5658 42.0872 59.8947 45.7500 15.4079 65.4084 69.6024 74.2947 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 10: The task-wise performance (%) of BaselineR+KL under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.3784 63.1235 yelp 63.1231 62.0227 amazon 62.1276 59.8555 MNLI 58.7442 59.9587 CB 42.4836 59.5803 COPA 58.3575 53.6636 QQP 58.1002 52.1156 RTE 60.5976 54.1796 IMDB 60.2305 54.6956 SST-2 60.1338 53.4228 dbpedia 60.8271 52.0124 agnews yahoo 46.7187 45.5452 MultiRC 55.4975 56.8627 BoolQA 51.6320 56.6219 42.4638 52.7692 WiC 65.6842 64.2632 64.5789 57.5779 33.0110 63.9514 65.6375 68.7404 67.0118 68.7731 73.2392 47.9543 54.1962 47.4503 35.5259 - - - - - - - - - - - - - - - - - - - - - 65.6842 64.5921 63.9342 55.9868 52.7237 85.0263 50.6974 45.8816 75.8816 94.6429 50.8816 47.4342 0.1053 0.0000 98.0000 60.4342 53.7500 55.7105 80.3571 76.0000 85.6316 60.3421 53.6184 62.9605 87.5000 85.0000 84.3158 90.2527 55.4868 56.4474 63.5000 87.5000 83.0000 84.3947 89.5307 82.7895 50.7500 50.2895 63.5263 87.5000 89.0000 84.1184 89.1697 81.8947 95.1835 49.9079 46.4474 64.4737 87.5000 94.0000 84.6184 88.0866 65.3158 82.3394 99.1447 52.6842 46.3816 64.1974 87.5000 82.0000 83.5526 83.0325 81.9605 94.9541 87.6842 93.1447 22.3421 2.8684 50.6974 60.7143 25.0000 35.9868 56.3177 39.4737 62.2706 74.0000 83.3158 73.2105 41.7368 33.8684 29.7895 30.3571 76.0000 84.3026 35.3791 75.5395 92.6606 72.5921 53.3026 25.1711 75.2475 38.6842 22.7105 4.1579 1.7857 45.0000 81.0132 1.0830 62.7895 81.7661 68.6974 52.5658 15.0395 73.2673 83.7003 17.8026 7.2368 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1.1974 0.0000 34.0000 60.4737 0.3610 48.9868 50.0000 51.0395 45.0000 15.4474 66.1304 69.3884 69. - - - - - - - - - - - - - - TABLE 11: The task-wise performance (%) of BaselineR+KL with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 65.3544 64.9123 amazon 63.3547 62.9515 MNLI 65.8955 61.4035 CB 66.4280 62.1603 COPA 55.2835 59.2363 QQP 63.2466 57.3443 RTE 62.3130 57.0691 IMDB 62.8281 57.3443 SST-2 63.8494 58.4451 dbpedia 65.5645 58.5827 agnews 65.8130 57.8259 60.6606 53.6292 yahoo MultiRC 64.4890 57.4475 BoolQA 64.8161 58.4795 60.3147 54.9364 WiC 65.8026 63.7632 71.0965 71.3248 51.8252 70.5033 68.6180 69.4715 70.3549 74.4356 76.3600 69.8140 73.4978 72.6927 66.8605 - - - - - - - - - - - - - - - - - - - - - 65.8026 63.8421 63.6842 64.9605 62.8289 85.5000 65.1053 63.2105 85.4868 94.6429 62.6447 61.8553 30.5395 33.9286 95.0000 63.4211 62.1579 69.8421 89.2857 91.0000 86.1842 64.1974 61.3421 62.5789 87.5000 93.0000 85.1053 90.2527 56.7500 58.3684 63.1579 87.5000 94.0000 85.1447 89.8917 82.7368 58.1053 57.9342 64.0132 89.2857 95.0000 85.2500 88.4477 82.3553 96.4450 55.1316 56.2368 64.5789 87.5000 95.0000 85.6053 86.6426 82.6579 95.6422 99.1579 56.2632 56.2632 64.6842 89.2857 97.0000 85.5000 86.2816 82.6053 95.5275 93.3026 92.9737 49.8421 42.7368 64.5658 91.0714 96.0000 70.5263 76.1733 80.1184 93.9220 87.4211 87.2763 72.5263 55.6053 56.4605 64.7237 91.0714 97.0000 84.5658 84.8375 82.3816 95.2982 98.6184 86.5526 54.6053 75.2475 55.7368 56.5263 65.0263 89.2857 98.0000 81.5789 81.5884 82.4211 95.1835 98.6579 85.8026 46.3684 74.4431 84.1896 56.8289 53.1711 59.8947 82.1429 89.0000 67.5000 71.8412 81.3158 89.2202 97.1053 79.0658 33.3026 67.3267 73.1193 73.5110 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 12: The task-wise performance (%) of BaselineR+L1 under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 18 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.1065 64.2243 yelp 63.3069 62.7107 amazon 63.4374 57.7227 MNLI 62.6949 56.6563 CB 44.5302 56.2779 COPA 58.2426 52.1844 QQP 56.6823 49.0196 RTE 55.7876 48.1596 IMDB 57.0907 50.0860 SST-2 62.7512 56.1404 dbpedia 63.3294 55.4180 agnews yahoo 56.9157 50.4988 MultiRC 63.4436 57.0003 BoolQA 64.0448 57.7915 60.0691 54.5924 WiC 66.0132 63.9145 70.4079 70.1741 36.8400 65.8921 67.1845 66.2868 66.3732 71.1267 73.8758 65.2009 71.5293 71.8155 66.7673 - - - - - - - - - - - - - - - - - - - - - 66.0132 64.2237 63.6053 64.7237 61.2237 85.2763 64.6842 62.1711 83.5263 89.2857 56.9605 53.0263 0.0000 0.0000 98.0000 60.2237 59.4737 57.6053 83.9286 92.0000 85.7895 61.1711 59.5395 62.6974 80.3571 88.0000 84.0658 91.6968 49.2763 50.5526 63.2632 83.9286 89.0000 84.6579 92.0578 82.3158 48.2237 49.3553 63.8289 85.7143 91.0000 84.3289 90.9747 81.5132 94.7248 46.3947 48.1974 65.0132 89.2857 96.0000 84.5921 87.7256 79.6842 94.0367 99.1842 49.3947 52.5526 64.6579 85.7143 97.0000 84.5132 81.9495 82.3684 94.7248 87.5263 93.0395 45.4474 32.3421 62.5000 85.7143 93.0000 59.4737 67.8700 74.9737 92.3165 83.5789 86.2632 73.3026 52.2500 54.4737 64.6184 89.2857 97.0000 83.8947 83.7545 81.8816 95.4128 97.4474 80.9342 50.1711 76.0932 52.9605 54.3684 64.4737 85.7143 98.0000 82.5921 82.3105 82.0263 95.1835 98.1316 81.6842 47.4737 75.3094 83.6086 57.5395 54.6316 51.1316 80.3571 83.0000 67.8421 68.2310 80.6316 90.0229 95.1842 79.4868 39.7500 69.3276 73.1804 72. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 13: The task-wise performance (%) of BaselineR+L1 with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.9877 64.6371 yelp 63.7353 63.8459 amazon 65.0210 59.6491 MNLI 65.5054 60.8187 CB 55.3894 59.1675 COPA 63.0276 57.6883 QQP 61.9077 57.2067 RTE 62.5765 57.8947 IMDB 62.9953 58.1699 SST-2 64.5297 58.2043 dbpedia 65.1227 57.5851 agnews yahoo 58.8319 53.6292 MultiRC 63.7090 56.5875 BoolQA 64.2837 58.3075 60.6113 55.0052 WiC 65.3421 63.6250 71.4561 70.9748 52.0648 69.4561 67.4505 68.0821 68.6936 72.3974 74.9307 65.1526 72.8810 71.6247 67.4899 - - - - - - - - - - - - - - - - - - - - - 65.3421 63.9342 63.3158 65.0263 63.1579 86.1842 65.1184 62.9474 84.6842 94.6429 62.9605 61.6316 31.1579 30.3571 98.0000 63.4868 61.2368 66.7237 85.7143 93.0000 85.9474 63.8816 59.6184 61.7237 87.5000 95.0000 83.1316 93.1408 55.1053 55.3289 62.5395 87.5000 95.0000 83.5000 91.6968 82.5789 54.7237 54.9079 63.5263 89.2857 96.0000 83.8289 90.6137 82.0526 95.8716 52.0789 50.1579 64.3947 91.0714 94.0000 84.2763 86.6426 80.8421 94.7248 99.1316 53.9474 54.2237 64.5658 87.5000 95.0000 83.9211 81.9495 82.6053 95.5275 89.5658 92.7105 47.0526 33.7237 60.7105 83.9286 87.0000 55.3421 62.8159 78.0526 92.4312 81.8684 87.5789 73.4211 52.2500 53.1842 64.4211 89.2857 97.0000 84.3816 84.8375 82.2632 95.2982 97.7105 88.0526 55.4211 75.8870 54.8684 55.4079 64.3289 85.7143 95.0000 81.4342 82.3105 82.4342 95.4128 97.8816 84.7105 40.6842 74.6081 85.1376 56.1842 54.8026 59.0921 75.0000 91.0000 65.4737 71.1191 82.2105 94.1514 95.9737 82.5000 34.5789 68.4406 77.6147 74. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 14: The task-wise performance (%) of BaselineR+L2 under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.9750 64.1555 yelp 63.8210 63.7083 amazon 65.9386 62.2291 MNLI 65.0262 60.8187 CB 50.7358 59.8555 COPA 62.3038 56.6219 QQP 61.5376 56.1404 RTE 61.4934 57.1723 IMDB 63.0449 59.2707 SST-2 64.8693 58.3419 dbpedia 64.5281 57.3443 agnews yahoo 55.2611 52.0468 MultiRC 64.8105 59.8211 BoolQA 64.1808 59.6147 61.2686 56.6219 WiC 65.8158 63.9342 70.1184 69.8591 44.0277 69.2532 68.0829 66.5210 67.3324 73.0413 73.7694 58.8986 70.7078 69.5043 66.7462 - - - - - - - - - - - - - - - - - - - - - 65.8158 64.0263 63.8421 64.8684 60.8684 84.6184 65.7105 61.1579 82.5132 96.4286 61.6711 60.5395 9.4737 3.5714 97.0000 63.4868 61.2895 65.8289 83.9286 91.0000 86.0132 63.6974 60.0921 62.8947 87.5000 93.0000 84.3816 89.8917 49.6447 51.6053 63.1184 89.2857 93.0000 84.3026 90.9747 82.5263 50.2500 52.0921 63.5658 91.0714 95.0000 84.3684 88.8087 81.9474 94.4954 51.4605 53.2500 64.5921 91.0714 96.0000 84.7237 83.0325 81.7105 94.7248 99.2237 53.0658 53.7895 63.4605 87.5000 94.0000 81.7368 79.4224 82.5526 95.2982 85.7368 93.0000 47.2895 27.2895 61.3947 78.5714 89.0000 34.8684 66.7870 61.5526 85.4358 78.0000 83.7895 73.1316 54.4211 54.2763 64.2105 87.5000 95.0000 83.2632 82.3105 82.0395 94.2661 96.4079 79.8816 44.7105 75.2269 56.1711 55.9737 60.9474 75.0000 97.0000 82.8816 75.4513 82.2105 94.7248 95.9079 77.0000 33.6842 73.2467 81.9572 56.7237 54.3947 56.6711 85.7143 92.0000 65.4474 66.4260 81.5395 93.3486 93.8026 78.7895 37.1974 67.6155 77.6147 74.6082 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 15: The task-wise performance (%) of BaselineR+L2 with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 65.6759 66.0131 amazon 64.7975 65.0843 MNLI 66.9683 64.7059 CB 66.9523 64.8091 COPA 65.2217 63.6395 QQP 67.0591 64.4307 RTE 64.1356 62.2979 IMDB 64.5184 61.6443 SST-2 65.5431 61.9195 dbpedia 66.6747 60.5091 agnews 68.2080 61.7475 66.5029 59.9243 yahoo MultiRC 67.5049 60.9907 BoolQA 63.1795 56.1404 64.3973 57.9635 WiC 65.3421 64.5132 69.3947 69.2422 66.8845 69.9110 66.0850 67.6736 69.6171 74.2394 76.1783 74.7041 75.5769 72.2370 72.4376 - - - - - - - - - - - - - - - - - - - - - 65.3421 64.8421 64.1842 62.9474 60.8684 84.3684 62.8553 60.9474 83.7763 89.2857 63.0132 61.5000 75.6184 87.5000 95.0000 62.7500 60.3289 71.1711 87.5000 97.0000 84.9079 61.8684 59.4605 61.4605 85.7143 96.0000 80.1842 88.8087 56.6711 53.8947 63.0789 89.2857 94.0000 81.3026 85.1986 82.2763 58.2500 57.1579 63.7632 89.2857 94.0000 82.6579 84.4765 82.2763 95.5275 56.6974 55.2368 66.9605 91.0714 90.0000 82.5000 80.8664 82.0789 95.0688 99.0000 57.1184 53.6447 64.9605 91.0714 85.0000 83.2237 80.8664 82.7105 95.5275 96.6447 92.3289 56.3421 51.7763 64.7895 91.0714 89.0000 83.3421 78.7004 81.9211 94.2661 95.3684 90.1184 71.2763 56.7368 55.9474 64.7500 87.5000 93.0000 83.1842 80.8664 82.4868 95.0688 96.9868 89.6053 71.1974 77.1040 55.5658 56.0658 51.6316 53.5714 69.0000 68.5789 59.5668 81.5658 95.4128 96.8553 89.3684 71.2895 71.0190 85.5657 56.5263 55.5000 61.2105 76.7857 81.0000 62.9342 68.9531 81.6447 95.1835 98.0263 88.0000 70.0921 72.1328 78.9602 76.3323 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 16: The task-wise performance (%) of BaselineR+L1 (w=100) under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 19 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 66.3682 66.4603 yelp 64.9774 65.1531 amazon 65.9586 64.7403 MNLI 65.5301 64.3963 CB 62.8714 62.8139 COPA 64.7986 63.4675 QQP 63.7388 62.8483 RTE 64.6181 62.9515 IMDB 65.4947 62.3667 SST-2 66.9472 60.6467 dbpedia 68.2635 61.4723 agnews yahoo 67.7980 61.8851 MultiRC 68.0148 62.2979 BoolQA 68.6232 62.5387 64.5103 59.0299 WiC 66.2763 64.8026 67.2237 66.7046 62.9291 66.1867 64.6548 66.3753 68.9531 74.7085 76.7416 74.9601 74.8869 76.0193 71.1125 - - - - - - - - - - - - - - - - - - - - - 66.2763 65.0000 64.6053 59.8026 58.0263 83.8421 60.2500 58.0395 81.6316 92.8571 59.5526 57.2895 71.3158 87.5000 97.0000 55.1974 52.2368 71.9342 92.8571 95.0000 84.8026 56.9474 55.0132 61.5789 91.0714 95.0000 83.6974 86.2816 51.2237 50.9342 62.2237 91.0714 93.0000 83.7895 85.9206 82.4605 56.0395 55.2763 63.0132 91.0714 93.0000 84.2632 87.3646 81.9605 95.6422 58.0526 56.8158 64.0789 91.0714 92.0000 84.4868 86.6426 82.5658 95.8716 99.0395 57.6447 54.8026 64.5000 91.0714 96.0000 84.2632 86.6426 82.6447 96.5596 98.3684 91.9737 54.4474 52.2500 65.3816 89.2857 95.0000 83.6711 86.2816 82.4079 96.4450 97.5921 89.4474 71.2368 53.8289 51.4737 65.9474 85.7143 96.0000 83.7368 83.3935 81.9079 95.6422 97.6316 89.4211 71.3026 76.1345 58.9737 54.8947 68.5921 82.1429 96.0000 82.0658 81.2274 82.1316 94.9541 97.9868 87.8421 70.9868 73.8449 83.9144 55.4211 51.0132 63.9079 78.5714 95.0000 62.7368 72.5632 78.6579 88.6468 98.3421 88.7105 71.1711 65.2021 71.2844 73. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 17: The task-wise performance (%) of BaselineR+L1 (w=100) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.7533 65.8755 yelp 64.7048 65.1187 amazon 66.8373 64.1211 MNLI 66.9012 64.2243 CB 60.6423 63.2955 COPA 66.4575 61.6099 QQP 62.4516 59.9587 RTE 62.4123 60.1307 IMDB 64.4296 60.3715 SST-2 65.7177 58.9267 dbpedia 67.2053 60.5779 agnews yahoo 65.6775 59.4771 MultiRC 67.7128 61.7819 BoolQA 67.8075 61.6787 66.1531 60.7499 WiC 65.6316 64.2961 69.7939 69.8110 58.2026 72.1331 65.1607 64.8739 69.0726 74.2778 75.4610 73.3210 74.9033 75.2887 72.6112 - - - - - - - - - - - - - - - - - - - - - 65.6316 64.1053 64.4868 63.5132 60.4474 85.4211 63.3158 60.6579 85.3158 89.2857 62.5395 60.6447 51.1316 28.5714 97.0000 62.4211 59.5263 80.2105 89.2857 94.0000 85.9605 60.6447 56.4605 62.1974 80.3571 90.0000 80.0000 89.8917 45.9211 47.3684 64.3684 89.2857 96.0000 82.6579 86.2816 82.6842 55.6316 55.3026 64.8026 91.0714 95.0000 83.5263 86.2816 81.9605 95.2982 57.0526 54.8158 65.3684 91.0714 93.0000 83.4079 84.8375 82.6184 96.1009 99.1447 53.3421 50.1842 65.3158 91.0714 92.0000 83.2500 84.4765 82.5658 95.8716 97.9737 92.5921 51.6974 46.6579 65.4868 89.2857 91.0000 83.0000 82.6715 82.5395 95.1835 92.1447 89.8158 72.0263 54.7105 50.5395 65.8026 91.0714 97.0000 83.8947 85.5596 82.6316 95.7569 96.9211 88.2237 71.7105 77.4134 55.8816 52.4342 65.5395 85.7143 96.0000 82.2895 77.6173 82.2763 95.7569 98.3553 88.3026 69.8553 74.9587 86.4526 54.8553 50.4474 62.2105 75.0000 95.0000 69.0395 70.7581 82.2237 94.6101 98.1053 88.7237 70.8026 70.1526 79.6636 75. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 18: The task-wise performance (%) of BaselineR+L2 (w=100) under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.7186 65.9787 yelp 64.9316 65.6691 amazon 63.5951 64.6027 MNLI 63.7175 64.6371 CB 32.8576 61.4379 COPA 63.9195 61.2315 QQP 61.8861 57.6539 RTE 62.1552 57.6883 IMDB 62.9882 57.5851 SST-2 65.7139 58.2731 dbpedia 65.6319 57.1723 agnews yahoo 66.0016 59.4427 MultiRC 66.4442 60.0275 BoolQA 66.9701 59.7179 64.6643 57.8947 WiC 65.4605 64.2105 62.6184 62.8238 22.4255 66.8543 66.7888 67.3718 69.5102 75.3331 77.0296 74.1873 74.3970 76.2272 73.2265 - - - - - - - - - - - - - - - - - - - - - 65.4605 64.6053 63.8158 53.8684 48.1842 85.8026 56.4079 50.9079 80.9211 94.6429 36.8947 29.5658 0.0000 0.0000 97.0000 64.3421 61.0526 56.2500 51.7857 90.0000 85.5789 63.3684 57.4605 62.4868 83.9286 95.0000 82.5658 88.0866 56.1447 54.9737 60.3553 83.9286 93.0000 81.9342 88.4477 82.2237 58.0789 57.1316 63.2895 87.5000 96.0000 83.2105 87.7256 81.7237 95.4128 59.0658 57.7237 66.1579 87.5000 95.0000 84.6842 86.6426 82.2237 95.6422 99.0526 58.1711 55.7500 65.8947 89.2857 97.0000 84.8553 85.1986 82.5132 95.6422 96.5263 92.7105 55.3158 49.1184 64.8947 87.5000 96.0000 84.3947 85.9206 82.2500 94.8394 93.4868 89.3158 71.5395 53.8553 50.9868 67.7632 85.7143 98.0000 84.2105 83.7545 79.9342 95.1835 93.0658 89.8684 71.1184 76.3614 58.1053 56.3684 68.7500 85.7143 96.0000 81.5789 79.4224 81.7105 95.7569 96.7632 89.2237 71.4211 74.5875 86.1162 56.9737 54.8158 67.3026 85.7143 97.0000 64.1316 73.2852 80.5263 93.2339 96.5395 89.7763 71.3289 71.1427 79.6942 76.3323 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 19: The task-wise performance (%) of BaselineR+L2 (w=100) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 65.8252 65.7035 amazon 64.7036 65.0155 MNLI 66.9695 62.7795 CB 66.3947 62.0227 COPA 51.3578 59.8555 QQP 66.0079 60.8531 RTE 64.3613 60.4059 IMDB 64.2449 59.8211 SST-2 65.1182 60.1995 dbpedia 61.1287 53.1476 agnews 64.1442 55.2116 54.1623 47.5404 yahoo MultiRC 62.6109 55.5556 BoolQA 63.5635 56.5187 59.4309 53.1132 WiC 65.9474 64.3947 71.7588 71.4298 44.9730 72.1168 68.8710 69.3753 70.9121 71.9305 76.5251 62.9273 71.7190 72.6144 67.4546 - - - - - - - - - - - - - - - - - - - - - 65.9474 64.9868 63.8026 65.2105 64.1579 85.9079 65.1842 64.4211 84.5132 94.6429 63.7500 63.3158 7.4868 0.0000 98.0000 64.2895 63.2763 74.3158 85.7143 98.0000 86.1447 63.8816 62.2895 62.9605 87.5000 98.0000 85.0000 91.6968 57.0132 57.4737 63.6316 91.0714 98.0000 84.5789 90.6137 82.8684 59.1974 59.5921 64.3421 89.2857 98.0000 84.8026 87.7256 82.6579 95.8716 53.7500 51.1711 65.0526 87.5000 95.0000 85.3684 80.8664 74.0658 91.7431 99.1579 59.4211 58.7632 65.5921 89.2857 98.0000 83.4342 72.2022 82.7763 94.4954 90.4211 92.9868 55.8553 37.2632 59.0789 69.6429 59.0000 27.5000 45.8484 79.1711 91.1697 80.9079 87.6579 73.3684 56.5395 56.9868 66.2368 87.5000 84.0000 84.0658 81.5884 82.5000 94.7248 96.8553 75.8947 48.9868 75.4950 57.4868 58.1447 66.5395 87.5000 63.0000 84.2368 82.6715 82.7763 95.6422 97.9737 77.2368 46.1974 75.3507 85.5963 57.3158 55.1053 60.9079 80.3571 86.0000 60.9605 68.9531 82.1316 91.5138 97.7237 77.8158 47.6579 60.3960 68.8991 76.3323 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 20: The task-wise performance (%) of BaselineR+L1 (w=dy) under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 20 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.7648 65.3251 yelp 63.7685 63.7083 amazon 64.3991 61.2315 MNLI 63.8369 60.6811 CB 9.8956 58.8923 COPA 62.0373 56.2092 QQP 58.2216 53.8700 RTE 60.9780 55.5900 IMDB 61.6219 56.6907 SST-2 59.2123 52.1844 dbpedia 60.6088 52.3564 agnews yahoo 47.1703 40.9013 MultiRC 59.5038 53.4228 BoolQA 61.0059 55.4524 58.3556 53.2852 WiC 66.2105 63.8289 67.9123 67.3390 5.4016 69.2139 63.3380 67.5227 67.4927 68.4277 71.9494 55.7089 67.1471 67.7955 64.4925 - - - - - - - - - - - - - - - - - - - - - 0.0000 0.0000 97. 66.2105 64.4079 63.2500 61.3421 57.0789 85.3158 61.7763 57.7500 82.2763 96.4286 11.6974 3.3421 64.6579 61.4868 64.6447 87.5000 92.0000 85.6316 63.5789 58.4737 62.1974 87.5000 92.0000 67.5658 90.2527 53.0658 55.2500 62.7500 87.5000 95.0000 82.3947 88.8087 82.8684 51.5921 52.6184 63.8421 91.0714 97.0000 83.0132 87.0036 81.9868 94.8394 43.3421 44.7105 64.6447 89.2857 94.0000 83.1053 83.0325 72.3421 87.7294 99.1842 43.4211 47.8816 63.8158 85.7143 93.0000 82.2368 83.3935 82.3289 95.1835 87.4868 93.0132 35.8816 20.7368 61.5789 76.7857 80.0000 9.5395 62.4549 70.3684 89.7936 81.3289 88.1579 73.4474 47.6447 49.9605 64.7237 91.0714 20.0000 84.7500 86.2816 81.2368 94.6101 95.2763 70.4737 34.7368 74.9381 48.4474 49.8947 64.6711 91.0714 14.0000 83.7895 86.6426 82.0658 95.1835 95.9605 70.1974 33.0132 73.2467 85.3517 49.4079 50.3026 62.8684 85.7143 22.0000 71.2368 81.2274 81.6316 94.6101 93.7237 68.3421 30.3816 65.2847 71.7431 73.5110 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 21: The task-wise performance (%) of BaselineR+L1 (w=dy) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 66.3052 66.1507 yelp 64.8726 64.6027 amazon 66.7933 63.1579 MNLI 66.7035 62.9515 CB 49.6547 59.8555 COPA 63.6291 57.3099 QQP 61.9088 57.0347 RTE 61.9748 57.1723 IMDB 63.2228 57.9979 SST-2 65.5600 58.7203 dbpedia 64.6367 56.2092 agnews yahoo 56.9917 51.4964 MultiRC 66.5245 59.8555 BoolQA 65.9936 58.7891 62.1001 55.1772 WiC 66.4605 65.1447 70.8728 70.9310 42.4246 71.5146 67.6937 67.6580 69.4823 74.2032 76.0371 63.8000 74.8660 75.2104 71. - - - - - - - - - - - - - - - - - - - - - 66.4605 65.4737 64.8158 64.1711 63.6316 84.8158 64.4342 63.4605 84.7237 94.6429 63.1974 62.5526 1.0921 3.5714 97.0000 62.9737 61.9868 74.7763 89.2857 96.0000 85.8684 63.0000 60.3684 62.1711 83.9286 97.0000 83.9868 88.0866 53.2763 53.6974 63.3289 87.5000 97.0000 84.1184 87.0036 82.6316 56.1447 55.8553 64.0132 85.7143 96.0000 84.6184 87.0036 82.6316 95.9862 54.5658 56.3289 64.7368 89.2857 96.0000 84.9737 82.3105 82.2632 95.4128 99.2237 57.6184 55.6316 64.7237 87.5000 95.0000 84.7368 79.0614 82.6974 95.4128 91.2632 92.9211 51.8947 35.6974 60.9737 80.3571 78.0000 46.4342 49.4585 72.8947 91.8578 80.5658 86.3816 72.5526 58.2368 57.4605 64.7237 85.7143 97.0000 84.5132 81.5884 82.3026 95.4128 98.2105 83.7895 65.8684 76.1964 59.4342 58.2368 64.6974 87.5000 96.0000 81.8421 80.1444 82.4079 95.4128 98.2368 84.7895 64.5789 75.5363 85.4128 58.9605 55.4211 58.7368 71.4286 94.0000 63.8026 63.5379 81.9342 93.2339 98.3026 84.3289 61.7105 70.8127 75.9939 74.2947 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 22: The task-wise performance (%) of BaselineR+L2 (w=dy) under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.7911 65.4283 yelp 63.3645 62.9515 amazon 67.1038 63.7083 MNLI 65.9670 62.9515 CB 46.6359 58.6859 COPA 61.3321 55.8996 QQP 59.3602 52.3564 RTE 58.6381 51.8060 IMDB 60.2293 53.3540 SST-2 62.2228 53.4572 dbpedia 63.7946 54.9708 agnews yahoo 58.2773 50.4300 MultiRC 64.7834 57.4475 BoolQA 63.4517 56.3123 60.7927 54.7988 WiC 66.1579 63.7829 70.8816 69.2860 38.6914 67.9343 68.5272 67.5461 69.1388 74.4270 75.9930 69.0170 74.2670 72.6642 68.2590 - - - - - - - - - - - - - - - - - - - - - 66.1579 64.0658 63.5000 65.2763 62.0000 85.3684 64.7237 61.6579 81.2632 98.2143 60.0789 55.5132 0.0000 0.0000 97.0000 64.5395 63.0263 57.8289 62.5000 92.0000 86.0658 64.0000 61.6316 62.6447 83.9286 89.0000 84.7500 87.7256 52.8816 54.0658 62.3947 91.0714 88.0000 84.6184 87.7256 82.5921 55.1184 56.0263 63.8289 87.5000 90.0000 84.4868 86.6426 82.1711 95.4128 55.0395 57.2105 65.0395 87.5000 95.0000 85.0789 83.7545 82.0132 95.1835 99.0921 55.6053 58.0658 64.7763 85.7143 95.0000 85.1447 82.6715 82.5921 95.6422 89.4605 93.4868 54.0789 44.6184 64.5658 87.5000 94.0000 66.1053 75.4513 72.1579 93.1193 84.4211 89.2763 73.4474 57.2632 56.7500 64.6316 85.7143 84.0000 82.6053 75.4513 81.8947 94.8394 98.3289 89.0658 61.1711 73.9686 56.1316 56.6053 63.3026 82.1429 88.0000 81.3421 71.8412 82.3026 95.5275 98.0263 89.1316 46.7105 72.4010 84.4343 55.7763 53.4868 57.9079 82.1429 65.0000 67.5921 64.9819 81.2895 93.4633 96.0526 89.3553 39.9868 65.2021 75.6881 74.7649 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 23: The task-wise performance (%) of BaselineR+L2 (w=dy) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 65.4521 65.0155 amazon 63.8612 63.8803 MNLI 65.4479 61.3003 CB 65.3685 60.9219 COPA 52.6889 58.0667 QQP 63.0186 59.6147 RTE 62.5993 58.5483 IMDB 63.6348 59.1331 SST-2 64.0274 59.1675 dbpedia 66.3010 60.0963 agnews 66.6486 59.1331 63.0513 55.6244 yahoo MultiRC 65.2985 57.5851 BoolQA 66.3967 59.1331 61.9756 55.3836 WiC 65.8947 63.8421 70.1974 70.5154 48.2227 66.8347 67.2526 68.8783 69.7570 73.9345 76.3526 72.7671 75.3977 75.6946 70.3490 - - - - - - - - - - - - - - - - - - - - - 65.8947 63.9868 63.6974 62.5658 61.6316 86.3947 63.5000 61.9079 86.0000 89.2857 60.8947 60.3816 23.0263 10.7143 97.0000 61.3553 59.4605 59.8421 80.3571 92.0000 86.2500 62.0526 58.6842 62.3553 82.1429 96.0000 84.5658 90.9747 56.4737 56.3816 62.9342 85.7143 97.0000 84.6974 89.8917 82.6447 56.9868 56.8289 63.6711 85.7143 95.0000 84.8421 88.8087 82.4079 95.0688 54.2895 54.7237 64.3421 85.7143 97.0000 85.4342 87.0036 82.4474 94.7248 99.1184 57.1053 56.8947 64.6053 85.7143 95.0000 85.3816 85.9206 82.6711 95.2982 91.6974 93.2763 51.4474 51.6974 64.6579 85.7143 93.0000 81.2632 79.7834 81.7895 94.8394 87.3553 87.2895 73.4868 55.1974 55.5395 64.4474 82.1429 96.0000 84.9079 87.0036 82.4342 95.0688 98.3684 87.1842 71.8816 75.7426 55.8684 56.2763 65.0263 83.9286 97.0000 83.4737 80.8664 82.3421 95.0688 98.6447 87.0395 70.5395 75.0825 84.9541 57.4868 54.5526 57.7763 76.7857 89.0000 63.1842 68.2310 80.6447 87.8440 98.5789 87.6184 69.1053 61.2624 63.2722 75.8621 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 24: The task-wise performance (%) of BaselineR+TM under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 21 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.1574 64.4995 yelp 63.1013 61.8163 amazon 62.4140 57.4819 MNLI 63.0028 57.9635 CB 45.2508 58.9611 COPA 61.5596 57.6539 QQP 61.1728 55.7276 RTE 61.3152 56.5531 IMDB 62.2389 57.2755 SST-2 64.5741 57.4475 dbpedia 64.5775 56.5531 agnews yahoo 58.1764 54.1796 MultiRC 65.0772 59.1675 BoolQA 65.5071 59.9243 62.7138 57.6539 WiC 65.8289 64.4408 68.2719 69.0016 36.7137 66.0329 67.7975 66.9529 68.1440 73.7192 75.2555 62.8098 72.2985 72.2370 68.7473 - - - - - - - - - - - - - - - - - - - - - 65.8289 64.9605 63.9211 61.7895 57.4737 85.5526 63.3289 59.3158 84.2237 87.5000 56.6974 52.4605 0.4474 0.0000 98.0000 62.0526 60.5132 55.2895 83.9286 94.0000 85.7763 63.3289 60.0395 62.6447 78.5714 95.0000 83.8289 92.7798 50.8947 52.3553 63.1974 78.5714 96.0000 84.4737 90.9747 82.5000 52.1842 53.5263 64.1184 80.3571 96.0000 84.5658 89.8917 81.8553 96.2156 53.4737 55.8947 65.1842 85.7143 98.0000 84.7895 88.4477 80.3553 95.6422 99.1579 53.9079 56.3947 64.3816 78.5714 99.0000 84.6184 88.4477 82.6316 95.1835 88.6711 93.0789 47.9079 28.8553 60.3947 80.3571 97.0000 51.6974 65.3430 71.5000 92.4312 83.0789 82.0263 72.9474 56.0132 56.2763 61.2500 80.3571 98.0000 83.6579 79.7834 81.7237 95.0688 97.2105 82.4868 54.8684 74.8350 56.4474 57.2632 58.9737 71.4286 99.0000 81.8289 75.4513 82.1316 95.7569 97.9342 83.3026 51.3947 73.0817 83.6697 58.0263 54.3947 53.8158 83.9286 98.0000 66.9605 70.0361 81.6711 93.3486 97.2632 81.4868 49.9737 67.8012 75.9021 75. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 25: The task-wise performance (%) of BaselineR+TM with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.1828 66.1851 yelp 64.2106 65.2219 amazon 67.0835 64.5683 MNLI 67.1489 64.4995 CB 67.3024 65.1531 COPA 67.5704 64.9467 QQP 65.2070 64.9123 RTE 67.0415 64.8779 IMDB 67.5522 64.9123 SST-2 69.8301 64.1555 dbpedia 70.3900 63.9491 agnews yahoo 68.0177 62.6075 MultiRC 67.9008 61.9883 BoolQA 68.2503 61.9883 66.7359 60.7155 WiC 64.2105 63.2303 69.8026 70.0254 69.5984 70.4150 65.5045 69.3545 70.4160 76.6059 78.2736 74.4513 75.0601 75.9196 74.0817 - - - - - - - - - - - - - - - - - - - - - 64.2105 63.6316 62.8289 63.6316 61.7368 84.0395 63.8553 62.0395 84.0395 89.2857 63.4079 61.6447 83.2632 89.2857 95.0000 61.0658 59.5658 76.6974 87.5000 95.0000 83.8816 60.9605 57.7368 61.0921 83.9286 94.0000 80.9868 85.5596 59.8684 58.6184 63.6184 87.5000 94.0000 81.7895 88.4477 81.7237 60.3026 58.8553 64.7500 83.9286 95.0000 82.4342 86.2816 81.8553 95.5275 63.4211 62.0658 66.9868 85.7143 93.0000 82.9737 84.1155 82.3684 96.1009 99.0263 62.5658 60.9474 66.1579 87.5000 94.0000 83.1184 83.3935 82.6579 95.6422 98.9211 91.0921 57.7500 53.8158 64.5263 83.9286 93.0000 80.2368 81.5884 81.1974 94.6101 98.4079 86.8684 69.9211 57.9211 56.0658 64.7368 85.7143 92.0000 80.9211 83.3935 81.0395 94.6101 98.5921 87.7237 69.9079 76.1964 61.3684 57.8816 67.0789 83.9286 90.0000 77.9474 79.0614 81.7895 94.6101 98.7763 87.5789 70.0395 74.3399 83.8226 59.8553 57.2368 60.1579 71.4286 88.0000 75.3289 76.5343 80.7105 94.1514 98.8421 86.6579 69.0263 74.9381 78.4404 72. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 26: The task-wise performance (%) of BaselineR+TM (w=100) under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.6749 66.3915 yelp 64.9092 65.2563 amazon 65.8225 65.2219 MNLI 64.7232 64.6715 CB 50.8783 63.3643 COPA 65.1654 62.8827 QQP 62.4651 62.4355 RTE 64.9101 62.9171 IMDB 65.6610 62.8827 SST-2 68.5353 63.9491 dbpedia 69.3027 63.6051 agnews yahoo 68.2932 63.5363 MultiRC 67.8287 62.6763 BoolQA 68.5678 62.6763 66.2396 60.9907 WiC 64.9737 64.5658 66.4342 64.7751 42.5030 67.6201 62.4947 67.0335 68.6961 73.8301 76.1215 73.8201 73.9041 75.6818 72.4771 - - - - - - - - - - - - - - - - - - - - - 64.9737 64.7895 64.3421 57.8684 57.0132 84.4211 59.1711 57.8158 77.1184 94.6429 57.7895 54.6053 14.6579 7.1429 97.0000 56.8158 54.8947 72.9868 91.0714 95.0000 85.2500 56.0526 53.8158 61.1447 89.2857 89.0000 77.5263 87.0036 55.8289 56.0789 61.5263 89.2857 93.0000 78.1184 87.3646 82.3684 57.5132 57.4605 62.4342 89.2857 90.0000 79.9079 87.7256 81.8947 96.1009 58.4342 56.7368 62.7500 89.2857 92.0000 80.3026 87.0036 82.4342 95.8716 98.9605 57.2895 55.4211 63.2895 89.2857 90.0000 81.8026 87.0036 82.6711 96.3303 97.8947 91.4868 53.6447 51.8289 62.1053 91.0714 86.0000 81.8816 86.6426 82.4079 96.3303 95.9605 88.8026 70.5921 50.9474 49.7632 65.2895 89.2857 95.0000 83.6053 84.8375 80.1579 93.8073 96.0263 89.2237 71.7632 76.0726 55.8947 55.9868 65.0658 82.1429 95.0000 81.8684 75.0903 82.0132 95.2982 97.0395 89.0263 71.4605 75.9282 85.9327 51.8158 52.5526 62.5132 82.1429 93.0000 72.4605 73.2852 80.3158 93.6927 98.1711 88.8553 71.6579 71.8647 70.1223 73.3542 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 27: The task-wise performance (%) of BaselineR+TM (w=100) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 66.2360 66.0131 amazon 65.2747 66.0131 MNLI 67.1812 63.7771 CB 67.4603 63.8459 COPA 67.7171 64.1899 QQP 68.4733 64.9811 RTE 66.7533 64.9467 IMDB 67.1946 64.9123 SST-2 67.8099 64.7747 dbpedia 68.1646 62.6763 agnews 69.7987 63.1579 66.5175 60.3371 yahoo MultiRC 68.4534 62.2635 BoolQA 68.4335 61.8163 66.9386 60.7843 WiC 66.4605 64.5526 70.9693 71.5086 71.6545 72.3622 68.6634 69.6433 71.1436 74.7063 78.0002 74.1084 76.0100 76.6373 74.4796 - - - - - - - - - - - - - - - - - - - - - 66.4605 64.5526 64.5526 64.9737 63.7632 84.1711 65.2105 64.0395 85.1316 91.0714 65.3421 63.9342 85.2237 87.5000 98.0000 64.5526 62.3947 76.8289 87.5000 97.0000 85.2368 64.5658 62.6053 62.5658 87.5000 97.0000 83.6579 89.1697 60.1842 57.8684 62.7895 89.2857 98.0000 83.8947 87.3646 82.3158 61.2763 59.7895 64.0526 89.2857 97.0000 84.1974 87.7256 82.5132 95.6422 55.8026 55.4211 67.1974 89.2857 96.0000 84.8553 85.5596 82.6711 95.1835 99.1579 59.8947 57.9342 66.2105 87.5000 96.0000 84.8816 83.3935 82.7763 94.8394 99.0000 92.8684 53.0263 49.8816 64.2105 87.5000 91.0000 83.0658 73.2852 82.5658 94.7248 96.9079 87.7632 72.7895 59.6053 57.8684 65.5921 85.7143 92.0000 83.8289 82.6715 82.4211 95.0688 98.6184 87.0132 69.9342 76.7739 61.4868 59.0921 66.3421 85.7143 94.0000 82.6316 79.4224 82.6184 95.9862 98.7895 86.8684 69.5263 75.5982 85.4434 60.9474 59.1579 62.3684 82.1429 94.0000 71.2763 73.2852 82.2763 94.3807 98.7763 86.9474 69.6842 72.4010 81.8960 74.2947 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 28: The task-wise performance (%) of BaselineR+TM (w=dy) under full-parameter setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 22 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 66.0494 65.7723 yelp 64.0687 63.4331 amazon 67.5616 64.6371 MNLI 66.9329 64.0179 CB 49.1982 58.4795 COPA 65.3409 61.7819 QQP 63.4401 59.8211 RTE 64.3878 60.3371 IMDB 64.4889 60.1651 SST-2 66.0656 59.3051 dbpedia 66.9819 59.1675 agnews yahoo 62.8714 55.2116 MultiRC 66.9502 61.1627 BoolQA 67.4003 61.3691 63.2068 57.2411 WiC 66.3289 64.7171 70.7632 70.1260 42.4595 69.3350 67.5251 69.0214 69.4823 74.5656 77.1746 72.9990 73.9474 74.7462 70.5607 - - - - - - - - - - - - - - - - - - - - - 66.3289 64.7632 64.6711 65.3816 62.2500 84.6579 64.9737 62.1842 83.0132 98.2143 60.0000 59.6974 7.2237 8.9286 96.0000 64.3421 62.7500 63.8421 62.5000 97.0000 86.0921 62.7763 59.5658 63.1053 89.2857 96.0000 83.3158 89.5307 56.2895 57.8289 63.5263 89.2857 97.0000 83.5132 89.1697 82.6974 55.7368 57.3421 64.2895 89.2857 98.0000 83.7500 87.0036 82.1579 95.4128 56.1974 57.1053 64.7895 85.7143 95.0000 84.5395 83.7545 82.5526 95.8716 99.0789 57.8816 57.6053 64.8421 87.5000 95.0000 84.8421 81.5884 82.5658 95.7569 97.0132 92.8684 55.1316 51.6842 64.4474 89.2857 94.0000 76.2632 81.2274 81.1447 95.0688 90.2895 89.2105 72.5921 56.6974 56.6053 65.0263 89.2857 96.0000 84.8947 81.5884 81.3947 95.2982 98.3158 79.8289 64.2895 76.1345 58.5395 58.3553 64.9605 87.5000 97.0000 81.3158 79.4224 82.2105 95.7569 98.5789 82.7105 63.8947 74.8762 84.8624 57.1053 55.1053 57.0395 78.5714 96.0000 68.6316 62.0939 79.2368 87.8440 98.5921 83.8158 64.2368 67.5330 71.1621 74. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 29: The task-wise performance (%) of BaselineR+TM (w=dy) with BI under full-parameter setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 63.5458 63.3299 yelp 62.1264 63.5019 amazon 61.0796 60.4403 MNLI 61.3035 59.9587 CB 62.8421 60.4403 COPA 63.3991 59.8899 QQP 62.4633 60.5435 RTE 65.8217 60.2339 IMDB 64.0636 60.0963 SST-2 65.4618 59.6491 dbpedia 65.0111 58.0323 agnews yahoo 62.6828 55.3492 MultiRC 63.8695 56.3811 BoolQA 65.6708 58.4795 63.3746 55.7620 WiC 63.7632 60.8092 61.7325 62.7100 65.4426 67.3452 64.5088 72.5522 68.5918 72.5296 73.8978 72.2567 73.6517 74.8786 73.3944 - - - - - - - - - - - - - - - - - - - - - 63.7632 60.6316 60.9868 52.3158 50.3026 82.5789 54.4474 52.3289 81.2105 82.1429 59.0263 58.8816 77.9342 82.1429 93.0000 53.7500 52.4605 78.7368 75.0000 93.0000 84.0395 57.2500 52.6053 68.0658 83.9286 91.0000 78.7763 87.7256 59.2763 58.8684 79.0921 91.0714 93.0000 82.0526 87.3646 82.5263 51.9211 52.4605 72.3684 80.3571 94.0000 80.2763 81.9495 82.0395 94.6101 53.1974 53.6579 69.8816 66.0714 92.0000 74.4868 80.1444 81.9079 94.8394 99.0000 44.7500 48.8026 72.9737 66.0714 90.0000 77.0526 79.0614 81.8026 93.8073 98.6053 90.6711 49.1974 49.0132 64.7237 33.9286 84.0000 77.9737 71.1191 80.4342 93.0046 96.4474 87.1842 70.8684 51.2895 49.1053 73.0921 73.2143 88.0000 79.7632 80.5054 79.4605 92.2018 97.0526 87.1974 68.9605 74.7937 55.5132 53.0000 70.7105 73.2143 90.0000 78.6974 77.2563 80.6974 92.0872 97.0658 88.0526 70.3289 73.7005 82.9358 55.0921 54.5263 69.2632 60.7143 91.0000 72.6316 72.9242 81.4211 93.1193 97.2895 86.9868 70.0395 69.1419 74.2508 71. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 30: The task-wise performance (%) of Baseline under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.8306 65.0843 yelp 63.1428 64.4995 amazon 62.9071 63.2611 MNLI 62.9278 61.1283 CB 63.3243 61.6443 COPA 64.3577 61.1283 QQP 62.9565 59.8555 RTE 64.9734 59.8555 IMDB 65.9899 60.2683 SST-2 67.4252 60.1307 dbpedia 67.7679 59.9587 agnews yahoo 64.5686 57.3787 MultiRC 66.1018 58.6515 BoolQA 66.6477 58.8923 66.0296 58.6515 WiC 64.5789 61.8421 62.5570 64.8364 65.0984 67.9474 66.3964 71.0483 72.9118 76.7338 77.9158 73.8185 75.7203 76.7555 75.5310 - - - - - - - - - - - - - - - - - - - - - 64.5789 62.4605 61.2237 55.5000 54.8684 77.3026 56.3026 55.7763 82.2500 89.2857 56.8947 55.5526 82.3026 87.5000 94.0000 57.6711 55.4737 75.2368 75.0000 93.0000 83.0263 55.5132 53.9605 72.8026 76.7857 90.0000 82.1184 88.4477 56.6447 55.9079 77.3553 76.7857 92.0000 82.8289 88.0866 81.5658 58.5263 58.2632 80.1184 78.5714 92.0000 82.4079 82.6715 82.0526 95.0688 58.1974 57.7105 79.4474 80.3571 91.0000 81.8684 84.8375 81.9605 94.4954 98.6711 59.8289 57.8684 74.7500 67.8571 88.0000 80.7368 83.3935 81.9079 93.6927 97.6842 90.5658 54.6842 51.0263 65.7105 58.9286 85.0000 80.1184 80.5054 81.6316 92.5459 96.0263 88.4079 70.5132 56.4211 53.9079 76.0000 73.2143 85.0000 81.3421 84.1155 81.8289 93.3486 96.8684 88.4079 69.5132 74.2162 59.8289 58.0789 79.2763 80.3571 85.0000 77.6447 79.4224 81.7237 93.4633 97.9342 88.8158 70.4474 70.9365 81.0703 60.2105 56.5263 77.1842 71.4286 85.0000 74.0789 79.7834 81.4342 93.5780 97.5789 88.6579 69.2237 71.0809 76.1774 70.6897 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 31: The task-wise performance (%) of BaselineR under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 64.0840 64.7747 amazon 62.9931 65.2563 MNLI 64.7046 63.9491 CB 64.5700 63.9147 COPA 63.7832 64.3963 QQP 67.3307 65.1875 RTE 62.2957 63.7083 IMDB 64.6159 64.0179 SST-2 66.5814 64.5683 dbpedia 67.6828 61.1971 agnews 67.5281 60.0275 63.4914 57.0347 yahoo MultiRC 64.8842 57.7227 BoolQA 65.9588 58.8579 63.8621 56.5187 WiC 63.4079 60.8816 65.4781 65.2389 63.1817 69.6197 60.9444 65.2252 68.7241 75.7062 77.1709 71.5965 74.0744 75.0082 73.3986 - - - - - - - - - - - - - - - - - - - - - 63.4079 60.6974 61.0658 56.3684 56.9868 83.0789 55.7895 57.3421 82.4079 89.2857 57.6974 59.6447 71.6184 83.9286 96.0000 59.8553 56.6842 77.6184 82.1429 97.0000 83.8684 54.6974 47.0658 60.6579 83.9286 98.0000 79.6711 89.1697 44.5395 48.6184 65.9737 85.7143 97.0000 83.2763 85.5596 82.4079 55.3816 53.3421 68.1579 85.7143 95.0000 80.7632 80.8664 82.0132 95.2982 60.5395 59.0789 72.0658 80.3571 92.0000 78.6184 81.2274 82.2368 94.9541 99.0395 58.6053 56.2500 71.9342 76.7857 92.0000 78.4868 83.0325 82.2763 94.9541 98.6711 91.5263 52.7105 46.5000 57.9342 37.5000 68.0000 74.7763 76.5343 81.7368 92.7752 96.6316 89.8947 70.2763 54.5132 48.5000 70.5000 82.1429 85.0000 78.7105 81.5884 81.5395 92.7752 97.5526 89.2895 68.7237 75.0825 58.9079 55.3816 69.1974 80.3571 84.0000 75.3158 77.2563 82.0132 94.9541 98.1711 87.7895 68.6842 73.2261 82.4771 58.3026 56.3816 69.5526 62.5000 84.0000 63.4605 71.8412 81.9737 94.1514 98.1842 88.3026 68.6316 70.4002 78.2263 71.6301 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 32: The task-wise performance (%) of BaselineR with BI under LoRA setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 23 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.6367 66.0819 yelp 63.7459 65.6003 amazon 65.2054 64.3963 MNLI 65.5178 63.9147 CB 66.0331 64.9811 COPA 66.7616 64.6371 QQP 65.6742 64.1211 RTE 68.0322 63.6739 IMDB 68.0461 63.5707 SST-2 69.5051 63.1235 dbpedia 68.8300 62.0227 agnews yahoo 65.4846 59.0987 MultiRC 66.7758 59.9243 BoolQA 66.9228 59.8555 67.2289 61.0251 WiC 65.1974 61.9934 66.0351 67.2034 67.1197 69.0306 67.3045 73.0310 73.1993 77.3222 77.3158 73.4176 75.3962 75.8825 74.8367 - - - - - - - - - - - - - - - - - - - - - 65.1974 61.8289 62.1579 58.1316 56.4605 83.5132 59.8421 58.2763 83.3553 85.7143 61.0658 58.5132 81.2368 89.2857 96.0000 59.5000 55.6579 76.4737 71.4286 96.0000 84.1184 58.1974 53.9342 72.6842 82.1429 95.0000 83.1974 87.3646 61.4474 58.2763 78.6842 85.7143 96.0000 83.7237 85.5596 82.1711 62.2237 57.7237 77.5000 78.5714 96.0000 82.8289 83.7545 82.3553 96.2156 61.6711 58.7763 78.3026 80.3571 93.0000 81.3684 84.4765 82.2895 94.9541 99.0132 58.4605 53.8816 74.3947 75.0000 91.0000 80.8553 84.1155 81.9737 93.6927 98.0526 91.3026 55.3158 49.8026 66.5263 62.5000 86.0000 78.2895 80.5054 81.2632 91.7431 95.4868 88.2895 69.9211 56.0000 51.9342 75.0263 71.4286 86.0000 81.4474 85.9206 81.7632 92.6606 97.1053 87.6579 69.7500 75.4125 59.5789 56.7368 76.4868 89.2857 82.0000 75.7632 81.9495 81.8684 93.2339 97.6053 85.9211 69.8158 72.3391 83.2110 59.2632 55.7895 74.1579 80.3571 85.0000 72.2895 76.1733 81.9474 92.6606 97.6711 86.6447 69.6184 70.7715 79.2966 71. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 33: The task-wise performance (%) of BaselineR+KL under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.5996 65.7379 yelp 63.6099 65.1531 amazon 64.9267 64.7059 MNLI 65.0925 64.9467 CB 65.4596 66.4603 COPA 66.9799 65.5315 QQP 65.7386 65.1875 RTE 64.6539 64.8435 IMDB 68.2430 65.6347 SST-2 71.2101 65.9099 dbpedia 70.7100 65.2907 agnews yahoo 66.9993 61.2315 MultiRC 68.4132 62.5043 BoolQA 68.7035 63.0547 66.7872 61.5755 WiC 63.5000 62.1382 65.1491 65.2389 64.4886 68.4939 66.2991 64.4654 71.0673 77.4374 77.1104 73.9667 75.5560 75.4639 72.9626 - - - - - - - - - - - - - - - - - - - - - 63.5000 62.5263 61.7500 56.4737 56.0526 82.9211 56.9342 56.8816 81.6974 92.8571 59.4474 60.4474 72.9605 87.5000 98.0000 54.2500 55.7895 79.6579 83.9286 99.0000 83.7632 56.2237 54.4474 71.5526 85.7143 97.0000 81.6842 86.6426 42.0526 40.4737 73.4474 85.7143 94.0000 82.4474 84.8375 82.6184 59.6447 54.6579 72.8947 85.7143 97.0000 81.9868 80.8664 82.5789 95.1835 63.0658 58.4737 77.1842 82.1429 96.0000 81.6974 81.5884 82.8026 95.1835 98.9342 58.8026 48.8158 76.5921 85.7143 95.0000 81.8553 80.1444 82.5526 94.9541 97.9868 90.7105 56.6974 51.2105 70.1184 80.3571 91.0000 76.6842 76.1733 80.9474 93.8073 95.8816 86.6316 70.9342 59.0395 52.6053 75.9474 82.1429 89.0000 79.9737 77.9783 81.3289 92.5459 97.2237 85.8158 70.2368 75.5776 58.8158 53.3421 72.0658 87.5000 91.0000 77.5395 74.0072 82.0526 94.1514 97.0263 86.4474 71.3553 74.1130 83.7003 57.1447 50.4079 67.3158 75.0000 92.0000 68.8289 68.5921 82.1711 93.5780 96.3684 86.2632 70.2632 72.3391 80.0000 71. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 34: The task-wise performance (%) of BaselineR+KL with BI under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.4596 66.2539 yelp 64.1957 66.1851 amazon 66.3919 65.6347 MNLI 67.2246 66.2883 CB 66.6241 66.4259 COPA 68.4241 66.3915 QQP 67.2146 65.4283 RTE 68.7426 65.2563 IMDB 68.7234 65.6003 SST-2 69.5023 64.2243 dbpedia 68.7413 62.3667 agnews yahoo 64.9156 59.2363 MultiRC 67.4783 61.1627 BoolQA 68.3416 61.9195 66.9565 61.5411 WiC 64.6842 62.3224 67.1667 68.1878 66.8235 70.5852 69.1013 72.6225 72.1588 75.7254 76.5673 71.7994 75.2483 76.2499 73.4170 - - - - - - - - - - - - - - - - - - - - - 64.6842 62.8684 61.7763 59.5789 58.0132 83.9079 63.7237 60.9211 79.7368 92.8571 64.6842 60.9737 74.2763 89.2857 95.0000 62.7632 58.2632 77.2500 83.9286 97.0000 83.6184 60.9474 55.7500 75.7895 85.7143 92.0000 82.7895 88.4477 61.3816 59.2368 77.1053 83.9286 95.0000 82.3421 86.2816 82.1711 61.7895 57.4211 74.2500 82.1429 95.0000 81.7105 85.9206 82.0132 95.9862 62.3421 60.6316 71.1974 58.9286 94.0000 76.3947 83.7545 82.1053 95.2982 99.0263 59.8947 55.8289 67.9605 62.5000 92.0000 77.8684 85.5596 81.9737 93.1193 98.6316 91.4868 53.9868 50.5395 55.8553 39.2857 88.0000 74.1579 84.8375 80.5921 91.7431 97.7500 88.7895 69.9868 54.7895 52.3947 74.0789 75.0000 81.0000 79.7105 85.5596 81.0658 91.3991 98.3947 88.7632 70.6842 74.9381 60.0000 58.1579 73.6316 87.5000 87.0000 75.8026 80.8664 81.8947 94.4954 98.5789 87.6842 70.6316 73.2880 83.2722 57.6184 54.9737 70.9211 83.9286 85.0000 65.8684 76.1733 80.9605 93.6927 98.6053 87.7500 69.5658 68.3375 77.6453 71.4734 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 35: The task-wise performance (%) of BaselineR+L1 under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 64.7243 65.8411 amazon 64.0712 66.1507 MNLI 66.7418 66.0131 CB 66.1626 65.5659 COPA 65.0898 66.3571 QQP 66.9136 65.9787 RTE 64.9409 65.6003 IMDB 67.4378 65.8755 SST-2 68.4099 66.0475 dbpedia 70.7552 66.1163 agnews 71.2588 66.2883 67.2247 63.4675 yahoo MultiRC 68.8897 64.2587 BoolQA 69.9449 65.0155 68.9253 65.1875 WiC 63.6447 62.1184 67.4868 66.7702 63.8700 67.8754 64.2947 69.0761 70.9477 76.0942 77.0351 71.4548 74.2401 75.6832 73.1178 - - - - - - - - - - - - - - - - - - - - - 63.6447 62.5000 61.7368 58.8158 60.5789 83.0658 59.2763 60.6579 80.1974 91.0714 60.0395 59.8816 71.0395 91.0714 98.0000 56.5000 55.9474 76.0658 71.4286 94.0000 82.6184 59.5921 57.1974 61.9342 80.3571 95.0000 77.0526 88.4477 58.8289 56.0526 68.0395 91.0714 92.0000 78.6711 87.3646 82.6579 60.5132 56.5132 71.0658 89.2857 93.0000 80.6184 85.1986 82.3289 94.9541 62.1842 58.7237 70.9079 69.6429 97.0000 80.4868 83.3935 82.5000 95.2982 99.0658 59.8684 52.7105 72.6053 83.9286 94.0000 80.1974 80.8664 82.1184 93.3486 98.0132 91.4474 55.3553 48.9605 56.1447 50.0000 90.0000 75.2763 78.3394 79.2368 80.6193 95.8026 88.3421 71.1316 56.8158 51.0000 70.5921 82.1429 93.0000 80.4079 76.1733 79.4342 84.8624 95.3684 86.7763 70.5789 76.3614 60.0658 56.2368 70.5263 73.2143 92.0000 77.5132 74.3682 80.9211 92.6606 95.8289 88.8684 70.5526 74.8556 83.5474 57.2632 52.7632 65.3553 69.6429 86.0000 69.4211 69.6751 81.7105 93.0046 97.4079 87.8553 68.9737 72.7517 78.3486 71.6301 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 36: The task-wise performance (%) of BaselineR+L1 with BI under LoRA setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 24 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.7792 66.4947 yelp 63.9428 65.9443 amazon 65.7765 64.5683 MNLI 66.2660 64.1899 CB 66.9421 65.8067 COPA 67.6247 65.7379 QQP 66.5499 64.5339 RTE 67.4151 63.9835 IMDB 67.4642 63.9147 SST-2 70.4538 64.5339 dbpedia 69.4072 62.9859 agnews yahoo 65.5182 58.2043 MultiRC 67.6884 60.8875 BoolQA 68.5123 62.0571 67.6656 61.6787 WiC 65.0789 62.0592 67.0307 68.4809 68.1173 69.6230 68.6959 71.2357 71.4311 77.5696 77.2865 74.9344 76.1997 76.4664 74.9397 - - - - - - - - - - - - - - - - - - - - - 65.0789 61.5658 62.5526 58.3553 59.2632 83.4737 61.0789 61.1316 83.0921 87.5000 62.6184 61.4868 79.7368 87.5000 96.0000 62.9605 59.1447 73.0263 78.5714 92.0000 83.0000 60.9868 57.4079 72.4211 85.7143 92.0000 82.8947 86.2816 60.0263 57.5526 73.3289 85.7143 94.0000 82.5789 85.1986 81.7763 59.9211 55.5132 74.6974 82.1429 93.0000 81.9868 84.8375 81.4211 95.5275 63.4868 60.5921 77.1316 80.3571 94.0000 80.7368 82.3105 82.1711 95.0688 98.8816 58.9868 53.8553 73.8553 83.9286 95.0000 80.6447 83.3935 82.1184 93.9220 97.8947 91.2368 56.9737 53.3158 69.7237 69.6429 83.0000 80.0526 83.0325 81.5263 93.4633 96.8026 88.3816 70.2105 59.1711 55.5921 73.3947 83.9286 87.0000 80.5789 84.4765 81.7895 93.6927 97.5000 88.6711 70.8684 75.4538 60.3947 56.9211 74.1842 89.2857 90.0000 79.3553 82.3105 81.8553 93.6927 97.7368 87.6053 70.0395 73.9068 82.9969 57.3289 54.4605 74.2500 83.9286 87.0000 76.5263 77.2563 81.6579 93.3486 98.3158 86.0526 69.7368 71.6378 77.8287 70. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 37: The task-wise performance (%) of BaselineR+L2 under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.5011 65.2563 yelp 63.3512 65.8067 amazon 64.9711 65.4627 MNLI 65.8420 65.2907 CB 65.4726 65.3939 COPA 66.8773 66.0819 QQP 66.1048 65.5659 RTE 66.9156 65.4971 IMDB 67.7855 65.7035 SST-2 70.9434 65.6691 dbpedia 70.1363 64.4307 agnews yahoo 68.1250 63.3643 MultiRC 67.9842 63.4675 BoolQA 69.8028 64.2587 68.9476 64.4651 WiC 63.7632 61.0724 64.4868 66.4027 65.5515 67.6921 66.6526 68.3970 70.0038 77.1389 76.9507 73.6591 73.1931 76.3938 74.1000 - - - - - - - - - - - - - - - - - - - - - 63.7632 60.2237 61.9211 54.7895 56.6711 82.0000 57.3816 59.6447 81.9868 92.8571 58.7237 60.4605 76.8816 91.0714 96.0000 53.9474 55.3816 77.3684 78.5714 93.0000 83.6579 58.2368 55.0395 70.1711 89.2857 98.0000 81.8816 85.9206 53.5658 47.6447 73.4079 91.0714 94.0000 83.7368 85.1986 82.5132 56.9868 53.4211 71.1447 87.5000 95.0000 82.4474 80.1444 82.2632 95.5275 61.4605 58.1184 77.0263 80.3571 97.0000 82.1053 83.0325 82.6447 95.0688 98.9211 57.8158 52.6447 73.0132 80.3571 91.0000 81.6579 84.8375 82.3684 93.4633 97.1711 91.5921 54.1184 52.6974 63.7763 71.4286 90.0000 78.4605 77.2563 81.6974 91.7431 97.3816 89.5000 69.2368 50.9868 48.1184 72.8158 75.0000 93.0000 79.9211 75.4513 80.8289 91.2844 91.7500 88.5658 68.9079 75.1031 59.7632 57.9868 70.4474 75.0000 92.0000 78.3026 76.5343 82.2237 94.1514 97.8553 89.9605 71.2763 73.7417 82.8746 57.0921 55.8553 66.1974 64.2857 90.0000 69.8816 67.5090 82.0263 93.0046 97.3026 90.0789 70.3553 72.9167 79.9694 76. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 38: The task-wise performance (%) of BaselineR+L2 with BI under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 65.9802 66.0131 yelp 64.2013 66.2195 amazon 66.7877 66.3915 MNLI 67.1974 66.6323 CB 66.5393 66.4947 COPA 68.0480 65.9787 QQP 66.7942 65.7379 RTE 68.4342 65.9787 IMDB 67.9225 66.0475 SST-2 69.6229 65.1531 dbpedia 70.5449 64.9811 agnews yahoo 68.2991 64.3619 MultiRC 70.4566 65.1531 BoolQA 69.9710 65.4627 69.8567 65.3251 WiC 65.9474 62.3026 67.1886 67.7721 66.5839 70.2513 67.8851 71.0795 69.9071 74.7511 77.1507 72.7494 76.7001 75.1463 75.0639 - - - - - - - - - - - - - - - - - - - - - 65.9474 62.9868 61.6184 59.8553 58.2105 83.5000 61.9079 60.1447 81.1184 87.5000 63.3553 59.4079 76.4605 89.2857 94.0000 61.8684 57.3158 77.2237 80.3571 93.0000 84.2237 59.5921 54.1447 73.0789 89.2857 92.0000 83.4737 89.1697 59.2763 56.1711 74.0921 83.9286 95.0000 82.5526 87.3646 82.3026 59.2632 53.1711 70.8026 82.1429 96.0000 80.2500 81.9495 82.1711 96.1009 61.8421 57.1184 70.9342 82.1429 96.0000 74.2368 82.6715 82.5789 95.5275 98.7895 60.7500 54.9737 70.6316 73.2143 97.0000 79.6711 83.3935 82.6184 94.9541 98.2500 90.6579 57.3684 49.8026 60.7632 58.9286 86.0000 72.1711 78.7004 81.8553 91.6284 97.1842 89.3026 71.0921 61.8553 56.3816 75.4342 80.3571 88.0000 79.4474 78.3394 81.7895 91.9725 97.8816 87.8816 71.1447 76.3820 61.4605 57.3289 70.0526 78.5714 89.0000 70.1447 80.1444 81.8421 94.7248 97.4211 88.4737 68.6974 74.3193 83.6086 59.3026 54.5526 71.9737 83.9286 89.0000 74.2368 75.8123 82.0921 93.4633 97.6053 88.3026 67.8421 74.2987 81.9572 71.9436 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 39: The task-wise performance (%) of BaselineR+TM under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 64.7595 66.0131 amazon 63.1847 65.7379 MNLI 66.0735 66.1163 CB 66.4132 66.2539 COPA 65.8838 66.2195 QQP 67.7531 66.4947 RTE 65.7343 66.4259 IMDB 62.0098 66.1851 SST-2 68.8088 66.5979 dbpedia 71.3194 66.3227 agnews 71.7573 66.5291 68.5125 64.5683 yahoo MultiRC 69.0975 64.8779 BoolQA 69.8066 65.1187 68.4606 64.6371 WiC 63.5526 60.8224 66.0307 66.5733 65.5515 69.0601 65.0569 58.3301 71.1716 77.1304 77.8773 72.9700 73.9041 75.2218 72.7650 - - - - - - - - - - - - - - - - - - - - - 63.5526 60.8947 60.7500 57.2237 57.9868 82.8816 59.7105 59.9474 79.8421 96.4286 61.7368 61.2763 73.0526 92.8571 95.0000 61.8421 58.5789 71.6974 87.5000 97.0000 83.6184 59.5132 56.1711 61.5526 80.3571 95.0000 81.6053 89.1697 31.9079 28.3158 65.1711 85.7143 93.0000 82.5921 87.3646 81.9474 61.4211 56.4342 69.6842 85.7143 93.0000 82.1711 83.7545 82.5132 95.4128 61.8026 59.6842 76.1184 85.7143 93.0000 81.0000 80.5054 82.6711 95.7569 98.9737 59.7763 57.2895 73.9737 87.5000 96.0000 80.5921 78.3394 82.3684 95.1835 98.4342 90.3947 56.5789 53.5658 55.8816 41.0714 92.0000 78.0395 71.1191 81.8553 93.4633 96.8421 88.5263 70.1711 54.7763 52.9868 67.8158 71.4286 92.0000 77.5789 74.3682 81.4474 90.4817 96.3026 87.9211 69.0526 75.8045 58.9211 56.2500 68.4342 73.2143 91.0000 75.5921 69.3141 81.6447 93.9220 97.6447 88.5789 69.4605 74.2781 83.8838 56.0263 51.4868 64.6974 73.2143 90.0000 70.3158 66.0650 80.7895 91.3991 97.5263 87.7632 68.8158 72.8754 78.8991 71.1599 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 40: The task-wise performance (%) of BaselineR+TM with BI under LoRA setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 25 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.6995 66.1163 yelp 62.9135 66.7011 amazon 61.3383 66.3915 MNLI 60.6811 66.3227 CB 59.1370 66.4947 COPA 61.1059 66.0819 QQP 62.2074 66.6323 RTE 64.8620 66.4603 IMDB 65.5385 66.7355 SST-2 67.1732 66.3915 dbpedia 67.6305 66.3915 agnews yahoo 64.8817 65.8411 MultiRC 63.2124 66.1163 BoolQA 65.5736 66.2195 64.9147 65.9443 WiC 63.3421 59.5329 57.0000 55.9240 53.2453 56.8268 58.3336 63.3388 64.3837 67.9736 68.9166 63.9498 60.5529 64.9403 63.9167 - - - - - - - - - - - - - - - - - - - - - 63.3421 59.7895 59.2763 49.3947 49.5000 72.1053 50.6184 49.8289 67.2237 69.6429 51.1842 48.9868 59.1184 57.1429 85.0000 49.3816 48.7763 50.5263 35.7143 75.0000 78.5395 49.3289 47.7237 58.0921 48.2143 80.0000 77.2895 77.2563 49.6184 50.8947 57.5132 48.2143 57.0000 76.3421 73.2852 82.1579 54.5263 51.6842 54.9868 58.9286 86.0000 75.1316 65.7040 81.8553 94.3807 59.6842 52.1579 44.7895 39.2857 84.0000 68.1579 61.0108 81.7237 93.4633 98.6579 51.5526 47.2500 42.0789 28.5714 78.0000 69.5789 63.8989 81.6053 93.0046 97.7500 90.1974 47.6711 43.5789 43.1316 46.4286 33.0000 64.2632 68.5921 79.7763 85.5505 89.0395 70.9605 71.0658 29.1579 26.2632 58.1711 50.0000 1.0000 70.6579 64.9819 79.9737 87.7294 85.1974 59.5263 66.1711 71.3490 54.2763 49.8158 49.2105 37.5000 82.0000 65.4211 63.8989 80.1316 92.2018 91.6579 66.7368 59.7632 60.1279 70.6728 53.1711 50.0658 41.4342 37.5000 84.0000 73.8553 67.8700 79.8553 91.3991 91.2237 69.0921 49.6579 60.6848 68.2263 61. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 41: The task-wise performance (%) of BaselineR+TM (w=100) under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB COPA QQP RTE IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.8046 66.5979 yelp 63.3197 66.4947 amazon 63.4808 66.6323 MNLI 60.6909 66.4947 CB 54.3829 66.2195 COPA 66.0703 66.8387 QQP 63.2571 66.9763 RTE 66.3707 66.2883 IMDB 67.3507 66.4259 SST-2 68.0776 66.1163 dbpedia 67.9356 66.3915 agnews yahoo 66.1892 65.9443 MultiRC 66.9679 66.0131 BoolQA 67.4027 66.0131 67.1323 65.5659 WiC 63.1053 60.4342 60.6140 55.8190 46.1361 65.3194 59.9293 66.4533 68.3017 70.1588 69.5533 66.4359 67.9507 68.8521 68.7755 - - - - - - - - - - - - - - - - - - - - - 63.1053 61.8553 59.0132 51.7632 49.7105 80.3684 49.1447 46.2895 71.8421 80.3571 47.3553 42.0132 48.2632 64.2857 95.0000 56.5658 51.9079 69.6184 76.7857 91.0000 82.7632 50.2763 47.3026 60.3026 80.3571 89.0000 80.4474 83.3935 54.1053 52.0395 65.3026 76.7857 86.0000 78.1579 79.0614 81.8684 58.3026 55.3947 65.7895 71.4286 91.0000 76.5263 72.9242 81.9079 95.2982 57.4737 51.6711 57.6447 50.0000 91.0000 70.7368 63.8989 82.0263 93.5780 98.8158 47.7895 42.9605 49.9474 42.8571 86.0000 74.0000 68.2310 81.2237 93.3486 97.7763 90.4737 47.7237 43.6184 46.4079 46.4286 61.0000 66.6053 68.5921 80.3026 90.5963 89.8158 83.8289 70.5526 47.4474 43.1316 64.1974 69.6429 59.0000 73.7632 72.2022 79.8684 87.0413 82.0789 77.5000 69.1974 74.5050 53.1316 49.2105 61.8421 60.7143 38.0000 72.0132 69.6751 81.3684 93.1193 94.1579 67.7105 64.2763 68.3375 80.6728 53.7500 49.8947 55.1711 58.9286 59.0000 70.7632 66.7870 81.2895 91.9725 95.0921 80.7237 60.5263 66.6048 73.2110 69. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 42: The task-wise performance (%) of BaselineR+TM (w=100) with BI under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.8175 66.2195 yelp 63.4872 66.8731 amazon 63.1611 66.3571 MNLI 61.1721 66.4603 CB 60.4614 66.5635 COPA 61.7453 66.4259 QQP 61.6476 66.6667 RTE 64.9994 66.2539 IMDB 66.2760 66.6667 SST-2 67.3716 66.4603 dbpedia 68.2192 66.6323 agnews yahoo 65.5524 66.1163 MultiRC 65.5709 66.1851 BoolQA 65.8838 66.3571 65.3352 66.2539 WiC 63.4737 60.4276 60.2588 56.6635 55.3842 57.6810 57.3314 63.7915 65.8898 68.3083 69.8835 64.9980 64.9680 65.4173 64.4417 - - - - - - - - - - - - - - - - - - - - - 63.4737 60.8158 60.0395 52.3158 51.3947 77.0658 50.3553 49.4605 70.0526 73.2143 52.5132 49.6053 63.6711 57.1429 82.0000 49.7105 49.2368 51.8421 37.5000 78.0000 79.8158 48.0789 47.2368 56.0395 39.2857 83.0000 76.9737 79.0614 45.4211 49.7763 65.3026 46.4286 30.0000 76.5132 71.8412 82.2237 54.5789 53.0921 60.8158 51.7857 88.0000 75.5789 70.7581 81.7763 94.1514 59.1974 51.4342 45.0789 33.9286 88.0000 71.2895 64.6209 81.2632 93.5780 98.8158 52.4605 49.1316 44.1053 37.5000 89.0000 70.9737 66.0650 81.6316 92.4312 98.0921 90.3289 49.4079 43.6974 46.9737 57.1429 79.0000 63.9474 64.6209 79.5789 89.3349 88.0132 74.3816 71.0789 34.4474 43.2368 60.0526 53.5714 70.0000 72.4737 67.8700 80.5658 89.6789 90.8816 64.9605 66.5395 70.7096 53.1316 49.0526 49.8553 48.2143 85.0000 66.0526 66.0650 80.8947 92.6606 92.4079 68.4211 59.2763 62.4587 72.0489 51.6711 49.8158 43.2895 35.7143 83.0000 74.0132 68.5921 80.5000 91.8578 91.3816 70.9605 49.1974 62.6238 69.6942 67.7116 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 43: The task-wise performance (%) of BaselineR+TM (w=dynamic) under LoRA setting Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC yelp 65.2051 66.8731 amazon 63.6777 66.9419 MNLI 63.6676 66.5635 CB 60.9491 66.1507 COPA 59.1730 66.0819 QQP 66.5630 66.7011 RTE 64.3032 66.8387 IMDB 65.4650 66.0131 SST-2 66.7806 65.6691 dbpedia 68.2080 66.3571 agnews 68.3889 66.0131 66.3217 65.7723 yahoo MultiRC 67.7357 65.4971 BoolQA 68.0276 65.8411 66.5906 65.4627 WiC 63.6184 60.7171 61.0132 56.5060 53.5721 66.4256 61.9531 64.9260 67.9303 70.1652 70.9421 66.8803 70.1328 70.3644 67.7580 - - - - - - - - - - - - - - - - - - - - - 63.6184 61.3026 60.1316 52.0395 50.0526 80.9474 50.0395 47.2237 72.0526 83.9286 52.8421 49.6316 57.6447 67.8571 91.0000 58.6711 54.7500 68.6579 82.1429 94.0000 83.1447 51.6053 50.1053 64.5658 82.1429 94.0000 80.0789 86.2816 53.7368 45.4474 64.6184 80.3571 93.0000 77.8026 81.2274 81.9474 57.4868 54.3026 65.9211 85.7143 95.0000 75.7237 77.2563 82.2500 95.2982 57.0000 51.9474 57.8553 58.9286 83.0000 71.4474 58.4838 81.8158 92.8899 98.6579 50.2105 47.2500 56.0263 66.0714 81.0000 71.8026 64.2599 81.0000 90.5963 98.0921 90.1053 51.7895 45.6974 43.2237 35.7143 84.0000 64.4474 63.1769 79.4079 86.2385 91.4342 85.6579 71.3026 50.1316 45.8816 64.2763 82.1429 86.0000 76.9079 74.7292 78.8816 89.1055 88.3947 81.5658 69.0921 75.2888 55.1447 52.8553 59.5921 67.8571 58.0000 74.7895 68.9531 81.6316 93.2339 94.1974 71.6579 66.6184 68.6881 82.2324 52.6579 50.3947 54.6184 66.0714 57.0000 65.4605 63.1769 81.2763 91.9725 94.1184 77.0789 61.5526 64.7690 76.9419 72.5705 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 44: The task-wise performance (%) of BaselineR+TM (w=dynamic) with BI under LoRA setting JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 26 Curr.Task F1 Avg MMLU Tasks Avg yelp amazon MNLI CB"
        },
        {
            "title": "RTE",
            "content": "IMDB SST-2 dbpedia agnews yahoo MultiRC BoolQA WiC 64.3813 64.7403 yelp 61.3441 62.4011 amazon 63.4462 61.0939 MNLI 63.4463 61.0939 CB 64.0736 62.2291 COPA 65.5306 61.7819 QQP 63.8376 61.5411 RTE 65.3259 61.5411 IMDB 64.9790 60.2339 SST-2 66.0818 59.1331 dbpedia 65.9922 58.0323 agnews yahoo 64.1233 55.9684 MultiRC 63.6088 55.3492 BoolQA 64.3424 56.0716 63.5707 55.8996 WiC 64.0263 60.3224 65.9868 65.9870 66.0307 69.7637 66.3121 69.6068 70.5356 74.8811 76.4829 75.0600 74.7659 75.4753 73.6823 - - - - - - - - - - - - - - - - - - - - - 64.0263 59.9079 60.7368 58.4737 58.6579 80.8289 59.3158 59.6842 78.8421 82.1429 59.9211 59.9605 77.7500 80.3571 93.0000 59.6316 59.0395 78.2368 73.2143 91.0000 81.8421 59.3158 59.2368 64.8421 76.7857 91.0000 80.7237 86.2816 60.7368 58.5395 64.4868 76.7857 90.0000 81.4211 87.0036 81.8947 61.2895 58.1447 65.6711 78.5714 92.0000 82.0263 83.3935 81.9605 94.7248 60.0000 58.2500 66.0921 80.3571 93.0000 80.8684 84.1155 82.2763 94.3807 98.9474 60.3421 57.1842 64.7105 80.3571 92.0000 79.6579 84.1155 82.0132 93.9220 98.6316 90.3289 54.8947 54.4211 69.5395 76.7857 90.0000 79.5000 79.7834 81.9868 92.8899 97.6711 88.7895 71.2500 55.1579 54.9342 68.5658 75.0000 88.0000 80.6711 77.9783 81.5921 92.8899 97.8947 88.0921 70.2500 72.5660 56.5395 57.3816 72.8947 82.1429 92.0000 77.6053 74.3682 81.9868 93.5780 97.0658 88.5921 70.1711 71.5553 79.5719 56.0921 56.3289 72.2763 66.0714 91.0000 67.2895 71.1191 81.8026 93.0046 97.3289 87.5132 70.5395 69.0388 76.7584 69.2790 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - TABLE 45: The task-wise performance (%) of O-LoRA"
        }
    ],
    "affiliations": [
        "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
        "Ysstech Info-Tech Co.,Ltd, Shenzhen"
    ]
}