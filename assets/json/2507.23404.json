{
    "paper_title": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring",
    "authors": [
        "Salah Eddine Bekhouche",
        "Azeddine Benlamoudi",
        "Yazid Bounab",
        "Fadi Dornaika",
        "Abdenour Hadid"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is a novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at \\href{https://github.com/Bekhouche/APR}{GitHub}."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 3 ] . [ 1 4 0 4 3 2 . 7 0 5 2 : r 2025 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING, AUG. 31 SEP. 3, 2025, ISTANBUL, TURKEY"
        },
        {
            "title": "ENHANCED ARABIC TEXT RETRIEVAL WITH ATTENTIVE RELEVANCE SCORING",
            "content": "Salah Eddine Bekhouche1 Azeddine Benlamoudi2 Yazid Bounab3 Fadi Dornaika1,4 Abdenour Hadid3,5 1 University of the Basque Country UPV/EHU, San Sebastian, Spain 2 Lab. de Genie Electrique (LAGE), University of Ouargla, Ouargla, Algeria 3 Faculty of Pharmacy, Helsinki University, Helsinki, Finland 4 IKERBASQUE, Basque Foundation for Science, Bilbao, Spain 5 Sorbonne University Abu Dhabi, Abu Dhabi, UAE ABSTRACT Arabic poses particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at GitHub. Index Terms Arabic NLP, Dense Passage Retrieval, Attentive Relevance Scoring 1. INTRODUCTION Arabic, one of the most widely spoken languages globally, presents unique linguistic challenges for natural language processing (NLP) and information retrieval (IR). Applying Dense Passage Retrieval (DPR) [1] to Arabic opens new avenues but also introduces unique challenges. Its rich morphology, frequent use of diacritics, syntactic complexity, and the coexistence of Modern Standard Arabic (MSA) with diverse dialects pose significant difficulties for conventional retrieval systems, which often struggle with normalization and semantic understanding. Despite its global importance, Arabic remains underrepresented in NLP research, resulting The supports of TotalEnergies and Sorbonne University Abu Dhabi are fully acknowledged. in fewer dedicated resources and tools compared to other major languages. While the advent of pre-trained transformer models like AraBERT, MARBERT, and multilingual BERT has significantly advanced Arabic NLP, creating highly effective DPR systems for Arabic requires more than just fine-tuning these general models on downstream tasks. Recognizing these limitations and the lack of dedicated Arabic DPR models, recent research, exemplified by the development of AraDPR [2], has focused on training specialized retrievers. AraDPR utilizes AraBERT as its backbone and employs contrastive learning approach, trained specifically on combination of translated benchmark datasets and native Arabic question-answering datasets. This method has produced the first publicly available, contrastively trained Arabic DPR model, demonstrating state-of-the-art performance on Arabic passage retrieval benchmarks and significantly outperforming both traditional methods and fine-tuned multilingual or cross-lingual models in Arabic open-domain QA contexts [2]. This was crucial step towards building more robust and linguistically nuanced dense retrieval systems tailored specifically for the Arabic language. However, even state-of-the-art dense retrieval models often rely on simple vector similarity measures (e.g., dot product or cosine similarity) for the final relevance scoring between query and passage representations. These standard scoring functions may not fully capture the intricate semantic relationships and account for the morphological variations inherent in Arabic text. To address this limitation and enhance semantic matching capabilities, we present novel system incorporating Attentive Relevance Scoring (ARS). ARS replaces the typical final scoring step based on simple vector similarity with more adaptive and semantically aware scoring function designed to better model relevance in the context of Arabics linguistic features. The potential applications for effective Arabic DPR are vast, including enhanced question-answering systems, digital libraries, Arabic-language search engines, and conversational agents for Arabic-speaking users. With the continuous increase of annotated Arabic datasets and targeted research efforts, the effectiveness and usability of Arabic DPR systems are expected to improve significantly. The main contributions of this work are: We propose an enhanced dense retrieval framework for Arabic, integrating lightweight transformer models with an adaptive scoring mechanism. We introduce an ARS module to improve semantic matching beyond conventional vector similarity functions used in standard DPR. We present extensive experimental analysis, pointing out some limitations and future directions. This rest of this paper is structured as follows: Section 2 overviews the foundational work on DPR in general and Arabic DPR in particular. In Section 3, we describe our methodology, highlighting the architectural advantages of the ARS. Section 4 presents the experimental validation of our approach, providing detailed results and comparison against some existing works. It also offers an in-depth analysis of the findings, discussing their implications, limitations, and potential future research directions. Finally, Section 5 summarizes our key findings and contributions to the field. 2. RELATED WORK The field of IR has been significantly transformed by advancements in deep learning, particularly the emergence of pre-trained transformer models [3, 4]. key development stemming from this is DPR, which has become cornerstone for modern open-domain Question Answering (QA) and search systems. The core idea of DPR, popularized by [1], involves encoding both user queries and text passages into low-dimensional, dense vector representations using dual-encoder architectures, typically based on BERT or its variants. Relevance scoring is then performed by calculating the similarity (e.g., dot product or cosine similarity) between the query vector and passage vectors. Retrieval is efficiently handled using Approximate Nearest Neighbor (ANN) search algorithms over the pre-computed passage embeddings [5]. This paradigm demonstrated substantial improvements over traditional sparse retrieval methods like BM25 [6] on various benchmarks. Subsequent research focused on refining DPR, particularly through improved training strategies like sophisticated negative sampling techniques (e.g., ANCE [7], RocketQA [8]) that dynamically mine hard negatives to create more robust models. While effective, standard DPR models based on large transformers can be computationally intensive. This has spurred research into more efficient architectures. ColBERT [9] introduced late-interaction mechanism, calculating relevance based on fine-grained token-level interactions between query and passage embeddings. This allows for richer semantic matching while maintaining efficiency through pre-computation and optimized vector similarity search [10]. Other approaches like SPLADE [11] explore learned sparse representations, bridging the gap between traditional lexical matching and dense semantic retrieval, often offering competitive performance with better efficiency. Furthermore, model compression techniques like knowledge distillation (e.g., DistilBERT [12], TinyBERT [13]) are increasingly explored to create lightweight yet powerful retrieval models suitable for resource-constrained environments. Applying these advanced retrieval techniques to Arabic poses unique challenges due to its complex morphology (rich inflection and derivation), orthographic variations (e.g., optional diacritics, inconsistent spelling of certain letters), and dialectal diversity [14]. Significant progress in Arabic NLP has been driven by the development of dedicated Arabic pre-trained language models, including AraBERT [15], MARBERT [16], ARBERT [16], AraELECTRA [17], and CamelBERT [18], which are trained on large Arabic corpora and better capture the languages nuances compared to multilingual models. However, developing effective dense retrieval systems specifically for Arabic has lagged behind English. Traditional Arabic IR systems often rely heavily on morphological analysis and query expansion techniques to handle lexical gaps [19]. The direct application of standard DPR techniques, even when fine-tuning multilingual models, often yields suboptimal results due to the languages specific characteristics [2]. Recognizing this gap, recent work has focused on creating dedicated Arabic dense retrieval models. landmark contribution is AraDPR [2], the first publicly available, contrastively trained DPR model specifically for Arabic. Utilizing AraBERT as its backbone and trained on mix of translated benchmarks and native Arabic QA datasets (like ARCD [20]), AraDPR established new state-of-theart for Arabic passage retrieval, significantly outperforming both traditional methods and general-purpose fine-tuned models. This highlights the importance of language-specific training and architectures for achieving high performance in Arabic retrieval contexts, also emphasized by cross-lingual benchmark efforts like TyDi QA [21]. Despite the success of models like AraDPR, standard dense retrieval predominantly relies on single vector representation for queries and passages, with relevance determined by simple geometric similarity (dot product/cosine). While computationally efficient, this approach might oversimplify the complex relevance judgments required, especially for morphologically rich and semantically nuanced languages like Arabic. While late-interaction models like ColBERT [9] address this by allowing token-level interactions, other neural ranking frameworks have long explored learned interaction layers on top of global embeddings to improve upon simple similarity measures [22, 23]. Our work builds on this latter paradigm, proposing lightweight, adaptive scoring module specifically tailored for the challenges of Arabic retrieval. and apply ℓ2 normalization to obtain fixed-size embeddings: = Norm(EQ(q)[CLS]) Rd, = Norm(EP (p)[CLS]) Rd, (1) where Norm() denotes ℓ2 normalization. This normalization projects vectors onto unit hypersphere, which is beneficial for stabilizing contrastive similarity computations. 3.2. Attentive Relevance Scoring The ARS module computes an adaptive semantic similarity between query and passage embeddings through trainable interaction model. First, the embeddings are projected into shared space using: hq = Wqq, hp = Wpp, (2) where Wq, Wp Rhd are learnable projection matrices and is the shared hidden dimensionality. Next, we model interactions using element-wise multiplication () followed by non-linear activation to compute the interaction vector a: = tanh(hq hp). (3) Here, tanh() is the hyperbolic tangent function, which applies non-linearity to the element-wise product of the projected embeddings. Finally, scalar relevance score is computed via an attention vector wa Rh: = σ (cid:0)w a(cid:1) , (4) where σ() is the sigmoid function. During inference, the passage embeddings (as defined in Equation 1) are pre-computed for all NP documents in the knowledge source to enable efficient query processing. When new query arrives, its embedding is generated in real time. The ARS module then computes relevance score r(j) by interacting the query embedding with each of the pre-computed passage embeddings p(j)j = 1, ..., NP . Finally, all NP passages are ranked based on the resulting ARS scores r(j) to produce the retrieval output. 3.3. Loss Function To optimize both overall and fine-grained semantic alignment, we define total loss function: Ltotal = α Lcons + β Ldyn + γ Lreg, (5) where α = 1, β = 1, and γ = 0.1 are empirically determined weights. During training, each batch contains queries, with each query paired with one positive and pool of 29 negative passages, ensuring diverse negative exposure while maintaining efficiency. Fig. 1. Overview of the proposed APR framework. 3. PROPOSED APPROACH This section introduces our proposed method, called Adaptive Passage Retrieval (APR), tailored for Arabic text retrieval. Our approach builds upon the DPR framework [24] and incorporates lightweight, Arabic-specific encoder (MiniBERT) [25] alongside novel scoring mechanism termed Attentive Relevance Scoring (ARS). This combination is designed to enhance retrieval accuracy by modeling enhanced semantic interactions in Arabic texts, while maintaining computational efficiency suitable for low-resource settings. The overall architecture of our pro APR is illustrated in Figure 1. 3.1. Dual-Encoder Architecture APR employs dual-encoder architecture consisting of question encoder (EQ) and passage encoder (EP ), both initialized with weights from MiniBERT, transformer model pre-trained on Arabic corpora. This initialization allows the system to better capture Arabic linguistic features. Given question and passage p, each encoder processes its respective input independently, generating two types of representations: sequence-level and pooled [CLS] token representations. The sequence-level representations, denoted Hq RBLd and Hp RBLd, capture contextual embeddings for each token in the question and passage, respectively. Here, is the batch size, is the input lengths, and is the hidden dimension of the MiniBERT model. For global semantic representation, we extract the finallayer hidden state corresponding to the special [CLS] token, 3.3.1. Contrastive Loss (Lcons) We use contrastive loss based on InfoNCE. It works on the [CLS] token embeddings. This loss helps the model align the query embedding (q) with the correct passage embedding (p+) and separate it from the incorrect ones (p): While Ldyn encourages variance in the final ARS scores (r+ and r), Lreg does the same for the raw logits (s+ and s). This helps maintain useful range of values before activation, supports gradient flow, and prevents the model from becoming too confident or producing uniform predictions, especially early in training or with hard negatives. The regularization loss is: Lcons = (cid:32) (cid:88) log"
        },
        {
            "title": "1\nB",
            "content": "i p+ exp(q /τ ) /τ ) + (cid:80)N j=1 exp(q p+ exp(q i=1 i,j/τ ) (6) Here, is the batch size. qi is the embedding for the i-th query. p+ is the embedding for the correct (positive) pasi sage. {p i,j}N j=1 are the embeddings for negative passages (N=29). The temperature parameter τ > 0 is learnable parameter used to scale the dot products. 3.3.2. Dynamic Relevance Loss (Ldyn) Standard contrastive learning separates positive and negative pairs, but it might not fully capture small differences in the scores. This is especially important in Arabic, where similar words can have slightly different meanings. To handle this, we add dynamic relevance loss that supervises the models relevance scores (ARS scores, r). This loss aims to increase the score r+ for the correct passage and decrease the score for the incorrect one. At the same time, it encourages wider range of scores across the batch. This prevents the scores from becoming too similar, which can happen with difficult negative passages. The formulation for Ldyn, averaged over the batch of size B, is: Ldyn = 1 (cid:88) i=1 (cid:2)log(r+ + ϵ) + log(1 i + ϵ)(cid:3) (7) Here, r+ and are the ARS scores (typically passed through sigmoid, and thus constrained between 0 and 1) for the positive and negative passages, respectively. ϵ is small constant (e.g., 108) added for numerical stability. The negative passage is randomly selected from the pool of negative and minimize passages. This loss aims to maximize r+ , ideally pushing r+ 0 for each sample in the batch. This encourages the model to produce confident and well-separated scores, improving the quality of passage retrieval. 1 and 3.3.3. Relevance Score Logit Regularization (Lreg) As an additional step, we apply regularization loss on the raw relevance scores before applying the sigmoid function (called logits, s). This helps keep the training stable and prevents all outputs from becoming too similar. (cid:33) , Lreg = Std(s+ batch) + Std(s batch), (8) Here, s+ batch and batch are the sets of raw, pre-sigmoid relevance scores (logits) for positive and negative examples in the batch. Std() means standard deviation. 4. EXPERIMENTS 4.1. Dataset For our experiments, we used the ArabicaQA dataset, comprehensive, human-annotated Arabic question answering corpus specifically designed for open-domain retrieval and machine reading comprehension tasks. The dataset1 is divided into standard training, validation and test subsets. The training set consists of 58,727 question-answer pairs, each accompanied by relevant positive passage with the answer and 29 hard negative passages. These hard negative passages are semantically similar to the question, but do not contain the correct answer, which makes them valuable for training robust retrieval models. The validation set contains 12,722 questionanswer pairs and the test set contains 12,597 question-answer. The textual knowledge source for ArabicaQA is derived from the Arabic Wikipedia2, which contains approximately 1,222,923 articles. These articles serve as the source passages from which answers are retrieved or extracted. During performance evaluation on both the validation and test sets, each question is evaluated against the full Wikipedia split, ensuring realistic and comprehensive assessment of retrieval and reading comprehension capabilities. 4.2. Experimental Setup All experiments were conducted on machine with six NVIDIA L4 GPUs, each providing 24 GB of VRAM. multi-GPU distributed training strategy was employed to accelerate the training process. Mixed precision training was not utilized, and the gradient accumulation step was set to 1 to maintain stable gradient updates. The model architecture comprises question encoder and context (passage) encoder, each containing approximately 11.55 million parameters. An auxiliary ARS module introduces an additional 0.13 million parameters, resulting in total of approximately 23.23 million trainable parameters for the complete APR model. 1Open-ArabicaQA Human-Annotated Retriever Dataset 2Open-ArabicaQA Wikipedia Split Dataset Table 1. Retriever Module Performance Comparison (Top-k accuracy on test set) Method Top-1 Top-10 Top-20 Top-50 Top-100 TF-IDF [27] BM25 [6] DPR [1] AraDPR [2] APR (Ours) 14.35 28.70 36.40 36.10 37.01 40.86 43.40 57.80 58.40 63.17 46.87 48.20 62.10 63.40 66.36 51.71 54.60 66.60 68.60 70.77 55.36 59.30 69.50 71.90 73.43 Training was performed on the training split of the ArabicaQA dataset, while model validation was conducted on the validation split, consisting of 12,722 examples. Both training and validation phases used per-GPU batch size of 32. Optimization was carried out using the AdamW optimizer [26] with fixed learning rate of 1 104 and an ϵ value of 1 108. linear learning rate scheduler was adopted, linearly increasing the learning rate from an initial factor of 0.1 to the target value over the course of training. To ensure numerical stability during training, gradient clipping was applied with maximum norm of 1.0. 4.3. Results and Discussion Figure 2 illustrates the top-k retrieval accuracy on the validation set, while Table 1 reports the performance on the test set, comparing our results with state-of-the-art methods on the ArabicaQA dataset. Fig. 2. Top-k retrieval accuracy comparison on the validation set of the ArabicaQA dataset. Our APR model demonstrates consistent improvements across all values of compared to existing methods. As shown in Table 1, our proposed APR model outperforms all baseline systems across all top-k retrieval thresholds (k = 1, 10, 20, 50, 100). Compared to AraDPRthe strongest Arabic baselineAPR achieves absolute gains of +0.91% in Top-1, +4.77% in Top-10, and +1.53% in Top-100 accuracy. These consistent improvements demonstrate that APR effectively leverages the ARS module to better distinguish truly relevant passages from semantically similar but incorrect ones. Furthermore, Figure 2 visually emphasizes the strong performance of APR at increasing values of k. While the performance gap between APR and the other retrievers is modest at lower values, it gradually increases as increases, indicating superior ranking capabilities and better understanding of the relevance of answers within the large document collection. More specifically, the figure shows that APR achieves an accuracy of about 38% at = 5, which is slightly ahead of dense baseline methods such as AraDPR (36.10%) and DPR (36.40%), and significantly higher than sparse methods such as BM25 (28.70%) and TF-IDF (14.35%). As increases, all dense models including APR, AraDPR and DPR begin to plateau at = 50, suggesting that most relevant passages are found early in the ranking process. Despite this saturation, APR maintains consistent lead over AraDPR and DPR at each value, highlighting the benefits of response-based ranking. Ultimately, APR achieves the highest top-k accuracy of 75.01% at = 100, demonstrating its robustness even for broader retrieval scopes. These results highlight the strength of incorporating Answer Relevance Scoring into dense retrieval. The higher Topk accuracy, particularly at low cutoffs such as Top-1 and Top10, ensures that downstream reader modules receive higherquality candidates, thereby improving the overall question answering pipeline. 5. CONCLUSION We presented an improved dense retrieval framework tailored for Arabic question answering. By integrating lightweight encoder and ARS, our approach addresses key challenges in Arabic IR, including morphological complexity and limited semantic generalization in traditional models. This work opens new directions for efficient and accurate retrieval in underrepresented languages and lays the foundation for future enhancements in Arabic-language AI systems. While our results are promising, we recognize that we need more detailed analysis. Future work will focus on doing thorough ablation studies to separate the contributions of our proposed components and conducting qualitative analysis to provide deeper insights into the models practical strengths. 6. REFERENCES [1] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih, Dense passage retrieval for open-domain question answerin Proceedings of the 2020 Conference on Empirical ing, Methods in Natural Language Processing (EMNLP). 2020, pp. 67696781, Association for Computational Linguistics. [2] Abdelrahman Abdallah, Mahmoud Kasem, Mahmoud Abdalla, Mohamed Mahmoud, Mohamed Elkasaby, Yasser Elbendary, and Adam Jatowt, Arabicaqa: comprehensive dataset for arabic question answering, in Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2024, pp. 20492059. [3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019, pp. 41714186, Association for Computational Linguistics. [4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin, Attention is all you need, Advances in neural information processing systems, vol. 30, 2017. [5] Jeff Johnson, Matthijs Douze, and Herve Jegou, Billion-scale similarity search with gpus, IEEE Transactions on Big Data, vol. 7, no. 3, pp. 535547, 2019. [6] Stephen Robertson, Hugo Zaragoza, et al., The probabilistic relevance framework: Bm25 and beyond, Foundations and Trends in Information Retrieval, vol. 3, no. 4, pp. 333389, 2009. [7] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Lau, Jimmy Lin, and Paul Bennett, Approximate nearest neighbor negative contrastive learning for dense text retrieval, 2020. [8] Yingqi Qu, Yujing Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang, RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering, in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021, pp. 58355847, Association for Computational Linguistics. [9] Omar Khattab and Matei Zaharia, Colbert: Efficient and effective passage search via contextualized late interaction over bert, in Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, 2020, pp. 3948. [10] Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia, Colbertv2: Effective and efficient retrieval via lightweight late interaction, arXiv preprint arXiv:2112.01488, 2021. [11] Thibault Formal, Benjamin Piwowarski, and Stephane Clinchant, Splade: Sparse lexical and expansion model for first stage ranking, in Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2021. [12] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf, Distilbert, distilled version of bert: smaller, faster, cheaper and lighter, arXiv preprint arXiv:1910.01108, 2019. [13] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, and Qun Liu, Tinybert: Distilling bert for natural language understanding, arXiv preprint arXiv:1909.10351, 2019. [14] Ahmed Magdy Ezzeldin and Mohamed Shaheen, survey of arabic question answering: challenges, tasks, approaches, tools, and future trends, in Proceedings of The 13th international Arab conference on information technology (ACIT 2012), 2012, pp. 18. [15] Wissam Antoun, Fady Baly, and Hazem Hajj, Arabert: Transformer-based model for arabic language understanding, arXiv preprint arXiv:2003.00104, 2020. [16] Muhammad Abdul-Mageed, AbdelRahim Elmadany, and Arbert & marbert: Deep arXiv preprint transformers for arabic, El Moatez Billah Nagoudi, bidirectional arXiv:2101.01785, 2020. [17] Wissam Antoun, Fady Baly, and Hazem Hajj, Araelectra: Pretraining text discriminators for arabic language understanding, arXiv preprint arXiv:2012.15516, 2020. [18] Go Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda Bouamor, and Nizar Habash, The interplay of variant, size, and task type in arabic pre-trained language models, arXiv preprint arXiv:2103.06678, 2021. [19] Kareem Darwish, Walid Magdy, et al., Arabic information retrieval, Foundations and Trends in Information Retrieval, vol. 7, no. 4, pp. 239342, 2014. [20] Rasha Obeidat, Marwa Al-Harbi, Mahmoud Al-Ayyoub, and Luay Alawneh, Arquad: An expert-annotated arabic machine reading comprehension dataset, Cognitive Computation, vol. 16, no. 3, pp. 9841003, 2024. [21] Jonathan Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki, Tydi qa: benchmark for information-seeking question answering in ty pologically di verse languages, Transactions of the Association for Computational Linguistics, vol. 8, pp. 454 470, 2020. [22] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck, Learning deep structured semantic models for web search using clickthrough data, in Proceedings of the 22nd ACM international conference on Information & Knowledge Management, 2013, pp. 23332338. [23] Sparsh Gupta and Vitor Carvalho, Faq retrieval using attentive matching, in Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2019, pp. 929932. [24] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick SH Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih, Dense passage retrieval for open-domain question answering., in EMNLP (1), 2020, pp. 67696781. [25] Ali Safaya, Moutasem Abdullatif, and Deniz Yuret, Kuisail at semeval-2020 task 12: Bert-cnn for offensive speech identification in social media, arXiv preprint arXiv:2007.13184, 2020. [26] Ilya Loshchilov and Frank Hutter, Decoupled weight decay regularization, in International Conference on Learning Representations (ICLR), 2019. [27] Hussein Mozannar, Karl El Hajal, Elie Maamary, and Hazem arXiv preprint Neural arabic question answering, Hajj, arXiv:1906.05394, 2019."
        }
    ],
    "affiliations": [
        "Faculty of Pharmacy, Helsinki University, Helsinki, Finland",
        "IKERBASQUE, Basque Foundation for Science, Bilbao, Spain",
        "Lab. de Genie Electrique (LAGE), University of Ouargla, Ouargla, Algeria",
        "Sorbonne University Abu Dhabi, Abu Dhabi, UAE",
        "University of the Basque Country UPV/EHU, San Sebastian, Spain"
    ]
}