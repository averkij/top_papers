{
    "paper_title": "Steepest Descent Density Control for Compact 3D Gaussian Splatting",
    "authors": [
        "Peihao Wang",
        "Yuehao Wang",
        "Dilin Wang",
        "Sreyas Mohan",
        "Zhiwen Fan",
        "Lemeng Wu",
        "Ruisi Cai",
        "Yu-Ying Yeh",
        "Zhangyang Wang",
        "Qiang Liu",
        "Rakesh Ranjan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time, high-resolution novel view synthesis. By representing scenes as a mixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for efficient rendering and reconstruction. To optimize scene coverage and capture fine details, 3DGS employs a densification algorithm to generate additional points. However, this process often leads to redundant point clouds, resulting in excessive memory usage, slower performance, and substantial storage demands - posing significant challenges for deployment on resource-constrained devices. To address this limitation, we propose a theoretical framework that demystifies and improves density control in 3DGS. Our analysis reveals that splitting is crucial for escaping saddle points. Through an optimization-theoretic approach, we establish the necessary conditions for densification, determine the minimal number of offspring Gaussians, identify the optimal parameter update direction, and provide an analytical solution for normalizing off-spring opacity. Building on these insights, we introduce SteepGS, incorporating steepest density control, a principled strategy that minimizes loss while maintaining a compact point cloud. SteepGS achieves a ~50% reduction in Gaussian points without compromising rendering quality, significantly enhancing both efficiency and scalability."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 ] . [ 1 7 8 5 5 0 . 5 0 5 2 : r Steepest Descent Density Control for Compact 3D Gaussian Splatting Peihao Wang1*, Yuehao Wang1*, Dilin Wang2, Sreyas Mohan2, Zhiwen Fan1, Lemeng Wu2, Ruisi Cai1, Yu-Ying Yeh2, Zhangyang Wang1, Qiang Liu1, Rakesh Ranjan2 1The University of Texas at Austin, 2Meta Reality Labs {peihaowang, yuehao, zhiwenfan, ruisi.cai, atlaswang}@utexas.edu, lqiang@cs.utexas.edu, {wdilin, sreyasmohan, lmwu, yyyeh, rakeshr}@meta.com vita-group.github.io/SteepGS Figure 1. We theoretically investigate density control in 3DGS. As training via gradient descent progresses, many Gaussian primitives are observed to become stationary while failing to reconstruct the regions they cover (e.g. the cyan-colored blobs in the top-left figure marked with ). From an optimization-theoretic perspective (see figure on the right), we reveal that these primitives are trapped in saddle points, the regions in the loss landscape where gradients are insufficient to further reduce loss, leaving parameters sub-optimal locally. To address this, we introduce SteepGS, which efficiently identifies Gaussian points located in saddle area, splits them into two off-springs, and displaces new primitives along the steepest descent directions. This restores the effectiveness of successive gradient-based updates by escaping the saddle area (e.g. the orange-colored blobs in the top-left figure marked with become optimizable after densification). As shown in the bottom-left visualization, SteepGS achieves more compact parameterization while preserving the fidelity of fine geometric details."
        },
        {
            "title": "Abstract",
            "content": "3D Gaussian Splatting (3DGS) has emerged as powerful technique for real-time, high-resolution novel view synthesis. By representing scenes as mixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for efficient rendering and reconstruction. To optimize scene coverage and capture fine details, 3DGS employs densification algorithm to generate additional points. However, this process often leads to redundant point clouds, resulting in excessive memory usage, slower performance, and substantial storage demandsposing significant challenges for deployment on resource-constrained devices. To address this limitation, we *Equal contribution. Work done during an internship with Meta Reality Labs. propose theoretical framework that demystifies and improves density control in 3DGS. Our analysis reveals that splitting is crucial for escaping saddle points. Through an optimization-theoretic approach, we establish the necessary conditions for densification, determine the minimal number of offspring Gaussians, identify the optimal parameter update direction, and provide an analytical solution for normalizing off-spring opacity. Building on these insights, we introduce SteepGS, incorporating steepest density control, principled strategy that minimizes loss while maintaining compact point cloud. SteepGS achieves 50% reduction in Gaussian points without compromising rendering quality, significantly enhancing both efficiency and scalability. 1. Introduction 3D Gaussian Splatting (3DGS) [13], as successor to Neural Radiance Fields (NeRF) [20] for novel view synthesis, excels in delivering impressive view synthesis results while achieving real-time rendering of large-scale scenes at high resolutions. Unlike NeRFs volumetric representation, 3DGS represents radiance fields of 3D scenes as mixture of Gaussian primitives, each defined by parameters such as location, size, opacity, and appearance [46]. By utilizing the rasterization pipeline integrated with GPUs, this approach allows for ultra-efficient rendering and backpropagation, significantly accelerating scene reconstruction and view inference. At the core of 3DGS is an alternating optimization process that enables accurate approximation of complex scenes using Gaussian primitives. Starting with precomputed sparse point cloud as the initialization, 3DGS cycles between standard gradient-based photometric error minimization to refine Gaussian parameters, and tailored Adaptive Density Control (ADC) algorithm [13] to adjusts the number of Gaussian points. During the densification phase, ADC identifies set of heavily optimized points and splits each into two offspring, assigning distinct parameter updates based on their absolute sizes to ensure comprehensive scene coverage and capture fine geometric details. However, this reconstruction pipeline in 3DGS often produces excessively large point clouds, causing increased memory usage, slower rendering speed, and significant disk overhead. This issue poses critical bottleneck for deployment on resource-constrained devices such as mobile phones and VR headsets. While post-hoc pruning and quantization-based compression algorithms have been widely used to address this challenge [9, 11, 16, 21, 2325, 31], there are only few approaches that directly tackle this problem through the densification process. Optimizing the densification phase could potentially yield compact Gaussian point clouds for faster rendering while simultaneously reducing training costs. Some prior works have attempted to revise the density control algorithm using heuristics, such as modifying the splitting criteria [3] or generating new Gaussians by sampling from the opacity distribution [14]. However, the densification process is not well understood, and as result, the existing solutions only achieve very limited improvement as they primarily rely on heuristics. In this paper, we theoretically demystify the density control algorithms for 3DGS through the lens of non-convex optimization. Our analysis characterizes the loss behavior after splitting by introducing novel matrix, termed the splitting matrix, which links the first-order gradient of each Gaussian to its corresponding Hessian. We prove that the splitting operation is crucial in 3DGS for escaping saddle points. However, not all points benefit from densification. Specifically, we demonstrate that splitting only reduces the loss if the associated splitting matrix is not positive semidefinite. This insight highlights the importance of splitting in density control algorithms, offering deeper optimizationtheoretic perspective to complement the existing geometric understanding. Based on these theoretical investigations, we further draw the following affirmative conclusions: (i) Splitting each Gaussian into two offspring is sufficient to achieve the optimal descent on loss while ensuring controlled growth rate of the number of points. (ii) The magnitude of the off-spring Gaussians should be halved to preserve the local density. (iii) To achieve the steepest descent in loss after splitting, the new Gaussians should be displaced along the positive and negative directions of the eigenvector corresponding to the least eigenvalue of the splitting matrix. We consolidate these findings into principled splitting strategy, termed Steepest Density Control (SDC), which provably maximizes loss reduction while minimizing the number of yielded Gaussian off-springs. We further demonstrate that Steepest Density Control (SDC) can be efficiently implemented and seamlessly integrated into the existing 3DGS CUDA kernel. To compute the splitting matrix, we propose parallel algorithm that leverages the closed-form Hessian for each Gaussian, combined with gradient information reused from backpropagation. We term this enhanced 3DGS-based reconstruction system SteepGS. Empirically, SteepGS achieves over 50% reduction in Gaussian points while maintaining high rendering quality, significantly improving memory efficiency and rendering speed. 2. Related Work 2.1. Efficient Scene Representations Recent advancements in neural scene representations have transformed view synthesis. Neural Radiance Fields (NeRF) [20] introduced method for synthesizing photorealistic views by optimizing continuous volumetric scene function using sparse input views, however their high computational cost limits their applications. Building on NeRF, several methods have attempted to reduce the computational like, InstantNGP [22] by employing multiresolution hash encoding, TensoRF [5] by modelling radiance field as 4D tensor with compact low-rank factorization, Generalizable NeRFs [4, 32, 34] by leveraging attention to decode assosciations between multiple views, and Plenoxel[10, 43] by using view-dependent sparse voxel model. Light Field Networks [28] and Surface Based Rendering [17, 27, 41], and Point Based Rendering [1, 40, 42] have also made significant contributions by proposing novel neural scene representations and differentiable rendering techniques. Unlike these methods, 3DGS [13] offers an alternative representation by modeling scenes with learnable anisotropic Gaussian kernels, enabling fast rendering through point-based rasterization. 2.2. Compact 3D Gaussian Splatting The original 3D Gaussian Splatting [13] optimization tends to represent the scene with redundant GS. Several works have been proposed to obtain more compact scene with distilled or compact representation on GS attributes [9, 16], improved pruning [9, 14], or even efficient densification [3, 14, 16, 18]. Among the densification approaches, Lee et al. [16] proposes learnable masking strategy during densification while using compact grid-based neural field and codebook to represent color and geometry. 3DGS-MCMC [14] rewrites densification and pruning as deterministic state transition of MCMC samples. Revising-3DGS [3] proposes pixel-error driven density control for densification. Taming-3DGS [18] applies score-based densification with predictable budget control. Instead, our method takes partial Hessian information to achieve steepest density control. 2.3. Neural Architecture Splitting In the field of neural architecture search, promising direction involves starting with small seed network and gradually expanding its size based on target performance and user constraints. This approach, known as neural architecture growth or splitting, was initially proposed by Net2Net [7], which introduced the concept of growing networks by duplicating neurons or layers with noise perturbation. Follow-up works [6, 8, 33, 39] extend network module-wise growth to enhance model performance across various applications. The most relevant prior work is perhaps S2D [30, 36, 38], which refines the neuron splitting process by calculating subsets of neurons to split and applying splitting gradient for optimal updating of the off-springs. After that, Firefly [37] introduces first-order gradient-based approach to approximate the S2D split matrix, accelerating the splitting process and making the splitting method scalable. Although theoretically related, these methods are not directly applicable to 3DGS optimization. Our investigation into splitting schemes in 3DGS aims to address this gap. 3. Preliminaries: 3D Gaussian Splatting In this section, we briefly review the reconstruction pipeline of 3DGS, along the way, introducing necessary notations. Scene Representation. The core idea of 3D Gaussian Splatting (3DGS) [13] is to approximate the radiance field [20] of complex scenes via mixture of Gaussian primitives [46]. Formally, consider one scene that is represented by set of primitives with parameters θ = {θ(i) Θ}n i=1, where θ(i) (p(i), Σ(i), o(i), c(i)), p(i) R3 denotes the central position, Σ(i) S33 + is the positive semi-definite covariance matrix, often re-parameterized via quaternion plus scaling vector, o(i) [0, 1] denotes the magnitude of the Gaussian function, often geometrically interpreted as the opacity value. Moreover, each Gaussian point is associated with color attributes c(i) R3, which are stored as spherical harmonics coefficients and converted to RGB values at the rendering time. The entire density field of the scene α : R3 is expressed as combination of all primitives α(ξ) = (cid:80)N i=1 σ(ξ; θ(i)), where each Gaussian primitive σ(; θ(i)) : R3 contributes as scaled Gaussian kernel on 3D point ξ R3 [46]: σ(ξ; θ(i)) = o(i) (ξ; p(i), Σ(i)). (1) Here (ξ; p, Σ) = exp( 1 an unnormalized Gaussian function. 2 (ξ p)Σ1(ξ p)) denotes Rasterization. To display pixel on the screen, Zwicker et al. [46] shows that volume rendering [19] can be realized by first projecting each primitive individually and then compositing each primitive via back-to-front α-blending. Formally, suppose the pixel location is R2 and worldto-camera projection is Π : R3 R2, which encompasses both camera extrinsics and intrinsics. To obtain the rendered color for pixel x, 3DGS first sorts points according to viewdependent depth and then adopts an efficient rasterization process formulated as follows: CΠ(x; θ) = (cid:88) i= ciTiσΠ(x; θ(i)), (2) where Ti = (cid:81)i1 the analytical form: j=1(1 σΠ(x; θ(j))), and σΠ(x; θ(i)) has σΠ(x; θ(i)) = o(i) (cid:16) x; Π(p(i)), Π(Σ(i)) (cid:17) , (3) denoting the Gaussian primitive being projected to the 2D space via the affine transformation Π1. Optimization. To acquire parameters θ to represent 3D scenes, Kerbl et al. [13] employs point cloud computed from Structure-from-Motion (SfM) software [26] with input images as the initial positions of Gaussian primitives. Afterward, 3DGS optimizes parameters θ by minimizing the photometric error between captured images and images rendered from θ at the same viewpoint. Suppose we have error function ℓ(, ), the total photometric loss can be written as: L(θ) = E(Π,x)D (cid:16) (cid:104) ℓ CΠ(x; θ), (cid:98)CΠ(x) (cid:17)(cid:105) , (4) where denotes sampling distribution of all collected pixels (and corresponding camera poses), and (cid:98)CΠ(x) is the corresponding ground-truth pixel color. In particular, 3DGS adopts ℓ1 distance as the loss function ℓ(, )2. We note that this photometric loss can be end-to-end viewed as functional, which maps set of basis functions {σΠ(x; θ(i))} to loss value according to the specified parameters (Π, x). 1Suppose affine transformation Π(x) = + for some R23 and R2, then when applied to matrix Σ R33, Π(Σ) = ΣP . 2Without loss of generality, we ignore the SSIM term for simplicity. Adaptive Density Control. In conjunction with the standard gradient-based method for optimizing Eq. 4, 3DGS incorporates an Adaptive Density Control (ADC) procedure, which dynamically prunes invisible points and introduces new primitives using geometric heuristics to more effectively cover the scene. We summarize this densification process here as it is of this papers main interest. (i) ADC first identifies set of points with large expected gradient norm on the view space: = {i [n] : E[Π(p(i))L2] ϵadc}. (ii) For points in with small scales Iclone = {i : Σ(i)2 τadc}, ADC considers them as under-reconstruction cases. ADC yields two offspring primitives for each point in Iclone by duplicating their attributes and adjusting the positions of new offspring along the gradient direction. (iii) For those who have large size Isplit = {i : Σ(i)2 τadc}, ADC regards them as over-reconstruction cases. Similarly, 3DGS generates two new off-spring points for each point in Isplit, while placing them at random location drawn from the parent density function, and downsizing the scales by factor of 0.8. 4. Methodology Despite the empirical success of the conventional ADC in 3DGS, it often produces redundant points given its heuristic and somewhat artisanal splitting criteria. In this section, we establish theoretical framework to investigate densification mechanism. By this means, we affirmatively answer three key questions: (i) What is the necessary condition for Gaussian primitive to be split? (Sec. 4.2) (ii) Where should new Gaussian off-springs be placed? (Sec. 4.3) and (iii) How to adjust opacity for new Gaussian points? (Sec. 4.3) Combining these results, we propose new density control strategy with hardware-efficient implementation (Sec. 4.4). 4.1. Problem Setup }mi j=1, where ϑ(i) Suppose the scene has been represented by Gaussian primitives with parameters collectively as θ = {θ(i)}n i=1 and the total loss is L(θ) as defined in Eq. 4. Our goal is to split each Gaussian into mi N+ off-springs. We denote the parameters of the i-th Gaussians off-springs as ϑ(i) = {ϑ(i) is the j-th off-spring. Furj ther on, we assign each Gaussian group of coefficients w(i) = {w(i) j=1 to reweigh their opacity. Since the scene are approximated via summation, the process of splitting can be equivalently viewed as replacing each extant Gaussian locally with combination of its off-springs: (cid:80)mi σ(; ϑ(i) ). The 2D projections of each old Gaussian then become (cid:80)mi ) for every camera pose Π. Note that mi = 1 implies no splitting happens and the original Gaussian remains unaltered. R+}mi σΠ(; ϑ(i) j=1 w(i) j=1 w(i) We collect parameters of all the new Gaussians as ϑ = i=1, and reweighting coefficients as = {w(i)}n i=1, {ϑ(i)}n Figure 2. Illustrative notation for the splitting process. The updates ϑ(i) θ(i) can be decomposed as first taking meanfield shift µ(i) and then applying individual updates δ(i) . By this decomposition, (cid:80) w(i) = 0. δ(i) for shorthand. densification algorithm determines values for {mi}n i=1, w, and ϑ at each step. After specifying values of w, these coefficients will be absorbed into the opacity values of the off-springs. The original ADC can be interpreted through the lens of this framework: (i) mi = 2 if E[Π(p(i))L2] ϵadc, or mi = 1 otherwise. (ii) If Iclone, then p(i) p(i) p(i)L, otherwise p(i) = 0.64Σ(i), for every [mi]. (iii) w(i) = 1, [mi] for either case. (p(i), Σ(i)), Σ(i) 4.2. When is Densification Helpful? In this section, we theoretically elucidate the effect of the density control algorithms by examining the photometric loss after splitting. With newly added Gaussian primitives, the loss can be evaluated as: (cid:16) (cid:17)(cid:105) L(ϑ, w) = E(Π,x)D (cid:104) ℓ CΠ(x; ϑ, w), (cid:98)CΠ(x) , (5) where CΠ(x; ϑ, w) denotes the color rendered for pixel via Eq. 2 with new parameters ϑ and w. The original ADC [13] has no guarantee that the loss will decrease after splitting. As we show later, densifying random point can even increase the loss. Bul`o et al. [3] and Kheradmand et al. [14] adjust opacity values for Gaussian off-springs to preserve total densities locally after splitting. In this setup, the loss L(ϑ, w) remains approximately equivalent to L(θ). However, as we will demonstrate next, this preservation principle is not necessarily the most effective approach. By choosing appropriate Gaussian primitives, it is even possible to further reduce the loss. j=1 w(i) From this point forward, we consider two additional practical conditions. First, to ensure the total opacity is conservative after splitting, we impose the constraint that (cid:80)mi = 1 for every [n]. Second, we assume the parameters of off-springs are close to the original parameters, i.e. {ϑ(i) j=1 are within neighborhood of θ(i): ϑ(i) θ(i)2 ϵ for some ϵ > 0. Let us define µ(i) = (cid:80)mi j=1 w(i) θ(i) as the average displacement of the i-th ϑ(i) }mi = (ϑ(i) Gaussian after densification, and δ(i) θ(i)) µ(i) denotes an offset additional to µ(i) for each off-spring. We visualize the splitting process in Fig. 2 for better illustration of our notations. The splitting process consists of two steps: first translating the parent Gaussian by an offset µ(i), and second, generating offspring with individual shifts {δ(i) }j[mi] whose mean is zero. With all these settings, below we present our first main result, which decomposes the loss after splitting: Theorem 1. Assume L(ϑ, w) has bounded third-order derivatives with respect to ϑ, then L(ϑ, w) = L(θ) + θL(θ)µ + 1 2 µ θL(θ)µ + 1 2 (cid:88) mi(cid:88) i= j=1 δ(i) w(i) S(i)(θ)δ(i) + O(ϵ3), where µ = (cid:2)µ(1) µ(n)(cid:3) age offsets and S(i)(θ) Rdim Θdim Θ is defined as: concatenates all averS(i)(θ) = E(Π,x)D (cid:34) ℓ σΠ(x; θ(i)) (cid:35) θ(i) σΠ(x; θ(i)) 2 . All proofs are provided in the supplementary material, Appendix C. Theorem 1 decouples and groups the effects of the mean displacement and the individual offsets of each offspring. The first three terms, highlighted in blue , are referred to as the mean shift terms, which collectively represent the impact of shifting the overall mean. Since shifting all off-springs simultaneously is equivalent to applying the same offset to the original Gaussian, the term involving individual offsets, highlighted in orange , fully captures the intrinsic effect of the splitting process. We isolate each term within this summation and refer to it as splitting characteristic function, which fully describes the effect of splitting on single Gaussian point: (i)(δ(i), w(i); θ) 1 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) . (6) Essentially, the splitting characteristic function takes quadratic form with respect to the matrix S(i)(θ). We refer to S(i)(θ) as the splitting matrix, which fully governs the behavior of the splitting characteristic function. Theorem 1 draws two insights as below: Densification escapes saddle points. By using the RHS of Theorem 1 as surrogate for minimizing the loss, one can observe that optimizing the mean shift terms does not require densification but can be achieved by standard gradient descent 3. However, it is worth noting that the loss function in 3More precisely, this aligns with the Newton method, where gradients are preconditioned by the inverse Hessian. Figure 3. Illustration of Steepest Density Control. SDC, as the optimal solution to Eq. 7, takes the steepest descent on the loss after splitting. Geometrically, it moves two off-spring Gaussians to opposite directions along the smallest eigenvector of the splitting matrix and shrinks the opacity of each Gaussian by 0.5. Eq. 4 is highly non-convex objective, exhibiting numerous superfluous saddle points in its loss landscape (see the right of Fig. 1 for an illustration). Gradients are prone to getting trapped at these saddle points, at which point gradient descent ceases to yield further improvements. However, by densifying Gaussian points at saddle points into multiple particles, new term captured by the splitting characteristic functions (i) emerges. These terms can become negative to further reduce the loss. Thus, densification serves as an effective mechanism for escaping saddle points. When does splitting decrease loss? In fact, finergrained analysis can be done with the splitting characteristic function (i). Since the overall contribution of splitting to the loss is expressed as sum of quadratic functions over the splitting matrices, (i) can be negative to decrease the loss only if the associated splitting matrix is not positive semi-definite. This implies that necessary condition for performing split is λmin(S(i)(θ)) < 0, where λmin() denotes the smallest eigenvalue of the specified matrix. 4.3. Optimal Density Control Based on Theorem 1, we can derive even stronger results. We intend to find density control strategy that introduces minimal number of points while achieving the steepest descent in the loss. Maximizing loss descent at each step enforces low reconstruction errors and accelerates convergence. To this end, we formulate the following constrained optimization objective: min L(ϑ, w), s.t. (cid:13) (cid:13)ϑ(i) (cid:13) θ(i)(cid:13) (cid:13) (cid:13)2 ϵ, mi(cid:88) j=1 w(i) = 1, (7) which seeks an optimal configuration of the number of offsprings mi N+, reweighting coefficients w(i) R+, and updates to the parameters for new primitives {δ(i) } for all [n], [mi] to maximize loss descent. While solving Eq. 7 directly is difficult, Theorem 1 provides an ideal second-order approximation as surrogate. Since the effect of splitting Gaussians is fully characterized by the splitting characteristic function, it is sufficient to consider minimizing (i) with respect to {δ(i) }. Consequently, the solution is simple and analytical. Our main result is presented below: Theorem 2. The optimal solution to Eq. 7 has two folds: 1. If splitting matrix S(i)(θ) is positive semi-definite λmin(S(i)(θ)) 0, then splitting cannot decrease the loss. In this case, we set mi = 1 and no splitting happens. 2. Otherwise, if λmin(S(i)(θ)) < 0, then the following splitting strategy minimizes (i)(δ(i), w(i); θ) subject to δ(i) 1 for every [mi]: i = 2, 1 = w(i) w(i) 2 = 1 2 , 1 = vmin(S(i)(θ)), δ(i) δ(i) 2 = vmin(S(i)(θ)), where vmin() denotes the eigenvector associated with the smallest eigenvalue λmin(). We term the splitting strategy outlined in Theorem 2 as Steepest Density Control (SDC). It has four practical implications: i) necessary condition for densification is the positive indefiniteness of the splitting matrices. ii) Splitting each Gaussian into two off-springs is sufficient, and generating more off-springs offers no additional benefit. iii) The magnitudes of the new primitives must be downscaled by factor of two to preserve local opacity. iv) The parameters of the two off-springs should be updated along the positive/negative directions of the eigenvector corresponding to the least eigenvalue of the splitting matrices. Further on, the result in (i), as already shown in Sec. 4.2, can be employed as filter to reduce the number of points to be densified. Implication by (ii) justifies the common choice of two off-springs in existing ADC algorithms [13] and ensures moderate growth rate. The result (iii) contrasts with the approaches of Bul`o et al. [3] and Kheradmand et al. [14], where opacities of new Gaussians are adjusted based on rendering-specific schemes. Notably, both opacity adjustment methods in these works are inexact and do not necessarily preserve total opacity. The point (iv) gives two update directions that shift points to the non-saddle area when they are optimized to the stationary point, as illustrated on the right of Fig. 1. We further demonstrate this splitting scheme in Fig. 3, which visualizes how our splitting strategy locally refines the geometry. 4.4. Steepest Gaussian Splatting In this section, we instantiate 3DGS optimization algorithm with SDC as the density control scheme, dubbed SteepGS. At the core of SteepGS is to compute the splitting matrices and leverage them to decide when and how to split points. Algorithm 1 in Appendix A.1 provides reference implementation for SteepGS. We show that these can be efficiently implemented and integrated into the CUDA kernel. Revisiting the form of splitting matrix in Theorem 1, we note that ℓ/σΠ(x; θ(i)) denotes the gradient of (scalar) loss ℓ back-propagated to the output of the i-th Gaussian θσ(θ(i), x) is the Hessian matrix of the primitive, and 2 i-th Gaussian with respect to its own parameters θ(i). It is noteworthy that splitting matrices are defined per point and only rely on the Hessian of each Gaussian individually. Therefore, the total memory footprint to store the splitting matrices is O(n(dim Θ)2). When we only consider the mean positions {p(i)}n i=1 as the parameters, dim Θ = 3. To compute splitting matrix, we note that the gradient ℓ/σΠ(x; θ(i)) has already been acquired during the backpropagation when computing θL(θ, x). The remaining θσΠ(x; θ(i)) can be approximated part, the Hessian matrix 2 analytically as (see derivations in Appendix C.4): θσΠ(x; θ(i)) σ(i)ΥΥ σ(i)P Π(Σ(i))1P , where Υ Π(Σ(i))1(x Π(p(i))), denotes the projection matrix given by Π1, and σ(i) σΠ(x; θ(i)). The S(i) can be computed in parallel, and intermediate results such as σ, Π(µ), Π(Σ) can be reused from previous forward computation. The complexity of computing the minimum eigenvalue and eigenvector for dim Θ dim Θ matrices is O((dim Θ)2). As we only use the position parameter, the least eigenvalue and eigenvector for 3 3 matrices can be calculated using the root formula [29]. Although splitting matrices leverage the second-order information, it is distinct from the full Hessian of the total loss 2 θL (e.g. used in Hanson et al. [11]) by precluding cross terms in full Hessian 2 θL [36]. Surprisingly, the structure of the problem allows for the pointwise identification of saddle points with only partial Hessian information provided by splitting matrices. 5. Experiments In this section, we empirically validate the effectiveness of our proposed SteepGS. 5.1. Settings In our main experiments, we train 3DGS with various densification schemes and compare their final number of points and the novel view synthesis quality. Datasets. We compare our methods and other baselines on three challenging real-world datasets: Mip-NeRF 360 Figure 4. Qualitative Results. We compare our SteepGS with other densification baselines. For each scene, the first row shows the rendered view, while the second row visualizes the error with respect to the ground truth. Key details are highlighted in the blue box. [2] including three outdoor and four indoor scenes, Tanks & Temples [15] with two outdoor scenes, and Deep Blending [12] containing two indoor scenes. Baselines. We compare SteepGS with the original ADC and the other two densification schemes: 3DGS-MCMC [14] and Revising-GS [3]. We use the official codebases for 3DGS and 3DGS-MCMC, while re-implementing RevisingGS based on the codebase of the original 3DGS. We added 3DGS-Thres. baseline which is modified from the original 3DGS ADC such that the training stops when meeting the same amount of points of other compared methods. Both 3DGS-MCMC and Revising-GS require maximum limit of the Gaussian number. We choose this number as the number of Gaussion our SteepGS yields. For all these baselines, we use their default hyper-parameters. Implementation Details. Our SteepGS is implemented based on the codebase of the official 3DGS codebase [13]. We further customize the CUDA kernel to compute the splitting matrices and their eigen-decompositions. We follow the standard training pipeline of 3DGS and perform density control for every 100 steps starting from the 500th step. The threshold for the smallest eigenvalues of splitting matrices is chosen as 1e 6. All other hyper-parameters are kept the same with 3DGSs default settings. Each of our per-scene training are conducted on single NVIDIA V100 GPU. 5.2. Results We adopt PSNR, SSIM [35], and LPIPS [44] as evaluation metrics for view synthesis quality, and present the final number of yielded points and training time as the efficiency metrics. Tab. 1 presents our quantitative experiments. ComMipNeRF360 # Points PSNR SSIM LPIPS 3DGS [13] 3DGS + Thres. [13] 3DGS-MCMC [14] Revising 3DGS [3] SteepGS (Ours) 3.339 1. 1.606 1.606 1.606 29.037 0.872 27. 28.149 28.085 0.848 0.853 0.850 28. 0.857 Tank & Temple 0.183 0.227 0.204 0. 0.211 # Points PSNR SSIM LPIPS 3DGS [13] 3DGS + Thres. [13] 3DGS-MCMC [14] Revising 3DGS [3] SteepGS (Ours) 1.830 0.973 0. 0.957 0.958 23.743 0.848 22.415 22. 22.339 0.812 0.817 0.811 23.684 0. Deep Blending 0.177 0.218 0.204 0.216 0. Figure 5. Visualization of splitting points. The rendered views are present on the left and the corresponding points to be split are visualized on the right. ter the entire training process, our method achieves these savings without the need for post-training steps. # Points PSNR SSIM LPIPS 5.3. Visualization and Interpretation 3DGS [13] 3DGS + Thres. [13] 3DGS-MCMC [14] Revising 3DGS [3] SteepGS (Ours) 2. 1.326 1.296 1.296 1.296 29.690 0. 29.374 29.439 29.439 0.900 0.901 0. 29.963 0.905 0.244 0.250 0.237 0. 0.250 Table 1. Comparison with representative baselines, including 3DGS [13], 3DGS + Thres. [13], and Revising 3DGS [3]. The unit of # Points is million. The best and second best approaches for improving densification are marked in colors. pared to the original adaptive density control, our method achieves comparable rendering performance on the MipNeRF 360 dataset while reducing the number of Gaussians by approximately 50%. Our method outperforms 3DGSThres., 3DGS-MCMC and Revising 3DGS baselines when the two methods are trained to generate the same number of Gaussians. Similarly, on the Tank & Temple and DeepBlending datasets, our approach attains around 50% reduction in the number of Gaussians and even achieves higher PSNR values for DeepBlending scenes. Fig. 4 presents qualitative comparisons between our densification algorithm and baseline methods. As illustrated by the difference maps, although our method generates only half the number of new points compared to the original densification approach, it maintains competitive rendering quality and preserves many details. These results suggest that the additional Gaussians produced by the original adaptive density control are redundant. In contrast, our method mitigates redundancy during the training process through the densification procedure. Notably, unlike compression-based methods such as LightGaussian [9], which identify and prune less important Gaussians afIn Fig. 5, we visualize the points filtered by our strategy and the original splitting strategy at the 1,000th iteration, respectively. The rendered RGB images show that the backrest of the bench has been trained to capture its basic shape and appearance, whereas the seat still lacks clear details. As depicted in the figure, our method effectively concentrates Gaussian splitting on the seat, leaving other regions to the optimizer. In contrast, the original adaptive density control allocates splitting to the backrest, resulting in approximately four times as many splitting points as our method. This suggests that our approach enhances efficiency by focusing splitting on areas that require more detail, thereby improving overall rendering performance in more efficient way. 6. Conclusion This work addresses the inefficiencies in 3D Gaussian Splatting (3DGS), leading technique for real-time, highresolution novel view synthesis. While effective, its densification process often generates redundant points, leading to high memory usage, slower performance, and increased storage demandshindering deployment on resource-constrained devices. To tackle this, we introduced theoretical framework that clarifies and optimizes density control in 3DGS. Our analysis highlights the necessity of splitting for escaping saddle points and establishes optimal conditions for densification, including the minimal number of offspring Gaussians and their parameter updates. Building on these insights, we proposed SteepGS, which integrates steepest density control to maintain compact point clouds. SteepGS reduces Gaussian points by 50% without sacrificing rendering quality, improving efficiency and scalability for practical use. Acknowledgments PW thanks Forrest Iandola, Zhen Wang, Jonathon Luiten, Nikolaos Sarafianos, and Amit Kumar for helpful discussion during the preparation of this work. Any statements, opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of their employers or the supporting entities."
        },
        {
            "title": "References",
            "content": "[1] Kara-Ali Aliev, Artem Sevastopolsky, Maria Kolos, Dmitry Ulyanov, and Victor Lempitsky. Neural point-based graphics. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part XXII 16, pages 696712. Springer, 2020. 2 [2] Jonathan Barron, Ben Mildenhall, Dor Verbin, Pratul Srinivasan, and Peter Hedman. Mip-nerf 360: Unbounded In Proceedings of the anti-aliased neural radiance fields. IEEE/CVF conference on computer vision and pattern recognition, pages 54705479, 2022. 7 [3] Samuel Rota Bul`o, Lorenzo Porzi, and Peter Kontschieder. Revising densification in gaussian splatting. arXiv preprint arXiv:2404.06109, 2024. 2, 3, 4, 6, 7, 8, 1 [4] Anpei Chen, Zexiang Xu, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu, and Hao Su. Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1412414133, 2021. 2 [5] Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su. Tensorf: Tensorial radiance fields. In European conference on computer vision, pages 333350. Springer, 2022. 2 [6] Cheng Chen, Yichun Yin, Lifeng Shang, Xin Jiang, Yujia Qin, Fengyu Wang, Zhi Wang, Xiao Chen, Zhiyuan Liu, and Qun Liu. bert2bert: Towards reusable pretrained language models. arXiv preprint arXiv:2110.07143, 2021. [7] Tianqi Chen, Ian Goodfellow, and Jonathon Shlens. Net2net: Accelerating learning via knowledge transfer. arXiv preprint arXiv:1511.05641, 2015. 3 [8] Utku Evci, Bart van Merrienboer, Thomas Unterthiner, Max Vladymyrov, and Fabian Pedregosa. Gradmax: Growing neural networks using gradient information. arXiv preprint arXiv:2201.05125, 2022. 3 [9] Zhiwen Fan, Kevin Wang, Kairun Wen, Zehao Zhu, Dejia Xu, and Zhangyang Wang. Lightgaussian: Unbounded 3d gaussian compression with 15x reduction and 200+ fps. arXiv preprint arXiv:2311.17245, 2023. 2, 3, 8 [10] Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong Chen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels: Radiance fields without neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 55015510, 2022. 2 [11] Alex Hanson, Allen Tu, Vasu Singla, Mayuka Jayawardhana, Matthias Zwicker, and Tom Goldstein. Pup 3d-gs: Principled uncertainty pruning for 3d gaussian splatting. arXiv preprint arXiv:2406.10219, 2024. 2, 6 [12] Peter Hedman, Julien Philip, True Price, Jan-Michael Frahm, George Drettakis, and Gabriel Brostow. Deep blending for free-viewpoint image-based rendering. ACM Transactions on Graphics (ToG), 37(6):115, 2018. [13] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkuhler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Trans. Graph., 42(4):1391, 2023. 2, 3, 4, 6, 7, 8 [14] Shakiba Kheradmand, Daniel Rebain, Gopal Sharma, Weiwei Sun, Jeff Tseng, Hossam Isack, Abhishek Kar, Andrea Tagliasacchi, and Kwang Moo Yi. 3d gaussian splatting as markov chain monte carlo. arXiv preprint arXiv:2404.09591, 2024. 2, 3, 4, 6, 7, 8, 1 [15] Arno Knapitsch, Jaesik Park, Qian-Yi Zhou, and Vladlen Koltun. Tanks and temples: Benchmarking large-scale scene reconstruction. ACM Transactions on Graphics (ToG), 36(4): 113, 2017. 7 [16] Joo Chan Lee, Daniel Rho, Xiangyu Sun, Jong Hwan Ko, and Eunbyung Park. Compact 3d gaussian representation for radiance field. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 21719 21728, 2024. 2, 3, 5 [17] Shichen Liu, Tianye Li, Weikai Chen, and Hao Li. Soft rasterizer: differentiable renderer for image-based 3d reasoning. In Proceedings of the IEEE/CVF international conference on computer vision, pages 77087717, 2019. 2 [18] Saswat Subhajyoti Mallick, Rahul Goel, Bernhard Kerbl, Francisco Vicente Carrasco, Markus Steinberger, and Fernando De La Torre. Taming 3dgs: High-quality radiance fields with limited resources. arXiv preprint arXiv:2406.15643, 2024. [19] Nelson Max. Optical models for direct volume rendering. IEEE Transactions on Visualization and Computer Graphics, 1(2):99108, 1995. 3 [20] Ben Mildenhall, Pratul Srinivasan, Matthew Tancik, Jonathan Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. Communications of the ACM, 65(1):99106, 2021. 2, 3 [21] Wieland Morgenstern, Florian Barthel, Anna Hilsmann, and Peter Eisert. Compact 3d scene representation via selforganizing gaussian grids. arXiv preprint arXiv:2312.13299, 2023. 2 [22] Thomas Muller, Alex Evans, Christoph Schied, and Alexander Keller. Instant neural graphics primitives with multiresolution hash encoding. ACM transactions on graphics (TOG), 41(4):115, 2022. 2 [23] KL Navaneet, Kossar Pourahmadi Meibodi, Soroush Abbasi Koohpayegani, and Hamed Pirsiavash. Compact3d: Compressing gaussian splat radiance field models with vector quantization. arXiv preprint arXiv:2311.18159, 2023. 2 [24] Simon Niedermayr, Josef Stumpfegger, and Rudiger Westermann. Compressed 3d gaussian splatting for accelerated novel view synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1034910358, 2024. [39] Lemeng Wu, Mengchen Liu, Yinpeng Chen, Dongdong Chen, Xiyang Dai, and Lu Yuan. Residual mixture of experts, 2022. [40] Qiangeng Xu, Zexiang Xu, Julien Philip, Sai Bi, Zhixin Shu, Kalyan Sunkavalli, and Ulrich Neumann. Point-nerf: Pointbased neural radiance fields. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 54385448, 2022. 2 [41] Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, and Yaron Lipman. Multiview neural surface reconstruction by disentangling geometry and appearance. Advances in Neural Information Processing Systems, 33:24922502, 2020. 2 [42] Wang Yifan, Felice Serena, Shihao Wu, Cengiz Oztireli, and Olga Sorkine-Hornung. Differentiable surface splatting for point-based geometry processing. ACM Transactions on Graphics (TOG), 38(6):114, 2019. 2 [43] Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa. Plenoctrees for real-time rendering of neural radiance fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 57525761, 2021. 2 [44] Richard Zhang, Phillip Isola, Alexei Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as perceptual metric. In CVPR, 2018. 7 [45] Zhaoliang Zhang, Tianchen Song, Yongjae Lee, Li Yang, Cheng Peng, Rama Chellappa, and Deliang Fan. Lp-3dgs: Learning to prune 3d gaussian splatting. In The Thirty-eighth Annual Conference on Neural Information Processing Systems. 3, [46] Matthias Zwicker, Hanspeter Pfister, Jeroen Van Baar, and Markus Gross. Ewa splatting. IEEE Transactions on Visualization and Computer Graphics, 8(3):223238, 2002. 2, 3 [25] Panagiotis Papantonakis, Georgios Kopanas, Bernhard Kerbl, Alexandre Lanvin, and George Drettakis. Reducing the memory footprint of 3d gaussian splatting. Proceedings of the ACM on Computer Graphics and Interactive Techniques, 7 (1):117, 2024. 2 [26] Johannes Schonberger and Jan-Michael Frahm. Structurefrom-motion revisited. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4104 4113, 2016. 3 [27] Tianchang Shen, Jun Gao, Kangxue Yin, Ming-Yu Liu, and Sanja Fidler. Deep marching tetrahedra: hybrid representation for high-resolution 3d shape synthesis. Advances in Neural Information Processing Systems, 34:60876101, 2021. 2 [28] Vincent Sitzmann, Semon Rezchikov, Bill Freeman, Josh Tenenbaum, and Fredo Durand. Light field networks: Neural scene representations with single-evaluation rendering. Advances in Neural Information Processing Systems, 34:19313 19325, 2021. 2 [29] Oliver Smith. Eigenvalues of symmetric 3 3 matrix. Communications of the ACM, 4(4):168, 1961. 6, 2 [30] Dilin Wang, Meng Li, Lemeng Wu, Vikas Chandra, and Qiang Liu. Energy-aware neural architecture optimization with fast splitting steepest descent. arXiv preprint arXiv:1910.03103, 2019. 3 [31] Henan Wang, Hanxin Zhu, Tianyu He, Runsen Feng, Jiajun Deng, Jiang Bian, and Zhibo Chen. End-to-end ratearXiv distortion optimized 3d gaussian representation. preprint arXiv:2406.01597, 2024. 2 [32] Peihao Wang, Xuxi Chen, Tianlong Chen, Subhashini Venugopalan, Zhangyang Wang, et al. Is attention all that nerf needs? arXiv preprint arXiv:2207.13298, 2022. 2 [33] Peihao Wang, Rameswar Panda, Lucas Torroba Hennigen, Philip Greengard, Leonid Karlinsky, Rogerio Feris, David Daniel Cox, Zhangyang Wang, and Yoon Kim. Learning to grow pretrained models for efficient transformer training. arXiv preprint arXiv:2303.00980, 2023. 3 [34] Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul Srinivasan, Howard Zhou, Jonathan Barron, Ricardo MartinBrualla, Noah Snavely, and Thomas Funkhouser. Ibrnet: Learning multi-view image-based rendering. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 46904699, 2021. [35] Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600612, 2004. 7 [36] Lemeng Wu, Dilin Wang, and Qiang Liu. Splitting steepest descent for growing neural architectures. Advances in neural information processing systems, 32, 2019. 3, 6 [37] Lemeng Wu, Bo Liu, Peter Stone, and Qiang Liu. Firefly neural architecture descent: general approach for growing neural networks. Advances in neural information processing systems, 33:2237322383, 2020. 3 [38] Lemeng Wu, Mao Ye, Qi Lei, Jason Lee, and Qiang Liu. Steepest descent neural architecture optimization: Escaping local optimum with signed neural splitting. arXiv preprint arXiv:2003.10392, 2020. 3 Steepest Descent Density Control for Compact 3D Gaussian Splatting"
        },
        {
            "title": "Supplementary Material",
            "content": "A. Implementation Details A.1. Pseudocode We provide reference pseudocode for our method, SteepGS, in Algorithm 1. We highlight the main differences from the original ADC in orange . The overall procedure consists of two main components. First, the algorithm estimates the splitting matrices on the fly in mini-batch manner. Second, at regular intervals, the accumulated splitting matrices are used to decide whether to split Gaussian point and where to place the resulting offspring. Our algorithm is designed to be general and can be integrated with other point selection criteria, such as the gradient-based strategy used in the original ADC. Finally, we note that all for loops in the pseudocode are executed in parallel for efficiency. Algorithm 1 Steepest Gaussian Splatting (SteepGS) Input: An initial point cloud of Gaussians θ = {(θ(i), o(i))}θ stepsize ϵ > 0; splitting matrix threshold εsplit 0; Total number of iterations ; Densification interval Tsplit. for each training step = 1, , do i=1; loss function L(θ) associated with training set D(X ); if mod Tsplit = 0 then Sample batch of data points D(X ) and compute loss function L(θ, x). for each Gaussian = 1, , θ do Update each Gaussian parameters θ(i), o(i) via standard gradient descent. Accumulate gradients: G(i) G(i) + θ(i) L(θ, x). Accumulate splitting matrix: S(i) S(i) + σ(i)ℓ(θ, x)2σ(θ(i), x). end for else for each Gaussian = 1, , θ do Obtain average gradient and splitting matrix: G(i) G(i)/Tsplit, S(i) S(i)/Tsplit. Compute the smallest eigenvalue and the associated eigenvector for the splitting matrix: λ λmin(S(i)), δ vmin(S(i)). if condition on G(i) and λ < εsplit then Replace this Gaussian with two Gaussian off-springs: θ θ {(θ(i), o(i))} {(θ(i) + ϵδ, o(i)/2), (θ(i) ϵδ, o(i)/2)} end if end for end if end for Return θ A.2. Variants Densification with Increment Budget. Recent densification algorithms [3, 14] have shown that fixing the number or ratio of incremental points can lead to more compact Gaussian point cloud. This corresponds to imposing global constraint on the total number of new points, (cid:80) i[n] mi 2K, when solving the objective in Eq. 7: min L(ϑ, w), s.t. (cid:13) (cid:13)ϑ(i) (cid:13) θ(i)(cid:13) (cid:13) (cid:13)2 ϵ, mi(cid:88) j=1 w(i) = 1, (cid:88) i[n] mi 2K, (8) where is the maximum number of increased points. According to Theorem 2, the maximal loss reduction achieved by splitting the i-th Gaussian is given by (i) λmin(S(i)(θ))/2. Therefore, the optimal point selection maximizing loss Tank & Temple Train 22.091 21.974 Truck Dr. Johnson 25.394 25.395 29.209 29. 3DGS SteepGS Deep Blending mip-NeRF 360 Outdoor mip-NeRF 360 Indoor Playroom Bicycle Garden 27.417 25.253 27.159 24.890 30.172 30. Stump Bonsai Counter Kitchen 31.628 26.705 31.030 26.115 32.298 31.911 29.006 28.737 Room 31.540 31.401 Tank & Temple Truck Train 0.882 0.813 0.879 0.802 3DGS SteepGS Table 2. Breakdown table for per-scene PNSR of 3DGS and our SteepGS. Deep Blending mip-NeRF 360 Outdoor mip-NeRF 360 Indoor Dr. Johnson 0.901 0.902 Playroom Bicycle Garden 0.867 0.766 0.851 0. 0.907 0.909 Stump Bonsai Counter Kitchen Room 0.919 0.942 0.908 0.915 0.900 0.742 0.773 0.938 0.928 0.922 Table 3. Breakdown table for per-scene SSIM of 3DGS and our SteepGS. descent can be done by efficiently choosing Gaussians with least-K values of λmin(S(i)) once the total number of Gaussians with negative λmin(S(i)) surpasses K, i.e. {i [n] : λmin(S(i)) < 0} > K. Compactest Splitting Strategy. There also exists theoretically most compact splitting strategy. Theorem 1 suggests that the optimal displacement µ corresponds to the standard negative gradient L(θ), which yields typical O(ϵ) decrease in loss at non-stationary points. In contrast, splitting introduces summation of splitting characteristic functions, each governed by its associated splitting matrix, resulting in cumulative effect of order O(ϵ2). This theoretical insight leads to an important implication: Gaussian should be split only when its gradient is small. Otherwise, splitting introduces redundant Gaussians that offer little improvement in loss. The compactest splitting condition can be formulated as below: G(i) εgrad and λmin(S(i)) < εsplit, [n], where εgrad > 0 is chosen hyper-parameter. While this conclusion may appear to contradict the original ADC strategy, we argue that ADC actually examines the variance of the gradient by estimating E[G(i)], rather than the norm of its expectation, i.e. E[G(i)]. Thus, our condition does not contradict the original approach, but rather complements it by offering more principled criterion. A.3. Eigendecomposition In our experiments, we only take position parameters into the consideration for steepest splitting descent. This simplifies the eigendecomposition of splitting matrices to be restricted to symmetric 3 3 matrices. We can follow the method by [29] to compute the eigenvalues. The characteristic equation of symmetric 3 3 matrix is: det(αI A) = α3 α2 tr(A) α 1 2 An affine change to will simplify the expression considerably, and lead directly to trigonometric solution. If = pB + qI, then and have the same eigenvectors, and β is an eigenvalue of if and only if α = pβ + is an eigenvalue of A. Let = tr(A) some algebraic simplification using the identity cos 3θ = 4 cos3 θ 3 cos θ, we can obtain cos 3θ = det(B) of characteristic equation are given by: , we derive det(βI B) = β3 3β det(B) = 0. Substitute β = 2 cos θ and (cid:0)tr(A2) tr2(A)(cid:1) det(A) = 0. (cid:16) (AqI)2 . Thus, the roots and = (cid:17)(cid:17)1/2 tr (cid:16) 2 β = 2 cos (cid:18) 1 3 arccos (cid:19) (cid:18) det(B) + 2kπ 3 (cid:19) , = 0, 1, 2. When is real and symmetric, det(B) is also real and no greater than 2 in absolute value. B. More Experiment Results Metrics Breakdown. Tables 2, 3, 4 and 5 provide breakdown numerical evaluations of PSNR, SSIM, LPIPS, and the number of points for both our method and the original adaptive density control. The results demonstrate that our method achieves performance comparable to the original densification across all scenes. Notably, in the Playroom and Dr. Johnson scenes, our method outperforms the original adaptive density control while utilizing only half the number of points. Tank & Temple Truck Train 0.147 0.207 0.160 0.230 3DGS SteepGS Deep Blending mip-NeRF 360 Outdoor mip-NeRF 360 Indoor Dr. Johnson 0.244 0.251 Playroom Bicycle Garden 0.107 0.210 0.142 0.268 0.244 0.250 Stump Bonsai Counter Kitchen Room 0.219 0.200 0.215 0.233 0.217 0.271 0.203 0. 0.126 0.137 Table 4. Breakdown table for per-scene LPIPS of 3DGS and our SteepGS. Tank & Temple Truck Train 2572172 1088197 1387065 530476 3DGS SteepGS Deep Blending Dr. Johnson 3316036 Playroom Bicycle 6074705 2320830 2900640 1107604 mip-NeRF 360 Outdoor Garden 5845401 2195185 Stump 4863462 3175021 mip-NeRF 360 Indoor Bonsai 1260017 746163 Counter 1195896 Kitchen 1807771 922717 Room 1550152 710212 Table 5. Breakdown table for the number of points densified by 3DGS and our SteepGS. 3DGS Ours Ours (more steps) Bicycle Garden 27.42 25.25 27.16 24.89 27.38 25.23 Stump 26.70 26.11 26. Figure 6. Improved visual quality of our method after more steps of Gaussian splitting. Table 6. Improved performance of our method evaluated in PSNR after more steps of Gaussian splitting. More Visualizations. Fig. 7 visualizes the points selected for densification in four scenes. It can be observed that our method selects fewer points by concentrating on regions with blurry under-reconstructed areas. In contrast, the original adaptive density control performs more densifications on high-frequency details, which is less likely to effectively enhance rendering quality. These findings validate that our method conserves computational resources by directing densification toward areas that result in the steepest descent in rendering loss. More Metrics and Compared Methods. In addition to the compared methods in the main text, we test two more baselines: Compact-3DGS [16] and LP-3DGS [45]. We also include elapsed time on GPU for training, mean and peak GPU memory usage for training, and rendering FPS4 as additional metrics. Table 7 presents the comparison results evaluated on MipNeRF360, Temple&Tanks, and Deep Blending datasets. Although Compact-3DGS and LP-3DGS yield fewer points in the final results, our method achieves better metrics in PSNR and significantly reduces training time on GPUs. Moreover, our method consistently decreases GPU memory usage and improves rendering FPS compared to the original 3DGS ADC, performing on par with the two newly compared methods. Improved Performance. Readers might feel curious if our method could achieve even more closer performance to that of the original 3DGS ADC. In our main experiments, to ensure fair comparisons, we reuse the hyper-parameters of ADC. However, we found that extending the densification iterations to 25K and the total training steps to 40K on some MipNeRF360 scenes allows our method to achieve better performance and further mitigates the blurriness observed in the rendered images. As reference, Table 6 demonstrates performance improvements with more densification iterations. Figure 6 shows reduced blurriness in the stump scene. 4We observed that measuring FPS can be inconsistent, and the values reported in the table should be considered as reference. Figure 7. More visualizations of splitting points. We compare the number of points split by our proposed method and the original ADC. C. Theory C.1. Notations and Setup To begin with, we re-introduce our notations and the problem setup more rigorously. We abstract each Gaussian as function σΠ(x; θ(i)) : Θ where θ(i) Θ are parameters encapsulating mean, covariance, density, SH coefficients, (Π, x) denote the camera transformations and the 2D-pixel coordinates respectively, and output includes density and RGB color in space O. Further on, we assign the input space probability measure D(X ). We combine α-blending and the photometric loss as single function ℓ() : P(O) (cid:55) R, where P(O) denotes the entire output space, i.e., all multisets whose elements are in the output space O. Suppose the scene has Gaussians, then we denote the all parameters as θ = {θ(i)}n for shorthand and the total loss function can be expressed as: i=1 L(θ) = EΠ,xD(X )[ℓ(σΠ(x; θ(1)), , σΠ(x; θ(n)))]. (9) Now our goal is to split each Gaussian into mi off-springs. We denote the parameters of the i-th Gaussians off-springs as j=1, where ϑ(i) ϑ(i) = {ϑ(i) is the j-th off-spring of the i-th Gaussian and assign it group of reweighting coefficients j=1 to over-parameterize the original Gaussian as: (cid:80)mi w(i) = {w(i) = 1 for every [n] We collect parameters of all the new Gaussians as ϑ = {ϑ(i)}n i=1, for ) such that (cid:80)mi j=1 w(i) i=1, and reweighting coefficients as = {w(i)}n σΠ(x; ϑ(i) }mi }mi j=1 w(i) MipNeRF360 # Points PSNR SSIM LPIPS GPU elapse mean GPU mem. peak GPU mem. FPS 3DGS 3.339 29.037 0.872 LP-3DGS 1.303 28. Compact-3DGS 1.310 28.504 0.865 0.856 SteepGS (Ours) 1.606 28. 0.857 0.183 0.198 0.208 0.211 1550.925 10.262 GB 1177.648 10.027 GB 4063.203 1051.276 7.274 GB 7.597 GB 12.110 GB 12.458 GB 9.044 GB 8.957 GB 350 98 252 Tank & Temple # Points PSNR SSIM LPIPS GPU elapse mean GPU mem. peak GPU mem. FPS 3DGS 1.830 23.743 0. LP-3DGS 0.671 23.424 Compact-3DGS 0.836 23.319 0.839 0. SteepGS (Ours) 0.958 23.684 0.840 0.177 0.197 0. 0.194 803.542 1021.806 1255.748 539.048 Deep Blending 5.193 GB 5.045 GB 3.802 GB 4.701 GB 6.241 GB 6.489 GB 4.774 GB 5.607 GB 248 150 357 # Points PSNR SSIM LPIPS GPU elapse mean GPU mem. peak GPU mem. FPS 3DGS 2.818 29.690 0.904 LP-3DGS 0.861 29.764 Compact-3DGS 1.054 29. 0.906 0.905 SteepGS (Ours) 1.296 29.963 0.905 0. 0.249 0.255 0.250 1429.878 1697.793 1861.897 956.536 8.668 GB 8.354 GB 6.332 GB 5.928 GB 10.218 GB 10.115 GB 8.026 GB 9.506 GB 187 134 280 Table 7. Comparison with LP-3DGS [45] and Compact-3DGS [16] baselines on MipNeRF360, Tank & Temple, and Deep Blending datasets. Additional metrics: GPU elapsed time for training, mean & peak GPU memory usage, and FPS are included. shorthand. With newly added Gaussians, the augmented loss function becomes: L(ϑ, w) = EΠ,xD(X ) ℓ m1(cid:88) j=1 σΠ(x; ϑ(1) w(1) ), , σΠ(x; ϑ(n) w(n) ) . mn(cid:88) j=1 (10) C.2. Main Results Proof of Theorem 1. We define µ(i) as the average displacement on θ(i): µ(i) = ((cid:80)mi (ϑ(i) θ(i))/ϵ µ(i) as offset additional to µ(i) for the j-th off-spring. It is obvious that: j=1 w(i) ϑ(i) θ(i))/ϵ and δ(i) = mi(cid:88) j=1 δ(i) w(i) = w(i) (cid:32) ϑ(i) θ(i) ϵ mi(cid:88) j=1 (cid:33) µ(i) = 1 ϵ mi(cid:88) j=1 ϑ(i) w(i) 1 ϵ mi(cid:88) j=1 w(i) θ(i) mi(cid:88) j=1 w(i) µ(i) = 1 ϵ mi(cid:88) j=1 ϑ(i) w(i) 1 ϵ θ(i) µ(i) = 0. (11) In addition, we let (i) auxiliary function: L(θ(i), ϑ(i), w(i)) as: = µ(i) + δ(i) , and ϑ(i) can be written as: ϑ(i) = θ(i) + ϵ(i) = θ(i) + ϵ(µ(i) + δ(i) ). We define an L(θ(i), ϑ(i), w(i)) = EΠ,xD(X ) ℓ σΠ(x; θ(1)), , mi(cid:88) j=1 σΠ(x; ϑ(i) w(i) ), , σΠ(x; θ(n)) , (12) which only splits the i-th Gaussian θ(i) as ϑ(i). By Lemma 6, we have that: (L(ϑ, w) L(θ)) = (cid:88) (cid:16) i=1 L(θ(i), ϑ(i), w(i)) L(θ) (cid:17) + ϵ2 2 (cid:88) i,i[n] i=i µ(i)2 θ(i)θ(i )L(θ)µ(i) + O(ϵ3). (13) By Lemma 7, we have: L(θ(i), ϑ(i), w(i)) L(θ) = ϵθ(i)L(θ)µ(i) + ϵ2 2 µ(i)2 θ(i)θ(i)L(θ)µ(i) + ϵ2 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) + O(ϵ3). (14) (15) Let µ = (cid:2)µ(1) conclude: µ(n)(cid:3) concatenate the average displacement on all Gaussians. Combining Eq. 13 and Eq. 14, we can (L(ϑ, w) L(θ)) = (cid:88) ϵθ(i)L(θ)µ(i) + ϵ2 2 µ(i)2 θ(i)θ(i) L(θ)µ(i) + ϵ2 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) i=1 ϵ2 2 + (cid:88) i,i[n] i=i µ(i)2 θ(i)θ(i )L(θ)µ(i) + O(ϵ3) = ϵ (cid:88) i=1 θ(i)L(θ)µ(i) + ϵ2 2 (cid:88) i,i[n] µ(i)2 θ(i)θ(i) L(θ)µ(i) + ϵ2 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) + O(ϵ3) = ϵθL(θ)µ + ϵ2 µ2L(θ)µ + ϵ2 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) + O(ϵ3), as desired. Proof of Theorem 2. By standard variational characterization, we have the following lower bound: (i)(δ(i), w(i); θ) := ϵ2 2 mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) ϵ2 2 mi(cid:88) j=1 w(i) λmin(S(i)(θ)) = ϵ2 2 λmin(S(i)(θ)), subject to δ(i) 1. The equality holds only if δ(i) equals to the smallest eigenvector of S(i)(θ). Hence, there is no decrease on the loss if λmin(S(i)(θ)) 0. Otherwise, we can simply choose mi = 2, w(i) 1 = vmin(S(i)(θ)), and δ(i) δ(i) 2 = vmin(S(i)(θ)) to achieve this lower bound. C.3. Auxiliary Results 1 = w(i) 2 = 1/2, Lemma 3. The following equalities hold for L(θ) for every [n] θ(i) L(θ) = EΠ,xD(X ) (cid:104) σ(i)ℓ θ(i)θ(i) L(θ) = (i)(θ) + S(i)(θ), 2 θ(i)θ(i ) L(θ) = EΠ,xD(X ) 2 (cid:104) 2 σ(i)σ(i )ℓ (cid:16) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:105) σΠ(x; θ(i)) , (cid:16) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) , [n], = i, where (i)(θ) = EΠ,xD(X ) (cid:104) 2 σ(i)σ(i) ℓ (cid:16) σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) . Proof. The gradient of L(θ) is proved via simple chain rule. And then 2 θ(i)θ(i) L(θ) = θ(i ) [θ(i) L(θ)] (cid:104) = EΠ,xD(X ) 2 σ(i)σ(i) ℓ (cid:16) (cid:104) (cid:16) + EΠ,xD(X ) σ(i)ℓ σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) (cid:105) θ(i )σΠ(x; θ(i)) . When = i, θ(i )σΠ(x; θ(i)) = 2σΠ(x; θ(i)), henceforth: θ(i)θ(i) L(θ) = (i)(θ) + S(i)(θ). Otherwise, θ(i) σΠ(x; θ(i)) = 0, and thus: θ(i)θ(i) L(θ) = EΠ,xD(X ) 2 (cid:104) 2 σ(i)σ(i )ℓ (cid:16) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) , all as desired. Lemma 4. The following equalities hold for L(ϑ, w) at ϵ = 0: ϑ(i) 2 ϑ(i) ϑ(i) 2 ϑ(i) ϑ(i) 2 ,ϑ(i ) ϑ(i) (cid:12) (cid:12) L(ϑ, w) (cid:12)ϵ=0 (cid:12) (cid:12) L(ϑ, w) (cid:12) (cid:12)ϵ=0 (cid:12) (cid:12) L(ϑ, w) (cid:12) (cid:12)ϵ=0 (cid:12) (cid:12) L(ϑ, w) (cid:12) (cid:12)ϵ=0 = w(i) θ(i)L(θ), [n], [mi], = w(i) S(i)(θ) + w(i) (i)(θ), [n], [mi], = w(i) w(i) (i)(θ), [n], j, [mi], = j, = w(i) w(i) 2 θ(i)θ(i )L(θ), i, [n], = i, [mi], [mi], (16) (17) (18) (19) (cid:104) 2 σ(i)σ(i) ℓ (cid:16) σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) is as defined in where (i)(θ) = EΠ,xD(X ) Lemma 3. Proof. Let (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi j=1 w(i) σΠ(x; ϑ(i) ) and we can express L(ϑ, w) as: L(ϑ, w) = EΠ,xD(X ) (cid:16) (cid:104) ℓ (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17)(cid:105) . (20) To take derivatives of L(ϑ, w), we leverage the chain rule. For every [n], [mi]: ϑ(i) L(ϑ, w) = ϑ(i) (cid:16) (cid:104) ℓ EΠ,xD(X ) (cid:104) = EΠ,xD(X ) = EΠ,xD(X ) (cid:104) ϑ(i) ℓ (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:16) (cid:16) (cid:17)(cid:105) (cid:17)(cid:105) σ(i)ℓ (cid:104) σ(i) ℓ (cid:105) (cid:101)σΠ(x; ϑ(i)) ϑ(i) (cid:105) (cid:17) (cid:16) σΠ(x; ϑ(i) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) ) = w(i) EΠ,xD(X ) . (21) Since ϵ = 0, we have ϑ(i) 21 as: = θ(i) and (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi j=1 w(i) σΠ(x; θ(i)) = σΠ(x; θ). Hence, we can further simplify Eq. ϑ(i) L(ϑ, w) (cid:12) (cid:12) (cid:12)ϵ=0 = w(i) EΠ,xD(X ) (cid:104) σ(i)ℓ (cid:16) EΠ,xD(X ) (cid:104) σ(i) ℓ (cid:16) = w(i) = w(i) θ(i) L(θ), (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) σΠ(x; ϑ(i) ) (cid:105) σΠ(x; θ(i)) (cid:17) (cid:105)(cid:12) (cid:12) (cid:12)ϵ=0 where the last step is due to Lemma 3. Next we derive second-order derivatives. Taking derivatives of Eq. 21 in terms of ϑ(i) for some [n], [mi], and by chain rule: 2 ϑ(i) ϑ(i) L(ϑ, w) = w(i) EΠ,xD(X ) ϑ(i ) (cid:104) σ(i)ℓ (cid:16) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) σΠ(x; ϑ(i) ) (cid:105) = w(i) EΠ,xD(X ) + w(i) EΠ,xD(X ) (cid:20) 2 σ(i)σ(i ) ℓ (cid:20) σ(i)ℓ (cid:16) (cid:16) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:21) (cid:101)σΠ(x; ϑ(i)) ϑ(i) (cid:21) σΠ(x; ϑ(i) ) σΠ(x; ϑ(i) ) ϑ(i ) (cid:17) = w(i) w(i) EΠ,xD(X ) (cid:20) σ(i)ℓ EΠ,xD(X ) (cid:104) 2 σ(i)σ(i )ℓ (cid:16) + w(i) (cid:16) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) ϑ(i ) σΠ(x; ϑ(i) ) (cid:21) . Now we discuss three scenarios: 1. When = and = j, ϑ(i) σΠ(x; ϑ(i) ) = 2σΠ(x; ϑ(i) ), and then 2 ϑ(i) ϑ(i) L(ϑ, w) = w(i)2 EΠ,xD(X ) (cid:104) + w(i) EΠ,xD(X ) 2 σ(i)σ(i) ℓ (cid:16) (cid:104) σ(i) ℓ (cid:16) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:105) 2σΠ(x; ϑ(i) ) σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (22) 2. When = and = j, ϑ(i) σΠ(x; ϑ(i) ) = 0, and thus 2 ϑ(i) ϑ(i) L(ϑ, w) = w(i) w(i) EΠ,xD(X ) (cid:104) 2 σ(i)σ(i)ℓ (cid:16) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) 3. When = i, ϑ(i ) σΠ(x; ϑ(i) ) = 0, and henceforth σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (23) 2 ϑ(i ) ϑ(i) L(ϑ, w) = w(i) w(i) EΠ,xD(X ) (cid:104) 2 σ(i)σ(i) ℓ (cid:16) (cid:101)σΠ(x; ϑ(1)), , (cid:101)σΠ(x; ϑ(n)) (cid:17) σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (24) Using this fact again: ϑ(i) 2 ϑ(i) ϑ(i) L(ϑ, w) (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 = θ(i) and (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi j=1 w(i) (cid:16) = w(i)2 EΠ,xD(X ) (cid:104) 2 σ(i)σ(i)ℓ (cid:16) (cid:104) σ(i)ℓ S(i)(θ), + w(i) = w(i)2 EΠ,xD(X ) (i)(θ) + w(i) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) σΠ(x; θ(i)) = σΠ(x; θ(i)) when ϵ = 0, Eq. 22 becomes: σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) (cid:105) 2σΠ(x; θ(i)) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) Eq. 23 can be simplified as: 2 ϑ(i) ϑ(i) (cid:12) (cid:12) L(ϑ, w) (cid:12) (cid:12)ϵ=0 = w(i) w(i) EΠ,xD(X ) (i)(θ), = w(i) w(i) and by Lemma 3, Eq. 24 turns into: (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 2 ϑ(i ) ϑ(i) j w(i) L(ϑ, w) = w(i) EΠ,xD(X ) (cid:104) 2 σ(i)σ(i) ℓ (cid:16) σΠ(x; θ(1)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) (cid:104) 2 σ(i)σ(i ) ℓ (cid:16) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(n)) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) = w(i) w(i) j ϑ(i ) ϑ(i) L(θ), all as desired. Lemma 5. The following equalities hold for L(θ(i), ϑ(i), w(i)) at ϵ = 0 for any [n]: ϑ(i) 2 ϑ(i) ϑ(i) 2 ϑ(i) ϑ(i) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ= = w(i) θ(i) L(θ), [mi], = w(i) S(i)(θ) + w(i)2 (i)(θ), [mi], = w(i) w(i) (i)(θ), j, [mi], = j, (cid:104) where (i)(θ) = EΠ,xD(X ) Lemma 3. Proof. The proof is identical to Lemma 4. We outline the details for completeness. Let (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi and we can express L(θ(i), ϑ(i), w(i)) as: σΠ(x; θ(1)), , σΠ(x; θ(n)) 2 σ(i)σ(i) ℓ σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) (cid:17) (cid:16) (25) (26) (27) is as defined in j=1 w(i) σΠ(x; ϑ(i) ) L(θ(i), ϑ(i), w(i)) = EΠ,xD(X ) (cid:16) (cid:104) ℓ σΠ(x; θ(1)), , (cid:101)σΠ(x; ϑ(i)), , σΠ(x; θ(n)) (cid:17)(cid:105) . (28) By chain rule, for every [mi]: (cid:104) (cid:16) ϑ(i) L(θ(i), ϑ(i), w(i)) = ϑ(i) = EΠ,xD(X ) (cid:104) = w(i) EΠ,xD(X ) ℓ EΠ,xD(X ) σΠ(x; θ(1)), , (cid:101)σΠ(x; ϑ(i)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(1)), , (cid:101)σΠ(x; ϑ(i)), , σΠ(x; θ(n)) (cid:101)σΠ(x; ϑ(i)) ϑ(i) (cid:105) (cid:17) (cid:16) σΠ(x; ϑ(i) σΠ(x; θ(1)), , (cid:101)σΠ(x; ϑ(i)), , σΠ(x; θ(n)) ) (cid:105) (cid:16) σ(i)ℓ (cid:104) σ(i) ℓ (cid:17)(cid:105) . (29) Using the fact that ϑ(i) as: = θ(i) and (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi j=1 w(i) σΠ(x; θ(i)) = σΠ(x; θ(i)) when ϵ = 0, Eq. 29 can be rewritten L(θ(i), ϑ(i), w(i)) ϑ(i) (cid:12) (cid:12) (cid:12)ϵ= = w(i) EΠ,xD(X ) (cid:104) σ(i)ℓ (cid:16) σΠ(x; θ(1)), , (cid:101)σΠ(x; ϑ(i)), , σΠ(x; θ(n)) (cid:17) σΠ(x; θ(1)), , σΠ(x; θ(i)), , σΠ(x; θ(n)) σΠ(x; ϑ(i) ) (cid:105) σΠ(x; θ(i)) (cid:17) (cid:105)(cid:12) (cid:12) (cid:12)ϵ=0 EΠ,xD(X ) (cid:104) σ(i) ℓ (cid:16) = w(i) = w(i) θ(i) L(θ), where the last step is due to Lemma 3. Next we derive second-order derivatives. Taking derivatives of Eq. 29 in terms of ϑ(i) for some [mi], and by chain rule: 2 ϑ(i) ϑ(i) w(i) EΠ,xD(X ) (cid:104) σ(i)ℓ (cid:16) , (cid:101)σΠ(x; ϑ(i)), (cid:17) (cid:105) σΠ(x; ϑ(i) ) EΠ,xD(X ) L(θ(i), ϑ(i), w(i)) = ϑ(i) (cid:20) 2 σ(i)σ(i) ℓ (cid:20) σ(i) ℓ EΠ,xD(X ) (cid:16) (cid:16) = w(i) + w(i) = w(i) w(i) + w(i) EΠ,xD(X ) (cid:20) σ(i) ℓ EΠ,xD(X ) (cid:104) 2 σ(i)σ(i)ℓ (cid:16) (cid:16) (cid:17) , (cid:101)σΠ(x; ϑ(i)), (cid:17) , (cid:101)σΠ(x; ϑ(i)), σΠ(x; ϑ(i) (cid:101)σΠ(x; ϑ(i)) )ϑ(i) (cid:21) σΠ(x; ϑ(i) ) (cid:21) , (cid:101)σΠ(x; ϑ(i)), σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) ϑ(i) (cid:17) , (cid:101)σΠ(x; ϑ(i)), (cid:17) ϑ(i) (cid:21) σΠ(x; ϑ(i) ) . Now we consider two scenarios: 1. When = j, ϑ(i) σΠ(x; ϑ(i) ) = 2σΠ(x; ϑ(i) ), and then 2 ϑ(i) ϑ(i) (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 = w(i)2 EΠ,xD(X ) (cid:104) + w(i) EΠ,xD(X ) (cid:16) 2 σ(i)σ(i) ℓ (cid:16) (cid:104) σ(i)ℓ , (cid:101)σΠ(x; ϑ(i)), (cid:17) , (cid:101)σΠ(x; ϑ(i)), (cid:17) σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (cid:105) 2σΠ(x; ϑ(i) ) (30) 2. When = j, ϑ(i) σΠ(x; ϑ(i) ) = 0, and thus 2 ϑ(i) ϑ(i) (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 = w(i) w(i) EΠ,xD(X ) (cid:104) 2 σ(i)σ(i) ℓ (cid:16) , (cid:101)σΠ(x; ϑ(i)), (cid:17) σΠ(x; ϑ(i) )σΠ(x; ϑ(i) )(cid:105) (31) Using this fact again: ϑ(i) = θ(i) and (cid:101)σΠ(x; ϑ(i)) = (cid:80)mi j=1 w(i) 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i)) = w(i)2 EΠ,xD(X ) (cid:104) + w(i) = w(i) EΠ,xD(X ) (i)(θ) + w(i) 2 σ(i)σ(i) ℓ (cid:16) (cid:104) σ(i) ℓ S(i)(θ), (cid:16) σΠ(x; θ(i)) = σΠ(x; θ(i)) when ϵ = 0, Eq. 30 becomes: σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) (cid:105) 2σΠ(x; θ(i)) , σΠ(x; θ(i)), (cid:17) , σΠ(x; θ(i)), (cid:17) and Eq. 31 can be simplified as: 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i)) = w(i) w(i) EΠ,xD(X ) (cid:104) 2 σ(i)σ(i)ℓ (cid:16) , σΠ(x; θ(i)), (cid:17) σΠ(x; θ(i))σΠ(x; θ(i))(cid:105) = w(i) w(i) (i)(θ), both as desired. Lemma 6. Assume L(ϑ, w) has bounded third-order derivatives with respect to ϑ, then we have (L(ϑ, w) L(θ)) = (cid:88) (cid:16) i= L(θ(i), ϑ(i), w(i)) L(θ) (cid:17) + ϵ2 2 (cid:88) i,i[n] i=i µ(i)2 θ(i)θ(i )L(θ)µ(i) + O(ϵ3), where L(θ(i), ϑ(i), w(i)) and µ(i) are as defined in Theorem 1. Proof. Define an auxiliary function: (ϵ) = (L(ϑ, w) L(θ)) (cid:16) (cid:17) L(θ(i), ϑ(i), w(i)) L(θ) . (cid:88) i=1 Note that (ϵ) also has bounded third-order derivatives. Hence, by Taylor expansion: (ϵ) = (0) + ϵ dϵ (0) + ϵ2 2 d2 dϵ2 (0) + O(ϵ3). Compute the first-order derivatives of via path derivatives, we can derive dϵ (L(ϑ, w) L(θ)) = (cid:88) mi(cid:88) i=1 j=1 L(ϑ, w) dϑ(i) dϵ = ϑ(i) (cid:88) mi(cid:88) i=1 j=1 ϑ(i) L(ϑ, w)(i) , and for every [n]: (32) (33) (cid:16) (cid:17) L(θ(i), ϑ(i), w(i)) L(θ) = dϵ = mi(cid:88) j=1 mi(cid:88) j=1 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i)) dϑ(i) dϵ L(θ(i), ϑ(i), w(i))(i) , (34) By Lemma 4 and Lemma 5, ϑ(i) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 = ϑ(i) L(ϑ, w) (cid:12) (cid:12) (cid:12)ϵ=0 , hence combining Eq. 33 and 34: dϵ (0) = (cid:88) mi(cid:88) i=1 j=1 ϑ(i) L(ϑ, w)(i) (cid:88) mi(cid:88) i= j=1 ϑ(i) L(θ(i), ϑ(i), w(i))(i) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 = 0. (35) We can also compute the second-order derivatives via path derivatives: d2 dϵ2 (L(ϑ, w) L(θ)) = dϵ (cid:88) mi(cid:88) i=1 j=1 ϑ(i) L(ϑ, w)(i) = = (cid:88) (cid:88) mi(cid:88) mi (cid:88) i= i=1 j=1 (cid:88) (cid:88) mi(cid:88) j=1 mi (cid:88) i=1 i=1 j=1 j=1 (i) 2 ϑ(i ) ϑ(i) L(ϑ, w) dϑ(i) dϵ (i) 2 ϑ(i ) ϑ(i) L(ϑ, w)(i) , (36) and similarly for every [n], (cid:16) (cid:17) L(θ(i), ϑ(i), w(i)) L(θ) = d2 dϵ dϵ mi(cid:88) j=1 ϑ(i) L(θ(i), ϑ(i), w(i))(i) = = mi(cid:88) mi(cid:88) j=1 mi(cid:88) j=1 mi(cid:88) j=1 j=1 (i) 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i)) dϑ(i) dϵ (i) 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i))(i) . (37) By Lemma 4 and Lemma 5, 2 ϑ(i) we can cancel all terms in Eq. 37 by: ϑ(i) (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ= = 2 ϑ(i) ϑ(i) (cid:12) (cid:12) L(ϑ, w) (cid:12) (cid:12)ϵ=0 for any [n] and j, [mi], hence d2 dϵ2 (0) = (cid:88) mi(cid:88) mi (cid:88) i,i[n] j=1 j=1 (i) 2 ϑ(i ) ϑ(i) L(ϑ, w)(i) n (cid:88) mi(cid:88) mi(cid:88) i=1 j=1 j= (i) 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i))(i) mi(cid:88) mi (cid:88) j=1 j=1 (cid:18) (i) 2 ϑ(i) ϑ(i) L(ϑ, w) 2 ϑ(i) ϑ(i) L(θ(i), ϑ(i), w(i)) (cid:19) (i) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 = (cid:88) i=1 (cid:88) + i=i mi(cid:88) (cid:88) = mi (cid:88) i=i j=1 (cid:88) mi(cid:88) j=1 mi (cid:88) i=i j=1 j=1 = mi(cid:88) mi (cid:88) j=1 j=1 (i) 2 ϑ(i ) ϑ(i) L(ϑ, w)(i) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 w(i) w(i) (i) 2 ϑ(i ) ϑ(i) L(θ)(i) µ(i)2 ϑ(i ) ϑ(i) L(θ)µ(i), (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)ϵ=0 (38) where we use Eq. 19 in Lemma 4 for the last second equality, and we use the fact: (cid:80)mi equality. Merging Eq. 32, 35, 38, we obtain the result as desired. j=1 w(i) (i) = µ(i) to get the last Lemma 7. Assume L(ϑ, w) has bounded third-order derivatives with respect to ϑ, then we have L(θ(i), ϑ(i), w(i)) L(θ) = ϵθ(i)L(θ)µ(i) + ϵ2 µ(i)2 θ(i)θ(i)L(θ)µ(i) + ϵ2 2 mi(cid:88) j= δ(i) w(i) S(i)(θ)δ(i) + O(ϵ3). (i) (i) Proof. Let θ identical to the original one, or namely we let ϵ = 0. If we replace ϑ(i) with θ = mi. This is we split the i-th Gaussian into mi off-springs with parameters , it holds that: = {θ(i), , θ(i)} such that θ (i) L(θ(i), θ (i) , w(i)) = EΠ,xD(X ) ℓ σΠ(x; θ(1)), , mi(cid:88) j=1 w(i) σΠ(x; θ(i)), , σΠ(x; θ(n)) = EΠ,xD(X ) (cid:16) (cid:104) ℓ σΠ(x; θ(1)), , σΠ(x; θ(i)), , σΠ(x; θ(n)) (cid:17)(cid:105) = L(θ), and By Taylor expansion, L(θ(i), θ (i) ϑ(i) , w(i)) = ϑ(i) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ=0 . L(θ(i), ϑ(i), w(i)) L(θ) = L(θ(i), ϑ(i), w(i)) L(θ(i), θ (i) , w(i)) = mi(cid:88) j=1 (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12) ϵ=0 (ϑ(i) θ(i)) (cid:88) + (ϑ(i) θ(i)) ϑ(i) ϑ(i) j,j[mi] By Lemma 5 and 3: L(θ(i), ϑ(i), w(i)) L(θ) (cid:12) (cid:12) L(θ(i), ϑ(i), w(i)) (cid:12) (cid:12)ϵ= (ϑ(i) θ(i)) + O(ϵ3). mi(cid:88) = ϵ j=1 ϵ2 2 + mi(cid:88) = ϵ j=1 ϵ2 2 + θ(i) L(θ)(i) w(i) + ϵ2 2 mi(cid:88) j=1 (i) (cid:16) S(i)(θ) + w(i)2 w(i) (cid:17) (i)(θ) (i) (cid:88) j,j[mi],j=j w(i) w(i) (i) (i)(θ)(i) + O(ϵ3) w(i) θ(i) L(θ)(i) + ϵ2 2 mi(cid:88) j=1 (i) w(i) S(i)(θ)(i) (cid:88) j,j[mi] w(i) w(i) (i) (i)(θ)(i) + O(ϵ3) mi(cid:88) j= (i) w(i) S(i)(θ)(i) + µ(i) (i)(θ)µ(i) + O(ϵ3) µ(i) (cid:16) S(i)(θ) + (i)(θ) (cid:17) µ(i) ϵ2 2 ϵ2 2 w(i) (cid:16) (i) S(i)(θ)(i) µ(i)S(i)(θ)µ(i)(cid:17) + O(ϵ3) = ϵθ(i) L(θ)µ(i) + = ϵθ(i) L(θ)µ(i) + mi(cid:88) + ϵ2 2 j=1 = ϵθ(i) L(θ)µ(i) + ϵ2 2 µ(i) θ(i)θ(i) L(θ)µ(i) + ϵ2 2 mi(cid:88) j=1 w(i) (cid:16) (i) S(i)(θ)(i) µ(i)S(i)(θ)µ(i)(cid:17) + O(ϵ3). Finally, we conclude the proof by showing that: (cid:16) w(i) mi(cid:88) j=1 (i) S(i)(θ)(i) µ(i)S(i)(θ)µ(i)(cid:17) = = mi(cid:88) j=1 mi(cid:88) j=1 (i) w(i) S(i)(θ)(i) + µ(i)S(i)(θ)µ(i) 2 mi(cid:88) (i) w(i) S(i)(θ)µ(i) (cid:16) w(i) ((i) µ(i))S(i)(θ)((i) µ(i)) j=1 (cid:17) = mi(cid:88) j=1 δ(i) w(i) S(i)(θ)δ(i) . C.4. Deriving Hessian of Gaussian In Sec. 4.4, we discussed that SteepGS requires the computation of Hessian matrices for σΠ(x; θ). We make the following simplifications: (i) We only consider position parameters as the optimization variable when computing the steepest descent directions. (ii) Although other variables may have dependency on the mean parameters, e.g. the projection matrix and view-dependent RGB colors, we break this dependency for ease of derivation. Now suppose we have 3D Gaussian point with parameters θ = (p, Σ, o), where we omit RGB colors as it can be handled similarly to opacity o. Given the affine transformation Π : (cid:55) + with R23 and R2, then σΠ(x; θ) can be expressed as: σΠ(x; θ) = exp (cid:18) 1 2 (x b)(P ΣP )1(x b) (cid:19) = (x; + b, ΣP ). Its gradient can be derived as: pσΠ(x; θ) = (x; + b, ΣP )p (cid:21) (x b)(P ΣP )1(x b) (cid:20) 1 2 = (x; + b, ΣP )P (P ΣP )1(x b). Now we can compute the Hessian matrix as: 2 pσΠ(x; θ) = (P ΣP )1(x + b)p (cid:104) (x; + b, ΣP ) (cid:105) (x; + b, ΣP )(P ΣP )1P = (x; + b, ΣP )P (P ΣP )1(x b)(x b)(P ΣP )1P (x; + b, ΣP )P (P ΣP )1P = σΠ(x; θ) (cid:16) (P ΣP )1(x b)(x b)(P ΣP )1P (P ΣP )1P (cid:17) as desired."
        }
    ],
    "affiliations": [
        "Meta Reality Labs",
        "The University of Texas at Austin"
    ]
}