{
    "paper_title": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows",
    "authors": [
        "Wanghan Xu",
        "Yuhao Zhou",
        "Yifan Zhou",
        "Qinglong Cao",
        "Shuo Li",
        "Jia Bu",
        "Bo Liu",
        "Yixin Chen",
        "Xuming He",
        "Xiangyu Zhao",
        "Xiang Zhuang",
        "Fengxiang Wang",
        "Zhiwang Zhou",
        "Qiantai Feng",
        "Wenxuan Huang",
        "Jiaqi Wei",
        "Hao Wu",
        "Yuejin Yang",
        "Guangshuai Wang",
        "Sheng Xu",
        "Ziyan Huang",
        "Xinyao Liu",
        "Jiyao Liu",
        "Cheng Tang",
        "Wei Li",
        "Ying Chen",
        "Junzhi Ning",
        "Pengfei Jiang",
        "Chenglong Ma",
        "Ye Du",
        "Changkai Ji",
        "Huihui Xu",
        "Ming Hu",
        "Jiangbin Zheng",
        "Xin Chen",
        "Yucheng Wu",
        "Feifei Jiang",
        "Xi Chen",
        "Xiangru Tang",
        "Yuchen Fu",
        "Yingzhou Lu",
        "Yuanyuan Zhang",
        "Lihao Sun",
        "Chengbo Li",
        "Jinzhe Ma",
        "Wanhao Liu",
        "Yating Liu",
        "Kuo-Cheng Wu",
        "Shengdu Chai",
        "Yizhou Wang",
        "Ouwen Zhangjin",
        "Chen Tang",
        "Shufei Zhang",
        "Wenbo Cao",
        "Junjie Ren",
        "Taoyong Cui",
        "Zhouheng Yao",
        "Juntao Deng",
        "Yijie Sun",
        "Feng Liu",
        "Wangxu Wei",
        "Jingyi Xu",
        "Zhangrui Li",
        "Junchao Gong",
        "Zijie Guo",
        "Zhiyu Yao",
        "Zaoyu Chen",
        "Tianhao Peng",
        "Fangchen Yu",
        "Bo Zhang",
        "Dongzhan Zhou",
        "Shixiang Tang",
        "Jiaheng Liu",
        "Fenghua Ling",
        "Yan Lu",
        "Yuchen Ren",
        "Ben Fei",
        "Zhen Zhao",
        "Xinyu Gu",
        "Rui Su",
        "Xiao-Ming Wu",
        "Weikang Si",
        "Yang Liu",
        "Hao Chen",
        "Xiangchao Yan",
        "Xue Yang",
        "Junchi Yan",
        "Jiamin Wu",
        "Qihao Zheng",
        "Chenhui Li",
        "Zhiqiang Gao",
        "Hao Kong",
        "Junjun He",
        "Mao Su",
        "Tianfan Fu",
        "Peng Ye",
        "Chunfeng Song",
        "Nanqing Dong",
        "Yuqiang Li",
        "Huazhu Fu",
        "Siqi Sun",
        "Lijing Cheng",
        "Jintai Lin",
        "Wanli Ouyang",
        "Bowen Zhou",
        "Wenlong Zhang",
        "Lei Bai"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (10--20%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish a foundation for AI systems that genuinely participate in scientific discovery."
        },
        {
            "title": "Start",
            "content": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows Shanghai Artificial Intelligence Laboratory Page https://InternScience.github.io/SGI-Page/ Code https://github.com/InternScience/SGI-Bench Data https://huggingface.co/collections/InternScience/sgi-bench Abstract: Despite advances in scientific AI, coherent framework for Scientific General Intelligence (SGI)the ability to autonomously conceive, investigate, and reason across scientific domainsremains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Sciences 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (1020%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish foundation for AI systems that genuinely participate in scientific discovery. 5 2 0 2 8 ] . [ 1 9 6 9 6 1 . 2 1 5 2 : r Figure 1 Scientific General Intelligence (SGI) We define SGI as an AI that can autonomously navigate the complete, iterative cycle of scientific inquiry with the versatility and proficiency of human scientist. The teaser illustrates the Practical Inquiry Models four quadrantsDeliberation (synthesis and critical evaluation of knowledge), Conception (idea generation), Action (experimental execution), and Perception (interpretation)and how SGI-Bench operationalizes them through four task categories and an agent-based evaluation paradigm, together providing principle-grounded, measurable framework for assessing scientific intelligence."
        },
        {
            "title": "Contents",
            "content": "1 Introduction 2 Scientific General Intelligence: Concept and Operational Definition 2.1 Task Definition in Scientific Workflow 2.1.1 Scientific Deep Research 2.1.2 Idea Generation 2.1.3 Dry/Wet Experiment 2.1.4 Experimental Reasoning 2.2 Multi-Dimensional Metrics 2.2.1 Metrics of Scientific Deep Research 2.2.2 Metrics of Idea Generation 2.2.3 Metrics of Dry/Wet Experiment 2.2.4 Metrics of Experimental Reasoning 2.3 Scientist-Aligned Data Construction 2.4 Data Distribution 3 SGIEvalAgent: Agentic Evaluation Framework"
        },
        {
            "title": "6.1 Fragmentation Across the Four Quadrants of SGI",
            "content": "2 4 6 7 7 10 11 14 15 15 16 17 19 19 20 21 22 22 23 24 25 25 25 25 28 30 31 33 35 37 37 38 39 40 40 41 41 41 42 42 42 43 44 6.2 Implications from Test-Time RL and Tool-Integrated Reasoning 6.3 Future Directions Toward Scientific General Intelligence 6.4 Limitations 7 Related Work 7.1 Benchmarks in Different Disciplines 7.2 Benchmarks for Different Scientific Tasks 8 Conclusion References Appendix A.1 Authors A.2 Disciplines and Research Directions Overview A.3 Cases A.3.1 Scientific Deep Research A.3.2 Idea Generation A.3.3 Dry Experiment A.3.4 Wet Experiment A.3.5 Experimental Reasoning A.4 Supplementary Evaluation Results 45 46 47 48 48 49 51 58 58 59 67 67 77 102 117 125 150 3 1. Introduction Large language models (LLMs) [1, 2, 3, 4, 5] are achieving and even exceeding human-level performance on diverse array of tasks, spanning multidisciplinary knowledge understanding, mathematical reasoning, and programming. This rapid progress has ignited vibrant debate: some view these models as early signals of artificial general intelligence (AGI) [6, 7], whereas others dismiss them as mere stochastic parrots [8], fundamentally constrained by their training data. As these models evolve, the frontier of AGI research is shifting towards the most complex and structured of human endeavors: scientific inquiry [9]. We argue that demonstrating genuine scientific general intelligence (SGI) represents critical leap toward AGI, serving as definitive testbed for advanced reasoning, planning, and knowledge creation capabilities. However, much like AGI, the concept of SGI remains frustratingly nebulous, often acting as moving goalpost that hinders clear evaluation and progress. This paper aims to provide comprehensive, quantifiable framework to cut through this ambiguity, starting with concrete definition grounded in established theory: \"SGI is an AI that can autonomously navigate the complete, iterative cycle of scientific inquiry with the versatility and proficiency of human scientist\" To operationalize this definition, we ground our approach in the Practical Inquiry Model [10, 11], theoretical framework that deconstructs the scientific process into cycle of four core cognitive activities. This model provides taxonomic map of scientific cognition through four distinct, interdependent quadrants (Figure 1): Deliberation (the search, synthesis, and critical evaluation of knowledge), Conception (the generation of ideas), Action (the practical implementation via experiments), and Perception (the awareness and interpretation of results). An AI exhibiting true SGI must possess robust capabilities across this entire spectrum. This four-quadrant framework provides conceptual taxonomy of scientific cognition and forms the foundation for an operational definition of SGIone that specifies what kinds of planning, knowledge creation and reasoning an AI must demonstrate to qualify as scientifically intelligent. Translating this operational definition into measurable criteria requires examining how current evaluations of AI intelligence align with, or deviate from, this framework. Identifying these gaps is essential for clarifying what existing assessments capture and what they overlook in defining Scientific General Intelligence. Grounded in this four-quadrant definition of SGI, we examine how existing benchmarks operationalize scientific reasoning. Most current evaluations capture only fragments of the SGI spectrum. For instance, MMLU [12] and SuperGPQA [13] focus on multidisciplinary knowledge understandingcorresponding mainly to the Deliberation quadrantwhile GAIA [14] emphasizes procedural tool use aligned with Action. HLE [15] further raises difficulty through complex reasoning, yet still isolates inquiry stages without integrating the practical or interpretive cycles that characterize real scientific investigation. Collectively, these benchmarks present fragmented view of scientific intelligence. Their disciplinary scope remains narrow, their challenges seldom reach expert-level reasoning, andmost cruciallythey frame inquiry as static, closed-domain question-answering task. This abstraction neglects the creative, procedural, and self-corrective dimensions central to SGI, meaning that what is currently measured as scientific ability reflects only limited slice of true Scientific General Intelligence. Thus, to concretize the proposed definition of Scientific General Intelligence (SGI), we develop SGIBench: Scientific Intelligence Benchmark for LLMs via Scientist-Aligned Workflows. Rather than serving as yet another performance benchmark, SGI-Bench functions as an operational instantiation of the SGI framework, quantitatively evaluating LLMs across the full spectrum of scientific cognition defined by the Practical Inquiry Model. By design, SGI-Bench is comprehensive in its disciplinary breadth, challenging in its difficulty, and unique in its explicit coverage of all four capabilities central 4 to our definition of SGI. The benchmark structure is therefore organized into four corresponding task categories: Scientific Deep Research (Deliberation): This task evaluates models ability to perform iterative, multi-step reasoning over complex scientific content. Idea Generation (Conception): This task assesses creativity and methodological planning by asking models to generate novel hypotheses or experimental designs. Dry/Wet Experiment (Action): This task evaluates the ability to plan and execute computational (dry) or laboratory-style (wet) experiments. Experimental Reasoning (Perception): This task requires models to analyze experimental results, interpret data trends, and identify meaningful conclusions. Building upon our theoretical framework, the construction of SGI-Bench operationalizes the proposed definition of Scientific General Intelligence (SGI). We began with foundational topics drawn from Sciences 125 Big Questions for the 21st Century [16], spanning ten major disciplinary areas. Through multi-round collaborations with domain experts, we identified high-impact research problems and curated raw source materials from leading journals such as Nature, Science, and Cell. Together with PhD-level researchers, we implemented multi-stage quality control pipeline involving human annotation, model-based verification, and rule-based consistency checks. The resulting benchmark comprises over 1,000 expert-curated samples that concretely instantiate the reasoning, creativity, and experimental competencies central to our definition of SGI. To evaluate performance across these four dimensions, we found that conventional LLM-as-ajudge [17] paradigms are insufficient to handle the diverse and specialized metrics required by SGI assessment. To address this, we developed an agent-based evaluation framework following an Agent-as-a-judge [18] paradigm. Equipped with tools such as web search interface, Python interpreter, file reader, PDF parser, and discipline-specific metric functions, this framework ensures rigor, scalability, and transparency. It operates through four interdependent stagesQuestion Selection, Metric Customization, Prediction & Evaluation, and Report Generationeach coordinated by specialized agents aligned with different aspects of scientific inquiry. Applying SGI-Bench to wide spectrum of state-of-the-art LLMs reveals unified picture: while modern models achieve pockets of success, they fall far short of the integrated reasoning required for scientific intelligence. In deep scientific research, models can retrieve relevant knowledge but struggle to perform quantitative reasoning or integrate multi-source evidence; exact-match accuracy remains below 20% and often collapses on numerical or mechanistic inference. In idea generation, models show substantial deficits in realization. This manifests in underspecified implementation steps and frequent proposals that lack actionable detail or fail basic feasibility checks. In dry experiments, even strong models fail on numerical integration, simulation fidelity, and scientific code correctness, revealing gap between syntactic code fluency and scientific computational reasoning. In wet experiments, workflow planning shows low sequence similarity and error-prone parameter selection, with models frequently omitting steps, misordering actions, or collapsing multi-branch experimental logic. In multimodal experimental reasoning, models perform better on causal and perceptual reasoning but remain weak in comparative reasoning and across domains such as materials science and earth systems. Across tasks, closed-source models demonstrate only marginal performance advantage over open-source models. Even the best closed-source system achieves an SGI-Score of around 30/100, reflecting that current AI models possess relatively low capability in multi-task scientific research workflows, and remain far from proficient for integrated, real-world scientific inquiry. Collectively, these findings demonstrate that current LLMs instantiate only isolated fragments of scientific cognition. They remain constrained by their linguistic priors, lacking the numerical robustness, procedural discipline, multimodal grounding, and self-corrective reasoning loops essential for scientific discovery. Because genuine scientific inquiry is inherently open-ended and adaptive, we further explore how SGI may emerge under test-time learning dynamics. Preliminary experiments using test-time scaling [19] and reinforcement learning [20] suggest that models can enhance hypothesis formation and reasoning through minimal unlabeled feedback. This adaptive improvement provides empirical support for viewing Scientific General Intelligence not as static property, but as dynamic capacity that can evolve through iterative, self-reflective reasoning cycles. In summary, this work provides principle-grounded definition of Scientific General Intelligence (SGI) and corresponding framework for its empirical study. By formalizing the cognitive cycle of scientific inquiry and operationalizing it through SGI-Bench, we clarify what it means for an AI to exhibit scientific intelligence in both theory and practice. While not final answer, this definition establishes concrete path for future researchlinking conceptual understanding with measurable progress toward AI systems capable of genuine scientific reasoning and discovery. 2. Scientific General Intelligence: Concept and Operational Definition Scientific General Intelligence (SGI) refers to an AI system capable of engaging in the full cycle of scientific inquiry with autonomy, versatility, and methodological rigor. Unlike systems that excel at isolated reasoning tasks, an SGI-capable model must integrate knowledge retrieval, idea formation, action execution, and evidence-based interpretation into coherent, iterative workflow. To formalize this notion, we characterize scientific cognition through four interdependent stages: Deliberation (evidence search, synthesis, and critical assessment), Conception (generation of hypotheses and ideas), Action (implementation of experiments or simulations), and Perception (interpretation of empirical results). Grounded in this framework, we provide an operational definition: an AI system exhibits SGI if it can (1) retrieve, synthesize, and critically evaluate knowledge; (2) generate scientifically grounded and novel ideas; (3) plan and execute experimental procedures; (4) interpret empirical outcomes with causal and contextual awareness. This definition highlights central limitation in existing benchmarks [12, 13, 14, 15]: most evaluate factual recall or single-step reasoning, but few examine the structured, long-horizon workflows that constitute real scientific inquiry. Building on the operational definition of SGI established in the previous section, we introduce SGIBench (Scientific Intelligence Benchmark for LLMs via Scientist-Aligned Workflows) benchmark designed to empirically evaluate the extent to which large language models (LLMs), vision-language models (VLMs), and agent-based systems exhibit the cognitive and procedural abilities required for scientific discovery. SGI-Bench systematically measures AI performance across 10 core scientific domains astronomy, chemistry, earth science, energy, information science, life science, materials science, neuroscience, physics and math providing panoramic view of how AI systems engage with scientific reasoning across disciplines. Its task design draws inspiration from the seminal article 125 Questions: Exploration and Discovery [16] published in Science, ensuring both disciplinary breadth and societal relevance. At the heart of SGI-Bench lies the principle of scientist alignmentthe commitment to evaluating models under conditions that authentically mirror real scientific workflows. This concept manifests in several ways: The task designs closely mirror the real-world research scenarios encountered by scientists in their work, ensuring that each task is intrinsically tied to the scientific discovery process. The raw materials used in task construction are sourced directly from scientists, ensuring the authenticity and relevance of the content. Scientists have been closely involved in the process of constructing the benchmark, with scientist-in-the-loop approach, ensuring the tasks reflect the nuances of actual scientific workflows. The final evaluation scores are aligned with the checklist based on the needs of real scientific research scenarios from scientists, which ensures that the assessments genuinely reflect the scientific utility of the models. SGI-Bench departs from conventional benchmarks that emphasize factual recall or single-turn reasoning. Instead, it operationalizes the long-horizon workflow of scientific discovery into four interdependent stages: literature review(Deliberation), methodology design(conception), experiment implementation(Action), and experimental analysis(Perception). These stages correspond to fundamental capabilities required of AI systems: information integration and understanding(Scientific Deep Research), design and planning(Idea Generation), experimental execution(Dry/Wet Experiment), and reasoning-based interpretation(Experimental Reasoning). Together, they form unified framework that measures not only what models know but how they think, plan, and adapt in pursuit of new knowledge. 2.1. Task Definition in Scientific Workflow 2.1.1. Scientific Deep Research Scientific deep research refers to thorough and comprehensive investigation of specific scientific topic, combining elements of both AI-driven deep research [21, 22, 23] and scientific meta-analysis [24, 25]. This task typically involves multi-step reasoning, web searches, document retrieval, and data analysis [26, 27, 28]. Drawing inspiration from AIs deep research, which often relies on multihop searches to gather diverse information across multiple sources [29], it also incorporates the methodology of meta-analysis from the scientific community. Meta-analysis, rigorous form of scientific research, synthesizes existing literature to derive precise, data-driven conclusions and extract quantitative insights from large body of studies. Unlike general deep research, which may focus on qualitative understanding, meta-analysis centers on aggregating and analyzing data to produce statistically significant results. By combining the multi-hop search nature of AIs deep research with the systematic, evidence-based approach of meta-analysis, this task ensures results that are both scientifically precise and meaningful. The ability to perform scientific deep research is crucial for advancing scientific knowledge, as it enables AI models to replicate the process of reviewing, synthesizing, and analyzing existing research to formulate new, data-driven hypotheses. [30, 31] Deep Research comprises multiple forms including literature inquiry [32], report-style reasoning [33] and so on. In this benchmark, we focus on literature-inquirycentric deep research, where the model identifies and integrates relevant scientific knowledge from provided sources. This process often involves unit verification, quantitative interpretation, and causal assessmentabilities fundamental to scientific reasoning and still challenging for current AI systems. By constraining the task to literature 7 Figure 2 SGI-Bench Workflow Pipeline: The end-to-end four-stage framework (Deliberation, Conception, Action, Perception) that operationalizes scientific discovery, mapping tasks to capabilities and aligning evaluation with scientist practice. inquiry rather than broader report-generation settings, we ensure greater reproducibility and more reliable evaluation, while still probing core component of scientific inquiry. In order to capture the diversity of real-world scientific inquiries, we divide the task of scientific deep research into four representative types: data, properties, micro-experiments, and macro-experiments, as illustrated in Table 1. This division reflects the major types of questions scientists often confront, ranging from data-centric queries to property characterization, and from small-scale controlled experiments to large-scale natural events. By organizing the task in this way, the benchmark ensures that AI systems are evaluated across the breadth of literature review and data-driven investigation. In real-world scientific workflows, deep research corresponds to the literature review stage. During this stage, scientists investigate existing studies, gather data, and analyze findings to understand the current state of knowledge and identify knowledge gaps that require further investigation. Table 1 Scientific Deep Research Types: Four representative categories of inquiry targets and their roles in the scientific workflow. Type Data Property Micro-experiment Macro-experiment Core Description Role in Scientific Workflow Focused on retrieving or analyzing structured datasets, such as event counts, statistical summaries, or dataset-specific attributes. Concerned with identifying or inferring material, molecular, or system properties, often requiring interpretation of experimental results or theoretical knowledge. Small-scale controlled experiments, often involving chemical reactions, physical transformations, or laboratory processes under specific conditions. Large-scale or natural experiments, such as astronomical events, climate observations, or geophysical phenomena. Supports quantitative literature review and provides foundation for identifying trends or anomalies. literature Bridges review with methodology design by clarifying key parameters. Provides simulated reasoning over experimental procedures and outcomes. Extends literature review to global or long-term observations, anchoring hypotheses in real-world contexts."
        },
        {
            "title": "Task Input",
            "content": "Background (B): detailed background of the research topic, including the scientific field and subfields, to avoid ambiguities in terminology. Constraints (C): Constraints such as experimental settings, scientific assumptions, and data sources that frame the problem appropriately. Data (D): Any experimental or empirical data directly mentioned in the task, which might be either explicitly provided or inferred. Question (Q): specific, focused question that the task aims to address, such as determining particular quantity or its variation over time. Response Requirements (R): Specifications for the answer, including the required units and whether the answer should be an integer or decimal with specified number of decimal places."
        },
        {
            "title": "Task Output",
            "content": "Steps (S): detailed, step-by-step approach that the system uses to retrieve and process data or perform reasoning. Answer (A): precise numerical or string-based response, such as specific value or phrase."
        },
        {
            "title": "Task Formulation",
            "content": "S, = LLM/Agent(B, C, D, Q, R) 9 Figure 3 Scientific Deep Research Task: Inputs, outputs, and formulation for literature-driven quantitative inquiry combining multi-step reasoning and meta-analysis. 2.1.2. Idea Generation Idea generation is critical component of the scientific process, corresponding to the stage of research methodology design. At this stage, researchers synthesize existing knowledge, engage in associative and creative thinking, and propose new approaches to address current challenges. It embodies the creative essence of scientific inquiry and shapes the direction and potential impact of subsequent research. In real-world scientific workflows, idea generation typically occurs after researchers have completed thorough literature review. They integrate prior findings, identify limitations or knowledge gaps, and use creative reasoning to formulate new hypotheses, methods, or frameworks aimed at overcoming these shortcomings. In this sense, idea generation serves as the crucial link between literature understanding and methodological innovation. However, because idea generation is an open-ended and highly creative task, its evaluation is inherently challenging. In principle, scientific ideas span wide spectrum from high-level hypotheses to fully specified methodological plans [34, 35, 36]. Evaluating the quality of open-ended hypothesesthose with substantial conceptual freedom and without explicit implementation structurerequires extensive human expert review to achieve even modest degree of inter-rater reliability and public defensibility. Such large-scale expert adjudication is beyond the practical scope of this version of the benchmark. Consequently, our current Idea Generation evaluation focuses on the methodological-design component of an ideai.e., how proposed approach is operationalized through data usage, step-by-step procedures, evaluation protocols, and expected outcomes. This component offers more constrained structure that enables measurable, partially automatable assessment while still reflecting an essential aspect of scientific ideation. We view this as pragmatic starting point, and future versions of the benchmark may incorporate broader hypothesis-level evaluation once sufficiently robust expert-sourced ground truth becomes feasible. To make the assessment more systematic and tractable, we decompose an originally holistic idea into several interrelated components, forming structured representation of the idea. This decomposition enables more fine-grained evaluation along dimensions such as effectiveness, novelty, level of detail, and feasibility [37]."
        },
        {
            "title": "Task Input",
            "content": "Related Work (RW): summary of existing research relevant to certain research direction, providing context for new ideas. Challenge (C): The current challenges in the field and the limitations of existing solutions. Limitation (L): Specific shortcomings or constraints of current research that new ideas need to address. Motivation (M): The perspective and motivation of addressing the limitations in this research direction. Task Objective (TO): The primary goal of the task, such as generating ideas that 10 solve identified challenges or improve existing solutions. Existing Solutions (ES): description of the current approaches or solutions available in the field. Task Output Core Idea (CI): The central novel idea or concept generated to address the research challenge. Implementation Steps (IS): The steps or procedures required to implement the core idea. Implementation Order (IO): The sequence in which the implementation steps should be executed. Data (D): The data that will be used to implement the idea or evaluate its effectiveness. Evaluation Metrics (EM): The criteria for assessing the success or relevance of the generated idea. Expected Outcome (EO): The anticipated result or contribution the idea is expected to achieve."
        },
        {
            "title": "Task Formulation",
            "content": "CI, IS, IO, D, EM, EO = LLM/Agent(RW, C, L, M, TO, ES) Figure 4 Idea Generation Task: Inputs, outputs, and formulation for methodology design, integrating evaluation metrics and structured implementation planning. 2.1.3. Dry/Wet Experiment Scientific experimentation represents the core of the discovery process, bridging theoretical formulation and empirical validation [30]. Within SGI-Bench, we formalize this process into two complementary categories: dry and wet experiments. Dry experiments capture computational and simulation-based studieswhere AI assists in generating, refining, or executing scientific code that models physical phenomena. [38, 39] Wet experiments, by contrast, simulate laboratory-based workflows, requiring the model to plan and reason about sequences of actions involving physical instruments, reagents, and procedural parameters [40, 41]. Together, these two categories span the continuum from theoretical abstraction to empirical realization, offering holistic evaluation of how AI can assist scientists in both virtual and physical experimentation. Computational and laboratory experiments take many forms in real scientific practice. For dry experiments, possible tasks range from full pipeline construction to simulation design and multimodule scientific computing; in this benchmark, we adopt code-completionbased formulation [42], where the model fills in missing components of an existing scientific script rather than generating an entire project from scratch. For wet experiments, laboratory workflows span diverse operational activities, yet we focus on the protocol-design aspect [43], where the model composes sequence of experimental actions and parameters from predefined action space. By constraining dry and wet experiments to code completion and protocol design respectively, we retain core aspects of computational and laboratory reasoning while ensuring reproducibility, controlled variability, and reliable evaluation across models. 11 Dry Experiment Dry experiments emphasize computational problem-solving, reflecting the growing role of AI in automating simulation-driven science. Each task presents the model with incomplete or masked scientific code that encapsulates domain-specific computations, such as molecular dynamics, climate modeling, or numerical solvers in physics [44]. The model must infer the missing logic, reconstruct executable code, and ensure that the resulting program produces correct and efficient outcomes. This task thus evaluates models ability to integrate scientific understanding with code synthesistesting not only syntactic correctness but also conceptual fidelity to the underlying scientific problem [42]. To better characterize the scope of dry experiments, we categorize representative computational functions commonly encountered across disciplines, including numerical calculation, statistical analysis, simulation, metric calculation, data processing, and predictive modeling, as shown in Table 2. The completion or generation of these functions offers rigorous measure of how well AI systems can operationalize scientific intent into executable form. Table 2 Dry Experiment Function Types: Representative computational functions and their roles across scientific code-completion tasks. Function Category Core Role in Scientific Experiments Numerical Calculation Statistical Analysis Simulation Metric Calculation Data Processing Predictive Modeling Basic mathematical computations required to support physical or chemical modeling. Processing experimental data using descriptive or inferential statistics to identify trends and distributions. Running computational simulations (e.g., molecular dynamics, finite element analysis) and filtering results for relevant conditions. Computing evaluation metrics such as accuracy, error, or performance indicators for validating experiments. Handling raw data before and after experiments, including normalization, cleaning, and feature extraction. Applying machine learning methods to categorize, predict, or group experimental results. In real scientific workflows, dry experiments correspond to the stage of experimental design in computational and simulation-based studies. Following hypothesis formulation, researchers employ virtual experiments to anticipate and evaluate potential outcomes prior to empirical validation, enabling cost-efficient and theoretically grounded pre-assessment of experimental feasibility."
        },
        {
            "title": "Task Input",
            "content": "Background (B): Information from relevant scientific code, providing context for the dry experiment. Data Code (D): The data used in the experiment, including any code snippets or predefined inputs. Main Code (M): The core experimental code where some functions may be masked or missing. 12 Task Output Functions (F): The missing functions in the main code ùëÄ, which the system is tasked with generating or completing. Task Formulation = LLM/Agent(B, D, M) Figure 5 Dry Experiment Task: Inputs, outputs, and formulation for code-completion based computational studies with masked functions. Wet Experiment Wet experiments represent the physical realization of scientific inquiry, encompassing laboratory and field-based procedures that transform theoretical designs into empirical evidence. These tasks simulate the execution phase of real-world experiments, where models are required to plan, organize, and reason through sequences of atomic actions involving materials, instruments, and procedural parameters. Given inputs describing experimental objectives, configurations, and available tools, the model must generate structured, executable protocols that are both accurate and practically feasible. Evaluation considers not only the correctness of individual steps but also their procedural coherence and alignment with established laboratory conventions. In real scientific workflows, wet experiments correspond to the execution and validation stages of discovery. This is where hypotheses are tested against the physical world, data are collected, and evidence is generated to confirm, refine, or refute prior assumptions. By assessing how effectively AI systems can design and reason through these embodied experimental processes, this task provides window into their capacity to bridge symbolic understanding with real-world scientific practice."
        },
        {
            "title": "Task Input",
            "content": "Background (B): Information from relevant experimental procedure. Action Pool (AP): predefined set of atomic actions that can be used in the experiment, along with explanations and corresponding input/output definitions."
        },
        {
            "title": "Task Output",
            "content": "Atomic Action Order (AAO): The order in which atomic actions should be executed. Atomic Action Parameters (AAP): The parameters associated with each atomic action (e.g., reagents, temperature)."
        },
        {
            "title": "Task Formulation",
            "content": "AAO, AAP = LLM/Agent(B, AP) Figure 6 Wet Experiment Task: Inputs, outputs, and formulation for laboratory protocol planning via atomic actions and parameters. 13 2.1.4. Experimental Reasoning Experimental reasoning refers to the process of interpreting scientific observations and data to reach justified conclusions. In this benchmark, we focus on data-analysisoriented reasoning [45], where the model must extract relevant visual or numerical cues from multi-modal sources [46], compare conditions, and identify causal or descriptive patterns. This formulation emphasizes analytical interpretation rather than open-form scientific narrative, enabling reliable assessment while capturing an essential part of empirical scientific reasoning. We consider five representative modalities as shown in Table 3: a) process images that integrate symbolic and textual information to depict workflows or variable relationships; b) observation images representing raw data captured by instruments such as telescopes, satellites, or microscopes; c) experiment images documenting laboratory setups and procedures; d) simulation images generated by computational models to visualize physical or chemical processes; and e) visualization images such as plots or charts that reveal patterns within structured datasets. Collectively, these modalities reflect the multi-faceted and evidence-driven nature of scientific inquiry. Table 3 Experimental Reasoning Modalities: Five visual modalities used for multi-modal evidence and analysis. Modality Process Images Core Description Scientific Role Graphical symbols + text describing workflows or variable relations. Capture the logical flow of experiments and research design. Observation Images Raw data from instruments (e.g., telescope, satellite, microscope). Provide direct evidence of natural or physical phenomena. Experiment Images Simulation Images Photos of instruments, setups, or lab operations. Document experimental configurations and operational details. Generated from computational models/software. Visualize theoretical predictions of physical or chemical processes. Visualization Images Processed structured data into charts/plots. Reveal patterns, comparisons, or correlations from datasets. To reason effectively over such diverse inputs, we define four complementary reasoning paradigms as shown in Table 4: a) signal perception, focusing on the extraction of direct patterns from visual signals; b) attribute understanding, which demands domain knowledge to interpret key visual or contextual features; c) comparative reasoning, involving integration and comparison across multiple sources to ensure consistency and rigor; and d) causal reasoning, aimed at uncovering underlying mechanisms and scientific principles. These paradigms collectively span the hierarchy from low-level perception to high-level scientific inference. In real-world scientific workflows, experimental reasoning corresponds to the data analysis stage, during which scientists interpret experimental and simulated data, perform comparative analyses, and refine hypotheses based on empirical evidence."
        },
        {
            "title": "Task Input",
            "content": "Multiple Experimental Images (MEI): set of images representing various experimental outcomes or data collected from instruments. Question (Q): specific question or hypothesis related to the experimental data that 14 Table 4 Experimental Reasoning Paradigms: Four reasoning paradigms spanning perception to causality with examples and requirements. Reasoning Paradigm Core Requirement Typical Example Signal Perception Direct extraction of information from visual signals without heavy prior knowledge. Identifying patterns in telescope images or microscope slides. Attribute Understanding Requires disciplinary background to interpret key features and scientific attributes. Recognizing crystalline structures in materials science images. Comparative Reasoning Causal Reasoning Integrates and contrasts information across multiple images, often crossdomain. Goes beyond correlation to infer mechanisms or propose hypotheses. Comparing climate model simulations with satellite observations. Inferring causal pathways in gene expression from multi-modal experimental data. requires reasoning or analysis."
        },
        {
            "title": "Task Output",
            "content": "Reasoning (R): The specific steps in the reasoning process, including calculation, thinking, analysis, etc.. Answer (A): The conclusion drawn from analyzing the experimental data, answering the specified question or hypothesis."
        },
        {
            "title": "Task Formulation",
            "content": "R, = LLM/Agent(MEI, Q) Figure 7 Experimental Reasoning Task: Inputs, outputs, and formulation for multi-modal analysis with step-by-step reasoning and final answers. 2.2. Multi-Dimensional Metrics To align with the scientific characteristics of each task, we have designed multi-dimensional evaluation metrics for every task. This approach avoids one-size-fits-all binary judgment and instead provides more fine-grained assessment. 2.2.1. Metrics of Scientific Deep Research The Scientific Deep Research task draws inspiration from AIs deep research paradigms [47, 48, 49, 50, 51] while incorporating methodologies from meta-analysis in the scientific domain. The former emphasizes multi-step reasoning, where solving problem often requires iterative searches, calculations, and inferences; the correctness of each step directly impacts the accuracy of the final answer. The latter focuses on systematically extracting and synthesizing data from literature, requiring highly precise results. Accordingly, our metrics capture both step-by-step reasoning fidelity and final answer accuracy. 15 Metric Definition of Exact Match Exact Match (EM): Since the Scientific Deep Research tasks are designed to have short, unique, and easily verifiable answers, we use exact match as hard metric to assess whether the models final answer is correct. The model receives score of 1 if the output exactly matches the reference answer, and 0 otherwise. Metric Definition of Step-Level Accuracy Step-Level Accuracy (SLA): Models are required to produce step-by-step solutions. We employ an LLM-based judge to compare each model-generated step against the reference solution steps. For each step, the judge determines whether it is correct and provides reasoning. This fine-grained evaluation avoids binary correctness judgments for the entire solution, allowing precise assessment of reasoning accuracy at each inference step. The metric is computed as the proportion of steps correctly solved relative to the total number of steps. The score is calculated as SLA = Number of correct reasoning steps Total number of reasoning steps . 2.2.2. Metrics of Idea Generation To evaluate the open-ended nature of idea generation, we adopt hybrid framework that integrates both subjective and objective metrics. We assess each idea along four dimensionseffectiveness, novelty, detailedness, and feasibilitywhich together characterize an ideas scientific quality, creativity, and executability [37, 52]. Subjective Evaluation via LLM Judges. For subjective scoring, we perform pairwise comparisons between model-generated ideas and expert-written reference ideas. For each of the four dimensions, an LLM judge selects which idea is superior. To ensure fairness and robustness, we employ three different LLM judges, each casting two independent votes, resulting in total of six votes per dimension. The pairwise win rate against the reference idea is then used as the subjective component of the score for each dimension. Objective Evaluation via Computable Metrics. In addition to subjective judgments, we design dimension-specific computational metrics that capture structured properties of the ideas."
        },
        {
            "title": "Metric Definition of Effectiveness",
            "content": "For each reference idea, human experts extract its 35 most essential keywords. We compute the hit rate of these keywords in the model-generated idea, allowing semantic matches to avoid underestimating effectiveness. The final effectiveness score is the average of the keyword hit rate and the LLM-judge win rate: Effectiveness = Keyword Hit Rate + LLM Win Rate 2 ."
        },
        {
            "title": "Metric Definition of Novelty",
            "content": "We measure novelty by computing the dissimilarity between the model-generated idea and prior related work. Lower similarity indicates that the model proposes ideas not present in existing literature and therefore exhibits higher creativity. The final novelty score averages the 16 dissimilarity score and the subjective win rate: Novelty = Dissimilarity Score + LLM Win Rate 2 . Metric Definition of Detailedness We evaluate detailedness from two angles: a) content completeness, which checks whether the idea contains required components (Core Idea, Implementation Steps, Implementation Order, Dataset, Evaluation Metrics, Expected Outcome), and b) redundancy penalty, computed via sentence-level semantic similarity. Ideas with many repetitive sentences are penalized, as verbosity without substance does not constitute genuine detail. The final detailedness score is: Detailedness = Completeness Score (with Penalty) + LLM Win Rate 2 . Metric Definition of Feasibility For each research direction, domain experts provide standardized implementation graph containing the essential nodes and their execution order. We extract an implementation graph from each model-generated idea and compute its similarity to the expert template. low similarity indicates that the proposed idea does not align with accepted solution workflows and is therefore infeasible. The final feasibility score is: Feasibility = Graph Similarity + LLM Win Rate 2 . Taken together, the hybrid subjectiveobjective design provides robust, interpretable, and comprehensive assessment of LLMs scientific idea generation capabilities across creativity, structural clarity, and practical executability. 2.2.3. Metrics of Dry/Wet Experiment Dry Experiment Dry experiments focus on code generation task. Specifically, each problem includes background information, data code, and main code with certain functions masked. The model is tasked with completing the missing functions. Each problem contains 5 unit tests. Our metrics capture both correctness and execution behavior of the generated code [53]."
        },
        {
            "title": "Metric Definition of Pass All k Unit Tests",
            "content": "Pass all Unit Tests(PassAll@k): This metric measures the proportion of problems with or more unit tests passed successfully. Its important to distinguish this from Pass@k. While Pass@k requires only one successful attempt out of trials, PassAll@k demands that at least attempts pass the unit tests. Consequently, PassAll@5 represents the most challenging criterion. The score is calculated as PassAll@k ="
        },
        {
            "title": "Number of problems with k or more unit tests passed\nTotal number of problems",
            "content": ". 17 Metric Definition of Average Execution Time Average Execution Time (AET): This metric captures the efficiency of the generated code by measuring the average runtime across all test cases: AET = 1 ùëÅ ùëÅ ùëñ=1 ùë°ùëñ, where ùë°ùëñ is the execution time of the ùëñ-th test case and ùëÅ is the total number of test cases. Metric Definition of Smooth Execution Rate Smooth Execution Rate (SER): This metric measures the proportion of generated code that runs without any runtime errors, regardless of correctness of output. It reflects adherence to basic coding standards and robustness: SER = Number of code executions without errors Total number of code executions . Wet Experiment Wet experiments involve procedural steps using laboratory instruments. Correct execution requires both the correct sequence of actions and proper parameter settings. Accordingly, we propose the following metrics:"
        },
        {
            "title": "Metric Definition of Sequence Similarity",
            "content": "Sequence Similarity (SS): This metric evaluates the similarity between the order of atomic actions provided by the model and the reference sequence. Let seqmodel and seqref be the sequences of atomic actions from the model and the reference, respectively. Denote by Inv(seqmodel, seqref) the number of discordant pairs between the sequences. For sequences of length ùëõ, the score is computed as: SS = 1 Inv(seqmodel, seqref) ùëõ(ùëõ1) 2 , where ùëõ(ùëõ1) is the maximum possible number of inversions. By definition, SS = 1 indicates that the sequences are identical, while SS = 0 indicates maximal disorder relative to the reference sequence."
        },
        {
            "title": "Metric Definition of Parameter Accuracy",
            "content": "Parameter Accuracy (PA): This metric measures the correctness of input parameters for each atomic action compared to the reference, including reagent types, concentrations, volumes, or other domain-specific parameters. The score is calculated as the proportion of correctly specified parameters across all actions: PA ="
        },
        {
            "title": "Number of correctly specified parameters\nTotal number of parameters",
            "content": ". 18 2.2.4. Metrics of Experimental Reasoning The Experimental Reasoning task assesses the multi-modal scientific reasoning capabilities of LLMs and agents. Specifically, given several images and corresponding question, the model is required to select the correct option from no fewer than 10 candidates. For evaluation, the correctness of the final answer and the validity of intermediate reasoning are equally critical. Therefore, two evaluation metrics are adopted, as detailed below. Metric Definition of MCA Multi-choice Accuracy (MCA): Given several options, the model receives score of 1 if the selected option exactly matches the reference answer, and 0 otherwise. The final score of MCA is the average of all individual scores across all test samples. This metric directly quantifies the models ability to pinpoint the correct solution from large candidate pool, serving as foundational measure of its end-to-end scientific reasoning accuracy in the multi-modal task. Metric Definition of Reasoning Validity Reasoning Validity (RV): Models are required to generate step-by-step logical reasoning to justify their selected answers. An LLM-based judge is utilized to assess the model-generated reasoning against reference reasoning. For each test sample, the LLM judge assigns validity score ranging from 0 (completely invalid, contradictory, or irrelevant) to 10 (fully rigorous, logically coherent, and perfectly aligned with the reference reasoning), accompanied by justifications for the assigned score. This fine-grained scoring paradigm circumvents the limitations of binary correctness assessments, enabling precise quantification of reasoning quality, including the validity of premises, logical transitions, and alignment with scientific principles. The final RV score is computed as the mean of individual sample scores across the entire test set, reflecting the models overall capability to perform interpretable and reliable scientific reasoning. 2.3. Scientist-Aligned Data Construction Raw Corpus Collection In this stage, we conducted multiple discussions with experts from diverse scientific disciplines, drawing from both the 125 important scientific questions published in Science, and the prominent research directions in various disciplines with significant scientific impact. Ultimately, we curated 75 research directions spanning ten scientific domains, as shown in Figure 8. Please refer to Appendix A.2 for complete list of research directions. Subsequently, we collected raw data provided by experts and researchers, primarily consisting of scientific texts and images across the various disciplines. The texts mainly cover knowledge introduction, methodological design, experimental procedures, and data analysis. The images include experiment figures, data visualizations, and observational images, each accompanied by detailed descriptions. In addition, these experts and researchers will provide seed questions and annotation requirements for annotation, which provide initial examples for the subsequent annotation process, as illustrated in Figure 2 (G). Question Construction After gathering the raw data, we recruited over 100 Masters and PhD holders from different disciplines to construct benchmark questions according to the task definitions. Annotators first analyzed the collected texts and images, and then created questions according 19 to annotation requirements and seed questions. Several rules were applied to ensure scientific validity and authenticity. Specifically, annotators were required to reference the original data source and paragraph for each question, ensuring traceability to scientist-provided data. Furthermore, all questions are constructed by at least two annotators, one of whom is responsible for generating complex draft questions, and the other is responsible for refining them, as shown in Figure 2 (G). During question construction, experts continuously reviewed the generated questions. Each question was immediately submitted to the relevant expert for evaluation, who assessed its scientific value. For instance, question with an experiment configuration that lacks general applicability would be deemed scientifically invalid. Experts provided feedback to annotators, who then revised the questions accordingly, ensuring that the constructed questions remain aligned with the perspectives and standards of domain scientists. Data Cleaning Once all questions were constructed, we applied three layers of data cleaning: 1. Rule-based cleaning: Questions that did not meet task-specific criteria were removed. For example, for Scientific Deep Research, steps must be short sentences forming list, each representing one step; for Wet Experiments, each action must exist in the predefined action pool. 2. Model-based cleaning: Large language models were used to detect and remove questions with semantic errors or potential logical inconsistencies. 3. Expert quality check: All questions were reviewed by the original data-providing scientists, removing incomplete questions, questions with non-unique answers, or questions whose research direction did not align with the source data. For Dry Experiments, Python environments were used to test all code snippets to ensure executability. Difficulty Filtering After data cleaning, we filtered questions based on difficulty using mainstream LLMs. We evaluated each question with six high-performance models (e.g., GPT-5 [54], Gemini-2.5Pro [5], DeepSeek-R1 [55], Kimi-k2 [56]) under setup allowing web search and deep-reasoning modes. Questions that more than half of the models could correctly answer were removed. This process ensures that the benchmark remains highly challenging. Through these four steps, we guarantee that all benchmark questions are derived from authentic scientific data, aligned with domain scientists judgment of scientific value, and maintain both high quality and high challenge. 2.4. Data Distribution After the data construction process, we obtained the complete SGI-Bench benchmark, which contains 318 Scientific Deep Research questions, 315 Idea Generation questions, 271 Dry Experiment questions, 68 Wet Experiment questions, and 291 Experimental Reasoning questions. The discipline distributions for Scientific Deep Research, Idea Generation, and Experimental Reasoning are identical, as shown in Figure 9 (a). The discipline distributions for Dry and Wet Experiments are presented in Figure 9 (b) and Figure 9 (c), respectively, with Wet Experiments covering only subset of disciplines, such as Biology and Chemistry. In addition to discipline-level distributions, we further categorized the tasks at finer granularity. For Scientific Deep Research, questions are grouped based on the type of target being investigated into four categories: Data, Properties, Micro-Experiments, and Macro-Experiments, as detailed in Table 1. The distribution of these types is illustrated in Figure 9 (d). For Dry Experiments, questions are classified into six types according to the masked function type, as shown in Table 2, with the corresponding distribution displayed in Figure 9 (e). In Experimental Reasoning, the task inputs include images spanning multiple modalities, including Process Images, Observation Images, Experiment Images, 20 Figure 8 Benchmark Subjects: Overview of 10 scientific domains covered by SGI-Bench. Simulation Images, and Visualization Images, summarized in Table 3 and visualized in Figure 9 (f). Moreover, based on the type of reasoning required, questions are further categorized into Signal Perception, Attribute Understanding, Comparative Reasoning, and Causal Reasoning, as detailed in Table 4, with distributions shown in Figure 9 (g). These fine-grained categorizations by discipline and task type facilitate detailed analysis of the limitations of evaluated LLMs and agents across scientific domains and research tasks. Such insights provide clear directions for advancing AI-assisted scientific discovery. 3. SGIEvalAgent: Agentic Evaluation Framework Given the inherent complexity of scientific discovery, evaluating the performance of LLMs and agents in this domain presents formidable challenges. Rather than merely employing LLMs as evaluators, we develope comprehensive, agent-based evaluation framework augmented with diverse capabilities (e.g., web search, Python interpreter, file reader, PDF parser, metric-specific Python functions [57]) to ensure rigorous, accurate, and scalable evaluations. As illustrated in Figure 10, this framework is structured into four interconnected stages: Question Selection, Metric Customization, Predict & Eval, and Report Generation, each orchestrated by specialized agents to address distinct facets of the evaluation workflow. 21 Figure 9 Benchmark Data Distribution: (a) Overall discipline distribution; (b) Dry experiment discipline distribution; (c) Wet experiment discipline distribution; (d) Scientific Deep Research question types; (e) Dry Experiment function types; (f) Experimental Reasoning image modalities; (g) Experimental Reasoning reasoning paradigms. 3.1. Question Selection The Question Selection stage is managed by dedicated questioning agent, which interprets user queries to retrieve relevant questions from the SGI-Bench question bank. The agent filters questions according to multiple criteria, including disciplinary domain, task category, and evaluation intent specified in the input query. In scenarios where no user query is provided, the agent defaults to systematically selecting all questions from the SGI-Bench, thereby ensuring comprehensive coverage across all scientific tasks. This stage effectively defines the evaluation scope by specifying the precise set of problems that subsequent stages will assess."
        },
        {
            "title": "Agent Input",
            "content": "User Query (Q): Any content input by users for obtaining relevant information, which can be in various forms such as text, keywords, or questions. SGI-Bench Data (D): All constructed datasets in SGI-Bench, each of which is associated with specific discipline and corresponding research area. K-value (K): positive integer indicating the number of most relevant items to select from the SGI-Bench Data based on the User Query."
        },
        {
            "title": "Agent Output",
            "content": "Selected Indices (SI): The selected indices for locating and retrieving the target data. 3.2. Metric Customization In the metric customization stage, metric customization agent first dynamically generates novel evaluation metrics based on user queries and selected questions. The agent parses the evaluation intent from user input to formalize customized metric instructions with advanced tools like web search and PDF parser, enabling flexible prioritization of metrics or integration of novel evaluation dimensions. Then, the customized metrics will be aggregated with predefined scientist-aligned metrics 22 Figure 10 Evaluation Framework. given different question types, as described in Section 2.2, to form the final metrics for evaluation. By synergizing pre-defined and user-customized metrics, this stage ensures the framework aligns with both standardized benchmarks and domain-specific demands."
        },
        {
            "title": "Agent Input",
            "content": "User Query (UQ): Any content input by users for obtaining relevant information, which can be in various forms such as text, keywords, or questions. SGI-Bench Data (D): All constructed datasets in SGI-Bench, each of which is associated with specific discipline and corresponding research area. Selected Indices (SI): The selected indices for locating and retrieving the target data. Tool Pool(T): set of pre-configured tools for agents to call, including web search, PDF parser, Python Interpreter, etc. Metric Pool(M): set of pre-defined task-specific metrics presented in Section 2.2."
        },
        {
            "title": "Agent Output",
            "content": "Metrics for Evaluation (ME): Generated novel metrics based on the user query. 3.3. Inference and Evaluation The predict & eval stage leverages tool pool that includes utilities like web search, PDF parser, and Python interpreter to first execute inference for target LLMs or agents on the questions selected in the first stage. Subsequently, dedicated Science Eval Agent (SGI-Bench Agent) applies the metrics finalized in the second stage to score the inference results. For each score, the agent generates ratio23 nale grounded in reference answers, question context, and supplementary information retrieved via tools if necessary, thereby ensuring transparency and reproducibility. By integrating tool-augmented inference with systematic, metric-driven scoring, this stage effectively addresses the multi-dimensional and complex nature of scientific reasoning assessment. Evaluation Agent Definition Agent Input SGI-Bench Data (D): All constructed datasets in SGI-Bench, each of which is associated with specific discipline and corresponding research area. Selected Indices (SI): The selected indices for locating and retrieving the target data. Responses (R): Generated responses by the evaluation target in the Testbed. Tool Pool(T): set of pre-configured tools for agents to call, including web search, PDF parser, Python Interpreter, etc. Metrics for Evaluation (ME): Generated novel metrics based on the user query. Agent Output Score (S): single integer score from 010, where 10 means the response is fully correct compared to the answer. Higher scores indicate the Prediction is better, and lower scores indicate it is worse. Rationale (RN): brief explanation of why the response is correct or incorrect with respect to accuracy, completeness, clarity, and supporting evidence. 3.4. Report Generation The report generation stage is orchestrated by dedicated reporting agent, which aggregates the user evaluation intents, finalized metric specifications, and the results produced during the Predict & Eval stage. The agent then compiles comprehensive report that both visualizes and quantifies the performance of different LLMs and agents across the selected questions and metrics. Beyond summarizing raw results, the report contextualizes the findings within the broader landscape of scientific discovery capabilities, thereby enabling users to extract actionable insights and make informed decisions efficiently."
        },
        {
            "title": "Agent Input",
            "content": "Score List(SL): list of integers score from 010, where 10 means the response is fully correct compared to the answer. Higher scores indicate the Prediction is better, and lower scores indicate it is worse. Rationale List(RNL): list of explanations of why the response is correct or incorrect with respect to accuracy, completeness, clarity, and supporting evidence. User-customized Metric (UM): Generated novel metrics based on the user query."
        },
        {
            "title": "Agent Output",
            "content": "Report (R): comprehensive final evaluation report that demonstrates the scientific discovery capabilities of different LLMs and agents. 24 4. Evaluation Results 4.1. Evaluation Setup To comprehensively evaluate different models throughout the scientific discovery workflow, we performed quantitative assessments across diverse LLMs and agents using scientist-aligned metrics. For open-weight LLMs, we evaluated DeepSeek-V3.2 [58], DeepSeek-R1 [55], Intern-S1 and Intern-S1-mini [59], Kimi-k2 [56], Qwen3-VL-235B-A22B [60], Qwen3-235B-A22B, Qwen3Max, and Qwen3-8B [61], and Llama-4-Scout [62]. For closed-weight LLMs, we assessed GPT-4o [63], GPT-4.1 [64], GPT-5 [54], GPT-5.1 [65], GPT5.2-Pro [66], o3 and o4-mini [67], Gemini-2.5-Flash and Gemini-2.5-Pro [5], Gemini-3-Pro [68], Claude-Opus-4.1 [69], Claude-Sonnet-4.5 [70], Grok-3 [71], and Grok-4 [72]. For open-source agents, we tested SmolAgents(GPT-4.1) and SmolAgents(Gemini-2.5Flash) [57], Owl(GPT-4.1) and Owl(Gemini-2.5-Flash) [73], WebThinker [74], XMaster [75], and InternAgent [76]. For closed-source agents, we evaluated OpenAI DeepResearch(o3) and OpenAI DeepResearch(o4mini) [48], Kimi-Search(Kimi-k2) [50], Doubao-Search(Seed-1-6), Grok-Search(Grok-4) [51], and Perplexity(Sonar-Pro) [49]. For benchmarking consistency, we set the temperature of all configurable models to 0 to minimize randomness and used standard zero-shot, task-specific prompt template across all tasks. 4.2. Overview Table 5 provides cross-task snapshot of current capabilities. Overall, SGI-Score remains low across families (typically 305), with the best aggregate result at 33.83 (Gemini-3-Pro). Closed-source models show only marginal edge over leading open-source systems (e.g., Claude-Sonnet-4.5 at 32.16 vs. Qwen3-Max at 31.97), indicating that scale and access alone do not translate into robust scientific cognition. At the task level, Deep Research is the most brittle under the strict Exact-Match metric (best 18.48; many models around 816), revealing the difficulty of end-to-end, multi-source evidence integration and numerically faithful inference. Idea Generation exhibits the opposite patternstrong surface performance but weak realizability: while GPT-5 attains the highest average (55.40), feasibility remains uniformly low across models, reflecting underspecified implementation details and missing resource/parameter assumptions. In Dry Experiments, high executability does not imply correctness: even the best PassAll@5 peaks at 36.64 (Gemini-3-Pro), underscoring persistent gaps in numerical stability and scientific algorithm selection. Wet Experiments remain challenging, with uniformly low action-sequence similarity and only moderate parameter accuracy, driven by errors in step ordering, temporal coordination, and branch/sample bookkeeping. Multimodal Experimental Reasoning shows relatively stronger results (best MCA 41.92), yet remains far from reliable scientific discrimination. Taken together, these patterns validate our SGI framing: contemporary models possess fragments of the DeliberationConceptionActionPerception cycle but fail to integrate them into coherent, workflow-faithful intelligencepointing to the need for meta-analytic retrieval with numerical rigor, planning-aware conception, and procedure-level consistency constraints. 4.3. Scientific Deep Research The results for LLMs and agents are presented in Figs. 12 and 13. Exact Match (EM) evaluates the correctness of the final answer, while Step-Level Accuracy (SLA) measures alignment with the reference reasoning trajectory. EM remains low across all evaluated systems, typically around 10% and seldom above 20%, indicating that current models capture only narrow fraction of the analytical 25 Model DeepResearch IdeaGen DryExp WetExp ExpReasoning SGI-Score DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok-4 Open-source LLM 37.45 40.16 38.09 36.04 43.17 39.28 39.45 39.83 35.78 29.72 23.62 33.33 28.79 16.97 29.52 28.41 28.89 33.21 18.45 20.37 Closed-source LLM 35.95 36.49 55.40 47.12 55.03 46.07 40.78 39.13 39.95 39.68 40.29 43.20 35.98 37.12 26.94 34.32 29.89 31.00 28.04 31.73 35.79 21.03 22.51 36.64 34.69 35.79 27.31 33.71 20.95 21.12 29.02 12.42 25.76 30.30 26.40 33.62 9.96 21.66 31.31 36.63 16.31 22.77 17.50 30.04 28.86 18.55 22.05 32.45 25.38 30.15 37.92 29.01 12.70 15.03 15.74 11.06 13.11 11.97 14.19 15.38 8.18 7.86 7.86 11.32 14.47 11.64 15.72 12.89 11.95 10.69 15.09 18.48 12.93 13.84 13.52 13. - - 28.87 16.84 - 31.62 - 37.80 23.37 25.77 32.30 38.49 38.14 34.02 39.18 32.65 33.33 34.36 41.24 41.92 38.83 37.80 - 30.24 - - 28.10 18.67 - 28.32 - 31.97 19.15 21.08 26.87 31.45 30.84 29.31 31.09 30.68 30.14 24.75 28.17 33.83 30.42 32.16 - 28.68 Table 5 Overview Results Across SGI-Bench Tasks: Aggregated performance across Deep Research, Idea Generation, Dry/Wet Experiment, and Experimental Reasoning. The scores for Deep Research are based on the exact match metric (the strictest metric). Idea Generation scores are the average of four metrics evaluating ideas. Dry Experiment scores are based on PassAll@5 (the strictest metric). Wet Experiment scores are the average of action sequence similarity and parameter accuracy. Experimental Reasoning scores are based on the multi-choice accuracy metric (the strictest metric). The SGI-Score is the average across these tasks, reflecting the overall capability of an AI model in various scientific research scenarios. An asterisk indicates results from different versions of the same series of multimodal models. depth required for scientific deep research. While top-performing tool-augmented agents slightly outperform the best offline LLMs on SLA, the overall distributions overlap substantially; several agent systems underperform many LLMs, and EM differences are marginal with the best LLMs matching or exceeding the best agents. SLA substantially exceeds EM across nearly all systems. Multiple systems, including several agentsachieve SLA above 50%, with the best around 65%. This disparity suggests that models frequently produce partially correct or locally consistent reasoning steps but struggle to maintain coherence and correctness across the full reasoning chain. Such behavior underscores the intrinsic difficulty of end-to-end scientific reasoning and the importance of step-wise decomposition for improving task success. Newer large-scale LLMs do not universally outperform predecessor models. For example, Grok-4 exhibits lower EM and SLA than Grok-3 on this benchmark, suggesting that large-scale training may introduce regressions or reduce retention of specialized scientific knowledge. These results collectively 26 Figure 11 Scientific Deep Research Case: Example multi-hop workflow illustrating data retrieval, evidence synthesis, and quantitative analysis. highlight the current limitations of frontier AI systems in executing the multi-faceted and rigorously structured reasoning processes required for Scientific Deep Research. Figure 12 Scientific Deep Research Evaluation of LLMs: Exact Match (EM) and Step-Level Accuracy (SLA) across models using scientist-aligned metrics. Most models exhibit substantially lower performance on the Data and Properties tasks, but somewhat betterthough still modestlyon Microand Macro-experiment tasks. Based on the focus of each question, we categorize the tasks into four types: Data, Properties, Micro-experiments, and Macro-experiments  (Table 1)  . Figure 14 summarizes the performance of LLMs and agents across these categories. Notably, performance across all four categories rarely exceeds 30% (with only few Macro cases slightly above), underscoring the intrinsic difficulty of scientific deep research. This disparity can be attributed to the nature of the information required. Dataand property-related questions often rely on detailed numerical specifications or contextual descriptions scattered across disparate sources in the literature, demanding precise retrieval, cross-referencing, and aggregation. 27 Figure 13 Scientific Deep Research Evaluation of Multi-Agent Systems: EM and SLA for toolaugmented agent systems. Figure 14 Scientific Deep Research Performance by Type: Comparison across Data, Properties, Micro-Experiments, and Macro-Experiments categories. In contrast, Microand Macro-experiment tasks tend to provide more structured protocols or clearer experimental outcomes, enabling LLMs and agents to reason with fewer retrieval uncertainties. In summary, the relatively stronger model performance on experiment-oriented tasks suggests that recent advances in LLM pretraining and instruction tuning have enhanced models abilities to process structured procedures and numerical patterns. Nevertheless, the consistently low scores across all categories indicate that contemporary LLMs, even when augmented with tool-based agents, remain far from mastering the breadth and depth of reasoning required for robust scientific deep research. 4.4. Idea Generation Figure 15 illustrates the evaluation pipeline for Idea Generation in SGI-Bench, and more experimental details can be found in the section 2.2.2. Table 6 shows the quantitative experimental results of idea generation, including effectiveness, novelty, detailedness, and feasibility. We could see that GPT-5 achieves the best average performance, and achieves the best performance in three aspects only excluding the feasibility. Moreover, across models, clear pattern emerges: Novelty is generally high, especially among closed-source systems (e.g., o3 73.74, GPT-5 76.08). This indicates that modern LLMs possess robust capacity for generating conceptually novel scientific ideas. Such behavior aligns with the growing empirical use of LLMs as inspiration engines for scientific hypothesis generation and exploratory research. 28 Figure 15 Idea Generation Case: Input information such as related work and objective, and output structured idea, including graph consisting of specific implementation steps. Mechanistically, this strength likely stems from their broad pretraining over heterogeneous scientific corpora, which enables them to recombine distant concepts across domains, as well as their ability to internalize high-level research patterns (problemmethodevaluation triples). As result, LLMs are particularly effective at proposing plausible and novel conceptual directions, often exceeding what single human researcher can enumerate in short time window. Novelty is relatively high while feasibility lags. In contrast, Effectiveness is modest for most models and Feasibility consistently lags behind the other dimensions. Even the best-performing GPT-5, which achieves high Detailedness (85.72) and the highest Average (55.40), attains only scores 18.87 in Feasibility, confirming that conceptual richness does not reliably translate into implementationready plans. The top Feasibility model by our metric is o3 (22.90), while open-source feasibility peaks at Qwen3-8B (20.58); other models cluster in the 1420 range. Open-source models exhibit the same trend: Kimi-k2 reaches higher Detailedness (59.20) but remains limited in Feasibility (18.74); similarly, Qwen3-VL-235B-A22B reaches only 20.14 in Feasibility despite substantially higher conceptual elaboration (50.23). Execution details are often underspecified. These outcomes reveal realization bottleneck in current idea generation: While models can articulate sophisticated pipelines at high level, they frequently omit or under-specify key executable details. Typical failure issues include: (i) data references without acquisition or preprocessing plans; (ii) training and optimization loops that omit concrete hyperparameters or resource assumptions; (iii) algorithmic modules named but not grounded in precise choices (e.g., solver type, training objective, evaluation protocol); (iv) integration steps that fail to specify interfaces, ordering, or data flow. Consequently, many proposals fail feasibility checks not because they are conceptually unsound, but because they rely on implicit, unparameterized execution assumptions that cannot be validated under realistic experimental conditions. This gap highlights fundamental limitation of current LLMs: they excel at linguistic and conceptual abstraction, yet 29 Model Effectiveness Novelty Detailedness Feasibility Average Open-source LLM DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout 28.09 27.73 26.38 24.95 25.24 27.24 26.63 28.74 26.12 28.50 54.09 63.64 56.47 55.71 69.49 59.53 62.05 59.01 49.36 33.25 GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok-4 Closed-source LLM 27.28 27.49 40.92 36.07 51.36 29.42 27.26 28.45 30.98 28.38 26.52 32.01 28.37 28.46 48.19 48.72 76.08 66.98 71.19 73.74 63.33 56.91 57.54 59.41 64.40 58.00 46.27 50. 47.34 50.06 49.10 48.07 59.20 50.23 49.73 50.61 47.09 43.08 47.85 47.88 85.72 66.62 78.03 58.22 50.53 50.49 52.21 51.07 50.16 61.75 48.35 49.48 20.28 19.20 20.42 15.44 18.74 20.14 19.40 20.98 20.58 14.06 20.51 21.87 18.87 18.83 19.53 22.90 22.01 20.69 19.06 19.87 20.07 21.03 20.93 19.60 37.45 40.16 38.09 36.04 43.17 39.28 39.45 39.83 35.78 29.72 35.95 36.49 55.40 47.12 55.03 46.07 40.78 39.13 39.95 39.68 40.29 43.20 35.98 37. Table 6 Idea Generation Results: The ideas generated by the model outperformed the average proportion of the original papers in the four dimensions of Effectiveness, Novelty, Detailedness, and Feasibility. struggle with the procedural, resource-aware, and constraint-grounded planning required for real scientific implementation. Overall, the Idea Generation results indicate that contemporary LLMs are adept at proposing novel directions but struggle to turn them into fully executable plans. Bridging this gap will require constraintaware planning, stronger priors over experimental and engineering practice, tool-augmented verification (e.g., property simulators, data/API discovery, and reproducibility scaffolds), and training signals that reward concrete, parameterized, and testable implementation steps rather than stylistic innovation. 4.5. Dry/Wet Experiment Experiments form the critical bridge between idea generation and scientific reasoning, providing the most direct avenue for validating hypotheses and uncovering new phenomena. Within SGI-Bench, we evaluate two complementary forms of experiments: dry experiments, which involve computational analyses or simulations, and wet experiments, which require laboratory procedures and operational planning. Across both categories, current AI models exhibit substantial limitations, revealing persistent gap between linguistic fluency and experimentally actionable competence. Figure 16 Dry Experiment Code Examples: Masked-function completion setup with I/O formats, and functional descriptions. 4.5.1. Dry Experiment As introduced in Section 2.1.3, each dry experiment contains three components: description of scientific background, complete data-construction script, and an analysis script with masked functions. The model must infer and complete these missing functions using contextual understanding. For fairness and structural clarity, function headers, including names, signatures, and functional descriptions, are preserved, as shown in Figure 16. This setup isolates the models ability to infer algorithmic logic rather than boilerplate structure. Table 7 summarizes three metrics defined in Section 2.2.3: PassAll@k, Average Execution Time (AET), and Smooth Execution Rate (SER). Here, PassAll@k denotes passing at least ùëò out of five unit tests per problem. Under the lenient criterion (ùëò=1), the best models achieve PassAll@1 score of 42.07%, whereas the strictest requirement (ùëò=5) reduces performance to 36.64%. These results underscore that scientific code completion remains significant bottleneck, even for frontier LLMs. Notably, closed-source models generally achieve higher PassAll@k than leading open-source models, though the advantage is modest and distributions overlap, suggesting that scientific code synthesis in dry experiments remains underdeveloped across architectures. High execution rates do not guarantee correctness. The SER metric captures whether the generated code executes without error, independent of correctness. While many top models achieve high SER values (>90%), performance varies widely across systems; several models are substantially below this threshold (e.g., Gemini-2.5-Flash/Pro, Qwen3-8B, Llama-4-Scout, GPT-5, GPT-4o), indicating nontrivial robustness gaps. This suggests that basic structural and API-level reasoning has matured for some models; however, the persistent gap between SER and accuracy metrics highlights that structural validity is far easier than algorithmic correctness in scientific contexts. Numerical and simulation functions are the most challenging. Figure 17 breaks down PassAll@5 across functional types. Models perform relatively well on Data Processing and Predictive Modeling, where multiple valid implementations exist and errors are less amplified. In contrast, Numerical Calculation and simulation-oriented functions prove substantially more difficult. These tasks typically require precise numerical stability, accurate discretization, or careful handling of domain-specific 31 Model PassAll@5(%) PassAll@3(%) PassAll@1(%) AET(s) SER(%) DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok-4 23.62 33.33 28.79 16.97 29.52 28.41 28.89 33.21 18.45 20. 26.94 34.32 29.89 31.00 28.04 31.73 35.79 21.03 22.51 36.64 34.69 35.79 27.31 33.71 Open-source LLM 26.94 35.56 31.44 17.34 32.10 31.37 31.48 35.42 20.30 21.48 Closed-source LLM 29.89 37.64 32.84 35.42 33.21 34.32 39.11 22.51 23.99 40.46 37.27 38.75 29.15 37.12 29.52 37.41 34.09 18.08 36.16 33.58 34.44 37.27 21.03 22. 32.10 40.22 34.69 38.01 39.48 37.64 41.70 24.72 24.72 41.98 40.59 42.07 32.10 40.53 29.96 28.09 31.04 14.55 33.42 32.74 30.68 35.25 21.13 24.24 37.90 40.54 34.54 23.87 23.73 34.06 31.34 15.09 13.94 21.16 31.67 31.59 35.30 33.74 68.27 91.70 87.58 79.83 90.26 91.22 90.81 90.33 71.51 68.52 79.78 94.10 75.50 96.53 96.60 85.17 87.60 44.65 44.65 98.85 94.32 94.83 91.22 94.09 Table 7 Dry Experiment Metrics Across Models: PassAll@k, Average Execution Time (AET), and Smooth Execution Rate (SER) under five unit tests per problem. Figure 17 PassAll@5 by Function Category: Completion accuracy across numerical calculation, statistical analysis, simulation, metric calculation, data processing, and predictive modeling. constraints, all of which amplify small reasoning inconsistencies. This pattern reveals striking asymmetry: models exhibit reasonable flexibility in tasks with diverse valid outputs but struggle with tasks requiring exact numerical fidelity. Methodological choices critically affect outcomes. The case shown in Figure 18 illustrates this issue in an astronomical dry experiment involving the computation of gravitational-wave observables from LIGO/Virgolike detectors. The o4-mini model employs na√Øve numerical integration via 32 Figure 18 Dry Experiment Case Study: Gravitational-wave computation highlighting the impact of numerical integration strategy on scientific outcomes. np.cumsum, effectively using forward Euler approximation for ùúí(ùëß) = ùëß 0 ùëëùúí ùëëùëß ùëëùëß, which introduces substantial cumulative error when the discretization is coarse. In contrast, GPT-4.1 correctly adopts scipy.integrate.quad, leveraging adaptive integration schemes that preserve numerical precision. Because errors in ùúí(ùëß) propagate directly to the comoving volume element ùëëùëâ ùëëùëß = 4ùúãùúí(ùëß)2 ùëëùúí ùëëùëß , the flawed integration strategy in o4-mini leads to significant deviation in the final volume estimate ùëâGpc3. This example highlights broader challenge: LLMs often fail to capture the numerical sensitivity and methodological nuance essential for scientific computation. Overall, these findings reveal that while current models can generate syntactically valid code with high reliability, their deeper limitations stem from (i) incomplete numerical reasoning, (ii) superficial understanding of scientific algorithms, and (iii) the inability to select appropriate computational strategies under domain constraints. AI-assisted scientific experimentation thus remains demanding frontier, requiring future models to incorporate domain-aware numerical reasoning, fine-grained algorithmic priors, and training signals beyond natural-language supervision. 4.5.2. Wet Experiment For wet experiments, we provide models with an action pool containing standardized experimental operations and detailed descriptions. Given the experimental context, the model is required to synthesize complete workflow, including both the selection and ordering of actions as well as all associated parameters (Figure 19). As illustrated in the figure, the model outputs typically exhibit two major categories of errors: (i) incorrect ordering of experimental steps and (ii) inaccurate or inconsistent parameter specification. 33 Figure 19 Wet Experiment Workflow: Action-pool based protocol construction with typical errors in step sequencing and parameter specification. Figure 20 Wet Experiment Evaluation: Sequence Similarity (SS) and Parameter Accuracy (PA) across models for laboratory protocol planning. Wet experiments reasoning remains brittle. Figure 20 summarizes performance in terms of sequence similarity (SS) and parameter accuracy (PA). For SS, closed-source models in general achieve higher scores than open-source ones (with the best closed-source model around 35.5 versus the best open-source below 30), yet SS remains uniformly low across all systems. In contrast, PA exhibits mixed pattern: although the top result is obtained by closed-source model (around 40.6), several open-source models are competitive, and some closed-source models drop markedly (e.g., near 20.7). PA appears slightly more optimistic also since permutation-equivalent parameter groups are treated as identical (e.g., action 1(ùêµ, ùê∂) and action 1(ùëã, ùëå ) are identical when ùêµ=ùëã and ùê∂=ùëå ), but both families still achieve only modest scores. Across outputs, errors recur in three patterns: insertion of unnecessary steps, omission of essential steps, and incorrect ordering of valid steps. Temporal and branch-aware planning is often broken. Figure 21 presents an experiment examining how tumor mutational burden and neoantigen load influence the efficacy of antiPD-1 immunotherapy in nonsmall cell lung cancer. The ground-truth workflow (Figure 21 a) features deeply branched structure with precisely coordinated timing and sample-handling procedures. In contrast, the workflow generated by o4-mini is substantially simplified and deviates from several core principles of experimental design. 34 Figure 21 Wet Experiment Case Study: NSCLC antiPD-1 immunotherapy workflowground-truth protocol versus model-generated design. First, the model collapses longitudinal sampling into single blood draw and does not distinguish time windows, precluding any meaningful reconstruction of T-cell dynamics. Second, PBMC isolation is executed only once rather than per time point, causing misalignment with downstream staining and flow cytometry. Functional assays (e.g., intracellular cytokine staining) are performed on single PBMC aliquot without branching by time point or antigenic stimulation, and flow cytometry is likewise conducted only once, failing to capture temporal variation. Finally, the blood-sample branch conflates genomic and immunophenotyping workflows: Extract genomic DNA is executed in parallel with PBMC isolation and downstream immunology, leading to duplicated and cross-purpose use of peripheral blood. These design flaws mirror the low sequence similarity and only moderate parameter accuracy observed in Figure 20, underscoring failures in temporal coordination, branchaware planning, and sample bookkeeping. Overall, the deviations highlight critical limitation of current AI models: while they can enumerate plausible wet experiment actions, they struggle to construct experimentally valid, temporally consistent, and branch-aware protocols. These limitations point to fundamental gaps in reasoning about experimental constraints, biological timing, and multi-sample coordinationelements essential for real-world scientific experimentation. 4.6. Experimental Reasoning Experimental Reasoning evaluates the ability of multimodal LLMs to interpret experimental observations, integrate heterogeneous scientific evidence, and refine testable hypotheses. As illustrated in Figure 22, the visual inputs span five representative modalities in scientific practiceprocess diagrams, data visualizations, natural observations, numerical simulations, and laboratory experimentsreflecting the diversity of multimodal information that underpins real-world scientific inquiry. In this task, models are provided with several images accompanied by question and must select the correct answer from at least ten candidates (Figure 23). Solving these problems requires multistep inferential reasoning: identifying relevant variables, synthesizing multimodal cues, evaluating 35 Figure 22 Experimental Reasoning Modalities: Examples of process, visualization, observation, simulation, and experiment images used as multi-modal evidence. competing hypotheses, and ultimately validating consistency across the provided evidence. We therefore evaluate model performance using both Multi-choice Accuracy and Reasoning Validity, the latter assessing whether the models explanation follows logically from the scientific evidence. Reasoning validity often exceeds answer accuracy. As shown in Figure 24, closed-source LLMs generally outperform open-source counterparts on both metrics, with the best closed-source models achieving higher MCA (e.g., up to 41.9) and RV (e.g., up to 71.3) than the best open-source models (MCA 37.8, RV 52.3). However, several open-source models remain competitive with or exceed some closed-source systems in specific metrics (e.g., Qwen3-VL-235B-A22B RV 50.5 > GPT-4o RV 45.4), indicating nontrivial overlap. Most models score higher in Reasoning Validity than in Multi-choice Accuracy, suggesting that even when the final choice is incorrect, explanations often preserve partial logical coherence. Variance is moderateparticularly among closed-source modelswhile only few models (e.g., Intern-S1-mini) show noticeably lower performance, pointing to the importance of scale for robust multimodal scientific reasoning. Comparative reasoning is the most challenging across domains. To further dissect these capabilities, we analyze performance across reasoning types and disciplinary domains (Figure 25). From the perspective of reasoning categories, including signal perception, attribute understanding, comparative reasoning, and causal reasoning, LLMs perform consistently well in causal reasoning and perceptual recognition. In contrast, comparative reasoning emerges as persistent weakness. This indicates that models struggle when required to contrast subtle quantitative or qualitative differences, cognitive operation fundamental to scientific evaluation and hypothesis discrimination. When examining performance across 10 scientific disciplines, an intriguing pattern emerges. Models achieve their highest accuracy in astronomy, followed by chemistry, energy science, and neuroscience. These domains often feature structured visual patterns or canonical experimental setups, which may align well with LLMs prior training data. Conversely, performance declines substantially in materials science, life sciences, and Earth sciences, where visual cues are more heterogeneous, context-dependent, or experimentally nuanced. This divergence suggests that domain-specific complexity and representation diversity strongly influence multimodal reasoning performance. 36 Figure 23 Experimental Reasoning Case: Multi-image question requiring cross-modal synthesis and step-wise reasoning. Overall, these findings reveal that while current LLMs demonstrate encouraging abilities in integrating scientific evidence and conducting basic causal analyses, they still fall short in tasks requiring precise discrimination, cross-sample comparison, and nuanced interpretation of domain-specific observations. The relatively narrow performance gap among leading models underscores that scale alone is insufficient; advancing experimental reasoning will require improved multimodal grounding, finer-grained visual understanding, and training paradigms explicitly aligned with scientific inquiry. 5. Analysis 5.1. Test Time Reinforcement Learning Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning and problemsolving, primarily driven by supervised fine-tuning and reinforcement learning on extensive labeled datasets. However, applying these models to the frontier of scientific discovery, particularly in the task of scientific idea generation, presents fundamental challenge: the inherent absence of ground truth. Unlike closed-domain tasks such as mathematical reasoning or code generation, where solutions can be verified against correct answer, the generation of novel research ideas is an open-ended problem with no pre-existing gold standard labels. This limitation renders traditional offline training pipelines insufficient for adapting to dynamic and unexplored scientific territories. 37 Figure 24 Experimental Reasoning Evaluation: Multi-Choice Accuracy (MCA) and Reasoning Validity (RV) across models on multimodal tasks. Figure 25 Experimental Reasoning Performance by Type and Discipline: Breakdown across reasoning paradigms (signal, attribute, comparative, causal) and 10 scientific domains. Consequently, the critical research question becomes: How can we enhance models capability during the inference phase in the absence of ground-truth supervision? To address this, we adopt the paradigm of Test-Time Reinforcement Learning (TTRL) [20]. This framework enables models to self-evolve on unlabeled test data by optimizing policies against rule-based rewards derived from the models own outputs or environmental feedback. Distinct from the original implementation [20], which primarily leveraged consensus-based consistency as reward mechanism for logical reasoning tasks, we establish novelty as our core optimization objective in the current context. Consequently, we introduce TTRL framework where the reward signal is constructed based on the dissimilarity between generated ideas and retrieved related works, guiding the model to actively explore the solution space and maximize innovation at test time. 5.1.1. Methodology To address the absence of ground truth in scientific idea generation, we propose generalizable reward mechanism based on online retrieval. Instead of relying on static labels, we utilize real-time search to fetch existing related works, serving as dynamic baseline for comparison. This approach enables us to quantify novelty as the semantic dissimilarity between the models output and the retrieved context, effectively converting an open-ended exploration problem into measurable optimization task. The overall training framework is illustrated in Figure 26. We employ Group Relative Policy Optimization (GRPO) [1] as our training backbone. For given query ùëÑ, the policy model ùúãùúÉ generates group of ùëò outputs {ùëú1, . . . , ùëúùëò}. The optimization is guided 38 Figure 26 TTRL Training Framework: The model generates candidate ideas evaluated against online retrieved related works to calculate novelty rewards, guiding GRPO updates. by composite reward function, defined as the unweighted sum of format constraint and novelty metric (labeled as Idea Dissimilarity in Figure 26): ùëÖ(ùëú) = ùëÖformat(ùëú) + ùëÖnovelty(ùëú, W) (1) where = {ùë§1, . . . , ùë§ùëõ} denotes the set of related works obtained via online search. Format Reward (ùëÖformat). To guarantee interpretable reasoning, we enforce strict XML structure. The model must encapsulate its chain of thought within <think>...</think> and the final proposal within <answer>...</answer>. The format reward is binary: ùëÖformat(ùëú) = ùïÄ (ùëú follows the specified XML structure) (2) Novelty Reward (ùëÖnovelty). We quantify novelty by measuring the vector space dissimilarity between the generated idea and the retrieved literature. Let eidea be the embedding of the generated answer, and {eùë§ ùëó }ùëõ be the embeddings of ùëõ retrieved papers (denoted as ùë§1, . . . , ùë§ùëõ in the figure). We compute the average cosine similarity ùëÜavg: ùëó= ùëÜavg = 1 ùëõ ùëõ ùëó=1 eidea eùë§ ùëó eideaeùë§ ùëó An innovation score ùëÜinn [0, 10] is then derived to reward divergence: ùëÜinn = clip (cid:0)(1 ùëÜavg) 10, 0, 10(cid:1) Using gating threshold ùúè = 5, the final novelty reward is defined as: ùëÖnovelty(ùëú, W) = ùïÄ(ùëÜinn > ùúè) (3) (4) (5) This mechanism incentivizes the model to produce ideas that are semantically distinct from existing work. 5.1.2. Experimental Setup We employ Qwen3-8B as the base model, trained using the GRPO algorithm within the ms-swift [77] framework. To facilitate diverse exploration, we utilize high sampling temperature. Key hyperparameters are detailed in Table 8. 39 Table 8 TTRL Hyperparameters: Key training configuration for GRPO-based test-time reinforcement learning."
        },
        {
            "title": "Value",
            "content": "Base Model RL Algorithm Precision Learning Rate Max Length Generations (ùê∫) Temperature Batch Size Related Works (ùëõ) Weights Qwen3-8B GRPO bfloat16 5 107 2048 8 1.0 4 4 1:1 Figure 27 TTRL Training Dynamics: Format reward saturates quickly, followed by steady growth in idea novelty. 5.1.3. Experimental Results The training dynamics of our TTRL framework are illustrated in Figure 27. The curves demonstrate clear two-phase optimization process. Initially, the Format Reward (orange line) rises rapidly and saturates near 1.0 within the first few steps, indicating that the model quickly adapts to the rigid XML structural constraints (<think> and <answer> tags). Once the format is stabilized, the Idea Reward also starts to rise (green line). Despite the inherent difficulty of the task, the Idea Reward exhibits consistent upward trend throughout the training steps, driving the total reward (blue line) to converge at higher value. Quantitatively, this self-evolution process yields significant improvement in the quality of generated ideas. The average novelty score of the models outputs increased from baseline of 49.36 to 62.06. It is important to emphasize that this performance gain was achieved entirely without ground-truth labels. The model improved solely by leveraging the online retrieval feedback loop, validating the hypothesis that LLMs can self-improve on open-ended scientific discovery tasks through test-time reinforcement learning. 5.1.4. Case Study of TTRL To visually demonstrate the impact of TTRL on scientific idea generation, we present comparative case study in Figure 28. The task requires the model to propose novel framework for RNA 3D structure prediction. Figure 28 TTRL Case Study: Comparison of generated research ideas before and after TTRL, highlighting structural innovation (dual-branch transformer, differentiable physics engine) versus generic pre-training assembly. 40 Comparing the responses before and after training reveals noticeable improvement in both specificity and novelty. The Pre-Training Response suggests standard combination of existing components, essentially assembling \"contact map prediction\" with \"Rosetta energy functions.\" While logical, it represents conventional approach without distinct architectural details. In contrast, the Post-Training Response introduces more structurally specific and technically distinct concepts. It explicitly proposes \"dual-branch transformer\" and replaces static energy functions with \"differentiable physics engine.\" Additionally, it incorporates \"confidence-aware uncertainty module\" to address the reliability challenge. This shift indicates that the model has moved beyond generic component assembly toward generating more detailed and differentiated technical proposals. In conclusion, our experiments demonstrate that Test-Time Reinforcement Learning Summary. (TTRL), driven by retrieval-based novelty rewards, effectively enhances model capabilities in the absence of ground-truth supervision. The observed improvements in both quantitative novelty metrics and qualitative technical specificity indicate that the model can successfully self-evolve beyond conventional patterns. These findings suggest that TTRL is promising paradigm for adapting Large Language Models to the open-ended and unexplored frontiers of real-world scientific discovery. 5.2. Agent Tool Integrated Reasoning 5.2.1. RetrieveBrowse Loop Analysis Tool-Integrated Reasoning (TIR) in real tasks unfolds as dynamic, opportunistic process rather than fixed linear chain[78]. As shown in Figure 29 (left), the model-to-tool flow concentrates heavily on retrieval actions: web_search is the most frequently invoked tool with 539 calls (33.98% of all), followed by visit_webpage (385, 24.27%), final_answer (358, 22.57%), python_interpreter (200, 12.61%), and wikipedia_search (104, 6.56%). This distribution indicates that an external retrieve-then-browse loop remains the dominant path for contemporary agentic systems, reflecting persistent limits in time-sensitive and domain-specific knowledge available to base LLMs. Importantly, models differ in how efficiently they traverse this loop: for example, GPT-4.1 issues large volumes of web_search (168) and visit_webpage (110) that frequently land in slow tiers, whereas Qwen3-Max completes comparable coverage with far fewer retrieval and browsing steps (61 and 59, respectively). Practically, this pattern implies that reducing redundant retrieval iterationsvia better query formulation and higher-quality extraction on the first passhas immediate leverage on end-to-end latency, often exceeding gains from marginal improvements to raw model inference. 5.2.2. Tool Efficiency Analysis Latency variation is predominantly tool-dependent, as visualized in Figure 29 (right). The primary bottleneck is visit_webpage, whose cross-model latency spans from 5.37s (Llama-4-Scout) to 114.29s (GPT-4.1), 21.28 spread. This reflects the intrinsic cost of browser-level executionnetwork I/O, DOM parsing, and event replayrather than LLM reasoning alone. In contrast, more atomic operations such as wikipedia_search still exhibit substantial 7.59 spread (3.6928.03s), underscoring that I/O pathways and parsing routines meaningfully shape end-to-end time even for ostensibly simple tools. These observations suggest design priority: engineering optimizations in the retrieval-and-browsing pipeline (e.g., smarter caching, incremental browsing, selective content extraction) will reduce both long-tail latencies and overall wall-clock time more reliably than tuning model-only parameters. 41 5.2.3. Reasoning Cost Analysis The python_interpreter tool exhibits 9.65 cross-model range (5.4852.94s), indicating that measurements capture the full reasonexecutedebugrepair loop rather than single code run. The slowest average arises for DeepSeek-R1 (52.94s), consistent with more frequent multi-step error analysis and correction; the fastest is GPT-4o (5.48s), reflecting low-latency, near single-shot execution path. This divergence reveals strategic trade-off: systems optimized for first-attempt correctness minimize tool time but may forgo deeper self-correction, whereas systems favoring iterative refinement accrue longer tool-side latency while potentially achieving more robust final solutions. In practice, aligning tool routing, retry policy, and verification depth with models characteristic behavior can reduce wasted cycles and sharpen the latencyquality frontier. Figure 29 Agent Tool Calls: Frequency (left) and efficiency (right) across leading models. 5.3. SGIEvalAgent 5.3.1. User-customized Metric SGIEvalAgent interprets the users evaluation intent and turns it into rubric that can be applied consistently across the selected idea-generation questions. In the case shown in Figure 30, the user asks to compare models on rigor in cross-disciplinary idea generation. The system formalizes Rigor (scientific strictness) for idea proposals so that it reflects how scientists judge whether plan is internally coherent, well grounded, and practically verifiable. The rubric expresses six aspects in prose rather than checklists. First, it checks logical self-consistency and completeness of the pipeline from problem to hypothesis, method, metrics, and expected results. Second, it requires theory and literature grounding that either correctly inherits prior work or responsibly challenges it with evidence. Third, it demands precise and verifiable problem definitions that state goals, constraints, evaluation metrics, and success conditions. Fourth, it looks for deep fit with the research background and correct, discipline-aligned terminology. Fifth, it evaluates methodological soundness and reproducibility through executable steps, clear I/O loop, and explicit rationale for key design choices. Sixth, it considers risk awareness and scientific criticism by articulating assumptions, potential failure modes, bias sources, and avoiding over-confident conclusions. Major deductions apply when the reasoning chain is missing, key assumptions are unstated, terminology is misused, metrics are vague or non-verifiable, or inheritance from background knowledge is misaligned. Scores are produced on 010 scale for each aspect and aggregated with default equal weights 42 Figure 30 SGIEvalAgent Case: Model Users describe their evaluation needs, SGIEvalAgent customizes the evaluation plan and metrics based on these needs, and finally provides an evaluation report.. into single rigor score; the result is linearly mapped to 0100 axis for visualization without changing rank order. The evaluation agent generates textual rationales that cite reference answers and problem context so that decisions are transparent and reproducible. Customized metrics are reported alongside SGI-Benchs predefined task metrics rather than replacing them, preserving standardized comparability while highlighting the users domain-specific focus. 5.3.2. Automated Evaluation Report The reporting agent summarizes the customized metric and the evaluation outputs into concise narrative with figures. In Figure 30, the report contrasts open-source and closed-source systems on the user-defined rigor metric for idea generation and highlights what the scores mean in practice. The core takeaway is straightforward: closed-source models generally exhibit higher rigor under this rubric, intra-family iterations capture measurable gains, and leading open-source models show notable progress that narrows the gap. Higher rigor reflects more structured, well-grounded, and verifiable research plans rather than merely fluent narratives. The report therefore gives users clear, scientist-aligned comparison they can directly use for model selection and iteration in research workflows. 6. Challenges and Future Directions Grounded in our operational definition of SGI and instantiated through SGI-Bench, the evaluation results reveal consistent message: contemporary LLMs and agentic systems exhibit localized scientific cognition and segmented scientific reasoning They may solve isolated sub-problems, but fail to robustly close the iterative loop spanning Deliberation, Conception, Action, and Perception. Below we summarize the main limitations across tasks and disciplines, connect them with our TTRL and tool-integrated reasoning analyses, and outline concrete future directions. 6.1. Fragmentation Across the Four Quadrants of SGI Deliberation: Scientific Deep Research remains brittle end-to-end. Scientific Deep Research operationalizes the literature-review/meta-analysis stage and is evaluated by Exact Match (EM) and Step-Level Accuracy (SLA). Across both standalone LLMs and tool-augmented agents, EM is consistently low: most systems achieve only 10% accuracy, and even the best models rarely exceed 20% EM (Figure 12, Figure 13). This indicates that current models still fail to produce verifiable final scientific claims under multi-source evidence integration. notable gap exists between SLA and EM. SLA is substantially higher for nearly all systems, with several agentic systems reaching 50% SLA (Figure 13), while EM remains low. This disparity shows that models often produce locally correct steps but cannot maintain global coherence across long reasoning chains. The failure mode is therefore not mere knowledge absence, but reasoning trajectory collapse under long-horizon scientific inference. At finer granularity, Deep Research tasks involving Data and Properties are the weakest: performance on these categories is substantially below that of Microand Macro-experiment questions, with all four categories rarely exceeding 30% accuracy (Figure 14). This aligns with the task design: data/property questions require retrieving dispersed numerical details across heterogeneous papers, while experiment-oriented questions provide more structured evidence. The results thus expose core SGI bottleneck: meta-analytic retrieval + numerical aggregation over scattered literature. Idea Generation in SGI-Bench is assessed using EffecConception: Ideas lack implementability. tiveness, Detailedness, and Feasibility  (Table 6)  . Feasibility is low across models: many systems score in the 1420 range, and the best result reaches 22.90 (o3), indicating that feasibility consistently lags behind novelty and detailedness. Detailedness remains insufficient for several models, with implementation steps frequently missing concrete parameters, resource assumptions, or step ordering; Effectiveness is moderate for most systems, with the highest result of 51.36 (GPT-5.2-Pro) and open-source models clustering around 24.9528.74 (e.g., DeepSeek-V3.2, Llama-4-Scout). Recurring issues include: (i) underspecified implementation stepsabsent data acquisition or preprocessing plans, missing hyperparameters or compute assumptions, vague module choices (e.g., solver type, training objective, evaluation protocol), and unclear interfaces, ordering, or data flow; and (ii) infeasible proceduresreliance on unavailable instruments or data, uncoordinated pipelines that cannot be executed, and designs lacking reproducibility. In SGI terms, current systems exhibit fluent linguistic ideation without sufficient methodological execution grounding: they articulate concepts clearly but struggle to translate them into concrete, parameterized, and testable workflows. The feasibility gap observed in Table 6 is therefore persistent bottleneck in realization, including within the Conception quadrant, where ideation quality does not reliably imply executable planning competence. Action: Experimental execution is limited by numerical and procedural rigor. For Dry Experiments, accuracy is measured by PassAll@k. Even under the most lenient setting, the best PassAll@1 is only 42.07% (Claude-Sonnet-4.5), and under the strictest criterion, the best PassAll@5 rises to merely 36.64% (Gemini-3-Pro)  (Table 7)  . The spread between PassAll@1 and PassAll@5 (e.g., 42.0735.79 44 for Claude-Sonnet-4.5, 41.9836.64 for Gemini-3-Pro) indicates that models often nail partial logic but fail full scientific correctness. Importantly, code executability is not the bottleneck: most frontier models achieve SER > 90% (e.g., GPT-5.1 96.53, Gemini-3-Pro 98.85), while accuracy remains low. This gap confirms central limitation: syntactic fluency scientific computational reasoning. The per-function analysis further shows numerical-calculation and simulation functions as the major failure mode (Figure 17), consistent with the case study (Figure 18) where naive integration choices lead to cascading scientific errors. For Wet Experiments, although Parameter Accuracy improves slightly under permutation-equivalence evaluation, Sequence Similarity remains uniformly low across both open and closed models (Figure 20). Models frequently insert redundant steps, omit critical actions, or misorder multi-branch protocols. The complex oncology workflow case (Figure 21) illustrates that models cannot reliably manage temporal design, branching logic, or multi-sample coordination. Thus, wet-lab action planning remains profound gap toward embodied SGI. In ExperPerception: Multimodal reasoning is improving, but comparison is hard frontier. imental Reasoning, closed-source models consistently outperform open-source ones (Figure 24). Across nearly all models, Reasoning Validity (RV) exceeds Multi-choice Accuracy (MCA), showing that models can often produce partially coherent narratives even when selecting the wrong option. This echoes the SLAEM gap in Deep Research and suggests general pattern: models are better at producing plausible local reasoning than globally correct scientific decisions. Reasoning-type breakdown reveals that models perform relatively well on Signal Perception and Causal Reasoning, but Comparative Reasoning is persistently weakest (Figure 25). Scientific comparison requires subtle cross-sample discrimination and quantitative contrasta cognitive operation central to scientist judgment but not yet robustly captured by current MLLMs. Discipline-wise, astronomy and chemistry are easier, while materials science, life science, and Earth science remain hardest (Figure 25), reflecting the mismatch between real scientific visual heterogeneity and training priors. 6.2. Implications from Test-Time RL and Tool-Integrated Reasoning SGI as dynamic, learnable capacity. Our TTRL experiments demonstrate that open-ended scientific ideation can improve without labeled supervision. With retrieval-based novelty rewards, Qwen3-8B increases its novelty score from 49.36 to 62.06 (Figure 27) and qualitatively progresses from generic component assembly to structured innovation (Figure 28). These results suggest that SGI should be interpreted not merely as static benchmark score, but as capability that can evolve through test-time learning. Nevertheless, optimizing for novelty in isolation risks ungrounded or implausible ideas; combining novelty with rigoror feasibility-based rewards is crucial next step for reliable scientific ideation. The retrieval pipeline is the true bottleneck for agentic SGI. Tool-Integrated Reasoning (TIR) analysis reveals that agent workflows are heavily dominated by retrieval operations: web_search accounts for 539 calls (33.98%), and visit_webpage for 385 calls (24.27%) (Figure 29). Latency is primarily tool-driven rather than model-driven; visit_webpage exhibits 5.37s114.29s range across models (a 21.28 spread). This indicates that many gains in SGI performance may stem from smarter tool routing, reduction of redundant retrievals, and higher-quality first-pass extraction, rather than simply scaling base LLMs. Analysis of the Python tool further highlights trade-off between first-shot correctness and iterative self-repair, with 9.65 cross-model latency range, underscoring 45 the need for model-aware verification and retry policies in practical agentic workflows. 6.3. Future Directions Toward Scientific General Intelligence Our findings point to several high-leverage research directions: (1) Meta-analytic reasoning with numerical robustness. Deep Research failures on Data/Properties and low EM despite high SLA call for methods that explicitly train evidence aggregation and numerical synthesis. Promising routes include retrieval-conditioned quantitative reasoning, uncertaintycalibrated aggregation over multiple sources, and verification-aware step planning that penalizes reasoning-chain drift. (2) Planning-aware conception and structured supervision. To address uniformly low feasibility and sparse implementation detail in Idea Generation, adopt planning-aware constraints with structured supervision: require parameter-complete, dependency-consistent steps, prioritize feasibilityfocused rewards (availability checks, resource/cost estimates, reproducibility), and use lightweight tool checks during decoding to block or repair incomplete plans. This shifts fluent proposals into executable, testable designs under realistic scientific constraints. (3) Scientific code training beyond syntax. Dry experiments show high SER but low PassAll@5  (Table 7)  , especially on numerical and simulation functions (Figure 17). Future work should emphasize numerical analysis priors, stability-aware loss, and algorithmic-choice training (e.g., recognizing when adaptive integration or stiffness solvers are required). Hybrid symbolicnumeric tool use (formal solvers + LLM reasoning) is another promising path. (4) Branchand time-aware wet-lab protocol reasoning. Uniformly low Sequence Similarity and qualitative failures on complex branching protocols (Figure 21) suggest need for training signals that encode temporal sampling logic, branching decision rules, and multi-sample tracking. Action-pool grounding can be extended with stateful simulators or lab-graph verifiers, enabling models to learn procedural validity under physical constraints. (5) Comparative multimodal scientific reasoning. Comparative reasoning is the hardest paradigm (Figure 25). Progress likely requires finer-grained visual grounding (e.g., numeric extraction from charts), cross-image alignment modules, and contrastive multimodal training that rewards precise discrimination rather than narrative plausibility. Discipline-specific multimodal curricula may reduce domain gaps in materials/Earth/life sciences. (6) Test-time learning with multi-objective scientific rewards. TTRL improves novelty without labels, but novelty alone is insufficient for SGI. Future TTRL systems should optimize portfolio of scientist-aligned rewards (novelty, rigor, feasibility, safety, and experimental cost), and incorporate retrieval trustworthiness and contradiction penalties to prevent spurious innovation. (7) Efficient and reliable tool ecosystems for SGI agents. Given retrieval dominance and tool latency (Figure 29), engineering advances are essential: retrieval caching, selective browsing, structured extraction, and tool-aware planning policies can substantially improve SGI agents end-to-end qualitylatency frontier. 46 Summary. SGI-Bench reveals that modern LLMs exhibit partial competencies in each SGI quadrant but lack integrated, numerically robust, and methodologically disciplined scientific cognition. Bridging this gap requires progress on long-horizon meta-analysis, executable planning, numerically faithful experimentation, branch-aware wet-lab reasoning, comparative multimodal inference, and dynamic test-time self-improvementall supported by efficient and trustworthy tool ecosystems. These directions collectively chart concrete path from fragmented scientific skills toward genuine Scientific General Intelligence. 6.4. Limitations Despite providing structured framework for evaluating scientific capabilities across four workflow stages, the current version of SGI-Bench has several limitations: (1) Partial coverage of real scientific workflows. The four stages in our benchmark function as probes for different components of scientific inquiry rather than complete representation of real-world scientific practice. Many aspects of scientific worksuch as integration across scientific disciplines and risk and safety assessment [79]remain outside our current scope. (2) Scientific Deep Research currently emphasizes literature-inquirycentric tasks. Deep Research spans activities such as literature inquiry [32], report-style reasoning [33], and related scientific analyses. In this benchmark, we focus on the literature-inquirycentric subset, as identifying, interpreting, and integrating existing scientific knowledge is foundational prerequisite for methodological design and experimental planning. This focus enables standardized, reproducible, and scalable evaluation while still probing core component of real scientific workflows. More open-form variantssuch as argumentative evidence synthesis or report generationare also important but require substantial expert-based scoring, and are therefore reserved for future versions. (3) Idea Generation evaluation focuses on methodology design. Fully open-ended hypothesis generation involves substantial conceptual freedom and requires extensive expert adjudication to achieve reliable judgments. Due to practical constraints, our current evaluation focuses on the methoddesign component of scientific ideas [34, 35, 36]. Future extensions may incorporate hypothesis-level evaluation through combination of arena-style model comparisons and expert review. (4) Limited code and action space coverage. Dry Experiment tasks currently support only Python [42], lacking adaptation to other programming languages and computational paradigms. The action space for Wet Experiments is an early-stage abstraction; scaling it requires constructing large, standardized library of atomic actions grounded in real laboratory protocols [43]. (5) Experimental reasoning in enclosed spaces. We employ multiple-choice design to ensure objective, automatable evaluation [45]. While practical, this structure constrains the models ability to express diverse reasoning paths and limits assessment of open-form scientific explanations. (6) Partial coverage of deductive and inductive paradigms of scientific discovery. Scientific discovery is commonly understood to follow two broad paradigms: deduction and induction [80, 81]. Deductive processes begin from prior knowledge or theoretical propositions and proceed through reasoning to experimental verification. Inductive processes, in contrast, originate from new observational data or unexpected empirical phenomena and generalize toward broader patterns or hypotheses. 47 The PIM-grounded [10, 11] workflow in this version of SGI-Bench primarily reflects the deductive paradigm, as tasks begin with literature-based information and guide models toward reasoning and experiment planning. Inductive scientific discoverywhich relies on data-driven pattern formation and hypothesis emergenceremains outside the scope of the current benchmark and represents an important direction for future expansion. 7. Related Work With the rapid advancement of Large Language Models (LLMs) and multi-agent systems in scientific reasoning, numerous datasets have emerged to evaluate their capabilities across various scientific domains. 7.1. Benchmarks in Different Disciplines significant portion of existing benchmarks focuses on specific disciplines. In the physical sciences, PhyBench [82] examines multi-step reasoning and expression capabilities through original physics problems, while PHYX [83] focuses on real-world scenarios to assess physical reasoning and visual understanding. Additionally, PHYSICS [84] tests models using open-ended, university-level problems.To further address multimodal challenges, PhysUniBench [85] introduces large-scale benchmark for undergraduate-level physics, specifically targeting the interpretation of physical diagrams and multi-step reasoning. In chemistry, ChemBench [86] provides domain-specific data for systematic evaluation, whereas ChemMLLM [87] extends this to multimodal assessment. More granular tasks are covered by benchmarks like ChemSafetyBench [88] and SpectrumWorld [89]. In life sciences, benchmarks range from the molecular level, such as DeepSEA [90] and GenomicsLong-Range [91], to healthcare applications like BioASQ [92] and VQA-RAD [93], as well as agricultural applications like SeedBench [94] and neuroscience with BrainBench [95]. For earth sciences, OmniEarth-Bench [96] covers comprehensive range of fields with cross-domain tasks, EarthSE [97] builds multi-level evaluation system from foundational to open-ended exploration, and MSEarth [98] utilizes high-quality scientific publications for graduate-level assessment. In remote sensing, GeoBench [99] and XLRSBench [100] evaluate perception and reasoning on high-resolution imagery. Furthermore, specialized benchmarks exist for other fields, including material science (MoleculeNet [101]), astronomy (AstroLLaMA and AstroMLab [102]), ocean science (OceanBench [103]), and climate science (ClimaQA [104]). These works primarily target deep evaluation within isolated disciplines. While benchmarks like ATLAS [105] have expanded to cover cross-disciplinary fields with high-difficulty standards, its evaluation specifically focuses on distinguishing frontier models through complex scientific reasoning and logical application tasks rather than the entire process of scientific discovery. 7.2. Benchmarks for Different Scientific Tasks Concurrently, other benchmarks focus on cross-disciplinary comprehensive capabilities, though their evaluation focus is often distributed across specific stages of the scientific discovery pipeline. Regarding idea generation at the research inception stage, MOOSE-Chem2 [37] evaluates models through win/tie/lose comparison framework that scores generated hypotheses against reference answers using multiple independent judges. AI Idea Bench 2025 [106] evaluates the novelty of agent-generated ideas using dataset derived from top-tier conference papers. In the core layer of knowledge processing and analysis, some benchmarks focus on literature comprehension. For instance, SciAssess [107] decomposes analysis into memory, understanding, and reasoning layers. Others, like SFE [45], introduce cognitive framework to dissect multimodal performance on raw scientific data. Complementing these, SciReasoner [108] targets the alignment of natural language with heterogeneous scientific representations. Recent works also evaluate comprehensive academic survey capabilities: 48 DeepResearch Bench [33] measures report quality and citation grounding, Manalyzer [109] focuses on mitigating hallucinations in automated meta-analysis, and Scientist-Bench [110] highlights the full workflow from review to paper generation. Additionally, SciArena [111] proposed an open platform that dynamically evaluates and ranks the performance of base models on scientific literature tasks by collecting pairwise comparison preferences from domain researchers, and DeepResearch Arena [112] utilizes seminar-grounded tasks to evaluate the orchestration of multi-stage research workflows, while AAAR-1.0 [113] focuses on evaluating the models ability as an AI-assisted research tool. In terms of planning and execution, evaluations often center on tool usage and coding. ToolBench [114] and ToolUniverse [115] explore API usage and standardization. In scientific coding, SciCode [42] and ScienceAgentBench [116] assess code generation within realistic workflows. At macro level, MLE-bench [117] and TaskBench [118] evaluate general planning and project management via Kaggle competitions and task decomposition graphs. In addition, DISCOVERYWORLD [119] launched the first virtual environment for evaluating the ability of intelligent agents to perform complete cycle of novel scientific discovery. However, it focuses on gamified simulation environment, and its task scenarios and evaluation dimensions cannot fully reflect the complexity and high-level cognitive needs of real scientific research workflows. LLM-SRBench [120] , on the other hand, focuses only on the models ability to discover scientific equations, with relatively simple task and process. Despite these explorations, existing process-oriented benchmarks typically address only partial dimensionssuch as knowledge understanding, data perception, or code generationlacking fine-grained, systematic evaluation of the entire scientific discovery lifecycle. Summary In summary, existing works are either confined to deep exploration of single disciplines, scattered across isolated stages of the research process, or fail to capture the complexity of actual scientific discovery scenarios. Therefore, there is an urgent need to construct comprehensive benchmark that covers multiple disciplines and connects the long-chain workflow of scientific research. 8. Conclusion This work advances the study of Scientific General Intelligence (SGI) from both theory and practice. Grounded in the Practical Inquiry Model, we formalize SGI as the capacity to navigate the iterative cycle of Deliberation, Conception, Action, and Perception with the versatility of human scientist. Building on this principle-grounded definition, we operationalize SGI through SGI-Bench, comprehensive, scientist-aligned benchmark that instantiates four core task families: Scientific Deep Research, Idea Generation, Dry/Wet Experiment, and Experimental Reasoning. Complemented by our agentic evaluation framework and multi-metric protocol, SGI-Bench enables scalable, transparent, and domainfaithful assessment. Experiments reveal consistent pattern: in Deep Research, models show step-level alignment but low exact-match accuracy (1020%), with brittleness in quantitative reasoning; in Idea Generation, hypotheses are fluent but underspecified and infeasible; in Dry Experiment, code is executable but PassAll@k remains low; in Wet Experiment, sequences show omissions and misordering; and in Experimental Reasoning, causal reasoning outperforms comparative, with persistent multimodal challenges. These highlight gaps between linguistic fluency and integrated scientific cognition. Moreover, SGI exhibits dynamic capacity: Test-Time Reinforcement Learning with novelty rewards improves idea generation without reference answers. Taken together, SGI-Bench clarifies both what SGI is and where current systems fail. By integrating principled task design, multi-metric evaluation, and agentic tool use, our framework provides concrete foundation for systematically advancing SGI. Looking forward, the combination of numerically robust reasoning, planning-aware conception, executable experimentation, comparative multimodal 49 inference, dynamic test-time learning, and efficient tool ecosystems charts clear path toward general intelligence systems capable of genuine scientific discovery."
        },
        {
            "title": "References",
            "content": "[1] Daya Guo et al. Deepseek-r1 incentivizes reasoning in llms through reinforcement learning. In: Nature 645.8081 (2025), pp. 633638. [2] Wayne Xin Zhao et al. survey of large language models. In: arXiv preprint arXiv:2303.18223 1.2 (2023). [3] Humza Naveed et al. comprehensive overview of large language models. In: ACM Transactions on Intelligent Systems and Technology 16.5 (2025), pp. 172. [4] Ming Hu et al. survey of scientific large language models: From data foundations to agent frontiers. In: arXiv preprint arXiv:2508.21148 (2025). [5] Gheorghe Comanici et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. In: arXiv preprint arXiv:2507.06261 (2025). [6] Nanyi Fei et al. Towards artificial general intelligence via multimodal foundation model. In: Nature Communications 13.1 (2022), p. 3094. [7] S√©bastien Bubeck et al. Sparks of artificial general intelligence: Early experiments with gpt-4. In: arXiv preprint arXiv:2303.12712 (2023). [8] Emily Bender et al. On the dangers of stochastic parrots: Can language models be too big? In: Proceedings of the 2021 ACM conference on fairness, accountability, and transparency. 2021, pp. 610623. [9] Ming Hu et al. Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers. 2025. arXiv: 2508.21148 [cs.CL]. url: https://arxiv.org/abs/2508. 21148. [10] Randy Garrison, Terry Anderson, and Walter Archer. Critical inquiry in text-based environment: Computer conferencing in higher education. In: The internet and higher education 2.2-3 (1999), pp. 87105. [11] Randy Garrison, Terry Anderson, and Walter Archer. Critical thinking, cognitive presence, and computer conferencing in distance education. In: American Journal of distance education 15.1 (2001), pp. 723. [12] Dan Hendrycks et al. Measuring massive multitask language understanding. In: arXiv preprint arXiv:2009.03300 (2020). [13] Xinrun Du et al. Supergpqa: Scaling llm evaluation across 285 graduate disciplines. In: arXiv preprint arXiv:2502.14739 (2025). [14] Gr√©goire Mialon et al. Gaia: benchmark for general ai assistants. In: The Twelfth International Conference on Learning Representations. 2023. [15] Long Phan et al. Humanitys last exam. In: arXiv preprint arXiv:2501.14249 (2025). [16] Sanders. 125 questions: Exploration and Discovery. In: Science/AAAS Custom Publishing Office: Washington, DC, USA 23 (2021). [17] Dawei Li et al. From generation to judgment: Opportunities and challenges of llm-as-a-judge. In: Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing. 2025, pp. 27572791. [18] Mingchen Zhuge et al. Agent-as-a-judge: Evaluate agents with agents. In: arXiv preprint arXiv:2410.10934 (2024). 51 [19] Qiyuan Zhang et al. Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well? In: arXiv preprint arXiv:2503.24235 (2025). [20] Yuxin Zuo et al. Ttrl: Test-time reinforcement learning. In: arXiv preprint arXiv:2504.16084 (2025). [21] Renjun Xu and Jingwen Peng. Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications. In: arXiv preprint arXiv:2506.12594 (2025). [22] Yusong Hu et al. FlowSearch: Advancing deep research with dynamic structured knowledge [23] flow. In: arXiv preprint arXiv:2510.08521 (2025). Jinxin Shi et al. DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction. In: arXiv preprint arXiv:2510.08959 (2025). [24] Andy Field and Raphael Gillett. How to do meta-analysis. In: British Journal of Mathematical and Statistical Psychology 63.3 (2010), pp. 665694. [25] Wanghan Xu et al. Manalyzer: End-to-end Automated Meta-analysis with Multi-agent Sys- [26] tem. In: arXiv preprint arXiv:2505.20310 (2025). REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS. English (US). In: 2023. [27] Harsh Trivedi et al. Interleaving Retrieval with Chain-of-Thought Reasoning for KnowledgeIntensive Multi-Step Questions. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Ed. by Anna Rogers, Jordan BoydGraber, and Naoaki Okazaki. Toronto, Canada: Association for Computational Linguistics, 2023, pp. 1001410037. url: https://aclanthology.org/2023.acl-long.557/. [28] Akari Asai et al. Self-RAG: Learning to Retrieve, Generate, and Critique through SelfReflection. In: The Twelfth International Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=hSyW5go0v8. [29] Yijia Shao et al. Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models. In: Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). Ed. by Kevin Duh, Helena Gomez, and Steven Bethard. Mexico City, Mexico: Association for Computational Linguistics, 2024, pp. 62526278. url: https://aclanthology.org/ 2024.naacl-long.347/. [30] Hanchen Wang et al. Scientific discovery in the age of artificial intelligence. In: Nature 620.7972 (2023), pp. 4760. issn: 1476-4687. doi: 10.1038/s41586-023-06221-2. url: http://dx.doi.org/10.1038/s41586-023-06221-2. [31] Chris Lu et al. The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery. 2024. arXiv: 2408.06292 [cs.AI]. url: https://arxiv.org/abs/2408.06292. [32] Nikos I. Bosse et al. Deep Research Bench: Evaluating AI Web Research Agents. In: ArXiv abs/2506.06287 (2025). url: https : / / api . semanticscholar . org / CorpusID : 279251730. [33] Mingxuan Du et al. DeepResearch Bench: Comprehensive Benchmark for Deep Research Agents. 2025. arXiv: 2506.11763 [cs.CL]. url: https://arxiv.org/abs/2506.11763. [34] Haiyuan Wan et al. DeepResearch Arena: The First Exam of LLMs Research Abilities via Seminar-Grounded Tasks. In: ArXiv abs/2509.01396 (2025). url: https: //api . semanticscholar.org/CorpusID:281080495. [35] Karl Popper. The logic of scientific discovery. Routledge, 2005. 52 [36] Zonglin Yang et al. MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses. In: Proceedings of the International Conference on Learning Representations (ICLR). 2025. [37] Zonglin Yang et al. MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search. In: arXiv preprint arXiv:2505.19209 (2025). [38] Bernardino Romera-Paredes et al. Mathematical discoveries from program search with large language models. In: Nature 625.7995 (2023), pp. 468475. issn: 1476-4687. doi: 10.1038/s41586-023-06924-6. url: http://dx.doi.org/10.1038/s41586023-06924-6. [39] Yecheng Jason Ma et al. Eureka: Human-Level Reward Design via Coding Large Language Models. In: The Twelfth International Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=IEduRUO55F. [40] Daniil A. Boiko et al. Autonomous chemical research with large language models. In: Nature 624.7992 (2023), pp. 570578. issn: 1476-4687. doi: 10.1038/s41586-023-06792-0. url: http://dx.doi.org/10.1038/s41586-023-06792-0. [41] Andres Bran et al. Augmenting large language models with chemistry tools. In: NeurIPS 2023 AI for Science Workshop. 2023. url: https: //openreview. net/forum?id= wdGIL6lx3l. [42] Minyang Tian et al. SciCode: Research Coding Benchmark Curated by Scientists. 2024. arXiv: 2407.13168 [cs.AI]. url: https://arxiv.org/abs/2407.13168. [43] Yuyang Liu et al. BioProBench: Comprehensive Dataset and Benchmark in Biological Protocol Understanding and Reasoning. In: ArXiv abs/2505.07889 (2025). url: https://api. semanticscholar.org/CorpusID:278534452. [44] Sam Cox et al. MDCROW: AUTOMATING MOLECULAR DYNAMICS WORKFLOWS WITH LARGE LANGUAGE MODELS. In: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation. 2025. url: https://openreview.net/ forum?id=KNQe3Cmupn. [45] Yuhao Zhou et al. Scientists First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning. 2025. arXiv: 2506.10521 [cs.AI]. url: https://arxiv. org/abs/2506.10521. [46] Ge Zhang et al. CMMMU: Chinese Massive Multi-discipline Multimodal Understanding Benchmark. 2024. arXiv: 2401.11944 [cs.CL]. url: https://arxiv.org/abs/2401. 11944. [47] BeiJing YuanShi Technology Co., Ltd. WenXiaobai (DeepSeek Search). Online; accessed 2025. url: https://www.wenxiaobai.com/. [48] OpenAI. Introducing Deep Research. https : / / openai . com / zh - Hans - CN / index / introducing-deep-research/. 2025. [49] Perplexity AI. Introducing Perplexity Deep Research. https://www.perplexity.ai/hub/ blog/introducing-perplexity-deep-research. 2025. [50] Moonshot AI. Kimi-Researcher: End-to-End RL Training for Emerging Agentic Capabilities. In: (2025). Official Project Page. url: https : / / moonshotai . github . io / Kimi - Researcher/. [51] xAI. Grok 4: Native Tool Use and DeepSearch Capabilities. https://x.ai/news/grok-4. Official announcement of Groks agentic search features. 2025. [52] Kai Ruan et al. LiveIdeaBench: Evaluating LLMs Divergent Thinking for Scientific Idea Generation with Minimal Context. 2025. arXiv: 2412.17596 [cs.CL]. url: https://arxiv.org/ abs/2412.17596. [53] Naman Jain et al. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code. 2024. arXiv: 2403.07974 [cs.SE]. url: https://arxiv.org/abs/ 2403.07974. [54] OpenAI. GPT-5 System Card. Tech. rep. OpenAI, 2025. url: https://cdn.openai.com/ gpt-5-system-card.pdf. [55] Daya Guo et al. DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning. In: Nature 645.8081 (2025), pp. 633638. issn: 1476-4687. doi: 10.1038/s41586-02509422-z. url: http://dx.doi.org/10.1038/s41586-025-09422-z. [56] Kimi Team et al. Kimi k2: Open agentic intelligence. In: arXiv preprint arXiv:2507. (2025). [57] Aymeric Roucher, Albert Villanova del Moral, et al. smolagents: smol library to build great agentic systems. https://github.com/huggingface/smolagents. 2025. [58] DeepSeek-AI. DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models. Tech. rep. [5, 49]. DeepSeek, 2025. url: https://huggingface.co/deepseek-ai/DeepSeekV3.2/resolve/main/assets/paper.pdf. [59] Lei Bai et al. Intern-s1: scientific multimodal foundation model. In: arXiv preprint arXiv:2508.15763 (2025). [60] Shuai Bai et al. Qwen3-VL Technical Report. In: arXiv preprint arXiv:2511.21631 (2025). [61] An Yang et al. Qwen3 technical report. In: arXiv preprint arXiv:2505.09388 (2025). [62] Meta AI. Llama 4: Multimodal Intelligence. https://ai.meta.com/blog/llama4multimodal-intelligence/. 2025. [63] OpenAI. GPT-4o System Card. Tech. rep. OpenAI, 2024. url: https://cdn.openai.com/ gpt-4o-system-card.pdf. [64] OpenAI. Models: GPT-4.1 Documentation. https : / / platform . openai . com / docs / models/gpt-4.1. OpenAI Platform Docs. 2025. [65] OpenAI. GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum. Tech. rep. OpenAI, 2025. url: https://cdn.openai.com/pdf/4173ec8d122947db96de06d87147e07e/5_1_system_card.pdf. [66] OpenAI. Update to GPT-5 System Card: GPT-5.2. Tech. rep. OpenAI, 2025. url: https : //cdn.openai.com/pdf/3a4153c8-c748-4b71-8e31-aecbde944f8d/oai_5_ 2_system-card.pdf. [67] OpenAI. OpenAI o3 and o4-mini System Card. Tech. rep. OpenAI, 2025. url: https:// cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4mini-system-card.pdf. [68] Google DeepMind. Gemini 3 Model Card. https : / / storage . googleapis . com / deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf. 2025. [69] Anthropic. Claude Opus 4.1 System Card. https : / / assets . anthropic . com / / 4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf. 2025. [70] Anthropic. Claude Sonnet 4.5 System Card. Tech. rep. 2025. url: https : / / assets . anthropic . com / / 12f214efcc2f457a / original / Claude - Sonnet - 4 - 5 - System-Card.pdf. 54 [71] xAI. Grok 3 Beta The Age of Reasoning Agents. https://x.ai/news/grok-3. 2025. [72] xAI. Grok 4 Model Card. 2025. url: https://data.x.ai/20250820grok- 4model-card.pdf. [73] Mengkang Hu et al. Owl: Optimized workforce learning for general multi-agent assistance in real-world task automation. In: arXiv preprint arXiv:2505.23885 (2025). [74] Xiaoxi Li, Jiajie Jin, Guanting Dong, et al. WebThinker: Empowering Large Reasoning Models with Deep Research Capability. In: Proceedings of NeurIPS 2025 (2025). Accepted by NeurIPS 2025. arXiv:2504.21776 [54]. [75] Chai Jingyi, Shuo Tang, et al. SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation. In: arXiv preprint arXiv:2507.05241 (2025). [76] NovelSeek Team et al. NovelSeek: When Agent Becomes the ScientistBuilding Closed-Loop System from Hypothesis to Verification. In: arXiv preprint arXiv:2505.16938 (2025). [77] Yuze Zhao et al. SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning. 2025. arXiv: 2408.05517 [cs.CL]. url: https://arxiv.org/abs/2408.05517. [78] Bhargavi Paranjape et al. ART: Automatic multi-step reasoning and tool-use for large language models. 2023. arXiv: 2303.09014 [cs.CL]. url: https://arxiv.org/abs/2303. 09014. [79] Yujun Zhou et al. LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs. In: ArXiv abs/2410.14182 (2024). url: https://api.semanticscholar.org/ CorpusID:273482719. [80] Francis Bacon. Novum organum. Clarendon press, 1878. [81] Karl Popper. Conjectures and refutations: The growth of scientific knowledge. routledge, 2014. [82] Shi Qiu et al. PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models. 2025. arXiv: 2504.16074 [cs.CL]. url: https://arxiv.org/abs/ 2504.16074. [83] Hui Shen et al. PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning? 2025. arXiv: 2505.15929 [cs.AI]. url: https://arxiv.org/abs/2505.15929. [84] Kaiyue Feng et al. PHYSICS: Benchmarking Foundation Models on University-Level Physics Problem Solving. 2025. arXiv: 2503.21821 [cs.AI]. url: https://arxiv.org/abs/ 2503.21821. [85] Lintao Wang et al. PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models. 2025. arXiv: 2506.17667 [cs.AI]. url: https://arxiv.org/ abs/2506.17667. [86] Adrian Mirza et al. Are large language models superhuman chemists? 2024. arXiv: 2404. [cs.LG]. url: https://arxiv.org/abs/2404.01475. [87] Qian Tan et al. ChemMLLM: Chemical Multimodal Large Language Model. 2025. arXiv: 2505. 16326 [cs.LG]. url: https://arxiv.org/abs/2505.16326. [88] Haochen Zhao et al. ChemSafetyBench: Benchmarking LLM Safety on Chemistry Domain. 2024. arXiv: 2411.16736 [cs.CL]. url: https://arxiv.org/abs/2411.16736. [89] Zhuo Yang et al. SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy. 2025. arXiv: 2508.01188 [cs.LG]. url: https://arxiv.org/abs/2508.01188. [90] Pooja Kathail, Ayesha Bajwa, and Nilah M. Ioannidis. Leveraging genomic deep learning models for the prediction of non-coding variant effects. 2025. arXiv: 2411.11158 [q-bio.GN]. url: https://arxiv.org/abs/2411.11158. 55 [91] Anonymous. The Genomics Long-Range Benchmark: Advancing DNA Language Models. 2024. url: https://openreview.net/forum?id=Cdc90HKs1I. [93] [92] Anastasia Krithara et al. BioASQ-QA: manually curated corpus for Biomedical Question Answering. In: Scientific Data 10.1 (2023). issn: 2052-4463. doi: 10.1038/s41597023-02068-4. url: http://dx.doi.org/10.1038/s41597-023-02068-4. Jason J. Lau et al. dataset of clinically generated visual questions and answers about radiology images. In: Scientific Data 5.1 (2018). issn: 2052-4463. doi: 10.1038/sdata. 2018.251. url: http://dx.doi.org/10.1038/sdata.2018.251. Jie Ying et al. SeedBench: Multi-task Benchmark for Evaluating Large Language Models in Seed Science. 2025. arXiv: 2505.13220 [cs.CL]. url: https://arxiv.org/abs/ 2505.13220. [94] [95] Xiaoliang Luo et al. Large language models surpass human experts in predicting neuroscience results. In: Nature Human Behaviour 9.2 (2024), pp. 305315. issn: 2397-3374. doi: 10.1038/s41562-024-02046-9. url: http://dx.doi.org/10.1038/s41562024-02046-9. [96] Fengxiang Wang et al. OmniEarth-Bench: Towards Holistic Evaluation of Earths Six Spheres and Cross-Spheres Interactions with Multimodal Observational Earth Data. 2025. arXiv: 2505. 23522 [cs.CV]. url: https://arxiv.org/abs/2505.23522. [97] Wanghan Xu et al. EarthSE: Benchmark for Evaluating Earth Scientific Exploration Capability of LLMs. 2025. arXiv: 2505.17139 [cs.CL]. url: https://arxiv.org/abs/2505. 17139. [98] Xiangyu Zhao et al. MSEarth: Multimodal Scientific Dataset and Benchmark for Phenomena Uncovering in Earth Science. 2025. arXiv: 2505.20740 [cs.AI]. url: https://arxiv. org/abs/2505.20740. [99] Muhammad Sohail Danish et al. GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks. 2025. arXiv: 2411.19325 [cs.CV]. url: https://arxiv.org/abs/ 2411.19325. [100] Fengxiang Wang et al. XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery? 2025. arXiv: 2503.23771 [cs.CV]. url: https://arxiv.org/abs/2503.23771. [101] Zhenqin Wu et al. MoleculeNet: Benchmark for Molecular Machine Learning. 2018. arXiv: 1703.00564 [cs.LG]. url: https://arxiv.org/abs/1703.00564. [102] Rui Pan et al. AstroMLab 2: AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy. 2024. arXiv: 2409.19750 [astro-ph.IM]. url: https://arxiv.org/ abs/2409.19750. [103] Anass El Aouni et al. OceanBench: Benchmark for Data-Driven Global Ocean Forecasting systems. In: The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2025. url: https://openreview.net/forum?id= wZGe1Kqs8G. [104] Veeramakali Vignesh Manivannan et al. ClimaQA: An Automated Evaluation Framework for Climate Question Answering Models. 2025. arXiv: 2410 . 16701 [cs.LG]. url: https : //arxiv.org/abs/2410.16701. [105] Hongwei Liu et al. ATLAS: High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning. 2025. arXiv: 2511.14366 [cs.CL]. url: https://arxiv.org/abs/2511. 14366. 56 [106] Yansheng Qiu et al. AI Idea Bench 2025: AI Research Idea Generation Benchmark. 2025. arXiv: 2504.14191 [cs.AI]. url: https://arxiv.org/abs/2504.14191. [107] Hengxing Cai et al. SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis. 2024. arXiv: 2403.01976 [cs.CL]. url: https://arxiv.org/abs/2403.01976. [108] Yizhou Wang et al. SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines. 2025. arXiv: 2509.21320 [cs.CL]. url: https://arxiv.org/abs/2509.21320. [109] Wanghan Xu et al. Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System. [110] 2025. arXiv: 2505.20310 [cs.AI]. url: https://arxiv.org/abs/2505.20310. Jiabin Tang et al. AI-Researcher: Autonomous Scientific Innovation. 2025. arXiv: 2505.18705 [cs.AI]. url: https://arxiv.org/abs/2505.18705. [111] Yilun Zhao et al. SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks. 2025. arXiv: 2507.01001 [cs.CL]. url: https://arxiv.org/abs/ 2507.01001. [112] Haiyuan Wan et al. DeepResearch Arena: The First Exam of LLMs Research Abilities via SeminarGrounded Tasks. 2025. arXiv: 2509.01396 [cs.AI]. url: https://arxiv.org/abs/ 2509.01396. [113] Renze Lou et al. AAAR-1.0: Assessing AIs Potential to Assist Research. 2025. arXiv: 2410.22394 [cs.CL]. url: https://arxiv.org/abs/2410.22394. [114] Yujia Qin et al. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. 2023. arXiv: 2307.16789 [cs.AI]. url: https://arxiv.org/abs/2307.16789. [115] Shanghua Gao et al. Democratizing AI scientists using ToolUniverse. 2025. arXiv: 2509.23426 [cs.AI]. url: https://arxiv.org/abs/2509.23426. [116] Ziru Chen et al. ScienceAgentBench: Toward Rigorous Assessment of Language Agents for DataDriven Scientific Discovery. 2025. arXiv: 2410.05080 [cs.CL]. url: https://arxiv. org/abs/2410.05080. Jun Shern Chan et al. MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering. 2025. arXiv: 2410.07095 [cs.CL]. url: https://arxiv.org/abs/ 2410.07095. [117] [118] Yongliang Shen et al. TaskBench: Benchmarking Large Language Models for Task Automation. 2024. arXiv: 2311.18760 [cs.CL]. url: https://arxiv.org/abs/2311.18760. [119] Peter Jansen et al. DISCOVERYWORLD: Virtual Environment for Developing and Evaluating Automated Scientific Discovery Agents. 2024. arXiv: 2406.06769 [cs.AI]. url: https: //arxiv.org/abs/2406.06769. [120] Parshin Shojaee et al. LLM-SRBench: New Benchmark for Scientific Equation Discovery with Large Language Models. 2025. arXiv: 2504.10415 [cs.CL]. url: https://arxiv.org/ abs/2504.10415. 57 A. Appendix A.1. Authors Lead Authors Wanghan Xu1,2, Yuhao Zhou1,3, Yifan Zhou1,2, Qinglong Cao2, Shuo Li1,4, Jia Bu1,5 Core Authors Bo Liu6, Yixin Chen1,7, Xuming He1,8, Xiangyu Zhao1,6, Xiang Zhuang1,8, Fengxiang Wang1,9, Zhiwang Zhou1,10 Contributors Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu Scientific Directors Bo Zhang1, Dongzhan Zhou1, Shixiang Tang1,11, Jiaheng Liu1,12, Fenghua Ling1, Yan Lu1, Yuchen Ren1, Ben Fei1,11, Zhen Zhao1, Xinyu Gu1, Rui Su1, Xiao-Ming Wu6, Weikang Si13, Yang Liu14, Hao Chen1, Xiangchao Yan1, Xue Yang2, Junchi Yan2, Jiamin Wu1, Qihao Zheng1, Chenhui Li5, Zhiqiang Gao1, Hao Kong16, Junjun He1, Mao Su1, Tianfan Fu1,12, Peng Ye1,11, Chunfeng Song1, Nanqing Dong1, Yuqiang Li1, Huazhu Fu16, Siqi Sun1,17, Lijing Cheng18, Jintai Lin15, Wanli Ouyang1,11, Bowen Zhou1, Corresponding Authors Wenlong Zhang1, Lei Bai1 Main Affiliations 1 Shanghai Artificial Intelligence Laboratory 2 Shanghai Jiao Tong University 3 Sichuan University 4 Central South University 5 East China Normal University 6 The Hong Kong Polytechnic University 7 University of California, Los Angeles 8 Zhejiang University 9 National University of Defense Technology 10 Tongji University 11 The Chinese University of Hong Kong 12 Nanjing University 13 National Institute of Metrology 58 14 Aerospace Information Research Institute,Chinese Academy of Sciences 15 Peking University 16 The Agency for Science, Technology and Research (A*STAR) 17 Fudan University 18 Chinese Academy of Sciences 19 Tsinghua University A.2. Disciplines and Research Directions Overview Table 9 Disciplines And Research Directions: Overview of 10 scientific domains and representative research topics curated for scientist-aligned SGI-Bench workflows. Disciplines Research Directions Astronomy Gravitational Wave Detection and Parameter Estimation"
        },
        {
            "title": "Astronomy",
            "content": "Fast Radio Burst Detection and Localization"
        },
        {
            "title": "Molecular Interaction",
            "content": "Description Analyzing data from interferometers like LIGO and Virgo to detect gravitational waves from compact binary coalescences (black holes, neutron stars) and precisely estimate their physical properties like mass, spin, and location to test general relativity. for Searching radio telescope data millisecond-duration, extragalactic radio flashes (FRBs) and using interferometry to pinpoint their host galaxies, aiming to uncover the mysterious physical mechanisms that produce them. Utilizing the Zwicky Transient Facility (ZTF) to scan the night sky, identifying new or changing celestial objects like supernovae and kilonovae, and issuing rapid alerts to the global astronomical community for multi-wavelength follow-up observations. Applying symbolic regression and other machine learning techniques to large astronomical datasets to automatically discover novel mathematical formulas or physical laws that describe the behavior of celestial objects and phenomena. Computationally simulating and quantifying the non-covalent forces between molecules, such as hydrogen bonds and van der Waals forces, to understand molecular recognition, protein-ligand binding, and self-assembly. 59 Disciplines Research Directions Chemistry Target Based Drug Design Chemistry De Novo Drug Design Chemistry Chemical Molecular Synthesis Pathway Planning Chemistry Molecular Property Prediction"
        },
        {
            "title": "Atmospheric Differential Equation",
            "content": "Description Employing computational methods to design drug candidates that specifically bind to known biological target, such as proteins active site, thereby modulating its function to achieve therapeutic effect. Using generative AI models to computationally design entirely new molecules with desired pharmacological properties, without starting from an existing chemical scaffold, to explore novel regions of chemical space. Developing algorithms, often based on retrosynthesis, to devise the most efficient and practical multi-step reaction routes for synthesizing target molecule, optimizing for yield, cost, and sustainability. Building and applying machine learning models (e.g., QSAR) to predict key chemical and physical properties of molecules, such as toxicity, solubility, and bioactivity, to accelerate materials discovery and drug development. Using networks of seismometers to detect and analyze seismic waves from earthquakes and other sources, enabling the study of fault lines and the tomographic imaging of the Earths mantle and core. Aggregating and analyzing temperature data from sources like Argo floats and satellites to calculate the total thermal energy stored within the ocean, critical indicator for quantifying global warming and climate change. Numerically solving the complex systems of partial differential equations (e.g., NavierStokes equations) that govern atmospheric fluid dynamics and thermodynamics to produce accurate weather forecasts and climate projections."
        },
        {
            "title": "Earth",
            "content": "Typhoon Wind Pressure Relationship Developing and validating models that describe the physical relationship between typhoons central pressure and its maximum sustained wind speeds, crucial for forecasting storm intensity and assessing potential damage. 60 Disciplines Research Directions Earth Vegetation Coverage Rate Earth Glacier Estimation Earth Ozone Pollution and Its Causes Earth Emission Inversion Based on Satellite Remote Sensing and 4D-Var"
        },
        {
            "title": "Emission Inversion Based on Local\nMass Conservation",
            "content": "Description Processing satellite and aerial imagery using spectral indices like NDVI to quantify the fraction of land covered by vegetation, which is vital for monitoring ecosystem health, agriculture, and deforestation. Combining satellite altimetry, gravimetry (GRACE), and imagery to measure changes in glacier volume and mass balance over time, providing direct evidence of the impacts of climate change. Investigating the chemical reactions between precursor pollutants (like NOx and VOCs) under sunlight that form harmful ground-level ozone, and modeling its transport and concentration in urban and rural areas. Using advanced data assimilation techniques (4D-Var) to combine satellite measurements of atmospheric composition with chemical transport models, thereby inferring the location and strength of pollutant emission sources on the ground. Applying mass balance principles to highresolution measurements (e.g., from aircraft) around specific region to calculate the net flux and estimate emissions of greenhouse gases or pollutants from sources like cities or industrial facilities."
        },
        {
            "title": "Optimal Power Flow Calculation",
            "content": "Multiple Seismic Wave Attenuations Modeling the progressive energy loss of seismic waves as they propagate through different geological materials, which helps in characterizing subsurface structures and identifying resources like oil and gas. Developing algorithms to solve complex optimization problems for electrical grids, determining the best generator outputs to meet demand reliably while minimizing generation costs and transmission losses. Creating predictive models using meteorological data (wind speed, solar irradiance) and machine learning to accurately forecast the power output of wind and solar farms, which is essential for stable grid management. Fengguang New Energy Power Forecasting 61 Disciplines Research Directions Information Multimodal Understanding Information Dialogue System Information Code Generation Information Sensor Spatial Characteristics Phase Free Reconstruction"
        },
        {
            "title": "RNA Tertiary Structure Prediction",
            "content": "Description Building AI systems that can process, interpret, and reason about information from multiple sources simultaneously, such as text, images, audio, and video, to achieve more holistic understanding. Designing and training conversational AI agents (chatbots) that can engage in natural, coherent, and context-aware conversations with humans for tasks like customer service or information retrieval. Developing large language models and other AI techniques to automatically write, complete, and debug computer code based on natural language descriptions or functional specifications. Creating novel algorithms to reconstruct the spatial sensitivity pattern of sensor (like microphone or antenna) using only the magnitude of its measurements, without needing phase information, which is often difficult to obtain. Developing computational methods to determine the amino acid sequence of novel protein directly from its tandem mass spectrometry data, without relying on reference genome. Using computational models to predict the biological effects of small molecules, such as their binding targets, mechanism of action, or potential toxicity, based on their chemical structure. Analyzing high-throughput biological data (e.g., genomics, proteomics) with statistical and machine learning methods to identify molecules whose presence or level can indicate specific disease state. Identifying unique peptides that arise from mutations in cancer cells, which can be recognized by the immune system, for the development of personalized cancer vaccines and immunotherapies. Computationally predicting the complex three-dimensional folded structure of RNA molecules from their primary sequence to understand their function in cellular processes like gene regulation and catalysis. 62 Disciplines Research Directions Life Protein Structure Life Genome Function Prediction Life Automatic Development of Medical Imaging Algorithms Life AI Drug Discovery"
        },
        {
            "title": "Life",
            "content": "Revealing the Mechanisms of the Tumor Microenvironment"
        },
        {
            "title": "Life",
            "content": "Early Screening and Risk Stratification of Pancreatic Cancer Description Predicting the three-dimensional atomic coordinates of protein from its amino acid sequence using methods like deep learning (e.g., AlphaFold) or homology modeling to understand its biological function. Annotating the functions of genes, regulatory elements, and non-coding regions across the genome by integrating diverse data types like DNA sequence, gene expression, and epigenetic modifications. Creating AI-powered systems that can automatically generate and optimize image analysis pipelines for tasks like segmentation, registration, and classification in various medical imaging modalities (MRI, CT). Applying range of AI and machine learning techniques across the entire drug discovery pipeline, from identifying novel drug targets and designing molecules to predicting clinical trial outcomes. Designing and developing therapeutic strategies, such as checkpoint inhibitors or CAR-T cells, that stimulate and enhance the patients own immune system to recognize and attack cancer cells. Studying the complex interplay between cancer cells, immune cells, stromal cells, and the extracellular matrix to understand how this environment promotes tumor growth and metastasis. Using machine learning models to design and optimize antibodies with high affinity and specificity for given antigen, accelerating the development of new therapeutics and diagnostics. Developing and applying computational algorithms, particularly deep learning models, to accurately predict the 3D structure of proteins from their amino acid sequence. Developing novel diagnostic tools, such as blood-based biomarkers or AI-driven imaging analysis, to detect pancreatic cancer at an early, more treatable stage and to classify patients by risk level. 63 Disciplines Research Directions Life Protein Protein Interaction Prediction Description Developing computational methods to predict which proteins in cell will physically bind to each other, in order to map out the cellular signaling pathways and protein complexes. Life Life Life"
        },
        {
            "title": "Material",
            "content": "Biomarker Discovery"
        },
        {
            "title": "Computational Drug Design",
            "content": "Strain Metabolic Reconstruction Discovery of Immunotherapy Targets Analyzing tumor and immune cell data to identify new molecular targets, such as surface proteins or mutated peptides, that can be exploited for cancer immunotherapy. Identifying molecular signatures (genes, proteins, metabolites) in patient samples that can be used for disease diagnosis, prognosis, or predicting response to therapy. Creating comprehensive computational models of the metabolic networks of microbial strains to understand their physiology and guide metabolic engineering for producing valuable chemicals. Designing synthetic DNA or RNA sequences, such as promoters and enhancers, to precisely control the expression of specific genes for applications in biotechnology and synthetic biology. Utilizing molecular modeling, simulation, and machine learning to design and optimize small molecules that can effectively bind to biological target and modulate its activity. Engineering the untranslated regions (UTRs) and other elements of mRNA sequences to optimize their stability, translation efficiency, and immune response for next-generation vaccine development. Developing deep learning models to analyze and interpret complex medical images (e.g., X-rays, MRIs, pathology slides) to assist clinicians in diagnosis, treatment planning, and disease monitoring. Designing and synthesizing polymer-based materials that can efficiently convert waste heat into useful electrical energy, focusing on enhancing their thermoelectric figure of merit (ZT). Investigating how to use thermal energy to enhance the performance and efficiency of catalytic materials in electrochemical reactions, such as in fuel cells or water splitting."
        },
        {
            "title": "Polymer Thermoelectric",
            "content": "64 Disciplines Research Directions Material Nano Adsorption Materials Material Chloride Solid State Electrolyte Material Oxygen Evolution Reaction Catalytic Materials Material KRF Resin Polymerization Reaction"
        },
        {
            "title": "Mathematics Differential Privacy",
            "content": "Mathematics Coordinate Descent Optimization Algorithm"
        },
        {
            "title": "Equations",
            "content": "Description Developing porous nanomaterials like metal-organic frameworks (MOFs) or zeolites with high surface area and specific chemical properties for applications in gas separation, storage, and carbon capture. Researching and developing novel solidstate materials that conduct chloride ions, aiming to create safer and more energydense all-solid-state batteries. Designing efficient, stable, and low-cost catalysts to accelerate the oxygen evolution reaction (OER), key bottleneck in processes like water splitting for hydrogen production. Investigating and optimizing the chemical reaction conditions and mechanisms for the polymerization of ketone-resolformaldehyde (KRF) resins to control their final properties for industrial applications. Researching and developing organic and composite polymer materials with high electrical conductivity and low thermal conductivity for flexible and lightweight thermoelectric devices. Developing mathematical frameworks and algorithms that allow for the analysis of sensitive datasets while providing rigorous, provable guarantees about the privacy of individuals in the data. Designing and analyzing efficient optimization algorithms that solve complex problems by iteratively optimizing one variable or small block of variables at time, while keeping others fixed. Developing algorithms to accurately recover full data matrix from small subset of its observed entries, with applications in recommender systems and image inpainting. Devising and implementing stable and accurate computational algorithms (e.g., Runge-Kutta methods) for finding approximate solutions to differential equations that model real-world phenomena. 65 Disciplines Research Directions Mathematics Shortest Path Planning Neuroscience Visual Decoding Neuroscience Motion Decoding Neuroscience Emotion Recognition Neuroscience Electron Microscopy Neuron Segmentation Neuroscience Neural Activity and Behavior Prediction"
        },
        {
            "title": "Physics",
            "content": "Research on Soft Condensed Matter Physics and Glass Transition Dynamics"
        },
        {
            "title": "Deep PDE Solving to Enhance Model\nExpressiveness",
            "content": "automated Description Developing and applying graph-based algorithms like Dijkstras or A* to find the most efficient route between two points in network, with applications in logistics, robotics, and network routing. Using machine learning models to analyze brain activity patterns, typically from fMRI or electrophysiology, to reconstruct or identify the visual images person is seeing. Developing brain-computer interfaces that can interpret neural signals from the motor cortex to predict intended movements, enabling control of prosthetic limbs or external devices. Analyzing neurophysiological signals (like EEG) or behavioral cues (like facial expressions) with AI to identify and classify human emotional states. Creating computational pipelines, often using deep learning, to trace and segment individual neurons and their connections in large-scale electron microscopy volumes of brain tissue. Building statistical and dynamical models that link the activity of neural populations to specific behaviors, in order to understand the neural codes underlying perception, decision-making, and action. Using first-principles simulations (like Density Functional Theory) and many-body techniques to predict the electronic, magnetic, and structural properties of materials from fundamental quantum mechanics. Precisely measuring the splitting of atomic spectral lines in the presence of an external magnetic field to probe the quantum mechanical properties of atoms, such as electron spin and angular momentum. Investigating the physical principles governing the behavior of soft materials (polymers, colloids) and studying the complex, slow dynamics associated with the transition from liquid to glassy state. Developing novel deep learning architectures, such as physics-informed neural networks (PINNs), to solve complex partial differential equations and improve the predictive power of physics-based models. 66 Disciplines Research Directions Physics Chaotic Behavior in Circuit Systems Physics Research on General Machine Learning Potential Function Model Architecture Physics Nuclear Magnetic Resonance and Its Imaging Experiment Physics Quadrupole Mass Spectrometer"
        },
        {
            "title": "Physics",
            "content": "Research on Superconducting Mechanisms, Discovery of Superconducting Materials and Process Optimization Description Studying and modeling the emergence of chaos and other nonlinear dynamical behaviors in electronic circuits, such as the Chuas circuit, to understand fundamental principles of complex systems. Developing universal machine learning frameworks to accurately model the potential energy surface of molecular systems, enabling large-scale molecular dynamics simulations with quantum accuracy. Utilizing the principles of nuclear magnetic resonance to probe the structure and dynamics of molecules in materials and to create non-invasive medical images (MRI) of biological tissues. Studying the principles of using combined electric and magnetic fields in quadrupole mass analyzer to separate ions based on their mass-to-charge ratio for chemical analysis. Investigating the fundamental quantum mechanisms of superconductivity, computationally searching for new materials with higher critical temperatures, and optimizing their synthesis for practical applications. A.3. Cases A.3.1. Scientific Deep Research"
        },
        {
            "title": "Example of Scientific Deep Research in Astronomy",
            "content": "Question The Dispersion Measure (DM) of Fast Radio Burst (FRB) is the integrated column density of free electrons along the line of sight. The observed value, ùê∑ùëÄùëúùëèùë†, is generally considered the sum of four primary components: ùê∑ùëÄùëúùëèùë† = ùê∑ùëÄùëÄùëä + ùê∑ùëÄ‚Ñéùëéùëôùëú + ùê∑ùëÄùêºùê∫ùëÄ + ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëúùëèùë† where ùê∑ùëÄùëÄùëä is the contribution from the Milky Ways interstellar medium, ùê∑ùëÄ‚Ñéùëéùëôùëú is from the Milky Ways halo, ùê∑ùëÄùêºùê∫ùëÄ is from the intergalactic medium, and ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëúùëèùë† is the contribution from the host galaxy in the observers frame. The host contribution in its rest frame, ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëüùëíùë†ùë°, is related to the observed value by ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëüùëíùë†ùë° = ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëúùëèùë†/(1 + ùëß). The Rotation Measure (RM) describes the Faraday rotation of linearly polarized signal passing through magnetized plasma. For the host galaxy, its contribution to the RM as ùëÖùëÄ‚Ñéùëúùë†ùë°, which is highly relevant with ùêµ , the average line-of-sight magnetic field strength in the host galaxys environment, measured in microgauss (ùúáùê∫). Astronomers have precisely localized the repeating FRB 20180814A and identified its host galaxy. The total observed dispersion measure is ùê∑ùëÄùëúùëèùë† = 189.4 pc cm3, and the spectroscopic redshift of the host is ùëß = 0.06835. After subtracting the Galactic contribution, the extragalactic rotation measure is found to be ùëÖùëÄùëíùë•ùë°ùëüùëéùëîùëéùëôùëéùëêùë°ùëñùëê 655 rad m2, which is assumed 67 to originate primarily from the FRBs host galaxy environment. Based on detailed Bayesian model presented in the source paper, the total contribution from extragalactic sources (IGM + host) is determined to be ùê∑ùëÄùëíùë•ùë°ùëüùëéùëîùëéùëôùëéùëêùë°ùëñùëê,ùëúùëèùë† = 64 pc cm3, within which the IGM contribution is estimated as ùê∑ùëÄùêºùê∫ùëÄ = 45 pc cm3. Based on the information above, calculate the lower limit of the average line-of-sight magnetic field strength, ùêµ , in the FRBs host galaxy environment. Provide numerical answer in units of microgauss (ùúáùê∫), rounded to the nearest integer. Steps Step 1. Search for the relevant paper about Sub-arcminute localization of 13 repeating fast radio bursts detected by CHIME/FRB. Step 2. Based on Macquart, ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëúùëèùë† = 61.515pc cm3. Step 3. Calculate the contribution of the host galaxy to the observer coordinate system (ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëúùëèùë† = 5.885pc cm3). Step 4. Calculate the contribution of the host galaxy in the stationary coordinate system (ùê∑ùëÄ‚Ñéùëúùë†ùë°,ùëüùëíùë†ùë° = 5.508pc cm3). Step 5. Calculate the average magnetic field intensity ùêµ = 46ùúáG. Answer"
        },
        {
            "title": "Example of Scientific Deep Research in Chemistry",
            "content": "Question In computational chemistry, the accurate parsing of molecules structure is fundamental to predicting its properties. critical structural attribute is aromaticity, and its determination often follows Huckels rule. Consider the neutral molecule, an isomer of Naphthalene, represented by the following SMILES string: c1cccc2cccc-2cc1 For the entire conjugated system of this molecule to be considered aromatic, how many ùúã-electrons in total must its ùúã-electron system contain? Provide the answer as single integer. Steps Step 1. Find the article title \"DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration\". Step 2. Parse the SMILES Structure: The SMILES string c1cccc2cccc-2cc1 describes the molecule Azulene, bicyclic conjugated system formed by the fusion of five-membered ring and seven-membered ring. Correctly identifying this non-standard structure is the first hurdle. Step 3. Correspondence to Document: This step directly corresponds to the initial input processing stage shown in Figure 1 (b) DrugCoder (Page 3), where SMILES string is taken as input before the Molecule Graph Construction module. Step 4. Define the System for Analysis: The key phrase in the question is entire conjugated system. Azulenes two rings form single, continuous, planar ùúã-conjugated system. The most critical trap is to avoid analyzing the fiveand seven-membered rings separately, which would lead to an incorrect conclusion. Step 5. Correspondence to Document: This conceptual step is an implicit requirement of the Molecule Graph Construction module in Figure 1 (b) (Page 3). correct graph cannot be built without correctly identifying the holistic nature of the conjugated system, which determines the properties of the graphs nodes (atoms) and edges (bonds). 68 Step 6. Count the Total ùúã-Electrons: The entire conjugated system of Azulene is composed of 10 carbon atoms. In this neutral hydrocarbon, each carbon atom participating in the conjugation contributes one ùúã-electron. Therefore, the total number of ùúã-electrons is 10. Step 7. Correspondence to Document: This calculation is core part of the feature extraction process. This concept is explicitly mentioned in the Idea Space section (lines 12-13, Page 5 of the PDF), which suggests to extract molecular descriptors and fingerprints from the SMILES strings. The ùúã-electron count is fundamental molecular descriptor. Step 8. Verify with Huckels Rule: Apply the total ùúã-electron count (10) to Huckels rule, 4n + 2. Setting 4n + 2 = 10 gives 4n = 8, which solves to = 2. Since is an integer, the system satisfies the rule and is aromatic. The question asks for the total number of ùúã-electrons, which is 10. Step 9. Correspondence to Document: This verification step is critical for assigning correct properties to the constructed molecular graph, which is the foundation for all downstream tasks, such as ADMET Prediction mentioned in Table 1 (Page 3). An incorrect determination of aromaticity would lead to flawed graph and an inaccurate final prediction. Answer"
        },
        {
            "title": "Example of Scientific Deep Research in Earth",
            "content": "Question The diurnal variation of the NO2 column concentration Œ© over city is governed by local mass balance, incorporating emissions, chemical loss, and photochemical production. The governing equation is: Where: ùëëŒ© ùëëùë° = ùê∏(ùë°) + ùëÉ(ùë°) Œ© ùúè ùê∏(ùë°) = 3.0 ùëíùë°/ (NOùë• emission rate in molec/cm2/h, ùë° in hours starting from 8:00 AM) ùëÉ(ùë°) = 1.5 ùë° (Photochemical NO2 production rate in molec/cm2/h2) ùúè = 1.5 hours (NO2 effective lifetime) At ùë° = 1 (9:00 AM), the observed concentration is Œ©1 = 4.2. Questions: 1. What was the initial NO2 column concentration Œ©0 at ùë° = 0 (8:00 AM)? 2. At what time ùë°peak does Œ©(ùë°) reach its maximum value between 8:00 AM and 12:00 PM? 3. At the time of the peak concentration, which is larger, the photochemical production term ùëÉ(ùë°) or the emission term ùê∏(ùë°), and by how much? Round the results of the first and third questions to two decimal places. Present your final answers as numbers separated by commas. Steps Step 1. Find paper \"Constraint of anthropogenic NOùë• emissions in China from different sectors: new methodology using multiple satellite retrievals\". 69 1 Step 2. Solving for Œ©0: Corresponding Text: Equation (1) on Page 6: ùõøŒ©NOùë• problem adds chemical production term ùëÉ(ùë°) to this equation. ùëëùë° + 1 Step 3. Formulate the governing equation: ùëëŒ© Step 4. Solve this first-order linear differential equation using the integrating factor method, which is used in the paper to derive the key discrete solution (Equation (2) on Page 6). The integrating factor is ùúá(ùë°) = exp (cid:16) 2 Step 5. Integrate from the initial time (ùë° = 0) to the observation time (ùë° = 1): 1.5 Œ© = 3ùëíùë°/2 + 1.5ùë°. = exp (cid:16) 2ùë° ùõøùë° = ùê∏ . This Œ©NOùë• ùúè 3 ùëëùë° (cid:17). (cid:17) 3 3 0 0 3 (cid:104) (cid:17)(cid:105) (cid:12) (cid:12) (cid:12) Œ©0 = 4.449. exp (cid:16) 2ùë¢ (cid:17) (cid:17) (cid:2)3ùëíùë¢/2 + 1.5ùë¢(cid:3) ùëëùë¢ ùëëùë° = 9 exp(ùë°/2) + 2.25 + 7.263 exp(2ùë°/3). . Calculating the derivative values at ùë° = 1, 2, 3, 4 hours shows Œ© exp (cid:16) 2ùë° = 1 Step 6. Step 7. This yields Œ©1 exp (cid:16) 2 Step 8. Substitute Œ©1 = 4.2 and solve for Œ©0: (4.2 1.9477) Œ©0 4.449, resulting in Œ©0 3.73. Step 9. Solving for ùë°peak: Corresponding Text: At the peak, ùëëŒ© ùëëùë° = 0, which is direct application of the mass conservation equation. The analysis must also consider the assumptions of short lifetime and photochemistry dominance mentioned on Page 7. Step 10. Find the complete function describing concentration evolution over time, Œ©(ùë°). Solving the differential equation gives: Œ©(ùë°) = 18 exp(ùë°/2) + 2.25ùë° 3.375 10.894 exp(2ùë°/3). Step 11. Differentiate Œ©(ùë°): ùëëŒ© Step 12. Analyze the sign of ùëëŒ© ùëëùë° it is consistently positive. Step 13. Conclusion: Within the given time window [0, 4] hours, the concentration Œ©(ùë°) is monotonically increasing, and no peak occurs. This means the strength of the sources (ùê∏(ùë°) + ùëÉ(ùë°)) is always greater than the sink (Œ©/ùúè) throughout the morning. Step 14. Comparing ùëÉ(ùë°) and ùê∏(ùë°): Corresponding Text: core aspect of the papers method is analyzing contributions from different sources (e.g., the four emission sectors). Here we compare two different source terms. Step 15. Since the concentration is monotonically increasing with no peak, we choose the end of the time window (ùë° = 4) to assess the relative importance of the sources. Step 16. Calculate the values at ùë° = 4: ùê∏(4) = 3.0 ùëí2 0.406. Step 17. ùëÉ(4) = 1.5 4 = 6.0. Step 18. Compare and calculate the difference: ùëÉ(4) ùê∏(4) 5.59. This result indicates that at this time, photochemical production has become significantly more important source of NO2 than anthropogenic emissions. Step 29. Final Answer: 3.73, no peak, 5.59 Answer 3.73, no peak, 5."
        },
        {
            "title": "Question\nA parabolic trough solar collector at steady state follows the energy balance",
            "content": "and instantaneous efficiency ùëûùë¢ = ùêπùëü (cid:2)ùêæùúÉ(ùúèùõº)ùê∫ ùëàùêø(ùëá ùëì ùëáùëé)(cid:3) ùúÇ = ùëûùë¢ ùê∫ . 70 The heat removal factor depends on mass flow via ùêπùëü = (cid:20) (cid:164)ùëöùëê ùëù ùê¥ùëàùêø 1 exp (cid:18) ùêπ ùê¥ùëàùêø (cid:164)ùëöùëê ùëù (cid:19)(cid:21) . Given: ùêπ = 0.94, ùê¥ = 6.00 m2 (receiver heat-transfer area), ùëàùêø = 2.20 W/m2 K, (ùúèùõº) = 0.90, ùêæùúÉ = 0.96, ùê∫ = 950 W/m2, ùëá ùëì = 150C, ùëáùëé = 35C, ùëê ùëù = 4180 J/kg K, and baseline mass flow (cid:164)ùëö = 0.12 kg/s. Answer the following (round to two decimals; use ENGLISH commas, no spaces, no units): (1) Baseline heat removal factor ùêπùëü. (2) Baseline efficiency ùúÇ. (3) Minimum mass flow (kg/s) required to guarantee ùúÇ 0.58 under the same operating conditions. Steps Step 1. Find paper 2D-interval forecasts for solar power production. Step 2. Compute temperature difference: Œîùëá = ùëá ùëì ùëáùëé = 150 35 = 115 K. Step 3. Compute absorbed solar term with IAM: ùëÜ = ùêæùúÉ(ùúèùõº)ùê∫ = 0.960.90950 = 0.864950 = 820.80 W/m2. Step 4. Compute loss term: ùëàùêøŒîùëá = 2.20 115 = 253.00 W/m2. Step 5. Baseline heat removal factor ùêπùëü: first find (cid:164)ùëöùëê ùëù = 0.12 4180 = 501.60 W/K, and ùê¥ùëàùêø = 6.00 2.20 = 13.20 W/K. Define ùë• = ùêπ ùê¥ùëàùêø 501.60 = 0.02474. Then (cid:164)ùëöùëê ùëù ùêπùëü = 1ùëíùë• 0.02474 0.99 (more precisely 0.9880.989). (1) ùêπùëü = 0.99 (two decimals). Step 6. Baseline useful gain and efficiency: ùëûùë¢ = ùêπùëü (ùëÜ ùëàùêøŒîùëá) = 0.989 (820.80 253.00) 0.989 567.80 561.60 W/m2. ùúÇ = ùëûùë¢/ùê∫ = 561.60/950 = 0.5912 (2) 0.59. Step 7. Target efficiency requirement: ùúÇtarget = 0.58 required heat removal factor ùêπùëü,req = ùúÇtarget ùê∫ ùëÜùëàùêøŒîùëá = 0.58950 Step 8. Solve for minimum mass flow producing ùêπùëü ùêπùëü,req using ùêπùëü = 1ùëíùë• small ùë•, 1ùëíùë• Then (cid:164)ùëöùëê ùëù = ùêπ ùê¥ùëàùêø decimals). Step 9. Check: With (cid:164)ùëö = 0.05 kg/s, ùë• = 12.408/(0.05 4180) = 12.408/209 0.0594 ùêπùëü 1ùëí0.0594 0.0594 0.97, yielding ùúÇ 0.58 as required. . For 2 . Set 1 ùë• 2 0.9704 ùë• 0.0592. 4180 = 0.0501 kg/s (3) 0.05 (two is monotone decreasing in ùë• and 1 ùë• 0.0592 = 209.6 W/K (cid:164)ùëö = (cid:164)ùëöùëê ùëù ùë• = 12.408 ùë• = 1ùëí0.02474 with ùë• = ùêπ ùê¥ùëàùêø (cid:164)ùëöùëê ùëù 567.80 = 551.00 567.80 = 0.9704. = 0.9413.20 501.60 = 12.408 = 209.6 ùëê ùëù ùë• ùë• Answer 0.99,0.59,0."
        },
        {
            "title": "Example of Scientific Deep Research in Information",
            "content": "Question In the research of electromagnetic measurement focusing on broadband planar near-field ùê∏-field reconstruction, microstrip patch-based 4 5 array antenna is used as the Antenna Under Test (AUT). The AUTs planar near-field scanning is performed in region close to its aperture, and the ùê∏-field at this region is transformed to two parallel observation planes (ùëÜ1 and ùëÜ2) via spatial convolution. The transformation satisfies the field distribution similarity theory: the ratio of the observation distances (ùëë2/ùëë1) between ùëÜ2 and ùëÜ1 equals the ratio of the corresponding test frequencies ( ùëì2/ ùëì1). For the ùê∏-field dataset on ùëÜ2 (target frequency ùëì2), undersampling is applied (sampling interval larger than ùúÜ2/2, where ùúÜ2 is the wavelength at ùëì2) to form defective dataset ùëã2. To reconstruct ùëã2, K-means clustering is first used to classify 71 2 , with the optimal number of clusters determined by the elbow point of the SSE (sum of ùëã squared errors) curve. Then Voronoi cell classification is employed, where the comprehensive index ùêø( ùëùùëö) = ùëû1ùëÜ( ùëùùëö) + ùëû2 ùê∑( ùëùùëö) (ùëû1 + ùëû2 = 1) is calculated to divide each cluster into deep interpolation regions (requiring 24 supplementary samples per point) and shallow interpolation regions (requiring 8 supplementary samples per point). It is known that: 1) The test frequency ùëì1 = 28 GHz, and the observation distance ùëë1 = 214.29 mm (corresponding to 20ùúÜ1, ùúÜ1 is the wavelength at ùëì1); 2) The scanning area of the near-field region close to the AUT aperture is square, and the sampling interval of ùëã2 is 0.8ùúÜ2; 3) The total number of sampling points in ùëã2 is 1681; 4) For specific cluster after K-means classification, the normalized cell area ùëÜ( ùëùùëö) of sampling points in the deep interpolation region is 1.2 times that of points in the shallow region, and the normalized gradient ùê∑( ùëùùëö) of shallow region points is 0.7 times that of deep region points; 5) The weight ùëû1 is set to 0.6 to prioritize area-based judgment for dynamic clusters. If the number of sampling points in this cluster where ùêø( ùëùùëö) 0.6 is 112, calculate the total number of supplementary interpolation samples for this cluster, unit: pieces. Do not keep any decimal places in the result. Steps Step 1. Retrieve core data from the paper \"An Efficient Data Reconstruction Method for Broadband Planar Near-Field Measurements Based on the Field Distribution Similarity.\" Step 2. From Section III.A \"Simulations\": ùëã 2 (defective dataset at ùëì2) is 41 41 sampling 2 = 41 41 = 1681; optimal K-means clustering number grid, so total sampling points of ùëã ùëò = 5 (determined by SSE curves elbow point); deep interpolation requires 24 samples per point, shallow interpolation requires 8 samples per point. Step 3. Calculate the total number of sampling points in the target cluster: ùëã 2 is evenly divided into 5 clusters (papers clustering logic for uniform data distribution). Single cluster points = Total ùëã 2 points ùëò = 1681 5 = 336.2. Since sampling points are discrete integers, round to the nearest integer: 336 pieces. Step 4. Determine the number of deep and shallow interpolation points in the cluster: The question specifies deep region points = 1 3 = 112 pieces; shallow region points = Total cluster points - Deep region points = 336 112 = 224 pieces. (This ratio is consistent with the papers \"deep regions are undersampled, sparse points\" logic, no fabricated data.) Step 5. Calculate total supplementary interpolation samples: Supplementary samples for deep region = Deep region points Samples per deep point = 112 24 = 2688 pieces; Supplementary samples for shallow region = Shallow region points Samples per shallow point = 224 8 = 1792 pieces; Total supplementary samples = 2688 + 1792 = 4480 pieces. Answer 4480 3 of cluster total points. Deep region points ="
        },
        {
            "title": "Example of Scientific Deep Research in Life",
            "content": "Question In the DeepSTARR model, human enhancer contains two identical p53 core motifs (RRRCWWGYYY) at positions +50 and +150. Experimental data show: Mutating the +50 motif alone reduces H3K27ac signal to 35% of wild-type Mutating the +150 motif alone reduces H3K27ac signal to 82% of wild-type DNase footprinting shows TF binding at the +50 motif but no binding at the +150 motif 72 Changing the 5 flanking sequence of the +150 motif from GGG to CTC confers TF binding ability Known effects of flanking sequences on p53 binding: Optimal flank GGG : increases binding affinity by 8-fold Suboptimal flank CTC : increases binding affinity by 3-fold Random flank: binding affinity = 1 (baseline) Assume H3K27ac signal strength is proportional to p53 binding affinity, and total signal equals the sum of both motifs binding affinities. If the +50 motif flank is changed from GGG to CTC and the +150 motif flank is changed from GGG to CTC, what is the predicted H3K27ac signal as percentage of wild-type? The result retains the integer. Steps Step 1. Find the article title DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers Step 2. Determine wild-type binding affinities +50 motif: flank GGG affinity = 8 (Article: Fig. 4 & related text flanking sequences significantly influence motif importance by altering TF binding affinity) +150 motif: flank GGG but no DNase footprint affinity = 1 (Article: Fig. 6d motifs without DNase footprints show minimal functional contribution) Step 3. Total affinity = 8 + 1 = 9. Step 4. Calculate modified binding affinities +50 motif: flank CTC affinity = 3 (Article: Fig. 4b flanking sequences quantitatively modulate motif contribution) +150 motif: flank CTC affinity = 3 (now gains binding ability) Step 5. Total affinity = 3 + 3 = 6. Step 6. 4. Calculate signal percentage Step 7. Modified signal = 100% 66.7% 67, So the answer is 67 (Article: Linear relationship between binding affinity and enhancer activity demonstrated in multiple figures) Answer 67 (cid:16) 6 9 (cid:17)"
        },
        {
            "title": "Example of Scientific Deep Research in Material",
            "content": "Question Polymer composite materials have the advantages of flexibility, low cost, and environmental friendliness, and are considered the most promising candidate materials for low-grade heat collection, thermal sensing, and sustainable energy development. Solid-state ùëñ-TE materials can undergo thermal power changes according to electrode conditions in fixed temperature and humidity environment. So, when the relative humidity increases from 50% to 70%, what changes will occur in the thermal power of the poly(vinylidene fluoride-co-hexafluoropropane) sample on the ùëù-type dual copper electrode? Steps Step 1. Find paper: Reversible bipolar thermopower of ionic thermoelectric polymer composite for cyclic energy generation Understanding the working principle of poly (vinylidene fluoride-coStep 2. hexafluoropropane) materials for p-type dual copper electrodes: the porous structure and hydrophilicity of sodium salts tend to absorb moisture from humid environments and can fill 73 the space of the poly (vinylidene fluoride-co-hexafluoropropane) matrix, Step 3. Identifying the impact of increased water absorption on thermopower: increased water absorption leads to an increase in thermopower (i.e., the Seebeck coefficient, ùëÜ), but does not alter the p-type characteristics of the material, Step 4. The result of comparative reasoning is that when the relative humidity increases from 50% to 70%, the thermopower of the poly (vinylidene fluoride-co-hexafluoropropane) sample of the p-type dual copper electrode will increase. Answer Increase Example of Scientific Deep Research in Math Question third-order homogeneous linear ordinary differential equation, ùëì (ùëß) 3 ùëì (ùëß) + ùõΩ ùëì (ùëß) = 0 (where ùõΩ is real parameter), is analyzed using Legendre collocation matrix method. The function ùëì (ùëß) is approximated by truncated Legendre series with ùëÅ = 3. To determine the coefficient vector ùê¥ = [ùëé0, ùëé1, ùëé2, ùëé3]ùëá , 4 4 homogeneous linear system (cid:101)ùëä ùê¥ = 0 is constructed. For the system to have non-trivial solution, it must satisfy the following four conditions: ùëì (0) = 0, ùëì (0) = 0 The differential equation is satisfied at the collocation point(z=1). The differential equation is satisfied at the collocation point(z=-1). For the system to have non-trivial solution, the parameter ùõΩ must satisfy ùõΩ2 = ùêæ. Calculate the value of the constant ùêæ. Round your answer to the nearest integer. Steps Step 1. Find the article title Numerical solution for high-order linear complex differential equations with variable coefficients Step 2. Establish High-Order Derivative Relations. The ùëõ-th derivative is expressed in matrix form as ùëì (ùëõ) (ùëß) = ùêø(ùëß)(ùëÄùëá )ùëõ ùê¥. For ùëÅ = 3, the third derivative matrix (ùëÄùëá )3 is calculated, yielding the critical simplification ùëì (ùëß) = 15ùëé3 for any ùëß. Step 3. Position in Paper: This leverages the core matrix relation for derivatives, Formula (2.4). Step 4. Formulate System Rows from Initial Conditions. The conditions at ùëß = 0 provide two linear constraints on the coefficients: ùëì (0) = ùëé0 0.5ùëé2 = 0 = ùëé2 = 2ùëé0 ùëì (0) = ùëé1 1.5ùëé3 = 0 = ùëé1 = 1.5ùëé3 Step 5. Position in Paper: This step converts the initial conditions into matrix form, as described by the process leading to Formula (2.10). Step 6. Formulate System Rows from Collocation Points. The differential equation ùëì (ùëß) 3 ùëì (ùëß) + ùõΩ ùëì (ùëß) = 0 is evaluated at ùëß = 1 and ùëß = 1, yielding two equations: At ùëß = 1: ùõΩùëé0 + ( ùõΩ 3)ùëé1 + ( ùõΩ 9)ùëé2 + ( ùõΩ 3)ùëé3 = 0 At ùëß = 1: ùõΩùëé0 ( ùõΩ + 3)ùëé1 + ( ùõΩ + 9)ùëé2 ( ùõΩ + 3)ùëé3 = 0 Step 7. Position in Paper: This applies the collocation method, transforming the differential equation into an algebraic system at specific points, as outlined in Formulas (2.7) through (2.9). Step 8. Reduce the System and Solve the Determinant Condition. Substitute the relations ùëé2 = 2ùëé0 and ùëé1 = 1.5ùëé3 from Step 2 into the two equations from Step 3. This reduces the 4 4 system to 2 2 homogeneous system for variables ùëé0 and ùëé3. 74 (cid:40)(3ùõΩ 18)ùëé0 + (2.5ùõΩ 7.5)ùëé3 = 0 (3ùõΩ + 18)ùëé0 (2.5ùõΩ + 7.5)ùëé3 = 0 Step 9. For non-trivial solution to exist, the determinant of this 2 2 coefficient matrix must be zero: det (cid:18) (cid:20)3ùõΩ 18 2.5ùõΩ 7.5 (cid:21) (cid:19) 3ùõΩ + 18 (2.5ùõΩ + 7.5) = 0 Step 10. Solving this determinant equation yields 2ùõΩ2 36 = 0, which simplifies to ùõΩ2 = 18. Step 11. Position in Paper: The requirement for non-trivial solution (det( (cid:101)ùëä) = 0) is the fundamental principle for determining coefficients, as discussed following Formula (2.12). Answer Example of Scientific Deep Research in Neuroscience Question Motor imagery tasks in braincomputer interfaces (BCIs) are usually designed around activity in the sensorimotor cortex, since this region is central to planning and controlling movement. However, accurate decoding of motor imagery does not rely solely on motor areas. Many studies have shown that other brain regions also become active during imagery tasks, especially when visual feedback or focused attention is involved. These additional signals can provide valuable features for classifiers, improving decoding accuracy. Understanding which non-motor regions contribute is important for both electrode placement and interpretation of neural mechanisms in BCI research. Which one cerebral lobe, besides sensorimotor cortex, often contributes significantly to motor imagery decoding? Please do not use abbreviations in your answer. Steps Step 1. Review the major cerebral lobes: The frontal lobe has motor-related areas; the parietal lobe supports attention and sensory integration; the occipital lobe handles visual processing and feedback, which can aid motor imagery decoding; the temporal lobe mainly handles auditory and memory functions. Step 2. Analyse brain regions become active during motor imagery tasks: Besides frontal lobe which directly mediates motor, check for other function required in motor imagery tasks. Visual feedback can significantly improves decoding accuracy. Step 3. Conlusion: The occipital lobe is the location of the primary visual cortex, whose core function is to receive and process visual informationvisual feedback in motor imagery tasks. Answer Occipital lobe"
        },
        {
            "title": "Example of Scientific Deep Research in Physics",
            "content": "Question In iron-based superconductors, the tight-binding model describes the low-energy electronic structure. Using the five-orbital model Hamiltonian ùêª = k,ùúé ùëñ, ùëó ùë°ùëñ ùëó (k)ùëê ùëñùúé (k)ùëê ùëóùúé (k), 75 where ùë°ùëñ ùëó (k) includes nearest-neighbor (NN) and next-nearest-neighbor (NNN) hopping integrals. For LaFeAsO, the NN hopping between ùëëùëß2 orbitals is ùë°1 = 0.3 eV, and the NNN hopping is ùë°2 = 0.2 eV. Calculate: 1. The effective hopping amplitude ùë°eff at the Œì point (k = (0, 0)) for ùëëùëß2 orbitals. 2. The superconducting gap Œî(k) at = (ùúã, 0) using the gap equation Œî(k) = ùëâ (k k) (cid:17) tanh (cid:16) ùê∏ (k ) 2ùëòùêµùëá 2ùê∏(k) Œî(k), assuming ùëâ (q) = 0.5 eV and ùëá = 4.2 K. 3. The critical temperature ùëáùëê if the gap magnitude Œî0 is 5 meV, using the BCS relation Œî0 = 1.76ùëòùêµùëáùëê. Numerical value with 2 decimal place. Steps Step 1. From \"Iron-based superconductors: Current status of materials and pairing mechanism\" Step 2. Extract NN hopping ùë°1 = 0.3 eV and NNN hopping ùë°2 = 0.2 eV for ùëëùëßùëß orbitals from \"Band structure and modeling\". Step 3. At Œì point (k = (0, 0)), the dispersion is ùê∏(k) = 2ùë°1(cos 0 + cos 0) 4ùë°2(cos 0 + cos 0) = 2(0.3)(2) 4(0.2)(2) = 1.2 1.6 = 0.4 eV. The effective hopping amplitude ùë°eff is derived from the coefficient of cos ùëòùë• + cos ùëò ùë¶, giving ùë°eff = 0.3 + 0.2 = 0.1 eV (Section 3.1). Step 4. For Œî(k) at = (ùúã, 0), use ùê∏(k) = ùúâ2(k) + Œî2(k). Assume ùúâ(k) = 2ùë°1 cos ùëòùë• 2ùë°1 cos ùëò ùë¶ and Œî(k) = Œî0. At ùëá = 4.2 K, tanh (cid:16) low-energy states. Substituting ùëâ (q) = 0.5 eV, the gap equation simplifies to (cid:17) ùê∏ 2ùëòùêµùëá 1 for With ùê∏ = (0.3)2 + (0.005)2 0.3 eV, Œî(ùúã, 0) = ùëâ 1 2ùê∏ Œî0. Œî(ùúã, 0) = 0.5 1 2 0. 0.005 = 0.04 eV (Section 4.2). Step 5. For ùëáùëê, use the BCS relation Œî0 = 1.76 ùëòùêµùëáùëê. Rearranging gives ùëáùëê = Œî0 Œî0 = 5 meV = 0.005 eV and ùëòùêµ = 8.617 105 eV/K, 1.76 ùëòùêµ . Substituting ùëáùëê = 0. 1.76 8.617 105 33.14 (Section 5.1). Step 6. Verify consistency with experimental ùëáùëê = 26 for LaFeAsO1ùë•Fùë• (Section 2.1). The calculated ùëáùëê = 33.14 aligns with theoretical predictions for optimized doping (Section 2.3). Step 7. Cross-reference all parameters with \"Materials: bulk\" section (Page 3), confirming ùë°1, ùë°2, and ùëâ values. Answer -0.1, 0.04, 33.14 76 A.3.2. Idea Generation Example of Idea Generation in Astronomy Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork Palomar Transient Factory (PTF): Predecessor to ZTF using the same telescope but smaller camera, providing moderate survey speed and limited temporal coverage. PTF pioneered timedomain transient discovery but suffered from longer readout times and lower areal coverage. Sloan Digital Sky Survey (SDSS): Large-area multi-band imaging survey with significant contributions to extragalactic and stellar astrophysics, but with relatively limited cadence and not optimized for rapid transient detection. Pan-STARRS: Wide-field survey with high sensitivity, flexible cadence, and broad range of science outputs. While highly productive, it does not reach ZTFs survey speed or alert distribution rate. ATLAS, ASAS-SN, and CRTS: Dedicated time-domain surveys with wide fields and rapid cadences, enabling rapid transient detection. However, these typically have smaller apertures and shallower depth compared to ZTF, restricting discovery of fainter phenomena. Dark Energy Survey (DES): Deep survey with the Dark Energy Camera, high image quality, and excellent photometric calibration. DES is less optimized for high-cadence wide-area transient monitoring due to smaller field of view and longer exposure times. Challenges Maximizing volumetric survey speedcombining wide field, fast readout, and high sensitivityto enable rapid, repeated coverage of large sky areas for transient discovery. Minimizing image artifacts and systematic errors to ensure precision in photometric and astrometric measurements across large, curved focal plane. Providing prompt, reliable, and information-rich alerts for real-time identification and classification of astrophysical transients and moving objects. Efficiently handling massive data volumes and complex processing requirements to deliver near-real-time data products and alerts to the community. Maintaining high photometric and astrometric accuracy in the presence of instrumental, atmospheric, and sky-background variability. Limitation Previous surveys were limited by smaller camera fields of view, slower readout and overheads, less optimized scheduling, and less sophisticated data pipelines, resulting in lower time-domain sampling, slower alert generation, and reduced ability to detect fast or faint transients across wide areas. Motivation The accelerating demand for high-cadence, wide-area sky monitoring in time-domain astronomyspanning supernovae, variable stars, NEOs, and multi-messenger counterpartsnecessitates system that surpasses existing surveys in speed, coverage, and data accessibility. Addressing limitations in cadence, alert timeliness, and survey efficiency is critical for enabling rapid discovery and follow-up of astrophysical transients, as well as for preparing the community for next-generation surveys like LSST. TaskObjective Develop and implement an integrated, high-speed, wide-field optical time-domain survey system capable of delivering near-real-time discovery, classification, and alerting of transient, 77 variable, and moving objects, while providing high-quality calibrated data products and supporting broad range of time-domain astrophysics. ExistingSolutions PTF: Utilized CCD camera on the Palomar 48-inch telescope for transient discovery with moderate areal coverage and cadence. Enabled systematic transient searches but constrained by small field of view and longer readout times. SDSS and Pan-STARRS: Both provided large-scale sky mapping and multi-filter photometry, but with relatively slow cadence and areal throughput unsuitable for rapid time-domain science. ATLAS and ASAS-SN: Optimized for rapid all-sky cadence and automated transient detection but limited in depth due to smaller apertures and less sensitive instrumentation. Alert and data distribution less feature-rich than ZTFs planned system. DES: Leveraged large, high-quality camera for deep imaging and science, but with narrower field and less frequent temporal sampling, making it suboptimal for high-cadence transient monitoring. Reference Answer Idea ZTF pioneers new era of high-speed, wide-field time-domain astronomy by equipping the Palomar 48-inch Schmidt telescope with custom-built CCD mosaic camera, optimized scheduling, and robust data system. It delivers an order of magnitude survey speed improvement, rapid image processing, and real-time, feature-rich alert stream, positioning ZTF as both state-of-the-art survey and testbed for LSST-scale time-domain operations. ImplementationSteps 1: Design and assemble large-format CCD mosaic camera with minimal chip gaps and high quantum efficiency, optimized for the Palomar Schmidt focal plane. 2: Upgrade telescope mechanics, optics, and control software for fast slewing, low overhead, and image quality preservation over the expanded field. 3: Develop and deploy robotic observing system and integer-linear-programmingbased survey scheduler to maximize nightly volumetric coverage and cadence. 4: Implement on-site, lossless data compression and high-speed transfer of image data to the IPAC processing center. 5: Process raw images through automated calibration pipelines: bias subtraction, flat-field correction, astrometric and photometric calibration, and artifact masking. 6: Generate coadded reference images using quality-filtered, multi-epoch stacks for each field, filter, and CCD quadrant. 7: Perform image differencing using the ZOGY algorithm to detect transient and moving sources at high significance. 8: Extract candidate sources, compute pixel-based features, and apply machine learning (Real-Bogus) for initial classification. 9: Package candidates with contextual data (cross-matches, light curves, images) into Avro alert packets and distribute in real time via Kafka queues. 10: Archive all processed data products, catalogs, and alerts at IRSA and provide public access according to survey data release policies. 11: Publish light curves from direct imaging for variable and periodic sources, and implement dedicated pipelines for moving object detection and orbit determination. 12: Conduct on-sky performance validation and commission the system with early science and rapid feedback loops for further optimization. ImplementationOrder 1-2 78 2-3 3-4 4-5 5-6 6-7 7-8 8-9 5-10 7-11 1-12 Data The primary dataset comprises optical images acquired with the Palomar 48-inch Schmidt telescope using 16-CCD, 6144x6160-pixel mosaic camera, covering 47.7 deg2 per exposure in g, r, and bands. Each exposure delivers science and auxiliary (guide/focus) CCD data, with per-night cadences ranging from minutes to once every three days. The system produces processed images, photometry catalogs, coadded references, image subtractions, light curves, and alert packets, all archived at IRSA. Early data include thousands of exposures, millions of cataloged sources, and time-series data for variable and transient objects. EvaluationMetrics Volumetric Survey Speed: Spatial volume probed per unit time for transient detectability at given absolute magnitude; incorporates field of view, sensitivity, and overheads. Image Quality: Median delivered PSF FWHM in arcseconds (e.g., 2.0\" in band). Limiting Magnitude: Median five-sigma detection limit in g, r, bands for standard exposure durations. Photometric Repeatability: Standard deviation of calibrated flux for non-varying sources (e.g., <10 mmag for bright stars). Astrometric Accuracy: Median positional residuals relative to reference catalog (e.g., Gaia). Alert Latency: Time from image acquisition to alert distribution (target: 4 minutes). Transient Yield: Number of confirmed supernovae and other transient discoveries per unit time. Moving Object Detection: Number and recovery rate of Near-Earth Asteroids and other small bodies identified and reported to the MPC. Data Throughput: Sustained image and alert processing rates under full survey cadence. ExpectedOutcome The ZTF system achieves >10 improvement in survey speed over PTF, routinely reaching 20.620.8 mag (r,g bands, 30s, 5ùúé) with 2.02.1\" image quality and <4-minute alert latency. Early operations yielded 38 spectroscopically classified supernovae (15 unique to ZTF), discovery of new Near-Earth Asteroids, and high-fidelity variable star and asteroid light curves. ZTF anticipates streaming 1 million alerts per night and delivering public data releases, thereby providing an essential precursor to LSST-scale time-domain surveys and enabling rapid, comprehensive follow-up of transients and solar system discoveries."
        },
        {
            "title": "Example of Idea Generation in Chemistry",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork 79 Gomez-Bombarelli et al. (2016): Proposed VAE that generates SMILES strings character by character. The model learns continuous latent space but frequently decodes to invalid SMILES, limiting the generation of chemically valid molecules. Kusner et al. (2017): Introduced Grammar VAE (GVAE), extending SMILES-based VAE by integrating syntactic constraints derived from context-free grammar, improving validity but still limited by the inability of grammar to fully encode chemical rules. Dai et al. (2018): Syntax-directed VAE (SDVAE) incorporates both syntactic and semantic constraints using attribute grammars, yielding further validity gains, though chemical correctness is not entirely guaranteed. Simonovsky & Komodakis (2018): GraphVAE generates molecular graphs via adjacency matrices and atom label prediction. While it addresses the linearization problem of SMILES, validity and scalability for larger and more complex molecules remain challenging. Li et al. (2018): Atom-by-atom graph generation via LSTM. This approach can model arbitrary graphs but often passes through chemically invalid intermediate states, resulting in incomplete validity guarantees and inefficiencies. Challenges Direct generation of molecular graphs from continuous latent representations is challenging due to the combinatorial nature of graph structures and strict chemical validity constraints. SMILES-based generative models struggle to enforce chemical validity and do not offer smooth latent spaces for molecular similarity. Atom-by-atom or edge-by-edge graph generation approaches often produce invalid intermediate structures, leading to low efficiency and limited chemical feasibility. Capturing both coarse-grained (substructure) and fine-grained (atomic connectivity) molecular features in unified generative framework. Limitation Existing approaches either operate on linearizations (e.g., SMILES), lacking direct correspondence to molecular structure and chemical validity, or generate graphs atom by atom, frequently passing through invalid intermediates. Even grammarand syntax-driven models cannot ensure full chemical correctness or smoothness in the latent space, limiting their utility for property-driven molecular design. Motivation Automating molecular design demands generative models that can create chemically valid, novel, and property-optimized molecules. Existing stringand atom-based methods fail to guarantee validity or exploit molecular substructure regularities. Addressing these gaps is critical for accelerating drug discovery and enabling efficient, reliable inverse molecular design. TaskObjective To develop generative model that directly produces chemically valid molecular graphs from continuous latent representations, supporting both unconstrained generation and propertydriven molecular optimization. ExistingSolutions CVAE (Gomez-Bombarelli et al., 2016): Learns continuous latent space for SMILES string generation. Achieves smooth interpolations but poor validity due to unconstrained syntax. GVAE (Kusner et al., 2017): Imposes syntactic constraints via grammar-based decoding, improving string validity but not fully encoding chemical rules. SD-VAE (Dai et al., 2018): Incorporates additional semantic constraints with attribute grammars, further improving validity but still limited by the expressivity of the grammar in capturing chemical feasibility. GraphVAE (Simonovsky & Komodakis, 2018): Directly generates molecular graphs via 80 adjacency matrices. Avoids string limitations but faces scalability and validity issues for larger molecules. Atom-by-Atom LSTM (Li et al., 2018): Autoregressive graph generation at the atomic level. Capable of arbitrary graph synthesis but inefficient due to invalid intermediate structures. Reference Answer Idea The core idea is to represent molecules as junction trees of valid chemical substructures, enabling two-stage variational autoencoder: first generating tree-structured scaffold of subgraphs, then assembling these into molecular graph using message passing. This approach maintains chemical validity throughout generation, leveraging coarse-to-fine modeling for efficient, valid, and property-driven molecular graph synthesis. ImplementationSteps 1: Apply tree decomposition to each molecular graph to construct its junction tree of valid substructures (clusters). 2: Encode the molecular graph using message passing neural network to obtain graph latent representation. 3: Encode the junction tree using tree message passing neural network to obtain tree latent representation. 4: Concatenate tree and graph embeddings to form the full latent representation. 5: Decode the latent representation by first generating the junction tree in top-down, sequential fashion via tree decoder with feasibility checks and teacher forcing during training. 6: Assemble the molecular graph from the predicted junction tree by sequentially merging clusters using graph decoder and scoring candidate subgraph combinations. 7: For stereochemistry, enumerate possible isomers of the generated graph and select the best via neural scoring. 8: For property-driven optimization, jointly train property predictor with JT-VAE and perform gradient-based or Bayesian optimization in the latent space. 9: Evaluate reconstruction, validity, property optimization, and neighborhood smoothness using standardized benchmarks. ImplementationOrder 1-2 1-3 2-4 3-4 4-5 5-6 6-7 4-8 5-9 6-9 7-9 8-9 Data The primary dataset is the ZINC molecular database (Kusner et al., 2017 split), containing approximately 250,000 drug-like molecules. Molecules are represented as graphs with atom and bond features, and decomposed into cluster vocabularies of 780 unique substructures (including rings, bonds, and atoms). The dataset is utilized for training, validation, and testing of molecular generation and optimization. EvaluationMetrics Reconstruction Accuracy: Percentage of input molecules correctly reconstructed from their latent representations (Monte Carlo estimate over multiple samplings). Validity: Proportion of generated molecules that are chemically valid, as checked by cheminformatics tools (RDKit). Novelty: Fraction of generated molecules not present in the training set, indicating generative diversity. Optimization Improvement: Average increase in target property (e.g., penalized logP) achieved via optimization, often reported with similarity constraints. Similarity: Tanimoto similarity between original and optimized molecules, measured via Morgan fingerprints. Predictive Performance: Log-likelihood and root mean squared error (RMSE) of property prediction models (e.g., sparse Gaussian process) trained on latent encodings. Success Rate: Fraction of optimization trials where valid, property-improved molecules satisfying similarity constraints are found. ExpectedOutcome JT-VAE achieves 100% validity in generated molecules, surpassing all prior baselines (e.g., SDVAE: 43.5%, Atom-by-Atom LSTM: 89.2%), with 76.7% reconstruction accuracy. For property optimization, it discovers molecules with target scores up to 5.3 (vs. 4.04 from SD-VAE), and achieves over 80% success in constrained optimization with >0.4 similarity, demonstrating both validity and smoothness in latent space. The model enables scalable, property-driven molecular design with significant accuracy and efficiency gains."
        },
        {
            "title": "Example of Idea Generation in Earth",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork Viljanen et al. (2018): Compared approaches using photogrammetric canopy height models, images, and vegetation indices from UAVs in estimating grass sward biomass, reporting strong results but site-specific dependencies. Michez et al. (2019): Mapped and monitored pasture biomass and grazing using UAVbased sward height and reflectance data, demonstrating promise but limited by environmental variability and DTM availability. Lussem et al. (2018): Evaluated RGB-based vegetation indices from UAV imagery for forage yield estimation, predominantly using NDVI and linear regression, revealing moderate-to-strong correlations but suffering from index saturation and reduced transferability. Insua et al. (2019): Coupled UAV imagery with crop simulation for spatial-temporal pasture growth estimation, but introduced complexity by integrating simulation models and site-specific variables. Challenges Accurate, spatially comprehensive, and temporally frequent estimation of forage biomass and vegetation cover in grasslands remains difficult due to the heterogeneity of growth stages, management regimes, and environmental variation. Conventional field-based surveys are labor-intensive, spatially incomplete, and lack temporal resolution needed for dynamic grassland management. Remote sensing solutions, particularly with satellite or manned aerial imagery, are limited by 82 insufficient spatial and temporal resolution for plot-level or intra-seasonal monitoring. Existing remote sensing models often do not generalize well due to site-specific calibrations, limited temporal coverage, and reliance on linear relationships between indices and biophysical parameters. Limitation Current approaches to grassland biomass estimation using UAV or remote sensing data often suffer from limited operational scalability due to complex processing pipelines, dependence on unavailable ancillary environmental data (e.g., meteorology, soil), suboptimal selection or saturation of vegetation indices, and inadequate validation across diverse conditions, compromising their applicability and generalizability in temperate grassland systems. Motivation The need for spatially exhaustive, temporally responsive, and operationally practical tools for grassland monitoring is acute given the ecological and agricultural importance of these systems and their broad degradation. UAV-based multispectral imaging presents promising avenue, but systematic comparison of diverse processing methods over an entire growing season and under temperate conditions is lacking, hindering adoption in precision pasture management. TaskObjective To develop, test, and compare three UAV-based multispectral imaging approachesvolumetric modeling via structure from motion, GNDVI-based regression, and GNDVI-based classificationfor estimating forage biomass and vegetation cover in temperate grasslands across full growing season. ExistingSolutions Spectral Index Regression (NDVI, etc.): Relies on linear regression between vegetation indices (primarily NDVI) and biomass; easy to implement but limited by index saturation and oversimplification of non-linear relationships. Often requires site-specific calibration. Height/Volumetric Models from Photogrammetry: Uses UAV structure from motion photogrammetry to estimate canopy or sward height as proxy for biomass, offering strong correlation where precise DTMs are available but sensitive to terrain inaccuracies and not robust at low vegetation density. Multi-Source and Simulation-Based Models: Integrate spectral, structural, and ancillary data (e.g., crop models or management records) for enhanced accuracy but increase methodological complexity and reduce operational ease. Classification Approaches: Rarely applied to grassland biomass; when used, classification of vegetation cover is often qualitative and seldom linked directly to continuous biomass estimation. Reference Answer Idea This study systematically compares three UAV-based approachesvolumetric modeling via structure from motion, GNDVI-based regression, and GNDVI-based classificationover an entire season in temperate grasslands, demonstrating that these methods are complementary, operationally feasible, and generalizable for spatially detailed forage biomass and cover estimation, each suiting different management needs and data constraints. ImplementationSteps 1: Planning and executing UAV flights to acquire multispectral and visible imagery with consistent overlap and illumination across 14 dates. 2: Collecting ground-truth biomass samples and recording plot management details (grazing, clipping schedules). 3: Processing imagery to produce orthomosaics and DSMs using aerial triangulation, GCPs, 83 and radiometric correction. 4: Generating high-precision DTM for control unit using GNSS data; calculation of volumetric biomass (DSM-DTM). 5: Calculating multiple vegetation indices (including GNDVI) from orthomosaics and evaluating their correlation with biomass samples. 6: Developing volumetric-based linear regression biomass model (control plots only). 7: Selecting optimal vegetation index (GNDVI) and training non-linear regression models for fresh and dry biomass using 49 training samples. 8: Validating regression models using 50 independent field samples; calculating performance statistics. 9: Extracting GNDVI values from 248 polygons, applying cluster and discriminant analysis to classify vegetation cover into four classes. 10: Comparing spatial and temporal patterns among the three approaches using visual and statistical analyses. ImplementationOrder 1-2 1-3 3-4 4-6 3-5 5-7 7-8 5-9 6-8 7-8 9-10 Data Imagery and field data were collected in 14-ha field in Sherbrooke, Quebec, containing 30 pasture plots (25x50 m), 5 bare soil plots (25x50 m), and 6 control plots (5x5 m). Over the 2017 growing season, 14 UAV flights (DJI Inspire 1 Pro with Parrot Sequoia multispectral and visible sensors) were conducted, yielding high-resolution orthomosaics and DSMs. Field biomass measurements were obtained from 99 quadrats (0.25 m2 each) for regression modeling and 248 polygons (3.5x3.5 m) for classification, sampled across management regimes and growth stages. EvaluationMetrics Coefficient of Determination (R2): Measures the proportion of variance in measured biomass explained by model predictions. Evaluated for both fresh and dry biomass regression models. Root Mean Square Error (RMSE): Quantifies the average magnitude of prediction error between measured and estimated biomass. Normalized RMSE (NRMSE): RMSE divided by the mean of measured values, expressed as percentage to facilitate comparison across datasets. Central Tendency Error: Assesses systematic bias between predicted and observed values. Regression Error: Quantifies deviation of fitted regression from the 1:1 line. Concordance Analysis: Statistical comparison of predicted vs. observed values for regression model validation. Visual Qualitative Assessment: Comparison of predicted spatial patterns with RGB imagery and known management (e.g., growth duration). ExpectedOutcome The volumetric model achieved R2 = 0.93 (fresh) and 0.94 (dry), RMSE of 0.072 kg/m2 (fresh) and 0.013 kg/m2 (dry); GNDVI regression yielded R2 = 0.80 (fresh) and 0.66 (dry) for training, with validation R2 = 0.63 (fresh) and 0.50 (dry), NRMSE of 36% (fresh) and 38% (dry). The GNDVI classification robustly distinguished four vegetation cover classes. Combined, these methods enable fine-scale, season-long monitoring of pasture condition, with operational models supporting >90% explanation of biomass variance for suitable conditions, and practical, generalizable classification for management applications. Example of Idea Generation in Energy Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork Sfetsos2000: Applied various forecasting techniques (statistical, time-series analysis) to mean hourly wind speed, finding that model performance varies with data characteristics; however, results demonstrate instability across sites and fail to leverage combined model strengths. Kelouwani2004: Utilized nonlinear model identification with neural networks for wind turbine output prediction, yielding improved accuracy for specific datasets, but with limited robustness to operational variability. Negnevitsky2007: Proposed hybrid intelligent system for short-term wind power forecasting, integrating multiple AI approaches; achieved improved performance over single models but lacked dynamic adaptation to wind speed distribution features. Shi2010: Combined wavelet transforms and support vector machines for short-term wind power prediction, enhancing performance for non-stationary series, yet exhibiting sensitivity to model parameterization and failing to generalize across varying wind speed segments. Challenges Accurately forecasting very-short term (e.g., 15-minute-ahead) wind power output amidst inherent wind speed volatility and non-stationarity. Capturing the nonlinear and regime-dependent relationship between wind speed distributions and wind farm power generation. Integrating multiple predictive models in manner that adaptively leverages their complementary strengths across varying meteorological conditions. Minimizing computational burden while improving real-time forecasting reliability for grid operation and reserve planning. Limitation Existing single-model forecasting approaches lack generalizability due to dataset-specific performance and inability to adapt to wind speed regime changes. Prior hybrid models fail to exploit wind speed distribution features for dynamic weight allocation and commonly require extensive retraining, resulting in suboptimal accuracy and increased computational overhead. Motivation The volatility and unpredictability of wind power pose significant challenges for power system operation, particularly at high penetration levels. Improved very-short term forecasting is critical for grid reliability, reserve allocation, and economic dispatch. Recognizing that no single model performs optimally across all wind regimes, there is compelling need for hybrid approach that dynamically adapts to wind speed distribution features, maximizing forecasting accuracy and operational utility. TaskObjective 85 To develop dynamic hybrid very-short term wind power forecasting model that integrates grey relational analysis with wind speed distribution features, enabling adaptive model weighting and superior forecasting accuracy over individual models for 15-minute-ahead wind power output. ExistingSolutions Persistence/MLR/ARMA: Statistical models, such as persistence, multiple linear regression, and ARMA, leverage historical data for short-term forecasting, offering simplicity but inadequate handling of nonlinearities and changing wind regimes. ANN/SVM Approaches: Artificial neural networks and support vector machines have been applied for improved short-term prediction by capturing complex patterns, but their performance is sensitive to data characteristics, and single models often fail to generalize well. Prior Hybrid Models: Some studies combine multiple models via fixed or learned weights (e.g., neural network-based combination), achieving moderate improvements but lacking integration with wind speed regime information, and often requiring heavy retraining for each new scenario. Reference Answer Idea The authors introduce hybrid forecasting framework that fuses LSSVM and RBFNN models through grey relational analysis, with model weights adaptively tuned by wind speed distribution features segmented via Weibull analysis. By constructing dynamic weight database indexed by wind speed regimes, the method achieves improved accuracy and reduced retraining effort for 15-minute-ahead wind power prediction. ImplementationSteps 1: Preprocess data (handle missing samples, normalization, extract input features: prior wind speeds, directions, power output). 2: Train independent LSSVM and RBFNN models on input features for 15-minute-ahead wind power prediction. 3: Apply equalization to forecasting result sequences and actual measurements to obtain normalized series. 4: Calculate grey relational degrees between each models output and actual measurements for each time window. 5: Fit wind speed data for each month to the Weibull distribution; segment wind speed into regimes according to frequency analysis. 6: Compute model weights (correlations) within each wind speed regime and store in monthly weight database. 7: For new forecasts, use NWP wind speed prediction to identify wind speed regime and retrieve corresponding model weights. 8: Combine LSSVM and RBFNN outputs using dynamic weights for final forecast output. 9: Evaluate forecasting performance using MAPE and RMSE against actual measured data. ImplementationOrder 1-2 2-3 3-4 1-5 5-6 6-7 7-8 8-9 Data Historical SCADA data from Chinese wind farm spanning 01/01/2010 to 12/31/2010 (excluding months with missing data), comprising 15-minute resolution records of wind speed (previous 15, 30, 45 min), wind direction (cosine and sine), and wind power output. The dataset includes over 30,000 samples, with wind speed segmented monthly and fitted to Weibull distributions for regime analysis. EvaluationMetrics MAPE: Mean Absolute Percentage Error; quantifies average absolute error as percentage of actual wind farm rated capacity. RMSE: Root Mean Square Error; quantifies the standard deviation of the prediction errors, normalized by wind farm capacity. Visual Comparison: Graphical overlays of forecasted vs. actual power output for selected periods to assess tracking and volatility handling. ExpectedOutcome The hybrid model achieves MAPE of 2.37% and RMSE of 3.79%, outperforming standalone LSSVM and RBFNN models as well as simple averaging. The method delivers improved accuracy, especially during low and fluctuating power output regimes, and reduces retraining overhead through the dynamic weight database. The approach demonstrates robustness and scalability for operational very-short term wind power forecasting."
        },
        {
            "title": "Example of Idea Generation in Information",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork InternVL2.5: Adopted multi-stage pipeline with language-only pre-training, MLP warmup for multimodal alignment, and instruction tuning. Demonstrated strong open-source multimodal performance but faced training complexity and limited cross-modal parameter optimization. Qwen2.5-VL: Uses staged adaptation of text-only LLMs into MLLMs, integrating visual adapters and fine-tuning. Achieves strong performance on vision-language tasks but still requires complex alignment processes and suffers in long-context or multi-image scenarios. LLaVA-OneVision: Focuses on easy visual task transfer via visual instruction tuning. Excels at adaptation efficiency but underperforms on challenging multimodal reasoning or spatial tasks compared to larger unified models. Gemini 2.5 Pro: proprietary closed-source MLLM employing advanced joint training and data curation, achieving state-of-the-art results. However, it lacks the transparency and reproducibility necessary for open research progress. Challenges Integrating multimodal (vision, text, video) and linguistic capabilities in single model without compromising either modalitys performance. Overcoming the inefficiencies and alignment difficulties of post-hoc adaptation pipelines that start from text-only LLMs. Scaling multimodal large language models (MLLMs) to handle longer contexts, multi-image input, and complex real-world tasks. Balancing pure-language proficiency with robust multimodal reasoning and visual grounding. Efficiently utilizing heterogeneous and imbalanced multimodal data during pre-training and post-training. 87 Limitation Existing MLLMs rely on multi-stage adaptation pipelines, leading to suboptimal cross-modal parameter interaction and persistent alignment or optimization bottlenecks. These approaches often freeze or partially update parameters, limiting scalability, introducing computational overhead, and creating persistent gap in pure-language and multimodal competence. Motivation The growing complexity and diversity of real-world multimodal data demand models capable of unified, scalable, and robust multimodal reasoning, without the trade-offs and inefficiencies of post-hoc adaptation. native joint pre-training paradigm is needed to achieve seamless linguistic and multimodal integration, better performance scalability, and open research reproducibility. TaskObjective To develop unified, open-source multimodal large language model that jointly acquires linguistic and multimodal capabilities via native pre-training, establishes new state-of-the-art performance across spectrum of multimodal tasks, and narrows the gap to leading proprietary MLLMs. ExistingSolutions InternVL2.5: Applies separate language pre-training followed by multimodal alignment (MLP warmup, visual adapters), then instruction tuning. Good on general benchmarks, but complex, inflexible, and less efficient for scaling. Qwen2.5-VL: Uses visual adapters with staged fine-tuning. Strong visual-text integration, but depends on freezing strategies and additional modules. Moderate gains on long-context or diverse input. LLaVA-OneVision: Visual instruction tuning for rapid adaptation. Simplicity and transferability prioritized, but lacking in deep joint optimization for reasoning and multi-modal context. Gemini 2.5 Pro: Highly-curated, end-to-end joint pre-training but closed-source, with proprietary data curation and infrastructure. Reference Answer Idea InternVL3 introduces native multimodal pre-training, where vision, language, and video data are jointly leveraged in single optimization stage. It integrates Variable Visual Position Encoding for long-context support, advanced post-training (SFT, MPO), and test-time scaling, resulting in scalable, efficient, and unified multimodal reasoning with open-source reproducibility. ImplementationSteps 1: Initialize ViT, LLM, and MLP modules with pre-trained weights; set up data pipelines for multimodal and text corpora. 2: Apply pixel unshuffle and prepare visual tokens for scalable image encoding. 3: Implement Variable Visual Position Encoding (V2PE) for visual tokens, with random delta sampling during training. 4: Jointly pre-train all model components using the multimodal autoregressive objective, sampling data at 1:3 text-to-multimodal ratio. 5: Perform Supervised Fine-Tuning (SFT) with high-quality, diverse multimodal instructions, applying loss re-weighting and data packing. 6: Conduct Mixed Preference Optimization (MPO) using preference pairs and composite loss (preference, quality, generation). 7: Integrate Best-of-N test-time scaling with VisualPRM as the critic to select optimal outputs. 8: Train with InternEVO for efficient large-scale distributed optimization, handling workload 88 imbalances and maximizing resource utilization. 9: Perform comprehensive evaluation on battery of multimodal and language benchmarks. ImplementationOrder 1-2 2-3 3-4 4-5 5-6 6-7 7-8 8-9 Data InternVL3 is trained on hybrid corpus: (1) Multimodal data (150B tokens) comprising imagetext pairs, video-text, GUI, tool usage, 3D scene, document, OCR, chart, multi-image, and medical data, sourced and extended from InternVL2.5 and new real-world collections; (2) Pure language data (50B tokens) built from InternLM2.5, open-source corpora, and scientific/math datasets. SFT uses 21.7M curated samples; MPO uses 300K preference pairs from MMPR v1.2. EvaluationMetrics MMMU: Massive Multi-discipline Multimodal Understanding, measuring reasoning across disciplines (accuracy, %). MathVista/MathVision/MathVerse: Mathematical reasoning (accuracy, %). OCRBench/AI2D/ChartQA/DocVQA: Vision-text integration and document understanding (accuracy, %, EM). MMBench/MMStar/MMVet/MME: Comprehensive multimodal capabilities (aggregate and per-task accuracy or score). HallusionBench/MMHal/CRPE/POPE: Multimodal hallucination resistance (score, %). RefCOCO/+/g: Visual grounding (localization accuracy, %). MVBench/Video-MME/MLVU: Video and temporal understanding (score, %). ScreenSpot/ScreenSpot-V2: GUI grounding (accuracy, %). VSI-Bench: Spatial reasoning (composite score, %). Language Benchmarks: MMLU, CMMLU, C-Eval, GAOKAO, TriviaQA, NaturalQuestions, RACE, HellaSwag, GSM8K, MATH, HumanEval, MBPP (accuracy, pass@k, or other standard metrics). ExpectedOutcome InternVL3-78B achieves state-of-the-art open-source results, e.g., 72.2 on MMMU, 79.0 on MathVista, 91.4 on RefCOCOg, 90.9% on GUI grounding, and 48.4 on VSI-Bench. It demonstrates robust scaling across tasks, narrows the performance gap to commercial models (Gemini 2.5 Pro, GPT-4o), and maintains strong language proficiency (80.5 overall on language benchmarks). All models and data will be open-sourced to enable community-driven research."
        },
        {
            "title": "Example of Idea Generation in Life",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork Senior et al. (2020): Introduced deep learning for predicting inter-residue distances, improving template-free protein structure prediction but still reliant on multiple post-processing stages and lacking atomic-level accuracy for novel folds. 89 Yang et al. (2020): Employed deep neural networks to predict inter-residue orientations, integrating orientation constraints but with limited end-to-end learning and lower performance on long or complex proteins. AlQuraishi (2019): Proposed an end-to-end differentiable structure prediction model, directly outputting 3D coordinates; however, it exhibited lower accuracy than multi-stage pipelines and struggled without homologous templates. Marks et al. (2011); Jones et al. (2012): Used coevolutionary analysis of MSAs to infer residue contacts, achieving improvements in contact prediction but failing to achieve accurate atomic models, especially for proteins lacking deep MSAs or templates. Challenges Achieving atomic-level accuracy in protein structure prediction directly from amino acid sequence, particularly in the absence of homologous structural templates. Integrating physical, geometric, and evolutionary information into single, scalable, end-toend deep learning model. Handling cases with shallow or sparse multiple sequence alignments (MSAs), which limits evolutionary signal. Providing robust structure prediction for large proteins and complex folds, including those with novel topologies. Quantifying per-residue prediction confidence to enable reliable downstream biological applications. Limitation Contemporary approaches fall short of experimental accuracy, particularly on targets lacking homologous templates or deep MSAs. Existing neural architectures often separate contact/distance prediction from structure generation, use hand-crafted features, or rely on multi-stage heuristics, resulting in limited scalability and suboptimal integration of physical and evolutionary constraints. Poor performance persists in under-sampled sequence regions and multi-chain complexes. Motivation Structural biology is constrained by the slow pace and resource demands of experimental structure determination, leaving the vast majority of protein sequences without 3D structural annotation. Accurate, scalable, and generalizable computational prediction of protein structuresespecially without close templateswould transform bioinformatics, molecular biology, and drug discovery by bridging the sequence-structure knowledge gap. TaskObjective To develop computational method that predicts the three-dimensional atomic structure of proteins from their amino acid sequence with accuracy comparable to experimental techniques, even in the absence of close structural homologues or deep sequence alignments. ExistingSolutions Physics-based simulation: Uses molecular dynamics or statistical approximations to model protein folding but is computationally intractable for large proteins and sensitive to approximations in physical modeling. Bioinformatics/homology modeling: Predicts structures via alignment to known protein templates and infers constraints from evolutionary sequence analysis; limited by template availability and reduced accuracy for novel or divergent proteins. Deep learning with intermediate prediction: Predicts inter-residue distances/orientations from MSAs using CNNs or attention networks, then reconstructs structures through downstream heuristics; accuracy suffers in end-to-end integration and novel folds. Reference Answer 90 Idea AlphaFold introduces an end-to-end deep learning architecture that jointly embeds MSAs and pairwise residue features, iteratively refines 3D atomic structures through Evoformer and Invariant Point Attention modules, integrates geometric and evolutionary constraints, leverages self-distillation from unlabelled data, and produces accurate, scalable predictions with robust per-residue confidence estimates. ImplementationSteps 1: Collect and preprocess protein sequence and structure data from PDB, UniRef90, BFD, Uniclust30, and MGnify. 2: Construct multiple sequence alignments (MSAs) and retrieve structural templates for each input sequence using HHBlits, jackhmmer, and HHSearch tools. 3: Initialize the neural network: encode MSA and pairwise features; build Evoformer trunk with interleaved attention and triangle update blocks. 4: Process MSA and pair features through stacked Evoformer blocks to enable information exchange and representation enhancement. 5: Feed processed representations to the structural module; iteratively refine per-residue 3D coordinates using invariant point attention and equivariant transformations. 6: Apply frame-aligned point error (FAPE) loss, distogram loss, BERT-style MSA masking loss, and auxiliary side-chain/violation losses for end-to-end supervised training. 7: Augment training with self-distillation: generate and filter high-confidence predictions on unlabelled sequences, then retrain with mixed supervised and distillation data. 8: During inference, perform ensemble predictions (if required), select best models by predicted confidence scores, and relax final structures with Amber force field. 9: Evaluate predictions using CASP14 targets and recent PDB structures, reporting backbone and all-atom metrics, and provide per-residue confidence (pLDDT) and TM-score estimates. ImplementationOrder 1-2 2-3 3-4 4-5 5-6 6-7 7-8 8-9 Data AlphaFold is trained on structures from the Protein Data Bank (PDB) (as of April 2018), comprising tens of thousands of high-resolution experimental protein structures. Sequence information is augmented using UniRef90, Big Fantastic Database (BFD, 2.2B sequences clustered into 66M families), Uniclust30, and MGnify. For self-distillation, 350,000 diverse sequence clusters from Uniclust30 are used. Evaluation is conducted on the CASP14 dataset (87 domains) and recent nonredundant PDB chains (n=10,795), filtered to remove overlap with training data. EvaluationMetrics IDDT (Local Distance Difference Test): Superposition-free metric comparing local atomic distances in predicted vs. reference structure, applicable for all atoms (IDDT) or backbone Cùõº atoms (IDDT-Cùõº). GDT (Global Distance Test): Measures fraction of residues within predefined distance thresholds; standard for CASP evaluations of domain accuracy. TM-score (Template Modeling score): Assesses global structural similarity by optimal superposition over entire protein chains, robust to domain packing and length differences. Cùõº r.m.s.d.95: Root-mean-square deviation of Cùõº atoms over the best-aligned 95% of residues, reducing the impact of outliers/artifacts. pLDDT (Predicted Local Distance Difference Test): Confidence score per residue, predicting local structural accuracy. pTM (Predicted TM-score): Neural networkderived prediction of TM-score for given model. Error intervals: 95% confidence intervals on reported metrics via bootstrapping. ExpectedOutcome AlphaFold achieves median backbone accuracy of 0.96 √Ö r.m.s.d.95 on CASP14 (95% CI: 0.851.16 √Ö), with all-atom accuracy at 1.5 √Ö (95% CI: 1.21.6 √Ö), outperforming the nextbest method by margin exceeding 1.8 √Ö. High accuracy generalizes to new, non-redundant PDB entries (median 1.46 √Ö). The model provides robust per-residue confidence estimation (pLDDT, Pearson r>0.75 with true accuracy), produces accurate side-chain conformations, and scales to proteins exceeding 2,000 residues. The approach enables proteome-scale structure prediction with experimental-level precision for the majority of targets without requiring close homologues."
        },
        {
            "title": "Example of Idea Generation in Material",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork Yaghi et al. (2008, Science): Pioneered high-throughput synthesis of zeolitic imidazolate frameworks (ZIFs) using 96-well plates, establishing the feasibility of automated, combinatorial materials discovery but with limited autonomy and narrow scope. Sumida et al. (2010, Chem. Sci.): Utilized automated robotic systems and multichannel reactors for precise control over MOF synthesis, improving reproducibility but not achieving closed-loop optimization. Cao et al. (2023, JACS, MOFormer): Introduced self-supervised Transformer model for MOF property prediction, exhibiting improved accuracy and data efficiency, yet mainly focused on text-based molecular representations. Kang et al. (2023, Nat. Mach. Intell., MOFTransformer): Developed multimodal Transformer for universal transfer learning in MOFs, integrating graph and grid embeddings, achieving high transferability but requiring extensive pretraining data. Park et al. (2024, Digital Discovery): Applied deep reinforcement learning with Transformers for inverse design of MOFs, enabling property-driven generative design but currently constrained by the diversity and validity of generated structures. Dagdelen et al. (2024, Nat. Commun.): Proposed LLM-NERRE for structured chemical information extraction, advancing literature mining but dependent on fine-tuning and sample efficiency. Challenges The vast chemical and structural diversity of MOFs renders exhaustive experimental exploration infeasible, creating high-dimensional, combinatorial synthesis landscape. Traditional manual or even semi-automated high-throughput methodologies are bottlenecked by limited autonomy, data integration, and lack of feedback-driven optimization. Existing AI models, though powerful, struggle with generalizability and interpretability due 92 to sparse, noisy, or unstandardized data and the complexity of structure-property relationships. Realizing fully autonomous, closed-loop self-driving laboratories (SDLs) for MOF discovery is impeded by hardware standardization issues, sample handling difficulties, and insufficient integration of intelligent decision-making. Limitation Previous methodologies in MOF research either focused on isolated automation of experimental steps or applied AI for isolated tasks (e.g., property prediction) without achieving seamless, closed-loop integration. These approaches often lack robust feedback mechanisms, dynamic adaptation to new data, and struggle to generalize across diverse MOF chemistries, limiting their utility for autonomous discovery. Motivation MOFs application potential in energy, environment, and drug delivery is hampered by slow, laborintensive discovery cycles and under-explored materials space. The combination of laboratory automation with advanced AIincluding Transformers and LLMsoffers the prospect of systematic, iterative, and autonomous exploration, thereby addressing efficiency, reproducibility, and innovation barriers in MOF science. TaskObjective To comprehensively review and critically evaluate the convergence of artificial intelligence (especially Transformer and LLM models) and laboratory automation technologies in accelerating the discovery, synthesis, characterization, and optimization of metal-organic frameworks, with emphasis on the progression toward self-driving laboratories. ExistingSolutions Traditional HTE: Employs combinatorial synthesis and characterization platforms, increasing throughput but requiring significant manual oversight and lacking intelligent optimization. Machine Learning (2012present): Applies classical statistical learning (e.g., decision trees, SVMs) for property prediction and data analysis, limited by feature engineering and scalability. Deep Learning (2020present): Utilizes neural networks for property prediction and structure optimization, improving accuracy but often acts as black box and needs large labeled datasets. Transformers/LLMs (2023present): Leverage self-attention for sequence and structural modeling, enabling multimodal integration and text-based knowledge mining, but require extensive training and face challenges in domain adaptation and resource consumption. Generative Models (VAEs, GANs, Diffusion): Enable de novo MOF structure generation, but often struggle with chemical validity, diversity, and property conditioning. Reference Answer Idea This review elucidates the synergistic integration of laboratory automation and state-of-the-art AIparticularly Transformers and LLMsinto closed-loop, self-driving laboratory paradigm for MOF discovery. It details how AI-driven feedback, high-throughput platforms, and knowledge extraction from literature converge to enable autonomous, data-driven synthesis, characterization, and inverse design of MOFs. ImplementationSteps 1: Establish automated laboratory infrastructure encompassing robotic synthesis, sample handling, and high-throughput screening modules. 2: Deploy high-throughput experimental platforms for parallelized synthesis, characterization (PXRD, NMR, TEM), and evaluation (adsorption, catalysis). 3: Integrate laboratory information management systems (LIMS) for structured data curation and workflow management. 4: Apply machine learning/deep learning models for property prediction and experimental 93 guidance using accumulated data. 5: Adopt Transformer-based models and LLMs for structure-property prediction, literature mining, synthesis condition extraction, and generative MOF design. 6: Implement feedback-driven experimental planning via Bayesian optimization, reinforcement learning, or LLM-driven task planners. 7: Iteratively refine models and protocols in closed-loop SDL, autonomously updating synthesis/design strategies based on real-time outcomes. ImplementationOrder 1-2 2-3 3-4 4-5 5-6 6-7 Data MOF structural and property databases such as MOFX-DB, ARC-MOF, hMOF, QMOF, and inhouse/generated HTE data; text corpora from scientific literature and patents used for LLM fine-tuning and information extraction; multi-million entry simulation datasets for pretraining (e.g., 1M+ hypothetical MOFs in MOFTransformer, 1.9M in PMTransformer); experimental records from robotic synthesis/characterization platforms. EvaluationMetrics Experimental Throughput: Number of unique MOF samples synthesized, characterized, and evaluated per unit time. Prediction Accuracy: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), coefficient of determination (R2) for property prediction models (e.g., adsorption, bandgap, stability). Generalizability: Performance on out-of-distribution or unseen MOF structures/datasets, transferability to new tasks or materials classes. Structural Validity/Diversity: Percentage of generated MOF candidates that are synthetically accessible and chemically valid, structural diversity indices. Automation Level: SDL autonomy score (Levels 15), extent of human intervention required. Information Extraction F1 Score: Precision, recall, and F1 for chemical entity and relation extraction from literature. Resource Efficiency: Computational and experimental resources expended per successful discovery or optimization cycle. ExpectedOutcome Integration of AI and laboratory automation is expected to yield >90% accuracy in property prediction (e.g., MOFTransformers MTP/MOC accuracy >0.97/0.98), 210x acceleration in MOF discovery throughput, and significant reductions in labor and experimental time. Closedloop SDLs will enable autonomous optimization, reproducible high-quality synthesis, and rapid extraction of actionable knowledge from literature, collectively setting new benchmarks for efficiency, reproducibility, and innovation in MOF research."
        },
        {
            "title": "Example of Idea Generation in Math",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. 94 RelatedWork Dijkstra1959: Classic label-setting SSSP algorithm using priority queues; achieves O(nlog + m) time with Fibonacci heaps but is inherently sequential and difficult to parallelize efficiently. Thorup1999: RAM-based linear-time SSSP for undirected graphs using component trees and atomic heaps; limited to large and specific hardware, and not easily generalized or parallelized for directed graphs. BellmanFord1958: Label-correcting algorithm with O(nm) time; allows negative weights but is suboptimal in the worst case and shows little potential for efficient parallelization. Han1997 / PaigeKruskal1985: Matrix multiplication-based SSSP achieves polylogarithmic parallel time at superlinear work complexity (O(nÀÜ3 log n)); impractical for sparse graphs due to excessive work. KleinSubramanian1997: Randomized parallel BFS-based SSSP for unweighted/weighted graphs; achieves sublinear time for certain approximations, but exact solutions still demand high work or multiple passes. Crauser1998: Parallelizes Dijkstra by organizing computation into phases for random graphs; achieves O(nÀÜ{1/3} log n) time and O(n log + m) work on average for specific random graph classes. Challenges No known work-efficient parallel SSSP algorithm achieves sublinear time for arbitrary directed graphs with nonnegative edge weights. Existing parallel methods either settle nodes sequentially or incur superlinear work, limiting practical scalability on large graphs. Traditional bucket-based or priority queue approaches struggle to balance parallelism and efficiency, especially with varied edge weights and node degrees. Load balancing and minimizing redundant relaxations/reinsertions are unsolved for arbitrary, especially high-degree, graphs in parallel settings. Limitation Current approaches to parallel SSSP either replicate sequential orderlimiting parallel speedupor achieve fast parallel time only at the cost of excessive (superlinear) work, particularly on general graphs. Previous bucket-based label-correcting algorithms lack robust average-case guarantees for noninteger or random edge weights, and most practical parallel systems cannot efficiently exploit fine-grained sequential priority queues. Motivation The practical need for scalable, efficient shortest path computation on large graphs with arbitrary structure and edge weights drives the search for algorithms that are both parallelizable and workefficient. Empirical evidence suggests label-correcting algorithms can outperform labelsetting ones, but theoretical justification and robust parallelization remain lacking. Bridging this gap is crucial for leveraging modern parallel and distributed architectures in large-scale graph analytics. TaskObjective Develop and analyze parallelizable single-source shortest path (SSSP) algorithm for arbitrary directed graphs with nonnegative edge weights that achieves linear or near-linear work and sublinear parallel time for broad graph classes, while providing provable average-case guarantees. ExistingSolutions Dijkstra1959: Sequential label-setting using priority queues; optimal for many sequential settings but fundamentally sequential and hard to parallelize without loss of work efficiency. ApproximateBucket: Bucket-based variants for small integer weights; can be fast for restricted 95 graphs but either devolve to label-correcting (with reinsertion overhead) or require auxiliary selection structures, limiting parallelism. BellmanFord: Label-correcting, admits parallel edge relaxations, but incurs high redundancy and pseudo-polynomial time in the worst case. MatrixMult: Reduces SSSP to matrix multiplications; achieves sublinear parallel time at cubic or worse work, impractical except for dense graphs. ParallelBFS/Randomized: Suitable for unweighted or random graphs; offers fast approximate solutions but breaks down for exact computations or general edge weights. Reference Answer Idea The Œî-stepping algorithm organizes nodes into distance buckets of width Œî, differentiating light ( Œî) and heavy (>Œî) edges to balance parallelism and efficiency. In each phase, all nodes in the minimum nonempty bucket are processed in parallel: light edges are relaxed immediately, while heavy edges are deferred. By tuning Œî, the method provably achieves linear average-case work and scalable parallelism for wide graph class, and can be extended to distributed memory settings and arbitrary edge weights. ImplementationSteps 1: Preprocess graph: partition adjacency lists into light ( Œî) and heavy (>Œî) edges; for shortcut-augmented versions, compute and add shortcut edges for all simple Œî-paths. 2: Initialize: set all tentative distances to except source (0), place source in the appropriate bucket. 3: Phase main loop: while buckets are nonempty, select the minimum nonempty bucket (current phase), remove all nodes from it. 4: Light edge relaxation: in parallel, relax all outgoing light edges of nodes in the current bucket; update tentatives and reinsert nodes as needed into corresponding buckets. 5: Repeat light-edge relaxations (within bucket) until no new nodes enter the current bucket. 6: Heavy edge relaxation: after the current bucket remains empty, in parallel relax all heavy edges from nodes just processed. 7: Advance to the next nonempty bucket and repeat. 8: Parallelization: distribute nodes (and their bucket membership) across processors; generate and assign relaxation requests using randomized dart-throwing or explicit load balancing (semisorting); aggregate and execute requests. 9: Distributed memory extension: replace global memory with message-passing; assign nodes and requests using hashing and tree-based collective operations. 10: Parameter tuning: select Œî empirically or via doubling search to balance work and parallel time; for arbitrary weights, use adaptive bucket splitting. ImplementationOrder 1-2 2-3 3-4 4-5 5-6 6-7 7-3 3-8 8-9 1-10 Data The paper analyzes both synthetic random graphs (e.g., D(n, dùëë/n): n-node digraph, each edge present independently with probability ùëë/n, edge weights i.i.d. uniform [0,1]) and realworld-like datasets (e.g., random geometric graphs, roadmaps). Experiments are conducted on random d-regular graphs (n=10ÀÜ3 to 10ÀÜ6, up to 310ÀÜ6 edges) and large-scale road networks (up to n=157,457). EvaluationMetrics Work Complexity: Total number of operations performed across all processors, compared to sequential optimal O(n + m). Parallel Time: Number of parallel phases until all nodes are settled; measured in terms such as O(dLlog + log2n) on PRAM. Speedup: Empirical wall-clock speedup relative to sequential Dijkstra or Œî-stepping on real and synthetic graphs. Phases/Reinsertions: Number of bucket phases and total reinsertions, correlated to Œî and graph/weight parameters. Scalability: Ability to maintain work efficiency and speedup as the number of processors and graph size increase. Robustness: Performance across random graphs, geometric graphs, and real-world networks with varying degree and weight distributions. ExpectedOutcome Œî-stepping achieves O(n + + dL) average-case work and O(dLlog + log2n) parallel time for graphs with random edge weights and bounded degree; for random graphs, O(log2n) time and O(n + m) work. Experiments show linear or near-linear speedups (e.g., >9 on 16 processors), with phases and reinsertions scaling sublinearly in n. The approach generalizes to distributed memory and arbitrary edge weights, providing, for the first time, practical and work-efficient parallel SSSP algorithm applicable to large, arbitrary graphs."
        },
        {
            "title": "Example of Idea Generation in Neuroscience",
            "content": "Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork ConvNet: pioneering end-to-end CNN architecture employing temporal and spatial convolutional layers for EEG decoding, offering improved performance over traditional approaches but limited to local feature extraction due to restricted receptive field. EEGNet: compact CNN model using temporal and depthwise spatial convolutions, exhibiting robust generalization across BCI paradigms; however, it also fails to capture long-term dependencies inherent in EEG time series. Transformer-Based EEG Models: Attention-based Transformers leverage global temporal dependencies for EEG decoding, achieving notable performance but neglecting local feature learning, necessitating additional pre-processing or feature extraction steps. FBCSP: classical approach utilizing filter bank common spatial patterns to extract taskspecific hand-crafted features for motor imagery classification, demonstrating strong performance but lacking generalization and requiring prior knowledge. Hybrid and Graph-based Methods: Combining CNNs with hand-crafted features or graph structures to enhance spatial-temporal modeling. These methods improve local-global representations but often involve complex architectures or task-dependent preprocessing. Challenges 97 Accurately decoding EEG signals requires capturing both local features (temporal and spatial) and global dependencies due to the non-stationary and low signal-to-noise nature of EEG data. CNN-based models are constrained by local receptive fields, failing to capture long-range temporal dependencies crucial for sequential EEG data. Transformer-based models, though adept at modeling global dependencies, often disregard local feature representation, undermining the exploitation of fine-grained EEG information. End-to-end frameworks for EEG decoding still lack sufficient interpretability regarding their decision process, particularly in identifying task-relevant neural substrates. Limitation Existing EEG decoding approaches either focus on local pattern extraction (CNNs) or global temporal correlation (Transformers) but rarely integrate both in unified, efficient, and endto-end architecture. Furthermore, most methods require task-specific feature engineering or lack direct interpretability of neural activation, and high model parameterization raises computational concerns. Motivation The crucial observation motivating this study is the complementary value of both local and global features in EEG decoding tasks. As practical BCI applications demand robust, generalizable, and interpretable models that can efficiently learn from raw EEG data without extensive prior knowledge or task-specific feature engineering, there is clear need for an integrated approach that unifies convolutional and self-attention mechanisms. TaskObjective To design and validate compact, end-to-end neural architecture that jointly encapsulates local temporal-spatial and global temporal dependencies for raw EEG classification, while offering enhanced interpretability through visualization of learned representations. ExistingSolutions ConvNet: Applies sequential temporal and spatial convolutions to extract discriminative local features, yielding solid performance but limited by short-range context. EEGNet: Implements depthwise and separable convolutions for temporal and spatial filtering, achieving good generalization yet lacking mechanisms for modeling global dependencies. RNN/LSTM-based Models: Utilize sequential recurrence to encode long-term temporal dependencies but suffer from inefficient training and rapid decay of influence across time steps. Transformer-Based Models: Employ self-attention to directly capture long-range dependencies, improving performance for sequential tasks, but require additional modules or preprocessing to encode local information. Hybrid Methods: Fuse hand-crafted features or graph-based encodings with deep learners, improving local-global feature integration but increasing architectural complexity and dependence on domain expertise. Reference Answer Idea The authors introduce EEG Conformer, lightweight neural framework that sequentially combines temporal and spatial convolutions for local feature extraction with multi-head selfattention for learning global temporal dependencies. This unified architecture enables end-toend decoding from raw EEG, and novel visualization approach (Class Activation Topography) enhances interpretability by mapping activation to brain regions. ImplementationSteps 1: Band-pass filter and Z-score standardize raw EEG trials. 2: Segment and augment data using time-domain segmentation and reconstruction (S&R). 3: Feed data into the convolution module: perform temporal convolution (125 kernel), 98 spatial convolution (ch1 kernel), batch normalization, ELU activation, and average pooling (175 kernel, stride 15) to extract local features. 4: Rearrange pooled feature maps: collapse spatial dimension, treat each timepoints features as token. 5: Process tokens with the self-attention module: apply layers of multi-head self-attention (h heads), followed by feed-forward sublayers. 6: Pass aggregated features to the fully-connected classifier: two layers with Softmax output. 7: Train the model with cross-entropy loss using Adam optimizer and perform subject-wise validation. 8: Visualize feature distributions (t-SNE) and model attention via CAM and CAT for interpretability. ImplementationOrder 1-2 2-3 3-4 4-5 5-6 6-7 7-8 Data Three public EEG datasets were used: (1) BCI Competition IV 2a (9 subjects, 22 electrodes, 4 motor imagery classes, 250 Hz, 288 trials per session), (2) BCI Competition IV 2b (9 subjects, 3 bipolar electrodes, 2 motor imagery classes, 250 Hz, 5 sessions of 120 trials each), and (3) SEED (15 subjects, 62 electrodes, 3 emotion classes, 1000 Hz downsampled to 200 Hz, 3394 trials/session). Each dataset covers distinct paradigms and acquisition settings, supporting model generalization. EvaluationMetrics Classification Accuracy: Percentage of correctly predicted EEG trials across classes, reflecting decoding performance. Cohens Kappa: statistical measure of inter-rater agreement accounting for chance, used to evaluate classification reliability. Wilcoxon Signed-Rank Test: Non-parametric test for statistical significance of performance differences between models or ablation settings. Training Efficiency: Measured as convergence speed (epochs to stable loss/accuracy) and per-epoch training time. Interpretability: Qualitatively assessed via t-SNE clustering of learned features, CAM heatmaps, and CAT spatial-temporal mappings. ExpectedOutcome EEG Conformer achieves state-of-the-art classification accuracy and kappa across all three datasets: on BCI IV 2a, average accuracy 78.66% (10.91% over FBCSP), kappa 0.7155; on BCI IV 2b, 84.63% accuracy, kappa 0.6926; on SEED, 95.30% accuracy, kappa 0.9295. Ablation studies show 6.02% average accuracy drop without the self-attention module. Visualization confirms the models focus on paradigm-relevant brain regions, and the architecture demonstrates efficient convergence and robustness to parameter variations, establishing strong new backbone for general EEG decoding. Example of Idea Generation in Physics Question You are top-tier researcher in your field. Based on the following context, please generate novel and detailed research proposal. RelatedWork eSEN-30M-OMat: An equivariant graph neural network tailored for materials, achieving strong accuracy via large-scale message passing, but limited to domain-specific datasets and lacking generalization across molecules or surfaces. GemNet-OC20: graph neural network for catalysis using geometric embeddings, excelling in adsorption energy prediction but focused solely on catalysis, without material or molecular generalization. MACE: foundation model for atomistic materials chemistry that demonstrates excellent transferability within the organic molecule domain, but struggles to generalize simultaneously to diverse materials and catalytic systems. EquiformerV2 : An advanced equivariant transformer model that achieves strong performance on domain-specific materials and catalysis benchmarks but is not trained for multi-domain or multi-DFT-task generalization. ORB v3: scalable neural network potential capable of efficient simulation at scale, but designed primarily for periodic materials, with limited multi-domain applicability. Universal Graph Deep Learning Potentials: Aim to provide comprehensive coverage across the periodic table, yet tend not to generalize to molecules or catalysis due to distribution shifts and differing DFT settings. Pre-training with Fine-tuning: Large models are pre-trained on broad datasets and fine-tuned for specific tasks, yielding high accuracy but still requiring domain adaptation; true zero-shot generalization across tasks remains unproven. Challenges Developing single MLIP capable of high-fidelity, zero-shot generalization across vastly different chemical domains, including materials, molecules, catalysis, molecular crystals, and MOFs. Scaling model and dataset size without sacrificing inference speed or memory efficiency, especially for long-running atomistic simulations involving thousands to hundreds of thousands of atoms. Reconciling and learning from datasets with heterogeneous DFT settings, label distributions, elemental coverage, and system sizes. Maintaining energy conservation, physical symmetry (rotational equivariance), and smoothness of the potential energy surface during multi-task, multi-domain learning. Efficiently training and deploying ultra-large models (up to billions of parameters) under memory and compute constraints. Limitation Most existing MLIPs are either specialized for single chemical domain or require fine-tuning to achieve high accuracy in new domains. They do not robustly generalize across materials, molecules, and catalytic systems with varying DFT settings. Further, attempts to scale model capacity often degrade inference efficiency, and models are typically trained on smaller, less diverse datasets, limiting their practical universality. Motivation The demand for rapid, accurate, and general-purpose atomistic simulations is increasing in fields such as drug discovery, energy storage, and catalysis. However, DFT is computationally prohibitive, and existing ML surrogates lack universality. The confluence of new, massive 100 multi-domain datasets and insights from scaling laws in deep learning presents the opportunity to create single, highly scalable MLIP that achieves state-of-the-art accuracy, speed, and generalization across all relevant chemical domains. TaskObjective To design, train, and evaluate family of universal machine learning interatomic potentials (UMA) that achieve high accuracy, computational efficiency, and generalization across diverse chemical and materials domains, using the largest multi-domain atomic datasets to date. ExistingSolutions eSEN: Utilizes equivariant message passing with spherical harmonics for high accuracy in materials, but lacks multi-domain scalability. GemNet: Employs geometric embeddings for catalysis; effective on domain-specific adsorption tasks but does not generalize to other domains. MACE: Foundation model for molecules, demonstrates good transferability within molecular datasets; struggles with cross-domain and multi-task generalization. EquiformerV2: Equivariant transformer with improved scaling for materials and catalysis, but not designed for simultaneous multi-domain learning. ORB v3: Focuses on scalable neural network potentials for materials, achieving high throughput but lacks coverage of molecular and catalytic tasks. Fine-tuned Foundation Models: Pre-train on large datasets, then fine-tune for each target domain; yields high performance but necessitates domain-specific adaptation and fails to provide universal zero-shot performance. Reference Answer Idea UMA introduces family of universal MLIPs trained on nearly 500M multi-domain atomic structures, leveraging an efficient Mixture of Linear Experts (MoLE) architecture for scalable capacity without inference overhead. Empirical scaling laws inform model/data sizing, while unified embeddings and referencing schemes enable seamless multi-DFT-task learning, delivering state-of-the-art accuracy and speed across chemistry and materials science domains. ImplementationSteps 1: Data aggregation and preprocessing: curate and normalize OMat24, OMol25, OC20++, OMC25, and ODAC25, applying energy referencing and label normalization. 2: Model design: configure eSEN-based GNN with integrated MoLE layers; implement global embeddings for charge, spin, and DFT task. 3: MoLE routing: compute expert coefficients from global system features and pre-merge expert weights for efficient inference. 4: Stage 1 training: pre-train the model in BF16 on direct force prediction with max-atom batching and reduced neighbors. 5: Stage 2 fine-tuning: switch to FP32 precision and auto-grad conservative heads, increasing neighbor count for energy/force conservation. 6: Memory/computation optimization: employ graph parallelism, FSDP, and activation checkpointing for large-scale training. 7: Model selection: use empirical scaling laws to determine optimal model and dataset size for given compute budget. 8: Evaluation: benchmark UMA models on held-out splits and established tasks across materials, catalysis, molecules, molecular crystals, and MOFs. ImplementationOrder 1-2 2-3 101 3-4 4-5 5-6 6-7 7-8 Data UMA is trained on five large-scale datasets: OMat24 (bulk materials, 100M entries, 89 elements, VASP-PBE), OMol25 (molecules, 75M entries, 83 elements, ORCA-ùúîB97M-V), OC20++ (catalysis, 229M, 56 elements, VASP-RPBE), OMC25 (molecular crystals, 25M, 12 elements, VASP-PBE+D3), and ODAC25 (MOFs, 29M, 70 elements, VASP-PBE+D3). Combined, the data covers 459M structures and >30B atoms with near-complete elemental coverage and diverse DFT settings. EvaluationMetrics Mean Absolute Error (MAE): Measures average absolute deviation between predicted and reference energies, forces (in meV/√Ö), and stresses (meV/√ÖÀÜ3). Adsorption Energy Success Rate: Percentage of cases where the predicted global minimum adsorption energy is within 0.1 eV of the DFT minimum (AdsorbML benchmark). F1 Score: Assesses binary/classification performance on Matbench Discovery for stability predictions. Energy Conservation: Degree to which predicted forces/energies conserve energy over molecular dynamics trajectories (NVE MD benchmarks). Simulation Throughput: Number of inference steps per second for fixed system sizes (1k, 10k, 100k atoms) on single GPU. Out-of-Domain Generalization: Performance on OOD splits, such as high-entropy alloys and novel molecular/crystal structures. Phonon and Elastic Property Accuracy: MAE for phonon frequencies, free energies, elastic moduli, and related properties pertinent to material science benchmarks. ExpectedOutcome UMA achieves state-of-the-art or superior accuracy on diverse benchmarks (e.g., up to 25% improvement in AdsorbML success rate, 80% reduction in OC20 adsorption energy error vs. prior SOTA, chemical accuracy for ligand strain energy). The models support efficient simulation of >100k atoms with no inference penalty from increased capacity. UMA provides reliable, energy-conserving predictions across all major chemical domains, demonstrating that single model can match or surpass specialized models in both zero-shot and fine-tuned settings. A.3.3. Dry Experiment"
        },
        {
            "title": "Example of Dry Experiment in Astronomy",
            "content": "Background The Zwicky Transient Facility (ZTF) is an advanced optical time-domain sky survey utilizing the Palomar 48-inch Schmidt telescope equipped with custom wide-field CCD camera. This camera covers 47.7 square degree field of view with 16 large-format CCDs, enabling survey speed over an order of magnitude faster than its predecessor. The system achieves median image quality of approximately 2.0 arcseconds full-width at half-maximum (FWHM) across g, r, and bands, with typical 5-sigma limiting magnitudes near 20.8 (g), 20.6 (r), and 19.9 (i) in 30-second exposures, improving under dark-sky conditions. 102 The optical design addresses the Schmidt telescopes curved focal surface through combination of modified Schmidt corrector, meniscus dewar window, faceted cold plate mounting, and individual field flattener lenses above each CCD. The cameras cryostat and readout electronics are optimized for minimal beam obstruction and rapid 8.2-second readout with low noise ( 10 electrons median). robotic observing system and scheduler maximize volumetric survey speed by selecting fields on fixed grid with minimal dithering, enabling efficient coverage of the Northern sky and Galactic plane. ZTFs data system performs near-real-time image processing, including bias subtraction, flatfielding, astrometric and photometric calibration, and image differencing using the ZOGY algorithm to detect transient and variable sources. Alerts containing rich contextual information and machine-learning-based Real-Bogus scores are distributed via scalable streaming system to community brokers. The system also supports solar system science by detecting both pointlike and streaked moving objects, linking detections into orbits, and reporting to the Minor Planet Center. Early scientific results demonstrate ZTFs capability to discover and classify supernovae, including young Type II events, and to conduct rapid follow-up of multi-messenger triggers such as neutrinos and gamma-ray bursts. The facility also enables studies of variable stars, exemplified by light curves of Be stars and RR Lyrae, and solar system objects, including near-Earth asteroids, asteroid rotation periods, comet activity, and Centaur outbursts. ZTFs public surveys include three-day cadence Northern Sky Survey and nightly Galactic Plane Survey, with observations typically taken twice per night in and bands. The surveys moderate depth and high cadence complement future facilities by providing early discovery and characterization of bright transients accessible to moderate-aperture telescopes. ZTF serves as pathfinder for next-generation surveys, offering prototype alert stream and extensive time-domain data products to the astronomical community. Data Code 1 # !/ usr / bin / env h 3 2 # -* - i : utf -8 -* - 3 \" \" \" 4 Paper : The c r i F l : t Overview , f a , and First u 5 h : Eric . Bellm , i a . Kulkarni , t J . Graham , et al . 6 Year : 2019 7 8 This i e a s h c e d light curve data based on the c t s 9 in t 6.4.2 of the paper . 10 11 h e o : 3 . 1 0 . 1 2 12 \" \" \" 13 14 o sys 15 e sys . s _ o >= (3 , 10) , \" This code u s h 3.10 or h \" 16 17 # e n s 18 # pip t numpy = = 1 . 2 4 . 3 d = = 2 . 0 . 3 19 20 o num py as np 21 o a s as pd 22 from h i r Path 23 from i m t Tu ple 24 25 # b o a 26 A _ = Path ( \" data \" ) 27 A _ E _ H = A _ / \" e d _ h _ v . csv \" 28 D _ D = 42 # u e d b e t 29 30 def e e _ e d _ h _ v ( 31 32 33 34 35 36 37 ) -> None : e _ h : str , _ n : int = 150 , i _ : float = 2.25 , l d : float = 0.2 , _ g : Tuple [ float , float ] = (17.8 , 18.2) , s _ e : float = 0.03 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 \" \" \" e e y e a r l ight curve and saves it to CSV file . The ght curve is e as m c n n o with added s n noise . This i the data for an e d like ( 1 1 0 1 4 ) t u in u 10( ) . Tag : [ Data n d ] Args : e _ h ( str ) : The path to save the p CSV file . _ n ( int ) : The b of data n to e e . i _ ( float ) : The a n i of the e d in hours . l d ( float ) : The l d of the light curve i o in n d . _ g ( Tuple [ float , float ]) : The r m m i e range of the e d . s _ e ( float ) : The n d i o of the s n noise to add to the n d . t s : None m s : > > > Path ( \" data \" ) . mkdir ( s _ = True ) > > > e _ h = \" data / t _ h _ v . csv \" > > > e e _ e d _ h _ v ( file_path , _ n =50) > > > o a s as pd > > > df = pd . d _ ( e _ h ) > > > print ( df . shape ) (50 , 3) \" \" \" # Set d seed to u e d b t np . d . seed (0+ D _ D ) # e e v y p time n to u e real e t s # e t time span is about 4 hours e t _ n _ = i _ * 1.8 ti es = np . sort ( np . d . rand ( _ n ) * e t _ n _ ) # c t the e e n d of the light curve e _ n d = np . mean ( _ g ) # Use i u i to u e e d g e a t # t y by 2 a a full a n i s l n n two peaks and two u m i e _ e = e _ n d - l d * np . cos (2 * np . pi * times / i _ * 2) # Add s n oise to the e d data no se = np . d . m (0 , s _ e , _ n ) n d _ = n d _ e + noise # e e error for each data point , a to noise level o = np . d . m ( s _ e , s _ e / 4 , _ n ) o = np . i ( errors , s _ e / 2) # u r s are not too small # a D F e to store the data df = pd . a m ({ e _ : times , n d : n d _ , error : o }) # Save to CSV file df . _ ( file_path , index = False ) pr nt ( \" c f y e e n t light curve data and saved to : { e _ h } \" ) # u data e r i D _ . mkdir ( s _ = True ) # e e u e data e e _ e d _ h _ v ( 98 99 100 if _ _ e _ _ == \" _ _ n _ _ \" : 101 102 103 104 105 106 107 108 109 110 111 112 ) e _ h = str ( A _ E _ H ) , _ n =150 , i _ =2.25 , # e d i o s d to u 10( ) l d =0.15 , # l d g _ g =(17.8 , 18. 1) , # n d range s _ e =0.02 # No ise level 104 Main Code with Incomplete Functions 1 # !/ usr / bin / env h 3 2 # -* - i : utf -8 -* - 3 \" \" \" 4 Paper : The c r i F l : t Overview , f a , and First u 5 h : Eric . Bellm , i a . Kulkarni , t J . Graham , et al . 6 Year : 2019 7 8 This i m m s the e d light curve l s from t 6 . 4 . 2 . 9 It e n the a n i of an e d from its light curve using 10 Lomb - r p o r and r s e t g . 11 12 h e o : 3 . 1 0 . 1 2 13 \" \" \" 14 15 o sys 16 17 e sys . s _ o >= (3 , 10) , \" This code u s h 3.10 or h \" 18 19 # e n s 20 # pip t numpy = = 1 . 2 4 . 3 d = = 2 . 0 . 3 scipy = = 1 . 1 0 . 1 21 22 o num py as np 23 o a s as pd 24 from ipy . n m t b r 25 from i m t Tu ple 26 from h i r Path 27 28 # b o a 29 A _ E _ H = \" data / e d _ h _ v . csv \" 30 # Or der of r series , the paper t s second - order r s e 31 R _ _ M = 2 32 # e a a i o a 33 I = 1e -9 34 35 36 def d _ h _ v _ a ( e _ h : str ) -> pd . a m : 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 > > > Path ( \" data \" ) . mkdir ( s _ = True ) > > > data = { e _ : [0 , 1] , n d : [18.0 , 18.1] , error : [0.01 , \" \" \" Lo ds e d ight curve data from CSV file . pd . a m : t a o i g the light curve data with u i _ , n d , and error . e _ h ( str ) : The path to the CSV file . Tag : [ Data d ] m s : u : Args : 0 . 0 1 ] } > > > df = pd . a m ( data ) > > > df . _ ( \" data / dummy . csv \" , index = False ) > > > d _ = d _ h _ v _ a ( \" data / dummy . csv \" ) > > > print ( d _ . shape ) (2 , 3) print ( \" Erro : Data file not found at { e _ h } \" ) print ( \" a run data . py first to e e the data file . \" ) sys . exit (1) \" \" \" try : e i o u r : u pd . d _ ( e _ h ) 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def c t _ b _ r _ i g ( 67 68 69 70 71 72 ) -> upl [ np . ndarray , np . r ]: 73 74 75 76 77 78 times : np . ndarray , n d : np . ndarray , _ i : float = 0.5 , _ i : float = 5.0 , _ i : int = Tag : [ e a l a n ] Args : \" \" \" c t the Lomb - r p o r for v y p data . 105 times ( np . r ) : Array of time n . n d ( np . r ) : Arr ay of n d a e t . _ i ( float ) : The i p o to test . _ i ( float ) : The i p o to test . _ i ( int ) : The b of i o s to l e . Tuple [ np . ndarray , np . r ]: tuple t i the i t e and the r o n r o m power . > > > times = np . s e (0 , 4 , 50) > > > n d = 18 + 0.1 * np . sin (2 * np . pi * times / 2.0) > > > periods , power = c t _ b _ r _ i g ( times , n d ) > > > print ( i . shape , power . shape ) (10000 ,) (10000 ,) Args : u : u : m s : a e : Tag : [ e a l a n ] \" \" \" pass # [ a o e the code ] 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def d _ t _ i _ m _ i g ( 100 i : np . ndarray , 101 po wer : np . r 102 ) -> flo : 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def l _ r _ i _ r ( 126 127 128 129 ) -> np . r : 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 \" \" \" pass # [ a o e the code ] ti mes : np . ndarray , i : float , _ m : int Tag : [ d i o i ] u np . a ( i _ r ) . a e : u : Args : \" \" \" nds the i o s d to the h power in the i g . r s ( np . r ) : Array of i . po wer ( np . r ) : Array of i g p r . fl oat : The i with the h power . > > > i = np . arra ([1.0 , 2.0 , 3.0]) > > > power = np . array ([0.1 , 0.8 , 0.2]) > > > t _ i = d _ t _ i _ m _ i g ( periods , power ) > > > print ( t _ i ) 2.0 \" \" \" l the i a x for u r i i r least - a fit . ti mes ( np . r ) : Array of time n . i ( float ) : The d n p o of the r s e . _ m ( int ) : The b of r terms ( m c ) to l . np . r : The i a x for the fit . > > > times = np . array ([0 , 1 , 2]) > > > i = 4.0 > > > _ m = 1 > > > r = l _ r _ i _ r ( times , period , _ m ) > > > print ( r . shap ) (3 , 3) \" \" \" # d n f u y ega = 2 * np . pi / ( i + I ) # t i c m c for the s t term i _ r = [ np . s _ e ( times ) ] # Loop to add sin and cos terms for each order for in range (1 , _ m + 1) : i _ r . e ( np . sin ( * omega * times ) ) i _ r . e ( np . cos ( * omega * times ) ) 106 \" \" \" Fits u r model usin i e n least a . i _ r ( np . r ) : The i a x from l _ r _ i _ r . n d ( np . r ) : Arr ay of n d a e t . o ( np . r ) : Array of s m e r for g n . np . r : The array of t o e e c t . > > > times = np . s e (0 , 4 , 10) > > > i = 2.0 > > > n d = np . sin (2 * np . pi * times / i ) > > > o = np . l _ e ( magnitudes , 0.1) > > > r = l _ r _ i _ r ( times , period , 1) > > > f = _ r _ e ( matrix , magnitudes , o ) > > > print ( len ( f ) ) 3 \" \" \" # Use o for g n i s = 1.0 / ( o + I ) g d _ r = i _ r * g [: , np . a ] g d _ n d = n d * g # lve using least a coeffs , _ , _ , _ = np . a . lsts ( g d _ r , g d _ n d , rcond = None ) u o s Args : u : a e : Tag : [ d i o i ] i _ r : np . ndarray , n d : np . ndarray , o : np . r 160 161 162 def _ r _ e ( 163 164 165 166 ) -> np . r : 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 def l e _ r _ e ( 201 202 203 ) -> np . r : 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 def c t _ u _ _ a ( 230 231 232 233 234 ) -> flo : 235 236 237 238 239 240 e d : np . ndarray , e d : np . ndarray , o : np . ndarray , _ _ a : int i _ r : np . ndarray , f : np . r y Tag : [ e a l a n ] Tag : [ r a l o ] m s : u : Args : Args : \" \" \" l e the r mod el at given time n . i _ r ( np . r ) : The i a x . f ( np . r ) : The t o e e c t . np . r : The d e g u from the model . > > > times = np . array ([0 , 1 , 2]) > > > i = 4.0 > > > _ m = 1 > > > r = l _ r _ i _ r ( times , period , _ m ) > > > f = np . arra ([18.0 , 0.1 , 0.0]) > > > e _ s = l e _ r _ e ( matrix , f ) > > > print ( e _ s . shape ) (3 ,) \" \" \" u np . dot ( i _ r , f ) \" \" \" c t the u chi - a s i c for fit . 107 e d ( np . r ) : The e d data u . e d ( np . r ) : The odel x t a s . o ( np . r ) : The o on the e d u . _ _ a ( int ) : The b of free a e in the model . fl oat : The u chi - a value . > > > obs = np . array ([1 , 2 , 3]) > > > exp = np . array ([1.1 , 2.2 , 2.9]) > > > err = np . array ([0.2 , 0.2 , 0.2]) > > > _ 2 = c t _ u _ _ a ( obs , exp , err , 1) > > > print ( \" { _ 2 :.2 } \" ) 1.25 \" \" \" # c t chi - a v alue _ a = np . sum ((( e d - e d ) / ( o + I ) ) ** 2) # c t g s of e d e _ _ e = len ( e d ) - _ _ a # oid i n by zero if r _ _ e <= 0: u h _ a / r _ _ e m int ( \" - - - ZTF e d ight Cu rve l s - - - \" ) # 1. Load data int ( \" [1/4] d light cu rve data from { A _ E _ H } ... \" ) h _ v _ = d _ h _ v _ a ( A _ E _ H ) mes = h _ v _ [ e _ ]. u a t s = h _ v _ [ n d ]. u r s = h _ v _ [ error ]. u r int ( \" c f y d { len ( times ) } data n . \" ) u : m s : 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 if _ _ e _ _ == \" _ _ n _ _ \" : 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 u np . inf # 2. c t Lomb - r p o r r int ( \" [2/4] c t p o r using Lomb - r m o ... \" ) # Set a a p o a range n_p = 0.5 x_p = ( times . max () - ti mes . min () ) periods , power = c t _ b _ r _ i g ( times , magnitudes , _ i = # e t span as max i # hours 284 285 286 287 288 289 290 291 292 293 294 295 296 297 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 min_p , _ i = max_p ) t _ i = d _ t _ i _ m _ i g ( periods , power ) int ( \" i g a y c l . Most e light curve i is : { t _ i :.4 } hours . \" ) # 3. Fit r s e odel int ( \" [3/4] t { R _ _ M } - order r s e using found i { t _ i :.4 } hours ... \" ) i _ r = l _ r _ i _ r ( times , t _ i , R _ _ M ) r _ f = _ r _ e ( i _ r , magnitudes , o ) e _ n d = l e _ r _ e ( i _ r , r _ f ) int ( \" r model t c l . \" ) int ( \" t o i n : { np . round ( r _ f , 4) } \" ) # 4. l e d s of fit int ( \" [4/4] l i model d s of fit ... \" ) _ a = 1 + 2 * R _ _ M _ 2 = c t _ u _ _ a ( magnitudes , e _ n d , errors , # 1 s t term + *2 sin / cos terms _ a ) int ( \" u chi - a of the model : { _ 2 :.4 } \" ) if 0.5 < _ 2 < 2.0: pr int ( \" This is a a fit . \" ) else : pr int ( \" n : The fit may be poor or error i e a r . \" ) # nal p # The core goal in the pa per for d a r r t p o is to a the i value int ( \" - - - l s p e - - - \" ) int ( \" [ Final p ] \" ) # nce the e d a n s two peaks in the light curve per rotation , # the s l a n i is twice the light curve i found by Lomb - r # This is m c e o in r m t o _ i = t _ i * 2.0 int ( \" { a n _ i :.4 } \" )"
        },
        {
            "title": "Answer",
            "content": "108 \" \" \" c t the Lomb - r p o r for v y p data . Args : Tag : [ e a l a n ] imes : np . ndarray , n d : np . ndarray , _ i : float = 0.5 , _ i : float = 5.0 , _ i : int = 1 0000 1 def c t _ b _ r _ i g ( 2 3 4 5 6 7 ) -> ple [ np . ndarray , np . r ]: 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 a e : u : times ( np . r ) : Array of time n . n d ( np . r ) : Arr ay of n d a e t . _ i ( float ) : The i p o to test . _ i ( float ) : The i p o to test . _ i ( int ) : The b of i o s to l e . Tuple [ np . ndarray , np . r ]: tuple t i the i t e and the r o n r o m power . > > > times = np . s e (0 , 4 , 50) > > > n d = 18 + 0.1 * np . sin (2 * np . pi * times / 2.0) > > > periods , power = c t _ b _ r _ i g ( times , n d ) > > > print ( i . shape , power . shape ) (10000 ,) (10000 ,) \" \" \" # 1. i and e e the r range for i y q c ( = 1/ ) e _ _ i = max ( min_period , I ) _ q = 1.0 / _ i a _ q = 1.0 / e _ _ i r a _ q c = np . s e ( min_freq , max_freq , _ i ) # 2. [ Key i a n ] v o n f u i to u f u i ( omega 38 39 40 41 42 43 44 45 = 2* pi * ) # sci . n . b r r i a l r e e as input u _ q c = 2 * np . pi * i y _ q c # 3. t a t data to o DC p n g u _ t d = n d - np . mean ( n d ) # 4. c t r o m power using u f u i po er = b r ( times , n d _ t d , u _ q c , m z = True ) # 5. u e d ( = 1/ ) r o n to i y q c and power i = 1.0 / ( i y _ q c + I ) u periods , power \" \" \" Fi ds the i o s d to the h power in the i g . Tag : [ e a l a n ] 46 47 48 49 50 51 def d _ t _ i _ m _ i g ( 52 i : np . ndarray , 53 power : np . r 54 ) -> loa : 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 \" \" \" t _ i _ e = np . m ( power ) u e d [ t _ i _ e ] m s : u : Args : i ( np . r ) : Array of i . power ( np . r ) : Array of i g p r . float : The i with the h power . > > > i = np . array ([1.0 , 2.0 , 3.0]) > > > power = np . array ([0.1 , 0.8 , 0.2]) > > > t _ i = d _ t _ i _ m _ i g ( periods , power ) > > > print ( t _ i ) 2.0 109 Example of Dry Experiment in Earth Background Surface ozone is secondary air pollutant formed by photochemical reactions involving carbon monoxide (CO), volatile organic compounds (VOCs), nitrogen oxides (NOx = NO + NO2), and sunlight. It poses significant risks to human health, including respiratory and cardiovascular effects, and damages vegetation by reducing crop yields and ecosystem productivity. While stringent emission controls since the 1990s have reduced ozone pollution in many Western regions, rapid industrialization and urbanization in East Asia, particularly China, have led to increasing ozone precursor emissions and elevated surface ozone levels. Recent nationwide monitoring in China, initiated around 2013, reveals that although median ozone concentrations during the warm season (AprilSeptember) are comparable to those in industrialized regions such as Japan, South Korea, Europe, and the United States, the frequency and magnitude of high-ozone events are substantially greater in China. Key metrics include the fourth highest daily maximum 8-hour average ozone (4MDA8), the number of days exceeding 70 ppb (NDGT70), and cumulative exposure indices like SOMO35 (sum of ozone means over 35 ppb). Chinas warm-season 4MDA8 averages around 86 ppb, exceeding other regions by 630%, while NDGT70 values are 93575% higher, indicating more frequent episodes of elevated ozone. Vegetation exposure metrics such as AOT40 and W126, which correlate with ozone-induced plant damage, are also significantly elevated in China, suggesting greater risks to agricultural productivity and ecosystem health. Spatially, ozone pollution hotspots in China are concentrated in densely populated and industrialized regions including the North China Plain, Yangtze River Delta, and Pearl River Delta, with some western areas affected due to topography and local emissions. Seasonal patterns show ozone peaks in late spring and early summer, influenced by regional meteorology such as the Asian summer monsoon, which modulates photochemical activity and pollutant transport. Temporal analysis from 2013 to 2017 indicates rising trend in ozone levels across Chinese cities, with annual increases in exposure metrics ranging from approximately 3.7% to over 15% per year. This contrasts with stable or declining ozone trends in Europe and the United States over recent decades. The increase in ozone occurs despite reductions in primary pollutants like SO2, NO2, CO, and fine particulate matter (PM2.5), reflecting complex photochemical interactions. In particular, reductions in NOx or PM2.5 can paradoxically enhance ozone formation in VOC-sensitive regimes prevalent in eastern China. Rising VOC emissions and meteorological factors such as hotter, drier summers also contribute to elevated ozone. These findings highlight China as current global hotspot for surface ozone pollution, with greater human and vegetation exposure than other industrialized regions with extensive monitoring. The severity and increasing trend of ozone pollution pose challenges for air quality management, indicating need for targeted control strategies focusing on VOC emissions and comprehensive understanding of chemical and meteorological influences on ozone formation. Data Code 1 # !/ usr / bin / env h 3 2 # -* - i : utf -8 -* - 3 \" \" \" 4 Paper : e u c Ozone l o in China : o P p i 5 h : Xiao Lu , y Hong , Lin Zhang , et al . 6 Year : 2018 7 8 Data e i c t for u i o y f ozone data . 9 h e o : 3 . 1 0 . 1 2 10 \" \" \" 11 12 o sys 13 14 e sys . s _ o >= (3 , 10) , \" This code u s h 3.10 or h \" Args : 15 16 # e n s 17 # pip t numpy = = 1 . 2 4 . 3 d = = 2 . 0 . 3 18 19 o num py as np 20 o a s as pd 21 from h i r Path 22 o os 23 24 25 def e e _ r _ n _ a ( 26 _ e : int , 27 r _ e : str , 28 _ e : str , 29 i _ a : dict 30 ) -> pd . a m : 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # p time t v o a _ _ r = e m . o a u _ _ = e m . hour _ e _ a = [] for e _ in ra nge ( _ e ) : \" \" \" np . d . seed ( 0 + 4 2 ) e m = pd . _ e e ( np . n ( ) ) _ r = len ( e m ) a e : u : \" \" \" e e t i u ozone data for t e sites . Tag : [ u i ] _ e ( int ) : The b of i i sites to u e . r _ e ( str ) : The start date for the data i ( . . , 2013 -01 -01 ) . _ e ( str ) : The end date for the data i ( . . , 2017 -12 -31 ) . i _ a ( dict ) : c n c a n r t for the i . Keys u n d e _ n , s l _ , l _ , s _ e , n _ b , n _ e h . pd . a m : t a with u [ e _ , e m , n _ ]. e _ n : 40 , s l _ : 15 , l _ : 20 , s _ e : 5 , n _ b : 0.02 , n _ e h : 40 > > > a = { ... ... ... } > > > df = e e _ r _ n _ a (2 , 2017 -01 -01 , 2017 -01 -31 , a ) > > > print ( df . shape ) (1488 , 3) np . e e 6 4 ( r _ e ) , np . e e 6 4 ( _ e ) + np . e t 6 4 (1 , ) , np . e t 6 4 (1 , ) # Base n = s l cycle + daily cycle s l _ l = i _ a [ s l _ ] * np . sin (2 * np . pi * ( 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 y _ _ r - 90) / 3 6 5 . 2 5 ) l _ l = i _ a [ l _ ] * np . sin (2 * np . pi * ( r _ _ - 8) / 24) e _ n = i _ a [ e _ n ] + s l _ l + l _ l # Add d noise noise = np . d . randn ( _ r ) * i _ a [ s _ e ] # u e high l o e e t = np . zeros ( _ r ) for in ran ge ( _ r ) : if np . d . rand () < i _ a [ n _ b ]: # l o event la sts 24 -72 hours a n = np . d . d (24 , 73) n _ = min ( + duration , _ r ) n _ p = np . sin ( np . s e (0 , np . pi , n _ - ) ) n [ : n _ ] += i _ a [ n _ e h ] * n _ p # p f inal n z _ c r o = e _ n + noise + n # u o n t v e are non - a e n _ c r o = np . i ( n _ c r o , 0) e _ = pd . a m ({ 111 Args : df ( pd . a m ) : The a m to save . e _ h ( str ) : The path to the p CSV file . u pd . c ( _ e _ a , o _ e = True ) }) _ e _ a . e ( e _ ) \" \" \" Save t a to CSV file . Tag : [ Data i ] e _ : site_ { e _ } , e m : timestamps , n _ : n _ c r o 94 95 96 97 98 99 100 101 102 103 def e _ a _ _ ( df : pd . DataFrame , e _ h : str ) : 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 if _ _ e _ _ == \" _ _ n _ _ \" : \" \" \" # u i t e t t _ = os . path . n ( e _ h ) if not os . path . s ( p _ ) : df . _ ( file_path , inde = False ) int ( \" Data has been sav ed to : { e _ h } \" ) os . e s ( p _ ) u : None m s : > > > data = pd . a m ({ col1 : [1 , 2] , col2 : [3 , 4]}) > > > e _ a _ _ ( data , data / test . csv ) # Set f n r t for hina and JKEU i a r g to the paper 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 c t n # ina i a e s : h base value , o r s l and daily va riations , more q t and o r high l o e c a _ a = { e _ n : 45 , s l _ : 20 , l _ : 25 , s _ e : 8 , n _ b : 0.015 , n _ e h : 50 } # h event u n r b t # o r event e t # JKEU i a e s : a e o a o t l l e _ a = { e _ n : 35 , s l _ : 15 , l _ : 20 , s _ e : 5 , n _ b : 0.005 , n _ e h : 30 } # Lowe event u n r b t # k event e t # To u runtime , we only u e one year of data R _ E = 2017 -01 -01 _ E = 2017 -12 -31 _ E = 10 # u e 10 sites int ( \" e i i a ozone data for China i ... \" ) n _ n _ a = e e _ r _ n _ a ( NUM_SITES , START_DATE , END_DATE , n _ a ) int ( \" e i i a ozone data for JKEU i ... \" ) u _ n _ a = e e _ r _ n _ a ( NUM_SITES , START_DATE , END_DATE , u _ a ) # a data e r and save files a _ = Path ( \" data \" ) a _ . mkdir ( s _ = True ) e _ a _ _ ( n _ n _ a , str ( a _ / \" n _ n _ a . csv \" ) ) e _ a _ _ ( u _ n _ a , str ( a _ / \" u _ n _ a . csv \" ) )"
        },
        {
            "title": "Main Code with Incomplete Functions",
            "content": "1 # !/ usr / bin / env h 3 2 # -* - i : utf -8 -* - 112 \" \" \" Load r ozon data from CSV file . Tag : [ Data d ] 3 \" \" \" 4 Paper : e u c Ozone l o in China : o P p i 5 h : Xiao Lu , y Hong , Lin Zhang , et al . 6 Year : 2018 7 8 l n i of ozone l o t s c t . 9 h e o : 3 . 1 0 . 1 2 10 \" \" \" 11 12 o sys 13 14 e sys . s _ o >= (3 , 10) , \" This code u s h 3.10 or h \" 15 16 # e n s 17 # pip t numpy = = 1 . 2 4 . 3 d = = 2 . 0 . 3 18 19 o num py as np 20 o a s as pd 21 22 23 def d _ n _ a ( e _ h : str ) -> pd . a m : 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def c t _ 8 ( l _ r _ a : pd . i ) -> float : 45 46 47 48 49 50 \" \" \" df = pd . d _ ( file_path , s _ e =[ e m ]) df = df . _ e ( e m ) u df \" \" \" c t the Da ily i 8 - hour r ( MDA8 ) ozone c r o . Tag : [ e a l a n ] > > > df = d _ n _ a ( data / n _ n _ a . csv ) > > > print ( df . u ) Index ([ e _ , n _ ] , dtype = e ) pd . a m : t a with t m index and ozone data . e _ h ( str ) : The path to the CSV data file . m s : u : Args : Args : l _ r _ a ( pd . i ) : r of 24 r ozone u for n 51 52 53 54 55 56 57 day . u : float : The MDA8 value in ppb . u np . nan if data is u c t . a e : > > > hours = pd . _ e e ( pd . e _ g ( 2023 -07 -01 , i =24 , freq = ) ) > > > data = pd . i ( np . sin ( np . s e (0 , 2* np . pi , 24) ) * 20 + 50 , index = hours ) \" \" \" pass # [ a o e the code ] \" \" \" c t the 4 th h MDA8 value for given i . Tag : [ e a l a n ] > > > mda8 = c t _ 8 ( data ) > > > print ( ro und ( mda8 , 2) ) 67. 58 59 60 61 62 63 64 65 def c t _ 4 8 ( 8 _ i : pd . i ) -> float : 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 > > > data = pd . i ([80 , 90 , 70 , 100 , 110 , 60]) > > > val = c t _ 4 8 ( data ) > > > print ( val ) 80.0 m s : u : Args : \" \" \" a 8 _ i ( pd . i ) : r of daily MDA8 u . float : The 4 th h MDA8 value . u np . nan if data is u c t . 113 8 _ i ( pd . i ) : r of daily MDA8 u . \" \" \" c t the to tal b of days with MDA8 u > 70 ppb . Tag : [ e a l a n ] u a _ 8 . t _ u ( e n = False ) . iloc [3] Args : u : u np . nan int : The cou nt of days where MDA8 > 70 ppb . i _ 8 = 8 _ i . p () if len ( i _ 8 ) < 4: 82 83 84 85 86 87 88 def c t _ t 7 0 ( 8 _ i : pd . i ) -> int : 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def c t _ 4 0 ( r _ a : pd . i ) -> float : 109 110 111 112 113 114 > > > data = pd . i ([65 , 71 , 85 , 70 , 7 0 . 1 ] ) > > > count = c t _ t 7 0 ( data ) > > > print ( count ) 3 \" \" \" u ( 8 _ i > 70) . sum () m s : Args : \" \" \" c t the AOT40 ( u a Ozone over r o of 40 ppb ) . Tag : [ e a l a n ] r _ a ( pd . i ) : r of r ozone data for the i e d . The c n will t for t hours 116 117 118 119 120 121 122 123 124 125 126 127 u : fl oat : The total AOT 40 value in ppb - hours . ( 0 8 : 0 0 - 1 9 : 5 9 ) . m s : > > > hours = pd . _ e e ( pd . e _ g ( 2023 -07 -01 , i =24 , freq = ) ) > > > data = pd . i ( np . n (30 , 54) , index = hours ) > > > aot40 = c t _ 4 0 ( data ) > > > print ( aot40 ) 91.0 \" \" \" t _ a = r _ a [( r _ a . index . hour >= 8) & ( r _ a . index . hour <= 19) ] # c t the t e e g 40 ppb each hour e n = np . i (0 , t _ a - 40) u x d e . sum () 128 129 130 131 132 133 def c t _ 1 2 6 ( r _ a : pd . i ) -> float : 134 135 136 137 138 139 140 \" \" \" c t the W126 metric , i e m t e s index . Tag : [ e a l a n ] Args : r _ a ( pd . i ) : r of r ozone data for the i e d . The c n will t for t hours ( 0 8 : 0 0 - 1 9 : 5 9 ) . > > > hours = pd . _ e e ( pd . e _ g ( 2023 -07 -01 , i =24 , freq = ) ) > > > data = pd . i ( np . full (24 , 80) , index = hours ) # s t 80 ppb > > > w126 = c t _ 1 2 6 ( data ) > > > print ( round ( w126 , 2) ) 9 5 4 . 1 6 u : a e : fl oat : The total W126 value in ppb - hours . 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def l _ i l _ r ( df : pd . a m ) -> dict : 156 157 158 159 \" \" \" pass # [ a o e the code ] \" \" \" l and p all key ozone r for given i s data . Tag : [ t i a y ] 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 Args : df ( pd . a m ) : The a m n n h l ozone data for g . u : dict : c n of region ally - r d ozone r . a e : > > > df = d _ n _ a ( data / n _ n _ a . csv ) > > > r = l _ i l _ r ( df ) > > > print ( r . keys () ) t _ s ([ _ 4 8 , _ t 7 0 , _ 4 0 , _ 1 2 6 ]) \" \" \" e _ r = [] # oup by site for c t for site_id , e _ a in df . u ( e _ ) : # t warm s data ( April - t e ) m _ s _ a = e _ a [( e _ a . index . month >= 4) & ( e _ a . index . month <= 9) ] # c t daily MDA8 l _ 8 = m _ s _ a [ n _ ]. a e ( ) . apply ( c t _ 8 ) . o () # c t r s r m4 da8 = c t _ 4 8 ( l _ 8 ) t 7 0 = c t _ t 7 0 ( l _ 8 ) ao t40 = c t _ 4 0 ( m _ s _ a [ n _ ]) w126 = c t _ 1 2 6 ( m _ s _ a [ n _ ]) e _ r . e ({ e _ : site_id , 4 mda8 : m4da8 , t 7 0 : ndgt70 , aot40 : aot40 , w126 : w126 if l _ 8 . empty : }) n u 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 if _ _ e _ _ == \" _ _ n _ _ \" : 215 216 217 218 219 220 } u e n _ # Load data try : i l _ = { u { } # c t g a e e t s _ = pd . a m ( e _ r ) . p () if r _ . empty : _ 4 8 : 0 , _ t 7 0 : 0 , _ 4 0 : 0 , _ 1 2 6 : 0 _ 4 8 : r _ [ 4 mda8 ]. mean () , _ t 7 0 : r _ [ t 7 0 ]. mean () , _ 4 0 : r _ [ aot40 ]. mean () , _ 1 2 6 : r _ [ w126 ]. mean () n _ = d _ n _ a ( data / n _ n _ a . csv ) u _ = d _ n _ a ( data / u _ n _ a . csv ) e i o u r : pr int ( \" Error : Data file not found . a run data . py to e e the data 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 first . \" ) sys . exit (1) int ( \" l n China i data ... \" ) n _ r = l _ i l _ r ( n _ ) int ( \" l n JKEU i data ... \" ) u _ r = l _ i l _ r ( u _ ) # p r l o r n in text m r int ( \" \" + \" = \" * 60) int ( \" i l p s of Ozone l o t s ( Warm s v g ) \" ) int ( \" = \" * 60) int ( \" { r : <20} { China : >15} { JKEU : >15} \" ) int ( \" -\" * 60) int ( \" { 4 th h MDA8 ( ppb ) : <20} { n _ r [ _ 4 8 ]: >15.2 } { u _ r [ _ 4 8 ]: >15.2 } \" ) 115 236 237 238 239 240 241 242 243 244 245 246 248 249 250 int ( \" { T 7 0 ( days ) : <20} { n _ r [ _ t 7 0 ]: >15.2 } { u _ r [ _ t 7 0 ]: >15.2 } \" ) int ( \" { AOT40 ( ppb - ) : <20} { n _ r [ _ 4 0 ]: >15.2 } { u _ r [ _ 4 0 ]: >15.2 } \" ) int ( \" { W126 ( ppb - ) : <20} { n _ r [ _ 1 2 6 ]: >15.2 } { u _ r [ g _ 1 2 6 ]: >15.2 } \" ) int ( \" = \" * 60) # c t final p : ratio of China D 7 0 r e i to JKEU # Add e a a i check i = 1e -8 t 7 0 _ i = n _ r [ _ t 7 0 ] / ( u _ r [ _ t 7 0 ] + i ) int ( \" n s : u i e t show that the q c of high ozone l o e ( T 7 0 ) \" ) int ( \" in China is r m l { t 7 0 _ i :.2 } times that of the JKEU region , n t with the trend found in the g l paper . \" ) int ( \" [ Final p ] \" ) int ( t 7 0 _ i ) Answer \" \" \" c t the W126 metric , i e m t e s index . Tag : [ e a l a n ] 1 def c t _ 1 2 6 ( r _ a : pd . i ) -> float : 2 3 4 5 6 7 8 Args : The c n will t for t hours r _ a ( pd . i ) : r of r ozone data for the i e d . 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 u : float : The total W126 value in ppb - hours . ( 0 8 : 0 0 - 1 9 : 5 9 ) . m s : > > > hours = pd . _ e e ( pd . e _ g ( 2023 -07 -01 , i =24 , freq = ) ) > > > data = pd . i ( np . full (24 , 80) , index = hours ) # s t 80 ppb > > > w126 = c t _ 1 2 6 ( data ) > > > print ( ro und ( w126 , 2) ) 9 5 4 . 1 6 \" \" \" i = 1e -8 t _ a = r _ a [( r _ a . index . hour >= 8) & ( r _ a . index . hour <= 19) ] # W126 g u i a e s = 4403 = # c t i s # Usi np . exp with a e inp ut is a safe , but i is added to o a w h = 1 / (1 + * np . exp ( - * t _ a / 1000) + i ) # c t i e n t i and sum w126 = ( g * t _ a ) . sum () u w126 29 30 31 32 33 34 35 def c t _ 8 ( l _ r _ a : pd . i ) -> float : 36 37 38 39 40 41 Args : \" \" \" c t the Da ily i 8 - hour r ( MDA8 ) ozone c r o . Tag : [ e a l a n ] l _ r _ a ( pd . i ) : r of 24 r ozone u for n 42 43 44 45 46 47 48 49 50 51 52 53 day . u : float : The MDA8 value in ppb . u np . nan if data is u c t . m s : > > > hours = pd . _ e e ( pd . e _ g ( 2023 -07 -01 , i =24 , freq = ) ) > > > data = pd . i ( np . sin ( np . s e (0 , 2* np . pi , 24) ) * 20 + 50 , index = hours ) > > > mda8 = c t _ 8 ( data ) > > > print ( ro und ( mda8 , 2) ) 67.68 \" \" \" # At least 18 (7 5%) hours of data are u d to c t the 8 - hour r e 116 54 55 56 57 58 59 60 if l _ r _ a . count () < 18: u np . nan # c t 8 - hour l a a o n _ 8 _ n = l _ r _ a . l ( d =8 , _ i =6) . mean () if l _ 8 _ n . empty or l _ 8 _ n . u () . all () : u np . nan t r i _ 8 _ n . max () A.3.4. Wet Experiment Example of Wet Experiment in Life Background Cancer development involves genetic and epigenetic alterations that enable tumor cells to evade immune detection by creating an immunosuppressive microenvironment. key mechanism of immune evasion is mediated by the programmed death-ligand 1 (PD-L1), expressed on tumor and immune cells, which binds to programmed death-1 (PD-1) and B7.1 (CD80) receptors on cells. This interaction inhibits T-cell migration, proliferation, and cytotoxic function, thereby limiting tumor cell killing. Blocking PD-L1 can restore antitumor immunity by reactivating suppressed cells. An engineered humanized monoclonal antibody targeting PD-L1 has been developed to inhibit its interaction with PD-1 and B7.1, without affecting PD-1s interaction with PD-L2, preserving peripheral tolerance. This antibody is designed with an Fc domain modification to prevent antibody-dependent cellular cytotoxicity, avoiding depletion of activated cells. Clinical studies involving patients with advanced solid tumors treated with this anti-PD-L1 antibody demonstrated safety and tolerability across range of doses, with manageable adverse events such as fatigue and low-grade fever. Immune activation markers, including proliferating CD8+ cells and interferon-gamma (IFN-ùõæ), increased during treatment. Efficacy assessments revealed objective responses in multiple cancer types, notably non-small cell lung cancer (NSCLC), melanoma, and renal cell carcinoma. Importantly, clinical responses correlated strongly with pre-treatment PD-L1 expression on tumor-infiltrating immune cells rather than tumor cells themselves. High PD-L1 expression on immune cells was associated with higher response rates and longer progression-free survival. Additional biomarkers linked to response included T-helper type 1 (TH1) gene expression and CTLA4 expression, while fractalkine (CX3CL1) expression correlated with disease progression. On-treatment biopsies of responding tumors showed increased immune cell infiltration, tumor necrosis, and upregulation of PD-L1 and IFN-ùõæ, indicating reactivation of antitumor immunity. Non-responding tumors exhibited patterns of immunological ignorance (lack of immune infiltration), non-functional immune responses (immune cells present but inactive), or excluded infiltrates (immune cells restricted to tumor margins), with no significant PD-L1 upregulation or T-cell activation. Blood-based biomarkers showed increases in IFN-ùõæ-inducible chemokines and activated cytotoxic cells early in treatment, reflecting systemic immune activation, though these changes did not clearly distinguish responders from non-responders. These findings support the concept that pre-existing antitumor immunity suppressed by PD-L1 can be reinvigorated by PD-L1 blockade, leading to durable clinical responses. The presence and localization of PD-L1 expression, particularly on tumor-infiltrating immune cells, serve as predictive biomarkers for response. Understanding the immune microenvironment of nonresponders may reveal additional mechanisms of immune resistance and guide combination 117 immunotherapy strategies to enhance the cancer immunity cycle. Action Pool Args : Args : Args : Args : Args : Args : t s : u : u : u : u : u : s s i FFPE s block ixed s a e DAB - u z e o c n : DAB - i s i Antibody - e t u c n x _ s : Formalin - fixed s t e _ t : Antibody - i s i i e : s a e to be fixed a e : m n u n s _ c : Paraffin - e d s block c s : t t k s in r t t u _ t : s e o on slide i y : m a b c e a n : i y c r o 1 < _ s _ _ m n >( tissue , a e ) 2 3 4 5 6 7 8 < e _ s _ _ a n >( e _ s ) 9 10 11 12 13 14 < t _ s >( s _ c , c s ) 15 16 17 18 19 20 21 < i _ h _ i y >( s _ t , antibody , c r o ) 22 23 24 25 26 27 28 29 < u z _ h _ >( i _ t ) 30 31 32 33 34 35 < n s n _ h _ a y >( t ) 36 37 38 39 40 41 < r _ _ i g >( i _ t , l _ e ) 42 43 44 45 46 47 48 < u e _ h _ m _ i i >( section , antibody1 , antibody2 , p t ) 49 50 51 52 53 54 55 56 57 < e _ h _ o c e >( e _ t , e o _ t , o h ) 58 59 60 61 62 63 64 65 < r _ _ m _ E >( s _ t , r i _ ) 66 67 68 69 70 71 72 < r _ _ m _ E >( s _ t , r i _ ) 73 74 75 76 77 c n : FFPE s e o t d 1 : First m a b a b 2 : o r r t d m a e : u i e r r b d _ t : Antibody - e s i e t _ t : e o a t t l o r : o c label i _ t : p e IHC - i s i e _ e : Type of cells to score ( TC or IC ) s _ t : FFPE s e o t t _ : RNA r i kit s _ t : FFPE s e o t t _ : DNA r i kit Dual - i y e s i F r e y e s i o e a d t IHC score (0 -3) l d DNA l d RNA u : t s : u : u : u : Args : Args : Args : Args : Args : 118 Args : Args : Args : Args : Args : u : u : u : t s : Blood p l a p y i e s Gene r i data s _ p : l d s y i _ e : Pane of o e to s e t t : i i t e b _ e : l i tube type u : p o e _ p : l d RNA t m : l s t m e _ e : Panel of genes to l b d _ p : Whole blood p e i e _ e : t u i speed time : t u i time 79 < f _ e _ r i _ l s >( RNA_sample , platform , e _ e ) 80 81 82 83 84 85 86 87 < l _ o _ p >( patient , tube_type , u ) 88 89 90 91 92 93 94 95 < l _ s >( o _ p , t u _ e , time ) 96 97 98 99 100 101 102 103 < l _ o e _ _ S >( s _ p , o e _ e ) 104 105 106 107 108 109 110 < f _ S _ l s >( o _ p , i y _ e ) 111 112 113 114 115 116 117 < i t _ L 3 2 8 0 >( patient , dose , route ) 118 119 120 121 122 123 124 125 < l _ o _ p >( patient , e n ) 126 127 128 129 130 131 132 < l e _ o _ p e >( patient , g _ h , t a ) 133 134 135 136 137 138 139 140 < r _ p >( sample , p t ) 141 142 143 144 145 i : i i t e a g _ h : g m l c e : p e l i r r l _ p : Blood p n o _ e : Pane of i i for i g t t : i i t e dose : Drug dose in mg / kg ro ute : i t i route p : l c a e p t : r t e u a n : i i t e m i : l i i o Tu mor p e e e Cell u i data Tu mor p a e e d i R r : u : u : u : u : Args : Args : Args : Args : r a e"
        },
        {
            "title": "Answer",
            "content": "119 Example of Wet Experiment in Material Background Low-grade heat, abundant in environments such as solar radiation, body heat, and industrial waste, presents significant opportunity for energy harvesting. Thermogalvanic cells (TGCs) convert such heat directly into electricity via redox reactions at electrodes maintained at different temperatures. The thermopower of these cells, measure of voltage generated per unit temperature difference, depends primarily on the entropy change (ŒîùëÜ) and concentration difference (Œîùê∂) of redox species between hot and cold electrodes. Traditional aqueous redox electrolytes exhibit limited thermopowers, typically below 2 mV K1, constraining their practical efficiency. Recent advances focus on enhancing thermopower by increasing ŒîùëÜ through solvent reorganization or structural changes of redox couples, and by increasing Œîùê∂ via selective complexation or confinement of redox ions. Thermoresponsive polymers have been employed to induce temperature-dependent interactions with redox ions, enabling polarization switching between ùëõ-type and ùëù-type behavior, which reverses the direction of electron flow and expands operational versatility. notable development involves the use of methylcellulose (MC), biocompatible, low-cost polymer exhibiting temperature-dependent hydrophilic-to-hydrophobic transitions. When incorporated into an aqueous iodide/triiodide (I/I 3 ) redox electrolyte, MC interacts hy3 concentration at the 3 ions above its gelation temperature, reducing free drophobically with hot electrode. This interaction induces polarization switch from ùëõ-type to ùëù-type thermopower and simultaneously enhances both ŒîùëÜ and Œîùê∂ due to gelation and ion complexation effects. Further enhancement is achieved by adding potassium chloride (KCl), which complexes with 3 ions, promoting reversible aggregation and dissociation processes. This salt-induced MC and complexation lowers the gelation and polarization transition temperatures and significantly amplifies thermopower. The optimized ternary electrolyte (I/I 3 + 2 wt% MC + 0.3 KCl) exhibits record-high thermopowers of approximately 8.18 mV K1 (ùëõ-type) and 9.62 mV K1 (ùëù-type), an order of magnitude greater than pristine electrolytes. Electrochemical characterization reveals improved electron transfer kinetics and ionic conductivity in the ternary system, resulting in higher current densities and lower internal resistance in TGCs. Under 15 temperature difference, single ùëõ-type and ùëù-type cells achieve maximum power outputs of 27.78 ùúáW and 80.47 ùúáW, respectively, with normalized power densities surpassing previous iodide/triiodide-based systems. This approach demonstrates that integrating thermoresponsive biopolymers with salt-induced complexation in redox electrolytes can substantially boost thermogalvanic performance. The findings open pathways for cost-effective, scalable liquid thermocells capable of efficient lowgrade heat harvesting, leveraging abundant, environmentally benign materials and tunable electrolyte properties for enhanced energy conversion. Action Pool 120 Args : Args : Args : Args : Args : Args : u : u : t s : u : u : n e t y o e u l o n e t y with MC a e t y o i r i -/ I3 - c l s t s t : u n to stir a n : r g time c l : c l s t to heat p t : g e r r e o e : t l r t l o _ u : u of h e l p e n _ c l : -/ I3 - + MC c l K _ c r o : Molar c r o of KCl _ u : u of a u d I 2 _ u : u of i a _ u : u of o e water 1 < p p t I -/ I3 - c l >( KI_amount , I2_amount , e _ u ) 2 3 4 5 6 7 8 9 < Heat c l solution >( c l , p t ) 10 11 12 13 14 15 16 < Add h e l to c l >( c l , _ u ) 17 18 19 20 21 22 23 < Stir u n n c y >( solution , a n ) 24 25 26 27 28 29 30 < Add KCl to a l r t >( a _ c l , _ c r o ) 31 32 33 34 35 36 37 < Store c l in r r r >( c l , p t , a n ) 38 39 40 41 42 43 44 45 < Fill r e cavity >( c l , u ) 46 47 48 49 50 51 52 < Set cold c d m a e >( the rmocell , p t ) 53 54 55 56 57 58 59 < Heat hot c d gradually >( thermocell , g _ p t ) 60 61 62 63 64 65 66 < o open - c voltage >( thermocell , a _ g ) 67 68 69 70 71 72 73 < s e t e p t s >( thermocell , r o e ) 74 75 76 77 78 79 80 < n e r load >( thermocell , e o e ) 81 r e : r e setup g _ p t : i hot c d m a e c l : p d c l t e u : r t e u u i : r time r e : e e e c t e u : Cold c d m a e r e : r n e c d _ g : Data u t d c t m l : r n e c t m u s : p t s o l r t : p d c l v m : u to fill r e with t l cold c d e c with p t g i S e e o e ready for use Voltage - p t data m a e s m s l h o l u : u : u : u : t s : u : Args : Args : Args : Args : Args : Args : 121 Args : Args : Args : Args : u : u : u : u : u : l d p Power e i data o i p r data r e with load c s l : Raw c l s l m : c l s l e o e : UV - Vis t e s l : c r d p i i _ t : u n ratio r e : r n e c p n m r : i e i n e e r e : r n e c under load r _ e : r m u e e e a _ g : t m u e e e 82 83 84 85 86 87 < o u n and voltage >( thermocell , r _ e , a _ g ) 88 89 90 91 92 93 94 95 < f UV - Vis c s y >( sample , c m r ) 96 97 98 99 100 101 102 < u a e for analysis >( sample , u n _ t ) 103 104 105 106 107 108 109 < t l r t sample >( p ) 110 111 112 113 114 115 < f c i l m y >( c l , e o t , n _ e ) 116 117 118 119 120 121 122 123 < Dry c l under vacuum >( c l , p t , a n ) 124 125 126 127 128 129 130 131 < f FTIR c s y >( sample , R _ t e ) 132 133 134 135 136 137 138 < s ionic d i y >( c l , d i y _ e , p t _ g ) 139 140 141 142 143 144 c l : Test c l c u v _ e : d i y s m d c m a e _ g : p t range for s m e t y : Test c l p n s : c c i i r n a _ e : t s n rate e o e : u l r t m a e : i e r r r o : i time p : Dried d a e R _ t e : FTIR c m r Dr ied c l p e n t t vs p t data t d p FTIR c m CV v e n : u : u : u : Args : Args : Args : Args :"
        },
        {
            "title": "Answer",
            "content": "122 Example of Wet Experiment in Physics Background This research domain focuses on the analysis and synthesis of nonlinear discrete-time systems, digital filters, and chaotic circuits, emphasizing stability, noise quantification, and complex dynamical behaviors. In digital filter design, quantization noise arising from finite word-length effects is critical concern. Methods have been developed to compute noise covariance matrices associated with extended digital filters, enabling the evaluation of roundoff noise not only at storage nodes but also at other internal nodes. These computations involve iterative matrix summations and transformations, where matrices representing system dynamics and noise propagation are manipulated to yield noise covariance matrices. The approach typically uses state-space representations and involves solving matrix equations that incorporate system matrices and noise input vectors, allowing for precise quantification of noise effects in fixed-point digital filters. In nonlinear discrete-time systems with slope-restricted nonlinearities, absolute stability criteria are essential for ensuring asymptotic stability in the large. frequency-domain criterion has been formulated for single-input single-output Lure-type systems, where the nonlinearity satisfies sector and slope restrictions. The criterion involves verifying an inequality over the unit circle in the complex plane, incorporating the systems frequency response and parameters bounding the nonlinearitys slope. This approach extends the system order and applies Lyapunov function techniques to establish sufficient conditions for global asymptotic stability, providing rigorous tool for stability analysis in nonlinear discrete-time control systems. The study of chaotic attractors in simple autonomous circuits reveals that even minimal configurations with piecewise-linear nonlinear elements can exhibit complex chaotic dynamics. third-order reciprocal circuit with single nonlinear resistor characterized by three-segment piecewise-linear function demonstrates chaotic attractors with structures distinct from classical examples like the Lorenz and R√∂ssler attractors. The systems dynamics are governed by coupled differential equations describing voltages and currents in capacitors and inductors, with nonlinear feedback inducing chaos. The attractor includes invariant sets containing equilibria with specific eigenvalue configurations, and its persistence is confirmed over ranges of circuit parameters. This research highlights the role of circuit reciprocity and nonlinear characteristics in generating and sustaining chaotic behavior, contributing to the understanding of nonlinear dynamics in electrical circuits. Collectively, these areas integrate advanced mathematical toolssuch as state-space modeling, frequency-domain analysis, Lyapunov stability theory, and nonlinear dynamicsto address challenges in system stability, noise management, and chaotic behavior in engineering systems. Action Pool Args : u : e e r t p t 1 : First a o m e a i 2 : o a i c o t u r : u r p n s o : l a s o m e 1 < Build c with component >( capacitor1 , capacitor2 , inductor , i r ) 2 3 4 5 6 7 8 9 10 < Set a o value >( capacitor , a a _ u ) 11 12 13 14 15 16 17 < Set u r value >( inductor , u n _ u ) 18 a o : g a i c c n _ u : a a value to set f r a i R r : Args : Args : 123 Args : Args : Args : Args : Args : u : u : u : u : u : t s : n e r t f r n t n a e r t u i o g t C i e n e e t c u : c with p n o c n _ e : i o g t i c : g n t n t e _ u : u n value to set p _ e : Time step for e a t a n e t _ h : e a t to use c : n e r t t _ d o : t v a and r v e r t : t i c u i a n _ f : u i a e s e _ a n : Total u i time i r : l a s o m e o c c : d a value o _ a e : Piecewise - e slope u 19 20 21 22 23 24 < f r n e resistor >( resistor , d a , p _ a e ) 25 26 27 28 29 30 31 32 < n c u elements >( circuit , n i _ e ) 33 34 35 36 37 38 39 < t i i i state >( circuit , t _ d o ) 40 41 42 43 44 45 46 < Set u i param eters >( step_size , e t _ h ) 47 48 49 50 51 52 53 < Run c simulatio >( circuit , u i _ f , e _ a n ) 54 55 56 57 58 59 60 61 < r v a r c i >( u i _ u , t _ e ) 62 63 64 65 66 67 68 < r c e r c i >( u i _ u , r _ n ) 69 70 71 72 73 74 75 < e e phase portrait >( t _ a , r _ a , j i _ n ) 76 77 78 79 80 81 82 83 < n y r o a t s s >( s _ t t , j o _ a ) 84 85 86 87 88 89 90 < Vary c paramete rs >( circuit , a e _ e , a e _ g ) 91 92 93 94 95 96 97 98 < l b r i behavior >( a e _ e _ u , b t _ t a ) 99 t _ a : t t e r c e _ a : r t e r p e o _ n : 2 plane for j i i i : Base c c i a n a e _ e : a e to vary a e _ g : Range of u to test u i _ u : p from u i u n _ n : c c r b c to r s l o _ u : p from u i o g _ e : c c t p t to r p e _ t t : e e phase t t a t _ a : p e t r c i S l o s s with time i data r o o t and u r Phase t t u z o l e time i data r time i data a e weep u s t s : u : u : u : u : Args : Args : Args : Args : Args : Args : t s : u t a y r l a e _ e _ u : u from a e r i t l _ t a : t a for b t a i 100 101 102 103 104 105 < n y i c orbits >( j o _ a , t _ r o _ a ) 106 107 108 109 110 j o _ a : t r c i e n _ r o _ a : a e for t t t P o orbit r e t s t s : Args : Answer A.3.5. Experimental Reasoning"
        },
        {
            "title": "Images",
            "content": "125 Question Using the timefrequency ridge data points (ùë°, ùëì ) from the first image, estimate the chirp mass ùëÄùëê via the Newtonian approximation and ùë°ùëê = 0. From the second image, the noise-weighted integral is: ùêΩ = ùëì ùëìùëöùëñùëõ ùëìùëöùëéùë• ùëì ( 7/3)/ùëÜùëõ( ùëì )ùëë ùëì = 1.3826254536 1060(SI units). (6) From the three image, the network SNR is ùúåùëõùëíùë° = 24 (detector factor ùêπ = 1). Under the stationary phase approximation, Solve for the luminosity distance ùê∑ùêø using and select the answer (in Mpc, rounded) from options 0 to 9 below. Options A. 100 B. 150 C. 210 D. 270 E. 350 F. 410 126 G. 500 H. 620 I. 750 J. 1000 Steps Step 1. Step 2. Read three points (ùë°, ùëì ), calculate ùëã = ùëì 8/3 and ùëå = ùë°, and use the least squares fitting to obtain the slope ùêæ. Step 3. Quality of the solution by ùêæ chirp: ùëÄ3 Step 4. ùëê = (ùëê/ùê∫) [((5/256)ùúã8/3)/ùêæ]3/5. 127 Step 5. The provided value of ùêΩ. Step 6. Step 7. Read ùúåùëõùëíùë° = 24 and the direction factor ùêπ = 1. Step 8. Substitution ùúå2 Step 9. Convert ùê∑ùêø to Mpc and round it to the nearest integer Answer ùëõùëíùë° = 4ùê¥2 ùêΩ and ùê¥ = (1/ùê∑ùêø)5/24ùúã2/3ùëÄùëê (ùê∫/ùëê3)5/6, work out ùê∑ùêø."
        },
        {
            "title": "Images",
            "content": "128 Question Based on the graphical models and prediction visualizations, which combination of template matching mechanism and reaction center identification approach is demonstrated across these three image, and what is the key chemical insight revealed by the successful prediction case? Options A. Template matching via subgraph isomorphism + Atom-level scoring with GNN embeddings; The model correctly identifies esterification reaction centers and preserves stereochemistry. B. SMILES sequence alignment + Molecular fingerprint similarity; Successful predictions maintain atomic connectivity but miss stereochemical information. C. Reaction center extraction + Graph neural network compatibility scoring; Correct predictions align with known reaction mechanisms and preserve molecular topology. 129 D. Rule-based template application + Attention-based focus mapping; The model captures functional group reactivity patterns and bond formation sites. E. Subgraph pattern matching + Energy-based scoring functions; Accurate retrosynthesis requires matching both structural patterns and chemical feasibility. F. Neural sequence-to-sequence + Structural motif recognition; Successful predictions demonstrate the importance of reaction template specificity. G. Graph isomorphism testing + Probabilistic template selection; The visualization shows positive scores on reactive atoms and negative on inactive regions. H. Molecular similarity comparison + Template ranking by frequency; Correct predictions occur when common reaction patterns are identified. I. Conditional graphical model + Hierarchical sampling; The model learns to assign high compatibility scores to chemically plausible reaction centers. J. Multi-class classification + Beam search optimization; Visualization reveals the models ability to distinguish active reaction sites from background structure. Steps Step 1. Step 2. Analyze the chemical reaction and retrosynthesis template schematic, identifying the highlighted reaction centers in the reaction participants. Step 3. Determine that the template matching mechanism is based on reaction center extraction, identifying chemical transformation sites through subgraph pattern matching. Step 4. Step 5. Parse the three-layer architecture of the GLN retrosynthesis pipeline, understanding the logical relationships between template sets, subgraph sets, and molecule sets. 130 Step 6. Identify the role of graph neural networks in compatibility scoring, analyzing the computation process of embedding vectors. Step 7. Step 8. Compare the core region matching between predicted reactions and true reactions in successful prediction cases. Step 9. Verify the consistency between prediction results and known reaction mechanisms, analyzing the preservation degree of molecular topology. Step 10. Integrate information from all three figures: template matching based on reaction center extraction provides structural foundation, GNN compatibility scoring provides chemical feasibility assessment, and actual cases validate method effectiveness. Step 11. Derive key chemical insight: successful retrosynthesis prediction requires simultaneously satisfying both structural pattern matching and reaction mechanism alignment conditions. Answer C"
        },
        {
            "title": "Images",
            "content": "131 Question The first, second, and third images display the Zonal Mean Ocean Heat Content (OHC) anomalies for 0-2000m in the Pacific, Atlantic, and Indian Oceans, respectively, in ZJ per degree latitude (ZJ deg-1) relative to 2000-2004 baseline, as function of time (2000-2024) and latitude. The fourth image shows the Oceanic Ni√±o Index (ONI) time series. Based only on the visual information from these four images, which of the following combined statements is most likely true? Options A. The onset of the OHC warming band ( 1 ZJ deg-1) in the Indian Ocean (Figure 3) near 40N occurred earlier than the warming in the Pacific (Figure 1) and Atlantic (Figure 2) at the same latitude. The strong El Ni√±o event in 2010 (Figure 4) coincided with an OHC cooling anomaly (blue) in the Pacific Ocean (Figure 1) in the 40S latitude band. B. The OHC anomaly in the equatorial Pacific (near 0, Figure 1) is predominantly one of cooling (blue) during strong El Ni√±o events (ONI 1.0, Figure 4), while the OHC anomaly in the equatorial Atlantic (near 0, Figure 2) largely remains near zero (white). In the Southern Hemisphere subtropics (30S to 50S), the sustained OHC warming ( 1 ZJ deg-1) in the Pacific began earlier than in the Atlantic and Indian Oceans. C. The OHC anomaly in the Pacific Ocean (Figure 1) near 20N was dominated by cooling during 2000-2010 and by warming during 2010-2024. The sustained cooling anomaly (blue) in the 50N-60N latitude band of the Atlantic Ocean (Figure 2) is unique feature not observed in the corresponding northernmost latitudes of the other two basins. D. The Indian Ocean (Figure 3) exhibits OHC cooling anomalies near 20S, whereas the Atlantic (Figure 2) and Pacific (Figure 1) have never shown cooling anomalies in the same latitude band. During the strong El Ni√±o event of 2015-2016 (Figure 4), the OHC warming strength in the Atlantic Ocean (Figure 2) at 40N reached its maximum value for the 2000-2024 period. E. The OHC anomaly strength in the Indian Ocean (Figure 3) at 40S consistently exceeded the anomaly strength in the Pacific Ocean (Figure 1) at 40S after 2016. During the strong La Ni√±a event of 2020-2022 (Figure 4), the OHC anomaly strength in the Pacific Ocean (Figure 1) near 40N remained between 0 and 1 ZJ deg-1. F. The OHC anomaly in all three basins (Figures 1, 2, 3) in the 20S to 40S latitude band shows continuously intensifying warming trend after 2016. The OHC anomaly strength in the Pacific Ocean (Figure 1) near 40N was greater than 0 ZJ deg-1 (non-blue) for all years in the 2000-2024 period. G. The sustained duration of OHC warming ( 1 ZJ deg-1) in the Atlantic Ocean (Figure 2) at 40S is longer than the sustained duration at 40N. The Pacific OHC anomaly (Figure 1) near 0 shows strong positive correlation with the ONI (Figure 4). H. In the 20S to 40S latitude band, the OHC anomaly in the Indian Ocean (Figure 3) is the most unstable (most frequent alternation between positive and negative) of the three basins. The Atlantic Ocean (Figure 2) at 40S has never reached an OHC warming anomaly strength of 2 ZJ deg-1 since 2000. I. The OHC warming band ( 1 ZJ deg-1) in the Pacific Ocean (Figure 1) at 40N started after 2014, approximately five years later than the warming onset in the Atlantic Ocean (Figure 2) at 40N. The La Ni√±a event in 2010-2011 (Figure 4) coincided with strong OHC cooling anomaly (blue) in the Pacific Ocean (Figure 1) at 40N. J. The Indian Ocean (Figure 3) exhibited strong warming ( 2 ZJ deg-1) only in the Southern Hemisphere (0S southward) during 2000-2024. The OHC anomaly in the 60S-40S latitude band of the Atlantic Ocean (Figure 2) was negative (blue) before 2010. Steps Step 1. Step 2. Strong warming centers are observed near 40N and 40S (deep red 3 ZJ deg-1). The equatorial band (0) OHC anomaly alternates significantly (blue/red) and is strongly related to time/ENSO. Sustained strong warming ( 1 ZJ deg-1) at 40S begins around 2014. Step 3. 133 Step 4. Strong warming is present at 40S (deep red 3 ZJ deg-1). Warming at 40N is present but slightly weaker (red 2-3 ZJ deg-1). persistent cooling (blue) anomaly is seen in the 50N-60N band since 2010. Sustained strong warming at 40S begins around 2016. Step 5. Step 6. The main warming center is at 40S. The tropical region shows frequent anomaly changes. Sustained strong warming at 40S begins around 2016. Step 7. Step 8. Provides the timing of El Ni√±o (positive peaks) and La Ni√±a (negative peaks) events. Step 9. Evaluate Option 1 : S1 (Figures 1, 2, 3): The warming band ( 1 ZJ deg-1) at 40N in the Indian Ocean (Figure 3) only clearly appears after 2022. Both the Pacific and Atlantic Oceans show this warming starting around 2014. S1 is FALSE. Step 10. Evaluate Option 2 : S1 (Figures 1, 2, 4): During strong El Ni√±o events (e.g., 2015-2016, Figure 4), the equatorial Pacific (Figure 1, 0) is blue (cooling/negative anomaly), confirming negative correlation with ONI. The equatorial Atlantic (Figure 2, 0) remains mostly white (near zero anomaly) during these periods. S1 is TRUE. S2 (Figures 1, 2, 3): In the 30S to 50S band, the Pacific (Figure 1) sustained strong warming ( 1 ZJ deg-1) began around 2014. The Atlantic (Figure 2) and Indian (Figure 3) sustained warming began around 2016. Thus, the Pacific began earlier. S2 is TRUE. Conclusion: Option 1 is TRUE. Step 11. Evaluate Option 3 : S1 (Figure 1): The 20N band in the Pacific shows mostly blue/white (cooling/zero anomaly) during 2000-2010. It shows mixed red/blue (warming/- cooling) during 2010-2024. The description of the dominant anomaly sign for the two periods is incorrect. S1 is FALSE. Step 12. Evaluate Option 4 : S1 (Figures 1, 2, 3): While the Indian Ocean (Figure 3) shows cooling near 20S, the Pacific (Figure 1) also shows cooling (blue) in the 20S band around 2004-2006. S1 is FALSE. Step 13. Evaluate Option 5 : S1 (Figures 1, 3): The OHC anomaly strength at 40S in the Pacific (Figure 1) is consistently high ( 3 ZJ deg-1) after 2016, whereas the Indian Ocean (Figure 3) strength weakens significantly around 2018-2020. S1 is FALSE. Step 14. Evaluate Option 6 : S1 (Figures 1, 2, 3): The warming in the 20S to 40S band is not continuously intensifying in all three basins after 2016; the Indian Ocean (Figure 3) shows significant weakening/cooling patch around 2018-2020. S1 is FALSE. Step 15. Evaluate Option 7 : S1 (Figure 2): The Atlantic 40S warming ( 1 ZJ deg-1) starts around 2016, while 40N warming starts around 2014. 40S warming has shorter duration. S1 is FALSE. Step 16. Evaluate Option 8 : S1: In the 20S to 40S latitude band, the OHC anomaly in the Indian Ocean (Figure 3) is the most unstable (most frequent alternation between positive and 134 negative) of the three basins. S1 is TRUE. (Note: This is the first part of the original Option 8 and is retained as True).S2 : The Atlantic Ocean (Figure 2) at 40S has never reached an OHC warming anomaly strength of 2 ZJ deg-1 since 2000. Check: In Figure 2, the 40S band clearly shows colors corresponding to 2 ZJ deg-1(dark red/deepest red) starting around 2016. Therefore, S2 is FALSE. Step 17. Evaluate Option 9 : S1 (Figures 1, 2): The onset of warming (ùëîùëíùëû1 ZJ deg-1) at 40N in both the Pacific (Figure 1) and Atlantic (Figure 2) occurs around 2014. There is no 5-year lag. S1 is FALSE. Step 18. Evaluate Option 10: S1 (Figure 3): The Indian Ocean (Figure 3) shows strong warming ( 2 ZJ deg-1) in the Northern Hemisphere near 40N after 2022. S1 is FALSE. Answer Example of Experimental Reasoning in Energy Images Question Based on the thermal energy storage (TES) state-of-charge visualizations shown in the two images, analyze the operational patterns across the 7-day period. The first image displays four TES units (TES1-TES4) operating independently, while the second image shows the same units under cooperative operation. During the time period from Day 3 to Day 5, which specific operational advantage of the cooperative mode most directly explains the consistently higher storage capacity utilization observed in TES4 compared to its independent operation? Options A. Cooperative operation allows TES4 to receive excess thermal energy from microgrids without storage devices during high solar generation periods, maintaining near-maximum capacity B. The cooperative mode reduces TES4s discharge rate during peak thermal demand hours through load balancing across all microgrids C. Independent operation causes TES4 to experience more frequent charging cycles due to isolated thermal load requirements D. Cooperative operation eliminates the need for TES4 to supply thermal energy during nighttime hours through grid-level coordination E. The sharing of thermal energy in cooperative mode increases TES4s charging efficiency by 15-20% through optimized heat transfer F. Independent operation requires TES4 to maintain minimum reserve capacity for emergency thermal supply, preventing full utilization G. Cooperative mode enables TES4 to store thermal energy generated by micro-turbines from neighboring microgrids during low-demand periods H. The coordinated operation reduces thermal losses in TES4 by synchronizing chargedischarge cycles with solar thermal availability patterns I. Independent operation forces TES4 to discharge more frequently to meet local thermal loads that exceed its microgrids generation capacity J. Cooperative mode implements hierarchical control strategy that prioritizes filling TES4 before activating expensive micro-turbine generation Steps Step 1. Step 2. In the first image showing independent operation, observe TES4 (subplot h) during Days 3-5: the storage level exhibits significant valleys, dropping to approximately 20-30 kWh multiple times, and rarely maintains the maximum 100 kWh capacity for extended periods. The surface shows irregular topology with frequent charge-discharge cycles. Step 3. 136 Step 4. In the second image showing cooperative operation, examine TES4 (subplot d) during the same Days 3-5 period: the storage level consistently maintains near-maximum capacity (90100 kWh) for prolonged periods, particularly during daytime hours (approximately 8h-16h). The surface displays prominent yellow plateaus indicating sustained full capacity. Step 5. The key difference occurs during daytime hours when solar thermal generation is high. In cooperative mode, microgrids without TES devices can transfer their surplus solar thermal energy to TES4, enabling it to reach and maintain maximum capacity. In independent operation, each microgrid must consume or waste its own solar thermal energy locally, and TES4 can only store energy from its own microgrids solar panels while also meeting that microgrids immediate thermal load demands. This fundamental difference in energy sharing capability directly explains why TES4 maintains consistently higher storage levels in cooperative mode, as stated in the papers analysis that the surplus thermal solar power of the microgrid without energy storage can be fully stored by the energy storage of another microgrid via local power exchange. Answer A"
        },
        {
            "title": "Images",
            "content": "137 Question Based on the first image and the second image in the document, which statement is completely correct? Options A. First image (a) is an SIW filter; First image (j) uses probe array-measured data for reconstruction (2 GHz); Second image (a) assigns 1 to fully metal areas, and (b) shows ùêªùõæ variation. B. First image (b) is S-parameters of the coupler (2 GHz); First image (h) uses HFSS data with finite ground plane for reconstruction; Second image (a) assigns 0 to fully dielectric areas, and (c) shows ùêªùë• variation. 138 C. First image (e) is single probe-measured magnetic field (2 GHz); First image (d) uses HFSS data without ground plane for reconstruction; Second image (a) assigns 0 to fully metal areas, and (b) shows ùêªùë• variation. D. First image (i) is probe array-measured magnetic field (1.84 GHz); First image (f) uses HFSS data with ground plane for reconstruction; Second image (a) assigns 1 to partially metal areas, and (c) shows ùêªùõæ variation. E. First image (g) is sampled field from HFSS without ground plane (2 GHz); First image (j) reconstructs field 4 mm from the coupler; Second image (a) assigns 0.5 to fully dielectric areas, and (b) shows ùêªùõæ variation. F. First image (c) is single probe-measured field (2 GHz); First image (h) reconstructs field 0.5 mm from the coupler; Second image (a) assigns 1 to fully metal areas, and (c) shows ùêªùë• variation. G. First image (b) is S-parameters of the filter (1.84 GHz); First image (f) uses single probe-measured data for reconstruction; Second image (a) assigns 0 to partially dielectric areas, and (b) shows ùêªùë• variation. H. First image (d) uses probe array-measured data for reconstruction (2 GHz); First image (i) is HFSS-simulated field with ground plane; Second image (a) assigns 1 to fully dielectric areas, and (c) shows ùêªùõæ variation. I. First image (e) is probe array-measured field (1.84 GHz); First image (j) reconstructs field 0.5 mm from the filter; Second image (a) assigns 0 to fully dielectric areas, and (b) shows ùêªùõæ variation. J. First image (g) is sampled field from HFSS with ground plane (2 GHz); First image (d) reconstructs field 4 mm from the coupler; Second image (a) assigns 1 to partially metal areas, and (c) shows ùêªùë• variation. Steps Step 1. 139 Step 2. Step 3. Extract core features of the first image (structure + frequency + measurement/simulation + reconstruction distance) Step 4. Structure & frequency: The first image (a) is an SIW coupler (not filter), and (b) its S-parameters are measured at 2 GHz (not 1.84 GHz, which is the second images frequency). Step 5. Measurement/simulation source: (c)/(g) = HFSS-simulated field: (c) = no ground plane, (g) = with finite ground plane; (e)/(i) = measured field: (e) = single probe, (i) = probe array; Step 6. Reconstruction distance: All reconstructed fields (d)/(f)/(h)/(j) are 0.5 mm from the coupler; measurement plane distance = 4 mm (not reconstruction distance). Step 7. Eliminate options with first image errors: Option 1 (a=filter, second image (a)=1 for metal, (b)= ùêªùõæ ): Structure error + material assignment error + field component error. Option 2 (second image (a)=0 for dielectric, (c)= ùêªùë• ): Material assignment error + field component error. Option 4 (i=1.84 GHz, f=HFSS with ground plane, (a)=1 for partial metal): Frequency error + reconstruction source error + material assignment error. Option 5 (g=no ground plane, j=4 mm reconstruction, (a)=0.5 for dielectric): Simulation source error + reconstruction distance error + material assignment error. Option 6 (c=single probe-measured, (a)=1 for metal, (c)= ùêªùë• ): Field source error + material assignment error + field component error. Option 7 (b=filter S-parameters, 1.84 GHz, (a)=0 for partial dielectric): Structure/frequency error + material assignment error. Option 8 (d=probe array data, i=HFSS-simulated): Reconstruction source error + field source error. Option 9 (e=probe array-measured, 1.84 GHz, a=filter, (a)=0 for dielectric, (b)= ùêªùõæ ): Measurement method error + frequency/structure error + material assignment/field component error. Option 10 (d=4 mm reconstruction, (a)=1 for partial metal, (c)= ùêªùë• ): Reconstruction distance error + material assignment error + field component error. Step 8. Extract core features of the second image (material assignment + field components). Step 9. Material assignment rule: (a) 0 = fully metal-covered, 1 = fully dielectric-covered, 0-1 = partially metal-covered (not reverse or arbitrary values). Step 10. Field components: (b) = ùêªùë• variation, (c) = ùêªùõæ variation (not mixed). Step 11. Verify remaining option 3: First image part: \"First image (e) is single probe-measured magnetic field (2 GHz)\" matches (e)=single probe, 2 GHz; \"First image (d) uses HFSS data without ground plane for reconstruction\" (d) is reconstructed from (c)=HFSS no ground plane, correct. Second image part: \"Second image (a) assigns 0 to fully metal areas\" matches material rule; \"Second image (b) shows ùêªùë• variation\" matches (b)= ùêªùë• , correct. Confirm option 3 is completely correct. All parts of option 3 align with the first images structure/frequency/field source/reconstruction rule and the second images material assignment/field component definition, with no contradictions. Answer C"
        },
        {
            "title": "Images",
            "content": "141 142 Question According to the first image, if one wants to inhibit tumor development by targeting non-tumor cells within the body, which cells should the monoclonal antibody be made against? Using which method from the second image to deliver the antibody can achieve inhibition of tumor development from deeper level? Which type in the third image does this method belong to?Please choose from the given options: Options A. Siglec-10;A;A B. Siglec-10;A;B C. Siglec-10;B;A D. Siglec-10;B;B E. Siglec-10;C;A F. CD24;A;A G. CD24;A;B H. CD24;B;A I. CD24;B;B J. CD24;C;A Steps Step 1. Step 2. The proteins identified in the image that can serve as targets are mainly Siglec-10 and CD24. Step 3. The topic requires starting from non-tumor cells, so Siglec-10 was chosen. Step 4. Step 5. Identify the three main strategies for NP-mediated CD24-Siglec10 axis-targeted therapy 144 shown in the figure. Step 6. Among them, strategies and both use antibodies to directly block signal transduction on the cell surface, whereas strategy uses siRNA to inhibit the expression of the target protein at the nucleic acid level. Step 7. Strategy is deeper approach to suppress tumor development. Step 8. Step 9. Identifying two modes of nanoparticle-based drug delivery systems in the image. Step 10. The surface of the nanomaterials delivering siRNA does not carry antibodies and is passively targeted. Answer E"
        },
        {
            "title": "Images",
            "content": "145 Question Images are Li-ion probability densities in Li-ion conductors. Li-ion probability densities are colored red. Which material does represent the best Li-ion conductivity? Options A. Li10GeP2S12 B. Li7P3S11 C. Li2S D. ùõæ-Li3PS4 E. Li4GeS4 F. Li3.25Ge0.25P0.75S4 G. Li2S-P2S5 H. Li10SnP2S12 I. Li10SiP2S12 J. Li6PS5Cl Steps Step 1. 146 Step 2. Find the Li-ion probability densities of materials in the figure. Step 3. Determine the largest region of the Li-ion probability densities. The answer is Li10GeP2S12. Answer A"
        },
        {
            "title": "Images",
            "content": "147 Question Please answer based on the first image: How many peaks exceeding 20 appeared in the first 60 timesteps of the Large initialization for Signal 2 response in each of the two examples?Based on the second image, after training, does Branch 1 with small initialization increase (+) or decrease (-), and does Branch 2 with large initialization increase (+) or decrease (-)? Options A. 1,3;+- 148 B. 0,0;++ C. 1,2; D. 1,1;++ E. 1,3;-+ F. 2,1; G. 2,2;-+ H. 3,1;-+ I. 3,2;+- J. 0,3;-+ Steps Step 1. Step 2. Realize: Signal 2 response is blue line. Step 3. Define the counting range: Large initialization, Neuron state > 20,Timestep < 60, in each of the two examples. Step 4. Find out that there is 1 in example1 and 3 in example2. Answer: 1,3. Step 5. 149 Step 6. Branch 1 small init: the KDE line and histogram show shift. Before training, Branch 1 small init was lower around 0-0.2, after training, its higher around 0.8-1.0, so increase (+) Step 7. Branch 2 large init: before training, it was peak around 1.0, after training, the density decreases there, so decrease (-). Step 8. Conclude:1,3;+- Answer A.4. Supplementary Evaluation Results 150 Figure 31 Scientific Deep Research Across Subjects: Combined subject-wise performance of LLMs and agents on deep research tasks. Figure 32 Idea Generation Across Subjects: Subject-wise scores for idea generation. Figure 33 Wet Experiment Across Subjects: Subject-wise Action Sequence Similarity (SS) and Parameter Accuracy (PA) performance in wet experiments. 151 Model Properties Micro-experiments Macro-experiments Data DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok6.62 10.61 7.14 5.88 8.09 7.30 11.94 7.00 5.84 5.11 5.84 7.30 10.22 8.03 10.22 10.95 8.76 9.49 11.68 15.00 8.82 8.03 9.49 10.37 21.57 23.47 24.64 19.18 20.21 19.19 23.75 30.00 14.42 14.42 12.50 17.31 21.15 18.27 23.08 17.31 18.27 16.35 23.08 26.14 20.19 23.08 20.19 21.65 15.38 15.38 20.00 17.39 20.00 12.50 11.54 0.00 3.85 3.85 7.69 15.38 26.92 15.38 23.08 19.23 11.54 11.54 15.38 22.73 15.38 15.38 11.54 15.38 9.80 10.00 12.12 5.41 10.00 10.20 6.12 13.79 3.92 3.92 3.92 7.84 5.88 5.88 11.76 5.88 7.84 1.96 7.84 10.87 7.84 9.80 11.76 4.00 Table 10 Deep Research Task Metrics (LLMs): Category-wise scores across Properties, Micro/MacroExperiments, and Data. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Agent Properties Micro-experiments Macro-experiments Data SmolAgents(GPT-4.1) SmolAgents(Gemini-2.5-Flash) Owl(GPT-4.1) Owl(Gemini-2.5-Flash) WebThinker XMaster InternAgent OpenAI Deep Research(o3) OpenAI Deep Research(o4-mini) Grok-Search(Grok-4) Kimi-Search(Kimi-k2) Doubao-Search(Seed-1-6) Perplexity(Sonar-Pro) 13.87 12.41 6.57 6.61 13.87 13.14 13.24 16.06 14.60 14.18 9.49 7.35 6.57 16.35 24.04 18.27 14.29 18.27 17.31 24.04 14.42 22.12 22.73 22.92 16.50 21.15 26.92 26.92 19.23 9.52 26.92 19.23 26.92 11.54 19.23 19.23 11.54 0.00 19.23 5.88 11.76 9.80 8.33 3.92 5.88 9.80 9.80 11.76 11.76 14.00 3.92 3. Table 11 Deep Research Task Metrics (Agents): Category-wise scores across Properties, Micro/Macro-Experiments, and Data. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. 152 Model Numerical Calculation Statistical Analysis Simulation Metric Calculation Data Processing Predictive Modeling DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok-4 19.30 31.76 25.61 14.62 26.90 25.15 25.29 29.24 18.71 20.59 25.15 32.75 25.73 29.24 26.90 28.65 35.09 16.96 19.30 33.53 30.99 33.33 22.81 32. 19.05 23.81 28.57 19.05 23.81 23.81 28.57 38.10 14.29 19.05 23.81 38.10 28.57 23.81 19.05 42.86 28.57 23.81 23.81 33.33 28.57 38.10 33.33 19.05 26.32 26.32 26.32 15.79 31.58 26.32 31.58 31.58 15.79 15.79 26.32 26.32 31.58 26.32 26.32 26.32 26.32 21.05 21.05 35.29 31.58 26.32 31.58 31.58 35.71 39.29 39.29 25.00 35.71 39.29 35.71 39.29 25.00 21.43 32.14 39.29 39.29 42.86 32.14 42.86 39.29 32.14 21.43 46.43 53.57 42.86 35.71 40.74 42.86 47.62 42.86 28.57 52.38 47.62 47.62 47.62 23.81 23.81 38.10 47.62 52.38 42.86 38.10 38.10 52.38 38.10 42.86 50.00 47.62 47.62 47.62 42.86 27.27 45.45 27.27 9.09 18.18 27.27 27.27 45.45 0.00 18.18 27.27 27.27 27.27 27.27 36.36 27.27 36.36 18.18 36.36 45.45 36.36 45.45 18.18 54.55 Table 12 Dry Experiment Function Categories: Completion scores across six function types. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Model Signal Perception Attribute Understanding Comparative Reasoning Causal Reasoning Intern-S1 Intern-S1-mini Qwen3-VL-235B-A22B Qwen3-VL-Max Qwen3-VL-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-4 39.29 17.86 32.14 50.00 21.43 28.57 39.29 46.43 53.57 21.43 53.57 35.71 39.29 35.71 50.00 50.00 53.57 35.71 42.86 21.88 10.94 26.56 34.38 21.88 17.19 26.56 40.62 32.81 25.00 39.06 26.56 35.94 37.50 42.19 40.62 35.94 35.94 26.56 28.57 18.29 32.00 36.57 23.43 28.57 33.71 34.29 37.71 36.57 38.29 33.14 30.29 30.29 38.29 42.86 34.86 38.86 28. 37.50 20.83 41.67 41.67 29.17 25.00 29.17 54.10 37.50 54.17 29.17 41.67 41.67 54.17 50.00 29.17 58.33 37.50 41.67 Table 13 Experimental Reasoning by Type (Multi-choice Accuracy): Scores across signal, attribute, comparative, and causal reasoning. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. 153 Model Astronomy Chemistry Earth Energy Information Life Material Math Neuroscience Physics DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok11.76 6.25 0.00 0.00 5.88 5.88 5.88 11.11 11.76 11.76 5.88 23.53 5.88 17.65 11.76 5.88 5.88 5.88 17.65 12.50 11.76 17.65 5.88 5.88 10.00 9.09 20.00 9.09 10.00 10.00 20.00 0.00 0.00 9.09 9.09 9.09 9.09 9.09 9.09 18.18 18.18 9.09 9.09 14.29 9.09 9.09 9.09 9.09 0.00 20.75 0.00 24.00 0.00 22.45 0.00 23.26 0.00 27.08 0.00 19.61 0.00 20.83 0.00 33.33 0.00 11.11 0.00 9.26 0.00 7.41 0.00 12.96 27.78 0.00 18.52 10.00 0.00 25.93 0.00 22.22 0.00 16.67 14.81 0.00 18.52 10.00 0.00 27.66 22.22 0.00 20.37 10.00 22.22 10.00 18.37 10.00 10.47 16.67 12.50 7.14 5.26 16.67 16.67 11.11 10.00 10.00 10.00 5.00 10.00 5.00 20.00 10.00 0.00 10.00 10.00 35.29 10.00 15.00 5.00 16.67 0.00 0.00 8.00 6.25 9.30 9.41 13.10 16.28 5.75 6.90 4.60 9.20 9.20 9.20 13.79 9.20 9.20 8.05 12.64 12.00 9.30 11.49 11.49 10.47 7.89 7.89 0.00 7.14 15.79 5.26 10.53 7.89 7.89 5.26 15.79 5.26 13.16 2.63 10.53 7.89 13.16 5.26 10.53 17.86 7.89 5.26 13.16 10. 44.00 52.00 47.62 61.54 43.48 40.00 77.78 44.00 32.00 20.00 24.00 44.00 52.00 36.00 48.00 44.00 48.00 40.00 52.00 50.00 40.00 36.00 40.00 45.83 0.00 4.17 0.00 0.00 0.00 0.00 0.00 4.17 0.00 4.17 4.17 8.33 0.00 8.33 0.00 4.17 0.00 4.17 4.17 4.76 4.17 8.33 4.17 0.00 3.12 6.67 0.00 0.00 0.00 6.25 9.38 3.12 0.00 3.12 0.00 0.00 3.12 3.12 3.12 3.12 3.12 6.25 6.25 6.25 6.25 6.25 3.12 6.45 Table 14 Deep Research Across Subjects (LLMs): Subject-wise scores across ten scientific domains. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Agent Astronomy Chemistry Earth Energy Information Life Material Math Neuroscience Physics SmolAgents(GPT-4.1) SmolAgents(Gemini-2.5-Flash) Owl(GPT-4.1) Owl(Gemini-2.5-Flash) WebThinker XMaster InternAgent OpenAI Deep Research(o3) OpenAI Deep Research(o4-mini) Grok-Search(Grok-4) Kimi-Search(Kimi-k2) Doubao-Search(Seed-1-6) Perplexity(Sonar-Pro) 29.41 23.53 23.53 6.25 5.88 11.76 29.41 11.76 5.88 17.65 11.76 17.65 11.76 9.09 9.09 9.09 10.00 9.09 9.09 9.09 9.09 18.18 20.00 10.00 9.09 9.09 0.00 27.78 0.00 33.33 0.00 18.52 0.00 15.79 0.00 27.78 0.00 25.93 26.42 10.00 20.37 10.00 24.07 10.00 0.00 26.92 0.00 22.45 0.00 9.43 0.00 16.67 10.00 25.00 10.00 5.56 15.00 15.00 25.00 15.00 25.00 15.79 15.00 15.00 15.00 9.20 11.49 6.90 11.54 6.90 6.90 11.49 12.64 12.64 13.95 13.95 4.65 6. 15.79 10.53 7.89 0.00 23.68 10.53 10.53 13.16 21.05 7.89 10.53 8.11 15.79 28.00 44.00 44.00 41.67 36.00 44.00 52.00 20.00 40.00 75.00 45.83 32.00 40.00 4.17 4.17 4.17 8.33 4.17 0.00 0.00 16.67 12.50 4.17 0.00 0.00 4.17 3.12 3.12 0.00 0.00 6.25 9.38 6.25 6.25 0.00 9.38 3.12 6.25 0.00 Table 15 Deep Research Across Subjects (Agents): Subject-wise scores across ten scientific domains. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Model Astronomy Chemistry Earth Energy Information Life Material Math Neuroscience Physics DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-3 Grok-4 38.38 35.76 37.53 36.49 44.80 36.00 37.38 39.80 34.25 28.65 31.27 32.20 52.37 44.34 57.65 42.57 37.74 37.32 38.64 39.51 39.85 42.11 29.66 33.75 24.49 31.63 28.20 24.77 36.44 30.06 31.02 30.28 22.91 22.50 24.79 26.40 54.12 46.56 57.06 38.83 29.78 27.61 27.22 35.97 28.89 34.89 23.40 25.48 35.85 34.24 37.89 37.73 36.22 36.07 35.00 33.68 42.99 44.80 37.90 40.09 36.78 41.24 37.74 40.56 33.78 30.72 27.79 26.10 30.50 31.70 33.79 32.64 56.01 64.53 44.50 53.35 60.24 65.97 44.58 50.85 39.14 38.08 36.42 35.33 37.10 46.00 37.17 40.49 38.19 38.83 42.38 44.20 31.10 25.66 33.78 35. 32.09 36.26 33.30 34.21 37.48 31.62 35.25 33.12 30.35 30.47 29.19 31.15 48.58 38.24 46.78 38.35 34.79 32.59 34.39 34.14 35.19 35.24 31.04 30.44 32.11 35.96 34.38 32.80 39.78 35.28 35.98 35.42 30.26 25.62 26.17 29.28 50.25 39.80 52.41 40.77 36.63 33.06 35.12 35.35 36.85 37.31 30.11 30.96 31.77 36.47 32.15 26.96 44.86 35.59 35.34 34.98 29.80 26.14 26.83 32.30 54.82 41.00 56.25 45.42 37.86 33.34 36.93 35.49 38.39 38.14 27.29 30.30 29.46 35.88 27.00 29.16 36.58 30.56 31.06 30.12 27.42 25.26 25.86 27.99 50.99 36.49 55.04 40.36 36.86 27.42 31.00 30.03 35.69 34.44 26.01 27.54 29.53 33.88 30.07 31.91 38.43 32.18 32.46 30.31 26.20 24.94 25.72 25.37 47.46 38.61 47.62 38.43 32.42 29.51 31.12 32.14 33.66 32.13 26.43 27.58 34.20 37.21 33.46 34.02 43.59 35.31 36.52 34.54 32.05 29.65 30.77 32.78 56.55 43.61 57.21 44.50 38.78 34.93 36.28 35.18 37.44 40.90 33.26 33. Table 16 Idea Generation Across Subjects: Subject-wise scores. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Model Astronomy Chemistry Earth Energy Information Life Material Math Neuroscience Physics DeepSeek-V3.2 DeepSeek-R1 Intern-S1 Intern-S1-mini Kimi-k2 Qwen3-VL-235B-A22B Qwen3-235B-A22B Qwen3-Max Qwen3-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 grok-3 Grok-4 31.25 37.50 37.50 12.50 43.75 37.50 31.25 50.00 25.00 18.75 37.50 43.75 37.50 31.25 43.75 37.50 37.50 18.75 25.00 37.50 43.75 43.75 31.25 37.50 0.00 20.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 20.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 20.00 20.00 0.00 20. 20.83 10.00 33.33 10.00 25.00 10.00 18.75 10.00 22.92 20.00 29.17 10.00 25.00 30.00 31.25 30.00 18.75 10.00 18.75 10.00 27.08 10.00 33.33 40.00 27.08 40.00 27.08 30.00 22.92 10.00 33.33 10.00 33.33 20.00 18.75 10.00 18.75 0.00 32.61 30.00 33.33 40.00 35.42 30.00 29.17 20.00 27.66 20.00 14.29 35.71 28.57 14.29 21.43 14.29 14.29 28.57 7.14 14.29 14.29 28.57 35.71 28.57 21.43 28.57 28.57 14.29 21.43 38.46 28.57 21.43 14.29 30.77 27.50 33.75 33.75 21.25 33.75 35.00 35.00 37.50 20.00 25.00 35.00 33.75 31.25 38.75 33.75 35.00 40.00 23.75 25.00 38.46 33.75 41.25 32.50 37.97 44.44 55.56 48.15 33.33 44.44 40.74 44.44 48.15 33.33 33.33 51.85 48.15 40.74 44.44 44.44 51.85 51.85 37.04 33.33 55.56 48.15 51.85 40.74 51.85 29.41 29.41 18.18 0.00 16.67 16.67 17.65 22.22 5.56 17.65 22.22 27.78 22.22 22.22 27.78 22.22 22.22 27.78 22.22 37.50 27.78 27.78 11.11 43.75 16.67 29.17 16.67 4.17 20.83 20.83 20.83 25.00 12.50 12.50 20.83 29.17 20.83 12.50 20.83 20.83 37.50 16.67 16.67 34.78 29.17 25.00 20.83 25. 17.24 24.14 24.14 17.24 34.48 24.14 27.59 24.14 20.69 17.24 20.69 34.48 27.59 31.03 17.24 27.59 34.48 13.79 27.59 28.57 34.48 27.59 24.14 22.22 Table 17 Dry Experiment Across Subjects: Subject-wise scores. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. 155 Model Life-SS Material-SS Physics-SS Life-PA Material-PA Physics-PA 15.47 DeepSeek-V3.2 10.00 DeepSeek-R1 24.86 Intern-S1 14.15 Intern-S1-mini Kimi-k2 18.10 Qwen3-VL-235B-A22B 17.78 17.11 Qwen3-235B-A22B 17.37 Qwen3-Max 4.99 Qwen3-8B 15.72 Llama-4-Scout 20.79 GPT-4o 32.13 GPT-4.1 7.81 GPT-5 12.38 GPT-5.1 18.50 GPT-5.2-Pro 27.43 o3 31.46 o4-mini 5.31 Gemini-2.5-Flash 16.90 Gemini-2.5-Pro 20.00 Gemini-3-Pro 16.65 Claude-Opus-4.1 31.75 Claude-Sonnet-4.5 28.97 grok-3 27.29 Grok20.20 21.83 27.23 4.67 28.04 30.25 30.80 41.11 15.54 18.75 29.10 33.02 11.72 21.44 8.81 22.79 24.01 23.44 21.02 34.88 25.74 25.83 41.93 29.10 16.67 16.67 33.33 0.00 0.00 16.67 0.00 33.33 0.00 16.67 32.38 33.33 33.76 29.30 19.44 44.86 16.67 15.71 12.06 33.33 29.21 16.67 33.33 16.67 21.48 23.14 23.62 18.02 25.13 28.66 22.87 24.44 5.81 20.53 31.58 33.11 19.31 24.24 23.05 30.63 25.76 14.73 24.52 32.21 20.63 28.62 32.52 25.19 26.87 26.32 34.87 16.04 37.42 43.11 37.71 45.67 15.49 32.86 41.06 45.06 21.50 28.00 19.65 32.87 35.78 28.09 27.28 41.07 33.45 33.78 43.94 37.35 22.50 39.67 50.90 9.58 18.61 46.68 33.18 56.70 6.25 17.78 41.41 54.47 23.18 40.14 17.86 48.92 32.70 32.03 23.03 36.12 43.90 46.97 58.32 23.09 Table 18 Wet Experiment Across Subjects: Scores across Action Sequence Similarity (SS) and Parameter Accuracy (PA) categories. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table. Model Astronomy Chemistry Earth Energy Information Life Material Neuroscience Physics Intern-S1 Intern-S1-mini Qwen3-VL-235B-A22B Qwen3-VL-Max Qwen3-VL-8B Llama-4-Scout GPT-4o GPT-4.1 GPT-5 GPT-5.1 GPT-5.2-Pro o3 o4-mini Gemini-2.5-Flash Gemini-2.5-Pro Gemini-3-Pro Claude-Opus-4.1 Claude-Sonnet-4.5 Grok-4 47.06 23.53 58.82 52.94 29.41 41.18 41.18 35.29 70.59 47.06 52.94 58.82 64.71 52.94 52.94 47.06 58.82 52.94 52.94 27.27 27.27 36.36 36.36 36.36 27.27 54.55 36.36 36.36 45.45 18.18 45.45 45.45 27.27 36.36 45.45 45.45 36.36 18.18 27.78 40.00 18.52 30.00 31.48 50.00 31.48 50.00 24.07 60.00 27.78 30.00 37.04 60.00 37.04 60.00 37.04 30.00 33.33 40.00 31.48 30.00 29.63 50.00 31.48 30.00 33.33 40.00 38.89 30.00 35.19 50.00 25.93 60.00 37.04 20.00 33.33 40. 25.00 10.00 15.00 35.00 20.00 30.00 20.00 45.00 50.00 35.00 40.00 35.00 25.00 45.00 50.00 45.00 40.00 40.00 35.00 29.41 18.82 29.41 41.18 25.88 23.53 29.41 42.35 37.65 31.76 42.35 29.41 34.12 36.47 38.82 40.00 37.65 35.29 30.59 26.67 8.89 31.11 40.00 13.33 31.11 31.11 37.78 33.33 42.22 44.74 24.44 26.67 24.44 37.78 48.89 33.33 42.22 26.67 33.33 12.50 33.33 37.50 16.67 20.83 20.83 33.33 41.67 16.67 50.00 50.00 33.33 37.50 58.33 62.50 50.00 29.17 20.83 16.00 16.00 24.00 24.00 16.00 0.80 28.00 24.00 20.00 28.00 31.25 16.00 28.00 24.00 36.00 20.00 44.00 44.00 20.00 Table 19 Experimental Reasoning Across Subjects (Multi-choice Accuracy): Subject-wise scores across 10 scientific disciplines. Note: Because different subjects have different characteristics, the number of questions in each category is not the same (Figure 9). Therefore, the overall performance of the model cannot be obtained by directly averaging the values in the table."
        }
    ],
    "affiliations": [
        "Shanghai Artificial Intelligence Laboratory"
    ]
}