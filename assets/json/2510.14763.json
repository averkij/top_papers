{
    "paper_title": "COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes",
    "authors": [
        "Yunwen Li",
        "Shuangshuang Ying",
        "Xingwei Qu",
        "Xin Li",
        "Sheng Jin",
        "Minghao Liu",
        "Zhoufutu Wen",
        "Tianyu Zheng",
        "Xeron Du",
        "Qiguang Chen",
        "Jiajun Shi",
        "Wangchunshu Zhou",
        "Jiazhan Feng",
        "Wanjun Zhong",
        "Libo Qin",
        "Stephen Huang",
        "Wanxiang Che",
        "Chenghua Lin",
        "Eli Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models exhibit systematic deficiencies in creative writing, particularly in non-English contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, a novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify a two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilization with general data. A ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models."
        },
        {
            "title": "Start",
            "content": "COIG-Writer: High-Quality Dataset for Chinese Creative Writing with Thought Processes M-A-P, 2077AI"
        },
        {
            "title": "Abstract",
            "content": "5 2 0 2 6 1 ] . [ 1 3 6 7 4 1 . 0 1 5 2 : r Large language models exhibit systematic deficiencies in creative writing, particularly in nonEnglish contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilisation with general data. ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models. Project Homepage: https://COIG-Writer.github.io/ 1. Introduction Process supervision has transformed structured reasoning, for example, pushing math competition benchmarks to about 93% accuracy [20, 23] and enhancing multi-step reasoning [18, 28], yet creative writing, which accounts for about 40% of LLM applications [1, 24], lacks comparable methodological advances. We hypothesize this gap stems from fundamental misunderstanding: creative writing is not monolithic but compositional, requiring both narrative logic (structural planning) and linguistic expression (stylistic realization). Current creative writing models exhibit systematic failures across three dimensions. First, narrative structures converge to predictable templatesrepetitive narratives with limited variation dominate outputs [30]. Second, stylistic diversity collapsesdistinct authorial voices homogenize into what practitioners term AI flavor [5]. Third, cultural authenticity deteriorates catastrophically in non-English contextsChinese models produce Western narrative Figure 1. Overview of COIG-Writer construction and evaluation. Stage 1 (Data Construction): High-quality Chinese texts spanning 51 genres are collected and filtered, followed by expert reverse-engineering to extract creative prompts and reasoning processes, yielding 1,665 validated triplets. Stage 2 (Human Evaluation): Models trained on COIG-Writer undergo rigorous human preference evaluation through pairwise comparisons, with analysis of win rates and lexical diversity (TTR) to assess creative writing quality. structures with superficial cultural markers rather than authentic qi-cheng-zhuan-he (beginningdevelopment-turn-conclusion) progression [7]. We introduce COIG-Writer, Chinese creative writing dataset that uniquely captures the reasoning process underlying creative decisions. Our 1,665 expert-curated triplets span 51 genres, each containing: (1) reverse-engineered prompts, (2) detailed creative reasoning chains, and (3) final texts. While existing datasets prioritize either scale (e.g. WritingPrompts [9] (300K samples), ROCStories [22] (100K samples)) or breadth (e.g. COIG [35] (67K samples), LCCC [27] (12M samples)), they provide only input-output pairs without process data. COIG-Writer uniquely combines multi-genre coverage with explicit reasoning chains, enabling process-level learning of creative decision-making. Figure 1 illustrates our two-stage construction pipeline: (i) systematic collection and filtering of high-quality texts, followed by (ii) expert reverse-engineering to extract the implicit creative reasoning. Our experiments reveal three key findings: (1) Process supervision achieves 62.75% win rate in Chinese creative writing, but this requires stabilization ratio of approximately one creative-process sample to twelve general-purpose samples. Below this threshold, performance degrades monotonically (with win rates rising from 35.78% to 62.75% as the ratio is approached). (2) No cross-lingual transfer occurs: English performance drops to 46.46%, with pure COIGWriter models generating Chinese text for 12.18% of English prompts. (3) Lexical diversity inversely correlates with qualityhighest Type-Token Ratio (TTR) (0.678) corresponds to lowest preference scores (37.25%). These findings support two-component model of creative writing: narrative logic (enhanced by process supervision) and linguistic expression (maintained by general data). Neither component alone sufficesthe optimal configuration requires both. Contributions: Reverse-engineering methodology: We develop systematic approach to extract reasoning chains from high-quality texts through multi-stage validation (LLM filtering + expert annotation). The methodology achieves 70% acceptance rate and generalizes to other creative domains. COIG-Writer dataset: 1,665 Chinese creative writing triplets spanning 51 genres, with average lengths of 283/1,089/2,214 characters (prompt/reasoning/article). Each triplet 2 undergoes 6-dimensional quality evaluation (score 50), representing expert annotations. Empirical validation of compositional hypothesis: Through controlled experiments, we demonstrate: (1) process supervision improves Chinese creative writing from 35.78% to 62.75% but requires stabilization ratio of approximately 1:12 (creative to general samples), (2) creative capabilities are language-specific with 16.29% performance gap between Chinese and English, and (3) lexical diversity inversely correlates with quality (TTR paradox). 2. The COIG-Writer Dataset Figure 2. The data curation pipeline of COIG-Writer. Our methodology consists of three main stages: (1) Genre scope definition through expert consultation, (2) Multi-stage source text collection and filtering, and (3) Reverse-engineering of thought processes with comprehensive quality control. To address these challenges, we introduce COIG-Writer, Chinese creative writing dataset that uniquely captures the reasoning process underlying creative decisions. Our 1,665 expertcurated triplets span 51 genres, each containing: (1) reverse-engineered prompts, (2) detailed creative reasoning chains, and (3) final texts. In the following section, we will elaborate on the datasets construction methodology, covering our systematic text collection, the reverseengineering of creative thought processes, and the multi-stage quality assurance pipeline While existing datasets prioritize either scale or breadth, they provide only input-output pairs without process data. COIG-Writer uniquely combines multi-genre coverage with explicit reasoning chains, enabling process-level learning of creative decision-making. Figure 1 illustrates our two-stage construction pipeline: (i) systematic collection and filtering of high-quality texts, followed by (ii) expert reverse-engineering to extract the implicit creative reasoning. 3 2.1. Data Collection Methodology Genre Taxonomy and Scope Definition. We established our genre taxonomy by aggregating categories from writing websites, merging categories, and removing duplicates. The selection process followed two core principles: (1) representational diversity to capture the rich spectrum of Chinese literary traditions, and (2) practical relevance to include contemporary forms with real-world applications. Our final taxonomy encompasses 51 specific genres organized across eight primary domains: Functional Writing (e.g., proposal planning, tutorial guides), Communicative Writing (e.g., social media content, advertising copy), Non-fictional Writing (e.g., essays, reviews), Fiction (spanning traditional genres like Wuxia to modern science fiction), Internet Culture (e.g., subcultural expressions, fan fiction), Poetry (classical and contemporary forms), Scripts (drama, debate), and Role-playing Writing (character-driven narratives). Annotator Recruitment and Training. We recruited 100 university students from diverse academic backgrounds, including literature and linguistics programs, humanities disciplines, and STEM fields. This interdisciplinary composition ensures broad perspective coverage while maintaining literary sensitivity. All annotators underwent standardized 8-hour training program covering: (1) quality assessment criteria, (2) reverse-engineering techniques, (3) reasoning process articulation, and (4) cultural sensitivity guidelines. Source Text Collection and Initial Filtering. Source texts were systematically collected from diverse online platforms including literary forums, social media platforms, professional blogs, and cultural websites. To ensure temporal relevance and avoid potential contamination with foundation model training data, we strictly limited collection to content published after October 2022, verified through rigorous URL tracing and cross-platform timestamp validation. Each collected text underwent five-dimensional initial assessment: Content Completeness (structural integrity), Format Standardization (presentation quality), Error Correction (linguistic accuracy), Logical Consistency (narrative coherence), and Creativity Assessment (originality and engagement). Texts were further evaluated using engagement metrics (likes, shares, comments) as proxy indicators for quality and appeal. Automated Quality Screening. We developed specialized LLM-based quality screening system using carefully designed prompts with Qwen3-235B-A22B [31]. The system evaluates texts across two dimensions through structured prompting: Article_quality (linguistic fluency, structural coherence, factual accuracy) and Article_creativity (originality, expressiveness, cultural resonance). 2.2. Thought Process Construction Reverse-Engineering Methodology. For each qualified article, annotators employed our systematic three-step reverse-engineering protocol to extract the implicit creative reasoning underlying the final text: (1) Prompt Reconstruction. Annotators analyze the articles core attributes across multiple dimensions: thematic focus (subject matter and conceptual depth), stylistic markers (tone, voice, linguistic register), structural organization (narrative flow, argument structure), and cultural grounding (idioms, references, contextual assumptions). Based on this analysis, annotators reverse-engineer plausible prompt that could have inspired the article. The reconstructed prompt must balance two competing requirements: sufficient specificity to constrain the creative space toward the target output, while maintaining adequate interpretative freedom to enable genuine creative decision-making. (2) Reasoning Process Articulation. Using both the original article and reconstructed prompt, annotators systematically document the hypothetical creative decision-making pathway connecting initial inspiration to final output. The reasoning process must explicitly address five critical decision categories: (a) initial interpretation and planning (understanding the prompt, establishing creative goals, conceptualizing the overall approach), (b) structural and stylistic choices (organizational framework, narrative perspective, tonal register, rhetorical strategies), (c) cultural and contextual considerations (selection of culturally resonant elements, audience adaptation, contextual knowledge embedding), (d) narrative development strategies (plot progression techniques, character development, argument construction, thematic elaboration), and (e) revision and refinement thoughts (metacognitive reflections on improving coherence, enhancing impact, resolving tensions). (3) Coherence Validation. Each resulting triplet (Article, Reverse Inspiration Prompt, Reasoning Process) undergoes self-consistency checks to ensure logical coherence across all components. Validation criteria include: (i) the prompt plausibly motivates the articles characteristics without being overly deterministic, (ii) each reasoning step logically follows from the prompt and previous decisions, (iii) the reasoning provides sufficient justification for major creative choices in the final article, and (iv) no contradictions exist between prompt requirements, reasoning explanations, and article content. Triplets failing these checks are flagged for iterative refinement. Multi-Dimensional Quality Evaluation. Each data triplet undergoes systematic evaluation across six interdependent dimensions spanning three components: Article (quality: fluency, coherence, cultural appropriateness; creativity: originality, expressiveness, engagement), Prompt (quality: clarity, specificity, generative potential; creativity: innovation, cultural grounding, complexity), and Reasoning (quality: logical consistency, completeness, clarity; creativity: insight depth, decision justification, authenticity). These dimensions enforce cohesionpoor article-reasoning alignment directly impacts quality scores. Triplets must satisfy dual thresholds to advance: cumulative score 50 and individual dimension scores 8, ensuring both overall excellence and consistent quality across all facets. 2.3. Quality Assurance and Final Validation Human-in-the-Loop Validation. Eight graduate-level domain experts in Chinese literature conducted manual validation following standardized calibration sessions. Each triplet underwent tiered review based on complexity: 2 reviewers for standard samples, 4 for samples requiring specialized cultural or stylistic knowledge. Review criteria encompassed: (i) semantic consistency across the triplet components, (ii) cultural and linguistic authenticity, (iii) reasoning process coherence, and (iv) contribution to genre diversity. Initial review achieved 70% acceptance rate, with rejected samples entering iterative refinement unless they contained factual errors (e.g., anachronistic references) or violated content guidelines, which warranted removal. This multi-stage validation pipeline produced final corpus of 1,665 verified triplets. Bias Mitigation and Diversity Assurance. We implemented five strategies to ensure dataset diversity: (1) balanced genre representation with minimum 15 samples per category, (2) geographic diversity across source platforms, (3) temporal spread throughout the collection period, (4) stylistic variety within each genre, and (5) regular bias audits during curation. These measures minimize systematic bias and promote equitable representation across all dimensions. 5 2.4. Evaluation Benchmark Construction We constructed comprehensive benchmark to systematically evaluate model performance on creative writing tasks. Test Query Development. Two computational linguistics postgraduate students developed 104 evaluation queries covering all 51 genres (minimum two queries per genre). Each query specifies three elements: target genre, creative constraints (length, style, theme), and cultural/contextual requirements. Our expert panel validated all queries for clarity, precision, and appropriate difficulty levels. Human Evaluation Protocol. Four trained graduate evaluators assessed model outputs using standardized 4-point scale (03) across five dimensions: Content Quality, Creative Merit, Cultural Appropriateness, Task Fulfillment, and Overall Preference. To ensure consistency, each evaluator assessed outputs from five specific models, achieving high inter-rater agreement and minimizing evaluation bias. (a) Main category distribution (b) Length distributions Figure 3. Dataset composition of COIG-Writer. (a) Distribution across 7 main categories encompassing 51 specific genres. Communication (28.9%) and Novel (28.0%) constitute the majority, followed by Non-fiction (14.6%) and Functional Writing (13.3%). (b) Length distributions for prompts (Query), reasoning processes (Thought), and articles (Answer) demonstrate the varying complexity across the dataset. 2.5. Dataset Statistics and Analysis COIG-Writer contains 1,665 high-quality triplets with substantial diversity. Average character lengths are 283 for prompts, 1,089 for reasoning processes, and 2,214 for articles, with maximum article length reaching 31,071 characters. The dataset spans 7 main categories with 51 specific genres. Communication and Novel categories each represent 30% of the dataset, followed by Non-fiction (14.6%) and Functional Writing (13.3%), as shown in Figure3a. Genres include poetry, social media content, fiction, and specialized forms like Xianxia and military novels (see Appendix B). Length distributions (Figure 3b) show articles ranging from 1231,071 characters, reasoning processes from 2524,094 characters, and prompts from 302,642 characters. This logarithmic distribution, concentrated between 10010,000 characters, reflects natural variation in creative writing genres and enables learning from both concise and elaborate examples. 6 3. Experiments and Analysis 3.1. Experimental Setup Model Configurations. We investigate five configurations that systematically vary the ratio of COIG-Writer data (DCW, 1,665 samples) to general-purpose data (DG). This design enables us to empirically determine the stabilization threshold required for process supervision to enhance creative writing capabilities. To ensure cross-lingual stability, we construct DG from two complementary sources: 10k Chinese samples from the DeepSeek-R1 distilled dataset [21] and 10k English samples from OpenThoughts [14], large-scale reasoning dataset. This yields balanced bilingual pool of 20k samples. We create training mixtures by sampling equal amounts from each language source: 1k per language (2k total), 5k per language (10k total), and 10k per language (20k total, using the complete pool). Table 1 summarizes the five experimental configurations, with DG quantities selected to span ratios from 1:1.2 to 1:12 (creative to general samples). Table 1. Training configurations and data composition."
        },
        {
            "title": "Model",
            "content": "COIG-Writer General Total MCW MCW+1k MCW+5k MCW+10k MG 1,665 1,665 1,665 1,665 0 0 2,000 10,000 20,000 20,000 1,665 3,665 11,665 21,665 20,000 Training Configuration. All models initialize from Qwen2.5-7B-Instruct [31] and undergo supervised fine-tuning for 3 epochs. We employ AdamW optimizer with learning rate 𝜂 = 2 105, global batch size 𝐵 = 32, and linear learning rate warmup over 10% of training steps. The maximum sequence length is set to 8,192 tokens. Evaluation Protocol. We construct comprehensive evaluation benchmark consisting of 557 test queries spanning all 51 genres in our taxonomy, with 204 Chinese queries and 353 English queries. Each query specifies the target genre, creative constraints (style, theme), and cultural or contextual requirements. Human evaluation follows rigorous pairwise comparison protocol. Four graduate-level evaluators (separate from the annotation team) assess model outputs using blind comparisons, where neither the model identities nor the training configurations are disclosed. 3.2. Main Results Human Preference Evaluation. Table 2 reports pairwise win rates across model configurations. Chinese Creative Writing: Substantial Effectiveness of COIG-Writer. For Chinese creative writingthe native language of the COIG-Writer datasetour results demonstrate substantial effectiveness. MCW+10k achieves statistically significant win rate of 62.75% against the baseline MG (𝑝 < 0.001), establishing it as the only configuration to meaningfully outperform general-purpose training. This 25.5 percentage point improvement represents substantial gain attributable to the specialized creative writing data when properly balanced with generalpurpose samples. 7 Table 2. Pairwise win rates (%) on creative writing tasks. Bold values indicate win rates > 55%. Each cell (𝑖, 𝑗) shows win rate of row 𝑖 vs. column 𝑗. Chinese (Original Dataset Language) English (Cross-lingual Transfer) Model MCW MCW+1k MCW+5k MCW+10k MG MCW MCW+1k MCW+5k MCW+10k MG MCW MCW+1k MCW+5k MCW+10k MG 60.78 67.65 74.02 64. 39.22 60.29 67.65 57.84 32.35 39.71 58.33 50.00 25.98 32.35 41.67 37.25 35.78 42.16 50.00 62.75 61.47 72.80 75.92 76.49 38.53 64.59 67.71 69. 27.20 35.41 50.71 57.79 24.08 32.29 49.29 53.54 23.51 30.03 42.21 46.46 (a) Chinese results (b) English results Figure 4. Distribution of character counts across model variants. Box plots show median, IQR (box), whiskers (1.5IQR), and outliers (dots). Both languages show MCW producing shortest outputs, with Chinese texts generally shorter due to character density. Performance exhibits monotonic improvement with increasing general data proportions: MCW+5k reaches parity (50.00%), while MCW+1k and MCW underperform at 42.16% and 35.78% respectively. This pattern suggests critical threshold of approximately 20k general samples (1:12 ratio of creative to general data) necessary to stabilize the creative enhancements introduced by specialized data. The strong performance in Chinese validates the effectiveness of processsupervised creative writing data for the language domain it was designed for. English Creative Writing: Limited Cross-lingual Transfer. In contrast, English results demonstrate limited cross-lingual transfer of creative writing capabilities. The baseline MG maintains dominance with win rates ranging from 53.54% against MCW+10k to 76.49% against MCW. The monotonic improvement with increasing general data (from 23.51% to 46.46%) indicates that Chinese-centric creative data, while highly effective for its native language, does not transfer effectively to English generation. The Two-Component Model of Creative Writing. Our results reveal that creative writing quality emerges from two distinct components that must be balanced: Narrative Logic. Provided by COIG-Writer through explicit reasoning chains, enabling coherent plot development, consistent character behavior, and structured storytelling. This component ensures logical connections between paragraphs and maintains thematic consistency. 8 Linguistic Expression. Maintained by general-purpose data, ensuring natural phrasing, stylistic fluency, and cultural idiomaticity. This component provides the surface realization that makes text feel naturally written rather than artificially generated. The failure of MCW (35.78% win rate) demonstrates that logic alone is insufficientqualitative analysis reveals well-structured narratives expressed in stilted, unnatural language. Conversely, MGs fluent surface but poor performance indicates that linguistic variety without logical scaffolding produces what annotators described as logical disconnection between paragraphs despite fluent expressionbeautiful nonsense that reads well locally but lacks global coherence. Generation Length Analysis. Table 3 and Figure 4 present output length characteristics across model variants. For Chinese generation, MCW+10k produces outputs of comparable length to the baseline (1,120.2 vs 1,137.3 characters) while achieving superior win rates, indicating that performance gains stem from content quality rather than mere verbosity. The MCW and MCW+1k models generate substantially shorter outputs (960.4 and 949.7 characters respectively), correlating with their inferior performance. In English tasks, the baseline produces the longest outputs (4,069.9 characters) and achieves highest win rates, suggesting positive correlation between generation length and quality in this domain. The MCW model generates the shortest responses (3,037.8 characters, 25.4% fewer than baseline), corresponding with its poorest performance (23.51% win rate). Notably, while MCW+10k approaches baseline length (98.3% of baseline characters), it still underperforms in preference evaluations, indicating that factors beyond lengthlikely coherence and cultural appropriatenessdetermine English generation quality. Table 3. Average generation length across model configurations. Chinese English Model Tokens Chars Tokens Chars MCW MCW+1k MCW+5k MCW+10k MG 606.9 602.9 699.4 710.7 730.3 960 950 1,099 1,120 1,137 1,195 1,382 1,533 1,577 1,577 3,038 3,690 3,988 4,002 4, The distribution analysis (Figure 4) reveals that variance in output length decreases as more general data is incorporated, with MCW exhibiting the highest variability across both languages. This suggests that specialized creative data alone leads to less predictable generation behavior, while mixing with general data stabilizes output characteristics. Table 4. Type-Token Ratio analysis reveals inverse correlation with creative quality. Chinese English Model Mean Median Mean Median MCW MCW+1k MCW+5k MCW+10k MG 0.522 0.578 0.576 0.593 0.678 0.513 0.570 0.576 0.586 0.671 0.562 0.571 0.574 0.590 0.590 0.515 0.554 0.561 0.579 0.571 (a) Chinese: wide TTR range (0.5220.678) (b) English: narrow TTR range (0.5620.590) Figure 5. The TTR Paradox. Higher lexical diversity correlates with lower creative quality. MG achieves highest TTR (0.678) but loses to MCW+10k (TTR = 0.593) with only 37.25% win rate, challenging conventional assumptions about diversity metrics. Lexical Diversity Analysis. We measure Type-Token Ratio (TTR) to test whether lexical diversity correlates with generation quality. For Chinese text, we apply jieba segmentation before computing TTR. Table 4 and Figure 5 reveal an inverse correlation between lexical diversity and quality. In Chinese, MG shows highest TTR (0.678) but lowest win rate (37.25%) against MCW+10k (TTR=0.593). For English, despite identical TTR (0.590), MCW+10k underperforms by 7 percentage points. This inverse relationship aligns with our two-component model: high TTR in MG indicates vocabulary variation without narrative coherencemanual inspection reveals frequent topic shifts and inconsistent terminology. Lower TTR in MCW+10k reflects deliberate term reuse for thematic consistency. 3.3. Qualitative Analysis Coherence and Instruction Adherence. Manual inspection of 557 test samples reveals systematic failure modes. For Chinese tasks, MG exhibits logical disconnection between paragraphs despite fluent surface form, while MCW produces unformatted text blocks without proper segmentation. MCW+10k successfully maintains narrative coherence while following complex instructions. In the \"Wu Song Fights Tiger\" reinterpretation task requiring critical commentary, MCW+10k correctly incorporates the meta-narrative critique, while MCW defaults to literal retelling and MG generates tangentially related content. Cross-Lingual Contamination. critical failure emerges in English generation: MCW produces Chinese text in 12.18% of English prompts (43/353), compared to 1.13% for MCW+10k and 1.42% for MG. Contamination correlates inversely with general data proportion, with intermediate rates for MCW+1k (1.70%) and MCW+5k (1.42%). Genre-Specific Performance. Performance varies significantly across 51 genres. Abstract tasks (homophonic wordplay \"XiLaNai\", experimental \"crazy literature\") fail across all models with <15% success rate, producing overly formal outputs lacking stylistic authenticity. Structured formats show differential improvement: advertisements and slogans benefit from MCW+10ks incorporation of classical poetry and idioms, while MCW+1k and MCW+5k produce simplified 10 vocabulary. Technical genres (\"instruction manuals\", \"proposals\") show no distinguishable quality differences in human evaluation. 3.4. Discussion Our findings reveal compositional structure underlying creative writing capability, with important implications for data-scarce languages: Language-Specific Effectiveness and Data Scarcity. The divergent results between Chinese (62.75% win rate) and English (46.46% win rate) reflect fundamental differences in data availability rather than inherent limitations of process supervision. Chinese creative writing with explicit reasoning chains remains severely underrepresented in general pretraining corpora, making COIG-Writers 1,665 samples valuable and distinctive contribution. The 25.5 percentage point improvement in Chinese demonstrates that even relatively small specialized datasets can substantially enhance capabilities when they address genuine data gaps. Conversely, English general corpora already contain abundant creative writing examples from diverse sources (published literature, online fiction, creative writing communities), diminishing the marginal value of additional specialized data. This suggests that the effectiveness of domain-specific datasets should be evaluated relative to their representation in existing general-purpose corporaspecialized data provides maximal benefit for underrepresented domains and languages. Stabilization Threshold. The monotonic performance improvement (35.78%62.75%) with increasing general data establishes minimum 22k sample requirement for process supervision effectiveness in Chinese. This 1:12 ratio (creative:general data) suggests narrative logic forms necessary but minority component, analogous to how mathematical reasoning enhances but cannot replace linguistic competence [19]. Future work scaling the creative writing dataset alongside general data could further elucidate whether this ratio remains optimal across different dataset sizes. Cultural and Reasoning-Level Specificity. The performance gap between languages demonstrates that creative patterns are culturally encoded at the reasoning level, not merely at the vocabulary level. The 12.18% Chinese generation on English prompts by MCW indicates that Chinese narrative structures (four-character idioms, implicit progression) constitute incompatible features for English generation. This finding provides strong evidence that creative writing competencies are culturally and linguistically bound, contradicting hypotheses of universal creative skill transfer. TTR as Diagnostic. The inverse correlation between lexical diversity and quality reveals compensatory behavior: models lacking process supervision increase vocabulary variation to mask logical deficiencies. This suggests TTR could serve as an early warning for training imbalancesabnormally high diversity signaling insufficient narrative coherence. Implications. These findings suggest: (1) scaling creative datasets provides maximal benefit for underrepresented languages and domains where general corpora lack sufficient creative examples, (2) cross-lingual transfer requires reasoning-level adaptation beyond translation, particularly when source and target languages have divergent narrative conventions, and (3) evaluation should separately assess narrative logic and linguistic expression. The substantial effectiveness in Chinese validates process supervision as viable approach for enhancing creative capabilities in data-scarce scenarios. Limitations. Our experimental design varied general-purpose data quantities by sampling equal amounts from each language: +1k per language (2k total), +5k per language (10k total), and +10k per language (20k total, the complete bilingual pool), while holding the COIG-Writer dataset fixed at 1,665 samples. This design choice, while revealing the stabilization threshold for combining creative and general data, limits our ability to assess whether scaling the creative writing dataset itself would yield further improvements. Future work should investigate whether increasing COIG-Writer data beyond 1,665 samples could enhance Chinese performance or enable more effective cross-lingual transfer. Additionally, the current study cannot definitively distinguish whether the limited English effectiveness stems from the datasets Chinese-centric cultural framing or simply from insufficient creative writing examples for English. Larger-scale experiments varying both creative and general data quantities would provide clearer insights into the optimal data composition for creative writing tasks. 4. Related Work Creative Writing Datasets and Evaluation. English creative writing has benefited from substantial dataset development. The WritingPrompts dataset [9], has provided foundational data for hierarchical neural story generation. More recently, Fein et al. [10] introduced LitBench, the first standardized creative writing benchmark, featuring 2,480 human-labeled story comparisons and training corpus of 43,827 pairs. LitBench demonstrated that Bradley-Terry reward models outperform zero-shot large language model (LLM) evaluators (78% vs. 73% human agreement). However, existing English datasets such as ROCStories [22] and poetry corpora [12, 15] target specific genres or limited creative aspects, neglecting process-oriented data and cross-genre diversity. By contrast, high-quality Chinese creative writing resources are critically scarce. Existing datasets target general tasks: LCCC [27] provides 12M dialogue pairs, LCSTS [16] contains 2.4M summarization pairs, while instruction tuning datasets COIG [35] and COIG-CQIA [2] focus on general instruction-following rather than creative writing. Process-Oriented Learning and Creative Writing. Process supervision improves LLMs on tasks with explicit structure: chain-of-thought prompting [28], self-consistency [26], and zeroshot CoT [18]. However, creative writing requires long-horizon narrative control, stylistic decision-making, and culturally informed choices that go beyond stepwise logical inference [4]. Prior computational creativity methodsfrom rules/templates [3, 11, 29] to outline/plan-first pipelines [32, 34]mainly cover high-level structure rather than the fine-grained thought signals (e.g., motif development, pacing, voice) that guide human composition. Quality Issues and Evaluation Challenges. AI-generated creative writing consistently exhibits identifiable \"AI flavor,\" characterized by weak logical coherence [33], monolithic stylistic expression [8], superficial observations [25], inappropriate ornate vocabulary [17], and formulaic narratives [13]. These systematic issues suggest fundamental shortcomings in current training methods rather than mere scaling limitations. Furthermore, evaluating creative content remains inherently challenging. Traditional automatic metrics like BLEU and ROUGE fail to capture the diversity and nuanced qualities inherent in creative writing [9]. Human evaluation, while more accurate, is expensive, subjective, and difficult to scale [6]. Recent LLM-based evaluation approaches [36] partially address scalability but inherit biases from underlying models, especially 12 when assessing culturally-specific creative content. 5. Conclusion We present COIG-Writer, Chinese creative writing dataset of 1,665 triplets spanning 51 genres with reverse-engineered prompts, reasoning processes, and final texts. Our experiments reveal two-component model where narrative logic (from process supervision) and linguistic expression (from general data) must be balanced for quality generation. Three findings support this model: (1) Process supervision requires minimum 22k general samplesbelow this threshold, performance degrades monotonically (35.78%62.75%). (2) Creative capabilities are language-specific, with Chinese models achieving 62.75% win rate but only 46.46% in English. (3) Lexical diversity inversely correlates with qualityhighest TTR (0.678) yields lowest preference scores. These results demonstrate that creative excellence requires both logical scaffolding and linguistic grounding. While smaller than English datasets, COIG-Writer enables mechanism discovery rather than scale optimization. The identified compositional structure suggests future work should separately optimize narrative logic and linguistic expression rather than treating creativity as monolithic. Process supervision proves necessary but insufficienteffective creative AI requires careful balance between structure and expression."
        },
        {
            "title": "Contributions and Acknowledgements",
            "content": "Multimodal Art Projection (M-A-P) is non-profit open-source AI research community, ran by donation. The community members are working on research topics in wide range of spectrum, including but not limited to the pre-training paradigm of foundation models, largescale data collection and processing, and the derived applications on coding, reasoning and music generation. Core Contributors (Equal Contribution) Yunwen Li, CUHK-Shenzhen, M-A-P Shuangshuang Ying, M-A-P Xingwei Qu, The University of Manchester"
        },
        {
            "title": "Contributors",
            "content": "Xin Li, Nanyang Technological University Sheng Jin, Zhejiang University Minghao Liu, 2077AI, M-A-P Zhoufutu Wen, M-A-P Tianyu Zheng, M-A-P Xeron Du, M-A-P Qiguang Chen, Harbin Institute of Technology Jiajun Shi, M-A-P Wangchunshu Zhou, M-A-P Jiazhan Feng, M-A-P Wanjun Zhong, M-A-P"
        },
        {
            "title": "Advisors",
            "content": "Libo Qin, Central South University Stephen Huang, Peking University Wanxiang Che, Harbin Institute of Technology Chenghua Lin, The University of Manchester"
        },
        {
            "title": "Corresponding Authors",
            "content": "Eli Zhang, University of Waterloo Chenghua Lin, The University of Manchester"
        },
        {
            "title": "1 Anthropic. Anthropic economic index: Understanding ai’s effects on the economy, 2025.",
            "content": "URL https://www.anthropic.com/economic-index. Accessed: 2025-09-16."
        },
        {
            "title": "9 Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. arXiv",
            "content": "preprint arXiv:1805.04833, 2018."
        },
        {
            "title": "11 Pablo Gervás. Computational approaches to storytelling and creativity. AI Magazine, 30(3):",
            "content": "4949, 2009."
        },
        {
            "title": "14 Etash Guha, Ryan Marten, Sedrick Keh, Negin Raoof, Georgios Smyrnis, Hritik Bansal,\nMarianna Nezhurina, Jean Mercat, Trung Vu, Zayne Sprague, Ashima Suvarna, Benjamin",
            "content": "15 Feuer, Liangyu Chen, Zaid Khan, Eric Frankel, Sachin Grover, Caroline Choi, Niklas Muennighoff, Shiye Su, Wanjia Zhao, John Yang, Shreyas Pimpalgaonkar, Kartik Sharma, Charlie Cheng-Jie Ji, Yichuan Deng, Sarah Pratt, Vivek Ramanujan, Jon Saad-Falcon, Jeffrey Li, Achal Dave, Alon Albalak, Kushal Arora, Blake Wulfe, Chinmay Hegde, Greg Durrett, Sewoong Oh, Mohit Bansal, Saadia Gabriel, Aditya Grover, Kai-Wei Chang, Vaishaal Shankar, Aaron Gokaslan, Mike A. Merrill, Tatsunori Hashimoto, Yejin Choi, Jenia Jitsev, Reinhard Heckel, Maheswaran Sathiamoorthy, Alexandros G. Dimakis, and Ludwig Schmidt. Openthoughts: Data recipes for reasoning models, 2025. URL https://arxiv.org/abs/2506.04178."
        },
        {
            "title": "16 Baotian Hu, Qingcai Chen, and Fangze Zhu. Lcsts: A large scale chinese short text summa-",
            "content": "rization dataset. arXiv preprint arXiv:1506.05865, 2015."
        },
        {
            "title": "23 OpenAI. Learning to reason with llms. Technical report, OpenAI, 2024. URL https:\n//openai.com/index/learning-to-reason-with-llms/. Accessed: 2024-09-12.\n24 OpenAI. How people are using chatgpt, 2025. URL https://openai.com/index/how-p",
            "content": "eople-are-using-chatgpt/. Accessed: 2025-09-15."
        },
        {
            "title": "25 Melissa Roemmele. Inspiration through observation: Demonstrating the influence of auto-",
            "content": "matically generated text on creative writing. arXiv preprint arXiv:2107.04007, 2021."
        },
        {
            "title": "29 Geraint A Wiggins. A preliminary framework for description, analysis and comparison of",
            "content": "creative systems. Knowledge-based systems, 19(7):449458, 2006."
        },
        {
            "title": "32 Kevin Yang and Dan Klein. Fudge: Controlled text generation with future discriminators.",
            "content": "arXiv preprint arXiv:2104.05218, 2021."
        },
        {
            "title": "33 Kevin Yang, Dan Klein, Nanyun Peng, and Yuandong Tian. Doc: Improving long story",
            "content": "coherence with detailed outline control. arXiv preprint arXiv:2212.10077, 2022."
        },
        {
            "title": "36 Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with\nmt-bench and chatbot arena. Advances in neural information processing systems, 36:46595–46623,\n2023.",
            "content": "17 A. Use of Large Language Models During the writing process, LLM was employed to polish and refine certain parts of the manuscript. The tool was used to improve sentence fluency and enhance clarity of expression, while preserving the original academic arguments and logical structure, thus ensuring that the overall language is more standardized and aligned with academic writing conventions. B. Complete Genre Distribution and Statistics This appendix provides comprehensive statistics for all 51 genres in the COIG-Writer dataset. Tables 510 present detailed breakdowns by category, including sample counts, percentages, and length distributions for Articles (A.L.), Reverse Inspiration Prompts (R.I.P.L.), and Reasoning Processes (R.P.L.). All lengths are measured in Chinese characters. Table 5. Overview statistics across main categories. Length values shown as (minmeanmax). Category Overall Communication Novel Non-fiction Functional Poetry Funny Literature Script Count % Article Length Prompt Length Reasoning Length 122,21431,071 1,665 100.0 121,5849,422 28.9 28.0 613,66931,071 14.6 2252,05212,766 1481,2819,057 13.3 38210695 7.7 4.1 1773012,117 3.4 3693,10813,339 481 467 243 221 128 68 302832,643 402861,754 413321,222 412261,718 412482,492 412031,118 301861,007 424052,643 2521,0894,094 3021,1623,816 3531,1352,964 4531,0662,661 4371,0854,094 4428672,935 2527031,826 5531,2073,647 Table 6. Funny Literature Genre Count % A.L. (minmeanmax) R.I.R.L. (minmeanmax) R.P.L. (minmeanmax) Funny Funny Subculture Esports Funny Fiction Anime/Manga Fan Fiction Subcultural Identity Expression Fan Circle Funny Literature Anti-Mainstream Consumption Funny Literature Internet Jargon Transnational/Crosslanguage Funny Literature 31 1.86% 171305.4512117 18 1.08% 241519.941008 8 0.48% 168506.25 30144.03691 99291.831007 67283.75542 252701.551826 476698.61923 351750.621033 4 0.24% 332486.75638 90153.25262 546794.75 3 0.18% 415543.67730 77108.67160 535627677 2 0.12% 194215 100153.5207 711774.5838 1 0.06% 1 0.06% 448448448 323323323 979797 105105105 536536536 643643 C. Reasoning Behavior Analysis To understand the mechanisms underlying performance differences between model configurations, we analyze reasoning patterns during generation by categorizing model behaviors into four types: normal writing, deep reasoning, self-exploration, and self-reflection. 18 Table 7. Communication Practical Writing Genre Count % A.L. (minmeanmax) R.I.R.L. (minmeanmax) R.P.L. (minmeanmax) Social Media Content Creation Advertising Copy Blog Post Debate Script Popular Science Speech Draft Slogan Product Review 124 7.45% 232426.58842 42383.491754 5451273.512940 74 4.44% 30410.424305 62 3.72% 4803164.379422 59 3.54% 5901167.632825 50 3.00% 1462178.746570 49 2.94% 7251974.927177 12261.231394 47 2.82% 16 0.96% 1912986.944635 44169.5708 302884.692978 129394.481461 6611150.451783 100257410 7741313.752320 44242.76751 6031053.043816 43329.161118 7281288.222485 446957.871718 40168.79570 57247.62641 7201315.312196 Table 8. Novel Genre Count % A.L. (minmeanmax) R.I.R.L. (minmeanmax) R.P.L. (minmeanmax) Fiction/Story Everyday Stories Costume Novels Mystery/Inference Stories Wuxia Novels Science Fiction Stories Xuanhuan Novels Fairy Tale Fantasy/Magic Stories Xianxia Novels Emotional Stories Military Novels Sports Novels Game Novels 104 6.25% 1223641.4527124 612129.528137 50 3.00% 40 2.40% 3446193.131071 31 1.86% 1104875.7119030 44349.191035 5821198.532964 41322.161222 6491217.422068 71442.58985 3531079.21785 42302.35765 4231176.352187 30 1.80% 11984586.7723797 28 1.68% 7793233.5712280 27 1.62% 4674925.0724706 25 1.50% 3641192.882544 2582925.649290 25 1.50% 24 1.44% 1704291.8820078 23 1.38% 3943119.2612147 23 1.38% 15153417.177095 22 1.32% 6223903.2710358 15 0.90% 10674309.9311492 49341.17586 6851126.932023 53293.36958 6031226.682935 90354.041005 3941192.522237 465772.961256 118198.52435 54283.08451 4171182.922098 498984.881881 6591131.31975 234362.13637 9391575.352784 72411221681 6291095.81506 177340892 253422.67 89385.421106 45263.7784 Chinese Reasoning Patterns. As illustrated in Figure 7, models trained with COIG-Writer data demonstrate significantly enhanced reasoning capabilities. The MCW+10k configuration exhibits balanced distributions across all reasoning types, with increased frequencies of deep reasoning and self-exploration phases compared to the baseline. This balanced reasoning profile correlates with superior creative performance, suggesting that explicit process supervision enables models to engage in more sophisticated creative planning and reflection. English Reasoning Patterns. Figure 8 reveals contrasting patterns for English generation. The baseline model maintains consistent deep reasoning throughout generation, while COIGWriter variants exhibit disrupted reasoning flows with excessive self-reflection but limited deep reasoning. This misalignment between the Chinese-oriented reasoning patterns encoded in COIG-Writer and the requirements of English creative writing explains the performance degradation, providing mechanistic evidence for the lack of cross-lingual transfer in creative capabilities. 19 Table 9. Functional Practical Writing Genre Count % A.L. (minmeanmax) R.I.R.L. (minmeanmax) R.P.L. (minmeanmax) Argumentative Essay Academic Abstract Proposal Planning Open Letter Apology Letter Eulogy Tutorial Guide Interview Questions Product Manual 67 4.02% 5511066.212309 62 3.72% 1961219.19057 33 1.98% 1481667.483951 24 1.44% 1911122.965704 11 0.66% 3181506.453677 10 0.60% 3951872.77032 7 0.42% 2212352.575276 5 0.30% 2038211448 2 0.12% 6211796.52972 46239.96806 48204.05478 598938.031568 440980.482728 41337.092492 7151415.393138 44220.25486 5481177.252427 581762.27954 92211.27445 69011531696 155258.3656 122399.861359 9361218.141491 437795.21044 7952444.54094 137235.8357 50164.5279 Table 10. Non-fiction Writing Genre Count % A.L. (minmeanmax) R.I.R.L. (minmeanmax) R.P.L. (minmeanmax) Essay Reviews Travel Writing Historical Stories Biography 73 4.38% 3741859.078585 22516494891 58 3.48% 54 3.24% 48319467733 34 2.04% 3592179.446856 24 1.44% 8004625.6212766 41279.991381 453918.671630 42193.55932 5021167.412661 80180.31804 5251016.331587 41275.03426 6751055.881930 43294.461718 5881212.122041 Figure 6. Complete distribution of all 51 genres in COIG-Writer, showing the full diversity of creative writing categories covered. 20 Figure 7. Reasoning behavior analysis on Chinese creative writing. Models trained with COIGWriter data exhibit balanced distributions across reasoning types, while baseline models show predominant normal writing with minimal deep reasoning. Figure 8. Reasoning behavior analysis on English creative writing. The baseline model maintains consistent deep reasoning patterns, while COIG-Writer variants show disrupted reasoning flows, explaining their inferior performance. 21 D. Prompts D.1. Prompt for pre-analyzing answer usability During the annotation process, it was observed that annotators spent substantial time on annotation only to find that the quality of the answers was unsatisfactory at the final scoring stage. Consequently, pre-analysis step was introduced to examine the usability of the answers. D.2. Prompt for analyzing answers Provide comprehensive analysis of the answer to help annotators quickly grasp the general idea of the answer and accelerate the annotation process."
        },
        {
            "title": "Prompt for analyzing answers",
            "content": "我希望你扮演一位资深的创作者和分析师请对以下片段进行专业分析 {} 请从以下方面进行详细分析 1. 内容结构分析文本的整体架构段落组织和逻辑流程指出结构的优缺点及 对整体效果的影响 2. 语言风格评估语言的色彩节奏句式变化和词汇选择这些元素如何塑造 了文本的整体风格和语调 3. 修辞手法识别并评价使用的修辞设备如比喻隐喻排比等及其效果 4. 有效性评估文本在实现其意图方面的有效程度如何哪些部分特别有力或薄 弱 5. 专业洞察从[文本类型]创作领域的专业角度指出这篇文本中的独特元素或 创新点 请确保你的分析既有理论依据又有实用价值能帮助我理解这篇文本的创作技巧和 效果 D.3. Prompt for analyzing answers and queries Provide comprehensive analysis of the connection between answer and query, offer reliable ideas for annotators to write thoughts, and accelerate the annotation process. D.4. Prompt for evaluating querys Score the quality and creativity of the queries provided by annotators based on the given answers, screen out some low-quality data in advance, and reduce the pressure of manual quality inspection. D.5. Prompt for evaluating answers Score the quality and creativity of the answers provided by annotators based on the given query, filter out some low - quality data in advance, and reduce the pressure of manual quality inspection."
        },
        {
            "title": "Prompt for analyzing answers and queries",
            "content": "你是一位资深内容分析专家专注于解析文本创作背后的思维过程结构设计和写作 技巧请基于提供的问题/主题(query)和对应的回答内容(answer)对这篇回答进行全 面专业的创作思路分析请提供: - Query: {} - Answer: {} 请从以下维度进行分析: 1. 需求理解与定位 - 对原始问题/主题的理解深度目标受众识别与内容定位核心问题提取与回应策 略 2. 内容架构设计 - 整体框架与结构布局开头与结尾的设计意图及效果主体部分的逻辑展开方式段落之间的衔接与层次关系 3. 表达技巧运用 - 语言风格与表达特点修辞手法与句式结构专业术语的运用与解释叙事策略与 读者引导方式 4. 论证方法策略论点构建与支持方式论据选择与运用效果反驳处理与多角度 思考说服力构建技巧 5. 创新与价值呈现 - 独特见解与创新点实用性建议的设计与呈现理论与实践的平衡处理知识深度 与广度的展示方式 整体效果评估 - 内容与原始需求的匹配度信息密度与可读性平衡专业性与通俗性的结合潜在 影响与应用价值 请记住你的分析旨在揭示这篇回答背后的创作思路组织策略和表达技巧帮助用户 理解创作者如何解读需求组织元素设计架构并最终呈现内容这将有助于用户学 习并掌握高质量内容创作的思维模式和方法论提升自身的内容创作能力 D.6. Prompt for evaluating thoughts Score the quality and creativity of the thoughts provided by annotators based on the given query, screen out some low - quality data in advance, and reduce the pressure of manual quality inspection. E. Case Study To illustrate the models performance on nuanced creative texts, this case study presents short, atmospheric horror story written in Chinese and its corresponding English translation generated by the model. This example is intended to highlight the models ability to preserve the originals tone, critical details, and narrative pacing."
        },
        {
            "title": "Baseline Case",
            "content": "This case examines generative output from the baseline model to illuminate its inherent limitations in maintaining narrative coherence. Notably, the baseline demonstrates proficiency in producing text with polished, fluent stylistic registerconsistent with its strengths in surfacelevel language generation. However, deeper reading reveals critical deficits in structural 23 and semantic cohesion: sentences often suffer from broken inter-clausal semantic links, while paragraphs lack coherent narrative thread, leading to disjointed content that fails to sustain logical progression. Specifically, the generated text frequently shifts between ideas without transitional reasoning or contextual grounding, resulting in fragmented output where successive segments appear tangential or even contradictory. This discrepancy between stylistic fluency and logical coherence in the baselines output not only exemplifies common failure mode in current generation frameworks but also underscores the need for more robust modeling of inter-utterance and inter-paragraph semantic dependencieskey gaps this work aims to address."
        },
        {
            "title": "Prompt for evaluating querys",
            "content": "你的任务是根据以下标准,基于给定的answer,对query进行精确的评估输出应包括两 个部分质量和创意性请遵循以下细化的评分标准以确保评估的细致性 1. 质量性(评分1-10): 评估问题的清晰度和完整性着重于问题是否明确且自包含能否在不需要额外信息 的情况下得到完整的答案 9-10分: 完全清晰精准且自包含无歧义问题结构合理能够直接解释和回 答无需额外澄清query几乎对齐了answeranswer中出现的大部分对象或概 念出现在query中query很清晰的描述了需求 7-8分: 基本清晰且易于理解歧义很少基本完整尽管小的澄清可能有助于 提高精确性query较好的对齐了answeranswer中出现的部分对象或概念出现 在query中query较清晰的描述了需求 5-6分: 可 理 解 但 缺 乏 一 定 清 晰 度 存 在 显 著 的 歧 义 或 细 微 缺 失 可 能 需 要 澄清以确保准确回答query几乎没对齐answeranswer中出现的内容没出现 在query中 3-4分: 相当模糊或缺失元素需要大量解释清晰度问题增加回答难度 1-2分: 非常不清晰模糊或不完整难以解释或无法直接回答 2. 创意性(评分1-10): 评估问题的原创性创新思维和启发潜力着重于问题是否打破常规思维模式能否 激发独特视角和深度思考 9-10分: 卓越创意提出全新视角或前所未见的问题框架巧妙连接不同领域挑 战根深蒂固的假设促使思维范式转换 7-8分: 显著创意以新颖方式重构熟悉问题融合不同领域知识提出令人意外 但有意义的问题角度鼓励跳出常规思维框架 5-6分: 中等创意在传统问题基础上有所创新提供略微出人意料的问题情境 鼓励一定程度的非线性思维但整体框架较为常见 3-4分: 有限创意主要遵循常规问题模式问题形式或内容略有变化但思路常 见很少激发非常规思考 1-2分: 极少创意完全遵循标准化传统的问题模式无任何新颖元素或独特视 角不鼓励创造性思维 请严格按以下格式回复不要包含其他内容 {{ \"quality\": 1-10, \"creative\": 1-10, }} 根据以上标准对以下问题进行评估 answer:{ } query: { } 输出格式示例: ```json { \"quality\": 8, \"creative\": 8 } ```"
        },
        {
            "title": "Prompt for evaluating answers",
            "content": "你的任务是根据以下标准,基于给定的query,对answer进行精确的评估输出应包括两 个部分质量和创意性请遵循以下细化的评分标准以确保评估的细致性 1. 质量性(评分1-10): 评估思考的质量逻辑性和完整性 9-10分: 思考全面深入逻辑严密准确把握问题核心分析角度多元论证有 力充分回应问题的各个方面 7-8分: 思考较为完整逻辑基本清晰涵盖问题主要方面有一定深度但在某 些细节上可进一步拓展 5-6分: 思考基本合理但不够全面有一定分析但缺乏深度对问题的理解和回应 存在部分不足 3-4分: 思考存在明显缺陷逻辑较弱遗漏关键方面对问题理解有限或偏离问 题核心 1-2分: 思考质量低下逻辑混乱分析肤浅未能有效回应问题或严重误解问 题意图 2. 创意性(评分1-10): 评估思考在原创性启发性方面的表现 9-10分: 思考极具创新性提出独特见解和全新视角打破常规思维框架融合多 领域知识产生富有启发性的洞见 7-8分: 思考有明显创新元素展现非常规思维路径提供新颖的分析角度超越 表面层次引发深度思考 5-6分: 思考包含一定创新点有自己的见解思路较为常见但有独到之处能在 一定程度上拓展问题讨论空间 3-4分: 思考创新性有限主要沿用常规分析方法观点较为传统很少跳出既定 框架思考 1-2分: 思考几乎无创新完全依循标准化惯性的思维模式未能提供任何新鲜 视角或独特分析 请严格按以下格式回复不要包含其他内容 query:{ } answer: { } 输出格式示例: ```json { \"quality\": 8, \"creative\": 8 } ```"
        },
        {
            "title": "Prompt for evaluating thoughts",
            "content": "你的任务是根据以下标准,基于给定的query,对thought进行精确的评估输出应包括两 个部分质量和创意性请遵循以下细化的评分标准以确保评估的细致性 1. 质量性(评分1-10): 评估思考的质量逻辑性和完整性 9-10分: 思考全面深入逻辑严密准确把握问题核心分析角度多元论证有 力充分回应问题的各个方面 7-8分: 思考较为完整逻辑基本清晰涵盖问题主要方面有一定深度但在某 些细节上可进一步拓展 5-6分: 思考基本合理但不够全面有一定分析但缺乏深度对问题的理解和回应 存在部分不足 3-4分: 思考存在明显缺陷逻辑较弱遗漏关键方面对问题理解有限或偏离问 题核心 1-2分: 思考质量低下逻辑混乱分析肤浅未能有效回应问题或严重误解问 题意图 2. 创意性(评分1-10): 评估思考在原创性启发性方面的表现 9-10分: 思考极具创新性提出独特见解和全新视角打破常规思维框架融合多 领域知识产生富有启发性的洞见 7-8分: 思考有明显创新元素展现非常规思维路径提供新颖的分析角度超越 表面层次引发深度思考 5-6分: 思考包含一定创新点有自己的见解思路较为常见但有独到之处能在 一定程度上拓展问题讨论空间 3-4分: 思考创新性有限主要沿用常规分析方法观点较为传统很少跳出既定 框架思考 1-2分: 思考几乎无创新完全依循标准化惯性的思维模式未能提供任何新鲜 视角或独特分析 请严格按以下格式回复不要包含其他内容 query:{ } answer: { } 输出格式示例: ```json { \"quality\": 8, \"creative\": 8 } ```"
        },
        {
            "title": "Prompt",
            "content": "创作一篇悬疑短篇小说文字风格恐怖惊悚但结尾荒诞夏天主人公应旧友之约去酒 吧在酒吧卫生间发现恐怖尸体朋友也变得恐怖在逃生过程中得到骷髅帮助又陷入 混乱的车祸最后回到恐怖起始点主旨是通过离奇的情节和恐怖氛围引发读者对于未 知危险的恐惧与思考 迷雾"
        },
        {
            "title": "The Mist",
            "content": "阿杰快出来我扯着嗓子在卫生间门口喊瓷砖缝隙里渗出的霉斑在昏黄灯光下像凝 固的血迹老友的手机屏幕亮起时我看到他正蹲在洗手台边后颈上洇着一圈深色液 体 \"Ajie, get out here!\" yelled at the bathroom door, my throat raw. In the dim yellow light, the mold seeping from between the tiles looked like clotted bloodstains. When my old friends phone screen lit up, saw him squatting by the sink, ring of dark liquid soaking the back of his neck. 尸体. . . . . . 他突然直起身指甲缝里卡着碎发就在. . . . . . 那个. . . . . . 女厕. . . . . . 话没 说完他忽然僵住镜子里我的倒影正盯着他后腰的青紫色瘀痕那是我三天前帮他按 过的淤血 \"A body...\" he said, suddenly straightening up, his fingernails jammed with bits of hair. \"Its in... in the... womens restroom...\" Before he could finish, he froze. In the mirror, my reflection was staring at the purplish-blue bruise on his lower backthe same bruise had massaged for him three days ago. 走廊传来脚步声我抓住他的手腕就跑夜班保安正用消毒水擦拭门把手看见我们 冲进吧台时吧台灯突然熄灭阿杰的喉结上下滚动指缝里渗出血珠混着酒精味的呕 吐物溅在他皮鞋上 Footsteps echoed from the hallway. grabbed his wrist and we ran. The night-shift security guard was wiping down doorknob with disinfectant. As we scrambled behind the bar, the bar lights abruptly went out. Ajies Adams apple bobbed, and beads of blood seeped from between his fingers. Vomit, reeking of alcohol, splattered onto his leather shoes. 快看他指向落地窗暴雨倾盆中女厕方向腾起团团白雾雾气里隐约浮现出 骷髅轮廓森白色的肋骨在雨幕中泛着磷火般的光我刚想报警整栋建筑突然剧烈晃 动警报器狂叫消防通道门哐当撞开 \"Look!\" he pointed towards the floor-to-ceiling window. In the pouring rain, plumes of white mist were rising from the direction of the womens restroom. skeletal silhouette loomed within the fog, its stark white ribs glowing like phosphorescent fire against the curtain of rain. Just as was about to call the police, the entire building began to shake violentlyalarms blared, and the fire escape door slammed open with clang. 28 有人撞车了阿杰指着监控屏画面里一辆救护车正碾过尸体残肢司机戴着墨 镜后视镜里反着我的脸警笛声中我们挤进停尸间冷冻柜里的女尸皮肤已呈半透明 状却在我们面前裂开一道血口子露出里面裹着的. . . . . . 裹尸袋 \"Someone crashed!\" Ajie pointed at security monitor. On the screen, an ambulance was running over the mangled limbs of corpse. The driver was wearing sunglasses, and the rearview mirror reflected my own face. Amid the wailing sirens, we squeezed into the morgue. The female corpse in the refrigerated drawer had skin that was already semi-translucent, yet right before our eyes, bloody gash split open, revealing what was wrapped inside... body bag? 裹 尸 袋 里 蜷 缩 着 的 骷 髅 突 然 抬 头 它 的 眼 睛 竟 与 阿 杰 后 腰 的 瘀 痕 一 模 一 样 这 是. . . . . . 我摸向自己口袋发现今天早上在地铁站买的占卜纸牌此刻正从裤裆里探 出一只苍白的手指指缝里卡着. . . . . . 卡着阿杰的手机 The skeleton curled up inside the body bag suddenly looked up. Its eyes were identical to the bruise on Ajies lower back. \"This is...\" reached for my pocket and found the tarot cards had bought at the subway station this morning. pale finger was now poking out from my crotch, and wedged between its knuckles was... was Ajies phone. 雨停后停尸间恢复冰凉寂静我盯着阿杰的后腰那里原本的淤青已经褪成暗紫 像某种正在消散的胎记你说. . . . . . 我指向窗外那里悬着半块被车灯照亮的骨骼这 是谁的骨头 After the rain stopped, the morgue returned to its icy silence. stared at Ajies lower back, where the original bruise had faded to deep violet, like some kind of disappearing birthmark. \"You think...\" pointed out the window, where half bone, illuminated by car headlights, was suspended in the air. \"Whose bone is that?\" 他突然大笑起来你记得吗去年冬天我们在郊外迷路的时候你不是一直往东走 吗 He suddenly burst out laughing. \"Do you remember? Last winter, when we got lost in the countryside, didnt you insist on walking east?\""
        }
    ],
    "affiliations": []
}