{
    "paper_title": "Monte Carlo Diffusion for Generalizable Learning-Based RANSAC",
    "authors": [
        "Jiale Wang",
        "Chen Zhao",
        "Wei Ke",
        "Tong Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Random Sample Consensus (RANSAC) is a fundamental approach for robustly estimating parametric models from noisy data. Existing learning-based RANSAC methods utilize deep learning to enhance the robustness of RANSAC against outliers. However, these approaches are trained and tested on the data generated by the same algorithms, leading to limited generalization to out-of-distribution data during inference. Therefore, in this paper, we introduce a novel diffusion-based paradigm that progressively injects noise into ground-truth data, simulating the noisy conditions for training learning-based RANSAC. To enhance data diversity, we incorporate Monte Carlo sampling into the diffusion paradigm, approximating diverse data distributions by introducing different types of randomness at multiple stages. We evaluate our approach in the context of feature matching through comprehensive experiments on the ScanNet and MegaDepth datasets. The experimental results demonstrate that our Monte Carlo diffusion mechanism significantly improves the generalization ability of learning-based RANSAC. We also develop extensive ablation studies that highlight the effectiveness of key components in our framework."
        },
        {
            "title": "Start",
            "content": "Monte Carlo Diffusion for Generalizable Learning-Based RANSAC Jiale Wang1 Chen Zhao2* Wei Ke1 Tong Zhang23 1Xian Jiaotong University 2EPFL 3University of Chinese Academy of Sciences 5 2 0 M 2 1 ] . [ 1 0 1 4 9 0 . 3 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Random Sample Consensus (RANSAC) is fundamental approach for robustly estimating parametric models from noisy data. Existing learning-based RANSAC methods utilize deep learning to enhance the robustness of RANSAC against outliers. However, these approaches are trained and tested on the data generated by the same algorithms, leading to limited generalization to out-of-distribution data during inference. Therefore, in this paper, we introduce novel diffusion-based paradigm that progressively injects noise into ground-truth data, simulating the noisy conditions for training learning-based RANSAC. To enhance data diversity, we incorporate Monte Carlo sampling into the diffusion paradigm, approximating diverse data distributions by introducing different types of randomness at multiple stages. We evaluate our approach in the context of feature matching through comprehensive experiments on the ScanNet and MegaDepth datasets. The experimental results demonstrate that our Monte Carlo diffusion mechanism significantly improves the generalization ability of learningbased RANSAC. We also develop extensive ablation studies that highlight the effectiveness of key components in our framework. The code is released at: project page. 1. Introduction Robust multi-view geometric estimation is crucial for 3D computer vision tasks such as structure-from-motion [34], SLAM [28], virtual reality [36], and augmented reality [40]. The goal is to estimate reliable geometric transformation model from noisy data with outliers. As the most established robust estimator, RANSAC [15] has been extensively studied and widely adopted for decades. RANSAC operates under the assumption of parametric model, relying on the consistency with this model to distinguish inliers from noisy data. Therefore, RANSAC is applicable to data generated by any methods for the same task. This property allows RANSAC to integrate seamlessly with multi-view geometry frameworks regardless of the source of the raw data. For *Authors contributed equally Corresponding author Figure 1. Advantage of Monte Carlo diffusion. Model-1 and Model-2 denote NG-RANSAC [6] trained on SIFT [24] and LoFTR [35], respectively. The green lines indicate inliers, and the red ones are outliers. As shown in the blue box, the models trained on specific patterns show limited generalization on out-ofdistribution data, e.g., Model-2 trained on LoFTR performs poorly when tested on SIFT. In contrast, we propose diffusion-based training mechanism where training data is agnostic to specific patterns through Monte Carlo diffusion process. NG-RANSAC trained on diffused matches demonstrates better generalization across different initial matches. instance, in camera pose estimation [18], RANSAC is compatible with various pixel-level correspondences, including those obtained from handcrafted detectors/descriptors [4, 24, 32] and learning-based alternatives[13, 14, 33, 35]. The major limitation of RANSAC lies in the sensitivity against outliers. As shown in the literature [18, 22, 44], RANSAC becomes less effective when the initial data contains high proportion of outliers. To handle this issue, some approaches have been proposed to improve the quality of initial data [5, 25, 39, 41, 45]. However, outliers are still inevitable, particularly in challenging scenarios. Therefore, some learning-based RANSAC algorithms [6, 7, 37] 1 have been introduced, leveraging deep learning to improve the robustness of RANSAC against outliers. In this paper, we focus on investigating these learning-based RANSACs. These methods demonstrate promising effectiveness when in the contested on in-distribution data. Specifically, text of feature matching [3], the existing learning-based RANSACs are trained and tested on pixel-level correspondences obtained using the same algorithm such as SIFT [24]. These methods exhibit limited generalization when applied to out-of-distribution data. As shown in Fig. 1, the correspondences established via different approaches exhibit significant differences in keypoint positions, spatial patterns, and outlier ratios. model trained on LoFTR [35] struggles when applied to SIFT [24] and vice versa, despite both addressing the same geometric problem. This observation indicates that the development of learning-based RANSAC variants [6, 7, 37] has inadvertently weakened the core strength of RANSAC, limiting its applicability in realworld scenarios where data is typically from diverse algorithms rather than specific one. Consequently, we propose novel training paradigm, incorporating diffusion-driven module that eliminates dependence on specific data distributions. Our key insight is to decouple the training process from specific data generation approaches by simulating diverse data patterns. Specifically, we progressively inject the noise to ground-truth data through diffusion process. To enhance the data diversity, we develop Monte Carlo sampling mechanism where we introduce different types of randomness at multiple stages of the diffusion module. This stochastic property enables our method to simulate noisy data with diverse distributions. We evaluate the applicability of RANSAC in feature matching through comprehensive experiments on ScanNet [12] and MegaDepth [23] datasets that cover diverse indoor and outdoor scenarios, respectively. We utilize SIFT [24] and LoFTR [35] to establish pixel-wise correspondences, which represent two types of distributions. Experimental results show that learning-based RANSAC trained on one distribution fails to generalize to the other during testing, whereas the method trained based on our Monte Carlo diffusion achieves significantly better generalization. Moreover, we conduct ablation studies where the results demonstrate the compatibility of our method with learning-based RANSACs and highlight the effectiveness of key components in our framework. In summary, our primary contributions are threefold: We investigate the generalization problem in learningbased RANSAC and identify existing training strategies as the primary factor limiting generalization. We propose diffusion-based mechanism that simulates noisy data independent of specific data generation algorithms. We introduce Monte Carlo sampling module that enhances the data diversity by injecting multiple sources of randomness at different stages of the diffusion process. 2. Related Work Random sample consensus. Random sample consensus (RANSAC) [15] has been widely explored in the literature [18, 19, 44], aiming to robustly compute parametric model from noisy data containing outliers. RANSAC iteratively generates model hypotheses based on subsets randomly sampled from the initial data and assesses the reliability of the generated hypotheses on the initial data. The hypothesis that aligns with the largest number of data points is selected as the most reliable model. The data points consistent with the selected model are identified as inliers. To enhance the effectiveness of RANSAC, several variants have been introduced, such as LO-RANSAC [10], PROSAC [9], USAC [29], and MAGSAC [1]. These variants modify the key components of RANSAC, such as subset sampling and model verification, based on handcrafted algorithms. The handcrafted RANSAC approaches excel in improving the robustness of model estimation in scenarios where raw data is of sufficient quality. However, the performance deteriorates when large proportion of outliers exists [20, 44]. Learning-based robust estimator. To improve the robustness against outliers, recent advances have combined deep neural networks with RANSAC. For instance, some methods, such as [22, 41, 43, 45], propose to utilize network as pruner to filter out outliers from raw data. The refined data is then processed by RANSAC [15] to estimate the parametric model. Notably, these methods act as independent pruners, separate from RANSAC itself. In this context, some approaches develop learning-based alternatives within the pipeline of RANSAC. DSAC [7] pioneers this direction by reformulating RANSAC as differentiable pipeline, enabling end-to-end training of hypothesis scoring networks through gradient-based optimization. Building on this concept, NG-RANSAC [6] explicitly models sampling distribution over raw data and employs network to prioritize high-confidence data points during hypothesis sampling. -RANSAC [37] introduces gradient-driven sampling, which dynamically refines hypothesis proposals using deep feature embeddings. These methods achieve promising performance on in-distribution data during inference. Nevertheless, their training strategy inherently ties them to the statistical properties of specific training data. As we will show in our experiments, existing learning-based RANSACs struggle to generalize to out-of-distribution data without retraining. This limitation weakens the advantage of RANSAC as general robust estimator in real applications. In this paper, we address this issue by decoupling training from fixed data distributions through diffusion-driven simulation 2 Figure 2. Pipeline of the diffusion process. We leverage diffusion to simulate noisy data for training learning-based RANSAC. Given ground-truth matches Cgt between two images, we randomly split them into two subsets Ca gt is processed by Monte Carlo diffusion module with multi-stage randomization, generating multiple sets of noised matches at different timesteps. The final diffused matches are formed by combining Cb sampled at timestep ti as outliers. The learning-based RANSAC is then trained on the resulting diffused matches. gt as inliers with Cb gt and Cb gt. Ca mechanism. Pixel-wise feature matching. Given two images, pixelwise correspondences are established to compute the geometric transformation for downstream tasks such as image alignment [8, 16] and 3D reconstruction [21, 27, 38]. Traditional feature matching methods establish correspondences between keypoints based on feature similarities, utilizing handcrafted keypoint detectors and feature descriptors such as SIFT [24] and ORB [32]. As shown in the literature [44], these methods often produce numerous false matches, i.e., outliers, particularly in textureless regions and under severe viewpoint changes. In contrast, Learning-based alternatives such as SuperPoint [13], SuperGlue [33], and LoFTR [35] employ deep neural networks to generate correspondences, leading to advanced matching quality compared with traditional approaches. Since outliers inevitably exist in initial correspondences for both handcrafted and learning-based methods, RANSAC plays crucial role in mitigating the impact of outliers and improving the accuracy of model estimation. Moreover, different matching methods produce distinct initial correspondences, characterized by variations in matching density, outlier ratio, and keypoint position. This variability presents significant challenges for learning-based RANSAC [6, 37] when applied to different matching approaches. Unfortunately, the existing learning-based RANSACs exhibit limited generalization to out-of-distribution correspondences. Consequently, we focus on enhancing the generalization of learning-based RANSAC and assessing its impact on feature matching. 3. Method As illustrated in Fig. 2, our primary innovation lies in employing diffusion mechanism to progressively transform ground-truth data into noisy variants, with noise intensity increasing over time. Furthermore, we enhance the diversity of the diffused data through Monte Carlo sampling in multi-stage randomization module. The diffused data points are then used to train learning-based RANSAC, aiming to robustly estimate the parametric model and identify inliers. 3.1. Problem Formulation Note that we focus on the applicability of RANSAC in feature matching. Therefore, we formulate the problem as follows. Let = {M1, M2, . . . , MK} represent the collection of all feature matching methods. For an image ), each matcher Mk generates set of pair (I, 1 , . . . , c(k) correspondences Ck = [c(k) ] RN 4, where c(k) = [xi, yi, i] indicates correspondence between keypoint (xi, yj) in and keypoint (x . Let Dall = (cid:83) DMk denotes the union of distributions produced by all matchers. The objective of training learning-based RANSAC is to learn parameters θ that minimize the expected loss over Dall: j) in i, i, θ = arg min θ ECDall [LRANSAC(Pθ C, Cgt)] , (1) 3 where θ denotes the learnable parameters in learning-based RANSAC; Pθ represents the results predicted from input correspondences C; LRANSAC() denotes the loss function that will be referred to as L() hereafter for notational simplicity; Cgt is the ground-truth correspondences. However, the optimization over Dall is impractical due to its computational complexity and cost. Instead, existing methods are typically trained on specific DMk . They fail to generalize to other DMj Dall, = k, due to differences in distribution. To overcome this issue, straightforward solution is to employ multiple matchers for training data generation. Nevertheless, incorporating multiple matchers increases computational cost, and the limited number of matchers lacks sufficient diversity to enable effective generalization. In contrast, we develop stochastic optimization strategy, approximating Dall via Monte Carlo sampling. Monte Carlo methods [17, 26, 31] are grounded in repeated random sampling, excelling in efficiently sampling from complex distributions and sufficiently exploring large solution spaces. In the pipeline of image matching, we integrate Monte Carlo sampling into match diffusion process, introducing multi-stage randomization module. At each training iteration, random correspondences Crnd are generated based on Monte Carlo sampling. Crnd, along with the ground truth ˆCgt, are then utilized to optimize the learnable parameters in learning-based RANSAC. We reformulate the expected loss over Dall as an empirical approximation: ECDall [L] 1 H (cid:88) i=1 (cid:16) Pθ C(i) rnd, ˆC(i) gt (cid:17) , (2) where denotes the number of samplings. As the sample size increases (H ), the Monte Carlo estimate of the expected loss converges to the true expectation. 3.2. Match Diffusion To generate Crnd in Eq. (2), we introduce match diffusion mechanism, injecting random noise into correspondences. Notably, instead of employing diffusion for content generation [11, 30, 42], we utilize diffusion to simulate diverse noisy correspondences from available ground truth with varying noise across different timesteps. As the timestep {t1, t2, , tT } increases, the ground truth gradually transitions to pure noise. Specifically, given ground-truth correspondences Cgt between two images, its noised version at timestep is generated through the recursive relation: = (cid:112)1 βtc(i) c(i) t1+(cid:112)βtϵt1, ϵt1 (0, 1), (3) where c(i) denotes correspondence derived from Cgt at timestep t, ϵ indicates the noise sampled from standard normal distribution, and βt [βstart, βend] controls the noise injection rate at t. We update βt across timesteps based on linear schedule: βt = βstart + (βend βstart). (4) The recursive formulation is simplified, directly computing c(i) from c(i) c(i) = αt c(i) 0 + 1 αt ϵ, ϵ (0, 1), (5) 0 as: grows, causing c(i) with αt = (cid:81)t in c(i) truth. Notably, in our method, c(i) 0 c(i) s=1(1 βs). As increases, the injected noise to deviate further from the ground represents an inlier, and serves as an outlier. However, diffusing all correspondences in Cgt may lead to scenario where the raw data lacks sufficient inliers required for model estimation. Therefore, we introduce diffusion ratio to control the proportion of correspondences processed by the diffusion module. As shown in Fig. 2, we randomly sample subset of ground-truth matches, referred to as Ca gt, with ratio of r. The remaining matches are denoted as Cb gt is perturbed with noise following Eq. (5), resulting in the noised counterpart Ca In addition, since the noise is sampled from n. fixed distribution ϵ (0, 1), similar coordinate shifts may occur in correspondences from Ca n. To enhance the diversity, we add noise scale during the diffusion process as: gt. Each correspondence c(i) 0 Ca gt to Ca ˆϵ = ϵ max(W, H), ϵ (0, 1), (6) where and represent the image width and height, respectively. Eq. (5) is then updated as: c(i) = αt c(i) 0 + 1 αt ˆϵ, c(i) 0 Ca gt. (7) The final diffused matches are generated by combining noised and clean subsets as: Crnd = Ca Cb gt, Crnd RN 4. (8) 3.3. Multi-Stage Randomization The proposed match diffusion module generates diffused timestep t, matches controlled by three hyperparameters: diffusion ratio r, and noise scale s. Varying these hyperparameters results in different distributions for Crnd. To determine the hyperparameters, simple approach is to fix them at predefined values. Nevertheless, such fixed hyperparameters contradict our expectation of Monte Carlo approximation, approximating Dall based on random sampling. Consequently, to enhance the randomness in the diffusion module, we propose multi-stage randomization (MSR) method, Figure 3. Illustration of the multi-stage randomization module. We randomly sample the three hyperparameters, timestep t, diffusion ratio r, and noise scale s, in the diffusion mechanism. This multi-stage randomization introduces different sources of randomness into the noised matches, affecting the diffusion intensity, outlier ratio, and noise level, respectively. Invalid matches in the tentative set are replaced by randomly sampled matches, which ensures the validity of the final diffused matches. where we inject randomness at multiple stages throughout the diffusion process. gt and Cb The framework of MSR is illustrated in Fig. 3. When partitioning Cgt into Ca gt, we randomly sample ratio RND-r from the range [rmin, rmax] instead of using fixed r. The ratio of noised matches in Crnd thereby varies between rmin and rmax, leading to diverse outlier ratios. We then scale the noise ϵ using scalar RND-s randomly sampled from the range [smin, smax], as formulated in Eq. (6). Due to the randomness in RND-s, the scaled noise ˆϵ can represent perturbations at varying levels. In addition, for each correspondence in Ca gt, we randomly sample timestep, denoted as RND-t, from {t1, t2, , tT }, and inject the noise to the correspondence as defined in Eq. (7). Notably, during the diffusion process, some correspondences may fall outside the image bounds, making them invalid for training. To handle this problem, we check the validity of the generated correspondences after noise injection and replace invalid matches with RND-Matches. RND-Matches indicate matches that are regenerated through uniform sampling: xrnd, rnd U(0, ), yrnd, rnd U(0, H). (9) further ensures replacement validity the the increasing of noised This randomness matches while in the diffusion module. By randomly sampling (RND-r, RND-s, RND-t, RND-Matches), our MSR introduces randomness at multiple stages of the diffusion module. Fig. 4 illustrates the impact of these hyperparameters on diffused matches. For the same image pair, varying and results in significantly different distributions of diffused matches. Therefore, our multi-stage randomization ensures data diversity and thus facilitates effective Monte Figure 4. Visualization of diffused matches. Given the same image pair, different values of diffusion ratio and noise scale result in significantly different diffused matches. Carlo approximation. Please refer to the supplementary material for more visualization results. 4. Experiments 4.1. Setup We conduct experiments on ScanNet [12] and MegaDepth [23] that include diverse indoor and outdoor scenarios, respectively. We follow the benchmark in SuperGlue [33] on ScanNet, splitting the dataset into 1,513 training scenes and 100 test scenes. We randomly sample 20 image pairs per training scene to construct our training set and employ the same image pairs used in SuperGlue [33] during inference. 5 On MegaDepth, we follow the setup in LoFTR [35], using 368 scenes for training and 5 scenes for testing. We randomly sample 80 image pairs per scene during training and conduct evaluations on the same image pairs as [35]. We employ SIFT [24] and LoFTR [24] as baselines for feature matching. SIFT represents traditional handcrafted approaches, while LoFTR exemplifies learning-based methods. SIFT is computationally efficient but may produce low-quality matches. In contrast, LoFTR generates dense and accurate correspondences but requires significant computational resources. Both of them have distinct advantages depending on the application and are widely used in 3D computer vision tasks. The evaluation is then performed using NG-RANSAC [6] as learning-based robust estimator by default. Specifically, we train NG-RANSAC separately on SIFT, LoFTR, and our diffused matches. We evaluate the trained models in multiple scenarios, employing AUC of the pose error as metric [33, 35]. Note that our method is also compatible with other learning-based RANSACs, as will be evidenced in our experiments. 4.2. Implementation Details Dataset construction. For each image pair (I, ), the corresponding depth maps and camera parameters are utilized to reconstruct 3D points [18]. These points are aligned in the world coordinate system, resulting in the ground-truth pixel-wise correspondences Cgt. We randomly subsample them to obtain 2000 correct correspondences per image pair. Training details. We set the diffusion parameters to βstart = 0.0005, βend = 0.0025, and = 500. RND-r and RNDs are randomly sampled within the ranges [0.2, 0.9] and [0.02, 0.7], respectively, resulting in diffused matches with diverse inlier ratios and noise levels. We maintain the hyperparameters in learning-based RANSAC at their default settings to ensure fair comparisons in our benchmarks. We train the model on GTX 2080 Ti, and the training process takes 60 hours. 4.3. Generalization to Out-of-Distribution Data To assess the generalization to out-of-distribution (OOD) data, we conduct experiments on SIFT [24] and LoFTR [35] correspondences. Specifically, NG-RANSAC [6] trained on SIFT is evaluated on LoFTR, and vice versa. Notably, the presented Monte Carlo diffusion (MCD) is agnostic to specific matchers. Therefore, for NG-RANSAC trained on diffused matches, we directly test it on SIFT and LoFTR. Table 1 and Table 2 list the results on ScanNet [6] and MegaDepth [23], respectively. The models trained on the diffused matches obtained through Mante Carlo match diffusion exhibit significant improvements in generalization ability. For instance, on ScanNet, MCD improves AUC @20 by 12% from 48.8% to 60.8% on LoFTR, when compared with the model trained on SIFT. Figure 5. Qualitative results. Init. Matches represent the initial correspondences generated by SIFT. Baseline and Ours indicate the pruned results using NG-RANSAC trained on LoFTR and diffused matches, respectively. The green and red lines denote inliers and outliers. The baseline shows limited generalization to SIFT, which serves as out-of-distribution data, leading to many outliers after the pruning. In contrast, our method achieves significantly better generalization, identifying more inliers. Notably, NG-RANSAC trained on LoFTR yields limited AUCs on SIFT, e.g., 8.5% in AUC @20. Our method significantly enhances the generalization in this case, improving AUC @20 by 17.7% from 8.5% to 26.2%. Additionally, we achieve consistent improvements on MegaDepth, increasing AUC @20 by 5.7% and 23.4% when tested on LoFTR and SIFT, respectively. Some qualitative results are illustrated in Fig. 5. 4.4. Comparisons in In-Distribution Scenarios In some scenarios, conducting inference on in-distribution data is practical. For example, LoFTR can be deployed in system with enough computational resources for both training and testing. To assess the applicability of our method in such setting, we compare our method with NG-RANSAC that is trained and tested on the same matcher. More specif6 Training Testing AUC @5 AUC @10 AUC @20 Training Testing AUC @5 AUC @10 AUC @20 LoFTR [35] MCD SIFT [24] MCD SIFT [24] SIFT [24] LoFTR [35] LoFTR [35] 1.5 7.6 (+6.1) 13.0 22.4 (+9.4) 4.4 16.2 (+11.8) 29.7 42.7 (+13.0) 8.5 26.2 (+17.7) 48.8 60.8 (+12.0) SIFT [24] SIFT [24] SIFT [24] MCD LoFTR [35] LoFTR [35] LoFTR [35] MCD 16.6 16.9 53.3 53.2 27.0 26.2 67.5 67.7 38.8 36.8 79.3 79. Table 1. Generalization to out-of-distribution data on ScanNet [12]. MCD indicates the diffused matches generated via our Monte Carlo diffusion. NG-RANSAC is separately trained on SIFT, LoFTR, and MCD. NG-RANSAC trained on SIFT is evaluated on LoFTR, and vice versa. AUCs of the pose error with different thresholds are reported, and the best results are highlighted in bold. Training Testing AUC @5 AUC @10 AUC @20 LoFTR [35] MCD SIFT [24] MCD SIFT [24] SIFT [24] LoFTR [35] LoFTR [35] 3.1 16.9 (+13.8) 41.8 53.2 (+11.4) 6.7 26.2 (+19.5) 59.0 67.7 (+8.7) 13.4 36.8 (+23.4) 73.5 79.2 (+5.7) Generalization to out-of-distribution data on Table 2. MegaDepth [23]. NG-RANSAC trained on SIFT, LoFTR, and our MCD is evaluated on out-of-distribution data measured by AUCs of the pose error. ically, we train NG-RANSAC on SIFT and test it on SIFT, and then repeat this process on LoFTR. In contrast, for our method, we retain the diffused matches during training and test the trained NG-RANSAC on both SIFT and LoFTR. As reported in Table 3 and Table 4, our method achieves performance comparable to the baseline, where NG-RANSAC is trained and tested on the same matchers. This evidences that our method not only shows superior generalization but also remains highly competitive in scenarios where the same matcher can be applied for both training and testing. Training Testing AUC @5 AUC @10 AUC @20 SIFT [24] SIFT [24] SIFT [24] MCD LoFTR [35] LoFTR [35] LoFTR [35] MCD 7.6 7.6 22.7 22. 16.1 16.2 42.7 42.7 25.5 26.2 60.1 60.8 Table 3. Comparisons in in-distribution scenarios on ScanNet [12]. The baseline trains and tests NG-RANSAC on the same matchers, while our method trains NG-RANSAC only using diffused matches. 4.5. Ablation Study 4.5.1. Compatibility with learning-based RANSACs Recall that we conduct experiments using NG-RANSAC by default. To shed more light on the compatibility with other learning-based RANSACs, we repeat the experiments in Sec. 4.3 and Sec. 4.4, employing another representative Comparisons in in-distribution scenarios on Table 4. MegaDepth [23]. NG-RANSAC is trained on the same matchers in the baseline but on diffused matches in our paradigm. learning-based RANSAC, -RANSAC [37]. We report the results on ScanNet in Table 5 and Table 6. As demonstrated in these tables, our method maintains the superiority when combined with -RANSAC. The model trained on the diffused matches exhibits better generalization to outof-distribution data, and its results are comparable to the ones trained and tested on the same matchers. These experiments highlight Monte Carlo diffusion as universal enhancer for learning-based RANSACs, improving the generalization ability. Training Testing AUC @5 AUC @10 AUC @20 LoFTR [35] MCD SIFT [24] MCD SIFT [24] SIFT [24] LoFTR [35] LoFTR [35] 2.7 7.6 (+4.9) 22.0 23.5 (+1.5) 4.4 15.8 (+11.4) 41.4 43.1 (+1.7) 10.5 26.2 (+15.7) 58.8 60.2 (+1.4) Table 5. Compatibility with -RANSAC [37] in out-ofdistribution data. The evaluation is conducted employing - RANSAC, and the AUCs on ScanNet [12] are reported. Training Testing AUC @5 AUC @10 AUC @20 SIFT [24] SIFT [24] SIFT [24] MCD LoFTR [35] LoFTR [35] LoFTR [35] MCD 7.3 7.6 23.1 23.5 16.6 15.8 42.8 43. 28.5 26.2 60.0 60.2 Table 6. Compatibility with -RANSAC [37] in in-distribution scenarios. Results on ScanNet [12] are listed. 4.5.2. Monte Carlo approximation MCD approximates all possible distributions Dall of the raw data through Monte Carlo sampling [26]. straightforward alternative is to approximate Dall by combining multiple matchers for data generation. Therefore, we construct training dataset using both SIFT [24] and LoFTR [35] to generate correspondences between images, doubling the size of the original dataset that uses single matcher. We employ SuperGlue (SG) [33] to establish correspondences during testing, treating it as out-of-distribution data. The experimental results on ScanNet are shown in Table 7. Our MCD consistently outperforms the baseline, demonstrating 7 better generalization to out-of-distribution data. While integrating multiple matchers expands the training dataset and covers more distribution types, fixed matchers cannot sufficiently explore Dall. In contrast, our method is independent of specific mathers, and the inherent randomness of the Monte Carlo diffusion module enables diverse sampling from Dall. This advantage thereby leads to improved generalization. Training Testing AUC @5 AUC @10 AUC @20 SIFT [24]+LoFTR [35] MCD SG [33] SG [33] 15.5 17.4 (+1.9) 33.4 35.5 (+2.1) 51.8 54.0 (+2.2) Table 7. Effectiveness of Monte Carlo approximation. NGRANSAC is trained on SIFT and LoFTR as baseline. The baseline and the model trained on our diffused matches are tested on SuperGlue (SG) [33] that indicates out-of-distribution data. AUCs on ScanNet [12] are reported. 4.5.3. Multi-Stage Randomization The randomness in the MSR module is controlled through three parameters, i.e., timestep t, diffusion ratio r, and noise scale s. To assess the contribution of each component, we progressively incorporate them into our framework. We train NG-RANSAC on diffused matches generated by each variant, and Table 8 lists the ablation results on ScanNet. The ablation starts with randomized while keeping = 0.5 and = 0.1 fixed. The inclusion of randomized and improves performance on both SIFT and LoFTR during testing, increasing AUC @20 by 19.6% and 4.0% on SIFT and LoFTR, respectively. These parameters introduce different types of randomness: determines the distribution of the noised data, controls the outlier ratio in diffused matches, and defines the noise level. Their combined effects enhance the diversity of generated data, leading to an optimal solution in our pipeline, as demonstrated by the experimental results. - Testing SIFT [24] LoFTR [35] - - - - - SIFT [24] LoFTR [35] LoFTR [35] SIFT [24] AUC @5 AUC @10 AUC @20 1.1 20.1 3.2 39.0 6.6 56. 4.9 (+3.8) 10.6 (+7.4) 18.3 (+11.7) 21.7 (+1.6) 42.2 (+3.2) 59.8 (+3.0) 7.6 (+2.7) 16.2 (+5.6) 26.2 (+7.9) 22.4 (+0.7) 42.7 (+0.5) 60.8 (+1.0) Table 8. Ablation study on MSR. t, r, and represent timestep, diffusion ratio, and noise scale, respectively. Each of these components introduces different types of randomness in MSR. We progressively add them to our pipeline, and the results on ScanNet [12] are shown. 8 4.5.4. Comparison With Traditional RANSAC In addition to learning-based RANSACs, we conduct comparisons between our method and traditional RANSAC variants. Specifically, we maintain the experimental setup, training NG-RANSAC on diffused matches as our method. We evaluate the trained model and the handcraft methods, RANSAC and MAGSAC++, on SIFT and LoFTR. The results on ScanNet are presented in Table 9. Traditional methods exhibit limited performance on SIFT, resulting in an AUC @5 of 0.6 for RANSAC and 0.8 for MAGSAC++. As SIFT typically produces noisy initial matches with numerous outliers, this finding indicates that handcraft RANSACs are sensitive to outliers, limiting their effectiveness in applications requiring robust parametric model estimation from low-quality data. In contrast, the learning-based RANSAC trained based on our Monte Carlo match diffusion module demonstrates superior adaptability across scenarios with varying data quality. Method Testing AUC @5 AUC @10 AUC @20 SIFT [24] RANSAC [15] SIFT [24] MAGSAC++ [2] SIFT [24] Ours RANSAC [15] LoFTR [35] MAGSAC++ [2] LoFTR [35] LoFTR [35] Ours 0.6 0.8 7.6 (+6.8) 20.4 21.6 22.4 (+0.8) 2.1 2.3 16.2 (+13.9) 39.4 41.1 42.7 (+1.6) 10.5 5.4 26.2 (+20.8) 58.1 59.3 60.8 (+1.5) Table 9. Comparison with handcrafted RANSAC variants on ScanNet [12]. We train NG-RANSAC based on MCD and compare the model with RANSAC and MAGSAC++. 5. Conclusion In this paper, we have presented Monte Carlo diffusion mechanism that enhances the generalization ability of learning-based RANSAC. Unlike existing methods that suffer from overfitting to specific data distributions, our approach decouples training from fixed data sources by simulating diverse noise patterns through diffusion-driven process. By incorporating Monte Carlo sampling, we inject randomness at multiple stages of the diffusion module, further increasing data diversity and robustness. We have evaluated our method on ScanNet and MegaDepth, demonstrating that learning-based RANSAC trained based on Monte Carlo diffusion achieves significantly better generalization when tested on out-of-distribution data. Our method also maintains competitive performance in in-distribution scenarios, ensuring broad applicability. Additionally, extensive ablation studies have confirmed the compatibility with different learning-based RANSAC variants and the effectiveness of key components in our framework."
        },
        {
            "title": "References",
            "content": "[1] Daniel Barath, Jiri Matas, and Jana Noskova. Magsac: marginalizing sample consensus. In IEEE Conf. Comput. Vis. Pattern Recog., pages 1019710205, 2019. 2 [2] Daniel Barath, Jana Noskova, Maksym Ivashechkin, and Jiri Matas. Magsac++, fast, reliable and accurate robust estimator. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13041312, 2020. 8 [3] Adam Baumberg. Reliable feature matching across widely separated views. In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, pages 774781. IEEE, 2000. 2 [4] Herbert Bay, Andreas Ess, Tinne Tuytelaars, and Luc Van Gool. Speeded-up robust features (surf). Computer Vision and Image Understanding, 110(3):346359, 2008. 1 [5] JiaWang Bian, Wen-Yan Lin, Yasuyuki Matsushita, Sai-Kit Yeung, Tan-Dat Nguyen, and Ming-Ming Cheng. Gms: Grid-based motion statistics for fast, ultra-robust feature corIn IEEE Conf. Comput. Vis. Pattern Recog., respondence. pages 41814190, 2017. 1 [6] Eric Brachmann and Carsten Rother. Neural-guided ransac: Learning where to sample model hypotheses. In Int. Conf. Comput. Vis., pages 43224331, 2019. 1, 2, 3, 6 [7] Eric Brachmann, Alexander Krull, Sebastian Nowozin, Jamie Shotton, Frank Michel, Stefan Gumhold, and Carsten Rother. Dsac-differentiable ransac for camera localization. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 66846692, 2017. 1, 2 [8] Matthew Brown and David Lowe. Automatic panoramic image stitching using invariant features. Int. J. Comput. Vis., 74(1):5973, 2007. [9] Ondrej Chum and Jiri Matas. Matching with prosacprogressive sample consensus. In IEEE Conf. Comput. Vis. Pattern Recog., pages 220226. IEEE, 2005. 2 [10] Ondˇrej Chum, Jiˇrı Matas, and Josef Kittler. Locally opIn Joint Pattern Recognition Symposium, timized ransac. pages 236243. Springer, 2003. 2 [11] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion models in vision: survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(9):1085010869, 2023. 4 [12] Angela Dai, Angel Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias Nießner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. In IEEE Conf. Comput. Vis. Pattern Recog., pages 58285839, 2017. 2, 5, 7, 8 [13] Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superpoint: Self-supervised interest point detection and description. In IEEE Conf. Comput. Vis. Pattern Recog. Worksh., pages 224236, 2018. 1, [14] Johan Edstedt, Qiyu Sun, Georg Bokman, Marten Wadenback, and Michael Felsberg. RoMa: Robust Dense IEEE Conference on Computer Vision Feature Matching. and Pattern Recognition, 2024. 1 [15] Martin Fischler and Robert Bolles. Random sample consensus: paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24(6):381395, 1981. 1, 2, 8 [16] Junhong Gao, Yu Li, Tat-Jun Chin, and Michael Brown. In Eurographics (Short PaSeam-driven image stitching. pers), pages 4548. Girona, 2013. 3 [17] John Hammersley. Monte carlo methods. Springer Science & Business Media, 2013. 4 [18] Richard Hartley and Andrew Zisserman. Multiple view geometry in computer vision. Cambridge university press, 2003. 1, 2, 6 [19] Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, Kwang Moo Yi, and Eduard Trulls. Image Matching across Wide Baselines: From Paper to Practice. International Journal of Computer Vision, 2020. 2 [20] Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, Kwang Moo Yi, and Eduard Trulls. Image matching across wide baselines: From paper to practice. International Journal of Computer Vision, 129(2):517547, 2021. 2 [21] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkuhler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Trans. Graph., 42(4):1391, 2023. 3 [22] Hyo Jin Kim, Enrique Dunn, and Jan-Michael Frahm. Learned contextual feature reweighting for image geoIn IEEE Conf. Comput. Vis. Pattern Recog., localization. pages 32513260. IEEE, 2017. 1, [23] Zhengqi Li and Noah Snavely. Megadepth: Learning singleIn Proceedview depth prediction from internet photos. ings of the IEEE conference on computer vision and pattern recognition, pages 20412050, 2018. 2, 5, 6, 7 [24] David Lowe. Distinctive image features from scaleinvariant keypoints. Int. J. Comput. Vis., 60(2):91110, 2004. 1, 2, 3, 6, 7, 8 [25] Jiayi Ma, Ji Zhao, Junjun Jiang, Huabing Zhou, and Xiaojie Guo. Locality preserving matching. Int. J. Comput. Vis., 127 (5):512531, 2019. 1 [26] Nicholas Metropolis and Stanislaw Ulam. The monte carlo method. Journal of the American statistical association, 44 (247):335341, 1949. 4, 7 [27] Ben Mildenhall, Pratul Srinivasan, Matthew Tancik, Jonathan Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. Communications of the ACM, 65(1):99106, 2021. 3 [28] Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan Tardos. Orb-slam: versatile and accurate monocular slam system. IEEE Transactions on Robotics, 31(5):11471163, 2015. [29] Rahul Raguram, Ondrej Chum, Marc Pollefeys, Jiri Matas, and Jan-Michael Frahm. Usac: universal framework for random sample consensus. IEEE Trans. Pattern Anal. Mach. Intell., 35(8):20222038, 2012. 2 [30] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image In Proceedings of synthesis with latent diffusion models. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1068410695, 2022. 4 9 [45] Chen Zhao, Yixiao Ge, Feng Zhu, Rui Zhao, Hongsheng Li, and Mathieu Salzmann. Progressive correspondence pruning by consensus learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6464 6473, 2021. 1, 2 [31] Reuven Rubinstein and Dirk Kroese. Simulation and the Monte Carlo method. John Wiley & Sons, 2016. [32] Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In Int. Conf. Comput. Vis., pages 25642571. Ieee, 2011. 1, 3 [33] Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, Superglue: Learning feature and Andrew Rabinovich. In Proceedings of matching with graph neural networks. the IEEE/CVF conference on computer vision and pattern recognition, pages 49384947, 2020. 1, 3, 5, 6, 7, 8 [34] Noah Snavely, Steven Seitz, and Richard Szeliski. Modeling the world from internet photo collections. Int. J. Comput. Vis., 80(2):189210, 2008. 1 [35] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching In Proceedings of the IEEE/CVF conwith transformers. ference on computer vision and pattern recognition, pages 89228931, 2021. 1, 2, 3, 6, 7, 8 [36] Richard Szeliski. Image mosaicing for tele-reality applications. In Proceedings of 1994 IEEE Workshop on Applications of Computer Vision, pages 4453. IEEE, 1994. 1 [37] Tong Wei, Yash Patel, Alexander Shekhovtsov, Jiri Matas, In and Daniel Barath. Generalized differentiable ransac. Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1764917660, 2023. 1, 2, 3, 7 [38] Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, and Long Quan. Mvsnet: Depth inference for unstructured multi-view stereo. In Proceedings of the European conference on computer vision (ECCV), pages 767783, 2018. 3 [39] Kwang Moo Yi, Eduard Trulls, Yuki Ono, Vincent Lepetit, Mathieu Salzmann, and Pascal Fua. Learning to find good correspondences. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 26662674, 2018. 1 [40] Jung-Jae Yu, Jae-Hean Kim, Hye-mi Kim, Il Choi, and IlKwon Jeong. Real-time camera tracking for augmented reIn 2009 11th International Conference on Advanced ality. Communication Technology, pages 12861288. IEEE, 2009. [41] Jiahui Zhang, Dawei Sun, Zixin Luo, Anbang Yao, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan, and Hongen Liao. Learning two-view correspondences and geometry using order-aware network. In Int. Conf. Comput. Vis., pages 58455854, 2019. 1, 2 [42] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 38363847, 2023. 4 [43] Chen Zhao, Zhiguo Cao, Chi Li, Xin Li, and Jiaqi Yang. Nm-net: Mining reliable neighbors for robust feature correspondences. In IEEE Conf. Comput. Vis. Pattern Recog., pages 215224, 2019. 2 [44] Chen Zhao, Zhiguo Cao, Jiaqi Yang, Ke Xian, and Xin Li. Image feature correspondence selection: comparative study and new contribution. IEEE Trans. Image Process., 29:35063519, 2020. 1, 2,"
        }
    ],
    "affiliations": [
        "EPFL",
        "University of Chinese Academy of Sciences",
        "Xian Jiaotong University"
    ]
}