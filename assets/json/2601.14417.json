{
    "paper_title": "Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis",
    "authors": [
        "Thanathai Lertpetchpun",
        "Yoonjeong Lee",
        "Thanapat Trachu",
        "Jihwan Lee",
        "Tiantian Feng",
        "Dani Byrd",
        "Shrikanth Narayanan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on speaker embeddings associated with specific accents. While effective, this approach offers limited interpretability and controllability, as embeddings also encode traits such as timbre and emotion. In this study, we analyze the interaction between speaker embeddings and linguistically motivated phonological rules in accented speech synthesis. Using American and British English as a case study, we implement rules for flapping, rhoticity, and vowel correspondences. We propose the phoneme shift rate (PSR), a novel metric quantifying how strongly embeddings preserve or override rule-based transformations. Experiments show that combining rules with embeddings yields more authentic accents, while embeddings can attenuate or overwrite rules, revealing entanglement between accent and speaker identity. Our findings highlight rules as a lever for accent control and a framework for evaluating disentanglement in speech generation."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 0 2 ] . [ 1 7 1 4 4 1 . 1 0 6 2 : r a"
        },
        {
            "title": "QUANTIFYING SPEAKER EMBEDDING PHONOLOGICAL RULE INTERACTIONS\nIN ACCENTED SPEECH SYNTHESIS",
            "content": "Thanathai Lertpetchpun1, Yoonjeong Lee1, Thanapat Trachu2, Jihwan Lee1, Tiantian Feng1, Dani Byrd3, Shrikanth Narayanan1,2,3 1Signal Analysis and Interpretation Lab, University of Southern California 2Thomas Lord Department of Computer Science, University of Southern California 3Department of Linguistics, University of Southern California ABSTRACT Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on speaker embeddings associated with specific accents. While effective, this approach offers limited interpretability and controllability, as emIn this beddings also encode traits such as timbre and emotion. study, we analyze the interaction between speaker embeddings and linguistically motivated phonological rules in accented speech synthesis. Using American and British English as case study, we implement rules for flapping, rhoticity, and vowel correspondences. We propose the phoneme shift rate (PSR), novel metric quantifying how strongly embeddings preserve or override rule-based transformations. Experiments show that combining rules with embeddings yields more authentic accents, while embeddings can attenuate or overwrite rules, revealing entanglement between accent and speaker identity. Our findings highlight rules as lever for accent control and framework for evaluating disentanglement in speech generation. Index Terms Text-to-Speech, Accent Control, Phonological Rules, Speaker Embeddings, Speech Generation 1. INTRODUCTION Accents are defining source of variation in spoken language, and English provides striking case. Spoken by approximately one-fifth of the worlds population, yet with only one-fourth native speakers [1, 2], the English language has developed broad range of accent varieties from both native and non-native speaker backgrounds [3]. These include regional varieties such as American, British, and Australian English, as well as global variants such as Indian English. [4, 5]. Capturing such variation has become an important goal for speech generation technologies. Accent in TTS is typically controlled by conditioning on speaker embeddings [6, 7]. However, embeddings also encode multiple traits unrelated to the accent, such as voice timbre [8, 9], speaker emotion [10, 11, 12], and background noise [13], making accent representation opaque and difficult to control. To address this, we use linguistically motivated phonological rules as targeted probes of accent control. Our goal is not to replace data-driven models with synthesis-byrule but to test how explicit phoneme-level transformations interact with speaker embeddings in modern TTS systems. *Equal contribution We focus on three well-documented phonological processes that differentiate American and British English varieties: flapping, rhoticity, and vowel correspondences. In American English, intervocalic /t/ is often realized as flap [R] in unstressed contexts (e.g., water [waRÄ]), while British English typically retains [t]. Rhoticity also diverges: American English is rhotic, preserving post-vocalic ô (e.g., car [kaô]), whereas most British varieties are non-rhotic, deleting or vocalizing ô in coda position (e.g., car [kA:]). Finally, systematic vowel correspondences arise across lexical sets. For example, bath is pronounced as /bæT/ in American English but /bAT/ in British English, and goat as [goUt] versus [g@Ut]. These selected contrasts are not modeled to capture every nuance of accent variation. Instead, we deliberately operationalize them as big-stroke transformationssalient enough to shift perceived accent without overfitting dialectal micro-variation. This makes them useful testbed for probing the balance between embedding-driven and linguistic control, focusing less on mimicking full dialects and more on revealing where embeddings and linguistic structure interact. Our substitutions target robust cross-accent pronunciation patterns that have been consistently documented in linguistic descriptions [3, 14] and behavioral studies of accent perception [15, 16], making them ideal probes for accent strength and principled lens on disentanglement in speech generation. To quantify accent strength we use an accent classification model, where higher predicted probability for given accent indicate stronger accentedness. caveat in this approach, however, is that predicted probabilities are inherently tied to the models training task and the particular accent contrasts it encodes, making them task-specific rather than general measures. To complement this, we also compute accent embedding similarity. If two utterances yield embeddings that lie close together in the accent space, they are assumed to share similar accent characteristics. While useful, neither of these measures directly captures the impact of phonological rules. Our rules are deliberately coarse, targeting the most salient cross-accent shifts, but the actual realization may be moderated by the speaker embedding. To evaluate this interaction, we introduce the phoneme shift rate (PSR), novel metric that quantifies how much speaker embeddings preserve or overwrite the rule-driven phoneme mappings. For example, when we convert [læR@ô] (latter) into more British-like target [lAt@@], the synthesized output may still realize [lætÄ], reflecting partial pull back toward the American form. PSR measures such cases of gradient reinforcement or attenuation, offering direct probe of where rulebased transformations hold versus where embeddings dominate. We Copyright 2026 IEEE. Published in ICASSP 2026 - 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3-8 May 2026 in Barcelona, Spain. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O. Box 1331 / Piscataway, NJ 08855-1331, USA. Telephone: + Intl. 908-562-3966. view PSR as first step toward systematic evaluation of disentanglement in TTS, offering an interpretable way to steer accent strength that is linguistically grounded yet flexible enough for modern TTS. The contributions of this study are: 1) We introduce small set of linguistically guided phonological rules for highly salient dialect differences that transform accents between American and British English, offering controlled and interpretable probe for accent in TTS. 2) We introduce the phoneme shift rate (PSR), novel metric to evaluate how rule-based transformations are preserved or attenuated by speaker embeddings. 3) We present systematic analysis of the interplay between phonological rules and speaker embeddings, showing how coarse, knowledge-driven constraints can reveal the degree of disentanglement in speech generation. Together, these results demonstrate that knowledge-driven rules, even at coarse granularity, can be effective levers for accent control, providing interpretable guidance within modern data-driven TTS systems. Speech samples are available1. Code implementing the phonological rules will be released upon acceptance. 2. PHONOLOGICAL RULES We define three sets of substitution rules to map American to British English phoneme sequences. Flapping: Intervocalic /t/ realized as [R] in American English is mapped to [t] in British English (e.g., water: [waRÄ] [wAt@]). Rhoticity: Post-vocalic /r/ is retained in American English but deleted or vocalized in British English (e.g., car: [kaô] [kA:]) Vowel correspondences: Systematic mappings are applied across lexical sets, such as TRAP, BATH, and GOAT (e.g., bath: /bæT/ /bAT/; goat: [goUt] [g@Ut]). The rules are applied as one-to-one substitutions, with the phoneme character count strictly preserved across the American and British IPA sequences, ensuring that differences in synthesized accent strength arise only from segmental mappings and speaker embeddings. 3. APPLICATION TO SPEECH GENERATION TASKS To implement our phonological rules, we follow the pipeline illustrated in Fig 1: 1) obtain an American English phoneme sequence from normalized text using Misaki G2P 2; 2) apply the proposed phonological rules to derive the corresponding British phoneme sequence; 3) synthesize speech outputs from both inputs. Speech is generated using Kokoro TTS 3. Inputs to the model include the phoneme sequence (American or British), speaker embedding, and fixed phoneme durations. The phoneme character count and duration are strictly preserved across all conditions, ensuring that observed accent differences reflect the interaction of phonological substitution rules with speaker embeddings rather than confounds from timing or text normalization. 4. METRICS Fig. 1. Synthesis and evaluation pipeline. Inputs to Kokoro TTS are phoneme sequence (American or British), speaker embedding, and fixed phoneme durations. The yellow path shows rule-based phoneme substitutions prior to synthesis, and the green path shows evaluation of their effect on the synthesized accented speech. Vox-Profile evaluates the synthesized speech with regard to the accent classifier output; while Phoneme Recognition measures how phoneme realizations shift under the influence of speaker embedding. The evaluation metrics are explicated further below. 4.1. Vox-Profile Accent Classifier Vox-Profile [17] is benchmark tool that predicts multiple speaker traits, including speaker accent. In this work, we use its Whisperbased broad accent classifier, trained on more than 100k unique utterances from 11 diverse data sources. Specifically, the classifier assigns each input utterance to one of three accent categories: North American English, British Isles English, and English spoken with other language backgrounds. To measure the accentedness in synthesized speech, we adopt two complementary measures, following prior work [19, 20, 21, 22]. The first is the accent probabilities: logits from the classifiers final layer are converted to class probabilities with the softmax function, and the average probability assigned to the target accent (North American or British Isles) is used as the index of accent strength. The second is accent similarities: cosine similarity is computed between the accent embedding of each synthesized speech and group-level reference accent embedding. The reference group-level embedding is derived by averaging accent embeddings from real speech of each accent in the Vox-Profile test set. We evaluate our approach along two dimensions: accent strength and naturalness. For indexing accent strength, we use two models: VoxProfile [17] and Phoneme Recognition [18] (Wav2Vec2Phoneme). 1https://sav-eng.github.io/icassp_samples.html 2https://github.com/hexgrad/misaki 3https://github.com/hexgrad/kokoro 4.2. Phoneme Shift Rate (PSR) Speaker embeddings encode many dimensions of speaker traits, and therefore condition speech generation on them. They can influence not only timbre but also phoneme realization. To quantify this interaction with our phonological rules, we introduce novel metric called phoneme shift rate (PSR). Without loss of generosity, we use the example in generating the British target speech described earlier. In this case, PSR is defined as the ratio 2 1 , where 1 is the number of phoneme substitutions specified by our rules to convert US phoneme sequence into British target, and 2 is the number of substitutions that must still be applied when re-applying the same rules to the phoneme transcript If the output perfectly respects of the synthesized British output. the rule-based transformations, 2 = 0 and SR = 0. If the speaker embedding completely overrides the rule inputs, 2 = 1 and SR = 1, under the assumption that TTS and phoneme recognition have perfect accuracy. Crucially, while our rules are modeled as categorical substitutions (e.g., mapping /t/ to [R], deleting post-vocalic /ô/, or shifting /ae/ to A), phonological categories are realized gradiently in natural speech. The same holds in synthesis: rule may surface fully, partially, or not at all, depending on how strongly the speaker embedding shapes the acoustic outcome. For example, British target like [lAt@:] (latter) may surface as [lætÄ], reflecting partial drift back toward the American form. PSR captures this continuum, quantifying how rule-based transformations interact with the gradient pressures of speaker embeddings. It thus goes beyond rule errors providing diagnostic for accent control and novel framework for analyzing how linguistic rules and embeddings compete or reinforce one another in synthesis. 4.3. Naturalness Evaluation with UTMOS We also evaluate the naturalness of synthesized speech to ensure that applying phonological rules shifts accent strength without degrading the naturalness of the output speech. For this, we use UTMOS [23], non-intrusive model trained to estimate human naturalness ratings (MOS) of speech without requiring subjective listening tests. UTMOS outputs score ranging from 1 (least natural) to 5 (human-level naturalness). We compute UTMOS for each utterance and average across the set to obtain an overall naturalness measure. 5. DATASETS AND EXPERIMENTAL SETUPS We use pretrained TTS model, Kokoro-82M v0.194, multilingual TTS model supporting eight languages including English, Japanese, and Mandarin. The model takes speaker embedding and phoneme sequence as input. For English, 28 preset speaker embeddings are available: 20 are derived from American English speakers, and 8 are from British speakers. Our experiments manipulate both the speaker embeddings and phonological rules to control accent strength. Synthesized utterances are based on transcripts from LibriTTS-R [24] on the train-clean-100 subset. For consistency, we use af heart as the primary American speaker, bm fable as the primary British speaker and assign the duration of each phoneme from af heart uniformly to British speakers. In total, the synthesized speech spans 33k utterances and 55.4 hours of speech. 5.1. Rule Application Configurations To assess the contribution of individual phonological rules, we conduct analyses under three configurations: (1) speaker embeddings alone, (2) embeddings plus single transformation rule, and (3) embeddings plus the full set of rules. For the full set, we also perform ablation experiments in which one rule is removed at time. This 4The model is available at https://huggingface.co/hexgrad/ Kokoro-82M. design allows us to isolate the effect of each rule on accent strength while also evaluating the combined benefit of data-driven and ruledriven approaches. 6. RESULTS AND DISCUSSION We present results from three sets of experiments. First, we fix the speaker embedding input to the TTS and vary the number of applied rules to assess how each rule contributes to accented speech. Second, we analyze synthesized phoneme sequences to see how speaker embeddings interact with or override rule-based transformations. Finally, we examine the role of individual speaker embeddings in shaping accented output. 6.1. Effects of Each Phonological Rule on Speech Synthesis Table 1. Results on accented speech synthesis under different phonological transformation rules. All rules applied in this experiment are crafted for British English. We also present results conditioned on speaker embeddings from both accents to study how strongly these speaker embeddings adhere to or override these ruledriven transformations. NA denotes North American. denotes British. Spk Emb denotes speaker embedding. UTMOS Accent Prob NA Accent Sim NA NA Spk Emb + All Spk Emb + Flapping + Rhoticity + Vowel + All - Flapping - Rhoticity - Vowel 4.43 4.42 3.74 3.74 3.73 3.73 3.72 3.72 3.73 3.73 86.5 58.8 17.6 17.3 9.5 9.8 5.3 5.3 9.5 9. 3.79 17.3 67.8 68.5 68.8 77.8 78.4 78.1 78.1 69.4 0.85 0.74 0.33 0.32 0.14 0.18 0.03 0.03 0.18 0.14 -0.05 0.21 0.67 0.67 0.78 0.78 0.85 0.85 0.78 0. PSR 0.856 0.827 0.775 0.749 0.739 0.693 0.628 0.646 0.670 0.716 Table 1 summarizes naturalness (UTMOS), accent strength (probabilities and similarities for North American vs. British), and phoneme shift rate (PSR) under different rule configurations. The column Accent Prob with (NA/B) indicates the average probabilities assigned by the Vox-Profile accent classifier to North American or British speech. The column Accent Sim with (NA/B) denotes the average cosine similarity between synthesized utterances and group-level reference embeddings for each accent. PSR measures how often rule-driven phoneme substitutions persist in the output, with lower values reflecting stronger rule preservation. Across conditions, naturalness is stable. UTMOS remains around 4.4 for North American and 3.7 for British settings, whether or not rules are applied. This indicates that integrating phonological rules alongside speaker embeddings does not degrade the naturalness of the synthesized speech. Consistently lower UTMOS scores across the board for the British-accented speech likely reflects bias in the predictor, which was trained on data with heavier North American representation [20] rather than any actual degradation. Second, accent probabilities show clear rule effects. With North American speaker embedding, the baseline system yields an 86.5% probability of the North American accent. Adding all three phonological transformation rules drops this to 58.8% and raises the British probability to 17.3%, showing that rules shift the classifiers decision away from North American toward British. Conversely, with British speaker embedding, the baseline system alFig. 2. Kernel Density Estimation (KDE) of histograms on the number of changes of the rules. ready achieves 67.8% British probability, but this increases to 78.4% when all British English substitution rules are applied. Third, accent similarities follow the same trend. With North American embeddings, British similarity increases from -0.05 to 0.21 when rules are applied, pulling synthesized speech closer to the British reference. With British embeddings, similarity to the British reference rises from 0.67 to 0.85. The role of individual rules emerges when applied selectively with British embeddings. Vowel correspondences drive the largest gains, raising British probability to 77.8% and reducing PSR to 0.693. Rhoticity increases similarity to the British embedding space (0.78) even when classifier probabilities remain modest. Flapping alone has minimal impact but contributes additively when combined with other rules. Ablations confirm vowel correspondences as the single most influential factor. Finally, PSR captures how often rule effects survive in output phonemes. Lower values indicate stronger preservation of ruledriven changes. With British embeddings, PSR falls from 0.775 without rules to 0.628 with all rules, showing that rules measurably shape outputs even when embeddings exert strong pull in the opposite direction. 6.2. How Do Rules Affect Phonemes of the Synthesized Speech? Table 2. Total number of times we apply the rule (in thousands). 1 and 2 are the notation from Fig 1 in the green highlight. NA and denote North American and British accents. Flapping Rhoticity Vowel All Rules NA (N 1) NA (N 2) w/o rules (N 2) w/ rules (N 2) 12.8 25.3 12.3 6.7 83.5 57.9 57.4 53.7 125.1 106.3 101.7 78.5 221.4 189.5 171.5 139.0 To analyze rule retention at the phoneme level, we compare the number of substitutions (N 1) expected with the number observed in recognized outputs (N 2), as summarized in Table 2. Ideally, if all substitutions survived, 2 would be zero after applying rules. It is often observed that speaker embeddings overwrite some substitutions, pushing outputs back toward their accent biases. The results show that vowel correspondences account for the largest number of changes, consistent with their strong effect in Table1. For flapping, 2 increases under North American embeddings, suggesting that the G2P baseline phonemes were not fully American and the embedding reinforced flapping. For rhoticity and vowels, 2 is significantly lower than 1 under North American embeddings, demonstrating that one speaker embedding can simultaneously represent different accent tendencies depending on the phoneme context. Fig 2 visualized these effects using KDE histograms; rule application increases the skewness toward smaller numbers of changes, indicating the effectiveness of the rules. However, distributions remain broad, highlighting how speaker embedding can override or dilute specific rule effects. 6.3. On the Role of Individual Speaker Embeddings in Accented Speech Synthesis. Table 3. Results on accented speech synthesis under different speaker embeddings. -R suffix denotes the addition of rules. NA and denote North American and British accents. Accent Prob NA Accent Sim NA PSR Isabella Isabella-R Lily Lily-R Fable Fable-R Daniel Daniel-R 2.7 1. 2.0 0.9 17.6 5.7 4.7 1.5 85.3 90.1 89.3 91.6 67.8 78. 89.8 93.2 0.03 -0.07 -0.01 -0.12 0.33 0.03 0.07 -0.07 0.88 0. 0.91 0.93 0.67 0.86 0.86 0.93 0.633 0.48115.2% 0.660 0.49416.6% 0.775 0.62814.7% 0.706 0.54316.3% Table 3 examines how individual speaker embeddings interact with rule application. Results are shown for Kokoro TTS voices5. Across voices, rules consistently strengthen accent probabilities. For example, the Fable embedding alone yields 67.8% British probability; with rules, this rises to 78.4%. Similarity to the British reference also improves, and PSR decreases from 0.775 to 0.628. For Isabella and Lily, rule application produces 15-17% absolute reductions in PSR, confirming stronger preservation of rule-driven transformations. The degree of interaction varies across embeddings. Some embeddings like Daniel, already produce high British probabilities ( 89.8%) but still show improvements when rules are applied (to 93.2%). Others, like Fable, rely more heavily on rule guidance. This variation suggests that embeddings encode accent characteristics with differing levels of entanglement, which rules can either reinforce or correct. 7. CONCLUSION Taken together, our results show that phonological rules are coarse but effective lever for accent control. They preserve naturalness, strengthen accent attributes, and reveal how speaker embeddings can reinforce or override explicit transformations. By offering interpretable, linguistically grounded modifications, rules complement speaker embeddings and highlight future directions for designing embeddings that disentangle accent from other traits while remaining responsive to rule-based inputs. 5https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md 8. ACKNOWLEDGMENT This work was supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the ARTS Program under contract D20232308110001. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. 9. REFERENCES [1] David Crystal, English as Global Language, Cambridge University Press, 2 edition, 2003. [2] Ethnologue, English language profile, https://www. Accessed: ethnologue.com/language/eng, 2024, 2025-09-15. [3] J. C. Wells, Accents of English, Cambridge University Press, 1982. [4] Braj B. Kachru, The Alchemy of English: The Spread, Functions, and Models of Non-Native Englishes, University of Illinois Press, 1990. [5] Edgar W. Schneider, Postcolonial English: Varieties around the World, Cambridge University Press, 2007. [6] Xuehao Zhou, Mingyang Zhang, Yi Zhou, Zhizheng Wu, and Haizhou Li, Multi-scale accent modeling and disentangling for multi-speaker multi-accent text-to-speech synthesis, arXiv preprint arXiv:2406.10844, 2024. [7] Xuehao Zhou, Mingyang Zhang, Yi Zhou, Zhizheng Wu, and Haizhou Li, Accented text-to-speech synthesis with limited data, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 32, pp. 16991711, 2024. [8] Chenpeng Du, Yiwei Guo, Xie Chen, and Kai Yu, Speaker adaptive text-to-speech with timbre-normalized vector-quantized feature, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 34463456, 2023. [9] Joun Yeop Lee, Jae-Sung Bae, Seongkyu Mun, Jihwan Lee, Ji-Hyun Lee, Hoon-Young Cho, and Chanwoo Kim, Hierarchical timbre-cadence speaker encoder for zero-shot speech synthesis, in Interspeech 2023, 2023, pp. 43344338. [10] Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, and Diemo-tts: Disentangled emotion repSeong-Whan Lee, resentations via self-supervised distillation for cross-speaker emotion transfer in text-to-speech, in INTERSPEECH, 2025. [11] Thanathai Lertpetchpun and Ekapol Chuangsuwanich, Instance-based temporal normalization for speaker veriin Proc. INTERSPEECH, 2023, vol. 2023, pp. fication, 31723176. [12] Heejin Choi, Jae-Sung Bae, Joun Yeop Lee, Seongkyu Mun, Jihwan Lee, Hoon-Young Cho, and Chanwoo Kim, Mels-tts : Multi-emotion multi-lingual multi-speaker text-to-speech system via disentangled style tokens, in ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024, pp. 1268212686. [13] Kenichi Fujita, Hiroshi Sato, Takanori Ashihara, Hiroki Kanagawa, Marc Delcroix, Takafumi Moriya, and Yusuke Ijima, Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters, in ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2024, pp. 1147111475. [14] Peter Trudgill, The Dialects of England, Blackwell, 1999. [15] James E. Flege, Second language speech learning: Theory, findings, and problems, in Speech Perception and Linguistic Experience: Issues in Cross-Language Research, Winifred Strange, Ed., pp. 233277. York Press, 1995. [16] Cynthia G. Clopper and David B. Pisoni, Homebodies and army brats: Some effects of early linguistic experience and residential history on dialect categorization, Language Variation and Change, vol. 16, no. 1, pp. 3148, 2004. [17] Tiantian Feng, Jihwan Lee, Anfeng Xu, Yoonjeong Lee, Thanathai Lertpetchpun, Xuan Shi, Helin Wang, Thomas TheVoxbaud, Laureano Moro-Velazquez, Dani Byrd, et al., profile: speech foundation model benchmark for characarXiv preprint terizing diverse speaker and speech traits, arXiv:2505.14648, 2025. [18] Qiantong Xu, Alexei Baevski, and Michael Auli, Simple and effective zero-shot cross-lingual phoneme recognition, arXiv preprint arXiv:2109.11680, 2021. [19] Yuancheng Wang, Haoyue Zhan, Liwei Liu, Ruihong Zeng, Haotian Guo, Jiachen Zheng, Qiang Zhang, Xueyao Zhang, Shunsi Zhang, and Zhizheng Wu, Maskgct: Zero-shot textto-speech with masked generative codec transformer, in ICLR, 2025. [20] Jinzuomu Zhong, Suyuan Liu, Dan Wells, and Korin Richmond, Pairwise evaluation of accent similarity in speech synthesis, arXiv preprint arXiv:2505.14410, 2025. [21] Jinzuomu Zhong, Korin Richmond, Zhiba Su, and Siqi Sun, Accentbox: Towards high-fidelity zero-shot accent generation, in ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2025, pp. 15. [22] Sho Inoue, Shuai Wang, Wanxing Wang, Pengcheng Zhu, Mengxiao Bi, and Haizhou Li, Macst: Multi-accent speech in synthesis via text transliteration for accent conversion, ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2025, pp. 15. [23] Takaaki Saeki, Detai Xin, Wataru Nakata, Tomoki Koriyama, Shinnosuke Takamichi, and Hiroshi Saruwatari, Utmos: Utokyo-sarulab system for voicemos challenge 2022, Interspeech2022, 2022. [24] Yuma Koizumi, Heiga Zen, Shigeki Karita, Yifan Ding, Kohei Yatabe, Nobuyuki Morioka, Michiel Bacchiani, Yu Zhang, Wei Han, and Ankur Bapna, Libritts-r: restored multi-speaker arXiv preprint arXiv:2305.18802, text-to-speech corpus, 2023."
        }
    ],
    "affiliations": [
        "Department of Linguistics, University of Southern California",
        "Signal Analysis and Interpretation Lab, University of Southern California",
        "Thomas Lord Department of Computer Science, University of Southern California"
    ]
}