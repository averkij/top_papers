{
    "paper_title": "LLM Watermark Evasion via Bias Inversion",
    "authors": [
        "Jeongyeon Hwang",
        "Sangdon Park",
        "Jungseul Ok"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Watermarking for large language models (LLMs) embeds a statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance a rigorous understanding and evaluation of such vulnerabilities, we propose the \\emph{Bias-Inversion Rewriting Attack} (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99\\% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal a systematic vulnerability, emphasizing the need for stress testing and robust defenses."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 2 ] . [ 1 9 1 0 3 2 . 9 0 5 2 : r a"
        },
        {
            "title": "LLM WATERMARK EVASION VIA BIAS INVERSION",
            "content": "Jeongyeon Hwang, Sangdon Park, Jungseul Ok Pohang University of Science and Technology (POSTECH), South Korea {oppurity,sangdon,jungseul}@postech.ac.kr"
        },
        {
            "title": "ABSTRACT",
            "content": "Watermarking for large language models (LLMs) embeds statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance rigorous understanding and evaluation of such vulnerabilities, we propose the Bias-Inversion Rewriting Attack (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal systematic vulnerability, emphasizing the need for stress testing and robust defenses."
        },
        {
            "title": "INTRODUCTION",
            "content": "The rapid advancement and proliferation of large language models (LLMs) (Minaee et al., 2024; Wang et al., 2024a) have intensified concerns about their misuse, ranging from the spread of misleading content (Monteith et al., 2024; Wang et al., 2024b; Papageorgiou et al., 2024) to threats to academic integrity, such as cheating (Stokel-Walker, 2022; Kamalov et al., 2023). To address these risks, watermarking has been proposed as promising approach for detecting LLM-generated content (Aaronson & Kirchner, 2022; Kirchenbauer et al., 2024b). The core idea is to embed an imperceptible statistical signal into generated text, for example, by partitioning the vocabulary into green and red lists using secret key, and biasing generation toward the green list. detector then identifies LLM-generated text by checking for statistical overrepresentation of green tokens. Recent work shows that watermarking is robust against common evasion strategies, such as text insertion, text substitution, and text deletion (Kirchenbauer et al., 2024b; Liu et al., 2024; Zhao et al., 2024; Lee et al., 2024; Lu et al., 2024). This robustness has drawn significant attention and spurred movement toward deployment. For instance, OpenAI has discussed adding watermarking to its products (Bartz & Hu, 2023), and U.S. policymakers have proposed legislation requiring watermarks for AI-generated content (Tong, 2024). However, recent studies (Raffel et al., 2020; Cheng et al., 2025; Wu & Chandrasekaran, 2024; Chen et al., 2024; Jovanovic et al., 2024) have questioned the robustness of watermarking, noting that existing methods have not been sufficiently stress-tested and showing that watermarks can be evaded through sophisticated strategies. These approaches fall into two categories: query-based attacks (Wu & Chandrasekaran, 2024; Chen et al., 2024; Jovanovic et al., 2024), which recover watermarks secret parameters but require unrestricted access to the target model through repeated queries, and query-free attacks (Raffel et al., 2020; Cheng et al., 2025), typically based on paraphrasing, which avoid this assumption but achieve only limited attack success and often distort semantic meaning. In response to these limitations and to advance the understanding of watermarking vulnerabilities, we propose the Bias-Inversion Rewriting Attack (BIRA), motivated by theoretical analysis showing that reducing the probability of generating green tokens by δ > 0 during the rewriting of watermarked text causes the overall detection probability to decay exponentially in δ. To achieve this, BIRA applies negative bias to proxy set of green tokens during paraphrasing with an LLM, without requiring knowledge of the underlying scheme. It consistently evades detection across wide range of recent watermarking algorithms while preserving the semantics of the original text. Our contributions are summarized as follows: Corresponding authors."
        },
        {
            "title": "Preprint",
            "content": "We formally demonstrate theoretical vulnerability in current watermarking schemes. Building on this theoretical insight, we introduce BIRA, which weakens the watermark signal by applying negative logit bias to likely watermarked tokens. We conduct extensive experiments showing that BIRA achieves state-of-the-art evasion rates against recent watermarking algorithms while maintaining semantic fidelity."
        },
        {
            "title": "2 RELATED WORK",
            "content": "LLM watermarking. Kirchenbauer et al. (2024a) introduced widely used scheme that partitions the vocabulary into green and red sets and embeds detectable statistical signal by adding positive logit bias to green tokens. Subsequent studies have enhanced its robustness by improving key generation and detection (Kirchenbauer et al., 2024b; Liu et al., 2023a; Zhao et al., 2024; Liu et al., 2024; Lee et al., 2024; Lu et al., 2024) or by preserving the original LLM distribution (Wu et al., 2023). Other lines of work investigate sampling-based watermarking approaches (Aaronson & Kirchner, 2022; Hu et al., 2023; Christ et al., 2024). Watermark evasion attacks. Watermark evasion attacks can be broadly categorized into two types: query-based and query-free. In query-based attacks (Wu & Chandrasekaran, 2024; Chen et al., 2024; Jovanovic et al., 2024), the adversary repeatedly queries the watermarked LLM to infer watermarking rules, often by issuing large number of crafted prefix prompts. Such approaches assume unrestricted access to the target model, which is of limited practicality and incurs significant computational overhead. In contrast, query-free attacks operate directly on generated text and do not interact with the watermarked model. These methods typically rely on editing or paraphrasing to obscure the statistical signal. Early work (Kirchenbauer et al., 2024a) introduced simple transformation attacks, such as inserting emojis or human-written fragments into watermarked text. More advanced methods either fine-tune an LLM as paraphrasing expert (Krishna et al., 2023) or use masking and rewriting strategy that targets high entropy tokens (assumed to be watermarked) and then regenerates them with an LLM (Cheng et al., 2025). These post-processing approaches often achieve only limited attack success and fail to preserve the original meaning. In contrast, our method attains substantially higher attack success rate while preserving semantic fidelity."
        },
        {
            "title": "3 PRELIMINARY",
            "content": "Language model. language model, denoted by M, generates text by predicting the next token in sequence. Given an input sequence x0:n1 = [x(0), . . . , x(n1)], the model outputs logit vector l(n) = (l(n) 1) RV from which it derives probability distribution Q(n) over the vocabulary of size using the softmax operator: 0 , . . . , l(n) exp(l(n) ) j=1 exp(l(n) The next token x(n) is then drawn from Q(n), either by sampling or by another decoding strategy. V. = Q(n) (cid:80)V ) , Watermarking algorithm. watermarking algorithm consists of two components: generation function and detection function D. Given secret key k, the algorithm Wk modifies the distribution Q(n) during text generation to produce (cid:98)Q(n) = M(x0:n1, Wk), embedding hidden patterns (e.g., green tokens) into the output y. For instance, Kirchenbauer et al. (2024a); Liu et al. (2023a); Zhao et al. (2024); Liu et al. (2024); Lee et al. (2024); Lu et al. (2024) add positive logit bias γ > 0 to l(n) for tokens G(Wk), the green set generated by the secret key k, which increases their sampling probability and biases the generated text ˆy toward green tokens. The detection function then takes text sequence and the same secret key as input, and determines whether is watermarked: D(y, Wk) = 1{Z(y; Wk) τ }, where Z(y; Wk) is test statistic on the watermark patterns (e.g., one-proportion z-statistic on the fraction of green tokens), and τ is the detection threshold. Here, the null hypothesis H"
        },
        {
            "title": "Preprint",
            "content": "Figure 1: Illustration of BIRA. watermarked LLM typically increases the likelihood of sampling green tokens by adding positive bias γ > 0 to their logits at each generation step. In contrast, BIRA applies negative bias β < 0 to proxy set of green tokens (since the true set is unknown), thereby suppressing their sampling probability. This inversion lowers the probability of generating green tokens and weakens the watermark signal, enabling the paraphrased text to evade detection. is that the text was not generated with Wk, and the watermark is detected by rejecting H0 when Z(y; Wk) τ . Threat model. We consider black-box threat model where the adversary has no knowledge of the watermarking scheme or the target model. Adversarys objective. The adversarys goal is to design text modification function that transforms watermarked text ˆy into modified text = F(ˆy), which is detected as unwatermarked, while preserving the original meaning of ˆy: = arg min [D(y, Wk)] s.t. S(y, ˆy) ϵ, (1) where is similarity measure between two texts used to evaluate semantic preservation."
        },
        {
            "title": "4 METHOD",
            "content": "In this section, we first present the theoretical analysis of watermarking vulnerabilities that our attack exploits (Section 4.1), and then describe the attack algorithm (Section 4.2). Figure 1 provides an overview of BIRA. 4.1 THEORETICAL ANALYSIS OF WATERMARKING VULNERABILITIES The goal of watermark evasion attack is to diminish the overrepresentation of green tokens in text to level that cannot be detected statistically. We first show that common watermark detectors, which rely on test statistics like the z-score, are functionally equivalent to simple threshold test on the empirical green token rate, ˆp(y; Wk) (Theorem 1). Building on this, we prove that if the average probability of generating green token across the sequence stays below the detection threshold by margin δ, then the detection probability decreases exponentially in δ (Theorem 2). Theorem 1. Let the detector be D(y, Wk) = 1{Z(y; Wk) τ } and suppose there exists nondecreasing function : [0, 1] with Z(y; Wk) = h(ˆp(y; Wk)) , ˆp(y; Wk) = 1 N 1 (cid:88) n=0 1{y(n) G(Wk)}, where G(Wk) denotes the green set produced by watermarking Wk. Then, for given , there exists pτ [0, 1] such that D(y, Wk) = 1{ˆp(y; Wk) pτ }, with pτ = inf{p : h(p) τ }. In particular, for the widely used one-proportion z-test for watermark detection, such function exists. Theorem 1 shows that detection can be expressed in terms of the empirical green rate ˆp(y; Wk) with threshold pτ . Using this, we now demonstrate that suppressing the average green token probability across the sequence yields exponential decay in the detection probability (Theorem 2)."
        },
        {
            "title": "Preprint",
            "content": "Algorithm 1 Pseudocode for Bias-Inversion Rewriting Attack Require: Watermarked text ˆy0:N 1; Language model M; Percentile [0, 1); Initial bias β0 < 0; lr > 0; Max restarts R; Max length Lmax; Window size h; threshold ρ (0, 1]. Phase 1: Construct Green Token Proxy Set (n) log PM(ˆy(n)ˆy0:n1) 1: Compute self-information (n) for each token ˆy(n) using the language model M: 2: for = 0, . . . , 1 do 3: 4: end for 5: Set percentile threshold η Percentile({I (n)}N 1 6: Define the proxy set (cid:98)G (cid:8)id(ˆy(n)) (cid:12) n=0 , q) (cid:12) (n) η, [0, 1](cid:9) Phase 2: Perform Bias-Inversion Rewriting + β 1{u (cid:98)G} for all in vocabulary 7: β β0 8: for = 1, . . . , do 9: 10: 11: Initialize empty sequence [] for = 0, . . . , Lmax 1 do Obtain logits l(t) from (y) Apply negative bias: l(t) Sample next token y(t) softmax(l(t)) Append y(t) to l(t) end for Let be the length of y. if Distinct-1-Gram-Ratio(yLh:L1) < ρ then 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: end for 24: return else end if β min(0, β + lr) Continue return Reduce the strength of bias and restart Return text Theorem 2. Let = [y(0), . . . , y(N 1)] be the attackers output and let pτ be the detection threshold. If there exists δ > 0 such that the average conditional green-token probability satisfies then 1 (cid:88) (cid:104) n=1 1{y(n) G(Wk)} (cid:12) (cid:12) (cid:12) y0:n1(cid:105) pτ δ, (cid:18) Pr(cid:2)D(y, Wk) = 1(cid:3) exp (cid:19) , δ2 1 Theorem 2 shows that if the average probability of sampling green token stays at least δ below the detector threshold pτ , then the detection probability decays exponentially in δ. In other words, even small reduction in the green-token probability, when achieved on average over the sequence, is sufficient to make the text statistically undetectable and drive the overall detection probability toward zero. Proofs of Theorems 1 and 2 are provided in Appendix A. Application to KGW watermarking. For KGW (Kirchenbauer et al., 2024a), the one-proportion z- (cid:1)(cid:14)(cid:112)p0(1 p0)/N , where p0 is the predefined green-token statistic is Z(y; Wk) = (cid:0)ˆp(y; Wk) p0 (cid:1)(cid:14)(cid:112)p0(1 p0)/N ratio and is the total number of generated tokens. Since h(p) = (cid:0)p p0 is nondecreasing, the threshold corresponds to pτ = p0 + τ (cid:112)p0(1 p0)/N . For default setups p0 = 0.5, τ = 4, and = 230, we obtain pτ 0.632. If the attack keeps E(cid:2)1{y(n) G(Wk)} y0:n1(cid:3) 0.632 δ, then by Theorem 2 the detection probability satisfies 1 Pr[D(y, Wk) = 1] exp(N δ2/2); e.g., δ = 0.1 e1.15 0.316, δ = 0.2 e4.6 0.010."
        },
        {
            "title": "4.2 BIAS-INVERSION REWRITING ATTACK",
            "content": "As established in Theorem 2, successful watermark evasion requires suppressing green token generation across the sequence. In black box setting, the adversary lacks access to the true green sets G(Wk), so we approximate them with proxy set (cid:98)G. Watermarking schemes typically embed their signal in high entropy (low probability) tokens to preserve text quality (Kirchenbauer et al., 2024a; Cheng et al., 2025; Lee et al., 2024). To identify such tokens, we use token self-information (surprisal) from public language model M: (n) = log PM(ˆy(n) ˆy0:n1). Given watermarked text ˆy = [ˆy(0), . . . , ˆy(N 1)], let η be the qth percentile of {I (n)}N 1 proxy green set is n=0 . The (cid:98)G (cid:8)id(ˆy(n)) (cid:12) (cid:12) (n) η, [0, 1](cid:9), where id() maps token to its vocabulary index. During paraphrase generation y, we add negative logit bias β < 0 to all tokens in (cid:98)G at each step n: l(n) l(n) + β 1{u (cid:98)G}. (cid:80)N This negative bias suppresses the generation of likely green tokens, which lowers the empirical green rate and thus enables evasion of detection. Since we rely on proxy green set (cid:98)G, some green tokens may be missed. However, Theorem 2 still holds as long as the average miss rate of the proxy set y(n) G(Wk) (cid:98)G y0:n1(cid:105) (cid:104) is bounded by ϵ, i.e., 1 ε and the average conditional 1{y(n) (cid:98)G} y0:n1(cid:105) (cid:80)N n=1 Pr probability of sampling from the proxy set is suppressed: 1 τ δ with p Remark. Our approach differs from the masking-and-rewriting strategy of Cheng et al. (2025), which masks high-entropy tokens and then rewrites the masked spans. In contrast, we apply negative logit bias to tokens in the proxy green set (cid:98)G at every decoding step. This consistently reduces the probability of sampling green tokens across the sequence and therefore lowers the detection probability, as established by Theorem 2. Moreover, by avoiding disruptive masking that breaks context, our method better preserves semantic fidelity. τ = pτ ε. Further details are provided in Appendix A.1. n=1 (cid:104) 4.2.1 MITIGATING TEXT DEGENERATION WITH ADAPTIVE BIAS We observe that applying strong negative bias β can occasionally cause text degeneration, where the model repeatedly generates the same phrase (qualitative examples are provided in Appendix F.2). This arises from distorted token distribution created by suppressing specific tokens and cannot be resolved by simply regenerating text, since the underlying distribution remains unchanged. To address this, our attack adaptively adjusts β by detecting degeneration through monitoring the diversity of the last generated tokens. Specifically, we compute the distinct 1-gram ratio within this window, yM h:M 1, and classify the text as degenerated if the ratio falls below predefined threshold ρ. The algorithms and details of degeneration detection are provided in Appendix B. Upon detection, the magnitude of negative bias is reduced for the next-generation attempt: β min(0, β + lr), where lr > 0 is small step size. This adaptive adjustment allows the attack to begin with strong bias for effective watermark removal and then gracefully reduce its strength only when necessary to prevent semantic degradation. The full procedure of our method is presented in Algorithm 1. To initialize the logit bias β, we generate 50 paraphrases from the C4 dataset (Raffel et al., 2020) and gradually decrease β (for example, from 1 down to 12) until degeneration appears in at least one of the 50 outputs. We then use this value as the initial logit bias β0, which strengthens the attack while minimizing the risk of degeneration. Since degeneration is rare (2.4% over 500 samples, with an average of only 1.03 iterations per text with lr = 0.125), the computational overhead of the adaptive process is negligible."
        },
        {
            "title": "5.1 SETUP",
            "content": "Dataset. Following prior work (Kirchenbauer et al., 2024a; Liu et al., 2023a; Zhao et al., 2024; Cheng et al., 2025; Lu et al., 2024), we use the C4 dataset to generate watermarked text. We take the first 500 test samples as prompts and generate 230 tokens for each. Watermark algorithms. We evaluate seven recent watermarking methods: KGW (Kirchenbauer et al., 2024a), Unigram (Zhao et al., 2024), UPV (Liu et al., 2023a), EWD (Lu et al., 2024), DIP (Wu et al., 2023), SIR (Liu et al., 2024), and EXP (Aaronson & Kirchner, 2022). For each method, we adopt the default or recommended hyperparameters from the original studies (Pan et al., 2024; Cheng et al., 2025). For KGW, we use single left hash on only the immediately preceding token to form the green and red token lists, since fewer preceding tokens improve robustness against watermark evasion attacks. Baselines and language models. We compare against three query-free attack baselines: Vanilla (paraphrasing with language model), DIPPER (Krishna et al., 2023) (a trained paraphrasing expert), and SIRA (Cheng et al., 2025) (masking and rewriting strategy). For DIPPER-1, we set lexical diversity to 60 without order diversity, and for DIPPER-2, we add order diversity of 40 to increase paraphrasing strength. We evaluate Vanilla, SIRA, and our method on Llama-3.1-8B, Llama-3.1-70B, and GPT-4o-mini with top-p sampling at 0.95 and temperature 0.7. The paraphrasing prompt is provided in Appendix D. Since GPT-4o-mini does not expose logits for computing self-information, we use Llama3.2-3B as an auxiliary model to estimate high self-information tokens. These tokens are first converted into text using the Llama-3.2-3B tokenizer and then re-tokenized with the GPT tokenizer for use in SIRA and our method. Negative logit bias is then applied through the GPT API, which supports token-level logit biasing. For SIRA, we set the masking threshold to 0.3, as recommended by Cheng et al. (2025), and apply it to high-entropy tokens across all models. For our method, we use percentile threshold of = 0.5 to construct the proxy green token set. The initial negative logit bias is β0 = 4 for Llama-3.1-8BInstruct and Llama-3.1-70B-Instruct (Dubey et al., 2023), and β0 = 11 for GPT-4o-mini (OpenAI, 2024b), following the initialization strategy in Section 4.2.1, with lr = 0.125. 5.1.1 EVALUATION METRICS We evaluate attacks in terms of both attack efficacy and text quality. Attack efficacy. Our primary measure is the Attack Success Rate (ASR), the proportion of attacked texts for watermarked text misclassified as non-watermarked. Additionally, to mitigate the effect of detector threshold choices, following (Zhao et al., 2024; Liu et al., 2024; Cheng et al., 2025), we build test set of 500 attacked texts and 500 human-written texts, and adjust the detectors zthreshold to match the False Positive Rate (FPR) at 1% and 10%. At these FPRs, we report the corresponding True Positive Rate (TPR) and F1-score. Text quality. We assess text quality using five metrics that cover semantic fidelity, paraphrasing strength, and fluency. To evaluate semantic preservation, we employ three measures. First, we use an LLM judgement score (Zheng et al., 2023; Fu et al., 2023; Liu et al., 2023b) from GPT-4o-202408-06 (OpenAI, 2024a), which scores meaning preservation on 1-to-5 scale: score of 5 indicates perfect fidelity, 4 allows for minor nuances without factual changes, and 3 reflects that only the main idea is preserved while important details or relations are altered (see Appendix for prompt details). We also compute an NLI score using nli-deberta-v3-large (He et al., 2020) to assess logical consistency between the original and attacked texts by evaluating mutual entailment. In addition, we report an S-BERT score (Reimers & Gurevych, 2019), following (Cheng et al., 2025), which is based on the cosine similarity between sentence embeddings of the two texts. To quantify the degree of paraphrasing and assess text naturalness, we use two additional metrics. Paraphrasing strength is measured with the Self-BLEU score (Zhu et al., 2018), which computes the BLEU score (Papineni et al., 2002) of each attacked text against its corresponding watermarked reference. This measures the overlap between the two texts, where lower score indicates less"
        },
        {
            "title": "Preprint",
            "content": "Table 1: Comparison of watermarking robustness under different attack methods. Our method, BIRA, achieves the highest attack success rate across all baselines. Watermark Attack Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg ASR 88.8% 87.4% 60.2% 93.8% 97.2% 98.8% 98.0% 98.0% 73.4% 67.0% 30.2% 61.2% 71.8% 95.0% 87.6% 85.2% 73.4% 65.0% 46.8% 80.6% 85.4% 87.6% 85.0% 84.8% 92.6% 89.4% 58.8% 92.8% 96.6% 99.8% 99.2% 97.2% 99.8% 54.0% 80.6% 98.8% 42.8% 70.4% 95.8% 23.6% 31.8% 99.4% 55.6% 90.8% 99.2% 70.4% 97.2% 99.6% 72.8% 95.2% 99.6% 60.6% 88.6% 99.6% 57.6% 94.8% 80.4% 74.4% 49.6% 82.0% 88.3% 92.7% 88.4% 88.2% BIRA (Llama-3.1-8B, ours) BIRA (Llama-3.1-70B, ours) BIRA (GPT-4o-mini, ours) 99.8% 99.4% 99.8% 100.0% 100.0% 99.6% 99.8% 99.8% 99.4% 99.0% 99.6% 99.8% 99.6% 98.8% 98.0% 99.2% 99.4% 100.0% 100.0% 99.8% 99.8% 99.4% 98.2% 99.5% Figure 2: Comparison of detection performance with the adjusted threshold across watermarking algorithms, mitigating the effect of default threshold. We show the best F1 score () and TPR () at FPR of 1% and 10%. BIRA consistently achieves lower F1 and TPR than all baselines, indicating greater difficulty for detectors in distinguishing attacked text from human-written text. Exact values are provided in Appendix G.1. Figure 3: Comparison of text quality across different attacks for various watermarking methods, evaluated by LLM judgment score (), Self-BLEU score (), and Perplexity (). Our method preserves semantic fidelity to the original text compared to other attack baselines (DIPPER and SIRA) while providing stronger paraphrasing, as reflected in lower Self-BLEU scores. Additional results for NLI score () and S-BERT score () are provided in Figure 6 and exact values are detailed in Appendix G.2. lexical overlap and therefore stronger paraphrasing. Text naturalness is evaluated using Perplexity (PPL) (Jelinek et al., 1977), where lower PPL corresponds to more probable and natural text. 5.2 EXPERIMENTAL RESULTS Attack efficacy. Table 1 reports the attack success rates of different watermark removal methods across multiple watermarking algorithms. Our method consistently outperforms all baselines across different language models, with especially strong gains against SIR, the most robust existing watermarking algorithm. Notably, on GPT-4o-mini, vanilla paraphrasing attains an average ASR of 49.6, while BIRA reaches 99.5, demonstrating substantial gain in watermark evasion. To further evaluate effectiveness and reduce the influence of fixed z-threshold, we follow prior work (Zhao et al., 2024; Liu et al., 2024; Cheng et al., 2025) by setting FPR to 1% and 10%, and report the"
        },
        {
            "title": "Preprint",
            "content": "Watermarked Text by KGW (z-score: 6.03) Graciousness might not seem like the most important thing in defining the success of nation, but it is paramount for Mr Lim Siong. By the age of 45, he already runs fortune of close to $1bn. His wife, Ms Rachel Jia Xu (above), started chain of popular supermarkets, which now has 13 outlets and employs more than 5,000 people. Not by sheer talent alone, but because of strong sense of character that has made him standout amongst the elite among Singapores business leaders. Attacked Text by BIRA (z-score: 0.83) Graciousness may appear insignificant in determining what makes country successful; however, it holds great importance for Mr. Lim Siong. At just 45 years old, he manages nearly $1 billion in wealth. His spouse, Ms. Rachel Jia Xu, has established an acclaimed supermarket franchise with currently 13 locations employing over 5,000 individuals. His prominence in Singapores business community is attributed not solely to his exceptional skills but also his remarkable personal qualities. Figure 4: Qualitative comparison of KGW-watermarked text and the same passage after BIRA attack with Llama-3.1-8B. The attack paraphrases to suppress green tokens while preserving meaning, lowering the score from 6.03 to 0.83 and evading detection at threshold of 4. More examples with longer sentences and other watermarking schemes appear in Appendix F.1. Table 2: Effect of logit bias β and percentile on attack performance Logit Bias (β) 0.0 -1.0 -2.0 -3.0 -4. -5.0 -6.0 -7.0 -8.0 -9.0 ASR () LLM Judgment () Self-BLEU () Perplexity () Iteration () 54.2% 74.4% 88.2% 97.2% 99.6% 99.4% 99.6% 99.8% 99.8% 99.6% 2.94 4.76 0.01 0.25 14.10 9.17 3.36 1.00 4.24 0.07 10.09 1.03 3.19 0.02 13.42 1.83 3.79 0.04 11.23 1.20 3.05 0.01 14.03 2.54 3.45 0.03 12.56 1. 4.69 0.20 8.99 1.00 4.62 0.15 9.07 1.00 4.48 0.11 9.47 1.01 Percentile (q) 0.0 0. 0.2 0.3 0.4 0.5 0.6 0. 0.8 0.9 ASR () LLM Judgment () Self-BLEU () Perplexity () Iteration () 99.0% 99.6% 99.2% 98.6% 99.6% 99.6% 98.4% 96.4% 89.0% 77.2% 4.60 4.15 0.18 0.06 8.93 12.16 1.00 1.06 4.15 0.06 11.72 1.05 4.20 0.06 12.01 1. 4.16 0.06 11.37 1.06 4.18 0.06 10.68 1.05 4.24 0.07 10.09 1.03 4.48 0.13 8.95 1.01 4.35 0.10 9.30 1.02 4.26 0.08 9.62 1. detectors TPR on attacked text using the corresponding adjusted thresholds. We additionally provide the best F1 score each watermarking algorithm can achieve under different attacks. lower TPR at given FPR indicates that the detector has greater difficulty distinguishing attacked texts from human-written texts. As shown in Figure 2, our method consistently lies below all baselines, demonstrating its superior attack effectiveness. Text quality. We evaluate the quality of the attacked text using five metrics. As shown in Figure 3, vanilla paraphrasing attains the highest LLM judgment score because its paraphrasing ability is weak and largely preserves the original structure, which leads to low ASR. This is consistent with its highest Self-BLEU score, indicating strong overlap with the source text. In contrast, our method achieves significantly higher LLM judgment score than stronger baselines such as DIPPER and SIRA, demonstrating better semantic preservation. At the same time, it yields much lower SelfBLEU score, showing that it generates more diverse paraphrases and relies less on reusing words from the watermarked text. For perplexity, our method remains comparable to other approaches, with only slight increase when GPT-4o-mini is used. We attribute this to GPT-4o-mini sometimes producing stiff text that, while grammatically correct and semantically accurate, employs unconventional vocabulary and thus sounds less natural. Qualitative examples illustrating this are provided in Appendix F.3. For NLI and S-BERT scores (Figure 6), the results align with the LLM judgment score and confirm our methods effectiveness. 5.3 ABLATION STUDIES AND ANALYSIS We conduct ablation studies on the logit bias β and the percentile used in our attack, and evaluate the effectiveness of self-informationguided token selection for applying negative logit bias. We also analyze the computational efficiency of different attack methods. Unless otherwise specified, all"
        },
        {
            "title": "Preprint",
            "content": "experiments are performed on the Llama-3.1-8B-Instruct model with the SIR watermarking method, following the setup in Section 5.1. Effect of logit bias β and percentile q. We vary β from 0.0 to 9.0 with the percentile fixed at = 0.5. Table 2 shows that without logit bias (β = 0.0, equivalent to vanilla paraphrasing), the ASR is low, but it increases as the absolute value of β grows. This is consistent with Theorem 2: increasing the negative bias further suppresses green token sampling and thus lowers the overall probability of detection. However, larger negative values of β gradually degrade text quality and require more iterations, as excessive bias restricts the token distribution too strongly. Next, we vary from 0.0 to 0.9 with β = 4.0. Table 2 shows that when = 0 (bias applied to all tokens in the watermarked text), ASR is moderately high, but text quality degrades slightly, and the number of iterations increases because many tokens are suppressed. As grows, the proxy set contains fewer tokens and fewer are suppressed, so ASR drops since the watermark signal is not effectively removed, while text quality improves as the token distribution is less constrained. Watermark SIR (τ = 0.2) Unigram (τ = 4.0) Vanilla DIPPER-1 DIPPER-2 SIRA BIRA 0.19 0.10 0.18 0.11 0.14 0.11 0.14 0.12 0.06 0.09 3.04 1.52 3.63 1.65 3.10 1.63 1.63 1.38 0.34 1.61 Table 3: z-score comparison of attacks on SIR and Unigram watermarking scheme. Effectiveness of statistical signal suppression. Table 3 presents z-scores and corresponding detection thresholds τ for different attacks under the SIR and Unigram watermarking schemes. Our method achieves lower z-scores than all baselines, making detection substantially more difficult. lower z-score indicates that the attacked text is harder to distinguish from human-written text. Additional results for other watermarking schemes are presented in Table 5, where our method consistently outperforms all baselines. Impact of token selection. To evaluate the effectiveness of self-informationguided token selection when applying logit bias, we vary the selection ratio from 0.1 to 0.9, choosing the highest self-information tokens at each ratio and comparing against random selection. As shown in Figure 5, applying negative logit bias to self-information-guided tokens consistently outperforms random selection, demonstrating its effectiveness in constructing proxy green set (cid:98)G. Computational efficiency. To assess computational overhead, we measured the average execution time per attack over 500 samples using the KGW watermark under the setup in Section 5.1. All experiments were conducted on single A6000 GPU, except for DIPPER built on T5-XXL (Raffel et al., 2020), which required two GPUs. As shown in Table 4, Vanilla is the most efficient baseline since it introduces no additional overhead. BIRA is the next most efficient, though it exhibits higher variance. This is caused by its adaptive bias procedure, which is designed to prevent text degeneration. This procedure was triggered in only 2.6% of samples, and those rare cases had much longer average runtime of 66.81 seconds because repeated generation continued until the maximum length is reached. By contrast, the vast majority of samples (97.4%) completed in single iteration with an average of 6.38 seconds, accounting for BIRAs overall efficiency despite the variance introduced by few outliers. Figure 5: Comparison of ASR for selfinformationguided token selection and random token selection. Table 4: Average execution time (in seconds) for different attacks. 5.52 2.82 9.73 2.24 8.57 2.03 7.95 9.01 Vanilla DIPPER SIRA BIRA Execution Time Attack"
        },
        {
            "title": "6 CONCLUSION",
            "content": "This paper exposes fundamental vulnerabilities in LLM watermarking through theoretical analysis, from which we developed the Bias-Inversion Rewriting Attack (BIRA). Our attack erases the watermarks statistical signal by applying negative logit bias to tokens identified using self-information. We empirically demonstrate that BIRA consistently evades detection from recent watermarking schemes while preserving the original texts meaning. Our work reveals significant limitations in current methods, highlighting the need for more rigorous evaluation of watermarking and motivating the defenses that remain robust against sophisticated paraphrasing attacks."
        },
        {
            "title": "REFERENCES",
            "content": "Scott Aaronson and H. Kirchner. Watermarking gpt outputs. https://www.scottaaronson. com/talks/watermark.ppt, 2022. Diane Bartz and Krystal Hu. Openai, google, others pledge to watermark ai content for safety, white house says. Reuters, July 21 2023. URL https://www.reuters.com/technology/ openai-google-others-pledge-watermark-ai-content-safety-white-house-2023-07-21/. Ruibo Chen, Yihan Wu, Junfeng Guo, and Heng Huang. De-mark: Watermark removal in large language models. arXiv preprint arXiv:2410.13808, 2024. Yixin Cheng, Hongcheng Guo, Yangming Li, and Leonid Sigal. Revealing weaknesses in text watermarking through self-information rewrite attacks. arXiv preprint arXiv:2505.05190, 2025. Miranda Christ, Sam Gunn, and Or Zamir. Undetectable watermarks for language models. In The Thirty Seventh Annual Conference on Learning Theory, pp. 11251139. PMLR, 2024. A. Dubey, A. Jauhri, A. Pandey, et al. The llama 3 herd of models. arXiv, 2023. URL https: //arxiv.org/abs/2407.21783. Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. Gptscore: Evaluate as you desire. arXiv preprint arXiv:2302.04166, 2023. Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with disentangled attention. arXiv preprint arXiv:2006.03654, 2020. Zhengmian Hu, Lichang Chen, Xidong Wu, Yihan Wu, Hongyang Zhang, and Heng Huang. Unbiased watermark for large language models. arXiv preprint arXiv:2310.10669, 2023. Fred Jelinek, Robert Mercer, Lalit Bahl, and James Baker. Perplexitya measure of the difficulty of speech recognition tasks. The Journal of the Acoustical Society of America, 62(S1): S63S63, 1977. Nikola Jovanovic, Robin Staab, and Martin Vechev. Watermark stealing in large language models. arXiv preprint arXiv:2402.19361, 2024. Firuz Kamalov, David Santandreu Calonge, and Ikhlaas Gurrib. New era of artificial intelligence in education: Towards sustainable multifaceted revolution. Sustainability, 15(16):12451, 2023. John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. In International Conference on Machine Learning, pp. watermark for large language models. 1706117084. ICML, 2024a. John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. On the reliability of watermarks for large language models. ICLR, 2024b. Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, and Mohit Iyyer. Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense. Advances in Neural Information Processing Systems, 36:2746927500, 2023. Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, and Gunhee Kim. Who wrote this code? watermarking for code generation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 48904911, 2024. Aiwei Liu, Leyi Pan, Xuming Hu, Shuang Li, Lijie Wen, Irwin King, and Philip Yu. An unforgeable publicly verifiable watermark for large language models. arXiv preprint arXiv:2307.16230, 2023a. Aiwei Liu, Leyi Pan, Xuming Hu, Shiao Meng, and Lijie Wen. semantic invariant robust watermark for large language models. ICLR 2024, 2024."
        },
        {
            "title": "Preprint",
            "content": "Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. G-eval: Nlg evaluation using gpt-4 with better human alignment. arXiv preprint arXiv:2303.16634, 2023b. Yijian Lu, Aiwei Liu, Dianzhi Yu, Jingjing Li, and Irwin King. An entropy-based text watermarking detection method. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1172411735, 2024. Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. Large language models: survey. arXiv preprint arXiv:2402.06196, 2024. Scott Monteith, Tasha Glenn, John Geddes, Peter Whybrow, Eric Achtyes, and Michael Bauer. Artificial intelligence and increasing misinformation. The British Journal of Psychiatry, 224(2): 3335, 2024. OpenAI. Gpt-4o: Multimodal and multilingual capabilities. OpenAI website, 2024a. URL https: //openai.com/index/hello-gpt-4o. Accessed: 2025-09-12. OpenAI. Gpt-4o mini: Advancing cost-efficient intelligence. OpenAI Platform Documentation, 2024b. URL https://platform.openai.com/docs/models/gpt-4o-mini. Accessed: 2025-09-12. Leyi Pan, Aiwei Liu, Zhiwei He, Zitian Gao, Xuandong Zhao, Yijian Lu, Binglin Zhou, Shuliang Liu, Xuming Hu, Lijie Wen, et al. Markllm: An open-source toolkit for llm watermarking. arXiv preprint arXiv:2405.10051, 2024. Eleftheria Papageorgiou, Christos Chronis, Iraklis Varlamis, and Yassine Himeur. survey on the use of large language models (llms) in fake news. Future Internet, 16(8):298, 2024. Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311318, 2002. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. Exploring the limits of transfer learning with unified text-to-text transformer. Journal of machine learning research, 21(140):167, 2020. Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bertnetworks. arXiv preprint arXiv:1908.10084, 2019. Chris Stokel-Walker. Ai bot chatgpt writes smart essays-should professors worry? Nature, 2022. Tong. of Anna ing //www.reuters.com/technology/artificial-intelligence/ openai-supports-california-ai-bill-requiring-watermarking-synthetic-content-2024-08-26/. watermarkURL https: Reuters, August Openai content. california requiring synthetic supports 2024. bill 26 ai Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345, 2024a. Xiao Wang, Tianze Chen, Xianjun Yang, Qi Zhang, Xun Zhao, and Dahua Lin. Unveiling the misuse potential of base large language models via in-context learning. arXiv preprint arXiv:2404.10552, 2024b. Qilong Wu and Varun Chandrasekaran. Bypassing llm watermarks with color-aware substitutions. arXiv preprint arXiv:2403.14719, 2024. Yihan Wu, Zhengmian Hu, Junfeng Guo, Hongyang Zhang, and Heng Huang. resilient and accessible distribution-preserving watermark for large language models. arXiv preprint arXiv:2310.07710, 2023. Xuandong Zhao, Prabhanjan Ananth, Lei Li, and Yu-Xiang Wang. Provable robust watermarking for ai-generated text. ICLR, 2024."
        },
        {
            "title": "Preprint",
            "content": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in neural information processing systems, 36:4659546623, 2023. Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu. Texygen: In The 41st international ACM SIGIR benchmarking platform for text generation models. conference on research & development in information retrieval, pp. 10971100, 2018."
        },
        {
            "title": "A PROOF OF THEOREM",
            "content": "Proof of Theorem 1. Fix N. By assumption there exists nondecreasing : [0, 1] with Z(y; Wk) = h(cid:0)ˆp(y; Wk)(cid:1), ˆp(y; Wk) ="
        },
        {
            "title": "1\nN",
            "content": "N 1 (cid:88) n=0 1{yn G(Wk)}. The range of ˆp is the grid PN := {0, 1/N, . . . , 1}. Define pτ = min{ PN : h(p) τ }, taking pτ = 1 if the set is empty and pτ = 0 if h(p) τ for all PN . Since is nondecreasing, for any p, PN with pτ > we have h(p) h(pτ ) τ while h(p) < τ . Therefore, for any y, D(y, Wk) = 1{Z(y; Wk) τ } = 1{h(ˆp(y; Wk)) τ } = 1{ˆp(y; Wk) pτ }. .Proof of Theorem 2. By Theorem 1, for fixed there exists pτ with D(y, Wk) = 1{ˆp(y; Wk) pτ }. Define the indicator variables and their conditional expectations: Xn := 1{y(n) G(Wk)}, pn := E[Xn Fn1], where Fn := σ(y0:n1) is the natural filtration. The premise of the theorem is that the average conditional probability pN := 1 n=1 pn satisfies pN pτ δ. (cid:80)N Define the martingale difference sequence and the martingale Dn := Xn pn, MN := (cid:88) n= Dn. This is martingale difference sequence since E[Dn Fn1] = E[Xn Fn1] pn = pn pn = 0. Moreover, since Xn {0, 1} and pn [0, 1], the increments are bounded in the interval Dn [1, 1]. We can relate the empirical green rate ˆp(y; Wk) to the martingale MN : ˆp(y; Wk) = 1 (cid:88) n=1 Xn = 1 (cid:88) (Dn + pn) = n= MN + pN . Thus, the detection event occurs iff: ˆp(y; Wk) pτ MN + pN pτ MN (pτ pN ). Using the premise that pN pτ δ, we have pτ pN δ. Therefore, Pr(ˆp(y; Wk) pτ ) Pr(MN δ) . By the AzumaHoeffding inequality, for increments Dn bounded in an interval of range 1 (1) = 2, Pr(MN δ) exp which yields the claim. (cid:32) (cid:33) 2(N δ)2 (cid:80)N n=1 22 (cid:18) (cid:19) 2N 2δ2 4N (cid:18) = exp (cid:19) , δ2 = exp"
        },
        {
            "title": "Preprint",
            "content": "A.1 ROBUSTNESS TO PROXY GREEN SETS In the black-box setting, the adversary does not have access to the true green sets G(Wk), so we use proxy (cid:98)G that may not contain all green tokens. The guarantee of Theorem 2 still holds if the following two conditions are met. Average miss rate bound. The average probability that sampled token is true green token not included in the proxy is at most ε:"
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) n=1 (cid:16) y(n) G(Wk) (cid:98)G Pr (cid:12) (cid:12) (cid:12) y0:n1(cid:17) ε. Average proxy suppression. The attack suppresses tokens from the proxy on average, such that"
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) (cid:104) n=1 1{y(n) (cid:98)G} (cid:12) (cid:12) (cid:12) y0:n1(cid:105) τ δ for some δ > 0, where τ := pτ ε. Under these conditions, the conclusion of Theorem 2 still holds. This follows by showing that its premise is satisfied. Let pN be the average conditional green probability: 1{y(n) G(Wk)} (cid:12) (cid:12) (cid:12) y0:n1(cid:105) pN = 1 = 1 (cid:88) (cid:104) n=1 (cid:88) (cid:104) n=1 τ δ) + ε (p = (pτ ε δ) + ε = pτ δ. 1{y(n) (cid:98)G} (cid:12) (cid:12) (cid:12) y0:n1(cid:105) + 1 (cid:88) (cid:104) n=1 1{y(n) G(Wk) (cid:98)G} (cid:12) (cid:12) (cid:12) y0:n1(cid:105) This satisfies the premise of Theorem 2, so the result holds."
        },
        {
            "title": "B DETAILS OF THE TEXT DEGENERATION DETECTION FUNCTION",
            "content": "Algorithm 2 Text Degeneration Detection Require: Paraphrased text = [y(0), . . . , y(L1)]; collapse window N; collapse threshold ρ (0, 1]. (cid:12) (cid:9) return False 1: min(h, L) 2: [y(Lm), . . . , y(L1)] 3: (cid:8)id(u) (cid:12) 4: if = 0 then 5: 6: end if 7: /W 8: if < ρ then 9: 10: else 11: 12: end if return False return True last tokens set of distinct token ids distinct one gram ratio in the window degeneration detected For paraphrasing, we set the maximum generation length of the LLM to 1,500 tokens. We observed that paraphrased text is typically generated normally when no degeneration occurs. However, when degeneration does occur, the text begins normally but then suddenly repeats the same phrase until the maximum token limit is reached, as shown in Appendix F.2. In the degenerated samples we examined, both the starting point of the repetition and the length of the repeated phrase varied. To ensure sufficient detection window, we chose large maximum generation length and window"
        },
        {
            "title": "Preprint",
            "content": "size of = 450 tokens. We set the threshold ρ = 0.25, meaning that if more than 75% of the tokens within the detection window are duplicates (which is not normal for natural text), the text is considered largely repetitive and redundant. PROMPT FOR SEMANTIC JUDGMENT (GPT) LLM-as-a-Judge Prompt You are an impartial evaluator. You will receive: 1) ORIGINAL: the source text 2) PARAPHRASE: rewritten version of the original Your task: Judge how well the PARAPHRASE preserves the ORIGINALs semantic meaning. Ignore style, tone, formality, phrasing, length, and order of information. What to check (do not output your analysis): - Core propositions and claims are preserved. - Entities, numbers, dates, units, polarity/negation, modality, and causal/temporal relations match. - No contradictions; no key facts dropped or altered. - Added details that do not change meaning should not be penalized. Rating scale (15): [5] Complete preservation bidirectional entailment; no contradictions; all key facts preserved. [4] High preservation meaning preserved with at most minor nuances/omissions; no factual changes. [3] Moderate main idea preserved, but some important details/relations are missing or changed. [2] Low only basic topic overlaps; several important changes/omissions or contradictions. [1] Minimal/none meaning is fundamentally different or unrelated. Special cases: - If specificity differs, score based on whether the essential meaning is preserved. - Any mismatch in numbers, named entities, dates, or negation is serious error. Output Format: - Provide only number in square brackets. No explanations, additional text, or commentary. - Correct format: [3] - Incorrect format: The score is [3] rate this [3] [3] - good preservation User Prompt: Heres the ORIGINAL: [Watermarked text] Heres the PARAPHRASE: [Attack text]"
        },
        {
            "title": "Paraphrasing Prompt",
            "content": "You are an expert paraphrasing system designed to rewrite text while maintaining complete semantic fidelity. Follow these precise guidelines: CORE REQUIREMENTS: - Preserve 100% of the original meaning and information content - Maintain identical factual accuracy, tone, and intent - Keep the same level of formality/informality as the source - Retain all specific details, numbers, names, and technical terms exactly as provided TRANSFORMATION RULES: - Use synonyms and alternative phrasings where semantically equivalent - Vary sentence structure and length for natural flow - Reorganize clauses and phrases without altering logical relationships - Maintain coherence and readability in the target language - Ensure each transformed sentence conveys the same scope and specificity as the original STRICT PROHIBITIONS: - Do not add interpretations, assumptions, elaborations, or external knowledge - Do not introduce information not explicitly present in the original text - Do not amplify, exaggerate, or minimize any claims or statements - Do not omit any information present in the original - Do not change the perspective, viewpoint, or stance - Do not include explanations, commentary, or meta-text - Do not expand on implicit meanings or draw inferences - Do not add contextual information or background details CONTENT BOUNDARIES: - Work only with information explicitly stated in the source text - If the original is vague or general, keep the paraphrase equally vague or general - If the original is specific, maintain that exact level of specificity - Do not fill in gaps or provide additional details, even if they seem logical OUTPUT FORMAT: - Provide only the paraphrased text - Match the original format (paragraphs, lists, etc.) - No prefacing remarks, explanations, or additional content QUALITY CHECK: Before outputting, verify that: 1) Someone reading only your paraphrase would understand exactly the same information as someone reading the original text 2) No new information has been introduced 3) No original information has been lost or altered 4) The scope and specificity remain identical z-SCORE COMPARISON OF ATTACKS ON DIFFERENT WATERMARKING SCHEMES Table 5: z-score comparison of attacks on different watermarking methods. Watermark KGWUnigram UPV EWD DIP SIR Vanilla DIPPER-1 DIPPER-2 SIRA BIRA 3.04 1.52 2.40 1.32 3.63 1.65 2.09 1.23 3.10 1.63 1.66 1.19 1.05 1.23 1.63 1.38 0.93 1.11 0.34 1.61 3.24 1.23 3.33 1.28 2.97 1.65 2.19 1.21 0.94 1.22 0.19 0.10 0.16 0.52 2.08 1.32 0.18 0.11 0.17 0.53 2.37 1.18 0.14 0.11 0.06 0.63 1.81 1.23 0.83 1.13 0.14 0.12 0.02 0.52 0.43 1.07 0.03 0.51 0.06 0."
        },
        {
            "title": "F QUALITATIVE EXAMPLES",
            "content": "F.1 EXAMPLES OF WATERMARKED TEXTS AND ATTACKED TEXTS Watermarked Text By KGW (z-score: 10.33) Was it surprise to you that you were given the arts and culture position? No, there is no surprise when you are cadre. And it was great honor. enjoy serving my country in that capacity. Its what really love. If anything, it was good to hear you say no once more; given that it was the first official rejection in your official career. Did anything take priority for you that the position didnt? Yes. One of those in-laws wanted to stay with little too much priority. But Im glad to know you asked. certainly wasnt giving up on helping my country in any capacity, thats not me at all. just didnt want to go at it one more time. Once you go you will know how to say no. had already been told in 2008 to hold off on being an officer until got my undergraduate degree, that was one such instance. Theres your answer. Ha, that is great. And good luck, Im sure youll do something great. Attacked Text by BIRA (z-score: 2.60) Was receiving the arts and culture position unexpected for you? Not at all, since am part of the cadres. It was actually huge honor. truly love serving my country in this role. Given that this was your first formal rejection, was glad to see you decline. Was there something specific that took precedence over this opportunity? One thing did - my desire to spend time with my in-laws took higher priority. appreciate you asking. Please know am still committed to contributing to my countrys efforts. simply chose not to pursue this particular path. Saying no becomes easier with time. For example, was advised back in 2008 to delay becoming an officer until finished my undergrad studies. Thats excellent. wish you all the best and am confident youll achieve great things. Watermarked Text by SIR (z-score: 0.57) MIDDLETOWN , NJ - The Middletown Township Public Library and the Township of Middletown are pleased to announce the 2014 Fall Book & Family Fun Series Fall Book Where The Crawdads Sing by Delia Owens Sometime in late November Club Pick: or early December , library volunteers will be coming to your neighborhood with book bags and taking you to see and talk with some of our favorite children authors , including Ann Robbins, Diane Trela , Mary Pope Osborne , Beverly Cleary, Eric Carle , fall , your free events ! Chris Van Allsburg and more ! This friendly neighborhood library will offer Saturday , November 29 from 10 to 11 am join us for cookies , two fun , coffee and reading of Where The Kids Play . Meet author and illustrator Ann Robbins and hear her include Miss those who would prefer Mabel and two other kitty mascots named Fat and Happy . reading to eating , we will offer reading from our previous fall book club favorite , Where The Bats Don read from her new book , where her latest creations For Attacked Text by BIRA (z-score: 0.11) - Middletown Township Public Library along with the Township of MIDDLETOWN , NJ the 2014 Fall Book & Family Fun Middletown is excited to announce the selection for late November or Series : Where the Crawdads Sing by Delia Owens . early December , volunteer librarians will visit neighborhoods equipped with book bags for engaging discussions featuring several beloved children authors such as Ann . Robbins , Diane Trela , Mary Pope Osborne, Beverly Cleary , Eric Carle , Chris Van Allsburg among On this autumn . library will host pair of enjoyable free events others ! Your Saturday , November 29th between 10 AM and 11 AM , come enjoy refreshments In either local like cookies and coffee while listening to presentation of Where the Kids Play . Authorillustrator Ann . Robbins will be present introduces characters like Miss Mabel along with couple of Fat and Happy . feature read - aloud of the Bats Don ... for live reading of her new work that feline companions known as focus on literature than snacks , session will also Where last season popular choice for the autumn book club : If you rather"
        },
        {
            "title": "Preprint",
            "content": "F.2 EXAMPLES OF TEXT DEGENERATION Example1 In highly anticipated matchup between two exceptional pitchers, Johan Santana (64, 3.16 ERA) faced off against Curt Schilling (92, 3.81 ERA) contest where Schilling had previously earned 2004 Cy Young Award victory over runner-up performance by Santana. Schilling reflected on their encounter by stating, knew right away he had what we needed. He believed single error would be enough for his team to secure win. For eight impressive innings, Santana demonstrated remarkable prowess by racking up an impressive total of 13 strikeouts figure only surpassed by left-handed pitcher once before when Tom Seaver achieved this feat in 1967. though there were two other pitchers who had done so before him: Tom Seaver achieved this feat before this game but also notable left-handed pitcher who achieved this feat before him: Sandy Koufax achieved this feat before this game; Tom Seaver actually achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game; Tom Seaver achieved this feat before this game; Sandy Koufax achieved this feat before this game, ... Example2 Bearing testament to this self-awareness, Mikes recounting of an experience involving none other than the legendary Viv Richards, often referred to as the Original King, showcases vividly how humbled he remained, despite being on opposite sides of an intense rivalry, especially evident within the dedicated chapter devoted to their storied encounter, where Mike pens about being, to put it mildly, utterly perplexed by how Mr Richards chose to treat him, revealing Mikes profound recognition and acceptance of his own limitations on the field, particularly amidst such high-caliber competition, like facing off against one of historys greatest batsmen, who undoubtedly left an indelible mark on Mikes memory, even to this day, an experience vividly captured within those pages, offering valuable insights into Mikes candid account, one deeply rooted within genuine humility, self-awareness, an extraordinary capacity to reflect, coupled by an all-consuming passion to explore, understand, analyze, learn, grow, an essential, enduring component, now woven into Mikes legacy. cherished, loved by all, forever, truly, an inspiration to many, today, now, always, cherished, loved by all, forever, truly, an inspiration to many, today, now, always, cherished, loved by all, forever, truly, an inspiration, an icon, cherished, loved, forever, truly, an inspiration, an icon, cherished, loved, forever, truly, an inspiration, an icon, cherished, loved, cherished, loved by all, forever, truly, an inspiration to many, today, now, always, cherished, loved by all, cherished, loved by all, forever, truly, an inspiration to many, today, now, always, cherished, loved by all, cherished, loved by all, forever, truly, an inspiration to many, today, now, always, cherished, loved by all, cherished, loved by all, forever, truly, an inspiration, ..."
        },
        {
            "title": "Preprint",
            "content": "F.3 EXAMPLE OF STIFF TEXT IN GPT-4O-MINI Watermarked Text1 by KGW Harry Connollys Twenty Palaces series is one of my favorite new storylines in science fiction. After several year hiatus Harry has brought back Raynor with new twist on the concept in 20 Palaces of Niven. In this sequel to Thrive there is something even better than the original Twenty Palaces (I mean, duh) - war. The premise for this story takes the format of earlier books - the protagonist goes to visit each successive palaces of the King, and learns how to interact with inhabitants in the culture, and so on - but introduces an element of fantasy: that of humans in space that have been rendered extinct by war-based plague that ended the universe (that is, until this novel came along). This raises an interesting question - are dragons actually extinct? And if not, how do you rebuild, and on what do they rebuild? The answer isnt really that simple - but Connolly does an amazing job of laying it out. With this book, he doesnt get bogged down with what happens after the end of the end of everything? and what happens to all of humanity. Attacked Text1 by BIRA (PPL=25.0) Harry Connollys Twenty Palaces saga ranks among my favorite recent narratives within sci-fi. Following multi-year break, he has reintroduced Raynor along with fresh perspective through his work titled 20 Palaces of Niven. This continuation to Thrive offers storyline thats superior to its predecessornaturallydue to its inclusion of conflict. The narrative structure mirrors previous installments where the main character visits various royal residences while learning to engage with their cultures. However, it adds fantastical element involving humanitys extinction caused by warfare-induced pandemic which obliterated existenceuntil this tale emerged. This prompts compelling inquiryare dragons truly gone? If not, what does rebuilding entail? The solution isnt straightforward; nonetheless, Connolly excels at presenting it. He skillfully avoids getting mired down by questions like what follows when all seems lost? or what becomes of humanity? Watermarked Text2 by KGW In the summer of 1993, had one of those experiences that stay with me for the rest of my life. spent 10 weeks in China volunteering for an orphanage, in one particularly sad season of the childrens lives. And, during that time, had to walk to take pictures of the kids in their houses, because they could never leave their houses on their own to go find the photos somewhere nearby. was alone each time and walking to and from the childrens houses, could see and hear all sorts of things: the way that the children fidgeted when there were other children around, the sadness and sorrowful looks that lit up their faces. had never met any of the young children of the orphanage before went. How did these little babies get there? How did get there to hold my arms around them? And why are they sad? If they wanted, could change their situation? If any of the children had been adopted, would other parents love them as much? As walked the paths and found way from their houses into one of the... Attacked Text2 by BIRA (PPL=19.13) In the summertime of 1993, experienced something unforgettable that has remained with me throughout my life. For ten weeks, volunteered at an orphanage in China during what was especially difficult times for those kids. During this period, it was necessary for me to stroll over to capture photographs of them at their homes since none were able to leave their residences independently to seek out their images elsewhere close by. Each time was solitary as walked back and forth; along those routes, observed various thingsthe mannerisms with which the kids would squirm around others present as well as their faces illuminated by expressions filled with grief and melancholy. Prior to this experience at the orphanage, none of those small kids were familiar figures to me. What circumstances led those tiny infants here? What brought me here so as to embrace them? What is causing their unhappiness? Could their circumstances be altered if given half chance? Would adoptive parents cherish them just as much if some were taken home? As traversed those pathways leading away from their homes toward another location..."
        },
        {
            "title": "G DETAILED EXPERIMENTAL RESULTS",
            "content": "G.1 DETAILED EXPERIMENTAL RESULTS FOR DYNAMIC THRESHOLD Table 6: Best F1 Score (%) across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPERSIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP 0.863 0.895 0.955 0.84 0.81 0.727 0.783 0.781 0.723 0.723 0.751 0.9 0.912 0.969 0.918 0. 0.78 0.845 0.875 0.666 0.667 0.668 0.907 0.939 0.97 0.908 0.867 0.806 0.828 0.837 0.667 0.666 0. 0.831 0.855 0.951 0.871 0.81 0.715 0.73 0.799 0.683 0.682 0.69 0.67 0.671 0.71 0.668 0. 0.667 0.668 0.667 0.668 0.667 0.667 0.893 0.919 0.964 0.869 0.824 0.803 0.84 0.872 0.666 0.667 0. 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 Table 7: TPR under 1% FPR (%) across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP 0.47 0.566 0.842 0.376 0.226 0.126 0.224 0. 0.084 0.092 0.12 0.612 0.722 0.932 0.762 0.68 0.242 0.438 0.498 0.038 0.052 0.022 0.572 0.708 0. 0.646 0.5 0.266 0.344 0.358 0.036 0.054 0.04 0.424 0.524 0.864 0.518 0.316 0.094 0.174 0. 0.042 0.078 0.05 0.022 0.052 0.144 0.032 0.02 0.014 0.014 0.024 0.018 0.014 0.012 0.638 0.748 0. 0.614 0.424 0.438 0.552 0.574 0.012 0.042 0.024 0.006 0.0 0.006 0.008 0.004 0.012 0.004 0. 0.014 0.012 0.024 Table 8: TPR under 10% FPR (%) across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPERSIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP 0.894 0.96 0.988 0.902 0.808 0.602 0.698 0.712 0.254 0.26 0.218 0.71 0.804 0.968 0.812 0. 0.33 0.466 0.588 0.212 0.278 0.236 0.186 0.204 0.404 0.158 0.128 0.108 0.114 0.162 0.1 0.102 0. 0.882 0.928 0.974 0.832 0.728 0.7 0.766 0.824 0.114 0.18 0.112 0.042 0.002 0.008 0.026 0. 0.06 0.034 0.026 0.108 0.092 0.092 0.772 0.854 0.98 0.714 0.6 0.406 0.548 0.566 0.356 0.346 0. 0.878 0.912 0.994 0.918 0.86 0.576 0.73 0.82 0.114 0.152 0."
        },
        {
            "title": "Preprint",
            "content": "Figure 6: Comparison of text quality across different attacks for various watermarking methods, evaluated by NLI score () and S-BERT score (). Our method is comparable to or outperforms other baselines on both metrics. Following (Cheng et al., 2025), we evaluate attacks on S-BERT score. However, we observe that the S-BERT score often fails to capture factual accuracy and finegrained meaning, sometimes assigning high scores despite factual errors and low scores even when the original meaning is preserved, likely because heavily paraphrased text is less familiar to the model. G.2 DETAILED EXPERIMENTAL RESULTS OF TEXT QUALITY EVALUATION Table 9: LLM Judgement Score () across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg Score 4.774 4.906 4.986 3.398 3.076 3.356 3.708 4.418 4.212 4.524 4.722 4.728 4.914 4. 3.504 3.092 3.34 3.72 4.49 4.212 4.454 4.688 4.778 4.93 4.99 3.636 3.204 3.356 3.744 4. 4.306 4.528 4.736 4.786 4.852 4.984 3.464 3.034 3.348 3.724 4.488 4.234 4.484 4.728 4.776 4.918 4. 3.446 3.016 3.364 3.72 4.506 4.296 4.544 4.778 4.76 4.894 4.974 3.55 3.122 3.25 3.654 4. 4.24 4.42 4.75 4.644 4.874 4.984 3.088 2.734 3.142 3.67 4.292 4.084 4.342 4.708 4.749 4.898 4. 3.441 3.04 3.308 3.706 4.432 4.226 4.471 4.73 Table 10: Self-BLEU Score () across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg Score 0.248 0.284 0.421 0.267 0.196 0.105 0.153 0.181 0.069 0.088 0. 0.265 0.298 0.435 0.28 0.204 0.119 0.159 0.192 0.077 0.091 0.088 0.25 0.287 0.409 0.255 0. 0.107 0.155 0.173 0.066 0.08 0.075 0.224 0.268 0.414 0.233 0.176 0.102 0.142 0.16 0.067 0.082 0. 0.248 0.285 0.42 0.263 0.195 0.109 0.151 0.176 0.07 0.086 0.079 0.247 0.282 0.422 0.26 0. 0.108 0.151 0.173 0.071 0.089 0.079 0.25 0.281 0.407 0.259 0.199 0.111 0.153 0.174 0.07 0.085 0. 0.252 0.295 0.436 0.291 0.205 0.108 0.149 0.176 0.068 0.084 0."
        },
        {
            "title": "Preprint",
            "content": "Table 11: Perplexity () across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg Score 8.931 9.315 11.272 10.953 11.371 9.099 9.659 9.39 10.586 12.367 15. 8.783 9.167 11.202 10.743 10.973 9.275 9.494 9.139 10.458 11.864 15.725 7.941 8.078 9.515 9.217 9. 9.155 8.748 8.515 9.864 11.463 14.434 8.814 9.236 11.19 10.719 10.956 8.888 9.381 9.279 10.54 12.065 15. 8.375 8.564 10.224 10.506 10.886 9.218 9.361 8.906 10.33 11.585 14.711 9.163 9.427 11.481 11.199 11. 9.984 9.860 9.453 10.189 11.539 15.067 10.64 11.434 13.636 13.659 13.831 10.51 11.314 11.528 11.813 13.632 17. 8.95 9.317 11.217 10.999 11.322 9.447 9.66 9.459 10.54 12.074 15.543 Table 12: NLI Score () across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg Score 0.982 0.992 1.0 0.938 0.86 0.782 0.89 0. 0.942 0.966 0.996 0.994 0.994 1.0 0.932 0.876 0.8 0.906 0.964 0.946 0.974 0.992 0.994 0.996 1. 0.944 0.852 0.774 0.884 0.95 0.928 0.962 0.998 0.992 0.996 1.0 0.942 0.842 0.794 0.906 0. 0.932 0.982 0.996 0.988 0.996 0.998 0.934 0.892 0.802 0.904 0.96 0.95 0.986 1.0 0.99 1.0 1. 0.948 0.89 0.78 0.892 0.956 0.952 0.974 0.996 0.976 0.998 1.0 0.928 0.86 0.812 0.894 0. 0.93 0.976 0.996 0.988 0.996 1.0 0.938 0.867 0.792 0.897 0.956 0.94 0.974 0.996 Table 13: S-BERT Score () across different models and watermarking algorithms. Watermark Model Vanilla (Llama-3.1-8B) Vanilla (Llama-3.1-70B) Vanilla (GPT-4o-mini) DIPPER-1 DIPPER-2 SIRA (Llama-3.1-8B) SIRA (Llama-3.1-70B) SIRA (GPT-4o-mini) BIRA (Llama-3.1-8B) BIRA (Llama-3.1-70B) BIRA (GPT-4o-mini) KGW Unigram UPV EWD DIP SIR EXP Avg Score 0.921 0.940 0.965 0.908 0. 0.847 0.826 0.893 0.879 0.899 0.907 0.921 0.940 0.964 0.910 0.887 0.846 0.839 0.901 0.877 0.896 0. 0.920 0.944 0.965 0.916 0.883 0.841 0.833 0.897 0.876 0.898 0.906 0.918 0.937 0.963 0.911 0. 0.851 0.834 0.898 0.875 0.895 0.907 0.918 0.938 0.966 0.912 0.888 0.845 0.826 0.897 0.875 0.897 0. 0.920 0.941 0.963 0.908 0.881 0.838 0.828 0.889 0.878 0.895 0.908 0.888 0.916 0.955 0.884 0. 0.797 0.796 0.856 0.848 0.868 0.888 0.915 0.936 0.963 0.907 0.879 0.838 0.826 0.890 0.873 0.892 0."
        },
        {
            "title": "H LLM USAGE",
            "content": "In this paper, we use LLMs to assist with text refinement such as trimming text, detecting grammatical errors, and correcting them."
        }
    ],
    "affiliations": [
        "Pohang University of Science and Technology (POSTECH), South Korea"
    ]
}