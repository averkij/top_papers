{
    "paper_title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
    "authors": [
        "Wei Liu",
        "Chao Peng",
        "Pengfei Gao",
        "Aofan Liu",
        "Wei Zhang",
        "Haiyan Zhao",
        "Zhi Jin"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The issue localization task aims to identify the locations in a software repository that requires modification given a natural language issue description. This task is fundamental yet challenging in automated software engineering due to the semantic gap between issue description and source code implementation. This gap manifests as two mismatches:(1) symptom-to-cause mismatches, where descriptions do not explicitly reveal underlying root causes; (2) one-to-many mismatches, where a single issue corresponds to multiple interdependent code entities. To address these two mismatches, we propose GraphLocator, an approach that mitigates symptom-to-cause mismatches through causal structure discovering and resolves one-to-many mismatches via dynamic issue disentangling. The key artifact is the causal issue graph (CIG), in which vertices represent discovered sub-issues along with their associated code entities, and edges encode the causal dependencies between them. The workflow of GraphLocator consists of two phases: symptom vertices locating and dynamic CIG discovering; it first identifies symptom locations on the repository graph, then dynamically expands the CIG by iteratively reasoning over neighboring vertices. Experiments on three real-world datasets demonstrates the effectiveness of GraphLocator: (1) Compared with baselines, GraphLocator achieves more accurate localization with average improvements of +19.49% in function-level recall and +11.89% in precision. (2) GraphLocator outperforms baselines on both symptom-to-cause and one-to-many mismatch scenarios, achieving recall improvement of +16.44% and +19.18%, precision improvement of +7.78% and +13.23%, respectively. (3) The CIG generated by GraphLocator yields the highest relative improvement, resulting in a 28.74% increase in performance on downstream resolving task."
        },
        {
            "title": "Start",
            "content": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization WEI LIU, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University, China CHAO PENG, Bytedance, China PENGFEI GAO, Bytedance, China AOFAN LIU, School of Electronic and Computer Engineering, Peking University, China WEI ZHANG, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University, China HAIYAN ZHAO, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University, China ZHI JIN, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University, China The issue localization task aims to identify the locations in software repository that requires modification given natural language issue description. This task is fundamental yet challenging in automated software engineering due to the semantic gap between issue description and source code implementation. This gap manifests as two mismatches: (1) symptomto-cause mismatches, where descriptions do not explicitly reveal underlying root causes; (2) one-to-many mismatches, where single issue corresponds to multiple interdependent code entities. To address these two mismatches, we propose GraphLocator, an LLM-based approach that mitigates symptomto-cause mismatches through causal structure discovering and resolves one-to-many mismatches via dynamic issue disentangling. The key artifact of GraphLocator is the causal issue graph (CIG), in which vertices represent discovered sub-issues along with their associated code entities, and edges encode the causal dependencies between them. The workflow of GraphLocator consists of two phases: symptom vertices locating and dynamic CIG discovering; it first identifies symptom locations on the repository graph, then dynamically expands the CIG by iteratively reasoning over neighboring vertices, discovering new sub-issues and updating causal dependencies. Experiments on three real-world Python and Java datasets demonstrates the effectiveness of GraphLocator: (1) Compared with baselines, GraphLocator achieves more accurate localization with average improvements of +19.49% in function-level recall and +11.89% in precision with acceptable overhead. (2) GraphLocator outperforms baselines on both symptom-to-cause and one-to-many mismatch scenarios, achieving recall improvement of +16.44% and +19.18%, precision improvement of +7.78% and +13.23%, respectively. (3) The disentangled causal structure CIG generated by GraphLocator yields the highest relative improvement, resulting in 28.74% increase in performance on downstream resolving task. CCS Concepts: Software and its engineering Software defect analysis; Computing methodologies Causal reasoning and diagnostics. Additional Key Words and Phrases: Issue Localization, Repository Mining, Causal Reasoning 5 2 0 2 7 ] . [ 1 9 6 4 2 2 . 2 1 5 2 : r Corresponding authors. Authors Contact Information: Wei Liu, weiliu@stu.pku.edu.cn, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University , Beijing, China; Chao Peng, pengchao.x@bytedance. com, Bytedance, Beijing, China; Pengfei Gao, pengchao.x@bytedance.com, Bytedance, Beijing, China; Aofan Liu, af.liu@stu. pku.edu.cn, School of Electronic and Computer Engineering, Peking University, China; Wei Zhang, zhangw.sei@pku.edu.cn, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University , Beijing, China; Haiyan Zhao, zhhy.sei@pku.edu.cn, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University , Beijing, China; Zhi Jin, zhijin@pku.edu.cn, Key Lab of High Confidence Software Technologies (PKU), MoE, China, China and School of Computer Science, Peking University , Beijing, China. 1:2 Liu et al."
        },
        {
            "title": "1 Introduction\nSoftware repositories evolve continuously as developers address issues such as feature implementa-\ntion, bug fixing, and code refactoring [6, 50]; a substantial portion of developer effort is devoted to\nunderstanding and resolving these issues [2]. A critical yet costly initial step in this process is issue\nlocalization, which maps a natural language issue description to the specific code snippets that\nrequire modification [6, 45, 47, 49]. Despite its importance, automating this task is fundamentally\ndifficult; even state-of-the-art large language models (LLMs) and frameworks [39, 45, 47] fail to\nlocalize the file to be changed over half of the issues in recent benchmarks [50]. This difficulty\nprimarily originates from the semantic gap between the abstract, often ambiguous issue descriptions\nand the concrete, structured nature of code implementations.",
            "content": "To bridge the semantic gap between issue description and source code implementation, effective issue localization requires addressing two prevalent types of mismatches: symptom-to-cause mismatch and one-to-many mismatch. symptomto-cause mismatch arises when issue descriptions report observable symptoms (e.g., does not compute separability correctly shown in Fig.1 (a)) instead of the underlying root cause [6]. Localizing the root cause therefore requires tracing these implicit, multi-hop causal paths. one-to-many mismatch arises when single high-level issue (e.g., speed up the endpoint shown in Fig. 1 (b)) requires coordinated changes across multiple interdependent code entities [54]. Effective localization required to identify the full set of related elements, rather than focusing on single entry point. Fig. 1. Examples of the two mismatches in issue localization: (a) symptomto-cause mismatch, where the issue description does not directly expose the underlying root cause; and (b) one-to-many mismatch, where resolving the issue requires modifying multiple interdependent code entities. Recently, variety of issue localization approaches have been proposed; however, as illustrated in Fig.2, significant limitations remain in addressing the symptomto-cause and one-to-many mismatches. Specifically, existing methods can be largely classified into embedding-based and LLM-based approaches: (1) Embedding-based approaches (e.g., SWERank-Large [31]) encode code entities and issue descriptions into embeddings and rank by similarity. They achieve high recall by retrieving broadly related code but fail to capture causal dependencies, resulting in low localization precision [35, 40]. (2) LLM-based approaches leverage the reasoning and code understanding capabilities of LLMs, and can be further divided into procedural and agentic workflows. Procedural workflows (e.g., Agentless [45]) follow fixed hierarchical process from files to functions. While structured, they typically yield low recall in the presence of symptomto-cause and one-to-many mismatches due to fixed traversal and the inability to capture cross-hierarchy dependencies. Agentic workflows (e.g., LocAgent [6], CoSIL [11]) allow LLMs to autonomously traverse repository graphs. Although more flexible, they prioritizes superficial relevance instead of underlying causality and GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:3 Fig. 2. Performance of localization approaches in addressing symptomto-cause (i.e., symptomto-cause distance > 1) and one-to-many mismatches (i.e., more than one ground-truth function). Results are averaged over issues from SWE-bench Lite, LocBench, and Multi-SWE-bench Java using Claude-3.5. struggle to maintain coherent causal chains without explicit contextual guidance [19, 41], thus limiting their effectiveness in resolving symptom-to-cause and one-to-many mismatches. To address these limitations, we propose GraphLocator, an LLM-based approach that addresses symptomtocause mismatches through causal structure discovering and resolves one-to-many mismatches via dynamic issue disentangling. Both of these capabilities are realized via an artifact called the causal issue graph (CIG). In particular, CIG is directed graph in which vertices represent sub-issues and edges encode causal dependencies between them. Each sub-issue is associated with the relevant code snippets it affects. To construct the CIG, GraphLocator first identifies symptom locations on repository dependency fractal structure (RDFS) using an agentic workflow. The RDFS is heterogeneous graph that includes repository elements of different granularity, such as directories, files, classes, and methods, as vertices, along with the dependency edges connecting them. Based on RDFS, GraphLocator then iteratively discovers the causal structure of the issue by performing abductive reasoning over neighboring vertices: each observed neighbor may give rise to new sub-issue, which is added to the CIG. This process naturally enables dynamic issue disentangling, as the process progressively decouples complex, interdependent issue components while constructing the CIG. Experiments based on three real-world datasets covering both Python and Java languages demonstrate the effectiveness of GraphLocator. Compared with embeddingand LLM-based approaches using Claude-3.5 on function-level localization, (1) GraphLocator achieves more accurate localization with average absolute improvements of +19.49% in recall and +11.89% in precision with acceptable overhead. (2) GraphLocator outperforms embeddingand LLM-based approaches on both symptom-to-cause mismatches (distance > 1) and one-to-many mismatches, achieving recall improvement of +16.44% and +19.18%, precision improvement of +7.78% and +13.23%, respectively. (3) The disentangled structure CIG generated by GraphLocator yields the highest relative improvement, resulting in 28.74% increase in performance on the downstream issue-resolving task. To summarize, our main contributions are: An LLM-based approach GraphLocator with hybrid workflow that combines agentic exploration of the RDFS with iterative causal structure discovery, effectively tracing root causes and disentangling interdependent code contexts. graph-based representation CIG (causal issue graph) that explicitly models causal dependencies between sub-issues, addressing symptomto-cause mismatches and mitigating one-to-many mismatches by decomposing issues into interdependent sub-issues. Experiments on three real-world Python and Java datasets show that GraphLocator significantly improves function-level localization (+19.49% function-level recall, +11.89% precision on average), 1:4 Liu et al. Fig. 3. An illustration of RDFS. effectively handles symptom-to-cause and one-to-many mismatches, and enhances downstream issue-resolving performance by 28.74%."
        },
        {
            "title": "2.1 Repository Dependency Fractal Structure\nThe RDFS serves as a unified graph representation that models the context of repositories across\nvarious object-oriented programming languages. It captures both hierarchical memberships and\nstructural dependencies among elements at different levels of granularity within a repository. By\norganizing these elements into a heterogeneous attributed graph, RDFS offers a scalable and flexible\nway for representing the intricate complexities of code repository.",
            "content": "Definition 2.1 (Repository Dependency Fractal Structure). repository dependency fractal structure (RDFS) is 7-tuple (cid:17) (ğ‘‰ , ğ¸,ğ‘‡ , ğ¶, ğ‘¡ğ‘¦ğ‘ğ‘’, ğ‘ğ‘œğ‘‘ğ‘’, ğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿ ), where: (1) ğ‘‰ is set of vertices, with each vertex representing an element in repository and associated with type in ğ‘‡ğ‘‰ ; (2) ğ¸ ğ‘‰ ğ‘‡ğ¸ ğ‘‰ is set of edges between vertices, with each edge representing relationship between two elements and associated with type in ğ‘‡ğ¸. Given an edge ğ‘’ = (ğ‘¢, ğœŒ, ğ‘£) ğ¸, ğ‘’ is an out-edge of ğ‘¢ and an in-edge of ğ‘£; (3) ğ‘‡ = ğ‘‡ğ‘‰ ğ‘‡ğ¸ is set of types, where ğ‘‡ğ‘‰ = {dir, pkg, file, class, interface, enum, field, method, func, global_var} is vertex types, and ğ‘‡ğ¸ = {UsedBy, ImportedBy, ExtendedBy, ImplementedBy, HasMember} represents edge types; (4) ğ¶ is the set of code snippets in repository and each vertex is associated with code snippet; (5) ğ‘¡ğ‘¦ğ‘ğ‘’ : (ğ‘‰ ğ‘‡ğ‘‰ ) (ğ¸ ğ‘‡ğ¸) is function that maps each element in ğ‘‰ ğ¸ to its type; (6) ğ‘ğ‘œğ‘‘ğ‘’ : ğ‘‰ ğ¶ is function that maps each vertex in ğ‘‰ to its code snippet in ğ¶; (7) ğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿ : ğ‘‡ğ‘‰ {1, , ğ¿} is surjective function that maps each vertex type to layer number. The RDFS has three key properties: (1) Edges only connect vertices from one type to those of type with layer number that is greater than or equal to its own: ğ‘’ = (ğ‘¢, ğœŒ, ğ‘£) ğ¸ layer(type(ğ‘¢)) layer(type(ğ‘£)). (2) The only edge type that exists cross layers is HasMember: ğ‘’ = (ğ‘¢, ğœŒ, ğ‘£) ğ¸ ğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿ (ğ‘¡ğ‘¦ğ‘ğ‘’ (ğ‘¢)) > ğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿ (ğ‘¡ğ‘¦ğ‘ğ‘’ (ğ‘£)) ğœŒ = HasMember. (3) The layer numbers create partition of the vertex type set: ğ‘–, ğ‘— {1, , ğ‘™ }, ğ¿ğ‘– = {ğ‘¡ ğ‘‡ğ‘‰ layer (ğ‘¡) = ğ‘–} , ğ¿ğ‘– ğ¿ğ‘— = , and (cid:208)ğ‘– ğ¿ğ‘– = ğ‘‡ğ‘‰ . GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:5 Fig. 4. Illustration of CIG for issue astropy__astropy-12907 in SWE-bench Lite[12]. Vertices represent subissues grounded to corresponding code entities in RDFS; edges denote probabilistic causal dependencies. Fig. 3 gives an illustration of RDFS and its instantiation in programming languages such as Python and Java. The elements in code repository can be categorized into ğ¿ = 4 distinct layers, each representing different level of granularity. At layer 1, directories and packages serve as logical groupings of related functionality, where directories may contain other directories, forming hierarchical structures connected by HasMember relationship. At layer 2, it consists of files within the repository, which may import other files, represented by the ImportedBy edge type. At layer 3, it includes vertices of types class, interface, and enum make up the third layer, where classes can extend or implement interfaces and reference other classes or enums. Relationships within this level includes ExtendedBy, ImplementedBy and UsedBy. At layer 4, fields, methods, and functions are represented. The relationships within this layer, including method/function calls and field usage, are denoted by the edge of type UsedBy. Across all layers, the HasMember edge type is used to represent hierarchical membership. To construct the RDFS, we first parse the entire codebase into an abstract syntax tree (AST) using tree-sitter1. We then extract code entities by tree-sitters pattern-matching language and establish the foundational hierarchical skeleton by adding HasMember edges between them. Subsequently, we perform static analysis on the AST to identify semantic dependencies, such as imports, inheritance, and function calls, and encode them as ImportedBy, ExtendedBy, and UsedBy edges. To ensure efficiency, we employ lazy-loading strategy: the full graph is built incrementally, beginning with the intra-layer HasMember skeleton, while the more computationally intensive inter-layer dependency edges are only analyzed and added on-demand during the GraphLocators traversal. This incremental approach also facilitates updates; for any modified file, we remove its corresponding subgraph and reconstruct it from the updated AST, seamlessly re-integrating it to maintain consistent graph representation."
        },
        {
            "title": "2.2 Causal Issue Graph\nTo capture the causal relationships among sub-issues and their associated code entities, we introduce\nthe Causal Issue Graph (CIG). Intuitively, a CIG is a directed graph where: (1) vertices represent\nsub-issues derived from the issue description and grounded to vertices in RDFS, and (2) edges\nrepresent potential causal dependencies between these sub-issues. Each edge is associated with a\nprobability reflecting the LLMâ€™s estimation of causal probability.",
            "content": "Definition 2.2 (Causal Issue Graph). causal issue graph (CIG) associated with an RDFS as the tuple G(ğ¼, R) (cid:17) (X, Y, R, ğœ™,ğœ“ ), where: (1) is the set of sub-issues, each described in natural language; (2) is the set of directed edges representing causal relations between sub-issues; (3) = (ğ‘‰ , ğ¸,ğ‘‡ , ğ¶, type, code, layer) denotes the corresponding RDFS of the repository; 1https://tree-sitter.github.io 1:6 Liu et al. (4) ğœ™ : 2ğ‘‰ is function mapping each sub-issue to its corresponding set of vertices in R; (5) ğœ“ : [0, 1] parametrizes the conditional probability of one sub-issue causing another. Conceptually, CIG can be viewed as domain-specific form of structural causal model (SCM) [26 28], but grounded in repositories: vertices(sub-issues) correspond to SCMs causal variables, edges encode causal dependencies, ğœ“ parametrizes conditional effects, and the mapping ğœ™ ties vertices to concrete code. Unlike classical SCMs, however, the CIG does not attempt to identify statistically validated causal effects. Instead, it provides structured representation of hypothesized causeeffect relations among sub-issue to guide LLM-driven abductive reasoning, helping the model to trace multi-hop causal paths and disentangle interdependent sub-issues. Fig.4 shows CIG generated by Claude-3.5 for issue astropy__astropy-12907 in SWE-bench Lite[12]. The CIG begins from symptom-level functions (e.g., separability_matrix mentioned in the issue description) and, rather than jumping directly to candidate root cause, incrementally introduces intermediate sub-issues (e.g., incorrect handling of nested separability matrices) by tracing dependencies in the RDFS. These intermediate nodes act as explanatory bridges, linking observable symptoms to the underlying defect. By explicitly modeling them, the CIG enables graphguided causal reasoning: the LLM can disentangle sub-issues, trace how high-level symptoms propagate through repository dependencies, and finally converge on the true root causes (e.g., _cstack). As illustrated in Fig. 4, the CIG resembles reversed tree that aggregates multiple causal paths. However, we use the term graph rather than tree to maintain generality, since causal paths may share intermediate nodes or intersect. Such overlaps introduce non-tree structures that tree representation cannot adequately capture."
        },
        {
            "title": "3 GraphLocator\nIn this section, we present GraphLocator, a graph-based issue localization framework. As shown\nin Fig. 5, GraphLocator takes as input an issue description as well as the corresponding code\nrepository, outputs a set of code entities that required modification. Specifically, GraphLocator\nconsists of two consecutive phases: symptom vertices locating and dynamic CIG discovering.\nâ€¢ In the symptom vertices locating phase (Section 3.1), GraphLocator aims to identify vertices in\nthe RDFS that correspond to the symptoms described in the issue report by iteratively invoking\ngraph-executable search tools.",
            "content": "In the dynamic CIG discovering phase (Section 3.2), starting from symptom vertices, GraphLocator incrementally constructs the CIG by iteratively traversing neighboring RDFS vertices, discovering new sub-issues, and grounding them to relevant code entities. This process supports multi-hop causal reasoning and disentangles interdependent components, addressing both symptom-to-cause and one-to-many mismatches. Due to space constraints, the prompt templates used in these two phases are omitted here but are provided in the artifact accessible via the data availability link."
        },
        {
            "title": "3.1 Phase I: Symptom Vertices Locating\nThe symptom vertices locating phase aims to identify a set of symptom vertices ğ‘† in the RDFS that\ndirectly correspond to issue description. To achieve this, GraphLocator employs an LLM-driven\nagent, SearchAgent, which iteratively invokes graph-executable search tools to autonomously\nidentify vertices that are semantically aligned with the issue description.",
            "content": "Tab.1 summarizes the search tool set of SearchAgent. This set is designed to handle issue descriptions, which are often unstructured, ambiguous, and vary in granularity. Such characteristics pose two specific challenges: (1) descriptions span multiple abstraction levels, and (2) they may embed implicit or explicit structural constraints. To address these challenges, GraphLocator GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:7 Fig. 5. Overview of GraphLocator for issue localization. Table 1. Specification of search tools. Wildcard symbols (*) are allowed for partial argument matching. Tool Name search_vertex search_edge finish Arguments vertex_name vertex_type src_vertex_type src_vertex_name edge_type trg_vertex_type trg_vertex_name - Description Retrieve vertex in RDFS by matching its name and type. Query an edge between two vertices, specified by type and name, with given relation. Finish and return the final results. enhances the expressiveness of the search tools compared to prior work[6, 11] in three key ways: (1) enabling layer-aware queries by incorporating vertex types, (2) supporting wildcard-based partial matching, and (3) introducing structure-aware search tool, search_edge, to capture dependencies between entities. Specifically, the tools include: search_vertex: This tool retrieves vertices from the RDFS that match the specified constraints, namely ğ‘£ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘¥_ğ‘›ğ‘ğ‘šğ‘’ and ğ‘£ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘¥_ğ‘¡ğ‘¦ğ‘ğ‘’. To accommodate the inherent ambiguity and variability of natural language issue description, wildcards (*) can be used for either field, for example search_vertex(vertex_name, *), enabling partial specification when full details are unavailable. In cases where no exact match exists, the tool performs fuzzy search based on string edit distance [22, 32], providing robustness against minor variations in naming or typographical errors. The top-k candidates retrieved are then filtered using prompt-based semantic reasoning by the SearchAgent, ensuring that only vertices most semantically aligned with the issue description are retained. During this filtering, each vertex ğ‘£ is serialized in the prompt by concatenating its file path, line number, and ğ‘ğ‘œğ‘‘ğ‘’ (ğ‘£) to facilitate judgment by the SearchAgent. search_edge: This tool identifies edges between vertices that satisfy specified relational constraints. For example, search_edge(class, CompoundModel, HasMember, method, __init__) retrieves the CompoundModel class vertex along with its constructor method __init__. By supporting wildcards similar to search_vertex, the tool allows flexible specification of edge endpoints or types. For example, search_edge(*, *, UsedBy, func, separability_matrix) retrieves all code entities that invoke the function separability_matrix. This tool enables the SearchAgent to capture explicit and implicit dependencies in issue descriptions, thus facilitating accurate localization. finish: This tool signals the end of the current phase. When invoked, it returns the collected vertices from the RDFS corresponding to the issue description, allowing the system to proceed to subsequent CIG discovering phase. 1:8 Liu et al."
        },
        {
            "title": "3.2 Phase II: Dynamic CIG Discovering\nGiven a repository RDFS R and an issue description ğ¼ , GraphLocator incrementally constructs\na CIG to unfold the underlying structure of the issue. The construction expands the CIG in a\npriority-driven manner, while applying graph-guided abductive reasoning to incorporate newly\ndiscovered vertices. Details are given in Alg. 1.",
            "content": "Priority-driven graph expansion. This step determines the order in which sub-issues are expanded during CIG construction. Agent-based approaches often suffer from incoherent multi-step reasoning, as the LLM may simultaneously handle multiple loosely connected sub-issues and lose causal focus [19, 41]. To mitigate this, we adopt procedural expansion strategy in which each iteration isolates and expands single sub-issue. Given CIG Gğ‘¡ at step ğ‘¡, the task is to select the most promising sub-issue ğ‘¥ for expansion. Intuitively, ğ‘¥ should be the vertex with the highest potential to causally influence other issues. We formalize this intuition using the priority score Î¨(ğ‘¥): Î¨(ğ‘¥) = 1 (cid:214) (cid:0)1 ğœ“ (ğ‘¥, ğ‘¦)(cid:1) (ğ‘¥,ğ‘¦) where ğœ“ (ğ‘¥, ğ‘¦) denotes the LLM-estimated probability that ğ‘¥ causally leads to ğ‘¦. At each step, the sub-issue with the largest Î¨(ğ‘¥) is dequeued and expanded (line 7 in Alg. 1), while newly discovered sub-issues are inserted into the priority queue with their own Î¨() values (line 10 in Alg. 1). This design ensures that the expansion process remains both focused and causally coherent, progressively prioritizing sub-issues most likely to reveal underlying root causes. Graph-guided Abductive Reasoning. This step determines how sub-issues are expanded during CIG construction by guiding the LLMs causal reasoning with structured context. At step ğ‘¡, given an issue description ğ¼ , the CIG from the previous iteration Gğ‘¡ 1, and the sub-issue ğ‘¥ to be expanded, we first identify the direct causal candidates of ğ‘¥ as the neighboring code vertices of ğœ™ (ğ‘¥) that have not yet been visited. These vertices are collected as newly observed nodes Oğ‘¡ (line 8 in Alg. 1). To perform abductive reasoning, we construct structured prompt for the LLM consisting of: (1) the issue description ğ¼ , (2) the serialized CIG Gğ‘¡ 1 in Mermaid format [36], (3) the target sub-issue ğ‘¥, and (4) the list of newly observed code vertices Oğ‘¡ . Mermaid is used since it provides concise, text-based representation of graph data with explicit causal edges (e.g., > B), which LLMs parse effectively than Json or adjacent format, allowing robust reasoning over causal relationships [4, 16]. Given this structured context, LLM evaluates whether each candidate in Oğ‘¡ constitutes plausible cause or intermediary for ğ‘¥ and updates the CIG accordingly (line 9 in Alg. 1). By iteratively applying this procedure, GraphLocator incorporates causally coherent and decoupled sub-issues, incrementally constructing causal chain from observed symptoms to root causes."
        },
        {
            "title": "4 Experimental Setups\nTo evaluate the performance of GraphLocator on issue localization tasks, we have formulated\nthe following four research questions (RQs):",
            "content": "RQ1 (Effectiveness): How effective is GraphLocator in localization compared to baselines? RQ2 (Generalizability): How does GraphLocator perform across tasks of varying complexity, particularly in scenarios involving symptom-to-cause and one-to-many mismatches? RQ3 (Ablation): How does each component of GraphLocator contribute to its performance? RQ4 (Cost): What is the computational cost of GraphLocator compared with other approaches? GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:9 Algorithm 1: Phase II - Dynamic CIG Discovering Input : Repository RDFS = (ğ‘‰ , ğ¸,ğ‘‡ , ğ¶, type, code, layer), issue description ğ¼ , symptom vertices ğ‘† ğ‘‰ , and maximum number of turns max_turn Output : CIG = (X, Y, R, ğœ™,ğœ“ ) 1 Initialize ğ‘¡ 0, visited set , observed set O0 ğ‘†, and represent issue ğ¼ as vertex ğ‘¥ğ¼ ; 2 G0 CausalAgent(ğ¼, , ğ‘¥ğ¼ , O0) ; 3 Initialize priority queue ğ‘„ with {(ğ‘¥, Î¨(ğ‘¥)) ğ‘¥ X0, ğ‘¥ ğ‘¥ğ¼ } sort descending with Î¨(ğ‘¥); 4 (cid:208)ğ‘¥ X0 ğœ™ (ğ‘¥) ; 5 while ğ‘„ is not empty and ğ‘¡ < ğ‘šğ‘ğ‘¥_ğ‘¡ğ‘¢ğ‘Ÿğ‘› do 6 7 9 10 ğ‘¡ ğ‘¡ + 1 ; ğ‘¥ ğ‘„.pop(); Oğ‘¡ {ğ‘¢ ğ‘‰ ğ‘£ ğœ™ (ğ‘¥)V, (ğ‘¢, ğœŒ, ğ‘£) ğ¸ (ğ‘£, ğœŒ, ğ‘¢) ğ¸}; Gğ‘¡ CausalAgent(ğ¼, Gğ‘¡ 1, ğ‘¥, Oğ‘¡ ) ; Insert Xğ‘¡ Xğ‘¡ 1 into ğ‘„ with priority Î¨(ğ‘¥); ((cid:208)ğ‘¥ Xğ‘¡ ğœ™ (ğ‘¥)) V; 11 12 end 13 return Final CIG Gğ‘¡ ;"
        },
        {
            "title": "4.1 Datasets\nTo comprehensively evaluate issue localization performance, we employ three datasets covering\ntwo programming languages (i.e., Python and Java). The three datasets consist of issues from\nGitHub repositories, where each issue includes (1) an issue description, (2) the repository commit\nversion, and (3) the corresponding diff-based fix patch.",
            "content": "SWE-bench Lite (Python) [12]: widely used benchmark for issue localization and resolving [6, 11, 31, 45, 46]. It comprises 300 issues from 11 large-scale Python projects, selected heuristically from the full 2294-issue SWE-bench. This 300-issue subset is designed to reduce evaluation costs while maintaining benchmark quality. To ensure clean, text-based evaluation, tasks containing non-textual elements (e.g., images and external hyperlinks) are excluded. LocBench (Python) [6]: recent dataset specifically designed for code localization task, including 560 issue instances from 164 Python repositories. Unlike SWE-bench Lite, whose issues are mostly bug report, LocBench covers broader range of issue types and more balanced distribution, including feature requests, security issues, performance problems, and also bug reports. As the repository NCSU-High-Powered-Rocketry-Club/AirbrakesV2 was no longer accessible as of June 25, 2025, its issue instance is excluded, resulting in final dataset of 559 issues. Multi-SWE-bench (Java) [50]: This dataset consists of 128 issue instances from 9 open-sourced Java projects, supporting both issue localization and resolving tasks. The dataset is constructed through systematic pipeline that ensures quality and reliability, including selection of highquality GitHub repositories based on stars and runnability, and manual verification via dual annotation and cross-review to produce human-verified ground truth. Extraction of Ground-truth Locations. Following prior work [6, 11], ground-truth locations are extracted from diff-based fix patches at three levels of granularity. However, the ground-truth extracted in these works contains missing locations for part of issues. To remedy this, the ground truth is re-extracted based on RDFS: At the file level, the paths of all modified files are recorded. At the module level, the enclosing structural unit in RDFS (e.g., class, enum, or interface) that contains the modified lines is identified. At the function level, the function or method in RDFS that directly contains the modified lines is extracted. This hierarchical definition ensures consistency with existing benchmarks while providing fine-grained supervision for evaluation. 1:10 Liu et al."
        },
        {
            "title": "4.2 Evaluation Metrics\nWe evaluate issue localization performance at three levels of granularity: file, module, and function.\nAt each level, we adopt four complementary metrics, Success Location, Recall, Precision, and\nF1-score. Formally, let I denote the set of issue instances, ğ¿ğ‘– the ground-truth locations for issue\nğ‘– âˆˆ I, and ğ¿â€²\nğ‘– the predicted locations at the file/module/function level. The metrics are defined as\nfollows:\nâ€¢ Success Location (SL) [6, 45, 49] measures if the predicted set fully covers the ground truth.",
            "content": "ğ‘†ğ¿ = 1 ğ‘– ğ¿ğ‘– ğ¿ ğ‘– Recall (REC) is the proportion of ground-truth locations captured by localization approaches. ğ‘…ğ¸ğ¶ = 1 ğ‘– ğ¿ğ‘– ğ¿ ğ‘– ğ¿ğ‘– Precision (PRE) penalizes overprediction by the fraction of predictions that are correct. ğ‘ƒğ‘…ğ¸ = 1 ğ‘– ğ¿ğ‘– ğ¿ ğ‘– ğ¿ ğ‘– F1-Score (F1) provides harmonic mean of precision and recall, offering balanced measure that accounts for both underand over-localization. ğ¹ 1 = 1 ğ‘– 2 ğ¿ğ‘– ğ¿ ğ‘– ğ¿ğ‘– + ğ¿ ğ‘–"
        },
        {
            "title": "4.3 Methods for Comparison\nTo ensure a comprehensive evaluation, GraphLocator is compared with representative baselines\nfrom embedding- and LLM-based approaches. For each of these two categories, baselines are chosen\nbased on performance: if one approach clearly outperforms another in prior work, only the superior\none is included. The selected baselines are:\nâ€¢ SWERank-Small/Large [31]: An embedding-based approach for issue localization that follows\na retrieve-then-rerank workflow. Specifically, SWERank-Small combines SWERankEmbed-Small\n(137M) for retrieval with SWERankLLM-Small (7B) for reranking, while SWERank-Large com-\nbines SWERankEmbed-Large (7B) with SWERankLLM-Large (32B). The top-10 reranked results\nare used as the final localization outputs.",
            "content": "Agentless [45]: An LLM-based approach with procedural workflow, which follows hierarchical localization process: it first identifies suspicious files, then narrows down to classes or functions. At each level, the LLM is used to rank and select the top-ğ‘ most likely locations. LocAgent [6]: An LLM-based approach with agentic workflow, which first parses the codebase to construct graph representation and then builds sparse indexes. Based on these indexes, LocAgent performs agent-guided searches with tool-assisted retrieval. CoSIL [11]: An LLM-based approach with agentic workflow, which uses module and function call graphs to identify suspicious code not explicitly mentioned in the issue. It performs iterative searches over the call graph, guided by pruning mechanism that restricts exploration to relevant paths and effectively manages contextual information. Note that SWERank and LocAgent are specific to Python: SWERank is fine-tuned on Python repositories, and LocAgent employs Python-specific backbone graph. Consequently, their evaluation is restricted to SWE-Bench Lite and LocBench, excluding Multi-SWE-bench Java. GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:"
        },
        {
            "title": "4.4 Implementation Details",
            "content": "Base LLMs. For GraphLocator and LLM-based baselines (i.e., Agentless, LocAgent, and CoSIL), we implement using two representative LLMs: gpt-4o-2024-1120 and claude-3-5-sonnet-20241022, short for GPT-4o and Claude-3.5, respectively. To ensure fair comparison, both the two models are configured with greedy decoding (i.e., temperature of 0) to minimize randomness. Implementation of Localization Approaches. GraphLocators RDFS construction is described in Section 2.1. For localization, Phase is limited to 5 search iterations, and Phase II allows up to 20 turns (ğ‘šğ‘ğ‘¥_ğ‘¡ğ‘¢ğ‘Ÿğ‘› = 20). Baseline approaches (i.e., SWERank, Agentless, LocAgent, and CoSIL) are implemented using their official GitHub repositories with default hyperparameters. To evaluate Java repositories, the Multi-SWE-Bench version of Agentless2 is used, and CoSIL is adapted to Java by leveraging this Java-specific code structure generation. Hardware Environments All experiments are conducted on cluster equipped with 64 cores Intel(R) Xeon(R) Platinum 8457C processor and Debian 10 Linux 5.4."
        },
        {
            "title": "5.1 RQ1: Effectiveness\nTab. 2 shows the effectiveness of GraphLocator and baseline approaches across the three datasets:\nSWE-bench Lite, LocBench, and Multi-SWE-bench Java. Based on these results, several key findings\ncan be summarized as follows:",
            "content": "GraphLocator consistently achieves superior performance across datasets and granularities among LLM-based approaches. Specifically, on both Python (SWE-bench Lite and LocBench) and Java (Multi-SWE-bench) datasets, GraphLocator achieves the highest localization performance at file-, module-, and function-level compared to Agentless, LocAgent, and CoSIL. Averaged across the three datasets, GraphLocator improves F1 scores on GPT-4o by 21.33%, 14.18%, and 8.16% at file-, module-, and function-level, respectively. On Claude-3.5, the corresponding gains are 16.79%, 12.64%, and 9.46%. Since SWE-bench Lite only contains single-file issues, file-level SL and REC are identical. Compared with Agentless, GraphLocator substantially increases REC by employing flexible agentic hierarchical traversal instead of the fixed traversal strategy used in Agentless, allowing it to better adapt to varying granularities in issue descriptions. Compared with LocAgent, GraphLocator improves F1 by 14.8330.68% across granularities on GPT-4o and 11.3337.37% on Claude-3.5, demonstrating higher precision and more coherent causal reasoning. Compared to CoSIL, which performs graph-based pruning guided solely by contextual relevance, GraphLocator achieves consistently better performance across all granularities. This improvement highlights the limitations of relevance-based heuristics: they can prune away potentially important nodes, accumulate errors or cause under-expansion during multi-step traversal. While the embedding-based approach SWERank-Large attains higher SL and REC at coarse granularities (file and module levels), it suffers from reduced effectiveness at finer granularity (function level). Specifically, SWERank-Large exhibits better performance at coarse granularities compared to GPT-4o by retrieving large number of code snippets. However, at function level, it underperforms both GPT-4o and Claude-3.5 with GraphLocator, and its PRE remains very low (e.g., 6.57% and 7.88% PRE on SWE-bench Lite and LocBench). In contrast, GraphLocator not only maintains competitive SL and REC but also substantially improves precision by causal structure discovering and dynamic issue disentangling. Consequently, the overall F1 gains of GraphLocator over SWERank reach up to 15.68-21.32% at the function level and 10.55-18.21% at file-level granularities, demonstrating that addressing causality rather than similarity is crucial in code localization. 2https://github.com/multi-swe-bench/MagentLess 1:12 Liu et al. Table 2. Effectiveness on the Python (i.e., SWE-bench Lite and LocBench) and Java (i.e., Multi-SWE-bench Java) datasets. Results show file-, module-, and function-level performance. All values are in percent(%). Bold numbers indicate the best results per base model. Underlined numbers indicate the best results across models and approaches for the same metrics. Base Model Approach File level Module level Function level SL REC PRE F1 SL REC PRE F1 SL REC PRE F1 SWE-bench Lite SWERank GPT-4o Claude-3.5 SWERank GPT-4o Claude-3.5 GPT-4o Claude-3.5 27.84 80. 77.00 82.67 61.67 80.67 38.55 Small 84.33 84.33 29.85 41.28 Large 38.50 77.00 Agentless 37.95 82.67 LocAgent CoSIL 20.77 61.67 GraphLocator 83.67 83.67 48.90 56.76 40.00 Agentless 41.15 LocAgent CoSIL 28.03 GraphLocator 89.33 89.33 45.81 55.17 25.67 26.50 12.49 80.00 84.33 82.33 80.00 84.33 82.33 26.67 29.79 16. 22.48 76.00 28.70 10.64 29.79 67.33 65.63 61.41 75.11 32.96 78.67 79.78 26.27 36.72 38.08 66.67 17.15 64.89 60.44 37.81 70.67 71.78 41.01 47.83 46.28 71.56 10.87 72.44 74.67 44.86 80.44 81.78 38.63 46.82 72.52 73.93 75. 37.15 6.55 34.31 30.65 81.17 72.95 78.86 60.75 75.85 40.51 Small 78.35 83.19 33.29 43.18 Large 39.67 67.98 Agentless 38.54 74.06 LocAgent CoSIL 23.88 56.71 GraphLocator 75.49 79.06 47.34 53.67 43.03 Agentless 44.40 LocAgent CoSIL 27.87 GraphLocator 84.97 88.42 48.13 55.73 28.50 28.21 15. 74.24 83.36 67.62 79.19 88.19 71.33 30.92 33.00 18.18 26.50 26.31 33.87 11.14 35.11 LocBench 35.29 68.17 73.61 35.79 70.43 75.65 40.82 65.10 59.65 17.38 65.02 59.15 47.87 38.84 52.89 60.40 65.38 42.49 46.41 47.47 65.41 12.61 63.91 59.90 44.42 74.44 80.27 43.68 49.98 70.40 70.38 64. 40.65 7.90 38.17 Multi-SWE-bench Java 29.56 18.36 66.89 57.68 57.26 50.00 39.01 Agentless CoSIL 25.94 GraphLocator 64.52 71.03 48.20 51.73 43.63 Agentless 29.25 CoSIL GraphLocator 70.16 76.03 43.26 48. 69.18 65.70 58.87 58.87 34.64 20.40 28.86 33.95 59.61 52.12 36.18 47.58 43.55 37.40 54.03 64.69 46.40 47.19 39.96 49.19 37.43 45.97 58.87 70.44 42.10 46. 62.00 55.62 32.60 32.90 6.06 6.57 14.44 7.24 11.37 10.73 51.26 52.44 11.61 55.23 56.50 20.70 55.72 53.43 12.28 54.48 51.99 46.21 18.05 48.35 60.65 63.18 20.82 27.29 23.27 37.91 8.60 58.48 59.21 24.69 70.76 73.23 20.51 27.73 18.75 5.01 15.94 40.01 61.94 62. 7.63 7.88 20.06 9.82 15.68 12.03 37.52 43.47 12.45 38.42 44.98 25.07 53.90 44.88 14.53 53.96 43.99 39.50 21.29 46.06 46.32 54.06 25.92 29.36 25.73 32.50 10.50 50.45 45.60 26.31 60.32 69.39 28.86 33.35 22.94 6.80 20.13 40.19 61.19 53.94 48.71 44.02 16.10 15. 21.09 34.82 36.61 20.99 39.29 51.51 21.30 24.65 21.06 25.00 21.69 31.25 46.43 60.13 24.56 26.64 19.72 17.40 33.11 42.05 Graph-guided causal reasoning significantly improves precision without sacrificing recall. GraphLocator consistently boosts PRE compared with both embedding-based and LLM-based approaches. For example, on the Python datasets SWE-bench Lite and LocBench, GraphLocator achieves nearly 4 the function-level PRE of the LLM-based agent approach LocAgent when using Claude3.5, which relies on unconstrained agent traversal over the repository graph. This implies that without explicit structural guidance, agent-based methods tend to over-expand the search space, introducing spurious candidates and severely lowering PRE. In contrast, GraphLocator leverages graph-guided abductive reasoning to constrain expansions to causally plausible neighborhoods, thereby filtering irrelevant vertices while still maintaining high REC. similar trend is observed on the Multi-SWE-bench Java, where GraphLocator consistently improves PRE over both Agentless and CoSIL by 4.84-29.84%. This demonstrates that the benefits of graph-guided causal reasoning generalize beyond Python repositories, enabling more accurate localization where interdependent modules and coordinated changes are more prevalent [50]. Effectiveness is more pronounced at finer granularities. The function-level improvements are more significant than fileor module-level. This suggests that GraphLocators ability to model multi-step causal chains and sub-issue dependencies is particularly beneficial for fine-grained issue localization. At coarser levels, such as file or module, baseline approaches can already achieve relatively high recall because the search space of coarser granularity is smaller and thus less GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:13 Fig. 6. Generalizability across symptom-to-cause distance. Performance decreases as the symptom-tocause distance grows, while GraphLocator consistently achieves the best results among baselines. Fig. 7. Generalizability across the number of involved functions. As the number of ground-truth functions increases, performance drops for all methods, but GraphLocator remains the most robust. precise reasoning is sufficient. However, at the function level, precise identification of the root cause requires distinguishing between closely related but non-causal code entities, task where traditional embeddingor agent-based methods often fail due to noise and over-expansion. By explicitly guiding the reasoning process with causal graphs, GraphLocator narrows the search to structurally plausible candidates, enabling significant precision gains without losing recall. Answer to RQ1: GraphLocator consistently outperforms baselines in issue localization across Python and Java datasets, achieving absolute improvements of +19.49% in function-level recall and +11.89% in precision with Claude-3.5."
        },
        {
            "title": "5.2.1 Generalizability on Symptom-to-Cause Distance. In this subsection, we evaluate the capability\nof the issue localization approaches to identify root causes given an issue description. We define the\nsymptom-to-cause distance as the number of traversal hops in the RDFS required to reach all ground-\ntruth locations. To compute this distance, we first extract keywords from the issue description\nusing Claude-3.5. These keywords are then mapped to RDFS nodes with exactly matching names.\nInstances without extractable keywords or without valid node mappings are excluded, forming the\nset C. In parallel, we map the ground-truth functions to another node set T . The symptom-to-cause\ndistance is then defined as:",
            "content": "ğ‘‘ (T , C) = max ğ‘¡ where ğ‘‘ (ğ‘¡, ğ‘) denotes the shortest path distance between node ğ‘¡ and node ğ‘ on the RDFS. For cases where ground-truth function is explicitly mentioned in the issue description, the distance is zero. Fig. 6 shows the generalizability of different approaches with respect to symptom-to-cause distance. For Python-specific approaches (SWERank-Small/Large and LocBench), results are averaged ğ‘‘ (ğ‘¡, ğ‘) min ğ‘ 1:14 Liu et al. over SWE-bench Lite and LocBench, while other methods are averaged over SWERank-Small/Large, LocBench, and Multi-SWE-bench Java. From Fig. 6, it can be observed three key trends: (1) Performance degradation with distance: SL and REC consistently decline as symptom-to-cause distance increases across all methods. (2) GraphLocators superiority: GraphLocator consistently outperforms baselines. At distance 0, where it achieves 95.59% REC and the highest precision, validating the effectiveness of its layer-wise RDFS. (3) Limitations of baselines to balance REC and PRE: Embedding-based approaches (SWERank-Small/Large) show the largest gap to GraphLocator at distance 0. Agentless suffers sharp declines due to the lack of structural context, though it maintains relatively high precision by retaining only the top-n most suspicious entities at each layer. Among graph-based agent methods, CoSIL achieves PRE and F1 scores close to GraphLocator at distances 3 and 4, benefiting from its pruner module that filters out some false positives; however, the absence of explicit causal-path reasoning results in low REC and SL. In contrast, LocAgent exhibits particularly low PRE and F1, as it fails to distinguish between relevant and true causal code, retrieving large number of non-causal snippets."
        },
        {
            "title": "5.2.2 Generalizability on Number of Involved Functions. Fig. 7 shows the generalizability of different\napproaches with respect to the number of functions in ground-truth. Similar to Fig. 6, for Python-\nspecific approaches, results are averaged over SWE-bench Lite and LocBench, while others are\naveraged over both the Python and Java datasets.",
            "content": "From Fig. 7, we observe that among all approaches, GraphLocator achieves the best balance between REC and PRE across varying numbers of functions in ground truth. Compared with embedding-based approaches (SWERank-Small/Large), GraphLocator maintains substantially higher SL and REC, highlighting its robustness in complex multi-function cases. Agentless, lacking structural reasoning, shows sharp declines in SL and REC as the number of functions grows. LocAgent performs comparably to GraphLocator when only single function is involved; however, as the number of functions increases, it loses the ability to trace multi-function dependencies due to the absence of CIG guidance, which is leveraged by GraphLocator. CoSIL benefits from its pruning strategy, yielding higher precision but at the cost of reduced recall, while LocAgent further suffers from poor discrimination of true causal functions, leading to consistently low PRE and F1. Additionally, there is an opposite trend between SL/REC and PRE/F1: as the number of ground-truth functions increases, SL and REC steadily decline, while PRE and F1 improve. This is partially because larger number of ground-truth functions expands the search space, making it more difficult to recover all functions (lowering SL and REC), yet simultaneously increasing the probability that predictions overlap with part of the correct functions (raising PRE and F1). Answer to RQ2: As both the symptom-to-cause distance and the number of ground-truth functions increase, GraphLocator consistently outperforms baseline approaches and demonstrates superior effectiveness in balancing recall and precision."
        },
        {
            "title": "5.3 RQ3: Ablation Study\nIn this subsection, we systematically evaluate the contributions of key components in GraphLo-\ncator. For Phase I (symptom vertex locating), we ablate the tools search_vertex and search_edge\nindividually. For Phase II (dynamic CIG discovery), two variants are considered: (i) w/o priority\nqueue, which replaces the priority queue with a simple first-in-first-out (FIFO) queue; and (ii) w/o\nCIG guidance, which excludes the CIG from the prompt, retaining only the already selected code\nentities and removing causal-structure guidance. All experiments use Claude-3.5, and results are\naveraged across SWE-bench Lite, LocBench, and Multi-SWE-bench Java.",
            "content": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:15 Table 3. Ablation study of components in GraphLocator. Results are averaged across the 987 issues of the three datasets (i.e., SWE-bench Lite, LocBench, and Multi-SWE-bench Java) based on Claude-3.5. Approach GraphLocator w/o search_vertex w/o search_edge w/o priority queue w/o CIG guided File-level Module-level Function-level F1 SL REC PRE 84.44 87.14 46.81 54.65 27.04 35.40 49.34 74.36 51.10 75.08 41.77 75. 24.56 42.04 44.00 33.83 37.23 78.44 78.98 80.09 F1 SL REC PRE 73.66 79.09 41.90 48.42 29.49 38.90 43.40 64.04 46.17 64.97 39.24 68.05 26.96 37.72 40.91 32. 41.78 69.68 70.17 73.99 F1 SL REC PRE 61.73 69.41 25.91 30.91 14.23 25.48 28.45 51.59 29.54 54.76 21.50 59.30 29.32 58.77 62.27 66.50 12.29 23.85 24.12 16. Table 4. Cost for interaction with LLM Approach Agentless LocAgent CoSIL GraphLocator Input (k) Output (k) Cost ($) GPT-4o-2024-1120 0.60 1.74 0.86 7.56 26.51 211.23 12.93 99.44 0.13 1.08 0.08 0. Fig. 8. Time efficiency of GraphLocator and LocAgent. Claude-3.5-Sonnet-20241022 Agentless LocAgent CoSIL GraphLocator 62.56 231.68 14.24 156.80 0.95 2.85 0.91 6.71 0.19 0.74 0.06 0. Tab. 3 reports the performance impact of ablating each component in GraphLocator. The localization performance of GraphLocator suffers significant drop after the removal of each of its component. Specifically, in the symptom vertices locating phase, search_vertex serves as the primary bridge linking issue descriptions to RDFS vertices; its removal collapses function-level F1 from 30.91% to 14.23%. search_edge provides supplementary context, and its absence also degrades performance, highlighting the necessity of both tools for accurate seed identification. In the dynamic CIG discovering phase, CIG-based guidance in prompts ensures that the LLM maintains awareness of previously identified causal dependencies, which is critical for the precise of causal reasoning. Priority-driven graph expansion, on the other hand, improves recall by steering reasoning toward the most promising sub-issues. This result further implies that though the LLM-estimated causal dependency probabilities may not exactly reflect the true values, they provide useful relative measure of the importance among sub-issues. Answer to RQ3: The performance of GraphLocator degrades after the removal of each of its key components. Each component, from search tools to priority-driven graph expansion, and graph-guided reasoning, directly enables effective localization."
        },
        {
            "title": "5.4 RQ4: Cost\n5.4.1 Graph Construction Time Efficiency. In Fig. 8, we study the time efficiency of GraphLocatorâ€™s\ngraph construction time. The graph construction time of GraphLocator consists of two parts:\nthe inter-layer skeleton construction time before agent processing the issue and the intra-layer\ndependencies lazy loading during the agent process. In Fig. 8(a), we compare the overall time of\nGraphLocator and LocAgent. In Fig. 8(b), we study how the inter-layer skeleton and intra-layer\ndependencies construction time scale as the number of functions in a repository grows. We do\nnot compare with the graph-based approach CoSIL since its graph is dynamically constructed by\nprompting LLM instead of static analysis, thus is hard to track.",
            "content": "1:16 Liu et al. As shown in Fig. 8(a), GraphLocator achieves higher average time efficiency in graph construction when the repository contains more than 20 functions. The RDFS used by GraphLocator is more fine-grained and complicate than that of LocAgent since it also incorporate entities such as class field and global variables, intuitively its fully construction is more time-consuming. However, the lazy loading mechanism used by GraphLocator effectively reduce the time by only load the dependencies that is useful instead of the fully construction used by GraphLocator. The fluctuation of GraphLocator on overall graph is resulting by the number of useful dependencies for resolving different issue instance varied. In Fig. 8 (b), we look into how the inter-layer skeleton construction time and intra-layer dependencies construction time scale as the number of functions grows. Both times grow with the number of functions. For repository with 10k functions, intralayer skeleton construction takes under 20 seconds, while inter-layer static analysis of single function ranges from 0.5 to 5 seconds. Time efficiency can be further improved by parallelizing the adding of intra-layer dependencies."
        },
        {
            "title": "5.4.2 Token Consumption. Tab. 4 presents the token consumption and associated cost of different\napproaches across two representative LLMs. Compared with LocAgent, GraphLocator achieves a\nsubstantial reduction in interaction overhead. Under GPT-4o, GraphLocator requires less than\nhalf of LocAgentâ€™s input tokens (99.44k vs. 211.23k), reducing token usage by 52.9% and cost\nby 43.5%. A similar trend holds under Claude-3.5, where GraphLocator reduces input tokens\nby 32.3% and cost by 22.9% relative to LocAgent. While GraphLocator consumes more tokens\nthan Agentless and CoSIL due to its repository-structural reasoning, the additional cost remains\nmoderate. Overall, GraphLocator strikes a favorable trade-off between accuracy and efficiency,\noffering significantly lower token consumption than agent-based baselines while maintaining\nstrong localization performance.",
            "content": "Answer to RQ4: GraphLocator demonstrates efficient graph construction and substantially lower token consumption compared with agent-based baseline LocAgent, achieving strong localization performance with acceptable overall cost."
        },
        {
            "title": "6.1 Impact on Downstream Issue Resolving\nIn this subsection, we examine how issue localization performance influences downstream issue\nresolving. We select two representative issue resolving frameworks: the procedural Agentless [45]\nand the recent agent-based Trae Agent [37]. Prior studies [11, 45, 49] have suggested a positive\ncorrelation between file- and function-level success localization (SL) rate and resolving performance;\nhere, we systematically quantify this relationship.",
            "content": "For integrating localization approaches into Agentless, we replace the original location module of Agentless by baseline localization approaches and GraphLocator. For Trae Agent, we serialize the localization results, including file paths and corresponding code snippets, in the order produced by each baseline and concatenate this information with the original issue description. To evaluate the contribution of GraphLocators causal issue graph (CIG) structure, we consider two settings: (1) GraphLocator (w/o struct.): code entities are serialized in topological order and appended to the issue description, without representing structural dependencies. (2) GraphLocator (w/ struct.): the generated CIG is serialized in topological order and represented using the Mermaid format, preserving structural relations. Both frameworks leveraging multi-sampling mechanism to improve issue resolved rate; for this evaluation, we use single-sample setting (num_sampling=1) with greedy decoding for proof of concept and budget saving reduce computational cost. Evaluation is GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:17 performed on SWE-bench Lite and Multi-SWE-bench Java, excluding LocBench due to missing unit tests information for correctness validation. The results are shown in Tab. 5. Table 5. Resolved rate on SWE-bench Lite and Multi-SWE-bench Java using Claude-3.5 with single-sample evaluation. GraphLocator (GL) is abbreviated as GL. File SL and Func SL represent fileand functionlevel success location rate, respectively. Improv. indicates the relative improvement in resolved rate over downstream framework. All results are in percentage (%). Approach File SL Func SL Resolved Improv. Approach File SL Func SL Resolved Improv. Agentless +SWERank-Large +LocAgent +CoSIL +GL (w/o struct.) +GL (w/ struct.) Agentless +CoSIL +GL (w/o struct.) +GL (w/ struct.) 80.00 84.33 84.33 82.33 89.33 89. 58.57 58.87 70.16 70.16 37.91 55.23 58.48 59.21 70.76 70.76 25.00 31.25 46.43 46.43 SWE-bench Lite - 3.95 1.34 2.65 3.95 13.19 Trae Agent +SWERank-Large +LocAgent +CoSIL +GL (w/o struct.) +GL (w/ struct.) Multi-SWE-bench Java Trae Agent +CoSIL +GL (w/o struct.) +GL (w/ struct.) - 45.54 54.60 63.68 25.33 26.33 25.67 26.00 26.33 28.67 8.59 12.50 13.28 14.06 58.33 84.33 84.33 82.33 89.33 89. 51.61 58.87 70.16 70.16 40.07 55.23 58.48 59.21 70.76 70.76 33.04 31.25 46.43 46.43 25.00 28.33 27.00 28.67 29.00 30.67 20.31 14.06 22.65 23.44 - 13.32 8.00 14.68 16.00 22. - 30.77 11.52 15.41 From Tab. 5, several key observations can be drawn: (1) Improved localization generally leads to higher resolved rates: across both frameworks, integrating GraphLocator consistently increases resolved rate compared to baselines. For example, on SWE-bench Lite, GraphLocator (w/ struct.) improves Trae Agents resolved rate from 25.00% to 30.67%. However, there is also an exception: on SWE-bench Lite, +SWERank-Large achieves higher resolved rate than LocAgent despite lower function-level SL, likely due to LocAgents lower precision and F1 (Tab.2) (2) Structural and explainable context provided by the Mermaid-serialized CIG, consistently enhances resolved rates, indicating that explicit encoding of causal and relationships helps LLMs better reason about necessary code changes. (3) Trae Agent benefits more from high-quality localization than Agentless, indicating that an agentic workflow can more effectively leverage prompt-based cues to guide autonomous issue resolving. (4) While accurate localization is undeniably crucial, how to effectively utilizing this information to generate correct patches remains significant challenge. The absolute resolved rates, though improved, indicate that translating accurate localization into correct fixes involves additional complexities beyond mere identification of code to be modified. Knowing where to change is not enough; it is also essential to know how to change it. Therefore, more sophisticated mechanisms for generating fix patches are required in future work to bridge this gap and fully leverage the potential of structural code understanding."
        },
        {
            "title": "6.2 Threats to Validity\nInternal validity. The internal threats to validity lie in the implementation of baseline approaches, the\npotential data leakage in LLMs, and the definition of ground-truth location. For the implementation\nof baselines, we directly use official implementations released on GitHub and configure them\naccording to their default settings to ensure fair comparison. For the adaption of CoSIL to Java\nversion, we implement by directly use the Magentless realized by Multi-SWE-bench [50]. For\nadapting CoSIL to Java, we follow the implementation of Magentless provided in Multi-SWE-\nbench [50] to generate the repository structure required by CoSIL. Regarding LLMs, while more\nrecent models could further validate GraphLocator, they pose a higher risk of data leakage.\nTo mitigate this, we avoid very recent releases (e.g., Claude-3.7-Sonnet, Claude-4-Opus, GPT-5)\nand instead select two widely adopted LLMs whose training data are less likely to overlap with\nLocBench, which was collected after October 2024. Moreover, as shown in Tab. 2, GraphLocator",
            "content": "1:18 Liu et al. consistently outperforms baselines even under potential leakage, suggesting that its improvements are not merely result of memorization. Finally, issue localization does not always have single definitive solution, as alternative code changes may also correctly resolve given issue. Following prior work [6, 11, 31], we use human-written fix patches to extract ground-truth locations, which reflect commonly accepted fixes while acknowledging that alternative valid solutions may exist. External validity. The primary external threat lies in the generalizability of our findings beyond the current evaluation setting, including applicability to other programming languages and to diverse types of repositories. Our evaluations focus on open-source repositories in two mainstream programming languages: Python and Java, so our results are limited in this scope. Nevertheless, GraphLocator can be extended to additional languages by constructing the RDFS from abstract syntax trees and reusing the same reasoning framework with relatively modest effort. Regarding repository diversity, our evaluation includes 164 repositories from LocBench, 12 from SWE-bench Lite, and 9 from Multi-SWE-bench Java, covering broad range of domains and sizes. Although not exhaustive, this selection provides representative basis for assessing the effectiveness of GraphLocator across different settings."
        },
        {
            "title": "7 Related Work",
            "content": "Issue Localization Approaches. Issue localization aims to map natural language descriptions of issues to the corresponding code entities that require modification. Existing approaches can be largely categorized into embedding-based and LLM-based approaches. Embedding-based methods formulate the task as semantic matching between issue descriptions and code entities. Representative models such as CodeSage [51], CodeRankEmbed [35], and SWERankEmbed [31] learn joint embedding spaces for natural language and code, ranking candidate entities by similarity. While lightweight, these methods require complex indexing infrastructures and incur storage and maintenance overheads. More importantly, they overlook structural and dependency relations within repositories, limiting their ability to trace true root causes [6] or capture interdependent changes. LLM-based approaches leverage the reasoning and code understanding capabilities of LLMs [5, 9, 30, 52]. These approaches can be further divided into procedural and agentic workflows. The procedural workflow follows fixed hierarchical steps guided by prompts. For example, Agentless [45] localizes issues progressively from files to classes to functions, while BugCerberus [3] employs specialized LLMs trained for different levels. Although structured, such approaches neglect code structure and cannot backtrack once errors occur. The agentic workflow treats LLMs as autonomous agents capable of tool use and exploration. Examples include SWE-Agent [47], OpenHands [39], and Trae Agent [37] and MoatlessTools [24]. To improve structural awareness, graph-based variants have been proposed [6, 11, 21, 25, 49]. For example, OrcaLoca [49] models hierarchical and call relations using relevance-priority scheduling. LocAgent [6] parses repositories into heterogeneous graphs, enabling tool-assisted exploration. CoSIL [11] extends this by pruning traversal paths using contextual relevance to reduce noise. While agentic graph-based approaches enhance structural awareness, they still rely on superficial relevance, lack explicit modeling of causality, and fail to effectively capture interdependent code entities. Causal Reasoning Ability of LLMs. Causal reasoning is fundamental aspect of human cognition and is considered essential for advancing machine intelligence [29]. Traditional frameworks, such as structural causal models (SCMs)[27] and the potential outcome framework[10], provide systematic definitions and methods for discovering causal relationships [23, 33, 38] and estimating causal effects [42, 48]. However, these approaches primarily target tabular data and are less effective for reasoning over natural language. Recent advancements in LLMs offer new opportunities to extend causal inference to textual and code contexts [8, 20]. Causal reasoning tasks can be grouped into three categories: causal discovery (recovering latent causal structures), cause attribution (identifying GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:19 potential causes), and causal effect estimation (measuring the impact of causal variables)[13, 14, 34, 43, 53]. While LLMs show promise in uncovering causal relationships[1, 17, 18, 55], they remain limited in counterfactual reasoning, which requires evaluating hypothetical scenarios [7, 15, 34, 44]. In this paper, GraphLocator leverages the causal discovery capabilities of LLMs to infer latent causal structures from observed code snippets, enabling more precise identification of interdependent sub-issues."
        },
        {
            "title": "8 Conclusion\nIn this paper, we present GraphLocator, an LLM-based approach for issue localization that ad-\ndresses the fundamental challenges of symptomâ€“to-cause and one-to-many mismatches between\nissue description and source code. By constructing a causal issue graph (CIG), GraphLocator\ncaptures multi-hop causal relationships among sub-issues and their corresponding code entities,\nenabling iterative abductive reasoning and dynamic disentangling of interdependent components.\nExtensive experiments on three real-world Python and Java datasets demonstrate that GraphLoca-\ntor consistently outperforms existing baselines, achieving substantial improvement in function-\nlevel localization recall and precision, as well as improved performance in both symptomâ€“to-cause\nand one-to-many scenarios. These results highlight the effectiveness of leveraging causal structure\ndiscovery and dynamic issue disentangling to bridge the semantic gap between natural language is-\nsues and source code, offering a promising direction for more accurate and interpretable automated\nissue localization.",
            "content": "Data Availability The prompt templates and code of GraphLocator are released at https://github.com/oceaneLIU/ GraphLocator. For baselines, we use their publicly available source code released on GitHub, including SWERank (https://github.com/SalesforceAIResearch/SweRank), CoSIL (https://github.com/ ZhonghaoJiang/CoSIL), LocAgent (https://github.com/gersteinlab/LocAgent), Agentless (https:// github.com/OpenAutoCoder/Agentless), and Trae Agent(https://github.com/bytedance/trae-agent). All datasets used in this study are publicly accessible. SWE-bench Lite is available at https: //huggingface.co/datasets/SWE-bench/SWE-bench_Lite, Multi-SWE-bench at https://huggingface. co/datasets/ByteDance-Seed/Multi-SWE-bench, and LocBench at https://huggingface.co/datasets/ czlll/Loc-Bench_V1. References [1] Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Dushyant Singh Sengar, Mayank Jindal, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, and Aman Chadha. 2024. Cause and effect: can large language models truly understand causality?. In Proceedings of the AAAI Symposium Series, Vol. 4. 29. [2] Marcel BÃ¶hme, Ezekiel Soremekun, Sudipta Chattopadhyay, Emamurho Ugherughe, and Andreas Zeller. 2017. Where is the bug and how is it fixed? an experiment with practitioners. In Proceedings of the 2017 11th joint meeting on foundations of software engineering. 117128. [3] Jianming Chang, Xin Zhou, Lulu Wang, David Lo, and Bixin Li. 2025. Bridging Bug Localization and Issue Fixing: Hierarchical Localization Framework Leveraging Large Language Models. arXiv preprint arXiv:2502.15292 (2025). [4] Boqi Chen, Ou Wei, Bingzhou Zheng, and Gunter Mussbacher. 2025. Accurate and Consistent Graph Model Generation from Text with Large Language Models. arXiv preprint arXiv:2508.00255 (2025). [5] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wanxiang Che. 2025. Towards reasoning era: survey of long chain-of-thought for reasoning large language models. arXiv preprint arXiv:2503.09567 (2025). [6] Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, and Xingyao Wang. 2025. Locagent: Graph-guided llm agents for code localization. arXiv preprint arXiv:2503.09089 (2025). [7] Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, and Bo Han. 2024. Unveiling causal reasoning in large language models: Reality or mirage? Advances in Neural Information Processing Systems 37 (2024), 9664096670. 1:20 Liu et al. [8] Amir Feder, Katherine Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar, Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret Roberts, et al. 2022. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. Transactions of the Association for Computational Linguistics 10 (2022), 11381158. [9] Sabaat Haroon, Ahmad Faraz Khan, Ahmad Humayun, Waris Gill, Abdul Haddi Amjad, Ali Butt, Mohammad Taha Khan, and Muhammad Ali Gulzar. 2025. How Accurately Do Large Language Models Understand Code? arXiv preprint arXiv:2504.04372 (2025). [10] Guido Imbens and Donald Rubin. 2015. Causal inference in statistics, social, and biomedical sciences. Cambridge university press. [11] Zhonghao Jiang, Xiaoxue Ren, Meng Yan, Wei Jiang, Yong Li, and Zhongxin Liu. 2025. CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching. arXiv preprint arXiv:2503.22424 (2025). [12] Carlos Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. 2024. SWE-bench: Can Language Models Resolve Real-world Github Issues?. In The Twelfth International Conference on Learning Representations. https://openreview.net/forum?id=VTF8yNQM66 [13] Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona Diab, and Bernhard SchÃ¶lkopf. 2023. Can large language models infer causation from correlation? arXiv preprint arXiv:2306.05836 (2023). [14] Emre Kiciman, Robert Ness, Amit Sharma, and Chenhao Tan. 2023. Causal reasoning and large language models: Opening new frontier for causality. Transactions on Machine Learning Research (2023). [15] Jiaxuan Li, Lang Yu, and Allyson Ettinger. 2023. Counterfactual reasoning: Testing language models understanding of hypothetical scenarios. arXiv preprint arXiv:2305.16572 (2023). [16] Zongqian Li, Ehsan Shareghi, and Nigel Collier. 2025. Reasongraph: Visualisation of reasoning paths. arXiv preprint arXiv:2503.03979 (2025). [17] Xiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan Yang, Yuhang Zhou, Fuxiao Liu, Tianrui Guan, Haoliang Wang, Tong Yu, et al. 2025. Large language models and causal inference in collaboration: comprehensive survey. Findings of the Association for Computational Linguistics: NAACL 2025 (2025), 76687684. [18] Stephanie Long, Tibor Schuster, and Alexandre PichÃ©. 2023. Can large language models build causal graphs? arXiv preprint arXiv:2303.05279 (2023). [19] Hang Luo, Jian Zhang, and Chujun Li. 2025. Causal graphs meet thoughts: Enhancing complex reasoning in graphaugmented llms. arXiv preprint arXiv:2501.14892 (2025). [20] Jing Ma. 2024. Causal inference with large language model: survey. arXiv preprint arXiv:2409.09822 (2024). [21] Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, and Yongbin Li. 2024. How to understand whole software repository. arXiv preprint arXiv:2406.01422 (2024). [22] William Masek and Michael Paterson. 1980. faster algorithm computing string edit distances. Journal of Computer and System sciences 20, 1 (1980), 1831. [23] Ana Rita Nogueira, Andrea Pugnana, Salvatore Ruggieri, Dino Pedreschi, and JoÃ£o Gama. 2022. Methods and tools for causal discovery and causal inference. Wiley interdisciplinary reviews: data mining and knowledge discovery 12, 2 (2022), e1449. [24] Albert Orwall. 2024. Moatless Tools. https://github.com/aorwall/moatless-tools. Accessed: 2024-07-16. [25] Siru Ouyang, Wenhao Yu, Kaixin Ma, Zilin Xiao, Zhihan Zhang, Mengzhao Jia, Jiawei Han, Hongming Zhang, and Dong Yu. 2024. RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph. arXiv preprint arXiv:2410.14684 (2024). [26] Judea Pearl. 2009. Causal inference in statistics: An overview. (2009). [27] Judea Pearl. 2009. Causality. Cambridge university press. [28] Judea Pearl. 2010. Causal inference. Causality: objectives and assessment (2010), 3958. [29] Judea Pearl. 2019. The seven tools of causal inference, with reflections on machine learning. Commun. ACM 62, 3 (2019), 5460. [30] Aske Plaat, Annie Wong, Suzan Verberne, Joost Broekens, Niki van Stein, and Thomas BÃ¤ck. 2024. Reasoning with large language models, survey. CoRR (2024). [31] Revanth Gangi Reddy, Tarun Suresh, JaeHyeok Doo, Ye Liu, Xuan Phi Nguyen, Yingbo Zhou, Semih Yavuz, Caiming Xiong, Heng Ji, and Shafiq Joty. 2025. SweRank: Software Issue Localization with Code Ranking. arXiv preprint arXiv:2505.07849 (2025). [32] Eric Sven Ristad and Peter Yianilos. 2002. Learning string-edit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence 20, 5 (2002), 522532. [33] Peter Spirtes and Kun Zhang. 2016. Causal discovery and inference: concepts and recent methodological advances. In Applied informatics, Vol. 3. Springer, 3. [34] Jiankai Sun, Chuanyang Zheng, Enze Xie, Zhengying Liu, Ruihang Chu, Jianing Qiu, Jiaqi Xu, Mingyu Ding, Hongyang Li, Mengzhe Geng, et al. 2023. survey of reasoning with foundation models. arXiv preprint arXiv:2312.11562 (2023). GraphLocator: Graph-guided Causal Reasoning for Issue Localization 1:21 [35] Tarun Suresh, Revanth Gangi Reddy, Yifei Xu, Zach Nussbaum, Andriy Mulyar, Brandon Duderstadt, and Heng Ji. 2025. CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking. In The Thirteenth International Conference on Learning Representations. [36] Sveidqvist. 2014. to. Mermaid: Generate diagrams from markdownlike text. [37] Trae Research Team, Pengfei Gao, Zhao Tian, Xiangxin Meng, Xinchen Wang, Ruida Hu, Yuanan Xiao, Yizhou Liu, Zhao Zhang, Junjie Chen, Cuiyun Gao, Yun Lin, Yingfei Xiong, Chao Peng, and Xia Liu. 2025. Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling. (2025). arXiv:2507.23370 [cs.SE] https: //arxiv.org/abs/2507.23370 [38] Matthew Vowels, Necati Cihan Camgoz, and Richard Bowden. 2022. Dya like dags? survey on structure learning and causal discovery. Comput. Surveys 55, 4 (2022), 136. [39] Xingyao Wang, Boxuan Li, Yufan Song, Frank Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, et al. 2024. Openhands: An open platform for ai software developers as generalist agents. arXiv preprint arXiv:2407.16741 (2024). [40] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, and Steven CH Hoi. 2023. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922 (2023). [41] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems 35 (2022), 2482424837. [42] Christopher Winship and Stephen Morgan. 1999. The estimation of causal effects from observational data. Annual review of sociology 25, 1 (1999), 659706. [43] Anpeng Wu, Kun Kuang, Minqin Zhu, Yingrong Wang, Yujia Zheng, Kairong Han, Baohong Li, Guangyi Chen, Fei Wu, and Kun Zhang. 2024. Causality for large language models. arXiv preprint arXiv:2410.15319 (2024). [44] Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin AkyÃ¼rek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim. 2024. Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. Association for Computational Linguistics. [45] Chunqiu Steven Xia, Yinlin Deng, Soren Dunn, and Lingming Zhang. 2024. Agentless: Demystifying llm-based software engineering agents. arXiv preprint arXiv:2407.01489 (2024). [46] Boyang Yang, Haoye Tian, Jiadong Ren, Shunfu Jin, Yang Liu, Feng Liu, and Bach Le. 2025. Enhancing Repository-Level Software Repair via Repository-Aware Knowledge Graphs. arXiv preprint arXiv:2503.21710 (2025). [47] John Yang, Carlos Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and Ofir Press. 2024. Swe-agent: Agent-computer interfaces enable automated software engineering. Advances in Neural Information Processing Systems 37 (2024), 5052850652. [48] Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, and Aidong Zhang. 2021. survey on causal inference. ACM Transactions on Knowledge Discovery from Data (TKDD) 15, 5 (2021), 146. [49] Zhongming Yu, Hejia Zhang, Yujie Zhao, Hanxian Huang, Matrix Yao, Ke Ding, and Jishen Zhao. 2025. OrcaLoca: An LLM Agent Framework for Software Issue Localization. arXiv preprint arXiv:2502.00350 (2025). [50] Daoguang Zan, Zhirong Huang, Wei Liu, Hanwu Chen, Linhao Zhang, Shulin Xin, Lu Chen, Qi Liu, Xiaojian Zhong, Aoyan Li, Siyao Liu, Yongsheng Xiao, Liangqiang Chen, Yuyu Zhang, Jing Su, Tianyu Liu, Rui Long, Kai Shen, and Liang Xiang. 2025. Multi-SWE-bench: Multilingual Benchmark for Issue Resolving. arXiv:2504.02605 [cs.SE] https://arxiv.org/abs/2504.02605 [51] Dejiao Zhang, Wasi Uddin Ahmad, Ming Tan, Hantian Ding, Ramesh Nallapati, Dan Roth, Xiaofei Ma, and Bing Xiang. 2024. Code Representation Learning at Scale. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net. https://openreview.net/forum?id=vfzRRjumpX [52] Zibin Zheng, Kaiwen Ning, Qingyuan Zhong, Jiachi Chen, Wenqing Chen, Lianghong Guo, Weicheng Wang, and Yanlin Wang. 2025. Towards an understanding of large language models in software engineering tasks. Empirical Software Engineering 30, 2 (2025), 50. [53] LYU Zhiheng, Zhijing Jin, Rada Mihalcea, Mrinmaya Sachan, and Bernhard SchÃ¶lkopf. 2022. Can large language models distinguish cause from effect?. In UAI 2022 Workshop on Causal Representation Learning. [54] Daihong Zhou, Yijian Wu, Lu Xiao, Yuanfang Cai, Xin Peng, Jinrong Fan, Lu Huang, and Heng Chen. 2019. Understanding evolutionary coupling by fine-grained co-change relationship analysis. In 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC). IEEE, 271282. [55] Yu Zhou, Xingyu Wu, Beicheng Huang, Jibin Wu, Liang Feng, and Kay Chen Tan. 2024. Causalbench: comprehensive benchmark for causal learning capability of large language models. CoRR (2024)."
        }
    ],
    "affiliations": [
        "Bytedance, China",
        "Key Lab of High Confidence Software Technologies (PKU), MoE, China",
        "School of Computer Science, Peking University, China",
        "School of Electronic and Computer Engineering, Peking University, China"
    ]
}