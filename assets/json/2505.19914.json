{
    "paper_title": "Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles",
    "authors": [
        "Jiangjie Chen",
        "Qianyu He",
        "Siyu Yuan",
        "Aili Chen",
        "Zhicheng Cai",
        "Weinan Dai",
        "Hongli Yu",
        "Qiying Yu",
        "Xuefeng Li",
        "Jiaze Chen",
        "Hao Zhou",
        "Mingxuan Wang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce Enigmata, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across seven categories, each with 1) a generator that produces unlimited examples with controllable difficulty and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose Enigmata-Eval, a rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata. This work offers a unified, controllable framework for advancing logical reasoning in LLMs. Resources of this work can be found at https://seed-enigmata.github.io."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 2 ] . [ 1 4 1 9 9 1 . 5 0 5 2 : r Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles 1ByteDance Seed 2Fudan University 3Institute for AI Industry Research (AIR), Tsinghua University 4Nanjing University 5Shanghai Jiao Tong University 6SIA-Lab of Tsinghua AIR and ByteDance Seed Full author list in Contributions."
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs), such as OpenAIs o1 and DeepSeeks R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce Enigmata, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across seven categories, each with 1) generator that produces unlimited examples with controllable difficulty and 2) rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose Enigmata-Eval, rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like EnigmataEval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata. This work offers unified, controllable framework for advancing logical reasoning in LLMs. Correspondence: Jiangjie Chen at jiangjiec@bytedance.com Project Page: https://seed-enigmata.github.io/"
        },
        {
            "title": "Introduction",
            "content": "Large Reasoning Models (LRMs) such as o1 and R1, trained from Large Language Models (LLMs) with Reinforcement Learning (RL), have demonstrated excellent performance in complex reasoning tasks [15], such as mathematics, STEM, and coding. The success of LRMs highlights the effectiveness of the Reinforcement Learning with Verifiable Rewards (RLVR) paradigm, which stresses the great importance of obtaining highquality verifiable prompts [68]. However, existing LRMs still struggle to complete various puzzle tasks that require purely logical reasoning skills rather than professional knowledge, which are easy and even obvious for human [912]. Most existing works targeting puzzles mainly focus on designing benchmarks for evaluation [10, 12, 13], lacking the training methods and resources for modern LLMs to tackle this challenge. Existing puzzle datasets often lack diversity and scalability, covering limited puzzle types and offering little 1 Figure 1 Overview of the Enigmata dataset: 36 puzzle tasks across seven categories, designed to enhance and evaluate diverse reasoning capabilities in large language models. control over generation or difficulty [1012]. Few works target solving puzzles, yet with either designing prompting workflow and relying on code interpreter [14], or training LLMs upon one or few puzzles [15, 16], which is difficult to generalize. Based on the success of the LLM+RLVR paradigm, it has become crucial to obtain large, diverse, and challenging set of verifiable puzzle prompts for training agents to master logical reasoning. To meet this need, we introduce Enigmata comprehensive suite that pairs scalable, controllable puzzle dataset with training recipe that equips LLMs with strong puzzle-solving abilities. Enigmata delivers fully synthesizable data across multiple categories, difficulty levels, and scales with automatic evaluation, thus offering effortless integration into RL pipelines. The whole Enigmata suite comprises of Enigmata-Data, Enigmata-Eval, and Enigmata-Model. First, Enigmata-Data comprises 36 task types spanning seven broad categories, each probing distinct facet of logical reasoning. Every task is backed by an automated generatorverifier pair: the generator can vary both the quantity and the difficulty of the puzzles it produces, while the verifier instantly checks the correctness. This design yields three key benefits: 1) It can generate unlimited self-verifying puzzle prompts, which plug seamlessly into the RLVR framework and support long chain-of-thought training. 2) Programmatic difficulty control allows researchers to mix puzzles in desired difficulty ratios and to conduct fine-grained experiments on how curriculum design influences reinforcement learning. 3) Generators can emit arbitrary sample counts per task, enabling task balancing and cross-task generalization studies. Based on Enigmata-Data, we present the Enigmata-Eval benchmark, diverse collection of puzzles that challenges even state-of-the-art LRMs such as o4-mini-high, providing comprehensive assessment of logical reasoning capabilities. We introduce the Enigmata-Model recipe, systematic approach for training highperformance LLMs on puzzle tasks. This recipe incorporates extensive research on multi-task training strategies, examining various training paradigms and data mixing techniques for controlling data amount and difficulty. Built upon Qwen2.5-32B [17], our resulting models surpass current state-of-the-art LRMs on both the Enigmata-Eval benchmark and the challenging ARC-AGI benchmark, while exhibiting remarkable improvements on out-of-domain (OOD) puzzle tasks and maintaining robust generalization in mathematical reasoning. When scaling the base model from Qwen2.5 (32B dense model) to Seed1.5-Thinking [5] (20B/200B 2 Mixture-of-Expert (MoE) model), we observe nice generalization from knowledge-orthogonal puzzle data from Enigmata to tasks that require advanced math and STEM domain knowledge and reasoning skills. Such improvement over SoTA model seems like nice free lunch, since the puzzle data are mostly synthetic. Overall, our key contributions are: We introduce Enigmata, the first suite for enabling LLMs with advanced and comprehensive logical reasoning abilities for solving puzzles. The Enigmata suite consists of Enigmata-Data, featuring 36 distinct tasks across 7 categories with controllable difficulty, scalable generation, and automatic verification, which seamlessly fit the RLVR training paradigm. We establish Enigmata-Eval, benchmark that rigorously and comprehensively evaluates puzzle reasoning abilities, and propose the Enigmata-Model recipe that trains models with superior performance on in-domain and OOD puzzle reasoning tasks."
        },
        {
            "title": "2 Related Work",
            "content": "Reinforcement Learning with Verifiable Rewards. Reinforcement Learning (RL) has become key method for improving models reasoning capabilities. Unlike Reinforcement Learning with Human Feedback (RLHF), Reinforcement Learning with Verifiable Rewards (RLVR) removes the need for reward model by directly assigning rewards based on objectively verifiable answers [2, 5, 18], which has shown strong performance in mathematics [1921], STEM [2, 22], and coding [5, 18]. For example, mathematical models are rewarded when their answers match standard solutions [20, 22], while coding models receive rewards when their code passes unit tests [23]. This method is appealing due to its automation and resistance to reward hacking. Puzzles are particularly well-suited for RLVR. They can be generated automatically without expert annotations [7, 8, 15], follow clear rules with algorithmically verifiable solutions [11], and support precise control over difficulty [10, 15]. However, most prior RLVR research has focused on other domains, overlooking puzzles potential for delivering effective reward signals. Puzzle Reasoning of LLMs. Unlike knowledge-intensive tasks, puzzles test models reasoning abilities rather than its knowledge or memory capacity [9, 11, 12]. Researchers have proposed various benchmarks to assess different types of reasoning, including abstract [9, 12], deductive [10], and compositional reasoning [13]. Some benchmarks support scalable generation and difficulty control but lack puzzle diversity [10, 12], while others offer diverse formats without controllable difficulty [11]. comprehensive benchmark that balances diversity, scalability, and controllability is still missing. Efforts to improve LLMs puzzle-solving abilities mainly fall into two categories: tool integration and RLVR. Tool-based methods [14] incorporate external resources such as code or symbolic solvers but do not directly enhance the models internal reasoning. Recent RLVR approaches leverage the scalable generation and verification properties of puzzles [15, 16], but often focus on single task type, such as countdown [16] or zebra logic [15], limiting generalization. Our work addresses these gaps by introducing diverse, controllable puzzle datasets and systematically analyzing factors that affect puzzle reasoning performance, including data mixing strategies and multi-task balancing."
        },
        {
            "title": "3 Enigmata-Data: The Puzzle Dataset",
            "content": "In this section, we introduce Enigmata-Data, comprehensive dataset designed to enhance and evaluate the complex reasoning capabilities of LLMs in RLVR training."
        },
        {
            "title": "3.1 Puzzle Categories",
            "content": "As shown in Figure 1, the Enigmata-Data is composed of 36 puzzle tasks of 7 primary categories, including: Crypto Puzzle is designed to evaluate models understanding of cryptography and pattern recognition. Tasks such as Crypto KPA and Crypto KKA require models to decode encrypted messages or solve cryptographic challenges, testing their ability to work with hidden or encoded information. 3 Arithmetic Puzzle challenges models to solve problems that require numerical reasoning and basic arithmetic operations. Puzzles like Game24 and Countdown test models ability to perform arithmetic calculations under constraints. Logic Puzzle assesses deductive reasoning and the ability to infer conclusions based on premises. Puzzles like Knights and Knaves and Zebra Logic test models logical thinking through challenging scenarios that require applying logical rules to solve problems. Grid Puzzle includes tasks that challenge models to solve problems involving structured grids. Puzzles in this category, such as Sudoku and Star Battle, require models to reason about numbers, patterns, and placements in grid format, testing logical and spatial reasoning abilities. Graph Puzzle involves tasks where models must reason about nodes, edges, and paths within graph structures. Challenges such as Hamiltonian Path and NL Navigation test models ability to understand and traverse graphs, evaluating its capacity for path-finding and network navigation. Search Puzzle includes tasks that require models to explore state space efficiently to find correct solution under specific rules and constraints. Puzzles in this category, such as Minesweeper and Tic Tac Toe, challenge models to simulate or search through potential action sequences, evaluate game or puzzle states, and make optimal decisions. These tasks emphasize planning, local and global search, and reasoning under uncertainty. Sequential Puzzle focuses on tasks that involve understanding and predicting sequences of steps. Examples include Eight Puzzle and Fifteen Puzzle, which test models abilities to manipulate objects in sequence or follow series of logical steps to reach solution."
        },
        {
            "title": "3.2 Data Construction",
            "content": "We outline our three-phase data construction pipeline for Enigmata-Data: (1) Tasks Collection and Design; (2) Auto-Generator and Verifier Development; (3) Sliding Difficulty Control. Phase I: Tasks Collection and Design. First, we curate and design 36 logic puzzle tasks that demand complex reasoning capabilities. Among these, 30 tasks are scalable with custom generators for creating additional puzzle instances, while the remaining 6 tasks draw puzzle instances from existing datasets. Most tasks feature multi-step reasoning that integrates various complex reasoning skills. For example, \"Twiddle\" simultaneously tests spatial manipulation and combinatorial planning abilities. Table 1 Task statistics in Enigmata-Data."
        },
        {
            "title": "Task Number",
            "content": "All Puzzles Auto-Generated Puzzles"
        },
        {
            "title": "Crypto Puzzle\nArithmetic Puzzle\nLogic Puzzle\nGrid Puzzle\nGraph Puzzle\nSearch Puzzle\nSequential Puzzle",
            "content": "36 30 2 2 3 10 4 7 8 Phase II: Auto-Generator and Verifier Development. Second, we equip 30 tasks in Enigmata with custom puzzle instance auto-generators, which enable automatic data scaling to generate training and evaluation data tailored to o1-like complex reasoning research. In addition, all 36 puzzle tasks have corresponding auto-verifiers that undergo manual validation. They evaluate the correctness of models outputs or provide outcome rewards and penalty scores for complete reasoning chains. Phase III: Sliding Difficulty Control. For each puzzle task, we identify key variables that control difficulty, such as grid size and blank cell count in Binario. These variables serve as parameters in our auto-generator to create puzzle instances across difficulty levels. We evaluate model performance on these puzzles using the pass@k = EProblems 1 metric (n = 200; = 1, 10, 100) following [24]. We establish three difficulty levels (Easy, Medium, Hard) for each task by analyzing performance trends across different parameter settings. (cid:20) (cid:21) (nc ) (n k) Table 2 Comparison of different puzzle reasoning benchmarks."
        },
        {
            "title": "Tasks",
            "content": "Scalable Auto-Verifier"
        },
        {
            "title": "Solution",
            "content": "KOR-Bench [11] NPR [12] ZebraLogic [10] SearchBench [13] FCoReBench [14] Logic-RL [15] Enigmata 5 1 1 1 5 1 7 125 1 1 11 40 1 36 N/A N/A N/A N/A Prompt-based RLVR RLVR"
        },
        {
            "title": "3.3 Task Statistics",
            "content": "Table 2 presents comparison between Enigmata and existing puzzle resources. Enigmata is the only dataset encompassing multiple task categories, offers scalability, provides automatic verification, and is publicly available. Additionally, it uniquely employs the RLVR approach to enhance models puzzle reasoning capabilities fundamentally. Table 1 presents the distribution of tasks across the Enigmata dataset."
        },
        {
            "title": "3.4 Enigmata-Eval",
            "content": "We develop Enigmata-Eval by systematically sampling from our broader dataset. For each task, we aimed to extract 50 instances per difficulty level (Easy, Medium, Hard). However, due to inherent constraints in some tasks, we collected 4,758 puzzle instances rather than the theoretical maximum of 5,400. This discrepancy arises because some tasks generate fewer than 50 instances per difficulty level, while others rely on manually collected and annotated data rather than auto-generation. Importantly, we ensured no data leakage between training and evaluation sets by implementing strict separation protocols during the sampling process."
        },
        {
            "title": "4 Enigmata-Model: The Training Recipe",
            "content": "Developing advanced logical reasoning in language models requires carefully structured training approach that develops diverse reasoning skills while avoiding overfitting specific problem types. Our training methodology follows two-stage process designed to build reasoning abilities systematically: (1) rejection fine-tuning to establish foundational reasoning patterns and (2) multi-task RL to develop general reasoning skills that transfer across diverse problem domains."
        },
        {
            "title": "4.1 Rejection Fine-tuning",
            "content": "Directly applying reinforcement learning to base model often results in training instability and may not unlock the models full performance potential [2]. To address this, we begin with rejection fine-tuning (RFT), i.e., leveraging high-quality solutions during supervised fine-tuning (SFT) to establish solid foundational reasoning patterns. In our training data, we strategically combine math problems with puzzles, as mathematics elicits diverse reasoning patterns and contributes to the model generalization [25]. For puzzles, we uniformly sample tasks and difficulty levels from the Enigmata dataset to ensure comprehensive coverage and balanced distribution of reasoning patterns. We also include the training data of the ARC-AGI puzzle [9, 26] in the RFT data, since it is too difficult to learn without RFT as cold-start. For each puzzle instance, we utilize DeepSeek-R1 [2] to generate 8 candidate solutions, from which we select the correct solution for RFT. The mathematical component consists of carefully curated examples from high-quality R1-distilled mathematical dataset [27]. Throughout RFT, we maintain balanced 1:1 ratio between puzzles and mathematical problems to ensure comprehensive reasoning development across domains. Detailed implementation and dataset specifications are provided in Appendices and C."
        },
        {
            "title": "4.2 RL with Verifiable Puzzles",
            "content": "We use VC-PPO [28], PPO variant [29], to train our models. Each of the 36 tasks in Enigmata has an automated verifier vi that instantly scores response as correct or incorrect. For 30 tasks we also have generator gi that can create examples at any difficulty; the other 6 tasks draw from fixed pools Fi. For each task and difficulty level Di, we choose how many examples Ni,d to use. Then: (cid:88) (cid:0)Ni,d, d(cid:1), gi si = dDi (cid:88) dDi Sample(cid:0)F , min(Ni,d, i )(cid:1), 30, > 30. The full training set is = (cid:83) si. By changing the Ni,d, we can easily adjust: 1) How many examples come from each task, 2) The mix of easy vs. hard items, 3) Overall dataset size. During training, each generated example is fed to its verifier vi, which returns reward that VC-PPO uses to update the policy. This loop provides fully automatic RL pipeline for puzzle reasoning. si, with total size = (cid:80)"
        },
        {
            "title": "4.3 Multi-task Training",
            "content": "Developing general logical reasoning is hard because different puzzles require different thinking skills. To build strong, transferable problem-solving abilities, we explore two multi-task training methods: Mix-training RL and Multi-stage RL, since single-task training often leads to narrow expertise and poor transfer to new puzzles [15]. rich diversity of tasks can significantly enhance generalization and actively prevent overspecialization [2]. Therefore, we employ Mix-training RL to integrate multiple puzzle types simultaneously during the training process. Our methodology involves meticulously constructed dataset that integrates three critical components: a) The training split of Enigmata, featuring balanced task and difficulty distributions; b) The public training set of ARC-AGI 1 and 2, which improve the generalization of existing reasoning abilities to unseen tasks; and c) AIME mathematical problems (1983-2023), which are difficult enough to elicit diverse reasoning patterns and enhance generalization. strategic 1:1 puzzle-to-mathematics ratio is maintained throughout this training process to foster the development of complementary reasoning systems within the model. Mix-training RL offers broad exposure to different puzzle types, but the varied reasoning skills required can cause conflicts between tasks. To address this, we adopt Multi-stage RL, curriculum-based approach that builds core skills before introducing new challenges. For difficult tasks like ARC-AGI, we use two-phase strategy: 1) train intensively on ARC-AGI 1, 2, and AIME until the model generalizes well and performance stabilizes; 2) gradually introduce Enigmata-Data while retaining earlier data to avoid forgetting. This stepby-step method helps the model learn complex reasoning more effectively and maintain strong performance on earlier tasks. More implementation details are provided in Appendix B."
        },
        {
            "title": "5.1 Experiment Setup",
            "content": "We adopt several challenging reasoning benchmarks for evaluation: Enigmata-Eval, and abstract reasoning challenges ARC-AGI 1 [9] and ARC-AGI 2 [26] known for their extreme difficulty for LLMs. We also include the knowledge-orthogonal reasoning benchmark KOR-Bench [11], which contains puzzles from five categories. To examine generalization capabilities, we include the advanced mathematics benchmark AIME 2024. We evaluate each AIME problem 32 times and others 4 times, reporting the average performance for reliability. Baselines are described in Appendix D. We train our models from Qwen2.5-32B-Instruct [17], solid starting point for training strong reasoning models [2, 30]. After acquiring the RFT model (Qwen2.5-32B-RFT), we leverage the Mix-Training approach with 370 training steps to get the RL model (Qwen2.5-32B-Enigmata), showing superior overall performance in our experiments. Each PPO step performs multiple gradient updates by iterating over 4 mini-batches derived from the training batch. Details are described in Appendix C. 6 Table 3 Performance of reasoning, generic, and our trained LLMs on reasoning benchmarks."
        },
        {
            "title": "Model",
            "content": "o4-mini-high o3-mini-high o1 DeepSeek-R1 Gemini-2.5-Pro Claude-3.7-Sonnet-Thinking DS-R1-Distilled-Qwen-32B QwQ-32B Grok-2-1212 GPT-4o-1120 Claude-3.7-Sonnet Qwen2.5-32B-Instruct Qwen2.5-32B-RFT Qwen2.5-32B-Enigmata"
        },
        {
            "title": "Puzzle",
            "content": "In-Domain Out-of-Domain ARC-AGI 1 ARC-AGI 2 Enigmata-Eval"
        },
        {
            "title": "KORBench",
            "content": "54.7 25.8 29.0 17.8 22.7 37.6 7.9 7.0 7.5 7.3 12.9 6.0 8.4 32.8 2.6 0.4 0.4 0.2 1.4 1.4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0. 65.1 59.9 54.9 49.2 50.6 53.2 31.1 43.8 13.6 14.2 22.7 12.6 46.6 62.6 72.7 69.6 69.9 71.7 68.2 67.8 63.5 61.8 54.9 57.9 56.9 54.7 61.0 65."
        },
        {
            "title": "Math",
            "content": "AIME 24 93.4 87.3 74.3 79.8 90.3 60.3 72.0 69.2 16.7 10.0 23.0 16.6 62.0 60."
        },
        {
            "title": "5.2 Results",
            "content": "According to Table 3, our model outperforms most of the public models on Enigmata-Eval with 32B parameters, demonstrating the effectiveness of our dataset and training recipe. Besides, our model stands out on the challenging ARC-AGI benchmark, surpassing strong reasoning models such as Gemini 2.5 Pro, o3-mini, and o1. Additionally, RFT and multi-task RL training strategies yield significant performance gains on OOD benchmarks. This indicates that our training recipe effectively enhances the models general logic reasoning abilities and can generalize to unseen tasks. Moreover, after RL training, our models maintain comparable math reasoning abilities gained from rejection fine-tuning, showing that our training strategy preserves general reasoning capabilities while enhancing logic-specific skills. Next, lets dive into detailed analysis across reasoning categories in Enigmata-Eval. In Table 4, Qwen2.5-32BEnigmata demonstrates exceptional performance in structured reasoning categories, particularly excelling in Crypto, Arithmetic, and Logic tasks. This suggests that our training approach effectively develops capabilities in rule-based reasoning with explicit constraints and patterns. Besides, our model shows competitive performance in search tasks, outperforming most baseline models. Search problems require strategic exploration of solution spaces and planning capabilities. The strong performance suggests that our approach effectively develops these higher-order reasoning skills. Notably, we observe consistent performance hierarchy across categories for most models. Crypto and Arithmetic tasks tend to yield the highest accuracy, while spatial and sequential tasks remain more difficult. These challenges point to promising directions for future work."
        },
        {
            "title": "5.3 Generalization with Scaling: Free Lunch from Enigmata",
            "content": "Can logical reasoning data, such as puzzles that do not require domain knowledge, benefit general reasoning capabilities? We do not observe such generalization for Qwen2.5-32B. Therefore, we scale the experiments to much larger model. We follow Seed1.5-Thinking [5] and train from the same Mixture-of-Experts (MoE) model in the RL stage, which features 20B activated and 200B total parameters. To make fair comparison between Seed1.5-Thinking, we adopt the same base model (20B/200B) and the same RL training data except for 20K Enigmata-Data, and train the models for comparable PPO steps. Surprisingly, the results in Table 5 show that our dataset enhances general capabilities like math and STEM problem-solving. When compared to Seed1.5-Thinking, leading reasoning model, additional training with Enigmata, i.e., Seed1.5-Thinking-Enigmata, generally improves performance on AIME 2024 and 2025, BeyondAIME [5] (an expert-curated, more challenging evaluation dataset), and GPQA Diamond [31]. Given 7 Table 4 Performance of reasoning LLMs, generic LLMs, and our trained LLMs on Enigmata-Eval."
        },
        {
            "title": "Sequential Overall",
            "content": "o4-mini-high o3-mini-high o1 DeepSeek-R1 Gemini-2.5-Pro Claude-3.7-Sonnet-Thinking DS-R1-Distilled-Qwen-32B QwQ-32B Grok-2-1212 GPT-4o-1120 Claude-3.7-Sonnet Qwen2.5-32B-Instruct Qwen2.5-32B-RFT Qwen2.5-32B-Enigmata 97.0 88.1 97.8 82.7 75.2 81.5 16.7 59.0 10.1 26.2 38.1 12.6 62.0 96. 93.3 76.9 80.0 77.1 95.4 75.4 47.3 65.7 9.4 1.9 16.7 4.0 71.7 93.7 82.2 74.3 60.1 71.4 71.5 76.6 62.9 74.4 50.0 34.5 60.0 10.3 71.6 90. 71.0 65.5 63.3 51.1 58.9 57.7 38.2 47.5 12.8 17.8 22.9 46.4 51.3 62.6 62.4 63.1 56.2 62.6 37.3 50.5 36.4 47.3 17.6 19.3 22.4 15.3 55.1 54. 64.3 61.5 50.9 38.4 49.4 49.4 12.4 28.2 3.9 6.0 7.8 7.3 39.3 70.4 34.0 29.6 23.6 19.5 17.5 26.4 18.8 24.4 6.4 3.9 15.0 2.5 18.4 29. 65.1 59.9 54.9 49.2 50.6 53.2 31.1 43.8 13.6 14.2 22.7 8.2 46.6 62.6 Table 5 Results on benchmarks for general reasoning capabilities. This demonstrates that additional RL training on Enigmata-Data generalizes well on larger models, showing the benefits of puzzle data for math and STEM reasoning."
        },
        {
            "title": "Model",
            "content": "o4-mini-high o3-mini-high o1 DeepSeek-R1 AIME 2024 AIME"
        },
        {
            "title": "BeyondAIME GPQA Diamond",
            "content": "93.4 87.3 74.3 79.8 92.7 86.5 79.2 65.0 55.7 63.6 50.0 42.4 81.4 79.7 78.0 71.5 Seed1.5-Thinking Seed1.5-Thinking-Enigmata 86.7 87.5(+0.8) 74.0 75.9(+1.9) 48.0 48.4(+0.4) 77.3 78.1(+0.8) the difficulty of further improving SoTA models like Seed1.5-Thinking, simply incorporating Enigmata synthetic puzzle data during the RL training stage appears almost like free lunch for expanding the capability spectrum of reasoning models, even leading to generalization improvements in general advanced reasoning."
        },
        {
            "title": "5.4 Ablation Studies\nTraining Data Size. We study the impact of varying sizes of Enigmata-Train data on model performance\nduring the second stage of Multi-stage Training. To ensure a fair comparison, all checkpoints were evaluated\nusing models obtained at step 150 from the sample stage-1 checkpoint, with equal sampling across all\ndifficulty levels. As shown in Figure 2, first, a small amount of Enigmata-Train data in the second stage\nsignificantly improves Enigmata-Eval performance while better preserving first-stage knowledge and OOD\nperformance. Second, increasing Enigmata-Train data progressively enhances in-domain Enigmata-Eval\nperformance. Third, excessive Enigmata-Train data leads to catastrophic forgetting and slightly degraded\nOOD performance.",
            "content": "Data Difficulty Control. We study how the distribution of data difficulty affects performance. As described . With Ni = 400 per task, we compare two in 4.2, we set the data size at different difficulty levels as easy : med ratios in Multi-stage Trainings second stage: balanced (N =1:1:1) versus medium-focused easy (N = 2:6:2). The latter setting quantifies how extreme samples can undermine RL training [20]. We also compare with historical reward variation (HRV) [32] as baseline data selection strategy, : hard : med : hard Note that, we primarily experiment upon Qwen2.5-32B for further analysis due to the prohibitive resources required to train 20B/200B model. 8 Figure 2 Impact of training data size in the second stage of Multi-stage Training on model performance across different benchmarks. The blue dashed line represents model performance after the first training stage, while the red solid line shows performance after the second stage. Table 6 Comparison between different data mixing strategies in the stage 2 of Multi-stage RL."
        },
        {
            "title": "Puzzle",
            "content": "In-Domain Out-of-Domain ARC-AGI 1 ARC-AGI 2 Enigmata-Eval"
        },
        {
            "title": "KORBench",
            "content": "HRV Easy:Medium:Hard = 1:1:1 Easy:Medium:Hard = 2:6:2 34.7 34.5 35.1 0.1 0.6 0.3 57.7 58.5 58.9 60.1 64.0 63."
        },
        {
            "title": "Math",
            "content": "AIME 24 50.1 56.6 48.0 using the same stage-1 checkpoint and 150 second-stage steps. As shown in Table 6, the balanced difficulty ratio (1:1:1) enables the model to demonstrate more robust complex reasoning performance. Also, our effortless difficulty control method based on difficulty tags in Enigmata data performs comparably to HRV on Enigmata-Eval while delivering superior results on OOD benchmarks. Multi-task Training. For the two training paradigms (Multi-stage RL and Mix-Training RL) in 4.3, we evaluate the impact of SFT/RFT using two variants: 1) SFTPart, which excludes three tasks (Countdown, Minesweeper, Light Up) to test transfer ability; and 2) SFTAll, which includes all tasks as complete baseline. To ensure fair comparison, all checkpoints were trained for identical total steps: (1) Multi-Stage training consisting of 200 steps in stage 1 and 225 steps in stage 2; and (2) Mix-Training using the combined dataset across all 425 steps. As shown in Table 7, first, Multi-Stage and Mix-Training approaches show complementary strengths. Multi-Stage builds deeper task-specific reasoning, while Mix-Training improves generalization. Second, With limited pre-training data, Multi-Stage transfers better to unseen tasks, especially complex ones like Enigmata and ARC-AGI, reflecting curriculum learning benefits. Third, Mix-Training generalizes better to OOD tasks, suggesting that diverse training helps models learn broader reasoning strategies beyond specific tasks. Moreover, Figure 4 shows Mix-Training RLs and Multi-Stage RLs training dynamics. We observe positive correlation between rewards and response length. Both approaches achieve similar final rewards, showing the signs of test-time scaling effect [33, 34] where models learn to explore more tokens to find better solutions. However, the more volatile response length under Multi-Stage RL suggests instability in generation. In contrast, Mix-Training RL yields more consistent outputs with smoother length curves, indicating greater training stability."
        },
        {
            "title": "5.5 Analysis\nHow does SFT affect RL training? We further analyze the influence of SFT on RL training to ex-\nplore the reason behind the performance gap in Table 4.3. We represent the reward curves across dif-\nferent training steps for different training approaches in Figure 3. For simple tasks like Countdown, all\nmethods achieve similar improvements, suggesting that SFT is not essential. For medium-complexity",
            "content": "9 Table 7 Comparison between different training strategies."
        },
        {
            "title": "Puzzle",
            "content": "In-Domain Out-of-Domain ARC-AGI 1 ARC-AGI 2 Enigmata-Eval"
        },
        {
            "title": "KORBench",
            "content": "Mix Training + SFT-Part Multi-Stage + SFT-Part Mix Training + SFT-All Multi-Stage + SFT-All 22.7 27.5 34.5 33.4 0.0 0.0 0.1 0.4 46.7 56.1 62.6 61.1 56.7 51.6 60.4 60."
        },
        {
            "title": "Math",
            "content": "AIME 24 51.8 45.9 58.8 55.6 Figure 3 Learning curves across training approaches for representative puzzle tasks. Each row represents different task, and each column represents different training approach. The curves show how the average reward changes with training steps for different difficulty levels. tasks like Minesweeper, Mix-Training struggles without SFT, while Multi-stage RL still learns effectively. When the task is included in SFTAll, both approaches start from higher baseline and quickly optimize to nearperfect accuracy. This pattern is typical for tasks with fixed solution patterns or shortcutsonce the model grasps the solving approach, performance improves dramatically. For high-complexity tasks like Light Up, the combination of comprehensive SFT and Multi-stage RL dramatically outperforms all other approaches, particularly for difficult variants of the task. Interestingly, Mix-Training RL without relevant SFT (c) fails, highlighting that complex reasoning tasks require both strong foundational knowledge (from relevant SFT) and structured learning approaches (from Multi-stage RL) to achieve optimal results. Table 8 Impact of code utilization on Qwen2.5-32BEnigmata accuracy"
        },
        {
            "title": "Overall\nWith code\nWithout code",
            "content": "62.6 41.8 63.6 34.5 12.5 35.7 ARC-AGI"
        },
        {
            "title": "Condition",
            "content": "Response Length Analysis. Figure 5 presents the distribution of reasoning token lengths for both correct and incorrect responses in ARC-AGI 1. Tasks, where the model produces more concise reasoning, showed significantly higher accuracy than those requiring longer reasoning chains. This analysis identifies potential inefficiencies in the models reasoning process and highlights opportunities for reasoning optimization. 10 Figure 4 The response length and reward curves during Mix-Training RL and Multi-Stage RL training. Figure 5 Performance analysis of Qwen2.5-32B-Enigmata on ARC-AGI 1: (a) distribution of reasoning token lengths for correct and incorrect responses, (b) and success rate by reasoning token length. Code Utilization in Puzzle Reasoning. We investigated whether code utilization enhances model performance on reasoning tasks. We identified code elements in model outputs using keyword detection and pattern matching and classified responses accordingly. According to Table 8, code utilization hindered puzzle task performance. This suggests that current models fail to effectively use code without executing it for complex reasoning tasks."
        },
        {
            "title": "6 Conclusion",
            "content": "In this paper, we present Enigmata, suite for equipping LLMs with advanced puzzle reasoning, which integrates seamlessly with reinforcement learning using verifiable rule-based rewards. Enigmata-Data features 36 tasks across seven reasoning categories, with its scalable generation, automated verification, and adjustable difficulty. We also introduce the Enigmata-Eval benchmark for assessing puzzle reasoning abilities and guiding research on generalizable reasoning models. Enigmata-Model, trained with RLVR, demonstrates its superior performance and robust generalization and reasoning skills. Experiments also demonstrate that when trained on larger models such as Seed1.5-Thinking (20B/200B), synthetic puzzle data brings extra benefits in other domains, such as math and STEM reasoning, over SoTA model. We hope Enigmata serves as solid foundation for the community to push forth the research on reasoning models."
        },
        {
            "title": "Project Lead",
            "content": "Jiangjie Chen1,6 Core Contributors Jiangjie Chen1,6, Qianyu He1,2, Siyu Yuan1,2, Aili Chen2 Contributors Zhicheng Cai4,6, Weinan Dai1,3,6, Hongli Yu1,3,6, Qiying Yu1,3,6, Xuefeng Li1,5, Jiaze Chen"
        },
        {
            "title": "Supervisors",
            "content": "Hao Zhou3,6, Mingxuan Wang1,"
        },
        {
            "title": "Affiliation",
            "content": "1ByteDance Seed 2Fudan University 3Institute for AI Industry Research (AIR), Tsinghua University 4Nanjing University 5Shanghai Jiao Tong University 6SIA-Lab of Tsinghua AIR and ByteDance Seed Equal Contribution. Order decided by institutions. Work done during internship at ByteDance Seed."
        },
        {
            "title": "References",
            "content": "[1] OpenAI. Learning to reason with llms, 2024. [2] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [3] Google. Gemini 2.5: Our most intelligent ai model, 2025. [4] Anthropic. Claude 3.7 sonnet and claude code, 2025. [5] ByteDance Seed, Yufeng Yuan, Yu Yue, Mingxuan Wang, Xiaochen Zuo, Jiaze Chen, Lin Yan, Wenyuan Xu, Chi Zhang, Xin Liu, et al. Seed-thinking-v1. 5: Advancing superb reasoning models with reinforcement learning. arXiv preprint arXiv:2504.13914, 2025. [6] Zhangchen Xu, Yang Liu, Yueqin Yin, Mingyuan Zhou, and Radha Poovendran. Kodcode: diverse, challenging, and verifiable synthetic dataset for coding. arXiv preprint arXiv:2503.02951, 2025. [7] Alon Albalak, Duy Phung, Nathan Lile, Rafael Rafailov, Kanishk Gandhi, Louis Castricato, Anikait Singh, Chase Blagden, Violet Xiang, Dakota Mahan, et al. Big-math: large-scale, high-quality math dataset for reinforcement learning in language models. arXiv preprint arXiv:2502.17387, 2025. [8] Zhiwei He, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xingyu Chen, Yue Wang, Linfeng Song, Dian Yu, Zhenwen Liang, Wenxuan Wang, et al. Deepmath-103k: large-scale, challenging, decontaminated, and verifiable mathematical dataset for advancing reasoning. arXiv preprint arXiv:2504.11456, 2025. [9] François Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547, 2019. [10] Bill Yuchen Lin, Ronan Le Bras, Kyle Richardson, Ashish Sabharwal, Radha Poovendran, Peter Clark, and Yejin Choi. Zebralogic: On the scaling limits of llms for logical reasoning. arXiv preprint arXiv:2502.01100, 2025. [11] Kaijing Ma, Xinrun Du, Yunran Wang, Haoran Zhang, Zhoufutu Wen, Xingwei Qu, Jian Yang, Jiaheng Liu, Minghao Liu, Xiang Yue, et al. Kor-bench: Benchmarking language models on knowledge-orthogonal reasoning tasks. arXiv preprint arXiv:2410.06526, 2024. [12] Zixuan Wu, Francesca Lucchetti, Aleksander Boruch-Gruszecki, Jingmiao Zhao, Carolyn Jane Anderson, Joydeep Biswas, Federico Cassano, Molly Feldman, and Arjun Guha. Phd knowledge not required: reasoning challenge for large language models. arXiv preprint arXiv:2502.01584, 2025. [13] Nasim Borazjanizadeh, Roei Herzig, Trevor Darrell, Rogerio Feris, and Leonid Karlinsky. Navigating the labyrinth: Evaluating and enhancing llms ability to reason about search problems. arXiv preprint arXiv:2406.12172, 2024. [14] Chinmay Mittal, Krishna Kartik, Mausam, and Parag Singla. Fcorebench: Can large language models solve challenging first-order combinatorial reasoning problems?, 2025. [15] Tian Xie, Zitian Gao, Qingnan Ren, Haoming Luo, Yuqian Hong, Bryan Dai, Joey Zhou, Kai Qiu, Zhirong Wu, and Chong Luo. Logic-rl: Unleashing llm reasoning with rule-based reinforcement learning. arXiv preprint arXiv:2502.14768, 2025. [16] Jiayi Pan, Junjie Zhang, Xingyao Wang, Lifan Yuan, Hao Peng, and Alane Suhr. Tinyzero. https://github.com/Jiayi-Pan/TinyZero, 2025. Accessed: 2025-01-24. [17] Qwen Team. Qwen2.5: party of foundation models, September 2024. [18] Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599, 2025. [19] Yufeng Yuan, Qiying Yu, Xiaochen Zuo, Ruofei Zhu, Wenyuan Xu, Jiaze Chen, Chengyi Wang, TianTian Fan, Zhengyin Du, Xiangpeng Wei, et al. Vapo: Efficient and reliable reinforcement learning for advanced reasoning tasks. arXiv preprint arXiv:2504.05118, 2025. [20] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, et al. Dapo: An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476, 2025. 13 [21] Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee Sun Lee, and Min Lin. Understanding r1-zero-like training: critical perspective. arXiv preprint arXiv:2503.20783, 2025. [22] Jingcheng Hu, Yinmin Zhang, Qi Han, Daxin Jiang, Xiangyu Zhang, and Heung-Yeung Shum. Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model. arXiv preprint arXiv:2503.24290, 2025. [23] Jiawei Liu and Lingming Zhang. Code-r1: Reproducing r1 for code with reliable rewards. arXiv preprint arXiv:2503.18470, 2025. [24] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. [25] Wei Shen, Guanlin Liu, Zheng Wu, Ruofei Zhu, Qingping Yang, Chao Xin, Yu Yue, and Lin Yan. Exploring data scaling trends and effects in reinforcement learning from human feedback. arXiv preprint arXiv:2503.22230, 2025. [26] Greg Kamradt."
        },
        {
            "title": "Abstraction and reasoning corpus for artificial general",
            "content": "intelligence v2 (arc-agi-2). https://github.com/arcprize/ARC-AGI-2, 2025. Accessed: 2025-05-12. [27] Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, Zhenyu Duan, Yimin Du, Junchen Liu, Lifu Tang, Xiaowei Lv, Haosheng Zou, Yongchao Deng, Shousheng Jia, and Xiangzheng Zhang. Light-r1: Curriculum sft, dpo and rl for long cot from scratch and beyond. arXiv preprint arXiv:2503.10460, 2025. [28] Yufeng Yuan, Yu Yue, Ruofei Zhu, Tiantian Fan, and Lin Yan. Whats behind ppos collapse in long-cot? value optimization holds the secret. arXiv preprint arXiv:2503.01491, 2025. [29] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. [30] Qwen Team. Qwq-32b: Embracing the power of reinforcement learning, March 2025. [31] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. GPQA: graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024. [32] Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, et al. Reinforcement learning for reasoning in large language models with one training example. arXiv preprint arXiv:2504.20571, 2025. [33] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314, 2024. [34] Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Zhihan Guo, Yufei Wang, Irwin King, Xue Liu, and Chen Ma. What, how, where, and how well? survey on test-time scaling in large language models. arXiv preprint arXiv:2503.24235, 2025. [35] Timo Kaufmann, Paul Weng, Viktor Bengs, and Eyke Hüllermeier. survey of reinforcement learning from human feedback. arXiv preprint arXiv:2312.14925, 10, 2023. [36] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles, 2023. [37] OpenAI. GPT4 technical report. arXiv preprint arXiv:2303.08774, 2023. [38] x.ai. Bringing grok to everyone, 2025. [39] jeggers. full_crossword_puzzles. https://huggingface.co/datasets/jeggers/full_crossword_puzzles. Accessed: 2025-05-15. [40] Qiming Bao, Gael Gendron, Alex Yuxuan Peng, Wanjun Zhong, Neset Tan, Yang Chen, Michael Witbrock, and Jiamou Liu. Assessing and enhancing the robustness of large language models with task structure variations for logical reasoning. arXiv preprint arXiv:2310.09430, 2023. 14 [41] Gaël Gendron, Qiming Bao, Michael Witbrock, and Gillian Dobbie. Large language models are not strong abstract reasoners. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI 24, 2024. [42] BIG bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research, 2023. [43] Roxana Szomiu and Adrian Groza. puzzle-based dataset for natural language inference. arXiv preprint arXiv:2112.05742, 2021. [44] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, et al. Folio: Natural language reasoning with first-order logic. arXiv preprint arXiv:2209.00840, 2022."
        },
        {
            "title": "A Reward Curves Across Individual Tasks in Enigmata",
            "content": "We conducted detailed analysis of our models learning dynamics by examining reward curves across all tasks in the Enigmata dataset. Figure 6 presents these learning trajectories, revealing several important patterns in how models acquire puzzle-solving capabilities. The reward curves across tasks reveal three distinct learning patterns: 1. Gradual Mastery Tasks: Several tasks, such as Light Up and Zebra Logic show smooth and consistent reward gains throughout training. These tasks typically involve complex reasoning chains or require integrating multiple constraints, making them suitable for long-horizon learning. The steady upward trend suggests that the agent is progressively refining its decision-making strategy through extended exploration. 2. Difficulty-Stratified Tasks: Tasks like Car Painting, Star Battle, and Hitori demonstrate clear separation between difficulty levels: easy instances are learned relatively early, while medium and hard variants require significantly more training to improve. This stratification indicates that the difficulty scaling mechanism is practical and yields meaningful distinctions in learning complexity. 3. Stagnant or Low-Learning Tasks: Some tasks, including Big Bench Symbolic and Magic Square, show little to no improvement across all difficulty levels, particularly on the challenging setting. This suggests that these tasks may suffer from challenges such as sparse rewards, long-term dependencies, or overly complex solution spaces that PPO struggles to handle without additional guidance. These learning patterns offer actionable insights for curriculum design. Tasks mastered early can serve as warm-up phases to bootstrap the agents core skills, while more challenging tasks can be introduced later to push reasoning boundaries. Understanding which tasks exhibit positive transfer or potential interference is key to optimizing multi-task training regimes. Table 9 Training data distribution across different strategies and stages."
        },
        {
            "title": "Method",
            "content": "Enigmata-Data ARC-AGI 1 ARC-AGI 2 AIME Mix-Training Multi-Stage Stage 1 Multi-Stage Stage 2 11557 0 11557 3160 3160 395 5934 5934 989 1738"
        },
        {
            "title": "B Training Dataset Details",
            "content": "B.1 Rejection Fine-tuning. For the puzzle part of the Rejection Finetuning (RFT) dataset, we sample 1,000 instances from each task in the Enigmata dataset. We also include synthetic ARC-AGI data. We then use DeepSeek-R1 to generate 8 candidate solutions for each instance and select one correct solution per instance. The final puzzle dataset contains 12,041 high-quality puzzle samples. For the mathematical part of the RFT dataset, we collected mathematical problems from light-R1 [27] that DeepSeek-R1 answered. We included all data from stage 2 of light-R1 and sampled 3,000 additional problems from stage 1, resulting in 12,533 mathematical samples. https://github.com/neoneye/arc-dataset-collection/blob/main/dataset/ARC-Heavy/readme.md 16 B.2 Reinforcement with Verifiable Puzzles. For our reinforcement learning with verifiable puzzles, we implemented two training paradigms. The detailed data mixing ratio is shown in Table 9 and introduced below. As for the Mix-Training, the dataset for this approach consists of three components: (1) Enigmata-Train: 400 samples per task with equal distribution across difficulty levels. Note that we excluded eight tasks from the training set: six tasks deemed too difficult (Eight Puzzle, Fifteen Puzzle, Nine Puzzle, Sixteen Puzzle, Natural Language Navigation, Slant), one task too simple (Game24) based on pass@k evaluation, and one task lacking training data (FOLIO). (2) ARC-AGI 1 and 2: Official datasets upsampled 8x to address specific reasoning challenges, (3) AIME problems from 1983-2023 upsampled 2x as the mathematical component. As for the Multi-stage RL, this approach follows curriculum strategy with two distinct stages: (1) Stage 1: Training on ARC-AGI 1 and 2 (upsampled 8x) along with AIME problems (upsampled 1x) (2) Stage 2: Incorporating Enigmata-Train while maintaining the datasets from Stage 1 (ARC-AGI 1, ARC-AGI 2, and AIME) without additional upsampling to prevent catastrophic forgetting"
        },
        {
            "title": "C Implementation Details",
            "content": "We finetune the model on this balanced dataset for 2 epochs using maximum sequence length of 32768 tokens and learning rate 1e-5, establishing strong reasoning foundation before proceeding to reinforcement learning. We adopt variant of Proximal Policy Optimization (PPO) [29], i.e., VC-PPO [28], to train our reasoning agent on verifiable puzzles. This variant introduces several modifications tailored to long-chain-of-thought generation, improving training stability and performance over long sequences. Standard PPO optimizes the following clipped objective: JPPO(θ) = E(q,a)D,otπθold min rt(θ) ˆAt, clip(rt(θ), 1 ε, 1 + ε) ˆAt , (1) (cid:34) (cid:32) (cid:33)(cid:35) where rt(θ) = πθ(otq,o<t) πθold (otq,o<t) ˆAt using Generalized Advantage Estimation (GAE) [29]: is the importance sampling ratio, and ˆAt is the estimated advantage. We compute GAE(γ,λ) ˆA = (cid:88) l=0 (γλ)lδt+l, where δl = Rl + γV (sl+1) (sl). (2) To optimize long-CoT training, we follow the VC-PPO and adopt the following modifications to the standard PPO algorithm: Removing KL Divergence Constraint. In traditional RLHF [35], KL penalty is used to prevent the policy from diverging too far from the reference model. However, in long-CoT settings, this constraint often limits exploration and learning capacity. Following VC-PPO, we remove the KL term by setting kl_loss_weight = 0.0, allowing the model to deviate from the initial policy distribution freely. Value Pretraining. We observe that initializing the value model from the reward model causes unstable training due to their objective mismatch. To address this, we adopt value pretraining: first sample responses from fixed SFT policy πsft, compute Monte Carlo returns, and train the value model until the loss and explained variance converge. The pretrained value model is then used to initialize the critic for PPO. Decoupled GAE. We use different λ values for the policy and the value model to reduce reward decay and improve optimization over long token sequences. Specifically, we set λcritic = 1.0 for unbiased value estimation, and λpolicy = 0.95 to improve sample efficiency and learning speed. 17 Training Details. We set the maximum prompt length to 6,144 tokens and the maximum response length to 26,624 tokens. PPO training is conducted for 425 steps with batch size 4,096 and mini-batch size 512. The actor and critic are optimized using Adam, with learning rates of 1 106 and 2 106, respectively, and linear warm-up schedule over 10 steps. Before PPO begins, we perform value pretraining [28] for 15 steps by collecting Monte Carlo returns from fixed SFT policy and fitting the value model to these returns. Our implementation is based on the VeRL framework. We enable gradient checkpointing for both the actor and the critic to reduce memory consumption. Rollouts are generated using temperature sampling (τ = 1.0), with enforced end-of-sequence tokens. We leverage vLLM [36] for efficient batched decoding with 256 rollout slots and paged attention."
        },
        {
            "title": "D Baselines",
            "content": "We categorize our baseline models into the following groups for comparison: General-purpose LLMs. As reference benchmarks, we also included several top-tier general-purpose models: GPT-4o-1120 [37]: OpenAIs model, representing the current highest standard of general models. Gemini 2.5 Pro [3]: Googles advanced model with excellent performance across various tasks. Claude 3.7 Sonnet [4]: Anthropics high-performance model known for its reliability and comprehensiveness. Grok-2-1212 [38]: xAIs open-weight model, demonstrating the potential of open-source models. Qwen-2.5-32B-Instruct [17]: Alibabas moderate-scale language model with strong performance in both Chinese and English tasks, which serves as our main backbone model for training. Reasoning-specialized LLMs. We selected the current state-of-the-art models specialized in reasoning: o1 [1], o3-mini [1], and o4-mini [1]: Representing OpenAIs advancements in reasoning capabilities, particularly excelling in solving complex problems. DeepSeek-R1 [2]: model optimized for mathematical and reasoning tasks, with outstanding performance in multi-step reasoning. Claude-3.7-Sonnet-Thinking [4]: Employing specialized chain-of-thought design to enhance capabilities in solving complex reasoning tasks. DeepSeek-R1-Distilled-Qwen2.5-32B [2]: Transferring DeepSeek-R1s reasoning capabilities to smaller model through knowledge distillation. QwQ-32B [30]: Alibabas reasoning model trained from Qwen-2.5-32B. This categorized comparison allows us to comprehensively evaluate our models performance in both specialized reasoning capabilities and general abilities, while comparing against different types of state-of-the-art models. For evaluation, we use temperature sampling (τ = 1.0)."
        },
        {
            "title": "Limitations",
            "content": "Due to the limited time and resources, we did not train on other backbone models with Enigmata-Data, or with RL algorithms other than VC-PPO. However, we believe the results from our experiments can be generalized to other back models and algorithms. Additionally, our data is all in single-turn textual form, and we did not include multi-turn puzzles or visual puzzles into Enigmata we leave for future research. Due to the research purpose of this work, we only train LLMs with hundreds of competitive math problems along with Enigmata-Data. In practice, our training resources could easily be included in an already comprehensive training set while maintaining (if not surpassing) the original performance of tasks in the original dataset. https://github.com/volcengine/verl. 18 Figure 6 Reward curves for Qwen2.5-32B-Enigmata across all individual tasks during training. Each subplot represents different puzzle task, with the x-axis showing training steps and the y-axis showing average reward. Colors indicate different difficulty levels: Easy (green), Medium (blue), and Hard (red)."
        },
        {
            "title": "E Enigmata Details",
            "content": "This section details the Enigmata dataset, including task specifications, difficulty estimation methodology, and example cases. E.1 Task Details We present the detailed specifications of all tasks in Enigmata in Tables 10, 11, and 12. These tables provide comprehensive information about each task, including: (1) Task category: Enigmata encompasses seven distinct reasoning categories. (2) Data source: Whether the task is automatically generated or sourced from existing datasets. (3) Difficulty control variables: The specific parameters used to adjust task difficulty. (4) Rule descriptions: Concise explanations of each puzzle types rules. These details illustrate the diversity and controllability of the Enigmata dataset, highlighting how each task contributes to different aspects of reasoning assessment. E.2 Difficulty Estimation In Section 3.2, we introduce our method for difficulty control in Enigmata: determining different difficulty levels (easy, medium, hard) for puzzles through model pass@k metrics. Specifically, we use GPT-4os pass@k (k=1,10,100) to establish these difficulty tiers. Table 13 showcases specific examples of puzzles at different difficulty levels. As demonstrated, there are clear distinctions in model pass@k performance between easy, medium, and hard levels across various tasks. 20 Task"
        },
        {
            "title": "Binario",
            "content": "Table 10 Details of 36 tasks in Enigmata. Categories Source Difficulty Vriables Rules"
        },
        {
            "title": "Auto",
            "content": "grid size n, mask rate r, minimal filled cells f"
        },
        {
            "title": "Auto",
            "content": "grid height h, grid width w, tent count grid size n, mask rate r"
        },
        {
            "title": "Auto",
            "content": "grid size n"
        },
        {
            "title": "Auto",
            "content": "grid size n"
        },
        {
            "title": "Auto",
            "content": "grid size n, number of star Sudoku"
        },
        {
            "title": "Auto",
            "content": "mask rate r"
        },
        {
            "title": "Auto",
            "content": "mask rate r"
        },
        {
            "title": "Grid",
            "content": "[39] grid size n"
        },
        {
            "title": "Grid",
            "content": "[40, 41] passrate/pass@k Given partially filled binary grid, determine its unique completion such that each row and column contains an equal number of 0s and 1s, no more than two identical digits are adjacent, and all rows and columns are pairwise distinct. Given grid with designated tree cells and empty cells, place tents on empty cells such that each tent is orthogonally adjacent to exactly one tree, no two tents are adjacent (including diagonally), and the number of tents in each row and column matches the specified totals. Complete the partially filled NN magic square by assigning distinct integers to the empty cells such that all rows, columns, and both main diagonals sum to magic number, while preserving the given entries and satisfying all structural constraints. Given an NN grid, assign each cell unique building height from 1 to per row and column, such that the number of visible buildings from each edge matches the provided visibility constraints, with taller buildings obscuring shorter ones. Return valid configuration or report infeasibility. Given an grid, fill it with numbers 1 to without repetition in any row or column, such that from each edge, the sum of visible building heightswhere taller buildings block shorter ones behindis equal to the corresponding clue. Given an NN grid composed of empty cells and blocked cells, place exactly one star in each row and each column such that stars occupy only empty cells and no two stars are adjacent horizontally, vertically, or diagonally. Given partially filled 44 Sudoku grid with digits 14, fill in the remaining cells so that each row, column, and 22 subgrid contains each digit exactly once. Given partially filled 99 Sudoku grid, complete it so that each row, column, and 33 subgrid contains the digits 1 through 9 exactly once. Given fixed crossword grid with blank and blocked cells, fill all blank cells with letters to form valid English words that satisfy the provided across and down clues, ensuring consistency at intersections. Given symbolic 2D grid of numbers, learn the transformation rule across rows and apply it to generate the consistent output pattern, preserving vertical segment structures and alternating 0s in specific column bands."
        },
        {
            "title": "Auto",
            "content": "plaintext length l, encryption method e, keyword length k, shift in Caesar s, rails in Rail Fence r, a/b range in Affine r, matrix size in Hill Known Key Attack-style Decryption. Given an encrypted ciphertext and the specification of an encryption method (e.g., Caesar, Vigenère, Hill, etc.), recover the original plaintext without being given the encryption algorithm or decryption procedure. The task requires understanding of classical ciphers and applying the correct decryption logic based on the cipher name and parameter settings. plaintext length l, encryption method e, keyword length k, hint range h, shift in Caesar s, rails in Rail Fence r, a/b range in Affine r, matrix size in Hill reverse-engineer Known Plaintext Attack-style Decryption. Given ciphertext and plaintext-ciphertext example pair only, the encryption transformationwithout being given the algorithmic rule or keyand apply the inferred pattern to decrypt the target ciphertext. The task involves cryptanalytic genlearning transformation from single eralization: annotated example, and applying it to unseen input. Table 11 Details of 36 tasks in Enigmata. Task"
        },
        {
            "title": "Twiddle",
            "content": "Categories Source Difficulty Vriables Rules"
        },
        {
            "title": "Auto",
            "content": "grid size , number of rotations Given an NXN grid of distinct numbers from 1 to n2, restore it to row-major order using sequence of counterclockwise kxk subgrid rotations, each specified by its top-left coordinate."
        },
        {
            "title": "Auto",
            "content": "number of cars , number of color type , shift range k, skew range Given fixed initial sequence of cars to be painted, each car may be moved up to positions forward or backward; the objective is to reorder the cars, within this constraint, to minimize adjacent color transitions (color switches)."
        },
        {
            "title": "Auto",
            "content": "sequence length l"
        },
        {
            "title": "Sequential",
            "content": "[40, 41] passrate/pass@k Given an input sequence, determine whether target output sequence can be produced using stack with only push (in order) and pop operations, ensuring lastin-first-out (LIFO) behavior. Given sequence of input-output list pairs, identify and apply the underlying symbolic transformation function to new input list to produce its corresponding output."
        },
        {
            "title": "Auto",
            "content": "number of inversion nGiven 33 grid representing an 8-puzzle state, output the shortest sequence of moves (Up, Down, Left, Right) to reach the goal configuration [[1, 2, 3], [4, 5, 6], [7, 8, 0]], or indicate if no solution exists. number of inversion nGiven 44 grid representing 15-puzzle state, output the shortest sequence of moves (U, D, L, R) to reach the goal configuration [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 0]], or report if no solution exists. number of inversion nGiven 33 grid of numbers 19, the player can circularly shift any row or column by 1 or 2 positions. Determine sequence of moves that results in the grid sorted in ascending order, or report that it is unsolvable. number of inversion nGiven 44 grid containing tiles numbered 116, players may circularly shift any row or column by 1 to 3 positions to sort the grid into ascending order; determine valid move sequence or prove it unsolvable."
        },
        {
            "title": "Auto",
            "content": "grid size n"
        },
        {
            "title": "Auto",
            "content": "grid size , black rate r"
        },
        {
            "title": "Auto",
            "content": "grid size , black cell ratio r1 , numbered ratio r2 Given an NxN grid of numbers, black out cells to ensure each row and column contains no duplicate numbers, no two blacked cells are orthogonally adjacent, and all remaining white cells form single connected group. Given grid with row and column sum constraints, select black cells such that the sum of their positions in each row and column equals the respective targets, where each cells value is its 1-based index. Given rectangular grid with black numbered and unnumbered cells, place bulbs on empty cells to illuminate all white cells without lighting another bulb, ensuring each numbered black cell has exactly that many adjacent bulbs."
        },
        {
            "title": "Auto",
            "content": "board size , mine density , initial reveal ratio Given partially revealed Minesweeper grid, identify all unrevealed cells that must contain mines, based solely on the numerical clues and adjacency constraints."
        },
        {
            "title": "Auto",
            "content": "board row , board col d, hint ratio h"
        },
        {
            "title": "Search",
            "content": "[42] passrate/pass@k Given grid with numeric constraints at intersections, assign diagonal slashes(two directions) to each cell such that intersection counts are satisfied and no loops are formed. Given legal board configuration, find move that results in immediate checkmatei.e., the opposing king is placed in check and has no legal way to escape."
        },
        {
            "title": "Auto",
            "content": "board size , comparative potential center control c, fork score Given partially filled NN Tic Tac Toe board and the active player, identify the optimal move that maximizes the players winning chances or prevents immediate loss, according to standard game rules. 22 Table 12 Details of 36 tasks in Enigmata. Task Categories Source Difficulty Vriables Rules"
        },
        {
            "title": "Auto",
            "content": "number of nodes , edge density Given an undirected graph, determine whether Hamiltonian cycle exists; if so, output one such cycle."
        },
        {
            "title": "Auto",
            "content": "number of nodes , edge density Given an undirected graph, determine whether Hamiltonian path exists; if so, output one such path."
        },
        {
            "title": "Logic",
            "content": "[43]"
        },
        {
            "title": "FOLIO",
            "content": "shortest path length Given spatial description of road network among city landmarks, identify the shortest path from designated starting point to the nearest landmark of specified type. obstacle percentage Given grid-based maze with designated start and end positions, the objective is to determine valid path from start to end. Movement is restricted to the four cardinal directions (up, down, left, right), and traversal through blocked or impassable cells is not allowed. ambiguity a, number of inhabitants Given statements from individuals who are either knights (truthful) or knaves (lying), decide if specific conclusion is logically entailed, contradicted, or undetermined."
        },
        {
            "title": "Logic",
            "content": "[44] number of primises Given set of premises, determine whether conclusion logically follows from them."
        },
        {
            "title": "Auto",
            "content": "Game"
        },
        {
            "title": "Auto",
            "content": "logic rule type t, columns , rows , minimal conditions Given fixed table structure and set of categorical items with positional or equality constraints, deduce unique one-to-one assignment of all elements that satisfies all logical conditions without transposing rows and columns. number of integers Given four to six integers, use each exactly once with +, , , , and parentheses to construct valid expression that evaluates to 24."
        },
        {
            "title": "Auto",
            "content": "number of integers n, range target value Given five integers and target value, form valid arithmetic expression using each number exactly once and the operators (+, , , ), such that all intermediate results are positive integers and the final result equals the target. Table 13 Pass@k scores of GPT-4o."
        },
        {
            "title": "Hard",
            "content": "pass@1 pass@10 pass@100 pass@1 pass@10 pass@100 pass@1 pass@10 pass@"
        },
        {
            "title": "Sudoku\nZebra Logic\nCampsite\nCrypto KKA\nCrypto KPA\nMaze\nMagic Square",
            "content": "79.5 74.6 25.5 51.9 17.5 36.2 85.0 99.9 100.0 87.3 82.8 36.5 88.5 100.0 100.0 100.0 100.0 97.4 54.2 100.0 100.0 44.0 11.6 4.7 35.4 8.1 12.1 46.3 82.7 49.9 33.0 65.4 13.7 49.0 88.3 96.2 84.7 75.0 82.5 23.1 83.6 99. 1.9 0.1 0.7 18.5 5.7 9.0 1.6 10.2 1.2 6.3 45.7 20.8 37.1 12.9 25.6 11.3 44.6 57.5 29.6 67.2 38.4 23 E.3 Task Cases The following listings present examples of each puzzle type in the Enigmata dataset. Each task includes rule description and few-shot examples demonstrating puzzle mechanics. Color coding in prompts indicates different puzzle categories. These examples highlight the diversity of our dataset, from grid-based challenges (Sudoku, Star Battle) to sequential puzzles (Eight Puzzle, Fifteen Puzzle). Each puzzle challenges distinct cognitive faculties, forming comprehensive dataset spanning wide spectrum of reasoning capabilities. (cid:4) (cid:5) (cid:4) (cid:7) You are tasked with solving Binario puzzle . Listing 1 Case of Binario Rules : 1. The Binario puzzle is played on grid of size NxN , where is an even number . 2. Each cell in the grid must be filled with either 0 or 1. 3. No more than half of the cells in any row or column can contain the same number . 4. No more than two identical numbers can be adjacent horizontally or vertically . 5. The puzzle must have unique solution . Task : Solve the following Binario puzzle by filling in the missing cells ( denoted by \" _ \") with 0 and 1 according to the rules above . Output Format : Please output your answer within code block ( ) and format the grid as numbers , for example : 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 If no solution exists , output within the code block : No valid solution exists for the given Binario puzzle . Puzzle : 0 0 1 _ 0 0 _ _ 1 1 0 0 1 1 0 0 (cid:6) (cid:7) You are tasked with solving campsite puzzle . Listing 2 Case of Campsite Rules : 1. Notations (1) Trees are represented by , tents are represented by * , and empty spaces are represented by . . (2) You will be given board with trees and empty spaces , the total number of tents , and indications for the number of tents in each row and column . Your goal is to place tents on the empty spaces . 2. Constraints (1) Every tree on the board is associated with one tent , which is always horizontally or vertically adjacent to it . (2) No tent can be horizontally , vertically or diagonally adjacent to another tent . (3) The number of tents in each row and column should match the given indications . (4) The number of tents on the board should match the given total number of tents . (5) tent can only be associated with one tree , but it can be adjacent to more than one tree . Output Format : 1. Your output should include solution followed by the final board . 2. You must not change trees ( ) on the board , but only place tents ( * ) on empty spaces ( . ) . 3. The final board should be wrapped between < begin_board > and < end_board > tags . Task : - Place tents on the empty spaces according to the given grid and rules . Final Board : 24 < begin_board > [ Final Board ] < end_board > Puzzle : Here is the puzzle : total number of tents : 4 tents in each row : 1 1 0 2 tents in each column : 1 1 1 1 . . . . . . . . . . . . (cid:6) (cid:7) You are provided with 3 x3 Magic Square puzzle . Some cells are filled with numbers , while blank cells are represented by dots . Your task is to find valid solution for the puzzle based on the following rules . Listing 3 Case of Magic Square Rules : 1. Magic square is 3 x3 partially filled matrix . 2. You need to fill in the blanks in the matrix so that the sum of the numbers in each row , each column , and the two diagonals is equal . 3. You can only fill the blanks with integers , the filled matrix only consists of integers . 4. The filled numbers should not duplicate the already filled numbers . 5. Make sure that the sum of the numbers in each row , each column , and the two diagonals is equal . Task : - Fill the blank cells according to the given numbers and rules . - Find valid magic square solution for the given puzzle . Output Format : Please output your answer within code block ( ) , formatted as grid of numbers , for example : 2 4 3 1 3 1 2 4 4 3 1 2 1 2 4 3 Puzzle : 0 35 10 . 15 5 20 . 30 (cid:6) (cid:7) Skycraper is logic puzzle game where the goal is to fill grid matrix based on the given clues . Here Listing 4 Case of Skyscraper are the basic rules : Rules : 1. Game Board : It typically consists of an grid matrix . Each cell represents building , and the building height is represented by number ranging from 1 to , where is the size of the matrix . 2. Building Heights : Each row and column must be filled with numbers that represent building heights . Each number can only appear once in row or column , similar to Sudoku constraints . 3. Visibility Clues : The hint numbers outside the matrix indicate how many buildings can be seen from that direction . Taller buildings block the view of shorter buildings behind them . Thus , hint number represents how many buildings are visible from one end of row or column . For example , if the clue for column is \"3\" , it means that from the top or bottom of that column , 3 buildings can be seen , and the building heights must increase , as shorter buildings will be blocked by taller ones . 4. Objective : Fill the entire matrix based on the clues , ensuring that the heights of the buildings are distinct in each row and column and follow the visibility clues at the edges . Example : (cid:5) (cid:4) (cid:5) (cid:4) [2] [1] [2] [3] + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ [2] [3] [2] [2] [1] [4] + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ [2] [3] [2] [1] [2] [1] This is an example of Skycraper puzzle : - The numbers at the top and bottom of the columns indicate how many buildings can be seen from that direction . For instance , the clue at the top of the first column is \"2\" , meaning that 2 buildings can be seen from the top , indicating that at least one building is hidden by taller one . - The left and right clues for the rows work similarly , indicating how many buildings are visible from that row left or right side . Task : Now , given Skycraper puzzle , your task is to reconstruct the height of the buildings in each cell . If there are multiple solutions , return any one . If no valid solution exists , state that no solution exists . Output Format : - Please output your answer within code block ( ) , formatted as grid of numbers , for example : 2 4 3 1 3 1 2 4 4 3 1 2 1 2 4 3 Puzzle : The input clues are : 3 2 2 1 Top : 4 2 3 1 Left : 1 2 2 2 Right : Bottom : 1 3 2 2 (cid:6) (cid:7) Sum Skycraper is logic puzzle game where the goal is to fill grid matrix based on given clues and the height and number restrictions of rows and columns . Here are the basic rules : Listing 5 Case of Sum Skyscraper Rules : 1. Game Board : Typically , it is an grid matrix . Each cell represents building , with its height represented by number ranging from 1 to , where is the length of the matrix side . 2. Building Heights : Each row and column must be filled with numbers representing the heights of the buildings . Each number can only appear once in row or column , similar to Sudoku constraints . 3. Visibility Clues : The hint numbers outside the matrix tell you how many buildings can be seen from that direction . Taller buildings will block shorter buildings behind them . Therefore , hint number indicates the total height of buildings visible from one end of the row or column . For example , if column hint is \"11 ,\" it means that looking from the top or bottom of that column , the total height of the visible buildings is 11. Additionally , the building heights need to be in increasing order , meaning shorter buildings are blocked by taller ones in front . 4. Objective : Fill the entire matrix according to the clues , ensuring that the heights of buildings in each row and each column are different , and that they comply with the visibility clues on the sides . Example : (cid:5) (cid:4) [7] [9] [4] [10] [7] [4] [5] [9] + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ + - - -+ - - -+ - - -+ - - -+ [5] [9] [7] [4] [6] [5] [7] [4] The above is an example of Sum Skycraper : - The numbers at the top and bottom of the columns indicate how many buildings can be seen from that direction . For example , the hint at the top of the first column is \"7 ,\" meaning that the total height of the visible buildings from top to bottom is 7. - The hints on the left and right of the rows are similar to those for the columns , indicating the total height of buildings visible from the left and right sides of that row . For example , if the hint is 10 , it means the visible buildings could possibly be 1 , 2 , 3 , 4. Task : Now , given Sum Skycraper scenario , please restore the height of each building in the scenario . If there are multiple answers , output any one of them . If there is no valid solution , then respond with \" no valid solution .\" 26 (cid:5) (cid:4) Output Format : - The input data consists of four lines : the first line represents the height seen from top to bottom , the second line from left to right , the third line from right to left , and the fourth line from bottom to top . - Using the previous example , the input data would be : 7 4 5 9 7 9 4 10 6 5 7 4 5 9 7 4 - Please output your answer within code block ( ) , formatted as grid of numbers storing the heights of the buildings , for example : 2 4 3 1 3 1 2 4 4 3 1 2 1 2 4 3 - If no solution exists , the result should be : \" No valid solution .\" Puzzle : 7 9 4 5 7 9 4 5 5 4 7 9 5 4 7 9 Please provide the answer according to the above requirements . (cid:6) (cid:7) You are tasked with solving customized version of the star - battle puzzle . The star - battle puzzle is Listing 6 Case of Star Battle logic puzzle that requires the placement of stars in grid . There is only one solution to this puzzle . Your goal is to determine the location of each star , adhering to the following rules : Rules : 1. NOTATIONS : - The initial board consists of empty cells and blocked cells . - Empty cells are denoted by . , blocked cells are denoted by , and stars are denoted by * . 2. STAR MUST BE PLACED IN EMPTY CELL : - Each star must be placed in an EMPTY cell . - Blocked cells cannot contain stars . - You can only change cells denoted by . , and must not change cells denoted by . 3. EXACTLY 1 STAR IN EACH ROW AND COLUMN : - Each row and column must contain EXACTLY one star . - No two stars can be in the same row or column . - There shouldn be rows or columns without stars . 4. NO ADJACENT STARS ROW - WISE , COLUMN - WISE , OR DIAGONALLY : No two stars can be adjacent to each other , even diagonally . - Row - wise adjacency : two stars are in the same row , and there is no empty cell between them . - Column - wise adjacency : two stars are in the same column , and there is no empty cell between them . - Diagonal adjacency : two stars are in the same diagonal , and there is no empty cell between them . Note that you are prone to make mistakes in diagonal adjacency , so be extra careful . Here are 2 examples of diagonal adjacency in partial grid : . * . . . . * . . . * . . * . . In both cases , the two stars are diagonally adjacent . You should avoid this situation . 5. CHECK FOR CONSTRAINTS AND BACKTRACK : - In each step , you should check if it violates the constraints in 2. , 3. , and 4. - If you find inconsistencies , you should backtrack and try different placement . - If you find that you can place star anywhere without violating the constraints , you should backtrack and try different placement . - Since there is only one solution , there is great chance your first placement is incorrect , which means you might need to start over . Task : Determin the location of each star and place them into the grid , adhering to the rules . 27 Output Format : - Your output should include the final board . - The final board is revised version of the initial board in way that if you need to place star in an empty cell , replace the . with * . - Don change the blocked cells denoted by . - Your final board should be wrapped between < begin_board > and < end_board > tags . - Use the following structure : Final Board : < begin_board > [ Final Board ] < end_board > Puzzle : The input clues are : . . . . . . . . . . . . . . . . . . . Please provide the answer according to the above requirements . (cid:6) (cid:7) You are provided with 4 x4 Sudoku puzzle . Some cells are filled with numbers , while empty cells are represented by dots . Your task is to find valid solution for the puzzle based on the following rules : Listing 7 Case of Sudoku2 Rules : 1. Board Structure : The Sudoku board is 4 x4 grid , divided into 4 smaller 2 x2 subgrids ( regions ) . 2. Number Range : Each cell can only contain number between 1 and 3. Row Rule : Each row must contain the numbers 1 through 4 , with no repeats . 4. Column Rule : Each column must contain the numbers 1 through 4 , with no repeats . 5. Subgrid Rule : Each 2 x2 subgrid must contain the numbers 1 through 4 , with no repeats . Task : - Find valid Sudoku solution for the given puzzle . - If there are multiple solutions , provide one . Output Format : - Please output your answer within code block ( ) representing the solved Sudoku board , formatted as grid of numbers , for example : 2 4 3 1 3 1 2 4 4 3 1 2 1 2 4 3 Puzzle : 4 2 . 3 3 . . 4 2 . 4 1 1 4 3 2 Please provide the answer according to the above requirements . (cid:6) (cid:7) You are provided with 9 x9 Sudoku puzzle . Some cells are filled with numbers , while empty cells are represented by dots . Your task is to find valid solution for the puzzle based on the following rules : Listing 8 Case of Sudoku Rules : 1. Board Structure : The Sudoku board is 9 x9 grid , divided into 9 smaller 3 x3 subgrids ( regions ) . 2. Number Range : Each cell can only contain number between 1 and 9. 3. Row Rule : Each row must contain the numbers 1 through 9 , with no repeats . 4. Column Rule : Each column must contain the numbers 1 through 9 , with no repeats . 5. Subgrid Rule : Each 3 x3 subgrid must contain the numbers 1 through 9 , with no repeats . Task : - Find valid Sudoku solution for the given puzzle . - If there are multiple solutions , provide one . 28 (cid:5) (cid:4) (cid:5) (cid:4) Output Format : - Please output your answer within code block ( ) representing the solved Sudoku board , formatted as grid of numbers , for example : 1 2 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9 1 3 4 5 6 7 8 9 1 2 4 5 6 7 8 9 1 2 3 5 6 7 8 9 1 2 3 4 6 7 8 9 1 2 3 4 5 7 8 9 1 2 3 4 5 6 8 9 1 2 3 4 5 6 7 9 1 2 3 4 5 6 7 8 Puzzle : 3 1 2 6 . . 5 9 4 . 8 6 4 5 9 3 1 2 5 9 4 2 3 1 7 8 6 1 2 5 3 8 6 9 4 7 8 6 3 7 9 4 1 2 . 9 4 7 5 1 2 8 6 3 4 7 8 . . . 6 . . 6 . 1 8 . . 2 5 9 2 5 9 . 6 . 4 7 8 Please provide the answer according to the above requirements . (cid:6) (cid:7) Task : Your task is to complete the crossword puzzle grid based on the given clues . Ensure that all words are meaningful and semantically valid . The grid consists of fillable blank spaces ( _ ) and blocked spaces ( * ) . You must strictly follow the provided grid layout , with no modifications allowed . Listing 9 Case of Full Crosswords Rules : 1. Completing the Grid : - Fill each blank space ( _ ) with letter to form valid words according to the given clues . - Blocked spaces ( * ) must remain unchanged and cannot contain any letters . - The number of rows and columns must match the provided grid exactly . - All blank spaces ( _ ) must be filled - - no empty spaces are allowed . 2. Clue Mapping Logic : (1) Across Clues : - Rows without * characters represent across words . These words correspond to across clues in order from top to bottom . - Rows containing * do not correspond to any across word or clue . (2) Down Clues : - Columns without * characters represent down words . These words correspond to down clues in order from left to right . - Columns containing * do not correspond to any down word or clue . 3. Matching Letters at Intersections : - Letters at the intersections of across and down words must match , ensuring valid words are formed both horizontally and vertically . Output Format : Please output your answer within code block ( ) as follows : across : ANSWER1 , ANSWER2 , .... , ANSWER_N down : ANSWER1 , ANSWER2 ,.... , ANSWER_N - \" across \" contains the list of across words , ordered from top to bottom . - \" down \" contains the list of down words , ordered from left to right . (cid:5) (cid:4) Puzzle : Across clues : 1. \" London farewell !\" (2001) 2. \" Fossil mollusk \" (1972) 3. \" Radial counterpart \" (2013) Down clues : 1. \" Measure of electric charge \" (1999) 2. \" Is bookends ?\" (2014) 3. Law - abiding (2010) 29 The grid is as follows : _ _ _ _ _ _ _ * _ _ * _ _ * _ _ _ _ _ _ _ * _ _ * _ _ * _ _ _ _ _ _ _ * _ _ * _ _ * _ _ _ _ _ _ _ (cid:6) (cid:7) Task and Rules : Figure out the pattern in the following examples and apply it to the test case . Your answer must follow Listing 10 Case of Symbolic Hard the format of the examples . Output Format : Please output your answer within code block ( ) , formatted as grid of numbers . (cid:5) (cid:4) Puzzle : # Examples Example 1: [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] -> [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] Example 2: [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] -> [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] Example 3: [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] -> [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2] , 30 [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] # Test Problem : [[2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2] , [2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 0 , 2] , [2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2]] -> [ Your Answer Here ] (cid:6) (cid:7) Task : Your task is to apply the provided decryption rules to decipher the given ciphertext . Listing 11 Case of Crypto KKA Rules : 1. Review the decryption rules carefully to understand how the encryption method works . 2. Decrypt the provided ciphertext according to the rules , and derive the correct plaintext . Output Format : Please output your answer within code block ( ) as follows : < result > - < result > should be the decrypted plaintext corresponding to the given ciphertext , for example : LOVE Puzzle : Ciphertext : DBUDIBUFOO Encryption Method : { method : Caesar Cipher , shift : 1} What the corresponding plaintext ? (cid:6) (cid:7) Task : Your task is to decrypt the given ciphertext and provide the corresponding plaintext . You will be given sample hint that illustrates pair of ciphertext and its matching plaintext to guide you in solving the puzzle . Listing 12 Case of Crypto KPA Rules : 1. Analyze the provided ciphertext . 2. Use the sample hint as reference to understand the encryption pattern or method used . 3. Apply the deciphering technique to convert the ciphertext into plaintext . Output Format : Please output your answer within code block ( ) as follows : < result > - < result > should be the decrypted plaintext corresponding to the given ciphertext , for example : ABCIDEFG Puzzle : hint : Known plaintext and ciphertext pair : Plaintext : R T S Y A D H I C A R E L M T A N A T I F A A R E L H O R I C I I F R Ciphertext : E G F L N Q U V P N E R Y Z G N A N G V S N 31 (cid:5) (cid:4) (cid:5) (cid:4) (cid:5) (cid:4) (cid:5) (cid:4) R C N J J A R N O G B G Use the example above to decode : RONYYGBERT (cid:6) (cid:7) Given 3 x3 sliding puzzle where each cell contains number (1 to 9) , your goal is to restore the puzzle to its original sorted order through series of rotation operations . Listing 13 Case of Twiddle Rules : 1. You can select 2 x2 region within the 3 x3 puzzle and rotate the positions of these 4 cells ou nt er loc kwise . 2. The goal is to restore the puzzle to its initial state ( as shown below ) : 1 2 3 4 5 6 7 8 9 Task : Please provide the steps to restore the puzzle to its initial state . Output Format : - Please output your answer within code block ( ) as follows : < result > - Replace < result > with sequence of rotation steps , where each step is represented by 2 coordinate (i , ) indicating the selection of the 2 x2 region with (i , ) as the top - left corner for counterclockwise rotation . For example : (0 ,0) - >(1 ,1) - >(0 ,1) - The problem guarantees that solution exists . Puzzle : 3 6 1 8 4 5 7 9 2 Please provide the answer according to the above requirements . (cid:6) (cid:7) You are tasked with solving Car Painting Problem . In the Car Painting Problem , you play the role of scheduler at car painting factory . Your job is to arrange the painting sequence for batch of cars to minimize the number of color switches , reducing Listing 14 Case of Car Painting paint waste and production time . Rules : 1. There are cars numbered from 1 to that need to be painted . 2. Each car has predetermined color ( labeled as , , , etc . , for total of colors ) . 3. Cars enter the painting workshop in fixed order , but can be rearranged within range . 4. Each car can be moved forward or backward by at most positions from its original position . 5. color switch occurs when two adjacent cars have different colors , adding to the cost . 6. Your goal is to minimize the number of color switches by optimally arranging the cars . Task : Find rearranged sequence of cars that minimizes the number of color switches . You must provide list of car IDs in their new order ( rearranged to minimize color switches ) . Puzzle : Given the following information : - Number of Cars ( ) : 14 - Number of Colors ( ) : 2 - Maximum Movement Range ( ) : 4 - Initial car sequence : [1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14] - Corresponding color : [ , , , , , , , , , , , , , ] Please find rearranged car sequence that minimizes the number of color switches . Remember : Each car can only be moved at most 4 positions forward or backward from its original position . Output Format : - Please output your answer within code block ( ) , formatted as an array of integers representing the new order of car IDs , for example : [2 , 3 , 1 , 5 , 8 , 4 , 6 , 9 , 7 , 10] - Replace < result > with sequence of rotation steps , where each step is represented by 2 coordinate (i , ) indicating the selection of the 2 x2 region with (i , ) as the top - left corner for ou nt er loc kwise rotation . For example : (0 ,0) - >(1 ,1) - >(0 ,1) - The problem guarantees that solution exists . (cid:6) (cid:7) Stack permutation is permutation problem related to stacks ( last - in , first - out data structure ) . Given an input sequence , the goal is to generate different output sequences using stack operations ( push and pop ) . sequence is called valid stack permutation if it can be obtained through stack operations . Listing 15 Case of Stack Permutation Task and Rules : Given sequence of natural numbers , such as [1 , 2 , 3 , 4] , we want to know if particular output sequence can be obtained through stack operations . The stack operations include : 1. Push : Add numbers from the input sequence to the stack in order . 2. Pop : Remove elements from the top of the stack and add them to the output sequence . Example : Suppose the input sequence is [1 , 2 , 3]. Here are some possible valid stack permutations : - [1 , 2 , 3]: Directly push all elements into the stack and then pop them in order . - [2 , 1 , 3]: Push 1 and 2 into the stack , pop 2 , then pop 1 , and finally push and pop 3. - [3 , 2 , 1]: Push all elements into the stack , then pop them in reverse order . Output Format : - Please output your answer within code block ( ) , for [\" Push (1) \" , \" Pop () \" , \" Push (2) \" , \" Push (3) \" , \" Pop () \" , \" Pop () \"] - If the output sequence is not valid stack permutation of the input sequence , output within the code block : \" The output sequence is not valid stack permutation .\" Puzzle : Input sequence : [5 , 2 , 1 , 3 , 4] Output sequence : [5 , 3 , 1 , 4 , 2] Please provide the solution according to the requirements below . (cid:6) (cid:7) Task and Rules : Apply function to the final input list to generate the output list . Use any preceding inputs and outputs as examples to find what is the function used . All example outputs have been generated using the same function . Listing 16 Case of Big Bench Symbolic Output Format : - Please output your answer within code block ( ) , formatted as list of numbers , for example : [0 , 2 , 3] (cid:5) (cid:4) (cid:5) (cid:4) Puzzle : # Examples Example 1: [7 , 7 , 9 , 21 , 7 , 4 , 4 , 91 , 0] -> [7 , 9 , 21 , 7 , 4 , 4 , 91 , 0] Example 2: [7 , 78 , 78 , 7] -> [78 , 78 , 7] Example 3: 33 (cid:5) (cid:4) (cid:5) (cid:4) [9 , 7 , 72 , 44 , 7 , 0 , 7 , 44] -> [9 , 72 , 44 , 7 , 0 , 7 , 44] Example 4: [7 , 8 , 7 , 7] -> [8 , 7 , 7] # Test Problem : [5 , 37 , 97 , 48 , 7 , 1] -> (cid:6) (cid:7) Task : The Eight puzzle is classic sliding puzzle game . It consists of 3 x3 grid containing 8 numbered tiles from 1 to 8 and one blank space ( represented by 0) . The player moves these tiles with the ultimate goal of arranging them in order from 1 to 8. Below are the detailed rules : Listing 17 Case of Eight Puzzle Rules : 1. Initial State : - The initial state of the puzzle is 8 numbered tiles randomly distributed in 3 x3 grid , with the blank space located anywhere . - The puzzle usually starts from scrambled state . 2. Movement : - The player can move tile adjacent to the blank space into the blank space . - Tiles can only move in the four directions : up ( ) , down ( ) , left ( ) , and right ( ) . - Only one tile can be moved at time . 3. Goal : - The ultimate goal is to arrange the tiles in order from left to right , top to bottom , as follows : 1 4 2 5 8 3 6 0 Output Format : - Please output your answer within code block ( ) as follows : < result > - If there is an answer , the is the sequence of moves , for example : LRURDL - If there is no answer , the is : No feasible move path exists . Puzzle : 4 2 3 (cid:6) 5 8 1 6 7 (cid:7) Task : The Fifteen puzzle is classic sliding puzzle game . It consists of 4*4 grid containing 15 numbered tiles from 1 to 15 and one blank space ( represented by 0) . The player moves these tiles with the ultimate goal of arranging them in order from 1 to 15. Below are the detailed rules : Listing 18 Case of Fifteen Puzzle Rules : 1. Initial State : - The initial state of the puzzle is 15 numbered tiles randomly distributed in 4*4 grid , with the blank space located anywhere . - The puzzle usually starts from scrambled state . 2. Movement : - The player can move tile adjacent to the blank space into the blank space . - Tiles can only move in the four directions : up ( ) , down ( ) , left ( ) , and right ( ) . - Only one tile can be moved at time . 3. Goal : - The ultimate goal is to arrange the tiles in order from left to right , top to bottom , as follows : 4 2 3 7 6 10 11 12 1 5 9 13 14 15 0 Output Format : 34 - Please output your answer within code block ( ) as follows : < result > - If there is an answer , the is the sequence of moves , for example : LRURDL - If there is no answer , the is : No feasible move path exists . Puzzle : 4 12 7 13 (cid:6) 9 3 8 10 2 11 14 6 1 5 0 15 (cid:7) Task : The nine puzzle is classic sliding number puzzle . It consists of 3 x3 grid containing 9 tiles numbered from 1 to 9. Players can choose to move an entire row or column in circular fashion each time . The ultimate goal is to arrange the tiles in numerical order from 1 to 9. The detailed rules are as follows : Listing 19 Case of Nine Puzzle Rules : 1. Initial State : - The initial state of puzzle consists of 9 number tiles randomly arranged on 3 x3 grid - The puzzle typically starts from scrambled state . 2. Movement : - Players can choose to move an entire row or column , shifting it by 1 to 2 steps in circular manner . For example : 1 2 3 , shifting by 1 step results in 2 3 1 , shifting by 2 steps results in 3 1 2. - We represent row moves as RAB , where is the row number and is the number of steps . Similarly , column moves are represented as CAB , where is the column number and is the number of steps . 3. Goal : - The ultimate goal is to arrange the tiles in order from left to right , top to bottom as follows : 1 4 7 2 5 8 3 6 9 Output Format : - If solution exists , output the sequence of moves within code block ( ) , for example : [\" R11 \" , \" C23 \" , \" R32 \" , \" C12 \" , \" R23 \" , \" C31 \"] - If no solution exists , output within the code block : \" No valid sequence of moves exists .\" Puzzle : 3 5 2 (cid:6) 1 7 8 4 6 (cid:7) Task : The sixteen puzzle is classic sliding number puzzle . It consists of 4 x4 grid containing 16 tiles numbered from 1 to 16. Players can choose to move an entire row or column in circular fashion each time . The ultimate goal is to arrange the tiles in numerical order from 1 to 16. The detailed rules are Listing 20 Case of Sixteen Puzzle as follows : Rules : 1. Initial State : - The initial state of the puzzle consists of 16 number tiles randomly arranged on 4 x4 grid . - The puzzle typically starts from scrambled state . 2. Movement : 35 (cid:5) (cid:4) (cid:5) (cid:4) - Players can choose to move an entire row or column , shifting it by 1 to 3 steps in circular manner . For example : 1 2 3 4 , shifting by 1 step results in 2 3 4 1 , shifting by 2 steps results in 3 4 1 2 , and shifting by 3 steps results in 4 1 2 3. - We represent row moves as RAB , where is the row number and is the number of steps . Similarly , column moves are represented as CAB , where is the column number and is the number of steps . 3. Goal : - The ultimate goal is to arrange the tiles in order from left to right , top to bottom as follows : 3 2 1 6 7 5 9 10 11 12 13 14 15 16 4 Output Format : - If solution exists , output the sequence of moves within code block ( ) , for example : [\" R11 \" , \" C23 \" , \" R32 \" , \" C12 \" , \" R23 \" , \" C31 \"] - If no solution exists , output within the code block : \" No valid sequence of moves exists .\" Puzzle : 11 12 1 8 (cid:6) 6 2 7 5 16 4 3 10 15 9 13 (cid:7) You are tasked with solving Hitori puzzle . Listing 21 Case of Hitori Rules : 1. The puzzle is played on an NxN grid ( where is an even number ) , with each cell containing number . 2. Your goal is to \" black out \" certain cells , following these rules : - In each row and column , the same number cannot appear more than once . To eliminate repetitions , you must black out some of the cells . - Black cells cannot be adjacent , either horizontally or vertically . - All white cells ( cells that are not blacked out ) must be connected , meaning you can travel between any two white cells through horizontal or vertical moves . Task : - Solve the following Hitori puzzle by blacking out the cells where needed . - You must provide the coordinates of the blacked - out cells . Output Format : - Please output your answer within code block ( ) , formatted as list of coordinates , for example : [(0 , 0) , (1 , 3) , (3 , 2) ] - If no solution exists , output within the code block : \" No valid solution exists for the given Hitori puzzle .\" Puzzle : [[5 , 3 , 1 , 3 , 5] , [1 , 4 , 3 , 5 , 3] , [1 , 3 , 2 , 4 , 3] , [3 , 5 , 1 , 1 , 2] , [3 , 1 , 4 , 2 , 2]] (cid:6) (cid:7) You are tasked with solving Kakurasu puzzle . Listing 22 Case of Kakurasu Task & Rules : 1. The puzzle is played on rectangular grid ( with arbitrary row and column sizes ) . 2. Your goal is to \" black out \" certain cells , following these rules : - The black cells in each row must sum up to the target number for that row . - The black cells in each column must sum up to the target number for that column . - To calculate the row sum : 36 (cid:5) (cid:4) (cid:5) (cid:4) - The value of the black cells in each row is determined by their position in the row . For example , the first black cell in row has value of 1 , the second black cell has value of 2 , and so on . - To calculate the column sum : - The value of the black cells in each column is determined by their position in the column . For example , the first black cell in column has value of 1 , the second black cell has value of 2 , and so on . 3. Coordinates are 1 - based . For example , the first row is row 1 , and the first column is column 1. Puzzle : Solve the following Kakurasu puzzle by blacking out the cells where needed . Board size : 4 4 Row sums : [0 , 5 , 10 , 5] Column sums : [5 , 7 , 7 , 5] You must provide the coordinates of the blacked - out cells . Output Format : - Please output your answer within code block ( ) , formatted as list of coordinates , for example : [(1 , 1) , (2 , 4) , (4 , 3) ] - If no solution exists , output within the code block : \" No valid solution exists for the given Kakurasu puzzle .\" Puzzle : [[5 , 3 , 1 , 3 , 5] , [1 , 4 , 3 , 5 , 3] , [1 , 3 , 2 , 4 , 3] , [3 , 5 , 1 , 1 , 2] , [3 , 1 , 4 , 2 , 2]] (cid:6) (cid:7) You need to solve Light Up puzzle . Listing 23 Case of Light Up Task & Rules : 1. The puzzle is played on rectangular grid ( the number of rows and columns is not fixed ) . 2. The goal is to place light bulbs ( represented by ) on the empty squares of the grid , following these rules : - Each numbered black square ( represented by numbers 1 -4) must have the specified number of light bulbs around it . For example , black square with \"1\" means it must have exactly 1 light bulb around it , \"2\" means exactly 2 light bulbs , and so on . - Light bulbs can only be placed on empty squares ( represented by .) and must only light up empty squares ; they cannot light up other light bulbs . - Black squares ( represented by #) cannot be illuminated and block the light of the light bulbs . Puzzle : Solve the following Light Up puzzle by placing the required light bulbs ( ) : .#..#. ...1.. #..... ...1.. .....# ...... You need to provide the coordinates of the light bulbs in the following format : Output Format : - - Please output your answer within code block ( ) , formatted as list of numbers , for example : [(2 , 4) , (6 , 2) , (7 , 5) , (0 , 0) , (4 , 3) , (1 , 1) , (2 , 0) , (5 , 1) , (1 , 7) , (3 , 2) ] - If no solution exists , output within the code block : \" No solution , unable to solve the given Light Up puzzle .\" (cid:6) (cid:7) You are playing Minesweeper game . On grid composed of different cells , the player goal is to deduce all cells that contain mines and avoid clicking on mines . Each cell in the game may either contain mine or show the number of adjacent mines . Listing 24 Case of Minesweeper (cid:5) (cid:4) (cid:5) (cid:4) Rules : 1. Grid and Mines The game grid consists of several cells , each of which may be : - Mine : If the player clicks on mine cell , the game ends . - Numbered cell : This cell displays the number of mines adjacent to it . The number indicates how many of the eight neighboring cells contain mines . 2. Current Grid State Representation The grid state is represented as : -2: Indicates the cell is unknown ( not revealed ) . 0 -8: Revealed non - mine cells , where the number indicates how many mines are adjacent to that cell . For example , cell with 0 means no mines adjacent , cell with 1 means one mine adjacent , and so on . Task : Based on current grid state , infer positions of the mines that can be definitively determined . Puzzle : The current grid state is : [[ -2 , 1 , -2 , -2 , -2 , -2 , -2 , -2 , 0] , [ -2 , -2 , -2 , 0 , 0 , -2 , 0 , -2 , 0] , [ -2 , 2 , -2 , -2 , -2 , -2 , -2 , -2 , -2] , [ -2 , 2 , -2 , -2 , -2 , 0 , -2 , -2 , -2] , [ -2 , -2 , -2 , -2 , 1 , 1 , -2 , -2 , -2] , [ -2 , -2 , -2 , -2 , 1 , -2 , 1 , -2 , -2] , [1 , -2 , 1 , -2 , -2 , -2 , 2 , 1 , -2] , [2 , -2 , -2 , -2 , -2 , 0 , 1 , -2 , -2] , [ -2 , -2 , -2 , 1 , -2 , 0 , 1 , 1 , 1]] Coordinate Explanation : - Coordinates start from (0 , 0) , where the first row , first column is (0 , 0) , the second row , second column is (1 , 1) , and so on . - You need to provide the coordinates of the determinable mines in the following format : Output Format : - Please output your answer within code block ( ) , formatted as list of coordinates (r , ) , for example : [(1 , 1) , (2 , 4) , (4 , 3) ] - If no solution exists , output within the code block : \" Unable to determine any mine locations .\" (cid:6) (cid:7) You need to solve Slant puzzle . Listing 25 Case of Slant Task & Rules : 1. Grid Numbers : - Each cell in the grid may contain number , indicating how many diagonal lines meet at that intersection . The number ranges from 0 to 4 , representing the number of intersecting diagonal lines . 2. Diagonal Line Rules : - Each cell must contain one diagonal line , either \"/\" ( forward slash , representing top - left to bottom - right ) or \"\" ( backslash , representing top - right to bottom - left ) . 3. Intersection Numbers : - The number indicates how many diagonal lines meet at that intersection . For example : - Number 1: Indicates 1 diagonal line intersects at that point . - Number 2: Indicates 2 diagonal lines intersect at that point . - Number 0: Indicates no diagonal lines intersect at that point . - Numbers 3 and 4: Represent 3 and 4 intersecting diagonal lines , respectively . 4. No Loops : - The diagonal lines must not form loops . All diagonal lines must connect , and no closed cycle can be formed . (cid:5) (cid:4) Puzzle : Solve the following slant puzzle : 1 0 1 . 0 2 0 1 3 1 1 4 0 2 1 1 4 2 0 . 0 1 . 2 2 3 1 1 0 4 0 2 3 2 1 2 1 3 2 0 3 1 0 . . 1 2 0 Output Format : 38 - Please output your answer within code block ( ) , formatted as grid of numbers , for example : 1 1 1 1 -1 1 -1 1 1 -1 -1 1 - 1 represents \"/\" ( forward slash , top - left to bottom - right ) - -1 represents \"\" ( backslash , top - right to bottom - left ) (cid:6) (cid:7) Task : You are tasked with finding move in the chess position resulting in checkmate : Listing 26 Case of Checkmate in One Output Format : - Please output your answer within code block ( ) as follows , for example : Rg5 # Puzzle : Here is the chess position : 1. c4 c5 2. g3 e6 3. Bg2 d5 4. cxd5 exd5 5. Nc3 Nf6 6. Nf3 b6 7. d4 c4 8. - Bb7 9. Ne5 Bd6 10. Bf4 - 11. Qc2 Nc6 12. Nxd5 Nxd4 13. Nxf6 + Kh8 14. Qxc4 Bxe5 15. Bxe5 Rc8 16. Qxd4 Qe7 17. Nd5 Bxd5 18. Bxg7 + Kg8 19. Qxd5 Rfd8 20. Qe5 Qb4 21. Rad1 Re8 22. Qg5 Qe4 23. Bh6 + Kh8 24.(cid:6) (cid:7) You are tasked with solving Tic Tac Toe puzzle . Listing 27 Case of Tic Tac Toe Task & Rules : 1. The board consists of 3 x3 cells . 2. Players take turns placing their mark on an empty cell , one move per turn . The two players use \" \" or \" \". 3. player wins by placing three of their marks consecutively in row , column , or diagonal . 4. If the board is completely filled without winner , the game is draw . You are playing tic - tac - toe as . Puzzle : Current board : - -- - -- - - - - -- - -- - - - Question : What is the best next move ? Please provide only your move and display the board . Output Format : - Please output your answer within code block ( ) , for example : \" \" \" \" \"\" \"\" \" \" \"\" \" \" \"\" \" \" (cid:6) 39 (cid:5) (cid:4) (cid:5) (cid:4) (cid:5) (cid:7) You are given four or five or six integers , ranging from 1 to 13 , provide an arithmetic expression that Listing 28 Case of Game24 (cid:4) results in 24. Task & Rules : You must use all the given numbers , each exactly once . The operators you can use include : addition (+) , subtraction ( -) , multiplication (*) , and division (/) . You can use parentheses to change the order of operations . Output Format : Please output your answer within code block ( ) as follows : < result > - If there is solution , < result > is the sequence of numbers and operators that results in 24 , for example : (8 / 2) * (8 - 2) - If there is no solution , < result > is \" cannot form 24\". Puzzle : Input : 7 , 1 , 7 , 13 Please provide solution for the 24 game according to the above rules and input . (cid:6) (cid:7) You are given 5 integers and target number . Your task is to create an arithmetic expression that results in exactly the target number . Listing 29 Case of Countdown Task & Rules : - You must use ALL the given numbers , each exactly once . - The operators you can use include : addition (+) , subtraction ( -) , multiplication (*) , and division (/) . - You can use parentheses to change the order of operations . - All intermediate results must be positive integers ( no fractions or negative numbers allowed ) . Output Format : Please output your answer within code block ( ) as follows : < result > - If there is solution , < result > is the sequence of numbers and operators that results in 24 , for example : (8 / 2) * (8 - 2) - If there is no solution , < result > is \" cannot form 85\". Puzzle : Numbers : 10 , 5 , 15 , 2 , 9 Target : 85 Please provide solution for the 24 game according to the above rules and input . (cid:6) (cid:7) You are tasked with solving Hamiltonian Cycle Puzzle . Listing 30 Case of Hamiltonian Cycle (cid:5) (cid:4) (cid:5) (cid:4) Task & Rules : Hamiltonian Cycle in an undirected graph is cycle that visits every vertex exactly once and returns to the starting vertex . The task is to determine whether Hamiltonian Cycle exists in the given graph . The graph is represented as follows : - The first line contains single integer , the number of vertices in the graph . - The subsequent lines each describe an edge in the graph . Each edge is represented by two space - separated integers and , which indicate that there is an undirected edge between vertex and vertex . - The vertices are numbered from 0 to -1 . Output Format : - Please output your answer within code block ( ) as follows : < result > 40 - If Hamiltonian Cycle exists , < result > should be list of vertex indices that form the cycle , where the last vertex is the same as the first vertex to complete the cycle , for example : [0 , 2 , 3 , 1 , 0] - If no Hamiltonian Cycle exists , < result > should be \" NO \". Puzzle : 11 0 1 0 4 2 3 0 2 6 10 1 10 1 3(cid:6) (cid:7) You are tasked with solving Hamiltonian Path Puzzle . Listing 31 Case of Hamiltonian Path Task & Rules : Hamiltonian Path in an undirected graph is path that visits every vertex exactly once . The task is to determine whether Hamiltonian Path exists in the given graph . The graph is represented as follows : - The first line contains single integer , the number of vertices in the graph . - The subsequent lines each describe an edge in the graph . Each edge is represented by two space - separated integers and , which indicate that there is an undirected edge between vertex and vertex . - The vertices are numbered from 0 to -1 Output Format : - Please output your answer within code block ( ) as follows : < result > - < result > should be list of vertex indices that form the Hamiltonian Path if it exists , for example : [0 , 2 , 3 , 1 , 0] - If no Hamiltonian Path exists , < result > should be \" NO \". Puzzle : 14 0 4 0 5 0 8 0 9 1 3 1 6 1 9 2 5 2 9 2 12 2 13 3 6 3 9 3 10 4 11 5 12 5 13 6 10 6 11 6 13 7 8 7 11 7 13 8 10 9 12 11 12(cid:6) (cid:7) You are tasked with solving spatial reasoning puzzle involving navigation in city . Follow these guidelines to determine the shortest path to specific landmark : Listing 32 Case of NL Navigation Task & Rules : 41 (cid:5) (cid:4) (cid:5) (cid:4) 1. Landmarks Definition : - Identify set of landmarks which include : store , bank , house , cinema , garden , and school . - The total number of landmarks in the puzzle will range from 7 to 10. 2. Structure : - The landmarks are organized in binary tree structure . - The root node of this tree represents the starting point for navigation . 3. Objective : - Your goal is to find the shortest path from the starting point to the nearest specified type of landmark . 4. Puzzle Input : - You will receive question . - Use the information provided in the question to determine the path . Output Format : - Please output your answer \"([ -Z , ]+) \" within code block ( ) , containing only the path letters , for example : EFJ - Your answer should only include the uppercase letters representing the landmarks in the path . - If the path is direct with no intermediate landmarks , provide an empty code block : Puzzle : Here is the puzzle : Story : There is set of roads and set of landmarks . The start point is cinema . There is road which is 100 meters long from cinema to house . There is road which is 200 meters long from house to store . There is road which is 200 meters long from store to cinema . There is road which is 100 meters long from cinema to bank . There is road which is 100 meters long from bank to house . There is road which is 200 meters long from cinema to house . There is road which is 100 meters long from house to bank . There is road which is 200 meters long from house to cinema . Question : From the start point , how to reach the nearest bank ? Please provide the solution according to the requirements above . (cid:6) (cid:7) You are tasked with solving Maze Puzzle . Listing 33 Case of Maze Puzzle : Given 5 x5 maze map , as shown below : . . . . . . . . . . . . . . . . . . . . (cid:5) (cid:4) Where : represents the start point ( located in the top - left corner at coordinates (1 , 1) ) represents the end point ( located in the bottom - right corner at coordinates (5 , 5) ) represents an obstacle ( impassable ) . represents open space ( passable ) Rules : 1. You can only move up , down , left , or right , not diagonally . 2. You cannot pass through obstacles ( ) . 3. You can move freely on open spaces (.) . 4. The goal is to find path from the start point ( ) to the end point ( ) . Please find valid path from the start point ( ) to the end point ( ) . If there are multiple paths , provide any one of them . If no valid path exists , state that it is impossible to reach the end point . Output Format : - Please output your answer within code block ( ) as follows : < result > - If there is path , < result > is the sequence of coordinates in the path . For example : (1 ,1) - >(1 ,3) - >(3 ,5) 42 - If no path exists , output directly : not exist the path from start to end . Please provide the solution according to the requirements above . (cid:6) (cid:7) In this puzzle , you are presented with scenario involving inhabitants of an island where each person is either knight or knave . Knights always tell the truth , while knaves always lie . Your task is to determine the truth value of given statement based on the information provided . Listing 34 Case of Knights and Knaves Task & Rules : 1. Knights always tell the truth . 2. Knaves always lie . 3. Use logical reasoning to determine the truth value of the statement . Output Format : - Please output your answer within code block ( ) as follows : < result > Options : - \" Entailment \": Use this if the statement is logically true based on the information provided . - \" Contradiction \": Use this if the statement contradicts known facts or logical deductions . - \" Unknown \": Use this if the truth value of the statement cannot be determined with the given information . Puzzle : On the island where each inhabitant is either knave or knight , knights always tell the truth while knaves always lie . You meet four inhabitants : Alice , Bill , Ted , and Mel . - Bill tells you that Mel and Ted are not the same . - Mel claims that it is false that Alice is knave . - Ted says that Alice is knight and Mel is knave . - Alice tells you that only knave would say that Ted is knave . Can you determine who is knight and who is knave ? Question : Is Ted the knight ? (cid:6) (cid:7) Analyze the given premises and determine the validity of the conclusion . Your task is to assess whether Listing 35 Case of FOLIO the conclusion is \" True ,\" \" False ,\" or \" Unknown \" based on the information provided . Task & Rules : 1. Premises : You will be provided with set of statements or premises . These premises are the foundational truths or assumptions for the puzzle . 2. Conclusion : statement will be presented as the conclusion . Your task is to evaluate this conclusion in the context of the given premises . 3. Evaluation Criteria : - True : The conclusion logically follows from the premises . - False : The conclusion contradicts the premises . - Unknown : The conclusion cannot be determined from the premises alone due to insufficient information . Output Format : - Please output your answer within code block ( ) as follows : < result > - Replace < result > with one of the following options : \" True \" , \" False \" , or \" Unknown \". Puzzle : premises : - Elephantopus is genus of perennial plants in the daisy family . - Elephantopus is widespread over much of Africa , southern Asia , Australia , and the Americas - Several species of Elephantopus are native to the southeastern United States . - Elephantopus scaber is traditional medicine . conclusion : No Elephantopus is native to the southeastern United States . Note : Ensure that your evaluation is based solely on the information provided in the premises without introducing external knowledge or assumptions . (cid:6) (cid:7) Listing 36 Case of Zebra Logic (cid:5) (cid:4) (cid:5) (cid:4) (cid:5) (cid:4) You are tasked with solving grid puzzle . This type of puzzle requires careful analysis of the provided background information and clues to deduce the correct arrangement of elements in grid format . Follow the steps below to solve the puzzle and present your solution in the specified format . Task & Rules : 1. Background Information : Carefully read any introductory information provided with the puzzle . This may include context or specific constraints that apply to the puzzle . 2. Clues : Analyze each clue given . These clues will guide you in determining the relationships between different elements in the grid . 3. Logical Deduction : Use logical reasoning to deduce the correct placement of each element in the grid . Consider all possible options and eliminate those that contradict the clues . 4. Consistency Check : Ensure that your solution is consistent with all the clues and background information provided . Your response should include solution followed by the final answer in markdown table format . Use the following structure : Assume column 1 is Year , column 2 is Wine , column 3 is Type . Output Format : - Please output your answer within code block ( ) as follows : 1984 [ Correct Wine ] [ Correct Type ] 1988 [ Correct Wine ] [ Correct Type ] 1992 [ Correct Wine ] [ Correct Type ] 1996 [ Correct Wine ] [ Correct Type ] Puzzle : Food : apricot , lemon Hobby : baking , card - games Job : bartender , writer Nationality : canadian , egyptian 1. Nationality : canadian is on the left of Job : writer 2. Hobby : card - games is on the right of Food : apricot Fill the following table to show your final answer . correct answer correct answer Food correct answer correct answer Hobby correct answer correct answer Job correct answer correct answer Nationality You must stick to the given uncompleted table and must not transpose the table . (cid:6) (cid:5)"
        }
    ],
    "affiliations": [
        "ByteDance Seed",
        "Fudan University",
        "Institute for AI Industry Research (AIR), Tsinghua University",
        "Nanjing University",
        "SIA-Lab of Tsinghua AIR and ByteDance Seed",
        "Shanghai Jiao Tong University"
    ]
}