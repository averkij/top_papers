{
    "paper_title": "Humans expect rationality and cooperation from LLM opponents in strategic games",
    "authors": [
        "Darija Barak",
        "Miguel Costa-Gomes"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As Large Language Models (LLMs) integrate into our social and economic interactions, we need to deepen our understanding of how humans respond to LLMs opponents in strategic settings. We present the results of the first controlled monetarily-incentivised laboratory experiment looking at differences in human behaviour in a multi-player p-beauty contest against other humans and LLMs. We use a within-subject design in order to compare behaviour at the individual level. We show that, in this environment, human subjects choose significantly lower numbers when playing against LLMs than humans, which is mainly driven by the increased prevalence of `zero' Nash-equilibrium choices. This shift is mainly driven by subjects with high strategic reasoning ability. Subjects who play the zero Nash-equilibrium choice motivate their strategy by appealing to perceived LLM's reasoning ability and, unexpectedly, propensity towards cooperation. Our findings provide foundational insights into the multi-player human-LLM interaction in simultaneous choice games, uncover heterogeneities in both subjects' behaviour and beliefs about LLM's play when playing against them, and suggest important implications for mechanism design in mixed human-LLM systems."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . e [ 1 1 1 0 1 1 . 5 0 5 2 : r a"
        },
        {
            "title": "Humans expect rationality and cooperation from LLM\nopponents in strategic games",
            "content": "Darija Barak School of Economics University of Edinburgh dbarakh@ed.ac.uk Miguel Costa-Gomes School of Economics University of Edinburgh miguel.costa-gomes@ed.ac.uk"
        },
        {
            "title": "Abstract",
            "content": "As Large Language Models (LLMs) integrate into our social and economic interactions, we need to deepen our understanding of how humans respond to LLMs opponents in strategic settings. We present the results of the first controlled monetarily-incentivised laboratory experiment looking at differences in human behaviour in multi-player p-beauty contest against other humans and LLMs. We use within-subject design in order to compare behaviour at the individual level. We show that, in this environment, human subjects choose significantly lower numbers when playing against LLMs than humans, which is mainly driven by the increased prevalence of zero Nash-equilibrium choices. This shift is mainly driven by subjects with high strategic reasoning ability. Subjects who play the zero Nash-equilibrium choice motivate their strategy by appealing to perceived LLMs reasoning ability and, unexpectedly, propensity towards cooperation. Our findings provide foundational insights into the multi-player human-LLM interaction in simultaneous choice games, uncover heterogeneities in both subjects behaviour and beliefs about LLMs play when playing against them, and suggest important implications for mechanism design in mixed human-LLM systems."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) are swiftly moving beyond the role of mere chatbots, and are increasingly integrated into every dimension of our social and economic lives. Soon, they will inevitably become active participants of complex interactions which were previously reserved exclusively for humans. It is also not difficult to imagine that soon humans will be interacting in environments dominated by hundreds and even thousands of agents with artificial intelligence (AI). This swift change presents new critical research frontier: understanding how humans adjust their behaviour when faced with strategic environments populated not only by people but also AI agents. In few years, understanding the nuances of human-AI strategic interaction will have profound implications for effective mechanism design in every facet of economic activity from markets for goods and services, through financial markets, to strategic negotiations. To date, effort has been dedicated to understanding how LLMs behave in both standard economic games [12] and more complex environments [16]. In contrast, strategic interactions of humans with LLMs have been largely left unexplored, with the exception of the work by Engel et al. [9] which looks at how humans interact with LLMs in two-player dominance-solvable prisoners dilemma. Crucially, an important question remains unaddressed: how do humans behave in strategic environments when faced with multiple LLM opponents where no dominant strategy exists? While existing experimental economics literature shows that human behaviour is sensitive to perceived characteristics of their opponents [1, 8], we currently lack insight into whether humans perceive LLMs as fundamentally Preprint. Under review. different from humans more rational, or perhaps more predictable, or even cooperative, and how these perceptions feed into observable behaviour in complex strategic settings. In this paper we take the first steps into the uncharted territory of human strategic interaction with multiple LLMs. To fix ideas, we focus on the classic p-beauty contest workhorse game for studying strategic reasoning (as revealed by subjects action choices and beliefs), often seen as simplified as simplified model of financial markets [15, 11]. The core novelty of our approach is in using within-subject experimental design, that allows us to compare how the same individuals approach the game when interacting with other human experimental participants or playing against LLMs (ChatGPT 3.5 and Claude v2). Our main interest here lies in looking at setups where humans interact with multiple opponents and no strategy for any of the players is dominant1. Such setup implies that, to choose strategy, our human participants have to form beliefs about their opponents actions. This allows us to investigate whether humans perceive LLMs differently from other humans. We also utilise version of the p-beauty contests with 2 contestants, which allows us to identify subjects with high strategic reasoning ability those that, beyond reasonable doubt, are capable of finding the (weakly) dominant strategy in the 2-player game. Separation of subjects into subsamples based on their reasoning ability allows us to further study heterogeneities in human behaviour when dealing with LLMs as opposed to humans. We are also able to examine which beliefs drive these behavioural shifts. By carefully studying behaviour in controlled laboratory environment with design that is incentivecompatible, we provide foundational insights into human-LLM strategic interactions, revealing not only that humans treat LLMs differently, but beginning to uncover who does so, and why. Our results map direction understanding the dynamic of complex human-LLM strategic interactions and designing economic mechanisms of the future."
        },
        {
            "title": "2 Related work",
            "content": "Beauty contests with 2 and more players. The behaviour of humans in = 2 and > 2 p-beauty contests has been widely studied [15, 10, 11, 6]. However, no previous study has used within-subject design to separate subjects based on their ability to solve the 2-player version of the contest (by identifying the weakly dominant strategy) and examine behavioural heterogeneities between these subjects when facing different types of opponents. As explained in Section 5, in our experiment we are able to identify subjects with high strategic reasoning ability ie those that can establish the (weakly) dominant strategy in the 2-player game, and show that these subjects are disproportionally represented among those who adapt their behaviour when interacting with LLMs. Strategic behaviour and observable characteristics of opponents. Experimental economics literature documents that subjects adjust their strategic behaviour depending on perceived characteristics of their opponents. For example, Agranov, et al. [1] find that subjects choose relatively lower number in the p-beauty contest when interacting with graduate students as opposed to undergraduate students. The central interest of this paper is in exploring how subjects interact with LLMs such as Chat-GPT, and Claude, which are rapidly becoming prevalent. To the best of our knowledge, no existing work has looked at human behaviour in the presence of LLMs in such strategic environments where players face multiple opponents. Role of LLMs in researching human behaviour. Leveraging LLMs to aid the study of human behaviour is novel research direction. Most efforts focus on understanding how LLMs themselves behave in standard games of economic interest [12] or using LLMs to simulate human behaviour [2]. Research into the direct interaction of humans with LLMs is rarer, with the most prominent exception being the recent experiments on human-LLM interactions in the prisoners dilemma [9]. None of the previous work has utilised within-subject design to study differences in human strategic behaviour in settings with single human and several LLM players, particularly in games like the p-beauty contest with more than 2 contestants which, unlike the prisoners dilemma, lack dominant strategy. The present paper is the first to address this gap. 1A (weakly) dominant strategy is the strategy that is (weakly) better than any other strategy available to the player regardless of opponents choices in the sense of expected payoff maximisation."
        },
        {
            "title": "3 Theoretical framework",
            "content": "The p-beauty contest is standard tool in experimental economics for studying strategic reasoning and belief formation [15, 11]. The task amounts to choosing an integer between 0 to 100. The winner is the person whose choice is closest to the target number equal to fraction of the average of all contestants choices. Often, = 2/3 but behaviour with other values of p, including those greater than one, has also been studied2. Crucially, the optimal guess in p-beauty contest depends on how many participants are there in the contest and the beliefs one forms about their opponents. 3."
        },
        {
            "title": "Identification of high strategic reasoning ability",
            "content": "An important distinction between p-beauty contests with 2 or more than 2 contestants that we use to identify subjects with high strategic reasoning ability lies in the existence of the (weakly) dominant strategy in the former, which is not present in the latter. In 2-player contests, choosing zero is the unique weakly dominant strategy ie the strategy that is (weakly) better than any other strategy against all possible strategies of ones opponent(s), for any < 1 [10]. Since the target number (p average) is always less than the average, the player choosing the lowest number, if unique, wins. Zero guarantees at least tie against any opponent choice and win against any choice larger than that. Identifying this requires recognising dominance of zero, either through iterative deletion of weakly dominated strategies or contingent reasoning. Despite this, many experimental subjects fail to choose zero [10, 6], suggesting heterogeneity in strategic ability. For p-beauty contests with more that two contestants, no strategy is weakly dominant. While the target number cannot exceed 100p and so any strategies above 100p are weakly dominated, selecting among the undominated strategies depends entirely on players beliefs about their opponents choices. Standard game theory predicts convergence to the Nash Equilibrium of zero through iterative deletion of weakly dominated strategies. The idea is that, if nobody is believed to be playing strategies above 100p, then the maximum value of the target value becomes 100p2, which, for any < 1 is smaller than 100p. Such iterative reasoning is akin to the removal of weakly dominated strategies, which at the end leaves only one undominated strategy ie zero3. However, observed choices are typically far above zero [15, 11], often interpreted through models of bounded rationality like Level-k thinking [15, 17, 7, 4]. In this framework, players perform some, but limited, number of steps of iterative reasoning, with higher levels leading to lower choices. This distinction between p-beauty contests with 2 or more than 2 participants is key for our identification strategy in this study. The 2-player version of the contest provides benchmark for identifying subjects capable of recognising the (weak) dominance of the zero strategy, which is indicative of high strategic ability. On the other hand, the contest with more than 2 contestants, lacking dominant strategy, is well-suited for studying how beliefs about opponents choices, and hence players own choices, could potentially be affected by the type of opponents (human or LLM) they face."
        },
        {
            "title": "3.2 The role of player’s beliefs about their opponents’ behaviour",
            "content": "In p-beauty contests with more than two contestants, as no strategy is (weakly) dominant, choosing specific strategy requires forming beliefs about how others will play, and then best-responding to those beliefs in the sense of expected payoff maximisation. Standard models assume that players form beliefs about other humans, drawing on shared experiences or assumptions about human rationality and cognitive limits. For example, in level-k model it is conjectured that players of level-1 assume that their non-strategic opponents randomise uniformly on [0, 100] and best-respond to those beliefs, level-2 players best-respond to level-1 players etc. The introduction of LLM opponents fundamentally challenges standard strategic reasoning. While LLMs do not think in the usual sense of the word, the text generated by largest and most capable modern LLMs closely resembles human-generated text and thus may give an impression of reasoning process. However, when dealing with LLMs, unlike when dealing with other humans, humans lack an established prior about LLMs behaviour in given task. Should one expect LLMs to engage in unbounded reasoning and perform all steps of iterative elimination of (weakly) dominated 2Nagel [15] used values of between 0.5 and 1.25, while Ho et al. [11] studied values in the 0.7-1.3 range. 3For = 2/3, arriving to zero takes 11 steps, while for = 1/2 only 7 steps are required. 3 Figure 1: Schematic summary of experimental design. strategies? Or is it more likely to mimic human play? Perhaps, one should expect LLMs to follow some other logic entirely, or be completely unpredictable? Understanding of human behaviour in human-LLM interactions requires examining both the behaviour itself but also the beliefs that humans form about their LLM opponents. Our experimental design described in Section 4 allows us to examine how perceived opponent type (human or LLM) influences strategic choices and underlying reasoning, focusing on whether subjects of different strategic reasoning ability exhibit behavioural patterns when interacting with humans and LLMs."
        },
        {
            "title": "4 Experimental design",
            "content": "The data for this paper was collected via monetarily-incentivised economics experiment conducted in laboratoryand is part of larger experimental study which poses questions outside of the scope of this paper. Below, we describe parts of experimental design that are relevant to this paper. This study received ethical approval from the Ethics Review Board at the University. All subjects gave informed consent prior to participation and were free to withdraw from the study at any point. The design of the experiment was pre-registered4. In accordance with standard practices, the experiment was coded in o-Tree [5] with server hosted on Heroku."
        },
        {
            "title": "4.1 Elicitation of choices against other participants",
            "content": "The first part of the experiment consisted of sequence of 6 versions of the p-beauty contest. The baseline variant G3P2/3 was 3-player beauty contest with = 2/3. The winner earned prize of 3, and in case of ties, the prize was split equally among the winners. For exact wording of the task, see Appendix A. For this paper, the other two relevant tasks were G2P1/2, G3P1/2, which are both variations of the above task with = 2/3 or 1/2 and group size set to 2 players. All 6 tasks (including the 3 relevant for this paper) were presented in random order."
        },
        {
            "title": "4.2 Elicitation of predictions about choices of other participants",
            "content": "As specified in Figure 1 (Task 2), in addition to eliciting subjects choices in the various versions of the p-beauty contest described above, in the second part of the experiment we elicited their predictions regarding the choices of other participants. For this paper, the relevant contest for which we elicited subjects predictions is G2P2/3. Our predictions elicitation task was similar to those proposed by Bosch-Rosa & Meissner [3] and Lahav [14], and amounted to asking subjects to allocate 17 tokens one for every other subject 4We used AsPredicted for pre-registration. copy of the form is available upon request. 4 participating in the same session across 20 equal-size bins5. See Figure 5 in Appendix for screenshot of experimental interface for this task. We use the data from this task in Section 5.1 to check whether subjects actions are consistent with their stated beliefs about the actions of their opponents. That is, we check whether the choices subjects made in the G2P2/3 version of the contest are best responses to their beliefs about choices of other experimental participants from the same session as elicited in this task."
        },
        {
            "title": "4.3 Elicitation of choices against LLMs",
            "content": "In the next task subjects were asked to make choice in the G3P2/3 version of the contest where their opponents were not other experimental participants but two Large Language Models (LLMs). The task presented to subjects in this part of the experiment was similar to that described in Section 4.1 but subjects were explicitly told that their two opponents are Chat-GPT (developed by OpenAI) and Claude (developed by Anthropic). For the exact wording of the task, see Appendix A. To extract LLMs choices, we prompted both Chat-GPT (v3.5) and Claude (v2) with the same text. Both language models picked 50 as their guess for the G3P2/3 version of the p-beauty contest. The exact prompt used along with responses of both LLMs are in Appendix B. This task was incentivised and we matched the choices of LLMs to choices of participants to determine earnings for this task. Notice that, when making their choices, our subjects had no knowledge of the actual choices of LLMs but were able to learn those at the very end of the experiment."
        },
        {
            "title": "4.4 Elicitation of choices against given play",
            "content": "After the main part of the experiment, subjects completed two tasks where play of opponents was given to them. Subjects were asked to choose decision in two versions of 2/3-beauty contest one with = 3 and another one with = 9. The decisions of their 2 or 8 opponents were drawn from U{0, 100} and given to the subjects, and the use of calculator was allowed. We included this task to check whether subjects are able to identify the best-response to the known choices of their opponents ie an environment very similar to that in the experiment but with Knightian uncertainty and risk completely suppressed. We use the data from this task in Section 5.1 to identify subjects who are able to best respond to known play of their opponents."
        },
        {
            "title": "4.5 Experimental workflow",
            "content": "All sessions of the experiment unfolded in the same way as described below. Subjects read and signed the consent forms. Then they completed instructions and quiz for the first task which amounted to making sequence of decisions as described in Section 4.1 above. Next, subjects completed instructions and quiz for the second task, which was the predictions elicitation task from Section 4.2. Next, as per Section 4.3, subjects completed the task against LLMs, followed by the task described in Section 4.4, and short demographics survey. No feedback was provided until the very end of the experiment. After everyone completed all parts of the experiment, subjects learned their payoffs and were able to browse the history of their decisions and outcomes for all tasks. Subjects had access to an on-screen calculator throughout all parts of the experiment. In addition to standard operations, the calculator had buttons for multiplication by 1/2 and 2/3 to ease calculations if required. See Figure 4 in Appendix for screenshot of our on-screen calculator. Subjects were paid for their choices in all parts of the experiment depending on their performance. Overall, subjects earned an average of 17 inclusive of the 5 show-up fee."
        },
        {
            "title": "4.6 Sample description",
            "content": "The experiment was conducted in April 2024 at the Behavioural Laboratory at the University using the local student population, including both undergraduates and postgraduates. total of 72 students completed the experiment across 4 sessions. Of these, at the time of taking the experiment, 43 students were studying towards an undergraduate degree, 22 towards postgraduate taught degree, and 3 5Since p-beauty contest has 101 possible choices, the first bin in our predictions elicitation task span numbers from 0 to 5 (inclusive). The second bin span numbers from 6 to 10, the third from 11 to 15, and so on. 5 towards PhD. The average age was 22.6 years, and 54 subjects were females. Each experimental session took about 1.5 hours to complete. When sampling, we avoided students from the Economics department, and focused on students from quantitative disciplines. Of the 72 subjects, 1 has taken at least one economics/game theory module as part of undergraduate education, and 43 took at least one mathematics module. Finally, 5 subjects indicated they came across the p-beauty contest or similar tasks before the experiment."
        },
        {
            "title": "5 Analysis and results",
            "content": "In this section we analyse our data and present our results. First, in Section 5.1, we introduce conditions that subjects need to satisfy to be classified as displaying high strategic reasoning ability, and identify subset of our sample who conform to these conditions. Second, in Section 5.2, we analyse the differences in behaviour of our subjects when interacting with other experimental participants and with LLMs. Here, we devote special attention to behavioural differences between subjects with high strategic reasoning ability and the rest of the sample. The insights from the qualitative data we collected on the motivations of behaviour against LLMs is discussed in Section 5.3. All statistical tests reported below are two-tailed."
        },
        {
            "title": "5.1 High strategic reasoning ability",
            "content": "In this section, using systematic approach, we identify subset of subjects characterised by high strategic reasoning ability. To achieve this, we specify and justify three conditions that subject needs to fulfil in order to be classified as possessing high strategic reasoning ability. We classify subjects as possessing high strategic reasoning ability if they simultaneously satisfy three conditions designed to identify genuine understanding of the game structure beyond chance: A: Chose the weakly dominant strategy (zero) in at least one 2-player contest ie G2P2/3 and G2P1/2 (Section 4, Task #1). B: Correctly best-responded to induced ie known and given, opponents choices (Section 4, Task #5). C: Exhibited choices consistent with their stated predictions about choices of other experimental participants in the G2P2/3 task (Section 4, Task #1 and Task #2). Compliance with all three conditions suggests robust understanding unlikely to occur by chance. For context, 6 of our subjects (8.3%) chose the dominant strategy in both 2-player contests an outcome with extremely low probability under uniform randomisation (p < (1/101)2), and all of these individuals also met conditions and C, thus falling within our high strategic reasoning ability classification. For full details of our classification method, see Appendix C. Overall, we identify that 16.7% of subjects in our sample can be classified as possessing high strategic reasoning ability. Importantly, all of them play zero in at least one of the 2-player versions. Result 1 In our sample, 16.7% of subjects possess high strategic reasoning ability. Crucially, these are the subjects who are capable of solving the 2-payer version of the p-beauty contest by identifying the (weakly) dominant strategy."
        },
        {
            "title": "5.2 Differences in behaviour against other subjects and LLMs",
            "content": "Figure 2(a) presents histograms of subjects choices in the humans and LLMs versions of the G3P2/3 task, both with fitted kernel density estimates. The mean number that subjects chose in the human version of the task was 29 (std 17.3). When interacting with LLMs, the mean number was 23 (std 17.3). This difference is statistically significant (Wilcoxon Sign Rank test (WSR), p-val = 0.004, N=72). Figure 2(b) presents subject-specific differences between choices submitted against humans and against LLMs. We see that, choices of 50% of our subjects against LLMs were lower than their choices against humans. For those subjects, the average reduction in the chosen number is 18.2pts. 6 Figure 2: G3P2/3 task when playing against humans and LLMs: (a) Frequency histograms of observed choices and (b) subject-specific differences between choices. In addition, 12.3% of subjects submitted the same choices against both humans and LLMs. Finally, for the remainder of the sample, the average increase in the chosen number is 7.3pts. Result At the individual level, choices of subjects in p-beauty contests made against LLMs are statistically lower than those made against humans. Importantly, we observe that 50% ie the plurality, of our subjects submitted lower choices against LLMs than against humans, while considerably fewer ie 37.7%, submitted relatively higher choices against LLMs. Te average decrease in the chosen number in the former subsample was almost 2.5 times larger in magnitude than the average increase in the latter. Next, from Figure 2(a), we see that there are significantly more zero-choices made against LLMs than against humans. The share of subjects we observe choosing zero when interacting with real people in the G3P2/3 version of the p-beauty contest is 4.2%, rising to 15.3% in the LLMs version. This difference is statistically significant (WSR, p-val = 0.024, N=72). Interestingly, of these 15.3% zerodecisions, 36.4% come from subjects who display high strategic reasoning ability who themselves represent only 16.7% of the sample. In fact, most of the difference between the choices against humans and LLMs is driven by the frequency of zero choices. In particular, discarding zeroes, the average choice we observe in the human version of G3P2/3 task is 30.5, and 27.2 in the LLMs version of the task. This is considerable reduction from the raw difference of 6pts observed when all observations are included. Nevertheless, dropping 20 observations which have at least one choice of zero across the two tasks, the difference between the choices becomes only marginally significant (WSR, p-val = 0.060, N=52). We recognise that the above results may be muddled by introspective learning. After all, all humanto-human interactions in the experiment came strictly before any interactions with LLMs. However, in 3 out of 4 of our sessions, the relevant choice against humans in the G3P2/3 task was made in round 4 or 5 ie relatively late in the sequence of decisions once introspective learning has plausibly already happened. Only in 1 of our sessions did this decision come first in the sequence. Recall that the difference in mean choices in the human and LLM versions of the task is 6pts. Excluding data from 18 subjects from the session where the G3P2/3 task came first, the difference between mean choices of subjects in the two versions of the tasks falls to 4.1pts and becomes insignificant with two-tailed test (WSR, p-val = 0.153, N=54). However, we see that in the 3 relevant sessions, zero is selected in 16.7% of decisions made against LLMs relative to 5.6% of decisions made against humans (WSR, p-val = 0.066, N=54). Overall, our data suggests that subjects choose zero significantly more often when they interact with LLMs as opposed to humans. The last question we ask is whether the behaviour of the subjects with high strategic reasoning ability is different from the rest of the sample when it comes to interaction with LLMs. Observe that the 3-player version of the p-beauty contest does not have weakly dominant action, so it is 7 not immediately obvious that we should see subjects with high strategic reasoning ability choosing zero relatively more often. Yet, this is exactly what we see with 35.7% of these subjects playing zero against LLMs relative to 10% observed in the rest of the sample (Mann-Whitney U-test, p-val = 0.066, N1 =17, N2 =55). Result 3 The previous result is mostly driven by subjects choosing zero more often when playing the p-beauty contest against LLMs compared to the case where they interact with other humans. The observation persists when introspective learning is accounted for. Subjects with high strategic reasoning ability are more likely to play zero against LLMs relative to the rest of the sample. This result suggests that, at least in one-shot interactions with LLMs, people especially those with high strategic reasoning ability, have tendency to perceive these models differently compared to other experimental participants and appear to expect more equilibrium behaviour from LLMs."
        },
        {
            "title": "5.3 Motivations of behaviour against LLMs",
            "content": "Once subjects made their decisions against LLMs, we asked them to explain their reasoning in this part of the experiment. This was an open-ended non-incentivised question. Focusing on 11 subjects who chose zero in the LLM task, 6 respond by referring to LLMs ability to reason through to select zero eg through familiarity with similar tasks, explicit iterative reasoning, etc. Interestingly, other 4 subjects refer to cooperation in their explanations. In particular, they say that they expect LLMs to select zero as, in the case of successful cooperation, this would guarantee that multiple winners share the prize equally6. One subject explicitly states that they expect LLMs to cooperate at least with each other. Result 4 When interacting with LLMs in p-beauty contests with no weakly-dominant strategy, subjects who choose zero do so because they expect LLMs to also choose zero. While most of these subjects expect LLMs to be able to reason through to equilibrium, another 36% expect LLMs to display cooperative behaviour. This suggests that people may perceive LLMs not only as being more prone to behave in manner consistent with Nash equilibrium but also perhaps display more cooperation relative to humans. The perception of LLMs as prone to cooperation is particularly noteworthy in the context of the p-beauty contest an inherently non-cooperative setting where coordinated action does not lead to increased individual or collective benefit. It is worth pointing that out of the 6 subjects who appeal to LLMs ability to reason, 3 belong to our subset of subjects with high reasoning ability, whereas out of the 4 subjects who quote cooperative tendencies, 3 belong to this subset. Intriguingly, these subjects, who are themselves highly able strategically, appear capable of attributing both high-level strategic reasoning and seemingly nonstrategic cooperative tendencies to LLMs, suggesting non-trivial mental models of LLM opponents."
        },
        {
            "title": "6 Discussion",
            "content": "In this section, we discuss several questions which arose from the experiment we report in this paper. Who are those who treat LLMs differently to humans in strategic settings? While we observe 50% of our sample choosing lower numbers when interacting with LLMs rather than humans, we find that subjects with high strategic reasoning ability are disproportionally represented among those treating LLMs differently to human opponents in p-beauty contests. These subjects, capable of solving the 2-player version of the contest, were more likely to choose zero when facing LLMs 6Observe that all players choosing the same number whether it is 0, 1, or 25, guarantees that the prize is split among them equally. The fact that players who expect cooperation from LLMs choose zero rather than any other number means they also recognise that this is an equilibrium outcome where nobody has an incentive to deviate. 8 compared to the rest of the sample. This suggests that, whether humans treat LLMs differently to other humans in strategic settings may significantly interact with their own strategic sophistication. While our findings point to strategic sophistication as the main factor driving behavioural heterogeneities, these results stem from university sample drawn primarily from quantitative backgrounds. Further research is needed to understand how our findings generalise to the broader population. What are the drivers of those differences? The main driver appears to be the expectation that LLMs are more likely to possess greater strategic sophistication, thereby displaying equilibrium-like behaviour. Using qualitative data, we find that many subjects who play zero anticipate LLMs to be able to reason through to zero. Importantly, notable proportion also cited perceived tendency to cooperation as reason, expecting models to aim to share the prize equally. This is particularly suprising in p-beauty contest setting which is not cooperative setting. We also find that subjects with high strategic reasoning ability are disproportionally represented among those citing both reasoning and cooperation motivations. Notice however that these beliefs were formed based on one-shot p-beauty contests with specific LLMs (ChatGPT 3.5, Claude v2). How beliefs form in other strategic settings and repeated interactions with feedback are both open questions. What are the implications for mechanism design? Our results highlight that, when designing mechanisms for mixed human-LLM interactive settings, we must account for heterogeneity of various types of agents as well as their beliefs about opponents. Assumptions about human behaviour using data from strategic environments populated only by humans may fail in settings where (numerous) LLM agents are involved. Researchers working on mechanism design need to carefully investigate the validity of those assumptions and ensure the mechanisms of the future are robust to various beliefs about LLM intentions and reasoning capabilities. At the same time, it may be possible to leverage the perception of LLM sophistication or cooperativeness to guide human behaviour. While the potential implications for mechanism design illuminated in this paper arise from observations of human behaviour specifically within p-beauty contests, they highlight the broader challenge of designing mechanisms for human-AI settings. Further research is needed to establish whether our findings translate into other environments such as (anti-)coordination or bargaining games. What are the implications for future research? Future research on this topic should significantly broaden the scope. Effort should be directed at exploring human-LLM interactions in wider range of strategic environments such as (anti-)coordination, public goods, and bargaining games, and in dynamic settings with learning opportunities. Importantly, research should test interactions with diverse LLMs beyond the two versions we used, including newer architectures and models calibrated for strategic play. Looking at the effects of scaling the number of LLM agents, potentially to hundreds or even thousands, and understanding how sensitive human behaviour is to varying LLM prompting strategies would also be valuable."
        },
        {
            "title": "7 Conclusion",
            "content": "This paper is the first to report results of controlled experiment where human subjects interact with Large Language Models (LLMs) in strategic environments. We show that, in p-beauty contests with no (weakly) dominant strategy, more subjects choose to play zero against LLMs than against other human participants. This behaviour suggests that subjects expect greater strategic sophistication from LLMs. Indeed, when explaining motivation for their zero-choices against LLMs, most subjects said that they expect models to be able to reason through to zero. Interestingly, the second motivation for choosing zero that we identify is the expectation that LLMs are more cooperative. Importantly, subjects who possess high strategic reasoning ability are disproportionally represented among those who chose to play zero against LLMs. While some research effort have already been directed to understanding how LLMs behave in both single-player and strategic environments, our paper is the first to illuminate the unexplored area of human interaction with LLMs in strategic settings with no (weakly) dominant strategy. We argue that understanding how and why humans interact with LLMs in strategic settings is an important emerging research direction."
        },
        {
            "title": "References",
            "content": "[1] M. Agranov, E. Potamites, A. Schotter, and C. Tergiman. Beliefs and endogenous cognitive levels: An experimental study. Games and Economic Behavior, 75(2):449463, 2012. 9 [2] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate. Out of one, many: Using language models to simulate human samples. Political Analysis, 31(3):337351, 2023. [3] C. Bosch-Rosa and T. Meissner. The one player guessing game: diagnosis on the relationship between equilibrium play, beliefs, and best responses. Experimental Economics, 23:11291147, 2020. [4] C. F. Camerer, T. H. Ho, and J. K. Chong. cognitive hierarchy model of games. The Quarterly Journal of Economics, 119(3):861898, 2004. [5] D. L. Chen, M. Schonger, and C. Wickens. oTree an open-source platform for laboratory, online, and field experiments. Journal of Behavioral and Experimental Finance, 9:8897, 2016. [6] E. Chou, M. McConnell, R. Nagel, and C. R. Plott. The control of game form recognition in experiments: Understanding dominant strategy failures in simple two person guessing game. Experimental Economics, 12:159179, 2009. [7] M. Costa-Gomes, V. P. Crawford, and B. Broseta. Cognition and behavior in normal-form games: An experimental study. Econometrica, 69(5):11931235, 2001. [8] J. Eichberger, D. Kelsey, and B. C. Schipper. Granny versus game theorist: Ambiguity in experimental games. Theory and Decision, 64:333362, 2008. [9] C. Engel, M. R. Grossmann, and A. Ockenfels. Integrating machine behavior into human subject experiments: user-friendly toolkit and illustrations. MPI Collective Goods Discussion Paper, (2024/1), 2024. [10] B. Grosskopf and R. Nagel. The two-person beauty contest. Games and Economic Behavior, 62(1):9399, 2008. [11] T. Ho, C. Camerer, and K. Weigelt. Iterated dominance and iterated best response in experimental p-beauty contests\". American Economic Review, 88(4):94769, 1998. [12] J. J. Horton. Large language models as simulated economic agents: What can we learn from homo silicus? Working Paper 31122, National Bureau of Economic Research, April 2023. [13] F. H. Knight. Risk, Uncertainty and Profit. Hart, Schaffner, and Marx Houghton Mifflin, 1921. [14] Y. Lahav. Eliciting beliefs in beauty contest experiments. Economics Letters, 137:4549, 2015. [15] R. Nagel. Unraveling in guessing games: An experimental study. American Economic Review, 85(5):1313 1326, 1995. [16] J. S. Park, J. OBrien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122, 2023. [17] D. O. Stahl II and P. W. Wilson. Experimental evidence on players models of other players. Journal of economic behavior & organization, 25(3):309327, 1994."
        },
        {
            "title": "A Wording of human and LLM versions of the contest",
            "content": "The wording of the human version of the G2P2/3 task was as follows: Choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous participants from this session. The winner will be the person whose number is closest to the target number. The target number is calculated as 2/3rds of the average of all chosen numbers of the 3 people in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. In contrast, below is the wording of the LLM version of the G2P2/3 task as presented to our human subjects: Choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous participants from this session. The winner will be the person whose number is closest to the target number. The target number is calculated as 2/3rds of the average of all chosen numbers of the 3 people in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Further suppose that the 2 anonymous players you are interacting with are advanced language models. In particular, you are playing against two advanced generative artificial intelligence chatbots: Chat-GPT (developed by OpenAI) and Claude (developed by Anthropic). Prompt for LLMs and models responses We prompted Claude (v2, Anthropic) and Chat-GPT (v3.5, OpenAI) on 07/02/2024 with the following text: Suppose you face the following decision scenario. You need to choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous players. The winner will be the player whose number is closest to the target number. The target number is 2/3rds of the average of all chosen numbers of the 3 players in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Choose your number. Claude chose 50 and responded as follows: Okay, lets think through this strategically. The target number will be 2/3 of the average of the numbers chosen by me and the other 2 players. If choose 100, the maximum possible number, the average could be at most (100 + 100 + 100)/3 = 100. So 2/3 of that is about 67. However, if the other players choose lower numbers, the average will be lower and so will the target number. So choosing 100 runs the risk that my number will be much higher than the target. On the other hand, if choose 0, the minimum possible number, the average could be at most (0 + 100 + 100)/3 = 67. So 2/3 of that is about 44. But again, if the other players choose higher numbers, my number of 0 may end up too low compared to the target. So think the optimal strategy is to choose 50. This balances the risk of being too high or too low compared to the range of possible target numbers. 50 seems like reasonable guess at what 2/3 of the average might be. Therefore, choose 50 as my number.\" Chat-GPT also chose 50 and provided the following response: In this scenario, rational approach involves considering what other players might choose and trying to optimize your own chances of winning or at least tying for the prize. Since the target number is 2/3rds of the average of all chosen numbers, we can expect players to choose numbers that are higher than 0 and lower than 100, as choosing extreme values wouldnt be advantageous. One common strategy in such scenarios, known as the \"centipede game,\" involves reasoning that players should aim to choose number around the middle of the possible range, as this would likely lead to higher average and thus higher target number. Given this, reasonable choice might be around 50, as its in the middle of the range and likely to be close to the average of the numbers chosen by all three players. So, would choose 50.\""
        },
        {
            "title": "C Identification of subjects with high strategic reasoning ability",
            "content": "In this appendix we specify and explain the three conditions we use to identify subjects with high strategic reasoning ability. To be classified as someone with such ability, subject must simultaneously satisfy all three conditions. Figure 3 schematically shows the subsets of our sample which conform with various combinations of conditions A, B, and C. Condition A: choose weakly dominant strategy at least once. Our first requirement is that subject with high strategic reasoning ability should choose the weakly dominant strategy ie play zero, in at least one contest with 2 players. The rationale is that people may not get it right the first time they face such contest, but arrive to this strategy through introspective learning. In our sample, in addition to the 6 (8.3%) subjects who choose zero in both 2-player contests, 10 subjects (13.9%) chose zero in one of them only7. Thus, in addition to the 6 subjects who chose zero in both G2P1/2 and G2P2/3, we have 10 of subjects who may have solved the contest at their second attempt thanks to introspective learning. However, it may also be that they chose zero the second time purely by accident. To rule out accidental choices, we make impose two extra conditions as follows. Condition B: best-respond to induced beliefs in the control task. We believe that displaying high strategic reasoning ability requires, at minimum, that one is able to best respond to induced ie known and given, beliefs. In the context of p-beauty contest, this entails that, if the actions of opponents are known meaning there is no Knightian uncertainty [13] or risk, player with high strategic reasoning ability should be able to win the contest. To test for ability to best-respond to induced beliefs, as explained in Section 4.4, we included control task where subjects faced p-beauty contests with 9 opponents8 In this task, subjects were interacting with computerised 7We also observe that only one of the subjects who chose zero in the first 2-player version of the contest they faced in the random sequence of contests subsequently chose different number in the second 2-player version. That is, only one subject, for some reason, has unlearned the weakly dominant strategy through introspection. This subjects failed to satisfy one other criteria we impose ie best responding to stated beliefs in G2P2/3, and so is not classified as possessing high strategic reasoning ability. 8In fact, for control, we included two versions of the contest with 9 players and with 3. Notice, however, that the latter is very similar to the understanding check that subjects had to complete after reading the instructions to participate in the experiment. We therefore consider it weak control. Additionally, 69 of 72 subjects won in 11 Figure 3: Schema showing the number (and proportion) of subjects who meet the three conditions we impose on individual decisions to identify subjects with high strategic reasoning ability. To be classified as displaying high strategic reasoning ability, subject must satisfy all three conditions A, B, and C. players who were randomising on [0, 100] uniformly and independently. The sequence of opponents actions was randomly generated for each subject and presented on the screen. In our sample of 72 subjects, 59 (81.9%) best-responded to induced beliefs in the 9-player control contest. Moreover, of our 16 subjects (22.2%) who chose weakly dominant strategy at least once, everybody bestresponded to induced beliefs, thereby satisfying the second condition. Condition C: best-respond to stated beliefs in G2P2/3. While being able to best-respond to induced beliefs is the minimum pre-requisite for displaying high strategic reasoning ability, to be classified as someone with such ability, one should also be capable of best-responding to their own beliefs. Given that we only have access to subjects stated beliefs (collected through our predictions elicitation task) rather than true beliefs, we require that the actions and predictions of subjects with high strategic reasoning ability are plausibly consistent for the G2P2/3 task9. We believe that best-responding to both induced and stated beliefs is unlikely to happen by accident, and so for such players stated beliefs are informative of their true beliefs. Out of our 72 subjects, 17 (23.6%) have plausibly consistent decisions in G2P2/3. This includes 5 subjects with non-zero (but consistent) choices, and 12 subjects with zero choices. Importantly, of the 16 subjects who satisfy conditions and above, 4 fail the requirement of best-response to stated beliefs in the G2P2/3 version of the contest10 Overall, 12 subjects (16.7% of the sample) simultaneously satisfy all three conditions and so are classified as possessing high strategic reasoning ability."
        },
        {
            "title": "D Experimental Instructions",
            "content": "Below are the instructions and understanding quizzes for all tasks from the experiment. Notice that all instructions were shown sequentially rather than together. Further, for Task #2 (the beliefs elicitation task), participants were given paper copy of instructions in addition to those available on their computer stations. Throughout instructions and quizzes, variables that were randomised at the subject level appear in brackets eg variable. Finally, for Task #5 (cognitive reflection test), the order of the four questions was randomised at the subject level. the 3-player control contest, and we have no subjects winning in the 9-player contest but failing the 3-player one. Thus, all subject who won the 9-player control contest also won the 3-player one. 9For the 2-player version of the contest, consistency only requires that subjects own action is (weakly) lower than the lowest predicted action of the 17 other experimental participants from the same session. 10Specifically, 3 allocate positive amount of tokens to bins associated with integers lower than their own chosen integer and so their decisions are clearly inconsistent. In addition, one subject allocated positive amount of tokens to the first bin but chose 1. It may be, that all tokens allocated to the first bin were associated with integers in [1, 5] rather than zero. Yet, looking at additional clarification data, we find that, if given the option, this subject would have allocated all tokens from the first bin to zero as opposed to integers in [1, 5], making the decision pair inconsistent. For details of the design of clarification questions see Section 4.2."
        },
        {
            "title": "Instructions",
            "content": "Hello and welcome to our experiment! We anticipate that completing this experiment should take about 60-90 minutes. Throughout the experiment, we will ask you to complete series of tasks followed short questionnaire. The instructions for every task will be given in due course. The questionnaire contains some questions regarding basic demographics, as well as those relating to your decisions in the experiment. You will be paid 5 for showing up to this experiment. Additionally, we will pay bonuses for your decisions in the tasks. The exact payment procedures for each task will be explained in due course. Throughout this study you will have access to simple on-screen calculator. You can access the calculator now by clicking on the Calculator button on the right hand-side of the interface. Should you want to make any calculations, we would like to ask you to use this calculator and refrain from using other calculators. Everyone participating in this study receives the same instructions for all tasks. Task #1: Instructions Before completing Task #1, you are asked to complete quiz question. You have 3 attempts and will only be allowed to continue with the experiment if you pass the quiz. Once you complete the quiz question, you will be asked to make series of decisions in 8 decision scenarios. We ask you to spend minimum of 60 seconds on each decision scenario. For Task #1, at the end of the experiment, we will randomly select 2 of decision scenarios and pay you bonus, the size of which will depend on your performance in those scenarios. Task #1: Quiz attempt Suppose you observe group of people X, Y, and face the following decision scenario. Everyone in the group is asked to choose number between 0 and 100 (inclusive of both endpoints). The winner is the person whose number is closest to the target number. The target number is calculated as 2/3rds of the average of all chosen numbers of the 3 people in the group. The winner gets prize of 3. In case of tie the prize is split among those who tie. Further suppose that chooses x, y, and z. Who is the winner in the decision situation above? Task #2: Instructions page 1 of In the previous task, every participant was asked to make series of decisions. In Task #2, we would like to ask you to estimate how the other 17 participants who are participating in this session today behaved in some of the decisions in Task #1. To make your predictions, we ask you to use set of 20 sliders. An example of the predictions interface is below. As you can see, each slider represents an interval of possible choices for example, choices between 0 and 5 (inclusive) correspond to the first slider, choices between 6 and 10 to the second slider etc. We ask you to allocate 17 prediction tokens to the sliders one for every participant (other than you) who is participating in this session. You can allocate the tokens to sliders by either pulling the relevant sliders 13 themselves or entering numbers directly over them using the keyboard. If you believe that no participant chose number in given interval, you should drag the relevant slider all the way to zero or input 0 in the field above it. Task #2: Instructions page 2 of 3 Earlier in the experiment you faced the following decision: Choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous participants from this session. The winner will be the person whose number is closest to the target number. The target number is calculated as 1/2 of the average of all chosen numbers of the 3 people in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. In Task #2 you need to predict the choices that the other 17 participants from this session made in the above decision in Task #1. As an example, suppose that you believe that in the above decision: 4 participants chose numbers between 21 and 25, and 13 participants chose numbers between 66 and 70. In this case, you should: drag the slider labelled 21-25 to 4 (or input 4 in the field directly above that slider), and drag the slider labelled 66-70 to 13 (or input 13 in the field directly above that slider). Feel free to use the sliders below to represent the above predictions. Task #2: Instructions page 3 of You may receive bonus for your predictions in Task #2. The accuracy of your predictions determines the probability with which you receive the bonus. In particular, once you make your predictions, we will calculate your score as the number of your prediction tokens that coincide with actual decisions of participants. We will then compare your score to random number drawn uniformly at random between 1 and 17 (inclusive). If your score is equal to or greater than the random number, you win bonus of 3 for that prediction. On the other hand, if your score is smaller than the random number, you do not win anything for that prediction. Therefore, the probability with which you win bonus for your prediction is calculated as probability of bonus = score 17 100% As an example, recall the predictions we discussed on the previous page: 4 participants chose numbers between 21 and 25, and 13 participants chose numbers between 66 and 70. Suppose that, indeed, 4 participants chose numbers between 21 and 25, and 13 participants chose numbers between 66 and 70. Then your score is 17. In this case, you win the bonus with probability 17 17 100% = 100%. In other words, you are guaranteed to win the bonus for this prediction. On the other hand, if 13 participants chose numbers between 21 and 25, and 4 participants chose numbers between 66 and 70, then your score is 8. In this case, you win the bonus with probability 8 17 100% = 47.1%. In other words, your odds of winning the bonus for this prediction are just about 50:50. Finally, if all 17 participants chose numbers between 30 and 35, then your score is 0. In this case, you win the bonus with probability 0%. In other words, there is no chance that you win the bonus for this prediction. 14 In Task #2, we will ask you to predict decisions of other participants in 3 decisions scenarios from Task #1. At the end of the experiment, we will randomly select 1 of your predictions for payment. If you won the bonus in that prediction, you would earn the value of the bonus for Task #2. Conversely, if you did not win bonus for that prediction, you would earn nothing for Task #2. Notice that we will never pay for your choice and predictions for the same decision scenario. Before completing Task #2, you are asked to complete 2 quiz questions. You have 3 attempts and will only be allowed to continue with the experiment if you answer both questions correctly. Task #2: Quiz attempt Earlier in the experiment you faced the following decision: Choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous participants from this session. The winner will be the person whose number is closest to the target number. The target number is calculated as 1/2 of the average of all chosen numbers of the 3 people in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Question A. Suppose that you believe that in the above decision: prediction 1 participants chose numbers between range 1, prediction 2 participants chose numbers between range 2, and prediction 3 participants chose numbers between range 3. Further suppose that the other participants choices were actually as follows: actual 1 participants chose numbers between range 1, actual 2 participants chose numbers between range 2, and actual 3 participants chose numbers between range 3. Please calculate your score based on your predictions and actual participants choices. Question B. Suppose your score is score and the random number is x. Do you win the bonus for your predictions? Task #3: Instructions Task #3 contains 1 question similar to the decision situations you have encountered earlier in the experiment. For this task, we will pay you bonus the size of which will depend on your decision in the question. You will have access to the calculator in the usual part of the interface. Task #3: Question Suppose you face the following decision scenario. You need to choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous players. The winner will be the player whose number is closest to the target number. The target number is 2/3rds of the average of all chosen numbers of the 3 players in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Further suppose that the 2 anonymous players you are interacting with are advanced language models. In particular, you are playing against two advanced generative artificial intelligence chatbots: Chat-GPT (developed by OpenAI) and Claude (developed by Anthropic). Choose your number. Task #4: Instructions Task #4 contains 2 questions similar to the decision scenarios you have encountered earlier in the experiment. We will randomly select 1 question and pay you bonus, the size of which will depend on your decision in that question. You will have access to the calculator in the usual part of the interface. 15 Task #4: Questions Question 1. Suppose you face the following decision scenario. You need to choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 2 other anonymous players. The winner will be the player whose number is closest to the target number. The target number is 2/3rds of the average of all chosen numbers of the 3 players in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Further suppose that the choices of other players are known to you. Specifically, they choose the following numbers: sequence of 2 random integers on [0, 100]. Choose your number. Question 2. Suppose you face the following decision scenario. You need to choose number between 0 and 100 (inclusive of both endpoints). You will be matched in group with 8 other anonymous players. The winner will be the player whose number is closest to the target number. The target number is 2/3rds of the average of all chosen numbers of the 9 players in your group (including you). The winner will get prize of 3. In case of tie the prize will be split equally among those who tie. Further suppose that the choices of other players are known to you. Specifically, they choose the following numbers: sequence of 8 random integers on [0, 100]. Choose your number. Task #5: Instructions Task #5 consists of 4 questions. You will earn 1 for each correct answer and nothing for each incorrect answer. You have 4 minutes to complete this task and the timer will always be displayed at the top of the page. You will have access to the calculator in the usual part of the interface. Task #5: Question 1 of 4. If youre running race and you pass the person in 2nd place, what place are you in? Task #5: Question 2 of 4. farmer had 15 sheep and all but 8 died. How many are left? Task #5: Question 3 of 4. Jerry received both the 15th highest and the 15th lowest mark in the class. How many students are in the class? Task #5: Question 4 of 4. man buys pig for 60, sells it for 70, buys it back for 80, and sells it finally for 90. How much has he made?"
        },
        {
            "title": "E Screenshots from the interface",
            "content": "Figure 4: Interface of the on-screen calculator used in the experiment. 16 Figure 5: Interface of the predictions elicitation task of the experiment."
        }
    ],
    "affiliations": [
        "School of Economics University of Edinburgh"
    ]
}