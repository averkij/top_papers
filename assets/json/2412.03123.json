{
    "paper_title": "Robust Multi-bit Text Watermark with LLM-based Paraphrasers",
    "authors": [
        "Xiaojun Xu",
        "Jinghan Jia",
        "Yuanshun Yao",
        "Yang Liu",
        "Hang Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We propose an imperceptible multi-bit text watermark embedded by paraphrasing with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave differently so that their paraphrasing difference reflected in the text semantics can be identified by a trained decoder. To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level. Then we use a text classifier as the decoder to decode each bit of the watermark. Through extensive experiments, we show that our watermarks can achieve over 99.99\\% detection AUC with small (1.1B) text paraphrasers while keeping the semantic information of the original sentence. More importantly, our pipeline is robust under word substitution and sentence paraphrasing perturbations and generalizes well to out-of-distributional data. We also show the stealthiness of our watermark with LLM-based evaluation. We open-source the code: https://github.com/xiaojunxu/multi-bit-text-watermark."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 4 ] . [ 1 3 2 1 3 0 . 2 1 4 2 : r ROBUST MULTI-BIT TEXT WATERMARK WITH LLM-BASED PARAPHRASERS Xiaojun Xu1, Jinghan Jia2*, Yuanshun Yao1, Yang Liu3*, and Hang Li {xiaojun.xu,kevin.yao,lihang.lh}@bytedance.com jiajingh@msu.edu, yangliu@ucsc.edu 1ByteDance Research 2Michigan State University 3University of California, Santa Cruz *Work done while at ByteDance Research. We propose an imperceptible multi-bit text watermark embedded by paraphrasing with LLMs. We fine-tune pair of LLM paraphrasers that are designed to behave differently so that their paraphrasing difference reflected in the text semantics can be identified by trained decoder. To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level. Then we use text classifier as the decoder to decode each bit of the watermark. Through extensive experiments, we show that our watermarks can achieve over 99.99% detection AUC with small (1.1B) text paraphrasers while keeping the semantic information of the original sentence. More importantly, our pipeline is robust under word substitution and sentence paraphrasing perturbations and generalizes well to out-of-distributional data. We also show the stealthiness of our watermark with LLM-based evaluation. We opensource the code: https://github.com/xiaojunxu/multi-bit-text-watermark."
        },
        {
            "title": "Introduction",
            "content": "Text watermark aims to encode some imperceptible signal into piece of text so that people are able to decode the signal from the text (Liu et al., 2024). It can be useful in various applications such as copyright protection and hidden message communication. With the development of Large Language Models (LLMs), there is also growing need to track misinformation spread by LLMs using text watermark injected to model outputs (Kirchenbauer et al., 2023). We study the methodology of injecting multi-bit watermark message into piece of text by paraphrasing. The watermarked text will keep the semantic meaning of the original text after paraphrasing. Another paired decoder will be used to decode the message from the watermarked text. Unlike lexical-based watermarks which inject watermarks by synonym substitutions, the paraphrasing-based method has larger action space for watermark injection and also is more robust under perturbations. However, there are also challenges in designing paraphrasing-based watermarks, as it is unclear on how to properly inject imperceptible but detectable watermark signal while keeping the text quality and original semantic meaning. In this work, we propose paraphrasing-based watermark by simultaneously fine-tuning an LLM-based paraphraser as the encoder and train LLM-based text classifier as the decoder. The pipeline is shown in Figure 1. In the encoding stage, we will paraphrase the input text conditioned on user-chosen key to generate the watermarked text. In the decoding stage, we will extract the code from the input text with the decoder and compare with the previously chosen key to see if it is watermarked by the user. The key to produce high-quality text watermark in our method is to train good encoder-decoder pair. For the decoder, we can train it with standard classification loss so that it can better classify between bit-0 texts and bit-1 texts. For the encoder, we would like to fine-tune it so that its generated text can be better classified by the decoder. Inspired by (Xu et al., 2024), we show that we can use the decoder as reward model to evaluate how well the paraphrased text generated by the encoder can be correctly classified. Thus, we can use PPO-based RL techniques to finetune the encoder so that the injected watermark can be better decoded. We adopt co-training framework so that the encoder and decoder are alternatively updated during the training process. Through experiments, we show that our experiments can achieve very high watermark detection performance while maintaining the paraphrasing fidelity. We achieve over 95% bit accuracy and over 0.99 detection AUC, both outperforming existing methods significantly. In addition, we can apply simple repetition-based strategy and improve the detection AUC to over 0.9999. In addition, our method also shows good robustness under word substitution and sentence paraphrasing perturbations. We also evaluate our methods over out-of-distributional Figure 1: The overview of our watermark pipeline. During encoding, we use an encoder to parapharse the input text given user-chosen key. During decoding, we extract the bits from the text using the decoder. (OOD) data and observe that our model can achieve over 0.99 AUC for most of the OOD tasks. All these results show the effectiveness and robustness of our watermark. The rest of the paper is organized as follows. We will first introduce the preliminary knowledge of the work in Section 2. Then we introduce our paraphrasing-based watermark methodology in Section 3. We will show the experiment results in Section 4. We discuss the related work in Section 5 and include other necessary discussions in Section 6. Finally, we conclude the work in Section 7."
        },
        {
            "title": "2 Preliminary",
            "content": "2.1 Multi-bit Text Watermark The goal of the work is to inject multi-bit watermark message into piece of text by paraphrasing. Formally speaking, in the watermark injection stage, we are given an original text xo and watermark message {0, 1}. We will inject watermark by generating new watermarked text with encoder xw = E(xo, ). To extract the watermark, we will use watermark decoder = D(xw) to decode the injected watermark. We hope that the decoded bits should match the prefix of the designed watermark message, i.e., = [: len(M )]. Note that this is vary-length watermark, where the length of watermark message is dependent on the length of text - the longer the text is, the more information we can encode in the watermarked text. This is contrary to the fix-length text watermark (e.g. (Zhang et al., 2024b)), where the watermark code is fixed length for any given input text. The length of depend on different watermark designs, and we will introduce them in Section 3.1. We have the following requirements on the paraphrased text: Fidelity: The watermarked text should not change the meaning of the original text. The similarity sim(xo, xw) should be high. Accuracy: The watermark decoder should accurately decode the watermark message. The error rate [: len(M )]0 should be low. Robustness: The watermark message should still exist after the watermarked text undergoes some perpert = D(pert(xw)) denote decoded message from perturbed watermarked text. We turbation. Let hope that the error rate after perturbation pert [: len(M pert)]0 should be low. Stealthiness: The watermark should not be easily detected by human eyes. We evaluate it with the criteria that human cannot easily detect the watermarks in the text. Formally speaking, let = Dhuman(xw) be the human guess on the watermark code. We hope that h)]0 should be high, i.e. human guess on the watermark code has high error rate. [: len(M 2.2 Background: PPO Proximal Policy Optimization (PPO) (Schulman et al., 2017) is standard way to optimize language model towards high reward calculated by some pre-defined reward functions r(x) R, where is the input text (i.e. 2 sequence of tokens). Let π(xtx<t) denote the probability of generating token xt given the context, and π(x<t) denote the overall probability vector. We use πθ to denote the model to train and πref to denote reference model. People will first estimate an advantage at each step At(x) given the final reward r(x), which approximates how each token contributes to the final reward. There are different choices of how to estimate the advantage. We use the Generalized Advantage Estimation (GAE) (Jaques et al., 2019; Zheng et al., 2023) with critic models, which we omit the details here. Having the advantage At(x) at each step, the PPO algorithm will optimize the input by minimizing the following loss: ℓP O(θ; x) = (cid:88) (cid:16) Et (cid:2) πθ(xtx<t) πref (xtx<t) At(x)(cid:3) + λkKL(πθ(x<t), πref (x<t)) (cid:17) (1) where the first term is to maximize the expected advantage on each token, and the second term is to regularize the model to not drastically change from the reference model."
        },
        {
            "title": "3 Methodology",
            "content": "3.1 Overview We illustrate the high-level pipeline of our watermark in Figure 1. Our core idea is to inject the watermark into piece of text by paraphrasing the text to include the imperceptible watermark signal, which can be later decoded by text classifier. To encode watermark message into piece of text, we will apply LLM-based paraphraser conditioned on one watermark bit (0 or 1). The watermark bit is initialized as the first bit of the watermark message, and updated to later bits during the token-by-token generation process. Different segments in the generated text will correspond to different bits in the message code. To decode the watermark message from piece of watermarked text, we will divide the text into multiple segments, and then apply the LM-based classifier to determine the watermark bit for each segment. The concatenated message is the decoded watermark message. Text Segmentor Note that both processes require mechanism to divide text into segments, so that we can assign one bit to each segment of the text to inject multi-bit watermark code. We use text segmentor to do the segmentation, which will operate in two different modes during encoding and decoding.During encoding, it will take the current generated text and output boolean value S(xmode=E) {0, 1} to determine whether the next token will belong to new segment. During decoding, it will take piece of text as input and segment it into list of segments S(xmode=D) = [x1, x2, . . .]. In this work, we choose to do the segmentation on the sentence-level, i.e. every sentence in the text is segment.We view it as simple yet robust choice, as word-level injection/deletion will not change the segmentation, and paraphrasing will also keep the sentence order in most cases. 3.2 Encoder: LLM-based Paraphraser The encoder aims to paraphrase the input text based on given watermark code and get xw = E(xo, ) based on LLMs. Our design of the encoder is to have two LLM-based paraphrasers (θ0, θ1) and use them alternatively in the token-by-token generation process, which is based on the current watermark code determined by the sentence segmentor. Formally speaking, let xw <t; θi) denote the process of generating the next token when paraphrasing the input xo parametrized by θi. The encoding algorithm is shown in Alg. 1. We track the current watermark bit, and the next token is generated with the corresponding paraphraser θbit. After each generation step, we check whether the next token will be in new segment by calculating S(xw; mode=E). If the new segment starts, we will update bit to be the next bit in the watermark message. = (xo, xw 3.3 Decoder: LLM-based Text Classifier The decoder will decode the watermark code from piece of text and get = D(xw) {0, 1}. We use g(x; θd) {0, 1} to denote binary classifier on text with parameters θd, and use gp(x; θd) (0, 1) to denote the predicted probability of class-1. The decoding algorithm is shown in Alg. 2. We will segment the input text into multiple segments S(x; mode=D), then apply the classifier to each segment to calculate the decoded watermark. 3.4 Co-training Framework The training framework is inspired by (Xu et al., 2024), which shows that the text classifier can be viewed as reward model to finetune LLMs with PPO, and that the text classifier and the LLM can be trained alternatively. In our work, we will alternate between two goals: optimizing the decoder (θd) and optimizing the paraphrasers 3 /* index of current watermark bit */ Algorithm 1 Watermark Encoding Algorithm xw = E(xo, ; S, θ0, θ1). Require: Input text xo; Watermark code ; Text segmentor S; Parameters for two paraphrasers θ0 and θ1. Ensure: Watermarked text xw 1: xw [ ] 2: 0 3: while xw[1] = EOS do 4: 5: 6: 7: 8: 9: 10: end while 11: return xw bit [i] xw.append(f (xo, xw; θbit)) /* Switch to the next bit if the current segmentation ends. if S(xw; mode=E) = 1 then + 1 end if */ Algorithm 2 Watermark Decoding Algorithm = D(xw; S, θd). Require: Input text xw; Text segmentor S; Parameters for the text classifier θd. Ensure: Decoded watermark 1: [ ] 2: for xi S(xw; mode=D) do 3: .append(g(xi; θd)) 4: end for 5: return (θ0 and θ1). The goal of the decoder is to accurately classify each bit of the original watermark code . We use the cross entropy loss to optimize the decoder: ℓD(θd; xw, ) = D(xw) (cid:88) i=1 (cid:18) [i] gs(xw ; θd) + (1 [i]) (1 gs(xw ; θd)) (cid:19) (2) The goal of the encoder is to generate inputs that can be better recognized by the decoder, while keeping its normal utility (i.e. good paraphrasing performance). To optimize the encoder, we utilize the idea of PPO that LLM can be fine-tuned with RL-based techniques with respect to reward model. Here, the decoder is used to calculate the reward of how the output of encoder can be successfully decoded as the original watermark code. Specifically, given original text xo, watermark code and the watermarked text xw = E(xo, ), the watermark reward rw is calculated by: rw(xw, ) = len(D(xw)) (cid:88) i=1 1{D(xw)[i] = [i]} (3) In addition, we will also calculate similarity reward rs(xw, xo) with text similarity model. The overall reward is weighted sum of the two rewards: r(xw, xo, ) = λw rw(xw, ) + λs rs(xw, xo) (4) Having the reward, we will use the PPO algorithm to update the parameters (θ0, θ1). One change in our PPO loss is that our xw is generated by two models θ0 and θ1, so each model only needs to update on the inputs that are generated by each model. The formal PPO loss for encoder, assuming we have calculated the advantage At(xw, xo, ) (which we will abbreviate as At without ambiguity), is as follows: ℓE(θ0, θ1) = + (cid:88) (cid:88) 1{xt πθ0(x<t)} 1{xt πθ1(x<t)} (cid:16) (cid:16) Et Et (cid:2) πθ0 (xtx<t) πref (xtx<t) (cid:2) πθ1 (xtx<t) πref (xtx<t) At (cid:3) + λkKL(πθ0 (x<t), πref (x<t)) (cid:17) At (cid:3) + λkKL(πθ1(x<t), πref (x<t)) (5) (cid:17) where the information of whether xt is generated by θ0 or θ1 is recorded during the generation stage. The algorithm is shown in Algorithm 3. We will have dataset consisting of original texts xo. In each training step, we randomly sample watermark key . Then we calculate the watermarked text xw with the current encoder (θ0, θ1) and the advantage function with the current decoder θd. Finally, we update the encoder and decoder with the respective losses. Algorithm 3 Training Algorithm of the Encoder and the Decoder. Require: Dataset D; Initialized parameters θ0, θ1, θd; Text Segmentor Ensure: Trained parameters θ0, θ1, θd 1: for all xo do 2: {0, 1} 3: 4: 5: 6: 7: end for 8: return xw E(xo, ; S, θ0, θ1) Calculate the advantage function At(xw, xo, ) with the reward function in Equation 4. Update θd with decoder loss ℓD(θd; xw, ) in Equation 2. Update θ0, θ1 with the encoder loss ℓE(θ0, θ1; At) in Equation 5. Initialization In practice, we observe that the training performance heavily depends on the model initialization. This is expected, as the encoder and decoder rely on each other to do the update and therefore requires good initialization - the update of (θ0, θ1) needs the reward provided by θd, and the update of θd needs the samples generated by (θ0, θ1). In our implementation, we will first initialize (θ0, θ1) with supervised finetuning (SFT) loss on paraphrasing dataset DSF = {(xSF para )}. We will simultaneously finetune the two models θ0 and θ1 on the paraphrasing dataset and hope that they both have small loss, but they also have difference in their behaviour (measured by JS divergence), with the loss as follows: , xSF ℓinit(θ0, θ1; xSF o , xSF para ) = ℓSF (θ0; xSF λJS JS(πθ0(xSF , xSF para xSF para ) + ℓSF (θ1; xSF para xSF ), πθ1(xSF o )) , xSF para ) (6) After the paraphrasers are finetuned, we will generate watermarked texts xw with randomly sampled watermark code , and initialize the decoder by optimizing ℓD(θd; xw, ) in Equation 2."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Setting Model and Training Settings We use relatively small TinyLlama-1.1b model architecture (Zhang et al., 2024a) for θ0, θ1 and θd, as we observe that small models can already achieve good performance in paraphrasing and watermarking. We show the experiments with larger Llama-2-7b models in Appendix C. The detailed prompt used by the pararphrasers are shown in Figure 3 in Appendix A. The encoder and decoder are trained and evaluated on the C4 RealNewsLike dataset (Raffel et al., 2020), processed using standard settings in (Kirchenbauer et al., 2023; Xu et al., 2024; Lau et al., 2024). Without specification, we will use texts with 128 tokens for training and evaluation. We fine-tune the model for 10,000 steps with batch size of 4. We use λw = 0.1, λs = 1.0 and λk = 0.02 as the coefficients. In the initialization stage, we will generate the paraphrased data xSF para with Pegasus paraphraser (Zhang et al., 2020), and use λJS = 1.0 for the intialization loss. Metric We evaluate three types of metrics of text watermark. The first type is the bit-wise accuracy, which evaluates how good the multi-bit watermark code is extracted. This includes the bit-wise accuracy (Bit Acc) of the decoded watermark and the number of total bits injected in the text (Bit Num). The second type is the textwise accuracy, which evaluates how well we can tell the watermarked text apart from other non-watermarked text. We will evaluate the decoder on both watermarked and non-watermarked texts, and calculate the area under ROC curve (AUC) and true positive rate under 1%, 0.01% false positve (TPR@FPR=1%, TPR@FPR=0.01%). For the fidelity, we calculate the similarity with the all-mpnet-base-v21 model following the setting in (Lau et al., 2024). Baselines We evaluate various baseline methods with different design ideas: RemarkLLM (Zhang et al., 2024b). The idea is to use fixed-length multi-bit watermark key and train Transformer-based paraphraser with watermark detector. The paraphraser is trained with Gumbel reparametrization techniques to minimize the decoding error. We use the T5-based paraphraser in their original setting and evaluate both the 4-bit version and 8-bit version of the watermarking model. KGW (Kirchenbauer et al., 2023) and KTH (Kuditipudi et al., 2023). They are LLM-based watermarks aiming to inject watermark to LLM-generated texts by altering the token sampling strategy during the generation stage of LLM. Note that their methods are not directly comparable with ours, as they are not designed to watermark non-LLM-generated text. For comparison, we adapt them to watermark any 1https://huggingface.co/sentence-transformers/all-mpnet-base-v2 5 Table 1: The performance of our watermark compared with baseline methods. The RemarkLLM method uses the T5 Raffel et al. (2020) model following their original settings. Other methods use TinyLlama-1.1B Zhang et al. (2024a) as the paraphraser. The bit-wise accuracy is marked as - if the method does not support multi-bit watermark code. Method Bit-wise Accuracy Text-wise Accuracy Fidelity Bit Acc Bit Num AUC TPR@FPR=1% TPR@FPR=0.01% Similarity RemarkLLM (4bit) RemarkLLM (8bit) KGW (zero-bit) KGW (multi-bit) KTH (zero-bit) KTH (multi-bit) Waterfall(κ = 0.5) Waterfall(κ = 1) Ours 0.7663 0.6953 - 0.6381 - 0.6129 - - 0.9563 4.0 8.0 - 4.46 - 4.26 - - 5.57 0.7861 0.8023 0.8652 0.8327 0.8919 0.6775 0.7787 0.9392 0. 0.0% 3.7% 25.9% 22.9% 61.4% 10.9% 14.0% 62.4% 98.0% 0.0% 0.0% 18.1% 6.3% 46.6% 2.3% 3.8% 35.5% 78.0% 0.8096 0.7793 0.7745 0.8123 0.8200 0.8176 0.8499 0.8423 0. text with two variant, zero-bit and multi-bit. In the zero-bit variant, we directly apply KGW or KTH to LLM-based (1.1B) paraphraser, which is then used to paraphrase the given text to inject watermarks. This is zero-bit watermark as the detector can only tell whether text is watermarked or not, but no other information will be carried in the watermark. In the multi-bit variant, we will apply KGW or KTH to two LLM-based paraphrasers. Then we use them as θ0 and θ1 in our approach and paraphrase one text based on watermark code. This allows the multi-bit information to be carried in the watermark. Waterfall (Lau et al., 2024). They prompt pretrained Llama model as the paraphraser and will change the sampling stage in order to inject the watermark signal. Their extracted watermark code is permutation, which does not support bit-wise comparison. We evaluate the watermark strength at κ = 0.5 and κ = 1. Note that in their original paper, they use strong watermark up to κ = 8. However, in our evaluation, we observe that even κ = 2 will affect the paraphrasing performance significantly for the 1.1B small model. Therefore, we use relatively small κ in the evaluation. Note that we did not compare with some well-known text watermark as they are already covered in previous works. We did not compare with AWT (Abdelnabi & Fritz, 2021) as RemarkLLM shows better performance in their paper. We did not compare with Robust Multi-bit (Yoo et al., 2023) and NLW (Qiang et al., 2023) as Waterfall shows better performance in their paper. There are also many works (e.g. (Christ et al., 2024; Zhao et al., 2023)) that focus on LLM watermarks, but we only choose the representative ones (KGW and KTH). 4.2 Performance We show the watermark performance in Table 1. We can observe that our method achieves better performance than existing methods on both bit-wise accuracy and text-wise accuracy. Our method also has high information density, with approximately one bit per 23 tokens (128/5.57). In addition, we also observe higher similarity score compared to baseline methods. This might be surprising at first glance. We owe it to the reason that we add similarity reward during the PPO process, so that the model is fine-tuned to achieve good paraphrasing performance. Multiple run In paraphrasing-based watermark, we can run the paraphraser multiple times and return the result with best watermark detection rate. This method is adopted in previous methods (Zhang et al., 2024b; Lau et al., 2024). In this section, we evaluate how different methods improve with multiple runs of the paraphraser. The results are shown in Figure 2. We can observe that our methods can scale to over 0.99 bit accuracy and 0.9999 detection AUC with five repeats of the paraphraser. Since we use 1.1B small model which can be run in parallel efficiently, we view it as good tradeoff to repeat five times and achieve better watermark performance. Other methods also get performance boost with more repeats, but there is still clear performance gap. Example and Analysis on Stealthiness We show several examples of the watermarked text and their original version in Table 5 in Appendix B. The sentences of class 0 and class 1 are marked with blue and green respectively. All the sentences are correctly classified by the decoder. From our observation, it is difficult to tell significant difference between the two classes of sentences, confirming the stealthiness of our watermark. To further validate the stealthiness of our watermark, we prompt GPT with in-context learning to see if it can tell the difference between the two classes of sentences. Specifically, we provide GPT with ten class-0 and ten class-1 sentences, and ask it to classify which class new sentence belongs to. The detailed prompt is shown in Figure 4 in Appendix A. We evaluate 1,000 class-0 and 1,000 class-1 sentences, and the accuracy is 57.0%, which is close 6 Figure 2: The detection performance of our watermark compared with baseline methods with multiple repeats of the paraphraser. Note that some methods do not support multi-bit watermark code, so they do not have curve of bit accuracy in the left figure. Table 2: The performance of our watermark compared with baseline methods under word substitution attack. Method Substitute ratio 5% Substitute ratio 10% Substitute ratio 20% bitacc AUC TPR@1% bitacc AUC TPR@1% bitacc AUC TPR@1% RemarkLLM (4bit) RemarkLLM (8bit) KGW (zero-bit) KGW (multi-bit) KTH (zero-bit) KTH (multi-bit) Waterfall(κ = 0.5) Waterfall(κ = 1) Ours Ours(advt) 0.6118 0.5685 - 0.6208 - 0.6018 - - 0.9382 0.9459 0.6215 0.6281 0.8458 0.8052 0.8718 0.6574 0.7578 0.9250 0.9945 0.9958 0.0% 0.6% 21.4% 20.9% 56.5% 9.0% 12.5% 54.1% 0.6315 0.5783 - 0.6134 - 0.5955 - - 93.5% 0.9193 94.1% 0.9352 0.6441 0.6445 0.8353 0.7914 0.8541 0.6504 0.7344 0.9096 0.9871 0.9936 0.0% 1.0% 16.5% 18.9% 51.8% 8.0% 9.1% 28.9% 0.6488 0.5921 - 0.5840 - 0.5610 - - 86.4% 0.8605 91.6% 0. 0.6624 0.6665 0.7779 0.7471 0.8128 0.6120 0.6893 0.8558 0.9469 0.9853 0.0 0.8% 7.0% 12.8% 41.5% 5.1% 5.3% 25.6% 51.6% 78.7% to the performance of random guess (50.0%). Thus, we conclude that our watermark is stealthy and it is difficult to tell difference of the two classes of sentences. 4.3 Robustness In this section, we study the robustness of our watermark. The evaluation pipeline follows the standard protocal - we first generate watermarked text, then modify the text with text-level perturbations, and finally test whether we can still detect the watermark in the text. We will evaluate word substitution and sentence paraphrasing, which are two most popular perturbations on texts. In addition to our benign-trained model, we also evaluate the adversarially trained model (denoted as Ours-AdvT), which has the knowledge of perturbation during training and will use the perturbed text when training the decoder. Word Substitution For paraphrasing attack, we will randomly substitute {5%, 10%, 20%} tokens in the text with another randomly chosen token (uniformly sampled from the vocabulary). We show the results in Table 2. The adversarial training model uses 10% of word substitution during the training process. We can observe that our original model can already outperform all the baselines when perturbed with word substitutions. With the knowledge of perturbation during the training process, we can further improve the performance and achieve over 0.99 detection AUC even when 10% of the tokens are randomly substituted. Sentence Paraphrasing For sentence paraphrasing, we consider three types. Following Lau et al. (2024), we will translate the sentence to Spanish and then back to English with Llama2-7B model, denoted as Translate. We will also directly prompt Llama2-7B model to paraphrase the sentence, denoted as LlamaPara. The detailed prompts used to do the translation and paraphrasing are shown in Figure 5 and 6 in Appendix A. In addition, following (Xu et al., 2024), we also paraphrase the sentence with the Pegasus (Zhang et al., 2020) paraphraser, denoted as PegasusPara. 7 Table 3: The performance of our watermark compared with baseline methods under sentence paraphrasing attack. Method Translate LlamaPara PegasusPara bitacc AUC TPR@1% bitacc AUC TPR@1% bitacc AUC TPR@1% RemarkLLM (4bit) RemarkLLM (8bit) KGW (zero-bit) KGW (multi-bit) KTH (zero-bit) KTH (multi-bit) Waterfall(κ = 0.5) Waterfall(κ = 1) Ours Ours(advt) 0.6885 0.6124 - 0.4997 - 0.4923 - - 0.8206 0.9003 0.7142 0.6904 0.4872 0.5829 0.8600 0.4990 0.6041 0.7432 0.9310 0.9709 0.0% 1.4% 0.2% 1.6% 30.6% 0.8% 4.0% 11.8% 0.7063 0.6023 - 0.4765 - 0.4952 - - 0.7137 67.4% 78.1% 0.8487 0.7311 0.6751 0.4872 0.5383 0.8559 0.4957 0.5833 0.6519 0.8649 0.9239 0.0% 1.5% 0.2% 1.5% 32.0% 1.7% 1.9% 3.1% 0.7033 0.6018 - 0.4817 - 0.4949 - - 43.9% 0.7388 0.8648 36.8% 0.7248 0.6687 0.4900 0.5654 0.8618 0.5025 0.5981 0.7283 0.8616 0.9546 0.0% 1.2% 0.0% 1.5% 43.7% 1.3% 5.0% 13.2% 53.7% 45.7% Table 4: The performance of our watermark, which is trained on the C4 dataset, evaluated on texts collected in other tasks. Dataset HH PKU Reward UltraF FineWeb Pile Bit-wise Accuracy Text-wise Accuracy Fidelity Bit Acc Bit Num AUC TPR@FPR=1% TPR@FPR=0.01% Similarity 0.9582 0.9613 0.9572 0.9519 0.9461 0.9140 5.856 5.325 5.684 6.234 6.066 6.026 0.9991 0.9959 0.9962 0.9931 0.9880 0.9713 97.9% 96.7% 96.7% 94.5% 93.3% 83.8% 92.1% 1.8% 51.4% 55.7% 19.3% 36.1% 0.8823 0.8923 0.8711 0.8830 0.8463 0.8430 The results are shown in Table 3. We observe that all these text watermarking methods suffer from significant performance drop under paraphrasing attacks. We owe it to the reason that the text watermarks aim to preserve the text meaning and inject watermarks with other signals (e.g. wording choices or stylish changes), while these signals will be easily broken by another paraphrasing process. As an extreme example, one may paraphrase the watermarked text into its original un-watermarked version (because the watermarking process requires that both texts should have the same semantic meaning), and it is impossible to detect the watermark from the text after the original text). Nevertheless, it is still possible to preserve part of the watermark signal perturbation (i.e. under mild paraphrasing, such as translation. We can observe that our method can outperform baselines on all the paraphrasing tasks, and can be further improved with adversarial training. 4.4 OOD As our pipeline relies on data-driven training process, we would like to evaluate how it performs on potential out-of-distribution data. In this section, we will evaluate our model, previously trained on the C4 dataset, on various other datasets, including Anthropic HH-RLHF (HH) (Bai et al., 2022), Synthetic instruction2(Instruct), PKU SafeRLHF (PKU) (Ji et al., 2024), Reward3, UltraFeedback(UltraF) (Cui et al., 2024), FineWeb (Penedo et al., 2024) and Pile uncopyrighted(Pile)4 datasets. Among the datasets, HH, Instruct, PKU, Reward and UltraF are QA datasets for alignment and we use their answers as the original texts. FineWeb is dataset consisting of articles from the Internet. Pile is dataset consisting of cleaned texts from different sources. The performance of our model is shown in Table 4. We can observe that our model can generally achieve good performance on different datasets, indicating its good generalization capability. We do observe relatively weak performance on the Pile task, which we view as result of the frequent structural texts (e.g. XML languages) in the dataset. Nevertheless, we emphasize that we can always include new data domain in the training process, so that they become in-domain and can achieve higher performance."
        },
        {
            "title": "5 Related Works",
            "content": "Text Watermarks People have been studying text watermarks for long time in order to protect copyrights (Liu et al., 2024). Early works on text watermarks focus on synonym substitution or other direct changes in the text. (Topkara et al., 2006) proposes to add watermarks to text by replacing the most ambiguous words with synonyms 2https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise 3https://huggingface.co/datasets/yitingxie/rlhf-reward-datasets 4https://huggingface.co/datasets/monology/pile-uncopyrighted 8 in text. (Xiang et al., 2018) investigated the frequency of synonym words so that more bits can be injected with the frequency information. (Munyer et al., 2024) considers the Word2Vec embedding (Mikolov, 2013) in the synonym substitution so that more information can be injected. (Yoo et al., 2023) extracts invariant features from the text to substitute synonyms so that the watermark can be more robust under different perturbations. More recently, people have studied how to directly inject watermark by paraphrasing the text. (Abdelnabi & Fritz, 2021) proposes LSTM-based pipeline to paraphrase text and inject fixed number of watermark bits. (Zhang et al., 2024b) improves the work by using Transformer-based pipeline and proposing to use Gumbel softmax for token selection conditioned on the watermark code. (Lau et al., 2024) proposes to use an LLM-based paraphraser and inject watermarks in the permutations of n-gram information in the text. LLM Output Watermarks Besides text watermarking, there is also line of research which studies the injection of watermarks into LLMs, so that the output texts of LLM can be later detected. (Kirchenbauer et al., 2023) first proposes to watermark an LLM. They will increase the logits of certain random tokens, which are generated based on n-gram information. They then perform statistical test on the text to determine whether the token appearance frequency is from the watermarked LLM. Follow-up works (Hou et al., 2023; Liu et al., 2023) will generate the random tokens based on semantic meaning rather than n-gram information, which makes the watermark robust against paraphrasing attacks. (Kuditipudi et al., 2023) adds perturbation during the sampling phase after the logits are generated, so that there is no distributional change on the output text. (Gu et al., 2023) proposes to distill watermarked model into new LLM model with changed parameters, so that no special mechanism is required during inference. (Xu et al., 2024) proposes co-training framework on the watermarked LLM and watermark detector so that the detector is trained to detect the watermarked text and the LLM is finetuned to get easily detected. Unlike text watermarking, this line of work focuses purely on LLM-generated text. In addition, all the methods are doing zero-bit watermark, i.e. the watermark will be detected but will not carry additional information."
        },
        {
            "title": "6 Discussion",
            "content": "Watermark Bit Rate Unlike some existing methods like remarkLLM (Zhang et al., 2024b), we cannot manually set the number of watermark bits injected to the text. Instead, the watermark length will be dependent on the text length, i.e. the longer the text is, the more information we will be able to inject. However, we view it possible to adjust the bit rate of our watermark with different approaches. First, we may add length penalty term in the SFT or PPO process, so that the parpahrasers tend to generate longer/shorter sentences. Second, instead of our current design with two paraphrasers and binary classification decoder, we can also use paraphrasers and K-way classification. By doing so, each bit becomes K-ary and thus carries more information. Choice of Text Segmentor Throughout the work, we use sentence-level segmentor to divide text into differment segments. This is simple yet effective choice, as it is generally robust under word substitution or parapharsing. However, it may be exploited by some adversary to decrease our model performance by, for example, merging or splitting sentences in the text. Potential directions to improve the segmentor include segmenting the text with more dedicated rules or with ML-based models on the semantic level, which we leave as future work. Controlling the Style of Watermark As we use data-driven method to train the paraphrasers for watermarking, we cannot explicitly choose the style of the watermark. Nevertheless, we may implicitly control the style by choosing appropriate data during the initialization process. For example, if we hope that the paraphraser only does synonym substitution, we can perform the initialization step by doing SFT on synonym-based paraphrasing data. The learned pattern will be inherited in the final paraphrasers given the KL constraint in Eqn. 5."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we propose multi-bit text watermark by paraphrasing piece of text to inject watermark signals. We show that our pipeline achieves very high detection accuracy with good fidelity and stealthiness. In addition, our method is robust under different attacks. Our method sheds new light on the study of text watermarks."
        },
        {
            "title": "References",
            "content": "Sahar Abdelnabi and Mario Fritz. Adversarial watermarking transformer: Towards tracing text provenance with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP), pp. 121140. IEEE, 2021. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862, 2022. 9 Miranda Christ, Sam Gunn, and Or Zamir. Undetectable watermarks for language models. In The Thirty Seventh Annual Conference on Learning Theory, pp. 11251139. PMLR, 2024. Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong Xie, Ruobing In Forty-first Xie, Yankai Lin, et al. Ultrafeedback: Boosting language models with scaled ai feedback. International Conference on Machine Learning, 2024. Chenchen Gu, Xiang Lisa Li, Percy Liang, and Tatsunori Hashimoto. On the learnability of watermarks for language models. arXiv preprint arXiv:2312.04469, 2023. Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, and Yulia Tsvetkov. Semstamp: semantic watermark with paraphrastic robustness for text generation. arXiv preprint arXiv:2310.03991, 2023. Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, and Rosalind Picard. Way off-policy batch deep reinforcement learning of implicit human preferences in dialog. arXiv preprint arXiv:1907.00456, 2019. Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Boxun Li, and Yaodong Yang. Pku-saferlhf: Towards multi-level safety alignment for llms with human preference. arXiv preprint arXiv:2406.15513, 2024. John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. watermark for large language models. In International Conference on Machine Learning, pp. 1706117084. PMLR, 2023. Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, and Percy Liang. Robust distortion-free watermarks for language models. arXiv preprint arXiv:2307.15593, 2023. Gregory Kang Ruey Lau, Xinyuan Niu, Hieu Dao, Jiangwei Chen, Chuan-Sheng Foo, and Bryan Kian Hsiang Low. Waterfall: Framework for robust and scalable text watermarking. arXiv preprint arXiv:2407.04411, 2024. Aiwei Liu, Leyi Pan, Xuming Hu, Shiao Meng, and Lijie Wen. semantic invariant robust watermark for large language models. arXiv preprint arXiv:2310.06356, 2023. Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, and Philip Yu. survey of text watermarking in the era of large language models. ACM Computing Surveys, 2024. Tomas Mikolov. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013. Travis Munyer, Abdullah Tanvir, Arjon Das, and Xin Zhong. Deeptextmark: deep learning-driven text watermarking approach for identifying large language model generated text. IEEE Access, 2024. Guilherme Penedo, Hynek Kydlıˇcek, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, and Thomas Wolf. The fineweb datasets: Decanting the web for the finest text data at scale, 2024. URL https://arxiv.org/abs/2406.17557. Jipeng Qiang, Shiyu Zhu, Yun Li, Yi Zhu, Yunhao Yuan, and Xindong Wu. Natural language watermarking via paraphraser-based lexical substitution. Artificial Intelligence, 317:103859, 2023. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. Exploring the limits of transfer learning with unified text-to-text transformer. Journal of machine learning research, 21(140):167, 2020. John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. Umut Topkara, Mercan Topkara, and Mikhail Atallah. The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions. In Proceedings of the 8th workshop on Multimedia and security, pp. 164174, 2006. Lingyun Xiang, Yan Li, Wei Hao, Peng Yang, and Xiaobo Shen. Reversible natural language watermarking using synonym substitution and arithmetic coding. Computers, Materials & Continua, 55(3), 2018. Xiaojun Xu, Yuanshun Yao, and Yang Liu. Learning to watermark llm-generated text via reinforcement learning. arXiv preprint arXiv:2403.10553, 2024. 10 KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, and Nojun Kwak. Robust multi-bit natural language watermarking through invariant features. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 20922115, 2023. Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International conference on machine learning, pp. 1132811339. PMLR, 2020. Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. Tinyllama: An open-source small language model, 2024a. Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara, and Farinaz Koushanfar. {REMARK-LLM}: robust and efficient watermarking framework for generative large language models. In 33rd USENIX Security Symposium (USENIX Security 24), pp. 18131830, 2024b. Xuandong Zhao, Prabhanjan Ananth, Lei Li, and Yu-Xiang Wang. Provable robust watermarking for ai-generated text. arXiv preprint arXiv:2306.17439, 2023. Rui Zheng, Shihan Dou, Songyang Gao, Yuan Hua, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin Liu, Yuhao Zhou, et al. Secrets of rlhf in large language models part i: Ppo. arXiv preprint arXiv:2307.04964, 2023."
        },
        {
            "title": "A Prompts Used in the Experiments",
            "content": "We show the detailed prompts used in the experiments as below: Figure 3: prompt used in the encoder. Figure 4: prompt used to do in-context classification with GPT. Figure 5: prompt used to translate text with Llama-2-7B. Figure 6: prompt used to paraphrase text with Llama-2-7B. We did not make special efforts to optimize these prompts. Human: Paraphrase the text below. {Original Text} Assistant: Paraphrased Text: Figure 3: The prompt used to paraphrase the text in the encoder. have two classes of text, C1 and C2, which have some intrinsic difference. will provide you with lists of texts from bothclasses. Can you help me classify which class new text is in? You answer should only contain one word, [C1] or [C2]. C1 texts: {Class-0 sentences} C2 texts: {Class-1 sentences} New text: {The new sentence to classify} Please answer C1 or C2. Figure 4: The prompt used to performance in-context classification of our watermarked text with GPT. [[INST]] <<SYS>> Translate the provided piece of text to {language}. Do not include any other sentences after the response, such as explanations of the translation. <</SYS>> {text} [/INST] Here is translated version of the text: Figure 5: The prompt used to evaluate the watermark robustness under translation."
        },
        {
            "title": "B Examples of Watermarked Texts",
            "content": "We show the watermarked texts generated by our pipeline in Table 5. Blue and green texts correspond to class-0 and class-1 texts respectively. We view it difficult to tell difference between the two classes of texts from human eyes. Experiments on Llama-2-7B Models We show the results of using Llama-2-7B model as the paraphraser in Table 6. Note that the RemarkLLM method does not support Llama models, so we do not evaluate the method; the Waterfall method on 7B models can support larger κ, so we included results of κ = 1, 2, 4 in the table. We can observe that our model keeps high performance with the 7B models. We do not see an improvement compared with the 1.1B models, which we guess is because that fine-tuned 1.1B models already have the capability to paraphrase texts, so that larger model may not help. On the other hand, baseline methods can have better fidelity with the larger model. The Waterfall methods are able to use larger κ to inject strong watermarks, and the strongest κ = 4 case can achieve comparable performance with our model, though there would be drop on the fidelity. 12 Table 5: Examples of watermarked texts. Blue and green texts correspond to class-0 and class-1 texts respectively."
        },
        {
            "title": "Watermarked Text",
            "content": "When it comes to fantasy sports and betting on NASCAR races, theres nothing wrong with it, Gaughan said. wanted to go all in on gambling last year, NASCAR executive Steve ODonnell said. We have so many people that are linked to the cars. think the integrity is big piece to it, ODonnell said. Nevadas effective monopoly on sports betting ended last spring, when the Supreme Court ruled the ban should be Theres nothing wrong with fantasy sports and betting on NASCAR races, Gaughan said. Steve said wanted to go all in on gambling last year. We have so many people that are linked to the cars, ODonnell said. The integrity of the car is big piece to it because they are linked to it. Nevadas effective monopoly on sports betting ended last spring, as the Supreme Court ruled that the ban should be"
        },
        {
            "title": "Similarity",
            "content": "0.9177 President Trumps decision Monday to revive plans to freeze federal employee pay in 2020 and to institute series of cuts to federal employee retirement programs was met with great consternation from stakeholder groups, although the ideas stand little chance of becoming law. Increasing employee contributions toward federal defined benefit annuity programs by 1 percent per year until those payments reach 50 percent of the total cost. Eliminating cost of living adjustments for FERS retirees, and reducing CSRS cost of living adjustments by 0.5 percent. Bob Bus Bob Krause, 59, of Waikiki, an Oahu Transit System bus driver, died at home. He was born in Bremen, Germany. He is survived by parents Hans Krause and Sonja Aiwohi, brother Ralph and sisters Lorraine Kinnamon and Charmaine Moniz. Celebration of life: 2 p.m. Friday at Outrigger Canoe Club Waikiki. Additional celebration of life: 4:30 p.m. on weekend of May 4 and 5 at Occasional diarrhea is common occurrence. Most people will experience an episode of diarrhea at least once or twice year that will disappear in couple of days. Luckily, there are many foods to eat that may help person reduce the symptoms of diarrhea. There are also some foods to avoid when dealing with bout of diarrhea, and some additional home care tips to consider. Anyone who is experiencing persistent diarrhea should see doctor, as person may become dehydrated over time. President Trumps decision Monday to resume plans to freeze federal employee pay and to cut retirement benefits for federal employees generated consternation from stakeholder groups, despite having little hope of becoming law. The employee contributions to the annuity programs are up by 1 percent year until they reach five percent of the total cost. There are cost of living adjustments for FERS retirees and cost adjustments for COLA, which are reduced by 0.5 percent. Bob Bus Bob Krause, the head driver of the Oahu Transit System, died at home. His parents lived in Germany when he was born. He has surviving relatives, including his mother, sister, and brother. The celebration of life is on Friday at the outrigger canoe club. There is celebration of life on Friday, May 4 and 5 at Occasional diarrhea is common occurrence. People will get sick more often than they used to do. There are many foods to eat that may help person reduce the symptoms of diarrhea. lot of people avoid foods when they are dealing with bout of diarrhea and few home care ideas to consider are worth checking out. Anyone who is suffering from persistent diarrhea should see doctor, as person may become dehydrated over time. 0.8947 0.8743 0.8392 Table 6: The performance of our watermark compared with baseline methods with the Llama-2-7B model."
        },
        {
            "title": "Method",
            "content": "Bit-wise Accuracy Text-wise Accuracy"
        },
        {
            "title": "AUC",
            "content": "TPR@FPR=1% TPR@FPR=0.01% Similarity KGW (zero-bit) KGW (multi-bit) KTH (zero-bit) KTH (multi-bit) Waterfall(κ = 1) Waterfall(κ = 2) Waterfall(κ = 4)"
        },
        {
            "title": "Ours",
            "content": "- 0.6302 - 0.5756 - - - 0.9605 - 5.17 - 5.075 - - - 5.874 0.8625 0.8498 0.8735 0.7296 0.7568 0.9213 0.9951 0. 24.4% 15.2% 26.5% 13.3% 13.3% 49.3% 96.3% 97.6% 13.7% 8.3% 12.5% 2.0% 3.7% 26.9% 89.8% 77.6% 0.8842 0.8986 0.9075 0.9073 0.8809 0.8743 0.8350 0. 13 [[INST]] <<SYS>> Paraphrase the user provided text while preserving semantic similarity. Do not include any other sentences in the response, such as explanations of the paraphrasing. Do not summarize. <</SYS>> {text} [/INST] Here is paraphrased version of the text: Figure 6: The prompt used to evaluate the watermark robustness under Llama paraphrasing."
        }
    ],
    "affiliations": [
        "ByteDance Research",
        "Michigan State University",
        "University of California, Santa Cruz"
    ]
}