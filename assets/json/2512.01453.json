{
    "paper_title": "Reinventing Clinical Dialogue: Agentic Paradigms for LLM Enabled Healthcare Communication",
    "authors": [
        "Xiaoquan Zhi",
        "Hongke Zhao",
        "Likang Wu",
        "Chuang Zhao",
        "Hengshu Zhu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Clinical dialogue represents a complex duality requiring both the empathetic fluency of natural conversation and the rigorous precision of evidence-based medicine. While Large Language Models possess unprecedented linguistic capabilities, their architectural reliance on reactive and stateless processing often favors probabilistic plausibility over factual veracity. This structural limitation has catalyzed a paradigm shift in medical AI from generative text prediction to agentic autonomy, where the model functions as a central reasoning engine capable of deliberate planning and persistent memory. Moving beyond existing reviews that primarily catalog downstream applications, this survey provides a first-principles analysis of the cognitive architecture underpinning this shift. We introduce a novel taxonomy structured along the orthogonal axes of knowledge source and agency objective to delineate the provenance of clinical knowledge against the system's operational scope. This framework facilitates a systematic analysis of the intrinsic trade-offs between creativity and reliability by categorizing methods into four archetypes: \\textit{Latent Space Clinicians}, \\textit{Emergent Planners}, \\textit{Grounded Synthesizers}, and \\textit{Verifiable Workflow Automators}. For each paradigm, we deconstruct the technical realization across the entire cognitive pipeline, encompassing strategic planning, memory management, action execution, collaboration, and evolution to reveal how distinct architectural choices balance the tension between autonomy and safety."
        },
        {
            "title": "Start",
            "content": "Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication XIAOQUAN ZHI, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, China HONGKE ZHAO, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, China LIKANG WU, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, China CHUANG ZHAO, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, China HENGSHU ZHU, Computer Network Information Center, Chinese Academy of Sciences, China Clinical dialogue represents complex duality requiring both the empathetic fluency of natural conversation and the rigorous precision of evidence-based medicine. While Large Language Models possess unprecedented linguistic capabilities, their architectural reliance on reactive and stateless processing often favors probabilistic plausibility over factual veracity. This structural limitation has catalyzed paradigm shift in medical AI from generative text prediction to agentic autonomy, where the model functions as central reasoning engine capable of deliberate planning and persistent memory. Moving beyond existing reviews that primarily catalog downstream applications, this survey provides first-principles analysis of the cognitive architecture underpinning this shift. We introduce novel taxonomy structured along the orthogonal axes of knowledge source and agency objective to delineate the provenance of clinical knowledge against the systems operational scope. This framework facilitates systematic analysis of the intrinsic trade-offs between creativity and reliability by categorizing methods into four archetypes: Latent Space Clinicians, Emergent Planners, Grounded Synthesizers, and Verifiable Workflow Automators. For each paradigm, we deconstruct the technical realization across the entire cognitive pipeline, encompassing strategic planning, memory management, action execution, collaboration, and evolution to reveal how distinct architectural choices balance the tension between autonomy and safety. Furthermore, we bridge abstract design philosophies with the pragmatic implementation ecosystem. By mapping real-world applications to our taxonomy and systematically reviewing benchmarks and evaluation metrics specific to clinical agents, we provide comprehensive reference for future development. Finally, we identify critical frontiers regarding trustworthiness, outlining roadmap for future research to foster reliable and ethically aligned healthcare AI. The latest papers and related resources are maintained on our website. Hongke Zhao is the corresponding author. Authors Contact Information: Xiaoquan Zhi, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, Tianjin, China, zhixiaoquan@tju.edu.cn; Hongke Zhao, hongke@tju.edu.cn, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, Tianjin, China; Likang Wu, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, Tianjin, China, wulikang@tju.edu.cn; Chuang Zhao, College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, Tianjin, China, zhaochuang@tju.edu.cn; Hengshu Zhu, Computer Network Information Center, Chinese Academy of Sciences, Beijing, China, zhuhengshu@gmail.com. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. Manuscript submitted to ACM Manuscript submitted to ACM 1 5 2 0 2 ] . - [ 1 3 5 4 1 0 . 2 1 5 2 : r 2 Zhi et al. CCS Concepts: Computing methodologies Artificial intelligence; Natural language processing. Additional Key Words and Phrases: Clinical dialogue, Large language models, Agents, Knowledge source ACM Reference Format: Xiaoquan Zhi, Hongke Zhao, Likang Wu, Chuang Zhao, and Hengshu Zhu. 2018. Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication. Proc. ACM Meas. Anal. Comput. Syst. 37, 4, Article 111 (August 2018), 58 pages. https: //doi.org/XXXXXXX.XXXXXXX 1 Introduction Clinical dialogue represents far more than mere exchange of information, as it constitutes goal-oriented, sequential decision-making process that is the cornerstone of healthcare delivery. It encompasses wide spectrum of high-stakes interactions, ranging from patient education and diagnostic information gathering to intricate treatment deliberation [56, 169] and behavior change counseling [220]. The effectiveness of this dialogue acts as primary determinant of clinical outcomes, directly influencing diagnostic accuracy, patient adherence to treatment regimens, and the long-term therapeutic alliance between provider and patient. However, the global scarcity of medical professionals often creates bottleneck, limiting the time and attention available for high-quality interactions. Consequently, the automation of clinical dialogue has become an imperative research frontier, aiming to scale personalized care without compromising quality. Historically, the automation of clinical dialogue has progressed through distinct paradigms, each grappling with the trade-off between control and flexibility. The earliest attempts were dominated by pipeline-based dialogue systems [153], which employed modular architecture comprising natural language understanding, dialogue state tracking [163], and policy execution [196]. While effective for structured, slot-filling tasks like appointment scheduling, these systems were inherently rigid, suffering from cascading errors where failure in one module propagated downstream. Subsequently, retrieval-based paradigm emerged [168]. These systems operate by matching user queries to predefined responses from curated knowledge base, offering high scalability and factual safety. However, they lack the generative flexibility to address the nuanced, long-tail queries typical of authentic patient interactions, often resulting in impersonal and disjointed communication that fails to address specific patient needs [291]. The advent of Large Language Models (LLMs) marked significant departure from these rigid approaches, introducing probabilistic generative paradigm. By leveraging linguistic patterns and world knowledge learned from massive corpora during self-supervised pre-training [71], these models function as powerful sequence-to-sequence generators[71]. Specialized models such as BioGPT [158] and Med-PaLM [216] demonstrate unprecedented fluency in understanding complex medical semantics. Their capabilities have been rigorously validated not only on high-stakes benchmarks like the USMLE [83] and MedMCQA [176], but also across wide array of pragmatic clinical tasks, ranging from clinical text summarization [94] and medical note generation [4] to patient-friendly text simplification [86]. This success across diverse scenarios [99, 239] underscores the potential to democratize access to medical knowledge, offering versatile, general-purpose interface for healthcare applications. Despite their linguistic prowess, the paradigm reveals significant design flaws when applied to the rigorous demands of complex clinical environments. Primarily, operating as probabilistic engines, these models often prioritize fluency over factual accuracy without an intrinsic mechanism to verify outputs against real-time clinical evidence, leading to plausible but clinically dangerous hallucinations [284]. Furthermore, their inherently reactive and stateless nature forces them to treat each patient encounter as discrete episode, preventing the construction of longitudinal and Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 3 coherent model of patients evolving condition, which is prerequisite for chronic disease management [32, 160]. Compounding these internal limitations is their operational isolation. Functioning as systems disconnected from the dynamic clinical environment, standard LLMs lack the agency to actively query external tools or interact with essential data repositories like Electronic Health Records (EHRs) and clinical guidelines, rendering them insufficient for orchestrating the multi-step, mixed-initiative workflows that define modern clinical practice [253]. 1.1 Difference between Agentic Paradigm with Traditional Methods To transcend these inherent limitations, the field is rapidly converging on an Agentic Paradigm, which fundamentally reconceptualizes the LLM from passive text generator into the central reasoning engine of an autonomous, goaldirected system [30, 135]. Unlike traditional models that merely predict the next token based on immediate context, clinical agent actively perceives its environment, engages in deliberate reasoning, and executes sequential trajectory of actions to achieve specific clinical objectives. This paradigm is operationalized through set of disentangled yet synergistic technical components, each rigorously designed to address specific cognitive deficit of the foundational model. To resolve the challenge of complex clinical reasoning, strategic planning modules enable the agent to break down high-level, ambiguous objectives (e.g., diagnosing rare disease) into structured sequence of executable sub-goals [24, 83]. To overcome the stateless nature of standard interactions, sophisticated memory management systems are employed to maintain persistent, longitudinal context of the patients history and the evolving dialogue state, ensuring continuity of care across sessions [203, 229]. Bridging the critical gap between the models internal knowledge and the real-world clinical environment, action execution mechanisms empower the agent to invoke verifiable external tools [240] and query authoritative knowledge sources [77], thereby grounding its decisions in reality rather than in hallucination. Furthermore, recognizing that effective healthcare is rarely solitary endeavor, collaboration layers orchestrate dynamic interactions among multiple specialized agents [207], simulating the multi-disciplinary team (MDT) approach found in real-world medical practice. Finally, distinguishing themselves from static pre-trained models, these systems incorporate evolutionary mechanisms for self-reflection and learning from environmental feedback [21], allowing the agent to continuously refine its clinical strategies over time. To construct comprehensive overview of this emerging field, we have conducted thorough review of over 300 papers investigating the theory and application of LLM-based agents in healthcare and related scientific domains. Our search was carried out using reputable academic databases such as PubMed, Google Scholar, ACM Digital Library, and DBLP, utilizing specific keywords, including \"medical agent\", \"clinical agent\", \"llm for medicine\", \"agentic paradigm\", in conjunction with \"healthcare\", \"clinical dialog\", and \"question answering\". The surveyed papers were meticulously sourced from esteemed computer science and medical informatics conferences and journals such as ACL, NeurIPS, ICLR, ICML, KDD, WWW, Nature Medicine, Nature Machine Intelligence, and NPJ Digital Medicine, as depicted in Fig. 1. To ensure the inclusion of state-of-the-art research, we also explored citation networks and incorporated relevant, high-impact preprints from arXiv. 1.2 Existing Surveys and Our Contribution While the rapid proliferation of LLMs in medicine has prompted several reviews, our work, as demonstrated in Table 1, addresses distinct void by shifting the focus from downstream applications to the intrinsic architectural philosophy of agentic systems. critical analysis of the existing literature reveals three major gaps that this survey uniquely aims to bridge. First, surveys on LLMs in healthcare predominantly offer task-centric taxonomy, categorizing papers by functions such as summarization, triage, or coding [144, 243]. While valuable for understanding utility, these works Manuscript submitted to ACM 4 Zhi et al. Fig. 1. Statistical overview of the literature surveyed. The bar chart (left) illustrates the temporal distribution of cited works, highlighting the surge in recent research (\"<19\" denotes 2019 and prior). The pie chart (right) depicts the distribution of articles across top-tier venues. Venue abbreviations follow the standard of ACM. Table 1. Comparison between existing surveys and our survey. denotes the presence of an attribute. Ref. 2019[104] 2022[235] 2024[243] 2024[86] 2024[162] 2024[209] 2024[144] 2024[314] 2025[53] 2025[253] 2025[134] Our Survey Paradigm of Clinical Dialogue In-depth Review of Agentic Clinical Dialgue LLM-Based Agentic Technical Component Planning Action Memory Collaboration Evolution Agentic Knowledge Agency (cid:34) (cid:34) (cid:34) (cid:34) (cid:34) (cid:34) (cid:34) (cid:34) (cid:34) treat the LLM primarily as static information processor, failing to capture the fundamental paradigm shift required to transform these passive models into proactive, state-tracking agents capable of autonomous workflow execution. Second, general surveys on Agentic AI establish foundational concepts of planning and tool use but operate largely within open domains [86, 162]. Consequently, they overlook the stringent constraints of the medical fieldspecifically, the non-negotiable requirements for safety, interpretability, and verifiable knowledge groundingnecessitating re-examination of agent architectures through the lens of clinical rigor. Third, and most critically, while recent reviews of medical agents have begun to emerge [134, 253], they largely remain at phenomenological level, classifying systems based on their clinical application scenarios or merely listing technical modules. These reviews often lack unified framework to explain why an agent is designed with specific memory or planning mechanisms [104, 209, 235]. Distinct from these works, we move beyond surface-level categorization to provide first-principles analysis of clinical agents, as shown in Table 1. We argue that the differentiation of agents should be based on how they derive knowledge and how they exercise agency, as these dimensions dictate the intrinsic trade-offs between generative creativity and factual reliability, and between operational autonomy and clinical safety. By bridging abstract design philosophies with concrete technological implementations, we offer conceptual lens that explains the trade-offs inherent in building reliable digital doctors. In nutshell, this survey fills this critical gap by providing principled, in-depth analysis of the agentic paradigms shaping modern healthcare communication. Our primary contributions are threefold: novel taxonomy based on fundamental trade-offs. We introduce novel taxonomy for clinical dialogue agents, organized along two critical and conceptually orthogonal perspectives: Knowledge Source and Agency Objective. We argue that these axes are fundamental because they dictate the two most critical trade-offs in Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication medical AI, implying the balance between creativity and reliability, and the balance between safety and autonomy. This framework allows for systematic analysis of the field, revealing four distinct paradigms. Comprehensive and in-depth component analysis. Moving beyond mere categorization, we conduct granular analysis of the core technical components within each of the four paradigms. We dissect how different paradigms operationalize these components differently to meet their specific objectives, highlighting distinct engineering challenges and delineating potential application scenarios to provide clear roadmap for developers. Systematic review of resources and future directions. We provide systematic review of the implementation tools, benchmark datasets, and evaluation metrics that are critical for developing and assessing clinical agents. Furthermore, we synthesize open challenges, such as neuro-symbolic integration and holistic patient management, to guide future research toward more reliable and ethically aligned healthcare AI. 1.3 Survey Organizations The rest of this survey is organized as follows. Section 2 establishes the preliminaries and defines the key concepts of clinical dialogue and the agentic paradigm. Section 3 forms the core of our analysis, where we systematically dissect each of the four proposed agentic paradigms. Section 4 provides an overview of implementation tools, datasets, and evaluation metrics. Section 5 maps real-world applications to our taxonomy. Finally, Section 6 discusses open research challenges and future directions before we conclude the survey. 2 Preliminaries and Definition This section establishes the formal conceptual groundwork for our survey. We rigorously define clinical dialogue as stochastic decision process under uncertainty. Subsequently, we delineate the pivotal paradigm shift from the foundational LLM paradigm to the emerging agentic paradigm. To facilitate clear understanding, we summarize the primary mathematical notations in Table 2. Table 2. Important mathematical notations used in this survey. Notation Detailed Description 洧노,洧녢 洧멇롐 洧녶洧노 洧녩洧노 洧냩洧노 洧랦 풙 洧냨 洧랢 洧녠() 洧랚 洧녪洧노 洧녡洧노 P洧노 洧랞 洧녟洧랚 G洧녫洧녶洧녵洧녵 Current turn index and the total number of dialogue turns The unobservable, latent state space and specific state at turn 洧노, 洧멇롐 The observation space and observation at turn 洧노 including user utterance 洧녹洧노 , 洧녶洧노 The action space and action at turn 洧노 including system response 洧洧노 and tool use, 洧녩洧노 Observable dialogue history at turn 洧노, 洧냩洧노 = {(洧녶1, 洧녩1), (洧녶2, 洧녩2), . . . , (洧녶洧노 1, 洧녩洧노 1)} interaction trajectory 洧랦 = {(洧1, 洧녩1), (洧2, 洧녩2) . . . , (洧멇롐 , 洧녩洧녢 )} The latent pathology/medical reality of the patient (풙 洧멇롐 ) The overarching clinical goal, including diagnosis, triage, and education External knowledge space, including EHRs, guidelines, and tools The policy function mapping history or belief states to actions The reward function evaluating clinical utility and safety Trainable parameters of the foundation model The theoretical belief state distribution over at turn 洧노 The agents internal memory state approximating 洧멇롐 The generated plan or sequence of sub-goals at turn 洧노 The memory transition function updating the internal state 洧녡洧노 The action-value function estimating the expected cumulative reward Topology graph defining agent connections in multi-agent systems Manuscript submitted to ACM 2.1 What is Clinical Dialogue? Zhi et al. From formal perspective, clinical dialogue represents goal-oriented, sequential decision-making process. Unlike opendomain chitchat, which primarily relies on surface-level semantics, clinical dialogue is characterized by fundamental information asymmetry: substantial gap exists between the observable dialogue surface, including patient utterances and reports, and the underlying, often unobservable, medical reality. To model this complex interaction rigorously, we conceptualize it as Partially Observable Markov Decision Process (POMDP) defined by the tuple = S, A, O, , Z, 洧녠, 洧. Central to this framework is the latent state 洧멇롐 S, which encapsulates the ground-truth patient status. While in diagnostic scenarios this corresponds to the latent pathology 풙, in broader contexts, it encompasses variables such as urgency levels, patient information gaps, or psychological states. The system interacts with this environment by executing actions 洧녩洧노 (e.g., inquiries, education, or reassurance) and receiving observations 洧녶洧노 (e.g., user responses 洧녹洧노 ), which serve as noisy probabilistic projections of the hidden state. The temporal decision horizon is regulated by discount factor 洧 [0, 1], which mathematically balances the trade-off between immediate patient satisfaction and long-term health outcomes. The interaction follows biological and cognitive logic governed by two probability functions: the transition function (洧멇롐 +1 洧멇롐, 洧녩洧노 ), modeling how the patient state evolves such as symptom worsening or anxiety reduction, and the observation function Z(洧녶洧노 洧멇롐, 洧녩洧노 1), modeling how internal states manifest externally. Since the true medical reality 풙 洧멇롐 is hidden, the system relies on the observable history 洧냩洧노 = {(洧녶1, 洧녩1), . . . , (洧녶洧노 1, 洧녩洧노 1)} to infer the state. Effective clinical reasoning requires maintaining belief state 洧녪洧노 , probability distribution over derived from 洧냩洧노 . Mathematically, updating this belief upon new evidence follows Bayesian inference: 洧녪洧노 (洧 ) Z(洧녶洧노 洧 , 洧녩洧노 1) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) (cid:123)(cid:122) (cid:124) Observation Probability 洧 (洧 洧, 洧녩洧노 1) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) (cid:123)(cid:122) (cid:124) State Evolution 洧녪洧노 1 (洧), (1) where 洧 denotes the candidate state. Eq. 1 mathematically formalizes the clinical reasoning process: iteratively refining the systems understanding of the patients needs and condition based on new evidence. The ultimate objective is to learn policy 洧랢 that maximizes the expected cumulative clinical utility (Reward 洧녠()) over the interaction trajectory 洧랦: 洧랢 = arg max 洧랢 E洧랦洧랢 (cid:34) 洧녢 洧노 =1 (cid:35) 洧쮫롐 1洧녠(洧멇롐, 洧녩洧노 , 洧냨) . (2) This formulation highlights that clinical dialogue systems must solve the dual challenges of state estimation to reduce entropy regarding 풙 and strategic planning to optimize the long-term utility defined in Eq. 2, thereby achieving the clinical goal. 2.2 What is LLM and Agentic Paradigm? LLMs represent technological inflection point; however, their application in medicine necessitates rigorous distinction between generative capabilities and agentic reasoning. We delineate this evolution from the foundational paradigm to the agentic paradigm, as visualized in Fig. 2. The foundational LLM paradigm in clinical dialogue. Traditional approaches utilizing LLMs simplify the POMDP by effectively assuming that the observable dialogue history is sufficient proxy for the latent state (i.e., 洧멇롐 洧냩洧노 ). Under this assumption, the complex decision process collapses into conditional sequence generation task. In this paradigm, the system response 洧洧노 is sampled from conditional probability distribution parameterized by 洧랚 , implicitly encoding Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 7 Fig. 2. Comparison of three paradigms of clinical dialogue. The evolution progresses from modular pipeline-based systems (upper left) and reactive LLM-based generators (upper right) to he agentic paradigm (bottom). It represents shift, elevating the LLM from passive text predictor to an autonomous controller by integrating strategic planning, persistent memory, tool execution, and others. specific knowledge Kimplicit: 洧洧노 洧녞洧랚 (cid:0)洧洧노 洧녹洧노 , 洧냩洧노 , 洧냨; Kimplicit (cid:1) . (3) Consequently, the learning strategy transitions from maximizing the intractable cumulative reward (Eq. 2) to supervised fine-tuning based on expert demonstrations. The optimization objective shifts to the maximum likelihood estimation of gold-standard response sequence 洧냥 = {(洧녹1, 洧 洧녢 )}, where the model is trained to minimize the divergence from human expert behavior: 1 ), . . . , (洧녹洧녢 , 洧 洧랚 = arg max 洧랚 (洧녹洧노 ,洧 洧노 ) 洧냥 log 洧녞洧랚 (洧 洧노 洧녹洧노 , 洧냩洧노 , 洧냨; Kimplicit). (4) Despite its efficacy in fluency and short-term context understanding [117], this paradigm is inherently reactive. By bypassing the explicit modeling of the latent medical state 洧멇롐 , it often struggles with long-horizon reasoning and factual consistency when the parametric knowledge conflicts with patient-specific data. The agentic paradigm: shift towards autonomous systems. The Agentic Paradigm elevates the LLM from passive text generator to the cognitive controller of an autonomous system [24, 125]. Unlike the reactive foundational paradigm, the agent explicitly addresses the POMDP structure by maintaining comprehensive internal state 洧녡洧노 to approximate the unobservable medical reality 洧멇롐 . The agent optimizes dynamic policy 洧랢洧랚 (洧녩洧노 洧녡洧노 ) to maximize the expected return: (洧랢洧랚 ) = E洧랦洧랢洧랚 洧쮫롐떯롐(洧녡洧노 +洧녲, 洧녩洧노 +洧녲, 洧냨) . (5) (cid:34) (cid:35) 洧녲=0 This paradigm is operationalized through five orthogonal yet synergistic components, each playing distinct mathematical role in solving the clinical POMDP: Strategic planning. To tackle the complexity of clinical goals 洧냨, this module bridges the gap between high-level objectives and executable actions. It generates plan P洧노 (a sequence of sub-goals or reasoning steps) conditioned Manuscript submitted to ACM 8 on the current belief state: P洧노 = 맗lan (洧냨, 洧녡洧노 , K) = {洧녮1, 洧녮2, . . . , 洧녮洧녲 }. Zhi et al. (6) In the POMDP context, P洧노 serves as constraint on the policy space, guiding the agent to select actions that systematically reduce the entropy of the latent pathology 풙 rather than engaging in greedy token generation [101, 295]. Memory management. To overcome the stateless nature of raw LLMs, agents must maintain persistent internal state 洧녡洧노 . This is formalized as memory transition function 洧랞, which approximates the Bayesian belief update (Eq. 1) defined in Section 2: 洧녡洧노 = 洧랞 (洧녡洧노 1, 洧녶洧노 , 洧녩洧노 1, K). (7) Here, 洧녡洧노 accumulates evidence from observations 洧녶洧노 and tool outputs, constructing an evolving patient model that tracks variables like symptom duration and medication history over time [319]. Action execution. The agent interacts with the physical and digital worlds through an expanded action space = Atext Atool Aplan. The policy selects specific actions not randomly but by evaluating their expected utility. We formalize this via an action-value function 洧녟洧랚 , which estimates the cumulative reward (Eq. 5) conditioned on the current plan: 洧녩洧노 = arg max 洧녩 洧녟洧랚 (洧녡洧노 , 洧녩, P洧노 ). (8) By invoking search engines or clinical tools (洧녩 Atool) [96], the agent actively gathers new information to bridge the gap between its belief 洧녡洧노 and the true medical reality 洧멇롐 , grounding its reasoning in verifiable evidence. Collaboration. In complex scenarios, the clinical outcome is an emergent property of the interaction between 洧녜 distinct agents. We formalize this interaction as consensus protocol 풛 defined over topology graph G洧녫洧녶洧녵洧녵. The systems final action is sampled from joint distribution derived by aggregating individual policies: (cid:16)(cid:8)洧랢洧녰 ( 洧녡 (洧녰 ) )(cid:9)洧녜 (cid:17) , 洧녩洧노 풛consensus (9) 洧노 洧녰=1; G洧녫洧녶洧녵洧녵 where 풛 represents the mechanism (e.g., weighted voting, iterative debate, or meta-policy) that minimizes the divergence between conflicting agents, mimicking medical board where diverse expert perspectives are synthesized to ensure decision robustness [265]. Agent evolution. Distinct from static deployment, agentic systems possess the capacity for self-improvement. Evolution is modeled as parameter update mechanism based on historical trajectories 洧랦history and feedback rewards 洧녠: 洧랚洧녲+1 洧랚洧녲 + 洧띺洧랚 E洧랦 [洧녠(洧랦)]. (10) This allows the agent to internalize successful diagnostic patterns from past experiences [93], progressively refining its policy 洧랢洧랚 to better approximate the optimal solution without extensive human retraining. These components collectively transform the LLM from static knowledge repository into dynamic problem-solving entity. They form the conceptual basis for the taxonomy of agentic paradigms for clinical dialogue, which will be systematically analyzed in the subsequent chapters. 2.3 Why Agents for Healthcare Communication? Unlike open-domain conversation, clinical encounter is structured to achieve specific outcome, such as diagnosis or treatment plan. This requires proactive state management, task decomposition, and the ability to steer the Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 9 conversation[118, 231]. The agentic paradigm, through strategic planning, explicitly models this workflow, transforming the LLM into purposeful conversational director rather than passive respondent [231]. Secondly, safe clinical dialogue must be radically contextual and grounded in an external, dynamic information ecosystem. The veracity of medical statement is contingent upon real-time patient data from EHRs and the latest evidence from clinical guidelines [259]. Relying solely on the models internal parameters creates an unacceptable risk of factual hallucination and clinically unsafe outputs [332]. An agent, via action execution, fundamentally reframes the dialogue as process of reasoning over retrieved authoritative evidence, making the communication verifiable and trustworthy. Thirdly, effective healthcare communication is inherently longitudinal, building cumulative and evolving understanding of patient over time. To avoid suffering from catastrophic forgetting between encounters [138], the agentic paradigm addresses this by introducing persistent memory management and agent evolution. This allows the agent to construct and continuously refine dynamic patient model, enabling context-aware engagement and ensuring continuity of care. This is hallmark of robust therapeutic alliance [31]. 2.4 Taxonomy of Agents To systematically analyze the burgeoning landscape of LLM-based agents in healthcare, we propose novel taxonomy structured along two conceptually orthogonal axes. These axes address the two most fundamental questions of any autonomous system: \"From where does it derive its knowledge?\" and \"What is its objective?\". The intersection of these axes defines 2 2 matrix, yielding four distinct agentic paradigms that frame the subsequent analysis of this survey. The Knowledge Source axis delineates the primary source of clinical knowledge that an agent utilizes. It spans spectrum from Implicit Knowledge Navigation, which emphasizes creativity by leveraging the vast, unstructured knowledge embedded within the LLMs parameters, to Explicit Knowledge Grounding, which prioritizes reliability by compelling the agent to anchor its reasoning in external, verifiable knowledge sources.The Agency Objective axis defines the agents primary operational objective. This axis ranges from Event Cognition, where the goal is to understand and summarize clinical situation, emphasizing safety and acting as an advisor, to Goal Execution, where the aim is to autonomously complete multi-step clinical workflow, emphasizing autonomy and acting as collaborator. The interplay between these two axes gives rise to four archetypal agent categories, as shown in Fig. 3: Latent Space Clinician (LSC). These agents leverage the LLMs vast internal knowledge for creative synthesis and forming coherent understanding of clinical situation. Their philosophy is to trust the models emergent reasoning capabilities to function like an experienced clinical assistant, providing insights. For instance, the zero/few-shot reasoning capabilities of Med-PaLM [216] or MedAgents [231] exemplify this paradigm. Grounded Synthesizer (GS). These agents operate under the principle that LLMs should function as powerful natural language interfaces to reliable external information rather than as knowledge creators. Their primary role is to retrieve, integrate, and accurately summarize information from verifiable sources such as medical databases or imaging data. Exemplars include the foundational frameworks for medical retrieval and indexing techniques such as Med-RAG [319] and MA-COIR [148]. Emergent Planner (EP). This paradigm grants the LLM high degree of autonomy, allowing it to dynamically devise its own multi-step plan to achieve complex clinical goal. The agents behavior is emergent, as it independently determines the necessary steps and goals. Frameworks like AgentMD, which use ReAct-style prompting [101, 295]. Manuscript submitted to ACM 10 Zhi et al. Fig. 3. Taxonomy of agentic clinical dialogue in our survey. Structured along the orthogonal axes of knowledge source and agency objective, this framework reveals that the design of these agents is governed by two trade-offs: the balance between generative creativity and factual reliability (dictated by knowledge source), and the tension between operational autonomy and clinical safety (dictated by agency objective). Verifiable Workflow Automator (VWA). In this paradigm, agent autonomy is strictly constrained within pre-defined, verifiable clinical workflows or decision trees. The LLM acts as natural language front-end to structured process, executing tasks rather than making open-ended decisions, which ensures maximum safety and predictability. This approach is exemplified by commercial triage bots, the structured conversational framework of systems like Googles AMIE[210], and principles from classic task-oriented dialogue systems such as MeDi-TODER[109]. Following this taxonomy, the subsequent sections will dissect each of the four agent paradigms through the lens of five core technical components: strategic planning, memory management, action execution, collaboration, and evolution. Specific categories and exemplary papers and works are shown in Fig. 4. Notably, our analysis of the Action Execution module is specific to agents on the Explicit Knowledge Grounding axis, as paradigms reliant on implicit knowledge, by definition, do not leverage external knowledge tools. 3 Agentic Paradigm for Health Communication Following the proposed framework, this section provides granular analysis of the four archetypal paradigms of clinical dialogue. We dissect the architectural design of each paradigm across five orthogonal dimensions, which include strategic planning, memory management, action execution, collaboration, and evolution. 3.1 Latent Space Clinician The LSC paradigm represents the foundational approach in which agents primarily leverage the implicit medical knowledge encoded within the LLMs parametric memory to perform creative synthesis and clinical reasoning. Distinct from paradigms that rely on external retrieval, the LSC simulates the cognitive intuition of physician by traversing latent representations to form coherent understanding of clinical situations. As illustrated in Fig. 5, the architecture Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 11 Latent Space Clinician (3.1) Strategic Planning (3.1.1) MedFound[152], Casual-Base Alignment[146], Foresight2[116] Memory Management (3.1.2) 洧냢3Tune[20], FAIIR[174], Recursive Summary[250], Patrika[189] Collaboration (3.1.3) MAM[324], ReConcile[28], MEDCO[267], ColaCare[265] Self-evolution (3.1.4) AlphaEvolve[173], STLLaVA-Med[224], Agent Hospital[128] Strategic Planning (3.2.1) Self-Consistency[257], Expectation-max[226], Claim Verification[135] Emergent Planner (3.2) Memory Management (3.2.2) MOTOR[219], SUFO[81], Open-ended VQA[236], Staf-LLM[289] Collaboration (3.2.3) MedLA[160], MultiMedRes[67], DynamiCare[204], ToR[182] Self-evolution (3.2.4) MedAgentSim[10], LLM Strategist[63], MedPAO[234], PPME[228] Strategic Planning (3.3.1) HyKGE[95], EvidenceMap[331], MHMKI[27], MedicalGLM[256] Memory Management (3.3.2) K-Comp[43], Rationale-Guided RAG[217], Seek Inner[159], CoE[187] Grounded Sythesizer (3.3) Action Execution (3.3.3) MedGENIE[57], MediSearch[233], MeNTi[330], BriefContext[305] s o D c M Collaboration (3.3.4) MedOrch[30], MedConMA[251], Debating Framework[161] Self-evolution (3.3.5) AMG-RAG[3], SFPS[212], MACD[130], SFDA[212] Strategic Planning (3.4.1) VITA[110], Quicker[126], LLM-AMT[261], MedPlan[83], RULE[281] Memory Management (3.4.2) EMRs2CSP[39], Medical Graph RAG[275], Deep-DxSearch[320] Verifiable Workflow Automator (3.4) Action Execution (3.4.3) Cli-RAG[105], Tala-med[8], PPME[228], CLI-RAG[105], Medex[301] Collaboration (3.4.4) TeamMedAgents[167], TAMA[285], MAKAR[207], ClinicalLab[292] Fig. 4. The main content flow and categorization of this survey. We identify several key works from each paradigm. Self-evolution (3.4.5) HealthFlow[329], MetaAgent[185], EvoAgentX[260], ZERA[297] focuses on activating these internal reasoning chains through strategic prompting and memory iteration. summary of representative works and their technical characteristics is presented in Table 3. Table 3. The summarization of LSC agentic approach, \"PT\" represents pre-training and fine-tuning, \"PE\" represents prompt engineering, \"MAS\" represents multi-agent system, \"RL\" represents reinforcement learning, and \"ST\" represents self-training. Agentic Approach MedFound[152] Casual-Base Alignment[146] Foresight2[116] 洧냢3Tune[20] FAIIR[174] Recursive Summary[250] MAM[324] ReConcile[28] AlphaEvolve[173] STLLaVA-Med[224] Main Corresponding Component Planning Strategies Planning Strategies Planning Strategies Memory Management Memory Management Memory Management Collaboration Collaboration Self-evolution Self-evolution Detailed Method Self-bootstrapping Strategy Downstream Task Task-oriented Casual Chain Decision Process Medical QA Task-oriented Medical VQA Supportive Medical QA Task-oriented Medical QA Task-oriented Medical VQA Contextual Fine-tuning Attention Alignment Tuning Domain-adapted Memory Iteration Role-specilization Multi-round Discussion Algorithm Improvement Instruction Generation Framework Type PE PE PT PT PT PE MAS MAS ST ST 3.1.1 Strategic Planning. Strategic planning of the LSC is the process of architecting an internal cognitive workflow to construct comprehensive and accurate clinical snapshot through structured path of inquiry and reasoning executed within the models latent space. Decomposition strategies. Decomposition for the LSC functions as the architect of an internal cognitive workflow, translating clinical query into structured path of inquiry entirely within the models latent space. The evolution of this strategy reveals clear trajectory from implicit semantic association to the explicit modeling of human-like clinical reasoning chains, showcasing the development of more deliberate and inspectable clinical logic. Manuscript submitted to ACM Zhi et al. Fig. 5. General structure of the single agent in the LSC paradigm. Decomposition breaks down queries into structured reasoning chains entirely within the latent space. Iteration functions as an internal deliberative cycle, employing self-correction mechanisms like consistency checks to refine hypotheses without external tools. The agent utilizes parametric memory as an internalized medical curriculum for reasoning, while non-parametric memory employs context extension techniques to maintain coherence. Core differences from other paradigms are covered with red blocks. An underlying premise is that effective decomposition depends on rich, structured internal knowledge base. Early generative task reframing demonstrated that models such as BioGPT [158] and BioBART [300] could perform ordered analysis based primarily on probabilistic associations. However, such implicit decomposition is clinically meaningful only when grounded in deep domain expertise, requiring specialized models like ClinicalBERT [85] and BioMegatron [213] to robustly encode clinical semantics. To transcend the limitations of implicit associations, contemporary research has adapted generic chain-of-thought methodologies into explicit clinical reasoning chains. Unlike general-purpose reasoning, this approach structures the latent space traversal to mirror the review of systems utilized by physicians. Med-PaLM [216] demonstrates that instruction fine-tuning serves as soft decomposition mechanism, compelling the model to externalize its latent reasoning into structured explanation before concluding. Moving beyond simple step-by-step generation, frameworks such as the chain of diagnosis [24] and HuatuoGPT-II [244] impose strict medical ontology on the decomposition process. By constraining the thought process to follow specific clinical sequence, ranging from symptoms and history to etiology and diagnosis, this transformation ensures that decomposition is not merely linguistic artifact but deliberate simulation of diagnostic logic, rendering the LSCs intuition transparent and inspectable. Representing the frontier of this paradigm, advanced decomposition strategies capture the distributed and causal nature of expert cognition, reflecting shift toward simulated multi-disciplinary collaboration. In systems like MedAgents [231], central coordinator breaks down complex clinical case into distinct medical perspectives, assigning subquestions to specialized \"expert\" roles (e.g., pathologist or cardiologist) instantiated within the latent space. This trend culminates in Causal Alignment, where problems are decomposed based on domain-specific causal mechanisms rather than heuristics. When guided to follow human-like causal reasoning, the LSCs internal plan mirrors the nuances of clinical judgment [146]. This granular cognitive modeling is architecturally supported by findings in knowledge editing, which indicate that factual medical knowledge is localized in modular LLM components, thereby enabling step-wise, targeted analysis without the need for external tools [252]. Iteration strategies. Reasoning within the LSC operates as an internal deliberative cycle, distinct from the physical trial-and-error observed in agentic planning [71, 155]. This mechanism simulates the cognitive process of clinician who pauses to refine hypothesis before speaking. Rather than seeking new external data, the cycle re-processes existing Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 13 latent information to produce reliable clinical snapshot, effectively turning the generation process into rigorous differential diagnosis loop [61]. prerequisite for this internal iteration is the capability to map high-dimensional patient data into structured cognitive space. Leveraging deep learning architectures such as FNAE [15], REGLE [325], and Autosurv [92], the LSC compresses complex, multi-modal clinical signals into low-dimensional latent space. In medical context, this represents the construction of clinical manifold, where patient states are dynamically adjusted through iterative clustering and prototyping. Within this manifold, the agent can simulate potential disease progressions or treatment outcomes by analyzing vector trajectories, projecting the patients future state to validate current decisions without requiring real-world intervention. To enhance diagnostic accuracy, the LSC employs multi-round reasoning that mirrors clinical self-correction. Instead of generating conclusion in single forward pass, the agent performs internal cycles of hypothesis generation and validation. Frameworks like Qilin-Med [296] and counterfactual reasoning [119] operationalize this by generating intermediate clinical questions or alternative scenarios, such as assessing whether diagnosis changes in the absence of specific symptom, to challenge and refine the initial hypothesis. Furthermore, predictive models like Foresight [116] enforce logical consistency by updating the internal representation of the patients condition after each dialogue turn. This ensures that the agents evolving understanding remains coherent with the longitudinal patient history, significantly reducing contradictions in both open-ended and task-oriented clinical conversations. At higher cognitive level, iteration strategies empower the LSC to emulate the experience-based intuition of human physicians through emergent analogical reasoning. Research indicates that by iteratively referencing known cases encoded within its parameters, the LSC can interpret novel clinical presentations by analogy [64]. This process transcends monolithic prediction, executing instead as series of incremental, stepwise inferences [152, 156]. By iteratively mapping the current patients symptoms against implicit case prototypes learned during training, the agent constructs diagnostic pathway that is closer to expert clinical judgment than to simple pattern matching. 3.1.2 Memory Management. The LSCs memory can be conceptualized along spectrum defined by two primary modalities: the static, foundational knowledge encoded within the models parameters and the dynamic, context-specific information managed during single interactive session. Parametric memory. Parametric memory constitutes the cognitive foundation of the LSC, functioning effectively as an internalized medical curriculum. Unlike GSs (please refer to Section 3.3) that strictly rely on external databases for verification [280], LSC agents encode vast repositories of biomedical literature, clinical guidelines, and reasoning patterns directly into the models weights during large-scale pre-training and fine-tuning [20]. This implicit encoding enables agents to perform complex inference and creative diagnostic reasoning solely through internal computation, establishing the models parameters as the primary source of clinical truth within this paradigm. The primary mechanism for leveraging this internalized knowledge is dynamic activation during inference, most effectively achieved via sophisticated prompt engineering. Methodologies such as in-context learning [166] function as cognitive scaffolds that guide the model to activate specific parametric pathways relevant to clinical query. Foundational research demonstrates that instruction fine-tuning [26] and contextual prompting [200] do not merely retrieve facts but restructure the models latent space to align with clinical tasks, thereby enhancing zero-shot summarization and reasoning capabilities [280]. Further elucidating this mechanism, studies analyzing the activation of parametric memory during in-context learning [68, 191] reveal that the transformer architecture performs an implicit model fitting, adapting its pre-trained medical representations to the specific context of the current interaction. Manuscript submitted to ACM Zhi et al. Beyond static fact recall, parametric memory underpins the agents capacity for dynamic semantic modeling. This capability is critical for constructing an accurate clinical snapshot, as it allows the LSC to maintain coherent understanding of an evolving patient narrative and the intricate relationships between clinical entities. Furthermore, this memory facilitates remarkable degree of generalization and creative inference. By drawing on deep, abstract patterns learned during pre-training [174], the LSC can reason about unseen clinical cases or rare symptom presentations [26], process that simulates the intuition of seasoned physician confronting novel diagnostic challenge. This ability to generalize beyond explicit training data represents distinct advantage of leveraging high-dimensional representations within parametric memory; however, it necessitates careful management to align with the rigorous factuality required in healthcare. Non-parametric memory. While parametric memory serves as the medical curriculum, non-parametric memory in the LSC paradigm functions as the patient context window. Its primary objective is not to verify facts against an external database but to maintain informational continuity across the patients narrative. This creates robust working memory that prevents the agent from suffering from catastrophic forgetting during long, multi-turn clinical encounters [314], ensuring that the generated advice remains consistent with the specific patients history. primary challenge in processing clinical narratives is the sheer length of longitudinal patient records, which often exceeds standard model constraints. To address this, architectural innovations have been specifically adapted for the medical domain to expand contextual capacity. Long-context frameworks, such as Clinical ModernBERT [124] and DK-BEHRT [11], represent shift from processing isolated sentences to modeling entire chronological care trajectories. By incorporating sparse or block-wise attention mechanisms tailored for sequential data [170], these models extend their effective receptive field to tens of thousands of tokens. This enhancement is crucial for capturing long-range dependencies in EHRs, ensuring that critical diagnostic clues mentioned early in patients timeline are retained and integrated into current decision-making [271]. To manage the cognitive load within finite context window, LSC agents employ recursive summarization [250] [238] and memory compression techniques [192]. Unlike generic text compression, these methods, in clinical setting, act as filters for clinical salience. The model periodically distills the dialogue history into compact vectors or structured summaries, effectively creating memory proxy analogous to physicians handover note [273]. This process frees up contextual space for new symptoms while preserving the essential trajectory of the interaction. By maintaining this cumulative understanding, the agent ensures that its reasoning is based on comprehensive view of the patients status rather than on disjointed fragments. At more granular level, non-parametric memory facilitates the dynamic tracking of clinical entities and their evolving states [116]. During dialogue, the LSC continuously updates its internal representation of critical variables, including symptom severity, medication adherence, and test results, based on new user inputs [189]. This mechanism transforms static text into dynamic clinical snapshot, allowing the agent to recognize when patients condition has changed and to adjust its internal reasoning accordingly. This real-time state tracking is the operational bridge that connects the agents vast medical knowledge to the specific, evolving needs of the individual patient. 3.1.3 Collaboration. The collaborative architecture of the LSC paradigm is designed to transcend the cognitive limitations of individual models by emulating the consultation dynamics found in clinical practice. While early implementations focused on operational simplicity, the field is progressively shifting towards architectures that simulate professional medical interaction [265], aiming to reduce the opacity of latent reasoning through structured communication. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 15 Single-agent system. single-agent system functions analogously to general practitioner, utilizing solitary LLM to independently process and generate the entirety of clinical dialogue [26]. The primary advantage of this approach lies in its computational efficiency and architectural coherence, making it highly effective for routine, well-defined tasks where the reasoning path is linear and contained within general medical knowledge. However, the reliance on single latent space reveals critical vulnerabilities in complex clinical scenarios: solitary model often exhibits cognitive tunneling, adhering to an initially incorrect diagnosis and lacking the specialized depth required for interdisciplinary cases. This limitation necessitates structural evolution from individual processing to collective intelligence [231], mirroring the referral system in healthcare, where complex cases are escalated to team of specialists. Multi-agent system. Multi-agent systems (MAS) introduce collaborative paradigm that simulates the MDT approach inherent in modern medicine [267]. In this model, individual agents are instantiated with specialized rolessuch as clinician, pathologist, or patient advocateeach accessing different subsets of implicit knowledge or employing distinct reasoning strategies to solve clinical task. By introducing diverse perspectives, MAS effectively operationalizes clinical peer review within the latent space, mitigating hallucinations common in single-model reasoning. As illustrated in Fig. 6, the effectiveness of this simulation is largely defined by the underlying collaboration topology. Fig. 6. Multiple topologies of agent collaboration. Single-agent system (left) is solitary LLM that handles the entire cognitive loop. Dominant topology (middle) mimics clinical ward led by central orchestrator agent. Distributed topology (right) simulates peer-to-peer medical board to achieve consensus on the common clinical goal. In dominant topology, the system mimics hierarchical clinical ward led by chief physician. dominant orchestrator agent is responsible for decomposing the clinical problem, assigning sub-tasks to subordinate agents, and synthesizing their outputs into final decision. Frameworks such as ColaCare [265] operate within this structure, where primary reasoning agent moderates findings from specialized modules to ensure high consistency and streamlined decision-making. This structure ensures that all information flows through single adjudicating entity, maintaining strict control over the diagnostic narrative. Conversely, distributed multi-agent systems emulate peer-to-peer clinical case conference, where agents collaborate without central controller to achieve consensus. In this topology, agents share information, debate hypotheses, and negotiate conclusions directly with one another. Systems like ReConcile [28] and MAM [324] utilize this structure to foster greater interpretive depth, allowing for the organic aggregation of diverse perspectives. This paradigm is particularly well-suited for ambiguous clinical scenarios requiring multi-faceted analysis. Frameworks such as MDagents [113] and MedAgent [231] have demonstrated that leveraging such peer-to-peer dynamics significantly enhances accuracy in medical exam tasks. Furthermore, the information flow in these systems can be structured through mechanisms like directed acyclic graphs [218], ensuring that the collaborative debate remains focused and converges efficiently on robust clinical conclusion. Manuscript submitted to ACM 16 Zhi et al. 3.1.4 Evolution. In the dynamic landscape of healthcare, where treatment protocols and patient demographics are in constant flux, self-evolution serves as the mechanism for transforming the LSC from static repository of pre-trained facts into an adaptive learning entity. This process mirrors the professional development of clinician who must continuously integrate new medical evidence without discarding foundational medical training [307]. The primary objective within this paradigm is to update the agents parametric memory to maintain relevance and accuracy over time, effectively turning static model weights into growing clinical experience base [173]. The core engine driving this evolution is continual learning [62], which addresses the critical challenge of catastrophic forgetting, phenomenon where adapting to new tasks, such as revised diabetes guideline, inadvertently erases previously learned knowledge. To mitigate this, recent research has adapted regularization techniques to the medical domain, introducing penalty terms that constrain the model to preserve established medical facts while accommodating new data [173]. Furthermore, systems like Agent Hospital [128] utilize experience replay buffers, which function analogously to physician reviewing past case logs. By periodically re-training on subset of historically successful diagnoses, the agent reinforces its long-term clinical memory. More advanced approaches employ model expansion, dynamically allocating new neural capacity to learn emerging diseases. This effectively isolates novel medical knowledge from the established parameter space, ensuring that the acquisition of new specialty skills does not interfere with the agents generalist capabilities [224]. Beyond the passive absorption of new data, intrinsic motivation frameworks endow the LSC with form of active clinical inquiry. Inspired by the learning trajectory of medical residents, these mechanisms enable agents to autonomously explore their environment and refine latent representations by pursuing tasks that maximize information gain [128]. Rather than random exploration, agents engage in self-directed curriculum learning, progressively advancing from routine common cold cases to complex multi-system pathologies. By selecting tasks and exploration strategies independently, the LSC shapes its own learning path, leading to robust and generalizable clinical reasoning that is less dependent on supervised fine-tuning and more reflective of the autonomous growth seen in human medical experts. 3.1.5 Summary. The LSC represents the foundational agentic paradigm situated at the intersection of implicit knowledge navigation and event cognition. By treating the LLMs parametric memory as an internalized medical curriculum, these agents excel at synthesizing fragmented symptoms into coherent diagnostic hypotheses [146, 216], effectively emulating the zero-shot reasoning and pattern recognition capabilities of experienced physicians in novel or ambiguous cases [117]. However, this reliance on latent intuition introduces inherent risks regarding factual hallucinations, knowledge staleness, and the opacity of the reasoning process, which challenge the rigorous auditability required in healthcare. Consequently, the primary research frontier lies in bridging the gap between the models powerful semantic intuition and clinical safety demands, specifically focusing on improving the interpretability of latent states and mitigating catastrophic forgetting during the continuous acquisition of new medical knowledge. Furthermore, as clinical care demands moving beyond passive case interpretation to active intervention, we next explore the EP paradigm, which harnesses this implicit intuition to autonomously orchestrate dynamic clinical workflows. 3.2 Emergent Planner The EP paradigm grants the LLM higher degree of autonomy, enabling it to dynamically devise and execute multi-step plans to achieve complex clinical goals based on internal procedural intuition. Unlike the LSC, which focuses on observation, EP agents operate as active digital collaborators that autonomously shape the workflow trajectory through self-directed planning and execution [22, 25]. As illustrated in Fig. 7, this paradigm relies on the models emergent Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication abilities to navigate open-ended clinical tasks. Key contributions to this autonomous framework are summarized in Table 4. Table 4. The summarization of EP agentic approach, \"PT\" represents pre-training and fine-tuning, \"PE\" represents prompt engineering, \"MAS\" represents multi-agent system, \"RL\" represents reinforcement learning, and \"ST\" represents self-training. Agentic Approach Self-Consistency[257] Expectation-maximization[226] Claim Verification[135] MOTOR[219] SUFO[81] Open-ended VQA[236] MedLA[160] MultiMedRes[67] MedAgentSim[10] LLM Strategist[63] Main Corresponding Component Planning Strategies Planning Strategies Planning Strategies Memory Management Memory Management Memory Management Collaboration Collaboration Self-evolution Self-evolution Detailed Method Reasoning Path Selection Knowledge Extraction Evidence Analysis Transfer Learning Downstream Task Medical QA Medical QA Task-oriented Task-oriented Interpreting Feature Space Task-oriented Medical VQA Medical QA Medical QA Task-oriented Task-oriented Prefix-tuning Reasoning Organization Learner Agent Knowledge Expansion Meta Learning Framework Type PE PE PE PT PT PT MAS MAS PE ST Fig. 7. General structure of single agent in the EP paradigm. Decomposition translates clinical goals into sub-tasks and involves generating cognitive maps that anticipate future states. Iteration is driven by self-reflection and real-time environmental feedback to dynamically adjust plans. Parametric memory provides the procedural intuition and strategic knowledge, while non-parametric memory serves as log or highlight to track the trajectory of the autonomous workflow execution and ensure continuity. Core differences from other paradigms are covered with red blocks. 3.2.1 Strategic Planning. For EPs, strategic planning constitutes the core of their intelligence. Unlike LSC agents that primarily interpret existing information, EPs must navigate complex clinical narratives through internal deliberation and autonomous planning [135, 293]. When confronted with high-level clinical goal, the agent is required to break it down into sequence of logical sub-goals. This process serves as cognitive self-guidance, systematically shaping the trajectory and efficiency of the agents actions [198]. Decomposition strategies. Clinical reasoning involves navigating landscape of uncertainty where single symptom may point to multiple etiologies, necessitating process akin to differential diagnosis [226]. To emulate this rigorous medical logic, EPs employ the self-consistency strategy [205, 257]. Instead of relying on single linear inference, the agent generates diversity of potential reasoning pathsparallel to physician considering various diagnostic hypothesesand aggregates the outcomes via voting mechanism [254]. This approach effectively mitigates the risk of idiosyncratic errors in generation, ensuring that the final clinical conclusion represents the most robust consensus derived from the models internal deliberation. Manuscript submitted to ACM 18 Zhi et al. Furthermore, real-world clinical decision-making is rarely straight line but rather branching tree of possibilities, where each action influences subsequent choices. To align with this reality, EPs integrate divergent lines of thought into structured decision blueprint [89]. Advanced frameworks like TREE-PLANNER [84] enable the agent to construct cognitive map prior to execution. By elevating decomposition from deterministic sequence to the comprehensive exploration of probabilistic action space [200], EPs can mentally simulate future clinical statessuch as predicting patients response to different treatmentsbefore committing to plan. This mechanism draws inspiration from hierarchical planning methods like Least-to-Most Prompting [321], yet it is specifically adapted to navigate the prunable, tree-like structure of clinical pathways. In addition to structural navigation, the decomposition process of EPs must adhere to established cognitive schemas used by medical experts. For instance, the verification of medical claim typically follows specific cognitive cycle: understanding the clinical puzzle, analyzing diagnostic goals, forming an interim verdict, and critically questioning that diagnosis. Research suggests that EPs can internalize such expert-level frameworks [247], using them as an implicit scaffold to decompose complex tasks. While some studies propose explicit multi-step prompting to guide this process for claim verification [135], sufficiently advanced EP implicitly models this workflow, ensuring that its autonomous decomposition remains clinically logical and methodologically sound. Finally, effective planning relies on the agents ability to model the intrinsic structure of medical data. EPs derive their planning capabilities from pre-training on vast biomedical corpora, where they learn the deep sequential patterns of disease progression and care delivery. Studies utilizing graph transformers demonstrate that capturing the relational structure among medical concepts in EHRs yields superior patient representations [184], which is prerequisite for generating plausible plans. Similarly, breaking down lengthy medical dialogues into section-specific segments is essential for producing well-structured clinical notes [304]. These findings highlight that the decomposition strategy of an EP is effectively an outward expression of its deep, implicit understanding of underlying data logic. Iteration strategies. While decomposition provides the initial roadmap, clinical management is inherently dynamic, requiring continuous adjustment based on evolving patient states. To address this, EPs employ iterative strategies that afford flexible planning capabilities [22]. This process is principally driven by self-reflection and critique. In high-stakes clinical setting, generating response without verification is hazardous; thus, the agent must not only execute actions but also scrutinize its own reasoning and conclusions [266]. This mechanism is structurally analogous to the clinical practice of differential diagnosis, where physician proposes hypothesis and immediately critiques it to rule out contraindications or rare pathologies [199]. Such an internal adversarial process enables the agent to identify logical flaws or safety risks early, iteratively refining the diagnostic path before any advice is delivered to the patient. Empirical studies like Reflexion [214] demonstrate that equipping LLMs with this self-corrective capability significantly boosts performance in complex medical reasoning tasks. Complementing this internal reflection is the feedback loop based on interaction history [298]. EPs treat every conversational exchange not merely as text generation, but as an opportunity to acquire external feedback, update their internal world model, and dynamically adjust future plans [18]. Since these agents rely on implicit knowledge, extracting cues directly from the dialogue becomes the primary means of strategy refinement. For instance, if patient expresses confusion or hesitation, the agent does not mechanically repeat prior information; instead, it iteratively modifies its communication policy to align with the patients health literacy level. This continuous, dialogue-driven feedback loop ensures that the clinical communication process is highly adaptive and personalized, allowing the planning trajectory to emerge organically from the interaction rather than adhering to rigid, preset script. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 19 3.2.2 Memory Management. Memory management in an EP is fundamentally oriented toward goal execution, built upon dual-system architecture in which both parametric and non-parametric memory are subordinated to executive function [147, 219]. Parametric memory acts as the deep, implicit foundation for strategic intuition and procedural knowledge [41, 293], while non-parametric memory serves as transient workspace for tactical planning and real-time state tracking. Together, these systems enable the coherent generation of goal-directed actions within complex clinical workflows. Parametric memory. The parametric memory of EP functions not merely serves as static knowledge repository, but it also functions as the central engine enabling autonomous planning and multi-step action execution [219]. Unlike the LSC, which utilizes parametric memory primarily to construct cognitive snapshot of clinical scenario, the EP is intrinsically tasked with leveraging this internal storage to navigate and execute end-to-end clinical workflows [222]. Consequently, its parametric memory encodes not only declarative knowledge but, more crucially, embodies the procedural knowledge and strategic intuition that underlie effective clinical practice. This procedural knowledge, embedded in the models weights, is acquired during pre-training through exposure to vast clinical text corpora that implicitly encode workflow patterns [223]. In clinical context, this process parallels the accumulation of experience by resident physician. For example, the model learns not only the diagnostic criteria for myocardial infarction but also the sequential actions and underlying decision logicspanning from evaluating patient presenting with chest pain to ordering ECG and troponin tests, to initiating emergency interventions [58]. This deep, implicit understanding of clinical processes enables the agent to autonomously generate coherent action sequences when provided with high-level goal, functioning as collaborator actively advancing clinical workflows [38]. During task execution, the management of parametric memory is realized through strategic activation and adaptive behavioral modification [289]. When presented with high-level clinical goal, the agent dynamically activates relevant procedural schemas within its parameter space rather than merely retrieving static factual knowledge [58]. This mechanism enables structured sequence of actions, such as assessing the patients current level of understanding, explaining pathophysiological mechanisms, demonstrating the use of glucose monitoring device, and collaboratively establishing initial dietary and physical activity goals [58]. Each step is generated based on an implicit cognitive model of effective health education, ensuring coherent progression toward the overarching clinical objective. Correspondingly, updating this memory is less concerned with correcting factual inaccuracies and more focused on refining behavioral patterns. In this context, medical fine-tuning techniques [115] and prefix-tuning [236] serve as essential instruments for aligning the agent with evolving standards of care. For instance, fine-tuning the agent on revised hypertension guideline that changes first-line medication recommendations directly alters its behavior within the initiate hypertension treatment workflow [115]. This process is analogous to reshaping physicians clinical practice habits rather than merely updating an isolated fact in memory, thereby reflecting the goal-oriented nature of the EP [147]. Non-parametric memory. If parametric memory constitutes the strategic intuition of an EP, then non-parametric memory functions as its essential tactical workspace [81]. Its primary role shifts from acting as an external source of static knowledge to serving as dynamic and ephemeral information hub for tracking, planning, and reflecting upon the trajectory within multi-step clinical workflow [13]. This specific utilization distinguishes the EP from the LSC, which employs non-parametric memory primarily to enrich context for precise cognitive snapshot. For the EP, the value of memory is measured principally by its utility in informing and optimizing the subsequent clinical action. Functionally, non-parametric memory operates as dynamic log of the workflow state. For an agent designed to drive clinical process forward, the complete dialogue history is more than collection of information; it acts as an Manuscript submitted to ACM 20 Zhi et al. executive log that records completed steps, pending actions, and critical junctures [12]. The agent must rely on this log to orient itself within the overall care pathway, ensuring its actions are coherent and purposeful. Technically, the most direct implementation of this dynamic workspace is through in-context learning [123], where the deliberative process and dialogue history are continuously integrated into the prompt for subsequent calls to the LLM [202]. To support longitudinal workflows that span multiple sessions, external storage mechanisms are utilized to extend the agents episodic reach, preventing the catastrophic forgetting of patient history [13]. Crucially, unlike the GS or VWA paradigms that query external databases for standardized medical guidelines or fixed protocols, the EP utilizes this memory strictly as dynamic archive of patient-specific context. By encoding interaction logs and successful communication patterns into vector databases, the agent retrieves the specific narrative of the patients care journey [12]. This ensures that subsequent autonomous planning is not restart-based but is continuously informed by the patients evolving preferences and past reactions. Thus, external memory in the EP serves to maintain the continuity of the emergent persona, rather than imposing rigid external workflow. 3.2.3 Collaboration. The essence of collaboration for EPs is defined by the capacity for dynamic coordination of multi-step, goal-oriented clinical workflows [160]. Distinct from the cognition-centric collaboration of LSCs, which prioritizes effective information transfer, collaboration in the EP paradigm centers on action synchronization, task allocation, and workflow progression, thereby embodying its core identity as an active clinical partner [204]. Single-agent system. Within this framework, the agent operates as an autonomous practitioner, leveraging its implicit procedural knowledge to proactively steer the clinical dialogue. In clinical setting, this goes beyond simple Q&A. The agent functions as facilitator of shared decision-making. It actively initiates health education, interprets the significance of test results, and proposes treatment options, inviting the human user to participate in the care plan [304]. The collaborative dynamic here is framed by the agents role in structuring the ambiguity of patient inputs into coherent medical narrative, using its internal planning capabilities to propel the consultation toward defined therapeutic objective [182]. Multi-agent system. MAS expands the capability envelope of the EP by distributing complex workflows among team of specialized agents [160]. This architecture emulates real-world MDT, enabling parallel task execution and the integration of diverse medical expertise to enhance system robustness [317]. Based on their organizational structure, these systems typically adopt one of two topologies. In dominant topology, the system mimics hierarchical clinical ward led by chief physician. The central agent acts as higher-order EP responsible for meta-planning: decomposing complex clinical objective into series of well-defined sub-tasks [30, 67]. It then delegates these sub-tasks to downstream worker agents, which may be domainspecific EPs or grounded tools. Information flows top-down: the central coordinator issues clinical directives, worker agents execute tasks such as history taking or differential diagnosis, and the coordinator synthesizes this feedback to determine the next global action [317]. This structure offers clear hierarchical control and predictable behavior, making it ideal for standardizable clinical pathways. Conversely, distributed MAS resembles peer-to-peer clinical case conference or tumor board assembled to address complex comorbidities [177]. In such systems, collaboration is driven not by delegation but by negotiation. Each agent, representing specialist with distinct implicit knowledge, generates local action plan informed by its unique perspective [160]. These agents broadcast their intentions through shared channel [204], engaging in conflict detection and plan integration. Through multi-round process of counter-proposals and mutual concessions, they iteratively refine their individual plans to converge on globally coherent and clinically optimal course of action [46]. While Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication computationally complex, this paradigm provides the flexibility required to solve integrative clinical problems where guidelines may conflict. 3.2.4 Evolution. In the EP paradigm, evolution is an intrinsic capability for autonomous self-improvement, distinct from external model updates or knowledge base expansions [10]. Since EPs rely on implicit procedural knowledge to navigate complex workflows, they require mechanism to dynamically refine their internal strategies based on action outcomes [63]. This capacity transforms them from static executors of pre-trained patterns into adaptive learners who grow expertise through clinical practice, mirroring the transition of physician from residency to fellowship. At the foundational level, the core of this evolutionary capability is feedback loop driven by real-world clinical outcomes. When an EP completes workflow, the resulting clinical impactmeasured by patient recovery rates, adherence metrics, or physician oversightis encoded as reward or penalty signal [164]. Leveraging frameworks inspired by human-AI collaboration [80], this signal fine-tunes the agents parametric memory. Crucially, this process does not merely correct isolated facts but reinforces or suppresses the entire neural policy associated with the action sequence. Consequently, decision paths leading to positive patient outcomes are strengthened, while those yielding suboptimal results are attenuated. This mechanism enables the agents implicit clinical intuition to evolve toward better standards of care through thousands of such micro-adjustments [234]. Progressing beyond case-by-case corrections, mature evolutionary mechanism must extract generalizable clinical heuristics from successful experiences. This necessitates meta-learning layer capable of identifying recurring success patterns across diverse tasks [228]. For instance, if an agent discovers that specific sequence of empathetic validation followed by technical explanation consistently improves compliance in anxious patients, it abstracts this pattern into reusable communication protocol [10]. This protocol is then stored as strong prior in its high-level parametric memory, allowing for rapid deployment in future encounters with similar patient profiles [63]. This abstraction from concrete experience to generalized strategy marks the agents cognitive shift from novice practitioner to an experienced expert. Ultimately, the most advanced form of evolution is proactive self-repair. truly evolving agent should not passively await external feedback but actively identify its capability limits and knowledge gaps to initiate targeted learning. This requires an internal auditing module to analyze the agents past performance stability [159]. For example, the system may detect consistently low confidence or high variance when handling cases involving rare drug-drug interactions. Upon identifying such competency weakness, the mechanism can autonomously trigger self-improvement task [131] to fine-tune specific parameters. This self-driven learning, guided by metacognitive awareness, parallels the continuing medical education of human doctors, ensuring efficient, directed evolution into reliable clinical collaborator. 3.2. Summary. The EP paradigm defines highly autonomous agent that utilizes deep, implicit procedural knowledge to generate and execute multi-step clinical workflows [67], with action trajectories dynamically shaped to achieve high-level goals. Relying on parametric memory as strategic engine and non-parametric memory as tactical workspace for action-oriented reasoning, EPs demonstrate exceptional flexibility and creative problem-solving in open-ended clinical tasks [12]. This execution-driven orientation critically distinguishes them from the more passive, cognition-focused LSCs; while both paradigms leverage internal knowledge, EPs utilize it to propel clinical processes forward rather than merely describing patient states. However, such significant autonomy introduces inherent risks regarding clinically dangerous hallucinations and the potential application of outdated procedures due to knowledge staleness. Consequently, the primary research challenge lies in balancing this generative freedom with the rigorous demands of clinical safety. This tension highlights the critical necessity for explicit verification mechanisms, Manuscript submitted to ACM Zhi et al. effectively paving the way for the GS paradigm, which prioritizes adherence to external evidence over creative autonomy to ensure reliability. 3.3 Grounded Synthesizer Addressing the critical challenge of hallucination in medical AI, the GS operates on the principle of strict explicit knowledge grounding. Unlike creative generators, these agents function as intelligent interfaces that retrieve, integrate, and cite verifiable external evidence to construct an accurate clinical snapshot, as illustrated in Fig. 8. By anchoring reasoning in traceable chain of evidence [187], the GS paradigm maximizes the safety and reliability necessary for clinical decision support. Table 5 provides systematic overview of methods within this evidence-driven category. Table 5. The summarization of grounded sythesizer agentic Approach, \"PT\" represents pre-training and fine-tuning, \"PE\" represents prompt engineering, \"MAS\" represents multi-agent system, and \"ST\" represents self-training. Agentic Approach HyKGE[95] EvidenceMap[331] MHMKI[27] MedicalGLM[256] K-Comp[43] Main Corresponding Component Planning Strategies Planning Strategies Planning Strategies Planning Strategies Memory Management Rationale-Guided RAG[217] Memory Management Memory Management Action Execution Action Execution Action Execution Collaboration Collaboration Self-evolution Self-evolution Seek Inner[159] MedGENIE[57] MediSearch[233] MeNTi[330] MedOrch[30] MedConMA[251] AMG-RAG[3] SFPS[212] Detailed Method Hypothesis Enhancement Content Summarization Knowledge Infusion Quality Evaluation Mechanism Knowledge Infusion Knowledge Retrieval Information Mining Information Generation Medical Search Engine Calculator Tool-use Downstream Task Medical QA Biomedical QA Biomedical QA Medical QA Medical QA Medical QA Medical VQA Medical QA Task-oriented Task-oriented Mediator-guided Collaboration Medical VQA Medical QA Medical QA Task-oriented Voting Mechanism Knowledge Updating Domain Adaptation Framework Type PE PT PT PT PT PT PE PE PE PT MAS MAS PE ST Fig. 8. General structure of single agent in the GS paradigm. Strategic planning decomposes broad clinical inquiries and maps these queries to specific external sources. Action execution serves as the core mechanism for evidence acquisition, performing three distinct epistemic operations. Non-parametric memory acts as an evidence boundary, strictly buffering the retrieved snippets to prevent contamination, while parametric memory synthesizes this grounded evidence into fluent response with traceable citations. Core differences from other paradigms are covered with red blocks. 3.3.1 Strategic Planning. In the context of the GS, strategic planning is not aimed at devising sequence of actions to alter the environment, but rather at planning how to better cognize. It breaks down broad cognitive goal into specific, answerable sub-questions, each designed to be resolved by querying external sources such as EHRs, medical literature, Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 23 or clinical guideline knowledge graphs(KGs) [180, 242]. This approach ensures that all information in the synthesized clinical snapshot is source-traceable, significantly reducing the risk of informational hallucinations [284] and reflecting the conservative, reliable standards essential in medical research. Decomposition strategies. To achieve this, the primary decomposition strategy functions as the construction of logically rigorous inquiry pathway that mirrors professional diagnostic workflows [95]. Unlike the implicit reasoning chains used in other paradigms, the GS maps complex clinical assessment tasks directly to standardized decision trees or guideline protocols. The agent generates an ordered sequence of sub-questions targeting atomic, verifiable clinical facts, such as specific biomarkers or symptom durations, that can be validated through external database queries [180]. This logic extends to handling the complexity of heterogeneous and multi-hop medical information, where decision-making necessitates the synthesis of diverse data sources, such as laboratory information systems and medical imaging archives. The strategy employs structured query dependency graph [220] to orchestrate the systematic retrieval of evidence fragments. Within this graph, the output of specific medical inquiry serves as the requisite input for subsequent diagnostic steps [331], thereby transforming high-complexity clinical reasoning into traceable, multi-hop information-gathering workflow that supports both concurrent and sequential execution [27]. Beyond static planning, advanced strategies incorporate iterative cognitive refinement driven by real-time clinical data feedback. The agent does not rely on intrinsic hallucinations for exploration; instead, it leverages specific retrieval results as conditional triggers to guide further investigation [284]. These data-driven triggers enable the system to dynamically instantiate fine-grained sub-query templates adapted to emerging clinical findings [256]. For instance, the detection of critical value, such as significantly elevated serum potassium, acts as signal to initiate new, targeted inquiry branch regarding potential causes, such as renal failure or medication side effects [284]. This adaptive mechanism shifts the cognitive workflow from rigid checklist to dynamic inquiry tree, selectively allocating cognitive resources to the most salient aspects of the patients condition to construct an increasingly deep and high-fidelity clinical snapshot. Iteration strategies. Iteration strategies within the GS framework introduce critical dimensions of circulation and refinement, serving not as model-driven self-correction but as rigorous mechanism to enhance the information density of the clinical snapshot through multiple structured interactions with external sources [43, 142]. Central to this process is an information-query loop [27] designed to emulate the systematic information gathering of clinician. primary objective is cyclical gap-filling to achieve information completeness. Unlike general open-domain inquiries, clinical data retrieval often necessitates adherence to strict task-relevant information schema or cognitive scaffold [284], analogous to populating diagnostic checklist or structured admission note. Following an initial retrieval, the agent systematically compares the obtained data against this predefined schema to automatically detect missing clinical parameters. It then generates and executes new set of highly focused sub-queries to address these specific deficits, continuing this goal-driven cycle until the patient profile is fully populated [226]. This ensures that the final clinical representation maintains structural integrity and covers all medically necessary dimensions. Parallel to gap-filling, the agent employs an evidence hierarchy-guided ambiguity resolution mechanism to handle the contradictions inherent in real-world medical records [311]. When retrieved information from multiple sources conflictssuch as discrepant pathology reports or inconsistent medication liststhe agent adheres to strict query escalation protocol rather than attempting to hallucinate reconciliation. By referencing predefined evidence hierarchy, the system systematically executes cyclical inquiry process to identify reliable anchor, such as prioritizing the clinical document with the most recent timestamp, seeking report signed by higher-level authority [142], or requesting final consensus version [145, 259]. If these automated pathways fail to resolve the discrepancy, the strategy mandates Manuscript submitted to ACM 24 Zhi et al. explicitly flagging the conflict to the human user, thereby prioritizing safety and accountability over forced coherence. Complementing these mechanisms is granularity-driven progressive deepening, which allows the agent to construct multi-layered clinical representation that integrates both breadth and depth. In this mode, the agent recursively executes sequence of increasingly specific sub-queries focused on core clinical entity [259]. This mimics the clinical drill-down process, whereby physician investigates general symptom by progressively querying for its specific attributes, severity, and associated context until the information granularity satisfies the requirements for precise diagnosis [240]. 3.3.2 Memory Management. For paradigm centered on the core principle of external knowledge grounding, the design of GSs memory system presents unique tension. On one hand, it must strictly rely on external, verifiable knowledge sources as the sole benchmark for facts [43, 187, 303]. On the other hand, it cannot dispense with the parametric memory inherent to the LLM itself to execute complex cognitive tasks [217]. Therefore, the essence of memory management in the GS is not simple storage and retrieval, but rather the construction of meticulously designed and highly controlled bridge between external truth and internal cognition [274]. Parametric memory. The role of parametric memory in the GS framework is to serve as an indispensable universal cognitive processor, providing the foundational cognitive capabilities necessary for the reliable integration and presentation of external knowledge. Its core value is manifested across three interconnected levels. Clinical dialogue is inherently complex, characterized by mix of colloquial patient descriptions and precise, domainspecific terminology. The agent must rely on the linguistic patterns encoded within its parametric memory to parse these interactions, effectively mapping lay descriptions of symptoms to standardized medical concepts and identifying latent clinical intents [90]. This deep natural language understanding capability enables the agent to navigate the semantic intricacies of medical dialogue, serving as prerequisite for any subsequent evidence retrieval. Once the users intent is identified, the agent employs its parametric knowledge to function as universal translator, converting abstract clinical questions into concrete, executable actions. This process involves transforming natural language into structured queries tailored for specific external targets, such as SQL for EHRs or SPARQL for biomedical KGs [217]. Such capability relies heavily on the procedural knowledge stored in the models parametersspecifically, the rules regarding database schemas, search optimization strategies, and API protocols learned during pre-training [27]. Eventually, information integration and fluent generation represent the culmination of the GS workflow, where parametric memory plays pivotal role in ensuring narrative quality. Data retrieved from heterogeneous sourcesranging from disjointed laboratory values to unstructured literature snippetsis often fragmented and lacks narrative flow [159]. The agent leverages its advanced generation capabilities to synthesize these disparate evidence fragments into coherent, fluent, and clinically appropriate output. By applying learned linguistic structures and medical reporting standards, parametric memory transforms raw, retrieved facts into synthesized clinical summary that ensures readability without compromising the factual integrity derived from external sources [284]. Thus, while the content is grounded externally, the coherence and accessibility of the final report depend entirely on the processing power of the models parametric memory. Non-parametric memory. If parametric memory functions as the cognitive processor, non-parametric memory acts as the verifiable epistemic scaffold of the GS paradigm. Unlike other agentic approaches where external memory serves merely as conversational buffer, here it is architecturally designed as structured log that enforces the rigorous standards of traceability and verifiability required in healthcare [125]. Functioning primarily as an evidential ledger, this memory system ensures that every interaction with an external knowledge source is not recorded as an isolated Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 25 data point but archived as complete clinical transaction [303]. Each entry captures the retrieved medical information, its precise source, and the query used to obtain it [138]. This design transforms memory from passive repository into dynamic, auditable chain of evidence [187]. In high-stakes clinical practice, this capability is essential as it allows human experts to retrospectively verify the informational basis of any AI-generated recommendation, ensuring that synthesized outputs can be systematically traced back to their foundational evidence units for accountability. Beyond auditability, non-parametric memory serves as the central mechanism for clinical state management. The strategic plans of the GS are explicitly instantiated and dynamically tracked within this external memory rather than being left to the opaque latent space of the LLM [159]. This system maintains comprehensive representation of the current diagnostic workflow, tracking which clinical sub-questions have been resolved, which information gaps remain, and how different pieces of evidence correlate [136]. During the iterative reasoning process, it is the evolving state of this external memory that triggers subsequent inquiry cycles, as in the case of patient chart [194]. This externalization of the cognitive state prevents procedural drift by ensuring that the agents behavior is strictly governed by accumulated evidence rather than unpredictable internal associations [301]. Consequently, when the final synthesis stage begins, the model is supplied with structured, contextually enriched body of evidence, enabling generation process that is faithful to the patients actual status. critical architectural imperative for non-parametric memory in this paradigm is information compartmentalization [48]. significant risk in medical AI is knowledge contamination, where verified external facts blend with the LLMs vast but potentially hallucinated internal knowledge. To mitigate this, non-parametric memory is designed as firewalled context [108]. The information flow is strictly unidirectional: from external clinical tools into this memory, and then to the LLMs context window for processing [305]. The system explicitly prevents the LLM from treating this memory as training data to update its internal beliefs, maintaining an absolute boundary between verifiable patient data and implicit model parameters [55]. This strict separation ensures that the agent functions purely as synthesizer of external truth, embodying the conservative, safety-first philosophy essential for reliable clinical decision support. 3.3.3 Action Execution. In the GS paradigm, the concept of action execution refers to the execution of epistemic operations whose sole purpose is to acquire information from external knowledge sources to construct an internal cognition [57]. Therefore, the function of the action execution module here is to serve as the physical interface connecting the logical inquiry pathway with the real-world data and situations [203]. It is responsible for translating abstract inquiry directives into syntactically precise API calls or query statements for specific data systems and faithfully transmitting the returned data to the memory module. Knowledge-based. primary mode of action execution within the GS paradigm involves knowledge-based actions, which specifically entail interactions with external structured, symbolic knowledge bases [303]. These interactions are designed to obtain facts characterized by explicit semantic relationships and high degree of logical certainty [203]. In the context of the GS paradigm, which prioritizes rigorous clinical reliability, such actions are not merely optional channels for information acquisition but serve as the cornerstone providing dual logical-semantic grounding for the entire cognitive process [108]. When the GS faces complex clinical scenario that requires multi-step, cross-concept deduction, such as crossreferencing symptoms with rare disease etiologies or analyzing potential adverse drug events, it generates formal query sequence through its strategic planning layer. This sequence traverses specific logical path on an external medical knowledge graph [27, 263]. Since the structure of these graphs is composed of nodes representing standardized medical entities and edges representing expert-defined patho-physiological relationships [203], it inherently constitutes Manuscript submitted to ACM 26 Zhi et al. an axiomatic logical skeleton. Each action performed by the agent becomes an independent, formally verifiable logical operation on this skeleton [306]. Consequently, complex diagnostic reasoning chain is decomposed into series of atomic, auditable transactions [306]. This mechanism not only renders every intermediate step of the final conclusion transparent and verifiable but, more importantly, establishes complete computational provenance trail for the entire cognitive process, which is critical requirement for the validation and regulatory approval of clinical decision support systems. Furthermore, the schema of the GSs knowledge base functions as robust cognitive guardrail [301]. By providing strict semantic and type constraints for the agents inquiries, the schema imposes strong domain-specific inductive bias. This mechanism effectively mitigates the risk of conceptual confusion and relational hallucinations often caused by natural language ambiguity [60]. For instance, while standard language model might statistically associate symptom with biologically implausible drug side effect based on text co-occurrence, strict medical ontology prevents such invalid logical leaps by enforcing predefined inheritance hierarchies and domain constraints [48]. This ensures that the agents cognitive outputs remain rigorously aligned with established medical truths at the ontological level. Search engine based. Search engine-based actions are primarily employed by the agent to explore the vast, unstructured knowledge frontier, encompassing extensive medical literature, clinical trial reports, conference abstracts, and real-time public health guidelines [55, 233]. Within the GS architecture, the strategic value of these actions lies in enabling dynamic adaptation to evolving knowledge, thereby addressing the inherent limitations of structured knowledge bases regarding coverage breadth and, critically, the timeliness of recent research advances [211]. However, integrating web-scale data introduces significant cognitive challenge: preserving reliability when navigating noisy, ambiguous, and potentially biased free text. To address this, the GS paradigm redefines search engine usage not as simple information retrieval, but as highly proceduralized process of dynamic evidential boundary construction. Rather than treating the search engine as an oracle that delivers direct answers, the agent positions it as provider of contextual evidence [97]. The core of this action execution consists of rigorous three-stage workflow: forage, constrain, and attribute. In the forage stage, the agent avoids executing one-shot query aimed at directly hitting an answer. Instead, it emulates the methodology of professional researcher conducting systematic review, performing strategic, multiround query sequence to collect comprehensive candidate evidence corpus [233]. This process is designed to ensure that the collected text snippets cover diverse aspects of the clinical question, including potential treatment controversies, varying clinical guidelines across regions, and the latest findings from ongoing trials. By systematically aggregating multi-faceted information, the agent constructs robust evidence base that mitigates the risk of bias inherent in single-source retrieval. The constraint stage represents the critical safety juncture of the process. All text snippets retrieved, along with their complete metadata, are injected into the non-parametric memory to construct temporary, disposable knowledge base that is strictly firewalled from the LLMs internal parameters [305]. Subsequently, the model is instructed to perform cognitive operations exclusively within this isolated context composed entirely of external evidence. This mechanism achieves strict contextual grounding, effectively transforming the nature of the LLMs task from open-domain question answeringwhich relies on vast but potentially hallucinatory internal weightsto highly constrained task of grounded text synthesis. This shift significantly reduces the risk of generating clinically unsafe advice, as the model is structurally prevented from citing any knowledge beyond the boundaries of the provided evidence [43]. Finally, in the attribute stage, when the LLM generates summary or recommendation based on this isolated knowledge, it is mandated to provide fine-grained citation pointer for every factual assertion. These pointers link directly back to the specific source text snippet in the non-parametric memory [249]. This achieves programmatic Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 27 attributability, ensuring that the final output is not monolithic block of text but composite structure of assertions and their corresponding proofs. In clinical setting, this design enables healthcare professionals to instantly verify the source and reliability of every piece of information, establishing transparent and auditable decision support process that balances the flexibility of unstructured data with the rigor required for medical safety. Tool-use. Tool-use represents the action modality with the highest cognitive certainty within the GS paradigm. It specifically entails the programmatic invocation of external, validated computational modules to execute precise clinical functions that lie beyond the stochastic capabilities of language models. These include deterministic applications such as drug dosage calculators [65], clinical risk stratification scores [330], and pharmacokinetic simulation engines. By strictly delegating these tasks, the agent achieves indispensable procedural grounding [125], ensuring that the systems operational behavior remains predictable and compliant with rigorous clinical standards. From an architectural perspective, these tools function as algorithmic oraclesaxioms within the cognitive process that encapsulate validated clinical logic. This approach embodies the principle of cognitive liability offloading [245]. The core design philosophy posits that any clinical task definable by deterministic algorithm or fixed mathematical formula must be strictly offloaded from the LLMs probabilistic cognitive space to specialized external tool [65]. This distinction stems from critical recognition of the LLMs capability boundaries: while powerful in semantic understanding and fluent generation, they lack the symbolic reasoning required for precise calculations or strict adherence to procedural guidelines. Consequently, by executing tool call, the agent facilitates programmatic inheritance of authority. The credibility of the output is not derived from the models internal intelligence but is directly inherited from the clinical validation embodied by the tool itself [138]. This replaces vulnerable link in the decision chainan opaque, probabilistic text generatorwith deterministic module that yields consistent, verifiable results. Under this framework, the LLM is redefined as universal orchestrator of semantic interfaces. Its primary responsibility shifts to accurately parsing the clinicians natural language intent, mapping it to the appropriate function, and integrating the structured output back into the dialogue, without needing to process the internal logic of the tool [206]. This design pattern significantly enhances system robustness, constructing modular AI architecture with clear liability boundaries that align with the safety-first objectives of the GS paradigm. 3.3.4 Collaboration. Within the GS paradigm, the concept of collaboration is reframed conceptually. Unlike goaloriented agents engaging in peer-to-peer negotiation, the GS agent functions within strictly asymmetric human-agent partnership aimed at cognitive augmentation [251]. Since the agent lacks the agency to alter patient states directlysuch as prescribing medication without approvalits role is confined to that of an advanced cognitive tool. Collaborative behaviors focus on enhancing the situational awareness of clinicians by presenting structured, verifiable evidence rather than acting as an autonomous participant in the decision-making process. Consequently, the core value of this paradigm lies in the reliability with which the agent supplies grounded information to support the human medical cognitive process [30]. Single-agent system. The single-agent architecture represents the native implementation of the GS paradigm, designed to construct singular, internally consistent clinical snapshot. In this model, the solitary agent acts as centralized information orchestrator, executing optimal inquiry pathways across heterogeneous sources, such as PubMed abstracts or patient histories. Since the objective is to complete highly focused cognitive synthesis tasksuch as summarizing discharge note or answering specific drug interaction query [43, 194]a single control core offers the most direct method to maintain logical consistency. This alignment with conservative, safety-first philosophy is crucial in medicine. Manuscript submitted to ACM 28 Zhi et al. However, as the volume and technical heterogeneity of external sources increase (e.g., combining genomic databases with unstructured nursing notes), the maintainability of this monolithic architecture faces significant engineering challenges [161], necessitating shift toward more modular organizational forms. Multi-agent system. Introducing MAS under the stringent constraints of the GS paradigm differs greatly from the emergent reasoning sought in LSC or the autonomous negotiation in EP. Instead, it represents systems engineering strategy designed to handle the complexity of heterogeneous medical data through functional cognitive division of labor. By assigning specialized agents for specific data modalities, such as one for radiology report extraction and another for clinical guideline retrieval, GS enhances the scalability and auditability of the evidence-gathering process. The dominant topology in this context functions strictly as verifiable evidence aggregation hub rather than consultation team. unique orchestrator agent acts as the absolute center, responsible not for synthesizing novel ideas, but for managing the logistics of multi-source retrieval [161]. For instance, it decomposes complex clinical query and dispatches specific fetch-tasks to worker agentsone accessing drug interaction databases and another retrieving patient historybefore rigorously compiling their structured outputs [37]. The primary advantage of this topology in GS is absolute auditability. By forcing all external information flows to pass through single control node, the system maintains global view of the evidence chain, ensuring that every piece of integrated data is traceable and preventing the hallucinated consensus that can occur in less constrained interactions [32]. Conversely, the distributed topology adapts the concept of clinical care pathways into deterministic data flow pipeline. Unlike the peer-to-peer negotiation characteristic of goal-oriented agents, collaboration here is governed by fixed cognitive workflow graph, typically directed acyclic graph [251]. Each node represents dedicated processor rather than decision-maker. For example, \"symptom extractor\" passes raw entities strictly to \"differential diagnosis filter\" for validation [52]. The collaboration is driven by the rigid flow of clinical data itself rather than dynamic mediation [29]. This structure is particularly effective for standardizable, multi-stage tasks like automated chart review, where the output of one specialist module serves as the immutable input for the next, ensuring execution adheres to medical protocols without deviation [32]. 3.3.5 Evolution. Distinct from paradigms that aim to enhance autonomous decision-making capabilities or update an internal world model through experiential learning, evolution in the GS framework focuses on optimizing the agents efficacy as cognitive tool [194]. This evolution is meta-cognitive and procedural, with its core objective being the refinement of \"how to cognize better\" rather than altering the factual basis of \"what to cognize\" [65]. Consequently, evolution is confined to safe and controllable trajectory, primarily realized through three interconnected mechanisms: the optimization of inquiry strategies, the refinement of action policies, and the human-driven expansion of knowledge boundaries. Inquiry pathway optimization represents the macro-evolutionary adaptation of the agent, targeting its strategic planning module. The core objective is for the GS to learn how to construct more efficient and clinically relevant inquiry pathways through experiential learning derived from its interactions [29]. Critically, this learning process is decoupled from clinical outcome feedback to prevent the agent from assuming decision-making responsibilities beyond its scope. Instead, the feedback signal for policy refinement is predicated on metrics of cognitive efficiency, such as the diagnostic information gain per query [194]. For instance, through the offline analysis of interaction logs, the system identifies inquiry patterns that most frequently yield comprehensive clinical snapshot with the minimum number of query stepsa principle mirroring the self-learned knowledge generation in multi-agent diagnostic frameworks [130]. Alternatively, this can be framed as reinforcement learning problem where the policy is refined using reward signals Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 29 such as maximizing the information adoption rate in human decision-making. This evolution enhances the agents utility as sophisticated information-provision tool without compromising safety. Operating at micro-technical level, action policy refinement focuses on the efficiency of action execution when interacting with external medical sources [264]. Every external tool or databasewhether PubMed search API or hospital EHR systempossesses unique operational characteristics, including specific query syntax, rate limits, and data format nuances. Action policy refinement enables the agent to adapt to these interfaces. For example, by analyzing cases of query failure, the agent acts as procedural learner, discovering that mapping user queries to MeSH (Medical Subject Headings) terms yields significantly higher retrieval success rate than free-text queries in biomedical databases [212]. Similarly, it can learn to adopt resilient calling strategies, such as automated retries or timeouts, when invoking slow-responding legacy EHR interfaces. By building an internal policy model on how to effectively converse with specific tools [65], the agent evolves from novice interface user [138] into proficient technical expert. This results in robust data acquisition layer that minimizes cognitive interruptions caused by technical friction. Human-in-the-Loop knowledge boundary expansion represents the most unique form of evolution within the GS paradigm [33], embodying the agents role as collaborative partner in human-machine cognitive community [78]. The agent is prohibited from autonomously updating the external knowledge bases on which it relies. However, when the agent repeatedly fails to retrieve an answer to specific clinical question from authoritative sources during an inquiry pathway, it records this evidence gap as structured event. These aggregated gaps form valuable, demanddriven knowledge list that is submitted to human experts and clinical knowledge engineers [49]. This feedback loop points human maintainers toward areas where clinical guidelines or databases require prioritization for expansion and updating [285]. Thus, symbiotic relationship is established: the agent exposes the boundaries of current medical knowledge through efficient inquiry, and human experts expand these boundaries, which in turn enhances the agents future capabilities. This indirect, human-centered evolutionary path ensures that the system remains safe and reliable cognitive-assistive tool. 3.3.6 Summary. The GS paradigm conceptualizes conservative agent functioning strictly as verifiable clinical decision support tool, which anchors its entire epistemic process in external sources to produce transparent synthesis of the clinical situation. Characterized by an unwavering commitment to explicit grounding, this paradigm effectively mitigates factual hallucinations by constructing cognitive conclusions upon an auditable chain of evidence [187], prioritizing patient safety and source traceability over generative creativity. However, this strict reliance on retrieved knowledge introduces critical trade-off: while ensuring high trustworthiness, it significantly constrains the agents flexibility in addressing novel or undocumented clinical scenarios compared to paradigms leveraging implicit latent knowledge. Consequently, the primary research frontier lies in overcoming retrieval bottlenecks that limit synthesis quality [55], managing the execution latency of complex multi-hop reasoning in time-sensitive acute care settings [27], and solving the logistical imperative of maintaining the continuous currency of the external medical knowledge bases upon which the agent depends [108]. 3.4 Verifiable Workflow Automator The VWA represents paradigm in which the LLM serves as an intelligent natural language interface that drives deterministic, protocol-based process engines. Distinct from the open-ended planning of EPs, VWA agents operate by strictly adhering to explicit clinical guidelines and verifiable workflows to ensure maximum safety and predictability, as depicted in Fig. 9. This approach balances the need for active clinical intervention with the requirement for rigorous Manuscript submitted to ACM 30 Zhi et al. algorithmic control. Table 6 provides comprehensive summary of methodologies categorized under this high-stakes execution framework. Agentic Approach VITA[110] Quicker[126] LLM-AMT[261] MedPlan[83] EMRs2CSP[39] Table 6. The summarization of VWA agentic approach, \"PT\" represents pre-training and fine-tuning, \"PE\" represents prompt engineering, \"MAS\" represents multi-agent system, \"RL\" represents reinforcement learning, and \"ST\" represents self-training. Framework Type PE PE PE PE PT PE RL PE PE RL MAS MAS ST ST Main Corresponding Component Planning Strategies Planning Strategies Planning Strategies Planning Strategies Memory Management Medical Graph RAG[275] Memory Management Memory Management Action Execution Action Execution Action Execution Collaboration Collaboration Self-evolution Self-evolution Detailed Method Relevant-visit selectIon Evidence Synthesis Query Augmenter Reasoning Structurizing Clinical Representation Knowledge Retrieval Tracebale Knowledge Reasoning Task-specific Retrival Synonym System Calculator Tool-use Shared Mental Model Thematic Analysis Tool-use Strategy Meta Learning Downstream Task Recommendation Recommendation Biomedical QA Task-oriented Medical QA Medical QA Task-oriented Task-oriented Task-oriented Task-oriented Medical QA Task-oriented Task-oriented Task-oriented Deep-DxSearch[320] Cli-RAG[105] Tala-med[8] PPME[228] TeamMedAgents[167] TAMA[285] HealthFlow[329] MetaAgent[185] Fig. 9. General structure of single agent in the VWA paradigm. Strategic planning maps the current patient state to nodes within pre-defined clinical workflow. Action execution employs knowledge-based actions to preprocess clinical data, search engines for programmatic validation, and strictly offloads high-stakes tasks to usable tools. Non-parametric memory maintains verifiable log of these executed actions for state tracking, while parametric memory acts as query engine to translate intents into precise tool calls. Core differences from other paradigms are covered with red blocks. 3.4.1 Strategic Planning. Strategic planning within the VWA paradigm operates as dual-process mechanism, synergizing decomposition and iteration to systematically navigate predefined clinical workflows [110]. Unlike the EP paradigm, which leverages the implicit intuition of LLMs for open-ended reasoning, the VWA focuses on strict adherence to verified clinical protocols [106]. In this framework, the decomposition strategy functions as structural anchor, translating high-level and often ambiguous clinical objectives into concrete sequence of verifiable sub-tasks [47]. Subsequently, the iteration strategy acts as dynamic execution engine, determining the optimal policy to traverse this established path through mechanisms such as closed-loop feedback [129]. This synergy ensures that the agents behavior remains autonomous in execution while being strictly verifiable in its logic, balancing the need for efficiency with the rigorous safety standards required in healthcare [76]. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 31 Decomposition strategies. Within the VWA framework, the decomposition strategy is principally structured mapping task anchored in external clinical knowledge. Rather than generating novel plans from scratch, the core objective is to align the current patient state with verified clinical workflow [110]. This relies on high-quality, structured knowledge bases derived from real-world medical data, such as clinical status pathways mined from electronic medical records [39] or hierarchical decision trees parsed from authoritative guidelines [47]. By standardizing the workflow into key nodes that range from problem decomposition to evidence evaluation, this approach ensures that the agent identifies the precise, protocol-compliant step within complex environment, thereby satisfying the critical medical need for standardization [126]. Operationally, this strategy mirrors the logic of clinical fact-based inferential rules, which decouple reasoning into fact verification and inferential reasoning [299]. Initially, the agent acts as an information processor, employing techniques akin to RAG to transform unstructured patient dialogue into structured clinical facts. To handle clinical ambiguity, complex inquiries are systematically broken down into standardized elements using models like PICO (population, intervention, comparison, outcome) [126, 261]. Leveraging the foundational reading comprehension of LLMs [221], the agent then utilizes these verified facts to perform inference against the external workflow, decomposing high-level goals into specific, executable sub-tasks. This decoupling renders each step of the clinical decision-making process transparent and evidence-based. However, addressing the inherent uncertainty of clinical interactions requires dynamic adaptation. The agent must effectively handle incomplete information by proactively initiating information-seeking behaviors rather than making probabilistic guesses and asking clarifying questions to bridge data gaps [129]. Furthermore, to mitigate risks associated with patient misreporting [186], the strategy incorporates pre-verification module that assesses input consistency before mapping. Crucially, strict safety boundaries are enforced. If patients condition falls outside the predefined workflow distribution, the agent halts execution to signal human intervention [76]. This cautious handling ensures that autonomy does not exceed the verifiable knowledge base [106]. Advanced implementations elevate this strategy to expert-level simulation, evolving into graph of thought processes where the agent navigates graph of logical sub-tasks [14]. By emulating the sequential cognitive process of physiciansassessing, diagnosing, and then planning [83]the strategy breaks down grand clinical tasks into concrete steps compliant with medical logic. The distinguishing characteristic of this approach is its path-following nature: whereas EP agents focus on discovering path through open-ended reasoning, VWA agents focus on selecting the correct path from pre-verified map, prioritizing safety and auditability over creative planning. Iteration strategies. Within the VWA framework, the iteration strategy serves principally to perform efficient adaptive navigation along predefined, verifiable clinical pathway. Unlike the EP paradigm, which relies on divergent planning, VWA iteration addresses the operational challenge of determining how the known next step can be best executed, given patient variability [112]. This process first functions as closed-loop locate-and-correct mechanism. In clinical practice, patient descriptions are often unstructured and ambiguous, making direct mapping to workflow nodes difficult. To resolve this, agents utilize feedback from tool retrievals to pinpoint their precise location within the protocol. The RGAR framework embodies this by iteratively querying between factual knowledge and conceptual data to accurately align ambiguous clinical objectives with specific workflow paths [137], effectively turning the process into precision pathfinding on known map. To enhance diagnostic efficiency, advanced strategies incorporate reinforcement learning for path policy optimization. Here, the clinical workflow is treated as the environment in which the agent learns to minimize diagnostic costssuch Manuscript submitted to ACM 32 Zhi et al. as reducing unnecessary interaction turnswhile maximizing accuracy. Systems like Deep-DxSearch employ endto-end RL to train agents in making optimal sequential decisions within retrieval-reasoning interleaved workflows [320]. Similarly, optimization techniques have been applied to refine retrieval strategies in unsupervised environments [286] and to determine optimal regimens for personalized treatments, such as H. pylori eradication [79]. Furthermore, this strategy supports cross-task continuous learning, enabling agents to evolve their navigation policies over time from incremental data streams, thereby ensuring that the systems handling of specific cases improves with historical experience. In scenarios involving complex comorbidities, the iteration strategy evolves into hierarchical and collaborative cyclic execution. complex clinical process is modeled as multi-stage collaborative graph where, if the initial information is insufficient, the system initiates subsequent iterations to delegate specific examination sub-tasks while strictly adhering to preset information flow paths [181]. Concurrently, microscopic iteration ensures robustness at the reasoning level, as seen in the HAR network, which dynamically adjusts attention weights on KGs based on downstream feedback [248]. By employing risk control frameworks like RULE to filter retrieved information [281], these cycles ensure rigorous adherence to protocols. The key difference distinguishing this module is its focus on executional optimization. Whereas EP agents iterate to generate plausible plans, VWA agents iterate to optimize the accuracy and efficiency of traversing fixed, verifiable clinical map. 3.4.2 Memory Management. In the VWA paradigm, memory management transcends the simple recall of conversational history. It is the critical mechanism for maintaining the state, consistency, and traceability of multi-step clinical workflow. The agents memory system is not merely passive repository but an active component that underpins its ability to execute complex procedures in grounded and reliable manner. It ensures that each action is contextually appropriate, informed by prior steps, and anchored to verifiable information. Parametric memory. In the VWA paradigm, parametric memory functions principally as sophisticated semantic processing unit rather than as the ultimate source of clinical truth. Its primary role is to provide the foundational linguistic capabilities required to parse complex medical terminology and translate user instructions into precise actions for external execution. While generalist models possess substantial inherent clinical knowledge, benchmarks such as M-QALM reveal that this internal memory is often prone to gaps and inconsistencies compared to human experts, particularly when lacking domain-specific fine-tuning [221]. Consequently, the VWA framework strategically repurposes this memory. It is necessary for understanding the medical context, but insufficient for asserting facts. This operational philosophy is exemplified in frameworks like EMRS2CSP, where the pipeline relies on parametric memory not to hallucinate patient status, but to leverage its internal grasp of sequential clinical logic to decompose unstructured electronic medical records into verifiable clinical status pathways [39]. Here, the models latent knowledge serves strictly to navigate the syntax of medical documents, demonstrating how parametric memory enables the execution of structured sub-tasks without becoming the factual authority. Similarly, unified evaluation protocols like PIPA highlight that an agents ability to maintain state consistency throughout an interaction depends on using parametric memory to track the dialogue flow and evolving clinical requests [112]. In these roles, parametric memory acts as short-term operational buffer that bridges the gap between natural language and long-term, verifiable nonparametric knowledge stores. Unlike the LSC paradigm, which treats parametric memory as an open clinical knowledge base, the VWA restricts it to the role of semantic controller for external tools, prioritizing procedural correctness over generative creativity. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 33 Non-parametric memory. Non-parametric memory constitutes the external, explicit, and auditable information sources that form the bedrock of the VWAs reliability. Unlike the associative memory of the human brain, this component serves as the verifiable aspect of the paradigm, strictly categorized into static long-term repositories and dynamic short-term state logs. First, static long-term memory functions as the repository of clinical axioms, providing the immutable ground truth for workflow execution. To ensure evidentiary traceability as non-negotiable requirement in clinical audits, frameworks like Medical Graph RAG construct KGs that explicitly link retrieved clinical information to source documents and formal definitions [275]. Similarly, MedRAG utilizes hierarchical diagnostic KGs to retrieve distinguishing features between diseases, anchoring the reasoning process in structured ontology rather than in probabilistic generation [319]. Beyond symbolic graphs, handling high-dimensional clinical data requires vectorized representations. Systems like CardioTRAP [70] and CLI-RAG [105] utilize vector stores of EHRs as their primary memory, where every retrieval action constitutes an explicit, loggable query to this verifiable repository. More specialized implementations, such as HI-DR, enhance this concept by structuring the knowledge base as weighted, directed EHR graph+ to accurately model the asymmetric nature of drug co-prescription relationships [111]. This ensures that the agents medication recommendations are governed by strict pharmacological rules rather than statistical likelihood. Conversely, dynamic short-term memory serves as the active clinical state register, explicitly tracking the trajectory of the current session. This capability is critical for multi-turn diagnostic workflows where the patients status evolves with every interaction. The Deep-DxSearch framework formalizes this by defining the systems state at any step as the complete history of prior actions and environmental feedback, serving as the explicit input for reinforcement learning policies [320]. This sequence acts as verifiable log of the reasoning trajectory, allowing for retrospective error analysis. Addressing the specific clinical challenge of unreliable narrators, the Listening to Patients framework constructs real-time dialogue entity graph [186]. This graph functions as structured working memory that the agent consults to detect inconsistencies or mitigate patient misreports during history taking. Furthermore, methods like KPL extend this verifiability to multimodal data by externalizing implicit visual cues from VLMs into retrieval-based text store [141]. 3.4.3 Action Execution. In the VWA paradigm, action execution transforms abstract workflow steps into concrete, auditable operations grounded in clinical evidence. This is achieved through three interconnected modalities, each addressing specific dimension of medical reliability. Its foundation is knowledge-based execution, wherein agent actions are defined as precise queries over structured databases, ensuring every inference is anchored in pre-vetted sources [319]. To integrate real-time information, the search engine functions as programmatic evidence acquisition node where the LLM generates optimized queries and validates retrieved data, creating mandatory evidence chain with clear provenance [55, 211]. Finally, tool-use endows the VWA with the capability to delegate specific clinical taskssuch as risk calculation or image analysisto deterministic external tools, ensuring operational precision beyond the stochastic nature of LLMs [73, 262]. Regardless of the modality, the defining characteristic of VWA action execution is that every operation is explicit, traceable, and evidence-backed, guaranteeing end-to-end safety in automated workflows. Knowledge-based. The core principle of this modality involves preprocessing unstructured clinical data into structured, machine-queryable knowledge bases[316]. During workflow execution, the agents actions are strictly defined as retrievals and inferences over these bases, ensuring that operational steps are grounded in verifiable evidence rather than generated from latent parameters. Early approaches leveraged RAG techniques to transform EHR data into vector databases, supporting specific clinical tasks. The CardioTRAP system exemplifies this by constructing specialized vector database for cardiology EHRs to Manuscript submitted to ACM 34 Zhi et al. manage complex, multidimensional biomedical data [70]. Within this framework, workflow actions (e.g., patient risk stratification) are anchored to specific evidence retrieved from vectorized records, demonstrating outcome verifiability. To enhance retrieval precision in generating structured clinical documentation like SOAP notes, the CLI-RAG framework introduces hierarchical chunking mechanism [105]. This design allows the agent to first globally identify relevant note types and then perform fine-grained content extraction, respecting the intrinsic structure of clinical documents and rendering the automated generation process interpretable. However, simple entity co-occurrence often fails to capture complex clinical relationships, necessitating structurally refined knowledge bases. Addressing this, the HI-DR framework constructs an EHR graph+ where directed edges are weighted by the degree of medication co-prescription, capturing asymmetric dependencies between drugs to improve the safety of recommendation actions [111]. Furthermore, to bridge the gap between information retrieval and diagnostic reasoning, advanced agents interact with formalized medical KGs [44]. The MedRAG framework employs four-tier hierarchical diagnostic KG to capture differential features between diseases [319]. Here, the agents action shifts from simple retrieval to querying the KG for distinguishing features, actively guiding the diagnosis. Similarly, Medical Graph RAG links user data with authoritative literature to form traceable evidence triplets, enhancing workflow trustworthiness [275]. Beyond text, sources for these knowledge bases have diversified to include multimodal data. The KPL framework utilizes knowledge proxy learning to distill implicit visual cues from large vision-language models into explicit textual descriptions [141]. The agents classification action then queries this structured base, effectively converting implicit foundation model knowledge into verifiable resource. Ultimately, the frontier of this domain advances toward end-toend policy learning. Frameworks like Deep-DxSearch formalize diagnosis as reinforcement learning problem where the agents action space consists of well-defined stepsreason, lookup, match, diagnosisexecuted within large-scale retrieval corpus [320]. Search engine based. Within the VWA paradigm, the utilization of search engines presents distinct methodological shift, transcending the passive information retrieval typical of the GS framework to address the specific deficits of implicit knowledge in clinical settings. As clinical practice indicates, directly utilizing original patient queries often yields suboptimal results due to the semantic gap between non-standardized lay descriptions and precise medical terminology [55]. To bridge this gap, the LLM within the VWA workflow functions as critical context-aware query generator. Inspired by advanced methods such as SearchRAG [211], the agent acts as clinical translator, decomposing complex medical scenarios into syntactically varied synthetic queries. These optimized instructions are designed to capture latent clinical intents with greater precision, effectively mapping patient narratives to standardized medical indices and significantly enhancing the recall of high-quality guidelines. Subsequently, the execution phase transforms the search engine from generic tool into programmatic evidence acquisition node. These optimized queries are routed to distinct targets, ranging from public indices to professionally engineered, domain-specific information retrieval systems like Tala-med [8]. Such specialized engines, utilizing modular architectures and synonym expansion, offer information sources of significantly higher relevance than general-purpose counterparts. Furthermore, this conceptualization lays the groundwork for distributed agent networks, where the search engine serves as core nexus for discovering specialized services [171]. Upon retrieval, the LLM activates its second critical role as structured validator. It is responsible for parsing unstructured text returns and executing programmatic validation step, often employing mechanisms based on information entropy to assess the contribution of each snippet to decision confidence. This ensures that only high-value evidenceverified against reliability metricsis incorporated into the workflow, effectively filtering out the noise inherent in web-scale health data. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication The ultimate value of this paradigm lies in its establishment of mandatory transparency mechanism. By mandating that every decision step be linked to specific literature or data points returned by the search engine, the VWA creates verifiable and auditable trail. This structured methodology addresses the critical issue of end-user over-trust in opaque search rankings, which often exacerbates health anxiety in online information-seeking scenarios [278]. Through this approach, the search engine is transformed from static repository into dynamic component of clinical decision support, ensuring that automated workflows are founded upon traceable medical evidence. Tool-use. Whereas search engines provide the informational context, tool-use endows the VWA with the operative capability to execute concrete, non-linguistic clinical tasks with mathematical precision. Within this framework, tool-use is strictly defined as the programmatic invocation of deterministic external modules to offload high-risk computations from the probabilistic LLM, including pharmacokinetic calculators and expert systems. Primarily, the LLM functions as an intelligent clinical orchestrator, translating high-level medical intent into specific machine instructions [228]. For instance, in data-intensive scenarios, the agent converts natural language inquiries into executable structured query language for EHR databases. This mechanism is critical for patient safety, as it enables automated, error-free access to complex medical histories without the risk of hallucinating data points inherent in direct text generation [232]. By entrusting specialized tasks to reliable, rule-based tools while reserving the LLM for comprehension and planning, recent studies have demonstrated that such autonomous systems can achieve diagnostic accuracy comparable to board-certified clinicians with minimal safety violations, validating the VWA paradigm in real-world settings [73]. Beyond simple calculation, the scope of tool-use extends to an ecosystem of specialized clinical agents that simulate multidisciplinary medical environment. In this advanced configuration, tools are conceptualized as distinct expert modules. For example, during simulated consultation, the central LLM acts as physician who proactively requests findings from dedicated measurement agent capable of interpreting ECGs or medical imaging, thereby mirroring the referral logic of real diagnostic processes [9]. This interactive capability is further augmented by integrating clinical experience models, which optimize information-gathering strategies to enhance diagnostic precision during the initial phases of care [228]. Furthermore, to address the challenge of diagnostic bias, advanced VWA systems orchestrate tool agents to engage in collaborative reasoning, utilizing specific \"critic\" agents to challenge premature consensus. This engineered disruption of silent agreement fosters deeper critical thinking and improves robustness in complex cases [262]. Additionally, tool invocation spans training domains, where agents drive virtual reality simulations for customizable clinical communication practice [328]. 3.4.4 Collaboration. In the VWA paradigm, collaboration serves as computational mirror of the rigid hierarchical interactions found in hospital operations. Unlike the emergent negotiation seen in EP, VWA collaboration is strictly governed by predefined clinical protocols, ensuring that the progression of multi-step tasksfrom triage to treatment planningadheres to the standard of care. The LLM acts not merely as participant but as the protocol enforcer, facilitating cooperation that prioritizes reliability and patient safety over creative consensus. Single-agent system. Conceptually, this architecture functions as digital general practitioner executing sequential checklist. Collaboration here is vertical and unidirectional: the agent interacts with series of external knowledge modules rather than with peer agents. For instance, the workflow might dictate calling guideline database to retrieve sepsis protocols, then querying search engine for drug interactions, and finally executing tool action to update the EHR. The agent serves as the sole active execution unit, with its collaborative scope strictly confined to the pre-configured logic of the clinical toolchain. Manuscript submitted to ACM 36 Zhi et al. Multi-agent system. To handle the complexity of specialized medicine, the multi-agent architecture simulates the division of labor inherent in hospital environment. This is predominantly realized through dominant topology, analogous to an \"attending physician\" model. Here, central router agent governs the patients journey, maintaining strict supervision over the entire workflow to ensure auditability. In the MAKAR framework, this router assesses clinical criteria complexity before dispatching sub-tasks to specialized knowledge-enhancement modules, effectively simulating referral to specialist [207]. Similarly, TeamMedAgents employs recruiter agent to dynamically assemble an MDT based on the case profile [167], while ClinicalAgent utilizes patient navigator to manage the end-to-end process from triage to consultation [292]. Crucially, this centralized control mitigates the optimization paradox where individually high-performing specialists fail to produce cohesive treatment plan due to poor coordination [45]. Alternatively, the distributed topology models the linear progression of clinical care pathway. In this structure, there is no central bottleneck; instead, agents engage in peer-to-peer handoffs based on shared protocols, simulating the transfer of patient between departments (e.g., from the ED to Radiology). The TAMA framework illustrates this with strict pipeline model where an agent, upon completing task like symptom extraction, directly passes the structured output to reasoning agent according to preset rules, without central mediation [285]. This topology can also incorporate distributed self-correction mechanisms, as seen in TeamMedAgents, where agents monitor peer performance and trigger error corrections based on medical logic [167]. The key difference distinguishing VWA collaboration is its nature of protocol-driven orchestration: whereas EP agents collaborate through negotiation to resolve ambiguity, VWA agents collaborate through rigid handoffs to ensure the clinical workflow is executed without deviation. 3.4.5 Evolution. In the VWA paradigm, self-evolution transcends the unconstrained internal knowledge updates typical of implicit navigation models, manifesting instead as highly structured process of meta-level strategic learning. This mechanism parallels the concept of clinical quality improvement in healthcare, where the objective is not to alter the physicians foundational medical knowledge (the model parameters) but to refine the operational protocols, tool-use strategies, and environmental interaction patterns used in practice. By adhering to the principle of learning-by-doing, the agent systematically distills successes and failures from past diagnostic executions into durable, reusable logic to guide future strategy formulation [329]. One primary aspect of this evolutionary process is the iterative optimization of verifiable workflow components. As comprehensive automation framework, VWA employs evolutionary algorithms to refine internal agentic workflows, including the adjustment of clinical prompts and tool configurations [260]. For instance, through meta-tool learning, the agent records and analyzes its interaction history with medical search engines or EHR APIs, thereby autonomously constructing \"procedural knowledge base\" that reduces query latency and improves information recall over time [185]. This optimization is strictly grounded in explicit evaluation principles (e.g., maximizing diagnostic accuracy or minimizing test costs), enabling performance enhancement through low-overhead iterations without requiring substantial manual intervention [297]. Furthermore, by drawing on principles from ensemble learning, VWA evolves superior prompt engineering strategies, such as employing ensemble voting mechanisms to handle biased or ambiguous clinical questions, thereby enhancing the robustness of classification tasks across diverse patient demographics [47]. From broader perspective, the evolutionary mechanism of VWA represents distinct branch of research focused on behavioral adaptation [59]. It emphasizes the adjustment of interaction patterns through reflection on historical case outcomes. This characteristic is vital in complex clinical environments where teamwork is essential. In multiagent collaborative scenarios, an advanced VWA system evolves not just individual competence but also sophisticated collaborative strategies. By observing the dynamics of collective cognition in human-agent hybrid societies, the system Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 37 learns to adapt communication styles and, crucially, to introduce structured dissent. This evolved capability allows the agent to challenge premature consensus within diagnostic team, disrupting silent agreement to stimulate deeper critical reasoning and enhance robustness in complex cases [260]. 3.4.6 Summary. In summary, the VWA paradigm defines clinically conservative approach that prioritizes patient safety and algorithmic accountability by constraining agent behaviors to predefined, auditable care pathways. Its primary advantage lies in providing the high trustworthiness and traceability required for high-stakes medical execution [285], strict operational boundary that distinguishes it from the generative, open-ended planning of the EP paradigm. Furthermore, unlike the GS framework, which focuses on cognitive information synthesis, the VWA is characterized by its commitment to deterministic workflow adherence, effectively transforming the LLM from passive knowledge interface into an active engine for executing standard operating procedures. However, this reliance on explicit structures introduces rigidity when facing undocumented clinical anomalies, and the optimization paradox reveals critical gaps in ensuring holistic agent compatibility within medical teams [45]. Addressing these architectural constraints necessitates rigorous validation standards and specialized engineering resources to ensure that such constrained behaviors are viable in practice. This necessity naturally bridges our discussion to the subsequent systematic review of implementation tools, datasets, and evaluation metrics that underpin the development and assessment of these reliable clinical agents. For clarity, we summarize the key differences of the four paradigms in Table 7. Table 7. Architectural deconstruction of the four agentic paradigms. This table summarizes the distinct technical mechanisms employed by each paradigm across the five core cognitive components. Strategic Planning Memory Manangement Action Execution Cooperation Paradigm LSC EP GS Goal Pattern Goal Pattern Goal Pattern VWA Goal Pattern Decomposition Architect cognition Internal reasoning chain Cognitive self-guidance Cognitive map Logical inquiry path Tree of queries Protocol alignment Node mapping Iteration Ensure consistency Deliberative cycle Dynamic adjustment Self-reflection Gap-filling Info-query loop Adaptive navigation Pathfinding policy Parametric Internalized medical curriculum Implicit weight encoding Strategic intuition Procedural schema Semantic translator Pattern mapping Instruction parser Syntax navigation Non-parametric Context extension Recursive summary Tactical workspace Dynamic log Evidential ledger Auditable trace State register Clinical axioms Knowledge-based Search engine based Tool-use - - - - Logical grounding Structured query Verifiable inference Vector retrieval - - - - - - - - Contextual evidence Forage constrain Programmatic acquisition Query generation Offload calculation Deterministic call Clinical orchestration Algorithmic oracle Dominant Simulating consultation Central orchestrator Meta-planning Task delegation Evidence aggregation Distributed Peer review Multi-round discussion Conflict resolution Data pipeline Hub-and-spoke DAG flow Strict supervision Attending physician Workflow handoff Linear transfer Evolution Prevent forgetting Continual learning Strategy refinement Optimize inquiry Policy refinement Meta-level learning Meta-tool tuning Negotiation Self-repair 4 Benchmark Datasets and Evaluations In this section, we provide detailed overview of the types of clinical dialogue and popular evaluation methods. 4.1 Datasets Researchers have developed numerous benchmark datasets to train and evaluate clinical dialogue agents across diverse communication scenarios. These datasets not only measure model performance but also reflect key tasks and challenges in the field. As comprehensively listed in Table 8, we classify these existing resources into five distinct categories based on core clinical dialogue functions: QA dialogue, task-oriented dialogue, recommendation dialogue, supportive dialogue, and hybrid-function dialogue. This classification clarifies the capabilities targeted by each dataset and supports the selection of appropriate resources for training and evaluation in specific applications. Manuscript submitted to ACM Zhi et al. Table 8. Collection of existing agentic medical dialogue datasets for distinct tasks. Dialogue Type Specific Task Dataset QA Dialgoue Medical Examination Literature-based Comsumer Health & Domain-specific Task-oriented Dialogue Symptom Diagnosis Entity Recognition & Extraction Instruction Following Recommendation Dialogue MedQA[99], MedMCQA[176], cMedQA2[308], CMExam[143],Medbullets[21], HeadQA[239], CasiMedicos-Arg[230], Huatuo-26M[255] PubMedQA[100], CliCR[229], MEDIQA-2019[4], MEDIQA-Ans[201], BioASQ[157], MedC-I[272], Medical Meadow[72] MASH-QA[327], HealthQA[326], webmedQA [74] AfriMed-QA[172], RJUA-MedDQA[98], MedAlign[56], MedCalc-Bench[107], MedHallu[178], MedicationQA[3], JAMA[21], cMedQA2[308] MedDialog[302], DialoAMC[36], MedDG[151], MZ[268], CMDD[140], DX[287], CovidDialog[322], iCliniq[132], Ext-CovidDialog[237], IMCS-21[36], HealthCareMagic[132] Mie[313], GENIA[175], ADE[69], BC5CDR[127], NCBI[51], PHEE[227], MultiCochrane[102], CADEC[103], MedDG[151], NoteCHAT[246],S2ORC[154] MEDEC[6], MedInstruct[312], BianqueCorpus[40], GPT-3-ENS[42], MedNLI[195], MedSynth[165], MeQSum[1], MedSTS[258] DialMed[77], ReMeDi[290], DrugBank[87], CMeKG[244], MIMIC-III[319], TCM[294], PubMed[216],NHANES[50], ProKnow-data[197], MedDG[151], KaMed[26] Supportive Dialogue General Empathetic EmpatheticDialogues[190], efaqa, Iemocap[17], MELD[183], DailyDialog[133], EmotionLines[82], EmoContext[270] Mental Health & Specific Scenario Hybrid Function SUPPORT[169], MTS-dialogue[5], SoulChat-Corpus[41], SMILECHAT[188], ESConv[149], PsyQA[225], EDOS[269], DeepDialogue[114] MidMed[208], MeQSum[1], CHARD[54] ChiDrug[279] MedEval[288], PathText[34], MENTAT[120], MedTrinity[283], MedAlpaca[72] 4.1.1 QA Dialogue. QA dialogue datasets assess the knowledge base and factual accuracy of medical intelligent agents by testing their ability to provide correct answers to user queries. Drawn from medical licensing exams to consumer health questions, these datasets enable comprehensive, multi-dimensional evaluation. Medical examination benchmarks. To quantify the mastery of professional medical knowledge in models, significant body of research has utilized datasets based on national medical licensing examinations. MedQA [99] is prominent example, integrating multiple-choice questions from licensing exams in the United States, mainland China, and Taiwan, which rigorously assesses the breadth and depth of models clinical knowledge. Building on this, MedMCQA [176] collects questions from Indian medical entrance exams, further expanding the geographical diversity of evaluation benchmarks. To address the need for multilingual capabilities, HeadQA [239] provides medical exam questions in Spanish, while CasiMedicos-Arg [230] focuses on the Argentinian medical examination context. Additionally, CMExam [143] and CMtMedQA [293] offer important multiple-choice question benchmarks for medical knowledge assessment in Chinese. Due to their standardized format and definitive answers, these datasets have become standard tools for scientifically measuring the professional proficiency of models. Literature-based QA. This category of datasets aims to evaluate models ability to read, comprehend, and extract key information from unstructured biomedical literature. PubMedQA [100] requires the model to answer \"yes, no, or maybe\" questions after reading PubMed abstracts, directly testing its information verification capabilities. BioASQ [157] presents more complex challenge, often requiring the model to synthesize answers from multiple literature sources. As series of evaluation tasks for medical text understanding and question answering, MEDIQA-2019 [4] and MEDIQA-Ans [201] have advanced the development of models in natural language inference and answer summarization. CliCR [229] focuses on more specialized domain, requiring the model to verify medical claims based on clinical trial reports. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 39 Consumer health and domain-specific QA. In contrast to professional examinations, these datasets are more aligned with the daily health needs of the general public. HealthQA [326] contains large volume of health-related questions from real users. MedQuAD [2] extracts numerous question-answer pairs from authoritative websites such as the National Institutes of Health (NIH). Similarly, webmedQA [74] and Medical Meadow [72] provide rich corpora for general health QA. In more specific domains, MedicationQA [3] concentrates on drug-related questions. To address the issue of model-generated hallucinations, MedHallu [178] was constructed to detect and evaluate such outputs. 4.1.2 Task-oriented Dialogue. Task-oriented dialogue datasets are intended for training and evaluating an agents ability to complete specific clinical or administrative workflows. These dialogues extend beyond single-turn QA, typically involving multi-turn, stateful interactions that require the agent to possess capabilities in contextual understanding, dialogue flow management, and goal-driven action. Simulated consultation and symptom diagnosis. This is the most central scenario within task-oriented dialogue datasets. MedDialog [302] provides massive collection of real-world online conversations between doctors and patients, serving as foundational resource for training simulated diagnostic models. Likewise, datasets such as CMDD [140], DialoAMC [36], MZ [268], and DX [287] offer rich corpora for the online medical consultation scenario. MedDG [151] not only provides dialogue data but also includes explicit diagnostic and recommendation labels, making it more suitable for training end-to-end diagnostic systems. In response to public health emergencies, datasets like CovidDialog [322] and Ext-CovidDialog [237] were rapidly developed for the preliminary screening and consultation of COVID-19. Data from ChatDoctor [132] and iCliniq, also sourced from real online medical platforms, possess high degree of authenticity. Medical entity recognition and information extraction. Accurately identifying medical entities such as symptoms, drugs, and tests from dialogue is prerequisite for task completion. Many classic biomedical named entity recognition and relation extraction datasets provide foundational training for this purpose. Key resources for training an agents slot-filling capabilities include the disease corpus NCBI [51], chemical and disease dataset BC5CDR [127], adverse drug events dataset CADEC [103], adverse drug effects dataset ADE [69], phenotypic information dataset PHEE [227], and medical entity dataset GENIA [175]. Instruction following and note generation. The powerful instruction-following capabilities of modern LLMs have spurred the creation of new tasks and datasets. MedInstruct [312] is large-scale medical instruction dataset covering over 50 task types, designed to train models to serve as capable assistants to physicians. Medical SOAP and MedSynth [165] focus on critical step in the clinical workflow: generating progress notes in the SOAP format. MeQSum [1] provides task for medical dialogue summarization, while MedSTS [258] enhances models understanding of patient chief complaints through semantic similarity matching task. Large corpora such as BianqueCorpus [40] and GPT-3-ENS [42] also support the training of more generalized task-execution capabilities. 4.1.3 Recommendation Dialogue. Recommendation dialogue datasets focus on training agents to provide personalized suggestions, such as recommending suitable drugs, treatment plans, or medical specialists. The challenge in these tasks lies in accurately matching the personalized, unstructured needs expressed by users in natural language with structured medical knowledge bases or large-scale databases. Drug and treatment recommendations. DialMed [77] is representative drug recommendation dialogue dataset that requires the model to recommend appropriate medications based on the users description of diseases and symptoms. The completion of such tasks often relies on robust external knowledge bases, with DrugBank being the most commonly Manuscript submitted to ACM 40 Zhi et al. used source that provides comprehensive drug information. ReMeDi [290] is another dataset that also focuses on drug recommendation. EHR and KG-based recommendations. Complex recommendation scenarios require reference to patients complete medical history. Large-scale anonymized EHR databases, such as MIMIC-III, are goldmine of data for building real-world recommendation tasks, although they are not in dialogue format themselves. Researchers can simulate recommendation scenarios based on the diagnostic, medication, and examination records contained within. Similarly, medical KGs like CMeKG, as well as knowledge bases containing traditional medical knowledge such as TCM [294], provide the structured knowledge necessary for agents to perform reasoning and make recommendations. The MedDG [151] dataset also explicitly integrates dialogue with KGs and can be used for recommendation tasks. Multi-source recommendation. To provide more comprehensive health advice, models also need to integrate broader range of data sources. The vast collection of literature in PubMed can provide evidence for recommending cutting-edge treatment options, while public health data from the NHANES (National Health and Nutrition Examination Survey) database can support recommendations for lifestyle and nutritional supplements. Data from ProKnow-data [197] and the NBME (National Board of Medical Examiners) can also be used to build learning resource recommendation systems for medical students or young doctors. 4.1.4 Supportive Dialogue. Supportive dialogue datasets aim to train agents to exhibit empathy, provide emotional comfort, and offer psychological guidance. In these dialogues, technical precision gives way to humanistic warmth, with the core objectives being effective listening and the provision of appropriate emotional feedback. General empathetic dialogue. As professional psychological counseling dialogue data are extremely sensitive and difficult to obtain, research typically begins with large-scale, general empathetic dialogue data. EmpatheticDialogues [190] is cornerstone dataset in this domain, providing open-domain dialogues annotated with 32 fine-grained emotions. DailyDialog [133] and EmotionLines [82] are also widely used for pre-training models emotional perception and generation abilities due to their rich everyday conversations and emotional expressions. Iemocap [17] and MELD [183] are classic datasets for multimodal emotion recognition, enhancing models ability to capture emotion by combining speech and text. Mental health support. In response to the growing need for mental health support, series of specialized datasets has emerged. PsyQA [225] collects large number of real questions and answers from online mental health communities. SoulChat-Corpus [41] and SMILECHAT [188] are dialogue corpora developed for creating mental health support chatbots in Chinese and English, respectively. ESConv [149] explicitly annotates dialogue strategies to train models on how to provide more effective emotional support. The EDOS [269] dataset focuses on the early detection of suicide risk from social media texts. Specific clinical scenarios. The SUPPORT [169] dataset is landmark work that records serious conversations about end-of-life care among critically ill patients, their families, and physicians, making it an invaluable resource for training agents to handle complex, high-stakes emotional interactions. MTS-dialogue [5] contains motivational interviewing dialogues aimed at motivating patient behavior change. Additionally, cross-domain supportive dialogue data, such as Twitter customer support and DeepDialogue [114], provide references for models to learn generic soothing and problem-solving linguistic patterns. 4.1.5 Hybrid-Function Dialogue. Hybrid-function dialogue datasets are the most complex category and closely simulate the dynamics of real-world clinical interactions. complete physician-patient communication often seamlessly integrates emotional support, symptom gathering, answering patient questions, and ultimately providing diagnosis Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication and recommendations. Such datasets are designed to cultivate and evaluate an agents comprehensive ability to handle dynamic, multi-objective dialogues. Full-process simulated consultation. This type of dataset attempts to fully replicate consultation session from start to finish. MedTrinity [283], through well-designed, multi-stage framework, utilizes LLMs to generate high-quality, full-workflow simulated dialogues that cover multiple stages from initial consultation to health education. Similarly, MedAlpaca [72] is dataset built through instruction fine-tuning, aimed at simulating comprehensive, multi-functional interactions between doctors and patients. MidMed [208] and MENTAT [120] are also dedicated to constructing comprehensive and functionally rich medical dialogue data. Comprehensive understanding and complex reasoning. In complex, lengthy dialogues, the synthesis of and reasoning over information is crucial. The MeQSum [1] dataset requires the model to generate summary for medical QA session, task that inherently integrates the capabilities of question understanding and summary generation. Although CHARD [54] and PathText [34] focus more on the comprehension of complex medical records or texts, the capabilities they cultivate are foundational for handling hybrid-function dialogues. ChiDrug [279] may involve querying, recommending, and explaining traditional Chinese medicine, representing typical hybrid-function scenario. 4.2 Evaluation Metrics The evaluation of LLM-driven clinical dialogue agents presents complex and multidimensional challenge, as it requires not only an assessment of their linguistic capabilities but also measure of their diagnostic reliability, decision-making safety, and interactional efficiency in simulated real-world clinical scenarios [323]. While traditional static benchmarks can gauge models foundational knowledge, they fail to capture the dynamic and interactive nature of clinical workflows [19]. Furthermore, many healthcare applications necessitate the integration of heterogeneous data types, including text, images, and laboratory results, which places higher demands on the evaluation framework. Recent studies have shown that simple accuracy metrics can be misleading, as models may exhibit vulnerability when facing adversarial or counterfactual questions, revealing significant deficiencies in their true diagnostic reliability [291]. Therefore, comprehensive evaluation framework must integrate automated, quantitative standard metrics with custom indicators that focus more on clinical utility, metacognitive abilities, and safety. To facilitate this, we systematically organize and categorize these existing metrics in Table 9. 4.2.1 Standard Metrics. Standard metrics, originating from the fields of NLP and information retrieval, provide baseline for assessing the fundamental linguistic capabilities and information processing accuracy of an agent. Exact match metrics. These metrics are applicable to tasks with definitive, clear-cut answers, such as relation extraction from text or multiple-choice questions. They are commonly used to evaluate model performance on standardized examination benchmarks [19]. Specific metrics include accuracy, precision, recall, and F1-Score. In specialized domains such as biomedicine, however, LLMs may generate responses using synonyms or abbreviations that differ from the gold-standard answers. This causes exact match metrics to fail as they cannot capture semantic equivalence, which is primary reason why human evaluation remains crucial. Content overlap and semantic similarity metrics. These metrics are used to evaluate text generation tasks, such as clinical report generation or diagnostic summarization, by comparing the similarity between the generated text and gold-standard reference. Metrics based on content overlap include BLEU [179], which assesses precision by counting the number of co-occurring n-grams between the generated and reference texts. ROUGE [139] calculates an F1-score based on n-grams, with greater emphasis on recall. METEOR [122] builds upon BLEU by considering synonyms and Manuscript submitted to ACM Zhi et al. Table 9. Collection of existing agentic medical dialogue metrics and evaluation for distinct tasks. Metric Category Specific Application of Metric Standard Metrics Exact Match Content Overlap and Semantic Similarity Language Generation Quality Human Evaluation LLM-as-a-Judge Conversational Efficiency Metrics Clinical Safety and Robustness Custom Indicators Metacognition and Confidence Calibration Attribution and Completeness Name of Metric or Evaluation Accuracy Precision Recall F1-Score BLEU[179] ROUGE[139] METEOR[122] BERTScore[309] MoverScore[318] RadGraph F1[88] Relevancy[310] Fluency[310] Knowledge Correctness[310] FKGL[91] ARI[91] SMOG[91] RSRS[91] SSI[7] AutoMedEval[310] LLM-Judges[121] Task Success Rate[323] Number of Turns[323] Latency[7] Memory Efficiency[7] FLOP[7] Token Limit[7] Number of Parameters[7] Correct Diagnosis Rate[215] Checklist Completion[215] Disparity Amplification[291] Adversarial Robustness[291] Confidence Accuracy[66] Expected Calibration Error[35] Negative Log-Likelihood[35] Statement-level Support[276] Response level Support[276] Citation Recall[282] Citation Precision[282] Claim Recall[282] Claim Precision[282] Relvant Essays Med-PaLM[216], MedBench[19], HuatuoGPT[26], MedBench[19], HuatuoGPT[26], MedAgent[231] MedBench[19], HuatuoGPT[26], MedAgent[231] MedBench[19], HuatuoGPT[26], MedAgent[231] ChatDoctor[132], MedicalGLM[256],SoulChat[41] ChatDoctor[132], MedicalGLM[256],SoulChat[41] ChatDoctor[132], MedDialog[302], HuatuoGPT[26] MedAlpaca[72], Bianque[40] Huatuo[244], Med-PaLM[216], BioBART[300] MEPNet[311], Medical AI Consensus[52] AIME[210], Med-PaLM[216], HuatuoGPT[26] AIME[210], Med-PaLM[216], HuatuoGPT[26] AIME[210], Med-PaLM[216], HuatuoGPT[26] MedReadMe[91], Patient-Friendly Reports[222] MedReadMe[91], Patient-Friendly Reports[222] MedReadMe[91], Patient-Friendly Reports[222] MedReadMe[91], Patient-Friendly Reports[222] MedSentry[32], ConfAgent[317], Safety-Prompt[332] AutoMedEval[310] LLM-Judges[121] AIME[210], MedAgent[231], MeDI-TODER[109] AIME[210], MedAgent[231], MAM[324], Bianque[40] PMC-LLAMA[272], Efficient QA[108] MedAgentSim[9], Recursive Sumarizing[250] BioMedLM[16], Efficient QA[108], FreshLLMs[242] PMC-LLAMA[272], Clinical ModernBERT[124] BioMedLM[16], MedAlpaca[72], TinyLlama[244] AIME[210], ClinicalLab[292], ERNIE Bot[215] ERNIE Bot[215], MediQ[129], Med-PaLM[216] Bias Evaluation[90], HealthFlow[262] Med-PaLM[216], MedSentry[32] MetaMedQA[66], MedConMA[251], Uncertainty Estimation[274] MR[35], MedConMA[251], Uncertainty Estimation[274] MR[35], MedConMA[251], Uncertainty Estimation[274] SourceCheckup[276], SearchRAG[211], HALO[12] SourceCheckup[276], SearchRAG[211], HALO[12] DOCLENS[282], MedRAG[319] DOCLENS[282], MedRAG[319] DOCLENS[282], Atomic Fact Checking[240] DOCLENS[282], Atomic Fact Checking[240] stemming to calculate an alignment-based F1-score. Metrics based on semantic similarity include BERTScore [309], which evaluates the semantic proximity by computing cosine similarity matrix between the BERT embeddings of each word in the generated and reference texts. MoverScore [318] is similar to BERTScore but considers many-to-one word correspondences. In tasks like radiology reporting, RadGraph F1 [88] assesses the accuracy of critical clinical information by comparing the F1-score of entities and relations extracted from both the generated and reference texts. Although widely used, these metrics are limited by the fact that mere textual overlap does not fully reflect clinical correctness. summary with high ROUGE score may still omit critical negative findings or fabricate facts. Conversely, two clinically identical statements can have very low BLEU and ROUGE scores. This highlights the inability of these metrics to effectively capture semantic meaning and clinical context. 4.2.2 Language Generation Quality. These metrics transcend simple lexical matching to focus on the intrinsic logical properties of the agents generated content and its adherence to human language conventions. Initially, this was subjective evaluation dimension dependent on human judgment, but it has since given rise to numerous model-based evaluation methods. Human evaluation. Human experts are asked to rate the quality of the generated content across multiple dimensions. Common dimensions include relevancy, which assesses whether the content is on-topic and answers the users question; fluency, which indicates whether the text is grammatically correct and easy to read; knowledge correctness, which evaluates the accuracy of the medical knowledge contained within the content [310]; and readability, which assesses the ease with which the text can be understood, ensuring that information is accessible to non-professionals. Researchers have developed specialized medical text readability datasets and measured them using classic formulas like FKGL, ARI, and SMOG, as well as model-based metrics like RSRS [91]. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 43 Deeper evaluations include sensibility, specificity, interestingness(SSI) [7], comprehensive extrinsic metric used to assess the overall logical flow and coherence of the generated text, ensuring that the response aligns with human behavior and conversational logic. Sensibility determines whether the models response is logical and understandable. Specificity assesses whether the response is concrete, neither non-committal nor overly general. Interestingness judges whether the response is engaging enough to encourage further interaction. Concise is another key extrinsic metric that evaluates the efficiency and clarity of the models communication, requiring answers to be both brief and direct while avoiding unnecessary verbosity and repetition. This is particularly crucial in medical scenarios where misunderstandings or contextual confusion can have serious consequences. LLM-as-a-judge. In recent years, researchers have begun using advanced language models as proxy evaluators to automate the assessment process. Through carefully designed prompts, powerful LLM is instructed to evaluate the text quality generated by another LLM [121]. The AutoMedEval model, for example, is an open-source evaluation model specifically trained for medical question answering [310]. The validity of such methods is typically confirmed by calculating the Pearson or Spearman correlation coefficient with human expert ratings; high correlation indicates strong agreement. While significantly more efficient, the accuracy of LLM judges in evaluating complex tasks like biomedical relation extraction can be below 50%, indicating need for improved reliability in specialized domains. Various methods aim to ameliorate this; for instance, performance can be significantly improved through structured outputs [121]. 4.2.3 Conversational Efficiency Metrics. These metrics measure the efficiency, resource consumption, and usability of the agent during interaction, which are directly related to user experience and the practical feasibility of deployment. Basic metrics include the task success rate, which measures the proportion of successfully completed clinical tasks and is core indicator of behavioral effectiveness, and the number of turns, which is used to evaluate the average number of dialog rounds required to complete task, where fewer turns typically signify higher efficiency [323]. Additionally, there are metrics related to the operational environment, such as latency, memory efficiency, and computational efficiency [7]. Latency measures the round-trip time from the user request to the response, where low latency is crucial for effective communication and user experience. Memory efficiency quantifies the memory usage of the chatbot, which is vital for deployment on resource-constrained devices, such as mobile phones or embedded systems. Floating-point operations (FLOP) quantify the floating-point operations required for single dialogue instance, serving as key indicator of the models computational efficiency and latency. Furthermore, the models scale also impacts its performance, including the Token Limit, which evaluates the number of tokens the model can process in multi-turn interaction and directly affects its contextual understanding and resource consumption [7]; and the number of parameters, which signifies the models size and complexity, influencing its data processing and learning capacity, as well as its memory and computational requirements [7]. 4.2.4 Custom Indicators. These indicators are closely tailored to specific application scenarios and requirements, relating to the reliability, safety, ethics, and user acceptance of clinical applications. Given the high-risk and specialized nature of the medical field, it is imperative to design custom evaluation indicators that go beyond the scope of traditional NLP and are directly linked to clinical value. Clinical safety and robustness. These metrics directly measure the models clinical performance, ensuring safety and stability when handling clinical tasks. Safety indicators quantify the frequency of unsafe AI behaviors and include metrics such as correct diagnosis rate and checklist completion. The former evaluates whether the AIs diagnosis and prescription recommendations adhere to clinical guidelines [215], while the latter assesses the comprehensiveness of Manuscript submitted to ACM 44 Zhi et al. the AIs inquiry by measuring the coverage of key questions in simulated consultation [215]. Robustness metrics measure the agents adaptability in complex clinical dialogues and are key to eliminating bias. Disparity amplification evaluates whether the AI treats simulated patients of different ages or economic statuses differently. For instance, by ordering more tests for wealthier patients. Adversarial robustness tests the models ability to distinguish fact from falsehood rather than relying on superficial cues by using adversarial question pairs that include one stating fact and the other slightly altered fallacy. Even advanced models may perform below random chance on such probing evaluations [291]. Metacognition and confidence calibration. Metacognitive abilities refer to the models capacity to \"know what it doesnt know,\" which is critical for high-stakes medical decision-making. Benchmarks like MetaMedQA are specifically designed to test this by introducing unanswerable or fictitious questions [66]. Confidence calibration is an important measure of models reliability, with specific metrics including expected calibration error and negative log-likelihood, which measure the consistency between models confidence and its actual accuracy [35]. Attribution and completeness. Attribution metrics evaluate whether each statement generated by the model can be substantiated by its cited literature. Frameworks like SourceCheckup [276] and DOCLENS [282] have proposed fine-grained metrics for this purpose. Statement-level Support reflects the proportion of statements supported by at least one cited source [276]. Response level support indicates the proportion of complete responses in which all statements are supported by citations [276]. Citation recall [282] measures whether each statement is supported by its corresponding citations, while citation precision [282] assesses whether each given citation is necessary and relevant for supporting its corresponding statement. Completeness metrics are used for the fine-grained evaluation of dialogue generation quality by atomically decomposing the answer for comparison. These include claim recall and claim precision, which measure the proportion of key information points from the reference answer that are covered by the generated content, and the proportion of information points in the generated content that are accurate and from the reference, respectively. 5 Real-World Applications The practical application of LLM-enabled agents in healthcare is rapidly evolving, moving from theoretical potential to tangible implementation. To systematically map this burgeoning landscape, we situate current real-world applications within the agentic paradigm framework defined by the orthogonal axes of knowledge and agency. This exercise not only validates the proposed taxonomy by demonstrating its ability to categorize and differentiate existing systems but also illuminates the epicenters of current research and development, while simultaneously revealing nascent frontiers that are yet to be fully explored. By analyzing how current systems populate this matrix, we can discern clear trends in the trade-offs between reliability and creativity, and between safety and autonomy. Application of LSC. The LSC quadrant represents the most accessible and widely explored application of LLMs in medicine to date [94]. These agents primarily leverage the vast, unstructured knowledge embedded within the LLMs parameters during pre-training to function as sophisticated medical consultants. prime example is the use of general-purpose models like ChatGPT to answer board-style examination questions across various specialties, such as pathology [277]. In these scenarios, the agents role is to comprehend clinical query and furnish an accurate, explanatory response, thereby demonstrating its grasp of the clinical context. Its strength lies in its broad, generalist knowledge, making it powerful tool for medical education, preliminary clinical inquiry, and the generation of patient-friendly summaries of complex medical reports. However, because their Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 45 reasoning is not anchored to verifiable external sources, these agents carry an inherent risk of hallucination, posing significant barrier to their direct use in high-stakes clinical decision-making. Application of GS. In stark contrast, the GS quadrant prioritizes reliability and verifiability by anchoring the agents function in explicit, curated knowledge sources [30]. These agents act as intelligent interfaces, translating natural language into structured queries to provide users with reliable, context-aware syntheses of information. The DrBioRight 2.0 [150] system serves as quintessential example, functioning as an LLM-powered bioinformatics chatbot that enables researchers to interact with large-scale, proprietary cancer proteomics database through intuitive dialogue. Instead of relying on its internal knowledge, the agent grounds its entire analytical and visualization process on this external, verifiable database, thus mitigating the risk of factual inaccuracies. This paradigm is pivotal for applications where data integrity is paramount, such as interacting with EHRs, querying clinical guidelines, or analyzing administrative data to optimize hospital resource allocation. By acting as reliable cognitive tool, the GS enhances the accessibility and utility of complex, structured data without sacrificing trustworthiness. Application of VWA. The VWA quadrant marks significant leap in agentic capability, coupling explicit knowledge grounding with proactive goal execution [281]. Agents in this category move beyond mere cognition to actively participate in and automate clinical workflows. The daGOAT system, an autonomous AI agent designed to prevent severe graft-versus-host disease (GvHD), stands as pioneering example in this domain [23]. This system autonomously monitors real-time, multimodal patient data from the hospitals information system, predicts the risk of GvHD, and independently initiates preventive drug prescription, which becomes the default action unless vetoed by clinician. Here, the agent is not consultant but an active collaborator, executing critical, multi-step clinical task. Its decisions are both verifiable, as they are based on explicit patient data, and autonomous, as they directly propel the clinical workflow forward. Such systems, which require sophisticated architectures for strategic planning, memory management, and action execution, represent tangible shift towards the autonomous scientific partners envisioned in next-generation healthcare, automating not just data analysis but clinical intervention itself. Application of EP. Finally, the EP quadrant remains the most speculative and sparsely populated area in real-world medical applications [219]. An agent in this category would leverage the creative, generative power of its implicit knowledge to autonomously devise and execute novel, multi-step clinical plans, potentially without being constrained by existing protocols. For instance, such an agent might devise novel therapeutic strategy for rare disease by synthesizing disparate insights from across the medical literature. While this holds immense transformative potential, it also carries substantial risks, as ungrounded, autonomous actions could lead to clinically unsafe or unpredictable outcomes [241]. The technical and ethical hurdles to developing and deploying such agents are formidable, requiring breakthroughs in managing hallucinations, ensuring goal alignment, and creating robust validation frameworks. Currently, this quadrant serves less as category of existing applications and more as critical beacon for future research, highlighting the ultimate challenge and promise of agentic AI in truly reinventing clinical dialogue and practice. 6 Open Challenges & Future Opportunities While LLM-based agents have demonstrated transformative potential in shifting healthcare communication from passive information retrieval to active clinical intervention, realizing truly reliable, autonomous, and ethically aligned Manuscript submitted to ACM 46 Zhi et al. digital doctors presents formidable challenges. As represented in Fig. 10, this section delineates three critical research trajectories and their associated hurdles. Fig. 10. The challenges of agentic clinical dialogue of three perspectives. Neuro-symbolic cognitive architectures. The current dichotomy between creative but hallucination-prone agents and reliable yet rigid systems necessitates hybrid approach. This hybrid approach aims to reconcile the intuitive reasoning of LLMs with the logical rigor of symbolic systems, primarily through dynamic fusion and conflict resolution. critical challenge lies in engineering metacognitive mechanisms capable of adaptively arbitrating between parametric memory and non-parametric external knowledge, particularly when model intuition contradicts clinical guidelines [185]. This demands agents possess intrinsic self-doubt and cognitive boundary awareness beyond simple retrieval augmentation. Furthermore, addressing generalization in medical long-tail scenarios, such as rare diseases and complex comorbidities, requires agents to transcend predefined workflows [57, 315]. By leveraging few-shot learning, medical ontologies, and causal reasoning, agents must autonomously construct logical diagnostic pathways in unstructured environments. Finally, ensuring intermediate alignment remains paramount [232]. Future research must anchor every reasoning step to verifiable medical facts. Developing fine-grained process supervision is essential to ensure that intermediate cognitive actions, from symptom extraction to differential diagnosis, are not only outcome-correct but also logically sound and auditable. Holistic patient management. Current session-based systems fail to integrate the longitudinal data necessary for comprehensive care. Establishing genuine therapeutic alliance requires agents to master lifelong memory and state tracking, processing care trajectories that span months or years [141]. The engineering challenge involves designing efficient memory compression and retrieval mechanisms to extract evolving clinical features, such as disease progression or medication tolerance, from massive EHRs, thereby mitigating catastrophic forgetting and advancing toward dynamic models. Moreover, effective healthcare demands sociolinguistic adaptation, recognizing that clinical dialogue is an interplay of information, emotion, and culture [91]. Agents must be endowed with cultural competence to adjust communication strategies based on patient dialects and socioeconomic backgrounds, thereby preventing stereotyping and ensuring equity. Ultimately, the field must evolve toward human-AI teaming, reflecting the multi-disciplinary nature of complex medical decision-making [193]. Future directions involve constructing heterogeneous agent ecosystems that seamlessly integrate human expertise, requiring robust communication protocols to prevent inter-agent consensus hallucination and clearly delineated boundaries of accountability. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication High-stakes control. As agents transition from passive advisors to active executors, traditional evaluation metrics become obsolete, and safety and ethical alignment must be prioritized. Establishing clinical ethics and safety guardrails is critical, as general reinforcement learning is insufficient for complex medical ethics citeEQUITY25. The challenge lies in constructing domain-specific constitutional AI frameworks that encode medical ethics as fundamental constraints, enabling agents to navigate ethical dilemmas and resist adversarial inputs. Simultaneously, error recovery mechanisms are essential for managing the uncontrollable risks associated with external tool use [75]. Research must prioritize robustness, equipping agents with the capacity for selfreflection, operational rollback, and soliciting human intervention to prevent cascading failures in automated workflows. Consequently, evaluation paradigms must shift toward simulation-based dynamic evaluation [9]. Moving beyond static benchmarks, the field requires high-fidelity clinical sandboxes populated by realistic patient simulators. These zero-risk environments are essential for rigorously assessing an agents interactive strategies, long-term planning, and adaptability to disease progression and emergent conditions. 7 Conclusion This survey provides comprehensive review of the ongoing paradigm shift in automated healthcare communication, charting the evolution from traditional pipeline-based systems to the era of autonomous, LLM-driven clinical agents. The implications of this transition are profound, demanding principled understanding of the new design space and its inherent trade-offs. To this end, we introduced novel taxonomy structured along two orthogonal axes, which yields four distinct agentic paradigms. For each paradigm, we conduct granular analysis of its core technical components, including strategic planning, memory management, action execution, collaboration, and evolution, systematically evaluating their respective architectural patterns, technical implementations, advantages, and limitations. By providing this structured framework, this survey offers more than mere catalog of existing work. It furnishes conceptual lens to analyze current systems and roadmap to guide the future development of clinical dialogue agents that are not only powerful and autonomous but also reliable, safe, and aligned with the core tenets of patient care. References [1] Asma Ben Abacha and Dina Demner-Fushman. 2019. On the Summarization of Consumer Health Questions. In ACL. Association for Computational Linguistics, 22282234. [2] Asma Ben Abacha and Dina Demner-Fushman. 2019. question-entailment approach to question answering. BMC Bioinform. 20, 1 (2019), 511:1511:23. [3] Asma Ben Abacha, Yassine Mrabet, et al. 2019. Bridging the Gap Between Consumers Medication Questions and Trusted Answers. In MEDINFO, Vol. 264. IOS Press, 2529. [4] Asma Ben Abacha, Chaitanya Shivade, and Dina Demner-Fushman. 2019. Overview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering. In BioNLP. Association for Computational Linguistics, 370379. [5] Asma Ben Abacha, Wen-wai Yim, et al. 2023. An Empirical Study of Clinical Note Generation from Doctor-Patient Encounters. In EACL. Association for Computational Linguistics, 22832294. [6] Asma Ben Abacha, Wen-wai Yim, et al. 2024. MEDEC: Benchmark for Medical Error Detection and Correction in Clinical Notes. CoRR abs/2412.19260 (2024). [7] Mahyar Abbasian, Elahe Khatibi, et al. 2024. Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI. npj Digit. Medicine 7, 1 (2024). [8] Florian Albrecht, Ruslan Talpa, and Raphael Scheible-Schmitt. 2025. Enhancing medical information retrieval: Re-engineering the tala-med search engine for improved performance and flexibility. Health Informatics J. 31, 3 (2025). [9] Mohammed Khaleed Almansoori, Komal Kumar, and Hisham Cholakkal. 2025. MedAgentSim: Self-evolving Multi-agent Simulations for Realistic Clinical Interactions. In MICCAI (Lecture Notes in Computer Science, Vol. 15968). Springer, 362372. [10] Mohammed Khaleed Almansoori, Komal Kumar, and Hisham Cholakkal. 2025. Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions. CoRR abs/2503.22678 (2025). Manuscript submitted to ACM 48 Zhi et al. [11] Ulzee An, Simon Lee, et al. 2025. Dk-behrt: Teaching language models international classification of disease (icd) codes using known disease descriptions. In AAAI. PMLR, 133143. [12] Sumera Anjum, Hanzhi Zhang, et al. 2024. HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making. CoRR abs/2409.10011 (2024). [13] Hania Aslam, Gousia K. Malak, et al. 2025. LIFE-CRAFT: Multi-agentic Conversational RAG Framework for Lifestyle Medicine Coaching with Context Traceability and Case-Based Evidence Synthesis. In MICCAI (Lecture Notes in Computer Science, Vol. 16147). Springer, 8594. [14] Rina Bao, Shilong Dong, and othes. 2025. Visual and Domain Knowledge for Professional-level Graph-of-Thought Medical Reasoning. In ICML. 29302952. [15] Fanghui Bi, Tiantian He, and Xin Luo. 2023. fast nonnegative autoencoder-based approach to latent feature analysis on high-dimensional and incomplete data. IEEE Transactions on Services Computing 17, 3 (2023), 733746. [16] Elliot Bolton, Abhinav Venigalla, et al. 2024. BioMedLM: 2.7B Parameter Language Model Trained On Biomedical Text. CoRR abs/2403.18421 (2024). [17] Carlos Busso, Murtaza Bulut, et al. 2008. IEMOCAP: interactive emotional dyadic motion capture database. Lang. Resour. Evaluation 42, 4 (2008), 335359. [18] Shihao Cai, Jizhi Zhang, et al. 2025. Agentic Feedback Loop Modeling Improves Recommendation and User Simulation. In SIGIR. ACM, 22352244. [19] Yan Cai, Linlin Wang, et al. 2024. MedBench: Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models. In AIII. AAAI Press, 1770917717. [20] Aofei Chang, Le Huang, et al. 2025. Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning. In ACL. Association for Computational Linguistics, 93579372. [21] Hanjie Chen, Zhouxiang Fang, et al. 2025. Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions. In NAACL. Association for Computational Linguistics, 35633599. [22] Junying Chen, Zhenyang Cai, et al. 2025. Towards Medical Complex Reasoning with LLMs through Medical Verifiable Problems. In ACL. Association for Computational Linguistics, 1455214573. [23] Junren Chen, Yigeng Cao, et al. 2025. Autonomous artificial intelligence prescribing drug to prevent severe acute graft-versus-host disease in HLA-haploidentical transplants. Nature Communications 16, 1 (2025), 8391. [24] Junying Chen, Chi Gui, et al. 2025. CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis. In ACL. Association for Computational Linguistics, 1434514368. [25] Junying Chen, Dongfang Li, et al. 2022. Diaformer: Automatic Diagnosis via Symptoms Sequence Generation. In AIII. AAAI Press, 44324440. [26] Junying Chen, Xidong Wang, et al. 2023. HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs. CoRR abs/2311.09774 (2023). [27] Jing Chen, Zhihua Wei, et al. 2025. Infusing Multi-Hop Medical Knowledge Into Smaller Language Models for Biomedical Question Answering. IEEE J. Biomed. Health Informatics 29, 7 (2025), 53175328. [28] Justin Chih-Yao Chen, Swarnadeep Saha, and Mohit Bansal. 2024. ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. In ACL. Association for Computational Linguistics, 70667085. [29] Kai Chen, Xinfeng Li, et al. 2025. MDTeamGPT: Self-Evolving LLM-based Multi-Agent Framework for Multi-Disciplinary Team Medical Consultation. CoRR abs/2503.13856 (2025). [30] Kaitao Chen, Mianxin Liu, et al. 2025. Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making. CoRR abs/2508.05996 (2025). [31] Kai Chen, Ji Qi, et al. 2025. Self-Evolving Framework for Multi-Agent Medical Consultation Based on Large Language Models. In ICASSP. IEEE, 15. [32] Kai Chen, Taihang Zhen, et al. 2025. MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems. CoRR abs/2505.20824 (2025). [33] Lei Chen. 2024. Medical education and artificial intelligence: Question answering for medical questions based on intelligent interaction. Concurr. Comput. Pract. Exp. 36, 14 (2024). [34] Pingyi Chen, Honglin Li, et al. 2024. WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images. In MICCAI (Lecture Notes in Computer Science, Vol. 15004). Springer, 546556. [35] Qianyu Chen, Xin Li, et al. 2025. Advancing Confidence Calibration and Quantification in Medication Recommendation. In KDD. ACM, 106117. [36] Wei Chen, Zhiwei Li, et al. 2023. benchmark for automatic medical consultation system: frameworks, tasks and datasets. Bioinform. 39, 1 (2023). [37] Wanyi Chen, Zihua Zhao, et al. 2025. Multi-modal Medical Diagnosis via Large-small Model Collaboration. In CVPR. [38] Ye Chen, Igor Couto, et al. 2024. SoftTiger: Clinical Foundation Model for Healthcare Workflows. CoRR abs/2403.00868 (2024). [39] Yifei Chen, Ruihui Hou, et al. 2025. EMRs2CSP : Mining Clinical Status Pathway from Electronic Medical Records. In ACL. Association for Computational Linguistics, 1723517251. [40] Yirong Chen, Zhenyu Wang, et al. 2023. BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT. CoRR abs/2310.15896 (2023). [41] Yirong Chen, Xiaofen Xing, et al. 2023. SoulChat: Improving LLMs Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations. In EMNLP. Association for Computational Linguistics, 11701183. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 49 [42] Bharath Chintagunta, Namit Katariya, et al. 2021. Medically Aware GPT-3 as Data Generator for Medical Dialogue Summarization. In MLHC (Proceedings of Machine Learning Research, Vol. 149). PMLR, 354372. [43] Jeonghun Cho and Gary Lee. 2025. K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor. In NAACL. Association for Computational Linguistics, 68786901. [44] Hui Tang Chuang Zhao et al. 2025. Beyond Sequential Patterns: Rethinking Healthcare Predictions with Contextual Insights. ACM Trans. Inf. Syst. 43, 4, Article 107 (July 2025), 32 pages. [45] Hui Tang Chuang Zhao et al. 2025. Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval. arXiv:2511.13293 [cs.AI] https://arxiv.org/abs/2511.13293 [46] Kristijan Cincar, Todor Ivascu, and Viorel Negru. 2024. MAS-PatientCare: Medical Diagnosis and Patient Management System Based on Multi-agent Architecture. In BCI (Communications in Computer and Information Science, Vol. 2391). Springer, 241255. [47] Cristian Cosentino, Annamaria Defilippo, et al. 2025. HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways. CoRR abs/2508.07308 (2025). [48] Menglin Cui, Xiang Li, and Peng Qin. 2024. Explainable Knowledge-Based Learning for Online Medical Question Answering. In KSEM (Lecture Notes in Computer Science, Vol. 14888). Springer, 294304. [49] Chao Ding, Mouxiao Bian, et al. 2025. Building Human-Verified Clinical Reasoning Dataset via Human LLM Hybrid Pipeline for Trustworthy Medical AI. CoRR abs/2505.06912 (2025). [50] An Dinh, Stacey Miertschin, Amber Young, and Somya D. Mohanty. 2019. data-driven approach to predicting diabetes and cardiovascular disease with machine learning. BMC Medical Informatics and Decision Making 19 (2019). https://api.semanticscholar.org/CorpusID:207888333 [51] Rezarta Islamaj Do르n, Robert Leaman, and Zhiyong Lu. 2014. NCBI disease corpus: resource for disease name recognition and concept normalization. Journal of biomedical informatics 47 (2014), 110. [52] Ahmed T. Elboardy, Ghada Khoriba, and Essam A. Rashed. 2025. Medical AI Consensus: Multi-Agent Framework for Radiology Report Generation and Evaluation. CoRR abs/2509.17353 (2025). [53] Jinyuan Fang, Yanwen Peng, et al. 2025. Comprehensive Survey of Self-Evolving AI Agents: New Paradigm Bridging Foundation Models and Lifelong Agentic Systems. CoRR abs/2508.07407 (2025). [54] Steven Y. Feng, Vivek Khetan, et al. 2023. CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models. In ACL. Association for Computational Linguistics, 313327. [55] Marcos Fern치ndez-Pichel, Juan Carlos Pichel, and David E. Losada. 2025. Evaluating search engines and large language models for answering health questions. npj Digit. Medicine 8, 1 (2025). [56] Scott L. Fleming, Alejandro Lozano, et al. 2024. MedAlign: Clinician-Generated Dataset for Instruction Following with Electronic Medical Records. In AAAI. AAAI Press, 2202122030. [57] Giacomo Frisoni, Alessio Cocchieri, et al. 2024. To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering. In ACL. Association for Computational Linguistics, 98789919. [58] Farieda Gaber, Maqsood Shaik, et al. 2025. Evaluating large language model workflows in clinical decision support for triage and referral and diagnosis. npj Digit. Medicine 8, 1 (2025). [59] Huan-ang Gao, Jiayi Geng, et al. 2025. Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence. CoRR abs/2507.21046 (2025). [60] Peng Gao, Feng Gao, et al. 2024. Medical knowledge graph question answering for drug-drug interaction prediction based on multi-hop machine reading comprehension. CAAI Trans. Intell. Technol. 9, 5 (2024), 12171228. [61] Shanghua Gao, Ada Fang, et al. 2024. Empowering biomedical discovery with AI agents. Cell 187, 22 (2024), 61256151. [62] Zhan Gao, Ling Huang, et al. 2026. Domain-continual learning for multi-center anatomical detection via prompt-enhanced and densely-fused MedSAM. Inf. Fusion 126 (2026), 103614. [63] Joseph Geraci, Bessi Qorri, et al. 2025. Integrating Dynamical Systems Learning with Foundational Models: Meta-Evolutionary AI Framework for Clinical Trials. CoRR abs/2506.14782 (2025). [64] Pedram Golnari, Katrina Prantzalos, et al. 2025. Ontology accelerates few-shot learning capability of large language model: study in extraction of drug efficacy in rare pediatric epilepsy. Int. J. Medical Informatics 201 (2025), 105942. [65] Alex J. Goodell, Simon N. Chu, et al. 2025. Large language model agents can use tools to perform clinical calculations. npj Digit. Medicine 8, 1 (2025). [66] Maxime Griot, Coralie Hemptinne, et al. 2025. Large Language Models lack essential metacognition for reliable medical reasoning. Nature Communications 16, 1 (2025), 642. [67] Zishan Gu, Fenglin Liu, et al. 2024. Inquire, Interact, and Integrate: Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning. CoRR abs/2405.11640 (2024). [68] Zishan Gu, Changchang Yin, et al. 2024. MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context. CoRR abs/2407.02730 (2024). [69] Harsha Gurulingappa, Abdul Mateen Rajput, et al. 2012. Development of benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports. J. Biomed. Informatics 45, 5 (2012), 885892. [70] Pietro Hiram Guzzi, Annamaria Defilippo, et al. 2025. CardioTRAP: Design of Retrieval Augmented System (RAG) for Clinical Data in Cardiology. In ICHI. IEEE, 397405. Manuscript submitted to ACM 50 Zhi et al. [71] Paul Hager, Friederike ungmann, et al. 2024. Evaluation and mitigation of the limitations of large language models in clinical decision-making. Nature medicine 30, 9 (2024), 26132622. [72] Tianyu Han, Lisa C. Adams, et al. 2023. MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data. CoRR abs/2304.08247 (2023). [73] Hashim Hayat, Maksim Kudrautsau, et al. 2025. Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in Real World Setting. CoRR abs/2507.22902 (2025). [74] Junqing He, Mingming Fu, and Manshu Tu. 2019. Applying deep matching networks to Chinese medical question answering: study and dataset. BMC Medical Informatics Decis. Mak. 19-S, 2 (2019), 91100. [75] Yexiao He, Ang Li, et al. 2025. MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility. CoRR abs/2506.00235 (2025). [76] Yajie Vera He, Mohita Chowdhury, et al. 2025. ASTRID - An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems. In ACL. Association for Computational Linguistics, 1670016716. [77] Zhenfeng He, Yuqiang Han, et al. 2022. DialMed: Dataset for Dialogue-based Medication Recommendation. In COLING. International Committee on Computational Linguistics, 721733. [78] Tove Helldin and Christian Norrie. 2025. Designing for human-centered AI - Lessons learned from case study in the clinical domain. Int. J. Hum. Comput. Stud. 205 (2025), 103623. [79] Kyle Higgins, Olga P. Nyssen, et al. 2024. The Helicobacter pylori AI-Clinician: Harnessing Artificial Intelligence to Personalize H. pylori Treatment Recommendations. CoRR abs/2412.06841 (2024). [80] Wenlong Hou, Guangqian Yang, et al. 2025. ADAgent: LLM Agent for Alzheimers Disease Analysis with Collaborative Coordinator. In MICCAI (Lecture Notes in Computer Science, Vol. 16147). Springer, 2332. [81] Aliyah R. Hsu, Yeshwanth Cherapanamjeri, et al. 2024. Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making. In ICLR. OpenReview.net. [82] Chao-Chun Hsu, Sheng-Yeh Chen, et al. 2018. EmotionLines: An Emotion Corpus of Multi-Party Conversations. In LREC. European Language Resources Association (ELRA). [83] Hsin-Ling Hsu, Cong-Tinh Dao, et al. 2025. MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan Generation. CoRR abs/2503.17900 (2025). [84] Mengkang Hu, Yao Mu, et al. 2024. Tree-Planner: Efficient Close-loop Task Planning with Large Language Models. In ICLR. OpenReview.net. [85] Kexin Huang, Jaan Altosaar, and Rajesh Ranganath. 2019. ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. CoRR abs/1904.05342 (2019). [86] Xu Huang, Weiwen Liu, et al. 2024. Understanding the planning of LLM agents: survey. CoRR abs/2402.02716 (2024). [87] Yoshitaka Inoue, Tianci Song, Xinling Wang, Augustin Luna, and Tianfan Fu. 2025. Drugagent: Multi-agent large language model-based reasoning for drug-target interaction prediction. ArXiv (2025), arXiv2408. [88] Saahil Jain, Ashwin Agrawal, et al. 2021. RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. In NeuralPS. [89] Sohyeon Jeon and Hong-Gee Kim. 2025. comparative evaluation of chain-of-thought-based prompt engineering techniques for medical question answering. Comput. Biol. Medicine 196 (2025), 110614. [90] Yuelyu Ji, Hang Zhang, and Yanshan Wang. 2025. Bias Evaluation and Mitigation in Retrieval-Augmented Medical Question-Answering Systems. CoRR abs/2503.15454 (2025). [91] Chao Jiang and Wei Xu. 2024. MedReadMe: Systematic Study for Fine-grained Sentence Readability in Medical Domain. In EMNLP. Association for Computational Linguistics, 1729317319. [92] Lindong Jiang, Chao Xu, et al. 2024. Autosurv: interpretable deep learning framework for cancer survival analysis incorporating clinical and multi-omics data. NPJ precision oncology 8, 1 (2024), 4. [93] Shuyang Jiang, Yusheng Liao, et al. 2025. MedS3: Towards Medical Slow Thinking with Self-Evolved Soft Dual-sided Process Supervision. arXiv preprint arXiv:2501.12051 (2025). [94] Songtao Jiang, Yan Zhang, et al. 2025. HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models. In ACL. Association for Computational Linguistics, 1385313868. [95] Xinke Jiang, Ruizhe Zhang, et al. 2025. HyKGE: Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses. In ACL. Association for Computational Linguistics, 1183611856. [96] Bowen Jin, Hansi Zeng, et al. 2025. Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning. CoRR abs/2503.09516 (2025). [97] Bowen Jin, Hansi Zeng, Zhenrui Yue, Dong Wang, Hamed Zamani, and Jiawei Han. 2025. Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning. CoRR abs/2503.09516 (2025). [98] Congyun Jin, Ming Zhang, et al. 2024. RJUA-MedDQA: Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning. In KDD. ACM, 52185229. [99] Di Jin, Eileen Pan, et al. 2020. What Disease does this Patient Have? Large-scale Open Domain Question Answering Dataset from Medical Exams. CoRR abs/2009.13081 (2020). Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 51 [100] Qiao Jin, Bhuwan Dhingra, et al. 2019. PubMedQA: Dataset for Biomedical Research Question Answering. In EMNLP. Association for Computational Linguistics, 25672577. [101] Qiao Jin, Zhizheng Wang, et al. 2024. AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning. CoRR abs/2402.13225 (2024). [102] Sebastian Joseph, Kathryn Kazanas, et al. 2023. Multilingual Simplification of Medical Texts. In EMNLP. Association for Computational Linguistics, 1666216692. [103] Sarvnaz Karimi, Alejandro Metke-Jimenez, Madonna Kemp, and Chen Wang. 2015. Cadec: corpus of adverse drug event annotations. J. Biomed. Informatics 55 (2015), 7381. [104] W. R. Kearns, N. C. Chi, et al. 2019. Systematic Review of Health Dialog Systems. Methods of information in medicine 58, 6 (2019), 179193. [105] Garapati Keerthana and Manik Gupta. 2025. CLI-RAG: Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs. CoRR abs/2507.06715 (2025). [106] Gregory Kell, Angus Roberts, et al. 2024. RealMedQA: pilot biomedical question answering dataset containing realistic clinical questions. CoRR abs/2408.08624 (2024). [107] Nikhil Khandekar, Qiao Jin, et al. 2024. MedCalc-Bench: Evaluating Large Language Models for Medical Calculations. In NeuralPS. [108] Julien Khlaut, Corentin Dancette, et al. 2024. Efficient Medical Question Answering with Knowledge-Augmented Question Generation. In NAACL. Association for Computational Linguistics, 1020. [109] Minji Kim, Joon Yoo, and OkRan Jeong. 2025. MeDi-TODER: Medical Domain-Incremental Task-Oriented Dialogue Generator Using Experience Replay. Expert Syst. J. Knowl. Eng. 42, 2 (2025). [110] Taeri Kim, Jiho Heo, et al. 2024. VITA: Carefully Chosen and Weighted Less Is Better in Medication Recommendation. In AIII. AAAI Press, 86008607. [111] Taeri Kim, Jiho Heo, et al. 2025. HI-DR: Exploiting Health Status-Aware Attention and an EHR Graph+ for Effective Medication Recommendation. In AIII. AAAI Press, 1195011958. [112] Takyoung Kim, Janvijay Singh, et al. 2025. PIPA: Unified Evaluation Protocol for Diagnosing Interactive Planning Agents. CoRR abs/2505.01592 (2025). [113] Yubin Kim, Chanwoo Park, et al. 2024. MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making. In NeuralPS. [114] Alkis Koudounas, Moreno La Quatra, and Elena Baralis. 2025. DeepDialogue: Multi-Turn Emotionally-Rich Spoken Dialogue Dataset. CoRR abs/2505.19978 (2025). [115] Ceca Kraisnikovic, Robert Harb, et al. 2025. Fine-tuning language model embeddings to reveal domain knowledge: An explainable artificial intelligence perspective on medical decision making. Eng. Appl. Artif. Intell. 139 (2025), 109561. [116] Zeljko Kraljevic, Joshua Au Yeung, et al. 2024. Large Language Models for Medical Forecasting - Foresight 2. CoRR abs/2412.10848 (2024). [117] Maya Kruse, Shiyue Hu, et al. 2025. Zero-shot Large Language Models for Long Clinical Text Summarization with Temporal Reasoning. CoRR abs/2501.18724 (2025). [118] Gleb Kumichev, Pavel Blinov, et al. 2024. MedSyn: LLM-Based Synthetic Medical Text Generation Framework. In ECML (Lecture Notes in Computer Science, Vol. 14950). Springer, 215230. [119] Evangelia Kyrimi, Somayyeh Mossadegh, et al. 2025. Counterfactual reasoning using causal Bayesian networks as healthcare governance tool. Int. J. Medical Informatics 193 (2025), 105681. [120] Max Lamparth, Declan Grabb, et al. 2025. Moving Beyond Medical Exam Questions: Clinician-Annotated Dataset of Real-World Tasks and Ambiguity in Mental Healthcare. CoRR abs/2502.16051 (2025). [121] Md. Tahmid Rahman Laskar, Israt Jahan, et al. 2025. Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge. In ACL. Association for Computational Linguistics, 2548325497. [122] Alon Lavie and Abhaya Agarwal. 2007. METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments. In WMT. Association for Computational Linguistics, 228231. [123] Chenqian Le, Ziheng Gong, et al. 2025. Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs. CoRR abs/2506.12182 (2025). [124] Simon A. Lee, Anthony Wu, and Jeffrey N. Chiang. 2025. Clinical ModernBERT: An efficient and long context encoder for biomedical text. CoRR abs/2504.03964 (2025). [125] Binxu Li, Tiankai Yan, et al. 2024. MMedAgent: Learning to Use Medical Tools with Multi-modal Agent. In EMNLP. Association for Computational Linguistics, 87458760. [126] Dubai Li, Nan Jiang, et al. 2025. From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making. CoRR abs/2505.10282 (2025). [127] Jiao Li, Yueping Sun, et al. 2016. BioCreative CDR task corpus: resource for chemical disease relation extraction. Database J. Biol. Databases Curation 2016 (2016). [128] Junkai Li, Siyu Wang, and otehrs. 2024. Agent Hospital: Simulacrum of Hospital with Evolvable Medical Agents. CoRR abs/2405.02957 (2024). [129] Shuyue Stella Li, Vidhisha Balachandran, et al. 2024. MediQ: Question-Asking LLMs and Benchmark for Reliable Interactive Clinical Reasoning. In NeuralPS. [130] Wenliang Li, Rui Yan, et al. 2025. MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM. CoRR abs/2509.20067 (2025). Manuscript submitted to ACM 52 Zhi et al. [131] Xueshen Li, Xinlong Hou, et al. 2025. two-stage proactive dialogue generator for efficient clinical information collection using large language model. Expert Syst. Appl. 287 (2025), 127833. [132] Yunxiang Li, Zihan Li, et al. 2023. ChatDoctor: Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge. CoRR abs/2303.14070 (2023). [133] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: manually labelled multi-turn dialogue dataset. arXiv preprint arXiv:1710.03957 (2017). [134] Yangning Li, Weizhi Zhang, et al. 2025. Towards Agentic RAG with Deep Reasoning: Survey of RAG-Reasoning Systems in LLMs. CoRR abs/2507.09477 (2025). [135] Siting Liang and Daniel Sonntag. 2025. Advancing Biomedical Claim Verification by Using Large Language Models with Better Structured Prompting Strategies. In BioNLP. 148166. [136] Sichu Liang, Linhai Zhang, et al. 2025. RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering. CoRR abs/2502.13361 (2025). [137] Sichu Liang, Linhai Zhang, et al. 2025. RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering. CoRR abs/2502.13361 (2025). [138] Yusheng Liao, Shuyang Jiang, et al. 2025. ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents. In ACL. Association for Computational Linguistics, 1350713531. [139] Lin and Chin Yew. 2004. ROUGE: Package for Automatic Evaluation of Summaries. In Text Summarization Branches Out. Association for Computational Linguistics, 7481. [140] Xinzhu Lin, Xiahui He, et al. [n. d.]. Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph. In IJCNLP, pages = 50325041, publisher = Association for Computational Linguistics, year = 2019. [141] Jiaxiang Liu, Tianxiang Hu, and othes. 2025. KPL: Training-Free Medical Knowledge Mining of Vision-Language Models. In AAAI. AAAI Press, 1885218860. [142] Jiandong Liu, Jianfeng Ren, et al. 2025. cascaded retrieval-while-reasoning multi-document comprehension framework with incremental attention for medical question answering. Expert Syst. Appl. 265 (2025), 125701. [143] Junling Liu, Peilin Zhou, et al. 2023. Benchmarking Large Language Models on CMExam - comprehensive Chinese Medical Exam Dataset. In NeuralPS. [144] Lei Liu, Xiaoyan Yang, et al. 2024. Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions. CoRR abs/2406.03712 (2024). [145] Liping Liu, Chunhong Zhang, Likang Wu, Chuang Zhao, Zheng Hu, Ming He, and Jianping Fan. 2025. Instruct-of-Reflection: Enhancing Large Language Models Iterative Reflection Capabilities via Dynamic-Meta Instruction. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 99569978. [146] Mingzhou Liu, Ching-Wen Lee, et al. 2025. Learning Causal Alignment for Reliable Disease Diagnosis. In ICLR. OpenReview.net. [147] Qidong Liu, Zhaopeng Qiu, et al. 2025. Contrastive Pretrain Model with Prompt Tuning for Multi-center Medication Recommendation. ACM Trans. Inf. Syst. 43, 3 (2025), 57:157:29. [148] Shanshan Liu, Noriki Nishida, et al. 2025. MA-COIR: Leveraging Semantic Search Index and Generative Models for Ontology-Driven Biomedical Concept Recognition. CoRR abs/2505.12964 (2025). [149] Siyang Liu, Chujie Zheng, et al. 2021. Towards Emotional Support Dialog Systems. In IJCNLP. Association for Computational Linguistics, 34693483. [150] Wei Liu, Jun Li, et al. 2025. DrBioRight 2.0: an LLM-powered bioinformatics chatbot for large-scale cancer functional proteomics analysis. Nature Communications 16, 1 (2025), 2256. [151] Wenge Liu, Jianheng Tang, et al. 2022. MedDG: An Entity-Centric Medical Consultation Dataset for Entity-Aware Medical Dialogue Generation. In NLPCC (Lecture Notes in Computer Science, Vol. 13551). Springer, 447459. [152] Xiaohong Liu, Hao Liu, et al. 2025. generalist medical language model for disease diagnosis assistance. Nature medicine 31, 3 (2025), 932942. [153] Zhengyuan Liu, Siti Umairah Md. Salleh, et al. 2023. Joint Dialogue Topic Segmentation and Categorization: Case Study on Clinical Spoken Conversations. In EMNLP. Association for Computational Linguistics, 185193. [154] Kyle Lo, Lucy Lu Wang, and otehrs. 2020. S2ORC: The Semantic Scholar Open Research Corpus. In ACL. Association for Computational Linguistics, 49694983. [155] Mary Lucas and Justin Yang andothers. 2024. Reasoning with large language models for medical question answering. Journal of the American Medical Informatics Association 31, 9 (2024), 19641975. [156] Ling Luo, Jinzhong Ning, et al. 2024. Taiyi: bilingual fine-tuned large language model for diverse biomedical tasks. J. Am. Medical Informatics Assoc. 31, 9 (2024), 18651874. [157] Man Luo, Arindam Mitra, et al. 2022. Improving Biomedical Information Retrieval with Neural Retrievers. In ACL. AAAI Press, 1103811046. [158] Renqian Luo, Liai Sun, et al. 2022. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Briefings Bioinform. 23, (2022). [159] Ao Ma, Zhiyuan Li, et al. 2025. Seek Inner: LLM-Enhanced Information Mining for Medical Visual Question Answering. In wWW. ACM, 22972305. [160] Siqi Ma, Jiajie Huang, et al. 2025. MedLA: Logic-Driven Multi-Agent Framework for Complex Medical Reasoning with Large Language Models. CoRR abs/2509.23725 (2025). Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication [161] Abdine Maiga, Anoop Shah, and Emine Yilmaz. 2025. Error Detection in Medical Note through Multi Agent Debate. In BioNLP. [162] Tula Masterman, Sandi Besen, et al. 2024. The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: Survey. CoRR abs/2404.11584 (2024). [163] Nikita Mehandru, Brenda Y. Miao, et al. 2023. Large Language Models as Agents in the Clinic. CoRR abs/2309.10895 (2023). [164] Timoth칠 M칠nard and Katrina A. Bramstedt. 2025. Artificial intelligence agent in clinical trial operations: fictional (for now) case study. AI Ethics 5, 5 (2025), 46274633. [165] Ahmad Rezaie Mianroodi, Amirali Rezaie, et al. 2025. MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs. CoRR abs/2508.01401 (2025). [166] Sewon Min, Xinxi Lyu, et al. 2022. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?. In EMNLP. Association for Computational Linguistics, 1104811064. [167] Pranav Pushkar Mishra, Mohammad Arvan, and Mohan Zalake. 2025. TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork. CoRR abs/2508.08115 (2025). [168] Ali Modarressi, Ayyoob Imani, et al. 2023. RET-LLM: Towards General Read-Write Memory for Large Language Models. CoRR abs/2305.14322 (2023). [169] Donald Murphy. 1990. SUPPORT: Study to understand prognoses and preferences for outcomes and risks of treatments. Study design. Journal of Clinical Epidemiology 43 (1990), 1S. [170] Subhash Nerella, Sabyasachi Bandyopadhyay, et al. 2024. Transformers and large language models in healthcare: review. Artif. Intell. Medicine 154 (2024), 102900. [171] Pedram Nilofary, Mehdi Feghhi, and Morteza Analoui. 2025. Designing Distributed LLM-Based Search Engine as Foundation for Agent Discovery. In CSICC. IEEE, 16. [172] Charles Nimo, Tobi Olatunji, et al. 2025. AfriMed-QA: Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset. In ACL. Association for Computational Linguistics, 19481973. [173] Alexander Novikov, Ng칙n Vu, et al. 2025. AlphaEvolve: coding agent for scientific and algorithmic discovery. CoRR abs/2506.13131 (2025). [174] Stephen Obadinma, Alia Lachana, et al. 2025. The FAIIR conversational AI agent assistant for youth mental health service provision. npj Digit. Medicine 8, 1 (2025). [175] Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002. The GENIA corpus: an annotated research abstract corpus in molecular biology domain. In Proceedings of the Second International Conference on Human Language Technology Research. 8286. [176] Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. 2022. MedMCQA: Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering. In CHIL, Vol. 174. PMLR, 248260. [177] Himanshu Pandey, Akhil Amod, and Shivang Kumar. 2024. Advancing Healthcare Automation: Multi-Agent System for Medical Necessity Justification. In BioNLP. Association for Computational Linguistics, 3949. [178] Shrey Pandit, Jiawei Xu, et al. 2025. MedHallu: Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models. CoRR abs/2502.14302 (2025). [179] Kishore Papineni, Salim Roukos, et al. 2002. Bleu: Method for Automatic Evaluation of Machine Translation. In ACL. ACL, 311318. [180] Baolin Peng, Michel Galley, et al. 2023. Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback. CoRR abs/2302.12813 (2023). [181] Qi Peng, Yi Cai, et al. 2025. Integration of Multi-Source Medical Data for Medical Diagnosis Question Answering. IEEE Trans. Medical Imaging 44, 3 (2025), 13731385. [182] Qi Peng, Jialin Cui, et al. 2025. Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree. CoRR abs/2508.03038 (2025). [183] Soujanya Poria, Devamanyu Hazarika, et al. 2019. MELD: Multimodal Multi-Party Dataset for Emotion Recognition in Conversations. In ACL. Association for Computational Linguistics, 527536. [184] Raphael Poulain and Rahmatollah Beheshti. 2024. Graph Transformers on EHRs: Better Representation Improves Downstream Performance. In ICLR. OpenReview.net. [185] Hongjin Qian and Zheng Liu. 2025. MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning. CoRR abs/2508.00271 (2025). [186] Lang Qin, Yao Zhang, et al. 2025. Listening to Patients: Detecting and Mitigating Patient Misreport in Medical Dialogue System. In ACL. Association for Computational Linguistics, 26502664. [187] Chen Qiu, Ke Huang, et al. 2025. Explainable medical visual question answering via chain of evidence. Knowl. Based Syst. 324 (2025), 113672. [188] Huachuan Qiu, Hongliang He, et al. 2024. SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support. In EMNLP. Association for Computational Linguistics, 615636. [189] Mashrur Rashik, Shilpa Sweth, et al. 2025. AI-Enabled Conversational Journaling for Advancing Parkinsons Disease Symptom Tracking. In CHI. ACM, 1029:11029:23. [190] Hannah Rashkin, Eric Michael Smith, et al. 2019. Towards Empathetic Open-domain Conversation Models: New Benchmark and Dataset. In ACL. Association for Computational Linguistics, 53705381. [191] Alexander Rau, Stephan Rau, et al. 2023. context-based chatbot surpasses radiologists and generic ChatGPT in following the ACR appropriateness guidelines. Radiology 308, 1 (2023), e230970. Manuscript submitted to ACM 54 Zhi et al. [192] Fran칞ois Remy, Kris Demuynck, and Thomas Demeester. 2024. BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights. J. Am. Medical Informatics Assoc. 31, 9 (2024), 18441855. [193] Jamil Ur Reza and Yasin Mamatjan. 2025. AI Agents for Clinical Data Assessment: Enhancing Decision-Making with Human-AI Collaboration. In COMPSAC. IEEE, 21122117. [194] Mohammad R. Rezaei, Reza Saadati Fard, et al. 2025. Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge. CoRR abs/2502.13010 (2025). [195] Alexey Romanov and Chaitanya Shivade. 2018. Lessons from Natural Language Inference in the Clinical Domain. In EMNLP. Association for Computational Linguistics, 15861596. [196] Benjamin Rose-Davis, William Van Woensel, et al. 2022. Semantic knowledge modeling and evaluation of argument Theory to develop dialogue based patient education systems for chronic disease Self-Management. Int. J. Medical Informatics 160 (2022), 104693. [197] Kaushik Roy, Manas Gaur, et al. 2022. ProKnow: Process knowledge for safety constrained and explainable question generation for mental health diagnostic assistance. Frontiers Big Data 5 (2022). [198] Reuben Sass. 2025. Equity, autonomy, and the ethical risks and opportunities of generalist medical AI. AI Ethics 5, 1 (2025), 567577. [199] William Saunders, Catherine Yeh, et al. 2022. Self-critiquing models for assisting human evaluators. CoRR abs/2206.05802 (2022). [200] Thomas Savage, Ashwin Nayak, et al. 2024. Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine. npj Digit. Medicine 7, 1 (2024). [201] Max E. Savery, Asma Ben Abacha, et al. 2020. Question-Driven Summarization of Answers to Consumer Health Questions. CoRR abs/2005. (2020). [202] Katharina Schuler, Ian-Christopher Jung, et al. 2025. Context factors in clinical decision-making: scoping review. BMC Medical Informatics Decis. Mak. 25, 1 (2025), 133. [203] Saptarshi Sengupta, Connor T. Heaton, et al. 2024. Towards Efficient Methods in Medical Question Answering using Knowledge Graph Embeddings. In BIBM. IEEE, 50895096. [204] Tianqi Shang, Weiqing He, et al. 2025. DynamiCare: Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making. CoRR abs/2507.02616 (2025). [205] Huihui Shao, Fanyu Wang, and Zhenping Xie. 2025. S2AF: An action framework to self-check the Understanding Self-Consistency of Large Language Models. Neural Networks 187 (2025), 107365. [206] Lingyu Shao, Jiarui Wang, et al. 2025. ADEPT: An advanced data exploration and processing tool for clinical data insights. Comput. Methods Programs Biomed. 268 (2025), 108860. [207] Hanwen Shi, Jin Zhang, and Kunpeng Zhang. 2024. Enhancing Clinical Trial Patient Matching through Knowledge Augmentation with Multi-Agents. CoRR abs/2411.14637 (2024). [208] Xiaoming Shi, Zeming Liu, et al. 2023. MidMed: Towards Mixed-Type Dialogues for Medical Consultation. In ACL. Association for Computational Linguistics, 81458157. [209] Xiaoming Shi, Zeming Liu, et al. 2024. Medical Dialogue System: Survey of Categories, Methods, Evaluation and Challenges. In ACL. Association for Computational Linguistics, 28402861. [210] Yexuan Shi, Mingyu Wang, et al. 2025. Aime: Towards Fully-Autonomous Multi-Agent Framework. CoRR abs/2507.11988 (2025). [211] Yucheng Shi, Tianze Yang, et al. 2025. SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering? CoRR abs/2502. (2025). [212] Seiji Shimizu, Shuntaro Yada, et al. 2024. Improving Self-training with Prototypical Learning for Source-Free Domain Adaptation on Clinical Text. In BioNLP. Association for Computational Linguistics, 113. [213] Hoo-Chang Shin, Yang Zhang, et al. 2020. BioMegatron: Larger Biomedical Domain Language Model. In EMNLP. Association for Computational Linguistics, 47004706. [214] Noah Shinn, Federico Cassano, et al. 2023. Reflexion: language agents with verbal reinforcement learning. In NeuralPS. [215] Yafei Si, Yurun Meng, et al. 2025. Quality safety and disparity of an AI chatbot in managing chronic diseases: simulated patient experiments. npj Digital Medicine 8, 1 (2025), 574. [216] Karan Singhal, Tao Tu, et al. 2025. Toward expert-level medical question answering with large language models. Nature Medicine 31, 3 (2025), 943950. [217] Jiwoong Sohn, Yein Park, et al. 2025. Rationale-Guided Retrieval Augmented Generation for Medical Question Answering. In NAACL. Association for Computational Linguistics, 1273912753. [218] Shashank Srivastava, Kartikeya Kansal, et al. 2025. Secure cognitive health monitoring using directed acyclic graph-based and AI-enhanced IoMT framework. Digit. Commun. Networks 11, 1 (2025), 594602. [219] Ethan Steinberg, Jason Alan Fries, et al. 2024. MOTOR: Time-to-Event Foundation Model For Structured Medical Records. In ICLR. OpenReview.net. [220] Xiaorui Su, Yibo Wang, et al. 2025. KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA. In ICLR. OpenReview.net. [221] Anand Subramanian, Viktor Schlegel, et al. 2024. M-QALM: Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering. In ACL. Association for Computational Linguistics, 40024042. [222] Malavikha Sudarshan, Sophie Shih, et al. 2024. Agentic LLM Workflows for Generating Patient-Friendly Medical Reports. CoRR abs/2408.01112 (2024). Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication 55 [223] Jennifer Sumner, Ravi Shankar, et al. 2025. Insights from high and low clinical users of telemedicine: mixed-methods study of clinician workflows, sentiments, and user experiences. Int. J. Medical Informatics 203 (2025), 106044. [224] Guohao Sun, Can Qin, et al. 2024. Self-Training Large Language and Vision Assistant for Medical Question Answering. In EMNLP. Association for Computational Linguistics, 2005220060. [225] Hao Sun, Zhenru Lin, et al. 2021. PsyQA: Chinese Dataset for Generating Long Counseling Text for Mental Health Support. In IJCNLP. Association for Computational Linguistics, 14891503. [226] Wei Sun, Mingxiao Li, et al. 2025. Generating Explanations in Medical Question-Answering by Expectation Maximization Inference over Evidence. ACM Trans. Comput. Heal. 6, 2 (2025), 23:123:23. [227] Zhaoyue Sun, Jiazheng Li, et al. 2022. PHEE: Dataset for Pharmacovigilance Event Extraction from Text. In EMNLP. Association for Computational Linguistics, 55715587. [228] Zhoujian Sun, Ziyi Liu, et al. 2025. Improving Interactive Diagnostic Ability of Large Language Model Agent Through Clinical Experience Learning. CoRR abs/2503.16463 (2025). [229] Simon Suster and Walter Daelemans. 2018. CliCR: Dataset of Clinical Case Reports for Machine Reading Comprehension. In NAACL. Association for Computational Linguistics, 15511563. [230] Ekaterina Sviridova, Anar Yeginbergen, et al. 2024. CasiMedicos-Arg: Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures. In EMNLP. Association for Computational Linguistics, 1846318475. [231] Xiangru Tang, Anni Zou, et al. 2024. MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning. In ACL. Association for Computational Linguistics, 599621. [232] Nikola Tankovic, Robert Sajina, and Ivan Lorencin. 2025. Transforming Medical Data Access: The Role and Challenges of Recent Language Models in SQL Query Automation. Algorithms 18, 3 (2025), 124. [233] Devharsh Trivedi, Vaishnavi Gopalakrishnan, and Dharati Dholariya. 2023. MediSearch: Advanced Medical Web Search Engine. In CCWC. IEEE, 534540. [234] Shrish Shrinath Vaidya, Gowthamaan Palani, et al. 2025. MedPAO: Protocol-Driven Agent for Structuring Medical Reports. In MICCAI, Vol. 16147. Springer, 3345. [235] Mina Valizadeh and Natalie Parde. 2022. The AI Doctor Is In: Survey of Task-Oriented Dialogue Systems for Healthcare Applications. In ACL. Association for Computational Linguistics, 66386660. [236] Tom van Sonsbeek, Mohammad Mahdi Derakhshani, et al. 2023. Open-Ended Medical Visual Question Answering Through Prefix Tuning of Language Models. In MICCAI (Lecture Notes in Computer Science, Vol. 14224). Springer, 726736. [237] Deeksha Varshney, Aizan Zafar, et al. 2023. Knowledge graph assisted end-to-end medical dialog generation. Artif. Intell. Medicine 139 (2023), 102535. [238] Dave Van Veen, Cara Van Uden, et al. 2024. Adapted large language models can outperform medical experts in clinical text summarization. Nature medicine 30, 4 (2024), 11341142. [239] David Vilares and Carlos G칩mez-Rodr칤guez. 2019. HEAD-QA: Healthcare Dataset for Complex Reasoning. In ACL. Association for Computational Linguistics, 960966. [240] Juraj Vladika, Annika Domres, et al. 2025. Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs. CoRR abs/2505.24830 (2025). [241] Josip Vrdoljak, Zvonimir Boban, et al. 2025. Evaluating large language and large reasoning models as decision support tools in emergency internal medicine. Comput. Biol. Medicine 192 (2025), 110351. [242] Tu Vu, Mohit Iyyer, et al. 2024. FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation. In ACL. Association for Computational Linguistics, 1369713720. [243] Dandan Wang and Shiqing Zhang. 2024. Large language models in medical and healthcare fields: applications, advances, and challenges. Artif. Intell. Rev. 57, 11 (2024), 299. [244] Haochun Wang, Chi Liu, et al. 2023. HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge. CoRR abs/2304.06975 (2023). [245] He Wang, Yang Ouyang, et al. 2025. KMTLabeler: An Interactive Knowledge-Assisted Labeling Tool for Medical Text Classification. IEEE Trans. Vis. Comput. Graph. 31, 9 (2025), 44934510. [246] Junda Wang, Zonghai Yao, et al. 2024. NoteChat: Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes. In ACL. Association for Computational Linguistics, 1518315201. [247] Li Wang, Xi Chen, et al. 2024. Prompt engineering in consistency and reliability with the evidence-based guideline for LLMs. npj Digit. Medicine 7, 1 (2024). [248] Liping Wang, Qiang Liu, et al. 2024. Stage-Aware Hierarchical Attentive Relational Network for Diagnosis Prediction. IEEE TKDE 36, 4 (2024), 17731784. [249] Liupu Wang, Juexin Wang, et al. 2012. Using Internet search engines to obtain medical information: comparative study. Journal of medical Internet research 14, 3 (2012), e74. [250] Qingyue Wang, Yanhe Fu, et al. 2025. Recursively summarizing enables long-term dialogue memory in large language models. Neurocomputing 639 (2025), 130193. Manuscript submitted to ACM 56 Zhi et al. [251] Rui Wang, Yonghe Chen, et al. 2025. MedConMA: Confidence-Driven Multi-agent Framework for Medical Q&A. In PAKDD (Lecture Notes in Computer Science, Vol. 15872). Springer, 421433. [252] Song Wang, Yaochen Zhu, et al. 2025. Knowledge Editing for Large Language Models: Survey. ACM Comput. Surv. 57, 3 (2025), 59:159:37. [253] Wenxuan Wang, Zizhan Ma, et al. 2025. Survey of LLM-based Agents in Medicine: How far are we from Baymax?. In ACL. Association for Computational Linguistics, 1034510359. [254] Weiqin Wang, Yile Wang, and Hui Huang. 2025. Ranked Voting based Self-Consistency of Large Language Models. In ACL. Association for Computational Linguistics, 1441014426. [255] Xidong Wang, Jianquan Li, et al. 2025. Huatuo-26M, Large-scale Chinese Medical QA Dataset. In NAACL. Association for Computational Linguistics, 38283848. [256] Xin Wang, Zhaocai Sun, et al. 2025. MedicalGLM: Pediatric Medical Question Answering Model with quality evaluation mechanism. J. Biomed. Informatics 165 (2025), 104793. [257] Xuezhi Wang, Jason Wei, et al. 2023. Self-Consistency Improves Chain of Thought Reasoning in Language Models. In ICLR. OpenReview.net. [258] Yanshan Wang, Naveed Afzal, et al. 2020. MedSTS: resource for clinical semantic textual similarity. Lang. Resour. Evaluation 54, 1 (2020), 5772. [259] Yanda Wang, Weitong Chen, et al. 2025. Beyond EHRs: External Clinical knowledge and cohort Features for medication recommendation. Knowl. Based Syst. 324 (2025), 113763. [260] Yingxu Wang, Siwei Liu, et al. 2025. EvoAgentX: An Automated Framework for Evolving Agentic Workflows. CoRR abs/2507.03616 (2025). [261] Yubo Wang, Xueguang Ma, and Wenhu Chen. 2024. Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering. In EMNLP. Association for Computational Linguistics, 17541770. [262] Yihan Wang, Qiao Yan, and journal = CoRR volume = abs/2505.21503 year = 2025 others, title = Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making. [n. d.]. ([n. d.]). [263] Ziyu Wang, Elahe Khatibi, and Amir M. Rahmani. 2025. MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering. CoRR abs/2508.15849 (2025). [264] Ziyue Wang, Junde Wu, et al. 2025. MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow. CoRR abs/2503.18968 (2025). [265] Zixiang Wang, Yinghao Zhu, et al. 2025. ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration. In WWW. ACM, 22502261. [266] Taylor Webb, Shanka Subhra Mondal, and Ida Momennejad. 2025. brain-inspired agentic architecture to improve planning with LLMs. Nature Communications 16, 1 (2025), 8633. [267] Hao Wei, Jianing Qiu, et al. 2024. MEDCO: Medical Education Copilots Based on Multi-agent Framework. In ECCV (Lecture Notes in Computer Science, Vol. 15630). Springer, 119135. [268] Zhongyu Wei, Qianlong Liu, et al. 2018. Task-oriented Dialogue System for Automatic Diagnosis. In ACL. Association for Computational Linguistics, 201207. [269] Anuradha Welivita, Yubo Xie, and Pearl Pu. 2021. Large-Scale Dataset for Empathetic Response Generation. In EMNLP. Association for Computational Linguistics, 12511264. [270] Anuradha Welivita, Chun-Hung Yeh, et al. 2023. Empathetic Response Generation for Distress Support. In Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue. ACL, Prague, Czechia, 632644. [271] Michael Wornow, Suhana Bedi, et al. 2025. Context Clues: Evaluating Long Context Models for Clinical Prediction Tasks on EHR Data. In ICLR. OpenReview.net. [272] Chaoyi Wu, Weixiong Lin, et al. 2024. PMC-LLaMA: toward building open-source language models for medicine. J. Am. Medical Informatics Assoc. 31, 9 (2024), 18331843. [273] Chaoyi Wu, Pengcheng Qiu, et al. 2025. Towards evaluating and building versatile large language models for medicine. npj Digit. Medicine 8, (2025). [274] Jiaxin Wu, Yizhou Yu, and Hong-Yu Zhou. 2024. Uncertainty Estimation of Large Language Models in Medical Question Answering. CoRR abs/2407.08662 (2024). [275] Junde Wu, Jiayuan Zhu, et al. 2025. Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation. In ACL. Association for Computational Linguistics, 2844328467. [276] Kevin Wu, Eric Wu, et al. 2025. An automated framework for assessing how well LLMs cite relevant medical references. Nature Communications 16, 1 (2025), 3615. [277] Keefer P. Wu and Patricia C. Tsang. 2024. Intersection of Artificial Intelligence and Medical Education (Student Abstract). In AAAI. AAAI Press, 2368423685. [278] Yuheng Wu, Yujie Dong, et al. 2025. How the Algorithmic Transparency of Search Engines Influences Health Anxiety: The Mediating Effects of Trust in Online Health Information Search. In CHI. ACM, 307:1307:10. [279] Yue Wu, Yangmin Huang, et al. 2025. Should Believe in What Medical AI Says? Chinese Benchmark for Medication Based on Knowledge and Reasoning. In ACL. Association for Computational Linguistics, 11551164. [280] Yongjian Wu, Yang Zhou, et al. 2025. AttriPrompter: Auto-Prompting With Attribute Semantics for Zero-Shot Nuclei Detection via Visual-Language Pre-Trained Models. IEEE Trans. Medical Imaging 44, 2 (2025), 982993. Manuscript submitted to ACM Reinventing Clinical Dialogue: Agentic Paradigms for LLM-Enabled Healthcare Communication [281] Peng Xia, Kangyu Zhu, et al. 2024. RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models. In EMNLP. Association for Computational Linguistics, 10811093. [282] Yiqing Xie, Sheng Zhang, et al. 2024. DocLens: Multi-aspect Fine-grained Medical Text Evaluation. In ACL. Association for Computational Linguistics, 649679. [283] Yunfei Xie, Ce Zhou, et al. 2025. MedTrinity-25M: Large-scale Multimodal Dataset with Multigranular Annotations for Medicine. In ICLR. OpenReview.net. [284] Guangzhi Xiong, Qiao Jin, et al. 2024. Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions. CoRR abs/2408.00727 (2024). [285] Huimin Xu, Seungjun Yi, et al. 2025. TAMA: Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews. CoRR abs/2503.20666 (2025). [286] Jiamin Xu, Zixuan Xu, et al. 2026. Labeling-free RAG-enhanced LLM for intelligent fault diagnosis via reinforcement learning. Adv. Eng. Informatics 69 (2026), 103864. [287] Lin Xu, Qixian Zhou, et al. 2019. End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis. In AAAI. AAAI Press, 73467353. [288] Ronghao Xu, Zhen Huang, et al. 2025. MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text. CoRR abs/2508.10947 (2025). [289] Tianhan Xu, Ling Chen, et al. 2025. STAF-LLM: scalable and task-adaptive fine-tuning framework for large language models in medical domain. Expert Syst. Appl. 281 (2025), 127582. [290] Guojun Yan, Jiahuan Pei, et al. 2022. ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues. In SIGIR. ACM, 30133024. [291] Qianqi Yan, Xuehai He, et al. 2025. Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA. In ACL. Association for Computational Linguistics, 1918819205. [292] Weixiang Yan, Haitian Liu, et al. 2024. ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World. CoRR abs/2406.13890 (2024). [293] Songhua Yang, Hanjie Zhao, et al. 2024. Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-World Multi-Turn Dialogue. In AAAI. AAAI Press, 1936819376. [294] Liang Yao, Yin Zhang, et al. 2018. Topic Modeling Approach for Traditional Chinese Medicine Prescriptions. IEEE Trans. Knowl. Data Eng. 30, 6 (2018), 10071021. [295] Shunyu Yao, Jeffrey Zhao, et al. 2023. ReAct: Synergizing Reasoning and Acting in Language Models. In ICLR. OpenReview.net. [296] Qichen Ye, Junling Liu, et al. 2023. Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model. CoRR abs/2310.09089 (2023). [297] Seungyoun Yi, Minsoo Khang, and Sungrae Park. 2025. ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization. CoRR abs/2509.18158 (2025). [298] Chengzhang Yu, Yiming Zhang, et al. 2025. FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights. In ACL. Association for Computational Linguistics, 76907704. [299] Guangya Yu, Yanhao Li, et al. 2025. CMQCIC-Bench: Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation. In ACL. Association for Computational Linguistics, 609626. [300] Hongyi Yuan, Zheng Yuan, et al. 2022. BioBART: Pretraining and Evaluation of Biomedical Generative Language Model. In BioNLP. Association for Computational Linguistics, 97109. [301] Aizan Zafar, Kshitij Mishra, and Asif Ekbal. 2025. MedEx: Enhancing Medical Question-Answering with First-Order Logic based Reasoning and Knowledge Injection. In COLING. Association for Computational Linguistics, 97019720. [302] Guangtao Zeng, Wenmian Yang, et al. 2020. MedDialog: Large-scale Medical Dialogue Datasets. In EMNLP. Association for Computational Linguistics, 92419250. [303] Zefan Zeng, Qing Cheng, et al. 2025. KoSEL: Knowledge subgraph enhanced large language model for medical question answering. Knowl. Based Syst. 309 (2025), 112837. [304] Chi Zhang, Tao Chen, et al. 2024. Cost-Effective Framework with Optimized Task Decomposition and Batch Prompting for Medical Dialogue Summary. In CIKM. ACM, 31243134. [305] Gongbo Zhang, Zihan Xu, et al. 2025. Leveraging long context in retrieval augmented language models for medical question answering. npj Digit. Medicine 8, 1 (2025). [306] Hongzhi Zhang and M. Omair Shafiq. 2025. MediTriR: Triple-Driven Approach to Retrieval-Augmented Generation for Medical Question Answering Tasks. In ICSC. IEEE, 187194. [307] Jenny Zhang, Shengran Hu, et al. 2025. Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents. CoRR abs/2505.22954 (2025). [308] Sheng Zhang, Xin Zhang, et al. 2018. Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection. IEEE Access 6 (2018), 7406174071. [309] Tianyi Zhang, Varsha Kishore, et al. 2020. BERTScore: Evaluating Text Generation with BERT. In ICLR. OpenReview.net. [310] Xiechi Zhang, Zetian Ouyang, et al. 2025. AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation. In ACL. Association for Computational Linguistics, 62726285. Manuscript submitted to ACM 58 Zhi et al. [311] Xiaodan Zhang, Yanzhao Shi, Junzhong Ji, Chengxin Zheng, and Liangqiong Qu. 2025. MEPNet: Medical Entity-Balanced Prompting Network for Brain CT Report Generation. In AAAI. AAAI Press, 2594025948. [312] Xinlu Zhang, Chenxin Tian, et al. 2023. AlpaCare: Instruction-tuned Large Language Models for Medical Application. CoRR abs/2310.14558 (2023). [313] Yuanzhe Zhang, Zhongtao Jiang, et al. 2020. MIE: Medical Information Extractor towards Medical Dialogues. In ACL. Association for Computational Linguistics, 64606469. [314] Zeyu Zhang, Xiaohe Bo, et al. 2024. Survey on the Memory Mechanism of Large Language Model based Agents. CoRR abs/2404.13501 (2024). [315] Chuang Zhao, Hui Tang, Jiheng Zhang, and Xiaomeng Li. 2025. Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases. In Proceedings of the ACM on Web Conference 2025. 17471758. [316] Chuang Zhao, Hongke Zhao, et al. 2024. Enhancing Precision Drug Recommendations via In-Depth Exploration of Motif Relationships. IEEE Transactions on Knowledge and Data Engineering 36, 12 (2024), 81648178. [317] Huiya Zhao, Yinghao Zhu, et al. 2025. ConfAgents: Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis. CoRR abs/2508.04915 (2025). [318] Wei Zhao, Maxime Peyrard, et al. 2019. MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance. In IJCNLP. Association for Computational Linguistics, 563578. [319] Xuejiao Zhao, Siyan Liu, et al. 2025. MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot. In WWW. ACM, 44424457. [320] Qiaoyu Zheng, Yuze Sun, et al. 2025. End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning. CoRR abs/2508.15746 (2025). [321] Denny Zhou, Nathanael Sch칛rli, et al. 2023. Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net. [322] Meng Zhou, Zechen Li, et al. 2021. On the Generation of Medical Dialogs for COVID-19. In IJCNLP. Association for Computational Linguistics, 886896. [323] Yuxuan Zhou, Xien Liu, et al. 2025. Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery. In ICLR. OpenReview.net. [324] Yucheng Zhou, Lingran Song, and Jianbing Shen. 2025. MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via RoleSpecialized Collaboration. In ACL. Association for Computational Linguistics, 2531925333. [325] Chenyang Zhu, Qian Wang, et al. 2024. Multiview latent space learning with progressively fine-tuned deep features for unsupervised domain adaptation. Information Sciences 662 (2024), 120223. [326] Ming Zhu, Aman Ahuja, et al. 2019. Hierarchical Attention Retrieval Model for Healthcare Question Answering. In WWW. ACM, 24722482. [327] Ming Zhu, Aman Ahuja, et al. 2020. Question Answering with Long Multiple-Span Answers. In EMNLP. Association for Computational Linguistics, 38403849. [328] Xiuqi Tommy Zhu, Heidi Cheerman, et al. 2025. Designing VR Simulation System for Clinical Communication Training with LLMs-Based Embodied Conversational Agents. In CHI EA. ACM, 181:1181:9. [329] Yinghao Zhu, Yifan Qi, et al. 2025. HealthFlow: Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research. CoRR abs/2508.02621 (2025). [330] Yakun Zhu, Shaohang Wei, et al. 2025. MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling. In NAACL. Association for Computational Linguistics, 50975116. [331] Chang Zong, Jian Wan, et al. 2025. EvidenceMap: Learning evidence analysis to unleash the power of small language models for biomedical question answering. Artif. Intell. Medicine 169 (2025), 103246. [332] Kaiwen Zuo, Zelin Liu, et al. 2025. How to make Medical AI Systems safer? Simulating Vulnerabilities, and Threats in Multimodal Medical RAG System. CoRR abs/2508.17215 (2025). Manuscript submitted to ACM"
        }
    ],
    "affiliations": [
        "College of Management and Economics, Laboratory of Computation and Analytics of Complex Management Systems(CACMS), Tianjin University, China",
        "Computer Network Information Center, Chinese Academy of Sciences, China"
    ]
}