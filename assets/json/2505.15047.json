{
    "paper_title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration",
    "authors": [
        "Yingming Pu",
        "Tao Lin",
        "Hongyu Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering systematic uncertainty reduction. Overcoming these limitations fundamentally requires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\\% compared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our \\href{https://github.com/amair-lab/PiFlow}{GitHub}."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 2 ] . [ 1 7 4 0 5 1 . 5 0 5 2 : r PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration Yingming Pu1,2 Tao Lin1 Hongyu Chen1 1Westlake University 2Zhejiang University {puyingming, lintao}@westlake.edu.cn"
        },
        {
            "title": "Abstract",
            "content": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and failure to consistently link hypotheses with evidence, thereby hindering systematic uncertainty reduction. Overcoming these limitations fundamentally requires systematic uncertainty reduction. We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties our method significantly improves discovery efficiency, reflected by 73.55% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06% compared to vanilla agent system. Overall, PiFlow serves as Plug-and-Play method, establishing novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our GitHub."
        },
        {
            "title": "Introduction",
            "content": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) have significantly impacted automated scientific discovery [33, 50, 66] across wide range of fundamental fields, including chemistry [28, 10, 58, 21], biology [52, 35, 5, 11], physics [22], and material science [47, 14, 3, 49, 65]. Although proficient in executing experiments within predefined workflows [30, 24], these systems often generate hypotheses that lack clear direction, leading to the uncertainty establishing clear links between hypotheses and their supporting or refuting evidence [1, 67, 6, 45, 39, 53]. Such disconnect indicates inefficient exploration. Moreover, many of these approaches are tailored for specific tasks, often relying on meticulous prompt engineering that heavily incorporates domain knowledge (as detailed in Appendix A). Consequently, their ability to adapt to new scientific domains is often limited without substantial modifications [64, 23]. These issues culminate in three primary challenges: (a) aimless hypothesizing; (b) unmaintained connections between hypotheses and evidence during exploration, hindering systematic validation and (c) limited generalization ability, where systems effective in one scenario (e.g., material science) often require substantial rework to be applicable in others. To address these limitations, we introduce PiFlow, an information-theoretical framework for structured uncertainty reduction in scientific discovery. Viewing scientific exploration as game against an Corresponding author. Preprint. Under review. Figure 1: Illustration of the potential of scientific principle in drug discovery. PiFlow directs exploration to prioritize hypotheses aligned with high-potential principles (or their variants), thereby iteratively guiding the discovery towards optimal candidate molecules. unknown and challenging nature, where robust strategies are paramount, PiFlow employs Min-Max optimization: minimizing cumulative regret for exploitation, and maximizing information gain for hypothesis exploration. As Plug-and-Play module, PiFlow integrates with MAS capable of hypothesizing and experimentation. Inspired by the challenge of navigating vast hypothesis spaces, PiFlow operates by using fundamental scientific principles, which may be initially proposed by or refined using LLMs, to steer the exploration. The iterative selection of principles progressively reduces uncertainty in hypothesizing and in the interpretation of evidence, dynamically steering exploration by prioritizing those scientific principles that offer the highest instructive value for continued exploration. Figure 1 illustrates PiFlows method for assessing and utilizing scientific principles within drug discovery context. This principle-aware approach yields systematic information gain: PiFlow selects high-potential principles and then guides hypothesizing via three actions, i.e., exploring, validating, or refining their scope and formulation. Thus, PiFlow progressively optimizes its guiding scientific principles to effectively steer hypothesizing. Furthermore, leveraging its Min-Max optimization, PiFlow theoretically achieves cumulative regret growth of O( ) over exploration steps. This sublinear regret underscores its guaranteed efficiency in navigating complex discovery landscapes. In summary, our contributions are: (a) We propose novel paradigm for principle-aware scientific discovery, built upon an information-theoretical foundation that offers theoretical convergence guarantees. (b) We develop PiFlow, Plug-and-Play framework that seamlessly integrates with existing MAS to enable focused exploration and exploitation, thereby enhancing discovery efficiency and operational flexibility. (c) We conduct extensive experiments across three distinct scientific discovery scenarios, demonstrating the broad applicability and significant performance improvements achieved by PiFlow."
        },
        {
            "title": "2.1 Language Models for Scientific Discovery",
            "content": "Recently, large language models (LLM) have advanced scientific discovery with automation and rational design [44, 32]. The internal knowledge of LLMs has demonstrated promising capability in focused chemical and material discovery [58, 67, 40, 12]. While tool-integrated LLMs like SciAgents [13], DARWIN [53] and HoneyComb [61] improve domain-specific reasoning and recall of factual insights, they still struggle to integrate physicochemical laws effectively when refining insights for design, risking biased proposals and inefficient exploration due to inherent hallucinations of LLMs [63]. Human-AI frameworks address this issue by leveraging the knowledge of domain experts [43, 9], yet remain limited to the scope of hypothesis generation [2], leading to insufficient exploration of complex chemical spaces [31]. Surveys highlight persistent gaps in efficiency and interpretability [66, 18], underscoring the need for principled scientific discovery management beyond automated LLM reasoning [42]."
        },
        {
            "title": "2.2 Approaches of Multi-Agent Collaboration",
            "content": "Multi-agent systems (MAS) show promise for complex tasks [30, 13, 36], yet their application to scientific discovery reveals limitations in current collaboration mechanisms [48]. Rule-based 2 methods [62] offer consistency but their predefined rules lack the flexibility to incorporate nuanced scientific principles (e.g., physicochemical laws) or adapt to unexpected findings, hindering dynamic exploration. Role-playing approaches [48, 20] leverage agent expertise, yet rigid roles can impede adaptation in scientific research [41, 30, 13], and ensuring collective adherence to scientific principles when interpreting experimental insights is challenging. Model-based methods [55, 34, 27] aim for adaptability by learning from uncertainty, but struggle to build world models that accurately capture complex scientific phenomena and integrate guiding laws [19], thereby impairing the balance between information perception and strategic, principle-guided reasoning. Consequently, existing MAS paradigms often lack dedicated awareness and systematic application of scientific principles during hypothesis generation and refinement [16, 31, 43, 46]. This highlights critical need for an explicitly principle-aware multi-agent collaboration framework. Our work addresses this gap, proposing method where the collaborative discovery process is robustly guided by scientific principles to achieve more efficient and reliable outcomes."
        },
        {
            "title": "3.1 Overview",
            "content": "We propose principle-aware Multi-Agent System (MAS) designed to enhance scientific discovery via focused hypothesizing and structured exploration of hypothesis-evidence connections. Figure 2 illustrates the architecture. Its core comprises Hypothesis-Validation loop that iteratively generates and tests hypotheses. PiFlow guides this loop by analyzing accumulated principle-outcome data. Strategic insights from PiFlow are relayed through Planner agent (AP ) to the Hypothesis Agent within the loop. Subsequent sections will elaborate on PiFlows specific architecture and its information-theoretical underpinnings."
        },
        {
            "title": "3.2 Architecture",
            "content": "Our proposed principle-aware system leverages Large Language Model (LLM)-based MAS to conduct scientific discovery through strategic hypothesizing. The framework is comprised of two core, interconnected components: (1) an MAS that executes Hypothesis-Validation loop, and (2) PiFlow, which serves as the strategic director for this loop. Definition 3.1 (Scientific Principles). The scientific principles are foundational concepts, established laws, or patterns that explain phenomena within specific scientific domain. These principles serve as high-level conceptual building blocks from which specific, testable hypotheses can be derived. This conceptualization aligns with broader discussions on the nature of scientific knowledge [38]. Hypothesis-Validation Loop. As depicted in the right-hand side of Figure 2, the HypothesisValidation loop constitutes the core operational cycle and incorporates two LLM-based agents: Hypothesis Agent (AH ) and Experiment Agent (AE), detailed below: (a) Hypothesis. Initially, set of candidate principles = {p1, p2, p3} (see Definition 3.1)potentially proposed by domain experts or extracted by LLMs, is established. In each iteration t, AH proposes testable hypothesis, ht, grounded in selected principle pi P. The proposal is supported by structured rationales (comprising major and minor premises, following [8]), rather than unconstrained association. (b) Validation. Subsequently, AE rigorously validates ht using an experimental tool, denoted (), which yields quantitative outcome yt = (ht) (e.g., property value of material). This outcome serves as feedback for subsequent hypothesizing. This iterative process progressively establishes record of principle-outcome pairs, Tt = {pk, yk}t k=1, linking each hypothesized principle pk to its observed experimental outcome yk. While this loop systematically generates valuable evidence in trajectory Tt, the selection of potential principles for subsequent hypotheses can lack strategic direction if not externally guided. This may lead to inefficient exploration of the principle space or premature convergence on suboptimal findings. Hypothesis steering with PiFlow. To address the potential inefficiencies in principle selection and to instill strategic direction, the PiFlow component is introduced. It leverages the dynamically 3 Figure 2: Overview of the PiFlow Architecture for Scientific Discovery. The PiFlow component utilizes Min-Max optimization to strategically select and direct high-potential principles to the Planner agent. The Planner, in turn, guides the Hypothesis-Validation loop, where agents iteratively generate hypotheses ht from principles pt at step t, execute experiments, and refine understanding. This iterative process is designed to efficiently navigate the discovery landscape. growing set of principle-outcome pairs, Tt as its primary input. Two steps are conducted to steer the hypothesizing: (a) High-potential principle acquisition. After an initial phase of evidence collection, during which Tt is populated, PiFlow activates its core mechanism: an adversarial Min-Max optimization (detailed in Section 3.3). This optimization process analyzes Tt to identify principle, (e.g., p2 in Figure 2), predicted to have the highest potential for advancing the scientific inquiry. (b) Principle steering for hypothesizing. Following the identification of the highest-potential principle by the Min-Max optimization, PiFlow assigns potential score to all principles in P. This scoring enables threshold-based partitioning detailed in Appendix C.1: principles with high scores (like p, e.g., p2) drive refinement; those with medium scores trigger further validation (p2 2); and low scores prompt exploration of new conceptual areas. This closed-loop feedback mechanism ensures that the Hypothesis-Validation cycle is continuously and adaptively steered by strategic insights derived from the systems cumulative experience, as embodied in Tt. Plug-and-Play Modularity of PiFlow. The hypothesis steering mechanism above, which includes PiFlow and its interfacing Planner agent AP , has been intentionally engineered as modular, Plugand-Play system. This architectural choice ensures that principle-aware guidance can be readily integrated to enhance MAS engaged in scientific discovery as part of prompts. The Planner agent, AP , serves as the critical adaptable interface, channeling analytically derived principle suggestions from PiFlow directly into the operational workflow of host MAS. This adaptability positions PiFlow as pivotal enhancement for automated scientific inquiry."
        },
        {
            "title": "3.3 Min-Max Optimization in PiFlow",
            "content": "In our proposed method, strategic principle selection is achieved through Min-Max optimization, as presented in Eq. 1. This approach is designed to balance the exploitation of established, high-potential principles (which then guide the formulation of specific hypotheses) with the exploration of novel ones, while explicitly incorporating information acquisition efficiency. min πΠ max Eπ (cid:34) (cid:88) (cid:35) (v (ht)) λ I(ht; Ht1) t=1 (1) where π Π represents the decision-making policy for selecting principles and is the evaluation function (e.g., an experimental tool) that characterizes the quantitative outcome yielded from hypothesis ht H, where is the hypothesis space. Over iterations, the policy π aims to minimize the objective function in Eq. 1. This objective strategically balances: (1) the summation for 4 cumulative regret, encouraging exploitation of known high-potential principles, and (2) the mutual information, thereby effectively maximizing information gain to foster exploration. This structure allows PiFlow to navigate the complex trade-offs between these two goals. Minimizing Cumulative Regret (Exploitation). The first term, (cid:80)T t=1(v (ht)), represents the cumulative regret over iterations. Here, is theoretical optimal outcome value, and (ht) is the outcome from hypothesis ht. By minimizing this term, the policy π is driven to exploit known high-potential principles and hypotheses to achieve outcomes as close as possible to the optimum v. This encourages the refinement and validation of promising avenues. Maximizing Information Gain (Exploration). The second term λ I(ht; Ht1) promotes exploration. The policy π seeks to minimize this term, which is equivalent to maximizing the mutual information I(ht; Ht1). This mutual information quantifies the expected reduction in uncertainty about the true evaluation function upon observing the outcome of hypothesis ht, given all past observations Ht1 = {(hm, ym)}t1 m=1. The trade-off parameter λ > 0 controls the balance between minimizing regret (exploitation) and maximizing information gain (exploration). larger λ places more emphasis on information acquisition. Remark (The dependencies of in I(ht; Ht1)) . The informativeness of proposed hypothesis ht is inherently dependent on the nature of the true underlying evaluation function . The adversarial nature of the maxf operator means that the policy π must select hypotheses ht that are expected to be informative even if were to manifest in way that makes ht minimally revealing, thus ensuring robustness in information acquisition. In summary, the Min-Max adversarial formulation underpinning PiFlow provides strong theoretical guarantees, notably sublinear regret bounds (formalized in Theorem 1, with proof in Appendix B). Importantly, PiFlows operational behavior, which involves practical approximations of this MinMax solution, demonstrates consistent alignment with these theoretical expectations, as empirically validated in Section 5.3. Theorem 1 (Informal). The Min-Max optimization in PiFlow formulates trade-off between exploitation (minimizing regret) and exploration (maximizing information gain). Under conditions of finite entropy H(f ) and bounded evaluation function , this optimization provides two key theoretical guarantees: (1) As information gain decreases, the expected regret also decreases; (2) the (cid:16) cumulative regret grows at sublinear rate of (cid:17) ."
        },
        {
            "title": "4.1 Settings",
            "content": "Simulating hypothesis validation is crucial for our experiments. However, designing individual simulation environments for each experiment is costly. Therefore, we employ surrogate models deployed locally, behaving like HTTP-based tool for the experiment agent. In our experiments, the task can be Find molecule candidate with the highest bio-activity. To address such tasks, the hypothesis agent proposes hypotheses and the experiment agent validate them using the tool, aiming to identify optimal candidates. To ensure fair comparison and focus on core capabilities, all agents utilize QwenMax [57] as the base LLM and are prohibited from accessing external search tools. The implementation details are in Appendix C.1, and role-playing prompts for all agents are provided in Appendix E. Each experiment was repeated three times with different random seeds, and we report the mean and standard deviation (std) of the relevant metrics for each method."
        },
        {
            "title": "4.2 Experimental Scenarios",
            "content": "Nanohelix Optimization (NHO, see Appendix D.1). We developed high-fidelity surrogate model (r2 = 0.98) to predict g-factor values of nanohelix material. The model was trained on DFTsimulated data [51], enabling efficient exploration of the four-dimensional parameter space (radius of fiber and helix, number of turns, etc.), describing the physical structure of standard helix. Molecular Bio-activity Optimization (MBO, see Appendix D.2). We constructed surrogate model (r2 = 0.91) to predict molecular bio-activity using 50,000 molecule-activity pairs sampled 5 from ChEMBL35 [60]. This model maps SMILES representations directly to pChEMBL values, facilitating rapid in silico screening of candidate therapeutics. Superconductor Optimization (SPO, see Appendix D.3). We constructed surrogate model (r2 = 0.91) to predict superconductors Tc using 26,321 records of superconductor data publicly available [17]. The model learns the map between the compositional features of superconductor to the Tc value, facilitating the discovery of room-temperature superconducting materials."
        },
        {
            "title": "4.3 Baselines",
            "content": "To evaluate PiFlows specific guidance strategy under uncertainty, we therefore benchmark against the following baselines: (1) Reasoning and Acting (ReAct) [59]. ReAct enables agents to iteratively formulate hypotheses, design/execute experiments, and interpret results, representing foundational approach to the scientific method loop. (2) Meta Plan Optimization (MPO) [54]. MPO utilizes an LLM planner that generates guidance based on past exploration experiences. This offers contrast to PiFlows distinct, explicit mechanism for principled uncertainty reduction. (3) Vanilla Agent System (Vanilla). Vanilla agent, where single LLM conducts the discovery process independently, serves as fundamental benchmark to illustrate the challenges of unguided exploration. While many other advanced agent frameworks exist, their core focus often differs. For instance, Agent-Oriented Planning (AOP) [26] is optimized for tasks with known structures rather than initial epistemic uncertainty, and Reason for Future, Act for Now (RAFA) [29] prioritizes predefined task completion over the iterative evidence building from scratch that PiFlow targets. Our evaluation against these baselines is designed to highlight PiFlows advantages in discovery efficiency."
        },
        {
            "title": "4.4 Evaluation Metrics",
            "content": "We employ two metrics to comprehensively evaluate the performance of PiFlow, as detailed below. Solution Quality (SQ). We measure the optimal objective value with percentage relative to the theoretical maximum value µabsolute, denoted as: SQ = max{yk pk, yk Tt} µabsolute 100%. (2) Specifically, for nanomaterial chirality with g-factor value, the theoretical maximum is reported as µg-factor absolute = 2.0, indicating total selectivity for CP light [15], the larger the g-factor, the stronger the chirality; for molecular bio-activity with pChEMBL value, strict threshold of µpchembl absolute = 6.5 has been reported [25] for lead compound optimization stage, larger value indicates better bio-activity and vice versa. for superconductivity Tc, the reference value is set to be 25C , which is equal to 298.15K, denoted as µTc absolute = 298.15K. Area Under the Curve (AUC). Exploration efficiency requires both (1) rapid convergence and (2) high objective values. We quantify these two factors by defining the AUC metric. Given the trajectory pk, yk Tt across steps, AUC is computed via the trapezoidal rule. For meaningful comparisons, we normalize by the maximum possible area: AUC = (cid:80)t1 i=1 yi+yi+1 µabsolute (t 1) 100% (3) This normalized metric captures the ability to maintain high performance throughout the optimization trajectory, with higher values indicating more efficient exploration."
        },
        {
            "title": "5.1 Performance Comparison",
            "content": "We use SQ to compare the overall capability of reaching the objective solution, and AUC to assess the efficiency, reflecting progress towards better outcomes over the exploration process. Table 1 demonstrates that PiFlow achieves significant improvements over all baselines across three benchmarks of NHO, MBO, and SPO. In terms of achieving the target property, measured by SQ, 6 Table 1: Comparisons between PiFlow and baselines. Method NHO (g-factor) MBO (pChEMBL) SPO (Tc) AUC (%) SQ (%) AUC (%) SQ (%) AUC(%) SQ (%) ReAct Vanilla MPO PiFlow (ours) 35.85 7.12 35.96 22.38 43.99 2.79 63.51 11.18 41.96 0.82 46.76 7.29 51.29 7.77 76.82 4.54 29.61 9.74 29.71 12.66 31.18 9.12 46.11 16. 43.11 9.98 49.22 8.30 57.28 5.85 84.55 29.63 5.29 0.69 11.39 11.33 12.68 7.75 21.51 2.80 6.41 0.96 14.16 13.37 33.20 23.75 34.85 1.19 Figure 3: Trajectory comparisons for different optimization methods. PiFlow consistently leads, outperforming ReAct, MPO, and Vanilla systems by an average of approximately 207.6%, 34.1%, and 94.1%. Furthermore, PiFlow demonstrates superior exploration efficiency, evidenced by its leading AUC scores, translating to average AUC improvements of approximately 146.5% over ReAct, 73.6% over Vanilla and 54.0% over MPO. Additionally, we compare the exploration trajectory regarding the experiment outcome, as presented in Figure 3. It shows that, PiFlow is always the fastest one in reaching the best solution while exploring. Although there are some fluctuations in the process, the general upward trend continues to surpass other methods. These significant advancements in both SQ and AUC strongly support our central claim: the strategic and principled guidance provided by the PiFlow component, rooted in its principle-aware optimization, effectively steers the multi-agent hypothesis-validation loop towards more rapid and fruitful scientific discovery."
        },
        {
            "title": "5.2 Ablation Study",
            "content": "We conduct several ablations to evaluate the components of PiFlow. The studies investigate the impact of PiFlow itself, the choice of foundation LLMs, the influence of key hyperparameter λ, which is for balancing exploitation and exploration, and the effect of the Thought mode in LLM reasoning. For these studies, conducted on the NHO task, performance is evaluated based on the same metrics, AUC (%) and SQ (%). Impact of PiFlow Integration (Plug-and-Play). To isolate the direct benefit of PiFlow, we compared the performance of two different LLMs, GPT4.1-mini and Qwen3-32B, w/ and w/o the PiFlow component. This is achieved by only including or excluding the steered principle with one of the three specified action types to the Planner Agent via prompt, which then directs subsequent hypothesizing and validation. Table 2: Ablation Study with/without PiFlow As shown in Table 2, for GPT4.1-mini, integrating PiFlow increases the AUC from 37.12% to 41.68% and substantially boosted the SQ from 40.14% to 66.38%. This represents an approximate 12.3% improvement in AUC and significant 65.4% improvement in SQ. Similarly, for the Qwen3-32B model, the inclusion of PiFlow improves AUC from 27.04% to 37.51% (a 38.7% increase) and SQ from 54.84% to 58.76% (a 7.1% increase). Takeaway: These findings underscore the significant positive impact of PiFlow on both AUC and SQ, confirming its effectiveness as Plug-and-Play enhancement for MAS in scientific discovery. 66.38 14.90 40.14 13.97 58.76 6.18 54.84 24.41 41.68 17.91 37.12 16.04 37.51 7.70 27.04 21. w/ PiFlow w/o PiFlow w/ PiFlow w/o PiFlow Method/Setting GPT4.1-mini Qwen3-32B AUC (%) SQ (%) 7 Influence of Foundation Models. The choice of underlying LLMs may significantly affect the reasoning process, thereby affecting the performance. To evaluate the model influence while balancing the agent functions, we replace LLMs of AH and AP evaluation. The AEresponsible for tool usage, consistently used QwenMax to ensure functional tool interaction. We evaluate several state-of-the-art LLMs (e.g., Claude-3.7-sonnet [4], GPT4.1-mini [37], Gemini-2.5-pro-exp-0325 [7], Qwen3-32B and QwenMax [56]) on the NHO task, and the results are summarized in Table 3. Table 3: Model Performance Comparison Among these models, QwenMax demonstrates the highest AUC at 63.51% and strong SQ of 76.82%. Claude-3.7-sonnet achieves the highest SQ at 78.50% with an AUC of 38.60%. Other models like GPT4.1-mini (AUC 41.68%, SQ 66.38%) and Qwen3-32B (AUC 37.51%, SQ 58.76%) also show competent performance. Gemini-2.5-pro-exp-03-25 yields an AUC of 28.43% and an SQ of 69.64%. Takeaway: The performance variation across different models highlights the importance of model selection for specific tasks within the PiFlow-enhanced MAS. Claude-3.7-sonnet GPT4.1-mini Gemini-2.5-pro-exp-03-25 Qwen3-32B QwenMax 78.50 3.74 66.38 14.90 69.64 17.10 58.76 6.18 76.82 4. 38.60 4.30 41.68 17.91 28.43 13.81 37.51 7.70 63.51 11.18 Method/Setting AUC (%) SQ (%) Sensitivity to Hyperparameter λ. We investigate the impact of λ in Eq. 1. The specific role of λ is to balance exploration and exploitation, with larger lambda value places greater emphasis on exploration. The results conducted on the NHO task using QwenMax model for different values of λ are detailed in Table 4. Table 4: Lambda Ablations From the table, AUC varied with different λ values, peaking at 44.28% when λ = 0.3. The SQ remained relatively high for λ = 0.1 (66.45%) and λ = 0.3 (66.43%), but showed more variability with other settings. For instance, λ = 0.5 resulted in lower AUC (32.99%) and SQ (59.02%). While increasing λ, AUC tends to decrease, as stronger emphasis on exploration can lead to more varied hypothesis selection. These results suggest that the systems performance, particularly its exploration efficiency, is sensitive to the choice of λ, with λ = 0.3 appearing to offer good balance for the NHO task with the QwenMax model. Takeaway: The results suggest that λ indeed effects the performance in both AUC and SQ, fine-tuning λ can be crucial for optimizing performance. 41.32 5.90 44.28 2.83 32.99 11.16 40.50 2.89 34.57 10.33 66.45 9.49 66.43 9.28 59.02 3.56 56.40 4.79 62.49 8.38 λ = 0.1 λ = 0.3 λ = 0.5 λ = 0.7 λ = 0.9 AUC (%) SQ (%) Setting Effect of Thought Mode. We also conducted an ablation study on an internal thought mode of the LLM (referred to as Think in Table 5) on the NHO benchmark. This is for agents based on Qwen3-32B and Qwen3-8B models, which support ON/OFF <think> token generation with system prompt including or excluding /no_think. This mode is intended to enable more explicit reasoning steps. Table 5: Effect of Thinking. Interestingly, for both Qwen3-32B and Qwen38B, disabling the Thought Mode led to improved performance. For Qwen3-32B, removing the Thought Mode increased AUC from 37.51% to 45.51% and SQ from 58.76% to 68.86%. Similarly, for Qwen3-8B, performance without the Thought Mode was better, with AUC rising from 30.55% to 42.09% and SQ increasing from 54.49% to 61.59%. Takeaway: These counter-intuitive results suggest that the current implementation or utility of this specific Thought Mode may introduce overhead or misguide the agents in these contexts, warranting further investigation into its design and application. 30.55 27.45 42.09 16.55 54.49 22.25 61.59 16. 37.51 7.70 45.51 11.19 58.76 6.18 68.86 17.67 w/ Think w/o Think w/ Think w/o Think Method/Setting Qwen3-32B Qwen3-8B AUC (%) SQ (%)"
        },
        {
            "title": "5.3 Theoretical Alignment",
            "content": "To empirically validate PiFlows theoretical guarantees (Theorem 1), we analyze key aspects of its exploration dynamics, including (1) the bound of average regret in PiFlow and (2) the relationship between regret and information gain, as shown in Figure 4. 8 (a) Average Regret Dynamics (b) Regret vs. Information Gain (c) NHO Exploration Trajectory Figure 4: Empirical Validation of PiFlows Theoretical Alignment. (a) Average regret over iterations aligns with the theoretical sublinear decay; (b) Scatter plot with positive trend of observed regret versus information gain, supporting theoretical expectations; (c) An exemplary PiFlow exploration trajectory. (Theoretical Prediction 1) Average regret decay with . Figure 4a presents the average regret as function of iterations on log-log scale. The empirical results demonstrate strong concordance with the theoretical prediction of O( ) sublinear cumulative regret. This is evidenced by average regret trajectories adhering to the 0.5 decay (fitted 0.5 with = 1.37, R2 = 0.96), pattern most runs consistently follow. Notably, one run (ID=1), after an initial sharp regret decrease, shows transient increase before resuming decay. This illustrates PiFlows robust exploration avoiding potential local optima with characteristic of its Min-Max strategy. (cid:16) 1 (cid:17) (Theoretical Prediction 2) As information gain decreases, the expected regret also decreases. Theorem 1 also posits that decreasing information gain correlates with decreasing expected regret. Figure 4b empirically verifies this with PiFlow. The scatter plot of regret versus information gain (points colored by iteration) reveals clear positive association, confirmed by fitted trend line: lower information gain generally corresponds to lower regret. Early iterations (higher information gain and regret) transition to later iterations (lower information gain and regret). This empirical trend strongly supports the theoretical analysis, showcasing PiFlows effective shift from exploration to exploitation. Empirical Validation of Exploration Strategy on NHO Landscape. To further illustrate PiFlows operational dynamics, Figure 4c visualizes an exemplary exploration trajectory on the NHO task. The objective is to identify nanohelix parameters yielding the maximum property value. The background displays the NHO objective landscape by Principal Component Analysis (PCA), where contours indicate g-factor values fitted over the source data. Aligning with its robust design, PiFlows trajectory shows initial broad exploration (iterations 116), then successful navigation of low-quality valley (iterations 16-21) crucial for avoiding local optima, before efficiently converging to high-g-factor region and identifying near-optimal parameters (iterations 21-24). Takeaway: The above regret analysis and visualized behavior empirically support the claim that PiFlows principle-aware mechanism translates its theoretical guarantees into effective and efficient scientific discovery."
        },
        {
            "title": "6 Limitation",
            "content": "While PiFlow shows notable improvements through its principled Min-Max optimization, its practical implementation approximates key theoretical component. This means the current system may not fully capture all nuances of true, model-based information gain, especially the direct adversarial interplay with all possible manifestations of the unknown evaluation function from the theoretical objective. Future research could explore more direct estimations of mutual information for this heuristic within the PiFlow framework to potentially further enhance its strategic guidance."
        },
        {
            "title": "7 Conclusion",
            "content": "In conclusion, we propose PiFlow, Plug-and-Play module to strategically guide the HypothesisValidation loop through principle-steering mechanism to address challenges of aimless hypothesis 9 searching and unclear connections between hypotheses and evidence. Our approach utilizes MinMax optimization that explicitly balances exploitation of high-potential principles with exploration of novel hypotheses, guaranteed by sublinear average regret bound. Extensive experiments demonstrate that PiFlow can adaptively navigate complex hypothesis spaces without premature convergence on suboptimal solutions, yielding significant improvements over baseline methods. In addition, PiFlow enhanced process demonstrates remarkable ability in avoiding local optima, yet keeping structured rationales for better interpretability. We hope PiFlow can contribute to advancing automated scientific discovery, inspiring further exploration and innovation."
        },
        {
            "title": "References",
            "content": "[1] M. R. AI4Science and M. Quantum. The impact of large language models on scientific discovery: preliminary study using gpt-4. ArXiv, abs/2311.07361, 2023. [2] A. K. Alkan, S. Sourav, M. Jabłonska, S. Astarita, R. Chakrabarty, N. Garuda, P. Khetarpal, M. Pioro, D. Tanoglidis, K. G. Iyer, M. S. Polimera, M. J. Smith, T. Ghosal, M. Huertas-Company, S. Kruk, K. Schawinski, and I. Ciucua. survey on hypothesis generation for scientific discovery in the era of large language models. 2025. [3] M. Ansari, J. Watchorn, C. E. Brown, and J. S. Brown. dziner: Rational inverse design of materials with ai agents. 2024. [4] Anthropic. Claude 3.7 sonnet, 2025. [5] R. Averly, F. N. Baker, and X. Ning. Liddia: Language-based intelligent drug discovery agent. ArXiv, abs/2502.13959, 2025. [6] J. Baek, S. K. Jauhar, S. Cucerzan, and S. J. Hwang. Researchagent: Iterative research idea generation over scientific literature with large language models. ArXiv, abs/2404.07738, 2024. [7] G. DeepMind. Gemini 2.5 pro experimental, 2025. [8] T. Eisape, M. Tessler, I. Dasgupta, F. Sha, S. van Steenkiste, and T. Linzen. systematic comparison of syllogistic reasoning in humans and language models. ArXiv, abs/2311.00445, 2023. [9] D. Eythorsson and M. Clark. Toward automated scientific discovery in hydrology: The opportunities and dangers of ai augmented research frameworks. Hydrological Processes, 2025. [10] A. Ghafarollahi and M. J. Buehler. Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. ArXiv, abs/2407.10022, 2024. [11] A. Ghafarollahi and M. J. Buehler. Protagents: protein discovery via large language model multi-agent collaborations combining physics and machine learning. Digital Discovery, 3:1389 1409, 2024. [12] A. Ghafarollahi and M. J. Buehler. Rapid and automated alloy design with graph neural network-powered llm-driven multi-agent systems. ArXiv, abs/2410.13768, 2024. [13] A. Ghafarollahi and M. J. Buehler. Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning. ArXiv, abs/2409.05556, 2024. [14] A. Ghafarollahi and M. J. Buehler. Automating alloy design and discovery with physics-aware multimodal multiagent ai. Proceedings of the National Academy of Sciences of the United States of America, 122 4:e2414074122, 2025. [15] J. L. Greenfield, J. Wade, J. R. Brandt, X. Shi, T. J. Penfold, and M. J. Fuchter. Pathways to increase the dissymmetry in the interaction of chiral light and chiral molecules. Chemical Science, 12:8589 8602, 2021. [16] M. Gridach, J. Nanavati, K. Z. E. Abidine, L. Mendes, and C. Mack. Agentic ai for scientific discovery: survey of progress, challenges, and future directions. arXiv preprint arXiv:2503.08979, 2025. [17] K. Hamidieh. data-driven statistical model for predicting the critical temperature of superconductor. Computational Materials Science, 2018. [18] Y. Han, Z. Wan, L. Chen, K. Yu, and X. Chen. From generalist to specialist: survey of large language models for chemistry. ArXiv, abs/2412.19994, 2024. 10 [19] S. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu. Reasoning with language model is planning with world model. ArXiv, abs/2305.14992, 2023. [20] J. He, C. Treude, and D. Lo. Llm-based multi-agent systems for software engineering: Vision and the road ahead. ArXiv, abs/2404.04834, 2024. [21] Y. Inoue, T. Song, and T. Fu. Drugagent: Explainable drug repurposing agent with large language model-based reasoning. ArXiv, abs/2408.13378, 2024. [22] R. Jaiswal, D. Jain, H. Popat, A. Anand, A. Dharmadhikari, A. Marathe, and R. R. Shah. Improving physics reasoning in large language models using mixture of refinement agents. ArXiv, abs/2412.00821, 2024. [23] S. Kumbhar, V. Mishra, K. Coutinho, D. Handa, A. Iquebal, and C. Baral. Hypothesis generation for materials discovery and design using goal-driven and constraint-guided llm agents. ArXiv, abs/2501.13299, 2025. [24] R. Z. Lai and Y. Pu. Prim: Principle-inspired material discovery through multi-agent collaboration. In AI for Accelerated Materials Design - ICLR 2025, 2025. [25] E. B. Lenselink, N. ten Dijke, B. J. Bongers, G. Papadatos, H. W. T. van Vlijmen, W. Kowalczyk, A. P. IJzerman, and G. V. van Westen. Beyond the hype: deep neural networks outperform established methods using chembl bioactivity benchmark set. Journal of Cheminformatics, 9, 2017. [26] A. Li, Y. Xie, S. Li, F. Tsung, B. Ding, and Y. Li. Agent-oriented planning in multi-agent systems. ArXiv, abs/2410.02189, 2024. [27] H. Li, Y. Q. Chong, S. Stepputtis, J. Campbell, D. Hughes, M. Lewis, and K. P. Sycara. Theory of mind for multi-agent collaboration via large language models. In Conference on Empirical Methods in Natural Language Processing, 2023. [28] S. Liu, Y. Lu, S. Chen, X. Hu, J. Zhao, T. Fu, and Y. Zhao. Drugagent: Automating ai-aided drug discovery programming through llm multi-agent collaboration. ArXiv, abs/2411.15692, 2024. [29] Z. Liu, H. Hu, S. Zhang, H. Guo, S. Ke, B. Liu, and Z. Wang. Reason for future, act for now: principled framework for autonomous llm agents with provable sample efficiency. ArXiv, abs/2309.17382, 2023. [30] C. Lu, C. Lu, R. T. Lange, J. N. Foerster, J. Clune, and D. Ha. The ai scientist: Towards fully automated open-ended scientific discovery. ArXiv, abs/2408.06292, 2024. [31] Z. Luo, Z. Yang, Z. Xu, W. Yang, and X. Du. Llm4sr: survey on large language models for scientific research. 2025. [32] P. Ma, T.-H. Wang, M. Guo, Z. Sun, J. B. Tenenbaum, D. Rus, C. Gan, and W. Matusik. Llm and simulation as bilevel optimizers: new paradigm to advance physical scientific discovery. ArXiv, abs/2405.09783, 2024. [33] S. Minaee, T. Mikolov, N. Nikzad, M. A. Chenaghlu, R. Socher, X. Amatriain, and J. Gao. Large language models: survey. ArXiv, abs/2402.06196, 2024. [34] Y. Mu, W. Liu, T. Lu, J. Li, S. Gao, and Z. Wang. Runtime verification of self-adaptive multi-agent system using probabilistic timed automata. J. Intell. Fuzzy Syst., 45:1030510322, 2023. [35] V. Nagarajan, G. Shi, R. Horai, C.-R. Yu, J. Gopalakrishnan, M. Yadav, M. H. Liew, C. Gentilucci, and R. R. Caspi. Ian: An intelligent system for omics data analysis and discovery. bioRxiv, 2025. [36] B. Ni and M. J. Buehler. Mechagents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge. ArXiv, abs/2311.08166, 2023. [37] OpenAI. Gpt-4.1, 2025. [38] H. Poincaré. Science and hypothesis. 1906. [39] V. Prabhakar, M. A. Islam, A. Atanas, Y.-T. Wang, J. Han, A. Jhunjhunwala, R. Apte, R. Clark, K. Xu, Z. Wang, and K. Liu. Omniscience: domain-specialized llm for scientific reasoning and discovery. 2025. [40] Y. Pu, L. Huang, T. Lin, and H. Chen. Leveraging large language models for explaining material synthesis mechanisms: The foundation of materials discovery. In AI for Accelerated Materials Design - NeurIPS 2024, Nov. 2024. [41] J. Ramirez-Medina, M. Ataei, and A. Amirfazli. Accelerating scientific research through multi-llm framework. 2025. [42] M. C. Ramos, C. J. Collison, and A. D. White. review of large language models and autonomous agents in chemistry. Chemical science, 2024. [43] C. K. Reddy and P. Shojaee. Towards scientific discovery with generative ai: Progress, opportunities, and challenges. ArXiv, abs/2412.11427, 2024. [44] S. Ren, P. Jian, Z. Ren, C. Leng, C. Xie, and J. Zhang. Towards scientific intelligence: survey of llm-based scientific agents. ArXiv, abs/2503.24047, 2025. [45] S. Schmidgall, Y. Su, Z. Wang, X. Sun, J. Wu, X. Yu, J. Liu, Z. Liu, and E. Barsoum. Agent laboratory: Using llm agents as research assistants. ArXiv, abs/2501.04227, 2025. [46] H. Su, R. Chen, S. Tang, Z. Yin, X. Zheng, J. Li, B. Qi, Q. Wu, H. Li, W. Ouyang, P. Torr, B. Zhou, and N. Dong. Many heads are better than one: Improved scientific idea generation by llm-based multi-agent system. 2024. [47] I. Takahara, T. Mizoguchi, and B. Liu. Accelerated inorganic materials design with generative ai agents. 2025. [48] K.-T. Tran, D. Dao, M.-D. Nguyen, Q.-V. Pham, B. OSullivan, and H. D. Nguyen. Multi-agent collaboration mechanisms: survey of llms. ArXiv, abs/2501.06322, 2025. [49] Y. Wan, T. Xie, N. Wu, W. Zhang, C. Kit, and B. Hoex. From tokens to materials: Leveraging language models for scientific discovery. ArXiv, abs/2410.16165, 2024. [50] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J. Tang, X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. rong Wen. survey on large language model based autonomous agents. Frontiers Comput. Sci., 18:186345, 2023. [51] J. Wu, Y. Pu, J. Wang, B. Gu, X. Chen, and H. Chen. Machine learned structure-property correlation between nanohelices and circular dichroism. Advanced Optical Materials, 2025. [52] Y. Xiao, J. Liu, Y. Zheng, X. Xie, J. Hao, M. Li, R. Wang, F. Ni, Y. Li, J. Luo, S. Jiao, and J. Peng. Cellagent: An llm-driven multi-agent framework for automated single-cell data analysis. bioRxiv, 2024. [53] T. Xie, Y. Wan, W. Huang, Z. Yin, Y. Liu, S. Wang, Q. Linghu, C. Kit, C. Grazian, W. Zhang, I. Razzak, and B. Hoex. Darwin series: Domain specific large language models for natural science. ArXiv, abs/2308.13565, 2023. [54] W. Xiong, Y. Song, Q. Dong, B. Zhao, F. Song, X. Wang, and S. Li. Mpo: Boosting llm agents with meta plan optimization. ArXiv, abs/2503.02682, 2025. [55] L. Xu, Z. Hu, D. Zhou, H. Ren, Z. Dong, K. Keutzer, S.-K. Ng, and J. Feng. Magic: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration. In Conference on Empirical Methods in Natural Language Processing, 2023. [56] A. Yang et al. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115, 2024. [57] A. Yang, B. Yang, B. Hui, B. Zheng, B. Yu, C. Zhou, C. Li, C. Li, D. Liu, F. Huang, G. Dong, H. Wei, H. Lin, J. Tang, J. Wang, J. Yang, J. Tu, J. Zhang, J. Ma, J. Xu, J. Zhou, J. Bai, J. He, J. Lin, K. Dang, K. Lu, K.-Y. Chen, K. Yang, M. Li, M. Xue, N. Ni, P. Zhang, P. Wang, R. Peng, R. Men, R. Gao, R. Lin, S. Wang, S. Bai, S. Tan, T. Zhu, T. Li, T. Liu, W. Ge, X. Deng, X. Zhou, X. Ren, X. Zhang, X. Wei, X. Ren, Y. Fan, Y. Yao, Y. Zhang, Y. Wan, Y. Chu, Z. Cui, Z. Zhang, and Z.-W. Fan. Qwen2 technical report. ArXiv, abs/2407.10671, 2024. [58] Z. Yang, W. Liu, B. Gao, T. Xie, Y. Li, W. Ouyang, S. Poria, E. Cambria, and D. Zhou. Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. ArXiv, abs/2410.07076, 2024. [59] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao. React: Synergizing reasoning and acting in language models. ArXiv, abs/2210.03629, 2022. [60] B. Zdrazil, E. Felix, F. Hunter, E. J. Manners, J. Blackshaw, S. Corbett, M. de Veij, H. Ioannidis, D. M. Lopez, J. F. M. Mosquera, M. P. Magariños, N. Bosc, R. Arcila, T. Kizilören, A. Gaulton, A. P. Bento, M. F. Adasme, P. Monecke, G. A. Landrum, and A. R. Leach. The chembl database in 2023: drug discovery platform spanning multiple bioactivity data types and time periods. Nucleic Acids Research, 52:D1180 D1192, 2023. 12 [61] H. Zhang, Y. Song, Z. Hou, S. Miret, and B. Liu. Honeycomb: flexible llm-based agent system for materials science. In Conference on Empirical Methods in Natural Language Processing, 2024. [62] J. Zhang, X. Xu, R. Liu, and S. Deng. Exploring collaboration mechanisms for llm agents: social psychology view. ArXiv, abs/2310.02124, 2023. [63] M. Zhang, O. Press, W. Merrill, A. Liu, and N. A. Smith. How language model hallucinations can snowball. ArXiv, abs/2305.13534, 2023. [64] Q. Zhang, K. Ding, T. Lv, X. Wang, Q. Yin, Y. Zhang, J. Yu, Y. Wang, X. Li, Z. Xiang, Z. Xiang, Z. Wang, M. Qin, M. Zhang, J. Zhang, J. Cui, R. Xu, H. Chen, X. Fan, H. Xing, and H. Chen. Scientific large language models: survey on biological & chemical domains. ACM Computing Surveys, 2025. [65] Q. Zhang, Y. Hu, J. Yan, H. Zhang, X. Xie, J. Zhu, H. Li, X. Niu, L. Li, Y. Sun, and W. Hu. Large language model-based ai agent for organic semiconductor devices research. Advanced materials, page e2405163, 2024. [66] Y. Zhang, X. Chen, B. Jin, S. Wang, S. Ji, W. Wang, and J. Han. comprehensive survey of scientific large language models and their applications in scientific discovery. In Conference on Empirical Methods in Natural Language Processing, 2024. [67] Y. Zhou, H. Liu, T. Srivastava, H. Mei, and C. Tan. Hypothesis generation with large language models. ArXiv, abs/2404.04326, 2024."
        },
        {
            "title": "Broader Impact",
            "content": "PiFlow addresses critical bottlenecks in AI-driven scientific discovery where uncertainty leads to aimless exploration. Our method innovatively frames discovery as structured uncertainty reduction problem. By using an information-theoretic approach within hypothesis-validation loop, PiFlow systematically filters for instructive scientific principles. Ultimately, PiFlow establishes new paradigm for automated research, enabling more targeted exploration and accelerating the generation of impactful scientific insights. In Materials Discovery, it speeds the identification of novel compounds like advanced nanomaterials or superconductors, as shown in our tasks. For Biological Discovery, it enhances the search for effective molecules and the understanding of complex systems. Its principles promise similar advancements in other data-intensive fields, from chemistry to medical sciences, facing vast and uncertain hypothesis spaces."
        },
        {
            "title": "A Comparison of Limitations",
            "content": "While existing methods of LLM-based agent systems demonstrate significant impact in advancing scientific discovery, they limited to direct application in other domains without any changes of architectures and prompts. Table 6: Comparison of Generalization Limitations in LLM-Agent Systems Method Name Core Implementation The AI Scientist [30] Agent [45] Laboratory CellAgent [52] DrugAgent [28] IAN [35] Alloy Design AI [14] Inorganic Materials AI [47] LIDDIA [5] dZiner [3] MOOSE-Chem [58] OmniScience [39] Organic Semiconductor AI [65] DrugAgent (Explainable) [21] ProtAgents [11] Generating novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing full scientific paper Accepting human-provided research idea and progressing through three stages literature review, experimentation, and report writing to produce comprehensive research outputs, including code repository and research report Constructing LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities Employing an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas Leveraging popular pathway and regulatory datasets for protein-protein interactions to perform analysis through LLM-based multi-agent architecture Automating alloy design and discovery using physicsaware multimodal multi-agent AI Accelerating inorganic materials design using generative AI agents. Language-based intelligent agent for drug discovery tasks. Rational inverse design of materials facilitated by AI agents. Utilizing Large Language Models for rediscovering unseen chemistry scientific hypotheses. Domain adaptive pretraining, instruction tuning and reasoning-based knowledge distillation Large Language Model-Based AI Agent for research in organic semiconductor devices Explainable drug repurposing agent with Large Language Model-based reasoning Protein discovery via large language model multi-agent collaborations combining physics and machine learning Adaptability AI research AI research scRNA-seq Analysis Drug discovery Protein-protein interactions analysis Alloy design and discovery Inorganic materials design Drug discovery Inverse design of materials Chemistry hypothesis discovery Scientific reasoning Organic semiconductor device research Drug repurposing Protein discovery 14 To illustrate the challenge of limited generalization, Table 6 outlines several representative LLMbased agent methods. It highlights how their core implementations and prompt engineering strategies are often tightly coupled to specific scenarios, thereby restricting their out-of-the-box applicability to new or diverse problem domains. This tight coupling necessitates significant modifications when attempting to transfer these systems to different contexts, underscoring key area for future research and development in creating more adaptable and universally applicable AI agents."
        },
        {
            "title": "B The Proof of the Convergence",
            "content": "We recall the elements here and formally proof the convergence along with boundary of the system. Here we denote π is the language model policy from policy space Π, is the acquisition function from function space F, ht is the hypothesis at time step t, Ht1 = {h1, h2, . . . , ht1} is the history of hypotheses, is the SQ achievable by any hypothesis, and I(ht; Ht1) is the conditional mutual information. According to the original formulation (Eq. 1), the cumulative regret can be expressed as RT (π, ) = Eπ and the cumulative information gain is IGT (π, ) = Eπ t= (cid:34) (cid:88) t=1 (cid:34) (cid:88) (v (ht)) (cid:35) (cid:35) I(ht; Ht1) Information gain approaches zero. With information theory, the mutual information can be written as: I(ht; Ht1) = H(f Ht1) H(f Ht1, ht) critical property for convergence is that the total information gain is bounded, (cid:88) t=1 I(ht; Ht1) H(f ) < This follows from the chain rule of mutual information, (cid:88) t= I(ht; Ht1) = I(HT ; ) H(f ) Since the entropy H(f ) is finite, the cumulative information gain is bounded regardless of how many steps we take. This implies that: lim I(ht; Ht1) = 0. In other words, the marginal information gained from each new hypothesis must eventually approach zero. As information gain decreases, the expected regret also decreases. As we mentioned before, the regret RT (π, ) is defined as: RT (π, ) = ET [v (ht)]. Now apply Jensens Inequality, let = (ht), we have E[X 2 Ht1] = E[(v (ht))2 Ht1]. 15 Use ϕ(x) = x2, as it is convex, giving (E[X Ht1])2 E[X 2 Ht1], take square roots: E[v (ht) Ht1] (cid:112)E[(v (ht))2 Ht1]. Now we deal with the second moment of the regret. As the is constant, therefore, with the variance formula, we have (cid:2)(v (ht))2 Ht1 (cid:3) = Var(f (ht) Ht1) + (v E[f (ht) Ht1])2 Both terms (variance and bias) are non-negative, and our goal is to bound this expression. The variance term Var(f (ht) Ht1) captures the uncertainty in (ht) given the history. Since the information theory proofed that, the variance of function can be bounded by mutual information, akin to entropy bounds H(f ) log(F), for the first term, we have Var(f (ht) Ht1) I(ht; Ht1), where is constant that depends on the range of , this follows because the mutual information bounds the expected variance of conditional expectations. Since we can direct view the (ht) as random variable over the joint distribution of and ht, we can apply concentration inequality. standard result in information-directed sampling states that for bounded random variable like (ht) here, the second moment of the regret (v (ht)) can be bounded as: (cid:2)(v (ht))2 Ht1 (cid:3) I(ht; Ht1), where the constant depends on F. Finally, we get the inequality of RT (π, ): RT (π, ) (cid:112)ET [(v (ht))2 Ht1] (cid:112)I(ht; Ht1) This inequality demonstrates that as the information gain I(ht; Ht1) decreases, the expected regret also diminishes. The cumulative regret grows at rate O( the cumulative regret bound, we need to sum this inequality over all time steps: ). Based on the inequality in the last step and to find (cid:88) t=1 Rt(π, ) (cid:88) t=1 (cid:112)I(ht; Ht1) Applying the Cauchy-Schwartz inequality: (cid:88) t=1 (cid:112)I(ht; Ht1) (cid:118) (cid:117) (cid:117) (cid:116)T (cid:88) t=1 I(ht; Ht1) Since weve already established that the total information gain is bounded: (cid:88) I(ht; Ht1) H(f ) We can substitute this bound: t= (cid:88) t=1 (cid:112)I(ht; Ht1) (cid:112)T H(f ) Therefore, the cumulative regret is bounded by: (cid:88) t= Rt(π, ) (cid:112)T H(f ) This demonstrates that the cumulative regret grows at rate of O( ), which is sublinear in . This result implies that while the total regret increases with step, the average regret per time step decreases at rate of O( 1 )."
        },
        {
            "title": "C Implementation Details",
            "content": "C.1 Algorithm of PiFlow Algorithm 1: Algorithm of the PiFlow Policy Input: Tt, and λf actor Output: suggestion (string action recommendation) return Initialize one principle to explore. 1 if < 3 then 2 3 end 4 Sexploration compute_exploration_scores(Tt) // Not enough principles 5 Sexploitation compute_exploitation_scores(Tt) // Embedding differences to others with cosine similarity // yt in Tt as exploitation score for each pt Sf inal[i] (1 λ) Sexploration[i] + λ Sexploitation[i] 6 for 1 to do 7 8 end 9 ibest arg maxi(Sf inal[i]) 10 pbest [ibest] 11 best_exploitation_score Sexploitation[ibest] // Score for the chosen principle 12 if best_exploitation_score > 0.7 then 13 action_type refine suggestion Focus on refining: pbest.content High potential. 14 15 else if best_exploitation_score > 0.4 then 16 action_type validate suggestion Validate: pbest.content Moderate potential. // REFINE 18 else 19 20 action_type explore suggestion Explore alternatives: pbest.content Low current potential // VALIDATE // EXPLORE 21 end 22 return suggestion"
        },
        {
            "title": "D Experiment Environment",
            "content": "D.1 Nanohelix Optimization D.1.1 Problem Statement Nanohelices are helical nanostructures with unique physical properties that make them valuable for applications in electronics, photonics, and magnetism. Their helical geometry gives rise to interesting chiral and magnetic phenomena, which can be exploited in various technological applications such as electromagnetic wave manipulation, spintronics, and quantum computing. Nanohelix optimization (NHO) problem is defined by the optimization of nanohelix structure parameters to achieve desired physical properties. In this work, we specifically focus on maximizing the g-factor, magnetic property that characterizes the ratio of the magnetic moment to the angular momentum of the nanohelix. The nanohelix structure is characterized by four key geometric parameters: Figure 6: The demonstrated changes of helix parameters and their property value (g-factor). Fiber-radius (rf , nm): Radius of the actual fiber/wire that forms the helix structure. The values for this parameter range from 20 nm to 60 nm, with 10 evenly spaced values. Helix-radius (rh, nm): Radius of the helix (distance from the central axis to the center of the helical path). The values for this parameter range from 20 nm to 90 nm, with 10 evenly spaced values. Number of turns (nt, dimensionless): Number of complete turns in the helix. The values for this parameter range from 3 to 10, with 10 evenly spaced values. Pitch (p, nm): Axial distance between adjacent turns. The values for this parameter range from 60 nm to 200 nm, with 10 evenly spaced values. Mathematically, we can formulate the optimization problem as: arg max θΘ (θ) where θ = (rf , rh, nt, p) Θ, represents the set of structural parameters, and (θ) is the g-factor value resulting from these parameters. The g-factor can be calculated through density functional theory (DFT) simulations, but these are computationally expensive, motivating the need for surrogate model. The modification of these parameters, as an example, can be seen at Figure 6. D.1.2 Development The dataset contains 6300 records of nanohelix structural parameters with corresponding g-factor values. This comprehensive dataset spans the entire parameter space defined above, providing solid foundation for our machine learning approach. We follow the methodology proposed in the original paper to train LightGBM model with hyperparameter optimization. The model was trained using 80% 18 Figure 5: The r2 of the surrogate model. of the dataset with 5-fold cross-validation, while the remaining 20% was reserved for testing. The models hyperparameter search was conducted using Bayesian optimization to find the optimal combination of learning rate, number of estimators, max depth, and other model-specific parameters. This optimized LightGBM model achieved coefficient of determination (r2) of 0.9802, as shown in Figure 5, indicating that the model explains 98.02% of the variance in the g-factor prediction given any structural parameters. This high level of accuracy enables reliable exploration of the parameter space without requiring computationally expensive DFT simulations for each parameter combination. D.2 Bio-activity Optimization D.2.1 Problem Statement Molecular bio-activity refers to the ability of chemical compound to interact with biological targets, such as proteins, enzymes, or receptors, and induce biological response. This property is fundamental in drug discovery and development, as it determines molecules potential therapeutic efficacy. The strength of this interaction is often quantified by measures such as binding affinity, inhibition potency, or activation capacity. Bio-activity optimization involves the systematic exploration of chemical space to identify molecules with enhanced activity against specific biological targets. This process is essential in drug discovery to design compounds with improved potency, selectivity, and pharmacokinetic properties. Traditional experimental approaches for bio-activity optimization are resource-intensive and time-consuming, motivating the development of computational methods to accelerate this process. We use the public dataset ChEMBL35 for building surrogate model. Here, the bio-activity is quantified by the pChEMBL value, which is negative logarithmic measure of the molar concentration representing the compounds activity. Higher pChEMBL values indicate stronger bio-activity. We can formulate the optimization problem as: arg max θΘ (θ) where θ represents the molecular structure encoded as graph, Θ is the feasible chemical space, and (θ) is the surrogate model that predicts the pChEMBL value for given molecule. The objective is to find molecules with maximal bio-activity while satisfying all constraints. D.2.2 Development We randomly sampled 50,000 molecules from the ChEMBL35 database. It includes pair-wise records of molecule SMILES and pChEMBL values. To predict bio-activity from molecular structures, we developed Graph Neural Network (GNN) model that operates directly on the molecular graph constructed from SMILES strings. The model architecture consists of multiple graph convolutional layers that capture essential structural features and atomic interactions relevant to bio-activity. Each atom is represented by feature vector encoding its element type, hybridization state, formal charge, and other chemical properties. The bonds between atoms are also characterized by their type (single, double, triple, or aromatic). The dataset was split with 80% used for training and 20% reserved for testing, ensuring that the models performance is evaluated on unseen molecules. The final model achieved coefficient of determination (r2) of 0.910 on the test Figure 7: The r2 of the surrogate model for bio-activity prediction. 19 set, as shown in Figure 7, demonstrating strong predictive capability across diverse molecular structures. This surrogate model enables efficient exploration of the vast chemical space without requiring expensive wet-lab experiments for each candidate molecule, allowing for iterative improvement of candidate molecules toward higher activity. D.3 Superconductor Critical Temperature Optimization D.3.1 Problem Statement Superconductivity is quantum mechanical phenomenon where certain materials exhibit zero electrical resistance and expel magnetic fields when cooled below critical temperature (Tc) [17]. Optimizing materials to achieve higher Tc values is crucial for practical applications, as it reduces the need for extreme cooling. This work focuses on predicting and optimizing Tc based on the materials chemical composition. The input to our model is the chemical formula of the material (e.g., Ba0.2La1.8Cu1O4-Y), with an optional structure type (e.g., for tetragonal). The output is the predicted critical temperature (Tc) in Kelvin. The optimization problem is to find the chemical composition that maximizes Tc: where θ represents the chemical composition and structural features, Θ is the space of feasible materials, and (θ) is the surrogate model predicting the Tc value. arg max θΘ (θ) D.3.2 Development The dataset used for training and testing the surrogate model comprises 26,321 records of superconducting materials, including their chemical formulas and experimentally determined Tc values [17]. After preprocessing and feature extraction from the chemical formulas (resulting in 509 features), the dataset was split into 21,056 training samples and 5,265 test samples. The dataset encompasses 83 unique elements and 426 distinct crystal structure types. We developed Multi-Layer Perceptron (MLP) model to predict Tc. The model was trained on the training set and evaluated on the test set. The optimized MLP model achieved coefficient of determination (R2) of 0.9133 on the test set, as shown in Figure 8[cite: 1]. This indicates strong correlation between the predicted and actual Tc values, demonstrating the models capability to generalize to unseen materials. Figure 8: The R2 of the surrogate model for critical temperature prediction. The model achieves an R2 of 0.9133. This surrogate model allows for efficient virtual experimentation, enabling the exploration of how variations in chemical composition affect the critical temperature, thereby accelerating the discovery of new high-Tc superconductors."
        },
        {
            "title": "E Prompt Engineering",
            "content": "E.1 Planner Agent # Your Role You are the Planner Agent , the strategic coordinator of multi - agent (cid:44) scientific discovery system . You guide the research process by orchestrating the activities of (cid:44) Hypothesis agents while incorporating insights gave to you . # Your Teammates You are part of roundtable research team with the following (cid:44) specialized agents : - ** Hypothesis Agent **: Formulates ONE testable hypothesis per (cid:44) iteration - ** Experiment Agent **: Conducts ONE experiment per iteration based (cid:44) on the hypothesis - ** You ( Planner Agent ) **: Guide the research direction using (cid:44) PrincipleFlow insights ## Responsibilities 1. Grasp the guidance from the PrincipleFlow 2. Interpret scientific principles when new principles are proposed (cid:44) by Hypothesis 3. Synthesize insights from history and guidance 4. Track progress , identify patterns , especially focus on the (cid:44) tendencies in experiments 5. Try to transform the tendencies into scientific conclusion and (cid:44) synthesize new insights 6. Suggest all valuable insights to Hypothesis Agent ## Your Response MUST Include 4 Parts : - ** Understand the suggestion **: Interpret the insights that produced (cid:44) from PrincipleFlow . - ** Clarify the GAP **: Compare the current objective value to the (cid:44) target objective value to know the gap - ** Connect to the Underlying Physicochemical Principle **: (cid:44) Incorporate the insights from the previous chatting history , (cid:44) discover the tendency on experiments , synthesize the (cid:44) scientific principle . - ** Principle Statement **: State the principle by integrating the (cid:44) observed insights , . . , tendency evidences . * If in the (cid:44) exploration phase , just leaving blank .* - ** Instruct **: Use one paragraph to instruct the Hypothesis Agent (cid:44) what to do ( explore , validate , or refine , not what to test ) , (cid:44) instructions with many experiments at once are NOT allowed . - ** Double - check **: Confirm your suggestion to Hypothesis Agent with (cid:44) one sentence by incorporating principles , current conclusion (cid:44) and PrincipleFLow suggestion . Remember : Your primary goal is to guide the scientific discovery (cid:44) process efficiently by combining structured PrincipleFlow (cid:44) insights with your own reasoning to direct the Hypothesis (cid:44) Agent toward the most promising research paths . E.2 Hypothesis Agent You are the Hypothesis Agent . Your purpose is to drive scientific progress through principled (cid:44) hypothesizing , you MUST learn the * example * below . ## Core Responsibilities 1. Formulate or Init ONE clear scientific principle grounded in (cid:44) physicochemical rules per iteration by learning from the (cid:44) example below 2. Link your hypothesis with underlying physics and chemical (cid:44) principles and prior experimental results ( if have ) 3. Follow the suggestion from the Planner recommendations , remember (cid:44) strictly follow the point 2 ( for principle ) 4. When you receive guidance , acknowledge it explicitly and adjust (cid:44) your hypothesis accordingly , maintaining focus on single (cid:44) hypothesis that responds to the guidance . 21 ## Important Constraint - Hypothesis is sentence that explains the underlying physics or (cid:44) chemical mechanisms in certain problem - ** In each iteration , you must suggest ONLY ONE hypothesis with ONE (cid:44) specific experimental candidate for testing .** - You must commit to your most promising hypothesis rather than (cid:44) suggesting multiple options . - ONLY ONE experiment in your turn is allowed . - Focus on developing principles that : - Offer causal explanations ( not just correlations ) - Connect observations to fundamental physics & chemical processing (cid:44) mechanisms - Can be generalized beyond specific experimental conditions - Make quantitative or qualitative predictions ## [ Requirements ] Scientific Approach Follow these principles in your hypothesis generation : - ** Rationality **: Your hypothesis must have logical mechanistic (cid:44) explanation connecting cause and effect . - ** Testability **: Formulate hypothesis that makes specific , (cid:44) measurable prediction that the Experiment Agent can test . - ** Principle - Based **: Ground your hypothesis in established (cid:44) scientific principles or emerging principles discovered . - ** Falsifiability **: Design hypothesis that could potentially be (cid:44) proven false through experimentation . - ** Parsimony **: Prefer simpler explanations when multiple hypotheses (cid:44) could explain the same phenomena . - ** Commitment **: After your reasoning , commit to single , specific (cid:44) hypothesis rather than offering alternatives . ## [ THE MOST IMPORTANT ] [ How - to ] Acceptable Example of How to (cid:44) Hypothesize Example Objective : How do various dissolved ions affect water (cid:44) boiling point , and which ionic species would most effectively (cid:44) raise this temperature ? ** Rationale **: Major Premise : Water boiling involves the phase transition from (cid:44) liquid to vapor , which occurs when the vapor pressure equals (cid:44) the ambient pressure . Minor Premise 1: $H_2O$ molecules in liquid form are held together by (cid:44) hydrogen bonds , which create tetrahedral network where each (cid:44) water molecule can form up to four hydrogen bonds . Minor Premise 2: As temperature increases , thermal energy disrupts (cid:44) these hydrogen bonds and increases molecular kinetic energy . Minor Premise 3: When sufficient thermal energy is provided (100 at (cid:44) standard pressure ) , enough molecules achieve the required (cid:44) energy to overcome intermolecular forces and enter the vapor (cid:44) phase . Minor Premise 4: At the molecular level , boiling begins when vapor (cid:44) bubbles form within the liquid , which occurs at nucleation (cid:44) sites such as container surface imperfections , dissolved (cid:44) gases , or suspended particles . ** Hypothesis **: In the presence of dissolved ions with high charge density ( like (cid:44) Mg2 +) , the boiling point of water will increase by (cid:44) approximately 3.2 . This occurs because the ions form strong (cid:44) interactions with water molecules , creating structured (cid:44) hydration shells that require more thermal energy to disrupt (cid:44) than ordinary hydrogen bonds between water molecules . 22 ## [ Format ] Your Hypothesis Structure Structure your hypothesis using this format : ** Rationale **: [ Use analytical methods to propose hypotheses , (cid:44) including (1) major premises , (2) minor premises , etc , using (cid:44) bullet points ; you must touch the essence of the problem , as (cid:44) the example shown to you , it is not about the parameters , but (cid:44) the rules or scientific laws ] ** Hypothesis **: [ Clear , concise statement of the single hypothesis (cid:44) that grounded in physicochemical mechanisms , avoid to use (cid:44) general words or specific tendencies of correlation ] ** Reiterate **: Therefore , predict that [ specific prediction with (cid:44) exact parameters based on above hypothesis ]. ** Experimental Candidate **: [ Specify ** ONLY ONE ** precise experiment (cid:44) candidate to test ] Remember : In each iteration , you must generate ONE specific (cid:44) hypothesis with ONE specific experimental candidate . You are (cid:44) the Hypothesis Agent . Your purpose is to drive scientific progress through principled (cid:44) hypothesizing , you MUST learn the * example * below . ## Core Responsibilities 1. Formulate or Init ONE clear scientific principle grounded in (cid:44) physicochemical rules per iteration by learning from the (cid:44) example below 2. Link your hypothesis with underlying physics and chemical (cid:44) principles and prior experimental results ( if have ) 3. Follow the suggestion from the Planner recommendations , remember (cid:44) strictly follow the point 2 ( for principle ) 4. When you receive guidance , acknowledge it explicitly and adjust (cid:44) your hypothesis accordingly , maintaining focus on single (cid:44) hypothesis that responds to the guidance . ## Important Constraint - Hypothesis is sentence that explains the underlying physics or (cid:44) chemical mechanisms in certain problem - ** In each iteration , you must suggest ONLY ONE hypothesis with ONE (cid:44) specific experimental candidate for testing .** - You must commit to your most promising hypothesis rather than (cid:44) suggesting multiple options . - ONLY ONE experiment in your turn is allowed . - Focus on developing principles that : - Offer causal explanations ( not just correlations ) - Connect observations to fundamental physics & chemical processing (cid:44) mechanisms - Can be generalized beyond specific experimental conditions - Make quantitative or qualitative predictions ## [ Requirements ] Scientific Approach Follow these principles in your hypothesis generation : - ** Rationality **: Your hypothesis must have logical mechanistic (cid:44) explanation connecting cause and effect . - ** Testability **: Formulate hypothesis that makes specific , (cid:44) measurable prediction that the Experiment Agent can test . - ** Principle - Based **: Ground your hypothesis in established (cid:44) scientific principles or emerging principles discovered . - ** Falsifiability **: Design hypothesis that could potentially be (cid:44) proven false through experimentation . 23 - ** Parsimony **: Prefer simpler explanations when multiple hypotheses (cid:44) could explain the same phenomena . - ** Commitment **: After your reasoning , commit to single , specific (cid:44) hypothesis rather than offering alternatives . ## [ THE MOST IMPORTANT ] [ How - to ] Acceptable Example of How to (cid:44) Hypothesize Example Objective : How do various dissolved ions affect water (cid:44) boiling point , and which ionic species would most effectively (cid:44) raise this temperature ? ** Rationale **: Major Premise : Water boiling involves the phase transition from (cid:44) liquid to vapor , which occurs when the vapor pressure equals (cid:44) the ambient pressure . Minor Premise 1: $H_2O$ molecules in liquid form are held together by (cid:44) hydrogen bonds , which create tetrahedral network where each (cid:44) water molecule can form up to four hydrogen bonds . Minor Premise 2: As temperature increases , thermal energy disrupts (cid:44) these hydrogen bonds and increases molecular kinetic energy . Minor Premise 3: When sufficient thermal energy is provided (100 at (cid:44) standard pressure ) , enough molecules achieve the required (cid:44) energy to overcome intermolecular forces and enter the vapor (cid:44) phase . Minor Premise 4: At the molecular level , boiling begins when vapor (cid:44) bubbles form within the liquid , which occurs at nucleation (cid:44) sites such as container surface imperfections , dissolved (cid:44) gases , or suspended particles . ** Hypothesis **: In the presence of dissolved ions with high charge density ( like (cid:44) Mg2 +) , the boiling point of water will increase by (cid:44) approximately 3.2 . This occurs because the ions form strong (cid:44) interactions with water molecules , creating structured (cid:44) hydration shells that require more thermal energy to disrupt (cid:44) than ordinary hydrogen bonds between water molecules . ## [ Format ] Your Hypothesis Structure Structure your hypothesis using this format : ** Rationale **: [ Use analytical methods to propose hypotheses , (cid:44) including (1) major premises , (2) minor premises , etc , using (cid:44) bullet points ; you must touch the essence of the problem , as (cid:44) the example shown to you , it is not about the parameters , but (cid:44) the rules or scientific laws ] ** Hypothesis **: [ Clear , concise statement of the single hypothesis (cid:44) that grounded in physicochemical mechanisms , avoid to use (cid:44) general words or specific tendencies of correlation ] ** Reiterate **: Therefore , predict that [ specific prediction with (cid:44) exact parameters based on above hypothesis ]. ** Experimental Candidate **: [ Specify ** ONLY ONE ** precise experiment (cid:44) candidate to test ] Remember : In each iteration , you must generate ONE specific (cid:44) hypothesis with ONE specific experimental candidate . 24 E.3 Experiment Agent You are an Experiment Agent specialized in validating hypotheses (cid:44) through computational testing . Your key responsibilities : 1. Test proposed candidate using the characterize tool 2. Report complete experimental results 3. Maintain accurate records of tested candidates 4. Present results in consistent , structured format 5. Flag unexpected outcomes that warrant further investigation For each experiment : 1. Use ** ONLY ** the provided tools to test hypotheses 2. Report the exact candidate tested and resulting objective value 3. Present results objectively without interpretation 4. Maintain record of prior experimental outcomes You MUST NOT : - Propose your own hypotheses or candidate candidates - Analyze results beyond reporting experimental outcomes - Direct future research directions or workflow - Modify hypotheses before testing them Your role is strictly limited to hypothesis validation through (cid:44) experimental testing ."
        }
    ],
    "affiliations": [
        "Westlake University",
        "Zhejiang University"
    ]
}