{
    "paper_title": "SynthID-Image: Image watermarking at internet scale",
    "authors": [
        "Sven Gowal",
        "Rudy Bunel",
        "Florian Stimberg",
        "David Stutz",
        "Guillermo Ortiz-Jimenez",
        "Christina Kouridi",
        "Mel Vecerik",
        "Jamie Hayes",
        "Sylvestre-Alvise Rebuffi",
        "Paul Bernard",
        "Chris Gamble",
        "MiklÃ³s Z. HorvÃ¡th",
        "Fabian Kaczmarczyck",
        "Alex Kaskasoli",
        "Aleksandar Petrov",
        "Ilia Shumailov",
        "Meghana Thotakuri",
        "Olivia Wiles",
        "Jessica Yung",
        "Zahra Ahmed",
        "Victor Martin",
        "Simon Rosen",
        "Christopher SavÄak",
        "Armin Senoner",
        "Nidhi Vyas",
        "Pushmeet Kohli"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We introduce SynthID-Image, a deep learning-based system for invisibly watermarking AI-generated imagery. This paper documents the technical desiderata, threat models, and practical challenges of deploying such a system at internet scale, addressing key requirements of effectiveness, fidelity, robustness, and security. SynthID-Image has been used to watermark over ten billion images and video frames across Google's services and its corresponding verification service is available to trusted testers. For completeness, we present an experimental evaluation of an external model variant, SynthID-O, which is available through partnerships. We benchmark SynthID-O against other post-hoc watermarking methods from the literature, demonstrating state-of-the-art performance in both visual quality and robustness to common image perturbations. While this work centers on visual media, the conclusions on deployment, constraints, and threat modeling generalize to other modalities, including audio. This paper provides a comprehensive documentation for the large-scale deployment of deep learning-based media provenance systems."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 0 1 ] . [ 1 3 6 2 9 0 . 0 1 5 2 : r 2025-10SynthID-Image: Image watermarking at internet scale Sven Gowal1,*,, Rudy Bunel1,*, Florian Stimberg1,*, David Stutz1,*, Guillermo Ortiz-Jimenez1,*, Christina Kouridi1,*, Mel Vecerik1,*, Jamie Hayes1,*, Sylvestre-Alvise Rebuffi1,*, Paul Bernard1,, Chris Gamble1,, MiklÃ³s Z. HorvÃ¡th1,, Fabian Kaczmarczyck1,, Alex Kaskasoli1,, Aleksandar Petrov1,, Ilia Shumailov1,, Meghana Thotakuri1,, Olivia Wiles1,, Jessica Yung1,, Zahra Ahmed1,, Victor Martin1,, Simon Rosen1,, Christopher SavÄak1,, Armin Senoner1,, Nidhi Vyas1, and Pushmeet Kohli1,, *Core contributor (randomized order), Contributor, Support, Sponsor, Lead, 1Google DeepMind We introduce SynthID-Image, deep learning-based system for invisibly watermarking AI-generated imagery. This paper documents the technical desiderata, threat models, and practical challenges of deploying such system at internet scale, addressing key requirements of effectiveness, fidelity, robustness, and security. SynthID-Image has been used to watermark over ten billion images and video frames across Googles services and its corresponding verification service is available to trusted testers. For completeness, we present an experimental evaluation of an external model variant, SynthID-O, which is available through partnerships. We benchmark SynthID-O against other post-hoc watermarking methods from the literature, demonstrating state-of-the-art performance in both visual quality and robustness to common image perturbations. While this work centers on visual media, the conclusions on deployment, constraints, and threat modeling generalize to other modalities, including audio. This paper provides comprehensive documentation for the large-scale deployment of deep learning-based media provenance systems. Keywords: provenance, watermarking, robustness 1. Introduction In the wake of powerful generative artificial intelligence (AI) systems and their accessibility in products such as Gemini, ChatGPT, Midjourney or ElevenLabs including their corresponding opensource alternatives (Rombach et al., 2022; Scao et al., 2022; Touvron et al., 2023), leading AI companies including Google committed to advancing responsible practices in deploying AI. One such practice consists of establishing the provenance of generated media artifacts. In this context, the Coalition for Content Provenance and Authenticity (C2PA; Coalition for Content Provenance and Authenticity, 2023), describes provenance as serving two main purposes: allowing leading AI companies to responsibly disclose that content is AI-generated and allowing users to verify the authenticity of these artifacts. The latter, in particular, has received considerable attention due to worries of widespread misinformation (Weidinger et al., 2021; Zellers et al., 2019) or impersonation (e.g., so-called deep fakes; Agarwal et al., 2019; Carlini and Farid, 2020; Vaccari and Chadwick, 2020; Yu et al., 2021). Importantly, we note that establishing provenance is materially different from detecting AI-generated content, as the public discourse tends to focus on.1 Not only are such detectors2 generally less reliable, but even if we could reliably detect AI-generated content, they do not necessarily establish provenance. Fine-grained origins are typically still unknown and we believe that the increase of fidelity of future generative models will also increase the complexity of establishing provenance through detection alone. 1https://www.technologyreview.com/2023/11/06/1082996/the-inside-scoop-on-watermarking-and-content-authentication 2https://contentatscale.ai/ai-content-detector/, https://www.compilatio.net/en/blog/best-ai-detectors, https://gptzero.me/ Corresponding author(s): sgowal@google.com, pushmeet@google.com 2025 Google DeepMind. All rights reserved SynthID-Image: Image watermarking at internet scale While C2PA establishes standard for encoding and verifying provenance through metadata that is attached to the content, this approach is vulnerable to removing said metadata (Zhao et al., 2025).3 Watermarking is promising responsible disclosure mechanism that allows to embed provenance information within the generated content directly. As visible watermarks (Braudaway, 1997) have been shown to be ineffective in the age of deep learning (Dekel et al., 2017), there has been recent revival of deep learning based methods for invisible watermarking. Originating in the information hiding community (Anderson, 1996; Cox, 2007), invisible watermarks aim to hide information within multimedia artifact. Classical methods use wavelet or Fourier transforms for this purpose and recently deep learning based methods have been introduced for this task (Adi et al., 2018; Zhu et al., 2018) as they promise to store more information with higher robustness to removal attempts. However, this exposes these methods to wide array of attacks that exploit vulnerabilities in the underlying deep neural networks. Furthermore, many methods still lack robustness to common post-processing or manipulations of the content and, unsurprisingly, they are vulnerable to adversarial attempts to remove or fake the watermark, e.g. by utilizing rich body of work on adversarial examples (Biggio et al., 2013; Szegedy et al., 2014). Building (adversarially) robust watermarking systems remains an extremely challenging problem. More importantly, there is little to no guidance on how to deploy such systems in robust manner at internet scale. To successfully enable provenance of AI-generated content at internet scale, watermarking system needs to balance number of potentially conflicting desiderata. As the main objective during the development of generative AI models is quality, it is crucial for watermarking systems not to impact it. This is commonly implied by demanding invisible watermarking. Then, we want the produced watermarks to be effective in verifying provenance which also includes robustness to expected and unexpected changes in the underlying media artifact due to every day use. Deviating from every day use, we explicitly want watermarks to be secure against malicious use, ranging from watermark removal or forgery attacks to attempts on model extraction. To enable watermarking at internet scale, it also needs to be sufficiently efficient in terms of runtime, with minimal overhead during generation and high throughput during detection and verification. rich literature on watermarking, see surveys by Cox (2007); Wan et al. (2022) and benchmarks by An et al. (2024); Petitcolas (2000), hints that many of these desiderata are conflicting and trade-offs have to be made. This is particularly important in light of our final desiderata, large-scale deployment. This means that, ultimately, decisions have to be made on how to handle trade-offs and deal with imperfect robustness and security in practice. With SynthID-Image,4 we built watermarking system that is currently watermarking all of Googles AI-generated imagery. Throughout development, we found that many existing surveys, benchmarks and methods do not realistically capture the above desiderata and their trade-offs, often ignoring key threat models, evaluations or deployment considerations. In this paper, we want to share detailed account of our learnings from developing, deploying and maintaining SynthID-Image since its first public announcement in August 2023.5 Moreover, with this work, we evaluate our external variant of SynthID-Image which is available via partnerships. Our contributions can be summarized along the structure of this paper: SynthID-Image (Section 2) follows post-hoc and model-independent approach to watermarking. This means the watermark is applied on top of the AI-generated content using an encoder, not as part of the generation process, and detected using corresponding decoder. This makes SynthID applicable to any generative model and thus maximizes utility, deployability and organizational flexibility at the cost of stringent constraints on quality and efficiency. 3Metadata is often stripped accidentally and can also be trivially removed. 4https://deepmind.google/technologies/synthid/ 5https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/ 2 SynthID-Image: Image watermarking at internet scale Invisibility (Section 3): Because quality dictates many trade-off among relevant desiderata, we meticulously benchmark the watermarks impact on quality by predominantly using human judgement on corner-case content. We frequently run internal studies and complement this with external ones. Framing these studies correctly is key. These studies are complemented using proxy metrics that enable auto-evaluation. Robustness (Section 4) requires comprehensive and reproducible benchmarking of numerous possible transformations. This is informed by manually deciding on appropriate ranges, essentially defining when transformed content can visibly be determined as heavily tampered or when transformations change the underlying (semantic) content significantly. Payload (Section 5): Tracking and establishing provenance goes beyond just detecting watermark. While many approaches allow multi-bit watermarks, it is often neglected how multi-bit payload is best used. Adapting SynthID-Images payload to its use case allows us to serve different generative models, users and deployment scenarios. Ensuring security (Section 6) of the watermarking system involves understanding wide range of threat models, setting them up for benchmarking and prioritizing them. The relevance of each threat model depends on how the system is deployed, i.e., what information of is publicly available or can be extracted under reasonable assumptions. Achieving perfect security is impossible; thus, we focused our efforts on making key attacks as difficult and expensive as possible. Deployment (Section 7): Aiming for internet-scale deployment requires solving wide range of additional problems, including decision making (i.e., what constitutes positive and when to abstain), defining payload use, and putting watermarking in context of other methods such as C2PA or retrieval (e.g., reverse image search). New state-of-the-art (Section 8): We present experimental results for one variant of SynthIDImage. This model achieves state-of-the-art performance across the most comprehensive range of transformations to date. We also provide usage recommendation of how to adopt this external variant securely. Figure 1 demonstrates that our models establish new state-of-the-art in terms of quality, detection performance and robustness across wide range or transformations. We believe this to be the first comprehensive account of deploying image watermarking models at internet scale. 2. Our approach Digital watermarking is commonly defined as the practice of hiding message about an image, audio clip, video clip, or other work of media within that work itself (Cox, 2007). Generally, this implies the ability to detect and extract this hidden message, which we refer to as the watermark payload, in way that is robust to post-processing of the watermarked artifact. While watermarking can be used for many modalities (e.g., text; Dathathri et al., 2024), in this paper, we solely consider multimedia watermarking and focus on images. Besides its original use for steganography (i.e., the practice of undetectably embedding secret message; Cox, 2007), watermarking in the context of generative AI is primarily associated with tackling misinformation, impersonation (Yu et al., 2021) and copyright protection (Kadian et al., 2021; Xuehua, 2010). The application to AI-generated content provenance is the dominant motivation of recent deep learning based watermarking methods. It deviates significantly from earlier research (Wan et al., 3 SynthID-Image: Image watermarking at internet scale Figure 1 Quality as evaluated by human raters against FNR at 0.1% FPR averaged across various image transformations. Each model is calibrated to obtain 0.1% FPR (more details to follow in Section 8). The quality is measured on the y-axis by looking at the difference in artifact rates between watermarked and non-watermarked content. SynthID-O (our external variant of SynthIDImage available via partnerships) achieves the highest quality (i.e., lowest perceptibility) and robustness (i.e., lowest brittleness) compared to other baselines. 2022). For example, we exclusively consider blind watermarking which assumes that we only have access to the watermarked content for detection, not pairs of original and watermarked content. In the context of text-to-image models, blind watermarking also excludes knowledge of the used prompt. Moreover, in contrast to steganography, we may not care about users or the general public knowing that content gets watermarked. In fact, companies have been vocal about their plans to watermark AI-generated content as demonstrated through the ongoing dialogue with legislators and participation in C2PA. Irrespective of the approach, there are several desiderata that we expect SynthID-Image to fulfill. Most prominently, these include quality preservation, robustness to every-day changes to the watermarked content, and hiding sufficiently large payload in the watermark. The difficulty of developing any watermarking system stems from unfavorable trade-offs between these desiderata, namely the quality-robustness-payload trade-off. For example, without requiring an invisible watermark, it becomes trivial to perform robust watermarking with large payload. Thus, in the following, we start with an overview of these desiderata and trade-offs. 2.1. Desiderata Quality and diversity. Product and research teams (especially those that build generative models) are keen to demonstrate and release their most powerful models. This race to higher quality content means that watermarking can be an afterthought and must, as result, maintain the quality and diversity of the generated content. While some ad-hoc watermarking schemes are provably lossless (Christ et al., 2024; Yang et al., 2024), they can reduce diversity (Gunn et al., 2025). Post-hoc schemes do not suffer from diversity degradation by construction, but may affect quality. In practice, all methods require careful empirical assessment. Unfortunately, quality is the most difficult requirement to properly measure and ensure. Common automated metrics are unreliable and can only be used as proxies during development. Thus, in developing SynthID-Image, we focused heavily on human studies to evaluate quality, as discussed in detail in Section 3. 6In the context of soft-binding schemes (https://c2pa.org/specifications/specifications/1.0/specs/C2PA_Specification.html#_soft_ bindings). SynthID-Image: Image watermarking at internet scale Effectiveness and robustness. It is important to properly define under which assumptions watermarking system is expected to work reliably. For start, the watermark should always be perfectly detectable when the watermarked content is not transformed or manipulated. Good detection performance is commonly evaluated using the true positive rate (TPR) at specific (low) false positive rate (FPR). Achieving high TPR at low FPR is what we call an effective watermarking scheme. Beyond effectiveness, we require watermark detection to be robust to general purpose, everyday changes such as compression, quantization, basic geometric transformations or image effects. While evaluating watermarking schemes against various such transformations is common practice, as shown in older as well as more recent benchmarks (An et al., 2024; Petitcolas, 2000; Piet et al., 2025), there is little agreement on which exact transformations to consider (across modalities) and evaluations are often not exhaustive, leading to misleading claims about the effectiveness of watermarking (Zhang et al., 2023). For SynthID-Image, we hand-picked and -tuned large variety of transformations, as detailed in Section 4. Payload. Beyond detection, we require watermarks to include an additional multi-bit payload. Again, we expect this payload to be robust to everyday content changes. This is commonly evaluated using bit accuracy, i.e., accuracy of predicting individual bits, or code accuracy, i.e., accuracy of predicting full multi-bit code. While most state-of-the-art methods (Fernandez et al., 2023; Yang et al., 2024; Zhang et al., 2019) directly tackle this multi-bit watermarking problem, the exact use of the payload at test time is rarely discussed and thus evaluation usually focuses on detection only. For SynthID-Image, we tackle the detection and payload problems separately and found the payload to play crucial role in how provenance is established, see Section 5. Security. The security of watermarking system entails both worst-case robustness of the watermark as well as security of the watermarking scheme itself. This includes variety of threat models, including evasion of watermark detection, watermark forgery, model stealing or secret extraction attacks. Depending on the threat model, ensuring security might result in number of secondary desiderata. Avoiding evasion and forgery attacks on the decoder generally requires an adversarially robust detector (see Section 2.3). Thus, adversarial robustness is an important but not the only part of security. For example, to avoid model extraction attacks we may require generated watermarks to be sufficiently diverse across different payloads or hard to train surrogate models on (Orekondy et al., 2020). Some aspects of security can also be addressed using infrastructure changes such as limiting the number of queries per second for the detector or providing only an encoder to trusted customers. We give comprehensive overview of threat models and their practical relevance for SynthID-Image in Section 6. Efficiency. Deploying watermarking at scale requires reasonably low latency for both encoding and decoding the watermark. For encoding, this is usually measured relative to the latency of content generation. Because this is often user-facing, we aim for single-digit percentage of additional overhead. For decoding, it is important to realize that it may be run orders of magnitude more frequently than encoding. This fact is commonly ignored in the literature where decoding is framed as an ad-hoc action initiated by user who wants to check for the watermark. However, we expect watermark decoders to be run at increasingly large scale to check the majority of content that is shared on the web, e.g., as part of social media, web search and scraping, training data creation, etc. Thus, decoding efficiency might often be the bottleneck. It is also important to realize that decoding may be run in addition to other checks such as verifying C2PA (Coalition for Content Provenance and Authenticity, 2023) metadata and content preor post-processing (e.g., video encoding/decoding). We benchmark efficiency in terms of throughput per second and hardware unit (e.g., GPU). At SynthID-Image: Image watermarking at internet scale encoding time, batch size will be pre-determined by generation requests; for decoding, batch size can be chosen to optimize throughput. Deployment. As SynthID-Image is intended for internet-scale deployment, it clearly distinguishes itself from prior work (see Section 9 for discussion). This introduces number of additional requirements not sufficiently considered previously. Most importantly, different deployment settings including internal deployment, watermarking-as-a-service or open watermarking models have significant influence on the above desiderata and key design choices. This includes proper decision making, versioning of watermarks and how SynthID-Image fits into larger landscape of methods for provenance, e.g., C2PA or search-based methods (Balan et al., 2023; Bharati et al., 2021; Nguyen et al., 2021; Zhang et al., 2020b). We found that such deployment considerations had the largest impact on deciding what approach to use and which operating point in terms of the above desiderata to choose. 2.2. Post-hoc, model-independent watermarking Watermarking schemes can be categorized along several, partly orthogonal dimensions. Because we focus on blind watermarking only, watermarking has to shift the distribution of generated content in detectable manner. Thus, blind watermarking is also referred to as distributional watermarking. Additionally, recent literature typically distinguishes between ad-hoc and post-hoc watermarking depending on whether the process of watermarking happens during the generative process (ad-hoc) (Fernandez et al., 2023; Wen et al., 2023; Yang et al., 2024) or as post-processing step (posthoc) (Bui et al., 2025; Hayes and Danezis, 2017; Hayes et al., 2020; Luo et al., 2020; Tancik et al., 2020; Wen and AydÃ¶re, 2019). Ad-hoc methods are typically integrated into the corresponding generative model and thus require at least partial access to the underlying generative model. Post-hoc watermarking, in contrast, can be performed without any knowledge or assumptions on the generative model and is thus model-independent. We deliberately designed SynthID-Image as post-hoc, model-independent approach, choice largely based on deployment considerations while ensuring the best trade-off between the remaining desiderata. Advantages. First and foremost, SynthID-Image must consistently watermark all of Googles current and future AI-generated content, stemming from variety of different models. We believe that the promise of watermarking in the context of preventing misinformation stems from this consistency, i.e., being able to mark all content using single (or as few as possible) watermarking scheme(s). Because ad-hoc approaches are inherently tied to the respective generative model architectures and versions, they are unable to fulfill this promise at scale. For example, having different watermarks for different generative models or versions necessitates running many multiple detectors or cleverly training meta-detectors. With post-hoc approach, this can be handled using payload. We also found that this creates less organizational dependencies and allows more flexibility in how the watermarking system is deployed internally and externally. For example, in contrast to most ad-hoc approaches, SynthID-Image could be open-sourced or deployed as-a-service without implications for any generative model. Moreover, it is easier to debug, update or simply turn on or off. We appreciate that some ad-hoc methods can be used in post-hoc way (Fernandez et al., 2023); but the dependence on details of the underlying generative model remains, combining the disadvantages of adand post-hoc approaches rather than their advantages. Drawbacks. The main disadvantage of post-hoc approaches is that they are inherently lossy, i.e., they impact the quality of the generated content. This is in contrast to ad-hoc approaches which can 6 SynthID-Image: Image watermarking at internet scale be completely lossless (Yang et al., 2024). However, we found that reaching level of quality where the watermark is essentially invisible to (expert) users is possible in practice. We also believe that the impact of watermarking on quality is also easier to measure for post-hoc approaches. This is because we can directly compare watermarked and non-watermarked content to judge invisibility, as done in our human studies, see Section 3. For ad-hoc approaches, by construction, judging quality is more entangled with the quality of the underlying generative model. Ad-hoc approaches risk reducing diversity of generations (Gunn et al., 2025), which is incredibly difficult to test for. There are various other implications of our choice. For example, post-hoc watermarking causes additional computational overhead for adding the watermark compared to ad-hoc approaches. This overhead can be limited using architectural changes, but cannot be entirely eliminated. This is rather critical for image generation where watermarking has to be performed after generation; for audio and video, generation and watermarking can be parallelized to large extent. On the other hand, watermark detection can be less efficient for ad-hoc methods, for example, if they require expensive inversion of the diffusion process (Wen et al., 2023; Yang et al., 2024). As we expect detection to be run several orders of magnitude more often, this is an important consideration. We also noticed that robustness of post-hoc approaches is easier to benchmark, since content to be watermarked can be fixed independent of the generative model, and more controllable. Watermark robustness of ad-hoc approaches may be entangled with internal representations of the underlying generative models. 2.3. Training formulation As post-hoc scheme, we used an encoder-decoder approach for SynthID-Image following prior work (Bui et al., 2023, 2025; Hayes and Danezis, 2017; Hayes et al., 2020; Luo et al., 2020; Tancik et al., 2020; Wen and AydÃ¶re, 2019). To be more specific, let ğ’™ be an image, where â„ğ‘› represents the set of all images (in practice, the set of all images is finite and countable). We assume there exists metric ğ‘‘ : â„+ that encodes the perceptual similarity between two images. We will use this metric to formalize the concept of invisibility of watermark. post-hoc watermarking scheme is pair ğ‘“ , ğ‘” consisting of an encoder function ğ‘“ : X, which adds an identification mark, and decoder function ğ‘” : {1}, which tries to detect if the mark is present. Let â„™X be target distribution that we would like to watermark. Given perceptual threshold ğœ– > 0, the optimal watermarking scheme on â„™X solves min ğ‘“ ,ğ‘” s. t. ğ”¼ğ’™â„™X [â„“(ğ‘”( ğ‘“ (ğ’™)), +1) + â„“(ğ‘”(ğ’™), 1)] (1) ğ‘‘(ğ’™, ğ‘“ (ğ’™)) ğœ–, where â„“ represents suitable classification loss function. Assuming that ğ‘” makes decision by thresholding some logit using threshold ğœ…, the classification loss we are ideally interested in is â„“(ğ‘”ğœ…( ğ‘“ (ğ’™)), ğ‘˜) = 1[sign(ğ‘”ğœ…( ğ‘“ (ğ’™))) = ğ‘˜]. In practice, an appropriate approximation such as crossentropy is used to train ğ‘” and the threshold ğœ… is calibrated for target FPR post-training. Minimizing this loss will ensure that the watermarking scheme is effective, i.e., is able to watermark content and detect them. The constraint on ğ‘‘, in contrast, will ensure quality, i.e., the watermark being invisible. It is important to note that Equation (1) assumes that images to watermark and non-watermarked images come from the same distribution â„™X. While we make this assumption to keep our watermarking scheme future-proof and universal across various generative models, this is clearly sub-optimal when targeting specific AI-generated content (e.g., coming from family of text-to-image models). We account for this discrepancy during the calibration process which is applied post-training. We are particularly interested in robust watermarking schemes. That is, schemes that are robust to everyday alterations of watermarked samples that still preserve the usefulness and semantic content 7 SynthID-Image: Image watermarking at internet scale of the samples. We define distribution of valid transformations â„™T that semantically preserve the content and require robustness on average, i.e., min ğ‘“ ,ğ‘” s. t. ğ”¼ğ’™â„™X ,ğœâ„™T [â„“(ğ‘”(ğœ( ğ‘“ (ğ’™))), +1) + â„“(ğ‘”(ğœ(ğ’™)), 1)] (2) ğ‘‘(ğ’™, ğ‘“ (ğ’™)) ğœ–. The difficulty of this problem is clearly determined by the perceptual threshold ğœ– and the distribution over transformations â„™T, resulting in robustness-quality trade-off. Clearly, allowing more visible watermarks will render the system more robust to stronger transformations. Note again that Equation (2) assumes that the same transformations are applied to watermarked and non-watermarked images. This is not necessarily the case in practice but it simplifies analysis and evaluation of the resulting scheme. For watermarking scheme to be secure, we might also need to be robust to specific malicious modifications of the content. Attackers may want to manipulate the images ğ’™ or ğ‘“ (ğ’™) to provoke false positives and false negatives, respectively. This leads to worst-case formulation of the above optimization problem that requires adversarial training (Madry et al., 2018) which remains largely unsolved. For SynthID-Image, we found that it is sufficient to enforce adversarial robustness only in settings where adversaries have limited information (e.g., black-box access) and constrained compute. As training perfectly robust and secure watermarking scheme may be infeasible, this shifts the focus to making malicious attacks as difficult as possible. An important aspect of useful provenance system is the ability to discern content from different actors. As such, having the ability to embed hidden message, called payload, in the watermark is fundamental. In this setting, training watermarking scheme becomes multi-bit classification problem rather than detection problem. More formally, let ğ’„ {1}ğ¶ be ğ¶-bit binary payload. The encoder function ğ‘“ : {1}ğ¶ now crafts watermark based on both ğ’™ and ğ’„ and the decoder function ğ‘” : {1}ğ¶ is now tasked with recovering the payload ğ’„ rather than detecting the presence of the watermark alone. The robust watermarking problem then becomes: min ğ‘“ ,ğ‘” s. t. ğ”¼ğ’™â„™X ,ğ’„ğ•Œ{1}ğ¶ ,ğœâ„™T [â„“(ğ‘”(ğœ( ğ‘“ (ğ’™, ğ’„))), ğ’„)] ğ‘‘(ğ’™, ğ‘“ (ğ’™)) ğœ–, (3) where ğ•Œğ”¸ represents the uniform distribution over the set ğ”¸. Clearly, this problem becomes more difficult for longer payloads, i.e., larger ğ¶. This means we are now dealing with robustness-qualitypayload trade-off. For SynthID-Image, we solve both the detection and the payload problem, i.e., Equations (2) and (3), separately, without making any assumptions on the payload ğ’„ such that it can serve variety of purposes. 2.4. Benchmarking to control trade-offs Primary trade-off. The most important trade-off between our desiderata is the robustness-qualitypayload trade-off. More visible watermarks are easier and more robust to detect and can store more bits. In nutshell, we want the watermark to be as robust and contain as many bits as possible while staying invisible. As we will see in Section 3, the main bottleneck of this approach is objectively ensuring invisibility through appropriate metrics and studies. In practice, we control these trade-offs using combination of different losses, data augmentation methods and payload encoding strategies. Moreover, the data distribution has large impact on this trade-off. For example, requiring invisible watermarks can be harder for some images (e.g., with less structure). Requiring high quality on these examples leads to less robustness overall. Thus, deciding to not watermark specific content can improve the trade-off significantly. SynthID-Image: Image watermarking at internet scale Secondary trade-offs. Besides the robustness-quality-payload trade-off, there are various secondary trade-offs. For example, requiring adversarial robustness or preventing watermark extraction or exchange attacks may worsen quality. Another example is using cascade of decoders, with more efficient decoders offering less robustness first, which allows to trade-off robustness and efficiency. For SynthID-Image, we found that the most effective way of controlling these trade-offs is proper end-to-end benchmarking of all desiderata of interest. While we will discuss appropriate metrics in detail in the following sections, we want to emphasize that end-to-end benchmarking in itself is non-trivial endeavor. Critically, benchmarking needs to include all key metrics and threat models to highlight relevant trade-offs. This requires high degree of automation and tooling around model development. Training and evaluation will also inherently include randomness. It is important to be able to control this randomness appropriately for debugging and reproducibility. For transformations and attacks this also includes appropriately tuning hyper-parameters. Moreover, the choice of datasets for evaluation is important: key considerations are whether to benchmark on natural or generated images and how to include corner-case content, especially for quality evaluation. 3. Invisibility Quality is the most difficult requirement to properly evaluate in practice because invisibiliy or any quality change in generated content is tricky to objectively quantify. So far, in Section 2.3, we worked with perceptual metric ğ‘‘ (many prior publications also work with an unknown oracle instead; Zhang et al., 2023). Of course, there exist automated metrics and proxies, including PSNR, SSIM (Wang et al., 2004) or pre-trained perceptual models such as L-PIPS (Zhang et al., 2018), FID (Heusel et al., 2017), CLIP (Radford et al., 2021) or CMMD (Jayasumana et al., 2024). However, none of these metrics can ultimately replace human evaluation. This is particularly relevant when dealing with wide distribution of generated content that might not match benign, natural content. Learned metrics will always be biased to the content distribution that these metrics have been developed for. In the case of images, these are typically ImageNet-style natural images. For SynthID-Image, we decided to go with rather basic metrics such as PSNR or SSIM, using them with extreme caution and mostly to perform relative comparisons while relying heavily on human evaluation, both internally and externally, to decide invisibility in absolute terms. The latter also includes hand-tuning relevant transformations considered during robustness evaluation, as detailed in Section 4. While we also rely heavily on standard datasets, we took particular care to run human studies on actual AI-generated content from state-of-the-art generative models, using diverse set of prompts. Independent of the metric, there are two modes of quality evaluation. First, we can compare Setups. pairs of original and watermarked content. This side-by-side comparison allows to directly quantify perceptual distance and is the default for most post-hoc approaches where we have one-to-one correspondence between original and watermarked content. In Equation (2), this means directly evaluating the distance ğ‘‘. Second, as users do not typically have access to the original content alongside the watermarked content, we can also compare the distributions of metrics. This is how ad-hoc approaches are typically evaluated, e.g., by computing FID or CLIP scores for original and watermarked content and performing hypotheses tests to see if both distributions are distinguishable (Yang et al., 2024). However, using CLIP also assumes access to the corresponding prompts and is thus limited to ad-hoc approaches. This approach is typically more difficult as we cannot directly judge, for fixed prompt or image, to what extent quality changes. For SynthID-Image, we generally found the first approach to be more appropriate for internal evaluation as it allows for more scrutiny. For studies with external users, in contrast, we follow the second approach because it represents the more realistic setting. 9 SynthID-Image: Image watermarking at internet scale Internal rater studies. More specifically, during fast-paced development, we used reasonably small set of generated images to run side-by-side comparison studies within the team for most model candidates. This involves showing the original and watermarked content side-by-side, randomizing which is the watermarked and asking ourselves to identify the watermarked one. Across the team, we usually target performance close to random chance 50% 10%. This is particularly high bar since watermarks are easier to spot side-by-side, with the ability to zoom in and out of the image. Moreover, throughout development, we learned to spot watermarks well as we usually know how watermarks of specific model versions look. Over time, as watermarks got less visible, we also added an option to abstain. We included hand-picked examples of generated content, often those that we found difficult to watermark or informed by direct feedback from colleagues working on the corresponding generative models. This also contributed to these studies being extremely conservative. In between these studies, we typically compare models in relative terms using PSNR, SSIM or similar automatic metrics, especially to hill-climb on quality or other desiderata. External rater studies. For evaluation using external raters, this side-by-side approach was replaced by showing either the original or the watermarked content and asking raters to find artifacts. This is the more realistic setup, simulating that users usually do not have access to pairs of original and watermarked content. In contrast to the very specific, hand-picked content examples in our internal evaluation, we constructed set of hundreds of prompts across various categories. For our image watermark evaluation, example categories are shown in Figure 2 with images generated (and watermarked) using Imagen and SynthID-Image. These categories also illustrate that the distribution of generated images tends to be significantly different from natural images; this, however, reflects many use-cases of such generative models. In the study, we also included training examples for the raters to highlight common types of artifacts. Here, it was important to include both watermarkrelated artifacts as well as generation-related artifacts. We also had to use dummy examples to double-check that raters pay attention. If, after the study, we cannot distinguish the rate of artifacts between the watermarked and non-watermarked with statistical significance, we concluded the watermark to be invisible. Additional considerations. There are several considerations that affect quality. For images, this mainly concerns resolution and color space. While resolution could be set by the corresponding generative model whose output must be watermarked; we intend SynthID-Image to be independent of such dependencies as generative models will likely change going forward. While higher resolution allows less visible watermarks at similar robustness and payload size, we found that efficiency constraints ended up determining resolution. This choice required taking care of not introducing any artifacts due to re-sizing during encoding. The color space largely impacts which pixel-level changes are actually perceptible. We found this matters particularly for black-and-white images or images with few colors or low contrast. Corner-cases. An important realization in terms of quality, but also relevant for robustness and security, is the frequency of corner-case imagery when working at internet scale. We already mentioned the tricky case of black-and-white images typically ignored in the literature. Other examples include logos with very few but uniform coloring, images with slow gradients, abstract paintings, pixel art, sparse drawings, etc. See Figure 2 for some examples. These types of images are rarely included in standard vision datasets that perceptual metrics are trained on. As corner-cases, we generally define any category of content that poses challenge to watermarking in terms of quality and is not well represented in many standard datasets. This might mean that such content is difficult to watermark in an invisible way, or that the watermark becomes fragile in terms of robustness. For SynthID-Image, 10 SynthID-Image: Image watermarking at internet scale 3D Rendering Abstract art Animal Painting Animal Photo Cartoon Defocused Blurry Fantasy Painting Flat art Historic Photo Landscape Painting Landscape Photo Line Drawing Logo Object Painting Object Photo Pencil Drawing Pixel art Portrait Painting Portrait Photo Poster Art SciFi Photo Shapes Stock Photo Text Wallpaper Figure 2 Illustrative images generated using Imagen for different categories of prompt. These images (either watermarked or not) are shown to external human raters and include corner-case images such as grayscale photographs, sketches or close-to-uniform color images. 11 SynthID-Image: Image watermarking at internet scale we found it important to identify and track such content throughout development. Large parts of the content used for internal studies included such corner cases. 4. Transformation robustness To consistently detect watermarks, it is important that they are robust to common transformations and content post-processing. This generally includes pre-determined set of transformations that we expect to be readily available on personal computers or smartphones, including resizing or cropping, quantization and compression, or common image processing filters (e.g. Instagrams photo filters). This is similar to the notion of corruption robustness in the computer vision literature (Hendrycks and Dietterich, 2019; Hendrycks et al., 2019) and has to be contrasted with adversarial transformations (Alaifari et al., 2019; Engstrom et al., 2017) that assume malicious intent. Concretely, this means that we expect robustness to random transformation with reasonable strength. The main metrics to evaluate detection performance are true and false positive rates (TPR and FPR) with and without transformations. Formally, given distribution â„™T over content transformations, we can measure the watermarking schemes nominal rates as ğ”¼ğ’™â„™X ,ğœâ„™T [ğ‘”ğœ…(ğœ(ğ’™))] (TPR) ğ”¼ğ’™â„™ [ğ‘”ğœ…(ğ’™)] (FPR) with â„™ representing the distribution over all possible non-watermarked content and ğ‘”ğœ… indicating the decoder at the operating point (commonly threshold) ğœ…. Note that we can also measure the worstcase across transformations for analysis purposes (replacing ğ”¼ğœâ„™T with maxğœâ„™T ). Some papers also report the area under the receiver operating characteristic (AUROC), considering TPR and FPR across various detection thresholds ğœ…. However, we found that AUROC is not sensitive enough in practice. This is because we are particularly interested in operating points with very low FPR (i.e., 1%), disregarding the majority of the ROC curve. Note that prior work (Fernandez et al., 2023; Yang et al., 2024) often simulates results at such low FPRs based on assumptions of the detection/payload logits distribution. But this has been found to be misleading (Fernandez et al., 2023) which is why we rely purely on sufficiently large datasets to avoid simulation. For evaluating TPR and FPR consistently across transformations, it is important to choose the operating point ğœ… consistently across transformations. This is because, for deployment, we have to choose single ğœ…; evaluation on different subsets of transformations with different operating points can thus be misleading. To the best of our knowledge, this is neglected in prior work, resulting in overly optimistic robustness evaluations. Prior work on watermarking quickly realized that properly specifying and training for relevant transformations is key for robustness. Thus, many previous works include concrete transformations and parameters to be tested for robustness (Tancik et al., 2020; Wen et al., 2023; Zhang et al., 2024). However, we found that none of these works are exhaustive, as also seen in the surveyed methods and transforms by Wan et al. (2022). Commonly overlooked transformations can be simple ones, such as small rotations, left/right and up/down flips, or different types of noise (Gaussian, salt&pepper, speckle). For example, GaussianShading (Yang et al., 2024) misses rotations and flips; StableSignature (Fernandez et al., 2023) and WAVES (An et al., 2024) ignore various noise types. This is despite common knowledge that these type of transformations are extremely common and work on corruption robustness indicates that deep neural networks are not inherently robust to them. Moreover, many methods are benchmarked against fixed-strength transformations, e.g., fixed rotations or crops, or fixed JPEG quality (Fernandez et al., 2023; Saberi et al., 2024b; Yang et al., 2024). While these usually correspond to rather strong transformations, it is not guaranteed that the methods are also the least robust against them; for example, neural networks may be more vulnerable to small rotations than 90, 180 or 270 degree rotations (Dumont et al., 2018; Engstrom et al., 2017). It has also been shown that combinations of transforms can be effective ways to fool SynthID-Image: Image watermarking at internet scale All rotations Brightness Combined Combined NoCrop Combined NoCrop Rotate Combined Rotate Contrast Crop resize Denoise Emoji overlay Exposure File format Flip left-right flip up-down Gaussian blur Gaussian noise Grayscale Hue Identity Impulse noise Instagram Light text overlay Resize Rotation Saturation Sharpness Shot noise Small rotation Speckle noise Zoom out Figure 3 Illustrative examples of the 30 basic transformations used in our evaluation (alphabetically listed). 13 SynthID-Image: Image watermarking at internet scale networks. For example, StableSignature has combinations based on cropping, brightness changes and JPEG compression. As generalization of neural networks between transformations is still poorly understood, key component of SynthID-Image is exhaustively listing, implementing and tuning relevant transformations. We developed set of basic transformations that we believe any large-scale watermarking system should be robust to. Our two guiding principles for inclusion in this basic set of transformations are accessibility and detectability. Rotations, flips, brightness changes, etc. are all very accessible on every smartphone camera or social media app. This also includes Instagram-like filters7 or overlaying texts and logos. To tune strengths, we consider all transformations reasonable if they have reasonable quality and preserve the underlying semantics of the content (as judged by human raters). It is also important to consider any possible transformations that any software might automatically include as preor post-processing, such as compression and quantization. All of our basic transformations are shown in Figure 3. 5. Payload For SynthID-Image, where we aim to serve several generative models across different partners, the payload is crucial component of turning watermarking into tool for provenance. While some recent work (Yang et al., 2024) simulates multiple users, details are scarce and suggest that simple integer user identifier is encoded in the payload, without any redundancy or additional logic. During development, we evaluate the payload robustness in terms of bit and code accuracy, across all relevant transformations. Letting ğ’„ = (ğ‘1, . . . , ğ‘ğ¶) be the originally encoded payload code and ğ‘”ğ‘– () the logit corresponding to ğ‘ğ‘– (with ğ‘”0() corresponding to the detection logit), we define bit accuracy as the accuracy of the predicted payload bits in expectation over bit positions: ğ”¼ğ’™â„™X ,ğœâ„™T (cid:34) 1 ğ¶ ğ¶ ğ‘–=1 1[sign(ğ‘”ğ‘– (ğœ( ğ‘“ (ğ’™)))) = ğ‘ğ‘–] . (cid:35) (4) Bit accuracy is comparable across models with different payload sizes. In some cases, it is also interesting to monitor bit accuracy individually as their accuracy can vary widely by location depending on the exact training procedure. This might inform how to robustly encode information in the payload in practice. Bit accuracy does not explicitly measure what we might be interested in, which is how often we get the entire payload right, i.e., code accuracy: ğ”¼ğ’™â„™X ,ğœâ„™T (cid:2)1[ğ¶ ğ‘–=1 sign(ğ‘”ğ‘– (ğœ( ğ‘“ (ğ’™)))) = ğ‘ğ‘–](cid:3) . (5) Code accuracy generally degrades with larger payload size and degrades more quickly with challenging transformations than bit accuracy. As before, it is important to monitor these metrics across transformations. This is because bit and code accuracy are highly relevant for many deployment scenarios where pure detection performance in terms of TPR/FPR is not sufficient. Note that both metrics are defined conditional on watermarked examples. That is, we generally neglect what happens to the payload on non-watermarked content. This is somewhat unique to SynthID-Image, as we explicitly separate detection and payload recovery (see Section 2.3). For approaches that directly use the payload for detection, TPR and FPR needs to be defined following Equation (5). For example, Fernandez et al. (2023); Yang et al. (2024) select random but fixed payload for each watermarked example and make detection decision by thresholding on the number of matching bits between this payload and the predicted one. Of course, if the reference payload is not available, this test is not applicable. 7https://github.com/akiomik/pilgram 14 SynthID-Image: Image watermarking at internet scale In the setting from Yang et al. (2024) where each user has an integer identifier, code accuracy becomes the relevant metric for provenance (in this case, watermark detection and payload recovery coincide). Essentially, this turns watermark detection into multi-class problem, where the number of classes grows with the number of users. For SynthID-Image, where we deliberately disentangled watermark detection and payload decoding for flexibility, we do not always need to invoke the logic for decoding the payload. 6. Ensuring security There is wide range of attacks on watermarking systems that SynthID-Image has to defend against (Zhao et al., 2025). In the following, we discuss the relevant threat models we considered. threat model describes an attackers objective, capabilities, and knowledge. Even though attackers might have different objectives, they often use common set of tools that can inform which defenses to prioritize. 6.1. Threat Models: Objectives, Capabilities, and Tools An attackers primary objectives are either watermark removal (creating false negative) to obscure content and possibly claim ownership or watermark forgery (creating false positive) to wrongly attribute ownership of potentially incriminating piece of content. Further objectives that aim at facilitating these goals include model extraction (Oh et al., 2019; Orekondy et al., 2019; TramÃ¨r et al., 2016) to steal the models themselves (or information about them, e.g., hyper-parameters,architecture details), secret extraction (Jovanovic et al., 2024) to find hidden keys (e.g., used for payload encoding), or payload attacks to manipulate the embedded information. The success of these attacks depends on the attackers capabilities. This includes their level of access, ranging from black-box (API-only) to white-box (full model weights and architecture). An attacker may also have privileged access to secrets (e.g., private keys) or possess paired information (both original and watermarked content), which significantly simplifies attacks, especially for posthoc systems like SynthID-Image. Finally, their available resources, such as query limits and computational power, constrain the feasibility of an attack. To execute an attack, adversaries can employ various tools, largely from the adversarial machine learning community (Papernot et al., 2018). (Universal) adversarial examples These are inputs with small, often imperceptible, perturbations designed to cause misclassification (Carlini and Wagner, 2017b; Szegedy et al., 2014). For watermarking, they can be used to make the decoder fail (removal) or fire incorrectly (forgery). While defenders aim for invisibility, attackers may tolerate visible artifacts, making attacks easier (Brown et al., 2017). Surrogate models Since adversarial examples often transfer between different models, an attacker can train local substitute model to craft attacks in black-box setting (Papernot et al., 2017; TramÃ¨r et al., 2016). Re-generation attacks These attacks use other powerful generative models (like diffusion models) to reconstruct watermarked image, potentially washing out the watermark in the process (An et al., 2024; Zhao et al., 2024). SynthID-Image: Image watermarking at internet scale 6.2. Defenses and discussion The main difficulty of defending against many of the above threat models is anticipating future attacks within relevant threat models (Papernot et al., 2018). These generally depend on how the watermarking scheme is deployed in practice (see Section 7). Our strategy for SynthID-Image has been to defend against attacks that are stronger than what we expect in real-world deployment. For example, ensuring robustness against white-box attacks provides strong defense against more realistic black-box threats (Croce and Hein, 2020). We identified relevant attacks through red-teaming and integrated them into our automated evaluation benchmarks to monitor trade-offs. Robust training and fine-tuning. The foundation of our defense is robust training. The watermark encoder and decoder are trained on wide range of data augmentations and transformations to help them withstand common image manipulations (Hayes, 2020; Zhu et al., 2018). Robust training may include adversarial training of the decoder (Kurakin et al., 2017; Madry et al., 2018), which aims to harden it against constrained adversarial manipulations. Additionally, for SynthID-Image, we specifically tested and ensured robustness against off-the-shelf weak re-generation attack models (e.g., using variational autoencoders). Ultimately, robustness to large range of different threat models has been shown to be particularly tricky (Maini et al., 2020; Stutz et al., 2020; TramÃ¨r and Boneh, 2019), as this will either reduce performance or require more visible watermark. However, since SynthID-Image is deployed in proprietary setting, our main goal is to make black-box attacks computationally infeasible at scale, more achievable goal than defending against determined white-box adversary. Randomness. Appropriate randomness in the watermarking process is crucial for countering certain extraction or exchange attacks. For given generative model, using the same seed and prompt should ideally produce the exact same watermarked output every time. This deterministic behavior prevents an attacker from re-generating the image to reveal differences in watermark patterns, technique known as collusion attack. On the other hand, for content that is highly predictable (e.g., due to severe memorization) or simple, an attacker might anticipate the output and attempt to forge or remove watermark. To mitigate this, the watermark generation process should incorporate stochastic elements, ensuring sufficient diversity in the watermarks applied to semantically similar but non-identical images. Specificity. To prevent watermark exchange attacks, the watermark pattern should be inextricably linked to the content it marks. We enforce this property by making the watermark generation process content-dependent. During training, we introduce specific loss functions designed to minimize the chance that watermark extracted from one piece of content can be successfully applied to another. This ensures the watermark is not merely generic stamp but specific signature of the content itself. Filtering. While detecting and filtering various types of adversarial attacks have been shown ineffective (Bryniarski et al., 2022; Carlini and Wagner, 2017a; Stutz et al., 2020), we can decide not to watermark specific content. In text watermarking (Kirchenbauer et al., 2023), for example, zero-entropy generations (e.g., due to memorization) are automatically not watermarked. Similarly, we can decide not to watermark specific corner-case content such as nearly uniform images. Such content can easily be filtered by looking at basic statistics of the content. 16 SynthID-Image: Image watermarking at internet scale 7. Internet-scale deployment Our final desiderata, requiring us to actually deploy SynthID-Image in various settings at scale, implies various practical considerations that we found rarely discussed in prior work. Some of these depend on the actual deployment scenario, while others address practicalities like decision making, versioning and combinations with other tools for provenance. Deployment settings. For SynthID-Image, we considered the following three deployment scenarios: As-an-internal-service: Here, either encoder, decoder or both are purely used for internal purposes. common construction is to allow watermarking of content generated by internal models (even if the content is then publicly served) and have detection run only internally, too. variation of this is to allow internal watermarking but expose detection externally to trusted partners or even the end-user. Note that paired information is only available internally and access to queries and secrets can be tightly controlled. As-a-service: Here, both encoder and decoder are offered as-a-service to third party companies. In this setting, third parties have access to paired information and potential secrets. Moreover, payloads need to be used to distinguish between different customers all using the same watermarking system. Again, third parties can decide to open the detection part to the end user. Open models: In this setting, either encoder, decoder or both are publicly available. This makes paired information more widely available and payloads derived from private keys become more important. In all these scenarios it is important to realize that SynthID-Image has two different components, the encoder and the decoder that are deployed differently. Also, models from the same model family, i.e., multiple SynthID-based models, might be deployed in different scenarios. The deployment specifics also affect the relevance of certain threat models in practice. This is because the attackers knowledge and level of access changes. Internal use has the smallest attack surface as access to models, paired information, and secret keys can be controlled tightly. Giving customers the possibility to produce paired information or opening encoder and/or decoder models increases the attack surface. Along this, threat models like watermark removal/false negatives become less relevant as they are particularly easy to provoke using (universal) adversarial examples against open models. False positives, in contrast, gain in importance and can be reduced through clever payload selection. In the setting where multiple similar models are released through different avenues, open models may also increase the risk to internal models by simplifying surrogate and transfer-based attacks. Decision-making. Previous work on watermarking used statistical tests for decision making on top of the decoders predictions. These approaches are often based on assuming Bernoulli distributions on the individual bits (Fernandez et al., 2023; Lukas and Kerschbaum, 2023; Roman et al., 2024; Yang et al., 2024; Yu et al., 2021) or exploit that diffusion models start from Gaussian distribution (Wen et al., 2023; Zhang et al., 2024). These are essentially parametric approaches; it has already been shown that individual bits can usually not be modeled using fair coin flips (Fernandez et al., 2023, Appendix B.5). Nevertheless, we believe that proper decision-making is important for deploying watermarking systems at large scale in responsible and reliable manner. To avoid any parametric 17 SynthID-Image: Image watermarking at internet scale assumptions, we found conformal ğ‘-values particularly scalable as they are non-parametric and recent work showed how to incorporate robustness considerations (Stutz et al., 2023). Moreover, as this approach is based on held-out set of calibration examples, it also offers an additional level of configuration before deployment. This can be important when having to react to distributional changes or minor issues for which updating the model is not an option (see Versioning below). We define the following hypotheses: ğ»0: input is not watermarked and ğ»1: input is watermarked. We then compute valid ğ‘-values following Bates et al. (2021, 2023) for both hypotheses using ğ‘–=1 and {ğ’™ (1) }ğ‘› }ğ‘› held-out set of calibration examples {ğ’™ ğ‘–=1 of non-watermarked and watermarked samples, respectively: (0) ğ‘– ğœŒğ‘˜ (ğ’™) = 1 + (cid:205)ğ‘› ğ‘–=1 ğ›¿[(2ğ‘˜ 1) ğ‘“0(ğ’™) (2ğ‘˜ 1) ğ‘“0(ğ’™ (ğ‘˜) ğ‘– )] ğ‘› + (6) where ğ‘“0() correspond to the detection logit. As these are valid ğ‘-values, i.e., ğœŒğ‘˜ is uniformly distributed over [0, 1] iff ğ»ğ‘˜ is true, thresholding ğœŒ0 (ğœŒ1) at ğ›¼ guarantees FPR (TPR) of at most ğ›¼ (at least 1 ğ›¼). We can control FPR and TPR simultaneously by allowing variable abstention rate. The calibration set can be updated online if necessary and include different transformations of the same image for robustness.8 Assuming an individual logit ğ‘“ ğ‘— () for each bit ğ‘ ğ‘— {1}, ğ‘— {1, . . . , ğ¶}, we can also compute ğ‘-values for each bit ğ‘ ğ‘— being positive or negative. Given an encoded payload ğ’„ = (ğ‘1, . . . , ğ‘ğ¶), we can then test whether the payload is likely the original one using any standard multiple hypothesis testing procedure (Hochberg, 1988; Holm, 1979; Simes, 1986). These methods usually come with confidence level ğ›¼ which controls the rate of correctly accepting the true payload. However, with larger ğ¶, these methods become more conservative. Especially in light of transformations this leads to possibly multiple payloads being accepted. This can be countered using redundant coding techniques. Again, an abstention mechanism can be created easily: if all used payloads ğ’„ can be enumerated, we can abstain if multiple payloads are accepted and the number of accepted payloads is often good mirror of whether the artifact has been tampered with or not. Versioning. Versioning is an important aspect of deploying at scale and for the long term. In the case of SynthID-Image, the encoder always determines the main version. This is because once watermarked content is out in the wild, we have to be able to detect it. The decoder, in contrast, can be updated much more easily. In sense this means that we need strict versioning for the encoder while the decoder can be updated continuously. This also implies that threat models that can be addressed in the encoder are more important. For example, once an encoder has been deployed, it is difficult to increase the diversity of watermarks or prevent watermark extraction. The decoder, in contrast, can be updated on the fly to address new attacks. Having the encoder determine the version means that eventually there will be multiple versions in production, assuming that watermarking quality, robustness and payload size will be improved over the coming years. This entails having to detect multiple versions of watermarks over time. This adds additional resource requirements, complicates decision making, and vulnerability might be inherited between versions. Combination with search and C2PA. For tackling provenance of AI-generated content, watermarking is promising but not the only tool at our disposal (Collomosse and Parsons, 2024). Generally, we expect watermarking to be deployed alongside metadata-based standard like C2PA which major companies vowed to implement. Moreover, there are also technologies based on search and retrieval. 8Following Stutz et al. (2023), this reduces the guaranteed FPR (TPR) to 2ğ›¼ (1 2ğ›¼); however, this drop is never observed empirically. 18 SynthID-Image: Image watermarking at internet scale For SynthID-Image, we explored various combinations, and focused on fingerprinting, which refers to the practice of computing low-dimensional embeddings for multimedia artifacts and storing them in an internal database. Learning such embeddings in robust way (Gowal et al., 2021) allows verifying the origin of AI-generated content using similarity search. Various works have applied variations of this idea to attribution and content provenance in the widest sense (Balan et al., 2023; Bharati et al., 2021; Nguyen et al., 2021; Saberi et al., 2024b; Zhang et al., 2020b). In comparison to watermarking, similarity search is more prone to false positives rather than false negatives. On its own, fingerprinting suffers from increased cost for storing embeddings (on top of the embedding cost) and poor scaling as false positives increase with database size. This means that there needs to be retention rules that e.g. store embeddings of generated content only within specific time-frame. However, as fingerprinting has complementary failure modes, it is natural to combine both approaches. For example, to mitigate forgery attacks, an image must not only contain the correct watermark payload but also match one of the stored embeddings. 8. Experimental results We evaluate the robustness and quality of our external SynthID-Image watermarking model variant, denoted SynthID-O. SynthID-O can encode 136-bit payloads within 512512 pixel images. We compare this variant against wide range of baselines. Our experiments show that SynthID-O establishes new state-of-the-art watermarking performance. Specifically, we find that it outperforms others in terms of quality, considering an extensive human rating study, and shows superior detection performance across comprehensive list of image transformations. Results are summarized in Figure 1. In this section, we provide further details. Baselines. To measure detection performance of given model, we leverage the models detection score if available or use the number of correct payload bits as score proxy (as proposed previously, e.g., Fernandez et al., 2023). To measure payload recovery performance, we directly measure the bit accuracy for models that provide it.9 We evaluate all models without any error code correction. We compare against the following: StegaStamp(Tancik et al., 2020): We use the model checkpoint released in the official repository.10 It can encode 100-bit payloads within 400400 pixel images. TrustMark(Bui et al., 2025): Our primary results leverage the TrustMark-Q and TrustMark-P variants. 11 We chose TrustMark-Q over TrustMark-B because, even though it prioritizes image quality over robustness compared to TrustMark-B, our evaluation found it to be more robust overall. All TrustMark variants can encode 100-bit payloads within 256256 pixel images. InvisMark (Xu et al., 2025): We use the model checkpoint released in the official repository.12 It can encode 100-bit payloads within 256256 pixel images. WAM (Sander et al., 2025): We use the model checkpoint released in the official repository.13 It can encode 32-bit payloads within 256256 pixel images. Note that WAM can be used to watermark individual areas within an image, we use it here to watermark full images. As detection score, we use the area of the detection mask returned by the model. For payload recovery, we use the semi-hard strategy. 9Note that bit accuracy performance depends heavily on the payload length ğ¶ and this might not be useful point of comparison. 10https://github.com/tancik/StegaStamp 11https://github.com/adobe/trustmark/tree/main/python 12https://github.com/microsoft/InvisMark 13https://github.com/facebookresearch/watermark-anything 19 SynthID-Image: Image watermarking at internet scale VideoSeal (Fernandez et al., 2024): We use the model checkpoints released in the official repository.14 VideoSeal-0.0 and VideoSeal-1.0 can encode 96-bit payloads and 256-bit payloads within 256256 pixel images, respectively. Note that VideoSeal was primarily developed to add watermarks to videos. However, it can be used for images. As detection score, we use the number of correct payload bits as using the available detection logit performs badly for the available checkpoints. For all methods, we use the default parameters provided by the authors in their individual code repositories. We use the watermark rescaling method presented by Bui et al. (2023) with bicubic resizing (which we found to outperform bilinear resizing consistently across all methods). 8.1. Quality evaluations Setup. As explained in Section 3, we perform human evaluations to assess the quality of SynthID-O and the models listed above. For each model, we collect 10,000 ratings (5,000 for watermarked and 5,000 for non-watermarked samples) using 1,000 images generated by Imagen.15 Unlike ImageNet which is used in the robustness evaluation, all images have resolution of 15361536, which reflects real-world product conditions with the focus placed on quality (as desired by creators). Images are generated across 25 high-level creative categories shown in Figure 2. Each high-level category is further sub-divided into different styles such as black & white and colorful for abstract art. All prompts are listed in the appendix (see Section B). We introduce 10 additional dummy images that exhibit clear artifacts. Ratings from raters with less than 70% success rate at correctly identifying dummy images are excluded from the study. Results. Figure 1 and 4 (top-left) report the average difference in human identified artifact rate between watermarked and non-watermarked samples. 5 percent point increase indicates that the corresponding watermarking method creates newly visible artifacts in at least 5% of the images (it is lower bound). SynthID-O performs best, followed by VideoSeal-1.0, InvisMark and WAM. StegaStamp has the largest reported artifacts rate, validating our observation that its high robustness relative to existing watermarking models comes at the cost of large degradation in quality. We also report computational quality metrics on the same clean and watermarked image pairs in Figure 4. While computational metrics tend to correlate with human judgment, they fail to capture obvious artifacts (especially when those are small in size). This is clearly noticeable for VideoSeal-0.0 and TrustMark-Q which exhibit strong performance on computational metrics, but do poorly on the human evaluation.16 8.2. Robustness evaluation Setup. We evaluate all models on consistent set of 10,000 images from ImageNets validation set. We focus this evaluation on photo-realistic content which is the most likely source of misinformation. The robustness of detection and payload recovery is assessed under 30 common image transformations (shown on Figure 3). In this section, we evaluate images at resolution of 512512. Evaluations at native image resolutions are shown in Appendix A.1. Evaluations where images are transformed after being resized at each methods preferred resolution are shown in Appendix A.2. We group image transformations into six categories: Color, Combination, Noise, Overlay, Quality and 14https://github.com/facebookresearch/videoseal 15https://deepmind.google/technologies/imagen-2/ 16It is worth noting that in side-by-side evaluations where trained raters are asked to tell which one between two almost identical images is watermarked, all methods (except SynthID) do poorly. 20 SynthID-Image: Image watermarking at internet scale Figure 4 Quality metrics for all methods computed on 1,000 watermarked and unwatermarked images. The top-left panel shows the average difference in identified artifact rate between watermarked and nonwatermarked samples (lower is better). 5 percent point increase indicates that the watermarking method creates visible artifacts in 5% of the images. For FID, CMMD and LPIPS the lower is better and for PSNR and SSIM the higher is better. Overall, we see little correlation between computational metrics and human ratings. Spatial. Aggregated includes all transformations across categories, and Identity applies no transformation. Additionally, we use two evaluation settings: Random: The strength of each transformation is sampled uniformly from within specified range. Worst: The strength of each transformation is set to its most severe value, typically an extreme within the range described above. While the random setting simulates real-world variability, worst setting allows us to discern the limits of model performance under extreme image manipulation. Unless stated otherwise, the models are calibrated to obtain 0.1% false positive rate in average on worst-case transformations. Detection results. In this section, we focus exclusively on the detection performance under various image transformations. For models that offer detection score independent of payload recovery (i.e., SynthID-O and WAM), we use this score. For models that solely perform payload recovery, we compute the detection score by counting the number of correctly decoded bits (as done by Fernandez et al., 2023).17 We do not observe any significant difference when using weighted sum over payload logits. We also include the performance of SynthID-O and WAM using payload matching in separate table. Table 1 summarizes the results. It reports the true positive rate (TPR) at fixed false positive rate 17This implies that, for all methods except SynthID-O and WAM, we assume that there is single, unique known payload we can match. 21 SynthID-Image: Image watermarking at internet scale SynthID-O InvisMark StegaStamp TrustMark-P TrustMark-Q Identity (excl. resizing) Aggregated Color Combination Noise Overlay Quality Spatial Aggregated Worst Color Worst Combination Worst Noise Worst Overlay Worst Quality Worst Spatial Worst 100.00% 100.00% 99.98% [70.06%, 70.41%] 100.00% [75.34%, 75.49%] 99.96% [22.28%, 23.19%] [92.10%, 92.73%] 99.98% 100.00% 100.00% 99.99% [89.51%, 89.78%] 99.98% [61.09%, 61.32%] 99.72% [60.11%, 60.53%] 100.00% [69.58%, 69.67%] [6.83%, 7.89%] 98.06% [80.86%, 82.05%] 99.96% 100.00% 100.00% 99.99% [76.24%, 76.73%] 99.97% [50.06%, 50.13%] 100.00% [72.41%, 72.57%] 99.95% [49.62%, 49.75%] 100.00% 100.00% 100.00% [25.23%, 25.73%] [66.51%, 66.79%] [99.79%, 99.82%] [27.07%, 27.83%] 100.00% 100.00% 100.00% [15.25%, 15.87%] [99.95%, 99.96%] [66.25%, 66.74%] [79.22%, 79.82%] [23.06%, 24.46%] [95.10%, 95.49%] [99.71%, 99.73%] [97.56%, 97.72%] [38.05%, 38.32%] [54.15%, 54.68%] [66.32%, 67.16%] [4.16%, 4.76%] [88.13%, 89.02%] [98.76%, 98.85%] [84.65%, 85.36%] [25.09%, 25.17%] 100.00% [78.61%, 79.02%] [99.65%, 99.69%] [64.00%, 66.25%] 100.00% 99.99% 100.00% [40.75%, 41.04%] [68.73%, 68.87%] [98.93%, 99.05%] [21.22%, 21.72%] 99.99% [99.87%, 99.89%] 99.99% [25.76%, 25.92%] VideoSeal-0.0 100.00% [78.35%, 78.91%] [75.97%, 76.22%] [77.67%, 79.65%] [96.93%, 97.37%] [99.93%, 99.95%] [98.60%, 98.76%] [55.95%, 56.46%] [61.22%, 61.91%] [66.19%, 66.49%] [27.71%, 29.05%] [90.77%, 91.93%] [99.79%, 99.83%] [81.84%, 82.97%] [38.89%, 39.32%] VideoSeal-1.0 WAM 100.00% 99.98% 90.62% [88.75%, 88.87%] 81.29% [99.86%, 99.87%] [84.59%, 84.91%] 96.08% [99.11%, 99.18%] 100.00% 100.00% 99.99% 99.97% 99.99% 84.34% [67.47%, 67.72%] 83.37% [76.74%, 76.89%] 84.00% [99.69%, 99.71%] [31.00%, 31.38%] 55.96% [97.73%, 97.89%] 100.00% 100.00% 99.38% 76.04% 99.97% 99.98% [51.62%, 51.86%] Table 1 TPR at 0.1% FPR aggregated across each transformation category when images are resized to 512512. For each model, the detection threshold is calibrated to reach 0.1% FPR across all worst transformations in average. When brackets are used, we display the range of TPR values that can accommodate the target FPR (this number is not unique when there are ties). SynthID-O WAM Identity (excl. resizing) Aggregated Color Combination Noise Overlay Quality Spatial Aggregated Worst Color Worst Combination Worst Noise Worst Overlay Worst Quality Worst Spatial Worst 100.00% [99.96%, 99.97%] [99.99%, 100.00%] [99.92%, 99.93%] [99.89%, 99.90%] 100.00% [99.96%, 99.97%] 99.98% [98.84%, 98.90%] 99.99% [91.96%, 92.36%] [99.74%, 99.77%] 100.00% 99.97% 99.97% [99.96%, 99.98%] [81.26%, 81.85%] [77.16%, 77.31%] [89.68%, 92.56%] [99.95%, 99.98%] [99.96%, 99.98%] [99.70%, 99.79%] [57.39%, 57.91%] [69.11%, 69.91%] [69.78%, 69.82%] [36.25%, 39.52%] [99.95%, 99.98%] [99.97%, 99.98%] [95.21%, 96.29%] [48.76%, 49.45%] Table 2 TPR at 0.1% FPR aggregated across each transform category when images are resized to 512512. The detection is performed by computing the number of correct bits in the payload. For each model, the detection threshold is calibrated to reach 0.1% FPR across all worst transformations. Models that are not listed here are already listed in Table 1. When brackets are used, we display the range of TPR values that can accommodate the target FPR (this number is not unique when there are ties). of 0.1% in average on worst-case transformations. We observe that over aggregated random and aggregated worst transformations, SynthID-O outperforms all other methods by significant margins (i.e., +9.36 and +16.35 percentage points respectively). In the worst setting, SynthID-O is the only models surpassing 99% TPR in aggregate and it reaches more than 98% TPR on combinations of transformations (which is the most challenging setting). Overall, it is worth noting that not single model outperforms all others across all categories. Comparisons are made more difficult when we start considering quality: StegaStamp is the worst offender in terms of quality and, as result, it is regularly topping individual categories in terms of robustness. For completeness, we also report the detection performance of SynthID-O and WAM if they were to use their payload for detection in Table 2. Payload recovery results. We report the bit accuracy measured on watermarked images (as detailed in Section 5). Table 3 compares SynthID-O to other models. We observe that SynthID-O often surpasses other models despite having larger payload (except VideoSeal-1.0) and better quality. WAM which tops few categories only has 32-bit payload. 22 SynthID-Image: Image watermarking at internet scale SynthID-O ( bits) InvisMark (100 bits) StegaStamp ( bits) TrustMark-P (100 bits) TrustMark-Q ( bits) VideoSeal-0.0 bits) (96 VideoSeal-1.0 ( bits) Identity (excl. resizing) Aggregated Color Combination Noise Overlay Quality Spatial Aggregated Worst Color Worst Combination Worst Noise Worst Overlay Worst Quality Worst Spatial Worst 100.00% 99.59% 99.97% 99.12% 98.57% 100.00% 99.73% 99.82% 98.07% 99.93% 89.46% 97.63% 99.99% 99.49% 99.77% 95.04% 79.28% 82.47% 56.57% 85.21% 94.62% 88.56% 76.40% 75.26% 78.31% 52.60% 80.61% 93.91% 84.17% 72.13% 99.84% 85.03% 99.14% 70.45% 99.61% 99.66% 99.75% 61.68% 82.58% 98.19% 62.62% 99.44% 99.04% 99.57% 57.87% 99.23% 79.46% 84.53% 58.64% 89.26% 97.55% 95.30% 68.09% 73.29% 76.86% 51.69% 84.64% 93.69% 89.02% 62.33% 99.91% 87.27% 98.16% 74.10% 98.85% 98.93% 99.62% 69.43% 82.47% 96.03% 58.16% 98.07% 94.80% 99.05% 63.04% 96.94% 82.67% 83.24% 74.75% 87.98% 96.24% 93.13% 74.85% 76.03% 78.16% 59.06% 84.34% 95.55% 87.00% 68.14% 99.61% 89.60% 97.60% 79.31% 90.13% 99.27% 98.75% 80.47% 83.53% 95.10% 60.49% 86.10% 98.52% 97.34% 73.00% WAM bits) (32 99.96% 90.62% 88.42% 93.04% 99.94% 99.96% 99.65% 79.83% 85.03% 84.29% 71.86% 99.91% 99.96% 97.30% 74.97% Table 3 Payload bit accuracy aggregated across each transformation category when images are resized to 512512. Note that numbers are not directly comparable as the payload size is different for different methods. 9. Related work While this paper is not meant to be comprehensive survey on watermarking we refer to Wan et al. (2022) for relatively recent overview we want to provide short overview of watermarking in general and recent developments in deploying watermarking alongside generative AI. Besides presenting results for SynthID-Image, this paper also touches on robustness, threat models and practical concerns. In this spirit, our paper is similar to this recent State-of-Knowledge on watermarking (Zhao et al., 2025). To the best of our knowledge, Braudaway (1997); Van Schyndel et al. (1994) presented the first invisible watermarks. As visible watermarks were not yet automatically removable as easily as today (Dekel et al., 2017), early work in invisible watermarking was closely entangled with steganography (Cox, 2007). Irrespective of the use, early methods either used the spatial or frequency domain to hide information. For example, Wang et al. (2001) hide information in less important bits across pixels. This is not very robust to common image transformations (Fazli and Khodaverdi, 2009). Instead, long line of work uses DCT (Ahmed et al., 1974) or DWT (Shensa, 1992) transforms. Well-received examples include Barni et al. (1998); Chen and Wornell (1998, 2001); Parah et al. (2016) and Barni et al. (2001); Kashyap and Sinha (2012), respectively. Approaches working in the spatial and frequency domains have also been combined, e.g., using DCT-SVD approaches (Singh and Singh, 2017; Su and Chen, 2018). Recently, DCT and DWT based approaches have been re-popularized due to their usage by Stability AI18 despite their flaws compared to recent deep learning based methods. While there are early experiments using neural networks for watermark detection in (Yu et al., 2001), proper deep learning based approaches gained traction around 2017 (Mun et al., 2017; Zhu et al., 2018). Usually, encoder-decoder architectures (i.e., content-based, post-hoc methods) tried to improve on quality and robustness (Bui et al., 2023, 2025; Hayes and Danezis, 2017; Hayes et al., 2020; Luo et al., 2020; Pan et al., 2023, 2024; Tancik et al., 2020; Wen and AydÃ¶re, 2019; Xu et al., 2025). Recently, these approaches have been extended to allow localization of (multiple) watermarks (Sander et al., 2025). Only more recently, with the rise of diffusion models (Ho et al., 2020; Sohl-Dickstein et al., 2015) such as stable diffusion (Rombach et al., 2022), watermarking has been integrated into the generation process; see Fernandez et al. (2023); Wen et al. (2023); Yang et al. (2024). The pros and cons have been discussed at length in Section 2. These works usually 18https://github.com/Stability-AI/invisible-watermark-gpu SynthID-Image: Image watermarking at internet scale exclusively focus on image watermarking; literature on video (Fernandez et al., 2024; Zhang et al., 2020a) or audio watermarking (Hua et al., 2016; Roman et al., 2024) tends to be sparse, possibly because methods are usually general enough across these modalities. The importance of appropriate benchmarks for watermarking has been highlighted as early as 2000 (Petitcolas, 2000) with thorough account of possible attacks some years later by Cox (2007). More recently, An et al. (2024) introduced an up-to-date and relatively comprehensive benchmark of deep learning based watermarking techniques. Proper benchmarking also includes considering variety of (adaptive) attacks (Lukas et al., 2024; Saberi et al., 2024a; Zhao et al., 2024), many of which have been discussed at length in Section 6. Meta also maintains benchmark for image watermarking, called Omni Seal Bench.19 In terms of deployed systems at the time of writing, the solution used by Stability AI20 has received considerable attention, but usage is difficult to track. Imatag released several models on Hugging Face, including StableSignature (Fernandez et al., 2023) based one.21 However, the corresponding proprietary service seems to focus on content tracking and information leak identification.22 For DALL-E 223, OpenAI experimented with visible watermark referred to as coloured squares by users. While there was no official communication on this, and OpenAIs FAQs state that users are allowed to remove it,24 this can be understood as an early approach to watermarking. More recently, for DALL-E 3,25 OpenAI announced both C2PA metadata as well as proper invisible watermarking (for image and audio). To date, however, this has not been released. Instead, OpenAI showcased early results for AI-generated image detection,26 which seems rather fragile under certain transformations. Meta recently announced to follow C2PA specifications and reveal this information to users on Facebook, Instragram and Threads.27 Meta seems to pursue invisible watermarking across modalities, as well, with some open-source models (Fernandez et al., 2024; Roman et al., 2024; Sander et al., 2025) but no concrete public-facing verification system yet. Similarly, Microsoft published and open-sourced an image watermarking model (Xu et al., 2025).28 Overall, this makes SynthID-Image the first system deployed at large-scale that consistently watermarks large amounts of generated content and discloses this information to end users. 10. Limitations and future work Despite its success, SynthID-Image alone will not solve many of the problems we set out to alleviate, including misinformation, impersonation or copyright tracking. This is because watermarking in itself does not solve the provenance problem. Instead, SynthID-Image needs to become part of an ecosystem of tools, including C2PA, that are adopted by all major players across industry and governments to watermark AI-generated content and surface this information to the public. This requires both technological advancements as well as work on policy and cooperation across companies and governments. Besides, there are various technical challenges that we believe will become important with advancements in generative AI. For example, SynthID operates on text, images, audio or video. Thus, work on detection and handling fractional watermarks becomes important. Similarly, we likely need larger payloads as use cases of generative AI grow and we want 19https://github.com/facebookresearch/omnisealbench 20https://github.com/ShieldMnt/invisible-watermark 21https://huggingface.co/imatag/stable-signature-bzh-sdxl-vae-weak 22https://www.imatag.com/ 23https://openai.com/index/dall-e-2/ 24https://web.archive.org/web/*/https://help.openai.com/en/articles/6468065-dall-e-2-faq 25https://openai.com/index/dall-e-3/ 26https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online/ 27https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/ 28https://github.com/microsoft/InvisMark 24 SynthID-Image: Image watermarking at internet scale to enable public detectability using cryptographic signatures (Fairoze et al., 2025). For open models, we need to work on improving security, particularly considering white-box threat models and we generally need to figure out proper versioning of watermarks, assuming that multiple watermarking solutions will be available soon."
        },
        {
            "title": "Acknowledgments",
            "content": "We would like to thank Demis Hassabis for starting, sponsoring and advising throughout this project. We thank Clement Wolf, Ian Goodfellow, Chris Bregler and Oriol Vinyals for their advice. We also thank many others who contributed across Google DeepMind and Google, including our partners at Google Research, Google Cloud, Google Global Business & Operations and YouTube."
        },
        {
            "title": "References",
            "content": "Y. Adi, C. Baum, M. CissÃ©, B. Pinkas, and J. Keshet. Turning your weakness into strength: Watermarking deep neural networks by backdooring. In USENIX Security Symposium, pages 16151631, 2018. S. Agarwal, H. Farid, Y. Gu, M. He, K. Nagano, and H. Li. Protecting world leaders against deep fakes. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. N. Ahmed, T. R. Natarajan, and K. R. Rao. Discrete cosine transform. IEEE Transactions on Computers, 23(1):9093, 1974. R. Alaifari, G. S. Alberti, and T. Gauksson. ADef: An iterative algorithm to construct adversarial deformations. In Proc. of the International Conference on Learning Representations (ICLR), 2019. B. An, M. Ding, T. Rabbani, A. Agrawal, Y. Xu, C. Deng, S. Zhu, A. Mohamed, Y. Wen, T. Goldstein, and F. Huang. WAVES: Benchmarking the robustness of image watermarks. In Proc. of the International Conference on Machine Learning (ICML), 2024. R. J. Anderson, editor. Information Hiding, First International Workshop, Cambridge, UK, May 30 - June 1, 1996, Proceedings, volume 1174, 1996. K. Balan, S. Agarwal, S. Jenni, A. Parsons, A. Gilbert, and J. P. Collomosse. EKILA: Synthetic media provenance and attribution for generative art. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2023. M. Barni, F. Bartolini, V. Cappellini, and A. Piva. DCT-domain system for robust image watermarking. Signal Processing, 66(3):357372, 1998. M. Barni, F. Bartolini, and A. Piva. Improved wavelet-based watermarking through pixel-wise masking. IEEE Trans. on Image Processing (TIP), 10(5):783791, 2001. S. Bates, E. Candes, L. Lei, Y. Romano, and M. Sesia. Calibrated out-of-distribution detection with conformal p-values. In Proc. of the International Conference on Machine Learning (ICML) Workshops, 2021. S. Bates, J. CandÃ¨s, L. Lei, Y. Romano, and M. Sesia. Testing for outliers with conformal p-values. Ann. of Statistics, 51(1):149178, 2023. SynthID-Image: Image watermarking at internet scale A. Bharati, D. Moreira, P. J. Flynn, A. de Rezende Rocha, K. W. Bowyer, and W. J. Scheirer. Transformation-aware embeddings for image provenance. Proc. of the IEEE Transactions on Information Forensics and Security, 16, 2021. B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Srndic, P. Laskov, G. Giacinto, and F. Roli. Evasion attacks against machine learning at test time. In Proc. of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD), 2013. G. W. Braudaway. Protecting publicly-available images with an invisible image watermark. In Proc. of the IEEE International Conference on Image Processing (ICIP), 1997. T. B. Brown, D. ManÃ©, A. Roy, M. Abadi, and J. Gilmer. Adversarial patch. arXiv.org, abs/1712.09665, 2017. O. Bryniarski, N. Hingun, P. Pachuca, V. Wang, and N. Carlini. Evading adversarial example detection defenses with orthogonal projected gradient descent. In Proc. of the International Conference on Learning Representations (ICLR), 2022. T. Bui, S. Agarwal, N. Yu, and J. P. Collomosse. RoSteALS: Robust steganography using autoencoder latent space. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023. T. Bui, S. Agarwal, and J. P. Collomosse. TrustMark: Universal watermarking for arbitrary resolution images. In Proc. of the IEEE International Conference on Computer Vision (ICCV), 2025. N. Carlini and H. Farid. Evading deepfake-image detectors with whiteand black-box attacks. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. N. Carlini and D. Wagner. Adversarial examples are not easily detected: Bypassing ten detection methods. In Proc. of the ACM Workshop on Artificial Intelligence and Security, 2017a. N. Carlini and D. Wagner. Towards evaluating the robustness of neural networks. In Proc. of the IEEE Symposium on Security and Privacy, 2017b. B. Chen and G. W. Wornell. Digital watermarking and information embedding using dither modulation. In IEEE Workshop on Multimedia Signal Processing (MMSP), 1998. B. Chen and G. W. Wornell. Quantization index modulation: class of provably good methods for digital watermarking and information embedding. IEEE Transactions on Information Theory, 47(4): 14231443, 2001. M. Christ, S. Gunn, and O. Zamir. Undetectable watermarks for language models. In Proc. of the Conference on Learning Theory (COLT), 2024. Coalition for Content Provenance and Authenticity. C2PA technical specifications version 1.3. https://c2pa.org/specifications/specifications/1.3/specs/C2PA_Specification.html, 2023. Online; accessed Mar 15 2024. J. Collomosse and A. Parsons. To authenticity, and beyond! Building safe and fair generative AI upon the three pillars of provenance. IEEE Computer Graphics and Applications, 44(3):8290, 2024. I. Cox. Digital watermarking and steganography. The Morgan Kaufmann Series in Multimedia Information and Systems, 2:893914, 2007. F. Croce and M. Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. In Proc. of the International Conference on Machine Learning (ICML), 2020. 26 SynthID-Image: Image watermarking at internet scale S. Dathathri, A. See, S. Ghaisas, P.-S. Huang, R. McAdam, J. Welbl, V. Bachani, A. Kaskasoli, R. Stanforth, T. Matejovicova, et al. Scalable watermarking for identifying large language model outputs. Nature, 634(8035):818823, 2024. T. Dekel, M. Rubinstein, C. Liu, and W. T. Freeman. On the effectiveness of visible watermarks. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. B. Dumont, S. Maggio, and P. Montalvo. Robustness of rotation-equivariant networks to adversarial perturbations. arXiv.org, abs/1802.06627, 2018. L. Engstrom, D. Tsipras, L. Schmidt, and A. Madry. rotation and translation suffice: Fooling CNNs with simple transformations. arXiv.org, abs/1712.02779, 2017. J. Fairoze, G. Ortiz-Jimenez, M. Vecerik, S. Jha, and S. Gowal. On the difficulty of constructing robust and publicly-detectable watermark. In Conference on Artificial Intelligence and Statistics (AISTATS), 2025. S. Fazli and G. Khodaverdi. Trade-off between imperceptibility and robustness of LSB watermarking using SSIM quality metrics. In Proc. of the International Conference on Machine Vision, 2009. P. Fernandez, G. Couairon, H. JÃ©gou, M. Douze, and T. Furon. The stable signature: Rooting watermarks in latent diffusion models. In Proc. of the IEEE International Conference on Computer Vision (ICCV), 2023. P. Fernandez, H. Elsahar, I. Z. Yalniz, and A. Mourachko. Video Seal: Open and efficient video watermarking. arXiv preprint arXiv:2412.09492, 2024. S. Gowal, P.-S. Huang, A. van den Oord, T. Mann, and P. Kohli. Self-supervised adversarial robustness for the low-label, high-data regime. In Proc. of the International Conference on Learning Representations (ICLR), 2021. S. Gunn, X. Zhao, and D. Song. An undetectable watermark for generative image models. In Proc. of the International Conference on Learning Representations (ICLR), 2025. J. Hayes. Provable trade-offs between private & robust machine learning. arXiv.org, abs/2006.04622, 2020. J. Hayes and G. Danezis. Generating steganographic images via adversarial training. In Advances in Neural Information Processing Systems (NeurIPS), 2017. J. Hayes, K. Dvijotham, Y. Chen, S. Dieleman, P. Kohli, and N. Casagrande. Towards transformationresilient provenance detection of digital media. arXiv.org, abs/2011.07355, 2020. D. Hendrycks and T. G. Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In Proc. of the International Conference on Learning Representations (ICLR), 2019. D. Hendrycks, M. Mazeika, and T. G. Dietterich. Deep anomaly detection with outlier exposure. In Proc. of the International Conference on Learning Representations (ICLR), 2019. M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by two time-scale update rule converge to local Nash equilibrium. In Advances in Neural Information Processing Systems (NeurIPS), 2017. J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models."
        },
        {
            "title": "In Advances in Neural",
            "content": "Information Processing Systems (NeurIPS), 2020. 27 SynthID-Image: Image watermarking at internet scale Y. Hochberg. sharper Bonferroni procedure for multiple tests of significance. Biometrika, 75(4): 800802, 1988. S. Holm. simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, pages 6570, 1979. G. Hua, J. Huang, Y. Q. Shi, J. Goh, and V. L. L. Thing. Twenty years of digital audio watermarking - comprehensive review. Signal Processing, 128:222242, 2016. S. Jayasumana, S. Ramalingam, A. Veit, D. Glasner, A. Chakrabarti, and S. Kumar. Rethinking FID: Towards better evaluation metric for image generation. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024. N. Jovanovic, R. Staab, and M. T. Vechev. Watermark stealing in large language models. In Proc. of the International Conference on Machine Learning (ICML), 2024. P. Kadian, S. M. Arora, and N. Arora. Robust digital watermarking techniques for copyright protection of digital data: survey. Wireless Personal Communications, 118(4), 2021. N. Kashyap and G. Sinha. Image watermarking using 3-level discrete wavelet transform (DWT). International Journal of Modern Education and Computer Science, 4(3):50, 2012. J. Kirchenbauer, J. Geiping, Y. Wen, J. Katz, I. Miers, and T. Goldstein. watermark for large language models. In Proc. of the International Conference on Machine Learning (ICML), 2023. A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial examples in the physical world. In Proc. of the International Conference on Learning Representations (ICLR), 2017. N. Lukas and F. Kerschbaum. PTW: Pivotal tuning watermarking for pre-trained image generators. In USENIX Security Symposium, 2023. N. Lukas, A. Diaa, L. Fenaux, and F. Kerschbaum. Leveraging optimization for adaptive attacks on image watermarks. In Proc. of the International Conference on Learning Representations (ICLR), 2024. X. Luo, R. Zhan, H. Chang, F. Yang, and P. Milanfar. Distortion agnostic deep watermarking. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. Proc. of the International Conference on Learning Representations (ICLR), 2018. P. Maini, E. Wong, and J. Z. Kolter. Adversarial robustness against the union of multiple perturbation models. In Proc. of the International Conference on Machine Learning (ICML), 2020. S. Mun, S. Nam, H. Jang, D. Kim, and H. Lee. robust blind watermarking using convolutional neural network. arXiv.org, abs/1704.03248, 2017. E. Nguyen, T. Bui, V. V. Swaminathan, and J. P. Collomosse. OSCAR-Net: Object-centric scene graph attention for image attribution. In Proc. of the IEEE International Conference on Computer Vision (ICCV), 2021. S. J. Oh, B. Schiele, and M. Fritz. Towards Reverse-Engineering Black-Box Neural Networks, pages 121144. 2019. In book: Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. T. Orekondy, B. Schiele, and M. Fritz. Knockoff nets: Stealing functionality of black-box models. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. 28 SynthID-Image: Image watermarking at internet scale T. Orekondy, B. Schiele, and M. Fritz. Prediction poisoning: Towards defenses against DNN model stealing attacks. In Proc. of the International Conference on Learning Representations (ICLR), 2020. M. Pan, Y. Zeng, X. Lin, N. Yu, C.-J. Hsieh, and R. Jia. AnchMark: Anchor-contrastive watermarking vs GenAI-based image modifications. In Advances in Neural Information Processing Systems (NeurIPS) Workshops, 2023. M. Pan, Y. Zeng, X. Lin, N. Yu, C.-J. Hsieh, P. Henderson, and R. Jia. JIGMARK: black-box approach for enhancing image watermarks against diffusion model edits. arXiv.org, abs/406.03720, 2024. N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami. Practical black-box attacks against machine learning. In Proc. of the ACM on Asia Conference on Computer and Communications Security (AsiaCCS). ACM, 2017. N. Papernot, P. D. McDaniel, A. Sinha, and M. P. Wellman. SoK: Security and privacy in machine learning. In Proc. of the IEEE European Symposium on Security and Privacy (EuroS&P), 2018. S. A. Parah, J. A. Sheikh, N. A. Loan, and G. M. Bhat. Robust and blind watermarking technique in DCT domain using inter-block coefficient differencing. Digital Signal Processing, 53:1124, 2016. F. A. P. Petitcolas. Watermarking schemes evaluation. Signal Processing Magazine, 17(5), 2000. J. Piet, C. Sitawarin, V. Fang, N. Mu, and D. A. Wagner. MarkMyWords: Analyzing and evaluating language model watermarks. In IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 2025. A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al. Learning transferable visual models from natural language supervision. In Proc. of the International Conference on Machine Learning (ICML), 2021. R. S. Roman, P. Fernandez, A. DÃ©fossez, T. Furon, T. Tran, and H. Elsahar. Proactive detection of voice cloning with localized watermarking. In Proc. of the International Conference on Machine Learning (ICML), 2024. R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with latent diffusion models. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. M. Saberi, V. S. Sadasivan, K. Rezaei, A. Kumar, A. M. Chegini, W. Wang, and S. Feizi. Robustness In Proc. of the International of AI-image detectors: Fundamental limits and practical attacks. Conference on Learning Representations (ICLR), 2024a. M. Saberi, V. S. Sadasivan, A. Zarei, H. Mahdavifar, and S. Feizi. DREW: Towards robust data provenance by leveraging error-controlled watermarking. arXiv.org, abs/2406.02836, 2024b. T. Sander, P. Fernandez, A. Durmus, T. Furon, and M. Douze. Watermark anything with localized messages. In Proc. of the International Conference on Learning Representations (ICLR), 2025. T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ilic, D. Hesslow, R. CastagnÃ©, A. S. Luccioni, F. Yvon, M. GallÃ©, J. Tow, A. M. Rush, S. Biderman, A. Webson, P. S. Ammanamanchi, T. Wang, B. Sagot, N. Muennighoff, A. V. del Moral, O. Ruwase, R. Bawden, S. Bekman, A. McMillan-Major, I. Beltagy, H. Nguyen, L. Saulnier, S. Tan, P. O. Suarez, V. Sanh, H. LaurenÃ§on, Y. Jernite, J. Launay, M. Mitchell, C. Raffel, A. Gokaslan, A. Simhi, A. Soroa, A. F. Aji, A. Alfassy, A. Rogers, A. K. Nitzav, C. Xu, C. Mou, C. Emezue, C. Klamm, C. Leong, D. van Strien, D. I. Adelani, and et al. BLOOM: 176b-parameter open-access multilingual language model. arXiv.org, abs/2211.05100, 2022. 29 SynthID-Image: Image watermarking at internet scale M. J. Shensa. The discrete wavelet transform: Wedding the Ã  trous and Mallat algorithms. IEEE Trans. on Signal Processing (TSP), 40(10):24642482, 1992. R. J. Simes. An improved Bonferroni procedure for multiple tests of significance. Biometrika, 73(3): 751754, 1986. D. Singh and S. K. Singh. DWT-SVD and DCT based robust and blind watermarking scheme for copyright protection. Multimedia Tools and Applications, 76(11):1300113024, 2017. J. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, and S. Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In Proc. of the International Conference on Machine Learning (ICML), 2015. D. Stutz, M. Hein, and B. Schiele. Confidence-calibrated adversarial training: Generalizing to unseen attacks. In Proc. of the International Conference on Machine Learning (ICML), 2020. D. Stutz, A. G. Roy, T. Matejovicova, P. Strachan, A. T. Cemgil, and A. Doucet. Conformal prediction under ambiguous ground truth. Transactions on Machine Learning Research, 2023. Q. Su and B. Chen. Robust color image watermarking technique in the spatial domain. Soft Computing, 22(1):91106, 2018. C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow, and R. Fergus. Intriguing properties of neural networks. In Proc. of the International Conference on Learning Representations (ICLR), 2014. M. Tancik, B. Mildenhall, and R. Ng. StegaStamp: Invisible hyperlinks in physical photographs. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux, T. Lacroix, B. RoziÃ¨re, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample. LLaMA: Open and efficient foundation language models. arXiv.org, abs/2302.13971, 2023. F. TramÃ¨r and D. Boneh. Adversarial training and robustness for multiple perturbations. In Advances in Neural Information Processing Systems (NeurIPS), 2019. F. TramÃ¨r, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Stealing machine learning models via prediction APIs. In USENIX Security Symposium, 2016. C. Vaccari and A. Chadwick. Deepfakes and disinformation: Exploring the impact of synthetic political video on deception, uncertainty, and trust in news. Social Media + Society, 6(1), 2020. R. G. Van Schyndel, A. Z. Tirkel, and C. F. Osborne. digital watermark. In Proc. of the IEEE International Conference on Image Processing (ICIP), 1994. W. Wan, J. Wang, Y. Zhang, J. Li, H. Yu, and J. Sun. comprehensive survey on robust image watermarking. Neurocomputing, 488, 2022. R. Wang, C. Lin, and J. Lin. Image hiding by optimal LSB substitution and genetic algorithm. Pattern Recognition, 34(3):671683, 2001. Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli. Image quality assessment: From error visibility to structural similarity. IEEE Trans. on Image Processing (TIP), 13(4):600612, 2004. 30 SynthID-Image: Image watermarking at internet scale L. Weidinger, J. Mellor, M. Rauh, C. Griffin, J. Uesato, P. Huang, M. Cheng, M. Glaese, B. Balle, A. Kasirzadeh, Z. Kenton, S. Brown, W. Hawkins, T. Stepleton, C. Biles, A. Birhane, J. Haas, L. Rimell, L. A. Hendricks, W. Isaac, S. Legassick, G. Irving, and I. Gabriel. Ethical and social risks of harm from language models. arXiv.org, abs/2112.04359, 2021. B. Wen and S. AydÃ¶re. ROMark: robust watermarking system using adversarial training. arXiv.org, abs/1910.01221, 2019. Y. Wen, J. Kirchenbauer, J. Geiping, and T. Goldstein. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv.org, abs/2305.20030, 2023. R. Xu, M. Hu, D. Lei, Y. Li, D. Lowe, A. Gorevski, M. Wang, E. Ching, A. Deng, et al. InvisMark: invisible and robust watermarking for AI-generated image provenance. In Proc. of the IEEE Winter Conference on Applications of Computer Vision (WACV), 2025. J. Xuehua. Digital watermarking and its application in image copyright protection. In Proc. of the International Conference on Intelligent Computation Technology and Automation, volume 2, pages 114117. IEEE, 2010. Z. Yang, K. Zeng, K. Chen, H. Fang, W. Zhang, and N. H. Yu. Gaussian shading: Provable performancelossless image watermarking for diffusion models. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024. N. Yu, V. Skripniuk, S. Abdelnabi, and M. Fritz. Artificial fingerprinting for generative models: Rooting deepfake attribution in training data. In Proc. of the IEEE International Conference on Computer Vision (ICCV), 2021. P. Yu, H. Tsai, and J. Lin. Digital watermarking based on neural networks for color images. Signal Processing, 81(3):663671, 2001. R. Zellers, A. Holtzman, H. Rashkin, Y. Bisk, A. Farhadi, F. Roesner, and Y. Choi. Defending against neural fake news. In Advances in Neural Information Processing Systems (NeurIPS), 2019. H. Zhang, H. Chen, C. Xiao, B. Li, D. S. Boning, and C. Hsieh. Towards stable and efficient training of verifiably robust neural networks. In Proc. of the International Conference on Learning Representations (ICLR), 2020a. H. Zhang, B. L. Edelman, D. Francati, D. Venturi, G. Ateniese, and B. Barak. Watermarks in the sand: Impossibility of strong watermarking for generative models. In Proc. of the International Conference on Learning Representations (ICLR) Workshops, 2023. K. A. Zhang, L. Xu, A. Cuesta-Infante, and K. Veeramachaneni. Robust invisible video watermarking with attention. arXiv.org, abs/1909.01285, 2019. L. Zhang, X. Liu, A. V. Martin, C. X. Bearfield, Y. Brun, and H. Guan. Robust image watermarking using stable diffusion. arXiv.org, abs/2401.04247, 2024. R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang. The unreasonable effectiveness of deep features as perceptual metric. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. X. Zhang, Z. H. Sun, S. Karaman, and S. Chang. Discovering image manipulation history by pairwise relation and forensics tools. IEEE Journal of Selected Topics in Signal Processing, 14(5):10121023, 2020b. 31 SynthID-Image: Image watermarking at internet scale X. Zhao, K. Zhang, Z. Su, S. Vasan, I. Grishchenko, C. Kruegel, G. Vigna, Y.-X. Wang, and L. Li. Invisible image watermarks are provably removable using generative AI. In Advances in Neural Information Processing Systems (NeurIPS), 2024. X. Zhao, S. Gunn, M. Christ, J. Fairoze, A. Fabrega, N. Carlini, S. Garg, S. Hong, M. Nasr, F. Tramer, et al. SoK: Watermarking for AI-generated content. In Proc. of the IEEE Symposium on Security and Privacy, 2025. J. Zhu, R. Kaplan, J. Johnson, and L. Fei-Fei. HiDDeN: Hiding data with deep networks. In Proc. of the European Conference on Computer Vision (ECCV), 2018. 32 SynthID-Image: Image watermarking at internet scale A. Additional robustness evaluations A.1. Native image resolution evaluation While Section 8 evaluated all models at 512512 resolution, this section evaluates all baselines as well as SynthID-O using the native resolution of images in ImageNet. The average resolution of ImageNet images is 469387, which means that methods that operate at larger resolutions may come at slight disadvantage since images will generally be downscaled compared to the resolution at which they are watermarked (due to the intrinsic resizing stemming from variable image resolutions). Table 4 summarizes the results. It reports the true positive rate (TPR) at fixed false positive rate of 0.1% in average on worst-case transformations. We observe that over aggregated random and aggregated worst transformations, SynthID-O continues to outperform all other methods by significant margins (i.e., +10.64 and +17.17 percentage points respectively). In the worst setting, SynthID-O is the only models surpassing 97% TPR in worst-case aggregate (which is the most challenging setting). SynthID-O InvisMark StegaStamp TrustMark-P TrustMark-Q VideoSeal-0.0 VideoSeal-1.0 WAM Aggregated Aggregated Worst 98.72% [65.60%, 65.88%] 97.22% [56.72%, 56.98%] [72.24%, 72.43%] [66.21%, 66.48%] [64.81%, 65.31%] [52.78%, 53.36%] [77.24%, 77.70%] [68.06%, 68.21%] [76.60%, 77.30%] [58.69%, 59.38%] [87.93%, 88.08%] 86.79% [76.31%, 76.49%] 80.05% Table 4 TPR at 0.1% FPR aggregated across random and worst-case categories. For each model, the detection threshold is calibrated to reach 0.1% FPR across all worst transformations in average. When brackets are used, we display the range of TPR values that can accommodate the target FPR target(this number is not unique when there are ties). We highlight the best model in bold and the second best with an underline. 33 SynthID-Image: Image watermarking at internet scale A.2. Native model resolution evaluation While the previous section evaluated all models using the native resolution of images in ImageNet, this section evaluates all baselines as well as SynthID-O at their preferred resolution. Table 5 reports the true positive rate (TPR) at fixed false positive rate of 0.1% in average on worst-case transformations. SynthID-O (512512) InvisMark (256256) StegaStamp (400400) TrustMark-P (256256) TrustMark-Q (256256) VideoSeal-0.0 (256256) VideoSeal-1.0 (256256) (256256) WAM Aggregated Aggregated Worst 99.98% 99.72% [61.45%, 61.77%] [51.11%, 51.40%] [72.42%, 72.58%] [66.49%, 66.78%] [58.91%, 59.54%] [47.89%, 48.38%] [77.69%, 78.11%] [67.61%, 67.78%] [64.53%, 65.45%] [52.08%, 52.60%] [86.56%, 86.78%] [78.73%, 78.95%] 82.32% 79.38% Table 5 TPR at 0.1% FPR aggregated across each transformation category when images are resized to the model input size. For each model, the detection threshold is calibrated to reach 0.1% FPR across all worst transformations in average. When brackets are used, we display the range of TPR values that can accommodate the target FPR target(this number is not unique when there are ties). We highlight the best model in bold and the second best with an underline. 34 SynthID-Image: Image watermarking at internet scale B. Human evaluation prompts Below is the list of prompts used to generated images for our quality evaluations. We used Imagen 2 to generate 1000 images (i.e., 4 images per prompt). Realistic 3d render of happy, furry and cute baby tiger smiling with big eyes looking straight at you, Pixar style, full body shot with light blue background Detailed robot portrait, shading details 3D rendering of spaceship. 3d rendering of sleek, silver futuristic car with glass roof and glowing blue light on the front. Isometric 3D render of small Japanese house with thatched roof, surrounded by bamboo and cherry blossoms. 3D render of 3 planets orbiting around themselves in space. The planets are made of different colors and textures. The background is black. 3D pixelated render of panda in the style of Doom, standing on rocky platform, with lava background. Ray-traced 3D rendering of crystal ball on table in dark room. The ball is reflecting the light from nearby candle. 3D render of Gandalf fighting Balrog in dark fantasy setting. The scene is rendered in Unity with realistic graphics. Exciting car race from 3D computer game, rendered in Unity, Abstract art, very regular shapes and lines. Cubist painting, digital art, colourful, patchwork An abstract expressionist painting using bold brush strokes, dripping paint, and vibrant colors, reflecting the inner emotions and turmoil regular black and white triangle pattern on white background. The pattern is made of equilateral triangles, and the triangles are arranged in grid. Abstract painting with all the colors of the rainbow, made with acrylic paint on canvas. Abstract art in greyscale. Abstract art piece of several overlapping circles in bright colors An art piece consisting of lot of eyes painting in different style, abstract Drawing of different traffic signs chaotically arranged, abstract art Abstract art painting made with oil, different shades of green in triangle shapes Painting of bear hiking in the mountains Ukiyo-e style cat Blacklight painting style cat, painting, blacklight painting water color painting of flamingo, Kilimanjaro in the background panda in the style of Miro Panda in the style of Picasso, Cubism Abstract painting of horse with broad brush strokes using only 2 colors Oil painting of close-up of cat eye photorealistic painting of family of African elephants with long tusks An impressionist painting of butterfly Black and white picture of swan swimming picture of cow on an alpine meadow. herd of zebras standing on the surface of mars. The sun is shining. High quality photograph. 4k. Photograph of coral reef with lots of colorful fishes swimming around. The reef is lit by sunlight coming through the water. Close up photo of dog with the pop rocket instagram color filter. The dog is golden retriever, and it is sitting on red blanket. The background is blur of green grass. Polaroid photo of horse, taken in park on sunny day. 70s photo. Polaroid photo with yellowed edges. Close-up of cat eye full-body photograph of Sumatran tiger roaring, with blurred background photograph of Humpback whale and its calf playing underwater Close up photograph of group of ants. Anime drawing, portrait sunny weather, wearing sun hat, shadow hiding part of the face still from an 80s cartoon show about butterfly with superpowers. The butterfly is wearing cape and has glowing red heart on its chest. It is flying through the air, surrounded by stars. male anime character with black hair runs through deep forest. He is wearing red ninja suit and has sword in his hand. The sun is shining through the trees, creating dappled pattern on the ground. anime, cartoon black and white cartoon of giraffe driving red car. The giraffe is wearing top hat and bow tie, and he is smiling. The car is driving down road, and there is palm tree in the background. cartoony, colorful icon of mobile game app. The icon is of smiling cat wearing hat and sunglasses, and it is sitting on pile of gold coins. The background is bright blue sky with clouds. close-up portrait of cute character in the style of Studio Ghibli, with big expressive eyes and bright smile. dark and atmospheric scene from seinen anime, with lone character walking through rain-soaked city, lit only by the neon lights of storefronts. whimsical and imaginative scene from childrens cartoon, with group of animal friends exploring magical forest filled with talking trees and playful fairies. humorous and satirical scene from an cartoon, with family sitting around the dinner table, engaging in witty banter and absurd situations. 1970s-style cartoon of futuristic car flying through the sky. The car is bright yellow and has big rocket engine on the back. The sky is deep blue and there are clouds floating by. Defocused specks of blurry swaying coral in landscape colorful Close-up of out-of-focus grass street lights, beautiful bokeh wasp in front of out-of-focus meadow black and white photo of microphone stand with the band members standing out of focus in the back. The band members are wearing black and white clothes, and the background is dark blue. The photo is taken in studio Underwater photo of sunken ship. Out of focus. Very blurry. supermarket selection of fruits. Out of focus and very blurry. wall of text, out of focus, unreadable, blurry Sunset at beach, out of focus, blurry large group of people in street, out of focus, blurry portrait of mysterious person sitting in an ornate, gothic throne room, with subtle elements of fantasy and magical realism, painted with the dark and dramatic style of the Baroque period dynamic action scene of knight battling dragon on cliffside, with roaring waves below, inspired by the Romanticism movement, reminiscent of the works of EugÃ¨ne Delacroix haunting gothic horror scene of an abandoned mansion on hill, with fog, full moon, and shadowy figures, in digital painting style reminiscent of the Castlevania game series. Dramatic fantasy painting of Balrog facing wizard. Fantasy painting of pirate ship resting inside canyon, with waterfall cascading down the rocks. The ship is lit by full moon, and the water is reflecting the stars. group of orcs with axes in forest, oil painting Detailed painting of wizard casting spell, she has magic wand and sparkles fly out of it beautiful painting of unicorn grazing in fairy tale forest fantasy dwarf with long beard sitting at camp fire, painting Dramatic and rich painting of medieval city with fireballs falling from the sky bear dancing disco. Flat art style. Hedgehog in the grass and tree in flat art style large cruise ship with lots of flags on it. Flat art style. 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering 3D Rendering Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Abstract Art Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Painting Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Animal Photo Cartoon Cartoon Cartoon Cartoon Cartoon Cartoon Cartoon Cartoon Cartoon Cartoon Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Defocused Blurry Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Fantasy Painting Flat art Flat art Flat art 35 SynthID-Image: Image watermarking at internet scale Flat art style postcard of sailor. All planets of our solar system in flat art style. Picture of flag of fictional country. 5 diagonal blue and green stripes and silver spoon in the top right corner. Made in flat art style. steak with potatoes, carrots and green beans. Flat art style. Abstract flat art style image of red radio tower with yellow lines emitting from it. White background. Lightning coming from cloud and hitting tree. Abstract. Minimalist. Flat art style. Cartoon in flat art style. Minimalist flat art style depiction of woman sitting on bench. The woman is black and wearing red clothes. Flat art style. Cartoon. Abstract. Black and white photo of train conductor in blue uniform standing on train platform in 1875 historic photograph of the Parthenon temple in Athens, Greece, taken before 1900 historic photo of family of 5. Mother, father, 2 sons and daughter. farmer in field of sun flowers. Historic photo from 1912. Historic photo from 1874 of personal computer. Cows in barn. Black and white photo from 1930. Historic photo of burning house. Taken in 1921. Grainy, bad quality. Black and white photo of 1900s Model Ford parked on dirt road in front of barn. The sky is cloudy and the sun is setting. Vintage photo of the Chicago skyline from the 1950s, with washed out colors and sepia tone. Vintage photo of steam boat on large river, with city in the background. digital painting of serene Japanese garden in autumn, with tea house, koi pond, and maple trees with falling leaves, with an anime-inspired art style reminiscent of Studio Ghibli films. wide-angle realistic painting of mount Bromo volcano in Indonesia erupting, with visible lava and volcanic fumes coming out of the crater dreamy watercolour painting of many cherry blossom trees in front of Mount Fuji in Japan, mainly in pastel colours realistic painting of stormy night in the mountains. Its raining and there are lightning visible in the background. Oil painting of savanna. The painting is in the Renaissance style, with lot of detail and bright colors. Impressionist painting of the ice cold plains of Antarctica. The sky is deep blue, and the sun is setting. There is sense of loneliness and isolation. Expressionist painting of the Grand Canyon in shades of red, orange, and yellow. The painting is done on canvas and is 3 feet by 4 feet. Baroque painting of camel caravan crossing the dunes in the desert of Tunisia. The painting is done in realistic style, with the dunes depicted in shades of yellow and brown. The sky is deep blue, and the sun is setting, casting long shadows across the sand. painting of the city of London in the early medieval period, with castle in the foreground and river in the background. The painting is done in realistic style, with the colors muted and the details precise. modern painting of deserted beach in the Caribbean. The painting is done in vibrant, fauvist style, and the colors are saturated and bright. The beach is deserted, with only few palm trees and few rocks. The sky is deep blue, and the water is clear turquoise. High quality photo of sun set on the beach. serene autumn landscape with reflective lake surrounded by trees with colorful fall foliage, in the style of the Hudson River School, capturing the romantic essence and fine details. black and white street photography of busy New York City intersection with the Empire State Building in the background, capturing the energy and chaos of city life realistic landscape shot of the Northern Lights dancing over snowy mountain range in Iceland, with long exposure to capture the motion and vibrant colors. realistic photo of the Milky Way with diagonal orientation, next to the Tre Cime di Lavaredo mountain peaks in Italy photo of Baroque chapel on green valley catching rays of the rising sun, with defined mountain peaks in the background photograph of the Golden Gate bridge on foggy sunset, with its pillars and the water underneath being illuminated by red light dramatic black and white photo of stone bridge leading to lighthouse on rocky cliff, with ocean waves crashing onto the cliff photograph capturing the movement of black horses running on the side of an empty road which leads towards large snowy mountain range beautiful photo of medieval castle in the mountains at sunset. The castle is made of gray stone and has turrets and towers. The mountains are covered in snow and the sky is deep blue. Figurative line drawing Blueprint for rocket ship heading to Mars, blueprint, pencil drawing, drawing City skyline picasso pencil Sketch of the ying yang Architectural drawing of bank floor plan, line drawing line drawing of womans face, with geometric patterns used to define facial features, line drawing Line drawing of two people arguing, pencil. black and white line drawing of skyscraper driving with wheels on road. Colorful line drawing of rooster, line drawing Pencil drawing of complex machine. Line drawing, pencil drawing mascot logo of robot, simple, vector minimalist logo of research company, consisting of magnifying glass and DNA strand. The logo is black and white, and the background is light blue. Just the logo. logo of fashion company. The logo is stylized letter \"Y\" in bright colors. The logo is on white background. complex logo made of geometric shapes and lines in dark blue color. The logo is on white background. red and white logo of games company. The logo is wolf with sunglasses on black background. playful logo of AI startup making shoes. The logo is cartoon of shoe with big smile on its face. The shoe is wearing hard hat and tool belt. Logo on white background. simple, modern logo for company called Logo. The logo is blue circle with white letter in the center. The logo is on white background. Logo for an early 2000s dot-com bubble company that sells books online. The logo is stylized book with rocket ship on top. modern, minimalist logo for new supermarket chain. The logo is green leaf with wavy black line circling around it. On pink background. Logo for new online bank. The logo has several currency symbols in triangle pattern with the word bank above it. The background is black. cubist painting of still life with geometric shapes, fragmented forms, and multiple perspectives, inspired by the works of Pablo Picasso and Georges Braque, using muted color palette Minimalist painting of flower on black background. Very minimalistic. Extremely minimalistic. Minimalism. painting of knight in the style of fauvism, with bold colors and simplified shapes. Horse Drawn Carriage. Simplistic woodcut from 1568. Still life painting of calculator. Oil on canvas Surrealist painting of toaster melting on white background. The toaster is made of blue and yellow plastic, and the melting is done in realistic style. baroque painting of chest full with treasure. painting of pineapple in the cubist style. An impressionist painting of shoe. Impressionist style. Oil painting of an very intrinsically decorated vase Chess board, high contrast, top view close-up macro shot of morning dew on spiders web, with the focus on the intricate patterns and water droplets, giving it an ethereal quality, high resolution. Large fireworks in the night sky. close up photograph of snowflakes Food photo of steak with potatoes, carrots and green beans. photo of house built of match sticks. table covered in various tools, high quality photograph Photo of an astronauts helmet, you can see the surface of the moon in the reflection photograph of broken glass lying across marble floor. Very close up photo of purple light diode Pencil drawing of cloud 1950s cat illustration Architectural pencil drawing of residential home. Pencil drawing of steam train. pencil drawing of street in Berlin. There is dÃ¶ner kebap shop next to bar. Flat art Flat art Flat art Flat art Flat art Flat art Flat art Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Historic Photo Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Painting Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Landscape Photo Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Line Drawing Logo Logo Logo Logo Logo Logo Logo Logo Logo Logo Object Painting Object Painting Object Painting Object Painting Object Painting Object Painting Object Painting Object Painting Object Painting Object Painting Object Photo Object Photo Object Photo Object Photo Object Photo Object Photo Object Photo Object Photo Object Photo Object Photo Pencil Drawing Pencil Drawing Pencil Drawing Pencil Drawing Pencil Drawing SynthID-Image: Image watermarking at internet scale pencil drawing of cityscape, with shadows on the glass and concrete of tall buildings An extremely detailed pencil portrait of black womans face Pencil drawing of rainbow Extremely realistic pencil drawing of an eye An inkjet printer drawn with pencil, pencil drawing man with blue hat jumping on two legged turtle. Pixel Art. female doctor jumping over an abyss. Pixel art game screenshot. pixelated screenshot of 8-bit game, showing spaceship shooting at asteroids. Pixel Art. Pixel art of steampunk machine with gears, cogs, and valves. Pixel art. Pixelated. Super Nintendo graphics. pirate ship on the sea, pixel art, 16-bit 16-bit pixel art of supermarket knight on horse riding over draw bridge, pixel art group of crocodiles in river, pixel art Pixel art drawing of cars on highway, top view, pixel art desert scene with cacti and tumble weeds, 32-bit pixel art portrait of man in glasses, psychedelic painting, primary colors, water color Renaissance painting of king wearing crown, reneaissance painting Abstract painting showing the portrait of women in her 20s on the left with bright colors and in her 80s on the right with darker colors Painting with thick lines and bold colors of doctors face Portrait of female african-american professor using pointillism Official painted portrait of the first Indian-American President of the United States Painted portrait of happy child, oil painting Portrait painting of female baker in traditional white clothing Baroque portrait of blacksmith in his workshop, baroque painting, painting Very detailed painting of female Chinese bank manager Close-up portrait of man, Sepia Colorful vivid portrait of woman, bokeh, kodachrome powerful portrait of an elderly person, capturing the wrinkles, texture of the skin, and expressive eyes that tell story of lifetime, in high resolution and natural lighting. black and white portrait of middle-aged Vietnamese lady smiling, and wearing traditional outfit and bamboo hat portrait of kid, balloons floating in the background. Bokeh portrait shot of group of 3 adult brothers, in garden Portrait photo of man in his 50s with sun glasses on, he has green colored hair and smiles airplane pilot in her full uniform, bokeh photo Wedding photo of couple College graduation photo of native american man Movie Poster of 1980s comedy movie about racoons living on college campus poster of Maneki-Neko (Japanese lucky cat) and bowl of ramen noodles on grey background, with the cat holding few noodles in its raised paw coffee guide poster with colourful icons of different kinds of coffees and brewing methods poster showing the dramatic cliffs and colourful houses in the Amalfi Cost, Italy, with text rendered on top ITALY, AMALFI COAST Abstract poster of pattern of thick black lines looking like maze Poster of an animated movie about funny bear with title poster for an action movie featuring panda in sunglasses, holding bamboo stick. The background is dark and stormy, and the panda is standing in front of burning building. An advertisement poster for new detergent scientific poster explaining neural networks to children Advertisement poster of new smartphone from the 1960s futuristic cyberpunk cityscape at night with towering neon-lit skyscrapers, flying cars, and diverse crowd of humans and androids, in highly detailed digital painting reminiscent of Blade Runner. portrait of post-apocalyptic warrior with battle scars, armor, and weapons, standing in desolate wasteland, in detailed digital painting with gritty textures, inspired by the Mad Max franchise. Empty spaceship interior. Dramatic light. futuristic hover craft with cyan and orange tones spacesuit-clad astronaut walking through forest, surrounded by trees and ferns. The astronaut is carrying backpack. Photo of green alien in Paris dressed like tourist Photo of woman in futuristic spacesuit floating in space Dramatic photo of UFO hovering over fast food restaurant Photo of man in futuristic jumpsuit riding gigantic grasshopper Close up photo of futuristic laser gun Black matte cube in the middle of room of poorly lit room dark but slightly transparent sphere, fre-floating in front of clear sky solid prism on table in front of forest An abstract sculpture out of dark metal in the middle of traffic circle closeup photo of honeycomb with hexagonal prismatic cells of varying size page of notebook with pencil drawing of triangle. The notebook is open to blank page, and the triangle is drawn in the center of the page. The pencil is resting on the page next to the triangle. Two circles overlapping (Venn diagram) An image filled with concentric circles Multiple irregular polygons in black and white smooth white pyramid on white floor scientist writing an equation on blackboard trader looking at stock price graphs on the screen group of business professionals with different nationalities having meeting female hacker sitting in front of computer, she is wearing dark hoody and the room is badly lit Stock photo of man eating salad Two men holding hands smiling at the camera An Asian man in cafe ordering, looking pensive, stock photo Two women high fiving. One is African American and one is Indian American Stock photo of person having headache woman having an idea, stock photo The word provenance in funny font Restaurant menu written on yellow page, written menu, full of text large blackboard with lecture notes from computer science lecture small whiteboard with Maxwells equations 3D rendering of letters forming \"HELLO\", with the front surface of each 3D letter having different inclination Logo of well-known web search company. White background and colorful letters. white letter with the words \"I love you\" written on them in red All the letters of the alphabet soup with letters in it forming the word \"Soup\" page in very old book vertical wallpaper that is painted to look like birds wing, with the wing in different shades of gray and streaks of light in the sky. Golden tree branches densely packed against dark background Clouds in blue sky, wallpaper photo Matte colors in triangle shapes, wallpaper Pencil Drawing Pencil Drawing Pencil Drawing Pencil Drawing Pencil Drawing Pixel art Pixel art Pixel art Pixel art Pixel art Pixel art Pixel art Pixel art Pixel art Pixel art Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Painting Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Portrait Photo Poster Art Poster Art Poster Art Poster Art Poster Art Poster Art Poster Art Poster Art Poster Art Poster Art SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo SciFi Photo Shapes Shapes Shapes Shapes Shapes Shapes Shapes Shapes Shapes Shapes Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Stock Photo Text Text Text Text Text Text Text Text Text Text Wallpaper Wallpaper Wallpaper Wallpaper 37 SynthID-Image: Image watermarking at internet scale Regular pattern of stick figures holding hands Wallpaper of stars on black background Stones of different colors and shapes, wallpaper An empty beach from above, perfect photography, clear blue water Wooden texture Image of seastar, made as tile mosaic, blue and white, phone wallpaper Wallpaper Wallpaper Wallpaper Wallpaper Wallpaper Wallpaper"
        }
    ],
    "affiliations": [
        "Google DeepMind"
    ]
}