{
    "paper_title": "SR-Scientist: Scientific Equation Discovery With Agentic AI",
    "authors": [
        "Shijie Xia",
        "Yuhan Sun",
        "Pengfei Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities."
        },
        {
            "title": "Start",
            "content": "SR-Scientist: Scientific Equation Discovery With Agentic AI Shijie Xia1,2,3*, Yuhan Sun1,3* and Pengfei Liu1,2,3 (cid:0) *Co-first authors, (cid:0)Corresponding author, 1Shanghai Jiao Tong University, 2SII, 3GAIR 2025-10-14 Code: https://github.com/GAIR-NLP/SR-Scientist Models: SR-Scientist-30B Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, framework that elevates the LLM from simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our methods robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agents capabilities. 1. Introduction In the era of Agentic AI, Large Language Models (LLMs) have evolved from simple knowledge retrievers to agentic models capable of completing complex tasks by interacting with their environments (Schneider, 2025), as exemplified by products like Claude Code (Anthropic, 2025) and Gemini CLI (Google, 2025). These agents exhibit many characteristics of human scientists, such as engaging in long-horizon interaction with environmental feedback, operating with autonomy, and relying less on predefined pipelines (Newell et al., 1972). However, in most current work using LLMs for scientific discovery (Novikov et al., 2025; Romera-Paredes et al., 2024; Shojaee et al., 2024), LLMs serve as static components within human-crafted pipelines, lacking the autonomy to generate and refine hypotheses through active environmental interaction. Building scientific discovery framework around agentic models could therefore shift the paradigm from using LLMs as passive tools to empowering them as autonomous agents that drive the entire discovery lifecycle. In this paper, we focus on equation discovery, fundamental task in science. Mathematical equations are central to scientific progress, serving as concise and interpretable models of physical phenomena (Batra et al., 2021; Hernandez et al., 2019; Lemos et al., 2022). The task of data-driven equation discovery, also known as symbolic regression (SR), is an NP-hard problem due to its vast search space (Virgolin and Pissis, 2022). Traditional methods have relied on Genetic Programming (GP) for combinatorial search (Cranmer, 2023) or on deep neural networks trained on large-scale synthetic data for direct prediction (Biggio et al., 2021; Kamienny et al., 2022), which often suffer from efficiency and scalability issues. Recently, the research community has begun to embed LLMs into GP algorithms as equation proposers, leveraging their scientific prior knowledge 5 2 0 2 3 1 ] A . [ 1 1 6 6 1 1 . 0 1 5 2 : r SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 1 The inference framework of SR-Scientist. At each iteration, the LLM agent autonomously conducts long-horizon optimization using code interpreters for data analysis and equation evaluation. To overcome the context length limitations of current LLMs, we implement an experience buffer to fetch the best-performing equations for subsequent iterations. Eq denotes the equation and denotes the equation score. to generate more effective hypotheses (Grayeli et al., 2024; Shojaee et al., 2024). While this can enhance search efficiency, LLMs primarily serve as equation generators in fixed pipeline, which lacks the autonomy to gain insight for equation design through tools. To address these limitations, we introduce SR-Scientist, framework designed to enable LLMs to find scientific equations through long-horizon optimization driven by experimental feedback and analysis. To achieve this, we wrap the code interpreter as tools to analyze data and evaluate equations. As shown in Figure 1, the LLM agent is instructed to solve problems by utilizing these tools, including writing code to analyze data, implementing the equation as code, submitting it for evaluation, and optimizing the equation based on experimental feedback. In the process, we emphasize long-horizon optimization, allowing the agent to interact with data through tools over multiple turns (e.g., more than twenty) to gather sufficient information for equation design. To overcome the context length limitations of current LLMs, we implement an experience buffer to store the explored equations and fetch the best-performing equations for subsequent iterations. Moreover, we adhere to the principle of minimal human-defined pipelines (Sutton, 2019), in which the agent is free to determine its own workflow for given problem. Within the flexible framework, we develop reinforcement learning (RL) pipeline from training data construction to reward design to help the LLM agent evolve its capabilities. To validate the effectiveness of our framework, we evaluate SR-Scientist using 5 different models as backbone LLMs on datasets covering 4 science disciplines carefully designed to prevent the LLMs from relying on memorized equations from their training data (Shojaee et al., 2025). Results demonstrate that SR-Scientist consistently outperforms state-of-the-art SR methods, with four of 2 SR-Scientist: Scientific Equation Discovery With Agentic AI the models achieving an absolute margin of 6% to 35% over baselines. We also observe significant improvement after applying RL training. Additionally, we demonstrate our methods robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, our ablation studies highlight the importance of data analysis, the experience buffer, and long-horizon optimization. Overall, our contributions are as follows: We develop SR-Scientist, framework where an autonomous agent discovers scientific equations through long-horizon, tool-driven data analysis and equation evaluation. We show that SR-Scientist significantly outperforms baseline methods in precision, generalization, robustness to noise, and symbolic accuracy. We develop corresponding end-to-end reinforcement learning pipeline to enhance the agents capabilities. 2. Related Work Symbolic Regression SR aims to identify an interpretable mathematical expression that accurately describes the relationship between variables in observed data (Cava et al., 2021; Makke and Chawla, 2024). Current popular methods can be categorized as follows: 1) GP-based Methods: This line of methods uses constrained representations, such as expression trees, to define search space composed of symbolic operators, constants, and variables (Cranmer, 2023). Evolutionary or genetic programming is then applied to search for solutions. 2) Deep learning Methods: These methods leverage deep neural networks to learn direct mapping from numerical observations to their underlying mathematical expressions through online (Landajuela et al., 2022; Petersen et al., 2021) or offline learning (Biggio et al., 2021; Kamienny et al., 2022). 3) LLM-based methods: Due to the efficiency and scalability issues of the above methods, the research community has integrated LLMs with traditional techniques like GP, leveraging the models extensive knowledge to generate more informed hypotheses (Grayeli et al., 2024; Ma et al., 2024; Shojaee et al., 2024; Wang et al., 2025b). While promising, current hybrid methods still lack the direct analysis of observed data through tools to gain insights. Furthermore, the LLMs behavior is often fixed, lacking the autonomy to decide its actions in goal-oriented manner. Moreover, most work focuses on using LLMs for inference, without exploring how these models evolve their abilities through methods like RL. Agentic AI Agentic AI can autonomously execute complex tasks in dynamic environments requiring adaptation, interaction, and reasoning in goal-oriented manner (Schneider, 2025). The open-source community has built powerful agentic models for tasks like software engineering (Team et al., 2025; Zeng et al., 2025a), search (Gao et al., 2025), and GUI operations (Qin et al., 2025; Wang et al., 2025a), enabling them to solve tasks in an end-to-end manner with minimal human intervention. However, there has been limited focus on scientific discovery. In this paper, we demonstrate that with careful design, these agentic models can be powerful for equation discovery and can also improve their abilities through RL. 3. SR-Scientist 3.1. Problem Formulation Symbolic regression aims to find symbolic expression that describes the underlying relationship in 𝑖=1, where x𝑖 ℝ𝑑 is an input vector and 𝑦𝑖 ℝ is dataset. Formally, given dataset = {(x𝑖, 𝑦𝑖)}𝑛 SR-Scientist: Scientific Equation Discovery With Agentic AI scalar output, an SR method seeks to find concise symbolic function 𝑓 such that 𝑓 (x𝑖) 𝑦𝑖. The goal of SR is not only to discover function that minimizes the error between the predicted values and the true values but also one that generalizes well to unseen inputs while maintaining interpretability. 3.2. Inference Framework We outline the overall inference framework in Algorithm 1. At each iteration, we set goal 𝐺𝑖 for desired optimization precision and the agent is instructed to find an equation that satisfies the precision. (cid:12) We choose the mean absolute percentage error1 (MAPE) as the goal: MAPE = 100% (cid:12) (cid:12). Then, the LLM agent solves the problem by interleaving internal reasoning with external environment feedback. Formally, the agents trajectory is structured as follows, typically within ReAct (Yao et al., 2023) framework: 𝑦𝑖 𝑓 (x𝑖 ) 𝑦𝑖 (cid:205)𝑛 𝑖=1 (cid:12) (cid:12) (cid:12) 𝑛 (𝑟1, T1, 𝑜1), (𝑟2, T2, 𝑜2), ..., (𝑟𝑘, T𝑘, 𝑜𝑘) (1) where 𝑟𝑖 denotes the models natural language reasoning at step 𝑖, T𝑖 is the set of tools invoked at step 𝑖, and 𝑜𝑖 is the observation received after executing the tools in T𝑖. We also set maximum number of interaction turns 𝑀 for the trajectory to avoid excessively long inference times without improved performance. Algorithm 1 SR-Scientist inference framework. Input: Iterations N; maximum turns 𝑀; number of # Generate candidate equations from LLM if 𝑖 == 1 then fetched equations 𝐾; the initial goal 𝐺1 1: # Store ranked equations by heap 2: heap() 3: for 𝑖 = 1, . . . , 𝑁 do 4: Tool Design We provide code interpreter as the primary tool, enabling the agent to write code for data analysis and performance evaluation. Specifically, we wrap the code interpreter into two common tools for the tasks, data analyzer and equation evaluator, denoted as 𝑇1 and 𝑇2, respectively. For 𝑇1, we link it to the observed data and include code example in the prompt demonstrating how to access the data. Through this tool, the agent can write code to analyze the data, including printing the data, conducting statistical analysis, or analyzing the residuals between the predicted value and the true value. For 𝑇2, following the approach of Shojaee et al. (2024), we design the tool to accept an equation skeleton with placeholders for constants in code format (See Figure 1 or 5 for the equation example). During the execution phase, the BFGS algorithm is implemented to optimize these constants and then report the performance of the equation. It also accepts equations with constants decided through other methods like data analysis. This tool prevents the agent from writing repetitive code for equation evaluation during the long-horizon exploration process. 12: 13: 14: 15: end if 16: 17: end for Output: H.topk(1) # Return the best end if H.append(𝐸𝑖) # Check stopping condition and update goal if stopping_condition(H) then 𝐸𝑖 LLM(H.topk(𝐾),𝑀,𝐺𝑖) 𝐺𝑖+1 UpdateGoal( 𝐻, 𝐺𝑖) 5: 6: 7: 8: 9: 10: 11: 𝐸𝑖 LLM(M,𝐺𝑖) break else else 1This is slightly different from other SR methods that usually use the mean squared error (MSE) or normalized mean squared error (NMSE) as the score, as we find MAPE provides more uniform precision target across different data than the aforementioned metrics. To ensure fair comparison with other SR methods, we select the equation with the lowest NMSE in practical evaluation. 4 SR-Scientist: Scientific Equation Discovery With Agentic AI Experience Buffer While the agent can continue the optimization process over multiple turns, the models limited context length presents challenge. Moreover, the equations can still perform poorly after long-horizon optimization. To overcome this, we maintain an experience buffer 𝐸 = {(𝑒𝑖, 𝑠𝑖)}𝑁 𝑖=1 to record the equations the agent has explored, where 𝑒𝑖 denotes the equation and 𝑠𝑖 is its corresponding MAPE. At the beginning of each iteration, we fetch the best 𝐾 equations from the buffer and provide them to the agent as in-context examples. The optimization goal is also updated if it was reached in the previous iteration. This mechanism effectively bypasses the context length limitation. Additionally, we explored using GP algorithms for experience management but observed no significant improvement. Stopping Condition and Submission We stop the exploration process when the maximum number of iterations is reached or the equations error is sufficiently small. Then, we select the equation with the best performance on the observed data and submit it for final evaluation. 3.3. Training Framework Training Data Construction Following the approach of Shojaee et al. (2025), we employ mixed strategy of rule-based and model-based data synthesis. For each scientific scenario covering multiple variables, we instruct an LLM to synthesize potential relationships between the variables, typically in the form of an equation skeleton. For each skeleton, we use the model to determine the values for the constants based on their physical significance and thereby construct the full equation. Once the complete equation is formulated, we define an appropriate range of values for its variables and synthesize the observed data accordingly. This dataset is then split into training and evaluation sets. The training data is accessible to the agent during rollouts, while the evaluation data is used to measure performance and calculate the reward. Reward Design In the rollout process, the LLM agent is instructed to find an equation that satisfies the precision specified by MAPE goal 𝑠goal. Then, the LLM agent interacts with the environment and generates multiple equations. To simplify the RL infrastructure, the agent conducts the optimization process for one iteration. Unlike math or code tasks that typically assign binary rewards based on the outcome (DeepSeek-AI et al., 2025; Zeng et al., 2025b), the performance of equations can be measured by continuous metrics such as MAPE. This makes it possible to assign continuous rewards to avoid reward sparsity. Since we only submit the best equation at inference (Petersen et al., 2021), we select the best equation from those explored and use its score 𝑠 for the calculation. We employ log-linear reward function that maps 𝑠 to the range [0, 1] as follows: = clip( lg 𝑠max lg 𝑠 lg 𝑠max lg 𝑠goal , 0, 1) (2) where 𝑠max represents the maximum MAPE for which non-zero reward can be gained. Additionally, we explore other reward functions and present the discussion in Appendix A.3.2. Training Algorithm We apply the Group Relative Policy Optimization (GRPO) (Shao et al., 2024) algorithm for optimization. To encourage exploration, we omit the KL penalty term against reference model and observe that this leads to faster convergence and comparable performance. Specifically, for each question 𝑞, we sample group of outputs {𝑜1, 𝑜2, , 𝑜𝐺} from the old policy 𝜋𝜃old and then 5 SR-Scientist: Scientific Equation Discovery With Agentic AI optimize the policy 𝜋𝜃 by maximizing the following objective: J𝐺𝑅𝑃𝑂(𝜃) = 𝔼[𝑞 𝑃(𝑄), {𝑜𝑖}𝐺 (cid:18) 𝜋𝜃(𝑜𝑖𝑞) (cid:18) 𝜋𝜃𝑜𝑙𝑑 (𝑜𝑖𝑞) 𝐺 min 1 𝐺 𝑖=1 𝑖=1 𝜋𝜃𝑜𝑙𝑑 (𝑂𝑞)] 𝐴𝑖, clip (cid:18) 𝜋𝜃(𝑜𝑖𝑞) 𝜋𝜃𝑜𝑙𝑑 (𝑜𝑖𝑞) , 1 𝜖, 1 + 𝜖 (cid:19) (cid:19)(cid:19) 𝐴𝑖 (3) where 𝜀 is the hyper-parameter, and 𝐴𝑖 is the advantage computed using group of rewards corresponding to the outputs within each group. 4. Experiments 4.1. Setup Dataset Due to the vast corpus that LLMs have been pretrained on, the evaluation dataset must be carefully curated to prevent LLMs from having memorized the equations. We evaluate our methods on the synthetic part of the LLM-SRBench (Shojaee et al., 2025), denoted as LSR-Synth2. It combines known terms in the underlying equation with synthetic, novel terms to create problems that go beyond memorization. It contains 129 problems, spanning four scientific domains: chemistry (36), biology (24), physics (44), and material science (25). For each problem, it has three types of datasets: training set accessible to the SR method, an in-domain (ID) test set, and an out-of-domain (OOD) test set. Evaluation Metrics We use accuracy-to-tolerance as our main metric. We find it serves as more robust metric when aggregating the overall results covering multiple problems than others, like Normalized Mean Squared Error. It is also more challenging than other metrics like 𝑅2. Please refer to Appendix A.4 for detailed analysis. Given desired tolerance threshold 𝜏, the metric calculates whether the predicted values and the ground truth values satisfy it as follows: Acc𝜏 = 1 (cid:18) max 1𝑖 𝑁test (cid:12) (cid:12) (cid:12) (cid:12) ˆ𝑦𝑖 𝑦𝑖 𝑦𝑖 (cid:12) (cid:12) (cid:12) (cid:12) (cid:19) 𝜏 (4) We discard the 5% worst predictions to prevent outliers due to the presence of the max operator, following Biggio et al. (2021); Kamienny et al. (2022). Additionally, we present symbolic accuracy, which checks if the discovered equations are identical to the ground truth equations. We present the details for the symbolic accuracy calculation in Appendix A.7. Baselines We comprehensively compare our methods against several baseline methods. For methods without LLMs, we include GPLearn, E2E (Kamienny et al., 2022), NeSymReS (Biggio et al., 2021), DSR (Petersen et al., 2021), uDSR (Landajuela et al., 2022), and PySR (Cranmer, 2023). For the LLM-based methods, we include LLM-SR and LaSR for comparison. For methods without LLMs, we constrain the number of equation candidates for each problem to 100,000. For methods with LLMs, we constrain the LLM calls to 1,000, with at most 1,000 equation candidates from each problem. For SR-Scientist, we set the maximum number of turns per iteration to 25, with total of 40 iterations. We present the configuration details of the baseline methods in Appendix A.1 and the configuration of SR-Scientist in Appendix A.2. We evaluate our method with different models as backbone LLMs, 2We also considered LSR-Transform (Shojaee et al., 2025) as candidate for the evaluation dataset. However, we found that it might still have memorization issues, as nearly 50% of the problems achieved sufficiently small error after the first iteration. 6 SR-Scientist: Scientific Equation Discovery With Agentic AI Method Overall Material Science Chemistry Biology Physics Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 GPLearn E2E NeSymReS DSR uDSR PySR 0.00 0.26 3.10 0.00 29.46 29.46 11.89 LaSR LLM-SR 41.08 SR-Scientist 49. 14.21 LaSR LLM-SR 35.92 SR-Scientist 48.32 0.00 0.00 0.78 0.00 12.40 14.47 7.49 18.09 24.55 8.53 14.47 25.06 16.02 LaSR LLM-SR 28.16 SR-Scientist 63.57 10.08 11.37 49. 12.66 LaSR LLM-SR 33.33 SR-Scientist 42.64 12.66 LaSR LLM-SR 24.55 SR-Scientist 32.30 40.92 + RL 8.53 12.92 23.00 8.27 7.24 16.02 20.69 Without LLMs 0.00 0.00 4.00 0.00 8.00 22. 0.00 0.00 2.78 0.00 50.00 25.93 0.00 0.00 0.00 0.00 25.00 11.11 0.00 1.33 8.00 0.00 36.00 53.33 Qwen3-Coder-480B-A35B-Instruct 13.33 80.00 86.67 6.67 52.00 69. 16.67 36.11 40.74 9.26 9.26 5.56 GLM-4.5-Air 12.00 38.67 70.67 16.67 30.56 45.37 10.18 3.71 11. GPT-OSS-120B 0.00 0.00 4.17 0.00 29.17 16.67 6.95 30.56 50.00 11.11 18.06 40.28 0.00 0.00 0.00 0.00 8.33 6.95 6.95 18.06 26. 5.56 4.17 16.66 0.00 0.00 0.00 0.00 9.09 25.76 9.85 28.79 34.09 11.36 35.61 36.37 0.00 0.00 0.00 0.00 6.82 16.67 6.82 6.06 13. 6.82 15.15 15.15 12.00 38.67 60.00 18.52 22.22 81.48 12.96 3.71 64.81 9.72 11.11 66.67 5.56 2.78 43. 15.15 21.97 40.91 9.09 6.82 34.09 GPT-OSS-20B 8.00 46.67 40.00 15.74 28.71 49.07 12.96 5.56 23. Qwen3-Coder-30B-A3B-Instruct 20.00 29.33 81.33 85.33 10.67 6.67 52.00 65.33 17.59 30.55 22.22 37.38 12.04 10.18 5.56 7.46 11.11 22.22 34. 8.33 15.28 22.22 29.17 6.95 2.78 19.44 6.95 5.55 8.33 11.11 9.85 21.97 30.30 6.82 21.97 18.18 25.00 6.06 5.30 15. 4.55 6.06 8.33 11.37 18.67 61.33 81.33 20.00 64.00 74.67 14.67 70.67 62.67 Table 1 Comparison of SR-Scientist and SR baseline models on different scientific benchmark problems measured by 𝐴𝑐𝑐0.01 and 𝐴𝑐𝑐0.001. including Qwen3-Coder-480B-A35B (Qwen, 2025), GLM-4.5-Air (Zeng et al., 2025a), GPT-OSS120B (OpenAI, 2025), GPT-OSS-20B, and Qwen3-Coder-30B-A3B. Due to computation costs and training infrastructure limitations, we use only Qwen3-Coder-30B-A3B for RL training, while the other models are used for inference only. However, we also verify the effectiveness of RL training on other models and present the results in Appendix A.3.4. For each experiment, we repeat it three times and report the average value to reduce noise. Training Details For training data construction, we synthesize training data for the scientific scenarios in LSR-Synth. To prevent data contamination, two authors of this paper independently and carefully checked the equation skeletons to prevent duplicates and confirmed their agreement. Finally, we obtained 1024 problems for RL training. Please refer to Appendix A.3.1 for details. During rollout, we set the maximum number of turns to 20 and train for 60 steps. We set 𝑠max to 100% and 𝑠goal to 0.1% in the reward design. The detailed training configure can be found in the Appendix A.3.3. 7 SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 2 Detailed results of in-domain (ID) and out-of-domain (OOD) performance using Acc0.01 across various LSR-Synth scientific domains. (with Qwen3-Coder-480B as LLM backbone) 4.2. Main Results Precision Table 1 presents the accuracy results. In terms of overall accuracy, SR-Scientist consistently outperforms the baseline methods, with four of the models achieving an absolute performance margin of 6% to 35% over the baselines. Notably, when using GPT-OSS-120B as backbone, SR-Scientist achieves the highest overall performance, with an 𝐴𝑐𝑐0.01 of 63.57% and an 𝐴𝑐𝑐0.001 of 49.35%. In terms of performance across different subjects, with backbones such as Qwen3-Coder-480B, GLM4.5-Air, and GPT-OSS-120B, SR-Scientist surpasses other LLM-based methods in all subjects. For Qwen3-Coder-30B, end-to-end RL training significantly improves its performance compared to the original model in all subjects, highlighting that the agent can evolve its abilities through its own experience. We provide further analysis of the LLM backbone for RL training in Appendix A.3.4 and the computation cost discussion in Appendix A.5. OOD Performance Figure 2 shows the performance of the discovered equations on OOD data. For material science, the performance of all methods improves when shifting from ID to OOD data, while for other subjects, the methods exhibit varying trends. Among them, SR-Scientist still achieves the best performance on OOD data, demonstrating its strong generalization capabilities. The results of other models are presented in Appendix A.6 and show similar trends. Robustness to Noise To test the robustness to noise in the observed data, we add Gaussian noise with different standard deviations (𝜎 = {0.01, 0.05, 0.1}) to each training data point the model has access to and report the overall performance. As shown in Figure 3, while the performance of all methods drops as the noise level increases, SR-Scientist consistently performs better than other methods, especially with Qwen3-Coder-480B and GLM-4.5-Air as LLM backbones. Symbolic Accuracy Table 2 shows the symbolic accuracy of representative methods, evaluated on all problems in the dataset. Overall, it is challenging to identify equations identical to the ground truth 8 SR-Scientist: Scientific Equation Discovery With Agentic AI Method SA 0.77 uDSR 4.65 PySR 5.43 LLM-SR (GLM) 4.65 LLM-SR (GPT) 5.43 LLM-SR (Qwen) 7.75 SR-Scientist (GLM) SR-Scientist (GPT) 7.00 SR-Scientist (Qwen) 7.00 Table 2 Symbolic accuracy (SA) of different methods. GLM, GPT, and Qwen represent GLM-4.5-Air, GPT-OSS-120B, and Qwen3-Coder-480B, respectively. Figure 3 Noise robustness analysis. Qwen, GLM, and GPT represent Qwen3-Coder-480B, GLM-4.5-Air, and GPT-OSS-120B, respectively. Method Acc0.01 Acc0. SR-Scientist (GPT) w/o 𝑇1 w/o experience SR-Scientist (Qwen) w/o 𝑇1 w/o experience SR-Scientist (GLM) w/o 𝑇1 w/o experience 63.57 35.66 57.36 49.09 41.08 35.66 48.32 46.51 37. 49.35 16.28 41.86 24.55 14.73 16.28 25.06 22.48 18.61 Table 3 Ablation studies. In w/o 𝑇1, the agent can not utilize the data analyzer tool. In w/o experience, the agent can not utilize the experience buffer and optimize from scratch for each iteration. GPT, Qwen, and GLM represent GPTOSS-120B, Qwen3-Coder-480B, and GLM-4.5Air, respectively. Figure 4 Overall performance under different maximum turns. We keep the total number of LLM calls at around 1,000 and trade off between maximum turns and iterations. from observed data. Among these methods, SR-Scientist achieves the best performance, correctly identifying the most equations. For more qualitative assessment, Figure 5 presents the discovered equations for the PO10 and PO37 physics problems, which are related to nonlinear oscillators. For both problems, SR-Scientist identifies the structure of the equation and its constants, while the equations from other methods are usually more complex and less accurate. Additionally, SR-Scientist produces trajectories that illustrate its derivation process, providing information that can inspire human scientists to design better equations. 9 SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 5 Equations discovered for the PO10 and PO37 physics problems. The variables (cid:164)𝑣(𝑡), 𝑡, 𝑥, and 𝑣 represent acceleration in non-linear harmonic oscillator, time, position, and velocity, respectively. Terms highlighted in green are common to both the predicted and ground truth equations. 4.3. Analysis Ablation studies Table 3 presents the results of our ablation studies on the data analysis and experience buffer components. The findings indicate that allowing the agent to perform data analysis is crucial for performance, particularly for the GPT-OSS-120B and Qwen3-Coder-480B models. Moreover, the experience buffer is essential for the continuous optimization of equations across iterations. The Effect of the Turn Number We fixed the LLM calls at around 1,000 and traded off between maximum turns and iterations to investigate the effect of different exploration lengths at each iteration. Increasing the maximum turns from 10 to 25, as shown in Figure 4, significantly improves performance, highlighting the value of long-horizon optimization. However, performance stagnates or slightly drops beyond 25 turns, indicating that excessively long exploration does not bring additional performance and that the inference budget should be allocated to initiating new iterations. Tool Call Analysis We analyzed the distribution of tool call types and instructed LLMs to classify the data analyzer behaviors, presenting the results in Figure 6. Overall, the Qwen and GLM families exhibit similar patterns, with around 80% of their calls dedicated to equation evaluation and 20% to data analysis. Within the data analysis calls, data statistics generally account for higher percentage, showing the importance of calculating relevant values such as correlations and averages. In contrast, GPT-OSS-20B and GPT-OSS-120B tend to directly write their own code to perform residual error 10 SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 6 The tool call behaviors of different models. analysis for more fine-grained information. Further case studies show that GPT-OSS-120B also tends to directly define equation constants through data analysis, demonstrating greater flexibility. Moreover, after RL training, the Qwen3-Coder-30B also increases its use of data statistics for more advanced data analysis. 5. Conclusion In this paper, we introduce SR-Scientist, framework that transforms the LLM from passive equation proposer into an autonomous scientist for symbolic regression. By analyzing data, evaluating and refining equations, the agent generates and refines hypotheses through active environmental interaction. Our experiments show that SR-Scientist significantly outperforms existing methods in precision, generalization, robustness to noise, and symbolic accuracy. Furthermore, we develop complete reinforcement learning pipeline that allows the agent to self-evolve and enhance its discovery capabilities."
        },
        {
            "title": "Acknowledgments",
            "content": "We would like to express our great gratitude to Yan Ma for assisting with the writing and to Xuefeng Li for providing advice on RL Infra. This work was partially funded by the National Natural Science Foundation of China (62476168), the National High Technology Research and Development Program of China (2015AA015408), the Shanghai Science and Technology Development Funds (14ZR1403200), and the AI for Science Program of the Shanghai Municipal Commission of Economy and Informatization (2025-GZL-RGZN-BTBX-01013)."
        },
        {
            "title": "References",
            "content": "Anthropic. claude-code. https://github.com/anthropics/claude-code, 2025. R. Batra, L. Song, and R. Ramprasad. Emerging materials intelligence ecosystems propelled by machine learning. Nature Reviews Materials, 6(8):655678, 2021. 11 SR-Scientist: Scientific Equation Discovery With Agentic AI L. Biggio, T. Bendinelli, A. Neitz, A. Lucchi, and G. Parascandolo. Neural symbolic regression that scales. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 936945. PMLR, 2021. URL http://proceedings.mlr.press/v139 /biggio21a.html. W. L. Cava, P. Orzechowski, B. Burlacu, F. O. de França, M. Virgolin, Y. Jin, M. Kommenda, and J. H. Moore. Contemporary symbolic regression methods and their relative performance, 2021. URL https://arxiv.org/abs/2107.14351. M. Cranmer. Interpretable machine learning for science with pysr and symbolicregression.jl, 2023. URL https://arxiv.org/abs/2305.01582. DeepSeek-AI, D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi, X. Zhang, X. Yu, Y. Wu, Z. F. Wu, Z. Gou, Z. Shao, Z. Li, Z. Gao, A. Liu, B. Xue, B. Wang, B. Wu, B. Feng, C. Lu, C. Zhao, C. Deng, C. Zhang, C. Ruan, D. Dai, D. Chen, D. Ji, E. Li, F. Lin, F. Dai, F. Luo, G. Hao, G. Chen, G. Li, H. Zhang, H. Bao, H. Xu, H. Wang, H. Ding, H. Xin, H. Gao, H. Qu, H. Li, J. Guo, J. Li, J. Wang, J. Chen, J. Yuan, J. Qiu, J. Li, J. L. Cai, J. Ni, J. Liang, J. Chen, K. Dong, K. Hu, K. Gao, K. Guan, K. Huang, K. Yu, L. Wang, L. Zhang, L. Zhao, L. Wang, L. Zhang, L. Xu, L. Xia, M. Zhang, M. Zhang, M. Tang, M. Li, M. Wang, M. Li, N. Tian, P. Huang, P. Zhang, Q. Wang, Q. Chen, Q. Du, R. Ge, R. Zhang, R. Pan, R. Wang, R. J. Chen, R. L. Jin, R. Chen, S. Lu, S. Zhou, S. Chen, S. Ye, S. Wang, S. Yu, S. Zhou, S. Pan, S. S. Li, S. Zhou, S. Wu, S. Ye, T. Yun, T. Pei, T. Sun, T. Wang, W. Zeng, W. Zhao, W. Liu, W. Liang, W. Gao, W. Yu, W. Zhang, W. L. Xiao, W. An, X. Liu, X. Wang, X. Chen, X. Nie, X. Cheng, X. Liu, X. Xie, X. Liu, X. Yang, X. Li, X. Su, X. Lin, X. Q. Li, X. Jin, X. Shen, X. Chen, X. Sun, X. Wang, X. Song, X. Zhou, X. Wang, X. Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. Zhang, Y. Xu, Y. Li, Y. Zhao, Y. Sun, Y. Wang, Y. Yu, Y. Zhang, Y. Shi, Y. Xiong, Y. He, Y. Piao, Y. Wang, Y. Tan, Y. Ma, Y. Liu, Y. Guo, Y. Ou, Y. Wang, Y. Gong, Y. Zou, Y. He, Y. Xiong, Y. Luo, Y. You, Y. Liu, Y. Zhou, Y. X. Zhu, Y. Xu, Y. Huang, Y. Li, Y. Zheng, Y. Zhu, Y. Ma, Y. Tang, Y. Zha, Y. Yan, Z. Z. Ren, Z. Ren, Z. Sha, Z. Fu, Z. Xu, Z. Xie, Z. Zhang, Z. Hao, Z. Ma, Z. Yan, Z. Wu, Z. Gu, Z. Zhu, Z. Liu, Z. Li, Z. Xie, Z. Song, Z. Pan, Z. Huang, Z. Xu, Z. Zhang, and Z. Zhang. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948. J. Gao, W. Fu, M. Xie, S. Xu, C. He, Z. Mei, B. Zhu, and Y. Wu. Beyond ten turns: Unlocking longhorizon agentic search with large-scale asynchronous rl, 2025. URL https://arxiv.org/abs/ 2508.07976. Google. Gemini cli. https://github.com/google-gemini/gemini-cli, 2025. A. Grayeli, A. Sehgal, O. Costilla-Reyes, M. Cranmer, and S. Chaudhuri. Symbolic regression with learned concept library, 2024. URL https://arxiv.org/abs/2409.09359. A. Hernandez, A. Balasubramanian, F. Yuan, S. Mason, and T. Mueller. Fast, accurate, and transferable many-body interatomic potentials by symbolic regression, 2019. URL https://arxiv.org/ab s/1904.01095. P. Kamienny, S. dAscoli, G. Lample, and F. Charton. End-to-end symbolic regression with transformers. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/42eb37cdbefd7abae0835f4 b67548c39-Abstract-Conference.html. 12 SR-Scientist: Scientific Equation Discovery With Agentic AI M. Landajuela, C. S. Lee, J. Yang, R. Glatt, C. P. Santiago, I. Aravena, T. N. Mundhenk, G. Mulcahy, and B. K. Petersen. unified framework for deep symbolic regression. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/pap er_files/paper/2022/hash/dbca58f35bddc6e4003b2dd80e42f838-Abstract-Confe rence.html. P. Lemos, N. Jeffrey, M. Cranmer, S. Ho, and P. Battaglia. Rediscovering orbital mechanics with machine learning, 2022. URL https://arxiv.org/abs/2202.02306. P. Ma, T.-H. Wang, M. Guo, Z. Sun, J. B. Tenenbaum, D. Rus, C. Gan, and W. Matusik. Llm and simulation as bilevel optimizers: new paradigm to advance physical scientific discovery, 2024. URL https://arxiv.org/abs/2405.09783. N. Makke and S. Chawla. Interpretable scientific discovery with symbolic regression: review. Artificial Intelligence Review, 57(1):2, 2024. A. Newell, H. A. Simon, et al. Human problem solving, volume 104. Prentice-hall Englewood Cliffs, NJ, 1972. A. Novikov, N. Vu, M. Eisenberger, E. Dupont, P.-S. Huang, A. Z. Wagner, S. Shirobokov, B. Kozlovskii, F. J. R. Ruiz, A. Mehrabian, M. P. Kumar, A. See, S. Chaudhuri, G. Holland, A. Davies, S. Nowozin, P. Kohli, and M. Balog. Alphaevolve: coding agent for scientific and algorithmic discovery, 2025. URL https://arxiv.org/abs/2506.13131. OpenAI. gpt-oss-120b & gpt-oss-20b model card, 2025. URL https://arxiv.org/abs/2508.1 0925. B. K. Petersen, M. Landajuela, T. N. Mundhenk, C. P. Santiago, S. Kim, and J. T. Kim. Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=m5Qsh0kBQG. Y. Qin, Y. Ye, J. Fang, H. Wang, S. Liang, S. Tian, J. Zhang, J. Li, Y. Li, S. Huang, W. Zhong, K. Li, J. Yang, Y. Miao, W. Lin, L. Liu, X. Jiang, Q. Ma, J. Li, X. Xiao, K. Cai, C. Li, Y. Zheng, C. Jin, C. Li, X. Zhou, M. Wang, H. Chen, Z. Li, H. Yang, H. Liu, F. Lin, T. Peng, X. Liu, and G. Shi. Ui-tars: Pioneering automated gui interaction with native agents, 2025. URL https://arxiv.org/abs/ 2501.12326. Qwen. Qwen3 technical report, 2025. URL https://arxiv.org/abs/2505.09388. B. Romera-Paredes, M. Barekatain, A. Novikov, M. Balog, M. P. Kumar, E. Dupont, F. J. Ruiz, J. S. Ellenberg, P. Wang, O. Fawzi, et al. Mathematical discoveries from program search with large language models. Nature, 625(7995):468475, 2024. J. Schneider. Generative to agentic ai: Survey, conceptualization, and challenges, 2025. URL https://arxiv.org/abs/2504.18875. Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, X. Bi, H. Zhang, M. Zhang, Y. K. Li, Y. Wu, and D. Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024. URL https://arxiv.org/abs/2402.03300. 13 SR-Scientist: Scientific Equation Discovery With Agentic AI P. Shojaee, K. Meidani, S. Gupta, A. B. Farimani, and C. K. Reddy. Llm-sr: Scientific equation discovery via programming with large language models, 2024. URL https://arxiv.org/abs/2404.184 00. P. Shojaee, N.-H. Nguyen, K. Meidani, A. B. Farimani, K. D. Doan, and C. K. Reddy. Llm-srbench: new benchmark for scientific equation discovery with large language models, 2025. URL https: //arxiv.org/abs/2504.10415. R. Sutton. The bitter lesson. Incomplete Ideas (blog), 13(1):38, 2019. K. Team, Y. Bai, Y. Bao, G. Chen, J. Chen, N. Chen, R. Chen, Y. Chen, Y. Chen, Y. Chen, Z. Chen, J. Cui, H. Ding, M. Dong, A. Du, C. Du, D. Du, Y. Du, Y. Fan, Y. Feng, K. Fu, B. Gao, H. Gao, P. Gao, T. Gao, X. Gu, L. Guan, H. Guo, J. Guo, H. Hu, X. Hao, T. He, W. He, W. He, C. Hong, Y. Hu, Z. Hu, W. Huang, Z. Huang, Z. Huang, T. Jiang, Z. Jiang, X. Jin, Y. Kang, G. Lai, C. Li, F. Li, H. Li, M. Li, W. Li, Y. Li, Y. Li, Z. Li, Z. Li, H. Lin, X. Lin, Z. Lin, C. Liu, C. Liu, H. Liu, J. Liu, J. Liu, L. Liu, S. Liu, T. Y. Liu, T. Liu, W. Liu, Y. Liu, Y. Liu, Y. Liu, Y. Liu, Z. Liu, E. Lu, L. Lu, S. Ma, X. Ma, Y. Ma, S. Mao, J. Mei, X. Men, Y. Miao, S. Pan, Y. Peng, R. Qin, B. Qu, Z. Shang, L. Shi, S. Shi, F. Song, J. Su, Z. Su, X. Sun, F. Sung, H. Tang, J. Tao, Q. Teng, C. Wang, D. Wang, F. Wang, H. Wang, J. Wang, J. Wang, J. Wang, S. Wang, S. Wang, Y. Wang, Y. Wang, Y. Wang, Y. Wang, Y. Wang, Z. Wang, Z. Wang, Z. Wang, C. Wei, Q. Wei, W. Wu, X. Wu, Y. Wu, C. Xiao, X. Xie, W. Xiong, B. Xu, J. Xu, J. Xu, L. H. Xu, L. Xu, S. Xu, W. Xu, X. Xu, Y. Xu, Z. Xu, J. Yan, Y. Yan, X. Yang, Y. Yang, Z. Yang, Z. Yang, Z. Yang, H. Yao, X. Yao, W. Ye, Z. Ye, B. Yin, L. Yu, E. Yuan, H. Yuan, M. Yuan, H. Zhan, D. Zhang, H. Zhang, W. Zhang, X. Zhang, Y. Zhang, Y. Zhang, Y. Zhang, Y. Zhang, Y. Zhang, Y. Zhang, Z. Zhang, H. Zhao, Y. Zhao, H. Zheng, S. Zheng, J. Zhou, X. Zhou, Z. Zhou, Z. Zhu, W. Zhuang, and X. Zu. Kimi k2: Open agentic intelligence, 2025. URL https://arxiv.org/abs/2507.20534. M. Virgolin and S. P. Pissis. Symbolic regression is np-hard, 2022. URL https://arxiv.org/abs/ 2207.01018. H. Wang, H. Zou, H. Song, J. Feng, J. Fang, J. Lu, L. Liu, Q. Luo, S. Liang, S. Huang, W. Zhong, Y. Ye, Y. Qin, Y. Xiong, Y. Song, Z. Wu, A. Li, B. Li, C. Dun, C. Liu, D. Zan, F. Leng, H. Wang, H. Yu, H. Chen, H. Guo, J. Su, J. Huang, K. Shen, K. Shi, L. Yan, P. Zhao, P. Liu, Q. Ye, R. Zheng, S. Xin, W. X. Zhao, W. Heng, W. Huang, W. Wang, X. Qin, Y. Lin, Y. Wu, Z. Chen, Z. Wang, B. Zhong, X. Zhang, X. Li, Y. Li, Z. Zhao, C. Jiang, F. Wu, H. Zhou, J. Pang, L. Han, Q. Liu, Q. Ma, S. Liu, S. Cai, W. Fu, X. Liu, Y. Wang, Z. Zhang, B. Zhou, G. Li, J. Shi, J. Yang, J. Tang, L. Li, Q. Han, T. Lu, W. Lin, X. Tong, X. Li, Y. Zhang, Y. Miao, Z. Jiang, Z. Li, Z. Zhao, C. Li, D. Ma, F. Lin, G. Zhang, H. Yang, H. Guo, H. Zhu, J. Liu, J. Du, K. Cai, K. Li, L. Yuan, M. Han, M. Wang, S. Guo, T. Cheng, X. Ma, X. Xiao, X. Huang, X. Chen, Y. Du, Y. Chen, Y. Wang, Z. Li, Z. Yang, Z. Zeng, C. Jin, C. Li, H. Chen, H. Chen, J. Chen, Q. Zhao, and G. Shi. Ui-tars-2 technical report: Advancing gui agent with multi-turn reinforcement learning, 2025a. URL https://arxiv.org/abs/2509.02544. R. Wang, B. Wang, K. Li, Y. Zhang, and J. Cheng. Drsr: Llm based scientific equation discovery with dual reasoning from data and experience, 2025b. URL https://arxiv.org/abs/2506.04282. S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview .net/pdf?id=WE_vluYUL-X. A. Zeng, X. Lv, Q. Zheng, Z. Hou, B. Chen, C. Xie, C. Wang, D. Yin, H. Zeng, J. Zhang, K. Wang, L. Zhong, M. Liu, R. Lu, S. Cao, X. Zhang, X. Huang, Y. Wei, Y. Cheng, Y. An, Y. Niu, Y. Wen, Y. Bai, Z. Du, Z. Wang, Z. Zhu, B. Zhang, B. Wen, B. Wu, B. Xu, C. Huang, C. Zhao, C. Cai, C. Yu, 14 SR-Scientist: Scientific Equation Discovery With Agentic AI C. Li, C. Ge, C. Huang, C. Zhang, C. Xu, C. Zhu, C. Li, C. Yin, D. Lin, D. Yang, D. Jiang, D. Ai, E. Zhu, F. Wang, G. Pan, G. Wang, H. Sun, H. Li, H. Li, H. Hu, H. Zhang, H. Peng, H. Tai, H. Zhang, H. Wang, H. Yang, H. Liu, H. Zhao, H. Liu, H. Yan, H. Liu, H. Chen, J. Li, J. Zhao, J. Ren, J. Jiao, J. Zhao, J. Yan, J. Wang, J. Gui, J. Zhao, J. Liu, J. Li, J. Li, J. Lu, J. Wang, J. Yuan, J. Li, J. Du, J. Du, J. Liu, J. Zhi, J. Gao, K. Wang, L. Yang, L. Xu, L. Fan, L. Wu, L. Ding, L. Wang, M. Zhang, M. Li, M. Xu, M. Zhao, M. Zhai, P. Du, Q. Dong, S. Lei, S. Tu, S. Yang, S. Lu, S. Li, S. Li, Shuang-Li, S. Yang, S. Yi, T. Yu, W. Tian, W. Wang, W. Yu, W. L. Tam, W. Liang, W. Liu, X. Wang, X. Jia, X. Gu, X. Ling, X. Wang, X. Fan, X. Pan, X. Zhang, X. Zhang, X. Fu, X. Zhang, Y. Xu, Y. Wu, Y. Lu, Y. Wang, Y. Zhou, Y. Pan, Y. Zhang, Y. Wang, Y. Li, Y. Su, Y. Geng, Y. Zhu, Y. Yang, Y. Li, Y. Wu, Y. Li, Y. Liu, Y. Wang, Y. Li, Y. Zhang, Z. Liu, Z. Yang, Z. Zhou, Z. Qiao, Z. Feng, Z. Liu, Z. Zhang, Z. Wang, Z. Yao, Z. Wang, Z. Liu, Z. Chai, Z. Li, Z. Zhao, W. Chen, J. Zhai, B. Xu, M. Huang, H. Wang, J. Li, Y. Dong, and J. Tang. Glm-4.5: Agentic, reasoning, and coding (arc) foundation models, 2025a. URL https://arxiv.org/abs/2508.06471. W. Zeng, Y. Huang, Q. Liu, W. Liu, K. He, Z. Ma, and J. He. Simplerl-zoo: Investigating and taming zero reinforcement learning for open base models in the wild, 2025b. URL https: //arxiv.org/abs/2503.18892. A. Appendix A.1. Baseline Implementation Details GPLearn The open-source gplearn3 library is Python package built on scikit-learn that uses genetic programming to perform SR. We set the population size to 500, the number of generations to 200, and the tournament size to 20. The function set includes addition, subtraction, multiplication, division, sine, cosine, square root, logarithm, absolute value, negation, and inverse. End-to-End Symbolic Regression (E2E) E2E (Kamienny et al., 2022) is method that uses single deep learning model, often Transformer, to directly predict complete mathematical expression, including both its structure and numerical constants. We implement the method using the symbolicregression Facebook repository4. For this method, we set the maximum input points to 200 and the number of trees for refinement to 10. NeSymReS NeSymReS (Biggio et al., 2021) is deep learning approach that uses pre-trained Transformer model to directly predict mathematical expression from data points. We use the NeuralSymbolicRegressionThatScales5 repository to implement this method. We set the number of data points passed to the Transformer to 500 and the beam size (expression sampling size) to 32. Deep Symbolic Regression (DSR) DSR (Petersen et al., 2021) is deep learning approach that uses recurrent neural network and reinforcement learning to search for the mathematical expression that best fits given dataset. We implement the method using the deep-symbolic-optimization6 repository. For this method, we set the number of samples to 100,000, the batch size to 512, and the 3https://gplearn.readthedocs.io/en/stable/ 4https://github.com/facebookresearch/symbolicregression 5https://github.com/SymposiumOrganization/NeuralSymbolicRegressionThatScales 6https://github.com/dso-org/deep-symbolic-optimization SR-Scientist: Scientific Equation Discovery With Agentic AI learning rate to 0.0005. The function set includes addition, subtraction, multiplication, division, sine, cosine, exponentiation, and logarithm, with expression lengths ranging from 1 to 9. Unified Deep Symbolic Regression (uDSR) uDSR (Landajuela et al., 2022) is deep learning framework that unifies multiple symbolic regression strategies into single modular system. It extends DSR by combining approaches like neural-guided search, pre-training, and linear models. We implement it using the deep-symbolic-optimization repository. For the genetic programming configuration, we set the population size to 100, generations to 20, crossover probability to 0.5, mutation probability to 0.5, tournament size to 5, and maximum mutation tree depth to 3. Other parameters are the same as DSRs. The function set is: add, sub, mul, div, sin, cos, exp, log, and poly. Python Symbolic Regression (PySR) The PySR Python package7 (Cranmer, 2023) uses powerful Julia backend to find simple, interpretable mathematical expressions that best fit the observed data. We set the number of iterations to 125, cycles per iteration to 550, populations to 15 with population size of 33, maximum size to 30, and the randomization weight to 0.1. Its binary operators are +, , , /, pow, and its unary operators8 are exp, log, sqrt, sin, cos. Library-Augmented Symbolic Regression (LaSR) LaSR (Grayeli et al., 2024) uses LLMs to discover and evolve library of abstract, natural-language concepts. We implement the method using the LibraryAugmentedSymbolicRegression.jl9 repository. For this method, we set the number of iterations to 25, cycles per iteration to 550, populations to 10 with population size of 33, maximum size to 30, and the maximum number of concepts to 20. The LLM operation weights for crossover, mutation, and randomization are each set to 0.02. The binary operators, unary operators, nested constraints, and other constraints are the same as those in PySR. LLM-SR LLM-SR (Shojaee et al., 2024) leverages the extensive scientific knowledge and codegeneration capabilities of LLMs to discover mathematical equations. It treats equations as programs and combines an LLMs scientific priors with an evolutionary search to find accurate and interpretable formulas. We implement it using the llm-srbench10 repository with its default configuration and set the maximum number of LLM calls to 1,000 for each problem. A.2. Details of SR-Scientist Inference Framework For each iteration, we set the initial MAPE goal to 0.1% and the termination MAPE threshold to 0.0001%. For each LLM, we set the sampling temperature to 0.7 and the maximum completion length per call to 8,192. For the equation evaluator tool, to control the length and the complexity of the generated equations, we set the maximum number of parameters to 10 in all experiments, following Shojaee et al. (2024). To ensure fair comparison with methods like LLM-SR, the optimization goal for the BFGS algorithm is the mean squared error. For parameter optimization, we use the scipy library for nonlinear optimization with the BFGS algorithm. The prompt for the LLM agent is shown in Figure 13 and Figure 14. For Qwen3-Coder-480B and GLM-4.5-Air, we use their FP8 quantization versions. 7https://astroautomata.com/PySR/ 8Nested Constraints: sin : {sin : 0, cos : 0}, cos : {sin : 0, cos : 0}, exp : {exp : 0, log : 0}, log : {exp : 0, log : 0}, sqrt : {sqrt : 0}; Constraints: {sin : 10, cos : 10, exp : 20, log : 20, sqrt : 20, pow : (1, 20)} 9https://github.com/trishullab/LibraryAugmentedSymbolicRegression.jl 10https://github.com/deep-symbolic-mathematics/llm-srbench SR-Scientist: Scientific Equation Discovery With Agentic AI A.3. Details of SR-Scientist Training Framework A.3.1. Training Data Synthesis We synthesize our training data following the approach of Shojaee et al. (2024), using hybrid model-based and rule-based method. The problems cover four scientific disciplines: materials science (Stress with respect to Strain and Temperature), chemistry (Reaction rate with respect to Time and Concentration), biology (Growth rate with respect to Time and Population size), and physics (Acceleration with respect to Time, Displacement, and Velocity). The detailed procedure is as follows: (1) Equation Skeleton Generation: Each equation skeleton contains at least one known and one novel term. The known terms refer to common concepts from an LLMs pre-training knowledge, and the novel terms refer to terms outside the LLMs prior knowledge. We synthesize both types of terms by prompting Claude 4 Sonnet. These terms are then combined into equation skeletons using addition. To ensure moderate level of complexity, each equation is limited to 2-4 total terms. To prevent potential data leakage between our training set and the benchmark data, two authors of the paper independently identify equations that are identical or too similar and discuss them for further reconciliation. Any equations deemed too similar are discarded. (2) Parameter Instantiation: For each equation skeleton, we transform it into complete equation by assigning values to each constant. This process is not random assignment; rather, it is guided by the scientific context and significance of each term. For example, in the context of material science, the reference temperature 𝑇0 is set to 273.15 (the triple point of water). We instruct the LLMs to perform value assignment, which is then followed by human validation. (3) Data Point Generation: For the material science equations, which represent static systems, we generate data points by uniformly sampling across defined range of parameters. The temperature 𝑇 is sampled from the range of [273 K, 573 K], and strain 𝜖 is sampled from [0, 0.6]. total of 5000 points are generated using an evenly spaced grid. The OOD test set is created by taking the 500 data points with the highest temperature values. The remaining 4500 points are then randomly shuffled, with 500 points allocated to the test set and the rest forming the training set. For the chemistry, biology, and physics equations, which represent dynamic systems, we use the solve_ivp function from the SciPy Python package with the RK45 method to solve the differential equations. Given initial conditions at 𝑡 = 0, we solve the equations to obtain the relationship between variables over time (equations that cannot be solved are simply discarded). We generate 5000 data points by uniformly sampling the time variable 𝑡 from the range of [0, 60]. The OOD test set is created by selecting the 500 data points with the highest time values. The remaining 4500 points are randomly partitioned into 500-point test set and the remaining training set. (4) Filtering and Final Dataset Assembly: In the filtering stage, we compute the statistical properties of the resulting data. Equations with data points that are scientifically anomalous are filtered out. This process ensures that our final dataset contains only scientifically meaningful equations with plausible data points. Finally, the instantiated equations, their corresponding numerical data points, and other relevant information (variable symbols, equation names, etc.) are packed for the subsequent training. A.3.2. Reward Design Besides the log-linear reward design, we also explore the stepwise reward function as follows: 17 SR-Scientist: Scientific Equation Discovery With Agentic AI Method Overall Material Science Chemistry Biology Physics Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 SR-Scientist + RL (log-linear) + RL (stepwise) 32.30 40.92 37.21 16.02 20.69 17.83 81.33 85.33 84.00 52.00 65.33 56. 22.22 37.38 27.78 5.56 7.46 2.78 22.22 29.17 33.33 8.33 11.11 16.67 18.18 25.00 20.45 8.33 11.37 9. Table 4 The performance of different reward functions. log-linear refers to the reward function corresponding to Equation 2 and stepwise refers to the reward function corresponding to Equation 5. Figure 7 The change in response length during training. Figure 8 The change in reward score during training. if 𝑠 < 0.001 if 0.001 𝑠 < 0.01 1.0 0.5 0.25 if 0.01 𝑠 < 0.1 0.1 0.0 if 0.1 𝑠 < 1 if 𝑠 = (5) where 𝑠 denotes the MAPE value. As shown in Table 4, the log-linear reward function performs better than the stepwise function. A.3.3. Training Details We conduct RL training on 32 NVIDIA H200 GPUs. For the infrastructure, we use the verl11 framework, employing SGLang as the rollout engine and FSDP as the training engine. For rollouts, we implement batch-level asynchronous rollouts to reduce the rollout time. We set the temperature to 1.0, the maximum response length to 10,240, and the maximum number of turns to 20. We use prompt batch size of 32 and generate 8 rollouts per prompt. The KL loss coefficient is set to 0 to encourage exploration. The remaining parameters use the default settings. Figures 7 and 8 present the training dynamics. As shown, the reward progressively increases and saturates at around 60 steps. The response length also increases, demonstrating that the model learns long-horizon problem-solving strategy. 11https://github.com/volcengine/verl 18 SR-Scientist: Scientific Equation Discovery With Agentic AI Method Overall Material Science Chemistry Biology Physics Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0.001 Acc0.01 Acc0. LLM-SR SR-Scientist +RL 30.49 29.46 39.53 LLM-SR SR-Scientist + RL 27.91 18.60 23.26 9.04 15.50 20.16 9.30 6.98 10. LLM-SR SR-Scientist + RL 22.48 15.50 20.93 8.53 4.65 9.30 34.67 72.00 80.00 56.00 48.00 52.00 48.00 40.00 68. Qwen3-32B 18.67 48.00 64.00 38.89 22.22 38.89 Qwen3-14B 32.00 28.00 40.00 16.67 13.89 16. Qwen3-8B 28.00 16.00 44.00 16.67 8.33 16.67 5.56 8.33 8.33 2.78 0.00 2.78 5.56 5.56 0. 15.28 20.83 25.00 8.33 12.50 20.83 8.33 16.67 4.17 4.17 4.17 4.17 0.00 4.17 0.00 0.00 0.00 0. 29.55 15.91 25.00 31.82 9.09 13.64 20.45 6.82 6.82 9.09 9.09 13.64 6.82 2.27 4.55 4.55 0.00 2. Table 5 Performance comparison of different LLM backbones for RL training, including Qwen3-8B, Qwen3-14B, and Qwen3-32B."
        },
        {
            "title": "Method",
            "content": "NMSE (Average) NMSE (Max) NMSE (Min) NMSE (Medium) LaSR LLM-SR SR-Scientist 1.53e-02 3.19e-03 1.29e-03 1.67e-01 7.83e-02 4.06e-02 2.66e-13 1.72e-14 1.57e-14 1.84e-03 8.87e-06 2.64eTable 6 Comparison of SR-Scientist and LLM-based SR baseline methods measured by NMSE. We report the result of Qwen3-Coder-480B on the physics subject. Method Overall (𝑅2) Material Science (𝑅2) Chemistry (𝑅2) Biology (𝑅2) Physics (𝑅2) LaSR LLM-SR SR-Scientist 0.991 0.998 0.998 0.998 0.996 0. 0.996 1.000 1.000 0.988 1.000 0.995 0.985 0.997 0.999 Table 7 Comparison of SR-Scientist and LLM-based SR baseline methods measured by 𝑅2. We report the result of Qwen3-Coder-480B. A.3.4. The Effect of LLM Backbone To further investigate the effect of RL training on different models, we conduct RL training on the Qwen3-8B, Qwen3-14B, and Qwen3-32B models using the same training configuration detailed in Appendix A.3.3 and present the results in Table 5. All models achieve significant performance gains after RL training, with most improving their performance across all subjects. When comparing LLM-SR and SR-Scientist without additional RL training, SR-Scientist outperforms LLM-SR on 𝐴𝑐𝑐0.01 and matches it on 𝐴𝑐𝑐0.1 when using Qwen3-32B as the LLM backbone. However, it lags behind when using the Qwen3-8B and Qwen3-14B models. This highlights the importance of models intrinsic ability in framework that provides the model with greater autonomy. 19 SR-Scientist: Scientific Equation Discovery With Agentic AI"
        },
        {
            "title": "API Cost Per Problem",
            "content": "SR-Scientist (GPT-OSS-120B) SR-Scientist (GPT-OSS-20B) Input: $0.05/1M; Output: $0.25/1M Input: $0.03/1M; Output: $0.15/1M $0.25 $0.1 Table 8 The estimated cost of SR-Scientist. This calculation does not consider cached tokens; including them would reduce the cost further. A.4. Analysis for the evaluation metrics Table 7 presents the results measured by the 𝑅2 metric. As shown, the differences between the various methods are small, making it difficult to distinguish their performance. Additionally, we present the NMSE results in Table 6. The average NMSE is sensitive to maximum values, which makes it an unreliable indicator of overall performance. Although quantitative methods could be employed, such as truncating errors that exceed certain constant, this threshold is difficult to define. Using the median value is also insufficient, as it cannot account for the entire performance distribution. Therefore, we abandoned these metrics and instead used accuracy-to-tolerance as the main metric. A.5. Cost For LLM-based methods, the cost mainly comes from API calls to LLMs. In Table 8, we present the estimated cost of SR-Scientist with GPT-OSS-120B and GPT-OSS-20B as the LLM backbones. We calculated the cost for each problem based on token consumption and common API pricing. As shown, the cost is acceptable for practical usage, and when considering cached tokens, the price can be further reduced. Additionally, we deployed GPT-OSS-120B on local server with 2 NVIDIA H100s for batch-level inference on 129 problems and recorded the wall-clock times. The maximum time was no more than 5 hours, duration that is acceptable for practical usage, as typical scenarios involve only few problems. A.6. OOD Performance of Other Models We illustrate the OOD performance using other models as LLM backbones in Figures 9, 10, 11, and 12. For models including GLM-4.5-Air, GPT-OSS-120B, and GPT-OSS-20B, SR-Scientist consistently outperforms the other methods in overall accuracy and most subjects. For Qwen3-Coder-30B, it slightly lags behind the method PySR on the OOD data. After RL training, it not only enhances its performance on ID data but also on OOD data, showing the generalization of the discovered equations. A.7. Symbolic Accuracy Calculation We calculate symbolic accuracy using two-step evaluation strategy: an initial assessment by an LLM, followed by human verification. Specifically, we instruct GPT-OSS-120B to determine the equivalence between predicted equation and its ground truth counterpart using the prompt shown in Figure 15. To ensure reliability, the LLM evaluates each problem 10 times. Our preliminary studies on 121 cases reveal 98.3% consistency rate between LLM and human evaluations for instances where the 10 voting results were unanimous. Therefore, our practical workflow involves first using the LLM for evaluation. However, for any case where the LLMs votes are inconsistent, we pass the problem to human evaluators for final decision. 20 SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 9 Detailed results of in-domain (ID) and out-of-domain (OOD) performance using Acc0.01 across various LSR-Synth scientific domains. (with GLM-4.5-Air as LLM backbone) A.8. Tool Call Analysis We instruct GPT-OSS-120B to perform tool call analysis using the prompt in Figure 16. We check 54 cases and find 94.4 % consistency between human and LLM-based evaluation. SR-Scientist: Scientific Equation Discovery With Agentic AI Figure 10 Detailed results of in-domain (ID) and out-of-domain (OOD) performance using Acc0.01 across various LSR-Synth scientific domains. (with GPT-OSS-120B as LLM backbone) Figure 11 Detailed results of in-domain (ID) and out-of-domain (OOD) performance using Acc0.01 across various LSR-Synth scientific domains. (with GPT-OSS-20B as LLM backbone) Figure 12 Detailed results of in-domain (ID) and out-of-domain (OOD) performance using Acc0.01 across various LSR-Synth scientific domains. (with Qwen3-Coder-30B as LLM backbone) 22 SR-Scientist: Scientific Equation Discovery With Agentic AI Your goal is to determine the correct equation, implement it as Python function, and optimize it until the mean absolute percentage error is less than 0.1%. You should use the equation_evaluator tool to evaluate the equations goodness of fit and the data_analyzer tool to write code for data analysis. For the equation_evaluator, it is code interpreter that wraps your function with the following code: python import numpy as np import sys import json # Initialize parameters MAX_NPARAMS = 10 params = [1.0] * MAX_NPARAMS # Example of user-provided equation def equation(x: np.ndarray, t: np.ndarray, v: np.ndarray, params: np.ndarray) -> np.ndarray: \"\"\" Mathematical function for Acceleration in Nonl-linear Harmonic Oscillator Args: x: numpy array representing observations of Position at time t. t: numpy array representing observations of Time. v: numpy array representing observations of Velocity at time t. params: Array of numeric constants or parameters to be optimized Return: numpy array representing Acceleration in Nonl-linear Harmonic Oscillator as the result of applying the mathematical function to the inputs. \"\"\" output = params[0] * + params[1] * + params[2] * + params[3] return output def evaluate(data: list) -> float: # Load data observations outputs = np.array([row[0] for row in data]) inputs = np.array([row[1:] for row in data]) = inputs # Optimize parameters based on data from scipy.optimize import minimize def loss(params): y_pred = equation(*X.T, params) return np.mean((y_pred - outputs) ** 2) loss_partial = lambda p: loss(p) result = minimize(loss_partial, [1.0] * MAX_NPARAMS, method=BFGS) # Return evaluation score optimized_params = result.x mse = result.fun if np.isnan(mse) or np.isinf(mse): return None, None, None var_outputs = np.var(outputs) if np.isclose(var_outputs, 0): nmse = 0.0 if np.isclose(mse, 0) else np.inf else: nmse = mse / var_outputs y_pred = equation(*X.T, optimized_params) zero_mask = np.isclose(outputs, 0) non_zero_mask = zero_mask mape = 0.0 if np.any(non_zero_mask): relative_errors=np.abs((y_pred[non_zero_mask] - outputs[non_zero_mask])/outputs[non_zero_mask]) mape = np.mean(relative_errors) return float(mse), float(nmse), float(mape) if __name__ == __main__: input_data_str = sys.stdin.read() data_list = json.loads(input_data_str) mse, nmse, mape = evaluate(data_list) if mse is not None: print(f\"MSE:{{mse:.6e}};NMSE:{{nmse:.6e}};Mean absolute percentage error:{{mape:.4%}}\") if mape < {mape_threshold}: print(\"Success: The mean absolute percentage error is smaller than 0.1%.\") else: print(\"Failure: The mean absolute percentage error is larger than 0.1%.\") As shown, the equation_evaluator tool assesses your equations goodness of fit. It uses SciPys BFGS optimizer to find the optimal parameters for your equation based on the dataset. It then provides an output with performance metrics (Mean Squared Error , Normalized Mean Squared Error, and Mean Absolute Percentage Error), the success status, and details of any bugs. In utilizing the tool, you only need to pass the entire function, including the function header, to the tool. For the data_analyzer tool, it is code interpreter that can run your data exploration snippet. You can access the data as shown in the example. However, you are forbidden from using any libraries like Matplotlib for plotting figures for analysis. python import json import sys # load the data input_data_str = sys.stdin.read() data_list = json.loads(input_data_str) # print the first 5 entries # In each entry of data_list, the first value is the output to predict, and the rest are the inputs. print(data_list[:5]) \"\"\" Figure 13 System prompt for the agent. SR-Scientist: Scientific Equation Discovery With Agentic AI Find the mathematical function skeleton that represents Acceleration in Nonl-linear Harmonic Oscillator, given data on Position at time t, Time, and Velocity at time t. Follow these steps to solve the problem: **1. Implement the Equation in Code** * Based on your knowledge and analysis, identify the standard equation and implement it in the code. * Your equation will likely have one or more constants. Use elements from the params list (e.g., params[0], params[1], params[2]) to represent these constants, as the equation_evaluator tool is designed to optimize them. Note that the params list has fixed size of 10 (MAX_NPARAMS = 10), so you can use up to 10 parameters in your model. **2. Test, Analyze, and Refine** * Evaluate the equations goodness of fit using the equation_evaluator tool. You need to pass the entire function, including the function header, to the tool. Here is an example: python def equation(x: np.ndarray, t: np.ndarray, v: np.ndarray, params: np.ndarray) -> np.ndarray: \"\"\" Mathematical function for Acceleration in Nonl-linear Harmonic Oscillator Args: x: numpy array representing observations of Position at time t. t: numpy array representing observations of Time. v: numpy array representing observations of Velocity at time t. params: Array of numeric constants or parameters to be optimized Return: numpy array representing Acceleration in Nonl-linear Harmonic Oscillator as the result of applying the mathematical function to the inputs. \"\"\" output = params[0] * + params[1] * + params[2] * + params[3] return output You can modify the function body, but the function header must remain unchanged. * Your goal is to reduce the mean absolute percentage error to less than 0.1000%. Meeting this condition indicates that your equation is good fit for the data. * If this goal is not met, refine your equation in Python and observe its performance. You can write your own data exploration snippet and use the data_analyzer tool to execute it, allowing you to inspect the data for potential relationships or anomalies. **3. Submit Your Final Answer** * Once you are confident your equation has met the condition, or if you conclude after numerous attempts that you cannot meet it, provide the completed Python function as your answer. \"\"\" Figure 14 User prompt for the agent. Given the ground truth mathematical expression and the hypothesis B, determine if there exist any constant parameter values that would make the hypothesis equivalent to the given ground truth expression. Lets think step by step. Explain your reasoning and then provide the final answer as: {{ \"reasoning\": \"Step-by-step analysis\", \"answer\": \"Yes/No\" }} Ground Truth A: {gt_equation} Hypothesis B: {pred_equation} Figure 15 Prompt for symbolic assessment. You are an expert code analyst. Your task is to classify Python code snippets written by an AI agent that is trying to discover scientific equations from data. Analyze the primary purpose of the code snippet and assign it category based on the definitions below. Category Definitions: - Data Statistics: The code calculates statistical property of the data. Examples include calculating the mean, variance, correlation, minimum, or maximum values. - IMPORTANT: For this category, you MUST respond in the format: Data Statistics: [STATISTIC_NAME]. For example: Data Statistics: Correlation or Data Statistics: Mean. - Data Print: The code prints raw data samples for the purpose of initial inspection and understanding. common example is printing the first few rows. - Residual Error Analysis: The code evaluates proposed mathematical equation by calculating the residuals (the difference between predicted and actual values) or other error metrics to determine its goodness of fit to the data. If the codes purpose does not fit any of the categories listed above, create new, concise, and specific category name. For all categories except Data Statistics, respond with ONLY the category name. Classify the following Python code snippet. Code Snippet: --- {code} --- Figure 16 Prompt for tool call analysis."
        }
    ],
    "affiliations": [
        "GAIR",
        "SII",
        "Shanghai Jiao Tong University"
    ]
}