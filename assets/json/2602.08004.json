{
    "paper_title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
    "authors": [
        "George Ling",
        "Shanshan Zhong",
        "Richard Huang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct a large-scale, data-driven analysis of 40,285 publicly listed skills from a major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for a substantial share of adoption. Beyond content trends, we uncover a pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite a heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide a quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design."
        },
        {
            "title": "Start",
            "content": "Agent Skills: Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality George Ling1, Shanshan Zhong2, Richard Huang1 1Bosch Research, 2Carnegie Mellon University 6 2 0 2 8 ] . [ 1 4 0 0 8 0 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct largescale, data-driven analysis of 40,285 publicly listed skills from major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for substantial share of adoption. Beyond content trends, we uncover pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design."
        },
        {
            "title": "Introduction",
            "content": "Large language model (LLM) agents have emerged as powerful paradigm for addressing complex, multi-step tasks that require reasoning, tool use, and interaction with external environments (Yao et al., 2022; Wang et al., 2024). Rather than relying on single prompt-response interaction, agents operate over extended horizons: they interpret user goals, decompose them into sub-tasks, and coordinate actions across diverse tools, data sources, and intermediate states (Shinn et al., 2023; Wang 1 Figure 1: Growth trend of agent skills. According to the well-known agent skills platform skills.sh, the number of recorded skills experienced rapid growth from mid-January to early February 2026, exceeding 40,000 by early February. During the same period, the popular open-source skills application OpenClaw (openclaw Community, 2026) saw sharp surge in GitHub stars, reaching over 25,000 stars in single day at the end of January, followed by gradual decline, with the total number of stars exceeding 170k. et al., 2023; Sapkota et al., 2025). This agentic execution model has enabled growing range of applications, from software development and data analysis to personal assistance and workflow automation (Wang et al., 2024). As agent-based systems scale in both complexity and deployment, new challenges arise around reliability, reuse, and maintainability (Liu et al., 2026a; Cemri et al., 2025; Raheem and Hossain, 2025). Many agent behaviors recur across tasks and users, yet are repeatedly re-specified through prompts or handcrafted control logic (Jin et al., 2026; Liu et al., 2025). This has motivated the emergence of agent skills (openclaw Community, 2026; Anthropic, 2025). The ecosystem around these skills has expanded rapidly in recent months, as reflected in Figure 1. This growth motivates closer look at what skills exist, how they are adopted, and what risks they may introduce. What are agent skills? Agent skills have recently emerged as an abstraction for structuring reusable and scalable agent behaviors (Anthropic, 2025; Wu and Zhang, 2026; Lee, 2025). The concept has been systematized and popularized by Anthropic in the context of the Claude agent framework (Anthropic, 2025), where skills are sometimes referred to as Claude Skills or Claude agent skills. An agent skill can be defined as reusable, plug-and-play module that specifies when the skill should be invoked and how the corresponding subtask should be carried out, typically in form that can be shared, versioned, and composed. In practical implementations, skill often combines lightweight metadata that supports discovery and selection with executable instructions and supporting resources such as files, scripts, and tool configurations (Anthropic, 2025). Appendix provides concrete example of skill structure. Why do agents need skills? Agent-based systems often revisit similar subtasks, such as data retrieval, information extraction, code modification, etc. Without explicit abstractions, these recurring behaviors must be specified repeatedly, either through prompts or through ad hoc control logic. This repetition increases prompt overhead, makes behavior brittle under small context changes, and complicates maintenance of shared procedures (Jin et al., 2026). Agent skills address these issues by packaging reusable behaviors into modular units that capture task knowledge, procedural logic, and tool use patterns. Because skills can be reused and composed, they improve behavioral consistency and reduce prompt complexity, making agent capabilities easier to extend and control. Shared skill libraries also support standardization and continuous refinement across applications. How are agent skills used in practice? In real systems, skills are typically organized as selfcontained modules that an agent can select and execute during task solving. common pattern is to load eligible skills into the system prompt as compact list of metadata with names and descriptions; the agent then selects skill based on the user request and follows the skill-defined instructions, issuing tool calls as needed. Appendix provides concrete example (Figure 11) that illustrates how an agent uses different skills to solve user questions. Taken together, these observations suggest that agent skills are growing quickly, but their functions and potential impacts vary widely. This makes it important to characterize what skills exist, how they are used, and what risks they may introduce. In this paper, we present large-scale, data-driven measurement of the emerging agent skills ecosystem. Using corpus collected from public skill platform, we analyze the following aspects: Growth trends in Section 2: we quantify publication over time and show rapid, bursty growth. Skill length and redundancy in Section 3: we measure prompt length and show heavy-tailed distribution, while most skills stay within typical prompt budgets. We also find that near-duplicate listings are common. Skill usage patterns in Section 4: we classify skills into taxonomy with 6 major categories and 20 sub-categories, and we show strong concentration in software engineering workflows. We further identify clear gaps between what is published and what users install. Safety risks in Section 5: we audit skills and find that most are low risk, while non-trivial share enables state-changing actions. Our results point to several open problems. First, the supplydemand gaps and high redundancy call for better skill discovery, de-duplication, and quality signals. Second, the presence of action-enabling skills motivates safety-aware design, including clearer permission models, stronger sandboxing, and more transparent risk labeling."
        },
        {
            "title": "2 Skill Data and Growth Trends",
            "content": "In this section, we introduce our skills dataset and summarizes how the agent-skill ecosystem has grown over time. We first describe how we collect skills and their metadata, and then report statistics that capture publication and adoption patterns."
        },
        {
            "title": "2.1 Data Collection",
            "content": "We construct our dataset by crawling agent skills listed on the public marketplace skills.sh. For each skill, we extract lightweight set of metadata describing the skill, its hosting location, the date when it first appeared on the marketplace, and how widely it has been installed. Specifically, each record includes the skill name, repository field that points to the hosted skill file, first_seen, which records the date when the skill was first uploaded to skills.sh, and installed_on, which reports per-platform installation counts across supported platforms. We store each skill as SKILL.md and JSONlike object with the following structure: \"name\": [SKILL NAME], \"repository\": [REPOSITORY LINK], \"first_seen\": [DD/MM/YY], { \"installed_on\": [ [NUMBER OF INSTALL]}, {\"platform\": \"claude-code\", \"installs\": (cid:44) {\"platform\": \"codex\", \"installs\": [NUMBER OF (cid:44) ... INSTALL]}, ] } We finalize data collection on February 5, 2026, yielding 40,285 skill metadata records. Unless otherwise stated, this snapshot underlies all analyses in Sections 2.25. All measurements are based solely on publicly accessible content; we avoid sensitive attributions about individual creators and report results only in aggregate."
        },
        {
            "title": "2.2 Skill Growth Trends",
            "content": "We study skill growth trends using the first_seen field in Section 2.1, which records when skill first appears on skills.sh. To capture parallel signal of community attention, we also track the popularity of OpenClaw (openclaw Community, 2026) by querying its GitHub star history via the GitHub GraphQL API (api.github.com/graphql). Figure 1 plots the cumulative number of listed skills and the cumulative number of OpenClaw stars. Growth is rapid and bursty. The marketplace grows from 2,179 skills on January 16, 2026 to 40,285 skills on February 5, 2026, net increase of 38,106 skills in 20 days. This corresponds to an 18.5 increase and an average multiplicative growth rate of about 15.7% per day. Despite mean inflow of 1,918 skills per day, arrivals are concentrated in short spikes. The largest spike occurs on January 25, 2026, when 8,857 skills are added in single day. This accounts for 23.2% of all new skills in the window. At the weekly level, the week centered on January 25 contributes 19,259 skills, or 47.8% of the full snapshot. Growth aligns with an application-level popularity signal. OpenClaw exhibits concurrent popularity shock. Daily new stars rise from the hundreds in mid-January to 10,543 on January 25, then peak at 25,432 on January 26, which is 2.4 the previous day. After the peak, daily gains decline into early February. For example, OpenClaw gains 1,718 new stars on February 5, which coincides with the slowdown in new listings. Taken together, the synchronized spikes suggest shared driver. wave of public attention likely encouraged both skill publication and exploration of skill-based tooling. While GitHub stars are an imperfect proxy for 3 Figure 2: Token-count distribution of agent skills. The distribution is heavy-tailed: the median skill contains 1,414 tokens (mean: 1,895). 90% of skills are no longer than 3,935 tokens and 99% are no longer than 9,253 tokens. small fraction are exceptionally long, with maximum of 116,239 tokens. real usage, their synchronized dynamics with marketplace listings provide evidence that rapid supply growth coincides with strong community interest."
        },
        {
            "title": "3 Skill Length and Redundancy",
            "content": "This section summarizes skill content and usage at scale. We first analyze skill length, and then report intent-level redundancy."
        },
        {
            "title": "3.1 Skill Length Characteristics",
            "content": "length by tokenizing each We measure skill SKILL.md and counting tokens. For every skill record in Section 2.1, we consistently use tiktoken (OpenAI, 2026) with the o200k_base encoding. This approach allows token counts to serve as straightforward proxy for prompt budget and inference cost. Typical skills are short. Figure 2 shows pronounced heavy-tailed distribution, but most skills are still compact. The median length is 1,414 tokens and the mean is 1,895 tokens, indicating that typical skill fits comfortably alongside planning context and tool schemas. Across quantiles, length is rarely binding constraint: 80% and 95% of skills are within 2,955 and 5,077 tokens, and 90% and 99% remain below 3,935 and 9,253 tokens. Meanwhile, the standard deviation of 2,025 tokens highlights substantial dispersion, even though the central mass is short. few skills are long due to the inclusion of multiple components. This dispersion is driven by small set of extreme outliers. The top 1% of skills exceed 9,253 tokens, and the maximum reaches 116,239 tokens, which can consume prompt budgets and hinder reliable selection and auditing when Figure 3: Name based redundancy distribution. Skills are grouped by normalized names using case insensitive matching after removing special characters. We report the fraction of skills that appear times, denoted as n. Skills that appear once account for 53.7%, while skills that appear more than once account for 46.3%. The names of the 30 most redundant skills under this metric are listed in Appendix Figure 4. loaded in full. Manual inspection suggests that many of these long skills consolidate multiple components into single file, including extended documentation, large code blocks, and reusable template collections. This pattern indicates that, while most skills support direct in-context use, minority behave like libraries and may benefit from modularization or retrieval-based loading so only the relevant portions are brought into context. 3. Intent-level Redundancy Analysis As the agent skills ecosystem grows, identical user intents are frequently published more than once, either by independent developers or through template-driven generation. Moderate repetition can be beneficial when it produces meaningfully improved variants, such as stronger safety checks, broader tool coverage, or clearer documentation. However, when most copies differ only in wording, marketplace volume rises without corresponding increase in capability diversity. We therefore quantify redundancy as the frequency with which the same intent is re-listed in the corpus. Redundancy measuring. We estimate redundancy with two signals. First, we apply namebased exact matching. We lowercase skill names, remove special characters, and group skills that share the same normalized name. Second, we apply semantic matching. We encode Name:[NAME] + Description:[DESCRIPTION] with BAAI/bge-m3 (Chen et al., 2024), and analyze nearest neighbor similarity together with t-SNE visualizations. In this marketplace, descriptions are often short, noisy, and template derived, so semanFigure 4: Top 30 redundant skills by name based matching. We rank skills by the number of listings that share the same normalized name, using the exact matching procedure in Section 3.2. This figure lists the 30 most frequently repeated skill names and their repetition counts. tically similar embeddings do not reliably separate true duplicates from loosely related skills. For this reason, we use strict name matching for the main results and report the embedding analysis in Appendix B. Nearly half of listings are duplicates. Figure 3 shows that unique entries only slightly outnumber repeated ones. Under strict exact matching, 53.7% of skills appear once, while 46.3% share normalized name with at least one other listing. Duplication is also concentrated. Pairs are common, with 2 groups contributing 18.7% of the corpus. Higher multiplicities still account for nontrivial share: 5 to 9 groups contribute 14.3%, and 10 to 49 groups contribute 8.8%. small number of names appear more than 100 times, which is consistent with repeated reposting or automated publication from shared templates. For concreteness, we provide the 30 most redundant skill names in Figure 4. Implications for discovery and maintenance. High redundancy increases user search costs and fragments feedback and adoption signals across near identical listings, which makes it harder for high quality implementations to become clear defaults. It also indicates that developer effort is often spent re-packaging common workflows rather than"
        },
        {
            "title": "Major Category",
            "content": "Sub-Category # Skills % of Total Avg Tokens Avg Downloads"
        },
        {
            "title": "Software Engineering Code Generation",
            "content": "Debug & Analysis Version Control Infrastructure"
        },
        {
            "title": "Productivity Tools",
            "content": "Data & Analytics"
        },
        {
            "title": "Content Creation",
            "content": "Utilities & Other"
        },
        {
            "title": "Team Communication\nDocument Systems\nTask Management",
            "content": "Data Processing Math & Calculation Data Visualization Image Generation Text Generation Audio & Video Local File Control Command Execution Memory & Cognition Other Utilities 5,743 5,319 1,275 9,664 567 1,083 277 698 1,579 2, 3,179 368 736 1,201 2,212 1,466 255 337 929 1,125 14.3% 13.2% 3.2% 24.0% 1.4% 2.7% 0.7% 1.7% 3.9% 5.6% 7.9% 0.9% 1.8% 3.0% 5.5% 3.6% 0.6% 0.8% 2.3% 2.8% 2004 1772 1403 1995 1517 2100 1514 1458 1981 2134 2028 2322 2145 1977 1744 1420 1541 1475 1684 235 103 71 114 1268 73 48 196 125 93 147 108 214 178 266 42 70 54 135 Table 1: Functional taxonomy and category-level statistics of agent skills. Skills are organized into 6 major categories and 20 sub-categories. For each sub-category, we report its size (# skills and % of corpus), the average skill length in tokens, and the mean downloads/installs. expanding coverage into less served tasks. This motivates platform mechanisms that encourage reuse and differentiation, including clearer canonical skills, more explicit versioning, and modular templates that reduce incentives to publish superficial copies."
        },
        {
            "title": "4 Skill Usage Patterns",
            "content": "In this section, we study what skills do and what users actually install. We summarize skill functionality with taxonomy to support corpus-level comparison of skills publication with adoption."
        },
        {
            "title": "4.1 Taxonomy and Classification",
            "content": "We define two-level taxonomy with 6 major categories and 20 sub-categories  (Table 1)  . The taxonomy covers end-to-end agent workflows and separates common intents that differ in practice, such as Code Generation and Debug & Analysis. For each sub-category, we report the number of skills, the mean token length, and the mean downloads or installs. Figure 5 provides qualitative signals by showing category-wise word clouds from frequent words in full skill markdown documents. We retained words only if their frequency in the target category exceeded 1.5 times the average of the remaining five categories. Marketplace tags are sparse and inconsistent, so we label skills with Qwen2.5-32B-Instruct (Qwen et al., 2025). Given skills name and description, the model selects one sub-category and returns strict JSON record. Appendix lists the taxonomy definitions and the prompt template."
        },
        {
            "title": "4.2 Distribution of Supply and Demand",
            "content": "Data-centric skills are longer. Token length varies by function. Data Visualization and Data Processing are the longest sub-categories on average, at 2,322 and 2,134 tokens. These skills often include multi-step pipelines, configuration blocks, and reusable templates. By comparison, Version Control and Local File Control are shorter at 1,403 and 1,420 tokens and are typically more procedural. These differences matter for prompt budgeting and auditing, since small category can still impose large review burden if its skills are long. Software Engineering dominates listings. In Table 1, Software Engineering accounts for 54.7% 5 Figure 5: Word clouds of skill names by major category. For each major category in Section 4.2, we show the most frequent terms derived from the skill document. Words are retained only if their frequency in the target category exceeds 1.5 times the average of the remaining five categories. Font size is proportional to within-category frequency, highlighting common topics and recurring workflow motifs. nectors are reused widely. Content creation also shows high mean installs, with Audio & Video at 266 and Image Generation at 214. Code Generation remains among the most installed at 235. In contrast, utility-focused skills have lower mean installs, including Local File Control at 42 and Memory & Cognition at 54. This may reflect narrower use cases, higher perceived risk, or overlap with builtin agent capabilities. We analyze this publication adoption gap further in Section 4. Overall, the taxonomy provides compact map of the ecosystem. It distinguishes what developers build from what users reuse and clarifies how content complexity varies across functions."
        },
        {
            "title": "4.3 Supplyâ€“Demand Dynamics",
            "content": "Ecosystem growth alone does not show whether developers publish the capabilities that users adopt most. We therefore compare supply and demand across functional categories. Following Section 3.2, we de-duplicate skills to reduce the impact of nearidentical reposts and template variants. We define supply as the number of de-duplicated skills in category, and define demand as the average installs per skill and use it as coarse proxy for adoption. Broad alignment with systematic deviations. Figure 6 summarizes the results. In most categories, supply and demand move in the same direction, suggesting that publication broadly tracks user inFigure 6: Supplydemand dynamics by major category. Supply denotes the number of de-duplicated skills after redundancy filtering (Section 3.2). Demand denotes the average installs per skill and is used as coarse proxy for adoption. Most categories are close to balanced, while content creation is demand-heavy, software engineering is supply-heavy, and information retrieval is demand-heavy despite limited supply. of the corpus across Code Generation, Debug & Analysis, etc. Infrastructure is the largest subcategory with 9,664 skills, or 24.0% of all listings. This suggests that developers often publish skills for environment setup, DevOps automation, tool configuration, and deployment. Adoption concentrates on few general skills. Adoption follows different pattern from publication. Web Search has the highest mean downloads at 1,268, but it represents only 1.4% of listings. This indicates that small number of retrieval conFigure 7: Supplydemand dynamics by sub-category. Supply denotes the number of de-duplicated skills in each of the 20 sub-categories, and demand denotes the average installs per skill. The figure highlights where publication volume and adoption diverge at finer granularity than Figure 6. terest. However, we observe three consistent gaps. First, content creation is demand-heavy. Users repeatedly reuse writing and media workflows, even when the number of listings is modest. Second, software engineering is supply-heavy. Skills that wrap coding, testing, and repository routines are easy to produce and share, which increases overlap and spreads installs across close substitutes. Third, information retrieval (Zheng et al., 2025; Wu et al., 2025) is demand-heavy despite limited supply. small number of reliable retrieval skills can attract many installs because web and database access is useful for everyday tasks. However, publishing these skills is costly because it requires stable connectors, careful query design, and ongoing maintenance as external interfaces and rate limits change. Figure 7 further provides the same comparison for all 20 sub-categories. Together, these results highlight where canonical implementations, stronger tool integration, and maintenance incentives may reduce supply-demand mismatches."
        },
        {
            "title": "5 Risk and Safety Assessment",
            "content": "Skills are executable procedures that interact with external services, local environments, and user context. Relative to prompt-only interactions, they expand the harm surface because skill may access sensitive data or trigger real-world side effects (Wu and Zhang, 2026; Schmotz et al., 2025; Liu et al., 2026b). We therefore quantify how often published skills enable privacy-sensitive reads, state-changing actions, or critical capabilities such Figure 8: Risk level distribution overall and by major category, where L0 is the lowest risk and L3 is the highest, audited with Qwen2.5-32B-Instruct using Appendix E. as arbitrary command execution. LLM-based auditing protocol. We audit each skill with Qwen2.5-32B-Instruct using the rubric in Appendix E. The model receives the skill name, description, and full SKILL.md content, and assigns exactly one risk level from L0 to L3 under worst-case interpretation, where L0 is safe, L1 is privacy risk, L2 is moderate risk, and L3 is critical risk. To support automatic aggregation, we require strict JSON response: {\"skill_name\": \"{{SKILL_NAME}}\", \"risk_level\": \"L0\" \"L1\" \"L2\" \"L3\", \"reasoning\": \"A (cid:44) concise sentence explaining the specific risk factor.\"} (cid:44) (cid:44) We report results by the six major categories from Section 4.2. For finer breakdown across all 20 sub-categories, see Appendix Figure 13. Overall distribution. Figure 8 shows that lowrisk skills dominate, but action-enabling skills are widespread. Overall, 54% are L0, 5% are L1, 30% are L2, and 9% are L3. Thus, nearly two fifths of the marketplace can access sensitive context or perform writes and actions, and nontrivial share exposes critical capabilities. Category-level patterns. Risk concentrates in categories that connect the model to external systems. Content Creation is the safest category, with 75% L0 and only small L3 share, which matches workflows whose outputs are mainly drafts or media artifacts. Information Retrieval is largely read oriented, with 68% L0 and the largest L1 share at 11%, often because connectors rely on user-specific tokens or private sources. Productivity Tools is dominated by L2 at 46%, reflecting common actions such as creating, editing, and sending emails, messages, calendar entries, and documents. Software Engineering has the highest L3 fraction at 7 Second, the heavy tailed length distribution of skills tokens means small fraction of skills can dominate prompt budgets. Future systems should support selective loading and modularization, retrieving only the steps, parameters, and tool schemas needed for the current subgoal. Summarization, pruning unused branches, and instruction compression can further reduce overhead while preserving faithful execution. Third, our observed supply-demand gaps in Agent Skills indicate that publication effort does not always track user adoption. In particular, information retrieval attracts high usage but remains costly to build and maintain, while many software engineering skills compete as close substitutes. Future Skills platforms can use demand signals to guide authoring tools, incentives, and review effort, and can support demand driven synthesis that adapts existing skills to new connectors, domains, and user constraints. Finally, the presence of high-risk skills calls for the establishment of proactive security protocols. Current frameworks lack fine-grained control over state-changing actions. Future research should implement standardized sandboxing environments that enforce the principle of least privilege. Such protocols would allow agents to perform complex tasks while protecting the host system from unauthorized or malicious operations."
        },
        {
            "title": "7 Conclusion",
            "content": "In this paper, we conducted large-scale, datadriven measurement of the agent skills ecosystem, analyzing over 40,000 publicly listed skills. Across production, adoption, redundancy, and safety auditing, our results provide quantitative snapshot of skills as an emerging abstraction for extending large language model agents. Overall, the ecosystem is expanding quickly but unevenly: supply is dominated by software engineering skills, intentlevel redundancy is pervasive, and adoption concentrates on smaller set of high-demand capabilities, notably information retrieval and content creation. From safety perspective, although most skills appear low risk, non-trivial subset enables state-changing or system-level actions, underscoring the need for safety-aware skill design and review. Taken together, these findings position agent skills as measurable infrastructure layer for agent systems and motivate future work on standardization, reuse, and governance. Figure 9: Risk level wordcloud. L0 lists safe design words like \"visual\" and \"component.\" L1 focuses on private data with terms like \"meeting\" and \"history.\" L2 shows action words like \"git\" and \"merge.\" L3 highlights critical system and security terms such as \"sudo,\" \"admin,\" and \"password.\" 14%, consistent with skills that manage environments, run commands, or manipulate repositories. Utilities & Other also shows elevated L1 at 10% and L3 at 11%, driven by local file operations and command execution utilities. Data & Analytics falls between these extremes, with 59% L0 and 23% L2, consistent with ETL-style pipelines that may write intermediate outputs. Figure 9 further presents detailed word cloud analysis across different risk levels from L0 to L3. Words are retained only if their frequency in the target level exceeds 1.5 times the average of the remaining three levels. Overall, the most severe cases are less about content generation and more about enabling external side effects. These results motivate least-privilege tool design and additional safeguards for high-risk operations."
        },
        {
            "title": "6 Potential Directions",
            "content": "In this paper, our measurements suggest that the agent skill ecosystem is at an inflection point. Progress now depends on improving quality, reducing overhead, and managing risk at scale. First, rapid growth of Agent Skills relies on community contribution, but long term value depends on high quality, non redundant skills. Given pervasive intent level duplication, future work should pair semantic de duplication with quality signals including documentation, execution reliability, maintenance, and usage. practical goal is convergence to small set of canonical skills per intent, so developers extend capabilities instead of re packaging the same workflows."
        },
        {
            "title": "Limitation",
            "content": "Our study has two main limitations. First, our measurements are derived from single snapshot of one public marketplace collected around early February 2026. As platform policies, ranking algorithms, and community composition evolve, both the supply and the demand for skills may change, and the bursty growth patterns we report may not persist. Second, we operationalize adoption using publicly visible signals rather than verified executions inside deployed agents. These signals can be affected by interface changes, caching, and social dynamics such as coordinated promotion, and they may under represent private usage that occurs through enterprise deployments or custom agent stacks."
        },
        {
            "title": "References",
            "content": "Anthropic. 2025. Agent skills overview. Mert Cemri, Melissa Pan, Shuyi Yang, Lakshya Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, and 1 others. 2025. Why do arXiv preprint multi-agent llm systems fail? arXiv:2503.13657. Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. arXiv preprint arXiv:2402.03216, 4(5). Haibo Jin, Kuang Peng, Ye Yu, Xiaopeng Yuan, and Haohan Wang. 2026. Agent primitives: Reusable latent building blocks for multi-agent systems. arXiv preprint arXiv:2602.03695. Han Lee. 2025. Claude agent skills: first principles deep dive. leehanchung.github.io/blogs/2025/ 10/26/claude-skills-deep-dive/. Daniel Liu, Krishna Upadhyay, Vinaik Chhetri, AB Siddique, and Umar Farooq. 2026a. large-scale study on the development and issues of multi-agent ai systems. arXiv preprint arXiv:2601.07136. Yi Liu, Weizhe Wang, Ruitao Feng, Yao Zhang, Guangquan Xu, Gelei Deng, Yuekang Li, and Leo Zhang. 2026b. Agent skills in the wild: An empirical study of security vulnerabilities at scale. arXiv preprint arXiv:2601.10338. Yimeng Liu, Misha Sra, Jeevana Priya Inala, and Chenglong Wang. 2025. Reuseit: Synthesizing reusable ai agent workflows for web automation. arXiv preprint arXiv:2510.14308. OpenAI. 2026. tiktoken. https://github.com/ openai/tiktoken. openclaw Community. 2026. openclaw. https:// github.com/openclaw/openclaw. Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, and 25 others. 2025. Qwen2.5 technical report. Preprint, arXiv:2412.15115. Tayiba Raheem and Gahangir Hossain. 2025. Agentic ai systems: Opportunities, challenges, and trustworthiness. In 2025 IEEE International Conference on Electro Information Technology (eIT), pages 618 624. IEEE. Ranjan Sapkota, Konstantinos Roumeliotis, and Manoj Karkee. 2025. Ai agents vs. agentic ai: conceptual taxonomy, applications and challenges. arXiv preprint arXiv:2505.10468. David Schmotz, Sahar Abdelnabi, and Maksym Andriushchenko. 2025. Agent skills enable new class of realistic and trivially simple prompt injections. arXiv preprint arXiv:2510.26328. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36:86348652. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, and 1 others. 2024. survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345. Yaxiong Wu and Yongyue Zhang. 2026. Agent skills from the perspective of procedural memory: survey. Authorea Preprints. Yujiang Wu, Shanshan Zhong, Yubin Kim, and Chenyan Xiong. 2025. What generative search engines like and how to optimize web content cooperatively. Preprint, arXiv:2510.11438. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations. Boyuan Zheng, Michael Fatemi, Xiaolong Jin, Zora Zhiruo Wang, Apurva Gandhi, Yueqi Song, Yu Gu, Jayanth Srinivasa, Gaowen Liu, Graham Neubig, and 1 others. 2025. Skillweaver: Web agents can self-improve by discovering and honing skills. arXiv preprint arXiv:2504.07079. 9 Figure 10: Internal structure of typical agent skill, illustrated using the find-best-product skill. The SKILL.md file begins with YAML metadata that specifies the skill name and description, which are used for skill discovery and selection. The subsequent Markdown sections define the procedural workflow and detailed execution instructions, including references to external tools such as product search APIs. This structure enables lightweight semantic matching at discovery time while supporting complex, tool-integrated execution when the skill is invoked."
        },
        {
            "title": "Agents",
            "content": "Skills provide modular and expressive mechanism for extending agent capabilities. By encapsulating triggering conditions, procedural logic, and tool interactions, skills enable agents to compose complex behaviors dynamically at runtime, while keeping the core agent architecture lightweight and unchanged. A.1 Skill Structure Skills act as first-class capability abstractions in an agent system, allowing agents to solve complex tasks through structured and reusable procedures. Unlike ad hoc prompts or isolated tool calls, each skill is defined as lightweight, program-like unit with explicit execution semantics. Formally, skill can be represented as: Skill = {Metadata, Instructions, Resources}, where metadata specifies the applicability conditions of the skill, instructions define the procedural steps to be executed, and resources link the skill to external tools, scripts, APIs, or auxiliary artifacts. In practice, each skill is organized within dedicated directory containing SKILL.md file that materializes this abstraction. As shown in Fig. 10, SKILL.md begins with YAML frontmatter that specifies the skill name and concise description. This metadata serves as compact semantic signal for skill discovery and selection. The remainder of the file is written in Markdown and encodes the Figure 11: Dynamic skill integration during agent execution. Given user request, the agent reasons over the injected skill index and selects the most relevant skill based on semantic matching. The full skill specification is then loaded, and the agent follows the skills instructions, potentially invoking external tools and producing intermediate outputs. Different user intents trigger different skills, enabling modular, reusable, and contextaware agent behavior through conditional skill selection and state-driven transitions. procedural logic of the skill, including high-level processing stages, decision criteria, and concrete instructions for tool invocation. This design separates lightweight skill discovery from full procedural execution. During agent initialization, only the metadata is exposed to the model, minimizing prompt overhead. Detailed instructions and associated resources are loaded only when skill is selected, enabling rich, tool-augmented behavior without inflating the agents baseline context. A.2 Skill Integration in Agents Beyond the definition of individual skills, agent intelligence critically depends on how multiple skills are dynamically coordinated during task execution. At the start of session, the agent is provided with summarized index of available skills, consisting of their names and descriptions. Given user request, the agent performs high-level reasoning to infer the underlying goal and decompose it into subgoals. Rather than following fixed execution pipeline, the agent conditionally selects skills based on the current subgoal and the evolving internal state. Once skill is invoked, the agent follows the skills procedural instructions, potentially interacting with external tools and producing structured intermediate outputs. These outputs are incorporated into the agents internal state and directly influence subsequent decisions. For instance, the execution operations."
        },
        {
            "title": "D Skill Classification Prompt",
            "content": "To label skill content at scale, we use an instructiontuned LLM to assign each skill to exactly one subcategory in our taxonomy. The prompt provides definitions for all 6 major categories and 20 subcategories, and it takes the skill name and description as input. We require the model to return strict JSON with both the chosen label and brief justification so that outputs can be parsed reliably and audited. Figure 14 shows the full prompt."
        },
        {
            "title": "E Skill Security Audit Prompt",
            "content": "To assess potential harms beyond content, we use LLM to label each skill by security risk. Figure 15 shows the full prompt used by LLM. The prompt asks the LLM to consider how skill interacts with data and tools, and to assign the highest applicable level under worst-case interpretation. We define four levels, from L0 for read-only public operations to L3 for high-impact actions such as destructive writes or arbitrary command execution. The model must output strict JSON so the labels can be parsed at scale and reviewed. The Examples of High-Risk (L3) Skills High-Risk (L3) skills are those that, if misused, prompt-injected, or misconfigured, may enable irreversible or high-impact actions. Typical cases include arbitrary command execution, handling of credentials and other secrets, escalation to privileged access, and operations that directly move or manage financial assets. To make these risks concrete, Table 2 summarizes representative examples across multiple major categories and provides concise rationales (see Section 5 for details) that follow worst-case reading of the skill instructions and tool interfaces. To protect the privacy of skill contributors, we omit skill names and redact identifiable keywords in black xxx. Moreover, we also highlight risk-related keywords in light yellow to help readers quickly locate the primary sources of risk in corresponding skill. of an analysis skill may introduce new constraints or observations, which in turn determine whether the agent invokes refinement skill, explores alternative strategies, or proceeds to synthesis step. As result, skill execution induces non-linear control flow in which transitions between skills are determined by intermediate state updates rather than pre-defined task graphs. Through iterative reasoning, skill selection, and execution, multiple skills collaboratively contribute to the completion of complex tasks. Fig. 11 illustrates this execution paradigm. The agent alternates between reasoning over the current state, selecting an appropriate skill from the available index, and executing the selected skill to update its state. Importantly, this coordination emerges from model-driven decision-making over skill abstractions, without relying on hard-coded orchestration rules or manually designed workflows."
        },
        {
            "title": "B Additional Analysis of Redundancy",
            "content": "This section provides two complementary views of redundancy that support the main analysis in Section 3.2. First, we report redundancy under exact name-based matching, which is conservative signal that is easy to interpret. Figure 4 shows that small set of generic names is repeatedly published. This pattern is consistent with template reuse and re-packaging of common workflows. Because name matching does not capture paraphrases, the true amount of redundancy is likely larger, which motivates our additional near-duplicate analysis in the main text. Second, we visualize skills in low-dimensional space to show how closely they cluster by functionality as shown in Figure 12. It provides complementary view based on semantic similarity. Skills form visible clusters within and across sub-categories, suggesting that many listings share overlapping intent even when their names differ."
        },
        {
            "title": "Assessment",
            "content": "This section complements the main results in Section 5 by reporting risk at the sub-category level. We use the same auditing protocol and the same four-level rubric, and we aggregate the predicted L0L3 labels within each of the 20 sub-categories shown in Figure 13. This view helps identify where risks concentrate and which types of skills most often enable state-changing actions or higher-impact 11 Figure 12: t-SNE view of skill embeddings by sub-category. Each point is skill represented by an embedding of its name and description. Points are colored by the predicted sub-category. Tight clusters suggest many skills with overlapping intent. Figure 13: Risk distribution by sub-category. Risk level distribution across the 20 sub-categories in our taxonomy, using the same auditing protocol as Figure 8. The figure shows how L0L3 risks vary across sub-categories and identifies the sub-categories that contribute the largest shares of L2 and L3 skills, which helps prioritize safeguards and review. 12 Prompt for skill classification (Qwen2.5-32B-Instruct). Role You are an expert AI Agent Skill Classifier. Your task is to categorize given agent skill into specific taxonomy based on (cid:44) its name and description. Taxonomy You must classify the skill into one of the following 6 Major Categories and their corresponding Sub Categories. Read the (cid:44) definitions carefully. scores. documents. databases. completion. pipelines, or server deployment. 1. Software Engineering 1.1 Code Generation: Skills related to writing source code, generating unit tests, code translation, refactoring, or code (cid:44) 1.2 Debug & Analysis: Skills for finding bugs, static analysis, code explanation, security auditing, or linting. 1.3 Version Control: Skills involving Git, GitHub, GitLab, managing pull requests, commits, or branching. 1.4 Infrastructure: Skills related to DevOps, Python environment, cloud services (AWS/Azure), Docker, Kubernetes, CI/CD (cid:44) 2. Information Retrieval 2.1 Web Search: General purpose internet search engines (Google/Bing) for current events, general knowledge, or news. 2.2 Academic Search: Searching specific knowledge bases, encyclopedias (Wikipedia), academic papers (ArXiv), or legal (cid:44) 2.3 Live Data Streams: Fetching real time dynamic data such as stock prices, weather forecasts, traffic status, or sports (cid:44) 3. Productivity Tools 3.1 Team Communication: Tools for messaging (Slack/Discord), emails, calendar scheduling, or meeting management. 3.2 Document Systems: Interactions with documentation tools (Notion/Google Docs), wiki systems, or reading/parsing PDF (cid:44) 3.3 Task Management: Skills for project planning tools (Jira/Trello), to do lists, or issue tracking. 4. Data & Analytics 4.1 Data Processing: ETL tasks, data cleaning, format conversion (JSON to CSV), sorting, filtering, or database querying (cid:44) 4.2 Math & Calculation: Performing mathematical operations, using calculators, symbolic math, or complex physics/logic (cid:44) 4.3 Data Visualization: Generating charts, graphs, plots, or visual reports from data sets. 5. Content Creation 5.1 Image Generation: Creating images from text, editing photos, style transfer, or object removal. 5.2 Text Generation: Creative writing, storytelling, translation between languages, poetry, or marketing copy. 5.3 Audio & Video: Text to Speech, Speech to Text, video editing, music generation, or video analysis. 6. Utilities & Other 6.1 Local File Control: Operations on the local file system such as reading, writing, moving, or deleting files and folders. 6.2 Command Execution: Running shell commands, terminal operations, or monitoring system resources (CPU/RAM). 6.3 Memory & Cognition: Managing conversation history, summarizing long contexts for memory, or storing user preferences. 6.4 Other Utilities: Miscellaneous tools that do not fit elsewhere, such as random number generation, UUID creation, or (cid:44) specific API wrappers. formulas. (SQL). Constraints Analyze the Skill Name and Skill Description deeply. Select exactly ONE Sub Category that best fits the skill. Output the result in strict JSON format. Do not output any conversational text. Input Format Skill Name: [Name] Skill Description: [Description] Output Format \"major_category_id\": \"Number\", \"major_category_name\": \"String\", \"sub_category_id\": \"Number.Number\", \"sub_category_name\": \"String\", \"reasoning\": \"Brief explanation in English\" Task Input: Skill Name: SKILL_NAME Skill Description: SKILL_DESCRIPTION Output: Figure 14: Prompt for skill classification (Qwen2.5-32B-Instruct). 13 Prompt for skill security auditing. Role You are an expert AI Security Auditor specializing in Large Language Model (LLM) tool safety and risk assessment. Your (cid:44) (cid:44) objective is to identify potential security vulnerabilities in \"agent skills\" (tools/functions) and categorize them based on their potential impact if misused, hallucinated, or hijacked. Risk Classification Framework (Levels) Classify each skill into exactly one of the following four levels: L0: Safe (Information/Public) Definition: Read-only operations on public or non-sensitive data. Impact: No side effects, no privacy leakage. Examples: get_weather, search_wikipedia, convert_currency, coding style guides, documentation helpers. L1: Privacy Risk (Read Sensitive) Definition: Read-only operations that access User Data, PII (Personally Identifiable Information), or private context. Impact: Potential for information leakage (Privacy Violation), but no state change. Examples: read_emails, get_calendar_events, query_user_profile, read local files. L2: Moderate Risk (Restricted Write/Action) Definition: Operations that change system state (Write/Edit/Send) but have limited scope or are generally reversible. Impact: Can cause annoyance, spam, or minor data clutter, but does not destroy assets or critical data. Examples: send_draft_email, add_calendar_event, set_alarm, create_todo_item, write to specific files. L3: Critical Risk (High Impact/Destructive) changes, or arbitrary code/command execution. Definition: Operations involving financial assets, irreversible data destruction, system-level configuration, authentication (cid:44) Impact: Financial loss, permanent data loss, account takeover, or remote code execution (RCE). Examples: transfer_money, delete_database_table, execute_shell_command, run_python_code, change_password, send_mass_email, (cid:44) database admin, arbitrary file operations. Analysis Steps Analyze Functionality: Does it Read data or Write data? Does it execute code/commands? Analyze Sensitivity: Is the data Public or Private? Does it involve system access? Analyze Code Patterns: Look for dangerous patterns like exec(), eval(), subprocess, os.system(), shell commands, SQL queries, (cid:44) Determine Level: Assign the highest applicable risk level based on the worst possible outcome. Adopt \"Worst Case Scenario\" (cid:44) file deletion, API keys, authentication tokens. mindset. Skill Document to Analyze Skill Name: SKILL_NAME Skill Description: SKILL_DESCRIPTION Full Skill Document (Markdown): SKILL_MARKDOWN_CONTENT Task Based on the skill document above, analyze this Agent Skill and classify its security risk level. Focus on: - What operations (cid:44) (cid:44) does this skill enable? - Does it execute arbitrary code or shell commands? - Does it access sensitive data or files? - What is the worst-case scenario if this skill is misused? Output Format Return ONLY valid JSON object. Do not output markdown code blocks or conversational text. The format must be: \"skill_name\": \"SKILL_NAME\", \"risk_level\": \"L0\" \"L1\" \"L2\" \"L3\", \"reasoning\": \"A concise sentence explaining the specific risk (cid:44) factor.\" (cid:44) Figure 15: Prompt for skill security auditing (Qwen2.5-32B-Instruct). 14 Table 2: Examples of High-Risk (L3) Agent Skills with Sensitive Information Handling. To protect the privacy of skill contributors, we do not display skill names and redact identifiable keywords in black xxx. In addition, we highlight specific risk-related keywords in light yellow. Category Reasoning Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Software Engineering Information Retrieval This skill involves handling and managing sensitive information such as API keys, database passwords, and TLS certificates, which can lead to critical risks including unauthorized access and data breaches if misused. The skill involves executing shell commands, handling sensitive credentials such as xxxxx ID credentials and Sparkle private keys, and performing actions that could lead to unauthorized distribution or modification of macOS applications. This skill enables critical operations such as gaining root/administrator access, extracting credentials, and performing destructive actions like creating persistent access mechanisms and compromising domains, leading to severe security breaches. This skill involves generating and deploying SSH keys, which can grant unauthorized access to remote servers if misused, leading to potential system compromise and data breaches. This skill enables critical operations such as gaining root/administrator access, extracting credentials, and performing actions that can lead to permanent data loss or system compromise. The skill involves creating and validating payment configurations which can lead to financial loss if misconfigured or misused. This skill involves financial transactions and can lead to financial loss if misused, such as unauthorized transfers or refunds. The skill manages secrets, cryptographic keys, and certificates, which can lead to critical risks such as unauthorized access to sensitive data and potential for account takeover if misused. This skill enables comprehensive exploitation leading to root-level control, which can result in full system compromise, including data theft, modification, and permanent damage. The skill includes operations that can perform backups, manage users, execute shell commands, and encrypt/decrypt files, which can lead to data loss, unauthorized access, or system compromise if misused. This skill handles and automates sensitive actions such as logging in with credentials and filling payment information, which involves high-risk operations like credential handling and financial transactions. Information Retrieval The skill can perform destructive actions such as DELETE requests and potentially execute arbitrary code via POST requests, leading to data loss or unauthorized access. Information Retrieval The skill involves financial transactions and handling of sensitive payment information, which could lead to financial loss if misused. Information Retrieval The skill involves managing reservations, upgrading flights, and accessing personal travel information, which could lead to financial loss or unauthorized transactions if misused. Information Retrieval The skill involves handling financial assets through wallet connectivity and executing transactions, posing high risk of financial loss if misused. Continued on next page... 15 Category Reasoning Continued from previous page Information Retrieval Information Retrieval Information Retrieval This skill involves financial transactions and access token management, which can lead to financial loss or unauthorized access if misused. The skill allows execution of arbitrary code via the /chunk endpoint, which can lead to RCE and other high-impact risks. The skill involves financial trading activities and can execute authenticated actions that may lead to financial loss or unauthorized transactions. Information Retrieval The skill involves handling financial assets through xxxxx balances and trade history, which can lead to financial loss if misused. Information Retrieval The skill enables financial transactions such as buying xxxxx, which can lead to financial loss if misused. Productivity Tools Productivity Tools The skill enables wide range of actions including sending emails, creating issues, posting messages, and updating databases, which can lead to financial loss, data leakage, or unauthorized access if misused. The skill involves financial transactions and management of sensitive employee data, including payroll processing and benefits administration, which could lead to financial loss or data breaches if misused. Productivity Tools The skill allows for critical operations such as user deletion, password reset, and device wiping, which can lead to permanent data loss and account compromise. Productivity Tools The skill enables in-app payments and xxxxx blockchain transactions, which can lead to financial loss if misused. Productivity Tools Productivity Tools Productivity Tools The skill involves storing and using webhook URLs containing authentication tokens, which could lead to unauthorized access and triggering of sensitive workflows if misused. The skill enables wide range of actions including sending emails, creating issues, posting messages, and updating databases, which can lead to financial loss, data leakage, or unauthorized access if misused. The skill includes examples of executing shell commands and performing actions that can lead to system-level changes, such as database failover and DNS updates, which pose high risk of causing significant damage if misused. Productivity Tools The skill involves managing payroll, employee data, and IT provisioning, which can lead to financial loss, data breaches, and system compromise if misused. Productivity Tools The skill includes operations that can modify or delete records in xxxxxx, which could lead to irreversible data loss if misused. Productivity Tools The skill includes operations that can lead to irreversible data loss, such as deleting project, which results in the loss of all issues within it. Data Analytics Data Analytics & & The skill enables operations that can lead to irreversible data destruction, such as delete operations, and involves managing database users and permissions, which can result in critical data loss or unauthorized access. The skill involves database administration tasks which can lead to irreversible data destruction, system-level configuration changes, and potentially allow for unauthorized access or manipulation of critical data. Continued on next page... 16 Category Reasoning Continued from previous page Data Analytics Data Analytics Data Analytics Data Analytics Data Analytics Data Analytics Data Analytics Data Analytics Content Creation Content Creation Content Creation Content Creation Content Creation Content Creation Content Creation Content Creation Content Creation & & & & & & & & This skill allows for the deletion of accounts, categories, category groups, payees, rules, and schedules, which can lead to permanent data loss and significant disruption of financial management. The skill involves creating data pipelines that can execute custom Python code and manage sensitive credentials, posing high risk of data leakage, unauthorized access, and potential for destructive actions. The skill enables operations that can modify, delete, or expose sensitive data within xxxxxxx databases, including executing shell commands and managing clusters, which can lead to data loss or unauthorized access. The skill enables database writes, deletions, and potentially destructive operations such as dropping tables or altering schemas, which can lead to permanent data loss or corruption. The skill allows for executing arbitrary SQL commands including destructive operations like DELETE and DROP, which can lead to irreversible data loss or corruption. The skill involves database administration tasks including setup replication, tuning VACUUM, ANALYZE, and autovacuum, which can lead to data corruption or loss if misused. The skill allows for full CRUD operations on the xxxxxx database, including DELETE which can lead to irreversible data loss. This skill involves managing real financial operations including transferring money and executing financial allocations, which can lead to significant financial loss if misused. The skill involves financial transactions and irreversible actions such as granting in-game currency and reviving players, which can lead to financial loss or abuse if misused. The skill involves financial transactions and potentially irreversible actions such as token creation, liquidity provisioning, and platform deployment on blockchain, which can lead to financial loss or asset manipulation. The skill allows publishing content and managing media, which can lead to unauthorized content publication and potential account takeover if misused. The skill involves API calls that could potentially execute arbitrary code or commands, leading to remote code execution or other high-impact risks if misused. The skill includes code execution capabilities through built-in Python interpreter and sandbox, which can lead to arbitrary code execution and potential system compromise. The skill includes code interpreter capability which can execute arbitrary code, posing high risk of remote code execution. The skill can execute arbitrary code via shell commands, posing high risk of remote code execution. The skill enables execution of arbitrary code and potentially destructive actions through the xxxxxxx command, which can lead to remote code execution or other high-impact outcomes. The skill includes code execution capabilities with built-in Python interpreter and sandbox, posing critical risk for potential arbitrary code execution. Continued on next page... 17 Category Reasoning Continued from previous page Content Creation Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other Utilities Other The skill allows publishing content and managing media, which can lead to unauthorized posting and potential data manipulation or loss. & & & & & & & & & & The skill provides low-level file operations and system calls, including file creation, deletion, modification, and permission changes, which can lead to critical data loss or corruption. The skill involves accessing and managing sensitive user credentials and performing actions such as storing, retrieving, and sharing passwords, which could lead to unauthorized access and data breaches if misused. This skill handles and stores API keys, which are sensitive credentials that could lead to unauthorized access if misused or leaked. This skill accesses and potentially manipulates sensitive user data stored in xxxxxxxx, including credentials and secrets, which poses high risk of data exposure and misuse if compromised. The skill allows for irreversible data destruction (e.g., delete operations) and system-level configuration changes (e.g., Admin SDK operations), posing high risk of permanent data loss and account management issues. The skill involves financial transactions such as deposits, withdrawals, and transfers, which can lead to financial loss if misused. This skill involves executing commands that can generate cryptographic keys and manage wallets, which poses high risk of financial loss and data exposure if misused. The skill provides commands for potentially destructive actions such as password brute-forcing and service scanning, which can lead to unauthorized access and system compromise. This skill permanently deletes an entity and all its data, which can lead to irreversible data loss. The skill allows for file editing, process interaction including running shell commands, and high-risk operations such as terminating processes, which can lead to data loss or system instability if misused."
        }
    ],
    "affiliations": [
        "Bosch Research",
        "Carnegie Mellon University"
    ]
}