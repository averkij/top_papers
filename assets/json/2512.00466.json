{
    "paper_title": "SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling",
    "authors": [
        "Yang Xiao",
        "Chunpu Xu",
        "Ruifeng Yuan",
        "Jiashuo Wang",
        "Wenjie Li",
        "Pengfei Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Test-time compute scaling has emerged as a powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning sub-problems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose \\textbf{SCALE} (Selective Resource Allocation), a framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33%-53%, representing a major advance in test-time scaling that addresses fundamental limitations of current approaches."
        },
        {
            "title": "Start",
            "content": "SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling Yang Xiao1 Chunpu Xu1 Ruifeng Yuan1 Jiashuo Wang1 Wenjie Li1* Pengfei Liu2,3* 1The Hong Kong Polytechnic University 2Shanghai Jiao Tong University 3SII yang-alan.xiao@connect.polyu.hk 5 2 0 2 9 ] . [ 1 6 6 4 0 0 . 2 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Test-time compute scaling has emerged as powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning subproblems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose SCALE (Selective Resource Allocation), framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33-53%, representing major advance in test-time scaling that addresses fundamental limitations of current approaches. Code https://github.com/XiaoYang66/DualThinking Data https://huggingface.co/datasets/YangXiaonlp/DualThinking Introduction Mathematical reasoning remains fundamental challenge for large language models, requiring sophisticated multistep reasoning across diverse cognitive demands. Inferencetime compute scaling has emerged as transformative paradigm that invests additional computational resources *Corresponding authors. Copyright 2026, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. during inference rather than relying exclusively on larger model parameters (Snell et al. 2024; Guo et al. 2025). Recent breakthroughs achieve this scaling by training models to generate extended reasoning traces during inference: supervised fine-tuning approaches like s1 and LIMO train models on long reasoning demonstrations to elicit extended inference-time reasoning, while reinforcement learning methods such as DeepSeek-R1s GRPO algorithm directly incentivize models to develop longer chain-ofthought reasoning patterns through reward-based optimization (Muennighoff et al. 2025; Ye et al. 2025; Guo et al. 2025). However, existing methods face fundamental limitation of overthinking in their resource allocation strategies (Chen et al. 2024; Chiang and Lee 2024). While recent adaptive approaches (Shen et al. 2025; Zhang et al. 2025; Yang, Lin, and Yu 2025) have made progress by dynamically adjusting reasoning depth based on global problem difficultyusing techniques such as Token Length Budget metrics and length-aware reward shapingthey still employ uniform resource allocation within individual problems, irrespective of sub-problem complexity. Consider mathematical problem containing both routine arithmetic operations and complex algebraic derivations: current methods allocate comparable computational 16 = 4) and inbudgets to elementary computations (e.g., tricate sub-problems requiring extensive reasoning tokens. Such uniform allocation creates critical inefficiencies where resources are systematically underutilized on routine operations while challenging solution-determining sub-problems receive insufficient computational attention, leading to performance bottlenecks where additional computational budget yields diminishing returns. The fundamental issue is that even within complex problems, individual reasoning subproblems can vary significantly in their cognitive demands, ranging from simple computations to advanced mathematical reasoning. As shown in Figure 1, we propose SCALE (Selective Resource Allocation), novel framework that overcomes traditional performance bottlenecks by implementing finegrained selective resource allocation based on the difficulty of individual reasoning sub-problems. It is motivated by dual-process theory from cognitive science, which distinguishes human cognitive strategies into System 1 (fast, auFigure 1: SCALE Framework Overview. SCALE operates through four stages: (1) Problem Decomposition - breaks the mathematical problem into sequential sub-problems; (2) Difficulty Assessment - computes difficulty scores for each sub-problem to distinguish between routine operations and computationally challenging sub-problems; (3) Adaptive Mode Selection - assigns sub-problems to either fast processing (System 1) or deliberate reasoning (System 2) based on difficulty threshold; (4) Sequential Execution - processes sub-problems with full context propagation. This selective resource allocation concentrates computation on challenging sub-problems while efficiently handling routine ones. tomatic, intuitive) and System 2 (slow, deliberate, effortful) (Kahneman 2011). For reasoning model, our approach operates through four sequential stages that mirror human cognitive processing strategies. (1) Problem Decomposition: the model decomposes the mathematical problem into sequence of discrete reasoning sub-problems with explicit logical dependencies. (2) Difficulty Assessment: it performs difficulty assessment for each sub-problem, distinguishing between routine operations and computationally challenging sub-problems. (3) Adaptive Mode Selection: leveraging existing models built-in dynamic thinking mode switching capabilities, it dynamically selects System 1 processing for straightforward sub-problems or System 2 processing for complex sub-problems demanding extensive reasoning resources. (4) Sequential Execution: it solves sub-problems sequentially while propagating contextual information, including previous solved sub-problems and corresponding intermediate results, to maintain coherent reasoning chains throughout the solution process. Extensive experiments across challenging mathematical reasoning benchmarks demonstrate that SCALE achieves substantial improvements over uniform inference-time scaling baselines. SCALE directly enhances the reasoning models performance by overcoming the bottlenecks inherent in uniform resource allocation, achieving accuracy improvements of up to 13.75 percentage points (from 57.50% to 71.25% on AIME25 with Qwen3-32B) while reducing token usage by 33-53% compared to baseline methods like InftyThink (Yan et al. 2025). Through supervised fine-tuning on SCALE-generated reasoning traces, non-reasoning models learn to adopt SCALEs inference-time scaling approach, significantly enhancing their reasoning capabilities with accuracy improvements of up to 38.93 percentage points (from 24.58% to 63.51% on AIME24 with Llama3.3-70BInstruct). Our contributions are threefold: (1) We identify the sub-problem-level resource allocation bottleneck in current inference-time scaling approaches, where uniform allocation prevents effective scaling. (2) We propose SCALE, cognitively-inspired framework that selectively allocates resources based on sub-problem difficulty, concentrating computation on solution-critical reasoning ones. (3) We demonstrate SCALEs versatility across both enhancing existing reasoning models and enabling non-reasoning models to acquire deep thinking capabilities, achieving substantial performance improvements in mathematical reasoning tasks. Method SCALE Framework Overview SCALE (Selective Resource Allocation) addresses the fundamental bottleneck of uniform resource allocation in current test-time scaling approaches by implementing selective resource distribution based on sub-problem difficulty. The framework operates through four sequential stages: (1) decomposing mathematical problems into logically ordered sub-problems, (2) evaluating difficulty by distinguishing routine operations from complex reasoning sub-problems, (3) dynamically assigning System 1 processing for simple sub-problems and System 2 processing for challenging ones based on difficulty thresholds, and (4) executing subproblems sequentially while maintaining complete contextual information to ensure coherent reasoning chains. Mathematical Formulation Let denote mathematical problem to be solved. SCALE processes through four sequential stages that work collaboratively to achieve optimal resource allocation. Problem Decomposition The decomposition stage transforms the original problem into sequence of logically ordered reasoning sub-problems that build systematically toward the final solution: D(P ) = {s1, s2, . . . , sn} (1) where si represents specific sub-problem with clearly defined objectives and logical dependencies on previous sub-problems. The decomposition ensures that each subproblem either builds upon previous results or can be executed independently while contributing meaningfully to the overall solution pathway. To ensure robustness, SCALE generates multiple alternative decompositions and selects the optimal one: = arg max Dj {D1,D2,...,Dk} Q(Dj, ) (2) where Dj represents different decomposition, and Q(Dj, ) evaluates the decomposition quality based on logical correctness, clarity, completeness, and relevance to achieving the final solution. In practice, we prompt the LLM to generate multiple alternative decompositions and prompt them to compare these candidates and select the decomposition that demonstrates the highest quality and effectiveness for the given problem. Difficulty Assessment For each sub-problem si in the selected decomposition, SCALE prompts the model to assess the complexity of the sub-problem: di = A(si, Ci) [0, 1] (3) where Ci represents the accumulated context including the original problem and all previously solved sub-problems {s1, s2, . . . , si1} with their solutions. The assessment considers computational complexity, mathematical sophistication required, reasoning depth needed, and solution uncertainty. Adaptive Mode Selection Modern large language models, including the Qwen3 series (Yang et al. 2025) and Claude family (Anthropic 2024), support switching between different thinking modes. SCALE utilizes this modeswitching capability by dynamically selecting the appropriate processing mode based on sub-problem difficulty. Based on difficulty assessment, SCALE assigns each subproblem to one of two LLM processing modes: mi = (cid:26)LLMsystem1 LLMsystem2 if di τ if di > τ (4) where mi represents the processing mode assigned to subproblem si, and τ represents the difficulty threshold that determines the boundary between routine (easy) and complex (hard) sub-problems. For models supporting dual processing modes (e.g., Qwen3), System 1 mode utilizes the models efficient processing capabilities for direct computation, while System 2 mode activates deliberate reasoning with chain-of-thought processing and comprehensive analysis. For reasoning-only models (e.g., QwQ (Qwen 2025)), we pair them with Qwen3s System 1 counterpart to ensure fair comparison. This threshold-based selection ensures that computational resources are allocated based on the subproblems actual complexity rather than assumptions about problem difficulty. Sequential Execution with Context Propagation sequentially while SCALE processes sub-problems maintaining coherent contextual information throughout the solution process. For each sub-problem si, the system constructs comprehensive context includes the original problem, all previous sub-problems with their corresponding solutions: that (cid:40) Ci = (cid:83)i j=2{sj, S(sj)} if = 1 if 2 (5) where S(sj) represents the solution or reasoning output generated for sub-problem sj. This ensures that each subproblem is solved with full awareness of both its specific requirements and the complete reasoning history."
        },
        {
            "title": "The solution process adapts to the assigned processing",
            "content": "mode: S(si) = mi(Ci, si) (6) Finally, SCALE extracts the final answer from the solution of the last sub-problem S(sn), ensuring that the complete reasoning chain culminates in coherent solution to the original problem . SCALE Process Formalization SCALEs complete process can be formalized as generating the final answer by integrating solutions from all subproblems through the four-stage pipeline. This process represents conditional probability that depends on the complete reasoning chain: P(AnswerP ) = (cid:89) i= (S(si)Ci, si) (7) where the final answer is conditioned on the original problem, the sequential pairs of sub-problems, and their solutions. The specific prompts utilized for each stage of the SCALE framework are provided in the appendix. Experimental Setup We evaluate SCALE through two complementary experimental settings designed to demonstrate its versatility and effectiveness. In the first setting, we examine SCALE as prompt-based framework that directly enhances the performance of existing reasoning models at inference time. In the second setting, we investigate SCALEs effectiveness in generating high-quality synthetic reasoning traces for improving non-reasoning models through supervised finetuning. This setting demonstrates SCALEs versatility as data generation tool for model training. Setting 1: Enhancing Reasoning Model Performance In this setting, we deploy SCALE as prompt framework to improve the test-time performance of state-of-the-art reasoning models without requiring any additional training. We evaluate SCALE on four advanced reasoning-capable models: Qwen3-32B (Yang et al. 2025), QwQ (Qwen 2025), DeepSeek-R1-Distill-Llama-70B, and DeepSeekR1-Distill-Qwen-32B (Guo et al. 2025). For brevity, we refer to the DeepSeek-R1 distilled variants as Distill-Llama70B and Distill-Qwen-32B, respectively, in our result tables. We compare SCALE against three baseline approaches: (1) The first is zero-shot chain-of-thought (Wei et al. 2022), denoted as CoT, which serves as the standard baseline using the prompt Please reason step by step, and put your final answer within boxed{}. (2) The second baseline is InftyThink (Yan et al. 2025), recent method that transforms monolithic reasoning into an iterative process with intermediate summarization. (3) The third baseline is MajorityVoting (Wang et al. 2023), which samples multiple reasoning chains from the base model using CoT prompting and selects the most frequent answer among the generated responses. This approach leverages the diversity of multiple reasoning paths to improve robustness and accuracy through ensemble voting. Setting 2: Enhancing Non-Reasoning Model Performance The second setting explores SCALEs effectiveness as framework for generating high-quality synthetic reasoning traces that can be used to enhance non-reasoning models through supervised fine-tuning. For our experimental setup, we utilize the problem set from the LIMOPro (Xiao et al. 2025) and apply our SCALE framework on QwQ to synthesize reasoning traces for these problems. To ensure data quality and consistency, we filter out instances where the final answers generated by SCALE differ from the original LIMOPro answers, resulting in curated dataset of 800 highquality question-response pairs with SCALE-generated reasoning traces. We then perform supervised fine-tuning on four base models: Qwen2.5-14B-Instruct, Qwen2.5-32BInstruct, Qwen2.5-72B-Instruct (Qwen et al. 2025), and Llama3.3-70B-Instruct (AI@Meta 2024), using the same training configurations as LIMOPro, including hyperparameters, optimization schedule, and fine-tuning procedures. We use -I to denote -Instruct for brevity in the table."
        },
        {
            "title": "Evaluation Benchmarks and Metrics",
            "content": "Both experimental settings are evaluated on three challenging mathematical reasoning datasets: (1) AIME 2024 (AIME24) (MAA. 2024), which contains problems from the 2024 American Invitational Mathematics Examination representing high-school competition-level mathematics; (2) AIME 2025 (AIME25) (MAA. 2025), featuring the most recent AIME problems to test the models ability to generalize to unseen mathematical challenges; and (3) AMC 2023 (AMC23) (MAA. 2023), comprising problems from the 2023 American Mathematics Competitions that cover broader range of mathematical topics. To comprehensively assess both effectiveness and efficiency, we employ three key metrics. Acc measures pass@1 accuracy as the percentage of problems solved correctly, obtained by sampling each model eight times. Since InftyThink involves multiple rounds of iterative reasoning while our approach generates different sub-problems, we introduce Tpi (tokens per iteration) as metric to fairly compare resource allocation granularity across different methods. Tpi calculates response tokens per iteration or sub-problems. Tok records total response tokens per problem, directly correlating with computational cost and inference time. For inference parameters, all models use temperature of 0.6 to balance creativity and consistency, with top-p set to 0.95 for nucleus sampling. Other settings follow the default configurations of their respective models. Enhancing Reasoning Model Performance We evaluate SCALEs effectiveness in enhancing reasoning model performance. Table 1 presents comprehensive results comparing SCALE against other baselines."
        },
        {
            "title": "Main Results",
            "content": "Table 1 presents the comprehensive evaluation of SCALE against baseline approaches across three challenging mathematical reasoning benchmarks. The results demonstrate that SCALEs selective resource allocation strategy effectively overcomes the performance bottlenecks inherent in uniform resource distribution methods. Overcoming Performance Bottlenecks. Compared to CoT baselines, SCALE achieves substantial improvements across all model-dataset combinations, with the most pronounced gains on AIME24 and AIME25. For Qwen3-32B, SCALE improves accuracy by 9.59 percentage points on AIME24 (from 73.33% to 82.92%) and 13.75 percentage points on AIME25 (from 57.50% to 71.25%). Similar patterns emerge across other models: QwQ shows improvements of 4.40 and 6.88 percentage points on AIME24 and AIME25, respectively. These results demonstrate that SCALE addresses the fundamental bottleneck where uniform distribution prevents effective scaling despite increasing computational resources. Superior Performance-Resource Trade-offs. When compared to InftyThink, SCALE demonstrates substantial performance improvements while achieving remarkable efficiency gains. SCALE consistently outperforms InftyThink on AIME25 across all models, with notable improvements of 10.42 and 7.50 percentage points for DeepSeek variants, and 4.68 percentage points for QwQ. On AIME24, SCALE shows strong gains with DeepSeek models (+5.83 and +1.67 percentage points) and QwQ (+2.15 percentage points). Against Majority Voting approaches, SCALE achieves competitive accuracy while using 2-3 fewer computational resources. This highlights SCALEs ability to match Majority Voting while avoiding the computational overhead that creates diminishing returns in uniform scaling approaches. Enhanced Resource Utilization Through Selective Allocation. key insight from our results is that SCALE achieves superior performance while demonstrating significantly improved resource utilization. Examining tokens per iteration (Tpi), SCALE consistently reduces the average computational cost per reasoning stepachieving 3,550 Tpi versus InftyThinks 5,900 Tpi on Qwen3-32B for AIME24, representing 40% reduction. This efficiency translates to total token usage (Tok) that is 33-53% lower than InftyThink across different model-dataset combinations while maintaining superior accuracy. For instance, on AIME25 with Qwen3-32B, SCALE uses only 26,643 total tokens compared to InftyThinks 36,640 tokens while achieving higher accuracy (71.25% vs 70.00%). Notably, the Majority Voting approaches consume substantially more resources (54,719-88,696 total tokens) yet fail to consistently outperform SCALE, highlighting the efficiency of selective allocation over brute-force ensemble methods. This enhanced resource utilization directly validates our core hypothesis: concentrating resources where they can maximize impact yields better returns than uniform allocation strategies that create performance bottlenecks. Model-Agnostic Bottleneck Resolution. The consistency of SCALEs improvements across diverse model architecturesfrom Qwen3-32B, QwQ, to Llama variantsdemonstrates that SCALE addresses fundamental bottlenecks in test-time scaling rather than exploiting modelspecific characteristics. Notably, SCALE achieves an average accuracy improvement of 3.41 percentage points over CoT baselines across all models and datasets, with the framework showing particular effectiveness on the more challenging AIME benchmarks where the bottlenecks of uniform resource allocation are most pronounced. These results establish SCALE as significant advancement in test-time scaling that can overcome the performance bottlenecks that limit uniform computational distribution approaches. Inference-Time Scaling Properties of SCALE To investigate SCALEs adherence to inference-time scaling laws and validate our selective resource allocation hypothesis, we systematically vary the Qwen3-32Bs maximum toFigure 2: Inference-time scaling of SCALE for Qwen3-32BSCALE across three benchmarks. ken limit for System 2 processing across different computational budgets ranging from 4,096 to 32,768 tokens. This experimental design allows us to examine how SCALEs performance scales with increased computational resources of System 2 while maintaining the token limit of System 1 processing for routine sub-problems. The result is demonstrated in Figure 2. Validation of Selective Resource Allocation. The dramatically different scaling curves between AMC23 and AIME benchmarks provide direct empirical validation of our core analysis about selective resource allocation. AIME24 and AIME25 exhibit steep, almost linear scaling trajectories, while AMC23 shows more gradual improvement curve that begins to plateau. This divergence directly reflects the underlying distribution of sub-problem difficulties: AIME benchmarks inherently contain higher proportion of difficult sub-problems, whereas AMC23 problems consist relatively more of routine computational subproblems. In our experiments, as we increase the maximum token limit, only sub-problems classified as hard receive additional computational resources, while simple subproblems maintain constant resource allocation. Therefore, when SCALE processes AIME problems, larger fraction of sub-problems are identified as challenging and benefit from the increased token budget, resulting in steep performance gains. This empirical evidence confirms that concentrating resources on difficult sub-problemsrather than distributing them uniformlyyields superior performance improvements. Adherence to Inference-Time Scaling Laws. Beyond the results validating our selective allocation approach, demonstrate that SCALE successfully preserves the fundamental scaling law principlethat increased computational resources during inference lead to improved performance. The monotonic improvement across all token budgets (from 4,096 to 32,768 tokens) confirms that SCALEs selective allocation does not disrupt the underlying scaling Model/Method Qwen3-32B-CoT Qwen3-32B-InftyThink Qwen3-32B-Majority-Voting Qwen3-32B-SCALE QwQ-CoT QwQ-InftyThink QwQ-Majority-Voting QwQ-SCALE Distill-Llama-70B-CoT Distill-Llama-70B-InftyThink Distill-Llama-70B-Majority-Voting Distill-Llama-70B-SCALE Distill-Qwen-32B-CoT Distill-Qwen-32B-InftyThink Distill-Qwen-32B-Majority-Voting Distill-Qwen-32B-SCALE AIME AIME25 AMC23 Avg. Acc (%) Acc (%) Tpi Tok Acc (%) Tpi Tok Acc (%) Tpi"
        },
        {
            "title": "Tok",
            "content": "73.33 83.75 76.67 82.92 75.00 77.25 76.67 79.40 70.00 69.58 76.67 71.25 72.50 67.50 80.00 73.33 7,409 7,409 5,900 38,451 59,279 3,550 25,581 / 9,957 9,957 8,722 62,557 79,663 4,157 29,812 / 8,159 8,159 5,921 42,143 65,277 4,313 30,696 / 7,909 7,909 5,244 37,062 63,276 4,270 30,175 / 57.50 70.00 53.33 71.25 63.33 65.53 63.33 70.21 61.37 54.58 56.67 62.08 58.75 48.75 60.00 59.17 6,839 6,839 6,538 36,640 54,719 3,709 26,643 / 11,087 11,087 10,114 73,473 88,696 4,673 33,965 / 8,218 8,218 5,362 38,763 63,830 4,913 35,517 / 8,699 8,699 4,915 35,187 69,595 4,140 29,641 / 96.88 98.12 97.50 98.44 96.88 97.19 97.50 96.25 95.31 93.75 95.00 96.88 95.00 92.81 95.00 95.63 5,789 5,789 3,723 23,117 46,315 1,991 12,556 / 6,161 6,161 5,449 34,725 49,291 2,551 16,259 / 4,825 4,825 3,844 24,327 38,605 2,566 16,238 / 4,994 4,994 3,711 23,332 39,953 2,672 16,804 / 75.90 83.96 75.83 84.20 78.40 79.99 79.17 81.95 75.56 72.64 76.11 76.74 75.42 69.69 78.33 76.04 Table 1: Performance comparison of SCALE against baseline methods on mathematical reasoning benchmarks. Acc: accuracy (%), Tpi: tokens per iteration, Tok: total tokens per problem."
        },
        {
            "title": "Threshold",
            "content": "AIME24 AIME"
        },
        {
            "title": "Tok Hard",
            "content": "78.75 77.50 73.33 74.58 70.00 50.00 46.25 27.50 22.5 19.2 19.5 20.3 17.8 12.2 11.4 8.2 75.61 56.66 55.66 55.68 47.69 17.68 14.08 0 63.75 61.67 51.67 56.25 58.75 39.17 35.83 25.00 23.2 20.6 20.5 21.0 19.0 11.7 10.6 6.8 75.78 57.53 57.93 58.53 50.97 19.60 13.95 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Table 2: Analysis on difficulty threshold values for Qwen332B-SCALE across AIME datasets. Acc: accuracy percentage, Tok: total tokens per problem in thousands, Hard: percentage of sub-problems classified as hard. dynamics but rather amplifies them. By concentrating additional resources precisely where they provide maximum benefit, SCALE achieves more efficient scaling compared to uniform allocation approaches. This is particularly evident in the near-linear scaling observed for AIME benchmarks, where each doubling of the token budget yields consistent accuracy improvements of approximately 10-15 percentage points, demonstrating that selective allocation creates more favorable scaling conditions for problems with heterogeneous cognitive demands. Difficulty Threshold Analysis To understand the impact of the difficulty threshold τ on SCALEs performance, we conduct comprehensive analysis using Qwen3-32B across different threshold values ranging from 0.2 to 0.9. The difficulty threshold determines the boundary for classifying sub-problems as easy (processed by System 1) or hard (processed by System 2), making it critical hyperparameter for optimal resource allocation. Table 2 presents the results. The results show clear trend: lower thresholds consistently achieve higher accuracy across both datasets. Optimal performance is achieved at τ = 0.2, reaching 78.75% on AIME24 and 63.75% on AIME25, with accuracy systematically decreasing as the threshold increases. At τ = 0.2, approximately 75% of sub-problems are classified as hard and processed through System 2, indicating that allocating more sub-problems to System 2 substantially benefits mathematical problem-solving, even at the cost of increased computation. Notably, even with higher thresholds that reduce accuracy, SCALE maintains substantial advantages over CoT baselines. For instance, on AIME24, SCALE with τ = 0.5 achieves 74.58% accuracystill outperforming CoTs 73.33%. On AIME25, SCALE at τ = 0.6 (58.75%) exceeds CoT performance (57.5%). This demonstrates SCALEs robustness: even suboptimal threshold settings preserve competitive performance while requiring significantly fewer sub-problems (47.69% and 50.97% respectively) to undergo System 2 processing. The inverse relationship between threshold and token usage presents practical deployment opportunities. As τ increases from 0.2 to 0.9, total tokens decrease dramaticallyby 63% on AIME24 (from 22,454 to 8,229 tokens) and 71% on AIME25 (from 23,212 to 6,811 tokens). Correspondingly, the percentage of hard sub-problems decreases from over 75% at low thresholds to 0% at τ = 0.9. This flexibility allows practitioners to adjust τ based on computational budgetsusing lower thresholds when accuracy is paramount, or higher thresholds when operating under strict resource constraints while still maintaining advantages over baseline methods."
        },
        {
            "title": "Model",
            "content": "AIME24 AIME25 AMC"
        },
        {
            "title": "Acc Tok Acc Tok Acc Tok",
            "content": "Qwen2.5-14B-I 13.75 1.0 13.33 0.9 57.19 0.8 27.50 24.4 20.00 25.0 61.88 14.5 w/ SCALE Qwen2.5-32B-I 17.92 0.9 16.67 0.9 68.75 0.7 53.33 22.0 39.17 22.2 86.23 10.7 w/ SCALE Qwen2.5-72B-I 17.92 1.2 12.92 1.0 66.87 0.9 54.17 21.1 47.50 21.4 88.12 11.7 w/ SCALE Llama3.3-70B-I 24.58 1.2 1.0 57.81 1.0 63.51 15.7 44.83 16.5 83.23 10.7 5.42 w/ SCALE Table 3: Performance comparison of SCALE-enhanced models against base models. Acc: accuracy (%), Tok: total tokens per problem in thousands. Enhancing Non-Reasoning Model Performance In addition to enhancing reasoning-capable models, we investigate SCALEs effectiveness in generating high-quality synthetic reasoning traces for improving non-reasoning models through supervised fine-tuning. This setting demonstrates SCALEs versatility as data generation tool for model training. Table 3 presents the comprehensive comparison between base models and their SCALE-enhanced counterparts across four different models. The results demonstrate substantial and consistent improvements across all model sizes and datasets. Significant Performance Gains Across All Benchmarks. All fine-tuned models show remarkable improvements over their base versions, with gains ranging from 4.69 to 39.41 percentage points across different benchmarks. The most notable improvements occur on challenging AIME problems, where Llama3.3-70B-Instruct achieves dramatic gains of 38.93 percentage points on AIME24 (from 24.58% to 63.51%) and Qwen2.5-32B-Instruct improves by 35.41 percentage points on the same benchmark. Cross-Architecture Generalization and Scaling Effects. SCALE demonstrates strong generalization across different model architectures and sizes. Within the Qwen2.5 family, clear scaling trends emerge: the 32B and 72B models achieve substantially larger gains than the 14B model, particularly on challenging AIME problems. However, the performance gap between 32B and 72B models is relatively small (53.33% vs 54.17% on AIME24), suggesting diminishing returns beyond certain capacity threshold. Importantly, Llama3.3-70B achieves competitive performance (63.51% on AIME24), demonstrating that SCALEs effectiveness transcends specific architectural choices. Enhanced Reasoning Pattern Transfer. The consistent improvements across different problem difficulties indicate that SCALE-generated reasoning traces effectively transfer sophisticated reasoning patterns to non-reasoning models. This is particularly evident on challenging AIME problems, where base models initially struggled with accuracy rates below 25%. After fine-tuning with SCALE-generated data, larger models reach 44-63% accuracy on AIME benchmarks, representing performance gains that would typically require substantially larger model parameters or architectural modifications."
        },
        {
            "title": "Related Work",
            "content": "The evolution of reasoning capabilities in large language models has progressed from early chain-of-thought (CoT) prompting techniques (Wei et al. 2022; Zhang et al. 2023) to process reward models (Lightman et al. 2023; Uesato et al. 2022). Advanced reasoning models like OpenAIs o1 and DeepSeek-R1 employ internal test-time scaling, generating extended chain-of-thought sequences before producing final answers (Guo et al. 2025; Jaech et al. 2024). However, Large Reasoning Models exhibit the overthinking phenomenon where longer reasoning sequences improve performance but introduce significant computational overhead (Sui et al. 2025; Chen et al. 2024). To address efficiency concerns, recent work has explored adaptive reasoning frameworks that dynamically adjust computational allocation based on task complexity. Several approaches focus on mode switching mechanisms, including Self-Route for automatic capability-based routing, ThinkSwitcher for systematic fast-slow thinking transitions, and Qwen3s seamless switching between thinking and non-thinking modes (He et al. 2025; Liang et al. 2025; Yang et al. 2025). Other methods target reasoning length optimization, such as AutoL2S which combines long and short chain-of-thought data adaptively, and TLDR for controlled reasoning compression (Luo et al. 2025; Li et al. 2025). Additional innovations include AdaptThinks learning-based reasoning engagement and various hybrid approaches like Llama-Nemotron, KATV1, and AdaCoT that integrate multiple adaptive strategies (Zhang et al. 2025; Bercovich et al. 2025; Zhan et al. 2025; Lou et al. 2025). Despite these advances in adaptive reasoning strategies, existing methods primarily operate at the problem level without fine-grained resource allocation within sub-problems. SCALE addresses this gap through fine-grained resource allocation at the sub-problem level, achieving superior computational efficiency through selective cognitive resource distribution."
        },
        {
            "title": "Conclusion",
            "content": "This work addresses fundamental bottleneck in test-time compute scaling for mathematical reasoning: the inefficient uniform resource allocation that prevents effective scaling despite increasing computational budgets. Our proposed SCALE framework overcomes these limitations through selective resource allocation inspired by dual-process theory. By decomposing problems into sequential reasoning subproblems, assessing their difficulty, and dynamically assigning appropriate processing modes, SCALE concentrates computational resources where they can maximize impact. Extensive experiments demonstrate SCALEs effectiveness, achieving substantial accuracy improvements while demonstrating superior resource utilization efficiency compared to uniform scaling approaches. Acknowledgments We would like to thank all reviewers for their insightful comments and suggestions to help improve the paper. This work was supported by the Research Grants Council of Hong Kong (GRF No. 15209724)."
        },
        {
            "title": "References",
            "content": "AI@Meta. 2024. Llama 3 Model Card. Anthropic. 2024. The claude 3 model family: Opus,sonnet, haiku. Bercovich, A.; Levy, I.; Golan, I.; Dabbah, M.; El-Yaniv, R.; Puny, O.; Galil, I.; Moshe, Z.; Ronen, T.; Nabwani, N.; et al. 2025. Llama-nemotron: Efficient reasoning models. arXiv preprint arXiv:2505.00949. Chen, X.; Xu, J.; Liang, T.; He, Z.; Pang, J.; Yu, D.; Song, L.; Liu, Q.; Zhou, M.; Zhang, Z.; et al. 2024. Do not think that much for 2+ 3=? on the overthinking of o1-like llms. arXiv preprint arXiv:2412.21187. Chiang, C.-H.; and Lee, H.-y. 2024. Over-reasoning and arXiv redundant calculation of large language models. preprint arXiv:2401.11467. Guo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.; Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. He, Y.; Ding, X.; Cai, B.; Zhang, Y.; Xiong, K.; Sun, Z.; Qin, B.; and Liu, T. 2025. Self-Route: Automatic Mode Switching via Capability Estimation for Efficient Reasoning. arXiv preprint arXiv:2505.20664. Jaech, A.; Kalai, A.; Lerer, A.; Richardson, A.; El-Kishky, A.; Low, A.; Helyar, A.; Madry, A.; Beutel, A.; Carney, A.; et al. 2024. Openai o1 system card. arXiv preprint arXiv:2412.16720. Kahneman, D. 2011. Thinking, fast and slow. macmillan. Li, Z.-Z.; Liang, X.; Tang, Z.; Ji, L.; Wang, P.; Xu, H.; Huang, H.; Deng, W.; Wu, Y. N.; Gong, Y.; et al. 2025. TL; DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression. arXiv preprint arXiv:2506.02678. Liang, G.; Zhong, L.; Yang, Z.; and Quan, X. 2025. Thinkswitcher: When to think hard, when to think fast. arXiv preprint arXiv:2505.14183. Lightman, H.; Kosaraju, V.; Burda, Y.; Edwards, H.; Baker, B.; Lee, T.; Leike, J.; Schulman, J.; Sutskever, I.; and Cobbe, K. 2023. Lets verify step by step. In The Twelfth International Conference on Learning Representations. Lou, C.; Sun, Z.; Liang, X.; Qu, M.; Shen, W.; Wang, W.; Li, Y.; Yang, Q.; and Wu, S. 2025. AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning. arXiv preprint arXiv:2505.11896. Luo, F.; Chuang, Y.-N.; Wang, G.; Le, H. A. D.; Zhong, S.; Liu, H.; Yuan, J.; Sui, Y.; Braverman, V.; Chaudhary, V.; et al. 2025. Autol2s: Auto long-short reasoning for efficient large language models. arXiv preprint arXiv:2505.22662. MAA. 2023. American mathematics competitions. In American Mathematics Competitions. MAA. 2024. American invitational mathematics examination - aime. In American Invitational Mathematics Examination - AIME. MAA. 2025. American invitational mathematics examination - aime. In American Invitational Mathematics Examination - AIME. Muennighoff, N.; Yang, Z.; Shi, W.; Li, X. L.; Fei-Fei, L.; Hajishirzi, H.; Zettlemoyer, L.; Liang, P.; Cand`es, E.; and s1: Simple test-time scaling. arXiv Hashimoto, T. 2025. preprint arXiv:2501.19393. Qwen; :; Yang, A.; Yang, B.; Zhang, B.; Hui, B.; Zheng, B.; Yu, B.; Li, C.; Liu, D.; Huang, F.; Wei, H.; Lin, H.; Yang, J.; Tu, J.; Zhang, J.; Yang, J.; Yang, J.; Zhou, J.; Lin, J.; Dang, K.; Lu, K.; Bao, K.; Yang, K.; Yu, L.; Li, M.; Xue, M.; Zhang, P.; Zhu, Q.; Men, R.; Lin, R.; Li, T.; Tang, T.; Xia, T.; Ren, X.; Ren, X.; Fan, Y.; Su, Y.; Zhang, Y.; Wan, Y.; Liu, Y.; Cui, Z.; Zhang, Z.; and Qiu, Z. 2025. Qwen2.5 Technical Report. arXiv:2412.15115. Qwen. 2025. QwQ-32B: Embracing the Power of Reinforcement Learning. Shen, Y.; Zhang, J.; Huang, J.; Shi, S.; Zhang, W.; Yan, J.; Wang, N.; Wang, K.; Liu, Z.; and Lian, S. 2025. Dast: Difficulty-adaptive slow-thinking for large reasoning models. arXiv preprint arXiv:2503.04472. Snell, C.; Lee, J.; Xu, K.; and Kumar, A. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314. Sui, Y.; Chuang, Y.-N.; Wang, G.; Zhang, J.; Zhang, T.; Yuan, J.; Liu, H.; Wen, A.; Zhong, S.; Chen, H.; et al. 2025. Stop overthinking: survey on efficient reasoning for large language models. arXiv preprint arXiv:2503.16419. Uesato, J.; Kushman, N.; Kumar, R.; Song, F.; Siegel, N.; Wang, L.; Creswell, A.; Irving, G.; and Higgins, I. 2022. Solving math word problems with process-and outcomebased feedback. arXiv preprint arXiv:2211.14275. Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.; Narang, S.; Chowdhery, A.; and Zhou, D. 2023. SelfConsistency Improves Chain of Thought Reasoning in LanIn The Eleventh International Conference guage Models. on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net. Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.; Le, Q. V.; Zhou, D.; et al. 2022. Chain-ofthought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35: 2482424837. Xiao, Y.; Wang, J.; Yuan, R.; Xu, C.; Xu, K.; Li, W.; and Liu, P. 2025. LIMOPro: Reasoning Refinement for Efficient and Effective Test-time Scaling. arXiv preprint arXiv:2505.19187. Yan, Y.; Shen, Y.; Liu, Y.; Jiang, J.; Zhang, M.; Shao, J.; and Zhuang, Y. 2025. Inftythink: Breaking the length limits of long-context reasoning in large language models. arXiv preprint arXiv:2503.06692. Yang, A.; Li, A.; Yang, B.; Zhang, B.; Hui, B.; Zheng, B.; Yu, B.; Gao, C.; Huang, C.; Lv, C.; et al. 2025. Qwen3 technical report. arXiv preprint arXiv:2505.09388. Yang, J.; Lin, K.; and Yu, X. 2025. Think when you need: arXiv preprint Self-adaptive chain-of-thought learning. arXiv:2504.03234. Ye, Y.; Huang, Z.; Xiao, Y.; Chern, E.; Xia, S.; and Liu, P. 2025. Limo: Less is more for reasoning. arXiv preprint arXiv:2502.03387. Zhan, Z.; Deng, K.; Tang, H.; Xiang, W.; Wu, K.; Li, W.; Zhu, W.; Xu, J.; Huang, L.; Feng, Z.; et al. 2025. KATarXiv preprint V1: Kwai-AutoThink Technical Report. arXiv:2507.08297. Zhang, J.; Lin, N.; Hou, L.; Feng, L.; and Li, J. 2025. Adaptthink: Reasoning models can learn when to think. arXiv preprint arXiv:2505.13417. Zhang, Z.; Zhang, A.; Li, M.; Zhao, H.; Karypis, G.; and Smola, A. 2023. Multimodal chain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923."
        }
    ],
    "affiliations": [
        "Shanghai Jiao Tong University",
        "The Hong Kong Polytechnic University"
    ]
}