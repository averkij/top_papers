{
    "paper_title": "Federated Computation of ROC and PR Curves",
    "authors": [
        "Xuefeng Xu",
        "Graham Cormode"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are fundamental tools for evaluating machine learning classifiers, offering detailed insights into the trade-offs between true positive rate vs. false positive rate (ROC) or precision vs. recall (PR). However, in Federated Learning (FL) scenarios, where data is distributed across multiple clients, computing these curves is challenging due to privacy and communication constraints. Specifically, the server cannot access raw prediction scores and class labels, which are used to compute the ROC and PR curves in a centralized setting. In this paper, we propose a novel method for approximating ROC and PR curves in a federated setting by estimating quantiles of the prediction score distribution under distributed differential privacy. We provide theoretical bounds on the Area Error (AE) between the true and estimated curves, demonstrating the trade-offs between approximation accuracy, privacy, and communication cost. Empirical results on real-world datasets demonstrate that our method achieves high approximation accuracy with minimal communication and strong privacy guarantees, making it practical for privacy-preserving model evaluation in federated systems."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 ] . [ 1 9 7 9 4 0 . 0 1 5 2 : r a"
        },
        {
            "title": "Federated Computation of ROC and PR Curves",
            "content": "Xuefeng Xu University of Warwick xuefeng.xu@warwick.ac.uk Graham Cormode University of Warwick g.cormode@warwick.ac.uk October 7, 2025 Abstract Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are fundamental tools for evaluating machine learning classifiers, offering detailed insights into the trade-offs between true positive rate vs. false positive rate (ROC) or precision vs. recall (PR). However, in Federated Learning (FL) scenarios, where data is distributed across multiple clients, computing these curves is challenging due to privacy and communication constraints. Specifically, the server cannot access raw prediction scores and class labels, which are used to compute the ROC and PR curves in centralized setting. In this paper, we propose novel method for approximating ROC and PR curves in federated setting by estimating quantiles of the prediction score distribution under distributed differential privacy. We provide theoretical bounds on the Area Error (AE) between the true and estimated curves, demonstrating the trade-offs between approximation accuracy, privacy, and communication cost. Empirical results on real-world datasets demonstrate that our method achieves high approximation accuracy with minimal communication and strong privacy guarantees, making it practical for privacy-preserving model evaluation in federated systems."
        },
        {
            "title": "1 Introduction",
            "content": "Federated learning (FL) (Kairouz et al., 2021b) is distributed machine learning paradigm that enables multiple clients to collaboratively train model without sharing their raw, heterogenous data. This framework is particularly valuable in privacy-sensitive domains such as healthcare and finance. However, current FL evaluation tools often rely on simple metrics like accuracy and loss, as implemented in frameworks like Flower (Beutel et al., 2020). These metrics, while useful during training, provide an incomplete picture of model performance. Accuracy, in particular, is unreliable on imbalanced datasets (Provost et al., 1998), where classifier may appear effective simply by predicting the majority class. Loss values are often not interpretable in practice and provide limited insight for deployment decisions. Moreover, one model may achieve lower loss value, but have worse ROC/PR curves compared to another. Without computing these curves in the federated setting, such differences in model behavior would remain hidden. Some systems, such as FATE (Liu et al., 2021), support more advanced metrics like Area Under the Curve (AUC), but only for local evaluation on individual clients, which fails to capture global model behavior across all participants. This limitation prevents full assessment of model performance, hindering informed decisions about model deployment and improvement. In contrast, ROC (Provost et al., 1998) and PR (Raghavan et al., 1989) curves are standard tools in centralized machine learning for evaluating binary classifiers. The ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR), while the PR curve plots precision against recall. These curves provide comprehensive view of model performance across all classification thresholds. However, computing ROC and PR curves in federated settings presents two major challenges. First, their exact computation requires access to all prediction scores and labels, which violates the privacy principles of FL. Second, naively aggregating this information incurs significant communication cost, which scales linearly with dataset size. Sampling-based alternatives could mitigate this cost, but they still require access to raw data and may leak sensitive information. Prior work (Matthews and Harel, 2013) has shown that even the ROC curve itself may reveal information about class labels, raising privacy concerns. All these challenges 1 prevent the coordinating server in FL from computing the exact ROC and PR curves as well as obtaining the raw prediction scores. In this paper we introduce methods to approximate ROC and PR curves in the federated setting using only quantiles of the prediction score distribution and class priors, without accessing raw data. We define the approximation quality via the Area Error (AE) (Definition 4.1), which measures the integral of the absolute error between the true and estimated curves. Under mild condition on the score distribution, we prove worst-case AE bound of O(1/Q) for the ROC curve, where is the number of quantiles used, which governs the communication cost. The AE bound is O(1/Q)1 for the PR curve under mild class imbalance, where the class ratio = n+/n 0.1, with n+ and representing the number of positive and negative examples, respectively. Under extreme imbalance, i.e., 1, the AE is bounded by O( 1 Qr ). + 1 This bound is extended to O( 1 nε ) 2 when differential privacy (Dwork and Roth, 2014) is applied, where is the total number of examples and ε is the standard privacy budget. Notably, our method is agnostic to data heterogeneity and skew, and requires only O(Q) communication, providing an efficient accuracy-privacy-communication trade-off. Empirically, we show that with 102, the AE of ROC is often close to 103, the AE of PR is below 102, and they remain low even under strong privacy settings (e.g., ε 1). Our method uses federated quantile estimation which can be implemented via histogram aggregation, where clients locally bin prediction scores with evenly spaced boundaries across the score range. This method is particularly well-suited for FL as it enables accurate quantile estimation with guaranteed error bounds, regardless of score distributions and data heterogeneity. For privacy, we adopt Distributed Differential Privacy (DDP) (Goryczka and Xiong, 2017), where each client adds independent noise to their local histograms before sending them to the server. The server aggregates histograms to estimate global quantiles and constructs approximate curves using monotone interpolation. Our contributions: We present and evaluate novel algorithms for providing characterizations of classifier efficacy with guaranteed privacy and accuracy. In more detail, our contributions are: 1. We present our approach for approximating ROC and PR curves in the federated setting without the need to share raw data. 2. We formally prove that the Area Error is bounded by O(1/Q) for the ROC curve and O(1/Q) for the PR curve under mild smoothness condition, regardless of data heterogeneity. 3. We also present privacy-preserving variant of our protocol achieving O( 1 + nε ) error under distributed differential privacy. 4. We perform empirical validation showing high approximation accuracy and low communication overhead under strong privacy guarantees. Related Work. Fawcett (2006) proposed heuristic methods for merging ROC curves across separated datasets, either by averaging TPRs at fixed FPRs or by averaging FPR-TPR pairs at fixed thresholds. These methods lack theoretical guarantees and are not suitable for heterogeneous data in FL. Chen et al. (2016) investigated differentially private ROC computation in centralized settings using median threshold selection and range queries, followed by post-processing for monotonicity, but did not provide formal error bounds. More recent work (Bell et al., 2020) addresses AUC computation under Local DP using hierarchical histograms. The error bound was improved by Cormode and Markov (2023) with relaxed assumptions. Sun et al. (2023) also explored DP-based AUC computation, but lacked theoretical guarantees. While AUC provides scalar performance summary, the full ROC and PR curves offer more detailed view and require different techniques for computation and error analysis. Barczewski et al. (2025) recently proposed differentially private computation of ROC in FL. Although their method and ours share comparable theoretical guarantees, empirical evaluations show that our method outperforms theirs. 1As usual, notation suppresses logarithmic factors. 2In the extreme class imbalance case for the PR curve, the error bound becomes O( Qr + 1 nε ); throughout the paper, our analysis focuses on mild class imbalance, where the error is O(1/Q)."
        },
        {
            "title": "2.1 The ROC and PR Curves",
            "content": "The ROC Curve evaluates classifiers by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR). The x-axis represents the FPR, defined as = FP/n, where FP counts false positives (as the score threshold varies) and is the total number of negative examples. The y-axis represents the TPR, defined as = TP/n+, where TP counts true positives and n+ is the number of positive examples. Since both FPR and TPR are independent of class distribution, the ROC curve remains invariant to class skew. An efficient algorithm for constructing the ROC curve is outlined by Fawcett (2006). It involves sorting prediction scores in descending order, using each score as threshold, and computing the corresponding FPRs and TPRs. Linear interpolation is applied between points. The ROC curve is non-decreasing, progressing from (0,0) (score threshold = 1) to (1,1) (s = 0). random classifier lies along the diagonal = x, while curves bending toward the top-left indicate better performance. The area under the ROC curve (AUC-ROC) is common summary metric, computed via the trapezoidal rule. The PR Curve plots precision against recall. The x-axis represents recall, equivalent to TPR, while the y-axis represents precision, defined as = TP/(TP+FP). Unlike the ROC curve, the PR curve is sensitive to class imbalance since precision depends on both class labels. This property makes the PR curve more informative when positive instances are rare (Saito and Rehmsmeier, 2015). The PR curve is nonmonotonic, spanning from (0,1) (s = 1) to (1, n+/n) (s = 0), as precision may decrease with increasing recall. random classifier yields horizontal line at = n+/n, while curves bending toward the top-right indicate better performance. There exists one-to-one correspondence between ROC and PR curves (Davis and Goadrich, 2006). However, linear interpolation in PR space is inappropriate, as it overestimates classifier performance. In Scikit-learn (Pedregosa et al., 2011), right-end constant interpolation is used to ensure consistency with average precision, which differs from the trapezoidal rule used for AUC-ROC."
        },
        {
            "title": "2.2 Differential Privacy and Federated Quantiles",
            "content": "Differential Privacy (DP) guarantees that the output of function is insensitive to the inclusion or exclusion of any single data point. Formally, mechanism satisfies ε-DP if for any two neighboring datasets and differing by one element, the output distributions M(D) and M(D) are close, with probability ratio bounded by eε. smaller ε implies stronger privacy but requires more noise, which may lead to less accurate results. The noise magnitude also depends on the sensitivity of the function, defined as = maxD,D (D) (D). One way to achieve DP is to add statistical noise to the output of , where the noise scale is proportional to /ε. Distributed DP (DDP) (Goryczka and Xiong, 2017) allows clients to collaboratively ensure privacy. Each client adds local noise such that the aggregated result achieves ε-DP. Continuous noise can be sampled from Gamma distribution, while discrete noise can be sampled from Polya distribution. This also extends to (ε, δ)-DP mechanisms such as the Skellam Mechanism (Agarwal et al., 2021) and the Distributed Discrete Gaussian Mechanism (Kairouz et al., 2021a). Federated Quantile Estimation can be achieved using histogram-based methods. Each client bins local data and transmits noisy histogram. The server aggregates these to form global histogram from which quantiles are estimated. Hierarchical histograms (Hay et al., 2010; Qardaji et al., 2013; Cormode et al., 2019) are preferred over flat histograms, as they provide improved accuracy and enable consistency enforcement via post-processing, making them well-suited for federated and differentially private settings."
        },
        {
            "title": "2.3 Monotone Interpolation",
            "content": "Linear interpolation is simple and efficient method for interpolating monotone series of points but may lack smoothness and fail to capture underlying trends of the data. Polynomial interpolation improves smoothness but may introduce oscillations, potentially violating monotonicity. Piecewise cubic Hermite interpolation (PCHIP) (Fritsch and Carlson, 1980; Fritsch and Butland, 1984; Moler, 2004) offers balance: it constructs piecewise cubics that preserve monotonicity and avoid overshoot via carefully selected derivatives at each point. Although higher-order methods like quintic interpolation (Costantini, 1997; Lux et al., 2023) can offer 3 Figure 1: ECDF approximation using quantiles for negative and positive classes. smoother results, they are less efficient. In this work, we make use of both linear and PCHIP interpolation for reconstructing curves from quantiles."
        },
        {
            "title": "3.1 Curve Approximation via Quantiles",
            "content": "Constructing ROC and PR curves uses prediction scores and corresponding class labels. In federated settings, Instead, we will estimate the empirical these raw values cannot be shared due to privacy constraints. cumulative distribution function (ECDF) Φ(s) of prediction scores using quantiles, computed separately for the positive and negative classes. Figure 1 shows an example where the ECDF is divided into five evenly spaced quantile intervals, each with width of 0.2. PCHIP interpolation is used to estimate the ECDF between quantile points. We can then compute TPR/FPR (for ROC) and Precision/Recall (for PR) at arbitrary thresholds using the interpolated ECDFs. For the ROC curve, the FPR depends only on the negative score distribution, while TPR depends on the positive score distribution, computed as: (s) = Pr[S > = 0] = 1 Φ(s), (s) = Pr[S > = 1] = 1 Φ+(s). The PR curve uses (s) as recall and computes precision (s) using and as: (s) = (s)n+ (s)n+ + (s)n . (1) (2) (3) In Figure 2 shows the resulting approximated ROC and PR curves derived from the estimated ECDFs. this example, the classifier used is XGBoost (Chen and Guestrin, 2016) on the Adult dataset (Becker and Kohavi, 1996), although our approach is agnostic to the classifier and data used. For exposition, we assume that prediction scores lie in [0, 1] (and so may be thought of as probabilities), but the approach applies to arbitrary score ranges."
        },
        {
            "title": "3.2 Quantile Estimation via Histograms",
            "content": "Quantiles are estimated via hierarchical histograms of height h. At each level (1 h), the prediction score range is divided into bi equal-width bins, where is the branching factor. Each client builds separate histograms for positive and negative examples and sends them to the server. Under DP, each client splits its privacy budget ε across the layers and adds independent noise to each bin (Hay et al., 2010; Qardaji 4 Figure 2: Approximated ROC and PR curves constructed from ECDFs. et al., 2013). The histograms are aggregated at the server, enabling quantile estimation without accessing raw scores. The full protocol is described in Algorithm 1 (Appendix A). Data Heterogeneity. The histogram-based quantile estimation is agnostic to data heterogeneity and skew. Since each client locally bins scores and the server aggregates counts additively, the resulting global histogram matches the centralized case, regardless of how data is distributed across clients. Communication Cost. The communication cost is linear in the number of leaf bins: O(bh). Under SA, each client sends only the bh leaf counts. Under DP, client sends + b2 + + bh = b(bh1) bins, which is also O(bh). To ensure accurate quantile estimation, we require bh > Q, where is the number of quantiles. To balance communication and accuracy, we set = logb + c, where is small constant (typically 2 or 3). This keeps the communication cost at O(Q), which is much smaller than the dataset size. In our experiments, we use = 2 and = 2. When = 1024, this is sufficient to ensure low Area Error (Definition 4.1). Under this setting, each client transmits approximately 213 bins per histogram, totaling around 8K integers (32-bit), i.e., 32K Bytes. b"
        },
        {
            "title": "4.1 Area Error Definition",
            "content": "We use Area Error (AE) to quantify the discrepancy between the true and approximated ROC or PR curves, similar in spirit to the notion of the L1 metric from Clemencon and Vayatis (2009). Formally: Definition 4.1 (AE). The Area Error is defined as the integral of the absolute difference between the true and estimated curves over [0, 1]: AEROC = AEPR = (cid:90) 1 0 (cid:90) 0 (f ) ˆT (f )df, (t) ˆP (t)dt. (4) (5) Here, (f ) and ˆT (f ) denote the true and estimated TPR at FPR , while (t) and ˆP (t) denote the true and estimated precision at recall (since recall is equivalent to TPR). AE is stricter error measure than absolute AUC difference (which computes (cid:82) 1 ˆT (f )df for ROC). small AE implies small AUC error, but not vice versa. This is because AUC aggregates performance into single scalar, while AE captures curve discrepancies over the full domain. Another weak alternative is the Point Error (Barczewski et al., 2025), which averages the absolute or squared difference at the score thresholds. However, this neglects cumulative errors and lacks robustness across the full curve. 0 (f )df (cid:82) 1"
        },
        {
            "title": "4.2 Bounding the Area Error Using Quantiles",
            "content": "We consider the case where quantiles are evenly spaced. Let and denote the exact FPR and TPR at score threshold s, and let ˆf and ˆt be their estimations. If and Q+ exact quantiles are used for the negative and positive classes respectively, then: ˆf 1 2(Q 1) , ˆt 1 2(Q+ 1) . (6) The bound arises because the maximum quantile error corresponds to half the width of quantile interval. Using this, we can now bound the AE for ROC and PR curves. Theorem 4.2 (ROC-AE). If exact quantiles are used for both positive and negative examples, then the Area Error between the true and estimated ROC curves is bounded by O(1/Q). Proof sketch. Evenly divide the ROC space into 1 vertical strips. Each strip contributes an error of O(1/Q2 + i/Q) at most, where the first term accounts for the bounded deviation in TPR/FPR and the second term corresponds to region of uncertain area. Since the ROC space is bounded, we have (cid:80) 1, resulting in an overall area error of O(1/Q) when summing over the 1 strips. See Appendix for full details of the proof. The analysis for the PR curve is similar in outline, but has more wrinkles. Precision depends on both (s) and (s) via Equation (3), and is also affected by class imbalance (Williams, 2021). In the worst case (when is close to 0), the absolute error (t) ˆP (t) can be close to 1. When is close 1, the absolute error is as high as O(1/Q). However, we can bound the AE by integrating the absolute error over the entire range of TPR (recall). Theorem 4.3 (PR-AE). If quantiles are used for both positive and negative examples, under mild class imbalance (r = n+/n 0.1), the Area Error between the true and estimated PR curves is bounded by O(1/Q). Under extreme class imbalance (r 1), the AE is bounded by O( 1 Qr ). Proof sketch. AE is the integral of (t) ˆP (t) over [0, 1]. By bounding ˆP as function of t, and integrating, we obtain worst-case Area Error. However, under extreme class imbalance, the bound is also dependent on the ratio r. See full details in Appendix D."
        },
        {
            "title": "4.3 Error Analysis in the Federated Setting with Security and Privacy",
            "content": "When applying our results to the federated setting, we need to extend the proof to incorporate the additional uncertainties due to approximate quantiles and privacy noise. Under mild assumption on the score distributions (formalized as Θ(1)-well-behaved in Definition E.1), we derive Area Error bounds separately for both the SA and DDP settings. Full proofs and further discussion are provided in Appendix E. Theorem 4.4 (AE-SA). Under Secure Aggregation, the Area Error between the true and estimated curves is bounded by O(1/Q) for the ROC curve and O(1/Q) for the PR curve. Theorem 4.5 (AE-DDP). Under Distributed Differential Privacy, the Area Error between the true and estimated curves is bounded by O( 1 nε ) for the ROC and PR curves. +"
        },
        {
            "title": "5 Empirical Evaluation",
            "content": "We evaluate our method on three public datasets: Bank (Moro et al., 2012), Adult (Becker and Kohavi, 1996), and Cover (Blackard, 1998). To account for the sensitivity of class imbalance, we select datasets with varying positive-to-negative ratios. Dataset statistics are summarized in Table 1. We try score functions of two baseline classifiers: XGBoost and Logistic Regression (see Appendices and for more results). In all experiments, we set the branching factor = 2 and the height = log2 + 2. For differential privacy, we use discrete noise and apply post-processing by default. The code is available at https:// github.com/xuefeng-xu/fedcurve. All experiments were performed on an Apple MacBook M3 (16GB RAM), completing within 8 hours. 6 Table 1: Dataset statistics. Datasets # Row # Col Pos-to-Neg Ratio Bank Adult Cover* 45K 33K 581K 16 14 54 0.132 0.317 0.574 *Class 1 is treated as positive; others as negative. Figure 3: Interpolation method comparison (ROC, XGBoost). 5."
        },
        {
            "title": "Initial Experiments",
            "content": "Interpolation Methods. We compare linear interpolation and piecewise cubic Hermite interpolation (PCHIP) for the interpolation step (Section 3.1). Results are shown in Figures 3 (more plots shown in Figure 9, 13, and 14 in the Appendix), under Secure Aggregation (SA, no privacy noise), and Distributed Differential Privacy (DDP, ε = 1 or 0.3). The PCHIP method consistently outperforms linear interpolation, though the margin is small in some cases. Since PCHIP yields smoother curves that more closely approximate the true ROC and PR curves, we recommend using it in practice. In Figure 3, we see that under SA the AE decreases as increases, whereas under DDP there is plateau due to privacy noise, as predicted by our analysis (Theorem 4.5). Privacy-Accuracy Trade-off. We evaluate performance under varying privacy levels ε. As shown in Figure 4 (more plots shown in Figure 10, 15, and 16 in the Appendix), smaller ε results in higher area error. Nonetheless, the error remains low even under strong privacy guarantees (ε 1). Larger datasets such as Cover exhibit smaller error due to more accurate quantile estimation under DP (recall, our error bound scales with 1 We also compare using the Exact Quantiles (EQ), as discussed in Section 4.2 and Secure Aggregation of histograms (SA), as discussed in Section 4.3. In Figure 4, for Cover dataset the gap between the two is more noticeable, while it is negligible on datasets like Adult and Bank. nε ). Strategies for PR Curve. We compare two strategies for computing the PR curve: (1) Separate: Estimate quantiles for positive and negative examples separately. (2) Combine: Estimate quantiles from all examples to approximate the denominator of precision, see Equation (3). Results are shown in Figures 5 and 17 (in the Appendix). The separate strategy consistently yields lower and more stable area error. This is because it ensures the precision numerator is always less than or equal to the denominator (Equation (3)). In contrast, the combine strategy may yield numerator greater than the denominator, requiring clipping to ensure the maximum value is 1. 7 Figure 4: Effect of ε (ROC, XGBoost). Figure 5: Comparison of strategies for PR curve (XGBoost)."
        },
        {
            "title": "5.2 Comparison with Prior Work",
            "content": "We compare our method with the range-query-based method of Barczewski et al. (2025), which estimates TPR and FPR at evenly spaced thresholds using DP-noised range queries. To enforce monotonicity, their method introduces smoothing variables vi added to the TPR and FPR series. The values of vi are optimized via l1 or l2 minimization. Their theoretical bound on the Squared Point Error of ECDF is O( log3 (nε)2 )3, which is O( log3/2 + log3/2 ) for the Absolute Point Error. Our bound on absolute point error of ECDF is O( 1 ) (Lemma E.2). Assuming , both approaches are asymptotically comparable, but we see that they behave quite different empirically. nε nε Note that the point error fails to capture cumulative errors over the entire curve, thus we evaluate both methods using Area Error. Empirically, as shown in Figures 6 (more plots shown in Figures 11, 18, and 19 in the Appendix), our method produces more stable area errors with increasing Q. In contrast, the Range method can show erratic AE results due to increased variance in each bin and added smoothing noise. The range method can perform better when < 100 (lower accuracy regime), especially on the Cover dataset, as it uses fixed thresholds for both TPR and FPR (for example, in Figure 6). Our approach, which estimates quantiles separately for positives and negatives, may diverge in threshold alignment, affecting accuracy at small Q. This discrepancy disappears as increases. 3The paper of Barczewski et al. (2025) omits the factor of in the statement of their error bound. Figure 6: Comparison with range-query method (ROC, XGBoost)."
        },
        {
            "title": "5.3 Experiments on Class Imbalance Data",
            "content": "We evaluate the effect of class imbalance on PR curves by varying the positive-to-negative ratio r. Specifically, we fix the set of negative examples and randomly subsample the positive examples to achieve the desired ratio. These experiments use the Secure Aggregation method, with results shown in Figures 12 and 20. In most cases, the AE increases as decreases, which aligns with the theoretical area error bound of O( 1 Qr ). However, there are instances where the observed error is smaller than expected. This occurs because classifier performance degrades significantly on extremely imbalanced datasets, causing the PR curve to approximate that of random classifier, represented by horizontal line at = n+/n 0. Since this curve is nearly flat, even poor approximation yields low area error."
        },
        {
            "title": "6 Discussion",
            "content": "Extension to Multi-class Setting. Our method extends to multi-class classification by decomposing the problem to multiple binary tasks, such as one-vs-rest or one-vs-one schemes. For each binary task, ROC and PR curves can be computed using the proposed quantile-based approach, with AE guarantees holding for each curve. Multi-class curves can then be obtained by macroor weighted-averaging the binary results, and the area error bounds carry over accordingly. Extension to Other Metrics. Our approach extends naturally to derived metrics such as AUC, where the area error directly bounds the AUC difference by O(1/Q); and the Mann-Whitney U-statistic, of which AUC is special case. It also applies to the Detection Error Tradeoff (DET) (Martin et al., 1997) curve, which plots the False Negative Rate (FNR) against the FPR on log scale. Since FNR = 1 TPR, we can compute DET similarly to ROC. Precision-Recall-Gain curves (Flach and Kull, 2015), which adjust precision and recall by the fraction of positive examples, are another promising direction for extending our approach. We leave their exploration for future work. Known Support of Prediction Scores. Our method does not assume prior knowledge of the support of prediction scores, as it uses equally spaced bins for histogram construction. However, in some cases, the support may be known. For example, the prediction scores of k-Nearest Neighbors classifier are influenced by the choice of k. In such scenarios, the histogram bins can be tailored to the known support to improve estimation accuracy. Handling Space Constraints. On devices with limited storage (e.g., edge clients), sketches such as GK (Greenwald and Khanna, 2001) can reduce space requirements. The differentially private version (Alabi et al., 2023) allows clients to construct histograms locally with bounded space, enabling private quantile estimation under tight client memory constraints. Extension to Local Differential Privacy. Our method generalizes to the local DP setting, where each client adds noise independently to their local histogram. In this case, the total noise increases with the number of clients, which is much larger than the distributed DP setting. To simplify the analysis, we assume each client holds one example, which is common in local DP. The total number of clients is equal to the number of examples n. The variance of the count in each bin is O(n/ε2), and the expected quantile nε ). Therefore, the Area Error is bounded by O( 1 estimation error is O( 1 bh n1/2ε ). See Cormode et al. (2019) for relevant local DP techniques. + h1/2 + Limitations. known limitation is that at small Q, our method may not outperform range-querybased methods, especially when aligned thresholds are critical. This can be mitigated by hybrid methods of quantiles and range queries. For ROC curve, quantiles of all examples can be computed, and TPR/FPR can be derived using range queries, as in Cormode and Markov (2023). Monotonicity can be enforced using post-processing as in Barczewski et al. (2025). Under mild assumptions, this approach may yield stronger area error bound for the ROC curve, though it introduces high variance when is large and lacks any clear area error bound for the PR curve."
        },
        {
            "title": "7 Conclusion",
            "content": "ROC and PR curves are critical for classifier evaluation. In federated settings, computing these curves must preserve privacy and minimize communication. Our method achieves both by approximating the curves with provably bounded area error, controlled by the number of quantiles Q. Communication scales linearly with Q, enabling an explicit trade-off between accuracy and bandwidth. The histogram-based quantile estimation is robust to data heterogeneity and compatible with both secure aggregation and differential privacy. Empirical results confirm that our method yields low area error under strong privacy guarantees, making it practical and efficient solution for federated model evaluation. Future work will be to integrate these techniques into popular FL frameworks such as Flower (Beutel et al., 2020), and to further expand the range of metrics that can be computed on federated models to ensure that their performance is reliable. Our trust model focuses on privacy for the clients; in future, we plan to study how to control the impact of malicious clients attempting to poison the data collection, by bounding their impact (via succinct non-interactive zero-knowledge proofs to demonstrate that each clients contribution falls within certain limits). References Agarwal, N., Kairouz, P., and Liu, Z. (2021). The skellam mechanism for differentially private federated learning. In Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 50525064. Alabi, D., Ben-Eliezer, O., and Chaturvedi, A. (2023). Bounded space differentially private quantiles. Trans. Mach. Learn. Res., 2023. Barczewski, A., Mawass, A., and Ramon, J. (2025). Differentially private empirical cumulative distribution functions. arXiv:2502.06651. Becker, B. and Kohavi, R. (1996). Adult. UCI Machine Learning Repository. DOI: https://doi.org/10. 24432/C5XW20. Bell, J., Bellet, A., Gascon, A., and Kulkarni, T. (2020). Private protocols for u-statistics in the local model In The 23rd International Conference on Artificial Intelligence and Statistics, AISTATS and beyond. 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy], volume 108 of Proceedings of Machine Learning Research, pages 15731583. PMLR. Beutel, D. J., Topal, T., Mathur, A., Qiu, X., Fernandez-Marques, J., Gao, Y., Sani, L., Kwing, H. L., Parcollet, T., Gusmao, P. P. d., and Lane, N. D. (2020). Flower: friendly federated learning research framework. arXiv preprint arXiv:2007.14390. Blackard, J. (1998). Covertype. UCI Machine Learning Repository. DOI: https://doi.org/10.24432/ C50K5N. Chen, T. and Guestrin, C. (2016). Xgboost: scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 16, page 785794, New York, NY, USA. Association for Computing Machinery. 10 Chen, Y., Machanavajjhala, A., Reiter, J. P., and Barrientos, A. F. (2016). Differentially private regression diagnostics. In IEEE 16th International Conference on Data Mining, ICDM 2016, December 12-15, 2016, Barcelona, Spain, pages 8190. IEEE Computer Society. Clemencon, S. and Vayatis, N. (2009). Tree-based ranking methods. IEEE Transactions on Information Theory, 55(9):43164336. Cormode, G., Kulkarni, T., and Srivastava, D. (2019). Answering range queries under local differential privacy. Proc. VLDB Endow., 12(10):11261138. Cormode, G. and Markov, I. L. (2023). Federated calibration and evaluation of binary classifiers. Proc. VLDB Endow., 16(11):32533265. Costantini, P. (1997). Algorithm 770: Bvspisa package for computing boundary-valued shape-preserving interpolating splines. ACM Trans. Math. Softw., 23(2):252254. Davis, J. and Goadrich, M. (2006). The relationship between precision-recall and ROC curves. In Machine Learning, Proceedings of the Twenty-Third International Conference (ICML 2006), Pittsburgh, Pennsylvania, USA, June 25-29, 2006, volume 148 of ACM International Conference Proceeding Series, pages 233240. ACM. Dwork, C. and Roth, A. (2014). The algorithmic foundations of differential privacy. Found. Trends Theor. Comput. Sci., 9(3-4):211407. Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognit. Lett., 27(8):861874. Flach, P. A. and Kull, M. (2015). Precision-recall-gain curves: PR analysis done right. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 838846. Fritsch, F. N. and Butland, J. (1984). method for constructing local monotone piecewise cubic interpolants. SIAM Journal on Scientific and Statistical Computing, 5(2):300304. Fritsch, F. N. and Carlson, R. E. (1980). Monotone piecewise cubic interpolation. SIAM Journal on Numerical Analysis, 17(2):238246. Goryczka, S. and Xiong, L. (2017). Comprehensive Comparison of Multiparty Secure Additions with Differential Privacy . IEEE Transactions on Dependable and Secure Computing, 14(05):463477. Greenwald, M. and Khanna, S. (2001). Space-efficient online computation of quantile summaries. In Proceedings of the 2001 ACM SIGMOD international conference on Management of data, Santa Barbara, CA, USA, May 21-24, 2001, pages 5866. ACM. Hay, M., Rastogi, V., Miklau, G., and Suciu, D. (2010). Boosting the accuracy of differentially private histograms through consistency. Proc. VLDB Endow., 3(1):10211032. Kairouz, P., Liu, Z., and Steinke, T. (2021a). The distributed discrete gaussian mechanism for federated learning with secure aggregation. In Meila, M. and Zhang, T., editors, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 52015212. PMLR. Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Nitin Bhagoji, A., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., DOliveira, R. G. L., Eichner, H., El Rouayheb, S., Evans, D., Gardner, J., Garrett, Z., Gascon, A., Ghazi, B., Gibbons, P. B., Gruteser, M., Harchaoui, Z., He, C., He, L., Huo, Z., Hutchinson, B., Hsu, J., Jaggi, M., Javidi, T., Joshi, G., Khodak, M., Konecny, J., Korolova, A., Koushanfar, F., Koyejo, S., Lepoint, T., Liu, Y., Mittal, P., Mohri, M., Nock, R., Ozgur, A., Pagh, R., Qi, H., Ramage, D., Raskar, R., Raykova, M., Song, D., Song, W., Stich, S. U., Sun, Z., Suresh, A. T., Tram`er, F., Vepakomma, P., Wang, J., Xiong, L., Xu, Z., Yang, Q., Yu, F. X., Yu, H., and Zhao, S. (2021b). Advances and open problems in federated learning. Foundations and Trends in Machine Learning, 14(12):1210. 11 Liu, Y., Fan, T., Chen, T., Xu, Q., and Yang, Q. (2021). Fate: an industrial grade platform for collaborative learning with data protection. J. Mach. Learn. Res., 22(1):16. Lux, T., Watson, L. T., Chang, T., and Thacker, W. (2023). Algorithm 1031: Mqsimonotone quintic spline interpolation. ACM Trans. Math. Softw., 49(1). Martin, A. F., Doddington, G. R., Kamm, T., Ordowski, M., and Przybocki, M. A. (1997). The DET curve in assessment of detection task performance. In Fifth European Conference on Speech Communication and Technology, EUROSPEECH 1997, Rhodes, Greece, September 22-25, 1997, pages 18951898. ISCA. Matthews, G. J. and Harel, O. (2013). An examination of data confidentiality and disclosure issues related to publication of empirical roc curves. Academic Radiology, 20(7):889896. Moler, C. B. (2004). Numerical Computing with Matlab. Society for Industrial and Applied Mathematics. Moro, S., Rita, P., and Cortez, P. (2012). Bank Marketing. UCI Machine Learning Repository. DOI: https://doi.org/10.24432/C5K306. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., VanderPlas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. (2011). Scikit-learn: Machine learning in python. J. Mach. Learn. Res., 12:28252830. Provost, F. J., Fawcett, T., and Kohavi, R. (1998). The case against accuracy estimation for comparing In Proceedings of the Fifteenth International Conference on Machine Learning, induction algorithms. ICML 98, page 445453, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. Qardaji, W. H., Yang, W., and Li, N. (2013). Understanding hierarchical methods for differentially private histograms. Proc. VLDB Endow., 6(14):19541965. Raghavan, V., Bollmann, P., and Jung, G. S. (1989). critical investigation of recall and precision as measures of retrieval system performance. ACM Trans. Inf. Syst., 7(3):205229. Saito, T. and Rehmsmeier, M. (2015). The precision-recall plot is more informative than the roc plot when evaluating binary classifiers on imbalanced datasets. PLOS ONE, 10(3):121. Sun, J., Yang, X., Yao, Y., Xie, J., Wu, D., and Wang, C. (2023). Dpauc: Differentially private auc computation in federated learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12):15170 15178. Williams, C. K. I. (2021). The effect of class imbalance on precision-recall curves. Neural Comput., 33(4):853 857."
        },
        {
            "title": "A Algorithm for Federated ROC and PR Curves",
            "content": "Algorithm 1 Federated Construction of ROC and PR Curves Client Part: 1: Input: Local prediction scores for positives s+ and negatives 2: Build histograms h+, over s+, 3: if Differential Privacy is enabled then 4: 5: end if 6: Send histograms h+ and to the server Add i.i.d. privacy noise to every histogram bin Server Part: Apply post-processing to enforce consistency across + and 1: Aggregate client histograms to obtain global counts + and 2: if Differential Privacy is enabled then 3: 4: end if 5: Extract total positive/negative counts n+, from +, 6: Extract set of quantiles q+, from +, 7: Interpolate q+, to build ECDFs Φ+(s), Φ(s) 8: for each evaluation threshold do 9: 10: (s) 1 Φ(s) (s) 1 Φ+(s) 11: (s) (s) n+ (s) n+ + (s) 12: end for 13: Plot ROC curve: (F (s), (s)); Plot PR curve: (T (s), (s)) Via Secure Aggregation Via Secure Aggregation FPR TPR / Recall Precision"
        },
        {
            "title": "B Shorthand Notation",
            "content": "Throughout the proofs, we use the following shorthand notation for the composition of functions , , 1, 1, where the variable used , t, indicates the elision that is happening: (f ) = (F 1(f )), (t) = (T 1(t)) For the estimated quantities, ˆT (f ) = ˆT ( ˆF 1(f )), ˆF (t) = ˆF ( ˆT 1(t)). When other combinations arise, such as ( ˆF 1(f )), ( ˆT 1(t)), ˆT (F 1(f )), ˆF (T 1(t)), (7) (8) (9) we will state them explicitly as needed. Proof of Theorem 4.2 We prove that the area error (AE) of the ROC curve is bounded by O(1/Q), where is the number of quantiles used separately to the negative and positive classes using evenly spaced thresholds. In Section C.1 and C.2 we assume that we have exact quantiles without estimation error; in Section C.3 and Appendix E, we explain how the proof changes in the federated setting. When querying the distribution of the negative class at the exact quantile points, the false positive rates (FPRs) are found precisely; when probing elsewhere in the distribution, the FPR absolute error is guaranteed to be at most half the quantile width (the distance between successive quantile measurements). The same 13 holds for true positive rates (TPRs) at quantile points for the positive class. As result, Area Error is bounded by the worst-case sum of trapezoidal area differences between the true and estimated ROC curves, as noted in the proof sketch. To formalize the proof, the subsequent subsections provide precise calculation of the worst case error. Since TPR and FPR are computed independently, we analyze them separately: we first apply exact quantiles on FPRs while treating TPRs as approximated (Section C.1), and then extend the analysis to include exact quantiles on TPRs as well (Section C.2). C.1 Using Quantiles for Negative Examples Dividing the FPR axis using quantiles results in 1 vertical strips. For any pair of consecutive negative quantiles, i+1) are accurately estimated. Let ti = (q ) denote the true and estimated TPRs, respectively. In order to show bound on the Area Error (AE), we consider the (deterministic) worst possible behavior of the ROC curve. i+1, the corresponding FPR values fi = (q ) and fi+1 = (q ) and ˆti = ˆT (q and To maximize AE under the constraints of the measured quantiles, we can set tiˆti = ti+1ˆti+1 = 1 2(Q+1) , the largest possible gap while meeting the quantile definition. Define = ti+1 ti as the change in TPRs between consecutive points. This scenario is illustrated in the left panel of Figure 7: it corresponds to the TPR suddenly leaping up to ti+1 at fi and remaining constant until fi+1 (blue line in the figure). The opposite extreme, of the TPR remaining steady from fi to fi+1 then leaping up to ti+1 would also contribute symmetric (negative) area error (similar to the dashed grey line), so it suffices to focus on the case of positive area error. Figure 7: Worst-case area error with quantiles on negative examples only. The total AE is computed as the sum of the areas of trapezoids, as illustrated in the right panel of 2 (a + b)h, where and are the lengths of parallel Figure 7. We apply the standard trapezoid area formula, 1 sides, and is the (perpendicular) height. Since (cid:80) 1, the worst-case error is bounded by O(1/Q): Q1 (cid:88) 1 2(Q+1) + AEROC 1 2(Q+1) + 2 1 1 i=1 Q1 (cid:88) i=1 = 1 2(Q+ 1)(Q 1) + 2(Q 1) 1 2(Q+ 1) + 1 2(Q 1) = O(1/Q) (10) (11) (12) C.2 Adding Q+ Quantiles for Positive Examples Now we consider incorporating Q+ quantiles for the TPR. If no positive quantile falls between the AE is as previously derived. Otherwise, suppose positive quantile q+ is accurate by construction, but its associated FPR ˆfj = ˆF (q+ lies in (q ) may deviate from fj = (q+ , j ). and i+1, i+1). Then tj = (q+ ) 14 Due to ECDF monotonicity, we have fi fj fi+1 and ti tj ti+1. Again, to maximize AE, we assume the true curve lies above the estimated curve: Set ti ˆti = ti+1 ˆti+1 = quantile values. Let δf = fj fi and δt = tj ti. This is shown in the left panel of Figure 8. 2(Q1) to maximize AE within the constraints on the 1 fi fj ˆfj fi+1, 2(Q+1) and ˆfj fj = 1 ˆti ti tj ˆti+1 ti+1 (13) Figure 8: Worst-case AE with additional positive quantile. In this configuration, the AE within the strip is composed of two trapezoids minus rectangle: AEi ROC 1 2(Q+1) + + δt 2 δt + 2 1 2(Q+1) + (cid:16) (cid:16) 1 2(Q 1) (cid:17) + δf 1 2(Q 1) (cid:17) δf δf (i δt) = 1 4(Q+ 1)(Q 1) + 3i 4(Q 1) (cid:16) + δt δf (cid:124) 1 2(Q 1) (cid:123)(cid:122) 0 (cid:17) iδf (cid:125) (14) (15) The last term contributes non-positive quantity, since δf 2(Q1) . Thus, the maximal AE occurs when δt = δf = 0, i.e., when tj = ti and fj = fi. In this case, the points (fi, ti) and (fj, tj) coincide, as shown in the right panel of Figure 8. 1 This scenario generalizes: any additional positive quantile within (q , i+1) does not increase AE beyond the bound. So in the worst case the AE is at the bound from (15): AEi ROC 1 4(Q+ 1)(Q 1) + 3i 4(Q 1) (16) Adding positive quantile reduces the first term but increases the second. Summing over all segments, and noting (cid:80) 1, we again obtain an O(1/Q) bound on the total AE. C.3 Proof Under Approximate Quantiles In the federated setting, it is difficult to obtain exact quantiles due to high communication costs and privacy constraints. Instead, we use approximate quantiles, which guarantee to report set of points for the quantile locations whose true position within the ECDF deviates by at most fixed amount. Let the quantile estimation error be α = O(1/Q), following the same outline as in Section C.1. This means that we can bound the absolute error in TPR at given as (see Lemma E.3): Therefore, the total area error is the integral of the absolute error: (f ) ˆT (f ) α AEROC = (cid:90) 1 (f ) ˆT (f )df α = O(1/Q) 15 (17) (18) Proof of Theorem 4.3 We prove that the area error (AE) of the PR curve is O(1/Q) when the class ratio = n+/n 0.1, and O( 1 Qr ) under extreme class imbalance. Different from the proof for the ROC curve (Appendix C), we omit the case using exact quantiles and trapezoidal rule, since it is an unrealistic scenario and often not acchievable in practice. Instead, we focus on the case of approximate quantiles, which is more relevant for federated learning settings. Since precision is dependent on TPR, we can bound the absolute error in precision (t) ˆP (t) as function of t, then compute the area error by integrating over the TPR range. Given Equation (3), we first reformulate the precision as function of t: (t) = n+ n+ + (t) (19) We first analyze the perfectly balanced case (Section D.1), and then extend to imbalanced settings (Section D.2). D.1 Perfectly Balanced Class Distribution (r = 1) To build an intuition, we first consider the case when the number of positive examples is exactly equal to the number of negative examples. This gives the pattern of the proof that we subsequently extend to arbitrary ratios of positive to negative examples. Since n+ = n, we have: (t) = + (t) and ˆP (t) = + ˆF (t) Let the absolute error in FPR at given be bounded by α = O(1/Q) (see Lemma E.3). (t) ˆF (t) α (20) (21) To maximize the error (t) ˆP (t), we minimize ˆP (t) by maximizing ˆF (t). We set ˆF (t) = (t) + α. This gives: (t) ˆP (t) + (t) + (t) + α = α (t + (t))(t + (t) + α) (22) (23) For the other direction, to maximize ˆP (t) (t), we maximize ˆP (t) by minimizing ˆF (t). We set ˆF (t) = (t) α. This gives: ˆP (t) (t) + (t) α + (t) = α (t + (t))(t + (t) α) Therefore, the absolute error in precision is bounded by the larger of (23) and (25), which is (25): ˆP (t) (t) = α (t + (t))(t + (t) α) α (1 + (t)/t)(t + (t) α) α + (t) α α α 16 (24) (25) (26) (27) (28) (29) Note that the precision is in the range of [0, 1], and the maximum absolute error is 1. Therefore, for 2α, the absolute error is bounded by 1; for > 2α, the absolute error is bounded by α/(t α), which is smaller than 1. Integrating this bound over yields the total area error: AEPR = (cid:90) 1 0 (t) ˆP (t)dt (cid:90) 1 2α + α α dt 2α = 2α + α log(1/α 1) 2α + α log(1/α) = O(log Q/Q) = O(1/Q) (30) (31) (32) (33) (34) For the last term, since α log(1/α) = log Q/Q and log grows much more slowly than Q, we may treat it as constant, and think of this term as being dominated by 1/Q. Pragmatically, setting = 104 gives AE 103, which is sufficient for most applications. D.2 Imbalanced Class Distribution (r = 1) Under the imbalanced class distribution, we consider the case to maximize ˆP (t) (t) by maximizing ˆP (t). For the other direction, the results are similar so we omit for brevity. The absolute error in precision is bounded by: ˆP (t) (t) = n+ n+ + ˆF (t) t n+ n+ + (F (t) α) n+ n+ + (t) n+ n+ + (t) = n+n = n+n n+ + (t) 1 n+ + (F (t)/t) α n+ + (t) α α n+ + (t) α Let = n+/n. We distinguish two cases: Case 1 (r > 1): The absolute error is bounded by: ˆP (t) (t) = n+ + (F (t)/t) n+ α n+ + (t) α α + (t)/r α/r 1 + (t)/t 1 α α/r α α/r α α This is the same as the perfectly balanced class distribution, the area error is bounded by O(1/Q). Case 2 (r < 1): The absolute error is bounded by: ˆP (t) (t) n+ n+ + (F (t)/t) n α n+ + (t) α = 1 1 + (t)/(t r) α + (t) α α α 17 (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45) (46) The Area Error is bounded by: AEPR = (cid:90) 1 (t) ˆP (t)dt (cid:90) 1 2α/r + α α dt 2α/r = 2α/r + α/r log(r/α 1) 2α/r + α/r log(r/α) (47) (48) (49) (50) Therefore, under the mild class imbalanced setting, i.e., 0.1, the Area Error is still bounded by O(1/Q). However, if the class distribution is extremely imbalanced, AE grows as O( 1 Qr ). Proof of Theorem 4.4 and 4.5 In the federated setting, additional quantile estimation error ˆq arise due to histogram binning and added privacy noise. We analyze these errors separately and outline the changes needed to prove the Area Error bound. We first formally define the notion of well-behaved score distribution, and provide the necessary lemmas (Section E.1). Then, we extend the proof to the federated setting with Secure Aggregation and Differential Privacy (Section E.2). E.1 Definition, Assumption, and Lemmas First, consider arbitrary score distributions. Even if the quantile estimation error can be bounded by bh (the width of the finest histogram bin), this does not imply bound on the error in the or . For example, when the score distribution has spikes (i.e., the same score value occurs for large fraction of positive or negative examples), even small quantile estimation error can cause large changes in or . To mitigate this, we require smoothness condition to ensure that the densities of positive and negative examples do not change too abruptly. Similar to Definition 1 in Cormode and Markov (2023), we formalize the notion of well-behaved score distribution: Definition E.1 (Well-behaved score distribution). Let Φ+(s) and Φ(s) denote the cumulative distribution functions of the score distribution for positive and negative examples, respectively. We say the distributions are ℓ-well-behaved if both are ℓ-Lipschitz: Φ+(s1) Φ+(s2) ℓs1 s2 and Φ(s1) Φ(s2) ℓs1 s2 (51) With well-behaved score distributions, we can bound the absolute error of the TPR and FPR using the quantile estimation error α. These bounds are crucial for proving the Area Error of the ROC and PR curves in the federated setting. The following lemmas formalize these bounds. Lemma E.2. Using the histogram approach for quantile estimation in the federated setting, let the additive error of quantile estimation be bounded by α, assuming the score distributions are Θ(1)-well-behaved, then we have the following bounds: (s) ˆT (s) Θ(α) and (s) ˆF (s) Θ(α) Proof. Sine the histogram approach guarantees that the quantile estimation error is bounded: 1(t) ˆT 1(t) α and 1(f ) ˆF 1(f ) α Since (s) = 1 Φ+(s) and (s) = 1 Φ(s), by Θ(1)-well-behaved distributions, we have: (s1) (s2) = Θ(s1 s2) and (s1) (s2) = Θ(s1 s2) (52) (53) (54) 18 Then the absolute error can be bounded as follows: (s) ˆT (s) = (s) (T 1( ˆT (s))) = Θ(s 1( ˆT (s))) = Θ( ˆT 1( ˆT (s)) 1( ˆT (s))) Θ(α) Similarly, we have: (s) ˆF (s) Θ(α) (55) (56) (57) (58) (59) Lemma E.3. Using the histogram approach for quantile estimation in the federated setting, let the additive error of quantile estimation is bounded by α, assuming the score distributions are Θ(1)-well-behaved, then we have the following bounds: (f ) ˆT (f ) Θ(α) and (t) ˆF (t) Θ(α) Proof. By Θ(1)-well-behaved distributions and additive error of quantile estimation, we have: (F 1(f )) ( ˆF 1(f )) = Θ(F 1(f ) ˆF 1(f )) = Θ(α) Now consider the absolute error: (f ) ˆT (f ) = (F 1(f )) ˆT ( ˆF 1(f )) = (F 1(f )) ( ˆF 1(f )) + ( ˆF 1(f )) ˆT ( ˆF 1(f )) (F 1(f )) ( ˆF 1(f )) + ( ˆF 1(f )) ˆT ( ˆF 1(f )) Θ(α) + Θ(α) = Θ(α) Similarly, we have: (t) ˆF (t) Θ(α) (60) (61) (62) (63) (64) (65) (66) Remark: If the Lipschitz condition is violated, approximation guarantees may degrade, especially near condensed data distributions. Specifically, the additive error guarantee on the ECDF may not be held in the dense region. Nonetheless, our empirical results suggest robustness in practical settings where distributions are not pathological. E.2 Secure Aggregation and Differential Privacy Secure Aggregation: In the absence of privacy noise, the quantile estimation error is at most the bin width bh. Assuming the score distributions are Θ(1)-well-behaved, the Lipschitz condition implies that the additive error in and is also bounded by Θ(bh), which is still O(1/Q). Combining this with the Area Error Theorems gives an overall area error of O(1/Q) for the ROC curve and O(1/Q) for the PR curve. Differential Privacy: When incorporating differential privacy, the privacy budget ε is split across layers. Each bin incurs noise with variance O(h2/ε2). Since quantile queries require traversing at most O(b) nodes per layer, and there are layers, the total query variance accumulates to O(bh3/ε2). The expected quantile error is thus O( 1 bh3/2. Applying standard statistical bounds and assuming the score distributions are Θ(1)-well-behaved, the AE under DP is bounded by O( nε ), assuming the total dataset size + 1 + 1 nε ). Meanwhile, n+ and are estimated from the aggregated histograms and are thus noisy under DP. Each count has an absolute error of O(h/ε), where = O(log Q). For typical ε (e.g., ε 1), this error is negligible compared to n+ and n. For the ROC curve, n+ and are not needed. For the PR curve, the error introduced by noisy counts is dominated by other factors and does not affect the overall area error bound. Therefore, Theorem 4.5 remains valid."
        },
        {
            "title": "F Experiments of PR Curve using XGBoost",
            "content": "Figure 9: Interpolation method comparison (PR, XGBoost). Figure 10: Effect of ε (PR, XGBoost). Figure 11: Comparison with range-query method (PR, XGBoost). 20 Figure 12: Effect of class imbalance on PR curve (XGBoost)."
        },
        {
            "title": "G Experiments using Logistic Regression",
            "content": "Figure 13: Interpolation method comparison (ROC, Logistic Regression). Figure 14: Interpolation method comparison (PR, Logistic Regression). 21 Figure 15: Effect of ε (ROC, Logistic Regression). Figure 16: Effect of ε (PR, Logistic Regression). Figure 17: Comparison of strategies for PR curve (Logistic Regression). 22 Figure 18: Comparison with range-query method (ROC, Logistic Regression). Figure 19: Comparison with range-query method (PR, Logistic Regression). Figure 20: Effect of class imbalance on PR curve (Logistic Regression)."
        }
    ],
    "affiliations": [
        "University of Warwick"
    ]
}