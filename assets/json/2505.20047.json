{
    "paper_title": "Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks",
    "authors": [
        "Debargha Ganguly",
        "Vikash Singh",
        "Sreehari Sankar",
        "Biyao Zhang",
        "Xuecen Zhang",
        "Srinivasan Iyengar",
        "Xiaotian Han",
        "Amit Sharma",
        "Shivkumar Kalyanaraman",
        "Vipin Chaudhary"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) show remarkable promise for democratizing automated reasoning by generating formal specifications. However, a fundamental tension exists: LLMs are probabilistic, while formal verification demands deterministic guarantees. This paper addresses this epistemological gap by comprehensively investigating failure modes and uncertainty quantification (UQ) in LLM-generated formal artifacts. Our systematic evaluation of five frontier LLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization's domain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on factual ones), with known UQ techniques like the entropy of token probabilities failing to identify these errors. We introduce a probabilistic context-free grammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty taxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy for logic, AUROC>0.93). Finally, a lightweight fusion of these signals enables selective verification, drastically reducing errors (14-100%) with minimal abstention, transforming LLM-driven formalization into a reliable engineering discipline."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 2 ] . [ 1 7 4 0 0 2 . 5 0 5 2 : r Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks Debargha Ganguly1, Vikash Singh1, Sreehari Sankar1, Biyao Zhang1, Xuecen Zhang1, Srinivasan Iyengar2, Xiaotian Han1, Amit Sharma3, Shivkumar Kalyanaraman2, Vipin Chaudhary1 1Case Western Reserve University 2Microsoft Corporation 3Microsoft Research {debargha,vikash,sreehari,bxz297,xxz1037,xhan,vipin}@case.edu {sriyengar,amshar,shkalya}@microsoft.com"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) show remarkable promise for democratizing automated reasoning by generating formal specifications. However, fundamental tension exists: LLMs are probabilistic, while formal verification demands deterministic guarantees. This paper addresses this epistemological gap by comprehensively investigating failure modes and uncertainty quantification (UQ) in LLM-generated formal artifacts. Our systematic evaluation of five frontier LLMs reveals Satisfiability Modulo Theories (SMT) based autoformalizations domain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on factual ones), with known UQ techniques like the entropy of token probabilities failing to identify these errors. We introduce probabilistic context-free grammar (PCFG) framework to model LLM outputs, yielding refined uncertainty taxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy for logic, AUROC>0.93). Finally, lightweight fusion of these signals enables selective verification, drastically reducing errors (14-100%) with minimal abstention, transforming LLM-driven formalization into reliable engineering discipline."
        },
        {
            "title": "Introduction",
            "content": "Formal methods offer robust mathematical guarantees for system reliability [Huth and Ryan, 2004], but their widespread adoption is impeded by high expertise and labor demands, traditionally limiting their application to safety-critical domains where failures have catastrophic consequences [Clarke et al., 2018, Woodcock et al., 2009]. Concurrently, Large Language Models (LLMs) have emerged with remarkable ability to generate formal artifacts such as code, proofs, and specifications [Brown et al., 2020, Chen et al., 2021, Jiang et al., 2023a], potentially democratizing formal methods [Hou et al., 2023] and finding new roles in formally correct reasoning and LLM verification [Ganguly et al., 2024, Pan et al., 2023]. However, these two approaches embody fundamentally different epistemological paradigms. Formal methods are rooted in deterministic logical calculi, where conclusions derive necessarily from premises via unambiguous inference rules. LLMs, in contrast, operate probabilistically, representing knowledge as distributions over tokens where multiple, even contradictory, outputs can possess non-zero probability [Wei et al., 2022a]. This inherent tension presents core challenge: how can we harness the generative power of LLMs for formal reasoning while upholding the rigorous guarantees that define formal verifications value? The central thesis of this paper is that the inherent probabilistic uncertainty in LLM outputs for formal reasoning tasks, particularly when generating formal artifacts like SMT-LIB programs, is not mere nuisance but valuable source of information for guiding verification. Existing methods often ignore this by selecting only the highest-probability output [Chen et al., 2022], simplification that we argue undermines the rigorous standards required for formal reasoning. In contrast, we demonstrate Preprint. Under review. how to systematically capture and analyze this output uncertainty by modeling LLM-generated SMT-LIB program distributions with Probabilistic Context-Free Grammars (PCFGs). Instead of focusing on single output, we analyze ensembles of LLM-generated SMT-LIB programs, treating these as samples from the models internal probability distribution [Kadavath et al., 2022], which we then approximate by applying PCFGs to the ensembles. This approximation not only identifies the most likely solutions but also reveals strategic diversity, common structural motifs, and areas of high model uncertainty. Deriving comprehensive suite of metrics from this structured, quantifiable understanding of uncertainty can then directly guide the verification workflowfor instance, by assessing artifact reliability, focusing human review on more ambiguous or structurally complex candidates, and improving error detection strategies. The core contributions of this paper are: We systematically evaluated frontier LLMs on four formal reasoning datasets, finding SMT-based autoformalization significantly boosted accuracy on tasks like ProofWriter (+34.8%) but harmed others like FOLIO (-44.5%), thus quantifying LLM-driven formal verifications failure modes. We then demonstrate that known uncertainty quantification techniques do not capture enough information to identify errors in FV artifacts. Introduce probabilistic framework using probabilistic context-free grammars to model LLMgenerated SMT-LIB programs, enabling mathematically sound uncertainty quantification and bridging neural models with formal verification. Developed and evaluated 25 uncertainty metrics, revealing refined taxonomy (epistemicknowledge, epistemic-procedural, recursive-complexity, capacity-limited) that offers more nuanced understanding of uncertainty in neurosymbolic systems than the traditional epistemic/aleatoric dichotomy. Demonstrated that formal reasoning uncertainty is task-dependent and introduced lightweight, model-agnostic fusion of these varied uncertainty signals. This approach outperforms individual metrics, improves calibration, enables selective verification to cut error rates by 14-100% with minimal abstention, and suggests modality-aware architectures for enhanced reliability."
        },
        {
            "title": "2 Methodology",
            "content": "Generating formal artifacts using ad-hoc Domain-Specific Languages (DSLs) introduces significant engineering friction. This friction arises from the need to redesign generators, models, and parsers for syntax changes, and it also complicates debugging erroneous outputs (e.g. syntactically incorrect FV artifacts). To mitigate this overhead, we adopt the stable, widely supported SMT-LIB standard as common intermediate representation targeting SMT solvers. In this section, we consequently present theoretical framework linking language models and verification to analyze LLM-generated SMT-LIB program distributions, enabling principled reasoning about their uncertainty. Problem Setup We formalize the probability space over SMT-LIB programs. Let Σ be finite alphabet. The set of all finite strings Σ forms measurable space (Σ, F), where is the σ-algebra generated by cylinder sets (strings sharing common prefix w). The SMT-LIB language LSM Σ, approximated by its standard context-free grammar GSM , is measurable in F. For task and an LLM with parameters θ, the LLM induces probability measure µT,θ on (Σ, F). The measure over valid SMT-LIB programs is then the conditional measure µT,θ,SM (A) = µT ,θ(ALSM ) for F. µT ,θ(LSM ) This definition requires µT,θ(LSM ) > 0, reasonable assumption that is empirically validated, as LLMs are generally trained to generate syntactically valid code and formal specifications. Modeling Background: To model distributions over structured programs like µT,θ,SM , we employ Probabilistic Context-Free Grammars (PCFGs). PCFGs extend standard Context-Free Grammars (CFGs) by associating probabilities with their production rules. Formally, PCFG is 5-tuple = (V, Σ, R, S, p), where is finite set of non-terminals; Σ is finite set of terminals disjoint from ; (V Σ) is finite set of production rules; and is the start symbol, such that (V, Σ, R, S) collectively form CFG. The fifth component, : [0, 1], is probability function assigning probability p(r) to each rule R. For each non-terminal , these probabilities must satisfy (cid:80) p(r) = 1, where RA denotes the set of rules with as their left-hand side. The probability of derivation π that applies rules r1, . . . , rk in sequence is p(π) = (cid:81)k i=1 p(ri). Consequently, for any terminal string L(G), where L(G) is the language generated by the rRA 2 Figure 1: Analysis of empirically observed LLM-generated SMT-LIB formalizations for the statement Everyone who studies math or physics and works hard will succeed. The figure presents actual outputs and measurements: LLM-generated logical variations (left), measured PCFG rule frequencies (center), and computed probability distributions (right). The calculated uncertainty metrics are derived from the observed PCFG patterns and successfully predict formalization uncertainty. No synthetic or simulated data is used. underlying CFG, its probability under is µG(w) = (cid:80) rπ p(r), where Π(w) represents the set of all leftmost derivations of from S. It is important to note that PCFG defines consistent probability measure (i.e., (cid:80) wL(G) µG(w) = 1) if and only if the spectral radius of its moment matrix MG is less than or equal to 1. This condition ensures that probabilities are well-defined and sum to one across the entire language generated by G. πΠ(w) p(π) = (cid:80) πΠ(w) (cid:81) Approximation: To connect the theoretical LLM distribution µT,θ,SM with tractable probabilistic model, we estimate parameters for PCFG. We use the SMT-LIB v2 grammar GSM = (VSM , ΣSM , RSM , SSM ) as its structural basis. We now generate SMT-LIB program samples PN = {P1, . . . , PN } from the target LLM (parameterized by θ) and parse them using GSM . This yields set of parse trees Π(PN ) from the successfully parsed programs. From each parse tree π Π(PN ), we identify and record every applied production rule = (A β) RSM . This record typically includes the rule itself, its source program identifier, structural context (such as depth), and optionally, the corresponding source text mapping for qualitative analysis. This data collection also allows for extracting richer contextual features than those used by standard Maximum Likelihood Estimation for estimating the rule probability function : RSM [0, 1] from these rule application frequencies. Maximum Likelihood Estimation (MLE) is used to estimate rule probabilities p(r) using counts from Π(PN ). Given total application counts C(r) for rule = (A β) and C(A) = (cid:80) C(r) for its left-hand side (LHS) non-terminal (where RA = {r RSM left(r) = A}), the MLE is its relative frequency ˆpM LE(r) = C(r)/C(A), defined if C(A) > 0. If C(A) = 0, rules in RA are assigned uniform probability 1/RA. For independent and identically distributed (i.i.d.) samples PN from µT,θ,SM , these estimated probabilities ˆpN (r) converge almost surely (a.s.) to p(r) as . The limits p(r) are the parameters of the GSM -based PCFG that is closest in Kullback-Leibler (KL) divergence to the true distribution µT,θ,SM (i.e., = argminp DKL(µT,θ,SM µG(p))). For finite , additive (Lidstone) smoothing with βs > 0 (e.g., βs = 1 for Laplace smoothing) addresses problematic zero counts where C(r) = 0 but C(A) > 0, yielding ˆp(βs) (r) = (C(r) + βs)/(C(A) + βsRA). rRA Beyond this (smoothed) MLE, other PCFG estimation models exist. The Bayesian PCFG Model offers one such alternative. It interprets additive smoothing, using parameter α such that ˆp(α) (r) = (C(r) + α)/(C(A) + αRA), as computing the posterior mean. This is under symmetric Dirichlet prior, Dir(α, . . . , α), over rule choices for each non-terminal, where the concentration parameter α > 0 reflects the priors strength. Another approach is the Neural PCFG Model. This model utilizes neural network fϕ(r) to score rules = (A β). As alluded to in the Approximation sections discussion of data collection, this model can leverage richer contextual features. Probabilities are 3 rRA then defined as pNeural(r) = exp(fϕ(r))/ (cid:80) exp(fϕ(r)). Network parameters ϕ are trained by maximizing the log-likelihood of the corpus Π(PN ), enabling the capture of complex dependencies. Theorem 1 (Coverage Guarantee). Let µ be distribution on discrete sample space Σ, with Shannon entropy H(µ) = (cid:80) xΣ µ(x) log2 µ(x). Suppose we draw i.i.d. samples from µ. Then, for any measurable subset Σ with µ(A) = ϵ, the probability that none of the samples (cid:16) land in is at most exp , provided is sufficiently large. Equivalently, the probability of failing to sample at least one point in every region of mass ϵ is at most exp( ϵ/ 2H(µ)). Moreover, (cid:17) the largest ϵ for which this miss probability is itself at most ϵ satisfies ϵ = 2 H(µ) , where () is the Lambert -function. As grows large, ϵ 2 H(µ) at rate on the order of ln(N )/N . Proof is provided in the appendix. , which vanishes ϵ 2 H(µ) ln (cid:16) (cid:16) 2 H(µ) 2 H(µ) (cid:17) (cid:17) 2.1 Probabilistic Context-Free Grammar (PCFG) Derived Metrics We derive several PCFG metrics to quantify different facets of uncertainty, using established notation (e.g., RA for the set of rules expanding non-terminal A). Static Metrics for Grammar Structure and Complexity Basic structural properties of the grammar GSM provide foundational understanding of its scale and potential complexity. These include the number of non-terminals (VSM ) and rules (RSM ), the average number of rules per nonterminal ( RSM β, where β denotes the length of β). Further metrics cover the maximum branching factor (maxAVSM RA), and the detection of various forms of recursion (e.g., left-recursion Aγ or right-recursion γA). These metrics collectively characterize the grammars static architecture. VSM ), and the average right-hand side (RHS) length ( 1 RSM AβRSM (cid:80) Spectral Properties The spectral radius of the grammars mean matrix (often referred to as the Jacobian matrix in this context), RVSM VSM , offers insights into its recursive structure and complexity. An element Bji is the expected number of times non-terminal Aj appears on the righthand side (RHS) of production chosen for Ai: Bji = (cid:80) p(Ai β) count(Aj, β), where count(Aj, β) is Ajs occurrences in β. The spectral radius ρ(B) = max{λ det(B λI) = 0} is Bs maximum absolute eigenvalue. Typically, ρ(B) < 1 indicates proper grammar with finite expected derivation lengths, while ρ(B) 1 suggests potentially unbounded derivations or higher complexity, contributing to structural uncertainty. This spectral radius is also key component of the NSUI metric (introduced later in this section). AiβRAi (cid:80) (cid:80) AβRA AβRA Information-Theoretic Measures Information theory provides principled ways to measure the uncertainty associated with probabilistic choices within the grammar. The Shannon Entropy per Nonterminal, for each VSM , quantifies the average uncertainty (in bits) in selecting production rule from RA: H(A) = (cid:80) p(A β) log2 p(A β) higher H(A) indicates greater uncertainty or variability in the expansions of A. The Rényi Entropy per Non-terminal, Hα(A), generalizes Shannon entropy and is parameterized by an order α 0. For α = 1: Hα(A) = 1 p(A β)α Key special cases include Shannon entropy (H1(A) = H(A) 1α log2 as α 1), max-entropy (H0(A) = log2 RA for α = 0, reflecting the number of choices), p(A β)2 for α = 2, sensitive to rule choice collision entropy (H2(A) = log2 repetition), and min-entropy (H(A) = log2 maxAβRA p(A β) for α , determined by the most probable rule). Calculating Rényi entropy for different α values (e.g., 0.5, 2) provides richer characterization of the uncertainty profile than Shannon entropy alone. The Overall Grammar Entropy is typically defined as the weighted average of the Shannon entropies of its non-terminals, H(A), where weights π(A) correspond to the stationary distribution or expected frequency of nonterminal in derivations starting from SSM : H(G) = (cid:80) π(A)H(A). The frequencies π(A) can be estimated iteratively. H(G) represents the average uncertainty per derivation step across the entire grammar. Perplexity, (G), measures how well the PCFG predicts derivations and is the exponentiated grammar entropy: (G) = 2H(G). It can be interpreted as the effective average number of choices the grammar presents at each derivation step, weighted by likelihood; lower perplexity indicates more predictable grammar. The KL divergence, DKL(pAUA) = log2 RAH(A), quantifies the inefficiency (in bits) of assuming uniform rule distribution (U (A β) = 1/RA) for non-terminal compared to using the true PCFG probabilities (p(A β)). AβRA AVSM 4 The overall grammar KL divergence from uniform, DKL(GU ) = (cid:80) quantifies the PCFGs deviation from maximum uncertainty. AVSM π(A)DKL(pAUA), Finally, we hypothesize novel composite metric, SU I(G), for probabilistic uncertainty and structural complexity. This metric, which ranges from 0 to 1, combines normalized grammar entropy with factor reflecting the grammars recursive structure (via its spectral radius ρ(B)). It is calculated as SU I(G) = Eratio Sf actor. The entropy ratio Eratio = H(G)/Hmax(G) [0, 1] uses the maximum grammar entropy Hmax(G) = (cid:80) π(A) log2 RA (assuming uniform rule choices). The spectral factor is Sf actor = ρ(B)/(1 + ρ(B)) [0, 1). The motivation was to link higher NSUI values to indicate greater probabilistic uncertainty via structural/recursive complexity. AVSM Rule Probability Distribution Metrics Analyzing the set of all rule probabilities = {p(A β) β RSM } involves computing descriptive statistics such as mean, median, minimum, maximum, standard deviation (σ(P)), skewness (γ1(P)), and kurtosis (γ2(P)). These statistics characterize the shape and spread of the learned probabilities. Fitting parametric distributions (e.g., Pareto, power-law) can further reveal structural patterns like Zipfian distributions, which are common in linguistic phenomena. Text SC reflects solution consistency (e.g., via majority vote) across multiple LLM textual outputs, while SMT SC measures it (e.g., via SMT solver agreement) across diverse LLM-generated SMT-LIB programs for the same prompt, adapting principles from [Wang et al., 2022]. We also implement four distinct ensemble predictors for enhanced uncertainty quantification. These are: (1) Ensemble Simple, an unweighted average of key subset of metrics; (2) Ensemble Average, comprehensive unweighted average of all metric scores; (3) Ensemble Weighted, where individual metric contributions are varied based on validation performance or theoretical importance; and (4) Ensemble ML, meta-machine learning model (e.g., logistic regression) trained on the vector of metric scores to predict errors. This approach aims to improve overall predictive accuracy, calibration, and robustness by combining varied uncertainty signals. Metrics for Evaluating Uncertainty-Based Error Detection To evaluate uncertainty quantification (UQ) methods for identifying prediction errors, we examine several facets: Error Discrimination utilizes the Area Under the Receiver Operating Characteristic Curve (AUROC) to assess if uncertainty scores distinguish correct from incorrect predictions; higher AUROC signifies better uncertaintyerror alignment. Selective Prediction Utility employs the Area Under the Risk-Coverage Curve (AURC) to measure practical risk mitigation via abstention (including analysis of optimal abstention percentages, associated error rates, and relative error reduction); lower AURC indicates effective error identification, improving performance on retained samples. Finally, Calibration Assessment evaluates the probabilistic reliability of confidence scores using metrics like Expected Calibration Error (ECE), Reliability Diagrams, and the Brier Score; lower ECE and Brier scores denote better calibration, where predicted confidence accurately reflects empirical correctness rates."
        },
        {
            "title": "3 Results",
            "content": "We have evaluated five frontier LLMs, namely o3-mini, DeepSeekR1 (with CoT enabled [Wei et al., 2022b]), DeepSeek-v3-04-21, Gemini Flash 2.0 & Lite (non-reasoning), on four datasets which are widely adopted and used for reasoning tasks; StrategyQA [Geva et al., 2021], ProntoQA [Saparov and He, 2023], ProofWriter[Tafjord et al., 2021] and FOLIO [Han et al., 2024]. From 5 LLM samples per question, answers were derived via: 1) Text: direct LLM output (intrinsic reasoning over text); 2) SMT: LLM-generated SMT-LIB solved by Z3 (autoformalization). Notably, SMT-LIB generation required significantly less effort (more syntactically valid programs in fewer attempts) and used dramatically fewer tokens per prompt compared to [Ganguly et al., 2024], while also offering multi-solver interoperability. On ProofWriter, task closely aligned with symbolic logic, SMT-based methods yielded substantial improvements for three models, particularly benefiting those that struggle with direct formal reasoning. Conversely, on ProntoQA and FOLIO, direct textual reasoning consistently outperformed SMT across most models, suggesting that for these QA tasks, the overhead introduced during autoformalization outweighs potential benefits. StrategyQA showed mixed results, with o3-mini slightly benefiting from SMT while other models performed better with direct reasoning. 5 The SMT approach systematically alters error profiles compared to direct reasoning, often trading precision for recall. For struggling models, autoformalization frequently increases recall dramatically while reducing precision, reflecting tendency to provide formal answers more often but introducing additional false positivesconsistent with LLMs documented proclivity toward proving satisfiability in [Ganguly et al., 2024]. On ProofWriter, where SMT generally helped, performance gains stemmed from simultaneous improvements in both precision and recall, indicating the approach successfully addressed fundamental reasoning errors. Conversely, on datasets where direct reasoning excelled, SMTs underperformance typically manifested as reduced recall, suggesting failures in the formalization process resulted in missed correct answers. Table 1: Benchmarking accuracy of frontier LLMs using direct text output (Text) versus SMT-LIB generation solved by Z3 (SMT). No approach universally outperforms the other across all models and datasets. Finer grained results are available in the supplementary material. ACCURACY StrategyQA SMT Text δ Text ProntoQA SMT δ Text ProofWriter SMT δ Text o3-mini DeepSeekv3 DeepSeek R1 Flash 2.0 Flash 2.0 Lite 0.7828 0.8292 0.8580 0.7188 0. 0.7980 0.6720 0.7760 0.5360 0.4500 -0.0152 0.1572 0.0820 0.1828 0.2260 1.0000 1.0000 0.9939 0.9820 0.9980 0.9980 0.4501 0.7440 0.9000 0.9980 0.0020 0.5499 0.2499 0.0820 0.0000 0.8893 0.8057 0.9423 0.4900 0. 0.9418 0.5800 0.4935 0.6660 0.7540 -0.0524 0.2257 0.4488 -0.1760 -0.3480 0.9450 0.9333 0.9252 0.9010 0.9017 FOLIO SMT 0.5000 0.5961 0.5200 0.5625 0.7321 δ 0.4450 0.3372 -0.4052 0.3385 0.1696 Our results reveal predominantly epistemic uncertainty in both reasoning approaches. Direct reasoning fails through knowledge gaps and procedural errors, while SMT introduces formalization errors when translating to formal specifications. This explains task-dependent performance: SMT benefits tasks with explicit premises (ProofWriter) by isolating deductive reasoning, while knowledge-intensive tasks (StrategyQA) expose formalization bottlenecks. These findings highlight the critical need for Uncertainty Quantification on LLM-generated formal artifacts to prevent upstream formalization errors from propagating through otherwise sound solvers. Table 2: Token-level Uncertainty quantification metrics and their results at detecting autoformalization errors w.r.t. ground truth for DeepSeek-v3-0324 across reasoning datasets. While conventional metrics (AUROC, ECE, Brier) show moderate performance, they inadequately capture the distinct epistemic uncertainties in formalization versus reasoning processes. Notably, no UQ method consistently excels across tasks . The uncertainty-aware abstention metrics reflect how the model can selectively answer questions by applying an optimal uncertainty threshold (Opt.Thresh) that minimizes error rate (Err@T) and maximizes error reduction (RelErrRed) compared to answering all questions.This suggests the need for specialized UQ approaches that explicitly model the distribution of formal artifacts. DeepSeekv3 is the only model we examined that provides token logprobs. StrategyQA ProntoQA ProofWriter FOLIO Entropy Perplexity Kurtosis Entropy Perplexity Kurtosis Entropy Perplexity Kurtosis Entropy Perplexity Kurtosis AUROC 0.5872 0.6179 0.6227 0.5622 0.6118 0.6078 0.5165 0.5893 0.5656 0.7001 0.5609 0.5548 ECE 0.1415 0.0802 0. 0.1395 0.1009 0.2390 0.1666 0.2430 0.1657 0.2101 0.2385 0.1761 Brier 0.2433 0.2218 0.3075 0.2685 0.2522 0. 0.2761 0.3021 0.2705 0.2465 0.2926 0.2428 AURC 0.2399 0.2218 0.2236 0.4585 0.4218 0.4265 0.3938 0.3214 0. 0.4737 0.5514 0.5560 Opt.T 0.0500 0.5000 0.5000 0.0500 0.0500 0.2000 0.0500 0.4000 0.4500 0.5000 0.0500 0. Err@T RelErrRed 0.3221 0.2520 0.2440 0.5408 0.5365 0.5102 0.4105 0.3633 0.3564 0.4767 0.6380 0. 0.0180 0.2317 0.2561 0.0166 0.0244 0.0722 0.0226 0.1349 0.1515 0.2679 0.0202 0.0296 3.1 Performance of Uncertainty Metrics We evaluated our uncertainty metrics in two distinct prediction tasks: (1) whether LLM-generated SMT programs, when executed by Z3, would yield the correct ground truth answer, and (2) whether the SMT output would be consistent with the models own natural language reasoning. It is important to note here that PCFG computation for uncertainty quantification imposes minimal computational overhead. Since we utilize the well-defined SMT-LIB grammar rather than learning it, parsers operate efficiently on the structured outputs. While we explored various estimation techniques (e.g., Bayesian 6 PCFG, Neural PCFG), Maximum Likelihood Estimation (MLE) proved to be both computationally efficient and sufficiently accurate for uncertainty modeling, aligning with established practices. Experiments for model and dataset combinations were chosen where performance gap was observed, with N=100 samples, thereby making UQ analysis meaningful, but where the SMT performance was not close to random guessing. Our argument here is that because we are relying on information within the FV artifacts, and those artifacts are not well-calibrated for the task (i.e., operating at the level of random guessing), we cannot extract information about failure from them. Task-Dependent Signal Dominance in SMT vs Ground Truth Prediction: Knowledge-Intensive Reasoning: For StrategyQA, cross-modal agreement metrics consistently dominated. O3-mini showed strong performance with grammar entropy (AUROC=0.7448, AURC=0.1113) and text consistency (AUROC=0.7369, AURC=0.1081). For DeepSeek-R1, text consistency substantially outperformed all pure PCFG metrics (AUROC=0.7835, AURC=0.0983). This indicates epistemic uncertainty in world knowledge as the primary correctness bottleneck as these cross-modal metrics effectively gauge if the SMT formalization aligns with the LLMs initial (potentially flawed) semantic interpretation. Premise-Explicit Reasoning: For ProofWriter, PCFG-derived metrics demonstrated exceptional discriminative power for ground truth prediction. O3-mini achieved near-perfect performance with grammar entropy (AUROC=0.9301, AURC=0.0008) and perplexity (AUROC=0.9194, AURC=0.0008). This confirms procedural epistemic uncertainty dominates in formal reasoning tasks, where an LLMs primary challenge shifts from knowledge recall to the correct application of formal rules. Thus, PCFG metrics assessing structural variance in the SMT-LIB output can identify such deductive missteps with high precisiono3-minis AURC of 0.0008 using grammar entropy, for instance, enables filtering nearly all errors by abstaining on minute fraction of outputs. Table 3: Uncertainty quantification metrics for predicting ground truth correctness via PCFGs of LLM-generated SMT programs. Results show AUROC, ECE, Brier, and AURC across models and reasoning tasks, with ensemble methods consistently outperforming individual metrics. Color intensity indicates performance strength (darker green = better) StrategyQA ProofWriter Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple o3-mini DeepSeek-v3Gemini 2.0 Flash Lite o3-mini AUROC ECE Brier AURC AUROC ECE Brier AURC AUROC ECE Brier AURC AUROC ECE Brier AURC 0.5380 0.3185 0.2869 0.1405 0.5934 0.3888 0.3182 0.1267 0.5164 0.3080 0.2797 0.1573 0.5243 0.3186 0.2642 0.1514 0.5996 0.4102 0.3368 0.1285 0.5933 0.4401 0.3581 0.1258 0.5417 0.3503 0.3045 0.1420 0.5177 0.3943 0.3426 0.1548 0.5011 0.5048 0.4157 0.1578 0.5011 0.3930 0.3172 0.1578 0.5167 0.4838 0.4215 0.1672 0.5549 0.2422 0.2315 0.1370 0.5840 0.2790 0.2656 0.1301 0.5631 0.3413 0.2906 0.1480 0.5745 0.2189 0.2293 0.1355 0.5838 0.4368 0.3713 0.1301 0.5144 0.4474 0.3795 0.1559 0.5844 0.4511 0.3779 0.1313 0.5044 0.1437 0.1913 0.1726 0.5525 0.2283 0.2419 0.1376 0.7364 0.3535 0.2751 0.1031 0.6140 0.3922 0.3192 0.1240 0.7235 0.3327 0.2539 0.1035 0.7631 0.2897 0.2229 0.0823 0.6476 0.3867 0.3039 0.1071 0.7087 0.1575 0.2302 0.2097 0.6122 0.1601 0.2641 0.2497 0.5723 0.1393 0.2322 0.2878 0.5997 0.0781 0.2191 0.2672 0.6195 0.1622 0.2679 0.2429 0.6126 0.1623 0.2626 0.2517 0.6851 0.0473 0.2099 0.2271 0.5311 0.1336 0.2538 0.3306 0.6800 0.0992 0.2236 0.2365 0.6800 0.0686 0.2148 0.2365 0.6115 0.1329 0.2469 0.2547 0.6197 0.1109 0.2252 0.2583 0.6021 0.0902 0.2260 0.2616 0.5122 0.1753 0.2712 0.3279 0.6180 0.1450 0.2270 0.2688 0.6021 0.1811 0.2534 0.2616 0.5281 0.1251 0.2573 0.3116 0.6036 0.1431 0.2489 0.2610 0.5787 0.1720 0.2600 0.2754 0.6017 0.2874 0.3048 0.2882 0.6203 0.2318 0.2745 0.2513 0.6795 0.1214 0.2077 0.2182 0.7211 0.1257 0.2135 0.1989 0.7709 0.0877 0.1968 0.1847 0.6401 0.1763 0.2514 0.2483 0.7448 0.3058 0.2340 0.1113 0.5589 0.3107 0.2862 0.1811 0.6428 0.2485 0.2385 0.1471 0.6334 0.2436 0.2539 0.1250 0.5175 0.3303 0.2997 0.1977 0.5973 0.3398 0.3042 0.1634 0.6649 0.3553 0.2935 0.1297 0.5385 0.3283 0.3028 0.1834 0.6334 0.2173 0.2364 0.1319 0.6334 0.2892 0.2747 0.1319 0.5111 0.3540 0.3188 0.2006 0.5548 0.2117 0.2385 0.1855 0.5737 0.2400 0.2415 0.1752 0.5350 0.6141 0.5651 0.1979 0.5181 0.1500 0.1997 0.1990 0.5740 0.3161 0.2836 0.1752 0.5291 0.3995 0.3517 0.1811 0.5833 0.3178 0.2850 0.1689 0.5659 0.3948 0.3420 0.1785 0.7369 0.1604 0.1603 0.1081 0.7416 0.1523 0.1609 0.1051 0.7622 0.3724 0.2916 0.1103 0.7657 0.1738 0.1617 0.1099 0.7850 0.2090 0.1756 0.1013 0.6702 0.2055 0.2104 0.1410 0.9301 0.4419 0.2500 0.0008 0.9194 0.5358 0.3515 0.0008 0.5108 0.5167 0.3260 0.0074 0.5645 0.5710 0.3843 0.0084 0.8871 0.5405 0.3598 0.0013 0.9301 0.4724 0.2879 0.0008 0.9086 0.7198 0.5550 0.0013 0.5860 0.5714 0.3764 0.0055 0.7473 0.3458 0.2247 0.0032 0.7473 0.3545 0.2305 0.0032 0.8011 0.4267 0.2397 0.0019 0.5108 0.4186 0.2201 0.0084 0.9301 0.5393 0.3499 0.0008 0.8011 0.6535 0.5086 0.0026 0.5914 0.2979 0.1377 0.0055 0.9301 0.4945 0.3034 0.0008 0.5108 0.5555 0.3723 0.0074 0.9301 0.4923 0.2987 0.0008 0.5860 0.5107 0.3115 0.0055 0.8990 0.0423 0.0280 0.0020 0.7121 0.8501 0.7764 0.0025 0.9949 0.3356 0.1414 0.0005 0.9785 0.4612 0.2566 0.0003 0.9892 0.0572 0.0280 0.0003 0.9355 0.4419 0.2582 0.0008 Predicting SMT-Text Consistency: Arithmetic Reasoning: On ProntoQA with Gemini Flash 2.0, SMT consistency achieved remarkable performance in predicting text-SMT alignment (AUROC=0.9291, AURC=0.0084), while spectral radius (AUROC=0.6425, AURC=0.0379) emerged as the only effective structural metric. This isolates recursive complexity as distinct source of uncertainty in arithmetic formalization, as excessively convoluted SMT structures, indicated by high spectral radius, risk diverging from the models more direct textual reasoning on numerical problems. 7 Model-Specific Patterns: For Gemini Flash 2.0 Lite on StrategyQA, kurtosis of the rule distribution was the strongest predictor of SMT-Text consistency (AUROC=0.8695). Analysis revealed distinctive switching\" behavior between minimal and verbose SMT patterns, producing bimodal distribution with heavy tailsa novel diagnostic for capacity limitations in formalization, whereby such stylistic oscillations between overly terse or verbose SMT, captured by kurtosis, make the resulting formal artifact more prone to misalign with the intended textual meaning. Table 4: Uncertainty metrics based on PCFGs for predicting consistency between LLMs SMT formalization and its natural language reasoning. Task-specific uncertainty patterns emerge: rule distribution kurtosis dominates for StrategyQA (AUROC=0.8695), while different metrics excel for each model-task combination, highlighting the multifaceted nature of formalization uncertainty. DeepSeek R1 StrategyQA DeepSeekv3Gemini 2.0 Flash Lite ProofWriter o3-mini Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC ECE Brier AURC AUROC ECE Brier AURC AUROC ECE Brier AURC AUROC ECE Brier AURC 0.8602 0.4419 0.2542 0.0013 0.9032 0.4429 0.2616 0.0013 0.6667 0.5167 0.3238 0.0039 0.9355 0.4077 0.2172 0.0008 0.9032 0.4382 0.2580 0.0013 0.8925 0.5063 0.3246 0.0013 0.9355 0.2589 0.1029 0.0008 0.9677 0.4074 0.2082 0.0003 0.5269 0.6329 0.5061 0.0084 0.5269 0.6243 0.4953 0.0084 0.6505 0.5520 0.3650 0.0047 0.5108 0.4186 0.2201 0.0064 0.8011 0.4394 0.2554 0.0026 0.5054 0.6535 0.5116 0.0074 0.7419 0.6809 0.5100 0.0032 0.8011 0.4842 0.2971 0.0026 0.8710 0.4232 0.2392 0.0013 0.8172 0.4864 0.2964 0.0019 0.9462 0.5107 0.3056 0.0008 0.7050 0.9352 0.9023 0.0030 0.7100 0.8600 0.7863 0.0030 0.9300 0.3560 0.1741 0.0007 1.0000 0.4231 0.2375 0.0003 1.0000 0.0496 0.0199 0.0003 0.6667 0.4419 0.2661 0.0039 0.7609 0.4617 0.2968 0.0216 0.6211 0.3789 0.2640 0.0361 0.5776 0.4408 0.2855 0.0443 0.5963 0.2529 0.1433 0.0462 0.6242 0.3980 0.2746 0.0378 0.6149 0.3942 0.2755 0.0376 0.7174 0.3994 0.2341 0.0262 0.5217 0.5047 0.3529 0.0543 0.5481 0.1533 0.0927 0.0640 0.5481 0.2067 0.1166 0.0640 0.5264 0.5679 0.4237 0.0557 0.6087 0.3083 0.1839 0.0396 0.7034 0.4068 0.2532 0.0273 0.5637 0.2491 0.1566 0.0544 0.6801 0.3325 0.2042 0.0324 0.7034 0.5352 0.3733 0.0273 0.6056 0.6755 0.5361 0.0413 0.6848 0.4800 0.3260 0.0309 0.5311 0.2521 0.1588 0.0534 0.8245 0.1002 0.0751 0.0155 0.7570 0.2062 0.1373 0.0268 0.8183 0.4695 0.3058 0.0180 0.8494 0.3256 0.1711 0.0155 0.8245 0.3084 0.2003 0.0170 0.6957 0.4363 0.2748 0.0316 0.7354 0.3058 0.2551 0.0970 0.6721 0.3282 0.2718 0.1205 0.5335 0.1195 0.1780 0.1633 0.5973 0.1768 0.1919 0.1411 0.6799 0.3403 0.2808 0.1160 0.6667 0.3333 0.2751 0.1223 0.6353 0.1309 0.1738 0.1247 0.6154 0.4091 0.3307 0.1446 0.7034 0.1254 0.1580 0.1206 0.7034 0.1896 0.1752 0.1206 0.5549 0.2271 0.2455 0.1480 0.5675 0.2025 0.2077 0.1485 0.6034 0.1393 0.1854 0.1399 0.5208 0.1254 0.1818 0.1972 0.5937 0.1563 0.1920 0.1457 0.6034 0.3210 0.2742 0.1399 0.6281 0.2226 0.2221 0.1445 0.5986 0.3057 0.2619 0.1406 0.6600 0.0731 0.1576 0.1256 0.5778 0.1874 0.2008 0.1754 0.7116 0.1662 0.1909 0.1054 0.7064 0.1876 0.1831 0.0983 0.7709 0.2340 0.1971 0.0798 0.8517 0.1861 0.1703 0.0573 0.6727 0.3021 0.2567 0. 0.6622 0.1277 0.2095 0.5689 0.7212 0.3255 0.2849 0.5273 0.5486 0.2387 0.2630 0.6341 0.6741 0.1195 0.1624 0.5221 0.7624 0.3192 0.2624 0.5037 0.6994 0.2766 0.2619 0.5438 0.5982 0.3401 0.3083 0.5900 0.5511 0.1641 0.2511 0.6346 0.6538 0.0943 0.1677 0.5316 0.6538 0.1648 0.1703 0.5316 0.5166 0.4180 0.3958 0.6509 0.5749 0.4256 0.3818 0.6252 0.6565 0.2913 0.2761 0.5923 0.6014 0.4855 0.4420 0.6098 0.5818 0.5167 0.4747 0.6313 0.6565 0.2197 0.2280 0.5923 0.7183 0.3136 0.2807 0.5455 0.6796 0.1783 0.2199 0.5720 0.8695 0.3187 0.2412 0.4448 0.5350 0.2788 0.2616 0.6064 0.7505 0.5380 0.4357 0.4822 0.7927 0.1531 0.1702 0.4848 0.8070 0.1673 0.1632 0.4718 0.7946 0.1308 0.1592 0.4784 0.7584 0.0796 0.1568 0.4929 Ablation Study Results PCFG spectral radius from LLM-generated SMT-LIB programs consistently decreases with sampling temperature, as broader exploration diversifies rule selections, reducing fixation on recursive productions that heavily influence moment matrix eigenvalues. Probability mass spreads more uniformly across production alternatives, diminishing single recursive pattern dominance and thus lowering the mean matrixs maximum absolute eigenvalue. Notably, grammatical properties lack sharp phase transitions across temperature ranges; derived PCFGs show smooth, monotonic changes in spectral and information-theoretic characteristics, implying continuous, rather than abrupt, generative response to temperature. Non-terminal expansion distributions shift from concentrated to broader with increasing temperature, though this plateaus, indicating finite exploration capacity, possibly constrained by inherent model biases or the grammars finite structure. The striking consistency of these spectral-temperature curves across diverse LLMs points to fundamental, universal mechanism by which these models navigate the coherence-diversity trade-off when generating structured formal languages. Finally, our fine-grained localized entropy within PCFG production rules surpasses global or non-grammatical standard techniques in error prediction, confirming that granular structural uncertainty in specific grammatical constructs directly flags component-level semantic error likelihood, offering more precise diagnostics. Discussion Our analysis reveals fundamental insight: the syntactic atypicality (e.g., in PCFG rule entropy or usage kurtosis) of LLM-generated formal artifacts serves as powerful signal for semantic errors, reminiscent of OOD detection [Ganguly et al., 2025]. When LLMs correctly understand logical relationships, they consistently produce high-probability rule sequences, whereas semantic misunderstandings manifest as statistical anomaliescreating distinctive \"syntactic fingerprints\" of reasoning failure that enable our exceptional error detection (AUROC=0.9301 on ProofWriter). This typicality-based approach transcends architectures, its PCFG metric rankings consistently capturing intrinsic difficulties like formalizing ambiguous language across diverse models. However, the relationship between typicality and correctness isnt straightforward; metrics with superior discriminative ability often exhibit poor calibration (ECE=0.4419), indicating anomaly magnitude doesnt linearly predict error probabilitynecessitating calibration-aware fusion, perhaps by integrating consistency signals. Even more revealing is asymmetric self-consistency (e.g., Gemini/ProntoQA: 8 SMT AUROC=0.9291 vs. text AUROC=0.5108), suggesting LLMs may use distinct, imperfectly aligned formal versus textual reasoning pathways, not just translate unified process. Such insights shift neurosymbolic design from translation-focus to pathway-alignment and grounding, e.g., via joint training, as SMT syntactic typicality alone is insufficient if its pathway misaligns with textual reasoning."
        },
        {
            "title": "4 Related Works",
            "content": "Formal Reasoning with LLMs LLMs show proficiency in formal reasoning [Welleck et al., 2022a, Chen et al., 2022], but face challenges including hallucination, uncertainty expression [Lin et al., 2022a], self-verification [Hou et al., 2023], and reasoning opacity [Wei et al., 2022b]. Hybrid approaches combine LLMs with formal tools but often overlook model uncertainty. For autoformalization, early sequence-to-sequence models [Wang et al., 2018, 2020] evolved into LLM-based approaches [Wu et al., 2022, Agrawal et al., 2022, Gadgil et al., 2022, Murphy et al., 2024], with structured methods [Jiang et al., 2023b, Zhao et al., 2024] combining LLMs with ATPs, and various applications [Liu et al., 2023, Pan et al., 2023, Olausson et al., 2023, Ye et al., 2023, Zhou et al., 2024, Huang et al., 2024a, Xin et al., 2024a, Jiang et al., 2024, Quan et al., 2024, Xin et al., 2024b]. Proofstep generation advanced from classification [Whalen, 2016, Huang et al., 2019, Bansal et al., 2019] to language modeling [Polu and Sutskever, 2020, First et al., 2023, Wang et al., 2024, Welleck et al., 2022b, Jiang et al., 2022], with recent work exploring zero-shot capabilities [Zhang et al., 2023, Yousefzadeh and Cao, 2023, Scheidt, 2023, Frieder et al., 2023a,b,c, Zhang et al., 2024a] and formal proof generation [Zheng et al., 2024, Xin et al., 2024a, Huang et al., 2024a, Thakur et al., 2024]. Proof search strategies include supervised learning [Loos et al., 2017, Chvalovsk`y et al., 2019], reinforcement learning [Kusumoto et al., 2018, Crouse et al., 2021, Piepenbrock et al., 2021], MCTS [Wu et al., 2021, Lample et al., 2022, Wang et al., 2023a], and language-agent methods [Thakur et al., 2024, An et al., 2024]. Uncertainty in LLM Reasoning Research explores various uncertainty estimation approaches in language models: information-theoretic methods using entropy [Kadavath et al., 2022, Kuhn et al., 2023, Duan et al., 2024], perplexity [Mora-Cross and Calderon-Ramirez, 2024, Margatina et al., 2023], and mutual information [Malinin, 2019, Wimmer et al., 2023, Depeweg, 2019, Ash, 1965]; ensemble strategies like MC Dropout [Srivastava et al., 2014, Gal and Ghahramani, 2016a, Lakshminarayanan et al., 2017], Deep Ensembles [Fadeeva et al., 2023, Lakshminarayanan et al., 2017], and BatchEnsemble [Gal and Ghahramani, 2016b, Lakshminarayanan et al., 2017, Wen et al., 2020] for hallucination detection [Arteaga et al., 2024]; consistency techniques evaluating output agreement [Wang et al., 2023b, Cole et al., 2023, Huang et al., 2024b, Zhang et al., 2024b, Lakshminarayanan et al., 2017, Gawlikowski et al., 2023, Manakul et al., 2023, Chen and Mueller, 2024]; similarity-based methods [Lin et al., 2024]; Bayesian approaches including BNNs [Shridhar et al., 2019, Blundell et al., 2015], variational inference [Graves, 2011, Jordan et al., 1999, Kullback and Leibler, 1951], Gaussian processes [Iwata and Ghahramani, 2017, Liu et al., 2020], and MCMC [Xiao and Wang, 2018]; and language-based methods extracting uncertainty from verbalizations [Cosmides and Tooby, 1996, Lin et al., 2022b, Tian et al., 2023, Xiong et al., 2024, Kojima et al., 2022, Groot and Valdenegro-Toro, 2024]. Our work models implicit uncertainty in distributions over multiple formal outputs rather than relying on individual response signals. Verification and Reasoning Uncertainty DTV [Zhou et al., 2024], SAT-LM [Ye et al., 2023], and related approaches [Quan et al., 2024] connect LLMs with formal verification, while latent space methods [Lee et al., 2020, Wu and Wu, 2021] complement uncertainty estimation research [Kadavath et al., 2022, Lin et al., 2022b]. PCFGs, which add probabilities to CFGs, have applications in NLP [Manning and Schutze, 1999], bioinformatics [Durbin et al., 1998], and program analysis [Alur et al., 2014], along with enabling probabilistic analysis for LLM generated DSL programs[Barke et al., 2024]. Our work extends PCFG inference [De la Higuera, 2010] to verification artifacts."
        },
        {
            "title": "5 Conclusion",
            "content": "Our research presents PCFG-based framework for SMT-LIB UQ, establishing that syntactic atypicalities in LLM-generated formal artifacts, previously underexploited, serve as potent, quantifiable signals of underlying semantic errors. Our evaluations revealed nuanced LLM behaviorstaskdependent uncertainty responses, localized PCFG entropys diagnostic power, and asymmetric 9 self-consistency suggesting distinct, imperfectly aligned formal versus textual reasoning pathways. Building on these discoveries, we introduced novel uncertainty taxonomy and lightweight, modelagnostic signal fusion technique that improves metric synergy and calibration. Applied together, this PCFG framework and fusion strategy achieve substantial error rate reductions via selective verification, offering an empirically validated methodology to significantly enhance LLM reliability in formal verification workflows."
        },
        {
            "title": "References",
            "content": "Michael Huth and Mark Ryan. Logic in Computer Science: Modelling and reasoning about systems. Cambridge university press, 2004. Edmund Clarke, Thomas Henzinger, Helmut Veith, Roderick Bloem, et al. Handbook of model checking, volume 10. Springer, 2018. Jim Woodcock, Peter Gorm Larsen, Juan Bicarregui, and John Fitzgerald. Formal methods: Practice and experience. ACM computing surveys (CSUR), 41(4):136, 2009. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. Mistral 7b, 2023a. URL https://arxiv.org/ abs/2310.06825. Bairu Hou, Yujian Liu, Kaizhi Qian, Jacob Andreas, Shiyu Chang, and Yang Zhang. Decomposing uncertainty for large language models through input clarification ensembling. arXiv preprint arXiv:2311.08718, 2023. Debargha Ganguly, Srinivasan Iyengar, Vipin Chaudhary, and Shivkumar Kalyanaraman. PROOF OF THOUGHT : Neurosymbolic program synthesis allows robust and interpretable reasoning. In The First Workshop on System-2 Reasoning at Scale, NeurIPS24, 2024. URL https://openreview. net/forum?id=Pxx3r14j3U. Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang Wang. Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. In Findings of the Association for Computational Linguistics: EMNLP, 2023. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022a. Wenhu Chen, Xueguang Ma, Xinyi Wang, and William Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022. Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022b. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use laptop? question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346361, 2021. doi: 10.1162/tacl_a_00370. URL https://aclanthology.org/2021.tacl-1.21/. Abulhair Saparov and He He. Language models are greedy reasoners: systematic formal analysis of chain-of-thought. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=qFVVBzXxR2V. Oyvind Tafjord, Bhavana Dalvi Mishra, and Peter Clark. ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language. In Findings of the Association for Computational Linguistics: ACL-IJCNLP, 2021. Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alexander Wardle-Solano, Hannah Szabó, Ekaterina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander Fabbri, Wojciech Maciej Kryscinski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying, Arman Cohan, and Dragomir Radev. FOLIO: Natural language reasoning with first-order logic. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 2201722031, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024. emnlp-main.1229. URL https://aclanthology.org/2024.emnlp-main.1229/. Debargha Ganguly, Warren Richard Morningstar, Andrew Seohwan Yu, and Vipin Chaudhary. Forte In The Thirteenth International : Finding outliers with representation typicality estimation. Conference on Learning Representations, 2025. URL https://openreview.net/forum?id= 7XNgVPxCiA. Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, and Yejin Choi. Naturalprover: Grounded mathematical proof generation with language models. Advances in Neural Information Processing Systems, 35:49134927, 2022a. Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in words. arXiv preprint arXiv:2205.14334, 2022a. Qingxiang Wang, Cezary Kaliszyk, and Josef Urban. First Experiments with Neural Translation of Informal to Formal Mathematics. In Proceedings of the International Conference on Intelligent Computer Mathematics, 2018. Qingxiang Wang, Chad Brown, Cezary Kaliszyk, and Josef Urban. Exploration of Neural Machine Translation in Autoformalization of Mathematics in Mizar. In Proceedings of the ACM SIGPLAN International Conference on Certified Programs and Proofs, 2020. Yuhuai Wu, Albert Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with Large Language Models. In Proceedings of the International Conference on Neural Information Processing Systems, 2022. Ayush Agrawal, Siddhartha Gadgil, Navin Goyal, Ashvni Narayanan, and Anand Tadipatri. Towards Mathematics Formalisation Assistant using Large Language Models. arXiv preprint arXiv:2211.07524, 2022. Siddhartha Gadgil, Anand Rao Tadipatri, Ayush Agrawal, Ashvni Narayanan, and Navin Goyal. Towards Automating Formalisation of Theorem Statements using Large Language Models. In International Conference on Neural Information Processing Systems Workshop on MATH-AI, 2022. Logan Murphy, Kaiyu Yang, Jialiang Sun, Zhaoyu Li, Anima Anandkumar, and Xujie Si. Autoformalizing Euclidean Geometry. In Proceedings of the International Conference on Machine Learning, 2024. 11 Albert Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample. Draft, Sketch, and Prove: Guiding Formal Theorem In Proceedings of the International Conference on Learning Provers with Informal Proofs. Representations, 2023b. Xueliang Zhao, Wenda Li, and Lingpeng Kong. Subgoal-Based Demonstration Learning for Formal Theorem Proving. In Proceedings of the International Conference on Machine Learning, 2024. Chengwu Liu, Jianhao Shen, Huajian Xin, Zhengying Liu, Ye Yuan, Haiming Wang, Wei Ju, Chuanyang Zheng, Yichun Yin, Lin Li, et al. FIMO: Challenge Formal Dataset for Automated Theorem Proving. arXiv preprint arXiv:2309.04295, 2023. Theo Olausson, Alex Gu, Benjamin Lipkin, Cedegao Zhang, Armando Solar-Lezama, Joshua Tenenbaum, and Roger Levy. LINC: Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2023. Xi Ye, Qiaochu Chen, Isil Dillig, and Greg Durrett. SATLM: Satisfiability-Aided Language ModIn Proceedings of the International Conference on Neural els using Declarative Prompting. Information Processing Systems, 2023. Jin Peng Zhou, Charles Staats, Wenda Li, Christian Szegedy, Kilian Weinberger, and Yuhuai Wu. Dont Trust: VerifyGrounding LLM Quantitative Reasoning with Autoformalization. In Proceedings of the International Conference on Learning Representations, 2024. Yinya Huang, Xiaohan Lin, Zhengying Liu, Qingxing Cao, Huajian Xin, Haiming Wang, Zhenguo Li, Linqi Song, and Xiaodan Liang. MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data. In Proceedings of the International Conference on Learning Representations, 2024a. Huajian Xin, Haiming Wang, Chuanyang Zheng, Lin Li, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, et al. LEGO-Prover: Neural Theorem Proving with Growing Libraries. In Proceedings of the International Conference on Learning Representations, 2024a. Dongwei Jiang, Marcio Fonseca, and Shay Cohen. LeanReasoner: Boosting Complex Logical Reasoning with Lean. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2024. Xin Quan, Marco Valentino, Louise Dennis, and André Freitas. Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving. arXiv preprint arXiv:2405.01379, 2024. Huajian Xin, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, and Xiaodan Liang. DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data. arXiv preprint arXiv:2405.14333, 2024b. Daniel Whalen. Holophrasm: Neural Automated Theorem Prover for Higher-Order Logic. arXiv preprint arXiv:1608.02644, 2016. Daniel Huang, Prafulla Dhariwal, Dawn Song, and Ilya Sutskever. GamePad: Learning Environment for Theorem Proving. In Proceedings of the International Conference on Learning Representations, 2019. Kshitij Bansal, Sarah M. Loos, Markus Norman Rabe, Christian Szegedy, and Stewart Wilcox. HOList: An Environment for Machine Learning of Higher Order Logic Theorem Proving. In Proceedings of the International Conference on Machine Learning, 2019. Stanislas Polu and Ilya Sutskever. Generative Language Modeling for Automated Theorem Proving. arXiv preprint arXiv:2009.03393, 2020. Emily First, Markus Rabe, Talia Ringer, and Yuriy Brun. Baldur: Whole-Proof Generation and Repair with Large Language Models. In Proceedings of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2023. 12 Haiming Wang, Huajian Xin, Zhengying Liu, Wenda Li, Yinya Huang, Jianqiao Lu, Zhicheng Yang, Jing Tang, Jian Yin, Zhenguo Li, et al. Proving Theorems Recursively. arXiv preprint arXiv:2405.14414, 2024. Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, and Yejin Choi. NaturalProver: Grounded Mathematical Proof Generation with Language Models. In Proceedings of the International Conference on Neural Information Processing Systems, 2022b. Albert Jiang, Wenda Li, Szymon Tworkowski, Konrad Czechowski, Tomasz Odrzygózdz, Piotr Miłos, Yuhuai Wu, and Mateja Jamnik. Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers. In Proceedings of the International Conference on Neural Information Processing Systems, 2022. Shizhuo Dylan Zhang, Talia Ringer, and Emily First. Getting More out of Large Language Models for Proofs. In Proceedings of the Conference on Artificial Intelligence and Theorem Proving, 2023. Roozbeh Yousefzadeh and Xuenan Cao. Large Language Models Understanding of Math: Source Criticism and Extrapolation. arXiv preprint arXiv:2311.07618, 2023. Gregor vom Scheidt. Experimental Results from Applying GPT-4 to An Unpublished Formal Language. arXiv preprint arXiv:2305.12196, 2023. Simon Frieder, Julius Berner, Philipp Petersen, and Thomas Lukasiewicz. Large Language Models for Mathematicians. arXiv preprint arXiv:2312.04556, 2023a. Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, and Julius Berner. Mathematical Capabilities of ChatGPT. In Proceedings of the International Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2023b. Simon Frieder, Martin Trimmel, Rashid Alawadhi, and Klaus Gy. LLM vs ITP. In International Conference on Neural Information Processing Systems Workshop on MATH-AI, 2023c. Lichen Zhang, Shuai Lu, and Nan Duan. Selene: Pioneering Automated Proof in Software Verification. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2024a. Chuanyang Zheng, Haiming Wang, Enze Xie, Zhengying Liu, Jiankai Sun, Huajian Xin, Jianhao Shen, Zhenguo Li, and Yu Li. Lyra: Orchestrating Dual Correction in Automated Theorem Proving. Transactions on Machine Learning Research, 2024. Amitayush Thakur, George Tsoukalas, Yeming Wen, Jimmy Xin, and Swarat Chaudhuri. An InContext Learning Agent for Formal Theorem-Proving. arXiv preprint arXiv:2310.04353, 2024. Sarah Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. Deep Network Guided Proof Search. In Proceedings of the International Conference on Logic for Programming, Artificial Intelligence and Reasoning, 2017. Karel Chvalovsk`y, Jan Jakubüv, Martin Suda, and Josef Urban. ENIGMA-NG: Efficient Neural and Gradient-Boosted Inference Guidance for E. In Proceedings of the International Conference on Automated Deduction, 2019. Mitsuru Kusumoto, Keisuke Yahata, and Masahiro Sakai. Automated Theorem Proving in Intuitionistic Propositional Logic by Deep Reinforcement Learning. arXiv preprint arXiv:1811.00796, 2018. Maxwell Crouse, Ibrahim Abdelaziz, Bassem Makni, Spencer Whitehead, Cristina Cornelio, Pavan Kapanipathi, Kavitha Srinivas, Veronika Thost, Michael Witbrock, and Achille Fokoue. Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021. Jelle Piepenbrock, Tom Heskes, Mikoláš Janota, and Josef Urban. Learning Equational Theorem Proving. In Proceedings of the Conference on Artificial Intelligence and Theorem Proving, 2021. 13 Minchao Wu, Michael Norrish, Christian Walder, and Amir Dezfouli. TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning. Proceedings of the International Conference on Neural Information Processing Systems, 2021. Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux, Aurelien Rodriguez, Amaury Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet. Hypertree Proof Search for Neural Theorem In Proceedings of the International Conference on Neural Information Processing Proving. Systems, 2022. Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen, Yichun Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, et al. DT-Solver: Automated Theorem Proving with Dynamic-Tree Sampling Guided by Proof-level Value Function. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2023a. Chenyang An, Zhibo Chen, Qihao Ye, Emily First, Letian Peng, Jiayun Zhang, Zihan Wang, Sorin Lerner, and Jingbo Shang. Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving. arXiv preprint arXiv:2404.07382, 2024. Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. arXiv preprint arXiv:2302.09664, 2023. Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias StengelEskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. Gtbench: Uncovering the strategic reasoning limitations of llms via game-theoretic evaluations. arXiv preprint arXiv:2402.12348, 2024. Maria Mora-Cross and Saul Calderon-Ramirez. Uncertainty estimation in large language models to support biodiversity conservation. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track), pages 368378, 2024. Katerina Margatina, Timo Schick, Nikolaos Aletras, and Jane Dwivedi-Yu. Active learning principles for in-context learning with large language models, 2023. URL https://arxiv.org/abs/2305. 14264. Andrey Malinin. Uncertainty estimation in deep learning with application to spoken language assessment. PhD thesis, University of Cambridge, 2019. Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, and Eyke Hüllermeier. Quantifying aleatoric and epistemic uncertainty in machine learning: Are conditional entropy and mutual information appropriate measures? In Robin J. Evans and Ilya Shpitser, editors, Proceedings of the ThirtyNinth Conference on Uncertainty in Artificial Intelligence, volume 216 of Proceedings of Machine Learning Research, pages 22822292. PMLR, 31 Jul04 Aug 2023. URL https://proceedings. mlr.press/v216/wimmer23a.html. Stefan Depeweg. Modeling epistemic and aleatoric uncertainty with bayesian neural networks and latent variables. 2019. URL https://api.semanticscholar.org/CorpusID:208224498. Robert Ash. Information theory. Dover Publications, 1965. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):19291958, 2014. Yarin Gal and Zoubin Ghahramani. Dropout as bayesian approximation: Representing model uncertainty in deep learning. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 10501059, New York, New York, USA, 2022 Jun 2016a. PMLR. URL https://proceedings.mlr.press/v48/gal16.html. Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017. 14 Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun, Artem Vazhentsev, Sergey Petrakov, Kirill Fedyanin, Daniil Vasilev, Elizaveta Goncharova, Alexander Panchenko, Maxim Panov, et al. Lmpolygraph: Uncertainty estimation for language models. arXiv preprint arXiv:2311.07383, 2023. Yarin Gal and Zoubin Ghahramani. Dropout as bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pages 10501059. PMLR, 2016b. Yeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: An alternative approach to efficient ensemble and lifelong learning, 2020. URL https://arxiv.org/abs/2002.06715. Gabriel Y. Arteaga, Thomas B. Schön, and Nicolas Pielawski. Hallucination detection in llms: Fast and memory-efficient finetuned models, 2024. URL https://arxiv.org/abs/2409.02976. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models, 2023b. URL https://arxiv.org/abs/2203.11171. Jeremy R. Cole, Michael J. Q. Zhang, Daniel Gillick, Julian Martin Eisenschlos, Bhuwan Dhingra, and Jacob Eisenstein. Selectively answering ambiguous questions, 2023. URL https://arxiv. org/abs/2305.14613. Hsiu-Yuan Huang, Zichen Wu, Yutong Yang, Junzhao Zhang, and Yunfang Wu. Unc-ttp: method for classifying llm uncertainty to improve in-context example selection, 2024b. URL https: //arxiv.org/abs/2408.09172. Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A. Malin, and Sricharan Kumar. Sac3: Reliable hallucination detection in black-box language models via semantic-aware cross-check consistency, 2024b. URL https://arxiv.org/abs/2311.01740. Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. survey of uncertainty in deep neural networks. Artificial Intelligence Review, 56(Suppl 1):15131589, 2023. Potsawee Manakul, Adian Liusie, and Mark J. F. Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models, 2023. URL https://arxiv.org/ abs/2303.08896. Jiuhai Chen and Jonas Mueller. Quantifying uncertainty in answers from any language model and enhancing their trustworthiness. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 51865200, Bangkok, Thailand, August 2024. Association for Computational Linguistics. URL https://aclanthology.org/2024.acl-long.283. Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. Generating with confidence: Uncertainty quantification for black-box large language models, 2024. URL https://arxiv.org/abs/2305.19187. Kumar Shridhar, Felix Laumann, and Marcus Liwicki. comprehensive guide to bayesian convolutional neural network with variational inference, 2019. URL https://arxiv.org/abs/1901. 02731. Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In International conference on machine learning, pages 16131622. PMLR, 2015. Alex Graves. Practical variational inference for neural networks. Advances in neural information processing systems, 24, 2011. Michael Jordan, Zoubin Ghahramani, Tommi Jaakkola, and Lawrence Saul. An introduction to variational methods for graphical models. Machine learning, 37:183233, 1999. S. Kullback and R. A. Leibler. On information and sufficiency. The Annals of Mathematical Statistics, 22(1):7986, 1951. ISSN 00034851. URL http://www.jstor.org/stable/2236703. Tomoharu Iwata and Zoubin Ghahramani. Improving output uncertainty estimation and generalization in deep learning via neural network gaussian processes, 2017. URL https://arxiv.org/abs/ 1707.05922. Jeremiah Zhe Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax-Weiss, and Balaji Lakshminarayanan. Simple and principled uncertainty estimation with deterministic deep learning via distance awareness, 2020. URL https://arxiv.org/abs/2006.10108. Yijun Xiao and William Yang Wang. Quantifying uncertainties in natural language processing tasks, 2018. URL https://arxiv.org/abs/1811.07253. Leda Cosmides and John Tooby. Are humans good intuitive statisticians after all? rethinking some conclusions from the literature on judgment under uncertainty. cognition, 58(1):173, 1996. Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in words, 2022b. URL https://arxiv.org/abs/2205.14334. Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D. Manning. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback, 2023. URL https: //arxiv.org/abs/2305.14975. Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms, 2024. URL https://arxiv.org/abs/2306.13063. Large language models are zero-shot Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 2219922213. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/ 8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf. reasoners. Tobias Groot and Matias Valdenegro-Toro. Overconfidence is key: Verbalized uncertainty evaluation in large language and vision-language models, 2024. URL https://arxiv.org/abs/2405. 02917. Dennis Lee, Christian Szegedy, Markus Rabe, Sarah Loos, and Kshitij Bansal. Mathematical Reasoning in Latent Space. In Proceedings of the International Conference on Learning Representations, 2020. Minchao Wu and Yuhuai Wu. Latent Action Space for Efficient Planning in Theorem Proving. In Proceedings of the Conference on Artificial Intelligence and Theorem Proving, 2021. Christopher Manning and Hinrich Schutze. Foundations of statistical natural language processing. MIT press, 1999. Richard Durbin, Sean Eddy, Anders Krogh, and Graeme Mitchison. Biological sequence analysis: probabilistic models of proteins and nucleic acids. Cambridge university press, 1998. Rajeev Alur, Milo Martin, Mukund Raghothaman, Christos Stergiou, Stavros Tripakis, and Abhishek Udupa. Synthesizing finite-state protocols from scenarios and requirements. In Hardware and Software: Verification and Testing: 10th International Haifa Verification Conference, HVC 2014, Haifa, Israel, November 18-20, 2014. Proceedings 10, pages 7591. Springer, 2014. Shraddha Barke, Emmanuel Anaya Gonzalez, Saketh Ram Kasibatla, Taylor Berg-Kirkpatrick, and Nadia Polikarpova. Hysynth: Context-free llm approximation for guiding program synthesis. Advances in Neural Information Processing Systems, 37:1561215645, 2024. Colin De la Higuera. Grammatical inference: learning automata and grammars. Cambridge University Press, 2010. 16 Appendix: Proofs A.1 Coverage Guarantees Theorem 1 : Coverage Guarantees Proof. Step 1: Construct high-probability set. By definition of Shannon entropy in bits, there can be at most 2H(µ) points Σ each having probability µ(x) 2H(µ). Gather all such points into set Shigh = { Σ : µ(x) 2H(µ)}. standard typical-set argument shows that µ(Shigh) 1/2 (or at least fixed positive constant). Step 2: Missing Shigh. The probability that one sample µ does not land in Shigh is at most 1 µ(Shigh) 1/2. Hence the probability that none of i.i.d. draws land in Shigh is at most (1/2)N = 2N . Thus any set of measure at least 1/2 is missed with exponentially small probability. Step 3: Missing smaller-mass region A. If µ(A) = ϵ 1/2, the probability that one draw misses is 1 ϵ, so the probability all draws miss is (1 ϵ)N exp(N ϵ) if ϵ is not too large. However, we need uniform guarantee over all possible of measure ϵ. By representing Σ as composed of at most 2H(µ) atoms each of probability at least 2H(µ), the number of distinct subsets is at most exp(cid:0)2H(µ) ln 2(cid:1). union bound then modifies the exponent by about factor of 1/2H(µ), so for large one has (cid:16) Pr(cid:2) : µ(A) = ϵ and all samples miss A(cid:3) exp ϵ 2H(µ) (cid:17) . This is the desired exponential coverage bound. Step 4: Inverting the bound with the Lambert -function. We have (cid:104) miss some set of mass ϵ Pr (cid:105) (cid:16) exp ϵ 2H(µ) (cid:17) . We want to find ϵ such that this probability is itself at most ϵ: (cid:16) exp ϵ 2H(µ) (cid:17) = ϵ. Rearrange as (cid:16) ϵ = exp (cid:17) ϵ 2H(µ) ϵ exp (cid:16) ϵ 2H(µ) (cid:17) = 1. Let = ϵ 2H(µ) . Then ϵ = 2H(µ) 2H(µ) x, and the above becomes exp(x) = 1 ex = 2H(µ) . By definition of the Lambert -function, = (cid:16) 2H(µ) (cid:17) . Substituting back, we get ϵ = 2H(µ) Thus ϵ decreases to 0 as , roughly like ln(cid:0) Hence, the probability of missing any set of mass at least ϵ is ϵ, with ϵ scaling on the order of ln(N ) (cid:16) 2H(µ) 2H(µ) 2H(µ) (cid:1). (cid:17) . . This completes the proof. 17 A.2 Temperature Sampling & Ablations Sampling from an LLM at higher temperatures effectively flattens its probability distribution over next-token choices, increasing the entropy of the samples and thus encouraging exploration of lower-probability (more diverse) regions of the program space. Conversely, sampling at lower temperatures sharpens the distribution, concentrating probability mass on the models highest-confidence predictions and yielding lower-entropy (more conservative) samples. In other words, low-temperature sampling focuses on the most likely, canonical SMT-LIB programs (small effective support), while high-temperature sampling ventures into rarer, more varied corners of the output space (large effective support). If instead of smoothly varying temperature schedule you simply draw many samples at fixed temperaturessay 0.5, 1.0, 1.5, and 2.0you will still span lowto high-entropy regimes, but less systematically. You risk oversampling similar outputs at each temperature (especially near the extremes) and undersampling the intermediate entropy levels that lie between 0.5->1.0 and 1.5->2.0. continuous schedule allocates exactly one sample per intermediate temperature, guaranteeing uniform coverage of entropy levels; fixed-temperature repetition may require substantially more draws to approximate that coverage, potentially leaving gaps in the distribution of generated programs. Definition 1 (Gaussian Temperature Schedule). To smoothly explore the distribution over SMT-LIB programs, we can define temperature schedule for samples as: τi = τmin + (τmax τmin) exp (cid:18) (cid:19) (i N/2)2 2σ2 (1) where τmin = 0.1, τmax = 1.5, and σ = 5 controls the spread of the Gaussian. We can also skew this gaussian towards lower temperatures. Definition 2 (Exponential Temperature Schedule). We can define schedule that emphasizes sampling at lower temperatures using: τi = τmin + (τmax τmin) exp (λ i) (2) where λ > 0 controls the decay rate, and = 0, 1, . . . , 1. Comparison: From purely coverage-guarantee standpoint (i.e. our goal of hitting every significant\" region of the SMT-LIB output distribution at least once), the Systematic uniform schedule remains the most theoretically justified. It uniformly samples every temperature exactly once, from low to high. Provably minimizes the worst-case miss probability by evenly covering the full entropy range. Gaussians concentrates samples near the middle temperature; fewer at extremes. It does provide smooth transitions; and avoids extreme high-entropy noise. However undersamples both very low-entropy (conservative) and very high-entropy (creative) regions resulting in weaker uniform coverage. The exponential decay schedule heavily biases toward low temperatures (low entropy), and therefore quickly focuses on high-confidence outputs. However, there is almost no exploration of rare programs; poor coverage of tail regions. Temperature-Varied SMT Generation and PCFG Analysis To empirically investigate the influence of LLM sampling temperature on the characteristics of generated formal artifacts, we performed SMT-LIB v2 program generation across defined temperature spectrum (e.g., Tmin = 0.0 to Tmax = 2.0). Distinct Probabilistic Context-Free Grammars (PCFGs) were induced from the SMT program ensembles parsed at each temperature point Ti, modeling the LLMs syntactic and structural tendencies under each generative condition. Our analysis of these per-temperature PCFGs revealed distinct and significant trends as sampling temperature was varied. Notably, the PCFG spectral radius generally trended upwards with increasing temperature. This intriguing behavior suggests that higher temperatures, while fostering diversity, may also enable the LLM to access and generate SMT structures with more pronounced or varied recursive complexity, perhaps by activating broader range of complex production rules rather than simplifying structural choices. Consistent with expectations of increased diversity, grammar entropy and its associated perplexity also demonstrated an upward trend, quantifying the heightened uncertainty and the expanded set of effective choices exercised by the LLM at higher temperatures. particularly interesting observation was that the KL divergence from uniform distribution also tended to increase with temperature. This implies that as the LLM explores wider variety 18 Figure 2: Spectral Radius VS Temperature Figure 3: Grammar Entropy VS Temperature Figure 4: KLD vs Temp Figure 5: Entropy Ratio vs Temp of production rules (evidenced by increased entropy), its choices within this expanded repertoire become, in relative sense, more specific or structured, deviating further from purely random uniform selection over the increasingly diverse set of utilized rules. Correspondingly, the entropy ratio generally decreased, which could occur if the maximum possible entropy (based on the growing set of observed rules and non-terminals at higher temperatures) increases at faster rate than the actual grammar entropy. The composite metric NSUI showed fluctuating behavior without clear monotonic direction, reflecting the complex interplay of its underlying components. The spectral factor, linked to the spectral radius, also exhibited slight upward trend. Figure 6: NSUI vs Temp Figure 7: Spectral Factor vs Temp Metrics related to the observed grammar structure, such as the average number of rules utilized per non-terminal, the maximum observed branching factor, and the average right-hand side (RHS) length of applied rules, all generally increased with temperature. This supports the notion that higher temperatures lead the LLM to explore and employ more extensive and potentially more elaborate subset of the SMT-LIB grammar. Regarding the shape of the rule probability distributions, kurtosis consistently decreased, indicating that these distributions become flatter (less peaked) as temperature promotes more uniform rule selection among the actively used rules. Conversely, the skew of these 19 Figure 8: Perplexity vs Temp Figure 9: Average Rules per Non-terminal vs Temp distributions tended to increase, suggesting shift in the asymmetry of rule preferences as temperature changes. Figure 10: Max Branching Factor vs Temp Figure 11: Average RHS Length vs Temp Figure 12: Kurtosis vs Temp Figure 13: Skew vs Temp These ablation studies are meaningful as they reveal nuanced picture of the LLMs generative process for formal languages. The trends suggest that increasing temperature doesnt merely lead to random, uniform outputs, but rather allows the LLM to explore richer, potentially more complex, and structurally diverse portion of the language space defined by GSM . This expansion, however, may also come with its own emergent structural specificities, as indicated by the KL divergence. These findings are crucial for understanding the coherence-diversity trade-off, for validating the sensitivity of PCFG-derived metrics, and for interpreting uncertainty scores, as the baseline characteristics of generated artifacts are systematically altered by temperature in complex ways. The observed responses underscore the value of empirical studies in characterizing LLM behavior for formal code generation."
        },
        {
            "title": "C Detailed Results",
            "content": "C.1 Benchmarking Autoformalization The performance benchmarks detailed in 5, 6, 7, 8, 9 were generated by evaluating five Large Language Models (o3-mini, DeepSeekR1 with Chain-of-Thought, DeepSeek-v3-04-21, Gemini Flash 2.0, and Gemini Flash 2.0 Lite) on four reasoning datasets. For each question, five samples were generated, and answers were derived either directly from the LLMs textual output or by solving LLM-generated SMT-LIB programs using the Z3 solver. The medium effort\" designation for o3-mini indicates specific prompting or iteration level for that model. In Table 5, the SMT approach for models like Deepseek v3 not only altered precision and recall but also resulted in substantial numbers of both False Positives (144) and True Positives (199), suggesting that while it attempted more proofs, large fraction of these new attempts were erroneous. This contrasts with its text performance (42 FP, 174 TP). For the ProntoQA training set, with only true answers  (Table 6)  , the SMT Precision of 1.0000 across all models is direct consequence of the experimental design (no false statements to misclassify as true if TN is inherently 0); the variance in False Negatives (e.g., 270 for Deepseek v3 SMT) thus purely reflects the inability to successfully formalize and prove statements known to be true, direct measure of formalization completeness for affirmatives. Table 5: LLM Performance on StrategyQA (Text vs. SMT): SMT often boosts recall (e.g., Deepseek v3 from 0.81 to 0.91) but can reduce precision and overall accuracy for several models, highlighting model-dependent autoformalization success on knowledgeintensive tasks. Accuracy Precision Recall Text StrategyQA SMT F1 TP TN FP FN Accuracy Precision Recall o3-mini (medium effort) Deepseek v3 0324 DeepSeek R1 Gemini Flash 2.0 Gemini Flash 2.0 Lite 0.7828 0.8292 0.8580 0.7188 0.6760 80 0.8609 0.6047 0.7104 130 260 21 42 0.8055 0.8055 0.8055 174 234 42 35 0.8364 0.8402 0.8383 184 245 36 75 0.6880 0.6570 0.6720 144 214 65 0.6770 0.4970 0.5736 109 229 52 110 0.7980 0.6720 0.7760 0.5360 0. F1 TP TN FP FN 0.8688 0.6347 0.7335 139 260 21 80 0.5801 0.9086 0.7081 199 137 144 20 0.7184 0.8037 0.7586 176 212 69 43 65 216 16 0.4840 0.9269 0.6363 203 6 12 269 0.4419 0.9726 0.6077 213 Table 6: LLM Performance on ProntoQA Train (True Statements Only; Text vs. SMT): SMT exposes significant failures in formalizing and proving known true statements for models like Deepseek v3 (Accuracy 0.45 vs. Text 1.00), indicating critical autoformalization recall deficiencies rather than precision issues (SMT Precision remains 1.00 for all). ProntoQA Train - ONLY TRUE Answers Text SMT Accuracy Precision Recall F1 TP TN FP FN Accuracy Precision Recall o3-mini (medium effort) Deepseek v3 0324 DeepSeek R1 Gemini Flash 2.0 Gemini Flash 2.0 Lite 1.0000 1.0000 0.9939 0.9820 0.9980 1.0000 1.0000 1.0000 499 1.0000 1.0000 1.0000 450 1.0000 0.9939 0.9969 489 1.0000 0.9820 0.9900 491 1.0000 0.9980 0.9980 499 0 0 0 0 0 0 0 0 0 0 0 3 9 1 0.9980 0.4501 0.7440 0.9000 0.9980 1.0000 0.9980 0.9889 499 1.0000 0.4501 0.6200 221 1.0000 0.7440 0.8532 372 1.0000 0.9000 0.9470 450 1.0000 0.9980 0.9989 499 F1 TP TN FP FN 0 0 1 0 270 0 0 128 0 50 0 0 1 0 0 The ProofWriter results Table 7 are notable. We advise the reader to ignore DeepSeek R1s SMT performance, since it is based on Partial Run,\" because of poor model ability to autoformalize, due to the overuse of thinking tokens, thereby causing an intractable timeline for converging to any solution and API call explosion. Here, o3-mini (medium effort) showcases successful SMT application, where its accuracy improved to 0.9418 with reduction in both False Positives (from 34 to 19) and False Negatives (from 21 to 10) compared to its text output. On the FOLIO dataset  (Table 8)  , common pattern observed in the SMT condition, beyond just low precision, was the significant reduction in True Negatives compared to the Text condition for several models (e.g., Deepseek v3 dropped from 34 TN via Text to 5 TN via SMT; Gemini Flash 2.0 from 37 TN to 0 TN). This suggests systemic challenge in generating SMT formulas that correctly evaluate to unsatisfiable for statements that are indeed false within the FOLIO logical structure. Finally, the ProntoQA test set which includes both true and false statements  (Table 9)  revealed extreme model-specific behaviors under SMT. DeepSeek R1s SMT output, for instance, correctly identified all 242 false statements (0 FP, 242 TN) but failed to correctly identify any of the 258 true statements (0 TP, 258 FN), indicating systematic bias in its SMT generation towards unsatisfiability or an inability to complete proofs for satisfiable formulas in mixed-distribution context, stark contrast to its perfect text performance and its SMT performance on true-only statements. Table 7: LLM Performance on ProofWriter (Text vs. SMT): SMT substantially improves models struggling with formal logic (e.g., Gemini Flash 2.0 Lite accuracy from 0.41 to 0.75), yet can degrade performance for models already strong in textual formal reasoning (e.g., DeepSeek R1 accuracy from 0.94 to 0.49), showcasing task-specific SMT utility. Accuracy Precision Recall F1 TP TN FP FN Accuracy Precision Recall Text SMT ProofWriter o3-mini (medium effort) Deepseek v3 0324 DeepSeek R1 (Partial Run) Gemini Flash 2.0 Gemini Flash 2.0 Lite 0.8893 0.8057 0.9423 0.4900 0.4060 21 0.8697 0.9153 0.8919 227 215 41 0.8016 0.8225 0.8110 190 175 0.9597 0.9220 0.9400 143 151 12 0.4960 0.5710 0.5300 140 106 142 105 61 142 108 189 0.3609 0.2440 0.2911 34 47 6 0.9418 0.5800 0.4935 0.6660 0.7540 0.9261 0.9597 0.9426 238 231 19 0.6587 0.3320 0.4414 0.4750 0.1870 0.2685 0.6844 0.6160 0.5313 154 106 71 0.7275 0.8120 0.7674 203 174 F1 TP TN FP FN 10 83 207 43 167 29 125 32 126 96 47 Table 8: LLM Performance on FOLIO (Text vs. SMT): Textual reasoning largely outperforms SMT. For many models, SMT results in high recall but poor precision (e.g., Gemini Flash 2.0 SMT F1 0.72 vs Text 0.92) and failure to identify false statements (e.g., 0 SMT True Negatives for Gemini Flash 2.0), indicating issues with formalizing negation or complex FOL conditions. Text Accuracy Precision Recall Folio SMT F1 TP TN FP FN Accuracy Precision Recall o3-mini (medium effort) Deepseek v3 0324 DeepSeek R1 Gemini Flash 2.0 Gemini Flash 2.0-lite 0.9450 0.9333 0.9252 0.9010 0.9017 0.9682 0.9384 0.9531 61 43 0.9259 0.9615 0.9433 50 34 0.9670 0.9090 0.9374 60 39 0.9275 0.9142 0.9200 64 37 0.923 66 35 0.904 0.9428 2 4 2 5 7 4 2 6 6 4 0.5000 0.5961 0.5200 0.5625 0. F1 TP TN FP FN 9 47 0.6890 0.2985 0.4166 20 36 0.6063 0.9193 0.7307 57 5 0.6363 0.5303 0.5785 35 21 20 31 7 0.6000 0.9000 0.7200 63 0 0 42 1 0.8235 70 12 30 5 37 0.7 Table 9: LLM Performance on ProntoQA Test (True/False Mix; Text vs. SMT): SMT shows divergent outcomes: catastrophic failure for some (e.g., DeepSeek R1 SMT F1 0.00 vs. Text 1.00), yet significant improvement for others (Gemini Flash 2.0 Lite SMT Accuracy 0.78 vs. Text 0.56), highlighting inconsistent SMT reliability on mixed arithmetic statements. ProntoQA TEST - BOTH TRUE AND FALSE Text SMT Accuracy Precision Recall F1 TP TN FP FN Accuracy Precision Recall 1.0000 1.0000 1.0000 258 242 85 172 0.5484 0.3295 0.4116 0 242 0.0000 0.0000 0.0000 0.4753 0.5232 0.4981 135 0.7210 0.9418 0.8168 243 148 F1 TP TN FP FN 0 0 70 173 0 258 93 149 123 15 o3-mini (medium effort) Deepseek v3 0324 DeepSeek R1 Gemini Flash 2.0 Gemini Flash 2.0 Lite 1.0000 0.7200 1.0000 0.7180 0.5630 1.0000 1.0000 1.0000 258 240 0 0 0.7138 0.7635 0.7378 197 163 79 61 0 0 1.0000 1.0000 1.0000 253 242 0.8232 0.5770 0.6780 149 210 32 109 0.5811 0.5333 0.5562 136 144 98 119 1.0000 0.5140 0.4840 0.4560 0.7820 22 C.2 Detailed Performance of Uncertainty Metrics for Ground Truth Prediction This section provides granular view of the performance of various Probabilistic Context-Free Grammar (PCFG) derived metrics, self-consistency measures, and ensemble methods in predicting the correctness of SMT-LIB outputs (with respect to ground truth) for specific LLM and dataset combinations. The metrics evaluated include AUROC (Area Under the Receiver Operating Characteristic Curve) for discrimination, ECE (Expected Calibration Error) and Brier score for calibration, and AURC (Area Under the Risk-Coverage Curve) along with optimal threshold (Opt.T), error rate at threshold (Err@T), and relative error reduction (RelErrRed) for selective prediction utility. The UQ results for o3-mini on StrategyQA demonstrate moderate success in distinguishing correct SMT outputs from incorrect ones. While Grammar Entropy shows good individual discriminative power (AUROC 0.7448, AURC 0.1113), achieving 13.88% relative error reduction by abstaining on just 5% of samples, many other standalone PCFG metrics exhibit weaker performance. The self-consistency metrics (Text and SMT) also perform well (AUROC 0.74), indicating that agreement between the LLMs own reasoning modalities is key signal. Notably, the Ensemble ML method achieves the highest AUROC (0.7850) and significant relative error reduction (29.29% by abstaining on 10% of samples), underscoring the benefit of integrating diverse uncertainty signals through learned model. The comparatively higher ECE for many metrics suggests that while discriminative, their raw scores may not always be well-calibrated probabilities. Table 10: Uncertainty Quantification for o3-mini on StrategyQA: Ensemble ML (AUROC 0.7850) and Self-Consistency metrics (Text/SMT AUROC 0.74) outperform most individual PCFG metrics (Grammar Entropy AUROC 0.7448 being strong contender). This suggests that for o3-mini on this knowledge-intensive task, learned combinations or behavioral consistency signals are more potent than isolated SMT structural properties for error detection. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.7448 0.5589 0.6428 0.6334 0.5175 0.5973 0.6649 0.5385 0.6334 0.6334 0.5111 0.5548 0.5737 0.5350 0.5181 0.5740 0.5291 0.5833 0.5659 0.7369 0.7416 0.7622 0.7657 0.7850 0.6702 StrategyQA - o3-mini ECE 0.3058 0.3107 0.2485 0.2436 0.3303 0.3398 0.3553 0.3283 0.2173 0.2892 0.3540 0.2117 0.2400 0.6141 0.1500 0.3161 0.3995 0.3178 0.3948 0.1604 0.1523 0.3724 0.1738 0.2090 0. Brier 0.2340 0.2862 0.2385 0.2539 0.2997 0.3042 0.2935 0.3028 0.2364 0.2747 0.3188 0.2385 0.2415 0.5651 0.1997 0.2836 0.3517 0.2850 0.3420 0.1603 0.1609 0.2916 0.1617 0.1756 0.2104 AURC 0.1113 0.1811 0.1471 0.1250 0.1977 0.1634 0.1297 0.1834 0.1319 0.1319 0.2006 0.1855 0.1752 0.1979 0.1990 0.1752 0.1811 0.1689 0.1785 0.1081 0.1051 0.1103 0.1099 0.1013 0.1410 Opt.T 0.0500 0.2000 0.3000 0.1500 0.3000 0.2500 0.0500 0.3000 0.1500 0.1500 0.2000 0.2000 0.2000 0.0500 0.1500 0.2000 0.0500 0.1500 0.0500 0.1500 0.1500 0.1000 0.0500 0.1000 0.2000 Err@T 0.1895 0.1750 0.1429 0.1882 0.1857 0.1600 0.1895 0.1857 0.1882 0.1882 0.2125 0.1750 0.1625 0.2105 0.1882 0.1625 0.2105 0.1765 0.2000 0.1529 0.1529 0.1556 0.1895 0.1556 0.1500 RelErrRed 0.1388 0.2045 0.3506 0.1444 0.1558 0.2727 0.1388 0.1558 0.1444 0.1444 0.0341 0.2045 0.2614 0.0431 0.1444 0.2614 0.0431 0.1979 0.0909 0.3048 0.3048 0.2929 0.1388 0.2929 0.3182 For DeepSeek-v3 on StrategyQA, UQ metrics show somewhat different pattern compared to o3mini. Ensemble ML again provides the best overall discrimination (AUROC 0.7709), achieving relative error reduction of 8.96% by abstaining on 5% of the samples. Interestingly, several individual PCFG-derived metrics, such as Grammar Entropy (AUROC 0.7087), Max Entropy (AUROC 0.6851), and Spectral Factor/Radius (AUROC 0.6800), demonstrate better discriminative power than the self-consistency metrics (AUROCs 0.60-0.62). This suggests that for DeepSeek-v3 on this task, intrinsic structural characteristics of the generated SMT are more indicative of correctness than its consistency with textual outputs. While Ensemble Simple yields the highest relative error reduction (35.14%), this comes at the cost of high abstention rate (Opt.T 0.50), indicating practical trade-offs in selective prediction. 23 Table 11: Uncertainty Quantification for DeepSeek-v3 on StrategyQA: Ensemble ML leads with an AUROC of 0.7709. Several individual PCFG-based metrics like Grammar Entropy (AUROC 0.7087) and Max Entropy (AUROC 0.6851) show reasonable efficacy, outperforming self-consistency measures for this model. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.7087 0.6122 0.5723 0.5997 0.6195 0.6126 0.6851 0.5311 0.68 0.68 0.6115 0.6197 0.6021 0.5122 0.618 0.6021 0.5281 0.6036 0.5787 0.6017 0.6203 0.6795 0.7211 0.7709 0.6401 ECE 0.1575 0.1601 0.1393 0.0781 0.1622 0.1623 0.0473 0.1336 0.0992 0.0686 0.1329 0.1109 0.0902 0.1753 0.145 0.1811 0.1251 0.1431 0.172 0.2874 0.2318 0.1214 0.1257 0.0877 0.1763 Brier 0.2302 0.2641 0.2322 0.2191 0.2679 0.2626 0.2099 0.2538 0.2236 0.2148 0.2469 0.2252 0.226 0.2712 0.227 0.2534 0.2573 0.2489 0.26 0.3048 0.2745 0.2077 0.2135 0.1968 0. AURC 0.2097 0.2497 0.2878 0.2672 0.2429 0.2517 0.2271 0.3306 0.2365 0.2365 0.2547 0.2583 0.2616 0.3279 0.2688 0.2616 0.3116 0.261 0.2754 0.2882 0.2513 0.2182 0.1989 0.1847 0.2483 Opt.T 0.05 0.5 0.05 0.1 0.45 0.5 0.1 0.05 0.05 0.05 0.45 0.15 0.05 0.1 0.05 0.05 0.5 0.1 0.05 0.1 0.1 0.1 0.05 0.05 0.5 Err@T 0.3474 0.28 0.3579 0.3222 0.2727 0.28 0.3222 0.3684 0.3474 0.3474 0.2909 0.3176 0.3579 0.3444 0.3474 0.3579 0.32 0.3444 0.3579 0.3444 0.3444 0.3222 0.3474 0.3368 0.24 RelErrRed 0.0612 0.2432 0.0327 0.1291 0.2629 0.2432 0.1291 0.0043 0.0612 0.0612 0.2138 0.1415 0.0327 0.0691 0.0612 0.0327 0.1351 0.0691 0.0327 0.0691 0.0691 0.1291 0.0612 0.0896 0.3514 The UQ performance for o3-mini on ProofWriter is remarkably high, demonstrating the strong potential of PCFG-based metrics in formal reasoning contexts. Numerous individual metrics, including Grammar Entropy, Perplexity (AUROC 0.9194), Renyi Entropy (0.5) (AUROC 0.9301), Average Rules / NT (AUROC 0.9301), and various rule distribution statistics, achieve AUROC scores exceeding 0.90. More impressively, their AURC values are exceptionally low (e.g., 0.0008 for Grammar Entropy), translating to 100% relative error reduction by abstaining on small fraction of samples (e.g., 10%). This strongly supports the hypothesis that syntactic irregularities in generated formal artifacts are highly indicative of underlying semantic errors when the task aligns well with the formal language. Ensemble methods elevate this performance to near-perfection (Ensemble Average AUROC 0.9949). Despite the excellent discrimination, some metrics show high ECE values (e.g., Grammar Entropy ECE 0.4419), suggesting that while they can effectively rank outputs by correctness likelihood, their raw scores may not be perfectly calibrated across the entire probability spectrum. The UQ results for Gemini 2.0 Flash Lite on ProofWriter present mixed picture, contrasting with o3-minis strong performance on the same task. Many individual PCFG-derived metrics demonstrate weak discriminative ability, with AUROC scores often between 0.50 and 0.59 (e.g., Grammar Entropy at 0.5380, Spectral Radius at 0.5011). However, SMT Self Consistency stands out as significantly stronger individual performer with an AUROC of 0.7364. Ensemble methods, particularly Ensemble ML, achieve the best overall performance (AUROC 0.7631, AURC 0.0823), leading to 14.61% relative error reduction when abstaining on 5% of the samples. This suggests that for Gemini 2.0 Flash Lite on ProofWriter, the structural variations in its SMT outputs are less consistently tied to semantic correctness compared to o3-mini. Instead, behavioral consistency (specifically, how its SMT outputs align with each other across multiple generations) and learned patterns across combination of (often individually weaker) signals provide more reliable error detection. 24 Table 12: Uncertainty Quantification for o3-mini on ProofWriter: PCFG-derived metrics achieve exceptional discriminative power (e.g., Grammar Entropy AUROC 0.9301, AURC 0.0008), enabling near-perfect error detection with minimal abstention (100% RelErrRed at Opt.T 0.10). Ensemble methods (e.g., Ensemble Average AUROC 0.9949) further refine this, confirming that SMT structural properties are extremely strong predictors of correctness for o3-mini on this formal reasoning task. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple ProofWriter AUROC 0.9301 0.9194 0.5108 0.5645 0.8871 0.9301 0.9086 0.586 0.7473 0.7473 0.8011 0.5108 0.9301 0.8011 0.5914 0.9301 0.5108 0.9301 0.586 0.899 0.7121 0.9949 0.9785 0.9892 0.9355 ECE 0.4419 0.5358 0.5167 0.571 0.5405 0.4724 0.7198 0.5714 0.3458 0.3545 0.4267 0.4186 0.5393 0.6535 0.2979 0.4945 0.5555 0.4923 0.5107 0.0423 0.8501 0.3356 0.4612 0.0572 0. Brier 0.25 0.3515 0.326 0.3843 0.3598 0.2879 0.555 0.3764 0.2247 0.2305 0.2397 0.2201 0.3499 0.5086 0.1377 0.3034 0.3723 0.2987 0.3115 0.028 0.7764 0.1414 0.2566 0.028 0.2582 AURC 0.0008 0.0008 0.0074 0.0084 0.0013 0.0008 0.0013 0.0055 0.0032 0.0032 0.0019 0.0084 0.0008 0.0026 0.0055 0.0008 0.0074 0.0008 0.0055 0.002 0.0025 0.0005 0.0003 0.0003 0.0008 Opt.T 0.1000 0.1000 0.0000 0.0000 0.1500 0.1000 0.1000 0.4500 0.3000 0.3000 0.2000 0.0000 0.1000 0.2500 0.4500 0.1000 0.5000 0.1000 0.4500 0.0500 0.1500 0.0500 0.0500 0.0500 0.1000 Err@T 0.0000 0.0000 0.0106 0.0106 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0106 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0105 0.0000 0.0000 0.0000 0.0000 0.0000 RelErrRed 1.0000 1.0000 0.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.4684 1.0000 1.0000 1.0000 1.0000 1.0000 Table 13: Uncertainty Quantification for Gemini 2.0 Flash Lite on ProofWriter: Performance is moderate; SMT Self Consistency (AUROC 0.7364) and Ensemble ML (AUROC 0.7631) are the strongest UQ signals. Most individual PCFG structural metrics show weak discriminative power (many AUROCs 0.50-0.59), indicating that for this model on ProofWriter, behavioral consistency (SMT-based) and learned combinations are more indicative of correctness than raw SMT syntactic properties alone. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.5380 0.5934 0.5164 0.5243 0.5996 0.5933 0.5417 0.5177 0.5011 0.5011 0.5167 0.5549 0.5840 0.5631 0.5745 0.5838 0.5144 0.5844 0.5044 0.5525 0.7364 0.6140 0.7235 0.7631 0.6476 ECE 0.3185 0.3888 0.3080 0.3186 0.4102 0.4401 0.3503 0.3943 0.5048 0.3930 0.4838 0.2422 0.2790 0.3413 0.2189 0.4368 0.4474 0.4511 0.1437 0.2283 0.3535 0.3922 0.3327 0.2897 0.3867 AURC 0.1405 0.1267 0.1573 0.1514 0.1285 0.1258 0.1420 0.1548 0.1578 0.1578 0.1672 0.1370 0.1301 0.1480 0.1355 0.1301 0.1559 0.1313 0.1726 0.1376 0.1031 0.1240 0.1035 0.0823 0.1071 Opt.T 0.4500 0.1000 0.0000 0.1500 0.1000 0.1000 0.5000 0.2000 0.0000 0.0000 0.1000 0.4000 0.3000 0.1000 0.3000 0.3000 0.3500 0.3000 0.4000 0.4500 0.2000 0.1000 0.1000 0.0500 0.2000 Err@T 0.1667 0.1742 0.1869 0.1845 0.1742 0.1742 0.1717 0.1835 0.1869 0.1869 0.1854 0.1610 0.1377 0.1685 0.1522 0.1377 0.1797 0.1522 0.1610 0.1545 0.1062 0.1722 0.1404 0.1596 0. RelErrRed 0.1081 0.0680 0.0000 0.0125 0.0680 0.0680 0.0811 0.0178 0.0000 0.0000 0.0079 0.1383 0.2632 0.0981 0.1857 0.2632 0.0384 0.1857 0.1383 0.1866 0.4408 0.0936 0.2484 0.1461 0.1871 Brier 0.2869 0.3182 0.2797 0.2642 0.3368 0.3581 0.3045 0.3426 0.4157 0.3172 0.4215 0.2315 0.2656 0.2906 0.2293 0.3713 0.3795 0.3779 0.1913 0.2419 0.2751 0.3192 0.2539 0.2229 0.3039 25 C.3 Detailed Performance of SMT-Based Uncertainty Metrics for Text-Answer Prediction This section evaluates the efficacy of uncertainty quantification (UQ) metrics derived from SMTLIB generations in predicting the correctness of the SMT results with the corresponding textual answers. The goal is to identify when the formalization (SMT output) aligns or diverges from the models natural language reasoning output (textual answer). On StrategyQA, o3 mini had 100% agreement between SMT and text answers, so UQ analysis for SMT-Text consistency prediction was not applicable for that specific model-dataset pair as there were no disagreements to predict. Results for other cases are detailed below. For DeepSeek R1 on StrategyQA, we assesses how well metrics derived from its SMT generations can predict alignment with its textual answers. The results are strong: ensemble methods integrating these SMT features, such as Ensemble Weighted (AUROC 0.8494) and Ensemble Average (AUROC 0.8183), are highly effective. Notably, Text Self Consistency (AUROC 0.8245) is top individual performer, suggesting that instability in textual outputs often correlates with SMT-Text divergence. Among metrics purely derived from SMT structure, Grammar Entropy (AUROC 0.7609) is noteworthy, achieving 100% relative error reduction in identifying SMT-Text disagreements if one abstains on 45% of cases. This performance in predicting SMT-Text consistency is robust and highlights that both SMT structural integrity and textual stability are key indicators. The AURC values are generally very low for top performers (e.g., 0.0155 for Ensemble Weighted), indicating high utility in selectively flagging potential cross-modal disagreements. Table 14: UQ for SMT-Text Consistency (DeepSeek R1, StrategyQA): SMT-derived metrics, especially ensembles (Ensemble Weighted AUROC 0.8494), effectively predict SMT-Text answer agreement. Text Self Consistency (AUROC 0.8245) is strong predictor, while SMT-derived Grammar Entropy (AUROC 0.7609) also shows good utility, enabling high error reduction (100% RelErrRed at Opt.T 0.45) in identifying SMT-Text divergences. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.7609 0.6211 0.5776 0.5963 0.6242 0.6149 0.7174 0.5217 0.5481 0.5481 0.5264 0.6087 0.7034 0.5637 0.6801 0.7034 0.6056 0.6848 0.5311 0.8245 0.7570 0.8183 0.8494 0.8245 0.6957 ECE 0.4617 0.3789 0.4408 0.2529 0.3980 0.3942 0.3994 0.5047 0.1533 0.2067 0.5679 0.3083 0.4068 0.2491 0.3325 0.5352 0.6755 0.4800 0.2521 0.1002 0.2062 0.4695 0.3256 0.3084 0.4363 Brier 0.2968 0.2640 0.2855 0.1433 0.2746 0.2755 0.2341 0.3529 0.0927 0.1166 0.4237 0.1839 0.2532 0.1566 0.2042 0.3733 0.5361 0.3260 0.1588 0.0751 0.1373 0.3058 0.1711 0.2003 0.2748 AURC 0.0216 0.0361 0.0443 0.0462 0.0378 0.0376 0.0262 0.0543 0.0640 0.0640 0.0557 0.0396 0.0273 0.0544 0.0324 0.0273 0.0413 0.0309 0.0534 0.0155 0.0268 0.0180 0.0155 0.0170 0. Opt.T 0.4500 0.5000 0.3000 0.1000 0.5000 0.5000 0.0500 0.3000 0.1500 0.1500 0.5000 0.4000 0.0500 0.1000 0.0500 0.0500 0.2000 0.0500 0.1000 0.0500 0.0500 0.2500 0.0500 0.2000 0.1000 Err@T 0.0000 0.0204 0.0580 0.0562 0.0204 0.0408 0.0638 0.0580 0.0476 0.0476 0.0408 0.0508 0.0638 0.0562 0.0638 0.0638 0.0506 0.0638 0.0674 0.0319 0.0532 0.0135 0.0319 0.0380 0.0562 RelErrRed 1.0000 0.7114 0.1801 0.2055 0.7114 0.4227 0.0973 0.1801 0.3265 0.3265 0.4227 0.2809 0.0973 0.2055 0.0973 0.0973 0.2839 0.0973 0.0465 0.5486 0.2477 0.8089 0.5486 0.4629 0.2055 When predicting SMT-Text consistency for DeepSeek v3 on StrategyQA, UQ metrics based on SMT generations prove highly effective. The Ensemble ML approach, which learns from various SMT-derived features, achieves an impressive AUROC of 0.8517 and offers 55.56% relative error reduction in spotting SMT-Text disagreements when abstaining on 25% of samples. Good individual predictors include SMT-derived Grammar Entropy (AUROC 0.7354) and SMT Self Consistency (AUROC 0.7116). This demonstrates that for DeepSeek v3, deviations from typical SMT structure (signaled by grammar entropy) or inconsistencies in the SMT generation process itself are strong indicators that the SMT output might not align with the models textual answer. The low AURC (0.0573) for Ensemble ML highlights its practical utility. This task of predicting internal consistency (SMT-Text) shows strong signals, comparable to or even clearer (e.g. for Ensemble ML) than predicting SMT-Ground Truth correctness for this model on the same dataset. 26 Table 15: UQ for SMT-Text Consistency (DeepSeek v3, StrategyQA): Ensemble ML using SMTderived features shows excellent performance (AUROC 0.8517) in predicting SMT-Text agreement, with 55.56% relative error reduction. SMT-derived Grammar Entropy (AUROC 0.7354) and SMT Self Consistency (AUROC 0.7116) also serve as solid individual predictors, indicating that atypical SMT structures and generation instability can flag potential SMT-Text divergences. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.7354 0.6721 0.5335 0.5973 0.6799 0.6667 0.6353 0.6154 0.7034 0.7034 0.5549 0.5675 0.6034 0.5208 0.5937 0.6034 0.6281 0.5986 0.66 0.5778 0.7116 0.7064 0.7709 0.8517 0.6727 ECE 0.3058 0.3282 0.1195 0.1768 0.3403 0.3333 0.1309 0.4091 0.1254 0.1896 0.2271 0.2025 0.1393 0.1254 0.1563 0.321 0.2226 0.3057 0.0731 0.1874 0.1662 0.1876 0.234 0.1861 0.3021 Brier 0.2551 0.2718 0.178 0.1919 0.2808 0.2751 0.1738 0.3307 0.158 0.1752 0.2455 0.2077 0.1854 0.1818 0.192 0.2742 0.2221 0.2619 0.1576 0.2008 0.1909 0.1831 0.1971 0.1703 0.2567 AURC 0.097 0.1205 0.1633 0.1411 0.116 0.1223 0.1247 0.1446 0.1206 0.1206 0.148 0.1485 0.1399 0.1972 0.1457 0.1399 0.1445 0.1406 0.1256 0.1754 0.1054 0.0983 0.0798 0.0573 0.1119 Opt.T 0.0500 0.3000 0.0500 0.0500 0.3000 0.3500 0.1000 0.5000 0.1000 0.1000 0.0500 0.1000 0.0500 0.0500 0.1000 0.0500 0.3000 0.0500 0.0500 0.1500 0.1000 0.1000 0.0500 0.2500 0. Err@T 0.1789 0.1143 0.2000 0.1895 0.1000 0.1077 0.1889 0.1000 0.1667 0.1667 0.2000 0.1778 0.1895 0.2000 0.1889 0.1895 0.1571 0.1895 0.1895 0.1765 0.1778 0.1667 0.1895 0.0933 0.1765 RelErrRed 0.1479 0.4558 0.0476 0.0977 0.5238 0.4872 0.1005 0.5238 0.2063 0.2063 0.0476 0.1534 0.0977 0.0476 0.1005 0.0977 0.2517 0.0977 0.0977 0.1597 0.1534 0.2063 0.0977 0.5556 0.1597 For Gemini Flash 2.0 Lite on StrategyQA, the task of predicting SMT-Text consistency reveals standout individual metric: Rule Distribution Kurtosis from the SMT generations achieves very high AUROC of 0.8695. This is particularly interesting finding, as it suggests that the \"tailedness\" or outlier presence in the distribution of PCFG rules used during SMT generation is very strong signal of whether the SMT output will align with the textual answer for this model. This metrics performance surpasses many other individual PCFG metrics (e.g., Grammar Entropy AUROC 0.6622, Perplexity AUROC 0.7212). Ensemble methods, like Ensemble Weighted (AUROC 0.8070) and Ensemble Average (AUROC 0.7927), provide robust overall performance, leveraging combinations of signals. The strong performance of kurtosis aligns with the our discussion about syntactic fingerprints\" and how atypical SMT patterns (like bimodal distributions captured by kurtosis) can signal reasoning issues or misalignments. The AURC for Kurtosis (0.4448) suggests that while discriminative, its practical utility in terms of risk reduction might require careful thresholding, achieving 30.56% error reduction at 50% abstention rate. The results for o3-mini on ProofWriter for predicting SMT-Text consistency are exceptional. Ensemble ML and Ensemble Weighted methods achieve perfect AUROC scores of 1.0000, signifying an ability to flawlessly distinguish SMT outputs that align with textual answers from those that diverge. This allows for 100% relative error reduction with very low 5% abstention rate. Beyond ensembles, many individual PCFG metrics derived from the SMT generations show extremely high predictive capabilities. For instance, Ent Ratio (AUROC 0.9677), Rule Dist Kurtosis (AUROC 0.9462), Max Ent (AUROC 0.9355), and NSUI (AUROC 0.9355) are all remarkably strong predictors, each achieving 100% relative error reduction at their respective optimal thresholds. This indicates that for o3-mini, particularly on formal reasoning task like ProofWriter, the structural and probabilistic characteristics of its SMT generations are almost perfectly indicative of whether its formal and textual reasoning pathways are aligned. The exceptionally low AURC values (e.g., 0.0003 for Ensemble ML) further emphasize the practical certainty offered by these UQ measures in this context. This level of predictability for SMT-Text consistency is even more pronounced than some of the SMT-Ground Truth prediction results for this model, demonstrating the power of SMT features for diagnosing internal reasoning coherence. 27 Table 16: UQ for SMT-Text Consistency (Gemini Flash 2.0 Lite, StrategyQA): Rule Distribution Kurtosis (AUROC 0.8695) from SMT generations is an exceptionally strong individual predictor of SMT-Text agreement, significantly outperforming other PCFG metrics. Ensemble methods (e.g., Ensemble Weighted AUROC 0.8070) also perform well. This highlights specific SMT structural feature as key indicator of cross-modal alignment for this model. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.6622 0.7212 0.5486 0.6741 0.7624 0.6994 0.5982 0.5511 0.6538 0.6538 0.5166 0.5749 0.6565 0.6014 0.5818 0.6565 0.7183 0.6796 0.8695 0.535 0.7505 0.7927 0.807 0.7946 0.7584 ECE 0.1277 0.3255 0.2387 0.1195 0.3192 0.2766 0.3401 0.1641 0.0943 0.1648 0.418 0.4256 0.2913 0.4855 0.5167 0.2197 0.3136 0.1783 0.3187 0.2788 0.538 0.1531 0.1673 0.1308 0.0796 Brier 0.2095 0.2849 0.263 0.1624 0.2624 0.2619 0.3083 0.2511 0.1677 0.1703 0.3958 0.3818 0.2761 0.442 0.4747 0.228 0.2807 0.2199 0.2412 0.2616 0.4357 0.1702 0.1632 0.1592 0.1568 AURC 0.5689 0.5273 0.6341 0.5221 0.5037 0.5438 0.59 0.6346 0.5316 0.5316 0.6509 0.6252 0.5923 0.6098 0.6313 0.5923 0.5455 0.572 0.4448 0.6064 0.4822 0.4848 0.4718 0.4784 0.4929 Opt.T 0.1000 0.0500 0.1000 0.5000 0.1000 0.0500 0.3000 0.2500 0.5000 0.5000 0.3500 0.1000 0.2500 0.0500 0.0500 0.2500 0.1500 0.2500 0.5000 0.3500 0.5000 0.4000 0.3000 0.5000 0. Err@T 0.6889 0.7053 0.7000 0.6600 0.6889 0.7053 0.6714 0.6667 0.6600 0.6600 0.6769 0.6889 0.6400 0.7053 0.7053 0.6400 0.6706 0.6400 0.5000 0.6462 0.5600 0.5833 0.6143 0.5400 0.6824 RelErrRed 0.0432 0.0205 0.0278 0.0833 0.0432 0.0205 0.0675 0.0741 0.0833 0.0833 0.0598 0.0432 0.1111 0.0205 0.0205 0.1111 0.0686 0.1111 0.3056 0.1026 0.2222 0.1898 0.1468 0.2500 0.0523 Table 17: UQ for SMT-Text Consistency (o3-mini, ProofWriter): SMT-derived UQ metrics demonstrate outstanding performance, with Ensemble ML and Ensemble Weighted achieving perfect AUROC (1.0000) in predicting SMT-Text agreement. Numerous individual PCFG metrics, such as Ent Ratio (AUROC 0.9677) and Rule Dist Kurtosis (AUROC 0.9462), are also exceptionally effective, enabling complete identification of SMT-Text inconsistencies with minimal abstention. This underscores very strong link between SMT formalization properties and cross-modal reasoning alignment for o3-mini on this formal task. Metric Grammar Entropy Perplexity KL Divergence NSUI Renyi Ent (2) Renyi Ent (0.5) Max Ent Ent Ratio Spectral Factor Spectral Radius # Nonterminals # Rules Avg Rules / NT Avg RHS Len Max Branch Factor Rule Dist Mean Rule Dist StdDev Rule Dist Skew Rule Dist Kurtosis Self Consistency Text Self Consistency SMT Ensemble Average Ensemble Weighted Ensemble ML Ensemble Simple AUROC 0.8602 0.9032 0.6667 0.9355 0.9032 0.8925 0.9355 0.9677 0.5269 0.5269 0.6505 0.5108 0.8011 0.5054 0.7419 0.8011 0.8710 0.8172 0.9462 0.7050 0.7100 0.9300 1.0000 1.0000 0.6667 ECE 0.4419 0.4429 0.5167 0.4077 0.4382 0.5063 0.2589 0.4074 0.6329 0.6243 0.5520 0.4186 0.4394 0.6535 0.6809 0.4842 0.4232 0.4864 0.5107 0.9352 0.8600 0.3560 0.4231 0.0496 0. AURC 0.0013 0.0013 0.0039 0.0008 0.0013 0.0013 0.0008 0.0003 0.0084 0.0084 0.0047 0.0064 0.0026 0.0074 0.0032 0.0026 0.0013 0.0019 0.0008 0.0030 0.0030 0.0007 0.0003 0.0003 0.0039 Opt.T 0.15 0.10 0.35 0.10 0.10 0.15 0.10 0.05 0.00 0.00 0.40 0.50 0.25 0.50 0.30 0.25 0.15 0.20 0.10 0.30 0.30 0.10 0.05 0.05 0.35 Err@T 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 RelErrRed 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.00 0.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 Brier 0.2542 0.2616 0.3238 0.2172 0.2580 0.3246 0.1029 0.2082 0.5061 0.4953 0.3650 0.2201 0.2554 0.5116 0.5100 0.2971 0.2392 0.2964 0.3056 0.9023 0.7863 0.1741 0.2375 0.0199 0."
        },
        {
            "title": "D Supplementary Experimental Details",
            "content": "The comprehensive PCFG analysis underpinning our uncertainty quantification was conducted on focused set of benchmarks. Specifically, for 100 questions each from the StrategyQA, ProofWriter, and ProntoQA datasets, corpus of NSM = 100 SMT-LIB v2 program samples per question was generated. The FOLIO dataset was excluded from this detailed PCFG study due to challenges in obtaining consistently robust SMT formalizations from the evaluated LLMs. Each SMT program within these corpora was parsed using an ANTLR-based parser to extract its constituent production rules. For the generation of these primary SMT samples used in uncertainty quantification (distinct from the temperature ablation study), LLM sampling temperature was maintained at its default setting to promote more deterministic outputs, with up to 10 generation attempts per SMT sample to ensure corpus completeness. For each of the selected questions, unique PCFG was induced from its corresponding 100 SMT samples. Rule probabilities within these per-question PCFGs were estimated via Maximum Likelihood Estimation (MLE), incorporating Lidstone smoothing (specifically, Laplace smoothing with βs = 1) to manage unseen production rules. Beyond the metrics detailed in the main methodology, specific configurations included the computation of Rényi entropy for orders α = 0.5 and α = 2.0 (Collision Entropy). The evaluation framework for the derived uncertainty metrics incorporated specific settings. Expected Calibration Error (ECE) was calculated using 10 discretization bins for confidence scores. In the analysis of selective prediction utility (error vs. abstention), optimal abstention thresholds were determined by targeting maximum relative error reduction while considering abstention levels up to practical maximum of 50%. For our Ensemble ML predictor, Logistic Regression model was employed, configured with balanced class weights and trained for up to 10, 000 iterations on scaled features derived from the suite of PCFG uncertainty metrics."
        },
        {
            "title": "E SMT Error Ratios vs Text Error Ratios",
            "content": "Figure 14: SMT vs. Text Error Ratio Analysis for o3-mini: Illustrates well-calibrated SMT generation, indicated by strong correlation between SMT and Text error patterns. Figure 15: SMT vs. Text Error Ratio Analysis for Gemini Flash 2.0: Depicts less-calibrated SMT generation, evidenced by weaker correlation between SMT and Text error patterns. The figures juxtapose SMT versus Text error ratios (with marginals) for o3-mini  (Fig. 14)  and Gemini Flash 2.0  (Fig. 15)  ; the Text error ratio is defined as the proportion of incorrect direct textual answers from the LLM per question out of the many samples, while the SMT error ratio is the proportion of incorrect answers derived from its SMT-LIB formalizations. O3-mini exhibits 29 notable correlation between its SMT and Text error distributions, characteristic of well-calibrated SMT generation process where formalization errors tend to align with textual reasoning errors. In contrast, Gemini Flash 2.0 shows weaker correlation, suggesting its SMT generations may introduce errors or exhibit patterns less consistently coupled with its textual output, indicative of poorer calibration. This comparative error ratio analysis is valuable for assessing the fidelity of an LLMs autoformalization. Strong SMT-Text error correlation implies that the SMT modality can be more reliable indicator of the LLMs general reasoning tendencies for problem, making SMT-derived uncertainty metrics potentially more transferable. Poor correlation, however, signals divergence between textual reasoning and formalization, cautioning against using SMT outputs as direct proxies without careful consideration of modality-specific error sources and motivating efforts towards better SMT-Text reasoning alignment."
        },
        {
            "title": "F Qualitative Analysis",
            "content": "Beyond quantitative uncertainty metrics, the PCFG framework, by its nature of parsing and structuring program ensembles, lends itself to nuanced qualitative analysis of LLM-generated formal artifacts. Initial explorations can focus on broad characteristics such as the distribution of SMT-LIB sorts (datatypes) employed or the prevalent logical fragments (e.g., QF_LIA, QF_AUFBV) selected by the LLM for given problem class. However, more profound understanding of an LLMs formalization strategy emerges from detailed examination of substrctures, like the assert statements, which constitute the semantic core of an SMT program by stipulating the conditions and axioms for the solver. Our PCFG-based analysis of these assertions, and the logical architectures therein, reveals critical patterns in how LLMs attempt to translate natural language problem specifications into rigorous, machine-interpretable logic. When an LLM generates multiple SMT program samples for single natural language input, the per-problem induced PCFG captures distribution over grammatical structures. This distribution inherently models the LLMs normative formalization pathways alongside its idiosyncratic variations, particularly in the construction of assert statements and their nested logical termsincluding quantifiers (forall, exists), logical connectives (=>, and, or, not), and predicate applications. Analyzing the probabilities and diversity of production rules within these PCFGs allows for the identification and interpretation of several key types of divergences and tendencies in formal specification: Formalization Aliasing and Representational Stability core aspect of problem specification may elicit syntactically diverse, yet ideally logically equivalent, assert statements across an ensemble of LLM generations. For instance, an implication might be directly asserted or rendered as B. The PCFG reflects such syntactic polymorphism through multiple, lower-probability rule sequences mapping to the same underlying semantic constraint. high degree of such variability for asserting fundamental problem axioms often signals the LLMs lack of converged or canonical formalization strategy, potentially indicating uncertainty or representational underspecification for that particular logical construct. Variance in Logical Decomposition and Structural Complexity The PCFG rule sets unveil the LLMs implicit preferences regarding the structural complexity and granularity of asserted logical terms. For given problem, some SMT samples might employ deeply nested quantifiers and connectives within monolithic assert statement. In contrast, other samples might exhibit preference for flatter, more direct assertions or decompose complex axiom into several simpler, conjoined assert statements. This divergence in logical decomposition strategies is captured by differing rule probabilities and derivation depths within the PCFG, pointing to variations in the LLMs approach to abstraction and information chunking during the formalization process. Identification of Atypical or Anomalous Assertions Occasionally, an LLM may generate assert statements possessing highly unusual or infrequent syntactic structures relative to the typical formalizations observed for given problem context or across dataset. The PCFG methodology inherently highlights these as low-probability production rules or derivations. Qualitative inspection of the SMT code corresponding to these rare assertion patterns can uncover unique, potentially innovative, or conversely, flawed and overly convoluted ways the LLM attempts to axiomatize specific constraints, offering insights into its error modes or its capacity for novel formal expression. Semantic Divergence in Axiomatization More critically, divergences can be semantic rather than merely syntactic, leading to logically distinct problem formalizations from the same natural language input. Such semantic drift often manifests as significantly different asserted terms within assert statements, pointing to LLM misinterpretation, unresolved ambiguity, or flaws in its inferential reasoning. For example, if an input \"All engineers use LaTeX\" is ambiguously formalized, one SMT sample might correctly assert (forall ((x Engineer)) (usesLaTeX x)), while semantically divergent sample might erroneously assert (forall ((x User)) (implies (usesLaTeX x) (isEngineer x))). The PCFG rules governing the predicates, variables, and logical structure of terms within these assertions would markedly differ, directly reflecting this semantic incongruity and providing diagnostic trace. Fidelity in Representing Ground Facts For declarative factual statements present in the input (e.g., \"Constantine is logician\"), the LLM is expected to consistently assert the corresponding ground fact in stable manner. If the PCFG reveals multiple, conflicting, or unstable rule applications for asserting properties of specific entities (e.g., some derivations asserting (isLogician constantine) while others, for the same conceptual input fact, generate (isPhilosopher constantine) or vary the predicate structure), this indicates deficiency in the LLMs fidelity in extracting and consistently formalizing elementary factual information, pointing to potential grounding issues. Program 1 Program 2 Program 3 Program (set-logic QF_LIA) (declare-const relation_count_G Int) (declare-const relation_count_J Int) (assert (> relation_count_G relation_count_J)) (assert (>= relation_count_G 1)) (assert (>= relation_count_J 0)) (check-sat) (get-model) (set-logic QF_LIA) (declare-const GC Int) (declare-const JC Int) (assert (> GC 0)) (assert (> JC 0)) (assert (> GC JC)) (assert (>= GC 10)) (assert (>= JC 1)) (check-sat) (get-model) (set-logic QF_LIA) (declare-const KN Int) (declare-const CA Int) (assert (> KN CA)) (assert (= KN 16)) (assert (= CA 1)) (check-sat) (get-model) (set-logic QF_LIA) (declare-fun people_genghis () Int) (declare-fun people_caesar () Int) (assert (>= people_genghis 0)) (assert (>= people_caesar 0)) (assert (> people_genghis people_caesar)) (assert (>= people_genghis 1000000)) (assert (<= people_caesar 500000)) (check-sat) (get-model) Table 18: Divergent LLM Formalizations of StrategyQA Problem: Sample SMT-LIB outputs illustrating varied axiomatization strategies, with assert statements highlighted (blue). Such variations are central to the qualitative PCFG analysis discussed."
        }
    ],
    "affiliations": [
        "Case Western Reserve University",
        "Microsoft Corporation",
        "Microsoft Research"
    ]
}