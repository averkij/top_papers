{
    "paper_title": "PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing",
    "authors": [
        "Zhuoqun Li",
        "Xuanang Chen",
        "Hongyu Lin",
        "Yaojie Lu",
        "Xianpei Han",
        "Le Sun"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Paper search is an important activity for researchers, typically involving using a query with description of a topic to find relevant papers. As research deepens, paper search requirements may become more flexible, sometimes involving specific details such as module configuration rather than being limited to coarse-grained topics. However, previous paper search systems are unable to meet these flexible-grained requirements, as these systems mainly collect paper abstracts to construct index of corpus, which lack detailed information to support retrieval by finer-grained queries. In this work, we propose PaperRegister, consisted of offline hierarchical indexing and online adaptive retrieval, transforming traditional abstract-based index into hierarchical index tree for paper search, thereby supporting queries at flexible granularity. Experiments on paper search tasks across a range of granularity demonstrate that PaperRegister achieves the state-of-the-art performance, and particularly excels in fine-grained scenarios, highlighting the good potential as an effective solution for flexible-grained paper search in real-world applications. Code for this work is in https://github.com/Li-Z-Q/PaperRegister."
        },
        {
            "title": "Start",
            "content": "PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing Zhuoqun Li1,2, Xuanang Chen1, Hongyu Lin1, Yaojie Lu1, Xianpei Han1, Le Sun1 1Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences 2University of Chinese Academy of Sciences {lizhuoqun2021,chenxuanang,hongyu,luyaojie,xianpei,sunle}@iscas.ac.cn 5 2 0 2 4 1 ] I . [ 1 6 1 1 1 1 . 8 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Paper search is an important activity for researchers, typically involving using query with description of topic to find relevant papers. As research deepens, paper search requirements may become more flexible, sometimes involving specific details such as module configuration rather than being limited to coarse-grained topics. However, previous paper search systems are unable to meet these flexible-grained requirements, as these systems mainly collect paper abstracts to construct index of corpus, which lack detailed information to support retrieval by finer-grained queries. In this work, we propose PaperRegister, consisted of offline hierarchical indexing and online adaptive retrieval, transforming traditional abstract-based index into hierarchical index tree for paper search, thereby supporting queries at flexible granularity. Experiments on paper search tasks across range of granularity demonstrate that PaperRegister achieves the state-of-the-art performance, and particularly excels in fine-grained scenarios, highlighting the good potential as an effective solution for flexible-grained paper search in real-world applications. Introduction Paper search is an important and almost everyday activity for researchers (Kuhlthau 1991; Ellis, Cox, and Hall 1993; Hemminger et al. 2007; Case and Given 2016). Typically, this process begins when the user submits natural-language query describing topic, then the retrieval system matches this query against the paper corpus and returns the subset of papers with the highest relevance (Wadden et al. 2020; Cohan et al. 2020; Ajith et al. 2024; He et al. 2025). As researchers delve more deeply into their work, the paper search requirements can become increasingly flexible. For example, the view of input query may refer to detailed module configuration or methodological operation, rather than being limited to the level of coarse-grained topic (Mysore et al. 2021; Kang et al. 2024; Wang et al. 2023; Zhang et al. 2025). Therefore, paper search system supporting queries at flexible levels of granularity is of important value. Unfortunately, existing paper search systems cannot effectively handle queries across flexible granularity, since they mainly use paper abstracts to construct index of corpus for retrieval (Zheng et al. 2020; Gao et al. 2023; Mackie, Chatterjee, and Dalton 2023; Lei et al. 2024). When querys view involves finer-grained information that does not appear in abstract, they fails to retrieve relevant papers. Figure 1: PaperRegister can support flexible-grained paper search through the hierarchical register, while traditional method fails due to abstract cannot contain required details. As shown in Figure 1, the input query Retrieve papers about jointly training encoder and generator via minimizing the negative marginal log-likelihood without document encoder specifies detailed training operation, expecting to find the relevant paper. However, the target cannot be successfully retrieved by traditional paper search systems via abstract-based index, because the abstract does not mention such detailed training operation. Therefore, building powerful paper search system that supports queries at flexible granularity remains an important open challenge. To this end, we propose PaperRegister, which transforms traditional abstract-based index into hierarchical index tree for paper search, thereby supporting queries at flexible granularity. Specially, PaperRegister includes offline hierarchical indexing and online adaptive retrieval. In the offline stage, to construct hierarchical index tree for corpus, PaperRegister uses hierarchical register schema, consisted of information nodes at various granularity, in which each node path Figure 2: The overview of PaperRegister, including hierarchical indexing and adaptive retrieval. In offline stage, PaperRegister constructs hierarchical index tree via fine-grained content extracting and bottom-up content aggregating based on hierarchical register schema. In online stage, PaperRegister first identify the views of input query and then conduct view-based matching. represents kind of view. Based on this schema, PaperRegister first extracts fine-grained contents for each paper, then aggregates contents bottom-up, layer by layer, yielding hierarchical register of the paper. And then hierarchical index tree is constructed by merging the register of all papers. In the online stage, to adaptively retrieve via the hierarchical index tree, PaperRegister first employs view recognizer to identify views of input query, which associates to suitable indexes from the hierarchical index tree, then matches query against these indexes to achieve precise paper search. One key aspect of PaperRegister is the view recognizer, which must be both low latency and high accuracy. To this end, we construct the view recognizer by training smallscale language model via hierarchical-reward reinforcement learning. Firstly, in order to alleviate the online latency, we adopt language model with 0.6 billion parameter as base. Then, in order to equip the model with basic identifying capability, we perform supervised fine-tuning (SFT) on it, with query as input and the golden view as label. Furthermore, in order to further enhance accuracy of the view recognizer, considering the hierarchical dependency of views in the hierarchical register schema, we design hierarchical reward as the reinforcement learning signal, which is calculated by closeness level between the predicted view and golden view in hierarchical register schema. And then we employ this reward on group relative policy optimization (GRPO) (Shao et al. 2024) training to enhance the view recognizer. In experiments, we compare PaperRegister with some common-used baselines on paper search tasks across various levels of granularity. The results show PaperRegister achieves state-of-the-art performance, with improvements being more pronounced as query granularity finer, confirming that PaperRegister is robust solution for challenging flexible-grained paper search tasks. Additionally, detailed ablation and analysis demonstrate the importance of hierarchical register indexing, the effect and performance of view recognizer training, the good compatibility with extra complex paper search frameworks, and the online low-latency advantage compared with several powerful baselines. Code for this work is in https://github.com/Li-Z-Q/PaperRegister. PaperRegister As mentioned, existing paper search systems fail to handle flexible-grained queries due to they primarily collect paper abstracts to construct index of corpus, which does not contain detailed information to support queries at finer granularity. To this end, we propose PaperRegister, which supports flexible-grained paper search via hierarchical register indexing. As illustrated in Figure 2, PaperRegister consists of two stages: in the offline stage, hierarchical index tree for paper corpus is built, and in the online stage, retrieval is performed by adaptively using suitable indexes from the tree. {p(m)}M Task Formulation The paper search task involved in this work provides query as input, with the goal of retrieving relevant papers {p(m)}M m=1 based on the index of paper corpus C, which can be expressed as the following formula: m=1 = F(q, I) (1) For regular paper search, the view of is typically coarse-grained topic that user interests, and systems mainly construct index based on paper abstracts to match against query q. As users requirements become more flexible, the view may refer to details such as module configuration and training operation. In this context, since these detailed information typically do not appear in abstract, existing paper search systems cannot perform accurate retrieval. Therefore, we propose PaperRegister to boost flexible-grained paper search, which transforms abstract-based index into hierarchical index tree for paper search, the specific process will be further explained in the following sections. Offline Hierarchical Indexing Considering that the granularity of view in queries can be flexible across very fine-grained, moderately fine-grained, to coarse-grained, PaperRegister offline constructs hierarchical index tree for paper corpus to support flexible paper search. Specifically, based on hierarchical register schema, PaperRegister obtains hierarchical register for each paper through fine-grained content extracting and bottom-up content aggregating. Then the hierarchical index tree is constructed by merging hierarchical register of all papers. Hierarchical Register Schema. To obtain the hierarchical register for each paper, we design hierarchical register schema, consisted of information nodes as following: Ni,j = {ni,j : (ci,j, {Ni+1,j}Z j=1)} (2) where Ni,j is the j-th information node at the i-th layer, ni,j is the node name, ci,j is the node content that will be obtained via specific paper text, Ni+1,j is sub-node of Ni,j, is the number of sub-nodes under each node, and [1, ..., L], where is the number of layers in schema. In this hierarchical register schema, the shallow-layer nodes represent coarse-grained information of the paper, and deep-layer nodes represent finer-grained information. For example, in the i+1-th layer, Ni+1,j and Ni+1,j+1 respectively denote module configuration and training operation in the paper, which are two kinds of relatively fine-grained information. While their common parent in the i-th layer, Ni,j, denotes method implementation, which is coarser-grained summary of Ni+1,j and Ni+1,j+1, thereby forming the register schema with hierarchical information nodes. In addition, since different types of papers have different styles and formats, we design five kinds of hierarchical register schema, corresponding to five types of paper including algorithm innovation, benchmark construction, mechanism exploration, survey, and theory proof. We use large language model to determine the type of input paper and then assign the corresponding hierarchical register schema. The detailed illustration is presented in the Appendix A. Fine-grained Content Extracting. Based on above hierarchical register schema, in order to obtain the fine-grained contents as much as possible, PaperRegister first perform extracting for each information node at the L-th layer based on paper p(m), which can be represented as follows: c(m) L,j = Mextract(p(m), nL,j) where nL,j represents the name of information node NL,j and Mextract is the extracting module for this process. (3) To achieve accurate extraction, learning from several widely recognized works, in which large language models are proven to possess reliable capabilities for content extraction (Edge et al. 2024; Li et al. 2025c), PaperRegister uses large language model as the extracting module. Specifically, PaperRegister takes the node name and the text-formatted paper as input, uses instructions to guide in outputting corresponding content for the information node, and leaves it blank if the paper does not include corresponding content. The detailed process and instructions are in Appendix B. Bottom-up Content Aggregating. After extracting all the finest-grained contents, in order to obtain the complete hierarchical register, PaperRegister aggregates node contents layer by layer from bottom to top based on the hierarchical register schema, which can be represented as follows: i,j = Maggregate({c(m) c(m) (4) where layer is from 1 to 1, thereby obtaining content for each node in the hierarchical register schema for p(m). i+1,j}Z j=1) To achieve accurate aggregation, as extraction process, PaperRegister uses large language model as the aggregating module Maggregate. Specifically, PaperRegister takes contents of sub-nodes as input and uses instructions to guide the large language model in summarizing, condensing, and removing details to turn into summary text, thus obtaining the content for upper-layer information node. The detailed process and instructions are presented in the Appendix C. At this point, PaperRegister obtains node contents at various granular levels to compose the hierarchical register for p(m), and then merges register of all papers in corpus to construct hierarchical index tree Ih, as shown in following: i=1 = {{Midx{c(m) Ih = {{Ii,j}Z i=1 (5) where Midx is the indexing module such as BM25 and DPR, each Ii,j is an index in the hierarchical index tree Ih, corresponding to kind of view for the paper corpus. i,j }C m=1}Z j=1}L j=1}L Online Adaptive Retrieval Based on above offline hierarchical indexing, PaperRegister perform online adaptive retrieval via suitable indexes from the hierarchical index tree. Specifically, PaperRegister first identifies views involved in the input query, determining corresponding indexes from the hierarchical index tree, then conduct retrieval by matching query against these indexes. View Identifying. In order to achieve adaptive retrieval, PaperRegister first uses view recognizer to identify the view vk in the input query q, represented as follows: {vk}K k=1 = Midentif y(q) (6) where the candidate set of vk is all node paths in the hierarchical register schema, Midentif is employed base on small-scale language model with special training, which will be explained in next section. And to ensure that identifying results can cover the real views of query as more as possible, Midentif uses the beam search strategy (Holtzman et al. 2020) to sample the top-K output views. View-based Matching. After identifying views in the input query, PaperRegister looks up corresponding indexes from the hierarchical index tree Ih, as following: {Ik}K k=1 = Mlookup(Ih, {vk}K k=1) (7) where each Ik is consisted of {c(m) }C m=1 as in Formula 5."
        },
        {
            "title": "Then these indexes are used to calculate relevance score",
            "content": "of input query and each paper p(m), as following: s(q, p(m)) = max{Mrel(q, c(m) )K k=1} (8) where Mrel is relevance module such as BM25 and DPR. Finally, the retrieved papers with top-M relevance score, m=1, are selected as retrieval results for query q. {p(m)}M Figure 3: Illustration of view recognizer training, including SFT and GRPO via hierarchical reward, which is calculated based on the closeness level of predicted view and golden view in the hierarchical register schema. View Recognizer Training For the PaperRegister system mentioned above, the view recognizer is key aspect, which must both alleviate the latency and ensure the accuracy of view identifying. To this end, as shown in Figure 3, we use small-scale language model with 0.6B parameters as the base model, followed by initial supervised fine-tuning (SFT), and then further enhance its view identifying capability by hierarchical-reward group relative policy optimization (GRPO) training. Training Data. The format of training dataset to support SFT and GRPO is shown as follows: Dtrain = {qj, vj}Dtrain j= (9) where qj is query, vj is the golden view of query, which is node path in hierarchical register schema. To ensure the stability of training, we make the approximate same number of each view in the training dataset through manual sampling. Supervised Fine-tuning. To give the small-scale view recognizer basic identifying ability and make it easier for subsequent reinforcement learning training, we first perform SFT by minimizing the following loss: LSF (θ) = E(q,v)Dtrain (cid:88) t= log πθ(vtq, v<t) (10) where πθ is the model and vt is the t-th token of golden view. Hierarchical-reward GRPO. To further strengthen the view identifying ability of small-scale view recognizer, we conduct GRPO (Shao et al. 2024) training with hierarchical reward, which is calculated based on the node paths closeness level of predicted view and golden view in the hierarchical register schema. Specially, considering the hierarchical feature of register schema, different wrong predicted views should not be treated equally. For example, if the golden views path in the hierarchical register schema is Abstract-Method-Implementation-Operation, and two predicted views are Abstract-Method-Implementation-Module and Abstract-Experiment-Dataset, although both are wrong, the first one is better than the second one because it is closer to golden view in the hierarchical register schema, suggesting higher information overlap with the golden view. Based on this idea, we measure the path overlap between the predicted view ˆvj and the golden view vj in the hierarchical register schema, obtaining the hierarchical reward: = Moverlap(vj, ˆvj) ˆvj + Moverlap(vj, ˆvj) vj (11) where Moverlap returns the overlapping level of two inputs, ˆvj means the path length of predicted view in the hierarchical register schema and vj is that of golden view. Then this hierarchical reward is used in GRPO training, which is by maximizing the following objective: JGRP (θ) = E(cid:104) qDtrain,{vi}G i=1 πθold min (cid:34) πθ πθold (cid:0)vi,t q, vi,<t (cid:1) (cid:0)vi,t q, vi,<t (cid:41) ˆAi,t, clip( (cid:1) βDKL [πθ πref] , where ˆAi,t = 1 (cid:88) 1 (cid:40) vi (cid:88) (cid:105) (vq) vi i=1 (cid:0)vi,t q, vi,<t (cid:1) (cid:0)vi,t q, vi,<t πθ πθold t=1 (cid:35) (cid:1) , 1 ϵ, 1 + ϵ) ˆAi,t ri mean({r1, r2, ..., rG}) std({r1, r2, ..., rG}) where πθold is initialized by the SFT model, is the number of each group, ϵ and β are two hyper-parameters."
        },
        {
            "title": "Experiments",
            "content": "Experimental Settings Datasets. We first use LitSearch (Ajith et al. 2024), mainly containing coarse-grained queries. And then we build new dataset, Flexible-grained Search, covering queries across various granularity and including data for test, development, and training. The detailed statistical information of dataset is shown in Appendix D. And the metrics used and reported in experiments are R@5 (recall@5) and R@10 (recall@10). (1) LitSearch (Ajith et al. 2024). By using GPT-4 to rewrite citations in papers and asking authors to write, this dataset constructs 597 paper search queries, mainly involving coarse-grained topics like Where can find research on evaluating consistency in generated summaries. (2) Flexible-grained Search. We collect 4,200 papers in machine learning field as corpus and perform the offline hierarchical indexing. To build test data across various granularity, we pick hierarchical register of 2,100 papers, employ Qwen3-32B to find original paper texts related to each content in register, then use Qwen3-32B to generate queries based on these texts, obtaining 5,644 test data including 3 parts: general-granularity (F.g.Search-1), fine-granularity"
        },
        {
            "title": "Method",
            "content": "Title Abstract Total Paper Rewriting HyDE CSQE Chunkavg Chunkmax Paragraphavg Paragraphmax BM25-based Matching DPR-based Matching"
        },
        {
            "title": "LitSearch",
            "content": "F.g.Search-1 F.g.Search-2 F.g.Search-"
        },
        {
            "title": "LitSearch",
            "content": "F.g.Search-1 F.g.Search-2 F.g.Search-3 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 54.2 67.1 64.2 61.9 68.9 69. 58.1 67.9 29.7 64.3 59.5 71.3 68.9 69.6 75.4 73.8 67.6 75.5 38.3 70.9 42.0 63.7 79.7 58.4 60.3 59. 68.1 80.0 58.9 73.8 47.3 69.0 82.4 64.2 66.3 64.4 74.2 83.1 66.6 78.8 36.1 57.4 81.4 54.1 54.3 54. 66.6 81.4 59.8 75.4 Direct Matching 42.0 62.9 83.5 30.4 54.2 84.2 35.3 59.7 86.2 Query Paraphrasing 59.8 60.0 58.6 71.9 84.7 66.5 79.9 50.9 51.5 51.3 56.3 57.6 55.9 Paper Splitting 65.9 85.3 58.2 80. 71.6 87.6 66.2 83.9 66.8 77.7 74.8 76.0 76.5 77.9 58.1 67.9 20.5 79.5 73.1 83.2 81.9 83.2 83.4 81. 67.6 75.5 22.8 85.0 52.0 69.4 72.9 67.1 66.8 65.8 51.1 79.8 23.3 79.2 58.8 74.3 78.7 72.6 72.3 71. 58.3 83.1 30.6 82.8 45.8 62.1 68.8 60.4 58.9 60.2 46.4 76.6 23.1 76.5 52.1 68.1 73.8 65.2 65.7 65. 53.4 80.5 29.8 81.4 40.6 58.2 65.8 55.2 56.3 55.2 46.4 79.0 22.4 78.8 47.1 63.1 71.0 60.9 62.4 60. 52.2 82.1 29.2 81.8 Hierarchical Register Indexing PaperRegister (Ours) 69.7 76.4 89. 90.9 88.0 89.0 87.5 88.7 81. 87.1 84.1 87.1 79.9 82.5 80. 82.9 Table 1: Main experimental results on paper-searching tasks across various granularity, where the granularity is coarse-to-fine from LitSearch to F.g.Search-3. The table shows that PaperRegister is powerful solution to addressing flexible-grained paper search and the advantages of PaperRegister become more pronounced at finer granular queries. (F.g.Search-2), and very fine-granularity (F.g.Search-3). The format of each test data is like {qj, pj}. To build training and development data, we use register of another 2,100 paper and directly generate queries for contents in each paper register, where each query is with golden view, the format of training and development data is like {qj, vj, pj}. Then we do random splitting and get 13,824 training data and 695 development data, the training data are used in view recognizer training part as illustrated in the Formula 9 and development data are used for analysis in the Table 3. Selected Baselines. We select baselines from commonly used or recent methods suitable for paper search tasks. (1) Direct Matching. These methods directly use paper titles, abstracts or total text of papers to construct index of corpus, and retrieval by matching query with these contents. (2) Query-paraphrasing Methods. These methods aim to improve paper-searching performance by paraphrasing the input query, including: Rewriting (Ma et al. 2023), which uses LLM to rewrite original query. HyDE (Gao et al. 2023), which uses LLM to generate fake document based on input query and retrieves real documents by this fake document. CSQE (Lei et al. 2024), which initially retrieves several documents and then uses LLM to expand original query based on these initially-retrieved documents. We use Qwen3-32B as the LLM when conducting these baselines. (3) Paper-splitting Methods. These methods split the original paper into multiple short parts, then calculate the similarity between the query and each short part, and finally integrate all the similarity to determine the overall similarity of query and original paper. In experiments, we employ four kinds of settings, including splitting the original paper to the fixed length of 512-token chunk or by the raw paragraph, taking the average similarity or the maximum similarity of all parts as the final score, represented as Chunkavg, Chunkmax, Paragraphavg, and Paragraphmax, respectively. Implementation Details. In the offline stage, we employ Qwen3-32B (Qwen 2025) as the large language model in process of fine-grained content extracting and bottom-up content aggregating, and deploy it as API by vllm1 on two A100 80G GPU for convenience. In the online stage, we set as 5 and as 5 or 10, use Qwen3-0.6B (Qwen 2025) as the base model of view recognizer, employ prefix tree-based restricted decoding strategy (Tang et al. 2024) in the view identifying process to prevent the model outputting irrelevant token, and conduct the view-based matching process via rank-bm252 for BM25 and gte-Qwen2-7B-instruct (Li et al. 2023) for DPR. For the view recognizer training, we use TRL3 framework to conduct SFT and GRPO. We set train epoch as 5 in SFT, as 5 and train epoch as 2 in GRPO, and keep all other parameters as default value in TRL. When conducting baselines, we keep the same settings as above. Overall Results Results compared with baselines are shown in the Table 1, there are two main conclusions based on the results: (1) PaperRegister is powerful solution to addressing flexible-grained paper search tasks. As shown in the Table 1, PaperRegister demonstrates excellent performance in paper search tasks at various granularity, outperforming all baselines in both BM25-based matching and DPR-based matching settings, on both recall@5 and recall@10 metrics. For example, in F.g.Search-3, under the DPR-based matching setting, PaperRegister achieves recall@5 score of 80.8, while using abstract-based index yields only 58.2, where PaperRegister can achieve performance improvement of 22.6. All in all, PaperRegister can improve lot compared with various previous paper search methods. 1https://pypi.org/project/vllm/ 2https://pypi.org/project/rank-bm25/ 3https://github.com/huggingface/trl BM25-based Matching DPR-based Matching Method"
        },
        {
            "title": "LitSearch",
            "content": "F.g.Search-1 F.g.Search-2 F.g.Search-"
        },
        {
            "title": "LitSearch",
            "content": "F.g.Search-1 F.g.Search-2 F.g.Search-3 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 R@5 R@10 PaperRegister (Ours) w/ only layer-1 w/ only layer-2 w/ only layer-3 69.7 64.5 66.8 64. 76.4 70.4 73.8 71.7 89.7 87.8 84.4 79.9 90.9 90.6 86.5 81.8 88.0 77.4 87.1 83.7 89.0 80.2 88.8 85.0 87.5 73.5 82.0 86. 88.7 76.7 84.4 88.1 81.0 79.0 78.9 78.8 87.1 83.5 84.2 85.2 84.1 82.5 81.1 77.8 87.1 85.2 84.9 81.1 79.9 73.4 79.3 77. 82.5 77.1 82.2 80.0 80.8 68.1 73.5 80.4 82.9 72.2 77.9 82.6 Table 2: Ablation results for the hierarchical register indexing. The table shows that hierarchical index tree are important for flexible-grained paper search and different layers in the hierarchical register schema serve queries at different granularity."
        },
        {
            "title": "Recognizer",
            "content": "ACC Latency (s) Qwen3-32B Qwen3-32B (few-shot) View Recognizer in PaperRegister w/ only SFT w/o hierarchical reward 30.5 47.8 83.5 80.9 81.7 28.3 37.8 2.3 - - Figure 4: Paper search performance of the PaperRegister with different view recognizer. The figure shows strong recognizer is with obvious positive impact on overall system. Table 3: Comparison and ablation for the view recognizer training. The table shows that the training process in this work is an effective approach to obtain view recognizer with both high performance and low latency. (2) Compared to traditional methods, the advantages of PaperRegister become more pronounced at these finer granular queries. According to experimental setting, from LitSearch to F.g.Search-1 to F.g.Search-2 to F.g.Search-3, the granularity of the paper search query becomes increasingly finer. And the experimental results show that the performance improvement of PaperRegister over the method using abstract-based index becomes larger. For example, under the DPR-based matching setting, PaperRegister achieves recall@5 scores of 81.0, 84.1, 79.9, and 80.8 on the four datasets, respectively, while using the abstract-based index yields scores of 77.7, 69.4, 62.1, and 58.2. Here, PaperRegister delivers performance improvements of 3.3, 14.7, 17.8, and 22.6, respectively. Therefore, PaperRegister exhibits more improvements over baseline on finer-grained queries, which can to some extent validate rationality of this works motivation, that traditional paper search via abstractbased index struggles to handle fine-grained queries. Ablation Results To validate the importance of hierarchical register indexing, we employ ablation experiments by simplifying the hierarchical register schema. As shown in Table 2, where w/ only layer-1 means retaining only the coarsest-grained nodes, w/ only layer-2 means retaining only the medium-grained nodes, and w/ only layer-3 means retaining only the finestgrained nodes. Based on these simplified register schema for experiments, we get the following conclusions: (1) Hierarchical register indexing is important for ensuring the effectiveness of paper search. As shown in Table 2, compared to using the complete hierarchical register schema, using register schema composed of nodes from any single layer leads to obvious performance drop. For example, recall@5 of LitSearch under BM25-based matching drops from 69.7 to 64.5, 66.8, 64.6 for w/ only layer1, w/ only layer-2, w/ only layer-3, respectively. And other datasets also show similar situation. Therefore, results strongly prove importance of hierarchical register indexing. (2) Different layers in the hierarchical register schema serve queries at different granularity. For example, under w/ only layer-1 setting, the DPR-based matching and recall@5 metric of F.g.Search-1 drops from 84.1 to 82.5 (1.6 decrease), while F.g.Search-1 is from 80.8 to 68.1 (12.7 decrease), which is significantly larger than 1.6. Conversely, under w/ only layer-3 setting, F.g.Search-1 drops from 84.1 to 77.8 (6.3 decrease), while F.g.Search-3 is from 80.8 to 80.4 (0.4 decrease), which is much smaller than 6.3. Therefore, nodes from different layers play specific roles in handling queries of different granularity, further strongly demonstrating necessity of hierarchical register indexing. Detailed Analysis In this section, we conduct detailed analysis including: the effect of view recognizer, the compatibility of PaperRegister with complex PaSa framework (He et al. 2025), and an analysis of the online search efficiency. Due to the space constraint, we only report the performance that is based on DPR-based matching for analysis in this section. Effect of View Recognizer and Training. To analyze the role of view recognizer in PaperRegister and necessity of our training, we first examine relationship between recognizer capability and PaperRegister performance in Figure 4, then compare with Qwen3-32B and conduct ablation in Table 3. As shown in Figure 4, where Bad Recognizer,Random Recognizer,Weak Recognizer represent the completely incorrect, randomly predicting, and weak-performing view recognizers, respectively, the curve demonstrates clear"
        },
        {
            "title": "Method",
            "content": "Online Paper Search Latency (s) Rewriting HyDE CSQE Chunkmax Paragraphmax PaperRegister (Ours) 9.3 20.7 33.5 5.4 4.2 2.5 Figure 5: Performance of adding PaperRegister into the PaSa framework. The figure shows that PaperRegister can greatly cooperate with extra complex modules in PaSa framework. Table 4: Comparison of online latency among PaperRegister and several baselines. The table show that PaperRegister is with better real-world applicability with less latency. positive correlation between the capability of view recognizer and final performance of PaperRegister. Therefore, building an accurate view recognizer is key factor for the PaperRegister to achieve high-performance paper search. As shown in Table 3, We compare accuracy and latency of view identifying between the view recognizer in PaperRegister and Qwen3-32B (enable thinking) under zero-shot and few-shot settings. The results show the view recognizer in PaperRegister is with better accuracy and latency than powerful Qwen3-32B. Furthermore, we only keep SFT for the view recognizer training, or replace the hierarchical reward with direct 0-1 reward in GRPO training. Results show that the accuracy decreases to some extent. Therefore, training small-scale language model with SFT and then hierarchicalreward GRPO is an effective approach to obtain the view recognizer with both high performance and low latency. Compatibility with Complex PaSa Framework. Considering that PaperRegister is mainly retrieval module, and given that some recent complex paper search frameworks such as PaSa (He et al. 2025) incorporate various modules like rewriting, retrieval, iteration, and filtering, in order to explore whether PaperRegister can be compatible with such complex frameworks and further enhance performance, we replace the original retrieval module in PaSa with PaperRegister. As shown in Figure 5, PaperRegister can further improve the performance of PaSa across paper search tasks at various granularity. Therefore, PaperRegister can be effectively adapted as retrieval module into complex paper search frameworks and further enhance the capability. Analysis for Online Search Efficiency. Considering that the efficiency of online paper search system is crucial aspect of its usability in practical scenarios, we compare the online search efficiency of PaperRegister with multiple baselines. As shown in the Table 4, the online latency of these baselines is significantly higher than that of PaperRegister, which limits the practical applicability of these methods in real-world scenarios. In contrast, PaperRegister demonstrates the acceptable online latency, proving its good potential for application in the real-world paper search. Related Work To achieve accurate paper search, previous related works mainly focus on enhancing the input query, with less attention given to the index of paper corpus. Some works improve paper search performance by rewriting the original query, such as using powerful large language models for rewriting based on some manually designed instructions (Ma et al. 2023; Anand et al. 2023), generating pseudo-documents to replace original query for retrieval real documents (Gao et al. 2023; Li et al. 2024a), or employing several powerful models as agent system to conduct multi-round rewriting and expansion (He et al. 2025; Ren et al. 2025). Another kind of works expands the input query through pseudorelevance feedback, such as augmenting the query based on initially retrieved documents (Lei et al. 2024; Li et al. 2025a), or extracting several keywords from the corpus to enrich the information of original query (Kang et al. 2024; Zhang et al. 2025). Although these works can improve performance in regular paper search, they fail to address flexible-grained queries because they do not solve the flaws in the index of paper corpus. Recently, several works split original paper by fine-grained fields and then construct multiple-field indexes for retrieval (Sotaro et al. 2024; Li et al. 2025b; Shi et al. 2025; Chen et al. 2025). However, these works still cannot effectively handle flexible-grained queries because they only focus on single granularity level. Compared with above related works, the largest advantage of PaperRegister is hierarchical register indexing and conducting paper search with hierarchical index tree, which can effectively handle flexible-grained paper search. Conclusion In this work, noticed limitation of existing methods in paper search tasks, we propose PaperRegister, boosting flexiblegrained paper search via hierarchical register indexing. In the offline stage, PaperRegister constructs hierarchical index tree by fine-grained content extracting and bottomup content aggregating. In the online stage, PaperRegister first identify views of input query, then matches the query against corresponding indexes from the hierarchical index tree. Furthermore, we construct the view recognizer by applying supervised finetuning and hierarchicalreward group relative policy optimization to small-scale language model. Experiments on extensive flexible-grained paper search tasks demonstrate that PaperRegister is an effective solution, which reaches the SOTA performance, with improvement being more pronounced as query granularity finer. Therefore, this work offers promising direction for developing more powerful paper search systems in future. References Ajith, A.; Xia, M.; Chevalier, A.; Goyal, T.; Chen, D.; and Gao, T. 2024. LitSearch: Retrieval Benchmark for Scientific Literature Search. In Al-Onaizan, Y.; Bansal, M.; and Chen, Y.-N., eds., Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 1506815083. Miami, Florida, USA: Association for Computational Linguistics. Anand, A.; Setty, V.; Anand, A.; et al. 2023. Context aware query rewriting for text rankers using llm. arXiv preprint arXiv:2308.16753. Case, D. O.; and Given, L. M. 2016. Looking for information: survey of research on information seeking, needs, and behavior. Emerald Group Publishing. Chen, P. B.; Wolfson, T.; Cafarella, M.; and Roth, D. 2025. EnrichIndex: Using LLMs to Enrich Retrieval Indices Offline. arXiv preprint arXiv:2504.03598. Cohan, A.; Feldman, S.; Beltagy, I.; Downey, D.; and Weld, D. 2020. SPECTER: Document-level Representation Learning using Citation-informed Transformers. In Jurafsky, D.; Chai, J.; Schluter, N.; and Tetreault, J., eds., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 22702282. Online: Association for Computational Linguistics. Edge, D.; Trinh, H.; Cheng, N.; Bradley, J.; Chao, A.; Mody, A.; Truitt, S.; Metropolitansky, D.; Ness, R. O.; and Larson, J. 2024. From local to global: graph rag approach to query-focused summarization. ArXiv preprint, abs/2404.16130. Ellis, D.; Cox, D.; and Hall, K. 1993. comparison of the information seeking patterns of researchers in the physical and social sciences. Journal of documentation, 49(4): 356 369. Gao, L.; Ma, X.; Lin, J.; and Callan, J. 2023. Precise ZeroShot Dense Retrieval without Relevance Labels. In Rogers, A.; Boyd-Graber, J.; and Okazaki, N., eds., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 17621777. Toronto, Canada: Association for Computational Linguistics. He, Y.; Huang, G.; Feng, P.; Lin, Y.; Zhang, Y.; Li, H.; and E, W. 2025. PaSa: An LLM Agent for Comprehensive Academic Paper Search. In Che, W.; Nabende, J.; Shutova, E.; and Pilehvar, M. T., eds., Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1166311679. Vienna, Austria: ISBN 979-8Association for Computational Linguistics. 89176-251-0. Hemminger, B. M.; Lu, D.; Vaughan, K.; and Adams, S. J. 2007. Information seeking behavior of academic scientists. Journal of the American society for information science and technology, 58(14): 22052225. Holtzman, A.; Buys, J.; Du, L.; Forbes, M.; and Choi, Y. 2020. The Curious Case of Neural Text Degeneration. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net. Kang, S.; Zhang, Y.; Jiang, P.; Lee, D.; Han, J.; and Yu, H. 2024. Taxonomy-guided Semantic Indexing for Academic Paper Search. In Al-Onaizan, Y.; Bansal, M.; and Chen, Y.- N., eds., Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 71697184. Miami, Florida, USA: Association for Computational Linguistics. Kuhlthau, C. C. 1991. Inside the search process: Information seeking from the users perspective. Journal of the American society for information science, 42(5): 361371. Lei, Y.; Cao, Y.; Zhou, T.; Shen, T.; and Yates, A. 2024. Corpus-Steered Query Expansion with Large Language Models. In Graham, Y.; and Purver, M., eds., Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), 393401. St. Julians, Malta: Association for Computational Linguistics. Li, H.; Wang, X.; Koopman, B.; and Zuccon, G. 2025a. Pseudo Relevance Feedback is Enough to Close the Gap Between Small and Large Dense Retrieval Models. arXiv preprint arXiv:2503.14887. Li, L.; Zhang, X.; Zhou, X.; and Liu, Z. 2024a. AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels. arXiv preprint arXiv:2410.20050. Li, M.; Chen, T.; Durme, B. V.; and Xia, P. 2025b. MultiIn The Thirteenth International Field Adaptive Retrieval. Conference on Learning Representations. Li, Z.; Chen, X.; Yu, H.; Lin, H.; Lu, Y.; Tang, Q.; Huang, F.; Han, X.; Sun, L.; and Li, Y. 2024b. Structrag: Boosting knowledge intensive reasoning of llms via inferencetime hybrid information structurization. ArXiv preprint, abs/2410.08815. Li, Z.; Lin, H.; Lu, Y.; Xiang, H.; Han, X.; and Sun, L. 2024c. Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge in Datasets and Large Language Models. arXiv preprint arXiv:2403.09750. Li, Z.; Yu, H.; Chen, X.; Lin, H.; Lu, Y.; Huang, F.; Han, X.; Li, Y.; and Sun, L. 2025c. DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking. In Che, W.; Nabende, J.; Shutova, E.; and Pilehvar, M. T., eds., Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 43804396. Vienna, Austria: Association for Computational Linguistics. ISBN 979-8-89176-251-0. Li, Z.; Zhang, X.; Zhang, Y.; Long, D.; Xie, P.; and Zhang, M. 2023. Towards general text embeddings with multi-stage contrastive learning. ArXiv preprint, abs/2308.03281. Ma, X.; Gong, Y.; He, P.; Zhao, H.; and Duan, N. 2023. Query Rewriting in Retrieval-Augmented Large Language Models. In Bouamor, H.; Pino, J.; and Bali, K., eds., Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 53035315. Singapore: Association for Computational Linguistics. Mackie, I.; Chatterjee, S.; and Dalton, J. 2023. Generative Relevance Feedback with Large Language Models. In Chen, H.; Duh, W. E.; Huang, H.; Kato, M. P.; Mothe, J.; Zheng, Z.; Hui, K.; He, B.; Han, X.; Sun, L.; and Yates, A. 2020. BERT-QE: Contextualized Query Expansion for DocIn Cohn, T.; He, Y.; and Liu, Y., eds., ument Re-ranking. Findings of the Association for Computational Linguistics: EMNLP 2020, 47184728. Online: Association for Computational Linguistics. and Poblete, B., eds., Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 2327, 2023, 20262031. ACM. Mysore, S.; OGorman, T.; McCallum, A.; and Zamani, H. 2021. CSFCube - Test Collection of Computer Science Research Articles for Faceted Query by Example. In Thirtyfifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). Qwen, T. 2025. Qwen3 Technical Report. ArXiv preprint, abs/2505.09388. Ren, S.; Jian, P.; Ren, Z.; Leng, C.; Xie, C.; and Zhang, J. 2025. Towards scientific intelligence: survey of llm-based scientific agents. arXiv preprint arXiv:2503.24047. Shao, Z.; Wang, P.; Zhu, Q.; Xu, R.; Song, J.-M.; Zhang, M.; Li, Y. K.; Wu, Y.; and Guo, D. 2024. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models. ArXiv preprint, abs/2402.03300. Shi, J.; Zhou, S.; Jin, B.; Hu, W.; Wang, S.; Narasimhan, G.; and Han, J. 2025. Hypercube-RAG: Hypercube-Based Retrieval-Augmented Generation for In-domain Scientific Question-Answering. arXiv preprint arXiv:2505.19288. Sotaro, T.; Simone, P.; Kai, E.; and Sotaro, T. 2024. GenGO: In Cao, ACL Paper Explorer with Semantic Features. Y.; Feng, Y.; and Xiong, D., eds., Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), 117126. Bangkok, Thailand: Association for Computational Linguistics. Tang, Q.; Chen, J.; Li, Z.; Yu, B.; Lu, Y.; Fu, C.; Yu, H.; Lin, H.; Huang, F.; He, B.; Han, X.; Sun, L.; and Li, Y. 2024. Self-Retrieval: End-to-End Information Retrieval with In Globersons, A.; Mackey, One Large Language Model. L.; Belgrave, D.; Fan, A.; Paquet, U.; Tomczak, J. M.; and Zhang, C., eds., Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024. Wadden, D.; Lin, S.; Lo, K.; Wang, L. L.; van Zuylen, M.; Cohan, A.; and Hajishirzi, H. 2020. Fact or Fiction: Verifying Scientific Claims. In Webber, B.; Cohn, T.; He, Y.; and Liu, Y., eds., Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 75347550. Online: Association for Computational Linguistics. Wang, J.; Wang, K.; Wang, X.; Naidu, P.; Bergen, L.; and Paturi, R. 2023. Scientific Document Retrieval using Multilevel Aspect-based Queries. In Oh, A.; Naumann, T.; Globerson, A.; Saenko, K.; Hardt, M.; and Levine, S., eds., Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Zhang, Y.; Yang, R.; Jiao, S.; Kang, S.; and Han, J. 2025. Scientific Paper Retrieval with LLM-Guided SemanticBased Ranking. ArXiv preprint, abs/2505.21815. Appendix This part is about detailed illustration for the hierarchical register schema. Since different types of papers have the different styles and formats, we design five kinds of hierarchical register schema, corresponding to five types of paper including algorithm innovation, benchmark construction, mechanism exploration, survey, and theory proof. We use large language model to determine the type of input paper and then assign the corresponding hierarchical register schema. The details of each kind of schema is in Figure 6 7 8 9 10. And the instruction used to help LLM to do determine is ==Instruction== Determine the category of the paper based on its abstract. The category options are as follows: Algorithm Innovation: Proposes new systems, new models, new training methods, new inference approaches, new data organization methods, etc. Benchmark Construction: Introduces new benchmark. Mechanism Exploration: Investigates and analyzes the mechanisms of existing systems, algorithms, phenomena, or functionalities. Theory Proof: Proves certain theory or formula. Survey and Review: Summarizes the research landscape of particular field. Your final output should be only the best correct category of the paper, do not contain any other information or explanation. ==Abstract== abstract Appendix This part is about detailed process and instructions for the fine-grained content extracting. Learning from several widely recognized works, in which large language models are proven to possess reliable capabilities for content extraction (Edge et al. 2024; Li et al. 2025c, 2024b,c), PaperRegister uses large language model as the extracting module. PaperRegister takes the node name and the text-formatted paper as input, uses instructions to guide in outputting corresponding content for the information node, and leaves it blank if the paper does not include corresponding content. In addition, PaperRegister also retrieve relevant paper text after the extracting as supplement to improve the register content. The instruction used for LLM is ==Instruction== You are an content extraction expert, particularly skilled at extracting structured records from academic papers. Below, need you to perform extraction based on given schema. Please note the following: 1. Your extraction does not need to preserve the original text verbatim. You may paraphrase or summarize the content to make the extracted content more comprehensive and fluent. 2. Not all field names in the schema will have corresponding content in the paper. If you cannot find precise match in the paper, leave that field empty. 3. Your final output must strictly adhere to the original schema in JSON format, starting with json and ending with . ==Schema== schema ==Paper== paper Figure 6: The first kind of hierarchical register schema. Figure 7: The second kind of hierarchical register schema. Figure 8: The third kind of hierarchical register schema. Figure 9: The fourth kind of hierarchical register schema. Figure 10: The fifth kind of hierarchical register schema. Appendix This part is about detailed process and instructions for the bottom-up content extracting. PaperRegister takes contents of sub-nodes as input and uses instructions to guide the large language model in summarizing, condensing, and removing details to turn into summary text, thus obtaining the content for upper-layer information node. In addition, PaperRegister also retrieve relevant paper text after the extracting as supplement to improve the register content. The instruction used for LLM is ==Instruction== You are an information integration expert, and now need your help to complete an information integration task. will provide you with two-level tree structure, including root node and two child nodes. Ideally, the content of the root node should be summary and generalization of the two child nodes. Your task is to generate the content of the root node based on the content of the two child nodes. Note the following: 1. The input provide you is dictionary in JSON format, including the keys root name and children, where the value of children is list of child nodes. 2. Each child node contains three fields: node name, node desc, and node value. You should primarily use the content of node value for summarization and generalization. 3. The root value field should provide an abstraction and summary of the two child nodes contents. In other words, the root value must not repeat keywords from the child nodes; instead, it should abstract based on those keywords. More strictly, the root value length must not exceed that of either child node. 4. Your output should be dictionary in JSON format, meaning the input dictionary will have content for the root value field. The final output should start with json and end with . ==Input Tree== tree Appendix This part is about detailed statistical information of dataset for the experiments. We first use LitSearch, mainly containing coarse-grained queries. And then we build new dataset, Flexible-grained Search, covering queries across various granularity and including data for test, development, and training. Due to limited computational resources, we are unable to conduct experiments based on an ultra-large-scale paper corpus. For LitSearch, we extract 3,400 papers as the corpus, using the original 597 paper search queries. For Flexible-grained Search, we collect 4,200 papers as the corpus. The numbers of queries included in F.g.Search-1, F.g.Search-2, and F.g.Search-3 are 1,922, 1,922, and 1,800, respectively."
        }
    ],
    "affiliations": [
        "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences"
    ]
}