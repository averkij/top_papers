{
    "paper_title": "Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face",
    "authors": [
        "Benjamin Laufer",
        "Hamidah Oderinwale",
        "Jon Kleinberg"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Many have observed that the development and deployment of generative machine learning (ML) and artificial intelligence (AI) models follow a distinctive pattern in which pre-trained models are adapted and fine-tuned for specific downstream tasks. However, there is limited empirical work that examines the structure of these interactions. This paper analyzes 1.86 million models on Hugging Face, a leading peer production platform for model development. Our study of model family trees -- networks that connect fine-tuned models to their base or parent -- reveals sprawling fine-tuning lineages that vary widely in size and structure. Using an evolutionary biology lens to study ML models, we use model metadata and model cards to measure the genetic similarity and mutation of traits over model families. We find that models tend to exhibit a family resemblance, meaning their genetic markers and traits exhibit more overlap when they belong to the same model family. However, these similarities depart in certain ways from standard models of asexual reproduction, because mutations are fast and directed, such that two `sibling' models tend to exhibit more similarity than parent/child pairs. Further analysis of the directional drifts of these mutations reveals qualitative insights about the open machine learning ecosystem: Licenses counter-intuitively drift from restrictive, commercial licenses towards permissive or copyleft licenses, often in violation of upstream license's terms; models evolve from multi-lingual compatibility towards english-only compatibility; and model cards reduce in length and standardize by turning, more often, to templates and automatically generated text. Overall, this work takes a step toward an empirically grounded understanding of model fine-tuning and suggests that ecological models and methods can yield novel scientific insights."
        },
        {
            "title": "Start",
            "content": "Anatomy of Machine Learning Ecosystem: 2 Million Models on Hugging Face Benjamin Laufer,, Hamidah Oderinwale,, Jon Kleinberg Abstract Many have observed that the development and deployment of generative machine learning (ML) and artificial intelligence (AI) models follow distinctive pattern in which pre-trained models are adapted and fine-tuned for specific downstream tasks. This process is responsible for much of the powerful functionality we see in current AI systems, but there is limited empirical work that examines the actual structure of these interactions across the AI development community broadly construed. Here we analyze 1.86 million models on Hugging Face, leading peer production platform for model development. Our study of model family treesnetworks that connect finetuned models to their base or parentreveals sprawling fine-tuning lineages that vary widely in size and structure. Using an evolutionary biology lens to study ML models, we use model metadata and model cards to measure the genetic similarity and mutation of traits over model families. We find that models tend to exhibit family resemblance, meaning their genetic markers and traits exhibit more overlap when they belong to the same model family. However, these similarities depart in certain ways from standard models of asexual reproduction, because mutations are fast and directed, such that two sibling models tend to exhibit more similarity than parent/child pairs. Further analysis of the directional drifts of these mutations reveals qualitative insights about the open machine learning ecosystem: Licenses counter-intuitively drift from restrictive, commercial licenses towards permissive or copyleft licenses; models evolve from multi-lingual compatibility towards English-only compatibility; and model cards reduce in length and standardize by turning, more often, to templates and automatically generated text. Overall, this work takes step toward an empirically grounded understanding of model fine-tuning and suggests that ecological models and methods can yield novel scientific insights about the development of cutting-edge AI models. 5 2 0 2 ] . [ 1 1 1 8 6 0 . 8 0 5 2 : r"
        },
        {
            "title": "Introduction",
            "content": "Generative artificial intelligence (AI) and machine learning (ML) models are being adopted across variety of domains. As these technologies develop, there is notable diversity in their Cornell Tech, bdl56@cornell.edu. McGill University, hamidah.oderinwale@mail.mcgill.ca. Equal contribution. Cornell University. 1 Figure 1: Family trees from the ecosystem dataset. Edges represent different forms of derivative models that are documented as having finetuned, quantized, adapter or merged existing models. Diffusion patterns reveal large broadcasts and numerous generations of derivatives. Graphs without merges are trees, meaning no model has more than one parent (upper left, upper right, and lower left). All graphs are directed and acyclic. levels of availability and paths of diffusion. For example, fully closed-source models may be available through chatbots and API calls, but their weights, source code, training data, and other artifacts remain hidden from view. In contrast, open models make some or all of these materials publicly available for developers and downstream users. The leading provider of open source models is Hugging Face, platform that hosts models, datasets, libraries, and other materials so that communities of developers can easily use AI models, and perhaps even create derivative products that are useful to others. By making AI models readily available, Hugging Face has cultivated an emerging ecosystem of interacting developers of open source models. The present work offers an empirical analysis of the open source ML/AI ecosystem on Hugging Face. We analyze information from the 1.86 million models indexed on Hugging Face, finding rich structural diversity in the diffusion of innovation of open source ML. In 2 particular, accessing information about model family trees,1 we trace the inheritance and mutation of traits between relatives to understand how models develop and evolve. Consider, as one example, the model ibm-granite/granite-3.1, language model developed by the company IBM [19] and available on Hugging Face. That models family tree is depicted in the upper right panel of Figure 1. The tree network depicts the connections among 147 modelsthe base model contributed by IBM and 146 derivative models, many contributed by open source developers. Every black dot represents distinct, publicly available model, and every directed edge represents path from parent model to derivative modelthat is, finetune, quantization, or adapter. The base model produced by IBM spawned eighteen children, of which five are finetunes and the rest are quantizations. Only two of the childrenboth finetunesspawned further generations of children. Moving down another layer, we can see that one of these children produced many more offspring than the other, and from this ancestor there are further branching generations. As of the time that our snapshot data was ingested, this tree spans five generations, but nothing is stopping developers from continuing to tweak, finetune, and produce new members of this family. The two other trees depicted in Figure 1 are families with considerably higher numbers of members. They demonstrate some of the diverse structures and rich topologies that arise when we map these model families. This paper makes the following contributions: 1. We propose studying the evolutionary biology of machine learning models to 1) understand the complexities of the development process, 2) analyze model properties and traits and 3) characterize evolutionary trends over time. To that end, we provide the largest dataset to date of the open-model development ecosystem. Using snapshot of all publicly available models hosted on the platform Hugging Face, our dataset contains variety of features and, crucially, rich information about the topological relations between modelsthat is, whether they finetune, merge, or adapt from one or more other models. 2. We use information from the metadata and model card to track the models genetic traits and measure the genetic similarity between models. We find that models of the same family bear significant resemblance. However, this resemblance departs from typical biological populations because mutations occur at high rate. For instance, we find that pairs of finetuned siblings share more traits than parent/child pairs, on average, suggesting that mutations occur at high rate, and are not random but have strong directional trends. 3. To understand these directional trends, we conduct network analysis of the diffusion of model traits between models. We find that mutations of traits including licenses, languages, and tasks are overwhelmingly acyclic; and we solve for optimal orderings over these properties. These orderings allow us to verify, for instance, that translation models are genetically upstream from text-generation models, on whole, and that models with llama3 licenses are genetically upstream from those with apache-2.0 1They are described as model families colloquially and on Hugging Faces webpage corresponding to any available model. 3 licenses. The directed and acyclic property of model traits suggests that models are evolving in response to environmental pressures, and we produce number of hypotheses from the data about the nature of these pressures, which may come from surrounding market or from behavioral tendencies of developers involved in open source communities. For example, the data suggest that models evolve: (a) From restrictive or commercial licenses toward permissive or copyleft licenses, at times representing departure from the terms of the upstream model. (b) From general multilingual support toward language specialization, with an overwhelming trend toward English-language support. (c) From expansive documentation practices toward lean or minimal documentation practices. These trends yield new hypotheses about the environmental pressures on AI development. For instance, the observation that licenses trend toward permissiveness and copyleft varieties suggests that preferences for open source outweigh existing regulatory pressures to comply with licenses. The drift toward English-language models suggests formidable market for english-language products. These and other hypotheses are discussed along with future directions for inquiry."
        },
        {
            "title": "1.1 Related work",
            "content": "This paper aims to measure and analyze the structure of AI fine-tuning and related adaptation and transfer learning procedures. These relationships connect finetuned and remixed AI models to their parent model(s) whose weights, structures, and other elements might influence the childs development. The sources of inspiration for this work come from scholarship on social networks and the web, multi-agent interactions and modeling AI development, and finally, approaches from theoretical ecology and genetics. We cover relevant work from each of these categories in turn. Social Networks on the Web. Goel et al. [17] differentiate broadcast diffusion trees from viral trees using metric they term structural virality, which we use to measure the connected components in Appendix 8. Many have considered the dependence of graph features on local network topology, including in the context of attachment [46], link prediction [31, 33], feature prediction [20, 23] and community inference [16]. In contrast, our approach attempts to predict trait similarity and trait transitions over tree network. Though empirical work on Hugging Face is limited, some strides have been made. Horwitz et al. [25] calls for work mapping an atlas of models on Hugging Face, demonstrating that directed acyclic graphs representing model relationships can be drawn for certain families and providing dataset with 1.1 million models. Our work answers this call and offers an expanded dataset. Choksi et al. [5] explore chats and conversations among community members and contributors, evidence of vibrancy and richness among contributing developers. Bommasani et al. [3] coin ecosystem graphs as an abstraction for understanding AI development, and analyze preliminary set of 128 models that they use to demonstrate the usefulness of ecosystems thinking for reasoning about social implications and regulation of AI. Duan et al. [11] tracks the frequency of copyleft license violations across model derivatives using dataset of around 4 15,000 models on Hugging Face. Rahman et al. [41] use the Hugging Face API to create graph of information about models totaling 402,654 nodes. Multi-agent interactions and modeling. Scholars have developed theoretical models and theories of the multi-actor system surrounding the development of AI technologies. Laufer et al. [29] create game-theoretic model to understand how domain specialists and generalists interact to produce the technology. Others have developed depth-one tree structures as model for understanding AI diffusion [8, 26, 30, 40]. Hopkins et al. [24] use directed acyclic graphs (DAGs) of arbitrary depth to allow supply chains of interacting actors to understand the dynamics of AI supply chains. There is budding work on decisionmaking along these networks [45, 48], though much of it is theoretical. Further, we claim that perspectives on incentives, competition, cooperation have tended to be organized by economicrather than ecologicalmetaphors. Here, we wish to go deeper with the ecological phenomenology of AI development and diffusion. Theoretical Ecology and Genetics. This paper is inspired by perspectives of systems as complex adaptive systems, characterized by emergent properties that arise from smallscale interactions between components [32]. Sclocchi et al. [42], taking machine learning perspective, understand model phylogeny as prediction problem, and show that models with larger normed parameter vectorsweights and biases of greater magnitudetend to be higher up in the family tree. In different genealogical approach to machine learning, Kalluri et al. [27] draw links between ML papers and downstream produce developments, focusing on surveillance applications."
        },
        {
            "title": "2 A dataset of 1.86 million models on Hugging Face",
            "content": "In this work, we examine the Hugging Face model hub, the largest public repository of machine learning models, containing 1.86 million models at the time of this study. We approach Hugging Face as platform for peer production, building on prior research into collaborative systems and the structure of the broader web [2, 15, 47]. With rich textual information containing information about the relationship between models as well as their traits, we can represent the complex network of models on Hugging Face as set of phylogeniesbranching trees rooted in base models, where nodes correspond to individual models and edges denote parentchild relationships."
        },
        {
            "title": "2.1 Data collection",
            "content": "We collected the data for our dataset in two stages. In the first stage, we used the Hugging Face model API to collect the model features and relationshipsthat is, all pieces of information in our dataset aside from the model cards. Hugging Face provides API access to individual lists of models, but these lists are capped to only list 1000 models. Using pagination, we were able to iterate over all such lists of models to collect the information in our dataset in JSON format. In the second stage, we collected the full text of every models model card through individual, per-model API calls to the model cards API. These cards 2Our dataset is publicly available at the following link: Hugging Face dataset. Our codebase is available at the following link: GitHub repository. 5 were significantly more data-intensivesince model cards can be quite large and many more API calls were required to find all 1.86 million models in the dataset. In total, our full dataset uses memory on the order of 10GB (depending on the file format used), and the dataset without model cards uses significantly lower memory, at around 500MB. All calls to the API were conducted through the authors registered accounts on Hugging Face, and in consultation with employees at Hugging Face, including Hugging Faces in-house librarian."
        },
        {
            "title": "2.2 Properties and summary statistics",
            "content": "Our dataset centers around snippets of text for every model known as the models metadata. Model metadata comes in JSON format, and this JSON is made readily available for any model through Hugging Faces API. These JSONs include the model id (a unique identifier for each model containing its author and name), likes, trendingScore (a trait defined by Hugging Face for ranking models on their website), downloads, pipeline tag (also known as taska categorization of models into e.g., feature-extraction, text- -generation, image-classification, and other modalities), library name (the Hugging Face library used to support development), createdAt (the date and time that the model was created3), and tags. Tags contain structured list of strings, some with organized prefixes. For example, tags beginning with base model:finetune: link finetuned model to its parents model id, tags beginning with license: contain the models license, and those beginning with arxiv: contain links to the arXiv identifiers of accompanying papers. Other tags do not have these prefixes, but their meaning can still be inferred. For example, languages are listed using twoor three-letter ISO-639 codes. summary of the distributions of the various metadata traits is provided in Figure 2. These distributions convey the relative frequencies of different traits, as well as the absolute number of papers with these documented traits. Here, we provide some findings these figures convey about the state of the open source ecosystem on Hugging Face, reading from left to right and top to bottom through the figure. First, permissive licenses especially apache-2.0 and mit are dominant, constituting over 60% of all reported licenses. Text-based tasksand especially text-generationare most common. English is by far the dominant language compatibility on Hugging Face, with over 75% of models that document any language compatibility marking english as supported language. Chinese is the second most-common at 4.4%. transformers is the most common Hugging Face library. black-forest-labs/FLUX.1-dev is the model that has the most children. imagefolder is the most commonly recorded dataset in metadata. Machine Learning and Computers and Society codes are the most common among linked arXiv papers. Finally, in the lower right figure, we show the most downloaded models, finding that the model Falconsai/nsfw image detection is the most downloaded. This models purpose is to detect and identify explicit imagery and is perhaps used for content moderation and compliance. remarkable amount of information is conveyed in text snippets that Hugging Face stores for every model. Throughout the paper, we treat the snippets of text provided by 3Tracking of the createdAt date and time began March 2, 2022. According to the Hugging Face documentation, and corroborated by our findings, all models created before that date are back-filled with that date; the date is accurate for all models uploaded thereafter. 6 Figure 2: Top ten most frequent licenses, tasks, languages, and libraries (top row). Top ten models ranked by number of children, datasets, arXiv categories of linked papers, and downloaded models (bottom row). the metadata JSON as the models DNA, as it contains rich information about traits and allows us to track changes and differences over generations (illustrated in Figure 4). Before embarking on this genetic analysis, we discuss one additional source of genetic information: the model cards. 2.2.1 Model cards Model cards are documents that carry information about the use, performance, compatibilities, risks, impacts, and many other pieces of information about models [38]. Model cards are the main form of documentation for models on the hub, and they constitute much of the information that populates on any given models associated webpage. Model cards can be considerably longer than metadata, and much less structured. They can therefore contain more information, however, not all models have corresponding model cards, and they are considerably less standardized and organized. According to our data, 67.04% of models currently have an associated model card. An analysis of the 1,247,149 cards available reveals an average model card length of 3575.60 characters ( 436.06 words), with median of 2073.0 characters ( 238.0 words). This wide range, from minimum of 11 characters to maximum of 18,289,454 characters ( 2,813,762 words), indicates that small number of extremely verbose cards significantly influence the average. 7 Figure 3: Schematic representing different family relationships using an example family tree from our dataset (left). For the ten largest family trees, we depict the growth of the graph over time using the CreatedAt field logged when new model is created on Hugging Face (right). The growth of the ten largest connected components in our dataset reveals S-curve adoption patterns [14], analogous to other domains with diffusion over network. Figure 4: The diff between two sequences of model metadata. We measure the overall mutation rate and genetic similarity by tracking rates of overlap and departure between these sequences. The metadata sequence depicted on top is that of Qwen/Qwen1.5-72B, the base model depicted in Figure 3; the bottom sequence is one of its finetunes. Additions are shown in green, deletions in red, and substitutions in yellow. This figure depicts characterlevel mutations corresponding most closely to the Levenshtein distance. We additionally measure and report similarity on term-level representations (using bag-of-words and TFIDF), which we believe better captures categorical shifts in metadata."
        },
        {
            "title": "3 Measuring genetic similarity",
            "content": "With rich structured data about the relationships between AI models, there are number of questions we can ask about the diffusion of model attributes. Inspired by ecological and genetic perspectives [12, 22] and existing work on network diffusion [46], here we explore the relationship between family structure and attribute similarity. We develop method for measuring how related two models tend to be given their proximity in our graph. If finetuning family trees are akin to genetic family trees, we might expect two models finetuned from the same parent model (siblings) to be more similar, on average, than any two models selected at random from our dataset. Taking the metaphor further, if we think of the encodings of model attributesincluding licenses, tags, text data, and other metadata informationas akin to DNA in biological species, reproductive models would predict that parent-child pairs tend to be more genetically related than uncle-nephew pairs or grandparent-grandchild pairs. Semantic similarity as genetic similarity. In living organisms, genes are encoded in semantic language through sequences of nucleotide basesor building blocksin DNA. One way of measuring genetic relation is by measuring the overlap or similarity in DNA sequences. AI models encode their own forms of semantically meaningful instruction sequences through their code bases, model cards, metadata, and model weights. Luckily, open models on Hugging Face make many of these resources publicly available, enabling formal approaches to reasoning about model similarity. Each of these artifacts is different in kind, and of course, none are perfect analogies for DNA. Here, we provide method for measuring genetic similarity between models, inspired by the genetic metaphor. Our approach measures the semantic distance between the models tokenized metadata. We propose measuring the frequency of different terms in the model metadata and tracking differences in these relative frequencies. Our approach to calculating similarities borrows from classical contributions in natural language processing based on term frequency. We replicate our analysis for three similarity measures the normalized Levenshtein Distance [52], which directly computes characterlevel insertions and deletions as depicted in Figure 4, the cosine similarity in term frequency (or bag-of-words) embeddings, and the cosine similarity in term frequency-inverse document frequency (TF-IDF) embeddings. We measure similarities across two different model artifacts metadata JSONs and the text of model cards. Our results across these different metrics reveal the same insights: that models of the same model family are more genetically similar than randomly paired models, and that genetic similarity is negatively related to the generational divide and topological distance. Further information on these various metrics and approaches are provided in Appendix 6. In the body of the text, we report the cosine similarity on TF-IDF embeddings derived from the metadata strings (Figure 5). Analyzing fine-tuning trees. To conduct our analysis for this section, we consider fine-tuning edges. We omit from consideration structures of model merges, adaptations and quantizations. Omitting merges allows us to work with treethat is, graph where nodes have at most one predecessorakin to asexual reproduction.4 We omit adaptations and 4We leave this as an open direction the genetic analysis of model merges, which can be thought of as form of sexual reproduction with two or more parents. Graphs depicting model merges are no longer trees, and the set of local family structures is more complex. Another challenge is the frequency of model merges, which we find are considerably more rare than other forms of reproduction. 9 quantizations because these forms of reproduction are far less likely to branch and further support their own offspring compared to finetunes, and we intend this analysis to provide insights about the propagation of attributes over multiple generations. Sampling immediate family structures. Our aim is to measure the similarities between models residing within different immediate family structures in our large tree graph. One challenge with estimating quantities over these local structures is that they may appear combinatorically many times in large graph. To illustrate what we mean by this, consider the set of all pairs of siblings in tree graph. If one model has 500 children, the total number of pairs of siblings among them is (cid:0)500 (cid:1) or 124, 750. Therefore, estimating the typical similarity over all pairs of siblings quickly becomes computationally burdensome. To handle this challenge, we design an estimation procedure, where we draw representative sample from the set of all pairs of models meeting certain relational criterion. Our approach specifies condition for checking whether particular node, or particular edge, resides within certain structure of subgraph, and if it does, we count how many such subgraphs it belongs to. Continuing our example of counting siblings, if any node has more than one child, this condition allows us to conclude that it belongs to at least one sibling subgraph (depicted in the third row of Table 1). By counting us children nsucc(u), we can infer the number of total such subgraphs contributes to, calculated as, (cid:0)nsucc(u) (cid:1). 2 If we keep lookup table of all such nodes meeting the subgraph condition, and the multiplicity of pairs contributed, then we can draw weighted sample of the nodes in our lookup table to efficiently estimate quantities defined over sibling pairs. The full set of conditions, multiplicity relations, and subtree structures we make estimates over is depicted in Table 1. We sample all possible subgraphs of size 2, 3, and 4, and we estimate the similarities between all possible pairs of nodes within these subgraphsparents, grandparents, siblings, etc. 2 Family resemblance and diffusion characteristics. Our main results are depicted in Figure 5. The results suggest that models that are close in network topology have considerably more similarity than randomly selected pairs of nodes. This offers some evidence that model family trees truly do exhibit family resemblances. However, patterns of similarity over family trees are not cleanly predicted by typical models of genetic diffusion. For example, we find that siblings are significantly more similar to one another than either is to its parent, on average (depicted in the first subfigure labeled C). This is counter to what an asexual model of genetic reproduction with mutation might predict. If we imagine each child model in family inheriting the parents genes subject to some rate of random mutation, siblings should be more related to their parent than each other, on average. We observe the opposite, suggesting that there is some directional effect of fine-tuning whereby all children tend to depart in attributes from their parents, on average, in characteristically similar ways (illustrated in Figure 6). When we look at pairs of nodes in variety of subgraphs, we see evidence of three major heuristics that seem to dictate the level of similarity between pairs of models: 1. Same family: If models belong to the same family tree, they appear to exhibit significantly higher levels of similarity, compared to models paired at random over our dataset. 2. Low generational divide: When we compare two models that are the same generation in their family tree (e.g., siblings or cousins), we find that this majorly increases 10 Figure 5: Cosine similarity between TF-IDF embedding vectors, trained on terms appearing in the model metadata for all models in our dataset. Here, we sample finetunes meeting specific family structures. We enumerate all possible sub-trees of size 2 (B), 3 (C), and 4 (D), and enumerate all possible pairs of nodes within these sub-trees. When we compare these genetic similarities to the baseline of the similarity between any two nodes in the graph (A), we find that all observed family ties strongly predict attribute similarity. Similarities between pairs of models suggest that models are more related when they reside at similar depths and when they are topologically close in distance. Topology Occurrences 3,470,193,356,870 191,072 119,795,843 40,922 193,010,561, 11,847,103 19,932,645 10,965 Figure 6: We observe that siblings exhibit greater similarity in traits than parent-child pairs. This implies not only that there is high rate of mutation, but that mutations are sufficiently directed. Figure 7: The graph contains many instances of some family subtrees. Pairwise similarities within subtrees are estimated via sampling. the level of similarity between models. Models that are one generation apart (e.g., parent/child pairs or uncle/nephew pairs) tend to be significantly more similar, on average, than models that are two generations apart (e.g., grandparent/grandchild pairs). The same relationship holds when comparing grandparent/grandchild pairs to great-grandparent/great-grandchild pairs. 3. Network distance: third heuristic that seems to explain the observed similarities in model attributes is the network distance, that is, the total number of edges one would need to traverse to get from one node pair to the other. This is what genetic model of mutation-based asexual reproduction would predict. This factor is supported by the fact that uncle/nephew pairs are observed to be less similar, on average, than parent/child pairs belonging to the same subgraph structures (depicted in the second and third columns of subfigure D3 in Figure 5). Though most measures suggest generational divide outweighs network distance in importance, there is one exception: In the last two similarity measures in D3, we observe parent-child pair with network distance one exhibits higher similarity than sibling pair with network distance two. There are further questions that one might ask about how the diffusion of characteristics relates to the strategies and decisions ML developers make. Scientists have used models of genetic diffusion to predict cooperative, altruistic, competitive, and perhaps even spiteful behaviors in living species. For example, the theory of kin selection predicts altruistic and competitive behaviors in wolves, which are known to engage in both 1) extreme forms of selfsacrifice for their closest genetic relatives in their packs, and 2) extreme forms of competition and fighting with more distant genetic relatives in other packs [4]. Open ML ecosystems similarly exhibit complex dynamics with fierce forms of competition and extreme forms of cooperation. Model providers are known to compete and may undercut each other in certain ways, but still exhibit altruistic behaviors to enable third-party development, for example by releasing model weights. The analysis in this section reveals that models have more attributes in common with members of their family, and future work could explore whether these relationships predict altruistic and competitive behaviors across this ecosystem."
        },
        {
            "title": "4 Evolution of traits",
            "content": "The previous section examined overall similarities between models across their recorded features. This section is concerned with individual traits, focusing on their inheritance and evolution. Unless otherwise specified, we refer to categorical features as traits and concentrate on three examples: license, language and task. Through analyzing these, we demonstrate general method for understanding trait evolution across family trees. We also report results on numerical attributes including the length of relevant documents and the number of languages. In many cases, traits remain the same between parent and child. However, if traits were always constant between parent and child, wed observe far less heterogeneity in our data, and wed find perfect similarity across all related model pairs in Figure 5. Because we do, in fact, observe feature diversity across models, here we focus on cases where model traits change between parent and child, that is, cases where the parent has trait i, the 12 child holds trait j, and = j. Further information about our formal way of defining the rate of mutation is provided in Appendix 7. In observing these instances of mutation, we make number of specific observations and findings pertaining to the individual traits in question (discussed in the proceeding subsections). More generally, we make two empirical observations that hold descriptively, but are not necessary or obvious. 1. Directedness: We observe that mutations tend to be overwhelmingly directed. Formally, for any two traits (i, j), it is most common that overwhelmingly mutates to or that overwhelmingly mutates to i, rather than some balance of traffic of mutations in both directions. We call this phenomenon drift. 2. Orderedness: When we consider the orientations of all directed mutations, we find that these orientations are ordered. If we define the oriented graph of typical transitions between traits, we are able to find orderings over these transitions that explain virtually all these orientations. Notice that the first observation does not imply the second. It could be that overwhelmingly mutates to j, which overwhelmingly mutates to k, which overwhelmingly mutates back to i. We do not observe this for the vast majority of drifts. Second, we note that the task of finding an ordering over directed graph is an integer programming problem, NP-hard in the worst cases. Our implementations are able to find optimal orderings, not due to luck but due to the natural orderings that emerge from our oriented graphs."
        },
        {
            "title": "4.1 Licenses drift from commercial to permissive and copyleft.",
            "content": "How do license assignments change and mutate across model lineages? We count 162 unique license types on the Hugging Face Hub, 98 of which are standardized license categories provided by the platform (excluding user-defined unknown and other licenses). Each model contains one license, so our reported mutation rate simply tracks the number of times parent and child have different licenses, as fraction of the overall number of observed inheritances. Our analysis of the direction of evolution of licenses is summarized in Figure 8. The figure depicts the most common licenses and the drifts between themthat is, the arrows point in the more frequent mutation direction over all observed mutations. The graph is an oriented directed graph of all 140 drifts between 20 traits, where edge weight depends on the total traffic of mutations. Using the graph, we can ask, what ordering over traits is most compatible with these drifts? If mutations were fully random, or if cycles were common, we would not be able to produce an ordering that captures more than approximately half of the observed mutation directions. However, we are able to produce an ordering accounting for 94% of all drift directions, and 84% of all mutations. This suggests strong directedness in the evolution of licenses. And, equipped with this ordering, we can begin to develop hypotheses about the environmental pressures leading to the observed evolution. The license mutations exhibit somewhat surprising pattern. We observe many instances in which the more restrictive, commercial licenses are upstream from the more permissive 13 Optimal ordering: gemma, llama3.1, llama3.2, openrail++, creativeml-openrail-m, cc-by-nc-4.0, llama3, llama2, mit, afl-3.0, bigscience-bloom-rail-1.0, llama3.3, apache-2.0, cc-by-nc-sa-4.0, cc-by-4.0, openrail, artistic-2.0, cc-by-sa-4.0, gpl-3.0, cc Observed inheritances: 320,065 Mutation rate: 14.98% Drifts following this order: 132/140 (94.29%) Mutations following this order: 84.26% Figure 8: An oriented directed network of license mutation drifts (left) and corresponding summary statistics (right). Each node represents license in our dataset, with directed edges indicating mutations in which parent and child have different licenses. Drifts seem to be directed from commercial and restrictive licenses to permissive and copyleft licenses. licenses.5 Consider, as one example, the gemma license, which appears first in our observed ordering. The terms of this license include the following requirement: You must provide all third party recipients of Gemma or Model Derivatives copy of this Agreement. The license further lists use restrictions, including restriction on uses that sexually explicit content, including content created for the purposes of pornography or sexual gratification (e.g. sexual chatbots). This license mutates most frequently to Apache-2.0 and MIT licenses, each which contain no such provisions. As second example, we observe mutation drifts from cc-by-nc-4.0, copyleft license that restricts derivatives from commercial uses, to MIT, which grants permissions without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell. The same non-commercial license also mutates to other licenses of the same variety (Creative Commons) but without the non-commercial agreement, which seems to be strict relaxation of terms. These instances of relaxations appear to be the norm rather than the exception. Of the first eight licenses in our ordering, seven are commercial (gemma or llama varieties) or otherwise restrictive (openrail varieties). Of the last eight licenses in our ordering, none are commercial; three are permissive or public domain (cc, apache-2.0, artistic-2.0) and four others are copyleft varieties (cc-by-*, gpl-3.0). Looking exclusively at creative commons licenses, non-commercial restrictions lie upstream from versions without these previsions. Why would licenses weaken and relax even when doing so might constitute violation of upstream agreement terms? The observed mutation drift suggests market and behavioral 5When we refer to the categories of permissive, restrictive, commercial, and copyleft, we are using taxonomies and descriptors from existing scholarship, most notably from Longpre et al. [36] in the context of machine learning licenses. Figure 9: Even though model cards diminish in length over generations (left), the absolute frequency with which they use the terms automatically generated or generated automatically increases precipitously (right). These markers of auto-generated cards are uniquely observed in finetunes and adapters, suggesting these are byproducts of existing packages and libraries that enable developers to create finetunes and adaptations, and not those that enable merges and quantizations. pressures toward openness outweigh the specter of legal enforcement as motivator for AI developers."
        },
        {
            "title": "4.2 Documentation thins.",
            "content": "Armed with method for analyzing how traits drift and evolve over generations, we now turn our attention to information about the model cards. Specifically, we are interested in the effort and resources devoted to documentation and transparency for models of different generations in the open source ecosystem. One significant trend that we observe is that documentation thins. Markers of bespoke effort aimed at supporting users, communicating methods, and demonstrating capabilities seem to atrophy. Markers of leaner approaches and automation develop and multiply. When we look at the state of model cards between parents and children in our family trees, we can make few straight-forward observations. Model cards exist at very high rate for models that belong to family trees. Missing model cards are far more frequent among models with no family ties. Among models with family ties, the model card is almost always available, even if it is only few characters long. Among parent-child pairs with model cards, we observe that the length of these cards drops by 5, 000 characters. The parents model card is roughly twice the size of the childs model card, on average. Even though the model cards get significantly shorter, we observe that they more frequently contain the terms that suggest automatic card generation. About 30% of derivative models contain the bigrams automatically generated or generated automatically. These results, depicted in Figure 9, suggest pressures toward lean documentation and automation technologies that remove costs to document and explain models, their capabilities, their uses, and other information typically contained in the model card. 15 Optimal ordering: Polish, Swedish, Thai, Italian, Portuguese, Romanian, Dutch, German, French, Japanese, Indonesian, Vietnamese, Turkish, Russian, Spanish, Chinese, Arabic, Hindi, Korean, English Observed inheritances: 115,660 Mutation rate: 12.80% Drifts following this order: 186/190 (97.89%) Mutations following this order: 74.71% Figure 10: Network of language mutation drifts (left) and corresponding summary statistics (center). Each node represents compatibility with language in our dataset, with directed edges indicating mutations in which parent and child have different language compatibilities. Drifts are directed towards English. We also see considerable diminishing language support over generations (right)."
        },
        {
            "title": "4.3 Languages specialize and drift toward English.",
            "content": "Language traits are different in kind from licenses because an individual model can be compatible with more than one language. Whereas mutation is binary event in the case of license traits, for languages we allow partial mutations. Consider case where model finetunes to model j. Model has language group (A, B, C) and has language group (B, C, D). We say that the overall mutation rate is the shared members of both groups divided by the union of both groups (i.e., in this example, the mutation rate would be 1 2). Further, we log distinct directional mutations from every dropped language to every child language, and from every parent language to every added language. To continue our example, wed log mutations from to B, C, and and from A, and to D. These enable us to produce similar drift diagrams and orderings to those produced for licenses. Our findings are summarized in Figure 10. The language traits show two dominant trends: 1) specialization and 2) drift towards English. The first of these trends, specialization, refers to the significant reduction in language compatibility from base models to child models. Large base models supporting significant family trees tend to support many languages, whereas derivative models tend to list compatibility with one or handful of languages. Therefore, we see precipitous reduction in the language support between parents and finetuned children. The second observation we can make about language traits is that they drift overwhelmingly from broad language support to English-language support. This drift suggests considerable market pressure towards English-speaking products and compatibilities. This drift is not entirely surprising given Hugging Face is United States-based company. However, an increasing number of Chinese models are being developed and hosted and we do not observe commensurate drift towards Chinese compatibility."
        },
        {
            "title": "4.4 Tasks appear to recapitulate the machine learning lifecycle.",
            "content": "The final branch of our analysis of individual traits will focus on the tasks. Tasks capture the models core capability or modality: Is the model text generation model? An image generation model? feature extraction model? text-to-image, image-to-text, text-to-text, or other modality-translation task? Is it classification model? Like the model licenses, tasks typically have one-to-one mapping to models, and so the overall rate of mutations can be interpreted simply as the fraction of edges where parent and child have different tasks. The rate of mutation is high, at 23%, and the ordering we uncover reveals very strong directed evolution, where 95% of mutations are observed along the ordering. Optimal ordering: fill-mask,image-text-to-text, feature-extraction, automatic-speech-recognition, text-to-speech, translation, summarization, text-generation, object-detection, text-to-image, any-to-any, sentence-similarity, question-answering, audio-to-audio, image-classification, image-to-text, text-classification, token-classification, audio-classification, reinforcement-learning Observed inheritances: 251,060 Mutation rate: 23.14% Drifts following this order: 111/121 (91.74%) Mutations following this order: 95.16% Figure 11: An oriented directed network of task mutation drifts (left) and corresponding summary statistics (right). Each node represents task in our dataset, with directed edges indicating mutations in which parent and child have different tasks. There is high rate of mutation, and the direction of drifts seems to recapitulate the machine learning pipeline. Our results are depicted in Figure 11. The results seem to suggest that tasks progress from low-level feature extraction tasks (e.g., fill-mask, feature-extraction, automatic- -speech-recognition) to modality translations (e.g., translation, text-generation, summarization, text-to-image), to classification and reinforcement learning tasks. One interpretation of this progression is that This progression seems to reflect stages in the machine learning training pipelinebeginning with general-purpose pre-training, followed by fine-tuning and alignmentmirroring how capabilities emerge and specialize over time [1, 49]. Foundational capabilities seem to appear first, followed by modality-specific tasks, to human-aligned reasoning that produces outputs for human use. The machine learning pipeline might be summarized as follows: First, raw inputs such as text, speech, or video are tokenized or embedded into vectors to prepare them for model processing [10, 34, 54]. Second, models perform representation learning by generating contextual embeddings through masked token prediction and related techniques [9]. Third, tasks become oriented around model adaptation, such as handling cross-modal inputs or supporting 17 low-resource languages [50]. Fourth, classification tasks assign discrete labels to how models have understood inputs [28] (their learned representations). Fifth, generative tasks such as summarization and text-to-image synthesis produce outputs from context [6, 44, 53]. Lastly, techniques like instruction tuning and reinforcement learning help improve how models generate outputs, especially for tasks that require complex reasoning or alignment with human preferences [7, 35, 39]. Overall, we offer this interpretation as possible explanatory hypothesis. We believe further research would be needed to substantiate or refute such an interpretation. Just as theories of recapitulation in human development have been contested and in many cases refuted6 we hope these observations are generative in motivating further inquiry."
        },
        {
            "title": "5 Discussion",
            "content": "In this paper we have proposed and taken step towards studying the evolutionary biology of machine learning models. We offer publicly-accessible dataset revealing the rich linkages between models and the genes and traits that models carry. We further propose measures to capture the genetic similarity between models using snippets of text summarizing model attributes. Analyzing the characteristic similarities between models belonging to different local family structures, we make certain intuitive observations (e.g., that related models are more genetically related than random pairs of models) and other less-intuitive observations (e.g., that sibling pairs are considerably more genetically related than parent-child pairs). Our analysis suggests that mutation is fast and directed, and we begin to analyze the particular directional evolution of traits, focusing on licenses, languages, model card lengths and terms, and tasks. These reveal environmental pressures towards informal, lean and open attributes, especially regarding license agreements and documentations. These pressures towards openness seem to outweigh pressures to abide by upstream agreements. Further, we observe language individuation and an overwhelming drift towards english-only compatibility, though upstream models often list compatibility across many languages. Limitations. Limitations to our findings include the fact that we only account for models that have logged fine-tuning relationships on Hugging Face. Many models may be related without having these relationships. For instance, models released with different numbers of paramaters are often each available as their own base model, so we do not consider Qwen/Qwen1.5-0.5B and Qwen/Qwen1.5-1.8B to be members of the same family. Though we use metadata and model card snippets as metaphors for DNA, there are other sources of semantic information we do not access. Future work may analyze model repositories config.JSON files to extract architectural parameters, such as vocabulary size (inferring the training dataset size and costs), attention heads, and hidden dimensions, to reveal further attributes of models and trace how structural traits evolve across the ecosystem. Text from code repositories and even the model weights themselves could contain additional low-level semantic encodings of model properties and internals. Finally, the timescale of this analysis is limited to the lifespan of the Hugging Face platform. However, since open models predate Hugging Face, future work could extend this analysis by incorporating historical data from 6Recapitulation theory is largely discredited theory of development. The view is often summarized by the idea that ontogeny recapitulates phylogeny [21, 37, 43]. 18 earlier model repositories and academic publications to capture the complete evolutionary trajectory of open source ML. Changes to the Hub interface (e.g., available fields and auto-generated documentation) affect what developers report about their models. As Hugging Face has evolved, shifts in reporting behavior may introduce inconsistencies in the data that reflect platform changes rather than changes in the models themselves. For example, the CreatedAt field was introduced in March 2022 and all existent models were back-filled values equal to the date of feature launch. This could possibly inflate the genetic similarity between such models. Future directions. We see the present work as first step towards range of studies that this dataset and perspective could support. For example, though our data represent snapshot in which models exhibit fixed qualities, there are variety of attributes that may be time-dependent or trends that could be uncovered with time-series data. Further, where our approach focused on open source models, there is huge industry of closed models and these ecosystems have interesting interactions. Structural complexity arises not only from the number of descendants but also from the introduction of merges, which combine distinct lineagesessentially marrying families. Mergers between models could be viewed as form of sexual reproduction, contrasting with the one-to-one parentchild mappings that this paper focuses on. As merges become more popular, the Hugging Face graph may undergo phase transition in which nearly all nodes become connected in single, massive connected component. Further analysis is needed to understand model merges and their effect on the ecosystem. Lastly, future work could build on the ecological ideas in this paper, exploring concepts such as niche formation, competition, cooperation, kin selection, and succession. Work in these areas could help explain how model families grow, stabilize, or die out and move into understandings of population dynamics."
        },
        {
            "title": "Acknowledgements",
            "content": "The authors thank the AI, Policy and Practice (AIPP) group at Cornell University and the Digital Life Initiative (DLI) at Cornell Tech. We thank Samuel Klein, Daniel van Strien (in-house librarian at Hugging Face), Aleksandra Korolova, Helen Nissenbaum, Tori Qiu, Solon Barocas, Madiha Zahrah Choksi, Gopal Raman, and Manish Raghavan for illuminating conversations and comments. BL also wishes to thank Professor Simon Levin, whose undergraduate course Theoretical Ecology was an inspiration. This work is supported by grant from the John D. and Catherine T. MacArthur Foundation. Ben Laufer is also supported by doctoral fellowship from DLI, LinkedIn-Bowers CIS PhD Fellowship, and SaTC NSF grant CNA-1704527. Hamidah Oderinwale is also supported by grant from Emergent Ventures and the Carina Fund. Jon Kleinberg is also supported by Vannevar Bush Faculty Fellowship, AFOSR aware FA9550-19-1-0183, and grant from the Simons Foundation. BL and HO are additionally supported by grant from the Cosmos Institute. Any opinions, findings, conclusions, or recommendations expressed in this material do not reflect the views of NSF or other funding agencies."
        },
        {
            "title": "References",
            "content": "[1] Hugging face hub statistics. Hugging Face documentation, 2025. The Hub hosts over one million transformer model checkpoints. [2] Yochai Benkler and Helen Nissenbaum. Commons-based peer production and virtue. Journal of political philosophy, 14(4), 2006. [3] Rishi Bommasani, Dilara Soylu, Thomas Liao, Kathleen Creel, and Percy Liang. Ecosystem graphs: The social footprint of foundation models. arXiv preprint arXiv:2303.15772, 2023. [4] Kira Cassidy and Richard McIntyre. Do gray wolves (canis lupus) support pack mates during aggressive inter-pack interactions? Animal Cognition, 19(5):939947, 2016. [5] Madiha Zahrah Choksi, Ilan Mandel, and Sebastian Benthall. The brief and wondrous life of open models. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency, pages 32243240, 2025. [6] Wesley T. Chuang and Jihoon Yang. Extracting sentence segments for text summarization: machine learning approach. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 00, page 152159, New York, NY, USA, 2000. Association for Computing Machinery. ISBN 1581132263. doi: 10.1145/345508.345566. URL https: //doi.org/10.1145/345508.345566. [7] Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, and Zeb Kurth-Nelson. Causal reasoning from meta-reinforcement learning. arXiv preprint arXiv:1901.08162, 2019. [8] Sarah Dean, Evan Dong, Meena Jagadeesan, and Liu Leqi. Accounting for ai and users shaping one another: The role of mathematical models. arXiv preprint arXiv:2404.12366, 2024. [9] DeepSeek-AI. Deepseek-v3 technical report, 2025. URL https://arxiv.org/abs/ 2412.19437. [10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pretraining of deep bidirectional transformers for language understanding, 2019. URL https://arxiv.org/abs/1810.04805. [11] Moming Duan, Mingzhe Du, Rui Zhao, Mengying Wang, Yinghui Wu, Nigel Shadbolt, and Bingsheng He. Position: Current model licensing practices are dragging us into quagmire of legal noncompliance. In Forty-second International Conference on Machine Learning Position Paper Track. 20 [12] Mary Jane West Eberhard. The evolution of social behavior by kin selection. The Quarterly Review of Biology, 50(1):133, 1975. [13] Hugging Face. Models - Hugging Face huggingface.co. https://huggingface.co/ models?library=safetensors, 2022. [Accessed 21-07-2025]. [14] Richard N. Foster. Assessing technological threats. Research Management, 29(4):1720, 1986. ISSN 00345334. URL http://www.jstor.org/stable/24121836. [15] David Gibson, Jon Kleinberg, and Prabhakar Raghavan. Inferring web communities from link topology. In Proceedings of the Ninth ACM Conference on Hypertext and Hypermedia : Links, Objects, Time and SpaceStructure in Hypermedia Systems: Links, Objects, Time and SpaceStructure in Hypermedia Systems, HYPERTEXT 98, page 225234, New York, NY, USA, 1998. Association for Computing Machinery. ISBN 0897919726. doi: 10.1145/276627.276652. URL https://doi.org/10.1145/276627. 276652. [16] David Gibson, Jon Kleinberg, and Prabhakar Raghavan. from link topology. links, objects, time and spacestructure in hypermedia systems: hypermedia: objects, time and spacestructure in hypermedia systems, pages 225234, 1998. Inferring web communities In Proceedings of the ninth ACM conference on Hypertext and links, [17] Sharad Goel, Ashton Anderson, Jake Hofman, and Duncan Watts. The structural virality of online diffusion. Management science, 62(1):180196, 2016. [18] Claudia Goldin and Lawrence Katz. The origins of technology-skill complementarity. Technical report, National Bureau of Economic Research, Cambridge, MA, July 1996. [19] IBM Granite Team. Granite 3.0 language models. URL: https://github. com/ibmgranite/granite-3.0-language-models, 2024. [20] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pages 855864, 2016. [21] Ernst Haeckel. Generelle Morphologie der Organismen: Allgemeine Grundzuge der organischen Formen-Wissenschaft, mechanisch begrundet durch die von Charles Darwin reformierte Descendenz-Theorie. Band 1: Allgemeine Anatomie. Band 2: Allgemeine Entwicklungsgeschichte. de Gruyter, 1866. [22] William Hamilton. The genetical evolution of social behaviour. ii. Journal of theoretical biology, 7(1):1752, 1964. [23] William Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. arXiv preprint arXiv:1709.05584, 2017. [24] Aspen Hopkins, Sarah Cen, Andrew Ilyas, Isabella Struckman, Luis Videgaray, and Aleksander Madry. Ai supply chains: An emerging ecosystem of ai actors, products, and services. arXiv preprint arXiv:2504.20185, 2025. 21 [25] Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, and Yedid Hoshen. Charting and navigating hugging faces model atlas. arXiv preprint arXiv:2503.10633, 2025. [26] Meena Jagadeesan, Michael Jordan, and Jacob Steinhardt. Safety vs. performance: How multi-objective learning reduces barriers to market entry. arXiv preprint arXiv:2409.03734, 2024. [27] Pratyusha Ria Kalluri, William Agnew, Myra Cheng, Kentrell Owens, Luca Soldaini, and Abeba Birhane. Computer-vision research powers surveillance technology. Nature, pages 17, 2025. [28] Sotiris Kotsiantis, Ioannis Zaharakis, Pintelas, et al. Supervised machine learning: review of classification techniques. Emerging artificial intelligence applications in computer engineering, 160(1):324, 2007. [29] Benjamin Laufer, Jon Kleinberg, and Hoda Heidari. Fine-tuning games: Bargaining and adaptation for general-purpose models. In Proceedings of the ACM Web Conference 2024, pages 6676, 2024. [30] Benjamin Laufer, Jon Kleinberg, and Hoda Heidari. The backfiring effect of weak ai safety regulation. arXiv preprint arXiv:2503.20848, 2025. [31] Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. Predicting positive and negative links in online social networks. In Proceedings of the 19th international conference on World wide web, pages 641650, 2010. [32] Simon Levin. Ecosystems and the biosphere as complex adaptive systems. Ecosystems, 1(5):431436, 1998. [33] David Liben-Nowell and Jon Kleinberg. The link prediction problem for social networks. In Proceedings of the twelfth international conference on Information and knowledge management, pages 556559, 2003. [34] Qi Liu, Matt J. Kusner, and Phil Blunsom. survey on contextual embeddings, 2020. URL https://arxiv.org/abs/2003.07278. [35] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc Le, Barret Zoph, Jason Wei, et al. The flan collection: Designing data and methods for effective instruction tuning. In International Conference on Machine Learning, pages 2263122648. PMLR, 2023. [36] Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Damien Sileo, William Brannon, Niklas Muennighoff, Nathan Khazam, Jad Kabbara, Kartik Perisetla, et al. The data provenance initiative: large scale audit of dataset licensing & attribution in ai. 2023. [37] Johann Friedrich Meckel. Beytrage zur vergleichenden Anatomie, volume 1. Reclam, 1808. 22 [38] Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency, pages 220229, 2019. [39] OpenAI. Gpt-4 technical report, 2024. URL https://arxiv.org/abs/2303.08774. [40] Tori Qiu, Benjamin Laufer, Jon Kleinberg, and Hoda Heidari. formal model of the economic impacts of ai openness regulation. arXiv preprint arXiv:2507.14193, 2025. [41] Mohammad Shahedur Rahman, Peng Gao, and Yuede Ji. Hugginggraph: Understanding the supply chain of llm ecosystem. arXiv preprint arXiv:2507.14240, 2025. [42] Antonio Sclocchi, Alessandro Favero, and Matthieu Wyart. phase transition in diffusion models reveals the hierarchical nature of data, 2024. URL https://arxiv.org/ abs/2402.16991. [43] Etienne Renaud Augustin Serres. Principes dembryogenie, de zoogenie et de teratogenie. Imprimerie de F. Didot fr`eres, fis et cie, 1859. [44] Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul Christiano. Learning to summarize from human feedback, 2022. URL https://arxiv.org/abs/2009.01325. [45] Boaz Taitler and Omer Ben-Porat. Selective response strategies for genai. arXiv preprint arXiv:2502.00729, 2025. [46] Johan Ugander, Lars Backstrom, Cameron Marlow, and Jon Kleinberg. Structural diversity in social contagion. Proceedings of the national academy of sciences, 109(16): 59625966, 2012. [47] Fernanda B. Viegas, Martin Wattenberg, and Matthew M. McKeon. The hidden order of wikipedia. In Proceedings of the 2nd International Conference on Online Communities and Social Computing, OCSC07, page 445454, Berlin, Heidelberg, 2007. SpringerVerlag. ISBN 9783540732563. [48] David Gray Widder and Dawn Nafus. Dislocated accountabilities in the ai supply chain: Modularity and developers notions of responsibility. Big Data & Society, 10 (1):20539517231177620, 2023. [49] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, et al. Huggingfaces transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019. [50] Zhe Yang, Qingkai Fang, and Yang Feng. Low-resource neural machine translation with cross-modal alignment. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1013410146, Abu Dhabi, United Arab Emirates, 2022. Association for Computational Linguistics. URL https://aclanthology.org/ 2022.emnlp-main.689. 23 [51] Takeshi Yoshimura, Tatsuhiro Chiba, Manish Sethi, Daniel Waddington, and Swaminathan Sundararaman. Speeding up model loading with fastsafetensors, 2025. URL https://arxiv.org/abs/2505.23072. [52] Li Yujian and Liu Bo. normalized levenshtein distance metric. IEEE transactions on pattern analysis and machine intelligence, 29(6):10911095, 2007. [53] Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In So Kweon, and Junmo Kim. Text-to-image diffusion models in generative ai: survey, 2024. URL https://arxiv. org/abs/2303.07909. [54] Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, and Jingren Zhou. Qwen3 embedding: Advancing text embedding and reranking through foundation models, 2025. URL https://arxiv.org/abs/2506.05176."
        },
        {
            "title": "6 Details on the measures of genetic similarity",
            "content": "Here we provide additional details on how we measure genetic similarity between models, and we report results across the range of measures we define. Our Figure 5 shows one of six ways we measure genetic similarity between models. These six methods align in the general trends and interpretations reported in the paper. Here we provide details on all six. The measures can be divided by two targets of similarity analysisthe metadata and model cards. On each of these pieces of text, we implement three distinct measures. One measureLevenshtein distancecomputes the total character-by-character difference. The other twoBag-of-words (BOW) and Term Frequency-Inverse Document Frequency (TFIDF)measure differences using the set of n-grams in the text."
        },
        {
            "title": "6.1 Formal definitions",
            "content": "Below we state the formal definitions of our various measures of genetic similarity. All take as input pair of strings s1, s2 and output measure, between 0 and 1, of similarity between them. Definition 6.1 (Cosine similarity in term frequency). Given two strings (s1, s2) in set of strings S, we compute the cosine similarity in term frequency as follows. Over all strings in S, produce an ordered list of the most frequently appearing terms (unigrams or bigrams). Then, for any string si S, define the vector vi Rn such that every value vi[k] is the number of times the kth term in the list appears in si. The similarity is vivj vivj . Definition 6.2 (Cosine similarity in term frequency-inverse document frequency). Given two strings (s1, s2) in set of strings S, we compute the cosine similarity in TF-IDF as follows. Over all strings in S, produce an ordered list of the most frequently appearing terms (unigrams or bigrams). Then, for any string si S, define the vector vi Rn such 24 that every value vi[k] is the product of the number of times the kth term appears in si (its term frequency) and the inverse of the fraction of documents which contain the term (its inverse document frequency). The similarity is vivj vivj . Definition 6.3 (Normalized Levenshtein Similarity). Given two strings (s1, s2), we define the normalized Levenshtein distance (NLD) as the minimum number of character-wise insertions, deletions, or substitutions to transform s1 into s2, divided by max(length(s1), length(s2)). The normalized Levenshtein distance is 1 NLD. The above definitions can be computed for general set of strings, and we report results comparing two sets of strings specifically: The metadata, which is highly structured and recorded for every model on Hugging Face, and the model cards, which is unstructured, much more variable in length, and missing for roughly third of all models. In the body of the text, we report results on the metadata."
        },
        {
            "title": "6.2 Why we prefer term frequency based similarity metrics to edit",
            "content": "distances We report the TF-IDF similarities in the body of the paper, and the other similarity metrics (which match in qualitative conclusions) in the appendix. We do this for two reasons. First, we believe mutations over the metadata are more function of differences in term-based tokens rather than character-based tokens. The difference between the snippets license: mit and license: gemma should not depend on how many letters mit and gemma share. Further, the use of traits that happen to have long names does not correspond to further genetic distance in meaningful. For instance, the tasks reinforcement-learning and fill-mask are not different because of the number of character deletions they require; rather they are different because they are different terms. Second, Levenshtein distance is significantly affected by the ordering of terms, such that the existance of long tag somewhere in the middle of the string could skew the distance measure. We believe these attributes are much more function of whether their semantic markers appear in the metadata, and less function of their ordering in the metadata. This is why we prefer term frequency based measures. Finally, we choose to report the measures normalized by inverse-document frequency because it is norm in the field, but generally we note that our qualitative insights and interpretations are consistent across the proposed measures."
        },
        {
            "title": "7 Measuring the Mutation Rate",
            "content": "In the paper, we attempt to measure the mutation rate over model traits. Depending on how various traits are logged in the metadata JSON, Hugging Face sometimes allows one model to list multiple traits in the same category. For other traits, however, model can only have one categorical value. For example, models can be compatible with multiple languages, because languages are logged in the metadata as tags. Models can only have one task (or pipeline tag), however. Here we provide definition for the mutation rate over category of traits. This is the definition used in all cases where mutation rate is reported 25 Figure 12: Bag of Words Cosine Similarity, Metadata. Figure 13: Levenshtein distance based similarity measure on the model metadata. Figure 14: TF-IDF Cosine Similarity, Model Cards. in the paper. It is compatible with both types of traits listed below (those for which models can have multiple values, and those for which models can have only one value). Definition 7.1 (Mutation rate over traits T). Given set of categorical traits . Every model in our graph has group of individual elements denoted ti = {a, b, ...} . Then the mutation rate over any directed edge (i, j) is given by m(i, j) = 1 titj . The mutation titj edges (i,j) m(i,j) Nedges rate over the set is equal to (cid:80) . Notice that, in cases where every model must have single categorical value in the set of traits (equivalently, ti has cardinality one i), the mutation rate on any edge is 0 if the parent and child have the same trait, and 1 if the parent and child have different traits. Figure 15: Bag of Words Cosine Similarity, Model Cards. Figure 16: Levenshtein distance based similarity measure using the model cards. We have reason to believe this is the least reliable measure, as model cards are free text and Levenshtein distance relies heavily on text ordering, making it more suitable for structured strings. Even still, the directional patterns resemble the findings using other metrics."
        },
        {
            "title": "8 Structural virality",
            "content": "Here, we consider the structural virality of the connected components of our dataset. Structural virality is defined as in Goel et al. [17]. We see evidence that structural virality is quite low in many graphs which tend to be broadcast in nature, but there nonetheless exists considerable branching, with number of models reaching depths of nearly 40 generations."
        },
        {
            "title": "9 Further information on the dataset",
            "content": "Here we provide some additional information on the dataset and general exploratory data analysis conducted."
        },
        {
            "title": "9.1 Linking papers from arXiv",
            "content": "To investigate the research inspiring models on the Hub, we extracted all linked papers from model metadata. For available arXiv IDs, we queried the arXiv API to retrieve the corresponding titles, abstracts, and subject classifications, allowing us to systematically categorize the papers by domain. 27 Figure 17: Scatter plots depicting the maximum depth of every node in the tree (left), the average depth of every node in the tree (center) and the structural virality (right), for trees of various sizes (measured in number of nodes). Structural virality is defined as in [17] for diffusion trees. We use only the first-listed parent for merged models to model our datasets connected components as trees. arXiv subject classification IDs (like cs.AI, cs.CL) are extracted from the categories column in the full JSON dataset, maps them to readable subject names using predefined dictionary, and counts the frequency of each subject across all models. The process handles both single categories and lists of categories per model, flattening all categories into single list before counting occurrences, where models with multiple arXiv categories contribute to the count of each individual category (e.g., model with [cs.AI, cs.CL] adds +1 to both Computer Science, Artificial Intelligence and Computer Science, Computation and Language). The top 20 most frequent research domains are then visualized in Figure 2."
        },
        {
            "title": "9.2 Documentation availability",
            "content": "We analyze model availability and observe low adoption of Hugging Face complimentary tools [18]. Only 5.96% of the models are endpoint-compatible or accessible via the Hugging Face API without local hosting. Furthermore, 6.6% of the models released with weights use the safetensor file formatthe default model weight format developed by Hugging Face in 2022 [13].7 Additionally, 23.69% of the models use automated training via Hugging Face Spaces containerized web deployment environments. Although only small subset of Hugging Face models have self-assigned DOIs, they are downloaded 29 more than those without. Possible explanations include DOIs make models more visible and trustworthy, and people tend to choose models that are already popular and well-documented."
        },
        {
            "title": "10 Further information on sampling subtree topologies",
            "content": "Here we provide more complete table as an addendum to Table 7. For each shape of subgraph, we implemented specific sampling method to get representative sample of 7Although the format was developed in 2022, it became the default (as zero-copy alternative to pickle) in 2023 [51]. 28 models. The sampling method is summarized in Table 1. Subgraph Occurrences Sampling condition Multiplicitycondition 3,470,193,356,870 Two arbitrary nodes. 191,072 119,795,843 40, 193,010,561,824 11,847,103 19,932,645 10,965 Single edge (u, v). Node with more than one successor. Edge (u, v) where has successors. Node with more than two successors. Edge (u, v) where has more than one successor. Edge (u, v) where has multiple successors and has successors. Edge (u, v) where has predecessor and has successors. 1 (cid:1) (cid:0)nsucc(u) 2 nsucc(v) (cid:1) (cid:0)nsucc(u) 3 (cid:1) (cid:0)nsucc(v) 2 nsucc(v)(nsucc(u) 1) nsucc(v) Table 1: Subgraph patterns, their total occurrences, sampling conditions, and associated multiplicities conditioned on each pattern. nsucc(u) refers to the number of successors (or, equivalently, the out-degree) of node u."
        }
    ],
    "affiliations": [
        "Cornell Tech",
        "Cornell University",
        "IBM",
        "McGill University"
    ]
}