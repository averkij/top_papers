{
    "paper_title": "Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024 SSA and Pediatrics",
    "authors": [
        "Sarim Hashmi",
        "Juan Lugo",
        "Abdelrahman Elsayed",
        "Dinesh Saggurthi",
        "Mohammed Elseiagy",
        "Alikhan Nurkamal",
        "Jaskaran Walia",
        "Fadillah Adamsyah Maani",
        "Mohammad Yaqub"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Identifying key pathological features in brain MRIs is crucial for the long-term survival of glioma patients. However, manual segmentation is time-consuming, requiring expert intervention and is susceptible to human error. Therefore, significant research has been devoted to developing machine learning methods that can accurately segment tumors in 3D multimodal brain MRI scans. Despite their progress, state-of-the-art models are often limited by the data they are trained on, raising concerns about their reliability when applied to diverse populations that may introduce distribution shifts. Such shifts can stem from lower quality MRI technology (e.g., in sub-Saharan Africa) or variations in patient demographics (e.g., children). The BraTS-2024 challenge provides a platform to address these issues. This study presents our methodology for segmenting tumors in the BraTS-2024 SSA and Pediatric Tumors tasks using MedNeXt, comprehensive model ensembling, and thorough postprocessing. Our approach demonstrated strong performance on the unseen validation set, achieving an average Dice Similarity Coefficient (DSC) of 0.896 on the BraTS-2024 SSA dataset and an average DSC of 0.830 on the BraTS Pediatric Tumor dataset. Additionally, our method achieved an average Hausdorff Distance (HD95) of 14.682 on the BraTS-2024 SSA dataset and an average HD95 of 37.508 on the BraTS Pediatric dataset. Our GitHub repository can be accessed here: Project Repository : https://github.com/python-arch/BioMbz-Optimizing-Brain-Tumor-Segmentation-with-MedNeXt-BraTS-2024-SSA-and-Pediatrics"
        },
        {
            "title": "Start",
            "content": "4 2 0 2 6 2 ] . e [ 2 2 7 8 5 1 . 1 1 4 2 : r Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024 SSA and Pediatrics Sarim Hashmi, Juan Lugo, Abdelrahman Elsayed, Dinesh Saggurthi, Mohammed Elseiagy, Alikhan Nurkamal, Jaskaran Walia, Fadillah Adamsyah Maani, and Mohammad Yaqub Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) Abu Dhabi, United Arab Emirates {sarim.hashmi, juan.lugo, abdelrahman.elsayed, dinesh.saggurthi, mohammed.abdelaziz, alikhan.nurkamal, jaskaran.walia, fadillah.maani, mohammad.yaqub}@mbzuai.ac.ae https://mbzuai.ac.ae Abstract. Identifying key pathological features in brain MRIs is crucial for the long-term survival of glioma patients. However, manual segmentation is time-consuming, requiring expert intervention and is susceptible to human error. Therefore, significant research has been devoted to developing machine learning methods that can accurately segment tumors in 3D multimodal brain MRI scans. Despite their progress, state-of-theart models are often limited by the data they are trained on, raising concerns about their reliability when applied to diverse populations that may introduce distribution shifts. Such shifts can stem from lower quality MRI technology (e.g., in sub-Saharan Africa) or variations in patient demographics (e.g., children). The BraTS-2024 challenge provides platform to address these issues. This study presents our methodology for segmenting tumors in the BraTS-2024 SSA and Pediatric Tumors tasks using MedNeXt, comprehensive model ensembling, and thorough postprocessing. Our approach demonstrated strong performance on the unseen validation set, achieving an average Dice Similarity Coefficient (DSC) of 0.896 on the BraTS-2024 SSA dataset and an average DSC of 0.830 on the BraTS Pediatric Tumor dataset. Additionally, our method achieved an average Hausdorff Distance (HD95) of 14.682 on the BraTS2024 SSA dataset and an average HD95 of 37.508 on the BraTS Pediatric dataset.Our GitHub repository can be accessed here: Project Repository. Keywords: BraTS Brain MRI Glioma Tumor segmentation MedNeXt BraTS-SSA BraTS-PEDs"
        },
        {
            "title": "Introduction",
            "content": "Gliomas remain the most common and malignant type of primary brain tumor despite advances in understanding their pathophysiology [14]. Only about 20% of individuals with glioma survive two years post-diagnosis, and they cause the highest number of cancer-related deaths in pediatrics. Their presence is visible through Magnetic Resonance Imaging (MRI) scans, which provide detailed information on the patients internal structures, tissues, and organs. Correctly bounding the tumor and identifying its sub-regions from the MRI scan is crucial first step in treatment options, including surgery, chemo, and radiation 2 S. Hashmi et al. therapy. Additionally, it is important for assessing treatment response and for the longitudinal monitoring of the patient [15]. Radiologists rely on MRI scans to manually predict tumor classification and localization, which is time-consuming, labor-intensive, and susceptible to human error. These challenges are further compounded in low-income countries, where overburdened healthcare systems and shortage of qualified specialists prevail [2]. As result, there is critical need for automated solutions, and machine learning pipelines for automatic tumor segmentation offer promising tool to provide accurate and efficient measurements. The Medical Image Computing and Computer Assisted Interventions (MICCAI) conference annually hosts various medical imaging competitions that draw research teams internationally. Among these is the BraTS challenge [13], which consists of ten distinct brain tumor-related tasks this year. Originally, BraTS centered on adult glioma segmentation [4,5], with datasets mainly sourced from the Global North. However, despite the advancements brought by this annual challenge, there have been concerns about the reliability of state-of-the-art models when applied to populations that introduce distribution shifts from the original dataset [1]. Such shifts can result from lower quality MRI technologies (e.g., in sub-Saharan Africa) or differences in the populations anatomy (e.g., childrens brains). Thus, the BraTS challenge expanded its dataset to include sub-Saharan African, pediatrics, and meningioma tumors. This paper focuses on the Africa and Pediatric tasks. Since the 2014 challenge, deep learning has become the state-of-the-art for brain tumor segmentation, driven by rapid advancements in GPU technology and the availability of large datasets [7]. Most solutions utilize the U-Net architecture, which features contracting path similar to convolutional network and an expansive path of up-sampling convolutions. Numerous enhancements have been made to the U-Net [17], including the incorporation of residual connections, densely connected layers, and attention mechanisms [7]. This paper focuses on the MedNeXt architecture [18], variation of U-Net that employs ConvNeXt [10] blocks, for automatic brain tumor segmentation. We delve into the various preprocessing, ensemble techniques, and training modifications implemented to achieve high accuracy. The data used for performance assessment was obtained from standard clinical care for brain tumors and was meticulously annotated by radiologists and reviewed by neurologists to ensure accuracy [2, 9]. The compounding improvements of these techniques result in state-of-the-art machine learning pipeline for the BraTS Africa and Pediatric challenges. Our main contributions are the following: deep learning pipeline for Africa and Pediatric brain tumor segmentation for the corresponding BraTS 2024 tasks. An integration of the novel schedule free [6] optimizer into the training algorithm. thorough analysis of finetuning and ensembling techniques, and their impact on performance. Title Suppressed Due to Excessive Length"
        },
        {
            "title": "2.1 Brain MRI Data",
            "content": "Brain MRI is an important imaging technique in neurological diagnostics, offering high-resolution images of the brains anatomy and function. patients MRI is divided into four key modalities, each detailing different aspects of medical interest. These are, T1-weighted imaging (T1) for detailed anatomical structure; T1 post galodinium contrast (T1Gd) for high vascularity pathologies; T2weighted imaging (T2W) for detecting edema and inflammation; and T2 FluidAttenuated Inversion Recovery (T2-FLAIR) for enhanced lesion visibility [13]. Combining these modalities provides comprehensive insights for diagnosing and managing conditions such as strokes, tumors, multiple sclerosis, and traumatic brain injuries, ultimately improving patient outcomes. The International Brain Tumor Segmentation (BraTS) challenge, ongoing since 2012, focuses on creating benchmarking environment and dataset for delineating adult brain gliomas from MRI scans following the aforementioned modalities. In 2024, the challenge expands to approximately 4,500 cases, addressing diverse clinical and technical considerations. Key tasks include evaluating algorithms for post-treatment glioma, radiotherapy meningioma, brain metastasis, handling missing data, pathology analysis, and segmenting the tumor of specific demographics. In particular, this paper focuses on the challenges of BraTS-Africa and Pediatrics. BraTS-Africa dataset The dataset [2] comprises multi-institutional structural MRI scans from 95 Sub-Saharan Africa patients. Out of these, 60 samples are used for training and 35 for validation. This years task consists of identifying and segmenting the tumor into three sub-regions: the enhancing tumor (ET), the Non-enhancing tumor core (NETC), and the Surrounding non-enhancing FLAIR hyperintensity (SNFH). The segmentation labels in the dataset were annotated by board-certified radiologists and validated by expert neuroradiologists following BraTS protocols. To ensure the validity of the leaderboard, the ground truth for the 35 testing datapoints was not made public. Figure 1 shows sample of the training split. Additionally, BraTS SSA 2024 allows the use of the 1470 MRIs and labels of the BraTS-2023 Adult Glioma Challenge for further training [3]. BraTS PED The BraTS-PED dataset [9] consists of multi-institutional conventional and structural MRI scans from 464 pediatric cases of high-grade glioma. There is heterogeneity in the images quality due to the different protocols and equipment used. The data went through several preprocessing steps to ensure data integrity and patient anonymity. This years task evaluates the accuracy of segmenting the tumor into six sub-regions of interest: the enhancing tumor (ET); the tumor core (TC); the whole tumor (WT); the non-enhancing tumor core (NETC); the cystic component (CC); and the peritumoral edema (ED). Out of these regions, only the first 3 are predicted by the model, and the latter 3 are inferred at testing time by the BraTS organizers. sample from the dataset is shown in Figure 2. preliminary automated segmentation pipeline was used to obtain the segmentation labels, and the results were then manually refined by volunteer neuroradiologists. These refinements underwent iterative reviews and approvals by three board-certified neuroradiologists until the labels met the criteria for public release [9]. Preprocessing The challenge organizer has performed an initial preprocessing of the MRI scans by co-registering the four modalities to standard SR124 4 S. Hashmi et al. Fig. 1. Cross sections of the four modalities obtained from sample data-point from the provided dataset for the BraTS-Africa challenge along with the corresponding segmentation masks template [16], isotropically interpolating to achieve 1mm³ resolution. Skullstripping was applied to the BraTS Africa Dataset, but not Pediatrics. All MRI images have uniform size of 240 240 155. We further preprocessed the images cropping the foreground, normalizing voxels with non-zero intensities, and stacking the four modalities into single image. We additionally crop the MRIs into patches of shape 128 160 112. We preprocessed all MRI scans in advance, stored them in \".npy\" format, and loaded the Numpy arrays during training to speed up data loading and prevent the CPU bottleneck."
        },
        {
            "title": "2.2 MedNeXt",
            "content": "Inspired by [11, 12] we adopted MedNeXt as our baseline model (Figure 3), following the standard implementation available on GitHub1. MedNeXt is stateof-the-art vision architecture that combines the long-range spatial representation of transformers with the inductive bias of ConvNets. It utilizes MedNeXt blocks arranged in U-net like shape, with the characteristic encoder on the left side, bottleneck center, and decoder on the right side. Each \"left-hand side\" MedNeXt block contains three convolutions: first, depth-wise convolution of dimension ((k {3, 5, 7, 9}) that emulates the large attention window of the vision transformer; second, an expansion layer, forming transformer-like inverse bottleneck, where the number of channels is multiplied by an expansion ratio; and then compression layer, where the number of channels is brought down again by 1 1 1 kernels. Each \"right-hand side\" MedNeXt block follows the same structure but uses convolutions transposed to account for the required 1 https://github.com/MIC-DKFZ/MedNeXt Title Suppressed Due to Excessive Length 5 Fig. 2. Different cross sections of the four modalities obtained from sample datapoint from the provided dataset for pediatrics challenge along with the corresponding segmentation masks up-sampling. MedNeXt also includes deep supervision to prevent vanishing gradients and improve performance. We used the Base (B) and Medium (M) sizes for the architecture."
        },
        {
            "title": "2.3 Model Development",
            "content": "Model training We conducted our experiments on an NVIDIA GPU with 24 GB of memory. For the SSA challenge, we combined the BraTS Adult Glioma and BraTS Africa Training datasets. In both tasks, Pediatrics and Africa, the models input size was set to 128x160x112 voxels, following our preprocessing. 6 S. Hashmi et al. Fig. 3. (a) Architectural design of the MedNeXt. The network has 4 Encoder and Decoder layers each, with bottleneck layer. MedNeXt blocks are present in Up and Downsampling layers as well. Deep Supervision is used at each decoder layer, with lower loss weights at lower resolutions. All residuals are additive while convolutions are padded to retain tensor sizes. For further details, we refer to [18] Using 5-fold cross-validation on the training set, we trained the MedNeXt-B and MedNeXt-M models for the BraTS Africa dataset. Both models were implemented with kernel size of 3 for 150 epochs. On the other hand, only MedNeXt-B was trained with kernel size of 3 and 75 epochs for the BraTS pediatrics dataset. Optimization was performed using the Schedule-free AdamW optimizer [6], recently proposed by the Fundamental AI Research Team at Meta, with learning rate of 0.0027 for BraTS Africa, learning rates of 0.0027 and 0.0005 for BraTS pediatrics, and no weight decay. We used batch size of 2 for training. For the objective function (loss), deep supervision, brain MRI preprocessing, and data augmentation, we followed the approach outlined in . We tuned postprocessing hyperparameters using Wandb sweep on the 5-fold CV and then manually adjusted them to fit the unseen validation set. Hyper-parameter tuning experiments Several experiments were conducted to fine-tune the hyperparameters of the models, particularly the learning rate. Baseline models used AdamW with cosine-annealing scheduler. However, upon transitioning to the schedule-free optimizer [6] developed by the Fundamental AI Research Team at Meta, the initial experimental configurations did not directly translate. As result, various learning rates were tested to determine the most effective one. Through these different experiments, the optimal learning rate of 0.0027 was identified and subsequently used in all further training experiments For BraTS Africa. For the BraTS pediatrics experiments, learning rate of 0.0027 and 0.0005 were used. This careful tuning was essential to boost the performance and efficiency of our models. Finetuning For the BraTS-Africa challenge, teams were allowed to use the 1470 samples available in the BraTS-2023 Adult Glioma task. Thus, we opted to combine this dataset with the African MRIs to obtain 1530 training samples. Title Suppressed Due to Excessive Length 7 Then, we finetuned the final decoder block and deep supervision layers of the base model exclusively with the African dataset, preserving the original training hyperparameters. We experimented with two types of initialization: (a) commencing the training from the final model checkpoint, and (b) re-initializing the fine-tuned layers. We observed that both initializations gave similar results, so we reported the best performances without distinction."
        },
        {
            "title": "2.4 Model Inference",
            "content": "We begin by preprocessing the input MRI scans as outlined in Subsection 2.1. Tumor probability maps are generated through sliding window inference, employing X% (X {50, 70}) overlap between windows to enhance the precision of our predictions. We improve the robustness of these predictions by averaging the tumor probability masks from all models in an ensemble approach, resulting in refined final tumor probability map. We then post-process the tumor probability map to detect and segment tumors. Ensemble Each model was trained in 5-fold cross-validation setting, resulting in five distinct models upon completion. This methodology facilitates rapid prototyping, as training and testing can be conducted on single fold, and enhances prediction robustness through the ensemble of these five models. During inference, the input image is processed by each of the five models, and the mean of their output probabilities is computed and normalized accordingly. Performance can be further optimized by ensembling models derived from different training strategies, such as varying hyper-parameters and architecture sizes. The idea is that ensembling harnesses the unique strengths of its individual components [19]. In this study, we aggregate models at the probability level, assigning equal importance to each component in the ensemble. The outcomes of this ensembling strategy are elaborated in Section 3."
        },
        {
            "title": "2.5 Experimental Setup",
            "content": "We employ 5-fold cross-validation (CV) training strategy, partitioning the training data into five subsets. In each iteration, four subsets are used for training, while the remaining subset serves as the validation set. Our networks are trained using region-based approach [8] for 150 epochs with batch size of 2. We implement on-the-fly data augmentation, which includes random spatial cropping to dimensions of 128 160 112, random flips, and random intensity, scaling, and shifting. The objective function combines batch Dice loss and focal loss with γ value of 2.0 to compute the total loss. For optimization, we utilize the Schedule-free AdamW optimizer [6] with learning rate (LR) of 0.0027 for the BraTS SSA 2024 dataset and two learning rates of values 0.0027 and 0.0005 for the BraTS pediatric dataset. We apply zero weight decay and set maximum of 150 epochs. Furthermore, we conduct additional experiments involving fine-tuning the last two stages of the BraTS SSA 2024 trained model. For the post-processing parameters, we threshold our predictions by the size of the predicted tumors. The values for the minimum threshold sizes were set experimentally by comparing the performance of each model given set of threshold values for each tumor type. For example, if we set the minimum size threshold for ET in the pediatric challenge as 100 voxels, each detected tumor with 8 S. Hashmi et al. size smaller than this will be removed. The comparisons in performance and the threshold values used are further discussed in the results of the BraTS pediatrics."
        },
        {
            "title": "3.1 BraTS Africa Results",
            "content": "S.No Model Name 1 Baseline 2 (+) Change patch size to: 128 160 112 (+) Train on SSA and Adult Gli. (+) Finetune the last 10 decoder layers on SSA (+) Reinitialize and finetune the last 10 decoder layers on SSA (+) Change the binarization threshold 0.7 for ET and TC ,0.5 for WT 3 4 5 ET Dice Score Avg ET TC WT Dice 39.96 0.8229 0.8151 0.8812 0.8397 0.852 0.839 0.912 0.8677 12.406 HD 95 Avg TC WT HD 95 37.16 25.04 46.48 26.09 10.431 16. 0.867 0.869 0.932 0.8893 15.578 22.145 8.833 0.874 0.870 0.933 0.8923 15.320 22.039 8.805 15.52 15.39 0.876 0.870 0.933 0.8930 15.328 22.040 8.746 15.37 0.883 0.873 0.933 0.8963 14.248 21.028 8.770 14. Table 1. Comparison of MedNeXt Base Models with Different Training Data, Patch Sizes, and Fine-tuning Strategies The performance of different MedNeXt models is summarized and compared in Table 1 for BraTS SSA 2024. The compared models differ in three key aspects: size (Base or Medium), resetting weights for the last 10 layers (True or False), and Binarization threshold for ET,TC and WT (0.5 or 0.7). The metrics for comparison are Dice scores (Dice) and Hausdorff Distance 95th percentile (HD 95) for the Enhancing Tumor (ET), Tumor Core (TC), and Whole Tumor (WT) labels. Additionally, we record the average of both Dice and HD 95 accross the labels, for each model. MedNext Models: MedNeXt Base achieved an average Dice of 0.889, which was the highest among the non-finetuned models. It performed well, especially in segmenting WT, with Dice score of 0.932. MedNeXt Base achieved Dice Average of 0.889, which was the highest among the non-finetuned models. It performed well, especially in segmenting WT, with Dice score of 0.932. MedNeXt Medium had Dice Average of 0.886, slightly lower than MedNeXt Base, with solid performance in ET (0.875) and WT (0.933). Its HD 95 scores for Tumor Core were higher compared to the Base model. However, it has the best H95 result for WT among all models. The MedNeXt Ensemble (Base + Medium) got Dice Average of 0.868. Although this model showed the best HD 95 score for ET, it underperformed in Dice scores compared to the individual models. Finetuned Models: MedNeXt Finetuned True 0.5 scored Dice Average of 0.893, showing an improvement over the Base model and similar performance to the Finetuned True 0.7 model. Title Suppressed Due to Excessive Length 9 MedNeXt Finetuned True 0.7 achieved the highest Dice score of 0.883 (for ET) among all models, with improvements in both average and TC Dice scores compared to the Base and Medium models. This model also had the lowest HD 95 Average (14.764), indicating better segmentation ability and reduced Hausdorff distance. MedNeXt Finetuned False 0.5 got Dice Average of 0.892, comparable to the finetuned True 0.5 model, with similar performance. MedNeXt Finetuned False 0.7 achieved Dice Average of 0.895, the highest among all models, with solid performance in both Dice scores and HD 95 metrics. MedNeXt Finetuned True 0.7,0.5 score the highest average Dice score of 0.896 among all the models and also the highest Dice score in both ET and WT. Moreover, It showed strong performance in HD95 average with value of 14.682. In conclusion, the finetuned models, especially the MedNeXt Finetuned True 0.7,0.5, excelled in terms of performance across most metrics. The improvements in Dice scores and reductions in HD 95 values indicates that the finetuning process enhanced the models ability to accurately segment tumor regions while reducing the Hausdorff distance values."
        },
        {
            "title": "3.2 BraTS pediatric Results",
            "content": "Model Learning Rate Min Size Th. Dice Scores HD 95 0.0027 MedNeXt Base TC WT NETC CC ED 500 0.555 0.869 0.869 0.834 0.71 0.967 122.219 20.595 20.595 23.842 91.287 12.33 250 0.543 0.838 0.838 0.798 0.655 0.967 124.183 33.228 33.226 34.421 98.004 12.33 125 0.507 0.832 0.832 0.791 0.634 0.967 122.545 37.176 37.173 38.199 104.089 12.33 0.853 0.723 0.967 88.651 17.269 17.269 18.571 83.234 12.33 500 0.654 0.89 0.89 250 0.657 0.89 0.89 0.853 0.723 0.967 76.553 17.269 17.269 18.391 83.234 12.33 125 0.619 0.885 0.885 0.848 0.659 0.967 86.829 19.312 19.312 20.398 104.002 12.33 Table 2. LesionWise Dice Scores, HD 95 Results, Minimum Size Thresholds, and Learning Rates for Various Runs ET TC WT ET TC WT NETC CC ED ET 100 150 50 75 25 37 100 150 50 75 25 37 0.0005 We summarize our results on the validation leaderboard in Table 2. Our approach began with the MedNeXt Base model, which established strong performance baseline. We experimented with the model with 2 different learning rates and with various minimum size thresholds for tumor detection, testing thresholds of 100, 150, and 500 for ET, TC, and WT, respectively. For the learning rate of 0.0027, the initial thresholds yielded the best Dice Scores and maintained balance in HD 95 metrics. Adjusting the thresholds to lower values, such as 50 for ET, 75 for TC, and 250 for WT, led to decrease in Dice Scores across all tumor classes, while HD 95 metrics showed increased results. Further lowering the thresholds to 25 for ET, 37 for TC, and 125 for WT resulted in further decrease in Dice Scores and also an increase in most of HD 95 metrics, indicating poorer segmentation precision. However, changing the learning rate to 0.0005 boosted the performance of the model to achieve better results than using the 0.0027 learning rate. The best-performing model was obtained using threshold values of 50, 75, and 250 for ET, TC, and WT, respectively. These results highlight the importance of the Data post-processing chosen parameters and the learning rate 10 S. Hashmi et al. in our model performance. Choosing the optimal Threshold sizes along with an optimal learning rate can hugely affect the model performance."
        },
        {
            "title": "4 Conclusion",
            "content": "This work represents our contribution to the Africa and Pediatrics tasks for the BraTS 2024 challenge. We utilized MedNeXt-based model to detect tumors from brain MRI scans. The model processes four MRI input channels and produces three output channels for TC, WT, and ET, respectively. We introduced several variations to the standard training procedure. Most notably, we achieved excellent metrics with the schedule-free optimizer, which are further improved via specific fine-tuning. We additionally verified the importance of post-processing techniques to enhance predictions and reduce noise, paying particular attention to the overlap proportion between prediction windows. Our best-performing models in the Africa dataset obtained state-of-the-art average Dice scores above 0.895, as well as excellent Hausdorff Distances below 14.765. Lastly, our best-performing model in the pediatric dataset achieved an average dice score of 0.83 and good-performing values for HD95 with an average of 37.508."
        },
        {
            "title": "Acknowledgement",
            "content": "We would like to express our deepest gratitude to Sanoojan Baliah and Dana Mohamed for their invaluable support and contributions to this project. Title Suppressed Due to Excessive Length"
        },
        {
            "title": "References",
            "content": "1. Adewole, M., Rudie, J.D., Gbadamosi, A., Toyobo, O., Raymond, C., Zhang, D., Omidiji, O., Akinola, R., Suwaid, M.A., Emegoakor, A., Ojo, N., Aguh, K., Kalaiwo, C., Babatunde, G., Ogunleye, A., Gbadamosi, Y., Iorpagher, K., Calabrese, E., Aboian, M., Linguraru, M., Albrecht, J., Wiestler, B., Kofler, F., Janas, A., LaBella, D., Kzerooni, A.F., Li, H.B., Iglesias, J.E., Farahani, K., Eddy, J., Bergquist, T., Chung, V., Shinohara, R.T., Wiggins, W., Reitman, Z., Wang, C., Liu, X., Jiang, Z., Familiar, A., Leemput, K.V., Bukas, C., Piraud, M., Conte, G.M., Johansson, E., Meier, Z., Menze, B.H., Baid, U., Bakas, S., Dako, F., Fatade, A., Anazodo, U.C.: The brain tumor segmentation (brats) challenge 2023: Glioma segmentation in sub-saharan africa patient population (brats-africa) (2023), https://arxiv.org/abs/2305.19369 2. Adewole, M., Rudie, J.D., Gbdamosi, A., Toyobo, O., Raymond, C., Zhang, D., Omidiji, O., Akinola, R., Suwaid, M.A., Emegoakor, A., et al.: The brain tumor segmentation (brats) challenge 2023: glioma segmentation in sub-saharan africa patient population (brats-africa). ArXiv (2023) 3. Baid, U., Ghodasara, S., Mohan, S., Bilello, M., Calabrese, E., Colak, E., Farahani, K., Kalpathy-Cramer, J., Kitamura, F.C., Pati, S., et al.: The rsna-asnr-miccai brats 2021 benchmark on brain tumor segmentation and radiogenomic classification. arXiv preprint arXiv:2107.02314 (2021) 4. Bakas, S., Akbari, H., Sotiras, A., Bilello, M., Rozycki, M., Kirby, J., Freymann, J., Farahani, K., Davatzikos, C.: Segmentation labels and radiomic features for the pre-operative scans of the tcga-lgg collection. The cancer imaging archive 286 (2017) 5. Bakas, S., Akbari, H., Sotiras, A., Bilello, M., Rozycki, M., Kirby, J.S., Freymann, J.B., Farahani, K., Davatzikos, C.: Advancing the cancer genome atlas glioma mri collections with expert segmentation labels and radiomic features. Scientific data 4(1), 113 (2017) 6. Defazio, A., Mehta, H., Mishchenko, K., Khaled, A., Cutkosky, A., et al.: The road less scheduled. arXiv preprint arXiv:2405.15682 (2024) 7. Ferreira, A., Solak, N., Li, J., Dammann, P., Kleesiek, J., Alves, V., Egger, J.: How we won brats 2023 adult glioma challenge? just faking it! enhanced synthetic data augmentation and model ensemble for brain tumour segmentation (2024), https://arxiv.org/abs/2402.17317 8. Isensee, F., Jäger, P.F., Full, P.M., Vollmuth, P., Maier-Hein, K.H.: nnu-net for brain tumor segmentation. In: Crimi, A., Bakas, S. (eds.) Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. pp. 118132. Springer International Publishing, Cham (2021) 9. Kazerooni, A.F., Khalili, N., Liu, X., Gandhi, D., Jiang, Z., Anwar, S.M., Albrecht, J., Adewole, M., Anazodo, U., Anderson, H., Baid, U., Bergquist, T., Borja, A.J., Calabrese, E., Chung, V., Conte, G.M., Dako, F., Eddy, J., Ezhov, I., Familiar, A., Farahani, K., Franson, A., Gottipati, A., Haldar, S., Iglesias, J.E., Janas, A., Johansen, E., Jones, B.V., Khalili, N., Kofler, F., LaBella, D., Lai, H.A., Leemput, K.V., Li, H.B., Maleki, N., McAllister, A.S., Meier, Z., Menze, B., Moawad, A.W., Nandolia, K.K., Pavaine, J., Piraud, M., Poussaint, T., Prabhu, S.P., Reitman, Z., Rudie, J.D., Sanchez-Montano, M., Shaikh, I.S., Sheth, N., Tu, W., Wang, C., Ware, J.B., Wiestler, B., Zapaishchykova, A., Bornhorst, M., Deutsch, M., Fouladi, M., Lazow, M., Mikael, L., Hummel, T., Kann, B., de Blank, P., Hoffman, L., Aboian, M., Nabavizadeh, A., Packer, R., Bakas, S., Resnick, A., Rood, B., Vossough, A., Linguraru, M.G.: The brain tumor segmentation in pediatrics (bratspeds) challenge: Focus on pediatrics (cbtn-connect-dipgr-asnr-miccai brats-peds) (2024), https://arxiv.org/abs/2404.15009 10. Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T., Xie, S.: convnet for the 2020s. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 1197611986 (2022) S. Hashmi et al. 11. Maani, F., Hashmi, A.U.R., Aljuboory, M., Saeed, N., Sobirov, I., Yaqub, M.: Advanced tumor segmentation in medical imaging: An ensemble approach for brats 2023 adult glioma and pediatric tumor tasks (2024), https://arxiv.org/abs/ 2403.09262 12. Maani, F.A., Ur Rehman Hashmi, A., Saeed, N., Yaqub, M.: On enhancing brain tumor segmentation across diverse populations with convolutional neural networks. In: 2024 IEEE International Symposium on Biomedical Imaging (ISBI). pp. 14 (2024). https://doi.org/10.1109/ISBI56570.2024.10635463 13. Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby, J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., et al.: The multimodal brain tumor image segmentation benchmark (brats). IEEE transactions on medical imaging 34(10), 19932024 (2014) 14. Mesfin, F.B., et al.: Gliomas. StatPearls [Internet] (2024), https://www.ncbi.nlm. nih.gov/books/NBK441874/, updated 2023 May 15. Owrangi, A.M., Greer, P.B., Glide-Hurst, C.K.: Mri-only treatment planning: benefits and challenges. Physics in Medicine & Biology 63(5), 05TR01 (2018) 16. Rohlfing, T., Zahr, N., Sullivan, E., Pfefferbaum, A.: The sri24 multichannel atlas of normal adult human brain structure. Human brain mapping 31, 798819 (05 2009). https://doi.org/10.1002/hbm.20906 17. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.) Medical Image Computing and Computer-Assisted Intervention MICCAI 2015. pp. 234241. Springer International Publishing, Cham (2015) 18. Roy, S., Koehler, G., Ulrich, C., Baumgartner, M., Petersen, J., Isensee, F., Jaeger, P.F., Maier-Hein, K.: Mednext: Transformer-driven scaling of convnets for medical image segmentation. arXiv preprint arXiv:2303.09975 (2023) 19. Zeineldin, R.A., Karar, M.E., Burgert, O., Mathis-Ullrich, F.: Multimodal cnn networks for brain tumor segmentation in mri: brats 2022 challenge solution. In: Bakas, S., Crimi, A., Baid, U., Malec, S., Pytlarz, M., Baheti, B., Zenk, M., Dorent, R. (eds.) Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. pp. 127137. Springer Nature Switzerland, Cham (2023)"
        }
    ],
    "affiliations": [
        "Mohammed bin Zayed University of Artificial Intelligence (MBZUAI), Abu Dhabi, United Arab Emirates"
    ]
}