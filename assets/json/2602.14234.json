{
    "paper_title": "REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents",
    "authors": [
        "Zheng Chu",
        "Xiao Wang",
        "Jack Hong",
        "Huiming Fan",
        "Yuqi Huang",
        "Yue Yang",
        "Guohai Xu",
        "Chenxiao Zhao",
        "Cheng Xiang",
        "Shengchao Hu",
        "Dongdong Kuang",
        "Ming Liu",
        "Bing Qin",
        "Xing Yu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interactionheavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, a unified framework that codesigns complex task synthesis, midtraining, and posttraining for scalable searchagent optimization. Specifically, REDSearcher introduces the following improvements: (1) We frame task synthesis as a dualconstrained optimization, where task difficulty is precisely governed by graph topology and evidence dispersion, allowing scalable generation of complex, highquality tasks. (2) We introduce toolaugmented queries to encourage proactive tool use rather than passive recall.(3) During midtraining, we strengthen core atomic capabilities knowledge, planning, and function calling substantially reducing the cost of collecting highquality trajectories for downstream training. (4) We build a local simulated environment that enables rapid, lowcost algorithmic iteration for reinforcement learning experiments. Across both textonly and multimodal searchagent benchmarks, our approach achieves stateoftheart performance. To facilitate future research on longhorizon search agents, we will release 10K highquality complex text search trajectories, 5K multimodal trajectories and 1K text RL query set, and together with code and model checkpoints."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 5 1 ] . [ 1 4 3 2 4 1 . 2 0 6 2 : r REDSearcher: Scalable and Cost-Efficient Framework for Long-Horizon Search Agents REDSearcher Team Project Page: redsearchagent.github.io"
        },
        {
            "title": "Abstract",
            "content": "Large language models are transitioning from general-purpose knowledge engines to real-world problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of high-quality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interaction-heavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, unified framework that co-designs complex task synthesis, mid-training, and post-training for scalable search-agent optimization. Specifically, REDSearcher introduces the following improvements: (1) We frame task synthesis as dual-constrained optimization, where task difficulty is precisely governed by graph topology and evidence dispersion, allowing scalable generation of complex, high-quality tasks. (2) We introduce tool-augmented queries to encourage proactive tool use rather than passive recall.(3) During mid-training, we strengthen core atomic capabilitiesknowledge, planning, and function callingsubstantially reducing the cost of collecting high-quality trajectories for downstream training. (4) We build local simulated environment that enables rapid, low-cost algorithmic iteration for reinforcement learning experiments. Across both text-only and multimodal searchagent benchmarks, our approach achieves state-of-the-art performance. To facilitate future research on long-horizon search agents, we will release 10K high-quality complex text search trajectories, 5K multimodal trajectories and 1K text RL query set, and together with code and model checkpoints. Figure 1: Benchmark performance of REDSearcher."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) [1, 38, 33] are transitioning from static, parametric knowledge engines into dynamic agents [23, 46, 35] capable of navigating the open world. While current models excel at simple retrieval tasks [17], they struggle with deep searchan interactive, long-horizon setting in which an agent must iteratively acquire evidence, maintain competing hypotheses, and synthesize information across multiple sources. In contrast to standard RAG [4], which typically relies on static one-shot retrieval, deep search requires closed-loop search-and-reason behavior that adapts to newly found evidence [31]. However, optimizing LLMs for such depth is hindered by critical bottleneck: the extreme sparsity of effective supervision signals [21, 20, 37]. Scaling these agents is currently intractable due to two prohibitive barriers: the difficulty of synthesizing complex, high-quality reasoning tasks at scale, and the immense computational and temporal cost of collecting interaction-heavy trajectories involving extensive external tool usage. Accordingly, we propose REDSearcher, framework for training tool-augmented deep-search agents across text-only and multimodal (image-text) settings, jointly optimizing task synthesis, mid-training, and post-training to enable scalable, controllable, and cost-effective optimization of long-horizon search behavior. REDSearcher introduces the following technical components: Dual-Constrained Task Synthesis. We mitigate the scarcity of challenging supervision by formulating query generation as constraint satisfaction problem over latent knowledge graph. Unlike standard QA datasets that predominantly admit linear, tree-like reasoning, we construct instances with higher structural complexity (e.g., cycles and interlocking constraints), which increases the effective reasoning load and requires maintaining multiple competing hypotheses rather than simple sequential deduction. In addition, we introduce an explicit evidence-dispersion constraint to discourage single-page shortcut solutions: logically coupled facts are deliberately placed in disjoint sources, encouraging iterative planning and cross-document synthesis under realistic search settings. Proactive Tool-Augmented Queries. Learning to use tools purely via sparse trial-and-error exploration is sample-inefficient. We therefore tool-ground the synthesized queries by rewriting key facts into tool-resolvable constraints that cannot be satisfied by text retrieval alone. Concretely, we replace explicit entities with operationalized specificationse.g., turning place name into routing/distance constraint resolved by map tool, or swapping named entity for visual cue that requires image understanding. This design makes successful task completion contingent on invoking the appropriate tool, thereby densifying learning signals for targeted tool usage during long-horizon rollouts. Cost-Efficient Mid-Training. Bridging the gap between static pre-training and dynamic agent deployment requires dedicated transitional phase. We adopt two-stage mid-training regimen that separates the acquisition of atomic subskills from interactive execution. In the first stage, synthetic data strengthens core competenciesintent-anchored grounding (filtering noise to find evidence) and hierarchical planning (structuring ambiguous goals)at scale without costly environment interaction. The second stage introduces simulated tool-use loops and long-horizon trajectories to capture environmental feedback and state retention. By warm-starting the model with these capabilities before real-world exposure, we significantly improve initial exploration success and reduce the sample complexity and computational cost of collecting high-quality trajectories for downstream training. Functionally Equivalent Simulation Environment. To facilitate rapid algorithmic iteration, we construct lightweight, local simulated environment that mimics real-world web dynamics while eliminating the latency and expense of live API calls. Crucially, this environment is engineered to balance guaranteed solvability with high-interference noise: it ensures that all necessary evidence is present within the closed corpus, yet physically dispersed and buried amidst extensive distractor documents. This design rigorously stress-tests the agents ability to discriminate valid signals from noise, providing high-throughput sandbox that enables efficient reinforcement learning experiments and scalable evaluation without the bottlenecks of external network interactions."
        },
        {
            "title": "2 Preliminary",
            "content": "2.1 Problem Formulation We model web-enabled question answering session as an interactive process between an agent and an environment equipped with external tools. Let denote the user question, which may be unimodal (text) or multimodal (e.g., text with an image). Over multiple steps, the agent issues tool calls, observes returned evidence, and finally produces an answer grounded in the collected information. Core variables. We define the following variables for session: Question (q). The user-provided information need. In our setting, can be long, fuzzy, and underspecified, often requiring aggregation across sources and iterative refinement of constraints. Action (at). tool-mediated operation at step (e.g., issuing search query, opening page, following links, extracting snippets, parsing content, deduplicating results, or terminating). Observation (ot). The tool feedback after executing at (e.g., ranked results, snippets, page content, images and associated metadata, and any structured fields produced by tools). Internal state (τt). The agents working state at step t, which serves as compact representation of the interaction history and current constraints (e.g., reasoning summary, extracted entities/attributes, active hypotheses, and intermediate conclusions) used to decide the next action. Answer (y). The final response produced at the end of the interaction, which should be grounded in collected evidence and satisfy the constraints implied by q. When evidence is incomplete or conflicting, should explicitly reflect uncertainty. Interaction dynamics (fully observed). Let ht = (cid:0)q, (a0, o0), . . . , (at1, ot1)(cid:1) denote the transcript up to step t. The agent selects the next tool call conditioned on the available context, at π( ht), and receives feedback ot = E(at). We treat as deterministic tool interface given the issued request, and any apparent stochasticity (e.g., ranking variability) is absorbed into the returned observation ot. For multimodal settings, ot may include images and associated metadata in addition to text, and the transcript ht aggregates evidence across modalities. After steps, the agent outputs = g(q, hT ). 2.2 ReAct-style Trajectory Representation ReAct [44] organizes the interaction as an interleaved sequence of (state/thought, action, observation) tuples. For single instance, we record the trajectory as HT = (cid:0)q, (τ0, a0, o0), (τ1, a1, o1), . . . , (τT , aT , oT ), y(cid:1). (1) Here, τt summarizes the current constraints and intermediate beliefs derived from the history, at is the tool call selected under that state, and ot is the returned evidence. The final answer is produced after the last update using the accumulated state and evidence. 2.3 Context Management Even with long context windows, search-based agent trajectories can easily grow beyond the models maximum input length due to repeated tool calls, long webpages, and accumulated intermediate notes. When the context approaches the window limit, the agent may be forced to truncate earlier steps, which can break constraint tracking and degrade long-horizon performance. To handle this practical bottleneck, we adopt simple context management strategy: Discard-all [3, 23]. Concretely, once the running context exceeds preset threshold of the window budget, we reset the in-context tool-call history (i.e., remove all past (τi, ai, oi) pairs from the prompt) while keeping the original question and minimal task specification. The agent then re-initiates the rollout from fresh context, effectively trading long-term in-context memory for larger remaining token budget to continue exploration and tool use."
        },
        {
            "title": "3 Scalable Complex Task Synthesis",
            "content": "To train deep search agents capable of navigating the open world, we require queries that exhibit specific challenging characteristics: multi-hop reasoning, ambiguity, and non-linear search paths. Solving such queries mandates iterative tool usage and the synthesis of fragmented evidence. However, existing open-source datasets [43, 19] are predominantly constituted of linear, retrieval-friendly tasks that fail to drive the evolution of agentic capabilities. To address this, we establish scalable, controllable synthesis pipeline. 3.1 Motivation Before detailing the synthesis pipeline, we first formalize the following question: How should the complexity of deep search problem be characterized? We argue that deep search complexity can be decomposed into two dimensions: (i) Topological Logical Complexity and (ii) Information Source Dispersion. 3.1.1 Topological Logical Complexity: Treewidth Perspective Reasoning over complex queries can be formulated as constraint satisfaction or traversal problems on an underlying knowledge graph structure. classical insight in algorithmic and database theory is that the computational difficulty of many such graph-structured problems depends critically on structural properties of the underlying graph [9]. In particular, while general CSP-style reasoning can be NP-hard, broad families become tractable on instances whose graphs have bounded treewidth [18], and more generally, properties definable in monadic second-order logic admit linear-time algorithms on bounded-treewidth graphs (Courcelles Theorem) [8]. This suggests that query difficulty is driven not only by size, but also by how tightly constraints are couplede.g., through cycles and limited decomposability. Motivated by this perspective, we adopt treewidth as structural metric for topological logical complexity. Let querys logical structure be represented by graph = (V, E). tree decomposition of is pair (T, {Xi}iI ), where is tree and each node in is associated with \"bag\" of vertices Xi , satisfying: 1. The union of all bags equals . 2. For every edge (u, v) E, there exists bag Xi containing both and v. 3. For any vertex v, the set of nodes {i Xi} forms connected subtree in . The width of the decomposition is maxiI Xi 1. The treewidth of G, denoted as tw(G), is the minimum width over all possible tree decompositions of G: (cid:18) (cid:19) tw(G) = min (T,{Xi}) max iI Xi 1 (2) Intuitively, treewidth serves as proxy for the working memory required to Complexity Scaling. satisfy coupled constraints: tree-like structures (low treewidth) admit divide-and-conquer, whereas high treewidth indicates stronger entanglement among variables. As coarse proxyconsistent with dynamic programming over tree decompositionswe approximate reasoning cost as Creasoning O(N dk+1) (3) where is the number of reasoning steps (hops), is the branching factor per step (e.g., top-d candidates), and = tw(G). This highlights that increasing can impose an exponential burden, forcing the agent to maintain multiple entangled hypotheses rather than performing simple sequential deduction. As illustrated in Figure 2, we characterize task difficulty through the treewidth of the underlying reasoning graph. The figure visualizes three representative structural regimes. In each example, green nodes denote observed facts (given entities), yellow nodes correspond to intermediate latent variables that must be inferred, and the red node represents the final answer. As increases, the structural coupling among variables strengthens, and the reasoning process transitions from simple propagation to globally constrained joint verification. 4 Figure 2: Increasing reasoning complexity as function of graph treewidth. From left to right, the dependency structure evolves from simple chain (k = 1), to cyclic constraint graph (k = 2), and finally to fully coupled tetrahedral structure (k = 3). Green nodes denote given entities and red nodes denote the final answer, while yellow nodes represent intermediate reasoning variables. Higher treewidth corresponds to larger jointly maintained variable sets and stronger global consistency constraints, transforming reasoning from linear propagation to high-dimensional constraint satisfaction. Type I: Linear Reasoning (k = 1). Structure: Trees or simple chains. Example: \"A is the father of B, is the father of C... Who is A?\" Cognitive Load: The agent only needs to track the immediate predecessor. Complexity is polynomial (O(N d2)). This represents the majority of current multi-hop QA datasets. Type II: Cyclic/Diamond Constraints (k = 2). Structure: Graphs containing cycles or parallel paths that re-converge. Example: \"In which 1990 gangster film did the director cast his own daughter as the main characters daughter?\" Cognitive Load: The agent must simultaneously satisfy constraints between the Movie, Director, and Actress. This requires maintaining larger \"bag\" of variables (triplets) in memory to verify consistency, creating search space of O(N d3). failure in one branch (e.g., an incorrect daughter) necessitates backtracking. Type III: High-Dimensional Coupling (k 3). Structure: Clique-like structures (e.g., Tetrahedron). Example: \"Identify Person A: tech co-founder ousted in mid-80s power struggle, he launched new venture whose core technology was later bought out by his original company. Cognitive Load: Here, variables A, B, C, and are fully coupled.\" Cognitive Load: Here, variables A, B, C, and are fully coupled. The problem cannot be decomposed into independent sub-problems. The agent must validate complete K4 subgraph, leading to combinatorial explosion (O(N d4)) if effective pruning is not applied. 3.1.2 Distributional Complexity: Information Dispersion While treewidth captures the structural coupling of reasoning graph, it does not fully determine search difficulty in open-web settings. In particular, high information density on the web can create shortcut retrieval: single comprehensive document may contain multiple logically connected facts (e.g., nodes A, B, C, D), allowing theoretically complex instance to be solved with near one-shot retrieval (effectively reducing the required reasoning depth). To characterize this orthogonal factor, we introduce Minimum Source Dispersion (MSD), which measures how fragmented the required evidence is across sources. MSD is defined as the minimum number of distinct documents needed to cover the information required by the reasoning graph G: Dtask = min SW s.t. Cover(S, G) = True (4) where denotes the document corpus and represents retrieved subset. The condition Cover(S, G) implies that the union of information in is sufficient to resolve all nodes in graph G. Taken together, structural and distributional complexity offer dual view of deep-search difficulty. In practice, instances are most resistant to shortcut retrieval when both tw(G) and Dtask are high, i.e., when coupled facts are dispersed across disjoint sources. This motivates our dual-constrained optimization for task synthesis: we jointly control graph topology (treewidth) and evidence dispersion (MSD), encouraging iterative planning and cross-document synthesis under realistic web retrieval. 5 3.2 Scalable Complex Task Synthesis Pipeline Figure 3: Overview of the scalable complex task synthesis pipelinee. The process operates via dual-pathway mechanism to maximize both structural complexity and information dispersion, followed by rigorous solver-based verification stage. Guided by the theoretical framework established in 3.1, we design scalable synthesis pipeline to manufacture QA pairs that exhibit specific topological properties (e.g., 2) and high information dispersion. As illustrated in Figure 3, our pipeline departs from random template filling. Instead, it operates as graph-to-text inverse problem: we first construct reasoning graph with the desired treewidth and dispersion, and then transform this structure into natural language query. The pipeline consists of two distinct phases: QA Generation and Task Verification. 3.2.1 QA generation Seed Collection and Filtering. To bootstrap the synthesis pipeline, we initialize seed pool using English and Chinese Wikipedia entities [39]. We apply filtering cascade to isolate entity-centric pages, pruning noise four criteria: (i) main-text length thresholds to remove pages that are too short (too sparse) or too long (too popular / over-covered); (ii) structure filtering to discard lists, indexes, and glossaries; (iii) meta-page removal for administrative content; and (iv) concept filtering, where an LLM classifier distinguishes concrete entities from abstract theories. We deduplicate aliases and redirects to establish compact, high-signal seed pool for downstream generation. Graph Construction and Topological Enrichment. We adopt Directed Acyclic Graph as the fundamental data structure, as it naturally models multi-step reasoning while ensuring auditability. Starting from filtered seed entity, we expand the graph through two complementary acquisition streams: (i) structured relation harvesting from Wikidata, and (ii) hyperlink-based document discovery via web traversal. These streams run in parallel and serve distinct roles in graph construction, without requiring unified merge into single substrate. Crucially, to transcend simple multi-hop retrieval and achieve the high structural complexity (k 2) defined in 3.1, we introduce Topology-Enriched Cross-Source Graph construction phase. Instead of relying solely on explicit database relations, we deploy an LLM-driven Graph Agent to densify the topology. This densification introduces cycles into the dependency graph, breaking the linearity of search paths. It compels the solver to shift from sequential retrieval to joint constraint satisfaction, where valid answer is not found by following single thread, but by verifying that multiple, distributed pieces of evidence are mutually consistent. Efficient Subgraph and Answer Sampling. Building fully enriched, topology-dense graph is computationally expensive, requiring substantial LLM reasoning and retrieval calls. To amortize this cost, we adopt One-Graph-Multi-Task sampling strategy: from each master graph, we extract multiple distinct connected subgraphs as independent reasoning contexts. Within each subgraph, answer nodes are selected strictly by topological role (e.g., deep leaves vs. high-degree hubs). Different structural positions induce different reasoning requirements (e.g., long-chain backtracking vs. multi-constraint verification), thereby increasing task diversity. Reusing the same underlying graph yields an order-of-magnitude more training instances, effectively distributing the graph construction overhead across dozens of high-quality samples. 6 Question generation. Given the sampled knowledge graph and the target answer, we use large language model to generate natural-language question that faithfully captures the graph constraints in concise, natural form. Tool-Enforced Query Evolution. To enforce the proactive tool-augmented behavior outlined in our motivation, we implement Tool-Injection Strategy beyond simple text obfuscation. specialized Editor Agent rewrites each query by converting static entities into tool-resolvable functional dependencies, replacing direct facts with computable constraints. For example, instead of naming location, the agent uses Maps API to specify it via routing constraint (e.g., the city about two hours drive west of [Entity A]). Similarly, person entity can be substituted with an attribute-based identifier that requires external lookup, such as the scholar with approximately citations (or within narrow citation interval) retrieved from an academic profile index. These rewrites create informational gaps that cannot be reliably closed by text retrieval alone, making tool execution an intrinsic prerequisite of the reasoning trajectory. 3.2.2 Verifier pipeline The QA synthesis procedure intentionally increases difficulty (e.g., via fuzzing) and combines signals from multiple local sources (KB and cached webpages). As result, non-trivial fraction of generated instances may become too easy, internally inconsistent (questiongraphanswer mismatch), weakly retrievable on the open web, or non-unique in their solutions. To produce dataset that is both challenging and reliably verifiable, we employ the multi-stage verifier pipeline illustrated in Figure 3, which starts with cheap filters and gradually escalates to stronger, more expensive checks: 1. LLM solver pre-filter (no tools). We run an LLM solver without tool access; if it answers correctly, the instance is treated as insufficiently challenging and removed. 2. Retrievability check (Search snippets). We query the question with the search engine API; if the given answer does not appear in the snippets of the top-50 results, we filter the instance as weakly supported for open-web retrieval. 3. Hallucination / inconsistency check. We provide the grounded evidence used during construction (e.g., KB triples and cached passages) together with the final question to an LLM verifier; instances with clear contradictions are removed. 4. Agent rollout verification. We run one strong tool-using agents for independent rollouts; an instance is kept if at least one rollout predicts the given answer, and we record the pass rate as confidence signal. 5. Answer uniqueness check. Building on the successful rollouts, we further scrutinize the results for solution multiplicity. We discard instances where the agent plausibly identifies valid alternative answers or distinct candidate sets that satisfy the query constraints. While not formal guarantee of uniqueness, this heuristic filter significantly mitigates the risk of ambiguous or underspecified tasks by removing cases where the solver naturally diverges. Quality study. We validate the synthesis pipeline along two axes: solvability and difficulty under realistic budgets. First, to assess data fidelity, we perform human verification on subset of 500 instances. University-level annotators check logical consistency and grounding sufficiency, and over 85% of instances pass verification, indicating that the synthesized problems are well-formed and likely solvable. Second, to quantify difficulty, we evaluate strong open model, DeepSeek-V3.2 [23], under our standard agent setting, obtaining 40% accuracy. To further contextualize hardness, we additionally measure time-bounded human solvability: with 30-minute search budget, annotators solve 47% of instances. Together, these results suggest that our data is largely solvable, yet remains challenging for both models and humans within practical interaction budgets. 3.3 Multimodal Task Synthesis Pipeline 3.3.1 Multimodal QA Generation Our synthesis pipeline can be conveniently migrated to multimodal QA generation. The key is to reuse the same end-to-end skeleton and only modify small number of steps to incorporate visual evidence. This design keeps the dependency structure explicit and verifiable, while allowing us 7 to scale multimodal synthesis with nearly the same efficiency as text-only synthesis. As result, the multimodal pipeline inherits the same desirable properties as the text-only setting: scalability, controllable difficulty, explicit dependencies, and verifiability. Concretely, we introduce modality injection to turn purely textual reasoning DAG into cross-modal reasoning DAG, where some constraints are anchored in images and must be resolved via visual understanding. We then extend fuzzing and verification with image-aware variants (3.3.1), so that the resulting multimodal questions remain challenging and grounded. Modality injection. We implement modality injection via two complementary mechanisms. Visual attribute anchoring selects an intermediate node in the DAG and augments its attribute field with an image-grounded textual description. Concretely, we attach an image to node and generate (or retrieve from cached pages) detailed textual description of the visual content (e.g., salient objects, scene type, distinctive symbols, or chart patterns). This description is stored as part of the node attributes and is treated as constraint for downstream construction, enabling the question to reference visual evidence without revealing the final answer. Cross-modal dependency enforces visual irreplaceability constraint: without extracting the required visual cue from the image (e.g., background object, an emblem on clothing, or trend line in chart), the model cannot obtain the information needed to derive the downstream node v. This prevents the image from being decorative and ensures that successful solving requires both visual understanding and external search. Multimodal question fuzzing. We introduce image-aware fuzzing strategies. Visual-semantic abstraction avoids directly naming the image content in the question and instead uses abstract references (e.g., pronouns or relative descriptions), forcing the model to first recognize the visual entity and then search. Modality translation allows visual evidence to be injected at arbitrary positions along the reasoning trajectory, rather than only at the beginning. By replacing selected intermediate textual constraints with image-grounded descriptions, we can (i) place visual bottleneck after several text-based steps to increase effective reasoning depth, and (ii) control difficulty more finely by choosing which intermediate constraint must be resolved visually. Multimodal verifier pipeline. We build the multimodal verifier pipeline by starting from the textonly verifier (3.2.2) and adding extra checks to ensure that the image is both necessary and consistent. In particular, we remove instances that remain solvable without using vision: text-only solvability discards cases where pure-text reasoner can answer correctly, and text-only retrievability discards cases where text-only web-search agent can recover the answer without accessing the image. The multimodal setting also introduces additional failure modes (e.g., images being too revealing or irrelevant). We therefore further extend the verifier pipeline with visual-consistency checks. Visiononly solvability check runs vision-language model with image input only; if the answer can be guessed from the image without search, the instance is discarded as overly direct. Visual-search alignment verifies that the image content and retrieved webpages form complementary reasoning loop, filtering instances where the image is unrelated or purely decorative. Multimodal agent rollout evaluates vision-capable tool-using agent end-to-end and records its success rate; instances with consistently high success rate over multiple rollouts are considered too easy and discarded. By integrating modality injection with vision-aware verification, our pipeline turns static knowledge graph into dynamic cross-modal reasoning scaffold. This design ensures that the resulting multimodal QA pairs are not merely text questions accompanied by decorative images, but visually grounded search tasks that require tight coupling between perception, reasoning, and retrieval. Importantly, this multimodal extension only requires simple yet necessary modifications to the original synthesis pipeline, enabling efficient large-scale multimodal QA generation. 3.3.2 Multimodal Trajectory Generation We synthesize high-quality SFT trajectories using ReAct [44] agent instantiated with standardized tool schemas. Qwen3VL-235B [5] alternates between generating intent-aware reasoning and issuing structured tool calls; tool outputs are returned as observations to guide subsequent steps. For efficiency and stability, we cap each episode at 20 interaction rounds, after which the model must produce final answer. We retain only trajectories whose final answers match the ground-truth labels for supervised fine-tuning. 8 Figure 4: Mid-training and post-training stages for REDSearcher."
        },
        {
            "title": "4 Overall Training Recipe",
            "content": "We start from pretrained open source models and specialize it for multi-turn online web search with tool interaction. Our training follows two-phase recipe, as shown in Figure 4. Mid-training exposes the model to long-horizon search traces and tool-use patterns, leveraging large-scale synthetic data to ensure sufficient coverage of diverse reasoning trajectories, so that it learns stable interleaved behaviors without degrading its general language ability at low cost. Post-training subsequently optimizes end-to-end behavior, thereby enhancing the models agentic reasoning capabilities for complex information seeking."
        },
        {
            "title": "5 Agentic Mid-Training via Low-Cost Large-Scale Data Synthesis",
            "content": "Figure 5: Two stage agentic mid-training framework. While pre-training equips LLMs with strong knowledge and reasoning capabilities, it lacks experiential interaction with external environments, leaving pronounced capability gap for agentic tasks requiring environmental perception, action execution, and feedback-driven strategy refinement. To bridge this gap, we introduce agentic mid-training as critical bridge between general-purpose pre-training and agent-specific post-training, comprising two sequential phases: the first strengthens atomic capabilities, including knowledge grounding and planning; the second builds upon this foundation to develop multi-turn environmental interaction and long-horizon decision-making capabilities. However, acquiring large-scale mid-training data through manual annotation or real-world environment interaction is prohibitively expensive. To address this, we propose scalable and cost-effective data synthesis framework for generating agent mid-training data at scale. 5.1 Stage I: Intent-anchored Grounding and Hierachical Planning (32K Context) Search-Agent tasks necessitate that models plan multi-step search strategies throughout long-horizon interactions and filter as well as integrate information from substantial volume of web pages. This process fundamentally relies upon two core atomic capabilities: the Grounding capability, which facilitates the extraction of key information from redundant observations in accordance with current intent, and the Hierarchical Planning capability, which decomposes complex tasks into hierarchical sub-goals to support multi-step planning while maintaining alignment with global objectives. Intent-anchored Grounding Within deep search tasks, models are required to accurately identify information that is absent from the current reasoning step amidst noisy web browsing environments. We refer to this process as Intent-anchored Grounding. This step serves as the cornerstone of deep 9 search agents; it is imperative that we ensure models acquire accurate and comprehensive information during this stage while avoiding the generation of hallucinations, thus laying robust foundation for subsequent long-horizon search tasks. To accomplish this, we adopt reverse question-answer synthesis approach incorporating distractors. More specifically, given central entity along with its corresponding document D, we extract factual segments pertinent to the central entity from the document, which encompass related events and attributes associated with the central entity. Following this extraction, we synthesize query intents related to the central entity based on these factual segments. Through this methodology, we are able to establish correspondences between the central entity under varying query intents. Moreover, in order to adapt to the noisy characteristics of web search environments, our input documents incorporate not only documents relevant to the central entity but also irrelevant distractor documents, which collectively serve as the final input. We leverage publicly available Wikipedia dumps and cached web crawls as seeds for QA synthesis, requiring no additional data collection effort. Hierarchical Planning When confronted with complex tasks, planning capability assumes paramount importance. In contrast to conventional multi-turn question-answering problems that possess clearly defined reasoning structures, deep search problems tend to exhibit greater ambiguity and necessitate an increased number of reasoning hops. It is unrealistic to directly determine each subsequent search and reasoning step based solely on the initial problem formulation. To address this challenge, we propose to resolve this issue through hierarchical planning. Hierarchical planning partitions the entry points for solving complex problems into two distinct categories: concrete goals that currently require explicit resolution (for instance, possessing clear query intent and desiring to obtain specific information related to that query intent), and ambiguous goals that require resolution in the future (seeking to narrow uncertainty through queries in order to determine specific target). This partitioning renders long-horizon planning for complex problems feasible, enabling the model to maintain awareness throughout the search process regarding both information that has already been acquired and information that remains to be obtained. We leverage the topological structure information of knowledge base entities and web pages that is obtained during the QAs synthesis pipeline. We flatten the graph along the information flow direction, then leverage LLMs to generate corresponding plans based on the preceding context. 5.2 Stage II: Agentic Tool Use and Long-horizon Interaction (128K Context) Pre-trained models lack exposure to environmental feedbacka critical component in agent systems. To address this, we incorporate tool-calling data involving external environment interactions during Mid-Training. We further introduce long-horizon interaction trajectories to strengthen the models agentic capabilities in complex deep information seeking scenarios. However, acquiring large-scale observations and trajectories through real-world environment is prohibitively expensive. To address this, we adopt two cost-effective and scalable strategies: (1) leveraging LLMs to generate large number of tool protocols and simulate diverse tool-calling interactions without invoking external services, and (2) deploying simulated environments to efficiently collect long-horizon agentic interaction trajectories. Agentic Tool Use To enable the model to acquire the capability of perceiving and responding to environmental feedback, we construct multi-turn tool-calling data that encompasses complete ReACT loops. However, invoking external tools, such as web search operations and external APIs, incurs substantial costs. To this end, we employ simulated environments to achieve large-scale environment augmentation during the Mid-Training stage. We utilize LLMs to generate tool sets, which include tool descriptions, interface signatures, and tool invocation chains. Subsequently, we synthesize relevant queries based on these tool sets and employ LLMs to provide environmental feedback for tool invocations. This approach enables the collection of extensive multi-turn tool interaction trajectories with diverse tool-calling patterns at scale. Long-Horizon Interaction Deep search tasks often involve dozens of search iterations, during which the model confronts core challenges including state space explosion, historical information forgetting, and goal consistency maintenance. To address these challenges, we introduce long-horizon environmental interaction data to enhance the models optimization in long-context scenarios. 10 In long-horizon search scenarios, using LLMs to simulate environmental inputs becomes infeasible, both from cost considerations and from the perspective of generation correctness and consistency. To overcome this limitation, we construct comprehensive local simulated web search environment based on Wikipedia and Web Crawl Dumps, supporting fundamental web search and webpage access operations. Moreover, our comprehensive simulated web search environment ensures that the complex queries synthesized through our data pipeline are solvable within the local environment. We employ large-scale synthesized complex queries as inputs to generate trajectories within the local search environment, which are utilized to enhance the models long-horizon reasoning capabilities."
        },
        {
            "title": "6 Agentic Post-Training",
            "content": "Through our mid-training phase, the model has acquired foundational capabilities for agentic tasks. In the post-training phase, we aim to activate these capabilities using high-quality data to enhance the models performance on downstream deep search tasks. REDSearcher employs two-stage post-training process: supervised fine-tuning on synthesized agentic trajectories, followed by agentic reinforcement learning. 6.1 High-quality Trajectory Synthesis in Real-world Environments Real-world Environment Interface REDSearcher employs five real-world environment interfaces, including web search, web visit, python code execution, google scholar, and google maps. Search uses google search engine for information retrieval from the Internet. The interface accepts multiple queries as input, and returns list of organic results, including page title, snippet, and url. Visit is used to access specific information in url. The interface accepts url and goal as input, and return the web page by Jina. Typically, we use summarizer to summarize webpage information according to the goal to alleviate the context pressure on the agent model. Python provides agents with code sandbox execution environment, supporting tasks such as mathematical calculations, data processing, and logical reasoning. Agents can write and execute Python code and obtain execution results. Google Scholar is specifically designed for academic literature retrieval, supporting agents in searching for academic papers, citation information, and author profiles Google Maps provides geographic location and map-related services, including place search, route planning, distance calculation, and geographic information queries. This interface enables agents to handle tasks involving spatial reasoning and geographic knowledge. High-quality Trajectory Synthesis We develop low-cost, highly scalable framework for generating complex deep search questions, as illustrated in Figure 3. This framework enables automated large-scale data synthesis at minimal cost without human intervention, while the synthesized problems achieve difficulty levels comparable to BrowseComp.1 In our trajectory synthesis and agentic reinforcement learning process, we exclusively use QAs synthesized through our own pipeline. We employ the ReAct workflow for trajectory synthesis. This paradigm addresses complex problems through an iterative thought-action-observation loop: at each turn, the agent makes decisions and invokes tools based on prior context, receives observations from the environment, and repeats this process until final answer is produced. During synthesis, we set the maximum context length to 128K tokens. Samples exceeding the maximum length are discarded rather than forcing response. Post-filtering is applied to ensure the correctness of trajectories used for supervised fine-tuning. First, we retain only samples where the final answer is correct. Second, to prevent the model from learning incorrect patterns or behaviors, we filter out samples that contain substantial number of failed action and tool response. Finally, to promote sample diversity, we preserve only one trajectory per question. 1DeepSeek-V3.2 achieves average@4 of approximately 40% on our synthetic QA dataset. 11 6.2 Supervised Fine-tuning We conduct supervised fine-tuning (SFT) on the mid-training checkpoint using high-quality trajectories to enhance RedSearchers agentic reasoning capabilities. During this stage, we employ the standard next-token prediction loss while masking the environment observation portions to exclude them from gradient updates. We set the maximum context length to 128K during SFT. 6.3 Agentic Reinforcement Learning We employ reinforcement learning with verifiable rewards (RLVR) to enable the continuous improvement of the policy agent through interactions with real environments. The policy model interacts with the environment through the ReAct (Reasoning and Acting) paradigm. At each turn, the model generates thoughts and executes corresponding actions, then adjusts its subsequent strategy based on environmental observation. After rollouts conclude, the LLM judge provides verifiable reward by evaluating the alignment between the agents prediction and the ground-truth answer. RL Algorithm. We use GRPO [29] as the training algorithm during reinforcement learning. Concretely, for each question we sample group of trajectories, compute their final rewards, and normalize rewards within the group to obtain relative advantages. We update πθ with clipped policy-gradient objective using these relative advantages. Following DAPO [45], we use clip higher during training. The final reward {0/1} only indicates the correctness of the model prediction, and since the model has already learned the required format during SFT, we do not employ any format rewards. JGRPO(θ) = Eq (cid:34) 1 (cid:88) k= (cid:16) min ρq,k(θ) ˆAq,k, clip(cid:0)ρq,k(θ), 1 ϵ, 1 + ϵ(cid:1) ˆAq,k (cid:35) (cid:17) , (5) , yk) denotes the where is the number of rollouts per question and Hk k-th rollout trajectory under ReACT paradigm. The advantage ˆAq,k of k-th sample of is computed via group-relative normalization: = (q, τ 0, . . . , τ 0 , ak 0, ok ˆAq,k = rq,k rq σq + ϵ , rq = 1 (cid:88) k=1 rq,k, σq = (cid:118) (cid:117) (cid:117) (cid:116) 1 (cid:88) (rq,k rq)2, (6) k=1 where rq,k {0, 1} denotes the outcome reward for the k-th trajectory. Functionally Equivalent Simulation Environment. Real-world web search APIs pose several challenges in early-stage experiments, such as unstable external interfaces2 and high query overhead, which hinder rapid experiment iteration. To address this, we construct an offline simulated search environment. When constructing the simulated environment, we focus on three key aspects: Interface Consistency: The API specifications should remain consistent with real search APIs to ensure experimental results are transferable to real-world settings. Evidence Completeness: The simulated environment should encompass all essential evidence required to answer the synthetic queries, including both directly supporting snippets and intermediate evidence necessary for multi-hop reasoning. Environmental Noise: The simulated environment should not be overly simplistic; it should be sufficiently large in scale and incorporate adequate distracting information to simulate the inherent noise and uncertainty in real-world web search scenario. To this end, we construct large-scale local search environment containing tens of millions of documents. This environment is built upon finewiki dumps and cached web search and visit results collected during the QAs synthesis process. Our environment supports three commonly used tools in search tasks: search, visit, and python. To prevent the model from being biased by Wikipedias URL patterns, we implement URL obfuscation pipeline. Specifically, we construct URL template library categorized by entity domain, then leverage an LLM to identify the domain of each entity given the 2Web crawling tools often suffer from high failure rates due to network instability and access restrictions. snippet and sample synthetic URL from the corresponding templates. The search contents retrieved during our data construction pipeline are already cached in the local search repository, thereby ensuring the completeness of the local environment for solving synthesized questions. Moreover, the tens of millions of documents also ensure sufficient level of noise in the environment, preventing the model from developing biased capabilities due to an overly simplistic setting. RL Query Curation For the RL query set construction, we filter out samples that are either too simple or too difficult, as these samples fail to provide effective learning signals during training. Our query set is derived from diverse synthesis pipelines, thereby covering wide range of problemsolving patterns and difficulty gradients. Furthermore, we observe that automatically constructed QAs often suffers from issues such as multiple valid answers or inconsistent ground truth, which can severely interfere with the learning signals in RLVR with outcome-based rewards. To address this, we introduce an Agent-as-Verifier pipeline, where verifier agent retrieves relevant information through external tool calls and compares it against the questions metadata and trajectory to determine the validity of each question. Human evaluation results demonstrate that this pipeline reduces the error rate of the RL query set to merely 10% of the original. RL Training Framework During the rollout phase, the agent needs to interact extensively with the environment. Traditional synchronous rollout approaches significantly slow down training efficiency. To address this, we implement an asynchronous rollout workflow based on Slime [48], effectively improving rollout throughput. Furthermore, rollout lengths in deep search tasks often reach up to 128k tokens, making efficient prefix cache hits critical for rollout performance. To tackle this problem, we design two-tier rollout load balancing strategy: requests within the same rollout maintain inference engine affinity to maximize prefix cache reuse, while load balancing across inference engines is achieved through combination of round-robin and least-access scheduling. For environment interaction, we deploy dedicated server to handle external environment calls during RL training. This server encapsulates all tool call interfaces into unified request interfaces and implements fallback strategies for error-prone interfaces such as search and web crawling, thereby ensuring maximum stability of environment interactions throughout the training process."
        },
        {
            "title": "7 Experiments",
            "content": "7.1 Experimental Setup Benchmarks. Following prior work, we evaluate our model on diverse set of highly challenging benchmarks and compare against representative baselines. We adhere to each benchmarks official evaluation protocol. Our evaluation suite includes: Humanitys Last Exam [26], BrowseComp [40], BrowseComp-ZH [47], GAIA [24]. We also evaluate on multimodal search benchmarks to validate our strong multimodal retrieval and reasoning capability, including MM-BrowseComp [22], BrowseComp-VL [12], MMSearch-Plus [32], MMSearch [41], and LiveVQA [11]. Baselines. We compare our model with the strongest existing search-agent baselines, including (1) proprietary agents, such as Seed1.8 [28], Gemini-3-Pro [10], GPT-5.2 [30]; (2) open-source agents, such as Kimi-K2.5 [34], GLM-4.7 [46], DeepSeek-V3.2 [23]; (3) open-source lightweight agents, including Tongyi DeepResearch [37], GLM-4.7-Flash [46], and so on. We also compare against state-of-the-art multimodal search models, including Gemini-3-Pro [10], Seed1.8 [28], and an agent workflow built on Qwen3-VL [5] with the same toolset as used in our experiments. Besides, we also compare REDSearcher-MM with existing multimodal deepsearch agents, such as DeepEyesV2 [14] and Vision-DeepResearch [15]. Implementation Details. Full implementation details for reproducibility are deferred to Appendix A. 13 Table 1: Comparison between REDSearcher and closed / open agentic models. The performance with the context management technique is noted with . Backbone Size BrowseComp [40] BrowseComp-zh [47] GAIA [24] HLE [26] Overall Proprietary Deep Research Agents Seed1.8 [28] Gemini2.5proDR [7] Gemini3Pro [10] Claude4.5sonnet [2] OpenAIo3 [25] GPT5Thinkinghigh [30] GPT5.2Thinkingxhigh [30] - - - - - - - 67.6 7.6 37.8 24.1 49.7 54.9 65.8 81.3 27.3 51.6 42.4 58.1 63.0 76.1 Open-source Deep Research Agents KimiK2.5Agent [34] GLM4.7 [46] DeepSeekV3.2 [23] LongCatFlashThinking [36] 1TA32B 355BA32B 671BA37B 560BA27B 60.6 / 74.9 52.0 / 66.6 51.4 / 67.6 56.6 / 73.1 - - / 67.5 - / 65.0 69.0 / 77.7 Open-source 30BA3B Agents WebResearcher30B [27] WebSailorV230B [21] Tongyi DeepResearch30B [37] GLM4.7Flash [46] REDSearcher 30BA3B 30BA3B 30BA3B 30BA3B 30BA3B 37.3 35.3 43.4 42.8 45.2 44.1 46.7 - 42.1 / 57.4 49.8 / 58.2 87.4 - 74.8 66.0 70.5 76.7 - - - - - - 74.1 70.9 - 80.1 40.9 - 45.8 32.0 20.2 41.7 - 50.2 42.8 40.8 - 28.8 30.6 32.9 - 34.3 69.3 - 52.5 41.1 49.6 59.1 - - - - - 46.0 48.5 - 51.6 7.2 LLM Experimental Results 7.2.1 Main Results As presented in Table 1 , REDSearcher establishes new state-of-the-art among open-source agents in the 30B parameter class. With the integration of our context management technique, the model achieves an Overall score of 51.3, substantially outperforming leading same-scale competitors such as Tongyi DeepResearch-30B (48.5) [37] and WebSailorV2-30B (46.0) [20]. Beyond its dominance in the open-source landscape, REDSearcher exhibits remarkable competitiveness against larger proprietary models. It surpasses both Claude-4.5-sonnet (41.1) [2] and OpenAI-o3 (49.6) [25] in overall performance metrics. Most strikingly on the GAIA benchmark, which evaluates complex agentic capabilities, REDSearcher attains score of 80.1, outstripping even the GPT-5Thinkinghigh model (76.7) [30]. These results underscore the efficacy of our proposed architecture, demonstrating that REDSearcher delivers top-tier deep research capabilities with superior parameter efficiency. 7.2.2 Ablation of Mid-Training Stages Table 2 summarizes the progressive impact of the mid-training stages. Overall, we observe steady improvement in average performance (42.81 to 47.39), validating mid-training as critical bridge for developing agentic capabilities. Stage (Grounding & Planning) focuses on building atomic competencies. The introduction of Intent-anchored Grounding improves BrowseComp (+1.87) by enhancing information extraction from noisy environments. Furthermore, Hierarchical Planning leads to significant leap in GAIA (+4.13), confirming that partitioning goals into concrete and ambiguous sub-tasks is essential for complex reasoning. Stage II (Agentic Tool Use & Interaction) facilitates the transition from \"understanding\" to \"acting.\" By incorporating environmental feedback and long-horizon trajectories, we see the most substantial gains in BrowseComp-ZH (+8.91). This breakthrough demonstrates that exposure to real-world action-feedback loops and 128K context is crucial for maintaining goal consistency and robust execution in deep search scenarios. 14 Table 2: Effect of progressive mid-training stages on downstream SFT performance across four benchmarks. Each stage builds upon the previous one to incrementally improve model capabilities. Base Stage I. Grounding Stage I. Planning Stage II. Agentic"
        },
        {
            "title": "34.74\nBrowseComp\nBrowseComp-ZH\n26.82\nHuman Last Exam 32.25\n77.43\nGAIA",
            "content": "Average 42.81 36.61 27.34 32.00 76.70 43.16 36.97 29.84 31.37 80.83 44. 40.44 38.75 31.25 79.13 47.39 Figure 6: Training dynamics of REDSearcher during Agentic Reinforcement Learning. (a) Training reward and evaluation reward across training steps. Evaluation reward is computed over BC, BC-ZH, HLE, and GAIA benchmarks. (b) Rollout lengths and rollout success rate during training. 7.3 RL Continues to Advance Model Capabilities We investigate the effectiveness of agentic RL in enhancing the long-horizon search capabilities of LLMs. As shown in Figure 6, the models performance continuously improves with RL training. As shown in Figure 6 (a), agentic RL continues to yield consistent improvements even when initialized from relatively strong SFT checkpoint. Prior to RL training, the SFT model achieves an average evaluation reward of 47.4 across four benchmarks (BrowseComp, BrowseComp-zh, HLE, and GAIA), with BrowseComp score of 39.4. Following RL training, the average reward increases to 51.3 (+3.9) and the BrowseComp score rises to 42.1 (+2.7), corresponding to relative performance gain of approximately 8.2% and 6.8%, respectively. Besides, we observe an interesting trend in search efficiency during training. As shown in Figure 6 (b), the rollout length gradually decreases over RL training, while the reward remains stable or continues to improve. This phenomenon suggests that the model learns more efficient explore and search strategies through RL. Quantitatively, the average number of tool calls decreases from 100.6 to 90.1, representing 10.4% reduction. The fact that performance does not degrade despite shorter trajectories indicates that the model has learned to identify more streamlined strategies for task completion, minimizing redundant tool calls without sacrificing effectiveness. 7.3.1 Decoupling Tool Use from Parametric Knowledge Final benchmark accuracy can conflate two factors: success from tool-mediated evidence acquisition versus direct recall from parametric knowledge. To better isolate tool-use capability, we evaluate each system in two regimestool-free and tool-enabledand analyze the resulting performance gap (Figure 7). In the tool-free regime, REDSearcher scores lowest among the compared systems, consistent with reduced reliance on memorized facts or benchmark overlap. When tools are enabled, REDSearcher improves substantially and achieves strong overall results, indicating effective planning, evidence gathering, and multi-step synthesis. Several strong baselines, however, maintain non-trivial accuracy without tools. This may reflect broader pre-training coverage and/or latent benchmark overlap, and can overstate long-horizon, tool-mediated ability if one considers final accuracy alone. Overall, tool-enabled gains provide more diagnostic signal of deep-search competence by more directly measuring how agents benefit from iterative tool interactions. 15 Figure 7: Performance comparison of REDSearcher and existing models in tool-free settings Table 3: Main results on multimodal search benchmarks. denotes results evaluated using the same evaluation tools as ours, and denotes results taken from [28]. Model Params MM-Browse Comp [22] Browse Comp-VL[12] MMSearch Plus [32] MM Search [41] Live VQA [11] HLE (text) [26] HLE -VL [26] Browse Comp [40] Browse Comp-ZH [47] Gemini-2.5-Flash [7] Gemini-2.5-Pro [7] Seed1.8 [28] Seed1.8 [28] GPT-5 [30] Gemini-3-Pro [10] Qwen2.5-VL [6] Qwen3-VL Thinking [5] Qwen3-VL Thinking [5] 72B 30B 235B MMSearch-R1 [41] WebWatcher [12] DeepEyesV2 [14] Vision-DeepResearch [15] REDSearcher-MM-SFT REDSearcher-MM-RL 7B 32B 7B 30B 30B 30B 5.6 7.1 46.3 21.4 28.5 1.8 10.7 12.1 25.3 23.5 Proprietary Deep Research Agents 44.6 49.9 54.1 46.1 56.4 10.2 37.1 43.1 27.0 53.7 55.3 57.2 19.9 22.2 11.0 17.2 38.1 64.0 69.0 69.7 63.7 73. Multimodal Agent Flow - 11.0 17.4 29.2 59.7 63.3 Multimodal Deep Research Agent 28.5 20.2 26. 53.8 55.3 63.7 69.6 70.3 72.9 73.0 76.0 62.4 73.3 79.9 35.7 64.8 70.2 48.4 58.7 77.6 78.5 79. - 40.9 41.7 45.8 8.8 14.5 24.4 25.3 - 31.5 36.0 4.9 8.7 14. 13.6 24.2 25.6 7.6 67.6 54.9 37.8 0.2 0.3 30.1 31. 27.3 81.3 63.0 51.6 7.2 18.6 43.1 44.5 7.4 Multimodal Experimental Results 7.4.1 Main Results Table 3 summarizes results on multimodal search benchmarks, where queries and evidence include visual inputs. Our model delivers strong vision-language search performance, demonstrating effective visual grounding and multimodal evidence integration. On highly challenging benchmarks such as MM-BrowseComp [22], our method achieves competitive performance against state-of-the-art systems (e.g., Gemini-3-Pro [10] and Seed1.8 [28]), while substantially outperforming strong Qwen3-VL-235B [5] agent baseline. Meanwhile, on relatively simpler multimodal search benchmarks (e.g., MMSearch [16] and LiveVQA [11]), our approach maintains excellent results, indicating robust multimodal retrieval and reasoning across difficulty levels. Finally, we also evaluate our multimodal search model on text-only benchmarks, where it achieves strong performance, suggesting that the learned search and reasoning capabilities transfer well even without visual inputs. In addition, we find that reinforcement learning further improves models overall performance. 7.4.2 MultiModal DeepReSearch Analysis Turns Distribution across Different Difficulty Benchmarks. We categorize the benchmarks into two groups according to their accuracy and difficulty: simple and challenging. We then analyze the distribution of tool-usage turns (i.e., the number of invoked tool calls) for both correct and incorrect predictions in Figure 8. Note that we enforce hard cutoff at 30 turns, where the model is forced to output final answer. We observe three phenomena from the turn distributions: (1) The turn distributions differ substantially between the simple and challenging benchmarks: simple benchmarks 16 Figure 8: Turns distribution of REDSearcher-MM on different kinds of benchmark. typically require only small number of turns for the model to retrieve sufficient evidence and answer with high confidence, whereas challenging benchmarks often demand many more search turns. (2) The model sometimes continues searching even after it has already encountered the correct evidence, due to insufficient confidence to finalize an answer. (3) This over-searching behavior is more pronounced on challenging benchmarks, where large fraction of examples concentrate near the 30-turn cutoff, indicating that the model frequently keeps searching until it is forced to answer. Furthermore, we observe reduction in the number of tool-use turns after RL training, trend that is particularly pronounced on relatively simple benchmarks. We attribute this to the strict search turn limit (20 turns) imposes during the RL phase, which encourages the model to minimize search steps while maintaining response accuracy. Figure 9: Tool category distribution of REDSearcher-MM. Tool Category Distribution. We further analyze tool usage by categorizing tool calls into different types in Figure 9, and we observe clear differences across benchmarks with different characteristics and difficulty. For example, MMSearch [16] mainly concentrates on web search and webpage browsing, whereas the more challenging MM-BrowseComp [22] induces substantially more textsearch steps due to its long-horizon evidence gathering requirements. In contrast, MMSearchPlus [32] emphasizes fine-grained visual perception in query construction, which leads to more frequent image-centric operations such as zoom-in and image search. Thinking Patterns. We further characterize the models high-level thinking patterns during tool use in Figure 10, which can be broadly grouped into three types: (1) Decomposition, where the model breaks complex query into smaller, actionable sub-questions and solves them sequentially via targeted tool calls; (2) Reflection, where the model revisits intermediate conclusions, identifies missing evidence or uncertainty, and adjusts the search plan accordingly; and (3) Verification, where the model cross-checks candidate answers against additional sources (or multiple pieces of evidence) 17 Figure 10: Thinking patterns of REDSearcher-MM on several multimodal search benchmarks. before committing to final response. It can be seen that models thinking patterns differ across benchmarks of varying difficulty levels and types. For relatively simple benchmarks (i.e., BroseCompVL [12] and MMSearch [16]), there is less decomposition, much smaller proportion of reflection, and also much lower proportion of verification. In addition, on multimodal search benchmarks, the model is more likely to take visual information into account during its reasoning."
        },
        {
            "title": "8 Conclusion",
            "content": "We present REDSearcher, scalable framework for training long-horizon deep search agents across text and multimodal settings. To address the scarcity of high-quality training data, we propose dual-constrained task synthesis that generates structurally complex reasoning tasks with dispersed evidence, ensuring the necessity of iterative planning and cross-document synthesis. To reduce the computational and temporal costs of trajectory collection, we introduce cost-efficient mid-training that separates atomic subskill acquisition from interactive execution, combined with functionally equivalent simulation environment that enables high-throughput trajectory generation without relying on expensive live API calls. Building upon this foundation, we advance the models search intelligence through trajectory synthesis, supervised fine-tuning, and agentic reinforcement learning. Together, these contributions provide practical pathway for scaling deep search agents, marking significant step toward transforming LLMs from passive knowledge retrievers into proactive agents capable of long-horizon reasoning and autonomous exploration over the open world."
        },
        {
            "title": "Contributions",
            "content": "Core Contributors Zheng Chu1, Xiao Wang2, Jack Hong2 Contributors Huiming Fan1, Yuqi Huang3, Yue Yang3, Guohai Xu2, Chenxiao Zhao2, Cheng Xiang2, Shengchao Hu3, Dongdong Kuang2, Bing Qin1, Xing Yu2 Project Leader Xiao Wang2 Advisors Ming Liu1, Xiao Wang2 1 Harbin Institute of Technology 2 Xiaohongshu Inc. 3 Shanghai JiaoTong University Emails: zchu@ir.hit.edu.cn, wangxiao14@xiaohongshu.com, mliu@ir.hit.edu.cn"
        },
        {
            "title": "References",
            "content": "[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. [2] Anthropic. Claude sonnet 4.5. https://www.anthropic.com/news/claude-sonnet-4-5, 2025. [3] Anthropic. System card: Claude opus 4.5, November 2025. [4] Muhammad Arslan, Hussam Ghanem, Saba Munawar, and Christophe Cruz. survey on rag with llms. Procedia computer science, 246:37813790, 2024. [5] Shuai Bai, Yuxuan Cai, Ruizhe Chen, Keqin Chen, Xionghui Chen, Zesen Cheng, Lianghao Deng, Wei Ding, Chang Gao, Chunjiang Ge, Wenbin Ge, Zhifang Guo, Qidong Huang, Jie Huang, Fei Huang, Binyuan Hui, Shutong Jiang, Zhaohai Li, Mingsheng Li, Mei Li, Kaixin Li, Zicheng Lin, Junyang Lin, Xuejing Liu, Jiawei Liu, Chenglong Liu, Yang Liu, Dayiheng Liu, Shixuan Liu, Dunjie Lu, Ruilin Luo, Chenxu Lv, Rui Men, Lingchen Meng, Xuancheng Ren, Xingzhang Ren, Sibo Song, Yuchong Sun, Jun Tang, Jianhong Tu, Jianqiang Wan, Peng Wang, Pengfei Wang, Qiuyue Wang, Yuxuan Wang, Tianbao Xie, Yiheng Xu, Haiyang Xu, Jin Xu, Zhibo Yang, Mingkun Yang, Jianxin Yang, An Yang, Bowen Yu, Fei Zhang, Hang Zhang, Xi Zhang, Bo Zheng, Humen Zhong, Jingren Zhou, Fan Zhou, Jing Zhou, Yuanzhi Zhu, and Ke Zhu. Qwen3-vl technical report, 2025. [6] Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923, 2025. [7] Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. [8] Bruno Courcelle. The monadic second-order logic of graphs. i. recognizable sets of finite graphs. Information and computation, 85(1):1275, 1990. [9] Víctor Dalmau, Phokion Kolaitis, and Moshe Vardi. Constraint satisfaction, bounded treewidth, and finite-variable logics. In International Conference on Principles and Practice of Constraint Programming, pages 310326. Springer, 2002. [10] Google DeepMind. Gemini 3 pro. https://deepmind.google/models/gemini/pro/, 2025. [11] Mingyang Fu, Yuyang Peng, Benlin Liu, Yao Wan, and Dongping Chen. Livevqa: Live visual knowledge seeking. arXiv preprint arXiv:2504.05288, 2025. [12] Xinyu Geng, Peng Xia, Zhen Zhang, Xinyu Wang, Qiuchen Wang, Ruixue Ding, Chenxi Wang, Jialong Wu, Yida Zhao, Kuan Li, et al. Webwatcher: Breaking new frontier of vision-language deep research agent. arXiv preprint arXiv:2508.05748, 2025. [13] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [14] Jack Hong, Chenxiao Zhao, ChengLin Zhu, Weiheng Lu, Guohai Xu, and Xing Yu. Deepeyesv2: Toward agentic multimodal model. arXiv preprint arXiv:2511.05271, 2025. [15] Wenxuan Huang, Yu Zeng, Qiuchen Wang, Zhen Fang, Shaosheng Cao, Zheng Chu, Qingyu Yin, Shuang Chen, Zhenfei Yin, Lin Chen, et al. Vision-deepresearch: Incentivizing deepresearch capability in multimodal large language models. arXiv preprint arXiv:2601.22060, 2026. [16] Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanmin Wu, Jiayi Lei, Pengshuo Qiu, Pan Lu, Zehui Chen, Chaoyou Fu, Guanglu Song, et al. Mmsearch: Benchmarking the potential of large models as multi-modal search engines. arXiv preprint arXiv:2409.12959, 2024. [17] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Zamani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025. [18] Ton Kloks. Treewidth: computations and approximations. Springer, 1994. [19] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453466, 2019. [20] Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, et al. Websailor-v2: Bridging the chasm to proprietary agents via synthetic data and scalable reinforcement learning. arXiv preprint arXiv:2509.13305, 2025. [21] Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, et al. Websailor: Navigating super-human reasoning for web agent. arXiv preprint arXiv:2507.02592, 2025. [22] Shilong Li, Xingyuan Bu, Wenjie Wang, Jiaheng Liu, Jun Dong, Haoyang He, Hao Lu, Haozhe Zhang, Chenchen Jing, Zhen Li, et al. Mm-browsecomp: comprehensive benchmark for multimodal browsing agents. arXiv preprint arXiv:2508.13186, 2025. [23] Aixin Liu, Aoxue Mei, Bangcai Lin, Bing Xue, Bingxuan Wang, Bingzheng Xu, Bochao Wu, Bowei Zhang, Chaofan Lin, Chen Dong, et al. Deepseek-v3. 2: Pushing the frontier of open large language models. arXiv preprint arXiv:2512.02556, 2025. [24] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations, 2023. [25] OpenAI. Openai o3. https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/ o3-and-o4-mini-system-card.pdf, 2025. [26] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanitys last exam. arXiv preprint arXiv:2501.14249, 2025. [27] Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, et al. Webresearcher: Unleashing unbounded reasoning capability in longhorizon agents. arXiv preprint arXiv:2509.13309, 2025. [28] Bytedance Seed. Seed1. 8 model card: Towards generalized real-world agency. [29] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. [30] Aaditya Singh, Adam Fry, Adam Perelman, Adam Tart, Adi Ganesh, Ahmed El-Kishky, Aidan McLaughlin, Aiden Low, AJ Ostrow, Akhila Ananthram, et al. Openai gpt-5 system card. arXiv preprint arXiv:2601.03267, 2025. [31] Zhongxiang Sun, Qipeng Wang, Weijie Yu, Jingxuan Yang, Haolang Lu, and Jun Xu. Deep search with hierarchical meta-cognitive monitoring inspired by cognitive neuroscience. arXiv preprint arXiv:2601.23188, 2026. [32] Xijia Tao, Yihua Teng, Xinxing Su, Xinyu Fu, Jihao Wu, Chaofan Tao, Ziru Liu, Haoli Bai, Rui Liu, and Lingpeng Kong. Mmsearch-plus: Benchmarking provenance-aware search for multimodal browsing agents. arXiv preprint arXiv:2508.21475, 2025. [33] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew Dai, Anja Hauth, Katie Millican, et al. Gemini: family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. [34] Kimi Team, Tongtong Bai, Yifan Bai, Yiping Bao, SH Cai, Yuan Cao, Charles, HS Che, Cheng Chen, Guanduo Chen, et al. Kimi k2. 5: Visual agentic intelligence. arXiv preprint arXiv:2602.02276, 2026. [35] Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, et al. Kimi k2: Open agentic intelligence. arXiv preprint arXiv:2507.20534, 2025. [36] Meituan LongCat Team, Anchun Gui, Bei Li, Bingyang Tao, Bole Zhou, Borun Chen, Chao Zhang, Chen Gao, Chen Zhang, Chengcheng Han, et al. Longcat-flash-thinking-2601 technical report. arXiv preprint arXiv:2601.16725, 2026. 21 [37] Tongyi DeepResearch Team, Baixuan Li, Bo Zhang, Dingchu Zhang, Fei Huang, Guangyu Li, Guoxin Chen, Huifeng Yin, Jialong Wu, Jingren Zhou, et al. Tongyi deepresearch technical report. arXiv preprint arXiv:2510.24701, 2025. [38] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023. [39] Denny Vrandeˇcic and Markus Krötzsch. Wikidata: free collaborative knowledgebase. Communications of the ACM, 57(10):7885, 2014. [40] Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. Browsecomp: simple yet challenging benchmark for browsing agents. arXiv preprint arXiv:2504.12516, 2025. [41] Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, and Ziwei Liu. Mmsearch-r1: Incentivizing lmms to search. arXiv preprint arXiv:2506.20670, 2025. [42] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. [43] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher Manning. Hotpotqa: dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 conference on empirical methods in natural language processing, pages 23692380, 2018. [44] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations, 2022. [45] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui Wu, and Mingxuan Wang. DAPO: an open-source LLM reinforcement learning system at scale. CoRR, abs/2503.14476, 2025. [46] Aohan Zeng, Xin Lv, Qinkai Zheng, Zhenyu Hou, Bin Chen, Chengxing Xie, Cunxiang Wang, Da Yin, Hao Zeng, Jiajie Zhang, et al. Glm-4.5: Agentic, reasoning, and coding (arc) foundation models. arXiv preprint arXiv:2508.06471, 2025. [47] Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, et al. Browsecomp-zh: Benchmarking web browsing ability of large language models in chinese. arXiv preprint arXiv:2504.19314, 2025. [48] Zilin Zhu, Chengxing Xie, Xin Lv, and slime Contributors. slime: An llm post-training framework for rl scaling. https://github.com/THUDM/slime, 2025. GitHub repository. Corresponding author: Xin Lv. Implementation Details. REDSearcher are trained based on Qwen3-30B-A3B [42]. During the mid-training phase, we use batch size of 512 in Stage 1 and batch size of 256 in Stage 2. For the SFT stage, we use batch size of 128. Throughout the mid-training and SFT phases, the learning rate decays from 5e-5 to 1e-6, with linear decay in mid-training followed by cosine decay in sft. We adopt GRPO as RL training algorithm. Each mini-step consists of 32 queries, with 16 rollout samples per query, resulting in mini-batch size of 512. The learning rate is fixed at 1e-6 throughout this stage. We set clip high to 0.28, and do not use entropy loss and kl loss. We employ Truncated Important Sampling (TIS) and Routing Replay (R2) to mitigate inconsistency issues. To ensure stable gradient updates during RL training, we filter out abnormal samples that exhibit repetition, excessive length, or frequent tool call failures. These samples still participate in advantage computation but are excluded from gradient updates. During inference, we set the temperature to 0.85, top_p to 0.95, and the maximum length to 128K. Once the model exceeds the context limit, we roll back to the previous round and force an answer. For summarizer used in visit tool, we employ Qwen3-30B-A3B-Instruct-2507. For LLM-as-Judge, we use GPT-OSS-120B. For multimodal search, we use Qwen3-VL-30B-A3B-Thinking [5]. For SFT, we train with batch size of 128 and learning rate of 1105. The model is optimized for three epochs using the AdamW optimizer with cosine learning-rate decay. For RL, we adopt GRPO [13, 29] as the optimization algorithm, with batch size of 32 and 8 rollouts per prompt. The KL coefficient is set to 0.0, and the maximum response length is capped at 32,768 tokens. During RL, we cap the tool-calling horizon to maximum of 20 tool calls per episode."
        },
        {
            "title": "System Prompt of REDSearcher",
            "content": "You are deep search assistant. Your primary role is to perform rigorous, multi-step, multi-source investigations on any topiccovering both broad, open-domain questions and highly specialized academic inquiries. For each user request, you must actively seek out and cross-check information from credible and diverse sources, then integrate the findings into response that is comprehensive, accurate, well-structured, and objective. ## Operating principle 1. **Plan and execute research**: Break complex questions into sub-questions, gather evidence across multiple sources, and prioritize primary sources and authoritative references when available. 2. **Evaluate source quality**: Prefer reputable institutions, peer-reviewed research, official documentation, and high-quality journalism. Note uncertainty, conflicts, and limitations when sources disagree. 3. **Synthesize, dont just list**: Combine evidence into coherent narrative or structured output (e.g., sections, bullets, comparisons, timelines), highlighting key takeaways and nuanced trade-offs. 4. **Maintain neutrality**: Present competing viewpoints fairly when relevant, and avoid unsupported speculation. When you have collected sufficient information and are ready to deliver the definitive response, you must wrap the entire final answer in **<answer></answer>** tags. # Tools You may call one or more functions to assist with the user query. You are provided with function signatures within <tools></tools> XML tags: <tools> {\"type\": \"function\", \"function\": {\"name\": \"search\", \"description\": \"Perform Google web searches then returns string of the top search results. Accepts multiple queries.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"description\": \"The search query.\"}, \"minItems\": 1, \"description\": \"The list of search queries.\"}}, \"required\": [\"query\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"visit\", \"description\": \"Visit webpage(s) and return the summary of the content.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"The URL(s) of the webpage(s) to visit. Can be single URL or an array of URLs.\"}, \"goal\": {\"type\": \"string\", \"description\": \"The specific information goal for visiting webpage(s).\"}}, \"required\": [\"url\", \"goal\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"PythonInterpreter\", \"description\": \"Executes Python code in sandboxed environment. To use this tool, you must follow this format:1. The arguments JSON object must be empty: {}.2. The Python code to be executed must be placed immediately after the JSON block, enclosed within <code> and </code> tags.IMPORTANT: Any output you want to see MUST be printed to standard output using the print() function.Example of correct call:<tool_call>{\"name\": \"PythonInterpreter\", \"arguments\": {}}<code>import numpy as np # Your code here print(f\"The result is: np.mean([1,2,3])\") </code></tool_call>\", \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}}} {\"type\": \"function\", \"function\": {\"name\": \"google_scholar\", \"description\": \"Leverage Google Scholar to retrieve relevant information from academic publications. Accepts multiple queries.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"description\": \"The search query.\"}, \"minItems\": 1, \"description\": \"The list of search queries for Google Scholar.\"}}, \"required\": [\"query\"]}}}"
        },
        {
            "title": "System Prompt of REDSearcher",
            "content": "{\"type\": \"function\", \"function\": {\"name\": \"google_maps\", \"description\": \"Search Google Maps places. Returns list of places with name, address, coordinates, ratings, categories, opening hours, and place identifiers.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"q\": {\"type\": \"string\", \"description\": \"Google Maps search query.\"}, \"page\": {\"type\": \"integer\", \"description\": \"Page number of results.\", \"default\": 1, \"minimum\": 1}}, \"required\": [\"q\"]}}} For each function call, return json object with function name and arguments within <tool_call></tool_call> XML tags: <tool_call> {\"name\": <function-name>, \"arguments\": <args-json-object>} </tool_call> 25 System Prompt of REDSearcher-MM You are an agent - please keep going until the users query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. Solve the following problem step by step. If you find you dont have sufficient knowledge to confidently answer the question, you MUST conduct search to thoroughly seek the internet for information. No matter how complex the query, you will not give up until you find the corresponding information. You can conduct image search, which will trigger Google Lens search using the original image to retrieve relevant information that can help you confirm the visual content, and text search, which will use Google Search to return relevant information based on your query. You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully. For all the provided images, in order, the i-th image has already been read into the global variable image_i using the PIL.Image.open() function. For example, the first image can be accessed as image_0. When writing Python code, you can directly use these variables. without needing to read them again. All image-capable tools also accept an optional JSON argument {\"image_index\": k, ...} to explicitly choose which image to operate on. The index is zero-based, so 0 refers to the first image by default; if you omit this field, the tool automatically uses image_0. Please put the answer within <answer></answer> tags. Inside these tags, the core answer must be wrapped in boxed{}. In addition, include supporting evidence, explanations, and broader context within the same <answer></answer> section. # Tools You may call one or more functions to assist with the user query. You are provided with function signatures within <tools></tools> XML tags: <tools> {\"type\": \"function\", \"function\": {\"name\": \"text_search\", \"description\": \"A web search tool that returns list of web pages with summaries based on input queries. Queries should be concise and clear. Break down complex questions into multiple steps. If no useful results are found, adjust the query by reducing qualifiers or changing the search approach. For better results, use Chinese queries for Chinese resources and English for non-Chinese resources.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"description\": \"The search query.\"}, \"minItems\": 1, \"description\": \"List of search queries.\"}}, \"required\": [\"query\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"text_image_search\", \"description\": \"A web image search tool that returns information such as images and corresponding original webpage URLs based on input queries. Queries should be concise and clear. Break down complex questions into multiple steps. If no useful results are found, adjust the query by reducing qualifiers or changing the search approach. For better results, use Chinese queries for Chinese resources and English for non-Chinese resources.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"search queries\"}}, \"required\": [\"query\"]}}} 26 System Prompt of REDSearcher-MM {\"type\": \"function\", \"function\": {\"name\": \"image_zoom_in_search\", \"description\": \"This is visual search tool used to search the entire web for image results similar to the input image. It performs searches based on images and returns relevant images, videos, and product information.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"image_index\": {\"type\": \"integer\", \"description\": \"Optional index of the image to search (default 0).\"}, \"bbox_2d\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}, \"description\": \"ROI coordinates. **Must** be an array containing 4 integer values (ranging from 0 to 1000), representing the normalized coordinates of the cropping region. Format. [left_top_x, left_top_y, right_bottom_x, right_bottom_y]. Example. [100, 289, 381, 465]. The meaningless full-image coordinates like [0, 0, 1000, 1000] are prohibited.\"}}, \"required\": [\"image_index\", \"bbox_2d\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"image_search\", \"description\": \"This is visual search tool used to search the entire web for image results similar to the input image. It performs searches based on images and returns relevant images, videos, and product information.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"image_index\": {\"type\": \"integer\", \"description\": \"Optional index of the image to search (default 0).\"}}, \"required\": [\"image_index\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"web_summary\", \"description\": \"This is web summary tool that can open links and summarize all relevant information on the page according to the goal. It is recommended to invoke this tool for valuable links to obtain information. Valuable links include but are not limited to the following types. 1. URLs explicitly provided in the task; 2. URLs with relevant abstracts returned by search results (source URLs of images returned by image searches are also included in this scope); 3. URLs contained in the content returned by previous calls of web_summary and judged to potentially contain useful information. Please try to avoid constructing links out of thin air.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"string\", \"description\": \"The target link shall be complete URL (starting with http).\"}, \"goal\": {\"type\": \"string\", \"description\": \"Requirement description text, which elaborates on the content to be retrieved from the current URL in detail.\"}}, \"required\": [\"url\", \"goal\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"image_zoom_in\", \"description\": \"Image zoom-in tool. Crop and magnify designated area for viewing image details, text recognition or subsequent identification processes. It is extremely useful for object location in images and content retrieval from images. For the thinking section after ZoomIn, detailed interpretation of the zoomed-in image is required.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"image_index\": {\"type\": \"integer\", \"description\": \"Optional index of the image to search (default 0).\"}, \"bbox_2d\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}, \"description\": \"ROI coordinates. **Must** be an array containing 4 integer values (ranging from 0 to 1000), representing the normalized coordinates of the cropping region. Format. [left_top_x, left_top_y, right_bottom_x, right_bottom_y]. Example. [100, 289, 381, 465]. The meaningless full-image coordinates like [0, 0, 1000, 1000] are prohibited.\"}, \"label\": {\"type\": \"string\", \"description\": \"Optional labels for describing the content of the cropped area, helping the model better understand the semantic information of the cropped image.\"}}, \"required\": [\"image_index\", \"bbox_2d\", \"label\"]}}} <tools> For each function call, return json object with function name and arguments within <tool_call></tool_call> XML tags: <tool_call> {\"name\": <function-name>, \"arguments\": <args-json-object>} </tool_call>"
        },
        {
            "title": "C Synthetic Data Case",
            "content": "We show some cases of our synthesized data. Its operational commencement coincided with this disease outbreak in July The founder, whose given name is common French masculine name and surname is Question: An industrial entity in the music production sectora record pressing plant and labelis located approximately 360 km southwest of the city that hosted the 2016 Summer Olympics, within the South American country that experienced significant outbreak of mosquito-borne viral disease, colloquially named for racial stereotype regarding attraction to people of East Asian descent, beginning in late 2016 and intensifying in mid-2017. 2017. of Hebrew origin meaning gift, previously created limited edition album of 500 copies released three years before the plants founding. format material derived from flexible, partially crystalline polymer. release using this specific material is limited edition EP of 500 copies created by musical artist known for the psychedelic garage acid punk genre, who formed in 2005 and is signed to record label whose acronym HFTG could also refer to high school metal band known as Hanging from the Gallows. Based on these clues, what is the name of this pressing plant and label, which combines the Portuguese word for vinyl with the name of South American country? Answer: Vinil Brasil The plant presses records using An example Question: During the year the WHO declared COVID-19 pandemic, 100-bed healthcare facility located in suburb approximately 27 km northeast of the financial capital of the Indian state that borders six other states including Gujarat and Madhya Pradesh, experienced critical generator failure. three minutes after sunset and resulted in fatal evacuation. calendar year with major electrical fire at repurposed hotel COVID facility in city situated on the banks of the Krishna River, approximately 63 km northwest of major port on the Bay of Bengal coast in the same state. infrastructure failures, what is the identity of the suburban facility where the generator failure proved fatal? Answer: Apex Hospital The failure, fire caused by short circuit, occurred about Based on this interconnected timeline of This incident shared its 28 Question: Held on one-mile oval track in the United States during the final months of 2001, this professional stock car racing event featured pole winner born at the start of the 1980s who had previously set qualifying record while still teenager. official name of the competition, which was won by the driver of the vehicle displaying the specific livery shown in the provided image. Identify the Answer: 14th Annual Checker Auto Parts 29 Question: In the late 1940s, strategic hilltop village was depopulated during military operation. This site is situated approximately halfway between the historic market town containing the medieval tower shown in the image and globally revered holy metropolis to the east. Its lands are currently occupied by modern cooperative settlementlocated in time zone two hours ahead of UTCwhose name translates to Root or Source, reference derived from the Septuagint translation of the Book of Joshua. depopulated village. Identify the name of the Answer: Saris 30 Question: The career of this gridiron athlete began in the metropolitan area defined by the massive copper sculpture shown in the image. He attended secondary school in neighboring districtan institution established to relieve overcrowding in the same year major volcanic eruption occurred less than 100 miles away, and which shares its name with historic local settlement. Identify the athlete. Answer: Erik Ainge"
        }
    ],
    "affiliations": []
}