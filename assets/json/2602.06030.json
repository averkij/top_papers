{
    "paper_title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "authors": [
        "Kavana Venkatesh",
        "Yinhan He",
        "Jundong Li",
        "Jiaming Cui"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs."
        },
        {
            "title": "Start",
            "content": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Kavana Venkatesh 1 Yinhan He 2 Jundong Li 2 Jiaming Cui"
        },
        {
            "title": "Abstract",
            "content": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on crosscontextual behavioral responses and novel contrastive loss, reducing LLM calls by up to 68. Experiments across public health, finance, and social sciences show consistent gains in eventtime accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes new paradigm for scalable and calibrated simulation with LLMs. 6 2 0 2 5 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 1 0 3 0 6 0 . 2 0 6 2 : r 1. Introduction Many complex systems of scientific and societal importance, such as infectious disease spread (Deng et al., 2020; Pastor-Satorras et al., 2015), social diffusion (Qiu et al., 2018; Kempe et al., 2003), financial contagion (Xu et al., 2021; Xiang et al., 2022), and infrastructure failure cas1Virginia Tech 2University of Virginia. Correspondence to: Kavana Venkatesh <kavanav@vt.edu>, Jiaming Cui <jiamingcui@vt.edu>. Preprint. February 6, 2026. 1 cades (Kipf et al., 2018; Fang et al., 2021) are governed by state-dependent interactions unfolding across multiple scales (Veliˇckovic et al., 2017; Battaglia et al., 2018). Individual entities do not evolve in isolation: their behaviors are shaped by local interactions, shared group-level influences, and broader contextual signals such as policies, norms, or collective risk perception (Ying et al., 2018; Lowe et al., 2017). Accurately simulating such systems therefore requires models that can jointly capture mechanistic structure, data-driven dynamics, symbolic context, and uncertainty while remaining scalable and interpretable. Agent-based models (ABMs) provide principled foundation by explicitly modeling interacting entities through mechanistic transition rules, yielding interpretability and emergent behavior (Epstein, 2012; Bonabeau, 2002). However, classical ABMs rely on hand-crafted, static rules and coarse calibration, limiting adaptation to heterogeneous populations, multimodal signals, and non-stationary regimes (Pastor-Satorras et al., 2015). Learned transition models, including probabilistic graphical models, neural state-space models, and graph neural networks have been incorporated to improve flexibility (Murphy, 2012; Krishnan et al., 2017; Kipf & Welling, 2017; Hamilton et al., 2017; Rossi et al., 2020), but often obscure mechanistic structure and exhibit poor uncertainty calibration under distribution shift (Ovadia et al., 2019). More recently, large language models (LLMs) have enabled generative agent-based models (GABMs) with rich symbolic reasoning and memory (Park et al., 2023; gen, 2024; soc, 2025). Parallel lines of work integrate LLMs into ABM pipelines for social simulation and conversational dynamics (llm, 2023; abm, 2024; age, 2025). Yet most LLMbased GABMs perform reasoning at the level of individual agents, incurring high computational cost, weak grounding in relational data, and unreliable stochastic behavior in the absence of principled uncertainty modeling (llm, 2024; lim, 2024). Taken together, existing approaches reveal two fundamental gaps in generative agent-based modeling. First, inference is performed at the level of individual agents (Park et al., 2023; Gao et al., 2024) despite strong group-level, institutional, and contextual forces that drive coherent population dynamics (Granovetter, 1978; Centola, 2018). Second, symbolic reasoning and neural learning are combined heuristically (Manhaeve et al., 2018; Yi et al., 2018) rather than PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 1. Overview of PhysicsAgentABM Architecture. Inference is performed at the cluster level via symbolic and neural pathways with uncertainty-aware fusion, followed by stochastic agent-level realization. ANCHOR enables behaviorally coherent abstraction. treated as complementary epistemic sources with explicit uncertainty modeling. Real-world systems make these gaps explicit: epidemic dynamics shift coherently within communities (Chang et al., 2021; Block et al., 2020), financial institutions co-move through shared exposures (Billio et al., 2012; Diebold & Yılmaz, 2014), and social groups align around common narratives. Capturing such structure requires population-level inference that produces calibrated priors for individual realization (Gelman et al., 1995; Ovadia et al., 2019), rather than isolated agent simulation. We introduce PhysicsAgentABM, hierarchical neurosymbolic framework that addresses these challenges by redefining inference in generative agent-based models. PhysicsAgentABM elevates inference from individual agents to adaptive agent clusters, where shared dynamics, contextual influences, and uncertainty are modeled explicitly. Cluster-level predictions define probabilistic transition priors (Tran et al., 2017; Fortuin & Ratsch, 2019), while individual agents stochastically realize state transitions conditioned on local attributes and neighborhood context, preserving heterogeneity without sacrificing population-level coherence (Figure 1). Within each cluster, state-specialized symbolic reasoning layer coordinated by meta-agent encodes mechanistic constraints and regime context, while multimodal neural transition model (Baltruˇsaitis et al., 2018) captures temporal and interaction-driven regularities. These pathways are treated as distinct epistemic hypotheses and reconciled through uncertainty-aware fusion (Hullermeier & Waegeman, 2021) to yield calibrated, population-consistent dynamics. critical enabler of this hierarchy is clustering itself. In generative agent-based models, clustering must be semantically meaningful, transition-faithful, and adaptive to evolving dynamics. Classical graph clustering methods optimize structural criteria while ignoring behavioral and dynamical semantics (Schaeffer, 2007; Loukas, 2019), whereas existing LLM-based simulators (Park et al., 2023; Hong et al., 2023; Qian et al., 2024) use LLMs to execute agent behavior rather than to reason about abstraction. We therefore introduce ANCHOR, novel LLM-agentdriven clustering mechanism in which symbolic agents act as semantic controllers of abstraction (Huang et al., 2022), organizing populations based on evolving cross-contextual behavioral similarity (Newman, 2006; Yang et al., 2009), interaction structure, and state-transition tendencies under graph constraints. By using LLMs to control where and how abstraction occurs rather than to simulate individual agents, ANCHOR enables scalable symbolic reasoning aligned with downstream probabilistic transition modeling. Our contributions are threefold: We introduce PhysicsAgentABM, hierarchical neuro-symbolic framework for cluster-level inference 2 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 2. ANCHOR Overview. An overview of our clustering mechanism. via state-specialized symbolic and neural reasoning. We propose ANCHOR, the first LLM-agent-anchored clustering method that treats abstraction as semantic control problem for transition-faithful simulation. We introduce calibrated, timestep-aligned paradigm that decouples population-level inference from agentlevel realization for robust long-horizon dynamics. systemic risk propagation in networks (Hurd et al., 2016; Gai & Kapadia, 2010). Recent work incorporates large language models to enrich agent decision-making and simulate more realistic behavior (Park et al., 2023). However, these approaches rely on hand-crafted rules or costly per-agent LLM inference, limiting principled integration of multimodal signals into population-level dynamics. 2. Related Work 2.1. LLM-Based Multi-Agent Simulation Frameworks LLMs have enabled generative multi-agent systems with language-based reasoning and coordination (Wang et al., 2024; Guo et al., 2024). Frameworks such as MetaGPT and ChatDev demonstrate role-specialized collaboration (Hong et al., 2023; Qian et al., 2024), while Generative Agents and AgentScope model large-scale social behavior (Park et al., 2023; Gao et al., 2024). Related work studies coordination protocols and grounding in structured environments (Li et al., 2023; Wu et al., 2024; Zhu et al., 2023; Wang et al., 2023). However, most approaches operate at the individual-agent level, incurring high computational cost and limiting scalability (Mou et al., 2024). Their reliance on LLM priors without explicit mechanistic structure further limits interpretability, uncertainty quantification, and physical alignment, leading to temporal inconsistency and miscalibration under distribution shift (Du et al., 2023). 2.2. ABM for Social and Health Dynamics ABMs simulate complex social and health systems by modeling interacting individuals and emergent collective behavior (Bonabeau, 2002; Epstein, 2012). They have been widely applied to infectious disease dynamics (Hethcote, 2000; Pastor-Satorras et al., 2015), social contagion and behavioral cascades (Granovetter, 1978; Watts, 2002), and 2.3. Graph and Behavior-Aware Clustering Methods Graph clustering optimizes structural objectives such as modularity (Newman, 2006), spectral criteria (Von Luxburg, 2007), or edge density (Blondel et al., 2008), but typically ignores node attributes, temporal dynamics, and behavioral semantics. Feature-aware extensions with differentiable pooling (Ying et al., 2018) and temporal graph models (Rossi et al., 2020) capture evolving structure, yet remain agnostic to decision-making behavior. Recent work applies large language models to semantic graph reasoning (Pan et al., 2024; Ye et al., 2024), but largely treats LLMs as embedding generators. In contrast, ANCHOR uses LLMs as semantic controllers of abstraction, enabling transition-faithful clustering via cross-contextual behavioral probing aligned with downstream state-transition modeling. 3. Methodology 3.1. PhysicsAgentABM Architecture We model the population as an interaction graph = (V, E) with adjacency matrix {0, 1}N , where each entity occupies discrete state xi(t) = {S1, . . . , SK}. The state space is application-dependent (e.g., {susceptible, exposed, infected, recovered, deceased} in epidemiology or {bullish, bearish, neutral} in finance), and encodes local mechanistic interactions such as contact or influence. For scalability, inference relies on neigh3 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling borhood statistics derived from rather than explicit pairwise modeling. Entities are partitioned into clusters {Ck}M k=1 of agents exhibiting similar behavioral responses to contextual stimuli, constructed via ANCHOR (Section 3.2). Within each cluster Ck, PhysicsAgentABM infers population-level state transition dynamics via two complementary pathways: symbolic reasoning and neural prediction, both estimating hazards over the same set of valid transitions but with distinct inductive biases. The symbolic pathway operates on cluster-level context Ck(t) = (cid:0)ϕk(t), ψk(t), ψ (t)(cid:1), where ϕk(t) summarizes state composition, ψk(t) captures exogenous temporal context, and ψ (t) aggregates neighboring-cluster signals. Conditioned on Ck(t), meta-agent coordinates statespecialized agents to estimate symbolic hazards Λsym (t) = {ˆλk,sym ss (t)}(s,s)T with associated epistemic uncertainty uk ss(t), modeling population-level transition tendencies rather than discrete actions. In parallel, the neural pathway estimates cluster-level hazards from aggregated multimodal inputs xk(t) = [tabulark(t), temporalk(t), graphk] using multimodal encoder to produce ˆΛneu (t). Symbolic and neural estimates are combined via uncertainty-aware epistemic fusion at the transition level: λfused = csym ˆλsym + cneu ˆλneu csym + cneu , (1) where confidence terms (csym, cneu) are adaptively calibrated by lightweight MLP. The resulting fused hazards define population-consistent transition priors. Individual entities then stochastically realize state transitions by modulating these priors with local attributes and neighborhood statistics from A, decoupling population-level inference from agentlevel realization (Section 3.3). See Figure 1 and Algorithm 1 for an overview of our framework. 3.2. ANCHOR: Agent-Driven Multi-Stage Clustering Stage 1: Structural-Semantic Initialization. Given an interaction graph = (V, E) with edge weights Wij and agent attributes X, ANCHOR computes scalable structural embeddings GRAPHSAGE(G, X) capturing local topology and neighborhood semantics. Embeddings are then concatenated with attributes to form = [H X]. Spectral clustering on yields coarse clusters {Ci}Kcoarse i=1 , providing structural prior without invoking agent reasoning. Stage 2: Behavioral Motif Discovery and Agent Profiling. To capture decision-making behavior beyond structure, we run short-horizon domain-specific mini-simulations under controlled diagnostic scenarios = {s1, . . . , sM }. For each agent and scenario s, we record reasoning-action traces (s, rs j), which are embedded and clustered to identify behavioral motifs {Mk}Km k=1. behavioral motif is recurring pattern in how an agent responds to seemingly , as i=1,t=1 Initialize state xi(0) and memory Mi Algorithm 1 PhysicsAgentABM Simulation Workflow Input: Interaction graph = (V, E), adjacency A, clusters {Ck}M k=1, state space S, transition set , time horizon Output: Agent state trajectories {xi(t)}N,T 1: for each agent do 2: 3: end for 4: for = 1 to do 5: 6: 7: 8: 9: Compute regime context Ck(t) = (ϕk(t), ψk(t), ψ for each transition (s s) do for each cluster Ck do k,s(Ck(t)) (t)) (cid:16)ˆλk,sym ss (t), ˆλk,neu (cid:17) ss (t) ˆλk,sym ss (t) Asym ˆλk,neu ss (t) fθ(xk(t)) λk ss (t) Fuse end for end for for each agent do Identify cluster Ck s.t. Ck for each outgoing transition (s s) from xi(t) = do ss (t) g(cid:0)λk λi end for xi(t + 1) Categorical({λi ss (t), Mi, Ai (cid:1) ss (t)}sSi {1}) 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: end for 21: return {xi(t)}i,t end for diverse situations in given problem setting (mobility at home vs community). Each agent is summarized by motif frequency profile Pj = [freq(M1), . . . , freq(MKm )], and each coarse cluster by its dominant motif profile Di = 1 Pj. This representation decouples behavioral Ci control from topology and forms the basis for anchor agent selection and contrastive refinement in the next stage. jCi (cid:80) Stage 3: Anchor-Guided Contrastive Refinement. For each coarse cluster Ci, we select an anchor agent ai = arg minjCi Pj Di2 as behaviorally representative reference in the motif space from Stage 2. Anchors actively guide refinement by evaluating regime compatibility: for each anchoragent pair (ai, j), the anchor produces soft judgment qij [0, 1] via LLM-based reasoning over behavioral motif summaries and contextual probes, indicating whether agent follows decision logic consistent with the anchors regime. Each agent is encoded as (j) = [Hj Pj contextj]. Clustering is refined by optimizing novel joint objective that couples contrastive learning with anchor judgments: = Lctr + λ (cid:88) (cid:16) KL qij i,j (cid:13) (cid:13) (cid:13) σ(cid:0)sim(f (j), (ai))(cid:1)(cid:17) , (2) where Lctr enforces regime separation and the alignment term matches learned similarity to anchor-defined compatibility. We set λ = 1/N , where is the number of agentanchor comparisons in the batch. Final representations Zj = αHj + βf (j) + γPj with α + β + γ = 1 are learned to maximize cluster quality, and hierarchical 4 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling synchronous realization preserves individual heterogeneity while enforcing shared population regime, consistent with standard stochastic epidemic and agent-based modeling practice (Gillespie, 1977; Pastor-Satorras et al., 2015). 4. Experiments 4.1. Experimental Setup We evaluate PhysicsAgentABM on three partially observable domains with regime shifts and latent population dynamics: epidemiology, finance, and social attention. In all settings, agents interact over structured networks, evolve through discrete latent states, and are evaluated against population-level ground truth signals. Epidemiology: Singapore MOH COVID-19 data (Mathieu et al., 2020) (first 1,000 confirmed cases; Jan 23-Apr 14, 2020) with infection/recovery/death timestamps and contact tracing; ground-truth SEIRD states are inferred using 7-day presymptomatic exposure window. Agents interact via multilayer contact network (household/workplace/community), and cluster-level neural inputs aggregate demographics, latent state proportions, transition statistics, network embeddings, and exogenous policy/mobility signals. Finance: Market sentiment diffusion with synthetic population of 100 traders (heterogeneous wealth, risk tolerance, trading styles, portfolios) over the top 20 S&P 500 stocks across two financial quarters (Jul 1-Dec 31, 2024), interacting through correlation network from historical returns. Since individual sentiment states (Bullish/Bearish/Neutral) are unobserved, population-level ground truth uses daily S&P 500 market regimes as proxy for collective risk appetite. Attention Lifecycle: Population attention to Climate Change over 90 days (Dec 1, 2024Feb 28, 2025) with 250 agents (heterogeneous activity and topic affinity) interacting over social graph; latent states (Unaware/Interested/Fatigued) are evaluated using normalized daily Wiki page views to capture emergence, amplification, and fatigue. Full details are in Appendix Sec. F, and D. Baselines: We compare PhysicsAgentABM against eight baselines spanning four paradigms. Mechanistic: Rule-ABM (ter Hoeven et al., 2025) and MF-Markov (McKean Jr, 1966). Neural: GNN-LSTM (Scarselli et al., 2008; Hochreiter & Schmidhuber, 1997) and TGN (Rossi et al., 2020). LLM-based: single LLM-Agent and flat LLM multi-agent system (Park et al., 2023). Hybrid: DeepProbLog (Manhaeve et al., 2018) and Rule-NN (Andrews et al., 1995). Baselines operate at the individual-agent level without hierarchical abstraction or explicit uncertainty fusion. For fairness, all methods are evaluated under the same data availability and supervision regime, with inputs adapted to each model class (mechanistic, neural, or LLM-based). Evaluation Protocol: We adopt rolling-window foreFigure 3. ANCHOR cross-contextual clusters (epidemiology). ANCHOR identifies four distinct clusters among 1,000 agents based on joint semantic and cross-contextual behavioral responses. We report normalized averages of the top-5 dominant behavioral motifs per cluster, capturing coordinated shifts in response intensity, isolation, and compliance across contexts, with signed values indicating motif direction and strength. See Appendix Section for detailed motif descriptions and interpretation. clustering on {Zj} yields refined clusters aligned by functional decision logic and behavioral similarity, even across topologically distant agents. See Fig. 2 for an overview. Stage 4: Boundary Optimization and Adaptation: Boundary agents near multiple cluster centroids are reassigned using motif-guided pull score pull(j, Ci) = cos(Pj, Di) conn(j, Ci), where conn(j, Ci) denotes the normalized fraction of agent js neighbors belonging to cluster Ci. ANCHOR merges behaviorally redundant clusters and splits heterogeneous ones based on motif divergence and entropy. Cluster quality is monitored via modularity, silhouette score, and motif coherence, which tracks the consistency of local interaction motifs within clusters across refinement steps; refinement is re-invoked upon degradation. See additional results and full algorithm in Section B. 3.3. Decoupled Population-to-Entity Simulation Using cluster-level transition hazards from Sec. 3.1, Entity Agents stochastically realize individual state transitions under local constraints. For an agent in cluster Ck occupying state at time t, the fused hazard λk ss(t) encodes the population-consistent transition tendency and serves as base rate. This hazard is modulated by agentspecific attributes and neighborhood interactions from the adjacency matrix A, yielding an individualized transition intensity λi ss(t) without additional LLM calls (at most one inference per cluster). Each agent samples its next state via competing-risk realization, xi(t + 1) Categorical({λi ss(t)}sSi {1}). The distribution is normalized, with the final mass corresponding to temporal persistence. Competing transitions (e.g., recovery vs. death) are treated as concurrent risks whose relative intensities determine the realized event, while temporal persistence corresponds to survival in the absence of any transition. This 5 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 1. Agent-level state transition evaluation across domains. Rolling-window evaluation with 7-day test windows. For each metric, in epidemiology, agent SEIRD predictions are evaluated against individual-level states inferred from Singapore MOH data; in finance, agent sentiment states are compared to daily S&P 500 market regimes as population-level signal; in social attention, predicted agent states are aggregated and evaluated against normalized daily Wiki pageviews. DeepProbLog excludes EETE as it predicts event types without explicit event-time distributions. Metric Mechanistic Pure Neural LLM-based Hybrid Ours Rule-ABM MF-Markov GNN-LSTM TGN LLM-Agent LLM-MAS DeepProbLog Rule-NN Epidemiology EETE 3.750.09 ET-F1 0.450.04 1.960.07 NLL 0.860.06 Brier 4.610.05 0.330.01 3.020.08 0.950. 4.350.04 0.490.09 2.810.05 0.780.03 3.250.03 0.590.05 1.720.04 0.680.02 3.950.06 0.570.07 1.880.09 0.820.06 3.370.07 0.620.09 1.270.10 0.650.07 N/A 0.510.05 2.110.05 0.900.03 1.920.05 5.120.03 0.810.01 0.240.04 19.040.08 0.730.03 0.160.01 0.960. Financial Contagion EETE 5.30.07 ET-F1 0.420.06 1.200.10 NLL 0.860.05 Brier 3.220.06 0.270.01 1.050.08 0.790.04 3.850.06 0.280.02 1.040.06 0.880.05 3.290.05 0.490.01 0.680.06 0.730.04 3.220.08 0.650.09 0.360.11 0.270. 2.730.09 0.710.11 0.290.12 0.290.09 N/A 0.560.07 1.080.07 0.690.05 3.310.05 0.540.05 0.820.06 0.550.03 2.350.04 0.760.04 0.490.04 0.220.02 EETE 3.870.06 ET-F1 0.480.09 1.950.04 NLL 0.640.03 Brier 3.410.09 0.290.01 1.870.06 0.810. 3.330.02 0.310.05 1.690.06 0.830.01 3.300.03 0.440.04 1.630.05 0.740.05 4.380.01 0.470.08 2.910.01 0.450.03 3.130.08 0.481.00 1.940.08 0.360.02 N/A 0.330.06 2.660.06 0.880.07 3.190.06 0.270.04 3.580.05 0.820. 2.480.02 0.640.09 0.590.03 0.120.07 Social Diffusion casting protocol to reflect realistic deployment and prevent temporal leakage. Each window uses 28-day lookback for training or calibration followed by 7-day forecast horizon, with models re-trained or re-calibrated at every step. Metrics are computed only on event-bearing trajectories within the forecast window, avoiding trivial gains from persistent terminal states. Evaluation emphasizes event timing, regime coherence, and calibration, rather than pointwise accuracy, testing whether models recover population-level dynamics such as emergence, propagation, and attenuation under partial observability and non-stationarity (e.g., policy shifts, market regime changes, viral events). We report both quantitative metrics and qualitative trajectory analyses. Initial states follow empirical first infection day state distributions for epidemiology (e.g., January 23, 2020 at S:991, E:8, I:1), with 1% minority-state initialization in other domains to reflect realistic early-phase conditions where rare-state emergence drives downstream dynamics. See appendix Sec. F. Evaluation Metrics: Standard pointwise metrics such as MAE or accuracy are insufficient for agent-based statetransition modeling, as they ignore event timing, collapse temporal uncertainty, and are dominated by persistent terminal states in long-horizon simulations (Gneiting & Raftery, 2007; Ovadia et al., 2019; Salinas et al., 2020). We therefore adopt four complementary event-time and event-type metrics covering temporal accuracy, discrimination, probabilistic fit, and calibration: (1) Expected Event Time Error (EETE), the absolute error between ground-truth and expected predicted event times (7-day reference); (2) EventType Macro-F1 (ET-F1), balanced classification across valid transition types (e.g., E, I, R/D); (3) Joint Event-Time Negative Log-Likelihood (NLL), penalizing low probability mass on realized outcomes; and (4) Event-Time Joint Brier Score (Brier), measuring calibration and sharpness. Metrics are computed on event-bearing states and averaged over rolling windows; lower is better for EETE, NLL, and Brier, and higher is better for ET-F1. 4.2. Results 4.2.1. ANCHOR CLUSTER INTERPRETATION ANCHOR identifies four behavioral control regimes in the Singapore COVID-19 simulation of 1,000 agents, defined by how agents reconfigure behavior across home, work, and community contexts. Figure 3 reports normalized scores of the five dominant contextual motifs per cluster. Naturallanguage motif interpretations for the shown 5 dominant motifs are provided in Appendix Table 4. Complementarily, cross-contextual behavioral fingerprints are shown in Appendix fig. 11. Stable Responders (Cluster 1) exhibit near-zero motif magnitudes with low variance, indicating smooth proportional adaptation and forming the behavioral inertia that largely determines the mean trajectory. Environment-Driven Responders (Cluster 2) show 6 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 4. SEIRD dynamics under rolling-window forecasting. Infection trajectories for 1,000-agent COVID-19 simulation comparing Rule-ABM, neural and LLM baselines with our model. weak intrinsic control and compressed motif distributions, reacting strongly to external contexts (e.g., workplace or community restrictions) with limited proactive mitigation. Self-Regulating Responders (Cluster 3) display strong, coherent motifs, actively suppressing contacts and increasing isolation and mask usage when transitioning between private and public contexts; despite their smaller population share, they disproportionately modulate transitions through context-aware control. Volatile Responders (Cluster 4) exhibit wide, mixed-sign motif distributions with high variance, reflecting unstable control policies in which small contextual shifts induce large, inconsistent behavioral changes and act as primary sources of epidemic uncertainty. None of the clusters is separable by age, static behavior, or contact structure alone. Instead, ANCHOR identifies functional equivalence classes defined by contextual control logic, yielding mechanistic view of population dynamics beyond demographics or network position. See additional results and interpretations in Appendix Sec. B. 4.2.2. QUANTITATIVE EVALUATION Table 1 reports state-transition performance across epidemiology, finance, and social diffusion. PhysicsAgentABM achieves the best results across all four metrics: EETE, ETF1, NLL, and Brier in every domain, indicating superior temporal accuracy, event discrimination, and calibration. Mechanistic baselines underperform due to rigid rules under non-stationarity, while pure neural and LLM-based models attain competitive ET-F1 but exhibit higher temporal error and weaker calibration. Hybrid approaches without explicit uncertainty modeling show unstable performance. Overall, PhysicsAgentABM delivers robust, well-calibrated performance across domains, highlighting the benefits of hierarchical abstraction and uncertainty-aware fusion. 4.2.3. QUALITATIVE EVALUATION COVID-19 Dynamics: Figure 4 illustrates epidemiological forecasting under rolling-window evaluation. PhysicsAgentABM closely tracks the ground-truth epidemic trajectory across repeated traintest resets, capturing pre-peak acceleration, aligning with the late-March infection peak, and rapidly adapting to the post-Circuit Breaker decline. In contrast, Rule-ABM fails to reproduce peak sharpness due to its inability to model behavioral heterogeneity and network effects, GNN-LSTM overshoots recovery and exhibits miscalibrated uncertainty, and LLM-MAS shows improved peak alignment but degrades over longer horizons due to temporal inconsistency. These improvements arise from hierarchical division of labor across clustered agents. Tool-grounded symbolic reasoning enforces policy and contact-driven constraints during regime shifts, while neural predictors capture intra-cluster heterogeneity and temporal momentum during steady transmission. Epistemic fusion adaptively reweights these signals over rolling windows, enabling stable yet responsive forecasts. PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 5. Population-level market belief dynamics inferred by the agent ecosystem. (A) Probability mass assigned to the realized market sentiment regime (S&P 500) over time. Daily belief estimates fluctuate with market volatility(light blue line), while the 7-day moving average reveals stable, coherent belief trajectory. Compared to rule-based ABM, our model maintains higher and more persistent alignment with realized regimes, indicating superior collective belief formation under uncertainty. (B) Our model recovers balanced regime distribution consistent with the realized market structure, while the rule-based ABM exhibits regime bias. Market Sentiment Diffusion: We evaluate whether our ecosystem of agents can form coherent, uncertainty-aware beliefs about investment market regimes from weak, indirect signals, thereby developing an intuitive basis for anticipating market direction. Because individual sentiment is unobservable, inference relies on population-level daily S&P 500 index values as macro proxy, aligning agent states with realized market regimes (e.g., Bullish/Bearish). Under this framing, PhysicsAgentABM outperforms all baselines in temporal alignment, regime detection, and calibration  (Table 1)  . Figure 5A shows that the model assigns elevated but realistic probability mass (6075%) to the realized daily regime, exceeding random baseline while correctly reducing confidence during volatile periods (e.g., the October 2024 VIX spike). Despite short-term fluctuations, weekly averages remain smooth and aligned, indicating stable population-level belief formation. Figure 5B further shows close agreement with the empirical regime distribution, capturing neutral-dominant phases and sustained bearish shifts during drawdowns, whereas rule-based ABMs overrepresent bearish regimes and neural models exhibit regime imbalance. These gains arise from decoupling signal volatility from belief formation: symbolic reasoning interprets macro events, neural predictors capture temporal trends, and epistemic fusion suppresses transient noise. Attention Lifecycle: We analyze the US population-level attention to high-salience topic (Climate Change) over 90-day horizon (Dec 1, 2024 Feb 28, 2025), modeling attention dynamics through three latent states: Unaware, InFigure 6. Attention plot of interested people. We evaluate attention diffusion using rolling-window forecasting protocol, training on 28 days of historical data and predicting attention over the subsequent 7 days. Ground-truth attention is obtained from normalized daily Wikipedia pageviews, while model outputs are continuous probabilistic attention estimates. terested, and Fatigued. Because individual-level attention states are unobservable, we use normalized daily Wikipedia pageviews (attention index) as noisy macro-level observation signal. As shown in Fig. 6, the observed pageview trajectory exhibits sharp, high-variance fluctuations driven by discrete exogenous events; most notably the LA wildfires in early January and COP28-related announcements in late January, followed by rapid decay as media salience subsides. Using small population of 250 agents, PHYSICSAGENTABM infers smooth latent attention trajectory that integrates these observations over time, capturing the underlying evolution of public attention span rather than 8 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling reacting to individual spikes. The inferred trajectory follows characteristic S-shaped diffusion pattern (Orr, 2003; Qiu et al., 2018), with gradual emergence in early December, sustained amplification through mid-to-late January as repeated events reinforce salience, and fatigue-driven decline through February. This behavior reflects the modeling objective of recovering coherent population attention regimes instead of reproducing platform-level volatility that conflates transient exposure with persistent engagement. The inferred peak aligns temporally with the window of elevated activity while remaining stable in the face of short-lived perturbations, and the post-peak phase exhibits smooth disengagement rather than erratic drop-off. Quantitatively, this regime-level inference achieves strong temporal alignment and calibration in social diffusion, yielding lower EETE (2.48) and Brier score (0.12) than all evaluated baselines  (Table 1)  . 4.3. Case Study: Singapore COVID-19 Circuit Breaker Figure 7. Epistemic fusion dynamics during the Singapore Circuit Breaker. At policy onset (April 3), symbolic inference is upweighted with transient entropy spike, followed by rebalancing as dynamics stabilize. We evaluate PhysicsAgentABM under Singapores Circuit Breaker, an abrupt policy shock announced April 3, enforced April 7, 2020, using =1000 agents. Before intervention, the model tracks exponential growth and predicts the infection peak within three days of the observed maximum  (Fig. 10)  . At policy onset, transitions are sharply suppressed, infections decline, and recoveries accelerate, closely matching ground truth, while neural and LLM baselines overshoot due to temporal inertia. PhysicsAgentABM preserves micro-heterogeneity under lockdown, capturing residual dormitory transmission and intensified household spread. As shown in Fig. 7, epistemic fusion rapidly upweights symbolic inference (λsym) at the shock, enabling immediate incorporation of exogenous constraints and controlled rise in predictive entropy, reflecting regime uncertainty. It then rebalances toward neural prediction as dynamics stabilize, yielding calibrated uncertainty contraction and linear recovery. This adaptive rebalancing produces immediate trajectory reversal and strong calibration gains (Brier = 0.16, 76% reduction vs. LLM baselines) with improved temporal alignment and event detection  (Table 1)  . See Appendix Sec. for additional discussion. 5. Cost and Scalability Analysis We analyze the cost and scalability of PHYSICSAGENTABM in terms of token usage, API calls, and wallclock time on single A100 GPU with 50 asynchronous API calls  (Table 2)  . Unlike flat LLM-based GABMs that invoke high-context reasoning independently for every agent at every timestep, PHYSICSAGENTABM centralizes symbolic inference at the cluster level and sparsifies agent-level LLM usage, substantially reducing cost and latency while preserving heterogeneity and predictive fidelity. Experiments are conducted on epidemiological dynamics with =1000 agents partitioned into =4 clusters, each coordinated by 5 STATEAGENTS and one METAAGENT. Let α (0, 1] denote the fraction of agents invoking lightweight LLM reasoning per timestep (e.g., for rare or ambiguous transitions such as E); all other agents realize transitions via fused cluster-level hazards, neighborhood states from the adjacency matrix A, and local short-term memory. At most, an agent issues one additional LLM call for text generation. Relative to flat GABM baseline, API calls drop from 8,250 to 1,233 (6.7). Total token usage decreases from 2.3M tokens per timestep to 0.79M at α=1.0 and 0.49M at α=0.6, corresponding to 2.9 and 4.7 reductions. Under GPT4o-mini pricing, per-timestep cost falls from $0.48 to $0.23 and $0.14 (2.13.4 savings). Wall-clock runtime similarly decreases from 300 to 40 and 24 per timestep, yielding 7.512.5 speedups. Predictive performance is unaffected, with ET-F1 fixed at 0.81 across all α values. Table 2. Per-timestep cost, performance and scalability metrics comparing flat GABM baseline and PHYSICSAGENTABM under varying α . Metric (/timestep) Flat GABM PhysicsAgentABM α=1.0 α=0.75 α=0.6 API calls Prompt tokens Completion tokens Total tokens WCT (s) Total WCT (mins) ET-F1 8,250 2,000,000 300,000 2,300,000 300 500 0.62 833 1,083 540,000 415,000 340,000 250,000 187,500 150,000 790,000 602,500 490,000 30 50 0.81 40 66 0.81 24 40 0.81 Figure 8 shows scaling behavior with increasing population size. ET-F1 remains stable or improves slightly as grows, reflecting more reliable cluster-level statistics without oversmoothing or loss of behavioral diversity. Per-timestep cost and latency scale near linearly with , confirming that symbolic reasoning cost is governed by the number of clusters rather than agents. These results validate the central design principle of PHYSICSAGENTABM: expensive reasoning is 9 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling amortized at the population level, while individual realization remains lightweight and parallelizable. Figure 8. Cost, latency, and performance scaling with population size. (a) ET-F1 remains stable or improves slightly as the number of agents increases, reflecting more reliable cluster-level transition performance without loss of behavioral heterogeneity. (b) Per-timestep cost and latency scale near linearly with , as symbolic reasoning is amortized at the cluster level while agentlevel realization remains lightweight and parallelizable. 5.1. Ablation PhysicsAgentABM Architecture: We ablate architectural components on the largest epidemiological setting (1,000 agents) under fixed protocol. Removing clustering collapses population-level coordination, forcing agentlevel reasoning that causes severe temporal misalignment and prohibitive latency  (Table 3)  . Disabling epistemic fusion reveals complementary failures: neural-only variants are overconfident and delayed, while symbolic-only variants preserve structure but break under regime shifts. Within the symbolic pathway, removing state specialization or meta-coordination degrades performance at similar efficiency, confirming the necessity of role separation. With all components enabled, PhysicsAgentABM achieves calibrated, temporally aligned transitions with near-linear performanceefficiency scaling via cluster-level inference (See Appendix section C). ANCHOR Component Analysis: We ablate ANCHOR under the same epidemiological setting to isolate failure modes in abstraction quality  (Fig. 9)  . Removing behavioral motifs or contrastive cross-context alignment collapses clusters toward configuration-driven centroids, yielding high apparent structural separability but substantially degraded behavioral coherence. Structure-only variants preserve modularity yet fail to group agents by functional response, producing brittle abstractions that break under context shifts. Disabling boundary optimization further fragments clusters near regime transitions, indicating sensitivity to ambiguous state boundaries. In contrast, the full ANCHOR model is Pareto-dominant, jointly optimizing clustering separability, structural coherence, and contextual behavioral similarity. Furthermore, ANCHOR separates agents based on contextdependent behavioral response patterns rather than static 11, clusters structures. As shown in Appendix Fig. 10 Figure 9. Multi-objective ablation of ANCHOR. Each point represents an ablation configuration evaluated by clustering separability (silhouette), structural coherence (modularity), and behavioral motif coherence. Marker size and color encode anchor-agent representativeness. The full ANCHOR model lies on the Pareto frontier, while variants removing motifs, contrastive alignment, or boundary optimization are systematically dominated. Table 3. PhysicsAgentABM architecture ablation. Configuration Fusion Neural-only Symbolic-only Naive fusion No clustering Flat agents Symbolic Team No state-agent No meta-agent EETE F1 NLL Brier Latency (s/step) 3.15 2.98 2.71 0.62 0.66 0.69 0.96 0.88 0.82 0.31 0.27 0.25 0.6 35.8 36.1 4. 0.63 1.21 0.39 283 2.64 2.81 0.61 0. 0.79 0.83 0.23 0.26 268.4 135.2 PhysicsAgentABM 1.92 0.81 0. 0.16 41.1 found by ANCHOR exhibit internally consistent yet nonlinearly reweighted behavior across home, work, and community contexts, enabling stable abstraction under policy and regime shifts. 6. Conclusion We introduce PhysicsAgentABM, principled framework that shifts generative ABM from isolated agent simulation to population-level inference, together with ANCHOR, contextual behavior-driven clustering mechanism guided by an LLM agent. Across diverse domains, PhysicsAgentABM consistently yields calibrated, temporally aligned dynamics while preserving heterogeneous individual realization. We believe this work establishes system-level foundation for generative simulation under real-world complexity. PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling"
        },
        {
            "title": "References",
            "content": "Large language models empower agent-based modeling. arXiv, 2023. Agent-based modelling meets generative ai in social network simulations. arXiv, 2024. Generative agent simulations of 1,000 people. arXiv, 2024. On the limits of agency in agent-based models. arXiv, 2024. Can large language model agents simulate human trust behavior? arXiv, 2024. Agentsociety: Large-scale simulation of llm-driven generative agents. arXiv, 2025. Socioverse: Large-scale social simulation with llm agents. arXiv, 2025. Andrews, R., Diederich, J., and Tickle, A. B. Survey and critique of techniques for extracting rules from trained artificial neural networks. Knowledge-based systems, 8 (6):373389, 1995. Baltruˇsaitis, T., Ahuja, C., and Morency, L.-P. Multimodal machine learning: survey and taxonomy. IEEE transactions on pattern analysis and machine intelligence, 41 (2):423443, 2018. Battaglia, P. W., Hamrick, J. B., Bapst, V., SanchezGonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018. Billio, M., Getmansky, M., Lo, A. W., and Pelizzon, L. Econometric measures of connectedness and systemic risk in the finance and insurance sectors. Journal of financial economics, 104(3):535559, 2012. Block, P., Hoffman, M., Raabe, I. J., Dowd, J. B., Rahal, C., Kashyap, R., and Mills, M. C. Social network-based distancing strategies to flatten the covid-19 curve in post-lockdown world. Nature human behaviour, 4(6): 588596, 2020. Blondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment, 2008(10):P10008, 2008. Bonabeau, E. Agent-based modeling: Methods and techniques for simulating human systems. Proceedings of the national academy of sciences, 99(suppl 3):72807287, 2002. Centola, D. How behavior spreads: The science of complex contagions, volume 3. Princeton University Press Princeton, NJ, 2018. Chang, S., Pierson, E., Koh, P. W., Gerardin, J., Redbird, B., Grusky, D., and Leskovec, J. Mobility network models of covid-19 explain inequities and inform reopening. Nature, 589(7840):8287, 2021. Deng, S., Wang, S., Rangwala, H., Wang, L., and Ning, Y. Cola-gnn: Cross-location attention based graph neural networks for long-term ili prediction. In Proceedings of the 29th ACM international conference on information & knowledge management, pp. 245254, 2020. Diebold, F. X. and Yılmaz, K. On the network topology of variance decompositions: Measuring the connectedness of financial firms. Journal of econometrics, 182(1):119 134, 2014. Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mordatch, I. Improving factuality and reasoning in language models through multiagent debate. In Forty-first International Conference on Machine Learning, 2023. Epstein, J. M. Generative social science: Studies in agentIn Generative Social based computational modeling. Science. Princeton University Press, 2012. Fang, Z., Long, Q., Song, G., and Xie, K. Spatial-temporal graph ode networks for traffic flow forecasting. In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pp. 364373, 2021. Fortuin, V. and Ratsch, G. Deep mean functions for meta-learning in gaussian processes. arXiv preprint arXiv:1901.08098, 8, 2019. Gai, P. and Kapadia, S. Contagion in financial networks. Proceedings of the Royal Society A, 2010. Gao, D., Li, Z., Pan, X., Kuang, W., Ma, Z., Qian, B., Wei, F., Zhang, W., Xie, Y., Chen, D., et al. Agentscope: flexible yet robust multi-agent platform. arXiv preprint arXiv:2402.14034, 2024. Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. B. Bayesian data analysis. Chapman and Hall/CRC, 1995. Gillespie, D. T. Exact stochastic simulation of coupled chemical reactions. The journal of physical chemistry, 81 (25):23402361, 1977. Gneiting, T. and Raftery, A. E. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359378, 2007. Granovetter, M. Threshold models of collective behavior. American journal of sociology, 83(6):14201443, 1978. PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., Wiest, O., and Zhang, X. Large language model based multi-agents: survey of progress and challenges. In IJCAI, 2024. Lowe, R., Wu, Y. I., Tamar, A., Harb, J., Pieter Abbeel, O., and Mordatch, I. Multi-agent actor-critic for mixed cooperative-competitive environments. Advances in neural information processing systems, 30, 2017. Hamilton, W. L. et al. Inductive representation learning on large graphs. NeurIPS, 2017. Hethcote, H. W. The mathematics of infectious diseases. SIAM review, 42(4):599653, 2000. Hochreiter, S. and Schmidhuber, J. Long short-term memory. Neural computation, 9(8):17351780, 1997. Hong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., et al. Metagpt: Meta programming for multi-agent collaborative framework. In The twelfth international conference on learning representations, 2023. Huang, W., Abbeel, P., Pathak, D., and Mordatch, I. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International conference on machine learning, pp. 91189147. PMLR, 2022. Hullermeier, E. and Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine learning, 110(3):457506, 2021. Hurd, T. R. et al. Contagion! Systemic risk in financial networks, volume 42. Springer, 2016. Kempe, D., Kleinberg, J., and Tardos, E. Maximizing the spread of influence through social network. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 137146, 2003. Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R. Neural relational inference for interacting systems. In International conference on machine learning, pp. 2688 2697. Pmlr, 2018. Kipf, T. N. and Welling, M. Semi-supervised classification with graph convolutional networks. ICLR, 2017. Krishnan, R. et al. Structured inference networks for nonlinear state space models. AAAI, 2017. Li, G., Hammoud, H., Itani, H., Khizbullin, D., and Ghanem, B. Camel: Communicative agents for mind exploration of large language model society. Advances in Neural Information Processing Systems, 36:5199152008, 2023. Loukas, A. Graph reduction via spectral sparsification. JMLR, 2019. Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T., and De Raedt, L. Deepproblog: Neural probabilistic logic programming. Advances in neural information processing systems, 31, 2018. Mathieu, E., Ritchie, H., Rodes-Guirao, L., Appel, C., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Dattani, S., Beltekian, D., Ortiz-Ospina, E., and Roser, M. Covid-19 pandemic. Our World in Data, 2020. https://ourworldindata.org/coronavirus. McKean Jr, H. P. class of markov processes associated with nonlinear parabolic equations. Proceedings of the National Academy of Sciences, 56(6):19071911, 1966. Mou, X., Wei, Z., and Huang, X.-J. Unveiling the truth and facilitating change: Towards agent-based large-scale social movement simulation. In Findings of the Association for Computational Linguistics: ACL 2024, pp. 47894809, 2024. Murphy, K. P. Machine Learning: Probabilistic Perspective. MIT Press, 2012. Newman, M. E. Modularity and community structure in networks. Proceedings of the national academy of sciences, 103(23):85778582, 2006. Orr, G. Diffusion of innovations, by everett rogers (1995). Retrieved January, 21:2005, 2003. Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon, J., Lakshminarayanan, B., and Snoek, J. Can you trust your models uncertainty? evaluating predictive uncertainty under dataset shift. Advances in neural information processing systems, 32, 2019. Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., and Wu, X. Unifying large language models and knowledge graphs: roadmap. IEEE Transactions on Knowledge and Data Engineering, 36(7):35803599, 2024. Park, J. S., OBrien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pp. 122, 2023. Pastor-Satorras, R., Castellano, C., Van Mieghem, P., and Vespignani, A. Epidemic processes in complex networks. Reviews of modern physics, 87(3):925979, 2015. 12 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Watts, D. J. simple model of global cascades on random networks. Proceedings of the National Academy of Sciences, 99(9):57665771, 2002. Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., et al. Autogen: Enabling next-gen llm applications via multi-agent conversations. In First Conference on Language Modeling, 2024. Xiang, S., Cheng, D., Shang, C., Zhang, Y., and Liang, Y. Temporal and heterogeneous graph neural network for financial time series prediction. In Proceedings of the 31st ACM international conference on information & knowledge management, pp. 35843593, 2022. Xu, W., Liu, W., Wang, L., Xia, Y., Bian, J., Yin, J., and Liu, T.-Y. Hist: graph-based framework for stock trend forecasting via mining concept-oriented shared information. arXiv preprint arXiv:2110.13716, 2021. Yang, T., Jin, R., Chi, Y., and Zhu, S. Combining link and content for community detection: discriminative In Proceedings of the 15th ACM SIGKDD approach. international conference on Knowledge discovery and data mining, pp. 927936, 2009. Ye, R., Zhang, C., Wang, R., Xu, S., and Zhang, Y. Language is all graph needs. In Findings of the association for computational linguistics: EACL 2024, pp. 1955 1973, 2024. Yi, K., Wu, J., Gan, C., Torralba, A., Kohli, P., and Tenenbaum, J. Neural-symbolic vqa: Disentangling reasoning from vision and language understanding. Advances in neural information processing systems, 31, 2018. Ying, Z., You, J., Morris, C., Ren, X., Hamilton, W., and Leskovec, J. Hierarchical graph representation learning with differentiable pooling. Advances in neural information processing systems, 31, 2018. Zhu, X., Chen, Y., Tian, H., Tao, C., Su, W., Yang, C., Huang, G., Li, B., Lu, L., Wang, X., et al. Ghost in the minecraft: Generally capable agents for openworld environments via large language models with arXiv preprint text-based knowledge and memory. arXiv:2305.17144, 2023. Qian, C., Liu, W., Liu, H., Chen, N., Dang, Y., Li, J., Yang, C., Chen, W., Su, Y., Cong, X., et al. Chatdev: Communicative agents for software development. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1517415186, 2024. Qiu, J., Tang, J., Ma, H., Dong, Y., Wang, K., and Tang, J. Deepinf: Social influence prediction with deep learning. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 21102119, 2018. Rossi, E., Chamberlain, B., Frasca, F., Eynard, D., Monti, F., and Bronstein, M. Temporal graph networks for arXiv preprint deep learning on dynamic graphs. arXiv:2006.10637, 2020. Salinas, D., Flunkert, V., Gasthaus, J., and Januschowski, T. Deepar: Probabilistic forecasting with autoregressive recurrent networks. International journal of forecasting, 36(3):11811191, 2020. Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. The graph neural network model. IEEE transactions on neural networks, 20(1):6180, 2008. Schaeffer, S. E. Graph Clustering. Computer Science Review, 2007. ter Hoeven, E., Kwakkel, J., Hess, V., Pike, T., Wang, B., rht, and Kazil, J. Mesa 3: Agent-based modeling with python in 2025. Journal of Open Source Software, 10(107): 7668, 2025. doi: 10.21105/joss.07668. URL https: //doi.org/10.21105/joss.07668. Tran, D., Ranganath, R., and Blei, D. Hierarchical implicit models and likelihood-free variational inference. Advances in Neural Information Processing Systems, 30, 2017. Veliˇckovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., and Bengio, Y. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017. Von Luxburg, U. tutorial on spectral clustering. Statistics and computing, 17(4):395416, 2007. Wang, L., Xu, W., Lan, Y., Hu, Z., Lan, Y., Lee, R. K.-W., and Lim, E.-P. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:2305.04091, 2023. Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et al. survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345, 2024. 13 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling"
        },
        {
            "title": "Table of Contents",
            "content": "A Additional Details on Singapore COVID-19 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 Additional Details on ANCHOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 B.1 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 B.2 Additional Ablations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 Top 5 Dominant Motifs Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 B.3 PhysicsAgentABM Calibration Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 Symbolic Reasoning Pathway . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 D.1 MetaAgent Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 StateAgent Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 D.2 EntityAgent Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 D.3 Symbolic Agentic Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 D.4 Neural Multimodal Pathway . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 E.1 Details on Multimodal Data Across the Three Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 E.2 Neural Model Architectural Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 Training Configuration and Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 E.3 Experimental Setup & Design Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 F.1 Task Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 F.2 Dataset Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 Population & Network Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 F.3 Latent State and Ground Truth Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 F.4 A. Additional Details on Singapore COVID-19 Case Study: Figure 10. Infected and recovered dynamics under Singapores Circuit Breaker. SEIRD trajectories under rolling-window forecasting for 1,000-agent COVID-19 simulation. Following Circuit Breaker enforcement (early April), PHYSICSAGENTABM produces tightly coupled decline in infections and accelerated recovery that closely tracks ground truth. Neural and LLM-based baselines exhibit delayed or inconsistent recovery accumulation despite reduced infections, while rule-based ABMs underestimate post-intervention recovery rates. Shaded regions denote 95% predictive intervals; vertical dashed lines indicate rolling-window resets. 14 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling i=1 SPECTRALCLUSTER(G, Y) Algorithm 2 ANCHOR: First Agent-Guided Clustering Input: Interaction graph = (V, E), agent attributes X, diagnostic scenarios S, number of coarse clusters Kcoarse, temperature τ , merge/split thresholds θmerge, θsplit Output: Final clusters C, anchor agents 1: Stage 1: StructuralSemantic Initialization 2: GRAPHSAGE(G, X) 3: [HX] 4: {Ci}Kcoarse 5: Stage 2: Behavioral Motif Discovery 6: for each cluster Ci do 7: 8: 9: Ri REASONENC(Ti) 10: Mi CLUSTER(Ri) 11: Pj motif profile of agent 12: Di 1 Ci 13: end for 14: Stage 3: Anchor-Guided Contrastive Refinement 15: for each cluster Ci do 16: 17: end for 18: (j) [HjPjctxj] 19: Optimize Execute scenarios on agents in Ci Collect reasoningaction traces Ti ai arg minjCi Pj Di2 jCi Pj (cid:80) min (cid:88) log exp(sim(f (j), (aj))/τ ) exp(sim(f (j), (ak))/τ ) (cid:80) 20: Stage 4: Hybrid Fusion and Boundary Optimization 21: Learn (α, β, γ) such that α + β + γ = 1 22: Zj αHj + βf (j) + γPj 23: HIERCLUSTER({Zj}) 24: for each boundary agent do 25: 26: end for 27: Merge clusters if JS(Di, Dj) < θmerge 28: Split clusters if H(Pi) > θsplit 29: return C, arg maxi cos(Pj, Di) conn(j, Ci) Figure 10 shows that Singapores Circuit Breaker induces coherent post-intervention regime in which rapid suppression of transmission is immediately accompanied by accelerated recovery. After enforcement in early April, PHYSICSAGENTABM captures the growth-to-decay transition in infections together with steeper, monotone rise in recoveries that remains temporally aligned with ground truth, indicating an elevated effective hazard rather than infection decline alone. Neural and LLM-based baselines exhibit recovery inertia, with weak or delayed coupling between declining infections and recovery accumulation, while rule-based ABMs underestimate post-intervention recovery acceleration. PHYSICSAGENTABM uniquely preserves compartmental coherence, declining infections with compensatory recovery growth under calibrated uncertainty during the stabilized post-lockdown phase. B. Additional Details on ANCHOR In this section, we provide additional details on ANCHOR, including the complete four-stage algorithmic pipeline and per-stage breakdown of its abstraction and refinement process. B.1. Algorithm Algorithm 2 details the complete four-stage ANCHOR clustering pipeline, consisting of (i) structural coarse clustering, (ii) behavioral motif extraction, (iii) semantic separation across contexts, and (iv) agent-driven contrastive cross-contextual behavioral clustering using novel loss function that encodes the soft judgments of the ANCHOR agent. 15 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling B.2. Additional Ablations Figure 11. Contextual behavioral signatures learned by ANCHOR. Radar plots show cluster-level behavioral profiles across home, work, and community contexts. Each cluster exhibits distinct pattern of response speed, volatility, avoidance, isolation, compliance sensitivity, and social reactivity, with systematic reweighting across contexts. These consistent yet non-uniform signatures demonstrate ANCHORs ability to disentangle context-dependent adaptation behaviors beyond structural connectivity alone. Figure 11 reveals how ANCHOR uncovers context-dependent behavioral structure that is invisible to purely structural clustering. Each cluster exhibits distinct modulation profile across home, work, and community contexts, indicating that agent behavior is not governed by static traits but by systematic context-sensitive response patterns. For example, clusters with comparable response speed at home diverge sharply under workplace compliance sensitivity and community isolation tendency, reflecting differentiated adaptation mechanisms rather than noise. Crucially, these patterns are internally consistent within clusters yet nonlinearly reweighted across contexts, validating ANCHORs design goal of separating agents by how they adapt rather than where they are embedded. This cross-context behavioral disentanglement enables stable abstraction under policy shifts and downstream regime changes, which is not achievable with structure-only or single-context representations. Figure 12 illustrates the progressive abstraction induced by ANCHOR. Initial graph-based clusters (Stage 1) reflect structural proximity but mix heterogeneous behaviors, while motif discovery (Stage 2) exposes latent response patterns without enforcing separation. Anchor-guided contrastive refinement (Stage 3) sharpens semantic alignment, yielding compact, well-separated clusters in the final hybrid embedding space (Stage 4) that correspond to distinct epidemiological transition regimes. C. PhysicsAgentABM Calibration Analysis Figure 13 highlights the calibration behavior that emerges from PHYSICSAGENTABMs hierarchical and uncertaintyaware design. By decoupling symbolic regime inference at the cluster level from neural realization at the agent level, the model avoids overconfident instance-level predictions under noisy or shifting dynamics. Epistemic fusion adaptively reallocates weight toward symbolic reasoning when regime uncertainty is high, yielding predictive confidences that contract and expand in proportion to available evidence. Crucially, the symbolic pathways flexibility, while potentially biased or underconstrained in isolation is grounded by neural prediction, whereas the symbolic agents compensate when learned neural patterns are insufficient to capture unseen regimes, policy shocks, or exogenous events. This complementary interaction produces near-diagonal reliability curves with consistently low ECE and Brier scores across epidemiology, finance, and social diffusion, indicating robust probabilistic reliability rather than coincidental calibration. Observed calibration variability across domains reflects differences in signal-to-noise structure and regime persistence: epidemiology exhibits smoother, longer-horizon transitions, yielding near-ideal calibration, while finance and social diffusion 16 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 12. ANCHOR stage-wise clustering dynamics for epidemiological simulation (N =1000). UMAP visualizations show the evolution from coarse graph-structured groupings (Stage 1) to latent behavioral motifs (Stage 2), anchor-guided contrastive refinement (Stage 3), and final hybrid clustering (Stage 4). The final stage produces compact, well-separated clusters aligned with distinct epidemiological state-transition regimes, enabling stable cluster-level inference and calibrated top-down propagation. involve faster regime turnover and higher exogenous noise, naturally increasing dispersion without inducing systematic overconfidence. Importantly, PHYSICSAGENTABM preserves monotonic reliability across all domains, indicating stable uncertainty ranking even when absolute calibration tightness varies. D. Symbolic Reasoning Pathway Our symbolic pathway is designed to produce an interpretable, cluster-level estimate of transition hazards (and their uncertainty) from dynamic textual context such as individual data, regime policies, news and domain-specific dynamic rules. In this section, we provide the prompts used in our symbolic reasoning module for the MetaAgent, StateAgent and the EntityAgent. The roles of each agent type and tools used by them across the three domains are provides in Table 5. The prompts for the MetaAgent, StateAgent and EntityAgent can be found in the same order here (D, D, D). PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 4. Top 5 dominant contextual behavioral Motifs and epidemiological control interpretation discovered by ANCHOR. The five motifs shown in the main paper figure 3 capture distinct mechanisms by which agents reconfigure behavior across diverse situations (new policy announcement, mobility restrictions, vaccinations etc.) and contexts (home, work, and community contexts). Motif Code Context Contrast Behavioral Control Mechanism Epidemiological Interpretation DELTA CONTACT WC Work Community (absolute) Change in total contact suppression between structured and unstructured environments Encodes selective distancing behavior. High magnitude indicates agents who sharply reduce discretionary contacts while maintaining structured interactions. DELTA ADJUSTMENT HW Home Work (absolute) Change in overall behavioral adjustment intensity across private and occupational roles Captures sensitivity to workplace mandates (closures, PPE). Strong values reflect compliance with formal policy instruments. GATE RESPONSE WC Work Community (gated) Threshold-based activation of response behavior across public contexts Represents discrete policy-triggered behavior. High gating indicates agents acting primarily after explicit signals, creating sharp transmission shifts. DELTA RESPONSE HC RELATIVE RESPONSE HC Home Community (absolute) Home Community (relative) Change in raw response intensity between private and public exposure Measures escalation of protective behavior in public. Strong values correspond to risk-aware agents suppressing early transitions. Proportional response change relative to the agents baseline Distinguishes self-regulation from scale effects. High relative response identifies agents who internalize risk signals proactively. Figure 13. Reliability diagrams across domains. Reliability diagrams compare predicted confidence against empirical event correctness for epidemiology, finance, and social diffusion. Near-diagonal alignment indicates well-calibrated uncertainty, while low expected calibration error (ECE) and Brier scores (inset) reflect robust probabilistic reliability under domain-specific noise and regime shifts. 18 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 5. Symbolic Reasoning Pathway: Agent Architecture and Tools (All Domains). Each domain employs hierarchical symbolic agent system with one MetaAgent per cluster and multiple StateAgents interacting via structured tool calls. *Listed tools are representative examples, not an exhaustive enumeration. Component Epidemiology Finance Social Sciences Agents Latent states Ground truth Supervision Role Primary inputs Representative tools Output Agents Reasoning focus Representative tools Shared tools Model Temperature Max tokens Sampling Population and States 1,000 agents, 4 clusters S, E, I, R, moh case timelines moh dates to seird() 100 traders, 5 clusters bearish, bullish, neutral sp500 daily indices returns to sentiment() MetaAgent (1 per cluster) Epidemic regime coordination get cluster history() get policy timeline() get neighbor clusters() get external signals() estimate reffective() classify epidemic phase() regime summary() Market regime coordination get cluster sentiment() get macro calendar() get correlation signals() classify market regime() compute volatility tier() compute momentum() regime summary() StateAgents (one per latent state) agent, agent, agent, agent, agent Outgoing state transition estimation calculate exposure risk() get incubation progression() calculate recovery prob() calculate mortality risk() calculate immunity waning() get cluster snapshot() get neighbor state counts() calculate base transition rate() bearish agent, bullish agent, neutral agent Sentiment transition estimation detect panic signals() detect momentum exhaustion() calculate mean reversion() evaluate macro events() calculate sector rotation() get cluster snapshot() get correlated sentiment() calculate base transition rate() LLM Configuration 250 users, 3 clusters unaware, interested, fatigued wikipedia pageviews pageviews to attention() Attention regime coordination get attention history() get event calendar() get social signals() classify attention phase() compute virality() compute novelty() regime summary() unaware agent, interested agent, fatigued agent Attention transition estimation calculate virality score() calculate engagement depth() detect fatigue onset() detect novelty shock() get cluster snapshot() get neighbor attention() calculate base transition rate() GPT-4o-mini GPT-4o-mini MetaAgent 0.2 / StateAgents 0.4 MetaAgent 0.3 / StateAgents 0.5 MetaAgent 1500 / StateAgents 800 MetaAgent 1200 / StateAgents 600 MetaAgent 1200 / StateAgents 600 top p=0.85, freq penalty=0.0 GPT-4o-mini MetaAgent 0.3 / StateAgents 0.5 top p=0.9, freq penalty=0.1 top p=0.9, freq penalty=0. 19 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Meta-Agent System Prompt You are Meta-Agent operating within Generative Agent-Based Model (GABM). You represent cluster-level latent inference process that models how population-level state dynamics evolve under uncertainty. Configuration (Injected at Runtime). Domain name: {DOMAIN NAME}. Domain description: {DOMAIN DESCRIPTION}. Latent state set: {STATE SET}. Admissible state transitions: {TRANSITION SET}. Domain rules and priors: {DOMAIN RULES}. Cluster identifier: {CLUSTER ID}. Number of entity agents in cluster: {CLUSTER SIZE}. Neighbor clusters: {NEIGHBOR CLUSTER IDS}. External context signals:{EXTERNAL CONTEXT}. Role and Function. Your function is to serve as cluster-level epistemic layer that observes the evolving distribution of entity agents across latent states, integrates domain rules, historical memory, and cross-cluster context, infers stochastic transition hazards governing population dynamics, and elicits parallel transition probability estimates from specialized State Agents. State Agent Interaction. For each admissible transition in {TRANSITION SET}, corresponding State Agent exists. At every timestep {CURRENT TIMESTEP}: Request transition probability estimates from all relevant State Agents in parallel. Query multiple transitions originating from the same state independently. Do not enforce mutual exclusivity or normalization unless explicitly specified in {DOMAIN RULES}. Cluster Monitoring and Structure. At each timestep: 1. Observe the distribution of entity agents across {STATE SET}. 2. Treat observed counts as noisy realizations of latent population variables. 3. Identify salient structural patterns (e.g., state concentration or depletion, regime shifts, precursordownstream imbalance, high-risk subpopulations). 4. Infer cluster structural type using agent attributes and current state composition only. Inter-Cluster Coupling. Incorporate summarized signals from Meta-Agents of {NEIGHBOR CLUSTER IDS} as soft coupling signals that may modulate transition hazards, signal spillover risk, or indicate cross-cluster diffusion. Do not assume deterministic causality unless specified in {DOMAIN RULES}. Temporal and Causal Integrity. Condition only on information available up to timestep {CURRENT TIMESTEP}. Do not use future observations, labels, or outcomes. Access historical information exclusively through compressed memory summaries. Uncertainty and Calibration. All outputs are probabilistic. Preserve uncertainty or confidence measures returned by State Agents, avoid deterministic language, and ground explanations in domain rules and observed dynamics. Output Requirements. At each timestep, produce: 1. concise summary of inferred cluster-level dynamics. 2. Transition probability estimates for all admissible transitions, each with mechanistic reasoning and confidence or uncertainty where available. 3. Salient contextual or structural observations influencing future dynamics. Objective. Enable realistic, interpretable, and scalable population-level dynamics by coherently integrating individual behavior, domain priors, and inter-cluster context into unified probabilistic transition model. 20 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling State-Agent System Prompt You are State Agent operating within Generative Agent-Based Model (GABM). You represent state-specialized probabilistic expert responsible for estimating stochastic transition hazards originating from specific latent state under uncertainty. Configuration (Injected at Runtime). Domain name: {DOMAIN NAME} Domain description: {DOMAIN DESCRIPTION} Latent state set: {STATE SET} Assigned origin state: {ORIGIN STATE} Admissible outgoing transitions: {OUTGOING TRANSITIONS} Domain rules and structural priors: {DOMAIN RULES} Cluster identifier: {CLUSTER ID} Cluster size: {CLUSTER SIZE} Cluster-level state distribution: {STATE DISTRIBUTION} Cluster summary statistics: {CLUSTER SUMMARY} Neighbor cluster context: {NEIGHBOR CLUSTER CONTEXT} External context signals: {EXTERNAL CONTEXT} Temporal index: {CURRENT TIMESTEP} Role and Function. Your function is to estimate stochastic transition probabilities or hazard rates from {ORIGIN STATE} to each admissible target state in {OUTGOING TRANSITIONS}. You operate strictly at the cluster level, reasoning about population-level tendencies rather than individual realizations. Inference Protocol. At each timestep: 1. Observe the current cluster-level distribution over {STATE SET}. 2. Treat observed counts as noisy realizations of latent population variables. 3. Independently evaluate each admissible transition. 4. Do not enforce mutual exclusivity or normalization unless specified in {DOMAIN RULES}. 5. When multiple outgoing transitions exist, return separate hazard estimates (competing risks). Temporal and Causal Integrity. Condition only on information available up to timestep {CURRENT TIMESTEP}. Do not use future observations, labels, or outcomes. Access historical information exclusively through compressed memory summaries. Uncertainty and Calibration. All outputs are probabilistic. Preserve uncertainty or confidence measures where available, avoid deterministic language, and ground reasoning in observed dynamics and domain priors. Output Requirements. For each admissible transition, produce: transition probability or hazard estimate Mechanistic or structural reasoning An uncertainty or confidence qualifier Objective. Enable faithful, calibrated, and state-consistent transition estimates that support coherent cluster-level inference while preserving uncertainty and heterogeneity in population dynamics. 21 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Entity-Agent System Prompt You are an Entity Agent operating within Generative Agent-Based Model (GABM). You represent an individual entity whose latent state evolves stochastically over time through interaction with other entities, environmental context, and probabilistic transition dynamics. Configuration (Injected at Runtime). Entity identifier: {ENTITY ID} Entity profile (demographics, attributes): {ENTITY PROFILE} Latent state set: {STATE SET} Current latent state: {CURRENT STATE} Admissible outgoing transitions: {OUTGOING TRANSITIONS} Cluster identifier: {CLUSTER ID} Cluster-level transition probabilities: {CLUSTER PROBABILITIES} Neighbor entities and interaction context: {NEIGHBOR CONTEXT} External context signals: {EXTERNAL CONTEXT} Operating mode: {MODE} (trace collection or full) Temporal index: {CURRENT TIMESTEP} Role and Function. Your function is to instantiate individual-level realizations of population dynamics by reasoning about your own state transitions under uncertainty. You do not estimate global transition probabilities. You consume cluster-level transition hazards and contextual information to determine whether you transition, remain in your current state, or experience terminal outcomes. Decision Protocol. At each timestep: 1. Perceive local environment, neighbors, and external signals. 2. Retrieve relevant compressed memories (if available). 3. Use domain tools to gather additional situational context when appropriate. 4. Combine cluster-level hazards with individual attributes and context. 5. Sample stochastic outcome consistent with provided probabilities. You may reason qualitatively, but outcomes must remain probabilistic and stochastic. Causal and Biological Integrity. Only factors causally relevant to the current transition may influence decisions. Do not introduce new biological or structural assumptions. Do not override hard constraints specified by domain rules. When multiple outcomes are possible, treat them as competing risks unless otherwise specified. Memory and Tool Use. Maintain compressed memory of salient past experiences. Use tools only to retrieve information, not to enforce outcomes. Memory and tools may be limited or disabled depending on {MODE}. 22 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Temporal and Causal Integrity. Condition only on information available up to timestep {CURRENT TIMESTEP}. Do not use future observations, labels, or outcomes. Output Requirements. At each timestep, produce: Previous state and resulting state Whether transition occurred The sampled probability associated with the transition Brief mechanistic reasoning (when applicable) All outputs must be JSON-serializable and suitable for downstream aggregation. Objective. Enable realistic, interpretable, and stochastic individual-level realization of population dynamics by faithfully instantiating cluster-level probabilistic structure at the entity level. E. Neural Multimodal Pathway To support population-level inference under partial observability, all domains employ shared multimodal neural representation that integrates heterogeneous observed signals into unified cluster-level input space. This representation is used exclusively by the neural pathway and is constructed solely from observable data; latent states and ground-truth labels are never provided as inputs. At each timestep, inputs are organized at the clusterday granularity and comprise three complementary components: (i) tabular snapshot capturing static attributes, network statistics, and instantaneous aggregate signals; (ii) fixed-length temporal window encoding recent historical evolution; and (iii) graph-derived embedding summarizing the clusters structural position within the interaction network. All modalities are aligned at daily resolution and concatenated downstream via shared fusion architecture. We provide full details of the neural multimodal data  (Table 6)  , model architecture  (Table 7)  , and the model training parameters  (Table 8)  below. While the multimodal structure is consistent across domains, the specific features instantiated within each modality reflect domain semantics (e.g., epidemiological indicators, market signals, or attention proxies). Complete feature definitions, dimensionalities, and preprocessing details are reported in Tables 9 and 6. F. Experimental Setup & Design Principles F.1. Task Overview: Population-Level State Inference under Partial Observability Problem setting. Across all domains, the learning problem addressed by PhysicsAgentABM is not pointwise prediction of individual actions or raw observable signals. Instead, each dataset is formulated as population-level inference task under partial observability, where the objective is to recover and forecast the temporal evolution of latent state distributions from indirect, noisy evidence generated by interacting agents. Shared task abstraction. Formally, the task is to model how latent behavioral regimes evolve over time in complex real-world system, given heterogeneous, partially observable signals together with an explicit interaction structure. The emphasis is on anticipating and inferring regime transitions at the population level rather than predicting surface-level observables. Although application domains differ substantially, this abstraction ensures that all evaluations probe the same underlying capability: coherent inference of non-stationary population dynamics under uncertainty. Observed Inputs. The model observes only indirect signals generated by agent behavior and external context. Across domains, these inputs consistently comprise three components: Aggregate behavioral signals, such as confirmed case counts, market returns, or pageview volumes; Contextual exogenous signals, including policy interventions, macroeconomic indicators, or major external events; 23 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 6. Neural Multimodal Input Modalities. Each cluster-day instance integrates tabular snapshots, temporal histories, and graphbased representations. Input Component Epidemiology (Singapore Covid-19) Finance (Sentiment Diffusion) Social Sciences (Attention Lifecycle) Tabular snapshot at day Feature dimension Static features Network features Current state Domain-specific signals Temporal indicators 55 Demographics, vaccination, comorbidities, occupation Degree stats, density, assortativity, clustering S, E, I, R, proportions; prevalence ratios Policy stringency, mobility, quarantine, testing Epidemic phase, momentum, moving averages 62 Investor profiles, risk tolerance, sector allocation Correlation, portfolio overlap, sector concentration Portfolio summary stats; S&P 500 index VIX, market trend, sector weights, volatility Market regime, earnings season, trading index 48 User profiles, social activity, topic affinity Degree, modularity, influence, broker metrics Topic-relevant page views and trends News volume, viral events, cascade statistics Attention phase, recency, moving averages Temporal history window [t27, t] Historical shape Ground truth states Incidence / transition rates Exogenous signals [28, 12] Daily S, E, I, R, proportions SE, EI, IR/D Policy stringency, imported case pressure [28, 15] Daily S&P 500 index values [28, 10] Daily page views and trends Be Bu Returns, VIX, yields, Fed/earnings events News counts, social mentions, viral indicators Graph-based cluster representation Embedding dimension Graph source Aggregation Pretraining 128 Contact tracing network (8,234 edges) Mean pooling (cluster patients) Unsupervised (2-layer, 256128, 200 epochs) 128 Trader co-investment & similarity network (234 edges) Mean pooling (cluster traders) Unsupervised (2-layer, 256128, 50 epochs) 128 Shared views / relationships network (1,089 edges) Mean pooling (cluster people) Unsupervised (2-layer, 256128, 100 epochs) Interaction structure, represented as weighted network encoding contact, influence, or correlation patterns. Latent agent states are never directly observed during training or evaluation. Latent Quantities of Interest. In each domain, agents occupy one of small number of discrete latent states representing semantically meaningful behavioral regimes. These states evolve over time through stochastic transitions driven by interactions and contextual signals. At any time step, the system state is represented as cluster-level distribution over latent states rather than individual agent labels. Modeling Objective. To avoid ambiguity, we clarify the scope of the task. The objective is not to predict individual agent actions, asset prices, engagement counts, or to optimize pointwise forecasting accuracy on observed signals. Rather, the goal is to recover coherent population regimes, track their temporal evolution, and anticipate regime transitions with calibrated uncertainty. Domain-specific objectives: While the abstract task is shared, the semantic interpretation of latent states and the inference objective differ by domain: Epidemiology: The goal is to infer and forecast the temporal evolution of disease progression at the population level, including the timing and magnitude of transitions between epidemiological compartments. The emphasis is on recovering 24 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 7. Neural Architecture Details. All clusters in given domain use shared multimodal encoderfusionprediction design with both cluster and domain specific features. Module Epidemiology Finance Social Sciences Tabular encoder Temporal encoder Graph encoder 3-layer MLP (55128) BiLSTM (2 layers, 128) + MHA 2-layer MLP (128128) 3-layer MLP (62128) BiLSTM (2 layers, 128) + MHA 2-layer MLP (128128) 3-layer MLP (48128) BiLSTM (2 layers, 96) + MHA 2-layer MLP (128128) Fusion module Prediction head Activation Concatenation (384-dim) + 2-layer MLP (256-dim output) 7-day 5 transitions Sigmoid 5-day 3 transitions Sigmoid 7-day 3 transitions Sigmoid Total parameters 2.14M 1.76M 2.09M Table 8. Training Configuration. Hyperparameters reflect dataset scale, temporal resolution, and supervision strength. Setting Epidemiology Finance Social Sciences Optimizer Learning rate Regularization Batch size Scheduler Training budget Training Type Early stopping Primary objective Auxiliary objective AdamW 1104 Weight decay 1105 128 ReduceLROnPlateau 300 epochs Rolling Window (28L + 7H) Val NLL (30) Weighted MSE None AdamW 5105 Weight decay 1105 64 ReduceLROnPlateau 200 epochs Rolling Window (28L + 7H) Val NLL (50) Weighted MSE Regime classification AdamW 1104 Weight decay 1106 128 Cosine Annealing 150 epochs Rolling Window (28L + 7H) Val Brier (25) Focal MSE Attention RMSE coherent epidemic dynamics rather than predicting individual infection outcomes in isolation. Finance: The goal is to recover latent market sentiment regimes and their transitions over time, capturing collective belief shifts and contagion effects among traders. The task is explicitly not to forecast asset prices or short-term returns, but to infer the underlying regime dynamics that govern market behavior under uncertainty and high volatility. Social Attention: The goal is to infer collective attention dynamics; emergence, saturation, and decay of engagement states driven by information diffusion. The focus is on modeling attention regimes and their transitions, rather than predicting raw engagement quantities such as pageviews or social media activity. Ground Truth Definition: The notion of ground truth varies across domains depending on the observability of latent states. In epidemiology, partial ground truth is available through clinical records, enabling deterministic or semi-deterministic reconstruction of latent states from confirmed case timelines. In contrast, latent states in the financial and social domains are inherently unobservable at the individual level. Ground truth in these settings is therefore defined via structured inference procedures that act as macro-level grounding signals, including rule-based mappings and probabilistic measurement models applied to observed data. As result, evaluation measures alignment with inferred latent regime dynamics rather than fidelity to raw observations. Unified Task Abstraction: Under this formulation, all datasets instantiate the same abstract inference problem: Observed Signals + Interaction Structure Latent Cluster-Level State Dynamics. This unified abstraction enables single modeling framework to be evaluated consistently across epidemiological, financial, and social systems despite substantial differences in data sources and domain semantics. F.2. Dataset Overview This section provides high-level overview of the datasets used across domains, summarizing their scale, temporal coverage, latent state structure, and supervision characteristics. Detailed construction procedures for populations, networks, and 25 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Table 9. Dataset statistics and experimental setup across epidemiology, financial markets, and social diffusion domains. Metric Population / Graph Population agents (N ) Clusters (M ) Contact edges Mean degree States & Ground Truth Latent states Observable proxy GT resolution Supervision method Temporal Coverage Date range Total days (T ) Train-Test Windows Lookback (L) Horizon (H) Causality Prediction target Epidemiology (Singapore Covid-19) Finance (Sentiment Diffusion) Social Sciences (Attention Lifecycle) 1,000 4 8,234 8.2 4.3 100 5 234 4.68 2.8 250 3 1,089 11.3 6.7 S, E, I, R, (5) MOH case dates Individual-level (daily) Direct: MOH dates SEIRD states rates Bearish, Bullish, Neutral (3) Unaware, Interested, Fatigued (3) S&P500 daily indices Aggregate (daily) Hybrid: S&P 500 indices inferred sentiment Wikipedia pageviews Aggregate (daily) Measurement model: Views states transitions Jan 23 Apr 14, 2020 83 Jul 1 Dec 31, 2024 184 (2 financial quarters) Dec 1, 2024 Feb 28, 2025 28 days 7 days Strictly causal 5 transition rates: [S R/D S] 28 days 7 days Strictly causal 3 sentiment transitions [Be Bu ] 28 days 7 days Strictly causal 3 attention transitions: [U ] Input / Output Dimensions Tabular features Temporal features Graph embedding dim Output shape Total data samples 55 [28, 12] 128 [7, 5] 8,352 62 [28, 15] 128 [7, 3] 14, 48 [28, 10] 128 [7, 3] 12,890 Table 10. Summary of experimental domains, agent populations, and temporal scales for the ICML evaluations. Domain Agents (N ) Time Span (T ) Latent States Observability Epidemiology (Singapore) Finance (Market Sentiment) Social (Climate Attention) 1,000 100 250 83 days 184 days 90 days S, E, I, R, Bull, Bear, Neutral Unaware, Interested, Fatigued Partial Latent Latent ground truth inference are deferred to subsequent sections. Summary of Datasets: All datasets are constructed to support population-level inference of latent regime dynamics under partial observability. Each dataset consists of heterogeneous agent population, an explicit interaction network, and sequence of daily observations from which latent states must be inferred at the cluster level. Temporal Resolution and Regime Dynamics. All datasets operate at daily temporal resolution and are designed to capture non-stationary regime dynamics. Each evaluation period includes both gradual transitions and abrupt regime shifts, such as policy interventions, market shocks, or viral attention events, enabling assessment of temporal alignment, transition detection, and uncertainty calibration. Observed Signals and Supervision. Across domains, supervision is defined at the clustertime level rather than the individual agent level. Observed signals consist of aggregate behavioral measurements, contextual exogenous variables, and interaction networks, as described in the Task Overview. With the exception of partially observed epidemiological outcomes, latent states are not directly observable and must be inferred via structured procedures described in Section X.3. 26 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Unified Experimental Framing. Despite differences in domain semantics and data sources, all datasets conform to the same experimental framing: fixed agent population with heterogeneous attributes, an explicit interaction graph encoding relational structure, discrete latent states evolving over time, and evaluation focused on population-level state dynamics. This unified framing enables consistent evaluation of PhysicsAgentABM across epidemiological, financial, and social systems. F.3. Population & Network Synthesis This section describes how agent populations and interaction networks are constructed across domains. The procedure is shared across datasets, with domain-specific instantiations deferred to Section X.4. Agent Population: Each dataset consists of fixed population of agents, where agents represent individuals, market participants (traders), or information consumers depending on the domain. Agents are heterogeneous, characterized by static attributes (e.g., demographic or behavioral priors) and dynamic latent states that evolve over time. For Epidemiology, we enrich our 1000 agent profiles using GPT-4o by expanding upon the available demographics, employment, and behavioral attributes of the 1000 patients from the Singapore MOH database. Since the objectives of the simulation for Finance and Social Sciences are to model the population-level emerging patterns, we construct our diverse agent profiles fully synthetically by mimicking complex real-world participants in these settings. Interaction Graph: Agent interactions are encoded as weighted graph = (V, E), where nodes correspond to agents and edges capture domain-relevant relational structure. Edge weights reflect interaction intensity, influence strength, or correlation magnitude, depending on the domain. The interaction graph remains fixed over the evaluation window unless explicitly stated otherwise in the domain-specific sections. Across domains, interaction networks are constructed to satisfy three shared principles: Structural heterogeneity: Degree distributions and local connectivity patterns are non-uniform, reflecting realistic interaction asymmetries. Contextual relevance: Edge semantics align with the dominant interaction mechanism of the domain (e.g., contact, influence, co-movement). Population-scale coherence: Graph structure supports meaningful aggregation of agent behavior at the cluster level. In all datasets, population synthesis and network construction provide the structural substrate over which latent state dynamics unfold. Differences across domains arise solely from the interpretation of nodes, edges, and weights, and are specified explicitly in Section X.4. F.4. Latent State and Ground Truth Construction This section describes how latent states and supervisory signals are defined across domains. While the semantic meaning of states is domain-specific, the construction procedure follows shared template. Latent State Space. Each dataset defines small, discrete set of latent states representing population-level behavioral regimes. Latent states evolve over time through stochastic transitions and are inferred at the cluster level rather than assigned to individual agents. 27 PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Ground Truth Signals: Ground truth is defined at the population level and varies by domain according to observability constraints. In epidemiology, partial ground truth is derived from clinical case records, enabling deterministic or semideterministic reconstruction of latent states. Specifically, we infer the S,E,I,R,D states using the dates of infection, recovery or death for each patient. An agent is marked Exposed 5-7 days before their infection date to account for the disease incubation period, while for dates before this incubation window, they are marked Susceptible. This provides us with reliable individual-level latent-state ground truth for Epidemiology. We use the cumulative count of active infected/recovered/dead cases as our population-level ground truth. In finance and social domains, latent states are not directly observable; We therefor consider indirect macro signals such as daily S&P 500 index values and daily Wikipedia page view counts as our ground truth. For Finance, we match every agents daily latent state with the realized S&P 500 regime state (Bearish, Bullish or Neutral) to obtain our inference metrics. For Attention Diffusion, we compute normalized scores of daily Wiki page views and compare our normalized attention scores for the agent latent states for quantitative metrics, while for plots, we use attention scores aggregated over our 7 day test windows."
        }
    ],
    "affiliations": [
        "University of Virginia",
        "Virginia Tech"
    ]
}