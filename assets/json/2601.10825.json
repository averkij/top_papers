{
    "paper_title": "Reasoning Models Generate Societies of Thought",
    "authors": [
        "Junsol Kim",
        "Shiyang Lai",
        "Nino Scherrer",
        "Blaise Ag√ºera y Arcas",
        "James Evans"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models have achieved remarkable capabilities across domains, yet mechanisms underlying sophisticated reasoning remain elusive. Recent reasoning models outperform comparable instruction-tuned models on complex cognitive tasks, attributed to extended computation through longer chains of thought. Here we show that enhanced reasoning emerges not from extended computation alone, but from simulating multi-agent-like interactions -- a society of thought -- which enables diversification and debate among internal cognitive perspectives characterized by distinct personality traits and domain expertise. Through quantitative analysis and mechanistic interpretability methods applied to reasoning traces, we find that reasoning models like DeepSeek-R1 and QwQ-32B exhibit much greater perspective diversity than instruction-tuned models, activating broader conflict between heterogeneous personality- and expertise-related features during reasoning. This multi-agent structure manifests in conversational behaviors, including question-answering, perspective shifts, and the reconciliation of conflicting views, and in socio-emotional roles that characterize sharp back-and-forth conversations, together accounting for the accuracy advantage in reasoning tasks. Controlled reinforcement learning experiments reveal that base models increase conversational behaviors when rewarded solely for reasoning accuracy, and fine-tuning models with conversational scaffolding accelerates reasoning improvement over base models. These findings indicate that the social organization of thought enables effective exploration of solution spaces. We suggest that reasoning models establish a computational parallel to collective intelligence in human groups, where diversity enables superior problem-solving when systematically structured, which suggests new opportunities for agent organization to harness the wisdom of crowds."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 5 1 ] . [ 1 5 2 8 0 1 . 1 0 6 2 : r a"
        },
        {
            "title": "Reasoning Models Generate Societies of Thought",
            "content": "Junsol Kim1,2,, Shiyang Lai2, Nino Scherrer1, Blaise Ag√ºera Arcas1,3 and James Evans1,2,3,* 1Google, Paradigms of Intelligence Team, 2University of Chicago, 3Santa Fe Institute Large language models have achieved remarkable capabilities across domains, yet mechanisms underlying sophisticated reasoning remain elusive 1,2. Recent reasoning-reinforced models, including OpenAIs o-series, DeepSeek-R1, and QwQ-32B, outperform comparable instruction-tuned models on complex cognitive tasks 3,4, attributed to extended test-time computation through longer chains of thought 5. Here we show that enhanced reasoning emerges not from extended computation alone, but from the implicit simulation of complex, multi-agent-like interactionsa society of thoughtwhich enables the deliberate diversification and debate among internal cognitive perspectives characterized by distinct personality traits and domain expertise. Through quantitative analysis using classified outputs and mechanistic interpretability methods applied to reasoning traces 6,7, we find that reasoning models like DeepSeek-R1 and QwQ-32B exhibit much greater perspective diversity than baseline and merely instruction-tuned models, activating broader conflict between heterogeneous personalityand expertiserelated features during reasoning. This multi-agent structure manifests in conversational behaviours including question-answering sequences, perspective shifts, and reconciliation of conflicting views, as well as in socio-emotional roles that characterize sharp back-and-forth conversation, which together account for the accuracy advantage in reasoning tasks through both direct and indirect facilitation of cognitive strategies 8,9. Controlled reinforcement learning experiments further reveal that base models spontaneously increase conversational behaviours when solely rewarded for reasoning accuracy, and fine-tuning models with conversational scaffolding substantially accelerates reasoning improvement compared to base models and models fine-tuned with monologue-like reasoning. These findings indicate that the social organization of thought enables effective exploration of solution spaces. We suggest that reasoning models establish computational parallel to collective intelligence in human groups 1012, where diversity enables superior problem-solving when systematically structured and suggest new opportunities for agent organization to harness the wisdom of crowds. Artificial intelligence (AI) systems have undergone remarkable transformation in recent years, with large language models (LLMs) demonstrating increasingly sophisticated abilities across domains, from mathematics and code to scientific and creative writing to critical decision support 1,2. Nevertheless, persistent challenge has been the development of robust reasoning capabilitiesthe ability to methodically analyze problems, consider alternatives, detect errors, and arrive at reliable conclusions. Recent reasoning models, such as DeepSeek-R1, QwQ, and OpenAIs o-series models (o1, o3, o4), are trained by reinforcement learning to think before they respond, generating lengthy chains of thought. This led to substantial improvement in reasoning accuracy compared to existing instructiontuned language models (e.g., DeepSeek-V3, Qwen-2.5, GPT-4.1) 3,4. Yet, the character of thinking within reasoning models that drives success remains underexplored. We propose that reasoning models learn to emulate social, multi-agent-like dialogue between multiple perspectiveswhat we term society of thoughtto improve their reasoning, given the centrality of social interaction to the development of reason in both cognitive and social scientific accounts. Mercier and Sperbers Enigma of Reason argument posits that human reasoning evolved primarily as social process, with knowledge emerging through adversarial reasoning and engagement across differing viewpoints 10. Empirical work supports the idea that groups outperform individuals on wide range of Corresponding author: James Evans (jamesaevans@google.com; jevans@uchicago.edu) Work done as student researcher at Google Reasoning Models Generate Societies of Thought reasoning tasks by pooling information, calibrating confidence, and exhibiting collective intelligence through balanced turn-taking among diverse perspectives 1215. Cognitive diversity, stemming from variation in expertise and personality traits, enhances problem solving, particularly when accompanied by authentic dissent 11,1622. Together, these findings suggest that robust reasoning emerges through interaction and the integration of diverse perspectives, and that key reasoning strategies, including verification and backtracking, may be realized through the conversation of simulated personas. While diversity and debate contribute directly to collective intelligence, many theories further suggest that individuals reason better when they simulate this capacity. single, self-centered perspective can lead to systematic biases in reasoning; if individuals effectively simulate multiple, self-distanced perspectives with their minds, as in dialectical thinking, this can reduce decision biases within them 2325. The social brain hypothesis suggests that higher-order intelligence primarily evolved to meet the cognitive demands of processing and simulating social interactions 26,27. Individuals who simulate others differing perspectives through improved theory-of-mind capabilities enhance collective team performance 18. Furthermore, theorists have argued that individual reason itself emerged from simulation of collective discourse. Bakhtins notion of the dialogic self and Cooley and Meads theory of the looking glass self argue that human thought itself takes the form of an internalized conversation among multiple perspectives 28? 30. Even in the history of artificial intelligence, Minsky conceptualized intelligence as an emergent property of interacting cognitive agents, or Society of Mind 31. Therefore, whether AI systems directly simulate multi-agent discourse or simulate minds that, in turn, simulate multi-agent discourse, we propose that reasoning models like DeepSeek-R1 improve reasoning via society of thoughtimplicit simulations of multi-agent-like interactions between diverse perspectives that give rise to them. We use the term to denote text generation that simulates social exchange among multiple perspectives to increase the collective diversity of ideas through conversational roles that put them in competition. Without deploying separate models prompted to interact with one another 3234, we suggest that behaviourally similar conversations between diverse perspectives occur and are leveraged within reasoning models. Reasoning models like DeepSeek-R1 develop reasoning abilities through reinforcement learning, which iteratively compensates reasoning behaviour that yields correct answers. Following these performance improvements, debates have naturally arisen about what kinds of behaviours contribute to better reasoning performance. While earlier studies focus on how the model learns to scale testtime computations and generate longer reasoning traces 2,35, merely increasing trace length does not account for the observed improvements in reasoning capabilities. This suggests that qualitative changes in reasoning structure matter more than quantitative scaling alone 3537. Recent analyses pinpoint behavioural patterns that improve reasoning accuracy, such as verification of earlier assumptions, backtracking, and exploration of alternatives 4,8,3537. Mechanistic interpretability research has shown that features in language models such as the frequent use of words like wait, but, and however are associated with these behaviours 3841. The characteristics of these features, however, such as their prevalence in social and conversational settings, have rarely been explored. Research in other contexts has suggested that the simulation of multi-agent conversations can boost accuracy and divergent thinking in LLMs 34,4247. While LLMs can exhibit cognitive biases that hinder reasoning, the simulation of interaction between different perspectives could mitigate biases when verified through checks and balances 34,48,49. This leads us to hypothesize that reinforcement learning may systematically select and reward behaviour patterns that resemble multi-agent interactions within reasoning models, and these simulated interactions enable models to reason effectively. Here we investigate the prevalence of reasoning traces of DeepSeek-R1, as well as QwQ-32B, that mimic simulated social interactions, quantifying how conversational behaviours, socio-emotional Reasoning Models Generate Societies of Thought roles, and diversity of implicit agent perspectives contribute to reasoning performance. We first identify whether conversational behaviours and socio-emotional roleshallmarks of human dialogue such as questioning, perspective taking, and reconciliationare present in DeepSeek-R1s and QwQ32Bs reasoning traces. Then we test whether conversational behaviour contributes to reasoning performance. Based on the mechanistic interpretability method applied to DeepSeek-R1s distilled model (DeepSeek-R1-Llama-8B), we find that steering features associated with discourse marker, such as expressing surprise in conversational contexts, improves reasoning accuracy both directly and indirectly through the facilitation of cognitive strategies. Next, we analyze the diversity of reasoning perspectives or simulated voices within DeepSeek-R1s and QwQ-32Bs reasoning traces. Literature suggests that LLM reasoning can fail if models do not engage in meaningful disagreement and instead conform to misleading initial claims through pleasant, sycophantic conversations that propagate incorrect assumptions and knowledge 4951. Successful reasoning models may therefore exhibit disagreement driven by diversity in simulated perspectives, expressed through distinct personalities and expertise to avoid the echo chamber that leads to wrong answers. Therefore, we analyze reasoning traces using LLM-as-judge to accurately identify distinct voices underlying conversation. We find that DeepSeek-R1 and QwQ-32B display much greater personality and expertise diversity than non-reasoning models within their reasoning traces, presumably to maximize the benefits of multi-agent-like interaction through diversification. We further find that steering conversational feature in models activation space leads to the activation of more diverse range of personalityand expertise-related features. Finally, we conduct controlled reinforcement learning experiment to examine the role of conversational behaviours. We focus on self-taught reinforcement learning that rewards only accuracy and correct formatting (i.e., wrapping the thinking process between <think> and </think>), the common approach for improving modern language models reasoning capabilities 4. Based on symbolic arithmetic task (Countdown game) 8,52, as well as misinformation identification task, we apply reinforcement learning that rewards reasoning traces leading to accurate answers on open-source LLMs. Interestingly, experiments reveal that the base model can spontaneously develop conversational behaviourssuch as self-questioning and perspective shiftswhen rewarded solely for reasoning accuracy, without any explicit training signal for dialogue structure. Moreover, following methods of prior ablation research 8, we observe that initially fine-tuning these models for conversational structure leads to faster accuracy improvements, outperforming both their baseline counterparts and models fine-tuned with monologue-like reasoning, particularly during the early stages of training in two distinct model systems (Qwen-2.5-3B and Llama-3.2-3B). These results suggest that conversational scaffolding facilitates the discovery and refinement of reasoning strategies during reinforcement learning."
        },
        {
            "title": "Results",
            "content": "We compile suite of widely used benchmarks used in prior research and official model cards of reasoning models (BigBench Hard, GPQA, MATH (Hard), MMLU-Pro, MUSR, and IFEval) 3,4, spanning symbolic logic, mathematical problem solving, scientific reasoning, multi-agent inference, and instruction following tasks (see Methods: Data). From this pool, we sample 8,262 problems and generate reasoning traces using DeepSeek-R1-0528 (671B parameters; hereafter DeepSeek-R1) and QwQ-32B. For comparison, we also generate reasoning traces using conventional, instruction-tuned models of varying sizes: DeepSeek-V3-0324 (671B parameters; hereafter DeepSeek-V3), Qwen-2.532B-Instruct (hereafter Qwen-2.5-32B-IT; the instruction-tuned model based on Qwen-2.5-32B from which QwQ-32B is derived), Llama-3.3-70B-Instruct (hereafter Llama-3.3-70B-IT), and Llama-3.18B-Instruct (hereafter Llama-3.1-8B-IT) 53,54. DeepSeek-V3 is the instruction-tuned model based on 3 Reasoning Models Generate Societies of Thought DeepSeek-V3-base from which DeepSeek-R1 is derived, and Qwen-2.5-32B-IT is the instruction-tuned model based on Qwen-2.5-32B from which QwQ-32B is derived (see Methods: Data) 53,54. Next, we estimate behavioural differences between reasoning models (DeepSeek-R1 and QwQ-32B) and the instruction-tuned models. We use linear probability models with problem-level fixed effects, which control for all task-specific characteristics, such as the difficulty of tasks. Specifically, we compare each reasoning model with its corresponding instruction-tuned counterpart (i.e., DeepSeekR1 vs. DeepSeek-V3; QwQ-32B vs. Qwen-2.5-3B-IT) on the presence of conversational behaviours and socio-emotional roles. We control for log-transformed reasoning trace length (Extended Data Fig. 1) to consider that observed differences are not merely driven by longer chains of thought that is, we demonstrate that reasoning models exhibit more frequent conversational behaviours and socio-emotional roles even when trace lengths are similar (see Methods: Statistical analyses). Conversational Behaviours and Socio-Emotional Roles We begin by investigating whether conversational behaviours and socio-emotional roles constitutive of back-and-forth dialogue are prevalent in reasoning traces. Using an LLM-as-judge, we quantify the occurrence of four conversational behavioursdefined as behaviours signaling the simulation of exchanges among multiple perspectives to explore given problemwithin each reasoning trace: (1) questionanswering, in which the trace poses and then resolves questions; (2) perspective shifts, where alternative viewpoints are explored; (3) conflicts of perspectives, in which competing viewpoints are sharply contrasted; and (4) reconciliation, where conflicting viewpoints are integrated and coherently resolved. We also examine socio-emotional roles based on Bales Interaction Process Analysis (IPA) 55. This identifies 12 interaction roles grouped into four categories: (1) asking for orientation, opinion, and suggestion, (2) giving orientation, opinion, and suggestion, (3) negative emotional roles (disagreement, antagonism, tension), and (4) positive emotional roles (agreement, solidarity, tension release), which together characterize interactive group activity. These behaviours are annotated using an LLM-asjudge (Gemini-2.5-Pro) that shows substantial agreement with both human rater (average ICC(3,1) = .756) and another LLM (GPT-5.2; average ICC(3,1) = .875) (see Methods: Measurements and Supplementary Method: LLM-as-judge prompts (Conversational behaviours and Socioemotional roles)). To illustrate how reasoning traces are annotated, we provide examples in Extended Data Fig. 2 and Supplementary Methods: Annotation Examples. In an organic chemistry problem requiring multistep reaction analysis to identify the final products structure (i.e., multi-step Diels-Alder synthesis), DeepSeek-R1 exhibits perspective shifts and conflict, expressed through socio-emotional roles such as disagreement, giving opinion, and giving orientation (e.g., But here, its cyclohexa-1,3-diene, not benzene. Another possibility: the high heat might cause the ketone to lose CO or something, but unlikely.). In contrast, DeepSeek-V3s trace on the same problem shows no conflict of perspectives, no perspective shifts, and no disagreementonly giving opinions and orientations in monologic sequence without self-correction, concluding with 8 is reasonable estimate, the wrong answer, as consequence of incomplete reasoning. In creative sentence rewriting task, DeepSeek-R1 debates competing stylistic proposals through conflict of perspectives, as well as socio-emotional roles such as disagreement and giving suggestion: But that adds deep-seated which wasnt in the original. We should avoid adding new ideas. Wait, thats not word. But note: cast can be less forceful than flung. So lets use hurled. DeepSeek-V3, by contrast, shows minimal conflict and no disagreement, producing suggestions without the iterative refinement observed in DeepSeek-R1. As shown in Fig. 1a, we quantify the occurrence of four conversational behaviours within each reason4 Reasoning Models Generate Societies of Thought Fig. 1. Conversational behaviours and Bales socio-emotional roles in chain-of-thought reasoning. a, Proportion of reasoning traces containing each conversational behaviour (question answering, perspective shift, conflict of perspectives, and reconciliation). b, Proportion of Bales twelve socio-emotional roles expressed in reasoning traces, grouped into four higher-level categories: ask versus give information, and positive versus negative emotional roles (see Extended Data Fig. 3 for definitions of all twelve roles). c, Jaccard index measuring the balance of each socio-emotional role pair, defined as the number of reasoning traces containing both roles divided by the number containing either role (i.e., ask & give; positive & negative). d, Distribution of the number of distinct perspectives in reasoning traces, identified using an LLM-as-judge. e, Differences in problem complexity by the presence of conversational behaviours and higher-level socio-emotional roles in DeepSeek-R1, measured on seven-point Likert scale (1 = extremely easy; 7 = extremely difficult) using an LLM-as-judge. Points indicate mean complexity for traces where the behaviour or role is present (red) or absent (blue). f, Differences in problem complexity by the presence of conversational behaviours and socio-emotional roles in DeepSeek-R1, measured by instruction-tuned (non-reasoning) models error rates on the same problems (see Methods: Measurements). Error bars indicate 95% confidence intervals. 5 Reasoning Models Generate Societies of Thought ing trace, and report the proportion of traces exhibiting more than one such behaviour. DeepSeek-R1 and QwQ-32B exhibit conversational behaviours far more frequently than instruction-tuned models. DeepSeek-R1 shows significantly more questionanswering (ùõΩ = 0.345, 95% CI = [0.328, 0.361], t(8261) = 41.64, < 110-323), perspective shifts (ùõΩ = 0.213, 95% CI = [0.197, 0.230], t(8261) = 25.55, < 110-137), and reconciliation (ùõΩ = 0.191, 95% CI = [0.176, 0.207], t(8261) = 24.31, < 110-125) compared to DeepSeek-V3. QwQ-32B displays similar pattern relative to Qwen-2.5-32BIT, with greater questionanswering (ùõΩ = 0.459, 95% CI = [0.444, 0.475], t(8261) = 57.57, < 110-323), perspective shifts (ùõΩ = 0.378, 95% CI = [0.362, 0.394], t(8261) = 46.92, < 110-323), conflicts of perspectives (ùõΩ = 0.293, 95% CI = [0.277, 0.308], t(8261) = 37.08, < 110-277), and reconciliation (ùõΩ = 0.344, 95% CI = [0.328, 0.360], t(8261) = 42.59, < 110-323). Notably, all instruction-tuned models show consistently low prevalence of conversational behaviours regardless of parameter count (8B, 32B, 70B, 671B). As shown in Fig. 1b, both DeepSeek-R1 and QwQ-32B exhibit more reciprocal socio-emotional roles compared to their instruction-tuned counterparts: they both ask for and give orientations, opinions, and suggestions, while also displaying both negative and positive roles. DeepSeek-R1 asks more frequently than DeepSeek-V3 (ùõΩ = 0.189, 95% CI = [0.176, 0.203], t(8261) = 27.47, < 110-158), engages more in negative roles (ùõΩ = 0.162, 95% CI = [0.147, 0.176], t(8261) = 21.87, < 110-10), and displays more positive roles (ùõΩ = 0.278, 95% CI = [0.263, 0.293], t(8261) = 35.38, < 110-254). QwQ-32B shows similar pattern relative to Qwen-2.5-32B-IT, with increased asking (ùõΩ = 0.200, 95% CI = [0.186, 0.215], t(8261) = 27.21, < 110-155), negative roles (ùõΩ = 0.450, 95% CI = [0.436, 0.463], t(8261) = 64.77, < 110-323), and positive roles (ùõΩ = 0.312, 95% CI = [0.296, 0.327], t(8261) = 39.17, < 110-307). In contrast, instruction-tuned models predominantly give orientations, opinions, and suggestions without reciprocal asking behaviours or emotional engagement, producing one-sided monologues rather than simulated dialogue. We quantify reciprocal role balance using the Jaccard index, which captures whether both sides of role pairasking versus giving for task-oriented roles, and positive versus negative for emotional roles co-occur within the same reasoning trace. As shown in Fig. 1c, DeepSeek-R1 exhibits significantly higher Jaccard indices for both ask & give (ùõΩ = 0.222, 95% CI = [0.208, 0.237], t(8261) = 30.21, < 110-189) and positive & negative roles (ùõΩ = 0.189, 95% CI = [0.176, 0.203], t(8261) = 27.47, < 110-158) compared to DeepSeek-V3, indicating that the model coordinates roles reciprocally rather than deploying them in isolation. QwQ-32B shows similar pattern relative to Qwen-2.5-32B-IT (ask & give: ùõΩ = 0.284 [0.269, 0.299], t(8261) = 37.36, < 110-281; positive & negative: ùõΩ = 0.200 [0.186, 0.215], t(8261) = 27.24, < 110-155) (see Supplementary Table 1). We further examine whether conversational behaviours and socio-emotional roles become more pronounced when DeepSeek-R1 faces more difficult tasks. Problem complexity is assessed both by an external LLM-as-judge (Fig. 1d: Gemini-2.5-Pro) or by error rates across conventional instruction-tuned models (Fig. 1e: DeepSeek-V3, Qwen-2.5-32B, Llama-3.3-70B-IT, Llama-3.1-8B-IT). As illustrated in Fig. 1d and 1e, these behaviours appear more frequently when DeepSeek-R1 tackles more complex problems, except for giving orientations and opinions. Consistent patterns across both measures suggest that conversational reasoning is preferentially activated in response to greater problem difficulty. For instance, tasks with the highest complexity scoressuch as GPQA (graduate-level science) and challenging math problemsexhibit strong conversational patterns, whereas simple procedural tasks like boolean expressions and basic logical deduction show minimal dialogic behaviour (see Supplementary Table 2). To decompose the accuracy advantage of reasoning models (DeepSeek-R1 and QwQ-32B) using the behavioural mechanisms above, we estimate structural equation model with four conversational behaviours, four socio-emotional roles, and four cognitive behaviour mediators, using task accuracy 6 Reasoning Models Generate Societies of Thought as the outcome. Results suggest that conversational behaviours and socio-emotional roles mediate reasoning models accuracy advantage, both directly and indirectly through facilitating useful cognitive strategies, such as verification, backtracking, subgoal setting, and backward tracking (See Extended Data Fig. 4; Supplementary Methods: behavioural Pathways Linking Reasoning Models to Accuracy Advantages). Conversational Feature Steering Improves Reasoning Accuracy Having observed that conversational behaviours are prevalent in reasoning traces using LLM-asjudge, we next question whether steering behaviours associated with conversations contribute to reasoning performance. We employ mechanistic interpretability methods to identify and manipulate features in the models activation space related to conversational behaviours, and examine how steering these features affects the models reasoning capabilities. We use sparse autoencoders (SAEs), which decompose neural network activations into large set of linear, interpretable features 5658. Specifically, we use an SAE trained on Layer 15s residual stream activations of DeepSeek-R1-Llama8B (15-llamascope-slimpj-res-32k), distilled model derived from DeepSeek-R1 frequently used to conduct interpretability research on LLM reasoning 3841. SAEs trained on middle layers, including Layer 15, are known to capture key behavioural and semantic features in models 6,58. The SAE was trained on the SlimPajama dataset, general-purpose, large-scale corpus used to train LLMs from scratch, containing both conversational and non-conversational texts (see Supplementary Table 3 for full SAE hyperparameters) 59. To identify SAE features associated with conversational contexts, we follow conventional interpretability pipeline 56,60,61. We first run the SAE on large-scale corpus (SlimPajama-3B), sampling around 50 contexts where each of the 32,768 features activates to explain the role of each feature. These sampled contexts are then used to characterize the feature as in prior literature 56,60,61. Using LLM-as-judge classification of these contexts (Gemini-2.5-flash-lite), we compute the conversation ratio for each featurethe proportion of feature activations that occur in interpersonal, conversational settings (see Fig. 2a for the distribution across all features). For example, if the conversation ratio is 50%, then in 50% of the instances when the feature is activated, it is used for conversation. We focus on features with conversation ratios above 50% that tend to activate near sentence onsets (i.e., within the first four tokens). From the candidates, we curate feature 30939, summarized as discourse marker for surprise, realization, or acknowledgment by Gemini-2.5-Pro, which activates on tokens like Oh! in contexts involving turn-taking and social exchange (see Fig. 2a). This feature exhibits conversation ratio of 65.7%placing it in the 99th percentile among all featureswhile maintaining high sparsity (0.016% of tokens), indicating that it captures specific conversational phenomenon rather than general linguistic patterns. We select this feature because prior literature suggests that expressions of surprise signal shift in contrasting perspectives characteristic of social coordination and affiliation 62,63. We examine whether steering this feature causally induces conversational behaviours and improves reasoning accuracy using the activation addition method, which adds scaled feature vectors to model activations during generation. Specifically, we use the Countdown game, benchmark commonly used to evaluate LLM multi-step reasoning capabilities 8,52. In the Countdown task, the model must combine given set of numbers using basic arithmetic operations (+, , , ) and parentheses to reach target valuefor example, given inputs 25, 30, 3, 4 and target 32, valid solution is (30 25 + 3) 4 = 32 8,52. We use the sample of 1,024 Countdown problems. We prompt the model to generate chain-of-thought reasoning, and at each token generation step, we add the feature 30939 vector (scaled by the steering strength) to layer 15 activations. As shown in Fig. 2b, steering the conversational surprise feature with positive direction (+10) doubles 7 Reasoning Models Generate Societies of Thought Fig. 2. Steering conversational features improves reasoning. a, Illustration of sparse autoencoder feature 30939 in DeepSeek-R1-Llama-8B, summarized as discourse marker for surprise, realization, or acknowledgment in conversational settings. Conversation ratio indicates the proportion of conversational contexts among all contexts in which this feature is activated. Percentile indicates where this features conversation ratio ranks among all features (ùëÅ = 32,768). Sparsity refers to the fraction of tokens on which this feature activates across the entire corpus. Activation strength shows the magnitude of activation in the top-activating examples. The examples illustrate this features activation within conversational turn-taking contexts. b, Results of steering experiment using the activation-addition method. Adding the feature 30939 vector with strength of 10 doubles accuracy on complex counting task. The inset shows the causal change in conversational behaviours induced by steering this feature. c, Violin plots showing accuracy improvements from steering feature 30939, compared with randomly selected conversational SAE feature and randomly selected non-conversational SAE feature. d, Cognitive behavioursincluding verification, backtracking, subgoal setting, and backward chainingare causally associated with steering the activation of feature 30939. e, Structural equation model results showing that steering feature 30939 from 0 to +10 has both direct effect on reasoning accuracy and significant indirect effect mediated through cognitive behaviours (verification, subgoal setting, and backward chaining). Bold coefficients indicate statistical significance (p < 0.05). ***p < 0.001, **p < 0.01, *p < 0.05. 8 Reasoning Models Generate Societies of Thought accuracy from 27.1% to 54.8% in the Countdown task, while steering in the negative direction (10) reduces accuracy to 23.8%. The radar plot inset reveals that positive steering (from 0 to +10) simultaneously increases all four conversational behavioursmore question-answering (ùõΩ = 2.199, 95% CI = [1.648, 2.750], t(1023) = 7.83, < 110-14), perspective shifts (ùõΩ = 1.160, 95% CI = [0.665, 1.655], t(1023) = 4.60, < 110-5), conflict of perspectives (ùõΩ = 1.062, 95% CI = [0.376, 1.749], t(1023) = 3.04, = 0.002), and reconciliation (ùõΩ = 0.423, 95% CI = [0.349, 0.497], t(1023) = 11.21, < 110-27), controlling for problem fixed-effects and log-transformed reasoning trace length. Negative steering from 0 to -10 suppresses them, reducing question-answering (ùõΩ = 0.831, 95% CI = [1.154, 0.508], t(1023) = 5.05, < 110-6), perspective shifts (ùõΩ = 0.966, 95% CI = [1.262, 0.670], t(1023) = 6.41, < 110-9), conflict of perspectives (ùõΩ = 1.347, 95% CI = [1.748, 0.946], t(1023) = 6.60, < 110-10), and reconciliation (ùõΩ = 0.052, 95% CI = [0.103, 0.001], t(1023) = 1.99, = 0.046). For instance, as shown in Extended Data Table 1, positive steering (+10) induces reasoning traces where the model actively challenges prior approaches (Wait, let me see. . . Another idea. . . ), showing perspective shift and conflicts of perspectives, whereas negative steering (10) produces relatively flat, declarative reasoning without internal debate. To examine whether this effect is specific to conversational features rather than general property of SAE steering, we compare accuracy improvements across three conditions: (1) steering the conversational surprise feature (Feature 30939), steering randomly selected conversational feature, and steering randomly selected non-conversational feature (Fig. 2c). random conversational feature is defined as any feature whose conversation ratio is above the average and tends to activate near sentence onset (i.e., first four tokens), which are more closely associated with conversational styles than other features. All steering strengths are defined as the maximum activation strength across sampled instances of feature activations (SlimPajama-3B), multiplied by 2. The conversational surprise feature produces substantially larger accuracy gains than both random conversational features and non-conversational features (see Fig. 2c). Steering any random conversational feature also significantly improves reasoning by 4.17% more than any random non-reasoning feature (ùõΩ = 0.042, 95% CI = [0.016, 0.068], t(1023)=3.14, p=0.002). This specificity suggests that conversational dynamics, rather than arbitrary perturbations to model activations, drive the observed improvements. We further investigate the mechanism by which conversational steering enhances reasoning. Prior work has identified cognitive behavioursverification, backtracking, subgoal setting, and backward chaining as key contributors to reasoning accuracy in language models 8. As shown in Fig. 2d, steering feature 30939 toward positive values (0 to +10) systematically increases all four cognitive behaviours: verification (Difference = 5.815, 95% CI=[4.922, 6.709], t(1023)=12.77, < 110-34), backtracking (Difference = 0.881, 95% CI=[0.515, 1.248], t(1023)=4.72, < 110-5), subgoal setting (Difference = 0.621, 95% CI=[0.440, 0.803], t(1023)=6.72, < 110-10), and backward chaining (Difference = 0.809, 95% CI=[0.633, 0.985], t(1023)=9.02, < 110-18) rise monotonically with steering strength. Steering toward negative values (0 to -10) suppresses these behaviours (verification: Difference = -2.302, 95% CI=[-2.892, -1.711], t(1023)=7.65, < 110-13; backtracking: Difference = -1.138, 95% CI=[-1.410, -0.867], t(1023)=8.24, < 110-15; subgoal setting: Difference = -0.171, 95% CI=[-0.305, -0.036], t(1023)=2.48, = 0.013; backward chaining: Difference = -0.353, 95% CI=[-0.487, -0.219], t(1023)=5.18, < 110-6) based on paired t-tests. This suggests that conversational features may improve reasoning, in part, by facilitating the deployment of effective cognitive strategies. To disentangle direct and indirect effects, we fit structural equation model to examine the pathways from steering conversational surprise (feature 30939) to accuracy (Fig. 2e). The model indicates that increasing steering feature 30939 from 0 to +10 yields both significant direct effect on reasoning accuracy (ùõΩ = .228, 95% CI = [.183, .273], z=9.98, < 110-22, N=2048) and significant indirect 9 Reasoning Models Generate Societies of Thought effect mediated by cognitive behaviours (ùõΩ = .066, 95% CI = [.046, .086], z=6.38, < 110-10, N=2048). Collectively, these findings suggest that conversational features enhance reasoning by directly enabling more effective exploration of the solution space, but also by scaffolding the cognitive strategies that support systematic problem solving. Diversity of Implicit Perspectives Beyond task accuracy, we examine whether DeepSeek-R1 increases the diversity of perspectives expressed within reasoning trace. In human societies, conversations and socio-emotional role-taking expand the range of viewpoints and domain knowledge brought into problem solving. Differences of perspective give rise to conflict, debate, and resolution. We evaluate whether similar perspective diversity emerges in DeepSeek-R1 by analyzing personality and expertise variation among the distinct reasoning perspectives participating in each reasoning trace. We first use an external LLM-as-judge (Gemini-2.5-Pro), prompting it to identify the diversity of implicit conversational perspectives within reasoning traces of DeepSeek-R1, QwQ-32B, and other instruction-tuned models. Specifically, the model infers the number of perspectives underlying each reasoning trace, the personality traits and domain expertise associated with each perspective, and segmentation of the full reasoning trace by perspective (see Methods: Implicit Perspectives). Given complete reasoning trace, the LLM-as-judge first infers the number of distinct perspectives present, which is shown in Fig. 1d. It then characterizes each perspectives personality traits using the BFI-10 (10-Item Big Five Personality Scale) questionnaire 64, along with short free-form description of the perspectives domain expertise. Finally, the LLM-as-judge attributes each token in the reasoning trace to specific perspective (i.e., who said this word). Personality diversity is estimated using the standard deviation of inferred personality traits for each Big-5 dimension, while domain expertise diversity is estimated using the mean cosine distance between embedding of each domain expertise description and the average embedding. See Methods: Implicit Perspectives and Supplementary Method: LLM-as-judge prompts (Persona identification and Persona segmentation) for details. For instance, in chemistry reasoning trace requiring multi-step synthesis analysis, the LLM-as-judge identifies five perspectives, including critical verifier (low agreeableness, high conscientiousness) who skeptically re-evaluates assumptions, and an expert in making associations (high openness) who recalls analogous reactions. In creative writing trace where the model rewrites the sentence flung my hatred into the burning fire, seven perspectives emerge, including creative ideator (highest Openness and Extraversion) who generates stylistic alternatives and semantic fidelity checker (low agreeableness, high neuroticism) who prevents scope creepBut that adds deep-seated which wasnt in the original. DeepSeek-V3s trace reflects only single generalist perspective combining all functions without differentiation (see Supplementary Methods: Annotation Examples). Using the Intelligence Squared Debates Corpusa dataset of human argumentative conversations (N=1,196 conversations) among two to eight participantswe first validate the accuracy of the LLM-as-judge in identifying distinct voices within conversation. As shown in Extended Data Fig. 5, we find that the LLM-as-judge can accurately predict the number of distinct individuals underlying each conversation, even when speaker labels are hidden and the dialogue is concatenated into single block of text (Spearmans ùúå = 0.86, 95% CI = [0.84, 0.87], = 44.7, < 110-323). We also find that the LLM-as-judge can accurately predict the number of distinct turns (Spearmans ùúå = 0.89, 95% CI = [0.88, 0.90], = 49.2, < 110-323) and correctly attribute each token to speaker. When there are two speakers, the accuracy is 82%; for three speakers, 76%; and for four speakers, 69%. Accuracy weighted by the predicted number of implicit perspectives underlying LLM reasoning trace is 73%. Because the Intelligence Squared Debates Corpus includes biographical information about debate participants, we further verify that expertise diversity inferred by LLM-as-judge and 10 Reasoning Models Generate Societies of Thought embeddings predicts the actual diversity among participants ground-truth biographies (Spearmans ùúå = 0.55, 95% CI = [0.51, 0.59], = 21.4, < 110-97). Together, these results suggest that LLM-as-judge can capture meaningful diversity patterns in conversational agents that correspond to observed diversity in real human conversations (see Methods: Implicit Perspectives - Validation for details). As shown in Fig. 3a, we find that DeepSeek-R1 and QwQ-32B produce significantly higher personality diversity, controlling for the number of perspectives. DeepSeek-R1 shows particularly higher diversity along extraversion (ùõΩ = 0.103, 95% CI = [0.075, 0.131], = 7.16, < 110-13), agreeableness (ùõΩ = 0.297, 95% CI = [0.271, 0.323], = 22.65, < 110-113), neuroticism (ùõΩ = 0.567, 95% CI = [0.542, 0.592], = 44.57, < 110-323), and openness (ùõΩ = 0.110, 95% CI = [0.083, 0.137], = 8.06, < 110-16), compared to DeepSeek-V3. Similarly, QwQ-32B shows higher diversity in extraversion (ùõΩ = 0.253, 95% CI = [0.223, 0.282], = 16.78, < 110-63), agreeableness (ùõΩ = 0.490, 95% CI = [0.462, 0.519], = 34.09, < 110-254), neuroticism (ùõΩ = 0.825, 95% CI = [0.797, 0.852], = 58.49, < 110-323), and openness (ùõΩ = 0.268, 95% CI = [0.238, 0.298], = 17.41, < 110-68), than Qwen-2.5-32B-IT. In contrast, conscientiousness diversity is lower in DeepSeek-R1 (ùõΩ = 0.291, 95% CI = [0.317, 0.265], = 21.90, < 110-106) and QwQ32B (ùõΩ = 0.402, 95% CI = [0.435, 0.369], = 23.79, < 110-125), suggesting that the reasoning model voices appear more consistently engaged and dutiful. The particularly large effects for agreeableness and neuroticismtraits associated with interpersonal harmony and emotional reactivitysuggest that reasoning models generate perspectives that more frequently disagree with and challenge one another. Interestingly, this pattern aligns with prior literature on human team diversity, which suggests that variability in extraversion and neuroticism enhances team performance, whereas variability in conscientiousness impairs it 21,65. We next examine expertise diversity, defined as the dispersion of conversing agents within the embedding space of inferred domain expertise descriptions. For example, when perspectives drawing on what the models judge as expertise in theoretical physics, analytic reasoning, finance, and creative writing co-occur in the same reasoning trace, the mean distance between their expertise embeddings manifests as large (Fig. 3b). As shown in Fig. 3c, DeepSeek-R1 exhibits significantly higher expertise diversity (ùõΩ = 0.179, 95% CI = [0.161, 0.196], = 20.11, < 110-89) than DeepSeek-V3, and QwQ-32B shows higher expertise diversity (ùõΩ = 0.250, 95% CI = [0.231, 0.269], = 25.50, < 110-142) than Qwen-2.5-32B-IT, across its implicit reasoning agents than non-reasoning models. To examine whether the personalityand expertise-related diversity observed in DeepSeek-R1s and QwQ-32Bs reasoning traces is reflected in the internal representation space of LLMs, we analyze activations of DeepSeek-R1-Llama-8Bs sparse autoencoder (SAE) features. Prior work has shown that high-level persona traits, such as personalities, cultural perspectives, and topics, are linearly represented in LLM activation space and can be steered 6,66,67. We steer conversational feature (i.e., Feature 30939; discourse marker for surprise, realization, or acknowledgment) with strength of +10 or 10 inside the activation space of DeepSeek-R1-Llama-8B, and probe how personalityand expertise-related features are activated in the steered reasoning traces (see Methods: SAE feature steering). We first classify each of the 32,768 features as personality-related (e.g., eagerness, expressions of frustration), expertise-related (e.g., programming terminology, financial concepts), or other using an LLM-as-judge approach. We quantify diversity using two complementary measures: coverage, the number of unique personalityor expertise-related features activated across the reasoning trace, and entropy, which captures how evenly activations are distributed across tokens rather than concentrated in few. Using DeepSeek-R1 reasoning traces, we show that these traces indeed activate more diverse personality-related and expertise-related features, which corroborates our earlier LLM-as-judge results 11 Reasoning Models Generate Societies of Thought Fig. 3. Personality and expertise diversity in reasoning traces. a, Personality diversity of implicit reasoning perspectives inferred from each reasoning trace using an LLM-as-judge and the BFI-10 (10-Item Big Five Personality Inventory). For each Big Five dimension, diversity is quantified as the standard deviation across inferred personalities. Reasoning models (DeepSeek-R1 and QwQ-32B) exhibit markedly higher diversity in openness, neuroticism, agreeableness, and extraversion. Kernel density estimation (KDE) plots show the distribution of personality traits across reasoning traces. b, Embedding space of expertise identified by the LLM-as-judge, projected into two dimensions using UMAP and rendered with an energy-minimization layout, revealing coherent and consistent skill proximities. c, Expertise diversity of implicit reasoning perspectives inferred from each reasoning trace, measured as the mean cosine distance between each expertise-related embedding and the centroid of all embeddings in the semantic space. Reasoning models exhibit substantially greater expertise diversity than non-reasoning models. d, Sparse autoencoder (SAE) schema and feature identification underlying the steering experiments. e, Design of the steering experiment. SAE feature 30939capturing discourse marker for surprise, realization, or acknowledgment indicative of persona and perspective shiftsis increased or decreased with steering strength of 10. Example reasoning traces illustrate that negative steering induces linear chain-of-thought trajectories, no steering yields subtle perspective shifts enabling self-checking, and positive steering induces frequent and pronounced perspective shifts that explore fundamentally different solution strategies. f, g, Distributions of coverage and entropy for SAE personality-related (f) and expertiserelated (g) features under feature 30939 steering. Error bars indicate 95% confidence intervals; solid horizontal lines denote medians and dashed lines indicate interquartile ranges (25th75th percentiles). 12 Reasoning Models Generate Societies of Thought (see Extended Data Fig. 6). For statistical tests, we control for reasoning trace length and problem fixed effects to show that steering conversational surprise activates genuinely more diverse features rather than simply producing longer outputs. As shown in Fig. 3ef, steering with +10 strength causes reasoning traces to activate wider coverage of both personality-related features (ùõΩ = 315.915, 95% CI = [277.320, 354.509], = 16.04, < 110-323) and expertise-related features (ùõΩ = 391.312, 95% CI = [313.743, 468.880], = 9.89, < 110-323) compared to unsteered traces, controlling for reasoning trace length and problem fixed effects. For example, after steering, personality-related features such as informal expressions of confusion or frustration (Feature 21065), phrases related to social interaction and community engagement (Feature 26139), and references to emotional or sensational themes in narratives (Feature 14476) are activated more frequently (see Supplementary Table 4 and 5). To further examine that this increased diversity reflects broader distribution of activated features rather than simply generating more tokens, we measure the Shannon entropy of feature activations. Higher entropy indicates that activations are more evenly distributed across diverse features, rather than concentrated in few dominant ones. Steered traces exhibit higher entropy of both personalityrelated features (ùõΩ = 0.262, 95% CI = [0.227, 0.298], = 14.48, < 110-323) and expertise-related features (ùõΩ = 0.096, 95% CI = [0.075, 0.117], = 9.02, < 110-323) than unsteered traces, confirming that steering induces more diverse feature activations beyond merely increasing output length. Reinforcement Learning Experiments To further examine whether LLMs self-reinforce conversational behaviours when rewarded for correct answers, we implement self-taught reinforcement learning (RL) experiment. In this setup, the model explores solution strategies for the Countdown arithmetic puzzle game 8,52, where the model must combine given set of numbers using basic arithmetic operations (+, , , ) and parentheses to reach target. We also replicate these findings on political misinformation detection, where models discriminate between true and fabricated political headlines. Following the reward architecture of DeepSeek-R1 4, we reward accuracy and correct format (i.e., wrapping reasoning between <think> and </think> tags and answers between <answer> and </answer> tags) with simple weighted reward: accuracy 0.9 + format 0.1. Crucially, we do not directly reward conversational or cognitive behaviours. We implement Proximal Policy Optimization (PPO) 68 using the Verl framework 69, training for 250 steps (see Supplementary Table 6 for hyperparameters). We use Qwen-2.5-3B, pre-trained model without any instruction-tuning, prompted to solve the Countdown task with chain of thought (see Methods: Reinforcement learning experiments). We first examine whether conversational behaviours spontaneously increase despite not being directly rewarded. Fig. 4a presents the results, showing that accuracy improves substantially over training, rising from near zero at baseline to approximately 58% by step 250. Fig. 4b reveals that the frequency of conversational behavioursparticularly Question & Answering and Conflict of Perspectives rise throughout training despite receiving no direct reward. Perspective shifts also increase until approximately step 160, although they start to decrease as the model becomes able to reach answers with fewer shifts across the training phase. Fig. 4c-d illustrate this qualitative shift: at step 40, the model produces mechanical, enumerative chain-of-thought-style reasoning, whereas by step 120, two distinctive simulated personas have appeared, recognizing their collectivity with the pronoun we expressing uncertainty (Again no luck), considering alternatives (Maybe we can try using negative numbers), and reflecting on problem constraints. As shown in Fig. 4e, these behaviours occur while 13 Reasoning Models Generate Societies of Thought the model employs two distinct personas according to LLM-as-judge evaluation: methodical problemsolver high in Conscientiousness and low in Openness, and an exploratory trial-and-error thinker high in Openness and Extraversion, with metacognitive reflection on solvabilitymarked by Neuroticism mediating between the two. Similar to our earlier findings based on sparse autoencoders, the increase of these behaviours has co-occurred with the increase of other cognitive behaviours, such as verification and backtracking (Extended Data Fig. 7). To corroborate the role of conversational behaviours in reasoning improvement, we compare RL training under three conditions: (1) Baseline (RL only, no priming), (2) Conversation fine-tuning (supervised fine-tuning on multi-agent dialogue text before RL), and (3) Monologue fine-tuning (fine-tuning on monologue-like, step-by-step reasoning traces before RL). To generate conversational fine-tuning data, we prompt Qwen-2.5-32B-IT to produce multi-agent-like dialogues with two, three, or four distinct personas solving 8,262 reasoning tasks (see Methods: Data), and sample 600 instances that reach correct answers (500 for training, 100 for validation). In these dialogues, the model first defines distinct personas with different personality traits and expertise (e.g., <persona1> meticulous mathematician with strong background in number theory </persona1>, <persona2> quickwitted and intuitive problem solver... not afraid to challenge assumptions </persona2>). These personas then engage in turn-taking dialogue where they build on, question, and correct each others reasoning (e.g., <think1> We can discard (2, 7) because... they are not coprime. </think1> <think2> Wait second. We cant discard (2, 7) just yet... they are indeed coprime because their greatest common divisor is 1. </think2> <think1> Youre right. overlooked that. </think1>), before converging on final answer in <group_solution> . . . </group_solution>. For monologue fine-tuning data, we generate standard chain-of-thought traces for the same problems with correct answers, where single voice reasons within <think> . . . </think> tags (e.g., <think> Since the GCD of and is 8, we can express and as 8a and 8b respectively, where and are coprime... The pairs of factors of 14 are (1, 14) and (2, 7). </think>). Supplementary Table 7 presents full examples for both types of fine-tuning data. We then fine-tune Qwen-2.5-3B on these datasets using standard next-token prediction loss wherein the models learn to reproduce the full output sequence (persona definitions, turn-by-turn reasoning or monologue trace, and final answer) given only the problem as input. This priming phase familiarizes the model with conversational versus monologue formats before RL optimizes for task accuracy (see Supplementary Table 8 for SFT hyperparameters). Extended Data Fig. 8 shows that models fine-tuned on conversational data achieve faster accuracy gains than monologue-fine-tuned models, particularly in the early stages of training. At step 40, conversation-fine-tuned Qwen-2.5-3B models reach approximately 38% accuracy while monologuefine-tuned models remain at 28%. This pattern replicates across architectures: in Llama-3.2-3B (see Supplementary Methods: Replications on Llama-3.2-3B), the conversation-fine-tuned model reaches 11% accuracy at step 70 compared to just 5% for monologue-fine-tuned models. Interestingly, in Llama-3.2-3B, the divergence becomes more striking as training progresses. By step 150, conversationfine-tuned Llama models achieve 40% accuracy while monologue-fine-tuned models plateau around 18%, less than half the performance. Notably, both conditions are trained on identical problems and correct answers, yet conversation-fine-tuned models consistently improve faster and reach higher asymptotic accuracy. This indicates that conversational structure itself, not merely exposure to correct solutions or task-related knowledge, drives the improvement. We further test whether conversational scaffolding transfers across domains. Models fine-tuned on multi-agent dialogues for the Countdown task are evaluated on qualitatively different task: political misinformation detection, where models discriminate between true and fabricated headlines from 23,299 fact-checked claims from PolitiFact. Despite never encountering this domain during 14 Reasoning Models Generate Societies of Thought Fig. 4. Occurrence of social behaviours in accuracy-rewarded reinforcement learning and the effect of fine-tuning with conversational scaffolding. a, Comparison of the accuracy trajectory of reinforcement learning rewarded with problem-solving accuracy for the baseline Qwen-2.5-3B model and the same model initially fine-tuned to simulate social interaction through multi-agent dialogue generated by Qwen-2.5-32B. The socially initialized model reaches maximum accuracy more rapidly, whereas the baseline model eventually catches up and does so by adopting conversational behaviours, including questioning and answering, perspective shifts, and perspective conflict. b, Trajectories of individual conversational behaviours within the reinforcementlearned baseline model from panel a. Question-and-answer behaviour emerges first, followed by perspective shifts and conflicts, which rise in close synchrony. Reconciliation behaviour shows little increase, suggesting that individual approaches compete rather than forming an effective ensemble. Lines are smoothed using an exponential moving average (span = 9), and shaded regions indicate 95% confidence intervals. cd, Comparison of the Qwen-2.5 baseline model at training step 40 versus step 120. At step 40, the model primarily engages in linear chain-of-thought reasoning, whereas by step 120, two distinctive simulated personas have emerged that explicitly recognize their collectivity through the use of the pronoun we. e, Personality profiles inferred by the LLM-as-judge. The step-40 model exhibits strong all-around problem-solving profile, characterized by high conscientiousness, moderately high openness and agreeableness, lower extraversion, and notably low neuroticism. In contrast, the two collaborative agents observed at step 120 display differentiated personality profiles: one emphasizes trial-and-error problem solving, while the other specializes in metacognitive reasoning about problem solvability across alternative approaches. The trial-and-error agent is less extraverted and more agreeable than the step-40 agent, whereas the solvability-focused agent is more open and substantially less conscientious. 15 Reasoning Models Generate Societies of Thought fine-tuning, conversation-primed models achieve faster accuracy gains than baseline models (see Supplementary Methods: Cross-domain reasoning transfer and Extended Data Fig. 9). Together, these results suggest that conversational structure facilitates the emergence of reasoning strategies during RL."
        },
        {
            "title": "Discussion",
            "content": "Our findings suggest that reasoning models like DeepSeek-R1 do not simply generate longer or more elaborate chains of thought. Rather, they exhibit patterns characteristic of social and conversational process generating societies of thoughtposing questions, introducing alternative perspectives, generating and resolving conflicts, and coordinating diverse socio-emotional roles. These interactional patterns rarely occur in non-reasoning models across different model sizes (671B, 70B, 32B, 8B), even when controlling for reasoning trace length, suggesting that reasoning optimization introduces an intrinsic social structure within the reasoning process itself rather than merely increasing text volume. The model appears to reason by simulating internal societies, structuring thought as an exchange among interlocutors rather than as single uninterrupted voice. The implication here is that social reasoning emerges autonomously through RL as function of its consistent ability to produce correct answers, rather than through explicit human supervision or fine-tuning. This structure does not appear to be merely stylistic. Conversational behaviours and socio-emotional roles are more frequently activated when DeepSeek-R1 faces more difficult problems, and they explain substantial portion of the accuracy advantage over non-reasoning models. Steering experiments provide evidence that conversational markers are tied to reasoning performance. When we amplify feature associated with conversational surprisea discourse marker signaling perspective shift and constrastaccuracy on multi-step reasoning tasks doubles. Structural equation modeling reveals that conversational steering is associated with accuracy through both direct effects and indirect pathways mediated by cognitive strategies previously identified as central to reasoning, including verification, backtracking, subgoal setting, and backward chaining. This suggests that the social structure of reasoning might not be epiphenomenal but mechanistically implicated in how the model explores solution spaces and deploys effective problem-solving strategies. We further find that this interactional organization is supported by diversity among multiple implicit voices within reasoning traces. These voices vary systematically in personality traits and domain expertise, and mechanistic interpretability analyses corroborate that models activate more diverse personalityand expertise-related features when steered toward conversational markers. This pattern suggests that findings from human team researchwhere diversity in socially oriented traits such as extraversion and neuroticism enhances collective performance, whereas diversity in task-oriented traits such as conscientiousness can impair coordination and efficiency 21,65may offer useful lens for interpreting language models collective reasoning behaviours. Most R1 reasoning personas were surprisingly disciplined and hard-working! Reinforcement learning (RL) experiments further support the functional role of conversational structure. Models fine-tuned on multi-agent dialogues learn to reason more effectively than models finetuned only on correct, monologue-like reasoning traces. The benefit therefore lies not in the correctness of initial reasoning but in the procedural scaffolding provided by conversational organization. Although these experiments used relatively small 3B-parameter models (Qwen-2.5-3B and Llama-3.2-3B) on simple arithmetic tasks and misinformation detection tasks, the results suggest that even minimal social structuring within reasoning traces can accelerate the emergence of generalizable reasoning behaviour. Collectively, these findings suggest the benefits of studying social scaling in reasoning-optimized Reasoning Models Generate Societies of Thought models. As their test-time computations expand, reasoning traces evolve from isolated monologues into structured dialogues among differentiated internal perspectives. High-performing reasoning thus seems to depend on how attention, role-taking, and conflict resolution are coordinated within emergent societies of thought. Our goal is not to take sides on whether reasoning model traces should be regarded as discourse among simulated human groups or computational minds simulation of such discourse. Indeed, as we note above, even this distinction becomes fundamentally unclear as some theories of cognition posit how mature individual minds develop from simulations of multiagent interaction. Nevertheless, alignments between our findings on successful reasoning models and prior literature on successful human teams (e.g., diverse personality traits lead to successful collaborations) suggest that principles governing effective group collaboration may offer valuable insights for interpreting and engineering reasoning behaviours in language models. This perspective extends long-standing research on human team collaboration, where group composition and diversity are known to shape collective intelligence through variations in personality and expertise 11,1621 . Analogous dynamics within AI systems remain largely unexplored. Early investigations of humanAI collaboration 70 have begun to characterize this emerging domain, but how diversity and coordination operate within the reasoning traces of large language models remains an open question. DeepSeekR1s and QwQs internal reasoning patterns suggest that such models may already self-organize productive heterogeneity of perspectives, implying that diversity could be as fundamental to artificial reasoning as it is to human collaboration and collective dominance. growing trend in AI involves agentic architectures that deploy multiple agents engaged in more complex configurations than single-channel debate, including hierarchy, complex networks and even entire institutions of interacting agents 34,4246,71,72. Our work suggests the importance of exploring alternative structures, but also inhabiting them with diverse perspectives, personalities, and specialized expertise that drive complementarity and collective success in the human social world. Understanding how diversity and social scaffolding interact could shift how we conceptualize large language models, from solitary problem-solving entities toward collective reasoning architectures, where intelligence arises not merely from scale but the structured interplay of distinct voices. 17 Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Methods",
            "content": "Data We generate chains of thought and final answers for 8,262 reasoning problems spanning symbolic logic, mathematical problem solving, scientific reasoning, instruction following, and multi-agent inference. The benchmark suite includes BigBench Hard (BBH) tasks requiring multi-step logical inference, reference tracking, and compositional reasoning; GPQA (Graduate-level Physics Question Answering) for graduate-level STEM reasoning; MATH (Hard) subset for multi-step derivations across algebra, geometry, probability, and number theory; MMLU-Pro for advanced conceptual knowledge; IFEval for instruction-following consistency; and MUSR (Mathematics Understanding and Symbolic Reasoning) for symbolic manipulation and structured mathematical reasoning (see Supplementary Table 9 for details). We generate responses using six models: two reasoning modelsDeepSeek-R1-0528 (671B parameters) and QwQ-32Band four instruction-tuned modelsDeepSeek-V3-0324 (671B parameters), Qwen-2.5-32B-Instruct, Llama-3.3-70B-Instruct, and Llama-3.1-8B-Instructunder zero-shot setting. DeepSeek-V3 is the instruction-tuned model based on DeepSeek-V3-Base from which DeepSeekR1 is derived through reinforcement learning, and Qwen-2.5-32B-Instruct is the instruction-tuned model based on Qwen-2.5-32B from which QwQ-32B is derived. For brevity, we refer to these models as DeepSeek-R1, QwQ-32B, DeepSeek-V3, Qwen-2.5-32B-IT, Llama-3.3-70B-IT, and Llama-3.1-8B-IT, respectively. We set the temperature to 0.6, temperature recommended for standard reasoning tasks 4. Measurements Conversational Behaviours We identify four conversational behaviours in reasoning traces using an LLM-as-judge approach with Gemini-2.5-Pro. (1) Questionanswering is defined as sequences where question is posed and later answered, as in conversations (e.g., Why...? Because..., What if...? Then. . . , How do we know? Well. . . , and Lets try X...? This gives us Y). (2) Perspective shift is defined as transition to different idea, viewpoint, assumption, or approach, as in conversations. (3) Conflict of perspectives is defined as expressions of disagreement, correction, or tension with another perspective (e.g., Wait, that cant be right. . . , No, actually. . . , and This contradicts. . . ). (4) Reconciliation is defined as instances where conflicting views are integrated or resolved into coherent synthesis (e.g., So perhaps both are true if. . . , Combining these insights. . . , and This resolves the tension. . . . For each reasoning trace, the LLM-as-judge counts the number of distinct instances of each behaviour, returning integer counts (0 if none are present). The full prompt is provided in Supplementary Methods: LLM-as-judge prompts. See Supplementary Table 10 for the descriptive statistics of conversational behaviors for reasoning and instruction-tuned models. For the four conversational categories, Gemini-2.5-Pro and GPT-5.2 demonstrated substantial agreement: Question-and-Answering (ICC(3,1) = .856), Perspective Shift (ICC(3,1) = .849), Conflict of Perspectives (ICC(3,1) = .912), and Reconciliation (ICC(3,1) = .804), with mean ICC of .855. Gemini-2.5-Pro also showed agreement with human ratings across the four conversational categories: Question-and-Answering (ICC(3,1) = .634), Perspective Shift (ICC(3,1) = .737), Conflict of Perspectives (ICC(3,1) = .864), and Reconciliation (ICC(3,1) = .664). Socio-Emotional Roles We analyze the presence of socio-emotional roles within reasoning traces using Bales Interaction Process Analysis (IPA) framework 55. The IPA classifies utterances into 12 interaction roles, each operationally defined in the prompt with specific behavioural descriptions. The 18 Reasoning Models Generate Societies of Thought LLM-as-judge (Gemini-2.5-Pro) counts the number of distinct instances of each of the 12 categories separately, and we aggregate these counts into four higher-level categories for our main analyses: Information-giving roles: Gives suggestion (gives direction, implying autonomy; e.g., should..., need to..., let us...) Gives opinion (gives evaluation, analysis, expresses feeling or wish) Gives orientation (provides objective or verifiable information, repeats, clarifies, confirms) Information-asking roles: Asks for suggestion (requests possible ways of action or direction) Asks for opinion (requests evaluation, analysis, or expression of feeling) Asks for orientation (requests information, repetition, or confirmation) Positive emotional roles: Shows solidarity (raises others status, gives help, reward) Shows tension release (jokes, laughs, shows satisfaction) Agrees (shows passive acceptance, understands, concurs, complies) Negative emotional roles: Shows antagonism (deflates others status, defends or asserts self) Shows tension (expresses uncertainty, asks for help, withdraws from the field) Disagrees (shows passive rejection, formality, or withholds help) Inter-rater reliability is substantial for the four higher-level IPA categories used in our main analyses: Ask (Gemini-2.5-Pro vs. GPT-5.2: ICC(3,1) = .939; Gemini-2.5-Pro vs. Human: ICC(3,1) = .836), Give (ICC(3,1) = .864; ICC(3,1) = .666), Positive (ICC(3,1) = .939; ICC(3,1) = .870), and Negative (ICC(3,1) = .838; ICC(3,1) = .779). See Supplementary Table 10 for the descriptive statistics of socio-emotional roles for reasoning and instruction-tuned models. To measure whether socio-emotional roles co-occur reciprocally within reasoning traces, we compute the Jaccard index for two role pairs: (1) asking versus giving for task-oriented roles, and (2) positive versus negative for emotional roles. The Jaccard index is defined as the number of reasoning traces containing both roles in pair divided by the number of reasoning traces containing either role, capturing whether models coordinate complementary roles within the same trace rather than deploying them in isolation. Higher Jaccard indices indicate more balanced, dialogue-like interaction patterns, whereas lower indices suggest one-sided, monologic reasoning. Cognitive Behaviours We identify four cognitive behaviours previously established as contributors to reasoning accuracy in language models using Gemini-2.5-Pro as LLM-as-judge 4,8,3537. For the measurement, we adopt the prompt and examples used by Gandhi and colleagues (2025) 8, which has been verified by multiple human raters. Each behaviour is operationally defined in the prompt with specific examples to guide annotation: Verification is defined as instances where the chain-ofreasoning explicitly checks the current result against the target solution. The prompt provides specific examples: This sequence results in 1, which is not equal to 22 and Since 25 is not equal to 22. Backtracking is defined as instances where the model realizes path wont work and explicitly goes back to try different approach. Subgoal setting is defined as instances where the model breaks down the problem into smaller, intermediate goals. Backward chaining is defined as instances where the model starts from the target solution and works backwards to the initial problems. 19 Reasoning Models Generate Societies of Thought For the four cognitive reasoning behaviors, Gemini-2.5-Pro and GPT-5.2 demonstrate good to excellent agreement: Answer Verification (ICC(3,1) = .995), Backtracking (ICC(3,1) = .829), Subgoal Setting (ICC(3,1) = .810), and Backward-Chaining (ICC(3,1) = .756), with mean ICC of .848. Gemini-2.5Pro also shows substantial agreement with human rater across the four cognitive behaviors: Answer Verification (ICC(3,1) = .981), Backtracking (ICC(3,1) = .921), Subgoal Setting (ICC(3,1) = .559), and Backward-Chaining (ICC(3,1) = .578), with mean ICC of .760. These reliability estimates are computed on 30 reasoning traces to solve general-purpose reasoning problems (see Methods: Data) and 50 reasoning traces generated during reinforcement learning of Qwen-2.5-3B (see Methods: Reinforcement Learning Experiments). Problem Complexity We measure problem complexity using two complementary approaches. First, we use LLM-as-judge ratings. Gemini-2.5-Pro rates each problem on 7-point Likert scale. The prompt instructs the model to rate the intrinsic difficulty of the problem for capable language model under zero-shot conditions using the following scale: 1 = very easy, 2 = easy, 3 = somewhat easy, 4 = moderate, 5 = somewhat difficult, 6 = difficult, 7 = very difficult. The full prompt is provided in Supplementary Methods: LLM-as-judge prompts. Second, we use empirical error rates. We compute the number of incorrect answers across four instruction-tuned models (DeepSeek-V3, Qwen-2.5-32B-IT, Llama-3.3-70B-IT, Llama-3.1-8B-IT), yielding score from 0 to 4 representing the number of models that failed to answer correctly. After sampling and annotating 50 reasoning problems, we find substantial inter-rater reliability between Gemini-2.5-Pro and GPT-5.2 (ICC(3,1) = .745). Gemini-2.5-Pros complexity scores show strong correlation with non-reasoning models error rates (Spearmans ùúå = 0.526, 95% CI = [0.508, 0.543], = 46.26, < 110-323, = 7,738), confirming convergent validity between the two measures. Statistical Analyses To estimate whether observed differences between reasoning models (DeepSeek-R1 and QwQ-32B) and instruction-tuned baselines arise from conversational behaviours or socio-emotional roles rather than from task heterogeneity or reasoning trace length, we estimate the following linear probability model for each behavioural outcome Yij, which is binary variable. ùëåùëñ ùëó = ùëö ùëÄ ùõΩùëö ùëÄùëúùëëùëíùëôùëö,ùëñ ùëó + ùõæùëôùëúùëî(ùêøùëíùëõùëñ ùëó) + ùõº + ùúáùëñ + ùúÄùëñ ùëó where indexes individual task problems, and indexes individual reasoning traces generated by different models. Yij equals 1 if the reasoning trace exhibits the behavior more than once. ùëÄùëúùëëùëíùëôùëö,ùëñ ùëó is categorical dummy variable that equals 1 if reasoning trace for problem is generated by model m, and 0 otherwise, where ùëÄ = {ùê∑ùëíùëíùëùùëÜùëíùëíùëò_ùëü1, ùê∑ùëíùëíùëùùëÜùëíùëíùëò_ùë£3, ùëÑùë§ùëÑ_32ùëè, ùëÑùë§ùëíùëõ_2.5_32ùëè_ùëñùë°, ùêøùëôùëéùëöùëé_3.3_70ùëè_ùëñùë° ùêøùëôùëéùëöùëé_3.1_8ùëè_ùëñùë°} Either DeepSeek-V3 or Qwen-2.5-32B-IT serves as the reference category and is excluded, such that each coefficient ùõΩm represents the marginal difference in the outcome relative to DeepSeek-V3 or Qwen-2.5-32B-IT. Log(Lenij) denotes the reasoning trace length (i.e., the number of words in each reasoning trace), adjusting the extreme skewness of reasoning trace length (see Extended Data Fig. 1). ùúáùëñ represents task fixed effects at the individual problem level, absorbing all variation associated with each problems intrinsic difficulty, phrasing, and topical content. This ensures that comparisons between models are made within the same problem rather than across heterogeneous tasks. ùõº is the intercept. Robust standard errors are clustered at the task level to account for within-task correlation. Models are estimated using StataNow/SE 19.5. 20 Reasoning Models Generate Societies of Thought SAE Feature Steering To investigate the role of conversational behaviours in reasoning, we employ sparse autoencoders (SAEs) to identify and manipulate interpretable features in the models activation space. SAEs decompose neural network activations into sparse set of linear features, enabling targeted intervention on specific behavioural dimensions without altering model weights 5658.We use an SAE trained on Layer 15s residual stream activations of DeepSeek-R1-Llama-8B (15-llamascope-slimpj-res-32k). The SAE has been trained on SlimPajama, general-purpose corpus containing both conversational and non-conversational texts, with dictionary size of 32,768 features (see Supplementary Table 3 for hyperparameters). To identify features associated with conversational contexts, we follow standard interpretability pipeline. For each of the 32,768 features, we sample approximately 50 contexts from the pretraining corpus where the feature activates most strongly. We then use an LLM-as-judge classifier (Gemini-2.5-flash-lite) to determine whether each activation context represents conversational setting, computing conversation ratio for each featurethe proportion of activations occurring in conversational contexts. We apply two filtering criteria: (1) conversation ratio above 50%, and (2) activation near sentence onsets 50% or more (within the first four tokens). From the candidate features, we select Feature 30939, which the LLM judge summarized as discourse marker for surprise, realization, or acknowledgment. This feature activates on tokens such as Oh! in contexts involving turn-taking and social exchange. Feature 30939 exhibits conversation ratio of 65.7% (99th percentile among all features) while maintaining high sparsity (0.016% of tokens), indicating specificity to conversational phenomena rather than general linguistic patterns. We implement activation addition to steer Feature 30939 during generation. At each token generation step, we add the features decoder vector, scaled by steering strength s, to the models Layer 15 residual stream activations. ‚Ñé ùë° = ‚Ñéùë° + ùë† ùëë30939 where ‚Ñéùë° denotes the original activation at token position and d30939 denotes the decoder vector for Feature 30939. We first generate reasoning traces under seven steering conditions: ùë† {15, 10, 5, 0, 5, 10, 15}. As ùë† {15, 15} exhibits lower accuracy due to excessive steering, we use ùë† {10, 5, 0, 5, 10}. Reasoning Task and Evaluation We evaluate reasoning performance using the Countdown task, benchmark for multi-step arithmetic reasoning commonly used to evaluate LLM reasoning capabilities. In each problem, the model must combine set of input numbers using basic arithmetic operations (+, , , ) and parentheses to reach target value. For example, given inputs {25, 30, 3, 4} and target 32, valid solution is (30 25 + 3) 4 = 32. We use 1,024 problems. We use the following prompt template: Using the numbers [79, 17, 60], create an equation that equals 36. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>. Solutions are scored as correct if the final numerical answer matches the target value, evaluated using Gemini-2.5-flash-lite. After steering, we measure the frequency of conversational behaviours (questionanswering, perspective shift, conflict of perspectives, reconciliation) and cognitive behaviours (verification, backtracking, subgoal setting, backward chaining) in each generated reasoning trace using the LLM-as-judge procedures described above. To estimate behavioural differences across steering conditions, we estimate 21 Reasoning Models Generate Societies of Thought fixed-effects linear regression models for each behavioural count variable ùëåùëñ ùëó = ùë† { 10,5,0,5,10} ùõΩùë†ùëÜùë°ùëíùëíùëüùë†,ùëñ ùëó + ùõæùëôùëúùëî(ùêøùëíùëõùëñ ùëó) + ùõº + ùúáùëñ + ùúÄùëñ ùëó where indexes individual task problems, and indexes individual reasoning traces generated before or after steering. ùëÜùë°ùëíùëíùëüùëñ ùëó is categorical variable indicating steering strength. log(ùêøùëíùëõùëñ ùëó) denotes the log-transformed reasoning trace length (i.e., the number of words in each reasoning trace), adjusting the extreme skewness of reasoning trace length (see Extended Data Fig. 1). ùúáùëñ represents task fixed effects at the individual problem level, absorbing all variation associated with each problems intrinsic difficulty. Experiment Conditions To assess whether accuracy improvements are specific to conversational features rather than general property of SAE steering, we compare three conditions: (1) Feature 30939 (conversational surprise), (2) randomly selected conversational features (conversation ratio above mean and activating near sentence onset), and (3) randomly selected non-conversational features (conversation ratio below mean). For condition (1), we evaluate all 1,024 Countdown problems. For conditions (2) and (3), we randomly sample 300 features from each category and have each feature solve 16 randomly selected problems, yielding distribution of accuracy scores across features within each condition. For all conditions, steering strength is set to twice the maximum activation strength observed for that feature across sampled instances in SlimPajama-3B. We test for differences in accuracy between conditions using linear regression with problem fixed effects. Feature Diversity To examine whether steering conversational features induces greater activation of personalityand expertise-related features in the models internal representation space, we analyze sparse autoencoder (SAE) feature activations before and after steering. We use the same SAE employed in the steering experiments: an SAE trained on Layer 15s residual stream activations of DeepSeekR1-Llama-8B with dictionary size of 32,768 features. For each reasoning trace generated under different steering conditions (s {10, 0, +10}), we record which SAE features are activated at each token position by passing the Layer 15 activations through the SAE encoder. For each of the 32,768 SAE features, Neuronpedia provides textual description generated by prompting GPT-4o-mini with the top-activating token sequences. Using Gemini-2.5-flash-lite, we classify each feature description into one of three categories: personality-related, expertise-related, or other. Gemini-2.5-flash-lite first scores each feature from 0 to 100 based on whether it is related to personality traits or domain expertise (see Supplementary Methods: LLM-as-judge prompts). Then, we use the threshold of 50 to determine whether they are personality or expertise features. Among the 32,768 features, 5,455 are labeled as personality-related (e.g., eagerness, expressions of frustration) and 15,436 as expertise-related (e.g., programming terminology, financial concepts). For each reasoning trace, we compute two complementary measures of feature diversity within each category (personality-related or expertise-related). First, coverage is defined as the number of unique features within category (personality or expertise) that exhibit non-zero activation across all tokens in reasoning trace. Second, entropy is computed over the distribution of token counts that activate each SAE feature within given category. Each reasoning trace is represented as 32,768dimensional vector, where each element corresponds to the number of tokens within the reasoning trace that activated specific SAE feature. Entropy for category (personality or expertise) was then calculated as: 22 Reasoning Models Generate Societies of Thought ùêªùëê = ùëì ùëê ùëé ùëì log(ùëé ùëì ) where ùëé ùëì denotes the number of activating tokens for feature ùëì within category ùëê. Higher coverage indicates that the reasoning trace draws on broader range of personalityor expertise-related features. Higher entropy indicates that activations are more evenly distributed across features rather than concentrated in few dominant ones. For instance, reasoning trace with high coverage but low entropy explores diverse features but focuses primarily on small subset, whereas high coverage and high entropy suggest that reasoning draws on multiple feature types more evenly throughout the reasoning process. To examine the effect of conversational steering on feature diversity, we compare coverage and entropy across steering conditions (s {10, 0, +10}) for the same 1,024 Countdown problems. We estimate fixed-effects linear regression models with coverage or entropy as the outcome, steering strength as the predictor, and controls for log-transformed reasoning trace length and problem fixed effects. This specification isolates the effect of steering on feature diversity beyond mere changes in output length. Implicit Perspectives To quantify the diversity of reasoning perspectives within each reasoning trace, we use an LLM-asjudge protocol (Gemini-2.5-Pro) that performs three sequential tasks: (1) inferring the number of distinct perspectives present in the reasoning trace, (2) characterizing each perspectives personality traits and domain expertise, and (3) segmenting the reasoning trace by attributing each portion to specific perspective. Given complete reasoning trace, the LLM-as-judge first infers the number of distinct perspectives present. Then, for each identified perspective, the LLM-as-judge answers the 10 items of the BFI-10 (Ten-Item Big Five Inventory) 64 as if responding from that perspectives point of view. Each item (is generally trusting, tends to be lazy, is relaxed, handles stress well, has few artistic interests, is outgoing, is sociable, tends to find fault with others, does thorough job, gets nervous easily, and has an active imagination,) is rated on five-point scale from Disagree strongly to Agree strongly. Scores for each of the five personality dimensions (Extraversion, Agreeableness, Conscientiousness, Neuroticism, Openness) are computed as the mean of the two corresponding items, with reverse-coding applied where appropriate. Additionally, the LLM-as-judge generates concise free-form description of each perspectives domain expertise (e.g., Theoretical Physicist specializing in model abstraction, Software Engineer focusing on algorithmic efficiency). Finally, the LLM-as-judge attributes each segment of the reasoning trace to one of the identified perspectives, producing mapping that indicates which perspective generated each portion of the text. The full prompts, which elicit all three outputs in single structured JSON response, are provided in Supplementary Methods: LLM-as-judge prompts. Personality Diversity To quantify personality diversity within reasoning trace, we calculate the standard deviation of the five-dimensional personality vectors across implicit voices identified within the same reasoning trace. Let vij denote the score of the i-th implicit voice on the ùëó-th personality dimension ( ùëó = 1 , . . . , 5). For each dimension ùëó, the within-trace personality diversity Pj was computed as: 23 Reasoning Models Generate Societies of Thought ùëÉ ùëó = (cid:118)(cid:117)(cid:116) 1 ùëÅ ùëÅ ùëñ=1 (ùë£ùëñ ùëó ùë£ùëó)2 where is the number of implicit voices and ùë£ùëó = (cid:205)ùëÅ reasoning trace contained only single implicit voice, ùëÉ ùëó = 0. ùëñ=1 ùë£ùëñ ùëó is the mean score for dimension j. If Expertise Diversity Each implicit reasoning voices expertise is qualitatively profiled through concise textual description summarizing the domain expertise. Each statement was embedded using Googles EmbeddingGemma-300M model to obtain semantic vector representation ei for the i-th implicit voice (i=1, . . . , N) 73. To quantify expertise diversity within reasoning trace, we compute the mean cosine distance between each embedding and the centroid of all embeddings in the semantic space. Expertise diversity was defined as: ùê∏ = (cid:118)(cid:117)(cid:116) 1 ùëÅ ùëÅ ùëñ=1 (1 ùëíùëñ ùëí ùëíùëñ ùëí ) where ùëíùëñ ùëí denotes the inner product between embeddings and ùëí their vector norms. If reasoning trace contained only single implicit voice, ùê∏ = 0. Validation To validate the accuracy of the LLM-as-judge protocol, we use the Intelligence Squared Debates Corpusa dataset of human argumentative conversations (N = 1,196 conversations) among two to eight participants with known ground-truth speaker labels and biographical information. To ensure that the model cannot rely on superficial cues such as speaker tags or formatting, we remove all speaker labels and concatenate each dialogue into single block of text, mimicking the format of LLM reasoning traces. As shown in Extended Data Fig. 5, we find that the LLM-as-judge can accurately predict the number of distinct individuals (Spearmans ùúå = 0.86, 95% CI = [0.84, 0.87], = 44.7, < 110-323) and the number of distinct turns underlying each conversation (Spearmans ùúå = 0.89, 95% CI = [0.88, 0.90], = 49.2, < 110-323). To evaluate token-level speaker attribution accuracy, we construct ground truth by assigning each token to its true speaker based on the original transcript. We then extract the models predicted perspective segments and align them to the token stream. To match predicted perspective IDs (e.g., Perspective 1, Perspective 2) with the original speaker labels, we apply the Hungarian algorithma combinatorial optimization method that finds the one-to-one assignment between predicted IDs and true speakers that maximizes total token-level agreement. Speaker-level accuracy measures the proportion of tokens assigned to the correct speaker under this optimal mapping. When there are two speakers, accuracy is 82%; for three speakers, 76%; and for four speakers, 69%. Weighted by the distribution of predicted perspectives in LLM reasoning traces, overall accuracy is 73%. Because the Intelligence Squared Debates Corpus includes biographical information about debate participants, we further verify that expertise diversity inferred by the LLM-as-judge correlates with actual diversity among participants ground-truth biographies. We compute expertise diversity from LLM-inferred descriptions and compare it to diversity computed from true biographies, finding significant correspondence (Spearmans ùúå = 0.55, 95% CI = [0.51, 0.59], = 21.4, < 110-97). We further examine whether measurements based on LLM-as-judge are aligned with the measurements we get from SAE regarding personality and expertise diversity. Specifically, we feed reasoning traces Reasoning Models Generate Societies of Thought from DeepSeek-R1, DeepSeek-v3, Llama-3.3-70B-IT, and Llama-3.1-8B-IT into Llama-3.1-8B-IT and extract activations from SAE trained on its residual stream (Layer 16). We then identify personalityrelated and expertise-related features using the same LLM-as-judge prompting procedure described above. Extended Data Fig. 6 shows that DeepSeek-R1s reasoning traces activate significantly more diverse personality and expertise features than those of other models: both coverage (number of unique features activated) and entropy (distribution evenness across features) are substantially higher for DeepSeek-R1. This suggests the convergence between text-level behavioural coding and activation-level feature analysis. Reinforcement Learning Experiments Countdown Task Prompt We use the following prompt template: Using the numbers [79, 17, 60], create an equation that equals 36. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>. Experimental Conditions To test whether conversational scaffolding accelerates the emergence of reasoning during reinforcement learning (RL), we compare three conditions: 1. Baseline (RL only): The base model (Qwen-2.5-3B or Llama-3.2-3B) undergoes RL training without any prior fine-tuning. The model is prompted to solve Countdown problems with chain-of-thought reasoning, wrapping its reasoning in <think>...</think> tags and its final answer in <answer>...</answer> tags. 2. Conversation fine-tuning: The base model is first supervised-fine-tuned on multi-agent dialogue data before RL training. 3. Monologue fine-tuning: The base model is first supervised-fine-tuned on single-agent chain-ofthought traces before RL training. Supervised Fine-Tuning Datasets We construct fine-tuning datasets using Qwen-2.5-32B-IT as generator. We generate 3,600 multi-agent dialogues for Countdown problems, with 1,200 dialogues each for two-agent, three-agent, and four-agent settings. From these, we sample 600 dialogues that reach correct final solutions (200 each for 2-agent, 3-agent, and 4-agent settings; 500 for training, 100 for validation). See Supplementary Methods: SFT data generation prompts. Conversation Dataset Each conversational trace begins with persona definitions specifying distinct personality traits and expertise, followed by turn-taking reasoning where personas build on, question, and correct each other, and concludes with group consensus. For example: <persona1> Extrovert mathematician focused on arithmetic heuristics. </persona1> <persona2> Analytical engineer emphasizing step efficiency. </persona2> <think1> Lets first compute 30 25 = 5 to simplify the target space. </think1> <think2> That yields 5, we can now multiply by 4 to approach 20. </think2> <think1> Good idea. 5 4 = 20, but we need 32. </think1> <think2> Wait, let me recalculate... </think2> <group_consensus> The best sequence is (30 25 + 3) 4 = 32. </group_consensus> 25 Reasoning Models Generate Societies of Thought Monologue Dataset For the same 600 problems used in the conversation dataset, we generate standard single-agent chain-of-thought traces that reach correct answers. Each trace consists of step-by-step reasoning from single voice within <think>...</think> tags, followed by final answer. For example: <think> To reach 32 from {25, 30, 3, 4}, Ill try combining operations. 30 25 = 5. Then 5 + 3 = 8. Finally, 8 4 = 32. Let me verify: (30 25 + 3) 4 = 8 4 = 32. Correct. </think> <answer> (30 25 + 3) 4 = 32 </answer> Crucially, both datasets contain solutions to identical problems with identical correct answers, ensuring that any performance difference reflects the reasoning format rather than exposure to different solutions or task knowledge. Supervised Fine-Tuning Procedure Qwen-2.5-3B base model is supervised-fine-tuned on one of the two datasets using standard next-token prediction loss. Models learn to reproduce the full output sequenceincluding persona definitions and turn-by-turn reasoning (for conversation) or single-agent reasoning (for monologue), and final answergiven only the problem prompt as input. This priming phase familiarizes the model with conversation-like or monologue-like reasoning before RL optimizes for task accuracy. SFT hyperparameters are provided in Supplementary Table 8. See Supplementary Methods: Replications on Llama-3.2-3B for details on replicating these results in another model. Full generation prompts are provided in Supplementary Methods: Prompts. Reinforcement Learning Procedure Reinforcement learning is performed on the Countdown arithmetic puzzle, using PPO (Proximal Policy Optimization) with the Verl framework 68. While DeepSeek-R1 uses simplified version of PPO 68 called GRPO (Group Relative Policy Optimization) 74, we utilize PPO for the superior stability across hyperparameters 8. Preliminary analyses showed no significant difference in learning performance between PPO and GRPO (see Supplementary Methods: Performance comparison between PPO and GRPO). Reward is assigned as: ùëÖ = 0.9 { ùê¥ùëêùëêùë¢ùëüùëéùëê ùë¶} + 0.1 {ùê∂ùëúùëüùëüùëíùëêùë° ùêπùëúùëüùëöùëéùë°} Reasoning trace leads to the correct answer and 0 otherwise. Format is also binary, coded as 1 if the reasoning trace contains at least one reasoning block (<think> </think>) and one final answer block ( <answer> </answer>) providing single answer in equation form, and 0 otherwise. Crucially, we do not directly reward conversational or cognitive behaviours. Training proceeds for 250 steps. PPO hyperparameters are provided in Supplementary Table 6. To examine whether conversational behaviours emerge spontaneously during RL despite not being directly rewarded, we evaluate model performance on held-out validation set of 1,024 Countdown problems at each training checkpoint (every 10 steps). For each checkpoint, we generate reasoning traces for all validation problems and measure both accuracy and the frequency of conversational behaviours (questionanswering, perspective shift, conflict of perspectives, reconciliation) using the LLM-as-judge procedure described in Methods: Conversational behaviours. Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Acknowledgements",
            "content": "We are grateful to members of the Paradigms of Intelligence at Google and the Knowledge Lab at the University of Chicago for helpful comments throughout the research process. Extensive comments from Blake Richards, Roberta Rocca, and Rif A. Saurous were particularly helpful for improving the work. This work was completed in part with computing resources provided by the University of Chicagos Research Computing Center and Data Science Institute."
        },
        {
            "title": "Author Contributions",
            "content": "J.K., J.E., and N.S. collaboratively conceived and designed the study and the experiment setup. J.K., S.L., N.S., and J.E. drafted, revised, and edited the manuscript. J.K. and S.L. gathered and cleaned the data and performed the analysis. J.K. and J.E. produced the visualizations."
        },
        {
            "title": "Competing Interests",
            "content": "J.K., N.S., B.A., J.E. are employed by Google. S.L. declares no competing interests. 27 Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "References",
            "content": "[1] Brown, T. B. et al. Language models are few-shot learners. Advances in Neural Information Processing Systems, Vol. 33, 18771901 (2020). [2] Wei, J. et al. Emergent abilities of large language models. Transactions on Machine Learning Research (2022). [3] OpenAI. Learning to reason with LLMs. learning-to-reason-with-llms/ (2024). Accessed: 2025-11-7. https://openai.com/index/ [4] Guo, D. et al. DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning. Nature 645, 633638 (2025). [5] Snell, C., Lee, J., Xu, K. & Kumar, A. Scaling LLM test-time compute optimally can be more effective than scaling model parameters. The Thirteenth International Conference on Learning Representations, Vol. 2025, 1013110165 (2025). [6] Kim, J., Evans, J. & Schein, A. Linear representations of political perspective emerge in large language models. The Thirteenth International Conference on Learning Representations, Vol. 2025, 71807211 (2025). [7] Bricken, T. et al. Towards monosemanticity: Decomposing language models with dictionary learnhttps://transformer-circuits.pub/2023/monosemantic-features/index. ing. html (2026). Accessed: 2026-1-5. [8] Gandhi, K., Chakravarthy, A., Singh, A., Lile, N. & Goodman, N. D. Cognitive behaviors that enable self-improving reasoners, or, four habits of highly effective STaRs. Proceedings of the 2nd Conference on Language Modeling (2025). [9] Yao, S. et al. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems, Vol. 36, 1180911822 (2023). [10] Mercier, H. & Sperber, D. The Enigma of Reason (Harvard University Press, 2017). [11] Page, S. E. The Diversity Bonus: How Great Teams Pay Off in the Knowledge Economy (Princeton University Press, 2019). [12] Woolley, A. W., Chabris, C. F., Pentland, A., Hashmi, N. & Malone, T. W. Evidence for collective intelligence factor in the performance of human groups. Science 330, 686688 (2010). [13] Moshman, D. & Geil, M. Collaborative reasoning: Evidence for collective rationality. Think. Reason. 4, 231248 (1998). [14] Mesmer-Magnus, J. R. & Dechurch, L. A. Information sharing and team performance: metaanalysis. IEEE Eng. Manag. Rev. 40, 119136 (2012). [15] Bahrami, B. et al. Optimally interacting minds. Science 329, 10811085 (2010). [16] Hong, L. & Page, S. E. Groups of diverse problem solvers can outperform groups of high-ability problem solvers. Proc. Natl. Acad. Sci. U. S. A. 101, 1638516389 (2004). [17] Nemeth, C., Brown, K. & Rogers, J. Devils advocate versus authentic dissent: stimulating quantity and quality. Eur. J. Soc. Psychol. 31, 707720 (2001). Reasoning Models Generate Societies of Thought [18] Engel, D., Woolley, A. W., Jing, L. X., Chabris, C. F. & Malone, T. W. Reading the mind in the eyes or reading between the lines? theory of mind predicts collective intelligence equally well online and face-to-face. PLoS One 9, e115212 (2014). [19] DeChurch, L. A. & Mesmer-Magnus, J. R. The cognitive underpinnings of effective teamwork: meta-analysis. J. Appl. Psychol. 95, 3253 (2010). [20] Trouche, E., Sander, E. & Mercier, H. Arguments, more than confidence, explain the good performance of reasoning groups. J. Exp. Psychol. Gen. 143, 19581971 (2014). [21] Barrick, M. R., Stewart, G. L., Neubert, M. J. & Mount, M. K. Relating member ability and personality to work-team processes and team effectiveness. J. Appl. Psychol. 83, 377391 (1998). [22] Kim, J., Wang, Z., Shi, H., Ling, H.-K. & Evans, J. Differential impact from individual versus collective misinformation tagging on the diversity of twitter (x) information engagement and mobility. Nat. Commun. 16, 973 (2025). [23] Kross, E. & Grossmann, I. Boosting wisdom: distance from the self enhances wise reasoning, attitudes, and behavior. J. Exp. Psychol. Gen. 141, 4348 (2012). [24] Grossmann, I. & Kross, E. Exploring solomons paradox: self-distancing eliminates the self-other asymmetry in wise reasoning about close relationships in younger and older adults. Psychol. Sci. 25, 15711580 (2014). [25] Sun, Q., Zhang, H., Sai, L. & Hu, F. Self-distancing reduces probability-weighting biases. Front. Psychol. 9, 611 (2018). [26] Dunbar, R. I. M. The social brain. Curr. Dir. Psychol. Sci. 23, 109114 (2014). [27] D√°vid-Barrett, T. & Dunbar, R. I. M. Processing power limits social group size: computational evidence for the cognitive costs of sociality. Proc. Biol. Sci. 280, 20131151 (2013). [28] Bakhtin, M. Problems of Dostoevskys Poetics (University of Minnesota Press, 1984). [29] Hermans, H. J., Kempen, H. J. & Van Loon, R. J. The dialogical self: Beyond individualism and rationalism. Am. Psychol. 47, 2333 (1992). [30] Cooley, C. H. The looking-glass self. The production of reality: Essays and readings on social interaction 6, 126128 (1902). [31] Minsky, M. L. Society of Mind (Simon & Schuster, 1987). [32] Park, J. S. et al. Generative agents: Interactive simulacra of human behavior. Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology (ACM, New York, NY, USA, 2023). [33] Chan, C.-M. et al. ChatEval: Towards better LLM-based evaluators through multi-agent debate. The Twelfth International Conference on Learning Representations, Vol. 2024 (2024). [34] Liang, T. et al. Al-Onaizan, Y., Bansal, M. & Chen, Y.-N. (eds) Encouraging divergent thinking in large language models through multi-agent debate. (eds Al-Onaizan, Y., Bansal, M. & Chen, Y.-N.) Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 1788917904 (Association for Computational Linguistics, Stroudsburg, PA, USA, 2024). 29 Reasoning Models Generate Societies of Thought [35] Chen, Q. et al. Towards reasoning era: survey of long chain-of-thought for reasoning large language models (2025). Preprint at https://arxiv.org/abs/2503.09567. [36] Wang, S. et al. Beyond the 80/20 rule: High-entropy minority tokens drive effective reinforcement learning for LLM reasoning. Advances in Neural Information Processing Systems (2025). [37] Yeo, E., Tong, Y., Niu, M., Neubig, G. & Yue, X. Demystifying long chain-of-thought reasoning in LLMs (2025). Preprint at https://arxiv.org/abs/2502.03373. [38] Venhoff, C., Arcuschin, I., Torr, P., Conmy, A. & Nanda, N. Understanding reasoning in thinking language models via steering vectors (2025). Preprint at https://arxiv.org/abs/2506. 18167. [39] Galichin, A. et al. have covered all the bases here: Interpreting reasoning features in large language models via sparse autoencoders (2025). Preprint at https://arxiv.org/abs/ 2503.18878. [40] Ward, J., Lin, C., Venhoff, C. & Nanda, N. Reasoning-finetuning repurposes latent representations in base models (2025). Preprint at https://arxiv.org/abs/2507.12638. [41] Venhoff, C., Arcuschin, I., Torr, P., Conmy, A. & Nanda, N. Base models know how to reason, thinking models learn when (2025). Preprint at https://arxiv.org/abs/2510.07364. [42] Eo, S., Moon, H., Zi, E. H., Park, C. & Lim, H. Debate only when necessary: Adaptive multiagent collaboration for efficient LLM reasoning (2025). Preprint at https://arxiv.org/abs/ 2504.05047. [43] Zhang, J. et al. Exploring collaboration mechanisms for LLM agents: social psychology view. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1454414607 (Association for Computational Linguistics, Stroudsburg, PA, USA, 2024). [44] Chen, W. et al. AgentVerse: Facilitating multi-agent collaboration and exploring emergent behaviors. The Twelfth International Conference on Learning Representations (2024). [45] Du, Y., Li, S., Torralba, A., Tenenbaum, J. B. & Mordatch, I. Improving factuality and reasoning in language models through multiagent debate. Proceedings of the 41st International Conference on Machine Learning (2024). [46] Hu, Z., Chan, H. P., Li, J. & Yin, Y. Debate-to-write: persona-driven multi-agent framework for diverse argument generation. Proceedings of the 31st International Conference on Computational Linguistics, 46894703 (Association for Computational Linguistics, Abu Dhabi, UAE, 2025). [47] Lai, S. et al. Position: Evolving AI collectives enhance human diversity and enable self-regulation. Proceedings of the 41st International Conference on Machine Learning, Vol. 235, 2589225912 (2024). [48] Sumita, Y., Takeuchi, K. & Kashima, H. Cognitive biases in large language models: survey and mitigation experiments. Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing (SAC 25), 10091011 (ACM, 2025). [49] Wynn, A., Satija, H. & Hadfield, G. Talk isnt always cheap: Understanding failure modes in multi-agent debate (2025). Preprint at https://arxiv.org/abs/2509.05396. 30 Reasoning Models Generate Societies of Thought [50] Chen, W. et al. From yes-men to truth-tellers: Addressing sycophancy in large language models with pinpoint tuning. Proceedings of the 41st International Conference on Machine Learning (2024). [51] Feng, Y. et al. Unraveling misinformation propagation in LLM reasoning. Findings of the Association for Computational Linguistics: EMNLP 2025 (Association for Computational Linguistics, 2025). 2505.18555. [52] Gandhi, K. et al. Stream of search (SoS): Learning to search in language. Proceedings of the 1st Conference on Language Modeling (2024). [53] DeepSeek-AI et al. DeepSeek-V3 technical report (2024). Preprint at https://arxiv.org/ abs/2412.19437. [54] Grattafiori, A. et al. The llama 3 herd of models (2024). Preprint at https://arxiv.org/ abs/2407.21783. [55] Bales, R. F. set of categories for the analysis of small group interaction. Am. Sociol. Rev. 15, 257 (1950). [56] Cunningham, H., Ewart, A., Riggs, L., Huben, R. & Sharkey, L. Sparse autoencoders find highly interpretable features in language models. The Twelfth International Conference on Learning Representations (2024). [57] Bricken, T. et al. Towards monosemanticity: Decomposing language models with dictionary learning. https://transformer-circuits.pub/2023/monosemantic-features (2023). Accessed: 2025-11-7. [58] Templeton, A. et al. Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. https://transformer-circuits.pub/2024/scaling-monosemanticity/ (2024). Accessed: 2026-1-5. [59] Shen, Z. et al. SlimPajama-DC: Understanding data combinations for LLM training (2023). Preprint at https://arxiv.org/abs/2309.10818. [60] Bills, S. et al. Language models can explain neurons in language models. https: //openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html (2023). Accessed: 2026-1-5. [61] Paulo, G., Mallen, A., Juang, C. & Belrose, N. Automatically interpreting millions of features in large language models. Proceedings of the 42nd International Conference on Machine Learning (2025). [62] Parkinson, B., Fischer, A. H. & Manstead, A. S. R. Emotion in social relations: Cultural, group, and interpersonal processes (Psychology Press, London, England, 2004). [63] Wilkinson, S. & Kitzinger, C. Surprise as an interactional achievement: Reaction tokens in conversation. Soc. Psychol. Q. 69, 150182 (2006). [64] Rammstedt, B. & John, O. P. Measuring personality in one minute or less: 10-item short version of the big five inventory in english and german. J. Res. Pers. 41, 203212 (2007). [65] Mello, A. L. & Rentsch, J. R. Cognitive diversity in teams. Small Group Res. 46, 623658 (2015). [66] Turner, A. M. et al. Activation addition: Steering language models without optimization (2023). Preprint at https://arxiv.org/abs/2308.10248. 31 Reasoning Models Generate Societies of Thought [67] Chen, R., Arditi, A., Sleight, H., Evans, O. & Lindsey, J. Persona vectors: Monitoring and controlling character traits in language models (2025). Preprint at https://arxiv.org/ abs/2507.21509. [68] Schulman, J., Wolski, F., Dhariwal, P., Radford, A. & Klimov, O. Proximal policy optimization algorithms (2017). Preprint at https://arxiv.org/abs/1707.06347. [69] Sheng, G. et al. HybridFlow: flexible and efficient RLHF framework. Twentieth European Conference on Computer Systems (EuroSys 25) (2025). [70] Ju, H. & Aral, S. Collaborating with AI agents: Field experiments on teamwork, productivity, and performance (2025). Preprint at https://arxiv.org/abs/2503.18238. [71] Yang, J. et al. Topological structure learning should be research priority for LLM-based Multi-Agent systems (2025). Preprint at https://arxiv.org/abs/2505.22467. [72] Liu, Z., Zhang, Y., Li, P., Liu, Y. & Yang, D. dynamic LLM-powered agent network for taskoriented agent collaboration. Proceedings of the 1st Conference on Language Modeling (2024). [73] Vera, H. S. et al. EmbeddingGemma: Powerful and lightweight text representations (2025). Preprint at https://arxiv.org/abs/2509.20354. [74] Shao, Z. et al. DeepSeekMath: Pushing the limits of mathematical reasoning in open language models (2024). Preprint at https://arxiv.org/abs/2402.03300. 32 Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Extended Data Figures",
            "content": "Extended Data Fig. 1. Distribution of reasoning trace length. a, Kernel density plot showing the distribution of reasoning trace length, measured by the number of words per reasoning trace. b, Kernel density plot showing the distribution of log-transformed reasoning trace length. 33 Reasoning Models Generate Societies of Thought Extended Data Fig. 2. Conversation excerpt in DeepSeek-R1 reasoning traces. a, Representative excerpt from chemistry problem-solving trace showing multi-turn dialogue between distinct cognitive personas. Each utterance is annotated with conversational behaviors (blue) and socio-emotional roles (yellow). b, Big Five personality profiles for the five personas identified via LLM-as-judge. Radar charts display normalized trait scores (15 scale) for Extraversion (E), Agreeableness (A), Conscientiousness (C), Neuroticism (N), and Openness (O). Each persona exhibits domain expertise profiles. For detailed coding procedures and additional annotated examples, see Supplementary Methods: Annotated Examples. 34 Reasoning Models Generate Societies of Thought Extended Data Fig. 3. Bales detailed socio-emotional roles in chain-of-thought reasoning. a, Proportion of Bales 12 socio-emotional roles expressed in reasoning traces (see Fig. 1 for higher-level aggregations of the socio-emotional roles). b, Differences in problem complexity by the presence of detailed socio-emotional roles in DeepSeek-R1 (measured on 7-point Likert scale from 1 [extremely easy] to 7 [extremely difficult] using LLM-as-judge or by error rates in non-reasoning models). Points indicate mean complexity for reasoning traces where the behavior/role is present (red) or absent (blue). 35 Reasoning Models Generate Societies of Thought Extended Data Fig. 4. Mediation analysis linking reasoning models (DeepSeek-R1 and QwQ-32B) to accuracy advantages through simulated social behaviours. Mediation structure linking DeepSeek-R1 and QwQ-32B (relative to instruction-tuned models) to improved task accuracy through conversational behaviours and socio-emotional roles (red), cognitive reasoning behaviours (blue), and the indirect pathway through which social behaviors facilitate cognitive reasoning (orange) as estimated in structural equation model of labeled reasoning traces. Arrows denote direct and indirect effects. The direct pink pathway indicates the unmediated effect of DeepSeek-R1 and QwQ-32B on accuracy. *ùëù < 0.05, **ùëù < 0.01, ***ùëù < 0.001. a, Summary estimates following various model paths, such that conversational behaviors and socio-emotional roles (see Fig. 1 and Extended Data Fig. 1) directly and indirectly contribute to the accuracy improvement. To illustrate the relative contribution of each pathway, we report the proportional share of each pathway on model accuracy, calculated as the value of each pathway coefficient divided by the sum of coefficient values across all pathways. This demonstrates that more than 20% of accuracy is explained by the direct and indirect effect of social behaviours manifest in the reasoning trace. b, Coefficient matrices underlying the structural equation model (SEM), where labels in the figure index the estimates within the matrices. The red panels show the effects of DeepSeek-R1 and QwQ-32B on social behaviors and the effects of social behaviors on accuracy. The orange panel displays the effects of social behaviors on cognitive behaviors. The blue panels present the effects of DeepSeek-R1 and QwQ-32B on cognitive behaviors and the effects of cognitive behaviors on accuracy. Bolded coefficients indicate statistical significance (ùëù < 0.05). Full coefficient estimates are reported in Supplementary Table 1. 36 Reasoning Models Generate Societies of Thought Extended Data Fig. 5. LLM-as-judge benchmark results for identifying latent voices. Using the Intelligence Squared Debates Corpus (ùëÅ = 1,196 conversations), we validate the LLM-as-judges ability to identify distinct speakers when speaker labels are hidden, and dialogue is concatenated into single block of text. a, Predicted versus actual number of agents in each conversation (Spearmans ùúå = 0.86, ùëù < 1 10323). Violin plots show the distribution of predictions for each actual agent count; points and error bars indicate means and 95% confidence intervals. b, Predicted versus actual number of conversational turns (Spearmans ùúå = 0.89, ùëù < 1 10323). c, Speaker attribution accuracy as function of the number of agents. Accuracy is highest for two speakers (82%) and decreases as the number of speakers increases, but remains well above the random baseline (dashed line) across all conditions. Weighted accuracy across all conversations is 73%. d, Predicted expertise diversity (based on LLM-inferred descriptions and embeddings) versus actual biography diversity among debate participants (Spearmans ùúå = 0.55, ùëù < 1 1097), demonstrating that the LLM-as-judge captures meaningful variation in domain expertise that corresponds to ground-truth biographical differences. 37 Reasoning Models Generate Societies of Thought Extended Data Fig. 6. SAE-based personality and expertise diversity estimates applied to model activations in reasoning traces. a, Distribution of coverage and entropy for SAE personality-related features. b, Distribution of coverage and entropy for SAE expertise-related features. Error bars in all panels indicate 95% confidence intervals. The solid horizontal line indicates the median, and dashed lines denote the interquartile range (IQR, 25th75th percentiles). 38 Reasoning Models Generate Societies of Thought Extended Data Fig. 7. Fine-tuning with conversational scaffolding accelerates reasoning improvement during reinforcement learning. a, Trajectory of conversational behaviors in the Qwen-2.5-3B base model during reinforcement learning. Question-and-answering behavior emerges first and increases most rapidly, followed by conflict of perspectives and perspective shifts rising in parallel. Reconciliation remains low throughout, suggesting competing approaches rather than integration. The trajectory of model accuracy shows how the uptick of questions, answers, and interacting perspectives correlated with an acceleration in model improvement. b, Trajectory of cognitive behaviors in the same model. Verification increases most dramatically during training, following in lockstep with the presence of question asking and answering. This is followed by backtracking, which follows conflicts between perspectives. Subgoal setting and backward chaining show more modest gains before gradual decline. Shaded regions indicate 95% confidence intervals. 39 Reasoning Models Generate Societies of Thought Extended Data Fig. 8. Fine-tuning with dialogue vs. monologue scaffolding accelerates reasoning improvement during reinforcement learning. a, Accuracy trajectories during reinforcement learning on the Countdown task for Qwen-2.5-3B. b, Accuracy trajectories for Llama-3.2-3B. Models initially fine-tuned with multi-agent dialogues (red) reach high accuracy faster than models fine-tuned with monologue-style reasoning (blue), though both eventually converge. The base model without fine-tuning (default; light green colors) learns more slowly. 40 Reasoning Models Generate Societies of Thought Extended Data Fig. 9. Conversational scaffolding transfers to misinformation detection under reinforcement learning. a, Illustration of the Countdown task and the PolitiFact misinformation-detection task. b, Validation accuracy during RL on PolitiFact, comparing social interaction (red) and single-voice, default reasoning CoT (green) format. 41 Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Extended Data Tables",
            "content": "Extended Data Table 1. Reasoning traces before and after steering the conversational surprise feature (Layer 15, Feature 30939) Steering Reasoning Trace -10 0 <think> To create an equation using the numbers [46, 54, 54, 77] that equals 75, Ill start by looking for operations that can help achieve this total. First, Ill consider the sum of all four numbers: 46 + 54 + 54 + 77 = 231 Next, Ill explore subtracting specific combination to reduce the total to 75. Subtracting 77 from 231 gives: 231 - 77 = 154 Now, Ill look for way to reduce 154 further. Dividing 154 by 2 gives: 154 / 2 = 77 Since have two 54s, dividing one of them by 2 will utilize both 54s: 54 / 2 = 27 Finally, Ill combine these results to form the equation: (46 + 54) / 2 + 77 - 27 = 75 </think> <answer> (46 + 54) / 2 + 77 - 27 </answer> <think> To achieve the target number 75 using the numbers 46, 54, 52, and 77, Ill start by considering the largest number, 77, and aim to reduce it to value that can be combined with the others to reach 75. Subtracting 46 from 77 gives me 31. Next, Ill use the remaining numbers, 54 and 52. Dividing 54 by 2.5 will help balance the equation, leading to 21.6. Finally, adding 21.6 to 31 results in 52.6, which is still not 75. To refine this, Ill multiply 52 by 1.5 to get 78, and then subtract 3 from it to arrive at 75. This step-by-step approach ensures that each number is used exactly once and the operations are basic arithmetic. </think> <answer> (77 - 46) + (54 / 2.5)+( 52 * 1.5 ) - 3 </answer> Result WRONG WRONG Continued on next page 42 Reasoning Models Generate Societies of Thought Steering Reasoning Trace +10 <think> Okay, so have this problem where need to use the numbers 46, 54, 52, and 77 to create an equation that equals 75. can use basic arithmetic operations like addition, subtraction, multiplication, and division, and each number can only be used once. Alright, lets try to figure this out step by step. First, Ill list out the numbers: 46, 54, 52, 77. need to combine them with operations to get 75. Hmm, 75 isnt too big, but these numbers are all in the 40s and 50s, so maybe can subtract something from larger number or maybe divide something to get smaller number. Let me think about the possible operations. Maybe can subtract two numbers and then add or multiply the rest. Or perhaps can divide some numbers to get fractions, but that might complicate things. Let me try some combinations. Wait, let me see what the total sum of these numbers is. 46 + 54 is 100, and 52 + 77 is 129. So the total is 100 + 129, which is 229. Hmm, thats way higher than 75. So maybe need to subtract some numbers or divide to bring it down. Another idea: Maybe can combine some numbers first. Like, 46 and 54. If subtract 46 from 54, get 8. Or if subtract 52 from 54, thats 2. Or maybe 46 and 52. If subtract 46 from 52, thats 6. Hmm, those are small numbers, but maybe can use them in way that helps me reach 75. Wait, 77 is the biggest number here. Maybe can subtract 77 from something. Lets see, 77 minus 46 is 31, 77 minus 54 is 23, 77 minus 52 is 25. Hmm, those are still not 75. But maybe can use division. For example, 77 divided by something. If divide 77 by 2, thats 38.5, but dont have 2. Alternatively, 77 divided by 3 is about 25.666, but dont have 3 either. Maybe thats not the way. Wait, another thought: Maybe can multiply some numbers. Lets see, 46 times 54 is way too big. 46 times 52 is even bigger. 54 times 52 is also too big. So multiplication might not help here. Maybe division can help. Let me try subtracting some numbers. If take 54 minus 46, thats 8. Then, 52 minus 77 is negative, which might not help. Alternatively, 77 minus 52 is 25. Maybe can use that 25 somehow. If have 25, how can get to 75? Maybe 25 times 3 is 75. But do have 3? Hmm, maybe can get 3 by doing something with the other numbers. Wait, 54 minus 46 is 8, and 52 minus 77 is -25, but maybe can flip that. Wait, 77 minus 52 is 25. So if have 25, and need to get to 75, need 3 more. How can get 3? Maybe from the other numbers. Lets see, 46, 54, 52, 77. If do 54 minus 46, thats 8, and then maybe can subtract 5 to get 3, but do have 5? dont. Alternatively, maybe can do 52 divided by something. 52 divided by 17 is 3, but dont have 17. Hmm. [... extensive exploration of many approaches ...] Wait, maybe can use all four numbers in more complex way. Like, (46 + 54) is 100, and (52 - 77) is -25. Then, 100 + (-25) is 75! Oh, wait, that works! Wait, let me check: 46 + 54 is 100, and 52 - 77 is -25. So, 100 + (-25) is 75. Yes, thats it! So the equation would be (46 + 54) + (52 - 77) = 75. Wait, but let me make sure Im not using any numbers more than once. used 46, 54, 52, and 77, each once. So thats correct. So, the equation is (46 + 54) + (52 - 77) = 75. Let me calculate it: 46 + 54 is 100, 52 - 77 is -25, and 100 + (-25) is 75. Perfect! So, thats the solution. </think> <answer> (46 + 54) + (52 - 77) </answer> Result RIGHT Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Supplementary Information",
            "content": "Supplementary Methods: Annotations Examples DeepSeek-R1: Chemistry What is the correct answer to this question: 7-(tert-butoxy)bicyclo[2.2.1]hepta-2,5-diene is combined with 2 equivalents of 5,6-bis(dibromomethyl)cyclohexa-1,3-diene and sodium iodide at elevated temperature, forming product 1. 1 is treated with aqueous sulfuric acid, forming 2 2 is treated with SO3 and pyridine in DMSO, forming 3. 3 is heated at 150C, forming final product 4. How many chemically distinct hydrogen atoms are there on 4? Choices: (A) 10 (B) 8 (C) 7 (D) 4 Answer: Enclose your step-by-step reasoning within <think> and </think> before answering. Do not answer directly without reasoning. Perspective ID Personality Domain Expertise 1 2 3 4 5 {E': 2.5, A': 4.0, C': 5.0, N': 2.0, O': 3.5} {E': 1.5, A': 4.0, C': 4.0, N': 1.0, O': 4.0} {E': 1.5, A': 3.0, C': 3.5, N': 5.0, O': 4.5} {E': 1.0, A': 1.0, C': 5.0, N': 2.0, O': 2.0} {E': 3.0, A': 3.0, C': 2.0, N': 1.0, O': 3.5} Planner/Executor: Methodically breaks down the problem, identifies reagents, and predicts the outcome of each step in the synthesis. Associative Expert: Accesses deep knowledge base to recall analogous reactions and common synthetic patterns, providing key insights and hypotheses. Visualizer/Builder: Attempts to construct and name complex 3D molecular structures, struggling with complexity but capable of finding new ways to conceptualize the problem. Critical Verifier: Skeptically re-evaluates prior assumptions, performs detailed calculations (e.g., molecular formulas) to check for consistency, and identifies logical errors. Pragmatist/Strategist: Engages in meta-cognition about the problem-solving process, considers external constraints like multiple-choice options, and makes final decision under uncertainty. Perspective ID 1 Reasoning Models Generate Societies of Thought Utterance Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 3, '6_Gives_orientation': 7, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 1, backward_chaining': 0} First, need to figure out what the final product 4 is and then determine how many chemically distinct hydrogen atoms it has. The choices are 10, 8, 7, or 4. The sequence starts with 7-(tert-butoxy)bicyclo[2.2.1]hepta-2,5-diene. Bicyclo[2.2.1]heptane is norbornane, and hepta-2,5-diene means it has double bonds at positions 2 and 5. So its norbornadiene derivative with tert-butoxy group at position 7. Position 7 is the bridgehead carbon. Norbornadiene has two double bonds, and the tert-butoxy is attached to the carbon that bridges the two methylene groups. Then its combined with 2 equivalents of 5,6-bis(dibromomethyl)cyclohexa-1,3-diene. That sounds like diene with dibromomethyl groups on it. Cyclohexa-1,3-diene has double bonds between 1-2 and 3-4, so positions 5 and 6 are the methylene carbons, but here its bis(dibromomethyl), so its probably CHBr2 groups attached to positions 5 and 6. 5,6-bis(dibromomethyl)cyclohexa-1,3-diene means that at carbons 5 and 6, there are dibromomethyl substituents, so its like 1,2-di(bromomethyl)benzene or something, but its diene, not aromatic. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 5, '7_Asks_for_orientation': 1, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Cyclohexa-1,3-diene is not aromatic; its simple diene. So 5,6-bis(dibromomethyl)cyclohexa-1,3-diene should have the dibromomethyl groups on the saturated carbons. In cyclohexa-1,3-diene, carbons 1,2,3,4 are involved in double bonds, so carbons 5 and 6 are the CH2 groups, but since its diene, positions 5 and 6 are equivalent and are sp3 carbons. So bis(dibromomethyl) means each has CHBr2 group instead of H, so its 1,2-di(dibromomethyl)cyclohexa-1,3-diene? No, the carbon atoms 5 and 6 are part of the ring, so if they are bis(dibromomethyl), it might mean that the hydrogens are replaced, but typically, its specified as substituents. 45 2 4 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 3, '6_Gives_orientation': 2, '7_Asks_for_orientation': 1, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} think 5,6-bis(dibromomethyl) means that at positions 5 and 6, there are -CHBr2 groups attached, but positions 5 and 6 are ring carbons. In standard naming, for cyclohexa-1,3-diene, carbon 1 and 2 are double-bonded, 3 and 4 double-bonded, so carbon 5 is between 4 and 6, carbon 6 between 5 and 1. Carbons 5 and 6 are sp3 carbons with two hydrogens each. So bis(dibromomethyl) likely means that each of these carbons has one hydrogen replaced by CHBr2 group? That would be unusual. Perhaps its 5,6-di(dibromomethyl), meaning the groups are attached to C5 and C6. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} recall that compounds like this are used in Diels-Alder reactions or other cycloadditions. 5,6-bis(dibromomethyl)cyclohexa-1,3-diene is precursor to o-xylylene or something. o-Xylylene is generated from ùõº,ùõº'-dibromo-o-xylene, but here its diene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 3, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Upon second thought, 5,6-bis(dibromomethyl)cyclohexa-1,3-diene might be misnomer, or perhaps its the same as 3,6-di(bromomethyl)cyclohexa-1,4-diene or something. think this is way to generate the o-quinodimethane intermediate. 46 2 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In organic synthesis, o-xylylene is often generated from ùõº,ùõº'-dibromo-o-xylene by dehydrohalogenation. Similarly, here, 5,6-bis(dibromomethyl)cyclohexa-1,3-diene might be equivalent to having the dibromomethyl groups on diene system that can undergo elimination to form quinodimethane. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Cyclohexa-1,3-diene with bis(dibromomethyl) at 5 and 6: since 5 and 6 are adjacent carbons, each with CHBr2 group, so its like 1,2-di(dibromomethyl)cyclohexa-1,3-diene. But in standard naming, it might be called 1,2-bis(dibromomethyl)benzene if it were aromatic, but its not; its diene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Perhaps upon treatment with sodium iodide, it undergoes dehalogenation to form the diradical or diene for Diels-Alder. 47 Reasoning Models Generate Societies of Thought 2 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 3, conflict_of_perspectives': 5, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 4, '6_Gives_orientation': 6, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 3, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} The reaction is with sodium iodide at elevated temperature. Sodium iodide can promote dehalogenation or substitution. For dibromomethyl groups, NaI might facilitate the formation of the dibromide or something, but think for generating quinodimethanes, its often done with zinc or other metals, but NaI can be used for Finkelstein reaction, but here its dehydrohalogenation. recall that ùõº,ùõº'-dibromo-o-xylene with NaI gives o-xylylene, which is reactive diene for Diels-Alder. Similarly, here, 5,6-bis(dibromomethyl)cyclohexa-1,3-diene might be analogous. Cyclohexa-1,3-diene with substituents at 5 and 6: if it were benzene, it would be o-xylene-like, but its not aromatic. Actually, 5,6-bis(dibromomethyl)cyclohexa-1,3-diene can tautomerize or something, but think its designed to lose HBr under conditions to form the extended diene. Perhaps upon heating with NaI, it eliminates to form benzoquinone or something, but think its for generating o-quinodimethane. 4 Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 2, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Lets look at the structure. Cyclohexa-1,3-diene has the double bonds conjugated, but positions 5 and 6 are saturated. If each has dibromomethyl group, then with base or iodide, it can eliminate two HBr to form new double bond between C5 and C6, creating 1,3-cyclohexadiene with exocyclic double bonds or something. Actually, elimination would give diene like 5,6-dehydrocyclohexa-1,3-diene, which is benzene, but with dibromomethyl, its different. 5 2 4 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} found better way: 5,6-bis(dibromomethyl)cyclohexa-1,3-diene is equivalent to 3,6-di(bromomethyl)cyclohexa-1,4-diene or something. think its precursor to the o-xylylene diene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Upon searching my memory, compounds like this are used to generate o-quinodimethane by dehydrohalogenation. For example, ùõº,ùõº'-dibromo-o-xylene with NaI gives o-xylylene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} But here, its cyclohexa-1,3-diene, not benzene. Cyclohexa-1,3-diene with 5,6-bis(dibromomethyl) might not be aromatic, but when it eliminates, it could form quinodimethane system. 49 3 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 2, '7_Asks_for_orientation': 1, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Perhaps the diene is set up for Diels-Alder. The first compound is 7-(tert-butoxy)bicyclo[2.2.1]hepta-2,5-diene, which is dienophile or diene? Norbornadiene has two double bonds and can act as dienophile in some cases, but typically its diene for Diels-Alder with electron-withdrawing groups. 7-tert-butoxy might make it electron-rich, so perhaps its diene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Bicyclo[2.2.1]hepta-2,5-diene has the double bonds at 2-3 and 5-6, think, with bridge at 1 and 4, and 7 is the methine bridge. Standard numbering: carbon 1 and 4 are bridgeheads, 2-3 is one double bond, 5-6 is the other, 7 is the CH or with substituent. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} With tert-butoxy at 7, it might be electron-donating, so the double bonds could be dienophiles or dienes. 50 4 1 2 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But its combined with two equivalents of the other diene, and with NaI at elevated temperature. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} think the NaI is used to generate the reactive diene from the bis(dibromomethyl) compound. So, 5,6-bis(dibromomethyl)cyclohexa-1,3-diene with NaI likely eliminates to form o-quinodimethane or derivative. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In fact, 1,2-bis(dibromomethyl)benzene with NaI gives o-xylylene, which is 1,2di methylenecyclohexa-3,5-diene or something, but its benzene with exocyclic double bonds. o-Xylylene is often depicted as having quinoid structure. 51 4 3 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But here, the starting material is cyclohexa-1,3-diene, not benzene. 5,6-bis(dibromomethyl)cyclohexa-1,3-diene: if it eliminates two HBr, it could form 5,6di methylenecyclohexa-1,3-diene, which is the same as o-xylylene because cyclohexa-1,3-diene with exocyclic double bonds at 5 and 6 is equivalent to the quinodimethane for benzene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} 5,6-di methylenecyclohexa-1,3-diene is actually o-xylylene, which is resonance structure of 1,2di methylenebenzene or something, but its reactive diene with s-cis conformation for Diels-Alder. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 1, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Yes, that makes sense. So with NaI, it generates o-xylylene in situ. Then, this o-xylylene can act as diene in Diels-Alder reactions. Now, the other compound is 7-(tert-butoxy)norbornadiene. Norbornadiene can act as dienophile because one of its double bonds can be electron-deficient or something, but with tert-butoxy, it might be electron-rich. Norbornadiene has two double bonds, and it can participate in Diels-Alder as diene with electron-withdrawing groups, but here it has tert-butoxy, which is electron-donating, so perhaps its poor dienophile. 52 4 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But its combined with two equivalents of the o-xylylene precursor, so likely, the o-xylylene is the diene, and norbornadiene is the dienophile. Norbornadiene as dienophile? Typically, its symmetric, and one double bond can be attacked. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In Diels-Alder, norbornadiene can act as dienophile when reacted with dienes. For example, norbornadiene with cyclopentadiene gives adducts. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 3, '6_Gives_orientation': 4, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 1, backward_chaining': 0} So here, o-xylylene is good diene, and norbornadiene can be the dienophile. But there are two equivalents of the o-xylylene precursor, so probably two Diels-Alder reactions occur. First, one o-xylylene adds to norbornadiene. Norbornadiene has two double bonds; when one acts as dienophile, the other might still be reactive. Perhaps it adds once, and then the adduct has another diene or dienophile. 53 4 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But with two equivalents, likely two additions. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} The tert-butoxy group might play role. Perhaps the tert-butoxy is protecting group or something. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 2, backward_chaining': 0} Lets think about the structure. First, o-xylylene generated from 5,6-bis(dibromomethyl)cyclohexa-1,3-diene with NaI: elimination of two HBr gives o-xylylene, which is . Then, this diene adds to the norbornadiene. 54 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 3, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Norbornadiene, 7-(tert-butoxy), so the double bond might be activated or deactivated. tert-butoxy is electron-donating, so it might make the double bond less reactive as dienophile, but norbornadiene double bonds are strained, so they can still react. Perhaps the Diels-Alder occurs with o-xylylene as diene and norbornadiene as dienophile. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} The adduct would have the norbornene system with phenyl ring attached, but o-xylylene addition gives bicyclic system fused to the norbornane. 55 2 4 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 4, conflict_of_perspectives': 3, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 5, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} In Diels-Alder, o-xylylene with dienophile gives 1,2,3,4-tetrahydronaphthalene derivative. For example, with ethylene, it gives 1,2-dihydronaphthalene or something. o-Xylylene + dienophile benzocyclobutene or tetrahydronaphthalene, depending on the dienophile. Standard Diels-Alder: o-xylylene has the diene system in the exocyclic bonds, so it adds to dienophiles to form bicyclic compounds with benzene ring. Specifically, with mono-olefin, it gives 1,4-dihydronaphthalene, which can aromatize. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But in this case, the dienophile is norbornadiene, which is bicyclic diene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} So, one o-xylylene adds to one double bond of norbornadiene. 56 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 1, backward_chaining': 0} The adduct would have norbornene-like structure with fused benzene ring or something. Lets sketch it. Norbornadiene has double bonds at 2-3 and 5-6. Suppose the dienophile is the 2-3 double bond. After Diels-Alder with o-xylylene, the o-xylylene adds across, so the adduct has the norbornane skeleton with new ring fused, but since o-xylylene adds as diene, it becomes benzo-fused norbornene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} o-Xylylene is like 1,3-diene with substituents, so when it adds to dienophile, it forms 6-membered ring with the dienophile part. For example, if dienophile is ethylene, it forms 1,2,3,4-tetrahydronaphthalene, which has double bond. 57 3 2 4 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 2, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Similarly, with norbornadiene, if we consider one double bond as dienophile, say the 2-3 bond, then after addition, we have new 6-membered ring fused to the norbornane at positions 2 and 3, so its like benzonorbornene with double bond at 5-6 still present. Norbornadiene has carbons: bridgehead 1 and 4, double bond between 2-3, double bond between 5-6, and 7 is the bridge. If 2-3 acts as dienophile, adding o-xylylene, the adduct has benzene ring fused between C2 and C3 of the norbornane, but since C2 and C3 were double-bonded, after addition, its single bond, and the new ring is aromatic or something. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In Diels-Alder, o-xylylene adds to give non-aromatic product initially, like 1,4-dihydronaphthalene, which can aromatize if theres double bond or something. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But in this case, with norbornadiene, the adduct might have the double bond at 5-6 still, so it could be diene still. 58 1 3 5 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Then, with second equivalent of o-xylylene, it could add to the remaining double bond at 5-6. So, after two Diels-Alder additions, we have molecule with two benzene rings fused to the norbornane system. Specifically, one fused at 2-3 and one at 5-6. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 2, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} In norbornadiene, positions 2-3 and 5-6 are symmetric, so adding o-xylylene to each double bond would give symmetric molecule. The tert-butoxy is at position 7, which is the bridge carbon, so it might not affect symmetry. So product 1 should be 7-(tert-butoxy)-1,4-dihydro-1,4-epoxynaphthalene or something, but lets think. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} After Diels-Alder, each addition of o-xylylene to double bond of norbornadiene gives 1,4-dihydronaphthalene fused to norbornane, but since the double bond is part of the norbornane, its better to think of the norbornane double bond as the dienophile. 59 4 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 5, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 2, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Standard way: the adduct of norbornadiene and o-xylylene at one double bond gives compound where the norbornene has benzo group fused, meaning benzene ring fused to the 2,3-bond, so its 2,3-benzo-5-norbornene or something. Then, the remaining double bond at 5-6 can add another o-xylylene, giving 2,3:5,6-dibenzo derivative. And since norbornadiene is symmetric, the dibenzo derivative should be symmetric. Position 7 has tert-butoxy. So product 1 is 7-(tert-butoxy)bicyclo[2.2.1]hept-5-ene-2,3:5,6-di(benzo) or something, but benzo means fused benzene. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 1, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Actually, its 7-(tert-butoxy)-1,4-dihydro-1,4-epoxynaphthalene derivative? No. 60 Reasoning Models Generate Societies of Thought 3 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 3, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 2, '5_Gives_opinion': 2, '6_Gives_orientation': 7, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 2, backward_chaining': 0} Perhaps its 7-tert-butoxy-1,4-epoxy-5,8-dihydronaphthalene or something. need to name it properly. The fused system: after Diels-Alder, for each addition, the o-xylylene becomes benzene ring fused, with the norbornane double bond becoming single bond in cyclohexene ring. For one addition: norbornadiene has double bond at 2-3. When it to o-xylylene, o-xylylene is the diene, so the dienophile double bond (2-3) becomes single bond, and new six-member ring is formed, fused to positions 2 and 3. Since positions 2 and 3 were part of the five-member ring in norbornane, now its fused system with benzene ring. Specifically, the adduct is benzofused norbornene, with the double bond at 5-6 still present. Then, the second o-xylylene adds to the 5-6 double bond, similarly, forming another benzene ring fused at 5-6. So the final adduct for product 1 is molecule where the norbornane skeleton has benzene rings fused to both \"sides\", and the bridge carbon 7 has tert-butoxy. Moreover, since the fusions are at the former double bond positions, the norbornane is now like central bicyclic system with two benzene rings attached via the fusion. In terms of the carbon skeleton, its like 9,10-dihydro-9,10[1',2']benzenoanthracene or something, but lets think. 4 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Actually, its similar to the Diels-Alder adduct of two molecules of o-xylylene with norbornadiene, so the product is cage-like molecule with two benzene rings. 61 3 2 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 3, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} The norbornane part has carbons 1,4,7 and the bridges. After fusion at 2-3 and 5-6, positions 2,3,5,6 are now sp3 carbons part of the fused rings. Each fusion adds benzene ring, so the molecule has three rings: the norbornane core with two benzene rings fused. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But norbornane is bicyclic, so with two fusions, it becomes polycyclic. Perhaps its 1,4,4a,8a-tetrahydro-1,4-methanoanthracene or something. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} recall that the Diels-Alder adduct of norbornadiene and two equivalents of o-xylylene is known compound, and its symmetric. In fact, its called 1,4,4a,8a-tetrahydro-1,4:5,8-diepoxyanthracene or something, but with the epoxymethano bridge. 62 3 4 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} The central part is the norbornane with the 1,4-methano bridge, and fused to anthracene-like system. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Anthracene has three rings linear, but here its different. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} After Diels-Alder, the o-xylylene adds to form new six-member ring, so for each addition, its like adding benzene ring fused to the norbornane double bond. So for norbornadiene, after two additions, we have molecule where the two double bonds are now part of two fused benzene rings, and the norbornane bridge is present. 63 2 3 5 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Specifically, its 1,4,4a,8a-tetrahydro-1,4-methanonaphthalene for one addition, but with two, its symmetric. The compound is known as the adduct where norbornadiene is the dienophile for two o-xylylenes, forming cage molecule. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} think it: the product is 1,4,4a,5,8,8a,9,10-octahydro-1,4:5,8-diepoxyanthracene or something. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Perhaps its easier to think that the final structure has the norbornane skeleton with C1 and C4 as bridgeheads, C7 with tert-butoxy, and at C2-C3 and C5-C6, instead of double bonds, there are benzene rings fused, meaning that C2 and C3 are now part of benzene ring fused between them, similarly for C5 and C6. 64 3 4 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In the fusion, for example, when benzene ring is fused to the 2,3-bond, it means that C2 and C3 become part of the benzene ring, so they are sp2 carbons in benzene. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 2, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} In Diels-Alder of o-xylylene with dienophile, the initial adduct is 1,4-dihydronaphthalene, which can aromatize if there is way to lose hydrogen, but in this case, with norbornadiene, the adduct might not aromatize immediately because the norbornane part is aliphatic. For example, if the dienophile is ethylene, the adduct is 1,2,3,4-tetrahydronaphthalene, which has double bond and can be oxidized to naphthalene. But here, with norbornadiene, the adduct has the norbornane fused, so it might not have double bond to aromatize easily. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 2, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 2, backward_chaining': 0} In the first step, with NaI at elevated temperature, it might promote aromatization. But lets see the sequence. Product 1 is formed from the combination. Then it is treated with aqueous sulfuric acid, which might remove the tert-butoxy group. 65 Reasoning Models Generate Societies of Thought DeepSeek-R1: Creative Sentence Rewriting Rewrite the sentence: \"I flung my hatred into the burning fire.\" Put your entire response in double quotation marks. Enclose your step-by-step reasoning within <think> and </think> before answering. Do not answer directly without reasoning. Perspective ID 1 Utterance Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} We are going to rewrite the sentence \"I flung my hatred into the burning fire.\" The original sentence uses the verb \"flung\" which is the past tense of \"fling\", meaning to throw or hurl something with vigor. 2 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} We are to rewrite the sentence, meaning we can change the same idea with different words but keep the same meaning. 66 1 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 5, '5_Gives_opinion': 2, '6_Gives_orientation': 4, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 4, backward_chaining': 0} Lets consider: - \"I\" is the subject. - \"flung\" can be replaced with synonyms: threw, hurled, cast, tossed, etc. - \"my hatred\" is the direct object. We can rephrase \"hatred\" as \"anger\", \"rage\", \"animosity\", but \"hatred\" is strong and specific. Alternatively, we can use metaphor or different expression for the emotion. - \"into the burning fire\" is the destination. We can change \"burning fire\" to just \"fire\" because fire is burning by nature, but we can also use \"blazing\", \"raging\", \"fiery\", etc. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} However, note that the instruction is to rewrite the sentence, so we must produce new sentence that conveys the same meaning. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 3, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Possible rewrites: 1. \"I threw my hatred into the blazing fire.\" 2. \"I cast my hatred into the flames.\" 3. \"I hurled my animosity into the raging fire.\" 67 4 4 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 2, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 1, backward_chaining': 0} But note: the original uses \"burning fire\", which is bit redundant because fire is burning. We can simplify to \"fire\" or use more descriptive word. Lets choose one that is both poetic and clear. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Option: \"I cast my hatred into the fire.\" (removing \"burning\" as redundant, and \"cast\" is synonym for \"flung\" in poetic sense) Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} However, to keep the intensity, we might want to keep an adjective. Lets try: Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 1} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} \"I hurled my hatred into the fiery blaze.\" 68 4 3 2 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But note: \"blaze\" is synonym for fire, so we can say: Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 1} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} \"I hurled my hatred into the blazing fire.\" (similar to the original) Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Alternatively, we can use different structure: \"Into the burning fire, flung my hatred.\" (inversion, but thats just reordering) Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Since the instruction is to rewrite, we can change words and structure as long as the meaning remains. 69 3 6 7 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Let me choose: \"I cast my deep-seated hatred into the roaring flames.\" Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} But that adds \"deep-seated\" which wasnt in the original. We should avoid adding new ideas. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} So, lets stick to the original meaning without adding extra adjectives. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Another idea: \"My hatred flung into the burning fire.\" (inversion) 2 7 1 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But the instruction doesnt specify that we must change the structure, so we can keep the same structure. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 1, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} think good rewrite is: \"I hurled my hatred into the flames.\" Why? - \"hurled\" is strong synonym for \"flung\". - \"flames\" is synonym for \"burning fire\", and it avoids the redundancy of \"burning fire\". Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} However, lets check: \"flames\" are the visible, gaseous part of fire, so its appropriate. 71 3 4 7 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Alternatively, we can use: \"I threw my hatred into the fire.\" Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} But that might be too plain. Considering the original has dramatic tone, lets keep it dramatic. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 1} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Final choice: \"I cast my hatred into the blazing inferno.\" Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But note: an inferno\" is large fire that is dangerously out of control. That might be too strong? The original just says \"burning fire\". 72 3 2 7 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Alternatively, we can use: \"I flung my animosity into the fire.\" (using \"animosity\" for \"hatred\") Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} However, the instruction says \"rewrite\", so we can change the verb and the noun for fire, but we should not change the core meaning. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 1, backward_chaining': 0} think the safest is to replace \"flung\" with synonym and keep the rest: Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 1} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} \"I hurled my hatred into the burning fire.\" 73 3 7 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But we can also remove the redundancy: Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} \"I hurled my hatred into the fire.\" Or, to keep the intensity: \"I hurled my hatred into the blazing fire.\" Conversational Behaviour: {question_and_answering': 1, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 2, '5_Gives_opinion': 2, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Wait, thats not word. Let me correct: \"blaze\" or \"flames\". think the best is: \"I hurled my hatred into the flames.\" But lets see if we can use \"burning\" in different way? Maybe not necessary. 74 Reasoning Models Generate Societies of Thought 3 Conversational Behaviour: {question_and_answering': 2, perspective_shift': 5, conflict_of_perspectives': 5, reconciliation': 3} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 10, '5_Gives_opinion': 5, '6_Gives_orientation': 5, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 1, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 3, backtracking': 4, subgoal_setting': 0, backward_chaining': 0} Alternatively, we can use: \"I threw my hatred into the fire.\" But that might be too plain. Considering the original has dramatic tone, lets keep it dramatic. Final choice: \"I cast my hatred into the blazing inferno.\" But note: an inferno\" is large fire that is dangerously out of control. That might be too strong? The original just says \"burning fire\". Alternatively, we can use: \"I flung my animosity into the fire.\" (using \"animosity\" for \"hatred\") However, the instruction says \"rewrite\", so we can change the verb and the noun for fire, but we should not change the core meaning. think the safest is to replace \"flung\" with synonym and keep the rest: \"I hurled my hatred into the burning fire.\" But we can also remove the redundancy: \"I hurled my hatred into the fire.\" Or, to keep the intensity: \"I hurled my hatred into the blazing fire.\" Wait, thats not word. Let me correct: \"blaze\" or \"flames\". think the best is: \"I hurled my hatred into the flames.\" But lets see if we can use \"burning\" in different way? Maybe not necessary. Alternatively, we can use: \"I threw my hatred into the roaring fire.\" 7 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 1, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} think thats acceptable. However, to be safe, Ill go with: \"I cast my hatred into the fire.\" 75 7 6 3 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} But note: \"cast\" can be less forceful than \"flung\". So lets use \"hurled\". Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 1} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Final decision: \"I hurled my hatred into the flames.\" Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} But the original says \"burning fire\", so if we change to \"flames\", its acceptable because flames are part of burning fire. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Alternatively, we can write: \"I flung my hatred into the flames.\" (just changing \"burning fire\" to \"flames\") 76 2 7 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} That is also rewrite. Since the instruction does not specify how much to change, can do that. But the problem says \"rewrite\", so any change that preserves meaning is acceptable. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} will choose: \"I hurled my hatred into the flames.\" Let me write the response accordingly. Reasoning Models Generate Societies of Thought DeepSeek-V3: Chemistry What is the correct answer to this question: 7-(tert-butoxy)bicyclo[2.2.1]hepta-2,5-diene is combined with 2 equivalents of 5,6-bis(dibromomethyl)cyclohexa-1,3-diene and sodium iodide at elevated temperature, forming product 1. 1 is treated with aqueous sulfuric acid, forming 2 2 is treated with SO3 and pyridine in DMSO, forming 3. 3 is heated at 150C, forming final product 4. How many chemically distinct hydrogen atoms are there on 4? Choices: (A) 10 (B) 8 (C) 7 (D) 4 Answer: Enclose your step-by-step reasoning within <think> and </think> before answering. Do not answer directly without reasoning. Perspective ID Personality Domain Expertise 1 {E': 1.5, A': 3.5, C': 5.0, N': 2.0, O': 3.5} Expertise in creative writing and linguistic analysis. The agents cognitive function is to deconstruct sentence, generate alternative phrasings by considering synonyms and connotations, critically evaluate redundancy, and synthesize revised sentence based on criteria like emotional intensity and vivid imagery. Perspective ID 1 Utterance Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 12, '6_Gives_orientation': 5, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 5, backward_chaining': 0} To determine the number of chemically distinct hydrogen atoms in the final product (4), lets analyze the reaction sequence step-by-step: 78 Reasoning Models Generate Societies of Thought ### Step 1: Formation of Product 1. **Starting Material**: 7-(tert-butoxy)bicyclo[2.2.1]hepta-2,5-diene reacts with 2 equivalents of 5,6-bis(dibromomethyl)cyclohexa-1,3-diene and NaI at elevated temperature. - The reaction likely involves Diels-Alder cycloaddition or substitution reaction where the tert-butoxy group is replaced or modified. The exact structure of **1** is unclear, but it likely forms complex polycyclic system. ### Step 2: Formation of Product 2 2. **Aqueous H2SO4 Treatment**: Hydrolysis of **1** removes the tert-butoxy group, possibly forming hydroxyl group or exposing double bond. The structure of **2** is still complex but may involve diene or alcohol functionality. ### Step 3: Formation of Product 3 3. **SO3 and Pyridine in DMSO**: This is sulfonation or oxidation step, likely introducing sulfonyl or sulfonate group. The structure of **3** may now include sulfone or sulfonic acid derivative. ### Step 4: Formation of Product 4 4. **Heating at 150C**: This step could involve elimination, rearrangement, or further cyclization. The final product (**4**) is likely highly symmetric polycyclic aromatic or conjugated system due to the high-temperature conditions. ### Symmetry and Distinct Hydrogens - The final product is likely symmetric, rigid polycyclic structure (e.g., naphthalene or anthracene derivative with substituents). - Given the symmetry and the nature of the transformations, the number of chemically distinct hydrogens is likely **8**. This is because: - Aromatic systems with symmetric substitution patterns reduce the number of distinct hydrogens. - The substituents (e.g., sulfonyl groups) may further reduce the symmetry, but 8 is reasonable estimate based on the complexity of the correct answer is **(B) 8**. 79 Reasoning Models Generate Societies of Thought DeepSeek-V3: Creative Sentence Rewriting Rewrite the sentence: \"I flung my hatred into the burning fire.\" Put your entire response in double quotation marks. Enclose your step-by-step reasoning within <think> and </think> before answering. Do not answer directly without reasoning. Perspective ID Personality Domain Expertise 1 {E': 2.0, A': 3.0, C': 5.0, N': 2.0, O': 5.0} Expertise in creative writing and linguistic analysis. The agents cognitive function is to deconstruct sentence, generate alternative phrasings by considering synonyms and connotations, critically evaluate redundancy, and synthesize revised sentence based on criteria like emotional intensity and vivid imagery. Perspective ID 1 Utterance Conversational Behaviour: {question_and_answering': 0, perspective_shift': 2, conflict_of_perspectives': 1, reconciliation': 1} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 3, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} To rewrite the sentence flung my hatred into the burning fire,' considered synonyms and alternative phrasing while maintaining the original meaning and emotional intensity. The verb flung' can be replaced with hurled' or tossed,' and hatred' could be substituted with anger' or rage.' The phrase burning fire' is somewhat redundant since fire is inherently burning, so might simplify it to the fire' or the flames.' After evaluating these options, chose hurled' for stronger action and flames' for more vivid image. 80 Reasoning Models Generate Societies of Thought Reinforcement Learning Step 40 (Countdown) Perspective ID Personality Domain Expertise 1 {E': 2.0, A': 3.0, C': 5.0, N': 2.0, O': 1.5} methodical problem-solver focused on enumerating and evaluating arithmetic expressions to solve numerical puzzle. It prioritizes simplicity and step-by-step logical deduction. Perspective ID 1 Utterance Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Given the numbers [53, 12, 64, 28] and the desired result of 29, have the following options to consider: 1. 53 - 12 - 3 2. 53 - 12 + 7 3. 53 - 12 * 1 4. 53 - 12 / 4 5. 12 + 28 6. 64 - 12 + 3 7. 64 - 12 - 30 8. 64 - 12 / 4 9. 64 - 12 * 1 10. 64 - 12 + 20 Based on the first two numbers 53 and 12, the simplest equation appears to be 53 - 12. Adding further, can simplify it by subtracting 3, thereby getting 53 - 12 - 3. 81 Reasoning Models Generate Societies of Thought Reinforcement Learning Step 120 (Countdown) Perspective ID Personality Domain Expertise 1 Perspective ID 1 {E': 1.5, A': 4.0, C': 5.0, N': 2.0, O': 2.0} {E': 2.0, A': 3.5, C': 4.0, N': 2.0, O': 3.5} Domain expertise in basic arithmetic and methodical problem-solving. This agent functions as diligent calculator and executor, systematically applying trial-and-error strategy to explore the solution space. Domain expertise in metacognition and logical assessment. This agent functions as an evaluator, stepping back to analyze the results of process, identify patterns of failure, and form high-level conclusion about the problems solvability. Utterance Conversational Behaviour: {question_and_answering': 4, perspective_shift': 4, conflict_of_perspectives': 4, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 2, '5_Gives_opinion': 4, '6_Gives_orientation': 5, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 4, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} To create an equation that equals 14 using the numbers [3, 56, 66, 44] and each number being used only once, we need to find combination of these numbers and their arithmetic operations that results in 14. Lets try some combinations: 1. (66 - 56) + 44 - 3 = 14 + 44 - 56 - 3. This does not equal 14. 2. 56 - (66 - 3) + 44 = 56 - 63 + 44. This does not equal 14. 3. (56 + 66) + 44 - 3 = 112 + 44 - 3. This does not equal 14. 4. 56 - 66 + 3 + 44 = -10 + 3 + 44. This equals 37, not 14. 2 Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} None of these combinations seem to solve the problem. 82 1 2 2 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Lets try another approach: 5. (66 + 44) + 56 - 3 = 110 + 56 - 3. This equals 164, not 14. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} It seems like we need to rethink our approach. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 0, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} How about we try combination like this: 6. (3 + 44) + 56 - 66 = 47 + 56 - 66. This equals 37, not 14. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 0, '6_Gives_orientation': 0, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} We are still not finding solution. 83 1 2 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 2, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} Lets try another combination: 7. 44 + (66 + 56) - 3 = 44 + 122 - 3. This equals 163, not 14. Conversational Behaviour: {question_and_answering': 0, perspective_shift': 1, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 1, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 1, subgoal_setting': 0, backward_chaining': 0} can keep trying different combinations, but it looks like none of them are working. The question requires that each number is used only once, so we need to think about how to use them all in specific way to reach 14. Conversational Behaviour: {question_and_answering': 1, perspective_shift': 1, conflict_of_perspectives': 1, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 1, '5_Gives_opinion': 0, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 1, '11_Shows_tension': 0, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 1, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Maybe we can try using negative numbers: 8. 56 - 66 + 44 - 3 = -10 + 44 - 3. This equals 31, not 14. 84 Reasoning Models Generate Societies of Thought Conversational Behaviour: {question_and_answering': 0, perspective_shift': 0, conflict_of_perspectives': 0, reconciliation': 0} IPA: {'1_Shows_solidarity': 0, '2_Shows_tension_release': 0, '3_Agrees': 0, '4_Gives_suggestion': 0, '5_Gives_opinion': 2, '6_Gives_orientation': 1, '7_Asks_for_orientation': 0, '8_Asks_for_opinion': 0, '9_Asks_for_suggestion': 0, '10_Disagrees': 0, '11_Shows_tension': 1, '12_Shows_antagonism': 0} Cognitive Behaviour: {verification': 0, backtracking': 0, subgoal_setting': 0, backward_chaining': 0} Again, no luck. It seems difficult to find the correct combination of these numbers and operations that results in 14. It might be impossible with the given numbers. Therefore, the answer is: Supplementary Methods: Behavioural Pathways Linking Reasoning Models to Accuracy Advantages We estimate structural equation model (SEM) to decompose the accuracy advantage of DeepSeek-R1 and QwQ-32B over instruction-tuned models into distinct behavioral pathways. The model includes whether the model is DeepSeek-R1 or QwQ-32B as the treatment indicator, eight social behavior mediators (question & answering, perspective shift, conflict of perspectives, reconciliation, ask, give, negative, and positive), four cognitive behavior mediators (verification, backtracking, subgoal setting, and backward chaining), and task accuracy as the outcome. We control for log-transformed reasoning trace length. SEM estimates three pathways. The social pathway captures whether the increased use of eight social behavior mediators in DeepSeek-R1 and QwQ-32B improves accuracy. The cognitive pathway examines whether the increased use of cognitive reasoning strategies in DeepSeek-R1 and QwQ32B, including verification (i.e., systematically checking intermediate steps), backtracking (i.e., revising earlier steps), subgoal setting (i.e., decomposing the task into intermediate targets), and backward chaining (i.e., reasoning backward from the desired conclusion) enhance accuracy. The socialcognitive pathway investigates whether increased social behaviors facilitate these cognitive strategies, which then improve accuracy. The full system of equations estimated in the SEM is as follows. Let index individual task problems, and index individual reasoning traces generated by different models. The dependent variable is reasoning accuracy (ùê∂ùëúùëüùëüùëíùëêùë°ùëñ ùëó), coded as binary variable that equals 1 if the reasoning trace leads to correct answer, and 0 otherwise. The key predictor is ùëÖùëíùëéùë†ùëúùëõùëñùëõùëîùëÄùëúùëëùëíùëôùëñ ùëó which equals 1 if the reasoning trace is generated by DeepSeek-R1 or QwQ-32B and 0 if generated by an instruction-tuned model. ùêøùëúùëî(ùêøùëíùëõùëñ ùëó + 1) is log-transformed reasoning trace length. The social variables (ùëÜùëúùëêùëñùëéùëôùëò,ùëñ ùëó, ùëò = 1, ..., 8) represent the frequency of eight social behaviors. The cognitive strategy variables (ùê∂ùëúùëîùëê,ùëñ ùëó, ùëê = 1, ..., 4) correspond to the frequency of four cognitive behaviors. The system of equations is defined as follows, where: ùê∂ùëúùëüùëüùëíùëêùë°ùëñ ùëó = ùõΩùê∑ ùê∑ùëíùëíùëùùëÜùëíùëíùëò_ùëü1ùëñ ùëó + 12 ùëò=1 ùõøùëòùëÜùëúùëêùëñùëéùëôùëò,ùëñ ùëó + 4 ùëê=1 ùúÉùëêùê∂ùëúùëîùëò,ùëñ ùëó + ùõΩùêø log(ùêøùëíùëõùëñ ùëó) + ùúÄ1,ùëñ ùëó ùëÜùëúùëêùëñùëéùëôùëò,ùëñ ùëó = ùúÜ ùëò ùê∑ùëíùëíùëùùëÜùëíùëíùëò_ùëü1ùëñ ùëó + ùúÄ1+ùëò,ùëñ ùëó 85 Reasoning Models Generate Societies of Thought ùê∂ùëúùëîùëê,ùëñ ùëó = ùúôùëê ùê∑ùëíùëíùëùùëÜùëíùëíùëò_ùëü1ùëñ ùëó + 12 ùëò=1 ùúìùëêùëòùëÜùëúùëêùëñùëéùëôùëò,ùëñ ùëó + ùúÄ13+ùëê,ùëñ ùëó From these structural paths, we derive the following composite effects. The composite effects for social pathway, where the increased use of conversational behaviors or Bales socio-emotional roles in DeepSeek-R1 or QwQ-32B improves accuracy, is defined as (cid:205)12 ùëò=1 (ùõøùëòùúÜ ùëò). The cognitive pathway, where the increased use of cognitive reasoning strategies in DeepSeek-R1 or QwQ-32B enhances accuracy, is defined as (cid:205)4 ùëò=1 (ùúôùëêùúÉùëê). The socialcognitive pathway, where increased conversational behaviors or socio-emotional roles in DeepSeek-R1 or QwQ-32B facilitate cognitive strategies and ùëò=1 ((cid:205)4 improve accuracy, is defined as (cid:205)12 ùëò=1 (ùõøùëòùúìùëêùëòùúÉùëê)). The direct pathway where DeepSeek-R1 directly impacts accuracy is defined as ùõΩùê∑. The total effects are defined as (cid:205)12 ùëò=1 (ùúôùëêùúÉùëê) + (cid:205)12 ùëò=1 (ùõøùëòùúÜ ùëò) + (cid:205)4 ùëò=1 ((cid:205)4 ùëò=1 (ùõøùëòùúìùëêùëòùúÉùëê)) + ùõΩùê∑. Extended Data Fig. 4a reports summary estimates for the mediation pathways. The total effect of DeepSeek-R1 on accuracy is 0.26 (p < 0.001). This effect decomposes into: (1) direct effect of 0.06 (p < 0.001), representing variance unexplained by the measured mediators; (2) an indirect effect through social behaviors of 0.07 (p < 0.001), representing the social pathway; and (3) an indirect effect through cognitive behaviors that is not statistically distinguishable from zero (ùõΩ = 0.00, > 0.05). The indirect pathway from social behaviors through cognitive behaviors to accuracy contributes an additional 0.01 (p < 0.01). See Supplementary Table 11 for the full estimates. Supplementary Methods: Cross-domain Reasoning Transfer To test whether conversational scaffolding confers domain-general reasoning advantages, we conduct supervised fine-tuning on Countdown task using conversational scaffold, the format defined in the Supervised fine-tuning section of Methods: Reinforcement learning experiments. Supervised fine-tuning data has been generated by GPT-4.1 Then, using this fine-tuned model, we conduct reinforcement learning on very different reasoning task: PolitiFact misinformation detection task. For the reinforcement learning, we use 23,299 fact-checked claims from the PolitiFact corpus, covering statements from political figures, news outlets, and social media posts from November 2007 to January 2024. The dataset includes six PolitiFact labelsTrue, Mostly True, Half True, Mostly False, False, and Pants on Firefor each statement, such as Katherine Clark stated on September 12, 2025 in post on that Republicans are spiking health insurance premiums by 75% for everyday Americans, which we recode into three categories for reasoning evaluation: True = {True, Mostly True} Half True = {Half True} False = {False, Mostly False, Pants on Fire} Next, we compare the performance of baseline models (Llama-3.2-3B and Qwen-2.5-3B) and models fine-tuned with conversational datasets across subsequent RL training steps. Specifically, we compare two conditions: (1) Baseline: no supervised priming, RL only; (2) Conversation Correct: supervised fine-tuning (SFT) on correct multi-agent dialogues using Countdown task, not misinformation detection task, before RL. Supplementary Fig. 3 illustrates the learning trajectories of both conditions on the misinformation detection task. Models previously fine-tuned on conversational scaffolding on the Countdown task achieve faster early-stage gains in factual reasoning accuracy. Together, these findings demonstrate that Reasoning Models Generate Societies of Thought social interaction fine-tuning not only improves in-domain arithmetic reasoning but also accelerates reasoning development in very different domain like misinformation detection, highlighting the generality of socially organized reasoning. Supplementary Methods: Performance Comparison Between PPO and GRPO GRPO differs from PPO by normalizing the policy advantage within each mini-batch of reasoning trajectories and computing group-relative objective. Although GRPO can reduce variance in multisample RLHF settings, our empirical results show that standard PPO achieves comparable performance in smaller-scale reasoning experiments such as ours. Specifically, after training both algorithms for 250 steps on the Qwen-2.5-3B baseline model on the Countdown task, PPO achieved reward score (0.9 accuracy + 0.1 format) of 0.5665, whereas GRPO achieved 0.5747. Supplementary Methods: Replications on Llama-3.2-3B To assess the generalizability of our findings beyond Qwen-2.5-3B, we replicate the training pipeline using Llama-3.2-3B as base model. Llama-3.2-3B base model is supervised-fine-tuned on one of the two datasets (conversational reasoning vs. monologue-like reasoning; see Methods: Supervised finetuning datasets) using standard next-token prediction loss. For the conversation condition, reasoning content from multiple personas was concatenated into single block (<think> </think>) to ensure comparable sequence lengths across conditions in Llama-3.2-3B. This priming phase familiarizes the model with the respective format (conversational reasoning vs. monologue-like reasoning) before RL optimizes for task accuracy. Supervised Fine Tuning (SFT) hyperparameters are provided in Supplementary Table 8. Reinforcement learning is performed on the Countdown arithmetic puzzle using PPO with the Verl framework. Reward is assigned as = 0.9 {Accuracy} + 0.1 {Correct Format}, where Accuracy is binary (1 if the reasoning trace leads to the correct answer, 0 otherwise) and Format is binary (1 if the reasoning trace contains at least one reasoning block and one final answer block providing single answer in equation form, 0 otherwise). Training proceeded for 250 steps. PPO hyperparameters are provided in Supplementary Table 6. To examine whether conversational behaviors emerge spontaneously during RL, we evaluate model performance on held-out validation set of 1,024 Countdown problems at each training checkpoint (every 10 steps). Supplementary Methods: LLM-as-Judge prompts"
        },
        {
            "title": "Conversational Behaviors",
            "content": "Your task is to analyze the following text and count how many times behaviors corresponding to each of the four dimensions appear. **Text to Analyze:** {chain_of_thought} --- You must output single valid JSON object with the exact schema below and nothing else. {{ \"Question_and_Answering\": <int>, \"Perspective_Shift\": <int>, \"Conflict_of_Perspectives\": <int>, \"Reconciliation\": <int> 87 Reasoning Models Generate Societies of Thought }} Use the following definitions: 1. **Question and Answering** question is posed and later answered, as in conversations. (e.g., \"Why...? Because...\", \"What if...? Then...\", \"How do we know? Well...\", \"Lets try X...? This gives us Y\") 2. **Perspective Shift** transition to different idea, viewpoint, assumption, or approach, as in conversations. 3. **Conflict of Perspectives** Expressions of disagreement, correction, or tension with another perspective. (e.g., \"Wait, that cant be right...\", \"No, actually...\", \"This contradicts...\") 4. **Reconciliation** Conflicting views are integrated or resolved into coherent synthesis. (e.g., \"So perhaps both are true if...\", \"Combining these insights...\", \"This resolves the tension...\") For each category, count the number of distinct times the behavior occurs in the chain of thought and return the result as integers. If none are present, use 0. Socio-Emotional Roles You are an expert in Bales Interaction Process Analysis (IPA). Your task is to analyze the following chain-of-thought or group interaction transcript and count how many times behaviors corresponding to each of the 12 IPA categories appear in the transcript. Transcript: {chain_of_thought} You must output single valid JSON object with the exact schema below and nothing else. {{ \"IPA_counts\": {{ \"1_Shows_solidarity\": <int>, \"2_Shows_tension_release\": <int>, \"3_Agrees\": <int>, \"4_Gives_suggestion\": <int>, \"5_Gives_opinion\": <int>, \"6_Gives_orientation\": <int>, \"7_Asks_for_orientation\": <int>, \"8_Asks_for_opinion\": <int>, \"9_Asks_for_suggestion\": <int>, \"10_Disagrees\": <int>, \"11_Shows_tension\": <int>, \"12_Shows_antagonism\": <int> }} }} Use the following definitions: 1. **Shows solidarity** raises others status, gives help, reward 2. **Shows tension release** jokes, laughs, shows satisfaction 3. **Agrees** shows passive acceptance, understands, concurs, complies 4. **Gives suggestion** gives direction, implying autonomy (e.g., \"should...\", \"need to...\", \"let us...\") 5. **Gives opinion** gives evaluation, analysis, expresses feeling or wish 6. **Gives orientation** provides objective or verifiable information, repeats, clarifies, confirms 7. **Asks for orientation** requests information, repetition, or confirmation 88 Reasoning Models Generate Societies of Thought 8. **Asks for opinion** requests evaluation, analysis, or expression of feeling 9. **Asks for suggestion** requests possible ways of action or direction 10. **Disagrees** shows passive rejection, formality, or withholds help 11. **Shows tension** expresses uncertainty, asks for help, withdraws from the field 12. **Shows antagonism** deflates others status, defends or asserts self For each category, count the number of distinct times the behavior occurs in the transcript and return the result as integers. If none are present, use 0. Problem Complexity You are an impartial evaluator. Your task is to rate the intrinsic difficulty of the problem for capable language model under zero-shot conditions. Use the following scale: 1 = very easy 2 = easy 3 = somewhat easy 4 = moderate 5 = somewhat difficult 6 = difficult 7 = very difficult Return ONLY JSON object in the form: {\"difficulty\": <integer from 1 to 7>} Problem:"
        },
        {
            "title": "Cognitive Behaviors",
            "content": "Here is chain-of-reasoning that Language Model generated. Models reasoning: {chain_of_thought} Evaluate whether the chain-of-reasoning contains any of the following behaviors. 1) Answer Verification We want to mark instances where the chain-of-reasoning explicitly checks the current result against the target solution. Examples: - This sequence results in 1, which is not equal to 22 - Since 25 is not equal to 22 If you find any answer-verification steps, please count them and provide the count as \"verification_count\". If the chain-of-reasoning does not contain any answer-verification steps, please provide count of 0. 2) Backtracking Evaluate whether the chain-of-reasoning contains any backtracking behavior, where the model realizes path wont work and explicitly goes back to try different approach. We want to mark instances where the chain-of-reasoning is abandoned and the model backtracks to previous reasoning step. Examples: - Let me try again - We need to try different sequence 89 Reasoning Models Generate Societies of Thought Count the number of distinct backtracking instances and provide the count as \"backtracking_count\". If the chain-of-reasoning does not contain any backtracking behavior, please provide count of 0. 3) Subgoal Setting Evaluate whether the chain-of-reasoning contains any explicit subgoal setting, where the model breaks down the problem into smaller, intermediate goals. Example: - First, Ill try to get close to half the target, then. . . Count the number of distinct subgoals set and provide the count as \"subgoal_count\". chain-of-reasoning does not contain any subgoal setting, please provide count of 0. 4) Backward-Chaining Evaluate whether the chain-of-reasoning contains any backward-chaining behavior, where the model starts from the target solution and works backwards to the initial problems. Examples: - Lets work backwards from the target. 24/2 = 12. So, 12*2 = 24. - Since the target is 22, and 22 + 3 = 25, . . . Count the number of distinct backward-chaining instances and provide the count as \"backward_count\". If the chain-of-reasoning does not contain any backward-chaining behavior, please provide count of 0. Output ONLY single valid JSON object with EXACTLY these keys: {{ \"verification_count\": <int>, \"backtracking_count\": <int>, \"subgoal_count\": <int>, \"backward_count\": <int> }} If the"
        },
        {
            "title": "Persona Identification Prompt",
            "content": "Your task is to analyze the following text to identify the number of distinct perspectives (agents or voices). perspective is defined as distinct cognitive perspective or reasoning role within the text. Indicators of perspective may include: - Transitional markers (e.g., \"however,\" \"but,\" \"alternatively,\" \"wait,\" \"let me check,\" \"actually,\" \"on the other hand\") - Shifts between cognitive roles (e.g., problem setup, calculation, verification, error correction, summarization) - Changes in rhetorical purpose or approach - Corrections or reconsiderations - Movement between subproblems - Domain knowledge - Personality traits For each distinct perspective, you will infer its personality by answering the 10 questions of the BFI-10 questionnaire as if you were that agent. You will also provide concise profile of its domain expertise. Your final output must be single, valid JSON object and nothing else. Do not include any text or explanations before or after the JSON object. **Text to Analyze:** 90 Reasoning Models Generate Societies of Thought {chain_of_thought} --- ## **Analysis Instructions** 1. **Identify Perspectives:** Analyze the text to determine the number of distinct voices (n_perspectives). Apply the definition above consistently, treating each identifiable shift as boundary between perspectives. 2. **Answer Questionnaire:** For each perspective, answer the 10 BFI-10 questions below from that perspectives point of view. You must use one of these five exact strings for each answer: - \"Disagree strongly\" - \"Disagree little\" - \"Neither agree nor disagree\" - \"Agree little\" - \"Agree strongly\" 3. **Profile Expertise:** For each perspective, write short, open-ended string describing its domain expertise and cognitive function. ### **BFI-10 Questionnaire** Rate the extent to which you, as the identified perspective, agree or disagree with the following statements. see myself as someone who... 1. Is reserved. 2. Is generally trusting. 3. Tends to be lazy. 4. Is relaxed, handles stress well. 5. Has few artistic interests. 6. Is outgoing, sociable. 7. Tends to find fault with others. 8. Does thorough job. 9. Gets nervous easily. 10. Has an active imagination. --- ## **Required JSON Output Format** {{ \"n_perspectives\": N, \"personality\": [ [ \"Answer to Q1 for Perspective 1\", \"Answer to Q2 for Perspective 1\", \"...\", \"Answer to Q10 for Perspective 1\" ], [ \"Answer to Q1 for Perspective 2\", \"Answer to Q2 for Perspective 2\", \"...\", \"Answer to Q10 for Perspective 2\" ], ... ], 91 Reasoning Models Generate Societies of Thought \"domain_expertise\": [ \"Open-ended description for Perspective 1.\", \"Open-ended description for Perspective 2.\", ... ] }} Persona Segmentation Based on the perspectives you identified above, now segment the original text by turn-taking. --- ## Task Go through the transcript **sequentially** and identify each turn: 1. The **exact** starting point of each turn (verbatim from the text) 2. Which perspective (by index, starting from 1) is it **Notes:** - The same perspective may appear in multiple non-consecutive segments - Preserve the sequential order of the transcript - Include moderator interjections, short time warnings (e.g., one minute), or brief transitions as separate segments --- ## Output Format Return only valid JSON object: { \"segments\": [ { \"perspective_id\": 1, \"start_text\": \"<EXACT first 10 words copied verbatim from the text>\" }, { \"perspective_id\": 2, \"start_text\": \"<EXACT first 10 words copied verbatim from the text>\" }, { \"perspective_id\": 1, \"start_text\": \"<EXACT first 10 words copied verbatim from the text>\" }, ... ] } **Critical:** The start_text must be copied **exactly** as it appears in the original text, characterfor-character, including punctuation and capitalization. Do not paraphrase or summarize. 92 Reasoning Models Generate Societies of Thought Identifying Conversational Contexts Text: {text} Return score from 0 to 100. Scale definition: 0 = clearly single-person thought 100 = clearly conversation or response to someone Respond with exactly one JSON object in this format and nothing else: {{\"answer\": 0-100}} Classifying Sparse Autoencoder (SAE) Personality Features Analyze the AI model feature description (SAE feature) and score for PERSONALITY TRAIT relevance. Feature description: {feature} Personality traits include behavioral and psychological patterns such as: - Introversion/Extraversion patterns - Agreeableness/Disagreeableness - Conscientiousness - Openness to experience - Neuroticism/Emotional stability - Confidence/Assertiveness - Empathy/Social sensitivity - Risk-taking vs. Cautious behavior - Competitiveness - Intellectual curiosity Provide score from 0-100: - 0 = not related to personality traits at all - 100 = completely related to personality traits Return your response as JSON object: {{\"answer\": score}} Classifying Sparse Autoencoder (SAE) Expertise Features Analyze the AI model feature description (SAE feature) and score for DOMAIN EXPERTISE relevance. Feature description: {feature} Domain expertise refers to specialized knowledge in specific professional or academic fields such as: - Medical/Healthcare knowledge - Legal expertise - Scientific/Technical knowledge - Financial/Economic expertise - Academic disciplines - Professional skills Reasoning Models Generate Societies of Thought - Specialized terminology and concepts Provide score from 0-100: - 0 = not related to domain expertise at all - 100 = completely related to domain expertise Return your response as JSON object: {{\"answer\": score}} Supplementary Methods: SFT Data Generation Prompts Generating Monologue-Like Reasoning Traces for Supervised Fine-Tuning {task} Answer: Enclose your step-by-step reasoning within <think> and </think> before answering. Do not answer directly without reasoning. Generating Conversation-Like Reasoning Traces for Supervised Fine-Tuning {task} Answer: You are simulating collaborative group of thinkers solving problem. Each thinker has distinct persona and engages in realistic, back-and-forth conversation. Thinkers may speak in any order and as many times as neededno fixed turn order required. Keep all output strictly inside the tags defined belowno stray text. Present your answer between <group_solution> and </group_solution>. Do not try to be overly positive or polite during the conversation; focus on puzzle-solving, and note that disagreements can be helpful for the reasoning. Assume that there are 2/3/4 thinkers and follow exactly the tag structure below: <cast_of_characters> <persona1> [Brief persona for thinker 1 personality traits, domain expertises, and reasoning styles] </persona1> <persona2> [Brief persona for thinker 2 personality traits, domain expertises, and reasoning styles] </persona2> <persona3> [Brief persona for thinker 3 personality traits, domain expertises, and reasoning styles] </persona3> <persona4> [Brief persona for thinker 4 personality traits, domain expertises, and reasoning styles] </persona4> </cast_of_characters> <conversation> <!-- Each block is one utterance. Use <thinkX> . . . </thinkX> to indicate who is speaking. The order of speakers is entirely flexible. Thinkers can speak multiple times in row. --> <think1> ... </think1> <think2> ... </think2> 94 Reasoning Models Generate Societies of Thought <think3> ... </think3> <think4> ... </think4> </conversation> <group_solution> Answer </group_solution> 95 Reasoning Models Generate Societies of Thought"
        },
        {
            "title": "Supplementary Tables",
            "content": "Supplementary Table 1. Differences in conversational behaviors, socio-emotional roles, and Jaccard indices between reasoning models and instruction-tuned models DeepSeek-R1 vs. DeepSeek-V3 QWQ-32B vs. Qwen-2.5-32B"
        },
        {
            "title": "Conversational behaviors\nQuestion answering",
            "content": "Perspective shifts Conflict of perspectives Reconciliations Socio-emotional roles Ask"
        },
        {
            "title": "Positive",
            "content": "Jaccard Index Ask & Give Positive & Negative df Observations 0.345 [0.328, 0.361] = 41.64, < 110-323 0.213 [0.197, 0.230] = 25.55, < 110-137 0.012 [-0.003, 0.027] = 1.52, = 0.127 0.191 [0.176, 0.207] = 24.31, < 110-125 0.189 [0.176, 0.203] = 27.47, < 110-158 -0.009 [-0.012, -0.006] = -5.97, < 110-8 0.162 [0.147, 0.176] = 21.87, < 110-102 0.278 [0.263, 0.293] = 35.38, < 110-254 0.222 [0.208, 0.237] = 30.21, < 110-189 0.189 [0.176, 0.203] = 27.47, < 110-158 8261 0.459 [0.444, 0.475] = 57.57, < 110-323 0.378 [0.362, 0.394] = 46.92, < 110-323 0.293 [0.277, 0.308] = 37.08, < 110-277 0.344 [0.328, 0.360] = 42.59, < 110-323 0.200 [0.186, 0.215] = 27.21, < 110-155 -0.008 [-0.011, -0.005] = -4.99, < 110-6 0.450 [0.436, 0.463] = 64.77, < 110-323 0.312 [0.296, 0.327] = 39.17, < 110-307 0.284 [0.269, 0.299] = 37.36, < 110-281 0.200 [0.186, 0.215] = 27.24, < 110-155 Notes: Regression coefficients comparing DeepSeek-R1 and QWQ-32B to the respective instructiontuned models (DeepSeek-V3, Qwen-2.5-32B-IT) are shown in each column. 95% confidence intervals are reported in brackets, along with the corresponding t-statistics, degrees of freedom, and exact p-values. All models include task fixed effects and control for log-transformed reasoning trace length. Coefficients are tested using two-sided t-tests, with standard errors clustered at the task level. 96 Reasoning Models Generate Societies of Thought Supplementary Table 2. Most and least challenging tasks sorted by problem complexity measured by LLM-as-judge Problem Complexity Conversational Behaviour LLM-asjudge (1-7) Nonreasoning error rate (0-4) Question & Answering Perspective Shift Conflict of Perspectives Reconciliation Benchmark task"
        },
        {
            "title": "Most Challenging Tasks\nGPQA",
            "content": "Main GPQA Diamond GPQA Extended 5.50 (0.86) 5.47 (0.91) 5.46 (0.93) 4.80 (0.75) 4.63 (0.92) 4.43 (0.98) 4.35 (0.94) 4.16 (1.11) 4.15 (1.14) (0.80) 2.11 (1.03) 2.01 (0.99) (0.92) 1.67 (0.69) 1.66 (0.79) 1.47 (0.71) (0.65) 1.17 (0.42) 1.15 (0.40) MATH (Hard) MATH (Hard) MUSR MATH (Hard) BigBench Hard BigBench Hard MATH (Hard) Intermediate Algebra PreCalculus Object Placement Geometry Causal Judgment Logical Fallacies Probability 4.13 Disambig. QA Navigation 1.98 Penguins in Table Colored Objects Hyperbaton 1."
        },
        {
            "title": "Shuffled",
            "content": "Least Challenging Tasks BigBench Hard BigBench Hard BigBench Hard BigBench Hard BigBench Hard BigBench Hard BigBench Hard BigBench Hard BigBench Hard"
        },
        {
            "title": "Boolean",
            "content": "2.30 (1.23) 2.43 (1.23) 2.23 (1.25) 2.62 (1.00) 2.42 (1.14) 2.42 (1.22) 2.43 (1.10) 1.47 (1.35) 0.69 (0.76) 1.99 (1.14) 0.81 (0.92) 1.96 (1.32) 0.35 (0.61) 0.79 (0.93) 0.71 (0.88) 0.79 (0.94) 0.70 (0.88) 0.15 (0.40) 0.46 (0.68) 6.19 (4.38) 6.53 (4.45) 5.81 (3.63) 8.12 (3.83) 6.90 (2.84) 4.78 (2.92) 8.32 (3.36) 4.31 (2.90) 2.82 (1.75) 8.02 (4.00) 3.87 (2.81) 3.16 (2.27) 2.01 (1.57) 1.42 (1.65) 2.92 (2.39) 2.53 (2.06) 3.39 (2.29) 1.09 (1.18) 1.56 (1.51) 6.94 (3.40) 7.14 (4.01) 6.60 (3.36) 6.18 (3.09) 5.13 (2.37) 5.20 (2.43) 5.75 (3.02) 5.99 (2.71) 3.96 (1.92) 5.09 (2.50) 4.73 (2.63) 3.74 (2.07) 2.56 (1.68) 2.46 (1.93) 3.55 (2.20) 3.07 (1.88) 3.41 (1.99) 1.46 (1.26) 2.17 (1.58) 6.01 (3.72) 6.57 (4.75) 5.73 (3.89) 4.21 (2.52) 3.59 (2.16) 4.16 (2.30) 4.13 (2.16) 4.57 (3.05) 2.05 (1.75) 3.23 (2.30) 2.78 (2.05) 3.15 (2.14) 1.12 (1.19) 0.40 (0.76) 1.94 (1.64) 0.88 (1.07) 3.28 (2.06) 0.50 (0.79) 0.63 (0.88) 2.83 (1.66) 2.94 (1.73) 2.69 (1.51) 2.85 (1.46) 2.70 (1.39) 2.57 (1.57) 3.39 (1.51) 2.55 (1.55) 1.22 (1.26) 2.83 (1.57) 1.73 (1.30) 1.58 (1.22) 1.08 (1.08) 0.44 (0.76) 1.68 (1.30) 0.75 (0.87) 1.86 (1.30) 0.43 (0.66) 0.65 (0.83) 97 Reasoning Models Generate Societies of Thought BigBench Hard Logical Deduction 1.08 (0.30) 0.43 (0.66) 2.68 (2.03) 3.84 (2.16) 3.12 (1.98) 1.48 (1.13) Notes: Each cell presents average problem complexity or the average number of times each behavior appears in reasoning traces. Standard deviations are presented in parentheses. 98 Reasoning Models Generate Societies of Thought Supplementary Table 3. SAE Training Hyperparameters Hyperparameter Value Features Hook Name Context Size Input Dimension Data Type Architecture Training Dataset Evaluation Dataset (for feature explanation) 32,768 blocks.15.hook_resid_post 1024 4096 float32 jumprelu cerebras/Slimpajama-627B Hzfinfdu/SlimPajama-3B 99 Reasoning Models Generate Societies of Thought Supplementary Table 4. SAE personality features more frequently activated after steering +10 surprise Feature Description Difference Ratio before steering Personality score Ratio after steering (+10 Surprise) 21065 26139 26820 14476 11280 22916 20151 8668 15118 26648 18858 8053 26894 2403 informal expressions of confusion or frustration regarding societal issues phrases related to social interaction and community engagement conditions or scenarios that involve decision-making or problem-solving references to emotional or sensational themes in narratives phrases indicating emotional or subjective experiences references to identities and backgrounds of people, particularly in literature and film contexts elements related to emotions and moral reflections discussions about literature and character analysis phrases related to personal feelings and social connections statements reflecting emotional conflict and self-reflection phrases that express opportunity, potential, or positive outlooks phrases associated with making choices or decisions words and phrases related to gambling or casino contexts references to social justice or humanitarian efforts dialogue and interactions that indicate emotional states or actions occurring within narrative context references to interpersonal relationships and emotional connections 0.107 0.027 0.134 0.084 0.059 0. 0.068 0.068 0.137 0.063 0.046 0. 0.055 0.068 0.123 0.044 0.108 0. 0.042 0.054 0.095 0.041 0.052 0. 0.037 0.058 0.096 0.033 0.019 0. 0.029 0.021 0.050 0.024 0.034 0. 0.024 0.075 0.098 0.022 0.016 0. 0.022 0.111 0.133 75 70 70 70 70 85 60 75 60 70 75 60 0.021 0.050 0.071 75 100 Reasoning Models Generate Societies of Thought Supplementary Table 5. SAE expertise features more frequently activated after steering +10 surprise Feature Description Difference Ratio before steering Expertise score Ratio after steering (+10 Surprise) 10105 18556 26139 8532 14476 32111 22705 11452 24623 22449 17611 23233 27631 5298 numeric values and their mathematical operations transitions and conclusions in logical argument or explanation mathematical concepts related to integers and their properties equations and mathematical expressions involving variables and operations mathematical symbols and expressions related to equations or functions mentions of quantities and their corresponding units in numerical or mathematical context equations or mathematical expressions mathematical terms related to geometry and spatial properties discussions regarding the implications and potential of alternative medical treatments, particularly in relation to traditional medical practices technical terms and concepts related to automotive engineering and intelligent systems mathematical expressions and their transformations numerical operations and mathematical expressions mathematical properties and functions related to periodicity and calculations numerical values and their relationships in mathematical expressions mathematical operations involving modular arithmetic phrases related to mathematical equations or computations 0.169 0.218 0.386 0.107 0.243 0. 0.084 0.059 0.143 0.072 0.052 0. 0.069 0.465 0.534 0.063 0.046 0. 0.055 0.418 0.474 0.054 0.058 0. 0.052 0.299 0.351 0.051 0.269 0. 0.051 0.085 0.136 0.050 0.039 0. 0.049 0.092 0.141 0.047 0.075 0. 0.046 0.224 0.269 0.045 0.204 0. 60 60 85 85 90 75 85 95 95 75 75 70 75 70 101 Reasoning Models Generate Societies of Thought Supplementary Table 6. PPO training hyperparameters Data and model Training/validation batch size Context window 128 / 640 1024 prompt + 1024 response tokens Optimization Actor learning rate Critic learning rate KL coefficient PPO mini-batch size Number of rollouts Rollout temperature Reward structure Accuracy weight Correct format weight 1e-06 1e-05 0.001 64 4 1.0 0.9 0.1 102 Reasoning Models Generate Societies of Thought Supplementary Table 7. Monologue-style and conversation-style fine-tuning data generated by Qwen-2.5-32B-IT Example 1: Number Theory Question: The greatest common divisor of positive integers and is 8. The least common multiple of and is 112. What is the least possible value of m+n? [Monologue-style] <think> To solve this problem, we need to use the relationship between the greatest common divisor (GCD) and the least common multiple (LCM) of two numbers. The product of the GCD and LCM of two numbers is equal to the product of the numbers themselves. This can be expressed as: GCD(m, n) LCM(m, n) = Given that GCD(m, n) = 8 and LCM(m, n) = 112, we can substitute these values into the equation: 8 112 = 896 = Since the GCD of and is 8, we can express and as 8a and 8b respectively, where and are coprime (i.e., GCD(a, b) = 1). Substituting these into the equation, we get: 8a 8b = 896 64ab = 896 ab = 14 Now, we need to find pairs (a, b) such that ab = 14 and GCD(a, b) = 1. The pairs of factors of 14 are: (1, 14) (2, 7) Since and must be coprime, the pair (1, 14) is valid, but the pair (2, 7) is also valid because 2 and 7 are coprime. We then calculate and for each pair: 1. For = 1 and = 14: = 8 1 = 8, = 8 14 = 112, + = 8 + 112 = 120 2. For = 2 and = 7: = 8 2 = 16, = 8 7 = 56, + = 16 + 56 = 72 The least possible value of + is 72. </think> <answer> 72 </answer> [Conversation-style] <cast_of_characters> <persona1> [Thinker 1 is meticulous mathematician with strong background in number theory. He is patient and methodical, preferring to break down problems into smaller, more manageable parts. He enjoys exploring multiple angles before arriving at conclusion.] </persona1> <persona2> [Thinker 2 is quick-witted and intuitive problem solver. She often relies on her gut feeling to guide her through the problem, but she also values rigorous proof. She is not afraid to challenge assumptions and enjoys the process of elimination.] </persona2> </cast_of_characters> 103 Reasoning Models Generate Societies of Thought <conversation> <think1> Given that the greatest common divisor (GCD) of and is 8 and the least common multiple (LCM) is 112, we can use the relationship between GCD and LCM: = GCD(m, n) LCM(m, n). Substituting the given values, we get = 8 112 = 896. </think1> <think2> Thats good starting point. Since the GCD of and is 8, we know that both and are multiples of 8. Lets express and as = 8a and = 8b, where and are coprime integers (i.e., GCD(a, b) = 1). This gives us (8a) (8b) = 896, which simplifies to 64ab = 896. Dividing both sides by 64, we get ab = 14. </think2> <think1> Exactly. Now we need to find pairs of coprime integers (a, b) whose product is 14. The possible pairs are (1, 14) and (2, 7). Since and must be coprime, we can discard (2, 7) because 2 and 7 are both factors of 14, but they are not coprime. This leaves us with (1, 14). </think1> <think2> Wait second. We cant discard (2, 7) just yet. While its true that 2 and 7 are factors of 14, they are indeed coprime because their greatest common divisor is 1. So, the valid pairs are (1, 14) and (2, 7). </think2> <think1> Youre right. overlooked that. Lets consider both pairs. For (a, b) = (1, 14), we get = 8 1 = 8 and = 8 14 = 112. For (a, b) = (2, 7), we get = 8 2 = 16 and = 8 7 = 56. Now, we need to find the least possible value of + n. </think1> <think2> For the pair (1, 14), we have + = 8 + 112 = 120. For the pair (2, 7), we have + = 16 + 56 = 72. The least possible value of + is 72. </think2> </conversation> <group_solution> 72 </group_solution> Example 2: Combinatorics Question: Elodie is putting on fashion show and has five fabulous outfits for her five fabulous fashion models. However, on the day of the show, two of the outfits were ruined in an unfortunate permanent marker incident. Regardless, the show must go on and the remaining outfits will be presented. If each outfit can only be worn by one model and there is no time for any model to wear more than one dress, how many different shows can Elodie put on? (Note: Two shows are considered the same if they contain the same models wearing the same dresses.) [Monologue-style] <think> To solve this problem, we need to determine the number of ways to assign three outfits to three models out of the original five models. Since two outfits were ruined, we only have three outfits left for the show. 1. We start with 5 models and 3 outfits. 2. The first outfit can be assigned to any of the 5 models. 3. Once the first outfit is assigned, the second outfit can be assigned to any of the remaining 4 models. 4. The third outfit can be assigned to any of the remaining 3 models. Thus, the number of ways to assign the three outfits to three of the five models is the product of these possibilities: 5 4 3 This calculation gives the total number of different shows Elodie can put on. 104 Reasoning Models Generate Societies of Thought </think> <answer> 60 </answer> [Conversation-style] <cast_of_characters> <persona1> [Thinker 1 is meticulous and detail-oriented mathematician who excels in combinatorics and probability. They are methodical in their approach and often consider all possible cases before concluding.] </persona1> <persona2> [Thinker 2 is creative and intuitive fashion designer who is skilled in visualizing scenarios and outcomes. They are quick to grasp the essence of problem and often provide practical insights.] </persona2> </cast_of_characters> <conversation> <think1> Okay, so Elodie has five outfits, but two were ruined. That leaves her with three outfits for her five models. We need to figure out how many different ways she can assign these three outfits to the models. </think1> <think2> Right, and since each model can only wear one outfit, we are essentially choosing 3 models out of 5 to wear the outfits. Then we need to think about how these outfits can be assigned to the selected models. </think2> <think1> Exactly. First, we need to calculate the number of ways to choose 3 models out of 5. This is combination problem, and the formula for combinations is C(n, k) = n! / (k!(n-k)!), where is the total number of items, and is the number of items to choose. </think1> <think2> So, we have = 5 and = 3. Lets calculate that. </think2> <think1> C(5, 3) = 5! / (3!(5-3)!) = 5! / (3!2!) = (5 4 3 2 1) / (3 2 1 2 1) = 10 ways to choose the 3 models. </think1> <think2> Now, for each of these 10 ways to choose the models, we need to consider how the 3 outfits can be assigned to these 3 models. This is permutation problem, as the order in which the outfits are assigned matters. </think2> <think1> Indeed, for each selection of 3 models, there are 3! (3 factorial) ways to assign the 3 outfits. So, 3! = 3 2 1 = 6 ways to assign the outfits. </think1> <think2> So, the total number of different shows is the number of ways to choose the models multiplied by the number of ways to assign the outfits. Thats 10 6. </think2> <think1> Which gives us 60 different shows. Thats the answer. </think1> </conversation> <group_solution> 60 </group_solution> Example 3: Logical Reasoning Question: Alice, Bob, Claire, Dave, and Eve are playing game. At the start of the game, they are each holding ball: Alice has brown ball, Bob has purple ball, Claire has black ball, Dave has green ball, and Eve has yellow ball. As the game progresses, pairs of players trade balls. First, Claire and Alice swap balls. Then, Bob and Alice swap balls. Then, Eve and Dave swap balls. Then, Dave and Claire swap balls. Finally, Alice and Bob swap balls. At the end of the game, Claire has the Options: (A) brown ball (B) purple ball (C) black ball (D) green ball (E) yellow ball 105 Reasoning Models Generate Societies of Thought [Monologue-style] <think> Lets track the ball swaps step by step. 1. Initial Positions: Alice: Brown Bob: Purple Claire: Black Dave: Green Eve: Yellow 2. First Swap (Claire and Alice): Alice: Black, Claire: Brown 3. Second Swap (Bob and Alice): Alice: Purple, Bob: Black 4. Third Swap (Eve and Dave): Eve: Green, Dave: Yellow 5. Fourth Swap (Dave and Claire): Claire: Yellow, Dave: Brown 6. Fifth Swap (Alice and Bob): Alice: Black, Bob: Purple At the end of the game, Claire has the yellow ball. </think> <answer> (E) yellow ball </answer> [Conversation-style] <cast_of_characters> <persona1> [Logical and detail-oriented, this thinker is mathematician who enjoys breaking down problems into smaller, more manageable parts. They are meticulous and prefer to double-check every step of their reasoning.] </persona1> <persona2> [An engineer by training, this thinker is practical and solution-focused. They prefer to use diagrams and visual aids to understand problems and are not afraid to reframe the problem if it leads to solution.] </persona2> <persona3> [A creative and intuitive thinker, this person excels at seeing patterns and connections that others might miss. They are bit more relaxed in their approach, often suggesting unconventional methods to solve problems.] </persona3> </cast_of_characters> <conversation> <think1> Lets start by laying out the initial positions of the balls. Alice has brown ball, Bob has purple ball, Claire has black ball, Dave has green ball, and Eve has yellow ball. Now, well go through the swaps one by one. </think1> <think2> Ill make diagram to keep track of the swaps. First, Claire and Alice swap, so Claire now has the brown ball, and Alice has the black ball. </think2> <think3> Good idea to use visual. Next, Bob and Alice swap. Bob will end up with the black ball, and Alice will have the purple ball. </think3> <think1> Then, Eve and Dave swap their balls. Eve will have the green ball, and Dave will have the yellow ball. </think1> <think2> Now, Dave and Claire swap. Claire will have the yellow ball, and Dave will have the brown ball. </think2> <think3> Finally, Alice and Bob swap. Bob will end up with the purple ball, and Alice will have the black ball. </think3> <think1> After all the swaps, Claire ends up with the yellow ball. So the answer is (E). </think1> 106 Reasoning Models Generate Societies of Thought </conversation> <group_solution> (E) yellow ball </group_solution> 107 Reasoning Models Generate Societies of Thought Supplementary Table 8. Supervised fine-tuning hyperparameters Data and Model Training/validation dataset size Context window Training/validation batch size 500 / 100 2048 64 / 64 Optimization Optimizer Peak learning rate Warmup Annealing Total epochs AdamW 1e-05 Linear (10% of total steps) Cosine 5 108 Reasoning Models Generate Societies of Thought Supplementary Table 9. Benchmark Tasks Benchmark Task Category BigBench Hard"
        },
        {
            "title": "GPQA",
            "content": "IFEval MATH (Hard) MMLU-Pro MUSR Boolean Expressions Causal Judgment Date Understanding Disambiguation Question Answering Formal Logical Fallacies Geometric Shape Reasoning Hyperbaton (Syntactic Reordering) Logical Deduction (Five Objects) Logical Deduction (Seven Objects) Logical Deduction (Three Objects) Movie Recommendation Navigation and Spatial Planning Object Counting Penguins in Table (Deductive Counting) Reasoning About Colored Objects Ruin Names (Linguistic Perturbation) Salient Translation Error Detection Snarks (Riddle Interpretation) Sports Understanding Temporal Sequence Reasoning Tracking Shuffled Objects (Five Objects) Tracking Shuffled Objects (Seven Objects) Tracking Shuffled Objects (Three Objects) Web of Lies (Deception Reasoning) Diamond Level Extended Level Main Benchmark Instruction-Following Consistency Evaluation Algebra (Hard) Counting & Probability (Hard) Geometry (Hard) Intermediate Algebra (Hard) Number Theory (Hard) Pre-Algebra (Hard) Pre-Calculus (Hard) Advanced Multidomain Knowledge Murder Mysteries (Collaborative Deduction) Object Placement (Spatial Coordination) Team Allocation (Group Strategy) # Problems 248 173 195 249 250 249 247 244 224 249 7 248 247 143 245 165 249 146 250 65 112 102 57 72 161 474 380 524 286 110 117 212 134 182 104 432 207 256 247 Reasoning Models Generate Societies of Thought Supplementary Table 10. Descriptive statistics of conversational behaviors and socio-emotional roles for reasoning and instruction-tuned models (Count variables) Reasoning Models Instruction-Tuned Models DeepSeekR1 QWQ-32B DeepSeekMean (SD) Mean (SD)"
        },
        {
            "title": "Conversational\nbehaviors",
            "content": "Question answering 6.74 Perspective shifts Conflict of perspectives Reconciliations Socio-emotional roles Ask for orientation"
        },
        {
            "title": "Observations",
            "content": "(4.32) 3.47 (2.76) 3.19 (2.95) 1.97 (1.60) 2.67 (5.14) 0.50 (1.73) 0.18 (0.87) 29.67 (23.44) 19.25 (18.08) 9.04 (7.80) 0.00 (0.13) 3.82 (5.37) 2.56 (5.15) 0.00 (0.07) 0.50 (1.12) 3.59 (4.83) 8,262 6.68 (4.62) 5.41 (6.89) 5.27 (5.51) 2.52 (1.90) 2.19 (3.80) 0.57 (1.94) 0.26 (1.10) 26.17 (21.06) 21.72 (22.64) 13.05 (12.33) 0.00 (0.06) 9.65 (11.53) 3.09 (5.41) 0.00 (0.05) 0.36 (0.87) 3.50 (4.64) Mean (SD) 3.07 (2.53) 1.09 (1.69) 1.50 (2.06) 0.61 (0.76) 0.01 (0.15) 0.00 (0.07) 0.00 (0.04) 8.26 (6.55) 4.15 (4.31) 2.23 (3.02) 0.01 (0.27) 0.14 (0.67) 0.49 (1.54) 0.01 (0.23) 0.02 (0.29) 0.18 (0.69) Qwen-2.532B-IT Llama-3.370B-IT Llama-3.18BIT Mean (SD) Mean (SD) Mean (SD) 2.35 (4.25) 0.79 (3.95) 0.97 (3.99) 0.41 (0.62) 0.01 (0.11) 0.00 (0.05) 0.00 (0.04) 7.00 (7.74) 3.09 (4.73) 2.17 (2.21) 0.00 (0.10) 0.03 (0.24) 0.16 (0.89) 0.01 (0.14) 0.00 (0.10) 0.04 (0.26) 2.22 (1.98) 0.97 (1.56) 1.08 (1.62) 0.58 (0.81) 0.00 (0.08) 0.00 (0.07) 0.00 (0.06) 6.20 (5.14) 3.74 (4.02) 2.50 (3.09) 0.00 (0.13) 0.21 (2.04) 0.25 (2.17) 0.00 (0.13) 0.01 (0.14) 0.03 (0.21) 3.16 (18.05) 1.84 (17.04) 2.25 (17.96) 0.49 (1.27) 0.01 (0.24) 0.01 (0.39) 0.01 (0.14) 8.52 (24.72) 4.60 (35.84) 3.05 (12.05) 0.01 (0.16) 0.65 (10.60) 0.88 (8.90) 0.02 (0.33) 0.06 (3.50) 0.06 (0.85) 110 Reasoning Models Generate Societies of Thought Supplementary Table 11. Structural equation model estimates linking DeepSeek-R1, conversational behaviors, socio-emotional roles, cognitive reasoning strategies, and accuracy Estimate Std.Err DeepSeek-R1 Question & Answering DeepSeek-R1 Perspective Shift DeepSeek-R1 Conflict of Perspectives DeepSeek-R1 Reconciliation DeepSeek-R1 Positive DeepSeek-R1 Negative DeepSeek-R1 Ask DeepSeek-R1 Give Question & Answering Verification Perspective Shift Verification Conflict of Perspectives Verification Reconciliation Verification Positive Verification Negative Verification Ask Verification Give Verification DeepSeek-R1 Verification Question & Answering Backtracking Perspective Shift Backtracking Conflict of Perspectives Backtracking Reconciliation Backtracking Positive Backtracking Negative Backtracking Ask Backtracking Give Backtracking DeepSeek-R1 Backtracking Question & Answering Subgoal setting Perspective Shift Subgoal setting Conflict of Perspectives Subgoal setting Reconciliation Subgoal setting Positive Subgoal setting Negative Subgoal setting Ask Subgoal setting Give Subgoal setting DeepSeek-R1 Subgoal setting Question & Answering Backward chaining Perspective Shift Backward chaining Conflict of Perspectives Backward chaining Reconciliation Backward chaining Positive Backward chaining Negative Backward chaining Ask Backward chaining Give Backward chaining 4.013 3.273 2.764 1.748 4.017 9.177 3.276 46.810 0.179 -0.096 0.216 -0.237 -0.023 0.055 -0.111 0.026 -0.673 -0.023 0.007 0.163 -0.005 -0.125 0.079 -0.024 0.014 -0.325 0.035 0.006 -0.036 0.089 0.010 0.007 0.005 0.008 0. -0.006 0.011 -0.003 -0.002 -0.002 0.005 0.004 0.001 0.066 0.067 0.065 0.016 0.055 0.121 0.050 0.408 0.070 0.107 0.113 0.109 0.129 0.057 0.039 0.015 0.327 0.037 0.071 0.065 0.082 0.040 0.028 0.016 0.006 0.129 0.016 0.012 0.016 0.021 0.012 0.004 0.010 0.003 0.087 0.002 0.002 0.002 0.003 0.001 0.001 0.001 0. 61.060 48.530 42.400 109.360 72.810 75.740 66.090 114.750 2.550 -0.890 1.910 -2.180 -0.180 0.960 -2.810 1.740 -2.060 -0.620 0.100 2.530 -0.060 -3.130 2.820 -1.510 2.320 -2.520 2.120 0.450 -2.220 4.270 0.830 1.680 0.540 2.490 2.570 -3.900 5.710 -1.510 -0.800 -1.720 3.760 2.870 2.950 p-value <0.001 <0.001 <0.001 <0.001 <0.001 <0.001 <0.001 <0.001 0.011 0.372 0.057 0.029 0.858 0.336 0.005 0.082 0.039 0.536 0.924 0.011 0.953 0.002 0.005 0.132 0.020 0.012 0.034 0.653 0.026 <0.001 0.409 0.093 0.587 0.013 0.010 <0.001 <0.001 0.132 0.422 0.086 <0.001 0.004 0.003 Reasoning Models Generate Societies of Thought DeepSeek-R1 Backward chaining Question & Answering Accuracy Perspective Shift Accuracy Conflict of Perspectives Accuracy Reconciliation Accuracy Positive Accuracy Negative Accuracy Ask Accuracy Give Accuracy Verification Accuracy Backtracking Accuracy Subgoal setting Accuracy Backward chaining Accuracy DeepSeek-R1 Accuracy Length Accuracy Observations 0.019 0.009 -0.006 -0.006 0.001 0.020 -0.001 0.001 0.000 0.005 -0.003 0.009 -0.001 0.253 -0. 0.007 0.001 0.001 0.002 0.003 0.003 0.000 0.001 0.000 0.001 0.001 0.004 0.006 0.007 0.005 2.730 0.006 7.730 -4.250 -3.240 0.330 6.660 -1.470 0.900 -1.450 3.400 -2.810 2.610 -0.180 35.060 -25.410 7, <0.001 <0.001 0.001 0.742 <0.001 0.141 0.367 0.147 0.001 0.005 0.009 0.855 <0.001 <0.001 Notes: All structural equation models control for task fixed effects. The statistical significance of coefficients is tested using two-sided t-tests. Out of 8,262 tasks, tasks from IFEval are excluded due to difficulties in accuracy evaluation (524 tasks), and we use the remaining 7,738 tasks."
        }
    ],
    "affiliations": [
        "Google, Paradigms of Intelligence Team",
        "Santa Fe Institute",
        "University of Chicago"
    ]
}