{
    "paper_title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
    "authors": [
        "Yutong Wang",
        "Siyuan Xiong",
        "Xuebo Liu",
        "Wenkang Zhou",
        "Liang Ding",
        "Miao Zhang",
        "Min Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2."
        },
        {
            "title": "Start",
            "content": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Yutong Wang 1 Siyuan Xiong 1 Xuebo Liu 1 Wenkang Zhou 1 Liang Ding 2 Miao Zhang 1 Min Zhang"
        },
        {
            "title": "Abstract",
            "content": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, testtime rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing retrieval-augmented rectifier to iteratively correct errors based on failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MASs task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging contextaware indicators to resolve wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/Age ntDropoutV2. 6 2 0 2 6 2 ] . [ 1 8 5 2 3 2 . 2 0 6 2 : r 1. Introduction Large language model (LLM)-based agents have achieved outstanding performance across wide range of tasks, including reasoning (Yao et al., 2023), planning (Prasad et al., *Equal contribution 1Harbin Institute of Technology, Shenzhen 2Alibaba Group. Correspondence to: Xuebo Liu <liuxuebo@hit.edu.cn>. Preprint. February 27, 2026. 1 Figure 1. Overview of AgentDropoutV2 versus AgentDropout. While AgentDropout directly discards erroneous agents, AgentDropoutV2 attempts iterative rectification before elimination. 2024), and action (Park et al., 2023). Despite the sophisticated designs that have enabled these agents to achieve significant gains, the single-model paradigm remains bottleneck that limits their potential. Consequently, growing body of research has shifted focus towards designing multiagent systems (MAS) to address more complex scenarios (Li et al., 2023; Guo et al., 2024). By harnessing collective intelligence (Zhuge et al., 2024; Wu et al., 2024) and orchestrating cooperative teams (Zhang et al., 2025d; Dang et al., 2025), MAS achieves remarkable performance in complex tasks such as software development (Hong et al., 2024; Qian et al., 2024), ultra-long context handling (Li et al., 2024a; Zhao et al., 2024), and scientific discovery (Ghafarollahi & Buehler, 2025; Ghareeb et al., 2025). However, the structural complexity of MAS also renders them susceptible to erroneous outputs from individual participants due to error propagation (Zhang et al., 2025f; Pan et al., 2025b). This necessitates the timely identification and pruning of incorrect information to prevent it from cascading to downstream agents and ultimately compromising the entire task. To mitigate the impact of errors, current research has predominantly diverged into two main paradigms: Structural Optimization and Parameter Internalization. The former seeks to constrain error pathways by engineering robust communication topologies, such as optimizing directed acyclic graphs (DAG) (Zhang et al., 2025c; Wang et al., 2025b; Zhang et al., 2025e). The latter focuses on enhancing the intrinsic reasoning of agents by fine-tuning them on failure trajectories (Motwani et al., 2025; Zhao et al., 2025) or utilizing process-supervision data (Lightman et al., 2024; AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Wang et al., 2025a; Zhang et al., 2025b). However, despite their contributions, these paradigms share critical bottleneck: the reliance on offline optimization at the expense of test-time adaptivity. As illustrated in Figure 1, methods like AgentDropout rely on pre-determined structural priors derived from training statistics. They enforce static connectivity graph that permanently excludes certain agents without attempting to rehabilitate their outputs or rectify their errors. Similarly, parameter-based methods depend on frozen weights, rendering them incapable of dynamic correction. This static nature prevents the system from salvaging potentially correctable errors during inference, highlighting the urgent need for test-time rectification framework that can actively intercept and resolve failures in real-time. To this end, we introduce AgentDropoutV2, an MAS information flow optimization framework based on test-time rectify-or-reject pruning. During the execution process, our method intercepts the output of each participant agent to perform iterative rectification before it is broadcast to downstream successors. Specifically, dedicated rectifier is prompted to scrutinize the output using adversarial indicators retrieved from pre-constructed pool of prior failure patterns, generating targeted feedback if errors are detected. If the rectification fails to resolve the issues, the erroneous output is pruned to strictly prevent error propagation. Experimental results demonstrate that our method significantly enhances MAS performance across diverse mathematical and code generation benchmarks by effectively rectifying and eliminating erroneous agent outputs. Extended analyses further confirm the systems adaptability, showing its capability to dynamically retrieve context-aware indicators based on task complexity, and to efficiently resolve distinct error patterns through variable iterative refinement. The observed correlation between pruning rates and reasoning difficulty positions our framework as potential task difficulty evaluator. Our main contributions are listed as follows: We propose test-time rectify-or-reject pruning method that intercepts and iteratively corrects agent outputs to effectively block error propagation in MAS, thereby safeguarding task performance against cascading degradation. We construct failure-driven indicator pool by distilling error patterns from failed MAS trajectories, providing an off-the-shelf knowledge base that encapsulates broad spectrum of reasoning pitfalls for precise error identification. We demonstrate that our method exhibits robust adaptivity across diverse task complexities and scenarios, confirming its effectiveness and generalization capability as plug-and-play intervention solution. 2. Preliminary Agent Definition We formulate the MAS workflow as an ordered sequence of agents, denoted as = (A1, A2, . . . , AN ). Each agent in this sequence Ai is selected from candidate set of all available agents A, and can be defined as tuple of three primary elements: Ai = (Φi, Ri, Ki) , (1) where: (1) Φi() represents the backbone model serving as the reasoning engine, which maps the input context to textual output; (2) Ri denotes the role specification, static set of instructions defining the agents persona, responsibilities, and constraints; (3) Ki represents the knowledge base, dynamic information repository containing the history of messages observable by agent Ai (Initially Ki = ). For an active agent Ai receiving an input denoted as xi, it utilizes its backbone model Φi to generate the output oi conditioned on its profile Ri and current knowledge Ki: oi = Φi (xi, Ri, Ki) . (2) Information Flow Once the output oi is generated, its dissemination is determined by the systems architecture, which is formalized as mapping function : 2A, which maps the current agent Ai to set of successor agents who are designated to receive the information. Then, the system updates the knowledge base of every successor agent Aj (Ai) by integrating the new message oi: Kj Kj {(Ri, oi)} , Aj (Ai). Through this mechanism, the framework-specialized mapping rigidly controls the information flow topology, ranging from broadcast structure (e.g., AutoGen) where (Ai) = A, to sequential chain where (Ai) = 1. (3) Control Flow Given task Q, the control flow of the MAS is modeled as the construction of an ordered sequence of agents, referred to as the inference trajectory. Specifically, upon the generation of output oi by the current agent Ai, routing policy π determines the next active agent Ai+1 based on the task, the existing sequence of activated agents, and their historical outputs: (4) Ai+1 = π (Q, A1:i, o1:i, A) . This iterative process constructs the execution path dynamically or statically, depending on the definition of π from the MAS framework. The workflow concludes when the sequence reaches the terminal output agent AN . Consequently, the final answer to the initial user task is defined as the output generated by this final agent, namely = oN . 3. Methodology We present test-time framework designed to intercept and refine agent outputs during the MAS execution. Specifi2 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Figure 2. Overview of the proposed framework. The upper block shows the test-time pipeline for iteratively rectifying agent outputs within the MAS. The lower block demonstrates the offline construction of the indicator pool via failure-driven mining and dual-stage deduplication. cally, before transmitting the output from agent Ai to its successors (Ai) (as defined in Eq. 3), we actively intercept the message. dedicated rectifier then scrutinizes the content for potential errors and attempts to resolve them through an iterative refinement process. If the output remains flawed despite these efforts, it is discarded rather than propagated, ensuring that downstream agents are shielded from unreliable information. 3.1. Test-Time Rectify-or-Reject Pruning Blindly prompting an agent to self-correct is often counterproductive; without specific direction on what went wrong, the agent may inadvertently introduce new hallucinations or simply rephrase the original error. To ensure the rectification is effective, it is essential to ground the refinement process on specific, verifiable standards. Therefore, we employ adversarial indicators to scrutinize the output for distinct error patterns. If specific error types are detected, these indicators guide the generation of targeted feedback, providing the agent with clear roadmap for correction. Relevant Indicator Retrieval To support this targeted supervision, our framework incorporates an Indicator Pool, denoted as I. Constructed offline via failure-driven mining strategy (detailed in 3.2), this repository encapsulates empirical knowledge regarding wide spectrum of potential errors that may emerge during MAS execution. Each indicator within this pool is structured as tuple = (n, d, c): 3 (Name): unique identifier for the specific error type. (Error Definition): description of the erroneous behavior, which serves as the standard to verify whether the agents output has deviated from requirements. (Trigger Condition): context describing when this specific error is likely to occur, which acts as filter to ensure the indicator is only retrieved in relevant scenarios. Leveraging this structured repository, we can now retrieve the most pertinent indicators to supervise the current reasoning step. For an active agent Ai producing an output o(t) at the t-th iteration (initially o(0) ), we first employ dedicated Rectifier Model Φrect to distill the semantic essence of the reasoning context. The rectifier extracts two distinct sets of keywords: (1) (t) scen, summarizing the task scenarios (e.g., geometric coordinates, algebraic operations, etc); (2) (t) act , representing the specific action types proposed by the agent. We transform these keywords into query vector q(t) act ) using an embedding model Memb. Subsequently, we retrieve the top-Kact most relevant indicators from whose trigger conditions exhibit the highest semantic similarity to the current query, forming the active indicator set (t) act : = Memb(S (t) scen (t) AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning (t) act = Top-Kact Ij (cid:32) (cid:33) , q(t) q(t) cj cj (5) where cj represents the trigger condition cjs embedding. MAS execution from scratch. This guarantees the final solution always emerges from sufficiently robust consensus, preventing degeneration into fragmented reasoning. Rectify-or-Reject Pruning The rectifier then evaluates the output o(t) against each retrieved indicator Ik = (nk, dk, ck), conditioned on the agents input xi and role Ri. For each indicator, the model generates binary violation flag v(t) {0, 1} and diagnostic rationale r(t) : (cid:16) (cid:16) o(t) xi, Ri, Ik , r(t) v(t) = Φrect (6) (cid:17) (cid:17) , where v(t) by Ik has been violated. = 1 signifies that the specific constraint defined We enforce strict zero-tolerance policy for the rectification procedure, where the global error state E(t) is immediately activated if any single indicator within the active set detects violation. Consequently, we derive the binary global error state E(t) and aggregate the specific feedback (t) as: v(t) (7) E(t) = max IkI (cid:110) r(t) (t) = (t) act Ik (t) act v(t) = 1 (cid:111) . (8) The rectification trajectory follows tri-state gating mechanism derived from the global assessment result E(t): Pass: If no significant error is detected (E(t) = 0), the output is accepted immediately: oi = o(t) . Retry: If the global error state is activated (E(t) = 1) and the iteration count has not exceeded the preset upper limit (t < Tmax), the agent regenerates its output conditioned on the feedback (t): xi, Ri, Ki, (t)(cid:17) (cid:16) If errors persist at the maximum iteration (E(Tmax) = 1), the output is discarded (oi = ) to act as semantic circuit breaker, preventing error propagation to downstream nodes. Reject: o(t+1) = Φi (9) . Ultimately, the final message transmitted to the successor set (Ai) is defined as: oi = (cid:40) o(t) if Tmax s.t. E(t) = 0, otherwise. (10) Global Fallback against Structural Degeneration While pruning ensures purity, excessive filtering risks destroying connectivity. Analogous to the principle of critical mass in collaborative dynamicswhich posits that group must maintain sufficient size to sustain effective interaction and consensuswe introduce safeguard against structural collapse. If the remaining message count falls below safety threshold γ, the MAS is deemed to have lost its reasoning integrity. Instead of forcing conclusion from this sparse context, we trigger system-wide reset to conduct Handling Zero-Shot Scenarios In scenarios where training dataset is unavailable to construct domain-specific indicator pool, our framework provides an optional solution. We initialize Iact with single, universally applicable general indicator Igen = (General Logic Check, dgen, cgen). Here, dgen prompts the model to check for logical consistency and hallucination, while cgen is set to always trigger. This ensures that the rectify-or-reject pruning remains functional and effective even in zero-shot settings without prior failure pattern mining. The pseudo-code for the test-time rectify-or-reject pruning is provided in Appendix A.1, and detailed prompt specifications are listed in Appendix A.2. Additionally, comprehensive case study demonstrating the rectification process is presented in Appendix A.4. 3.2. Failure-Driven Indicator Pool Construction Just as mature organizations rely on institutional memory, which codifies lessons learned from past projects to prevent the recurrence of known pitfalls, our framework necessitates structured repository of error patterns. Blindly correcting errors without understanding their origins is inefficient; effective rectification requires reference to historical mistakes. To this end, we construct repository of adversarial indicators by mining historical failure cases. This process transforms raw failure trajectories into structured knowledge base, serving as comprehensive handbook of prohibitions to guide the agents real-time rectification. Offline Indicator Mining As illustrated in the lower block of Figure 2, we focus on collecting execution strategies where the MAS fails to deliver the correct solution. Let Dsrc = {Q, } denote the source dataset, where and represent the input query and the corresponding groundtruth answer, respectively. For each instance, we conduct full inference roll-out to obtain the MAS execution trajectory = (Q, A1:N , o1:N , Y). We collect failure cases where the solution diverges from the ground truth into failure set Dfail. teacher model Φteach then scrutinizes individual agents within Dfail. Upon detecting deviation in agent Ais output oi given its role Ri and the overall task Q, Φteach synthesizes set of indicators: Inew = Φteach (T , , Ri, oi) . (11) Redundancy Elimination Since identical or highly similar error patterns frequently recur across different failure trajectories, naive accumulation of indicators would result in bloated repository saturated with duplicate constraints. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Table 1. Performance comparison of our method against baseline reasoning techniques across mathematical domain benchmarks. OlymB, OlymE, and OlymH represent OlympiadBench, OlymMATH Easy, and OlymMATH Hard, respectively. System Single AutoGen w/ Generic Indicators w/ Retrieved Indicators GSM8K MATH-500 AQuA AMC23 OlymB OlymE OlymH AIME24 AIME25 Average 87.64 91.36 90.52 91.74 74.80 76.80 77.40 78.40 84.19 85.03 84.98 87. 62.50 62.50 72.50 75.00 47.56 48.89 50.37 51.11 20.00 19.00 26.00 25.00 16.00 17.00 11.00 19.00 13.33 26.67 33.33 40.00 20.00 13.33 23.33 30. 47.34+0.00 48.95+1.62 52.16+4.82 55.25+7.92 Such redundancy poses critical risk to the retrieval mechanism, as it may cause the top-Kact retrieved indicators to be dominated by single error type, thereby crowding out other diverse but equally critical constraints and limiting the multi-dimensional evaluation of agent outputs. To prevent this semantic collapse and ensure compact, high-entropy global pool I, we employ dual-stage deduplication process. For newly generated indicator Inew, we obtain its semantic vector vnew = Memb(dnew cnew) by encoding the concatenation of its description and triggering condition using an embedding model Memb. Then we retrieve the most similar existing indicators Isim of size Kdedup based on cosine similarity. deduplication LLM Φdedup is then employed to verifies redundancy, adding Inew to only if it represents novel error pattern: (cid:40) {Inew} if Φdedup (Inew, Isim) , otherwise. (12) Examples of the constructed indicators, along with the general indicators used for scenarios where specific pool is unavailable, are provided in Appendix A.2. 4. Experiment 4.1. Experimental Setup MAS Framework We employ the SelectorGroupChat1 framework within AutoGen (Wu et al., 2024)the current de facto standard for MASthereby grounding our implementation in widely used infrastructure that features classic automatic routing mechanism. In this setup, selector iteratively identifies the next speaker based on context, where decision agent formulates the final conclusion. Crucially, communication is globally transparent, meaning that every message is broadcast to all participants, establishing shared reasoning environment. Backbone Models We adopt GPT-4.1-mini-2025-04142 as the backbone of the AutoGen MAS selector. For the reasoning components encompassing all participants and 1https://microsoft.github.io/autogen/stab le/user-guide/agentchat-user-guide/selecto r-group-chat.html 2https://platform.openai.com/docs/models/ gpt-4.1-mini rectifiers, we deploy Qwen3-8B3 and Qwen3-4B, configured with the thinking mode explicitly disabled. For the offline indicator pool construction process, GPT-4o-2024-08-06 and GPT-4.1-mini-2025-0414 serve as the foundation for the teacher and deduplicator, respectively. Finally, Qwen3Embedding-8B is adopted as the embedding model Memb. Datasets We comprehensively evaluate the performance of our method across two primary domains: mathematical reasoning and code generation. For mathematical reasoning, we employ nine benchmarks spanning spectrum of difficulty levels, including GSM8K (Cobbe et al., 2021), MATH-500 (Lightman et al., 2024), AQuA (Patel et al., 2021), AMC234, OlympiadBench (He et al., 2024), OlymMATH Easy, OlymMATH Hard (Sun et al., 2025), AIME24 (Zhang & Math-AI, 2024), and AIME25 (Zhang & Math-AI, 2025). For code generation capabilities, we assess the model on four established datasets: MBPP (Austin et al., 2021), HumanEval (Chen et al., 2021), CodeContests (Li et al., 2022), and LiveCodeBenchV1 (Jain et al., 2025). Regarding the indicator pool construction, we leverage the training splits of MATH and AQuA as source corpora to sample trajectories and distill adversarial indicators specifically for the mathematical domain. Detailed statistics for each dataset and the indicator pool are provided in Appendix A.3. Hyper-Parameters We set the max chat turns of SelectorGroupChat to 6, and the max reflection turns Tmax to 3. We set the number of retrieved indicators for test-time matching to Kact = 5, while the retrieval count for the deduplication process during pool construction is set to Kdedup = 20. The safety threshold γ of the remaining message count for triggering the global fallback against structural degeneration is set to 1. The temperature of the rectifier is set to 0, and the others remain 0.7. 4.2. Main Results Table 1 presents the comparative performance of our proposed framework against baseline approaches across nine mathematical reasoning benchmarks with Qwen3-8B as the backbone model. Our full method (w/ Retrieved Indicators) demonstrates consistent superiority, surpassing the baselines 3https://huggingface.co/Qwen/Qwen3-8B 4https://huggingface.co/datasets/math-ai/ amc23 5 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Table 2. Performance comparison of our method against baselines using Qwen3-4B as the backbone model. The indicator pool is transferred directly from Qwen3-8B source model to the Qwen3-4B agents to test transferability. System Single AutoGen w/ Generic Indicators w/ Retrieved Indicators GSM8K MATH-500 AQuA AMC23 OlymB OlymE OlymH AIME24 AIME25 Average 84.53 88.02 88.32 90. 75.00 73.60 77.00 77.04 82.68 85.04 85.04 87.80 62.50 67.50 62.50 70.00 44.44 47.56 49.33 47.70 23.00 23.00 21.00 21.00 16.00 13.00 13.00 14. 13.33 30.00 30.00 26.67 26.67 16.67 20.00 20.00 47.57+0.00 49.38+1.81 49.58+2.01 50.54+2.97 Table 3. Performance comparison of our method against baseline reasoning techniques across code domain benchmarks. System Single AutoGen w/ Generic Indicators MBPP HumanEval CodeContests LiveCodeBench Average 64.98 65.37 68.09 81.37 85.09 84.50 4.85 6.06 9. 24.50 29.25 32.75 43.93+0.00 46.44+2.52 48.65+4.72 across all benchmarks. It achieves the highest average accuracy of 55.25%, achieving an average accuracy gain of 6.3 percentage points compared to the AutoGen baseline. While the native AutoGen framework provides marginal improvement over the single-agent setting (+1.62% on average), it struggles in complex scenarios (e.g., dropping to 13.33% on AIME25). By introducing the feedback-based mechanism in the absence of pre-built indicator pool (w/ Generic Indicators), which applies generic verification logic, we observe substantial performance leap to 52.16%. This confirms that the rectify-or-reject architecture itself provides robust safety net for multi-agent reasoning. Crucially, by retrieving task-specific constraints from the equipped indicator pool (w/ Retrieved Indicators), our method further achieves massive gains on highly difficult tasks like AIME25 (improving from 23.33% to 30.00%). This demonstrates that while the rectification mechanism provides the means to correct errors, the indicator pool provides the necessary guidance to accurately pinpoint issues and ensure effective refinement. 4.3. Cross-Model and Cross-Domain Transferability Indicator Portability across Models We investigate scalability by deploying the indicator pool mined by Qwen3-8B directly to smaller Qwen3-4B backbone. As shown in Table 2, this yields robust gains across most benchmarks, confirming that fundamental reasoning pitfalls are largely scale-invariant. While performance plateaus on complex tasks due to minor misalignments between high-level indicators and rudimentary failures, the overall success validates build once, deploy anywhere paradigm. This enables capable models to construct offline knowledge bases that effectively supervise resource-constrained edge models without redundant mining. domain sharing the rigorous logic requirements of mathematics. As shown in Table 3, our method consistently outperforms standard baselines, achieving superior average accuracy of 48.65% compared to AutoGens 46.44%. Notably, the improvements are most pronounced in complex benchmarks like CodeContests (6.06% 9.26%) and LiveCodeBench (29.25% 32.75%). This confirms that the rectify-or-reject pruning is not limited to math but serves as generalizable reasoning enhancer, effectively mitigating errors across diverse complex reasoning tasks. 5. Analysis 5.1. Ablation Study Impact of Rectification Iteration Rounds We first examine the impact of the rectification iteration budget Tmax on overall performance. As shown in Block of Table 4, setting Tmax = 0 (no rectification) leads to sharp performance drop, especially on complex tasks like AIME24, confirming that initial outputs often contain errors requiring active correction. However, increasing the budget to Tmax = 4 does not yield further improvements, suggesting that excessive iterations may induce over-correction or introduce noise. Thus, our default Tmax = 3 strikes the optimal balance between efficiency and thoroughness. Sensitivity to Retrieved Indicator Count Next, we explored the impact of the number of retrieved indicators as shown in Block II of Table 4. Both reducing the retrieved count to = 3 and increasing it to = 8 degrade performance compared to the optimal setting of = 5. This indicates that while agents benefit from diverse failure patterns, providing an excessive number of indicators results in information overload, distracting the model with less relevant constraints rather than aiding the reasoning process. Cross-Domain Generalization We further assess the versatility of our framework by extending it to code generation, Effectiveness of the Retrieval Mechanism To validate that performance gains stem from relevant guidance, we re6 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Table 4. Results of the ablation study. System Ours GSM8K MATH500 AQuA AMC23 OlymB OlymE OlymH AIME24 AIME25 Average 91.74 78.40 87.01 75. 51.11 25.00 19.00 40.00 30.00 55. 0 Iterations 2 Iterations 4 Iterations 91.96 91.96 91.74 3 Indicators 8 Indicators 91.74 91.74 76.40 78.20 78.40 77.00 78. (I) Rectification Iteration Rounds (Tmax, Default: 3) 14.00 16.00 12.00 70.00 72.50 72.50 46.37 46.52 49.33 19.00 32.00 30.00 87.80 86.61 86.22 (II) Number of Retrieved Indicators (Kact, Default: 5) 17.00 18. 67.50 65.00 52.59 48.15 25.00 29.00 85.04 86.96 23.33 30.00 36.67 33.33 33. 26.67 16.67 16.67 30.00 23.33 50.61 52.27 52.61 53.24 52.63 Random 5 91. 76.60 83.46 67.50 48.00 25.00 13. 23.33 23.33 50.21 (III) Indicator Retrieval Mechanism w/o Dedup 92. 79.40 86.61 72.50 50.37 26.00 17. 30.00 23.33 53.03 (IV) Indicator Pool Deduplication Figure 3. Distribution of rectification iterations across different benchmarks. Simpler tasks exhibit high first-pass rates, whereas complex tasks necessitate more refinement rounds and result in higher rejection rates due to persistent errors. This contrast demonstrates that our method dynamically modulates its intervention intensity according to task complexity. placed the retrieved indicators with five indicators randomly sampled from the pool. As shown in Block III of Table 4, the average accuracy decreases to 50.21%, score even lower than the 0 Iterations setting. This critical comparison proves that the systems success depends strictly on the semantic relevance of the constraints, which is necessary for locating specific error patterns to guide the agent. Necessity of Pool Deduplication Finally, we demonstrate the necessity of the deduplication operation during indicator pool construction. As shown in Block IV of Table 4, removing the dual-stage deduplication process also causes an average accuracy decrease. This decline suggests that without the deduplication process, the retrieved top-k indicators are occupied by redundant variations of the same or similar error patterns. As result, this lack of diversity prevents the agent from receiving comprehensive safety check. This validates the importance of our compact, high-entropy pool construction strategy. Figure 4. Jaccard similarity between the set of ten most frequently used indicators across different benchmarks. Indicators chosen for similar tasks tend to have higher overlaps. This distribution reveals that our indicator pool is diverse enough to cover wide range of failure modes. 5.2. Iteration Dynamics and Adaptability We analyze the distribution of iteration rounds across varying difficulties to evaluate the adaptability of our method. The results are visualized in Figure 3, where Pass @ k-th indicates the proportion of outputs successfully rectified and accepted at the k-th iteration, while Rejected denotes instances that remained erroneous after exhausting the maximum budget. pronounced correlation exists between task complexity and rectification depth. Simpler datasets (e.g., GSM8K) exhibit high Pass @ 1st rate (60.1%), indicating immediate acceptance. Conversely, complex tasks like AIME 24/25 show significant shift toward multi-round rectifications and rejection rates exceeding 60%. This demonstrates that our method dynamically modulates intervention intensity, conserving resources on simple queries while allocating sustained effort to resolve intricate errors in challenging scenarios. Moreover, this strong correlation allows our framework to double as potential difficulty evaluator, where the aggregate rectification depth and rejection rate serve as quantifiable proxies for dataset complexity. 7 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning 5.3. Distribution of Retrieved Indicators To provide deeper insight into the composition and utility of our constructed indicator pool, we analyzed the overlaps of the retrieved active indicators across distinct task domains. Specifically, we identify the sets of ten most frequently retrieved indicators for different benchmarks and calculate the pair-wise Jaccard similarity (the ratio of the size of the intersection to the size of the union). The resulting heatmap in Figure 4 reveals distinct block-wise correlation pattern. Benchmarks requiring similar reasoning capabilities exhibit high indicator overlap. For instance, foundational math datasets like GSM8K and AQuA share significant similarity of 0.43, suggesting they suffer from common failure modes. Conversely, the overlap drops precipitously when comparing foundational tasks with advanced Olympiadlevel challenges (e.g., GSM8K vs. AIME25 yields nearly no overlap). This sharp separation confirms that error patterns are highly task-dependent. It further validates that our constructed pool is diverse enough to cover wide spectrum of failure modes, and that the retrieval mechanism effectively isolates the specific, context-aware constraints required for each unique domain. 6. Related Work As MAS scales to handle complex tasks, they become increasingly vulnerable to error propagation, where individual mistakes amplify downstream and disrupt the entire reasoning process. To address this, prior research focuse on three resilience strategies: (1) robust architecture design, (2) error monitoring, and (3) utilization of inference trajectories. Robust MAS Architectures Existing research attempts to mitigate the propagation of erroneous and redundant information by engineering more robust system structures. Several studies explicitly model MAS as optimizable graphs or topologies, employing learning or search algorithms to identify superior workflow structures (Zhuge et al., 2024; Zhang et al., 2025d; Wang et al., 2025b; Zhang et al., 2025a). Adopting sparse communication topologies has also proven effective in reducing noise disturbance (Li et al., 2024b). Furthermore, introducing advanced initialization, orchestration or routing strategies to construct cooperative teams with specialized roles can further suppress the spread of errors originating from underperforming agents (Tian et al., 2025; Dang et al., 2025; Zhang et al., 2025g; Wang et al., 2026; Ong et al., 2025). Error Monitoring Mechanisms These methods focus on designing or training monitors to detect anomalies within the MAS workflow, thereby enabling information correction to prevent error cascading. Graph-based approaches treat information flow and topology as signals, utilizing anomaly detectors to capture abnormal patterns and identify system errors (Wang et al., 2025a; Zhou et al., 2025; Pan et al., 2025a). Test-time rectification serves as an efficient intervention strategy, implementing an interceptdetect-correct process for each action or message within the system (Xiang et al., 2024; Chen et al., 2025b; Luo et al., 2025). Conversely, error attribution and tracking methods aim to perform root cause analysis, identifying the specific agents responsible for introducing hallucinatory or incorrect information upon task failure (Zhang et al., 2025f; Pan et al., 2025b; Zhang et al., 2025b; Ge et al., 2025). Utilization of Inference Trajectories These approaches enhance MAS reliability by leveraging real execution trajectories to construct preference or contrastive data for training key components (e.g., reasoners or planners), thereby improving reasoning accuracy (Chen et al., 2025a; Motwani et al., 2025; Zhao et al., 2025). Process-aware variants further verify intermediate steps to provide fine-grained supervision, preventing models from falling into locally plausible but globally incorrect reasoning paths (Zelikman et al., 2022; Lightman et al., 2024). Additionally, some works mine exploration or failure trajectories as hard negatives to strengthen preference optimization, rendering the system more robust against misleading intermediate states (Song et al., 2024; Aksitov et al., 2024; Lyu et al., 2025). Our framework integrates these paradigms to overcome their limitations. Unlike rigid structural designs, our approach serves as model-agnostic, plug-and-play module adaptable to diverse frameworks. We advance error monitoring from passive detection to active rectification, ensuring real-time stability via feedback-driven reflection. Finally, leveraging trajectory utilization, we distill historical failures into an adversarial indicator pool, providing precise, prior-guided online supervision."
        },
        {
            "title": "Conclusion",
            "content": "In this paper, we introduced AgentDropoutV2, novel framework designed to optimize information flow in MAS via test-time rectify-or-reject pruning. By mining historical failure trajectories, we constructed an indicator pool that encapsulates domain-specific error patterns. During test-time inference, our framework actively intercepts agent outputs, retrieves pertinent indicators, and enforces an iterative refinement process to resolve latent errors before they propagate. Experimental results demonstrate that this mechanism effectively cleanses the information flow, thereby significantly enhancing system accuracy. Furthermore, our analysis confirms that the indicator retrieval and rectification processes exhibit strong adaptivity to varying task difficulties, along with robust transferability across different domains and backbone models. 8 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning"
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents work aiming to enhance the reliability and accuracy of Multi-Agent Systems through test-time error rectification and pruning. By actively identifying and intercepting erroneous reasoning and hallucinations before they propagate, our framework contributes to the development of more robust and trustworthy automated systems, particularly in domains requiring rigorous logic, such as mathematics and software development. While the construction of adversarial indicators relies on historical data, potentially reflecting existing data distributions, the methodology itself serves to enforce constraints and improve adherence to ground truth. We do not foresee specific negative societal consequences or ethical concerns beyond those generally associated with the development and deployment of large language models."
        },
        {
            "title": "References",
            "content": "Aksitov, R., Miryoosefi, S., Li, Z., Li, D., Babayan, S., Kopparapu, K., Fisher, Z., Guo, R., Prakash, S., Srinivasan, P., Zaheer, M., Yu, F., and Kumar, S. ReST meets react: Self-improvement for multi-step reasonIn ICLR 2024 Workshop on Large ing LLM agent. Language Model (LLM) Agents, 2024. URL https: //openreview.net/forum?id=7xknRLr7QE. Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021. URL https: //arxiv.org/abs/2108.07732. Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. URL https://arxiv.org/abs/2107.03374. Chen, W., Yuan, J., Qian, C., Yang, C., Liu, Z., and Sun, M. Optima: Optimizing effectiveness and efficiency for LLM-based multi-agent system. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Findings of the Association for Computational Linguistics: ACL 2025, pp. 1153411557, Vienna, Austria, 2025a. Association for Computational Linguistics. ISBN 979-8-89176-2565. doi: 10.18653/v1/2025.findings-acl.601. URL https://aclanthology.org/2025.findin gs-acl.601/. Chen, Z., Kang, M., and Li, B. Shieldagent: Shielding agents via verifiable safety policy reasoning. In Fortysecond International Conference on Machine Learning, 2025b. URL https://openreview.net/forum ?id=DkRYImuQA9. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. URL https: //arxiv.org/abs/2110.14168. Dang, Y., Qian, C., Luo, X., Fan, J., Xie, Z., Shi, R., Chen, W., Yang, C., Che, X., Tian, Y., Xiong, X., Han, L., Liu, Z., and Sun, M. Multi-agent collaboration via evolving orchestration. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. URL https://openreview.net/forum?id=L0xZ PXT3le. Ge, Y., Xie, L., Li, Z., Pei, Y., and Zhang, T. Who is introducing the failure? automatically attributing failures of multi-agent systems via spectrum analysis. arXiv preprint arXiv:2509.13782, 2025. URL https: //arxiv.org/abs/2509.13782. Ghafarollahi, A. and Buehler, M. J. Sciagents: automating scientific discovery through bioinspired multi-agent intelligent graph reasoning. Advanced Materials, 37(22): 2413523, 2025. URL https://advanced.onlin elibrary.wiley.com/doi/full/10.1002/ adma.202413523. Ghareeb, A. E., Chang, B., Mitchener, L., Yiu, A., Szostkiewicz, C. J., Laurent, J. M., Razzak, M. T., White, A. D., Hinks, M. M., and Rodriques, S. G. Robin: multi-agent system for automating scientific discovery. arXiv preprint arXiv:2505.13400, 2025. URL https://arxiv.org/abs/2505.13400. Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., Wiest, O., and Zhang, X. Large language model based multi-agents: survey of progress and challenges. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI 2024, Jeju, South Korea, August 3-9, 2024, pp. 80488057. ijcai.org, 2024. URL https://www.ijcai.org/procee dings/2024/890. He, C., Luo, R., Bai, Y., Hu, S., Thai, Z., Shen, J., Hu, J., Han, X., Huang, Y., Zhang, Y., et al. OlympiadBench: challenging benchmark for promoting AGI with olympiad-level bilingual multimodal scientific problems. In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 38283850, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acllong.211. URL https: //aclanthology.org/2024.acl-long.211/. Hong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., et al. 9 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Metagpt: Meta programming for multi-agent collaborative framework. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https: //openreview.net/forum?id=VtmBAGCN7o. Jain, N., Han, K., Gu, A., Li, W., Yan, F., Zhang, T., Wang, S., Solar-Lezama, A., Sen, K., and Stoica, I. Livecodebench: Holistic and contamination free evaluation of large language models for code. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025. URL https://openreview.net/forum ?id=chfJJYC3iL. Li, G., Hammoud, H., Itani, H., Khizbullin, D., and Ghanem, B. CAMEL: communicative agents for mind exploration of large language model society. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/pa per/2023/hash/a3621ee907def47c1b952a de25c67698-Abstract-Conference.html. Li, S., He, Y., Guo, H., Bu, X., Bai, G., Liu, J., Liu, J., Qu, X., Li, Y., Ouyang, W., et al. GraphReader: Building graph-based agent to enhance long-context abilities of large language models. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 12758 12786, Miami, Florida, USA, 2024a. Association for Computational Linguistics. doi: 10.18653/v1/2024.f indings-emnlp.746. URL https://aclanthology .org/2024.findings-emnlp.746/. Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Lago, A. D., et al. Competition-level code generation with alphacode. Science, 378(6624):10921097, 2022. doi: 10.1126/science.abq1158. URL https://www.scie nce.org/doi/abs/10.1126/science.abq1 158. Li, Y., Du, Y., Zhang, J., Hou, L., Grabowski, P., Li, Y., and Ie, E. Improving multi-agent debate with sparse communication topology. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 72817294, Miami, Florida, USA, 2024b. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-emnlp.427. URL https://aclanthology.org/2024.fi ndings-emnlp.427/. Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker, B., Lee, T., Leike, J., Schulman, J., Sutskever, I., and Cobbe, K. Lets verify step by step. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum ?id=v8L0pN6EOi. Luo, W., Dai, S., Liu, X., Banerjee, S., Sun, H., Chen, M., and Xiao, C. AGrail: lifelong agent guardrail with effective and adaptive safety detection. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 81048139, Vienna, Austria, 2025. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.399. URL https: //aclanthology.org/2025.acl-long.399/. Lyu, Y., Yan, L., Wang, Z., Yin, D., Ren, P., de Rijke, M., and Ren, Z. MACPO: weak-to-strong alignment via multi-agent contrastive preference optimization. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025. URL https://openreview .net/forum?id=x1Okv4kbVR. Motwani, S. R., Smith, C., Das, R. J., Rafailov, R., Laptev, I., Torr, P., Pizzati, F., Clark, R., and de Witt, C. S. MALT: Improving reasoning with multi-agent LLM training. In Workshop on Reasoning and Planning for Large Language Models, 2025. URL https://openreview .net/forum?id=lIf7grAC7n. Ong, I., Almahairi, A., Wu, V., Chiang, W.-L., Wu, T., Gonzalez, J. E., Kadous, M. W., and Stoica, I. RouteLLM: Learning to route LLMs from preference data. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net /forum?id=8sSqNntaMr. Pan, J., Liu, Y., Miao, R., Ding, K., Zheng, Y., Nguyen, Q. V. H., Liew, A. W.-C., and Pan, S. Explainable and fine-grained safeguarding of llm multi-agent systems via bi-level graph anomaly detection. arXiv preprint arXiv:2512.18733, 2025a. URL https://arxiv.or g/abs/2512.18733. Pan, M. Z., Cemri, M., Agrawal, L. A., Yang, S., Chopra, B., Tiwari, R., Keutzer, K., Parameswaran, A., Ramchandran, K., Klein, D., Gonzalez, J. E., Zaharia, M., and Stoica, I. Why do multiagent systems fail? In ICLR 2025 Workshop on Building Trust in Language Models and Applications, 2025b. URL https://openreview.net/forum ?id=wM521FqPvI. 10 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Park, J. S., OBrien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pp. 122, 2023. URL https://dl.acm .org/doi/abs/10.1145/3586183.3606763. Patel, A., Bhattamishra, S., and Goyal, N. Are NLP models really able to solve simple math word problems? In Toutanova, K., Rumshisky, A., Zettlemoyer, L., Hakkani-Tur, D., Beltagy, I., Bethard, S., Cotterell, R., Chakraborty, T., and Zhou, Y. (eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 20802094, Online, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168. URL https://ac lanthology.org/2021.naacl-main.168/. Prasad, A., Koller, A., Hartmann, M., Clark, P., Sabharwal, A., Bansal, M., and Khot, T. ADaPT: Asneeded decomposition and planning with language modIn Duh, K., Gomez, H., and Bethard, S. (eds.), els. Findings of the Association for Computational Linguistics: NAACL 2024, pp. 42264252, Mexico City, Mexico, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findingsnaacl.264. URL https://aclanthology.org/2024.findin gs-naacl.264/. Qian, C., Liu, W., Liu, H., Chen, N., Dang, Y., Li, J., Yang, C., Chen, W., Su, Y., Cong, X., et al. ChatDev: Communicative agents for software development. In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 15174 15186, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.810. URL https://aclanthology.org/2024.ac l-long.810/. Song, Y., Yin, D., Yue, X., Huang, J., Li, S., and Lin, B. Y. Trial and error: Exploration-based trajectory optimization of LLM agents. In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 75847600, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.409. URL https://acla nthology.org/2024.acl-long.409/. Sun, H., Min, Y., Chen, Z., Zhao, W. X., Liu, Z., Wang, Z., Fang, L., and Wen, J.-R. Challenging the boundaries of reasoning: An olympiad-level math benchmark for large language models. arXiv preprint arXiv:2503.21380, 2025. URL https://arxiv.org/abs/2503.21380. Tian, C., Wang, Y., Liu, X., Wang, Z., Ding, L., Zhang, M., and Zhang, M. AgentInit: Initializing LLM-based multiagent systems via diversity and expertise orchestration for effective and efficient collaboration. In Christodoulopoulos, C., Chakraborty, T., Rose, C., and Peng, V. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2025, pp. 1187011902, Suzhou, China, November 2025. Association for Computational Linguistics. ISBN 979-8-89176-335-7. doi: 10.18653/v1/2025.f indings-emnlp.636. URL https://aclanthology .org/2025.findings-emnlp.636/. Wang, J., Zhao, S., Liu, J., Wang, H., Li, W., Qin, B., and Liu, T. Orchestrating intelligence: Confidence-aware routing for efficient multi-agent collaboration across multi-scale models. arXiv preprint arXiv:2601.04861, 2026. URL https://arxiv.org/abs/2601.0 4861. Wang, S., Zhang, G., Yu, M., Wan, G., Meng, F., Guo, C., Wang, K., and Wang, Y. G-safeguard: topology-guided security lens and treatment on LLM-based multi-agent systems. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 72617276, Vienna, Austria, 2025a. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.359. URL https://aclanthology.org/2025.ac l-long.359/. Wang, Z., Wang, Y., Liu, X., Ding, L., Zhang, M., Liu, J., and Zhang, M. AgentDropout: Dynamic agent elimination for token-efficient and high-performance LLMbased multi-agent collaboration. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 24013 24035, Vienna, Austria, 2025b. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.1170. URL https://ac lanthology.org/2025.acl-long.1170/. Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., et al. Autogen: Enabling next-gen llm applications via multi-agent conversations. In First Conference on Language Modeling, 2024. URL https://openreview.net/forum?id=BAak Y1hNKS. Xiang, Z., Zheng, L., Li, Y., Hong, J., Li, Q., Xie, H., Zhang, J., Xiong, Z., Xie, C., Yang, C., et al. Guardagent: Safeguard llm agents by guard agent via knowledgeenabled reasoning. arXiv preprint arXiv:2406.09187, 2024. URL https://arxiv.org/abs/2406.0 9187. 11 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning URL https://openreview.net/forum?id= GazlTYxZss. Zhang, W., Cui, C., Zhao, Y., Liu, Y., and An, B. Agentorchestra: hierarchical multi-agent framework arXiv preprint for general-purpose task solving. arXiv:2506.12508, 2025g. URL https://arxiv. org/abs/2506.12508. Zhang, Y. and Math-AI, T. American invitational mathematics examination (aime) 2024, 2024. URL https://hu ggingface.co/datasets/math-ai/aime24. Zhang, Y. and Math-AI, T. American invitational mathematics examination (aime) 2025, 2025. URL https://hu ggingface.co/datasets/math-ai/aime25. Zhao, J., Zu, C., Hao, X., Lu, Y., He, W., Ding, Y., Gui, T., Zhang, Q., and Huang, X. LONGAGENT: Achieving question answering for 128k-token-long documents through multi-agent collaboration. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1631016324, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.912. URL https://aclanthology.org/2024.em nlp-main.912/. Zhao, W., Yuksekgonul, M., Wu, S., and Zou, J. Sirius: Self-improving multi-agent systems via bootstrapped In Workshop on Reasoning and Planning reasoning. for Large Language Models, 2025. URL https: //openreview.net/forum?id=sLBSJr3hH5. Zhou, J., Wang, L., and Yang, X. GUARDIAN: Safeguarding LLM multi-agent collaborations with temporal graph modeling. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. URL https: //openreview.net/forum?id=6j9xJ9pBjm. Zhuge, M., Wang, W., Kirsch, L., Faccio, F., Khizbullin, D., and Schmidhuber, J. Gptswarm: Language agents as optimizable graphs. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL https: //openreview.net/forum?id=uTC9AFXIhg. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. R., and Cao, Y. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/forum?id= WE_vluYUL-X. Zelikman, E., Wu, Y., Mu, J., and Goodman, N. D. Star: Bootstrapping reasoning with reasoning. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/pa per/2022/hash/639a9a172c044fbb64175b 5fad42e9a5-Abstract-Conference.html. Zhang, G., Chen, K., Wan, G., Chang, H., Cheng, H., Wang, K., Hu, S., and Bai, L. Evoflow: Evolving diverse agentic workflows on the fly. arXiv preprint arXiv:2502.07373, 2025a. URL https://arxiv.org/abs/2502.0 7373. Zhang, G., Wang, J., Chen, J., Zhou, W., Wang, K., and Yan, S. Agentracer: Who is inducing failure in the llm agentic systems? arXiv preprint arXiv:2509.03312, 2025b. URL https://arxiv.org/abs/2509.03312. Zhang, G., Yue, Y., Li, Z., Yun, S., Wan, G., Wang, K., Cheng, D., Yu, J. X., and Chen, T. Cut the crap: An economical communication pipeline for llm-based multiagent systems. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025c. URL https: //openreview.net/forum?id=LkzuPorQ5L. Zhang, G., Yue, Y., Sun, X., Wan, G., Yu, M., Fang, J., Wang, K., Chen, T., and Cheng, D. G-designer: Architecting multi-agent communication topologies via In ICLR 2025 Workshop on graph neural networks. Foundation Models in the Wild, 2025d. URL https: //openreview.net/forum?id=Jov79pGXc6. Zhang, R., Zhao, X., Wang, R., Chen, S., Zhang, G., Zhang, A., Wang, K., and Wen, Q. Safesieve: From heuristics to experience in progressive pruning for llm-based multiagent communication. arXiv preprint arXiv:2508.11733, 2025e. URL https://arxiv.org/abs/2508.1 1733. Zhang, S., Yin, M., Zhang, J., Liu, J., Han, Z., Zhang, J., Li, B., Wang, C., Wang, H., Chen, Y., and Wu, Q. Which agent causes task failures and when? on automated failure attribution of LLM multi-agent systems. In Forty-second International Conference on Machine Learning, 2025f. 12 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning A. Appendix A.1. Pseudo Codes Algorithm 1 outlines the pseudo-code for our rectify-or-reject pruning. During MAS execution, the output of each agent is actively intercepted to undergo the rectification process. First, an active indicator set is retrieved based on semantic similarity to serve as reference for potential error patterns (Lines 6-8). rectifier model then scrutinizes the output against each retrieved indicator, generating diagnostic rationales as feedback whenever specific constraint is violated (Lines 10-14). Subsequently, the algorithm employs tri-state gating mechanism based on the evaluation results, terminating the iteration if the output passes all checks or if the iteration budget is exhausted (Lines 15-24). Upon successful verification, the qualified output is propagated to successor agents (Lines 25-27). Finally, if the resulting information flow becomes critically sparse, global fallback process is triggered to reset the system and re-initialize execution from scratch (Lines 28-31). The pseudo-code for the Failure-Driven Indicator Pool Construction is outlined in Algorithm 2. The process begins by iterating through the source dataset to collect execution trajectories where the MAS fails to deliver the correct solution (Lines 3-4). Subsequently, teacher model scrutinizes these failure instances, synthesizing candidate indicators that capture the specific error patterns exhibited by individual agents (Lines 5-6). To prevent repository bloating, redundancy elimination mechanism is applied to each candidate. The algorithm first encodes the new indicator into semantic vector to retrieve the most similar existing constraints (Lines 7-9). deduplication model then verifies the novelty of the candidate, admitting it into the global pool only if it represents distinct and previously unrecorded error type (Lines 10-12). A.2. Indicator & Prompt Design Indicator Design Figure 5 displays an example from our constructed indicator pool. This specific indicator is tailored to verify the precision of square root calculations (a detailed application case is provided in Appendix A.4). For scenarios where pre-defined indicator pool is unavailable, we design general-purpose math and code indicators, as illustrated in Figure 6 and Figure 7, respectively. Prompt Design The prompt templates for the rectifier in the math and code domains are presented in Figure 8 and Figure 9. Additionally, Figure 10 depicts the prompt template for the teacher model, which is responsible for generating new indicators based on failed MAS execution trajectories. A.3. Dataset Statistics Table 5 lists the detailed statistics of the size of the datasets and the constructed indicator pool. The indicator pool for the math domain is constructed on the failed MAS trajectories on the sampled instances from the MATH and AQuA training sets. No indicator pool is built for the code domain. A.4. Case Study This case study exemplifies the frameworks capability to navigate complex constraint satisfaction problems through rectify-or-reject dialectical process. The agent was tasked with determining the number of real values for such that (cid:112)120 results in an integer (Figure 11). The resolution trajectory began with common cognitive deficit where the agent implicitly conflated the set of integers (Z) with positive integers (Z+), positing that the expression equaled for {1, . . . , 10} (Figure 12). This under-inclusion error was immediately intercepted by the rectifier via the INTEGER CONDITION MISMANAGEMENT indicator, which explicitly challenged the agents assumption by instructing it to re-evaluate the valid range to include zero (Figure 13). Responding to this guidance, the agent rectified the omission, but another error occurred. In an effort to strictly adhere to the instruction that integers include negatives, the agent expanded the domain to include negative values (e.g., {10, . . . , 10}), thereby neglecting the intrinsic non-negativity property of the principal square root function (Figure 14). This error represents classic instance of contextual detachment, where satisfying one constraint leads to the violation of another. The rectifier subsequently intervened with SQUARE ROOT MANIPULATION CHECK, providing critical boundary correction that the output of square root must remain non-negative (Figure 15). Ultimately, logical synthesis was achieved in the final iteration. By integrating the integer nature constraint from the first round of feedback with the non-negativity constraint from the second, the agent correctly defined the valid range as 13 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning the intersection of integers and non-negative values (n {0, 1, . . . , 10}) (Figure 16). The system converged on the correct count of 11 real values, achieving precise alignment with the ground truth, therefore the passing all indicator check by the rectifier and received no more feedback (Figure 17). This trajectory demonstrates the robustness of the rectify-or-reject mechanism in stabilizing reasoning through iterative, multi-dimensional constraint enforcement. 14 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Algorithm 1: Test-Time rectify-or-reject Pruning for MAS Information Flow Optimization Input Parameters :Max iterations Tmax, Top-K retrieval Kact, Safety threshold γ Output :Active agent set A, Indicator Pool I, Rectifier Model Φrect, Embedding Model Memb :Final answer // Phase 1: Agent Execution & Rectification 1 ; 2 foreach Agent Ai do 3 4 5 7 8 9 10 11 13 14 15 16 17 19 20 21 22 23 25 26 27 o(0) Φi(xi, Ri, Ki) ; 1; while Tmax do act ) ; act Φrect(o(t) ) ; scen (t) , I) ; // Step 1: Relevant Indicator Retrieval (t) scen, (t) q(t) Memb(S (t) act Top-Kact(q(t) (t) // Step 2: Verification E(t) 0, (t) ; foreach Indicator Ik (t) ) Φrect(o(t) xi, Ri, Ik); act do (v(t) if v(t) , r(t) = 1 then E(t) 1; (t) (t) {r(t) }; // Step 3: Tri-State Gating Decision if E(t) = 0 then oi o(t) {oi}; break ; ; else if < Tmax then o(t+1) Φi(xi, Ri, Ki, (t)) ; + 1; else oi ; break; // Propagate Output to Successors if oi = then foreach Agent Aj (Ai) do Kj {Ri, oi} // Phase 2: Global Fallback Check // Initialize valid output set // Initial Generation // Extract keywords // Compute query // Retrieve active indicator set // Pass:"
        },
        {
            "title": "Accept output",
            "content": "// Retry:"
        },
        {
            "title": "Regenerate",
            "content": "// Reject:"
        },
        {
            "title": "Discard output",
            "content": "28 Nvalid {o = }; 29 if Nvalid < γ then 30 Trigger System-Wide Reset; Discard and re-initialize with fresh agents; 31 32 return oN ; 15 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Algorithm 2: Failure-Driven Indicator Pool Construction Input :Source Dataset Dsrc = {Q, }, Teacher Model Φteach, Deduplication Model Φdedup, Embedding Model Memb Parameters :Retrieval size Kdedup Output :Optimized Indicator Pool // Initialize empty indicator pool 1 ; 2 foreach Instance (Q, ) Dsrc do // Step 1: Failure Trajectory Collection Execute MAS to obtain trajectory: = (Q, A1:N , o1:N , Y); if = then // Step 2: Offline Indicator Mining foreach Agent Ai in do Inew Φteach (T , , Ri, oi) ; // Step 3: Redundancy Elimination foreach Indicator Inew = (nnew, dnew, cnew) Inew do vnew Memb(dnew cnew) ; Isim Top-Kdedup(vnew, I) ; IsN ovel Φdedup (Inew, Isim); if IsN ovel is True then {Inew} ; 3 4 6 7 8 9 10 12 13 return I; // Generate candidate indicators // Compute semantic vector // Retrieve top-Kdedup similar set // Add novel error pattern AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning An Indicator Example Name: SQUARE ROOT MANIPULATION CHECK: Detailed Definition: This error occurs when mathematical expressions in radical form are manipulated in way that leads to logical contradictions relating to divisibility or integer properties. Trigger Condition: When the agent performs manipulations involving expressions in radical form and calculations involving divisibility and integer properties. Figure 5. An example of the indicators from the constructed pool for the math domain. General Indicator for Math Name: CRITICAL MATH LOGIC AUDIT Detailed Definition: focused audit to detect substantive logical fallacies, calculation errors, or conditional oversights that invalidate the final result. Trigger Condition: The Agent is performing mathematical reasoning, derivation, or calculation. Figure 6. The design of the general indicator for the math domain. General Indicator for Code Name: CRITICAL CODE CORRECTNESS CHECK Detailed Definition: functional audit focusing on runtime safety, logical integrity, and adherence to requirements in code implementation. Trigger Condition: The Agent is generating, debugging, or analyzing computer code. Figure 7. The design of the general indicator for code domain. 17 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Prompt for Math Rectifier You are an Objective Logic Auditor. Your task is to verify if specific team member (**Agent Role**) has committed **FATAL LOGIC ERROR** regarding specific **Area of Concern**. ### The Impact & Action Protocol 1. **Presumption of Validity**: You must assume the Agents reasoning is correct unless you find irrefutable evidence of fatal flaw. 2. **The Actionability Test**: If you cannot provide specific, mathematical correction (a formula, step, or value), **IT IS NOT FLAW**. 3. **The Impact Test**: If the Agents phrasing is imperfect but the **FINAL ANSWER** remains mathematically correct, **IT IS NOT FLAW**. ### Judgment Criteria **[Area of Concern]**: {trigger condition} ### CONTEXT - **Task**: {task} - **Agent Role**: {role} - **Agent Output**: {agent output} ### OUTPUT FORMAT (JSON ONLY) You must generate the fields in this **EXACT ORDER**. The logical flow determines the verdict. { evidence quote: Verbatim quote of the problematic part. Write N/A if valid., analysis: Explain WHY this specific part violates the Area of Concern. Focus on logic, not style. Try to express in concise and to the point manner, avoid lengthy speeches. Write N/A if valid., suggestion: Concrete instruction on how to fix it (e.g., Change to y, Apply formula Z). If no fix is needed or possible, write N/A., impact assessment: Simulate the correction. Does the FINAL ANSWER or core conclusion change? (YES/NO) and brief reason., is flawed: boolean // Set to true ONLY if suggestion is concrete AND impact assessment is YES. Otherwise false. } Figure 8. The prompt template for math rectifiers. 18 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Prompt for Code Rectifier You are Senior Code Auditor and Architect. Your task is to verify if specific team member (**Agent Role**) has committed **FATAL CODING ERROR** regarding specific **Area of Concern**. ### The Impact & Action Protocol 1. **Presumption of Validity**: You must assume the Agents code is functionally correct unless you find irrefutable evidence of fatal flaw (syntax error, logic bug, or interface violation). 2. **The Actionability Test**: If you cannot provide specific code correction (a line change, logic fix, or parameter adjustment), **IT IS NOT FLAW**. 3. **The Impact Test**: If the code is inefficient, verbose, or stylistically non-standard but **EXECUTES CORRECTLY** and returns the right result, **IT IS NOT FLAW**. ### Judgment Criteria **[Area of Concern]**: {trigger condition} ### CONTEXT - **Task**: {task} - **Agent Role**: {role} - **Agent Output**: {agent output} ### OUTPUT FORMAT (JSON ONLY) You must generate the fields in this **EXACT ORDER**. The logical flow determines the verdict. { evidence quote: Verbatim quote of the problematic code snippet. Write N/A if valid., analysis: Explain WHY this specific part violates the Area of Concern. Focus on functional correctness (bugs/crashes), not style (PEP8/comments).Try to express in concise and to the point manner, avoid lengthy speeches. Write N/A if valid., suggestion: Concrete instruction on how to fix the code (e.g., Change index to i+1, Import module X). If no fix is needed, write N/A., impact assessment: Simulate the correction. Does it fix runtime error, infinite loop, or incorrect output? (YES/NO) and brief reason., is flawed: boolean // Set to true ONLY if suggestion is concrete AND impact assessment is YES. Otherwise false. } Figure 9. The prompt template for code rectifiers. 19 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Prompt for Teacher You are an AI acting as **Lead Mathematics Auditor and Logic Specialist**, specifically optimized for the MATH dataset (high-difficulty competitions like AMC, AIME). ### Background & Goal **Background**: An agent team has attempted to solve complex math problem, and **the teams final answer is INCORRECT**. **Goal**: Synthesize the known problem (problem), standard solution (solution), and the Agents output to strictly evaluate the Agents reasoning process. **IMPORTANT CONTEXT**: The provided solution is standard, single-path reference answer. However, the Agent is part of Multi-Agent System (MAS). - Its output depends on its agent role (e.g., Python Coder writes code, Critic critiques). - **DO NOT** penalize the Agent simply because its output does not look like the standard solution (e.g., using code instead of pure derivation is valid if the role permits). - Only penalize **logical errors**, **calculation errors**, or **hallucinations** that contradict mathematical truths. ### MATH Input Context 1. **problem**: {problem} 2. **solution**: (Ground Truth) {solution} 3. **agent role**: {agent role} 4. **output**: (Agents Attempt) {output} ### Phase 1: Diagnosis Please execute the following logical judgment: 1. Assess whether the Agents output is logically and mathematically correct **within the scope of its role**. 2. **AUDIT STRATEGY (CRITICAL)**: - **DO NOT STOP at the first error.** You must scan the ENTIRE output line by line. - Independent errors often exist (e.g., logical fallacy in Step 1 AND formatting error in the Final Answer). - You are expected to find **MULTIPLE distinct errors** (less than 5) if they exist. 3. **Decision**: - If the output contains **NO errors**: Output NO ERROR. - If the output contains **errors**: Identify **ALL** of them and proceed to Phase 2. ### Phase 2: Metric Extraction Transform **EACH identified error** separately into **generalized** JSON metric object. **CRITICAL**: The name, detailed definition, trigger condition, and example error must be **generalizable** to other similar math problems. 1. **name**: * **Requirement**: Summarize the error pattern. It can be **appropriately longer** to avoid ID collisions. * **Format**: UPPER CASE WITH UNDERSCORES. 2. **domain tag**: * **Requirement**: Classify this error into specific mathematical or operational domain. * **Examples**: Geometry, Probability, Algebra, Number Theory, Python Implementation, Logical Reasoning. 3. **detailed definition**: * **Requirement**: Define the **ROOT CAUSE** or **Mental Misconception** behind the error. Do not just say used wrong formula; explain confused concept with concept B. * **Format**: This error occurs when the agent [misconception], leading to [consequence]. 4. **evaluator prompt**: Contains the trigger condition for retrieving this metric: * **trigger condition**: * **Requirement**: Describe the **Context** or **Action** where this error is likely to happen. **DO NOT** assume the error has already occurred (Decriminalized). * **Format**: When the problem involves [context]... OR When the agent attempts to [action]... 5. **example error**: * **Requirement**: Provide concrete example of the error AND the logic for why it is wrong/how to fix it. * **Format**: Error Snippet: [Quote agents wrong step] Correction Logic: [Explain why it is wrong and what the correct approach/formula should be]. ### Output Format - If no error: Output NO ERROR only. - If errors exist: **ALWAYS Output JSON LIST** containing one or more metric objects. - Structure: [ { name: ERROR 1, ... }, { name: ERROR 2, ... } ] - **CRITICAL JSON SYNTAX RULE**: - When writing LaTeX inside JSON strings, **YOU MUST DOUBLE-ESCAPE BACKSLASHES**. - **WRONG**: equation: frac{1}{2} (This causes JSON parse error!) - **CORRECT**: equation: frac{1}{2} (This works!) Figure 10. The prompt template for the teacher model during indicator pool construction. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Table 5. Dataset statistics Domain Dataset Test Set GSM8K MATH-500 AQuA ACM23 OlympiadBench OlymMATH Easy OlymMATH Hard AIME24 AIME24 MBPP HumanEval CodeContests LiveCodeBenchV1 Training Set MATH AQuA Indicator Pool Math Code Math Math Size 1,319 500 254 40 675 100 100 30 30 257 161 165 400 2,000 2,000 2,000 Math Task and Correct Answer Task: For how many real values of is Answer: 11 (cid:112)120 an integer? Figure 11. An example of the given math task. 21 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Math Solver: Initial Output o(0) We are given the expression: (cid:113) 120 and we are asked to find how many **real values of x** make this expression an **integer**. ### Step 1: Let the expression be an integer Let: (cid:113) 120 = n, where Z+ Squaring both sides: Solving for x: Now square both sides again to solve for x: 120 = = 120 n2 = (120 n2)2 ### Step 2: Determine the possible values of We must ensure that So: = 120 n2 0, because square roots of real numbers are non-negative. Approximating: 120 n2 0 n2 120 120 120 10. So the largest integer can be is 10. Since Z+, the possible values of are: That gives us **10 values** of n. ### Step 3: Verify that all these values produce real For each {1, 2, . . . , 10}, we compute: = 1, 2, 3, . . . , 10 = (120 n2)2 This will always be real number, since it is square of real number. ### Step 4: Conclusion Each integer from 1 to 10 gives unique real value of x, and all such values make the expression ### Final Answer: (cid:112)120 an integer. 10 Figure 12. The initial output of the math solver agent. 22 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Rectifier: Rectification Round 0/2 Evaluation [1] Matched Indicators: - MODULAR ARITHMETIC CONTEXT CHECK - MISSING CHECK FOR INTEGER SOLUTIONS - LACK OF COMPREHENSIVE OPTION ELIMINATION - INCORRECT EXPRESSION FOR DISTANCE - INTEGER CONDITION MISMANAGEMENT [2] Evaluations: - MODULAR ARITHMETIC CONTEXT CHECK: Flawed - The Agent assumes that must be positive integer, but the problem asks for real values of x. The expression being an integer does not require to be strictly positive; it could also be zero. This oversight restricts the possible values of and may lead to an incomplete solution. - MISSING CHECK FOR INTEGER SOLUTIONS: Correct - LACK OF COMPREHENSIVE OPTION ELIMINATION: Flawed - The Agent assumes must be positive integer, but the problem asks for real values of x. The square root function can yield non-integer values for as long as the expression remains real. The constraint that must be positive integer is not justified by the problem statement, which only requires the expression to be an integer, not necessarily that must be positive integer. - INCORRECT EXPRESSION FOR DISTANCE: Correct - INTEGER CONDITION MISMANAGEMENT: Flawed - The assumption that must be positive integer (n Z+) excludes the possibility of = 0, which is valid integer and could yield real value of x. The Area of Concern requires checking all integer solutions, including zero, to ensure all constraints are satisfied across calculations. (cid:112)120 (cid:112)120 [3] Feedback: An external auditor has reviewed your previous output (Attempt 1) and flagged some potential issues. Please review the following suggestions critically: - [MODULAR ARITHMETIC CONTEXT CHECK]: Allow to be zero as well, since can be zero and still be an integer. This would expand the range of to include 0. (Auditors Note: The Agent assumes that must be positive integer, but the problem asks for real values of x. The expression (cid:112)120 being an integer does not require to be strictly positive; it could also be zero. This oversight restricts the possible values of and may lead to an incomplete solution.) - [LACK OF COMPREHENSIVE OPTION ELIMINATION]: Allow to be any integer (positive, negative, or zero) such that 120 n2 0, and re-evaluate the valid range of n. (Auditors Note: The Agent assumes must be positive integer, but the problem asks for real values of x. The square root function can yield non-integer values for as long as the expression remains real. The constraint that must be positive integer is not justified by the problem statement, which only requires the expression to be an integer, not necessarily that must be positive integer.) - [INTEGER CONDITION MISMANAGEMENT]: Allow to be in (including 0) and re-evaluate the range of based on the constraint 120 n2 0. (Auditors Note: The assumption that must be positive integer ((n Z+)) excludes the possibility of = 0, which is valid integer and could yield real value of x. The Area of Concern requires checking all integer solutions, including zero, to ensure all constraints are satisfied across calculations.) **Instruction**: 1. If you agree with the advice, please refine your solution. 2. **If you are confident your original logic is correct, you may ignore this advice.** 3. Please output the corrected solution. Figure 13. The rectifiers judgments and feedback to the initial output. 23 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Math Solver: Rectification Round 1/2 Output o(1) being an integer You are absolutely correct to be critical of the original solution. The key point is that the expression does **not** require the integer to be strictly positive. In fact, it can be **zero**, which is also an integer. Therefore, we should allow Z, not just Z+. ### Revised Step-by-Step Solution: We are given: (cid:112)120 Squaring both sides: Solving for x: Now square both sides to find x: (cid:113) 120 = n, where 120 = n2 = 120 n2 = (120 n2)2 ### Step 1: Determine the valid values of We must ensure that So: = 120 n2 0, since square roots are non-negative. 120 n2 0 n2 120 120 Approximating: 120 10.95 So the integer values of that satisfy 10.95 are: This gives us total of: = 10, 9, 8, . . . , 1, 0, 1, . . . , 8, 9, 10 Number of values of = 2 10 + 1 = 21 ### Step 2: Verify that all these values produce real For each {10, 9, . . . , 10}, we compute: = (120 n2)2 This will always be real number, as it is square of real number. ### Step 3: Conclusion Each of the 21 integer values of from 10 to 10 (inclusive) gives unique real value of such that ### Final Answer: (cid:112)120 is an integer. Figure 14. The output of the math solver agent in Rectification Round 1. 24 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Rectifier: Rectification Round 1/2 Evaluation [1] Matched Indicators: - INVALID SOLUTION DISMISSAL BASED ON SIGN - INCORRECT FORM REPRESENTATION - INCORRECT LOGIC FOR NON-PRIME IDENTIFICATION - SQUARE ROOT MANIPULATION CHECK - USE OF CAUCHY SCHWARZ INEQUALITY [2] Evaluations: - INVALID SOLUTION DISMISSAL BASED ON SIGN: Flawed (cid:112)120 - The Agents reasoning is flawed because the square root function is defined to be non-negative. Therefore, the expression can only equal non-negative integers, not negative integers. Allowing introduces invalid negative values that do not satisfy the original equation. - INCORRECT FORM REPRESENTATION: Correct - INCORRECT LOGIC FOR NON-PRIME IDENTIFICATION: Correct - SQUARE ROOT MANIPULATION CHECK: Flawed - The agent correctly identifies that can be zero, which is an integer. However, the critical error lies in the assumption that = implies that must be non-negative because the square root (cid:112)120 negative integers for are valid. The expression function only yields non-negative results. Therefore, should be in Z+, not Z. - USE OF CAUCHY SCHWARZ INEQUALITY: Correct (cid:112)120 [3] Feedback: An external auditor has reviewed your previous output (Attempt 2) and flagged some potential issues. Please review the following suggestions critically: - [MODULAR ARITHMETIC CONTEXT CHECK]: Allow to be zero as well, since can be zero and still be an integer. This would expand the range of to include 0. (Auditors Note: The Agent assumes that must be positive integer, but the problem asks for real values of x. The expression (cid:112)120 being an integer does not require to be strictly positive; it could also be zero. This oversight restricts the possible values of and may lead to an incomplete solution.) - [INVALID SOLUTION DISMISSAL BASED ON SIGN]: Restrict to non-negative integers (n Z+) since the square root function only yields non-negative results. is defined to be non-negative. (Auditors Note: The Agents reasoning is flawed because the square root function Therefore, the expression can only equal non-negative integers, not negative integers. Allowing introduces invalid negative values that do not satisfy the original equation.) (cid:112)120 - [SQUARE ROOT MANIPULATION CHECK]: Restrict to non-negative integers (n Z+) since the square root function only yields non-negative results. (Auditors Note: The agent correctly identifies that can be zero, which is an integer. However, the critical error lies in the assumption that negative integers for are valid. The expression = implies that must be non-negative because the square root function only yields non-negative results. Therefore, should be in Z+, not Z.) (cid:112)120 **Instruction**: 1. If you agree with the advice, please refine your solution. 2. **If you are confident your original logic is correct, you may ignore this advice.** 3. Please output the corrected solution. Figure 15. The rectifiers judgments and feedback to the Round 1 output. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Math Solver: Rectification Round 2/2 Output o(2) is defined After carefully reviewing the auditors feedback, agree with the advice. The square root function to return **non-negative** real number. Therefore, the expression can only equal **non-negative integers**, i.e., Z+ (positive integers) or = 0. Negative integers are not valid for because the square root cannot be negative. ### Corrected Step-by-Step Solution: We are given: (cid:112)120 (cid:113) 120 = n, where Z+ {0} Squaring both sides: Solving for x: Now square both sides to find x: 120 = n2 = 120 n2 = (120 n2)2 ### Step 1: Determine the valid values of We must ensure that So: = 120 n2 0, since square roots are non-negative. 120 n2 0 n2 120 120 Approximating: So the non-negative integer values of that satisfy n2 120 are: 120 10.95 This gives us total of: = 0, 1, 2, . . . , 10 Number of values of = 11 ### Step 2: Verify that all these values produce real For each {0, 1, 2, . . . , 10}, we compute: = (120 n2)2 This will always be real number, as it is square of real number. ### Step 3: Conclusion Each of the 11 non-negative integer values of from 0 to 10 (inclusive) gives unique real value of such that an integer. ### Final Answer: (cid:112)120 is 11 Figure 16. The output of the math solver agent in Rectification Round 2. 26 AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Rectifier: Rectification Round 2/2 Evaluation [1] Matched Indicators: - ROOT FORM ASSUMPTION - INCORRECT EXPRESSION FOR DISTANCE - ARITHMETIC ERROR IN QUADRATIC SOLUTIONS - INCORRECT IDENTIFICATION OF NEXT SMALLEST SOLUTION - FINAL SOLUTION SELECTION CHECK [2] Evaluations: - ROOT FORM ASSUMPTION: Correct - INCORRECT EXPRESSION FOR DISTANCE: Correct - ARITHMETIC ERROR IN QUADRATIC SOLUTIONS: Correct - INCORRECT IDENTIFICATION OF NEXT SMALLEST SOLUTION: Correct - FINAL SOLUTION SELECTION CHECK: Correct [3] Feedback: [EMPTY] Figure 17. The rectifiers judgments and feedback to the Round 2 output."
        }
    ],
    "affiliations": [
        "Alibaba Group",
        "Harbin Institute of Technology, Shenzhen"
    ]
}