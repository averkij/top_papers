{
    "paper_title": "Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs",
    "authors": [
        "Richard Cornelius Suwandi",
        "Feng Yin",
        "Juntao Wang",
        "Renjie Li",
        "Tsung-Hui Chang",
        "Sergios Theodoridis"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of the Gaussian process (GP) kernel, which plays a central role in balancing exploration and exploitation under limited evaluation budgets. Traditional BO methods often rely on fixed or heuristic kernel selection strategies, which can result in slow convergence or suboptimal solutions when the chosen kernel is poorly suited to the underlying objective function. To address this limitation, we propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO with large language models (LLMs). Concretely, CAKE leverages LLMs as the crossover and mutation operators to adaptively generate and refine GP kernels based on the observed data throughout the optimization process. To maximize the power of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to select the most effective kernel through balancing the model fit measured by the Bayesian information criterion (BIC) with the expected improvement at each iteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO method consistently outperforms established baselines across a range of real-world tasks, including hyperparameter optimization, controller tuning, and photonic chip design. Our code is publicly available at https://github.com/cake4bo/cake."
        },
        {
            "title": "Start",
            "content": "Richard Cornelius Suwandi1 Yin Feng1 Juntao Wang1 Renjie Li2 Tsung-Hui Chang1 Sergios Theodoridis3 1The Chinese University of Hong Kong, Shenzhen 2University of Illinois at Urbana-Champaign 3University of Athens 5 2 0 2 2 2 ] . [ 1 8 9 9 7 1 . 9 0 5 2 : r {richardsuwandi, juntaowang}@link.cuhk.edu.cn {yinfeng, changtsunghui}@cuhk.edu.cn renjie2@illinois.edu, stheodor@di.uoa.gr"
        },
        {
            "title": "Abstract",
            "content": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of the Gaussian process (GP) kernel, which plays central role in balancing exploration and exploitation under limited evaluation budgets. Traditional BO methods often rely on fixed or heuristic kernel selection strategies, which can result in slow convergence or suboptimal solutions when the chosen kernel is poorly suited to the underlying objective function. To address this limitation, we propose freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO with large language models (LLMs). Concretely, CAKE leverages LLMs as the crossover and mutation operators to adaptively generate and refine GP kernels based on the observed data throughout the optimization process. To maximize the power of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to select the most effective kernel through balancing the model fit measured by the Bayesian information criterion (BIC) with the expected improvement at each iteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO method consistently outperforms established baselines across range of real-world tasks, including hyperparameter optimization, controller tuning, and photonic chip design. Our code is publicly available at https://github.com/cake4bo/cake."
        },
        {
            "title": "Introduction",
            "content": "Many important scientific and engineering problems require optimizing objective functions that are noisy and expensive to evaluate. These objective functions often lack closed-form expressions, let alone gradient information, making optimization particularly difficult [50]. Nonetheless, Bayesian optimization (BO) has shown remarkable success in optimizing such functions, due to its ability to operate on limited data and incorporate prior knowledge to guide the optimization process [17]. In the past couple of decades, BO has been used for diverse tasks ranging from tuning hyperparameters in machine learning [43, 29] to designing policies in robotics [9, 33] and recommending new molecules in drug discovery [25, 49]. The main idea behind BO is to first construct surrogate model, typically using Gaussian process (GP) [36], to represent the prior belief about the objective function. Then, by conditioning on the observations and the prior, the posterior is calculated using Bayes rule to reflect the updated belief about the objective function. Based on this posterior, an acquisition function is further used to determine the next promising query positions while balancing exploration (i.e., moving to regions with high uncertainty) and exploitation (i.e., moving to regions with high expected value). Corresponding author. 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Figure 1: Overview of CAKE. Starting with an initial population of kernels, the LLM acts as crossover and mutation operators, proposing new kernels based on the given prompts. The proposed kernels are then evaluated using fitness calculator, and the fittest ones advance to the next generation. Although the past decades have witnessed rapid development of BO, much of the focus has been drawn on designing novel acquisition functions [2, 1]. In contrast, the challenge of appropriately choosing the surrogate model has received comparatively less attention [40]. In the context of GPs, most off-the-shelf BO methods simply use general-purpose kernels, such as the squared exponential kernel or Matérn-5/2 kernel [43]. While convenient, this one-size-fits-all approach may introduce bias that can negatively impact the sampling of potential solutions during optimization [15], especially when the kernels assumptions do not align with the statistical properties of the underlying objective function [37]. It has also been studied that with poor choice of the kernel, BO may converge very slowly, especially when optimizing complex functions in moderate-to-high dimensional spaces [16]. These considerations underscore the need for more sophisticated kernel design in BO. While the pursuit for automatic kernel design is not new [12, 54], existing approaches might not be straightforward in the setting of BO. In BO, the objective function is typically expensive to evaluate, limiting the number of evaluations we can perform and leaving us with small number of observations to tune the kernel. Moreover, since the functional form is generally unknown and the gradient information is unavailable, it becomes infeasible to apply traditional optimization-based kernel selection methods, such as [4, 19]. At its core, these challenges can be framed within the few-shot learning setting, where swift learning and generalization from limited data are required. Notably, these challenges align with the strengths of large language models (LLMs) [52], which excel at generalizing from few-shot samples [8], thus enabling efficient exploration with limited data. The in-context learning capability of LLMs also acts as implicit Bayesian inference [56, 20], allowing them to encode prior knowledge about the optimization task, search space, and other relevant information. LLMs ability in performing complex reasoning further enhances their capacity to process contextual information and improve search performance [57]. Moreover, LLMs are also pretrained on massive internet data, which potentially contains transferable domain knowledge applicable to various optimization tasks [29]. Given these insights, we aim to investigate the following question: Can LLMs, with their encoded knowledge and few-shot prompting, help to adaptively evolve kernel structures based on the observed data, thereby improving the BO performance? Contributions. In this paper, we introduce Context-Aware Kernel Evolution (CAKE) to enable adaptive BO using LLMs. Unlike conventional BO setups, which often rely on fixed kernels or heuristic selection strategies, CAKE leverages the in-context learning capabilities of LLMs to iteratively generate and refine expressive kernel structures based on the acquired data during the 2 optimization process (see Figure 1). CAKE is guided by few-shot prompting and operates entirely in-context, without requiring fine-tuning or parameter updates to the LLM. To further complement CAKE, we propose BIC-Acquisition Kernel Ranking (BAKER) to select the most effective kernel through balancing the model fit measured by the Bayesian information criterion (BIC) with the expected improvement at each iteration of BO. We demonstrate through extensive experiments that our proposed method consistently outperforms established baselines across range of real-world optimization tasks, including optimizing the hyperparameters of machine learning models, tuning controllers for dynamic environments, and designing photonic chips with optimal configurations."
        },
        {
            "title": "2 Preliminaries",
            "content": "We first review some key concepts in BO and the so-called kernel grammar, which serve as the bedrock for this paper. R, Bayesian optimization. Consider optimizing black-box objective function : where the function evaluations are noisy, expensive, and the gradients are not available. Bayesian optimization (BO) addresses these challenges by employing probabilistic surrogate model g, typically using Gaussian processes (GP) [36], to approximate on the fly [17]. At each iteration t, the calibration of the posterior distribution p(gt = t1 t), an acquisition (xi, yi) i=1 informs where to explore and exploit in { defines policy to choose the next best point to evaluate. After each evaluation, function α : the surrogate model is refined to reflect the updated belief about . We refer the readers to Appendix A.1 for thorough treatment of BO with GPs. t) given the previous observations . Then, based on p(gt Rd } Kernel grammar. The kernel grammar introduced by Duvenaud et al. [12] defines comprehensive and flexible space of kernels. Such space exploits the closure properties of kernel functions under addition and multiplication, which ensures that: if k1(x, x) and k2(x, x) are valid kernels, then both k1(x, x) + k2(x, x) and k1(x, x) k2(x, x) are also valid kernels [42]. Starting from set of base kernels, such as the squared exponential (SE), linear (LIN), and periodic (PER) kernels, one can construct more expressive kernels by combining such base kernels via addition and multiplication operators. For instance, LIN + PER kernel can capture periodic structure with linear trend and SE denote subexpression. For example, in the expression LIN + (PER SE is subexpression. The entire kernel space is described by all kernels that can be constructed by + , multiplying subexpression with base kernel adding base kernel to subexpression PER kernel can capture locally periodic components. Let denote base kernel and SE), the term PER , and replacing base kernel with another base kernel . B"
        },
        {
            "title": "3 Context-Aware Kernel Evolution",
            "content": "The main motivation behind our method is to refine the kernel choice at each iteration before determining the next query point. To this end, we introduce Context-Aware Kernel Evolution (CAKE), which leverages LLMs as genetic operators to adaptively construct kernels based on the data obtained on the fly. We summarize the complete procedure of CAKE in Algorithm 1. } { = (xi, yi) Conditioning the LLM. We begin by randomly sampling points from the input space to initialize i=1. These observations are then used as few-shot samples to prompt the observations the LLM. The prompt is designed based on the concept of conditioning on high performance, as suggested by [60]. Specifically, we start the prompt with statement, You are an expert in machine learning, specializing in Gaussian processes, to simulate the reasoning of human expert in the field. It has also been shown that chain-of-thought reasoning, or generating intermediate reasoning steps, can improve the performance of LLMs [53, 24]. Motivated by this, we instruct the LLM to analyze the provided observations and identify patterns that can be represented by kernel functions, before proposing the kernels at each iteration. The designed system prompt is shown in Figure 2. Initializing the population. We draw some inspiration from the genetic algorithm [22], where we maintain population of candidates (kernels) throughout the optimization process. We define as K, we measure its fitness using the Bayesian Information our population, and for each kernel Criterion (BIC) [39]. The BIC is widely used metric for model selection that measures the trade-off between model fit and model complexity [46]. It can also be viewed as an approximation of the Laplace method for estimating the marginal likelihood [35]. We provide more detailed discussions"
        },
        {
            "title": "System Prompt",
            "content": "You are an expert in machine learning, specializing in Gaussian processes. Here are the observations we have collected so far: {observations}. Please analyze these observations to identify patterns in the data that can be captured by kernel function. You can use any of the following base kernels: {base_kernels}, and combine these kernels using the following operators: {operators}. Your goal is to construct kernel expression that best explains the observed data. The kernel will be evaluated using fitness score normalized between [0, 1], where higher values indicate better fit to the data. Figure 2: The designed system prompt. {} indicate placeholders."
        },
        {
            "title": "Mutation Prompt",
            "content": "You are given two parent kernels and their fitness scores: {kernel1} ({fitness1}), {kernel2} ({fitness2}). Please propose new kernel that has potentially higher fitness score. You may combine the parent kernels using any of the operators from: {operators}. Briefly explain your reasoning behind the proposed kernel. You are given kernel and its fitness score: {kernel} ({fitness}). Please propose new kernel that has potentially higher fitness score. You may replace base kernel in the current expression with another base kernel from the set: {base_kernels}. Briefly explain your reasoning behind the proposed kernel. (a) Crossover prompt. (b) Mutation prompt. Figure 3: Prompts for evolving the kernels via crossover and mutation. on BIC and model selection for GPs in Appendix A.2. To ensure the fitness score is consistent across different tasks, we normalize it to the range [0, 1]. { k1, . . . , kr Proposing the kernels. We consider generalized notion of the kernel grammar [7], which involves N. Each operator set of base kernels , for = 1, . . . , l, is closed operator (e.g., addition, multiplication, convolution, : . Based on this, we can define the composition, affine transformation) on the space of kernels kernel grammar space recursively as follows: K0 := {T Ki1, = 1, . . . , the LLM as genetic operators to propose kernels using the following operations: N. By leveraging this kernel grammar space, we can leverage , where r, } and set of operators k1, . . . , kr Ki1, for and Ki := j(k1, k2) 1, . . . , k1, k2 } {T } { } 1. Crossover: We perform nc crossover operations. For each crossover, we sample two parent kernels k1, k2 from with probability proportional to their fitness. We then prompt the LLM to propose new kernel kc by applying an operator on the parent kernels. 2. Mutation: With probability pm, we perform mutation operation. We select the fittest kernel kf from and prompt the LLM to suggest new kernel km, by replacing one of the base kernels in kf with another base kernel. The sample prompts for the crossover and mutation operations are shown in Figure 3. In the prompts, we also ask the LLM to report its reasoning behind the proposed kernels (see Appendix C.3 for sample response). This serves as sanity check, enabling us to verify and interpret the choices made by the LLM. The proposed kernels from the two operations are added to K, and their fitnesses are measured. Then, we select the top np fittest kernels to form the next generation of K. Choosing the next query point. In our experiments, we observed that some kernels may promise good fit, but the actual improvement from the query points they propose is not as substantial as expected. For this reason, we propose the BIC-Acquisition Kernel Ranking (BAKER) to jointly rank kernels based on both their model fit and their potential to yield high-utility query points. We first based on its BIC: wk = exp( assign weights to each kernel BICk), where BICk is the BIC value of the GP model associated with kernel k. We denote the acquisition BICk)/ (cid:80) kK exp( 4 } { = i= (xi, yi) (see Fig. 2) Update system prompt with for = 1 to nc do Sample two parent kernels k1, k2 from Generate new kernel kc via crossover (see Fig. 3a) Algorithm 1 Context-Aware Kernel Evolution (CAKE) Require: Budget , number of crossovers nc, mutation probability pm, population size np 1: Randomly sample points to form the initial observations 2: Initialize the kernel population with the set of base kernels 3: for = 1 to do 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: end for end if Evaluate the fitnesses and keep the top-np kernels in Choose the most effective kernel via BAKER (see Eq. 1) Obtain the next point xt = xt,k and evaluate yt = (xt) Update the observations as Select the fittest kernel in Generate new kernel km via mutation (see Fig. 3b) end for if rand() < pm then { (xt, yt) } function2 as α(x; , k), which quantifies the utility of evaluating candidate point under the model that kernel is being used, given the current observations . Based on this, BAKER computes weighted acquisition value for each kernel and selects the kernel that maximizes this value, i.e., k = arg max kK wkα(xt,k; , k), (1) where xt,k denotes the candidate query point proposed by kernel at iteration t. BAKER allows us to balance the kernels ability to fit the data (as indicated by wk) with the expected improvement at the proposed query point (as measured by α). Once is selected, we use the corresponding kernel to obtain the next query point xt = xt,k , evaluate yt = (xt), and update the observations as { (xt, yt) } . This iterative process continues until predefined budget is exhausted."
        },
        {
            "title": "4 Related Work",
            "content": "Expressive kernel design. Several methods have been developed to construct more expressive kernels beyond manual composition of base kernels. One such method involved multiple kernel learning techniques [4, 19], which aim to identify the optimal kernel configuration by optimizing linear or nonlinear combination of base kernels. However, these methods restrict the kernel space and require prior specification of the kernel hyperparameters. Another approach involved searching for the optimal kernel structure across space of kernels [12], but since the space is infinite, efficiently navigating this space demands modeling expertise. Other works focus on designing flexible kernel families via spectral approximations [26, 54], or integrating GPs with deep neural networks [55]. While powerful, these approaches either assume stationarity or require complex inference techniques. In contrast, our method is based on the kernel grammar and in-context learning via LLMs, which offers flexible yet computationally feasible approach. Surrogate modeling in BO. When using GPs as the surrogate model in BO, the kernel is typically selected priori based on an experts knowledge concerning the problem at hand. Unfortunately, if there is no prior knowledge available, most BO methods simply use default kernels such as the SE kernel or the Matérn-5/2 kernel [43]. While this seems reasonable, it has been reported that with poor or overly general choices of the kernel, BO may converge very slowly [16]. For this reason, deep GPs have been proposed to help model non-stationary behaviors [21], but at the cost of increased computational complexity. Other works explore adaptive kernel strategies, such as using discrete mixtures of GPs [18], maintaining parallel GPs with different kernels [37], or using ensembles of GP [31]. Recent works have also showed great potential in using LLMs for surrogate modeling in 2We use the expected improvement (EI) as our default acquisition function, normalized to [0, 1] to ensure comparability across different kernels. 5 BO [29, 11, 59]. We extend this line of research by using LLMs to automatically generate and refine kernels during the optimization process, enabling new-fashioned adaptive kernel design. LLMs as genetic operators. As the model size and amount of training data increase, LLMs exhibit emergent abilities that significantly improve their performance across diverse tasks [52, 8]. Inspired by these abilities, recent works have explored using LLMs as genetic operators for generating code [34], assisting robot simulations [27], and designing neural network architectures [10]. To the best of our knowledge, the current work is the first to use LLMs as genetic operators for constructing adaptive and expressive GP kernel design for BO. Compared to the other transformer-based methods [41], our method can be applied entirely in-context and does not require any fine-tuning."
        },
        {
            "title": "5 Experiments",
            "content": "To evaluate the performance of our proposed method, we test it against several baselines across set of real-world optimization tasks with varying characteristics, including diverse optimization landscapes, dynamic environments, and multi-objective settings. Setup. Our experiments were conducted using the software package BoTorch [6] and we used the expected improvement (EI) as our default acquisition function. For the LLM, we use OpenAIs gpt-4o-mini model as it offers an excellent balance between API cost affordability, fast inference speed, and intelligence for our implementation. We define as our base as our operators. Moreover, we set the number of crossovers nc = 5, mutation kernels and probability pm = 0.7, and population size np = 10. To facilitate reproducibility, our code is available online at https://github.com/cake4bo/cake. The shaded regions in all figures represent the standard error over independent trials. In the interest of space, more experimental details can be found in Appendix B, and additional results are provided in Appendix C. SE, PER, LIN, RQ, M3, M5 } +, { { } Baselines. We compare our proposed method against the following established baselines: Fixed: Default method in BO, where we fix the kernel throughout the optimization process. Adaptive: An adaptive kernel selection method proposed in [37]. We employ three different selection criteria to adaptively change the kernel: Random, Utility, and BIC. Deep GP: Uses deep GP (DGP) as the surrogate model, implemented through functional composition of stationary GPs [21]. Ensemble GP: Uses an ensemble of GPs (EGP) to adaptively select the surrogate model [31]. The kernel dictionary consists of the same six kernels used in CAKE. Compositional Kernel Search (CKS): Uses greedy search to discover kernel structures that best explains the observed data [12]. Automated BO (ABO): 5.1 Hyperparameter Optimization Setup. We consider the hyperparameter optimization tasks available in the HPOBench package [14]. We included total of 60 tasks, comprising 12 OpenML datasets and 5 machine learning (ML) models: logistic regression (LR), support vector machine (SVM), random forest (RF), XGBoost (XGB), and multi-layer perceptron (MLP). Each model-dataset pair exhibits unique optimization landscape, making these tasks an ideal testbed for evaluating the generalization performance of BO methods across diverse scenarios. Further details regarding the hyperparameter search spaces and dataset characteristics are provided in Appendix B.3.1. Here, our goal for each task is to maximize the accuracy of the ML model on the unseen test data. Each experiment was executed for = 100 trials and repeated using 20 different random seeds. Results. Figure 4 shows the average test accuracy for different ML models on all datasets. The results demonstrate that CAKE consistently achieves the highest accuracy compared to the other methods across all tasks. It is also worth noting that CAKE excels in the earlier stages of the optimization process, when fewer observations are available. This suggests that CAKE is able to effectively leverage fewer data samples to quickly converge to high-performing configurations. We provide quantitative analysis to support this finding in Appendix C.7. Our results also reveal significant variations in performance among fixed and adaptive kernel methods. For instance, M5 and Utility 6 Figure 4: Average test accuracy over 20 random seeds for different ML models. perform reasonably well in tuning SVM and RF models, but struggle with tuning LR and XGB. EGP and DGP exhibit moderate performance, often outperforming fixed kernels but falling short compared to more flexible approaches such as CKS and ABO. Overall, CAKE demonstrates superior performance consistently across all tasks. Another key advantage of CAKE is that the learned kernel expressions are also interpretable. In Appendix C.4, we analyze one such expression and show how CAKE automatically translates it into natural language description. 5.2 Controller Tuning Setup. We consider two real-world controller tuning tasks that simulate dynamic environments, where small changes in the environment condition may result in significantly different outcomes. For the first task, we consider the robot pushing problem [51], which involves tuning controller for two robotic hands to push two objects towards some specified target positions. The controller is parameterized by = 14 parameters that determine the position and orientation of the hands, the pushing speed, direction of movement, and duration of the push. The second task involves tuning controller for the lunar lander environment [48], which is defined by = 12 parameters that determine how to map the 8-dimensional state vector comprising of position, angle, velocity, and ground contact indicators, to one of four actions: firing the main engine, left or right orientation engines, or doing nothing. The goal is to achieve cumulative reward of at least 200 points, which corresponds to successful landing while minimizing penalties from crashes or excessive engine use. For both tasks, we evaluate the performance using = 1000 iterations, averaging the results over 10 different initial conditions (e.g., positions, terrains, velocities). We provide more details regarding the reward functions and environment implementations in Section B.3.2. Results. The results shown in Figure 5 demonstrate that the controllers optimized by CAKE achieved the highest average rewards in both tasks. In robot pushing task, CAKE converges to highperforming solution much faster than the other methods, highlighting its ability to quickly learn effective control policies from limited data. On the other hand, we found that fixed kernels like SE and M5 tend to plateau earlier, while adaptive methods such as Utility and BIC show only moderate improvements over the fixed kernels and still lag behind compositional approaches. Notably, ABO is 7 Figure 5: Average reward for the controller tuning tasks over 10 different initial conditions. the only method besides CAKE that is able to reach the target score of 200 points in the lunar landing task. Despite this, we observed that ABO exhibits greater performance fluctuations compared to CAKE, especially in more challenging environments. Meanwhile, the remaining methods struggle to maintain high scores and often incur greater penalties due to crashes or inefficient landings. Overall, these results show that CAKEs adaptive nature enables it to effectively respond to changes in the underlying objective (e.g., environmental shifts), offering greater robustness than fixed-kernel methods that may fail under such conditions. 5.3 Photonic Chip Design Setup. We apply our method to the design of photonic chips, which is challenging problem in physics and engineering [28]. Due to the high cost of fabrication, it is infeasible to try all, or even few, of the design parameters. As result, one has to rely on extensive computer simulations to assess the chips performance. This makes the task black-box inverse design problem, where the goal is to optimize the chip parameters to meet some desired performance indicators. We consider five key indicators for assessing the chips performance: Q-factor (f1), wavelength (f2), lasing area (f3), power (f4), and divergence angle (f5). Based on these performance indicators, we can calculate the overall score for given set of parameters: αf1 + βf2 + γf3 + δf4 + ϵf5, where we set α = β = 1, γ = δ = 100, and ϵ = 20 to unify the scale between different objectives. Our goal is to find Pareto-optimal solution that balances the trade-offs among the five competing objectives, thereby achieving the best overall chip performance. We provide detailed descriptions of each objective and their physical interpretations in Appendix B.3.3. Baselines. We consider two widely-used multi-objective BO methods: Single-Task GP, where each objective is modeled separately using GP with an M5 kernel, and Additive GP, which models the overall objective as sum of independent GPs, each using an SE kernel. We also include CKS and ABO as compositional kernel baselines to provide direct comparison against our proposed CAKE method. For all methods, we set = 250 with 10 different random initializations and employed the expected hypervolume improvement (EHVI) [58] as the acquisition function. Results. Figure 6 shows the score and hypervolume of the chip designed by CAKE and the competing baselines. Compared to the baselines, CAKE achieved the highest values in both metrics, indicating superior optimization performance and better exploration of the Pareto front. This likely stems from its ability to utilize different kernels tailored to individual objectives, unlike the other baselines that rely on single or additive kernel shared across all objectives. CAKE also outperforms CKS and ABO, demonstrating its advantage in handling multi-objective settings. Notably, CAKE found solution with significantly higher score in less than 40 trials, which is equivalent to tenfold speedup in the design cycle compared to the baselines. From practical point-of-view, this level of acceleration translates to significant reductions in both the time and cost needed to design the chips. 8 Figure 6: Average score and hypervolume of the designed chip over 250 trials. Table 1: Average rank ( LR Method ) standard error on HPOBench over 20 random seeds. SVM RF XGB MLP Average 6.8 Random Sampling 2.6 Genetic Algorithm 3.0 CAKE + BIC CAKE + Utility 2.3 Adaptive + BAKER 4.5 3.1 CKS + BAKER 1.1 CAKE + BAKER 0.1 0.1 0.1 0.1 0.1 0.1 0.1 6.9 2.5 3.1 2.2 4.4 3.2 1.0 0.1 0.1 0.1 0.1 0.1 0.1 0.1 6.7 2.7 2.9 2.4 4.6 3.0 1. 0.1 0.1 0.1 0.1 0.1 0.1 0.1 6.8 2.8 3.0 2.5 4.8 3.1 1.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 6.8 2.9 3.1 2.6 4.7 3.2 1. 0.1 0.1 0.1 0.1 0.1 0.1 0.1 6.80 2.70 3.02 2.40 4.60 3.12 1.04 5.4 Ablation Study Setup. To evaluate the influence of each component of our method, we conduct an ablation study with the following configurations: (1) Random Sampling: randomly combines base kernels using addition and multiplication, (2) Genetic Algorithm: applies genetic operators on population of kernels guided by fitness, (3) CAKE + BIC / CAKE + Utility: CAKE selects kernels based on the fitness or acquisition value only, (4) Adaptive + BAKER / CKS + BAKER: adaptive or compositional baselines with BAKER, and (5) CAKE + BAKER: full method with LLM and BAKER. We evaluate all ablation setups on the full set of 60 tasks in HPOBench. Results. Table 1 shows that CAKE + BAKER achieves the best overall performance, indicating that both the LLM and BAKER contribute to the effectiveness of our method. We found that removing either component leads to performance degradation. For instance, CAKE + BIC and CAKE + Utility, which only use one selection criterion, perform reasonably well but underperform compared to CAKE + BAKER. This suggests that while the fitness-based or utility-based kernel selection is individually effective, combining them with BAKER improves the performance across diverse tasks. As expected, random sampling performs the worst, suggesting that the LLM generates meaningful kernel expressions rather than just random combinations. We further support this by analyzing the evolution of the kernel populations fitness (see Section 5.5), where we observe distribution shift toward higher fitness values after each successive round of LLM edits. Although CKS + BAKER outperforms Adaptive + BAKER, it still underperforms compared to CAKE + BAKER. This indicates that while compositional kernels can capture more complex patterns than standard kernels, they still lack the contextual understanding provided by the LLM. 5.5 Evolution of Population Fitness To demonstrate the benefits of using LLM for kernel generation, we conduct an experiment analyzing how the fitness of the kernel population evolves through successive edits by the LLM3. Starting with 3In this context, an LLM edit refers to performing both crossover and mutation operations. 9 Figure 7: Evolution of the kernel populations fitness over successive edits by LLM, random recombination, and genetic algorithm (GA). an initial population of base kernels, we evaluate their fitness scores and then iteratively apply LLM edits to evolve the population over time. We further compare it with two baselines which replaces the edit step with random recombination and genetic algorithm (GA) operators. Figure 7 illustrates the progression of the fitness distributions after 1, 5, and 10 successive edits. The initial population exhibits wide distribution of fitness values with concentration on lower scores, reflecting the variability in the fitness scores among the base kernels. After just one LLM edit, the distribution immediately shifts toward higher fitness values, indicating that the LLM effectively enhances the population through both crossover and mutation. As more LLM edits are applied, the mean fitness continues to increase, and the variance narrows, indicating consistent improvement and convergence toward high-performing kernels. In contrast, Random and GA show slower convergence, with their fitness distributions remaining broader and less sharply peaked over the same number of edits. in driving population fitness upward. Overall, these results demonstrate that not only LLMs can serve as effective genetic operators, but also outperform those produced by random recombination and traditional GA operators."
        },
        {
            "title": "6 Conclusion",
            "content": "We introduced CAKE, novel kernel design method that leverages LLMs as crossover and mutation operators to enable adaptive surrogate modeling in BO. To complement CAKE, we further propose BAKER to address the issue where kernels with good model fit may not lead to substantial improvement towards the optimization progress. Experimental results have shown that CAKE achieved superior accuracy across all of the hyperparameter optimization tasks, particularly excelling in the early stages when the observations are scarce. In the dynamic controller tuning tasks, CAKE consistently obtained the highest average rewards and showed strong adaptability under varying environmental conditions. In the photonic chip design problem, CAKE demonstrated its ability to effectively balance multiple conflicting objectives while achieving significant speedup over baseline methods. While the current work focuses on BO, our broader goal is to develop universal adaptive kernel method that is applicable to various ML tasks. We refer the readers to Appendix for further discussions on the limitations and directions for future work."
        },
        {
            "title": "Acknowledgements",
            "content": "This work was supported in part by the NSFC under Grant 62271433, in part by Shenzhen Science and Technology Program under Grant RCJC20210609104448114, and in part by the Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen."
        },
        {
            "title": "References",
            "content": "[1] Aglietti, V., Ktena, I., Schrouff, J., Sgouritsa, E., Ruiz, F. J. R., Malek, A., Bellot, A., and Chiappa, S. FunBO: Discovering acquisition functions for Bayesian optimization with FunSearch. arXiv preprint arXiv:2406.04824, 2024. [2] Ament, S., Daulton, S., Eriksson, D., Balandat, M., and Bakshy, E. Unexpected improvements to expected improvement for Bayesian optimization. Advances in Neural Information Processing Systems, 36, 2023. [3] Arango, S. P., Jomaa, H. S., Wistuba, M., and Grabocka, J. HPO-B: large-scale reproducible benchmark for black-box HPO based on OpenML. In Neural Information Processing Systems Datasets and Benchmarks Track, 2021. [4] Bach, F. Exploring large feature spaces with hierarchical multiple kernel learning. arXiv preprint arXiv:0809.1493, 2008. [5] Bach, F. Learning theory from first principles. MIT Press, 2024. [6] Balandat, M., Karrer, B., Jiang, D., Daulton, S., Letham, B., Wilson, A. G., and Bakshy, E. BoTorch: framework for efficient Monte-Carlo Bayesian optimization. Advances in Neural Information Processing Systems, 33, 2020. [7] Bitzer, M., Meister, M., and Zimmer, C. Structural kernel search via Bayesian optimization and symbolical optimal transport. Advances in Neural Information Processing Systems, 35: 3904739058, 2022. [8] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 2020. [9] Calandra, R., Seyfarth, A., Peters, J., and Deisenroth, M. P. Bayesian optimization for learning gaits under uncertainty. Annals of Mathematics and Artificial Intelligence, 76(1):523, 2016. ISSN 1573-7470. [10] Chen, A., Dohan, D., and So, D. EvoPrompting: Language models for code-level neural architecture search. Advances in Neural Information Processing Systems, 36, 2024. [11] Chen, G., Zhu, K., Kim, S., Zhu, H., Lai, Y., Yu, B., and Pan, D. Z. LLM-enhanced Bayesian optimization for efficient analog layout constraint generation. arXiv preprint arXiv:2406.05250, 2024. [12] Duvenaud, D., Lloyd, J., Grosse, R., Tenenbaum, J., and Zoubin, G. Structure discovery in nonparametric regression through compositional kernel search. In International Conference on Machine Learning, pp. 11661174. PMLR, 2013. [13] Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., Leyton-Brown, K., et al. Towards an empirical foundation for assessing Bayesian optimization of hyperparameters. In NIPS Workshop on Bayesian Optimization in Theory and Practice, volume 10, pp. 15, 2013. [14] Eggensperger, K., Müller, P., Mallik, N., Feurer, M., Sass, R., Klein, A., Awad, N., Lindauer, M., and Hutter, F. HPOBench: collection of reproducible multi-fidelity benchmark problems for HPO. In Neural Information Processing Systems Datasets and Benchmarks Track, 2021. [15] Frazier, P. I. tutorial on Bayesian optimization. arXiv preprint arXiv:1807.02811, 2018. [16] Gardner, J., Guo, C., Weinberger, K., Garnett, R., and Grosse, R. Discovering and exploiting additive structure for Bayesian optimization. In Artificial Intelligence and Statistics, pp. 1311 1319. PMLR, 2017. [17] Garnett, R. Bayesian optimization. Cambridge University Press, 2023. [18] Ginsbourger, D., Helbert, C., and Carraro, L. Discrete mixtures of kernels for kriging-based optimization. Quality and Reliability Engineering International, 24(6):681691, 2008. [19] Gönen, M. and Alpaydin, E. Multiple kernel learning algorithms. Journal of Machine Learning Research, 12(64):22112268, 2011. [20] Han, C., Wang, Z., Zhao, H., and Ji, H. Explaining emergent in-context learning as kernel regression. arXiv preprint arXiv:2305.12766, 2023. [21] Hebbal, A., Brevault, L., Balesdent, M., Talbi, E.-G., and Melab, N. Bayesian optimization using deep Gaussian processes with applications to aerospace system design. Optimization and Engineering, 22:321361, 2021. [22] Holland, J. H. Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence. MIT press, 1992. [23] Jones, D. R., Schonlau, M., and Welch, W. J. Efficient global optimization of expensive black-box functions. Journal of Global Optimization, 13(4):455492, 1998. [24] Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners. Advances in Neural Information Processing Systems, 35, 2022. [25] Korovina, K., Xu, S., Kandasamy, K., Neiswanger, W., Poczos, B., Schneider, J., and Xing, E. P. ChemBO: Bayesian optimization of small organic molecules with synthesizable recommendations. arXiv preprint arXiv:1908.01425, 2019. [26] Lázaro-Gredilla, M., Quinonero-Candela, J., Rasmussen, C. E., and Figueiras-Vidal, A. R. Sparse spectrum Gaussian process regression. The Journal of Machine Learning Research, 11: 18651881, 2010. [27] Lehman, J., Gordon, J., Jain, S., Ndousse, K., Yeh, C., and Stanley, K. O. Evolution through large models. In Handbook of Evolutionary Machine Learning, pp. 331366. Springer, 2023. [28] Li, R., Zhang, C., Xie, W., Gong, Y., Ding, F., Dai, H., Chen, Z., Yin, F., and Zhang, Z. Deep reinforcement learning empowers automated inverse design and optimization of photonic crystals for nanoscale laser cavities. Nanophotonics, 12(2):319334, 2023. [29] Liu, T., Astorga, N., Seedat, N., and van der Schaar, M. Large language models to enhance Bayesian optimization. In International Conference on Learning Representations, 2024. [30] Lloyd, J. R., Duvenaud, D., Grosse, R., Tenenbaum, J. B., and Ghahramani, Z. Automatic construction and natural-language description of nonparametric regression models. arXiv preprint arXiv:1402.4304, 2014. [31] Lu, Q., Polyzos, K. D., Li, B., and Giannakis, G. B. Surrogate modeling for Bayesian optimization beyond single Gaussian process. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(9):1128311296, 2023. [32] Malkomes, G. and Garnett, R. Automating Bayesian optimization with Bayesian optimization. Advances in Neural Information Processing Systems, 31, 2018. [33] Martinez-Cantin, R. Bayesian optimization with adaptive kernels for robot control. In IEEE International Conference on Robotics and Automation, pp. 33503356, 2017. [34] Meyerson, E., Nelson, M. J., Bradley, H., Gaier, A., Moradi, A., Hoover, A. K., and Lehman, J. Language model crossover: Variation through few-shot prompting. arXiv preprint arXiv:2302.12170, 2024. [35] Murphy, K. P. Probabilistic machine learning: An introduction. MIT Press, 2022. 12 [36] Rasmussen, C. E. and Williams, C. K. I. Gaussian processes for machine learning. MIT Press, Cambridge, Mass, 2006. [37] Roman, I., Santana, R., Mendiburu, A., and Lozano, J. A. An experimental study in adaptive IEEE Access, 7:184294184302, 2019. doi: kernel selection for Bayesian optimization. 10.1109/ACCESS.2019.2960498. [38] Salimbeni, H. and Deisenroth, M. Doubly stochastic variational inference for deep Gaussian processes. Advances in Neural Information Processing Systems, 30, 2017. [39] Schwarz, G. Estimating the dimension of model. The Annals of Statistics, 6(2):461464, 1978. [40] Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., and de Freitas, N. Taking the human out of the loop: review of Bayesian optimization. IEEE, 104(1):148175, 2016. [41] Simpson, F., Davies, I., Lalchand, V., Vullo, A., Durrande, N., and Rasmussen, C. E. Kernel identification through transformers. Advances in Neural Information Processing Systems, 34: 1048310495, 2021. [42] Smola, A. J. and Schölkopf, B. Learning with kernels, volume 4. Citeseer, 1998. [43] Snoek, J., Larochelle, H., and Adams, R. P. Practical Bayesian optimization of machine learning algorithms. arXiv preprint arXiv:1206.2944, 2012. [44] Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. W. Information-theoretic regret bounds for Gaussian process optimization in the bandit setting. IEEE Transactions on Information Theory, 58(5):32503265, 2012. [45] Surjanovic, S. and Bingham, D. Virtual library of simulation experiments: Test functions and datasets. URL http://www.sfu.ca/ssurjano, 2013. [46] Theodoridis, S. Machine learning: From the classics to deep networks, transformers, and diffusion models. Elsevier, 2024. [47] Thompson, W. R. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3-4):285294, 1933. [48] Towers, M., Kwiatkowski, A., Terry, J., Balis, J. U., De Cola, G., Deleu, T., Goulao, M., Kallinteris, A., Krimmel, M., KG, A., et al. Gymnasium: standard interface for reinforcement learning environments. arXiv preprint arXiv:2407.17032, 2024. [49] Tripp, A. and Hernández-Lobato, J. M. Diagnosing and fixing common problems in Bayesian optimization for molecule design. arXiv preprint arXiv:2406.07709, 2024. [50] Wang, X., Jin, Y., Schmitt, S., and Olhofer, M. Recent advances in Bayesian optimization. ACM Computing Surveys, 55(13s), 2023. [51] Wang, Z., Gehring, C., Kohli, P., and Jegelka, S. Batched large-scale Bayesian optimization in high-dimensional spaces. In International Conference on Artificial Intelligence and Statistics, pp. 745754. PMLR, 2018. [52] Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022. [53] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:2482424837, 2022. [54] Wilson, A. G. and Adams, R. P. Gaussian process kernels for pattern discovery and extrapolation. In International Conference on Machine Learning, pp. 10671075, 2013. [55] Wilson, A. G., Hu, Z., Salakhutdinov, R., and Xing, E. P. Deep kernel learning. In International Conference on Artificial Intelligence and Statistics, volume 51, pp. 370378, 2016. 13 [56] Xie, S. M., Raghunathan, A., Liang, P., and Ma, T. An explanation of in-context learning as implicit Bayesian inference. arXiv preprint arXiv:2111.02080, 2022. [57] Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. Large language models as optimizers. In International Conference on Learning Representations, 2024. [58] Yang, K., Emmerich, M., Deutz, A., and Bäck, T. Multi-objective Bayesian global optimization using expected hypervolume improvement gradient. Swarm and Evolutionary Computation, 44: 945956, 2019. [59] Yang, Z., Ge, L., Han, D., Fu, T., and Li, Y. Reasoning BO: Enhancing Bayesian optimization with long-context reasoning power of LLMs. arXiv preprint arXiv:2505.12833, 2025. [60] Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., and Ba, J. Large language models are human-level prompt engineers. In International Conference on Learning Representations, 2023."
        },
        {
            "title": "A Mathematical Details",
            "content": "A.1 Bayesian Optimization with Gaussian Processes Gaussian process (GP) describes collection of random variables, any finite number of which have (m(x), kθ(x, x; θ)), joint Gaussian distribution [36]. Mathematically, GP can be expressed as, where m(x) is the mean function and kθ(x, x; θ) is the covariance (kernel) function parameterized by some hyperparameters θ. Given any finite collection of inputs = x1:t, the outputs are jointly Gaussian, GP where mX = m(X) practice, and K(X, X; θ) We assume that the evaluations of at any point xt are corrupted by σ-sub-Gaussian noise [5], (2) Rt is the mean function vector evaluated at X, often assumed to be 0 in Rtt is the covariance matrix with entries [K(X, X; θ)]i,j = kθ(xi, xj). (mX, K(X, X; θ)) , (X) where ϵt ϵ ). Given the observed data distribution of the observed data and an arbitrary query point is: X, t = { (0, σ2 yt = (xt) + ϵt, (3) , where = y1:t, the joint Gaussian } (cid:20) Kt;θ + σ2 ϵ t;θ(x) where Kt;θ = K(X, X; θ) and kt;θ(x) = kθ(X, x). It follows that, the posterior distribution of any query point is marginally Gaussian, kt;θ(x) kθ(x, x) (cid:20) (x) (cid:21)(cid:19) (4) 0, (cid:18) (cid:21) , where (x) t; θ (µt(x; θ), σ2 (x; θ)), µt(x; θ) = E[f (x) (x; θ) = E[f (x)f (x) σ t] = ϵ I)1y, t,θ(x)(Kt;θ + σ2 t,θ(x)(Kt;θ + σ2 t] = kθ(x, x) ϵ I)1kt,θ(x). (5) (6a) (6b) Based on the above posterior distribution, the acquisition function the use its statistics to trade-off exploitation (where µt(x; θ) is high) and exploration (where σ2 (x; θ) is high) effectively. Among the various acquisition functions proposed, expected improvement (EI) [23] remains the default choice in many BO applications [43]. Let us define µ+ θ = maxxX µt(x; θ) as the best mean value. The EI acquisition function can then be expressed in closed form as: t) = E[max { µ+ θ )/σt(x; θ), and ϕ( ) are the standard normal density and ] = σt(x; θ)[uΦ(u) + ϕ(u)], where = (µt(x; θ) cumulative distribution functions, respectively. µ+ θ } ) and Φ( 0, (x) α(x; (7) A.2 Model Selection We conduct model selection over discrete, infinite space of kernels . As each kernel } comes with its own hyperparameters, we are actually dealing with space of kernel families. Thus, when referring to kernel k, we consider the whole family over its hyperparameters Θ . } Given some model selection criteria : kθ R, our goal is to identify the optimal kernel, k1, k2, . . . = θ { { = arg max kK commonly-used criterion for probabilistic models, such as GPs, is the marginal log-likelihood [46], h(k (8) ). (cid:90) h(k ) = log p(y X, k) = log X, θ, k)p(θ)dθ. p(y (9) Unfortunately, the above likelihood is generally intractable for GPs [36], so we resort to the Laplace approximation [35], log p(y X, k) log p(y X, ˆθ, k) + log p(ˆθ) 1 2 log det Σ1 + dθ 2 log 2π (10) where ˆθ denotes the maximum posteriori (MAP) estimate of the hyperparameters with dθ being its dimension. The term Σ1 = θ=ˆθ represents the Hessian matrix evaluated at the MAP estimate. Note that Eq. (10) can be interpreted as rewarding model fit while penalizing model complexity. In this work, we use the Bayesian Information Criterion (BIC) [39], which was also previously employed in [12] and can be seen as an approximation of the Laplace method. 2 log p(θ , k) (a) Number of crossovers. (b) Mutation probability. (c) Population size. Figure 8: Average fitness ( standard errors. ) with respect to different CAKE setup. The error bars indicate the"
        },
        {
            "title": "B Experimental Details",
            "content": "In this section, we provide additional details on the implementation, baselines, and benchmarks employed in our experiments. B.1 Implementation As described in Algorithm 1, CAKE depends on three key parameters: the number of crossovers nc, the mutation probability pm, and the population size np. To evaluate the impact of these parameters, we conduct sensitivity analysis in Fig. 8, which shows the average fitness of the population over generations under different settings. Below, we provide some intuition for setting these parameters. Number of crossovers. The number of crossovers determines how many new candidate kernels are generated via crossover in each iteration. higher value of nc can accelerate the exploration of diverse kernel combinations but increases the number of API calls to the LLM, which may be costly. In our experiments, we found that setting nc = 5 offers good balance between exploration and efficiency. Mutation probability. Each mutation operation introduces local variations to existing kernels in the population, which may help to refine solutions and escape local optima. The mutation probability controls the likelihood of applying mutation operation during each iteration. higher pm promotes greater diversity and prevents premature convergence, especially when the top-performing kernels become similar. However, excessively high mutation rates risk disrupting promising kernel structures before they can be fully explored. Based on our experiments, we set pm = 0.7 to maintain balance between sufficient exploration and stable evolution. Population size. The population size dictates how many candidate kernels evolve simultaneously. larger np enhances diversity in the search space and supports more thorough exploration, but also increases computational cost due to repeated GP model fitting for each kernel. Conversely, smaller np may lead to premature convergence or insufficient sampling of the kernel space. Empirically, we found that setting np = 10 maintains diverse yet computationally manageable population. B.2 Baselines To test our proposed method, we consider three categories of baseline methods: fixed, adaptive, and compositional approaches. B.2.1 Fixed For the fixed kernel-based baselines, we consider the following widely-used kernels in BO, along with their respective hyperpriors: 16 1. Squared Exponential (SE): k(x, x) = σ2 exp (cid:18) (x x)2 2l (cid:19) , (11) where is the lengthscale parameter and σ is the amplitude parameter. The hyperpriors are: σ2 Gamma(2.0, 2.0), Gamma(2.0, 3.0). 2. Periodic (PER): k(x, x) = σ2 exp (cid:18) sin2 (π l2 (cid:19) /p) , (12a) (12b) (13) where is the lengthscale parameter, is the period length, and σ is the amplitude parameter. The hyperpriors are: 3. Linear (LIN): σ2 Gamma(2.0, 2.0), Gamma(2.0, 3.0), Gamma(2.0, 2.0). k(x, x) = σ2xx + σ2 , where σ2 is the variance parameter, σ2 is the noise variance. The hyperpriors are: σ2 σ2 Gamma(2.0, 3.0), Gamma(2.0, 3.0). 4. Rational Quadratic (RQ): k(x, x) = σ2 (cid:18) 1 + (x x)2 2αl2 (cid:19)α , (14a) (14b) (14c) (15) (16a) (16b) (17) where is the lengthscale parameter, α is the relative weighting parameter, and σ is the amplitude parameter. The hyperpriors are: 5. Matérn: where σ2 α Gamma(2.0, 2.0), Gamma(2.0, 3.0), Gamma(2.0, 2.0). k(x, x) = σ2 21ν Γ(ν) (cid:16) 2νD (cid:17)ν (cid:16) 2νD (cid:17) , Kν (x = x)2 l2 (18a) (18b) (18c) (19) (20) is the distance between and scaled by the lengthscale parameter, Kν is the modified Bessel function, and σ is the amplitude parameter. In our experiments, the smoothness parameter ν is set to 1/2, 3/2, or 5/2, corresponding to Matérn-1/2 (M1), Matérn-3/2 (M3), or Matérn-5/2 (M5) respectively. The hyperpriors are: σ2 Gamma(2.0, 2.0), Gamma(2.0, 3.0). (21a) (21b) Note that all the above kernels are defined on and are applied to input dimension when indicated by the base kernel symbol, e.g., SEi denotes SE kernel is applied to the i-th dimension. 17 Table 2: Details of the OpenML datasets used in the experiments. More information can be found at https://www.openml.org. Dataset"
        },
        {
            "title": "Task ID Number of Instances Number of Features",
            "content": "credit_g vehicle kc1 phoneme blood_transfusion australian car segment heart_h tic_tac_toe kr_vs_kp qsar 31 53 2109 9952 10101 146818 146821 146822 50 145804 3 9957 1000 846 2109 5404 748 690 1728 2310 294 958 3196 1055 21 19 22 6 5 15 7 20 14 10 37 42 B.2.2 Adaptive For the adaptive kernel-based baselines, we adopt the implementation from Roman et al. [37] and apply the following selection criteria: 1. Random: This criterion selects kernel randomly from the set of available kernels. 2. Utility: Based on the proposed query points from each kernel, this criterion selects the kernel with the highest utility (acquisition) value: = arg max kK α(xt,k; , k). 3. BIC: This criterion selects the kernel with the lowest BIC value: = arg min kK BIC(k; ). (22) (23) B.2.3 Compositional For the compositional kernel-based baselines, we consider the following methods: 1. Deep GP. For the deep GP baseline, we use the DeepGP implementation from GPyTorch, where training and inference are conducted using the doubly stochastic variational inference method [38]. 2. Ensemble GP. For the ensemble GP baseline, we follow the implementation suggested by Lu et al. [31], using the six base kernels used in CAKE to form the kernel dictionary. 3. Compositional Kernel Search (CKS). For the CKS baseline, we start from the same base kernels used in CAKE and apply greedy search to search for the kernel structures [12]. 4. Automated BO (ABO) For the ABO baseline, we use the code provided by the authors at https://github.com/gustavomalkomes/abo and follow the setup suggested in [32]. B.3 Benchmarks All experiments on the benchmarks were conducted locally on consumer-grade laptop4, except for the photonic chip design experiment in Section 5.3, which was executed on high-performance computing (HPC) cluster due to the computational demands of the physics-based simulation. B.3.1 Hyperparameter Optimization Datasets. We include 12 OpenML datasets available in the HPOBench package [14]. The details of the selected datasets are given in Table 2. 4MacBook Air M2 (2022) with an 8-core CPU, 8-core GPU, 8 GB unified memory, and 256 GB SSD storage. 18 Search space. We follow the search space designated in HPOBench, where we discretize the search space to facilitate efficient tabular lookup operations for various configurations [13]. Each hyperparameter is defined by its type (linear or log scale), along with lower and upper bounds. For example, [log, 0.001, 1.0] indicates that the hyperparameter values are sampled on logarithmic scale between 0.001 and 1.0. In contrast, [linear, 0.0, 1.0] implies uniform sampling over the interval [0.0, 1.0]. The search space for each ML model is summarized as follows: Logistic Regression (d = 2) alpha: Regularization strength, [log, 0.001, 1.0] eta0: Initial learning rate, [log, 0.001, 1.0] Support Vector Machine (SVM) (d = 2) C: Inverse of regularization strength, [log, 0.01, 10.0] gamma: RBF kernel coefficient, [log, 0.001, 1.0] Random Forest (d = 4) max_depth: Maximum depth of each tree, [log, 1, 50] max_features: Number of features to consider when looking for the best split, [linear, 0.0, 1.0] min_samples_leaf: Minimum number of samples required to be at leaf node, [linear, 1, 2] min_samples_split: Minimum number of samples required to split an internal node, [log, 2, 128] XGBoost (d = 4) colsample_bytree: Fraction of features to use per tree, [linear, 0.1, 1.0] eta: Learning rate that controls the contribution of each tree to the final prediction, [log, 0.001, 1.0] max_depth: Maximum depth of tree, [log, 1, 50] reg_lambda: L2 regularization term on weights, [log, 0.1, 10.0] Multi-Layer Perceptron (MLP) (d = 5) alpha: L2 penalty (regularization term) coefficient, [log, 0.001, 1.0] batch_size: Number of training examples used in one forward/backward pass, [log, 16, 128] depth: Number of hidden layers in the neural network, [linear, 1, 3] learning_rate_init: Initial learning rate for weight updates, [log, 0.001, 1.0] width: Number of neurons in each hidden layer, [log, 16, 128] B.3.2 Controller Tuning Robot pushing. The reward function is defined as: (x) = xf , where xsi represents the starting positions of the objects, xf denotes their final positions, and xgi indicates the goal. The objective is to minimize the total distance from the initial and final positions of the objects to their respective goals, thereby maximizing the reward. We use the original code provided by Wang et al. [51], which is available online at https://github.com/zi-w/ Ensemble-Bayesian-Optimization. i=1 xgi xgi xsi (cid:80) Lunar lander. The reward system includes +100 points for successful landing, -100 points for crash, +10 points per frame for each leg in contact with the ground, -0.3 points per frame for firing the main engine, and -0.03 points per frame for firing side engines. We implement the lunar lander environment using the code from https://github.com/Farama-Foundation/Gymnasium. B.3.3 Photonic Chip Design Objective. The design parameters and indicators for optimizing the photonic chip are detailed in Figure 9. We established target values based on our experiments and literature review to identify optimal standards for high-quality chip [28]. For instance, wavelength of 1310 nm is crucial for telecommunications and satellite applications, while high output power is essential for fields such as 19 Figure 9: Illustration of photonic chip and its design parameters. The inverse design problem focuses on optimizing these parameters to satisfy certain performance indicators. Table 3: Details of the test functions used in the experiments. Function Ackley-d Beale Branin Dropwave Eggholder Griewank-d Hartmann Levy Rastringin-d Rosenbrock Six-Hump Camel [ Domain 5, 5]d [ 1, 1]2 [ 5, 10]2 [ 5.12, 5.12]2 512, 512]2 600, 600]d [0, 1]3 10, 10]d 5.12, 5.12]d 5, 10]2 [ [ 3, 3] [ [ [ [ [ 2, 2] 2, 5 2 2 2 2 2, 5 3 2, 3 2, 4 2 2 autonomous driving and medicine. Additionally, small divergence angle is vital for ensuring high beam quality and effective long-distance light propagation. Based on these performance indicators, we can define the objectives as follows, f1 = 1 f2 = 1 f3 = f4 = 1 f5 = 1 + Q λ ω λ ω , λ , , , ω . (24a) (24b) (24c) (24d) (24e) Q-factor (f1) is related to the loss and threshold of the laser, wavelength (f2) is the operation wavelength of the laser, lasing area (f3) is the area of the laser beam at the lasers top surface, power (f4) is the lasing power of the laser in watts, and divergence angle (f5) is the angle between outer boundary and centerline of the laser beam. B.4 Prompt Design Our prompts are designed based on three core components: Problem Context: The optimization history, including the observed input-output pairs and corresponding fitness scores, provided as in-context examples to guide kernel evolution. 20 Figure 10: Visualization of the optimization landscapes of two-dimensional test functions. Figure 11: Ablation of prompt components on HPOBench averaged over 20 different random seeds. Task Instruction: The role assignment and explicit guidelines on how to generate valid kernels using the kernel grammar during crossover and mutation operations. Reasoning: phrase asking the LLM to provide brief natural language explanation for each proposed kernel. To evaluate the contribution of each component, we conduct an ablation study with the following configurations: Full: This is the vanilla CAKE setup employed in our experiments, incorporating all three components. No Context: This variant evaluates the importance of problem context by removing the optimization history (i.e., the observations and fitness values), while keeping the other components. 21 ) over 20 random seeds for different test functions and methods. Table 4: Average normalized regret ( The values in parentheses indicate the standard errors. The best value is highlighted in bold and the second best value is underlined. Function Ackley-2 Ackley-5 Beale Branin Dropwave Eggholder Griewank-2 Griewank-5 Hartmann Levy-2 Levy-3 Rastringin-2 Rastringin-4 Rosenbrock Six-Hump Camel Mean regret Median regret Fixed Adaptive Compositional SE Random Utility BIC DGP EGP CKS ABO CAKE 0.1773 (0.0232) 0.3185 (0.0117) 0.3554 (0.0845) 0.0183 (0.0080) 0.5110 (0.0568) 0.4941 (0.0602) 0.1196 (0.0692) 0.0204 (0.0032) 0.0007 (0.0001) 0.1562 (0.0684) 0.1141 (0.0209) 0.4325 (0.0571) 0.5765 (0.0482) 0.1025 (0.0476) 0.2840 (0.0856) 0.2454 0.1773 0.1220 (0.0262) 0.2369 (0.0184) 0.3522 (0.1006) 0.0155 (0.0037) 0.5411 (0.0523) 0.3545 (0.0452) 0.1282 (0.0687) 0.0223 (0.0059) 0.0019 (0.0011) 0.0418 (0.0227) 0.1422 (0.0403) 0.4251 (0.0765) 0.5461 (0.0671) 0.0898 (0.0510) 0.1507 (0.0459) 0.2111 0. 0.1358 (0.0210) 0.1722 (0.0145) 0.3855 (0.0775) 0.0227 (0.0106) 0.5460 (0.0698) 0.4015 (0.0416) 0.1295 (0.0686) 0.0232 (0.0051) 0.0021 (0.0009) 0.0835 (0.0460) 0.1495 (0.0290) 0.5310 (0.0613) 0.4815 (0.0400) 0.1015 (0.0573) 0.3455 (0.1014) 0.2341 0.1495 0.1062 (0.0165) 0.2278 (0.0171) 0.4410 (0.0989) 0.0372 (0.0107) 0.5265 (0.0622) 0.4855 (0.0527) 0.1310 (0.0685) 0.0178 (0.0033) 0.0358 (0.0159) 0.0555 (0.0060) 0.0880 (0.0159) 0.3455 (0.0442) 0.5905 (0.0509) 0.1405 (0.0695) 0.3310 (0.0760) 0.2373 0.1405 0.1863 (0.0187) 0.3590 (0.0338) 0.3571 (0.0806) 0.0371 (0.0152) 0.5461 (0.0750) 0.5485 (0.0749) 0.1272 (0.0686) 0.0281 (0.0096) 0.6800 (0.0734) 0.1145 (0.0666) 0.1125 (0.0230) 0.4490 (0.0632) 0.5200 (0.0529) 0.1475 (0.0688) 0.3265 (0.0786) 0.3026 0. 0.2510 (0.0357) 0.3110 (0.0215) 0.4775 (0.0958) 0.4810 (0.1017) 0.5560 (0.0531) 0.4535 (0.0615) 0.1156 (0.0297) 0.0815 (0.0171) 0.1305 (0.0441) 0.1965 (0.0326) 0.2265 (0.0511) 0.5405 (0.0751) 0.5340 (0.0475) 0.5340 (0.1101) 0.4940 (0.0854) 0.3589 0.4535 0.1878 (0.0196) 0.2285 (0.0139) 0.3088 (0.0898) 0.2045 (0.0725) 0.6290 (0.0651) 0.4345 (0.0497) 0.0935 (0.0248) 0.0478 (0.0110) 0.1780 (0.0402) 0.0765 (0.0198) 0.0805 (0.0173) 0.3869 (0.0338) 0.3270 (0.0329) 0.6040 (0.0971) 0.5345 (0.0528) 0.2881 0.2285 0.1012 (0.0177) 0.1812 (0.0856) 0.4040 (0.0712) 0.0301 (0.0122) 0.5788 (0.0669) 0.4536 (0.0533) 0.0589 (0.0686) 0.0258 (0.0076) 0.0001 (0.0611) 0.0668 (0.0431) 0.0580 (0.0194) 0.3722 (0.0588) 0.3285 (0.0511) 0.0907 (0.0686) 0.1071 (0.0771) 0.1905 0. 0.1020 (0.0195) 0.1910 (0.0188) 0.3118 (0.0733) 0.0101 (0.0478) 0.5529 (0.0611) 0.4210 (0.0516) 0.0357 (0.0244) 0.0320 (0.0125) 0.0001 (0.0544) 0.0519 (0.0187) 0.0590 (0.0181) 0.3420 (0.0397) 0.3179 (0.0375) 0.0901 (0.0907) 0.1002 (0.0563) 0.1745 0.1002 0.0783 (0.0203) 0.1732 (0.0250) 0.2565 (0.0786) 0.0070 (0.0534) 0.4690 (0.0538) 0.1241 (0.0541) 0.0267 (0.0256) 0.0185 (0.0133) 0.0001 (0.0529) 0.0353 (0.0197) 0.0505 (0.0190) 0.3341 (0.0468) 0.3128 (0.0499) 0.0483 (0.0531) 0.1015 (0.0669) 0.1357 0.0783 No Instruct: This variant excludes task instructions and omits the explicit kernel generation guidelines (i.e., how to perform the crossover and mutation operators), while keeping the other components. No Reasoning: Thus variant removes the requirement for the LLM to explain its reasoning, producing only the kernel expression. We evaluate all variants on the HPOBench benchmark, as detailed in Section 5.1. The results, summarized in Figure 11, demonstrate that the full CAKE setup consistently outperforms all ablated variants, underscoring the importance of each prompt component in achieving superior optimization performance. The No Reasoning experience slight degradation in performance, which suggests that the reasoning prompt not only serves to enhance interpretability, but also as form of self-reflection that helps the LLM evaluate and refine its own proposals. In contrast, the No Context variant performs significantly worse, demonstrating that access to optimization history (i.e., observed data points and kernel fitness values) is crucial and that the LLM effectively leverages this information. The No Instruct variant performed the worst compared to the other variants. To understand this drop, we examined the percentage of valid kernels, defined as the proportion of kernels that satisfy the kernel properties. We found that the No Instruct variant generated valid kernels only 68% of the time, while the other variants consistently produced valid kernels. This is due to the absence of the generation guidelines from the kernel grammar, which underscores its importance in the kernel generation process. Overall, these results strongly support the design choice of our prompts."
        },
        {
            "title": "C Additional Results",
            "content": "In this section, we provide additional results and empirical analysis on our proposed method. 22 Table 5: Average computational time ("
        },
        {
            "title": "Method",
            "content": "Time (s) ) in seconds per iteration for different methods."
        },
        {
            "title": "Fixed\nAdaptive\nEGP\nDeep GP\nCKS\nABO\nCAKE",
            "content": "0.6 3.7 3.9 4.8 5.6 7.4 8.3 Single GP fitting Multiple GP fitting & kernel selection Multiple GP fitting & weight update Variational inference Multiple GP fitting & greedy search Multiple GP fitting & nested BO loop Multiple GP fitting & LLM inference C.1 Benchmark Function Optimization Setup. We consider optimizing set of test functions commonly used as benchmark for optimization [45]. We provide additional details on the selected test functions5, including the input domain and dimensionality, in Table 3. We visualize the optimization landscapes of the two-dimensional test functions in Figure 10. From the figure, one can see the challenging nature of these functions, characterized by non-convexity, many local minima, and steep ridges. The goal is to find the global minimum of each test function, where the maximum number of function evaluations is limited to 10 times the dimensionality of the function input, i.e., = 10 d. To evaluate the performance of each method, we consider the normalized regret [3]: (xopt) (xopt) (xbest) (xinit) , where (xinit) is the best function value among the initial points, (xbest) is the best value found by the method, and (xopt)is the ground truth optimum. This metric is favorable as it provides normalized and task-agnostic measure to compare the optimization performance across different tasks. (25) Results. Table 4 shows the normalized regret averaged over 20 seeds for different functions and methods. Our results demonstrate that CAKE outperforms the baselines, achieving roughly 22.2% improvement in the mean regret and 21.9% improvement in the median regret compared to the second-best method. Notably, CAKE ranks among the top two for all functions and achieves the best performance 12 times out of 15. Our results also reveal that fixed kernels such as SE and M5, which are the default in BO, are not universally effective and actually perform poorly in many test functions. We also found that adaptive methods exhibit inconsistent performance and generally underperform compared to the compositional approaches like ABO. C.2 Computational Time Table 5 shows the average clock time per iteration for different BO methods. Note that we only measure the time spent on surrogate model computation, not including the black-box function evaluations. In CAKE, we use OpenAIs gpt-4o-mini as the LLM. Based on our measurements, it processes about 104.5 tokens per second. Each LLM call, including both the input prompt and output response, uses around 180 tokens. This results in an inference time of approximately 180/104.5 = 1.72 seconds per call. Each iteration of CAKE also involves fitting GP models for all kernels in the current population. Our experiments show that fitting one GP takes about 0.5 seconds. Therefore, fitting multiple GPs per iteration adds about 35 seconds to the total runtime. Other adaptive and compositional kernel methods that maintain multiple GP models also experience similar computational costs. However, methods like CKS and ABO involve additional steps, such as greedy search or nested BO loops, for constructing the kernels, which further increases their runtime. DGP requires performing doubly stochastic variational inference across deep layers, which adds even more computational overhead. In contrast, fixed and simple adaptive kernel methods, which either use single GP or choose from small set of kernels, are much faster per iteration. While CAKE has higher average runtime per iteration than the baselines, this increase is largely due to external 5The analytic expression as well as the global optimum of these functions can be found at https://www. sfu.ca/ssurjano/optimization.html."
        },
        {
            "title": "Crossover Response",
            "content": "Prompt: You are given two parent kernels and their fitness scores: LIN (0.53), SE (0.67). Please propose new kernel that has potentially higher fitness score. You may combine the parent kernels using any of the operators from {+, }. Briefly explain your reasoning behind the proposed kernel. Response: Kernel: LIN + SE Analysis: The LIN kernel captures linear trends in the data, which may be present given the varying function values across different inputs. The SE kernel, on the other hand, is effective in modeling smooth variations in the data, which could account for the fluctuations observed in the function values despite the overall linear trend. By combining these two kernels with the addition operator (+), we can leverage the linear trend from the LIN kernel while also allowing for smooth deviations from this trend through the SE kernel. Figure 12: Sample response for the crossover step. Mutation Response Prompt: You are given kernel and its fitness score: LIN + SE (0.72). Please propose new kernel that has potentially higher fitness score. You may replace base kernel in the current expression with another base kernel from the set {SE, PER, LIN, RQ, M3, M5}. Briefly explain your reasoning behind the proposed kernel. Response: Kernel: LIN + RQ Analysis: The LIN + SE kernel captures linear trend with smooth variations. However, the SE kernel assumes constant level of smoothness, which may not be appropriate for all data patterns. By replacing the SE kernel with the RQ kernel, we can introduce varying smoothness, allowing the model to adapt to different levels of noise in the data. Figure 13: Sample response for the mutation step. factors such as internet connectivity and API latency. Importantly, in most BO tasks, evaluating the black-box function is far more time-consuming than the BO process itself. Thus, reducing the number of function evaluations (i.e., improving sample efficiency) is often more important than minimizing the wall-clock time per iteration. C.3 Case Study We conducted case study to examine the LLMs outputs and assess whether it provides useful responses. Specifically, we analyzed sample responses from the LLM during the crossover and mutation steps, which are shown in Figure 12 and Figure 13, respectively. In Figure 12, the LLM is given two parent kernels, LIN and SE, along with their fitness scores. It suggests combining them using the addition operator (+) to improve the fitness. The explanation states that the LIN kernel captures linear trends, while the SE kernel models smoothness. Thus, combining them as LIN + SE allows the new kernel to represent both linear and smooth patterns in the data. In Figure 13, the LLM is given the kernel LIN + SE and its fitness score. It proposes replacing the SE kernel with the RQ kernel to further improve fitness. The reasoning is that while the SE kernel assumes constant smoothness, the RQ kernel allows for varying levels of smoothness. This makes the model more flexible, especially when dealing with data that has changing noise patterns. These examples show that the LLM posesses solid understanding about the kernel properties and how they affect modeling (i.e., how different kernels can be combined or modified to better fit specific data characteristics), enabling it to make meaningful proposals during the kernel generation process. 24 C. Interpretability of CAKE By design, the kernel grammar used in CAKE enables us to automatically generate interpretable descriptions of the data based on the proposed hypothesis (kernel expression). In this section, we analyze the kernel expression discovered by CAKE for one of the hyperparameter optimization tasks from HPOBench, which involves tuning an SVM model on the credit_g dataset. Recall that, for the SVM model, we have two hyperparameters to tune: the regularization parameter and the RBF kernel coefficient gamma. The kernel expression proposed by CAKE for this specific task is, (SE PER) + (LIN RQ) + (M5 SE). (26) Existing kernel grammar-based methods, such as Automatic Bayesian Covariance Discovery (ABCD) [30], typically interpret such expressions by first simplifying them into canonical sum-of-products form to enable modular interpretation. The natural language descriptions are then generated by applying predefined template rules that map each kernel component and its parameters to descriptive phrases. In contrast, in our CAKE framework, the LLM itself acts as the interpreter of the kernel structures, producing natural language descriptions directly and automatically for free without the need for explicit simplification or handcrafted template rules (see Fig. 14. This level of interpretability highlights key advantage of our CAKE framework. The LLMs contextual understanding and access to broad domain knowledge enable it not only to evolve expressive kernels, but also to explain them through meaningful natural language descriptions. Unlike traditional methods that treat kernel learning as purely numerical optimization task, CAKE generates interpretable hypotheses that reveal insights into the structure of the underlying black-box objective function. CAKEs Interpretation Response: Kernel: (SE PER) + (LIN RQ) + (SE M5) Analysis: The observations can be described using combination of three distinct patterns. rThe first term, SE PER, captures recurring fluctuations in the performance across the (C, gamma) space. High gamma values lead to overfitting, but increasing mitigates this effect, resulting in overfitting-recovery cycle. The second term, LIN RQ, models general increase in performance as increases, as stronger regularization improves generalization. However, the RQ component allows the model to adapt to varying levels of smoothness which is useful near extreme gamma values. The third term, M5 SE, combines the M5s robustness to non-smooth changes with SEs smoothness to capture complex, localized variations in performance that are not easily explained by global trends or periodicity alone, such as sharp drops in accuracy when both and gamma are too large. Figure 14: Intepretation for the SVM hyperparameter optimization task on the credit_g dataset. C.5 Choice of LLM In this section, we analyze the impact of the LLM choice on the performance of our method. We evaluated three open-source modelsQwens qwen-2.5-7b, DeepSeeks deepseek-r1-distill-qwen-7b, and Metas llama-3.1-8balongside three closed-source models: Googles gemini-2.0-flash, Anthropics claude-3.5-haiku, and OpenAIs gpt-4o-mini, on the HPOBench functions described in Section 5.1. The results in Table 6 show that, despite some variations in performance across different HPOBench functions, there is clear trend: our method performs better when using more recent and capable LLMs. We also observe performance boost with deepseek-r1-distill-qwen-7b, suggesting that reasoning-based models can further improve results. However, this gain comes at the cost of longer inference time, trade-off we plan to explore in future work. Overall, these results indicate that as LLMs become more advanced, our method naturally benefits from their improved capabilities. C.6 Choice of Acquisition Function We test the robustness of CAKE under different choice of acquisition functions, including EI [23], upper confidence bound (UCB) [44], and Thompson sampling (TS) [47]. While each acquisition function embodies different exploration-exploitation trade-off (i.e., TS exhibits slightly higher standard errors due to its stochastic nature while CAKE-UCB occasionally underperforms or outperforms ) on HPOBench over 20 random seeds for different LLMs. The values Table 6: Average accuracy ( in parentheses indicate the standard errors. LR"
        },
        {
            "title": "LLM",
            "content": ""
        },
        {
            "title": "SVM",
            "content": "RF"
        },
        {
            "title": "MLP",
            "content": "qwen-2.5-7b deepseek-r1-distill-qwen-7b llama-3.1-8b claude-3.5-haiku gemini-2.0-flash gpt-4o-mini 0.7720 (0.0310) 0.8122 (0.0210) 0.7815 (0.0290) 0.8177 (0.0231) 0.8253 (0.0204) 0.8188 (0.0220) 0.8520 (0.0180) 0.8630 (0.0141) 0.8581 (0.0177) 0.8655 (0.0130) 0.8720 (0.0121) 0.8663 (0.0130) 0.8810 (0.0260) 0.8964 (0.0234) 0.8873 (0.0252) 0.8982 (0.0242) 0.9056 (0.0223) 0.8991 (0.0250) 0.9030 (0.0380) 0.9211 (0.0320) 0.9110 (0.0355) 0.9240 (0.0331) 0.9310 (0.0303) 0.9257 (0.0340) 0.8610 (0.0330) 0.8692 (0.0292) 0.8652 (0.0312) 0.8712 (0.0301) 0.8780 (0.0281) 0.8722 (0.0310) standard error over 20 random seeds for CAKE with Table 7: Average normalized regret ( different acquisition functions. Value that are not significantly different from the lowest average regret for each function are bolded. ) Function CAKE-EI CAKE-UCB CAKE-TS Ackley-2 Ackley-5 Beale Branin Dropwave Egg holder Griewank-2 Griewank-5 Hartmann Levy-2 Levy-3 Rastrigin-2 Rastrigin-4 Rosenbrock Six-Hump Camel 0.0783 0.1732 0.2565 0.0070 0.4690 0.1241 0.0267 0.0185 0.0001 0.0353 0.0505 0.3341 0.3128 0.0483 0.1015 0.0203 0.0250 0.0786 0.0534 0.0538 0.0541 0.0256 0.0133 0.0529 0.0197 0.0190 0.0468 0.0499 0.0531 0.0669 0.0812 0.1654 0.2488 0.0065 0.4820 0.1350 0.0275 0.0190 0.0003 0.0360 0.0580 0.3520 0.3150 0.0490 0.0920 0.0215 0.0262 0.0810 0.0510 0.0560 0.0570 0.0260 0.0140 0.0515 0.0205 0.0200 0.0490 0.0510 0.0540 0. 0.0921 0.1789 0.2720 0.0082 0.5010 0.1298 0.0310 0.0195 0.0005 0.0402 0.0520 0.3650 0.3300 0.0510 0.1030 0.0287 0.0310 0.0920 0.0601 0.0650 0.0620 0.0305 0.0180 0.0580 0.0240 0.0235 0.0580 0.0570 0.0600 0.0750 EI due to its optimism bias), CAKE consistently achieves comparable performance across all variants. As shown in table below, the performance of CAKE-UCB and CAKE-TS remains close to that of CAKE-EI across diverse set of benchmark functions. To rigorously assess statistical equivalence, we conducted one-sided paired Wilcoxon signed-rank test (at the 5% significance level) comparing CAKE-EI against CAKE-UCB and CAKE-TS across multiple random seeds. The results indicate that, on the majority of functions, differences are not statistically significant. Overall, these results confirm that CAKEs effectiveness is not sensitive to the specific choice of acquisition function. C.7 Quantitative Analysis To rigorously support our claim in Section 5.1 that CAKE excels in the early stages of optimization, we conducted quantitative analysis based on normalized improvement, defined as: Normalized improvement at trial = ft f0 f0 , (27) where f0 is the initial performance, ft is the best performance at trial t, and is the final performance at 100% budget. This measures how much of the total progress CAKE achieves up to the t-th iteration. As shown in Table 8, CAKE achieves 67.5% of its total improvement within just 25% of the budget, on average. By 50%, it reaches over 83% of its final improvement, and by 75%, it is nearly converged. 26 Table 8: Normalized improvement on HPOBench at different budget level."
        },
        {
            "title": "Budget",
            "content": "25% 50% 75%"
        },
        {
            "title": "LR\nSVM\nRF\nXGB\nMLP",
            "content": "0.6183 0.7007 0.6244 0.6914 0.7394 0.8065 0.8244 0.7685 0.8643 0.9155 0.8401 0.9481 0.8646 0.9767 0."
        },
        {
            "title": "Average",
            "content": "0.6749 0.8358 0.9207 This demonstrates that CAKE rapidly identifies effective kernels and drives fast early progress, making it particularly effective in data-scarce regimes."
        },
        {
            "title": "D Limitations and Future Work",
            "content": "Computational cost. While CAKE can be applied entirely in-context and does not require any fine-tuning, using LLMs for inference may result in larger computational footprint compared to traditional BO methods (see Appendix C.2). Despite this, our findings indicate that CAKE trades this off with improved sample efficiency, which is particularly desirable property for black-box optimization tasks. This suggests the potential for integrating CAKE with more computationally efficient approaches, such as deploying it in the earlier stage of the optimization process. Data Contamination. We acknowledge the possibility that LLMs may have been exposed to scientific literature or code related to common optimization benchmarks during pre-training. However, we argue that data contamination is unlikely to meaningfully affect our results. While the LLM may possess general knowledge about kernels or synthetic functions, our approach to adaptive kernel evolution in BO is novel and there is no evidence that the specific kernel expressions or the optimization trajectory, exist in any public dataset or text. Thus, we believe that the observed performance stems from in-context adaptation, not memorization. This is further supported by our ablation study in Section B.4 which shows that removing the observed data from the prompt leads to significant performance degradation, confirming that the LLM relies on in-context learning rather than prior knowledge alone. Generalized kernel grammar. While we focus on addition and multiplication as initial proof-ofconcept operators, these operators are in fact good enough to form rich and expressive space of kernels. For example, by only using these operations, we can construct polynomial kernels to capture non-linear patterns as well as multi-dimensional kernels to model interactions among input features [12]. However, we would like that to note that the kernel grammar can be extended using other operators that preserve the closure properties of kernel functions, such as convolution, composition, and affine transformations [42]. We aim to explore these possibilities further in future work. Extension to broader ML tasks. Our long-term goal is to develop universal adaptive kernel method that can be applied across wide range of ML tasks. While the current work focuses on BO, the underlying idea of using an LLM to guide kernel evolution is not task-specific. We believe that CAKE can be easily adapted for other kernel-based methods such as SVM-based regression and classification, kernel principal component analysis, and metric learning with kernels. By leveraging task-specific performance signals, CAKE can automate and enhance kernel design across variety of kernel-based methods, demonstrating its broader potential to improve ML applications."
        },
        {
            "title": "NeurIPS Paper Checklist",
            "content": "1. Claims Question: Do the main claims made in the abstract and introduction accurately reflect the papers contributions and scope? Answer: [Yes] Justification: All claims are discussed in the main text. Guidelines: The answer NA means that the abstract and introduction do not include the claims made in the paper. The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. No or NA answer to this question will not be perceived well by the reviewers. The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 2. Limitations Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations of the proposed are clearly discussed in Appendix D. Guidelines: The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. The authors are encouraged to create separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on few datasets or with few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach. For example, facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, worse outcome might be that reviewers discover limitations that arent acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 3. Theory assumptions and proofs Question: For each theoretical result, does the paper provide the full set of assumptions and complete (and correct) proof? Answer: [NA] 28 Justification: The current paper does not include any theoretical results. Guidelines: The answer NA means that the paper does not include theoretical results. All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. All assumptions should be clearly stated or referenced in the statement of any theorems. The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide short proof sketch to provide intuition. Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. Theorems and Lemmas that the proof relies upon should be properly referenced. 4. Experimental result reproducibility Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Details are provided in the main text and in Appendix B. The code is also available online. Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. If the contribution is dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is novel architecture, describing the architecture fully might suffice, or if the contribution is specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to hosted model (e.g., in the case of large language model), releasing of model checkpoint, or other means that are appropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is new model (e.g., large language model), then there should either be way to access this model for reproducing the results or way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. 5. Open access to data and code Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? 29 Answer: [Yes] Justification: The code is available online at https://github.com/cake4bo/cake. Guidelines: The answer NA means that paper does not include experiments requiring code. Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for new open-source benchmark). The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only subset of experiments are reproducible, they should state which ones are omitted from the script and why. At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. 6. Experimental setting/details Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Details are provided in the text and in Appendix B. Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to level of detail that is necessary to appreciate the results and make sense of them. The full details can be provided either with the code, in appendix, or as supplemental material. 7. Experiment statistical significance Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The figures in Section 5 include error bars based on the standard error across multiple independent runs with different random seeds. Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). The method for calculating the error bars should be explained (closed form formula, call to library function, bootstrap, etc.) The assumptions made should be given (e.g., Normally distributed errors). 30 It should be clear whether the error bar is the standard deviation or the standard error of the mean. It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report 2-sigma error bar than state that they have 96% CI, if the hypothesis of Normality of errors is not verified. For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. 8. Experiments compute resources Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The paper provides details regarding the computing resources in Appendix B. Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didnt make it into the paper). 9. Code of ethics Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research was conducted in compliance with the NeurIPS Code of Ethics. Additionally, no deprecated datasets were used, and all external assets (e.g., OpenML datasets) were appropriately cited and used under permissible licenses. Guidelines: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. If the authors answer No, they should explain the special circumstances that require deviation from the Code of Ethics. The authors should make sure to preserve anonymity (e.g., if there is special consideration due to laws or regulations in their jurisdiction). 10. Broader impacts Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The proposed method does not directly lead to societal impacts that we feel must be highlighted beyond algorithmic improvements. Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. 31 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how system learns from feedback over time, improving the efficiency and accessibility of ML). 11. Safeguards Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The proposed method does not lend itself to this type of misuse. Guidelines: The answer NA means that the paper poses no such risks. Released models that have high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make best faith effort. 12. Licenses for existing assets Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The paper uses publicly available datasets (e.g., OpenML) and benchmarks, all of which are properly cited with references to their original sources. Guidelines: The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include URL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from particular source (e.g., website), the copyright and terms of service of that source should be provided. If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of dataset. For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. 32 If this information is not available online, the authors are encouraged to reach out to the assets creators. 13. New assets Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The code is well-documented and available at the anonymized repository https://github.com/cake4bo/cake. Guidelines: The answer NA means that the paper does not release new assets. Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. The paper should discuss whether and how consent was obtained from people whose asset is used. At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. 14. Crowdsourcing and research with human subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines: The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 15. Institutional review board (IRB) approvals or equivalent for research with human subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing or research with human subjects. Therefore, no IRB approval or equivalent was required. Guidelines: The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. 33 16. Declaration of LLM usage Question: Does the paper describe the usage of LLMs if it is an important, original, or non-standard component of the core methods in this research? Note that if the LLM is used only for writing, editing, or formatting purposes and does not impact the core methodology, scientific rigorousness, or originality of the research, declaration is not required. Answer: [Yes] Justification: The use of LLMs is detailed in Section 3 and Appendix B. Guidelines: The answer NA means that the core method development in this research does not involve LLMs as any important, original, or non-standard components. Please refer to our LLM policy (https://neurips.cc/Conferences/2025/LLM) for what should or should not be described."
        }
    ],
    "affiliations": [
        "The Chinese University of Hong Kong, Shenzhen",
        "University of Athens",
        "University of Illinois at Urbana-Champaign"
    ]
}