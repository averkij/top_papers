{
    "paper_title": "AutoIntent: AutoML for Text Classification",
    "authors": [
        "Ilya Alekseev",
        "Roman Solomatin",
        "Darina Rustamova",
        "Denis Kuznetsov"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "AutoIntent is an automated machine learning tool for text classification tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with embedding model selection, classifier optimization, and decision threshold tuning, all within a modular, sklearn-like interface. The framework is designed to support multi-label classification and out-of-scope detection. AutoIntent demonstrates superior performance compared to existing AutoML tools on standard intent classification datasets and enables users to balance effectiveness and resource consumption."
        },
        {
            "title": "Start",
            "content": "AutoIntent: AutoML for Text Classification Alekseev Ilya1,2,4, Solomatin Roman1,3, Rustamova Darina3, Kuznetsov Denis1 1Moscow Center for Advanced Studies, 2Moscow State University, 3ITMO University, 4dresscode.ai. Correspondence: ilya_alekseev_2016@list.ru 5 2 0 2 5 2 ] . [ 1 8 3 1 1 2 . 9 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "AutoIntent is an automated machine learning tool for text classification tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with embedding model selection, classifier optimization, and decision threshold tuning, all within modular, sklearn-like interface. The framework is designed to support multi-label classification and out-of-scope detection. AutoIntent demonstrates superior performance compared to existing AutoML tools on standard intent classification datasets and enables users to balance effectiveness and resource consumption."
        },
        {
            "title": "Introduction",
            "content": "Text classification remains fundamental task in natural language processing, with applications ranging from intent detection in conversational systems (Weld et al., 2021) to content categorization and sentiment analysis (Taha et al., 2024). Modern NLP has been revolutionized by transformerbased embedding models (Vaswani et al., 2023; Devlin et al., 2019; Reimers and Gurevych, 2019), which provide rich contextual representations of text. However, effectively utilizing these models for classification tasks requires careful consideration of multiple components: the choice of pretrained embedding model, the selection of appropriate classification algorithms, and the optimization of their hyperparameters. Traditional machine learning approaches often require manual tuning of these components, which can be time-consuming and requires significant expertise. While automated machine learning (AutoML) frameworks (Baratchi et al., 2024) have emerged to automate this process, existing solutions for NLP tasks often lack comprehensive support for the full spectrum of hyperparameter optimization (for instance, choosing best embedding model) and tuning confidence thresholds for hanFigure 1: Average accuracy (banking77 (Casanueva et al., 2020), massive (FitzGerald et al., 2022), minds14 (Gerz et al., 2021), hwu64 (Liu et al., 2019)) and training duration (on minds14) of AutoIntent presets (orange) and baseline AutoML tools (blue). dling multi-label classification and out-of-scope (OOS) detection (Larson et al., 2019). This paper introduces AutoIntent1, novel AutoML framework specifically designed for intent classification tasks. The framework offers sklearn-like interface (Pedregosa et al., 2018) for ease of use and supports even multi-label classification and OOS detection, bridging the gap between AutoML and conversation systems."
        },
        {
            "title": "2 Background",
            "content": "Automated machine learning, by definition, is tool for automating routines like data splitting for validation, hyperparameter tuning, model ensembling, and model selection. AutoML is highly relevant in scenarios where machine learning tasks need to be solved by non-experts and in conjunction with no-code ML, which is sometimes called ML as service (Bisong, 2019; Barga et al., 2015; Liberty et al., 2020; LeDell and Poirier, 2020; Carney 1https://github.com/DeepPavlov/AutoIntent 1 Approach Scarce train data Custom search space Experiments tracking H2O TAML & Word2Vec Flexible API H2O Flow integration Embedding prompting OOS detection Multi-label & LightAutoML AutoGluon TAML emb. Has data modes HP presets Encoder fine-tuning small AutoIntent (ours) Embeddings for Adapted small datasets Presets & customizble configs W&B*, tensorboard*, codecarbon*. FEDOT TAML & TF-IDF Adaptable HP presets Table 1: Comparison of NLP functionality in AutoML frameworks: H2O (LeDell and Poirier, 2020), LightAutoML (Vakhrushev et al., 2022), AutoGluon (Tang et al., 2024), FEDOT (Nikitin et al., 2021) and ours AutoIntent. HP stands for hyperparameters, TAML stands for tabular AutoML. *Weights and Biases (Biewald, 2020), Tensorboard (Abadi et al., 2015), CodeCarbon (Courty et al., 2024). et al., 2020; Acito, 2023). The applications include sentiment analysis, robotics, healthcare, business analysis (Yuan et al., 2024; Salehin et al., 2024). Tabular AutoML focuses on feature engineering, feature selection and model ensembling (Feurer et al., 2022; Vakhrushev et al., 2022; Erickson et al., 2020; LeDell and Poirier, 2020; Nikitin et al., 2021). Usually, they employ classical machine learning methods like GBMs (Chen and Guestrin, 2016; Prokhorenkova et al., 2018; Ke et al., 2017) and linear models, fast hyperparameter tuning methods with budget-aware strategies (Akiba et al., 2019), and ensembling strategies like stacking, blending and voting. Such frameworks sometimes can supersede exploratory data analysis and extensive research with just running preset training recipe. It is not rare to see AutoML frameworks winning machine learning contests, but the open source solutions often are not transferable to production-ready systems as the resulting pipeline is an ensemble of numerous amount of models without clear guides for deployment. Neural architecture search can be viewed as an automation in the field of deep learning (Salehin et al., 2024). It emphasizes finding optimal computational graph using approaches like cell-based and hierarchical search spaces (Zoph et al., 2018; Real et al., 2019) or using scaling laws (Tan and Le, 2020). It cannot be treated as full-fledged AutoML, as it is designed to address only the model selection problem. Though, it can be part of an AutoML pipeline (Jin et al., 2023). AutoML tools in the NLP domain primarily stand out from other AutoML by native support of text inputs (Tang et al., 2024; Vakhrushev et al., 2022). This is especially important for use by nonexperts, as it removes the requirement of manual tokenization and vectorization. Though, some tabular AutoML frameworks provide auxiliary tools for text feature extraction (LeDell and Poirier, 2020). The next peculiarity of text AutoML frameworks is their usage of transformer-based backbones, which makes sense, as this is the state-of-the-art in the field of NLP. Note that NLP AutoML primarily focuses on simple tasks like classification and regression, ignoring text generation and named entity recognition, for instance. In AutoML frameworks, the model selection can be implemented in three ways. The first and most straightforward is to use hyperparameter tuning tools like Optuna (Akiba et al., 2019) and genetic algorithms (Feurer et al., 2022) with preset search spaces. Usually, these presets differ in how much time and computational resources they require to reach acceptable quality. The variety of presets is provided to cover all possible use cases and hardware settings. Another option is not to tune hyperparameters but use some generic hyperparameters that reach balance between the final quality and the generalization across different tasks. These hyperparameters can be obtained empirically (Tang et al., 2024). The compromise between freezing hyperparameters and tuning all of them is the metalearning (Desai et al., 2022; Feurer et al., 2022; Wang, 2021; Tian et al., 2022; Huisman et al., 2021), where metamodel takes dataset as input and predicts hyperparameters. 2 Figure 2: (Left) AutoIntents three levels of hyperparameter optimization: at the module level, the embedding, scoring, and decision models are optimized sequentially; at the model level, each classification approach is tested against each other to select the best one; at the instance level, hyperparameters for each model is tuned individually with optuna samplers. (Right) Inference pipeline as result of AutoIntents hyperparameter optimization."
        },
        {
            "title": "3.1 Design Principles",
            "content": "The design of AutoIntent is guided by several key principles to ensure practical usability and maintainability (see Table 1). It features modular architecture with clear separation of concerns, adhering to software engineering best practices like type checking, auto-testing, and comprehensive documentation. The framework offers model diversity, supporting both high-performance deep learning models and efficient classical ML models that operate on pre-computed transformer embeddings. This embedding-centric design leverages the HuggingFace model repository and eliminates complex feature engineering. For usability, AutoIntent provides flexible optimization strategies (from presets to custom search spaces), multi-label classification, out-of-scope (OOS) detection, and few-shot learning."
        },
        {
            "title": "3.2 Separation of Concerns",
            "content": "AutoIntent defines scoring module as section of the text classification pipeline that outputs class probabilities, establishing clear separation from the decision module, which makes the final prediction by applying thresholds. This separation enhances modularity and flexibility, allowing single scoring models outputs to be reused with various decision strategies without re-computation, which is highly efficient for experimentation."
        },
        {
            "title": "3.3 Embedding Module",
            "content": "AutoIntent leverages the sentence-transformers library (Reimers and Gurevych, 2019), providing access to wide range of pre-trained transformer models from Hugging Face Hub (Wolf et al., 2020). AutoIntent offers three strategies for embedding model selection: Pipeline-level optimization. The embedding 3 preset duration banking hwu64 massive minds14 snips avg AutoGluon (best) AutoGluon (high) AutoGluon (medium) LightAutoML h2o zero-shot-transformers nn-medium nn-heavy zero-shot-openai classic-light classic-medium 461 430 24 44 47 27 136 216 Baselines 6.98 92.60 92.40 53.31 75.32 12.64 90.80 91.17 77.85 77.32 AutoIntent Presets 69.51 79.95 78.84 76.43 92.23 92. 71.47 70.79 72.96 85.04 90.83 90.92 21.39 89.22 87.13 47.41 75.30 63.58 72.75 73.39 80.49 87.11 87.19 85.19 95.37 92.59 72.22 76.85 87.04 75.31 80.86 96.30 97.53 97.84 96.00 98.86 98.86 98.38 98. 89.43 96.74 97.40 96.86 98.43 98.98 44.44 93.37 92.43 69.83 80.63 76.21 79.11 80.69 87.02 93.23 93.45 Table 2: Performance comparison across different presets averaged from three runs (except H2O and AutoGluon which were launched once). Column 1: Baseline AutoML frameworks: AutoGluon (Tang et al., 2024) with non-HPO presets best_quality, high_quality, medium_quality, H2O (LeDell and Poirier, 2020) with their word2vec, LightAutoML (Vakhrushev et al., 2022); and AutoIntent presets: nn (CNN (Kim, 2014), RNN), zero-shot (description-based biand cross-encoder, LLM prompting), classic (knn, logreg, random forest, catboost (Prokhorenkova et al., 2018)). Column 2: Duration in seconds evaluated on minds14 (Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz, single Tesla P100-SXM2-16GB). Columns 37: Accuracy on test sets. model is chosen once at the start of the pipeline to maximize efficiency. The selection is based on either retrieval metrics (e.g., NDCG) or the performance of simple downstream classifier (e.g., logistic regression). Scoring-level optimization. The embedding model is optimized individually for each candidate model during the optimization of the scoring module. This is more computationally intensive, but may yield better performance. Fixed embedding. Users can specify default embedding model to skip optimization entirely."
        },
        {
            "title": "This flexible approach allows users to balance",
            "content": "optimization quality and computational cost."
        },
        {
            "title": "3.4 Scoring Module",
            "content": "AutoIntent offers diverse set of scoring models. key architectural feature is that all the classifiers are able to operate on pre-computed embeddings. This separates computationally intensive embedding generation from the lightweight classification step, enabling balance between effectiveness and efficiency and allowing deployment on CPU-only systems. The available scoring modules include: et al., 2024) for efficient search, two-stage crossencoder re-ranking approach, and MLKNN (Zhang and Zhou, 2007) for multi-label tasks. BERT-based classifiers. Support full model fine-tuning and parameter-efficient approaches like LoRA (Hu et al., 2021) and P-Tuning (Mangrulkar et al., 2022). Generic sklearn integration allows use of any sklearn classifier operating on embedding vectors. Zero-shot methods utilize text descriptions of classes and either measure the closeness with bior cross-encoder or prompt LLM by API (OpenAI, 2023)."
        },
        {
            "title": "3.5 Decision Module",
            "content": "The Decision Module processes scores to produce final predictions, which is crucial for multi-label and OOS scenarios. AdaptiveDecision (Hou et al., 2020): samplespecific thresholding method for multi-label classification. JinoosDecision (Zhang et al., 2020): Finds universal threshold that balances in-domain and OOS accuracy. KNN-based approaches. These include KNearest Neighbors method with FAISS (Douze ThresholdDecision: Uses fixed, user-specified threshold, suitable for use within the AutoML tunframework in domain accuracy out-of-scope F1-measure AutoIntent AutoGluon (Tang et al., 2024) H2O (LeDell and Poirier, 2020) 96.13 95.76 85.22 76.79 48.53 40. Table 3: Performance comparison on out-of-scope detection task on CLINC150 (Larson et al., 2019). ing pipeline. TunableDecision: Employs Optuna (Akiba et al., 2019) to automatically find the optimal threshold by maximizing the F1 score. 3.6 AutoML Pipeline AutoIntent orchestrates the optimization of all components hierarchically  (Fig. 2)  , with two distinct levels of optimization. At the highest level, the pipeline performs module-level optimization, where it sequentially optimizes the embedding, scoring, and decision modules. Each module builds upon the best model from the previous modules optimization, creating cohesive pipeline. For instance, the scoring module utilizes features from the best embedding model, while the decision module processes probabilities from the best classifier. This greedy approach effectively prevents combinatorial explosion while maintaining strong performance. The second level focuses on model-level optimization, where both the model and its hyperparameters are sampled with Optunas random sampling and Tree-structured Parzen Estimators (Watanabe, 2023). This includes various transformer models for the embedding module, different classification methods for the scoring module, and multiple threshold strategies for the decision module. crucial aspect of the pipeline is its clear distinction between tuning (non-gradient optimization of hyperparameters) and training (gradient optimization of model weights, if applicable). AutoIntent implements careful data handling with separate data subsets for training weights and validating hyperparameter configurations, and strategies to prevent target leakage. For cross-validation, it uses out-of-fold predictions to train stacked models (as we can view the whole three-stage pipeline with embedding, scoring and decision nodes as stacked models). The optimization is configured via dictionary-like search space, and the final optimized pipeline can be saved and used later with simple save, load, and predict methods."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Baselines We compared AutoIntent against several opensource NLP AutoML frameworks: H2O (LeDell and Poirier, 2020), LightAutoML (LAMA) (Vakhrushev et al., 2022), and AutoGluon (Tang et al., 2024). The evaluation was conducted across five standard intent classification datasets  (Table 2)  . The results show that AutoGluon and AutoIntent are highly competitive, while H2O achieves moderate performance and LAMA fails on these tasks. AutoIntent provides the most affordable options in terms of balance between the quality and the computational cost. Also during the testing, we revealed several limitations in baseline frameworks: Hyperparameter Optimization: AutoGluon uses fixed training recipe; AutoGluon does support HPO presets, but they are too time and disk space consuming to test. Feature Engineering: H2O lacks native text features support. Model Flexibility: LAMA supports only three predefined transformer models. Inference Efficiency: AutoIntent can select lighter models for comparable performance, unlike AutoGluons fine-tuned transformer as fixed output. Model Variety: Only AutoIntent provides the whole range of ML and DL models for text classification."
        },
        {
            "title": "4.2 OOS Detection",
            "content": "We evaluated OOS capabilities on the CLINC150 dataset (Larson et al., 2019). Since baselines lack native OOS support, we treated OOS as an additional class for them while using AutoIntents builtin OOS support. The results in Table 3 demonstrate AutoIntents superiority, attributable to its dedicated confidence thresholds tuning. We utilize in-domain accuracy, because the dataset is quite balanced. Though, this is detection task, so we consider F1-score as appropriate choice for OOS class. 5 Figure 3: Performance comparison in scenario of scarce training data. Baseline AutoML frameworks: AutoGluon (Tang et al., 2024) with non-HPO preset medium_quality, H2O (LeDell and Poirier, 2020) with their word2vec; and AutoIntent preset classic-light."
        },
        {
            "title": "4.3 Few-shot Scenario",
            "content": "We evaluated the capabilities of AutoIntent in scenario of scarce training data. We synthetically subsampled the datasets to have only shots per class, with ranging from 4 to 128. The results in Figure 3 demonstrate AutoIntents robustness and superiority due to employing neighbor-based classification methods."
        },
        {
            "title": "5 Conclusion",
            "content": "AutoIntent addresses the critical gap in automated machine learning for intent classification tasks, where existing AutoML frameworks lack comprehensive support for NLP-specific challenges including embedding model selection, multi-label classification, out-of-scope detection, and few-shot learning. The frameworks importance stems from democratizing intent classification through end-toend automation. The systems novelty lies in its optimization strategy and embedding-centric design leveraging precomputed transformer representations. AutoIntent targets NLP practitioners, conversational AI developers, and ML-as-a-service platforms. AutoIntent operates through three-stage pipeline (embedding, scoring, decision) with hierarchical optimization using Optuna. The embedding module selects optimal transformer models, the scoring module offers diverse classifiers. The system was evaluated across five intent classification datasets. While demonstrating strong performance, limitations include no user studies conducted and focus on intent classification datasets. The framework is released under Apache-2.0 license to encourage community adoption."
        },
        {
            "title": "6 Acknowledgements",
            "content": "supported by the Ministry This work was the Russian of Economic Development of 139-15-2025Federation (agreement No. 013, dated June 20, 2025, subsidy identifier 000000C313925P4B0002)."
        },
        {
            "title": "References",
            "content": "Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, and 21 others. 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org. Frank Acito. 2023. Predictive analytics with knime. Analytics for citizen data scientists. Switzerland: Springer. Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019. Optuna: nextgeneration hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pages 26232631. Mitra Baratchi, Can Wang, Steffen Limmer, Jan van Rijn, Holger Hoos, Thomas Bäck, and Markus Olhofer. 2024. Automated machine learning: past, present and future. Artificial intelligence review, 57(5):122. Roger Barga, Valentine Fontama, Wee Hyong Tok, and Luis Cabrera-Cordon. 2015. Predictive analytics with Microsoft Azure machine learning. Springer. Lukas Biewald. 2020. weights and biases. wandb.com. Experiment tracking with Software available from Ekaba Bisong. 2019. An overview of google cloud platform services. Building Machine learning and deep learning models on google cloud platform: comprehensive guide for beginners, pages 710. Michelle Carney, Barron Webster, Irene Alvarado, Kyle Phillips, Noura Howell, Jordan Griffith, Jonas Jongejan, Amit Pitaru, and Alexander Chen. 2020. Teachable machine: Approachable web-based tool for exploring machine learning classification. In Extended abstracts of the 2020 CHI conference on human factors in computing systems, pages 18. Iñigo Casanueva, Tadas Temˇcinas, Daniela Gerz, Matthew Henderson, and Ivan Vulic. 2020. Efficient intent detection with dual sentence encoders. Preprint, arXiv:2003.04807. Tianqi Chen and Carlos Guestrin. 2016. Xgboost: In Proceedings of scalable tree boosting system. the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785 794. spoken language understanding system for private-bydesign voice interfaces. Preprint, arXiv:1805.10190. Benoit Courty, Victor Schmidt, Sasha Luccioni, GoyalKamal, MarionCoutarel, Boris Feld, Jérémy Lecourt, LiamConnell, Amine Saboni, Inimaz, supatomic, Mathilde Léval, Luis Blanche, Alexis Cruveiller, ouminasara, Franklin Zhao, Aditya Joshi, Alexis Bogroff, Hugues de Lavoreille, and 11 others. 2024. mlco2/codecarbon: v2.4.1. Rushil Desai, Aditya Shah, Shourya Kothari, Aishwarya Surve, and Narendra Shekokar. 2022. Textbrew: Automated model selection and hyperparameter optimization for text classification. International Journal of Advanced Computer Science and Applications, 13(9). Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. Preprint, arXiv:1810.04805. Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé arXiv preprint Jégou. 2024. The faiss library. arXiv:2401.08281. Kenneth Enevoldsen, Isaac Chung, Imene Kerboua, Márton Kardos, Ashwin Mathur, David Stap, Jay Gala, Wissam Siblini, Dominik Krzeminski, Genta Indra Winata, Saba Sturua, Saiteja Utpala, Mathieu Ciancone, Marion Schaeffer, Gabriel Sequeira, Diganta Misra, Shreeya Dhakal, Jonathan Rystrøm, Roman Solomatin, and 67 others. 2025. MMTEB: Massive Multilingual Text Embedding Benchmark. Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. 2020. Autogluon-tabular: Robust and accurate automl for structured data. Preprint, arXiv:2003.06505. Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer, and Frank Hutter. 2022. Auto-sklearn 2.0: Hands-free automl via metalearning. Preprint, arXiv:2007.04074. Jack FitzGerald, Christopher Hench, Charith Peris, Scott Mackie, Kay Rottmann, Ana Sanchez, Aaron Nash, Liam Urbach, Vishesh Kakarala, Richa Singh, Swetha Ranganath, Laurie Crist, Misha Britan, Wouter Leeuwis, Gokhan Tur, and Prem Natarajan. 2022. Massive: 1m-example mullanguage understanding dataset tilingual natural with 51 typologically-diverse languages. Preprint, arXiv:2204.08582. Alice Coucke, Alaa Saade, Adrien Ball, Théodore Bluche, Alexandre Caulier, David Leroy, Clément Doumouro, Thibault Gisselbrecht, Francesco Caltagirone, Thibaut Lavril, Maël Primet, and Joseph Dureau. 2018. Snips voice platform: an embedded Daniela Gerz, Pei-Hao Su, Razvan Kusztos, Avishek Mondal, Michal Lis, Eshan Singhal, Nikola Mrksic, Tsung-Hsien Wen, and Ivan Vulic. 2021. Multilingual and cross-lingual intent detection from spoken data. CoRR, abs/2104.08524. 7 Yutai Hou, Yongkui Lai, Yushan Wu, Wanxiang Che, and Ting Liu. 2020. Few-shot learning for multilabel intent detection. Preprint, arXiv:2010.05256. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. Preprint, arXiv:2106.09685. Mike Huisman, Jan Van Rijn, and Aske Plaat. 2021. survey of deep meta-learning. Artificial Intelligence Review, 54(6):44834541. Haifeng Jin, François Chollet, Qingquan Song, and Xia Hu. 2023. Autokeras: An automl library for deep learning. Journal of Machine Learning Research, 24(6):16. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30. Yoon Kim. 2014. Convolutional neural networks for sentence classification. Preprint, arXiv:1408.5882. Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke, Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A. Laurenzano, Lingjia Tang, and Jason Mars. 2019. An evaluation dataset for intent classification and out-ofscope prediction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 13111316, Hong Kong, China. Association for Computational Linguistics. Erin LeDell and Sebastien Poirier. 2020. H2o automl: Scalable automatic machine learning. In Proceedings of the AutoML Workshop at ICML, volume 2020, page 24. Sean Lee, Aamir Shakir, Darius Koenig, and Julius Lipp. 2024. Open source strikes bread - new fluffy embeddings model. Xianming Li and Jing Li. 2023. Angle-optimized text embeddings. arXiv preprint arXiv:2309.12871. Edo Liberty, Zohar Karnin, Bing Xiang, Laurence Rouesnel, Baris Coskun, Ramesh Nallapati, Julio Delgado, Amir Sadoughi, Yury Astashonok, Piali Das, and 1 others. 2020. Elastic machine learning algorithms in amazon sagemaker. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, pages 731737. Xingkun Liu, Arash Eshghi, Pawel Swietojanski, and Verena Rieser. 2019. Benchmarking natural language understanding services for building conversational agents. Preprint, arXiv:1903.05566. Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Peft: State-of-the-art parameterBossan. 2022. https://github. efficient fine-tuning methods. com/huggingface/peft. Niklas Muennighoff, Nouamane Tazi, Loïc Magne, and Nils Reimers. 2023. MTEB: Massive Text Embedding Benchmark. Preprint, arXiv:2210.07316. Nikolay O. Nikitin, Pavel Vychuzhanin, Mikhail Sarafanov, Iana S. Polonskaia, Ilia Revin, Irina V. Barabanova, Gleb Maximov, Anna V. Kalyuzhnaya, and Alexander Boukhanovsky. 2021. Automated evolutionary approach for the design of composite machine learning pipelines. Future Generation Computer Systems. OpenAI. 2023. Openai api. https://openai.com/ api/. Accessed: 26 may 2025. Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Andreas Müller, Joel Nothman, Gilles Louppe, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Édouard Duchesnay. 2018. Scikit-learn: Machine learning in python. Preprint, arXiv:1201.0490. Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. 2018. Catboost: unbiased boosting with categorical features. Advances in neural information processing systems, 31. Esteban Real, Alok Aggarwal, Yanping Huang, and Regularized evolution for Preprint, Quoc Le. 2019. image classifier architecture search. arXiv:1802.01548. Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. Imrus Salehin, Md Shamiul Islam, Pritom Saha, SM Noman, Azra Tuni, Md Mehedi Hasan, and Md Abu Baten. 2024. Automl: systematic review on automated machine learning with neural architecture Journal of Information and Intelligence, search. 2(1):5281. Kamal Taha, Paul D. Yoo, Chan Yeun, Dirar Homouz, and Aya Taha. 2024. comprehensive survey of text classification techniques and their research applications: Observational and experimental insights. Computer Science Review, 54:100664. Mingxing Tan and Quoc V. Le. 2020. Efficientnet: Rethinking model scaling for convolutional neural networks. Preprint, arXiv:1905.11946."
        },
        {
            "title": "A Computational Efficiency",
            "content": "To quantify the computational requirements of different scoring modules, we conducted comprehensive analysis using the Code Carbon library (Courty et al., 2024). This analysis measured various aspects of computational resource consumption for single trial (training and evaluation of single model configuration). The results, presented in Table 4, reveal significant variations in resource usage across different approaches. The analysis revealed significant variations in resource efficiency across different scoring methods. KNN-based methods demonstrated exceptional efficiency, with minimal emissions and runtime, making them particularly suitable for resource-constrained environments. Logistic regression showed moderate resource consumption while maintaining high performance, representing balanced trade-off between computational cost and effectiveness. In contrast, BERT-based methods exhibited the highest resource requirements, necessitating substantial computational infrastructure. These findings provide valuable insights for deployment scenarios with varying resource constraints and for building AutoIntents presets. A.1 Embedding Module Effectiveness We evaluated our retrieval-based embedding selection heuristic (optimizing NDCG) against the ground truth (final accuracy from the full pipeline), as described in Section 3.3. As shown in Figure 4 and Table 5, while the approximate ranking is imperfect, it successfully identifies the best model (stella_en_400M_v5). This demonstrates that the heuristic effectively balances computational cost and selection quality. We have taken top models from MTEB(eng)(Muennighoff et al., 2023; Enevoldsen et al., 2025) leaderboard. Zhiqiang Tang, Haoyang Fang, Su Zhou, Taojiannan Yang, Zihan Zhong, Tony Hu, Katrin Kirchhoff, and George Karypis. 2024. Autogluon-multimodal (automm): Supercharging multimodal automl with foundation models. Preprint, arXiv:2404.16233. Yingjie Tian, Xiaoxi Zhao, and Wei Huang. 2022. Metalearning approaches for learning-to-learn in deep learning: survey. Neurocomputing, 494:203223. Anton Vakhrushev, Alexander Ryzhkov, Maxim Savchenko, Dmitry Simakov, Rinchin Damdinov, and Alexander Tuzhilin. 2022. Lightautoml: Automl solution for large financial services ecosystem. Preprint, arXiv:2109.01528. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. Attention is all you need. Preprint, arXiv:1706.03762. Jane Wang. 2021. Meta-learning in natural and artificial intelligence. Current Opinion in Behavioral Sciences, 38:9095. Shuhei Watanabe. 2023. Tree-structured parzen estimator: Understanding its algorithm components and their roles for better empirical performance. Preprint, arXiv:2304.11127. H. Weld, X. Huang, S. Long, J. Poon, and S. C. Han. 2021. survey of joint intent detection and slotfilling models in natural language understanding. Preprint, arXiv:2101.08091. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, and 3 others. 2020. Huggingfaces transformers: State-of-the-art natural language processing. Preprint, arXiv:1910.03771. Han Yuan, Kunyu Yu, Feng Xie, Mingxuan Liu, and Shenghuan Sun. 2024. Automated machine learning with interpretation: systematic review of methodologies and applications in healthcare. Medicine Advances, 2(3):205237. Jian-Guo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan, Philip S. Yu, Richard Socher, and Caiming Xiong. 2020. Discriminative nearest neighbor few-shot intent detection by transferring natural language inference. Preprint, arXiv:2010.13009. Min-Ling Zhang and Zhi-Hua Zhou. 2007. Ml-knn: lazy learning approach to multi-label learning. Pattern recognition, 40(7):20382048. Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. 2018. Learning transferable architectures for scalable image recognition. Preprint, arXiv:1707.07012. 9 model emissions runtime energy gpu cpu ram bert ptuning lora linear rerank dnnc rand forest knn 1.382 1.118 0.863 0.428 0.270 0.122 0.073 0.009 103.911 83.455 65.157 73.393 29.040 10.000 11.367 1.281 units grams sec 3.133 2.535 1.957 0.971 0.613 0.276 0.166 0.019 Wh 2.198 1.785 1.372 0.312 0.355 0.192 0.074 0.014 0.774 0.620 0.484 0.545 0.213 0.070 0.080 0.004 1.615e-01 1.295e-01 1.009e-01 1.138e-01 4.436e-02 1.455e-02 1.664e-02 9.044e-04 rate 0.014 0.014 0.013 0.006 0.010 0.013 0.007 0.012 Wh Wh Wh grams/sec Table 4: Computational resource consumption for different scoring modules. The experiments are conducted on banking77 dataset with mixedbread-ai/mxbai-embed-large-v1 (Lee et al., 2024; Li and Li, 2023), system with AMD Ryzen 7 5800H, NVIDIA RTX 3060 Laptop. Median values of 10 trials are displayed. Embeddings were pre-computed."
        },
        {
            "title": "Accuracy NDCG",
            "content": "stella_en_400M_v5 multilingual-e5-1 GIST-large-2 UAE-Large-V1 bge-m3 multilingual-e5-large LaBSE KaLM-embedding-3 nomic-embed-4 deberta-v3-small deberta-v3-large deberta-v3-base 94.28 93.65 93.51 92.89 92.69 91.41 90.47 89.65 87.24 81.15 75.39 75.00 93.83 92.97 93.32 93.25 92.49 92.45 89.51 92.88 89.63 67.20 59.59 59.28 Table 5: Embedding models performance averaged over hwu64 (Liu et al., 2019), massive (FitzGerald et al., 2022), minds14 (Gerz et al., 2021), snips (Coucke et al., 2018). 1large-unstruct, 2Embedding-v0, 3multilingualmini-instruct-v1.5, 4text-v1.5 Figure 4: Encoders ranking: (Left) precise ranking obtained via training full AutoML pipeline with only this model, (Right) approximate ranking based on retrieval quality (NDCG)."
        }
    ],
    "affiliations": [
        "ITMO University",
        "Moscow Center for Advanced Studies",
        "Moscow State University",
        "dresscode.ai"
    ]
}