{
    "paper_title": "The Open Source Advantage in Large Language Models (LLMs)",
    "authors": [
        "Jiya Manchanda",
        "Laura Boettcher",
        "Matheus Westphalen",
        "Jasser Jasser"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) mark a key shift in natural language processing (NLP), having advanced text generation, translation, and domain-specific reasoning. Closed-source models like GPT-4, powered by proprietary datasets and extensive computational resources, lead with state-of-the-art performance today. However, they face criticism for their \"black box\" nature and for limiting accessibility in a manner that hinders reproducibility and equitable AI development. By contrast, open-source initiatives like LLaMA and BLOOM prioritize democratization through community-driven development and computational efficiency. These models have significantly reduced performance gaps, particularly in linguistic diversity and domain-specific applications, while providing accessible tools for global researchers and developers. Notably, both paradigms rely on foundational architectural innovations, such as the Transformer framework by Vaswani et al. (2017). Closed-source models excel by scaling effectively, while open-source models adapt to real-world applications in underrepresented languages and domains. Techniques like Low-Rank Adaptation (LoRA) and instruction-tuning datasets enable open-source models to achieve competitive results despite limited resources. To be sure, the tension between closed-source and open-source approaches underscores a broader debate on transparency versus proprietary control in AI. Ethical considerations further highlight this divide. Closed-source systems restrict external scrutiny, while open-source models promote reproducibility and collaboration but lack standardized auditing documentation frameworks to mitigate biases. Hybrid approaches that leverage the strengths of both paradigms are likely to shape the future of LLM innovation, ensuring accessibility, competitive technical performance, and ethical deployment."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 6 1 ] . [ 1 4 0 0 2 1 . 2 1 4 2 : r THE OPEN-SOURCE ADVANTAGE IN LARGE LANGUAGE MODELS (LLMS) Jiya Manchanda Department of Philosophy and Religion Rollins College Winter Park jmanchanda@rollins.edu Laura Boettcher Department of Mathematics and Computer Science Rollins College Winter Park lboettcher@rollins.edu Matheus Westphalen Department of Mathematics and Computer Science Rollins College Winter Park mwestphalen@rollins.edu Jasser Jasser Department of Mathematics and Computer Science Rollins College Winter Park jjasser@rollins.edu"
        },
        {
            "title": "ABSTRACT",
            "content": "Large language models (LLMs) mark key shift in natural language processing (NLP), having advanced text generation, translation, and domain-speciﬁc reasoning. Closed-source models like GPT4, powered by proprietary datasets and extensive computational resources, lead with state-of-the-art performance today. However, they face criticism for their \"black box\" nature and for limiting accessibility in manner that hinders reproducibility and equitable AI development. By contrast, opensource initiatives like LLaMA and BLOOM prioritize democratization through community-driven development and computational efﬁciency. These models have signiﬁcantly reduced performance gaps, particularly in linguistic diversity and domain-speciﬁc applications, while providing accessible tools for global researchers and developers. Notably, both paradigms rely on foundational architec- (2017). Closed-source tural innovations, such as the Transformer framework by Vaswani et al. models excel by scaling effectively, while open-source models adapt to real-world applications in underrepresented languages and domains. Techniques like Low-Rank Adaptation (LoRA) and instruction-tuning datasets enable open-source models to achieve competitive results despite limited resources. To be sure, the tension between closed-source and open-source approaches underscores broader debate on transparency versus proprietary control in AI. Ethical considerations further highlight this divide. Closed-source systems restrict external scrutiny, while open-source models promote reproducibility and collaboration but lack standardized auditing documentation frameworks to mitigate biases. Hybrid approaches that leverage the strengths of both paradigms are likely to shape the future of LLM innovation, ensuring accessibility, competitive technical performance, and ethical deployment. Keywords Open-source models Large Language Models (LLMs) Transparency"
        },
        {
            "title": "1 Introduction",
            "content": "Large language models (LLMs) stand at the forefront of connectionist artiﬁcial intelligence (AI) today, having revolutionized the realm of natural language processing (NLP) and driven advancements in areas such as text generation, Equal contribution Equal contribution Equal contribution The Open-Source Advantage in Large Language Models (LLMs) translation, domain-speciﬁc inferencing, and sentiment analysis [1]. These models, built on cutting-edge neural architectures and trained on expansive datasets, have not only become indispensable tools in industry but also focal points of academic investigation. However, their rapid development has brought critical issues into focuschief among them is the tension between open-source and closed-source approaches [2]. This underexplored division (in part, of labor) presents urgent questions about transparency, accessibility, and the equitable distribution of the beneﬁts of AI, and will be the subject of much consideration in this paper. The closed-source approach, typiﬁed by models like OpenAIs GPT-4, has thus far dominated benchmarks for LLMs [3]. Their ability to excel stems squarely from the proprietary datasets that they are trained on (in addition to signiﬁcant computational investments), which have enabled advanced capabilities in reasoning, text synthesis, and conversational AI [4]. Despite their technical achievements, though, these models are often criticized for their lack of transparency [5]. The proprietary nature of their design, development, and data restricts access to methodologies and ﬁndings, and has raised concerns about the reproducibility of their outcomes. Moreover, the concentration of these resources within small number of organizations is claimed to have exacerbated inequities in global AI development. Needless to say, this dynamic has restricted many researchers and practitioners from competing effectively or even building upon these systems [6]. It is in light of the aforementioned trajectory of development that open-source LLMs, including LLaMA and BLOOM, have emerged as powerful alternatives. These models operate on the ethos of accessibility and community-driven innovation, and now offer researchers and developers the tools to advance NLP without vast computational resources [7]. By way of innovations in ﬁne-tuning, such as low-rank adaptation (LoRA) and domain-speciﬁc optimization, open-source models have signiﬁcantly narrowed performance gaps in recent months [8]. Projects like BLOOMs multilingual framework demonstrate the capacity of open-source efforts to address linguistic diversity and real-world complexity, while models like LLaMA highlight the feasibility of achieving high performance with computational efﬁciency. These initiatives underscore the role of open collaboration in broadening the scope of AI research and ensuring more equitable distribution of its beneﬁts. The divide between openand closed-source models is best framed within the historical development of LLMs, which provides essential context for understanding their current capabilities. Early statistical language models, inspired by Shannons Information Theory, relied on probabilistic methods to predict word sequences [9]. While these models laid the groundwork for computational linguistics, they were limited in handling long-range dependencies and capturing the semantic properties of pragmatic language use [10]. The transition to neural network-based models in the 2000s marked signiﬁcant advancement. Word embeddings like Word2Vec and GloVe enabled dense vector representations of words, which improved our ability to model such semantic relationships [11]. The development of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks further expanded this capacity for processing sequential data and capturing temporal dependencies [12]. However, these architectures struggled with scalability when handling large datasets. The introduction of the Transformer architecture in 2017 by Vaswani et al. shifted the paradigm of NLP insofar as it overcame these limitations to statistically signiﬁcant degree [13]. Transformers, with their self-attention mechanisms, allowed for parallel sequence processing and the corresponding modeling of long-range dependencies, which have since become the backbone of modern LLMs. Subsequent innovations built upon this Transformer framework. Simply look to BERTs bidirectional training approach, which enhanced performance on tasks like question answering and natural language inference, as well as GPTs autoregressive design, which excelled in text generation and summarization [14]. The release of the closed-source GPT-3, which came bearing 175 billion parameters, demonstrated how scaling model size could improve generalization abilities and enable few-shot learning across highly varied tasks [15]. It was not long before open-source models such as BLOOM and LLaMA met those same benchmarks, though. This achievement quickly showcased how high performance can be attained without dependence on massive scale or proprietary frameworks. In examining this dynamic between openand closed-source LLMs, this paper seeks to elucidate the core issues that will shape the trajectory of developments in computational linguistics. Section 2 explores the innovation and development processes underpinning open-source and closed-source models, highlighting key breakthroughs and limitations. Section 3 evaluates the comparative performance of these models, focusing on benchmarks and task-speciﬁc outcomes. Section 4 addresses accessibility and use cases, speciﬁcally assessing how the availability and practical applications of these systems impact various stakeholders. Section 5 delves into ethical considerations concerning transparency, scrutinizing the implications of proprietary practices and open collaboration. Section 6 discusses the broader implications of the open-versus-closed divide, integrating ﬁndings from previous sections. Finally, Section 7 outlines potential directions for future research, proposing mechanism of how to best foster innovation while ensuring equitable AI deployment and governance. 2 The Open-Source Advantage in Large Language Models (LLMs)"
        },
        {
            "title": "2 Innovation and Development",
            "content": "The innovation and development of Large Language Models (LLMs) are marked by (a) foundational architectural changes and (b) reﬁned training methodologies. As noted, the Transformer architecture, introduced by Vaswani et al. in 2017, fundamentally changed the way machine learning models process sequences of data. Previous models, such as recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, operated sequentially. This means that they processed one word or token at time, with each step depending on the previous output. While effective for short-term dependencies, these architectures struggled to efﬁciently handle long-range relationships in data. As result, they were challenged by vanishing gradients and slow training times. Transformers addressed these limitations by introducing mechanism called self-attention [16]. This mechanism allows the model to evaluate the relationship between all tokens in sequence simultaneously, rather than step-by-step. So, for example, when processing sentence, Transformer can determine the importance of every word relative to the others in single compute. This parallel processing capability reduces computational bottlenecks by allowing for faster training and, by extension, inference. Moreover, self-attention enables Transformers to model long-range dependencies. In natural language, the meaning of word or phrase often depends on context from distant parts of the text. Transformers excel in capturing these relationships, which is critical for tasks like summarization, translation, and complex reasoning. Of course, the architectures scalability naturally facilitated its adoption in large-scale closed-source models like GPT3 and GPT-4. Yet, it was not lost on open-source models including BLOOM and LLaMA to leverage the Transformer framework for the purpose of achieving competitive performance via computational efﬁciency. Subsidiary incremental developments upon this foundation like LLaMAs grouped query attention (GQA) reduced memory demands by sharing attention weights, which allowed for performance gains without exorbitant resource requirements. In similar fashion, Flash Attention optimized for training speed and energy efﬁciency by reducing the computational complexity of self-attention operations [17]. These advancements sufﬁciently demonstrate how open-source models may meet closed-source models on the question of scalability by innovating within architectural constraints. The evolution of training techniques has been equally pivotal. Closed-source models often utilize proprietary datasets encompassing billions of tokens, which renders them able to achieve comprehensive pretraining objectives. key instance of this phenomenon would be autoregressive modeling, which, employed in GPT, trains models to predict the next token in sequence [18]. In so doing, it reinforces the coherence and ﬂuency of its outcomes. Similarly, masked language modeling, which, employed in BERT, predicts missing tokens in sentence, fostering deeper understanding of bidirectional context [19]. These methods allow models to capture the nuanced language patterns and semantic relationships that form the basis of their strong generalization capabilities [20]. It is important to note that Reinforcement Learning from Human Feedback (RLHF) enhances this process by incorporating human evaluative feedback directly into training loops. In RLHF, the models are ﬁne-tuned to align their outputs with human-deﬁned preferences, thus improving both accuracy and alignment with values [21]. This approach is particularly impactful in domains where value-based considerations stand at the forefront of decision-making, such as healthcare and governance. In response to these advancements, open-source models have introduced training approaches that effectively balance computational efﬁciency with performance optimization. Low-Rank Adaptation (LoRA), for example, reduces the computational burden during ﬁne-tuning by updating only subset of task-speciﬁc parameters. This method enables smaller organizations to tailor large models to speciﬁc applications without incurring the substantial costs associated with full model retraining. Moreover, publicly available instruction-tuning datasets provide open-source models with an alternative to Reinforcement Learning from Human Feedback (RLHF). These datasets allow models to adapt to highly varied tasks by leveraging clearly structured instructions. Quantization techniques further enhance their efﬁciency by reducing the precision of model weights. Now, model distillation complements this by compressing large models into smaller, more efﬁcient versions that retain their essential capabilities. These compressed models are particularly valuable for edge-case applications where computational resources are limited. Notably, it is the real-world applications of LLMs that illustrate the distinct trajectories of openand closed-source models. Closed-source LLMs dominate high-stakes domains such as conversational AI, creative content generation, and advanced reasoning. For example, GPT-3 was widely adopted for automated content creation, customer support, and other on-demand tasks. Conversely, open-source models rely on their adaptive capabilities to meet inclusivity metrics given their access to expansive training. case in point is BLOOMs multilingual framework that supports over 40 languages. As such, open-source models have the potential to, and already are, surpassing closed-source models on the question of diverse datasets and how those contribute to global NLP research. Collaboration between LLMs and external tools has further expanded their utility. Retrieval-Augmented Generation (RAG), for instance, integrates information retrieval systems with generative models, enabling real-time access to updated knowledge [22]. Such systems are particularly effective in ﬁelds like healthcare, law, and ﬁnance, where timely and accurate information is critical [23]. By building on modular architectures and publicly accessible datasets, open-source models have been able to achieve comparable functionality to closed-source systems. The Open-Source Advantage in Large Language Models (LLMs)"
        },
        {
            "title": "3 Performance",
            "content": "The performance of open-source and closed-source Large Language Models (LLMs) is indicative of their underlying architecture, pre-training datasets, and optimization strategies, but understanding their comparative strengths requires closer evaluation. Closed-source models, such as GPT-4, dominate state-of-the-art benchmarks like HumanEval and GSM8K [24]. This is due in part to their ability to leverage proprietary datasets and in part result of their expansive pre-training corpora. The datasets on which these models are trained span hundreds of terabytes, which allows them to excel at wide range of domain-general tasks with minimal ﬁne-tuning [25]. This is precisely the reason that closedsource models possess superior generalization capabilities when it comes to generative tasks, such as creative writing and textual summarization. Look also to GPT-4s parameter count of one trillion. It is this critical component, coupled with chain-of-thought prompting, that underlies o1s ability to outperform the vast majority of open-source models on multi-step problem-solving and step-by-step reasoning [26]. However, the dominance of closed-source models is constrained by marked methodological challenges. Data contamination, i.e., overlaps between training and evaluation datasets, has been claimed to compromise the reliability of benchmarks for closed-source models [27]. The lack of transparency in proprietary datasets compounds this issue, leaving many results difﬁcult to validate independently [28]. Despite these advantages, open-source LLMs have made signiﬁcant progress in closing the performance gap. Techniques like Low-Rank Adaptation (LoRA) and Conditioned Reinforcement Learning Fine-Tuning (C-RLFT) have been instrumental in this advancement. LoRAs capacity to selectively ﬁne-tune parameters, for example, minimizes computational costs while maintaining high domain-speciﬁc accuracy with competitive results on benchmarks such as GSM8K. NVIDIAs NVLM 1.0D 72B model exempliﬁes domain-speciﬁc excellence, achieving 4.3-point improvement in mathematical reasoning and coding tasks through multimodal training [29]. Unlike models such as InternVL2Llama3-76B, which exhibit degraded text-based performance after multimodal training, NVLM not only preserves but also enhances its textual capabilities. This robustness enables NVLM to handle complex domain-speciﬁc inputs, such as handwritten pseudocode or location-speciﬁc queries, underscoring its precision within specialized contexts. Its performance provides proof-of-concept for domain-speciﬁc models to complement domain-general systems. Similar outcomes in performance hold true for domain-speciﬁc models like StarCoder, which underwent targeted optimization for programming tasks, and ClinicalBERT, which underwent targeted optimization for medical analyses. These platforms often outperform general-purpose closed-source models in benchmarks like HumanEval. Techniques like knowledge distillation and model compression are salient instances of the aforementioned open-source optimization strategies [30]. Knowledge distillation creates smaller, efﬁcient versions of larger models by transferring essential performance traits, while model compression reduces the requirements of computational resources. To be sure, these models underscore how open-source frameworks not only rival but increasingly exceed closed-source models in specialized applications, while maintaining their stronghold on accessibility to resource-constrained communities. Now although open-source models transparency facilitates reproducibility of outcomes, their benchmarking potential is limited by narrower dataset scopes and fewer resources. Current benchmarks often prioritize narrow task-speciﬁc metrics, overlooking the complexity and diversity of real-world applications. Resource disparities further skew these outcomes in performance, as closed-source models beneﬁt from high-performance distributed systems, whereas opensource models must optimize performance through collaborative resource pooling and parameter-efﬁcient strategies. Overcoming these limitations would require the development of parameter-normalized and task-agnostic evaluation frameworks to enable more comprehensive comparisons."
        },
        {
            "title": "4 Accessibility",
            "content": "The question of how accessible Large Language Models (LLMs) are varies substantially between open-source and closed-source systems in way that inﬂuences their deployment on range of applications. Open-source initiatives such as LLaMA and BLOOM have been instrumental in democratizing LLM technology. LLaMA achieves this by enabling researchers to run advanced NLP tasks on single GPUs [31]. Optimizing for smaller model sizes lowers computational barriers while maintaining high benchmark performance, particularly in reasoning and mathematical tasks, and allows LLaMa to often surpass larger closed-source counterparts like GPT-3 and Chinchilla. Similarly, BLOOM was developed collaboratively by over 1,000 researchers; it supports 46 natural languages and 13 programming languages [32]. Its public release forefronted the potential of open science to expand LLM applications globally and foster inclusion for underrepresented linguistic communities. Techniques like Low-Rank Adaptation (LoRA) further enhance such accessibility by signiﬁcantly reducing computational requirements for ﬁne-tuning. LoRA achieves this by freezing most model parameters and optimizing low-rank adaptation of the model weights, enabling developers to tailor LLMs such as GPT-3 for speciﬁc tasks with consider4 The Open-Source Advantage in Large Language Models (LLMs) ably lower resource demands. This mechanism has proven versatile and found applications in areas such as textual summarization and SQL query generation, which are critical for both academic research and industry use [33]. Additionally, smaller and distilled models, such as DistilBERT, play key role in bridging the gap between cutting-edge NLP capabilities and practical deployment. By reducing the size of BERT by 40% while retaining 97% of its language understanding ability, DistilBERT facilitates real-time, on-device applications [34]. Domain-speciﬁc LLMs have also begun to make solutions tailored for specialized ﬁelds more accessible. ClinicalBERT, ﬁne-tuned on medical datasets, improves performance in tasks such as named entity recognition (NER) and natural language inference (NLI) for healthcare applications [35]. By releasing ClinicalBERT publicly, researchers have ensured that even organizations with limited resources can access advanced NLP tools to enhance clinical decisionmaking and patient care. Likewise, LEGAL-BERT and FinBERT address speciﬁc needs in the legal and ﬁnancial sectors. LEGAL-BERT outperforms general-purpose models in tasks such as contract analysis and case law classiﬁcation [36], while FinBERT excels in sentiment analysis for ﬁnance-related tasks, aiding in market trend predictions and supporting strategic ﬁnancial decisions [37]. These domain-speciﬁc models illustrate the versatility of open-source systems in addressing niche requirements while ensuring accessibility for smaller organizations. Yet, it must be acknowledged that closed-source models like Codex can also expand accessibility within targeted use cases. Integrated into GitHub Copilot, Codex translates natural language inputs into code. This signiﬁcantly lowers the barrier to entry for non-programmers and enhances efﬁciency for experienced developers by 55% [38]. By streamlining the software development process and offering educational tools, Codex exempliﬁes how closed-source models can drive adoption in speciﬁc domains despite their proprietary nature. However, the lack of transparency and limited availability of these models often restrict customization, which are hallmarks of open-source initiatives."
        },
        {
            "title": "5 Transparency",
            "content": "The ethical dimensions of Large Language Models (LLMs) lie at the heart of their societal impact, with transparency emerging as pivotal factor in evaluating their fairness, accountability, and trustworthiness. The contrasting approaches taken by open-source and closed-source LLMs reveal fundamental trade-off between visibility and proprietary control. Open-source models offer unmatched access to internal mechanisms but often lack the governance structures necessary for consistent ethical rigor. Conversely, closed-source models protect intellectual property at the expense of public trust and external accountability. This ongoing debate underscores the challenge of balancing innovation with moral standards in the development and deployment of LLMs. By deﬁnition, open-source LLMs promote transparency by providing unrestricted access to their architectures, weights, and training methodologies [39]. This openness allows researchers and developers to scrutinize these models at granular levels, auditing for biases, testing adherence to fairness metrics, and identifying vulnerabilities within their decisionmaking processes. The communal nature of open-source ecosystems democratizes ethical oversight to certain extent. Platforms like GitHub and Hugging Face not only disseminate open-source models but also provide accompanying documentation, such as model cards, that outline ethical considerations, known limitations, and appropriate usage contexts. As such, distributed networks of researchers and practitioners can collaboratively review and improve these models, often uncovering latent issues such as algorithmic bias, adversarial weaknesses, or dual-use risks [40]. For instance, the open scrutiny of datasets and ﬁne-tuning protocols has led to signiﬁcant advancements in understanding and mitigating biases in multilingual models like BLOOM. Yet, this distributed accountability relies heavily on the quality of available data, and the effectiveness of this transparency is often undermined by inconsistencies in documentation quality. It has been noted that templates are frequently reused, which leads to superﬁcial descriptions of ethical risks and gaps in actionable insights for addressing them. For these reasons, establishing rigorous, standardized frameworks for ethical auditingincluding detailed model cards with metrics for bias auditing, fairness evaluations, potential misuse scenarios presented in standardized schema, and testing of interpretabilityis crucial to fully realize the transparency potential of open-source LLMs. Moreover, tools for automated ethical assessments, such as explainability algorithms and adversarial robustness tests, could supplement human-led audits and provide baseline evaluations that align with broader governance standards. By contrast, closed-source LLMs operate within proprietary frameworks that limit visibility into their internal mechanisms [41]. The lack of access to training datasets, preprocessing pipelines, and decision-making logic restricts third-party audits and independent evaluations to degree that has effectively rendered them black boxes. This opacity exacerbates the difﬁculty of identifying and addressing biases embedded in these systems. For example, when closed-source models produce outputs that reinforce harmful stereotypes, as was the case with Googles Gemini model, it remains unclear whether the issue stems from biased training data, ﬂawed objective functions, or other systemic deﬁciencies [42]. Worse still is the fact that in virtue of the models being closed-source, their developers are not obligated to disclose ethical risks, mitigation strategies, or even the fundamental design principles guiding their 5 The Open-Source Advantage in Large Language Models (LLMs) models. This lack of disclosure creates trust deﬁcit, particularly in high-stakes domains such as healthcare diagnostics, legal decision-making, or autonomous transportation systems like self-driving cars, where the consequences of errors or biases can be profound. Moreover, the absence of external oversight often means that ethical considerations are deprioritized in favor of performance optimization or market demands. For these reasons, regulatory frameworks serve as critical mediators of closed-source LLMs [43]. Governments and industry consortia should establish mandates for transparency in high-risk applications. These could include requirements for disclosing anonymized datasets, publishing high-level explanations of decision-making processes, or engaging external (third-party, independent, unafﬁliated) ethics oversight boards for pre-deployment risk assessments. While such measures may not match the transparency of open-source systems models, they can provide critical visibility into the ethically salient dimensions of proprietary systems without compromising trade secrets. In short, bridging this divide between openand closed-source LLMs will require hybrid solutions that combine the strengths of both paradigms. For instance, closed-source developers could adopt modular transparencyreleasing anonymized components or high-level abstractions of decision-making logic to facilitate third-party evaluations. Simultaneously, open-source ecosystems could leverage advancements in ethical assessment tools to enhance their auditing processes. By integrating these complementary approaches, the ML community can create systems that not only achieve state-of-the-art performance but also uphold principles of fairness, accountability, and trustworthiness. This kind of interdisciplinary collaboration between computer science, ethics, policy, and sociology will be sure to play decisive role in deﬁning the trajectory of ethical LLM development and its alignment with our values."
        },
        {
            "title": "6 Discussion",
            "content": "Our comparative analysis of open-source and closed-source Large Language Models (LLMs) offers critical insights into the differing trajectories of innovation, accessibility, and collaboration in natural language processing (NLP). Both paradigms share foundational technologies, such as Transformer architectures, but their distinct underlying philosophical commitments have led to varied impacts on the ﬁeld. This discussion evaluates both trajectories, clarifying the strengths and limitations of each, while advancing clear and grounded position on the transformative potential of open-source models. Closed-source LLMs continue to lead in performance, leveraging proprietary datasets and signiﬁcant computational investments to excel in tasks requiring advanced generative abilities, multi-step reasoning, and broad generalization. However, their success comes at the cost of limited transparency and restricted accessibility, which creates challenges for external validation and replication. The closed-source approach also consolidates resources and technological power within few institutions. In so doing, it poses barriers to equitable AI development and raising concerns about reproducibility of outcomes and organizational accountability. By contrast, open-source LLMs emphasize accessibility and collaborative development. While these models often trail closed-source systems in absolute performance, they have made signiﬁcant progress in narrowing the gap through methods such as Low-Rank Adaptation (LoRA) and quantization. These strategies enable efﬁcient, competitive outcomes even in resource-constrained environments. By utilizing diverse datasets across languages and contexts, open-source models demonstrate their capacity to address realworld challenges with inclusivity. This democratic ethos has already empowered researchers and developers globally, and is likely to continue to do so. The scalability of closed-source models is evident in their ability to set performance benchmarks, leveraging extensive datasets and robust infrastructure. However, their reliance on proprietary resources limits their adaptability to niche or underrepresented use cases. By contrast, open-source models, though constrained by resource limitations, possess the potential to surpass these benchmarks by leveraging their access to diverse and evolving datasets. Their adaptability allows them to address specialized challenges and emerging contexts, but their success hinges on sustained contributions from the global community. Collaborative efforts are essential to overcoming resource gaps and achieving continuous improvement. Accessibility remains key distinction between the two paradigms. Closed-source systems have improved accessibility within speciﬁc domains through tools like GitHub Copilot, which streamline adoption for non-expert users. However, these tools often lack the ﬂexibility needed for personal customization [44]. Open-source models excel in this regard, offering modular architectures and reduced computational barriers that enable widespread experimentation and deployment. This ﬂexibility supports innovation across academic, industrial, and grassroots initiatives and serves to highlight the potential for integrating the strengths of both approaches to optimize usability and adaptability. Notably, ethical considerations further differentiate these paradigms. The opacity of closed-source models exacerbates deﬁcits in trust, particularly in critical applications such as healthcare and legal decision-making. Their restricted access to internal mechanisms limits external auditing and accountability, which, by extension, raises concerns about The Open-Source Advantage in Large Language Models (LLMs) fairness and safety. In contrast, open-source models prioritize transparency by providing unrestricted access to architectures, datasets, and methodologies. However, inconsistencies in documentation and the absence of standardized ethical frameworks pose challenges for ensuring reliable oversight. hybrid approach that combines the transparency of open-source models with regulatory measures could address these concerns, ensuring more responsible AI deployment. One promising avenue for future research lies in addressing the phenomenon of hallucinations in LLMs, which manifests differently depending on the context. When these models generate incorrect outputs, they are often labeled as mistakes, yet when their outputs are creative and contextually aligned, they are celebrated as innovation [45]. This tension is particularly pronounced in reasoning tasks, where precision and coherence are of paramount importance. Understanding and mitigating hallucinations requires systematic approach to model evaluation, focusing on distinguishing productive creativity from erroneous reasoning. Open-source models can play pivotal role in this research by fostering collaborative experiments with diverse datasets and benchmarking strategies that illuminate the mechanisms underlying hallucinations. Another direction for future work involves enhancing the reasoning capabilities of LLMs through interdisciplinary contributions. By integrating insights from cognitive science and formal logic, researchers can develop frameworks to improve reasoning ﬁdelity and robustness in LLMs. Open-source ecosystems are uniquely positioned to drive progress in this area, offering the transparency and ﬂexibility needed to experiment with novel architectures, training methods, and evaluation protocols. Collaborative efforts could enable the design of more reliable and context-aware reasoning systems, pushing the boundaries of what LLMs can achieve in tasks requiring deep understanding and logical coherence. To be sure, closed-source LLMs currently dominate performance benchmarks due to their resource-intensive strategies, while open-source models offer unparalleled accessibility and the potential for equitable AI advancement. The future of open-source LLMs depends on fostering robust ecosystem of contributors to drive innovation and reﬁnement. By leveraging diverse datasets and emphasizing collaboration, open-source models have the capacity to address global challenges and redeﬁne the NLP landscape in way that is thus far unclear whether closed-source models can."
        },
        {
            "title": "Acknowledgments",
            "content": "This work was supported in part by contributions from the open-source AI community."
        },
        {
            "title": "References",
            "content": "[1] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. Large language models: survey. arXiv preprint arXiv:2402.06196, 2024. [2] Hao Yu, Zachary Yang, Kellin Pelrine, Jean Francois Godbout, and Reihaneh Rabbany. Open, closed, or small language models for text classiﬁcation? arXiv preprint arXiv:2308.10092, 2023. [3] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. survey of large language models. arXiv preprint arXiv:2303.18223, 2023. [4] Hailin Chen, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shaﬁq Joty. Chatgpts one-year anniversary: are open-source large language models catching up? arXiv preprint arXiv:2311.16989, 2023. [5] Meysam Alizadeh, Maël Kubli, Zeynab Samei, Shirin Dehghani, Juan Diego Bermeo, Maria Korobeynikova, and Fabrizio Gilardi. Open-source large language models outperform crowd workers and approach chatgpt in text-annotation tasks. arXiv preprint arXiv:2307.02179, 101, 2023. [6] Frank Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn. systematic evaluation of large In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine language models of code. Programming, pages 110, 2022. [7] Sanjay Kukreja, Tarun Kumar, Amit Purohit, Abhijit Dasgupta, and Debashis Guha. literature survey on open source large language models. In Proceedings of the 2024 7th International Conference on Computers in Management and Business, pages 133143, 2024. [8] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021. [9] Claude Elwood Shannon. mathematical theory of communication. The Bell system technical journal, 27(3):379423, 1948. 7 The Open-Source Advantage in Large Language Models (LLMs) [10] Yoshua Bengio, Réjean Ducharme, and Pascal Vincent. neural probabilistic language model. Advances in neural information processing systems, 13, 2000. [11] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013. [12] Pramita Sree Muhuri, Prosenjit Chatterjee, Xiaohong Yuan, Kaushik Roy, and Albert Esterline. Using long Information, 11(5):243, short-term memory recurrent neural network (lstm-rnn) to classify network attacks. 2020. [13] Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017. [14] Zichong Wang, Zhibo Chu, Thang Viet Doan, Shiwen Ni, Min Yang, and Wenbin Zhang. History, development, and principles of large language models: an introductory survey. AI and Ethics, pages 117, 2024. [15] Will Douglas Heaven. Openais new language generator gpt-3 is shockingly goodand completely mindless. MIT Technology Review, 29:16, 2020. [16] Zhaoyang Niu, Guoqiang Zhong, and Hui Yu. review on the attention mechanism of deep learning. Neurocomputing, 452:4862, 2021. [17] Tendai Mukande, Esraa Ali, Annalina Caputo, Ruihai Dong, and Noel OConnor. ﬂash attention transformer for multi-behaviour recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, pages 42104214, 2023. [18] Fei Du, Xin-Jian Ma, Jing-Ru Yang, Yi Liu, Chao-Ran Luo, Xue-Bin Wang, Hai-Ou Jiang, and Xiang Jing. survey of llm datasets: From autoregressive model to ai chatbot. Journal of Computer Science and Technology, 39(3):542566, 2024. [19] Jacob Devlin. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018. [20] Wenxiong Liao, Zhengliang Liu, Haixing Dai, Zihao Wu, Yiyang Zhang, Xiaoke Huang, Yuzhong Chen, Xi Jiang, David Liu, Dajiang Zhu, et al. Mask-guided bert for few-shot text classiﬁcation. Neurocomputing, 610:128576, 2024. [21] Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, Jérémy Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, et al. Open problems and fundamental limitations of reinforcement learning from human feedback. arXiv preprint arXiv:2307.15217, 2023. [22] Alireza Salemi and Hamed Zamani. Evaluating retrieval quality in retrieval-augmented generation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 23952400, 2024. [23] Satvik Tripathi, Kyle Mongeau, Dana Alkhulaifat, Ameena Elahi, and Tessa Cook. Large language models in health systems: governance, challenges, and solutions. Academic Radiology, 2024. [24] Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, and Yang Liu. Openchat: Advancing opensource language models with mixed-quality data. arXiv preprint arXiv:2309.11235, 2023. [25] Touﬁque Ahmed, Christian Bird, Premkumar Devanbu, and Saikat Chakraborty. Studying llm performance on closed-and open-source data. arXiv preprint arXiv:2402.15100, 2024. [26] Siwei Wu, Zhongyuan Peng, Xinrun Du, Tuney Zheng, Minghao Liu, Jialong Wu, Jiachen Ma, Yizhi Li, Jian Yang, Wangchunshu Zhou, et al. comparative study on reasoning patterns of openais o1 model. arXiv preprint arXiv:2410.13639, 2024. [27] Simone Balloccu, Patrícia Schmidtová, Mateusz Lango, and Ondˇrej Dušek. Leak, cheat, repeat: Data contamination and evaluation malpractices in closed-source llms. arXiv preprint arXiv:2402.03927, 2024. [28] Andreas Liesenfeld, Alianda Lopez, and Mark Dingemanse. Opening up chatgpt: Tracking openness, transparency, and accountability in instruction-tuned text generators. In Proceedings of the 5th international conference on conversational user interfaces, pages 16, 2023. [29] Wenliang Dai, Nayeon Lee, Boxin Wang, Zhuolin Yang, Zihan Liu, Jon Barker, Tuomas Rintamaki, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nvlm: Open frontier-class multimodal llms. arXiv preprint arXiv:2409.11402, 2024. [30] Yu-Wei Hong, Jenq-Shiou Leu, Muhamad Faisal, and Setya Widyawan Prakosa. Analysis of model compression using knowledge distillation. IEEE Access, 10:8509585105, 2022. 8 The Open-Source Advantage in Large Language Models (LLMs) [31] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efﬁcient foundation language models. arXiv preprint arXiv:2302.13971, 2023. [32] BigScience Workshop, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, et al. Bloom: 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100, 2022. [33] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Shaochen Zhong, Bing Yin, and Xia Hu. Harnessing the power of llms in practice: survey on chatgpt and beyond. ACM Transactions on Knowledge Discovery from Data, 18(6):132, 2024. [34] Sanh. Distilbert, distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108, 2019. [35] Emily Alsentzer, John Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, and Matthew McDermott. Publicly available clinical bert embeddings. arXiv preprint arXiv:1904.03323, 2019. [36] Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. Legalbert: The muppets straight out of law school. arXiv preprint arXiv:2010.02559, 2020. [37] Yi Yang, Mark Christopher Siy Uy, and Allen Huang. Finbert: pretrained language model for ﬁnancial communications. arXiv preprint arXiv:2006.08097, 2020. [38] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. [39] Sabrina Sicari, Jesus Cevallos M, Alessandra Rizzardi, and Alberto Coen-Porisini. Open-ethical ai: Advancements in open-source human-centric neural language models. ACM Computing Surveys, 2024. [40] Haoyu Gao, Mansooreh Zahedi, Christoph Treude, Sarita Rosenstock, and Marc Cheong. Documenting ethical considerations in open source ai models. In Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, pages 177188, 2024. [41] Magdalena von Schwerin and Manfred Reichert. systematic comparison between open-and closed-source large language models in the context of generating gdpr-compliant data categories for processing activity records. Future Internet, 16(12):459, 2024. [42] Julia Barroso da Silveira and Ellen Alves Lima. Racial biases in ais and geminis inability to write narratives about black people. Emerging Media, 2(2):277287, 2024. [43] Carson Ezell and Abraham Loeb. Post-deployment regulatory oversight for general-purpose large language models. Available at SSRN 4658623, 2023. [44] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. Once: Boosting content-based recommendation with both open-and closed-source large language models. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining, pages 452461, 2024. [45] Oussama Hamid. Beyond probabilities: Unveiling the delicate dance of large language models (llms) and ai-hallucination. In 2024 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA), pages 8590. IEEE, 2024."
        }
    ],
    "affiliations": [
        "Rollins College, Winter Park"
    ]
}