{
    "paper_title": "An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning",
    "authors": [
        "Andrew Zamai",
        "Nathanael Fijalkow",
        "Boris Mansencal",
        "Laurent Simon",
        "Eloi Navet",
        "Pierrick Coupe"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The differential diagnosis of neurodegenerative dementias is a challenging clinical task, mainly because of the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging. To improve diagnostic efficiency and accuracy, deep learning-based methods such as Convolutional Neural Networks and Vision Transformers have been proposed for the automatic classification of brain MRIs. However, despite their strong predictive performance, these models find limited clinical utility due to their opaque decision making. In this work, we propose a framework that integrates two core components to enhance diagnostic transparency. First, we introduce a modular pipeline for converting 3D T1-weighted brain MRIs into textual radiology reports. Second, we explore the potential of modern Large Language Models (LLMs) to assist clinicians in the differential diagnosis between Frontotemporal dementia subtypes, Alzheimer's disease, and normal aging based on the generated reports. To bridge the gap between predictive accuracy and explainability, we employ reinforcement learning to incentivize diagnostic reasoning in LLMs. Without requiring supervised reasoning traces or distillation from larger models, our approach enables the emergence of structured diagnostic rationales grounded in neuroimaging findings. Unlike post-hoc explainability methods that retrospectively justify model decisions, our framework generates diagnostic rationales as part of the inference process-producing causally grounded explanations that inform and guide the model's decision-making process. In doing so, our framework matches the diagnostic performance of existing deep learning methods while offering rationales that support its diagnostic conclusions."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 2 ] . [ 1 4 5 9 9 1 . 5 0 5 2 : r An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning Andrew Zamai1 Nathanaël Fijalkow1 Boris Mansencal1 Laurent Simon1 Eloi Navet1 Pierrick Coupé1 1Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France"
        },
        {
            "title": "Abstract",
            "content": "The differential diagnosis of neurodegenerative dementias is challenging clinical task, mainly because of the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging. To improve diagnostic efficiency and accuracy, deep learningbased methods such as Convolutional Neural Networks and Vision Transformers have been proposed for the automatic classification of brain MRIs. However, despite their strong predictive performance, these models find limited clinical utility due to their opaque decision making. In this work, we propose framework that integrates two core components to enhance diagnostic transparency. First, we introduce modular pipeline for converting 3D T1-weighted brain MRIs into textual radiology reports. Second, we explore the potential of modern Large Language Models (LLMs) to assist clinicians in the differential diagnosis between Frontotemporal dementia subtypes, Alzheimers disease, and normal aging based on the generated reports. To bridge the gap between predictive accuracy and explainability, we employ reinforcement learning to incentivize diagnostic reasoning in LLMs. Without requiring supervised reasoning traces or distillation from larger models, our approach enables the emergence of structured diagnostic rationales grounded in neuroimaging findings. Unlike post-hoc explainability methods that retrospectively justify model decisions, our framework generates diagnostic rationales as part of the inference processproducing causally grounded explanations that inform and guide the models decision-making process. In doing so, our framework matches the diagnostic performance of existing deep learning methods while offering rationales that support its diagnostic conclusions."
        },
        {
            "title": "Introduction",
            "content": "Neurodegenerative dementias denote group of disorders characterized by progressive loss of neuronal structure and function, resulting in cognitive, motor, and behavioral impairments [1]. These conditions typically develop insidiously and worsen over time [2]. Early and accurate diagnosis is therefore critical to slow disease progression and improve patients quality of life. However, the differential diagnosis of neurodegenerative dementiasparticularly between Alzheimers disease (AD), subtypes of Frontotemporal Dementia (FTD), and cognitively normal aging (CN)remains an open clinical challenge, due to the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging [3, 4]. In this work, following [5], we focus on structural Magnetic Resonance Imaging (MRI) due to its widespread availability, non-invasive nature, and ability to detect region-specific patterns of cerebral atrophy that are indicative of neurodegeneration. Correspondence to andrew.zamai@u-bordeaux.fr Preprint. Under review. Existing deep learning approaches, employing either Convolutional Neural Networks (CNNs) [68] or Vision Transformers (ViTs) [9, 10], have demonstrated strong performance distinguishing between AD, FTD, and healthy controls from 3D MRI scans. However, despite advances in diagnostic performance, significant limitation lies in their limited interpretabilitythe ability to understand the internal mechanics of the modeland their insufficient explainability, that is the capacity to provide human-understandable justifications, or rationales, that clarify why specific prediction was made. Post-hoc explainability methods have been applied to medical imaging [1113]. However, such tools often only indicate where the model focused, not why it reached particular diagnosis. Methods like [12, 13] generate visual heatmaps over MRI scans to indicate which regions influenced the models prediction, but they lack semantic attributionthey neither explicitly identify the anatomical regions (e.g., \"the hippocampus\") nor explain their clinical relevance (e.g., how hippocampal atrophy is indicative of Alzheimers disease). Furthermore, these methods operate post hoc and play no role in the models decision-making process, thereby failing to provide causally grounded justifications. Figure 1: Overview of the proposed framework for the automated differential diagnosis of neurodegenerative dementias. 3D T1-weighted brain MRIs are converted into radiology reports and used to prompt an LLM for detailed diagnostic reasoning and final ranked list of candidate diagnoses. Our aim in this work is to leverage reasoning-capable Large Language Models (LLMs) to generate rationales that inform and support the diagnostic process, directly addressing key limitations of prior methods. We present the first comprehensive framework for detailed diagnostic reasoning based on neuroimaging evidence in the differential diagnosis of neurodegenerative dementias2. While visionto-text models in the medical domain exist [14], they typically require massive datasets for training and often fail to capture the fine-grained anatomical details critical for neurological differential diagnosis. To address this, we introduce framework that integrates high-resolution segmentation and statistical analysis with the text-based reasoning strengths of LLMs, as illustrated in Figure 1. Synthetic radiology report generation from neuroimaging. To enable diagnostic reasoning grounded in neuroimaging evidence, we develop modular pipeline that transforms T1-weighted 3D MRI scans into textual radiology reports. These reports capture clinically relevant features such as spatial atrophy patterns and anatomical asymmetries, expressed in semantically meaningful terms (e.g., hippocampal atrophy). Unlike end-to-end deep learning solutions [1517], our approach allows each intermediate output to be verified and adjusted for clinical fidelity. We then employ prompting strategy that guides LLMs to perform differential diagnosis based on these synthetic reports. Reinforcement learningoptimized reasoning. To address the lack of training data, we apply Group Relative Policy Optimization (GRPO), reinforcement learning paradigm recently introduced by DeepSeek [18, 19], to fine-tune lightweight open-source LLMs, optimizing them to generate diagnostic rationales based on image findings. In the absence of labeled reasoning traces for supervised training, GRPO enables emergent reasoning capabilities without relying on explicit supervision. Our experiments first evaluate the zero-shot diagnostic capabilities of existing LLMs, providing not only comparative benchmark of their performance, but also intrinsic validation of our synthetic report generation pipeline. Their zero-shot performance suggests that the generated reports effectively capture clinically relevant information and align with the distributional characteristics of real-world radiology reports likely encountered during pretraining. Building on this, we apply GRPO-based fine-tuning to lightweight 8B-scale models, enabling them to not only match but often surpass the diagnostic accuracy of much larger models like GPT-4o. Beyond improved diagnostic accuracy, fine-tuned models exhibit detailed and nuanced reasoning grounded in neuroanatomical evidence. 2The framework will be available soon at https://www.volbrain.net/. 2 Their outputs demonstrate sophisticated behaviors such as hypothesis testing, iterative refinement, and ranked differential diagnoses. Finally, compared to conventional classification-only deep learning solutions, our LLM-based framework achieves competitive diagnostic accuracy while providing transparent, causally grounded rationales that inform and support its diagnostic conclusions."
        },
        {
            "title": "2 Related work",
            "content": "Neuroimaging-based Diagnosis and Post-hoc Explainability Limitations. Deep learning modelsparticularly CNNs [68] and, more recently, ViTs [9, 10]have achieved strong performance in structural MRI-based diagnosis. However, these studies primarily focus on distinguishing cognitively normal individuals, AD, and FTD, without explicitly addressing the more challenging task of differentiating between FTD subtypes. Post-hoc explainability techniques have been utilized in medical imaging [1113], but these methods have inherent limitations in this specific context [20]. These visualizations typically highlight where the model focused, without providing insight into why particular diagnosis was made. This is particularly problematic in disorders with overlapping atrophy patterns, where accurate diagnosis depends not just on the presence of atrophy, but on its severity, distribution, and clinical relevance. LLMs in medicine. LLMs have proven effective in encoding medical knowledge [21] and supporting various clinical tasks, including medical question answering [22], discharging summaries generation [23, 24], electronic health record (EHR) analysis [25], and text-based differential diagnosis [26]. Domain-adapted models fine-tuned on biomedical corporasuch as PMC-LLaMA, MedAlpaca, BioBERT, and BioGPT [2730]along with multimodal architectures (e.g., Med-Flamingo, LLaVA-Med, Gemini)[3134], are increasingly capable of assisting clinical decision-making tasks. LLMs have shown promise in clinical reasoning and explainability. For instance, Savage et al. [35] recently demonstrated that GPT-4 can be prompted to produce structured, step-by-step diagnostic reasoning. This approach, along with [36, 37], offers physicians way to assess the plausibility and trustworthiness of LLM-generated predictions. Recent work by DeepSeek [18] introduced Group Relative Policy Optimization (GRPO), reinforcement learning method that has powered new family of LLMs with emergent reasoning capabilities. GRPO shapes the reward signal without relying on labeled preference data or supervised reasoning traces, estimating group-wise relative advantage across candidate responses, enabling reasoning behaviors to emerge from diverse prompt-response examples alone. This recent work opens the path to the development of reasoning-powered models in medical domain [38]. To our knowledge, no prior work has used GRPO to optimize LLMs for generating diagnostic rationales from radiological reports, especially in the context of differential diagnosis of neurodegenerative dementias."
        },
        {
            "title": "3 Approach",
            "content": "Figure 1 illustrates the overall architecture of our automated diagnostic framework. The pipeline begins with the processing of 3D T1-weighted brain MRI using AssemblyNet [39], which generates detailed anatomical segmentations organized into quantitative volumetric report. This data is then translated into qualitative radiology report, which serves as input for the LLM. In this section, we first describe the process of generating these synthetic radiology reports. We then detail the prompting strategy employed to guide the LLM in interpreting these reports effectively. Finally, we describe the training procedure, with particular focus on the strategies employed to encourage nuanced and detailed rationale generation through reinforcement-optimized reasoning."
        },
        {
            "title": "3.1 From Brain MRI to Text: A Modular Pipeline for Synthetic Report Generation",
            "content": "We propose modular pipeline capable of converting 3D T1-weighted brain MRI into textual radiology report through series of interpretable intermediate steps. Unlike end-to-end visionto-text models [1517], our approach preserves the clinical detail essential for the diagnosis of neurodegenerative diseases and offers transparency into each intermediate output. The pipeline consists of four main stages: (1) fine-grained brain segmentation, (2) volume ratio computation of each anatomical structure, (3) atrophy estimation via normative modeling, and (4) textual report generation. We describe each step in detail below. 3 (1) MRI segmentation. Fine-grained whole-brain segmentation is obtained using AssemblyNet [39], state-of-the-art deep learning framework designed for high-resolution brain segmentation, employing multiscale ensemble of 3D U-Net models. Two assemblies operating at different spatial resolutions enable the model to progressively refine anatomical boundaries and capture detailed structural information. The final output is detailed segmentation map that includes over 132 brain structures, with specific identification of bilateral elements and detailed left/right segmentation, and particular focus on cortical, subcortical, and lobar areaskey regions for the diagnosis of neurodegenerative diseases. (2) Volume ratio computation. Volume ratios are computed by first measuring the absolute volume of each anatomical region based on the voxel-wise segmentation output; each regional volume is then normalized by the subjects total intracranial volume (ICV) to produce relative volume ratio. This normalization facilitates the comparison of brain structure sizes between subjects with different brain volumes, accounting for inter-subject variability in brain size. (3) Atrophy Estimation via Normative Modeling. To assess the clinical relevance of volumetric changes in brain structures, our pipeline estimates structural atrophy by comparing an individuals measured brain volume ratios to normative models that account for age and sex differences. These normative trajectories are derived from the lifespan analysis conducted in [40], which provides robust, data-driven volumetric reference curves based on 2,944 high-quality T1-weighted MRI scans from healthy individuals aged 9 months to 94 years. As depicted in Figure 2, for each brain structure, we compute its Structural Deviation Score (SDS) as rsubjectµnorm(a,s) , where rsubject is the subjects measured volume ratio, µnorm(a, s) is the expected normative volume ratio for the subjects age and sex s, and σnorm(a, s) is the corresponding standard deviation from the normative distributions 95% confidence interval. This computation provides measure of how many standard deviations the subjects volume ratio deviates from the expected value, where negative SDS indicate smaller-thanexpected volumes (atrophy) and positive SDS suggest larger-than-expected volumes (enlargements). As suggested on the right of Figure 2, the magnitude of the score is key for categorizing the severity of these deviations, as it helps distinguish between neurodegenerative diseases with overlapping affected structures. σnorm(a,s) (4) Radiology Report generation. The conversion from quantitative volumetric measures to clinically interpretable qualitative descriptions represents critical component of our pipeline. While the above SDS score provides standardized measurements of deviation from normative reference trajectories, clinicians typically rely on categorical severity assessmentssuch as mild, moderate, or severe atrophy. Our pipelines final stage translates these SDS scores into descriptive report using mapping consisting of seven-point severity scale ranging from normal to severe, with intermediate gradations (e.g. normal-to-mild). As illustrated on the left of Figure 3, the severity thresholds can be visualized on Gaussian distribution representing the normative population data, with vertical demarcation lines indicating the boundaries between severity categories. The central region of the curve represents volumes within normal limits, while progressively leftward regions correspond to increasing degrees of atrophy severity. Conversely, the right tail of the distribution represents structural enlargement or hypertrophy, which may be particularly relevant for ventricular assessment. This mapping provides an intuitive severity assessments while preserving some of the granularity Figure 2: Atrophy estimation via normative modeling. Left: Lifespan curve of left hippocampal volume ratio with normative mean µnorm(a, s) (black) and confidence bounds σnorm(a, s) (blue/red). Right: SDS distributions across diagnostic groups, reflecting condition-specific structural deviations. 4 necessary for differential diagnosis of neurodegenerative conditions with overlapping atrophy patterns. Thresholds were chosen based on the statistical meaning of SDS magnitudes, rather than tuning to specific dataset distributions, to prevent overfitting and maintain interpretability. Preliminary zero-shot tests with existing LLMs showed promising results, supporting our decision to retain general-purpose, interpretable thresholds. The radiology report itself is hierarchically structured, grouping findings by anatomical domain (cortical, subcortical, ventricular). Within each group, regions are sorted by severity, and cortical findings are further differentiated between diffuse lobar atrophy and focal subregional lossesimportant cues for differential diagnosis. For bilateral structures, we assess both overall and asymmetric volume changes, explicitly noting hemisphere-specific atrophy when present, which is especially relevant for syndromes with lateralized presentations. By standardizing atrophy descriptions across brain regions using consistent severity terminology, the system enhances clinical communication and supports diagnostic reasoning. In Appendix A, we provide full synthetic report alongside comparison with human-generated one. Figure 3: Mapping structural deviation to qualitative severity. Left: Quantitative-to-qualitative conversion of Structural Deviation Scores (SDS) using seven-point severity scale ranging from severe atrophy to severe enlargement. Right: Example of (truncated) generated radiology report summarizing anatomical findings by region and hemisphere, using standardized severity descriptors."
        },
        {
            "title": "3.2 Prompting strategy",
            "content": "Figure 4 illustrates the adopted prompting strategy, designed to elicit an open-ended and thorough diagnostic reasoning based on the neuroimaging findings. The model is instructed to act as neurologist with expertise in neurodegenerative diseases, tasked with interpreting T1-weighted MRI radiology reports. To encourage deeper engagement with the imaging features, the prompt explicitly requires the model to think exhaustively within <think> tags before committing to final diagnosis. This intermediate reasoning step encourages detailed examination of regional atrophy patterns, asymmetries, and structural deviations described in the report. Finally, the output is structured as ranked list of differential diagnoses. This format reflects the clinical reasoning process where multiple possibilities are considered and prioritized based on their fit to the observed data. To enhance diagnostic stability and consensus at inference, we employ dual-sampling strategy. First, multiple linguistically varied radiology reports are generated for each brain MRI using sentence templates. Second, the model produces multiple diagnostic predictions for each report via nondeterministic sampling. This approach captures wider range of interpretations, reducing sensitivity to report phrasing and mitigating LLM inference stochasticity. Final diagnoses are determined by majority vote on the top-ranked differential diagnosis from all aggregated samples, with supporting reasoning randomly selected from those aligning with the consensus. 3."
        },
        {
            "title": "Incentivizing diagnostic reasoning with GRPO",
            "content": "In the absence of labeled reasoning traces for supervised training (SFT), GRPO [19, 18] has been shown to foster emergent reasoning capabilities without relying on explicit supervision or distillation from larger teacher models. Chosen an LLM as our policy model πθ, where θ represents its trainable parameters, and training dataset consisting of tuples (r, d), each comprising properly converted MRI radiology report and gold diagnosis d. Each report is formatted into prompting query q, using the template in Figure 4. The goal of GRPO is to optimize πθ such that the generated outputs exhibit human-understandable reasoning that end with diagnostically accurate prediction. To do so, at each training iteration, for query we let the model generate group of candidate outputs 5 Figure 4: Prompt used to elicit open-ended diagnostic reasoning from MRI reports, ending in ranked list of differential diagnoses. {oi}G i=1 from the current policy πθold, i.e., the model parameters before the update. Each output oi contains (1) diagnostic reasoning trace enclosed between <think>...</think> tags, and (2) ranked differential diagnosis list in JSON format enclosed in triple backticks json ... . For each output oi, GRPO computes scalar reward ri using task-specific reward function (detailed below). It then calculates the group-relative advantage Ai for each output as follows: Ai = ri µ σ , where µ = mean({r1, r2, . . . , rG}), σ = std({r1, r2, . . . , rG}). Completions with above-average rewards receive amplified policy gradient updates, thereby reinforcing desirable behaviors such as coherent diagnostic reasoning and accurate differential ranking. The model πθ is updated by maximizing JGRPO, as further detailed in the original work by DeepSeek [18]. We design our task-specific reward function to consist of two terms, format and accuracy reward. Format reward. Each completion is scored on 1.0-point scale, composed of four equally weighted components (0.25 points each): (1) the presence of <think>...</think> reasoning block followed immediately by JSON output ensures proper structural delimitation; (2) single well-formed JSON block enclosed in triple backticks guarantees parseability; (3) the ability to extract the top-ranked diagnosis from the JSON confirms correct output formatting; and (4) the inclusion of all expected diagnostic categories, matched via regular expressions, checks for class coverage and no other diseases considered. If multiple diagnoses are assigned the top rank, the total reward is capped at 0.25 to penalize ambiguity. Accuracy reward. We assign binary reward by comparing the models top-ranked diagnosis to the ground truth. The predicted diagnosis is extracted from the JSON output, mapped to class ID using regex-based scheme, and compared against the gold label. reward of 1.0 is given for correct match, and 0.0 otherwise, incentivizing clinically accurate predictions."
        },
        {
            "title": "4 Experiments",
            "content": "Our experiments aim to assess: (1) the zero-shot diagnostic performance of existing LLMs in interpreting our synthetic reportsand, conversely, how well these reports align with their pretrained knowledge and typical report distributions; (2) the impact of GRPO fine-tuning on the emergence of diagnostic reasoning; and (3) how our framework compares to established deep learning classifiers trained directly on brain MRI data."
        },
        {
            "title": "4.1 Experimental setup",
            "content": "Datasets. Table 1 summarizes the diagnostic distribution across training, validation, and test sets for all 615 participants included in this study. The data were aggregated from two major sources: the Alzheimers Disease Neuroimaging Initiative (ADNI) [41] and the Neuroimaging Initiative for Frontotemporal Lobar Degeneration (NIFD)3. Cases from NIFD included behavioral variant frontotemporal dementia (bvFTD), non-fluent variant primary progressive aphasia (nfvPPA), and semantic variant primary progressive aphasia (svPPA). Alzheimers disease (AD) cases were drawn from ADNI, and cognitively normal (CN) controls from both datasets. Differentiating between FTD subtypes using only structural neuroimaging is challenging, due to the heterogeneity in atrophy patterns within each subtype, the potential for overlapping regions of neurodegeneration across subtypes (e.g., anterior temporal involvement in both svPPA and some bvFTD, or fronto-insular atrophy in both nfvPPA and some bvFTD), particularly in early stages, and the tendency for atrophy to become more widespread with disease progression, further obscuring initial distinctions. Limited samplesparticularly for nfvPPA and svPPAexacerbate these challenges for robust model training and evaluation. To mitigate this, we applied stratified splitting to preserve class distributions and deliberately allocated more data to the test setat the expense of training set sizein order to retain sufficient samples for reliable evaluation. Table 1: Diagnostic distribution across splits for all 615 participants included in this study."
        },
        {
            "title": "Train\nValidation\nTest",
            "content": "160 62 94 75 30 44 38 14 22 20 8 12 17 8 11 310 122 Models and training details. We evaluate diverse set of LLMs encompassing range of model families, parameter scales, and reasoning capabilities. Specifically, we consider the GPT-4o model [42], renowned for its strong general-purpose performance, as well ranked highly on the Open Medical LLM Leaderboard 4. From the top of this leaderboard, we also include Llama3OpenBioLLM-70B [43], domain-specialized model based on the LLaMA-3 70B architecture and fine-tuned for medical tasks. In addition to these, we assess several open-source generalist models across different model families. From the LLaMA family, we include Llama-3.3-Instruct models at 70B and 8B parameter scales [44]. From the Qwen family, we evaluate Qwen-2.5-Instruct-7B [45] and the recent natively reasoner Qwen-3-8B [46]. Finally, we evaluate reasoning-augmented models trained via GRPO as introduced by DeepSeek [18]. Specifically, we consider two distilled variants of these reasoner models aligned to the LLaMA architecture, with parameter sizes of 70B and 8B. Resource constraints limited our fine-tuning efforts to the smaller 8B variants. Notably, GRPO training is computationally intensive; our setup utilized four NVIDIA H100 80GB GPUs, allocating three for training and one for completions generation using the vLLM framework [47]. To enable efficient fine-tuning, we employed Low-Rank Adaptation (LoRA) [48], using rank = 16 and scaling factor α = 32, targeting the query, key, and value projection weights in the attention layers. Specific to GRPO training, we followed established configurations from [49] and [18]. We set the maximum generation length to 3000 tokens and generated = 6 completions per query, with sampling temperature of 0.9 to encourage exploration. In accordance with [49], we adopted maxcompletion-length averaging scheme for the loss computation, mitigating the bias on completions length. However, contrary to their recommendation, we retained deviation scaling in the advantage estimation, as removing it consistently degraded training performance in our setting. To ensure stable updates and accommodate diverse query set across multiple classes, we used gradient accumulation step size of 64 and conservative learning rate of 5 105, preventing abrupt shifts in model behavior. Finally, we preserved the default GRPO ϵ parameter at 0.2, as in [18], but found that lowering β to 0.005 was crucial. Setting β = 0 caused the model to produce incoherent outputs and deviate from its pre-trained domain knowledge, whereas larger values excessively suppressed the advantage estimation term, limiting effective learning. 3Available at https://ida.loni.usc.edu/ 4https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard"
        },
        {
            "title": "4.2 Results",
            "content": "Off-the-shelf LLMs. Table 2 presents the zero-shot diagnostic performance of the models selected in Subsection 4.1. Using the inference prompting strategy outlined in Subsection 3.2, we generate 3 synthetic reports per brain MRI, each followed by 3 independent diagnostic predictions, yielding total of 9 candidate outputs per case. The final diagnosis is obtained via majority voting, promoting more stable and consensus-driven decision. In terms of M-F1, GPT-4o demonstrates the strongest overall zero-shot performance, confirming to be top-tier generalist model. Among the open-source 70B models, the DeepSeek-R1-Distill-Llama achieves the best results, highlighting the effectiveness of GRPO-style reasoning also for clinical tasks. Notably, Llama3-OpenBioLLM, despite being domain-specialized, performs worse than its base model, likely due to fine-tuning on radiology reports predominantly associated with pathological cases, introducing bias toward dementia prediction. Among the 8B models, DeepSeek-R1-Distill-Llama and LLaMA-3.1-Instruct demonstrate strong zero-shot performance, even surpassing some 70B models, while their 3B variants, lacking sufficient pre-trained domain knowledge at that scale, were excluded for poor performance. These results not only provide comparative benchmark of the diagnostic capabilities of each model, but also offer an intrinsic validation of the proposed synthetic report generation pipeline, indicating that the generated reports effectively capture clinically relevant information and exhibit distributional characteristics consistent with real-world radiology reports likely encountered during pre-training. Table 2: Diagnostic performance of off-the-shelf LLMs and GRPO fine-tuned 8B variants. Models marked with are reasoning models or distilled from them. Model Params class-wise F1 BACC M-F CN AD bvFTD nfvPPA svPPA gpt-4o Llama-3.3-Instruct Llama3-OpenBioLLM DeepSeek-R1-Distill-Llama DeepSeek-R1-Distill-Llama LlaMA-3.1-Instruct Qwen-2.5-Instruct Qwen-3 DeepSeek-R1-Distill-Llama GRPO LlaMA-3.1-Instruct GRPO Qwen-2.5-Instruct GRPO Qwen-3 GRPO Zero-shot 70.81 51.76 59.57 43.55 64.38 72.05 64.94 47.24 60. 43.37 44.44 59.93 53.19 31.75 47.41 54.95 51.52 44.71 44.74 48.19 38.46 54.05 36.84 39.13 19. 0.00 0.00 0.00 11.76 15.38 0.00 19.05 Our GRPO fine-tuned models 84.16 85.86 78.36 83.33 51.43 53.33 49.44 46.88 70.59 73.17 58.06 66. 11.76 41.67 0.00 48.00 - 70B 70B 70B 8B 8B 7B 8B 8B 8B 7B 8B 48. 42.11 36.36 31.25 25.00 36.73 0.00 10.00 80.00 71.43 42.42 64.52 55.46 48.94 49.38 48.18 42.64 53.06 33.66 42. 62.48 67.33 52.89 68.38 48.32 37.95 33.82 39.55 40.09 40.57 26.23 36.74 59.55 65.09 45.66 61.88 GRPO Fine-Tuned LLMs. We extend Table 2 by reporting the diagnostic performance of the 8B models fine-tuned via GRPO, as detailed in Subsection 4.1. Remarkably, without any supervised reasoning traces or distillation from larger models, GRPO enables the emergence of detailed, evidencebased diagnostic reasoning that contributes to improved diagnostic accuracy. Due to the length of the generated outputs, in Figure 5 we present only excerpts from the DeepSeek-R1-Distill-Llama-8B model. Qualitative analysis of these outputs reveals several key reasoning behaviors. First, the models engage in explicit hypothesis testing, systematically evaluating each candidate diagnosis by weighing supporting and opposing imaging features. This promotes balanced consideration across differential diagnoses rather than premature commitment. Second, the models demonstrate non-linear reasoning, often revisiting and refining earlier conclusions as additional evidence is considered. Third, responses typically conclude with ranked list of differential diagnoses, reflecting varying degrees of confidence rather than single-label decision. The rationales exhibit high degree of anatomical specificity, referencing expected neuroanatomical atrophies and capturing distribution patterns that reflect known disease profiles, including severity and asymmetry. Finally, we observe that output length and detail correlate with case complexity. For straightforward cases (e.g., cognitively normal scans or reports with hallmark disease features), the model produces concise justifications. In contrast, challenging cases elicit significantly longer and more elaborate reasoningsometimes up to three times longer. Further insights into training dynamics and full diagnostic reasoning examples are provided in Appendix and Appendix C, respectively. 8 Figure 5: Excerpts from the DeepSeek-R1-Distill-Llama-8B-GRPO model. The responses exhibit properties such as evidence-based hypothesis testing, non-linear reasoning, and detailed understanding of expected anatomical regions and atrophy severity. Comparison with classification-only approaches. We compare our LLM-based diagnostic framework with existing deep-learning classification methods training directly on brain MRIs. Nguyen et al. [10] demonstrated that 3D transformer-based models achieve strong predictive performance, outperforming previous approaches [50, 6]. While these prior works focus on distinguishing between AD, FTD, and CN cases, we extended Nguyen et al.s framework to include FTD subtypes. In line with their setup, we also evaluate Support Vector Machine (SVM) classifier trained on the Structural Deviation Scores computed as detailed in Subsection 3.1. Further implementation and training details are provided in Appendix D. Table 3 presents the diagnostic performance of the ViT and SVM classifiers, compared with our best-performing zero-shot LLM and best GRPO fine-tuned variants. While GradCAM-based post hoc visualizations in [10] offer some interpretability by highlighting image regions that influence model predictions, they lack semantic attribution and clinical contextualization. In contrast, our LLM-based framework achieves comparable diagnostic performance while producing transparent, human-readable rationales that explicitly reference neuroanatomical structures and articulate their relevance to the differential diagnosis. Table 3: Diagnostic performance comparison between our LLM-based framework and existing classification-only deep learning approaches. Model Params class-wise F1 BACC M-F1 CN AD bvFTD nfvPPA svPPA"
        },
        {
            "title": "Classification only",
            "content": "3D-Vision Transformer SVM atrophies 64M - 88.44 86.43 72.50 69.66 62.50 73.91 12.50 0. 78.26 84.21 63.57 62.39 62.84 62."
        },
        {
            "title": "LLMs providing diagnostic reasoning",
            "content": "gpt-4o DeepSeek-R1-Distill-Llama GRPO LLaMA-3.1-Instruct GRPO Qwen-3 GRPO - 8B 8B 8B 70.81 84.16 85.86 83.33 51.76 51.43 53.33 46.88 51.52 70.59 73.17 66.67 19.05 11.76 41.67 48. 48.48 80.00 71.43 64.52 55.46 62.48 67.33 68.38 48.32 59.55 65.09 61."
        },
        {
            "title": "5 Conclusions",
            "content": "We introduced modular framework for the differential diagnosis of neurodegenerative dementias that combines high-resolution MRI analysis, synthetic radiology reporting, and LLM-based reasoning. By shifting from post hoc explanations to inference-time diagnostic reasoning, our method provides anatomically grounded rationales, offering physicians way to access the plausibility and trustworthiness of LLM-generated predictions. Fine-tuning lightweight LLMs via reinforcement learning with Group Relative Policy Optimization (GRPO), we demonstrate that coherent diagnostic reasoning can be achieved without requiring supervised reasoning traces. This work demonstrates the promise of using reasoning models in clinical contextsparticularly for complex, multi-hypothesis tasks such as differential diagnosis. We take an important first step in this direction, opening avenues for future systems that combine data-driven prediction with structured and transparent reasoning."
        },
        {
            "title": "Acknowledgments",
            "content": "This work benefited from the support of the project HoliBrain funded by the French National Research Agency (ANR-23-CE45-0020-01) and the prematuration project ChatvolBrain funded by the CNRS. Moreover, this project is supported by the Precision and global vascular brain health institute funded by the France 2030 investment plan as part of the IHU3 initiative (ANR-23-IAHU0001). Finally, this study received financial support from the French government in the framework of the University of Bordeauxs France 2030 program / RRI \"IMPACT and the PEPR StratifyAging. This work was also granted access to the HPC resources of IDRIS under the allocation 2022-AD011013848R1 made by GENCI."
        },
        {
            "title": "References",
            "content": "[1] Richard N. L. Lamptey, Bivek Chaulagain, Riddhi Trivedi, Avinash Gothwal, Buddhadev Layek, and Jagdish Singh. review of the common neurodegenerative disorders: Current therapeutic approaches and the potential role of nanotherapeutics. International Journal of Molecular Sciences, 23(3):1851, 2022. doi: 10.3390/ijms23031851. URL https://www.ncbi.nlm.nih. gov/pmc/articles/PMC8837071/. [2] M. Crous-Bou, C. Minguillón, N. Gramunt, et al. Alzheimers disease prevention: from risk factors to early intervention. Alzheimers Research & Therapy, 9(1):71, 2017. doi: 10.1186/s13195-017-0297-z. URL https://doi.org/10.1186/s13195-017-0297-z. [3] Celtia Domínguez-Fernández, June Egiguren-Ortiz, Jone Razquin, Margarita Gómez-Galán, Laura De las Heras-García, Elena Paredes-Rodríguez, Egoitz Astigarraga, Cristina Miguélez, and Gabriel Barreda-Gómez. Review of technological challenges in personalised medicine and early diagnosis of neurodegenerative disorders. International Journal of Molecular Sciences, 24(4), 2023. ISSN 1422-0067. doi: 10.3390/ijms24043321. URL https://www.mdpi.com/ 1422-0067/24/4/3321. [4] Leonidas Chouliaras and John T. OBrien. The use of neuroimaging techniques in the early and differential diagnosis of dementia. Molecular Psychiatry, 28(10):40844097, October 2023. ISSN 1476-5578. doi: 10.1038/s41380-023-02215-8. [5] Lorna Harper, Frederik Barkhof, Philip Scheltens, Jonathan Schott, and Nick Fox. An algorithmic approach to structural imaging in dementia. Journal of Neurology, Neurosurgery & Psychiatry, 85(6):692698, 2014. ISSN 0022-3050. doi: 10.1136/jnnp-2013-306285. URL https://jnnp.bmj.com/content/85/6/692. [6] Jingjing Hu, Qing Zhao, Renyuan Liu, Xin Zhang, Pin Lv, Maoxue Wang, Yang Wang, Kelei He, Yang Gao, and Bing Zhang. Deep learning-based classification and voxel-based visualization of frontotemporal dementia and alzheimers disease. Frontiers in Neuroscience, 14:626154, 2021. doi: 10.3389/fnins.2020.626154. [7] Da Ma, Donghuan Lu, Karteek Popuri, Lei Wang, and Mirza Faisal Beg. Differential diagnosis of frontotemporal dementia, alzheimers disease, and normal aging using multi-scale multitype feature generative adversarial deep neural network on structural magnetic resonance images. Frontiers in Neuroscience, 14:853, 2020. doi: 10.3389/fnins.2020.00853. [8] Huy-Dung Nguyen, Michaël Clément, Vincent Planche, Boris Mansencal, and Pierrick Coupé. Deep grading for mri-based differential diagnosis of alzheimers disease and frontotemporal dementia. Artificial Intelligence in Medicine, 140:102636, 2023. doi: 10.1016/j.artmed.2023. 102636. [9] Yitong Li, Morteza Ghahremani, Youssef Wally, and Christian Wachinger. DiaMond: Dementia diagnosis with multi-modal vision transformers using MRI and PET, October 2024. [10] Huy-Dung Nguyen, Michaël Clément, Boris Mansencal, and Pierrick Coupé. 3d transformer based on deformable patch location for differential diagnosis between alzheimers disease and frontotemporal dementia. In 14th International Workshop on Machine Learning in Medical Imaging (MLMI), Held in Conjunction with MICCAI 2023, pages 5363, Vancouver, Canada, October 2023. Springer. doi: 10.1007/978-3-031-45676-3_6. URL https://hal.science/ hal-04201135. [11] Ramprasaath R. Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, and Dhruv Batra. Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization. CoRR, abs/1610.02391, 2016. URL http://arxiv. org/abs/1610.02391. [12] Huy-Dung Nguyen, Michaël Clément, Boris Mansencal, and Pierrick Coupé. Interpretable differential diagnosis for alzheimers disease and frontotemporal dementia. In Linwei Wang, Qi Dou, P. Thomas Fletcher, Stefanie Speidel, and Shuo Li, editors, Medical Image Computing and Computer Assisted Intervention MICCAI 2022, pages 5565, Cham, 2022. Springer Nature Switzerland. ISBN 978-3-031-16431-6. [13] Huy-Dung Nguyen, Michaël Clément, Vincent Planche, Boris Mansencal, and Pierrick Coupé. Deep grading for MRI-based differential diagnosis of Alzheimers disease and Frontotemporal dementia. Artificial Intelligence in Medicine, 144:102636, October 2023. ISSN 1873-2860. doi: 10.1016/j.artmed.2023.102636. [14] Iryna Hartsock and Ghulam Rasool. Vision-language models for medical report generation and visual question answering: review. Frontiers in Artificial Intelligence, Volume 7 - 2024, 2024. ISSN 2624-8212. doi: 10.3389/frai.2024.1430984. URL https://www.frontiersin.org/ journals/artificial-intelligence/articles/10.3389/frai.2024.1430984. [15] Ibrahim Ethem Hamamci, Sezgin Er, and Bjoern Menze. Ct2rep: Automated radiology report generation for 3d medical imaging, 2024. URL https://arxiv.org/abs/2403.06801. [16] Cheng-Yi Li, Kao-Jung Chang, Cheng-Fu Yang, Hsin-Yu Wu, Wenting Chen, Hritik Bansal, Ling Chen, Yi-Ping Yang, Yu-Chun Chen, Shih-Pin Chen, Shih-Jen Chen, Jiing-Feng Lirng, Kai-Wei Chang, and Shih-Hwa Chiou. Towards holistic framework for multimodal llm in 3d brain ct radiology report generation. Nature Communications, 16(1), March 2025. ISSN 2041-1723. doi: 10.1038/s41467-025-57426-0. URL http://dx.doi.org/10.1038/ s41467-025-57426-0. [17] Stephanie L. Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Mercy Ranjit, Anton Schwaighofer, Fernando Pérez-García, Valentina Salvatelli, Shaury Srivastav, Anja Thieme, Noel Codella, Matthew P. Lungren, Maria Teodora Wetscherek, Ozan Oktay, and Javier AlvarezValle. MAIRA-1: specialised large multimodal model for radiology report generation, April 2024. [18] DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong 11 Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948. [19] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024. URL https://arxiv.org/abs/ 2402.03300. [20] Subhashis Suara, Aayush Jha, Pratik Sinha, and Arif Ahmed Sekh. Is Grad-CAM Explainable in Medical Images?, page 124135. Springer Nature Switzerland, 2024. ISBN 9783031581816. doi: 10.1007/978-3-031-58181-6_11. URL http://dx.doi.org/10. 1007/978-3-031-58181-6_11. [21] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Abubakr Babiker, Nathanael Schärli, Aakanksha Chowdhery, Philip Mansfield, Dina Demner-Fushman, Blaise Agüera Arcas, Dale Webster, Greg S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and Vivek Natarajan. Large language models encode clinical knowledge. Nature, 620(7972):172180, August 2023. ISSN 1476-4687. doi: 10.1038/s41586-023-06291-2. [22] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Mohamed Amin, Le Hou, Kevin Clark, Stephen R. Pfohl, Heather Cole-Lewis, Darlene Neal, Qazi Mamunur Rashid, Mike Schaekermann, Amy Wang, Dev Dash, Jonathan H. Chen, Nigam H. Shah, Sami Lachgar, Philip Andrew Mansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Agüera Arcas, Nenad Tomašev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle K. Barral, Dale R. Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, and Vivek Natarajan. Toward expert-level medical question answering with large language models. Nature Medicine, 31(3):943950, March 2025. ISSN 1546-170X. doi: 10.1038/s41591-024-03423-7. [23] Sajan B. Patel and Kyle Lam. ChatGPT: The future of discharge summaries? The Lancet. Digital Health, 5(3):e107e108, March 2023. ISSN 2589-7500. doi: 10.1016/S2589-7500(23)00021-3. [24] Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerová, Nidhi Rohatgi, Poonam Hosamani, William Collins, Neera Ahuja, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, John Pauly, and Akshay S. Chaudhari. Adapted large language models can outperform medical experts in clinical text summarization. Nature Medicine, 30(4): 11341142, April 2024. ISSN 1546-170X. doi: 10.1038/s41591-024-02855-5. [25] Lavender Yao Jiang, Xujin Chris Liu, Nima Pour Nejatian, Mustafa Nasir-Moin, Duo Wang, Anas Abidin, Kevin Eaton, Howard Antony Riina, Ilya Laufer, Paawan Punjabi, Madeline Miceli, Nora C. Kim, Cordelia Orillac, Zane Schnurman, Christopher Livia, Hannah Weiss, David Kurland, Sean Neifert, Yosef Dastagirzada, Douglas Kondziolka, Alexander T. M. Cheung, Grace Yang, Ming Cao, Mona Flores, Anthony B. Costa, Yindalon Aphinyanaphongs, Kyunghyun Cho, and Eric Karl Oermann. Health system-scale language models are allpurpose prediction engines. Nature, 619(7969):357362, July 2023. ISSN 1476-4687. doi: 10.1038/s41586-023-06160-y. [26] Daniel McDuff, Mike Schaekermann, Tao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan Singhal, Yash Sharma, Shekoofeh Azizi, Kavita Kulkarni, Le Hou, Yong Cheng, Yun Liu, S. Sara Mahdavi, Sushant Prakash, Anupam Pathak, Christopher Semturs, Shwetak Patel, Dale R. Webster, Ewa Dominowska, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S. Corrado, Yossi Matias, Jake Sunshine, Alan Karthikesalingam, and Vivek Natarajan. Towards Accurate Differential Diagnosis with Large Language Models, November 2023. 12 [27] Tianyu Han, Lisa C. Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexei Figueroa, Alexander Löser, Daniel Truhn, and Keno K. Bressem. MedAlpaca An Open-Source Collection of Medical Conversational AI Models and Training Data, March 2025. [28] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. BioBERT: pre-trained biomedical language representation model for biomedical text mining, October 2019. [29] Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. BioGPT: Generative pre-trained transformer for biomedical text generation and mining. Briefings in Bioinformatics, 23(6):bbac409, November 2022. ISSN 1477-4054. doi: 10.1093/ bib/bbac409. [30] Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing, September 2021. [31] Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Yash Dalmia, Jure Leskovec, Cyril Zakka, Eduardo Pontes Reis, and Pranav Rajpurkar. Med-Flamingo: Multimodal Medical Few-shot Learner. In Proceedings of the 3rd Machine Learning for Health Symposium, pages 353367. PMLR, December 2023. [32] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng Gao. LLaVA-Med: Training Large Language-andVision Assistant for Biomedicine in One Day, June 2023. [33] Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, Tim Strother, Chunjong Park, Elahe Vedadi, Juanma Zambrano Chaves, Szu-Yeu Hu, Mike Schaekermann, Aishwarya Kamath, Yong Cheng, David G. T. Barrett, Cathy Cheung, Basil Mustafa, Anil Palepu, Daniel McDuff, Le Hou, Tomer Golany, Luyang Liu, Jean-baptiste Alayrac, Neil Houlsby, Nenad Tomasev, Jan Freyberg, Charles Lau, Jonas Kemp, Jeremy Lai, Shekoofeh Azizi, Kimberly Kanada, SiWai Man, Kavita Kulkarni, Ruoxi Sun, Siamak Shakeri, Luheng He, Ben Caine, Albert Webson, Natasha Latysheva, Melvin Johnson, Philip Mansfield, Jian Lu, Ehud Rivlin, Jesper Anderson, Bradley Green, Renee Wong, Jonathan Krause, Jonathon Shlens, Ewa Dominowska, S. M. Ali Eslami, Katherine Chou, Claire Cui, Oriol Vinyals, Koray Kavukcuoglu, James Manyika, Jeff Dean, Demis Hassabis, Yossi Matias, Dale Webster, Joelle Barral, Greg Corrado, Christopher Semturs, S. Sara Mahdavi, Juraj Gottweis, Alan Karthikesalingam, and Vivek Natarajan. Capabilities of Gemini Models in Medicine, May 2024. [34] Lin Yang, Shawn Xu, Andrew Sellergren, Timo Kohlberger, Yuchen Zhou, Ira Ktena, Atilla Kiraly, Faruk Ahmed, Farhad Hormozdiari, Tiam Jaroensri, Eric Wang, Ellery Wulczyn, Fayaz Jamil, Theo Guidroz, Chuck Lau, Siyuan Qiao, Yun Liu, Akshay Goel, Kendall Park, Arnav Agharwal, Nick George, Yang Wang, Ryutaro Tanno, David G. T. Barrett, Wei-Hung Weng, S. Sara Mahdavi, Khaled Saab, Tao Tu, Sreenivasa Raju Kalidindi, Mozziyar Etemadi, Jorge Cuadros, Gregory Sorensen, Yossi Matias, Katherine Chou, Greg Corrado, Joelle Barral, Shravya Shetty, David Fleet, S. M. Ali Eslami, Daniel Tse, Shruthi Prabhakara, Cory McLean, Dave Steiner, Rory Pilgrim, Christopher Kelly, Shekoofeh Azizi, and Daniel Golden. Advancing Multimodal Medical Capabilities of Gemini, May 2024. [35] T. Savage, A. Nayak, R. Gallo, et al. Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine. npj Digital Medicine, 7:20, 2024. doi: 10.1038/s41746-024-01010-1. URL https://doi.org/10.1038/s41746-024-01010-1. [36] Shuang Zhou, Mingquan Lin, Sirui Ding, Jiashuo Wang, Canyu Chen, Genevieve B. Melton, James Zou, and Rui Zhang. Explainable differential diagnosis with dual-inference large language models. npj Health Systems, 2(1):12, 2025. ISSN 3005-1959. doi: 10.1038/ s44401-025-00015-6. URL https://doi.org/10.1038/s44401-025-00015-6. [37] Taeyoon Kwon, Kai Tzu-iunn Ong, Dongjin Kang, Seungjun Moon, Jeong Ryong Lee, Dosik Hwang, Beomseok Sohn, Yongsik Sim, Dongha Lee, and Jinyoung Yeo. Large language models are clinical reasoners: Reasoning-aware diagnosis framework with prompt-generated 13 rationales. Proceedings of the AAAI Conference on Artificial Intelligence, 38(16):1841718425, Mar. 2024. doi: 10.1609/aaai.v38i16.29802. URL https://ojs.aaai.org/index.php/ AAAI/article/view/29802. [38] Yuxiang Lai, Jike Zhong, Ming Li, Shitian Zhao, and Xiaofeng Yang. Med-r1: Reinforcement learning for generalizable medical reasoning in vision-language models, 2025. URL https: //arxiv.org/abs/2503.13939. [39] Pierrick Coupé, Boris Mansencal, Michaël Clément, Rémi Giraud, Baudouin Denis de Senneville, Vinh-Thong Ta, Vincent Lepetit, and José V. Manjon. Assemblynet: large ensemble of cnns for 3d whole brain mri segmentation. NeuroImage, 219:117026, 2020. ISSN 1053-8119. doi: https://doi.org/10.1016/j.neuroimage.2020.117026. URL https: //www.sciencedirect.com/science/article/pii/S1053811920305127. [40] Pierrick Coupé, Gwénaëlle Catheline, Enrique Lanuza, José V. Manjón, and Alzheimers Disease Neuroimaging Initiative. Towards unified analysis of brain maturation and aging across the entire lifespan: mri analysis. Human Brain Mapping, 38(11):55015518, November 2017. doi: 10.1002/hbm.23743. Epub 2017 Jul 24. [41] Clifford R. Jack, Matt A. Bernstein, Nick C. Fox, Paul Thompson, Gene Alexander, Danielle Harvey, Bret Borowski, Paula J. Britson, Jennifer L. Whitwell, Chadwick Ward, Anders M. Dale, Joel P. Felmlee, Jeffrey L. Gunter, Derek L.G. Hill, Ron Killiany, Norbert Schuff, Sabrina Fox-Bosetti, Chen Lin, Colin Studholme, Charles S. DeCarli, Gunnar Krueger, Heidi A. Ward, Gregory J. Metzger, Katherine T. Scott, Richard Mallozzi, Daniel Blezek, Joshua Levy, Josef P. Debbins, Adam S. Fleisher, Marilyn Albert, Robert Green, George Bartzokis, Gary Glover, John Mugler, and Michael W. Weiner. The alzheimers disease neuroimaging initiative (adni): Mri methods. Journal of Magnetic Resonance Imaging, 27(4):685691, April 2008. ISSN 1053-1807. doi: 10.1002/jmri.21049. [42] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen OKeefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira 14 Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, C. J. Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. GPT-4 Technical Report, March 2024. [43] Malaikannan Sankarasubbu Ankit Pal. Openbiollms: Advancing open-source large lanhttps://huggingface.co/aaditya/ guage models for healthcare and life sciences. OpenBioLLM-Llama3-70B, 2024. [44] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, Danny Wyatt, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco Guzmán, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Govind Thattai, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jack Zhang, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Karthik Prasad, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Kushal Lakhotia, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Maria Tsimpoukelli, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Ning Zhang, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta Raileanu, Rohan Maheswari, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, Vítor Albiero, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan, Xide Xia, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine 15 Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aayushi Srivastava, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Amos Teo, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Dong, Annie Franco, Anuj Goyal, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Ce Liu, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Cynthia Gao, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat Ozgenel, Francesco Caggioni, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hakan Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan Zhan, Ibrahim Damlaj, Igor Molybog, Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli, Janice Lam, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kiran Jagadeesh, Kun Huang, Kunal Chawla, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Miao Liu, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikhil Mehta, Nikolay Pavlovich Laptev, Ning Dong, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Rangaprabhu Parthasarathy, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Russ Howes, Ruty Rinott, Sachin Mehta, Sachin Siby, Sai Jayesh Bondu, Samyak Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Mahajan, Saurabh Verma, Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin, Shengxin Cindy Zha, Shishir Patil, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Summer Deng, Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara Best, Thilo Koehler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaojian Wu, Xiaolan Wang, Xilun Wu, Xinbo Gao, Yaniv Kleinman, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yu Zhao, Yuchen Hao, Yundi Qian, Yunlu Li, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao, and Zhiyu Ma. The llama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783. [45] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, 16 Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. URL https://arxiv.org/abs/2412.15115. [46] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. Qwen3 technical report, 2025. URL https://arxiv.org/abs/2505.09388. [47] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles, 2023. [48] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021. URL https://arxiv.org/abs/2106.09685. [49] Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee Sun Lee, and Min Lin. Understanding r1-zero-like training: critical perspective, 2025. URL https: //arxiv.org/abs/2503.20783. [50] Da Ma, Donghuan Lu, Karteek Popuri, Lei Wang, Mirza Faisal Beg, and Alzheimers Disease Neuroimaging Initiative. Differential Diagnosis of Frontotemporal Dementia, Alzheimers Disease, and Normal Aging Using Multi-Scale Multi-Type Feature Generative Adversarial Deep Neural Network on Structural Magnetic Resonance Images. Frontiers in Neuroscience, 14, October 2020. ISSN 1662-453X. doi: 10.3389/fnins.2020.00853."
        },
        {
            "title": "A Example of a Complete Synthetic Report and Human Comparison",
            "content": "We provide an illustrative example of complete synthetic radiology report generated from 3D T1-weighted MRI scan using the pipeline detailed in Subsection 3.1. The input scan was obtained from an open-access case on Radiopaedia.org 5, enabling direct comparison with expert-curated findings authored by neuroradiologist Dr. Frank Gaillard (founder of Radiopaedia). Figure 6 displays the expert-written report (top) and the corresponding synthetic report generated by our model (bottom). To aid visual inspection, we highlight areas of overlap in atrophy pattern descriptions using color coding. We observe that while both reports capture key neurodegenerative features consistent with the clinical picturein this case, diagnosis of behavioral variant frontotemporal dementia (bvFTD)their reporting styles differ. The synthetic report is more exhaustive and systematically structured: it enumerates wide range of anatomical regions, including both affected and unaffected areas. In contrast, the expert human report adopts more concise, diagnosis-driven narrative, focusing selectively on findings most relevant to the suspected pathology. This reflects typical clinical reporting practice, where radiologists tailor descriptions to guide differential diagnosis rather than provide exhaustive anatomical reviews. Nonetheless, despite stylistic differences, the synthetic report successfully captures all key anatomical patterns relevant to the diagnosis, demonstrating its effectiveness in supporting the subsequent differential diagnosis task. 5https://radiopaedia.org/cases/frontotemporal-dementia-behavioural-variant-2 17 Figure 6: Comparison of expert-written (top) and synthetic (bottom) radiology reports for the same T1-weighted MRI scan. Colored highlights indicate overlapping descriptions of atrophic patterns."
        },
        {
            "title": "B Insight into GRPO Training Dynamics",
            "content": "This appendix provides additional insight into the training dynamics of the GRPO-fine-tuned 8B models. In Figure 7, we visualize key performance metrics across training iterations. The left panel illustrates the progression of the mean diagnostic accuracy reward on the training set, while the right panel shows the corresponding performance on the validation set. All models exhibit consistent increase in diagnostic accuracy as training progresses, with similar upward trend on the validation set, highlighting the effectiveness and generalizability of the GRPO optimization process. Figure 8 presents the evolution of two additional metrics. The left panel depicts the mean length of generated completions (i.e., the number of generated tokens). Interestingly, the trend in response length varies across models. For instance, the Qwen3-8B and DeepSeek-Llama-8B models show clear upward trend in maximum response length (more marked in the first), aligning with observations in [46, 18]. This suggests growing capacity for analysis, reasoning refinement, and even self-doubt, as the model develops more nuanced diagnostic justifications. In contrast, models that are not natively trained for reasoning, such as Qwen-2.5-Instruct and LLaMA-3.1-Instruct, maintain relatively stable response length throughout training. This stability could suggest early convergence in reasoning style, with responses remaining short and focusedreflecting compressed but effective form of justification. Finally, the right panel of Figure 8 shows the evolution of the KL divergence term relative to the original model. We observe that all models diverge from their initial response distributions over the course of training. This indicates that GRPO effectively reshapes the models output behavior while maintaining human-readability through this regularization KL penalty. (a) Training set: Mean diagnostic accuracy reward (b) Validation set: Mean diagnostic accuracy reward Figure 7: Progression of diagnostic accuracy during the initial 60K steps of GRPO training across training and validation sets. (a) Mean generated response length (tokens) (b) KL divergence relative to the original model Figure 8: Evolution of mean response length and KL divergence over the first 60K steps of GRPO training."
        },
        {
            "title": "C Full Diagnostic Reasoning Examples",
            "content": "We present complete diagnostic outputs generated by GRPO-trained models on randomly sampled case of behavioral variant frontotemporal dementia (bvFTD). These examples highlight distinct reasoning styles that emerged during training. The LLaMA and Qwen models produce concise, focused justifications, emphasizing key diagnostic features with minimal elaboration. In contrast, the DeepSeek and Qwen-3 model exhibits more expansive diagnostic narrative, engaging in lengthier analysis. Figure 9: Full diagnostic output from GRPO-trained DeepSeek-R1-Llama-8B on bvFTD case. 20 Figure 10: Full diagnostic output from the GRPO-trained Qwen-3-8B model on bvFTD case. 21 Figure 11: Full diagnostic output from the GRPO-trained LlaMA-3.1-Instruct-8B model on bvFTD case. Figure 12: Full diagnostic output from the GRPO-trained Qwen-2.5-Instruct-7B model on bvFTD case. 22 Training Details for Classification-Only Baselines Vision-transformer (ViT). We build on the 3D ViT architecture and training pipeline from Nguyen et al. [10], originally designed for ADFTDCN classification. To support our extended diagnostic setting, we modify the final classification head to 5-way MLP, enabling prediction across CN, AD, bvFTD, svPPA, and nfvPPA. All other architectural components, data preprocessing steps, and optimization settings (e.g., learning rate, batch size, data augmentation) are retained from the original implementation. Support Vector Machine (SVM). We train SVM classifiers using the Structural Deviation Score features described in Subsection 3.1. Hyperparameter tuning is performed via grid search across two kernel types (linear, rbf) and 100 logarithmically spaced values of the regularization strength [104, 101.5]. The best model is selected based on balanced accuracy on the held-out validation folds."
        }
    ],
    "affiliations": [
        "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France"
    ]
}