{
    "paper_title": "FreNBRDF: A Frequency-Rectified Neural Material Representation",
    "authors": [
        "Chenliang Zhou",
        "Zheyuan Hu",
        "Cengiz Oztireli"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Accurate material modeling is crucial for achieving photorealistic rendering, bridging the gap between computer-generated imagery and real-world photographs. While traditional approaches rely on tabulated BRDF data, recent work has shifted towards implicit neural representations, which offer compact and flexible frameworks for a range of tasks. However, their behavior in the frequency domain remains poorly understood. To address this, we introduce FreNBRDF, a frequency-rectified neural material representation. By leveraging spherical harmonics, we integrate frequency-domain considerations into neural BRDF modeling. We propose a novel frequency-rectified loss, derived from a frequency analysis of neural materials, and incorporate it into a generalizable and adaptive reconstruction and editing pipeline. This framework enhances fidelity, adaptability, and efficiency. Extensive experiments demonstrate that \\ours improves the accuracy and robustness of material appearance reconstruction and editing compared to state-of-the-art baselines, enabling more structured and interpretable downstream tasks and applications."
        },
        {
            "title": "Start",
            "content": "2025 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING, AUG. 31 SEP. 3, 2025, ISTANBUL, TURKEY FreNBRDF: FREQUENCY-RECTIFIED NEURAL MATERIAL REPRESENTATION Chenliang Zhou, Zheyuan Hu, Cengiz Oztireli"
        },
        {
            "title": "Department of Computer Science and Technology\nUniversity of Cambridge",
            "content": "5 2 0 2 1 ] . [ 1 6 7 4 0 0 . 7 0 5 2 : r Fig. 1. Overview of FreNBRDF architecture. ABSTRACT Accurate material modeling is crucial for achieving photorealistic rendering, bridging the gap between computergenerated imagery and real-world photographs. While traditional approaches rely on tabulated BRDF data, recent work has shifted towards implicit neural representations, which offer compact and flexible frameworks for range of tasks. However, their behavior in the frequency domain remains poorly understood. To address this, we introduce FreNBRDF, frequency-rectified neural material representation. By leveraging spherical harmonics, we integrate frequency-domain considerations into neural BRDF modeling. We propose novel frequency-rectified loss, derived from frequency analysis of neural materials, and incorporate it into generalizable and adaptive reconstruction and editing pipeline. This framework enhances fidelity, adaptability, and efficiency. Extensive experiments demonstrate that FreNBRDF improves the accuracy and robustness of material appearance reconstruction and editing compared to state-of-the-art baselines, enabling more structured and interpretable downstream tasks and applications. : Equal contribution. Index Terms Appearance modeling, frequency-aware methods, material reconstruction, material editing 1. INTRODUCTION Material properties play crucial role in visual computing, serving as fundamental component in applications such as rendering, augmented reality, and scene understanding [1]. This is usually realized through the modeling and reconstruction of the bidirectional reflectance distribution functions (BRDFs) [2], which describe the relationship between the incident and outgoing radiances for specific material. By capturing the complex interactions of light with different surfaces, material representations enhance the realism and fidelity of synthesized images, improving the overall visual quality in various computational applications. Data-driven BRDF models [3], which map spatial coordinates to reflected light distributions, have demonstrated high fidelity in capturing complex material appearances. However, their inherently large data size poses significant challenges for downstream tasks such as material reconstruction, editing, storage, and real-time rendering. Efficiently representing and reconstructing BRDF data still remains critical issue. Implicit neural BRDF models (e.g., NBRDFs [4, 1, 5]) offer promising solution to these challenges by incorporating neural networks into the BRDF modeling pipeline, providing more scalable and adaptive solution for material representation. Based on NBRDF, recent research has explored leveraging latent space representations through an encoder-decoder architecture [6]. This approach seeks to reconstruct BRDFs from compressed latent space, reducing memory requirements while maintaining high reconstruction fidelity. However, the behavior of material representations in the frequency domain remains insufficiently explored. To address this gap, we propose FreNBRDF, frequency-rectified neural material representation. By leveraging spherical harmonics, we integrate frequency rectification [7] into the NBRDF framework and introduce novel frequency-rectified loss to achieve more structured and accurate representation of material appearance. The primary contributions of this work are: method for extracting frequency information from neural materials using spherical harmonics; and generalizable and adaptive material reconstruction and editing framework based on an autoencoder architecture, incorporating frequency rectification and achieving stateof-the-art performance. 2. RELATED WORK Material acquisition Gonio-photometers [8] are widely used for measuring retro-reflection, enabling precise characterization of material appearance. Using this technique, RGL [9] captured 62 materials, including anisotropic ones. In contrast, image-based measurement devices [10] were used to construct the MERL dataset [3], which consists of 100 isotropic materials. Similarly, digital consumer cameras have been employed for texture acquisition [11], forming the bidirectional texture function database Bonn (BTFDBB) using 151 such cameras mounted on structured rack. Material modeling Bidirectional reflectance distribution functions (BRDFs) [2] are widely adopted for material modeling. Early BRDF models [12, 13, 14] introduced analytical expressions derived from empirical observations. Other models [15, 16, 17] incorporate physical scattering principles while maintaining artist-friendly parameterization. These models offer balance between realism and efficiency, as their limited set of tunable parameters can be fitted to measured material data [17], making them computationally efficient in terms of both time and memory. However, due to inherent model approximations, many analytical BRDFs struggle to capture complex reflectance behaviors, particularly for highly detailed or anisotropic materials [4]. Neural BRDFs Data-driven material representations (e.g., MERL [3]) produce highly realistic renderings compared to analytical models. However, their large data size presents significant challenge for real-world applications. To address this, compression techniques such as dimensionality reduction [18] or neural network-based compression [4, 6] are commonly used. Among these, neural BRDFs (NBRDFs) [4] offer compelling balance of high fidelity and low memory demand, making them an efficient latent representation for various tasks. Built upon this, recent research has introduced set encoder hypernetwork [6] that enables generalizable and adaptive BRDF reconstruction from sparse samples. This approach is designed to handle unseen data while accommodating varying sample sizes, making it flexible and scalable solution. Building on this work, we further explore neural BRDF representations within the frequency domain. Frequency rectification FrePolad [7] utilizes spherical harmonics [19] to extract frequency information from point clouds, improving the quality and diversity of point cloud generation while maintaining high computational efficiency. Inspired by this approach, we integrate frequency information into the NBRDF representation, aiming to enhance accuracy in NBRDF modeling, reconstruction, and editing. 3. METHOD 3.1. NBRDF autoencoder pipeline Under Rusinkiewicz reparameterization of BRDFs [20], we represent the incoming and outgoing directions using the half and difference vectors or their spherical coordinates θH , ϕH and the difference vector θD, ϕD, respectively. Note that for isotropic materials, the BRDFs are independent of ϕD. Therefore, BRDF can be expressed as either fr(H, D) or fr(θH , θD, ϕH ). Inspired by prior work [4, 6, 5], we first represent BRDFs via lightweight neural fields called NBRDFs [4] that map the half Hn and difference vectors Dn to reflectance values fr(Hn, Dn). To facilitate NBRDF reconstruction and editing, our autoencoder-based pipeline trains pair of encoder and decoder to capture lower dimensional space of the weights of NBRDFs. During inference, the model accepts queries in terms of (H, D) coordinate and returns the reflectance values at that coordinate. Moreover, the set encoder provides low-dimensional embeddings of neural materials, enabling material editing through interpolation. By linearly interpolating between the embeddings of different materials, we can reconstruct range of novel appearances. We illustrate this autoencoder architecture in Fig. 1. For the network, we adopt set encoder [21] with permutation invariance and flexibility of input size. It takes an arbitrary set of samples as input, which is the concatenation of BRDF values and coordinates, containing four fully connected layers with two hidden layers of 128 hidden neurons and ReLU activation function. The reconstruction loss Lrec(fr, r) between two NBRDFs is defined to be the sum of the L1 loss between samples of the two underlying BRDFs and the two regularization terms for NBRDF weights and latent embeddings z: Consequently, suitable candidate is the normalized Gaussian function with standard deviation σ: Lrec(fr, r) := 1 P (cid:88) i=1 (fr(Hi, Di) r(Hi, Di)) cos θi + λ1 (cid:88) i=1 w2 + λ2 (cid:88) j=1 z2 , (1) where is the predefined set of indices for samples, θi is the angle between the incoming light direction and the normal of the surface, and λ1 and λ2 are regularization coefficients. Following previous work [18], we also adopt the preprocessing technique of log-relative mapping for BRDFs: fr (cid:55) ln (cid:19) (cid:18) fr + ϵ fref + ϵ (2) where the reference value fref is the median BRDF value and ϵ is small constant to avoid division or logarithm of zero. 3.2. Frequency Recitification We observe that the naive NBRDF autoencoder pipeline described above lacks the frequency information between the two NBRDFs, which might help the learning of NBRDF weight distribution [7]. To extract frequency information from BRDFs, we apply spherical harmonic transformation [19, 7]. Note that the spherical harmonics require continuous functions on the unit sphere S2. Our first problem is that the BRDF fr(θH , θD, ϕH ) is not function on S2. We address this by fixing the third argument ϕH to some value α, and the function is thus defined on S2: fr(θ, ϕ) := fr(θH , θD, ϕH = α). (3) We can then apply the technique multiple times for different values of ϕH and average the result. Another problem is that the given MERL dataset [3] only provides BRDF values at discrete sample positions , but we need continuous function. To overcome this, we obtain the BRDF values at an arbitrary position (θ, ϕ) by interpolating the values at its nearest neighbors Pk(θ, ϕ) in the sample positions with weights wi: := di2 2σ2 ; j wi := (cid:80) . (6) (7) After we obtain BRDFs expressed as continuous functions on the unit sphere S2, we can further leverage spherical harmonics to express them as linear combination of orthonormal base functions : S2 of degrees and orders m: fr(θ, φ) = cl,m = (cid:88) (cid:88) l=0 (cid:90) 2π m=l (cid:90) π 0 cl,mGl,m(θ, φ); (8) fr(θ, ϕ)Gl,m(θ, ϕ) sin θdθdϕ. (9) Note that BRDFs have three channels (RGB). Therefore, we apply the above method to each channel separately, producing the frequency coefficients cl,m R3. The key insight here is that these frequency coefficients now contain the extracted frequency information at each degree and order m. Therefore, we can define frequency-rectified loss on BRDFs based on the mean squared error of frequency coefficients Lfre(fr, r) := 1 P (cid:88) i=1 (cid:13) (cid:13)cl,m l,m (cid:13) 2 (cid:13) (10) and consequently, we can incorporate this loss into the reconstruction loss Eq. (1): L(fr, r) := Lrec(fr, r) + ηLfre(fr, r), (11) where η is the hyperparameter controlling the strength of frequency rectification and cl,m and l,m are the frequency coefficients for fr and r, respectively. With the help of frequency information, our pipeline is able to better learn the NBRDF weight distribution, enabling better reconstruction and editing tasks as demonstrated in Sec. 4. fr(θ, ϕ) := (cid:88) wifr(θi, ϕi). (4) iPk(θ,ϕ) 4.1. Dataset 4. EXPERIMENTS The nearest neighbors (θi, ϕi) of (θ, ϕ) are determined through their distances di to the points (θ, ϕ): di = (cid:112)2 2 [sin θ sin θi cos(ϕ ϕi) + cos θ cos θi]. (5) For the choice of weights wi, since closer points should have larger weights, {wi}i should be decreasing sequence on di. The MERL dataset [3] is used in this study for its diversity and data-driven nature, making it suitable for both statistical and neural-network-based methods. It contains 100 measured real-world materials. Each BRDF is represented as 9090 180 3 floating-point array, mapping uniformly sampled input angles (θH , θD, ϕD) under Rusinkiewicz reparametrization [20] to reflectance values in R3. Fig. 2. FreNBRDF reconstructs 30 MERL materials [3] with high quality, indicating that FreNBRDF effectively learns the material distribution (ground truths to the left and the reconstructed material to the right). 4.2. Training and testing procedures maximum pixel value p, PSNR is defined as The dataset is divided into training, validation, and testing sets in 70%-10%-20% split. We use the Adam optimizer [22], first-order gradient-based method for optimizing stochastic objective functions. During training, the specified losses are reported at each epoch, and optimal hyperparameters are selected based on performance on the validation set. Model performance is then evaluated on the hold-out test set using range of quantitative metrics introduced in Sec. 4.3. LPSNR(I1, I2) := 10 log10 p2 RMSE(I1, I2) L2 . (13) Structural similarity index measure (SSIM) [23]. SSIM is perception-based metric that measures the perceptual similarity between the two images, which aims for higher values for better performance. SSIM is computed from the luminance l(I1, I2), contrast c(I1, I2), and structure s(I1, I2) of the two images with exponential weights a, b, > 0: 4.3. Metrics LSSIM(I1, I2) := la(I1, I2)cb(I1, I2)sc(I1, I2). (14) To evaluate the performance of material reconstruction and editing, we report the frequency-rectified loss (Eq. (10)) accessing the frequency compliance. We also report the following three rendering-based metrics assessing the perceptual similarity and reconstruction quality between the two images I1, I2 : {1, 2, . . . , w} {1, 2, . . . , h} [0, 1]3, where w, are the width and height of the images: Root mean squared error (RMSE). RMSE checks if pixel values at the same coordinates match: LRMSE(I1, I2) := (cid:118) (cid:117) (cid:117) (cid:116) 1 wh (cid:88) (cid:88) i=1 j=1 (I1(i, j) I2(i, j))2. (12) Note that RMSE depends strongly on the image intensity scaling. RMSE aims for lower value. Peak signal-to-noise ratio (PSNR). PSNR is the scaled mean squared error (MSE). PSNR measures the image reconstruction quality and aims for higher values. Given the 4.4. Material reconstruction We present 30 reconstructed materials rendered under consistent scene and lighting conditions in Fig. 2. The results demonstrate that FreNBRDF effectively learns the material distribution and produces high-quality, faithful reconstructions. In Tab. 1, we compare the performance of FreNBRDF on the material reconstruction task with two state-of-the-art the method of Gokbudak et al. [6] and naive baselines: NBRDF [4] reconstruction pipeline, as described in Sec. 3.1, without frequency rectification. From the results, we can see that FreNBRDF outperforms both baselines across most metrics evaluating frequency compliance, rendering quality, and visual similarity, confirming the effectiveness of our proposed approach. Note that the higher RMSE score for FreNBRDF is likely due to its reconstruction loss (Eq. (11)) being designed to enforce consistency in both the spatial and frequency domains. Metrics RMSE102 () PSNR () SSIM10 () Lfre 103 () [6] NBRDF [4] FreNBRDF (ours) 6.89 26.3 9.26 6. 6.60 29.2 9.50 6.80 6.74 29.9 9.88 0.23 Table 1. Quantitative comparison on material reconstruction against state-of-the-art baselines. FreNBRDF achieves superior performance, showing its effectiveness. Metrics RMSE102 () PSNR () SSIM10 () Lfre 103 () [6] NBRDF [4] FreNBRDF (ours) 8.42 22.4 9.13 6.72 7.63 27.6 9.42 6.80 6.92 30.1 9.82 0.22 Table 2. Quantitative comparison on material editing with two state-of-the-art baselines. Materials represented by FreNBRDF exhibit significantly higher quality compared to the two baselines, indicating that FreNBRDF effectively learns the distribution of neural materials. 4.5. Material editing Our pipeline provides low-dimensional space of neural materials, enabling material editing by linearly interpolating between embeddings of different materials. We compare different models on this task. The ground truth can be obtained by directly linearly interpolating the MERL materials [3]. Figure 3 illustrates interpolations between five pairs of MERL materials where each row represents one interpolation. The smooth transitions between the two endpoints demonstrate the capability of our FreNBRDF as robust and effective implicit neural representation for materials. We also report the relevant metrics in Tab. 2, computed over 2000 randomly interpolated materials. The results show that materials represented by FreNBRDF exhibit consistently higher quality compared to the two baselines. Compared to the reconstruction results in Tab. 1, the interpolated materials produced by the two baselines show degraded performance, while those generated by FreNBRDF maintain similar quality. This indicates that FreNBRDF effectively captures the underlying distribution of neural materials. 4.6. Further analysis We further visualize the sample-wise performance of the naive NBRDF [4] reconstruction pipeline and FreNBRDF with frequency rectification in Figs. 4 and 5, respectively, with the mean (solid line) and variance (dashed line) indicated. This visualization reveals overall statistical trends and helps identify outliers or failure cases, providing deeper insight into each models behavior. The results show that Fig. 3. Linearly interpolation between embeddings of five pairs of MERL materials (each row is an interpolation). From left to right, the interpolation weights are 0.0, 0.2, 0.4, 0.6, 0.8, 1.0. The smooth transitions between the two endpoints demonstrate the capability of our FreNBRDF as robust and effective implicit neural representation for materials. (a) RMSE (b) PSNR (c) SSIM Fig. 4. Sample-wise performance of the naive NBRDF reconstruction with mean (solid) and variance (dashed line). FreNBRDF effectively reduces frequency domain discrepancies while maintaining comparable qualitative and quantitative performance. This underscores the potential of our method and suggests promising directions for future research in frequency-aware material modeling. 5. CONCLUSION AND FUTURE WORK In this work, we propose FreNBRDF, frequency-rectified neural material representation. Building on this representation, we develop material reconstruction and editing pipeline based on an autoencoder architecture, incorporating novel frequency-rectified loss to enforce accuracy in the frequency domain. We evaluate our method against stateof-the-art baselines using both qualitative and quantitative metrics, with FreNBRDF consistently outperforming competing approaches. By integrating frequency information, FreNBRDF has the potential to unlock novel techniques for (a) RMSE (b) PSNR (c) SSIM Fig. 5. Sample-wise performance of FreNBRDF on material reconstruction, with mean (solid) and variance (dashed line). refining material details. Promising directions for future work include extending the approach to more complex materials, such as anisotropic BRDFs, spatially varying BRDFs, and physically-based materials. We also hope this work contributes to future research and applications, including game development, virtual environments, and simulation systems, where realistic material representation is crucial for visual accuracy and immersion. 6. REFERENCES [1] Chenliang Zhou, Zheyuan Hu, Alejandro Sztrajman, Yancheng Cai, Yaru Liu, and Cengiz Oztireli, Neumadiff: Neural material synthesis via hyperdiffusion, 2024. [2] Mislene da Silva Nunes, Fernando Melo Nascimento, Gastão Florêncio Miranda Jr., and Beatriz Trinchão Andrade, Techniques for brdf evaluation, The Visual Computer, vol. 38, pp. 573 589, 2021. [3] W. Matusik, H. Pfister, M. Brand, and L. McMillan, datadriven reflectance model, ACM Transactions on Graphics (TOG), vol. 22, no. 3, pp. 759769, July 2003. [4] Alejandro Sztrajman, Gilles Rainer, Tobias Ritschel, and Tim Neural brdf representation and importance samWeyrich, pling, Computer Graphics Forum, 2021. [5] Chenliang Zhou, Alejandro Sztrajman, Gilles Rainer, Fangcheng Zhong, Fazilet Gokbudak, Zhilin Guo, Weihao Xia, Rafal Mantiuk, and Cengiz Oztireli, Physically based neural bidirectional reflectance distribution function, arXiv preprint arXiv:2411.02347, 2024. [6] Fazilet Gokbudak, Alejandro Sztrajman, Chenliang Zhou, Fangcheng Zhong, Rafal Mantiuk, and Cengiz Oztireli, Hypernetworks for generalizable brdf representation, The 18th European Conference on Computer Vision (ECCV), 2024. [7] Chenliang Zhou, Fangcheng Zhong, Param Hanji, Zhilin Guo, Kyle Fogarty, Alejandro Sztrajman, Hongyun Gao, and Cengiz Oztireli, Frepolad: Frequency-rectified point latent diffusion for point cloud generation, in ECCV 2024, 2024. [8] PAB Advanced Technologies Ltd., Pab pgii goniophotometer, 2018, Accessed: 2018-01-09. [9] Jonathan Dupuy and Wenzel Jakob, An adaptive parameterization for efficient material acquisition and rendering, Transactions on Graphics (Proceedings of SIGGRAPH Asia), vol. 37, no. 6, pp. 274:1274:18, Nov. 2018. [10] Stephen R. Marschner, Stephen H. Westin, Eric P. F. Lafortune, and Kenneth E. Torrance, Image-based bidirectional reflectance distribution function measurement, Appl. Opt., vol. 39, no. 16, pp. 25922600, Jun 2000. [11] Christopher Schwartz, Ralf Sarlette, Michael Weinmann, Martin Rump, and Reinhard Klein, Design and implementation of practical bidirectional texture function measurement devices focusing on the developments at the university of bonn, Sensors, vol. 14, no. 5, 2014. [12] Bui Tuong Phong, Illumination for computer generated pictures, Commun. ACM, vol. 18, no. 6, pp. 311317, jun 1975. [13] Eric P. F. Lafortune, Sing-Choong Foo, Kenneth E. Torrance, and Donald P. Greenberg, Non-linear approximation of reflectance functions, in Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, USA, 1997, SIGGRAPH 97, p. 117126, ACM Press/AddisonWesley Publishing Co. [14] Gregory J. Ward, Measuring and modeling anisotropic reflection, SIGGRAPH Comput. Graph., vol. 26, no. 2, pp. 265272, jul 1992. [15] R. L. Cook and K. E. Torrance, reflectance model for computer graphics, ACM Trans. Graph., vol. 1, no. 1, pp. 724, jan 1982. [16] Bruce Walter, Stephen R. Marschner, Hongsong Li, and Kenneth E. Torrance, Microfacet models for refraction through in Proceedings of the 18th Eurographics rough surfaces, Conference on Rendering Techniques, Goslar, DEU, 2007, EGSR07, p. 195206, Eurographics Association. [17] Brent Burley, Physically-based shading at disney, SIGGRAPH Comput. Graph., 2012. [18] Jannik Boll Nielsen, Henrik Wann Jensen, and Ravi Ramamoorthi, On optimal, minimal brdf sampling for reflectance acquisition, ACM Transactions on Graphics (TOG), vol. 34, no. 6, pp. 186:1186:11, November 2015. [19] Boris Bonev, Thorsten Kurth, Christian Hundt, Jaideep Pathak, Maximilian Baust, Karthik Kashinath, and Anima Anandkumar, Spherical fourier neural operators: Learning stable dynamics on the sphere, 2023. [20] Szymon M. Rusinkiewicz, new change of variables for efficient brdf representation, in Rendering Techniques 98, George Drettakis and Nelson Max, Eds., Vienna, 1998, pp. 11 22, Springer Vienna. [21] Manzil Zaheer, Satwik Kottur, Siamak Ravanbhakhsh, Barnabás Póczos, Ruslan Salakhutdinov, and Alexander Smola, Deep sets, in Proceedings of the 31st International Conference on Neural Information Processing Systems, Red Hook, NY, USA, 2017, NIPS17, p. 33943404, Curran Associates Inc. [22] Diederik P. Kingma and Jimmy Ba, Adam: method for stochastic optimization, CoRR, vol. abs/1412.6980, 2014. [23] Zhou Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli, Image quality assessment: from error visibility to structural similarity, IEEE Transactions on Image Processing, vol. 13, no. 4, pp. 600612, 2004."
        }
    ],
    "affiliations": []
}