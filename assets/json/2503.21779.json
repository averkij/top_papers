{
    "paper_title": "X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction",
    "authors": [
        "Weihao Yu",
        "Yuanhao Cai",
        "Ruyi Zha",
        "Zhiwen Fan",
        "Chenxin Li",
        "Yixuan Yuan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Four-dimensional computed tomography (4D CT) reconstruction is crucial for capturing dynamic anatomical changes but faces inherent limitations from conventional phase-binning workflows. Current methods discretize temporal resolution into fixed phases with respiratory gating devices, introducing motion misalignment and restricting clinical practicality. In this paper, We propose X$^2$-Gaussian, a novel framework that enables continuous-time 4D-CT reconstruction by integrating dynamic radiative Gaussian splatting with self-supervised respiratory motion learning. Our approach models anatomical dynamics through a spatiotemporal encoder-decoder architecture that predicts time-varying Gaussian deformations, eliminating phase discretization. To remove dependency on external gating devices, we introduce a physiology-driven periodic consistency loss that learns patient-specific breathing cycles directly from projections via differentiable optimization. Extensive experiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR gain over traditional methods and 2.25 dB improvement against prior Gaussian splatting techniques. By unifying continuous motion modeling with hardware-free period learning, X$^2$-Gaussian advances high-fidelity 4D CT reconstruction for dynamic clinical imaging. Project website at: https://x2-gaussian.github.io/."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 2 ] . [ 1 9 7 7 1 2 . 3 0 5 2 : r X2-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction Weihao Yu1 Yuanhao Cai2 Ruyi Zha3 Zhiwen Fan4 Chenxin Li1 Yixuan Yuan1* 1The Chinese University of Hong Kong 3The Australian National University 2Johns Hopkins University 4University of Texas at Austin Figure 1. Dynamic reconstruction results of the proposed X2-Gaussian on public DIR Dataset [9]. The red dashed line is the reference line for diaphragm movement, and blue dashed box shows some tissue deformation. Our method demonstrates superior capability in continuous-time reconstruction, significantly outperforming existing approaches."
        },
        {
            "title": "Abstract",
            "content": "Four-dimensional computed tomography (4D CT) reconstruction is crucial for capturing dynamic anatomical changes but faces inherent limitations from conventional phase-binning workflows. Current methods discretize temporal resolution into fixed phases with respiratory gating devices, introducing motion misalignment and restrictIn this paper, We propose X2ing clinical practicality. Gaussian, novel framework that enables continuoustime 4D-CT reconstruction by integrating dynamic radiative Gaussian splatting with self-supervised respiratory motion learning. Our approach models anatomical dynamics through spatiotemporal encoder-decoder architecture that predicts time-varying Gaussian deformations, eliminating phase discretization. To remove dependency on external gating devices, we introduce physiology-driven periodic consistency loss that learns patient-specific breathing cycles directly from projections via differentiable opti- *Corresponding Author. mization. Extensive experiments demonstrate state-of-theart performance, achieving 9.93 dB PSNR gain over traditional methods and 2.25 dB improvement against prior Gaussian splatting techniques. By unifying continuous motion modeling with hardware-free period learning, X2Gaussian advances high-fidelity 4D CT reconstruction for dynamic clinical imaging. Project website at: https: //x2-gaussian.github.io/. 1. Introduction Four-dimensional computed tomography (4D CT) has become cornerstone in dynamic medical imaging, especially for respiratory motion management in clinical applications such as image-guided radiotherapy (IGRT) [12, 38]. By capturing both spatial and temporal information of the chest cavity during breathing cycles, 4D CT enables clinicians to monitor and assess respiratory-induced tumor motion and other dynamic anatomical changes during treatment [3, 13, 49]. Traditional 4D CT reconstruction follows phasebinning workflow. It first divides the projections into discrete respiratory phases using external gating devices that require direct patient contact, followed by independent reconstruction of each phase to obtain sequence of 3D volumes. Within this framework, 3D reconstruction methods such as Feldkamp-David-Kress (FDK) algorithm [42], or total variation minimization [47, 48], can be directly applied to 4D CT reconstruction. Due to the limited number of projections available per phase, the reconstructed CT images frequently exhibit significant streak artifacts, which degrade the visibility of fine tissue structures. To address this issue, several researchers [5, 11, 33, 41, 62] have proposed methods for extracting patient-specific motion patterns to compensate for respiratory motion across different phases. Meanwhile, other studies [22, 24, 25, 31, 63] have explored the use of Convolutional Neural Networks (CNNs) to restore details in artifact-contaminated images. Recent advances in Neural Radiance Fields (NeRF) [37] have introduced improved methods for CT reconstruction [7, 59]. These approaches enable high-fidelity 3D reconstruction from sparse views, thereby mitigating the projection undersampling issues caused by phase partitioning. The emergence of 3D Gaussian splatting (3DGS) [29] has further facilitated the development of more efficient and higher-quality methods [6, 60]. Despite these progress, the reconstruction of 4D CT still suffers from two challenges rooted in the traditional phase-binning paradigm. Firstly, previous methods simulate 4D imaging through series of disjoint 3D reconstructions at predefined phases, failing to model the continuous spatiotemporal evolution of anatomy. This discretization introduces temporal inconsistencies, limits resolution to few static snapshots per cycle, and produces artifacts when interpolating between phases. Secondly, they heavily relies on external respiratory gating devices, not only introducing additional hardware dependencies and potential measurement errors that can compromise reconstruction accuracy, but also imposing physical constraints and discomfort on patients during the scanning process. To overcome these limitations, we propose X2-Gaussian, novel framework that achieves genuine 4D CT reconstruction by directly modeling continuous anatomical motion. Firstly, unlike previous approaches that perform sequential 3D reconstructions, our method introduces dynamic Gaussian motion model that explicitly captures the continuous deformation of anatomical structures over time by extending radiative Gaussian splatting [60] into the temporal domain. Specifically, we design spatiotemporal encoder that projects Gaussian properties onto multi-resolution feature planes, effectively capturing both local anatomical relationships and global motion patterns. The encoded features are then processed by lightweight multi-head decoder network that predicts deformation parameters for each Gaussian at any queried timestamp, enabling true 4D reconstruction without discrete phase binning. Secondly, we introduce self-supervised respiratory motion learning method to eliminate the requirement of external gating devices. By leveraging the quasi-periodic nature of respiratory motion, our approach learns to estimate the breathing period directly from the projection data through novel physiology-driven periodic consistency mechanism that enforces temporal coherence across respiratory cycles. This approach fundamentally differs from traditional phase-based methods by transforming the discrete phase assignments into learnable continuous parameters, enabling our model to automatically discover and adapt to patient-specific breathing patterns. As shown in Fig. 1, X2-Gaussian exhibits superior reconstruction performance compared to existing state-of-the-art methods, establishing new benchmark in 4D CT reconstruction. Our contributions can be summarized as follows: We present X2-Gaussian, the first method to directly reconstruct time-continuous 4D-CT volumes from projections, which bypasses phase binning entirely, enabling motion analysis at arbitrary temporal resolutions. We extend the static radiative Gaussian splatting into the temporal domain. To our knowledge, this is the first attempt to explore the potential of Gaussian splatting in dynamic tomographic reconstruction. We introduce novel self-supervised respiratory motion learning module that jointly estimates the respiratory cycle and enforces periodic consistency, eliminating reliance on external gating devices. Extensive experiments demonstrate that our method significantly improves reconstruction quality, reduces streak artifacts, and accurately models respiratory motion, while also showing potential for automatic extraction of various clinical parameters. 2. Related Work 2.1. CT Reconstruction Traditional 3D computed tomography reconstruction methods mainly include two categories: analytical algorithms [15, 55] and iterative algorithms [1, 35, 44, 46]. Analytical methods estimate the radiodensity by solving Radon transformation and its inverse version. Iterative algorithms are based on optimization over iterations. In recent years, deep learning based models [2, 18, 26, 32, 34] like CNNs have been employed to learn brute-force mapping from X-ray projections to CT slices. Another technical route is to employ the 3D rendering algorithms such as neural radiance fields (NeRF) [37] and 3D Gaussian Splatting (3DGS) [29] to solve the CT reconstruction prolblem in self-supervised manner, i.e. using only 2D X-rays for training. Based on these algorithms, when coping with 4D CTs, researchers typically segment the projections into ten discrete respiratory phases for sequential 3D reconstruction. This approach not only necessitates external devices for phase measurement during scanning but also impedes accurate modeling Figure 2. Framework of our X2-Gaussian, which consists of two innovative components: (1) Dynamic Gaussian motion modeling for continuous-time reconstruction; (2) Self-Supervised respiratory motion learning for estimating breathing cycle autonomously. of the continuous motion of anatomical structures. Concurrent work [17] also employs dynamic Gaussian splatting. However, they merely establish ten timestamps corresponding to ten phases, thereby maintaining discrete representation. In contrast, this paper is dedicated to achieving truly continuous-time 4D CT reconstruction. 2.2. Gaussian Splatting 3D Gaussian splatting [29] (3DGS) is firstly proposed for view synthesis. It uses millions of 3D Gaussian point clouds to represent scenes or objects. In the past two years, 3DGS has achieved great progress in scene modeling [51, 54, 56, 61], SLAM [36, 53, 57], 3D Generation [40, 52], medical imaging [6, 60], etc. For instance, Cai et al. design the first 3DGS-based method, X-GS [6], for X-ray projection rendering. Later work R2GS [60] rectifies 3DGS pipeline to enable the direct CT reconstruction. Nonetheless, these algorithms show limitations in reconstructing dynamic CT volumes. Our goal is to cope with this problem. 3. Preliminaries Radiative Gaussian Splatting [60] represents 3D CT using collection of Gaussian kernels = {Gi}K i=1, each characterized by its central position µi R3, covariance matrix Σi R33, and isotropic density ρi: Gi(xρi, µi, Σi) = ρiexp (cid:18) (x µi)T Σ1 (cid:19) (x µi) . 1 2 (1) 3 RT The covariance matrix can be decomposed as: Σi = , where Ri R33 is the rotation matrix and RiSiST Si R33 is the scaling matrix. Then the total density at position is computed as the sum of all contributed Gaussian kernels: σ(x) = (cid:88) i=1 Gi(xρi, µi, Σi). (2) For 2D image rendering, the attenuation of X-ray through medium follows the Beer-Lambert Law [27]: I(r) = log I0 log (r) = (cid:90) σ(r(t))dt, (3) where I0 is the initial X-ray intensity, r(t) = + td R3 represents ray path, and σ(x) denotes the isotropic density at position R3. Thus, the final pixel value is obtained by integrating the density field along each ray path Ir(r) = (cid:88) (cid:90) i=1 Gi(r(t)ρi, µi, Σi)dt, (4) where Ir(r) is the rendered pixel value. 4. Methods 4.1. Overview Given sequence of X-ray projections {Ij}N timestamps {tj}N j=1 and view matrices {Mj}N j=1 acquired at j=1, our goal is to learn continuous representation of the dynamic CT volume that can be queried at arbitrary timestamps, thereby overcoming the inherent limitations of discrete phase binning. To accomplish this, as shown in Fig. 2, our method seamlessly integrates dynamic Gaussian motion modeling with self-supervised respiratory motion learning scheme into unified, end-to-end differentiable framework. Specifically, raw Gaussian parameters are initialized from {Ij}N j=1 and {Mj}N j=1. Given timestamp tj, dynamic Gaussian motion modeling module predicts the deformation of each parameter, allowing continuous-time reconstruction. Additionally, we model the respiratory cycle as learnable parameter and sample another timestamp accordingly. Through carefully designed periodic consistency loss, we mine the real breathing period in self-supervised way. 4.2. Dynamic Gaussian Motion Modeling To achieve continuous 4D CT reconstruction, we introduce deformation field that models the anatomical dynamics. At the core of our method is time-dependent deformation field D(µi, t) that predicts the deformation parameters Gi for each Gaussian at time t. The deformed Gaussians can be computed as: = Gi + Gi = (µi + µi, Ri + Ri, Si + Si, ρi), (5) where µi, Ri, and Si are the deformation offsets for position, rotation, and scaling, respectively. Our deformation field is implemented as composition of two components: = E, where is spatiotemporal encoder and is deformation-aware decoder. Decomposed Spatio-Temporal Encoding. To encode the spatiotemporal features of Gaussian primitives, straightforward approach would be to employ neural networks to directly parameterize E. But such method may lead to low rendering speed and potential overfitting issues, especially given the sparse projection data in 4D CT reconstruction. Inspired by recent advances in dynamic scene reconstruction [8, 14, 51], we adopt decomposed approach that factorizes the 4D feature space into set of multi-resolution K-Planes [16], which reduces memory requirements while preserving the ability to model complex spatiotemporal patterns in respiratory motion. Specifically, given Gaussian center µ = (x, y, z) and timestamp t, we project 4D coordinates = (x, y, z, t) onto three spatial planes Pxy, six orthogonal feature planes: Pxz, Pyz and three temporal planes Pxt, Pyt, Pzt. Each plane RdlM lM stores learnable features of dimension at multiple resolutions 1, ..., L, where is the basic resolution, enabling simultaneous modeling of fine local motion and global respiratory patterns. The encoded feature fe is computed through bilinear interpolation across multi-resolution planes: fe = (a,b) ψ (cid:0)P ab(v)(cid:1) , (6) 4 Figure 3. Periodic display of respiratory motion (T = 3s). specific anatomical structure (framed by boxes of the same color) at time has the same position at time + nT . where ψ denotes bilinear interpolation, represents feature concatenation, is Hadamard product, and (a, b) {(x, y), (x, z), (y, z), (x, t), (y, t), (z, t)}. Then fe is further merged through tiny feature fusion network ϕh (i.e. one layer of MLP) as fh = ϕh(fe). Deformation-Aware Gaussian Decoding. Once the spatiotemporal features are encoded, we employ lightweight multi-head decoder network to predict the deformation parameters for each Gaussian: µ, R, = Fµ(fh), FR(fh), FS(fh). (7) Such decoupled design allows specialized learning of different motion characteristics: position shifts for translational movements, rotation for orientation changes, and scaling for volumetric expansion/contraction. Then the deformed Gaussian parameters at timestamp can be calculated according to Eq. 5. In this way, our dynamic Gaussian motion modeling not only allows independently fine-tune different aspects of motion but also facilitates continuous interpolation across time, yielding smooth temporal transitions in the reconstructed CT volume. 4.3. Self-Supervised Respiratory Motion Learning To eliminate the need for external respiratory gating devices while accurately capturing breathing patterns, we introduce self-supervised approach that directly learns respiratory motion from projection data. Our method leverages the inherently periodic nature of human respiration to establish temporal coherence across respiratory cycles. Physiology-Driven Periodic Consistency Loss. Respiratory motion exhibits an inherently cyclic pattern, with anatomical structures returning to approximately the same position after each breathing cycle [20]. This physiological characteristic serves as powerful prior to constrain seconds and our model learns ˆT = 4 seconds, then with = 6, we would enforce consistency between times and + 24 seconds, which coincidentally satisfies periodicity (as 24 is divisible by the true period of 3). By limiting to adjacent cycles, we ensure the model learns the fundamental period rather than its harmonics. Log-Space Parameterization: We represent ˆT = exp(ˆτ ) where ˆτ is an unbounded learnable variable. This ensures positivity and provides smoother gradient updates compared to direct period estimation. This logarithmic parameterization ensures remains positive, improves numerical stability by preventing extremely small period values, and creates more uniform gradient landscape for optimization. As shown in Fig. 4, these two technical designs are critical for accurate and stable period estimation. Without bounded cycle shifts, the learned period ˆT oscillates with large amplitude approaching sub-harmonics (i.e. /2) of the true respiratory period, as the periodic consistency loss can be satisfied by most common multiples of sub-harmonics. Direct optimization in linear space leads to pronounced oscillations in the learning trajectory of ˆT . With both techniques implemented, ˆT converges stably and accurately to the correct breathing cycle. In this way, we reformulate Eq. 9 as Lpc = L1 (cid:16) I(t), I(cid:0)t + exp(ˆτ )(cid:1)(cid:17) + λ1 Lssim (cid:16) I(t), I(cid:0)t + exp(ˆτ )(cid:1)(cid:17) , (10) where {1, 1}. Then the optimal period can be learned via τ = arg min ˆτ Lpc, = exp(τ ). (11) Through this self-supervised optimization approach, our model automatically discovers patient-specific breathing patterns directly from projection data without requiring external gating devices, simplifying clinical workflow while improving reconstruction accuracy. 4.4. Optimization Loss Function. We optimize our framework by employing compound loss function. Similar to Lpc, we use L1 loss and D-SSIM loss to supervise the rendered X-ray projections as Lrender = L1 + λ2 Lssim. Following [60], we integrate 3D total variation (TV) regularization term [43] L3D to promote spatial homogeneity in the CT volume. We also apply grid-based TV loss [8, 16, 51] L4D to the multi-resolution k-plane grids used during spatiotemporal encoding. The overall loss function is then defined as: Ltotal = Lrender + α Lpc + β L3D + γ L4D , (12) where α, β, and γ are weights that control the relative influence of the periodic consistency and regularization terms. Figure 4. Convergence behavior of the learnable period ˆT . Without Bounded Cycle Shifts, ˆT undergoes wide-ranging oscillations approaching half the true period. Without Log-Space Parameterization, the optimization curve exhibits large oscillations. With both techniques implemented, ˆT converges stably and accurately to the correct breathing cycle. the reconstruction process. As illustrated in Fig. 3, given anatomical position at time should match its state at time + nT , where represents the respiratory period and is an integer. To explicitly encode this periodicity, we enforce consistency constraint on the rendered images: I(t) = I(t + nT ). (8) Lpc = L1 In practice, we define periodic consistency loss: (cid:0)I(t), I(t + nT )(cid:1) + λ1 Lssim (cid:0)I(t), I(t + nT )(cid:1), (9) which encourages the reconstructed images at times and + nT to be similar. Here, L1 and Lssim are L1 loss and D-SSIM loss [50], respectively. This constraint effectively reduces the temporal degrees of freedom in our model by enforcing cyclic coherence, helping to mitigate artifacts and improve reconstruction quality, especially in regions with significant respiratory-induced motion. Differentiable Cycle-Length Optimization. In realistic scenarios, the true respiratory cycle is not available priori. Hence, we treat it as learnable parameter ˆT within our framework. Instead of being provided externally, ˆT is optimized directly from the projection data by backpropagating the periodic consistency loss. This allows the network to automatically discover the breathing period in selfsupervised manner. To ensure numerical stability and avoid harmonic artifacts, we implement two critical designs: Bounded Cycle Shifts: We restrict the integer in our periodic consistency loss to {1, 1}, focusing only on adjacent respiratory cycles. This restriction is critical for avoiding potential ambiguities in period estimation. When using larger values of n, the optimization might converge to period estimates that are multiples or divisors of the true period. For example, if the true period is 3 5 Table 1. Comparison of our X2-Gaussian with different methods on the DIR dataset. Patient1 Patient Patient3 Patient4 Patient"
        },
        {
            "title": "Average",
            "content": "PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM 0.727 34.47 0.917 40.04 0.931 40.85 0.898 33.21 0.912 38.21 0.942 37.21 0.801 34.19 0.819 38.00 40.51 0.943 44.6 0.978 35.32 0.935 43.22 0.972 37.18 0.942 36.36 0.947 39.34 0.955 0.638 0.935 0.955 0.928 0.927 0.947 0.812 0.793 0.937 25.05 30.62 32.87 30.32 31.73 31.53 22.96 25.32 33.75 28.05 33.00 33.66 33.64 33.95 34.30 26.32 28.69 36.45 25.25 32.8 34.29 32.40 31.74 33.14 29.89 28.77 35.09 0.624 0.889 0.917 0.864 0.875 0.938 0.713 0.739 0. 0.826 0.888 0.897 0.881 0.900 0.929 0.840 0.854 0.956 0.709 0.910 0.922 0.813 0.911 0.944 0.793 0.807 0.938 34.23 33.55 33.43 33.47 34.11 36.71 32.53 33.54 39.66 29.41 34.00 35.02 32.61 33.95 34.58 29.18 30.86 37.09 0.836 0.965 0.964 0.907 0.945 0.961 0.847 0.903 0."
        },
        {
            "title": "Method",
            "content": "FDK [42] IntraTomo [58] NeRF [37] TensoRF [10] NAF [59] SAX-NeRF [7] 3D-GS [29] X-GS [6] R2-GS [60] Ours Table 2. Comparison of our X2-Gaussian with different methods on the 4DLung and SPARE datasets. Method FDK [42] IntraTomo [58] TensoRF [10] NAF [59] X-GS [6] R2-GS [60] Ours 4DLung SPARE SSIM PSNR 0.359 27.03 0.871 34.28 0.857 34.55 0.893 34.94 0.442 29.62 37.31 0.908 38.61 0.957 32.24 0.922 SSIM PSNR 14.25 0.611 27.29 0.939 26.91 0.937 28.44 0.936 18.20 0.705 31.12 0.952 Progressive Training Procedure. During training, we first train static 3D radiative Gaussian splatting model [60] for 5000 iterations. This warm-up phase ensures that the model effectively captures the underlying anatomical structures from the projection data. After the warm-up period, we extend the framework to its full 4D form. The Gaussian parameters, spatiotemporal encoder/decoder, and the learnable respiratory period parameter ˆτ are jointly optimized using the combined loss Ltotal. This progressive training strategy enables the model to build on robust 3D reconstruction before incorporating temporal dynamics, resulting in stable convergence and high-quality dynamic reconstruction. 5. Experiments 5.1. Dataset and Implementation Details We conducted experiments on 4D CT scans from 13 patients across three public datasets: 5 patients from DIR dataset [9], 5 from 4DLung dataset [23], and 3 from SPARE dataset [45]. Each patients 4D CT consists of 10 3D CTs from different phases. We used the tomographic toolbox TIGRE [4] to simulate clinically significant one-minute 4D CT sampling. The respiratory cycle was configured at seconds, with the corresponding phase determined based on sampling time to obtain X-ray projections. For each patient, 300 projections were sampled, which is substantially fewer than the several thousand projections currently required in clinical settings. Our X2-Gaussian was implemented by PyTorch [39] and CUDA [19] and trained with the Adam optimizer [30] for 30K iterations on an RTX 4090 GPU. Learning rates for position, density, scale, and rotation are initially set at 2e4, 1e-2, 5e-3, and 1e-3, respectively, and decay exponentially to 10% of their initial values. The initial learning rates for the spatio-temporal encoder, decoder, and learnable period are set at 2e-3, 2e-4, and 2e-4, respectively, and similarly decay exponentially to 10% of their initial values. ˆτ was initialized to 1.0296 ( ˆT = 2.8). λ1 and λ2 in Lpc and Lrender were 0.25. α, β, and γ in Eq. 12 were set to 1.0, 0.05, and 0.001, respectively. During testing, We used PSNR and SSIM to evaluate the volumetric reconstruction performance. X2-Gausian predicted 10 3D CTs corresponding to the time of each phase, with PSNR calculated on the entire 3D volume and SSIM computed as the average of 2D slices in axial, coronal, and sagittal directions. 5.2. Results Tab. 1 and Tab. 2 illustrate the quantitative results of our X2Gaussian and SOTA 3D reconstruction methods which follow the phase-bining workflow, including traditional methods (FDK [42]), NeRF-based methods (IntraTomo [58], NeRF [37], TensoRF [10], NAF [59], SAX-NeRF [7]), and GS-based methods (3D-GS [29], X-GS [6], R2-GS [60]). As can be seen in Tab. 1, our method significantly outperforms other approaches in reconstruction quality. Specifically, compared to the traditional FDK method, our approach demonstrates 9.93 dB improvement in PSNR, achieving approximately 34% enhancement. When compared to state-of-the-art methods, our approach surpasses the NeRF-based method SAN-NeRF by 4.76 dB and the GS-based method R2-GS by 2.25 dB. Similar results can be observed in Tab. 2, demonstrating the superiority of our 6 Figure 5. Qualitative comparison of reconstruction results across coronal, sagittal, and axial planes. Our method shows superior performance in modeling dynamic regions (e.g. diaphragmatic motion and airway deformation) while preserving finer anatomical details compared to existing approaches. method. Fig. 5 shows the quantitative comparison of reconstruction results between our method and existing approaches. Examination of the coronal and sagittal planes shows that our method distinctly captures diaphragmatic motion with remarkable fidelity, which can be attributed to the powerful continuous-time reconstruction capability of X2-Gaussian. Similarly, on the axial plane, X2-Gaussian successfully reconstructs the deformed airways. Additionally, X2Gaussian preserves fine anatomical details that competing approaches fail to recover, underscoring its effectiveness for high-fidelity volumetric reconstruction. 5.3. Ablation study Period Optimization Tab. 3 demonstrates the effectiveness of our X2-Gaussian for respiratory cycle estimation and examines how various optimization techniques influence estimation precision. Our approach achieves exceptional accuracy with an average error of just 5.2 millisecondsapproximately one-thousandth of typical human respiratory cycle. This precision stems from two key technical contributions: Log-Space Parameterization and Bounded Cycle Shifts. Without Log-Space Parameterization, we observe oscillatory convergence behavior that compromises accuracy. More dramatically, when Bounded Cycle Shifts are omitted, the optimization incorrectly converges to harmonic frequencies rather than the fundamental cycle, resulting in 40-fold increase in estimation error. These findings highlight the critical importance of our optimization framework in achieving reliable respiratory cycle estimation. Component Analysis We conducted ablation experiments on DIR dataset to validate the effect of key components in X2-Gaussian, including the dynamic gaussian motion modeling (DGMM) and self-supervised respiratory motion learning (SSRML). Tab. 4 reports the results. As we can see, DGMM extends the static 3D radiative Gaussian splatting model to temporal domain, enabling continuoustime reconstruction and achieving improved 4D reconstruction results. Building upon this foundation, SSRML leverages the periodicity of respiratory motion to directly learn breathing patterns. Remarkably, this approach not only successfully captures specific respiratory cycles but also further enhances reconstruction quality by 0.78 dB, demonstrating its significant contribution to improving temporal coherence Figure 6. (a) Reconstruction results of X2-Gaussian using different numbers of projections. (b) Temporal variations of lung volume in 4D CT reconstructed by X2-Gaussian. and physiological motion plausibility. Table 3. Results of respiratory cycle estimation and different optimization techniques used on DIR dataset. Table 4. Ablation studies on components and hyperparameters. DGMM denotes dynamic gaussian motion modeling in Sec. 4.2, and SSRML is self-supervised respiratory motion learning in Sec. 4.3. α is the weight of periodic consistency loss in Eq. 12. Method Ours - Log-sp. param. - B. cyc. shifts - Both PSNR SSIM Est. error of (ms) 39.34 0.955 0.954 39.32 0.954 39.28 0.953 39. 5.2 12.0 216.8 914.0 Hyperparameter Analysis We further analyzed the impact of different weights α of periodic consistency loss Lpc in Tab. 4. The optimal performance is achieved when periodic consistency loss and rendering loss are equally weighted (i.e. α = 1.0), as this balance enables the model to simultaneously preserve visual fidelity while enforcing physiologically plausible temporal dynamics. When the weighting is either too high or too low, this equilibrium is disrupted, leading to performance degradation due to either over-constraining the periodic structure at the expense of reconstruction accuracy or prioritizing visual appearance without sufficient temporal coherence. 5.4. Discussion Projection Numbers Fig. 6 (a) demonstrates the reconstruction results of X2-Gaussian using different numbers of projections. As can be observed, the reconstruction quality gradually improves with an increasing number of available projections. Surprisingly, when compared with Tab. 1, we found that even when trained with only 100 X-ray images, our method still achieves better reconstruction results than the current SOTA method R2-GS using 300 X-rays (37.41 dB vs. 37.09 dB). This clearly demonstrates the powerful capability of our approach. Respiratory Motion Quantification We densely sampled our X2-Gaussian reconstructed 4D CT within 9 seconds, resulting in 180 3D CT volumes. With automated segmentation algorithm [21], we extracted lung masks and Method Baseline + DGMM PSNR 37.09 38.56 + DGMM + SSRML 39.34 38.86 39.14 39.34 38.41 α = 0.1 α = 0.5 α = 1.0 α = 2.0 SSIM 0.943 0.947 0.955 0.952 0.954 0.955 0.949 calculated the volumetric changes of the lungs over time, as displayed in Fig. 6 (b). The pulmonary volume dynamics exhibit periodic sinusoidal pattern, which precisely correlates with the subjects respiratory cycle, demonstrating that our method successfully models respiratory dynamics while achieving truly temporally continuous reconstruction. Furthermore, clinically relevant parameters can be quantitatively extracted from the volume-time curve: Tidal Volume (TV) is 370 ml, Minute Ventilation (MV) is 7.4 L/min, I:E Ratio is 1:1.9, etc. These automatically extracted clinical parameters demonstrate the potential of X2-Gaussian in radiomic-feature-guided treatment personalization. 6. Conclusion This paper presents X2-Gaussian, continuous-time 4D CT reconstruction framework that leverages dynamic radiative Gaussian splatting to capture smooth anatomical motion. Our method bypasses the limitations of phase binning and external gating by integrating dynamic Gaussian motion modeling with self-supervised respiratory motion module. Experimental results on clinical datasets demonstrate notable improvements in reconstruction fidelity and artifact suppression. This work bridges the gap between discretephase reconstruction and true 4D dynamic imaging, offering practical benefits for radiotherapy planning through improved motion analysis and patient comfort."
        },
        {
            "title": "References",
            "content": "[1] Anders Andersen and Avinash Kak. Simultaneous algebraic reconstruction technique (sart): superior implementation of the art algorithm. Ultrason. Imaging, 6(1):8194, 1984. 2 [2] Rushil Anirudh, Hyojin Kim, Jayaraman Thiagarajan, Aditya Mohan, Kyle Champley, and Timo Bremer. Lose the views: Limited angle ct reconstruction via implicit sinoIn IEEE Conf. Comput. Vis. Pattern gram completion. Recog., pages 63436352, 2018. 2 [3] Pia Baumann, Jan Nyman, Morten Hoyer, Berit Wennberg, Giovanna Gagliardi, Ingmar Lax, Ninni Drugge, Lars Ekberg, Signe Friesland, Karl-Axel Johansson, et al. Outcome in prospective phase ii trial of medically inoperable stage nonsmall-cell lung cancer patients treated with stereotactic body radiotherapy. J. Clin. Oncol., 27(20):32903296, 2009. 1 [4] Ander Biguri, Manjit Dosanjh, Steven Hancock, and Manuchehr Soleimani. Tigre: matlab-gpu toolbox for cbct image reconstruction. Biomed. Phys. Eng. Express, 2(5): 055010, 2016. 6, 1 [5] Marcus Brehm, Pascal Paysan, Markus Oelhafen, and Marc Kachelrieß. Artifact-resistant motion estimation with patient-specific artifact model for motion-compensated cone-beam ct. Med. Phys., 40(10):101913, 2013. 2 [6] Yuanhao Cai, Yixun Liang, Jiahao Wang, Angtian Wang, Yulun Zhang, Xiaokang Yang, Zongwei Zhou, and Alan Yuille. Radiative gaussian splatting for efficient x-ray novel view synthesis. In Eur. Conf. Comput. Vis., pages 283299. Springer, 2024. 2, 3, 6, [7] Yuanhao Cai, Jiahao Wang, Alan Yuille, Zongwei Zhou, and Angtian Wang. Structure-aware sparse-view x-ray 3d reconstruction. In IEEE Conf. Comput. Vis. Pattern Recog., pages 1117411183, 2024. 2, 6, 1 [8] Ang Cao and Justin Johnson. Hexplane: fast representation for dynamic scenes. In IEEE Conf. Comput. Vis. Pattern Recog., pages 130141, 2023. 4, 5 [9] Richard Castillo, Edward Castillo, Rudy Guerra, Valen Johnson, Travis McPhail, Amit Garg, and Thomas Guerrero. framework for evaluation of deformable image registration spatial accuracy using large landmark point sets. Phys. Med. Biol., 54(7):1849, 2009. 1, 6 [10] Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and In Eur. Conf. Hao Su. Tensorf: Tensorial radiance fields. Comput. Vis., pages 333350. Springer, 2022. 6, 1, 2 [11] Mingqing Chen, Kunlin Cao, Yefeng Zheng, and Alfredo Siochi. Motion-compensated mega-voltage cone beam ct using the deformation derived directly from 2d projection images. IEEE Trans. Med. Imag., 32(8):13651375, 2012. 2 [12] Joanne Davis, Clinton Medbery, Sanjeev Sharma, John Pablo, Frank Kimsey, David Perry, Alexander Muacevic, and Anand Mahadevan. Stereotactic body radiotherapy for centrally located early-stage non-small cell lung cancer or lung metastases from the rssearch patient registry. Radiat. Oncol., 10:110, 2015. [13] Achilles Fakiris, Ronald McGarry, Constantin Yiannoutsos, Lech Papiez, Mark Williams, Mark Henderson, and Robert Timmerman. Stereotactic body radiation therapy for early-stage nonsmall-cell lung carcinoma: four-year results of prospective phase ii study. Int. J. Radiat. Oncol. Biol. Phys., 75(3):677682, 2009. 1 [14] Jiemin Fang, Taoran Yi, Xinggang Wang, Lingxi Xie, Xiaopeng Zhang, Wenyu Liu, Matthias Nießner, and Qi Tian. Fast dynamic radiance fields with time-aware neural voxels. In SIGGRAPH Asia, pages 19, 2022. 4 [15] Lee Feldkamp, Lloyd Davis, and James Kress. Practical cone-beam algorithm. Journal of the Optical Society of America A, 1(6):612619, 1984. 2 [16] Sara Fridovich-Keil, Giacomo Meanti, Frederik Rahbæk Warburg, Benjamin Recht, and Angjoo Kanazawa. K-planes: Explicit radiance fields in space, time, and appearance. In IEEE Conf. Comput. Vis. Pattern Recog., pages 12479 12488, 2023. 4, 5 [17] Yabo Fu, Hao Zhang, Weixing Cai, Huiqiao Xie, Licheng Kuo, Laura Cervino, Jean Moran, Xiang Li, and Tianfang Li. Spatiotemporal gaussian optimization for 4d cone beam ct reconstruction from sparse projections. arXiv preprint arXiv:2501.04140, 2025. [18] Muhammad Usman Ghani and Clem Karl. Deep learningbased sinogram completion for low-dose ct. In IVMSP, pages 15. IEEE, 2018. 2 [19] Design Guide. Cuda programming guide. NVIDIA, July, 29:31, 2013. 6 [20] Emma Harris, Naomi Miller, Jeffrey Bamber, Richard Symonds-Tayler, and Philip Evans. Speckle tracking in phantom and feature-based tracking in liver in the presence of respiratory motion using 4d ultrasound. Phys. Med. Biol., 55(12):3363, 2010. 4 [21] Johannes Hofmanninger, Forian Prayer, Jeanny Pan, Sebastian Rohrich, Helmut Prosch, and Georg Langs. Automatic lung segmentation in routine imaging is primarily data diversity problem, not methodology problem. Eur. Radiol. Exp., 4:113, 2020. 8 [22] Dianlin Hu, Yikun Zhang, Jin Liu, Yi Zhang, Jean Louis Coatrieux, and Yang Chen. Prior: Prior-regularized iterative IEEE J. Biomed. optimization reconstruction for 4d cbct. Health Inform., 26(11):55515562, 2022. [23] Geoffrey Hugo, Elisabeth Weiss, William Sleeman, Salim Balik, Paul Keall, Jun Lu, and Jeffrey Williamson. Data from 4d lung imaging of nsclc patients. 2016. 6, 1 [24] Zhuoran Jiang, Yingxuan Chen, Yawei Zhang, Yun Ge, Fang-Fang Yin, and Lei Ren. Augmentation of cbct reconstructed from under-sampled projections using deep learning. IEEE Trans. Med. Imag., 38(11):27052715, 2019. 2 [25] Zhuoran Jiang, Zeyu Zhang, Yushi Chang, Yun Ge, FangFang Yin, and Lei Ren. Enhancement of 4-d cone-beam computed tomography (4d-cbct) using dual-encoder convolutional neural network (decnn). IEEE Trans. Radiat. Plasma Med. Sci., 6(2):222230, 2021. 2 [26] Kyong Hwan Jin, Michael McCann, Emmanuel Froustey, and Michael Unser. Deep convolutional neural network for inverse problems in imaging. IEEE Trans. Image Process., 26(9):45094522, 2017. 2 [27] Avinash Kak and Malcolm Slaney. Principles of computerized tomographic imaging. SIAM, 2001. 3 [28] Paul Keall. 4-dimensional computed tomography imaging and treatment planning. In Semin. Radiat. Oncol., pages 81 90. Elsevier, 2004. 9 [29] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkuhler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Trans. Graph., 42(4):1391, 2023. 2, 3, 6, 1 [30] Diederik Kingma and Jimmy Ba. Adam: method for arXiv preprint arXiv:1412.6980, stochastic optimization. 2014. 6 [31] Anish Lahiri, Gabriel Maliakal, Marc Klasky, Jeffrey Fessler, and Saiprasad Ravishankar. Sparse-view cone beam ct reconstruction using data-consistent supervised and adversarial learning from scarce training data. IEEE Trans. Comput. Imaging, 9:1328, 2023. 2 [32] Suhyeon Lee, Hyungjin Chung, Minyoung Park, Jonghyuk Park, Wi-Sun Ryu, and Jong Chul Ye. Improving 3d imaging with pre-trained perpendicular 2d diffusion models. In IEEE Conf. Comput. Vis. Pattern Recog., pages 1071010720, 2023. [33] Li, Eduard Schreibmann, Yang, and Xing. Motion correction for improved target localization with on-board conebeam computed tomography. Phys. Med. Biol., 51(2):253, 2005. 2 [34] Yiqun Lin, Zhongjin Luo, Wei Zhao, and Xiaomeng Li. Learning deep intensity field for extremely sparse-view cbct reconstruction. In MICCAI, pages 1323. Springer, 2023. 2 [35] Stephen Manglos, George Gagne, Andrzej Krol, Deaver Thomas, and Rammohan Narayanaswamy. Transmission maximum-likelihood reconstruction with ordered subsets for cone beam ct. Phys. Med. Biol., 40(7):1225, 1995. 2 [36] Hidenobu Matsuki, Riku Murai, Paul HJ Kelly, and Andrew Davison. Gaussian splatting slam. In IEEE Conf. Comput. Vis. Pattern Recog., pages 1803918048, 2024. 3 [37] Ben Mildenhall, Pratul Srinivasan, Matthew Tancik, Jonathan Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. Commun. ACM., 65(1):99106, 2021. 2, 6, 1 [38] Hiroshi Onishi, Hiroki Shirato, Yasushi Nagata, Masahiro Hiraoka, Masaharu Fujino, Kotaro Gomi, Katsuyuki Karasawa, Kazushige Hayakawa, Yuzuru Niibe, Yoshihiro Takai, et al. Stereotactic body radiotherapy (sbrt) for operable stage nonsmall-cell lung cancer: can sbrt be comparable to surgery? Int. J. Radiat. Oncol. Biol. Phys., 81(5):13521358, 2011. 1 [39] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Adv. Neural Inform. Process. Syst., 32, 2019. 6 [40] Jiawei Ren, Liang Pan, Jiaxiang Tang, Chi Zhang, Ang Cao, Gang Zeng, and Ziwei Liu. Dreamgaussian4d: Generative 4d gaussian splatting. arXiv preprint arXiv:2312.17142, 2023. [41] Simon Rit, Jasper Nijkamp, Marcel van Herk, and Jan-Jakob Sonke. Comparative study of respiratory motion correction techniques in cone-beam computed tomography. Radiat. Oncol., 100(3):356359, 2011. 2 [42] Thomas Rodet, Frederic Noo, and Michel Defrise. The cone-beam algorithm of feldkamp, davis, and kress preserves oblique line integrals. Med. Phys., 31(7):19721975, 2004. 2, 6, 1 [43] Leonid Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation based noise removal algorithms. Phys. D: Nonlinear Phenom., 60(1-4):259268, 1992. 5 [44] Ken Sauer and Charles Bouman. local update strategy for iterative reconstruction from projections. IEEE Trans. Signal Process., 41(2):534548, 1993. 2 [45] Chun-Chien Shieh, Yesenia Gonzalez, Bin Li, Xun Jia, Simon Rit, Cyril Mory, Matthew Riblett, Geoffrey Hugo, Yawei Zhang, Zhuoran Jiang, et al. Spare: Sparse-view reconstruction challenge for 4d cone-beam ct from 1-min scan. Med. Phys., 46(9):37993811, 2019. 6, 1 [46] Emil Sidky and Xiaochuan Pan. Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization. Phys. Med. Biol., 53(17):4777, 2008. [47] Solberg, Wang, Mao, Zhang, and Xing. Enhancement of 4d cone-beam computed tomography through constraint optimization. In ICCR, 2010. 2 [48] Jiayu Song, Qing Liu, Allan Johnson, and Cristian Badea. Sparseness prior based iterative image reconstruction for retrospectively gated cardiac micro-ct. Med. Phys., 34 (11):44764483, 2007. 2 [49] Jan-Jakob Sonke, Lambert Zijp, Peter Remeijer, and Marcel Van Herk. Respiratory correlated cone beam ct. Med. Phys., 32(4):11761186, 2005. 1 [50] Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Trans. Image Process., 13(4): 600612, 2004. 5 [51] Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Qi Tian, and Xinggang Wang. 4d gaussian splatting for real-time dynamic scene rendering. In IEEE Conf. Comput. Vis. Pattern Recog., pages 20310 20320, 2024. 3, 4, 5 [52] Yinghao Xu, Zifan Shi, Wang Yifan, Hansheng Chen, Ceyuan Yang, Sida Peng, Yujun Shen, and Gordon Wetzstein. Grm: Large gaussian reconstruction model for efficient 3d reconstruction and generation. In Eur. Conf. Comput. Vis., pages 120. Springer, 2024. [53] Chi Yan, Delin Qu, Dan Xu, Bin Zhao, Zhigang Wang, Dong Wang, and Xuelong Li. Gs-slam: Dense visual slam with 3d gaussian splatting. In IEEE Conf. Comput. Vis. Pattern Recog., pages 1959519604, 2024. 3 [54] Zeyu Yang, Hongye Yang, Zijie Pan, and Li Zhang. Real-time photorealistic dynamic scene representation and arXiv preprint rendering with 4d gaussian splatting. arXiv:2310.10642, 2023. 3 [55] Lifeng Yu, Yu Zou, Emil Sidky, Charles Pelizzari, Peter Munro, and Xiaochuan Pan. Region of interest reconstruction from truncated data in circular cone-beam ct. IEEE transactions on medical imaging, 25(7):869881, 2006. 2 [56] Zehao Yu, Anpei Chen, Binbin Huang, Torsten Sattler, and Andreas Geiger. Mip-splatting: Alias-free 3d gaussian splatIn IEEE Conf. Comput. Vis. Pattern Recog., pages ting. 1944719456, 2024. 3 [57] Vladimir Yugay, Yue Li, Theo Gevers, and Martin Oswald. Gaussian-slam: Photo-realistic dense slam with gaussian splatting. arXiv preprint arXiv:2312.10070, 2023. 3 [58] Guangming Zang, Ramzi Idoughi, Rui Li, Peter Wonka, and Wolfgang Heidrich. Intratomo: self-supervised learningbased tomography via sinogram synthesis and prediction. In IEEE Conf. Comput. Vis. Pattern Recog., pages 19601970, 2021. 6, 1, 2 [59] Ruyi Zha, Yanhao Zhang, and Hongdong Li. Naf: neural attenuation fields for sparse-view cbct reconstruction. In MICCAI, pages 442452. Springer, 2022. 2, 6, 1 [60] Ruyi Zha, Tao Jun Lin, Yuanhao Cai, Jiwen Cao, Yanhao Zhang, and Hongdong Li. R2-gaussian: Rectifying radiative gaussian splatting for tomographic reconstruction. arXiv preprint arXiv:2405.20693, 2024. 2, 3, 5, 6, 1 [61] Dongbin Zhang, Chuming Wang, Weitao Wang, Peihao Li, Minghan Qin, and Haoqian Wang. Gaussian in the wild: 3d In gaussian splatting for unconstrained image collections. Eur. Conf. Comput. Vis., pages 341359. Springer, 2024. 3 [62] Shaohua Zhi, Marc Kachelrieß, and Xuanqin Mou. Highquality initial image-guided 4d cbct reconstruction. Med. Phys., 47(5):20992115, 2020. 2 [63] Shaohua Zhi, Marc Kachelrieß, Fei Pan, and Xuanqin Mou. Cycn-net: convolutional neural network specialized for 4d IEEE Trans. Med. Imag., 40(11): cbct images refinement. 30543064, 2021. 11 X2-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction"
        },
        {
            "title": "Supplementary Material",
            "content": "tomography methods: NeRF [37] (using MLP-based volumetric scene representation) ,IntraTomo [58] (using large MLP for density field modeling), TensoRF [10] (utilizing tensor decomposition for efficient scene representation), NAF [59] (featuring hash encoding for faster training), and SAX-NeRF [7] (employing line segment-based transformer). The implementations of NAF and SAX-NeRF used their official code with default hyperparameters, while NeRF, IntraTomo, and TensoRF were implemented using code from the NAF repository. All NeRF-based methods were trained for 150,000 iterations. We also evaluated three SOTA 3DGS-based methods: 3DGS [29] (introducing realtime rendering with 3D Gaussians), X-GS [6] (incorporating radiative properties into Gaussian Splatting), and R2GS [60] (proposing tomographic reconstruction approach to Gaussian Splatting). Since 3DGS and X-GS lack the capability for tomographic reconstruction, following [6], we leveraged their novel view synthesis abilities to generate an additional 100 X-ray images from new viewpoints for each 3D CT. These synthesized views, together with the training data, were used with the FDK algorithm to perform reconstruction. All 3DGS-based methods used their official code with default hyperparameters. All experiments were executed on single NVIDIA RTX 4090 GPU. 9. More Quantitative Results Tab. 5 and Tab. 6 present the comparative results for each patient in the 4DLung dataset and DIR dataset, respectively. Our method achieved optimal reconstruction results for nearly all patients across both datasets. 7. Details of Dataset DIR Dataset We collected 4D CT scans from the DIR dataset [9], which were acquired from patients with malignant thoracic tumors (esophageal or lung cancer). Each 4D CT was divided into 10 3D CT volumes based on respiratory signals captured by real-time position management respiratory gating system [28]. For each patient, the CT dimensions are 256 256 in the and axes, while the z-axis dimension varies from 94 to 112 slices. The z-axis resolution is 2.5 mm, and the xy-plane resolution ranges between 0.97 and 1.16 mm. The CT scan coverage encompasses the entire thoracic region and upper abdomen. Following the approach in literature [7, 59], we preprocessed the original data by normalizing the density values to the range of [0, 1]. We simulated the classical one-minute sampling protocol used in clinical settings by uniformly sampling 300 paired time points and angles within one-minute duration and 0 to 360 angular range. Based on the respiratory phase corresponding to each timestamp, we selected the appropriate 3D CT volume, and then utilized the tomographic imaging toolbox TIGRE [4] to capture 512 512 projections. 4DLung Dataset 4D CTs in 4DLung dataset [23] were collected from non-small cell lung cancer patients during their chemoradiotherapy treatment. All scans were respiratory-synchronized into 10 breathing phases. For each patient, the CT scans have dimensions of 512 512 pixels in the transverse plane, with the number of axial slices varying between 91 and 135. The spatial resolution is 0.9766 to 1.053 mm in the transverse plane and 3 mm in the axial direction. Following the same pipeline as DIR dataset, We captured 300 projections with sizes of 1024 1024. SPARE Dataset The 4D CT images from the SPARE dataset [45] have dimensions of 450 450 pixels in the transverse plane and 220 slices in the axial direction, with an isotropic spatial resolution of 1.0 mm in all directions. Following the same methodology as the DIR dataset, we acquired 300 projections, each with dimensions of 512 512 pixels. 8. Implementation details of baseline methods We conducted comparison with various 3D reconstruction methods, which were directly applied to 4D reconstruction under the phase binning workflow. Traditional algorithm FDK [42] was implemented using the GPU-accelerated TIGRE toolbox [4]. We evaluated five SOTA NeRF-based 1 Table 5. Comparison of our X2-Gaussian with different methods on the 4DLung dataset. Patient Patient2 Patient3 Patient4 Patient"
        },
        {
            "title": "Average",
            "content": "PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM 0.611 27.36 0.939 30.39 0.937 30.42 0.936 30.76 30.62 0.705 0.952 33.19 34.49 0.929 40.44 0.957 39.94 0.966 38.10 0.943 40.06 0.973 38.61 0.957 27.59 0.654 28.76 35.02 0.941 35.29 35.14 35.86 0.944 35.47 0.947 36.30 29.98 0.773 30.88 38.96 0.939 37.29 22.98 35.73 36.67 37.46 25.16 39.22 28.48 34.99 34.64 34.69 31.45 37.90 27.03 34.28 34.55 34.94 29.62 37.31 0.646 0.926 0.907 0.901 0.709 0. 0.410 0.930 0.931 0.932 0.526 0.972 0.662 0.938 0.933 0.934 0.722 0.960 0.684 0.960 0.969 0.964 0.792 0."
        },
        {
            "title": "Method",
            "content": "FDK [42] IntraTomo [58] TensoRF [10] NAF [59] X-GS [6] R2-GS [60] Ours Table 6. Comparison of our X2-Gaussian with different methods on the SPARE dataset. Method FDK [42] IntraTomo [58] TensoRF [10] NAF [59] X-GS [6] R2-GS [60] Ours Patient1 Patient Patient3 Average PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM 0.359 9.85 0.871 27.55 0.857 26.88 0.893 28.67 0.442 14.16 30.04 0.908 31.38 0.920 32.47 0.907 32.87 0.939 32.24 0.922 11.85 27.83 27.21 29.25 17.37 32.06 21.04 26.48 26.64 27.39 23.06 31.26 0.232 0.889 0.863 0.908 0.328 0. 0.229 0.864 0.832 0.880 0.356 0.901 0.616 0.860 0.877 0.892 0.652 0.916 14.25 27.29 26.91 28.44 18.20 31."
        }
    ],
    "affiliations": [
        "Johns Hopkins University",
        "The Australian National University",
        "The Chinese University of Hong Kong",
        "University of Texas at Austin"
    ]
}