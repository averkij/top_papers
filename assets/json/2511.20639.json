{
    "paper_title": "Latent Collaboration in Multi-Agent Systems",
    "authors": [
        "Jiaru Zou",
        "Xiyuan Yang",
        "Ruizhong Qiu",
        "Gaotang Li",
        "Katherine Tieu",
        "Pan Lu",
        "Ke Shen",
        "Hanghang Tong",
        "Yejin Choi",
        "Jingrui He",
        "James Zou",
        "Mengdi Wang",
        "Ling Yang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS."
        },
        {
            "title": "Start",
            "content": "Latent Collaboration in Multi-Agent Systems Jiaru Zou1,2,*,, Xiyuan Yang2,*,, Ruizhong Qiu2,, Gaotang Li2,, Katherine Tieu2,, Pan Lu3,, Ke Shen , Hanghang Tong2, Yejin Choi3, Jingrui He2, (cid:66), James Zou3, (cid:66), Mengdi Wang1, (cid:66), Ling Yang1, (cid:66) 1Princeton University 2University of Illinois Urbana-Champaign 3Stanford University *Co-Leadership Core Contributors (cid:66)Corresponding Authors Code: https://github.com/Gen-Verse/LatentMAS Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. shared latent working memory then preserves and transfers each agents internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4-4.3 faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. 5 2 0 2 ] . [ 2 9 3 6 0 2 . 1 1 5 2 : r Figure 1 Evaluation of LatentMAS across (i) accuracy performance (%), (ii) inference speed (times(s)/run), and (ii) token usage (per token) over 9 benchmarks and 3 LLM model scales under the Hierarchical MAS setting. LatentMAS consistently improves system-level reasoning accuracy while substantially reducing computational overhead compared with single model and text-based MAS. Contact: Ling Yang, ly1988@princeton.edu. Work done when Jiaru visits Princeton. Latent Collaboration in Multi-Agent Systems 1. Introduction Model collaboration emerges as the foundation of system-level intelligence in the era of Agentic AI (Acharya et al., 2025). Recent advances in multi-agent systems (MAS) (Hong et al., 2023; Hu et al., 2025; Wu et al., 2024) have catalyzed paradigm shift from solitary, model-centric reasoning into collaborative endeavor among multiple interacting models. Among these, large language model (LLM)-based MAS has been adopted across various downstream applications, including cooperative math and science reasoning (Pezeshkpour et al., 2024; Zhou et al., 2025), distributed tool-use in open-domain QA (Jin et al., 2025; Li et al., 2025d), and embodied decision-making in robotics (Feng et al., 2025; Li et al., 2025c). Within LLM-based MAS, natural language or text generally serves as the lingua francathe common medium that carries each agents internal thoughts and enables communication across different agents (Guo et al., 2024). Beyond explicit text, several studies have explored the use of LLMs continuous latent space as new form of model language, (Chen et al., 2025b) by either (i) leveraging hidden representations within transformers to enable single models internal latent chain-of-thought (CoT) reasoning (Hao et al., 2024; Zhang et al., 2025; Zheng et al., 2025), or (ii) employing KV caches or layer embeddings for information exchange across two models (Fu et al., 2025; Liu et al., 2024). However, comprehensive model collaboration framework unifying both latent reasoning and latent communication remains unexplored. Moving one step forward, we investigate: Can multi-agent systems achieve pure latent collaboration? To address this question, we introduce LatentMAS, an end-to-end collaborative framework that operates entirely within the continuous latent space. Our core design integrates both internal latent thoughts generation and cross-agent latent working memory transfer. Inside each agent, reasoning unfolds through auto-regressive generation of last-layer hidden representations, capturing the models ongoing internal thoughts without explicit decoding. Across agents, information is exchanged via shared latent working memory stored in layer-wise KV caches, capturing both the input context and newly generated latent thoughts. Overall, LatentMAS is completely training-free, enabling all agents to think and interact purely through their internal latent representations. Building on our framework design, LatentMAS is grounded on three foundational principles, verified by comprehensive theoretical and empirical analyses: Reasoning Expressiveness: Hidden representations naturally encode models continuous thoughts, allowing each latent step to convey far richer information than discrete tokens. Communication Fidelity: Latent working memory preserves input representations and latent thoughts of each model, enabling lossless cross-agent information transfer. Collaboration Complexity: LatentMAS achieves higher collaborative expressiveness of TextMAS while achieving significantly lower inference complexity. The first two principles jointly underscore the advantage of LatentMAS by enabling richer latent reasoning and lossless latent communication. The third principle further provides an overall complexity analysis, showing that LatentMAS achieves substantially lower computational complexity than textbased MAS while maintaining higher level of model expressiveness. To empirically assess the efficacy of LatentMAS, we conduct comprehensive evaluations on nine benchmarks spanning math and science reasoning, commonsense understanding, and code generation, as illustrated in Figure 1. Across both sequential and hierarchical MAS settings and three backbone scales (4B, 8B, and 14B (Yang et al., 2025)), LatentMAS consistently outperforms strong singlemodel and text-based MAS baselines by (i) improving accuracy by up to 14.6%, (ii) reducing output Latent Collaboration in Multi-Agent Systems token usage by 70.8%-83.7%, and (iii) delivering 4-4.3 faster end-to-end inference. These results demonstrate that latent collaboration not only enhances system-level reasoning quality but also provides substantial efficiency gains without any additional training. Further detailed analyses of latent thought expressiveness, working-memory transfer, and inputoutput alignment confirm that LatentMAS enables semantically meaningful, lossless, and stable collaboration entirely in latent space. 2. Preliminary and Notations Auto-regressive Generation in Transformer. Let ğ‘“ğœƒ() denotes the function computed by standard Transformer model (Vaswani et al., 2017), parameterized by ğœƒ. Given an input sequence ğ‘¥ = (ğ‘¥1, ğ‘¥2, . . . , ğ‘¥ğ‘‡ ), the transformer ğ‘“ğœƒ() first encodes each token via its input embedding layer ğ‘Šin to obtain token embeddings up to step ğ‘¡, i.e., ğ¸ = [ğ‘’1, ğ‘’2, . . . , ğ‘’ğ‘¡] â„ğ‘¡ğ‘‘â„, where ğ‘‘â„ is the models hidden dimension. The input token embeddings ğ¸ then successively process through ğ¿ transformer layers in the forward pass through the models residual stream, yielding the final-layer hidden representations ğ» = [â„1, â„2, . . . , â„ğ‘¡] â„ğ‘¡ğ‘‘â„. For next token generation, the model computes: ğ‘“ğœƒ(ğ‘¥ğ‘¡+1 ğ‘¥ğ‘¡) = softmax(â„ğ‘¡ğ‘Šout), (1) where ğ‘Šout denotes the language model head that maps the hidden representation to the vocabulary space. Each token is generated in an auto-regressive manner and appended to the input sequence. For latent space generation, the model feeds the last hidden state from the previous token directly as the next input embedding without explicit decoding (Hao et al., 2024; Zhu et al., 2025). KV Cache as Working Memory. In decoder-only Transformers, the Key-Value (KV) cache functions as dynamic working memory during auto-regressive generation, storing intermediate representations from previous decoding steps to avoid redundant computation. Specifically, given the input embeddings ğ¸, each transformer layer projects them through projection matrices ğ‘Šğ‘„, ğ‘Šğ¾, ğ‘Šğ‘‰ to obtain ğ‘„, ğ¾, ğ‘‰. When the next token at step ğ‘¡ + 1 is generated, the model appends its embedding to the input sequence and updates the cache (ğ¾cache, ğ‘‰cache) as: ğ¾cache [ğ¾ğ‘¡; ğ¾ğ‘¡+1], ğ‘‰cache [ğ‘‰ğ‘¡; ğ‘‰ğ‘¡+1], (2) where ğ¾ğ‘¡, ğ‘‰ğ‘¡ are accumulated key/value matrices from all previous steps and ğ¾ğ‘¡+1, ğ‘‰ğ‘¡+1 are new key/value vectors computed from the current tokens hidden state. This accumulative property enables the KV cache to maintain growing working memory of model internal representations. LLM-based MAS Setting. We consider multi-agent system composed of ğ‘ agents, denoted as = { ğ´1, ğ´2, . . . , ğ´ğ‘ }, where each agent ğ´ğ‘– is an LLM corresponding to ğ‘“ğœƒğ‘– above. At inference time, an input question ğ‘ is provided to the system S, which orchestrates interactions among agents to collaboratively produce final answer ğ‘ corresponding to ğ‘. As MAS design paradigms are not definitive in general and often vary across downstream tasks (Cemri et al., 2025; Tran et al., 2025), we do not restrict our latent collaboration design to any particular architecture. Instead, we adopt two most commonly used MAS settings (sequential and hierarchical) as the bases to experimentally evaluate our method. Figure 2 illustrates the two MAS architecture settings. In the sequential MAS, we adopt chain-of-agents design (Zhang et al., 2024b; Zhao et al., 2025a) comprising four LLM agents: planner, critic, refiner, and solver. These agents assume complementary reasoning roles and are organized in sequential pipeline, Figure 2 Illustration of sequential and hierarchical MAS. 3 Latent Collaboration in Multi-Agent Systems Figure 3 Overview of LatentMAS. Each LLM agent in the system first generates latent thoughts through last-layer hidden states, then transfers information layer-wise via shared latent working memory stored in KV-caches, enabling completely system-wide latent collaboration. where the CoT output of each agent with the question ğ‘ serves as the input to the next agent. In the hierarchical MAS, we adopt domain-specialized design (Zhao et al., 2025b; Zhuge et al., 2024). Multiple LLM agents, including code, math, and science agents, operate as different domain experts. Each agent independently reasons over the question ğ‘ from its disciplinary perspective. summarizer agent then receives all intermediate responses along with the question ğ‘ and performs hierarchical aggregation to synthesize and refine the final answer. 3. Building Latent Collaborative Multi-Agent System We introduce LatentMAS, an end-to-end latent collaboration framework that, given an input question, all agents reason and communicate entirely within the latent space and only decode the final answer in text. Our method enables LLM agents within the system to (i) perform super-expressive thoughts generation in the latent space (Section 3.1), (ii) preserve and transfer each agents latent working memory with lossless fidelity across interactions (Section 3.2), and (iii) achieve substantially lower complexity than vanilla text MAS while maintaining the same level of expressiveness (Section 3.3). Method Roadmap. In following sections, we present the complete pipeline of LatentMAS, detailing each component and interleaving theoretical analyses to justify the corresponding design principles. 3.1. Auto-regressive Latent Thoughts Generation in Agents. We start by describing, inside each LLM agent, how the model performs latent reasoning through its layer-wise hidden states. Instead of generating explicit tokens, reasoning unfolds directly within the model by auto-regressively appending hidden representations produced by the final transformer layer. 4 Latent Collaboration in Multi-Agent Systems Specifically, given the input embeddings ğ¸ = [ğ‘’1, ğ‘’2, . . . , ğ‘’ğ‘¡] containing the information from the question ğ‘ and each agents instruction prompt, each LLM agent ğ´ğ‘– passes ğ¸ through ğ¿ transformer layers to compute the last-layer hidden representation â„ğ‘¡ at current step ğ‘¡. Then, we insert â„ğ‘¡ as the input embedding for the next step ğ‘¡ + 1, replacing the original decoding and next-token embedding processes used in standard token generation. We auto-regressively repeat the process for ğ‘š latent steps, yielding sequence of newly generated last-layer hidden states ğ» = [â„ğ‘¡+1, â„ğ‘¡+2, . . . , â„ğ‘¡+ğ‘š]. We define the continuous output representations ğ» as the latent thoughts generated by ğ´ğ‘–. Input-Output Distribution Alignment. Since the newly generated ğ» form sequence of dense, high-level representations, directly inserting them into shallow layers as input embeddings may lead to out-of-distribution activations (Meegahapola et al., 2019; Zhou et al., 2019) , as these hidden states differ from the statistical patterns of learned token embeddings. To mitigate this in training-free manner, we propose linear alignment operator that maps last-layer hidden states back to the valid input embeddings. Specifically, given ğ‘Šin, ğ‘Šout as the input and output embedding layers of ğ´ğ‘–, we seek projection matrix ğ‘Šğ‘ â„ğ‘‘â„ ğ‘‘â„ that maps each output vector â„ ğ» to new input vector ğ‘’ to align with valid input space defined by ğ‘Šin: ğ‘’ = â„ğ‘Šğ‘, where ğ‘Šğ‘ ğ‘Š 1 out ğ‘Šin, (3) ğ‘œğ‘¢ğ‘¡ is the pseudo-inverse of ğ‘Šğ‘œğ‘¢ğ‘¡ where the ğ‘Š 1 1. We then append the aligned vector ğ‘’ into the input sequence for auto-regressive latent generation. Note that ğ‘Šğ‘ is small projection matrix of size ğ‘‘â„ ğ‘‘â„ (e.g., ğ‘‘â„=1024 for Qwen3-0.6B) and is computed once and reused in all subsequent latent steps. This design makes the alignment computationally negligible while maintaining distributional consistency between latent and discrete representations. In Appendix A.2, we further provide detailed theoretical justification for the effectiveness of ğ‘Šğ‘ during the input-output alignment process. Expressiveness on Continuous Latent Thoughts. With the mechanism of latent thought generation established within each agent, we next provide theoretical analysis to quantify its representational advantage over conventional discrete token generation. The following theorem formalizes that latent thoughts, which inherently preserve richer semantic structures, achieve substantially higher expressive capacity than discrete text-based reasoning. Theorem 3.1 (Expressiveness of Latent Thoughts). Under the Linear Representation Hypothesis on â„ (detailed in Assumption B.1), if the sequence of all latent thoughts with length ğ‘š can be expressed losslessly through corresponding text-based reasoning, then the length of text (in tokens) needs to be at least Î©(cid:0)ğ‘‘â„ğ‘š/log (cid:1), where > 1 denotes the vocabulary size. Remark 3.2. Theorem 3.1 suggests that latent thoughts generation can be ğ‘‚(cid:0)ğ‘‘â„/log (cid:1) times more efficient than text-based reasoning. In addition, the expressiveness scales linearly with ğ‘‘â„, implying that larger models inherently exhibit greater latent reasoning capacity. As an illustration to Remark 3.2, for Qwen3-4B / 8B / 14B models (Yang et al., 2025), latent thoughts generation can be 235.7 / 377.1 / 471.4 times more efficient than text-based reasoning. The full proof of Theorem 3.1 is provided in Appendix B.1. Beyond reasoning within individual agents, collaboration in LatentMAS further relies on how these agents exchange latent information, which we detail next. 3.2. Working Memory Preservation and Thoughts Transfer across Agents. In text-based MAS, after one LLM agent completes its generation, the natural language output is directly appended to the input sequence of the next agent. However, since each agent in LatentMAS 1As ğ‘Šout is typically non-square, its true inverse cannot be directly calculated as is. In practice, we compute ğ‘Šğ‘ in ğ¹ } , which can be Equation 3 by solving ridge regression (Hoerl and Kennard, 1970): minğ‘Šğ‘ {ğ‘Šoutğ‘Šğ‘ ğ‘Šin 2 computed efficiently in polynomial complexity by ğ‘Šğ‘ = (ğ‘Š out ğ‘Šin (Detailed in A.1). ğ‘Šout + ğœ† ğ¼) 1ğ‘Š out ğ¹ + ğœ† ğ‘Šğ‘ 2 5 Latent Collaboration in Multi-Agent Systems performs hidden-state generation without explicit text outputs, we design new latent working memory transfer mechanism to ensure lossless information preservation and exchange. For clarity, we describe the transfer mechanism using the first two consecutive LLM agents ğ´1, ğ´2 in LatentMAS. As shown in Figure 3, agent ğ´1 first performs ğ‘š latent steps of generation (Section 3.1). After completing these steps, we extract the KV-caches from all ğ¿ transformer layers of ğ´1 once, and define its latent working memory as: ğ´1 = (cid:110)(cid:16) ğ¾ (ğ‘™) ğ´1,cache where ğ¾ (ğ‘™) ğ´1,cache , ğ‘‰ (ğ‘™) ğ‘™ = 1, 2, . . . , ğ¿ (cid:17) (cid:12) (cid:12) (cid:12) , . . . , ğ¾ (ğ‘™) ğ´1,ğ‘¡+ğ‘š], (cid:111) , ğ‘‰ (ğ‘™) ğ´1,cache = [ğ‘‰ (ğ‘™) ğ´1,1 , . . . , ğ‘‰ (ğ‘™) ğ´1,ğ‘¡+ğ‘š]. (4) ğ´1,cache = [ğ¾ (ğ‘™) ğ´1, ğ´1,cache and ğ‘‰ (ğ‘™) Here ğ¾ (ğ‘™) ğ´1,cache are accumulated key and value matrices at the ğ‘™-th layer. Unlike existing cache-sharing methods (Fu et al., 2025; Ye et al., 2025a) that exchange information only on prefilled input context across models, the collection of layer-wise caches in ğ´1 encapsulates both the initial input context and the newly generated latent thoughts of agent ğ´1. Next, the successive agent ğ´2 integrates the working memory ğ´1 from agent ğ´1. Before ğ´2 generates latent thoughts (i.e., last-layer hidden states), we perform layer-wise concatenation to update its KV cache by prepending each ğ¾ (ğ‘™) ğ´2,cache. By doing so, the new latent thoughts generation in ğ´2 is conditioned on both the working memory of ğ´1 and its own internal representations. ğ´1,cache to existing ğ¾ (ğ‘™) ğ´1,cache and ğ‘‰ (ğ‘™) ğ´2,cache and ğ‘‰ (ğ‘™) Lossless Information Transfer. The latent working memory transfer mechanism ensures that each succeeding agent in LatentMAS seamlessly receives its predecessors complete output without reencoding. The following theorem formalizes this property, showing that latent working memory transfer guarantees information fidelity equivalent to explicit input exchange. Theorem 3.3 (Information Preservation via Latent Working Memory). In both latent and text-based reasoning, the outputs of an agent when receiving latent working memory from preceding agents are equivalent to those obtained when directly inputting the preceding agents outputs. The full proof of Theorem 3.3 is provided in B.2. In addition, with lossless information preservation, we transfer latent working memory in KV rather than directly transmitting hidden states to avoid redundant recomputation for the successive agent. 3.3. End-to-End Pipeline with Complexity Analyses For the remaining agents in LatentMAS, we follow the same latent thoughts generation and working memory transfer mechanism described above. Specifically, agent ğ´3 inherits the working memory ğ´2 from the preceding agent ğ´2, performs auto-regressive last-layer hidden state generation, and subsequently transmits its updated latent working memory ğ´3 to the next agent. This process continues across all agents in LatentMAS, with only the last agent decoding the final answer. Below, we theoretically analyze the overall complexity of our framework. Theorem 3.4 (LatentMAS Complexity). The time complexity for each agent of LatentMAS is ğ‘š + ğ‘‘â„ğ‘š2 + ğ‘‘â„ğ‘¡ğ‘š)ğ¿(cid:1), where ğ‘¡ is the input length of this agent, and ğ‘š is the length of latent ğ‘‚(cid:0)(ğ‘‘2 â„ thoughts. In contrast, assuming Theorem 3.1, the time complexity for each agent of the vanilla (cid:1) to achieve text-based MAS needs to be ğ‘‚(cid:0)(cid:0)ğ‘‘3 the same expressiveness. log + ğ‘‘ â„ ğ‘š 1 1 log2 (cid:1) ğ¿ + ğ‘‘2 ğ‘¡ğ‘š 1 + ğ‘‘2 â„ ğ‘š log log ğ‘š2 â„ â„ Proof of Theorem 3.4 is provided in B.3. Note that LatentMAS is agnostic to specific model collaboration strategies and can be seamlessly applied to sequential, hierarchical, or other advanced MAS designs. 6 Latent Collaboration in Multi-Agent Systems Table 1 Main results of LatentMAS on 6 general tasks under the Sequential MAS setting. We report 3 metrics in total, including task accuracy (%, Acc.\"), total output token usage (Token\"), and end-to-end inference speed (time(s) / run, Speed\"). We compare LatentMAS with both TextMAS and single-model (Single\") baselines. For each metric, we bold the better performance and visualize LatentMAS gains over TextMAS in the Improve columns. Tasks Metrics Qwen3-4B Improve Qwen3-8B Improve Qwen3-14B Improve Single TextMAS LatentMAS Single TextMAS LatentMAS Single TextMAS LatentMAS ARC-E ARC-C GSM8K Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. HumanEval+ Token Speed MBPP+ MedQA 95.4 724 369 89.2 913 97 82.4 1136 469 47.7 2134 236 63.5 1634 523 75.0 2380 274 96.4 2420 2874 90.0 2678 1579 89.8 3172 1970 65.3 3962 1267 69.8 4420 2148 79.7 5987 1044 Sequential MAS Setting 98.6 581 512 92.3 718 260 88.2 607 375 66.3 1685 438 73.5 1339 577 79.9 1775 2.2 95.6 76.0% 656 5.6 404 2.3 91.0 73.2% 846 6.1 266 1.6 81.1 80.9% 1280 5.3 449 1.0 53.0 57.5% 2098 2.9 476 3.7 64.8 69.7% 2053 3.7 1064 0.2 74.4 70.4% 2507 3.0 502 99.1 2085 3702 94.6 2252 2059 92.3 2324 1739 75.0 4260 1923 69.5 3695 3628 80.5 4593 1619 98.8 490 1759 94.4 529 703 93.8 860 543 75.3 1555 928 74.6 1164 1275 80.5 1866 497 0.3 97.2 76.5% 608 2.1 551 0.2 92.6 76.5% 773 2.9 338 1.5 83.7 63.0% 1118 3.2 536 0.3 64.7 63.5% 1746 2.1 1360 5.1 68.5 68.5% 1858 2.8 2410 0.0 76.8 59.4% 2366 3.3 1084 99.0 1670 9171 95.9 2985 5125 93.8 3324 3729 80.3 3444 4142 72.8 4971 8728 81.1 5934 4062 99.4 224 2124 95.6 426 1136 95.2 644 1952 80.7 1841 1420 75.7 1621 2400 86.5 2042 0.4 86.6% 4.3 0.3 85.7% 4.5 1.4 80.6% 1.9 0.4 46.5% 2.9 2.9 67.4% 3.6 5.4 65.6% 3.2 Table 2 Main results of LatentMAS on 6 general tasks under the Hierarchical MAS setting. We report accuracy, token usage, and end-to-end speed, and highlight the performance gains following the same evaluation protocol as in Table 1. Tasks Metrics Qwen3-4B Improve Qwen3-8B Improve Qwen3-14B Improve Single TextMAS LatentMAS Single TextMAS LatentMAS Single TextMAS LatentMAS ARC-E ARC-C GSM8K Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. Token Speed Acc. HumanEval+ Token Speed MBPP+ MedQA 95.4 724 369 89.2 913 97 82.4 1136 469 47.7 2134 236 63.5 1634 523 75.0 2380 274 97.1 2054 2239 92.5 2674 1275 89.4 3098 1878 65.0 6702 1495 69.3 6782 1766 76.2 8127 931 Hierarchical MAS Setting 96.8 363 591 91.7 447 299 88.4 555 360 67.3 1015 557 70.6 1339 489 79.3 1373 333 0.3 95.6 82.3% 656 3.8 404 0.8 91.0 83.3% 846 4.3 266 1.0 81.1 82.1% 1280 5.2 449 2.3 53.0 84.9% 2098 2.7 476 1.3 64.8 80.3% 2053 3.6 1064 3.1 74.4 83.1% 2507 2.8 98.2 2237 3619 93.3 2854 2034 90.4 2370 1365 76.3 6893 3387 71.9 7703 3898 76.8 8768 1809 98.3 308 1779 93.9 344 714 89.5 353 702 77.0 1007 964 72.2 1264 1387 78.0 1274 439 0.1 97.2 86.2% 608 2.0 551 0.6 92.6 87.9% 773 2.8 338 0.9 83.7 85.1% 1118 1.9 536 0.7 64.7 85.4% 1746 3.5 1360 0.3 68.5 83.6% 1858 2.8 2410 1.2 76.8 85.5% 2366 4.1 1084 98.3 2752 7102 95.3 2167 4283 90.8 3021 3675 78.0 5473 7591 73.0 7458 9162 84.1 8114 3988 98.7 619 1884 95.5 295 1090 91.6 495 1631 78.3 899 1250 73.8 1187 2507 86.6 1512 1188 0.4 77.5% 3.8 0.2 86.4% 3.9 0.8 83.6% 2.3 0.3 83.6% 6.1 0.8 84.1% 3.7 2.5 81.4% 3. 4. Empirical Evaluations Tasks and Datasets. We conduct comprehensive evaluation of LatentMAS across nine benchmarks spanning both general-purpose and reasoning-intensive tasks: (i) Math & Science Reasoning, including GSM8K (Cobbe et al., 2021), AIME24 (Maxwell-Jia, 2024), AIME25 (math ai, 2025), GPQA-Diamond (Rein et al., 2023), and MedQA (Yang et al., 2024a); (ii) Commonsense Reasoning, including ARC-Easy 7 Latent Collaboration in Multi-Agent Systems Table 3 Main results of LatentMAS on 3 reasoning-intensive tasks under both Sequential and Hierarchical MAS settings. We report accuracy, token usage, and end-to-end speed, and highlight the performance gains following the same evaluation protocol as in Table 1. Tasks Metrics Qwen3-8B Improve Qwen3-14B Improve Single TextMAS LatentMAS Single TextMAS LatentMAS AIME24 50.0 Acc. Token 12891 421 Speed 46.7 Acc. Token 14692 Speed Acc. GPQA-Diamond Token Speed 450 39.9 6435 813 AIME25 AIME 50.0 Acc. Token 12891 421 Speed 46.7 Acc. Token 14692 Speed Acc. GPQA-Diamond Token Speed 450 39.9 6435 813 AIME25 Sequential MAS Setting 53.3 38596 2808 53.3 45088 3150 43.4 17986 5771 56.7 8953 688 53.3 8699 820 45.5 4571 3.4 63.3 76.8% 11263 4.1 1018 0.0 56.7 80.7% 11298 3.8 1040 2.1 48.5 74.6% 5547 6.8 1043 Hierarchical MAS Setting 53.3 42629 3132 50.0 53929 3488 43.0 22450 6108 53.3 7526 776 50.0 13230 616 46.9 3395 798 0.0 63.3 82.3% 11263 4.0 1018 0.0 56.7 75.5% 11298 5.7 1040 3.9 48.5 84.9% 5547 7.7 1043 63.3 32092 4554 60.0 44618 5184 51.5 12676 70.0 29025 5718 66.7 50003 6019 52.0 20931 9119 66.7 10593 1149 63.3 11402 1473 52.0 5454 1475 73.3 10230 1089 66.7 9527 1056 53.0 3606 1458 3.4 67.0% 4.0 3.3 74.4% 3.5 0.5 57.0% 6.6 3.3 64.8% 5.3 0.0 80.9% 5.7 1.0 82.8% 6.3 (Clark et al., 2018b) and ARC-Challenge (Clark et al., 2018a); and (iii) Code Generation, including MBPP-Plus (Liu et al., 2023) and HumanEval-Plus (Liu et al., 2023). Detailed descriptions of each benchmark are provided in Appendix C.1. Models and Baselines. We adopt three off-the-shelf models from the Qwen3 family (Yang et al., 2025) (4B, 8B, and 14B) to construct LatentMAS at different scales. For baseline comparison, we evaluate LatentMAS against: (i) Single LLM agents (Single), where single LLM directly performs standard auto-regressive generation with token-level decoding; (ii) Sequential text-based MAS (Sequential TextMAS), following the chain-of-agents design (Zhang et al., 2024b) with text-mediated reasoning and communication; and (iii) Hierarchical text-based MAS (Hierarchical TextMAS), where domainspecialized agents collaborate through summarizer (Zhuge et al., 2024) using text-based reasoning and communication. Detailed model and baseline implementations are provided in Appendix C.2. Implementation Details. For latent thoughts generation, we compute the realignment matrix ğ‘Šğ‘ once per run and reuse it across all inference steps. Each LLM agent performs ğ‘š {0, 10, 20, 40, 80} latent steps during reasoning. For working memory transfer, we directly concatenate the KV caches from the immediately preceding agent into the corresponding transformer layers through the past_key_values interface in HuggingFace Transformers (Face, 2025). Besides the HuggingFace implementation, we also integrate all baseline methods and LatentMAS with the vLLM backend (Kwon et al., 2023), enabling prefix caching and tensor-parallel inference for efficient deployment of larger LLM agents. We perform hyperparameter tuning and report the mean performance over three independent runs. Across both baselines and our method, we set all LLM agents with temperature of 8 Latent Collaboration in Multi-Agent Systems Figure 4 Efficiency gains of LatentMAS over single model and TextMAS under the sequential MAS setting. Left: LatentMAS achieves substantially faster end-to-end inference, even though all baselines are accelerated with vLLM backend. Right: LatentMAS requires far fewer system-wise token usage. 0.6 and top-ğ‘ of 0.95. We adjust the maximum output length for each task according to its relative difficulty. We set the maximum length to 2,048 tokens for ARC-Eacy, ARC-Challenge, and GSM8K, 4096 tokens for MedQA, MBPP+, and Humaneval+, 8,192 tokens for GPQA and 20,000 tokens for AIME24/25. All experiments are conducted on 8NVIDIA A100-80G GPUs. 4.1. LatentMAS Delivers Higher Accuracy with Efficient Collaboration Main Results. Tables 1, 2, and 3 report the overall performance of LatentMAS across 9 general and reasoning-intensive benchmarks built from 3 different scales of LLM backbones. To thoroughly examine collaboration behaviors during inference, we evaluate each method from three complementary perspectives: (i) task accuracy, (ii) system throughput (total output tokens), and (iii) end-to-end inference speed. Across all tasks, LatentMAS consistently improves over the single-model baseline by an average of 14.6% and 13.3% under the sequential and hierarchical settings, respectively, and further yields gains of 2.8% and 4.6% over text-based MAS. Under identical MAS architectures, LatentMAS provides 4 and 4.3 faster inference speed on average compared with sequential and hierarchical text-based MAS. Additionally, as the entire collaboration occurs entirely in latent space, LatentMAS reduces token usage significantly by 70.8% and 83.7% relative to sequential and hierarchical TextMAS. Superior Efficiency on Latent Collaboration. As early established in Theorem 3.1, LatentMAS can theoretically achieve orders-of-magnitude higher efficiency than text-based MAS. We further empirically validate this advantage through efficiency analyses comparing LatentMAS with TextMAS. As visualized in Figure 1 and 4 (left), even after accelerating the TextMAS baselines using the vLLM service, LatentMAS still achieves 2.6-7 speedup over the vLLM-optimized TextMAS. This improvement stems from the substantially reduced number of latent steps required for latent thoughts generation compared with the much larger decoding steps needed for per-token text generation. For instance, with fewer than 50 latent steps, LatentMAS attains comparable or even higher performance on reasoning-intensive tasks such as AIME 24/25, whereas TextMAS typically requires more than 20K output tokens to complete full text-based CoT trajectories. In addition, as illustrated in Figure 1 and 4 (right), LatentMAS reduces token usage by 59.4%-87.9% compared with TextMAS, as agents in LatentMAS communicate by directly transferring latent working memory into another agents internal layers rather than relying on text-based medium. Noteably, LatentMAS also achieves 15.0%-60.3% lower token usage than single agents. Compared with singlemodel reasoning, LatentMAS distributes the input question across multiple collaborating agents, greatly reducing the burden on the final agent, which primarily aggregates preceding latent thoughts 9 Latent Collaboration in Multi-Agent Systems Figure 5 Illustration of the semantic meaning encoded by latent thoughts in LatentMAS. Newly generated latent thought embeddings in LatentMAS largely cover the embedding space of text-based generated tokens, indicating semantic consistency and greater expressive capacity than discrete text. and decodes the final answer using only small number of tokens. As result, the entire system generates fewer output tokens while still achieving higher accuracy. 4.2. In-depth Analyses on LatentMAS Do Latent Thoughts Reflect Text Reasoning? We first verify whether latent thoughts generation in LatentMAS produces meaningful and semantically expressive representations. To this end, we compare the distribution of newly generated last-layer embeddings in LatentMAS with the embeddings of token-by-token responses produced by TextMAS. Experiments are conducted on 300 MedQA questions, using 40 latent steps for LatentMAS and 4096 max-token budget for the TextMAS baseline. As shown in Figure 5, we highlight two key observations: (i) The last-layer embeddings from LatentMAS share nearly the same region of the embedding space with the token embeddings from TextMAS, indicating that latent thoughts encode similar semantic representations as the correct text responses. (ii) The last-layer embeddings from LatentMAS largely cover the distribution of token embeddings from TextMAS, indicating that latent thoughts offer greater diversity and expressive capacity than discrete tokens. Together, these findings show that latent thoughts not only capture the valid semantics of their corresponding text responses but also encode richer and more expressive representations inside. We further include case study in Appendix analyzing how LLM agents in LatentMAS interpret their own latent thoughts to provide additional validation for our claim. Figure 6 Effectiveness of the input-output alignment ğ‘Šğ‘ on MedQA. Unaligned output embeddings (â„ğ‘¡) drift away from the original input embeddings (ğ‘’ğ‘¡), while the aligned vectors (ğ‘’ğ‘¡+1) realign with ğ‘’ğ‘¡, demonstrating that ğ‘Šğ‘ preserves embedding-space structure and prevents representation drift. 10 Latent Collaboration in Multi-Agent Systems ğ‘š 0 10 40 80 160 ARC-C 91.3 93.4 93.4 94.9 94.8 93.7 ARC-E 94.7 98.9 98.9 99.4 99.6 98.3 GSM8K 85.6 90.3 90.9 91.4 92.0 91.9 Figure 7 Downstream performance before/after applying the input-output alignment ğ‘Šğ‘. Figure 8 Effectiveness of different latent step depths of LatentMAS on downstream performance. Effectiveness on Input-Output Alignment. We next empirically evaluate the effectiveness of the input-output alignment in our method design. First, we compare the input vector ğ‘’ğ‘¡ obtained from the standard token embedding layer with both the newly generated output vector â„ğ‘¡ before alignment and the after-aligned vector ğ‘’ğ‘¡+1. As shown in Figure 6, we visualize the three embedding vectors by comparing both density distributions and geometric relationships in the projected embedding space. We observe that the new â„ğ‘¡ deviates largely from the original input embedding ğ‘’ğ‘¡. After applying ğ‘Šğ‘, the aligned vector ğ‘’ğ‘¡+1 realigns with ğ‘’ğ‘¡, indicating that ğ‘Šğ‘ effectively restores the geometric and statistical structure of the input embedding space and mitigates representation drift across iterative latent steps. In Figure 7, we further compare downstream performance before and after applying ğ‘Šğ‘ and observe consistent accuracy gains of 2.3%-5.3% brought by ğ‘Šğ‘. Optimal Latent Step Depth. To understand how many latent steps are needed for optimal performance in LatentMAS, we analyze the effect of increasing latent step depth across three downstream tasks. As shown in Figure 8, increasing the number of latent steps generally improves downstream performance, indicating that additional latent thoughts enhance collaborative expressiveness. Across the three tasks on Qwen3-14B, we find that accuracy steadily rises and peaks around 40-80 steps. Beyond this range, performance plateaus or declines, suggesting that excessive latent thought generation may introduce redundant or less useful information. Based on this observation, we adopt moderate latent step budget within this range in practice, as it consistently provides the best accuracy-efficiency trade-off without requiring any task-specific training procedures. 5. Related Work LLM-based Multi-agent Systems. Recent studies in Agentic AI have extended classical multi-agent systems (Park et al., 2023a; Yang et al., 2024b) grounded in traditional reinforcement learning and policy coordination (Li et al., 2025b; Tan et al., 2025), to modern LLM settings, enabling models to operate as autonomous agents that collaborate in reasoning, planning, and problem-solving (Tao et al., 2024; Wang et al., 2025b; Zhao et al., 2025b). Early investigations, such as ReAct (Yao et al., 2022), AutoGen (Wu et al., 2024), and CAMEL (Li et al., 2023), coordinate multiple LLMs through explicit dialogue or role assignment to improve task diversity and reliability. Additional methods introduce structured communication protocols or training paradigms to enhance cooperation efficiency (Chen et al., 2025a; Yan et al., 2025; Ye et al., 2025a; Zou et al., 2025) and emergent specialization (Huang et al., 2025; Mieczkowski et al., 2025) among agents. In summary, large amount of prior works follow 11 Latent Collaboration in Multi-Agent Systems sequential planner-solver pipelines or hierarchical expert-summarizer structures, which correspond to the two MAS settings we adopt for evaluating LatentMAS. Beyond algorithmic advances, LLM-based MAS have been applied across diverse domains, such as math and science reasoning (Pezeshkpour et al., 2024; Yue et al., 2024), open-domain question answering (Fourney et al., 2024; Wu et al., 2025), and multi-modal GUI interaction (Ye et al., 2025b; Zhang et al., 2024a), demonstrating their versatility in complex real-world settings. Building upon these advanced text-MAS methods, our work aims to enable latent-based multi-agent collaboration system, treating agents as tightly integrated components that achieve more efficient coordination and expressive capabilities. Model Collaboration in Latent Space. Recent works on model ensemble collaboration (Sagi and Rokach, 2018; Zhang and Ma, 2012) have shifted from text-level coordination to latent-space interaction. For example, ThoughtComm (Zheng et al., 2025) learns shared latent space and routes agent information through trained encoderdecoder and prefix modules on top of frozen LLMs. Cache-to-Cache (Fu et al., 2025) enables semantic transfer across two models by projecting the sharer models input-prompts KV into receiver model. Mixture of Thoughts (Fein-Ashley et al., 2025) leverages primary expert model to aggregate cross-attention information of other models, enabling single-pass, centrally controlled latent fusion. On the other hand, LatentMAS is training-free latent MAS in which each model first generates its own latent thoughts, and then the input with the newly generated thoughts is transferred from one model to another for subsequent collaboration. Latent Reasoning in LLMs. Beyond explicit chain-of-thought (CoT) reasoning, recent work has explored the continuous latent space of LLMs as an alternative reasoning medium (Chen et al., 2025b; Hao et al., 2024), revealing that hidden states encode richer semantic structures than what discrete token generation can express (Liu et al., 2024; Zhang et al., 2025). Latent reasoning methods such as CoCoNut (Hao et al., 2024) and latent-space editing approaches (e.g., RepE (Zou et al., 2023), LoT (Fungwacharakorn et al., 2024)) demonstrate that manipulating internal representations can guide models to reason more coherently and improve controllability without explicit token-level rationales. Other works (Fein-Ashley and Fein-Ashley, 2025; Li et al., 2025a; Wang et al., 2025a) have also extended latent reasoning paradigms to vision-language models. These methods leverage the structure of hidden states to perform interventions, such as steering, editing, or optimizing latent trajectories, that shape downstream reasoning behavior while remaining agnostic to surface-level text. By operating directly in the continuous space, they can induce reasoning steps that would be difficult or inefficient to express (Coda-Forno et al., 2025; Liu et al., 2024; Zhang et al., 2025). Despite these benefits, existing techniques are confined to single models internal computations and do not consider interaction or coordination across multiple reasoning entities (Hao et al., 2024). On the other hand, LatentMAS extends latent reasoning to multi-agent setting, enabling each agent to generate latent thoughts and propagate latent information to others. Our new framework shifts latent reasoning from an isolated capability of individual models to system-level collaborative mechanism. 6. Conclusion We introduced LatentMAS, training-free framework that enables multi-agent systems to collaborate entirely within the continuous latent space. By combining latent auto-regressive reasoning with lossless latent working-memory transfer mechanism, LatentMAS overcomes the inherent inefficiencies and information bottlenecks of text-based collaboration. Our theoretical analyses establish substantial gains in expressiveness and computational efficiency, and our empirical results across diverse reasoning, commonsense, and code-generation benchmarks demonstrate that latent collaboration consistently improves accuracy performance, token usage, and decoding speed over strong single-model and text-based MAS baselines. Together, LatentMAS serves as scalable and general paradigm for building next-generation agentic systems that cooperate beyond the limits of natural language. An exciting Latent Collaboration in Multi-Agent Systems future direction is to adapt advanced post-training paradigms from text-based MAS to optimize LatentMAS latent collaboration protocols to unlock more effective multi-agent reasoning strategies."
        },
        {
            "title": "References",
            "content": "D. B. Acharya, K. Kuppan, and B. Divya. Agentic ai: Autonomous intelligence for complex goalsa comprehensive survey. IEEe Access, 2025. S. K. Ainsworth, J. Hayase, and S. Srinivasa. Git re-basin: Merging models modulo permutation symmetries. arXiv preprint arXiv:2209.04836, 2022. M. Cemri, M. Z. Pan, S. Yang, L. A. Agrawal, B. Chopra, R. Tiwari, K. Keutzer, A. Parameswaran, D. Klein, K. Ramchandran, et al. Why do multi-agent llm systems fail? arXiv preprint arXiv:2503.13657, 2025. W. Chen, J. Yuan, C. Qian, C. Yang, Z. Liu, and M. Sun. Optima: Optimizing effectiveness and efficiency for llm-based multi-agent system. In Findings of the Association for Computational Linguistics: ACL 2025, pages 1153411557, 2025a. X. Chen, A. Zhao, H. Xia, X. Lu, H. Wang, Y. Chen, W. Zhang, J. Wang, W. Li, and X. Shen. Reasoning beyond language: comprehensive survey on latent chain-of-thought reasoning. arXiv preprint arXiv:2505.16782, 2025b. P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018a. P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018b. K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers to solve math word problems, 2021. URL https://arxiv.org/abs/2110.14168. J. Coda-Forno, Z. Zhao, Q. Zhang, D. Tamboli, W. Li, X. Fan, L. Zhang, E. Schulz, and H.-P. Tseng. Exploring system 1 and 2 communication for latent reasoning in llms. arXiv preprint arXiv:2510.00494, 2025. H. Face. Transformers documentation. https://huggingface.co/docs/transformers/en/ index, 2025. B. Fein-Ashley and J. Fein-Ashley. Bridging hidden states in vision-language models. arXiv preprint arXiv:2511.11526, 2025. J. Fein-Ashley, D. Parikh, R. Kannan, and V. Prasanna. Mixture of thoughts: Learning to aggregate what experts think, not just what they say. arXiv preprint arXiv:2509.21164, 2025. Z. Feng, R. Xue, L. Yuan, Y. Yu, N. Ding, M. Liu, B. Gao, J. Sun, X. Zheng, and G. Wang. Multi-agent embodied ai: Advances and future directions. arXiv preprint arXiv:2505.05108, 2025. A. Fourney, G. Bansal, H. Mozannar, C. Tan, E. Salinas, F. Niedtner, G. Proebsting, G. Bassman, J. Gerrits, J. Alber, et al. Magentic-one: generalist multi-agent system for solving complex tasks. arXiv preprint arXiv:2411.04468, 2024. 13 Latent Collaboration in Multi-Agent Systems T. Fu, Z. Min, H. Zhang, J. Yan, G. Dai, W. Ouyang, and Y. Wang. Cache-to-cache: Direct semantic communication between large language models. arXiv preprint arXiv:2510.03215, 2025. W. Fungwacharakorn, N. H. Thanh, M. M. Zin, and K. Satoh. Layer-of-thoughts prompting (lot): Leveraging llm-based retrieval with constraint hierarchies. arXiv preprint arXiv:2410.12153, 2024. T. Guo, X. Chen, Y. Wang, R. Chang, S. Pei, N. V. Chawla, O. Wiest, and X. Zhang. Large language model based multi-agents: survey of progress and challenges. arXiv preprint arXiv:2402.01680, 2024. S. Hao, S. Sukhbaatar, D. Su, X. Li, Z. Hu, J. Weston, and Y. Tian. Training large language models to reason in continuous latent space. arXiv preprint arXiv:2412.06769, 2024. A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1):5567, 1970. S. Hong, M. Zhuge, J. Chen, X. Zheng, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, et al. Metagpt: Meta programming for multi-agent collaborative framework. In The Twelfth International Conference on Learning Representations, 2023. M. Hu, Y. Zhou, W. Fan, Y. Nie, B. Xia, T. Sun, Z. Ye, Z. Jin, Y. Li, Q. Chen, et al. Owl: Optimized workforce learning for general multi-agent assistance in real-world task automation. arXiv preprint arXiv:2505.23885, 2025. Q. Huang, Z. Zhou, Y. Li, K. Yang, B. Wang, and Y. Wang. Many minds, one goal: Time series forecasting via sub-task specialization and inter-agent cooperation. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. B. Jin, H. Zeng, Z. Yue, J. Yoon, S. Arik, D. Wang, H. Zamani, and J. Han. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025. W. Kwon, Z. Li, S. Zhuang, Y. Sheng, L. Zheng, C. H. Yu, J. Gonzalez, H. Zhang, and I. Stoica. Efficient memory management for large language model serving with pagedattention. In Proceedings of the 29th symposium on operating systems principles, pages 611626, 2023. B. Li, X. Sun, J. Liu, Z. Wang, J. Wu, X. Yu, H. Chen, E. Barsoum, M. Chen, and Z. Liu. Latent visual reasoning. arXiv preprint arXiv:2509.24251, 2025a. G. Li, H. A. Al Kader Hammoud, H. Itani, D. Khizbullin, and B. Ghanem. Camel: communicative agents for \"mind\" exploration of large language model society. In Proceedings of the 37th International Conference on Neural Information Processing Systems, NIPS 23, Red Hook, NY, USA, 2023. Curran Associates Inc. Z. Li, Q. Ji, X. Ling, and Q. Liu. comprehensive review of multi-agent reinforcement learning in video games. IEEE Transactions on Games, 2025b. Z. Li, W. Wu, Y. Guo, J. Sun, and Q.-L. Han. Embodied multi-agent systems: review. IEEE/CAA Journal of Automatica Sinica, 12(6):10951116, 2025c. Z. Li, H. Zhang, S. Han, S. Liu, J. Xie, Y. Zhang, Y. Choi, J. Zou, and P. Lu. In-the-flow agentic system optimization for effective planning and tool use. arXiv preprint arXiv:2510.05592, 2025d. J. Liu, C. S. Xia, Y. Wang, and L. Zhang. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. Advances in Neural Information Processing Systems, 36:2155821572, 2023. 14 Latent Collaboration in Multi-Agent Systems L. Liu, J. Pfeiffer, J. Wu, J. Xie, and A. Szlam. Deliberation in latent space via differentiable cache augmentation. arXiv preprint arXiv:2412.17747, 2024. math ai. AIME 2025 dataset. https://huggingface.co/datasets/math-ai/aime25, 2025. Maxwell-Jia. AIME 2024 dataset. https://huggingface.co/datasets/Maxwell-Jia/AIME_ 2024, 2024. L. Meegahapola, V. Subramaniam, L. Kaplan, and A. Misra. Prior activation distribution (pad): versatile representation to utilize dnn hidden units. arXiv preprint arXiv:1907.02711, 2019. E. Mieczkowski, R. Mon-Williams, N. Bramley, C. G. Lucas, N. Velez, and T. L. Griffiths. Predicting multi-agent specialization via task parallelizability. arXiv preprint arXiv:2503.15703, 2025. J. S. Park, J. OBrien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122, 2023a. K. Park, Y. J. Choe, and V. Veitch. The linear representation hypothesis and the geometry of large language models. arXiv preprint arXiv:2311.03658, 2023b. P. Pezeshkpour, E. Kandogan, N. Bhutani, S. Rahman, T. Mitchell, and E. Hruschka. Reasoning capacity in multi-agent systems: Limitations, challenges and human-centered solutions. arXiv preprint arXiv:2402.01108, 2024. D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman. Gpqa: graduate-level google-proof q&a benchmark, 2023. URL https://arxiv.org/abs/ 2311.12022. O. Sagi and L. Rokach. Ensemble learning: survey. Wiley interdisciplinary reviews: data mining and knowledge discovery, 8(4):e1249, 2018. L. Tan, F. Wei, X. Ma, R. Peng, H. Xiao, and L. Yang. Systemic condition-based maintenance optimization under inspection uncertainties: customized multiagent reinforcement learning approach. IEEE Transactions on Reliability, 2025. W. Tao, Y. Zhou, Y. Wang, W. Zhang, H. Zhang, and Y. Cheng. Magis: Llm-based multi-agent framework for github issue resolution. Advances in Neural Information Processing Systems, 37:5196351993, 2024. K.-T. Tran, D. Dao, M.-D. Nguyen, Q.-V. Pham, B. OSullivan, and H. D. Nguyen. Multi-agent collaboration mechanisms: survey of llms. arXiv preprint arXiv:2501.06322, 2025. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. Q. Wang, Y. Shi, Y. Wang, Y. Zhang, P. Wan, K. Gai, X. Ying, and Y. Wang. Monet: Reasoning in latent visual space beyond images and language. arXiv preprint arXiv:2511.21395, 2025a. Z. Wang, S. Moriyama, W.-Y. Wang, B. Gangopadhyay, and S. Takamatsu. Talk structurally, act hierarchically: collaborative framework for llm multi-agent systems. arXiv preprint arXiv:2502.11098, 2025b. Latent Collaboration in Multi-Agent Systems M. Wortsman, G. Ilharco, S. Y. Gadre, R. Roelofs, R. Gontijo-Lopes, A. S. Morcos, H. Namkoong, A. Farhadi, Y. Carmon, S. Kornblith, et al. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In International conference on machine learning, pages 2396523998. PMLR, 2022. F. Wu, Z. Li, F. Wei, Y. Li, B. Ding, and J. Gao. Talk to right specialists: Routing and planning in multi-agent system for question answering. arXiv preprint arXiv:2501.07813, 2025. Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang, S. Zhang, J. Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversations. In First Conference on Language Modeling, 2024. B. Yan, Z. Zhou, L. Zhang, L. Zhang, Z. Zhou, D. Miao, Z. Li, C. Li, and X. Zhang. Beyond self-talk: communication-centric survey of llm-based multi-agent systems. arXiv preprint arXiv:2502.14321, 2025. A. Yang, A. Li, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Gao, C. Huang, C. Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. H. Yang, H. Chen, H. Guo, Y. Chen, C.-S. Lin, S. Hu, J. Hu, X. Wu, and X. Wang. Llm-medqa: Enhancing medical question answering through case studies in large language models. arXiv preprint arXiv:2501.05464, 2024a. Y. Yang, Q. Peng, J. Wang, Y. Wen, and W. Zhang. Llm-based multi-agent systems: Techniques and business perspectives. arXiv preprint arXiv:2411.14033, 2024b. S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations, 2022. H. Ye, Z. Gao, M. Ma, Q. Wang, Y. Fu, M.-Y. Chung, Y. Lin, Z. Liu, J. Zhang, D. Zhuo, et al. Kvcomm: Online cross-context kv-cache communication for efficient llm-based multi-agent systems. arXiv preprint arXiv:2510.12872, 2025a. J. Ye, X. Zhang, H. Xu, H. Liu, J. Wang, Z. Zhu, Z. Zheng, F. Gao, J. Cao, Z. Lu, et al. Mobile-agent-v3: Fundamental agents for gui automation. arXiv preprint arXiv:2508.15144, 2025b. L. Yue, S. Xing, J. Chen, and T. Fu. Clinicalagent: Clinical trial multi-agent system with large language model-based reasoning. In Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics, pages 110, 2024. C. Zhang and Y. Ma. Ensemble machine learning, volume 144. Springer, 2012. C. Zhang, S. He, J. Qian, B. Li, L. Li, S. Qin, Y. Kang, M. Ma, G. Liu, Q. Lin, et al. Large language model-brained gui agents: survey. arXiv preprint arXiv:2411.18279, 2024a. Y. Zhang, R. Sun, Y. Chen, T. Pfister, R. Zhang, and S. Arik. Chain of agents: Large language models collaborating on long-context tasks. Advances in Neural Information Processing Systems, 37: 132208132237, 2024b. Z. Zhang, X. He, W. Yan, A. Shen, C. Zhao, S. Wang, Y. Shen, and X. E. Wang. Soft thinking: Unlocking the reasoning potential of llms in continuous concept space. arXiv preprint arXiv:2505.15778, 2025. J. Zhao, H. Xie, Y. Lei, X. Song, Z. Shi, L. Li, S. Liu, and H. Zhang. Connecting the dots: chain-ofcollaboration prompting framework for llm agents. arXiv preprint arXiv:2505.10936, 2025a. Latent Collaboration in Multi-Agent Systems W. Zhao, M. Yuksekgonul, S. Wu, and J. Zou. Sirius: Self-improving multi-agent systems via bootstrapped reasoning. arXiv preprint arXiv:2502.04780, 2025b. Y. Zheng, Z. Zhao, Z. Li, Y. Xie, M. Gao, L. Zhang, and K. Zhang. Thought communication in multiagent collaboration. arXiv preprint arXiv:2510.20733, 2025. H. Zhou, H. Geng, X. Xue, L. Kang, Y. Qin, Z. Wang, Z. Yin, and L. Bai. Reso: reward-driven self-organizing llm-based multi-agent system for reasoning tasks. arXiv preprint arXiv:2503.02390, 2025. W. Zhou, J. Du, and X. Ren. Improving bert fine-tuning with embedding normalization. arXiv preprint arXiv:1911.03918, 2019. H. Zhu, S. Hao, Z. Hu, J. Jiao, S. Russell, and Y. Tian. Reasoning by superposition: theoretical perspective on chain of continuous thought. arXiv preprint arXiv:2505.12514, 2025. M. Zhuge, W. Wang, L. Kirsch, F. Faccio, D. Khizbullin, and J. Schmidhuber. Language agents as optimizable graphs. arXiv preprint arXiv:2402.16823, 2024. A. Zou, L. Phan, S. Chen, J. Campbell, P. Guo, R. Ren, A. Pan, X. Yin, M. Mazeika, A.-K. Dombrowski, et al. Representation engineering: top-down approach to ai transparency. arXiv preprint arXiv:2310.01405, 2023. J. Zou, Y. Ban, Z. Li, Y. Qi, R. Qiu, L. Yang, and J. He. Transformer copilot: Learning from the mistake log in LLM fine-tuning. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. 17 Latent Collaboration in Multi-Agent Systems"
        },
        {
            "title": "Table of Contents",
            "content": "A Input-Output Alignment in LatentMAS 19 A.1 Solving the Alignment Matrix ğ‘Šğ‘ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 A.2 Theoretical Justification on ğ‘Šğ‘ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Theoretical Analysis 22 B.1 Proof of Theorem 3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 B.2 Proof of Theorem 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 B.3 Proof of Theorem 3.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Experiment Setups C.1 Evaluation Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 C.2 Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 C.3 Additional Discussions on LatentMAS . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Case Study Prompt Template for LatentMAS 27 29 18 Latent Collaboration in Multi-Agent Systems"
        },
        {
            "title": "Appendix",
            "content": "A. Input-Output Alignment in LatentMAS A.1. Solving the Alignment Matrix ğ‘Šğ‘ In Section 3.1, we put the last-layer hidden states â„ back to the input sequence to enable the models latent reasoning. However, since the â„ is not perfectly aligned with the input embedding space, directly feeding â„ into shallow layers may lead to out-of-distribution activation patterns inside LLMs. To mitigate this in training-free way, we seek matrix ğ‘Šğ‘ which maps â„ to valid input space (i.e., ğ‘’ = â„ğ‘Šğ‘). straightforward way to calculate ğ‘Šğ‘ is to enforce that the aligned latent vector ğ‘’ behaves similarly to real input embedding when it enters the model. Motivated by our Theorem A.1 below, this corresponds to the following minimization problem: min ğ‘Šğ‘ ğ‘Šoutğ‘Šğ‘ ğ‘Šin2 ğ¹ . (5) This objective is quadratic in ğ‘Šğ‘, so we can derive closed-form solution by setting its derivative to zero, which yields the normal equation: ğ‘Š out ğ‘Šoutğ‘Šğ‘ ğ‘Š out ğ‘Šin = 0. (6) Solving for ğ‘Šğ‘ gives: ğ‘Šout For numerical stability, we further add small hyperparameter ğœ† > 0 to obtain ridge regression solution: ğ‘Šin. (7) ğ‘Šğ‘ = (cid:0)ğ‘Š out (cid:1) 1ğ‘Š out ğ‘Šğ‘ = (cid:0)ğ‘Š out ğ‘Šout + ğœ† ğ¼(cid:1) 1ğ‘Š out ğ‘Šin, (8) which we compute once and reuse for all latent reasoning steps. A.2. Theoretical Justification on ğ‘Šğ‘ In this section, we outline the theoretical justification for how ğ‘Šğ‘ minimizes the distributional gap between the distribution of token embeddings and the distribution of aligned embeddings. Let ğ‘ƒğ‘’ and ğ‘ƒâ„ be the distribution of token embeddings ğ‘’ and the hidden embeddings â„, respectively. We assume that ğ‘ƒğ‘’ and ğ‘ƒâ„ can be generated by ğ‘’ = ğ‘Šin,ğ‘¥ and â„ = ğ‘Šout,ğ‘¥, respectively, where token ğ‘¥ follows an underlying token distribution ğ‘¥ ğ‘ƒV. For an alignment matrix ğ‘Šğ‘, the aligned embedding distribution ğ‘ƒË†ğ‘’,ğ‘Šğ‘ is ğ‘ƒË†ğ‘’,ğ‘Šğ‘ : Ë†ğ‘’ = â„ğ‘Šğ‘, â„ ğ‘ƒâ„. (9) Our goal is to minimize the distance between the aligned embedding distribution ğ‘ƒË†ğ‘’,ğ‘Šğ‘ and the token embedding distribution ğ‘ƒğ‘’, which we measure via the Wasserstein distance: ğ‘‘Wasserstein(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’) := inf ğ›¾Î“(ğ‘ƒğ‘’,ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ”¼ (Ë†ğ‘’,ğ‘’)ğ›¾ [Ë†ğ‘’ ğ‘’2 ], where Î“(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’) is the set of all couplings of ğ‘ƒğ‘’ and ğ‘ƒË†ğ‘’,ğ‘Šğ‘. (10) 19 Latent Collaboration in Multi-Agent Systems Theorem A.1 (Upper Bound on Distribution Alignment). Suppose that the rows of ğ‘Šin and ğ‘Šout are mutually distinct. Then for any non-singular alignment matrix ğ‘Šğ‘, the Wasserstein distance between ğ‘ƒğ‘’ and ğ‘ƒË†ğ‘’,ğ‘Šğ‘ is upper bounded by ğ‘‘Wasserstein(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’) ğ‘Šoutğ‘Šğ‘ ğ‘Šin ğ¹ . (11) As we show in Appendix A.1, our choice of ğ‘Šğ‘ (Equation 3) minimizes this upper bound of ğ‘Š (ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’). Proof. Consider the following joint distribution ğ›¾(Ë†ğ‘’, ğ‘’): ğ›¾(Ë†ğ‘’, ğ‘’) := ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’]1[ğ‘Šin,ğ‘¥ =ğ‘’] . Since the rows of ğ‘Šin are mutually distinct, then for every Ë†ğ‘’, ğ›¾(Ë†ğ‘’, ğ‘’) = ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’]1[ğ‘Šin,ğ‘¥ =ğ‘’] ğ‘’supp(ğ‘ƒğ‘’ ) = = ğ‘’supp(ğ‘ƒğ‘’ ) ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’] ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’] ğ‘’supp(ğ‘ƒğ‘’ ) 1[ğ‘Šin,ğ‘¥ =ğ‘’] ğ‘¥ = ğ‘ƒË†ğ‘’,ğ‘Šğ‘ (Ë†ğ‘’); and since the rows of ğ‘Šout are mutually distinct, and ğ‘Šğ‘ is non-singular, then for every ğ‘’, ğ›¾(Ë†ğ‘’, ğ‘’) = Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) = = Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ‘ƒV (ğ‘¥)1[ğ‘Šin,ğ‘¥ =ğ‘’] ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šin,ğ‘¥ =ğ‘’] ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’]1[ğ‘Šin,ğ‘¥ =ğ‘’] 1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’] Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ‘¥ = ğ‘ƒğ‘’(ğ‘’). (12) (13) (14) (15) (16) (17) (18) (19) (20) 20 Latent Collaboration in Multi-Agent Systems This implies ğ›¾ Î“(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’). It follows that ğ”¼ (Ë†ğ‘’,ğ‘’)ğ›¾ [Ë†ğ‘’ ğ‘’2 2 ] inf ğ›¾Î“(ğ‘ƒğ‘’,ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ”¼ (Ë†ğ‘’,ğ‘’)ğ›¾ [Ë†ğ‘’ ğ‘’2 2 ] Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ‘’supp(ğ‘ƒğ‘’ ) ğ›¾(Ë†ğ‘’, ğ‘’)Ë†ğ‘’ ğ‘’2 (21) (22) (23) Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ‘’supp(ğ‘ƒğ‘’ ) ğ‘¥ ğ‘ƒV (ğ‘¥)1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’]1[ğ‘Šin,ğ‘¥ =ğ‘’] Ë†ğ‘’ ğ‘’2 2 (24) ğ‘‘Wasserstein(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ , ğ‘ƒğ‘’) = = = = = ğ‘¥ ğ‘¥ ğ‘¥ ğ‘ƒV (ğ‘¥) Ë†ğ‘’supp(ğ‘ƒË†ğ‘’,ğ‘Šğ‘ ) ğ‘’supp(ğ‘ƒğ‘’ ) ğ‘ƒV (ğ‘¥)ğ‘Šout,ğ‘¥ğ‘Šğ‘ ğ‘Šin,ğ‘¥ 2 2 ğ‘Šout,ğ‘¥ğ‘Šğ‘ ğ‘Šin,ğ‘¥ 2 = ğ‘Šoutğ‘Šğ‘ ğ‘Šin2 ğ¹ = ğ‘Šoutğ‘Šğ‘ ğ‘Šin ğ¹ . 1[ğ‘Šout,ğ‘¥ğ‘Šğ‘=Ë†ğ‘’]1[ğ‘Šin,ğ‘¥ =ğ‘’] Ë†ğ‘’ ğ‘’2 2 (25) (26) (27) (28) (29) 21 Latent Collaboration in Multi-Agent Systems B. Theoretical Analysis B.1. Proof of Theorem 3.1 Assumption B.1 (Linear Representation Hypothesis; Park et al., 2023b). We assume that the hidden embeddings â„ are linear combinations (cid:205)ğ‘‘â„ ğ‘ğ‘–ğ‘ ğ‘– of an underlying semantic basis {ğ‘ 1, . . . , ğ‘ ğ‘‘â„ } â„ğ‘‘â„ ğ‘–=1 (linearly independent) with ternary coefficients ğ‘1, . . . , ğ‘ğ‘‘â„ {0, 1}, where ğ‘ğ‘– = 0 represents that â„ does not have semantic ğ‘–, and ğ‘ğ‘– = 1 represents that â„ has semantic ğ‘– in positive/negative way. Theorem B.1 (Restate of Theorem 3.1). Under the Linear Representation Hypothesis on â„, if the sequence of all latent thoughts with length ğ‘š can be expressed losslessly through corresponding text-based reasoning, then the length of text (in tokens) needs to be at least Î©(cid:0)ğ‘‘â„ğ‘š/log (cid:1), where > 1 denotes the vocabulary size. Proof of Theorem 3.1. Under Assumption B.1, the set of hidden embeddings is = (cid:26) ğ‘‘â„ ğ‘–=1 ğ‘ğ‘–ğ‘ ğ‘– : ğ‘1, . . . , ğ‘ğ‘‘â„ {0, 1} (cid:27) , (30) where {ğ‘ 1, . . . , ğ‘ ğ‘‘â„ } â„ğ‘‘â„ is the underlying semantic basis. Then, the set of length-ğ‘¡ latent reasoning sequences is ğ‘š. Since the semantic basis is linearly independent, the size of the set of hidden embeddings is = {0, 1} {ğ‘ 1,...,ğ‘ ğ‘‘â„ } = 3ğ‘‘â„ . Thus, the size of the set of length-ğ‘š latent reasoning sequences is ğ‘š = ğ‘š = (3ğ‘‘â„)ğ‘š = 3ğ‘‘â„ğ‘š. (31) (32) To represent the set ğ‘š of length-ğ‘š latent reasoning sequences via the set ğ‘š reasoning sequences losslessly, there needs to exist an surjective map from ğ‘š that ğ‘š ğ‘š. Therefore, of length-ğ‘š text-based to ğ‘š, which implies ğ‘š = log (V ğ‘š ) = log ğ‘š log ğ‘š = log (3ğ‘‘â„ğ‘š) = ğ‘‘â„ğ‘š log 3 log = Î© (cid:16) ğ‘‘â„ğ‘š log (cid:17) . (33) (34) (35) B.2. Proof of Theorem 3.3 Theorem B.2 (Restate of Theorem 3.3). In both latent and text-based reasoning, the outputs of an agent when receiving latent working memory from preceding agents are equivalent to those obtained when directly inputting the preceding agents outputs. Proof. Let â„(ğ‘™) , ğ¾ (ğ‘™) , ğ‘‰ (ğ‘™) and â„(ğ‘™) , ğ¾ (ğ‘™) , ğ‘‰ (ğ‘™) denote the output, keys, and values of ğ‘™-th transformer layer when receiving latent working memory from preceding agents and when directly inputting the preceding agents outputs, respectively. In the following, we will use induction to show that â„(ğ‘™) = â„ (ğ‘™) for every layer ğ‘™ = 1, . . . , ğ¿. Latent Collaboration in Multi-Agent Systems Induction step. Suppose that â„(ğ‘™1) = â„ (ğ‘™1) , and we will show that â„(ğ‘™) = â„ (ğ‘™) . (ğ‘™) and ğ‘‰ğ‘¡+ğ‘š (ğ‘™) . For each past token layer, at each attention layer, the The KV cache contains ğ¾ğ‘¡+ğ‘š (ğ‘™) . At the next transformer produces one column of ğ¾ğ‘¡+ğ‘š step the model forms query from the current input and then uses that query together with the stored (ğ‘™) to form the attention result. That attention result is deterministic function of ğ¾ğ‘¡+ğ‘š the query and of the keys and values it attends to. (ğ‘™) and corresponding column of ğ‘‰ğ‘¡+ğ‘š (ğ‘™) and ğ‘‰ğ‘¡+ğ‘š We are comparing two ways to make those same keys and values available to the current computation: (i) actually feeding the earlier tokens into the model again, in which case the model will recompute (ğ‘™) from the the same keys and values and then use them in attention; (ii) reading in ğ¾ğ‘¡+ğ‘š cache and use them directly. In both cases, the keys and values presented to the attention computation are identical, because the cache was produced by the same model on the same inputs. (ğ‘™) and ğ‘‰ğ‘¡+ğ‘š Given identical keys and values and the same current input, the attention output is the same in both scenarios. The remainder of the transformer computation that produces the last-layer hidden embedding is deterministic function of that attention output (and the current input). Therefore, the last-layer hidden embedding â„(ğ‘™) produced for the current step is the same whether the model (ğ‘™) from cache. Formally, since â„(ğ‘™1) = recomputed keys/values from tokens or read ğ¾ğ‘¡+ğ‘š â„ (ğ‘™1) , ğ¾ğ‘¡+ğ‘š (ğ‘™) , ğ‘‰ğ‘¡+ğ‘š (ğ‘™) , then â„(ğ‘™) = â„ (ğ‘™) . (ğ‘™) , and ğ‘‰ğ‘¡+ğ‘š (ğ‘™) = ğ¾ (ğ‘™) = ğ‘‰ ğ‘¡+ğ‘š ğ‘¡+ğ‘š Induction base case. For the first layer, similarly with the induction step, since the input is the (1) , same (for both latent-based and text-based reasoning), ğ¾ğ‘¡+ğ‘š then â„(1) = â„ (1) . (1) , and ğ‘‰ğ‘¡+ğ‘š (1) = ğ¾ (1) = ğ‘‰ ğ‘¡+ğ‘š ğ‘¡+ğ‘š Conclusion. By induction, we have that â„(ğ‘™) = â„ (ğ‘™) of every layer ğ‘™ = 1, . . . , ğ¿. In particular, since â„ = â„(ğ¿) and â„ = â„ (ğ¿) , then â„ = â„(ğ¿) = â„ (ğ¿) = â„. B.3. Proof of Theorem 3.4 Theorem B.3 (Restate of Theorem 3.4). The time complexity for each agent of LatentMAS is ğ‘‚(cid:0)(ğ‘‘2 ğ‘š + ğ‘‘â„ğ‘š2 + ğ‘‘â„ğ‘¡ğ‘š)ğ¿(cid:1), where ğ‘¡ is the input length of this agent, and ğ‘š is the length of latent â„ thoughts. In contrast, assuming Theorem 3.1, the time complexity for each agent of the vanilla (cid:1) to achieve text-based MAS needs to be ğ‘‚(cid:0)(cid:0)ğ‘‘3 the same expressiveness. log + ğ‘‘3 â„ ğ‘š 1 1 log2 (cid:1) ğ¿ + ğ‘‘2 ğ‘¡ğ‘š 1 + ğ‘‘2 â„ ğ‘š 1 log log ğ‘š2 â„ â„ Proof. We analyze the time complexity of our LatentMAS and the vanilla text-based MAS separately. Time complexity of our method. Recall that transformer layer consists of two main components: self-attention and feed-forward networks. For length-(ğ‘¡ + ğ‘š) sequence, the time complexity to compute self-attention for ğ‘š latent reasoning steps is ğ‘‚(ğ‘‘â„(ğ‘¡ + ğ‘š)ğ‘š) = ğ‘‚(ğ‘‘â„(ğ‘š2 + ğ‘¡ğ‘š)) due to the attention computation between ğ‘‚(ğ‘¡2) pairs of tokens, and the time complexity to compute feedforward networks for ğ‘š latent reasoning steps is ğ‘‚(ğ‘‘2 ğ‘š) due to matrixvector multiplication. Since â„ there are ğ¿ layers, the overall time complexity of our method is ğ‘‚(cid:0)(ğ‘‘â„(ğ‘š2 + ğ‘¡ğ‘š) + ğ‘‘2 â„ ğ‘š)ğ¿(cid:1) . (36) Latent Collaboration in Multi-Agent Systems Time complexity of the vanilla text-based MAS. Let ğ‘š denote the number of text-based reasoning steps. Similarly to the complexity analysis of our method, the time complexity to compute the hidden embeddings is ğ‘‚(cid:0)(ğ‘‘â„(ğ‘š2 + ğ‘¡ğ‘š) + ğ‘‘2 â„ ğ‘š)ğ¿(cid:1) . (37) Besides that, due to matrixvector multiplication and softmax computation, the time complexity to decode hidden embeddings into tokens is ğ‘‚(cid:0)ğ‘‘â„V ğ‘š(cid:1) . Hence, the overall time complexity of the vanilla MAS is ğ‘‚(cid:0)(ğ‘‘â„(ğ‘š2 + ğ‘¡ğ‘š) + ğ‘‘2 â„ ğ‘š)ğ¿ + ğ‘‘â„V ğ‘š(cid:1) . Assuming Theorem 3.1, the number of text-based reasoning steps is It follows that the overall time complexity is ğ‘š = ğ‘‚ (cid:16) ğ‘‘â„ğ‘š log (cid:17) . ğ‘‚(cid:0)(ğ‘‘â„(ğ‘š2 + ğ‘¡ğ‘š) + ğ‘‘2 (cid:16)(cid:16) (cid:16)(cid:16) ğ‘‘â„ğ‘š (cid:17) 2 + ğ‘¡ = ğ‘‘â„ log ğ‘š2 = ğ‘‚ (cid:16)(cid:16) ğ‘‘3 â„ log2 + ğ‘š ğ‘‘3 â„ log â„ ğ‘š)ğ¿ + ğ‘‘â„V ğ‘š(cid:1) (cid:16) ğ‘‘â„ğ‘š (cid:17)(cid:17) log ğ‘‘2 â„ log + ğ‘‘2 â„ ğ¿ + ğ‘¡ğ‘š + (cid:17) (cid:17)(cid:17) (cid:16) ğ‘‘â„ğ‘š log ğ‘‘2 â„ ğ‘š log (cid:17) . ğ¿ + ğ‘‘â„V (cid:17)(cid:17) (cid:16) ğ‘‘â„ğ‘š log (38) (39) (40) (41) (42) (43) 24 Latent Collaboration in Multi-Agent Systems C. Experiment Setups C.1. Evaluation Details We introduce all datasets used in our experiments as follows: Math & Science Reasoning. GSM8K (Cobbe et al., 2021) is widely used benchmark of 8.5K grade-school math word problems designed to evaluate multi-step numerical reasoning. Each problem requires decomposing naturallanguage description into structured arithmetic steps, making it standard testbed for assessing chain-of-thought reasoning ability. AIME24 (Maxwell-Jia, 2024) consists of 30 competition-level problems from the 2024 American Invitational Mathematics Examination. These questions span algebra, geometry, number theory, and combinatorics, and require precise numeric answers with typically 13 digits, making the benchmark compact but challenging evaluation of high-school Olympiad-style reasoning. AIME25 (math ai, 2025) provides 30 additional problems from the 2025 AIME exam, maintaining the same answer format and difficulty profile. Compared with AIME24, this benchmark includes more multi-phase derivations and intricate combinatorial constructions, offering complementary stress test for mathematical robustness. GPQA-Diamond (Rein et al., 2023) is the most difficult split of the GPQA benchmark with 198 questions, featuring graduate-level multiple-choice questions written by domain experts in physics, biology, and chemistry. The dataset emphasizes conceptual depth, cross-disciplinary reasoning, and the ability to synthesize multi-step scientific arguments under rigorous distractor settings. MedQA (Yang et al., 2024a) contains real medical licensing exam questions that assess biomedical knowledge, clinical reasoning, and diagnostic decision-making. Problems require integrating textual context with domain-specific medical understanding, making the benchmark representative testbed for professional-level scientific reasoning. Commonsense Reasoning. ARC-Easy (Clark et al., 2018b) consists of grade-school science questions from the AI2 Reasoning Challenge that test foundational factual knowledge and straightforward commonsense reasoning. As simplified subset of ARC, it serves as baseline measure of basic scientific understanding without requiring complex multi-step inference. ARC-Challenge (Clark et al., 2018a) includes the most difficult items from the AI2 Reasoning Challenge. These questions are intentionally adversarial, requiring multi-hop reasoning, causal and counterfactual inference, and systematic elimination of distractor choices. Performance on ARCChallenge is widely regarded as strong indicator of robust commonsense reasoning capabilities. Code Generation. MBPP-Plus (Liu et al., 2023) extends the original MBPP benchmark with broader input coverage, additional hidden test cases, and stricter execution-based evaluation. Each problem requires generating self-contained Python function that satisfies comprehensive unit-test suite, making the benchmark robust measure of code synthesis reliability and correctness. HumanEval-Plus (Liu et al., 2023) augments HumanEval with denser, more challenging test suites, significantly increasing the rigor of functional correctness evaluation. The benchmark emphasizes 25 Latent Collaboration in Multi-Agent Systems generalization beyond prompt examples and tests models ability to produce semantically precise, executable Python code under more demanding verification settings. C.2. Implementation Details Beyond the experimental setup described in the main paper, we provide additional implementation and evaluation details below. Software Backend All methods are implemented in Python using PyTorch and HuggingFace Transformers, with an optional vLLM backend for fast decoding and tensor-parallel inference. We use the official chat templates and special tokens such as <im_start> and <im_end>. Evaluation protocol. For all non-coding benchmarks, we report accuracy based on answer matching of the final answer after text normalization (lowercasing, trimming whitespace, and removing extraneous punctuation). For multiple-choice datasets (GPQA-Diamond, MedQA, ARC-Easy, ARC-Challenge), we first extract the models final answer string and then compare it via exact match to the answer letter. For numeric problems (GSM8k, AIME24, AIME25), we evaluate correctness based on numeric equality: we extract the final predicted answer, parse both prediction and answer into numbers, and mark as correct only if the two values match. Predictions that fail numeric parsing are counted as incorrect. For code generation tasks (MBPP-Plus and HumanEval-Plus), we evaluate the code by executing unit tests. Specifically, we extract the predicted code from the models output, append the ground-truth tests provided by the benchmark, and execute the combined script in sandboxed environment with 10-second timeout. sample is counted as correct if and only if all tests pass without runtime errors. C.3. Additional Discussions on LatentMAS Extension to Heterogeneous Agents. For simplicity and training-free purposes, we assume that all agents in LatentMAS share the same shape of transformer layers. To relax this assumption and support heterogeneous agents in practice, one can directly leverage prior studies on layer mapping and ensemble learning (Ainsworth et al., 2022; Wortsman et al., 2022) by introducing trainable adapter to align and share latent representations across different models. 26 Latent Collaboration in Multi-Agent Systems D. Case Study Case Study (TextMAS on GSM8K) Input Question: Debra is monitoring beehive to see how many bees come and go in day. She sees 30 bees leave the hive in the first 6 hours, and then she sees 1/2 that many bees return in the next 6 hours. She sees two times as many bees as she saw first leave the hive fly from the hive and leave in the next 6 hours. Then every bee that left before that hadnt already returned returns to the hive in the next 6 hours. How many bees did Debra see return to the hive in the last 6 hours of the day? TextMAS Output Planner Agent: Okay, lets see. need to figure out how many bees Debra saw return to the hive in the last 6 hours. Let me break down the problem step by step. First, the problem mentions different time intervals: first 6 hours, next 6 hours, then the next 6 hours, and finally the last 6 hours. So there are four 6-hour periods in day, making up 24 hours total. Let me note each period and what happens in each. Starting with the first 6 hours: Debra sees 30 bees leave the hive. Let me write that down as the first data point. So, Period 1 (0-6 hours): 30 bees leave. Then, the next 6 hours (Period 2: 6-12 hours), she sees half that number return. Half of 30 is 15. So, 15 bees return in Period 2. Next, the third period (Period 3: 12-18 hours), she sees two times as many bees as she saw first leave the hive fly from the hive and leave. The first time she saw 30 bees leave, so two times that is 60. So, 60 bees leave in Period 3. Then, the fourth period (Period 4: 18-24 hours), every bee that left before that hadnt already returned returns to the hive. Critic Agent: The reasoning plan correctly identifies all four 6-hour periods and reaches the right final conclusion, but the intermediate analysis contains several issues that reduce clarity and efficiency. First, the interpretation of the phrase before that is revisited multiple times, even though it simply refers to the event in the previous sentence (the 60 bees leaving), meaning only bees that left in Period 1 are relevant. Second, the plan temporarily entertains the possibility that bees may have left in Period 2, despite the problem statement explicitly describing only returns during this interval. Third, the plan repeatedly questions whether the 15 returning bees in Period 2 originate from the initial 30, even though the text directly states they are half that many and therefore unambiguously tied to Period 1. These detours introduce redundancy and confusion. Overall, while the conclusion of 15 returning bees is correct, the path to it is unnecessarily convoluted and would benefit from more concise timeline-based analysis. Refiner Agent: will provide refined plan based on previous agents information. 1. Identify the Time Periods and Events. We divide the day into four 6-hour intervals and record the events in each: Period 1 (06 hours): 30 bees leave the hive. Period 2 (612 hours): Half of those bees return, i.e., 15 bees. Period 3 (1218 hours): Twice the number of bees that left in Period 1 leave the hive: 2 30 = 60 bees. Period 4 (1824 hours): Every bee that left before Period 3 and has not yet returned comes back to the hive. 2. Track Bees Leaving and Returning. Period 1: 30 bees leave. Period 2: 15 of these 30 bees return, leaving 15 still outside the hive. Period 3: 60 new bees leave (these are not relevant for the final return count). Period 4: Only bees that left before Period 3 and have not returned will come back. 3. Determine Which Bees Return in Period 4. The only bees that left before Period 3 are the 30 from Period 1. Of these, 15 returned in Period 2. Thus, the remaining 15 bees from Period 1 return in Period 4. 4. Return the Final Answer. need to figure out how many bees Debra saw return to the hive in the last Solver Agent: Okay, lets see. hours. Let me break down the problem step by step. First, the problem mentions different time intervals: first 6 hours, next 6 hours, then the next 6 hours, and finally the last 6 hours. So there are four 6-hour periods in day, making up 24 hours total. Let me note each period and what happens in each. Starting with the first 6 hours: Debra sees 30 bees leave the hive. Let me write that down as the first data point. So, Period 1 (0-6 hours): 30 bees leave. Then, the next 6 hours (Period 2: 6-12 hours), she sees half that number return. Half of 30 is 15. So, 15 bees return in Period 2. Next, the third period (Period 3: 12-18 hours), she sees two times as many bees as she saw first leave the hive fly from the hive and leave. The first time she saw 30 bees leave, so two times that is 60. So, 60 bees leave in Period 3. Then, the fourth period (Period 4: 18-24 hours), every bee that left before that hadnt already returned returns to the hive. So, bees that left in Period 1 and Period 2. But some of those bees may have already returned in Period 2. ### Final Answer Debra saw 15 bees return to the hive in the last 6 hours of the day. ( Wrong Final Answer) 27 Latent Collaboration in Multi-Agent Systems Case Study (LatentMAS on GSM8K) Input Question: Debra is monitoring beehive to see how many bees come and go in day. She sees 30 bees leave the hive in the first 6 hours, and then she sees 1/2 that many bees return in the next 6 hours. She sees two times as many bees as she saw first leave the hive fly from the hive and leave in the next 6 hours. Then every bee that left before that hadnt already returned returns to the hive in the next 6 hours. How many bees did Debra see return to the hive in the last 6 hours of the day? LatentMAS Output We are given sequence of events involving bees leaving and returning to the hive over the course of day, broken into 6-hour intervals. According to the refiners plan, we need to track how many bees leave and return during each 6-hour interval, noting that 30 leave first, 15 return next, and 60 more leave afterward. In the final interval, all bees that had left and not yet returned came back, giving total of 15 remaining from the first group, plus 60 from the third group, for total of 75 returning bees. Lets break it down step by step based on the plan: Step 1: Bees that leave in the first 6 hours. Debra sees 30 bees leave the hive during the first 6-hour period. Step 2: Bees that return in the next 6 hours. In the second 6-hour period, she sees half as many bees return: 1 2 30 = 15 bees return. Step 3: Bees that leave in the third 6-hour period. 2 30 = 60 bees leave. In the next 6 hours, twice the number from Step 1 leave: Step 4: Bees that return in the final 6 hours. During the final 6 hours, every bee that had left earlier and had not yet returned comes back to the hive. We track the bees that left and determine which have already returned: From the first 6 hours: 30 bees left; 15 returned in Step 2, leaving 15 bees still out. From the third 6 hours: 60 bees left; none have returned yet. Thus, the total number of bees returning in the final 6 hours is 15 + 60 = 75 bees. ###Final Answer: 75 ( Correct Final Answer) To better understand how latent collaboration changes multi-agent reasoning dynamics, we conduct detailed case study on GSM8K using the Qwen3-14B backbone under the Sequential MAS setting. As shown in the example, TextMAS agents rely on lengthy textual exchanges that often amplify early reasoning errors, misinterpretations by the planner propagate through the critic and refiner, ultimately constraining the solvers search space. In contrast, LatentMAS operates entirely through latent workingmemory transfer: each agent receives rich, continuous representations of prior reasoning rather than brittle text, enabling later agents to reinterpret, refine, and correct upstream reasoning without inheriting surface-level mistakes. This latent collaboration leads to more coherent intermediate steps, more stable numerical reasoning, and ultimately yields the correct final answer, where TextMAS fails. The case study illustrates how LatentMAS mitigates error compounding in multi-agent pipelines and demonstrates the qualitative advantage of latent over text-based communication. 28 Latent Collaboration in Multi-Agent Systems E. Prompt Template for LatentMAS Sequential LatentMAS Prompts on Numeric Tasks (GSM8K / AIME2024 / AIME2025) System Prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Planner Agent: You are Planner Agent. Given an input question, design clear, step-by-step plan for how to solve the question. Question: {question} Your outlined plan should be concise with few bulletpoints for each step. Do not produce the final answer. Now output your plan to solve the question below: Prompt for Critic Agent: You are Critic Agent to evaluate the correctness of the input plan for the given question and provide helpful feedback for improving the plan. Question: {question} The plan information is provided in latent KV representation format. Review the plan and question and output: (1) original plan contents (2) constructive feedback on the original plan. Format your response as follows: Original Plan: [Copy the provided Planner Agents plan here] Feedback: [Your detailed feedback to improve the plan here] Now, output your response below: Prompt for Refiner Agent: You are Refiner Agent to provide refined step-by-step plan for solving the given question. Question: {question} You are provided with: (1) latent-format information: previous plan with feedback (2) text-format information: the input question you need to solve. Based on the input, write refined and improved plan to solve the question. Make sure your output plan is correct and concise. Now, output your refined plan below: Prompt for Judger Agent: You are helpful assistant. You are provided with latent information for reference and target question to solve. Target Question: {question} The latent information might contain irrelevant contents. Ignore it if it is not helpful for solving the target question. Now, reason step by step and output the final answer inside boxed{YOUR_FINAL_ANSWER}: 29 Latent Collaboration in Multi-Agent Systems Sequential LatentMAS prompts for multiple-choice tasks (ARC-E, ARC-C, GPQA, MedQA) System Prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Planner Agent: You are Planner Agent. Given an input question, design clear, step-by-step plan for how to solve the question. Question: {question} Your outlined plan should be concise with few bulletpoints for each step. Do not produce the final answer. Now output your plan to solve the question below: Prompt for Critic Agent: You are Critic Agent to evaluate the correctness of the input plan for the given question and provide helpful feedback for improving the plan. Question: {question} The plan information is provided in latent KV representation format. Review the plan and question and output: (1) original plan contents (2) constructive feedback on the original plan. Format your response as follows: Original Plan: [Copy the provided Planner Agents plan here] Feedback: [Your detailed feedback to improve the plan here] Now, output your response below: Prompt for Refiner Agent: You are Refiner Agent to provide refined step-by-step plan for solving the given question. Question: {question} You are provided with: (1) latent-format information: previous plan with feedback (2) text-format information: the input question you need to solve. Based on the input, write refined and improved plan to solve the question. Make sure your output plan is correct and concise. Now, output your refined plan below: Prompt for Judger Agent: You are helpful assistant. You are provided with latent information for reference and target question to solve. Target Question: {question} The latent information might contain irrelevant contents. Ignore it if it is not helpful for solving the target question. Your final answer must be selected from A,B,C,D. For example boxed{A}. Do not add any other contents inside the box. Now, reason step by step and output the final answer inside boxed{YOUR_FINAL_ANSWER}: 30 Latent Collaboration in Multi-Agent Systems Sequential LatentMAS prompts for python coding tasks (MBPP-Plus, HumanEval-Plus) System Prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Planner Agent: You are Planner Agent. Given an input question, design clear, step-by-step plan for how to solve the question. Question: {question} Your outlined plan should be concise with few bulletpoints for each step. Do not produce the final answer. Now output your plan to solve the question below: Prompt for Critic Agent: You are Critic Agent to evaluate the correctness of the input plan for the given question and provide helpful feedback for improving the plan. Question: {question} The plan information is provided in latent KV representation format. Review the plan and question and output: (1) original plan contents (2) constructive feedback on the original plan. Format your response as follows: Original Plan: [Copy the provided Planner Agents plan here] Feedback: [Your detailed feedback to improve the plan here] Now, output your response below: Prompt for Refiner Agent: You are Refiner Agent to provide refined step-by-step plan for solving the given question. Question: {question} You are provided with: (1) latent-format information: previous plan with feedback (2) text-format information: the input question you need to solve. Based on the input, write refined and improved plan to solve the question. Make sure your output plan is correct and concise. Now, output your refined plan below: Prompt for Judger Agent: You are helpful assistant. You are provided with latent information for reference and target question to solve. Target Question: {question} The latent information might contain irrelevant contents. Ignore it if it is not helpful for solving the target question. Your must reason step-by-step to solve the **provided Target Question** witout outputing other irrelevant inforamtion. You must put all python code as self-contained Python function in markdown code blocks. For example python import math def add(a, b): return + b. Do not add any other contents inside the markdown code block. Now, reason step by step and output the final answer inside python YOUR_PYTHON_CODE: Latent Collaboration in Multi-Agent Systems Hierarchical LatentMAS prompts for numeric-answer tasks (GSM8K, AIME2024, AIME2025) System prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Math Agent: You are math agent. boxed{YOUR_FINAL_ANSWER}. Question: {question} Your response: Given the input question, reason step-by-step and put the final answer inside Prompt for Science Agent: You are science agent. boxed{YOUR_FINAL_ANSWER}. Question: {question} Your response: Given the input question, reason step-by-step and put the final answer inside Prompt for Code Agent: You are code agent. boxed{YOUR_FINAL_ANSWER}. Question: {question} Your response: Given the input question, reason step-by-step and put the final answer inside Prompt for Task Summarizer Agent: You are task summarizer. Given the input question and responses from previous agents as reference, reason step-by-step and put the final answer inside boxed{YOUR_FINAL_ANSWER}. Question: {question} Your response: Hierarchical LatentMAS prompts for multiple-choice tasks (ARC-E, ARC-C, GPQA, MedQA) System Prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Math Agent: You are math agent. the final answer inside boxed{YOUR_FINAL_ANSWER}. Your final answer must be selected from A,B,C,D. For example boxed{A}. Do not add any other contents inside the box. Question: {question} Your response: reason step-by-step and put Given the input question, Prompt for Science Agent: You are science agent. Given the input question, reason step-by-step and put the final answer inside boxed{YOUR_FINAL_ANSWER}. Your final answer must be selected from A,B,C,D. For example boxed{A}. Do not add any other contents inside the box. Question: {question} Your response: Prompt for Code Agent: You are code agent. the final answer inside boxed{YOUR_FINAL_ANSWER}. Your final answer must be selected from A,B,C,D. For example boxed{A}. Do not add any other contents inside the box. Question: {question} Your response: reason step-by-step and put Given the input question, Prompt for Task Summarizer Agent: You are task summarizer. Given the input question and responses from previous agents as reference, reason step-by-step and put the final answer inside boxed{YOUR_FINAL_ANSWER}. Your final answer must be selected from A,B,C,D. For example boxed{A}. Do not add any other contents inside the box. Question: {question} Your response: 32 Latent Collaboration in Multi-Agent Systems Hierarchical LatentMAS prompts for python coding tasks (MBPP-Plus, HumanEval-Plus) System Prompt for All Agents: You are Qwen, created by Alibaba Cloud. You are helpful assistant. Prompt for Math Agent: You are math agent. Given the input question, reason step by step and provide an efficient and self-contained Python function that solves the following problem in markdown code block. You must put all python code as self-contained Python function in markdown code blocks. For example python import math def add(a, b): return + b. Do not add any other contents inside the markdown code block. Question: {question} Your response: Prompt for Science Agent: You are science agent. Given the input question, reason step by step and provide an efficient and self-contained Python function that solves the following problem in markdown code block. You must put all python code as self-contained Python function in markdown code blocks. For example python import math def add(a, b): return + b. Do not add any other contents inside the markdown code block. Question: {question} Your response: Prompt for Code Agent: You are code agent. Given the input question, reason step by step and provide an efficient and self-contained Python function that solves the following problem in markdown code block. You must put all python code as self-contained Python function in markdown code blocks. For example python import math def add(a, b): return + b. Do not add any other contents inside the markdown code block. Question: {question} Your response: Prompt for Task Summarizer Agent: You are task summarizer. Given the input question and responses from previous agents as reference, reason step by step and provide an efficient and self-contained Python function that solves the following problem in markdown code block. You must put all python code as self-contained Python function in markdown code blocks. For example python import needed_library def FUNC_NAME(a, b): return + b. Do not add any other contents inside the markdown code block. Input Question: {question} Your response:"
        }
    ],
    "affiliations": [
        "Princeton University",
        "Stanford University",
        "University of Illinois Urbana-Champaign"
    ]
}