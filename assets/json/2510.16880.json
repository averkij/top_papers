{
    "paper_title": "Chem-R: Learning to Reason as a Chemist",
    "authors": [
        "Weida Wang",
        "Benteng Chen",
        "Di Zhang",
        "Wanhao Liu",
        "Shuchen Pu",
        "Ben Gao",
        "Jin Zeng",
        "Lei Bai",
        "Wanli Ouyang",
        "Xiaoyong Wei",
        "Tianshu Yu",
        "Tianfan Fu",
        "Shuzhou Sun",
        "Jiatong Li",
        "Zifu Wang",
        "Yuqiang Li",
        "Shufei Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Although large language models (LLMs) have significant potential to advance chemical discovery, current LLMs lack core chemical knowledge, produce unreliable reasoning trajectories, and exhibit suboptimal performance across diverse chemical tasks. To address these challenges, we propose Chem-R, a generalizable Chemical Reasoning model designed to emulate the deliberative processes of chemists. Chem-R is trained through a three-phase framework that progressively builds advanced reasoning capabilities, including: 1) Chemical Foundation Training, which establishes core chemical knowledge. 2) Chemical Reasoning Protocol Distillation, incorporating structured, expert-like reasoning traces to guide systematic and reliable problem solving. 3) Multi-task Group Relative Policy Optimization that optimizes the model for balanced performance across diverse molecular- and reaction-level tasks. This structured pipeline enables Chem-R to achieve state-of-the-art performance on comprehensive benchmarks, surpassing leading large language models, including Gemini-2.5-Pro and DeepSeek-R1, by up to 46% on molecular tasks and 66% on reaction tasks. Meanwhile, Chem-R also consistently outperforms the existing chemical foundation models across both molecular and reaction level tasks. These results highlight Chem-R's robust generalization, interpretability, and potential as a foundation for next-generation AI-driven chemical discovery."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 1 ] . [ 1 0 8 8 6 1 . 0 1 5 2 : r Chem-R: Learning to Reason as Chemist CHEM-R: LEARNING TO REASON AS CHEMIST Weida Wang1,2, Benteng Chen1,3, Di Zhang2, Wanhao Liu1,4, Shuchen Pu1,4, Ben Gao1, Jin Zeng5, Lei Bai1, Wanli Ouyang1, Xiaoyong Wei7, Tianshu Yu8,1, Tianfan Fu6,1, Shuzhou Sun1, Jiatong Li7, Zifu Wang1, Yuqiang Li1, Shufei Zhang1 1Shanghai AI Lab 2Fudan University 3The University of Hong Kong 4University of Science and Technology of China 7Hong Kong Polytechnic University 8The Chinese University of Hong Kong, Shenzhen 5Tongji University 6Nanjing University"
        },
        {
            "title": "ABSTRACT",
            "content": "Although large language models (LLMs) have significant potential to advance chemical discovery, current LLMs lack core chemical knowledge, produce unreliable reasoning trajectories, and exhibit suboptimal performance across diverse chemical tasks. To address these challenges, we propose Chem-R, generalizable Chemical Reasoning model designed to emulate the deliberative processes of chemists. Chem-R is trained through three-phase framework that progressively builds advanced reasoning capabilities, including: 1) Chemical Foundation Training, which establishes core chemical knowledge. 2) Chemical Reasoning Protocol Distillation, incorporating structured, expert-like reasoning traces to guide systematic and reliable problem solving. 3) Multi-task Group Relative Policy Optimization that optimizes the model for balanced performance across diverse molecularand reaction-level tasks. This structured pipeline enables ChemR to achieve state-of-the-art performance on comprehensive benchmarks, surpassing leading large language models, including Gemini-2.5-Pro and DeepSeekR1, by up to 46% on molecular tasks and 66% on reaction tasks. Meanwhile, Chem-R also consistently outperforms the existing chemical foundation models across both molecular and reaction level tasks. These results highlight ChemRs robust generalization, interpretability, and potential as foundation for nextgeneration AI-driven chemical discovery. The code and model are available at https://github.com/davidweidawang/Chem-R."
        },
        {
            "title": "INTRODUCTION",
            "content": "Large Language Models (LLMs) have recently emerged as transformative force in scientific discovery (Bai et al., 2025; Ma et al., 2024; Shojaee et al., 2024; Hatakeyama-Sato et al., 2023; Xia et al., 2025). Within the field of chemistry, LLMs demonstrate exceptional potential by learning expressive representations and knowledge of molecular structures and chemical reactions directly from large-scale datasets. This capability enables them to support wide array of tasks, including molecular property prediction, reaction outcome estimation, retrosynthetic route planning, and reagent selection (Zhang et al., 2024b; Tan et al., 2025; Zhao et al., 2024; Jiang et al., 2025). However, the lack of chemical structured and reliable reasoning processes in current LLMs leads to suboptimal performance and limited interpretability on complex chemical problems. Specifically, current LLMs encounter three fundamental challenges in performing chemical reasoning. Challenge 1: Current LLMs often lack the essential chemical fundamentals, leading to frequent mistakes in molecular representations and reaction rules, which undermines reliability at the initial reasoning stage (Zhong et al., 2024; Liu et al., 2025). As illustrated in Figure 1 (Challenge 1), several Chain-of-Thought (CoT) on different tasks generated by DeepSeek-R1 (Guo et al., 2025) demonstrates that the model may fail to recognize basic SMILES (Weininger, 1988) and IUPAC (Kuhn et al., 2004), which undermines the reliability of any subsequent reasoning. Challenge Equal contribution. Corresponding author: zhangshufei@pjlab.org.cn. 1 Chem-R: Learning to Reason as Chemist Figure 1: Challenges and the proposed Chem-R solution. The left panel highlights three key deficiencies observed in current reasoning models. To overcome these limitations, we introduce three-phase training framework, illustrated on the right. This strategy is designed to first build solid chemical foundation (Phase 1), then instill correct, step-by-step reasoning pathways (Phase 2), and finally, optimize for balanced, multi-task proficiency (Phase 3). 2: The models reasoning process is fundamentally flawed because it is unsystematic, failing to adhere to the coherent, step-by-step workflow of an expert (Ouyang et al., 2023; Bran et al., 2025). This lack of structured approach makes the reasoning unreliable and prone to factual errors. This lack of structure results in confusing and untrustworthy reasoning process, as exemplified in Figure 1 (Challenge 2) where the model misidentifies fundamental functional groups and generates flawed, unstructured line of reasoning. Challenge 3: As shown in Figure 1 (Challenge 3), even when models are guided by explicit reasoning patterns, their performance across diverse molecular and reaction level tasks remains highly imbalanced, with strong tasks dominating and weaker tasks underrepresented. Together, these issues highlight that effective chemical reasoning requires domain knowledge, reliable and structured thought, and balanced generalization across heterogeneous tasks. To address these challenges, we propose Chem-R, unified framework comprising three phases that enables structured reasoning in molecularand reaction-level tasks. As shown in Fig. 1, ChemR follows three-phase training paradigm, where each phase systematically mitigates one of the aforementioned bottlenecks. Phase 1: Chemical Foundation Training equips the model with robust chemical fundamentals by fine-tuning on large-scale non-reasoning corpora, covering both molecular representations (e.g., SMILES, IUPAC) and reaction-level patterns, thereby reducing elementary errors. Phase 2: Chemical Reasoning Protocol (CRP) Distillation leverages structured protocols to guide general-purpose teacher model toward expert-level chemical reasoning, subsequently disIn this process, expert-like protocols are converted tilling these strategies into student model. into reusable, modular workflows that facilitate coherent and interpretable problem-solving. As illustrated in bottom row of Fig. 1, the reasoning process can be enhanced by extracting structured Chemical Reasoning Protocols, incorporating correction information, and providing targeted hints to mitigate common errors. Phase 3: Multi-task Group Relative Policy Optimization (Multi-task GRPO) further enhances the learned reasoning paradigm across heterogeneous tasks, employing curriculum-like weighting scheme to prevent strong-task dominance and improve performance balance. Together, these three phases form principled pipeline that not only reduces low-level mistakes, but also enables the model to generate chemically sound, structured, and explainable reasoning across both molecular and reaction domains. Our main contributions are summarized as follows: (1) We propose Chem-R, unified three-phase framework that enables structured and generalizable chemical reasoning across both molecular and reaction level tasks. Phase 1 (Chemical Foundation Training) equips the model with robust chemical fundamentals by pre-training on large-scale non-reasoning corpora. Phase 2 (CRP Distillation) introduces Chemical Reasoning Protocols (CRP) distilled from teacher model, providing modular and interpretable workflows that guide problem solving. Phase 3 (Multi-task GRPO) applies GRPO with curriculum-like weighting scheme to enhance and balance performance across heterogeneous tasks. 2 Chem-R: Learning to Reason as Chemist (2) We comprehensively evaluate the model on four widely used benchmarks, including ChemLLMBench (Guo et al., 2023), ChEBI-20 (Edwards et al., 2022), TOMG-Bench (Li et al., 2024a), and USPTO (Schneider et al., 2016). Our evaluation spans two major families of tasks, namely molecularand reaction-level tasks, covering nine macro-tasks and 25 sub-tasks in total. Across this diverse suite, Chem-R consistently achieves state-of-the-art performance. For instance, compared with ChemDFM-v1.0-13B (Zhao et al., 2025c), Gemini-2.5-Pro (Comanici et al., 2025), and DeepSeek-R1 (Guo et al., 2025), Chem-R improves by 33%, 32%, and 44% on Name Prediction (Exact Match), and by 53%, 50%, and 52% on Yield Prediction (Accuracy), respectively. These substantial gains highlight Chem-Rs ability to deliver both reliable accuracy and robust generalization across heterogeneous molecular and reaction tasks."
        },
        {
            "title": "2.1 REASONING FOR LLMS",
            "content": "Generating CoT (Wei et al., 2022; Kojima et al., 2022) significantly improves the ability of LLMs to perform complex reasoning. To elicit high-quality reasoning chains, various strategies have been proposed, including rejection sampling (Liu et al., 2023a; Tong et al., 2024), reward modeling (Ouyang et al., 2022; Zhang et al., 2025b), and preference learning (Rafailov et al., 2023; Pang et al., 2024). More recently, DeepSeek-R1 (Guo et al., 2025) has shown that complex reasoning behaviors (Gandhi et al., 2025) can emerge from simple rule-based reinforcement learning, particularly when initialized with cold start phase using CoT data. However, common limitation of these approaches is their reliance on outcome-based supervision, which can produce unstructured, inconsistent and flawed reasoning chains (Arcuschin et al., 2025; Chen et al., 2025), critical risk in scientific applications. To address this, process-level supervision provides fine-grained feedback on each intermediate step (Lightman et al., 2024; Wang et al., 2024; Zhang et al., 2024a; 2025a). Another strategy involves multi-model systems where verifier models scrutinize the reasoning process of primary generator model (Du et al., 2023; Kirchner et al., 2024; Baker et al., 2025). 2.2 LLMS FOR CHEMISTRY The application of LLMs is driving paradigm shift in chemistry. Early work demonstrated that generalist models possess latent chemical knowledge (Hatakeyama-Sato et al., 2023; Sallam et al., 2024), paving the way for specialized models fine-tuned for chemistry-specific tasks. These include models like ChemLLM (Zhang et al., 2024b), ChemMLLM (Tan et al., 2025), Chem3DLLM (Jiang et al., 2025), ChemDFM (Zhao et al., 2025c) and others (Liu et al., 2023c; Zhang et al., 2025c; Li et al., 2025c), which handle tasks ranging from molecular captioning to reaction analysis. More recent advancements have focused on complex reasoning and cross-domain integration. Reasoning models such as ether0 (Narayanan et al., 2025) and ChemDFM-R (Zhao et al., 2025b), trained via reinforcement learning, exhibit strong performance across diverse chemical tasks and provide transparent, interpretable outputs. In parallel, scientific foundation models like NatureLM (Xia et al., 2025) and Intern-S1 (Bai et al., 2025) have been trained on large-scale data from various scientific fields. These models can handle diverse range of inputs spanning biology, chemistry, and materials science. Despite these advances, the progress of foundation models in chemistry lags significantly behind that in high-resource domains like mathematics and code, largely due to the relative scarcity of specialized scientific data for training (Bai et al., 2025). To overcome this data bottleneck, we introduce specialized pipeline designed to synthesize high-quality CoT data on par with expert-level annotations for model training."
        },
        {
            "title": "3 METHOD",
            "content": "Overview. We propose Chem-R, three-phase framework explicitly designed to endow LLMs with structured and generalizable chemical reasoning capabilities. Phase 1 (Section 3.1) establishes chemistry-aware foundation by supervised fine-tuning on large-scale non-reasoning corpora, grounding the model in valid molecular and reaction representations. Phase 2 (Section 3.2) 3 Chem-R: Learning to Reason as Chemist Figure 2: The overall pipeline of Chem-R. The model is trained in three phases. 1) Chemical Foundation Training: Instills basic chemical knowledge using question-answer pairs. 2) Chemical Reasoning Protocol Distillation: Teaches structured reasoning by fine-tuning on protocol-guided CoT. 3) Multi-task GRPO: Refines reasoning skills across all tasks using reinforcement learning. introduces Chemical Reasoning Protocol (CRP) Distillation, which transfers structured and reusable reasoning workflows from teacher model into compact student model. Phase 3 (Section 3.3) employs Multi-task Group Relative Policy Optimization (Multi-task GRPO) to further enhance and balance performance across diverse molecularand reaction-level tasks. Together, these phases form principled pipeline that transforms ad-hoc CoT traces into chemically sound, interpretable, and broadly generalizable reasoning. 3.1 PHASE 1: CHEMICAL FOUNDATION TRAINING Establishing reliable chemical LLM necessitates the integration of domain-specific knowledge in molecular representations and reaction notation. General-purpose corpora (e.g., Wikipedia, textbooks) are inadequate in this regard, as they rarely capture the syntactic rules of SMILES strings or the systematic regularities of IUPAC nomenclature, let alone the canonical mapping between different molecular descriptors (Luo et al., 2022; Taylor et al., 2022; Irwin et al., 2022). To this end, Phase 1 establishes chemistry-aware foundation by supervised fine-tuning (SFT) on largescale non-reasoning corpora Dchem, thereby grounding the model in chemically valid inputoutput behaviors. Formally, Dchem is paired chemistry corpus, Dchem = {(xi, yi)}N i=1, where xi represents structured chemical input (e.g., SMILES string, an IUPAC name, or reaction query), and yi is the corresponding labels (e.g., canonical IUPAC name, valid SMILES string, or the main product of chemical reaction). Dchem encompasses both molecularand reaction-level supervision. At the molecule level, the corpus aligns alternative descriptors of the same compound. This enables the model to master not only the bidirectional translation between SMILES and IUPAC forms, but also the mapping from molecular structure to its textual description. Such examples teach the model chemically consistent string generation and reduce elementary notational errors. At the reaction level, the corpus encodes prototypical transformations, mapping reactants to their products or reagents and specifying the functional roles of reagents and conditions. Although such instances require only static mapping rather than explicit reasoning, they provide essential priors that prevent chemically implausible outcomes. In this phase, the model is trained via supervised fine-tuning (SFT) to internalize the syntax and semantics of Dchem, as illustrated in Figure 2 (left). This chemistry-aware initialization substantially reduces representational errors and serves as the basis for structured reasoning in subsequent phases. Examples of data used in the first phase can be found in Appendix B. 3.2 PHASE 2: CHEMICAL REASONING PROTOCOL DISTILLATION While Phase 1 equips the model with foundational chemical knowledge by training on correct question-answer pairs, it does not yet instill the ability to perform reliable and structured reason4 Chem-R: Learning to Reason as Chemist ing. conventional approach to bridge this gap is to distill CoT data from more powerful teacher model and then train the student model. However, this direct distillation often perpetuates the exact problems we seek to eliminate; as shown in Figure 1, even advanced models can produce chaotic and unreliable reasoning trajectories. To address this challenge and ensure the distilled reasoning is of high quality, we introduce Phase 2 (as shown in middle pannel of Figure 2): CRP Distillation. This phase consists of two stages: (I) generating an expert-like reasoning protocol, and (II) using this protocol to guide the synthesis of high-quality CoT data for finetuning. The overall objective is to teach Chem-R systematic and reliable reasoning methodology. I. Chemical Reasoning Protocol Generation. It creates the experts blueprint for chemical reasoning. For given task, we use simple prompt to have the teacher model generate multiple, varied responses. From this collection of responses, we then sample positive examples (reasoning paths leading to the correct answer, as Ri in Figure 2) and negative examples (those leading to incorrect answers). The teacher model systematically analyzes these positive examples to conclude generalizable, step-by-step reasoning template. Concurrently, the teacher model also examines failed reasoning attempts to identify common mistakes, summarizing them as cautionary guidance attached to each step of the protocol. This process results in strong thinking guide for each task. Furthermore, we create more holistic and robust final reasoning guide by merging the cautionary guidance from analogous steps across different tasks, enriching the protocol for any given step with insights from as many relevant contexts as possible. II. Protocol-Guided Synthesis and Finetuning. With the expert protocol established, the second stage focuses on data synthesis and student model training. For each question, we guide the teacher model by providing it with an Instantiated Protocol, combination of the tasks governing CRP and the reliable correct information (i.e., functional groups and final answer). This prompts the model to produce detailed CoT that strictly adheres to the protocols structured steps. To ensure the absolute quality and logical fidelity of this synthetic data, we implement Rejected Sampling mechanism. Specifically, the answer portion of generated CoT (e.g., tokens included in <answer> tag) is removed, and the model must regenerate the answer based solely on the preceding reasoning. Only those CoT paths where the regenerated answer matches the original correct answer are retained, guaranteeing that the reasoning logically and consistently leads to the correct solution. Finally, this curated dataset of pristine (Question, CoT + Answer) pairs is used to fine-tune Chem-R via SFT, effectively teaching it to internalize and replicate reliable and interpretable reasoning process. 3.3 PHASE 3: MULTI-TASK GRPO While Phase 2 equips the model with structured reasoning protocols, ensuring their robust execution across heterogeneous tasks remains non-trivial. In particular, naive multi-task training tends to favor easier or high-resource tasks, causing weaker tasks to be underrepresented and resulting in imbalanced performance. To overcome this issue, we introduce Multi-task GRPO scheme, which enhances protocol-guided reasoning while explicitly enforcing balance across tasks. Let denote the task mixture. For each task , we estimate its validation accuracy st after Phase 2, and assign sampling probability pt that up-weights weaker tasks: pt = (1 st)α tT (1 st)α , (cid:80) (1) where α 0 controls the strength of reweighting. This adaptive curriculum ensures that difficult or underperforming tasks contribute proportionally more updates, thereby mitigating strong-task dominance and fostering balanced improvement. For each sampled question q, we roll out responses {oi}G i=1 using the current policy πθold. Each token oi,t within trajectory is optimized under clipped-ratio surrogate with KL regularization: JGRPO(θ) = q,{oi}G i=1 (cid:2) 1 πθ(oi,tq) πθold(oi,tq) Ai, (2) , 1 ϵ, 1 + ϵ)Ai) βDKL(πθπref)(cid:3). (cid:88) oi (cid:88) min( i=1 t=1 πθ(oi,tq) πθold (oi,tq) clip( 5 Chem-R: Learning to Reason as Chemist Here, oi,t is the t-th token of the i-th response oi, which has length oi, ϵ is hyperparameter that defines the clipping range, Ai is the normalized group advantage, and DKL(πθπref) is KL divergence regularizer, weighted by β, that penalizes deviation from reference policy πref (initialized from Phase 2). As for our reward design, we do not use any format-based rewards. The accuracybased rewards are task-specific, with detailed calculations provided in Section 4.1."
        },
        {
            "title": "4.1 EXPERIMENTAL SETUP",
            "content": "Benchmarks. We collect four widely used chemical benchmarks, ChemLLMBench (Guo et al., 2023), ChEBI-20 (Edwards et al., 2022), TOMG-Bench (Li et al., 2024a), and USPTO (Schneider et al., 2016), with their official splits to ensure fair comparison. Based on these, we organize the evaluation into two families: molecular tasks and reaction tasks, covering 9 macro-tasks with 25 sub-tasks in total. Molecular tasks include (1) name prediction (IUPACSMILES); (2) property prediction on BBBP, HIV, Tox21, ClinTox, and BACE (Wu et al., 2018); (3) molecule design from text to SMILES; (4) molecule captioning from SMILES to text; (5) text-based open molecule generation includes molecule editing (with functional group addition, replacement, or removal), molecule optimization (guided toward target LogP, MR, and QED) and customized molecule generation (by atom count, bond count, and functional-group count). Reaction tasks include (6) yield prediction for BuchwaldHartwig and Suzuki reactions; (7) reagent selection for reactant, solvent, and ligand in multiple-choice form (8) reaction prediction and (9) retrosynthesis. More detailed descriptions of the tasks can be found in Appendix B. Evaluation Metrics. We adopt task-specific evaluation metrics aligned with prior work. For name prediction (1), we report exact match between predicted and reference strings. For property prediction (2) and yield prediction (6), which are binary classification tasks, we use average Accuracy across datasets. For molecule design (3), we measure exact match on the generated SMILES. For molecule captioning (4), we compute BLEU-4 to evaluate text generation quality. For text-based open molecule generation (5), which covers editing, optimization, and customized generation, we report weighted accuracy over constraints such as functional groups, atom counts, and property targets. For reagent selection (7), we evaluate by multiple-choice accuracy. For reaction prediction (8) and retrosynthesis (9), we use exact match on canonical SMILES, with unordered set matching for multi-product or multi-reactant cases separated by .. All SMILES and IUPAC comparisons are performed after canonicalization to ensure consistency. For more comprehensive analysis, supplementary metrics for these tasks are also reported in the Appendix D. Baselines. We group baselines into five families, with the first four reported in the main tables and the fifth provided in Appendix D. The first group consists of general foundation models. These include Llama-3.1-8B-Instruct, Llama-3.3-70B (Dubey et al., 2024), and GPT-4o (Hurst et al., 2024). This group establishes the capability of nonchemistry-adapted systems. The second group is general reasoning models. Examples are Gemini-2.5-Pro (Comanici et al., 2025), DeepSeek-R1 (Guo et al., 2025), and QWQ-32B (Yang et al., 2025). These models test whether generic reasoning gains transfer to chemistry. The third group contains chemical foundation models. These are ChemLLM-DPO-20B (Zhang et al., 2024b), ChemDFM-v1.0-13B, and ChemDFM-v1.58B (Zhao et al., 2025c). This set of models emphasizes chemistry knowledge coverage without explicit multi-step reasoning optimization. The fourth group includes chemical reasoning models, such as ether0-24B (Narayanan et al., 2025) and our Chem-R, which target process-level reasoning and interpretability. To account for task-specific nuances, we additionally compare against fifth group, task-specialized models, in the appendix. We evaluate these under each benchmarks standard protocol with unified normalization and scoring scripts for fairness and reproducibility. Implementation Details. We select Llama-3.1-8B-Instruct as our base model, and Llama-3.370B-Instruct as our teacher model. The detailed data configurations, hyperparameter settings and specific prompts are provided in Appendix C. 6 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "4.2 MAIN RESULTS",
            "content": "As shown in Table 1, our 8B model sets new state-of-the-art across diverse range of chemical benchmarks. It surpasses not only general-purpose models like Gemini-2.5-Pro and other chemical foundation models like ether0-24B, but also outperforms task-specific specialist models in Property Prediction, Molecule Design, and TOMG tasks (see Appendix D). While the non-reasoning chemical model ChemDFM-v1.5-8B achieves higher score in the Molecule Design task with direct outputs, Chem-R provides interpretable, step-by-step reasoning chains, offering critical explainability for scientific discovery. The models most significant advances are in reaction-related tasks, where its performance represents paradigm shift. Chem-R achieves score of 0.85 in Yield Prediction (more than doubling the next-best score) and 0.39 in Retrosynthesis, nearly threefold improvement over the strongest baseline of 0.15. These results validate that our methodology enables superior chemical reasoning within an efficient 8B parameter model. Additionally, the models performance at various training phases is shown in Figures 3(a) and (b). For the performance curve during the multi-task GRPO phase, please refer to Figures 3(d) and (e). Table 1: Performance of different models on chemistry-related tasks. The score for each major task is the average of its subtasks. Column headers use short names: Name = Name Prediction (evaluated by Exact Match), Prop. = Property Prediction (Accuracy), Design = Molecule Design (Accuracy), Capt. = Molecule Captioning (BLEU-4), TOMG = Tasks in TOMG-Bench (Weighted Accuracy), Yield = Yield Prediction (Accuracy), Reag. = Reagents Selection (Accuracy), React. = Reaction Prediction (Accuracy), Retro = Retrosynthesis (Exact Match). For each column: the best and second-best models are highlighted. Model Name Prop. Design Capt. TOMG Yield Reag. React. Retro Molecule Tasks Reaction Tasks General Foundation Models GPT-4o Llama-3.1-8B-Instruct Llama-3.3-70B 0.01 0.00 0.01 General Reasoning Models Gemini-2.5-Pro DeepSeek-R1 QWQ-32B 0.17 0.05 0. Chemical Foundation Models ChemLLM-DPO-20B ChemDFM-v1.5-8B ChemDFM-v1.0-13B 0.00 0.14 0.16 Chemical Reasoning Models ether0-24B Chem-R-8B (Ours) 0.15 0.49 4.3 ABLATION STUDY 0.68 0.47 0. 0.56 0.63 0.71 0.49 0.74 0.78 0.64 0.87 0.07 0.00 0.03 0.29 0.22 0.03 0.00 0.53 0. 0.30 0.42 0.01 0.01 0.02 0.04 0.04 0.04 0.03 0.10 0.27 0.03 0.41 0.32 0.07 0. 0.30 0.10 0.12 0.27 0.03 0.42 0.20 0.26 0.22 0.35 0.33 0.29 0.21 0.37 0. 0.03 0.85 0.26 0.26 0.38 0.27 0.13 0.39 0.08 0.35 0.37 0.21 0.69 0.04 0.00 0. 0.04 0.34 0.01 0.02 0.50 0.31 0.65 0.82 0.00 0.00 0.00 0.15 0.13 0.00 0.00 0.07 0. 0.04 0.39 Phase-wise Contributions. To understand the unique contribution of each training phase, we systematically removed individual phases while holding all other variables constant. The results, shown in Table 2 (A), confirm that all three phases are essential and work synergistically. First, Phase 1 (Foundation Training) establishes the models fundamental understanding of chemistry. Removing this phase severely degrades performance, as seen by the Name Prediction score dropping from 0.49 to 0.14. While critical, this phase does not by itself enable the chain-of-thought reasoning necessary for explainability. The ability to reason emerges in Phase 2 (CRP Distillation), which introduces the core reasoning framework. Without it, the model fails at performing complex reasoning; for example, performance on Reaction Prediction collapses to zero when both Phase 1 and 2 are removed. Lastly, Phase 3 (Multi-task GRPO) acts as crucial refinement stage. Building on the skills from the previous phases, it delivers consistent improvements, boosting the Reagent Selection score from 0.50 to 0.69. Components of Instantiated Protocol in Phase 2. We analyze the two core components of our CRP Distillation in Phase 2: the tasks governing CRP and Correct Information. As detailed in 7 Chem-R: Learning to Reason as Chemist Figure 3: Comprehensive evaluation of Chem-R. (a) Molecule task performance in different phases. (b) Reaction task performance in different phases. (c) Effect of sample size (k) on performance. (d) Molecule task performance during phase 3. (e) Reaction task performance during phase 3. (f) Model performance comparison across OOD tasks in ChemCoTBench (Li et al., 2025a). Table 2 (B) and cases in Appendix E, the CRP is crucial for improving accuracy by enforcing logical structure on the reasoning. Its absence results in consistent performance decline across tasks; for example, the Retrosynthesis score decreases from 0.28 to 0.20 (compared with ChemR w/o Phase 3). Furthermore, incorporating the ground-truth Correct Information is essential for generating high-quality, large-scale dataset of reasoning chains. Removing this component leads to severe degradation in performance, with the Reaction Prediction score dropping from 0.69 to only 0.13. Therefore, the CRP provides the indispensable reasoning architecture, while the Correct Information ensures that architecture is used to teach truth, not sophisticated error. Single-task vs. Multi-task Training in Phase 2. As shown in Table 2 (C), we compare specialized Single-task models against unified Multi-task model in Phase 2. While Single-task models (i.e., 9 models in total) achieve high scores on their respective tasks, such as 0.75 in Reaction Prediction, confirming the quality of our distilled CoT data, the Multi-task model demonstrates clear positive transfer. It outperforms Single-task models on related tasks like Reagent Selection (0.50 vs. 0.46) and Retrosynthesis (0.28 vs. 0.26). Effect of Sample Size in Phase 2. We investigate the effect of the sample size, k, used to generate the CRP in Phase 2. As shown in Figure 3 (c), performance on both Name Prediction and Molecule Design improves rapidly as increases, but the gains begin to diminish significantly after reaches approximately 10. This indicates that simply collecting more samples for single task yields limited returns. Crucially, we find that small number of samples (e.g., k=5) is sufficient when we enhance the protocol with our cross-task mixture strategy. This efficient approach allows us to achieve high level of performance, as indicated by the dotted lines, without the need for extensive sampling. This is critical advantage for complex tasks where successful reasoning paths are often too scarce to collect in large numbers. Uniform vs. Weighted Sampling in Phase 3. comparison between Uniform and our Weighted sampling in Phase 3 demonstrates the effectiveness of the latter. The results, presented in Table 2 (D), indicate that allocating more training focus to tasks the model finds more difficult yields significant performance gains within the same number of training steps. Notably, the score for the challenging Retrosynthesis task improved from 0.33 to 0.39, and the Reagent Selection score rose from 0.63 to 0.69. Generalization to Out-of-Distribution Tasks. To assess our models generalization capabilities, we evaluate it on four out-of-distribution (OOD) molecule optimization tasks (Solubility, DRD2, JNK3, and GSK3) from ChemCoTBench (Li et al., 2025a). We intentionally select these tasks because they are not part of our training data and differ significantly from our training objectives, providing robust test of generalization. As shown in Figure 3 (f), the baseline model (Llama-3.18B-Instruct) performs poorly, confirming its inability to generalize. In contrast, Chem-R achieves Chem-R: Learning to Reason as Chemist Table 2: Ablation study across 9 chemistry tasks (25 sub-tasks). Columns follow the same shorthand as the main table. Gray cells denote Chem-Rs performance. Ablation Variant Name Prop. Design Capt. TOMG Yield Reag. React. Retro Molecule Tasks Reaction Tasks (A) Phase-wise Contributions Chem-R w/o Phase 1 Chem-R w/o Phase 2 Chem-R w/o Phase 3 Chem-R w/o Phase 1&2 Chem-R w/o Phase 1&3 Chem-R w/o Phase 2&3 Chem-R w/o Phase 1&2&3 0.14 0.53 0.39 0.00 0.10 0.52 0.00 0.87 0.88 0.86 0.67 0.85 0.88 0.47 0.20 0.43 0.35 0.03 0.27 0.43 0.00 0.34 0.41 0.33 0.17 0.27 0.40 0.01 0.38 0.41 0.41 0.30 0.37 0.42 0. 0.87 0.80 0.85 0.80 0.84 0.11 0.26 0.58 0.59 0.50 0.51 0.55 0.55 0.26 0.54 0.82 0.69 0.00 0.48 0.83 0.00 0.34 0.39 0.28 0.00 0.19 0.40 0.00 (B) Components of Instantiated Protocol in Phase 2 Phase 2 w/o CRP Phase 2 w/o Correct Information 0.84 0. 0.31 0.04 0.27 0.07 0.33 0.02 0.42 0.27 0.69 0.67 0.43 0. 0.67 0.13 0.20 0.05 (C) Single-task vs. Multi-task Training in Phase 2 0.87 Single-task 0.86 Multi-task 0.41 0.39 0.40 0.35 0.32 0. 0.41 0.41 0.84 0.85 0.46 0.50 0.75 0.69 0.26 0.28 (D) Uniform vs. Weighted Sampling in Phase 3 Uniform 0.43 0.87 Chem-R-8B (Ours) 0.49 0.87 0. 0.42 0.39 0.41 0.41 0.42 0. 0.85 0.63 0.69 0.81 0.82 0. 0.39 massive leap in performance across all four tasks, for example, improving the success rate on Solubility from 10% to 83%. Human Expert Evaluation. To qualitatively assess CoTs, we conduct human expert evaluation. We had chemistry PhDs rate 50 randomly sampled responses from Chem-R and three strong baselines (Gemini-2.5Pro, DeepSeek-R1, ether0) on 1-to-5 scale across six dimensions, with detailed rubric available in the Appendix D. The averaged scores are visualized in radar chart for comparison, as shown in Figure 4. Chem-R receives the highest scores across all six metrics, from Chemical Soundness and Logical Coherence to Expertlevel Insight, validating the effectiveness of our structured reasoning protocol. This comprehensive feedback confirms that Chem-R not only achieves high accuracy but also generates reasoning chains that are significantly more reliable, interpretable, and aligned with expert thinking. This all-around superiority underscores its potential as more trustworthy and dependable tool for chemical inquiry."
        },
        {
            "title": "5 CONCLUSION",
            "content": "Figure 4: Radar chart of the human expert evaluation. Chem-R establishes new state-of-the-art in chemical reasoning by uniquely emulating the deliberative thought processes of expert chemists. Our novel three-phase training framework systematically builds foundational knowledge, distills structured reasoning protocols, and optimizes for balanced performance across wide array of tasks. This approach enables Chem-R to significantly outperform leading models, including ChemDFM-v1.5-8B and Gemini-2.5-Pro, achieving unprecedented gains, particularly in complex reaction prediction and retrosynthesis tasks. Beyond superior accuracy, Chem-Rs primary advantage lies in its ability to generate interpretable, logically coherent, and chemically sound reasoning chains, quality validated by human expert evaluation. By producing reliable and explainable outputs, Chem-R provides powerful and trustworthy foundation for accelerating the next generation of AI-driven chemical discovery. 9 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "REFERENCES",
            "content": "Ivan Arcuschin, Jett Janiak, Robert Krzyzanowski, Senthooran Rajamanoharan, Neel Nanda, and Arthur Conmy. Chain-of-thought reasoning in the wild is not always faithful. arXiv preprint arXiv:2503.08679, 2025. Lei Bai, Zhongrui Cai, Maosong Cao, Weihan Cao, Chiyu Chen, Haojiong Chen, Kai Chen, Pengcheng Chen, Ying Chen, Yongkang Chen, et al. Intern-s1: scientific multimodal foundation model. arXiv preprint arXiv:2508.15763, 2025. Bowen Baker, Joost Huizinga, Leo Gao, Zehao Dou, Melody Guan, Aleksander Madry, Wojciech Zaremba, Jakub Pachocki, and David Farhi. Monitoring reasoning models for misbehavior and the risks of promoting obfuscation. arXiv preprint arXiv:2503.11926, 2025. Andres Bran, Theo Neukomm, Daniel Armstrong, Zlatko Jonˇcev, and Philippe Schwaller. Chemical reasoning in llms unlocks steerable synthesis planning and reaction mechanism elucidation. arXiv preprint arXiv:2503.08537, 2025. He Cao, Zijing Liu, Xingyu Lu, Yuan Yao, and Yu Li. for building versatile and reliable molecular assistant in drug discovery. arXiv:2311.16208, 2023. Instructmol: Multi-modal integration arXiv preprint Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, et al. Reasoning models dont always say what they think. arXiv preprint arXiv:2505.05410, 2025. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Yilun Du, Shuang Li, Antonio Torralba, Joshua Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. Forty-first International Conference on Machine Learning, 2023. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv e-prints, pp. arXiv2407, 2024. Carl Edwards, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and Heng Ji. Translation between molecules and natural language. arXiv preprint arXiv:2204.11817, 2022. Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. Mol-instructions: large-scale biomolecular instruction dataset for large language models. arXiv preprint arXiv:2306.08018, 2023. Kanishk Gandhi, Ayush Chakravarthy, Anikait Singh, Nathan Lile, and Noah Goodman. Cognitive behaviors that enable self-improving reasoners, or, four habits of highly effective stars. arXiv preprint arXiv:2503.01307, 2025. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Taicheng Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh Chawla, Olaf Wiest, Xiangliang Zhang, et al. What can large language models do in chemistry? comprehensive benchmark on eight tasks. Advances in Neural Information Processing Systems, 36:5966259688, 2023. Kan Hatakeyama-Sato, Naoki Yamane, Yasuhiko Igarashi, Yuta Nabae, and Teruaki Hayakawa. Science and Prompt engineering of gpt-4 for chemical research: what can/cannot be done? Technology of Advanced Materials: Methods, 3(1):2260300, 2023. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. 10 Chem-R: Learning to Reason as Chemist Ross Irwin, Spyridon Dimitriadis, Jiazhen He, and Esben Jannik Bjerrum. Chemformer: pretrained transformer for computational chemistry. Machine Learning: Science and Technology, 3 (1):015022, 2022. Lei Jiang, Shuzhou Sun, Biqing Qi, Yuchen Fu, Xiaohua Xu, Yuqiang Li, Dongzhan Zhou, and Tianfan Fu. Chem3dllm: 3d multimodal large language models for chemistry. arXiv preprint arXiv:2508.10696, 2025. Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, and Yuri Burda. Prover-verifier games improve legibility of llm outputs. arXiv preprint arXiv:2407.13692, 2024. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:2219922213, 2022. HJ Kuhn, SE Braslavsky, and Schmidt. Chemical actinometry (iupac technical report). Pure and Applied Chemistry, 76(12):21052146, 2004. Youngchun Kwon, Dongseon Lee, Youn-Suk Choi, and Seokho Kang. Uncertainty-aware prediction of chemical reaction yields with graph neural networks. Journal of Cheminformatics, 14(1):2, 2022. Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, and Yu Li. Beyond chemical qa: Evaluating llms chemical reasoning with modular chemical operations. arXiv preprint arXiv:2505.21318, 2025a. Jiatong Li, Junxian Li, Yunqing Liu, Dongzhan Zhou, and Qing Li. Tomg-bench: Evaluating llms on text-based open molecule generation. arXiv preprint arXiv:2412.14642, 2024a. Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang Tang, and Qing Li. Empowering molecule discovery for molecule-caption translation with large language models: chatgpt perspective. IEEE transactions on knowledge and data engineering, 2024b. Jiatong Li, Weida Wang, Qinggang Zhang, Junxian Li, Di Zhang, Changmeng Zheng, Shufei Zhang, Xiaoyong Wei, and Qing Li. Mol-r1: Towards explicit long-cot reasoning in molecule discovery. arXiv preprint arXiv:2508.08401, 2025b. Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Yaotian Yang, Xinrui Xiong, et al. Chemvlm: Exploring the power of multimodal large language models in chemistry area. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 415423, 2025c. Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Lets verify step by step. The Twelfth International Conference on Learning Representations, 2024. Tianqi Liu, Yao Zhao, Rishabh Joshi, Misha Khalman, Mohammad Saleh, Peter Liu, and arXiv preprint Jialu Liu. Statistical rejection sampling improves preference optimization. arXiv:2309.06657, 2023a. Xinyi Liu, Lipeng Ma, Yixuan Li, Weidong Yang, Qingyuan Zhou, Jiayi Song, Shuhao Li, and Ben Fei. Chemau: Harness the reasoning of llms in chemical research with adaptive uncertainty estimation. arXiv preprint arXiv:2506.01116, 2025. Zequn Liu, Wei Zhang, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Ming Zhang, and TieYan Liu. Molxpt: Wrapping molecules with text for generative pre-training. arXiv preprint arXiv:2305.10688, 2023b. Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, and Tat-Seng Chua. Molca: Molecular graph-language modeling with cross-modal projector and unimodal adapter. arXiv preprint arXiv:2310.12798, 2023c. 11 Chem-R: Learning to Reason as Chemist Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. Biogpt: generative pre-trained transformer for biomedical text generation and mining. Briefings in bioinformatics, 23(6):bbac409, 2022. Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua Tenenbaum, Daniela Rus, Chuang Gan, and Wojciech Matusik. Llm and simulation as bilevel optimizers: new paradigm to advance physical scientific discovery. arXiv preprint arXiv:2405.09783, 2024. Siddharth M. Narayanan, James D. Braza, Ryan-Rhys Griffiths, Albert Bou, Geemi P. Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G. Rodriques, and Andrew D. White. Training scientific reasoning model for chemistry. arXiv preprint arXiv:2506.17238, 2025. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35, 2022. Siru Ouyang, Zhuosheng Zhang, Bing Yan, Xuan Liu, Yejin Choi, Jiawei Han, and Lianhui Qin. Structured chemistry reasoning with large language models. arXiv preprint arXiv:2311.09656, 2023. Richard Yuanzhe Pang, Weizhe Yuan, He He, Kyunghyun Cho, Sainbayar Sukhbaatar, and Jason Weston. Iterative reasoning preference optimization. Advances in Neural Information Processing Systems, 2024. Qizhi Pei, Wei Zhang, Jinhua Zhu, Kehan Wu, Kaiyuan Gao, Lijun Wu, Yingce Xia, and Rui Yan. Biot5: Enriching cross-modal integration in biology with chemical knowledge and natural language associations. arXiv preprint arXiv:2310.07276, 2023. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher Manning, Stefano Ermon, and Chelsea Finn. Direct preference optimization: Your language model is secretly reward model. Advances in neural information processing systems, 2023. Kohulan Rajan, Achim Zielesny, and Christoph Steinbeck. Stout: Smiles to iupac names using neural machine translation. Journal of Cheminformatics, 13(1):34, 2021. Malik Sallam, Khaled Al-Salahat, Huda Eid, Jan Egger, and Behrus Puladi. Human versus artificial intelligence: Chatgpt-4 outperforming bing, bard, chatgpt-3.5 and humans in clinical chemistry multiple-choice questions. Advances in Medical Education and Practice, pp. 857871, 2024. Nadine Schneider, Nikolaus Stiefl, and Gregory Landrum. Whats what: The (nearly) definitive guide to reaction role assignment. Journal of chemical information and modeling, 56(12):2336 2346, 2016. Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, and Chandan Reddy. Llm-sr: Scientific equation discovery via programming with large language models. arXiv preprint arXiv:2404.18400, 2024. Qian Tan, Dongzhan Zhou, Peng Xia, Wanhao Liu, Wanli Ouyang, Lei Bai, Yuqiang Li, and Tianfan Fu. Chemmllm: Chemical multimodal large language model. arXiv preprint arXiv:2505.16326, 2025. Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: large language model for science. arXiv preprint arXiv:2211.09085, 2022. Yuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, and Junxian He. Dart-math: Difficulty-aware rejection tuning for mathematical problem-solving. Advances in Neural Information Processing Systems, 2024. Peiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and Zhifang Sui. Math-shepherd: Verify and reinforce llms step-by-step without human annotations. Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024. 12 Chem-R: Learning to Reason as Chemist Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. David Weininger. Smiles, chemical language and information system. 1. introduction to methodology and encoding rules. Journal of chemical information and computer sciences, 28(1):3136, 1988. Zhenqin Wu, Bharath Ramsundar, Evan Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh Pappu, Karl Leswing, and Vijay Pande. Moleculenet: benchmark for molecular machine learning. Chemical science, 9(2):513530, 2018. Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, et al. Nature language model: Deciphering the language of nature for scientific discovery. arXiv preprint arXiv:2502.07527, 2025. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, arXiv preprint Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv:2505.09388, 2025. Di Zhang, Xiaoshui Huang, Dongzhan Zhou, Yuqiang Li, and Wanli Ouyang. Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b. arXiv preprint arXiv:2406.07394, 2024a. Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, Weiran Huang, Xiangyu Yue, Wanli Ouyang, et al. Chemllm: chemical large language model. arXiv preprint arXiv:2402.06852, 2024b. Di Zhang, Weida Wang, Junxian Li, Xunzhi Wang, Jiatong Li, Jianbo Wu, Jingdi Lei, Haonan He, Peng Ye, Shufei Zhang, et al. Control-r: Towards controllable test-time scaling. arXiv preprint arXiv:2506.00189, 2025a. Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, and Rishabh Agarwal. Generative verifiers: Reward modeling as next-token prediction. The Thirteenth International Conference on Learning Representations, 2025b. Yu Zhang, Yang Han, Shuai Chen, Ruijie Yu, Xin Zhao, Xianbin Liu, Kaipeng Zeng, Mengdi Yu, Jidong Tian, Feng Zhu, et al. Large language models to accelerate organic chemistry synthesis. Nature Machine Intelligence, pp. 113, 2025c. Guojiang Zhao, Sihang Li, Zixiang Lu, Zheng Cheng, Haitao Lin, Lirong Wu, Hanchen Xia, Hengxing Cai, Wentao Guo, Hongshuai Wang, et al. Molreasoner: Toward effective and interpretable reasoning for molecular llms. arXiv preprint arXiv:2508.02066, 2025a. Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Yansi Li, Zhongyang Dai, Xin Chen, and Kai Yu. Chemdfm-x: towards large multimodal model for chemistry. Science China Information Sciences, 2024. Zihan Zhao, Bo Chen, Ziping Wan, Lu Chen, Xuanze Lin, Shiyang Yu, Situo Zhang, Da Ma, Zichen Zhu, Danyang Zhang, et al. Chemdfm-r: An chemical reasoner llm enhanced with atomized chemical knowledge. arXiv preprint arXiv:2507.21990, 2025b. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, Hongshen Xu, Zichen Zhu, Su Zhu, et al. Developing chemdfm as large language foundation model for chemistry. Cell Reports Physical Science, 6(4), 2025c. Zhiqiang Zhong, Kuangyu Zhou, and Davide Mottin. Benchmarking large language models for molecule prediction tasks. arXiv preprint arXiv:2403.05075, 2024. Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng Zhang, and Guolin Ke. Uni-mol: universal 3d molecular representation learning framework. 2023. 13 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "Appendix",
            "content": "A Overview of the Appendix Task Description B.1 Molecular Tasks . B.2 Reaction Tasks . . . Implementation Details C.1 Hyper-parameters . C.2 Data Statistics . . . . . . . C.3 Distillation Prompts . C.4 Human Evaluation . Experiement Result D.1 Name Prediction . . D.2 Property Prediction . D.3 Molecule Design . . . . . . . . . . . D.4 Molecule Captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.5 Text-based Open Molecule Generation . . . . . . . . . . . . . . . . . . . . . . . . D.6 Yield Prediction . . D.7 Reagent Selection . . . D.8 Reaction Prediction . D.9 Retrosynthesis . . D.10 Out of Domain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . More Cases Use of LLMs 15 15 15 17 19 20 22 36 37 37 38 38 39 41 41 42 42 43 48 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "A OVERVIEW OF THE APPENDIX",
            "content": "Section (Task Description) outlines the various tasks used to evaluate the model, which are divided into two main categories. Molecular Tasks focus on individual molecules, including challenges like predicting chemical names and properties, designing new molecules, and generating descriptions. Reaction Tasks involve chemical transformations, such as predicting reaction yields, selecting reagents, and determining the products or starting materials of reaction. Section (Implementation Details) details the technical methodology of the study. It covers the specific hyper-parameters for model training, the data statistics showing how datasets were divided, and the structured distillation prompts used to guide the models reasoning process. Additionally, it explains the criteria for the human evaluation performed by chemistry experts to assess the quality of the models logic. Section (Experiment Result) presents the quantitative outcomes of the experiments. It contains series of tables with performance metrics that demonstrate the models effectiveness on each of the tasks described in Section and on OOD tasks, providing detailed, data-driven assessment of its capabilities in chemical reasoning. Section (More Case) provides additional, specific examples of the models outputs. Section (Use of LLM) clarifies the specific role and application of LLMs within this research."
        },
        {
            "title": "B TASK DESCRIPTION",
            "content": "In this section, we describe the tasks used in our experiments, which span both molecular tasks and reaction tasks. We selected these tasks from four widely recognized chemistry benchmarksChEBI-20, ChemLLMBench, USPTO, and TOMG-Benchbased on their practical relevance and the diversity they offer in evaluating molecular and reaction-level capabilities. These tasks cover range of applications, from molecule generation and property prediction to reaction prediction and retrosynthesis, providing comprehensive evaluation of the models performance in chemical reasoning. B.1 MOLECULAR TASKS In this task, the goal is to convert between IUPAC names (International (1) Name Prediction. Union of Pure and Applied Chemistry) and SMILES (Simplified Molecular Input Line Entry System) strings, which are two widely used methods for representing chemical structures. IUPAC names provide formal, systematic way to describe molecules based on their structure, while SMILES is textual representation that encodes molecular structure through series of symbols and characters. Converting between these formats requires reasoning about the chemical structure itselfunderstanding the arrangement of atoms, bonds, functional groups, and molecular topology. The model must interpret the chemical details embedded in IUPAC names or SMILES strings and produce the corresponding representation, which involves complex reasoning about chemical conventions and rules. Name Prediction (SMILESIUPAC) Question: Provide the IUPAC name for the following molecule. SMILES: CCOC(=O)C(C(C)=O)=C(C)N. Answer: ethyl 2-acetyl-3-aminobut-2-enoate (2) Property Prediction. Property prediction involves classifying molecules into categories based on their biological activity or toxicity (i.e., BBBP, HIV, Tox21, ClinTox, BACE). For this, the model needs to reason about the underlying structure-property relationships. molecules structure influences its biological properties through factors like functional group interactions, molecular size, and polarity. The model must learn these complex relationships from data and reason about which aspects of the molecules structure contribute to its biological effects. This makes property prediction key task for reasoning models, as they must generalize these chemical insights across diverse molecular structures and predict their effects. 15 Chem-R: Learning to Reason as Chemist Property Prediction (BACE) Question: Predict whether the following molecule can inhibit BACE1 (Yes/No). SMILES: Clc1cc(cnc1)-c1cc2c(CC(CC23N=C(OC3)N)(C)C)cc1. Answer: No In this task, model is given textual description of molecule and must (3) Molecule Design. generate its corresponding SMILES representation. The challenge here is that the model needs to map linguistic descriptions (which are often abstract) to concrete molecular structures. For instance, the description might mention the presence of functional group, the molecules size, or other key features, which the model must translate into valid SMILES string. This task requires the model to reason about the relationship between the described features and how they translate into molecular structure. It tests the models ability to use abstract information to generate precise molecular representations, showcasing its reasoning in both language and chemistry. Molecule Design Question: Generate molecules SMILES string that fits the following description. Description: The molecule is member of the class of cyclopentanols carrying 1,2,4-triazol1-ylmethyl and 4-chlorobenzylidene and geminal dimethyl substituents at positions 1, 2 and 5 respectively. It is member of triazoles, member of monochlorobenzenes, member of cyclopentanols, tertiary alcohol and an olefinic compound. Answer: CC1(C)CC/C(=Cc2ccc(Cl)cc2)C1(O)Cn1cncn1 (4) Molecule Captioning. This task is the inverse problem of molecule design. Given SMILES string, the model generates natural language description of the molecule. Here, the model must reason about the structure encoded in the SMILES and generate coherent description that accurately captures key molecular features, such as functional groups, chemical bonding, and overall molecular properties. The challenge lies in translating the complex, compact SMILES format into human-readable description that captures both the structure and function of the molecule. It requires the model to interpret structured representation and reason about how to explain it in way that makes sense in natural language. Molecule Captioning Question: Provide chemical description for the following molecule. SMILES: CC1(C)CC/C(=Cc2ccc(Cl)cc2)C1(O)Cn1cncn1. Answer: The molecule is member of the class of cyclopentanols carrying 1,2,4-triazol1-ylmethyl and 4-chlorobenzylidene and geminal dimethyl substituents at positions 1, 2 and 5 respectively. It is member of triazoles, member of monochlorobenzenes, member of cyclopentanols, tertiary alcohol and an olefinic compound. (5) Text-based Open Molecule Generation. The TOMG-Bench benchmark focuses on text-based open molecule generation, evaluating models ability to generate, modify, and optimize molecular structures based on textual descriptions or specified criteria. Tasks in this benchmark include Customized Molecule Generation, Molecule Editing, and Molecule Optimization. In Customized Molecule Generation, the model is tasked with creating molecules that meet specific constraints, such as predefined number of atoms, bonds, or functional groups, while maintaining chemical validity. Molecule Editing requires the model to modify an existing molecule by adding, replacing, or removing functional groups, with the challenge of reasoning about how these changes affect the overall structure and properties of the molecule. Molecule Optimization involves optimizing molecules to improve specific properties like LogP (partition coefficient), QED (drug-likeness), and MR (molecular refractivity), where the model must navigate trade-offs between conflicting goals, such as balancing hydrophobicity to improve LogP without compromising QED. Together, these tasks test models ability to generate, edit, and optimize molecules, requiring reasoning about molecular structure, function, and the interdependencies between chemical properties. Chem-R: Learning to Reason as Chemist Text-based Open Molecule Generation (MolOpt-LogP) Question: Modify the molecule N#CCC1(n2cc(-c3ccnc4[nH]ccc34)cn2)C[NH+](C2CCN(C(=O)Nc3ccccc3Cl) CC2)C1 to have lower LogP value. Answer: O=C(Nc1ccccc1Cl)N1CCC([NH+]2CC(CO)(n3cc(-c4ccnc5[nH]ccc4 5)cn3)C2)CC1 B.2 REACTION TASKS (6) Yield Prediction. Yield prediction involves determining whether given chemical reaction will result in high or low yield based on the reactants and reaction conditions in the BuchwaldHartwig and Suzuki-coupling reactions. Here, reasoning is necessary because predicting the yield requires the model to understand both the intrinsic properties of the reactants and the external factors that can influence the efficiency of the reaction. It requires the model to simulate the chemical behavior of the system, predict potential losses, and estimate the likelihood of successful reaction based on prior examples. This is classic task of predicting outcomes under uncertainty, demanding robust reasoning capabilities to account for various complex variables. Yield Prediction (Buchwald-Hartwig reaction) Question: Predict if the following Buchwald-Hartwig reaction is high-yielding (Yes for >70% yield, No otherwise). Reaction: Brc1cccnc1.Cc1ccc(N)cc1. O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2N-1)C(F)(F)F. COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H] 4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C. CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C. CCOC(=O)c1cc(OC)no1>>Cc1ccc(Nc2cccnc2)cc1. Answer: No (7) Reagent Selection. This task involves selecting the appropriate reagents (reactants, solvents, and ligands) from predefined list for given reaction. Reasoning is critical here, as the model must understand the chemical context of the reaction and predict which reagents will interact most effectively to drive the desired transformation. Importantly, we choose this task over USPTO-Condition because, in Reagent Selection, each option comes with an associated yield value, making the reasoning more concrete and verifiable. Additionally, this task more closely mimics real-world chemical practices, where chemists have to select reagents from limited set of available chemicals, often due to budget, availability, or experimental constraints. In contrast, USPTO-Condition involves broader, less constrained reaction conditions that may not align with practical laboratory limitations, and its accuracy is harder to verify because it lacks specific yield values and focuses on wider range of conditions. Thus, Reagent Selection provides more focused and realistic task, better suited to evaluating models ability to reason within the practical boundaries of chemical experimentation. 17 Chem-R: Learning to Reason as Chemist Reagent Selection Question: From the provided list, select the optimal reactant to maximize the yield for the following reaction setup. Reaction Setup: reactant: Ic1ccc2ncccc2c1 catalyst: CC(=O)[O-].CC(=O)[O-].[Pd+2] ligand: none reagent: O=P([O-])([O-])[O-].[K+].[K+].[K+] solvent: C1CCOC1 list of reactants for selection: [B(O)O, Cc1ccc2c(cnn2C2CCCCO2)c1B1OC(C)(C)C(C)(C)O1, Cc1ccc2c(cnn2C2CCCCO2)c1[B-](F)(F)F.[K+]] Answer: Cc1ccc2c(cnn2C2CCCCO2)c1B1OC(C)(C)C(C)(C)O (8) Reaction Prediction. This task requires predicting the products of chemical reaction based on the given reactants and reaction conditions. Reasoning is essential here because the model needs to understand the underlying chemistry, such as functional group reactivity, reaction mechanisms, and stereochemistry, in order to predict the correct products. Unlike simpler tasks that only involve pattern recognition, this task demands an ability to apply chemical principles (like how certain bonds break and form) and anticipate the reactions outcome, which requires sophisticated reasoning beyond just memorization. Reaction Prediction Question: Predict the main product(s) for the following reaction. Reactants: CN(C)C=O.COc1cccc(N)c1.Cc1nc(CCl)cs1.Cl.O=C([O-])[O-].[K+].[K+] Answer: COc1cccc(NCc2csc(C)n2)c1 (9) Retrosynthesis. Retrosynthesis involves predicting the starting materials (reactants) required to synthesize given target molecule. To perform reasoning, the model needs to deconstruct the target molecule into simpler components and reverse-engineer the chemical process. This requires understanding reaction pathways, identifying suitable reactions to break bonds, and selecting the appropriate reagents. Its form of reverse reasoning, where the model must consider multiple potential pathways and choose the one that is most likely to lead to the desired product, based on its chemical structure and reactivity. Retrosynthesis Question: Predict the necessary reactant(s) for the following product. Product: CNC(=O)c1c(-c2ccc(F)cc2)oc2cc(N(C)S(C)(=O)=O)c(-c3cccc([N+] (=O)[O-])c3)cc12 Answer: CNC(=O)c1c(-c2ccc(F)cc2)oc2cc(N(C)S(C)(=O)=O)c(Br)cc12. O=[N+]([O-])c1cccc(B(O)O)c 18 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "C IMPLEMENTATION DETAILS",
            "content": "C.1 HYPER-PARAMETERS In this section, we list the hyper-parameters used in different phases of training and inference. We used Llama-Factory to conduct SFT training (Phase 1 and Phase 2), and EasyR1 for GRPO training (Phase 3). Table 3 provides the values for the hyper-parameters in Phase 1, Phase 2, and Phase 3, as well as for inference. The table includes settings such as the number of GPUs, learning rates, batch sizes, and the number of epochs for each phase. Item Phase 1 gpu number (H100) per device train batch size gradient accumulation steps learning rate num train epochs lr scheduler type warmup ratio epoch Phase 2 gpu number (H100) per device train batch size gradient accumulation steps learning rate num train epochs lr scheduler type warmup ratio epoch Value 2 1 4 1.0e-5 5 cosine 0.1 3 2 1 4 1.0e-5 5 cosine 0.1 5 Item Phase 3 gpu number (H100) learning rate weight decay kl coef rollout.temperature global batch size rollout batch size micro batch size per device for update epoch step Inference temperature top max tokens Value 8 1.0e-6 1.0e-2 1.0e-2 5 1.0 128 512 4 3 683 0.6 0.9 4096 Table 3: Hyper-parameters for Different Phases of Training and Inference 19 Chem-R: Learning to Reason as Chemist C.2 DATA STATISTICS In this section, we outline the data splits used across different phases of training. The data partitioning follows the benchmark division strategies, ensuring that the test set is consistent with the evaluation criteria and standards. The amount of training data is strategically varied across the phases to match their distinct objectives: Phase 1 (Chemical Foundation Training): The goal is to build comprehensive foundation of chemical knowledge. Therefore, this phase utilizes large volume of questionanswer pairs (e.g., 920k for Name Prediction) to ensure broad exposure to facts and patterns. Phase 2 (CRP Distillation): This phase focuses on teaching structured reasoning method using high-quality synthetic CoT data. The strategy here is to provide substantial and relatively balanced number of examples across different task categories, generally targeting around 100k samples per major task. For tasks identified as particularly difficult, such as Name Prediction, we ensure higher volume of data to help the model master their complex reasoning protocols. Phase 3 (Multi-task GRPO): The objective is to refine the models reasoning skills. For this targeted alignment, the amount of training data for each task is not fixed but is calculated based on the models performance after Phase 2. This strategy, detailed in Section 3.3, allows us to concentrate the training effort on tasks the model finds more difficult, optimizing the refinement process. Importantly, we ensure that no molecules appearing in the test set are included in the training sets. For detailed overview of the data splits and their distribution, please refer to Table 4. It is particularly noteworthy that the TOMG tasks were intentionally excluded from the GRPO phase (Phase 3) due to their long evaluation times and better performance. Chem-R: Learning to Reason as Chemist Tasks Name Prediction SMILES2IUPAC IUPAC2SMILES Property Prediction BACE BBBP ClinTox HIV Tox21 Molecule Design ChEBI-20 Molecule Captioning ChEBIPhase 1 Phase 2 Phase 3 Train Valid Test 920,734 920,734 100,000 100,000 6,978 7,821 828,661 828,661 500 500 1,413 1,950 1,384 41,027 20,000 20,000 20,000 20,000 20,000 3,489 2,286 241 0 2,166 1,413 1,950 1,384 41,027 7,914 50 50 50 50 50 100 100 100 100 100 100 26,407 100,000 7,821 26,407 3,300 3, 26,407 100,000 7,008 26,407 3,300 3, Text-based Open Molecule Generation MolCustom-AtomNum MolCustom-BondNum MolCustom-FunctionalGroup MolEdit-AddComponent MolEdit-DelComponent MolEdit-SubComponent MolOpt-LogP MolOpt-MR MolOpt-QED 133,334 133,334 133,334 133,333 133,333 133,333 133,333 133,333 133,333 Yield Prediction Buchwald-Hartwig Suzuki-Miyaura Reagent Selection Reactant Selection Solvent Selection Ligand Selection Reaction Prediction USPTO-Mixed Retrosynthesis USPTO-50k 33,333 33,333 33,333 33,333 33,333 33,333 33,333 33,333 33,333 40,515 58,485 44,763 41,770 13,467 1,925 1,685 5,174 6,497 6, 133,334 133,334 133,334 133,333 133,333 133,333 133,333 133,333 133,333 3,855 5,660 1,436 1,340 380 50 50 100 100 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 100 100 100 100 100 3,855 5,660 1,436 1,340 380 409, 100,000 3,730 409,035 30,000 100 40, 100,000 8,663 40,029 5,004 100 Table 4: Tasks and data splits across different phases. Note that the quantities listed for Phases 1, 2, and 3 refer to the total data volume, inclusive of any repeated samples. 21 Chem-R: Learning to Reason as Chemist C.3 DISTILLATION PROMPTS Name Prediction (SMILESIUPAC) You are an expert chemist demonstrating how to determine the IUPAC name for given molecule. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. Your task is to generate step-by-step reasoning process that logically deduces the systematic IUPAC name from the SMILES string. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Deconstruct & Analyze: Thoroughly parse the SMILES string to visualize the molecular graph, identifying all functional groups, cyclic systems, points of unsaturation, and any specified stereocenters. * Translate the linear SMILES notation into clear mental or physical representation of the molecular structure. * Systematically identify every functional group and ring, paying close attention to IUPAC priority. * Note all stereochemical indicators (@, @@, /, ) for inclusion in the final name. 2. Determine the Principal Chain or Parent Ring: Apply IUPAC priority rules to identify the principal functional group, which in turn determines the parent structure (the longest chain or main ring system) and the suffix of the name. * The parent structure must contain the highest-priority functional group. * If choice exists, the parent is the structure with the most multiple bonds, then the longest carbon chain. 3. Number & Name the Parts: Systematically number the atoms of the parent structure to assign the lowest possible locant to the principal functional group, then identify and name all substituent groups attached to the parent. * The numbering must grant the lowest locant to the principal functional group above all other considerations. * If choice remains, assign lowest locants to multiple bonds, then to the first point of difference in substituent locants. * Correctly name each substituent (e.g., methyl, chloro) and note its locant. 4. Assemble & Order: Construct the complete IUPAC name by arranging the named substituents alphabetically, prefixing them to the parent name, and incorporating all locants and stereochemical descriptors in their correct positions. * Alphabetize substituents by name, ignoring multiplying prefixes (di, tri) but not iso or neo. * Assemble the final name in the standard order: Stereochemistry-Substituents-Parent-Suffix. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} Ground-truth IUPAC Name: {target} Output: <think> 1. Deconstruct & Analyze: ... 2. Determine the Principal Chain or Parent Ring: ... 3. Number & Name the Parts: ... 4. Assemble & Order: ... </think> <answer>{target}</answer> 22 Chem-R: Learning to Reason as Chemist Name Prediction (IUPACSMILES) You are an expert chemist demonstrating how to determine the IUPAC name for given molecule. You are given: 1. An IUPAC name representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. Your task is to generate step-by-step reasoning process that logically deduces the SMILES string from the IUPAC name. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Deconstruct IUPAC Name & Identify Components: Break down the IUPAC name into its fundamental components, identifying the parent structure (chain or ring), principal functional group, all substituents, and their corresponding locants. * The parent name (e.g., hexane, cyclohexane) forms the SMILES backbone. * Pay close attention to suffixes (-ol, -one, -oic acid) as they define the principal group. * Isolate all stereochemical prefixes (R/S, E/Z, cis/trans) for later use. 2. Formulate Conceptual Structure: Translate the deconstructed components into clear, verbal description of the molecules connectivity, specifying how each substituent attaches to the parent structure at its designated locant. * This step acts as blueprint before writing any SMILES code. * Mentally or explicitly number the parent chain to map out attachment points. * Clarify the precise atom-to-atom connections for all parts. 3. Attempt SMILES Translation: Individually convert each identified componentthe parent structure, substituents, and functional groupsinto its correct SMILES representation, treating them as separate fragments. * Use parentheses () for branches off the main chain. * Represent double and triple bonds with = and #, respectively. * Keep track of numeric labels for defining ring closures. 4. Construct Final SMILES String: Systematically assemble the individual SMILES fragments into single, valid string, ensuring correct connectivity, branching, ring closures, and the inclusion of stereochemical markers. * Start with the fragment for the principal functional group or logical endpoint of the main chain. * Insert substituent fragments inside parentheses at the correct atom of the main chain. * Apply stereochemical symbols (@, @@, /, ) last to ensure correct placement relative to the final structure. Input: IUPAC: {instruction} FunctionalGroups: {functional groups str} Ground-truth SMILES Name: {target} Output: <think> 1. Deconstruct Name & Identify Components: ... 2. Formulate Conceptual Structure: ... 3. Translate Components to SMILES: ... 4. Assemble & Finalize String: ... </think> <answer>{target}</answer> 23 Chem-R: Learning to Reason as Chemist Property Prediction (BACE1) You are an expert chemist demonstrating how to predict the BACE1 inhibition potential of molecule from its chemical structure. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. Your task is to generate step-by-step reasoning process that logically deduces whether the molecule can inhibit (Yes) or cannot inhibit (No) the Beta-site Amyloid Precursor Protein Cleaving Enzyme 1 (BACE1). You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Structural/Property Identification: Analyze the SMILES to identify key pharmacophores, functional groups, and physicochemical properties relevant for BACE1 inhibition. * Identify key pharmacophoric features (H-bond donors/acceptors, aromatic rings). * Assess general drug-like properties such as MW, flexibility, and logP. * Check for structural motifs common to known inhibitors of this target class. 2. Property-Activity Correlation: Correlate the identified features with general StructureActivity Relationships (SAR) for BACE1 inhibition. * Assess how functional groups might form hydrogen bonds or electrostatic interactions in an active site. * Evaluate if hydrophobic regions are suitably sized for binding within lipophilic pockets. * Align the molecules properties with general drug-likeness principles (e.g., Lipinskis Rules). 3. Holistic Assessment & Consideration: Synthesize all positive and negative factors to form holistic judgment of the molecules inhibitory potential. * Weigh the combined evidence for and against binding, not just simple count of features. * Consider potential liabilities that could prevent binding, such as steric hindrance or unfavorable charges. 4. Final Prediction Verdict: Conclude with definitive Yes or No prediction based on the integrated assessment. * The final verdict must be direct logical consequence of the previous assessment. * State the primary molecular features that drive the final Yes or No decision. Wrap your entire reasoning process in <think> tags and output only the final answer (Yes or No) in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} Ground-truth Answer: {target} Output: <think> 1. Structural/Property Identification: ... 2. Property-Activity Correlation: ... 3. Holistic Assessment & Consideration: ... 4. Final Prediction Verdict: ... </think> <answer>{target}</answer> 24 Chem-R: Learning to Reason as Chemist Property Prediction (BBBP) You are an expert chemist demonstrating how to predict the Blood-Brain Barrier (BBB) penetration potential of molecule from its chemical structure. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. Your task is to generate step-by-step reasoning process to predict the binary label (Yes for penetration, No for non-penetration) for the given molecules ability to cross the Blood-Brain Barrier. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Structural/Property Identification: Identify key physicochemical properties from the SMILES that govern membrane permeability. * Estimate properties like molecular weight (MW), lipophilicity (logP), and polar surface area (TPSA). * Count hydrogen bond donors/acceptors and identify any permanent charges. 2. Property-Activity Correlation: Correlate the identified properties with principles favoring or hindering BBB penetration. * Assess if size, polarity, and lipophilicity fall within favorable range for passive diffusion. * Recognize that high polarity or permanent charge strongly hinders penetration. 3. Holistic Assessment & Consideration: Synthesize all factors to form balanced judgment on the molecules overall profile for BBB penetration. * Weigh the combined impact of all properties; single critical flaw can prevent penetration. * Consider the possibility of active efflux mechanisms (e.g., P-gp substrate). 4. Final Prediction Verdict: Conclude with definitive Yes or No prediction based on the holistic assessment. * The final verdict must be logical conclusion of the prior analysis. * State the most influential properties driving the decision. Wrap your entire reasoning process in <think> tags and output only the final answer (Yes or No) in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} Ground-truth Answer: {target} Output: <think> 1. Structural/Property Identification: ... 2. Property-Activity Correlation: ... 3. Holistic Assessment & Consideration: ... 4. Final Prediction Verdict: ... </think> <answer>{target}</answer> 25 Chem-R: Learning to Reason as Chemist Property Prediction (ClinTox) You are an expert chemist demonstrating how to predict the clinical trial toxicity of molecule from its chemical structure. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. 3. The FDA approval status for clinical trials. Your task is to generate step-by-step reasoning process to predict whether molecule is Clinically-trial-Toxic (Yes) or Not Clinically-trial-toxic (No). The FDA-approved status is provided as an additional piece of evidence. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Structural/Property Identification: Identify structural alerts, reactive functional groups, and other properties linked to toxicity from the SMILES. * Identify known toxicophores and chemically reactive motifs. * Assess if extreme physicochemical properties (e.g., high MW or logP) increase risk. 2. Property-Activity Correlation: Correlate the identified structural risks with general toxicological principles. * Assess how reactive groups could potentially cause organ damage. * Note that structural alert suggests risk but is not definitive proof of toxicity. 3. Holistic Assessment & Consideration: Synthesize the structural risk analysis with the provided FDA approval status to form comprehensive judgment. * Use the FDA approval status as powerful evidence to adjust the initial structural risk assessment. * An Approved status implies any identified structural risks were clinically acceptable. 4. Final Prediction Verdict: Conclude with definitive Yes or No prediction based on the integrated evidence. * The verdict must balance the structural analysis against the FDA approval status. * State the primary factors that drive the final Yes or No decision. Wrap your entire reasoning process in <think> tags and output only the final answer (Yes or No) in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} FDA APPROVED: {FDA APPROVED} Ground-truth Answer: {target} Output: <think> 1. Structural/Property Identification: ... 2. Property-Activity Correlation: ... 3. Holistic Assessment & Consideration: ... 4. Final Prediction Verdict: ... </think> <answer>{target}</answer> 26 Chem-R: Learning to Reason as Chemist Property Prediction (HIV) You are an expert chemist demonstrating how to predict the HIV replication inhibition potential of molecule from its chemical structure. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. 3. The result from an activity test, classified as CA (confirmed active), CM (confirmed moderately active), or CI (confirmed inactive). Your task is to generate step-by-step reasoning process to predict the binary label for the molecules ability to inhibit HIV replication (Yes or No), considering its structure and the provided activity test result. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Structural/Property Identification: Analyze the SMILES for structural motifs and properties linked to antiretroviral activity. * Identify scaffolds similar to known HIV inhibitor classes (e.g., protease inhibitors). * Assess functional groups for key interactions (e.g., H-bonding) with viral targets. * Evaluate general properties like size and polarity relevant for cellular uptake. 2. Property-Activity Correlation: Correlate the identified features with general mechanisms of HIV inhibition. * Assess the molecules potential to mimic the natural substrates of viral enzymes. * Consider if the molecules geometry is suitable for binding to key viral targets. 3. Holistic Assessment & Consideration: Synthesize the structural analysis with the provided activity data to form comprehensive judgment. * Use the activity result (CA/CM/CI) as key evidence to confirm or override the structural analysis. * CA or CM result strongly supports Yes prediction, even with subtle structural cues. * CI result strongly supports No prediction, regardless of favorable features. 4. Final Prediction Verdict: Conclude with definitive Yes or No prediction based on the integrated evidence. * The verdict must clearly integrate the structural analysis with the activity data. * State the primary factors (e.g., Structurally promising and confirmed by CA result) driving the decision. * The final verdict must explicitly state how the structural analysis and the activity data were combined. * Summarize the key factors (e.g., Structurally promising and confirmed active by CA result) driving the decision. Wrap your entire reasoning process in <think> tags and output only the final answer (Yes or No) in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} activity: {activity} Ground-truth Answer: {target} Output: <think> 1. Structural/Property Identification: ... 2. Property-Activity Correlation: ... 3. Holistic Assessment & Consideration: ... 4. Final Prediction Verdict: ... </think> <answer>{target}</answer> 27 Chem-R: Learning to Reason as Chemist Property Prediction (Tox21) You are an expert chemist demonstrating how to predict the toxicity of molecule from its chemical structure. You are given: 1. SMILES string representing the molecule. 2. list of functional groups present in the molecule (with representative SMILES patterns) to serve as hints. Your task is to generate step-by-step reasoning process to predict whether molecule is toxic (Yes) or not toxic (No). You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Structural/Property Identification: Analyze the SMILES string for known toxicophores, structural alerts, and chemically reactive functional groups. * Identify highly reactive motifs (e.g., Michael acceptors, epoxides) or strained rings. * Search for groups that can be metabolically activated into toxic species (e.g., nitroaromatics). * Assess if extreme physicochemical properties (e.g., high logP) suggest non-specific toxicity. 2. Property-Activity Correlation: Correlate the identified structural features with common mechanisms of chemical toxicity. * Evaluate the potential for reactive groups to cause cellular damage via covalent modification of proteins or DNA. * Consider the possibility of off-target pharmacology based on the molecules overall profile. * Recognize that structural alert increases toxicity risk but is not definitive proof. 3. Holistic Assessment & Consideration: Synthesize all structural risk factors to form comprehensive judgment on the molecules likely toxicity. * Weigh the combined impact of all identified risks; the presence of multiple alerts is strong indicator of toxicity. * Consider if the overall molecular context might mitigate the reactivity of potential toxicophore (e.g., via steric hindrance). 4. Final Prediction Verdict: Conclude with definitive Yes (toxic) or No (not toxic) prediction based on the overall risk assessment. * The verdict must be logical conclusion derived from the balance of identified structural risks. * State the primary structural reasons that drive the final Yes or No decision. Wrap your entire reasoning process in <think> tags and output only the final answer (Yes or No) in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} Ground-truth Answer: {target} Output: <think> 1. Structural/Property Identification: ... 2. Property-Activity Correlation: ... 3. Holistic Assessment & Consideration: ... 4. Final Prediction Verdict: ... </think> <answer>{target}</answer> 28 Chem-R: Learning to Reason as Chemist Molecule Design (TextSMILES) You are an expert chemist demonstrating how to solve molecule design problem. You are given: 1. molecular description. 2. list of functional groups present in the molecule (with representative SMILES patterns). Your task is to generate step-by-step reasoning process that logically deduces the SMILES from the description and the functional groups. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Identify the core structure: Determine the central molecular scaffold or backbone by interpreting the root name in the chemical description. * Focus on identifying the parent compound, such as main chain (hexane) or ring system (benzene). * This core structure will serve as the primary chain for the SMILES string. 2. Summarize key elements: Systematically list all substituents and functional groups from the description and identify their attachment points (locants) on the core. * Create clear connectivity map, linking each group to its specific locant on the parent structure. * Use the provided functional group list to confirm the identity of complex groups. 3. Address stereochemistry: Scan the description for any stereochemical descriptors and determine the specific configuration at each chiral center or double bond. * Identify specific prefixes such as (R)/(S) for chiral centers and (E)/(Z) for double bonds. * If no stereochemistry is mentioned, explicitly note this fact. 4. Construct SMILES: Build the final SMILES string by translating the conceptual blueprint into the correct syntax, combining the core, substituents, and stereochemistry. * Use parentheses () for branches and numeric labels for ring closures. * Apply stereochemical markers (@, @@, /, ) at their correct positions after establishing atom connectivity. Wrap your reasoning in <think> tags and output the final SMILES in <answer> tags. Input: Description: {instruction} FunctionalGroups: {functional groups str} Ground-truth SMILES: {target} Output: <think> 1. Identify the core structure: ... 2. Summarize key elements: ... 3. Address stereochemistry: ... 4. Construct SMILES: ... </think> <answer>{target}</answer> 29 Chem-R: Learning to Reason as Chemist Molecule Captioning (SMILESText) You are an expert chemist demonstrating how to describe molecule based on its structure. You are given: 1. SMILES string. 2. list of functional groups present in the molecule (with representative SMILES patterns). Your task is to generate step-by-step reasoning process that logically deduces detailed chemical description from the SMILES. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Analyze Molecular Structure: Deconstruct the SMILES string by identifying the primary carbon backbone with its branching points, systematically locating all heteroatoms and specified functional groups, and characterizing any cyclic systems found via ring-closure numerals. * Account for all specified functional groups without omission. * Note aromaticity from lowercase letters to define the core scaffold. 2. Summarize Key Elements: Integrate the individual components into cohesive overview to characterize the core scaffold, such as an aliphatic chain or aromatic system, and determine the principal chemical class or classes to which the molecule belongs based on the combination of functional groups. * Synthesize findings into chemical class (e.g., substituted ester), not simple list of parts. * Infer the molecules dominant chemical character from its functional groups. * Consider the relative positions of substituents on the core structure. 3. Address Stereochemistry: Scrutinize the SMILES string for stereochemical indicators, specifically @ and @@ for tetrahedral chirality and / and for geometric isomerism, to explicitly determine the R/S or E/Z configuration for each identified stereocenter or double bond. * Explicitly state if stereochemistry is absent or unspecified. * Link each R/S or E/Z descriptor to its precise atom or bond. 4. Predict Molecular Description: Construct final, detailed chemical description by systematically assembling the preceding findings, starting with the core structure before adding the names and locations of all functional groups and incorporating stereochemical descriptors to form complete narrative. * The final description must be cohesive, flowing narrative. * Ensure all identified structural and stereochemical features are included. * Avoid simple list of facts; the summary should be comprehensive chemical story. Wrap your complete reasoning process in <think> tags and output the final description in <answer> tags. Input: SMILES: {instruction} FunctionalGroups: {functional groups str} Ground-truth description: {target} Output: <think> 1. Analyze Molecular Structure: ... 2. Summarize Key Elements: ... 3. Address Stereochemistry: ... 4. Predict Molecular Description: ... </think> <answer>{target}</answer> 30 Chem-R: Learning to Reason as Chemist TOMG (MolCustom) You are an expert chemist demonstrating how to solve molecule generation problem based on given constraints (Mol Custom). You are given: 1. An instruction that specifies the constraints for the molecule to be generated. Your task is to generate step-by-step reasoning process that logically constructs valid molecule that satisfies all the given constraints. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Analyze Constraints: Deconstruct the instruction to create comprehensive checklist of all specified molecular requirements. * List all explicit constraints, such as required functional groups, atom counts, or ring systems. * Identify any implicit chemical rules, like ensuring correct valency for all atoms. * This checklist will serve as the guide and final validation tool. 2. Construct Core Backbone: Begin molecular construction by creating the primary scaffold that satisfies the most significant structural constraint. * Start with the largest specified fragment, such as named ring system or carbon chain of specific length. * If no core is defined, choose simple starting point that facilitates adding other required features. 3. Assemble and Refine Structure: Iteratively add the remaining functional groups and substituents to the core backbone to satisfy all remaining constraints. * Attach the required groups at chemically plausible positions on the backbone. * Adjust the structure as needed, ensuring all atoms adhere to standard valency rules during assembly. 4. Comprehensively Validate: Perform final, rigorous check of the generated molecule against the initial constraint checklist for accuracy and chemical validity. * Systematically verify that every single constraint from the initial list has been met. * Confirm the final SMILES string is syntactically correct and represents chemically stable molecule. The final predicted molecule must be expressed as SMILES string. Wrap your entire reasoning process in <think> tags and output only the final answer in <answer> tags. Input: Instruction: {instruction} Ground-truth Molecule: {target} Output: <think> 1. Analyze Constraints: ... 2. Construct Core Backbone: ... 3. Assemble and Refine Structure: ... 4. Comprehensively Validate: ... </think> <answer>{target}</answer> 31 Chem-R: Learning to Reason as Chemist TOMG (MolEdit) You are an expert chemist demonstrating how to solve molecule editing problem. You are given: 1. molecule editing problem. 2. list of key functional groups present in the SMILES, which can serve as hints. Your task is to generate step-by-step reasoning process that logically deduces the final edited molecules SMILES from the given starting molecule and editing instruction. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Task Parsing: Deconstruct the problem statement to identify the starting molecule, the specific editing operation, and the target substructure. * Clearly state the input molecules SMILES and the intended action (e.g., add, remove, replace). * Identify the precise chemical group or site targeted for modification as described in the instruction. 2. Functional Group Analysis & Site Localization: Analyze the starting molecules SMILES to pinpoint the exact location for the edit. * Identify all functional groups within the starting molecule to create structural map. * Use this map to locate the exact atom(s) corresponding to the target site from the instruction. 3. Edit Molecule: Execute the specified modification on the SMILES string by performing the necessary bond-breaking and bond-forming operations. * Describe the transformation in terms of SMILES manipulation (e.g., inserting atom into the chain). * Generate the new SMILES string that represents the post-edit molecular structure. 4. Structure Validation: Verify that the resulting molecule accurately reflects the requested edit and is chemically plausible. * Confirm that the modification has been correctly applied to the intended site. * Check the final SMILES for correct syntax and ensure all atoms have proper valency. The final predicted molecule must be expressed as SMILES string. You must reasoning within <think>...</think> and the final answer within output your <answer>...</answer>. Input: Problem: {problem} FunctionalGroups: {functional groups str} Ground-truth Edited Molecule: {target} Output: <think> 1. Task Parsing: ... 2. Functional Group Analysis & Site Localization: ... 3. Edit Molecule: ... 4. Structure Validation: ... </think> <answer>{target}</answer> 32 Chem-R: Learning to Reason as Chemist TOMG (MolOptimization) You are an expert chemist demonstrating how to solve molecule optimization problem. You are given: 1. molecule optimization problem, which includes the starting molecule (SMILES) and the optimization goal. 2. list of key functional groups present in the starting molecule, which can serve as hints. Your task is to generate step-by-step reasoning process that logically deduces the final optimized molecules SMILES. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Clarify Optimization Goal: Interpret the optimization instruction to define the target property and the underlying chemical principle for its improvement. * Clearly state the property to be optimized (e.g., solubility, binding affinity, metabolic stability). * Connect the goal to specific chemical strategy (e.g., increase solubility by adding polar groups). 2. Molecular Analysis & Strategy Customization: Analyze the starting molecule to identify suitable site for modification that aligns with the optimization strategy. * Identify regions of the molecule where modification is chemically feasible and unlikely to disrupt core activity. * Select specific substituent or functional group to add/remove/replace based on the defined strategy. 3. Modify Molecule: Execute the planned structural modification on the starting molecules SMILES to generate the new, optimized structure. * Describe the specific edit performed on the SMILES string to implement the chemical change. * Generate the new SMILES string representing the final, optimized molecule. 4. Validate Modification: Confirm that the edit was performed correctly and that the resulting molecule plausibly achieves the optimization goal. * Verify that the final structure incorporates the intended change at the correct location. * Briefly rationalize how the modification is expected to improve the target property (e.g., the added hydroxyl group increases polarity). The final predicted molecule must be expressed as SMILES string. You must reasoning within <think>...</think> and the final answer within output your <answer>...</answer>. Input: Problem: {problem} FunctionalGroups: {functional groups str} Ground-truth Optimized Molecule: {target} Output: <think> 1. Clarify Optimization Goal: ... 2. Molecular Analysis & Strategy Customization: ... 3. Modify Molecule: ... 4. Validate Modification: ... </think> <answer>{target}</answer> 33 Chem-R: Learning to Reason as Chemist Reaction Prediction You are an expert chemist demonstrating how to solve reaction prediction problem. You are given: 1. set of chemical reactants represented by SMILES string. 2. list of key functional groups present in the reactants, which serve as hints for disconnection. Your task is to generate step-by-step reasoning process that logically predicts the product SMILES from the given reactant SMILES and its functional groups. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Reactant Analysis: Examine the reactants structures to identify key features relevant to reactivity. * Assess the overall structure, including the carbon skeleton and stereochemistry. * Identify any notable structural motifs that could influence the reaction. 2. Functional Group Identification: Locate and classify all functional groups to determine potential reaction sites. * Identify all key functional groups and classify them by reactivity (e.g., nucleophilic, electrophilic, acidic, basic). * Consider potential interactions between these groups or with external reagents. 3. Reaction Type Analysis: Determine the most probable reaction pathway based on the reactants structural and functional group properties. * Deduce the most plausible chemical transformation by correlating the functional groups present. * Propose likely reaction type, such as known named reaction or fundamental class like substitution or addition. 4. Product Prediction: Construct the final product by applying the proposed reaction mechanism and generating the resultant SMILES string. * Detail the bond formations and breakages, considering regioselectivity and stereoselectivity to determine the precise product structure. * Generate the new SMILES string that represents the final predicted molecule(s). The final predicted product must be expressed as SMILES string. If multiple products are predicted, they MUST be separated by period . instead of commas. You must output your reasoning within <think>...</think> and the final answer within <answer>...</answer>. Input: Reactants SMILES: {reactants} FunctionalGroups: {functional groups str} Ground-truth Product: {target} Output: <think> 1. Reactant Analysis: ... 2. Functional Group Identification: ... 3. Reaction Type Analysis: ... 4. Product Prediction: ... </think> <answer>{target}</answer> 34 Chem-R: Learning to Reason as Chemist Retrosynthesis You are an expert chemist demonstrating how to solve retrosynthesis problem. You are given: 1. chemical product represented by SMILES string. 2. list of key functional groups present in the product, which serve as hints for disconnection. Your task is to generate step-by-step reasoning process that logically deduces the reactant SMILES from the given product SMILES and its functional groups. You MUST NOT mention ground-truth, given reactants, provided answer, or any similar phrases in your <think> block. You must write the reasoning as if you are deducing the answer from scratch, even though you already know the destination. Please structure your reasoning as follows: 1. Product Analysis: Examine the products structure to identify strategic bonds for disconnection. * Assess the products carbon skeleton, stereochemistry, and any notable structural motifs. * Identify key bonds whose formation is synthetically plausible, often adjacent to functional groups. 2. Functional Group Identification: Analyze the functional groups to infer the last synthetic step. * Locate all key functional groups, recognizing them as the results of specific chemical reactions. * Use these groups to guide the selection of primary disconnection strategy. 3. Reaction Type Analysis: Propose plausible forward reaction that could have formed key bond in the product. * Based on the target bond and adjacent functionalities, suggest reliable forward synthesis reaction (e.g., Wittig, Grignard, Diels-Alder). * This proposed reaction dictates the nature of the precursor fragments (synthons). 4. Reactant Prediction: Perform the disconnection to derive the structures of the starting materials. * Break the target bond in the product to generate the corresponding synthons. * Convert these synthons into stable, charge-neutral reactant molecules and generate their SMILES strings. The final predicted reactants must be expressed as SMILES strings. If multiple reactants are predicted, they MUST be separated by period . instead of commas. You must output your reasoning within <think>...</think> and the final answer within <answer>...</answer>. Input: Product SMILES: {products} FunctionalGroups: {functional groups str} Ground-truth Reactants: {target} Output: <think> 1. Product Analysis: ... 2. Functional Group Identification: ... 3. Reaction Type Analysis: ... 4. Reactant Prediction: ... </think> <answer>{target}</answer> 35 Chem-R: Learning to Reason as Chemist C.4 HUMAN EVALUATION To provide nuanced assessment of reasoning quality, we conducted human evaluation with the help of chemistry experts. The experts were tasked with evaluating the generated CoT from Chem-R and several leading baseline models. We designed comprehensive rubric consisting of six distinct, orthogonal metrics to capture different facets of high-quality explanation: Chemical Soundness (the factual correctness of the chemistry), Logical Coherence (the step-by-step logical flow), Stepby-Step Completeness (whether crucial steps are missing), Justification of the Conclusion (the faithfulness of the reasoning to the final answer), Clarity and Conciseness (the quality of the language), and Expert-level Insight (the depth and nuance of the reasoning). Each metric was scored on 0-5 scale, allowing for detailed comparison of the models ability to produce human-like, expert-level thought processes. Evaluation Limitations. potential limitation is that CoT from Chem-Rcan be stylistically distinct, often more structured, due to its protocol-based training. To mitigate any resulting bias, the evaluation was conducted under strictly blind conditions. Experts assessed fully anonymized responses without any knowledge of the generating model, ensuring their ratings were based exclusively on the intrinsic quality of the reasoning rather than on stylistic patterns. Figure 5: Human evaluation rubric for Chain-of-Thought quality. Experts are to score the generated reasoning on 0-5 scale (0=worst, 5=best) across the six metrics provided: Chemical Soundness, Logical Coherence, Completeness, Justification, Clarity, and Expert-level Insight. Table 5: Human evaluation of model-generated reasoning. second-best models are highlighted. For each column the best and Metric Chem-R Gemini-2.5 Pro DeepSeek-R1 ether0 Chemical Soundness Logical Coherence Step-by-Step Completeness Justification of the Conclusion Clarity and Conciseness Expert-level Insight 4.75 4.85 4.20 4.28 4.65 4.55 3.95 4.25 3.85 4.10 4.55 3. 3.45 3.80 3.90 3.55 3.70 3.20 2.15 2.35 1.95 2.05 2.55 1.85 36 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "D EXPERIEMENT RESULT",
            "content": "In this section, we will present the specific results of each subtask in the experiment to provide better demonstration of the models performance. D.1 NAME PREDICTION In our name prediction task, we evaluated the models performance on two sub-tasks: SMILES to IUPAC name translation (SMILES2IUPAC) and IUPAC name to SMILES translation (IUPAC2SMILES). For both sub-tasks, we use the exact match accuracy as the evaluation metric. Model SMILES2IUPAC IUPAC2SMILES Average Task-specific specialist models STOUT (Rajan et al., 2021) LLM-based generalist models GPT-4o Gemini-2.5-Pro DeepSeek-R1 ChemDFM-v1.5-8B ether0-24B Chem-R-8B 0.55 0.00 0.01 0.01 0.06 0.00 0.51 0.70 0.02 0.33 0.09 0.22 0.29 0. 0.63 0.01 0.17 0.05 0.14 0.15 0.49 Table 6: Accuracy scores in name prediction tasks. The task-specific specialist models are sourced from (Guo et al., 2023). D.2 PROPERTY PREDICTION In the molecule property prediction task, we evaluated the models performance across suite of benchmark datasets: BACE, BBBP, ClinTox, HIV, and Tox21. Each task is formulated as binary classification problem. For evaluation, we uniformly use classification accuracy as the sole metric across all datasets. Model BACE BBBP ClinTox HIV Tox21 Avg. Task-specific specialist models Uni-Mol (Zhou et al., 2023) MolXPT (Liu et al., 2023b) InstructMol (Cao et al., 2023) LLM-based generalist models ChemDFM-v1.5-8B ether0-24B Chem-R-8B 0.86 0.88 0.86 0.78 0.58 0.78 0.73 0.80 0. 0.75 0.64 0.81 0.92 0.95 - 0.69 0.62 0.95 0.81 0.78 0.74 0.88 0.67 1.00 0.80 0.77 - 0.74 0.51 0.71 0.82 0.84 - 0.77 0.60 0.85 Table 7: AUC-ROC scores of different models in molecular property prediction tasks. Avg.: average. The task-specific specialist models are sourced from (Zhao et al., 2025c). Model BACE BBBP ClinTox HIV Tox21 Avg. GPT-4o Gemini-2.5-Pro DeepSeek-R1 ChemDFM-v1.5-8B ether0-24B Chem-R-8B 0.34 0.36 0.38 0.77 0.43 0.74 0.61 0.78 0.63 0.57 0.48 0.82 0.98 0.30 0.8 0.69 0.74 0.98 1.00 1.00 1.00 0.85 0.82 1.00 0.49 0.36 0.34 0.81 0.72 0. 0.68 0.56 0.63 0.74 0.64 0.87 Table 8: Accuracy scores of different models in molecular property prediction tasks. Avg.: average. 37 Chem-R: Learning to Reason as Chemist D.3 MOLECULE DESIGN In the text-based molecule design task, we evaluate the models ability to generate correct SMILES string from given textual description of molecule, using the ChEBI-20 dataset. The evaluation is multi-faceted. First, we measure the fundamental Validity of the outputs, which is the percentage of generated SMILES that represent chemically valid molecules as verified by RDKit. To assess textual fidelity against the ground-truth SMILES, we employ several string-based metrics: Exact Match (EM) for identical strings, Levenshtein Distance (Lev.) to measure edit distance (lower is better), and the BLEU score, which quantifies n-gram overlap via the formula: BLEU = BP exp (cid:33) wn log pn (cid:32) (cid:88) n=1 (3) where BP is the Brevity Penalty and pn is the modified n-gram precision. Finally, to evaluate structural correctness, we calculate the Tanimoto coefficient between the molecular fingerprints (MACCS, RDKit, and Morgan) of the generated and ground-truth molecules, where higher similarity score indicates greater structural resemblance. We choose MolT5-large (Edwards et al., 2022), MolReGPT (Li et al., 2024b), Mol-Instruction (Fang et al., 2023), MolReasoner (Zhao et al., 2025a) and Mol-R1 (Li et al., 2025b) as the task-specific specialist models. Model BLEU EM Lev. MACCS RDK Morgan Validity Task-specific specialist models 0.85 MolT5-large 0.86 MolReGPT 0.30 Mol-Instruction 0.78 MolReasoner 0.64 Mol-R1 LLM-based generalist models 0.45 GPT-4o 0.69 Gemini-2.5-Pro 0.51 DeepSeek-R1 0.90 ChemDFM-v1.5-8B 0.39 ether0-24B 0.84 Chem-R-8B 0.31 0.28 0.04 0.08 0.23 0.07 0.29 0.22 0.55 0.27 0.41 16.07 17.14 39.42 26.93 32.94 48.38 130.26 169.36 7.12 860.99 17.42 0.83 0.90 0.44 0.68 0.82 0.79 0.95 0.92 0.94 0.82 0. 0.74 0.80 0.29 0.44 0.68 0.58 0.88 0.82 0.88 0.70 0.83 0.68 0.74 0.25 0.36 0.61 0.50 0.82 0.75 0.84 0.64 0.78 0.91 0.90 1.00 0.97 0.85 0.77 0.91 0.78 0.98 0.73 0. Table 9: Performance of different models on the text-based molecule generation task on the ChEBI20 dataset. BLEU: Bilingual Evaluation Understudy, EM: Exact Match, Lev.: Levenshtein distance, MACCS: MACCS fingerprint similarity, RDK: RDK fingerprint similarity, Morgan: Morgan fingerprint similarity, Validity: Percentage of valid molecules. D.4 MOLECULE CAPTIONING In the molecule captioning task, we evaluate the models ability to generate an accurate and fluent natural language description from given molecular structure (SMILES string), using the ChEBI-20 dataset. To comprehensively assess the quality of the generated text, we employ suite of standard metrics. We use the BLEU score to measure n-gram precision, specifically reporting BLEU-2 (N = 2, w1 = w2 = 0.5) and BLEU-4 (N = 4, wn = 0.25), based on the general formula: BLEU = BP exp (cid:33) wn log pn (cid:32) (cid:88) n=1 (4) where BP is the Brevity Penalty and pn is the modified n-gram precision. For recall-oriented evaluation, we utilize the ROUGE family of metrics. We report the F1-scores for ROUGE-1 (R-1) and ROUGE-2 (R-2), which measure unigram and bigram overlap, and ROUGE-L (R-L), which is based on the longest common subsequence (LCS). The ROUGE-L F-score is computed as: ROUGE-Lf-score = (1 + β2)RlcsPlcs Rlcs + β2Plcs (5) 38 Chem-R: Learning to Reason as Chemist where Rlcs and Plcs are the LCS-based recall and precision, and β is set to 1 to weigh recall and precision equally for the F1-score. Lastly, we incorporate the METEOR score, which enhances evaluation by considering synonymy and stemming. It is based on the harmonic mean of unigram precision (P ) and recall (R), Fmean, which weights recall more than precision: Fmean = 10P + 9P The final score is calculated by applying fragmentation penalty (P en) to this value: METEOR = Fmean (1 en) (6) (7) where en is penalty for fragmentation based on the alignment of chunks between the generated and reference texts. Model BLEU-2 BLEU-4 R-1 R-2 R-L METEOR Task-specific specialist models 0.59 MolT5-large 0.61 MolReGPT 0.68 MolReFlect 0.10 Mol-Instruction 0.44 MolReasoner LLM-based generalist models 0.04 GPT-4o 0.09 Gemini-2.5-Pro 0.10 DeepSeek-R1 0.33 ChemDFM-v1.5-8B 0.01 ether0-24B 0.48 Chem-R-8B 0.51 0.53 0.61 0.07 0.32 0.01 0.04 0.04 0.28 0.00 0.41 0.65 0.63 0.70 0.28 0. 0.13 0.20 0.14 0.46 0.05 0.61 0.51 0.48 0.57 0.18 0.37 0.02 0.06 0.03 0.36 0.01 0.44 0.59 0.56 0.64 0.26 0.48 0.10 0.13 0.11 0.43 0.04 0.53 0.61 0.61 0.68 0.19 0. 0.11 0.31 0.15 0.40 0.05 0.58 Table 10: Performance of different models on the molecule description task on the ChEBI-20 dataset. R-1: ROUGE-1 (Recall-Oriented Understudy for Gisting Evaluation-1), R-2: ROUGE-2, R-L: ROUGE-L (ROUGE-L stands for longest common subsequence), MTEOR: METEOR (Metric for Evaluation of Translation with Explicit ORdering). D.5 TEXT-BASED OPEN MOLECULE GENERATION In the text-based open molecule generation task, we evaluate the models ability to perform complex chemical reasoning and creative design, using the TOMG-Bench benchmark (Li et al., 2024a). The evaluation is structured around three distinct tasks designed to probe different capabilities: Molecule Editing (MolEdit), Molecule Optimization (MolOpt), and Customized Molecule Generation (MolCustom). And we choose MolT5 (Edwards et al., 2022), BioT5 (Pei et al., 2023) and OpenMolIns (Li et al., 2024a) (which is trained on the full set of training data of TOMG-Bench) for the task-specific specialist models. For the MolEdit and MolOpt tasks, which involve modifying an existing molecule, the assessment is threefold. First, we measure the Success Rate (SR) to verify if the models output correctly fulfills the textual instruction. Second, to ensure the modification is rational and localized edit rather than completely new structure, we calculate the Tanimoto Similarity (Sim.) between the Morgan fingerprints of the original and generated molecules. For the MolCustom task, which requires generating molecule from scratch (de novo), the metrics are adapted. The Success Rate (SR) evaluates if the generated molecule adheres to set of specified structural constraints (e.g., atom counts, bond types). Instead of similarity, we measure Novelty (Nov.) to quantify the uniqueness of the generated molecule. The novelty for generated molecule mg is calculated as: n(mg) = 1 (cid:80) mkZinc δ(mg, mk) Zinc (8) where δ(mg, mk) is the Tanimoto similarity to known molecule mk in the Zinc database. Chem-R: Learning to Reason as Chemist To provide single, comprehensive ranking of model performance, the benchmark introduces Weighted Success Rate (WSR). This metric combines the core success rate with quality metric relevant to each taskSimilarity for MolEdit/MolOpt and Novelty for MolCustom. The WSR for given subtask is defined as: SRt = (cid:26)nt SRt, δt SRt, {MolCustom} {MolEdit, MolOpt} (9) where nt is the novelty score and δt is the similarity score for that subtask. The final performance is then the average WSR across all nine subtasks: SR = 1 9 (cid:88) t"
        },
        {
            "title": "W SRt",
            "content": "(10) Finally, for all tasks, we measure the fundamental Validity (Val.) to ensure every generated SMILES string represents chemically sound molecule. MolEdit AddComponent DelComponent SubComponent SR Sim. Val. SR Sim. Val. SR Sim. Val. Task-specific specialist models MolT5 BioT5 OpenMolIns 0.28 0.35 0.78 0.11 0.16 0.68 LLM-based generalist models GPT-4o 0.62 ChemDFM 0.29 0.89 Chem-R MolOpt 0.68 0.65 0.69 LogP 0.93 1.00 0. 0.74 0.91 0.98 0.22 0.17 0.86 0.70 0.21 0.89 0.12 0.16 0.62 0.60 0.69 0.62 MR 0.92 1.00 0. 0.85 0.93 0.93 0.17 0.07 0.61 0.80 0.22 0.62 0.94 1.00 0.96 0.94 0.87 0.99 0.09 0.16 0. 0.72 0.64 0.75 QED SR Sim. Val. SR Sim. Val. SR Sim. Val. Task-specific specialist models MolT5 BioT5 OpenMolIns 0.10 0.15 0.67 0.42 0.52 0.88 LLM-based generalist models 0.72 GPT-4o ChemDFM 0.30 Chem-R 0.90 MolCustom 0.66 0.66 0.66 AtomNum 0.82 1.00 0.93 0.88 0.76 0.97 0.45 0.51 0.70 0.69 0.25 0.92 0.11 0.16 0.67 0.64 0.68 0.68 BondNum 0.87 1.00 0.94 0.84 0.82 0.97 0.47 0.51 0.86 0.12 0.16 0.67 0.92 1.00 0.93 0.40 0.31 0. 0.86 0.62 0.81 0.66 0.98 0.68 FunctionalGroup SR Nov. Val. SR Nov. Val. SR Nov. Val. Task-specific specialist models MolT5 BioT5 OpenMolIns 0.71 0.84 0. 0.02 0.01 0.12 LLM-based generalist models GPT-4o 0.20 ChemDFM 0.01 0.22 Chem-R 0.67 0.68 0.69 0.84 1.00 0.85 0.59 0.67 0.85 0.01 0.01 0. 0.07 0.02 0.10 0.56 0.67 0.67 0.63 0.61 0.70 0.89 1.00 0.90 0.86 0.90 0.70 0.04 0.05 0. 0.23 0.03 0.31 0.61 0.68 0.64 0.65 0.60 0.64 0.94 1.00 0.95 0.86 0.81 0.93 Table 11: Detailed results on TOMG-Bench for different models. The indicators are: SR = Success Rate, Sim. = Similarity, Nov. = Novelty, Val. = Validity. MolT5 refers to MolT5-large, BioT5 refers to BioT5-base, OpenMolIns refers to the performance of the Llama-3.1-8B model trained on the largest instruction fine-tuning dataset OpenMolIns-xlarge proposed by TOMG-Bench, and ChemDFM refers to ChemDFM-v1.5-8B. The task-specific specialist models are sourced from (Li et al., 2024a). 40 Chem-R: Learning to Reason as Chemist D.6 YIELD PREDICTION In the reaction yield prediction task, we evaluate the models performance on two reaction datasets: Buchwald-Hartwig and Suzuki-Miyaura. The task is framed as binary classification problem to predict whether reaction yield is high or low. We use classification accuracy as the sole evaluation metric, with the average accuracy across both datasets also reported. Model Buchwald-Hartwig Suzuki-coupling Average Task-specific specialist models UAGNN (Kwon et al., 2022) LLM-based generalist models GPT-4o Gemini-2.5-Pro DeepSeek-R1 ChemDFM-v1.5-8B ether0-24B Chem-R-8B 0.97 0.20 0.23 0.20 0.35 0.02 0.87 0.96 0.20 0.47 0.45 0.38 0.03 0. 0.96 0.20 0.35 0.33 0.37 0.03 0.86 Table 12: Accuracy scores of different models in yield prediction tasks. The task-specific specialist models is sourced from (Zhao et al., 2025c). D.7 REAGENT SELECTION In the reagent selection task, we utilize the Suzuki High-Throughput Experimentation (HTE) dataset. This task is divided into three sub-tasks: predicting the correct reactant, solvent, and ligand for given reaction. The evaluation metrics vary by sub-task. For reactant and solvent prediction, we report the top-1 accuracy. For ligand prediction, we report the top-5 accuracy, which considers prediction correct if the ground-truth ligand is among the top five candidates proposed by the model. The Avg. column in the table represents the average of these three accuracy scores. And we choose Chemformer (Irwin et al., 2022), Mol-Instruction (Fang et al., 2023) and InstructMol (Cao et al., 2023) for the task-specific specialist models. Model Reagent Selection Reaction RetrosynReactant Solvent Ligand Avg. Prediction thesis Task-specific specialist models Chemformer Mol-Instruction InstructMol LLM-based generalist models 0.48 GPT-4o 0.17 Gemini-2.5-Pro 0.15 DeepSeek-R1 0.47 ChemDFM-v1.5-8B 0.11 ether0-24B 0.62 Chem-R-8B 0.11 0.07 0.17 0.10 0.35 0.57 0.19 0.56 0.08 0.49 0.18 0. 0.26 0.27 0.13 0.35 0.21 0.69 0.94 0.05 0.54 0.04 0.35 0.34 0.50 0.65 0.82 0.54 0.00 0.15 0.13 0.07 0.04 0. Table 13: Performance of task-specific specialist models and LLM-based generalist models on reagent selection, reaction prediction, and retrosynthesis tasks. The task-specific specialist models are sourced from (Zhao et al., 2025c). means that the model was not designed for the task. D.8 REACTION PREDICTION In the reaction prediction task, we evaluate the models ability to predict the major product of chemical reaction, using the USPTO Mixed dataset. Performance is measured using exact match accuracy, where the predicted products SMILES string must be identical to the ground-truth SMILES. 41 Chem-R: Learning to Reason as Chemist D.9 RETROSYNTHESIS In the retrosynthesis task, the goal is to predict the reactants that form given product molecule. This is evaluated on the widely-used USPTO-50k dataset. Similar to reaction prediction, we employ exact match accuracy as the evaluation metric. prediction is considered correct only if the set of predicted reactant SMILES is identical to the ground-truth set. D.10 OUT OF DOMAIN To evaluate the out-of-domain (OOD) generalization of our model, Chem-R, we benchmarked its performance on the challenging Molecular Property Optimization task from ChemCoTBench (Li et al., 2025a). We selected four representative targets: Solubility, DRD2, JNK3, and GSK-3β. The evaluation, presented in Table D.10, compares Chem-R against its base model, Llama-3.1-8BInstruct, and other powerful LLMs. The results clearly demonstrate the effectiveness of our training. The base Llama-3.1-8B-Instruct model performs poorly, whereas Chem-R shows dramatic improvement in both success rate (SR%) and mean property improvement () across all tasks. This signifies that Chem-R has acquired robust chemical reasoning skills that generalize effectively. Furthermore, Chem-R proves to be highly competitive, significantly outperforming the much larger Llama-3.3-70B-Instruct model, which confirms the strong OOD capabilities of our approach. Solubility DRD JNK3 GSK3-β Models SR% SR% SR% SR% Qwen3-235B-A22B-think Qwen3-32B-think Llama-3.1-8B-Instruct Chem-R 0.27 0.11 0.01 0. 42 23 10 83 0.03 0.00 -0.07 0.01 31 6 2 36 -0.01 -0.02 -0.10 -0.02 23 6 4 24 0.01 -0.02 -0.08 -0. 31 5 3 29 Table 14: Performance of various models on different molecular optimization tasks. Evaluation was conducted on one physicochemical property (Solubility) and three more challenging protein activity targets (DRD2, JNK3, and GSK3-β). The mean improvement in property is denoted by ; negative indicates degradation of the property. The success rate (SR%) represents the percentage of optimizations that led to an increase in the target property. 42 Chem-R: Learning to Reason as Chemist"
        },
        {
            "title": "E MORE CASES",
            "content": "Reaction Prediction (Chem-R generated response) You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Note: If multiple products are predicted, they MUST be separated by period . instead of commas. Now predict the product for the following reaction: Reactants: C1CCOC1.CC(C)(C)[O-].O=C(Cl)c1cccc([N+](=O)[O-])c1.[K+] Ground Truth: CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c1 LLM Answer: <think> 1. Reactant analysis: The reactant molecules are represented by their SMILES strings, indicating complex mixture. One of the reactants is an ether (C1CCOC1), suggesting the presence of an oxygen atom connected to two alkyl groups. Another reactant is tertiary alkoxide (CC(C)(C)[O-]), which is strong nucleophile. The presence of O=C(Cl)c1cccc([N+](=O)[O-])c1 indicates an aromatic ring with nitro group and an acyl chloride, which is highly reactive due to the chlorine atom attached to the carbonyl group. The potassium ion [K+] suggests that there might be an ionic interaction or potential for nucleophilic substitution reaction. 2. Functional group identification: Key functional groups identified include the ether (COC), chlorine (Cl), and nitro (N(=O)[O-]) groups. These groups can serve as reaction sites for various chemical transformations. The ether group might not be directly involved in the primary reaction due to its relatively stable nature, but it could influence the reaction conditions or the solubility of the reactants. The chlorine atom attached to the carbonyl group is highly reactive and susceptible to nucleophilic attack, which could lead to the formation of new bond. 3. Reaction type analysis: Given the presence of strong nucleophile (the alkoxide ion) and highly reactive acyl chloride, nucleophilic acyl substitution reaction is likely. This type of reaction involves the nucleophile attacking the carbonyl carbon of the acyl chloride, leading to the replacement of the chlorine atom with the nucleophile. The nitro group on the aromatic ring might influence the electron density on the ring, potentially affecting the reaction rate or the stability of the product, but it is not directly involved in the primary reaction site. 4. Product prediction: Based on the identified reaction type, the most likely product formed is the result of the nucleophilic substitution of the chlorine atom in the acyl chloride by the alkoxide ion. This would lead to the formation of an ester. The predicted product SMILES string, considering the substitution of the chlorine with an alkoxide group (which would then be part of an ester linkage), is CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c1. </think> <answer>CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c1</answer> Critique: This is an excellent example of correct chemical reasoning. It accurately identifies the roles of each reactant, correctly pinpointing the tert-butoxide as the strong nucleophile and the acyl chloride as the highly reactive electrophile. Crucially, it correctly dismisses the solvent (ether) as primary participant. The thinking process logically flows from identifying the key functional groups to naming the correct reaction type (nucleophilic acyl substitution) and accurately describing the mechanism. This step-by-step deduction directly and soundly leads to the correct final product. Chem-R: Learning to Reason as Chemist Reaction Prediction (w/o CRP) Problem: You are an expert chemist. Your task is to solve the given problem step by step. You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Note: If multiple products are predicted, they MUST be separated by period . instead of commas. Now predict the product for the following reaction: Reactants: C1CCOC1.CC(C)(C)[O-].O=C(Cl)c1cccc([N+](=O)[O-])c1.[K+] Ground Truth: CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c1 LLM Answer: <think> To solve this problem, we first need to identify the reactants and their possible roles in the reaction. The given reactants are C1CCOC1 (tetrahydrofuran, the solvent), CC(C)(C)[O- ] with [K+] (potassium tert-butoxide), and O=C(Cl)c1cccc(N+[O-])c1 (a chloroformylated pyridine with nitro group). The key reactant is the potassium tert-butoxide. It is known as strong, non-nucleophilic, bulky base. Its primary role in organic chemistry is to promote elimination reactions over substitution reactions. Given its strong basicity, the most likely first step is an E2 elimination. The tert-butoxide will abstract proton from the aromatic ring, likely ortho to the carbonyl group, which is the most acidic position. This process will lead to the expulsion of the chloride ion and the formation of highly reactive benzyne intermediate. This benzyne intermediate is then rapidly attacked by molecule of tert-butoxide. This addition step, followed by protonation from trace amounts of water or other proton sources during workup, results in the final product. This mechanism ensures that the bulky base does not need to directly attack the sterically hindered carbonyl carbon. The final product forms by replacing the chloride with the tert-butoxy group. </think> <answer>CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c1</answer> Critique: This reasoning is fundamentally flawed, even though it happens to arrive at the correct product. The proposed reaction mechanism, involving the formation of benzyne intermediate, is chemically incorrect for this scenario. Tert-butoxide is not strong enough to deprotonate the aromatic ring, and this is not the correct pathway for benzyne formation. The actual reaction is much more straightforward nucleophilic acyl substitution, where the tert-butoxide ion directly attacks the electrophilic carbonyl carbon, displacing the chloride ion. 44 Chem-R: Learning to Reason as Chemist Reaction Prediction (w/o correct information) Problem: You are an expert chemist. Your task is to solve the given problem step by step. You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Note: If multiple products are predicted, they MUST be separated by period . instead of commas. Now predict the product for the following reaction: Reactants: C1CCOC1.CC(C)(C)[O-].O=C(Cl)c1cccc([N+](=O)[O-])c1.[K+] Ground Truth: CC(C)(C)OC(=O)c1cccc([N+](=O)[O-])c LLM Answer: <think> 1. Reactant analysis: The reactants are represented by their SMILES strings. C1CCOC1 is tetrahydrofuran (THF), common aprotic polar solvent. CC(C)(C)[O-] and [K+] together form potassium tert-butoxide, strong base and sterically hindered nucleophile. O=C(Cl)c1cccc([N+](=O)[O-])c1 is an aromatic compound with nitro group and an acyl chloride group, acting as the electrophile. 2. Functional group identification: The key functional groups include the acyl chloride (-COCl) and the nitro group (-NO2). Typically, the carbonyl carbon of an acyl chloride is very strong electrophilic site. However, due to misinterpretation of the SMILES string O=C(Cl)c1cccc([N+](=O)[O-])c1, the connectivity is incorrectly perceived. It is mistakenly assumed that the chlorine atom (Cl) is directly attached to the aromatic ring (c1) and the carbonyl group (C=O) is separate ketone substituent. Aryl chlorides are significantly less reactive towards nucleophilic substitution than acyl chlorides. 3. Reaction type analysis: Based on the incorrect structural interpretation above, nucleophilic acyl substitution will not occur. Since the molecule is now incorrectly viewed as an aryl chloride and ketone, the most likely role for the strong base potassium tert-butoxide is as base rather than nucleophile. It will attempt to abstract proton from the most acidic position on the aromatic ring (ortho to the nitro group) to initiate an elimination-addition (benzyne) mechanism. 4. Product prediction: Following this incorrect mechanism, the potassium tert-butoxide acts as strong base to deprotonate the carbon between the nitro and chloro groups, followed by the departure of the chloride ion to form benzyne intermediate. The tert-butoxide anion then adds to this benzyne. This ultimately results in the replacement of the chlorine atom on the ring by the tert-butoxy group. </think> <answer>CC(C)(C)Oc1cccc([N+](=O)[O-])c1</answer> Critique: This Chain of Thought (CoT) arrives at an incorrect answer due to critical error in its initial analysis. The fundamental flaw lies in Step 2, where it completely misinterprets the SMILES string for 3-nitrobenzoyl chloride. The string O=C(Cl)c1... correctly describes an acyl chloride functional group (-C(=O)Cl) attached to the aromatic ring. The CoT incorrectly reads this as an aryl chloride (a chlorine atom, -Cl, bonded directly to the ring) and separate ketone. This single mistake invalidates the entire subsequent reasoning. By ignoring the extremely reactive acyl chloride electrophile, the CoT proposes much less favorable and inapplicable benzyne mechanism. The actual reaction is straightforward and rapid nucleophilic acyl substitution, where the tert-butoxide attacks the carbonyl carbon. The incorrect product is direct consequence of reacting with the wrong functional group based on flawed structural interpretation. Chem-R: Learning to Reason as Chemist Molecule Design (Chem-R generated response) Problem: You are an expert chemist. Your task is to solve the given problem step by step. You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Now predict the SMILES representation for the following molecular design requirement: Description: The molecule is an N-carbamoylamino acid that is aspartic acid with one of its amino hydrogens replaced by carbamoyl group. It has role as Saccharomyces cerevisiae metabolite, an Escherichia coli metabolite and human metabolite. It is N-carbamoylamino acid, an aspartic acid derivative and C4-dicarboxylic acid. It is conjugate acid of N-carbamoylaspartate(2-). Ground Truth: C(C(C(=O)O)NC(=O)N)C(=O)O LLM Answer: <think> 1. Identify the core structure: The molecule is described as an aspartic acid derivative, which is type of amino acid. Aspartic acid has core structure that includes central carbon atom bonded to an amino group, carboxylic acid group, and side chain that also contains carboxylic acid group. Given that its derivative, we start with this basic amino acid structure. 2. Summarize key elements: The molecule is an N-carbamoylaspartic acid, meaning one of the hydrogens on the amino group of aspartic acid is replaced by carbamoyl group (NC(=O)N). The key elements include: - central carbon (C) that is part of the amino acid backbone. - An amino group (N) attached to this central carbon, which is then modified. - carbamoyl group (NC(=O)N) replacing one of the hydrogens on the amino group. - Two carboxylic acid groups, one attached to the central carbon and the other as part of the side chain. - The side chain contains carboxylic acid group (CC(=O)O). 3. Address stereochemistry: The description does not specify any particular stereochemistry for the molecule, suggesting that either the stereochemistry is not relevant for the identification of the molecule or it is assumed to be in specific form by default (e.g., L-form for amino acids). However, since the task focuses on generating SMILES string based on the functional groups and molecular description without specific stereochemical details, we will not include explicit stereochemical indicators in our SMILES string. 4. Construct SMILES: To construct the SMILES, we start with the central carbon (C) of the amino acid, which is bonded to the amino group modified with the carbamoyl group (NC(=O)N), and two carboxylic acid groups (C(=O)O) - one directly attached to the central carbon and the other as part of the side chain. Combining these elements, we get the SMILES string. The carbamoyl group replaces one of the amino hydrogens, and the side chain contains carboxylic acid group, leading to the structure: C(C(C(=O)O)NC(=O)N)C(=O)O. </think> <answer>C(C(C(=O)O)NC(=O)N)C(=O)O</answer> Critique: This is an excellent example of successful molecule design process. The reasoning is direct, systematic, and chemically accurate. It correctly identifies the core structure (aspartic acid) and the key modification (N-carbamoyl) directly from the problem description, avoiding any irrelevant distractions. The step-by-step deconstruction of the molecule into its constituent parts is clear and logical. It also correctly addresses the lack of stereochemical information and makes sound decision for the final SMILES representation. The entire process is model of how to translate chemical name into molecular structure. 46 Chem-R: Learning to Reason as Chemist Molecule Design (w/o CRP) Problem: You are an expert chemist. Your task is to solve the given problem step by step. You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Now predict the SMILES representation for the following molecular design requirement: Description: The molecule is an N-carbamoylamino acid that is aspartic acid with one of its amino hydrogens replaced by carbamoyl group. It has role as Saccharomyces cerevisiae metabolite, an Escherichia coli metabolite and human metabolite. It is N-carbamoylamino acid, an aspartic acid derivative and C4-dicarboxylic acid. It is conjugate acid of N-carbamoylaspartate(2-). Ground Truth: C(C(C(=O)O)NC(=O)N)C(=O)O LLM Answer: <think> To predict the SMILES representation of the molecule described, we first identify the base structure, which is aspartic acid. The SMILES for aspartic acid can be written by identifying its main chain and substituents. We can represent the backbone as C(C(C(=O)O))C(=O)O, with the amino group being substituent on the alpha-carbon, which we would write as (N). The description states that carbamoyl group (-CONH2) replaces one of the amino hydrogens. In SMILES notation, when new group is added, it is often treated as new, separate substituent on the same parent atom. Therefore, we will add the carbamoyl group, which can be written as (C(=O)N), as second substituent on the alpha-carbon. This would initially give us the structure C(C(C(=O)O)(N)(C(=O)N))C(=O)O. However, this representation is not the most stable or conventional. There is widely used rule in SMILES generation for simplifying structures where two nitrogen-containing groups are attached to the same carbon atom. This rule involves an intramolecular rearrangement where the smaller nitrogen group (in this case, the amino group N) attacks the larger group (the carbamoyl group C(=O)N) to form more stable, single linear substituent. This Nto-N bond fusion rule merges the two parenthesized groups (N)(C(=O)N) into single, more compact representation, NC(=O)N. By applying this simplification, we replace the two separate substituents with the newly formed single group, leading to the final, correct SMILES string. </think> <answer>C(C(C(=O)O)NC(=O)N)C(=O)O</answer> Critique: This CoT correctly identifies the basic components, aspartic acid and carbamoyl group, but its reasoning for how to combine them into SMILES string is fundamentally incorrect. The process described, which involves treating the amino group and the carbamoyl group as two separate substituents on the same carbon and then invoking fictitious compaction rule to merge them, does not reflect how SMILES notation actually works. In reality, the carbamoyl group is single substituent on the nitrogen atom, which is itself part of the main amino acid backbone. The final answer is correct only by coincidence, not because the described methodology is valid. 47 Chem-R: Learning to Reason as Chemist Molecule Design (w/o correct information) Problem: You are an expert chemist. Your task is to solve the given problem step by step. You should put your reasoning in <think> </think> tags. The final answer MUST BE put in <answer> </answer> tags. Please strictly follow the format. Now predict the SMILES representation for the following molecular design requirement: Description: The molecule is an N-carbamoylamino acid that is aspartic acid with one of its amino hydrogens replaced by carbamoyl group. It has role as Saccharomyces cerevisiae metabolite, an Escherichia coli metabolite and human metabolite. It is N-carbamoylamino acid, an aspartic acid derivative and C4-dicarboxylic acid. It is conjugate acid of N-carbamoylaspartate(2-). Ground Truth: C(C(C(=O)O)NC(=O)N)C(=O)O LLM Answer: <think> 1. Identify the core structure: The molecule is derivative of aspartic acid. The SMILES for the basic aspartic acid backbone can be represented as C(C(C(=O)O)N)C(=O)O, showing the alpha-carbon connected to side-chain carbon, carboxyl group, and an amino group. 2. Summarize key elements: The carbamoyl group itself has the chemical structure - C(=O)N-. This group replaces one of the hydrogens on the aspartic acids original amino group (-NH2). 3. Address stereochemistry: We need to integrate this modification into the aspartic acid SMILES. The amino group in the original SMILES C(C(C(=O)O)N)C(=O)O will be modified. The hydrogen is replaced by the carbamoyl group. This means the becomes part of larger group, which we can write by attaching the SMILES for the carbamoyl group directly to it. 4. Construct SMILES: Starting with the nitrogen of the amino acid, we attach the carbamoyl group -C(=O)N to it, resulting in the combined fragment NC(=O)N. We then substitute this entire fragment back into the parenthesis where the original was located. This yields the final, complete SMILES string. </think> <answer>C(C(C(=O)O)NC(=O)N)C(=O)O</answer> Critique: The reasoning contains subtle inaccuracy in Step 2. It identifies the carbamoyl group as NC(=O)N. Strictly speaking, carbamoyl group is -C(=O)NH2. The final functional group formed on the aspartic acid nitrogen is an N-carbamoylamino group or ureido group, which is represented by N-C(=O)NH2. Although the CoT mislabels the group, it correctly identifies the final connectivity NC(=O)N required for the SMILES string, allowing it to reach the right answer despite the slight nomenclatural error."
        },
        {
            "title": "F USE OF LLMS",
            "content": "During the preparation of this work, the author(s) used LLMs to improve the language and readability. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication."
        }
    ],
    "affiliations": [
        "Fudan University",
        "Hong Kong Polytechnic University",
        "Nanjing University",
        "Shanghai AI Lab",
        "The Chinese University of Hong Kong, Shenzhen",
        "The University of Hong Kong",
        "Tongji University",
        "University of Science and Technology of China"
    ]
}