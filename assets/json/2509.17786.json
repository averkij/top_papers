{
    "paper_title": "Accurate and Efficient Low-Rank Model Merging in Core Space",
    "authors": [
        "Aniello Panariello",
        "Daniel Marczak",
        "Simone Magistri",
        "Angelo Porrello",
        "Bartłomiej Twardowski",
        "Andrew D. Bagdanov",
        "Simone Calderara",
        "Joost van de Weijer"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "In this paper, we address the challenges associated with merging low-rank adaptations of large neural networks. With the rise of parameter-efficient adaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-tuning has become more accessible. While fine-tuning models with LoRA is highly efficient, existing merging methods often sacrifice this efficiency by merging fully-sized weight matrices. We propose the Core Space merging framework, which enables the merging of LoRA-adapted models within a common alignment basis, thereby preserving the efficiency of low-rank adaptation while substantially improving accuracy across tasks. We further provide a formal proof that projection into Core Space ensures no loss of information and provide a complexity analysis showing the efficiency gains. Extensive empirical results demonstrate that Core Space significantly improves existing merging techniques and achieves state-of-the-art results on both vision and language tasks while utilizing a fraction of the computational resources. Codebase is available at https://github.com/apanariello4/core-space-merging."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 2 ] . [ 1 6 8 7 7 1 . 9 0 5 2 : r Accurate and Efficient Low-Rank Model Merging in Core Space Aniello Panariello1 Daniel Marczak2,3 Simone Magistri4 Angelo Porrello1 Bartłomiej Twardowski5,6 Joost van de Weijer5 Simone Calderara1 Andrew D. Bagdanov4 1AImageLab, University of Modena and Reggio Emilia, Italy 2Warsaw University of Technology, Poland 3IDEAS NCBR, Warsaw, Poland 4Media Integration and Communication Center (MICC), University of Florence, Italy 5IDEAS Research Institute, Warsaw, Poland 6Computer Vision Center, Universitat Autònoma de Barcelona, Spain"
        },
        {
            "title": "Abstract",
            "content": "In this paper, we address the challenges associated with merging low-rank adaptations of large neural networks. With the rise of parameter-efficient adaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-tuning has become more accessible. While fine-tuning models with LoRA is highly efficient, existing merging methods often sacrifice this efficiency by merging fully-sized weight matrices. We propose the Core Space merging framework, which enables the merging of LoRA-adapted models within common alignment basis, thereby preserving the efficiency of low-rank adaptation while substantially improving accuracy across tasks. We further provide formal proof that projection into Core Space ensures no loss of information and provide complexity analysis showing the efficiency gains. Extensive empirical results demonstrate that Core Space significantly improves existing merging techniques and achieves state-of-the-art results on both vision and language tasks while utilizing fraction of the computational resources. Codebase is available at https://github.com/apanariello4/core-space-merging."
        },
        {
            "title": "Introduction",
            "content": "In recent years, the size of neural networks has grown substantially [2, 4, 9, 13, 51], increasing the economic and computational costs associated with training from scratch and fine-tuning. As consequence, efficient low-rank adaptation techniques have emerged, which enable broader access to these powerful models [15, 16, 21, 26, 56]. Techniques like Low-Rank Adaptation (LoRA) [16] reparameterize model updates to significantly reduce the number of trainable parameters. This makes it feasible for broader range of users to fine-tune large architectures on their specific tasks. At the same time, the advent of model hubs such as Hugging Face [17] has simplified the diffusion of pre-trained and fine-tuned models, opening new opportunities for collaborative and multi-task learning by allowing users to acquire and build upon existing models easily. In this context, model merging, which aims to combine multiple specialized models into one capable of handling various tasks, has been gaining interest [32, 37, 48, 27, 39]. However, most prior works focus on fully fine-tuned models [6, 12, 18, 28, 34, 46, 50, 38]. While this is practical for smaller architectures, fully fine-tuned versions of larger models are rare due to their high memory and compute costs. As model sizes grow, new strategies are needed to efficiently merge fine-tuned adaptations without incurring the prohibitive overhead of merging full models. Equal Contribution. aniello.panariello@unimore.it, daniel.marczak.dokt@pw.edu.pl 39th Conference on Neural Information Processing Systems (NeurIPS 2025). In [42], the authors observe that directly applying existing merging techniques [18, 50, 55] to updates derived by multiplying low-rank components leads to suboptimal results. To address this, they introduce an alignment space that improves update compatibility. However, merging in this alignment space requires abandoning the low-rank representation and performing singular value decomposition (SVD) on the horizontally concatenated full space upit eliminates the efficiency benefits of dates. This suffers from two significant drawbacks: low-rank adaptation, and becomes prohibitively expensive as the base model size increases. To overcome such limitations, we propose Core Space, novel parameter-efficient subspace that supports arbitrary merging techniques while retaining the benefits of low-rank adaptation. Core Space provides common alignment basis for all task-specific low-rank components without loss of information. Notably, its dimensionality depends solely on the number of tasks and the LoRA rank, remaining tractable regardless of the base model size. Beyond its advantages in terms of efficiency, merging in Core Space also consistently improves the performance of existing merging strategies. We evaluate three setups: (1) first multiplying low-rank matrices and then applying merging techniques, (2) merging in the KnOTS space [42], and (3) merging in our proposed Core Space. Across both vision and language domains, merging in Core Space achieves the best results demonstrated on ViT-B/32, ViTL/14, and Llama 3 8B backbones highlighting that our approach not only preserves parameter efficiency but also leads to improved generalization and task performance (see Fig. 1). Figure 1: Merging in full space is fast but suboptimal (bottom center). Merging in KnOTS space or using strong merging methods (e.g., TSV) improves performance but increases cost by orders of magnitude (right). Core Space merging is effective and efficient (top left). Results on Llama 3 8B. The main contributions of this paper are the following: We introduce Core Space Merging, framework to merge LoRA-adapted models in shared low-rank basis, avoiding costly full space operations, while improving accuracy. Our approach can be easily integrated with existing merging methods. We prove that projection into Core Space ensures no loss of information, and provide complexity analysis demonstrating the efficiency gain of merging in the proposed space. We present an extensive empirical evaluation showing state-of-the-art results achieved at fraction of the computational cost of competing methods by merging in Core Space for vision and language tasks, including experiments on ViT-B/32, ViT-L/14, and Llama 3 8B."
        },
        {
            "title": "2 Related Work",
            "content": "Parameter-efficient fine-tuning (PEFT). Pre-trained models serve as starting point for training experts specialized in various downstream tasks [10, 36]. As the size of frontier models grows, the cost of fully fine-tuning such models increases accordingly. Therefore, several parameter-efficient finetuning (PEFT), updating small fraction of parameters, have been proposed, including adapters [15], prefix tuning [25], and prompt tuning [24]. Nowadays, LoRA [16] and its variants [21, 26], which rely on low-rank updates, have emerged as one of the most popular PEFT techniques. Model merging. The abundance of available expert models inspired the fundamental question behind model merging [32]: how can we integrate knowledge from multiple expert models into single multi-task model? Task Arithmetic [18] proposed to construct task vectors (i.e., the parameter difference between expert and base model) and aggregate them via scaled addition, creating multitask expert. Since significant performance gap between the single-task and the merged models 2 remains, many approaches were proposed to address this issue [1, 19, 29, 31, 43, 52, 54, 35]. TIESMerging [50] focuses on reducing sign conflicts between the parameters of expert models. Model Breadcrumbs [8] removes outliers from the task vectors, while Consensus Merging [46] eliminates catastrophic and selfish weights. Most recent methods, like TSV [12] and Iso-C [28], rely on singular value decomposition (SVD) of weight update matrices to reduce task interference when merging models. However, most methods are designed for merging fully fine-tuned models. Merging LoRA-adapted models. Methods designed to merge fully fine-tuned models do not necessarily transfer well to merging LoRA-adapted models [44]. The authors of [44] proposed and improved method to merge LoRAs. However, their approach relies on altering the fine-tuning procedure. KnOTS [42] proposes to merge LoRA updates in the shared subspace, achieving significant improvement. However, KnOTS performs SVD on the concatenation of full-size matrices instead of leveraging their decomposed update representations, making it costly, especially for large weight matrices. Therefore, finding method that effectively and efficiently merges LoRA-adapted models remains an open challenge."
        },
        {
            "title": "3 Preliminaries",
            "content": "LoRA fine-tuning. Low-Rank Adaptation (LoRA) [16] is technique for efficient fine-tuning of large pre-trained models. Instead of updating the full model weights Rmn, LoRA introduces two learnable matrices Rrn and Rmr (where min(m, n)), and modifies the weight update as = W0 + = W0 + BA, where W0 is the original weight matrix. This significantly reduces the number of parameters that need to be updated during fine-tuning. Model merging. Given set of parameters {W1, . . . , WT }, for common architecture trained on different tasks, basic model merging approach calculates task vectors Wi = Wi W0, and computes weighted sum Wmerged = W0 + α (cid:80)T i=1 Wi. When dealing with LoRA-adapted models we obtain common W0 and set of decomposed, low-rank updates {Wi = BiAi}T i=1. However, merging such weight matrices obtained from LoRA leads to suboptimal performance as shown in [42], since LoRA-adapted models are less aligned w.r.t. to their fully fine-tuned counterparts."
        },
        {
            "title": "4 The Core Space Merging Framework",
            "content": "In this section, we introduce Core Space Merging (see Fig. 2), framework designed to identify an effective and efficient subspace referred to as the Core Space in which model merging for LoRA-adapted models can be performed while remaining in the low-rank regime. Core Space is designed to be reversible it ensures no loss of information when projecting into Core Space and back to the original space while being as compact as possible. Compactness allows for the use of state-of-the-art merging methods relying on Singular Value Decomposition (SVD) of weight matrices, which are highly costly to perform in the original space for large models."
        },
        {
            "title": "4.1 Model Merging in Core Space",
            "content": "Let A(t) Rrn and B(t) Rmr denote the low-rank matrices for task t, derived from shared pre-trained base model W0. Each task update (t) = B(t)A(t) can be reconstructed from the reduced SVD2 of the matrices: A(t) = (t) Σ(t) (t) , B(t) = (t) Σ(t) (t) , (t) = (t) Σ(t) (t) (t) Σ(t) (t) . (1) The shapes of the matrices in the decomposition are: (t) (t) Rmr, Σ(t) Definition 1 (Core Matrix). Given the SVD of low-rank matrices A(t) Rrn and B(t) Rmr, the core matrix (t) Rrr is defined as: Rrr, and (t) Rrr, Σ(t) Rrr, (t) Rnr, Rrr. (t) 2We use the reduced SVD throughout, as it offers suitable alternative for low-rank matrices where m, n. (t) := Σ(t) (t) Σ(t) . (2) 3 Figure 2: Full Space Merging (left) firstly reconstructs full space matrices (t) = B(t)A(t), and then performs merging in the full space to obtain . KnOTS Merging concatenates the (t) matrices, and performs costly SVD on this high-dimensional matrix. Then, the (t) matrices are merged and used to obtain the final . The proposed Core Space Merging (right) performs SVD on concatenation of low-dimensional A(t) and B(t) matrices to obtain reference bases. Afterwards, it performs SVD on the individual A(t) and B(t) matrices and calculates the core matrices. It then performs merging in the Core Space and reconstructs to obtain the final . Intuitively, the core matrix (t) is compact representation summarizing the directional transformation applied by the low-rank update of task t, expressed in the singular spaces of A(t) and B(t). We confirm this intuition in Sec. 5.2. Under the hypothesis that all tasks share approximately the same common bases (UB, VA) such that UB (t) , {1, . . . , }, the following holds: , VA (t) = (cid:88) t= (t) UB (cid:33) (t) , (cid:32) (cid:88) t=1 (3) suggesting that, under aligned bases, the sum of low-rank updates (i.e., Task Arithmetic [18]) can be approximated by merging the corresponding core matrices reducing the merging problem to operations in much smaller space. However, task-specific bases are misaligned in practice, making it impossible to directly compare or merge task-specific core matrices as in Eq. (3). Therefore, we aim to find shared basis that can represent all tasks without loss of information. Intuitively, such shared basis should span the subspace formed by the union of the individual task subspaces. Definition 2 (Reference Bases). Given collection of low-rank matrices {A(t), B(t)}T as reference bases the orthonormal matrices (U ref vertically stacked A(t) and horizontally stacked B(t) low-rank matrices across tasks. t=1, we define ) obtained by performing SVD over the , ref [B(1); ; B(T )] = ref ΣBV ; = UAΣA (cid:0)V ref (cid:1) . (4) A(1) ... A(T ) These bases span shared latent subspace into which all task-specific updates are projected. For each task t, we express the task-specific bases (U (t) the reference bases (U ref , (t) R(t) = arg min RRT rr , ref ) by solving the following least-squares problems: (cid:13) (cid:13)U ref (cid:13) (t) (cid:13) (cid:13)V ref (cid:13) , Q(t) = arg min QRT rr RnT (and similarly for (t) and ref (cid:13) 2 (cid:13) (cid:13) (t) F where (t) convex, and since ref Rnr and ref and ref ). These problems are are orthonormal, setting the gradients to zero yields the global (cid:13) 2 (cid:13) (cid:13) , (5) ) in the coordinate system defined by 4 minimizers (see Sec. A.1 for the full derivation): The aligned core matrix (t) for task is then computed as: R(t) = ref , Q(t) (t) = ref (t) = R(t) (t)Q(t) . (t) (6) (7) Finally, we merge the set of aligned core matrices { (t)}T M({ (t)}T weight matrix from Mmerged by projecting it back to the full space using the reference bases: t=1 using function M, yielding Mmerged = t=1), where denotes any existing merging strategy. We then reconstruct the final = ref MmergedV ref . (8) Core Space merging offers several advantages over merging in the full space: No loss of information transformation to core space and back to full space is lossless (see Sec. 4.2 for the proof of zero alignment error). Moreover, when the merging function is linear (e.g., Task Arithmetic), the model merged in full space will be the same as the model merged in core space (t) and then reconstructed using the reference bases. Efficiency aligned core matrices (t) RT rT have considerably lower dimensionality than full space matrices (t) Rmn since T, m, n. Therefore, we can perform an expensive merging technique in the subspace of reduced dimensionality for fraction of the total computational cost (see Sec. 4.3 for detailed complexity analysis). Efficacy in Sec. 5.1 we show that merging in Core Space yields better performance than merging in alternative spaces, when the merging function is non-linear. In Sec. 5.2, we shed light on the reasons for Core Space superiority. Our approach is found to yield compact representations of each task and improve alignment between subspaces of each task."
        },
        {
            "title": "4.2 No Information Loss in Core Space Representation",
            "content": "For each task t, reconstructing from the aligned core matrix (t) exactly recovers the original low-rank update, i.e.: (t) = (t) (t)V (t) = ref M (t)V ref (cid:16) = R(t) ref (cid:17) (t) (cid:16) Q(t) ref (cid:17) . (9) R(t) Q(t) = ref = ref and ref and (t) The outer expressions are given by construction (see Eqs. (1), (2) and (7)). The middle equality holds if (t) or, equivalently, if the solutions of the least squares problems (defined in Eq. (5)) incur zero alignment error. Indeed, we show that the reference bases ref , computed via the SVD of the stacked matrices B(t) and A(t) (see Eq. (4)), minimize the total alignment error across all tasks, achieving an error of exactly zero. To illustrate this, we first analyze the alignment error for single task t, explicitly focusing on ref . Analogous conclusions hold symmetrically for ref . For clarity, in the following derivations, we assume that and n, so that the total LoRA rank does not exceed the maximum possible rank of the target weight matrix. In Sec. A.4, we provide more general formulation covering the case where this assumption is violated and show that the same zero alignment error result continues to hold. Lemma. Let (t) Rmr and ref RmT be matrices with orthonormal columns, and let R(t) (t) RT rr be the optimal solution minimizing the error of the least-square problem. Then, the optimal alignment error is given by: = ref εU = (cid:13) (cid:13)U ref (cid:13) R(t) (t) (cid:13) 2 (cid:13) (cid:13) = (cid:13) (cid:13) (t) (cid:13) (cid:13)"
        },
        {
            "title": "U ref\nB",
            "content": "(cid:13) 2 (cid:13) (cid:13) (cid:13) . (10) and ref The proof, provided in Sec. A.2, leverages the properties of Frobenius norm and the orthonormality of (t) minimizes the alignment error across all tasks (or equivalently maximize (t) for each task t), we first formulate B . To formally demonstrate that our chosen reference basis ref"
        },
        {
            "title": "U ref",
            "content": "5 Algorithm 1 Core Matrix Alignment and Merging Require: Low-rank updates {(A(t), B(t))}T 1: Stack A(t) vertically, B(t) horizontally 2: Compute SVDs: stack(A(t)) = UAΣAV ref 3: for = 1 to do 4: 5: Merge aligned core matrices: Mmerged = M({ (t)}T MmergedV ref 6: return = ref Compute: (t) = ref B(t)A(t)V ref A t=1) t=1, merging function M(). , stack(B(t)) = ref ΣBV reference bases Eq. (6) and Eq. (7) reconstructed merged model the following constrained optimization problem for single task, and then extend it to the multi-task scenario: (cid:13) (cid:13) (t) (cid:13) (cid:13) , = (cid:8)U RmT (cid:12) (cid:12) = IT = max U (t) (t) max (cid:13) 2 (cid:13) (cid:13) (cid:13) (11) (cid:9) , tr (cid:18) (cid:19) F where tr() denotes the trace operator. The optimization domain is restricted to the Stiefel manifold (i.e., the set of matrices with orthonormal columns). The following lemma characterizes the solution to this optimization problem: Lemma. solution to the quadratic program in Eq. (11) is given by basis whose columns include the eigenvectors corresponding to nonzero eigenvalues of B(t)B(t) Rmm or, equivalently, by the left singular vectors of the matrix B(t). Moreover, at the optimum, the objective attains its maximum value r, resulting in zero alignment error in Eq. (10). We refer the reader to Appendix A.3 for detailed proof. Briefly, the result follows by applying the method of Lagrange multipliers to augment the optimization objective with the Stiefel manifold constraint and then enforcing stationarity by setting the gradient of the Lagrangian to zero. Extension to multiple tasks. Achieving zero reconstruction error for single model does not guarantee optimality for any other model = t. Therefore, we aim to identify reference basis that jointly optimizes Eq. (11) across all models. We formulate this global problem as: max (cid:88) t=1 tr(U (t) (t) ) = max tr(U UBU BU ), (12) . . . (T ) (2) ] denotes the horizontal concatenation of all (t) where UB = [U (1) matrices. The equality in Eq. (12) follows directly from the linearity of the trace operator and the distributivity of matrix multiplication concerning matrix addition: A1M + A2M = (A1 + A2)M . By considerations analogous to the single task-case, global solution is given by the top left singular vectors of the matrix B, obtained by vertically stacking each matrix B(t), i.e., = ref . This choice ensures zero alignment error simultaneously across all tasks, consistent with the procedure described in Sec. 4.1. Exact merging via linear functions in Core Space. Thanks to the lossless reconstruction of each task-specific update (see Eq. (9)), if the merging function is linear (such as in Task-Arithmetic), then merging in Core Space produces the same merged matrix as merging in full space. Specifically: M({W (t)}T t=1) = M({U ref (t)V ref t=1) = ref }T M({ (t)}T t=1)V ref . (13) It is worth noting that Core Space merging is computationally efficient and does not increase time complexity even when task arithmetic is applied in Core Space due to its lower dimensionality, as we will show in the next section. Moreover, when the merging function is non-linear, we will show in Sec. 5.1 that it can improve performance compared to standard merging strategies applied in the full space at fraction of the computational cost. For example, when dealing with Llama 3 8B, we have speedup of more than 600 with respect to KnOTS [42] for the Iso-C [28] method. Practical Implementation. While we introduce the per-task SVDs of A(t) and B(t) for theoretical clarity, in practice the core matrix can be computed more directly as (t) = ref B(t)A(t)V ref , 6 Figure 3: Core Space merging is more efficient than the previous state-of-the-art KnOTS. The cost is similar to full space merging, which results in much lower performance. We visualize the number of operations performed to merge rank LoRA modules of final shape n. and Q(t) without explicitly decomposing each LoRA matrix. This follows directly by substituting the definitions of R(t) from Eq. (6) into Eq. (7), and by recalling the definitions of B(t), A(t), and (t) (see Eqs. (1) and (2)). This yields identical results and is marginally more computationally efficient. The decomposition of A(t) and B(t) helps formalize the projection process and support the derivations in Sec. A, including orthogonality, rank preservation, and the zero-error reconstruction proofs. For this reason, we retain the SVD-based formulation in the theoretical exposition. We report in Algorithm 1 the algorithm for Core Space merging with this computationally optimized approach and the illustration in Sec. D.1."
        },
        {
            "title": "4.3 Computational Complexity Analysis",
            "content": "Table 1: O() time complexities. The cheapest method is highlighted in bold (T, n). We summarize the time complexities of TA, Iso-C, and TSV merged in all three spaces (Full, KnOTS, and our Core) in Tab. 1 and Fig. 3. Details on the derivation of the complexities are in Appendix B. Our approach exhibits time complexity comparable to that of Task Arithmetic in full space. Our methods additional terms are negligible unless the product becomes significantly large. key advantage of our method lies in its scalability compared to KnOTS, whose time complexity is super-cubic, driven by factor that scales cubically with the weight matrix size n. Finally, we emphasize the minimal additional overhead incurred when combining our method with Iso-C or TSV in the core space; it introduces cost substantially lower than its counterpart in full space or KnOTS space. n3T n3T 2 + 3r2n n2T n2T + 3r3 n2T + 4r3 TA n2T Full KnOTS n3T 2 Core n3 n3T 2 + n2T r"
        },
        {
            "title": "Space",
            "content": "Iso-C"
        },
        {
            "title": "5 Experimental Results",
            "content": "Experimental setup. We follow the experimental setup of KnOTS and use the LoRA checkpoints provided by the authors [42]. For the vision experiments, we use two variants of CLIP [36] with ViT-B/32 and ViT-L/14 [11] as vision encoders fine-tuned on standard set of 8 tasks. We employ Llama 3 8B [13] fine-tuned on 6 NLI tasks for the language experiments. All models are fine-tuned with LoRA [16] with rank 16 applied on all matrices (keys, queries, values, and outputs) across all attention layers. Following [42], we report normalized accuracy as ratio of the accuracy of the merged model on given task to the accuracy of the model fine-tuned on this task. We also report absolute accuracy for the joint-task setting (additional experimental details in Sec. D). Baseline merging spaces. We compare our proposed Core Space with two alternative merging spaces. Full Space operates in space of full reconstructed weight matrices (t) = B(t)A(t) Rmn. KnOTS Space [42] operates in the space of the right singular vectors of the concatenated reconstructed weight matrices {W (t)}T t=1 RmnT . Baseline merging methods. We evaluate each merging space using the following merging methods. Task Arithmetic (TA) [18] performs scaled summation of each task matrix Wmerged = 7 Table 2: Normalized accuracies of merged models on NLI tasks for Llama 3 8B."
        },
        {
            "title": "RTE",
            "content": "SCITAIL Avg (Acc) Time [s] Rel. Time Abs. Accurcay TA"
        },
        {
            "title": "TIES",
            "content": "DARE-TIES"
        },
        {
            "title": "TSV",
            "content": "Iso-C"
        },
        {
            "title": "Full\nKnOTS\nCore",
            "content": "92.50 93.57 95.17 91.82 92.07 94.76 91.62 92.10 95.38 92.53 95.86 55.00 85.28 91. 90.31 95.28 96.19 94.19 93.51 96.8 96.72 93.58 95.12 95.83 95.70 39.04 52.86 90. 91.58 87.96 84.18 92.97 93.63 78.39 74.90 93.70 88.83 82.77 89.25 76.54 89.43 87. 94.49 68.71 74.18 78.57 83.72 72.08 84.75 83.68 76.80 77.01 83.89 55.90 54.90 75. 89.86 100.0 100.0 100.0 99.19 98.39 99.48 99.19 101.61 100.0 102.42 46.77 75.00 99. 96.52 96.73 96.78 97.61 97.66 96.20 99.13 97.66 97.56 97.08 97.86 69.25 77.73 97. - 90.38 (+0.00) 91.08 (+0.00) 92.53 (+1.45) 93.30 (+2.22) 89.44 (+0.00) 91.10 (+1.66) 93.32 (+3.88) 92.55 (+0.00) 90.87 (-1.68) 94.16 (+1.61) 57.08 (+0.00) 72.53 (+15.45) 90.33 (+33.25) - 9 72 3000 8 108 3180 8 3360 4800 12 540 4860 - - 9 375 1 13 397 1 280 400 1 67 607 W0 + α (cid:80)T i=1 Wi. As this is linear operation, the results of merging in each space are the same (see Eq. (13) for Core and [42] for KnOTS). TIES [50] trims low-magnitude parameters and averages parameters with dominating sign, while DARE [55] preprocesses task vectors by randomly dropping fraction of parameters and rescaling the remaining ones. TSV [12] concatenates low-rank approximations of task matrices and orthogonalizes them across tasks. CART [6] calculates centered task vectors as difference of fine-tuned weights from the average of all fine-tuned weights and performs task arithmetic on the low-rank approximation of these centered task vectors. Iso-C [28] flattens the spectrum of singular values for model merged with task arithmetic. As the spectrum flattening can be performed on weights merged with any merging technique, we combine Iso with other merging techniques, denoting it with +Iso-C."
        },
        {
            "title": "5.1 Results",
            "content": "LLMs merging. We present Llama 3 8B results in natural language inference in Tab. 2. In line with our complexity analysis, merging in Core Space is much more efficient than merging in Full or KnOTS space, bringing up to 600 merging speed-up. Moreover, merging in Core Space improves the performance of all tested merging methods. In particular, it elevates TSV to 94.16% average normalized accuracy, achieving state-of-the-art results. Per-task evaluation in vision setting. We present per-task vision results for ViT-B/32 in Tab. 3. We observe that 8 out of 9 merging methods achieve their highest average accuracy when performed in our proposed Core Space. The best combination TSV + Iso-C merged in Core Space achieves stateof-the-art average normalized accuracy of 76.3%. It significantly outperforms the previously reported SoTA of TIES in KnOTS space, achieving 68.0% [42]. Similar conclusions hold for experiments on ViT-L/14 presented in Sec. E.1. Heterogeneous ranks. While handling LoRA modules with heterogeneous ranks might seem non-trivial, our method supports it seamlessly without modification. Even with different ranks, the modules can be concatenated across tasks to form an aggregate basis spanning the combined subspaces, after which projection and alignment are applied to each local task core matrix. Since SVD makes no assumptions about input ranks, it yields valid orthonormal bases in all cases, enabling our framework to merge variable-rank LoRA modules naturally. We evaluate this setting by assigning rank 16 to half the tasks and rank 64 to the rest; the results reported in Sec. E.2 show that our method still outperforms other approaches. Additional PEFT methods Our method can also be applied to other PEFT methods, such as In VeRA, = ΛbBΛdA, where Rrn, Rmr, Λb R1m, and VeRA [21]. Λd Rr1. Unlike LoRA, in VeRA the and matrices are randomly chosen, frozen, and shared across the network, while only the two scaling vectors Λ are learned for each layer. To adapt VeRA to our Core Space merging, we absorb the scaling vectors into the matrices, i.e., = ΛbB and = ΛdA, and then treat and as the LoRA and matrices. To confirm that our method also works with VeRA, we report additional experiments in Sec. E.3, which show that our method outperforms other baselines also in this setting. 8 Table 3: Normalized accuracies of merged models on the vision tasks with ViT-B/32. Method Space Cars DTD EuroSAT GTSRB MNIST RESISC SUN397 SVHN Avg ( Acc) Abs. accuracies TA TIES DARE-TIES TSV CART TIES +Iso-C DARE-TIES +Iso-C TSV +Iso-C CART +Iso-C Iso-C Full Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core 74.00 58.30 81.97 73.72 82.37 83.75 84. 82.14 82.01 84.57 83.44 81.86 83.86 83.04 83.94 80.83 78.86 78.46 82.91 78.71 82.93 83.27 79.38 80.81 82. 80.33 82.05 82.93 80.16 80.33 83.35 72.72 74.45 76.46 73.72 72.90 76.09 75.55 74.91 75.09 81.93 75.18 83. 74.45 80.38 84.76 75.54 74.18 83.12 80.38 83.03 85.12 82.11 80.47 84.21 83.03 79.29 84.30 99. 48.97 49.91 50.36 52.19 49.35 44.15 57.09 50.99 51.25 52.64 50.39 52.23 54.99 60.01 58.81 52. 50.84 49.31 54.55 57.99 58.25 50.95 57.31 56.12 51.14 51.44 57.50 50.13 92.70 42. 36.62 47.31 50.41 37.78 45.54 51.01 45.03 41.64 45.39 70.17 54.48 73.28 39.02 64.97 78.79 42.86 46.73 79. 65.64 74.34 84.25 77.38 64.58 81.32 74.76 67.60 81.97 99.30 53.12 57.16 67.01 67. 56.63 60.59 66.64 59.31 53.93 58.53 59.14 64.78 66.25 66.65 72.10 71.56 65.03 66.64 71.83 64.22 67.66 71. 71.17 62.40 72.12 70.72 65.63 71.07 88.40 71.50 69.38 71.79 71.21 70.14 70.89 71. 73.33 71.64 72.95 79.11 74.48 80.95 70.30 76.89 81.43 71.88 71.82 82.08 79.74 79.69 84.39 81.57 78.81 82. 79.89 79.54 83.46 64.50 97.46 96.92 96.51 96.45 97.35 95.56 96.16 96.40 97.95 97. 99.26 95.88 98.69 98.39 98.33 99.48 98.92 96.72 99.36 98.59 98.54 99.06 98.72 99.22 99.33 98.66 99.26 99. 96.20 41.25 44.56 50.64 50.18 42.12 47.64 52.14 49.23 40.36 45.21 49.11 55.73 48. 48.59 49.78 52.14 48.08 50.57 52.37 46.49 49.86 53.53 51.91 45.05 55.32 50.20 46.62 53.90 - 63.78 (+0.00) 63.70 (+0.00) 67.73 (+4.03) 68.63 (+4.93) 63.65 (+0.00) 64.91 (+1.26) 69.39 (+5.74) 66.66 (+0.00) 64.19 (-2.47) 66.41 (-0.25) 71.52 (+0.00) 69.59 (-1.93) 73.44 (+1.92) 67.03 (+0.00) 72.47 (+5.44) 75.44 (+8.41) 66.48 (+0.00) 67.36 (+0.88) 75.70 (+9.22) 71.55 (+0.00) 74.02 (+2.47) 76.43 (+4.88) 75.06 (+0.00) 71.09 (-3.97) 76.15 (+1.09) 73.60 (+0.00) 71.97 (-1.63) 75.92 (+2.32) Table 4: Joint-task setting absolute accuracy of merged models on the vision tasks with ViT-B/32."
        },
        {
            "title": "Space",
            "content": "TA TIES DARE-TIES"
        },
        {
            "title": "TSV CART",
            "content": "TIES +Iso-C DARE-TIES +Iso-C TSV +Iso-C CART +Iso-C Iso-C"
        },
        {
            "title": "Full\nKnOTS\nCore",
            "content": "43.5 43.5 43.5 43.6 46.8 47.4 44.0 45.2 47.6 45.4 44.6 44.5 44.8 44.7 49.6 43.5 40.5 54. 44.3 44.8 54.0 48.3 51.4 55.7 44.8 52.6 55.6 52.1 52.9 55.9 Joint-task evaluation in vision setting. We also evaluate vision models in the challenging joint-task setting introduced in [42], in which the task ID is unknown during inference. Instead of performing multi-task evaluation, it evaluates the merged model based on the union of all classes, requiring the model to distinguish between classes from all tasks. We present the results in Tab. 4. Core Space facilitates merging with almost all methods, achieving state-of-the-art results when combined with Iso-C."
        },
        {
            "title": "5.2 Analysis",
            "content": "Truncation. In this Section, we compare the utilization of full subspace and core space for models merged with TA. Firstly, we calculate the SVD of the merged matrices: Wmerged for full space and Mmerged for core space. Then, we truncate fraction of least significant values, i.e., σi = 0 for > (1 p) dim(Σ), and observe the drop in the performance of the merged model after truncation. We present the results in Fig. 4. In full space, we can truncate fraction up to = 0.8 values without performance loss, while in core space, truncation of any component results in performance drop. It shows that the core space is dense while the full space contains many unused or redundant components. We hypothesize that the compactness of core space facilitates model merging as it extracts only the relevant components. Core Space improves subspace alignment. In this Section, we evaluate the Subspace Alignment Ratio (SAR) [28] between each pair of LoRA updates fine-tuned on different tasks. The SAR measures how much of the subspace of one task is contained in another and correlates with postmerge performance. We compute SAR in full and core space. Fig. 5 shows that core space yields 9 Figure 4: Most components in full space are irrelevant when doing Task-Arithmetic (TA). Removing any components from the core space results in performance drop, showing that it is an information-dense space. We report the results on vision tasks with ViT-B/32. Figure 5: Subspace Alignment Ratio (SAR) [28]. Each bar shows the average SAR between LoRA task matrices, Full, and Core Space. In Core Space, task matrices exhibit higher SAR. The associated performance gains suggest that better alignment facilitates more effective merging. consistently higher alignment. We argue that this result is because the core space enforces shared basis across tasks, which filters out task-specific noise and promotes alignment. In Sec. C.1 we show that higher SAR correlates with lower merging interference. Table 5: Ablations on the choice of reference basis. Our selected basis (3) achieves significantly higher results than the single-task basis (1) and the random orthonormal basis of the same dimensionality (2). We proceed with ref analogously to ref . We report the TIES-Core results on vision tasks with ViT-B/32. Choice of the reference basis. To evaluate the reference bases choice, we compare the performance of merging in core space against different reference bases, and compute the alignment error εU defined in Eq. (10) (averaged over all layers and tasks). We present the results in Tab. 5. In row (1), we evaluate using the basis of the first task as reference basis. In row (2), we set the reference basis to random orthonormal basis of the same dimensionality. These two bases perform much less than our reference basis in row (3). Moreover, we confirm that the optimal reference basis from row (3) achieves zero alignment error. Additionally, we verified experimentally that even in the extreme case where > min(m, n) (e.g., = 2048 > 768 for merging 8 ViT-B/32 LoRA models), the reconstruction error defined in Eq. (10) remains exactly zero, consistent with the generalized theoretical result in Sec. A.4. (1) (1) (first task) (2) Random orthonormal (3) Concatenation (Eq. (4)) r"
        },
        {
            "title": "Reference Basis U ref\nB",
            "content": "Avg. Acc. Avg. εU 60.4 61.6 68.6 13.4 13.3 0."
        },
        {
            "title": "6 Conclusion",
            "content": "We propose Core Space, an efficient and effective method for merging task-specific LoRA modules. By projecting task-specific LoRA updates into common subspace, Core Space reduces alignment error, leading to consistent accuracy improvements and SOTA results in both vision and language settings, while remaining computationally efficient. Our evaluations across vision and language domains confirm its scalability and strong performance in practical settings. We believe that Core Space can contribute to more efficient and accessible model adaptation in multi-task settings, particularly for large models."
        },
        {
            "title": "Acknowledgments",
            "content": "the project"
        },
        {
            "title": "Spanish",
            "content": "acknowledge PID2022-143257NB-I00, We by MCIN/AEI/10.13039/501100011033 and FEDER, and Funded by the European Union ELLIOT project. This work was supported by the Fortissimo Plus (FFplus) project Grant Agreement No. 101163317), under the European High-Performance Computing Joint Undertaking (EuroHPC JU) and the Digital Europe Programme. The authors gratefully acknowledge access to compute resources enabled by FFplus. Funded by the European Union. Aniello Panariello acknowledges travel support from ELIAS (GA no 101120237). Daniel Marczak is supported by National Centre of Science (NCN, Poland) Grant No. 2021/43/O/ST6/02482. Bartłomiej Twardowski acknowledges the grant RYC2021-032765-I and National Centre of Science (NCN, Poland) Grant No. 2023/51/D/ST6/02846. financed"
        },
        {
            "title": "References",
            "content": "[1] T. Akiba, M. Shing, Y. Tang, Q. Sun, and D. Ha. Evolutionary optimization of model merging recipes. Nature Machine Intelligence, 2025. [2] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cappelli, R. Cojocaru, M. Alhammadi, M. Daniele, D. Heslow, J. Launay, Q. Malartic, B. Noune, B. Pannier, and G. Penedo. The falcon series of language models: Towards open frontier models. arXiv preprint arXiv: 2311.16867, 2023. [3] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning. large annotated corpus for learning natural language inference. Empirical Methods in Natural Language Processing, 2015. [4] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot learners. Advances in Neural Information Processing Systems, 2020. [5] G. Cheng, J. Han, and X. Lu. Remote Sensing Image Scene Classification: Benchmark and State of the Art. Proceedings of the IEEE, 2017. [6] J. Choi, D. Kim, C. Lee, and S. Hong. Revisiting weight averaging for model merging. arXiv preprint arXiv:2412.12153, 2024. [7] M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, and A. Vedaldi. Describing Textures in the Wild. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2014. [8] M.-J. Davari and E. Belilovsky. Model breadcrumbs: Scaling multi-task model merging with sparse masks. Proceedings of the European Conference on Computer Vision, 2024. [9] DeepSeek-AI. Deepseek-v3 technical report. arXiv preprint arXiv: 2412.19437, 2024. [10] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, 2019. [11] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021. [12] A. A. Gargiulo, D. Crisostomi, M. S. Bucarelli, S. Scardapane, F. Silvestri, and E. Rodolà. Task singular vectors: Reducing task interference in model merging. Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2025. [13] A. Grattafiori, A. Dubey, A. Jauhri, and A. P. et al. The llama 3 herd of models. arXiv preprint arXiv: 2407.21783, 2024. 11 [14] P. Helber, B. Bischke, A. Dengel, and D. Borth. Introducing eurosat: novel dataset and deep learning benchmark for land use and land cover classification. In IEEE International Geoscience and Remote Sensing Symposium, 2018. [15] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, 2019. [16] J. E. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, and W. Chen. Lora: Low-rank adaptation of large language models. International Conference on Learning Representations, 2021. [17] Hugging Face. https://huggingface.co, 2024. [18] G. Ilharco, M. T. Ribeiro, M. Wortsman, L. Schmidt, H. Hajishirzi, and A. Farhadi. Editing models with task arithmetic. In International Conference on Learning Representations, 2023. [19] X. Jin, X. Ren, D. Preotiuc-Pietro, and P. Cheng. Dataless knowledge fusion by merging weights of language models. In International Conference on Learning Representations, 2023. [20] T. Khot, A. Sabharwal, and P. Clark. SciTail: textual entailment dataset from science question answering. In Proceedings of the AAAI Conference on Artificial Intelligence, 2018. [21] D. J. Kopiczko, T. Blankevoort, and Y. M. Asano. Vera: Vector-based random matrix adaptation. International Conference on Learning Representations, 2023. [22] J. Krause, M. Stark, J. Deng, and L. Fei-Fei. 3d object representations for fine-grained categorization. In IEEE International Conference on Computer Vision and Pattern Recognition Workshops, 2013. [23] Y. LeCun, C. Cortes, and C. Burges. Mnist handwritten digit database. ATT Labs [Online]., 2, 2010. [24] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691, 2021. [25] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021. [26] S. Liu, C. Wang, H. Yin, P. Molchanov, Y. F. Wang, K. Cheng, and M. Chen. Dora: Weightdecomposed low-rank adaptation. In International Conference on Machine Learning, 2024. [27] G. Mancusi, M. Bernardi, A. Panariello, A. Porrello, S. Calderara, and R. Cucchiara. Is multiple object tracking matter of specialization? In Advances in Neural Information Processing Systems, 2024. [28] D. Marczak, S. Magistri, S. Cygert, B. Twardowski, A. D. Bagdanov, and J. van de Weijer. No task left behind: Isotropic model merging with common and task-specific subspaces. In International Conference on Machine Learning, 2025. [29] D. Marczak, B. Twardowski, T. Trzcinski, and S. Cygert. Magmax: Leveraging model merging for seamless continual learning. Proceedings of the European Conference on Computer Vision, 2024. [30] M. Marelli, S. Menini, M. Baroni, L. Bentivogli, R. Bernardi, and R. Zamparelli. SICK cure for the evaluation of compositional distributional semantic models. In Proceedings of the Ninth International Conference on Language Resources and Evaluation, 2014. [31] I. E. Marouf, S. Roy, E. Tartaglione, and S. Lathuilière. Weighted ensemble models are strong continual learners. arXiv preprint arXiv: 2312.08977, 2023. [32] M. Matena and C. Raffel. Merging models with fisher-weighted averaging. In Advances in Neural Information Processing Systems, 2021. [33] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images with unsupervised feature learning. In Neural Information Processing Systems Workshops, 2011. [34] G. Ortiz-Jiménez, A. Favero, and P. Frossard. Task arithmetic in the tangent space: Improved editing of pre-trained models. In Advances in Neural Information Processing Systems, 2023. [35] A. Panariello, E. Frascaroli, P. Buzzega, L. Bonicelli, A. Porrello, and S. Calderara. Modular embedding recomposition for incremental learning. Brit. Mach. Vis. Conf., 2025. [36] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, 2021. [37] A. Rame, M. Kirchmeyer, T. Rahier, A. Rakotomamonjy, P. Gallinari, and M. Cord. Diverse weight averaging for out-of-distribution generalization. Advances in Neural Information Processing Systems, 35, 2022. [38] F. Rinaldi, G. Capitani, L. Bonicelli, D. Crisostomi, F. Bolelli, E. Ficarra, E. Rodolà, S. Calderara, and A. Porrello. Update your transformer to the latest release: Re-basin of task vectors. International Conference on Machine Learning, 2025. [39] A. Soutif, S. Magistri, J. v. d. Weijer, and A. D. Bagdanov. An empirical analysis of forgetting in pre-trained models with incremental low-rank updates. In Proceedings of The 3rd Conference on Lifelong Learning Agents, Proceedings of Machine Learning Research, 2025. [40] C. . C. Staff. Singular value decompositions, 2020. Course Notes, CS 357: Numerical Methods I, Fall 2020. [41] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition. Neural Networks, 32:323332, 2012. [42] G. Stoica, P. Ramesh, B. Ecsedi, L. Choshen, and J. Hoffman. Model merging with svd to tie the knots. International Conference on Learning Representations, 2025. [43] D. Tam, M. Bansal, and C. Raffel. Merging by matching models in task subspaces. arXiv preprint arXiv: 2312.04339, 2023. [44] A. Tang, L. Shen, Y. Luo, Y. Zhan, H. Hu, B. Du, Y. Chen, and D. Tao. Parameter efficient multi-task model fusion with partial linearization. In International Conference on Learning Representations, 2023. [45] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. GLUE: multi-task benchmark and analysis platform for natural language understanding. In International Conference on Learning Representations, 2018. [46] K. Wang, N. Dimitriadis, G. Ortiz-Jiménez, F. Fleuret, and P. Frossard. Localizing task information for improved model merging and compression. In International Conference on Machine Learning, 2024. [47] A. Williams, N. Nangia, and S. R. Bowman. broad-coverage challenge corpus for sentence understanding through inference. Naacl, 2018. [48] M. Wortsman, G. Ilharco, S. Y. Gadre, R. Roelofs, R. Gontijo-Lopes, A. S. Morcos, H. Namkoong, A. Farhadi, Y. Carmon, S. Kornblith, et al. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In ICML, 2022. [49] J. Xiao, K. A. Ehinger, J. Hays, A. Torralba, and A. Oliva. Sun database: Exploring large collection of scene categories. International Journal of Computer Vision, 2016. [50] P. Yadav, D. Tam, L. Choshen, C. Raffel, and M. Bansal. TIES-merging: Resolving interference when merging models. In Advances in Neural Information Processing Systems, 2023. 13 [51] A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu, F. Huang, H. Wei, H. Lin, J. Yang, J. Tu, J. Zhang, J. Yang, J. Yang, J. Zhou, J. Lin, K. Dang, K. Lu, K. Bao, K. Yang, L. Yu, M. Li, M. Xue, P. Zhang, Q. Zhu, R. Men, R. Lin, T. Li, T. Xia, X. Ren, X. Ren, Y. Fan, Y. Su, Y. Zhang, Y. Wan, Y. Liu, Z. Cui, Z. Zhang, and Z. Qiu. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115, 2024. [52] E. Yang, L. Shen, G. Guo, X. Wang, X. Cao, J. Zhang, and D. Tao. Model merging in llms, mllms, and beyond: Methods, theories, applications and opportunities. arXiv preprint arXiv: 2408.07666, 2024. [53] E. Yang, L. Shen, Z. Wang, G. Guo, X. Chen, X. Wang, and D. Tao. Representation surgery for multi-task model merging. International Conference on Machine Learning, 2024. [54] E. Yang, Z. Wang, L. Shen, S. Liu, G. Guo, X. Wang, and D. Tao. Adamerging: Adaptive model merging for multi-task learning. In International Conference on Learning Representations, 2024. [55] L. Yu, B. Yu, H. Yu, F. Huang, and Y. Li. Language models are super mario: Absorbing abilities from homologous models as free lunch. In International Conference on Machine Learning, 2024. [56] Q. Zhang, M. Chen, A. Bukharin, N. Karampatziakis, P. He, Y. Cheng, W. Chen, and T. Zhao. In International Adalora: Adaptive budget allocation for parameter-efficient fine-tuning. Conference on Learning Representations, 2023."
        },
        {
            "title": "Contents of the Appendix",
            "content": "No Information Loss in Core Space Representation A.1 Least Squares Solutions A.2 Alignment Error Quantification A.3 Optimal Reference Bases A.4 Generalization Beyond the m, Assumption Computational Complexity Analysis Additional Analysis C.1 High subspace alignment leads to lower interference C.2 Rank of the merged update matrices Additional Experiment Details"
        },
        {
            "title": "Experimental Environment",
            "content": "D.1 D.2 Hyperparameter Search D.3 Code Availability and Pseudocode Additional Results E.1 E.2 E.3 Per-task evaluation in vision setting for ViT-L/14 Experiments with Heterogeneous Ranks Extension to VeRA"
        },
        {
            "title": "A No Information Loss in Core Space Representation",
            "content": "A.1 Least Squares Solutions Rrr, (t) Rrr, Σ(t) Rmr, Σ(t) Let (t) Rnr, (t) Rrr be the RmT components of two low-rank matrices A(t) and B(t) represented in SVD form. Let ref RnT be the shared reference bases, obtained by taking the left and the right singular and ref vectors from the SVD of the horizontally and vertically stacked low-rank matrices B(t) and A(t), respectively (see Eq. 4 in the main paper). We assume and n, where is the number of tasks and is LoRA rank, as both are typically small relative to the feature dimension. Then, the solutions to the least square problems: Rrr, and (t) R(t) = arg min RRT rr are given by: (cid:13) (cid:13)U ref (cid:13) (t) (cid:13) 2 (cid:13) (cid:13) , Q(t) = arg min QRT rr (cid:13) (cid:13)V ref (cid:13) (t) R(t) = ref , Q(t) (t) = ref (t) . (cid:13) 2 (cid:13) (cid:13) , (14) (15) Proof. Since (t) and (t) come from the SVDs of A(t) and B(t), they are orthonormal: (t) = Ir where Ir is the identity matrix. Similarly, the reference bases ref orthonormal columns: = Ir, (t) (t) (t) ref where IT is the and identity matrix. ref = IT r,"
        },
        {
            "title": "U ref\nB",
            "content": "B = IT r, and ref also have Consider the problems in Eq. (14). Each objective is convex and admits unique global minimizer, as ref have full column rank due to their orthonormality. To solve the first problem, we compute the gradient of the objective function with respect to R: and ref (cid:13) (cid:13) (cid:13)U ref (t) (cid:13) 2 (cid:13) (cid:13) = 2U ref (U ref (t) ). Setting the gradient to zero and solving the resulting equation gives:"
        },
        {
            "title": "U ref\nB",
            "content": "B R(t) ref = ref R(t) (t) = ref (t) , since ref"
        },
        {
            "title": "U ref",
            "content": "B = IT r. Similarly, for the second problem in Eq. (14): Q(t) = ref (t) A.2 Alignment Error Quantification Rmr and ref Lemma. Let (t) = rank([B(1), . . . , B(T )]) m, and let R(t) minimizing the error of the least-square problem. Then, the optimal alignment error is given by: RmT be matrices with orthonormal columns where (t) RT rr be the optimal solution = ref εU = (cid:13) (cid:13)U ref (cid:13) R(t) (t) (cid:13) 2 (cid:13) (cid:13) = (cid:13) (cid:13) (t) (cid:13) (cid:13)"
        },
        {
            "title": "U ref\nB",
            "content": "(cid:13) 2 (cid:13) (cid:13) (cid:13) . (16) Proof. To derive the alignment error, we simplify the notation by temporarily omitting the dependency on the model index t. Substituting the definition RB = ref UB from Eq. (15), we can write: εU = ref ref (cid:18)(cid:104) UB UB2 ref Im)UB2 = (U ref (cid:105) (cid:104) (U ref ref Im)UB (U ref ref Im)UB (cid:105)(cid:19) = tr (cid:16) (cid:16) (cid:16) (cid:16) = tr = tr = tr = tr (U ref ref B (U ref ref (U ref ref Im)2UB (cid:17)"
        },
        {
            "title": "U ref",
            "content": "B ref 2U ref ref (cid:17) + Im)UB (cid:17) 2U ref ref (cid:17) )UB = (Im ref (cid:17) ref (cid:16) (cid:16) UB tr UB = tr = (cid:13) (cid:13)U ref (cid:13) 2 , (cid:13) ref ref (cid:17) UB (by linearity of trace) + Im)UB (by using ref"
        },
        {
            "title": "U ref",
            "content": "B = I) where tr(U 2 ref UB) = UB2 ref by the cyclic property of the trace and definition of the Frobenius norm. = r, since UB has orthonormal columns, and tr(U ref UB) = A.3 Optimal Reference Bases Lemma. solution to the quadratic program: (cid:13) (cid:13) (t) (cid:13) (cid:13) (cid:13) 2 (cid:13) (cid:13) (cid:13) max (cid:18) = max tr U (t) (t) (cid:19) , = (cid:8)U RmT (cid:12) (cid:12) = IT (cid:9) , is given by any orthonormal basis whose columns include the top eigenvectors corresponding to nonzero eigenvalues of B(t)B(t) Rmm or, equivalently, by the top left singular vectors of B(t). At the optimum, the objective achieves the maximum value of r, yielding zero alignment error in εU as defined in Eq. (16). Proof. The proof proceeds in two steps. First, we show that any orthonormal basis containing the top eigenvectors of (t) solves the optimization problem. Second, we establish that the eigenvectors of (t) (t) are the same as those of B(t)B(t). U (t) 16 (18) (19) (20) (21) Step 1: Solving the constrained optimization. By leveraging the method of Lagrange multipliers, we write the augmented objective function: L(U, Λ) = tr(U (t) (t) ) tr (cid:0)Λ(U IT r)(cid:1) , (17) where Λ RT rT is matrix of Lagrange multipliers. Taking gradients with respect to and Λ, we obtain: L(U, Λ) = tr(U (t) (t) ) tr(Λ(U IT r)) = 2U (t) (t) 2U Λ ΛL(U, Λ) = Λ tr(Λ(U IT r)) = IT r. Setting the gradients to zero gives the two necessary optimality conditions: (t) (t) = UΛ, = IT r. The second condition, Eq. (21), holds by construction: we explicitly choose RmT to be an orthonormal matrix. Specifically, we define = [v1, . . . , vr, p1, . . . , p(T 1)r], where {vi}r i=1 are orthonormal eigenvectors of (t) associated with its nonzero eigenvalues λ1, . . . , λr, and {pj}(T 1)r j=1 Next, to verify the first condition reported in Eq. (20), we define the diagonal matrix Λ = diag(λ1, . . . , λr, 0, . . . , 0) RT rT r, where the trailing zeros correspond to the eigenvalues associated with the orthogonal complement. Since each vi is an eigenvector of (t) with eigenvalue λi, and each pj lies in the nullspace of that matrix, we have: are additional orthonormal vectors chosen to complete the basis. (t) (t) B (t) (t) vi = λivi for = 1, . . . , r, and (t) (t) pj = for = 1, . . . , (T 1) r. Therefore: (t) (t) = [λ1v1, . . . , λrvr, 0, . . . , 0] = UΛ, which confirms that the first-order condition in Eq. (20) is satisfied. Next, we substitute this result into the original expression to obtain the optimal value: = tr(U (t) (t) U) = tr(U UΛ) = tr(Λ) = (cid:88) i=1 λi = tr(U (t) (t) ) = r, proving that the maximum value of the quadratic problem is r, and the corresponding alignment error εU for is zero. Step 2: Equivalence of eigenspaces. Now we show that, given the matrix B(t) Rnr from LoRA-based adaptation, if is an eigenvector of B(t)B(t), then is also, by construction, an Σ(t)V (t) eigenvector of (t) (t) , where B(t) = (t) is an eigenvector of B(t)B(t) = B(t)B(t)v = λv : Σ2(t) = (t) (t) = (B(t)B(t))U (t) Σ2(t) (t) = (t) = λB(t)B(t)v. = λv Σ2(t) (t) = (B(t)B(t))λv From the second and fourth rows, we obtain: λB(t)B(t)v = λv (22) 17 If λ > 0, we obtain that is an eigenvector of B(t)B(t) and its corresponding eigenvalue is = 1. If λ = 0, then we have: is an eigenvector of B(t)B(t), λ = 0 = B(t)B(t)v = 0 (t) Σ2(t) = (t) = vU (t) Σ2(t) = 0 (t) = Since the matrix has rank r, it has exactly strictly positive singular values, while all other singular values beyond rank are zero. Thus, the matrix Σ2(t) is positive definite. Hence, it must be: vU (t) Σ2(t) = 0 = (t) (t) = 0 = (t) (t) = 0, (23) which confirms that if λ = 0, then is an eigenvector of (t) (t) with eigenvalue 0. Generalization to Multiple Tasks. This result generalizes directly to the multi-task setting, as defined in the main paper, by applying it to the matrix RmT obtained by horizontally stacking the LoRA updates B(t) from all tasks . Then the optimal reference basis = ref (as done in our approach) is given by the left singular vectors of B, obtained via SVD. This matrix satisfies both orthonormality and the optimality conditions derived above. Defining Λ = diag(λ1, . . . , λT r), where λi are the eigenvalues of BB, guarantees perfect reconstruction and zero alignment error for all tasks. A.4 Generalization Beyond the m, Assumption The derivations in Secs. A.1 to A.3 assumed that the total LoRA rank is less than both and n. We now show that this assumption is not necessary, and that the reconstruction error remains zero even when > or > n. Intrinsic rank. When > (for B) or > (for A), stacking the LoRA matrices still yields reference bases with intrinsic dimensions: dU = rank([B(1), . . . , B(T )]) m, dV = rank([A(1), . . . , A(T )]) n, since the number of linearly independent directions cannot exceed the number of rows or columns RnT with truncated We can therefore replace the reference bases ref orthonormal bases: RmT and ref whose columns span the full LoRA update space. RmdU , ref RndV , ref Least-Squares Solution. Rewriting the least-squares problem (Eq. (14)) in terms of the truncated ref gives: R(t) = arg min RRdU U ref (t) 2 . Following the same derivation as in Sec. A.1, the optimal solution is R(t) = (U ref )U (t) , with an analogous expression for Q(t) . Alignment Error. Substituting this solution into the error expression of Sec. A.2 shows that the optimal alignment error remains εU = (U (t) )U ref 2 , which achieves zero when ref extend unchanged to the case > m, n. spans the column space of all B(t). Hence, the theoretical guarantees"
        },
        {
            "title": "B Computational Complexity Analysis",
            "content": "Iso-C Complexity. To assess the time complexity of our approach, we begin by analyzing that of Iso-C [28], to establish baseline for comparison. For each layer, the Iso-C procedure can be broken down into the following steps: LoRA full space: Compute (t) = B(t)A(t) for = 1, . . . , , given the matrices B(t) and A(t). The resulting complexity is O(T m). Summation: Applying task arithmetic in the full space, TA = (cid:80)T (t), involves cost of O(T m). SVD computation: Computing the decomposition TA = ΣV for an matrix has complexity of O(m2 + n3) [40]. Isotropization: The final step, Iso-C = ΣavgV , is dominated by O(m2 n). Overall, the total cost of Iso-C is dominated by O(T + m2 + n3). Assuming that = n, then the time complexity of Iso-C is approximately cubic: O(n3 + n2) with respect to the number of features. KnOTS Complexity. Secondly, we analyze the computational cost of the KnOTS method [42]: LoRA full space: As in Iso-C, this step has complexity O(T m). Concatenation: Stacking all weight matrices = (cid:2)W (1), . . . , (T )(cid:3) as block columns of global matrix has time complexity of O(T m). SVD computation: This is performed on matrix of size m(nT ), resulting in complexity of O(n2 2 + m3), by making use of the transpose trick3. Merge: Assuming simple task arithmetic is performed in the space, blocks of columns each are summed, yielding complexity of O(T 2 n) to compute merge. Reconstruction: The final step KNOTS = ΣV merge has complexity of O(m + n). Overall, the total cost of KNOTS is dominated by O(m3 + n(2r + + + + r)). Assuming = n, the time complexity simplifies to O(n3T 2). Compared to Iso-C, the time complexity of KNOTS remains cubic with respect to the number of features. However, it includes an additional 2 factor that scales quadratically with the number of tasks being merged. TSV Complexity. Then we analyze the cost of TSV [12]: LoRA full space: As previously, this step has complexity O(T m). SVD Computation: In this step SVD is performed on matrices of size resulting in complexity of O(T (m2 + n3)). Concatenation: Stacking the first components of left and right singular vectors for all tasks results in O(T k(n + m)). Global SVD Computation: The SVD performed on the stacked matrices requires O(2 (m2 + n3)). Obtaining orthogonal matrices: This step requires O(2 m2 n). Merge: The final merge has complexity of O(m + n). The overall cost of TSV is thus O(T rmn+T rn+T m2n+T n3+T km+T kn+m2n+n3). Assuming that = and T, r, n, the computational cost is dominated by O(T n3). Core Space Complexity. Finally, we analyze the cost of our approach in Core Space. 3SVD(P ) = Σ = (U Σ ) = ΣU of operations. We will apply the transpose trick throughout. , thus, if n, this will reduce the number 19 Stacking A(t) and B(t): Stacking two sequences of matrices one with each matrix of shape and the other with each matrix of shape results in cost of O(T r(n + m)). SVD computation: The stacked global matrix has shape (T r) n; hence, the cost of its SVD is O(n2 (T r) + (T r)3), by using the transpose trick. The stacked matrix has shape (T r), with cost of O(m2 (T r) + (T r)3). The overall cost of this step is O((m2 + n2) (T r) + 2 (T r)3). Low-rank loop: In the optimized version of the low-rank loop, we only compute the matrix multiplication to obtain the aligned matrices. In this case the total cost is O(T (T mr2 + r2n + 2r3)) (using the optimal matrix multiplication order (U ref )). Assuming that T, << n, m, the cost is dominated by O(T 2r2(m + n)). B)(AV ref Merge: Assuming simple task arithmetic is performed in the aligned core space, the cost is O(T 3 r2). Isotropization: Optionally, Iso-C can be applied in the core space; since the core space is defined within square matrix of dimension r, this step adds an additional time complexity of O(T 3r3). Reconstruction: The final step requires O(m 2 r2 + n). To sum up, our approach involves: O( r(n + m) (cid:125) (cid:123)(cid:122) Stacking (cid:124) + r(m2 + n2) + 2(T r)3 (cid:123)(cid:122) (cid:125) SVD refs. (cid:124) + (cid:124) + (T 2r2(m + n)) (cid:125) (cid:123)(cid:122) Low-rank loop. + r(T 2r + rm + mn) (cid:125) (cid:123)(cid:122) Merge & Rec. O(T r(m + + 2m2 + 2n2 + mn + r2) + 2r2(2m + + ) + 3r3) ) = (cid:124) If we assume that = n, the total time complexity simplifies to: O(T r(2n + 5n2 + r2) + 2r2(3n + ) + 3r3), which, if we assume T, n, is dominated by: O(T rn2) (24) (25)"
        },
        {
            "title": "C Additional Analysis",
            "content": "C.1 High subspace alignment leads to lower interference In this Section, we experimentally show that merging in Core Space reduces interference when merging models. We follow [53, 28] and measure the interference as the L1 distance between the final embeddings of task-specific models and the merged one. We compare the interference when merging with TSV + Iso-C in Full Space versus Core Space. For each dataset, we collect the activations from the final layer (i.e., the projection to common vision-language space) of both the task-specific model and the merged model. We present the average distance across all the samples in the test set. We observe lower interference when merging in Core Space, highlighting its effectiveness. Note that Full Space merging, which causes higher interference, also exhibits higher SAR in Sec. 5.2. C.2 Rank of the merged update matrices Consider = 8 ViT-B/32 models fine-tuned with LoRA of rank = 16. The merged update matrices resulting from different merging methods and spaces can have different effective ranks rW . Table 6 reports the average rank of across all layers. In most cases, the target rank of is equal to = 128. The only exception is merging with TIES in Full space, where for weight matrices Rmn the effective rank approaches the dimensionality of the matrices = min(m, n) = 768. This phenomenon arises because TIES performs trimming on the reconstructed weight matrices Wt = BA, which destroys the low-rank structure. In contrast, both Core and KnOTS operate directly in constrained r-dimensional space, ensuring that the merged maintains the intended rank. Figure 6: Mean L1 distance between the final embeddings of task-specific models and the merged one using TSV + Iso in Full and Core space. We used ViT-B/16 model. Table 6: Average rank rW of merged update matrices obtained by merging 8 ViT-B/32 LoRA models with = 16 (so = 128)."
        },
        {
            "title": "Merging Space",
            "content": "TA"
        },
        {
            "title": "Full\nKnOTS\nCore",
            "content": "128.00 128.00 128.00 128.00 128.00 128.00 766.25 128.00 128."
        },
        {
            "title": "Licenses of Used Datasets and Models",
            "content": "In our research, we employed publicly available datasets and models, each governed by specific licenses. Below, we outline the sources and associated licenses for each: KnOTS LoRA Checkpoints [42]: The KnOTS repository, which provides LoRA-adapted model checkpoints and training scripts, is licensed under the MIT License. This permissive license allows for reuse and modification with proper attribution. Cars196 [22]: The Cars196 dataset is available for non-commercial research purposes. Specific licensing details are not explicitly provided. Describable Textures Dataset (DTD) [7]: The DTD is made available to the computer vision community for research purposes. The dataset is licensed under the Creative Commons Attribution 4.0 License (CC BY 4.0). EuroSAT [14]: The EuroSAT dataset is licensed under the MIT License. German Traffic Sign Recognition Benchmark (GTSRB) [41]: The GTSRB dataset is licensed under the Creative Commons Zero (CC0) Public Domain Dedication. MNIST [23]: The MNIST dataset is publicly available for research purposes. Specific licensing details are not explicitly provided; users are advised to consult the datasets source for more information. NWPU-RESISC45 [5]: The NWPU-RESISC45 dataset is licensed under the Creative Commons Attribution 4.0 License (CC BY 4.0). 21 Figure 7: The proposed Core Space Merging with the optimized algorithm. First, we perform SVD on concatenation of low-dimensional A(t) and B(t) matrices to obtain reference bases. Afterwards, we directly compute the aligned core matrices. Finally, we perform merging in the Core Space and reconstruct to obtain the final . SUN397 [49]: The SUN397 dataset is available for research purposes only. Specific licensing details are not explicitly provided; users are advised to consult the datasets source for more information. Street View House Numbers (SVHN) [33]: The SVHN dataset is available for noncommercial use only. Stanford Natural Language Inference (SNLI) [3]: The SNLI dataset is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0). Multi-Genre Natural Language Inference (MNLI) [47]: The MNLI dataset is released under the Open American National Corpus (OANC) license, which permits free use, modification, and sharing under permissive terms. Sentences Involving Compositional Knowledge (SICK) [30]: The SICK dataset is distributed under Creative Commons Attribution-NonCommercial-ShareAlike license. Question Natural Language Inference (QNLI) [45]: The QNLI dataset is part of the GLUE benchmark. Specific licensing details are not explicitly provided; users are advised to consult the datasets source for more information. Recognizing Textual Entailment (RTE) [45]: The RTE dataset is part of the GLUE benchmark. Specific licensing details are not explicitly provided; users are advised to consult the datasets source for more information. SciTail [20]: The SciTail dataset is licensed under the Apache License 2.0. D.1 Optimized Pipeline We report in Fig. 7 the illustration of the Core Space approach with the optimized pipeline presented in Sec. 4.2. D.2 Experimental Environment The language experiments with Llama 3 8B were performed with single 48G NVIDIA L40S. In contrast, the more affordable vision experiments were executed using single 16G NVIDIA RTX 4080. To keep things fair, the reported times for the language experiments all refer to experiments performed on the same machine. Our implementation builds directly on the KnOTS codebase [42] and uses the exact LoRA checkpoints they released. For full details on the original training and adaptation procedures, please refer to [42]. 22 D.3 Hyperparameter Search To find optimal hyperparameters for each model, we adopt the widely used validation holdout strategy [42, 28, 12, 50]. Specifically, we perform linear search for hyperparameters on the validation set, starting from defined minimum value and incrementally increasing it until performance declines, indicating the optimal range. The identified optimal hyperparameters are then applied to the test set. We use the following search settings: Scaling factor α starts at 0.1, increasing in increments of 0.1. This is used for every approach. The top-K parameter for TIES and DARE-TIES begins at 10 and increases in increments of 10. The pruning factor for DARE-TIES starts at 0.1 and increases in increments of 0.1. For CART, the pruning rank is searched over the set {0.04, 0.08, 0.16, 0.32}, following the methodology of the original paper. Additionally, CART includes an extra scaling factor λ in its merging formulation. Specifically, the merged weights are computed as Wmerged = W0 + α(θavg + λ (cid:80)T t=1 τt), where θavg denotes the average of the updates and τt represents the centered task vector for task t. For further details, we refer the reader to [6]. In Tab. 7, we report the parameters used for the various merging methods in Core Space across all backbones. Note that we search for the optimal parameters for all methods across all spaces to maintain fairness. For the natural-language inference experiments, we omit CART as its hyperparameter tuning proved prohibitively expensive and exclude +Iso-C variants, as they consistently degraded performance. Table 7: Optimal hyperparameters for Core-Space merging on each backbone and merging strategy, including +Iso-C variants."
        },
        {
            "title": "Backbone Merging Method",
            "content": "TIES-Core TIES-Core+Iso-C DARE-TIES-Core DARE-TIES-Core+Iso-C TSV-Core TSV-Core+Iso-C CART-Core CART-Core+Iso-C Iso-C-Core TIES-Core TIES-Core+Iso-C DARE-TIES-Core DARE-TIES-Core+Iso-C TSV-Core TSV-Core+Iso-C CART-Core CART-Core+Iso-C Iso-C-Core TIES-Core DARE-TIES-Core TSV-Core Iso-C-Core ViT-B/32 ViT-L/14 Llama 3 8B α 0.6 2.0 0.6 2.0 0.2 0.9 0.4 0.7 0.9 0.4 2.4 0.4 2.4 0.2 0.9 0.1 1.0 0.9 1.1 1.1 0.5 2.8 Top-K Pruning CART rank 10 30 10 30 - - - - - 10 20 10 20 - - - - - 80 80 - - - - 0.1 0.1 - - - - - - - 0.1 0.2 - - - - - - 0.1 - - - - - - - - 0.32 0.04 - - - - - - - 0.04 0.08 - - - - - λ - - - - - - 5.8 2.6 - - - - - - - 6.5 2.0 - - - - - D.4 Code Availability and Pseudocode Our Core Space merging implementation is released at https://github.com/apanariello4/ core-space-merging. 23 Listing 1 Basic PyTorch pseudocode for model merging in Core Space. from torch.linalg import svd A_list, B_list = ..., ... r, = A_list[0].shape m, _ = B_list[0].shape A_stack = torch.cat(A_list, dim=0) B_stack = torch.cat(B_list, dim=1) # (T*r, n) # (m, T*r) # Calculate reference bases Vh_A_ref = svd(A_stack, full_matrices=False)[2] # (T*r, n) U_B_ref = svd(B_stack, full_matrices=False)[0] # (m, T*r) M_list = [] for A, in zip(A_list, B_list): # Theory Version # U_A, S_A, Vh_A = svd(A, full_matrices=False) # (r, r), (r,), (r, n) # U_B, S_B, Vh_B = svd(B, full_matrices=False) # (m, r), (r,), (r, r) # = torch.diag(S_B) @ (Vh_B @ U_A) @ torch.diag(S_A) # (r, r) # Calculate alignment matrices # Q_A = Vh_A @ Vh_A_ref.T # R_B = U_B_ref.T @ U_B # Align the core matrix # M_aligned = R_B @ @ Q_A # (T*r, T*r) # Optimized Version M_aligned = U_B_ref.T @ @ @ Vh_A_ref.T M_list.append(M_aligned) if merge_strategy == 'TA': M_merged = torch.stack(M_list).sum(dim=0) elif merge_strategy == 'ties': M_merged = ties_merging(M_list) elif merge_strategy == '...': M_merged = ... # Reconstruct delta delta_W = U_B_ref @ M_merged @ Vh_A_ref 1 2 3 4 5 7 8 9 10 11 13 14 15 16 17 19 20 21 22 23 25 26 27 28 29 31 32 33 34 35 37 38 39 40 41 Listing 1 gives PyTorch-style pseudocode illustrating how to apply any merging strategy within the Core Space framework. 24 Table 8: Accuracies of merged models normalized against fine-tuned models on the vision datasets with ViT-L/14. Method Space Cars DTD EuroSAT GTSRB MNIST RESISC SUN SVHN Avg ( Acc) Abs. Accuracy TA TIES DARE-TIES TSV CART TIES +Iso-C DARE-TIES +Iso-C TSV +Iso-C CART +Iso-C Iso-C Full Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core 99.70 70. 80.01 79.50 79.65 82.47 81.94 79.70 80.41 82.97 82.38 80.17 82.10 91.88 79.65 86. 84.11 86.44 91.13 83.25 87.32 90.84 86.44 88.47 91.54 88.78 88.72 92.08 86.83 88.27 91.23 78.28 80.26 80. 78.82 79.65 80.03 80.11 79.95 79.80 88.53 79.73 86.33 83.07 88.23 90.58 81.78 87.78 91.12 89.07 90.58 91. 90.43 89.60 92.48 86.94 89.75 90.28 98.50 65.59 64.43 64.65 65.78 64.99 64.84 65. 66.12 66.94 67.05 75.51 64.39 72.39 74.94 78.74 79.53 73.03 74.12 79.15 82.49 77.69 80.24 78.59 80.77 81. 80.65 78.36 80.28 97.20 59.98 61.10 68.85 68.94 60.63 62.95 68.34 68.18 60.24 66. 80.88 58.28 82.82 76.66 78.94 87.67 77.25 81.50 88.14 84.68 83.91 86.79 87.04 79.84 88.96 77.99 85.41 85. 99.50 82.20 83.82 88.48 87.44 83.92 85.33 87.75 85.46 83.76 87.50 68.99 80.42 91. 92.88 94.27 86.47 86.81 94.21 90.19 90.76 87.48 87.39 91.96 87.18 89.80 92.09 91.65 89.71 95. 79.55 79.42 82.37 81.85 79.32 79.73 82.48 83.02 79.35 82.32 92.77 78.52 85.93 87.88 87.94 90. 86.78 89.48 90.73 90.03 90.00 91.51 90.96 89.50 91.97 87.88 90.93 90.96 79.60 86. 87.45 88.18 88.48 87.07 87.55 88.80 87.89 86.85 87.71 88.17 86.52 88.46 88.58 88.62 90.05 88.24 88.88 89. 87.99 88.76 89.59 89.32 88.38 89.81 88.50 88.85 89.58 97.7 64.74 69.94 76.63 73. 69.84 71.00 75.88 70.76 65.59 71.89 64.81 63.24 72.67 74.61 72.24 72.28 74.44 70.87 72.05 67.98 67.49 71. 75.18 68.07 73.56 68.69 70.97 70.66 - 74.79 (+0.00) 75.51 (+0.00) 78.99 (+3.48) 78.53 (+3.02) 75.53 (+0.00) 76.43 (+0.90) 78.99 (+3.46) 77.99 (+0.00) 75.36 (-2.63) 78.16 (+0.17) 81.44 (+0.00) 73.84 (-7.60) 83.21 (+1.77) 82.84 (+0.00) 84.43 (+1.59) 86.02 (+3.18) 81.45 (+0.00) 84.27 (+2.82) 86.52 (+5.07) 84.93 (+0.00) 84.30 (-0.63) 86.21 (+1.28) 86.53 (+0.00) 84.01 (-2.52) 87.49 (+0.96) 83.70 (+0.00) 85.52 (+1.82) 86.00 (+2.30)"
        },
        {
            "title": "E Additional Results",
            "content": "E.1 Per-task evaluation in vision setting for ViT-L/14 We provide in Tab. 8 per-task results vision model merging using the ViT-L/14 backbone. Similarly to what we observed for other backbones, in this case, performing the merging in Core Space yields consistent improvements across all methods, resulting in new state-of-the-art results. E.2 Experiments with Heterogeneous Ranks In the main paper, we discussed that Core Space merging naturally extends to the heterogeneous rank setting (Tab. 9). Here we provide additional details. When tasks are fine-tuned with different LoRA ranks, we horizontally and vertically stack the B(t) and A(t) matrices across tasks as usual. The resulting aggregate matrices have rank equal to the dimension of the union of all task subspaces. Performing SVD on these aggregates yields orthonormal reference bases ref that span the combined subspaces, regardless of how individual task ranks vary. and ref Projection into these reference bases followed by task-specific alignment (see Sec. A.1) guarantees that reconstruction is lossless. This explains why the results in Tab. 9 show that heterogeneous ranks incur no additional degradation in performance under our framework, whereas baselines that lack such alignment struggle with mismatched subspace dimensions. E.3 Extension to VeRA We also evaluated the applicability of Core Space merging beyond LoRA, specifically on VeRA [21] (Tab. 10). In VeRA, the decomposition = ΛbBΛdA differs structurally from LoRA since and are fixed random matrices, and only the scaling vectors Λb, Λd are trainable. 25 Table 9: Normalized accuracies of merged models on the vision tasks with ViT-B/32 with LoRA mixed ranks 16 (Cars, EuroSAT, MNIST, SVHN) and 64 (DTD, GTSRB, RESISC, SUN397). Method Abs. accuracy TA TIES DARE-TIES TSV TIES +Iso-C DARE-TIES +Iso-C TSV +Iso-C Iso-C Space - Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Cars DTD EuroSAT GTSRB MNIST RESISC SUN397 74. 98.00 99.00 68.03 93.85 99.30 70. 81.97 65.83 80.94 82.70 79.74 80.81 82.98 80.98 80.98 82.51 80.46 78.94 81.42 79. 80.33 82.11 78.75 76.46 78.88 79.30 78.48 78.92 81.17 64.74 67.08 67.71 65.60 67.08 68.80 67.94 65.91 69. 69.90 68.49 75.84 70.76 67.71 75.37 73.65 72.79 78.26 75.61 76.31 79.20 47.06 42.01 49.01 41. 41.11 45.57 44.26 50.95 43.66 51.44 54.02 60.19 58.66 60.98 58.92 58.47 61.02 66.59 63.94 63.37 56.19 59. 51.66 53.91 55.00 71.86 54.89 56.34 68.07 59.10 48.98 58.33 53.13 45.09 64.09 51.48 41.44 64. 56.41 54.61 58.11 63.05 63.50 70.86 57.18 55.41 57.39 69.59 56.14 62.34 64.43 64.65 60.52 61. 66.83 56.70 80.14 61.58 57.92 80.83 69.02 78.83 77.28 77.14 75.11 81.90 72.91 72.16 73.74 75. 72.45 75.65 74.45 75.82 71.47 76.70 75.11 70.83 76.76 74.16 69.69 77.00 74.04 72.21 74.40 77.10 77.08 78. 89.75 89.76 90.14 91.43 89.74 90.06 91.44 90.76 89.22 89.37 90.64 90.43 90.52 90.41 90.37 90. 90.01 89.03 89.85 90.22 90.53 90.81 SVHN Avg ( Acc) 96.20 - 48.37 49.09 45.97 67. 49.70 53.53 62.99 53.37 51.29 52.43 46.63 40.11 55.13 47.26 38.79 55.53 49.12 50.28 50.97 51.50 52.44 56. 64.34 (+0.00) 63.50 (+0.00) 65.13 (+1.63) 70.59 (+7.09) 63.81 (+0.00) 66.69 (+2.88) 69.43 (+5.62) 67.95 (+0.00) 64.20 (-3.75) 67.41 (-0.54) 66.90 (+0.00) 64.16 (-2.74) 72.56 (+5.66) 67.12 (+0.00) 63.37 (-3.75) 72.68 (+5.56) 68.72 (+0.00) 70.40 (+1.68) 71.51 (+2.79) 72.06 (+0.00) 71.26 (-0.80) 74.90 (+2.84) Table 10: Normalized accuracies of merged models on the vision tasks with ViT-B/32 with VeRA rank 16. Method Space Cars DTD EuroSAT GTSRB MNIST RESISC SUN SVHN Avg ( Acc) Abs. Accuracy TA TIES DARE-TIES TSV TIES +Iso-C DARE-TIES +Iso-C TSV +Iso-C Iso-C - Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core Full KnOTS Core"
        },
        {
            "title": "Full\nKnOTS\nCore",
            "content": "62.79 57.07 95.78 77.73 95.53 96.64 97.06 94.44 96.52 97. 93.35 92.73 93.75 94.79 94.81 95.43 93.82 94.88 94.14 93.37 92.58 93.57 93.50 94.59 91.77 77.73 77.91 77. 77.73 77.54 77.82 77.54 78.19 76.51 77.26 77.26 77.63 76.98 77.17 77.26 76.70 75.30 76.89 77.26 77.35 75. 96.55 47.26 44.76 50.13 44.30 47.26 52.13 44.27 45.11 54.85 60.15 46.84 47.33 50. 46.34 47.37 53.01 48.29 52.51 63.33 52.05 47.76 63.60 90.85 39.77 39.07 39.61 41. 42.09 40.88 42.02 37.44 38.77 37.94 36.11 35.49 37.14 36.80 35.52 37.45 35.92 36.47 39.27 37.42 35.52 38. 98.60 49.10 48.25 50.46 50.35 49.82 50.46 50.41 53.50 56.20 54.32 48.78 48.67 50. 49.47 48.64 52.90 51.47 58.16 57.53 49.49 48.73 58.53 88.50 70.61 69.92 70.52 71. 69.37 70.25 71.75 69.40 69.10 68.38 68.19 68.10 69.06 68.26 68.13 68.13 68.11 67.36 68.63 68.06 68.27 67. 62.79 100.74 100.58 100.85 100.44 100.05 100.06 100.48 99.70 98.82 98.77 100.81 100.67 100. 100.44 100.66 100.09 100.30 99.83 99.18 100.62 100.52 97.67 93.10 37.29 35.62 35.93 38. 38.28 37.24 38.97 33.85 34.02 34.63 34.03 33.74 33.77 34.69 33.75 31.80 34.35 35.43 34.07 34.22 33.68 36. - 64.78 (+0.00) 63.93 (+0.00) 65.26 (+1.33) 65.31 (+1.39) 64.88 (+0.00) 65.63 (+0.75) 65.35 (+0.47) 63.74 (+0.00) 65.33 (+1.59) 65.56 (+1.82) 63.35 (+0.00) 63.26 (-0.09) 64.38 (+1,03) 63.35 (+0.00) 63.27 (-0.08) 64.35 (+1.00) 63.56 (+0.00) 64.71 (+1.15) 66.56 (+3.00) 64.08 (+0.00) 63.30 (-0.78) 66.27 (+2.19) To apply our method, we absorb the scaling vectors into the low-rank matrices: = ΛbB, = ΛdA, and then treat ( A, B) as if they were standard LoRA components. Since the subsequent steps (stacking, SVD, projection, and alignment) are agnostic to how and were obtained, the derivations in Sec. apply without modification. The empirical results in Tab. 10 confirm this reasoning: Core Space merging consistently outperforms other approaches even in the VeRA setting, validating that the framework is general to low-rank adaptation methods beyond LoRA."
        }
    ],
    "affiliations": [
        "AImageLab, University of Modena and Reggio Emilia, Italy",
        "Computer Vision Center, Universitat Autònoma de Barcelona, Spain",
        "IDEAS NCBR, Warsaw, Poland",
        "IDEAS Research Institute, Warsaw, Poland",
        "Media Integration and Communication Center (MICC), University of Florence, Italy",
        "Warsaw University of Technology, Poland"
    ]
}