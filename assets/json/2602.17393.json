{
    "paper_title": "Contact-Anchored Proprioceptive Odometry for Quadruped Robots",
    "authors": [
        "Minxing Sun",
        "Yao Mao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\\sim$200\\,m horizontal loop and a $\\sim$15\\,m vertical loop return with 0.1638\\,m and 0.219\\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\\,m and 0.199\\,m. On wheel-legged robot~C, a $\\sim$700\\,m horizontal loop yields 7.68\\,m error and a $\\sim$20\\,m vertical loop yields 0.540\\,m error. Unitree Go2 EDU closes a $\\sim$120\\,m horizontal loop with 2.2138\\,m error and a $\\sim$8\\,m vertical loop with less than 0.1\\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git"
        },
        {
            "title": "Start",
            "content": "Contact-Anchored Proprioceptive Odometry for"
        },
        {
            "title": "Quadruped Robots",
            "content": "Minxing Sun1,2,3, Yao Mao1 6 2 0 2 0 2 ] . [ 2 3 9 3 7 1 . 2 0 6 2 : r Abstract Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as kinematic anchor: joint-torquebased foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce lightweight height clustering and timedecay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot A, 200 horizontal loop and 15 vertical loop return with 0.1638 and 0.219 error, respectively; on wheel-legged robot B, the corresponding errors are 0.2264 and 0.199 m. On wheel-legged robot C, 700 horizontal loop yields 7.68 error and 20 vertical loop yields 0.540 error. Unitree Go2 EDU closes 120 horizontal loop with 2.2138 error and 8 vertical loop with less than 0.1 vertical error. We publicly release the complete implementation (github.com/ShineMinxing/Ros2Go2Estimator.git) and the ROS bags of the Go2 EDU trials, including synchronized video, to enable reproducible evaluation. This research was supported by the China Scholarship Council funding. 1Institute of Optics and Electronics, Chinese Academy of Sciences, Chengdu, China, sunminxing20@mails.ucas.ac.cn, maoyao@ioe.ac.cn 2Institute for Infocomm Research (I2R), Agency for Science, Technology and Research, Singapore. 3Shenzhen Astralldynamics Technology. 2 quadruped robots, proprioceptive odometry, sensor fusion, cubature Kalman estimator Index Terms I. INTRODUCTION Accurate estimation of legged robots pose and velocity is prerequisite for motion planning and stable locomotion control [1], [2]. In many deployed systems, exteroceptive sensors such as depth cameras and LiDAR are coupled with SLAM to provide global state feedback [3][5]. However, these sensors can become unreliable in the presence of challenging illumination, airborne particulates, or vegetation clutter, and their computational and installation requirements may be undesirable for lightweight or cost-sensitive platforms. This motivates proprioceptive state estimation methods that remain effective when no vision or LiDAR feedback is available. Most legged robots provide rich proprioceptive measurements, including an inertial measurement unit (IMU) and motor encoder readings; many platforms additionally provide estimated joint torques or contact-related signals. Early approaches relied heavily on IMU acceleration integration (with frame transformations and additional dynamic cues) [6][8]. In practice, double integration is extremely sensitive to bias, timing mismatch, and discrete sampling noise, leading to rapid drift. To mitigate this, modern estimators incorporate leg kinematics to introduce velocity constraints from stance feet: when foot is stationary relative to the ground, the body velocity can be inferred from the relative footbody motion. key difficulty is determining which legs provide valid constraints, especially under imperfect contact conditions. Probabilistic contact estimation and impact detection have been used to gate these measurements and detect slippage [9]. Building on contact-aware kinematic constraints, invariant EKF formulations have been explored for legged state estimation [10], and learning-based measurement models have further improved contact classification under difficult terrains [11]. Hybrid systems that incorporate cameras can provide stronger observability [12], but they reintroduce the fragility of exteroception that motivates proprioceptive odometry in the first place. Moreover, even when velocity estimation is improved, position drift can still accumulate over time, and foot velocity computed directly from noisy joint velocities may exhibit spikes caused by encoder quantization and numerical differentiation. This work targets robust purely proprioceptive odometry for biped, quadruped, and wheel-legged robots using only IMU and motor measurements. The key idea is to anchor the body state to discrete footfall events: we record the world-frame footfall position at touchdown and treat it as an intermittent constraint during the stance phase. In our implementation, stance selection is enabled by joint-torque based foot wrench estimation, while wheel-legged locomotion is handled by compensating the effective 3 wheel rotation during ground contact. To prevent long-term elevation drift, we introduce lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes within configurable resolution. To address spiky velocity observations from joint encoders, we further employ cubature Kalman filter (CKF) under an inverse-kinematics observation model to estimate and smooth foot-end velocities directly from joint angles and angular velocities. Compared with linear Kalman filtering and EKF-style approximations [13][18] and with alternatives such as invariant EKF and UKF [10], [11], [19][22], CKF provides numerically stable, Jacobianfree nonlinear filtering rule and avoids UKF-style scaling parameters, which is convenient for inversekinematics measurements [23][25]. Finally, we correct long-horizon yaw drift by enforcing multi-contact geometric consistency between body-frame kinematics and world-frame contact records, which also provides fallback yaw reference when IMU yaw constraints are degraded or disabled. Contributions. This paper makes the following contributions: Unified kinematics-based proprioceptive odometry across morphologies. We formulate contactanchored odometry framework that relies only on IMU and motor measurements (joint angles, velocities, and estimated torques). The framework is morphology-agnostic: at each time step, it forms constraints only from the currently contacting end-effectors (feet or wheels), so the same estimator applies to bipeds, quadrupeds, and wheel-legged robots with different numbers of contacts over time. In our implementation, stance is selected via joint-torquebased foot wrench estimation, and wheellegged platforms are supported through effective wheel rotation compensation during contact. Footfall recording with height correction for accurate elevation. We record world-frame contact (footfall) positions at touchdown and use them as intermittent constraints during stance to suppress longhorizon drift. To prevent elevation drift over extended traversal, we propose lightweight support-plane height clustering with time-decayed confidence that snaps newly recorded footfall heights to previously observed planes at configurable resolution. Inverse-kinematics nonlinear filtering for encoder-induced velocity spikes. To mitigate spiky foot velocity observations caused by encoder quantization and discrete differentiation, we introduce an inverse-kinematics CKF (IKVel-CKF) that estimates foot-end velocities directly from joint angles and angular velocities under nonlinear observation model, and integrates the filtered velocities into the fusion estimator. Yaw drift suppression with kinematics-only fallback. We reduce long-horizon yaw drift by enforcing multi-contact geometric consistency between body-frame kinematics and world-frame contact records. In particular, during prolonged standing with stable multi-contact, this constraint effectively arrests IMU yaw drift by continuously re-anchoring heading to the contact geometry. When IMU yaw constraints are disabled, the estimator still provides kinematics-derived heading reference; empirically, the accumulated error is about 10 per closed turn for short-step gaits and about 30 per closed turn for long-step gaits, indicating residual sensitivity to unmodeled attitude coupling and contact compliance. Real-robot evaluation on multiple platforms and public artifacts. We evaluate the estimator on four platforms (three Astrall robots and Unitree Go2 EDU) using long closed-loop trajectories with both horizontal and vertical motion. We publicly release the complete implementation and representative ROS bags (including synchronized video) for the Go2 EDU trials to enable reproducible evaluation. The remainder of this paper is organized as follows: Section II presents the contact-anchored proprioceptive odometry formulation, including stance selection, footfall recording, and the support-plane height correction strategy. Section III discusses end-effector radius modeling and wheel contact compensation, and analyzes the approximation error introduced when modeling rounded point-foot as an effective shank extension. Section IV introduces the IKVel-CKF used to suppress encoder-induced velocity spikes and to provide smoother hipfoot velocity feedback for fusion. Section presents kinematics-based yaw estimation method based on multi-contact geometric consistency, and discusses its ability to arrest"
        },
        {
            "title": "IMU yaw drift during prolonged standing as well as its graceful degradation when IMU yaw constraints",
            "content": "are unreliable. Section VI reports evaluation results in both physics simulation and real-robot experiments, covering flat-ground and stair scenarios as well as long closed-loop trajectories on multiple platforms. Section VII concludes the paper and outlines future work. II. CONTACT-ANCHORED PROPRIOCEPTIVE ODOMETRY This section presents the contact-anchored proprioceptive odometry implemented in our system, including stance selection, footfall recording, and support-plane height correction. Wheel-specific contact propagation is addressed separately in Section III. A. Inputs, Frames, and Notation We consider world frame FW and body frame FB attached to the robot trunk. At time tk, the trunk pose is represented by position pW B,k R3 and rotation RW B,k SO(3). For each leg i, motor measurements provide joint angles qi,k, joint angular velocities qi,k, and estimated joint torques τ i,k. Robot geometry provides the hip mounting position pB hip,i and link parameters. We use right-handed frames with forward, left, and upward. The estimated end-effector force is the wrench-equivalent force consistent with the virtual-work mapping τ = Jf (Appendix A). Under our sign convention, supporting contact produces negative vertical component. 5 We denote the set of contacting end-effectors (feet or wheels) at time tk as Ck. For each leg, forward kinematics yields the end-effector position and velocity relative to the hip in FB, and wrench estimation yields contact-normal force used for stance gating. The explicit kinematic and wrench formulas matching our implementation are given in Appendix A. B. Stance Selection via Torque-Based Wrench Estimation To enable contact-anchored constraints, we must select legs that are in reliable ground contact. In our implementation, the end-effector force is estimated from joint torques and the geometric Jacobian (Appendix A). Let i,k be the estimated end-effector force in FB and i,k = RW B,kf i,k in FW . We declare leg as contacting when the vertical component satisfies Ck i,k,z fth, where fth is configurable threshold under our sign convention."
        },
        {
            "title": "A touchdown event is detected by",
            "content": "Touchdown(i, k) (cid:0)i Ck (cid:1) (cid:0)i / Ck1 (cid:1), which triggers footfall recording and height correction (Section II-D). C. Footfall Recording and Contact-Anchored Body Observations (1) (2) Fig. 1. Footfall records provide continuous body position Fig. 2. Encoder-derived joint rates provide continuous body feedback. velocity feedback. Given leg i, forward kinematics provides the hip-to-end-effector vector in the body frame, rB i,k, and its velocity rB i,k (Appendix A). The body-frame end-effector position is then and its world-frame counterpart is ee,i,k = pB pB hip,i + rB i,k, ee,i,k = pW B,k + RW B,kpB pW ee,i,k. (3) (4) a) Footfall record.: When Touchdown(i, k) is true, we initialize (or reset) the footfall record pW cW ee,i,k. 6 (5) Fig. 1 illustrates the anchoring intuition: at touchdown we store the world-frame contact point cW ; during stance the contact is treated as stationary, so the trunk position is obtained by subtracting the current body-frame kinematics (rotated into FW ) from the stored footfall record. b) Contact-anchored position observation.: During stance (i Ck), the footfall point is assumed stationary in FW . Thus the trunk position implied by leg is pW B,k(i) = cW RW B,kpB ee,i,k. (6) c) Contact-anchored velocity observation.: During stance, assuming cW = 0, differentiating (4) yields vW B,k(i) = RW B,k (cid:0)ωB,k pB ee,i,k + pB ee,i,k (cid:1) , (7) where ωB,k is the trunk angular velocity measured by the IMU. In practice, vW B,k(i) is formed from encoder-derived joint velocities through forward kinematics (Appendix A), which provides continuous velocity feedback during stance  (Fig. 2)  . Since encoder quantization and discrete differentiation can introduce spikes, Section IV replaces this term with an IKVel-CKF estimate when enabled. pW B,k = 1 Ck (cid:88) iCk pW B,k(i), vW B,k = 1 Ck (cid:88) iCk vW B,k(i). (8) The fused observation (pW B,k, vW B,k) updates the translational state estimator when Ck > 0; otherwise the estimator proceeds by prediction only. D. Support-Plane Height Correction Fig. 3. Footstep tracking correction strategy flowchart. 7 Fig. 4. Correction of footstep position. Directly recorded footfall heights are sensitive to small biases; without correction, vertical drift accumulates over long traversal. We maintain discrete set of support-plane height records = {(hn, wn, tn)}Nh n=1, (9) where hn is the plane height, wn confidence weight, and tn the last update time. Fig. 3 summarizes the touchdown-triggered correction logic. At each touchdown, we (i) prune stale support-plane records, (ii) associate the raw touchdown height to an existing plane if possible, and (iii) either snap-and-refresh the matched plane or create new one. Fig. 4 illustrates typical stair/step scenario where repeated small touchdown biases would otherwise accumulate into elevation drift. Let the raw touchdown height be = cW (3) at time tk. We maintain set of plane records = n=1 and first discard records with tk tn > Tfade. plane is considered match if {(hn, wn, tn)}Nh hn h. If match exists, we compute 0, = hn h/10, z, hn, otherwise, and update its confidence with time decay, (cid:18) wn wn exp (cid:19) tk tn κTfade + 1, tn tk. (10) (11) If no match exists, we create new record (hn, wn, tn) (z, 1, tk). Finally, the corrected value is written back to the footfall record, cW (3) z. This correction is applied only at touchdown and stabilizes longhorizon elevation estimation under repeated height changes  (Fig. 3)  . 8 III. END-EFFECTOR RADIUS MODELING AND WHEEL CONTACT COMPENSATION Contact-anchored proprioceptive odometry is only as accurate as the underlying end-effector contact model. For rounded point feet, the stance contact can roll even without slip; for wheel-legged robots, the contact point propagates through wheel rotation. This section first quantifies the systematic bias introduced when rounded point foot is approximated as rigid shank extension, which motivates the wheel-contact treatment developed in Section III-B. A. Rolling-Contact Bias of Rounded Point Feet Fig. 5. Sagittal-plane model of rounded point foot. O1 is the shankfoot connection. Touchdown and lift-off shank pitch angles are a1 and a2. Ignoring rolling yields the fictitious displacement O1 O3, while hemispherical rolling yields the physical displacement O1 O2. We analyze 2D sagittal-plane (xz) model, where is forward and is upward. The foot is modeled as hemisphere of radius R. Let O1 be the shankfoot connection point at touchdown, and let a1 and a2 denote the shank pitch angles (measured from the +x axis) at touchdown and lift-off, respectively  (Fig. 5)  . We compare two contact models. a) Model (shank-extension approximation).: common point-foot approximation is to treat the end-effector radius as rigid extension of the shank and to assume fixed stance contact point. Let the (fictitious) contact point at touchdown be F0 = O1 + cos a1 sin . (12) If the shank rotates to a2 while keeping F0 fixed, the implied connection point becomes O3 = F0 + cos a2 sin a2 . (13) b) Model (hemispherical rolling contact).: Under no-slip rolling, the touchdown contact is the vertical projection of O1: F1 = O1 + . 0 During stance, the contact point translates along the ground by the arc-length = (a2 a1), so the lift-off contact is F2 = F1 + [s, 0]T , and the corresponding connection point is O2 = F2 + . 0 (14) (15) (16) Fig. 6. Rolling-contact modeling bias for = 0.03 and touchdown pitch a1 = 80, with a2 [60, 140]. The curves plot (red) and (blue) from (18). c) Displacement bias.: We define the modeling error as the difference between the displacement predicted by Model and the physical displacement under Model B: (O3 O1) (O2 O1) = O3 O2 = . (17) z Substituting (12)(16) yields the closed form = R(cos a1 cos a2 (a2 a1)) , = R( sin a1 + sin a2) . (18) The bias scales linearly with and grows with the stance pitch excursion (a2 a1). d) Implication for odometry.: In contact-anchored estimation, the stance contact is modeled as stationary in the world frame. When rounded foot undergoes rolling while the estimator assumes fixed contact point, the displacement bias given by (18) manifests as perturbation of the contact anchor. However, the magnitude of this bias is bounded and directly proportional to the foot radius R. Figure 6 reports the bias (18) for representative touchdown pitch a1 = 80 and lift-off pitch a2 [60, 140] with = 0.03 m. While the bias increases toward larger a2, the shank pitch during typical stance-to-swing transitions in our experiments is mostly within a2 [60, 120]. Over this practical range, the error remains below 5 mm in and 1 mm in x, which is small compared with dominant proprioceptive error sources (timing mismatch, encoder quantization, noise, slip, and compliance). Accordingly, we model the rounded point foot as an effective shank extension to keep unified and lightweight kinematic estimator. Therefore, to preserve unified kinematic formulation across platforms and to avoid introducing additional model complexity and state variables, we deliberately approximate the point foot as an effective shank extension. This approximation yields negligible degradation in practical estimation accuracy while maintaining algorithmic consistency and computational simplicity. B. Wheel-Contact Propagation for Wheel-Legged Platforms For wheel-legged robots, the stance end-effector is not stationary even under no-slip contact: the ground contact point translates as the wheel rolls. Therefore, the contact-anchored formulation of Section II must be augmented by kinematic propagation of the recorded contact point. In our implementation, this is achieved by estimating an effective wheel rolling angle that removes the apparent rotation induced by shank pitching, and then integrating the corresponding planar displacement into the footfall record. a) Effective rolling angle.: wheel-legged robot may experience apparent wheel rotation even when the ground contact does not translate. Consider the common stance scenario where the wheel is firmly constrained on the ground (no-slip) while the leg swings relative to the trunk during stepping. In this case, the wheelground contact point and the wheel center remain approximately fixed in the world frame, yet the wheel motor encoder can still report nonzero change in wheel angle and angular velocity. This apparent rotation is induced by the shank pitch motion: as the shank pitches, the wheel joint axis rotates with respect to the world, producing encoder motion that should not be interpreted as true rolling along the ground. 11 To isolate the physically meaningful rolling component, we subtract the shank pitch contribution from the wheel encoder increment. Let ψi,k denote the wheel joint angle of leg at time tk (encoder) and ψi,k its angular velocity. We define the shank pitch angle in the world frame as βi,k = θpitch,k + qi,2,k + qi,3,k, (19) where θpitch,k is the estimated body pitch and qi,2,k, qi,3,k are the thigh and calf joint angles. The wheel encoder increment is wrapped to avoid discontinuities, ψi,k = wrap(ψi,k ψi,k1) [π, π], (20) and the shank pitch increment is βi,k = βi,k βi,k1. The effective rolling increment is then computed as ψeff i,k = ψi,k βi,k, (21) which approximates the net wheel rotation relative to the ground during stance by removing the pitchinduced encoder motion. b) Heading direction on the ground plane.: Let ex = [1, 0, 0] be the body forward axis. We compute its world-frame direction hk = RW B,kex and project to the horizontal plane: ˆtk = (cid:113) 1 x,k + h2 h2 y,k , (cid:113) if x,k + h2 h2 y,k > εh, (22) hx,k hy,k where εh is small numerical threshold (in code: 109). This matches the implementation that extracts (hx, hy) directly from the current attitude quaternion and normalizes the planar component. c) Contact-point propagation.: Let cW i,k denote the world-frame contact (footfall) record of leg i. For wheel-legged stance, we update its planar components by integrating the rolling displacement: i,k cW cW i,k1 + rw ψeff i,k ˆtk, (23) where rw is the wheel radius (parameter Par_WheelRadius). This step is applied only when the leg is deemed in contact, and it reduces systematic bias that would arise if rolling wheel were treated as fixed stance anchor. d) Velocity augmentation.: The same idea is used to augment the stance-based velocity observation. In implementation we subtract the joint-induced shank pitch rate ( q2 + q3); including θpitch is straightforward but was found unnecessary in our runs. Using the encoder angular velocity and joint angular velocities, we form an effective wheel rolling rate i,k = ψi,k ( qi,2,k + qi,3,k) , ψeff (24) consistent with the implementation (wheel rate minus shank pitch rate induced by the leg joints). The induced planar rolling velocity is roll,i,k = rw ψeff vW i,k ˆtk, (25) which is added to the kinematics-derived stance velocity term when forming the fused body velocity observation (cf. (8)). e) Degenerate case and point-foot platforms.: If rw = 0, the propagation (23)(25) vanishes and the formulation reduces to the point-foot case where the stance anchor is treated as stationary. In our parameterization, point-foot robots absorb the foot radius into the effective shank length (Section III-A), whereas wheel-legged robots keep rw > 0 and apply the explicit rolling propagation above. IV. INVERSE-KINEMATICS CUBATURE KALMAN FILTERING FOR FOOT-END VELOCITY Contact-anchored proprioceptive odometry (Section II) relies on stance-phase kinematics to provide body-velocity observations. practical challenge is that joint angular velocities obtained from motor encoders are affected by quantization and discrete-time differentiation, and their noise is amplified by the nonlinear leg kinematics. As result, the derived hip-to-foot velocity can exhibit impulsive spikes, which then propagate into the fused body velocity and degrade the stability of contact-anchored updates. To suppress these artifacts while keeping the pipeline purely proprioceptive, we introduce an IKVel-CKF that estimates the hip-to-end-effector Cartesian velocity directly from joint angles and joint velocities. The analytic inverse-kinematics mapping and the CKF recursion used in our implementation are provided in Appendix B. A. Motivation: Spurious Velocity Spikes from Encoder-Derived Joint Rates Figure 7 (left) shows the estimated body linear velocity when the system uses raw encoder-derived joint rates without IKVel-CKF. The horizontal channels (vx and vy) contain pronounced spikes, reaching up to roughly 200% of the nominal signal magnitude. These spikes are consistent with encoder quantization, discrete differentiation, and slight timing mismatch, which are then magnified by nonlinear kinematic projection. The issue is further illustrated at the leg level in Fig. 8, where the raw hipfoot velocity of representative leg (blue) contains impulsive excursions. B. IKVel-CKF: Nonlinear Filtering under an Inverse-Kinematics Measurement Model For each leg i, IKVel-CKF maintains 6D latent Cartesian state xi,k ri,k ri,k R6, (26) where ri,k and ri,k are the hip-to-end-effector relative position and velocity. constant-velocity prior propagates xi,k between timestamps, while the measurement is the joint configuration and joint velocity, 13 zi,k qi,k qi,k = h(xi,k) + vi,k, (27) where h() is an analytic inverse-kinematics and differential inverse-kinematics mapping. Because h() is strongly nonlinear and may be piecewise-defined due to kinematic branches, we employ CKF to update xi,k without requiring Jacobians. In implementation, each leg caches (xi, Pi, ti), and single CKF instance is reused by swapping in/out the cached state for efficiency. The filtered Cartesian velocity ri,k then replaces the raw forward-kinematics velocity before transforming to the world frame and contributing to stance velocity constraints. C. Effect on Body Velocity Estimation After enabling IKVel-CKF, the estimated body velocity becomes substantially more stable. As shown in Fig. 7 (right), the horizontal velocity spikes are reduced to within roughly 25% of the nominal magnitude. At the leg level  (Fig. 8)  , IKVel-CKF (red) effectively suppresses impulsive excursions compared with the raw signal (blue). zoomed view (Fig. 8, right) indicates modest smoothing-induced lag, but the reduction of high-frequency noise and spike removal yields more reliable velocity feedback for contact-anchored fusion. (a) Without IKVel-CKF. (b) With IKVel-CKF. Fig. 7. Estimated body linear velocity. Red/green/blue correspond to vx, vy, and vz. Without IKVel-CKF, the horizontal channels exhibit large impulsive errors (up to 200% of nominal magnitude). With IKVel-CKF enabled, the spikes are strongly suppressed (within 25% of nominal magnitude). 14 (a) Overview. (b) Zoomed view. Fig. 8. Representative hipfoot velocity feedback (leg 1). Blue: raw forward-kinematics velocity using encoder-derived joint rates. Red: IKVel-CKF filtered velocity. IKVel-CKF effectively removes impulsive spikes; the zoomed view shows modest smoothing-induced lag, trading small phase delay for substantially improved robustness. In our fusion pipeline, the IKVel-CKF output replaces the raw encoder-derived hipfoot velocity in the stance-phase velocity constraint of Section II, so that the contact-anchored update uses denoised end-effector velocity observation. a) Computationaccuracy trade-off.: In our MATLAB/MEX deployment, enabling IKVel-CKF increases the per-cycle computation time by more than factor of two due to the nonlinear cubature updates. Accordingly, IKVel-CKF is best treated as an optional module: when reliable outer-loop contact-anchored position feedback is available from footfall constraints, the impact of IKVel-CKF on overall position accuracy is limited, while its primary benefit remains improved velocity smoothness and robustness; thus it should be enabled only when required by the downstream control or estimation objectives. V. KINEMATICS-BASED YAW ESTIMATION VIA MULTI-CONTACT GEOMETRIC CONSISTENCY Yaw is weakly observable from inertial sensing alone because gravity does not constrain heading. As result, IMU-based yaw can drift during long-horizon operation, and the effect becomes especially visible during prolonged standing, where the robot should remain stationary but the integrated yaw slowly wanders. This section presents proprioceptive yaw correction method that leverages the geometric consistency between (i) the current body-frame end-effector configuration computed from joint kinematics and (ii) the world-frame contact (footfall) records maintained by the contact-anchored odometry in Section II. The key idea is simple: when multiple contacts are simultaneously stationary, the relative geometry between contact points is fixed in the world, and any discrepancy between this world geometry and the tilt-compensated body geometry reveals the yaw misalignment. 15 (a) Top view (yaw twist with fixed contacts). (b) Front view. Fig. 9. Illustration of the geometric cue exploited for yaw correction. The blue model denotes the initial configuration and the yellow model denotes the twisted trunk pose while feet remain fixed. With multi-contact, the world-frame inter-foot geometry stays constant, enabling kinematics-derived heading reference. A. Pairwise Yaw from Contact Geometry Let Ck denote the set of end-effectors in stance at time tk (Section II-B). For each contacting leg Ck, we use: (1) the body-frame end-effector position pB stored world-frame footfall record cW ee,i,k from forward kinematics; and (2) the (assumed stationary during stance). To eliminate dependence on global translation and improve robustness, we form pairwise relative vectors: ij,k = pB vB ee,j,k pB ee,i,k, ij = cW vW cW , (28) for all unordered pairs (i, j) with i, Ck and < j. We assume roll and pitch are available from the state estimator (e.g., IMU tilt) and isolate heading by constructing tilt-only rotation Rrp,k Ry(θk)Rx(ϕk), (29) where (ϕk, θk) are the estimated roll and pitch. We then tilt-compensate the body-frame relative vector: vij,k = Rrp,kvB ij,k. (30) The yaw implied by pair (i, j) is computed from the difference between the horizontal bearings of vW ij and vij,k: ˆψij,k = wrap(cid:0)atan2(cid:0)(vW ij )y, (vW ij )x (cid:1) atan2(cid:0)(vij,k)y, (vij,k)x (cid:1)(cid:1) , (31) where wrap() maps angles to (π, π] to avoid discontinuities. Finally, we aggregate all available pairs using circular mean: ˆψk = atan (cid:88) (i,j) cos( ˆψij,k) . sin( ˆψij,k), (cid:88) (i,j) (32) 16 The estimator requires at least two simultaneous contacts (Ck 2); otherwise no geometric yaw constraint is applied. Using multiple pairs increases robustness by averaging over baselines of different lengths and orientations, and it naturally rejects wrap-around artifacts via (32). B. Drift Suppression and Kinematics-Only Fallback We use the kinematics-derived heading ˆψk as stabilizing reference to correct the current yaw state ψk. Let We apply bounded corrective update ek = wrap( ˆψk ψk). ψk wrap(ψk + αkek) , (33) (34) where αk (0, 1] controls how aggressively the kinematic constraint is enforced. Our implementation uses contact-dependent schedule for αk that matches the code logic. When fewer than four end-effectors are in stance (typical during walking, or when contacts are uncertain), we reset the accumulation timer and keep small gain αk = α0 to avoid over-correcting under intermittent contact changes. When all four feet are simultaneously in stance and remain stable (prolonged standing), we ramp αk linearly from α0 to 1 over time constant Tψ: (cid:18) αk = clip α0 + (cid:19) (1 α0), 0, 1 , tk t0 Tψ (35) where t0 is the time when full support is first detected. This design has an important practical consequence: during long stationary standing with stable multi-contact, the yaw correction (34) continuously re-anchors the heading to the contact geometry, effectively arresting IMU yaw drift. When IMU yaw constraints are disabled, (32)(34) still provide purely kinematics-derived heading reference. In this mode, the heading is no longer tied to inertial integration, but residual drift can still arise from unmodeled attitude coupling, contact compliance, and minor slip; therefore, we treat the kinematics-derived yaw primarily as stabilizing prior rather than an absolute compass. A. Physics Simulation in Gazebo VI. EXPERIMENTAL EVALUATION We first evaluate the proposed estimator in physics simulation using Unitrees AlienGo model in Gazebo. We compare (i) Lidar-based SLAM baseline following [5], (ii) CAPO, our contact-anchored proprioceptive odometry, and (iii) CAPO-CKE, which denotes CAPO with the IKVel-CKF module (Section IV) enabled. Gazebo ground-truth base states are used for error computation. Two closed-loop trajectories are executed  (Fig. 10)  : flat-ground loop with obstacle avoidance (blue), and stair-climbing loop (red). All methods are evaluated on the same commanded motions. 17 Fig. 10. Locomotion trajectories in simulation. The flat-ground loop is shown in blue and the stair-climbing loop in red. 1) Flat-Terrain Loop: Figure 1113 report the estimated base position components during the flatground loop. Both proprioceptive methods (CAPO and CAPO-CKE) maintain stable elevation estimates and substantially reduce drift compared to the SLAM baseline, particularly along the vertical channel. On this trajectory, CAPO and CAPO-CKE achieve comparable terminal accuracy; this is consistent with the fact that, under sustained stance constraints, the contact-anchored position update dominates long-horizon drift suppression, and additional velocity denoising mainly improves robustness under stronger excitation. Table summarizes mean absolute errors (MAE) along each axis and the Euclidean terminal-position error. Fig. 11. Estimated x-position during flatFig. 12. Estimated y-position during flatFig. 13. Estimated z-position during flatground walking. ground walking. ground walking. 2) Stair-Climbing Loop: The stair-climbing loop stresses proprioceptive velocity feedback due to repeated impacts and increased trunk vibration. As shown in Fig. 15, the body velocity inferred directly 18 ESTIMATION ERROR DURING FLAT-GROUND WALKING IN SIMULATION. TABLE Error MAE MAE MAE CAPO-CKE CAPO SLAM 0.5671 0.5099 0.5329 0.0818 0.0885 0.7149 0.0072 0.0073 0.6503 Terminal error 0.6157 0.6232 2.078 from encoder-derived joint rates exhibits larger-amplitude jitter and occasional impulsive outliers. In CAPO (without IKVel-CKF), single pronounced spike around 115.5 corrupts the stance/landing decision and induces an erroneous foot-contact update, which subsequently biases the estimated support height and leads to persistent degradation of the estimate. In contrast, CAPO-CKE attenuates such outliers via IKVel-CKF (Section IV), thereby preventing the false contact event and maintaining consistent long-horizon height tracking  (Fig. 1415) . Meanwhile, the SLAM baseline (pink curve) continues to drift in this low-texture environment, resulting in progressively worse estimates over time. Fig. 14. Estimated z-position during stair climbing. Fig. 15. Estimated z-velocity during stair climbing. B. Real-World Experiments We evaluate CAPO on four quadruped platforms: Unitree Go2 EDU and three Astrall robots, including point-foot platform and two wheel-legged platforms B, C. All experiments are conducted in purely proprioceptive regime using IMU and motor sensing only; no exteroceptive pose feedback is used for online drift correction. For the Go2 planar-loop trial only, we additionally run ROS 2 slam_toolbox in mapping-only setting with scan matching disabled, such that geometric inconsistencies in the reconstructed map directly visualize odometry drift (rather than scan-to-map optimization effects). For the remaining trials (including all Astrall experiments), we report the real-time estimated (x, y, z) traces. Horizontal-loop error is reported as the planar closure error exy = (cid:112)x2 + y2. For vertical-loop tests we report the height closure error ez = z, since long-horizon elevation consistency is the primary objective in these sequences. summary of the closed-loop results is provided in Table II. CLOSED-LOOP PERFORMANCE. HORIZONTAL: PLANAR CLOSURE ERROR exy . VERTICAL: HEIGHT CLOSURE ERROR ez . TABLE II Platform Horizontal loop Vertical loop Unitree Go2 EDU 120 m, 2.2138 8 m, < 0.1 Astrall (point-foot) 200 m, 0.1638 15 m, 0.219 Astrall (wheel-legged) 200 m, 0.2264 15 m, 0.199 Astrall (wheel-legged) 700 m, 7.68 20 m, 0.540 1) Unitree Go2 EDU: a) Flat-court closed loop.: The Go2 executes planar closed-loop traversal on basketball court, starting from the map corner, following the planned trajectory, and returning to the initial area. At loop closure, the terminal error is = 1.61 and = 1.52 m, corresponding to planar distance error of 2.2138 m. Figure 16 reports both the mapping-only visualization and the real-time estimated (x, y, z) trace. The map exhibits small but visible wall-orientation inconsistency (newly observed black segment versus the manually annotated red extension), which is consistent with residual heading drift when scan matching is disabled. This observation supports that yaw drift remains major contributor to long-horizon horizontal error in the absence of an exteroceptive heading reference. b) Repeated step-up/step-down.: To stress elevation consistency under repeated contact switching, the Go2 repeatedly traverses single low step for five cycles (up/down). Figure 17 shows the RViz view and the corresponding real-time estimated (x, y, z) trace. Across the five cycles, the estimator exhibits no visually observable accumulated drift in the vertical channel at the plot scale, i.e., < 0.1 upon returning to the initial region, indicating stable elevation consistency under repetitive elevation changes. 20 (a) Mapping-only RViz view (slam_toolbox with scan matching (b) Real-time estimated position (x/y/z in blue/red/green). disabled). Fig. 16. Unitree Go2 EDU planar closed-loop traversal on basketball court. (a) RViz visualization of repeated step traversal (five cycles). (b) Real-time estimated position (x/y/z in blue/red/green). Fig. 17. Unitree Go2 EDU repeated ascent/descent over single low step. 2) Astrall Platforms (A, B, C): The three Astrall platforms are equipped with higher-grade IMUs than Go2, yielding reduced inertial bias and improved heading stability, which enables tighter closedloop consistency in typical scenarios. Moreover, stance detection and contact anchoring are generally more reliable on the point-foot platform A, whereas wheel-legged platforms and face additional challenges from wheel slip and intermittent contact conditions. In particular, slip is not explicitly detected or compensated in the current implementation, and step-down motions on wheel-legged robots can exhibit brief ballistic phases that violate the ideal stationary-contact assumption, both of which can degrade horizontal-loop closure. 21 (a) Astrall (point-foot): 200 horizontal loop and 15 vertical (b) Astrall (wheel-legged): 200 horizontal loop and 15 loop. vertical loop. Fig. 18. Astrall closed-loop trials: real-time estimated (x, y, z) traces for Robot (MP) and Robot (MW). a) Robot vs. Robot (single mixed 3D loop): Figure 18 reports representative real-time estimated (x, y, z) traces for Robot and Robot B. Each robot executes one closed-loop trajectory that combines approximately 200 of horizontal travel with an accumulated 15 vertical excursion, returning to the start. Robot achieves 0.1638 horizontal-loop error and 0.219 vertical-loop error, while Robot yields 0.2264 and 0.199 m, respectively (Table II). b) Robot (two separate trials): Robot is evaluated in two separate runs: (i) substantially longer 700 horizontal closed loop, and (ii) 20 vertical loop trajectory. Figure 19 reports the corresponding real-time estimated (x, y, z) traces. The horizontal-loop error increases to 7.68 m, while the vertical-loop error remains 0.540 (Table II). We attribute the larger horizontal drift primarily to slip events and contact-geometry violations that are more pronounced for long-range wheel-legged operation, especially during step-down segments where the motion may involve brief loss of sustained rolling contact. c) Public artifacts.: To support reproducible evaluation, we release (i) the complete implementation and (ii) the ROS bags of the Unitree Go2 EDU trials, including synchronized video.1 2 1https://github.com/ShineMinxing/Ros2Go2Estimator.git 2https://drive.google.com/drive/folders/1FfVO69rfmUu6B9crPhZCfKf9wFnV4L7n?usp=sharing 22 (a) Astrall C: 700 horizontal closed loop. (b) Astrall C: 20 vertical closed loop. Fig. 19. Astrall Robot closed-loop trials: real-time estimated (x, y, z) traces. C. Discussion and Limitations a) Wheel slip.: The current wheel-legged pipeline does not explicitly detect or compensate wheel ground slip. Slip violates the rolling/contact assumptions and is likely source of long-horizon drift, especially over long-range runs. Future work will incorporate slip-aware gating/weighting using kinematic inertial inconsistency and/or wrench cues. b) Contact detection with fixed threshold.: Stance selection currently relies on constant verticalforce threshold. This is robust for typical point-foot gaits, but can be suboptimal for wheel-legged modes with prolonged light contact, while lowering the threshold may harm stair-climbing robustness. An adaptive or probabilistic contact model is therefore desirable. c) Flat-ground assumption in wheel contact propagation.: Wheel contact propagation currently translates the recorded contact point along horizontal plane using an effective rolling increment. This implicitly assumes locally flat terrain and can bias odometry on slopes. natural extension is to estimate local support plane (normal/height) from multi-contact geometry and propagate contacts along the plane tangent. d) Supplementary clarification on biped applicability.: CAPO is contact-set driven and thus extends to bipeds by operating on time-varying set of contacting end-effectors. demonstration video shows quadruped switching between two-foot and four-foot morphologies while completing closed loop without scan matching.3 3https://www.bilibili.com/video/BV1UtQfYJExu 23 e) Supplementary yaw-drift compensation and IMU-free degradation.: We provide video showing that the kinematics-based yaw correction arrests IMU yaw drift during prolonged standing and remains stable under short in-place rotations.4 When IMU yaw constraints are disabled, the kinematics-only heading reference degrades gracefully, with empirical errors of 10 per closed turn for short-step turning and 30 per closed turn for long-step turning, suggesting residual sensitivity to unmodeled attitude coupling (notably roll/pitch) and contact compliance. VII. CONCLUSION This paper presented CAPO, purely proprioceptive, contact-anchored odometry framework for legged and wheel-legged robots using only IMU and motor measurements. The estimator treats stance endeffectors as intermittent world-frame anchors by recording footfall positions at touchdown and enforcing contact-anchored kinematic consistency during stance. To stabilize long-horizon elevation, we introduced lightweight support-plane height correction that clusters touchdown heights with time-decayed confidence. For wheel-legged platforms, we incorporated an effective rolling-angle compensation to propagate wheel contact consistently under stance. To mitigate encoder-induced impulsive artifacts in hipfoot velocity, we further integrated an optional IKVel-CKF, yielding the CAPO-CKE variant with substantially smoother velocity feedback for fusion. Finally, we proposed kinematics-based yaw correction based on multicontact geometric consistency, which arrests IMU yaw drift during prolonged standing and provides graceful kinematics-only fallback when IMU yaw constraints are degraded. We evaluated the approach in both physics simulation and real-robot trials. In simulation, CAPO and CAPO-CKE significantly outperformed the SLAM baseline in low-texture settings, particularly in the vertical channel, and CAPO-CKE improved robustness against occasional encoder-driven velocity outliers during stair climbing. On real hardware, we validated the estimator on four quadruped platforms (Unitree Go2 EDU and three Astrall robots) using closed-loop trajectories with horizontal and vertical motion. The results demonstrate that contact anchoring with touchdown footfall records can provide accurate long-horizon proprioceptive odometry in practice, while residual horizontal drift remains most sensitive to heading errors and contact-model violations (e.g., slip). There remain several limitations and opportunities for improvement. Future work will focus on (i) explicit slip detection and down-weighting for wheel-legged contacts, (ii) adaptive contact classification beyond fixed-threshold wrench gating to handle prolonged light contacts without sacrificing stair robustness, and (iii) generalizing wheel contact propagation from horizontal-plane assumption to locally sloped 4https://www.bilibili.com/video/BV1frykB8ETV 24 terrain using an estimated support-plane normal. In addition, reducing the runtime overhead of IKVelCKF (e.g., by conditional enabling, lower-rate updates, or more efficient sigma-point implementations) would improve deployability on resource-constrained onboard computers. REFERENCES [1] O. Villarreal, V. Barasuol, P. M. Wensing, D. G. Caldwell, and C. Semini, MPC-based Controller with Terrain Insight for Dynamic Legged Locomotion, in 2020 IEEE International Conference on Robotics and Automation (ICRA), May 2020, pp. 24362442. [2] S. Qi, W. Lin, Z. Hong, H. Chen, and W. Zhang, Perceptive Autonomous Stair Climbing for Quadrupedal Robots, in 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Sep. 2021, pp. 23132320. [3] O. A. V. Magana, V. Barasuol, M. Camurri, L. Franceschi, M. Focchi, M. Pontil, D. G. Caldwell, and C. Semini, Fast and Continuous Foothold Adaptation for Dynamic Locomotion Through CNNs, IEEE Robotics and Automation Letters, vol. 4, no. 2, pp. 21402147, Apr. 2019. [4] R. Grandia, F. Jenelten, S. Yang, F. Farshidian, and M. Hutter, Perceptive Locomotion through Nonlinear Model Predictive Control, Aug. 2022. [5] K. Chen, B. T. Lopez, A.-a. Agha-mohammadi, and A. Mehta, Direct LiDAR Odometry: Fast Localization With Dense Point Clouds, IEEE Robotics and Automation Letters, vol. 7, no. 2, pp. 20002007, Apr. 2022. [6] M. Bloesch, C. Gehring, P. Fankhauser, M. Hutter, M. A. Hoepflinger, and R. Siegwart, State estimation for legged robots on unstable and slippery terrain, in 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, Nov. 2013, pp. 60586064. [7] N. Dini, V. J. Majd, F. Edrisi, and M. Attar, Estimation of external forces acting on the legs of quadruped robot using two nonlinear disturbance observers, in 2016 4th International Conference on Robotics and Mechatronics (ICROM), Oct. 2016, pp. 7277. [8] S. Yang, Z. Zhang, B. Bokser, and Z. Manchester, Multi-IMU proprioceptive odometry for legged robots, in 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Oct. 2023, pp. 774779. [9] M. Camurri, M. Fallon, S. Bazeille, A. Radulescu, V. Barasuol, D. G. Caldwell, and C. Semini, Probabilistic Contact Estimation and Impact Detection for State Estimation of Quadruped Robots, IEEE Robotics and Automation Letters, vol. 2, no. 2, pp. 10231030, Apr. 2017. [10] R. Hartley, M. Ghaffari, R. M. Eustice, and J. W. Grizzle, Contact-aided invariant extended Kalman filtering for robot state estimation, The International Journal of Robotics Research, vol. 39, no. 4, pp. 402430, Mar. 2020. [11] D. Youm, H. Oh, S. Choi, H. Kim, and J. Hwangbo, Legged Robot State Estimation With Invariant Extended Kalman Filter Using Neural Measurement Network, Feb. 2024. [12] S. Yang, Z. Zhang, Z. Fu, and Z. Manchester, Cerberus: Low-Drift Visual-Inertial-Leg Odometry For Agile Locomotion, in 2023 IEEE International Conference on Robotics and Automation (ICRA), May 2023, pp. 41934199. [13] R. E. Kalman, new approach to linear filtering and prediction problems, Journal of Basic Engineering, vol. 82, no. 1, pp. 3545, Mar. 1960. [14] A. H. Sayed, framework for state-space estimation with uncertain models, IEEE TRANSACTIONS ON AUTOMATIC CONTROL, vol. 46, no. 7, pp. 9981013, Jul. 2001. [15] T. Zhou, Sensitivity penalization based robust state estimation for uncertain linear systems, IEEE TRANSACTIONS ON AUTOMATIC CONTROL, vol. 55, no. 4, pp. 10181024, Apr. 2010. 25 [16] M. Sun, Y. Mao, and H. Liu, robust state estimator with adaptive factor, IEEE ACCESS, vol. 8, pp. 144 514144 521, 2020. [17] B. Bell and F. Cathey, The iterated kalman filter update as gauss-newton method, IEEE Transactions on Automatic Control, vol. 38, no. 2, pp. 294297, Feb. 1993. [18] J. Zhao, M. Netto, and L. Mili, robust iterated extended kalman filter for power system dynamic state estimation, IEEE Transactions on Power Systems, vol. 32, no. 4, pp. 32053216, Jul. 2017. [19] A. Barrau and S. Bonnabel, The invariant extended kalman filter as stable observer, IEEE Transactions on Automatic Control, vol. 62, no. 4, pp. 17971812, Apr. 2017. [20] E. Wan and R. Van Der Merwe, The unscented kalman filter for nonlinear estimation, in Proceedings of the IEEE Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No.00EX373), Oct. 2000, pp. 153158. [21] S. Julier and J. Uhlmann, Unscented filtering and nonlinear estimation, Proceedings of the IEEE, vol. 92, no. 3, pp. 401422, Mar. 2004. [22] M. Sun, H. Liu, Q. Duan, J. Wang, Y. Mao, and Q. Bao, Intention inference-based interacting multiple model estimator in photoelectric tracking, IET Control Theory & Applications, vol. 18, no. 9, pp. 12101222, 2024. [23] I. Arasaratnam and S. Haykin, Cubature kalman filters, IEEE Transactions on Automatic Control, vol. 54, no. 6, pp. 12541269, Jun. 2009. [24] C. Shen, Y. Zhang, X. Guo, X. Chen, H. Cao, J. Tang, J. Li, and J. Liu, Seamless GPS/inertial navigation system based on self-learning square-root cubature kalman filter, IEEE Transactions on Industrial Electronics, vol. 68, no. 1, pp. 499508, Jan. 2021. [25] W. Liu, X. Xia, L. Xiong, Y. Lu, L. Gao, and Z. Yu, Automated vehicle sideslip angle estimation considering signal measurement characteristic, IEEE Sensors Journal, vol. 21, no. 19, pp. 21 67521 687, Oct. 2021."
        },
        {
            "title": "LEG KINEMATICS AND WRENCH ESTIMATION",
            "content": "This appendix summarizes the explicit formulas used in our implementation to compute hip-to-endeffector relative position/velocity and to estimate end-effector contact force from joint torques. A. Parameters and Modeling Convention Each leg is modeled as 3-DoF chain with joint angles = [q1, q2, q3]T and joint velocities = [ q1, q2, q3]T . We use side sign {+1, 1} to distinguish left/right legs. Link parameters are: Lhip: hip lateral offset, Lthigh: thigh link length, Lcalf : calf/shank effective length, rw: wheel radius (wheel-legged only). Point-foot convention (matching our code). For point-foot robots, the foot-end radius is treated as an effective extension of the shank, hence it is absorbed into Lcalf and we set rw = 0. Wheel-legged 26 convention. For wheel-legged robots, Lcalf denotes the link length to the wheel axis, and rw > 0 is the wheel radius. Define the trigonometric shorthand ci = cos qi, si = sin qi, c23 = cos(q2 + q3) = c2c3 s2s3, s23 = sin(q2 + q3) = s2c3 + c2s3. (36) B. Hip-to-End-Effector Relative Position (Body Frame) The hip-to-end-effector relative position (expressed in the body frame) is rB(q) = = z (cid:0)Lcalf s23 + Lthigh s2 Lhip c1 + (Lcalf + rw) s1 c23 + Lthigh c2 s1 (cid:1) Lhip s1 Lcalf c1 c23 Lthigh c1 c2 + rw . The body-frame end-effector position is obtained by adding the hip mounting offset ee = pB pB hip + rB(q). C. Hip-to-End-Effector Relative Velocity (Body Frame) Differentiating (37) yields the relative linear velocity vB(q, q) = = vx vy vz (cid:0)(Lcalf c23 + Lthighc2) q2 + (Lcalf c23) q3 (cid:0)(Lcalf + rw)c1c23 + Lthighc1c2 sLhips1 (cid:1) (cid:1) q1 +(cid:0) (Lcalf + rw)s1s23 Lthighs1s2 (cid:0)Lcalf s1c23 + Lthighc2s1 + sLhipc (cid:1) q2 + (cid:0) (Lcalf + rw)s1s23 (cid:1) q1 +(cid:0)Lcalf c1s23 + Lthighc1s2 (cid:1) q2 + (cid:0)Lcalf c1s23 (cid:1) q3 (37) (38) (cid:1) q3 . (39) D. Geometric Jacobian The geometric Jacobian J(q) R33 is defined by From (37), the Jacobian entries are vB(q, q) = J(q) q. (40) J(q) = (Lcalf + rw)c1c23 + Lthighc1c2 sLhips1 (Lcalf + rw)s1s23 Lthighs1s2 (Lcalf + rw)s1s23 0 (Lcalf c23 + Lthighc2) (Lcalf c23) Lcalf s1c23 + Lthighc2s1 + sLhipc Lcalf c1s23 + Lthighc1s2 Lcalf c1s23 (41) . E. End-Effector Force Estimation from Joint Torques Let τ = [τ1, τ2, τ3]T denote the measured joint torques. Under the quasi-static mapping τ = JT (q) B, we compute the end-effector force in the body frame by = (JJT )1Jτ , which is equivalent to = JT τ when is invertible. The world-frame force is and its vertical component is used for stance gating in (1). = RW Bf B, 27 (42) (43) (44)"
        },
        {
            "title": "APPENDIX B",
            "content": "IKVEL INVERSE-KINEMATICS MEASUREMENT MODEL AND CUBATURE KALMAN FILTER This appendix summarizes the inverse-kinematics measurement model and the CKF recursion used by IKVel-CKF (Estimator1003 in our implementation). A. State, Process Model, and Side Constraint For end-effector i, define the hip-to-end-effector Cartesian state (cid:104) xi,k = xi,k yi,k zi,k vx,i,k vy,i,k vz,i,k (cid:105) . constant-velocity prior is used: xi,k+1 = I3 tkI3 03 I3 (cid:124) (cid:123)(cid:122) F(tk) xi,k + wi,k, (cid:125) (45) (46) where tk = tk+1 tk is truncated for robustness to timestamp anomalies (in the implementation, tk is set to 0 when tk exceeds small bound), and wi,k (0, Q). To enforce consistent kinematic branch for left/right legs, we apply side constraint on the lateral coordinate, yi,k siyi,k, si {+1, 1}, (47) where si denotes the leg side sign. B. Inverse-Kinematics Measurement Model 28 The measurement is the joint configuration and joint velocity: zi,k qi,k qi,k = h(xi,k) + vi,k, vi,k (0, R). (48) Let Lhip, Lthigh, Lcalf be link lengths and let ree be the modeled end-effector radius (absorbed into the effective shank length for point feet, explicit for wheels). Define L2 Lcalf + ree. Given (x, y, z), the analytic inverse kinematics computes (θ1, θ2, θ3) as follows. First solve the ab/adduction angle θ1 in the (y, z) plane: θ1 = si arcsin (cid:113) 2Lhipz + ϵ + 4L2 hipz2 4(z2 + y2)(cid:0)L2 2(z2 + y2) hip y2(cid:1) , where ϵ > 0 is small constant added for numerical robustness. Then remove the hip offset: = siLhip sin θ1, = siLhip cos θ1. Let = (cid:112)y2 + z2 and = r2 + x2. The remaining planar angles are θ3 = π + arccos (cid:32) L2 thigh + L2 2 r2 2LthighL2 (cid:33) , θ2 = arctan 2(x, r) + arccos (cid:32) r2 + L2 thigh L2 2 (cid:33) 2rLthigh . To predict joint velocities from (vx, vy, vz), we use the differential relationship = J(θ) θ, θ = J(θ)1v, (49) (50) (51) (52) (53) where θ = [θ1, θ2, θ3] and = [vx, vy, vz]. With cj = cos θj, sj = sin θj, c23 = cos(θ2 + θ3), s23 = sin(θ2 + θ3), the Jacobian used in the implementation is 0 L2c23 + Lthighc2 L2c23 J(θ) = siLhips1 + L2c1c23 + Lthighc2c1 L2s1s23 Lthighs1s2 L2s1s siLhipc1 + L2s1c23 + Lthighc2s1 L2c1s23 + Lthighc1s2 L2c1s"
        },
        {
            "title": "The observation function is therefore",
            "content": "(cid:104) h(x) = θ1 θ2 θ3 θ θ2 (cid:105) , θ3 θ = J(θ)1v. . (54) (55) 29 C. Cubature Kalman Filter Recursion Let = dim(x) and let (ˆxk, Pk) be the prior estimate. CKF constructs 2n cubature points using the Cholesky factor Sk such that Pk = SkS : χ(j) = ˆxk + Skej, χ(j+n) = ˆxk Skej, (56) with equal weights w(m) = 2n . The points are propagated through the process model (46) to obtain predicted mean and covariance: = 2n (cid:88) m=1 w(m) (cid:16) χ(m) (cid:17) , = + 2n (cid:88) m=1 w(m)(cid:0)f (χ(m) ) (cid:1)(cid:0)f (χ(m) ) (cid:1). Similarly, the measurement mean and covariances are computed via (55): zk = 2n (cid:88) m=1 (cid:16) w(m) χ(m) (cid:17) , Pzz = + 2n (cid:88) m=1 w(m)(cid:0)h(χ(m) ) zk (cid:1)(cid:0)h(χ(m) ) zk (cid:1), Pxz = 2n (cid:88) m= w(m)(cid:0)χ(m) (cid:1)(cid:0)h(χ(m) ) zk (cid:1)."
        },
        {
            "title": "The gain and posterior update are",
            "content": "Kk = PxzP1 zz , = ˆx+ + Kk(zk zk), P+ = KkPzzK . (57) (58) (59) (60) (61) (62) This is the CKF recursion implemented by Estimator1003, using equal-weight sphericalradial cubature points and Cholesky factorization for numerical stability."
        }
    ],
    "affiliations": [
        "Institute for Infocomm Research (I2R), Agency for Science, Technology and Research, Singapore",
        "Institute of Optics and Electronics, Chinese Academy of Sciences, Chengdu, China",
        "Shenzhen Astralldynamics Technology"
    ]
}