{
    "paper_title": "Atom of Thoughts for Markov LLM Test-Time Scaling",
    "authors": [
        "Fengwei Teng",
        "Zhaoyang Yu",
        "Quan Shi",
        "Jiayi Zhang",
        "Chenglin Wu",
        "Yuyu Luo"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) achieve superior performance through training-time scaling, and test-time scaling further enhances their capabilities by conducting effective reasoning during inference. However, as the scale of reasoning increases, existing test-time scaling methods suffer from accumulated historical information, which not only wastes computational resources but also interferes with effective reasoning. To address this issue, we observe that complex reasoning progress is often achieved by solving a sequence of independent subquestions, each being self-contained and verifiable. These subquestions are essentially atomic questions, relying primarily on their current state rather than accumulated history, similar to the memoryless transitions in a Markov process. Based on this observation, we propose Atom of Thoughts (AoT), where each state transition in the reasoning process consists of decomposing the current question into a dependency-based directed acyclic graph and contracting its subquestions, forming a new atomic question state. This iterative decomposition-contraction process continues until reaching directly solvable atomic questions, naturally realizing Markov transitions between question states. Furthermore, these atomic questions can be seamlessly integrated into existing test-time scaling methods, enabling AoT to serve as a plug-in enhancement for improving reasoning capabilities. Experiments across six benchmarks demonstrate the effectiveness of AoT both as a standalone framework and a plug-in enhancement. Notably, on HotpotQA, when applied to gpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and DeepSeek-R1 by 10.6%. The code will be available at https://github.com/qixucen/atom."
        },
        {
            "title": "Start",
            "content": "Atom of Thoughts for Markov LLM Test-Time Scaling Fengwei Teng1,2 Zhaoyang Yu2 Quan Shi3 Jiayi Zhang1,2 Chenglin Wu*2 Yuyu Luo1 1The Hong Kong University of Science and Technology (Guangzhou) 2DeepWisdom 3Renmin University of China 5 2 0 2 7 1 ] . [ 1 8 1 0 2 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) achieve superior performance through training-time scaling, and test-time scaling further enhances their capabilities by conducting effective reasoning during inference. However, as the scale of reasoning increases, existing test-time scaling methods suffer from accumulated historical information, which not only wastes computational resources but also interferes with effective reasoning. To address this issue, we observe that complex reasoning progress is often achieved by solving sequence of independent subquestions, each being self-contained and verifiable. These subquestions are essentially atomic questions, relying primarily on their current state rather than accumulated history, similar to the memoryless transitions in Markov process. Based on this observation, we propose Atom of Thoughts (AOT), where each state transition in the reasoning process consists of decomposing the current question into dependency-based directed acyclic graph and contracting its subquestions, forming new atomic question state. This iterative decomposition-contraction process continues until reaching directly solvable atomic questions, naturally realizing Markov transitions between question states. Furthermore, these atomic questions can be seamlessly integrated into existing test-time scaling methods, enabling AOT to serve as plug-in enhancement for improving reasoning capabilities. Experiments across six benchmarks demonstrate the effectiveness of AOT both as standalone framework and plug-in enhancement. Notably, on HotpotQA, when applied to gpt-4omini, AOT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and DeepSeek-R1 by 10.6%. The code will be available at https://github.com/qixucen/atom. * Corresponding authors. Figure 1: Comparison of computational resource allocation in test-time scaling methods. Traditional testtime scaling methods allocate computational resources partially to process historical information, while AOT dedicates all computational resources to reasoning directly related to the current atomic question state."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) demonstrate significant scaling effects, with their capabilities showing predictable improvements as model parameters and training data increase, leading to enhanced performance across diverse domains (Kaplan et al., 2020). While this scaling law faces bottlenecks in high-quality data availability, test-time scaling offers an alternative solution by forcing LLMs to engage in effective logical reasoning during inference to improve performance on diverse tasks (Snell et al., 2024; Muennighoff et al., 2025; Hou et al., 2025; Zhang et al., 2024a). However, existing test-time scaling methods excessively maintain historical information during reasoning, as they rely heavily on complex structural dependencies throughout the reasoning process. Chain-based methods must preserve the enFigure 2: The overview of AOT. The left portion illustrates our Markov process where each state Qi represents an atomic reasoning state derived through DAG decomposition and contraction from its predecessor. The right portion demonstrates AOTs integration capability with existing test-time scaling methods (e.g., CoT, ToT). key feature of this integration is that any intermediate state Qi from our Markov process can serve as an entry point (Q0) for other methods, enabling flexible composition while maintaining answer equivalence with the original question. This design allows AOT to function both as standalone iterative framework and as preprocessing module that can enhance existing approaches through structural optimization. tire reasoning history to generate each subsequent step (Wei et al., 2022; Zhang et al., 2023), while tree-based approaches require tracking both ancestor and sibling relationships for branch selection (Yao et al., 2023; Zhou et al., 2024; Ding et al., 2024). Graph-based structures further compound these challenges through arbitrary node dependencies. As the scale of reasoning increases, the accumulation of historical dependencies not only wastes substantial computational resources but also interferes with the models ability to reason effectively, as illustrated in Figure 1. Human reasoning often progresses through solving sequence of independent subquestions, fundamental principle established in cognitive science (Simon, 1962) and problem-solving theory (Polya, 1945). When solving complex problem, we naturally identify and resolve self-evident subquestions first, then seamlessly incorporate these solutions to reformulate simplified problem state, rather than maintaining detailed reasoning processes for resolved components. This progression closely resembles Markov process (Markov, 1906), where each state represents question, and state transitions occur through resolving partial problems to form new, independent questions. Inspired by this Markov nature of human reasoning, we propose Atom of Thoughts (AOT), framework that realizes the Markov-style reasoning process. Our key insight is that each reasoning state can be defined as simplified problem equivalent to the original one, where partial reasoning steps are either transformed into known conditions or excluded as incorrect explorations. This definition is achieved through two-phase state transition mechanism: first decomposing the current question into dependency-based directed acyclic graph (DAG) to capture rich structural information, then contracting subquestions into new independent question. This iterative decomposition-contraction process continues until reaching directly solvable atomic questions, ensuring each state transition depends only on the current state while progressively reducing problem complexity. This design endows AOT with two key advantages. First, AOT eliminates the need for maintaining and computing historical information when scaling computational resources. Second, these atomic questions can be seamlessly integrated into existing test-time scaling frameworks, allowing AOT to function as either standalone framework or plug-in enhancement for improving the overall reasoning capabilities. In summary, our contributions are as follows: Atom of Thoughts. We introduce AOT, novel reasoning framework with Markov property that progressively decomposes problems into atomic units. This approach significantly reduces computational resources wasted on historical information processing, allowing the model to focus on effective reasoning during test-time scaling. Zhang et al., 2025; Xiang et al., 2025; Zhang et al., 2024b). Plug-In Enhancement. The atomic questions derived by AOT can be directly integrated into existing test-time scaling methods (Bi et al., 2024; Wang et al., 2023b), enhancing both their performance and cost efficiency. Extensive Evaluation. Experiments across six benchmarks demonstrate the effectiveness of AOT both as standalone framework and as plug-in enhancement. AOT outperforms all baselines, and notably on HotpotQA dataset, enables gpt-4o-mini to surpass reasoning models: o3-mini by 3.4% and DeepSeekR1 by 10.6%."
        },
        {
            "title": "2.1 Reasoning Framework",
            "content": "Chain-of-Thought (Wei et al., 2022) prompting has emerged as fundamental technique for enhancing LLMs reasoning. Decomposition methods like Least-to-Most (Zhou et al., 2023) and Plan-andSolve (Wang et al., 2023a) prompting parse complex problems into sequential subtasks. Iterative optimization approaches like Self-Refine (Madaan et al., 2023), Step-Back (Zheng et al., 2024) prompting and Progressive-Hint Prompting (Zheng et al., 2023) refine solutions through cyclic feedback or abstraction. Multi-path aggregation techniques like Self-Consistency CoT (Wang et al., 2023b) and LLM-Blender (Jiang et al., 2023) further improve reasoning reliability by multitrajectory consensus. More sophisticated frameworks structure the representation of reasoning space through dedicated formalisms: Tree of Thoughts (Yao et al., 2023) enables systematic exploration of multiple reasoning paths, while Graph of Thoughts (Besta et al., 2024) represents reasoning processes as dynamic graphs with backtracking mechanisms. Addressing fundamental limitations in resampling-based paradigms, Thought Space Explorer (Zhang and Liu, 2024) strategically explores under-sampled regions of the solution space. These frameworks serve as universal augmentation of LLMs reasoning, enhancing their capacity across various domains, with their principles being widely adopted in agentic workflows for code generation, question answering, and data science applications (Hong et al., 2024b; Zhang et al., 2024a; Hong et al., 2024a;"
        },
        {
            "title": "2.2 Test-time Scaling",
            "content": "Test-time scaling approaches have demonstrated the value of extended computation during inference. Supervised fine-tuning on long chain-of-thought traces has proven effective at enhancing models capabilities to conduct extended reasoning (Yeo et al., 2025; Yao et al., 2025). Building on this foundation, reinforcement learning methods have enabled models to automatically learn optimal inference expansion strategies, allowing for adaptive scaling of the reasoning process (Kimi et al., 2025; Zeng et al., 2025; DeepSeek-AI, 2025). Frameworkbased approaches have further expanded these capabilities by extending inference through external systems, incorporating techniques like verification, budget forcing, and ensemble methods (Zhang et al., 2024a; Saad-Falcon et al., 2024; Chen et al., 2024). These complementary approaches demonstrate how strategic use of additional computation during inference through learned behaviors, automated scaling, and system-level interventions can substantially enhance model performance. However, these approaches universally maintain extensive historical information throughout the reasoning process, leading to computational inefficiency and potential interference with effective reasoning. In contrast, AOT introduces Markovian perspective that eliminates the need for historical dependency tracking, enabling more efficient resource allocation while maintaining compatibility with existing test-time scaling methods."
        },
        {
            "title": "3 An Overview of AOT",
            "content": "This section presents an overview of AOT from probabilistic modeling perspective. We first examine how traditional reasoning chains work and then introduce our dependency-based graph structures and their contraction mechanisms to enhance the modeling capability of reasoning processes."
        },
        {
            "title": "3.1 Reasoning Chain",
            "content": "Chain-of-Thought (CoT) prompting enables LLMs to progressively propose intermediate thoughts Ti when solving problem. As discussed earlier, this approach requires maintaining complete reasoning history, which can be formalized as probabilistic sampling procedure: p(AT , Q0) (cid:89) i=0 p(TiT<i, Q0) (1) Here, = {T0, T1, . . . , TN } represents the sequence of intermediate thoughts generated by the LLM. Each thought Ti depends on the previous thoughts T<i and the initial question Q0. To explore chain-based methods with different node definitions, Least-to-Most (Zhou et al., 2023) replaces the intermediate thoughts Ti with subquestions Qi, resulting in different formulation of the reasoning chain: In our DAG definition, nodes represent subquestions Qi, and edges (Qj, Qi) indicate that Qj contains necessary information for solving Qi. major challenge in constructing Markov processes stems from the dependencies of various information in complex reasoning scenarios, and this definition provides structural information for identifying dependencies through rule-based determination. Based on their dependency relationships, all subquestion nodes can be categorized into two types: Independent subquestions Qind (nodes without incoming edges): p(AQ) (cid:89) i=0 Qind = {Qi Qj Q, (Qj, Qi) E} (5) p(QiQ<i) (2) Dependent subquestions Qdep (nodes with incoming edges): where = {Q0, Q1, . . . , QN } is the sequence of subquestions. In an ideal scenario where the reasoning chain exhibits the Markov property, each subquestion Qi+1 would only depend on its immediate predecessor Qi, similar to how humans naturally solve complex problems by resolving independent subquestions and reformulating simplified states. This leads to: p(AQN ) (cid:89) i=0 p(Qi+1Qi) (3) However, achieving true Markov property in realworld reasoning tasks is challenging. We adopt the subquestion-based node structure from reasoning chains as states while exploring two-phase state transition mechanism consisting of decomposition and contraction to address this challenge."
        },
        {
            "title": "3.2 Dependency Directed Acyclic Graph",
            "content": "AOT utilizes temporary DAG structures to decompose the current question, unlike existing methods that maintain complex dependencies throughout the reasoning process. This DAG structure serves as scaffold during state transitions, providing rich structural information to guide the complete state transition process, specifically functioning as the decomposition phase to facilitate the subsequent contraction phase. The DAG is defined as: = (Q, E), = {Qi}n i=1, (4) Qdep = {Qi Qj Q, (Qj, Qi) E} (6) The key assumption of acyclicity in our DAG is guaranteed by this edge definition: since subquestions are generated following natural language order, any subquestion Qi can only depend on previously generated subquestions Q<i. Even in the maximally connected case where each subquestion links to all its predecessors, acyclicity is maintained, as any additional edges would create cycles by connecting to future nodes while violating the natural language order."
        },
        {
            "title": "3.3 Contraction",
            "content": "The contraction phase transforms the temporary DAG structure into the next atomic state while preserving the Markov property. To ensure this Markov process is meaningful, we must maintain state atomicity while ensuring progress in the reasoning process. As the reasoning progresses, new conclusions and information are continuously derived, necessitating the selective discarding of information to maintain atomic states. AOT addresses this by treating results from Qind as either given conditions or eliminated process information, while contracting Qdep into an independent question as the next state. This contracted question maintains solution equivalence to Qi, ensuring the reasoning process stays on track. The reasoning process is formally described in Algorithm 1, which shows how AOT iterates through decomposition and contraction steps. This Algorithm 1 Algorithm of AOT Require: Initial question Q0 Ensure: Final answer 1: Iteration counter 0 2: max depth None 3: while < or is None do Gi decompose LLM(Qi) 4: // Generate dependency DAG if is None then 5: 6: 7: 8: 9: 10: GetMaxPathLength(Gi) // Rule-based path length calculation end if Qind {Qi Qj Q, (Qj, Qi) E} Qdep {Qi Qj Q, (Qj, Qi) E} Qi+1 contractLLM(Qind, Qdep) // Contract subquestions into independent question + 1 11: 12: end while 13: solveLLM(QD) // Generate final answer 14: return iterative process continues until it reaches maximum number D, which is assigned by the depth of the first generated graph G0 to prevent infinite decomposition. The process can be formalized as: p(AQD) (cid:89) i=0 p(Qi+1Gi) p(GiQi) (7)"
        },
        {
            "title": "4 The Design Details of AOT",
            "content": "This section details the implementation of AOTs core components: decomposition and contraction, which together form one iteration of state transition in the Markov reasoning process, as illustrated in Figure 2. Through structured decomposition and principled contraction, our approach establishes foundation for iterative reasoning that can flexibly integrate with other methods while balancing computational efficiency and reasoning depth."
        },
        {
            "title": "4.1 Decomposition",
            "content": "Dependency Directed Acyclic Graph. Addressing the challenge of excessive historical information maintenance, our decomposition phase introduces an efficient dependency extraction mechanism that only temporarily captures rich structural information, which provides the foundation for subsequent simplification. This process starts with decomposing the current question into granular subquestions, then leverages LLMs zero-shot capabilities to efficiently identify inter-question dependencies. The dependency extraction is achieved through JSON-formatted LLM invocation that progressively labels each subquestions dependencies by indexing its upstream questions (see Appendix B.2 for annotation prompt templates)."
        },
        {
            "title": "4.2 Contraction",
            "content": "Subquestions Contracting. Based on the dependency relationships identified in DAG structure, AOT performs contraction through single LLM invocation. This process constructs an independent contracted question by selectively integrating information from independent subquestions as known conditions and incorporating the descriptions of current dependent subquestions into the main body. This process maintains answer equivalence throughout the Markov chain while continuously eliminating the test-time of solved independent subquestions in past iterations when solving the contracted question independently. The elimination of the dependency relationships from independent subquestions and the generated contracted question facilitates the transmission of key information that causes dependency. (see Appendix B.3 for contraction prompt templates). Markov Property Maintenance. Through this contraction process, AOT effectively eliminates redundant information in historical reasoning steps to reduce the test-time required for solving questions in subsequent states. The contraction mechanism ensures that each state generated in the process depends only on its immediate predecessor, preserving the Markov property while progressively simplifying inherent complexity of the question in the current state. 4."
        },
        {
            "title": "Integration",
            "content": "Iterative Process. The pipeline of AOT operates through an iterative process where each state transition step involves question decomposition followed by contraction. The contracted question from each iteration serves as the input for the next decomposition phase. As the number of iterations increases, the test-time scales up in an attempt to achieve more robust and effective reasoning. Termination Mechanism. To optimize test-time efficiency, AOT incorporates an automated termination mechanism that uses LLM evaluation to assess solution quality through answer comparison. After each contraction step, an LLM examines three key elements: the execution results of the original question Qi, the decomposed DAG structure Gi, and the independent execution results of contracted question Qi+1. The LLM synthesizes these elements to generate comprehensive answer for Qi. If this synthesized answer demonstrates consistency with the answer produced by Qi+1, the iterative process continues. Upon termination, AOT combines the current contracted question with the union of independent subquestions Qdep = (cid:83)i j=1 Qdepj accumulated from all previous iterations to form complete solution to the initial question Q0. This structure provides solution composed entirely of independent questions, maintaining semantic independence of each subquestion while ensuring completeness of whole solution. Integration Through Configurable Termination. Building upon this termination mechanism, AOT enables seamless integration with existing test-time scaling methods by allowing any intermediate state to serve as an entry point. This flexibility comes from AOTs configurable termination strategy - often just single decomposition-contraction cycle - before passing this simplified question to other methods (refer to the right portion of Figure 2). This approach leverages AOTs structural optimization capabilities as preprocessing step while allowing other methods to operate on more manageable question. The contracted question passed to subsequent methods maintains answer equivalence with the original question while AOTs initial structural simplification helps redirect computational resources towards more direct and effective reasoning. The seamless transition between methods is facilitated by the atomic state representation in our Markov process, ensuring that essential question characteristics are preserved while unnecessary historical information is eliminated. mechanism confirm the essentiality of our design choices."
        },
        {
            "title": "AOT",
            "content": "evaluate reasoning tasks: mathematical Datasets. We using gpt-4o-mini-0718 as the backbone model, chosen for its strong performance-efficiency trade-off. Our evaluation covers four categories of reasoning (MATH (Hendrycks et al., 2021) with numerical answers and GSM8K (Cobbe et al., 2021)), knowledge-intensive reasoning (MMLU-CF (Zhao et al., 2024)), logical reasoning (multiple-choice subsets of BBH (Suzgun et al., 2023), see Appendix D.1 for details), and multi-hop reasoning (HotpotQA (Yang et al., 2018) and LongBench (Bai et al., 2024) which test models ability to connect information across multiple contexts). We use the first 1,000 examples from each datasets test set, except for GSM8K where we use its complete test set (1,319 examples) and LongBench where we use the combined MuSiQue (Trivedi et al., 2022) and 2WikiMultiHopQA (Ho et al., 2020) subsets (400 examples). include Baselines. Our baselines classical prompting methods (Chain-of-Thought (CoT), CoT with Self-Consistency (CoT-SC, = 5), Self-Refine, and Analogical Reasoning (Yasunaga et al., 2024)) and advanced reasoning frameworks (agentic workflow AFlow (Zhang et al., 2024a) and Forest of Thought (FoT)). For FoT, we implement it using Tree of Thoughts with branch number = 3, chosen for its generalizability across diverse tasks. All experiments are averaged over three runs, with detailed reproduction settings in Appendix D."
        },
        {
            "title": "5.2 Experimental Results and Analysis.",
            "content": "We conduct comprehensive experiments to examine AOT through extensive benchmark evaluation on six standard datasets, reasoning models comparison, test-time optimization experiments, and ablation studies. Our main results demonstrate consistent improvements across different reasoning tasks, with significant gains especially in multi-hop reasoning. Through comparison with state-of-the-art reasoning models, we show AOTs effectiveness as general framework. Our test-time optimization experiments further validate AOTs adaptability and efficiency. Finally, ablation studies on key components like DAG structure and decomposition Main Results As shown in Table 1, AOT demonstrates consistent improvements across different reasoning tasks. AOT achieves strong performance on mathematics tasks, with AOT reaching 84.9% on MATH and 95.1% on GSM8K (+1.9% over AFlow on MATH, +1.1% over FoT(n=8) on GSM8K). The most notable improvements are in multi-hop QA tasks, where our base version achieves 80.6% F1 score on HotpotQA (+7.1% over AFlow). Similar improvements on LongBench (68.8%, +7.5% over AFlow) further demonstrate the effectiveness of AOTs atomic state representation in long context scenarios. Table 1: Performance Comparison Across Tasks (%). We evaluate three variants: the base version (AOT), version integrated with FoT (AOT (d=1) + FoT(n=2)), and computationally intensive version (AOT ) that uses LLM to select the optimal answer from three runs. Results are reported as exact match accuracy for MATH, GSM8K, BBH, and MMLU-CF, and F1 scores for HotpotQA and LongBench. Method CoT CoT-SC (n=5) Self-Refine Analogical Prompting AFlow FoT (n=8) AOT (d=1) + FoT (n=2) AOT (Ours) AOT (Ours) MATH GSM8K BBH MMLU-CF HotpotQA LongBench Avg. 73.7 75.5 74.4 68.1 76.1 75.9 75.8 80.8 81.4 78.3 83.4 80.0 72.5 76.0 82.4 82.2 86.0 87. 69.6 71.1 69.7 65.8 69.5 70.6 69.7 70.9 71.2 57.6 58.6 58.2 52.9 61.0 59.1 58.4 68.5 68.8 67.2 66.2 68.3 64.7 73.5 66.7 67.6 80.6 81.0 90.9 92.0 91.7 87.2 93.5 94.0 94.2 95.0 95.1 78.3 81.8 78.7 65.4 83.0 82.5 82.6 83.6 84.9 Table 2: Comparison of Reasoning Model Performance on Multi-hop QA Tasks. Results show F1 scores and Hit rates (F1 > 0) for HotpotQA and LongBench across different models. Method CoT AOT QwQ DeepSeek-R1 o3-mini gpt-4o-mini o3-mini HotpotQA Hit F1 82.4 68.1 85.5 70.0 88.3 77.2 89.8 80.6 91.4 81.4 LongBench Hit F1 65.6 52.7 69.9 56.0 70.0 55.3 69.3 60.5 72.1 63. Reasoning Models Comparison Results. We compare AOT with several reasoning modincluding QwQ-32B-Preview (Qwen-Team, els, 2024), DeepSeek-R1 (DeepSeek-AI, 2025), and o3-mini-2025-01-31(OpenAI, 2025). Notably, o3-mini demonstrates remarkable raw performance with 77.2% F1 score on HotpotQA, surpassing our previous best baseline AFlow (73.5% F1) in the main experiments, highlighting its strength as foundation model. When integrated into our framework, even relatively modest model like gpt-4omini achieves an impressive 80.6% F1 score. Furthermore, employing o3-mini as the backbone of AOT leads to exceptional results: the F1 score increases to 81.4% and the Hit rate reaches 91.4% on HotpotQA. On the LongBench subset, our framework with o3-mini achieves 63.3% F1 score and 72.1% Hit rate, establishing new state-of-the-art performance across all metrics. Due to the computational constraints and stability considerations, we evaluated on the first 100 examples from the Musique subset of LongBench, which may result in slightly higher scores compared to our main experiments in Table 1. Figure 3: Performance scaling with transition times on MATH dataset. Darker blue indicates larger sample sizes at shallower depths, as most problems are solved with fewer decomposition steps. Test-Time Optimization Results. We investigate the test-time scaling behavior of AOT through two sets of experiments. First, as shown in Figure 3, we analyze the performance scaling of AOT on MATH dataset. Unlike the dynamic iteration limit determined by problem-specific graph structures described in Section 3, here we set uniform maximum of 5 iterations to explicitly examine the depth-wise scaling behavior. Since each iteration produces an evaluable solution, we can track performance across different iteration depths. All 1000 test samples naturally generate solutions at depth 1, while fewer samples proceed to deeper iterations (dropping to 207 at depth 5), as many problems achieve satisfactory solutions at earlier depths. The results demonstrate that AOT exhibits consistent accuracy improvements from 83.2% to 92.7% as the iteration depth increases, with the performance gains gradually tapering. This pattern suggests that while deeper iterations continue to benefit overall performance, many problems can be effectively solved with fewer iterations, providing natural trade-off between computational cost and solution quality. Table 3: Ablation Study on AOT Components (%). Removing the decomposition phase causes notable performance drops, while removing the DAG structure but keeping decomposition leads to even larger degradation. Method AOT (Full) AOT w/o Decomposition AOT w/o DAG Structure MATH GSM8K 83.6 82.9 82.7 95.0 94.8 94.3 marginal improvement in accuracy per unit of computational investment. Ablation Study. We conduct ablation studies to analyze the contribution of key components in AOT. As shown in Table 3, removing the decomposition phase (i.e., no extracted independent or dependent sub-problems as guidance) causes notable performance drops, while removing the DAG structure but keeping the decomposition phase (i.e., only extracting the first semantically independent subproblem as guidance) leads to even larger degradation. Without decomposition structure, the LLM struggles to capture crucial dependencies between subquestions in the contraction phase, resulting in contracted questions that often contain redundant information. Moreover, providing single subproblem guidance without proper structural information disrupts the parallel relationships between sub-problems. This reveals critical insight: imperfect structural guidance can be more detrimental than no guidance at all (see Appendix C.1 for examples)."
        },
        {
            "title": "6 Conclusion",
            "content": "In this paper, we introduced Atom of Thoughts (AOT), novel framework that transforms complex reasoning processes into Markov process of atomic questions. By implementing two-phase transition mechanism of decomposition and contraction, AOT eliminates the need to maintain historical dependencies during reasoning, allowing models to focus computational resources on the current question state. Our extensive evaluation across diverse benchmarks demonstrates that AOT serves effectively both as standalone framework and as plug-in enhancement for existing test-time scaling methods. These results validate AOTs ability to enhance LLMs reasoning capabilities while optimizing computational efficiency through its Markov-style approach to question decomposition and atomic state transitions. Figure 4: Performance comparison on MATH dataset showing computational efficiency. The green line shows FoT scaling with varying tree numbers (2k, = 0, 1, 2, ...), while the gray trend line (representing other baseline methods) together demonstrate the trade-off between performance gains and computational costs. AOT (d=1) combined with FoT(n=2) achieves slightly better performance to standalone FoT(n=8) while requiring substantially less computation. In our second experiment (Figure 4), we examine the effectiveness of AOT as plug-in for existing test-time scaling methods. When integrated with FoT, AOT demonstrates promising efficiency. This efficiency gain stems from how AOT restructures the reasoning process: by iteratively solving sub-problems and using them as known conditions for subsequent steps, it eliminates redundant derivations. This leads to substantially reduced test-time demands in the FoT phase while achieving slightly better performance, demonstrating how our approach can systematically optimize existing test-time scaling methods. Cost Analysis. Through analyzing computational efficiency as shown in Figure 4, our AOT achieves superior efficiency by reaching competitive performance at significantly lower computational costs compared to existing methods. This enhanced efficiency can be attributed to our atomic state representation that preserves only necessary information while eliminating redundant computations. Notably, AOT demonstrates the steepest performance-to-cost ratio among all compared methods, indicating it achieves the highest"
        },
        {
            "title": "7 Limitations",
            "content": "A key limitation of AOT lies in its Markov state transition process without well-designed reflection mechanism. When the initial DAG decomposition fails to properly model parallel relationships between subquestions or captures unnecessary dependencies, it can negatively impact subsequent contraction and reasoning process, scenario that occurs frequently in practice. The framework currently lacks the ability to detect and rectify such poor decompositions, potentially leading to compounded errors in the atomic state transitions. This limitation suggests the need for future research into incorporating effective reflection and adjustment mechanisms to improve the robustness of DAGbased decomposition."
        },
        {
            "title": "8 Ethics Statement",
            "content": "While this work advances the computational efficiency and test-time scaling capabilities of language models through the AOT framework, we acknowledge that these models process information and conduct reasoning in ways fundamentally different from human cognition. Making direct comparisons between our Markov reasoning process and human thought patterns could be misleading and potentially harmful. The atomic state representation and dependency-based decomposition proposed in this research are computational constructs designed to optimize machine reasoning, rather than models of human cognitive processes. Our work merely aims to explore more efficient ways of structuring machine reasoning through reduced computational resources and simplified state transitions, while recognizing the distinct nature of artificial and human intelligence. We encourage users of this technology to be mindful of these limitations and to implement appropriate safeguards when deploying systems based on our framework."
        },
        {
            "title": "References",
            "content": "Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. 2024. Longbench: bilingual, multitask benchmark for long context understanding. In ACL (1), pages 31193137. Association for Computational Linguistics. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2024. Graph of thoughts: Solving elaborate problems with large language models. In AAAI, pages 1768217690. AAAI Press. Zhenni Bi, Kai Han, Chuanjian Liu, Yehui Tang, and Yunhe Wang. 2024. Forest-of-thought: Scaling testtime compute for enhancing LLM reasoning. CoRR, abs/2412.09078. Lingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter Bailis, Ion Stoica, Matei Zaharia, and James Zou. 2024. Are more LLM calls all you need? towards scaling laws of compound inference systems. CoRR, abs/2403.02419. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. CoRR, abs/2110.14168. DeepSeek-AI. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. Preprint, arXiv:2501.12948. Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, and Dongmei Zhang. 2024. Everything of thoughts: Defying the law of penrose triangle for thought generation. In ACL (Findings), pages 1638 1662. Association for Computational Linguistics. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the MATH dataset. In NeurIPS Datasets and Benchmarks. Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. 2020. Constructing multi-hop QA dataset for comprehensive evaluation of reasoning steps. In COLING, pages 66096625. International Committee on Computational Linguistics. Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Ceyao Zhang, Chenxing Wei, Danyang Li, Jiaqi Chen, Jiayi Zhang, et al. 2024a. Data interpreter: An llm agent for data science. arXiv preprint arXiv:2402.18679. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. 2024b. Metagpt: Meta programming for multi-agent collaborative framework. In ICLR. OpenReview.net. Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, and Yuxiao Dong. 2025. Advancing language model reasoning through reinforcement learning and inference scaling. Preprint, arXiv:2501.11651. Dongfu Jiang, Xiang Ren, and Bill Yuchen Lin. 2023. Llm-blender: Ensembling large language models with pairwise ranking and generative fusion. In ACL (1), pages 1416514178. Association for Computational Linguistics. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. CoRR, abs/2001.08361. Kimi, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. 2025. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. 2023. Self-refine: Iterative refinement with self-feedback. In NeurIPS. Andrey Andreyevich Markov. 1906. Extension of the law of large numbers to dependent quantities. Izv. Fiz.-Matem. Obsch. Kazan Univ.(2nd Ser), 15(1):135 156. Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, and Tatsunori Hashimoto. 2025. s1: Simple test-time scaling. Preprint, arXiv:2501.19393. OpenAI. 2025. OpenAI o3-mini: Pushing the frontier of cost-effective reasoning. Polya. 1945. How to solve it: new aspect of mathematical method. Qwen-Team. 2024. QwQ: Reflect deeply on the boundaries of the unknown. Jon Saad-Falcon, Adrian Gamarra Lafuente, Shlok Natarajan, Nahum Maru, Hristo Todorov, Etash Guha, Estefany Kelly Buchanan, Mayee F. Chen, Neel Guha, Christopher Ré, and Azalia Mirhoseini. 2024. Archon: An architecture search framework for inference-time techniques. CoRR, abs/2409.15254. Herbert Simon. 1962. The architecture of complexity. Proceedings of the American Philosophical Society, 106(6):467482. Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. ArXiv, abs/2408.03314. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. 2023. Challenging big-bench tasks and whether chain-of-thought can solve them. In ACL (Findings), pages 1300313051. Association for Computational Linguistics. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022. Musique: Multihop questions via single-hop question composition. Trans. Assoc. Comput. Linguistics, 10:539554. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023a. Plan-and-solve prompting: Improving zeroshot chain-of-thought reasoning by large language models. In ACL (1), pages 26092634. Association for Computational Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023b. Self-consistency improves chain of thought reasoning in language models. In ICLR. OpenReview.net. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In NeurIPS. Jinyu Xiang, Jiayi Zhang, Zhaoyang Yu, Fengwei Teng, Jinhao Tu, Xinbing Liang, Sirui Hong, Chenglin Wu, and Yuyu Luo. 2025. Self-supervised prompt optimization. arXiv preprint arXiv:2502.06855. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: dataset for diverse, explainable multi-hop question answering. In EMNLP, pages 23692380. Association for Computational Linguistics. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. In NeurIPS. Xinhao Yao, Ruifeng Ren, Yun Liao, and Yong Liu. 2025. Unveiling the mechanisms of explicit cot training: How chain-of-thought enhances reasoning generalization. arXiv preprint arXiv:2502.04667. Michihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H. Chi, and Denny Zhou. 2024. Large language models as analogical reasoners. In ICLR. OpenReview.net. Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, and Xiang Yue. 2025. Demystifying long chain-of-thought reasoning in llms. Preprint, arXiv:2502.03373. Weihao Zeng, Yuzhen Huang, Wei Liu, Keqing He, Qian Liu, Zejun Ma, and Junxian He. 2025. 7b model and 8k examples: Emerging reasoning with reinforcement learning is both effective and efficient. https://hkust-nlp.notion.site/ simplerl-reason. Notion Blog. Guibin Zhang, Kaijie Chen, Guancheng Wan, Heng Chang, Hong Cheng, Kun Wang, Shuyue Hu, and Lei Bai. 2025. Evoflow: Evolving diverse agentic workflows on the fly. Preprint, arXiv:2502.07373. Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, et al. 2024a. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762. Jiayi Zhang, Chuang Zhao, Yihan Zhao, Zhaoyang Yu, Ming He, and Jianping Fan. 2024b. Mobileexperts: dynamic tool-enabled agent team in mobile devices. arXiv preprint arXiv:2407.03913. Jinghan Zhang and Kunpeng Liu. 2024. Thought space explorer: Navigating and expanding thought space for large language model reasoning. In 2024 IEEE International Conference on Big Data (BigData), pages 82598251. IEEE. Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023. Automatic chain of thought prompting in large language models. In ICLR. OpenReview.net. Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xingxing Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, and Furu Wei. 2024. MMLU-CF: contamination-free multitask language understanding benchmark. CoRR, abs/2412.15194. Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li. 2023. Progressive-hint prompting improves reasoning in large language models. CoRR, abs/2304.09797. Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2024. Take step back: Evoking reasoning via abstraction in large language models. In ICLR. OpenReview.net. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. 2024. Language agent tree search unifies reasoning, acting, and planning in language models. In ICML. OpenReview.net. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le, and Ed H. Chi. 2023. Least-to-most prompting enables complex reasoning in large language models. In ICLR. OpenReview.net."
        },
        {
            "title": "Graph structure and Chain Length",
            "content": "Figure 5: Distribution of solution depths across questions. Darker orange bars indicate depths that appear more frequently in the dataset. Figure 7: Number of subquestions vs accuracy. Color intensity (green) reflects data density - darker points represent more frequent patterns. Figure 6: Distribution of subquestion counts across questions. Darker green bars represent more common subquestion counts in the solutions. Figure 8: Solution depth vs accuracy. Color intensity (orange) reflects data density - darker points represent more frequent patterns. To understand the structural characteristics of decomposed questions, we analyzed the first 1,000 questions from the MATH dataset after performing DAG decomposition. Our analysis focused on two key structural metrics: the depth of the solution graph and the number of subquestions (chain length) in each decomposition. The distributions shown in Figures 5 and 6 reveal clear patterns in question structure. The depth distribution (indicated by orange bars) shows that most questions have depths between 2 and 4, with depth 3 being the most common as indicated by the darkest orange bar. Similarly, the subquestion count distribution (shown in green) indicates that questions typically contain 2 to 5 subquestions, with the darker green bars highlighting that 3-4 subquestions is the most frequent decomposition pattern. Notably, we observed correlations between these structural metrics and solution accuracy. The scatter plots reveal two important patterns: First, as shown in Figure 8, as the depth of the solution graph increases, there is general trend of decreasing accuracy. Second, as illustrated in Figure 7, questions with more subquestions tend to show lower accuracy rates. The color intensity of the points provides additional insight - darker points represent more common structural patterns in our dataset, showing that most of our highaccuracy solutions come from questions with moderate depth and subquestion counts. This suggests that more complex question structures, characterized by either greater depth or more subquestions, pose greater challenges for question-solving systems. The decline in accuracy could be attributed to error propagation through longer solution chains and the increased cognitive load required to maintain consistency across more complex question structures."
        },
        {
            "title": "B The prompt used in AOT",
            "content": "In this section, we mainly present the basic prompts in mathematical scenarios. B.1 Direct Solver ''' def direct ( question : str ): instruction = \"\"\" You are precise math question solver . Solve the given math question step by step using standard algebraic approach : QUESTION : { question } You can freely reason in your response , but please enclose the final answer within < answer > </ answer > tags ( pure number without units and explanations ) \"\"\" prompt = instruction . format ( question = question ) return prompt Listing 1: Direct Solver Prompt Template B.2 Dependency Annotation def label ( question : str , result : dict ): instruction = \"\"\" For the original question : { question }, We have broken it down into the following subquestions : subquestions : { result [\" subquestions \"]} And obtained complete reasoning process for the original question : { result [\" response \"]} We define the dependency relationship between subquestions as : which information in the current subquestion description does not come directly from the original question , but from the results of other subquestions . You are math question solver specializing in analyzing the dependency relationships between these subquestions . Please return JSON object that expresses complete reasoning trajectory for the original question , including the description , answer , and dependency relationships of each subquestion . The dependency relationships are represented by the indices of the dependent subquestions in subquestions , starting from zero . \"\"\" formatter = ''' Format your response as the following JSON object : { \" thought \": \" Give your thought process here \", \" subquestions \": [ for , sub_q in enumerate ( result [\" subquestions \" ]) : formatter += ''' {{\" description \": \"{ sub_q }\" , \" answer \": \"< the answer of this subquestion >\" , \" depend \": [< indices of the dependent subquestions >, ...]}} ''' if != len ( result [\" subquestions \" ]) - 1: formatter += \" ,n\" else : formatter += \" ] }\" return instruction + formatter Listing 2: Dependency Annotation Prompt Template B.3 Subquestions Contracting def contract ( question : str , decompose_result : dict , independent : list , dependent : list ): instruction = \"\"\" You are math question solver specializing in optimizing step -by - step reasoning processes . Your task is to optimize the existing reasoning trajectory into more efficient , single self - contained question . For the original question : { question } Here are step -by - step reasoning process : { response } The following subquestions and their answers can serve as known conditions : { independent } The descriptions of the following questions can be used to form the description of the optimized question : { dependent } Here are explanations of key concepts : 1. self - contained : The optimized question must be solvable independently , without relying on any external information 2. efficient : The optimized question must be simpler than the original , requiring fewer reasoning steps and having clearer reasoning process ( these steps are reduced because some solved subquestions become known conditions in the optimized question or are excluded as incorrect explorations ) You can freely reason in your response , but please enclose the your optimized question within < question > </ question > tags \"\"\" for sub_q in independent : sub_q . pop (\" depend \" , None ) for sub_q in dependent : sub_q . pop (\" depend \" , None ) return instruction . format ( question = question , response = decompose_result [\" response \"], independent = independent , dependent = dependent ) \" description \": \" Is Ajuga genus ?\" , \" supporting_sentences \" : [ \" Ajuga , also known as bugleweed , ground pine , carpet bugle , or just bugle , is genus of 40 species annual and perennial herbaceous flowering plants in the mint family Lamiaceae ... \" ], \" answer \": \" yes \" } ], \" conclusion \" : \" Both are genera .\" , \" answer \": \" yes \" , \" f1 \": } Listing 4: Destruction of Parallelism Example Contracted decomposition (showing parallelism destruction): { \" question \": \" Are both Cypress and Ajuga genera ?\" , \" subquestions \" : [ Listing 3: Subquestions Contracting Prompt Template {"
        },
        {
            "title": "C Case study",
            "content": "C.1 The illusion phenomenon when contracting subquestions Destruction of Parallelism When solving complex questions through decomposition, parallel subquestions should maintain their independence. However, parallelism can be destroyed when merging results, as illustrated by this example: Original decomposition: { \" question \": \" Are both Cypress and Ajuga genera ?\" , \" groundtruth \": \" no \" , \" thought \": \" To determine if both Cypress and Ajuga are genera , need to consider each term separately .\" , \" subquestions \": [ { \" description \": \" Is Cypress genus ?\" , \" supporting_sentences \": [ \" Cypress is conifer tree or shrub of northern temperate regions that belongs to the family Cupressaceae .\" , \" The genus Cupressus is one of several genera within the family Cupressaceae ... \" ], \" answer \": \" yes \" }, { \" description \": \" Is Cypress genus ?\" , \" supporting_sentences \" : [ \" Cypress is conifer tree or shrub of northern temperate regions that belongs to the family Cupressaceae . \" ], \" answer \": \" yes \" }, { \" description \": \" Cypress is genus , Is Ajuga genus ?\" , \" answer \": \" yes \" } ], \" f1 \": } Listing 5: Destruction of Parallelism Example The destruction of parallelism is manifested in that the answers to the questions after contraction cannot be used to answer the original question, but instead create an illusion of answering certain subquestion."
        },
        {
            "title": "Destruction of Independence",
            "content": "When subquestions have dependencies, maintaining independence in the analysis chain is crucial. Loss of independence occurs when the relationship between dependent subquestions is not properly maintained during contraction, as shown in this example: Original decomposition: { { \" question \": \" What is the name of the executive producer of the film that has score composed by Jerry \" description \": \" Which films have scores by Jerry Goldsmith ?\" , \" answer \": [ Goldsmith ?\" , \" groundtruth \": \" Ronald Shusett \" , \" thought \": \" First identify films with Goldsmith scores , then find their executive producers .\" , \" subquestions \": [ { \" description \": \" Identify films with scores composed by Jerry Goldsmith \" , \" supporting_sentences \": [ \" The iconic score to ' Alien ' was composed by Jerry Goldsmith \" , \"L.A. Confidential 's score was composed by Jerry Goldsmith \" , \" Innerspace , with music composed by Jerry Goldsmith \" , \" Lionheart 's score by Jerry Goldsmith \" ], \" answer \": [ \" Alien \" , \"L.A. Confidential \" , \" Innerspace \" , \" Lionheart \" ] }, { \" description \": \" Determine the executive producer for each identified film \" , \" supporting_sentences \": [ \" Alien : Shusett was executive producer \" , served as executive producer \" , \" Innerspace : Spielberg \"L.A. Confidential : No executive producer mentioned \" , \" Lionheart : Coppola as executive producer \" ], \" answer \": [ \" Ronald Shusett \" , \" Steven Spielberg \" , \" Francis Ford Coppola \" ] } ], \" f1 \": 0 } Listing 6: Destruction of Independence Example Contracted decomposition (showing independence destruction): { \" question \": \" What is the name of the executive producer of the film that has score composed by Jerry Goldsmith ?\" , \" subquestions \": [ \" Alien \" , \"L.A. Confidential \" , \" Innerspace \" , \" Lionheart \" ] }, { \" description \": \" Who is the executive producer ?\" , \" answer \": \" Steven Spielberg \" } ], \" f1 \": 0 } Listing 7: Destruction of Independence Example Independence destruction is reflected in the fact that the second subquestion, after contraction, lost its dependency on the answer to the first subquestion, directly producing an independent answer instead of determining the executive producer based on the list of movies found from the first subquestion. This led to final answer that deviated from the original questions requirements and failed to accurately identify the executive producer of films scored by Jerry Goldsmith. C.2 Example of AOT Reasoning Process"
        },
        {
            "title": "Question Statement",
            "content": "For given constant > 10, there are two possible triangles ABC satisfying AB = 10, AC = b, and sin = 3 5 . Find the positive difference between the lengths of side BC in these two triangles. 5 . For cos = 4 Ground Truth We have that cos2 = 1 sin2 = 16 25 , so cos = 4 5 , let a1 = BC. Then 1 + 100 20a1 4 by the Law of Cosines, b2 = a2 5 = 1 16a1 + 100. For cos = 4 a2 5 , let a2 = BC. Then by the Law of Cosines, b2 = a2 2 + 100 20a2 (cid:0) 4 2 + 16a2 + 100. Subtracting these 5 equations, we get a2 1 + 16a2 + 16a1 = 0. We can factor as (a2 a1)(a2 +a1)+16(a2 +a1) = 0. Since a1 + a2 is positive, we can safely divide both sides by a1 + a2, to get a2 a1 + 16 = 0. Hence, a1 a2 = 16 . (cid:1) = a2 2 a2 LLM Input-Output Solution To find the lengths of side BC in the two possible triangles ABC given AB = 10, AC = b, and sin = 3 5 , we will employ the Law of Sines. From the Law of Sines, we know: sin = sin = sin angles corresponding to the two triangles possible due to the ambivalence in triangle formation. When considering these angles, the two possible values arise from: where a, b, and are the sides opposite angles A, B, and C, respectively. In our triangle, we assign AB = = 10, AC = b, BC = a, and sin = 3 5 . The Law of Sines gives us: sin = 10 sin From which we can write: = 10 sin sin Since sin = 3 5 , we can substitute: = 10 sin 3 = 10 5 sin 3 = 50 sin 3 Using the Law of Sines again for side b: sin = sin We have: 3 5 Rearranging gives: = sin b sin = 3 5 From the triangles cosine rule: a2 = b2 + 102 2 10 cos Using the sine identity sin2 + cos2 = 1, we get: cos = (cid:112) 1 sin2 = (cid:115) 1 (cid:19) (cid:18) 3 5 = 4 5 Substituting into the cosine rule: a2 = b2 + 100 2 10 4 Calculating 2 10 4 5 = 16b, we get: a2 = b2 + 100 16b = b2 16b + 100 We have the equation = 50 sin . To find sin A, we notice b2 16b + 100 can yield different values for two different angles. Let A1 and A2 be the sin A1 = 3A1 5 and similarly for the alternate A2. The key observation is that both values yield values symmetric around 10. The two sides will be exactly equal distances away from midpoint. Using numeric approximations where = 11, = 12, etc., leads to side length differences. Final calculation yields: a2 a1 = c2 + c1 = 6 Therefore, the positive difference between the lengths of side BC in these two triangles is 6 . Decomposition-Only Solution Q1: What are the known values and definitions for triangle ABC? A: In triangle ABC: AB = 10, AC = (where > 10), sin = 3 5 . For the derivation of cos B: Since sin = 3 5 , using the Pythagorean identity: sin2 + cos2 = 1 ( 3 5 )2 + cos2 = 1 9 + cos2 = 1 9 25 = 16 25 cos2 = 1 cos = 4 5 Q2: How to express sin in terms of using the Law of Sines? A: sin = 3b 50 . Q3: How do we determine the lengths of side BC using the Law of Sines? A: BC1 = 100 . Q4: Are there different cases for angle that affect the length of BC? A: No, both acute and obtuse angles give the same result due to the symmetry of sine. Q5: What is the positive difference between the lengths of side BC in the two triangles? A: 0. Final Answer:"
        },
        {
            "title": "Error Analysis",
            "content": "and factoring: In the Direct Solution, the key error lies in only considering cos = 4 5 while missing cos = 4 5 , leading to just one triangle configuration instead of two and eventually an incorrect conclusion of 6. In the Decomposition Solution, despite breaking down the question into subquestions, the crucial mistake was concluding that angles give \"the same result due to the symmetry of sine\" when in fact the Law of Cosines with different cos values leads to distinct triangle configurations whose BC lengths differ by 16. AOT Reasoning Process First initialize the origin question as Q0. Decomposition of Q0: Q: What are the values of the known sides triangle ABC? A: AB = 10. Q: What boundary conditions are known? A: AC = > 10. Q: It is known that sin = 3 5 in triangle ABC, so what is the value of cos B? A: Use the Pythagorean identity, cos = 4 5 . Contracted Question Q1: Given two triangles ABC satisfying AB = 10, AC = > 10, sinB = 3/5, cosB = 4/5 respectively, find the positive difference between the lengths of side BC. Decomposition of Q1: Q: Given that in triangle ABC, cos = 4 5 , AC = b, AB = 10, let BC = a1, find the equation of these two variables. A: b2 = a2 1 + 100 20a1 4 1 16a1 + 100 5 = a2 Q: Given that in triangle ABC, cos = 4 5 , AC = b, AB = 10, let BC = a1, find the equation of these two variables. A: b2 = a2 2 + (cid:1) = a2 100 20a2 (cid:0) 4 2 + 16a2 + 100. 5 (a1 a2)(a1 + a2) = 16(a1 + a2). Dividing by a1 + a2: a1 a2 = 16. Thus, the positive difference between a1 and a2 is 16. Final Answer: 16 ."
        },
        {
            "title": "D Implementation Details",
            "content": "D.1 Data Subset Selection For the BBH dataset, we select all multiple-choice subsets to evaluate the models logical reasoning capabilities. The selected subsets include temporal sequences, salient translation error detection, penguins in table, snarks, ruin names, date understanding, hyperbaton, logical deduction (with three, five, and seven objects), movie recommendation, geometric shapes, disambiguation QA, and reasoning about colored objects. These subsets cover diverse range of logical reasoning tasks, from temporal and spatial reasoning to deductive logic and error detection. selected_sets = [ ' temporal_sequences ' , ' salient_translation_error_detection ' , ' penguins_in_a_table ' , ' snarks ' , ' ruin_names ' , ' date_understanding ' , ' hyperbaton ' , ' logical_deduction_five_objects ' , ' movie_recommendation ' , ' logical_deduction_three_objects ' , ' geometric_shapes ' , ' disambiguation_qa ' , ' logical_deduction_seven_objects ' , ' reasoning_about_colored_objects ' ] Listing 8: BBH Subset Selection Contracted Question Q1: Given two triangles ABC satisfying AB = 10, AC = > 10, sinB = 3/5, cosB = 4/5 respectively, find the positive difference between the lengths of side BC. Solution of Q2: Equating the two expressions for b2: 1 16a1 = a2 a2 2 + 16a2, D.2 Forest of Thoughts In our implementation, we utilize the classical Tree of Thoughts (ToT) approach as the fundamental tree structure in our Forest of Thoughts framework, while maintaining several critical mechanisms from the original FoT, including majority voting for aggregating results across different trees and expert evaluation for assessing solution quality. However, our implementation differs from the original FoT in certain aspects as we address broader range of questions. Specifically, we remove its early stopping criteria. The original FoT terminates tree splitting when nodes cannot produce valid outputs, which is particularly effective for mathematical questionsolving like Game-of-24 where rule-based validation is straightforward. However, for our diverse use cases where output validity is less clearly defined, we maintain tree expansion regardless of intermediate output quality, allowing the framework to explore potentially valuable paths that might initially appear suboptimal. The Input Data Augmentation technique is also omitted since such analogical reasoning approach does not demonstrate consistent effectiveness across different types of questions. These modifications allow the Forest of Thoughts framework to maintain the strengths of FoT while being more adaptable to wider range of question domains. The implementation not only successfully reproduces the scaling curves reported in the original FoT paper but also achieves superior performance across multiple benchmarks. D.3 AFlow In our implementation, we leverage the optimal workflows identified by AFlow across different benchmark datasets while adapting them to suit our specific requirements. For mathematical reasoning tasks on MATH and GSM8k datasets, we directly adopt AFlows established optimal workflows, which have demonstrated strong performance in these domains. Similarly, for multi-hop reasoning scenarios in LongBench, we utilize the workflow originally optimized for HotpotQA, as both datasets share fundamental multi-hop reasoning characteristics. For knowledge-intensive evaluation on MMLU-CF and logical reasoning tasks on BBH, which were not covered in the original AFlow paper, we conducted new workflow search (consistent with the settings in the original paper) to identify the most effective approach, resulting in specialized workflows optimized for these formats."
        }
    ],
    "affiliations": [
        "DeepWisdom",
        "Renmin University of China",
        "The Hong Kong University of Science and Technology (Guangzhou)"
    ]
}