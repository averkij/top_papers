{
    "paper_title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
    "authors": [
        "Shuzhou Yuan",
        "Michael Färber"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Concerns about hallucinations in Large Language Models (LLMs) have been raised by researchers, yet their potential in areas where creativity is vital, such as drug discovery, merits exploration. In this paper, we come up with the hypothesis that hallucinations can improve LLMs in drug discovery. To verify this hypothesis, we use LLMs to describe the SMILES string of molecules in natural language and then incorporate these descriptions as part of the prompt to address specific tasks in drug discovery. Evaluated on seven LLMs and five classification tasks, our findings confirm the hypothesis: LLMs can achieve better performance with text containing hallucinations. Notably, Llama-3.1-8B achieves an 18.35% gain in ROC-AUC compared to the baseline without hallucination. Furthermore, hallucinations generated by GPT-4o provide the most consistent improvements across models. Additionally, we conduct empirical analyses and a case study to investigate key factors affecting performance and the underlying reasons. Our research sheds light on the potential use of hallucinations for LLMs and offers new perspectives for future research leveraging LLMs in drug discovery."
        },
        {
            "title": "Start",
            "content": "Shuzhou Yuan , Michael Farber Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI), Germany Dresden University of Technology, Germany {shuzhou.yuan, michael.faerber}@tu-dresden.de 5 2 0 2 3 2 ] . [ 1 4 2 8 3 1 . 1 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Concerns about hallucinations in Large Language Models (LLMs) have been raised by researchers, yet their potential in areas where creativity is vital, such as drug discovery, merits exploration. In this paper, we come up with the hypothesis that hallucinations can improve LLMs in drug discovery. To verify this hypothesis, we use LLMs to describe the SMILES string of molecules in natural language and then incorporate these descriptions as part of the prompt to address specific tasks in drug discovery. Evaluated on seven LLMs and five classification tasks, our findings confirm the hypothesis: LLMs can achieve better performance with text containing hallucinations as part of the input compared to prompts without hallucination or with reference description text. Notably, Llama-3.1-8B achieves an 18.35% gain in ROC-AUC compared to the baseline without hallucination. Furthermore, hallucinations generated by GPT-4o provide the most consistent improvements across models. Additionally, we conduct empirical analyses and case study to investigate key factors affecting performance and the underlying reasons. Our research sheds light on the potential use of hallucinations for LLMs and offers new perspectives for future research leveraging LLMs in drug discovery."
        },
        {
            "title": "1 Introduction\nLarge Language Models (LLMs) have not only been exten-\nsively applied in daily life to address real-world tasks [Ge\net al., 2023; Yao et al., 2024], but also increasingly utilized\nas tools or agents in scientific domains, including materi-\nals science [Zhang et al., 2024b], biology [Madani et al.,\n2023] and chemistry [Boiko et al., 2023; Zhang et al., 2024a].\nHowever, LLMs often generate plausible yet incorrect factual\ninformation or unrelated content in reference to the source\ntext [Huang et al., 2023; Bang et al., 2023; Yuan and Faerber,\n2023]. The issue of hallucination has raised major concerns\nin the NLP community regarding their reliability and appli-\ncability [Rawte et al., 2023]. While various methods have\nbeen proposed to mitigate hallucinations in LLMs [Dhuli-\nawala et al., 2024; Ji et al., 2023], a novel perspective sug-",
            "content": "Figure 1: Factual consistency scores evaluated using the HHEM2.1-Open Model, which measures the degree of hallucination relative to the reference descriptions generated by MolT5. The scores represent the average across five datasets used in this work (see 5.1). With the exception of ChemLLM, all other LLMs achieve scores below 10%, indicating high level of hallucination when generating natural language descriptions of molecules. gests that hallucinations may contribute to fostering creativity [Lee, 2023; Wang, 2024]. As creativity extends beyond merely retrieving information to include recombining and expanding existing knowledge, it closely resembles hallucination [Ye et al., 2023]. This creativity is vital in drug discovery, where exploring vast chemical spaces and devising innovative solutions to complex biological challenges are indispensable. The process of drug discovery involves evaluating vast number of potential drugs and requires long-term experimental trials, making it highly time-consuming and expensive [Gaudelet et al., 2021]. Prior work has leveraged machine learning to assist with this process [Rifaioglu et al., 2018; Mak et al., 2024], and generative models have also been utilized to facilitate drug discovery [Chakraborty et al., 2023; Murakumo et al., 2023]. Additionally, researchers have discovered that textual descriptions in chemistry can improve models generalization ability [Liu et al., 2023]. As discovering new drugs requires domain-specific knowledge and the creativity to identify new patterns, hallucination becomes potential strength for discovering molecules with high-level functions and abstract properties [Edwards et al., 2024a]. Researchers have started exploring the potential of LLMs Figure 2: Illustration of the evaluation method with an example molecule from the HIV dataset: 1. We use LLMs to generate textual description of the molecule based on its SMILES string. 2. The generated text, which contains hallucinations, is added to the prompt, and the LLM is tasked with predicting the specific property of the molecule. The answer is constrained to Yes or No to evaluate the LLMs performance. We highlight obvious hallucinations that are unrelated to the input using colors. for tasks such as drug generation [Pal et al., 2023]. Edwards et al. [2022, 2024b] used language models to generate descriptions of molecules as first step toward leveraging AI for higher-level control over molecule design, studying the connection between molecules and natural language. While this approach helps researchers study and understand molecular structures through natural language, LLMs without domainspecific fine-tuning often generate text with hallucinations. As shown in Figure 1, we use LLMs to generate descriptions of molecules and compare them with reference descriptions generated by the domain-specific model MolT5 [Edwards et al., 2022]. The factual consistency is notably low, indicating that LLMs hallucinate extensively. However, these hallucinated descriptions may still provide valuable insights that help LLMs differentiate between molecules and support drug discovery. For instance, they might include high-level descriptions of the molecule, potential applications of the compounds, and other relevant information. We acknowledge that the exploration of leveraging hallucination, rather than mitigating it, remains unexplored. Thus, we propose the hypothesis that hallucinations can improve LLMs in drug discovery. As LLMs are sensitive to prompts, subtle change can result in entirely different outputs [Sclar et al., 2024]. Regarding the connections between language and molecules, we assume that the prompt text is of paramount importance for LLMs performance in drug discovery. To verify our hypothesis and investigate the effects of hallucinations on LLMs in drug discovery, we design comprehensive experiments that involve modifying the prompt formatting and input to the LLMs. As shown in Figure 2, we first use LLMs to generate textual descriptions of molecules based on their SMILES al., 2024], Falcon3-Mamba-7B [Zuo Ministral-8B et strings [Weininger, 1988]. We then add the text descriptions, along with the SMILES strings of molecules, to the models input and provide task-specific instructions to predict whether molecule possesses specific function, such as antiviral properties or toxicity, depending on the dataset. For comparison, we use MolT5 to translate molecules into natural language [Edwards et al., 2022] as the reference description. In our study, we evaluate seven instructiontuned LLMs: Llama-3-8B, Llama-3.1-8B [Dubey et [MistralAI, al., 2024], 2024], ChemLLM-7B [Zhang et al., 2024a], GPT-3.5, and GPT-4o [Achiam et al., 2023]. The results confirm our hypothesis and show that LLM-generated hallucinations can improve models for drug discovery tasks. Notably, Llama-3.1-8B achieves an 18.35% gain in ROC-AUC compared to the SMILES baseline and 13.79% gain compared to the MolT5 baseline. Furthermore, hallucinations generated by GPT-4o provide the greatest average improvement across models. We also investigate additional factors that potentially affect hallucination and model performance, namely model size, generation temperature, and the language of the LLM-generated hallucinations. While generation temperature has minimal impact on the observed improvements, model size plays significant role, with larger models demonstrate greater potential for improvement with hallucinations. Additionally, generating hallucinations in other languages reveals that hallucinations in Chinese yield the most significant improvement compared to five other languages. Last but no least, we conduct case study to analyze why hallucinated text improves LLMs by examining attention scores. Our findings reveal that hallucinations contain unrelated yet faithful information, such as suggestions for the molecules potential usage, which may inadvertently assist LLMs in making predictions. In summary, our contributions are threefold: We conduct the first systematic investigation into how hallucinations affect LLMs in drug discovery, providing valuable insights for future research on harnessing LLMs for pharmaceutical innovation. By evaluating seven instruction-tuned LLMs, we validate the hypothesis that hallucinations can enhance LLM performance in drug discovery tasks. Through empirical experiments and case study, we examine the factors that influence hallucinations, assess their impact on performance, and uncover the reasons behind this phenomenon."
        },
        {
            "title": "2 Related Work\nLLMs for Drug Discovery Many researchers have recog-\nnized the potential of LLMs and generative AI in drug dis-\ncovery and medical domains [Pal et al., 2023; Murakumo et\nal., 2023; Chakraborty et al., 2023; Savage, 2023]. Zheng\net al. [2024] reviewed the role of LLMs in various stages of\ndrug discovery pipelines, while Guan and Wang [2024] dis-\ncussed the advantages and applications of LLMs in drug de-\nvelopment. Zhong et al. [2024] evaluated LLMs on a range\nof molecule prediction tasks. More specifically, while some\nresearchers worked on LLM multi-agent frameworks for AI-\naided drug discovery tasks [Liu et al., 2024], others explored\nthe use of LLMs, such as GPT-4o, to curate datasets for drug-\ninduced toxicity [Liu et al., 2024]. Prompt-based methods\nhave also been applied to generate natural language explana-\ntions for cancer drug discovery [Zhang et al., 2024c]. Also,\nthe connection between SMILES strings and natural language\nhas been widely studied using language models [Edwards et\nal., 2022; Ganeeva et al., 2024]. In the era of LLMs, these\nmodels are primarily used as agents to assist in drug discov-\nery [Fossi et al., 2024]. Building on previous work that pri-\nmarily investigates the role of LLMs and their potential to\nassist in the drug discovery domain, our study goes further by\nnot only evaluating the capabilities of LLMs but also explor-\ning their novel integration with hallucinations in drug discov-\nery.",
            "content": "Hallucination and Creativity in LLMs LLMs often generate false or unrelated outputs with respect to the source [Maynez et al., 2020; Rawte et al., 2023; Ye et al., 2023], and researchers have proposed various methods to mitigate hallucinations [Dhuliawala et al., 2024; Manakul et al., 2023; Li et al., 2023; Shi et al., 2023; Ji et al., 2023]. However, with growing attention on the creativity of artificial intelligence [Lee, 2022; Zhao et al., 2024], investigating creativity in LLMs has also captured public interest [Chen and Ding, 2023]. Lu et al. [2024] proposed framework to enhance the creativity of LLMs, while Gomez-Rodrıguez and Williams [2023] evaluated the creative writing capabilities of LLMs. Franceschelli and Musolesi [2024] explored the creativity of LLMs and analyzed their societal impact on the creative industries. At the same time, hallucination has been regarded as form of creativity in LLMs as Jiang et al. [2024] considered hallucination not merely as negative phenomenon but also as potential driver of creativity. They examined the interplay between hallucination and creativity through cognitive science and neuroscience perspectives. For instance, Alexander Flemings accidental discovery of penicillin exemplifies how unintended outcomes can lead to groundbreaking innovations. This illustrates how both factual and faithfulness hallucinations can play pivotal role in fostering creativity. Additionally, mathematical analysis reviewed the relationship between hallucination and creativity in LLMs based on probability and information theory [Lee, 2023]. Building on the established connection between hallucination and creativity, we are the first to explore the impact of hallucinations on LLMs in drug discovery."
        },
        {
            "title": "Generation",
            "content": "Translating molecules into natural language has been shown in prior research to offer significant benefits across range of scientific domains [Edwards et al., 2022]. As illustrated in Figure 2: Hallucination Generation, we translate molecules represented as SMILES strings into natural language. To generate description for given molecule, we provide the model with SMILES string and ask it to generate descriptive text using the same prompt template across all datasets. Additionally, we define the system role as an expert in drug discovery: System: You are an expert in drug discovery. User: [SM ILES] Describe the molecule in natural language: To evaluate the generated text and verify whether it contains hallucinations, we use HHM-2.1-Open Model [Bao et al., 2024] to assess the factual consistency between the LLMgenerated descriptions and the translations from MolT5 [Edwards et al., 2022]. MolT5 is pre-trained and fine-tuned model leveraging extensive molecule-text pairs. We consider the text generated by MolT5 as the reference description. As shown in Figure 1, the descriptions generated by most LLMs exhibit low factual consistency compared with the references produced by MolT5. Even for ChemLLM, which is pre-trained with extensive chemical knowledge, achieves score of 20.89%. Other models display average scores ranging from 7.42% to 13.58%, indicating that LLMs generate significant hallucinations when translating SMILES strings into natural language. Since we do not impose further constraints during the translation process, all generated hallucinations are in English under the default setting."
        },
        {
            "title": "4 Task Formulation for Drug Discovery\nWe formulate the drug discovery task as a classification task\nto predict whether a molecule possesses a specific property or\nability relevant to a target disease or function, e.g., the abil-\nity to inhibit HIV virus replication. To better align with the",
            "content": "requirements of LLMs, we cast the classification task as next-token prediction problem."
        },
        {
            "title": "Given a molecule represented as a SMILES string\nlanguage\nand its description in natural\ntemplate with",
            "content": "[SM ILES] [Description], we construct prompt the task instruction [Instruct]: System: You are an expert in drug discovery. User: [SM ILES] [Description] [Instruct] As shown in Figure 2: Label Prediction, the LLM processes the input and generates the next token as the predicted label ˆy. We constrain the output vocabulary space by instructing the model to only answer Yes or No for binary classification tasks. The predicted label is determined by selecting the token with the highest probability: ˆy = arg max yV Pϕ(y) (1) where Pϕ(y) represents the generative probability from the LLM, and is the vocabulary space for the labels, defined as = {Yes, No} in binary classification tasks. Details of the different settings for [Description] are elaborated in 5."
        },
        {
            "title": "5 Experiment Design",
            "content": "BBBP includes binary labels indicating the blood-brain barrier penetration (permeability) of molecules. Clintox labels drugs based on whether they failed clinical trials due to toxicity. SIDER, called the Side Effect Resource, is database of marketed drugs and adverse drug reactions, grouping drug side effects into 27 system organ classes. Tox21 measures the toxicity of compounds on 12 different targets. Data Split We follow the split strategies outlined by Wu et al. [2018] to divide the datasets. HIV and BBBP are split using scaffold splitting, which partitions the samples based on their two-dimensional structures [Bemis and Murcko, 1996]. Clintox, SIDER, and Tox21 are split randomly. For all datasets, we allocate 10% of the entire dataset as the test set. Label Selection and Evaluation We use the original labels of HIV, BBBP, and Clintox, as these are binary classification tasks that measure whether the input molecule possesses specific ability or not. To follow the same setting, we select the label with the most balanced distribution in the test set for SIDER and Tox21, as they contain multiple labels. For SIDER, we test whether the molecule causes the side effect of reproductive system and breast disorders. For Tox21, we test whether the molecule shows evidence of activity against matrix metalloproteinases (SR-MMP). We evaluate model performance using ROC-AUC, following Wu et al. [2018]. We investigate how hallucinations from different LLMs template for affect model performance. represented as the user [SM ILES][Description][Instruct], while varying the [Description] component under different settings. We establish the following baselines: remains consistent with 4, The prompt SMILES: The [Description] is set to ϵ, an empty string, so the model makes predictions solely based on the SMILES string of the molecule. MolT5: The [Description] is set to the description of the molecule generated by MolT5, allowing the LLM to access both the molecular structure and reference description of the molecule in natural language. LLMs: Beyond the baselines, we evaluate how hallucinations generated by different LLMs influence performance. For each LLM, we generate textual description of the molecule and replace [Description] with text containing hallucinations generated from itself or other LLMs. Specifically, [Description] is replaced with the hallucinated text generated by the same LLM for the label prediction, or with hallucinated text generated by other LLMs under the same conditions. This setup enables us to assess how performance changes with hallucinations produced by various models."
        },
        {
            "title": "5.1 Dataset\nWe select five datasets from the MoleculeNet benchmark [Wu\net al., 2018]. The selected datasets are related to classify-\ning and inferring the ability of molecules regarding biophys-\nical and physiological features. They focus on determining\nif the input molecule exhibits certain properties in the hu-\nman body. HIV is a dataset containing molecules experi-\nmentally measured for their ability to inhibit HIV replication.",
            "content": "for Except"
        },
        {
            "title": "6 Main Results and Analysis\nWe conduct our main experiments to investigate the follow-\ning:",
            "content": "i) whether adding hallucinations to the prompt improves the performance of LLMs compared to prompts containing only the SMILES string or reference descriptive text and ii) which LLM-generated hallucinations lead to the greatest improvement. Can Hallucination Improve LLMs? We report the main results in Table 1, showing the performance of the two baselines and one hallucinated text that brings the most improvement for each LLM.1 When comparing the average per1The full results of each LLM on all hallucinated texts generated by the LLMs are available in the Appendix E. Model [Description] HIV BBBP Clintox SIDER Tox21 Avg SMILES MolT5 Llama-3-8B Llama-3.1-8B Ministral-8B Falcon3-Mamba-7B ChemLLM-7B GPT-3.5 GPT-4o SMILES MolT5 Ministral SMILES MolT5 GPT-3.5 SMILES MolT5 GPT-4o SMILES MolT5 GPT-4o SMILES MolT5 GPT-4o SMILES MolT5 GPT-4o SMILES MolT5 GPT-4o 67.78 47.65 55.09 38.10 43.04 64.66 59.35 44.54 51.66 40.64 49.02 51.59 55.54 50.33 52.68 61.32 49.34 49. 47.19 41.73 53.30 53.08 59.65 61.13 37.56 45.30 47.20 48.87 44.10 64.94 48.33 47.92 55.73 38.69 41.01 55. 28.94 52.64 34.61 46.79 40.57 52.73 63.04 43.20 63.84 35.30 39.28 73.19 60.19 53.95 58.73 31.72 18.58 53. 24.02 35.43 40.74 63.90 64.30 60.83 40.00 38.09 57.12 61.79 61.14 57.56 52.70 52.06 55.57 57.27 63.83 60. 52.53 55.84 56.03 47.85 53.06 44.59 53.77 56.00 62.41 52.30 65.22 47.82 60.34 61.73 55.41 44.89 51.72 59. 57.42 59.02 61.07 47.45 48.27 51.54 65.59 61.50 62.63 61.92 60.39 65.36 63.25 53.42 65.34 61.21 54.68 58. 41.71 46.28 60.07 56.62 53.09 59.39 44.13 43.93 53.69 46.34 48.27 51.28 53.97 56.53 54.57 49.91 47.80 55. - -6.53 -2.60 - 4.57 18.35 - -3.53 2.77 - -0.21 9.55 - 1.93 4.94 - 2.56 0. - -2.10 5.35 6.53 - 3.93 -4.57 - 13.79 3.53 - 6.30 0.21 - 9.76 -1.93 - 3. -2.56 - -1.96 2.10 - 7.46 Table 1: The main results (ROC-AUC &) for the LLMs. Only the hallucinations that result in the most improvement for each LLM are included in the table. [Description] represents the description from the baseline SMILES, MolT5, or hallucinations generated by the LLMs. SMILES and MolT5 denote the difference in average ROC-AUC scores compared to the baselines SMILES and MolT5, respectively, using the same LLM. We highlight the best results across all the LLMs in bold. formance against the baseline SMILES, all LLMs except Llama-3-8B achieve better average performance with hallucinations than with only the SMILES string, where no descriptive text is provided. Similarly, compared to the baseline Gold, all LLMs except GPT-3.5 perform better with hallucinations than with the gold reference provided as input. Among all the LLMs, Llama-3.1-8B demonstrates the highest improvement when using hallucinations generated by GPT-3.5, achieving 18.35% better performance than the SMILES baseline and 13.79% better than the Gold baseline. Additionally, Falcon3-Mamba-7B also surpasses the baselines by nearly 10%. From these results, we conclude that hallucinations can improve LLMs in drug discovery. The category of the LLM does not play significant role, as domain-specific models like ChemLLM also benefit from hallucinations. Which LLM Generates the Most Beneficial Hallucinations for Drug Discovery? We further investigate which LLM-generated hallucinations bring the greatest benefits to LLMs in drug discovery. Figure 3 shows the average improvement across all the LLMs we used when leveraging hallucinations generated by different models. The model names denote the sources of the hallucinations. We can see that hallucinations generated by OpenAI models provide the most significant improvements. In particular, hallucinations from GPT-4o increase model performance by an average of 4.07% and 4.54% compared to the SMILES and MolT5 baselines, respectively. Similarly, hallucinations generated by GPT-3.5 yield average performance Figure 3: Overall average improvement across seven LLMs using hallucinations generated by different models compared to the baselines. The x-axis indicates the source model for the generated hallucinations. gains of 1.6% and 2.08%. Additionally, text generated by Llama-3 and Ministral improves model performance by approximately 1%. However, hallucinations generated by Falcon3-Mamba and Llama-3.1 lead to performance drops of -1.65% and -0.31%, respectively, compared to the SMILES baseline. Overall, while hallucinations generated by most LLMs can improve the performance of LLMs in drug discovery, GPT-4o delivers the most significant improvements."
        },
        {
            "title": "7.1 Model Size\nModel size is a critical factor influencing the performance\nof LLMs [Dubey et al., 2024]. We evaluate four sizes of\ninstruction-tuned LLMs, namely 1B, 3B, 8B and 70B from\nLlama-32 models and compare their performance.",
            "content": "Each model is evaluated using hallucinations generated by all other models discussed in 6. We calculate the average improvement across all hallucinations relative to the baselines SMILES and MolT5. As shown in Figure 4, while all models outperform the SMILES baseline, Llama-3.2-1B is the only model that fails to surpass the MolT5 baseline. clear trend emerges: as model size increases, performance also improves gradually from the 1B to the 8B models when compared to the MolT5 baseline. Although the 70B model does not outperform the 8B model, it still achieves better results than the smaller 1B and 3B models. In contrast, comparisons with the SMILES baseline do not reveal similar trend; all models outperform it when hallucinations are included in the prompt. In summary, increasing model size enhances the influence of hallucinations, but this effect appears to plateau at model sizes around 8B. Figure 4: Average improvement for Llama-3 with different model size."
        },
        {
            "title": "7.2 Generation Temperature\nPrevious research has investigated the role of temperature in\nLLMs [Peeperkorn et al., 2024; Renze, 2024]. Temperature",
            "content": "2The 1B and 3B models are from Llama-3.2, as only Llama-3.2 provides instruction-tuned LLMs smaller than 7B. The 8B and 70B models are from Llama-3.1. Figure 5: Average performance and hallucination scores of the generated text at different temperature settings across five datasets. is key parameter that influences the generated text, controlling the randomness of the models output [Van Koevering and Kleinberg, 2024]. We use Llama-3.1-8B to generate molecule descriptions under different temperature settings: {0.1, 0.3, 0.5, 0.7, 0.9}. First, we evaluate the generated text using the hallucination score. As illustrated by the line chart in Figure 5, the average hallucination score across the five datasets shows clear trend: higher temperatures result in lower factual consistency and, consequently, higher hallucination. The models performance across different temperatures reveals general pattern where higher hallucination scores correlate with worse performance. However, there is an exception at temperature of 0.3, where the model does not perform as well compared to the temperature 0.5 and 0.7. Despite these variations, the overall performance with different temperatures does not differ significantly, ranging from 54.20% at temperature of 0.9 to 57.10% at 0.1. This may be due to the relatively small differences in hallucination scores across temperatures. As shown in Table 1, without LLM-generated hallucinations, Llama-3.1-8B achieves only 41.71% and 46.28% average ROC-AUC for the SMILES and MolT5 baselines, respectively. These scores are lower than the ROC-AUC achieved at any temperature setting. This further supports our finding that hallucinations can improve LLM performance in drug discovery. investigate whether the models performance."
        },
        {
            "title": "7.3 Language of Hallucination\nthe language of hallu-\nWe further\nTaking\ncination can affect\nLlama-3.1-8B as the base model, we modify the\n[Instruct] template to prompt the LLM to generate molecule\ndescriptions in six different languages: four languages in-\ncluded in the pretrained language list of Llama (English, Ger-\nman, French, Spanish) and two unseen languages (Chinese\nand Japanese). Prior research indicates that LLMs have mul-\ntilingual capabilities, enabling them to understand languages\neven if they were not encountered during pretraining [Nie et\nal., 2024].",
            "content": "Figure 6 presents the performance of Llama-3.1-8B with hallucinations in different languages across five datasets. charged atom negatively giving it an overall charge has potential applications in drug discovery pharmaceutical research due its unique properties Notably, the text of the example contains hallucinations, such as the obviously incorrect claim that the molecule is made up of hydrogen, despite hydrogen not being present in the molecule. Additionally, the text includes subjective and unrelated information, such as has potential application.... As attention score measures how much focus model assigns to one token when processing another, capturing their relationship in context, we highlight tokens based on their corresponding attention scores as computed by Llama-3.1-8B, where the intensity of the color reflects the strength of the attention. The attention scores reveal that, aside from stopwords, the model focuses on the hallucinated content, assigning higher attention to tokens describing the elements and structure of the molecule (e.g., carbon, hydrogen, oxygen, ring). Similarly, the phrase potential applications in drug discovery, which is unrelated yet faithful information, receives above-average attention. We hypothesize that this subjective assumption about potential usage likely increases the models confidence, thereby enhancing its overall performance in drug discovery tasks."
        },
        {
            "title": "9 Conclusion\nIn this work, we investigate whether hallucination can help\nLLMs in drug discovery. Coming up with the hypothesis that\nhallucinations can improve LLMs in drug discovery, we eval-\nuate seven LLMs across five drug discovery datasets by incor-\nporating LLM-generated hallucinations into the prompt. The\nexperimental results confirm our hypothesis: hallucinations\nenhance the performance of LLMs compared to when no hal-\nlucination is provided. Nearly all the evaluated LLMs demon-\nstrate better performance with hallucinations compared to\nwithout them.",
            "content": "We further explore factors that may influence hallucinations and the performance of LLMs. As model size increases, the improvement in LLM performance with the same hallucination shows general trend of growth. While generation temperature impacts the hallucination score, it has minimal effect on the models performance. Most notably, hallucinations in Chinese yield the highest average improvement for Llama-3.1-8B, despite Chinese not being pre-trained language for the model. Meanwhile, we conduct case study to investigate why text containing hallucinations can enhance LLM performance. We hypothesize that unrelated yet faithful information may contribute to this improvement. Our work provides new perspective on leveraging hallucinations for LLMs and highlights their potential for fostering creativity in AI. Future research could build on these findings to further investigate the effects of hallucinations and explore the underlying mechanisms in depth. Figure 6: Performance of hallucinations in six languages across all datasets using Llama-3.1-8B. Chinese achieves the highest average ROC-AUC score of 57.81%, which is surprising given that it is not included in the pretrained language list [Dubey et al., 2024]. French and English follow closely with average ROC-AUC scores of 56.21% and 55.88%, respectively. German and Spanish show moderate performance, while Japanese has the lowest average score. Upon reviewing the generated text in Chinese, we observed that much of it is written in Pinyin, romanization system for Standard Chinese, and includes extensive English explanations, which may contribute to the higher performance. Individual datasets show varying preferences for specific languages. HIV and BBBP achieve the best performance with English, while Clintox performs best with French. SIDER achieves its highest performance with German, and Tox21 yields the best results with Spanish. In summary, the language of hallucination significantly impacts model performance. While pretrained languages generally perform well, the surprising performance of Chinese highlights the potential of LLMs to leverage unseen languages effectively."
        },
        {
            "title": "8 Case Study",
            "content": "To investigate why hallucinated text generated by LLMs can improve their performance in drug discovery, we conduct case study using an example text generated by GPT-3.5 to describe the molecule. The analysis is performed with Llama-3.1-8B, as it achieves the best performance with the hallucinated text generated by GPT-3.5. We take the example molecule as SMILES string: CC1(Br)C(=O)NC(=O)N(C2CC(O)C(CO)O2)C1N=[N+]=[N-]. This molecule is compound with complex structure made up of carbon , hydrogen nitrogen oxygen and brom ine atoms . It consists central ring connected to various functional groups including carb ony The also contains positively References Josh Achiam, Steven Adler, Sandhini Agarwal, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung. multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers). 2023. Forrest Bao, Miaoran Li, Rogger Luo, Ofer Mendelevitch. HHEM-2.1-Open, 2024. Guy Bemis, Mark Murcko. The properties of known Journal of medicinal drugs. 1. molecular frameworks. chemistry, 39(15):28872893, 1996. Daniil Boiko, Robert MacKnight, Ben Kline, et al. Autonomous chemical research with large language models. Nature, 2023. Chiranjib Chakraborty, Manojit Bhattacharya, Sang-Soo Lee. Artificial intelligence enabled chatgpt and large language models in drug target discovery, drug discovery, and development. Molecular Therapy-Nucleic Acids, 2023. Honghua Chen, Nai Ding. Probing the creativity of large language models: Can models produce divergent semantic association? In Findings of the Association for Computational Linguistics: EMNLP 2023. 2023. Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, Jason Weston. Chainof-verification reduces hallucination in large language models. In Findings of the Association for Computational Linguistics: ACL 2024. 2024. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, arXiv preprint The llama 3 herd of models. et al. arXiv:2407.21783, 2024. Carl Edwards, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, Heng Ji. Translation between molecules and natural language. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022. Carl Edwards, Qingyun Wang, Heng Ji. Language + molecules. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts. 2024. Carl Edwards, Qingyun Wang, Lawrence Zhao, Heng Ji. L+M-24: Building dataset for Language+Molecules @ ACL 2024. In Proceedings of the 1st Workshop on Language + Molecules (L+M 2024). 2024. Gabriele Fossi, Youssef Boulaimen, Leila Outemzabet, Swiftdossier: Tailored automatic dossier for arXiv preprint et al. drug discovery with llms and agents. arXiv:2409.15817, 2024. Giorgio Franceschelli, Mirco Musolesi. On the creativity of large language models. AI & SOCIETY, 2024. Veronika Ganeeva, Andrey Sakhovskiy, Kuzma Khrabrov, Andrey Savchenko, Artur Kadurin, Elena Tutubalina. Lost in translation: Chemical language models and the misunderstanding of molecule structures. In Findings of the Association for Computational Linguistics: EMNLP 2024. 2024. Thomas Gaudelet, Ben Day, Arian Jamasb, et al. Utilizing graph machine learning within drug discovery and development. Briefings in bioinformatics, 22(6):bbab159, 2021. Yingqiang Ge, Wenyue Hua, Kai Mei, et al. Openagi: When llm meets domain experts. In NeurIPS. 2023. Carlos Gomez-Rodrıguez, Paul Williams. confederacy of models: comprehensive evaluation of LLMs on creative writing. In Findings of the Association for Computational Linguistics: EMNLP 2023. 2023. Shenghui Guan, Guanyu Wang. Drug discovery and development in the era of artificial intelligence: From machine learning to large language models. Artificial Intelligence Chemistry, 2024. Lei Huang, Weijiang Yu, Weitao Ma, et al. survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems, 2023. Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, Pascale Fung. Towards mitigating LLM hallucination via self reflection. In Findings of the Association for Computational Linguistics: EMNLP 2023. 2023. Xuhui Jiang, Yuxing Tian, Fengrui Hua, et al. survey on large language model hallucination via creativity perspective, 2024. Hye-Kyung Lee. Rethinking creativity: creative industries, ai and everyday creativity. Media, Culture & Society, 2022. Minhyeok Lee. mathematical investigation of hallucination and creativity in gpt models. Mathematics, 2023. Junyi Li, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, Ji-Rong Wen. HaluEval: large-scale hallucination evaluation In Proceedings benchmark for large language models. of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023. Shengchao Liu, Weili Nie, Chengpeng Wang, et al. Multimodal molecule structuretext model for text-based reNature Machine Intelligence, trieval and editing. 5(12):14471457, 2023. Sizhe Liu, Yizhou Lu, Siyu Chen, et al. Drugagent: Automating ai-aided drug discovery programming arXiv preprint through llm multi-agent collaboration. arXiv:2411.15692, 2024. Li-Chun Lu, Shou-Jen Chen, Tsung-Min Pai, et al. LLM discussion: Enhancing the creativity of large language models via discussion framework and role-play. In COLM. 2024. Ali Madani, Ben Krause, Eric Greene, et al. Large language models generate functional protein sequences across diverse families. Nature Biotechnology, 2023. Kit-Kay Mak, Yi-Hang Wong, Mallikarjuna Rao Pichika. Artificial intelligence in drug discovery and development. Drug discovery and evaluation: safety and pharmacokinetic assays, 2024. Potsawee Manakul, Adian Liusie, Mark Gales. SelfCheckGPT: Zero-resource black-box hallucination detection for In Proceedings of the generative large language models. 2023 Conference on Empirical Methods in Natural Language Processing. 2023. Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan McDonald. On faithfulness and factuality in abstractive summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020. MistralAI. Ministral-8b-instruct-2410, 2024. Kusuri Murakumo, Naruki Yoshikawa, Kentaro Rikimaru, et al. LLM drug discovery challenge: contest as feasibility study on the utilization of large language models In AI for Accelerated Materials in medicinal chemistry. Design - NeurIPS 2023 Workshop. 2023. Ercong Nie, Shuzhou Yuan, Bolei Ma, , et al. Decomposed prompting: Unveiling multilingual linguistic structure knowledge in english-centric large language models. arXiv preprint arXiv:2402.18397, 2024. Soumen Pal, Manojit Bhattacharya, Md Aminul Islam, et al. Chatgpt or llm in next-generation drug discovery and development: pharmaceutical and biotechnology companies can make use of the artificial intelligence-based device for faster way of drug discovery and development. International Journal of Surgery, 2023. Max Peeperkorn, Tom Kouwenhoven, Dan Brown, Anna Jordanous. Is temperature the creativity parameter of large language models? arXiv preprint arXiv:2405.00492, 2024. Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Amitava Das. The troubling emergence of hallucination in large language models - an extensive defIn inition, quantification, and prescriptive remediations. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023. Matthew Renze. The effect of sampling temperature on problem solving in large language models. In Findings of the Association for Computational Linguistics: EMNLP 2024. 2024. Ahmet Sureyya Rifaioglu, Heval Atas, Maria Jesus Martin, et al. Recent applications of deep learning and machine intelligence on in silico drug discovery: methods, tools and databases. Briefings in Bioinformatics, 2018. Neil Savage. Drug discovery companies are customizing chatgpt: heres how. Nat Biotechnol, 2023. Melanie Sclar, Yejin Choi, Yulia Tsvetkov, et al. Quantifying language models sensitivity to spurious features in prompt design or: How learned to start worrying about prompt formatting. In ICLR. 2024. Xiao Shi, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li. Hallucination mitigation in natural language generation from In Proceedlarge-scale open-domain knowledge graphs. ings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023. Katherine Van Koevering, Jon Kleinberg. How random is random? evaluating the randomness and humaness of llms coin flips. arXiv preprint arXiv:2406.00092, 2024. Feng Wang. Lighthouse: survey of agi hallucination. arXiv preprint arXiv:2401.06792, 2024. David Weininger. Smiles, chemical language and information system. 1. introduction to methodology and encoding rules. Journal of chemical information and computer sciences, 1988. Zhenqin Wu, Bharath Ramsundar, Evan Feinberg, et al. Moleculenet: benchmark for molecular machine learning. Chemical science, 9(2):513530, 2018. Yifan Yao, Jinhao Duan, Kaidi Xu, et al. survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing, 2024. Hongbin Ye, Tong Liu, Aijia Zhang, et al. Cognitive mirage: review of hallucinations in large language models. arXiv preprint arXiv:2309.06794, 2023. Shuzhou Yuan, Michael Faerber. Evaluating generative models for graph-to-text generation. In Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing. 2023. Di Zhang, Wei Liu, Qian Tan, et al. Chemllm: chemical large language model. arXiv preprint arXiv:2402.06852, 2024. Huan Zhang, Yu Song, Ziyu Hou, Santiago Miret, Bang Liu. HoneyComb: flexible LLM-based agent system for materials science. In Findings of the Association for Computational Linguistics: EMNLP 2024. 2024. Ke Zhang, Yimiao Feng, Jie Zheng. Prompt-based generation of natural language explanations of synthetic lethality for cancer drug discovery. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024). 2024. Yunpu Zhao, Rui Zhang, Wenyi Li, et al. Assessing and understanding creativity in large language models. arXiv preprint arXiv:2401.12491, 2024. Yizhen Zheng, Huan Yee Koh, Maddie Yang, et al. Large language models in drug discovery and development: From arXiv preprint disease mechanisms to clinical arXiv:2409.04481, 2024. trials. Zhiqiang Zhong, Kuangyu Zhou, Davide Mottin. Benchmarking large language models for molecule prediction tasks. arXiv preprint arXiv:2403.05075, 2024. Jingwei Zuo, Maksim Velikanov, Dhia Eddine Rhaiem, et al. Falcon mamba: The first competitive attention-free 7b language model. arXiv preprint arXiv:2410.05355, 2024. Details of the Models In Table 2, we list the full names and the links of the LLMs used in the work. All the open-source LLMs can be applied directly using Transformers library by Huggingface. Details of the Datasets The details, including the number of samples and the count of positive labels in each dataset are reported in Table 3. Prompt Template for Different Tasks For each task, we use different instruction as they aim for predicting different properties of molecules. C.1 HIV System: You are an expert in drug discovery. User: [SM ILES] [Description] Does the molecule have the ability to inhibit HIV replication? Only answer Yes or No: C.2 BBBP System: You are an expert in drug discovery. User: [SM ILES] [Description] Does the molecule have the ability to penetrate the blood-brain barrier? Only answer Yes or No: Full Results of Main Experiments The full results for all LLMs used in our study are presented in Table 5. Each LLM is evaluated using at least nine prompt templates: two from the baselines and seven incorporating hallucinations generated by other models. Full Results for Model Size Experiments The full results for the model size experiments are shown in Table 6. Additionally, the hallucination scores for each model size are provided in Table 7."
        },
        {
            "title": "Generation Temperature",
            "content": "Table 8 presents the complete results of Llama-3.1-8B performance when using hallucinations generated at different temperatures. Additionally, the corresponding hallucination scores are shown in Table 9."
        },
        {
            "title": "Hallucination in Different Languages",
            "content": "Algorithm 1 Generate Molecule Descriptions in Multiple Languages Require: SMILES [SM ILES], = list {English, Chinese, German, French, Japanese, Spanish} languages languages string of C.3 Clintox 1: for all lang languages do 2: prompt [SM ILES] Describe the molecule in lang Generate description using LLM with prompt 3: 4: end for"
        },
        {
            "title": "I Full Results for Experiments on Language",
            "content": "of Hallucination Table 10 presents the complete results for Llama-3.1-8B when using hallucinations generated by itself in various languages."
        },
        {
            "title": "Languages",
            "content": "We present an example of molecule alongside the textual descriptions generated by MolT5 and Llama-3.1-8B in various languages in Table 11. System: You are an expert in drug discovery. User: [SM ILES] [Description] Did the molecule fail clinical trials due to toxicity? Only answer Yes or No: C.4 SIDER System: You are an expert in drug discovery. User: [SM ILES] [Description] Does the molecule cause side effects on the reproductive system or breast? Only answer Yes or No: C.5 Tox21 System: You are an expert in drug discovery. User: [SM ILES] [Description] Does the molecule have the potential toxicity affecting mitochondrial membrane potential (SR-MMP)? Only answer Yes or No:"
        },
        {
            "title": "Description",
            "content": "We evaluate the LLMs generated description using HHM-2.1Open and report the results in Table 4. Model Full-name Link Llama-3-8B Llama-3.1-8B Ministral-8B Falcon3-Mamba-7B ChemLLM-7B GPT-3.5 GPT-4o meta-llama/Meta-Llama-3-8B-Instruct meta-llama/Llama-3.1-8B-Instruct mistralai/Ministral-8B-Instruct-2410 tiiuae/Falcon3-Mamba-7B-Instruct AI4Chem/ChemLLM-7B-Chat-1 5-DPO https://huggingface.co/AI4Chem/ChemLLM-7B-Chat-1 5-DPO gpt-3.5-turbo gpt-4o-2024-08https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct https://huggingface.co/mistralai/Ministral-8B-Instruct-2410 https://huggingface.co/tiiuae/Falcon3-Mamba-7B-Instruct - - Table 2: Details of the evaluated models, including their full names and links to their respective HuggingFace pages. Dataset Number Positive Label HIV BBBP Clintox SIDER Tox21 4113 205 148 143 175 172 11 74 108 Table 3: Summary of the datasets used, including the number of samples and the count of positive labels in each dataset. Model Llama-3.1-8B Llama-3-8B Ministral-8B Falcon3-Mamba-7B ChemLLM-7B GPT-3.5 GPT-4o HIV BBBP Clintox 7.12 7.15 14.45 8.74 20.48 8.62 8.51 7.76 8.04 13.47 9.05 17.75 8.35 7.67 8.67 7.24 14.23 8.92 23.36 6.85 8. SIDER Tox21 6.86 7.11 12.56 9.26 20.66 6.90 7.44 9.45 7.57 13.17 11.13 22.20 7.20 7.28 Avg 7.97 7.42 13.58 9.42 20.89 7.58 7.88 Table 4: The HHM-2.1 score % for LLMs across five datasets, all the models are using the same hyperparameters, e.g.: the temperature, max new tokens. [Description] HIV BBBP Clintox SIDER Tox Avg smiles MolT5 SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o 67.78 47.65 53.13 57.60 55.09 54.02 46.83 58.45 45.97 38.10 43.04 56.80 50.92 59.73 57.92 50.83 64.66 56.64 59.35 44.54 52.91 56.06 60.04 55.37 46.35 53.23 51.66 40.64 49.02 47.84 48.36 47.32 44.59 53.46 51.63 51. 55.54 50.33 56.29 57.17 61.35 57.52 45.37 57.48 52.68 61.32 49.34 52.55 55.90 55.84 52.11 50.27 58.47 49.67 47.19 41.73 48.95 53.02 55.34 54.01 53.00 47.51 53.30 53.08 59.65 58.21 51.02 61.13 51.73 60.22 46.52 53.72 37.56 45.30 47.71 42.11 50.18 51.11 52.18 47.20 53.37 48.87 44.10 31.27 46.62 46.42 50.16 48.66 36.89 64. 48.33 47.92 53.40 60.15 47.82 57.05 61.82 48.47 55.73 38.69 41.01 45.68 43.02 37.70 39.76 41.83 38.16 55.73 28.94 52.64 30.00 39.31 29.63 27.96 45.97 33.53 34.61 46.79 40.57 36.23 45.57 40.13 35.37 54.92 40.80 52.73 Llama-3-8B 63.04 43.20 57.13 39.75 63.84 43.00 52.36 57.13 54. 61.79 61.14 57.07 60.63 57.56 47.06 58.50 56.15 45.86 Llama-3.1-8B 35.30 39.28 68.08 49.97 70.01 53.22 47.45 73.19 55.28 52.70 52.06 54.21 38.11 51.65 42.38 53.17 55.57 52.60 Ministral-8B 60.19 53.95 65.49 36.23 55.34 53.62 62.11 46.85 58. 57.27 63.83 50.45 55.95 52.82 47.14 58.97 51.63 60.54 60.34 61.73 59.75 59.70 55.41 48.91 50.83 66.00 60.90 44.89 51.72 60.75 51.74 55.59 47.57 49.84 59.70 61.65 57.42 59.02 55.81 58.33 53.58 58.30 55.36 59.86 61.07 Falcon3-Mamba-7B 31.72 18.58 50.76 34.84 27.94 39.42 45.12 45.26 53. 52.53 55.84 51.31 57.60 51.90 50.10 53.56 50.98 56.03 ChemLLM-7B 24.02 35.43 47.51 28.33 39.95 29.46 42.80 51.76 40.74 47.85 53.06 44.95 43.83 37.76 44.71 53.15 41.72 44.59 GPT-3.5 63.90 64.30 38.27 41.83 39.89 54.29 63.03 44.81 60. 40.00 38.09 52.97 54.10 49.46 50.00 55.59 46.03 57.12 53.77 56.00 52.22 57.16 56.61 48.69 53.77 62.24 62.41 GPT-4o 52.30 65.22 42.73 48.71 42.44 45.83 45.36 47.27 47.82 47.45 48.27 48.44 54.26 47.54 46.64 43.43 46.73 51.54 65.59 61.50 51.59 56.96 51.64 50.18 46.60 59.37 62. 61.92 60.39 55.71 59.60 56.31 59.10 54.57 56.46 65.36 63.25 53.42 62.00 64.07 64.17 63.34 61.15 63.82 65.34 61.21 54.68 57.06 53.74 58.61 48.94 53.75 56.85 52.25 41.71 46.28 57.51 46.57 57.43 50.44 50.69 60.07 55.91 56.62 53.09 51.19 50.64 53.64 52.92 54.29 49.69 59.39 44.13 43.93 50.35 51.04 44.50 47.56 51.48 48.61 53. 46.34 48.27 49.20 45.86 45.68 44.33 45.95 49.70 51.28 53.97 56.53 45.75 50.76 47.66 48.43 53.52 51.10 54.57 49.91 47.80 48.58 53.09 50.31 49.71 54.00 49.09 55.26 0.00 -6.53 -4.15 -7.46 -2.60 -12.26 -7.46 -4.36 -8.96 0.00 4.57 15.80 4.86 15.72 8.73 8.98 18.35 14.20 0.00 -3.53 -5.43 -5.98 -2.98 -3.70 -2.33 -6.93 2. 0.00 -0.21 6.22 6.91 0.37 3.43 7.35 4.48 9.55 0.00 1.93 2.87 -0.47 -0.66 -2.01 -0.39 3.36 4.94 0.00 2.56 -8.22 -3.21 -6.31 -5.54 -0.45 -2.87 0.60 0.00 -2.10 -1.33 3.19 0.40 -0.20 4.10 -0.82 5.35 6.53 0.00 2.38 -0.93 3.93 -5.73 -0.93 2.18 -2.42 -4.57 0.00 11.23 0.29 11.15 4.16 4.41 13.79 9. 3.53 0.00 -1.90 -2.45 0.56 -0.17 1.20 -3.40 6.30 0.21 0.00 6.42 7.12 0.58 3.63 7.55 4.69 9.76 -1.93 0.00 0.94 -2.40 -2.59 -3.94 -2.32 1.43 3.01 -2.56 0.00 -10.78 -5.77 -8.88 -8.10 -3.01 -5.43 -1.96 2.10 0.00 0.77 5.29 2.50 1.90 6.20 1.28 7.46 Table 5: Full results (ROC-AUC %) for all LLMs, including hallucinations generated by each model and baselines. indicates the source of the hallucination or baseline used. [Description] [Description] HIV BBBP Clintox SIDER Tox21 Avg SMILES MolT5 SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o SMILES MolT5 Llama-3 Llama-3.1 Ministral Falcon3 ChemLLM GPT-3.5 GPT-4o 44.27 45.26 46.79 44.79 46.94 52.08 46.23 54.33 50.29 43.57 48.17 48.52 46.99 49.65 59.43 44.99 53.66 50.12 38.10 43.04 56.80 50.92 59.73 57.92 50.83 64.66 56.64 49.21 42.02 48.34 53.67 59.85 54.12 46.11 52.63 53. 32.31 38.30 47.32 50.93 42.00 58.58 44.77 45.24 60.02 40.40 45.77 32.42 40.93 47.18 44.96 44.75 32.61 42.20 37.56 45.30 47.71 42.11 50.18 51.11 52.18 47.20 53.37 39.40 42.86 47.54 43.36 60.62 40.02 59.21 47.72 62.98 Llama-3.2-1B 19.31 79.50 60.19 51.56 54.48 56.01 60.25 58.00 64. 60.79 57.95 56.23 59.09 51.94 50.55 56.35 56.01 52.88 46.88 51.42 44.25 53.73 52.71 47.14 44.19 58.94 52.10 Llama-3.2-3B 40.15 51.23 53.55 33.78 50.76 39.81 46.05 58.93 38.42 56.13 49.47 52.60 53.09 47.79 52.51 45.73 55.70 59.38 48.62 42.55 54.09 50.48 50.82 42.38 47.30 47.01 54. Llama-3.1-8B 35.30 39.28 68.08 49.97 70.01 53.22 47.45 73.19 55.28 52.70 52.06 54.21 38.11 51.65 42.38 53.17 55.57 52.60 44.89 51.72 60.75 51.74 55.59 47.57 49.84 59.70 61.65 Llama-3.1-70B 52.12 61.94 68.08 37.79 68.31 60.75 57.43 54.91 50. 45.98 54.66 45.73 56.27 51.22 43.24 50.18 52.76 56.67 47.73 48.48 50.95 48.69 48.28 53.02 48.85 44.31 53.07 40.71 54.49 50.96 52.02 49.61 52.87 50.36 54.50 55.94 45.77 47.44 48.23 45.05 49.24 47.82 45.76 49.58 48.89 41.71 46.28 57.51 46.57 57.43 50.44 50.69 60.07 55.91 46.89 49.99 52.13 47.95 57.66 50.23 52.35 50.47 55. 0.00 13.77 10.24 11.31 8.90 12.16 9.65 13.79 15.23 0.00 1.67 2.46 -0.72 3.47 2.05 -0.01 3.81 3.12 0.00 4.57 15.80 4.86 15.72 8.73 8.98 18.35 14.20 0.00 3.11 5.24 1.07 10.77 3.34 5.47 3.58 8.44 -13.77 0.00 -3.53 -2.47 -4.87 -1.62 -4.13 0.02 1.46 -1.67 0.00 0.80 -2.39 1.80 0.38 -1.68 2.14 1. -4.57 0.00 11.23 0.29 11.15 4.16 4.41 13.79 9.63 -3.11 0.00 2.14 -2.04 7.67 0.24 2.36 0.47 5.34 Table 6: Full results (ROC-AUC %) of model size experiments. [Description] indicates the hallucination source, whether generated by specific model or from baseline descriptions. Model Llama-3.2-1B Llama-3.2-3B Llama-3.1-8B Llama-3.1-70B HIV BBBP Clintox 10.54 10.26 8.41 10.16 7.24 7.15 7.31 8.37 13.06 10.06 8.04 6. SIDER Tox21 9.74 10.43 10.61 9.59 7.11 7.57 6.62 8.60 Avg 10.81 9.77 7.42 7.54 Table 7: HHM-2.1 scores for Llama models of different sizes. Temperature HIV BBBP Clintox 49.77 0.1 52.36 0.3 69.48 0.5 51.36 0.7 56.20 0.9 61.82 61.38 60.03 62.85 61.34 64.85 50.67 48.11 49.84 45. SIDER Tox21 54.93 54.13 54.31 54.95 57.38 50.10 58.95 57.27 59.66 48.69 Avg 57.10 54.73 57.02 56.05 54.20 Table 8: Full results (ROC-AUC %) of Llama-3.1-8B using hallucination generated by different generation temperatures. Temperature HIV BBBP Clintox 0.1 0.3 0.5 0.7 0.9 8.25 8.75 8.27 6.88 6.85 7.52 6.87 7.83 7.37 6. 8.02 8.57 8.35 8.10 6.61 SIDER Tox21 Avg 7.93 7.92 7.96 7.73 6.82 8.07 8.05 5.96 8.71 6.27 7.81 7.39 9.38 7.57 7.96 Table 9: The HHM-2.1 score for Llama3.1-8B generated hallucinations in different temperatures. Language HIV BBBP Clintox 47.31 English 65.03 Chinese 51.56 German 68.41 French 47.11 Japanese 58.06 Spanish 63.50 57.23 57.31 60.10 55.51 55.85 59.87 57.12 47.57 42.28 51.39 44.91 SIDER Tox21 50.49 58.22 57.47 52.21 52.42 60.22 56.10 54.15 54.91 49.00 61.79 50.43 Avg 55.88 57.81 53.82 56.21 51.59 54.21 Table 10: Full results (ROC-AUC %) of Llama3.1-8B using hallucination generated in different languages. Name SMILES Reference tion English Chinese German French Japanese Spanish Description N#Cc1ccccc1O descripThe molecule is nitrile that is hydrogen cyanide in which the hydrogen has been replaced by hydroxy group. It has role as an EC 1.2.1.3 [aldehyde dehydrogenase (NAD(+))] inhibitor. It is nitrile and member of phenols. It derives from hydride of pyridine. The given molecular formula is N#Cc1ccccc1O. This formula represents molecule of benzenecarbonitrile, also known as benzonitrile. The molecule consists of benzene ring, which is planar, ring-shaped structure composed of six carbon atoms, each bonded to hydrogen atom. In this case, one of the carbon atoms in the benzene ring is bonded to nitrile group (CN), which consists of carbon atom triple-bonded to nitrogen atom. Additionally, the molecule has an oxygen atom bonded to one of the carbon atoms in the benzene ring, making it benzonitrile derivative with an alkoxy group (-O-). To describe the molecule in Chinese, we first need to identify the chemical structure. The given chemical formula is N#Cc1ccccc1O. Breaking it down: - represents Nitrogen. - # represents triple bond. - represents Carbon. - c1 represents ring (benzene ring). - ccc represents three connected carbons. - 1 is the number of the ring. - represents Oxygen. So, the molecule is Benzotriazole molecule. In Chinese, it is written as: 苯三唑 Die Molekulformel in deutscher Sprache ist: N-(Phenyl)-acetohydrazid Die Molekulstruktur ist ein Hydrazid, das aus einem Acetohydrazid-Molekul und einem Phenyl-Rest besteht. Der Name N-(Phenyl)-acetohydrazid beschreibt die Struktur des Molekuls, wobei das Acetohydrazid-Molekul an das Phenyl-Rest gebunden ist. Eine alternative Bezeichnung fur dieses Molekul acetohydrazid ist eine allgemein akzeptierte und einfache Bezeichnung. Es ist wichtig zu beachten, dass die Molekulformel N#Cc1ccccc1O eine SMILES-Notation ist, eine kurze Bezeichnung fur Molekule, die in der Chemie verwendet wird. Diese Notation kann jedoch nicht direkt als Name eines Molekuls verwendet werden. ist 1-Hydroxy-2-phenyl-2-hydrazinethanon, aber N-(Phenyl)- La molecule decrite par la formule chimique N#Cc1ccccc1O est un isocyanure, plus precisement un isocyanure aromatique. Dans la nomenclature chimique, la formule peut ˆetre decomposee comme suit : - represente un atome dazote. - Le # indique un pont triple entre lazote et le carbone suivant. - represente des atomes de carbone. - Les entre les atomes de carbone indiquent des liaisons entre eux. - Le chiffre 1 entre les parenth`eses indique un cycle (un anneau) compose de 6 atomes de carbone. - represente un atome doxyg`ene. La molecule decrite est donc un isocyanure aromatique cetogenique, qui peut ˆetre nomme isocyanure benz`ene ou isocyanure cetogenique benzenique . Cependant, il est important de noter que la formule chimique donnee peut egalement correspondre `a The molecule you provided is 3-Quinuclidinone. In Japanese, the name of this molecule is 3-キヌキジンオニウム (3-Kinukijinoniu), but this is not entirely accurate, as the molecule is not an ion, but rather ketone. more accurate Japanese name for this molecule would be 3-キヌキジノン (3-Kinukijinon). Heres breakdown of the name: - 3-: indicates the position of the carbonyl group - キヌキジ - (Kinukiji-): refers to the quinuclidine ring - ノン (Non): indicates the presence of carbonyl group (ketone) So, the correct Japanese name for the molecule N#Cc1ccccc1O is 3-キヌキジノン (3-Kinukijinon). La molecula descrita es un anillo aromatico de benzeno (C6H6) con un grupo aminocloruro sustituido (NHCl) un grupo hidroxilo (OH) sustituido en el anillo. Sin embargo, considerando la notacion SMILES proporcionada (N#Cc1ccccc1O), es mas probable que la molecula sea una anilina (C6H5NH2) con un grupo hidroxilo (OH) sustituido en el anillo. La estructura quımica serıa: C1=CC=C(C=C1)N=O. Table 11: Example of molecule and descriptions in different languages generated by Llama-3.1-8B."
        }
    ],
    "affiliations": [
        "Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI), Germany",
        "Dresden University of Technology, Germany"
    ]
}