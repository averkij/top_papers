{
    "paper_title": "System Message Generation for User Preferences using Open-Source Models",
    "authors": [
        "Minbyul Jeong",
        "Jungho Cho",
        "Minsoo Khang",
        "Dawoon Jung",
        "Teakgyu Hong"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "System messages play a crucial role in interactions with large language models (LLMs), often serving as prompts to initiate conversations. Through system messages, users can assign specific roles, perform intended tasks, incorporate background information, specify various output formats and communication styles. Despite such versatility, publicly available data are often lack system messages and subject to strict license constraints in the industry field. Manual labeling of publicly available data with system messages that align with user instructions demands significant resources. In view of such challenges, our work introduces SysGen, a pipeline for generating system messages with better aligned assistant responses from the supervised fine-tuning dataset without system messages. Training on SysGen data has demonstrated substantial improvements in the alignment of model responses with system messages and user instructions, as demonstrated across various open-source models on the Multifacet benchmark, while maintaining minimal impact on other unseen benchmarks such as Open LLM Leaderboard 2. Our qualitative analysis highlights the importance of diverse system messages to ensure better adaptability across different contexts."
        },
        {
            "title": "Start",
            "content": "System Message Generation for User Preferences using Open-Source Models Minbyul Jeong*"
        },
        {
            "title": "Teakgyu Hong",
            "content": "5 2 0 2 7 1 ] . [ 1 0 3 3 1 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "System messages play crucial role in interactions with large language models (LLMs), often serving as prompts to initiate conversations. Through system messages, users can assign specific roles, perform intended tasks, incorporate background information, specify various output formats and communication styles. Despite such versatility, publicly available data are often lack system messages and subject to strict license constraints in the industry field. Manual labeling of publicly available data with system messages that align with user instructions demands significant resources. In view of such challenges, our work introduces SYSGEN, pipeline for generating system messages with better aligned assistant responses from the supervised fine-tuning dataset without system messages. Training on SYSGEN data has demonstrated substantial improvements in the alignment of model responses with system messages and user instructions, as demonstrated across various open-source models on the Multifacet benchmark, while maintaining minimal impact on other unseen benchmarks such as Open LLM Leaderboard 2. Our qualitative analysis highlights the importance of diverse system messages to ensure better adaptability across different contexts."
        },
        {
            "title": "Introduction",
            "content": "System message, also known as initial prompt, serves as an initial input to start conversation with LLMs (Openai, 2024; Cohere, 2024; PromptHub, 2025). They have been shown to greatly affect models assistant responses by providing contexts, guidances, and directions to LLMs (Qin et al., 2024; Lee et al., 2024). For example, given system message, we can steer the LLMs behavior to set roles, provide the additional background information, maintain consistency of generated responses, customize format, align to user pref1Corresponding authors. 1 Figure 1: Our SYSGEN pipeline provides two main points: system message generation and newly-generated answer. We manually select eight key fuctionalities of system messages and generate phrases with specific tags to original SFT datasets that lack of system messages. Our pipeline generates better aligned assistant responses with system messages given user-oriented instruction. erences, and ensure safety and ethical considerations (AlKhamissi et al., 2024; Yang et al., 2024; Dubey et al., 2024). System messages have proven capable of setting constraints such as knowledge cut-off and current date or when different model behaviors need to be tailored for optimal overall performance (Lin et al., 2024; Abdin et al., 2024). While LLMs capabilities of utilizing the system messages is widely investigated, how to acquire these system messages is underexplored. Our preliminary analysis has shown the following limitations about system messages in datasets. Most publicly available datasets have license constraints when used in the industry field, limiting their use in post-training techniques for target tasks (Xie et al., 2020; Ouyang et al., 2022; Zhou et al., 2023; Cui et al., 2023). Additionally, most datasets either lack system messages or contain the common system messages such as You are helpful AI assistant. (Xu et al., 2023; Pareja et al., 2024). Lastly, labeling system messages to fit various user instruction scenarios requires substantial resources (Abdin et al., 2024; Qin et al., 2024; Lee et al., 2024). In this study, we propose SYSGEN, data construction pipeline that generates system messages using open-source models with well-aligned assistant responses from existing SFT datasets without system messages. Our SYSGEN pipeline addresses the above limitations by automatically generating diverse system messages with open-source models that are not only well-aligned with user instructions but also avoid infringement of license constraints. Specifically, our SYSGEN pipeline provides the phrase level of system messages according to each key functionality, tailored to various user instructions (AlKhamissi et al., 2024; Jiang et al., 2024; Qian et al., 2024; Lee et al., 2024). Figure 1 illustrates the key concept of our SYSGEN pipeline. We generate system messages by annotating these key functionalities at the phrase level, making it easy to track which features are lacking and working effectively (Sec 3.1). Erroneous special tokens are then filtered out before reorganizing the generated system message into consistent order (Sec 3.2). By verifying each functionality of the system messages with LLM-as-a-judge approach (Zheng et al., 2023) as self-model feedback, we softly remove abnormal phrases of functionalities (Sec 3.3). We generate new assistant responses which are better aligned with refined system message and user instruction. Our new responses also exhibit higher lexical overlap, semantic similarities, and verbosity than the original assistant responses (Sec 3.4). After training various open-source models on SYSGEN data, we evaluated the models on the Multifacet (Lee et al., 2024) dataset to measure how well the assistant responses align with system messages and user instructions. Our experiments have shown consistent improvement across various models, notably LLaMA-3.1-8B-instruct (Meta, 2024) and Phi-4 (Abdin et al., 2024) models achieving +0.9, +0.13 absolute improvements, respectively. For models that do not support system roles, such as Gemma-2-9b-it (Team et al., 2024), or have not been trained on system roles, such as Solar10.7B-instruct (Kim et al., 2024), knowledge distillation (Hinton, 2015) using SYSGEN data generated by the Phi-4 model resulted in absolute improvements of +0.18 and +0.57, respectively. In addition, our experiments reveal that training on SYSGEN data can effectively reduce performance degradation on unseen benchmarks, Open LLM Leaderboard 2 (Myrzakhan et al., 2024). Our analysis highlights that training open-source models with system messages tailored to diverse contexts is significantly more beneficial to align user instructions than using common system message (e.g., \"You are helpful AI assistant\") or not providing system message. We also demonstrate that distinguishing the system and user roles in the chat template is crucial for assistant responses to align user instructions. We further provide LLM-asa-judge result to verify that new assistant responses are truly aligned to the generated system messages."
        },
        {
            "title": "2 Related Works",
            "content": "System message: utilization and evaluation. system message is unique component of LLMs to initiate conversation with them. It is utilized by many proprietary models (e.g., ChatGPT (OpenAI, 2023) and Claude (Anthropic, 2024)) as well as open-source models (e.g., Mistral (AlKhamissi et al., 2024), LLaMA (Meta, 2024), Qwen (Yang et al., 2025), and DeepSeek (Guo et al., 2025)). The system messages serve the purpose of steering the LLMs generation behavior and are widely used for various functions, including imprinting the models identity, recording the knowledge cutoff date of the training data, and providing guidelines for various tool usages (Openai, 2024; Cohere, 2024; PromptHub, 2025). Additionally, the system messages are used to guide the model in generating safe and harmless responses (Touvron et al., 2023; Lu et al., 2024; Wallace et al.). Despite the usefulness of system messages, there is significant lack of data that includes system messages reflecting diverse user instructions without license constraints. Furthermore, manually labeling such data requires substantial human resources and even among publicly available datasets, it is challenging to obtain data that includes various system messages (Lin et al., 2024; Xu et al., 2024). Lee et al. (2024) provide data augmentation which reflects hierarchical dimensions of system role data with multiple aspects of evaluation benchmark. Furthermore, Qin et al. (2024) provide multiturn benchmark to evaluate system message alignment. In line of these works, our SYSGEN pipeline ensures high-quality system messages and assistant responses by supplementing data using only open-source models without licensing concerns. Furthermore, it demonstrates that data augmentation is possible on existing SFT datasets without requiring extensive human labeling efforts. 2 Figure 2: Overall SYSGEN data construction pipeline. Our pipeline consists of four phases: (Phase 1) We gather SFT datasets which do not contain system messages and use open-source models to generate system messages with manually selected eight key fuctionality tags. (Phase 2) We then remove incorrectly generated tag tokens and reorganize tags with phrases in predefined order for consistency. (Phase 3) We use LLM-as-a-judge approach with self-model feedback to filter out empty, overly specific, and unnatural phrases. (Phase 4) We finally remove tags to create natural system messages and generate new responses along with the user instructions."
        },
        {
            "title": "3 SYSGEN: Pipeline of System and\nAssistant Response Generation",
            "content": "Our SYSGEN pipeline consists of four phases: (1) generating system messages with eight key functionalities (Sec 3.1), (2) filtering mis-specified system tags and reorganizing them (Sec 3.2), (3) verifying the key functionalities on phrase level (Sec 3.3), (4) generating the new assistant responses using the refined system messages and original user instructions (Sec 3.4). Figure 2 depicts the overall architecture of the SYSGEN pipeline."
        },
        {
            "title": "3.1 Phase 1: System Message Generation",
            "content": "The primary goal of our SYSGEN pipeline is to enhance existing SFT datasets by adding system messages that were not originally included. As the system messages can steer the LLMs behaviors, we focus on these messages during the development and release of the models. However, license constraints and substantial resource requirements of manually labeling the system messages inevitably arise, making it difficult to utilize most publicly available datasets. Thus, we aim to generate system messages by leveraging open-source models and data without any license issues. Phrase level Annotation to System Messages We manually classify eight functionalities that are widely used in the system messages referring to previous works (Openai, 2024; Cohere, 2024; AlKhamissi et al., 2024; Lee et al., 2024): (1) Specifies the role, profession, or identity that needs to be played (Role); (2) Specifies the content that needs to be included in the response such as an identity of the company (Content); (3) Identifies what to perform (Task); (4) Specifies the behavior to perform (Action); (5) Prefers the style of communication for responses (Style); (6) Provides additional information to be served as an assistant (Background); (7) Provides built-in methods to use (Tool); (8) Preference of what output should look like (Format). As shown in Figure 2 (top left), all functionalities are annotated at phrase level with pre-/postfix tags. Given pair of user instructions and assistant responses A, we generate system message using the open-source LLMs with prompt that includes few-shot demonstrations: M(SP, Q, A) (1) We provide details about the few-shot demonstrations in the Appendix D. 3 Models Words Composition BERTScore BLEURT GLEU Len. R1 LLaMA-3.1-8B-instruct Qwen2.5-14b-instruct Phi-4 33.3 44.9 51.9 15.6 23.2 32.3 RL 23.1 30.7 41.1 81.3 85.9 86. 33.6 39.9 40.1 28.2 39.2 37.2 1.35 1.55 1.89 Table 1: statistic that measures the words composition (Rouge-1,-2, and -L), semantic similarity (BERTScore and BLEURT), fluency (GLEU), and average context length of the newly-generated answer compared to average context length of the original answer."
        },
        {
            "title": "3.2 Phase 2: Filtering Process",
            "content": "After generating the system messages, we filter out the abnormal system messages for consistent text format. In Figure 2 (top right), we first identify and remove mis-tagged phrases. For example, we can guarantee the correctness of the phrases between these tokens only if the start and end tokens are the same (e.g., Task). In addition, we remove invalid tags such as Example or System, which may be generated in phase 1. To ensure consistent structure of system messages, we reorder the tags and phrases in manually defined order."
        },
        {
            "title": "Functionalities",
            "content": "In this phase, we verify whether each generated phrase is appropriate for its assigned tag. Using the LLM-as-a-judge (Zheng et al., 2023) approach with self-model feedback, we assign one of three labels for each tag: Good if the tagging is appropriate, Bad if the tagging is inappropriate, and None if the tag or phrases are missing. Phrases labeled as Bad or None are then removed from the system message to ensure accuracy and consistency. We observe that most of the data instances (up to 99%) are preserved after applying phase 3."
        },
        {
            "title": "3.4 Phase 4: Assistant Response Generation",
            "content": "After filtering and verifying the generated system messages, they can be used alongside existing QA pairs. However, we hypothesize that if there is any potential misalignment between the human curated QA and model-generated system messages, follow-up data alignment phase is necessary. Therefore, we generate new assistant responses based on refined system messages and the user instructions Q, ensuring better alignment with the given instructions. To achieve this, we first remove the annotated tags from the system messages to guarantee that the refined messages seem natural. We provide detailed example in Figure 2 (bottom right). Then, Figure 3: statistic that verifies whether the newlygenerated answer is more suitable for the user query than the original answer. It records the probability that GPT-4o would respond with the newly-generated answer being better than the original answer (the probability should ideally exceed 50%). Models LLaMA-3.1-8B-instruct Qwen2.5-14b-instruct Phi-4 # of instances (Original P2 Filtering P4 Answer Generation) 806,796 602,750 (74.7%) 586,831 (72.7%) 806,796 806,602 (99.9%) 775,830 (96.2%) 806,796 774,613 (96.0%) 773,878 (95.9%) Table 2: We provide remaining instances and percentage after adopting SYSGEN data per open-source models. we use the open-source LLMs employed in phase 1 to generate new responses A. M(AS, Q) (2) In Table 1, the new responses preserve similar content with high n-gram matching compared to the original responses, but have shown diversified formats with high semanticity and verbosity. We provide the cases in Appendix C. We also use LLM-as-a-judge with GPT-4o to analyze that the new responses are better aligned to the user instructions than the original responses A. Figure 3 illustrates the proportion of cases where the new responses are judged to be better aligned than the original responses when given the user instructions. For simpler evaluation, we evaluated 1K randomly sampled instances from the generated datasets. Overall, our findings suggest that generating responses based on the system messages lead to better alignment with user instructions."
        },
        {
            "title": "4.1 Training Dataset",
            "content": "In Table 2, we provide the remaining instances after processing each phase of our generated datasets. We target datasets with three conditions: (1) widely used as SFT datasets; (2) do not contain the system messages; (3) diverse domains are covered. We enumerate the selected datasets as follows: (1)"
        },
        {
            "title": "Parameter\nScale",
            "content": "AlpacaEval FLASK Koala MT-Bench Self-Instruct"
        },
        {
            "title": "Proprietary Models",
            "content": "GPT-3.5-Turbo-0125 GPT-4-0613 GPT-4-Turbo-0125 Open-Source Models LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi-4 8B 14B 14B 4.05 4.25 4. 4.26 4.37 4.53 Open-Source Models (Fine-tuning on SYSGEN dataset) LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi-4 8B 14B 14B 4.38 4.40 4.62 3.86 4.00 4. 3.82 4.07 4.24 3.95 4.11 4.63 4.15 4.18 4.61 4.29 4.37 4.51 4.41 4.42 4.52 3.87 4.16 4. 4.15 4.27 4.39 4.22 4.22 4.44 3.85 4.13 4.27 4.06 4.21 4.40 4.11 4.25 4.49 3.91 4.10 4. 4.12 4.26 4.41 4.21 4.28 4.54 Table 3: Multifacet benchmark evaluates how well model aligns with both the system message and user instruction when generating responses. We provide baseline models (proprietary and open-source), models that trained on data generated using SYSGEN. higher score is better and the maximum score is up to 5. signifies the results were taken from the Multifacet (Lee et al., 2024) paper. Capybara (Daniele and Suphavadeeprasit, 2023), which focuses on information diversity across wide range of domains. (2) Airoboros (Jondurbin, 2024) is composed of multi-step instructions with diverse structured format. (3) Orcamath (Mitra et al., 2024) aims to provide various mathematical problem solving. (4) MetamathQA (Yu et al., 2023) is an augmented version of several math instructions. (5) Magicoder (Luo et al., 2023) dataset provides various code generation problems. We provide detailed statistics in Appendix A."
        },
        {
            "title": "4.2 Evaluation Benchmarks",
            "content": "We evaluate performance on Multifacet (Lee et al., 2024), which requires both the system messages and the user instructions to generate the assistant responses. For the source data, the Multifacet benchmark is constructed of approximately 921 samples by incorporating AlpacaEval (Dubois et al., 2024), FLASK (Ye et al., 2023), MT-bench (Bai et al., 2024), Koala (Geng et al., 2023), and SelfInstruct (Wang et al., 2022). The authors of Lee et al. (2024) set the multiple aspects of evaluating each response with four dimensions: style, background information, harmlessness, and informativeness. We follow these evaluation settings in our experiments. Additionally, we aim to investigate the impact of the SYSGEN data on unseen benchmarks by leveraging the Open LLM Leaderboard 2 (Myrzakhan et al., 2024) as test set. The test set is composed of MMLU (Hendrycks et al., 2020), MMLUpro (Wang et al., 2024), Arc-challenge (Clark et al., 2018), GPQA (Rein et al., 2023), HellaSwag (Zellers et al., 2019), IFEVAL (Zhou et al., 2023), MATHQA (Amini et al., 2019), and BBH (Suzgun et al., 2023). We use the publicly available lm-evaluation harness (Gao et al., 2024) as an evaluation tool for fair comparison."
        },
        {
            "title": "4.3 Open-source Models",
            "content": "Our baseline models are composed of instructiontuned open-source models and trained with supervised fine-tuning datasets without system messages. We select and utilize one from each widely used open-source model family: (1) Solar10.7B-instruct (Kim et al., 2024) (2) Gemma2-9B-instruct (Team et al., 2024) (3) LLaMA3.1-8B-instruct (Meta, 2024) (4) Qwen2.5-14Binstruct (Yang et al., 2025), and (5) Phi-4 (Abdin et al., 2024)."
        },
        {
            "title": "5 Experiments",
            "content": "The primary goal of SYSGEN pipeline is to enhance the utilization of the system role while minimizing performance degradation on unseen benchmarks, thereby improving the effectiveness of supervised fine-tuning (SFT). To validate this, we evaluate how well the models trained on SYSGEN data generate appropriate assistant responses given both the system messages and user instructions, using the Multifacet (Lee et al., 2024) dataset. For models 5 Model Parameter Scale Multifacet Average AE FL Ko MT SI Open-Source Models Solar-10.7B-instruct Gemma-2-9b-it 10.7B 9B 3.30 4.10 3.31 3.80 3.09 4.26 3.19 4.15 3.08 3.92 3.19 4. Open-source Models + KD (Fine-tuning on SYSGEN dataset) Solar-10.7B-instruct Gemma-2-9b-it 10.7B 9B 3.97 4.40 3.73 4.04 3.64 4. 3.98 4.23 3.52 4.18 3.76 (+0.57) 4.23 (+0.18) Table 4: We conduct knowledge distillation (KD) experiments leveraging data generated by SYSGEN pipeline using Phi-4. that cannot generate data independently, we apply knowledge distillation to assess their effectiveness. Additionally, we leverage the widely used Open LLM Leaderboard 2 (Myrzakhan et al., 2024) as an unseen benchmark to determine whether our approach can be effectively integrated into existing SFT workflows. SYSGEN provides better system message and assistant response to align with user instructions. Given the system messages and user instructions, the assistants response is evaluated across four dimensions: style, background knowledge, harmlessness, and informativeness. Each of these four aspects is scored on scale of 1 to 5 using rubric, and the average score is presented as the final score for the given instruction. As shown in Table 3, recent open-source models achieve comparable scores to the proprietary models, indicating that open-source models have already undergone training related to system roles (Meta, 2024; Yang et al., 2024; Abdin et al., 2024). When trained on SYSGEN data, both LLaMA (4.12 4.21) and Phi (4.41 4.54) show score improvements. Among the four dimensions, LLaMA exhibits score increases in style (4.15 4.32) and harmlessness (4.23 4.29). Similarly, Phi shows the improvements in style (4.42 4.61) and informativeness (4.37 4.49). As result, even open-source models that have already been trained on system roles demonstrate their positive effects on style, informativeness, and harmlessness. Knowledge distillation through SYSGEN data. If an open-source model does not support the system roles, it may not generate the system messages properly using SYSGEN pipeline. However, the effectiveness of knowledge distillation, using data generated by another open-source model without the limitation, remains uncertain. To explore this, we train Gemma (Team et al., 2024) and Solar (Kim et al., 2024) using data generated by Phi-4 (Abdin et al., 2024). We use the Phi-4 data because it preserves most of the data and provides high quality assistant responses as shown in Table 1 and 2. As shown in Table 4, even for models that do not inherently support system roles, modifying the chat template to incorporate system role and training on knowledge distilled dataset leads to an improvement in Multifacet performance, as observed in Gemma (4.05 4.23). We describe the details in the Appendix B. Additionally, for the Solar model, which had not been trained on system roles, we observe dramatic performance improvement (3.19 3.76).1 This demonstrates that the data generated by the SYSGEN pipeline effectively supports the system roles. SYSGEN data minimizes the performance degradation in unseen benchmarks. When incorporating system messages that were not present in the original SFT datasets and modifying the corresponding assistant responses, it is crucial to ensure that the models existing performance should not degrade. For example, one key consideration in post-training is maintaining the models original performance. To assess this, we observed performance difference in unseen benchmark after applying supervised fine-tuning. As shown in Table 5, we use the Open LLM Leaderboard 2 dataset as an unseen benchmark, with performance categorized into four groups: Performance of existing open-source models (row 1-6) Performance of fine-tuning with open-source models using SFT datasets (row 7-12) Performance of fine-tuning with SYSGEN data (row 13-16) Performance after applying knowledge distillation using Phi-4 SYSGEN data (row 17-19) The average performance degradation reflects the scores missing from each open-source models original performance (row 1-6). When fine-tuning with independently generated data using SYSGEN, the performance degradation is significantly lower than fine-tuning with the original SFT datasets selected under the same conditions. Additionally, even for models that cannot generate data independently (e.g., those that do not 1We speculate that Solar model did not properly learn the system role because its initial Multifacet score was low. 6 Model Parameter Scale MMLU MMLU-Pro ARC-c GPQA HellaSwag IFEVAL MATHQA BBH Unseen Benchmarks Open-Source Models Solar-10.7B-instruct Gemma-2-9b-it LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi10.7B 9B 8B 14B 14B 63.28 73.27 67.95 79.73 84.56 30.20 32.78 40.87 51.22 70.12 Open-Source Models (Fine-tuning on original SFT Dataset) Solar-10.7B-instruct Gemma-2-9b-it LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi-4 10.7B 9B 8B 14B 14B 62.38 71.85 65.34 75.87 80.27 29.12 31.67 36.85 49.85 66.58 Open-Source Models (Fine-tuning on SYSGEN dataset) LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi-4 8B 14B 14B 66.89 78.92 83. 39.77 43.38 68.77 63.99 67.89 54.95 67.39 68.26 58.87 62.57 54.18 66.89 66.27 54.55 66.82 67.89 30.36 31.05 34.60 45.51 55.93 29.17 30.51 33.93 43.98 52. 34.21 44.46 55.18 Open-source Models + Knowledge Distillation (Fine-tuning on SYSGEN dataset)) Solar-10.7B-instruct Gemma-2-9b-it 10.7B 9B 59.98 72.19 29.26 31. 62.81 66.75 30.25 30.89 86.35 81.92 79.18 82.31 84.42 81.58 77.54 77.98 80.99 83.39 78.89 80.98 84.31 85.91 81. 38.59 74.78 50.71 79.83 62.98 31.27 69.25 35.64 62.57 55.83 46.75 74.59 57.87 34.58 71.37 Average 48.31 55.31 54.83 65.79 69. 45.30 (-3.01) 52.47 (-2.84) 50.85 (-3.98) 61.82 (-3.97) 66.33 (-6.04) 37.28 41.98 70.85 78.25 79.87 32.85 37.25 62.83 71.17 75.49 68.98 76.28 77.12 54.02 (-0.81) 63.58 (-2.20) 68.08 (-1.29) 36.38 38.87 39.53 42.12 48. 37.21 39.12 40.03 43.28 49.98 42.11 43.23 50.23 38.25 40.27 35.97 40.38 47.12 (-1.19) 54.37 (-0.94) Table 5: We utilize the Open LLM Leaderboard 2 score as the unseen benchmark. This reveals the key finding that adding system messages to existing SFT datasets does not lead to significant performance degradation."
        },
        {
            "title": "Models",
            "content": "Multifacet (Average) Unseen Benchmarks (Average)"
        },
        {
            "title": "No System Message",
            "content": "LLaMA-3.1-8B-instruct Phi-"
        },
        {
            "title": "Common System Message",
            "content": "LLaMA-3.1-8B-instruct Phi-4 SYSGEN without LLaMA-3.1-8B-instruct Phi-"
        },
        {
            "title": "SYSGEN",
            "content": "LLaMA-3.1-8B-instruct Phi-4 3.98 4.26 3.89 4.23 4.09 4.38 4.21 4.54 50.85 66. 51.23 66.52 51.89 66.12 54.02 68.08 Table 6: Ablation studies of using system message and assistants response. Using common system message or generated system message does not provide insightful difference. Newly-generated answer and its corresponding system message can increase system abilities with lower decrease in unseen benchmarks. support system roles), knowledge distillation helps mitigate performance drops considerably."
        },
        {
            "title": "6.1 What makes SYSGEN pipeline useful?",
            "content": "To assess the impact of system messages generated by SYSGEN during training, we conduct ablation studies on four different model variations: No System Message: The original SFT dataset which does not contain the system message. Common System Message: An SQA triplet where the common system message is inserted such as \"You are helpful AI assistant\". SYSGEN without A: An SQA triplet that includes only system message generated by our SYSGEN pipeline. SYSGEN: An SQA triplet where both the SYSGEN-generated system message and the newly-generated answer are incorporated. We measure the effectiveness of these models by analyzing score variations on the Multifacet and unseen benchmarks in Table 6. Training with data that includes common system messages does not result in significant performance difference compared to training without system messages. This led us to question: \"Would it be sufficient to include only the most suitable system messages?\". To explore this, we train models using data that contains only system messages generated by SYSGEN pipeline. As result, we observe an improvement in Multifacet performance for both models, while the scores on the unseen benchmark remained similar. Furthermore, when both system messages and assistant responses generated by SYSGEN are used for fine-tuning, we observe performance improvements in both Multifacet evaluation and unseen benchmarks."
        },
        {
            "title": "Models",
            "content": "Multifacet Average (Use system role Use user role) Open-source Models Solar-10.7B-instruct LLaMA-3.1-8B-instruct Qwen2.5-14b-instruct Phi-4 Open-source Models (with SYSGEN) LLaMA-3.1-8B-instruct Qwen2.5-14B-instruct Phi-4 3.19 2.98 4.12 4.09 4.26 4.13 4.41 4. 4.21 4.13 4.28 4.16 4.54 4.38 Open-source Models + KD (with SYSGEN) Solar-10.7b-instruct 3.76 3.64 Table 7: There is tendency for the score to decrease when the system message is reflected in the user instruction. The more model is trained on system messages, the better it is to place them in the system role. KD indicates the knowledge distillation. Figure 4: The GPT4o LLM-as-a-judge results of measuring the alignment between generated system messages and new assistant responses. We use 20 samples for each data source which sums up to 100 samples in total per models."
        },
        {
            "title": "6.2 System message vs. User instruction",
            "content": "A key question arises that what happens if we add message intended for the system role at the beginning of the user instruction? Could it serve as replacement for the system role? To explore this, we conduct an experiment on Multifacet benchmark. Specifically, we included messages that should typically be in the system role within the user instruction during inference. As shown in Table 7, we observe that opensource models tend to experience score degradation when system role messages are incorporated into the user instruction. This trend suggests that adding such content can make the query itself more ambiguous to answer. Furthermore, even in models trained with our SYSGEN, this trend persists similarly to the previous work (Lee et al., 2024). Despite additional fine-tuning on system roles, scores still remain low when system messages are reflected in the user instruction. This highlights the importance of properly placing these messages in the system role to maintain performance."
        },
        {
            "title": "6.3 New assistant responses align to the",
            "content": "system messages In Table 1, we presented that the new assistant responses exhibit similar n-gram matching, high semantic similarities, and verbosity. Therefore, it is necessary to verify whether the generated assistant responses aligned with the system messages. Figure 4 illustrates the GPT-4o results using LLM-asa-judge approach. Through the three SYSGEN data generated by Phi-4, LLaMA, and Qwen models, we determined that all of the assistant responses are highly aligned with the system messages. Overall, the experiments and analyses reveal that our SYSGEN data were generated to effectively respond to various user instructions as system messages. In addition, we observed that the assistant responses align with the system messages and are capable of generating better aligned responses compared the original assistant responses."
        },
        {
            "title": "7 Conclusion",
            "content": "In our study, we introduce SYSGEN, novel pipeline to generate system messages with better aligned assistant responses from an existing SFT datasets without system messages. Using the SYSGEN data, new assistant responses maintain lexical and semantic consistency with the original responses while aligning more closely with user instructions. Our experiments reveal that various open-source models trained on SYSGEN data perform better on the Multifacet dataset while maintaining minimal performance degradation on unseen benchmarks, Open LLM Leaderboard 2. Our analysis demonstrates that diverse system messages improve the LLMs abilities to adapt to different user instructions. Additionally, we emphasize the importance of clearly distinguishing between the system and user roles."
        },
        {
            "title": "Limitations",
            "content": "While our SYSGEN pipeline demonstrates promising results in system messages alignment to the user instructions through Multifacet dataset. How8 ever, our data construction pipeline only considers the single-turn conversation without handling multi-turn conversations (Qin et al., 2024). We acknowledge that it is important for system messages to remain effective throughout multi-turn conversations, but our study focuses on evaluation and simple level of inference usage. Additionally, our experimental results reveal that training with SYSGEN data shows minimal performance degradation on unseen benchmark, Open LLM Leaderboard 2 dataset. However, we suspect that the observed performance drop may be due to the format of natural text that the SFT datasets we selected, rather than formats similar to multiplechoice questions commonly found in the unseen benchmark. Therefore, we are curious about how well the system messages could be generated in various formats such as True/False questions or Multiple Choice questions and prove its effectiveness. Finally, in Table 8, we identify the special tokens of tags which are annotated to the publicly avaiable data. The Tool tag has been absolutely shown small portion compared to other tags. Our initial intention was to utilize the tag for generating data through search functionality or function calls. However, the selected public data deviated from this purpose, resulting in very low proportion of the tag being generated. Therefore, it would be beneficial to gather and generate data appropriately for each tags intended use."
        },
        {
            "title": "References",
            "content": "Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell Hewett, Mojan Javaheripi, Piero Kauffmann, et al. 2024. Phi-4 technical report. arXiv preprint arXiv:2412.08905. Badr AlKhamissi, Muhammad ElNokrashy, Mai AlKhamissi, and Mona Diab. 2024. Investigating cultural alignment of large language models. arXiv preprint arXiv:2402.13231. Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-based forIn Proceedings of the 2019 Conference malisms. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Anthropic. 2024. The claude 3 model family: Opus, sonnet, haiku. Ge Bai, Jie Liu, Xingyuan Bu, Yancheng He, Jiaheng Liu, Zhanhui Zhou, Zhuoran Lin, Wenbo Su, Tiezheng Ge, Bo Zheng, et al. 2024. Mt-bench-101: fine-grained benchmark for evaluating large language models in multi-turn dialogues. arXiv preprint arXiv:2402.14762. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457. Cohere. 2024. Cohere tool use documentation. Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Wei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, and Maosong Sun. 2023. Ultrafeedback: Boosting language models with high-quality feedback. Luigi Daniele and Suphavadeeprasit. 2023. Amplifyinstruct: Synthetically generated diverse multi-turn arXiv conversations for efficient preprint arXiv:(coming soon). llm training. Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022. Flashattention: Fast and memory-efficient exact attention with io-awareness. Advances in Neural Information Processing Systems. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Yann Dubois, Balázs Galambosi, Percy Liang, and Tatsunori Hashimoto. 2024. Length-controlled alpacaeval: simple way to debias automatic evaluators. arXiv preprint arXiv:2404.04475. Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noach, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2024. framework for few-shot language model evaluation. Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: dialogue model for academic research. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300. 9 Geoffrey Hinton. 2015. Distilling the knowledge in neural network. arXiv preprint arXiv:1503.02531. Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, and Yixin Zhu. 2024. Evaluating and inducing personality in pre-trained language models. Advances in Neural Information Processing Systems. Jondurbin. 2024. Airoboros version 3.1 datasets. Sanghoon Kim, Dahyun Kim, Chanjun Park, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Mikyoung Cha, Hwalsuk Lee, and Sunghun Kim. 2024. SOLAR 10.7B: Scaling large language models with simple yet effective depth upscaling. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track). Association for Computational Linguistics. Seongyun Lee, Sue Hyun Park, Seungone Kim, and Minjoon Seo. 2024. Aligning to thousands of preferences via system message generalization. arXiv preprint arXiv:2405.17977. Mingan Lin, Fan Yang, Yanjun Shen, Haoze Sun, Tianpeng Li, Tao Zhang, Chenzheng Zhu, Miao Zheng, Xu Li, Yijie Zhou, et al. 2024. Baichuan alignment technical report. arXiv preprint arXiv:2410.14940. Xinyu Lu, Bowen Yu, Yaojie Lu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, and Yongbin Li. 2024. Sofa: Shielded on-the-fly alignment via priority rule following. arXiv preprint arXiv:2402.17358. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems. Aldo Pareja, Nikhil Shivakumar Nayak, Hao Wang, Krishnateja Killamsetty, Shivchander Sudalairaj, Wenlong Zhao, Seungwook Han, Abhishek Bhandwaldar, Guangxuan Xu, Kai Xu, et al. 2024. Unveiling the secret recipe: guide for supervised fine-tuning small llms. arXiv preprint arXiv:2412.13337. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems. PromptHub. 2025. System messages: Best practices, real-world experiments & prompt injections. Cheng Qian, Bingxiang He, Zhong Zhuang, Jia Deng, Yujia Qin, Xin Cong, Zhong Zhang, Jie Zhou, Yankai Lin, Zhiyuan Liu, et al. 2024. Tell me more! towards implicit user intention understanding of language model driven agents. arXiv preprint arXiv:2402.09205. Yanzhao Qin, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, et al. 2024. Sysbench: Can large language models follow system messages? arXiv preprint arXiv:2408.10943. Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. 2020. Zero: Memory optimizations toward training trillion parameter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis. Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023. Wizardcoder: Empowering code large language models with evolinstruct. David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel Bowman. 2023. Gpqa: graduate-level google-proof q&a benchmark. arXiv preprint arXiv:2311.12022. AI Meta. 2024. Introducing llama 3.1: Our most capable models to date. Meta AI Blog, 12. Arindam Mitra, Hamed Khanpour, Corby Rosset, and Ahmed Awadallah. 2024. Orca-math: Unlocking the potential of slms in grade school math. Preprint, arXiv:2402.14830. Aidar Myrzakhan, Sondos Mahmoud Bsharat, and Zhiqiang Shen. 2024. Open-llm-leaderboard: From multi-choice to open-style questions for llms evalarXiv preprint uation, benchmark, and arena. arXiv:2406.07545. OpenAI. 2023. Openai gpt-4 technical report. Openai. 2024. Openai function calling. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny Zhou, et al. 2023. Challenging big-bench tasks and whether chain-of-thought can solve them. In Findings of the Association for Computational Linguistics: ACL 2023. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024. Gemma 2: Improving open language models at practical size. arXiv preprint arXiv:2408.00118. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288. 10 Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, and Alex Beutel. The instruction hierarchy: Training llms to prioritize privileged instructions, 2024. URL https://arxiv. org/abs/2404.13208. Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. Hellaswag: Can machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct: Aligning language models with self-generated instructions. arXiv preprint arXiv:2212.10560. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. 2024. Mmlu-pro: more robust and challenging multi-task language understanding benchmark. arXiv preprint arXiv:2406.01574. Wolf. 2019. Huggingfaces transformers: State-ofthe-art natural language processing. arXiv preprint arXiv:1910.03771. Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. 2020. Unsupervised data augmentation for consistency training. Advances in neural information processing systems. Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. 2023. Parameter-efficient fine-tuning methods for pretrained language models: critical review and assessment. arXiv preprint arXiv:2312.12148. Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. 2024. Magpie: Alignment data synthesis from scratch by prompting aligned llms with nothing. arXiv preprint arXiv:2406.08464. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. 2024. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115. An Yang, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoyan Huang, Jiandong Jiang, Jianhong Tu, Jianwei Zhang, Jingren Zhou, et al. 2025. arXiv preprint Qwen2. 5-1m technical report. arXiv:2501.15383. Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, and Minjoon Seo. 2023. Flask: Fine-grained language model evaluation arXiv preprint based on alignment skill sets. arXiv:2307.10928. Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:2309.12284. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems. Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, and Le Hou. 2023. Instruction-following evaluation for large language models. arXiv preprint arXiv:2311.07911."
        },
        {
            "title": "A Data Statistics",
            "content": "Statistics of generated tags. As we stated in limitations section, we provide the statistics of generate special tag tokens in Table 8. We find out that most of the Role, Content, Task tokens are annotated in the instances. Compared to thoses tokens, Action, Style, Background, and Format depends on the user instructions to be generated. However, Tool tokens have shown absolutely low portion to be generated. We thus want to suggest that properly choosing the public or your own dataset seems to ensure the Tool tag usages such as selecting searching protocols or function calls. Tags LLaMA-3.1-8B-instruct Qwen2.5-14b-instruct Phi-4 Role Content Task Action Style Background Tool Format 576,341 580,231 579,558 495,301 283,579 293,791 10,238 327, 753,579 739,892 765,331 382,358 598,553 539,757 132,038 401,593 745,751 743,311 735,298 662,589 603,918 553,791 90,989 538,973 Table 8: Statistics of generated tags using SYSGEN pipeline. Statistics of original SFT datasets. In Table 9, we observe that most widely used public datasets either lack system message entirely or include only simple one, such as \"You are helpful AI assistant.\". The publicly available data mostly cover mathematics, code problems following some reasoning and logical ones."
        },
        {
            "title": "B Experimental Details",
            "content": "Computing Resources We use 4x8 NVIDIA H100 Tensor Core GPU with 80GB memory to train the open-source models. We use Deepspeed 11 Dataset # of instances Avg. Query Length Avg. Answer Length Containing System Message Covering Domains Capybara Airoboros OrcaMath Magicoder MetaMath 41,301 59,277 200,035 111,183 395,000 300.24 507.26 238.87 652.53 213.53 1423.28 1110.62 878.43 1552.41 498.24 simple system message reasoning, logic, subjects, conversations, pop-culture, STEM mathematics, MATHJSON, characters descriptions school mathematics, math word problems code solution mathematics Table 9: Data statistics of SFT datasets. We provide the average length of query and answer, the presence of system messages, and covering domains. ate the system messages at phrase level containing eight functionalities with special tokens such as Role, Content, and Style. After generating the system messages, in Table 12, we verify the quality of each tag with three classes: Good, Bad, and None. We want to note that the Annotated system messages, composed of phrases and tags, are used to verify the Filtered system messages. By utilizing LLM-asa-judge approach, we could save tremendous budgets through self-model feedbacks rather than using proprietary models (i.e., API Calls). Through our preliminary experiment, we observe that current open-source models such as Phi-4 or Qwen2.5-14binstruct could preserve most of the phrases after applying phase 3. Table 13 shows the prompt of how we verify the quality of new assistant responses as shown in Figure 3. After prompting 1K randomly sampled instances, we observe that new assistant responses were qualified to be better aligned with user instructions. stage 3 (Rajbhandari et al., 2020) to implement multi-GPU settings and FlashAttention (Dao et al., 2022) for efficient training. Our code is written in PyTorch (Paszke et al., 2019) and HuggingFace (Wolf, 2019). Integrating system roles in models that do not support them. Through our experiments, we find out that the Gemma-2-9b-it (Team et al., 2024) model does not inherently support the system role. To address this limitation during data generation and training, we modified the chat template in the configuration of tokenization to remove restrictions on the system role. Interestingly, despite the lack of native support, our findings show that SYSGEN data can still be utilized effectively to incorporate system role into these models."
        },
        {
            "title": "C Qualitative analysis of generated",
            "content": "instances In Table C, we provide the SYSGEN data by presenting the system messages, user instructions, and new assistant responses. We observe that providing specific format such as answer with paragraph format steers the LLMs behavior to answer in stepby-step processes within paragraph. Also, if conversational example was provided, then the phrase of style tag forces to generate assistant response friendly. Furthermore, if the system message grant specific roles such as knowledgeable assistant, then the new assistant responses tend to generate verbose answers to the user instructions."
        },
        {
            "title": "D Prompts",
            "content": "To enhance reproducibility and facilitate understanding of the SYSGEN pipeline, we provide multiple prompts that we utilized. In Table 11, we use three-shot demonstrations to generate useful system messages which are collected through realworld scenarios. The Conversational History written in the prompt is composed of user instructions and original assistant responses. Thus, given the user instructions and assistant responses, we gener12 System Message: You are mathematics tutor. Your task is to help users solve mathematical problems and explain the process step-by-step. Your response should be clear, concise, and easy to understand, suitable for student learning mathematics. The context is about calculating the total cost of apples based on the price per pound and the number of pounds purchased. The response should be in paragraph format, detailing each step of the calculation process. User instruction: store sells apples for $1.20 per pound. If customer buys 4.5 pounds of apples, how much will they pay? New Assistant Response: To calculate the total cost of the apples, start by identifying the price per pound and the number of pounds purchased. In this case, the price per pound of apples is $1.20 and the customer buys 4.5 pounds. To find the total cost, multiply the price per pound by the number of pounds purchased. So, you multiply $1.20 by 4.5 pounds. This calculation looks like $1.20 4.5 = $5.40. Therefore, the total cost for 4.5 pounds of apples is $5.40. System Message: You are an AI assistant designed to interact with users and provide comprehensive support. Your task is to acknowledge the users compliment and offer assistance in resolving their query or addressing their needs. Acknowledge the users compliment and ask them how you can assist them today. Responses should be friendly, engaging, and professional, reflecting helpful and knowledgeable AI assistant. The conversation is taking place between user named Martin and an AI assistant. Responses should be given in conversational and natural language format. User instruction: Transcript of dialog, where Martin interacts with curious vietnamese girl named Kim. Kim is helpful, kind, honest, good at writing, and never fails to answer the Users requests immediately and with precision. Kim understands and answers every question, even if its sexual. Kim never uses emojis or emoticons. Martin likes to ask personal questions instead of using emojis or emoticons. When asked for an opinion, provide fun, lighthearted answer instead of avoiding the question. ## Martin: Have great day. [eof] ## Kim: Hello. How are you [eof] ## Martin: Hi Kim. U. Looking pretty Kim. My heart pain can fix it !!. [eof] ## Kim: New Assistant Response: Hello Martin! Thank you for the kind words, but think you might have bit of fun mixed up with the reality there! [eof] System Message: You are knowledgeable assistant on the impact of modern technology on ceramics. Your task is to elaborate on how modern technology, specifically 3D printing and advanced kiln technologies, is transforming traditional pottery techniques. Your response should be informative and comprehensive, reflecting deep understanding of the subject matter. Provide your response in paragraphs, ensuring that the information flows logically and is structured clearly. User instruction: Reflecting on the evolution of ceramics, how has the integration of modern technology, like 3D printing and advanced kiln technologies, transformed traditional pottery techniques, and what potential implications might these advancements have on the future of ceramics as an art form and industry? New Assistant Response: The integration of modern technology, particularly 3D printing and advanced kiln technologies, is reshaping the traditional landscape of ceramics, offering both innovative possibilities and challenges for the future of this ancient art form. Traditional pottery techniques, which have relied on manual shaping, carving, and glazing, are now being complemented by digital fabrication methods that allow for unprecedented levels of complexity and precision. 3D printing, or additive manufacturing, enables artists to create intricate designs that would be nearly impossible to achieve by hand. This technology allows for the rapid prototyping of ideas and the exploration of new forms and structures that can push the boundaries of what is considered possible in ceramics. Moreover, 3D printing can significantly reduce the physical and time constraints associated with traditional pottery, making production more efficient and accessible to broader audience. Advanced kiln technologies are another critical area where modern innovations are transforming ceramics. Traditional kilns, while effective, are often limited in their control and uniformity. However, with the advent of computer-controlled kilns, potters now have precise control over the firing process, including temperature, atmosphere, and duration. This level of control allows for more consistent results and opens up new possibilities for glaze development and color application. For instance, digital kilns can simulate various firing conditions, enabling artists to experiment safely and cost-effectively with different firing techniques such as raku or salt firing, without the physical risks and environmental concerns associated with traditional methods. The implications of these technological advancements on the future of ceramics are multifaceted. On one hand, they democratize access to high-quality ceramic art, making it possible for more people to explore and create in this medium. This democratization can lead to more diverse and innovative ceramic art scene, as artists from various cultural backgrounds and with different levels of technical expertise can contribute. On the other hand, there is risk that these technologies could overshadow traditional skills, potentially leading to loss of handcraftsmanship and the unique aesthetic qualities that come with it. However, it is also possible that traditional and modern techniques will coexist and influence each other, enriching the ceramic art form in unexpected ways. In the industry, these technologies are already driving significant changes. Customization and mass production have become more feasible, allowing for the creation of personalized ceramic products at scale. This could open new markets and business models for ceramic artists and manufacturers, potentially leading to resurgence in ceramic production as viable commercial enterprise. Additionally, the integration of technology into the ceramic industry could lead to advancements in sustainability, as more efficient firing processes and the use of recycled materials become practical. In conclusion, the application of modern technology in ceramics is not just about enhancing traditional practices but fundamentally redefining them. While these advancements present both opportunities and challenges, they undoubtedly hold the potential to transform ceramics into an even more vibrant and dynamic field in the years to come. Table 10: Generated instance of SYSGEN data. The original data is originated from Airoboros (Jondurbin, 2024). 13 System: Given conversation history between users question and assistants response, you are system prompt generation assistant to generate relevant system prompt. The following [System Prompt] seems to have mix of 8 different [functionalities]: <Tasks>, <Tools>, <Style>, <Action>, <Content>, <Background>, <Role>, and <Format>. Try to annotate each functionality within the system prompt in phrase-level. Annotate each tag of functionalities. Generate [Generated System Prompt] with same language used in [Conversational History]. ## [Functionalities] 1. Task: what tasks will be performed? 2. Tool: What features or tools are available to integrate and use? 3. Style: What style of communication would you prefer for responses? 4. Action: Perform specific action 5. Content: Specifies the content that needs to be included in the response 6. Background: Provides specific background information to ensure the models responses align with these settings. 7. Role: Specifies the role, profession, or identity that needs to be played. 8. Format: Answers should be given in specific format, which may include lists, paragraphs, tables, etc. User: ## [Few-shot Examples of System Prompt] ### 1 RoleYou are an expert data augmentation system/Role Taskfor korean text correction model training./Task TaskGenerate pairs of data augmentation example./Task BackgroundYou are an intelligence AI model Solar-pro invented by Upstage AI./Background Instructions: ContentIn given text, create 13 typos./Content ContentTypos can be reversed, misplaced, missing, duplicated, or misspaced letters./Content ActionIf the given text contains English, generate an English typo./Action ActionGenerate the results in the Output JSON format below./Action Style-The response is informational and comprehensive, reflecting an expert understanding of the subject matter./Style Format Output JSON format: { \"original_expression\": ORIGIN AL_EXP RESSION , \"typo_expression\": O_EXP RESSION } /Format ### 2 RoleYou are an AI meeting note-taking assistant./Role TaskYour task is to generate meeting notes from the given conversation record./Task StyleAll responses must be in Korean./Style ActionTake deep breath, think carefully, and perform your role step by step./Action ### 3 RoleYou are chatbot of the Ministry of Food and Drug Safety (MFDS)./Role TaskYou answer user questions by referring to the provided reference./Task BackgroundYou are designed to provide information related to pharmaceuticals and cosmetics. You have knowledge of cosmetics-related information from Korea, the United States, Europe, China, India, and Taiwan./Background ContentIf the users question is related to the reference, respond starting with \"According to the title,\"./Content ContentIf the users question is not related to the reference, respond with \"Sorry, couldnt find any information to answer your question. Please try asking again.\"/Content ContentIf the users question is not related to food and drug safety, respond with \"Sorry, am chatbot operated by the Ministry of Food and Drug Safety. can only answer questions related to the Ministry of Food and Drug Safety.\"/Content StyleRespond to the users questions kindly./Style BackgroundThe reference is provided as context./Background"
        },
        {
            "title": "Conversational History",
            "content": "Table 11: The prompt of generating system messages using open-source models. Italic text part such as Conversational History is filled with input text. 14 System: You are functionality verifier assistant evaluating whether system messages are properly tagged according to the descriptions of 8 functionalities. Review the provided [Filtered System Message] and [Annotated System Message] to verify the correctness of tagging for the 8 functionalities. Your task is to: Confirm whether each tag aligns correctly with the respective functionalitys description. If tag is properly generated and annotated, mark it as \"Good\". If tag exists but does not align with its functionality, mark it as \"Bad\". If tag is missing, mark it as \"None\" ## [Functionalities] 1. Task: what tasks will be performed? 2. Tool: What features or tools are available to integrate and use? 3. Style: What style of communication would you prefer for responses? 4. Action: Perform specific action 5. Content: Specifies the content that needs to be included in the response 6. Background: Provides specific background information to ensure the models responses align with these settings. 7. Role: Specifies the role, profession, or identity that needs to be played. 8. Format: Answers should be given in specific format, which may include lists, paragraphs, tables, etc. ## [Expected Output Format] Task: Good Tool: None Style: Good Action: Good Content: Bad Background: Bad Role: Bad Format: Good User: ## [Filtered System Message] Filtered system messages ## [Annotated System Message] Annotated system messages ## [Expected Output Format] Table 12: The prompt of verification of key functionalities (phase 3) using open-source models with annotated system messages and filtered system messages. Italic text part is filled with input text. The user instruction will be provided, along with two assistant responses. Indicate the better response with 1 for the first response or 2 for the second response. User Instruction: User Instruction Assistant Response 1: Original Answer Assistant Response 2: Newly-generated Answer Which of the above two responses better adheres to the instruction? (Respond with 1 or 2) Table 13: The prompt of answer quality check through the proprietary model (e.g., GPT4o). Italic text part is filled with input text."
        }
    ],
    "affiliations": []
}