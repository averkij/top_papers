{
    "paper_title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?",
    "authors": [
        "Jingyi Chai",
        "Shuo Tang",
        "Rui Ye",
        "Yuwen Du",
        "Xinyu Zhu",
        "Mengcheng Zhou",
        "Yanfeng Wang",
        "Weinan E",
        "Yuzhi Zhang",
        "Linfeng Zhang",
        "Siheng Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The rapid advancements of AI agents have ignited the long-held ambition of leveraging them to accelerate scientific discovery. Achieving this goal requires a deep understanding of the frontiers of human knowledge. As such, Humanity's Last Exam (HLE) provides an exceptionally challenging touchstone for evaluating scientific AI agents. In this work, we aim to construct the foundational architecture for general-purpose agents and validate the capabilities through leading performance on HLE. To achieve this, we introduce X-Master, a tool-augmented reasoning agent designed to emulate human researchers by interacting flexibly with external tools during its reasoning process. This agent, guided by the conceptualization of code as an interaction language, can flexibly leverage built-in Python libraries and our customized tools to augment the reasoning. We further scale its capabilities through X-Masters, a scattered-and-stacked agentic workflow that systematically enhances breadth and depth of reasoning. Our open-source solution, X-Masters, sets a new state-of-the-art record on HLE with a score of 32.1%, surpassing OpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to exceed the 30% threshold. This work allows us to gain a deeper understanding of complex task-solving and accumulates valuable experience that can inform future advancements, guiding subsequent model training."
        },
        {
            "title": "Start",
            "content": "SciMaster: Towards General-Purpose Scientific AI Agents Part I. X-Master as Foundation Can We Lead on Humanitys Last Exam? Jingyi Chai1 Shuo Tang1 Rui Ye1 Yuwen Du1 Xinyu Zhu1 Mengcheng Zhou1 Siheng Chen1 Yanfeng Wang1 Weinan E1,2 Yuzhi Zhang2 Linfeng Zhang2 1 School of Artificial Intelligence, Shanghai Jiao Tong University 2 DP Technology 5 2 0 2 J 8 ] . [ 2 1 4 2 5 0 . 7 0 5 2 : r X-Master: https://github.com/sjtu-sai-agents/X-Master SciMaster is series of studies aimed at developing general-purpose scientific AI agents. In Part I, X-Master establishes the foundational architecture, laying the groundwork for enhancing the general capabilities of AI agents. Figure 1: Comparisons on Humanitys Last Exam. Our X-Masters achieves the state-of-the-art score of 32.1%, surpassing deep research products from Kimi, Gemini, and OpenAI."
        },
        {
            "title": "Abstract",
            "content": "The rapid advancements of AI agents have ignited the long-held ambition of leveraging them to accelerate scientific discovery. Achieving this goal requires deep understanding of the frontiers of human knowledge. As such, Humanitys Last Exam (HLE) provides an exceptionally challenging touchstone for evaluating scientific AI agents. In this work, we aim to construct the foundational architecture for general-purpose agents and validate the capabilities through leading performance on HLE. To achieve this, we introduce X-Master, tool-augmented reasoning agent designed to emulate human researchers by interacting flexibly with external tools during its reasoning process. This agent, guided by the conceptualization of code as an interaction language, can flexibly leverage built-in Python libraries and our customized tools to augment the reasoning. We further scale its capabilities through X-Masters, scattered-and-stacked agentic workflow that systematically enhances breadth and depth of reasoning. Our open-source solution, X-Masters, sets new state-of-the-art record on HLE with score of 32.1%, surpassing OpenAIs and Googles Deep Research (26.6% and 26.9%) and becoming the first to exceed the 30% threshold. This work allows us to gain deeper understanding of complex task-solving and accumulates valuable experience that can inform future advancements, guiding subsequent model training. Equal Contributions. The ordering was randomized via dice roll. Technical Report"
        },
        {
            "title": "Introduction",
            "content": "Artificial intelligence (AI), particularly in the form of large language models (LLMs) (OpenAI, 2022; Dubey et al., 2024; Yang et al., 2024) is evolving at an unprecedented rate. In just two years, the landscape has shifted dramatically: from the conversational abilities of models like GPT3.5/4 (Ouyang et al., 2022; OpenAI, 2023), to the emergence of powerful reasoners like DeepSeek R1 (Guo et al., 2025), and now towards AI agents like OpenAIs o3 (OpenAI, 2025a) and Googles Gemini 2.5 Pro (DeepMind, 2025) with flexible tool-use capabilities. This shift towards generalpurpose agents has ignited the long-held ambition of leveraging AI agents to accelerate scientific discovery (Gottweis et al., 2025), where they can catalyze breakthroughs by reasoning over vast knowledge and exploring ideas beyond the constraints of human cognition. In this series of studies, we aim to progressively build up SciMaster, open-source, general-purpose scientific AI agents. To enable AI-driven scientific discovery, an essential prerequisite is that an AI agent first demonstrate deep grasp of the current frontiers of human scientific knowledge. To this end, Humanitys Last Exam (HLE) (Phan et al., 2025) serves as critical and exceptionally challenging touchstone. Developed through global collaboration of nearly 1,000 subject experts from over 500 institutions, HLE comprises diverse, expert-level challenges at the frontier of human knowledge. Consequently, strong performance on HLE is highly indicative of an agents aptitude for navigating the complex problems inherent in advanced scientific research. While promising strides have been made on HLE by leading models from OpenAI (26.6%) (OpenAI, 2025c) and Google DeepMind (26.9%) (DeepMind, 2025), their closed-source nature severely limits community understanding and participation, hindering widespread exploration and innovation. In light of this, in the first part of this series, we focus on constructing the foundational architecture for general-purpose agents and validating its general capabilities through leading performance on HLE. Our work explores practical roadmap of inference-time computation that enables opensource models to lead. This approach, bypassing the need for extensive model training, allows us to gain deeper understanding of diverse task-solving and accumulates valuable experience that can inform future advancements, guiding subsequent model training. By openly sharing the insights and methodologies developed throughout this process, we hope to foster greater participation and accelerate progress within the field. To achieve this goal, we introduce X-Master, general tool-augmented reasoning agent designed to flexibly interact with external tools during its reasoning process. As general-purpose agent architecture, X-Master will provide the architectural foundation for the development of SciMaster. The design rationale of X-Master is to emulate the dynamic problem-solving process of human researchers who fluidly pivot between internal reasoning and external tool-use. This creates symbiotic loop: tool outputs provide crucial feedback to sharpen the agents reasoning, while clearer reasoning leads to more intelligent and effective tool use. The core mechanism enabling this process is the conceptualization of code as an interaction language. When confronted with problem it cannot solve internally, X-Master formulates precise plan of action as code block. This \"plan\" is then executed, interfacing with any required resourcefrom the numerical power of NumPy and SciPy to our custom-designed toolkit for live web searches and data extraction. The result is seamlessly absorbed back into the agents context, enriching its understanding and informing its subsequent reasoning. This architecture transforms the model from static reasoner into an agile problem-solving agent, capable of actively seeking out and utilizing information just as human would. To unlock the full potential of our X-Master, we design scattered-and-stacked agentic workflow designed to scale its intelligence at inference time. This workflow, called X-Masters, is engineered to systematically enhance both the breadth and depth of reasoning by orchestrating multi-agent cognitive process, where instances of our X-Master adopt several specialized roles. The process begins with the scattered phase to establish breadth: multiple Solver agents work in parallel to generate diverse array of solutions, while Critic agents correct their potential flaws. Then, the stacked phase enhances depth, where Rewriter agents synthesize all preceding outputs into superior solutions before final Selector agent adjudicates the single best answer. Through such broad exploration and in-depth improvement, this workflow significantly enhances the capabilities of solving complex problems. Our X-Masters sets new record on Humanitys Last Exam with remarkable score of 32.1%. This score exceeds the previous records held by OpenAI and Googles Deep Research by substantial margin of 5.5 and 5.2 points respectively, being the first in the world to surpass 2 Figure 2: Overview of our X-Master, tool-augmented reasoning agent. Given user query, the agent starts the thinking process, where interaction with the environments such as tool calling would be invoked by generating code snippet. The execution results will be appended to the agents context, enriching its understanding and informing its subsequent thinking. In this case, the agent invokes interactions for three times (search to get the GitHub link, parse to get the arXiv paper link, then parse to get the affiliation) until it arrives at the final answer. the 30% threshold. Practically, when faced with challenging problem and uncertain about which model or method to use, X-Masters offers one of the bestif not the bestsolutions available. Critically, while these top-performing products remain closed-source, our solution is fully opensourced, providing all the essential details for replications and further improvements. In summary, the primary contribution of this paper is not single, novel method, but rather the sharing of valuable \"know-how\" with the research community. We demonstrate the possibility of achieving leading performance on an important benchmark, using accessible open-source models. In the future, we plan to build upon this work by developing an end-to-end trained system that internalizes these capabilities. Related code will be publicly available to encourage further research and collaboration."
        },
        {
            "title": "2 Tool-Augmented Reasoning Models as Agents",
            "content": "This section introduces our tool-augmented reasoning agent, starting from an overview, to our core design of code as interaction language, to tools for interaction with the internet. 2.1 Overview X-Master is tool-augmented reasoning agent powered by open-source models (e.g., DeepSeekR1 (Guo et al., 2025)) designed for flexible interaction with external tools during its deep thinking process. To achieve this without requiring extensive model retraining, our approach primarily centers on the dynamic manipulation of the models context. Given query from the user that is potentially time-sensitive and knowledge-intensive, the reasoning agent initiates thought process akin to that of non-agentic models. Distinctively, our method guides this agent to engage with external environments (e.g., the internet) as needed, for instance, when real-time information is required. Specifically, if the agent intends to interact with the environments, the agent is guided to generate Python code that accurately reflects its current requirements. This generated code is then extracted and dispatched to code executor, which provides access to various Python libraries and our implemented tools. The execution results are subsequently appended to the models context, enabling the reasoning model to seamlessly continue its thought process. Notably, the agent possesses the capability to initiate such interactions iteratively, either to acquire novel information or to validate its existing conclusions. Please refer to Figure 2 for an overview. This methodology effectively augments the reasoning capabilities of models by extending their access to external environments, thereby transcending the limitations of their inherent knowledge and intelligence boundaries. In the following, we introduce how the agent interacts with environments via coding, how non-agentic model is guided towards an agent, and our principal tools. 2.2 Code as Interaction Language Our X-Master is designed to generate Python code as language to interact with external environments. Specifically, during the thinking process of the agent (i.e., between <think> and </think> ), the agent could either generate non-code texts for reasoning or codes within the special tokens of <code> and </code> for interacting with the environments. Once this pattern is detected via string matching, the code within would be extracted and executed in sandbox environment, where various python libraries and tools are accessible. The executed result is then appended to the models context, enclosed by two special tokens <execution_results> and </execution_results> . Subsequently, the reasoning model continues the thinking process, interpreting the execution results and reasoning further, until the next interaction is invoked or the ending of thinking. Representing interaction intention as Python code offers three advantages: (1) Universality: almost all functions can be implemented through writing code, facilitating the agent to address various tasks. (2) Accuracy: coding language can reflect the accurate needs of agents in compact and logical manner, enabling efficient interaction. (3) Compatibility: using Python code indicates that the reasoning models can access any existing well-established libraries from the community. 2.3 Initial Reasoning Guidance Since currently available strong reasoning models (e.g., DeepSeek-R1) are inherently non-agentic and often exhibit limited instruction-following capabilities, conventional prompt engineering alone proves insufficient to reliably guide these models towards expected agentic behavior. Instead, we introduce simple yet effective mechanism: Initial Reasoning Guidance. Specifically, rather than allowing the reasoning models to commence their unconstrained thinking process immediately upon receiving user query, we embed series of guiding texts directly after the models initial <think> token. These guiding texts are deliberately crafted from the perspective of the reasoning agent itself, speaking in the first person. For instance, such guidance includes statements like: (1) can answer this query effectively by leveraging access to external environments. (2) Every time determine the need for interaction with external tools, will generate Python code enclosed between <code> and </code> tags. By concatenating these meticulously designed self-statements into the models context, we effectively lead the model to \"believe\" in its own enhanced capabilities. Consequently, the model is empowered to spontaneously generate and execute code, interact with its environment, and ultimately function as capable agent, even without explicit finetuning for agentic behavior. 2.4 Tools By expressing interactions as Python code, our X-Master gains strong flexibility, capable of integrating wide spectrum of toolsfrom existing Python libraries to custom-built modules, and even generating new tools dynamically. Notably, when we equip X-Master with suite of professional scientific computing tools, empowering it to solve domain-specific research problems and advance scientific discovery. Here, we mainly introduce our custom-built tools for information-seeking tasks. To emulate human-like online information-seeking behavior, we design two core tools: web search and web parse. The web search tool facilitates the agents ability to identify relevant webpages based on the question. It provides concise summaries for each retrieved page, enabling the agent to strategically determine which links warrant deeper exploration. The web parse tool is employed when the agent requires more thorough examination of selected webpage to extract information directly related to the user query. Web search. The web search tool leverages the Google search engine to identify the most relevant webpages for given question. It furnishes three types of highly valuable information: (i) Entityrelated facts: For questions containing identifiable entities (e.g., company or application), the tool can detect these and retrieve structured facts from its knowledge graph, including name, description, and key attributes. Extracting these facts enables the agent to rapidly comprehend the core concept 4 Figure 3: Overview of our X-Masters, scattered-and-stacked agentic workflow. The workflow leverages X-Master as different roles to enhance solution quality at inference. It includes (1) Solvers generating five initial solutions, (2) Critics refining the initial solution, (3) Rewriters synthesizing all five solutions to generate new five, and (4) Selector choosing the best solution. of the question, thereby providing crucial context for subsequent reasoning. (ii) Relevant webpage previews: For each pertinent page, the tool presents preview comprising its title, URL, and descriptive snippet. This functionality assists the agent in quickly discerning the pages content and prioritizing those warranting deeper exploration. (iii) Related search queries: The tool also provides common related queries, which offer the agent avenues for follow-up searches and contribute to broader understanding of the topic. Web parse. The web parse tool offers support for two distinct parsing strategies, tailored for general webpages and scientific papers, respectively: (i) General webpage parsing: This strategy initiates by extracting the primary content from the target webpage. To ensure robust operation, fallback mechanism is incorporated to manage instances where direct content extraction may encounter failures. Following content acquisition, the tool proceeds to identify segments highly relevant to the query. Furthermore, it automatically detects and returns links along with brief descriptions of pertinent subpages. This feature enables the agent to explore information more deeply, effectively emulating human behavior of navigating interconnected web content to gain comprehensive topic understanding. (ii) Scientific paper parsing: For scientific papers, the tool employs two-step strategy to guarantee reliable content retrieval. Initially, it endeavors to retrieve an HTML version of the publication from ar5iv. In the event of an unsuccessful or incomplete HTML fetch, the system transparently reverts to downloading the authoritative PDF document. Upon successful acquisition of the papers full content, the tool automates the process of extracting information directly correlated with the question. In this way, the web search and web parse tools not only help the agent find relevant information, but also encourage the agent to explore the web in more human-like wayby searching, scanning, clicking, and digging deeper as needed."
        },
        {
            "title": "3 Scattered-and-Stacked Agentic Workflows for Inference-Time Computation",
            "content": "To further scale the potential of our powerful tool-augmented reasoning agent at inference time, we propose X-Masters, an agentic workflow based on the principles of scattered and stacked process. Scattering enables broad problem-solving across multiple instances, generating diverse solutions, while stacking facilitates iterative improvements through rewriting and final selection. The agent, powered by X-Master, performs four specialized roles: Solver, Critic, Rewriter, and Selector in tool-integrated manner, to execute this scattered-and-stacked process. 3.1 Workflow Overview As depicted in Figure 3, this workflow alternates between expansive exploration (scattering) and sequential refinement (stacking), leveraging X-Master at every stage. Specifically, the workflow includes four stages: (1) broad initial solutions generation by Solver, (2) solution refinement by Critic, (3) broad solutions rewriting, and (4) final selection. In Stage 1, Solver generates five initial solutions using tool-augmented reasoning for exploring scattered potential solutions. In Stage 2, Critic diagnoses flaws and amends the solution. Stage 3 stacks these results with Rewriter referring 5 to all solutions and rewriting five. Stage 4 stacks once more: the Selector compares all five solutions from Rewriters, then selects the optimal one. Overall, scattering aims to explore different diverse solutions, while stacking enhances the quality by integrating the intelligence of previous solutions. The scatteredstacked design combines breadth and depth: broadening solutions fosters diversity, whereas iterative improvement enhances precision. 3.2 Scattering for Broad Exploration The scattering phase of the workflow involves two distinct broad processes to explore diverse solutions. For breadth, the agent answers the query five times concurrently, each with the same temperature, leveraging the random nature of the decoding process of large language models. In Stage 1, the Solver generates five initial solutions concurrently, each with tool-augmented reasoning. Afterward, the Critic concurrently evaluates each of these five solutions, identifying flaws and providing corrections or improvements, ensuring that all generated solutions are internally consistent and refined. The second part of the scattering phase (Stage 3) enhances the quality of solutions by the rewriting process. The Rewriter generates five refined versions of each initial solution. This ensures that multiple improvements are explored simultaneously, creating diverse set of reworked answers. By combining breadth in both solution generation and rewriting, the system enhances its ability to explore and refine multiple solution paths, providing richer set of potential solutions for further refinement. 3.3 Stacking for Sequential Refinement The stacking phase enhances and combines solutions through rewriting and selection. In Stage 3, the Rewriter synthesizes the scattered solutions into coherent draft, resolving redundancies and contradictions. Then, second scattering occurs, where five Rewriters comprehensively analyze the previous five solutions and generate five. Finally in Stage 4, the Selector aggregates these refined solutions, selecting the most optimal one based on logical consistency and factual accuracy. By treating selection as form of stacking, the workflow ensures that the final output combines diverse insights and iterative refinements, resulting in high-quality solution. 3.4 Discussion: An Analogy to Rollouts in Reinforcement Learning Our scattered-and-stacked architecture is fundamentally strategy for structured exploration and exploitation, drawing strong parallel to the concept of \"rollouts\" in reinforcement learning (RL) (Tesauro et al., 1995; Sutton et al., 1998; Auer et al., 2002; Guo et al., 2025). This underlying logic also resonates with recent advancements in RL, where enabling models to explore diverse solutions and leveraging self-generated rewards has proven effective in training stronger models (Zhao et al., 2025a,b; Prabhudesai et al., 2025). (1) The \"scattered\" phase mirrors the exploratory principle of rollouts in RL that simulate several future trajectories to evaluate the potential of different actions. Leveraging the agents (models) stochastic decoding, each agent explores different reasoning path, ensuring diversity of initial strategies and preventing premature convergence on single, potentially suboptimal idea. (2) The subsequent \"stacked\" phase is analogous to the aggregation and \"exploitation\" step that follows rollouts in RL. Agents aggregate insights from all parallel explorations to construct superior, more robust solution, ensuring the final output synthesizes the best elements discovered. In essence, the scattered-and-stacked workflow operationalizes the exploration-exploitation paradigm at inference time. Scattering broadly explores possibilities, while stacking deeply refines them. This structured thinking allows the system to tackle complex problems more effectively than single reasoning process, thereby scaling the agents intelligence."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Experimental Setups Agent. We use DeepSeek-R1-0528 (DeepSeek-AI, 2025) as the reasoning model to drive the agent. The maximum completion of tokens is set to 64k with temperature of 0.6. 6 Figure 4: Performance across categories of DeepSeek-R1-0528 and X-Masters on HLE. Figure 5: Performance of Biology/Medicine category of HLE. Testing. Since the currently leveraged model is not multi-modal, we focus on the text-only subset from Humanitys Last Exam (Phan et al., 2025), which comprises 2,518 samples following (Moonshot-AI, 2025). For evaluation, we run the workflow for three times and report the average score, and utilize o3-mini (OpenAI, 2025b) as the judge model following the official setup. Baselines. We compare our workflows performance against systems spanning two categories: research agents (OpenAIs Deep Research (OpenAI, 2025c), Google DeepMinds Deep Research (DeepMind, 2025), Kimi-Researcher (Moonshot-AI, 2025)) and advanced models (Gemini 2.5 Pro (DeepMind, 2025), DeepSeek-R1-0528 (DeepSeek-AI, 2025), and Claude 4 Opus (Anthropic, 2025)). The results on HLE of these models are taken from existing leaderboards. 4.2 Main Results on Humanitys Last Exam The performance results of X-Masters against other systems in Humanitys Last Exam (HLE) are shown in Figure 1. X-Masters achieves the highest score of 32.1%, surpassing all existing agents and models, including Gemini Deep Research, and OpenAI Deep Research, which scored 26.9% and 26.6%. Excitingly, this is the first time that system performs above 30% on HLE, setting promising new record. The leading performance on extremely challenging HLE speaks volumes about the excellence of tool-augmented X-Master and the inference-time agentic workflow. In addition, we report the performance across different categories in Figure 4, where X-Masters shows notable improvement across all categories compared to DeepSeek-R1-0528. This highlights the broad applicability and effectiveness of our tool-augmented reasoning and agentic workflow. We also present the ablation results across workflow stages in Table 1. The results reveal progressive gains in the agentic workflow: tool-augmented reasoning (Solver) lifts baseline accuracy by 3.4%, iterative refinement (Critic and Rewriter) adds 9.5%, and final selection (Selector) achieves the record 32.1%. Detailed role-wise analysis follows in Section 4.4. 4.3 Comparisons with Scientific Agents on Biology X-Masters outperforms existing systems on the Biology/Medicine category of HLE. Recent works, such as Biomni (Huang et al., 2025) and STELLA (Jin et al., 2025b) have made progress in addressing biological challenges by leveraging LLM agents with an extensive collection of specialized tools. As illustrated in Figure 5, while Biomni gets 17.3% and STELLA gets approximately 26%, our X-Masters achieves 27.6% accuracy in Biology/Medicine category. Note that these two systems evaluate on their selected questions from the Biology/Medicine category; in contrast, we evaluate X-Masters on the complete 222 text-only questions. The domain-specific results illustrate X-Masters advanced capabilities in solving complex biomedical problems, emphasizing its significant potential for contributing to biological research. X-Masters achieves the state-of-the-art performance on the biology benchmark TRQA. Beyond general scientific challenges, we evaluate X-Master on TRQA-lit (choice) (Zhang et al., 2025), specialized benchmark comprising 172 multiple-choice questions on biological research. The TRQAlit dataset targets complex research tasks in the biological domain, including the identification of therapeutic targets, and biomedical mechanisms. These tasks represent high-level challenges faced by human experts in the field. 7 Figure 6: Performance of X-Masters with other models on biology benchmark TRQA-lit (choice). Without any modification, X-Masters also achieves the state-of-the-art performance on this benchmark. Figure 7: Frequency of correct answers before and after rewriting stage. Rewriting significantly enhances the likelihood of all 5 solutions being correct. Table 1: Progressive accuracy improvement across stages of the X-Masters agentic workflow versus the DeepSeek-R1-0528. Tool augmentation and inference-time computation drive performance gains. Method R1 Reasoning Model without Tool X-Master (Ours) Solver Critic Rewriter Selector Accuracy (%) 17.7 21.1 25.0 30.6 32.1 Here, we report the results of X-Master and X-Masters in Figure 6, where the results of other models are referred from paper (Zhang et al., 2025). Results show that (1) standalone X-Master achieves 62.1%, already outperforming other models with tool-augmented reasoning. (2) With the simple agentic workflow, X-Masters achieves state-of-the-art 67.4%, demonstrating the effectiveness of scattered exploration and stacked selection. (3) Compared with OriGene (Zhang et al., 2025), multi-agent system that integrates over 500 expert tools, our X-Master, utilizing only two web tools, obtains higher accuracy. This reinforces the demonstrated efficiency of X-Masters tool-augmented reasoning process, where broad exploration and stacked selection enable it to effectively solve complex biological tasks. 4.4 Analysis Tool-augmented reasoning enhances DeepSeek-R1. In our agentic workflow, Solver accesses external tools an average of 3 times per query while generating initial solutions. For simplicity, we use the average score of the parallel generated initial 5 solutions to estimate the pass@1. Shown in Table 1, when tool support is enabled, pass@1 rises from 17.7% to 21.1%, indicating the effectiveness of inference-time tool augmentation in improving the accuracy of the first attempt. Critic boosts refinement of solution. In the scattered solution exploration, each solution is first generated by the Solver and then refined by the Critic. We compare the average scores of the initial five solver solutions before and after applying the criticism in Table 1. We find that this stage delivers substantial improvement: the average accuracy rises from 21.1% to 25.0%. This demonstrates the Critics crucial role in identifying errors and enhancing solution quality. Rewriting significantly improves solution quality. From Table 1, the Rewriter consolidates insights from scattered solutions, achieving 5.6 point leap to 30.6% accuracy. To further understand the essence of the rewriting stage, we compare the frequency of the number of correct answers among 5 solutions before and after applying the rewriting. Shown in Figure 7, we can observe noticeable increase in the frequency of higher correctness numbers ( 3), particularly for solutions with 5 fully correct answers. This shift suggests that the rewriting process effectively improves the quality of the solutions. In addition, the movement from mid-frequency correctness to higher correctness also 8 makes the subsequent Selector choose the optimal solution from 5 solutions. Therefore, the rewrite phase serves as critical quality amplifier, transforming scattered candidate solutions into refined, high-value solution pool. Scattering and stacking matter in the agentic workflow. We conduct an ablation study of our scattered-and-stacked agentic workflow, shown in Table 2. When no scattering, Solver only generates one solution, Critic refines the solution, and Rewriter analyzes the single solution to generate new one. The absence of parallel exploration slashes accuracy to 25.5%. When no stacking, rewriting and final selection stages are removed, the workflow loses its depth-wise improvements and accuracy drops to 25.0%. Enabling both scattering and stacking boosts performance to 32.1%. The results confirm that scattering supplies diverse solutions, while stacking distills them into higher-quality answer; only their synergy realizes both breadth and depth in reasoning. Table 2: Ablation study of scattering and stacking feature in the agentic workflow. scatter stack Accuracy (%) 25.5 25.0 32.1 Examples. We provide three examples of X-Masters problem-solving trajectories in Figure 8, 9, 10."
        },
        {
            "title": "5 Related Works",
            "content": "Tool-augmented LLMs. There are several recent works that focus on leveraging external tools to augment LLMs, which apply different strategies for tool invocation. (1) Prompt engineering for structured outputs. Some methods, like Agentic Reasoning (Wu et al., 2025b), leverage prompt engineering to guide LLMs in generating outputs in specific format for subsequent processing by other LLM calls. While effective for fixed agentic workflows, these approaches often lack the adaptability needed for complex problems requiring iterative tool usage. (2) Special token-guided tool invocation. Methods such as Search-R1 (Jin et al., 2025a), Search-o1 (Li et al., 2025a), R1Searcher (Song et al., 2025), WebThinker (Li et al., 2025b), and WebDancer (Wu et al., 2025a) guide the model to generate tool invocation content within specific special tokens (e.g., search). The results from these tools are then re-inserted into the models context. However, significant limitation here is that integrating each new tool necessitates manual modifications to the tool invocation rules. This makes them less practical for diverse and complex real-world tasks, such as scientific research, which often demand wide array of tools. (3) Code generation for computation. Methods such as ToRL (Li et al., 2025c) and ReTool (Feng et al., 2025) enable LLMs to generate code for computational tasks, like mathematical calculations. However, their scope is typically limited to computation, overlooking the broader need for custom tools tailored to real-world scenarios beyond mere calculations. Addressing the limitations of existing methods, our work offers the most general approach to tool usage currently available. We leverage Python code as an interaction language, which allows our agent to access: built-in Python libraries (e.g., for computation), our customized tools (e.g., web search), and even build its own tool during inference time. This unique extensibility empowers our agent to meet the demands of complex real-world tasks. Agentic workflows. Agentic workflows empower LLMs to tackle more complex tasks by orchestrating multiple LLM calls and tool interactions. For instance, AI co-scientist (Gottweis et al., 2025) leverages multiple agents and tools for scientific research; ChatDev (Qian et al., 2024) and MetaGPT (Hong et al., 2024) design agentic workflows for software development; MAS-GPT (Ye et al., 2025) generates query-specific workflows represented as Python code. However, common limitation in these existing methods is that their agents operate in fixed single-turn manner. This means they perform only one actioneither generating textual response or calling toolfor each assigned (sub-)task. In contrast, our X-Masters framework features agents that work in flexible multi-turn manner. This allows them to flexibly and iteratively interplay between internal reasoning and external tool usage, enabling more dynamic and adaptive approach to problem-solving."
        },
        {
            "title": "6 Conclusions and Future Works",
            "content": "This work presents X-Master, the foundational agent introduced as Part of our SciMaster series, which aims to enhance the general capabilities of AI agents and accelerate the pace of future scientific discovery. X-Master is general tool-augmented reasoning agent, designed to emulate human 9 problem-solving by flexibly interplaying between internal reasoning and external tool usage. Our conceptualization of code as an interaction language allows X-Master to flexibly interact with diverse resources. To further scale its intelligence at inference time, we develop scattered-and-stacked agentic workflow X-Masters, systematically enhancing both the breadth of exploration and the depth of exploitation during task solving. Remarkably, our X-Masters achieves score of 32.1% on Humanitys Last Exam (HLE), setting new world record that crosses the 30% threshold and surpassing the previous leading closed-source models from OpenAI (26.6%) and Google DeepMind (26.9%) by substantial margins. Our primary contribution lies not in proposing yet another algorithm, but in openly sharing the practical \"know-how\" that enables open-source models to attainand even surpassstate-of-theart performance on challenging benchmarks, such as HLE. By providing practical roadmap for enhancing LLM capabilities without requiring extensive retraining, we share insights into complex problem-solving and lay the groundwork for future advancements. With this work, we hope to demonstrate to the community that cutting-edge benchmarks are not the exclusive domain of resourcerich industry labs. Whats next? Looking ahead, SciMaster will significantly expand on the architectural foundation of X-Master. Our roadmap includes the development of specialized scientific agents and tools to support literature analysis, scientific computing, and experimental workflows. In addition, we aim to build end-to-end trained agents that fully internalize the sophisticated reasoning and tool-use capabilities showcased by X-Masters."
        },
        {
            "title": "References",
            "content": "Anthropic. Introducing claude 4. https://www.anthropic.com/news/claude-4, 2025. Accessed: 202507-03. Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 47:235256, 2002. Google DeepMind. Gemini 2.5: Our most intelligent ai model. https://blog.google/technology/ google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-thinking, 2025. Accessed: 2025-06-24. DeepSeek-AI. Deepseek-r1-0528. https://huggingface.co/deepseek-ai/DeepSeek-R1-0528, 2025. Accessed: 2025-06-27. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, and Wanjun Zhong. Retool: Reinforcement learning for strategic tool use in llms. arXiv preprint arXiv:2504.11536, 2025. Juraj Gottweis, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, Felix Weissenberger, Keran Rong, Ryutaro Tanno, et al. Towards an ai co-scientist. arXiv preprint arXiv:2502.18864, 2025. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al. Metagpt: Meta programming for multi-agent collaborative framework. In The Twelfth International Conference on Learning Representations, 2024. Kexin Huang, Serena Zhang, Hanchen Wang, Yuanhao Qu, Yingzhou Lu, Yusuf Roohani, Ryan Li, Lin Qiu, Junze Zhang, Yin Di, et al. Biomni: general-purpose biomedical ai agent. bioRxiv, pages 202505, 2025. Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Zamani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025a. Ruofan Jin, Zaixi Zhang, Mengdi Wang, and Le Cong. Stella: Self-evolving llm agent for biomedical research. arXiv preprint arXiv:2507.02004, 2025b. 10 Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng Dou. Search-o1: Agentic search-enhanced large reasoning models. arXiv preprint arXiv:2501.05366, 2025a. Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, and Zhicheng Dou. Webthinker: Empowering large reasoning models with deep research capability. arXiv preprint arXiv:2504.21776, 2025b. Xuefeng Li, Haoyang Zou, and Pengfei Liu. Torl: Scaling tool-integrated rl. arXiv preprint arXiv:2503.23383, 2025c. Moonshot-AI. Kimi-researcher: End-to-end rl training for emerging agentic capabilities. https://moonshotai. github.io/Kimi-Researcher/, 2025. Accessed: 2025-06-26. OpenAI. Introducing chatgpt. https://openai.com/index/chatgpt/, 2022. Accessed: 2025-06-24. OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. OpenAI. Introducing openai o3 and o4-mini. https://openai.com/index/ introducing-o3-and-o4-mini/, 2025a. Accessed: 2025-06-24. OpenAI. Openai o3-mini. https://openai.com/index/openai-o3-mini/, 2025b. Accessed: 2025-06-26. OpenAI. Introducing deep research. https://openai.com/index/introducing-deep-research/, 2025c. Accessed: 2025-06-26. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. NIPS, 35:2773027744, 2022. Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanitys last exam. arXiv preprint arXiv:2501.14249, 2025. Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, and Deepak Pathak. Maximizing confidence alone improves reasoning. arXiv preprint arXiv:2505.22660, 2025. Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, et al. Chatdev: Communicative agents for software development. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1517415186, 2024. Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne Xin Zhao, Lei Fang, and Ji-Rong Wen. R1-searcher: Incentivizing the search capability in llms via reinforcement learning. arXiv preprint arXiv:2503.05592, 2025. Richard Sutton, Andrew Barto, et al. Reinforcement learning: An introduction, volume 1. MIT press Cambridge, 1998. Gerald Tesauro et al. Temporal difference learning and td-gammon. Communications of the ACM, 38(3):5868, 1995. Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Yong Jiang, Pengjun Xie, et al. Webdancer: Towards autonomous information seeking agency. arXiv preprint arXiv:2505.22648, 2025a. Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research. arXiv preprint arXiv:2502.04644, 2025b. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115, 2024. Rui Ye, Shuo Tang, Rui Ge, Yaxin Du, Zhenfei Yin, Siheng Chen, and Jing Shao. Mas-gpt: Training llms to build llm-based multi-agent systems. arXiv preprint arXiv:2503.03686, 2025. Zhongyue Zhang, Zijie Qiu, Yingcheng Wu, Shuya Li, Dingyan Wang, Zhuomin Zhou, Duo An, Yuhan Chen, Yu Li, Yongbo Wang, et al. Origene: self-evolving virtual disease biologist automating therapeutic target discovery. bioRxiv, pages 202506, 2025. 11 Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, and Gao Huang. Absolute zero: Reinforced self-play reasoning with zero data. arXiv preprint arXiv:2505.03335, 2025a. Xuandong Zhao, Zhewei Kang, Aosong Feng, Sergey Levine, and Dawn Song. Learning to reason without external rewards. arXiv preprint arXiv:2505.19590, 2025b."
        },
        {
            "title": "7 Cases",
            "content": "Figure 8: Case 1. X-Master fluently handles the case where the tools do not work as expectation by adjusting the usage; and ensures the correctness of answer by cross-checking. 13 Figure 9: Case 2. X-Master fluently handles the case where the tools do not return the expected content by trying different strategies. 14 Figure 10: Case 3. X-Master conducts computations, adjusts strategies when encountering unmatched results, and verifies the final answer by writing python code."
        }
    ],
    "affiliations": [
        "DP Technology",
        "School of Artificial Intelligence, Shanghai Jiao Tong University"
    ]
}