{
    "paper_title": "Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance",
    "authors": [
        "Kwanyoung Kim"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Diffusion models have demonstrated strong generative performance when using guidance methods such as classifier-free guidance (CFG), which enhance output quality by modifying the sampling trajectory. These methods typically improve a target output by intentionally degrading another, often the unconditional output, using heuristic perturbation functions such as identity mixing or blurred conditions. However, these approaches lack a principled foundation and rely on manually designed distortions. In this work, we propose Adversarial Sinkhorn Attention Guidance (ASAG), a novel method that reinterprets attention scores in diffusion models through the lens of optimal transport and intentionally disrupt the transport cost via Sinkhorn algorithm. Instead of naively corrupting the attention mechanism, ASAG injects an adversarial cost within self-attention layers to reduce pixel-wise similarity between queries and keys. This deliberate degradation weakens misleading attention alignments and leads to improved conditional and unconditional sample quality. ASAG shows consistent improvements in text-to-image diffusion, and enhances controllability and fidelity in downstream applications such as IP-Adapter and ControlNet. The method is lightweight, plug-and-play, and improves reliability without requiring any model retraining."
        },
        {
            "title": "Start",
            "content": "Kwanyoung Kim Samsung Research 0.kim@samsung.com 5 2 0 2 0 1 ] . [ 1 9 9 4 7 0 . 1 1 5 2 : r Figure 1: Qualitative comparison. (a) unconditional generation, (b) conditional generation with other guidance sampling methods, and (c) conditional generation using ControlNet and IP-Adapter. Our method, ASAG, significantly improves visual quality in both unconditional and conditional settings. It also remarkably enhances external frameworks like ControlNet and IPAdapter. Crucially, ASAG requires no additional training, making it broadly compatible and readily deployable. Abstract Diffusion models have demonstrated strong generative performance when using guidance methods such as classifierfree guidance (CFG), which enhance output quality by modifying the sampling trajectory. These methods typically improve target output by intentionally degrading another, often the unconditional output, using heuristic perturbation functions such as identity mixing or blurred conditions. However, these approaches lack principled foundation and rely on manually designed distortions. In this work, we propose Adversarial Sinkhorn Attention Guidance (ASAG), novel method that reinterprets attention scores in diffusion models through the lens of optimal transport and intentionally disrupt the transport cost via Sinkhorn algorithm. Instead of naively corrupting the attention mechanism, ASAG injects an adversarial cost within self-attention layers to reduce pixel-wise similarity between queries and keys. This deliberate degradation weakens misleading attention alignments and leads to improved conditional and unconditional sample quality. ASAG shows consistent improvements in text-to-image diffusion, and enhances controllability and fidelity in downstream applications such as IP-Adapter and ControlNet. The method is lightweight, plug-and-play, and improves reliability without requiring any model retraining. Introduction Diffusion models have led to substantial progress in the field of image and video generation (Rombach et al. 2022; Esser et al. 2024a; Ruiz et al. 2023; Chen et al. 2024b; Xie et al. 2024; Blattmann et al. 2023; Chen et al. 2024a). Despite their effectiveness, direct or naıve sampling often results in subpar output quality. widely adopted solution is Classifier-Free Guidance (CFG) (Ho and Salimans 2022), which enhances class-conditional generation by computing the difference between the score functions of conditional and unconditional models and applying weighted adjustment. Although CFG improves sample fidelity, it introduces additional training and can lead to degraded outputs when the guidance scale is too large. Inspired by CFG, number of guidance-based sampling techniques have emerged (Hong et al. 2023; Karras et al. 2024; Ahn et al. 2025; Hong 2024; Chung et al. 2024; Sadat et al. 2024; Li et al. 2024). common strategy involves generating weakened outputs to serve as auxiliary signals that guide the primary model toward better sampling. While such approaches have shown empirical success, they come with inherent limitations. For example, AutoGuidance (AG) (Karras et al. 2024) relies on poorly trained model, which is often unstable and difficult to optimize. To avoid retraining, attention based alternatives have been proposed. Perturbed Attention Guidance (Ahn et al. 2025) distorts attention maps using identity masking, and Smooth Energy Guidance (SEG) (Hong 2024) applies Gaussian blur to attention weights. Although these methods aim to weaken model outputs for improved guidance, they rely on naive heuristic functions and lack clear theoretical justification as to why such perturbations consistently enhance sample quality. This theoretical gap naturally raises fundamental question: what constitutes an optimal perturbation for weakening outputs in theoretically grounded manner? To address this question, we first revisit the intrinsic connection between attention mechanisms and optimal transport (OT) theory. One of the key contributions of this paper is the discovery and reinterpretation of classical results from optimal transport, highlighting how attention mechanisms can be framed within the OT framework. Prior studies, such as those by (Sander et al. 2022; Kim, Oh, and Ye 2024), have shown that attention computations can be improved by employing OT-inspired methods, specifically the SinkhornKnopp algorithm (Cuturi 2013), to produce doubly stochastic attention maps. While these previous studies have largely utilized OT theory to boost attention performance in vision and language tasks (Chen et al. 2020; Liu et al. 2020; Chen et al. 2022), our approach deviates significantly from this established perspective. Specifically, we propose novel guidance frametermed Adversarial Sinkhorn Attention Guidwork, ance (ASAG), which explicitly reinterprets self-attention scoresrepresenting pixel-level similarities and interactionsthrough the lens of OT theory. In contrast to classical OT-based approaches that minimize transport cost to encourage semantic alignment between image embeddings, ASAG adopts an adversarial perspective by intentionally minimizing their interactions. This leads to an entropy-maximizing attention map, which corresponds to an optimally perturbed self-attention distribution. In doing so, we establish theoretically grounded method for systematically disrupting similarity-based alignments in diffusion models. To the best of our knowledge, this is the first work to leverage OT theory to construct an adversarial attention perturbation, leading to significant improvements in the fidelity and controllability of diffusion-based image generation. Building upon these theoretical foundations and insights, we demonstrate that our proposed method, ASAG, effectively improves generation quality in both unconditional and conditional diffusion sampling settings. Furthermore, extensive experiments show that when combined with existing frameworks such as ControlNet and IP-Adapter, ASAG consistently outperforms other guidance approaches by significant margin. Our key contributions can be summarized: We propose ASAG, novel and theoretically grounded diffusion guidance method that adversarially disrupts attention mechanisms by intentionally minimizing interaction between image embeddings. We provide an in-depth theoretical analysis, leveraging OT theory to establish clear and rigorous foundation for our guidance method. To the best of our knowledge, our study is the first to reinterpret OT theory from an adversarial perspective for perturbing attention scores to improve diffusion generative performance. We empirically demonstrate that ASAG significantly enhances performance across general generative tasks, including unconditional and conditional image generation. Furthermore, we show the broad applicability and generalizability of ASAG by integrating it with widelyused generative frameworks such as ControlNet and IPAdapter, achieving substantial improvements over existing guidance approaches."
        },
        {
            "title": "Diffusion Models",
            "content": "Diffusion models (DM) (Ho, Jain, and Abbeel 2020; Song et al. 2021) are class of generative models that produce samples by reversing known forward diffusion process through estimation of the score function of given data distribution. Specifically, given samples x0 qdata(x), DMs define forward noise-adding Markov process q(xtxt1) = ( = 1, . . . , T, where the variance schedule {βt}t=1,...,T is predefined. 1 βtxt1, βtI), Consequently, the distribution at any intermediate timestep can be explicitly expressed as q(xt) = αtx0, (1 αt)I), with the cumulative coefficient deN ( fined as αt = (cid:81)t i=1 αi, where αt = 1 βt. As approaches , the distribution q(xT ) converges to an isotropic Gaussian distribution, q(xT ) (0, I). To generate samples, diffusion models parameterize the reverse diffusion process as, pθ(xt1xt) = (µθ(xt, t), Σθ(xt, t)), where the model parameters θ can be optimized by denoising score matching (DSM) objective (Vincent 2011): (cid:2)ϵθ( αtx0 + Ex0,ϵ min θ 1 αtϵ, t) ϵ2 (cid:3) , (1) where ϵ (0, I). Once trained, sampling from diffusion model proceeds by sequentially reversing the diffusion steps starting from an isotropic Gaussian noise sample. For instance, the Denoising Diffusion Implicit Model (DDIM) (Song, Meng, and Ermon 2021) generates samples by iteratively applying the update rule: xt1 = αt1 ˆx0(t) + (cid:112)1 αt1ϵθ(xt, t), (2) where the denoised estimate ˆx0(t) = E[x0xt] is computed using Tweedies formula (Efron 2011; Kim and Ye 2021): xt 1 αtϵθ(xt, t) ˆx0(t) = . (3) αt The sampling step described above is repeated recursively from timestep down to timestep 1."
        },
        {
            "title": "Guidance Sampling in Diffusion Models",
            "content": "To enhance generation with arbitrary conditions (typically class or textual embeddings), various guidance-based sampling methods have been proposed (Dhariwal and Nichol 2021; Ho and Salimans 2022; Chung et al. 2024; Hong et al. 2023; Karras et al. 2024; Ahn et al. 2025; Hong 2024; Sadat et al. 2024). Let the conditional model be defined as ϵθ(xt, t, c), which we simplify as ϵθ(xt, c), and the unconditional counterpart as ϵθ(xt, ). Several studies (Ho and Salimans 2022; Hong et al. 2023; Ahn et al. 2025) have proposed generalized guidance frameworks using imaginary labels. We revisit this idea with an implicit discriminator D(xt) = p(yxt) p(yxt) , which distinguishes desirable from undesirable samples during the diffusion process. Here, and denote imaginary desirable and undesirable labels, respectively. Similar to CFG, which uses an implicit classifier, implicit discriminator encourages sampling along desirable trajectories while suppressing undesirable ones. By applying Bayes rule and mathematical transformation, we derive the following guided sampling objective: ϵ θ(xt, c) = ϵθ(xt, c) sσtxt (log p(xty) log p(xty)) = ϵθ(xt, c) + (ϵθ(xt, c) ϵθ(xt, c)) , (4) where is the guidance strength. Since the diffusion model learns to approximate the score function of the desirable distribution, the term σtxt log p(xty) can be replaced by ϵθ(xt, c). The term ϵθ is heuristically constructed weaker variant that simulates an undesirable score. For example, in CFG, the class condition is dropped, while in PAG, an identity condition is injected to produce undesirable outputs. Although these approaches have shown empirical success and clearly demonstrate the necessity of modeling undesirable paths, the theoretical justification for how to construct such paths remains limited. Optimal Transport and Sinkhorn-Knopp In classical discrete optimal transport (OT), given predefined cost matrix Rnn and two probability vectors µ, ν Σn = {p Rn : 0, 1p = 1}, the OT problem is formulated as: dM(µ, ν) = min P, M, (5) U(µ,ν) where U(µ, ν) = {P Rnn + P1n = µ, P1n = ν} denotes the transport polytope consisting of non-negative matrices with prescribed row and column sums, and , indicates the Frobenius inner product. Directly solving the OT problem incurs computational cost of O(n3 log n), which is often prohibitively expensive. To overcome this, the entropy-regularized OT formulation, solved via the Sinkhorn-Knopp (Sinkhorn) algorithm (Cuturi 2013), is defined as: dλ M(µ, ν) = min U(µ,ν) P, 1 λ P, log P, (6) where λ > 0 is the regularization parameter, and the second term is the entropy regularizer. This problem is efficiently solved by iteratively updating scaling vectors. Specifically, at iteration , the optimal transport plan via Sinkhorn, Sinkhorn(λM) := P, can be expressed as: = diag(ui) exp(λM)diag(vi), where scaling vectors ui and vi are updated via: ui = µ exp(λM)vi1 , vi = ν exp(λM)ui , (7) (8) with initialization v0 = 1. To improve numerical stability, we adopt the log-domain scaling version of Sinkhorn optimization (Schmitzer 2019). Connecting Self-Attention with Sinkhorn Given an input sequence = [x1, x2, . . . , xn] embedded in d-dimensional space, the self-attention mechanism in Transformer models is defined as: SA(Q, K, V) = SoftMax V, (9) (cid:19) (cid:18) QK where = ϕq(X), = ϕk(X), = ϕv(X). Here, Q, K, Rnd denote the query, key, and value matrices obtained via learned linear projections, each corresponding ϕq(), ϕk(), and ϕv() It has been shown that the first iteration of the Sinkhorn algorithm corresponds exactly to the SoftMax (Sander et al. 2022), suggesting natural generalization of attention via optimal transport. Specifically, by interpreting the attention score as similarity matrix and defining the cost as = (1 QK), Sinkhorn-based attention (Sink-Attention) optimizes doubly-stochastic plan that favors high similarity alignments. This leads to more structured and expressive attention maps compared to standard softmax-based attention, and empirically improves performance (Kim, Oh, and Ye 2024). The Sink-Attention can be formulated as: Sink-A(Q, K, V) = Sinkhorn (λM) V, (10) where Sinkhorn() computes doubly-stochastic matrix via Eq.(7), with regularization parameter λ set to 1/ d. Figure 2: Conceptual comparison between ASAG and other guidance methods. Existing guidance methods often rely on null conditions or heuristic perturbations of self-attention, such as injecting identity matrices or applying Gaussian blurs, to simulate undesirable paths. In contrast, ASAG explicitly defines an attention cost function based on pixel-level interactions and disrupts attention scores by minimizing this cost, thereby intentionally breaking semantic interactions through the Sinkhorn algorithm. Methods Selfand Sinkhorn Attention in Diffusion Models Recent DMs extensively utilize attention mechanisms throughout their architecture. At each timestep t, the model processes features via self-attention, typically expressed as: SA(Qt, Kt, Vt) = SoftMax (cid:19) (cid:18) QtK Vt. (11) As introduced in Eq. 10, an alternative based on optimal transport is Sinkhorn attention, which replaces the Softmax with Sinkhorn operator which compute transport plan via iterative optimization: Sink-A(Qt, Kt, Vt) = Sinkhorn(λM )Vt, (12) d, = (1 QtK ). Minimizing this where λ = 1/ cost means that maximize similarity between query and key matrices at t. While Sink-A can improve alignment, it is computationally expensive due to its iterative nature. When applied to all attention layers, the overhead becomes even more significant. However, our goal is not to enhance all attention mechanisms. Instead, within the guidance sampling framework, we aim to construct an effective undesirable path ϵθ(xt, c) that simulates degraded attention behavior. Adversarial Sinkhorn Attention Guidance To construct the undesirable score function ϵθ(xt, c), we propose Adversarial Sinkhorn Attention Guidance (ASAG), which selectively applies Sink-A in reverse direction to degrade attention quality in specific layers as shown Fig 2. This design is inspired by prior works such as PAG and SEG, which perturb only subset of attention maps. In ASAG, we replace cost = ) for direction minimizing similarity between query in Eq. (12) with (QtK and key matrices: ASA(Qt, Kt, Vt) = Sinkhorn (cid:16) λM (cid:17) Vt, (13) Algorithm 1: Adversarial Sinkhorn Attention Input : query Qt , key Kt, and value Vt matrices d, at timestep t, hyper-parameter λ = 1/ error threshold ϵmax Initialization: Attention cost = (QtK ), = , = 1, v0 = 1 Calculate Sinkhorn distance within inner loop ; 2 while < ϵmax do ui = log µ log λM (cid:16) 3 (cid:104)(cid:80) exp (cid:104)(cid:80) exp (cid:16) + vi1(cid:17)(cid:105) ; ) + ui(cid:17)(cid:105) ; λ(M 4 5 vi = log ν log = vi vi11 ; + 1 ; 6 7 = diag(exp(ui)) exp(λM Output: ASA(Qt, Kt, Vt) = PVt ) diag(exp(vi)) where ASA denotes Adversarial Sinkhorn Attention. Unlike Sink-A with the OT objective that maximize similarity, ASA seeks to minimize interaction between noisy queries and keys, leading to attention collapse and disrupted interactions as detailed Algorithm 1. Since degradation does not require precise convergence, only few Sinkhorn iterations are sufficient, resulting in minimal computational overhead. The resulting attention maps simulate an undesirable path where semantic coherence is lost. Using ASA, we compute ϵθ(xt, c) in Eq. (4), and pseudo code are provided in Algorithm 2. Theoretical Justification for ASAG. We formally justify ASAs perturbation as an entropy-maximizing transport plan that disrupts semantic alignment. This direction is not arbitrary but results from constrained optimization aligned with disruptive axis in score space. Theorem 1 (Entropy-Maximizing Plan via Adversarial Algorithm 2: Diffusion Sampling with ASAG Input: Diffusion model ϵθ(xt) with self-attention module, ϵθ(xt, c) with ASA guidance scale s. 1 for in T, 1, , 1 do 2 3 ϵθ(xt, c) ϵθ(xt, c) + (ϵθ(xt, c) ϵθ(xt, c)) ˆx0(t) (xt xt1 return: x0 1 αt1ϵθ(xt, c) 1 αtϵθ(xt, c))/ αt1 ˆx0(t) + αt = (QtK Sinkhorn). Let Qt, Kt Rnd be the query and key matrices at diffusion timestep t. Define the adversarial cost matrix as ). The entropy-regularized OT problem is P, defined as dλ (µ, ν) = min λ P, log P. U(µ,ν) Then in the limit λ 0 (i.e., 1/λ ), the solution converges to the maximum-entropy plan: lim λ0 = 1 n2 11. Lemma 1 (Uniform Plan Maximizes Entropy). Under uniform marginals µ and ν, the coupling = 1 n2 1 1 uniquely maximizes the Shannon entropy over the transport polytope U(µ, ν). All proofs are deferred in supplement. Remark 1. By Theorem 1 and Lemma 1, the adversarial Sinkhorn plan converges to the maximum-entropy uniform coupling as λ 0, effectively diminishing semantic preferences. This leads to an increasingly unstructured attention map, representing limiting case of semantic alignment degradation. ASA leverages this behavior to construct an adversarial attention map that systematically disrupts semantic correspondence. Corollary 1.1. Let δt := ϵθ(xt, c) ϵθ(xt, c) be the guidance energy between the original and ASA-induced score estimates in Eq. 4. Then δt defines semantically grounded direction in score spaceanchored to the original attention and diverging from the entropy-maximizing adversarial trajectory. Unlike heuristic perturbations, it enables principled contrastive guidance by preserving structural semantics while deliberately reducing alignment. Practical Justification via Sinkhorn Approximation. While the uniform plan 1 n2 11 represents the theoretical extreme of semantic disruption, applying it directly often leads to reduced generation diversity and unstable behavior. ASA instead adopts Sinkhorn plan with small but finite λ, which retains doubly stochastic structure and enables controlled entropy increase while preserving attention stability. Unlike heuristic perturbations, this approach maintains the optimization structure of attention with reversed objective, offering principled and tunable guidance strategy grounded in theory and robust in practice. Experiments Setup. For fair comparison, we use SDXL(Podell et al. 2023) and SD3 (Esser et al. 2024b). We compare against Table 1: Quantitative results of various guidance methods on the MS-COCO dataset with SDXL and SD3 in uncoditional and conditional generation. Bold text indicates the best performance for each metric. Condition Unconditional Generation Method Vanilla PAG SEG ASAG (Ours) FID 122.07 108.63 95.43 92.01 KID Inception Score 0.086 0.067 0.062 0.059 7. 10.46 10.35 10.54 Condition Method FID CLIPScore ImageReward Conditional Generation (SDXL) CFG PAG SEG ASAG (Ours) 28.15 24.32 26.80 23.30 25. 25.41 25.39 25.85 0.415 0.448 0. 0.459 Condition Method FID CLIPScore ImageReward Conditional Generation (SD3) CFG PAG ASAG (Ours) 24.19 23. 22.87 26.03 26.14 26.33 0.931 0. 0.978 Table 2: Quantitative comparison of text alignment and human preference across datasets using various guidance methods with SDXL. For PAG, SEG, and ASAG, CFG guidance is used jointly. Dataset Method CLIPScore PickScore ImageReward HPSv2 Drawbench CFG PAG SEG ASAG (Ours) HPD CFG PAG SEG ASAG (Ours) 25. 26.17 26.03 26.62 27.88 28.00 28. 28.58 21.70 21.93 21.78 21.99 21. 22.12 21.96 22.21 0.196 0.294 0. 0.316 0.565 0.635 0.622 0.673 26. 26.84 27.06 27.08 26.63 28.83 28. 28.84 PAG and SEG with guidance scale of 3.0, following their official settings. SEG is not officially supported on SD3 and IP-Adapter, so it is omitted in those cases. For ASAG, we set the guidance scale = 1.5 and use 25 sampling steps. Full implementation details are provided in the supplement. All experiments are run on single NVIDIA H100 GPU. Evaluation Metrics. We evaluate our method across multiple dimensions. For visual quality, we report the Frechet Inception Distance (FID) (Heusel et al. 2017) and Kernel Inception Distance (KID), and Inception score (Diversity) using 30K randomly sampled prompts from the MSCOCO validation set (Lin et al. 2014). To assess textimage alignment and human preference, we use CLIPScore (Hessel et al. 2021), ImageReward (Xu et al. 2024), PickScore (Kirstain et al. 2023), and Human Preference Score (HPS v2.1) (Wu et al. 2023). Evaluations are conducted on prompts from both MS-COCO (Lin et al. 2014) and additional benchmarks including DrawBench (Saharia et al. 2022) and HPD (Wu et al. 2023). Further evaluation details are provided in the supplement. Results on Diffusion Generation To rigorously evaluate the effectiveness of our method, we generate 30K samples on the MSCOCO dataset using various guidance sampling techniques in both unconditional and conditional generation settings. Figure 3: Comparison results on (A) unconditional and (B) conditional generation using Vanilla, CFG, PAG, SEG, and ASAG. While other guidance methods often alter the structure of the original outputs, ASAG achieves both higher visual quality and stronger consistency in structure and intent. Figure 4: ControlNet examples with different guidance sampling methods. Left: Canny condition; Right: Depth condition. Our method, when integrated with ControlNet, substantially improves visual quality and preserves fine-grained image details. Unconditional Generation To isolate the effect of our method, we first evaluate ASAG in an unconditional generation setup. As shown in Tab. 1, ASAG consistently outperforms other guidance approaches across all evaluation metrics, demonstrating improved visual fidelity and greater diversity, as reflected by higher Inception Scores. Qualitatively, ASAG also produces outputs that are more visually appealing and better aligned with the original vanilla results, particularly in cases where other guidance methods generate high-quality images that nonetheless diverge significantly from the vanilla outputs  (Fig. 3)  . These findings suggest that ASAG serves as strong guidance strategy even in scenarios without any conditional information. Conditional Generation We further evaluate our method in conditional generation setup, where guidance sampling is combined with CFG. As shown in Tab. 1, while existing guidance methods benefit from CFG, ASAG achieves superior performance in both visual quality and text-image alignment. It is also compatible with the SD3 backbone and consistently outperforms other methods, demonstrating strong generalizability. To further validate its effectiveness, we evaluate on human preference dataset (Tab. 2), where ASAG with CFG achieves state-of-the-art performance across all metrics. Qualitative results in Fig. 3 show that ASAG enhances visual quality while preserving the structural intent of the original CFG output, unlike other methods that often alter the generation semantics."
        },
        {
            "title": "Results on Downstream Tasks",
            "content": "To evaluate the effectiveness of ASAG in downstream tasks, we conduct experiments with ControlNet and IP-Adapter under various conditioning settings, keeping all configurations identical except for the guidance method. As shown in Fig. 4, ASAG consistently outperforms baselines under Canny and depth conditions by better preserving structural fidelity. In more challenging setupspose with ControlNet and multimodal IP-Adapter  (Fig. 5)  ASAG captures fine-grained details and maintains stronger visual coherence, Table 3: Ablation study on transport cost for Sinkhorn. Method FID KID Inception Score Sinkhorn Iteration Vanilla Mt = 1 QK 11 = 1 Mt = QK 122.07 111.53 92.11 0.086 0.078 0.058 92.01 0. 7.052 9.085 9.710 10.54 - 10 - 2 Table 4: Comparison computation cost with various approaches. Inference time is measured per prompt. Method CFG PAG SEG Ours Inference Time (sec) Memory (G) 1.198 16. 1.280 16.46 1.513 16.61 1.551 (+0.35) 16.61 (+0.20) Figure 5: Comparison of guidance sampling methods combined with ControlNet and IP-Adapter under pose and depth conditions. Our method significantly enhances image quality, yielding clearer structures. even where other methods degrade. Notably, these improvements are achieved without any additional training or fine-tuning, demonstrating the plugand-play flexibility of ASAG. Its principled perturbation strategy effectively guides pretrained models along optimal generation paths, ensuring robust performance across diverse conditional settings. Additional qualitative results are provided in the supplement."
        },
        {
            "title": "Ablation Study",
            "content": "Optimal Transport Cost. Rather than maximizing similarity by setting the cost as Mt = 1QtK , ASAG defines the cost as Mt = QtK , which explicitly minimizes similarity and disrupts semantic alignment. As shown in Tab. 3, the similarity-maximizing variant also improves over vanilla sampling, likely due to extrapolation effects similar to CFG, but incurs higher inference time due to the increased complexity of the Sinkhorn optimization. We further evaluate the extreme case using the uniform plan 1 n2 11, which represents theoretical upper bound on semantic disruption. Interestingly, while it shows performance improvement over the baseline, we observe reduction in sample diversity. In contrast, our Sinkhorn-based formulation achieves similar degree of semantic disruption with better diversity and stability, validating its effectiveness as practical and principled guidance strategy. Computational Complexity. We further assess the efficiency of ASAG by measuring inference time and memory usage, as shown in Tab. 4. As described in Algorithm 1, the Sinkhorn process includes early stopping based on convergence threshold. In practice, only 2 iterations are sufficient in most cases to produce stable transport plans. Remarkably, using just 2 iterations increases inference time by only +0.35 seconds while even improving generation qualFigure 6: Analysis of guidance scale across various metrics using our method. ity, confirming that ASAG is not only efficient but also effective under minimal Sinkhorn updates. Guidance Scale To determine the optimal guidance scale in ASAG, we conduct experiments by varying and measuring the impact on generation performance, as shown in Figure 6. We observe that performance improves with increasing up to certain point, but overly large values cause slightly degradation as observed in CFG cases. The peak performance is achieved at = 1.5, which we adopt as the default configuration throughout our experiments. Conclusion In this work, we propose Adversarial Sinkhorn Attention Guidance (ASAG), novel guidance sampling approach designed to address the lack of theoretical foundation behind existing perturbed self-attention methods for generating undesirable paths. Rather than relying on heuristic perturbations, we define an attention cost that reflects interactions between pixel embeddings, and disrupt those interactions via the Sinkhorn algorithmframing the process through the lens of optimal transport. Our method is theoretically grounded and demonstrates state-of-the-art performance across various real-world scenarios, including both unconditional and conditional generation. Furthermore, we show that ASAG is highly compatible with downstream frameworks such as ControlNet and IPAdapter, achieving significant improvements over existing guidance methods without requiring any additional training. We believe ASAG not only provides principled and effective guidance mechanism, but also offers both theoretical insight and practical utility within the diffusion generation framework. Our results suggest that ASAG can generalize to wide range of generative tasks and pave the way for future research in attention-based guidance strategies. References Ahn, D.; Cho, H.; Min, J.; Jang, W.; Kim, J.; Kim, S.; Park, H. H.; Jin, K. H.; and Kim, S. 2025. Self-rectifying diffusion In European sampling with perturbed-attention guidance. Conference on Computer Vision, 117. Springer. Blattmann, A.; Dockhorn, T.; Kulal, S.; Mendelevitch, D.; Kilian, M.; Lorenz, D.; Levi, Y.; English, Z.; Voleti, V.; Letts, A.; et al. 2023. Stable video diffusion: Scaling latent video diffusion models to large datasets. arXiv preprint arXiv:2311.15127. Chen, G.; Yao, W.; Song, X.; Li, X.; Rao, Y.; and Zhang, K. 2022. Prompt Learning with Optimal Transport for VisionLanguage Models. arXiv preprint arXiv:2210.01253. Chen, H.; Zhang, Y.; Cun, X.; Xia, M.; Wang, X.; Weng, C.; and Shan, Y. 2024a. Videocrafter2: Overcoming data limitations for high-quality video diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 73107320. Chen, J.; Ge, C.; Xie, E.; Wu, Y.; Yao, L.; Ren, X.; Wang, Z.; Luo, P.; Lu, H.; and Li, Z. 2024b. Pixart-σ: Weak-tostrong training of diffusion transformer for 4k text-to-image In European Conference on Computer Vision, generation. 7491. Springer. Chen, L.; Gan, Z.; Cheng, Y.; Li, L.; Carin, L.; and Liu, J. 2020. Graph optimal transport for cross-domain alignment. In International Conference on Machine Learning, 1542 1553. PMLR. Chung, H.; Kim, J.; Park, G. Y.; Nam, H.; and Ye, J. C. 2024. Cfg++: Manifold-constrained classifier free guidance for diffusion models. arXiv preprint arXiv:2406.08070. Cuturi, M. 2013. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information processing systems, 26. Dhariwal, P.; and Nichol, A. 2021. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34: 87808794. Efron, B. 2011. Tweedies formula and selection bias. Journal of the American Statistical Association, 106(496): 1602 1614. Esser, P.; Kulal, S.; Blattmann, A.; Entezari, R.; Muller, J.; Saini, H.; Levi, Y.; Lorenz, D.; Sauer, A.; Boesel, F.; et al. 2024a. Scaling rectified flow transformers for highresolution image synthesis. In Forty-first international conference on machine learning. Esser, P.; Kulal, S.; Blattmann, A.; Entezari, R.; Muller, J.; Saini, H.; Levi, Y.; Lorenz, D.; Sauer, A.; Boesel, F.; et al. 2024b. Scaling rectified flow transformers for highresolution image synthesis. In Forty-first international conference on machine learning. Hessel, J.; Holtzman, A.; Forbes, M.; Bras, R. L.; and Choi, Y. 2021. Clipscore: reference-free evaluation metric for image captioning. arXiv preprint arXiv:2104.08718. Heusel, M.; Ramsauer, H.; Unterthiner, T.; Nessler, B.; and Hochreiter, S. 2017. Gans trained by two time-scale update rule converge to local nash equilibrium. Advances in neural information processing systems, 30. Ho, J.; Jain, A.; and Abbeel, P. 2020. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33: 68406851. Ho, J.; and Salimans, T. 2022. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598. Hong, S. 2024. Smoothed energy guidance: Guiding diffusion models with reduced energy curvature of attention. arXiv preprint arXiv:2408.00760. Hong, S.; Lee, G.; Jang, W.; and Kim, S. 2023. Improving sample quality of diffusion models using self-attention In Proceedings of the IEEE/CVF International guidance. Conference on Computer Vision, 74627471. Karras, T.; Aittala, M.; Kynkaanniemi, T.; Lehtinen, J.; Aila, T.; and Laine, S. 2024. Guiding Diffusion Model with Bad Version of Itself. arXiv preprint arXiv:2406.02507. Kim, K.; Oh, Y.; and Ye, J. C. 2024. OTSeg: Multi-Prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation. In European Conference on Computer Vision, 200217. Springer. Kim, K.; and Ye, J. C. 2021. Noise2Score: Tweedies Approach to Self-supervised Image Denoising Without Clean Images. Advances in Neural Information Processing Systems, 34: 864874. Kirstain, Y.; Polyak, A.; Singer, U.; Matiana, S.; Penna, J.; and Levy, O. 2023. Pick-a-pic: An open dataset of user preferences for text-to-image generation. Advances in Neural Information Processing Systems, 36: 3665236663. Li, T.; Luo, W.; Chen, Z.; Ma, L.; and Qi, G.-J. 2024. Self-Guidance: Boosting Flow and Diffusion Generation on Their Own. arXiv preprint arXiv:2412.05827. Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollar, P.; and Zitnick, C. L. 2014. Microsoft In Computer Vision coco: Common objects in context. ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part 13, 740 755. Springer. Liu, Y.; Zhu, L.; Yamada, M.; and Yang, Y. 2020. Semantic In Procorrespondence as an optimal transport problem. ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 44634472. Podell, D.; English, Z.; Lacey, K.; Blattmann, A.; Dockhorn, T.; Muller, J.; Penna, J.; and Rombach, R. 2023. Sdxl: Improving latent diffusion models for high-resolution image synthesis. arXiv preprint arXiv:2307.01952. Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Ommer, B. 2022. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 10684 10695. Ruiz, N.; Li, Y.; Jampani, V.; Pritch, Y.; Rubinstein, M.; and Aberman, K. 2023. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2250022510. Sadat, S.; Kansy, M.; Hilliges, O.; and Weber, R. M. 2024. No training, no problem: Rethinking classifier-free guidance for diffusion models. arXiv preprint arXiv:2407.02687. Saharia, C.; Chan, W.; Saxena, S.; Li, L.; Whang, J.; Denton, E. L.; Ghasemipour, K.; Gontijo Lopes, R.; Karagol Ayan, Photorealistic text-toB.; Salimans, T.; et al. 2022. image diffusion models with deep language understanding. Advances in neural information processing systems, 35: 3647936494. Sander, M. E.; Ablin, P.; Blondel, M.; and Peyre, G. 2022. Sinkformers: Transformers with doubly stochastic attention. In International Conference on Artificial Intelligence and Statistics, 35153530. PMLR. Schmitzer, B. 2019. Stabilized sparse scaling algorithms for entropy regularized transport problems. SIAM Journal on Scientific Computing, 41(3): A1443A1481. Song, J.; Meng, C.; and Ermon, S. 2021. Denoising Diffusion Implicit Models. In ICLR. Song, Y.; Sohl-Dickstein, J.; Kingma, D. P.; Kumar, A.; Ermon, S.; and Poole, B. 2021. Score-Based Generative Modeling through Stochastic Differential Equations. In International Conference on Learning Representations. Vincent, P. 2011. connection between score matching and denoising autoencoders. Neural computation, 23(7): 1661 1674. Wu, X.; Hao, Y.; Sun, K.; Chen, Y.; Zhu, F.; Zhao, R.; and Li, H. 2023. Human preference score v2: solid benchmark for evaluating human preferences of text-to-image synthesis. arXiv preprint arXiv:2306.09341. Xie, E.; Chen, J.; Chen, J.; Cai, H.; Tang, H.; Lin, Y.; Zhang, Z.; Li, M.; Zhu, L.; Lu, Y.; et al. 2024. Sana: Efficient highresolution image synthesis with linear diffusion transformers. arXiv preprint arXiv:2410.10629. Xu, J.; Liu, X.; Wu, Y.; Tong, Y.; Li, Q.; Ding, M.; Tang, J.; and Dong, Y. 2024. Imagereward: Learning and evaluating human preferences for text-to-image generation. Advances in Neural Information Processing Systems, 36."
        },
        {
            "title": "Toward the Frontiers of Reliable Diffusion Sampling\nvia Adversarial Sinkhorn Attention Guidance\nSupplementary Material",
            "content": "In this supplementary document, we present the following: Detailed description of the evaluation metrics and implementation. The proof of Theorem 1 and Lemma 1. Additional qualitative results, including unconditional and conditional case with SDXL and SD3, further ablation studies. Metrics and Implementation Detail For the results in Table 1, we conduct unconditional image sampling using 30,000 samples generated with SDXL. For the conditional case, we randomly select text prompts from the MSCOCO validation set. To evaluate the robustness of guidance scales, we perform conditional generation using Classifier-Free Guidance (CFG) with scale values uniformly sampled from the range (3, 5). For both PAG and SEG, we fix the scale to 3.0, following the settings recommended in their respective papers. For Table 2, we sample 200 prompts from DrawBench (Saharia et al. 2022) and 400 prompts from HPD (Wu et al. 2023), generating 5 images per prompt. Additionally, for the ablation study in Figure 6, we generate 5,000 images from the MSCOCO validation set using CFG-based sampling. Proof of Theorem 1 Theorem 1 (Entropy-Maximizing Plan via Adversarial Sinkhorn). Let Qt, Kt Rnd be the query and key matrices at diffusion timestep t. Define the adversarial cost matrix as ). The entropy-regularized OT problem is defined P, as dλ λ P, log P. Then in the limit λ 0 (i.e., 1/λ ), the solution converges to the = (QtK (µ, ν) = min 1 P U(µ,ν) maximum-entropy plan: lim λ = 1 n2 11. Proof. The entropy-regularized OT problem admits the closed-form Sinkhorn solution (Cuturi 2013): = diag(u) diag(v), Kij = exp(cid:0)λ t,ij (cid:1), with scaling vectors u, > 0 chosen so that P1 = µ and (P)1 = ν. As λ 0, we have Kij = exp(λ t,ij) 1, hence = diag(u) diag(v) diag(u) 11 diag(v) = v. Under uniform marginals µ = ν = 1, the constraints P1 = (v1) = 1 1, (P )1 = (u1) = 1 1 force = 1 Therefore, 1 and = 1 1. as claimed. = = lim λ0 1 1 (cid:0) 1 1(cid:1) = 1 n2 1 1, Proof of Lemma 1 Lemma 1 (Uniform Plan Maximizes Entropy). Under uniform marginals µ = 1 and ν = 1 1, the coupling uniquely maximizes the Shannon entropy over the transport polytope U(µ, ν). = 1 n2 1 1 H(P ) = (cid:88) i,j Pij log Pij Proof. Introduce Lagrange multipliers {αi}n j=1 for the row and column constraints, respectively: i=1 and {βj}n (cid:88) Pij = µi = 1 , (cid:88) Pij = νj = 1 . The Lagrangian is L(P, α, β) = (cid:88) i,j Pij log Pij + (cid:88) αi (cid:16)(cid:88) Pij 1 (cid:17) + (cid:88) βj (cid:16)(cid:88) Pij 1 (cid:17) . j Stationarity L/Pij = 0 yields (cid:0)log Pij + 1(cid:1) + αi + βj = 0 = Pij = exp(αi + βj 1) = ui vj, where we set ui = eαi1 and vj = eβj . Enforcing the marginals gives (cid:88) uivj = ui (cid:88) vj = 1 , (cid:88) uivj = vj (cid:88) ui = 1 . Thus (cid:80) vj = (cid:80) ui = 1 and ui = vj = 1 for all i, j. Hence Pij = uivj = 1 n2 . Finally, since H(P ) is strictly concave on U(µ, ν), this stationary point is the unique global maximizer. Additional Qualitative Results In this section, we present additional qualitative results to further demonstrate the effectiveness and versatility of our proposed method, ASAG, across various generation tasks and in combination with other guidance approaches. Comparison of Guidance Sampling with Our Method Fig.7 and 9 provide qualitative comparisons between ASAG and existing guidance methods including Vanilla, CFG, PAG, and SEG. In both unconditional and conditional generation settings, while existing methods often enhance visual appearance, they tend to distort the original structural and semantic consistency. In contrast, ASAG not only significantly improves visual quality but also faithfully preserves the structural layout and semantic intent of the original input. Effect of Guidance Scale in ASAG Fig. 8, 10, and 11 illustrate the impact of varying the guidance scale in ASAG, under both unconditional generation and conditional generation using ControlNet. We observe that increasing the ASAG guidance scale consistently enhances overall generation quality across different input conditions, validating the effectiveness of our approach. In particular, for unconditional generation, guidance scales of 1.5 and 2.0 strike good balance between quality and stability. For ControlNet-based conditional tasks, scales in the range of 1.5 to 3.0 are effective in achieving high visual fidelity. Comparison with and without CFG Fig. 12 shows qualitative results under the pose condition with and without classifierfree guidance (CFG) using ControlNet. Interestingly, PAG fails to deliver meaningful improvements without CFG. In contrast, ASAG surprisingly achieves high-quality generations even without CFG. Furthermore, when CFG is applied, our method further boosts generation quality, indicating that ASAG serves as strong and reliable guidance sampling strategy in both CFG and non-CFG scenarios. Figure 7: Qualitative comparison on unconditional generation. Unlike other guidance methods that often distort the original structure, ASAG maintains structural and semantic consistency while significantly improving visual fidelity. Figure 8: Unconditional generation results with varying ASAG guidance scales. Increasing the ASAG scale consistently improves visual quality over vanilla SDXL. Scales of 1.5 and 2.0 are found to be effective configurations for balancing quality and stability. Figure 9: Conditional generation results with CFG, PAG, SEG, and ASAG. Unlike other methods that frequently disrupt structural integrity, ASAG enhances visual fidelity while retaining the original layout and semantic alignment. Figure 10: Comparison results on Canny-conditioned generation with ControlNet using different guidance scales. We observe that guidance scales in the range of 1.5 to 3.0 yield enhanced visual quality while maintaining stable generation, making them suitable configurations for ControlNet. Figure 11: Comparison results on depth-conditioned generation with ControlNet using different guidance scales. We find that guidance scales in the range of 1.5 to 3.0 are effective for ControlNet, yielding enhanced visual quality while maintaining stable generation. Figure 12: Comparison results on ControlNet under pose condition, with and without CFG. ASAG produces visually pleasing results even without CFG, whereas PAG fails to generate satisfactory outputs in the same setting. Furthermore, when combined with CFG, our method further boosts generation quality."
        }
    ],
    "affiliations": [
        "Samsung Research"
    ]
}