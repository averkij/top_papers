{
    "paper_title": "Artificial Intelligence and Misinformation in Art: Can Vision Language Models Judge the Hand or the Machine Behind the Canvas?",
    "authors": [
        "Tarian Fu",
        "Javier Conde",
        "Gonzalo Martínez",
        "Pedro Reviriego",
        "Elena Merino-Gómez",
        "Fernando Moral"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The attribution of artworks in general and of paintings in particular has always been an issue in art. The advent of powerful artificial intelligence models that can generate and analyze images creates new challenges for painting attribution. On the one hand, AI models can create images that mimic the style of a painter, which can be incorrectly attributed, for example, by other AI models. On the other hand, AI models may not be able to correctly identify the artist for real paintings, inducing users to incorrectly attribute paintings. In this paper, both problems are experimentally studied using state-of-the-art AI models for image generation and analysis on a large dataset with close to 40,000 paintings from 128 artists. The results show that vision language models have limited capabilities to: 1) perform canvas attribution and 2) to identify AI generated images. As users increasingly rely on queries to AI models to get information, these results show the need to improve the capabilities of VLMs to reliably perform artist attribution and detection of AI generated images to prevent the spread of incorrect information."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 ] . [ 1 8 0 4 1 0 . 8 0 5 2 : r ARTIFICIAL INTELLIGENCE AND MISINFORMATION IN ART: CAN VISION LANGUAGE MODELS JUDGE THE HAND OR THE MACHINE BEHIND THE CANVAS? Tarian Fu Nanjing University of Aeronautics and Astronautics Javier Conde Universidad Politécnica de Madrid Gonzalo Martínez Universidad Politécnica de Madrid Pedro Reviriego Universidad Politécnica de Madrid Elena Merino-Gómez Universidad de Valladolid Fernando Moral Universidad Antonio de Nebrija August 5,"
        },
        {
            "title": "ABSTRACT",
            "content": "The attribution of artworks in general and of paintings in particular has always been an issue in art. The advent of powerful artificial intelligence models that can generate and analyze images creates new challenges for painting attribution. On the one hand, AI models can create images that mimic the style of painter, which can be incorrectly attributed, for example, by other AI models. On the other hand, AI models may not be able to correctly identify the artist for real paintings, inducing users to incorrectly attribute paintings. In this paper, both problems are experimentally studied using state-of-the-art AI models for image generation and analysis on large dataset with close to 40,000 paintings from 128 artists. The results show that vision language models have limited capabilities to: 1) perform canvas attribution and 2) to identify AI generated images. As users increasingly rely on queries to AI models to get information, these results show the need to improve the capabilities of VLMs to reliably perform artist attribution and detection of AI generated images to prevent the spread of incorrect information. Keywords Analysis of Artwork, Vision Language Models, Text to image models, Artificial Intelligence, Performance Evaluation"
        },
        {
            "title": "Introduction",
            "content": "The attribution of works has always been fundamental issue in art history and the cause of many disputes. Notorious is the fake ancient Roman fresco with which the painter Anton Raphael Mengs (17281779) deceived Johann Joachim Winckelmann, the eminent art historian and theorist of Neoclassicism. Created around 1755, the scene of Jupiter kissing Ganymede (see Figure 1) was intended as stylistic homage to antiquity, but was presented as authentic. Winckelmann, convinced of its antiquity, praised it as rare survival of Greco-Roman painting, thereby exposing the vulnerability of even the most refined connoisseurly judgment to forgeries when driven by idealistic expectations about the classical past [1]. Mengs later confessed the deception, underscoring the subjective limits of connoisseurship in the pre-scientific era of art historical evaluation. More than century later, the modern art world was shaken by the infamous forgeries of Han van Meegeren, who successfully passed off multiple paintings in the style of Johannes Vermeer, including \"The Supper at Emmaus\" (1937), as authentic 17th-century Dutch masterpieces. Acclaimed by leading Vermeer expert Abraham Bredius and purchased by Dutch museums, van Meegerens forgeries exposed both desire to \"complete\" Vermeers sparse oeuvre and the PREPRINT - AUGUST 5, 2025 Figure 1: Anton Raphael Mengs, Jupiter kissing Ganymede, c. 1755. absence of rigorous technical analysis at the time. His eventual confession in 1945, delivered during trial in which he was accused of selling Dutch cultural property to the Nazis, turned him from traitor to national hero, and marked turning point in forensic art authentication [2]. Modern pigment analysis, particularly the detection of synthetic ultramarine and phenol-formaldehyde resins, later proved vital in debunking his paintings historical authenticity [3]. Perhaps even more challenging is the question of authorship in the oeuvre of Rembrandt van Rijn. Unlike Vermeer, Rembrandt worked in bustling studio environment and often encouraged his students to emulate his style closely. Complicating matters further is his inconsistent signing practice (sometimes abbreviated, sometimes fully written, and often absent) rendering signatures an unreliable tool for authentication. The launch of the Rembrandt Research Project (RRP) in 1968 brought systematic scrutiny to Rembrandt attribution. Under the leadership of Ernst van de Wetering, the RRP employed combination of connoisseurship, archival research, and advanced imaging techniques (including X-radiography and dendrochronology) to reassess the authenticity of hundreds of works. As result, many previously accepted paintings were downgraded, while others were reattributed to Rembrandt after long exclusion [4, 5]. wide range of Artificial Intelligence (AI)-driven techniques, such as the use of information-based processing [6], deep transfer learning [7], and surface scanning of the canvas [8], have been explored for artist attribution [9],[10]. Those studies focus on specific artists or techniques and the tools developed are not available to the general public. The advent of powerful vision language models capable of advanced image analysis [11] offers additional tools for artist attribution [12]. These models have been trained with billions of images and can answer sophisticated questions on almost any kind of image. In fact, any user can upload an image of painting and ask the model about it. This can be an issue if their responses are not correct as they may create confusion or even disinformation on users who tend to query and trust AI models [13]. Therefore, it is of interest to evaluate the capabilities of state-of-the-art vision language models to perform artist attribution. The impact of generative AI on artist attribution does not end with vision language models, the development of powerful text-to-image models [14] enables users to create images imitating given painter or style [15] or even to modify real paintings [16]. This can lead to additional confusion for artist attribution by having AI-generated images attributed to artists. An interesting twist is when vision language models are presented with an AI-generated painting imitating an artist. Would the model incorrectly attribute the image to the painter or would it recognize that it was generated by another AI tool? Exploring this issue is also of interest, as more and more AI-generated content populates the Internet. In this paper, we present an extensive experimental evaluation of the capabilities of set of relevant vision language models when performing artist attribution on dataset with close to 40,000 images of paintings from 128 artists, and AI-generated imitations of those paintings. The main contributions of this work are: 1. To evaluate and analyze the capabilities for artist attribution of real paintings of vision language models at scale. 2 PREPRINT - AUGUST 5, 2025 2. To evaluate and analyze the capabilities for artist attribution of AI-generated paintings of vision language models at scale. 3. To make available dataset of AI-generated descriptions of real paintings and Web interface for visualization1. 4. To make available dataset of AI-generated images that mimic the style of the artists. 5. To discuss the implications of vision language models artist attribution performance as generative AI adoption becomes widespread. The rest of the paper is organized as follows, section 2 discusses related works on the use of AI for artists attribution and image generation. The methodology used in the evaluation is presented in section 3 and the results as well as the limitations of the study are discussed in section 4. The paper ends with the conclusion in section 5."
        },
        {
            "title": "2 Related work",
            "content": "The use of image processing and machine learning models for the identification of artists has been explored for decades [17, 18]. Initially, simple models such as support vector machines (SVMs) operating on different features extracted from the painting were proposed. The rapid development of Convolutional Neural Networks (CNNs) for image processing that achieve excellent performance in several tasks [17] led to the use of CNNs for the identification of artists [19] and more recently, to the use of transformers [20]. All of these models and tools are specialized and not widely available to users. The development of Vision Language Models (VLMs) that can combine text and image [21] has been revolution [11]. VLMs can answer almost any question about an image and are available to users in applications such as ChatGPT that are used by billions of people every day. The use of VLMs has been proposed, for example, to explain artworks [22]. Today, any user can upload an image of painting and ask the VLM for the artist who drew the painting. In fact, VLMs have been evaluated to identify painting styles and have been shown to achieve lower accuracy than specific tools [23]. This is worrying as users are increasingly dependent on VLM based applications and assistants to access information. However, to the best of our knowledge, no large-scale evaluation of VLM performance when used for artist identification has been reported in the literature. Another area that has experienced impressive progress in recent years is image generation from text prompts [24]. Again, there are many publicly available models, such as Stable Diffusion [25] that can generate all sorts of images. These are incorporated into tools so that users can easily create images at will, for example, imitating given artist [26]. This adds another dimension to the identification of artists, as now there is need to also detect and discriminate images created by AI models. Although specific models can be designed to detect AI-generated images [27], users are more likely to ask general-purpose VLMs for an answer. Therefore, there is further interest in understanding whether VLMs can identify AI-generated images and not attribute them to painters even when they mimic their style. Again, to the best of our knowledge, no large-scale evaluation of VLM performance when used for artist identification has been reported in the literature when run on AI-generated images."
        },
        {
            "title": "3 Methodology",
            "content": "To evaluate the performance of vision language models in artist attribution, we have to select relevant dataset of images and models to evaluate. In the case of AI-generated images, no such dataset was found at the time of writing this paper, and therefore we created it as part of this work. We also need to define the procedure used for the evaluation as well as the metrics used to analyze the results. The following subsections discuss each of these issues in detail. 3.1 Real paintings dataset To perform an evaluation at scale, we have selected the ikiArt dataset2 that contains paintings by 128 artists covering 10 genres and 27 styles. Each image in the dataset has the artist, genre, and style as metadata. Images with \"unknown\" artists are not considered leaving 39,530 images. This dataset provides sufficient number of artists and paintings and is publicly available which facilitates reproducing or extending our research. 1The code and raw data are available at https://github.com/aMa2210/WikiArt_VLM_Web. In addition, website is also available to interactively visualize the results https://ama2210.github.io/WikiArt_VLM_Web/. 2https://huggingface.co/datasets/huggan/wikiart 3 PREPRINT - AUGUST 5, 2025 3.2 AI-generated paintings dataset In the case of paintings generated by AI, it was not possible to find suitable dataset to perform an evaluation at scale. Therefore, we decided to create it as part of this work. To do it, we first extracted the caption from the 39,530 WikiArt images using GPT4.1-mini3. Then the prompts were used to generate images with three text-to-image models: Stable Diffusion4, Flux5, and F-Lite6. The general process is illustrated in Figure 2. The prompts are publicly available to facilitate the creation of data sets with other text-to-image models. The prompt used to generate the images has the following structure: Produce an image that closely resembles painting by <correct painter>, but is not an exact copy of his works: <caption of the real painting> The images created with Stable Diffusion, Flux and F-Lite are also in the same repository so that they can be reused in other works7. An advantage of the method used to generate the images is that the real and AI-generated datasets are homogeneous in terms of number and type of images, which makes comparisons between datasets more meaningful. Figure 2: Process to generate the AI painting imitations 3.3 Vision language models group of five open-weight vision language models from different companies has been selected for evaluation. These models can be run locally in off-the-shelf GPUs. The set is completed with proprietary model from Open AI. The six models evaluated are: 1. GPT4.1-mini: model from OpenAI8. 2. Gemma3-12B: model from Google9. 3. LLaMa3.2-11B model from Meta10. 4. Phi-4-5.6B model from Microsoft11. 5. QwenVL-2.5-7B model from Alibaba12. 6. Pixtral-12B model from Mistral13. This group of models provides sample of vision language models that is sufficient to extract relevant conclusions while keeping the computational effort and cost manageable. 3The version used was gpt-4.1-mini-2025-04-14. 4The version used was stable-diffusion-3.5-large. 5The version used was FLUX.1-dev. 6The version used was F-Lite. 7The prompts and images are available at https://github.com/aMa2210/WikiArt_VLM 8The version of the model is gpt-4.1-mini-2025-04-14 9The model is https://huggingface.co/google/gemma-3-12b-it 10The model is https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct 11The model is https://huggingface.co/microsoft/Phi-4-multimodal-instruct 12The model is https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct 13The model is https://huggingface.co/mistral-community/pixtral-12b 4 PREPRINT - AUGUST 5, 2025 3.4 Evaluation procedure As we want to conduct an evaluation at scale on tens of thousands of paintings on several models, the process has to be automated to be manageable. This poses some limitations on how to ask the models for the author of painting. If we ask an open question, the model may reply with reasoning from which it may be hard to get the name of the artist. We can ask the model to just give the name of the author or provide the explanation and then end with the name in given format, for example in brackets. However, the model can produce the name of an artist in different ways, for example give just the surname or the full name. This makes the parsing of the responses complex and error prone. To avoid this problem, we have used simple prompt: Prompt-1 correct artist: \"Is this real painting from <correct painter>? Please answer only yes or no\" Taking the \"correct painter\" from the metadata in the WikiArt dataset. This strategy makes the processing simple to automate but has potential problem as model that always answers yes will get 100% accuracy. To ensure that models can discriminate paintings, we use second prompt: Prompt-2 incorrect artist: \"Is this real painting from <incorrect painter>? Please answer only yes or no\" Asking if the painting corresponds to another painter, different from the author selected randomly from the remaining 127 artists. The dataset is run twice, once with each prompt, to assess the models capability to identify the author and also to detect that it was not painted by other artists. The process and rationale are illustrated in Figure 3. We run the same two promts with every AI-generated image too. In this case, the correct answer is no for both prompts, but the difference in the attribution rates for both prompts can also be informative. Figure 3: Process to evaluate the models 3.5 Evaluation Metrics To evaluate the performance of vision language models, we will use two individual metrics C1, C2 that are the correctness of the responses for Prompt-1 and Prompt-2, respectively normalized to the random guess value of 50% for two-response question as follows: = Percentage of correct responses 50 (1) As each of those individual metrics provides information only on one aspect of the performance, we also propose to use combined metric, the arithmetic mean AM calculated as: AM = C1 + C2 2 (2) For real paintings, ideally, both C1, C2 will be close to one, and the arithmetic mean will only approach one when both are close to one. For AI-generated paintings, ideally, both C1, C2 will also be close to one, taking into account that now in both cases the correct answer is no. Therefore, the arithmetic mean which captures the ability of the models to identify that both 5 PREPRINT - AUGUST 5, 2025 AI-generated images mimicking the style of the painter (Prompt-1) or of different painter (Prompt-2) are not attributed to any painter is also relevant metric."
        },
        {
            "title": "4 Results and analysis",
            "content": "This section presents the results of the experimental evaluation. First, we discuss the results of running Prompt-1 and Prompt-2 on images of real paintings. Then the results of the evaluation on AI-generated images that mimic paintings are presented and the limitations of the study discussed. The section ends with an analysis and discussion of the results. 4.1 Real paintings The average results for all artists for C1, C2 are shown in Figure 4 per model. It can be seen that the results vary significantly between models. GPT4.1-mini does not attribute paintings neither to the real author (C1) nor to random painter (C2). Instead, Pixtral-12B answers correctly most of the time when the painter is the real one and fails when the painter is random one. They are examples of conservative model that tends not to attribute paintings (GPT4.1-mini) and more aggressive model that tends to attribute the painting to the suggested painter (Pixtral-12B). Both are undesired behaviors being aggressiveness potentially more dangerous from misinformation perspective. The rest of the models present more even values of C1, C2 with Gemma3-12B and LLaMa3.2-11B achieving more than 40% normalized correct answers in both C1, C2. Figure 4: Average C1 and C2 scores on all painters for the VLMs considered on WikiArt images of real paintings The combined metric AM is shown per model in Figure 5. The results show that again Gemma3-12B and LLaMa3.2-11B are the best performing models. The results per painter are shown in Figure 6 with the correspondence of numbers with artists in Table 1. It can be seen that there are large differences in performance between painters. The painter with best results, Utagawa Kuniyoshi, has over 80% normalized average accuracy, while the worst, M.C. Escher, has almost 0% normalized average accuracy. The popularity of the artist does not seem to help VLMs to recognize their paintings as Vincent Van Gogh or Salvador Dalí are among the bottom 10 models. It is also worth noting that universally known artworks, such as La Gioconda by Leonardo da Vinci or The Kiss by Gustav Klimt, are not recognized as authentic by any of the VLMs considered. In summary, the evaluation on large set of painters shows that current VLMs have strong limitations when identifying the artist of real canvas and thus cannot be considered reliable source of information. 4.2 AI-generated paintings In the case of AI-generated paintings, the correct answer is no for both Prompt-1 and Prompt-2. The values of C1, C2 are shown per model in Figures 7, 8, 9 for Stable Diffusion, Flux, and F-Lite respectively. For Stable Diffusion, it can be observed that GPT4.1-mini is the best performing model that is capable of identifying over 95% of the canvas as not generated by the suggested painter. This is consistent with the behavior observed for 6 PREPRINT - AUGUST 5, Figure 5: Average AM scores on all painters for the VLMs considered on WikiArt images of real paintings Figure 6: Painters ordered by average AM scores for the VLMs considered on WikiArt images of real paintings. The maximum and minimum AM scores across the VLMs are also shown. real paintings for which GPT4.1-mini was also capable of not attributing canvas to an incorrect painter. On the other extreme, Pixtral-12B gets the worse scores as it tends to identify the image with the proposed painter. LLaMa3.2-11B also has good results, with the rest of the models obtaining lower values. Across models, the results for the painter being imitated by the AI generator are lower than for random painter. This indicates that models can, to some extent, imitate the style of painters in way that fools VLMs. This effect is quite large in all models except GPT4.1-mini. The combined results in terms of AM are shown per model in Figure 10. The results show that again GPT4.1-mini is the best performing model and Pixtral-12B the worst. LLaMa3.2-11B also has good performance identifying most of the AI generated images as not being created by painter. For Flux and F-Lite, the results are similar and quite different from those of Stable Diffusion. All VLMs can identify the majority of images as not being painted by the proposed artist. In fact, three models, GPT4.1-mini, LLaMa3.2-11B, and Qwen2.5-VL-7B, achieved close to 100% accuracy. This is clearly seen in Figures 11, 12. These results suggest that some AI image generators have style that can be easily recognized as not corresponding to human artists. In this case, the performance gap between the correct and incorrect painter prompts is also smaller, confirming that Flux imitations are easily identified. The results per painter are shown in Figures 13,14,15 with the correspondence of numbers with artists in Tables 2, 3, 4. 7 PREPRINT - AUGUST 5, 2025 No. Artist No. Artist No. Artist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Utagawa Kuniyoshi Lucas Cranach the Elder Fra Angelico Juan Gris Pietro Perugino Antoine Blanchard Edouard Cortes Hans Memling Jacob Jordaens Albrecht Durer Ivan Bilibin Hans Holbein the Younger Paolo Veronese Hieronymus Bosch Frans Hals Anthony Van Dyck Gustave Loiseau Joshua Reynolds Tintoretto Georges Braque Gustave Dore Pierre Auguste Renoir Katsushika Hokusai Eugene Boudin Fernando Botero Joseph Wright Marc Chagall Pyotr Konchalovsky Fernand Leger Ivan Aivazovsky Paul Cezanne Egon Schiele 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 Aubrey Beardsley Theo Van Rysselberghe Nikolay Bogdanov Belsky Felix Vallotton Camille Pissarro Raoul Dufy Koloman Moser Berthe Morisot Alfred Sisley Maurice Prendergast Konstantin Makovsky Henri Matisse Sam Francis Titian Vasily Perov Aleksey Savrasov Peter Paul Rubens Mstislav Dobuzhinsky Niko Pirosmani Raphael William Turner John Henry Twachtman Amedeo Modigliani Bartolome Esteban Murillo Orest Kiprensky Edward Burne Jones Gustave Moreau Maxime Maufra David Burliuk Boris Kustodiev Konstantin Korovin Claude Monet 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 Edgar Degas El Greco Dante Gabriel Rossetti Nicholas Roerich Martiros Saryan Ivan Kramskoy Ilya Repin Ferdinand Hodler Ernst Ludwig Kirchner Henri Martin Gene Davis Camille Corot Karl Bryullov Rembrandt Canaletto Henri De Toulouse Lautrec William Merritt Chase Mary Cassatt Zinaida Serebriakova Gustave Caillebotte Henri Fantin Latour Gustav Klimt Thomas Gainsborough Kuzma Petrov Vodkin Konstantin Somov Childe Hassam Vasily Polenov Ilya Mashkov Mikalojus Ciurlionis Pierre Bonnard Gustave Courbet Raphael Kirchner No. 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 Artist Valentin Serov Giovanni Boldini Andy Warhol Francisco Goya James Tissot Odilon Redon Jacek Malczewski Leonardo Da Vinci John Singer Sargent Pablo Picasso Michelangelo Sir Lawrence Alma Tadema Isaac Levitan Ivan Shishkin James Mcneill Whistler Vasily Vereshchagin Arkhip Kuindzhi Paul Gauguin Jan Matejko Georges Seurat Lucian Freud Viktor Vasnetsov Joaquín Sorolla Edvard Munch Thomas Eakins Mikhail Vrubel Vincent Van Gogh Vasily Surikov Edouard Manet Eugene Delacroix Salvador Dalí M.C. Escher Table 1: List of 128 Artists Sorted by Arithmetic Mean Normalized Accuracy on WikiArt images of real paintings Figure 7: Average C1 and C2 scores on all painters for the VLMs considered on the images generated with Stable Diffusion 8 PREPRINT - AUGUST 5, 2025 Figure 8: Average C1 and C2 scores on all painters for the VLMs considered on the images generated with Flux Figure 9: Average C1 and C2 scores on all painters for the VLMs considered on the images generated with F-Lite Figure 10: Average AM scores on all painters for the VLMs considered on the images generated with Stable Diffusion 9 PREPRINT - AUGUST 5, 2025 Figure 11: Average AM scores on all painters for the VLMs considered on the images generated with Flux Figure 12: Average AM scores on all painters for the VLMs considered on the images generated with F-Lite For Stable Diffusion, M.C. Escher has the best performance. Interestingly, this artist had the worst performance for real paintings. The worst results for Stable Diffusion are for Gustave Loiseau and like with real paintings there is large difference among the best and worst painters. In this case, there are several popular painters, such as Michelangelo, Leonardo Da Vinci, Salvador Dalí, El Greco, or Andy Warhol among the top 10 which suggest that there can be relationship between popularity and performance. Another interesting observation is that the spread between the performance of the best and worst models is much larger than for real paintings. This is in part due to the poor performance of Pixtral-12B, which has negative normalized accuracy. For Flux, the results are more consistent with smaller differences between the painters and also between the best and worst models. The best performing artist is Henri De Toulouse Lautrec and the worst Maxime Maufra who still is above 40% average normalized accuracy. For the top performing artists, the worst model is above 80% average normalized accuracy, so all models can identify the images as not being paintings of the suggested artist. For F-Lite, the overall results are similar to those of Flux with smaller differences between the painters and also between the best and worst models than in Stable Diffusion. The best performing artist is Leonardo Da Vinci with Michelangelo, Salvador Dalí, Rembrandt, or Andy Warhol in the top 10. Once again, this may indicate correlation between artist popularity and performance. Interestingly, M.C. Escher is the third best performing artist. The artist with the worst performance is Antoine Blanchard, and the bottom 10 artists are not among the most popular. To illustrate the differences between real and AI-generated images, an example is shown in Figure16. It can be seen that in most cases Stable Diffusion does better job of imitating Van Gogh style than Flux and F-Lite. The performance of 10 PREPRINT - AUGUST 5, Figure 13: Painters ordered by average AM scores for the VLMs considered on the images generated with Stable Diffusion. The maximum and minimum AM scores across the VLMs are also shown. Figure 14: Painters ordered by average AM scores for the VLMs considered on the images generated with Flux. The maximum and minimum AM scores across the VLMs are also shown. Figure 15: Painters ordered by average AM scores for the VLMs considered on the images generated with F-Lite. The maximum and minimum AM scores across the VLMs are also shown. 11 PREPRINT - AUGUST 5, 2025 No. Artist No. Artist No. Artist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 M.C. Escher Michelangelo Leonardo Da Vinci Salvador Dalí El Greco Mikhail Vrubel Andy Warhol Albrecht Durer Ivan Bilibin Jan Matejko Peter Paul Rubens Sam Francis Rembrandt Katsushika Hokusai Gustave Moreau Tintoretto Francisco Goya Odilon Redon Raphael Mikalojus Ciurlionis Viktor Vasnetsov Vincent Van Gogh Titian Eugene Delacroix Giovanni Boldini William Turner Gustav Klimt Thomas Gainsborough Pablo Picasso Aubrey Beardsley Niko Pirosmani Paolo Veronese 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 Martiros Saryan Mstislav Dobuzhinsky Vasily Vereshchagin Bartolome Esteban Murillo Pyotr Konchalovsky Dante Gabriel Rossetti Jacek Malczewski Hieronymus Bosch Arkhip Kuindzhi Frans Hals Gustave Dore Vasily Surikov Anthony Van Dyck Ivan Shishkin Georges Braque Marc Chagall Valentin Serov Lucian Freud Utagawa Kuniyoshi Fra Angelico Orest Kiprensky Egon Schiele Raphael Kirchner Joseph Wright Gustave Courbet John Singer Sargent Hans Memling Edvard Munch James Tissot Joshua Reynolds Fernand Leger Sir Lawrence Alma Tadema 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 Gene Davis Hans Holbein The Younger Jacob Jordaens James Mcneill Whistler Fernando Botero Edouard Manet Edgar Degas Karl Bryullov Nicholas Roerich Vasily Perov Zinaida Serebriakova Edward Burne Jones Canaletto Thomas Eakins Antoine Blanchard Boris Kustodiev Theo Van Rysselberghe JoaquãN Sorolla Juan Gris Paul Gauguin Koloman Moser Felix Vallotton Ivan Kramskoy Childe Hassam Henri Fantin Latour Konstantin Makovsky Amedeo Modigliani Edouard Cortes Pietro Perugino Georges Seurat Konstantin Somov David Burliuk No. 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 Artist Henri De Toulouse Lautrec Kuzma Petrov Vodkin Claude Monet Mary Cassatt Aleksey Savrasov Lucas Cranach The Elder Ilya Repin Ernst Ludwig Kirchner Isaac Levitan Vasily Polenov Paul Cezanne Henri Matisse Ilya Mashkov Raoul Dufy Ferdinand Hodler Berthe Morisot Camille Corot Ivan Aivazovsky Nikolay Bogdanov Belsky Maurice Prendergast William Merritt Chase Konstantin Korovin Gustave Caillebotte Pierre Auguste Renoir John Henry Twachtman Henri Martin Camille Pissarro Alfred Sisley Eugene Boudin Pierre Bonnard Maxime Maufra Gustave Loiseau Table 2: List of 128 Artists Sorted by Arithmetic Mean Normalized Accuracy of Stable Diffusion-Generated paintings No. Artist No. Artist No. Artist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Henri De Toulouse Lautrec Dante Gabriel Rossetti Mary Cassatt Michelangelo Edgar Degas Giovanni Boldini Sir Lawrence Alma Tadema Ivan Kramskoy Lucian Freud Jan Matejko JoaquãN Sorolla Amedeo Modigliani Edouard Manet Leonardo Da Vinci John Singer Sargent Edvard Munch Mikhail Vrubel El Greco Vasily Perov Pablo Picasso Francisco Goya Marc Chagall Vasily Vereshchagin Vincent Van Gogh Eugene Delacroix Edward Burne Jones Egon Schiele Orest Kiprensky Valentin Serov Ivan Bilibin Gustave Moreau James Tissot 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 Karl Bryullov Berthe Morisot Vasily Surikov Gustave Dore Henri Matisse Viktor Vasnetsov Odilon Redon Albrecht Durer Salvador Dalí Rembrandt James Mcneill Whistler Katsushika Hokusai Hans Holbein The Younger Niko Pirosmani M.C. Escher Anthony Van Dyck Fra Angelico Zinaida Serebriakova Thomas Eakins Peter Paul Rubens Titian Paul Cezanne Kuzma Petrov Vodkin Georges Braque Pietro Perugino Pierre Auguste Renoir Childe Hassam Frans Hals Gustave Courbet Paolo Veronese Andy Warhol Felix Vallotton 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 Paul Gauguin Camille Pissarro Tintoretto Boris Kustodiev Ferdinand Hodler Konstantin Somov Gustav Klimt Raphael Jacek Malczewski Mstislav Dobuzhinsky Pierre Bonnard Pyotr Konchalovsky Arkhip Kuindzhi Georges Seurat Fernando Botero Gustave Caillebotte Hieronymus Bosch Thomas Gainsborough Theo Van Rysselberghe Maurice Prendergast Utagawa Kuniyoshi Ernst Ludwig Kirchner Henri Fantin Latour Martiros Saryan William Turner Canaletto Bartolome Esteban Murillo Aubrey Beardsley Koloman Moser Joshua Reynolds Joseph Wright Konstantin Makovsky No. 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 Artist Vasily Polenov Ilya Repin Raphael Kirchner Claude Monet Fernand Leger Ivan Shishkin Nicholas Roerich Jacob Jordaens Hans Memling Raoul Dufy Camille Corot Lucas Cranach The Elder Isaac Levitan William Merritt Chase Edouard Cortes Konstantin Korovin Mikalojus Ciurlionis Henri Martin Ivan Aivazovsky Alfred Sisley Juan Gris Sam Francis Aleksey Savrasov Antoine Blanchard Nikolay Bogdanov Belsky Ilya Mashkov John Henry Twachtman David Burliuk Gustave Loiseau Eugene Boudin Gene Davis Maxime Maufra Table 3: List of 128 Artists Sorted by Arithmetic Mean Normalized Accuracy of Flux-Generated paintings 12 PREPRINT - AUGUST 5, 2025 No. Artist No. Artist No. Artist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 Leonardo Da Vinci Michelangelo M.C. Escher Salvador Dalí Rembrandt Andy Warhol Edvard Munch Raphael Eugene Delacroix Amedeo Modigliani Albrecht Durer Marc Chagall Henri De Toulouse Lautrec El Greco Edgar Degas Pablo Picasso Mary Cassatt James Mcneill Whistler Vincent Van Gogh Egon Schiele Thomas Eakins Sam Francis Francisco Goya Felix Vallotton John Singer Sargent Karl Bryullov Edouard Manet Thomas Gainsborough Orest Kiprensky Jan Matejko Anthony Van Dyck Ivan Kramskoy 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 Mikhail Vrubel Titian JoaquãN Sorolla Dante Gabriel Rossetti Edward Burne Jones Peter Paul Rubens Fra Angelico Katsushika Hokusai William Turner Giovanni Boldini Vasily Vereshchagin Paolo Veronese Tintoretto James Tissot Vasily Surikov Valentin Serov Georges Braque Henri Matisse Hans Holbein The Younger Viktor Vasnetsov Odilon Redon Gustave Moreau Frans Hals Gustave Courbet Niko Pirosmani Kuzma Petrov Vodkin Pietro Perugino Pyotr Konchalovsky Fernando Botero Pierre Auguste Renoir Vasily Perov Arkhip Kuindzhi 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 Henri Fantin Latour Berthe Morisot Utagawa Kuniyoshi Ferdinand Hodler Ivan Bilibin Canaletto Bartolome Esteban Murillo Zinaida Serebriakova Raphael Kirchner Georges Seurat Ernst Ludwig Kirchner Joseph Wright Lucian Freud Gustav Klimt Hieronymus Bosch Ivan Aivazovsky Childe Hassam Fernand Leger Boris Kustodiev Jacek Malczewski Koloman Moser Mikalojus Ciurlionis Nicholas Roerich Gustave Dore Camille Corot Konstantin Somov Gene Davis Martiros Saryan Camille Pissarro Paul Cezanne Raoul Dufy Mstislav Dobuzhinsky No. 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 Artist Paul Gauguin Sir Lawrence Alma Tadema Claude Monet Aubrey Beardsley Isaac Levitan Jacob Jordaens Gustave Caillebotte Juan Gris Ivan Shishkin Theo Van Rysselberghe Aleksey Savrasov Joshua Reynolds Vasily Polenov Pierre Bonnard Alfred Sisley Hans Memling William Merritt Chase Ilya Repin Maurice Prendergast Lucas Cranach The Elder Konstantin Korovin Eugene Boudin Konstantin Makovsky John Henry Twachtman Henri Martin Gustave Loiseau David Burliuk Ilya Mashkov Maxime Maufra Edouard Cortes Nikolay Bogdanov Belsky Antoine Blanchard Table 4: List of 128 Artists Sorted by Arithmetic Mean Normalized Accuracy of F-Lite-Generated paintings Stable Diffusion appears to rely on certain artistic clichés. For example, when recreating paintings by Van Gogh that depict skies, it often reproduces the swirling patterns from his famous Starry Night (see Figure 17), even when such elements are absent from the reference original images provided (see Figure 18). similar pattern is observed in some of Dalís recreations by Stable Diffusion, where clocks appear even when they are absent from the original works14. In summary, the accuracy of VLMs in identifying AI-generated images as not being made by human painters depends largely on the text-to-image generator model. For Flux and F-Lite, several VLMs are capable of performing the identification accurately, while for Stable Diffusion, the results are worse. As for the painters, in some cases there seems to be correlation between performance and artist popularity, but in others there is no such effect. There are also specific artists that tend to get extreme performance values. An example is M.C. Escher which is the worst for real painters and among the best for AI generated images. In this case, it may be due to its particular style that is not recognized either in the original paintings nor in the paintings. AI generated images. 4.3 Limitations The study presented in this paper has several limitations. First, although the dataset of canvas used is extensive, the experimental evaluation can always be extended with additional artists or paintings. The same reasoning applies to both the VLMs and the text-to-image AI models, additional models can be evaluated, in fact by the time the paper is published there will be newer VLMs and text-to-image models. To mitigate this issue, the code and data used in our experiments have been designed to facilitate the testing of new models, for example by releasing the descriptions of all the paintings of the dataset so that they can be used with newer text-to-image models to generate AI imitations. Beyond the dataset and models, there are also limitations in the prompts used which target given artist giving the VLM only the yes or no options for answering. It would be interesting to use open questions on the artist to better understand if the models are capable of identifying the artist or if they attribute the painting to different one. Similarly, additional analysis in which the models are asked about painters that have similar styles or features in their canvas would also be of interest, as well as doing finer analysis of the results per painter, genre, and style. To mitigate this issue, data obtained in the evaluation are publicly available for other researchers that can conduct additional analysis. 4.4 Analysis and discussion The results presented in the previous subsections show the limitations of current VLMs to: 14see works 5, 89, and 389 by Salvador Dalí in https://ama2210.github.io/WikiArt_VLM_Web/ 13 PREPRINT - AUGUST 5, 2025 Figure 16: painting by Van Gogh (top-left) and the images generated by Stable Diffusion (top-right), Flux (bottomleft) and F-Lite (bottom-right) . 1. Identify real paintings that correspond to the original artist. 2. Identify real paintings that do not correspond to random artist. 3. Identify AI-generated images that imitate the style of painter for some AI text-to-image generation models. Only half of the VLMs can reliably identify the content generated by two of the three text-to-image generators used as not corresponding to human painters. Instead, for Stable Diffusion, the detection is not reliable. The results also show large variations depending on the artist, with no clear correlation between performance for real and AI-generated images. For some of the AI generators there seems to be correlation between the artist popularity and the model performance, while that is not the case for real painters. Further analysis of the data may provide additional insight into how the performance of VLMs depends on different characteristics of the artist or the painting, such as the style, the genre, or the painting techniques used. These analyses are left for future work, and to facilitate further research, the data is released both in raw format and with an interactive visualization tool. The same applies to the study of the correlation of VLM performance with artist popularity, production, or number of imitations and presence in, for example, merchandising such as mugs, t-shirts or low-cost reproductions [28]. As mentioned earlier, current systems fail to recognize even what is arguably the most famous painting in the world: La Gioconda. The limitations of VLMs to perform artist attribution pose significant risk that can lead to confusion or even misinformation. For example, as users increasingly rely on AI models to answer queries, incorrect information can propagate to millions of users given the widespread adoption of VLMs. However, this is not the only issue, as AI models are also used to process data massively, incorrect information may propagate to websites or other sources 14 PREPRINT - AUGUST 5, Figure 17: Vincent Van Gogh. //artsandculture.google.com/asset/bgEuwDxel93-Pg). 1889. Starry Night. Museum of Moder Art. New York (source https: of content. For example, VLMs can be used to automatically annotate large set of paintings that are subsequently published online. In fact, the ease of massive processing of data may be larger issue than user queries. To address these issues, ideally the performance of VLMs would improve to reach accuracy values that provide reliable information. However, while that is not the case, VLMs should be carefully used for painting attribution, only as another tool that provides information to take decision, but not blindly. good policy for VLMs would be to include warnings or disclaimers in their responses to prevent misinterpretation or misuse of their responses. Another possibility could be to fine-tune the models on large dataset of paintings to see if the performance improves. further step would be to include the datasets generated in this work as training data for future VLMs. Both ideas are left for future work, and facilitated by making our datasets public."
        },
        {
            "title": "5 Conclusion",
            "content": "This paper has presented comprehensive evaluation of state-of-the-art Vision Language Models (VLMs) on tasks: artist attribution for real paintings and detection of AI-generated imitations. Using nearly 40,000 paintings from 128 artists, together with synthetic images generated in the style of those artists, we have demonstrated that most VLMs suffer from substantial limitations in both domains. First, when attribution of real paintings is made, the best performing VLMs, Gemma312B and LLaMa3.211B, achieve modest normalized accuracy, while others like GPT4.1-mini and Pixtral-12B show consistent failures or unreliable behavior. Second, when confronted with AI-generated images mimicking painters styles, models again vary widely: GPT4.1-mini excels at rejecting attribution, whereas Pixtral-12B often mistakenly credits the suggested artist but results depend heavily on the AI generator used to create the images. These findings expose important risks: as users increasingly rely on VLMs for artist information, errors may lead to widespread confusion or misinformation. The potential scale of harm increases as AI annotations proliferate online and across downstream applications. To mitigate these risks, we recommend caution in the deployment of VLM-based attribution tools using them as decision-support tools rather than definitive authorities."
        },
        {
            "title": "Acknowledgments",
            "content": "This work is supported by the FUN4DATE (PID2022-136684OB-C22) and SMARTY (PCI2024-153434) projects funded by the Spanish Agencia Estatal de Investigación (AEI) 10.13039/501100011033, by TUCAN6-CM (TEC2024/COM-460), funded by CM (ORDEN 5696/2024) and by the Chips Act Joint Undertaking project SMARTY (Grant no. 101140087)."
        },
        {
            "title": "References",
            "content": "[1] Hugh Honour. Neo-Classicism. Penguin, Harmondsworth, 1977. 15 PREPRINT - AUGUST 5, 2025 Figure 18: On the left are original works by Vincent van Gogh; on the right, parallel recreations by Stable Diffusion, which incorporate the characteristic swirling of Starry Night despite its absence in the original images. (Items 49, 51 and 65 in https://ama2210.github.io/WikiArt_VLM_Web/. [2] Denis Dutton. Artistic crimes: The problem of forgery in the arts. British Journal of Aesthetics, 19(4):302314, 1979. [3] P. B. Coremans. Van Meegerens Faked Vermeers and De Hooghs: Scientific Examination. Cassell & Co. Ltd., London, 1949. [4] Ernst Van de Wetering. Rembrandt: The Painter at Work. University of California Press, Berkeley, 2004. [5] Ernst Van de Wetering. Corpus of Rembrandt Paintings VI. Rembrandts Paintings Revisited - Complete Survey. Springer, Dordrecht, 2015. PREPRINT - AUGUST 5, 2025 [6] Jorge Miguel Silva, Diogo Pratas, Rui Antunes, Sérgio Matos, and Armando J. Pinho. Automatic analysis of artistic paintings using information-based measures. Pattern Recognition, 114:107864, 2021. [7] Hassan Ugail, David Stork, Howell Edwards, Steven Seward, and Christopher Brooke. Deep transfer learning for visual analysis and attribution of paintings by raphael. Heritage Science, 11(1):268, 2023. [8] Fang Ji, Michael McMaster, Samuel Schwab, Gundeep Singh, Lauryn Smith, Shishir Adhikari, Márcio ODwyer, Farah Sayed, Anthony Ingrisano, Dean Yoder, et al. Discerning the painters hand: machine learning on surface topography. Heritage Science, 9:111, 2021. [9] Marcelo Fraile Narváez, Ismael Sagredo-Olivenza, and Nadia McGowan. Painting authorship and forgery detection challenges with ai image generation algorithms: Rembrandt and 17th century dutch painters as case study. International Journal of Interactive Multimedia and Artificial Intelligence, 7:7, 01 2022. [10] Howell G. M. Edwards. The Application of Artificial Intelligence (AI) to the Attribution of Art Works, pages 181215. Springer Nature Switzerland, Cham, 2024. [11] Jingyi Zhang, Jiaxing Huang, Sheng Jin, and Shijian Lu. Vision-language models for vision tasks: survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(8):56255644, 2024. [12] Yi Bin, Wenhao Shi, Yujuan Ding, Zhiqiang Hu, Zheng Wang, Yang Yang, See-Kiong Ng, and Heng Tao Shen. Gallerygpt: Analyzing paintings with large multimodal models. In Proceedings of the 32nd ACM International Conference on Multimedia, MM 24, page 77347743, New York, NY, USA, 2024. Association for Computing Machinery. [13] Xin Sun, Rongjun Ma, Xiaochang Zhao, Zhuying Li, Janne Lindqvist, Abdallah El Ali, and Jos Bosch. Trusting the search: unraveling human trust in health information from google and chatgpt. arXiv preprint arXiv:2403.09987, 2024. [14] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1068410695, 2022. [15] Andrea Asperti, Franky George, Tiberio Marras, Razvan Ciprian Stricescu, and Fabio Zanotti. critical assessment of modern generative models ability to replicate artistic styles. arXiv preprint arXiv:2502.15856, 2025. [16] Javier Conde, Miguel Gonzalez, Gonzalo Martínez, Fernando Moral, Elena Merino-Gomez, and Pedro Reviriego. Recursive inpainting (rip): how much information is lost under recursive inferences? AI & SOCIETY, pages 117, 2025. [17] C. R. Johnson et al. Image processing for artist identification. IEEE Signal Processing Magazine, 25(4):3748, 2008. [18] Babak Saleh and Ahmed Elgammal. Large-scale classification of fine-art paintings: Learning the right metric on the right feature. In International Conference on Big Data, pages 479483, 2015. [19] Minghui Tan, Chee Seng Chan, and Huay S. Lim. Ceci nest pas une pipe: deep convolutional network for fine-art paintings classification. In 2016 IEEE International Conference on Image Processing (ICIP), pages 37033707, 2016. [20] Ludovica Schaerf, Eric Postma, and Carina Popovici. Art authentication with vision transformers. Neural Comput. Appl., 36(20):1184911858, August 2023. [21] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning. PMLR, 2021. [22] Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, and Taro Watanabe. Towards artwork explanation in large-scale vision language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 705729, 2024. [23] Ombretta Strafforello, Derya Soydaner, Michiel Willems, Anne-Sofie Maerten, and Stefanie De Winter. Have large vision-language models mastered art history? arXiv preprint arXiv:2409.03521, 2024. [24] Pengfei Yang, Ngai-Man Cheung, and Xinda Ma. Text to image generation and editing: survey. arXiv preprint arXiv:2505.02527, 2025. [25] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1068410695, June 2022. 17 PREPRINT - AUGUST 5, 2025 [26] Stephen Casper, Zifan Guo, Shreya Mogulothu, Zachary Marinov, Chinmay Deshpande, Rui-Jie Yew, Zheng Dai, and Dylan Hadfield-Menell. Measuring the success of diffusion models at imitating human artists. arXiv preprint arXiv:2307.04028, 2023. [27] Meien Li and Mark Stamp. Detecting ai-generated artwork. arXiv preprint arXiv:2504.07078, 2025. [28] Jonathan Schroeder. Aesthetics awry: The painter of light and the commodification of artistic values. Consumption, Markets and Culture, 9(02):8799, 2006."
        }
    ],
    "affiliations": [
        "Nanjing University of Aeronautics and Astronautics",
        "Universidad Antonio de Nebrija",
        "Universidad Politécnica de Madrid",
        "Universidad de Valladolid"
    ]
}