{
    "paper_title": "Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs",
    "authors": [
        "Pasin Buakhaw",
        "Kun Kerdthaisong",
        "Phuree Phenhiran",
        "Pitikorn Khlaisamniang",
        "Supasate Vorathammathorn",
        "Piyalitt Ittichaiwong",
        "Nutchanon Yongsatianchot"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The emergence of large language models (LLMs) has opened new opportunities for cre- ating dynamic non-player characters (NPCs) in gaming environments, enabling both func- tional task execution and persona-consistent dialogue generation. In this paper, we (Tu_Character_lab) report our participation in the Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2, which eval- uates agents across three tracks: task-oriented dialogue, context-aware dialogue, and their integration. Our approach combines two complementary strategies: (i) lightweight prompting techniques in the API track, including a Deflanderization prompting method to suppress excessive role-play and improve task fidelity, and (ii) fine-tuned large models in the GPU track, leveraging Qwen3-14B with supervisedfinetuning (SFT) and Low-Rank Adaptation(LoRA). Our best submissions ranked 2nd on Task 1, 2nd on Task 3 (API track), and 4th on Task 3 (GPU track)."
        },
        {
            "title": "Start",
            "content": "Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs Pasin Buakhaw1, Kun Kerdthaisong2, Phuree Phenhiran2,, Pitikorn Khlaisamniang3, Supasate Vorathammathorn3, Piyalitt Ittichaiwong4,5,*, Nutchanon Yongsatianchot2,* 1 Department of Computer Engineering and Digital Technology, Faculty of Engineering, Chulalongkorn University 2Thammasat School of Engineering, Thammasat University 3Artificial Intelligence Association of Thailand 4School of Biomedical Engineering & Imaging Sciences, Kings College London 5Siriraj Informatics and Data Innovation Center (SIData+), Faculty of Medicine, Siriraj Hospital, Mahidol University These authors contributed equally to this work. *Corresponding author 5 2 0 2 5 1 ] . [ 1 6 8 5 3 1 . 0 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "The emergence of large language models (LLMs) has opened new opportunities for creating dynamic non-player characters (NPCs) in gaming environments, enabling both functional task execution and persona-consistent dialogue generation. In this paper, we (Tu_Character_lab) report our participation in the Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2, which evaluates agents across three tracks: task-oriented dialogue, context-aware dialogue, and their integration. Our approach combines two complementary strategies: (i) lightweight prompting techniques in the API track, including Deflanderization prompting method to suppress excessive role-play and improve task fidelity, and (ii) fine-tuned large models in the GPU track, leveraging Qwen3-14B with supervised finetuning (SFT) and Low-Rank Adaptation (LoRA). Our best submissions ranked 2nd on Task 1, 2nd on Task 3 (API track), and 4th on Task 3 (GPU track)."
        },
        {
            "title": "Introduction",
            "content": "The revolution of large language models (LLMs) has demonstrated that transformer architectures can engage in human-like dialogue interactions within virtual environments. Recent studies have categorized persona-enabled LLMs into two distinct adaptation approaches: user-focused personalization and environment-based role-playing (Tseng et al., 2024). First, user persona-LLMs are designed as purpose-built assistants that adapt to individual users preferences, backgrounds, and behavioral patterns (Salemi et al., 2023; Zhang et al., 2024). These personalization systems leverage user-specific information to provide tailored responses, recommendations, and interactions. For example, LaMP (Large Language Models Meet Personalization) introduces comprehensive benchmarks for evaluating personalized text generation (Salemi et al., 2023), while recent work explores personalized dialogue agents that maintain consistent user preferences across conversations (Zhang et al., 2018). Second, environment adaptation involves LLMs tasked with maintaining consistent personas within specific contexts, commonly referred to as roleplaying. This approach has gained significant traction in multi-agent systems where LLMs assume distinct professional roles. ChatDev (Qian et al., 2023) exemplifies this paradigm by creating virtual software development company where different agents handle specialized tasks such as programming, testing, and documentation. Similarly, MetaGPT (Hong et al., 2023) proposes metaprogramming framework for collaborative multiagent workflows, while Generative Agents (Park et al., 2023) demonstrates believable human behavior simulation through persistent agent personas. Advanced frameworks like CAMEL (Li et al., 2023) and Voyager (Wang et al., 2023) further explore how role-playing agents can engage in complex problem-solving and open-ended exploration tasks. These developments showcase the remarkable ability of modern LLMs to facilitate and embody given personas, with applications spanning from personalized user assistance to sophisticated multiagent collaborations in virtual environments (Chan et al., 2023; Jiang et al., 2022). Despite the rapid growth of LLM research, the entertainment field has remained relatively underin Minecraft showcase how LLM-driven NPCs can work alongside human players to accomplish shared objectives (Rao et al., 2024), while functioncalling capabilities enable AI Game Masters or NPCs to manage complex game mechanics and narrative progression (Chen et al., 2024). Furthermore, specialized datasets like MCPDial (Yang et al., 2024) and PeaCoK (Gao et al., 2023) provide rich persona-driven dialogue collections that enhance the authenticity and depth of NPC interactions, supporting the development of more sophisticated conversational agents in gaming environments. The growing interest in persona-grounded gaming applications has culminated in organized competitions such as the Commonsense PersonaGrounded Dialogue Challenge (CPDC) 2025 (Sony AI, 2025). This competition invited submissions aimed at developing NPC agents that demonstrate both persona consistency and task execution capabilities in fantasy Role-Playing Game (RPG) environment, as illustrated in Figure 1. From our participation in this challenge across every track, both GPU and API divisions, the following are key points that we investigated: Deflanderization prompting technique to maintain dialogue generation and function generation ability in common fantasy RPG world setting."
        },
        {
            "title": "2.1 Agents for Game-Oriented Dialogue",
            "content": "Task-oriented systems are designed to complete specific tasks within larger projects, often as prerequisites for subsequent steps. This approach emphasizes efficient and effective task completion to achieve defined goals. The integration of agentic systems into such workflows enables agents to analyze problems, formulate plans, and execute them to achieve desired outcomes. The performance of these agents, particularly in task-oriented dialogue (TOD), has been key area of research. For instance, (Kazi et al., 2024) established benchmark for evaluating agent performance in TOD systems. They highlight that an agents planning capabilities can be assessed by focusing on the final stage of simulation, the alignment of the proposed solution with the goal, or the methods the agent uses to interact with the system, such as gathering sufficient information to solve problem. Figure 1: Examples of playerNPC interactions using LLM-based agents in the CPDC 2025 competition, Top panel: Early Summer 7 PM, clear night at the Weapon Shop, showing an example of user-NPC interaction in Task 1 (function generation). Bottom panel: Late Winter 2 PM, rainy conditions at the Quest Reception Desk, showing an example of dialogue generation in Task 2. explored, particularly in traditional entertainment media creation such as video games. Conventional game development relies heavily on programmed logic, where in-game events and character interactions follow predetermined scripts and dialogue trees. To enhance player immersion and narrative depth, developers have begun incorporating LLMs as integral components of NPCs. This integration enables them to exhibit human-like behaviors and engage in dynamic, contextually-aware conversations with players (Song et al., 2024). However, maintaining the consistency and depth of these dynamic personas over long-term interactions presents significant challenge. One such pitfall, drawn from media analysis, is the trend of \"flanderization\" (Larsen, 2019). Flanderization is the process through which complex character is progressively simplified over time, eventually becoming caricature defined by single, exaggerated trait. The term originates from the character Ned Flanders in The Simpsons, who evolved from genuinely good-natured neighborwhose faith was one of many aspects of his personalityinto one-dimensional religious zealot. Recent advances in LLM-driven NPCs demonstrate significant potential for transforming player experiences. Cross-platform dialogue systems allow NPCs to maintain consistent interactions across both game environments and social platforms like Discord (Song et al., 2024), creating unprecedented continuity in player-character relationships. Collaborative quest completion systems In the context of gaming, completing sequence of events often involves accomplishing series of tasks. To aid players, especially newcomers, (Lee et al., 2025) developed specialized game assistant. This assistant leverages an LLM that has undergone continuous pre-training and instruction tuning to answer specific game-related questions, thereby helping users navigate complex game mechanics. To ensure that interactive agents can successfully complete their objectives within game (Phillips et al., 2025) introduced framework that utilizes two distinct agents: Dialogue agent and goalverifying agent. This system employs shared memory to manage interactions, ensuring that dialogue and actions remain aligned with the overarching task goals. 2.2 Tool calling Tool-calling or function-calling, an ability of LLMs to interact with external tools or functions, experienced recent surge in interest, driven by the potential of LLMs to autonomously complete tasks by dynamically accessing and acting upon external resources, extending their capabilities to become agentic AI (Xu et al., 2025; Patil et al., 2025). The architecture of these agents typically involves multi-step framework to ensure accuracy in complex, real-world tasks. This framework includes components for executing actions, perceiving the environment, validating results, controlling the overall plan, and retrieving tools from toolset (Xu et al., 2025). key challenge in this domain is the development of robust evaluation benchmarks. While existing benchmarks have focused on single-control environments where only the AI agent can interact with tools, recent work has introduced more complex scenarios. For instance (Barres et al., 2025), the τ 2-Bench introduces dual-control environment where both the agent and the user can utilize tools to act in shared, dynamic world. This setup is designed to more accurately represent real-world collaborative scenarios, such as technical support, and to expose the challenges of agent coordination and communication that are absent in single-user control evaluations. The performance of LLMs degrades significantly in such dual-control settings, underscoring the difficulty of guiding user actions and the importance of further research in this area."
        },
        {
            "title": "3 Competition Overview",
            "content": "3.1 Competition Tasks The CPDC competition aims to facilitate dialogues that seamlessly integrate contextual understanding, knowledge utilization and task execution capabilities in fantasy RPG game setting (Sony AI, 2025). The competition comprises two tracks, API Track and GPU Track (detailed in the next section), and each track consists of three tasks: Task 1: Task-Oriented Dialogue Agents, Task 2: Context-Aware Dialogue Agents, Task 3: Integrated Contextual Dialogue and Task Execution (combining both Task 1 and Task 2). Examples of these tasks are illustrated in Figure 1."
        },
        {
            "title": "4.1 API Track",
            "content": "In the API track, participants submit their work within specific environment and constraints such as the allowed LLM is GPT4o-mini (see for full details). We focused on prompting methods. Our pipeline is illustrated in Figure 2. We systematically explored the following prompting approaches: (Deflanderization): Prompts the model to respond naturally and concisely while avoiding exaggerated role-playing. Start Step 1: Prepare Function Calling Prompt Define function: Provides two sample function arguments (merchant and guild receptionist) with their items in JSON format. Our best submission (ranked 2nd on Task 3, 2nd on Task 1 and 5th on Task 2) on public leader board used only D-RW combined with two turns of sample dialogues. Step 2: Function Generation (API Call #1) 4.2 GPU Track Step 3: Execute Functions Step 4: Prepare Dialogue Prompt Step 5: Dialogue Generation (API Call #2)"
        },
        {
            "title": "Final Response",
            "content": "Figure 2: Main pipeline for the API Track task 3. The prompting stages are Step1 and Step4 and generataion stages are in Step2 and Step5 (Fewshot): Includes two sample dialogues (merchant and guild receptionist) from sample.json in the prompt. ZeroShot: Uses the initial baseline prompt from the competition repository. CoT (Chain of Thought): Instructs the model to think step-by-step before answering. RW (Remove world setting): Removes worldview information when constructing dialogue prompts. (Guide): Guides response style by limiting to 12 short sentences, using simple language, and restricting to provided knowledge. MW (Most word): Guides word usage and provides example phrases. Due to the compute limitations described in Appendix D, we selected models that can be executed on the AWS g5e.2xlarge instances with L40s GPUs instance. We first validated inference submission feasibility using Qwen2.5 (Qwen et al., 2024), Qwen3 (Yang et al., 2025), LLaMA3.1 (Grattafiori et al., 2024), and Phi-4 (Abdin et al., 2024), before proceeding with finetuning experiments on both initial and augmented data. To improve dialogue grounding, we incorporated hybrid Retrieval Augmented Generation (RAG) +Memory approach. The retrieval module encodes both player and NPC conversation histories using Qwen3-Embedding-0.6B, enabling similarity search across pre-collected interaction datasets. The retrieved context is injected at two stages: (i) Function Selection, where prior conversations guide accurate tool invocation, and (ii) Dialogue Drafting, where relevant NPC responses provide style and factual grounding. Additionally, we explored RAG+Refine step, where generated drafts are rewritten to match the tone and length of high-similarity golden responses, ensuring stylistic consistency with provided ingame dialogue. Our best-performing submission (ranked 4th on Task 3 public leaderboard) was achieved applied Supervised with Qwen3-14B. We Finetuning (SFT) with Low-Rank Adaptation (LoRA) (Hu et al., 2022) using the Unsloth framework (Daniel Han and team, 2023). The training procedure was divided into two stages: (1) Full SFT on initial and synthetic multi-turn followed by (2) LoRA-SFT dialogue data, (rank=32, α = 32) on combined dialogue and function-calling datasets. We generated the datasets using gemini-2.5pro-preview-05-06 (deepmind, 2025) for functioncalling data and Gpt4o-mini (OpenAI, 2024) for dialogue data. The generated datasets consist of: Multi-turn (2,800 datapoints), Multi-turn reasoning (2,800 datapoints) for Task 2 (3.1.2) and we For Funtion-calling generation (328 data points) for Task 1 (3.1.1). Prompts used for data generation are provided in C.1. inference, deploy2023) ment with using hyperparameters: the dtype=bfloat16, gpu_memory_utilization=0.8, enable_LoRA, max_model_len=4096, and disable_sliding_window=True, enabling Qwen3-14B to run within the L40s memory budget. vLLM (Kwon following optimized et al.,"
        },
        {
            "title": "5 Results",
            "content": "5.1 API Track Before submitting to the (AIcrowd, 2025) submission system, we focused on testing the API track on existing datasets to explore possible prompting technique. The dataset consists of Task 1 train.json, sample.json and Task 2: train.json, sample.json. Tables 1 and 2 summarize the the API track results for Task 1 and Task 3, respectively. We observe several notable trends: 1. Effectiveness of Deflanderization prompting. Across both tasks, the Deflanderization (D) strategy consistently improved scores compared to the In Task 3  (Table 2)  , D-RW zero-shot baseline. achieved +0.013 absolute gain in CPDCscore(all) compared to zero-shot. This supports our hypothesis that overly strong role-playing can hinder functional correctness by diverting the model toward stylistic embellishment rather than more realistic character. 2. Sample-based prompting further boosts accuracy. Adding few-shot examples (F) to the Deflanderization prompt provided clear benefits in Task 1 function name and argument matching  (Table 2)  , with improvements of +0.092 and +0.133, respectively, on train.json. Notably, our best-performing API submission combined D-RW with two-turn few-shot examples, yielding the highest leaderboard placement (2nd on Task 3, 2nd on Task 1, and 5th on Task 2). Adding few-shot examples (F) to the Deflanderization prompt provided clear benefits in Task 1  (Table 1)  , with improvements of +0.092 and +0.133 on train.json, respectively. Notably, our bestperforming API submission combined D-RW with two-turn few-shot examples, yielding the highest leaderboard placement (2nd on Task 3, 2nd on Task 1, and 5th on Task 2). 3. Limited benefits of more complex prompting. Chain-of-Thought (CoT), guiding responses (G), and Most Word (MW) constraints yielded marginal or inconsistent gains. For instance, CoT improved BERTScore in Task 1 but decreased function argument accuracy, likely due to verbose reasoning diluting key arguments. Similarly, MW improved BLEU on train.json but did not transfer to the leaderboard CPDCscore. This suggests that lightweight strategies (D + few-shot) are more robust under competition constraints than complex, multi-signal prompts for these tasks. Table 3 presents results for Task 3 under the GPU track. 1. Model scaling and finetuning are critical. Baseline submissions with smaller models (e.g., LLaMA3.1-8B, Phi-4-mini) underperformed, with In contrast, Qwen3-14B all-scores below 0.40. with full SFT and LoRA achieved significant improvement, reaching 0.598 all-score, ranking 4th on the leaderboard. This highlights the importance of both model size and targeted finetuning on domain-specific data. 2. Retrieval augmentation provided modest improvements. RAG+Refine and RAG+Memory approaches improved Qwen3-8B performance to 0.522 for Task 1, showing that retrieval helps stabilize dialogue grounding. However, these methods fell short of the gains achieved by LoRA-SFT. We attribute this to the limited scale of the retrieval corpus and the challenge of injecting retrieved context seamlessly without overloading prompts. 3. Trade-off between Task 1 and Task 2. Interestingly, while RAG+Refine gave the best Task 1 score (0.522), it underperformed on Task 2 compared to baseline. Conversely, LoRA-SFT balanced both tasks, producing the highest joint score. This suggests that alignment between functional reasoning (Task 1) and persona-grounded dialogue (Task 2) requires joint optimization, rather than modular improvements in isolation."
        },
        {
            "title": "6 Discussion",
            "content": "Overall, our findings reveal complementary strategies across the API and GPU tracks. Promptingbased Deflanderization with few-shot grounding proved effective in low-resource API settings, while finetuned large models dominated the GPU track. Importantly, both tracks highlighted the challenge of balancing persona consistency with funcTable 1: API Track Task 1 Result Dataset train.json sample.json metrics Function name exact match Function argument exact match BERTScore Function name exact match Function argument exact match BERTScore test(submission) CPDCscore(Task 1) ZeroShot(Z) CoT(CoT) F(F) Define function(func) Our Best(D), (RW) 0.622 0.226 0.542 0.667 0.333 0. 0.422 0.537 0.211 0.566 0.333 0.000 0.534 0.633 0.199 0.538 0.600 0.100 0.491 0. 0.441 0.615 0.210 0.539 0.714 0.429 0.496 0.430 0.714 0.359 0.569 0.727 0.364 0. 0.586 Table 2: API Track Task 3 Result Dataset train.json metrics BLEU-4 Word-level F1 BERTScore ZeroShot D(D) D-F-RW(RW) D-F-G-RW(G) D-F-MW-G-RW(MW) Our Best 0.041 0.290 0. 0.043 0.300 0.542 0.032 0.279 0.527 0.031 0.293 0.525 0.040 0.292 0.540 0.035 0.273 0.543 sample.json test(submission) BLEU-4 Word-level F1 BERTScore CPDCscore(Task 1) CPDCscore(Task 2) CPDCscore(all) 0.027 0.276 0.536 0.422 0.598 0.510 0.028 0.281 0.548 0.436 0.614 0.525 0.024 0.293 0.553 0.429 0.619 0.524 0.030 0.319 0.557 0.432 0.612 0. 0.050 0.327 0.568 0.441 0.612 0.526 0.095 0.331 0.577 0.587 0.615 0.601 tional precision: methods that improved role-play fidelity sometimes hurt argument correctness, and vice versa. Future work should explore hybrid strategies that unify lightweight prompting with retrieval-augmented finetuning, enabling agents to sustain both accuracy and believability in fantasy RPG environments. See Our final ranking in Appendix F."
        },
        {
            "title": "References",
            "content": "Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell J. Hewett, Mojan Javaheripi, Piero Kauffmann, James R. Lee, Yin Tat Lee, Yuanzhi Li, Weishung Liu, Caio C. T. Mendes, Anh Nguyen, Eric Price, Gustavo de Rosa, Olli Saarikivi, and 8 others. 2024. Phi-4 technical report. AIcrowd. 2025. Aicrowd: Open challenges and competitions. https://www.aicrowd.com/. Accessed: 2025-06-26. Victor Barres, Honghua Dong, Soham Ray, Xujie Si, and Karthik Narasimhan. 2025. t2-bench: Evaluating conversational agents in dual-control environment. Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. OReilly Media. Steven Bird, Edward Loper, Ewan Klein, and the NLTK Team. 2025. Natural Language Toolkit (NLTK). GitHub repository. Commit as of latest access; see https://github.com/nltk/nltk. Ning Chan, Siyuan Tang, Yinting Feng, Xiang Wang, Qingsheng Zhang, and Qiang Chen. 2023. Large language models are diverse role-players for summarization evaluation. arXiv preprint arXiv:2303.15078. Irene Chen, Kavi Kant, Lucia Singh, Skylar Chen, Sophia Halder, Jamie Kiros, Dhruvil Thakkar, Kevin Zhang, Niket Tandon, Yejin Chandra, and 1 others. 2024. You have thirteen hours in which to solve the labyrinth: Enhancing ai game masters with function calling. arXiv preprint arXiv:2409.06949. Michael Han Daniel Han and Unsloth team. 2023. Unsloth. deepmind. 2025. Gemini 2.5: thinking. Our newest https: gemini model with //blog.google/technology/google-deepmind/ gemini-model-thinking-updates-march-2025/. Accessed: 2025-05-18. Silin Gao, Beatriz Borges, Soyoung Oh, Deniz Bayazit, Saya Kanno, Hiromi Wakaki, Yuki Mitsufuji, and Antoine Bosselut. 2023. PeaCoK: Persona commonsense knowledge for consistent and engaging narratives. In Proceedings of the 61st Annual Meeting of Table 3: Result submission at GPU Track on Task 3. Model LLaMA3.1-8B Phi4-mini Qwen2.5-7B Qwen3-8B Method baseline baseline baseline baseline Qwen3-14B-FP8 Rag + Refine Rag Memory SFT + LoRA (Our Best) Score Task 1 Score Task 2 All 0.439 0. 0.440 0.449 0.522 0.502 0.590 0.333 0.354 0. 0.587 0.549 0.532 0.606 0.386 0.341 0.513 0. 0.535 0.517 0.598 the Association for Computational Linguistics (Volume 1: Long Papers), pages 65696591, Toronto, Canada. Association for Computational Linguistics. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, and 542 others. 2024. The llama 3 herd of models. Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Wang, Zili Wang, Steven CH Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, and 1 others. 2023. Metagpt: Meta programming for multiarXiv preprint agent collaborative framework. arXiv:2308.00352. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations. Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, and Yixin Peng. 2022. Evaluating and inducing personality in pre-trained language models. arXiv preprint arXiv:2206.07550. Taaha Kazi, Ruiliang Lyu, Sizhe Zhou, Dilek HakkaniTur, and Gokhan Tur. 2024. Large language models as user-agents for evaluating task-oriented-dialogue systems. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles. Jeehyun Lee, Seung-Moo Yang, and Won Ik Cho. 2025. AMAN: Agent for mentoring and assisting newbies in MMORPG. In Proceedings of the 31st International Conference on Computational Linguistics: Industry Track, pages 522532, Abu Dhabi, UAE. Association for Computational Linguistics. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. Camel: Communicative agents for \"mind\" exploration of large language model society. arXiv preprint arXiv:2303.17760. Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 21222132, Austin, Texas. Association for Computational Linguistics. Jekaterina Novikova, Ondˇrej Dušek, Amanda Cercas Curry, and Verena Rieser. 2017. Why we need new evaluation metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 22412252, Copenhagen, Denmark. Association for Computational Linguistics. OpenAI. 2024. Gpt-4o mini: advancing cost-efficient intelligence. Accessed: 2025-05-18. Joon Sung Park, Joseph OBrien, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael Interactive Bernstein. 2023. Generative agents: arXiv preprint simulacra of human behavior. arXiv:2304.03442. Shishir G. Patil, Huanzhi Mao, Charlie Cheng-Jie Ji, Fanjia Yan, Vishnu Suresh, Ion Stoica, and Joseph E. Gonzalez. 2025. The berkeley function calling leaderboard (bfcl): From tool use to agentic evaluation of large language models. In Forty-second International Conference on Machine Learning. Brittany Larsen. 2019. Gatekeeping remix: Fandom spaces and identity politics. Masters thesis, Illinois State University. Adon Phillips, Jochen Lang, and David Mould. 2025. Goal-oriented interactions in games using llms. IEEE Transactions on Games, 17(2):510521. Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: have dog, do you have pets too? Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 22042213. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. Xinyu Zhang, Yong Li, Zheng Chen, and Fei Tan. 2024. Personalized language modeling from personalized human feedback. arXiv preprint arXiv:2402.05133. Chen Qian, Xin Liu, Jingyao Liu, Ziyi Wen, Yufan Zhao, Yue Dang, and 1 others. 2023. Communicative agents for software development. arXiv preprint arXiv:2307.07924. Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, and 25 others. 2024. Qwen2.5 technical report. Abhijeet Rao, Yiming Xu, Dakshinamurthy Karra Chaudhary, Lucian Pistol, Yolanda Dobre, Jonathan Ho, Alistair Knott, and Craig McDonald. 2024. Collaborative quest completion with llm-driven nonarXiv preprint player characters in minecraft. arXiv:2407.03460. Alireza Salemi, Sheshera Mysore, Michael Bendersky, and Hamed Zamani. 2023. Lamp: When large language models meet personalization. arXiv preprint arXiv:2304.11406. Li Song and 1 others. 2024. Llm-driven npcs: Crossplatform dialogue system for games and social platforms. arXiv preprint arXiv:2504.13928. Sony AI. 2023. The commonsense persona-grounded dialogue challenge 2023. Competition timeline: November 3, 2023 - March 15, 2024. Sony AI. 2025. The commonsense persona-grounded dialogue challenge 2025. Competition timeline: April 9 - June 30, 2025. Yu-Min Tseng, Yu-Chao Huang, Teng-Yun Hsiao, WeiLin Chen, Chao-Wei Huang, Yu Meng, and YunNung Chen. 2024. Two tales of persona in llms: survey of role-playing and personalization. In Findings of the Association for Computational Linguistics: EMNLP 2024. Association for Computational Linguistics. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291. Weikai Xu, Chengrui Huang, Shen Gao, and Shuo Shang. 2025. Llm-based agents for tool learning: survey. Data Science and Engineering. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41 others. 2025. Qwen3 technical report. Seyed Hamed Haddadi Yang, Sina Lazar, and Chris Biemann. 2024. Mcpdial: minecraft persona-driven dialogue dataset. arXiv preprint arXiv:2410.21627."
        },
        {
            "title": "A Exploratory Data Analysis",
            "content": "Before doing some experiments, we perform data analysis on Task 1_train.json and Task 2_train.json. Age-gender of characters Figure 3: in Task 2_train.json, the diagram shown that balanced NPC characters(20 merchant and 20 guild receptionist) most NPC are women with the younger age than men. Figure 6: Merchant NPC Response Return Value Ratios in Task 1_train.json (Green = return; Red = no return) Figure 7: Barplot of frequency merchant/guild receptionist mapped with their weather on that situation. automatically evaluate the dialogue generation so we try to use some of these metrics in our local environment for task dialogue generation B.2 and task function generation we use these metrics in experiments B.1. While automatic metrics alone are not fully reliable for evaluating dialogue systems (Liu et al., 2016; Novikova et al., 2017), the organizers therefore relied on human evaluation for the final private leaderboard. B.1 Task 1 B.1.1 Function name exact match This metric checks if the predicted function name matches the reference exactly: Accname ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) i=1 1{f pred = ref }, (1) Figure 4: Date-time distribution in Task 2_train.json, most of event occur after 1 pm and there are only quest reception place event in winter season. Figure 5: Guild NPC Response Return Value Ratios in Task 1_train.json (Green = return; Red = no return)"
        },
        {
            "title": "B Evaluation Metrics",
            "content": "In CPDC2023 (Sony AI, 2023) they used WordF1, BLEU, CPDScore, USEScore and BERTScore to where pred sets of instance i. and ref denote the functions name B.1.2 Function argument exact match B.2.3 CPDCscore This metric checks if all predicted arguments exactly match the reference: Accargs = 1 (cid:88) i=1 1{Apred = Aref }, (2) Shown in public leader board it is expected that weighted between WordF1, BLEU, USEScore and BERTScore in dialogue generation task and weighted exact match function name, args in function generation task. where Apred instance i. and Aref B.1.3 BERTScore denote the argument sets of"
        },
        {
            "title": "C Prompts",
            "content": "We also measure semantic similarity of function calls with BERTScore (Zhang et al., 2019). Given tokens = (x1, . . . , xm) from prediction and = (y1, . . . , yn) from reference: s(xi, yj) = E(xi) E(yj) E(xi)E(yj) , (3) = 1 m (cid:88) i=1 max s(xi, yj), = 1 (cid:88) j= max s(yj, xi) BERTScore-F1 = 2P + . (4) (5) B.2 Task 2 In Track 2, we evaluate role-playing consistency using four metrics, including BERTScore (described in Appendix B.1.3), with the remaining metrics detailed below. B.2.1 BLEU-4 BLEU-4 is based on modified n-gram precision (for = 1, 2, 3, 4) with brevity penalty (BP): BLEU-4 = BP exp (cid:32) (cid:33) log pn , (6) 1 4 (cid:88) n=1 where pn is the modified n-gram precision and BP = 1 if > r, otherwise exp(1 r/c), with = candidate length and = reference length. B.2.2 Word-level F1 First we tokenize both pred and ref using NLTK (Bird et al., 2025, 2009) then calculate Wordlevel F1 over token sets: F1 = 2 + , (7) where = TpredTref Tpred and = TpredTref Tref . C.1 Additional Data Generation prompt for data generation in Task 1 by Gemini-2.5-pro \"\"\"You are tasked with generating highquality game dialogue between player and an NPC who has merchant role. You are provided with: 1. list of available function calls that the NPC can use to respond. 2. Structured knowledge relevant to the NPCs inventory, abilities, or item lore. Your responsibilities are: - Generate natural and contextually appropriate player dialogue that clearly expresses the players intent or question. - Select function call from the provided list that appropriately addresses the players request. - Fill in the functions parameters using only the provided knowledge base. Do not invent new values. #Provided Function(s) formatted_tools #Knowledge knowledge #Desired Output Format json \"<string>\", \"gold_functions\": [ \"name\": \"<string>\", \"parameters\": \"<parameter_name>\": \"<pa- #Example Outrameter value>\" ] put \"The price is reasonable. Though before deciding, could you tell me more about how other magic users integrate this dagger into their combat style?\", \"gold_functions\": [ \"name\": \"check_description\", \"parameters\": \"item_name\": \"Man Gauche\" ] \"\"\" \"player_dialogue\": \"player_dialogue\": prompt for data generation in Task 2 by Gpt4o-mini \"role\": \"system\", \"content\": \"You are tasked with generating natural and immersive dialogue between player character (adventurer) and non-player character (NPC) \" \"in fantasy RPG game setting, using the provided NPC persona and role.\" \"The players dialogue must show clear purpose and in-world context such as:\" \"- preparing for mission\" \"- reporting back from quest\" \"- gathering supplies for an event (e.g. before sunset)\" \"- checking for new tasks after returning to town\" \"Do NOT let the player speak in vague or generic ways. Avoid lines like: Got anything?, What do you have?, Any work? instead, have them speak based on time, place, or situation. Make their goal and urgency clear.\" \"NPC responses must:\" \"- be short and natural (23 sentences only)\" \"- ask at most ONE question\" \"- reflect their persona, role, and current knowledge\" \"- avoid formal or bookish vocabulary (e.g., commendable, evaluate, indeed)\" \"- avoid exaggerated roleplay or dramatic taglines\" \"- be grounded in the world its fine to say Im not sure, or suggest next steps\" , \"role\":\"user\", \"content\": f\"NPC Role: NPC_ROLE\" f\"NPC Persona: NPC_PERSONA\", prompt for reasoning generation in Task 2 by Gpt4o-mini \"You are non-player character (NPC) in fantasy RPG game.\" \"You will be given:\" \"- Your **Role**\" \"- Your **Persona** (your personality and worldview)\" \"- **Players Dialogue** (the message they say to you)\" \"- Your own **NPC Response** (what you said back)\" \"Your task is to **reason from your NPC point of view**:\" \"**Explain why you responded that way** what in the players message triggered your response? What logic, emotion, or instinct guided you?\" \"\" \"Do NOT include any title, heading, or explanation only your internal monologue as the NPC.\" C.2 FewShot FewShot prompt for Task 2 in API Track \"# Instruction\" \"You are acting as an NPC character in game.\" \"Respond naturally and concisely, based only on the provided knowledge.\" \"Avoid exaggerated roleplay or guessing. Its okay to say youre unsure.\" \"Speak like real person in that world short, simple, and in character.\" \"\" \"# NPC Character Profile\" #\"Play this character without over-acting. Use brief, helpful, and realistic responses.\" \"{character_setting}\" \"\" \"# Knowledge\" \"1. Function Call Knowledge (recent and specific)\" \"{function_knowledge}\" \"2. General Knowledge (background/context)\" \"{general_knowledge}\" \"\" \"# Example Dialogue\" \"Player: Im gathering information about the legendary sword. Have you heard any of the tales about it?\" \"NPC:Oh, absolutely. Every warrior dreams of it. Many have ventured into unknown territories in search of Ive heard stories of people traveling it. to all sorts of places, from the continent to the seas.\" \"Player: Everyone seems to be interested in legendary weapons. guess they must be that prestigious, huh?\" \"NPC:Yeah, thats probably true. But think its not so much about the weapon itself having honor, but more about whether the person wielding it has the skill and is worthy of it.\" FewShot prompt for Task 1 in API Track \"# Instruction\" \"You are an assistant in estimating function names and arguments given some dialogues in video game world.\" \"You will need the following information to respond to the users input. \" \"Use the following steps to estimate the necessary function names and arguments. \" \"\" \"1. Read the dialogue and the target item. \" \"2. From the given function information, select the functions that can obtain the information you need. \" \"3. Fill in the arguments needed by the function as appropriate. \" \"Note: You may select multiple functions or no functions at all. \" \"\" \"# Additional Information \" \"{}\" \"# Example Function Information\" \"{merchant_info}\" \"{guild_info}\" \"# Dialogue\" \"The user input for the current turn is as follows. \" C.3 Chain of Thought Chain of Thought prompt for Task 1 in API Track \"# Instruction\" \"You are an assistant in estimating function names and arguments given some dialogues in video game world.\" \"You will need the following information to respond to the users input and always explains your reasoning before making any function call.\" \"In each turn, first output paragraph beginning with **Reasoning:** explaining what you are trying to do, \" \"and why the function(s) you are calling are needed.\" \"Then, generate the appropriate function call(s).\" \"#Use the following steps to estimate the necessary function names and arguments.\" \"You MUST follow the structure below. If you skip any part, your answer will be considered invalid.\" \"## Step-by-step:\" \"1. Read the dialogue and the target item.\" \"2. Select the functions that can retrieve the information needed.\" \"3. Fill in the arguments based on context.\" \"4. First, generate ResponseOutputMessage explaining your decision using this format:\" \" **Reasoning:** <explanation>\" \"5. Then generate one or more ResponseFunctionToolCall objects (if needed).\" \"6. You must always include the reasoning message, even if the reasoning seems obvious.\" \"Note: You may choose to call multiple functions, or none at all, depending on the users intent.\" \"\" \"# Additional Information \" \"{}\" \"# Dialogue\" \"The user input for the current turn is as follows. \" C.4 Deflanderization Deflanderization prompt for Task 2 in API Track \"# Instruction\" \"You are acting as an NPC character in video game.\" \"Respond naturally and concisely, based only on the provided knowledge.\" \"Avoid exaggerated roleplay or guessing. Its okay to say youre unsure.\" \"Speak like real person in that world short, simple, and in character.\" \"\" \"# Character Profile\" \"Play this character without over-acting. Use brief, helpful, and realistic responses.\" \"{character_setting}\" \"\" \"# Knowledge\" \"There are two parts of knowledge. The first part is the specific knowledge obtained from the function calls. \" \"The second part is the general knowledge of all items involved in the dialogue. \" \"\" \"## Knowledge from Function Calls\" \"{function_knowledge}\" \"## General Knowledge of All Items\" \"{general_knowledge}\" \"\" \"# Worldview: It describes the setting of the world in the video game. \" \"{worldview}\" C.5 Most word Most word prompt for Task 2 in API Track \"# Instruction\" \"You are acting as an NPC character in game.\" \"Respond naturally and concisely, based only on the provided knowledge.\" \"Avoid exaggerated roleplay or guessing. Its okay to say youre unsure.\" \"Speak like real person in that world short, simple, and in character.\" \"\" \"# Character Profile\" #\"Play this character without over-acting. Use brief, helpful, and realistic responses.\" \"{character_setting}\" \"\" \"# Knowledge\" \"1. Function Call Knowledge (recent and specific)\" \"{function_knowledge}\" \"2. General Knowledge (background/context)\" \"{general_knowledge}\" \"\" \"# Response Style Guide\" \"- Limit to 12 short, natural sentences.\" \"- Use simple, in-character language.\" \"- Only use information in the knowledge.\" \"- If unsure, its okay to express doubt.\" \"- Avoid formal or bookish vocabulary (e.g., commendable, evaluate, indeed).\" \"- Avoid using dramatic or generic taglines.\" \"\" \"# Good Example Phrases You May Use\" \"- Thank you for stopping by\" \"- What would you like to know\" \"- Every warrior dreams of it\" \"- Well, sometimes find weapons on the market\" \"\" \"# Avoid These Overused Phrases\" \"- Good luck out there, Feel free to stop by anytime\" \"- You wont regret visiting, Take care out there\" \"- Stay sharp, Thats wise outlook, Better be careful out there\" \"\" \"# Guide word using in the dialogue\" thats probably true, \"- Say Yeah, Maybe, Could be, Hard to say, or guess so instead of Indeed, Certainly, Without doubt, Undoubtedly, or Affirmative.\" \"- Say Ive heard. . . , Some say. . . , People talk about it, Not sure, honestly, or Its just rumor instead of Legend has it. . . , It is believed that. . . , Sources indicate. . . , Historical records show. . . , or Tradition holds. . . .\" \"- Say dont know, Never seen it myself, Hard to say, Maybe yes, maybe no, or Couldnt tell you instead of The truth is unknown, No definitive account exists, One cannot say for certain, The mystery remains, or There is no clear answer.\" \"- Say Better be careful, Could be risky, Dont go alone, You never know whats out there, or Watch yourself instead of One must exercise caution, It is advisable to remain vigilant, Proceed with utmost care, Caution is warranted, or Act with prudence.\" \"- Say Thats impressive, Youre right, Good luck with that, Hope it works out, or Sounds good to me instead of noble endeavor, Such ambition is admirable, Truly commendable, virtuous pursuit, or praiseworthy goal.\" \"- Say Sometimes I. . . , Other times I. . . , trade when can, make them myself, or Depends on the day instead of It is customary to. . . , Generally one would. . . , As is tradition. . . , By standard practice. . . , or The typical approach is. . . .\" \"- Say Well, weapons are always evolving, Been in the game long time, Ive seen lot come and go, Stop by anytime, or Let me know if you need anything instead of Weapons evolve perpetually, Over the years, trends emerge, You may return at your convenience, or Should you require assistance. . . .\" \"- Say Youve got the right person to ask, Good to see you, Cant go wrong with solid blade, Ive been in this business while, or If you want the best, you know where to find me instead of possess the requisite knowledge, It is pleasure to encounter you again, or Optimal choices include. . . .\" \"- Say Oh, absolutely, Of course do, Sure thing, Yeah, or No doubt instead of Indisputably, With complete certainty, or It is universally acknowledged.\" \"- Say Ah, see, What would you like to know?, Welcome to the guild, Thank you for stopping by, or Anything youre looking for today? instead of Please proceed with your inquiry, Your visit is appreciated, or We welcome new registrants accordingly.\" \"\" \"1# Example Dialogue\" \"Player: Im gathering information about the legendary sword. Have you heard any of the tales about it?\" \"NPC:Oh, absolutely. Every warrior dreams of it. Many have ventured into unknown territories in search of it. Ive heard stories of people traveling to all sorts of places, from the continent to the seas.\" \"Player: Everyone seems to be interested in legendary weapons. guess they must be that prestigious, huh?\" \"NPC:Yeah, thats probably true. But think its not so much about the weapon itself having honor, but more about whether the person wielding it has the skill and is worthy of it.\" C.6 Guide Guide prompt for Task 2 in API Track \"# Instruction\" \"You are acting as an NPC character in game.\" \"Respond naturally and concisely, based only on the provided knowledge.\" \"Avoid exaggerated roleplay or guessing. Its okay to say youre unsure.\" \"Speak like real person in that world short, simple, and in character.\" \"\" \"# Character Profile\" #\"Play this character without over-acting. Use brief, helpful, and realistic responses.\" \"{character_setting}\" \"\" \"# Knowledge\" \"1. Function Call Knowledge (recent and specific)\" \"{function_knowledge}\" \"2. General Knowledge (background/context)\" \"{general_knowledge}\" \"\" \"# Response Style Guide\" \"- Limit to 12 short, natural sentences.\" \"- Use simple, in-character language.\" \"- Only use information in the knowledge.\" \"- If unsure, its okay to express doubt.\" \"\" \"1# Example Dialogue\" \"Player: Im gathering information about the legendary sword. Have you heard any of the tales about it?\" \"NPC:Oh, absolutely. Every warrior dreams of it. Many have ventured into unknown territories in search of it. Ive heard stories of people traveling to all sorts of places, from the continent to the seas.\" \"Player: Everyone seems to be interested in legendary weapons. guess they must be that prestigious, huh?\" \"NPC:Yeah, thats probably true. But think its not so much about the weapon itself having honor, but more about whether the person wielding it has the skill and is worthy of it.\""
        },
        {
            "title": "D Compute Constraints",
            "content": "GPU Track AWS g6e.2xlarge node. This node has 8 vCPUs, 64 GB RAM and L40s GPU with 48 GB VRAM. Timeout per turn is 7 seconds. API Track AWS m5.large node. This node has 2 vCPUs, 8 GB RAM. maximum of 2 API calls per utterance. Input token limit per turn : 2,000 tokens. Output token limit per turn : 200 tokens. Only Gpt-4o-mini is allowed and available on the Servers. Fine-tuned API models are not allowed. Network access is expected to be blocked for OpenAI API usage. Timeout per turn: 7s."
        },
        {
            "title": "E Additional Results",
            "content": "We fine-tuned Qwen3-8B using both supervised fine-tuning (SFT) with LoRA and GRPO-based tuning. The resulting CPDCScore on Task 3 was 0.324, while Task 1 achieved 0.290 and Task 2 achieved 0.359. E.1 Supervised Fine-Tuning (SFT) We applied SFT on Task 2 using both the original dataset and additional generated samples. The training was implemented with the Unsloth framework. The key hyperparameters are summarized below: Gradient accumulation steps: 1 Warmup steps: 5 Maximum training steps: Learning rate: 2 104 Optimizer: adamw_8bit Weight decay: 0.01 Scheduler: Linear E.2 LoRA We applied LoRA in combination with SFT on the dataset for Task 1. The main configuration was: r: 64 lora_alpha: 64 E.3 GRPO Tuning on Reasoning Data We further performed GRPO tuning using curated dataset of enchanted reasoning interactions. Each sample consists of role-play between player and an NPC (non-player character), enriched with persona-level metadata (e.g., age, gender, occupation, background, personality traits, and goals). An example instance is shown below: NPC Role: Merchant selling weapons. Player: just returned from the Hollow Vale with stash of monster claws. Im looking for something solid to upgrade my weapon. NPC: Youre in luck! just received shipment of reinforced swords. This one here has wicked edge and sturdy hilt. Do you want to equip it right away or save it for later? Reasoning: The NPC infers the players urgency and background, tailoring the response to highlight reliability and efficiency while staying faithful to the persona. The GRPO training was run with the following hyperparameters: Batch size per device: 1 Gradient accumulation steps: 1 Warmup steps: 5 Training epochs: Learning rate: 2 104 Optimizer: adamw_8bit Weight decay: 0.01 Scheduler: Linear E."
        },
        {
            "title": "Inference with vLLM and LoRA\nAdapters",
            "content": "For inference, we adopted the vLLM framework to efficiently serve both the base model and LoRAtuned checkpoints for the function generation task. We utilized the LoRAInferenceEngine, which allows dynamic loading of adapters on top of the base model. The configuration was as follows: Maximum sequence length: 4096 GPU memory utilization: 0.5 Maximum LoRA rank:"
        },
        {
            "title": "Task Rank Automatic Sum of Rank Response Rank Knowledge Rank",
            "content": "1 2 3 3rd 3rd 2nd 0.563 0.623 0.590 - 8 5 - 1 3 - 7 Table 4: our team Tu_Character_labs final result on API Track by AIcrowd Team. Task2 and Task3 also were evaluated by human while Task1 do only automatic evaluation."
        }
    ],
    "affiliations": [
        "Artificial Intelligence Association of Thailand",
        "Department of Computer Engineering and Digital Technology, Faculty of Engineering, Chulalongkorn University",
        "School of Biomedical Engineering & Imaging Sciences, Kings College London",
        "Siriraj Informatics and Data Innovation Center (SIData+), Faculty of Medicine, Siriraj Hospital, Mahidol University",
        "Thammasat School of Engineering, Thammasat University"
    ]
}