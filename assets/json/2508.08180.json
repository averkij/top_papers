{
    "paper_title": "RedDino: A foundation model for red blood cell analysis",
    "authors": [
        "Luca Zedda",
        "Andrea Loddo",
        "Cecilia Di Ruberto",
        "Carsten Marr"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Red blood cells (RBCs) are essential to human health, and their precise morphological analysis is important for diagnosing hematological disorders. Despite the promise of foundation models in medical diagnostics, comprehensive AI solutions for RBC analysis remain scarce. We present RedDino, a self-supervised foundation model designed for RBC image analysis. RedDino uses an RBC-specific adaptation of the DINOv2 self-supervised learning framework and is trained on a curated dataset of 1.25 million RBC images from diverse acquisition modalities and sources. Extensive evaluations show that RedDino outperforms existing state-of-the-art models on RBC shape classification. Through assessments including linear probing and nearest neighbor classification, we confirm its strong feature representations and generalization ability. Our main contributions are: (1) a foundation model tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations for RBC modeling, and (3) a detailed evaluation of generalization performance. RedDino addresses key challenges in computational hematology by capturing nuanced morphological features, advancing the development of reliable diagnostic tools. The source code and pretrained models for RedDino are available at https://github.com/Snarci/RedDino, and the pretrained models can be downloaded from our Hugging Face collection at https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ] . [ 1 0 8 1 8 0 . 8 0 5 2 : r REDDINO: FOUNDATION MODEL FOR RED BLOOD CELL ANALYSIS Luca Zedda , Andre Loddo , Cecilia Di Ruberto , Carsten Marr Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy {luca.zedda,andre.loddo,cecilia.dir}@unica.it Institute of AI for Health, Helmholtz Munich, Munich, Germany carsten.marr@helmholtz-muenchen.de"
        },
        {
            "title": "ABSTRACT",
            "content": "Red blood cells (RBCs) are fundamental to human health, and precise morphological analysis is critical for diagnosing hematological disorders. Despite the potential of foundation models for medical diagnostics, comprehensive AI solutions for RBC analysis remain limited. We introduce RedDino, self-supervised foundation model specifically designed for RBC image analysis. Leveraging RBC-tailored version of the DINOv2 self-supervised learning framework, RedDino is trained on an extensive, meticulously curated dataset comprising 1.25 million RBC images from diverse acquisition modalities and sources. Comprehensive evaluations demonstrate that RedDino significantly outperforms existing state-of-the-art models on the RBC shape classification task. Through systematic assessments, including linear probing and nearest neighbor classification, we validate the models robust feature representation and strong generalization capabilities. Our key contributions are (1) dedicated foundation model tailored for RBC analysis, (2) detailed ablation studies exploring DINOv2 configurations for RBC modeling, and (3) comprehensive generalization performance evaluation. We address key challenges in computational hematology by developing RedDino, robust and generalizable model that captures nuanced morphological characteristics and represents substantial advancement in developing reliable diagnostic tools. The source code and pretrained models for RedDino are available at https://github.com/Snarci/RedDino, and the pretrained models can be downloaded from our Hugging Face collection at RedDino Huggingface space. Keywords Red Blood Cell Analysis Self-Supervised Learning Foundation Models Hematology DINOv2 Medical Imaging"
        },
        {
            "title": "Introduction",
            "content": "The hematopoietic process forms the foundation of the blood cell life cycle, where stem cells, through natural aging and mutation, differentiate into various subtypes essential for sustaining bodily functions. Understanding this intricate process is key to unraveling numerous hematological phenomena and diseases [12]. In hematology, computer-aided diagnosis has emerged as tool to tackle critical diagnostic challenges [27]. Two prominent areas of focus are red blood cell and white blood cell analysis [8, 9, 11], both of which rely extensively on imaging-based assessments to derive meaningful insights into patients health. Blood smear analysis serves as the cornerstone of these investigations, involving the microscopic examination of blood smeared on glass slides. These slides are systematically stained to enhance cellular structures, with staining techniques tailored to specific diagnostic objectives. Variability in staining protocols and imaging acquisition introduces biases [35], complicating the analysis process and demanding extensive training for medical personnel. Beyond staining, the physical preparation of smears can also slightly alter cell morphology due to the pressure applied during the process. For efficient and robust analysis of white blood cells, the emergence of foundation models has significantly advanced the prediction of clinical outcomes [15]. These models demonstrate impressive capabilities while addressing critical challenges, such as the batch effect, common issue in multi-source or multi-patient scenarios [21, 36]. In contrast, red blood cell analysis has yet to fully explore the potential"
        },
        {
            "title": "Running Title for Header",
            "content": "Figure 1: The RedDino training set comprises 56712 original images. We extracted over 3 million single RBC images and more than 1.2 million patches. of such advanced technologies. This work seeks to pioneer the development of foundation models tailored for RBC analysis, addressing the nuances and requirements necessary for achieving highly representative and expressive models in this domain. Since training foundation models typically requires massive amounts of data [23], we also contributed to extracting the most complete and representative collection of red blood cell images in different acquisition scenarios. We demonstrate that, with carefully guided tailoring to state-of-the-art self-supervised learning methods, our family of foundation models achieves state-of-the-art performance across several red blood cell datasets. These models exhibit remarkable generalization capabilities, effectively mitigating the challenges posed by the batch effect. Our contributions include: dedicated family of foundation models optimized for RBC analysis, named RedDino, trained using selfsupervised learning. Rigorous comparative investigation studies to evaluate the effectiveness of DINOv2 [23] configurations in capturing RBC morphology. Extensive benchmarking against existing state-of-the-art models, demonstrating superior performance on RBC classification and shape analysis tasks."
        },
        {
            "title": "2 Methodology",
            "content": "2.1 Training Data RedDino is trained on the largest collection of publicly available RBC image datasets, spanning various imaging modalities, resolutions, and staining techniques. Leveraging the DINOv2 self-supervised framework, our dataset selection was unconstrained by label availability, significant advantage given the scarcity of annotated RBC data. We selected 18 datasets [1, 2, 3, 4, 6, 10, 16, 17, 18, 19, 20, 25, 28, 29, 32, 33, 34], comprising over 50,000 images from more than 420 individuals (Figure 1). To mitigate the natural imbalance between red and white blood cells, we also incorporated datasets containing white blood cell images [2, 19, 28]. To extract training samples, we applied two approaches. The first involved segmentation with fine-tuned version of CellPose [24, 30, 31], iteratively improved through manual corrections, producing 3,076,269 segmented cells. The second approach involved extracting nonoverlapping patches of smear images with size of 224 by 224 pixels, ensuring aspect ratio preservation and dataset diversity, generating 1,250,781 patches (Figure 1). 2.2 Testing Data To rigorously evaluate model embeddings, we used datasets with diagnostic or morphological labels as out-ofdistribution test sets. Specifically, we employed the Elsafty dataset [13], the most comprehensive resource for RBC classification, containing 240,000 images across nine classes from four sources, with image distributions of 72517, 52506, 52103, and 63381, respectively. Additional out-of-distribution test sets included the Chula dataset [22], comprising 20,875 images across 12 RBC classes, and the DSE dataset [20], which consists of 5,659 images spanning eight classes."
        },
        {
            "title": "Running Title for Header",
            "content": "Figure 2: RedDino outperforms the baseline models on the weighted F1 score in the linear probing evaluation by removing the Koleo regularizer and applying the Sinkhorn-Knopp algorithm. The evaluation uses source 1 of the Elsafty dataset as the training set and source 2 as the test set."
        },
        {
            "title": "3 Experiments and Results",
            "content": "3.1 Development strategies An extensive comparative investigation was conducted to evaluate and improve RedDinos effectiveness. Comparisons were made against baseline models, specifically DINOv2 and DinoBloom [15], the latter being the current state-of-theart feature extractor for hematological data. The experiments were divided into two main approaches: one focusing on training with individual cells and the other on patched smear images. The optimal configuration, which guided the development of all subsequent models, was selected from the best-performing setup. Since RedDino is designed to serve as state-of-the-art backbone for various tasks in RBC analysis, its development was guided by evaluating feature quality in RBC shape classification, using the Etsalfy dataset as the primary benchmark. Among the various training strategies explored, the DINOv2 framework was selected due to its strong performance on natural images and robust generalization across downstream tasks. The evaluation approach involved extracting features from the models and training linear probing to assess feature quality. Specifically, logistic regression classifier from the sklearn library was trained on data from source 1 of the Etsalfy dataset and tested on source 2. The results revealed several key findings. First, training RedDino resulted in performance decline, similar to DinoBloom, when local crops were used in the training process. Second, training on patched smear images instead of individual cells led to significant improvements in model performance. Third, integrating custom augmentation pipeline, which replaced DINOv2s pixel-level augmentations with 32-pixel-level augmentations from the Albumentations library [5], further enhanced feature quality. Two key modifications enabled the model to outperform the state-of-the-art. The first was the removal of the Koleo regularizer, which is critical in natural image scenarios to prevent feature collapse by ensuring uniform feature distribution. However, the regularizer hindered representation quality for RBC images due to the natural uniformity of RBCs in shape and color. Pathological and abnormal RBCs, which should stand out in the feature space, were overly suppressed. The second modification involved replacing the moving average centering with the Sinkhorn-Knopp centering, which improved representation quality (Figure 2). The final model configuration, identified as the best-performing approach, is the foundation for developing the full suite of RedDino models. We then proceeded to train suite of models for 2,000 iterations each, after which performance decreased over time, pattern not limited to our RedDino models but well-known phenomenon in foundation model research [26]. We finally trained our models using the same hyperparameters as the original DINOv2 while adjusting the batch size to accommodate training on two NVIDIA A100 80GB GPUs. In this setup, the RedDino small model employs feature dimension of 384 with batch size of 512 and contains 22 million parameters. The RedDino base model is configured with feature dimension of 768, batch size of 384, and 86 million parameters. Lastly, the RedDino large model features 1024-dimensional feature space, batch size of 256, and comprises 304 million parameters."
        },
        {
            "title": "Running Title for Header",
            "content": "3.2 Multiple scenario evaluation Our downstream tasks aim to evaluate the expressiveness of the features extracted from the RedDino model family while keeping the evaluation scenario as close as possible to the actual use case. We chose to focus on the classification task either because ViTs have already demonstrated impressive results in natural image segmentation and detection using adapters [7] or because state-of-the-art hematology models like CellPose [30] and RedTell [27] have achieved remarkable success. On the classification side, the heavily imbalanced nature of the data poses critical challenge. As with most medical imaging problems, many classes related to pathological findings are underrepresented. Therefore, we conduct experiments on the recognition of such critical RBC subtypes by training linear probing and K-nearest neighbors (K-NN) classifiers on the extracted features. The linear probing assesses the adaptability of our features to downstream tasks, while the K-NN evaluates the effectiveness and robustness of the features under potential batch effect. For evaluation, we employ accuracy (Acc), balanced accuracy (bAcc), and the weighted F1 measure (wF1) as metrics. Table 1: RedDino models outperform ResNet50, DINOv2, and DinoBloom by over 2.1% in linear probing evaluation and 3.0% in 1-NN and 20-NN evaluation on the Elsafty dataset using leave-one-source-out strategy, where one source is fixed for training and the others have been used for testing. Model ResNet50 [14] DinoBloom-S DinoBloom-B DinoBloom-L DINOv2 small DINOv2 base DINOv2 large RedDino small RedDino base RedDino large Improvement Avg improvement Linear probing bAcc 80.36.0 85.26.7 85.46.3 87.24.0 83.96.7 86.84.5 87.24.6 87.26.1 89.34.7 89.15.2 2.1 3.4 Acc 77.88.0 83.38.0 84.76.5 85.65.0 82.28.2 85.45.6 85.95.7 86.26.6 88.24.9 88.45.5 2.6 4.1 wF1 77.68.1 83.28.2 84.66.5 85.45.2 82.18.2 85.45.5 86.05.6 86.07.0 88.14.9 88.55.5 2.5 4.0 wF1 64.34.8 73.15.1 72.46.2 74.15.0 73.54.8 75.54.3 73.76.2 76.84.9 78.83.6 78.54.6 3.2 5.6 1-NN bAcc 65.84.7 76.73.9 75.65.4 76.74.0 75.64.3 76.24.8 73.36.5 79.83.4 81.82.7 79.74.5 5.0 6. Acc 64.24.9 73.25.1 72.26.3 74.24.8 73.54.7 75.64.2 73.96.2 76.94.8 78.63.7 78.44.6 3.1 5.6 wF1 66.24.9 76.54.2 76.16.1 77.04.5 77.24.6 79.24.8 76.47.0 80.04.5 82.62.8 81.64.7 3.4 5.9 20-NN bAcc 66.94.9 79.63.6 78.95.6 79.04.4 78.54.5 78.65.9 74.87.3 82.63.4 84.82.5 81.94.9 5.2 6.5 Acc 67.54.5 77.14.1 76.85.8 77.94.1 77.94.5 79.94.3 77.46.4 80.44.4 82.92.8 81.94.6 3.0 5.3 Elsafty evaluation is designed in cross-source fashion since the Elasfty dataset is subdivided into four sources. This cross-source approach is particularly relevant in clinical trials, where significant variability is often observed in day-to-day analyses due to differences in equipment, protocols, or sample preparation methods. Our strategy involves training shallow models on the features from fixed source and iteratively testing on the remaining three, cycling through all possible combinations. This choice ensures comprehensive evaluation of the models robustness and adaptability to such variations. The results are averaged across the experiments, and the findings are reported in Table 1. In the summary table, we present both the results and the improvements achieved by our RedDino models compared to the selected baselines. Specifically, on the one hand, the row Improvement represents the difference between the best results from our RedDino models and the best baseline result. On the other hand, the row Avg Improvement captures the difference between the average performance of our models and the average performance of the baselines. The Improvement metric provides more impactful depiction of the advancement over the state-of-the-art, while the Table 2: RedDino outperforms baseline models in linear probing evaluations, with the only exception of the bAcc on the DSE dataset, in five-fold cross-validation approach. Name ResNet50 [14] DinoBloom-S DinoBloom-B DinoBloom-L DINOv2 small DINOv2 base DINOv2 large RedDino small RedDino base RedDino large Improvement Avg improvement Linear probing Chula bAcc 70.70.6 76.01.0 74.30.5 75.00.7 73.90.7 73.60.5 74.80.8 78.51.1 78.61.0 79.00.8 3.0 3.0 Acc 76.90.4 81.40.6 78.90.4 80.20.6 81.10.4 80.10.6 81.30.2 84.40.4 83.80.5 85.00.4 3.6 4.4 wF1 76.90.4 81.40.6 79.00.4 80.00.3 81.00.4 80.10.5 81.50.7 84.30.4 83.80.5 83.90.5 2.9 4.0 Linear probing DSE bAcc 51.59.0 57.53.7 59.95.4 60.73.6 54.43.6 56.24.5 54.43.9 56.55.1 57.93.0 60.14.8 -0.6 1.8 Acc 83.20.7 84.31.1 85.41.0 86.20.9 83.60.9 84.80.5 84.90.5 84.90.8 86.00.5 86.61.0 0.4 1.2 wF1 83.20.8 84.41.2 85.31.0 86.20.8 83.60.9 84.80.5 84.70.6 84.91.0 85.90.5 86.61.0 0.4 1."
        },
        {
            "title": "Running Title for Header",
            "content": "Avg Improvement offers subtler analysis. Often, the choice of model for downstream tasks is guided by extensive and computationally expensive benchmarks designed to identify the optimal model through brute-force search approach. In contrast, the proposed indicator offers more realistic reflection of performance improvement. Our models demonstrated an improvement of over 2% in reference metrics for the linear probing and over 3% for the 1-NN and 20-NN, surpassing the current state-of-the-art methods. Chula and DSE evaluation is designed to represent heavily unbalanced scenarios. We employ 5-fold cross-validation for both datasets. For the sake of this evaluation, it is worth noting that the Chula dataset was part of the training data for the DinoBloom methods. Despite this, RedDino proves its generalization capabilities, surpassing all other models in linear probing. We do not report results for NN classification due to insufficient samples of rare classes to perform significant analysis. These strong capabilities are also evident in the DSE dataset, where RedDino outperforms all other models in almost all the selected metrics and evaluation algorithms. It is important to note that for all analyzed datasets, the Avg Improvement was always positive, showcasing the importance and relevance of our models, as they consistently outperformed other representations for RBC analysis tasks across different microscopes and sources. Additionally, the evaluations yielded key insights: training RedDino on patched smear images rather than individual cells significantly enhanced model performance. Furthermore, RedDino base proved to be strong general solution, balancing performance with efficiency by utilizing fewer parameters (86 million vs. 304 million). Figure 3: Abnormal RBC distinguished by RedDino: the highlighted regions in (a) and (c) correlate with distinct colors in the PCA visualization (b) and (d), showcasing their differentiation provided in the embedding space. Specifically, (a) contains malaria-infected RBCs, while (c) includes echinocytes. 3.3 Visualization of the RedDino Features PCA Visualization demonstrates feature relevance via two analyses of RedDino features in three-components PCA visualization (Figure 3). Panels (a)-(b) show smear patch from the MP-IDB dataset with healthy and Plasmodium falciparum-infected RBCs and the PCA visualization from which it is observable how the model distinguishes background, cells, membranes, and parasites with high responses, highlighting the latter structures. Panels (c)-(d) apply the same approach to brightfield image, revealing distinct features for echinocytes from the DSA dataset. This behavior arises from self-supervised training alone. The regions of interest are marked with black dotted boxes. UMAP Visualization reveals batch effects within the feature space. Using the Elsafty dataset (source 1), Figure 4 shows distinct clusters without subclusters, indicating no batch across individuals. Nevertheless, overlapping classes (Rounded RBCs, Ovalocytes, and Borderline Ovalocytes) remain hard to separate due to the lack of clear clinical thresholds. Clumps form distinct clusters, confirming the models ability to differentiate single cells from agglomerations."
        },
        {
            "title": "Running Title for Header",
            "content": "Figure 4: Different classes show distinct clusters in the UMAP projection of the feature embeddings from the Elsafty dataset source 1. On the left, we show the subject distribution across the UMAP space, while on the right, we show the class distribution. CO2 Emissions from Experiments. Our experiments were run on our in-house infrastructure, using the NVIDIA A100SXM4-80GB hardware; the total emissions are estimated to be 4.15 kg CO2eq."
        },
        {
            "title": "4 Conclusion",
            "content": "In this paper, we presented RedDino, cutting-edge foundation model specifically designed for red blood cell analysis. By leveraging self-supervised learning techniques, particularly custom DINOv2 architecture, our models demonstrated superior generalization across wide range of red blood cell datasets, effectively mitigating challenges such as the batch effect. The extensive range of experimentations conducted, including an extensive comparative investigation and multiple scenario evaluations, confirm that RedDino achieves state-of-the-art performance in red blood cell classification, surpassing previous baselines. The models ability to adapt to different data sources, imaging protocols, and patient populations demonstrates its robustness and potential for clinical applications. RedDino sets new standard for RBC analysis and offers strong foundation for future advancements in automated hematological diagnostics."
        },
        {
            "title": "References",
            "content": "[1] Hemocompatibility of - hemocompatibility-of-nanocrystalline-diamond-layers,202109101719035242391-0 Bridge of nanocrystalline Knowledge, diamond Data https://mostwiedzy.pl/en/open-research-data/ Research layers Open - [2] MIMM_sbilab, https://www.cancerimagingarchive.net/collection/mimm_sbilab/ [3] SN-AM, https://www.cancerimagingarchive.net/collection/sn-am/ [4] Arshad, Q.A., Ali, M., Hassan, S.u., Chen, C., Imran, A., Rasul, G., Sultani, W.: Dataset and Benchmark for Malaria Life-Cycle Classification in Thin Blood Smear Images (Feb 2021) [5] Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov, A., Druzhinin, M., Kalinin, A.A.: Albumentations: fast and flexible image augmentations. Information 11(2), 125 (2020) [6] Chen, H., Liu, J., Hua, C., Feng, J., Pang, B., Cao, D., Li, C.: Accurate classification of white blood cells by coupling pre-trained ResNet and DenseNet with SCAM mechanism. BMC Bioinformatics 23 (Jul 2022) [7] Chen, Z., Duan, Y., Wang, W., He, J., Lu, T., Dai, J., Qiao, Y.: Vision transformer adapter for dense predictions. In: The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 (2023) [8] Chossegros, M., Delhommeau, F., Stockholm, D., Tannier, X.: Improving the generalizability of white blood cell classification with few-shot domain adaptation. Journal of Pathology Informatics p. 100405 (2024)"
        },
        {
            "title": "Running Title for Header",
            "content": "[9] Cuevas, E., Diaz, M., Manzanares, M., Zaldivar, D., Perez-Cisneros, M.: An Improved Computer Vision Method for White Blood Cells Detection. Computational and Mathematical Methods in Medicine 2013(1), 137392 (2013) [10] Delgado-Ortet, M., Molina, A., Alférez, S., Rodellar, J., Merino, A.: Dataset B: 331 digital images of MGG-stained blood smears from five malaria-infected patients (May 2020), https://data.mendeley.com/datasets/ 2v6h4j48cx/1 [11] Deshpande, N.M., Gite, S., Aluvalu, R.: review of microscopic analysis of blood cells for disease detection with AI perspective https://peerj.com/articles/cs-460 [12] Doulatov, S., Notta, F., Laurenti, E., Dick, J.E.: Hematopoiesis: Human Perspective. Cell Stem Cell 10(2), 120136 (Feb 2012) [13] Elsafty, A., Soliman, A., Ahmed, Y.: 1 Million Segmented Red Blood Cells With 240 Classified in 9 Shapes and 47 Patches of 25 Manual Blood Smears. Scientific Data 11(1), 722 (Jul 2024) [14] He, K., Zhang, X., Ren, S., Sun, J.: Deep Residual Learning for Image Recognition. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 770778. IEEE, Las Vegas, NV, USA (Jun 2016) [15] Koch, V., Wagner, S.J., Kazeminia, S., Sancar, E., Hehr, M., Schnabel, J.A., Peng, T., Marr, C.: Dinobloom: foundation model for generalizable cell embeddings in hematology. In: Medical Image Computing and Computer Assisted Intervention - MICCAI 2024 - 27th International Conference, Marrakesh, Morocco, October 6-10, 2024, Proceedings, Part XII. Lecture Notes in Computer Science, vol. 15012, pp. 520530. Springer (2024) [16] Kouzehkanan, Z.M., Saghari, S., Tavakoli, S., Rostami, P., Abaszadeh, M., Mirzadeh, F., Satlsar, E.S., Gheidishahran, M., Gorgi, F., Mohammadi, S., Hosseini, R.: large dataset of white blood cells containing cell locations and types, along with segmented nuclei and cytoplasm. Scientific Reports 12(1), 1123 (Jan 2022) [17] Labati, R.D., Piuri, V., Scotti, F.: All-IDB: The acute lymphoblastic leukemia image database for image processing. In: 2011 18th IEEE International Conference on Image Processing. pp. 20452048 (Sep 2011) [18] Loddo, A., Di Ruberto, C., Kocher, M., ProdHom, G.: MP-IDB: The Malaria Parasite Image Database for Image Processing and Analysis. In: Lepore, N., Brieva, J., Romero, E., Racoceanu, D., Joskowicz, L. (eds.) Processing and Analysis of Biomedical Information. pp. 5765. Springer Int. Pub. (2019) [19] Madhloom, H.T., Kareem, S.A., Ariffin, H.: Computer-aided acute leukemia blast cells segmentation in peripheral blood images. Journal of Vibroengineering 17(8) (Dec 2015) [20] Makhro, A., Hegemann, I., Goede, J.S., Wijk, R.v., Mañú-Pereira, M., Sadafi, A., Marr, C., Kaestner, L., Bogdanova, A.: Red Blood Cell RedTell Dataset (Apr 2023) [21] Moor, M., Banerjee, O., Abad, Z.S.H., Krumholz, H.M., Leskovec, J., Topol, E.J., Rajpurkar, P.: Foundation models for generalist medical artificial intelligence. Nature 616(7956), 259265 (Apr 2023) [22] Naruenatthanaset, K., Chalidabhongse, T.H., Palasuwan, D., Anantrasirichai, N., Palasuwan, A.: Red Blood Cell Segmentation with Overlapping Cell Separation and Classification on Imbalanced Dataset (Mar 2023) [23] Oquab, M., Darcet, T., Moutakanni, T., Vo, H., Szafraniec, M., Khalidov, V., Fernandez, P., Haziza, D., Massa, F., El-Nouby, A., Assran, M., Ballas, N., Galuba, W., Howes, R., Huang, P.Y., Li, S.W., Misra, I., Rabbat, M., Sharma, V., Synnaeve, G., Xu, H., Jegou, H., Mairal, J., Labatut, P., Joulin, A., Bojanowski, P.: DINOv2: Learning Robust Visual Features without Supervision (Apr 2023) [24] Pachitariu, M., Stringer, C.: Cellpose 2.0: how to train your own model. Nature Methods 19(12), 16341641 (Dec 2022) [25] Rezatofighi, S.H., Soltanian-Zadeh, H.: Automatic recognition of five types of white blood cells in peripheral blood. Computerized Medical Imaging and Graphics 35(4), 333343 (Jun 2011) [26] Roth, B., Koch, V., Wagner, S.J., Schnabel, J.A., Marr, C., Peng, T.: Low-resource finetuning of foundation models beats state-of-the-art in histopathology (Jan 2024) [27] Sadafi, A., Bordukova, M., Makhro, A., Navab, N., Bogdanova, A., Marr, C.: Redtell: an ai tool for interpretable analysis of red blood cell morphology. Frontiers in Physiology 14, 1058720 (2023) [28] shenggan: Shenggan/BCCD_dataset (Jan 2025), https://github.com/Shenggan/BCCD_Dataset [29] Sidhom, J.W., Siddarthan, I.J., Lai, B.S., Luo, A., Hambley, B.C., Bynum, J., Duffield, A.S., Streiff, M.B., Moliterno, A.R., Imus, P., Gocke, C.B., Gondek, L.P., DeZern, A.E., Baras, A.S., Kickler, T., Levis, M.J., Shenderov, E.: Deep learning for diagnosis of acute promyelocytic leukemia via recognition of genomically imprinted morphologic features. npj Precision Oncology 5(1), 18 (May 2021)"
        },
        {
            "title": "Running Title for Header",
            "content": "[30] Stringer, C., Pachitariu, M.: Cellpose3: one-click image restoration for improved cellular segmentation (Feb 2024). https://doi.org/10.1101/2024.02.10.579780, https://www.biorxiv.org/content/10.1101/2024. 02.10.579780v1 [31] Stringer, C., Wang, T., Michaelos, M., Pachitariu, M.: Cellpose: generalist algorithm for cellular segmentation. Nature Methods 18(1), 100106 (Jan 2021) [32] Sultani, W., Nawaz, W., Javed, S., Danish, M.S., Saadia, A., Ali, M.: Towards Low-Cost and Efficient Malaria Detection (Apr 2022) [33] Tyas, D.A., Ratnaningsih, T., Harjoko, A., Hartati, S.: ThalassemiaPBS (Jan 2022), https://data.mendeley. com/datasets/gd9ysj73jd/1 [34] Vogelbacher, M., Strehmann, F., Bellafkir, H., Mühling, M., Korfhage, N., Schneider, D., Rösner, S., Schabo, D.G., Farwig, N., Freisleben, B.: Identifying and Counting Avian Blood Cells in Whole Slide Images via Deep Learning. Birds 5(1), 4866 (Jan 2024) [35] Zedda, L., Loddo, A., Di Ruberto, C.: deep architecture based on attention mechanisms for effective end-to-end detection of early and mature malaria parasites in realistic scenario. Computers in Biology and Medicine 186, 109704 (Mar 2025) [36] Zhang, S., Metaxas, D.: On the challenges and perspectives of foundation models for medical image analysis. Medical Image Analysis 91, 102996 (Jan 2024)"
        }
    ],
    "affiliations": [
        "Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy",
        "Institute of AI for Health, Helmholtz Munich, Munich, Germany"
    ]
}