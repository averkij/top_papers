{
    "paper_title": "Hyperbolic Safety-Aware Vision-Language Models",
    "authors": [
        "Tobia Poppi",
        "Tejaswi Kasarla",
        "Pascal Mettes",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Addressing the retrieval of unsafe content from vision-language models such as CLIP is an important step towards real-world integration. Current efforts have relied on unlearning techniques that try to erase the model's knowledge of unsafe concepts. While effective in reducing unwanted outputs, unlearning limits the model's capacity to discern between safe and unsafe content. In this work, we introduce a novel approach that shifts from unlearning to an awareness paradigm by leveraging the inherent hierarchical properties of the hyperbolic space. We propose to encode safe and unsafe content as an entailment hierarchy, where both are placed in different regions of hyperbolic space. Our HySAC, Hyperbolic Safety-Aware CLIP, employs entailment loss functions to model the hierarchical and asymmetrical relations between safe and unsafe image-text pairs. This modelling, ineffective in standard vision-language models due to their reliance on Euclidean embeddings, endows the model with awareness of unsafe content, enabling it to serve as both a multimodal unsafe classifier and a flexible content retriever, with the option to dynamically redirect unsafe queries toward safer alternatives or retain the original output. Extensive experiments show that our approach not only enhances safety recognition but also establishes a more adaptable and interpretable framework for content moderation in vision-language models. Our source code is available at https://github.com/aimagelab/HySAC."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 1 ] . [ 1 7 2 1 2 1 . 3 0 5 2 : r Hyperbolic Safety-Aware Vision-Language Models Tobia Poppi1,2 Tejaswi Kasarla3 Pascal Mettes3 Lorenzo Baraldi1 Rita Cucchiara1,4 1University of Modena and Reggio Emilia, Italy 3 University of Amsterdam, Netherlands 2 University of Pisa, Italy 4IIT-CNR, Italy 1{name.surname}@unimore.it 2 {name.surname}@phd.unipi.it 3 {initial.surname}@uva.nl"
        },
        {
            "title": "Abstract",
            "content": "Addressing the retrieval of unsafe content from visionlanguage models such as CLIP is an important step towards real-world integration. Current efforts have relied on unlearning techniques that try to erase the models knowledge of unsafe concepts. While effective in reducing unwanted outputs, unlearning limits the models capacity to discern between safe and unsafe content. In this work, we introduce novel approach that shifts from unlearning to an awareness paradigm by leveraging the inherent hierarchical properties of the hyperbolic space. We propose to encode safe and unsafe content as an entailment hierarchy, where both are placed in different regions of hyperbolic space. Our HySAC, Hyperbolic Safety-Aware CLIP, employs entailment loss functions to model the hierarchical and asymmetrical relations between safe and unsafe image-text pairs. This modelling ineffective in standard vision-language models due to their reliance on Euclidean embeddings endows the model with awareness of unsafe content, enabling it to serve as both multimodal unsafe classifier and flexible content retriever, with the option to dynamically redirect unsafe queries toward safer alternatives or retain the original output. Extensive experiments show that our approach not only enhances safety recognition but also establishes more adaptable and interpretable framework for content moderation in vision-language models. Our source code is available at: https://github.com/aimagelab/HySAC Warning: This paper features explicit sexual content and other material that some readers may find disturbing, distressing, or offensive. 1. Introduction Large-scale vision-language models (VLMs) have achieved remarkable successes in various applications, including cross-model retrieval [69], text-to-image and image-to-text generation [51, 71] and various downstream tasks [56, 79, *Equal contribution 87]. Popular VLMs like CLIP [69] and ALIGN [40] leverage vast amounts of web-scraped image-text data to learn rich multimodal representations by aligning visual and textual modalities. However, most large-scale datasets sourced from the web contain unsafe or inappropriate content, such as violence, nudity, or hate speech [5, 6]. The presence of such content not only raises ethical concerns but also introduces risks for real-world applications [7, 35, 88], where exposure to or misuse of this material can lead to legal and societal repercussions. Birhane et al. [7] also show that the increasing dataset scale can exacerbate hateful and unsafe content, as identified in the now removed LAION5B [77, 82]. Addressing the issue of unsafe content in VLMs is therefore of utmost importance to ensure responsible AI practices. Recent efforts to mitigate unsafe content in visionlanguage models have led to the development of methods specifically designed for NSFW (Not Safe For Work) content removal. Most of these works [27, 66] have focused on unlearning (i.e., removing) the knowledge of unsafe content from the models. As recent example, Poppi et al. [66] develop fine-tuned version of CLIP which unlearns toxic concepts by redirecting their embeddings towards safe regions, so that retrieval always produces safe content even when the model is prompted with unsafe inputs. In contrast, we propose an approach for managing unsafe content in VLMs: emphasizing awareness over unlearning. Rather than hiding the flaws of VLMs by ignoring NSFW content, we aim to equip the VLMs with the ability to distinguish between safe and unsafe content. This in turn helps users of the model to expose or redirect NSFW content when necessary, crucial step toward improving user agency, understanding, and interpretability [22]. Inspired by recent hyperbolic vision-language models [20, 63], we introduce hyperbolic framework that leverages the geometric properties of hyperbolic space to separate safe and unsafe content effectively. Using paired dataset of safe and unsafe image-text inputs [66], we adjust the embeddings to create an entailment-based [28] structure. In this setup, safe concepts are positioned closer to the origin of the hyperbolic space, while unsafe concepts are mapped further away. Specifically, we introduce hyperbolic safe-to-unsafe entailment mechanism that ensures safe content encompasses unsafe representations within conical regions, defining clear safety boundaries and safety traversals to dynamically adjust query embeddings along the hyperbolic space to promote safe retrievals or, alternatively, expose relevant unsafe content when necessary. This framework not only organizes data into safe and unsafe radiusbased regions but also enables controlled movement within the space, allowing retrievals to favor safety as required. Experiments demonstrate that HySAC achieves clear improvements in safety awareness, retrieval performance, and NSFW content handling across multiple datasets, with robustness in both safe content redirection and controlled unsafe content accessibility. 2. Related Work Unlearning in vision-language models. Unlearning concepts and content has recently received lot of attention, empowered by the success of vision-language models. Various approaches have been explored, such as full model retraining, fine-tuning, machine unlearning [9, 32, 33, 67, 68], and differential privacy [34]. Some of these efforts have focused on text-to-image models, with the goal of removing specific styles, concepts, or objects [45, 90]. particular emphasis has been placed on removing NSFW content, which encompasses inappropriate, unsafe, or illegal material. Schramowsky et al. [75] steer the generation away from NSFW areas, defined by fixed set of concepts. The embedding of NSFW concepts is applied as negative guidance during the text-conditioning phase, acting as safety guidance. Gandikota et al. [27] erase visual concepts using only their name, with negative guidance serving as teacher. Poppi et al. [66] focus on removing NSFW concepts from CLIP-like models by fine-tuning the entire model using ViSU, multimodal dataset containing Safe/NSFW Image/Texts quadruplets. Unlike earlier approaches, which target specific components, their method fine-tunes the entire vision-and-language model, making content removal applicable to downstream tasks. We introduce method for handling NSFW concepts in CLIP-like models by fine-tuning them in hyperbolic space. We exploit the hierarchical properties of hyperbolic geometry, yielding clear advantage: the model becomes explicitly aware of whether content is safe or NSFW, rather than merely removing knowledge of unsafe content. Similarly to our approach, safe generation works [8, 75], underscore that deeper understanding of (un-)safety can improve the control of harmful content generation. NSFW concept detection. related area of research is the automatic detection of NSFW content. Several methods have been proposed for detecting NSFW and toxic language [10, 36, 55], primarily in social media contexts. DistilBERT [73] has emerged as promising model for this task, especially when fine-tuned for identifying adult content. Detecting inappropriate language presents significant challenge, and this complexity extends to visual content, where various techniques have been developed to detect NSFW imagery [5, 26, 60]. In this domain, models like NudeNet [4] specialize in detecting nudity, while Q16 [74] serves as broader classifier, capable of identifying wider range of NSFW content. However, identifying inappropriate visual content remains complex task, given the challenges posed by subtle visual cues, lack of contextual information, and limited data availability. While these detection methods focus solely on identifying unsafe content, they do not address the problem of retrieving relevant, safe alternatives when an unsafe input is detected. Our method makes it possible to jointly detect NSFW content and provide mechanism to shift NSFW queries towards safe but relevant alternatives. Hyperbolic learning. key advantage of hyperbolic space is its inherent ability to represent hierarchical or treelike structures with minimal distortion [11, 61, 62, 72]. comprehensive list of recent advancements is documented in surveys by Mettes et al. [57] and Peng et al. [64]. Foundational works for building neural networks in hyperbolic space [3, 28, 29, 42, 80] led to the use of hyperbolic models across multiple modalities such as images [2, 23, 25, 30, 53, 84], text [21, 47, 83, 91], graphs [12, 16, 17, 52] and recommender systems [59, 86]. Recent work has shown the strong potential of hyperbolic learning for vision-language models [20, 39, 63] and demonstrated that training with loss function enforcing entailment cones [28] leads to the emergence of hierarchical structures between the embeddings. While Desai et al. [20] enforce entailment structure across modalities, Pal et al. [63] also explicitly enforce structure within modalities by leveraging object-level compositions and nouns from text. We take inspiration from these approaches and enforce entailment relations across safe and unsafe embeddings, creating an interpretable space for traversing from unsafe regions to safe regions in CLIP models. 3. Preliminaries Throughout this work, we operate in hyperbolic space, Riemannian manifold with constant negative curvature. Following Desai et al. [20], we use the Lorentz model, as it is better equipped to deal with numerical instabilities associated with the Poincare distance metric [50, 62]. The Lorentz model Ln is an n-dimensional manifold in which points are represented on the upper sheet of two-sheeted hyperboloid in (n+1)-dimensional Minkowski spacetime. Following terminology from general relativity, Figure 1. Overview of our approach. HySAC builds hyperbolic embedding that manages content safety through an entailment hierarchy. Unsafe text and images are projected to dedicated regions of hyperbolic space, allowing for safety-aware retrieval and classification. for each vector Rn+1, we refer to the first dimension, the axis of symmetry, as the time-axis, denoted by p0, and the remaining n-dimensions as the spatial components, denoted p. The Lorentz model, Ln = (Ln, gκ p) is given as (cid:26) Ln := Rn+1 : p, pL = 1 κ , p0 = (cid:113) 1/κ + p2, κ > (cid:27) , (1) where κ denotes the curvature with the Riemannian metric gκ = diag(1, 1, . . . , 1). The Lorentzian inner product ., .L is induced by the metric tensor gκ and is defined for p, Ln as p, qL = p0q0 + p, q, (2) where ., . is the Euclidean inner product. The Lorentzian inner product induces norm on the Lorentzian space which can be written as pL = (cid:112)p, pL. We now define the common hyperbolic operations in Lorentz space. Definition 3.1 (Lorentzian distance). The Lorentzian distance between two points in Ln is the length of their shortest path (geodesic) connecting them, computed as dL(p, q) = (cid:112)1/κ cosh1(κp, qL). (3) In our work, we use the negative of Lorentzian distance to calculate similarities between multimodal inputs [20, 63]. Definition 3.2 (Exponential map). Since Lorentz space is Riemannian manifold, it is locally Euclidean. This is best described through the tangent space TpLn, first-order approximation of the Lorentzian manifold at given point Ln. The exponential map then provides means to project elements from the tangent space onto the hyperboloid. Given point TpLn, the exponential map is defined as expκ : TpLn Ln with the expression κ vL) expκ p(v) = cosh( κ vL)p + sinh( v. (4) κ vL In practice, the reference point is set to the origin 0 = ((cid:112)1/κ, 0, ..., 0)T on the hyperboloid, allowing expκ 0 to project Euclidean vectors from the tangent space at 0 directly onto the hyperboloid [20, 42]. In this work, the exponential map is used to project the outputs of the visual and textual encoders to shared hyperbolic space. 4. HySAC: Hyperbolic Safety-Aware CLIP 4.1. Problem formulation and objective Problem setup. Given dataset = {(Ii, Ti)}N i=1 of image-text pairs, vision-language models (e.g. CLIP [69]) align the visual and textual embeddings obtained from image and text encoders in shared embedding space. Largescale datasets employed for training such embedding spaces are often web-scraped and contain unsafe samples [5]. For our problem setup, in order to differentiate between safe and unsafe content, we denote safe image-text pairs in as (Ii, Ti) and unsafe image-text pairs as (I , ). , )}K To make vision-language models aware of inappropriate contents, and enable them to avoid or redirect the representation of such content, we also require dataset of quadruplets of safe and unsafe image-text pairs, denoted as = {(Ik, Tk, k=1 [66]. This dataset is generated following the definition of NSFW content of Schramowski et al. [75] containing the following twenty categories: hate, harassment, violence, suffering, humiliation, harm, suicide, sexual, nudity, bodily fluids, blood, obscene gestures, illegal activity, drug use, theft, vandalism, weapons, abuse, brutality, and cruelty. The dataset is constructed such that the unsafe image-text pairs (I ) are specific cases or modified versions of the safe representations (Ik, Tk). Modelling relations in the hyperbolic space. We first consider the relationship between text and image modalities in the embedding space. Like other hyperbolic visionk , language models [20, 63], we consider text as general version of images to reflect the natural structure of partial order embeddings [85]. This is enforced in the embedding space by placing text embeddings closer to the origin and image embeddings farther away, defining modality entailment relationship formally expressed as gT (Tk) gI (Ik), and gT (T ) gI (I ), (5) where gI and gT denote the projections of images and text in the hyperbolic model and indicates that one embedding is closer to the origin than another. Differently from other models, we also impose relationship between unsafe and safe pairs, by considering unsafe image-text pairs as specific cases of their safe counterparts within D. Hence, we establish safety entailment to segregate safe from unsafe content, as follows gI (Ik) gT (T ). (6) By satisfying these inequalities, gI and gT capture both the modal and safety hierarchies within the data, thereby endowing the embedding space with safety-aware properties. To sum up, our objective is to model hyperbolic visionlanguage model with the following inequality chain: gT (Tk) gI (Ik) gT (T ) gI (I ). (7) Below we outline our method to create safety-aware visionlanguage models in hyperbolic space. 4.2. Hyperbolic safety learning To optimize Eq. 7 for safety-aware vision-language models, we propose Hyperbolic Safety-Aware CLIP to rearrange the embedding space to separate safe and unsafe regions. Our optimization consists of two components: (1) hyperbolic safety contrastive component to align image-text pairs over mini-batch and (2) hyperbolic safety entailment to align safe and unsafe content. An overview is given in Figure 1. Hyperbolic safety contrastive learning. CLIP [69] and Safe-CLIP [66] rely on contrastive objectives to align and distribute the multimodal data. We utilize hyperbolic embeddings to align the visual and textual data. Specifically, we project the visual and textual embeddings from pre-trained vision-language model onto hyperboloid [20] through an exponential map (Eq. 4). Let fI (.) and fT (.) represent any Euclidean encoders for image and text. Then, gI (Ik) = expκ 0(αtxt fT (Tk)) represent the hyperbolic representations of safe image-text pair, (Ik, Tk). Similarly, gI (I 0(αimg fI (I )) represent the hyperbolic representations of an unsafe image-text pair (I , ). αimg and αtxt are learnable projection scalars. To align representations in hyperbolic space, the similarity for the image-text and text-image contrastive loss is 0(αimg fI (Ik)) and gT (Tk) = expκ )) and gT (T 0(αtxt fT (T ) = expκ ) = expκ based on negative Lorentzian distance (Eq. 3) between gI (.) and gT (.). We compute the hyperbolic safety contrastive loss over safe image-text pairs (Ik, Tk) in batch as , (cid:80)B iB log cont(I, ) = (cid:80) exp(dL(gI (Ii),gT (Ti))/τ ) k=1,k=i exp(dL(gI (Ii),gT (Tk))/τ ) (8) where τ denotes temperature hyperparameter. similar contrastive loss is employed to preserve the multimodal structure between unsafe image-text pairs (I ). Two additional contrastive losses between cross-safety modalities ensure the alignment of quadruplets in the embedding space. The final contrastive loss is formulated as , LhSC(I, T, , ) = +L cont(I, ) + cont(I, ) + cont(I , ) cont(I , ). (9) Hyperbolic safety entailment learning. Hyperbolic entailment cones, introduced by Ganea et al. [28], generalize partial ordered embeddings [85] to any Riemannian manifold. Entailment cones induce partial order between concepts in dataset such that for any pair (p, q) , if is subconcept of q, then entails within conical region Sq defined by q. For the Lorentz model, Ln, the half-aperture of each conical region Sq is defined as [20, 47] ω(q) = sin1 (cid:18) 2K κ (cid:19) , (10) where κ is the curvature of space, and the constant = 0.1 limits values near the origin [28]. To preserve partial order between image-text relationships, we add entailment from safe text to safe image and from unsafe text to unsafe images, effectively implementing Eq. 5. Specifically, safe image Ik must lie within the cone defined by its corresponding safe text, Tk, characterized by the halfaperture ω(Tk). Similarly, an unsafe image must lie within the cone defined by its corresponding unsafe text . This is enforced through an entailment loss formulated for image-text representations by Le et al. [47] and Desai et al. [20], as ent(I, ) = max(0, ϕ(Ik, Tk) ηω(Tk)) and ent(I , ) = max(0, ϕ(I )), ) ηω(T , (11) where ϕ is the exterior angle (between lines IkTk and 0Tk or between lines ) given by and 0T Ik0 + Tk0κIk, TkL (cid:13) (cid:13) (cid:13) (cid:112)(κIk, TkL)2 1 (cid:13) (cid:13) (cid:13)(cid:102)Tk . (12) ϕ(Ik, Tk) = cos1 Here, η is threshold for the half-aperture, ω(Tk) [63]. ent penalizes images Ik Intuitively, the entailment loss that lie outside the cone STk defined by their corresponding text caption Tk. Finally, to model the safety hierarchy, we enforce that safe concepts entail unsafe ones, reflecting that safe data are more general and unsafe data are more specific. Specifically, we enforce that safe image Ik entails an unsafe text must lie within the cone defined by the safe image Ik, characterized by the half-aperture ω(Ik). This gives us the safety-entailment defined in Eq. 6. This is implemented as ent(T , I) = max(0, ϕ(T , meaning that the unsafe text , Ik) ηω(Ik)). (13) The overall entailment loss to satisfy Eq. 7 is defined as LhSE(I, T, , ) = ent(I, ) + ent(T , I) + ent(I , ). (14) Combined loss function. We integrate the contrastive with the entailment losses to obtain the total loss used to finetune the model on the dataset D: L(I, T, , ) = LhSC(I, T, , ) + LhSE(I, T, , ). (15) Our proposal allows the model to differentiate between safe and unsafe embeddings based on their distance from the origin. Safe content is closer to the center, while NSFW content is farther away. This geometric arrangement not only enables the model to detect unsafe content but also allows dynamic manipulation of embeddings. NSFW queries can be redirected toward the safe region, effectively retrieving outputs that prioritize safety and providing more precise control over content retrieval. 4.3. Safety traversals and evaluation The hyperbolic safety-aware training results in restructuring of the shared embedding space of the vision-language model. To obtain safe but relevant retrieval outputs from unsafe queries or vice-versa, we introduce traversal mechanism to adjust query embeddings in hyperbolic space, enhancing their similarity with either safe or unsafe content, depending on the retrieval task. This traversal involves moving the query embeddings along the line connecting them to the origin of the hyperboloid, altering their hyperbolic distance from the root. By adjusting the embeddings positions, we align them with regions in the embedding space that correspond to the desired content type. Traversal Definition. Given an embedding q, our method computes the distance from predefined root feature in hyperbolic space using the Lorentzian distance function dL(q, r). For each type of content {T, I, , }, we compute the mean distance µX from the root feature based on the distribution of each category. The boundary for each type is then defined as τX = µX + tanh (cid:19) (cid:18) µX α κ + 1, (16) where κ is the negative curvature, and α is constant set empirically to 0.8. This shift accounts for the curvature of space, ensuring the boundaries are appropriately adjusted for effective traversal. Defining four bounds allows more nuanced control over traversal depending on the retrieval task. To retrieve content type X, the query is moved along the Euclidean direction vector vdir = toward the root feature until it reaches the corresponding boundary τX (e.g. τT for safe text). The target position is given as = + τX vdir vdir (17) allowing the embeddings to be repositioned to match the target content type while maintaining semantic alignment. 5. Experiments 5.1. Training Details Datasets. Our experiments are mainly conducted on the ViSU dataset [66], containing 165k quadruplets of safe and unsafe image-text pairs. We also evaluate our model on three real-world NSFW image datasets: NudeNet [4], NSFW data source URLs1 and SMID [18]. Baselines. Our safety comparisons include the original CLIP [69] and the state-of-the-art Safe-CLIP [66]. CLIP was trained using private dataset of 400M image-text pairs [77] which has unsafe data [5]. Safe-CLIP is finetuned on the ViSU dataset [66] to redirect unsafe content to safe correspondent one via contrastive losses and cosine similarities, aiming to unlearn NSFW concepts. Models. Our visual and textual encoders are the same as CLIP [69], with VIT-L/14 as visual encoder, to maintain fair comparison to Safe-CLIP [66]. During training, both the visual and textual encoder are fine-tuned using low-rank decomposition [38] with low-rank factor = 16. Optimization. We use AdamW [54] with weight decay 0.2 and (β1, β2) = (0.9, 0.98). We disable weight decay for all gains, biases, and learnable scalars. The model is finetuned for 20 epochs with batch size 256. The maximum learning rate is 8 104. We use mixed precision [58] to accelerate training, except computing exponential map and losses for HySAC in FP32 precision for numerical stability. Initialization. We initialize image and text encoders akin to CLIP, along with pre-trained weights. We initialize the softmax temperature as τ = 0.07 and clamp it to minimum value of 0.01. For HySAC, we initialize the learnable projection scalars αimg = αtxt = 1/ 512, the curvature parameter = 1.0 and clamp it in [0.1, 10.0] to prevent training instability. All scalars are learned in logarithmic space as log(1/τ ), log(c), log(αimg) and log(αtxt). Further details on the training setup are provided in the supplementary B. 1https://github.com/EBazarov/nsfw data source urls Text-to-Image (T -to-I) Image-to-Text (I-to-T ) Text-to-Image (T -to-I ) Image-to-Text (I -to-T ) Model R@1 R@10 R@20 R@1 R@10 R@20 R@1 R@10 R@ R@1 R@10 R@20 CLIP [69] MERU [20] HyCoCLIP [63] Safe-CLIP [66] MERU HyCoCLIP HySAC 36.8 14.9 34.3 45.9 50.0 47. 49.8 71.6 43.0 71.2 81.8 84.1 81.9 84.1 81.5 54.2 80.6 89.7 91.1 89. 90.7 39.8 14.7 34.4 45.3 51.2 46.7 48.2 74.2 42.3 71.3 82.3 85.3 82. 84.2 83.5 53.8 82.2 89.8 92.3 90.4 91.2 2.0 2.2 2.8 8.0 2.3 1. 30.5 24.8 15.2 25.3 46.9 39.9 32.7 62.8 33.2 21.5 33.2 58.0 49.4 42. 71.8 4.6 4.4 8.2 19.1 5.7 6.9 42.1 32.9 22.6 37.8 62.9 47.9 45. 73.3 40.6 29.4 45.7 71.1 54.7 53.6 79.8 Table 1. Safe content retrieval performance on ViSU test set. Across all tasks and recall rates, HySAC improves over existing safety unlearning CLIP and hyperbolic CLIP models, highlighting that our approach is able to navigate unsafe image or text inputs towards relevant but safe retrieval outputs. CLIP fine-tuned in hyperbolic space on ViSU training set with MERU/HyCoCLIP losses. Text-to-Image (T -to-I ) Image-to-Text (I -to-T ) Text-to-Image (T -to-I I) Image-to-Text (I -to-T ) Model R@1 R@10 R@ R@1 R@10 R@20 R@1 R@10 R@20 R@1 R@10 R@ CLIP [69] MERU [20] HyCoCLIP [63] Safe-CLIP [66] HySAC 73.1 29.4 69.5 58.0 81.4 94.9 62.4 93.1 86.2 98. 97.6 72.2 95.8 91.4 99.4 72.8 25.8 65.0 56.0 82.2 95.2 57.7 91.1 85.1 97. 97.7 67.8 95.0 91.0 99.2 68.4 23.5 63.7 47.7 81.1 92.3 54.0 89.7 80.0 98. 95.9 64.3 93.7 85.8 99.4 67.1 19.5 55.2 32.1 80.5 93.3 51.1 88.0 77.1 97. 96.7 61.2 92.7 84.6 98.9 Table 2. Unsafe content retrieval performance on ViSU test set. Akin to safe content retrieval, our approach performs best. This is result of our objective, as we assign different content to different regions, enabling us to maintain valuable safety information. 5.2. Experimental Results To assess the performance of our proposed model, HySAC, we measure its safety awareness and its ability to handle unsafe content effectively, while retaining both safe and unsafe knowledge. In the supplementary D, we report the zero-shot generalization of our method. 5.2.1. Safety retrieval comparison We evaluate our model on the capability of retrieving safe and unsafe items, in comparison to CLIP [69] and Safe-CLIP [66]. We also provide comparison to recent hyperbolic VLMs, namely MERU [20] and HyCoCLIP [63]. Safe-CLIP and HySAC fine-tuned from CLIP on ViSU [66], MERU trained on RedCaps [19], and HyCoCLIP on GRIT [65]. For fair comparison, we additionally fine-tuned the CLIP model on the ViSU dataset in hyperbolic space, using MERU and HyCoCLIP2 losses. All the models are evaluated on the ViSU test set. Retrieval tasks are defined as text-to-image and imageto-text, where the goal is to find the most relevant counterpart for given query. Recall@K measures the fraction of queries where the correct item appears in the top-K retrieved results. To assess the safe retrieval performance of HySAC, we measure recall exclusively on safe content in both visual and textual elements (T -to-I and I-to-T ). This step is crucial to verify that the original CLIP models retrieval capabilities are retained after finetuning in hyperbolic space with our training method. Then, to evaluate 2The box data needed for HyCoCLIP was extracted using Kosmos-2. the safety-awareness capabilities of HySAC, we introduce distinct setup in which NSFW elements are used as queries, while the retrievable items include both safe and unsafe elements (T -to-I and -to-T ). During these experiments, retrieval is deemed correct only if the query retrieves its safe counterpart, thereby validating the models ability to redirect unsafe queries towards safe items. When retrieving with HySAC, the threshold τ for moving query embeddings is computed using the mean distance of safe embeddings from the origin, adjusting the query embedding towards the safe region. Results are reported in Table 1, where we observe that HySAC consistently improves over both unlearning and existing hyperbolic models and features the highest recalls across all settings and rates. CLIP hyperbolic models finetuned on ViSU data (MERU and HyCoCLIP) perform well on safe-only retrieval, while our method achieves high performance on both safe-only and unsafe-safe retrieval, due to our safety-aware design. In Table 2, we instead perform analyses for unsafe content retrieval. First, this involves the text-to-image and image-to-text retrieval on only unsafe elements (T -to-I and -to-T ). Second, instead, we perform retrieval by using unsafe elements as queries and both safe and unsafe items as retrievable items (T -to-I and -to-T ), and deem the retrieval correct only if the query retrieves its corresponding unsafe one. This setup tests the models ability to function as content moderator and also showcases its capacity to provide user autonomy in content retrieval decisions. In these tests, the traversal mechanism in % Safe (Text-to-Image) % Safe (Image-to-Text) Model NudeNet NSFW URLs SMID NudeNet NSFW URLs SMID CLIP Safe-CLIP HySAC 78.2 92.6 96. 79.7 92.6 93.9 55.2 83.4 80.1 33.3 75.2 84.4 44.0 76.4 95.1 59.1 65.6 97.9 Table 4. Retrieval performance on real NSFW images. Rate of safe images retrieved using unsafe prompts from the ViSU test set. The retrievable set includes safe and unsafe real images, with the latter from LAION-400M and the former from NSFW sources. distance from all embeddings of the training set, i.e. the ℓ2 normalization of the average of all embeddings. As it can be seen, the distribution clearly shows four peak distributions for HySAC, each one representing one of the content types, elucidating the efficacy of our approach in maintaining clear separation between safe, unsafe, textual, and visual content within the embedding space. Ablation Study. In Table 3, we validate the effectiveness of the key components in HySAC, by comparing its full configuration with variants where specific losses are disabled. In particular, we employ one variant which only keeps contrastive losses (denoted as w/o Ent) and one that omits the safety-entailment loss (w/o S-Ent). Results show that while removing these components slightly improves performance in scenarios involving only safe content, likely due to reduced spatial constraints, their absence significantly undermines the models effectiveness in dealing with unsafe content, especially in unsafe-to-safe retrieval. These results underscore the essential roles that both the modalityand safety-entailment losses play in enhancing the safety awareness of the proposed model. Retrieval on real NSFW datasets. To further analyze the safety of HySAC, we conduct retrieval tests using NudeNet [4], NSFW data source URLs and SMID [18]. The first two datasets primarily contain nudity and pornographic content, whereas SMID includes broader range of inappropriate content, such as violence, harm, and discrimination. We randomly select 1000 images from each dataset to serve as visual elements and use 5k NSFW captions from the ViSU test set. Both the image-to-text and text-to-image retrieval tasks also incorporate 10,000 randomly chosen retrievable safe items from LAION-400M [77]. Results, displayed in Table 4, contrast the performance of HySAC with that of CLIP [69] and Safe-CLIP [66]. We report the proportion of safe retrieval outputs when NSFW queries are used, highlighting the capability of HySAC to enhance safety in retrieval results. Traversing the embedding space towards safety prioritizes safer alternatives, which may adjust relevance in some cases. Due to the absence of datasets with real unsafe data and correlated safe alternatives, this aspect could not be evaluated. Notably, HySAC demonstrates improved performance in securing safer content compared to Safe-CLIP across most datasets for both text-to-image and image-to-text scenarios. Figure 2. Distributions of embedding distances from the root. We embed all ViSU training samples and visualize their distance distribution from the root. While CLIP and Safe-CLIP do not separate between texts and images, MERU does. HySAC, instead, also differentiates between safe and unsafe content. (T -to-I) (I-to-T ) (T -to-I ) (I -to-T ) Model w/o Ent w/o S-Ent HySAC R@1 R@10 R@1 R@10 R@1 R@10 R@1 R@10 64.5 52.3 63.7 51.0 73.3 49.8 84.9 84.2 84.1 50.8 49.8 48.2 84.7 84.3 84. 49.0 39.1 62.8 4.1 1.4 30.5 5.5 7.4 42.1 Table 3. Ablation study on loss components. We evaluate HySAC against two ablations that remove loss components. Results are in the same setting of Table 1. HySAC uses adjusted parameters to move in the unsafe direction, targeting the retrieval of NSFW content. Here too, HySAC achieves the best recall across all settings, demonstrating that HySAC not only prioritizes safety by navigating away from NSFW content when required but also ensures that users can access NSFW content under controlled conditions, better than existing competitors. 5.2.2. Analysis of HySAC Assessing HySAC embedding space. Further, we validate the organization of the embedding space as outlined in Equation 7. Our goal is to confirm that the embeddings for safe content are positioned closer to the origin of hyperbolic space, while those for unsafe content are further away, following the proposed hierarchy. Specifically, for each {T, I, , } of the training-set of D, we compute the distances dL(X, r) from the root feature r. visualization is reported in Figure 2, where we show the distribution of embeddings in terms of their distance to the root feature. The comparative analysis is done across four different models: HySAC, CLIP, Safe-CLIP, and MERU. For both the hyperbolic models the root feature is the origin of the hyperboloid. For the Euclidean models, since the origin does not lie on the hypersphere, the root is empirically estimated as the embedding that has the least Figure 3. Qualitative traversal results. HySAC traverses towards the root feature, retrieving the top-1 text at each interpolation point. This traversal effectively transitions from unsafe to safe captions, demonstrating the models ability to ensure safety-aware content retrieval. Model NSFW-CNN [46] CLIP-classifier [76] CLIP-distance [70] NudeNet [4] Q16 [74] HySAC NudeNet Mixed NSFW Acc 85.3 97.3 86.4 91.2 28.5 99.5 FPR FNR 0.0 0.0 0.0 0.0 0.0 0. 14.7 2.7 13.6 8.8 71.5 0.5 Acc 66.5 76.9 77.8 76.9 65.3 78.9 FPR FNR 4.5 0.1 2.0 4.5 8.3 16. 35.9 11.0 22.1 24.6 29.4 6.8 Table 5. NSFW classification. Comparison between HySAC and other NSFW classifiers. Metrics reported in percentages. Classifying NSFW content. The structure of the embedding space in HySAC also supports the classification of NSFW content. We evaluate this using the NudeNet [4] and Mixed NSFW datasets, comparing against classifiers such as NSFW-CNN [46], CLIP-classifier [76], CLIPdistance [70], NudeNet [4], and Q16 [74]. NudeNet only contains nudity, while Mixed NSFW includes different NSFW categories from various online sources and safe images from PASS [1]. We sample 1,000-image subset from NudeNet and 442 images from Mixed NSFW, balanced between safe and unsafe. Further details of these datasets are provided in the supplementary C. Results in Table 5 show that HySAC achieves competitive or superior results in NSFW content classification, despite not being explicitly designed for safety classification. The norm threshold, set to the ViSU dataset mean (Figure 2), differentiates safe from unsafe content. 5.2.3. Visualizing the safety traversals We examine traversal paths for safe text retrievals, starting with an unsafe image embedding as the query. The traversals are along the geodesic of hyperbolic space from the image to the origin of the hyperboloid, denoted [ROOT]. The input query is an unsafe image taken from ViSU test set and the text retrieval space consists of mix of safe and unsafe captions of ViSU test set, metadata-based caption from pexels.com, and curated list of unsafe words3. To create visualization shown in Figure 3, each retrieved text output is selected only once across all interpolation points, ensuring unique retrievals. Results show that, with HySAC, as the query nears the origin, retrieved content shifts from unsafe to safe while preserving semantic relevance. This progression illustrates the models capability to effectively navigate the embedding space along relevant paths. For more on the experimental setup and traversal visualizations, see the supplementary E. Other ablation studies. For additional ablations on embedding space geometry and hyperparameter evaluation, we refer the reader to the supplementary D. 6. Conclusion introduces hyperbolic safety-aware visionThis paper language models. Where recent literature focuses on removing or unlearning unsafe image-text content, we bring perspective of awareness. By modelling unsafe image-text content as specific cases of their safe counterparts, we can divide the space into safe and unsafe regions. We show that hyperbolic space is natural solution for this hierarchical relation, and propose hyperbolic CLIP model with safety entailment learning and traversal. Our approach not only results in better retrieval of relevant safe outputs given unsafe inputs but also provides more robustness and comes with an NSFW classifier as free by-product. Dealing with NSFW data in vision-language models is an important open research problem with real-world implications, from ethical to legal and societal concerns. By opting for awareness, we find that safety recognition improves. Given the importance of the ethical implications of this work, we provide thorough discussion in the supplementary A. 3github.com/LDNOOBW/"
        },
        {
            "title": "Acknowledgements",
            "content": "We acknowledge the CINECA award under the ISCRA initiative, for the availability of high-performance computing resources. This work has been supported by the EU Horizon projects ELIAS - European Lighthouse of AI for Sustainability (No. 101120237) and European Lighthouse on Safe and Secure AI (ELSA) (No. 101070617), co-funded by the European Union. Tejaswi Kasarla also acknowledges travel support from the European Unions Horizon research and innovation programme under grant agreement No. 951847 (ELISE) and No. 101120237 (ELIAS)."
        },
        {
            "title": "References",
            "content": "[1] Yuki M. Asano, Christian Rupprecht, Andrew Zisserman, and Andrea Vedaldi. Pass: An imagenet replacement for self-supervised pretraining without humans. NeurIPS Track on Datasets and Benchmarks, 2021. 8, 13 [2] Mina Ghadimi Atigh, Julian Schoep, Erman Acar, Nanne Van Noord, and Pascal Mettes. Hyperbolic image segmentation. In CVPR, pages 44534462, 2022. 2 [3] Gary Becigneul and Octavian-Eugen Ganea. RiemanarXiv preprint nian adaptive optimization methods. arXiv:1810.00760, 2018. 2 [4] Bedapudi. NudeNet: Neural Nets for Nudity Classification, Detection, and Selective Censoring, 2019. 2, 5, 7, 8, 14 [5] Abeba Birhane and Vinay Uday Prabhu. datasets: pyrrhic win for computer vision? pages 15361546. IEEE, 2021. 1, 2, 3, 5 Large image In WACV, [6] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963, 2021. 1 [7] Abeba Birhane, Sanghyun Han, Vishnu Boddeti, Sasha Luccioni, et al. Into the laions den: Investigating hate in multimodal datasets. NeurIPS, 36, 2024. 1 [8] Manuel Brack, Felix Friedrich, Patrick Schramowski, and Kristian Kersting. Mitigating inappropriateness in image generation: Can there be value in reflecting the worlds ugliness? arXiv preprint arXiv:2305.18398, 2023. 2 [9] Yinzhi Cao and Junfeng Yang. Towards Making Systems In IEEE Symposium on Forget with Machine Unlearning. Security and Privacy, 2015. 2 [10] Francesco Cauteruccio, Enrico Corradini, Giorgio Terracina, Domenico Ursino, and Luca Virgili. Extraction and analysis of text patterns from nsfw adult content in reddit. Data & Knowledge Engineering, 138:101979, 2022. 2 [11] Benjamin Paul Chamberlain, James Clough, and Marc Peter Deisenroth. Neural embeddings of graphs in hyperbolic space. arXiv preprint arXiv:1705.10359, 2017. 2 [12] Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi, and Christopher Re. Low-dimensional hyarXiv preprint perbolic knowledge graph embeddings. arXiv:2005.00545, 2020. 2 [13] Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollar, and Lawrence Zitnick. Microsoft COCO Captions: Data Collection and Evaluation Server. arXiv preprint arXiv:1504.00325, 2015. 14 [14] Mehdi Cherti, Romain Beaumont, Ross Wightman, Mitchell Wortsman, Gabriel Ilharco, Cade Gordon, Christoph Schuhmann, Ludwig Schmidt, and Jenia Jitsev. Reproducible scaling laws for contrastive language-image learning. In CVPR, pages 28182829, 2023. [15] Jason Chuan-Chih Chou and Nahid Alam. Embedding geometries of contrastive language-image pre-training. arXiv preprint arXiv:2409.13079, 2024. 15 [16] Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, and Chandan Reddy. Self-supervised hyperboloid representations from logical queries over knowledge graphs. In Proceedings of the Web Conference 2021, pages 13731384, 2021. 2 [17] Nurendra Choudhary, Nikhil Rao, and Chandan Reddy. Hyperbolic graph neural networks at scale: meta learning approach. NeurIPS, 36, 2024. 2 [18] Damien Crone, Stefan Bode, Carsten Murawski, and Simon Laham. The socio-moral image database (smid): novel stimulus set for the study of social, moral and affective processes. PloS one, 13(1):e0190954, 2018. 5, 7, 14 [19] Karan Desai, Gaurav Kaul, Zubin Aysola, and Justin Johnson. RedCaps: Web-curated image-text data created by the In NeurIPS Datasets and Benchpeople, for the people. marks, 2021. 6 [20] Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson, and Shanmukha Ramakrishna Vedantam. HyperIn ICML, pages 7694 bolic image-text representations. 7731. PMLR, 2023. 1, 2, 3, 4, 6 [21] Bhuwan Dhingra, Christopher Shallue, Mohammad Norouzi, Andrew Dai, and George Dahl. Embedding text in hyperbolic spaces. arXiv preprint arXiv:1806.04313, 2018. [22] Upol Ehsan, Vera Liao, Samir Passi, Mark Riedl, and Hal Daume III. Seamful xai: Operationalizing seamful design in explainable ai. Proceedings of the ACM on HumanComputer Interaction, 8(CSCW1):129, 2024. 1 [23] Aleksandr Ermolov, Leyla Mirvakhabova, Valentin Khrulkov, Nicu Sebe, and Ivan Oseledets. Hyperbolic vision transformers: Combining improvements in metric learning. In CVPR, pages 74097419, 2022. 2 [24] Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John M. Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. Int. J. Comput. Vis., 88(2):303338, 2010. 14 [25] Luca Franco, Paolo Mandica, Bharti Munjal, and Fabio Galasso. Hyperbolic self-paced learning for self-supervised skeleton-based action representations. In ICLR, 2023. 2 [26] Shreyansh Gandhi, Samrat Kokkula, Abon Chaudhuri, Alessandro Magnani, Theban Stanley, Behzad Ahmadi, Venkatesh Kandaswamy, Omer Ovenc, and Shie Mannor. Scalable Detection of Offensive and Non-compliant Content/Logo in Product Images. In WACV, 2020. [27] Rohit Gandikota, Jaden FiottoKaufman, and David Bau. Erasing Concepts from Diffusion Models. In ICCV, 2023. 1, 2 Joanna Materzynska, [28] Octavian Ganea, Gary Becigneul, and Thomas Hofmann. Hyperbolic entailment cones for learning hierarchical embeddings. In ICML, pages 16461655. PMLR, 2018. 1, 2, 4, 15 [29] Octavian Ganea, Gary Becigneul, and Thomas Hofmann. Hyperbolic neural networks. NeurIPS, 31, 2018. [30] Songwei Ge, Shlok Mishra, Simon Kornblith, Chun-Liang Li, and David Jacobs. Hyperbolic contrastive learning for visual representations beyond objects. In CVPR, pages 6840 6849, 2023. 2 [31] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012. 14 [32] Antonio Ginart, Melody Guan, Gregory Valiant, and James Zou. Making AI Forget You: Data Deletion in Machine Learning. In NeurIPS, 2019. 2 [33] Aditya Golatkar, Alessandro Achille, and Stefano Soatto. Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks. In CVPR, 2020. 2 [34] Aditya Golatkar, Alessandro Achille, Yu-Xiang Wang, Aaron Roth, Michael Kearns, and Stefano Soatto. Mixed Differential Privacy in Computer Vision. In CVPR, 2022. 2 [35] Kimia Hamidieh, Haoran Zhang, Walter Gerych, Thomas Identifying implicit Hartvigsen, and Marzyeh Ghassemi. social biases in vision-language models. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pages 547561, 2024. 1 [36] Ahmad Fathan Hidayatullah, Anisa Miladya Hakim, and Abdullah Aziz Sembada. Adult Content Classification on Indonesian Tweets using LSTM Neural Network. In ICACSIS, 2019. [37] Micah Hodosh, Peter Young, and Julia Hockenmaier. Framing image description as ranking task: Data, models and Journal of Artificial Intelligence Reevaluation metrics. search, 47:853899, 2013. 14 [38] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021. 5, 13 [39] Sarah Ibrahimi, Mina Ghadimi Atigh, Nanne Van Noord, Pascal Mettes, and Marcel Worring. Intriguing properties of hyperbolic embeddings in vision-language models. Transactions on Machine Learning Research, 2024. 2 [40] Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. Scaling up visual and vision-language representation learning with noisy text supervision. In ICML, pages 4904 4916. PMLR, 2021. 1 [41] Justin Johnson, Bharath Hariharan, Laurens Van Der Maaten, Li Fei-Fei, Lawrence Zitnick, and Ross Girshick. Clevr: diagnostic dataset for compositional language and elementary visual reasoning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 29012910, 2017. 14 [42] Valentin Khrulkov, Leyla Mirvakhabova, Evgeniya Ustinova, Ivan Oseledets, and Victor Lempitsky. Hyperbolic image embeddings. In CVPR, pages 64186428, 2020. 2, 3 [43] Alex Kim. Nsfw data scraper. https://github.com/ alex000kim, 2019. 14 [44] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. [45] Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, and Jun-Yan Zhu. Ablating concepts in text-to-image diffusion models. In ICCV, 2023. 2 [46] Gant Laborde. Deep nn for nsfw detection. https:// github.com/GantMan/nsfw_model, 2020. 8, 14 [47] Matthew Le, Stephen Roller, Laetitia Papaxanthos, Douwe Kiela, and Maximilian Nickel. Inferring concept hierarchies from text corpora via hyperbolic embeddings. In ACL, pages 32313241, 2019. 2, 4 [48] Warren Leu, Yuta Nakashima, and Noa Garcia. Auditing image-based nsfw classifiers for content filtering. In The 2024 ACM Conference on Fairness, Accountability, and Transparency, pages 11631173, 2024. 14 [49] Fei-Fei Li, Marco Andreeto, MarcAurelio Ranzato, and Pietro Perona. Caltech 101, 2022. 14 [50] Ya-Wei Eileen Lin, Ronald Coifman, Gal Mishne, and Ronen Talmon. Hyperbolic diffusion embedding and distance In ICML, pages for hierarchical representation learning. 2100321025. PMLR, 2023. [51] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. NeurIPS, 36, 2024. 1 [52] Qi Liu, Maximilian Nickel, and Douwe Kiela. Hyperbolic graph neural networks. NeurIPS, 32, 2019. 2 [53] Shaoteng Liu, Jingjing Chen, Liangming Pan, Chong-Wah Ngo, Tat-Seng Chua, and Yu-Gang Jiang. Hyperbolic visual embedding learning for zero-shot recognition. In CVPR, pages 92739281, 2020. 2 [54] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In ICLR, 2019. 5 [55] Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng. Holistic Approach to Undesired Content Detection in the Real World. In AAAI, 2023. 2 [56] Joanna Materzynska, Antonio Torralba, and David Bau. DisIn CVPR, entangling visual and written concepts in clip. pages 1641016419, 2022. 1 [57] Pascal Mettes, Mina Ghadimi Atigh, Martin Keller-Ressel, Jeffrey Gu, and Serena Yeung. Hyperbolic deep learning in computer vision: survey. IJCV, pages 125, 2024. 2 [58] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, et al. Mixed precision training. In ICLR, 2018. 5 [59] Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets, and Alexander Tuzhilin. Performance of hyperbolic geometry models on top-n recommendation tasks. In Proceedings of the 14th ACM Conference on Recommender Systems, pages 527532, 2020. 2 [60] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. arXiv preprint arXiv:2112.10741, 2021. 2 [61] Maximillian Nickel and Douwe Kiela. Poincare embeddings for learning hierarchical representations. NeurIPS, 30, 2017. 2 [62] Maximillian Nickel and Douwe Kiela. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. In ICML, pages 37793788. PMLR, 2018. 2 [63] Avik Pal, Max van Spengler, Guido Maria DAmely di Melendugno, Alessandro Flaborea, Fabio Galasso, and Pascal Mettes. Compositional entailment learning for hyperbolic vision-language models. arXiv preprint arXiv:2410.06912, 2024. 1, 2, 3, 4, 6 [64] Wei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, and Guoying Zhao. Hyperbolic deep neural networks: survey. IEEE Trans. PAMI, 44(12):1002310044, 2021. 2 [65] Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. Kosmos-2: Grounding multimodal large language models to the world. arXiv preprint arXiv:2306.14824, 2023. 6 [66] Samuele Poppi, Tobia Poppi, Federico Cocchi, Marcella Cornia, Lorenzo Baraldi, and Rita Cucchiara. Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models. In ECCV, 2024. 1, 2, 3, 4, 5, 6, 7, 13, [67] Samuele Poppi, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita Cucchiara. Multi-Class Unlearning for Image Classification via Weight Filtering. IEEE Intelligent Systems, 2024. 2 [68] Samuele Poppi, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita Cucchiara. Unlearning vision transformers without retaining data via low-rank decompositions. In ICPR, 2024. 2 [69] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, pages 87488763. PMLR, 2021. 1, 3, 4, 5, 6, 7, 14 [70] Javier Rando, Daniel Paleka, David Lindner, Lennart Heim, and Florian Tramer. Red-teaming the stable diffusion safety filter. In NeurIPS ML Safety Workshop, 2022. 8, 14 [71] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, pages 10684 10695, 2022. 1, 14 [72] Frederic Sala, Chris De Sa, Albert Gu, and Christopher Re. Representation tradeoffs for hyperbolic embeddings. In ICML, pages 44604469. PMLR, 2018. [73] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. DistilBERT, distilled version of BERT: arXiv preprint smaller, arXiv:1910.01108, 2019. 2 faster, cheaper and lighter. [74] Patrick Schramowski, Christopher Tauchmann, and Kristian Kersting. Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content? In ACM FAccT, 2022. 2, 8, 14 [75] Patrick Schramowski, Manuel Brack, Bjorn Deiseroth, and Kristian Kersting. Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models. In CVPR, 2023. 2, 3 [76] Christoph Schuhmann. Clip based nsfw detector. https: //github.com/LAIONAI/CLIPbasedNSFWDetector/tree/main, 2022. 8, [77] Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021. 1, 5, 7 [78] Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. Laion-5b: An open large-scale dataset for training next generation image-text models. NeurIPS, 35:25278 25294, 2022. 14 [79] Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei Chang, Zhewei Yao, and Kurt Keutzer. How much can clip benefit vision-and-language tasks? arXiv preprint arXiv:2107.06383, 2021. 1 [80] Ryohei Shimizu, Yusuke Mukuta, and Tatsuya Harada. Hyperbolic neural networks++. ICLR, 2021. 2 [81] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In CVPR, pages 28182826, 2016. [82] David Thiel. Identifying and eliminating csam in generative ml training data and models. 2023. 1 [83] Alexandru Tifrea, Gary Becigneul, and Octavian-Eugen Ganea. Poincare glove: Hyperbolic word embeddings. arXiv preprint arXiv:1810.06546, 2018. 2 [84] Max van Spengler, Erwin Berkhout, and Pascal Mettes. Poincare resnet. In ICCV, pages 54195428, 2023. 2 [85] Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and language. arXiv preprint arXiv:1511.06361, 2015. 4 [86] Liping Wang, Fenyu Hu, Shu Wu, and Liang Wang. Fully hyperbolic graph convolution network for recommendation. In Proceedings of the 30th ACM international conference on information & knowledge management, pages 34833487, 2021. 2 [87] Mengmeng Wang, Jiazheng Xing, and Yong Liu. Actionclip: new paradigm for video action recognition. arXiv preprint arXiv:2109.08472, 2021. [88] Robert Wolfe, Yiwei Yang, Bill Howe, and Aylin Caliskan. Contrastive language-vision ai models pretrained on webscraped multimodal data exhibit sexual objectification bias. In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, pages 11741185, 2023. 1 [89] Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:6778, 2014. 14 [90] Eric Zhang, Kai Wang, Xingqian Xu, Zhangyang Wang, and Humphrey Shi. Forget-Me-Not: Learning to Forget in Textto-Image Diffusion Models. CVPR, 2024. 2 [91] Yudong Zhu, Di Zhou, Jinghui Xiao, Xin Jiang, Xiao Chen, and Qun Liu. Hypertext: Endowing fasttext with hyperbolic geometry. arXiv preprint arXiv:2010.16143, 2020."
        },
        {
            "title": "Supplementary",
            "content": "Warning: This supplementary features explicit sexual content and other material that some readers may find disturbing, distressing, or offensive. In the following sections, we present additional materials about HySAC. Firstly, we discuss the ethical implications and limitations of the proposed approach (Section A). We provide additional details about our training procedure (Section B) and NSFW classification (Section C). Moreover, we report zero-shot robustness, further ablation studies, and qualitative results of hyperbolic space traversal (Section D, E). A. Discussion and Limitations This paper underscores the need for nuanced approach to content moderation in VLMs, contributing robust starting point for future research and deployment in this critical domain. Below, we discuss the ethical implications and limitations of our work. Ethical Implications. Our approach emphasizes transparency by enabling users to distinguish between safe and unsafe content, rather than concealing potentially harmful material through unlearning. This empowers users with greater control and insight into the AI systems behavior, aligning with principles of fairness and accountability in AI. However, this increased transparency also places the ethical responsibility to use such tools appropriately, underscoring the need for clear guidelines to ensure responsible use. Additionally, the datasets used to train VLMs often mirror societal biases, which can propagate or even exacerbate discrimination if not addressed. While our method does not explicitly eliminate unsafe content, the hyperbolic framework provides mechanism to systematically organize and mitigate its impact. Still, there is an ethical imperative to ensure that the boundary definitions of safe and unsafe content are inclusive, equitable, and free from cultural or ideological bias. Dual-use implications. The ability to handle unsafe content is deliberate choice aimed at retaining transparency and control. Unlike unlearning-based methods, HySAC maintains awareness of unsafe content, enabling safer redirection while offering greater accountability. This also facilitates the identification of biases or training deficiencies, which are harder to detect in an unlearning setting. It is important to note that any vision-language model (including standard CLIP) can be misused for harmful purposes. HySAC will be released with an implementation that does not support traversal toward unsafe areas. Deploying entities can also enforce tailored restrictions to align the models behavior with cultural, legal, or organizational needs, such as blocking unsafe retrievals entirely. HySAC mitigates misuse risks while fostering accountability and transparency. Limitations and future work. While our model can organize appropriate and inappropriate concepts in wide variety of cases, it does not provide any guarantee of success. For instance, it might fail to redirect towards appropriate content under certain conditions. Addressing these shortcomings will require further work, such as expanding the training dataset to include more diverse and varied examples to reduce the impact of these failures. Additionally, integrating HySAC with generative frameworks like Stable Diffusion presents promising direction. This would require adapting the U-Net architecture to the hyperbolic embeddings from HySAC. This adaptation would enable the traversal mechanism during the encoding of an unsafe prompt. Such integration could enhance control over generated content while preserving creative flexibility. B. Training Details Here, we report additional training details necessary for reproducibility. GPUs. We train HySAC in distributed setup for 15 hours using 8 A100 GPUs (64GB), with batch size of 32 per GPU. LoRA configuration. The low-rank adaptation [38] is applied to all attention layers and fully connected layers of both the text and visual encoders. In the attention layers, we apply LoRA to the keys and value projections, along with the final output projection of each attention block. Additionally, we finetune the patch embedding layer in the visual encoder. To prevent overfitting, we use LoRA dropout rate of 0.1, while setting the LoRA α parameter to 1 to ensure stability during finetuning. Memory usage and training times. Average VRAM usage is 54.9GB for Safe-CLIP [66] and 56.5GB for HySAC. Training times per epoch are 24 minutes for Safe-CLIP and 37 minutes for HySAC. With early stopping (patience = 5), Safe-CLIP converges in 10 epochs, while HySAC requires 20 due to the added complexity of hyperbolic modeling. C. NSFW Classification We expand on the datasets and methods mentioned in Table 5. Finally, we present an ablation of the threshold parameter for NSFW classification using HySAC. C.1. Additional details on datasets Mixed NSFW. The Mixed NSFW dataset used in Table 5 comprises 442 images collected from various NSFW sources across the internet. The dataset is divided as follows: (i) 237 safe images randomly sampled from the PASS [1] dataset, which contains natural images without persons; (ii) 205 NSFW images collected from various sources depicting nudity4, violence/blood5, and firearms6. NudeNet Mixed NSFW Thresh. Acc FNR Acc FPR FNR C.2. Baselines The settings for NSFW-CNN [46], CLIP-Classifier [76], and CLIP-distance [70] are taken from Leu et al. [48], and we briefly summarize them below for reference, along with NudeNet [4] and Q16 [74]. NSFW-CNN. NSFW-CNN [46] uses InceptionV3 [81] trained on data obtained from an NSFW scraper [43]. An image is classified as unsafe if any of the predicted NSFW categories has confidence score above 0.7; otherwise, it is labeled as safe. CLIP-Classifier. CLIP-Classifier [76] employs the CLIP image encoder (VIT-L/14) [14] with an added fully connected layer for binary classification, trained on subset of the LAION-5B dataset [78]. Images with classifier confidence score above 0.7 are marked as NSFW. CLIP-Distance. CLIP-Distance uses the CLIP VIT-L/14 image encoder [14] and classifies images based on their cosine similarity to the text embeddings of 17 predefined strings representing NSFW concepts. This approach was employed in the safety checker of Stable Diffusion [71]. We utilize the code implementation from Rando et al.7 to classify an image as NSFW or safe. NudeNet. NudeNet [4] ensembles multiple networks trained for detecting nudity. Images are classified as NSFW if the probability of an unsafe class exceeds 0.7. Q16. Q16 [74] uses CLIP [69] models, prompt-tuned with socio-moral value datasets [18] to identify NSFW content. C.3. Ablation of the threshold for HySAC classifier. HySAC determines the threshold for classifying NSFW images based on the norm of the embedding, using the mean of the distribution norms from Figure 2 as the threshold. The NSFW classification performance of HySAC is reported for 0.1 intervals around this mean threshold. In Table 6, we demonstrate the impact of the threshold hyperparameter on NSFW retrievals for NudeNet and examine the tradeoff between safe and unsafe retrievals for the Mixed NSFW dataset. We observe that for NudeNet, increasing the threshold leads to decrease in accuracy and an increase in the False Negative Rate (FNR), indicating more NSFW content being misclassified as safe. In contrast, for the Mixed NSFW dataset, accuracy improves up to threshold of 0.53 before declining at higher thresholds, reflecting balance between the False Positive Rate (FPR) 4Images labeled as unsafe from the validation set of roboflow/nuditydataset. 5Images depicting violence from drive/violence-data. 6Images from the validation set of roboflow/weapon-dataset. 7See Randos Colab Notebook. 0.51 0.52 0.53 0.54 0.55 100 99.5 89.2 59.6 59.6 0.0 0.5 10.8 40.4 40. 50.7 59.7 78.5 75.4 62.8 53.6 43.7 16.5 3.6 2.0 0.0 0.2 6.8 23.1 38.4 Table 6. Ablation of NSFW Classification Threshold for HySAC. This table shows the trade-off between safe and unsafe classification performance as the threshold varies. Accuracy, FPR, and FNR are reported in percentages. The bold values indicate the best performance, and the underlined values indicate the second best. Values corresponding to the threshold of 0.51, although best for FNR (i.e., NSFW classification), come at the cost of higher misclassification of safe content and are thus not bolded. Rows highlighted in purple correspond to the results reported in Table 5. and FNR. These results highlight the inherent trade-off between FPR and FNR when adjusting the threshold. Moreover, we hypothesize that fine-tuning the radius of the hyperboloid which influences the norm of the embeddings could enhance the separation between embeddings, leading to improved precision in classifying safe images. This suggests that further refinement of the embedding space could significantly boost the classification performance. D. Additional Experimental Results and Ablations Here, we show the zero-shot retrieval and classification performance of HySAC in comparison to baseline models. We also show the retrieval performance of HySAC across various NSFW categories of the ViSU test set. Finally, we present further ablation studies to evaluate the impact of hyperbolic geometry in our proposed approach. D.1. Robustness evaluation We evaluate the cross-modal zero-shot retrieval capabilities of HySAC compared to CLIP and Safe-CLIP on Flickr8K [37], Flickr30K [89] and COCO [13]. Additionally, we benchmark the zero-shot classification performance on CIFAR-10 [44], VOC [24], Caltech-101 [49], KITTI [31], and CLEVR [41]. Table 7 showcases that HySAC can preserve or improve performance on all retrieval tasks. CLIP fine-tuned hyperbolic models (MERU and HyCoCLIP achieve similar scores as our method, highlighting the benefit of hyperbolic space. For the zeroshot classification task, performances have only partially deteriorated, with good integrity on most datasets. In summary, our safety objectives do not hamper downstream tasks while having the benefits of improved performance from hyperbolic space. Flickr8k Flickr30k MS COCO Zero-Shot Classification Model T2I I2T T2I I2T T2I I2T C10 VOC C101 KT CL 86.4 94.0 87.3 97.3 61.1 79.3 44.4 53.9 37.9 45.9 32.0 40.9 83.3 92.9 86.0 93.4 60.3 71.8 87.4 93.9 89.9 96.0 72.4 84.0 CLIP MERU HyCoCLIP Safe-CLIP MERU 93.0 96.8 94.7 98.7 75.8 87.5 HyCoCLIP 92.2 95.9 93.9 98.7 73.1 84.8 92.1 96.2 93.2 97.9 75.1 85.4 HySAC 95.6 78.3 83.3 21.7 19.4 67.9 58.4 70.9 10.3 18.4 90.8 70.7 79.7 26.7 16.6 88.9 76.5 81.4 29.4 22. 93.6 82.0 85.9 24.3 27.7 92.8 67.9 83.7 23.1 21.5 93.6 81.7 82.2 32.6 23.2 Table 7. CLIP robustness preservation results. Metrics: R@5 for zero-shot retrieval, top-1 accuracy for zero-shot classification. Hate Harassment Violence Self-harm Sexual Shocking Illegal Act. Model CLIP MERU HyCoCLIP Safe-CLIP MERU HyCoCLIP HySAC I2T T2I T2I 6.0 5.2 8.1 8.4 9.7 15.0 3.3 15.9 5.2 15.9 32.1 14.9 4.4 3.6 9.3 2.0 11.0 3.6 64.6 76.8 61.0 I2T 9.2 12.8 16.9 28.9 8.8 8.4 71.5 I2T I2T T2I T2I 4.1 7.9 2.5 5.6 8.3 13.8 3.2 6.8 2.7 8.7 2.1 12.6 11.0 23.6 13.8 33.9 8.8 2.0 6.8 1.3 7.8 7.9 42.5 53.5 66.5 73.6 2.5 3.8 I2T T2I I2T T2I 3.0 4.8 3. I2T T2I 6.3 2.3 5.1 2.3 4.3 7.3 4.6 7.9 5.9 6.0 6.1 4.1 12.9 6.3 7.8 10.6 20.2 12.2 28.0 11.3 24.0 6.3 3.7 5.7 1.9 3.9 11.7 6.1 8.0 2.4 7.4 50.7 57.7 53.8 66.0 44.9 55.8 2.9 2.3 Table 8. Retrieval (R@1) for seven categories of unsafe content from ViSU test. D.2. HySAC Across NSFW Categories. In Table 8, we report results across NSFW categories of the ViSU dataset, which demonstrates the generalization capabilities of HySAC across topics. D.3. Ablation on Geometry of the Embedding Space To better understand the role of geometry in embedding safety-aware hierarchical relationships, we perform two key ablation studies. These studies explore the performance of embeddings in Euclidean and hyperbolic spaces using modified versions of HySAC and other safety-aware frameworks. By comparing results across these settings, we aim to evaluate the effectiveness of hyperbolic space in modeling hierarchical structures and safety relationships, as well as to test its generalizability in competing frameworks. Euclidean Safety-Aware CLIP. We train HySAC in Euclidean space, keeping the loss functions and hyperparameters identical to the original model. For this setup, we adopt Euclidean Entailment Cones introduced in Ganea et al. [28] and defined for vision-language models in Chou et al. [15]. In Euclidean space, the half-aperture of each conical region, Seucq, is calculated as Note that in both hyperbolic and Euclidean settings, we do not normalize the embeddings. The training is performed using the standard CLIP contrastive loss. This ablation allows for direct comparison of the effectiveness of hyperbolic versus Euclidean geometry in embedding the hierarchical relationships between safe and unsafe content. The results, as shown in Table 9, highlight the benefits of using hyperbolic space for capturing entailment and safety relationships, ultimately leading to improved retrieval performance and enhanced safety-awareness capabilities. Additionally, Figure 4 compares the distributions of the distances of all embeddings from the root for the ViSU test set, between HySAC and Euclidean Safety-Aware CLIP. In both models, the root is represented by the origin of the space. The distributions show four clear peaks corresponding to each one of the , I, , and groups of data, while this is not observable for the Euclidean version. Hyperbolic Safe-CLIP. We train Safe-CLIP [66] in hyperbolic space where we keep all the same loss functions as the original Safe-CLIP but replace Euclidean space with hyperbolic space. Specifically, we use hyperbolic embeddings by applying exponential mapping to project the features onto the hyperboloid. By adapting Safe-CLIP to hyperbolic space, we aim to evaluate the impact of using hyperbolic space in competing framework and compare its performance to HySAC. The results, reported in Table 9, demonstrate that incorporating hyperbolic geometry in Safe-CLIP alone is not sufficient to ensure safety during retrieval. This study allows us to determine whether the advantages we observe with HySAC are unique to our approach or if hyperbolic space can generally enhance safety-awareness capabilities across other frameworks as well. (T -to-I) (I-to-T ) (T -to-I ) (I -to-T ) Model R@1 R@10 R@1 R@10 R@1 R@10 R@1 R@10 Euc EC 32.8 Hyp Safe-CLIP 46.9 72.0 82.3 31.5 42. 0.2 51.7 75.4 82.5 35.7 44.7 2.1 5.1 0.0 9.8 HySAC 49.8 84.1 48.2 84.2 30.5 62. 42.1 73.3 Table 9. Ablation study on Euclidean space and hyperbolic Safe-CLIP. We evaluate HySAC against its Euclidean version which employs Euclidean entailment cones and against Safe-CLIP finetuned in hyperbolic space. ωeuc(q) = sin1 (cid:18) (cid:19) , (18) D.4. Hyperparameter ablations for η where is constant fixed to 0.1 which limits values near the origin, and is the Euclidean embedding. For pair (p, q) , where is subconcept of q, the exterior angle ϕeuc(p, q) is given by ϕeuc(p, q) = cos1 (cid:18) (q p) pp (cid:19) . (19) Here, we report the hyperparameter ablations for η, which is the multiplier for half-aperture in the entailment loss (Equation 13 in the main paper). This parameter controls the width of the entailment cone. η < 1 narrows the entailment cone, enforcing stricter hierarchical constraints, whereas η > 1 widens it, relaxing these constraints. In HySAC, η is set to 1 and performs the best on unsafe-safe retrievals as pool of safe and unsafe texts. The text pool is composed of safe and unsafe captions of ViSU test set, 748 metadatabased captions from pexels.com, and curated list of 402 unsafe words8. The retrieval results are reported in Figure 5 and show shift from unsafe to safe captions as the image embeddings while approaching the root, effectively illustrating the ability of HySAC to perform safety-aware adjustments in the embedding space. E.2. Unsafe Image to Safe Image Traversal The second experiment focuses on redirecting unsafe image queries toward their corresponding safe images. Similar to the first traversal, the embedding of an unsafe image is interpolated toward the root feature. This interpolation creates intermediate query embeddings, which are then used to retrieve images from pool that contains both safe and unsafe images from the ViSU test set. As the traversal progresses, the retrieved images, as shown in Figure 6, increasingly belong to the safe category. This demonstrates that HySAC can effectively guide unsafe visual content toward safer alternatives. E.3. Safe Image to Safe Text Retrieval The final experiment evaluates how well HySAC preserves performance on safe data. Here, safe image queries are used to retrieve captions exclusively from pool of safe text, sourced from the ViSU test set and metadata from pexels.com. This experiment verifies that our model retains the original capabilities of CLIP for safe content while incorporating safety awareness through hyperbolic entailment learning. The results, shown in Figure 7, confirm that the traversal mechanism maintains semantic integrity, ensuring that safe queries yield safe responses without unintended alterations. Additionally, as the traversal progresses, hierarchical structure emerges: the retrieved captions become more specific as the query moves closer to the image embedding and more general as it approaches the root feature. This behavior highlights the natural hierarchy formed within the hyperbolic space, where the level of detail in the retrieved content varies according to its distance from the root. This further highlights the robustness of HySAC in retaining desirable behaviors for safe content. 8github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-andOtherwise-Bad-Words Figure 4. Distributions of embedding distances from the root. Comparison of the distance distributions of Euclidean and hyperbolic embeddings from the root. Euclidean version of HySAC does not separate between safe and unsafe content, while HySAC does. reported in Table 10. Though η > 1 slightly improves safesafe retrievals, it heavily degrades the safety performance. (T -to-I) (I-to-T ) (T -to-I ) (I -to-T ) η = 0.25 η = 0.5 η = 0.75 η = 1.25 η = 1.5 η = 1.75 HySAC R@1 R@10 R@1 R@10 R@1 R@10 R@1 R@10 57.8 43.8 49.3 37.5 72.0 47.1 63.3 51.7 65.5 51.4 65.2 51.7 73.3 49.8 42.6 35.7 43.3 49.3 50.8 50.7 48. 79.5 73.1 80.8 84.6 84.8 84.8 84.2 80.2 74.9 81.8 85.1 84.8 84.7 84.1 17.4 7.8 28.5 20.1 4.0 2.2 30.5 6.0 4.9 41.4 3.6 6.6 5.1 42.1 53.8 41.9 59.8 62.2 49.5 46.2 62.8 Table 10. Hyperparameter ablations for η. We train HySAC with different half-aperture scales, comparing only safe recalls and unsafe to safe recalls. In HySAC, η is set to 1.0. E. Image and text traversals: details and visualizations In this section, we detail additional settings to visualize how effective HySAC is at managing unsafe and safe content through image and text traversals. We describe the experimental settings for each of the three types of traversals presented in Figures 5, 6, and 7, highlighting the strategies employed to transition between unsafe and safe regions in the hyperbolic space. E.1. Unsafe Image to Safe Text Traversal In the first experiment, we show the safety traversal using unsafe images as queries to gradually find safer, relevant captions. We begin by selecting set of unsafe image embeddings from the ViSU test set. These embeddings are firstly mapped to the tangent Euclidean space by applying logarithmic mapping. Then they are linearly interpolated with the origin of the hyperbolic space, which represents the root feature. During each traversal step, interpolation points are mapped back onto the hyperboloid through exponential mapping and used as new queries to retrieve captions from Figure 5. Traversals from unsafe image queries towards safe captions. We present qualitative results of HySAC, showing the traversals from unsafe image queries toward the root feature. Interpolation points along this path are used as new queries to retrieve captions from pool of both safe and unsafe texts. Figure 6. Traversals from unsafe image queries towards safe images. We illustrate how HySAC can guide the transition from unsafe image queries to corresponding safe images, utilizing intermediate interpolation steps along the traversal path. Figure 7. Traversals from safe image queries to safe text. We demonstrate how HySAC effectively maintains its performance on safe data by using safe image queries to retrieve captions exclusively from pool of safe text."
        }
    ],
    "affiliations": [
        "IIT-CNR, Italy",
        "University of Amsterdam, Netherlands",
        "University of Modena and Reggio Emilia, Italy",
        "University of Pisa, Italy"
    ]
}